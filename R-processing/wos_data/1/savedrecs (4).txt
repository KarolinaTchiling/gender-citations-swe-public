FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Kuo, YH
   Yang, JF
   Chen, J
AF Kuo, Yonghong
   Yang, Jiefeng
   Chen, Jian
TI An efficient mode decision algorithm for H.264/AVC intra prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264/AVC; Intra prediction; Texture direction difference; Sum of
   absolute transform difference
ID DISTORTION ESTIMATION; BLOCK SIZE
AB Rate distortion optimization technique is adopted by H.264/AVC to select the best intra and inter prediction modes. It achieves remarkable improvement in compression performance, but the computational complexity of coding increases greatly. In order to reduce the computational complexity as much as possible while guaranteeing the video encoding quality and compression efficiency, this paper proposes a fast mode decision method based on the texture direction information of intra prediction modes and the encoding macroblocks. For intra luminance prediction, the proposed algorithm utilizes the smoothness of the encoding macroblock to select the suitable intra prediction block sizes, and then uses the texture direction difference to filter out low possibility prediction modes. The calculation expressions of texture direction difference can be derived by extracting texture direction features from intra prediction modes. For intra chrominance prediction, the candidate prediction modes are determined by a combination of texture direction difference and the sum of absolute transformed difference, which doesn't significantly degrade peak-signal-noise-rate or increase bit rate. Based on the processing, the number of rate distortion cost calculations decreases dramatically, which indicates a significant reduction of computation cost for intra prediction. Compared with JM11.0 reference software, the proposed algorithm can cut down about 76.79 % total intra-frame coding time at the expense of only about 0.08 dB peak-signal-noise-rate degradation and 2.07 % bit rate increase. It proves that the proposed algorithm achieves a tradeoff between the rate distortion performance and the computational complexity.
C1 [Kuo, Yonghong; Yang, Jiefeng; Chen, Jian] Xidian Univ, Sch Telecommun Engn, Xian 710071, Peoples R China.
C3 Xidian University
RP Kuo, YH (corresponding author), Xidian Univ, Sch Telecommun Engn, Xian 710071, Peoples R China.
EM kuoyonghongxd@yahoo.com.cn
RI KUO, Yong-Hong/M-9078-2015
FU National Science Foundation China [60972072]; 111 Project of China
   [B08038]
FX This work was supported by the National Science Foundation China under
   grant 60972072 and the 111 Project of China (B08038).
CR Chen CN, 2013, MULTIMED TOOLS APPL, V62, P719, DOI 10.1007/s11042-011-0862-6
   Huang YH, 2010, IEEE T CIRC SYST VID, V20, P1122, DOI 10.1109/TCSVT.2010.2057018
   Lim K, 2012, IEEE T CONSUM ELECTR, V58, P654, DOI 10.1109/TCE.2012.6227473
   Lin Yu-Kun, 2005, P IEEE INT C IM PROC, V1, pI
   Moon JM, 2010, IEEE T CIRC SYST VID, V20, P207, DOI 10.1109/TCSVT.2009.2031389
   Pan F, 2005, IEEE T CIRC SYST VID, V15, P813, DOI 10.1109/TCSVT.2005.848356
   Quan D, 2010, IEEE T CONSUM ELECTR, V56, P1049, DOI 10.1109/TCE.2010.5506038
   Sarwer MG, 2008, SIGNAL PROCESS-IMAGE, V23, P571, DOI 10.1016/j.image.2008.05.002
   Sarwer MG, 2007, IEEE T CIRC SYST VID, V17, P1402, DOI 10.1109/TCSVT.2007.903787
   Su XQ, 2011, MULTIMED TOOLS APPL, V52, P65, DOI 10.1007/s11042-009-0452-z
   Tian GF, 2008, 2008 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2008), VOLS 1-4, P1348, DOI 10.1109/APCCAS.2008.4746278
   Tsai AC, 2008, IEEE T CIRC SYST VID, V18, P694, DOI 10.1109/TCSVT.2008.919113
   Tu YK, 2006, IEEE T CIRC SYST VID, V16, P600, DOI 10.1109/TCSVT.2006.873160
   Wang JC, 2007, IEEE T CIRC SYST VID, V17, P1414, DOI 10.1109/TCSVT.2007.903786
   Wang P, 2012, MULTIMED TOOLS APPL, V60, P139, DOI 10.1007/s11042-011-0807-0
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zeng HQ, 2010, IEEE T CIRC SYST VID, V20, P907, DOI 10.1109/TCSVT.2010.2045802
   Zhang K, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P673
NR 18
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1803
EP 1821
DI 10.1007/s11042-013-1480-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300034
DA 2024-07-18
ER

PT J
AU Shamsi, A
   Nezamabadi-pour, H
   Saryazdi, S
AF Shamsi, Asma
   Nezamabadi-pour, Hossein
   Saryazdi, Saeid
TI A short-term learning approach based on similarity refinement in
   content-based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Relevance feedback; Short-term learning;
   Similarity refinement; Query refinement
ID RELEVANCE FEEDBACK; INFORMATION-RETRIEVAL; CLASSIFICATION; COLOR
AB This paper presents a new relevance feedback approach based on similarity refinement. In the proposed approach weight correction of feature's components is done by a proposed rule set using mean and standard deviation of feature vectors of relevant (positive) and irrelevant (negative) images. Also, the weight of each type of features is adjusted according to the relevant images' rank in the retrieval based on only the same type of feature. To evaluate the performance of the proposed method, a set of comparative experiments on a general database containing 20,000 images of various semantic groups are performed. The results confirm the effectiveness of the proposed method comparing with two well-known methods.
C1 [Shamsi, Asma; Nezamabadi-pour, Hossein; Saryazdi, Saeid] Shahid Bahonar Univ Kerman, Dept Elect Engn, Kerman, Iran.
C3 Shahid Bahonar University of Kerman (SBUK)
RP Nezamabadi-pour, H (corresponding author), Shahid Bahonar Univ Kerman, Dept Elect Engn, POB 76169-133, Kerman, Iran.
EM nezam@uk.ac.ir
RI Saryazdi, Saeid/GQY-9790-2022; Saryazdi, Saeid/D-4488-2015; Saryazdi,
   Saeid/GQZ-0186-2022; Nezamabadi-pour, Hossein/AAB-4009-2019
OI Saryazdi, Saeid/0000-0002-4577-1971; Saryazdi,
   Saeid/0000-0002-4577-1971; Nezamabadi-pour, Hossein/0000-0002-3350-7348
FU Iran Telecommunication Research Center, ITRC
FX The authors would like to thank the MTAP Editorial Board and the
   anonymous reviewers for their very helpful suggestions. This work was
   supported in part by the Iran Telecommunication Research Center, ITRC.
CR Albanesi MG, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P410, DOI 10.1109/ICIAP.2001.957044
   [Anonymous], 2003, PROC ACM SPECIAL INT, DOI [10.1145/872757.872829, DOI 10.1145/872757.872829]
   [Anonymous], COLOR IMAGE PROCESSI
   [Anonymous], 2000, Em: Proceedings of the 2000 ACM workshops on Multimedia, DOI DOI 10.1145/357744.357758
   Barrett S, 2009, IEEE INT CON MULTI, P838, DOI 10.1109/ICME.2009.5202625
   Bertini M, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING WORKSHOPS, PROCEEDINGS, P160, DOI 10.1109/ICIAPW.2007.43
   Chen YX, 2005, IEEE T IMAGE PROCESS, V14, P1187, DOI 10.1109/TIP.2005.849770
   Cheng PC, 2008, EXPERT SYST APPL, V34, P2193, DOI 10.1016/j.eswa.2007.02.030
   Clough P, 2008, LNCS, V5152, P473
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Deselaers T, 2008, INT C PATT RECOG, P2100
   He XF, 2003, IEEE T CIRC SYST VID, V13, P39, DOI 10.1109/TCSVT.2002.808087
   Huang TS, 2002, 2ND INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING, PROCEEDINGS, P155, DOI 10.1109/DEVLRN.2002.1011829
   ISO/IECJTC1/SC29/WG11 Coding of Moving pictures and audio, 2000, JTC1SC29WG11 ISOIEC
   Laaksonen J, 2004, PATTERN ANAL APPL, V2-3, P140
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   MacArthur SD, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P68, DOI 10.1109/IVL.2000.853842
   Manjunath B.S., 2002, INTRO MPEG 7
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Modaghegh H., 2010, AUST J BASIC APPL SC, V4, P171
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Nezamabadi-Pour H, 2004, PATTERN RECOGN LETT, V25, P1547, DOI 10.1016/j.patrec.2004.05.019
   Nezamabadi-pour H, 2004, J COMPUT SCI ENG, V2, P37
   Nezamabadi-pour H, 2005, J MODARRES, V22, P89
   Nezambadi-pour H, 2009, EXPERT SYST APPL, V36, P5948, DOI 10.1016/j.eswa.2008.07.008
   Papa JP, 2009, INT J IMAG SYST TECH, V19, P120, DOI 10.1002/ima.20188
   Park S. J., 2000, M5984 MPEG
   Qian F, 2003, MULTIMED TOOLS APPL, V21, P35, DOI 10.1023/A:1025030131788
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   Rubner Y, 2001, COMPUT VIS IMAGE UND, V84, P25, DOI 10.1006/cviu.2001.0934
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621
   Schettini R., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P75, DOI 10.1109/ICIP.1999.817072
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith JR, 1999, COMPUT VIS IMAGE UND, V75, P165, DOI 10.1006/cviu.1999.0771
   Wan X, 1998, IEEE T CIRC SYST VID, V8, P628, DOI 10.1109/76.718509
   Wei LY, 2009, PATTERN RECOGN, V42, P1126, DOI 10.1016/j.patcog.2008.08.028
   Wood M. E. J., 1998, Proceedings ACM Multimedia 98, P13, DOI 10.1145/290747.290750
   Wu J, 2010, LECT NOTES COMPUT SC, V5916, P650
   Xu XQ, 2009, NEUROCOMPUTING, V72, P2259, DOI 10.1016/j.neucom.2008.12.029
   Yoo HW, 2002, PATTERN RECOGN, V35, P749, DOI 10.1016/S0031-3203(01)00072-3
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
   Zhuang YT, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P62, DOI 10.1109/CGI.2001.934659
NR 44
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 2025
EP 2039
DI 10.1007/s11042-013-1503-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300044
DA 2024-07-18
ER

PT J
AU Xiao, QK
   Luo, YC
   Wang, HY
AF Xiao, Qinkun
   Luo, Yichuang
   Wang, Haiyun
TI Motion retrieval based on Switching Kalman Filters Model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion retrieval; Multi-view; Graph model; S-KFM
AB A novel content-based motion descriptor is proposed. Firstly, the multi-view image information is captured to represent motion, and then the Switching Kalman Filters Model (S-KFM), which is a kind of the Dynamic Bayesian Network (DBN), is built based on the images fusion and the optical stream technology. Secondly, through the S-KFM inferring and sequence signal coding, a graph-based motion descriptor can be obtained. Lastly, motion matching results based on the graph model descriptor show our method is effective.
C1 [Xiao, Qinkun; Luo, Yichuang] Xian Technol Univ, Dept Elect Informat Engn, Xian 710032, Peoples R China.
   [Wang, Haiyun] STMicroelect R&D Asia Pacific, Singapore 554574, Singapore.
C3 Xi'an Technological University; STMicroelectronics
RP Xiao, QK (corresponding author), Xian Technol Univ, Dept Elect Informat Engn, Xian 710032, Peoples R China.
EM xiaoqinkun10000@163.com; 623634511@qq.com; haiyun_w@gmail.com
FU National Basic Research Project of China [2010CB731800]; China National
   Foundation [60972095, 61271362]
FX This work is partly supported by the National Basic Research Project of
   China (No. 2010CB731800) and the China National Foundation (No.
   60972095, 61271362).
CR [Anonymous], 2004, P INT C VERY LARGE D
   Bashir FI, 2007, IEEE T MULTIMEDIA, V9, P58, DOI 10.1109/TMM.2006.886346
   Chakrabarti K, 2002, ACM T DATABASE SYST, V27, P188, DOI 10.1145/568518.568520
   Chao MW, 2012, IEEE T VIS COMPUT GR, V18, P729, DOI 10.1109/TVCG.2011.53
   Duan XH, 2013, IEEE T MULTIMEDIA, V15, P167, DOI 10.1109/TMM.2012.2225029
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Huang Q, 2010, IEEE T CIRC SYST VID, V20, P673, DOI 10.1109/TCSVT.2010.2045807
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Lin Y., 2006, Proceedings of the 4th international Conference on Computer Graphics and interactive Techniques in Australasia and Southeast Asia (Kuala Lumpur, Malaysia, November 29 - December 02, 2006), P31
   Liu F, 2003, COMPUT VIS IMAGE UND, V92, P265, DOI 10.1016/j.cviu.2003.06.001
   Liu XB, 2011, IEEE T CIRC SYST VID, V21, P1588, DOI 10.1109/TCSVT.2011.2129410
   Muller M, 2006, P ACM SCA
   Nixon MS, 2008, FEATURE EXTRACTION I, P135
   Pavlovic V., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P94, DOI 10.1109/ICCV.1999.791203
   Russell S, 2004, ARTIF INTELL, P430
   Shah VP, 2008, IEEE T GEOSCI REMOTE, V46, P1323, DOI 10.1109/TGRS.2008.916211
   Tam GKL, 2007, IEEE T VIS COMPUT GR, V13, P470, DOI 10.1109/TVCG.2007.1011
   Tang JKT, 2012, PATTERN RECOGN LETT, V33, P420, DOI 10.1016/j.patrec.2011.06.005
   Tian JW, 2011, INT J SOFTW ENG KNOW, V21, P523, DOI 10.1142/S0218194011005396
   Xiao QK, 2008, ELECTRON LETT, V44, P847, DOI 10.1049/el:20080314
   Xiao QK, 2011, NEUROCOMPUTING, V74, P3486, DOI 10.1016/j.neucom.2011.06.002
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Zhang Z, 2012, IEEE T PATTERN ANAL, V34, P436, DOI 10.1109/TPAMI.2011.157
NR 24
TC 7
Z9 8
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 951
EP 966
DI 10.1007/s11042-013-1416-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800043
DA 2024-07-18
ER

PT J
AU Chen, CM
   Chen, LH
AF Chen, Chun-Min
   Chen, Ling-Hwei
TI A novel approach for semantic event extraction from sports webcast text
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic event detection; Webcast text; Information retrieval; Video
   retrieval
AB Semantic event extraction is helpful for video annotation and retrieval. For sports video, most previous works detect events by video content itself. Some useful external knowledge has been researched recently. In this paper, we proposed an unsupervised approach to extract semantic events from sports webcast text. First, unrelated words in the descriptions of webcast text are filtered out, and then the filtered descriptions are clustered into significant event categories. Finally, the keywords for each event category are extracted. According to our experimental results, the proposed approach actually extracts significant text events, which can be used for further video indexing and summarization. Furthermore, we also provide a hierarchical searching scheme for text event retrieval.
C1 [Chen, Chun-Min; Chen, Ling-Hwei] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chen, LH (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 300, Taiwan.
EM cmchen@debut.cis.nctu.edu.tw; lhchen@cc.nctu.edu.tw
FU National Science Council of Republic of China
   [NSC-100-2221-E-009-140-MY2]
FX This work is supported in part by National Science Council of Republic
   of China under grant NSC-100-2221-E-009-140-MY2.
CR Chen YH, 2011, INT C GEN EV COMP IC
   Hassan E, 2011, INT C COMP VIS WORKS
   Kim HG, 2011, IEEE INT CON MULTI
   Manning C, 2008, INTRO INFORM RETRIEV, P27
   Nitta N, 2005, MULTIMED TOOLS APPL, V25, P59, DOI 10.1023/B:MTAP.0000046382.62218.e1
   Schreer O, 2010, MULTIMED TOOLS APPL, V48, P23, DOI 10.1007/s11042-009-0375-8
   Shen JL, 2008, IEEE T CIRC SYST VID, V18, P1587, DOI 10.1109/TCSVT.2008.2005607
   Shyu ML, 2008, IEEE T MULTIMEDIA, V10, P252, DOI 10.1109/TMM.2007.911830
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P1342, DOI 10.1109/TMM.2008.2004912
   XU H, 2004, P WORKSH MULT INF RE
   Zhou HY, 2010, NEUROCOMPUTING, V73, P1718, DOI 10.1016/j.neucom.2009.09.022
   Zhu XQ, 2005, IEEE T KNOWL DATA EN, V17, P665, DOI 10.1109/TKDE.2005.83
NR 12
TC 10
Z9 14
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1937
EP 1952
DI 10.1007/s11042-012-1323-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000043
DA 2024-07-18
ER

PT J
AU Yan, B
   Guo, YJ
   Liu, XF
AF Yan, Bin
   Guo, Yin-Jing
   Liu, Xiao-Feng
TI Condition for energy efficient watermarking without WSS assumption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Energy efficient watermarking; Matrix Wiener filter; Eigen-Value
   Decomposition (EVD); Hilbert space; Linear Prediction Analysis (LPA)
ID SPEECH WATERMARKING; INFORMATION; SYNCHRONIZATION; SECURITY
AB Energy efficient watermarking preserves the watermark energy after linear attack as much as possible. We consider in this paper the non-stationary signal models and derive conditions for energy efficient watermarking under random vector model without wide sense stationary (WSS) assumption. We find that the covariance matrix of the energy efficient watermark should be proportional to the host covariance matrix to best resist the optimal linear removal attacks. For WSS process model, our result reduces to the well-known power spectrum condition. Intuitive geometric interpretations of the results in Hilbert space of random vectors are discussed, which also provides us simpler proof of the main results. Practical implementation of the covariance matrix shaped watermark for speech signal using linear prediction analysis (LPA) and image signal using eigen-value decomposition (EVD) are also presented and tested, showing improved performance as compared to lowpass and Su's global watermark.
C1 [Yan, Bin; Guo, Yin-Jing] Shandong Univ Sci & Technol, Sch Informat & Elect Engn, Dept Commun Engn, Qingdao 266510, Shandong, Peoples R China.
   [Liu, Xiao-Feng] Hohai Univ, Coll Comp & Informat Engn, Nanjing 213022, Jiangsu, Peoples R China.
C3 Shandong University of Science & Technology; Hohai University
RP Yan, B (corresponding author), Shandong Univ Sci & Technol, Sch Informat & Elect Engn, Dept Commun Engn, Qingdao 266510, Shandong, Peoples R China.
EM yanbinhit@hotmail.com; xfliubme@gmail.com
RI Yan, Bin/Y-7642-2019; Liu, Xiaofeng/JCD-9463-2023; Liu,
   Xiaofeng/HHN-3239-2022
OI Liu, Xiaofeng/0000-0003-1310-6739; Liu, Xiaofeng/0000-0003-1310-6739;
   Yan, Bin/0000-0003-2929-464X
FU National Natural Science Foundation of China (NSFC) [61272432]; Qingdao
   science and technology development plan [12-1-4-6-(10)-jch]; NSFC
   [61071087, 60905060]; natural science foundation of Shandong province
   [ZR2011FM018]
FX This work is supported by the project of National Natural Science
   Foundation of China (NSFC) under project grant number: 61272432. The
   work of Bin Yan is also supported by Qingdao science and technology
   development plan (No. 12-1-4-6-(10)-jch). The work of Yin-Jing Guo is
   supported by the project of NSFC under project grant number: 61071087,
   and the natural science foundation of Shandong province(ZR2011FM018).
   The work of Xiao-Feng Liu is supported by the project of NSFC under
   project grant number: 60905060. The authors would like to thank the
   anonymous reviewers for their constructive comments and suggestions. We
   are indebted to the reviewers for their valuable time spent on the
   manuscript of this paper. The first author would like to thank Prof.
   Zhe-Ming Lu, Prof. Sheng-He Sun, Prof. Jeng-Shyang Pan and Prof. Xia-Mu
   Niu for their guidance and help. Their insight in watermarking research
   have significant influence on this work.
CR [Anonymous], 1993, Discrete Time Processing of Speech Signals
   [Anonymous], 2006, SPR S STAT
   [Anonymous], 2002, Discrete-Time Speech Signal Processing: Principles and Practice
   [Anonymous], 2007, EEG SIGNAL PROCESSIN, DOI DOI 10.1002/9780470511923
   [Anonymous], 1998, FUNDAMENTALS STAT SI
   Balado F, 2005, IEEE T SIGNAL PROCES, V53, P4006, DOI 10.1109/TSP.2005.855412
   Barni J., 2004, WATERMARKING SYSTEMS
   Celik M., 2005, P 2005 IEEE INT C AC
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cheng Q, 2001, INT CONF ACOUST SPEE, P1337, DOI 10.1109/ICASSP.2001.941175
   Cheng Q., 2005, United States Patent, Patent No. [US6892175B1, 6892175]
   Chu W.C., 2003, SPEECH CODING ALGORI
   Coumou DJ, 2008, IEEE T INF FOREN SEC, V3, P153, DOI 10.1109/TIFS.2008.920728
   Coumou DJ, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P849, DOI 10.1109/ICME.2006.262634
   Cox IJ, 1999, P IEEE, V87, P1127, DOI 10.1109/5.771068
   Cox IJ., 2007, DIGITAL WATERMARKING
   Dietl GKE, 2007, FOUND SIGNAL PROCESS, V1, P1
   Gang LT, 2002, INT CONF ACOUST SPEE, P3736
   GERBRANDS JJ, 1981, PATTERN RECOGN, V14, P375, DOI 10.1016/0031-3203(81)90082-0
   Gray RM, 2006, FOUND TRENDS COMMUN, V2, DOI 10.1561/0100000006
   Hofbauer K, 2009, IEEE T AUDIO SPEECH, V17, P1624, DOI 10.1109/TASL.2009.2021543
   Hwang YH, 2002, PROC SPIE, V4675, P441, DOI 10.1117/12.465302
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jayant N.C., 1984, Digital Coding of Waveforms: Principles and Applications to Speech and Video
   Kay S. M., 1988, Modern Spectral Estimation: Theory and Application
   Kay S. M., 1993, FUNDAMENTALS STAT SI
   Kejariwal A, 2006, IEEE T VLSI SYST, V14, P625, DOI 10.1109/TVLSI.2006.878218
   Lee LT, 2009, THESIS NATL TAIWAN U
   Luenberger DG, 1997, OPTIMIZATION VECTOR
   Moulin P, 2003, IEEE T INFORM THEORY, V49, P563, DOI 10.1109/TIT.2002.808134
   Moulin P, 2001, IEEE INT C IM PROC T
   Orfanidi SJ, 2007, SVD PCA KLT CCA ALL
   Pai YT, 2005, LECT NOTES ARTIF INT, V3681, P1219
   Painter T, 2000, P IEEE, V88, P451, DOI 10.1109/5.842996
   Panda J., 2011, 2011 Proceedings of International Conference on Computational Intelligence and Communication Networks (CICN 2011), P202, DOI 10.1109/CICN.2011.40
   Pateux S, 2002, ELSEVIER SIGNAL PROC, P283
   Pérez-González F, 2003, IEEE T SIGNAL PROCES, V51, P960, DOI 10.1109/TSP.2003.809368
   Sadasivam S, 2011, IEEE T INF FOREN SEC, V6, P894, DOI 10.1109/TIFS.2011.2129511
   Sakaguchi S, 2000, INT CONF ACOUST SPEE, P917
   SCHONEMANN PH, 1985, MULTIVAR BEHAV RES, V20, P113, DOI 10.1207/s15327906mbr2002_1
   Sequeira A, 2001, PROC SPIE, V4518, P216, DOI 10.1117/12.448206
   Su J. K., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P301, DOI 10.1109/ICIP.1999.821618
   Su JK, 2002, IEEE T MULTIMEDIA, V4, P551, DOI 10.1109/TMM.2002.806535
   Su JK, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P530, DOI 10.1109/MMCS.1999.778540
   Wang HG, 2013, MULTIMED TOOLS APPL, V67, P119, DOI 10.1007/s11042-011-0928-5
   Yan B, 2010, J MEASUREMENT SCI IS, V1, P271
   Yan B, 2011, P 1 INT C PERV COMP, P1009
   Yan B, 2011, ICIC EL, V5, P2179
   Yan B, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1227
   Yan B, 2006, IEEE T INF FOREN SEC, V1, P386, DOI 10.1109/TIFS.2006.879285
   ZUE V, 1990, SPEECH COMMUN, V9, P351, DOI 10.1016/0167-6393(90)90010-7
NR 51
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1499
EP 1528
DI 10.1007/s11042-012-1291-x
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000024
DA 2024-07-18
ER

PT J
AU Kim, J
   Chung, KY
AF Kim, Jonghun
   Chung, Kyung-Yong
TI Ontology-based healthcare context information model to implement
   ubiquitous environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Context information model; Ontology; Healthcare service; Personalized
   ubiquitous service
AB To establish real u-healthcare environments, it is necessary to receive the context information obtained from various platforms at the proper time in portable devices which operate using both wired and wireless communication. Moreover, a knowledge model is required that reflects the information and characteristics needed for such services while remaining appropriate for medical reference. This paper develops an ontology-based healthcare context information model to implement a ubiquitous environment. Contextual information will be extracted and classified to implement the healthcare services using the context information model. The healthcare context information model can be defined using the ontology, and a common healthcare model will be developed by considering medical references and service environments. Application and healthcare service developers can use the sensed information in various environments by authoring device- and space-specific ontologies based on this common ontology. In addition, this paper designs a personalized u-healthcare service system. The validity of the model used in this study is evaluated for the food and exercise recommendation in u-healthcare services.
C1 [Kim, Jonghun] BIT Comp Co Ltd, U Healthcare Dept, Seoul, South Korea.
   [Chung, Kyung-Yong] Sangji Univ, Sch Comp Informat Engn, Wonju, Gangwon, South Korea.
C3 Sangji University
RP Chung, KY (corresponding author), Sangji Univ, Sch Comp Informat Engn, Wonju, Gangwon, South Korea.
EM kimjh@bit.kr; dragonhci@gmail.com
RI Chung, Kyungyong/JAC-2276-2023
FU Basic Science Research Program through the National Research Foundation
   of Korea - Ministry of Education, Science and Technology [2011-0008934]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea funded by the Ministry of
   Education, Science and Technology. (No. 2011-0008934)
CR Choi YS., 1999, KOR J NUTR, V32, P681
   Dobrev P, 2002, IEEE COMMUN MAG, V40, P86, DOI 10.1109/MCOM.2002.1024420
   Gong L, 2001, IEEE INTERNET COMPUT, V5, P64, DOI 10.1109/4236.895144
   Lee MeeSook Lee MeeSook, 2004, Korean Journal of Community Nutrition, V9, P695
   McCarthy H., 1993, IJCAI-93. Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, P555
   Samulowitz M, 2001, NEW DEV DISTRIBUTED, P22
   Schilit B., 1994, 1994 1 WORKSHOP MOBI, P85, DOI [DOI 10.1109/WMCSA.1994.16, 10.1109/WMCSA.1994.16]
   Schmidt A, 1999, COMPUT GRAPH-UK, V23, P893, DOI 10.1016/S0097-8493(99)00120-X
   Schmidt A., 2001, COMMUNICATION
   Sheng QZ, 2005, ICMB 2005: International Conference on Mobile Business, P206, DOI 10.1109/ICMB.2005.33
NR 10
TC 103
Z9 108
U1 2
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 873
EP 888
DI 10.1007/s11042-011-0919-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400030
DA 2024-07-18
ER

PT J
AU Serral, E
   Gil, M
   Valderas, P
   Pelechano, V
AF Serral, Estefania
   Gil, Miriam
   Valderas, Pedro
   Pelechano, Vicente
TI Automating unobtrusive personalized services in ambient media
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unobtrusive ambient media; Personalized services; Context awareness
ID SYSTEMS; COMMUNICATION; PRINCIPLES; MODELS
AB In the age of ambient media, people are surrounded by lots of physical objects (media objects) for rendering the digital world in the natural environment. These media objects should interact with users in a way that is not disturbing for them. To address this issue, this work presents a design and automation strategy for augmenting the world around us with personalized ambient media services that behave in a considerate manner. That is, ambient services are capable of adjusting its obtrusiveness level (i.e., the extent to which each service intrudes the user's mind) by using the appropriate media objects for each user's situation.
C1 [Serral, Estefania] Vienna Univ Technol, Christian Doppler Lab Software Engn Integrat Flex, A-1040 Vienna, Austria.
   [Gil, Miriam; Valderas, Pedro; Pelechano, Vicente] Univ Politecn Valencia, Ctr Invest Metodos Prod Software, Valencia 46022, Spain.
C3 Technische Universitat Wien; Universitat Politecnica de Valencia
RP Serral, E (corresponding author), Vienna Univ Technol, Christian Doppler Lab Software Engn Integrat Flex, Favoritenstr 9-11-188, A-1040 Vienna, Austria.
EM estefania.serral@tuwien.ac.at; mgil@pros.upv.es; pvalderas@pros.upv.es;
   pele@pros.upv.es
RI Gil, Miriam/AAB-1461-2020; Gil, Miriam/HGD-5342-2022; Serral,
   Estefanía/I-8123-2018; Valderas, Pedro/X-3605-2018; Pelechano,
   Vicente/S-4344-2016
OI Gil, Miriam/0000-0002-2987-1825; Serral, Estefanía/0000-0001-7579-910X;
   Valderas, Pedro/0000-0002-4156-0675; Pelechano,
   Vicente/0000-0003-1090-230X
FU MICINN, under the project EVERYWARE [TIN2010-18011]; Christian Doppler
   Forschungsgesellschaft; BMWFJ, Austria
FX This work has been developed with the support of MICINN, under the
   project EVERYWARE TIN2010-18011, and the support of the Christian
   Doppler Forschungsgesellschaft and the BMWFJ, Austria.
CR Bencomo N, 2008, ICSE'08 PROCEEDINGS OF THE THIRTIETH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, P811, DOI 10.1145/1368088.1368207
   Blumendorf M, 2010, EICS 2010: PROCEEDINGS OF THE 2010 ACM SIGCHI SYMPOSIUM ON ENGINEERING INTERACTIVE COMPUTING SYSTEMS, P9
   Brown D.M., 2010, Communicating design: Developing web site documentation for design and planning
   Calinescu Radu., 2011, Proceedings of the 8th Workshop on Assurances for Self-adaptive Systems, P1, DOI [10.1145/2024436.2024438., DOI 10.1145/2024436.2024438]
   Filieri A, 2011, 2011 33RD INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P341, DOI 10.1145/1985793.1985840
   Gershenfeld N, 2004, SCI AM, V291, P76, DOI 10.1038/scientificamerican1004-76
   Gibbs WW, 2005, SCI AM, V292, P54, DOI 10.1038/scientificamerican0105-54
   Gulliksen J, 2003, BEHAV INFORM TECHNOL, V22, P397, DOI 10.1080/01449290310001624329
   Hinckley K., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P191, DOI 10.1145/502348.502382
   Ho J., 2005, P SIGCHI C HUMAN FAC, P909
   Horvitz E, 2003, COMMUN ACM, V46, P52, DOI 10.1145/636772.636798
   Ju W, 2008, DES ISSUES, V24, P72, DOI 10.1162/desi.2008.24.3.72
   Kortuem G, 2010, IEEE INTERNET COMPUT, V14, P44, DOI 10.1109/MIC.2009.143
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Lugmayr A, 2009, MULTIMED TOOLS APPL, V44, P337, DOI 10.1007/s11042-009-0282-z
   Mattern F., 2003, Proceedings of the Smart Objects Conference (SOC 03), P15
   Morin B, 2009, COMPUTER, V42, P44, DOI 10.1109/MC.2009.327
   NELSON L, 2005, SMART OBJ SYST WORKS
   Paterno F., 2003, MODEL BASED NATURAL, P592
   Paterno Fabio., 2002, The Handbook of Analysis for Human-Computer Interaction, P483, DOI DOI 10.1111/J.1467-923X.1954.TB00152.X
   Ramchurn SD, 2004, PROCEEDINGS OF MOBIQUITOUS 2004, P364
   Runeson P, 2009, EMPIR SOFTW ENG, V14, P131, DOI 10.1007/s10664-008-9102-8
   Schmidt A., 2000, Personal Technologies, V4, P191, DOI 10.1007/BF01324126
   Serral E, 2010, PERVASIVE MOB COMPUT, V6, P254, DOI 10.1016/j.pmcj.2009.07.006
   Serral E, 2010, LECT NOTES COMPUT SC, V6051, P378, DOI 10.1007/978-3-642-13094-6_30
   Siegemund F, 2004, LECT NOTES COMPUT SC, V3001, P69
   Streitz NA, 2005, COMPUTER, V38, P41, DOI 10.1109/MC.2005.92
   Thiesse Frederic, 2008, Electronic Markets, V18, P232, DOI 10.1080/10196780802265751
   Vastenburg MH, 2008, PERS UBIQUIT COMPUT, V12, P555, DOI 10.1007/s00779-007-0176-x
NR 29
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 159
EP 178
DI 10.1007/s11042-013-1634-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700008
OA Green Published
DA 2024-07-18
ER

PT J
AU Lee, H
   Baek, J
   Kim, E
AF Lee, Heesung
   Baek, Jeonghyun
   Kim, Euntai
TI A probabilistic image-weighting scheme for robust silhouette-based gait
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; Silhouette-based gait recognition; PSVM; CASIA
   database; SOTON database; Biometrics
ID REPRESENTATION
AB Many gait recognition methods use silhouettes as a feature due to their simplicity and effectiveness. However, silhouette-based gait recognition algorithms have the drawback of performance degradation when the silhouette images are corrupted. To solve this problem, this paper proposes a new gait representation method by emphasizing the noise-free silhouettes while suppressing the corrupted ones. The probabilistic support vector machine (PSVM) is employed to weigh the silhouette images according to quality and to construct a new gait representation for robust recognition. Experiments are conducted with the CASIA and SOTON databases, and the proposed method makes silhouette-based gait recognition as reliable biometrics.
C1 [Lee, Heesung; Baek, Jeonghyun; Kim, Euntai] Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea.
C3 Yonsei University
RP Kim, E (corresponding author), Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea.
EM etkim@yonsei.ac.kr
OI lee, heesung/0000-0001-9944-3976
CR Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Bazin AI, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P60
   BenAbdelkader C, 2001, LECT NOTES COMPUT SC, V2091, P284
   Bobick AF, 2001, PROC CVPR IEEE, P423
   Boulgouris NV, 2007, IEEE T IMAGE PROCESS, V16, P731, DOI 10.1109/TIP.2007.891157
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Lam THW, 2006, LECT NOTES COMPUT SC, V3832, P612
   Lee H, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/384384
   Lee H, 2009, INT J CONTROL AUTOM, V7, P638, DOI [10.1007/S12555-009-0414-2, 10.1007/s12555-009-0414-2]
   Li XL, 2008, IEEE T SYST MAN CY C, V38, P145, DOI 10.1109/TSMCC.2007.913886
   Madevska-Bogdanova A, 2004, NEUROCOMPUTING, V62, P293, DOI 10.1016/j.neucom.2003.03.002
   MURRAY MP, 1964, J BONE JOINT SURG AM, V46, P335, DOI 10.2106/00004623-196446020-00009
   Platt JC, 2000, ADV NEUR IN, P61
   Shutler J.D., 2002, 4th International Conference on Recent Advances in Soft Computing, P66
   Tan DL, 2006, INT C PATT RECOG, P1000
   Vapnik V., 1988, Statistical Learning Theory
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024
   Zhon XL, 2007, IEEE T SYST MAN CY B, V37, P1119, DOI 10.1109/TSMCB.2006.889612
NR 20
TC 4
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1399
EP 1419
DI 10.1007/s11042-012-1163-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500002
DA 2024-07-18
ER

PT J
AU Haslhofer, B
   Sanderson, R
   Simon, R
   van de Sompel, H
AF Haslhofer, Bernhard
   Sanderson, Robert
   Simon, Rainer
   van de Sompel, Herbert
TI Open annotations on multimedia Web resources
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Annotations; Web; Linked data
ID ONTOLOGY
AB Many Web portals allow users to associate additional information with existing multimedia resources such as images, audio, and video. However, these portals are usually closed systems and user-generated annotations are almost always kept locked up and remain inaccessible to the Web of Data. We believe that an important step to take is the integration of multimedia annotations and the Linked Data principles. We present the current state of the Open Annotation Model, explain our design rationale, and describe how the model can represent user annotations on multimedia Web resources. Applying this model in Web portals and devices, which support user annotations, should allow clients to easily publish and consume, thus exchange annotations on multimedia Web resources via common Web standards.
C1 [Haslhofer, Bernhard] Cornell Univ, Dept Informat Sci, Ithaca, NY 14850 USA.
   [Sanderson, Robert; van de Sompel, Herbert] Los Alamos Natl Lab, Los Alamos, NM 87544 USA.
   [Simon, Rainer] Austrian Inst Technol, A-1220 Vienna, Austria.
C3 Cornell University; United States Department of Energy (DOE); Los Alamos
   National Laboratory; Austrian Institute of Technology (AIT)
RP Haslhofer, B (corresponding author), Cornell Univ, Dept Informat Sci, 301 Coll Ave, Ithaca, NY 14850 USA.
EM bernhard.haslhofer@cornell.edu; rsanderson@lanl.gov;
   rainer.simon@ait.ac.at; herbertv@lanl.gov
FU European Commission as part of the eContentplus program
   (EuropeanaConnect); Marie Curie International Outgoing Fellowship within
   the 7th Europeana Community Framework Program; Andrew W. Mellon
   foundation
FX The work has partly been supported by the European Commission as part of
   the eContentplus program (EuropeanaConnect) and by a Marie Curie
   International Outgoing Fellowship within the 7th Europeana Community
   Framework Program. The development of OAC is funded by the Andrew W.
   Mellon foundation.
CR Agosti M, 2007, INT J DIGIT LIBRARIE, V8, P1, DOI 10.1007/s00799-007-0010-0
   Arndt R, 2007, LECT NOTES COMPUT SC, V4825, P30
   Berners-Lee T., 2005, Uniform Resource Identifier
   Blustein J, 2011, LECT NOTES COMPUT SC, V6966, P252, DOI 10.1007/978-3-642-24469-8_27
   Bradley J, 2008, J DIGIT INF, V9
   Ciccarese Paolo, 2011, J Biomed Semantics, V2 Suppl 2, pS4, DOI 10.1186/2041-1480-2-S2-S4
   Dodds L.Davis., 2012, Linked Data Patterns: A pattern catalogue for modelling, publishing, and consuming Linked Data
   HARDMAN L, 1994, COMMUN ACM, V37, P50, DOI 10.1145/175235.175239
   Haslhofer B, 2011, WORKSH MULT WEB 2011
   Haslhofer B, 2009, INT J DIGIT LIBRARIE, V10, P15, DOI 10.1007/s00799-009-0050-8
   Hausenblas M, 2009, WWW 2009 WORKSH LINK
   Heath  T., 2011, SYNTHESIS LECT SEMAN, DOI [10.2200/S00334ED1V01Y201102WBE001, DOI 10.2200/S00334ED1V01Y201102WBE001, 10.2200/s00334ed1v01y201102wbe001]
   Hunter J, 2009, ANNU REV INFORM SCI, V43, P187
   Hunter J, 2008, IEEE MULTIMEDIA, V15, P42, DOI 10.1109/MMUL.2008.75
   ISO/IEC, 2006, MULT FRAM MPEG 21 17
   Jacobs I, 2004, POS STAT W3C VID WOR
   Kahan J., 2001, P INT WORLD WIDE WEB, P623, DOI DOI 10.1145/371920.372166
   Kim H.L., 2008, International Conference on Dublin Core and Metadata Applications, P128
   Klein M., 2011, Proceedings of the 11th Annual International ACM/IEEE Joint Conference on Digital Libraries, JCDL '11, P137, DOI [10.1145/1998076.1998101, DOI 10.1145/1998076.1998101]
   Koch J, 2009, REPRESENTING CONTENT
   Koivunen M. R., 2006, 5 INT SEM WEB C ISWC
   Marshall CC, 2004, ACM-IEEE J CONF DIG, P349, DOI 10.1145/996350.996432
   Marshall CC, 2000, CL LIB APPL, P97
   Morishima A, 2009, 20TH ACM CONFERENCE ON HYPERTEXT AND HYPERMEDIA (HYPERTEXT 2009), P15
   Nack F, 1999, IEEE MULTIMEDIA, V6, P64, DOI 10.1109/93.809235
   Pfeiffer S, 2007, POS STAT W3C VID WOR
   Phelps T.A., 2000, UCBCSD001091 EECS DE
   Popitsch N, 2011, J WEB SEMANT, V9, P266, DOI 10.1016/j.websem.2011.05.002
   Qayyum A, 2008, CAN J INFORM LIB SCI, V32, P35
   Saathoff C, 2010, P 19 INT C WORLD WID, P831, DOI [10.1145/1772690.1772775, DOI 10.1145/1772690.1772775]
   Sanderson R, 2011, P 11 ANN INT ACM IEE, P175, DOI [10.1145/1998076.1998111, DOI 10.1145/1998076.1998111, 10.1145/1998076]
   Sanderson R., 2010, P 10 ANN JOINT C DIG
   Schroeter R., 2007, ESWC, V4519
   Simon Rainer, 2011, P 11 ANN INT ACM IEE, P199
   Van de Sompel H., 2009, ARXIV09111112
   Van de Sompel H., 2010, ABS10033661 CORR
   Van Deursen D., 2010, Proceedings of the 19th international conference on World wide web (WWW '10), P1361, DOI DOI 10.1145/1772690.1772931
   Verspoor K, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S20
   W3C Media Fragments Working Group, 2011, MED FRAGM URI 1 0
NR 39
TC 8
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 847
EP 867
DI 10.1007/s11042-012-1098-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kavasidis, I
   Palazzo, S
   Di Salvo, R
   Giordano, D
   Spampinato, C
AF Kavasidis, Isaak
   Palazzo, Simone
   Di Salvo, Roberto
   Giordano, Daniela
   Spampinato, Concetto
TI An innovative web-based collaborative platform for video annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ground truth data; Video labeling; Object detection; Object tracking;
   Image segmentation
AB Large scale labeled datasets are of key importance for the development of automatic video analysis tools as they, from one hand, allow multi-class classifiers training and, from the other hand, support the algorithms' evaluation phase. This is widely recognized by the multimedia and computer vision communities, as witnessed by the growing number of available datasets; however, the research still lacks in annotation tools able to meet user needs, since a lot of human concentration is necessary to generate high quality ground truth data. Nevertheless, it is not feasible to collect large video ground truths, covering as much scenarios and object categories as possible, by exploiting only the effort of isolated research groups. In this paper we present a collaborative web-based platform for video ground truth annotation. It features an easy and intuitive user interface that allows plain video annotation and instant sharing/integration of the generated ground truths, in order to not only alleviate a large part of the effort and time needed, but also to increase the quality of the generated annotations. The tool has been on-line in the last four months and, at the current date, we have collected about 70,000 annotations. A comparative performance evaluation has also shown that our system outperforms existing state of the art methods in terms of annotation time, annotation quality and system's usability.
C1 [Kavasidis, Isaak; Palazzo, Simone; Di Salvo, Roberto; Giordano, Daniela; Spampinato, Concetto] Univ Catania, Dept Elect Elect & Comp Engn, Catania, Italy.
C3 University of Catania
RP Kavasidis, I (corresponding author), Univ Catania, Dept Elect Elect & Comp Engn, Catania, Italy.
EM kavasidis@dieei.unict.it; simone.palazzo@dieei.unict.it;
   roberto.disalvo@dieei.unict.it; dgiordan@dieei.unict.it;
   cspampin@dieei.unict.it
OI Palazzo, Simone/0000-0002-2441-0982
FU European Commission [257024]
FX We would like to thank the anonymous reviewers for their constructive
   and invaluable comments. This research was funded by European Commission
   FP7 grant 257024, in the Fish4Knowledge project.<SUP>3</SUP>
CR [Anonymous], VIGTA 12
   [Anonymous], VIGTA 12
   [Anonymous], 2012, P 1 INT WORKSHOP VIS
   [Anonymous], 1988, Proceedings of the SIGCHI conference on Human factors in computing systems-CHI, DOI DOI 10.1145/57167.57203
   [Anonymous], ADV COMP HUM INT 200
   [Anonymous], ICDAR 99
   [Anonymous], VIGTA 12
   [Anonymous], P SSPR 2003
   [Anonymous], VIGTA 12
   [Anonymous], ADV NEURAL INFORM PR
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bassel GW, 2011, PLANT CELL, V23, P3101, DOI 10.1105/tpc.111.088153
   Bertini M., 2005, 13th Annual ACM International Conference on Multimedia, P395, DOI 10.1145/1101149.1101235
   Biewald Lukas, 2012, Current Trends in Web Engineering. Workshops, Doctoral Symposium, and Tutorials Held at ICWE 2011. Revised Selected Papers, P171, DOI 10.1007/978-3-642-27997-3_18
   Brabham D. C, 2008, Convergence, V14, P75, DOI DOI 10.1177/1354856507084420
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Doermann D, 2000, INT C PATT RECOG, P167, DOI 10.1109/ICPR.2000.902888
   Faro A, 2011, IEEE T INTELL TRANSP, V12, P1398, DOI 10.1109/TITS.2011.2159266
   Fisher R., 2004, CAVIAR Test Case Scenarios
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Giordano D., 2011, 2011 9th International Workshop on Content-Based Multimedia Indexing (CBMI), P181, DOI 10.1109/CBMI.2011.5972542
   Griffin G., 2007, CALTECH 256 OBJECT C
   Mai HT, 2014, MULTIMED TOOLS APPL, V72, P331, DOI 10.1007/s11042-013-1360-9
   Heroux P, 2007, PROC INT CONF DOC, P476
   Howe J, 2006, WIRED, V14, P1, DOI DOI 10.1086/599595
   Jaynes C., 2002, PROC IEEE WORKSHOP P, P32
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Marques O, 2003, LECT NOTES COMPUT SC, V2870, P550
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mihalcea R., 2006, P 21 NAT C ART INT, V6, P775
   Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0
   Quinn AJ, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1403
   Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.5555/1866696.1866717
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rotter P, 2014, MULTIMED TOOLS APPL, V72, P667, DOI 10.1007/s11042-013-1384-1
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Sorokin A, 2008, PROC CVPR IEEE, P23
   Spampinato Concetto, 2012, Proceedings of the International Conference on Computer Vision Theory and Applications. VISAPP 2012, P409
   Spampinato C, 2014, MULTIMED TOOLS APPL, V70, P199, DOI 10.1007/s11042-012-1101-5
   von Ahn L, 2006, COMPUTER, V39, P92, DOI 10.1109/MC.2006.196
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   Wache H., 2001, P IJCAI 01 WORKSH ON, P108
   Yuen J, 2009, IEEE I CONF COMP VIS, P1451, DOI 10.1109/ICCV.2009.5459289
NR 45
TC 53
Z9 54
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 413
EP 432
DI 10.1007/s11042-013-1419-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300019
DA 2024-07-18
ER

PT J
AU Liu, XL
   Huet, B
AF Liu, Xueliang
   Huet, Benoit
TI On the automatic online collection of training data for visual event
   modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Events; Social media; Multimedia semantics
AB The last decade has witnessed the development and uprising of social media web services. The use of these shared online media as a source of huge amount of data for research purposes is still a challenging problem. In this paper, a novel framework is proposed to collect training samples from online media data to model the visual appearance of social events automatically. The visual training samples are collected through the analysis of the spatial and temporal context of media data and events. While collecting positive samples can be achieved easily thanks to dedicated event machine-tags, finding the most representative negative samples from the vast amount of irrelevant multimedia documents is a more challenging task. Here, we argue and demonstrate that the most common negative samples, originating from the same location as the event to be modeled, are best suited for the task. A novel ranking approach is devised to automatically select a set of negative samples. Finally the automatically collected samples are used to learn visual event models using Support Vector Machine (SVM). The resulting event models are effective to filter out irrelevant photos and perform with a high accuracy as demonstrated on various social events originating for various categories of events.
C1 [Liu, Xueliang; Huet, Benoit] EURECOM, Boit, France.
C3 IMT - Institut Mines-Telecom; EURECOM
RP Liu, XL (corresponding author), EURECOM, Boit, France.
EM xueliang.liu@eurecom.fr; benoit.huet@eurecom.fr
OI Huet, Benoit/0000-0002-0608-6939
FU "Adaptable Ambient Living Assistant" (ALIAS) - European Commission
   [AAL-2009-2-049]; French Research Agency (ANR) in the Ambient Assisted
   Living (AAL) programme
FX The research leading to this paper was partially supported by the
   project AAL-2009-2-049 "Adaptable Ambient Living Assistant" (ALIAS)
   co-funded by the European Commission and the French Research Agency
   (ANR) in the Ambient Assisted Living (AAL) programme.
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   [Anonymous], 2010, P 3 ACM INT C WEB SE, DOI DOI 10.1145/1718487.1718524
   Arase Y., 2010, Proceedings of the international conference on Multimedia, MM '10, (New York, NY, USA), P133
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Becker H., 2009, WebDB
   Becker H, 2012, ACM C WSDM
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Delgado D, 2010, IEEE INT C SEMANT CO, P73, DOI 10.1109/ICSC.2010.68
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   Firan C.S., 2010, Proceedings of the 19th ACM international conference on Information and knowledge management, P189
   Hong R, 2010, ACM C CIVR XIAN CHIN
   Kennedy Lyndon., 2009, WWW 09, P311, DOI [DOI 10.1145/1526709.1526752, 10.1145/1526709.1526752]
   Lei Z, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P721, DOI 10.1109/ICIP.2001.958595
   Li LJ, 2007, LECT NOTES ARTIF INT, V4456, P1
   Li X, 2011, P ACM INT C MULT RET
   Liu Dong., 2010, Proceedings of the International Conference on Multimedia, P491
   Liu TY, 2011, LEARNING TO RANK FOR INFORMATION RETRIEVAL, P1, DOI 10.1007/978-3-642-14267-3
   Liu X, 2011, ACM C ICMR
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Over P, 2011, P TRECVID
   Papadopoulos S, 2012, MEDIAEVAL12, P1
   Quack Till., 2008, P 2008 INT C CONTENT, P47
   Schroff F, 2007, IEEE I CONF COMP VIS, P2120
   Tang Jinhui., 2009, Proceedings of ACM international conference on Multimedia, P223, DOI DOI 10.1145/1631272.1631305
   Wang Y, 2012, ACM C MULT
   Zha ZJ, 2009, J VIS COMMUN IMAGE R, V20, P97, DOI 10.1016/j.jvcir.2008.11.009
NR 28
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 525
EP 542
DI 10.1007/s11042-013-1376-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300024
DA 2024-07-18
ER

PT J
AU Zahariadis, T
   Alvarez, F
   Olmstead, JPM
AF Zahariadis, Theodore
   Alvarez, Federico
   Moore Olmstead, John Paul
TI An architectural approach towards Future Media Internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Open future internet architecture; Media internet; User-centric;
   Content-awareness; Content location awareness
AB Internet is the most important information exchange means nowadays and has become the core communication environment, not only for business relations, but also for social and human interaction. Yet, the immense success of Internet has created even higher hopes and expectations for new immersive and real-time applications and services. However, there are no guarantees that the current Internet will be able to support them. To face the new requirements coming from these new applications and services, several architectural approaches have been proposed. Evolutionary and clean-slate approaches, based on content-centric architectures, have been proposed for meeting new requirements regarding media. This paper highlights the main architectural functions and presents a revolutionary protocol stack and a holistic architectural approach that targets Future Media Internet (FMI). Among the architectural functions and the holistic approach, the paper presents solutions to overcome the current content delivery limitations, moving intelligence in the network and converting it into a content oriented/centric network, that goes well beyond current CDNs; supporting the functionalities for producing, publishing, caching, finding and consuming content; and a novel Future Media Internet protocol stack and network architecture.
C1 [Zahariadis, Theodore] Synelixis TEI Chalkida, Chalkida, Greece.
   [Alvarez, Federico] Univ Politecn Madrid, Madrid, Spain.
   [Moore Olmstead, John Paul] Atos Origin, Madrid, Spain.
C3 Universidad Politecnica de Madrid
RP Zahariadis, T (corresponding author), Synelixis TEI Chalkida, Farmakidou 10, Chalkida, Greece.
EM zahariad@synelixis.com
RI Zahariadis, Theodore/ABI-6729-2020; Alvarez, Federico/AAA-7628-2019
OI Alvarez, Federico/0000-0001-7400-9591; Zahariadis,
   Theodore/0000-0002-2408-4582
FU EC [FP7-248036-COAST, FP7-249065 nextMedia]
FX This work has been partially funded by the EC via the projects
   FP7-248036-COAST and FP7-249065 nextMedia. Moreover, the authors would
   like to acknowledge the EC special interest group Future Media Internet
   Architecture-Think Tank (FMIA-TT) for various contributions.
CR Alduan M, 2010, 2 INT C US CENTR MED
   Boukerche A, 2007, 32 IEEE C LOC COMP N, P207
   Dharmapurikar S, 2004, IEEE MICRO, V24, P52, DOI 10.1109/MM.2004.1268997
   Jacobson V., 2009, P ACM CONEXT 2009 RO
   Lange S, 2010, INT THINGS 2010 C 29
   Rexford J, 2010, COMMUN ACM, V53, P36, DOI 10.1145/1810891.1810906
   Serafini M, 2010, D2 2 END TO END FUTU
   Wenger S, 2007, IEEE T CIRC SYST VID, V17, P1164, DOI 10.1109/TCSVT.2007.905523
   Zahariadis Th, 2010, 2 INT C TEL MULT CHA, P263
NR 9
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 297
EP 309
DI 10.1007/s11042-011-0826-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300013
DA 2024-07-18
ER

PT J
AU Zigkolis, C
   Papadopoulos, S
   Filippou, G
   Kompatsiaris, Y
   Vakali, A
AF Zigkolis, Christos
   Papadopoulos, Symeon
   Filippou, George
   Kompatsiaris, Yiannis
   Vakali, Athena
TI Collaborative event annotation in tagged photo collections
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event authoring; Multimedia annotation; Ground truth generation
ID RECOMMENDER SYSTEMS; STRATEGIES
AB Events constitute a significant means of multimedia content organization and sharing. Despite the recent interest in detecting events and annotating media content in an event-centric way, there is currently insufficient support for managing events in large-scale content collections and limited understanding of the event annotation process. To this end, this paper presents CrEve, a collaborative event annotation framework which uses content found in social media sites with the prime objective to facilitate the annotation of large media corpora with event information. The proposed annotation framework could significantly benefit social media research due to the proliferation of event-related user-contributed content. We demonstrate that, compared to a standard "browse-and-annotate" interface, CrEve leads to a 19% increase in the coverage of the generated ground truth in a large-scale annotation experiment. Furthermore, the paper discusses the results of a user study that quantifies the performance of CrEve and the contribution of different event dimensions in the event annotation process. The study confirms the prevalence of spatio-temporal queries as the prime option of discovering event-related content in a large collection. In addition, textual queries and social cues (content contributor) were also found to be significant as event search dimensions. Finally, it demonstrates the potential of employing automatic photo clustering methods with the goal of facilitating event annotation.
C1 [Zigkolis, Christos; Papadopoulos, Symeon; Kompatsiaris, Yiannis] CERTH, Inst Informat Technol, Thessaloniki, Greece.
   [Zigkolis, Christos; Papadopoulos, Symeon; Filippou, George; Vakali, Athena] AUTH, Dept Informat, Thessaloniki, Greece.
C3 Centre for Research & Technology Hellas; Aristotle University of
   Thessaloniki
RP Zigkolis, C (corresponding author), CERTH, Inst Informat Technol, Thessaloniki, Greece.
EM chzigkol@csd.auth.gr; papadop@iti.gr; gfilip@csd.auth.gr; ikom@iti.gr;
   avakali@csd.auth.gr
RI Kompatsiaris, Ioannis/P-8594-2015; Papadopoulos, Symeon/AET-0683-2022
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Papadopoulos,
   Symeon/0000-0002-5441-7341
FU European Union; Greek national funds through the Operational Program
   "Education and Lifelong Learning" of the National Strategic Reference
   Framework (NSRF)-Research Funding Program: Heracleitus II; GLOCAL
   project; SocialSensor project; European Commission [FP7-248984,
   FP7-287975]
FX Christos Zigkolis's work has been co-financed by the European Union
   (European Social Fund-ESF) and Greek national funds through the
   Operational Program "Education and Lifelong Learning" of the National
   Strategic Reference Framework (NSRF)-Research Funding Program:
   Heracleitus II. Investing in knowledge society through the European
   Social Fund. The work of Symeon Papadopoulos was supported by the GLOCAL
   and SocialSensor projects, partially funded by the European Commission,
   under contract numbers FP7-248984 and FP7-287975.
CR Ames M, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P971
   [Anonymous], 2008, ACM INT C MULT INF R
   [Anonymous], 2008, P 17 INT C WORLD WID
   [Anonymous], P SIGCHI C HUM FACT
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], P 30 ANN INT ACM SIG
   [Anonymous], P COLL WEB TAGG WORK
   [Anonymous], 2009, ICIVR
   [Anonymous], P 12 ANN ACM INT C M
   Appan P, 2005, P 10 INT C INT US IN, P106
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Cooper Matthew., 2005, ACM T MULTIM COMPUT, V1, P269, DOI [DOI 10.1145/1083314.1083317, 10.1145/1083314.1083317]
   Golder S.A., 2006, The Structure of Collaborative Tagging systems
   Liu X, 2011, ACM INT C MULT RETR
   Lowe D., 2004, INT J COMPUT VISION, V60, P91110
   Marlow C., 2006, P 17 C HYP HYPERTEXT, P31, DOI [https://doi.org/10.1145/1149941.1149949, DOI 10.1145/1149941.1149949]
   Mirkovic M., 2011, 2011 International Conference on Computational Aspects of Social Networks (CASoN 2011), P189, DOI 10.1109/CASON.2011.6085942
   Naaman M., 2004, P 12 ANN ACM INT C M
   Papadopoulos S., 2011, DATA MIN KNOWL DISC, V1, P1
   Papadopoulos S, 2010, TECHN DEM SESS ACM M
   Papadopoulos S, 2011, IEEE MULTIMEDIA, V18, P52, DOI 10.1109/MMUL.2010.68
   Pu P, 2008, ELECTRON COMMER RES, V8, P1, DOI 10.1007/s10660-008-9015-z
   Quack Till., 2008, P 2008 INT C CONTENT, P47
   Sayyadi H, 2009, P INT AAAI C WEBL SO
   Scherp A, 2012, MULTIMED TOOLS APPL, V58, P293, DOI 10.1007/s11042-010-0667-z
   Shaw R, 2009, 4 AS SEM WEB C ASWC
   Shneiderman B, 2006, COMMUN ACM, V49, P69, DOI 10.1145/1121949.1121985
   Suh B, 2007, INTERACT COMPUT, V19, P524, DOI 10.1016/j.intcom.2007.02.002
   Troncy R, 2010, 6 INT C SEM SYST COL
   Vander-wal T, 2007, EXPLAINING SHOWING B
   VandeSande KE, 2009, IEEE T PATTERN ANAL, V99
   Westermann U, 2007, IEEE MULTIMEDIA, V14, P19, DOI 10.1109/MMUL.2007.23
   Wu XA, 2011, IEEE MULTIMEDIA, V18, P38, DOI 10.1109/MMUL.2011.12
   Xie LX, 2008, P IEEE, V96, P623, DOI 10.1109/JPROC.2008.916362
   Zsombori Vilmos., 2011, P 22 ACM C HYPERTEXT, P325, DOI DOI 10.1145/1995966.1996009
NR 35
TC 9
Z9 9
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 89
EP 118
DI 10.1007/s11042-012-1154-5
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300005
DA 2024-07-18
ER

PT J
AU Ben Fradj, B
   Zaid, AO
AF Ben Fradj, Bilel
   Zaid, Azza Ouled
TI Scalable video coding using motion-compensated temporal filtering and
   intra-band wavelet based compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scalable video coding; Wavelet transform; Motion-compensated temporal
   filtering; Rate control
ID H.264/AVC STANDARD; HIERARCHICAL TREES; MC-EZBC; EXTENSION; CODEC
AB Scalable video compression is a crucial task that allows for high flexibility of video streams to different networks in various applications. Current video coding techniques exploit temporal correlation using motion-compensated predictive or filtering approaches. Particularly, motion-compensated temporal filtering (MCTF) is a useful framework for scalable video compression schemes. In this paper, we propose a new scalable video coding method that combines open-loop motion-compensated prediction with an embedded intra-band wavelet based compression. Our major objective is to provide a wavelet based video coding system that circumvents the drawbacks of conventional closed-loop prediction systems, without sacrificing compression performance. To improve the coding efficiency, we adaptively weight the target bitrate according to the temporal frame position in the temporal pyramid. Comparisons with state-of-the-art scalable video coding solutions confirm an overall coding efficiency gain of the proposed method specially at high bitrates.
C1 [Ben Fradj, Bilel; Zaid, Azza Ouled] Natl Engn Sch Tunis, SysCom Lab, Tunis 1002, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT)
RP Zaid, AO (corresponding author), Natl Engn Sch Tunis, SysCom Lab, BP 37, Tunis 1002, Tunisia.
EM bilel.benfredj@gmail.com; azza.ouledzaid@isi.rnu.tn
OI Ouled Zaid, Azza/0000-0002-3264-5933
CR Andreopoulos Y, 2004, SIGNAL PROCESS-IMAGE, V19, P653, DOI 10.1016/j.image.2004.05.007
   Andreopoulos Y, 2004, M11045 ISOIEC JTC1SC
   Chen PS, 2004, IEEE T CIRC SYST VID, V14, P1183, DOI 10.1109/TCSVT.2004.833165
   CHEN Y, 1996, P SPIE VIS COMM IM P, P1302
   Cohen RA, 2007, THESIS FACULTY RENSS
   Hsiang ST, 2001, SIGNAL PROCESS-IMAGE, V16, P705, DOI 10.1016/S0923-5965(01)00002-9
   Hsiang ST, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL III, P662, DOI 10.1109/ISCAS.2000.856147
   Juan L, 2011, IEEE T IMAGE PROCESS, V10, P1647
   Kim BJ, 2000, IEEE T CIRC SYST VID, V10, P1374, DOI 10.1109/76.889025
   Leonardi R, 2003, JTC1SC29WG11 ISOIEC
   Munteanu A, 1999, IEEE Trans Inf Technol Biomed, V3, P176, DOI 10.1109/4233.788579
   Naman AT, 2011, IEEE T IMAGE PROCESS, V20, P2650, DOI 10.1109/TIP.2011.2126588
   OHM JR, 1994, IEEE T IMAGE PROCESS, V3, P559, DOI 10.1109/83.334985
   Reichel J, 2004, N6716 ISOIEC JTC1SC2
   Reichel J., 2007, JOINT SCALABLE VIDEO
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Schelkens P, 2003, IEEE T MED IMAGING, V22, P441, DOI 10.1109/TMI.2003.809582
   Schelkens P, 2000, P PRORISC IEEE WORKS, P495
   Schwarz H, 2004, M11244 ISOIEC JTC1SC
   Schwarz H, 2008, IEEE SIGNAL PROC MAG, V25, P135, DOI 10.1109/MSP.2007.914712
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   TAUBMAN D, 1994, IEEE T IMAGE PROCESS, V3, P572, DOI 10.1109/83.334984
   Tham JY, 1998, IEEE J SEL AREA COMM, V16, P12, DOI 10.1109/49.650917
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   Wood JW, 2002, JTC1SC29WG11 ISOIEC
   Wu YJ, 2008, IEEE T CIRC SYST VID, V18, P1432, DOI 10.1109/TCSVT.2008.927003
   Xiong R, 2004, INT S PICT COD, P583
   Zhang DD, 2008, IEEE T CIRC SYST VID, V18, P516, DOI 10.1109/TCSVT.2008.918536
NR 31
TC 6
Z9 6
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 1089
EP 1109
DI 10.1007/s11042-012-1170-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300023
DA 2024-07-18
ER

PT J
AU Ntalianis, K
   Tsapatsoulis, N
   Doulamis, A
   Matsatsinis, N
AF Ntalianis, Klimis
   Tsapatsoulis, Nicolas
   Doulamis, Anastasios
   Matsatsinis, Nikolaos
TI Automatic annotation of image databases based on implicit crowdsourcing,
   visual concept modeling and evolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Implicit crowdsourcing; User feedback; Visual concept modeling;
   Clickthrough data; Automatic image annotation
ID RELEVANCE FEEDBACK; RETRIEVAL; PATTERNS
AB In this paper a novel approach for automatically annotating image databases is proposed. Despite most current schemes that are just based on spatial content analysis, the proposed method properly combines several innovative modules for semantically annotating images. In particular it includes: (a) a GWAP-oriented interface for optimized collection of implicit crowdsourcing data, (b) a new unsupervised visual concept modeling algorithm for content description and (c) a hierarchical visual content display method for easy data navigation, based on graph partitioning. The proposed scheme can be easily adopted by any multimedia search engine, providing an intelligent way to even annotate completely non-annotated content or correct wrongly annotated images. The proposed approach currently provides very interesting results in limited-size both standard and generic datasets and it is expected to add significant value especially to billions of non-annotated images existing in the Web. Furthermore expert annotators can gain important knowledge relevant to user new trends, language idioms and styles of searching.
C1 [Ntalianis, Klimis] Technol Educ Inst Athens, Dept Mkt, Athens 12210, Greece.
   [Tsapatsoulis, Nicolas] Cyprus Univ Technol, Dept Commun & Internet Studies, CY-3603 Limassol, Cyprus.
   [Doulamis, Anastasios; Matsatsinis, Nikolaos] Tech Univ Crete, Dept Prod Engn & Management, Khania 73100, Greece.
C3 University of West Attica; Cyprus University of Technology; Technical
   University of Crete
RP Ntalianis, K (corresponding author), Technol Educ Inst Athens, Dept Mkt, Agiou Spyridonos Str, Athens 12210, Greece.
EM kntal@image.ntua.gr; nicolas.tsapatsoulis@cut.ac.cy;
   adoulam@dpem.tuc.gr; nikos@ergasya.tuc.gr
RI TSAPATSOULIS, NICOLAS/E-4146-2016; Doulamis, Anastasios/AAL-5972-2021;
   Matsatsinis, Nikolaos F/Q-8291-2016
OI TSAPATSOULIS, NICOLAS/0000-0002-6739-8602; 
FU Republic of Cyprus; European Regional Development Fund;  [ANTHRO/0308
   (BIE)/04]
FX This work falls under the Cyprus Research Promotion Foundation's
   Framework Programme for Research, Technological Development and
   Innovation 2008 (DESMI 2008), co-funded by the Republic of Cyprus and
   the European Regional Development Fund, and specifically under Grant
   ANTHRO/0308 (BIE)/04.
CR [Anonymous], P IEEE C COMP VIS PA
   Assfalg J, 2002, IEEE MULTIMEDIA, V9, P52, DOI 10.1109/93.998060
   Bach F.R., 2004, Advances in Neural Information Processing Systems (NIPS), V16
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Dawid A. P., 1979, J ROY STAT SOC C, P28
   Delias P, 2011, IEEE T KNOWL DATA EN, V23, P417, DOI 10.1109/TKDE.2010.113
   Doulamis AD, 2000, IEEE T CONSUM ELECTR, V46, P758, DOI 10.1109/30.883444
   Doulamis N, 2006, SIGNAL PROCESS-IMAGE, V21, P334, DOI 10.1016/j.image.2005.11.006
   Doulamis N, 2009, STUD COMPUT INTELL, V240, P189
   Duda RO., 2004, Pattern Classification, V2nd
   Gao S, 2006, P 2006 IEEE ICASSP T, V2, pII
   He XF, 2003, IEEE T CIRC SYST VID, V13, P39, DOI 10.1109/TCSVT.2002.808087
   Heisterkamp DR, 2002, INT C PATT RECOG, P134, DOI 10.1109/ICPR.2002.1047417
   Howe J., 2008, Crowdsourcing: Why the Power of the Crowd Is Driving the Future of Business
   Hsueh P-Y, 2009, P NAACL HLT 2009 WOR
   Jain S., 2009, P ACM SIGKDD WORKSH, P58, DOI [10.1145/1600150.1600171, DOI 10.1145/1600150.1600171]
   Joachims T., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P154, DOI 10.1145/1076034.1076063
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Kaisser M, 2008, P ACL
   Karamolegkos PN, 2009, J COMPUTERS MATH APP, V58
   Karypis G, 1995, ACM C SUP
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Lin CX, 2005, LECT NOTES COMPUT SC, V3399, P707
   Liu D, 2011, IEEE T MULTIMEDIA, V13, P702, DOI 10.1109/TMM.2011.2134078
   Macdonald Craig., 2009, WSCD'09: Proceedings of the 2009 workshop on Web Search Click Data, P75, DOI DOI 10.1145/1507509.1507521
   Man-Ching Yuen, 2009, 2009 International Conference on Computational Science and Engineering (CSE), P723, DOI 10.1109/CSE.2009.395
   Müller H, 2004, INT J COMPUT VISION, V56, P65, DOI 10.1023/B:VISI.0000004832.02269.45
   Natsev A, 2008, P TRECVID 2008
   Nesvadba J, 2007, 8 IEEE WIAMIS SANT G
   Ning HZ, 2010, PATTERN RECOGN, V43, P113, DOI 10.1016/j.patcog.2009.06.001
   Ntalianis KS, 2010, MULTIMED TOOLS APPL, V50, P199, DOI 10.1007/s11042-009-0369-6
   Ntalianis KS, 2008, P 1 ACM INT WORKSH A
   Petridis K, 2004, P 2004 EUR WORKSH IN, P33
   Quinn AJ, 2009, TECHNICAL REPORT
   Rapantzikos K, 2007, IET IMAGE PROCESS, V1, P237, DOI 10.1049/iet-ipr:20060040
   Raykar VC, 2009, P 26 ANN INT C MACH, P889, DOI [10.1145/1553374.1553488, DOI 10.1145/1553374.1553488]
   Sheng VS, 2008, KDD
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Siorpaes K, 2008, IEEE INTELL SYST, V23, P50, DOI 10.1109/MIS.2008.45
   Smyth P, 1995, ADV NEURAL INFORM PR
   Snow R, 2008, P 2008 C EMP METH NA, P254, DOI DOI 10.3115/1613715.1613751
   Sorokin A, 2008, IEEE WORKSH INT VIS
   Spain M., 2008, ECCV
   Suh B., 2009, Proceedings of the 5th International Symposium on Wikis and Open Collaboration - WikiSym '09, P10, DOI [DOI 10.1145/1641309.1641322, 10.1145/1641309.1641322]
   Sunstein CR, 2006, INFOTOPIA MANY MINDS
   Tsapatsoulis N, 2007, SECOND INTERNATIONAL WORKSHOP ON SEMANTIC MEDIA ADAPTATION AND PERSONALIZATION, PROCEEDINGS, P92, DOI 10.1109/SMAP.2007.49
   Tseng VS, 2008, IEEE T MULTIMEDIA, V10, P260, DOI 10.1109/TMM.2007.911832
   Tsikrika T, 2009, P 8 INT C IM VID RET
   Ulges A, 2008, P TRECVID 2008
   Vijayanarasimhan S, 2009, PROC CVPR IEEE, P2262, DOI 10.1109/CVPRW.2009.5206705
   von Ahn L, 2008, SCIENCE, V321, P1465, DOI 10.1126/science.1160379
   von Ahn L, 2008, COMMUN ACM, V51, P58, DOI 10.1145/1378704.1378719
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   Wang A, 2010, TECHNICAL REPORT
   Wang XJ, 2006, MULTIMEDIA SYST, V11, P340, DOI 10.1007/s00530-006-0013-5
   Whitehill J, 2009, ADV NEURAL INFORM PR
NR 56
TC 13
Z9 13
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 2
BP 397
EP 421
DI 10.1007/s11042-012-0995-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4FN
UT WOS:000333203400009
DA 2024-07-18
ER

PT J
AU Lo Presti, L
   La Cascia, M
AF Lo Presti, Liliana
   La Cascia, Marco
TI Concurrent photo sequence organization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital library; Personal photo album; Concurrent photos;
   Co-organization; Content analysis; Hidden Markov Model
AB Personal photo album organization is a highly demanding domain where advanced tools are required to manage large photo collections. In contrast to many previous works, that try to solve the problem of organizing a single user photo sequence, we present a new technique to account for the concurrent photo sequence organization problem, that is the problem of organizing multiple photo sequences taken during the same event. Given a set of sequences acquired at the same place during the same temporal window by several users using different cameras, our framework is intended to capture the evolution of the event and groups photos based on temporal proximity and visual content. The method automatically organizes the reference sequence in a tree capturing the event structure. Such a structure is then used to align the remaining photo sequences to the reference one. We tested our approach on the publicly available Gallagher dataset and on a new dataset we collected; this new dataset is composed of four photo sequences taken by four users at a public event. Results demonstrate the effectiveness of our method.
C1 [Lo Presti, Liliana] Boston Univ, Dept Comp Sci, Boston, MA 02215 USA.
   [La Cascia, Marco] Univ Palermo, DICGIM, Palermo, Italy.
C3 Boston University; University of Palermo
RP Lo Presti, L (corresponding author), Boston Univ, Dept Comp Sci, 111 Cummington St, Boston, MA 02215 USA.
EM loprest@bu.edu; marco.lacascia@unipa.it
RI La Cascia, Marco/E-9612-2012
OI La Cascia, Marco/0000-0002-8766-6395; Lo Presti,
   Liliana/0000-0003-0833-4403
CR [Anonymous], 2003, ACM Multimedia Conference
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], 2006, PATTERN RECOGN
   Ardizzone E, 2008, IEEE IMAGE PROC, P85, DOI 10.1109/ICIP.2008.4711697
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Choi J.Y., 2008, MIR 08, P44
   Chu WT, 2009, INT CONF ACOUST SPEE, P1141, DOI 10.1109/ICASSP.2009.4959790
   Cooper Matthew., 2005, ACM T MULTIM COMPUT, V1, P269, DOI [DOI 10.1145/1083314.1083317, 10.1145/1083314.1083317]
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gong B, 2008, PROC SPIE, V6820, DOI 10.1117/12.766917
   Hao Jiang, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2474, DOI 10.1109/CVPRW.2009.5206776
   Jaimes A, 2002, P INT C IM PROC ICIP, V3, P528
   Jang C, 2010, MULTIMED TOOLS APPL, V50, P441, DOI 10.1007/s11042-010-0485-3
   Leow WK, 2004, COMPUT VIS IMAGE UND, V94, P67, DOI 10.1016/j.cviu.2003.10.010
   Li CH, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1033, DOI 10.1109/ICME.2006.262710
   Li SZ, 2005, MARKOV RANDOM FIELD
   Lin DH, 2010, LECT NOTES COMPUT SC, V6311, P243
   Lo Presti L, 2012, MULTIMED TOOLS APPL, V61, P321, DOI 10.1007/s11042-011-0839-5
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Presti L. L., 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P318, DOI 10.1109/ISM.2010.55
   Sandhaus P, 2011, MULTIMED TOOLS APPL, V51, P5, DOI 10.1007/s11042-010-0673-1
   Tavanapong W, 2004, IEEE T MULTIMEDIA, V6, P517, DOI 10.1109/tmm.2004.830810
   Wu KL, 2007, PATTERN RECOGN, V40, P3035, DOI 10.1016/j.patcog.2007.02.006
   Zhang L., 2004, MULTIMEDIA 04, P716
NR 26
TC 2
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 777
EP 803
DI 10.1007/s11042-012-1079-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000013
DA 2024-07-18
ER

PT J
AU Leszczuk, M
AF Leszczuk, Mikolaj
TI Optimising task-based video quality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video; Quality; Experiments; Models; Optimisation
AB Development of techniques for assessing video quality is reviewed. Examples have been provided on the quality of video applications ranging from popular entertainment to new trends such as applications in wide-reaching public systems, not just those used by security forces but also for medical purposes. In particular, two typical usages of task-based video: surveillance video for accurate licence plate recognition, and medical video for credible diagnosis prior to bronchoscopic surgery were introduced by the author. The problem of task-based video quality assessment starting from subjective psychophysiological experiments to objective quality models is discussed. Example test results and models are provided alongside to the descriptions. Finally, a quality optimisation approach, driven by recognition rates is presented.
C1 AGH Univ Sci & Technol, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Leszczuk, M (corresponding author), AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM leszczuk@agh.edu.pl
RI Leszczuk, Mikołaj I/C-4857-2011
OI Leszczuk, Mikołaj I/0000-0001-9123-1039
FU European Commission [FP7-218086]
FX This work was supported by the European Commission under the Grant
   INDECT No. FP7-218086. The author extends his thanks to his AGH
   colleague, Lucjan Janowski, for his ideas and general guidance on
   statistics.
CR [Anonymous], 2008, P912 ITUT
   [Anonymous], 1996, P800 ITUT
   [Anonymous], 1999, P910 ITUT
   Bartkowiak M, 2001, APPL CHROMINANCE VEC
   Duplaga M, 2008, LECT NOTES COMPUT SC, V5188, P227, DOI 10.1007/978-3-540-85891-1_25
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Hosmer D, 2000, WILEY SERIES PROBABI
   Janowski L, 2010, LECT NOTES COMPUT SC, V6157, P34, DOI 10.1007/978-3-642-13789-1_4
   Leszczuk M, 2011, 4 MULT COMM SERV SEC
   Leszczuk M, 2006, THESIS AGH U SCI TEC
   Leszczuk M, 2012, MULTIMEDIA COMMUNICA
   Leszczuk M, 2011, COMM COM INF SC, V149, P91
   Leszczuk M, 2010, ADV INTEL SOFT COMPU, V69, P587
   Pezzullo JC, 2005, LOGISTIC REGRESSION
   Przelaskowski A, 2002, THESIS
   Skarbek W, 1998, MULTIMEDIA ALGORYTMY
   Takahashi A, 2010, REPORT VALIDATION VI
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wikipedia, 2011, LOG FUNCT
NR 19
TC 4
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 1
BP 41
EP 58
DI 10.1007/s11042-012-1161-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 283JZ
UT WOS:000329243600004
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, NN
   Men, CG
AF Wang, Nana
   Men, Chaoguang
TI Reversible fragile watermarking for locating tampered blocks in 2D
   vector maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile watermarking; Reversible data hiding; Authentication; Tamper
   localization; 2D vector map
AB For 2D vector maps, obtaining good tamper localization performance and original content recovery with existing reversible fragile watermarking schemes is a technically challenging problem. Using an improved reversible watermarking method and a fragile watermarking algorithm based on vertex insertion, we propose a reversible fragile watermarking scheme that detects and locates tampered blocks with high accuracy while ensuring recovery of the original content. In particular, we propose dividing the features of the vector map into different blocks, calculating the block authentication watermarks and embedding the watermarks with different watermarking schemes. While the block division ensures superior accuracy of tamper localization, the reversible watermarking method and the fragile watermarking algorithm based on vertex insertion provide recovery of the original content. Experimental results show that the proposed scheme could detect and locate malicious attacks such as vertex/feature modification, vertex/feature addition, and vertex/feature deletion.
RP Wang, NN (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.
EM wangnana_5@yahoo.com; menchaoguang@hrbeu.edu.cn
RI lu, yuan/JZD-0832-2024; wang, yan/GSE-6489-2022; wang, na/HSF-2140-2023
CR Amat P, 2010, SIGNAL PROCESS-IMAGE, V25, P400, DOI 10.1016/j.image.2010.05.002
   [Anonymous], TAYLOR ROOKERY 1 500
   [Anonymous], 2005, P DOCT FOR CHIN
   [Anonymous], INT C COMP ENG TECHN
   [Anonymous], 2009, P INT C E BUS INF SY
   [Anonymous], SR41 42 NO P CHARLES
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Cayre F, 2003, IEEE T SIGNAL PROCES, V51, P939, DOI 10.1109/TSP.2003.809380
   Chang CC, 2010, INFORM SCIENCES, V180, P3045, DOI 10.1016/j.ins.2010.03.027
   Doncel VR, 2007, IEEE T VIS COMPUT GR, V13, P851, DOI 10.1109/TVCG.2007.1050
   Dziembowski S, 2008, ANN IEEE SYMP FOUND, P293, DOI 10.1109/FOCS.2008.56
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Giannoula A, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA549
   Gou HM, 2005, IEEE T SIGNAL PROCES, V53, P3988, DOI 10.1109/TSP.2005.855411
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Honsinger CW, 2001, United States Patent, Patent No. [6278791B1 US, 6278791B1]
   Horness Elias, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P2291
   *IEEE, 1985, 7541985 ANSIIEEE
   Lee SH, 2013, MULTIMED TOOLS APPL, V63, P757, DOI 10.1007/s11042-011-0894-y
   Lopez C, 2002, INT J GEOGR INF SCI, V16, P589, DOI 10.1080/13658810210129148
   Niu XM, 2006, INT J INNOV COMPUT I, V2, P1301
   Ohbuchi R, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P577, DOI 10.1109/ICME.2002.1035847
   Ohbuchi R, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P216
   PaperdJuly W., 1998, ESRI shapefile technical description, V16, P370
   Peng F, 2011, COMPUT AIDED DESIGN, V43, P1018, DOI 10.1016/j.cad.2011.03.011
   Solachidis V, 2004, IEEE COMPUT GRAPH, V24, P44, DOI 10.1109/MCG.2004.1297010
   Sonnet H, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P73, DOI 10.1109/PCCGA.2003.1238249
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Voigt M, 2004, P 2004 MULT SEC WORK, P160, DOI DOI 10.1145/1022431.1022459
   Wang CJ, 2012, MULTIMED TOOLS APPL, V57, P67, DOI 10.1007/s11042-010-0536-9
   Wang PC, 2007, J INF SCI ENG, V23, P1889
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   Wu HT, 2010, IEEE T INSTRUM MEAS, V59, P221, DOI 10.1109/TIM.2009.2022453
   Wu HT, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P801
   Yan HW, 2011, COMPUT ENVIRON URBAN, V35, P485, DOI 10.1016/j.compenvurbsys.2010.10.004
NR 35
TC 27
Z9 32
U1 1
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2013
VL 67
IS 3
BP 709
EP 739
DI 10.1007/s11042-012-1333-4
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 209JD
UT WOS:000323750900010
DA 2024-07-18
ER

PT J
AU Choi, JH
   Lee, HY
   Lee, HK
AF Choi, Jung-Ho
   Lee, Hae-Yeoun
   Lee, Heung-Kyu
TI Color laser printer forensic based on noisy feature and support vector
   machine classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital forensics; Color laser printer; Gray level co-occurrence matrix;
   Support vector machine classifier
ID SECURITY
AB Digital forensics in the ubiquitous era can enhance and protect the reliability of multimedia content where this content is accessed, manipulated, and distributed using high quality computer devices. Color laser printer forensics is a kind of digital forensics which identifies the printing source of color printed materials such as fine arts, money, and document and helps to catch a criminal. This paper present a new color laser printer forensic algorithm based on noisy texture analysis and support vector machine classifier that can detect which color laser printer was used to print the unknown images. Since each printer vender uses their own printing process, printed documents from different venders have a little invisible difference looks like noise. In our identification scheme, the invisible noises are estimated with the wiener-filter and the 2D Discrete Wavelet Transform (DWT) filter. Then, a gray level co-occurrence matrix (GLCM) is calculated to analyze the texture of the noise. From the GLCM, 384 statistical features are extracted and applied to train and test the support vector machine classifier for identifying the color laser printers. In the experiment, a total of 4,800 images from 8 color laser printer models were used, where half of the image is for training and the other half is for classification. Results prove that the presented algorithm performs well by achieving 99.3%, 97.4% and 88.7% accuracy for the brand, toner and model identification respectively.
C1 [Choi, Jung-Ho; Lee, Heung-Kyu] Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea.
   [Lee, Hae-Yeoun] Kumoh Natl Inst Technol, Sch Comp & Software Engn, Gumi, Gyeongbuk, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Kumoh National
   University Technology
RP Lee, HK (corresponding author), Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea.
EM jhchoi@mmc.kaist.ac.kr; haeyeoun.lee@kumoh.ac.kr; hklee@mmc.kaist.ac.kr
RI Lee, Heung Kyu/C-1941-2011
FU Ministry of Culture, Sports and Tourism (MCST); Korea Creative Content
   Agency (KOCCA) in Culture Technology (CT) Research & Development Program
FX This research is supported by Ministry of Culture, Sports and Tourism
   (MCST) and Korea Creative Content Agency (KOCCA) in Culture Technology
   (CT) Research & Development Program 2009.
CR [Anonymous], 1992, COMPUTER ROBOT VISIO, DOI DOI 10.1504/IJICT.2016.079962
   [Anonymous], 2005, PROBABILITY STAT ENG
   Chang C., 2010, LIBSVM: A library for support vector machines 2010
   Chang L., 2010, 2010 6th International Conference on Networked Computing (INC), P1, DOI DOI 10.1109/ICC.2010.5502298
   Chiang PJ, 2009, IEEE SIGNAL PROC MAG, V26, P72, DOI 10.1109/MSP.2008.931082
   Choi JH, 2009, IEEE IMAGE PROC, P1505, DOI 10.1109/ICIP.2009.5414614
   Electronic Frontier Foundation, DOCUCOLOR TRACK DOT
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hsu C. W., 2004, TECHNICAL REPORT
   Jafri R, 2009, J INF PROCESS SYST, V5, P41, DOI 10.3745/JIPS.2009.5.2.041
   Lim J.S., 1990, 2 DIMENSIONAL SIGNAI, P548
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mikkilineni AK, 2004, PROC SPIE, V5306, P455, DOI 10.1117/12.531944
   Ohta N., 2006, COLOR DESKTOP PRINTE
   Orfanidis S., 1996, OPTIMUM SIGNAL PROCE, V2nd
   Ryu SJ, 2008, LECT NOTES COMPUT SC, V5353, P486
   Tay FEH, 2001, OMEGA-INT J MANAGE S, V29, P309, DOI 10.1016/S0305-0483(01)00026-3
   Wei Deng, 2008, 2008 First International Conference on Intelligent Networks and Intelligent Systems (ICINIS), P565, DOI 10.1109/ICINIS.2008.158
NR 18
TC 21
Z9 23
U1 0
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 2
BP 363
EP 382
DI 10.1007/s11042-011-0835-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 205HY
UT WOS:000323435800003
DA 2024-07-18
ER

PT J
AU Du, YT
   Chen, F
   Xu, WL
   Qian, XM
AF Du, Youtian
   Chen, Feng
   Xu, Wenli
   Qian, Xueming
TI Video content categorization using the double decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video content categorization; Double decomposition; Dynamic Bayesian
   network; Multiple scales; Stochastic process
ID ACTIVITY RECOGNITION; GAIT RECOGNITION; HIDDEN; CLASSIFICATION
AB Video contents contain complex structures due to the variety of the components and events involved. For example, surveillance videos often record multi-object interactions and consist of various scales of motion detail; Web videos are composed of multimodal cues, and each cue generally consists of a variety of scales of information. Generally, video contents comprise two types of the combination of the inherent structures: multi-modality/multi-scale and multi-object /multi-scale. Therefore, in this paper, we propose a new framework for video content modeling, under which video contents are decomposed into multiple interacting processes by double decomposition that aims at each type of combination of structures. To model the resulting processes, we propose a method named double-decomposed hidden Markov models (DDHMMs). DDHMMs contain multiple state chains that correspond to the interacting processes. To make the switching frequency of states in each chain consistent with the scale of the corresponding process, a durational state variable is introduced in DDHMMs. The proposed method performs well in modeling the relations among the interacting processes and the dynamics of each. We discuss the appropriate features under the proposed framework and evaluate DDHMMs in two applications, human motion recognition and web video categorization. The experimental results demonstrate that the double decomposition enhances video categorization performance in both cases.
C1 [Du, Youtian] Xi An Jiao Tong Univ, Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian 710049, Peoples R China.
   [Chen, Feng; Xu, Wenli] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
   [Qian, Xueming] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University; Tsinghua University; Xi'an Jiaotong
   University
RP Qian, XM (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM duyt@mail.xjtu.edu.cn; qianxm@mail.xjtu.edu.cn
RI Qian, Xueming/E-9867-2015; Chen, Feng/K-4179-2012
OI Du, Youtian/0000-0002-1714-3433
FU National Natural Science Foundation [60905018, 60903121, 61173109,
   61175039]; Key Projects in the National Science & Technology Pillar
   Program [2011BAK08B02]; Research Fund for Doctoral Program of Higher
   Education [20090201120032]; Fundamental Research Funds for the Central
   Universities, of China [xjj2009041, xjj20100051]
FX The research presented in this paper is supported in part by the
   National Natural Science Foundation (60905018, 60903121, 61173109,
   61175039), Key Projects in the National Science & Technology Pillar
   Program (2011BAK08B02), Research Fund for Doctoral Program of Higher
   Education (20090201120032), Fundamental Research Funds for the Central
   Universities (xjj2009041, xjj20100051), of China. The authors would like
   to thank the video team at United Technologies Research Center (UTRC)
   for their pertinent and constructive discussion, and thank Dr. K.P.
   Murphy for his Matlab Bnet toolbox. Also, the authors would like to
   thank all the anonymous reviewers for their constructive advices.
CR Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450
   Brezeale D, 2008, IEEE T SYST MAN CY C, V38, P416, DOI 10.1109/TSMCC.2008.919173
   Chen CH, 2011, PATTERN RECOGN, V44, P988, DOI 10.1016/j.patcog.2010.10.021
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Duong TV, 2005, PROC CVPR IEEE, P838
   Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079
   FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030
   Ghahramani Z, 1997, MACH LEARN, V29, P245, DOI 10.1023/A:1007425814087
   Gu JX, 2010, IEEE T SYST MAN CY B, V40, P1021, DOI 10.1109/TSMCB.2010.2043526
   Huang CL, 2006, IEEE T MULTIMEDIA, V8, P749, DOI 10.1109/TMM.2006.876289
   Junejo IN, 2010, SIGNAL IMAGE VIDEO P, V4, P1, DOI 10.1007/s11760-008-0099-7
   Liu XH, 2006, IMAGE VISION COMPUT, V24, P166, DOI 10.1016/j.imavis.2005.09.024
   Liu YA, 2009, MULTIMED TOOLS APPL, V41, P93, DOI 10.1007/s11042-008-0220-5
   Manohar Vasant, 2011, P ACM C MULT, P1537
   Mitchell C, 1999, IEEE T SPEECH AUDIO, V3, P213
   Murphy Kevin Patrick, 2002, Dynamic bayesian networks: representation, inference and learning
   Natarajan P., 2007, MOTION VIDEO COMPUTI, P10, DOI DOI 10.1109/WMVC.2007.12
   Nefian AV, 2002, INT CONF ACOUST SPEE, P2013
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Oliver N, 2004, COMPUT VIS IMAGE UND, V96, P163, DOI 10.1016/j.cviu.2004.02.004
   Roach MJ, 2001, INT CONF ACOUST SPEE, P1557, DOI 10.1109/ICASSP.2001.941230
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Tan BT, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P2431, DOI 10.1109/ICSLP.1996.607300
   Wang L., 2009, APPL COMPUTER VISION, P1
   Wang M., 2007, ACM Multi- media, P862
   Wu Y., 2004, ACM INT C MULTIMEDIA, P572, DOI DOI 10.1145/1027527.1027665
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
NR 28
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2013
VL 66
IS 3
BP 545
EP 572
DI 10.1007/s11042-012-1213-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 179TX
UT WOS:000321545300009
DA 2024-07-18
ER

PT J
AU Memar, S
   Affendey, LS
   Mustapha, N
   Doraisamy, SC
   Ektefa, M
AF Memar, Sara
   Affendey, Lilly Suriani
   Mustapha, Norwati
   Doraisamy, Shyamala C.
   Ektefa, Mohammadreza
TI An integrated semantic-based approach in concept based video retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video retrieval; Semantic knowledge; Content-based analysis; Similarity;
   Search
ID IMAGE; WEB
AB Multimedia content has been growing quickly and video retrieval is regarded as one of the most famous issues in multimedia research. In order to retrieve a desirable video, users express their needs in terms of queries. Queries can be on object, motion, texture, color, audio, etc. Low-level representations of video are different from the higher level concepts which a user associates with video. Therefore, query based on semantics is more realistic and tangible for end user. Comprehending the semantics of query has opened a new insight in video retrieval and bridging the semantic gap. However, the problem is that the video needs to be manually annotated in order to support queries expressed in terms of semantic concepts. Annotating semantic concepts which appear in video shots is a challenging and time-consuming task. Moreover, it is not possible to provide annotation for every concept in the real world. In this study, an integrated semantic-based approach for similarity computation is proposed with respect to enhance the retrieval effectiveness in concept-based video retrieval. The proposed method is based on the integration of knowledge-based and corpus-based semantic word similarity measures in order to retrieve video shots for concepts whose annotations are not available for the system. The TRECVID 2005 dataset is used for evaluation purpose, and the results of applying proposed method are then compared against the individual knowledge-based and corpus-based semantic word similarity measures which were utilized in previous studies in the same domain. The superiority of integrated similarity method is shown and evaluated in terms of Mean Average Precision (MAP).
C1 [Memar, Sara; Affendey, Lilly Suriani; Mustapha, Norwati; Doraisamy, Shyamala C.; Ektefa, Mohammadreza] Univ Putra Malaysia, Dept Comp Sci, Serdang 43400, Selangor, Malaysia.
C3 Universiti Putra Malaysia
RP Memar, S (corresponding author), Univ Putra Malaysia, Dept Comp Sci, Serdang 43400, Selangor, Malaysia.
EM sr.memar@gmail.com
RI ektefa, moe/KFS-2528-2024
OI Doraisamy, Shyamala/0000-0001-5502-8754
CR [Anonymous], P ACM INT C IM VID R
   [Anonymous], 2005, GUIDELINES TRECVID 2
   [Anonymous], 2003, P 2003 C N AM CHAPT
   [Anonymous], 2007, CIVR '07
   [Anonymous], P INT C IM VID RETR
   [Anonymous], 2007, COLUMBIA U BASELINE
   Aytar Y., 2008, IEEE C COMP VIS PATT
   Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785
   BLAIR DC, 1979, J AM SOC INFORM SCI, V30, P374, DOI 10.1002/asi.4630300621
   Campbell M, 2006, TRECVID WORKSH
   Chang S. F., 2006, NIST TRECVID WORKSH
   Coelho TAS, 2004, IEEE T KNOWL DATA EN, V16, P408, DOI 10.1109/TKDE.2004.1269666
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Frankel C., 1996, Webseer: An image search engine for the world wide web
   Frawley, 2013, LINGUISTIC SEMANTICS
   Hatzivassiloglou V., 1999, Detecting text similarity over short passages: Exploring linguistics feature combinations via machine learning
   Hauptmann A, 2007, IEEE T MULTIMEDIA, V9, P958, DOI 10.1109/TMM.2007.900150
   Hauptmann AG, 2008, P IEEE, V96, P602, DOI 10.1109/JPROC.2008.916355
   Hopfgartner F, 2008, PROC VLDB ENDOW, V1, P1604, DOI 10.14778/1454159.1454233
   Islam A., 2008, ACM Trans. Knowl. Discov. Data, V2, P1, DOI [10.1145/1376815.1376819, DOI 10.1145/1376815.1376819]
   Jiang Y.-G., 2009, Proc. ACM MM, P155, DOI DOI 10.1145/1631272.1631296
   Jones K.Sparck., 1997, READINGS INFORM RETR
   Ko Y, 2004, INFORM PROCESS MANAG, V40, P65, DOI 10.1016/S0306-4573(02)00056-0
   Liu T, 2005, LECT NOTES COMPUT SC, V3644, P456
   Markkula M., 2000, Information Retrieval, V1, P259, DOI 10.1023/A:1009995816485
   Mihalcea R., 2006, P 21 NAT C ART INT, V6, P775
   OGAWA Y, 1991, FUZZY SET SYST, V39, P163, DOI 10.1016/0165-0114(91)90210-H
   Park EK, 2005, INFORM PROCESS MANAG, V41, P1207, DOI 10.1016/j.ipm.2004.08.002
   Pedersen T, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P1024
   ROBERTSON SE, 1976, J AM SOC INFORM SCI, V27, P129, DOI 10.1002/asi.4630270302
   Rodden K., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P190, DOI 10.1145/365024.365097
   SALTON G, 1983, COMMUN ACM, V26, P1022, DOI 10.1145/182.358466
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   SALTON G, 1968, J ACM, V15, P8, DOI 10.1145/321439.321441
   Smeaton AF, 2007, INFORM SYST, V32, P545, DOI 10.1016/j.is.2006.09.001
   Smith JR, 1997, IEEE MULTIMEDIA, V4, P12, DOI 10.1109/93.621578
   SNOEK CGM, 2007, IEEE T MULTIMEDIA, V9
   TURTLE H, 1991, ACM T INFORM SYST, V9, P187, DOI 10.1145/125187.125188
   Wang Dong., 2007, the 15th ACM International Conference on Multimedia, P285
NR 41
TC 8
Z9 8
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 1
BP 77
EP 95
DI 10.1007/s11042-011-0848-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 114SU
UT WOS:000316763600005
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Raad, E
   Chbeir, R
   Dipanda, A
AF Raad, Elie
   Chbeir, Richard
   Dipanda, Albert
TI Discovering relationship types between users using profiles and shared
   photos in a social network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social networks; Link type prediction; Photo based inference; User
   profile; Photo metadata; Rule mining
AB In this paper, we propose a new approach to discover the relationship types between a user and her contacts in a social network. This is of key importance for many applications in the domain of photo sharing, privacy protection, information enriching, etc. Our approach is based, on one hand, on information extracted from users' profiles and their shared photos, and, on the other hand, on a set of predefined rules validated by the main user before being mined and derived according to her preferences and social network content. The contribution of our method is twofold: 1) it is user-based enabling the user to set her preferences and give her feedbacks on the derived rules and results, and 2) it is multi-criteria that exploits and combines several attributes and features from user profiles and shared photos respectively. It also allows the user to define new relationship types. We conducted a set of experiments to validate our approach. The obtained results show the accuracy of our approach in different scenarios.
C1 [Raad, Elie; Chbeir, Richard; Dipanda, Albert] Univ Bourgogne, CNRS LE2I, Dijon, France.
C3 Universite de Bourgogne
RP Raad, E (corresponding author), Univ Bourgogne, CNRS LE2I, Dijon, France.
EM elie.raad@u-bourgogne.fr
RI Chbeir, Richard/A-1071-2013
OI Chbeir, Richard/0000-0003-4112-1426
CR Adamic LA, 2003, SOC NETWORKS, V25, P211, DOI 10.1016/S0378-8733(03)00009-1
   Agrawal R., 1994, P INT VLDB C VLDB 94, P487, DOI DOI 10.5555/645920.672836
   [Anonymous], Combining collective classification and link prediction. Seventh IEEE Int. Conf. Data Mining Workshops (ICDMW 2007), 2007, DOI [DOI 10.1109/ICDMW.2007.35, 10.1109/ICDMW.2007.35]
   [Anonymous], 1983, INTRO MODERN INFORM
   Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9
   Bojars U, 2007, P INT C SOC SEM WEB, P47
   boyd D.M., 2004, CHI '04 Extended Abstracts on Human Factors in Computing Systems, P1279
   Cohen WW, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-440
   DT PengWu., 2009, Proceedings of MM09, P709
   Elliott B, 2008, CIVR 08, P75
   Gabrilovich E, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1606
   Golbeck J., 2008, AAAI, V8, P1138
   Golder S, 2008, P 19 ACM C HYP HYP, P43, DOI 10.1145/1379092.1379104
   Green T, 2010, PERCEPTION ONLINE SO, V288
   Han J., 2006, DATA MINING CONCEPTS
   Hogg T., 2008, Proc. of the AAAI Symposium on Social Information Processing, P30
   JARO MA, 1989, J AM STAT ASSOC, V84, P414, DOI 10.2307/2289924
   Jin Y, 2007, LNCS, V4519
   Kaplan AM, 2010, BUS HORIZONS, V53, P59, DOI 10.1016/j.bushor.2009.09.003
   Kautz H, 1997, AI MAG, V18, P27
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Lin MS, 2008, LECT NOTES COMPUT SC, V4956, P77
   Mika P, 2005, J WEB SEMANT, V3, P211, DOI 10.1016/j.websem.2005.05.006
   Miki T, 2005, 2005 SYMPOSIUM ON APPLICATIONS AND THE INTERNET, PROCEEDINGS, P38, DOI 10.1109/SAINT.2005.58
   Min JK, 2009, LECT NOTES COMPUT SC, V5585, P111
   Mori J, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2820
   Poole D, 2000, LECT NOTES ARTIF INT, V1861, P70
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Rowe R., 2007, Proceedings of the 9th WebKDD and 1st SNA-KDD 2007 Workshop on Web Mining and Social Network Analysis, WebKDD/SNA-KDD '07, P109
   Singla Parag, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563047
   Stefanone MA, 2008, BEHAV INFORM TECHNOL, V27, P97, DOI 10.1080/01449290600802429
   Tyler JR, 2005, INFORM SOC, V21, P133, DOI 10.1080/01972240590925348
   Vapnik V, 1998, DATA MIN KNOWL DISC, P1
   Wang C., 2010, P 16 ACM SIGKDD INT, P203
   Yu K., 2006, Advances in Neural Information Processing Systems, P1553, DOI DOI 10.7551/MITPRESS/7503.003.0199
   Zhang Tong., 2010, P ACM INT C IMAGE VI, P143
   Zhao M, 2009, LECT NOTES COMPUT SC, V5821, P269, DOI 10.1007/978-3-642-04843-2_29
NR 37
TC 9
Z9 13
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 1
BP 141
EP 170
DI 10.1007/s11042-011-0853-7
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 114SU
UT WOS:000316763600008
DA 2024-07-18
ER

PT J
AU Haque, MA
   Kim, JM
AF Haque, Mohammad A.
   Kim, Jong-Myon
TI An enhanced motion estimation approach using a genetic trail bounded
   approximation for H.264/AVC codecs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264; Inter-prediction; Motion estimation; Video compression; Genetic
   algorithm
ID ALGORITHM; PATTERN
AB Genetic algorithm-based motion estimation schemes play a significant role in improving the results of H.264/AVC standardization efforts when addressing conversational and non-conversational video applications. In this paper, we present a robust motion estimation scheme that uses a noble genetic trail bounded approximation (GTBA) approach to speed up the encoding process of H.264/AVC video compression and to reduce the number of bits required to code frame. The proposed algorithm is utilized to enhance the fitness function strength by integrating trail information of motion vector and sum of absolute difference (SAD) information into a fitness function. Experimental results reveal that the proposed GTBA resolves conflict obstacles with respect to both the number of bits required to code frames and the execution time for estimation.
C1 [Haque, Mohammad A.; Kim, Jong-Myon] Univ Ulsan, Sch Elect Engn, Ulsan 689749, South Korea.
C3 University of Ulsan
RP Kim, JM (corresponding author), Univ Ulsan, Sch Elect Engn, Ulsan 689749, South Korea.
EM jongmyon.kim@gmail.com
OI Haque, Mohammad Ahsanul/0000-0001-5613-2190
FU National Research Foundation of Korea(NRF); Korea government(MEST)
   [2011-0017941]
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MEST) (No.
   2011-0017941).
CR Adedoyin S, 2005, P CAN C EL COMP ENG, P927
   [Anonymous], J CONVERGENCE
   Cheong H.Y., 2002, 5 M JVT ISO IEC MPEG
   CHONG RM, 2010, J CONVERGENCE, V1, P49
   Chow KHK, 1993, IEEE T CIRC SYST VID, V3, P440, DOI 10.1109/76.260203
   Goldberg D. E., 1989, GENETIC ALGORITHMS S
   Gong ML, 2002, INT C PATT RECOG, P644, DOI 10.1109/ICPR.2002.1044829
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Koga T, 1981, P NTC 81 NEW ORL LA, V81
   Lin CH, 1998, IEEE T CIRC SYST VID, V8, P386, DOI 10.1109/76.709405
   Mayuran S, 2006, CAN CON EL COMP EN, P1488
   Po LM, 2007, IEEE T MULTIMEDIA, V9, P9, DOI 10.1109/TMM.2006.886330
   Sathappan O. L., 2011, International Journal of Information Technology, Communications and Convergence, V1, P146, DOI 10.1504/IJITCC.2011.039282
   Tsai JJ, 2010, IEEE T CIRC SYST VID, V20, P136, DOI 10.1109/TCSVT.2009.2026805
   Tsai JJ, 2007, IEEE P INT S CIRC SY
   Wang H, 2004, IEEE IMAGE PROC, P1469
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu T, 2006, P 20 INT C ADV INF N
   Yunming Ye, 2011, International Journal of Information Technology, Communications and Convergence, V1, P206, DOI 10.1504/IJITCC.2011.039286
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu S, 1997, ICICS - PROCEEDINGS OF 1997 INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING, VOLS 1-3, P292, DOI 10.1109/ICICS.1997.647106
NR 21
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 1
BP 63
EP 76
DI 10.1007/s11042-012-1023-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105KY
UT WOS:000316069400005
DA 2024-07-18
ER

PT J
AU Mekhaldi, D
   Lalanne, D
   Ingold, R
AF Mekhaldi, Dalila
   Lalanne, Denis
   Ingold, Rolf
TI A multimodal alignment framework for spoken documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal document; Document structure; Thematic alignment; Quotation
   alignment; Reference alignment
AB We present a multimodal document alignment framework, which highlights existing alignment relationships between documents that are discussed and recorded during multimedia events such as meetings. These relationships that should help indexing the archives of these events are detected using various techniques from natural language processing and information retrieval. The main alignment strategies studied are based on thematic, quotation and reference relationships. At the analysis level, the alignment framework was applied at several levels of granularity of documents, requiring specific document segmentation techniques. Our framework that is language independent was evaluated on corpora in French and English, including meetings and scientific presentations. The satisfactory evaluation results obtained at several stages show the importance of our approach in bridging the gap between meeting documents, independently from the language and domain. They highlight also the utility of the multimodal alignment in advanced applications, e.g. multimedia document browsing, content-based / temporal-based searching, etc.
C1 [Mekhaldi, Dalila] Wolverhampton Univ, Computat Linguist Grp, Wolverhampton WV1 1DJ, W Midlands, England.
   [Lalanne, Denis; Ingold, Rolf] Univ Fribourg, Dept Informat, CH-1700 Fribourg, Switzerland.
C3 University of Wolverhampton; University of Fribourg
RP Mekhaldi, D (corresponding author), Wolverhampton Univ, Computat Linguist Grp, Wolverhampton WV1 1DJ, W Midlands, England.
EM dalila.mekhaldi@gmail.com; Denis.lalanne@unifr.ch; Rolf.ingold@unifr.ch
OI Ingold, Rolf/0000-0001-7738-133X; Lalanne, Denis/0000-0001-7834-0417
CR Anderson R, 2005, COMPUT GRAPH-UK, V29, P480, DOI 10.1016/j.cag.2005.05.002
   Anderson R, 2007, COMPUTER, V40, P56, DOI 10.1109/MC.2007.307
   Anderson Richard., 2004, MULTIMEDIA '04: Proceedings of the 12th annual ACM international conference on Multimedia, P796
   [Anonymous], HTK TOOL
   Barras C., 1998, P 1 INT C LANG RES E, P1373
   Behera A, 2008, MULTIMED TOOLS APPL, V37, P135, DOI 10.1007/s11042-007-0137-4
   Bloechle J.L, 2006, P DAS 7 IAPR INT WOR
   Brotherton JA, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P54, DOI 10.1109/MMCS.1998.693625
   BROTHERTON JA, 2001, THESIS GEORGIA I TEC
   Chiu P., 2000, ACM 2000 Hypertext. Proceedings of the Eleventh ACM Conference on Hypertext and Hypermedia, P244, DOI 10.1145/336296.336403
   Chiu P., 2000, IEEE Multimedia, V7, P48, DOI 10.1109/93.895154
   Chiu P., 2004, P IEEE INT C MULT EX
   Corral D, 2005, THESIS U FRIBOURG SW
   Cutler R., 2002, MULTIMEDIA 02, P503, DOI DOI 10.1145/641007.641112
   Elsweiler D, 2007, J AM SOC INF SCI TEC, V58, P924, DOI 10.1002/asi.20570
   Girgensohn A, 2001, COMPUTER, V34, P61, DOI 10.1109/2.947093
   Gruenstein A., 2007, 8th ACL Workshop on Discourse and Dialogue (SIGDIAL), P111
   HEARST MA, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P9
   Kornfield EM, 2004, FIRST INTERNATIONAL WORKSHOP ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P195, DOI 10.1109/DIAL.2004.1263249
   Le Meur JY, 2005, FLASH INFORM, P12
   Le Q. A., 2009, P INTERSPEECH 2009 1, P624
   Little S., 2002, Research and Advanced Technology for Digital Libraries. 6th European Conference, ECDL 2002. Proceedings (Lecture Notes in Computer Science Vol.2458), P158
   Macedo A. A., 2001, Proceedings of the ACM Symposium on Document Engineering (DocEng '01), P144, DOI 10.1145/502187.502209
   Macedo AA, 2004, HYPERTEXT 04, P112, DOI DOI 10.1145/1012807.1012840
   Matrakas M. D., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P242, DOI 10.1109/ITCC.2000.844221
   Mekhaldi D, 2005, PROC INT CONF DOC, P924, DOI 10.1109/ICDAR.2005.117
   Mekhaldi D., 2007, P MULT INF RETR WORK
   Mekhaldi D, 2004, P 12 ANN C ACM MULT, P804
   Mekhaldi D, 2006, THESIS FRIBOURG SWIT
   Mekhaldi  D., 2010, J MULTIMED P TECHNOL, V1, P30
   Moore D, 2002, 20041068 USGS
   Morde A, 2002, P DOC AN SYST, P595
   Mukhopadhyay S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P477, DOI 10.1145/319463.319690
   Olligschlaeger AM, 1999, P ESRI US C CAL US
   Ponte JM, 1997, LECT NOTES COMPUT SC, V1324, P113, DOI 10.1007/BFb0026725
   Popescu-Belis A, 2004, P ACL 2004 WORKSH RE, P71
   Popescu-Belis A, 2010, P SIGIR 10 33 ANN IN
   Popescu-Belis A, 2004, P LREC 04 PORT, P1451
   Saetre R, 2005, LECT NOTES COMPUT SC, V3482, P327
   Schultz T, 2002, P HSC WORKSH HANDS F
   Tang LJ, 2005, PROC INT CONF DOC, P919
   Von Rotz D, 2006, F1106 EC POL FED LAU, P3
   WAHLSTER W, 1993, ARTIF INTELL, V63, P387, DOI 10.1016/0004-3702(93)90022-4
   Yu JH, 2004, STUDENT WORKSH COCLI
   Zhang B, 2004, P 13 ACM C INF KNOWL, P162
NR 45
TC 3
Z9 3
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 2
BP 353
EP 388
DI 10.1007/s11042-011-0842-x
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 985MK
UT WOS:000307270600005
DA 2024-07-18
ER

PT J
AU Yoo, B
   Park, J
   Lim, S
   Bang, J
   Lee, S
AF Yoo, Byeongyeong
   Park, Jungheum
   Lim, Sungsu
   Bang, Jewan
   Lee, Sangjin
TI A study on multimedia file carving method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia file; File carving; NTFS compressed file
AB File carving is a method that recovers files at unallocated space without any file information and used to recover data and execute a digital forensic investigation. In general, the file carving recovers files using the inherent header and footer in files or the entire file size determined in the file header. The largely used multimedia files, such as AVI, WAV, and MP3, can be exactly recovered using an internal format in files as they are continuously allocated. In the case of the NTFS, which is one of the most widely used file system, it supports an internal data compression function itself, but the NTFS compression function has not been considered in file carving. Thus, a large part of file carving tools cannot recover NTFS compressed files. Also, for carving the multimedia files compressed by the NTFS, a recovery method for such NTFS compressed files is required. In this study, we propose a carving method for multimedia files and represent a recovery plan for deleted NTFS compressed files. In addition, we propose a way to apply such a recovery method to the carving of multimedia files.
C1 [Yoo, Byeongyeong; Park, Jungheum; Lim, Sungsu; Bang, Jewan; Lee, Sangjin] Korea Univ, Ctr Informat Secur Technol, Grad Sch Informat Management & Secur, Seoul, South Korea.
   [Yoo, Byeongyeong; Park, Jungheum; Lim, Sungsu; Bang, Jewan; Lee, Sangjin] Korea Univ, Digital Forens Res Ctr, Seoul, South Korea.
C3 Korea University; Korea University
RP Lee, S (corresponding author), Korea Univ, Ctr Informat Secur Technol, Grad Sch Informat Management & Secur, Seoul, South Korea.
EM pinpanel@korea.ac.kr; junghmi@korea.ac.kr; nemography@korea.ac.kr;
   jwbang@korea.ac.kr; sangjin@korea.ac.kr
FU IT R&D program of MKE/KEIT [10035157]
FX This work was supported by the IT R&D program of MKE/KEIT[10035157,
   Development of Digital Forensic Technologies for Real-Time Analysis].
CR [Anonymous], 2005, File System Forensic Analysis
   Garfinkel SL, 2007, DIGITAL INVESIGATION, V4
   Library of Congress, 2009, WAVE AUD FIL FORM
   Metz Joachim, 2009, CARVING NTFS COMPRES
   Mikus N., 2005, An analysis of disc carving techniques
   Sanderson P, 2002, NTFS COMPRESSION FOR
NR 6
TC 18
Z9 22
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 1
BP 243
EP 261
DI 10.1007/s11042-010-0704-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 973FP
UT WOS:000306345000015
DA 2024-07-18
ER

PT J
AU Chen, HY
   Leou, JJ
AF Chen, Hsuan-Ying
   Leou, Jin-Jang
TI Multispectral and multiresolution image fusion using particle swarm
   optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Satellite image fusion; Particle swarm optimization (PSO); Color
   distortion; Blocking artifacts
ID LANDSAT THEMATIC MAPPER; SPOT; TM; ADJUSTMENT; TRANSFORM
AB Multispectral and multiresolution image fusion is important for many multimedia and remote sensing applications, such as video surveillance, medical imaging, and satellite imaging. For the commercial satellite "IKONOS," spatial resolutions of high-resolution panchromatic (PAN) and low-resolution multispectral (MS) satellite images are 1 m and 4 m, respectively. To cope with color distortion and blocking artifacts in fused images, in this study, a multispectral and multiresolution image fusion approach using PSO is proposed. The pixels of fused images in the training set are classified into several categories based on the characteristics of low-resolution MS images. Then, the smooth parameters of spatial and spectral responses between the high-resolution PAN and low-resolution MS images are determined by PSO. All the pixels within each category are normalized by its own smooth parameter so that color distortion and blocking artifacts can be greatly reduced. Based on the experimental results obtained in this study, the overall visual quality of the fused images by the proposed approach is better than that by three comparison approaches, whereas the correlation coefficients, gamma (PAN) , for the fused images by the proposed approach are greater than that by three comparison approaches.
C1 [Chen, Hsuan-Ying; Leou, Jin-Jang] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
C3 National Chung Cheng University
RP Leou, JJ (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
EM chenhy@cs.ccu.edu.tw; jjleou@cs.ccu.edu.tw
FU National Science Council, Taiwan, Republic of China [NSC
   98-2221-E-194-034-MY3, NSC 99-2221-E-194-032-MY3]
FX This work was supported in part by National Science Council, Taiwan,
   Republic of China under Grants NSC 98-2221-E-194-034-MY3 and NSC
   99-2221-E-194-032-MY3.
CR Aiazzi B, 2002, IEEE T GEOSCI REMOTE, V40, P2300, DOI 10.1109/TGRS.2002.803623
   [Anonymous], 1978, ACM SIGGRAPH COMPUT, DOI [10.1145/800248.807361, DOI 10.1145/965139.807361]
   [Anonymous], 2002, COMPUTATIONAL INTELL
   Barlas G, 2008, MULTIMED TOOLS APPL, V40, P361, DOI 10.1007/s11042-008-0211-6
   CARPER WJ, 1990, PHOTOGRAMM ENG REM S, V56, P459
   CHAVEZ PS, 1988, PHOTOGRAMM ENG REM S, V54, P1699
   CHAVEZ PS, 1989, PHOTOGRAMM ENG REM S, V55, P339
   CHAVEZ PS, 1986, PHOTOGRAMM ENG REM S, V52, P1637
   CHAVEZ PS, 1991, PHOTOGRAMM ENG REM S, V57, P295
   Davis L., 1991, Handbook of Genetic Algorithms
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   GarguetDuport B, 1996, PHOTOGRAMM ENG REM S, V62, P1057
   GILLESPIE AR, 1987, REMOTE SENS ENVIRON, V22, P343, DOI 10.1016/0034-4257(87)90088-5
   González-Audícana M, 2006, IEEE T GEOSCI REMOTE, V44, P1683, DOI 10.1109/TGRS.2005.863299
   Ioannidou S, 2007, IEEE GEOSCI REMOTE S, V4, P166, DOI 10.1109/LGRS.2006.887056
   Jian M, 2010, MULTIMEDIA TOOLS APP
   Kalpoma KA, 2007, IEEE T GEOSCI REMOTE, V45, P3075, DOI 10.1109/TGRS.2007.897692
   Kang LW, 2006, J VIS COMMUN IMAGE R, V17, P1127, DOI 10.1016/j.jvcir.2006.08.003
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Kovacevic A, 2010, MULTIMED TOOLS APPL, V47, P525, DOI 10.1007/s11042-009-0336-2
   Malpica JA, 2007, IEEE GEOSCI REMOTE S, V4, P27, DOI 10.1109/LGRS.2006.883523
   Núñez J, 1999, IEEE T GEOSCI REMOTE, V37, P1204, DOI 10.1109/36.763274
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Richards J.A., 2006, Remote Sensing Digital Image Analysis: An Introduction, Vfourth
   Schowengerdt R.A., 1997, REMOTE SENSING MODEL
   Tseng CC, 2008, IMAGE VISION COMPUT, V26, P1154, DOI 10.1016/j.imavis.2008.01.003
   Tu TM, 2007, IEEE GEOSCI REMOTE S, V4, P302, DOI 10.1109/LGRS.2007.894143
   Tu TM, 2004, IEEE GEOSCI REMOTE S, V1, P309, DOI 10.1109/LGRS.2004.834804
   Wang ZJ, 2005, IEEE T GEOSCI REMOTE, V43, P1391, DOI 10.1109/TGRS.2005.846874
   Zhou J, 1998, INT J REMOTE SENS, V19, P743, DOI 10.1080/014311698215973
NR 30
TC 9
Z9 9
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2012
VL 60
IS 3
BP 495
EP 518
DI 10.1007/s11042-011-0820-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 965ZC
UT WOS:000305805300002
DA 2024-07-18
ER

PT J
AU Bigot, B
   Ferrané, I
   Pinquier, J
   André-Obrecht, R
AF Bigot, Benjamin
   Ferrane, Isabelle
   Pinquier, Julien
   Andre-Obrecht, Regine
TI Detecting individual role using features extracted from speaker
   diarization results
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker segmentation; Speaker role detection; Temporal and prosodic
   features; Dimensionality reduction; Classification methods
ID SEMANTIC GAP; RETRIEVAL; SPEECH
AB In the field of automatic audiovisual content-based indexing and structuring, finding events like interviews, debates, reports, or live commentaries requires to bridge the gap between low-level feature extraction and such high-level event detection. In our work, we consider that detecting speaker roles like Anchor, Journalist and Other is a first step to enrich interaction sequences between speakers. Our work relies on the assumption of the existence of clues about speaker roles in temporal, prosodic and basic signal features extracted from audio files and from speaker segmentations. Each speaker is therefore represented by a 36-feature vector. Contrarily to most of the state-of-the-art propositions we do not use the structure of the document to recognize the roles of the interveners. We investigate the influence of two dimensionality reduction techniques (Principal Component Analysis and Linear Discriminant Analysis) and different classification methods (Gaussian Mixture Models, K-nearest neighbours and Support Vectors Machines). Experiments are done on the 13-h corpus of the ESTER2 evaluation campaign. The best result reaches about 82% of well recognized roles. This corresponds to more than 89% of speech duration correctly labelled.
C1 [Bigot, Benjamin; Ferrane, Isabelle; Pinquier, Julien; Andre-Obrecht, Regine] Univ Toulouse, IRIT, F-31062 Toulouse 09, France.
C3 Universite de Toulouse; Universite Toulouse III - Paul Sabatier;
   Universite Federale Toulouse Midi-Pyrenees (ComUE); Institut National
   Polytechnique de Toulouse
RP Bigot, B (corresponding author), Univ Toulouse, IRIT, 118 Route Narbonne, F-31062 Toulouse 09, France.
EM bigot@irit.fr; ferrane@irit.fr; pinquier@irit.fr; obrecht@irit.fr
RI PINQUIER, Julien/HGB-7599-2022
OI PINQUIER, Julien/0000-0003-1556-1284
FU  [ANR-06-CIS6-MDCA-006]
FX This work is conducted within the EPAC Project-ANR-06-CIS6-MDCA-006.
CR Banerjee S, 2006, NAACL HLT WORKSH AN
   Barzilay R, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P679
   Béchet F, 2004, SPEECH COMMUN, V42, P207, DOI 10.1016/j.specom.2003.07.003
   Bigot Benjamin, 2008, 2008 International Workshop on Content-based Multimedia Indexing - CBMI 2008, P162, DOI 10.1109/CBMI.2008.4564942
   Bigot B, 2008, ACM SIGIR WORKSH SEA, P62
   Canseco L, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P415
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   de Cheveigné A, 2002, J ACOUST SOC AM, V111, P1917, DOI 10.1121/1.1458024
   Duda R., 1973, Pattern Classification and Scene Analysis
   El-Khoury E, 2009, INT CONF ACOUST SPEE, P4097, DOI 10.1109/ICASSP.2009.4960529
   Esteve Y, 2010, P 7 LANG EV RES C EL
   Favre S, 2009, ACM INT C MULT BEIJ
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Furnkranz J., 2001, P 18 INT C MACHINE L, P146
   Galliano S, 2006, P LANG EV RES C
   Hsueh P-Y, 2007, P 45 ANN M ASS COMP, P1016
   Lamel L, 2005, INT CONF ACOUST SPEE, P1005
   Li BX, 2004, J VIS COMMUN IMAGE R, V15, P393, DOI 10.1016/j.jvcir.2004.04.006
   Liu Y., 2006, Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers, P81
   Luz S., 2009, P ACM MULT WORKSH SE, P21
   Mccowan I., 2005, P MEAS BEH 2005 5 IN
   Popescu A.-M., 2007, NATURAL LANGUAGE PRO, P9, DOI DOI 10.1007/978-1-84628-754-1_2
   Rouas JL, 2005, SPEECH COMMUN, V47, P436, DOI 10.1016/j.specom.2005.04.012
   Rui Cai, 2005, 13th Annual ACM International Conference on Multimedia, P628, DOI 10.1145/1101149.1101292
   Stolcke A., 1999, P DARPA BROADCAST NE, P61
   Vinciarelli A, 2007, IEEE T MULTIMEDIA, V9, P1215, DOI 10.1109/TMM.2007.902882
   Zhao R, 2002, IEEE T MULTIMEDIA, V4, P189, DOI 10.1109/TMM.2002.1017733
NR 27
TC 4
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 2
BP 347
EP 369
DI 10.1007/s11042-010-0609-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 958YH
UT WOS:000305276400006
DA 2024-07-18
ER

PT J
AU Nafaa, A
   Gourdin, B
   Murphy, L
AF Nafaa, Abdelhamid
   Gourdin, Baptiste
   Murphy, Liam
TI A dependable multisource streaming system for peer-to-peer -based video
   on demand services provisioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia communication; Multisource streaming; Error control; VOD
   services provisioning; QoS; P2P communication
AB In this article, we present the design, implementation, and analysis of a scalable VOD (Video On Demand) distribution architecture for IP networks. The focus of our work is on the underlying multisource streaming architecture upon which the P2P (Peer-to-Peer) -based VOD services provisioning system relies. While multipoint-to-point multisource streaming is the core building block for a distributed VOD services provisioning system, it also introduces new reliability challenges as the streaming failure probability increases with the number of sources in a session. A major contribution of our work is the design of a suite of distinct yet complementary reliability/failover mechanisms that can be leveraged to improve the dependability of multisource streaming, and the viability of P2P-based VOD systems in general. Our work shows that the reliability/failover mechanisms can be arranged, combined, and alternated in advanced adaptation policies in order to deal with different conditions exhibited by the network. Another contribution of our work consists of implementing and assessing the performance of the different reliability mechanisms and adaptation policies in a real prototype system. We evaluate both the accuracy of streaming problems diagnosis, and the efficiency of the reliability mechanisms, in two adaptation strategies: one responsive to loss variation, and the other responsive to delay variation.
C1 [Nafaa, Abdelhamid; Gourdin, Baptiste; Murphy, Liam] Univ Coll Dublin, Sch Comp Sci & Informat, Dublin 2, Ireland.
   [Gourdin, Baptiste; Murphy, Liam] Univ Coll Dublin, Performance Engn Lab, Dublin 2, Ireland.
C3 University College Dublin; University College Dublin
RP Nafaa, A (corresponding author), Univ Coll Dublin, Sch Comp Sci & Informat, Dublin 2, Ireland.
EM nafaa@ieee.org
OI Murphy, Liam/0000-0001-9777-005X
FU Science Foundation Ireland [09/SIRG/I1560]; Enterprise Ireland
   [CFTD/07/203-VIDAS]; Science Foundation Ireland (SFI) [09/SIRG/I1560]
   Funding Source: Science Foundation Ireland (SFI)
FX This material is partially based upon works supported by the Science
   Foundation Ireland under Grant No 09/SIRG/I1560. The work was also
   partially supported by the Enterprise Ireland VidAs project, Technology
   Development Commercialisation Fund, CFTD/07/203-VIDAS.
CR Annapureddy S, 2007, IEEE INFOCOM SER, P2571, DOI 10.1109/INFCOM.2007.323
   Apostolopoulos J, 2002, IEEE INFOCOM SER, P1736, DOI 10.1109/INFCOM.2002.1019427
   Bindal R., 2006, Operating Systems Review, V40, P22, DOI 10.1145/1151374.1151382
   Do TT, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1467, DOI 10.1109/ICC.2004.1312755
   Heffeeda M., 2003, P ACM MULTIMEDIA, P45
   Huang Y, 2007, NOSSDAV 2007 URB CHA
   Huntington D, 2005, U.S. Patent, Patent No. [6,970,937, 6970937]
   Itaya S, 2005, 11TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED SYSTEMS, VOL I, PROCEEDINGS, P15
   Liao X., 2006, P IEEE INFOCOM, P1
   López-Fuentes FD, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P457, DOI 10.1109/ICME.2008.4607470
   Magharei N, 2007, IEEE INFOCOM SER, P1415
   Mundur P, 2004, IEEE T MULTIMEDIA, V6, P129, DOI 10.1109/TMM.2003.819757
   Nafaa A, 2010, IEEE T IN PRESS  JUN
   Schierl T, 2006, IEEE WIREL COMMUN, V13, P96, DOI 10.1109/WC-M.2006.250365
   Vikash A, 2005, P SPIE MULT COMP NET, V5680, P13
   Xu DY, 2002, INT CON DISTR COMP S, P363, DOI 10.1109/ICDCS.2002.1022274
   Yoshihiro K, 2000, RFC3016
NR 17
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 1
BP 169
EP 220
DI 10.1007/s11042-011-0755-8
PG 52
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 940DI
UT WOS:000303869800010
DA 2024-07-18
ER

PT J
AU Ghazal, M
   Vázquez, C
   Amer, A
AF Ghazal, Mohammed
   Vazquez, Carlos
   Amer, Aishy
TI Real-time vandalism detection by monitoring object activities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vandalism detection; Event detection; Surveillance systems; Video
   processing
AB This paper proposes a novel method for the detection of vandalism events in video sequences. The method is based on a proposed definition for common vandal behaviors recorded on surveillance video sequences. To do this, the method monitors changes inside a restricted site containing vandalism-prone objects such as a vending machine, a pay phone, or a street sign. When an object is detected as leaving such a site, the proposed method checks if the site contains temporally consistent and significant static changes, representing damage. If there are such changes and given that the site is normally unchanged after legal use, a vandalism event is declared and the vandals are tracked. The proposed method is tested on video sequences showing real and simulated vandal behaviors and it achieves a detection rate of 96%. It detects different forms of vandalism such as graffiti and theft, and can handle sudden illumination changes, occlusions, and segmentation errors. The proposed method operates at a frame rate of 13 frames per second.
C1 [Ghazal, Mohammed; Amer, Aishy] Concordia Univ, Montreal, PQ H3G 1M8, Canada.
   [Vazquez, Carlos] Commun Res Ctr Canada, Ottawa, ON K2H 8S2, Canada.
C3 Concordia University - Canada; Communications Research Centre Canada
RP Ghazal, M (corresponding author), Concordia Univ, 1455 Maisonneuve, Montreal, PQ H3G 1M8, Canada.
EM ghazal@ieee.org; carlos.vazquez@crc.ca; amer@ece.concordia.ca
OI Vazquez, Carlos/0000-0003-2161-8507; Ghazal,
   Mohammed/0000-0002-9045-6698
FU Natural Sciences and Engineering Research Council (NSERC) of Canada
FX This work was supported, in part, by the Natural Sciences and
   Engineering Research Council (NSERC) of Canada.
CR Achkar F., 2007, PROC SPIE VISUAL COM, V6508, pJ1
   Allen P, 2004, ACM-IEEE J CONF DIG, P389, DOI 10.1145/996350.996455
   Amer A, 2005, IEEE T CIRC SYST VID, V15, P1448, DOI 10.1109/TCSVT.2005.857311
   Angiati D, 2005, AVSS 2005: Advanced Video and Signal Based Surveillance, Proceedings, P242
   BARKER M, 1994, POLICE RES GROUP CRI, P1
   Candamo J, 2010, IEEE T INTELL TRANSP, V11, P206, DOI 10.1109/TITS.2009.2030963
   Chan T. S. K., 2008, IEDM, P1
   Chee BC, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P143, DOI 10.1109/ICIAP.2007.4362771
   Cupillard F., 2004, 2004 IEEE International Conference on Networking, Sensing and Control (IEEE Cat. No.04EX761), P186
   di Stefano L, 2008, 8 INT WORKSH VIS SUR, V1
   Ghazal M, 2007, IEEE SYS MAN CYBERN, P2756
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686
   Krausz B, 2010, MULTIMED TOOLS APPL, V50, P123, DOI 10.1007/s11042-009-0367-8
   Ma JB, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P382, DOI 10.1109/AVSS.2009.25
   Nguyen N.T., 2003, IEEE C COMPUTER VISI, P1
   NING N, 2006, P 9 INT C CONTR AUT, P1
   Oates T, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P846
   Sacchi C, 2001, IEEE IMAGE PROC, P541, DOI 10.1109/ICIP.2001.959073
   Sacchi C, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P529, DOI 10.1109/ICIAP.2001.957064
   Sauve J, 2004, CRIME STAT CANADA, V25
   Tombari F., 2008, GRAFFITI DETECTION U, P645
   Valera M, 2005, IEE P-VIS IMAGE SIGN, V152, P192, DOI 10.1049/ip-vis:20041147
   Vazquez Carlos., 2008, SIVIP, V3, P13
NR 24
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2012
VL 58
IS 3
BP 585
EP 611
DI 10.1007/s11042-011-0751-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 935GU
UT WOS:000303507900007
DA 2024-07-18
ER

PT J
AU Chang, S
   Chung, J
   Seo, K
   Suh, D
AF Chang, Seongju
   Chung, Jaedo
   Seo, Kiwon
   Suh, Dongjun
TI Modularized multimedia framework for multi-modal and multi-functional
   interactions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Modular unit; Planar construct; Smart cell; Multi-modality; Functional
   polymorphism; Interactive multimedia
AB Smart Architectural Surface is a novel and highly integrated planar construct for diversified smart home services with networked smart cell units equipped with various sensing, cognition and actuation capabilities that would allow run-time polymorphism as the basis for functional changes for various event-driven operation scenarios. The SAS system can demonstrate the outcomes of collective intelligence that are mediated by various multi-modal interactions. Current SAS prototype is capable of polymorphous functional changes for dynamically adjustable electronic wallpaper, location/distance-aware video conferencing, personalized information browser, and automatic responses to various unintended events. Future applications would harness machine learning and machine vision techniques and will explore the advantages of having computational ecology of its digital modular units constituting smart wall system for multi-modal and multi-functional interactions.
C1 [Chang, Seongju; Suh, Dongjun] Korea Adv Inst Sci & Technol, Taejon 305701, South Korea.
   [Chung, Jaedo] Univ Auckland, Bioengn Inst, Auckland 1142, New Zealand.
   [Seo, Kiwon] NCsoft R&D Ctr BD, NC Soft, Seoul 135090, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); University of
   Auckland
RP Chang, S (corresponding author), Korea Adv Inst Sci & Technol, 291 Daehak Ro,373-1 Guseong Dong, Taejon 305701, South Korea.
EM schang@kaist.ac.kr; jaedo.chung@auckland.ac.nz; oedalpha@gmail.com;
   djsuh@kaist.ac.kr
FU High tech Urban Development Program [07High Tech A01]; Ministry of Land,
   Transportation and Maritime Affairs of Korean government
FX This research was supported by a grant (07High Tech A01) from High tech
   Urban Development Program funded by Ministry of Land, Transportation and
   Maritime Affairs of Korean government.
CR [Anonymous], MICR DIRECTX
   [Anonymous], DILBERTS ULTIMATE CU
   [Anonymous], BUILD ONL
   Cline LS, IEEE MULT SYST 98 AU
   Hereld M, 2000, IEEE COMPUT GRAPH, V20, P22, DOI 10.1109/38.851746
   Jeong B., 2006, SC 2006 Conference, Proceedings of the ACM/IEEE, P24, DOI 10.1109/SC.2006.35
   Low K-L, 2001, VRST 01 NOV 2001 ALB
   Minar N, 1999, ASA MA 99 M IN PRESS
   Nirnimesh, 2007, IEEE T VIS COMPUT GR, V13, P864, DOI 10.1109/TVCG.2007.1049
   Pape D, 1997, CAVE USERS GUIDE ELE
   Prante T, 2003, P UB COMP UBICOMP 03
   Wilhelmson R, 2004, 18 INT C IIPS JAN 20
NR 12
TC 4
Z9 4
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 2
SI SI
BP 331
EP 349
DI 10.1007/s11042-010-0653-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AR
UT WOS:000300189100007
DA 2024-07-18
ER

PT J
AU Zafar, K
   Baig, AR
AF Zafar, Kashif
   Baig, Abdul Rauf
TI Optimization of route planning and exploration using multi agent system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ant colony optimization; Route planning; Autonomous agents; Multi agent
   system; Swarm intelligence
AB This research presents an optimization technique for route planning and exploration in unknown environments. It employs the hybrid architecture that implements detection, avoidance and planning using autonomous agents with coordination capabilities. When these agents work for a common objective, they require a robust information interchange module for coordination. They cannot achieve the goal when working independently. The coordination module enhances their performance and efficiency. The multi agent systems can be employed for searching items in unknown environments. The searching of unexploded ordinance such as the land mines is an important application where multi agent systems can be best employed. The hybrid architecture incorporates learning real time A* algorithm for route planning and compares it with A* searching algorithm. Learning real time A* shows better results for multi agent environment and proved to be efficient and robust algorithm. A simulated ant agent system is presented for route planning and optimization and proved to be efficient and robust for large and complex environments.
C1 [Zafar, Kashif; Baig, Abdul Rauf] Natl Univ Comp & Emerging Sci, Islamabad, Pakistan.
RP Zafar, K (corresponding author), Natl Univ Comp & Emerging Sci, Islamabad, Pakistan.
EM kashif.zafar@nu.edu.pk; rauf.baig@nu.edu.pk
CR Ahn S, 2003, P INT ROB SYST IROS
   [Anonymous], 1991, Proceedings of the International Joint Conference in Artificial Intelligence
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   Dorigo M, 2007, IRIDIA TECHNICAL REP
   Engelbrecht A., 2007, Computational Intelligence: An Introduction, Vsecond
   Howard A, 2002, DISTRIBUTED AUTONOMOUS ROBOTIC SYSTEMS 5, P299
   ISHIDA T, 1995, IEEE T PATTERN ANAL, V17, P609, DOI 10.1109/34.387507
   Jing Xiao, 1997, IEEE Transactions on Evolutionary Computation, V1, P18, DOI 10.1109/4235.585889
   Korf R. E., 1988, AAAI 88. Seventh National Conference on Artificial Intelligence, P139
   KORF RE, 1990, ARTIF INTELL, V42, P189, DOI 10.1016/0004-3702(90)90054-4
   KORF RE, 1987, P AAAI 87 SEATTLE, P133
   Latimer D, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P961, DOI 10.1109/ROBOT.2002.1013480
   Li ZY, 2004, LECT NOTES COMPUT SC, V3320, P376
   Mei H., 2006, International Journal of Information Technology, V12, P78
   Qiang Z, 2006, LNCS
   Russell S., 1995, Prentice Hall series in artificial intelligence, V25, P27
   Solanas A., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P717
   Stentz A, 1994, P INT C ROB AUT IEEE
   Vien NA, 2007, LNCS
   Yamauchi B, 1997, P INT S COMP INT ROB
   Yamauchi B, 1998, P 2 INT C AUT AG ACM
   Zafar K, 2009, P INT C COMP SYST AP
   Zafar K, 2006, P INT COMP SOFTW APP, P327
NR 23
TC 3
Z9 5
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 2
SI SI
BP 245
EP 265
DI 10.1007/s11042-010-0585-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AR
UT WOS:000300189100002
DA 2024-07-18
ER

PT J
AU Wang, WY
   Chen, YW
AF Wang, Wenyi
   Chen, Yaowu
TI SmartPeerCast: a Smart QoS driven P2P live streaming framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE P2P; Broadcasting; Live streaming; QoS; Transrating
ID PEER-TO-PEER; CHALLENGES; NETWORK; MESH
AB The P2P swarm technologies have been shown to be very efficient for medium scale content distribution systems in the last few years, such as the file sharing and video-on-demand (VOD) applications. However it is still an open topic about how to deploy the P2P paradigm for the real time video broadcasting (RTVB) applications. The P2P RTVB application is different from the cache based P2P system because it has more stringent restrictions for startup time and packet loss ratio. In this paper, an adaptive media broadcasting P2P framework named SmartPeerCast which employs the media transrating service to control the quality of service (QoS), is proposed. SmartPeerCast achieves a network awareness, codec awareness, and high performance RTVB service with four key designs: (1) It groups the newly joined peers into different quality clusters by their uploading capability. This clustering mechanism avoids the bandwidth bottleneck between the heterogeneous peers of the overall P2P overlay by only forwarding the same quality stream over the peers in the same cluster. (2) The streaming quality is adjusted adaptively between the sending and the receiving peers by a Smart QoS algorithm to compensate for the network jitters to reduce the receiving peer's playback jitter. (3) The receiving peer monitors the data forwarding QoS of the sending peer to select the best suitable parent node dynamically. The SmartPeerCast uses this Smart QoS framework to implement an incentive mechanism to award the peers with high uploading contributions by migrating them to a higher quality cluster. (4) A transrating engine is used at the leaf nodes of the high quality cluster to forward the stream with suitable bits rate to the nodes of the low quality cluster; this transrating service not only can fully utilize the uploading bandwidth of the peers in the higher quality cluster but also avoids the bandwidth bottleneck of stream forwarding between the heterogeneous peers. Our experiment results and the real deployment show that SmartPeerCast can eliminate the bandwidth bottleneck and content bottleneck between the heterogeneous peers with a smaller startup time and packet loss and it is a high performance and medium scale P2P RTVB framework.
C1 [Wang, Wenyi; Chen, Yaowu] Zhejiang Univ, Adv Digital Technol & Instruments Inst, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Wang, WY (corresponding author), Zhejiang Univ, Adv Digital Technol & Instruments Inst, Hangzhou 310027, Zhejiang, Peoples R China.
EM walker_wwy@hotmail.com
CR Ahmed T, 2007, J NETW SYST MANAG, V15, P289, DOI 10.1007/s10922-007-9068-7
   Annapureddy S., 2007, Proc. Int'l WWW Conference, P903
   [Anonymous], P 3 ACM SIGOPS EUROS
   Assuncao PAA, 1997, IEE P-VIS IMAGE SIGN, V144, P377, DOI 10.1049/ip-vis:19971558
   Cai Y, 2006, IEEE T KNOWL DATA EN, V18, P1711, DOI 10.1109/TKDE.2006.181
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   Cheng B., 2008, 18th Int'l Workshop on Network and Operating Systems Support for Digital Audio and Video (NOSSDAV '08), P93, DOI DOI 10.1145/1496046.1496068
   Cheng B, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1412196.1412199
   Chu YH, 2002, IEEE J SEL AREA COMM, V20, P1456, DOI 10.1109/JSAC.2002.803066
   Dana C., 2005, Multimedia Signal Processing, 2005 IEEE 7th Workshop on, P1, DOI [DOI 10.1109/MMSP.2005.248586, 10.1109/MMSP.2005.248586.]
   Do TT, 2008, COMPUT COMMUN, V31, P506, DOI 10.1016/j.comcom.2007.08.024
   Guo Y., 2003, Proceedings of the 12th International Conference on World Wide Web, P301, DOI DOI 10.1145/775152.775195
   Guo Y, 2008, COMPUT COMMUN, V31, P520, DOI 10.1016/j.comcom.2007.08.022
   Huang Y, 2008, ACM SIGCOMM COMP COM, V38, P375, DOI 10.1145/1402946.1403001
   IIQBAL R, 2009, DAG STREAM DISTRIBUT
   Jannotti J., 2000, OSDI 00 P 4 C S OPER, P14
   JIANG X, 2003, INT C MULT EXP ICME, V2, P325
   Jin X., 2007, ADV MULTIMEDIA, V2007, P10
   Jurca D, 2007, IEEE COMMUN MAG, V45, P108, DOI 10.1109/MCOM.2007.374427
   Kim H, 2008, MULTIMED TOOLS APPL, V39, P117, DOI 10.1007/s11042-007-0160-5
   Kostic D., 2003, Operating Systems Review, V37, P282, DOI 10.1145/1165389.945473
   LAVRENTIEV M, 2009, THESIS
   Liao XF, 2007, IEEE T PARALL DISTR, V18, P1663, DOI 10.1109/TPDS.2007.70708
   Liu JC, 2008, P IEEE, V96, P11, DOI 10.1109/JPROC.2007.909921
   Liu Y, 2008, PEER PEER NETW APPL, V1, P18, DOI 10.1007/s12083-007-0006-y
   Magharei N, 2007, IEEE INFOCOM SER, P1415
   Magharei N, 2007, IEEE INFOCOM SER, P1424
   Mol JJD, 2008, PROC SPIE, V6818, DOI 10.1117/12.774909
   Pai V, 2005, LECT NOTES COMPUT SC, V3640, P127
   Pianese F, 2007, IEEE T MULTIMEDIA, V9, P1645, DOI 10.1109/TMM.2007.907466
   Tian Y, 2008, J SYST ARCHITECT, V54, P55, DOI 10.1016/j.sysarc.2007.03.008
   Tran DA, 2003, IEEE INFOCOM SER, P1283
   Vlavianos Aggelos., 2006, Proceedings IEEE INFOCOM 2006. 25TH IEEE International Conference on Computer Communications, P1
   Wang M, 2007, IEEE J SEL AREA COMM, V25, P1655, DOI 10.1109/JSAC.2007.071205
   YVES DON, 2008, THESIS
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
NR 36
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 2
BP 445
EP 471
DI 10.1007/s11042-010-0547-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 781SK
UT WOS:000291953700012
DA 2024-07-18
ER

PT J
AU Zaki, WMDW
   Fauzi, MFA
   Besar, R
   Ahmad, WSHMW
AF Zaki, W. Mimi Diyana W.
   Fauzi, M. Faizal A.
   Besar, Rosli
   Ahmad, W. Siti Haimatul Munirah W.
TI Abnormalities detection in serial computed tomography brain images using
   multi-level segmentation approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-level segmentation; Otsu thresholding; Fuzzy C-Means; CT brain
   images; Content-based medical image retrieval
AB Segmentation, where pixels are categorized by tissue types, is essential in medical image processing. This paper proposes a multi-level Fuzzy C-Means method to extract an intracranial from its background and skull. Then, a two-level Otsu multi-thresholding method is applied to segment the intracranial structure into cerebrospinal fluid, brain matters and other homogenous regions. Based on symmetrical properties in the intracranial structures, the left-half and right-half segmented intracranial regions are quantitatively compared with respect to the intracranial midline. The segmented regions are found to be very useful in providing information regarding normal and abnormal structures in the intracranial because any asymmetry that is detected would indicate a high probability of abnormalities. Additionally, pixel intensity information such as standard deviation and the maximum value of the pixels of the segmented regions are used to distinguish abnormalities such as bleeding and calcification from normal cases. This experimental work uses a medical image database consisting of 519 normal and 201 abnormal serial computed tomography (CT) brain images from 31 patients. The proposed multi-level segmentation approach proved to effectively isolate important homogenous regions in CT brain images. The extracted features of the regions would provide a strong basis for the application of content-based medical image retrieval (CMBIR).
C1 [Zaki, W. Mimi Diyana W.] Univ Kebangsaan Malaysia, Dept Elect Elect & Syst, Fac Engn & Built Environm, Bangi 43600, Selangor, Malaysia.
   [Fauzi, M. Faizal A.; Ahmad, W. Siti Haimatul Munirah W.] Multimedia Univ, Fac Engn, Cyberjaya 63100, Selangor, Malaysia.
   [Besar, Rosli] Multimedia Univ, Fac Engn & Technol, Melaka 75450, Malaysia.
C3 Universiti Kebangsaan Malaysia; Multimedia University; Multimedia
   University
RP Zaki, WMDW (corresponding author), Univ Kebangsaan Malaysia, Dept Elect Elect & Syst, Fac Engn & Built Environm, Bangi 43600, Selangor, Malaysia.
EM wmdiyana@eng.ukm.my; faizal1@mmu.edu.my; rosli@mmu.edu.my;
   halimatul@mmu.edu.my
RI Fauzi, Mohammad Faizal Ahmad/J-9555-2012; W Ahmad, W S H
   Munirah/A-6666-2017; Zaki, Wan Mimi Diyana Wan/D-9631-2017; Besar,
   Rosli/E-3541-2010
OI W Ahmad, W S H Munirah/0000-0001-6364-6341; Zaki, Wan Mimi Diyana
   Wan/0000-0001-5808-4348; Ahmad Fauzi, Mohammad
   Faizal/0000-0001-5382-6269
FU MOSTI [01-02-01-SF0014]
FX The authors are grateful to Faculty of Engineering, Multimedia
   University, Malaysia. We are also grateful to the MOSTI for their
   support under grant number 01-02-01-SF0014 (the eScienceFund Project),
   and to our collaborator, the Imaging Department of Hospital Putrajaya,
   Malaysia, which provides the CT brain images used in this work. Besides,
   we also would like to thank Dr. Fatimah Othman for her guidance.
CR [Anonymous], 2006, IMAGE PROCESSING TOO
   Bushberg J. T., 2002, The Essential Physics of Medical Imaging
   Cosic D., 1996, Proceedings. 11th International Symposium on Biomedical Engineering '96, P63
   Gong TX, 2007, LECT NOTES COMPUT SC, V4774, P401
   Hara T, 2007, PROC SPIE, V6514, DOI 10.1117/12.710307
   Hu QM, 2005, P ANN INT IEEE EMBS, P3375
   KOVACEVIC D, 1998, P IEEE MELECON, DOI DOI 10.1109/MELCON.1998.692188
   Lauric A., 2007, TR20073 TUFTS U DEP
   Lewis S., 2007, RADIOGRAPHIC PRACTIC
   LIU R, 2008, P ICPR, DOI DOI 10.1109/ICPR.2008.4761745
   LONCARIC S, 1996, P IEEE EMBS, DOI DOI 10.1109/IEMBS.1996.651952
   LONCARIC S, 1998, P MELECON, DOI DOI 10.1109/MELCON.1998.699485
   MAJCENIC Z, 2007, P 9 EUSIPCO
   Maksimovic R, 2000, INT J MED INFORM, V58, P29, DOI 10.1016/S1386-5056(00)00073-3
   Mancas M, 2004, PROC SPIE, V5370, P1598, DOI 10.1117/12.535017
   Manikandan S., 2008, EUR J SCI RES, V24, P163
   OTSU N, 1979, P SMCS, DOI DOI 10.1109/TSMC.1979.4310076
   Shao H, 2003, P SOC PHOTO-OPT INS, V5286, P741, DOI 10.1117/12.538780
   Wasserberg J., 2009, CT SCAN GUIDELINE
   WEI K, 2007, P IEEE ICBBE, DOI DOI 10.1109/ICBBE.2007.187
   Zaki WMDW, 2009, LECT NOTES COMPUT SC, V5857, P156, DOI 10.1007/978-3-642-05036-7_16
   ZAKI WMD, 2003, WORLD SCI J J MECH M, V3, P247, DOI DOI 10.1142/S0219519403000752
   2008, WEBMD PART WEBMD NET
NR 23
TC 17
Z9 17
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 2
BP 321
EP 340
DI 10.1007/s11042-010-0524-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 781SK
UT WOS:000291953700006
DA 2024-07-18
ER

PT J
AU Jian, MW
   Dong, JY
AF Jian, Muwei
   Dong, Junyu
TI Capture and fusion of 3d surface texture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; 3D surface textures; Wavelet decomposition; Saliency
AB Image fusion is a process that multiple images of a scene are combined to form a single image. The aim of image fusion is to preserve the full content and retain important features of each original image. In this paper, we propose a novel approach based on wavelet transform to capture and fusion of real-world rough surface textures, which are commonly used in multimedia applications and referred to as3D surface texture. These textures are different from 2D textures as their appearances can vary dramatically with different illumination conditions due to complex surface geometry and reflectance properties. In our approach, we first extract gradient/height and albedo maps from sample 3D surface texture images as their representation. Then we measure saliency of wavelet coefficients of these 3D surface texture representations. The saliency values reflect the meaningful content of the wavelet coefficients and are consistent with human visual perception. Finally we fuse the gradient/height and albedo maps based on the measured saliency values. This novel scheme aims to preserve the original texture patterns together with geometry and reflectance characteristics from input images. Experimental results show that the proposed approach can not only capture and fuse 3D surface texture under arbitrary illumination directions, but also has the ability to retain the surface geometry properties and preserve perceptual features in the original images.
C1 [Jian, Muwei] Shandong Univ Weihai, Sch Space Sci & Phys, Weihai 264209, Peoples R China.
   [Dong, Junyu] Ocean Univ China, Dept Comp Sci & Technol, Qingdao 266100, Peoples R China.
C3 Shandong University; Ocean University of China
RP Dong, JY (corresponding author), Ocean Univ China, Dept Comp Sci & Technol, 238 Songling Rd, Qingdao 266100, Peoples R China.
EM jianmuwei@gmail.com; dongjunyu@ouc.edu.cn
RI ; Jian, Muwei/Q-8319-2018
OI Dong, Junyu/0000-0001-7012-2087; Jian, Muwei/0000-0002-4249-2264
FU National Natural Science Foundation of China [60702014]
FX We would like to thank the anonymous reviewers for their helpful
   comments. The project (No. 60702014) is supported by National Natural
   Science Foundation of China.
CR ABIDI M, 1992, DATA FUSION ROBOTICS, P10
   Burschka D, 2003, P IEEE VIRT REAL ANN, P299, DOI 10.1109/VR.2003.1191174
   Burt P. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P173, DOI 10.1109/ICCV.1993.378222
   Cardinali A, 2005, 2005 7TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), VOLS 1 AND 2, P475
   Dong J.Y., 2003, P 3 INT WORKSH TEXT, P31
   Dong JY, 2005, INT J COMPUT VISION, V62, P177, DOI 10.1007/s11263-005-4641-6
   Dong JY, 2004, FOURTH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, PROCEEDINGS, P716
   Drbohlav O, 2002, LECT NOTES COMPUT SC, V2351, P46
   GANZALO P, 2004, PATTERN RECOGN, V37, P1855
   HILL P, 2002, P 13 BRIT MACH VIS C, P487, DOI DOI 10.5244/C.16.47
   Holly E., 1997, P EUROGRAPHICS WORKS, P35
   Jian MW, 2007, INT C WAVEL ANAL PAT, P338
   Jian MW, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2194
   Jian MW, 2007, SNPD 2007: EIGHTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, VOL 1, PROCEEDINGS, P764, DOI 10.1109/SNPD.2007.104
   KOREN I, 1995, P 1995 INT C IM PROC, V1, P323
   Lewis J. J., 2004, Seventh International Conference on Information Fusion, P555
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li ZH, 2003, 2003 IEEE INTELLIGENT TRANSPORTATION SYSTEMS PROCEEDINGS, VOLS. 1 & 2, P96
   Ma H., 2005, INT J INFORM TECHNOL, V11, P81
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Piella G, 2002, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOL II, P1557, DOI 10.1109/ICIF.2002.1021002
   Robb M., 2003, P VIS VID GRAPH 2003, P79
   Rockinger O, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P288, DOI 10.1109/ICIP.1997.632093
   Sebe N, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P15, DOI 10.1109/IVL.2000.853833
   TIAN Q, 2001, J ELECT IMAGING  OCT
   Toet A., 1990, Machine Vision and Applications, V3, P3, DOI DOI 10.1007/BF01211447
   WOODHAM RJ, 1981, ARTIF INTELL, V17, P117, DOI 10.1016/0004-3702(81)90022-9
NR 27
TC 11
Z9 12
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2011
VL 53
IS 1
BP 237
EP 251
DI 10.1007/s11042-010-0509-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 746AZ
UT WOS:000289214700010
DA 2024-07-18
ER

PT J
AU Lu, X
   Matsuda, S
   Unoki, M
   Nakamura, S
AF Lu, Xugang
   Matsuda, Shigeki
   Unoki, Masashi
   Nakamura, Satoshi
TI Temporal modulation normalization for robust speech feature extraction
   and recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE Robust speech recognition; Temporal modulation; Speech intelligibility;
   Edge-preserved smoothing
AB Speech signals are produced by the articulatory movements with a certain modulation structure constrained by the regular phonetic sequences. This modulation structure encodes most of the speech intelligibility information that can be used to discriminate the speech from noise. In this study, we proposed a noise reduction algorithm based on this speech modulation property. Two steps are involved in the proposed algorithm: one is the temporal modulation contrast normalization, another is the modulation events preserved smoothing. The purpose for these processing is to normalize the modulation contrast of the clean and noisy speech to be in the same level, and to smooth out the modulation artifacts caused by noise interferences. Since our proposed method can be used independently for noise reduction, it can be combined with the traditional noise reduction methods to further reduce the noise effect. We tested our proposed method as a front-end for robust speech recognition on the AURORA-2J data corpus. Two advanced noise reduction methods, ETSI advanced front-end (AFE) method, and particle filtering (PF) with minimum mean square error (MMSE) estimation method, are used for comparison and combinations. Experimental results showed that, as an independent front-end processor, our proposed method outperforms the advanced methods, and as combined front-ends, further improved the performance consistently than using each method independently.
C1 [Lu, Xugang; Matsuda, Shigeki; Nakamura, Satoshi] Natl Inst Informat & Commun Technol, Tokyo 1848795, Japan.
   [Unoki, Masashi] Japan Adv Inst Sci & Technol, Ishikawa 9231292, Japan.
C3 National Institute of Information & Communications Technology (NICT) -
   Japan; Japan Advanced Institute of Science & Technology (JAIST)
RP Lu, X (corresponding author), Natl Inst Informat & Commun Technol, Tokyo 1848795, Japan.
EM xugang.lu@nict.go.jp
OI Unoki, Masashi/0000-0002-6605-2052
FU Grants-in-Aid for Scientific Research [22700193] Funding Source: KAKEN
CR Atlas L, 2003, EURASIP J APPL SIG P, V2003, P668, DOI 10.1155/S1110865703305013
   Chen CP, 2007, IEEE T AUDIO SPEECH, V15, P257, DOI 10.1109/TASL.2006.876717
   de la Torre A, 2005, IEEE T SPEECH AUDI P, V13, P355, DOI 10.1109/TSA.2005.845805
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P2670, DOI 10.1121/1.409836
   Elad M, 2002, IEEE T IMAGE PROCESS, V11, P1141, DOI 10.1109/TIP.2002.801126
   *ETSI ES, 2007, 202050V115 ETSI ES
   FUJIMOTO M, 2006, ICASSP06, V1, P769
   Hermansky H., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P83, DOI 10.1109/ICASSP.1993.319236
   HOUTGAST T, 1985, J ACOUST SOC AM, V77, P1069, DOI 10.1121/1.392224
   Hung JW, 2006, IEEE T AUDIO SPEECH, V14, P808, DOI 10.1109/TSA.2005.857801
   Kanedera N, 1999, SPEECH COMMUN, V28, P43, DOI 10.1016/S0167-6393(99)00002-3
   Loizou P. C., 2007, Speech Enhancement: Theory and Practice
   Lu X, 2009, INT CONF ACOUST SPEE, P4573, DOI 10.1109/ICASSP.2009.4960648
   Moore BCJ, 2003, INTRO PSYCHOL HEARIN
   NEUMANN J, 2007, PERS UBIQUIT COMPUT, P1617
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Shen JL, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P881, DOI 10.1109/ICSLP.1996.607742
   Xiao X, 2008, IEEE T AUDIO SPEECH, V16, P1662, DOI 10.1109/TASL.2008.2002082
   Xiao X, 2007, IEEE SIGNAL PROC LET, V14, P500, DOI 10.1109/LSP.2006.891341
   YOUNG, 2002, HTK BOOK VERSION 3 2
NR 20
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 187
EP 199
DI 10.1007/s11042-010-0465-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500015
DA 2024-07-18
ER

PT J
AU Battikh, T
   Jabri, I
AF Battikh, Tahar
   Jabri, Imed
TI Camera calibration using court models for real-time augmenting soccer
   scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sport video processing; Camera calibration; Pose estimation; Model-based
   video analysis; Computer vision; KLT; Hough transform
AB In this paper, we present a procedure to estimate the position, orientation and focal length of a camera in a soccer field. These parameters are then used in real-time overlay of graphics on a soccer pitch. The method uses court model composed by arcs and lines. A means of automatically initializing the tracking process is also presented which uses Hough transform with a combination of a non-linear least squares optimization method. For the tracking of camera parameters, two cases arise: the center of the pitch and the 18 m area. A combination of automatic court model recognition with the Kanade-Lucas-Tomasi (KLT) algorithm is also used.
C1 [Battikh, Tahar; Jabri, Imed] Ecole Super Sci & Tech Tunis, Tunis, Tunisia.
C3 Universite de Tunis
RP Jabri, I (corresponding author), Ecole Super Sci & Tech Tunis, Tunis, Tunisia.
EM btahar@yahoo.com; imedjabri@yahoo.com
CR Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   EKIN A, 2003, SPIE STORAGE RETRIEV, V4, P339
   Farin D., 2004, SPIE STORAGE RETRIEV
   GONG Y, 1995, 2 AS C COMP VIS DEC, V2, P509
   Kim H, 2001, PATTERN ANAL APPL, V4, P9, DOI 10.1007/s100440170020
   LETROTER A, 2005, SIPS
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Slama C.C., 1980, MANUAL PHOTOGRAMMETR, Vfourth
   Thomas G. A., 2006, CVMP
   Tomasi C, 1991, DETECTION TRACKING P
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
NR 12
TC 12
Z9 13
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2011
VL 51
IS 3
BP 997
EP 1011
DI 10.1007/s11042-009-0434-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 717XL
UT WOS:000287081100008
DA 2024-07-18
ER

PT J
AU Luo, JB
   Joshi, D
   Yu, J
   Gallagher, A
AF Luo, Jiebo
   Joshi, Dhiraj
   Yu, Jie
   Gallagher, Andrew
TI Geotagging in multimedia and computer vision-a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geotagging; GPS; Multimedia; Context; Location; Recognition
ID WORLD
AB Geo-tagging is a fast-emerging trend in digital photography and community photo sharing. The presence of geographically relevant metadata with images and videos has opened up interesting research avenues within the multimedia and computer vision domains. In this paper, we survey geo-tagging related research within the context of multimedia and along three dimensions: (1) Modalities in which geographical information can be extracted, (2) Applications that can benefit from the use of geographical information, and (3) The interplay between modalities and applications. Our survey will introduce research problems and discuss significant approaches. We will discuss the nature of different modalities and lay out factors that are expected to govern the choices with respect to multimedia and vision applications. Finally, we discuss future research directions in this field.
C1 [Luo, Jiebo; Joshi, Dhiraj; Yu, Jie; Gallagher, Andrew] Eastman Kodak Co, Kodak Res Labs, Rochester, NY 14650 USA.
C3 Eastman Kodak
RP Joshi, D (corresponding author), Eastman Kodak Co, Kodak Res Labs, Rochester, NY 14650 USA.
EM dhiraj.joshi@kodak.com
RI Luo, Jiebo/AAI-7549-2020
OI Luo, Jiebo/0000-0002-4516-9729
CR Agarwal Sameer, 2009, P ICCV
   Ahlers D, 2008, P MMM
   Amitay E., 2004, P ACM SIGIR C RES DE
   [Anonymous], 2007, P SIGCHI C HUM FACT
   [Anonymous], P IEEE INT C MOB DAT
   [Anonymous], P CVPR
   [Anonymous], P CIVR
   [Anonymous], P ECCV
   [Anonymous], P ACM MULT
   [Anonymous], 2007, P IEEE ICCV
   [Anonymous], P CVPR
   [Anonymous], 2009, P WWW
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], P INT WORKSH LOC WEB
   [Anonymous], P ICCV
   [Anonymous], P ACM MULT
   [Anonymous], P SIGIR
   [Anonymous], 2006, P ECCV
   Arslan S, 2009, P ACM MULT
   Arslan S, 2008, P ACM MULT
   Ay SA, 2010, MULTIMEDIA SYST, V16, P105, DOI 10.1007/s00530-009-0177-x
   Backstrom L., 2010, P WWW
   Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002
   Cao L., 2009, P ACM MULT
   Cao L, 2010, P ICASSP
   Cao L, 2008, P IEEE CVPR
   Cao L, 2008, P ACM MULT
   Cham TJ, 2010, P IEEE CVPR
   CHEN L, 2005, P ACM SIGMOD
   Chen W.C., 2009, P ACM MULT
   Chen Y, 2004, IBM J RES DEV, V48, P601, DOI 10.1147/rd.485.0601
   Cristani M, 2008, P IEEE CVPR
   Davis M, 2005, P ACM MULT
   De Silva GC, 2009, P ACM MULT
   Divvala S., 2009, P IEEE CVPR
   Epshtein B, 2007, P 15 ACM INT S ADV G
   Gallagher A, 2009, THESIS
   Gallagher A, 2009, P IEEE WORKSH INT VI
   Goodchild MF, 2007, GEOJOURNAL, V69, P211, DOI 10.1007/s10708-007-9111-y
   Hao Q., 2010, P WWW
   Hao Q, 2009, P ACM MULT
   Hays J., 2008, P IEEE CVPR
   Hinz S, 2003, ISPRS J PHOTOGRAMM, V58, P83, DOI 10.1016/S0924-2716(03)00019-4
   Hinze A, 2003, LECT NOTES COMPUT SC, V2750, P489
   Hsieh C-C, 2008, P ACM MULT
   Jacobs N, 2007, P IEEE ICCV
   Jaffe A., 2006, P ACM MULT INF RETR
   Ji R, 2009, P ACM MULT
   Joshi D, 2010, P IEEE ICASSP
   Joshi D, 2008, P ACM CIVR
   Kalogerakis E., 2009, P IEEE ICCV
   Kaminsky R., 2009, P IEEE WORKSH INT VI
   Kennedy L., 2007, P ACM MULT
   Kennedy L., 2008, P WWW
   Kim SH, 2010, P ACM MULT SYST C
   Kleban J., 2009, P ACM CIVR
   Kosecka J., 2002, P EUR C COMP VIS ECC
   Leung D., 2010, P IEEE CVPR
   Liao L., 2007, Int J Rob Res
   Lothe P, 2010, P CVPR
   Lowe D, 2004, J COMPUT VIS
   Luo J, 2008, P ACM MULT
   Luo JB, 2006, IEEE SIGNAL PROC MAG, V23, P101
   Luo Z, 2010, P MMM
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Moxley E., 2008, P ACM MULT INF RETR
   Naaman M., 2004, P ACM IEEE CS JOINT
   Naaman M, 2005, P ACM IEEE CS JOINT
   O'Hare N, 2007, THESIS
   O'Hare N, 2009, IEEE T MULTIMEDIA
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Park M, 2010, P ACM MULT
   Paucher R, 2010, P IEEE CVPR
   Pavlidis T, 2009, P IEEE ICME
   Pei J, 2004, IEEE T KNOWL DATA EN, V16, P1424, DOI 10.1109/TKDE.2004.77
   Pelekis N., 2009, P ICDM
   Pigeau A, 2005, P ACM MULT
   Popescu A., 2009, P ACM CIVR
   Popescu A, 2009, P CIKM
   Quack T., 2008, P CIVR
   Rattenbury T., 2007, P SIGIR
   Rattenbury T, 2009, ACM T WEB, V3, DOI 10.1145/1462148.1462149
   Sakaki T., 2010, P INT C WWW
   Schaffalitzky Frederik, 2002, P ECCV
   Schiller J., 2004, Location-Based Services
   Schindler G, 2008, P IEEE CVPR
   Schindler G., 2007, P IEEE CVPR
   Simon I., 2008, P ECCV
   Singh V, 2010, P ACM MULT
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Snavely N, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360614
   Szeliski R, 2005, P IEEE ICCV COMP VIS
   Torniai C., 2006, Sharing, Discovering and Browsing Photo Collections through RDF geo-metadata
   Toyama K, 2003, P ACM MULT
   Trinder JC, 1998, DIGIT SIGNAL PROCESS, V8, P215, DOI 10.1006/dspr.1998.0322
   Tsai C-M, 2005, P IEEE ICME
   Tsikrika T, 2009, P ACM CIVR
   Tuytelaars T., 2004, Int J Comput Vis
   Ueda T, 2002, P INT C DAT EXP SYST
   Wei X-Y, 2009, P ACM CIVR
   Wolf L, 2006, INT J COMPUT VISION, V68, P43, DOI 10.1007/s11263-005-4841-0
   Xiaoying Jin, 2005, Information Fusion, V6, P257, DOI 10.1016/j.inffus.2004.06.003
   Yu J, 2008, P ACM CIVR
   Yuan J, 2008, P MULT INF RETR MIR
   Zhang W., 2006, P 3DPVT
   Zheng Vincent W., 2010, P WWW
   Zheng Y, 2009, P MDM
   Zheng Y., 2009, P WWW
   [No title captured]
NR 110
TC 101
Z9 122
U1 1
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 1
BP 187
EP 211
DI 10.1007/s11042-010-0623-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 705BO
UT WOS:000286103800008
DA 2024-07-18
ER

PT J
AU Kawulok, M
AF Kawulok, Michal
TI Energy-based blob analysis for improving precision of skin segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin segmentation; Blob detection; Face detection; Gesture recognition
ID FACE; RECOGNITION; SCALE
AB This paper addresses a problem of precise skin segmentation necessary for sign language recognition purposes. The main contribution of the presented research is an adaptive skin model enhanced with a blob analysis algorithm which significantly reduces false positives and improves skin segmentation precision. Adaptive skin detector utilizes a statistical skin color model updated dynamically based on a face region defined by eye positions. Face geometry is used for face and eye detection in luminance channel prior to the model adaptation. Color-based skin detectors classify every pixel separately which results in high false positives for background pixels which color is similar to human skin. The proposed blob analysis technique verifies detected skin regions by taking into account pixel topology. The experiments for ECU database showed that with the proposed approach false positive rate was reduced from 15.6% to 6% compared with a statistical model in RGB, which can be regarded as a significant improvement.
C1 Silesian Tech Univ, Inst Informat, PL-44100 Gliwice, Poland.
C3 Silesian University of Technology
RP Kawulok, M (corresponding author), Silesian Tech Univ, Inst Informat, Akad 16, PL-44100 Gliwice, Poland.
EM michal.kawulok@polsl.pl
RI Kawulok, Michal/K-9359-2017; Kawulok, Michal/F-6118-2011
OI Kawulok, Michal/0000-0002-3669-5110; 
CR Albiol A, 2001, IEEE IMAGE PROC, P122, DOI 10.1109/ICIP.2001.958968
   [Anonymous], 1991, P 1991 IEEE COMP SOC, DOI DOI 10.1109/CVPR.1991.139758
   Argyros AA, 2004, LECT NOTES COMPUT SC, V3023, P368
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Brand J, 2000, INT C PATT RECOG, P1056, DOI 10.1109/ICPR.2000.905653
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Fang GL, 2004, IEEE T SYST MAN CY A, V34, P305, DOI 10.1109/TSMCA.2004.824852
   FILIPE T, 2003, 8 DIGITAL IMAGE COMP, P419
   Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584
   Forsyth DA, 1999, INT J COMPUT VISION, V32, P63, DOI 10.1023/A:1008145029462
   Fotouhi M, 2009, ICDT: 2009 FOURTH INTERNATIONAL CONFERENCE ON DIGITAL TELECOMMUNICATIONS, P59, DOI 10.1109/ICDT.2009.18
   Fritsch J, 2002, IEEE ROMAN 2002, PROCEEDINGS, P337, DOI 10.1109/ROMAN.2002.1045645
   Gomez G., 2002, Proa, of the ICML Workshop on Machine Learning in Computer Vision, P31
   HAN CC, 1998, P 9 INT C IM AN PROC, P469
   Hernandez-Rebollar JL, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P547, DOI 10.1109/AFGR.2004.1301590
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Ikonen L, 2007, PATTERN RECOGN LETT, V28, P604, DOI 10.1016/j.patrec.2006.10.010
   Imagawa K, 2000, INT C PATT RECOG, P849, DOI 10.1109/ICPR.2000.903050
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kawulok M., 2005, MED INFORM TECHNOLOG, V9, P143
   KAWULOK M, 2009, STUD INFORM, V30, P341
   Kawulok M, 2008, LECT NOTES COMPUT SC, V5099, P112, DOI 10.1007/978-3-540-69905-7_13
   Kovac J, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P144
   Kruppa H., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P109
   Kukharev G., 2004, Machine Graphics & Vision, V13, P377
   Lagodzinski P, 2008, LECT NOTES COMPUT SC, V5197, P626, DOI 10.1007/978-3-540-85920-8_76
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Maio D, 2000, PATTERN RECOGN, V33, P1525, DOI 10.1016/S0031-3203(99)00130-2
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Nurzynska K., 2006, 8 INT WORKSH CAND DO
   Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310
   PHUNG SL, 2003, P IEEE INT C AC SPEE, V3, P353
   Rowley HA, 1996, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.1996.517075
   Sarfraz M, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P233, DOI 10.1109/IV.2005.14
   SORIANO M, 2000, P ICPR 00, V1, P1839
   SUSZCZANSKA N, 2002, P 20 IASTED INT MULT, P282
   Terrillon JC, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P112, DOI 10.1109/AFGR.1998.670934
   TSEKERIDOU S, 1998, P 9 EUR SIGN PROC C, P315
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vogler C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P363, DOI 10.1109/ICCV.1998.710744
   Wang P, 2007, COMPUT VIS IMAGE UND, V105, P99, DOI 10.1016/j.cviu.2006.08.008
   YANG G, 1994, PATTERN RECOGN, V27, P1877
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 46
TC 16
Z9 17
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2010
VL 49
IS 3
SI SI
BP 463
EP 481
DI 10.1007/s11042-009-0444-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 608ZF
UT WOS:000278623800005
DA 2024-07-18
ER

PT J
AU Li, LS
   Mei, T
   Hua, XS
AF Li, Lusong
   Mei, Tao
   Hua, Xian-Sheng
TI GameSense: game-like in-image advertising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic multimedia; Multimedia mashup; Online advertising; Game
AB Considering the continuously increasing availability and accessibility of multimedia contents via social networking sites, our research addresses how to monetize the social multimedia contents with an efficient advertising approach. This paper presents a novel game-like advertising system called GameSense, which is driven by the compelling contents of online images. The contextually relevant ads (i.e., product logos) are embedded at appropriate positions within the online games, which are created on the basis of online images. The ads are selected based on multimodal relevance, i.e. text relevance, user relevance and visual content similarity. The game is able to provide viewers rich experience and thus promotes the embedded ads to provide more effective advertising. GameSense represents one of the first attempts toward effective online mashup applications which connect a photo-sharing site with an advertising agency. The effectiveness of GameSense is evaluated over a large-scale real world image set.
C1 [Li, Lusong] Beihang Univ, State Key Lab Software Dev Environm, Beijing, Peoples R China.
   [Mei, Tao; Hua, Xian-Sheng] Microsoft Res Asia, Beijing, Peoples R China.
C3 Beihang University; Microsoft; Microsoft Research Asia
RP Li, LS (corresponding author), Beihang Univ, State Key Lab Software Dev Environm, Beijing, Peoples R China.
EM lilusong@gmail.com; tmei@microsoft.com; xshua@microsoft.com
RI Mei, Tao/GQZ-0596-2022
OI Mei, Tao/0000-0002-5990-7307
FU National Key Basic Research Program of China [2005CB321901]
FX The authors would like to gratefully acknowledge Geoffry Nordlund,
   Xinmei Tian, Dong Liu, Jing Li and Bo Geng for their valuable comments
   and suggestions to this paper. The authors would also like to
   acknowledge Chris Liu, Wei Ma and Jinlian Guo for their contributions on
   developing the system. This research is supported by the National Key
   Basic Research Program of China (Grant No. 2005CB321901).
CR [Anonymous], P SIGIR
   [Anonymous], 2007, AMSTERDAM
   [Anonymous], 2003, P 11 ACM INT C MULTI, DOI DOI 10.1145/957013.957094
   [Anonymous], 2007, P WWW
   [Anonymous], P WWW
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Chen XR, 2001, LECT NOTES COMPUT SC, V2195, P222
   Dai H. K., 2006, P WWW
   Datta AK, 2008, OPT LASER TECHNOL, V40, P1, DOI 10.1016/j.optlastec.2007.04.006
   He XF, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1230812.1230816
   HUA XS, 2008, WORKSH MULT SIGN PRO
   JOSHI A, 2006, P WORKSH IEEE INT C
   KASTIDOU G, 2006, P EUR C INT TEL
   Kennedy L.S., 2006, P 8 ACM INT WORKSH M
   Lacerda Anisio, 2006, P SIGIR
   LI H, 2007, INT WORKSH DAT MIN A
   Li SZ, 2002, LECT NOTES COMPUT SC, V2353, P67
   LIAO WS, 2008, P ACM SIGIR C RES DE, P767
   Lim J, 2008, MULTIMED TOOLS APPL, V36, P11, DOI 10.1007/s11042-006-0079-2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma, 2008, P ACM MULT, P1051
   McCoy S, 2007, COMMUN ACM, V50, P84, DOI 10.1145/1226736.1226740
   Mehta A, 2007, J ACM, V54, DOI 10.1145/1284320.1284321
   Mei T., 2008, P 16 ACM INT C MULT, P439, DOI [https://doi.org/10.1145/1459359.1459418, DOI 10.1145/1459359.1459418]
   Mei T., 2007, TREC VID RETR EV ONL
   Mei Tao., 2007, Proceedings of the 15th International Conference on Multimedia, P1075
   MURDOCK V, 2007, INT WORKSH DAT MIN A
   PATRALI C, 2003, MARK SCI, V22, P520
   RIBEIRONETO B, 2005, P SIGIR
   TUCHINDA R, 2008, P 13 INT C INT US
   Yang Y., 1999, P SIGIR
   Yih W., 2006, P WWW
NR 32
TC 4
Z9 5
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 1
SI SI
BP 145
EP 166
DI 10.1007/s11042-009-0399-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 595WF
UT WOS:000277643600008
DA 2024-07-18
ER

PT J
AU Sevil, SG
   Kucuktunc, O
   Duygulu, P
   Can, F
AF Sevil, Sare Gul
   Kucuktunc, Onur
   Duygulu, Pinar
   Can, Fazli
TI Automatic tag expansion using visual similarity for photo sharing
   websites
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tagging; Photo-annotation; Visual similarity; Folksonomy; Flickr
ID IMAGE RETRIEVAL
AB In this paper we present an automatic photo tag expansion method designed for photo sharing websites. The purpose of the method is to suggest tags that are relevant to the visual content of a given photo at upload time. Both textual and visual cues are used in the process of tag expansion. When a photo is to be uploaded, the system asks for a couple of initial tags from the user. The initial tags are used to retrieve relevant photos together with their tags. These photos are assumed to be potentially content related to the uploaded target photo. The tag sets of the relevant photos are used to form the candidate tag list, and visual similarities between the target photo and relevant photos are used to give weights to these candidate tags. Tags with the highest weights are suggested to the user. The method is applied on Flickr ( http://www.flickr.com). Results show that including visual information in the process of photo tagging increases accuracy with respect to text-based methods.
C1 [Sevil, Sare Gul; Kucuktunc, Onur; Duygulu, Pinar; Can, Fazli] Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
C3 Ihsan Dogramaci Bilkent University
RP Sevil, SG (corresponding author), Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
EM sareg@cs.bilkent.edu.tr; onurk@cs.bilkent.edu.tr;
   duygulu@cs.bilkent.edu.tr; canf@cs.bilkent.edu.tr
RI Duygulu, Pinar/IZP-7770-2023; Duygulu, Pinar/N-2707-2013; Can,
   Fazli/HHS-8385-2022
OI Duygulu, Pinar/0000-0002-6420-2838; 
FU TUBITAK [104E065]
FX We thank Muhammet Bastan for preparing MPEG-7 visual feature extractor,
   and all the users participated in the user-study. This research is
   partially supported by TUBITAK Career grant number 104E065.
CR [Anonymous], 2008, P 17 INT C WORLD WID
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   BYDE A, 2007, P INT C WEBL SOC MED
   Carneiro G, 2005, PROC CVPR IEEE, P163
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Jäschke R, 2008, AI COMMUN, V21, P231, DOI 10.3233/AIC-2008-0438
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Kucuktunc O, 2008, LECT NOTES COMPUT SC, V5392, P61, DOI 10.1007/978-3-540-92235-3_7
   Lavrenko V., 2003, NIPS
   Lazarinis F, 2007, J AM SOC INF SCI TEC, V58, P1645, DOI 10.1002/asi.20648
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   LI X, 2009, IEEE T MULT IN PRESS
   LINDSTAEDT S, 2009, MULTIMEDIA TOOLS APP, V42
   Liu WY, 2001, HUMAN-COMPUTER INTERACTION - INTERACT'01, P326
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LUX M, 2008, P KNOWL ACQ SOC WEB
   MARLOW C, 2006, P 17 C HYP HYP OD DE
   MARON O, 1998, P 15 INT C MACH LEAR, P341
   MARTINEZ JM, 2001, N4031 ISOIEC JTC1SC2
   MISHNE G, 2008, P 15 INT C WORLD WID
   Monay F., 2004, P 12 ANN ACM INT C M, P348, DOI [10.1145/1027527.1027608, DOI 10.1145/1027527.1027608]
   Mori Y., 1999, MISRM
   Pan JY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1987, DOI 10.1109/ICME.2004.1394652
   QUACK T, 2008, P ACM INT C IM VID R
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   *TU MUNCH I INT CI, 2001, MPEG 7 XM SOFTW
   Wang CH, 2008, MULTIMEDIA SYST, V14, P205, DOI 10.1007/s00530-008-0128-y
   WANG G, 2009, P 19 INT C PATT REC
   WANG X, 2006, P INT C COMP VIS PAT
   WENYIN L, 2000, P 8 ACM INT C MULT, P479
   XU Z, 2008, P 3 INT C INT WEB AP
NR 37
TC 14
Z9 19
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 1
SI SI
BP 81
EP 99
DI 10.1007/s11042-009-0394-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 595WF
UT WOS:000277643600005
DA 2024-07-18
ER

PT J
AU Adami, N
   Boschetti, A
   Leonardi, R
   Migliorati, P
AF Adami, Nicola
   Boschetti, Alberto
   Leonardi, Riccardo
   Migliorati, Pierangelo
TI Embedded indexing in scalable video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scalable video coding; Low-level descriptors embedding; Midstream
   content access
AB Effective encoding and indexing of audiovisual documents are two key aspects for enhancing the multimedia user experience. In this paper we propose the embedding of low-level content descriptors into a scalable video-coding bitstream by jointly optimizing encoding and indexing performance. This approach provides a new type of bitstream where part of the information is used for both content encoding and content description, allowing the so called "Midstream Content Access". To support this concept, a novel technique based on the appropriate combination of Vector Quantization and Scalable Video Coding has been developed and evaluated. More specifically, the key-pictures of each video Group Of Pictures (GOP) are encoded at a first draft level by using a suitable visual-codebook, while the residual errors are encoded using a conventional approach. The same visual-codebook is also used to encode all the key-pictures of a video shot, where boundaries are dynamically estimated. In this way, the visual-codebook is freely available as an efficient visual descriptor of the considered video shot. Moreover, since a new visual-codebook is introduced every time a new shot is detected, also an implicit temporal segmentation is provided.
C1 [Adami, Nicola; Boschetti, Alberto; Leonardi, Riccardo; Migliorati, Pierangelo] Univ Brescia, DEA, SCL, I-25123 Brescia, Italy.
C3 University of Brescia
RP Adami, N (corresponding author), Univ Brescia, DEA, SCL, Via Branze 38, I-25123 Brescia, Italy.
EM nicola.adami@ing.unibs.it; alberto.boschetti@ing.unibs.it;
   riccardo.leonardi@ing.unibs.it; pierangelo.migliorati@ing.unibs.it
RI Leonardi, Riccardo/F-5666-2010
OI Leonardi, Riccardo/0000-0003-0755-1924; Adami,
   Nicola/0000-0002-8879-9456
CR ADAMI N, 2008, P MMSP 2008, P388
   Adami N, 2007, IEEE T CIRC SYST VID, V17, P1238, DOI 10.1109/TCSVT.2007.906828
   [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], 2012, VECTOR QUANTIZATION
   [Anonymous], 2003, INT C INT C MACH LEA, DOI DOI 10.1016/0026-2714(92)90278-S
   BENINI S, 2006, P INT C IM PROC ICIP
   Burnett I.S., 2006, MPEG 21 BOOK, V1st
   CHANG SF, 2007, P ICASSP 2007 HAW
   Hanjalic A., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P807, DOI 10.1109/ICIP.1999.817234
   IZQUIERDO E, 2005, IST 2001 32795 SCHEM
   MORAND C, 2007, ICIAPW 07, P71, DOI DOI 10.1109/ICIAPW.2007.34
   MORAND C, 2008, P CONT BAS MULT IND, P417, DOI DOI 10.1109/CBMI.2008.4564977
   *NIST, 2008, GUID TRECV 2007 EV S
   PICARD RW, 1994, 295 MIT MED LAB PERC
   Qiu GP, 2004, J VIS COMMUN IMAGE R, V15, P507, DOI 10.1016/j.jvcir.2003.11.002
   Saraceno C, 1998, INT J IMAG SYST TECH, V9, P320, DOI 10.1002/(SICI)1098-1098(1998)9:5<320::AID-IMA2>3.0.CO;2-C
   SCHAEFER G, 2004, P 2004 C COMP VIS PA, P144
   *SMPTE, 2009, 037712009 SMPTE
   SWANSON MD, 1996, SPIE, V2727, P4
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Taubman D.S., 2001, JPEG 2000: Image Compression Fundamentals, Standards and Practice
   Wang HS, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/60971
   ZHANG H, 1997, P IEEE INT C IM PROC, V1, P13
NR 23
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 48
IS 1
SI SI
BP 105
EP 121
DI 10.1007/s11042-009-0356-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 575PM
UT WOS:000276079400007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hakkoymaz, V
AF Hakkoymaz, Veli
TI Multimedia presentation organization and playout management using
   intelligent agents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia retrieval; Presentation organization; Information association
   agents
ID VIDEO DATABASE; WEB; SYSTEMS
AB This paper presents a model for organization, computation and management of automated multimedia presentations based on active multimedia segments retrieved from a multimedia information system as well as the Web. Existing multimedia presentation system is extended in such a way that its content selection component spans from local data resources to the entire Web by use of intelligent agents which associates related multimedia segments. We describe a multimedia presentation authoring environment in which a new heuristic method is introduced based on the multimedia resources selected and organization operators to apply. This method is used for the construction of a presentation graph representing an organized presentation. Once the presentation graph is constructed, we show how to obtain an event-point representation of the presentation graph. Based on event-point representation, three methods are given for playing out the constructed presentations at the presentation terminal. Presentation environments of the end-users are modeled as (i) without any constraint, (ii) with a single constraint, and (iii) with multiple constraints (one constraint for each type of multimedia segments in the organized presentation). In accordance with these limitations (i.e., without violating any of the end-user specified constraints), three methods play out any organized presentation.
C1 Fatih Univ, Dept Comp Engn, Buyukcekmece Istanbul, Turkey.
C3 Fatih University
RP Hakkoymaz, V (corresponding author), Fatih Univ, Dept Comp Engn, Buyukcekmece Istanbul, Turkey.
EM hakkoymaz@fatih.edu.tr
RI Hakkoymaz, Veli/A-1139-2013
OI Hakkoymaz, Veli/0000-0002-3245-4440
CR ABITEBOUL S, 1997, P 6 INT C DAT THEOR
   ABITEBOUL S, 1997, INT J DIGITAL LIBRAR, V1, P1
   ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   [Anonymous], 1968, Introduction to Combinatorial Mathematics
   [Anonymous], ARTIFICIAL INTELLIGE
   [Anonymous], 2008, DCMI metadata terms
   BEERI C, 1990, LOGICAL QUERY LANGUA
   BEIGI M, 1998, SPIE C STOR RETR IM
   Biersack E, 1999, MULTIMEDIA SYST, V7, P70, DOI 10.1007/s005300050112
   Chang SK, 2001, IEEE T KNOWL DATA EN, V13, P112, DOI 10.1109/69.908984
   Chang SK, 1996, IEEE MULTIMEDIA, V3, P18, DOI 10.1109/93.556536
   Chen SC, 2001, IEEE T KNOWL DATA EN, V13, P607, DOI 10.1109/69.940735
   DEMPSEY L, 1996, D LIB MAG        JUL
   Dönderler ME, 2005, MULTIMED TOOLS APPL, V27, P79, DOI 10.1007/s11042-005-2715-7
   Garey M.R., 1979, COMPUTERS INTRACTABI
   Hakkoymaz V, 1999, MULTIMEDIA SYST, V7, P500, DOI 10.1007/s005300050150
   Hakkoymaz V, 1997, MULTIMED TOOLS APPL, V4, P171, DOI 10.1023/A:1009666332261
   Hakkoymaz V, 1997, INT J SOFTW ENG KNOW, V7, P371, DOI 10.1142/S0218194097000229
   HAKKOYMAZ V, 1996, CONSTRAINT DRIVEN ME
   He B, 2007, COMMUN ACM, V50, P95
   HOEPNER P, 1991, NETWORK OPERATING SY
   KNOBLOCK, 1997, MODELING WEB SOURCES
   Kücüktunç O, 2007, IEEE MULTIMEDIA, V14, P83, DOI 10.1109/MMUL.2007.1
   LABROU Y, 1997, CS9703 U MAR
   Little T., 1993, Multimedia System, V1, P87
   LITTLE TDC, 1993, IEEE T KNOWLDATA ENG, V5
   Nekrestyanov IS, 2002, PROGRAM COMPUT SOFT+, V28, P207, DOI 10.1023/A:1016371117213
   NICOLAOU C, 1990, IEEE J SEL AREA COMM, V8, P391, DOI 10.1109/49.53015
   Özsoyoglu G, 2004, ACM T DATABASE SYST, V29, P581, DOI 10.1145/1042046.1042047
   PADHGAM L, 2004, DEV INTELLIGENT AGEN
   PAEPCKE A, 2000, SIGMOD RECORD, V29
   PAYNTER GW, 2005, P 5 ACM IEEE CS JOIN
   Polat F, 2002, ARTIF INTELL REV, V17, P21, DOI 10.1023/A:1015009422110
   Santanchè A, 2007, MULTIMEDIA SYST, V12, P403, DOI 10.1007/s00530-006-0050-0
   STUART S, 1995, D LIB MAGAZINE   JUL
   TILKI B, 2008, DESIGNING MODEL EFFI
   Zhang D, 2000, COMPUT NETW, V33, P449, DOI 10.1016/S1389-1286(00)00056-6
   Zhu X., 2000, Proceedings o fthe 23rdAnnual International ACMSIGIR Conference on Research and Development in Information Retrieval, P288
   [No title captured]
   [No title captured]
NR 40
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 47
IS 3
SI SI
BP 477
EP 505
DI 10.1007/s11042-009-0334-4
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 572BC
UT WOS:000275800200007
DA 2024-07-18
ER

PT J
AU Han, BJ
   Rho, S
   Jun, S
   Hwang, E
AF Han, Byeong-jun
   Rho, Seungmin
   Jun, Sanghoon
   Hwang, Eenjun
TI Music emotion classification and context-based music recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion state transition model; Music information retrieval; Mood;
   Emotion; Classification; Recommendation
AB Context-based music recommendation is one of rapidly emerging applications in the advent of ubiquitous era and requires multidisciplinary efforts including low level feature extraction and music classification, human emotion description and prediction, ontology-based representation and recommendation, and the establishment of connections among them. In this paper, we contributed in three distinctive ways to take into account the idea of context awareness in the music recommendation field. Firstly, we propose a novel emotion state transition model (ESTM) to model human emotional states and their transitions by music. ESTM acts like a bridge between user situation information along with his/her emotion and low-level music features. With ESTM, we can recommend the most appropriate music to the user for transiting to the desired emotional state. Secondly, we present context-based music recommendation (COMUS) ontology for modeling user's musical preferences and context, and for supporting reasoning about the user's desired emotion and preferences. The COMUS is music-dedicated ontology in OWL constructed by incorporating domain-specific classes for music recommendation into the Music Ontology, which includes situation, mood, and musical features. Thirdly, for mapping low-level features to ESTM, we collected various high-dimensional music feature data and applied nonnegative matrix factorization (NMF) for their dimension reduction. We also used support vector machine (SVM) as emotional state transition classifier. We constructed a prototype music recommendation system based on these features and carried out various experiments to measure its performance. We report some of the experimental results.
C1 [Han, Byeong-jun; Jun, Sanghoon; Hwang, Eenjun] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Rho, Seungmin] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.
C3 Korea University; Carnegie Mellon University
RP Hwang, E (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM hbj1147@korea.ac.kr; smrho@andrew.cmu.edu; ysbhjun@korea.ac.kr;
   ehwang04@korea.ac.kr
RI Rho, Seungmin/HTP-6683-2023
FU Korean Government (MOEHRD) [KRF-2007-313-D00758]
FX This work was supported by the Korea Research Foundation Grant funded by
   the Korean Government (MOEHRD). (KRF-2007-313-D00758)
CR Allwein E. L., 2001, Journal of Machine Learning Research, V1, P113, DOI 10.1162/15324430152733133
   [Anonymous], IFIP WG 5 7 WORKSH B
   [Anonymous], 1999, MSRTR9987
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cord M, 2008, COGN TECHNOL, P1, DOI 10.1007/978-3-540-75171-7
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Ellis DPW, 2007, INT CONF ACOUST SPEE, P1429
   Feng Y., 2003, P 26 ANN INT ACM SIG, P375, DOI [DOI 10.1145/860500.860508, 10.1145/860435, DOI 10.1145/860435]
   Feng YZ, 2003, IEEE/WIC INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P235
   HAN B, 2007, ACM MULTIMEDIA, P496
   Holzapfel A, 2008, IEEE T AUDIO SPEECH, V16, P424, DOI 10.1109/TASL.2007.909434
   ISO, Acoustics-normal equal-loudness-level contours. 2003, 226:2003, ICS:13.140 Noise with respect to human beings
   JUN S, 2008, IEEE INT C IN PRESS
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Kalat J.W., 2007, EMOTION
   Klapuri A, 2006, SIGNAL PROCESSING ME
   Krumhansl C. L., 1990, Cognitive foundations of musical pitch
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   MULLER M, 2008, INFORM RETRIEVAL MUS
   OSCAR C, 2006, INT C SEM DIG MED TE
   OSCAR C, 2006, P 5 INT SEM WEB C IS
   PACHET F, 2000, P 6 C CONT BAS MULT
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Rho S, 2008, J SYST SOFTWARE, V81, P1065, DOI 10.1016/j.jss.2007.05.038
   ROBINSON DW, 1956, BRIT J APPL PHYS, V7, P166, DOI 10.1088/0508-3443/7/5/302
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Scherer K.R., 1992, INT REV STUDIES EMOT, V2, P139
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   THAYER RE, 1989, BIPSYCHOLOGY MOOD AR
   Xiao SA, 2005, Proceedings of the 2005 IEEE International Conference on Natural Language Processing and Knowledge Engineering (IEEE NLP-KE'05), P232
   YVES R, 2007, P INT C MUS INF RETR, P417
   YVES R, 2007, ONTOLOGY SPECIFICATI
   Zwicker E., 2013, Psychoacoustics: Facts and Models
NR 36
TC 90
Z9 101
U1 3
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 47
IS 3
SI SI
BP 433
EP 460
DI 10.1007/s11042-009-0332-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 572BC
UT WOS:000275800200005
DA 2024-07-18
ER

PT J
AU Hopfgartner, F
   Urruty, T
   Lopez, P
   Villa, R
   Jose, J
AF Hopfgartner, Frank
   Urruty, Thierry
   Bermejo Lopez, Pablo
   Villa, Robert
   Jose, Joemon M.
TI Simulated evaluation of faceted browsing based on feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video retrieval; Feature selection; Clustering; Log file analysis
AB In this paper we explore the limitations of facet based browsing which uses sub-needs of an information need for querying and organising the search process in video retrieval. The underlying assumption of this approach is that the search effectiveness will be enhanced if such an approach is employed for interactive video retrieval using textual and visual features. We explore the performance bounds of a faceted system by carrying out a simulated user evaluation on TRECVid data sets, and also on the logs of a prior user experiment with the system. We first present a methodology to reduce the dimensionality of features by selecting the most important ones. Then, we discuss the simulated evaluation strategies employed in our evaluation and the effect on the use of both textual and visual features. Facets created by users are simulated by clustering video shots using textual and visual features. The experimental results of our study demonstrate that the faceted browser can potentially improve the search effectiveness.
C1 [Hopfgartner, Frank; Villa, Robert; Jose, Joemon M.] Univ Glasgow, Dept Comp Sci, Glasgow G12 8QQ, Lanark, Scotland.
   [Urruty, Thierry] Univ Lille 1, F-59655 Villeneuve Dascq, France.
   [Bermejo Lopez, Pablo] Univ Castilla La Mancha, Intelligent Syst & Data Min Grp SIMD, Albacete, Spain.
C3 University of Glasgow; Universite de Lille; Universidad de Castilla-La
   Mancha
RP Hopfgartner, F (corresponding author), Univ Glasgow, Dept Comp Sci, Glasgow G12 8QQ, Lanark, Scotland.
EM hopfgarf@dcs.gla.ac.uk; thierry.urruty@lifl.fr; pbermejo@dci.uclm.es;
   villar@dcs.gla.ac.uk; jj@dcs.gla.ac.uk
RI Hopfgartner, Frank/H-4598-2014
OI Hopfgartner, Frank/0000-0003-0380-6088; Jose,
   Joemon/0000-0001-9228-1759; Urruty, Thierry/0000-0003-1339-1920
FU European Commission [FP6-027122-SALERO]; JCCM [PCI08-0048-8577]; MEC
   [TIN2007-67418-C03-01]; FEDER
FX This research was supported by the European Commission under contract
   FP6-027122-SALERO. The third author was supported by the JCCM under
   project (PCI08-0048-8577), MEC under project (TIN2007-67418-C03-01) and
   FEDER funds. It is the view of the authors but not necessarily the view
   of the community.
CR [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], 2008, MM 08 P 16 ACM INT C
   [Anonymous], P 9 ACM SIGMM INT WO
   Bekkerman R., 2005, Automatic categorization of email into folders: Benchmark experiments on Enron and SRI corpora
   Bermejo J.P.P., 2008, INCREMENTAL WRAPPER
   FININ TW, 1989, GUMS GEN USER MODELI, P411
   Flores MJ, 2008, COMPUT ELECTRON AGR, V60, P167, DOI 10.1016/j.compag.2007.08.004
   Forman G., 2003, Journal of Machine Learning Research, V3, P1289, DOI 10.1162/153244303322753670
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Halvey M. J., 2007, P 18 C HYP HYP HT 07, P217, DOI DOI 10.1145/1286240.1286301
   HARPER DJ, 2006, IIIX P 1 INT C INF I, P129
   HERSH W, 2000, 8 TEXT RETR C TREC 8
   HU YJ, 1998, FEATURE EXTRACTION C
   Jain A. K., 1988, Algorithms for Clustering Data, P446
   Kerne A, 2007, CC2007-CREATIVITY AND COGNITION 2007 SEEDING CREATIVITY: TOOLS, MEDIA, AND ENVIRONMENTS, P117
   LARSEN O, 2002, P GEN EV COMP C GECC
   Liu H., 1998, FEATURE EXTRACTION C, V453, DOI 10.1007/978-1-4615-5725-8
   NAKAZATO N, 2002, P ADV VIS INT
   OVER P, 1999, 7 TEXT RETR C TREC 5
   QUINLAN JR, 1986, MACH LEARN, V1, P106
   ROBERTSON SE, 1994, P 3 TEXT RETR C TREC
   RUDINAC S, 2007, SMAP 07, P199
   Shen H.T., 2005, P ACM SIGMOD INT C M, P730
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SPARCKJONES K, 1975, 5266 U COMP LAB BRIT
   URBAN J, 2004, P 2 INT WORKSH AD MU, P3
   URRUTY T, 2008, MIR 08, P313
   van Rijsbergen C. J, 1979, Information Retrieval, V2nd
   VILLA R, 2008, SIGIR 2008, P775
   Webb GI, 2005, MACH LEARN, V58, P5, DOI 10.1007/s10994-005-4258-6
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   WHITE AP, 1994, MACH LEARN, V15, P321, DOI 10.1007/BF00993349
   WHITE R, 2007, ACM SIGIR 2007, P159
NR 33
TC 5
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 47
IS 3
SI SI
BP 631
EP 662
DI 10.1007/s11042-009-0340-6
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 572BC
UT WOS:000275800200013
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Lee, I
   Park, JH
AF Lee, Ivan
   Park, Jong Hyuk
TI A scalable and adaptive video streaming framework over multiple paths
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video; Streaming; Peer-to-peer; Multi-path
ID INTERNET; COMMUNICATION
AB In this paper, we examine the frame loss probabilities for multiple-description coded video transmitted over independent paths. We apply an efficient multiple description coding technique for the analysis, and we investigate the impact of drifting error in terms of the probability of receiving freeze frames for reconstructed video. In order to improve the video delivery, an adaptive video coding scheme by adjusting the length of group-of-pictures is investigated in this paper. In addition, a scalable video streaming framework from client-server, centralized peer-to-peer, and decentralized peer-to-peer network topologies are examined. Analytical and experimental results based on Gilbert model are used to evaluate the performance of the proposed adaptive and scalable video streaming framework.
C1 [Park, Jong Hyuk] Seoul Natl Univ Technol, Dept Comp Sci & Engn, Seoul, South Korea.
   [Lee, Ivan] Univ S Australia, Sch Comp & Informat Engn, Adelaide, SA 5001, Australia.
C3 University of South Australia
RP Park, JH (corresponding author), Seoul Natl Univ Technol, Dept Comp Sci & Engn, Seoul, South Korea.
EM Ivan.Lee@unisa.edu.au; parkjonghyuk1@hotmail.com
RI Lee, Ivan/F-4131-2013
OI Lee, Ivan/0000-0002-2826-6367
FU MKE (Ministry of Knowledge Economy), Korea; ITRC (Information Technology
   Research Center); IITA (Institute of Information Technology Advancement)
   [IITA-2008-C10900801-0020]
FX This research was supported in part by the MKE (Ministry of Knowledge
   Economy), Korea, under the ITRC (Information Technology Research Center)
   Support program supervised by the IITA (Institute of Information
   Technology Advancement) (IITA-2008-C10900801-0020).
CR Chakareski J, 2006, IEEE T MULTIMEDIA, V8, P207, DOI 10.1109/TMM.2005.864284
   CHAKARESKI J, 2005, P IEEE INT C MULT EX, P1529
   Chow ALH, 2005, PERFORM EVALUATION, V62, P417, DOI 10.1016/j.peva.2005.07.029
   CLARK DD, 1990, SEP SIGCOMM S COMM A, P200
   Cui Y, 2004, IEEE J SEL AREA COMM, V22, P91, DOI 10.1109/JSAC.2003.818799
   EFFELSBERG W, 1996, HIGH SPEED NETWORKIN
   Jeon WJ, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA57
   KANAKIA H, 1993, SIGCOMM S COMM ARCH, P20
   Lee I, 2002, GLOB TELECOMM CONF, P539
   LEE I, 2005, P IEEE INT C MULT EX
   LEE I, 2005, P IEEE MULT SIGN PRO, P189
   Lee I, 2008, INTERNATIONAL SYMPOSIUM ON UBIQUITOUS MULTIMEDIA COMPUTING, PROCEEDINGS, P112, DOI 10.1109/UMC.2008.30
   Ling Z, 2006, IEEE INT SYM MULTIM, P399
   NAHRSTEDT K, 1995, COMPUTER, V28, P52, DOI 10.1109/2.384118
   Nguyen TP, 2002, PROC SPIE, V4673, P186
   Roberts J., 1996, BROADBAND NETWORK TE
   ROSU D, 1999, THESIS GEORGIA I TEC
   Steinmetz R, 1996, IEEE J SEL AREA COMM, V14, P61, DOI 10.1109/49.481694
   TRAN DA, 2002, ZIGZAG EFFICIENT PEE
   Wang X, 1999, IEICE T COMMUN, VE82B, P806
   Wu DP, 2001, IEEE T CIRC SYST VID, V11, P282, DOI 10.1109/76.911156
   Wu DP, 2000, IEEE J SEL AREA COMM, V18, P977, DOI 10.1109/49.848251
   Wu F, 2001, IEEE T CIRC SYST VID, V11, P332, DOI 10.1109/76.911159
   YEE JR, 1995, IEEE T COMMUN, V43, P2316, DOI 10.1109/26.403764
NR 24
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2010
VL 47
IS 1
BP 207
EP 224
DI 10.1007/s11042-009-0414-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 554LV
UT WOS:000274437400012
DA 2024-07-18
ER

PT J
AU Chang, SK
   Zhao, L
   Guirguis, S
   Kulkarni, R
AF Chang, Shi-Kuo
   Zhao, Lei
   Guirguis, Shenoda
   Kulkarni, Rohit
TI A computation-oriented multimedia data streams model for content-based
   information retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia data streams model; Multimedia dependency theory; Continuous
   queries; Content-based information retrieval
AB Multimedia applications nowadays are becoming prevalent. In the past the relational database model was generalized to the multimedia database model. More recently the relational database model was generalized to the data streams model, as the technology advanced and data became bulky and unbounded in size due to the utilization of sensor networks. In this paper we take one more step of generalization by providing a multimedia data streams model. The objective is to furnish a formal framework to design multimedia data streams (MMDS) schema for efficient content based information retrieval. We also extend the functional dependency theory and the normalization framework to handle multimedia data streams. Finally we present algorithmic methods of generating continuous multimedia queries along with examples for illustration.
C1 [Chang, Shi-Kuo; Guirguis, Shenoda] Univ Pittsburgh, Dept Comp Sci, Pittsburgh, PA 15260 USA.
   [Zhao, Lei] Soochow Univ, Sch Comp Sci & Technol, Suzhou 215006, Peoples R China.
   [Kulkarni, Rohit] Univ Pittsburgh, Dept Informat Sci, Pittsburgh, PA 15260 USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); University
   of Pittsburgh; Soochow University - China; Pennsylvania Commonwealth
   System of Higher Education (PCSHE); University of Pittsburgh
RP Chang, SK (corresponding author), Univ Pittsburgh, Dept Comp Sci, Pittsburgh, PA 15260 USA.
EM chang@cs.pitt.edu; zhaol@suda.edu.cn; shenoda@cs.pitt.edu;
   rok26@pitt.edu
OI Kulkarni, Rohit/0009-0002-0883-3800
CR Abadi DJ, 2003, VLDB J, V12, P120, DOI 10.1007/s00778-003-0095-z
   ABADI DJ, 2005, DESIGN BOREALIS STRE, P277
   Arasu A, 2006, VLDB J, V15, P121, DOI 10.1007/s00778-004-0147-z
   Arasu A., 2003, SIGMOD 03
   Chang SK, 2004, IEEE T MULTIMEDIA, V6, P687, DOI 10.1109/TMM.2004.834862
   CHANG SK, 2009, INTELLIGENT QUERYING
   CHANG SK, 2007, IEEE T KNOWLEDGE DAT, V19
   CHEN J, 2000, SIGMOD, P379
   Gaber M., 2005, SIGMOD RECORD, V34
   GIRGUIS S, 2008, P 2008 INT C DISTR M, P232
   Jain N, 2008, PROC VLDB ENDOW, V1, P1379, DOI 10.14778/1454159.1454179
   Sharaf MA, 2008, ACM T DATABASE SYST, V33, DOI 10.1145/1331904.1331909
   TATBUL N, 2006, P VLDB C
NR 13
TC 4
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 2-3
SI SI
BP 399
EP 423
DI 10.1007/s11042-009-0372-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 542GF
UT WOS:000273480300011
DA 2024-07-18
ER

PT J
AU Kim, H
   Sakamoto, R
   Kitahara, I
   Toriyama, T
   Kogure, K
AF Kim, Hansung
   Sakamoto, Ryuuki
   Kitahara, Itaru
   Toriyama, Tomoji
   Kogure, Kiyoshi
TI Toward cinematizing our daily lives
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D video system; Cinematized reality; Multiple camera system;
   Cinematographic camera control
AB We introduce a cinematographic video production system to create movie-like attractive footage from our indoor daily life. Since the system is designed for ordinary users in non-studio environments, it is composed of standard hardware components, provides a simple interface, and works in near real-time of 5 similar to 6 frames/sec. The proposed system reconstructs a visual hull from acquired multiple videos and then generates final videos from the model by referring to the camera shots used in film-making. The proposed method utilizes "Reliability" to compensate for errors that may have occurred in non-studio environments and to produce the most natural scene from the reconstructed model. By using a virtual camera control system, even non-experts can easily convert the 3D model to movies that look as if they were created by experienced filmmakers.
C1 [Kim, Hansung] Univ Surrey, Ctr Vis Speech & Signal Proc, Surrey, England.
   [Sakamoto, Ryuuki] Wakayama Univ, Wakayama, Japan.
   [Kitahara, Itaru] Univ Tsukuba, Dept Intelligent Interact Technol, Tsukuba, Ibaraki, Japan.
   [Toriyama, Tomoji] Toyama Prefectural Univ, Imizu, Toyama, Japan.
   [Kogure, Kiyoshi] ATR, Knowledge Sci Labs, Kyoto 6190288, Japan.
C3 University of Surrey; Wakayama University; University of Tsukuba; Toyama
   Prefectural University
RP Kim, H (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Surrey, England.
EM h.kim@surrey.ac.uk; rkskmt@sys.wakayama-u.ac.jp;
   kitahara@iit.tsukuba.ac.jp; toriyama@pu-toyama.ac.jp; kogure@atr.jp
OI Kim, Hansung/0000-0003-4907-0491
FU National Institute of Information and Communications Technology; KAKENHI
   [20700122]; Grants-in-Aid for Scientific Research [20700122] Funding
   Source: KAKEN
FX This research was supported in part by the National Institute of
   Information and Communications Technology and KAKENHI(20700122).
CR Ahn JH, 2006, LECT NOTES COMPUT SC, V4319, P1185
   Allili MS, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P183, DOI 10.1109/CRV.2007.33
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], 1991, Grammar of the film language
   BRESENHAM JE, 1965, IBM SYST J, V4, P25, DOI 10.1147/sj.41.0025
   FABIZ F, 2005, IEEE TANS MULTIMEDIA, V7, P514
   FURHT B, 2008, ENCY MULTIMEDIA, P170
   GELASCA ED, 2006, P CVPR WORKSH, P198
   Grauman K, 2003, PROC CVPR IEEE, P187
   Gross M, 2003, ACM T GRAPHIC, V22, P819, DOI 10.1145/882262.882350
   Guan L., 2007, IEEE C COMPUTER VISI, P1
   Gueziec A, 1995, IEEE T VIS COMPUT GR, V1, P328, DOI 10.1109/2945.485620
   GUILLEMAUT JY, 2007, P 3DIM, P167
   HAN B, 2004, P ACCV
   HE LW, 1996, P 23 ANN C COMP GRAP, P217
   Inoue A, 2004, 2004 INTERNATIONAL SYMPOSIUM ON APPLICATIONS AND THE INTERNET, PROCEEDINGS, P277
   Kanade T, 1997, IEEE MULTIMEDIA, V4, P34, DOI 10.1109/93.580394
   KATZ SD, 2004, CIN MOT FILM DIR WOR
   KIM H, 2007, P ACM MULT, P257
   KIM H, 2006, P 3DPVT
   KIM H, 2007, P ACCV
   Kumar P, 2000, INT C PATT RECOG, P1096, DOI 10.1109/ICPR.2000.905663
   Lee DS, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P973
   LEE JY, 1999, P SPW HOS
   LI M, 2003, P VIS MOD VIS
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Magnor M., 2005, Video-based Rendering
   Matsuyama T, 2004, IEEE T CIRC SYST VID, V14, P357, DOI 10.1109/TCSVT.2004.823396
   Mittal A, 2004, PROC CVPR IEEE, P302
   NOBUHARA S, 2006, P 3DPVT, P264
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   PORIKLI F, 2003, P PETS ICVS
   Ronfard R, 2007, IEEE COMPUT GRAPH, V27, P18, DOI 10.1109/MCG.2007.64
   Sormann M, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P1085
   Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   TAKAI T, 2006, P ISMAR WORKSH
   TENMOKU R, 2007, P ISMAR WORKSH MIX R
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Tuzel O, 2005, IEEE I CONF COMP VIS, P18
   Ueda M, 2004, LECT NOTES COMPUT SC, V3331, P418
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   YAMAZAKI S, 2002, P 13 EUR WORKSH REND, P175
NR 43
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2009
VL 44
IS 1
BP 87
EP 110
DI 10.1007/s11042-009-0274-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 457KJ
UT WOS:000266926600005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, ZG
   Peng, YH
   Yang, Y
AF Liu, Zhao-Guang
   Peng, Yu-Hua
   Yang, Yang
TI An adaptive GOP structure selection for haar-like MCTF encoding based on
   mutual information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Key frame; Mutual information; Motion compensated temporal filtering;
   Group of picture
AB In conventional motion compensated temporal filtering based wavelet coding scheme, where the group of picture structure and low-pass frame position are fixed, variations in motion activities of video sequences are not considered. In this paper, we propose an adaptive group of picture structure selection scheme, which the group of picture size and low-pass frame position are selected based on mutual information. Furthermore, the temporal decomposition process is determined adaptively according to the selected group of picture structure. A large amount of experimental work is carried out to compare the compression performance of proposed method with the conventional motion compensated temporal filtering encoding scheme and adaptive group of picture structure in standard scalable video coding model. The proposed low-pass frame selection can improve the compression quality by about 0.3-0.5 dB comparing to the conventional scheme in video sequences with high motion activities. In the scenes with un-even variation of motion activities, e.g. frequent shot cuts, the proposed adaptive group of picture size can achieve a better compression capability than conventional scheme. When comparing to adaptive group of picture in standard scalable video coding model, the proposed group of picture structure scheme can lead to about 0.2 similar to 0.8 dB improvements in sequences with high motion activities or shot cut.
C1 [Liu, Zhao-Guang] Shandong Econ Univ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
   [Liu, Zhao-Guang; Peng, Yu-Hua; Yang, Yang] Shandong Univ, Sch Informat Sci & Engn, Jinan 250100, Peoples R China.
C3 Shandong University of Finance & Economics; Shandong University
RP Liu, ZG (corresponding author), Shandong Econ Univ, Sch Comp Sci & Technol, 7366 ERHuan DongLu, Jinan 250014, Peoples R China.
EM liuzhg1031@yahoo.com.cn
RI peng, yu/GXW-2071-2022
CR Andreopoulos Y, 2004, SIGNAL PROCESS-IMAGE, V19, P653, DOI 10.1016/j.image.2004.05.007
   BUTZ T, 2001, IEEE INT C IM PROC, V3, P421
   Cerneková Z, 2006, IEEE T CIRC SYST VID, V16, P82, DOI 10.1109/TCSVT.2005.856896
   Chen CY, 2006, IEEE T SIGNAL PROCES, V54, P4004, DOI 10.1109/TSP.2006.880202
   CHEN P, 2004, IEEE T CIRCUITS SYST, V14, P982
   CHEN P, SOFTWARE PACKAGE MC
   CHEN P, 2003, THESIS RENSSELAER PO
   CHENG W, 2003, P 2003 IEEE INT C NE, V2, P1237
   Choi SJ, 1999, IEEE T IMAGE PROCESS, V8, P155, DOI 10.1109/83.743851
   DUBOIS E, 1984, IEEE T COMMUN, V32, P826, DOI 10.1109/TCOM.1984.1096143
   EECKHAUT H, 2005, IEEE DES AUT TEST EU, V3, P14
   Hsiang ST, 2001, SIGNAL PROCESS-IMAGE, V16, P705, DOI 10.1016/S0923-5965(01)00002-9
   Lee J, 2006, IEEE T CIRC SYST VID, V16, P1271, DOI 10.1109/TCSVT.2006.881856
   LEE JW, 1994, IEEE T IMAGE PROCESS, V3, P513, DOI 10.1109/83.334989
   LEONARDI R, 2006, JTC1SC29WG11 ISOIEC
   Li X, 2004, SIGNAL PROCESS-IMAGE, V19, P637, DOI 10.1016/j.image.2004.05.006
   LUO L, 2001, IEEE INT C MULT EXP, P365
   OHM JR, 1994, IEEE T IMAGE PROCESS, V3, P559, DOI 10.1109/83.334985
   Ohm JR, 2005, P IEEE, V93, P42, DOI 10.1109/JPROC.2004.839611
   PARK GH, 2005, IMPROVE SVC CODING E
   PARK GH, 2005, ISOIECJTC1SC29WG11MP
   PARK MW, 2007, IEICE T COMMUNICA B2, V90
   Pesquet-Popescu B, 2001, INT CONF ACOUST SPEE, P1793, DOI 10.1109/ICASSP.2001.941289
   Secker A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P1029, DOI 10.1109/ICIP.2001.958672
   Song H, 1999, SIGNAL PROCESS-IMAGE, V15, P127, DOI 10.1016/S0923-5965(99)00027-2
   Tillier C, 2006, IEEE T IMAGE PROCESS, V15, P2545, DOI 10.1109/tip.2006.877411
   Turaga DS, 2005, SIGNAL PROCESS-IMAGE, V20, P1, DOI 10.1016/j.image.2004.08.006
   Wang LM, 2000, SIGNAL PROCESS-IMAGE, V15, P493, DOI 10.1016/S0923-5965(99)00009-0
   Wang YH, 2006, IEEE T CIRC SYST VID, V16, P166, DOI 10.1109/TCSVT.2005.861940
   Wang YL, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P293
NR 30
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2009
VL 43
IS 1
BP 25
EP 43
DI 10.1007/s11042-008-0255-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 425HF
UT WOS:000264626900002
DA 2024-07-18
ER

PT J
AU Poon, HT
   Miri, A
   Zhao, JY
AF Poon, Hoi Ting
   Miri, Ali
   Zhao, Jiying
TI An improved watermarking technique for multi-user, multi-right
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Joint ownership; Secret sharing; Digital rights management
ID AUTHENTICATION
AB In digital rights management, there are many instances where there is more than one user involved, with each user having different level of rights. In this paper, we develop a novel approach to the multi-user, multi-right problem, where users are tied to various rights in an arbitrary access structure. Our approach is applicable to all kinds of media and can be used with any watermarking algorithm, provided that keys are used to generate the watermarks. This flexibility also enables it to benefit from future progress in the development of watermarking algorithms, in particular that of multiple watermarking. The proposed technique uses the generalized secret sharing scheme of Benaloh and Leichter, and builds on the earlier work of Guo on the joint ownership problem. By noting that the number of rights is likely much smaller than the number of users in most practical situations, and by generating the watermarks independently, the proposed approach achieves greater fidelity and detection capability than Guo's schemes while remaining secure against colluding users.
C1 [Poon, Hoi Ting; Miri, Ali; Zhao, Jiying] Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON, Canada.
C3 University of Ottawa
RP Miri, A (corresponding author), Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON, Canada.
EM hpoon015@site.uottawa.ca; samiri@site.uottawa.ca; jyzhao@site.uottawa.ca
CR Barreto PSLM, 2002, IEE P-VIS IMAGE SIGN, V149, P57, DOI 10.1049/ip-vis:20020168
   BENADA O, 1988, J APICULT RES, V27, P35, DOI 10.1080/00218839.1988.11100779
   Cox I., 2001, Digital Watermarking
   Cox I. J., 1996, Information Hiding. First International Workshop Proceedings, P185
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Gui GF, 2006, IEEE INT SYMP CIRC S, P5756
   Gui GF, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2178293
   GUO H, 2002, ACM MULTIMEDIA, P362
   Guo HP, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P497
   Guo HP, 2003, MULTIMEDIA SYST, V9, P249, DOI 10.1007/s00530-003-0096-1
   Ito M., 1987, PROC IEEE GLOB TELEC, P99
   Jackson WA, 1997, J CRYPTOL, V10, P261, DOI 10.1007/s001459900031
   JACKSON WA, 1995, INT C THEOR APPL CRY, P183
   Li CT, 2004, IEE P-VIS IMAGE SIGN, V151, P460, DOI 10.1049/ip-vis:20040812
   Li QM, 2004, LECT NOTES COMPUT SC, V2939, P558
   Mintzer F, 1999, INT CONF ACOUST SPEE, P2067, DOI 10.1109/ICASSP.1999.758338
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Raval MS, 2003, TENCON IEEE REGION, P935
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   SHEPPARD NP, 2001, WORKSH SEC MULT ACM, P3
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Wu YD, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P985
   ZHANG L, 2007, PAC RIM C MULT 2007, P377
   Zhang YQ, 2005, 2005 International Conference on Cyberworlds, Proceedings, P109
   Zheng D, 2003, IEEE T CIRC SYST VID, V13, P753, DOI 10.1109/TCSVT.2003.815959
NR 25
TC 3
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2009
VL 42
IS 2
BP 161
EP 181
DI 10.1007/s11042-008-0232-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 415EY
UT WOS:000263918300002
DA 2024-07-18
ER

PT J
AU Gao, Y
   Chen, JZ
   Yu, SS
   Zhou, JL
   Po, LM
AF Gao, Yi
   Chen, Jiazhong
   Yu, Shengsheng
   Zhou, Jingli
   Po, Lai-Man
TI The training of Karhunen-LoSve transform matrix and its application for
   H.264 intra coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Karhunen-Loeve transform; Discrete cosine transform; Intra coding;
   H.264/AVC
ID IMAGE COMPRESSION; LOEVE TRANSFORM; PREDICTION; STANDARD; FILTER
AB In H.264/AVC, 4 x 4 discrete cosine transform (DCT) is performed on the residual signals after intra prediction for decorrelation. Actually, residual blocks with different prediction modes exhibit different frequency characteristics. Therefore, the fixed transform matrix cannot match the energetic distribution of residual signals very well, which degrades the decorrelation performance. Fortunately, the energetic distributions of residual blocks with the same mode are relatively coincident, which makes it possible to train a universally good Karhunen-LoSve transform (KLT) matrix for each mode. In this paper, an optimal frequency matching (OFM) algorithm is proposed to train KLT matrices for residual blocks and nine KLT matrices corresponding to nine prediction modes of 4 x 4 intra blocks are trained. Experimental results show that KLT with trained matrices yields a persistent gain over H.264 using 4 x 4 DCT with an average peak signal-to-noise ratio (PSNR) enhancement of 0.22dB and a maximum enhancement of 0.33dB.
C1 [Gao, Yi; Chen, Jiazhong; Yu, Shengsheng; Zhou, Jingli] Huazhong Univ Sci & Technol, Dept Comp Sci, Wuhan 430074, Peoples R China.
   [Po, Lai-Man] City Univ Hong Kong, Dept Elect Engn, Kowloon 999077, Hong Kong, Peoples R China.
C3 Huazhong University of Science & Technology; City University of Hong
   Kong
RP Yu, SS (corresponding author), Huazhong Univ Sci & Technol, Dept Comp Sci, Wuhan 430074, Peoples R China.
EM ssyu@mail.hust.edu.cn; eelmpo@cityu.edu.hk
RI Yu, Sheng-Sheng/AAE-4862-2022
OI Yu, Sheng-Sheng/0000-0003-1304-5630
CR [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   Chen JZ, 2006, MULTIMED TOOLS APPL, V29, P175, DOI 10.1007/s11042-006-0006-6
   Effros M, 1999, IEEE T IMAGE PROCESS, V8, P1317, DOI 10.1109/83.791958
   Effros M, 2004, IEEE T INFORM THEORY, V50, P1605, DOI 10.1109/TIT.2004.831787
   Feng HY, 2002, IEEE T IMAGE PROCESS, V11, P113, DOI 10.1109/83.982819
   Gaydecki P, 2001, MEAS SCI TECHNOL, V12, P82, DOI 10.1088/0957-0233/12/1/311
   HALBACH T, 2002, PERFORMANCE COMP H 2
   He ZH, 2007, IEEE T IMAGE PROCESS, V16, P1741, DOI 10.1109/TIP.2007.896599
   Jia J, 2007, IEICE T INF SYST, VE90D, P1709, DOI 10.1093/ietisy/e90-d.10.1709
   Lee YL, 2006, ETRI J, V28, P668, DOI 10.4218/etrij.06.0206.0095
   Marpe D, 2006, IEEE COMMUN MAG, V44, P134, DOI 10.1109/MCOM.2006.1678121
   MARTINELLI G, 1993, IEEE T SIGNAL PROCES, V41, P1737, DOI 10.1109/78.212760
   Páta P, 2006, 2006 IEEE International Symposium on Signal Processing and Information Technology, Vols 1 and 2, P332, DOI 10.1109/ISSPIT.2006.270821
   Penna B, 2007, IEEE GEOSCI REMOTE S, V4, P664, DOI 10.1109/LGRS.2007.903976
   Saghizadeh P, 1998, IEEE T SIGNAL PROCES, V46, P1544, DOI 10.1109/78.678467
   SICORA T, 1997, IEEE T CIRCUITS SYST, V7, P19, DOI DOI 10.1109/76.554415
   Suh K, 2005, ETRI J, V27, P511, DOI 10.4218/etrij.05.0905.0032
   Tsai AC, 2008, IEEE T CIRC SYST VID, V18, P694, DOI 10.1109/TCSVT.2008.919113
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   2005, ADAPTIVE QUANTIZATIO
NR 20
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2009
VL 41
IS 1
BP 111
EP 123
DI 10.1007/s11042-008-0221-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 387LJ
UT WOS:000261953400005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lavee, G
   Khan, L
   Thuraisingham, B
AF Lavee, Gal
   Khan, Latifur
   Thuraisingham, Bhavani
TI A framework for a video analysis tool for suspicious event detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video analysts; semantic gap; surveillance video; unusual event; event
   detection; event classification; event understanding
ID MODEL
AB This paper proposes a framework to aid video analysts in detecting suspicious activity within the tremendous amounts of video data that exists in today's world of omnipresent surveillance video. Ideas and techniques for closing the semantic gap between low-level machine readable features of video data and high-level events seen by a human observer are discussed. An evaluation of the event classification and detection technique is presented and a future experiment to refine this technique is proposed. These experiments are used as a lead to a discussion on the most optimal machine learning algorithm to learn the event representation scheme proposed in this paper.
C1 Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.
   Univ Texas, Richardson, TX 75080 USA.
C3 Technion Israel Institute of Technology; University of Texas System;
   University of Texas Dallas
RP Lavee, G (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.
EM gallavee@cs.technion.ac.il; lkhan@utdallas.edu;
   bhavani.thuraisingham@utdallas.edu
OI Khan, Latifur/0000-0002-9300-1576
CR [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Atluri V, 2004, IEEE T DEPEND SECURE, V1, P238, DOI 10.1109/TDSC.2004.32
   Bertino E, 2003, ACM T INFORM SYST, V21, P155, DOI 10.1145/763693.763695
   BERTINO E, 2000, C INF KNOWL MAN MCLE
   CHEN T, 2005, INTEL TECHNOL J, V9
   NATICK MA, 1992, MATH WORKS
   RUI Y, 2000, IEEE C COMP VIS PATT
   WANG L, 2007, IN PRESS MULTIMED TO
NR 10
TC 37
Z9 42
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2007
VL 35
IS 1
BP 109
EP 123
DI 10.1007/s11042-007-0117-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 209RY
UT WOS:000249406900006
DA 2024-07-18
ER

PT J
AU Kusmierek, E
   Lu, Y
   Du, DHC
AF Kusmierek, Ewa
   Lu, Yingping
   Du, David H. C.
TI Periodic broadcast with dynamic server selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia; periodic broadcast; dynamic server selection; proxy server;
   video caching
ID VIDEO
AB Service replication is an effective way to address resource requirements and resource availability problem. Dynamic service selection enables clients to choose a server offering the best performance. Proper server selection is especially important for video streaming over the Internet due to its high bandwidth requirements. However, given the length of a typical video transmission, the server priorly selected may no longer be an optimal one for the duration of the entire transmission. More importantly, a server may fail during the transmission of a video. In this paper we examine the possibility of switching to another server during an on-going transmission for Periodic Broadcast schemes. Due to the timing requirements typical for Periodic Broadcast the server switch may cause playback disruptions. We analyze the magnitude of the problem and propose an easy to implement solution. We define the criteria, additional to the bandwidth availability for example, according to which a new server should be selected. The client is also required to delay its playback by the amount of time bounded by the server transmission offset. In addition, we propose an alternative method to ensure uninterrupted playback that relies on proxy caching. Simulation results show that our approach can significantly reduce the likelihood of playback disruptions.
C1 Poznan Supercomputing & Networking Ctr, PL-91704 Poznan, Poland.
   Univ Minnesota, Digital Technol Ctr, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.
C3 Polish Academy of Sciences; Poznan Supercomputing & Networking Center;
   University of Minnesota System; University of Minnesota Twin Cities
RP Kusmierek, E (corresponding author), Poznan Supercomputing & Networking Ctr, PL-91704 Poznan, Poland.
EM kusmiere@man.poznan.pl; lu@cs.umn.edu; du@cs.umn.edu
CR AMINI L, 2003, P IEEE INT C MULT EX, V1, P393
   Carter RL, 1997, IEEE INFOCOM SER, P1014, DOI 10.1109/INFCOM.1997.631117
   DUFFIELD N, 1999, IEEE ACM T NETW  DEC
   EAGER DL, 1998, LECT NOTES COMPUT SC, V1508
   Fei ZM, 1998, IEEE INFOCOM SER, P783, DOI 10.1109/INFCOM.1998.665101
   Fu ZH, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P469
   Fung CW, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P67, DOI 10.1109/MMCS.1999.778141
   GAO L, 1998, P INT WORKSH NETW OP
   HU A, 2001, P IEEE INFOCOM, V1, P508
   Hua K., 1997, PROC SIGCOMM, P89
   JUHN L, 1997, IEEE T BROADCAST, V44
   Juhn LS, 1998, IEEE T BROADCAST, V44, P100, DOI 10.1109/11.713059
   KUSMIEREK E, 2004, 6 INT WORKSH MULT NE
   KUSMIEREK E, 2004, J SYSTEMS SOFTWARE S
   KUSMIEREK E, 2004, PERIODIC BROADCAST D
   Lei Z., 2003, P IEEE INT C MULT EX
   Ma WH, 2002, IEEE T MULTIMEDIA, V4, P539, DOI 10.1109/TMM.2002.806536
   Miao ZR, 2002, IEEE J SEL AREA COMM, V20, P1315, DOI 10.1109/JSAC.2002.802061
   Pâris JF, 1998, IEEE IC COMP COM NET, P690, DOI 10.1109/ICCCN.1998.998831
   Rejaie R, 1999, COMP COMM R, V29, P189, DOI 10.1145/316194.316222
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
   Zhang ZL, 2000, IEEE ACM T NETWORK, V8, P429, DOI 10.1109/90.865072
NR 22
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2007
VL 34
IS 3
BP 267
EP 297
DI 10.1007/s11042-007-0107-x
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 189SJ
UT WOS:000248008500001
DA 2024-07-18
ER

PT J
AU Ardito, C
   Costabile, MF
   De Angeli, A
   Pittarello, F
AF Ardito, C.
   Costabile, M. F.
   De Angeli, A.
   Pittarello, F.
TI Navigation help in 3D worlds: some empirical evidences on use of sound
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE auditory interfaces; experimental evaluations; interaction locus;
   usability; virtual environments
ID VIRTUAL ENVIRONMENTS
AB The concept of Interaction Locus (IL) has been introduced to help the users to orient, navigate, and identify relevant interaction areas in 3D Virtual Environments (VEs). The IL is a multimodal concept: it adds to the 3D visual scene parallel information channels that are perceived by other senses. In particular, the IL emphasizes the role of music as a navigation aid in a VE. This paper reports three user-evaluations of different IL enriched virtual worlds, and in particular of the role of the IL auditory component. Results suggest that audio in 3D plays not only an aesthetic role, which the users greatly appreciate, but also a functional role simplifying navigation and helping the users to recognise scenes in the environment. Such a functional role however is subordinated to a proper understanding of the link between music and virtual space. While these experiments refer to desktop virtual reality environments, their findings are general enough to inform the design of navigational tools for other segments of the mixed reality domain.
C1 Univ Bari, Dipartimento Informat, I-70125 Bari, Italy.
   Univ Manchester, Sch Informat, Manchester M60 1QD, Lancs, England.
   Univ Ca Foscari, Dipartimento Informat, I-30172 Venice, Italy.
C3 Universita degli Studi di Bari Aldo Moro; University of Manchester;
   Universita Ca Foscari Venezia
RP Ardito, C (corresponding author), Univ Bari, Dipartimento Informat, Via Orabona 4, I-70125 Bari, Italy.
EM ardito@di.uniba.it; costabile@di.uniba.it;
   Antonella.De-angeli@manchester.ac.uk; pitt@dsi.unive.it
RI De Angeli, Antonella/AAN-6245-2021; Ardito, Carmelo/AAJ-9697-2020
OI Ardito, Carmelo/0000-0001-8993-9855; Pittarello,
   Fabio/0000-0003-2825-9754; Costabile, Maria/0000-0001-8554-0273
CR [Anonymous], 1998, 9241 ISO
   Blattner M. M., 1989, Human-Computer Interaction, V4, P11, DOI 10.1207/s15327051hci0401_1
   BOWMAN D, 2000, IEEE INT VIRT REAL 2
   BREWSTER SA, 1994, P CHI 94, P173
   Chen JL, 1999, PRESENCE-TELEOP VIRT, V8, P671, DOI 10.1162/105474699566558
   COSTALLI F, 2001, P INT CULT HER INF M
   Dix A.J., 1998, HUMAN COMPUTER INTER, V2nd
   FOGLI D, 2003, 5 INT S HUM COMP INT, P434
   Gabbard J.L., 1997, TAXONOMY USABILITY C
   Gaver W. W., 1989, Human-Computer Interaction, V4, P67, DOI 10.1207/s15327051hci0401_3
   GAVER WW, 1990, HUMAN-COMPUTER INTERACTION : INTERACT 90, P735
   GAVER WW, 1991, CHI 91, P85
   GRASSI P, 1997, P GRASSI WEB SITE
   Kalawsky R., 1993, SCI VIRTUAL REALITY
   KAUR K, 1999, DESIGNING VIRTUAL EN
   Pittarello F., 1998, Virtual Environments '98. Proceedings of the Eurographics Workshop, P162
   Pittarello F., 2003, Universal Access in the Information Society, V2, P189, DOI 10.1007/s10209-003-0044-z
   PITTARELLO F, 2001, P INT CULT HER INF M, V1, P73
   PITTARELLO F, 2001, THESIS
   Stanney KM, 2002, HUM FAC ER, P1
   SUMIKAWA D, 1985, 53656 UCRL LAWR LIV
   SUMIKAWA D, 1986, 92925 UCRL LAWR LIV
   [No title captured]
NR 23
TC 11
Z9 11
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2007
VL 33
IS 2
BP 201
EP 216
DI 10.1007/s11042-006-0060-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 149GB
UT WOS:000245134000005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Karydis, I
   Nanopoulos, A
   Manolopoulos, Y
AF Karydis, Ioannis
   Nanopoulos, Alexandros
   Manolopoulos, Yannis
TI Finding maximum-length repeating patterns in music databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE maximum-length repeating patterns; data mining; theme discovery; music
   databases
AB This paper introduces the problem of discovering maximum-length repeating patterns in music objects. A novel algorithm is presented for the extraction of this kind of patterns from a melody music object. The proposed algorithm discovers all maximum-length repeating patterns using an "aggressive" accession during searching, by avoiding costly repetition frequency calculation and by examining as few as possible repeating patterns in order to reach the maximum-length repeating pattern(s). Detailed experimental results illustrate the significant performance gains due to the proposed algorithm, compared to an existing baseline algorithm.
C1 Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
C3 Aristotle University of Thessaloniki
RP Manolopoulos, Y (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
EM karydis@delab.csd.auth.gr; alex@delab.csd.auth.gr; manolopo@csd.auth.gr
RI Manolopoulos, Yannis/AAI-7767-2020; Karydis, Ioannis/AAM-1645-2021
OI Karydis, Ioannis/0000-0002-9470-2729
CR AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415
   Alghoniemy M., 2000, Proceedings ACM Multimedia 2000, P356, DOI 10.1145/354384.375451
   [Anonymous], P 1998 ACM SIGMOD IN
   Aucouturier JJ, 2002, VIRTUAL, SYNTHETIC, AND ENTERTAINMENT AUDIO, P412
   BAINBRIDGE D, 2001, P 1 ACM IEEE JOINT C, P446, DOI DOI 10.1145/379437.379765
   BARLOW H, 1975, DICT MUSCIAL THEMES
   BARTSCH M, 2001, P 2 ANN INT S MUS IN, P73
   Byrd D, 2002, INFORM PROCESS MANAG, V38, P249, DOI 10.1016/S0306-4573(01)00033-4
   Chavez E., 2002, P LAT AM THEOR INF, P181
   Chen ALP, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P873, DOI 10.1109/ICME.2000.871498
   CHEN HC, 2001, P ACM C INF KNOWL MA, P231
   Chen JCC, 1998, EIGHTH INTERNATIONAL WORKSHOP ON RESEARCH ISSUES IN DATA ENGINEERING - CONTINUOUS-MEDIA DATABASES AND APPLICATIONS, PROCEEDINGS, P139, DOI 10.1109/RIDE.1998.658288
   CHUO TC, 1996, P INT WORKSH MULT DA, P46
   Crawford Tim., 1998, COMPUTING MUSICOLOGY, V11, P73
   DOVEY M, 2001, P 1 ACM IEEE JOINT C, P249
   Durey A., 2001, INT S MUSIC INFORM R, P109
   Francu C, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P889, DOI 10.1109/ICME.2000.871502
   Hamilton J.D., 1994, Time series analysis
   Hsu JL, 2001, IEEE T MULTIMEDIA, V3, P311, DOI 10.1109/6046.944475
   HSU JL, 1998, P ACM INT C INF KNOW
   ILIOPOULOS CS, 2002, P CONV ART INT SIM B, P49
   ILIOPOULOS CS, 2002, P AISB 2002 S AI CRE, P67
   KANG YK, 2001, P 5 E EUR C ADV DAT, P84
   Kassler M., 1966, Perspectives of New Music, V4, P59
   KOH JL, 2001, P 12 C DAT EXP SYST, P221
   Kornstadt A., 1998, Melodic similarity: concepts, procedures, and applications, P231
   Lin CF, 2002, IEEE PHOTONIC TECH L, V14, P3, DOI 10.1109/68.974142
   Meek C., 2001, P 2 ANN INT S MUS IN P 2 ANN INT S MUS IN, P119
   MONGEAU M, 1990, COMPUT HUMANITIES, V24, P161, DOI 10.1007/BF00117340
   Nishimura T., 2001, P ISMIR 2001, P211
   OMAIDIN DS, 2001, P 2 ANN INT S MUS IN, P59
   Park JS, 1997, IEEE T KNOWL DATA EN, V9, P813, DOI 10.1109/69.634757
   PIENIMAKI A, 2002, P 3 INT C MUS INF RE, P25
   PIKRAKIS A, 2002, P 2 INT C MUS ART IN, P133
   Raphael S., 2001, BROOKINGS WHARTON PA, P99, DOI DOI 10.1353/urb.2001.0013
   Rolland P.-Y., 2002, Pattern Detection and Discovery. ESF Exploratory Workshop Proceedings (Lecture Notes in Artificial Intelligence Vol. 2447), P190
   SHIFRIN J, 2002, P 2 ACM IEEE CS JOIN, P295
   Smith L., 2001, P 2 ANN INT S MUSIC, P31
   TAKASU A, 1999, 3 EUR C RES ADV TECH, P92
   Uitdenbogerd A, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P57, DOI 10.1145/319463.319470
   VELIVELLI A, 2003, P ACM SIGIR WORKSH M
   Zaki M. J., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P283
   刘海燕, 1999, [新型炭材料, New Carbon Materials], V14, P21
NR 43
TC 10
Z9 11
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2007
VL 32
IS 1
BP 49
EP 71
DI 10.1007/s11042-006-0068-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 119YC
UT WOS:000243049400003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, J
   Chung, JY
AF Zhang, Jia
   Chung, Jen-Yao
TI An open framework supporting multimedia web services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 5th IEEE International Symposium on Multimedia Software Engineeting
CY DEC 10-12, 2003
CL Tai Chung, TAIWAN
SP IEEE Comp Soc, Taichung Healthcare & Management Univ, Natl Tsing Hua Univ, Natl Cent Univ, Bioinformat Soc Taiwan, Univ Calif Irvine
DE multimedia Web services; service broker; three-tier open environment;
   requirements
AB With the rapid emergence of Web services, more and more Web services are published on the Internet as resources for Web application development. There may exist some relationships among different Web services, such as exact match, plug-in match, and irrelevant. In this paper, we discuss a set of requirements related to multimedia Web services, and propose a three-tier framework to establish an open environment supporting multimedia Web services, while partially implementing the requirements. This paper focuses on the design of the service broker tier that is essential for future Web services-oriented system design and integration and enabling Web services more transparent, interoperable, and fault-tolerate.
C1 No Illinois Univ, Dept Comp Sci, De Kalb, IL 60115 USA.
   IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
C3 Northern Illinois University; International Business Machines (IBM)
RP Zhang, J (corresponding author), No Illinois Univ, Dept Comp Sci, De Kalb, IL 60115 USA.
EM jiazhang@cs.niu.edu; jychung@us.ibm.com
CR ALLMAN M, 2003, ACM SIGMETRICS PERFO, V30, P2
   [Anonymous], 2000, EXTENSIBLE MARKUP LA
   Chen MK, 2003, IEEE MICRO, V23, P26, DOI 10.1109/MM.2003.1261384
   Fielding R., 1997, HYPERTEXT TRANSFER P
   Gao X, 2002, FOURTH INTERNATIONAL SYMPOSIUM ON MULTIMEDIA SOFTWARE ENGINEERING, PROCEEDINGS, P56, DOI 10.1109/MMSE.2002.1181596
   Hong D. W.-K., 2003, International Journal of Network Management, V13, P115, DOI 10.1002/nem.465
   Laurent S.S., 2001, Programming web services with XML- RPC
   Reed DP, 1998, IEEE NETWORK, V12, P69
   Roy J., 2001, IT Professional, V3, P69, DOI 10.1109/6294.977775
   Tsalgatidou A, 2002, DISTRIB PARALLEL DAT, V12, P135, DOI 10.1023/A:1016599017660
   VANDENHEUVEL WJ, 2001, P 6 INT C COOP INF S
   Vinoski S, 2003, IEEE INTERNET COMPUT, V7, P69, DOI 10.1109/MIC.2003.1167342
   Zhang M, 2002, ASIA PAC J CLIN NUTR, V11, P13, DOI 10.1046/j.1440-6047.2002.00259.x
NR 13
TC 6
Z9 6
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2006
VL 30
IS 2
BP 149
EP 164
DI 10.1007/s11042-006-0022-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 082CG
UT WOS:000240363500003
DA 2024-07-18
ER

PT J
AU Peyrard, N
   Bouthemy, P
AF Peyrard, N
   Bouthemy, P
TI Motion-based selection of relevant video segments for video
   summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video segmentation; probabilistic motion modelling; supervised event
   classification
ID MODELS
AB We present a method for motion-based video segmentation and segment classification as a step towards video summarization. The sequential segmentation of the video is performed by detecting changes in the dominant image motion, assumed to be related to camera motion and represented by a 2D affine model. The detection is achieved by analysing the temporal variations of some coefficients of the 2D affine model (robustly) estimated. The obtained video segments supply reasonable temporal units to be further classified. For the second stage, we adopt a statistical representation of the residual motion content of the video scene, relying on the distribution of temporal co-occurrences of local motion-related measurements. Pre-identified classes of dynamic events are learned off-line from a training set of video samples of the genre of interest. Each video segment is then classified according to a Maximum Likelihood criterion. Finally, excerpts of the relevant classes can be selected for video summarization. Experiments regarding the two steps of the method are presented on different video genres leading to very encouraging results while only low-level motion information is considered.
C1 INRA, F-84914 Avignon, France.
   Inst Natl Rech Informat & Automat, IRISA, F-35042 Rennes, France.
C3 INRAE; Universite de Rennes
RP INRA, Domaine St Paul Site Agroparc, F-84914 Avignon, France.
EM nathalie.peyrard@avignon.inra.fr; patrick.bouthemy@irisa.fr
CR ARDIZZONE E, 1996, 3 IEEE INT C IM PROC
   BASSEVILLE M, 1988, AUTOMATICA, V24, P309, DOI 10.1016/0005-1098(88)90073-8
   Boreczky JS, 1996, P SOC PHOTO-OPT INS, V2670, P170, DOI 10.1117/12.234794
   Bouthemy P, 1999, IEEE T CIRC SYST VID, V9, P1030, DOI 10.1109/76.795057
   BRUNO E, 2003, CBMI 2003 RENN SEPT
   CHRISTEL M, 1998, ACM C HUM FACT COMP
   Fablet R, 2002, IEEE T IMAGE PROCESS, V11, P393, DOI 10.1109/TIP.2002.999674
   FABLET R, 2001, IEEE INT C COMP VIS
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   LIU W, 2001, CVPR WORKSH EMP EV M
   MA Y, 2002, 10 ACM INT C MULT JU
   Ma YF, 2003, EURASIP J APPL SIG P, V2003, P199, DOI 10.1155/S1110865703211021
   MENG J, 1996, 4 ACM INT C MULT BOS
   NAM J, 1999, 7 ACM INT C MULT ORL, P53
   ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029
   PEYRARD N, 2003, INT C IM PROC ICIP 2
   PEYRARD N, 2002, BRIT MACH VIS C BMVC
   Rui Y, 2000, PROC CVPR IEEE, P111, DOI 10.1109/CVPR.2000.855807
   SANCHEZ J, 2002, IEEE INT C PATT REC
   Vasconcelos N, 2000, IEEE T IMAGE PROCESS, V9, P3, DOI 10.1109/83.817595
   VERMAAK J, 2002, BRIT MACH VIS C BMVC
   Zelnik-Manor L, 2001, PROC CVPR IEEE, P123
NR 22
TC 9
Z9 10
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2005
VL 26
IS 3
BP 259
EP 276
DI 10.1007/s11042-005-0891-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 942YO
UT WOS:000230319000002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Di Sciascio, E
   Donini, FM
   Mongiello, M
AF Di Sciascio, E
   Donini, FM
   Mongiello, M
TI A logic for SVG documents query and retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st Workshop on Multimedia Semantics
CY NOV 28-29, 2002
CL Milovy, CZECH REPUBLIC
DE Scalable Vector Graphics; retrieval; knowledge representation; spatial
   similarity
ID IMAGE RETRIEVAL; SPATIAL SIMILARITY; PATTERN-RECOGNITION; RELEVANCE
   FEEDBACK; REPRESENTATION; MANAGEMENT; DATABASES; FRAMEWORK; SKETCH
AB We propose a knowledge representation approach to the semantic retrieval by content of graphics described in Scalable Vector Graphics (SVG), the novel XML based W3C approved standard language for describing two-dimensional graphics.
   The approach is based on a description logic devised for the semantic indexing and retrieval of complex objects. We provide a syntax to describe basic shapes, complex objects as compositions of basic ones, and transformations. An extensional semantics, which is compositional, is introduced for defining retrieval, classification, and subsumption services. Algorithms exploiting reasoning services, which are sound with respect to the semantics, are also described.
   Using our logical approach as a formal specification, we implemented a prototype system. A set of experiments, carried out on a testbed of SVG documents to assess the retrieval capabilities of the system, is presented.
C1 Politecn Bari, I-70125 Bari, Italy.
   Univ Tuscia, I-01100 Viterbo, Italy.
C3 Politecnico di Bari; Tuscia University
RP Politecn Bari, Via Re David 200, I-70125 Bari, Italy.
EM disciascio@poliba.it; donini@unitus.it; mongiello@poliba.it
RI Mongiello, Marina/E-8740-2015; Donini, Francesco Maria/E-5286-2010;
   Mongiello, Marina/M-7607-2019
OI Mongiello, Marina/0000-0002-1477-1434; Donini, Francesco
   Maria/0000-0003-0284-9625; Mongiello, Marina/0000-0002-1477-1434; di
   sciascio, eugenio/0000-0002-5484-9945
CR AIELLO M, 2001, LECT NOTES ARTIF INT, V2175, P99
   [Anonymous], 1988, PRINCIPLES DATABASE
   [Anonymous], LECT NOTES ARTIFICIA
   [Anonymous], P INT SPEECH IM UND
   Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3
   ARDIZZONE E, 1997, ARTIFICIAL VISION, P193
   Baader Franz., 1991, Proceedings of the 12th International Joint Conference on Artificial Intelligence. Sydney, Australia, August 24-30, P452
   Bertino E, 1998, MULTIMEDIA SYST, V6, P2, DOI 10.1007/s005300050072
   BOLLMANN P, 1985, SIGIR 85, P213
   BORGIDA A, 1995, IEEE T KNOWL DATA EN, V7, P671, DOI 10.1109/69.469829
   BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X
   Cardoze DE, 1998, ANN IEEE SYMP FOUND, P156, DOI 10.1109/SFCS.1998.743439
   Celentano A, 1998, J ELECTRON IMAGING, V7, P308, DOI 10.1117/1.482646
   Chew LP, 1997, COMP GEOM-THEOR APPL, V7, P113, DOI 10.1016/0925-7721(95)00047-X
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   DELBIMBO A, 1999, VISUAL INFORMATION R
   Di Sciascio E, 2002, PATTERN RECOGN LETT, V23, P1599, DOI 10.1016/S0167-8655(02)00124-1
   Di Sciascio E, 2002, J ARTIF INTELL RES, V16, P209, DOI 10.1613/jair.902
   Di Sciascio E, 1999, J VISUAL LANG COMPUT, V10, P565, DOI 10.1006/jvlc.1999.0145
   Donini F M., 1996, Foundations of Knowledge Representation, P191
   EDELMANN S, 1999, REPRESENTATION RECOG
   El-Kwae EA, 1999, ACM T INFORM SYST, V17, P174, DOI 10.1145/306686.306689
   Fuhr N., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P257, DOI 10.1145/290941.291005
   GUDIVADA VN, 1995, ACM T INFORM SYST, V13, P115, DOI 10.1145/201040.201041
   Gudivada VN, 1998, IEEE T KNOWL DATA EN, V10, P504, DOI 10.1109/69.687982
   Haarslev Volker., 1998, PRINCIPLES KNOWLEDGE, P112
   HACID MS, 1999, P 12 INT S METH INT, P340
   HANG S, 1983, IEEE T PATTERN ANAL, V9, P413
   HARTMAN J, 1996, VRML 2 0 HDB
   Meghini C, 2001, J ACM, V48, P909, DOI 10.1145/502102.502103
   REITER R, 1989, ARTIF INTELL, V41, P125, DOI 10.1016/0004-3702(89)90008-8
   Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621
   SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175
   Straccia U, 2001, J ARTIF INTELL RES, V14, P137, DOI 10.1613/jair.813
   TAGARE HD, 1995, IEEE T PATTERN ANAL, V17, P880, DOI 10.1109/34.406653
   WOODS WA, 1992, COMPUT MATH APPL, V23, P133, DOI 10.1016/0898-1221(92)90139-9
   Yen J., 1991, IJCAI, P472
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 38
TC 7
Z9 7
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2004
VL 24
IS 2
BP 125
EP 153
DI 10.1023/B:MTAP.0000036840.61778.04
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 843OT
UT WOS:000223094200004
DA 2024-07-18
ER

PT J
AU Parvathy, CS
   Jayan, JP
AF Parvathy, C. S.
   Jayan, J. P.
TI Lung cancer prediction in chest CT using an active contour based
   segmentation and 3DCNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lung cancer prediction; Active contour segmentation algorithm; 3DCNN;
   Chest CT images
ID MODEL
AB Uncontrollable growth of cells in the lung tissue is the condition that results in lung cancer. Early screening is ideal for lung cancer detection and treatment to prevent these kinds of disorders. The proposed model performed lung cancer detection through three phases. The Chest CT images are initially preprocessed by applying some preprocessing strategies like image demising and contrast enhancement. Here, General Adversarial Network (GAN) is considered for performing the image denoising process, and adaptive histogram equalization is adapted for the enhancement of image contrast. Then, an active contour algorithm is applied to segment the tumor affected region of the chest CT image. Finally, the detection is done through the 3DCNN model, which categorizes whether a segmented region is affected by lung cancer or not. The proposed lung cancer detection model's effectiveness is estimated with several performance evaluation metrics. Moreover, some recent prior standard works are also considered to prove the effectiveness of the lung cancer detection model. The proposed 3DCNN model attained an accuracy of 98%, a precision of 97.2%, a recall of 98.5%, an error of 2%, a specificity of 97.7% and an NPV of 97.1%. The proposed lung cancer detection approach makes it possible to identify the disease at an early stage and take preventative measures.
C1 [Parvathy, C. S.] Noorul Islam Ctr Higher Educ, Dept Comp Applicat, Kumaracoil 629180, Tamilnadu, India.
   [Jayan, J. P.] Noorul Islam Ctr Higher Educ, Dept Software Engn, Kumaracoil 629180, Tamilnadu, India.
RP Parvathy, CS (corresponding author), Noorul Islam Ctr Higher Educ, Dept Comp Applicat, Kumaracoil 629180, Tamilnadu, India.
EM parvathymca90@gmail.com
RI J P, Jayan/AAM-4997-2021
OI J P, Jayan/0000-0002-9192-8116
CR Acharya UK, 2021, OPTIK, V230, DOI 10.1016/j.ijleo.2021.166273
   Ahmad F, 2023, OPT MEMORY NEURAL, V32, P126, DOI 10.3103/S1060992X23020091
   Al-Hammadi M, 2020, IEEE ACCESS, V8, P192527, DOI 10.1109/ACCESS.2020.3032140
   [Anonymous], Dataset 1
   Bhatia S, 2019, ADV INTELL SYST COMP, V817, P699, DOI 10.1007/978-981-13-1595-4_55
   Bhattacharjee A, 2022, PHYS ENG SCI MED, DOI 10.1007/s13246-022-01150-2
   Chen SK, 2020, IEEE ACCESS, V8, P82819, DOI 10.1109/ACCESS.2020.2988284
   Chen W, 2019, IEEE ACCESS, V7, P75591, DOI 10.1109/ACCESS.2019.2921434
   Doppalapudi S, 2021, INT J MED INFORM, V148, DOI 10.1016/j.ijmedinf.2020.104371
   Heuvelmans MA, 2021, LUNG CANCER, V154, P1, DOI 10.1016/j.lungcan.2021.01.027
   Pham HHN, 2019, AM J PATHOL, V189, P2428, DOI 10.1016/j.ajpath.2019.08.014
   Hu QH, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2020.101792
   Ibrahim DM, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104348
   Karthick S, 2024, NATL ACAD SCI LETT, V47, P279, DOI 10.1007/s40009-023-01353-5
   Lakshmanaprabu SK, 2019, FUTURE GENER COMP SY, V92, P374, DOI 10.1016/j.future.2018.10.009
   Liu H, 2020, J DIGIT IMAGING, V33, P1242, DOI 10.1007/s10278-020-00372-8
   Moitra D, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113564
   Moitra D, 2019, HEALTH INF SCI SYST, V7, DOI 10.1007/s13755-019-0077-1
   Nithila EE, 2019, BIOMED SIGNAL PROCES, V47, P57, DOI 10.1016/j.bspc.2018.08.008
   Perez G, 2020, MED BIOL ENG COMPUT, V58, P1803, DOI 10.1007/s11517-020-02197-7
   Sankar SP, 2017, CURR MED IMAGING REV, V13, P223, DOI 10.2174/1573405612666160617082639
   Shakeel PM, 2019, MEASUREMENT, V145, P702, DOI 10.1016/j.measurement.2019.05.027
   Sori WJ, 2019, MULTIDIM SYST SIGN P, V30, P1749, DOI 10.1007/s11045-018-0626-9
   Stimper V, 2019, IEEE ACCESS, V7, P165437, DOI 10.1109/ACCESS.2019.2952899
   Togaçar M, 2020, BIOCYBERN BIOMED ENG, V40, P23, DOI 10.1016/j.bbe.2019.11.004
   Xiong JF, 2019, IEEE ACCESS, V7, P64583, DOI [10.1109/access.2019.2916557, 10.1109/ACCESS.2019.2916557]
   Zheng SH, 2021, COMPUT METH PROG BIO, V210, DOI 10.1016/j.cmpb.2021.106363
   Zhou YX, 2021, MICROPROCESS MICROSY, V81, DOI 10.1016/j.micpro.2020.103754
NR 28
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 29
PY 2023
DI 10.1007/s11042-023-17792-7
EA DEC 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL1O1
UT WOS:001132108500008
DA 2024-07-18
ER

PT J
AU Wu, ZX
   Yu, JN
   Chen, XH
   Shen, J
   Xie, SM
   Zeng, Y
AF Wu, Zhanxiong
   Yu, Jiangnan
   Chen, Xuanheng
   Shen, Jian
   Xie, Sangma
   Zeng, Yu
TI Structural networks of healthy infants built from dMRI images smoothed
   with multi-volume nonlocal estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Magnetic resonance imaging; Diffusion weighted imaging; Structural
   connectome; Infant; Brain network
ID DIFFUSION MRI; NOISE; HUBS
AB In vivo revealing how brain subregions are structurally connected during neonatal period via diffusion magnetic resonance imaging (dMRI) is critical for understanding brain development and pediatric mental disorders. However, even if preprocess was performed on dMRI images including denoising, eddy and motion correction, and unring, residual artifacts still affect the construction of brain structural networks. In this study, nonlocal estimation of multispectral magnitudes (NESMA) was extended to further smooth the preprocessed brain dMRI images of 46 healthy infants from the developing Human Connectome Project (dHCP). The proposed method smoothed dMRI images by exploiting similar multispectral diffusion-weighted signal pattern and the signal redundance among 3D patches. After structural connectivity networks were constructed from the smoothed dMRI images, network-level and nodal topological measures were estimated. While characteristic path length remained unchanged, significantly higher global efficiency, average clustering coefficient, and transitivity were observed in the infant structural networks built from NESMA-smoothed dMRI images. Additionally, more brain subregions with clustering coefficient > = 0.035 and local efficiency > = 0.05 were identified. In summary, higher efficiency was observed in the structural connectivity networks of healthy infants. Nonlocal estimation of multispectral diffusion-weighted volumes has nonnegligible effect on topological analysis of infant brain structural networks. The code for this algorithm is publicly available at https://github.com/freedom1979/NESMA-dMRI.
C1 [Wu, Zhanxiong; Yu, Jiangnan; Chen, Xuanheng; Zeng, Yu] Hangzhou Dianzi Univ, Sch Elect & Informat, Hangzhou 310018, Zhejiang, Peoples R China.
   [Shen, Jian] Zhejiang Univ, Affiliated Hosp 1, Neurol Dept, Sch Med, Hangzhou 310003, Zhejiang, Peoples R China.
   [Xie, Sangma] Hangzhou Dianzi Univ, Inst Biomed Engn & Instrumentat, Sch Automat, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University; Zhejiang University; Hangzhou Dianzi
   University
RP Zeng, Y (corresponding author), Hangzhou Dianzi Univ, Sch Elect & Informat, Hangzhou 310018, Zhejiang, Peoples R China.
EM zyu20@hdu.edu.cn
FU Natural Science Foundation of Zhejiang Province [LY20E070005,
   LY17E070007]; National Natural Science Foundation of China [51207038]
FX The research is supported in part by Natural Science Foundation of
   Zhejiang Province (LY20E070005, LY17E070007), National Natural Science
   Foundation of China (51207038).
CR Adamson CL, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61326-2
   Aja-Fernández S, 2008, IEEE T IMAGE PROCESS, V17, P1383, DOI 10.1109/TIP.2008.925382
   Akarca D, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-24430-z
   Arnatkeviciute A, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-24306-2
   Avena-Koenigsberger A, 2018, NAT REV NEUROSCI, V19, P17, DOI 10.1038/nrn.2017.149
   Bastiani M, 2019, NEUROIMAGE, V184, P801, DOI 10.1016/j.neuroimage.2018.09.073
   Bastiani M, 2019, NEUROIMAGE, V185, P750, DOI 10.1016/j.neuroimage.2018.05.064
   Basu S, 2006, LECT NOTES COMPUT SC, V4190, P117
   Bazinet V, 2021, NEUROIMAGE, V243, DOI 10.1016/j.neuroimage.2021.118546
   Ben Hamza A, 2001, LECT NOTES COMPUT SC, V2134, P19
   Benjamini D, 2021, FRONT PHYS-LAUSANNE, V9, DOI [10.3389/fphy.2021.737374, 10.1101/2021.07.06.451291]
   Bhujle HV, 2019, BIOMED SIGNAL PROCES, V47, P252, DOI 10.1016/j.bspc.2018.08.031
   Bouhrara M, 2019, MAGN RESON IMAGING, V55, P133, DOI 10.1016/j.mri.2018.08.011
   Bouhrara M, 2018, J NEUROSCI METH, V309, P121, DOI 10.1016/j.jneumeth.2018.08.018
   Bouhrara M, 2018, J NEUROIMAGING, V28, P640, DOI 10.1111/jon.12537
   Bouhrara M, 2017, IEEE T MED IMAGING, V36, P181, DOI 10.1109/TMI.2016.2601243
   Chen G, 2019, MED IMAGE ANAL, V53, P79, DOI 10.1016/j.media.2019.01.006
   Coupé P, 2010, MED IMAGE ANAL, V14, P483, DOI 10.1016/j.media.2010.03.001
   Daneshvarfard F, 2020, BRAIN STRUCT FUNCT, V225, P2165, DOI 10.1007/s00429-020-02117-3
   Deprez M, 2020, IEEE T MED IMAGING, V39, P1104, DOI 10.1109/TMI.2019.2943565
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Fouladivanda M, 2021, J NEURAL ENG, V18, DOI 10.1088/1741-2552/abfd46
   Irfanoglu MO, 2021, MAGN RESON MED, V85, P2696, DOI 10.1002/mrm.28624
   Kaiser M, 2017, TRENDS COGN SCI, V21, P703, DOI 10.1016/j.tics.2017.05.010
   Khader M, 2017, APPL INTELL, V46, P241, DOI 10.1007/s10489-016-0833-8
   Le Bihan D, 2014, EMBO MOL MED, V6, P569, DOI 10.1002/emmm.201404055
   Liu RW, 2014, MAGN RESON IMAGING, V32, P702, DOI 10.1016/j.mri.2014.03.004
   Ma XD, 2020, NEUROIMAGE, V215, DOI 10.1016/j.neuroimage.2020.116852
   Manjón JV, 2015, MED IMAGE ANAL, V22, P35, DOI 10.1016/j.media.2015.01.004
   Mijalkov M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0228334
   Prohl AK, 2019, FRONT INTEGR NEUROSC, V13, DOI 10.3389/fnint.2019.00024
   Raja R, 2019, NEUROSCI LETT, V694, P198, DOI 10.1016/j.neulet.2018.12.007
   Sahu S, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03681-0
   Smith-Collins APR, 2015, HUM BRAIN MAPP, V36, P2483, DOI 10.1002/hbm.22786
   Srivastava P, 2020, NETW NEUROSCI, V4, P1122, DOI 10.1162/netn_a_00158
   Tong QQ, 2019, MAGN RESON IMAGING, V59, P1, DOI 10.1016/j.mri.2019.02.011
   Tristán-Vega A, 2008, LECT NOTES COMPUT SC, V5242, P27, DOI 10.1007/978-3-540-85990-1_4
   van den Heuvel MI, 2018, DEV COGN NEUROS-NETH, V30, P108, DOI 10.1016/j.dcn.2018.02.001
   van den Heuvel MP, 2013, TRENDS COGN SCI, V17, P683, DOI 10.1016/j.tics.2013.09.012
   Veraart J, 2016, NEUROIMAGE, V142, P384, DOI 10.1016/j.neuroimage.2016.08.016
   Wu ZX, 2019, J NEUROSCI METH, V312, P105, DOI 10.1016/j.jneumeth.2018.11.020
   Yeh FC, 2010, IEEE T MED IMAGING, V29, P1626, DOI 10.1109/TMI.2010.2045126
NR 42
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 28
PY 2023
DI 10.1007/s11042-023-17918-x
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL0A9
UT WOS:001132069200006
OA Bronze
DA 2024-07-18
ER

PT J
AU Dehkordi, MH
   Mashhadi, S
   Farahi, ST
   Noorallahzadeh, MH
AF Dehkordi, Massoud Hadian
   Mashhadi, Samaneh
   Farahi, Seyed Taghi
   Noorallahzadeh, Mohommad Hosein
TI Changeable essential threshold secret image sharing scheme with
   verifiability using bloom filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Secret sharing; Changeable threshold; Essential shareholders; Bloom
   filter; Birkhoff interpolation polynomial
ID STEGANOGRAPHY; LEVEL
AB In threshold secret image sharing schemes (k, n), the secret image S is distributed among n shareholders. To recover the secret image, at least k shareholders must be present during the restoration phase. In the traditional secret image sharing schemes, there is no ability to change the threshold or define a share for essential and non-essential shareholders. In certain circumstances, it may be necessary for certain shareholders to be present during the secret recovery phase and surrender their shares. This requires the use of essential secret sharing schemes. Additionally, if the security policy for the recovery phase changes, the number of shareholders required to be present may change as well, necessitating the use of changeable secret sharing schemes. In this paper, a changeable threshold secret image sharing scheme with the presence of essential shareholders is introduced for the first time. In this scheme, the threshold of essential and non-essential shareholders can be increased or decreased based on the chosen policy. Also, the shares of the shareholders are verified using the Bloom Filter. Tables 7 and 8 outline the advantages and features of the proposed scheme in comparison to other schemes.
C1 [Dehkordi, Massoud Hadian; Mashhadi, Samaneh; Farahi, Seyed Taghi] Iran Univ Sci & Technol Tehran, Sch Math, Cryptog & Data Secur Lab, Tehran 1684613114, Iran.
   [Noorallahzadeh, Mohommad Hosein] Qom Univ, Qom, Iran.
C3 Iran University Science & Technology; University of Qom
RP Farahi, ST (corresponding author), Iran Univ Sci & Technol Tehran, Sch Math, Cryptog & Data Secur Lab, Tehran 1684613114, Iran.
EM mhadian@iust.ac.ir; smashhadi@iust.ac.ir; St_farahi@mathdep.iust.ac.ir;
   hossein.n@chmail.ir
RI mashhadi, samaneh/ISV-0962-2023
OI mashhadi, samaneh/0000-0001-9191-1376; Farahi, Seyed
   Taghi/0000-0001-8414-4439
CR Azza AA, 2020, MULTIMED TOOLS APPL, V79, P21241, DOI 10.1007/s11042-020-08823-8
   Barwick SG, 2005, IEEE T INFORM THEORY, V51, P620, DOI 10.1109/TIT.2004.840857
   BENALOH JC, 1987, LECT NOTES COMPUT SC, V263, P251
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   BLOOM BH, 1970, COMMUN ACM, V13, P422, DOI 10.1145/362686.362692
   Blundo C, 1996, THEOR COMPUT SCI, V165, P407, DOI 10.1016/0304-3975(96)00003-5
   Blundo C., 1994, Advances in Cryptology - CRYPTO '93. 13th Annual International Cryptology Conference Proceedings, P110
   Bose P, 2008, INFORM PROCESS LETT, V108, P210, DOI 10.1016/j.ipl.2008.05.018
   Charnes C., 1997, Information and Communications Security. First International Conference, ICIS '97. Proceedings, P81, DOI 10.1007/BFb0028464
   Chauhan S., 2021, 2021 IEEE 2 INT C EL, P1
   Chen CC, 2017, J INF SECUR APPL, V33, P45, DOI 10.1016/j.jisa.2017.01.006
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Chor B., 1985, 26th Annual Symposium on Foundations of Computer Science (Cat. No.85CH2224-4), P383, DOI 10.1109/SFCS.1985.64
   Christensen K, 2010, INFORM PROCESS LETT, V110, P944, DOI 10.1016/j.ipl.2010.07.024
   Dehkordi MH, 2024, IET IMAGE PROCESS, V18, P1053, DOI 10.1049/ipr2.13006
   Dehkordi MH, 2024, CAAI T INTELL TECHNO, V9, P388, DOI 10.1049/cit2.12271
   Deshmukh M, 2016, INT CON ADV INFO NET, P690, DOI 10.1109/AINA.2016.56
   Desmedt Y, 1997, Tech Rep. ISSE-TR-97-01
   Ding WM, 2018, INT J DIGIT CRIME FO, V10, P120, DOI 10.4018/IJDCF.2018040107
   Feldman P., 1987, 28th Annual Symposium on Foundations of Computer Science (Cat. No.87CH2471-1), P427, DOI 10.1109/SFCS.1987.4
   Garg M, 2023, MULTIMED TOOLS APPL, V82, P6271, DOI 10.1007/s11042-022-13596-3
   Ghebleh M, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10050742
   Gollmann D., 1996, P 1996 CAMBRIDGE WOR, P139
   Guo C, 2020, COMPUT SECUR, V99, DOI 10.1016/j.cose.2020.102021
   Guo C, 2020, J NETW COMPUT APPL, V162, DOI 10.1016/j.jnca.2020.102664
   Guo C, 2020, IEEE INTERNET THINGS, V7, P3104, DOI 10.1109/JIOT.2020.2964412
   Guo C, 2016, MULTIMED TOOLS APPL, V75, P11577, DOI 10.1007/s11042-015-2885-x
   Guo C, 2012, PATTERN RECOGN LETT, V33, P1594, DOI 10.1016/j.patrec.2012.04.010
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Harn L, 2015, INFORM PROCESS LETT, V115, P851, DOI 10.1016/j.ipl.2015.06.014
   Jia XX, 2019, INFORM SCIENCES, V473, P13, DOI 10.1016/j.ins.2018.09.024
   LAIH CS, 1990, LECT NOTES COMPUT SC, V435, P286
   Lalitha RVSS, 2017, LECT NOTE NETW SYST, V5, P261, DOI 10.1007/978-981-10-3226-4_26
   Li M, 2003, Lecture Notes in Computer Science, V3006, P101
   Li P, 2018, SIGNAL PROCESS-IMAGE, V65, P210, DOI 10.1016/j.image.2018.04.002
   Li P, 2016, DIGIT SIGNAL PROCESS, V50, P51, DOI 10.1016/j.dsp.2015.12.004
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1106, DOI 10.1016/j.jvcir.2013.07.005
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Liu YX, 2019, MULTIMED TOOLS APPL, V78, P18653, DOI 10.1007/s11042-019-7205-4
   Liu YX, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1084-7
   Liu YN, 2018, MULTIMED TOOLS APPL, V77, P6017, DOI 10.1007/s11042-017-4512-5
   Martin KM, 1999, AUST COMPUT J, V31, P34
   Martin KM, 1999, COMPUT J, V42, P638, DOI 10.1093/comjnl/42.8.638
   MULLIN JK, 1983, COMMUN ACM, V26, P570, DOI 10.1145/358161.358167
   Nag A, 2020, MULTIMED TOOLS APPL, V79, P16219, DOI 10.1007/s11042-019-07807-7
   Pakniat N, 2014, J VIS COMMUN IMAGE R, V25, P1093, DOI 10.1016/j.jvcir.2014.03.004
   Patra A, 2010, LECT NOTES COMPUT SC, V5973, P74, DOI 10.1007/978-3-642-14496-7_7
   PEDERSEN TP, 1992, LECT NOTES COMPUT SC, V576, P129
   Pilaram H, 2017, SCI IRAN, V24, P1448, DOI 10.24200/sci.2017.4126
   Riemenschneider SD., 1983, Encyclopedia Math Appl, V19, P1984
   Sardar MK, 2020, SIGNAL PROCESS-IMAGE, V87, DOI 10.1016/j.image.2020.115923
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Srinivasu PN, 2022, GAZI U J SCI, V35, P1372, DOI 10.35378/gujs.884880
   Stadler M, 1996, LECT NOTES COMPUT SC, V1070, P190
   Steinfeld R, 2007, IEEE T INFORM THEORY, V53, P2542, DOI 10.1109/TIT.2007.899541
   Steinfeld R, 2006, FINITE FIELDS TH APP, V12, P653, DOI 10.1016/j.ffa.2005.04.007
   Tassa T, 2007, J CRYPTOL, V20, P237, DOI 10.1007/s00145-006-0334-8
   Ulutas M, 2013, J SYST SOFTWARE, V86, P485, DOI 10.1016/j.jss.2012.09.027
   Wang HX, 2008, IEEE T INFORM THEORY, V54, P473, DOI 10.1109/TIT.2007.911179
   Wu Z, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8030448
   Yadav M, 2022, MULTIMED TOOLS APPL, V81, P22677, DOI 10.1007/s11042-021-10625-5
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2015, SIGNAL PROCESS-IMAGE, V31, P1, DOI 10.1016/j.image.2014.11.003
   Yuan LF, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0165512
   Zarepour-Ahmadabadi J, 2016, INFORM SCIENCES, V369, P467, DOI 10.1016/j.ins.2016.07.001
   Zhang ZF, 2012, THEOR COMPUT SCI, V418, P106, DOI 10.1016/j.tcs.2011.09.027
NR 67
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 27
PY 2023
DI 10.1007/s11042-023-17777-6
EA DEC 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DE0M1
UT WOS:001130236200001
DA 2024-07-18
ER

PT J
AU Sun, H
   Qin, XL
   Liu, XJ
AF Sun, Hao
   Qin, Xiaolin
   Liu, Xiaojing
TI Flexible graph-based attention and pooling network for image-text
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Common representation; Graph data; Attention mechanism; Image-text
   retrieval
AB To explore the cross-modal semantic relevance, image-text retrieval has attracted much attention from the research community. The most of prominent models have shown that introducing structured graph information is capable of improving the cross-modal retrieval performance. However, the existing models either only focus on exploiting the structured information within individual modality, or learn specific cross-modal graph-level metric functions which fail to construct a shared semantic subspace for efficient retrieval. In this paper, we propose a graph attention network to transform general structured visual and textual graphs into the shared semantic subspace. Specially, a structured semantic enhancement module is proposed to learn the graph-level relevance information between images and sentences, which is further utilized to promote the cross-modal semantic alignment. And the enhancement module only depends on the structured input information at retrieval stage, which endows our model with the flexibility that processing fragment-level data no matter whether the structured information lacks. Besides, a graph-based pooling network is proposed to transform the fragment-level features to the common cross-modal representations for efficient retrieval. When compared with several state-of-the-art baselines, the experiments show that our model achieves competitive performance on two publicly available datasets Flickr30k and MS-COCO.
C1 [Sun, Hao; Qin, Xiaolin; Liu, Xiaojing] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Qin, XL (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
EM sunhao123@nuaa.edu.cn; qinxcs@nuaa.edu.cn; liuxiaojing@nuaa.edu.cn
FU National Natural Science Foundation of China [61728204, 61802182];
   National Natural Science Foundation of China
FX The research was supported by The National Natural Science Foundation of
   China (grant nos. 61728204, 61802182).
CR Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   [Anonymous], 2011, Torch7: A matlab-like environment for machine learning
   Belghazi MI, 2018, PR MACH LEARN RES, V80
   Cheng ZY, 2024, Arxiv, DOI arXiv:2304.14614
   Cho KYHY, 2014, Arxiv, DOI arXiv:1409.1259
   Cui Y., 2021, P IEEECVF INT C COMP, P8138
   Cui YM, 2021, NEUROCOMPUTING, V432, P300, DOI 10.1016/j.neucom.2020.12.067
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Faghri F, 2018, Arxiv, DOI arXiv:1707.05612
   Ge XR, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5185, DOI 10.1145/3474085.3475634
   Haoran Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P18, DOI 10.1007/978-3-030-58586-0_2
   Hendrycks Dan, 2017, INT C LEARNING REPRE
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang FR, 2019, IEEE T IMAGE PROCESS, V28, P2008, DOI 10.1109/TIP.2018.2882225
   Huang Y., 2017, Instance-aware image and sentence matching with selective multimodal lstm, V1, P2310
   Ji Z, 2019, IEEE I CONF COMP VIS, P5753, DOI 10.1109/ICCV.2019.00585
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kipf TN, 2017, INT C LEARN REPR
   Krishna R, 2016, Arxiv, DOI arXiv:1602.07332
   Lan H, 2022, IEEE SIGNAL PROC LET, V29, P374, DOI 10.1109/LSP.2021.3135825
   Lee K-H, 2018, Stacked cross attention for image-text matching, P201
   Lei Ba J., 2016, arXiv
   Li JT, 2022, AAAI CONF ARTIF INTE, P1323
   Li KP, 2019, IEEE I CONF COMP VIS, P4653, DOI 10.1109/ICCV.2019.00475
   Li YK, 2017, IEEE I CONF COMP VIS, P1270, DOI 10.1109/ICCV.2017.142
   Liang YZ, 2019, IEEE I CONF COMP VIS, P10402, DOI 10.1109/ICCV.2019.01050
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu C., 2020, Graph structured network for image-text matching, P10921
   Liu CX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P3, DOI 10.1145/3343031.3350869
   Liu DF, 2021, AAAI CONF ARTIF INTE, V35, P6101
   Liu DF, 2020, IEEE IJCNN, DOI [10.1145/3334480.3382998, 10.1109/ijcnn48605.2020.9207265]
   Long SQ, 2022, IEEE WINT CONF APPL, P2463, DOI 10.1109/WACV51458.2022.00252
   Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101
   Lu X, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1414, DOI 10.1145/3474085.3475598
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Qu LG, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1104, DOI 10.1145/3404835.3462829
   Qu LG, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1047, DOI 10.1145/3394171.3413961
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tang KH, 2020, PROC CVPR IEEE, P3713, DOI 10.1109/CVPR42600.2020.00377
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Q., 2023, Mustie: multimodal structural transformer for web information extraction, P2405
   Wang Q., 2022, Proc ACM Web Conf, V2022, P1
   Wang SH, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1398, DOI 10.1145/3240508.3240535
   Wang SJ, 2020, IEEE WINT CONF APPL, P1497, DOI 10.1109/WACV45572.2020.9093614
   Wang Y., 2019, arXiv
   Wu J, 2022, IEEE T CIRC SYST VID, V32, P388, DOI 10.1109/TCSVT.2021.3060713
   Wu YL, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2088, DOI 10.1145/3343031.3350940
   Xi Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10938, DOI 10.1109/CVPR42600.2020.01095
   Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330
   Xu ZJ, 2021, ASIA-PAC J CHEM ENG, V16, DOI 10.1002/apj.2605
   Yan L., 2022, Gl-rg: global-local representation granularity for video captioning
   Yan LQ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2220, DOI 10.1109/ICASSP39728.2021.9414517
   Yan LQ, 2020, IEEE INT C INT ROBOT, P5847, DOI 10.1109/IROS45743.2020.9341398
   Yang L, 2023, Mixpave: mix-prompt tuning for few-shot product attribute value extraction
   Yu T, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1146, DOI 10.1145/3404835.3462924
   Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611
   Zhang K, 2022, PROC CVPR IEEE, P15640, DOI 10.1109/CVPR52688.2022.01521
   Zhang Q, 2020, PROC CVPR IEEE, P3533, DOI 10.1109/CVPR42600.2020.00359
NR 61
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 16
PY 2023
DI 10.1007/s11042-023-17798-1
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DE1R9
UT WOS:001130268000004
DA 2024-07-18
ER

PT J
AU Huang, GC
   Wang, XH
   Li, XS
   Wang, YR
AF Huang, Guancheng
   Wang, Xiuhui
   Li, Xuesheng
   Wang, Yaru
TI Spatiotemporal feature enhancement network for action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Action recognition; Temporal modeling; Feature enhancement; Deep
   learning
ID FLOW
AB As a hot topic in the field of computer vision, video action recognition has great application potential, such as intelligent monitoring, data recommendation and virtual reality. However, although convolutional neural network has achieved great success in the field of image classification, it has not ushered in its "AlexNet" moment in the field of action recognition, and temporal modeling is still the key and challenge of video action recognition. Aiming at the problem that spatiotemporal feature can not be fully used in video action recognition, a spatiotemporal feature enhancement network for action recognition is proposed. First of all, we designed a novel temporal feature aggregation module to enhance the short-range temporal features and enhance action related features. Then, we present a grouping convolution superposition module to expand the receptive field of temporal features and improve the learning ability of the network to long-term temporal and spatial features. Finally, experiments are conducted on the public action datasets UCF-101 and HMDB-51, and the experimental results demonstrate that the proposed method in this paper effectively enhances the fusion of spatiotemporal features and achieves high accuracy.
C1 [Huang, Guancheng; Wang, Xiuhui] China Jiliang Univ, Coll Informat Engn, Hangzhou 310018, Peoples R China.
   [Li, Xuesheng; Wang, Yaru] Key Lab Safety Engn & Technol Res Zhejiang Prov, Hangzhou 310027, Peoples R China.
C3 China Jiliang University
RP Wang, XH (corresponding author), China Jiliang Univ, Coll Informat Engn, Hangzhou 310018, Peoples R China.
EM wangxiuhui@cjlu.edu.cn
OI Wang, Xiuhui/0000-0003-1773-9760
FU Key Research and Development Program of Zhejiang Province [2021C03151];
   Key R &D project of Zhejiang Province of China [LY20F020018]; Natural
   Science Foundation of Zhejiang Province of China [LGG21G010001]; Public
   Projects of Zhejiang Province of China
FX This work is supported by the Key R &D project of Zhejiang Province of
   China (No. 2021C03151), the Natural Science Foundation of Zhejiang
   Province of China (No. LY20F020018) and the Public Projects of Zhejiang
   Province of China (No. LGG21G010001).
CR Alkaddour M, 2022, IEEE T AFFECT COMPUT, V13, P2071, DOI 10.1109/TAFFC.2022.3197622
   Anshu Ashish Kumar, 2020, 2020 IEEE 15th International Conference on Industrial and Information Systems (ICIIS), P242, DOI 10.1109/ICIIS51140.2020.9342689
   Cui MM, 2023, IEEE T IMAGE PROCESS, V32, P295, DOI 10.1109/TIP.2022.3228156
   Dobricki Tomislav, 2022, 2022 13th International Conference on Information and Communication Technology Convergence (ICTC), P591, DOI 10.1109/ICTC55196.2022.9952910
   Gangrade S, 2023, 2023 5 INT C ELECT C, P1
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Geng TT, 2022, IEEE T IMAGE PROCESS, V31, P5484, DOI 10.1109/TIP.2022.3196175
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu WM, 2022, IEEE T PATTERN ANAL, V44, P7010, DOI 10.1109/TPAMI.2021.3100277
   Huang Y, 2022, IEEE T MULTIMEDIA, V24, P2273, DOI 10.1109/TMM.2021.3078882
   Jiang BY, 2019, IEEE I CONF COMP VIS, P2000, DOI 10.1109/ICCV.2019.00209
   Khairallah MZ, 2022, IEEE IMAGE PROC, P3521, DOI 10.1109/ICIP46576.2022.9897875
   Khan S, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13148003
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lai YC, 2019, 2019 IEEE 6TH INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND APPLICATIONS (ICIEA), P485, DOI 10.1109/IEA.2019.8715217
   Li Ning, 2022, 2022 IEEE 8th International Conference on Computer and Communications (ICCC), P2151, DOI 10.1109/ICCC56324.2022.10065900
   Li S, 2023, IEEE T PATTERN ANAL, V45, P8477, DOI 10.1109/TPAMI.2023.3238411
   Lin W, 2023, IEEE T IMAGE PROCESS, V32, P2493, DOI 10.1109/TIP.2023.3269228
   Liu J, 2022, IEEE T NEUR NET LEAR, V33, P1609, DOI 10.1109/TNNLS.2020.3043002
   Luo HN, 2022, IEEE T CIRC SYST VID, V32, P3073, DOI 10.1109/TCSVT.2021.3100842
   Luo Y, 2022, 2022 2 INT C COMPUTE, P129
   Miao X, 2022, 2022 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, COMPUTER VISION AND MACHINE LEARNING (ICICML), P245, DOI 10.1109/ICICML57342.2022.10009833
   Nigam N, 2022, IEEE T CIRC SYST VID, V32, P976, DOI 10.1109/TCSVT.2021.3070688
   Owoyemi J, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P1810, DOI 10.1109/ICMA.2017.8016092
   Paing MP, 2023, IEEE ACCESS, V11, P16644, DOI 10.1109/ACCESS.2023.3246730
   Soomro K., 2012, CoRR, V2
   Svecic A, 2023, IEEE T BIO-MED ENG, V70, P1692, DOI 10.1109/TBME.2022.3225261
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wang Fubo, 2022, 2022 International Conference on Cyberworlds (CW), P23, DOI 10.1109/CW55638.2022.00013
   Wang LM, 2021, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR46437.2021.00193
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang MM, 2023, IEEE T PATTERN ANAL, V45, P3347, DOI 10.1109/TPAMI.2022.3173658
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang YC, 2022, IEEE T NEUR NET LEAR, V33, P5332, DOI 10.1109/TNNLS.2021.3070179
   Wang ZW, 2021, PROC CVPR IEEE, P13209, DOI 10.1109/CVPR46437.2021.01301
   Yan R, 2023, IEEE T PATTERN ANAL, V45, P10317, DOI 10.1109/TPAMI.2023.3261659
   Zhang H, 2023, IEEE J-STARS, V16, P1269, DOI 10.1109/JSTARS.2023.3235535
   Zhu Wenming, 2023, 2023 4th International Conference on Computer Vision, Image and Deep Learning (CVIDL), P531, DOI 10.1109/CVIDL58838.2023.10166466
NR 38
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 15
PY 2023
DI 10.1007/s11042-023-17834-0
EA DEC 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3L6
UT WOS:001155145800005
DA 2024-07-18
ER

PT J
AU Gwon, MG
   Kim, W
AF Gwon, Mi-Gyeong
   Kim, Wonjun
TI One-class learning for face anti-spoofing via pseudo-negative sampling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Face anti-spoofing; Pseudo-negative sampling; Siamese architecture;
   Two-stage one-class learning scheme
ID DOMAIN ADAPTATION
AB Face anti-spoofing, which aims to defend against various attacks in face authentication systems, has drawn increasing attention with the advance in biometrics. Although many studies for face anti-spoofing have shown the remarkable performance improvement, they still suffer from a lack of generality, i.e., vulnerability to unknown attacks frequently occurring in real-world scenarios. Recently, the one-class learning approach has emerged as a way to overcome the aforementioned issue thanks to its capability to distinguish unseen forgery types by precisely understanding the subtle pattern of real faces. However, it is quite a difficult problem to determine the accurate decision boundary by only using real facial images. To cope with this limitation, we propose to apply a novel pseudo-negative sampling scheme in one-class learning for face anti-spoofing. More concretely, pseudo-negative samples are generated based on the statistical distribution of real facial samples and utilized as the proxy of fake facial samples to construct the robust decision boundary. The proposed method is designed by following a two-stage unsupervised learning framework. Firstly, the model learns the feature representation of real faces via the Siamese architecture in the pre-training stage. In the fine-tuning stage, pseudo-negative features are randomly sampled at a suitable distance from real facial features in the latent space. These sampled features are then utilized with real facial features to guide the classifier. Since such pseudo-negative features are not limited to specific fake properties, our classifier can effectively learn to distinguish real and fake faces without using any fake facial images during the training. Experimental results on benchmark datasets show that the proposed method is effective for face anti-spoofing even with unseen spoofing attacks, which achieves the state-of-the-art performance on the Replay-Attack dataset, i.e., 94.48% in AUC. The code and model are publicly available at: https://github.com/DCVL-FA/PNS-release.
C1 [Gwon, Mi-Gyeong; Kim, Wonjun] Konkuk Univ, Dept Elect & Elect Engn, Seoul 05029, South Korea.
C3 Konkuk University
RP Kim, W (corresponding author), Konkuk Univ, Dept Elect & Elect Engn, Seoul 05029, South Korea.
EM kmk3942@konkuk.ac.kr; wonjkim@konkuk.ac.kr
RI Kim, Wonjun/JXN-3386-2024
FU Ministry of Science and ICT, South Korea [2020R1F1A1068080]; National
   Research Foundation of Korea (NRF) - Korea government (MSIT)
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.2020R1F1A1068080).
CR Atoum Y, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P319, DOI 10.1109/BTAS.2017.8272713
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Cai RZ, 2022, IEEE T INF FOREN SEC, V17, P1201, DOI 10.1109/TIFS.2022.3158551
   Chen HN, 2019, IEEE ACCESS, V7, P170116, DOI 10.1109/ACCESS.2019.2955383
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Chen XL, 2021, PROC CVPR IEEE, P15745, DOI 10.1109/CVPR46437.2021.01549
   Chingovska I., 2012, 2012 BIOSIG P INT C, P1
   European union agency for cybersecurity, 2022, Publications Office, DOI [10.2824/183066, DOI 10.2824/183066]
   Feng HC, 2020, Arxiv, DOI arXiv:2005.03922
   Feng Jun, 2021, 2021 International Conference on Computer Engineering and Artificial Intelligence (ICCEAI), P295, DOI 10.1109/ICCEAI52939.2021.00059
   George A, 2021, IEEE T INF FOREN SEC, V16, P361, DOI 10.1109/TIFS.2020.3013214
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang HY, 2022, INT CONF ACOUST SPEE, P2939, DOI 10.1109/ICASSP43922.2022.9746716
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jia Y., 2020, P IEEECVF C COMPUTER, P8484, DOI DOI 10.1109/CVPR42600.2020.00851
   Jia YP, 2022, IEEE T INF FOREN SEC, V17, P138, DOI 10.1109/TIFS.2021.3134869
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li HL, 2018, IEEE T INF FOREN SEC, V13, P1794, DOI 10.1109/TIFS.2018.2801312
   Li L, 2019, IEEE T INF FOREN SEC, V14, P2246, DOI 10.1109/TIFS.2019.2895212
   Lim S, 2020, IEEE ACCESS, V8, P201635, DOI 10.1109/ACCESS.2020.3035747
   Liu W, 2021, IEEE Transactions on Cognitive and Developmental Systems
   Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048
   Maatta J, 2011, INT JOINT C BIOM IJC, P1, DOI DOI 10.1109/IJCB.2011.6117510
   Oza P, 2019, IEEE SIGNAL PROC LET, V26, P277, DOI 10.1109/LSP.2018.2889273
   Panwar A, 2021, IEEE INT CONF AUTOMA, DOI 10.1109/FG52635.2021.9667073
   Ramachandra R, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3038924
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Rusia MK, 2023, MULTIMED TOOLS APPL, V82, P1669, DOI 10.1007/s11042-022-13248-6
   Shao R, 2019, PROC CVPR IEEE, P10015, DOI 10.1109/CVPR.2019.01026
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun WY, 2020, IEEE ACCESS, V8, P66553, DOI 10.1109/ACCESS.2020.2985453
   Wang GQ, 2021, IEEE T INF FOREN SEC, V16, P56, DOI 10.1109/TIFS.2020.3002390
   Wang ZZ, 2020, PROC CVPR IEEE, P5041, DOI 10.1109/CVPR42600.2020.00509
   Wang Z, 2022, PROC CVPR IEEE, P4113, DOI 10.1109/CVPR52688.2022.00409
   Xiong F, 2018, INT CONF BIOMETR THE
   Yang J., 2013, 2013 INT C BIOM ICB, P1
   Yu ZT, 2021, IEEE T PATTERN ANAL, V43, P3005, DOI 10.1109/TPAMI.2020.3036338
   Yu ZT, 2020, PROC CVPR IEEE, P5294, DOI 10.1109/CVPR42600.2020.00534
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
   Zitong Yu, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P285, DOI 10.1109/TBIOM.2021.3065526
NR 44
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 8
PY 2023
DI 10.1007/s11042-023-17739-y
EA DEC 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AE1J4
UT WOS:001116691800001
DA 2024-07-18
ER

PT J
AU Shukla, A
   Chourasia, K
   Jain, G
   Venkanna, U
AF Shukla, Anurag
   Chourasia, Kavyansh
   Jain, Gazal
   Venkanna, U.
TI DeepInsight: a CNN-based approach for machine reading comprehension in
   query answering systems and its applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Encoding; Convolutional neural network; Embedding; Attention; Machine
   reading comprehension; Recurrent neural network
AB Understanding and reading an unstructured text to answer queries on it, also called Machine Reading Comprehension (MRC), has been a hot topic amongst researchers worldwide in the past few years. There are many ways in which this problem has been tackled; each one has its perks and pitfalls. MRC is being thought about meticulously because of its various applications which are a pressing need due to ever-increasing data in this modern world. However, no work has been done focusing on the applications of MRC. We propose DeepInsight, an efficient CNN-based machine reading comprehension model inspired by QANet and an assemblage of three case studies. Each case study is about a specific application of DeepInsight, alongside the details of its implementation, results from the analysis, and shortcomings. These case studies can be referred to by developers around the world while building similar applications.The first case study is a fully implemented end-to-end android-based application that can upload documents to a server and receive different queries. Second, a mobile application that can help people with visual impairment to comprehend documents. Third, a video query application that can answer questions posed on video data, using the deep captioning model as a core for this application. DeepInsight has an EM/F1 score of 77.0 / 86.3 and performs better than the present state-of-the-art models while keeping the inference time of 0.535 seconds, justifiable for real-world applications.
C1 [Shukla, Anurag; Chourasia, Kavyansh; Jain, Gazal] IIIT Naya Raipur, Dept Comp Sci & Engn, Naya Raipur, India.
   [Venkanna, U.] Natl Inst Technol Warangal, Warangal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Warangal
RP Venkanna, U (corresponding author), Natl Inst Technol Warangal, Warangal, India.
EM shukla.anurag006@gmail.com; kavyansh.chourasia98@gmail.com;
   gazaljain7523@gmail.com; venkannau@nitw.ac.in
OI u, venkanna/0000-0002-3596-6679
CR Abadi M., 2016, arXiv, DOI DOI 10.48550/ARXIV.1603.04467
   Abobeah R, 2020, IEEE ACCESS, V8, P18097, DOI 10.1109/ACCESS.2020.2967750
   Escorcia V, 2016, LECT NOTES COMPUT SC, V9907, P768, DOI 10.1007/978-3-319-46487-9_47
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gehring J, 2017, PR MACH LEARN RES, V70
   Guadarrama S, 2013, IEEE I CONF COMP VIS, P2712, DOI 10.1109/ICCV.2013.337
   Harris CR, 2020, NATURE, V585, P357, DOI 10.1038/s41586-020-2649-2
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83
   Li HR, 2021, MEMET COMPUT, V13, P1, DOI 10.1007/s12293-021-00328-7
   Li WK, 2018, AAAI CONF ARTIF INTE, P604
   Liu SS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183698
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Riloff E., 2000, A rule-based question answering system for reading comprehension tests, DOI [10.3115/1117595.1117598, DOI 10.3115/1117595.1117598]
   Rohrbach M, 2013, IEEE I CONF COMP VIS, P433, DOI 10.1109/ICCV.2013.61
   Seo M, 2018, Arxiv, DOI arXiv:1611.01603
   Srivastava R.K., 2015, ARXIV
   Sutskever I, 2014, ADV NEUR IN, V27
   Vaswani A, 2017, ADV NEUR IN, V30
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang JW, 2018, PROC CVPR IEEE, P7190, DOI 10.1109/CVPR.2018.00751
   Wang SH, 2016, Arxiv, DOI [arXiv:1608.07905, DOI 10.48550/ARXIV.1608.07905]
   Wang WH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P189, DOI 10.18653/v1/P17-1018
   Yu AW, 2018, Arxiv, DOI arXiv:1804.09541
   Xiao H, 2018, Arxiv, DOI arXiv:1809.01997
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
NR 30
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 2
PY 2023
DI 10.1007/s11042-023-17732-5
EA DEC 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AV0F5
UT WOS:001121103400005
DA 2024-07-18
ER

PT J
AU Rimal, Y
   Sharma, N
AF Rimal, Yagyanath
   Sharma, Navneet
TI Hyperparameter optimization: a comparative machine learning model
   analysis for enhanced heart disease prediction accuracy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Bayesian optimization; Genetic optimization; GAsearchCV optimization;
   Optuna optimization; Gaussian; Random forest; Support vector machine;
   Principal component analysis
AB An optimizer is the process of hyperparameter tuning that updates the machine learning model after each step of weight loss adjustment of input features. The permutation and combination of high and low learning rates with various step sizes ultimately leads to an optimal tuning model. The step size and learning rate sometimes take much smaller steps, allowing the derivatives of tangent to gradually reach global minima. The primary goal of this study is to compare the prediction accuracy of enhanced heart disease using various optimization algorithms. Heart disease treatment requires ensemble hyperparameter tuning for accurate prediction and classification due to multiple feature dependencies. The study analyzed model tuning techniques using the AUC and confusion matrix, revealing improvements in precision, recall, and f1 score from default to optimized models. The Hyper-opt in Bayesian optimizer and T-pot classifiers were used in genetic populations and offspring with 5 and 10 generations, while using Optuna optimization frozen trails was combined with a random forest algorithm. The default random forest (86.6%), Bayesian optimization with random forest (89%), and Bayesian optimization with support vector machines (90%) scored the highest accuracy among all. The generic algorithm with five generations (86.8%) and GAsearchCV with 10 generations (88.5%) scored the second highest accuracy, while Optuna's support vector machine model (84%) scored the least accuracy, respectively. This research further compares the machine learning accuracy, precision, recall, F1 score, macro average, and confusion matrix of each optimized model with their model's actual performance execution time. The predictive accuracy from exploratory data analysis and data pre-processing was further tested after the pipeline design of one-hot encoding and standard scaling of enhanced (31-featured) data sets and heart disease data (13 features). The gaussian algorithm (84%), logistic regression (83%), and classification models predict with higher accuracy than dummy classifiers (54%), when compared with standalone default machine learning models.
C1 [Rimal, Yagyanath; Sharma, Navneet] IIS Univ, Jaipur 302020, Rajasthan, India.
RP Rimal, Y (corresponding author), IIS Univ, Jaipur 302020, Rajasthan, India.
EM rimal.yagya@gmail.com; navneet.sharma@iisuniv.ac.in
OI Rimal, Yagyanath/0000-0003-1045-7728
CR Abdeldjouad F.Z., 2020, ICOST 2020 INT C SMA, P299, DOI DOI 10.1007/978-3-030-51517-1_26
   Al-Azzam N, 2021, ANN MED SURG, V62, P53, DOI 10.1016/j.amsu.2020.12.043
   Biethahn Jorg., 2012, Evolutionary algorithms in management applications
   Christou V., 2022, Heart, V9, P10, DOI [10.1093/eurjpc/zwac056.174, DOI 10.1093/EURJPC/ZWAC056.174]
   El-Hasnony IM, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22031184
   Fitriyani NL, 2020, IEEE ACCESS, V8, P133034, DOI 10.1109/ACCESS.2020.3010511
   Hamdia KM, 2021, NEURAL COMPUT APPL, V33, P1923, DOI 10.1007/s00521-020-05035-x
   HELLER RF, 1984, BMJ-BRIT MED J, V288, P1409, DOI 10.1136/bmj.288.6428.1409
   Hrizi O, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/8950243
   Kahraman C., 2022, INT C INTELLIGENT FU, P463, DOI [DOI 10.1007/978-3-030-85577-2_55, 10.1007/978-3-030-85577-2_55]
   Krishnamoorthi R, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/1684017
   Loh L., 2022, FinTech, V1, DOI [10.3390/fintech1020008, DOI 10.3390/FINTECH1020008]
   Moons P, 2021, INT J CARDIOL CONGEN, V2, DOI 10.1016/j.ijcchd.2020.100074
   Mustapha A., 2020, Proceedings, V3, P349, DOI [10.1007/978-3-030-45183-7_27, DOI 10.1007/978-3-030-45183-7_27]
   Nandy S, 2023, NEURAL COMPUT APPL, V35, P14723, DOI 10.1007/s00521-021-06124-1
   Nematzadeh S, 2022, COMPUT BIOL CHEM, V97, DOI 10.1016/j.compbiolchem.2021.107619
   Ouf A. I. B., 2021, J. Southwest Jiaotong Univ., V56, P220, DOI [10.35741/issn.0258-2724.56.4.19.[31]R., DOI 10.35741/ISSN.0258-2724.56.4.19.[31]R]
   Phasinam K, 2022, J FOOD QUALITY, V2022, DOI 10.1155/2022/7529472
   Raju KB, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/1070697
   Rani Pooja, 2021, Journal of Reliable Intelligent Environments, V7, P263, DOI 10.1007/s40860-021-00133-6
   Repaka Anjan Nikhil, 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P292, DOI 10.1109/ICOEI.2019.8862604
   Riyaz Lubna, 2022, International Conference on Innovative Computing and Communications: Proceedings of ICICC 2021. Advances in Intelligent Systems and Computing (1389), P81, DOI 10.1007/978-981-16-3071-2_8
   Sheeba A, 2022, COMPUT METHOD BIOMEC, V25, P1180, DOI 10.1080/10255842.2022.2034795
   Singh Archana, 2020, 2020 International Conference on Electrical and Electronics Engineering (ICE3), P452, DOI 10.1109/ICE348803.2020.9122958
   Singh P, 2018, INT J NANOMED, V13, P3571, DOI [10.2147/IJN.S157958, 10.2147/IJN.S124998]
   Subahi AF, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su142114208
   Yadav DP, 2021, 2021 5 INT C INF SYS, P1, DOI [10.1109/ISCON52037.2021.9702410, DOI 10.1109/ISCON52037.2021.9702410]
   Yang L, 2020, NEUROCOMPUTING, V415, P295, DOI 10.1016/j.neucom.2020.07.061
NR 28
TC 1
Z9 1
U1 6
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 30
PY 2023
DI 10.1007/s11042-023-17273-x
EA NOV 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z2YV8
UT WOS:001110791700002
DA 2024-07-18
ER

PT J
AU Wang, FM
   Wang, RJ
   Huang, ZL
   Dong, SF
   Wang, XZ
   Zhou, Q
   Zheng, SJ
   Liu, L
AF Wang, Fenmei
   Wang, Rujing
   Huang, Ziliang
   Dong, Shifeng
   Wang, Xiuzhen
   Zhou, Qiong
   Zheng, Shijian
   Liu, Liu
TI EACT-Det: An Efficient Adjusting Criss-cross windows Transformer
   Embedding Pyramid Networks for Similar Disease Detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Criss-cross window transformer; Pyramid networks; EACT-Det; Efficient
   interactive spatial module; Global relation aggregation module; Crop
   disease detection
AB The difficulty of crop disease detection lies in the variation in light, background, similar symptoms and the serious problem of multiple diseases overlapping due to shading, etc., posing a great challenge to disease detection. These problems make the convolutional kernel use the sliding window method for feature extraction, which lacks the ability to obtain global background information. To address this problem, we first developed an efficient, adjusting self-attentive mechanism with vertical and horizontal windows. Then, within the self-attentive mechanism, an efficient interactive spatial module was designed in our multi-headed attention mechanism to obtain a more comprehensive association of the target global contextual information of crop diseases. Next, an efficient Criss-cross window transformer module is formed which can solve the problem of large background area and highly similar disease characteristics of crop diseases. Finally, a global relationship aggregation module was designed to integrate the global dependencies of efficient cross-window transformers into the features of the pyramidal network, which can more effectively solve the problem of severe overlapping crop disease detection. This model is stated as the efficient adjusted Criss-cross window transformer (EACT-Det) for crop. Experiments on a dataset containing 21 diseases from four different crops (rice, wheat, maize and oilseed rape) show that our method improves the accuracy by 1.9% and reduces the maximum size parameter of the model by 5.96 M compared to Swin-T, a classic and excellent model in the Transformer structure. The performance of our Adjusting Criss-Cross Window Transformer Network has improved significantly. In addition, the dataset of similar modalities in this article provides a data foundation for future disease similarity detection, and is also an important innovation of this article.
C1 [Wang, Fenmei; Wang, Rujing; Huang, Ziliang; Dong, Shifeng; Zhou, Qiong] Chinese Acad Sci, Hefei Inst Phys Sci, Inst Intelligent Machines, Hefei 230031, Peoples R China.
   [Wang, Fenmei; Wang, Rujing; Huang, Ziliang; Dong, Shifeng; Zhou, Qiong] Univ Sci & Technol China, Hefei 230026, Peoples R China.
   [Wang, Fenmei; Wang, Xiuzhen] PLA Army Acad Artillery & Air Def, Hefei 230031, Peoples R China.
   [Zheng, Shijian] Southwest Univ Sci & Technol, Mianyang 621000, Peoples R China.
   [Liu, Liu] Hefei Univ Technol, Hefei 230009, Peoples R China.
C3 Chinese Academy of Sciences; Hefei Institutes of Physical Science, CAS;
   Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Southwest University of Science & Technology - China; Hefei
   University of Technology
RP Wang, RJ (corresponding author), Chinese Acad Sci, Hefei Inst Phys Sci, Inst Intelligent Machines, Hefei 230031, Peoples R China.; Wang, RJ (corresponding author), Univ Sci & Technol China, Hefei 230026, Peoples R China.
EM rjwang@iim.ac.cn
FU International Cooperation in Science and Technology Innovation between
   Governments
FX No Statement Available
CR Akshitha M, 2022, 2022 IEEE 2 MYSORE S, P1
   Dong XY, 2022, PROC CVPR IEEE, P12114, DOI 10.1109/CVPR52688.2022.01181
   Dosovitskiy A., 2021, ICLR
   El-Nouby A, 2021, Arxiv, DOI [arXiv:2102.05644, DOI 10.48550/ARXIV.2102.05644]
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fuentes Alvaro, 2020, Advanced Concepts for Intelligent Vision Systems. 20th International Conference, ACIVS 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12002), P3, DOI 10.1007/978-3-030-40605-9_1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Jiang ZH, 2021, Arxiv, DOI arXiv:2104.10858
   Karatay B, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16342-5
   Kendler S, 2022, COMPUT ELECTRON AGR, V193, DOI 10.1016/j.compag.2022.106732
   Lee S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI [10.14722/ndss.2017.23457, 10.1016/j.patcog.2017.05.015]
   Liu J, 2021, PLANT METHODS, V17, DOI 10.1186/s13007-021-00722-9
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Mishra S, 2020, PROCEDIA COMPUT SCI, V167, P2003, DOI 10.1016/j.procs.2020.03.236
   Qin ZP, 2022, Arxiv, DOI arXiv:2201.04019
   Roy A, 2021, T ASSOC COMPUT LING, V9, P53, DOI 10.1162/tacl_a_00353
   Tay Y, 2020, Arxiv, DOI arXiv:2011.04006
   Tian Z, 2022, IEEE T PATTERN ANAL, V44, P1922, DOI 10.1109/TPAMI.2020.3032166
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2021, PROC CVPR IEEE, P12889, DOI 10.1109/CVPR46437.2021.01270
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wu HP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P22, DOI 10.1109/ICCV48922.2021.00009
   Xu WJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9961, DOI 10.1109/ICCV48922.2021.00983
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zen BP, 2022, Sinkron
   Zhang PC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2978, DOI 10.1109/ICCV48922.2021.00299
   Zhu XZ, 2021, Arxiv, DOI arXiv:2010.04159
NR 28
TC 0
Z9 0
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 29
PY 2023
DI 10.1007/s11042-023-17360-z
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8A7
UT WOS:001120006300003
DA 2024-07-18
ER

PT J
AU Chai, SY
   Zhao, XX
   Zhang, JM
   Kan, JM
AF Chai, Shuyao
   Zhao, Xixuan
   Zhang, Jiaming
   Kan, Jiangming
TI Defocus blur detection based on transformer and complementary residual
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Defocus blur detection; Transformer encoder; Complementary information;
   Residual learning
ID MAP ESTIMATION; IMAGE
AB Defocus blur detection (DBD), a technique for detecting defocus or in-focus pixels in a single image, has been widely used in various fields. Although deep learning-based methods applied to DBD attain superior performance compared to traditional methods that rely on manually-constructed features, these methods cannot distinguish many microscopic details when the images are complex. To address this issue, this work proposes a hybrid CNN-Transformer architecture (TCRL) based on complementary residual learning, which employs global information captured by the Transformer and hierarchical complementary information from the network to optimize DBD. Specifically, to enhance global target detection, our backbone network adopts a CNN-Transformer architecture, where the Transformer effectively drives the network to focus on the global context and thus achieve precise localization. To better detect microscopic details, we combine each convolutional neural network layer with layered complementary information from the network module to optimize the defocus blur detection process. This strategy opposes current schemes that output a binary mask, affording the layered feature-guided learning method to exploit better both low- and high-level information and effectively drive the network to refocus on boundaries and sparse, easily overlooked parts. Additionally, this work also considers the features of the in-focus and defocus pixels within the image. In this complementary model, the information ignored by one side may be learned by the other side, thus enhancing global target detection and local boundary refinement process. The experimental results on three datasets validate the effectiveness and superiority of the developed method.
C1 [Chai, Shuyao; Zhao, Xixuan; Zhang, Jiaming; Kan, Jiangming] Beijing Forestry Univ, 35 Qinghua East Rd, Beijing 100083, Peoples R China.
   [Chai, Shuyao; Zhao, Xixuan; Zhang, Jiaming; Kan, Jiangming] Key Lab State Forestry Adm Forestry Equipment & A, Beijing 100083, Peoples R China.
   [Zhao, Xixuan; Kan, Jiangming] Foshan Zhongke Innovat Res Inst Intelligent Agr &, Jingu Zhichuang Ind Community, 2 Yongan North Rd,Dawei Community,Guicheng St, Foshan 528251, Peoples R China.
C3 Beijing Forestry University
RP Zhao, XX (corresponding author), Beijing Forestry Univ, 35 Qinghua East Rd, Beijing 100083, Peoples R China.; Zhao, XX (corresponding author), Key Lab State Forestry Adm Forestry Equipment & A, Beijing 100083, Peoples R China.; Zhao, XX (corresponding author), Foshan Zhongke Innovat Res Inst Intelligent Agr &, Jingu Zhichuang Ind Community, 2 Yongan North Rd,Dawei Community,Guicheng St, Foshan 528251, Peoples R China.
EM chaisy@bjfu.edu.cn; zhaoxixuan@bjfu.edu.cn; jmzhang@bjfu.edu.cn;
   kanjm@bjfu.edu.cn
FU Guangdong Basic and Applied Basic Research Foundation [2022A1515110024];
   Fundamental Research Funds for the Central Universities [BLX202018]
FX This work was supported by Guangdong Basic and Applied Basic Research
   Foundation (Grant No.2022A1515110024) and the Fundamental Research Funds
   for the Central Universities (No. BLX202018).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Bac S, 2007, COMPUT GRAPH FORUM, V26, P571, DOI 10.1111/j.1467-8659.2007.01080.x
   Chen ZY, 2020, AAAI CONF ARTIF INTE, V34, P10599
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Darren M., 2019, J Am Musicological Soc, V72, P279, DOI [10.1525/jams.2019.72.1.279, DOI 10.1525/JAMS.2019.72.1.279]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Golestaneh SA, 2017, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2017.71
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirakawa K., 2013, Imaging Syst Appl, DOI [10.1364/ISA.2013.IM2E.1, DOI 10.1364/ISA.2013.IM2E.1]
   Hong YZ, 2016, MULTIMED TOOLS APPL, V75, P10807, DOI 10.1007/s11042-015-2792-1
   Jiang P, 2013, IEEE I CONF COMP VIS, P1976, DOI 10.1109/ICCV.2013.248
   Kirillov A, 2023, Arxiv, DOI arXiv:2304.02643
   Lee J, 2019, PROC CVPR IEEE, P12214, DOI 10.1109/CVPR.2019.01250
   Lin XY, 2022, NEUROCOMPUTING, V501, P88, DOI 10.1016/j.neucom.2022.06.023
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P5155, DOI 10.1109/TIP.2018.2847421
   Masia B, 2012, COMPUT GRAPH FORUM, V31, P1867, DOI 10.1111/j.1467-8659.2012.03067.x
   Pang YW, 2016, IEEE T CYBERNETICS, V46, P2220, DOI 10.1109/TCYB.2015.2472478
   Park J, 2017, PROC CVPR IEEE, P2760, DOI 10.1109/CVPR.2017.295
   Ranftl R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12159, DOI 10.1109/ICCV48922.2021.01196
   Saad E, 2016, IEEE T IMAGE PROCESS, V25, P3141, DOI 10.1109/TIP.2016.2555702
   Shi JP, 2015, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2015.7298665
   Shi JP, 2014, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2014.379
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su B, 2011, Proceedings of the 19th ACM International Conference on Multimedia. MM'11, DOI [DOI 10.1145/2072298.2072024, DOI 10.5555/1785794.1785825]
   Sun PZ, 2021, Arxiv, DOI arXiv:2012.15460
   Tang C, 2022, IEEE T PATTERN ANAL, V44, P955, DOI 10.1109/TPAMI.2020.3014629
   Tang C, 2017, IEEE SIGNAL PROC LET, V24, P490, DOI 10.1109/LSP.2016.2620162
   Tang C, 2016, IEEE SIGNAL PROC LET, V23, P1652, DOI 10.1109/LSP.2016.2611608
   Tang C, 2013, OPT LETT, V38, P1706, DOI 10.1364/OL.38.001706
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Wang R, 2019, SIGNAL PROCESS, V155, P73, DOI 10.1016/j.sigpro.2018.09.027
   Wang WH, 2021, Arxiv, DOI arXiv:2102.12122
   Wei Zhang, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1947, DOI 10.1109/ICCVW.2009.5457520
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   Xu GD, 2017, IEEE I CONF COMP VIS, P5381, DOI 10.1109/ICCV.2017.574
   Yi X, 2016, IEEE T IMAGE PROCESS, V25, P1626, DOI 10.1109/TIP.2016.2528042
   Yu Q., 2021, arXiv
   Zeng K, 2019, IEEE T IMAGE PROCESS, V28, P2107, DOI 10.1109/TIP.2018.2881830
   Zhao WD, 2021, IEEE T IMAGE PROCESS, V30, P5426, DOI 10.1109/TIP.2021.3084101
   Zhao WD, 2019, PROC CVPR IEEE, P8897, DOI 10.1109/CVPR.2019.00911
   Zhao WD, 2020, IEEE T PATTERN ANAL, V42, P1884, DOI 10.1109/TPAMI.2019.2906588
   Zhao ZJ, 2022, APPL INTELL, V52, P14426, DOI 10.1007/s10489-022-03303-y
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhu X, 2013, IEEE T IMAGE PROCESS, V22, P4879, DOI 10.1109/TIP.2013.2279316
   Zhuo SJ, 2011, PATTERN RECOGN, V44, P1852, DOI 10.1016/j.patcog.2011.03.009
NR 45
TC 1
Z9 1
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 14
PY 2023
DI 10.1007/s11042-023-17560-7
EA NOV 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JF3O4
UT WOS:001171713900011
DA 2024-07-18
ER

PT J
AU Rafie, A
   el Berrouhi, S
   Chenouni, D
   Tahiri, A
   el Mallahi, M
AF Rafie, Abderazzak
   el Berrouhi, Sanae
   Chenouni, Driss
   Tahiri, Ahmed
   el Mallahi, Mostafa
TI AI-based feature parameters extraction from color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artificial intelligent; Augmented reality; F1-score; Features
   extraction; AI-MD; Accuracy; LOSS; ROC
ID RECOGNITION; INVARIANT; TRANSLATION; ALGORITHM
AB The article presents a novel artificial Intelligent based feature parameters extraction that utilizes Mixed descriptors for analyzing white blood cell images. The proposed approach involves integrating these matrices into an artificial intelligent and Mixed descriptor architecture called AI-MD. The performance of the AI-MD model is evaluated using four cross-validation methods and various evaluation metrics including loss and accuracy curves, F1-score, recall, and receiver operating characteristic curve. The study concludes with a comparison of the proposed method with other recognition approaches. In order to assess the effectiveness of our architecture, we utilized the four cross-validation method. Recognition accuracy was evaluated using the area under the curve (AUC) metric for specific classes for all based on the original image matrices. The AUC values attained for these classes were as follows: 99.49%, 99.75%, 98.60%, and 99.72% respectively. Our method yielded highly favorable outcomes, with an impressive AUC value of 93.93%. This result outperformed existing approaches, highlighting the significant potential of our method. Consequently, it underscores the necessity for additional research in the realm of screening methods within medical applications, we also validate this experimentation using dataset of UCI has suggested to classify the fetus into three classes: normal, suspicious, and pathological.
C1 [Rafie, Abderazzak; el Berrouhi, Sanae; Chenouni, Driss; Tahiri, Ahmed; el Mallahi, Mostafa] Sidi Mohammed ben Abdellah Univ, High Normal Sch, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP el Mallahi, M (corresponding author), Sidi Mohammed ben Abdellah Univ, High Normal Sch, Fes, Morocco.
EM mostafa.elmallahi@usmba.ac.ma
OI El Mallahi, Mostafa/0000-0001-9735-6799
CR Abramowiz M, 1965, Hand Book of Mathematical Functions
   Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Amakdouf H, 2018, PROCEDIA COMPUT SCI, V127, P226, DOI 10.1016/j.procs.2018.01.118
   Amakdouf H, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   [Anonymous], 1938, Report No. VG1196-G-1
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Colaboratory, About us
   Ebrahimi M, 2021, MINER ENG, V170, DOI 10.1016/j.mineng.2021.106987
   El Mallahi M., 2018, Pattern Recognition and Image Analysis, V28, P207, DOI 10.1134/S1054661818020128
   El Mallahi M., 2017, Pattern Recognition and Image Analysis, V27, P810
   El Mallahi M, 2016, INT CONF MULTIMED, P41, DOI 10.1109/ICMCS.2016.7905531
   El Mallahi M, 2014, WSEAS transactions on circuits and systems
   El Mallahi M, 2015, 2015 INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV)
   El Mallahi M, 2018, NEURAL COMPUT APPL, V30, P2283, DOI 10.1007/s00521-016-2782-x
   El Mallahi M, 2018, INT J AUTOM COMPUT, V15, P277, DOI 10.1007/s11633-017-1071-1
   El Mallahi M, 2018, INT J AUTOM COMPUT, V15, P169, DOI 10.1007/s11633-017-1105-8
   El Mallahi M, 2018, MULTIMED TOOLS APPL, V77, P6583, DOI 10.1007/s11042-017-4573-5
   El Mallahi M, 2017, 2017 INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV)
   El Mallahi M, 2015, I C COMP SYST APPLIC
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Ghanou Y., 2016, IAENG International Journal of Computer Science, V43, P20
   Hosny KM, 2019, PATTERN ANAL APPL, V22, P1105, DOI 10.1007/s10044-018-0740-1
   Hosny KM, 2011, PATTERN RECOGN LETT, V32, P795, DOI 10.1016/j.patrec.2011.01.006
   HSU HS, 1993, OPT ENG, V32, P1596, DOI 10.1117/12.139804
   Jazzar MM, 2013, ARAB J SCI ENG, V38, P849, DOI 10.1007/s13369-012-0524-7
   Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5
   Li SY, 2021, PROC CVPR IEEE, P13544, DOI 10.1109/CVPR46437.2021.01334
   Mesbah A, 2016, INT CONF MULTIMED, P1, DOI 10.1109/ICMCS.2016.7905559
   Mesbah A, 2017, 3D RES, V8, DOI 10.1007/s13319-016-0113-8
   Mesbah A, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061621
   Mesbah A, 2017, LECT NOTES ELECTR EN, V397, P357, DOI 10.1007/978-981-10-1627-1_28
   Mesbah A, 2016, LECT NOTES ELECTR EN, V380, P267, DOI 10.1007/978-3-319-30301-7_28
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   paperpile, About us
   Pawlak M., 2006, Image Analysis by Moments: Reconstruction and Computational Aspects
   Song JK, 2018, Arxiv, DOI arXiv:1812.11004
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Xiao B, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023002
   Zhi RC, 2018, INFORM PROCESS LETT, V130, P30, DOI 10.1016/j.ipl.2017.09.010
   Zouhri A, 2024, MULTIMED TOOLS APPL, V83, P19817, DOI 10.1007/s11042-023-15374-1
NR 44
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 14
PY 2023
DI 10.1007/s11042-023-17193-w
EA NOV 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JF3O4
UT WOS:001171713900002
DA 2024-07-18
ER

PT J
AU Convertini, VN
   Gattulli, V
   Impedovo, D
   Terrone, G
AF Convertini, Vito Nicola
   Gattulli, Vincenzo
   Impedovo, Donato
   Terrone, Grazia
TI Classification bullying/cyberbullying through smartphone sensor and a
   questionnaire application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine Learning; Bullying; Cyberbullying; Shallow Learning; Smartphone;
   Behavioral Biometrics
AB This study establishes a correlation between computer science and psychology, specifically focusing on the incorporation of smartphone sensors and users' personality index. A limited number of state-of-the-art approaches have considered these factors, while no existing dataset currently encompasses this correlation. In this study, an Android application was developed to implement a questionnaire on bullying and cyberbullying, using smartphone sensors to predict Personal Index. Sensor data are collected in the "UNIBA HAR Dataset" and were analyzed using AI algorithms to find a correlation between the categorization class of the questionnaire (Personality Index) and the prediction of ML behavioral models. The results indicate that the Bayesian Bridge with "Bullying bully vs. Victimization bullying" and "Total bullying vs. Total victimization" performs better on average 0.94 accuracy, and the LSTM with the last categorization performs 0.89 accuracy. These results are crucial for future development in the same research area.
C1 [Convertini, Vito Nicola; Gattulli, Vincenzo; Impedovo, Donato] Univ Bari Aldo Moro, Dept Comp Sci, Via Edoardo Orabona 4, I-70125 Bari, Italy.
   [Terrone, Grazia] Univ Roma Tor Vergata, Dept Hist Cultural Heritage Educ & Soc, Rome, Italy.
C3 Universita degli Studi di Bari Aldo Moro; University of Rome Tor Vergata
RP Gattulli, V (corresponding author), Univ Bari Aldo Moro, Dept Comp Sci, Via Edoardo Orabona 4, I-70125 Bari, Italy.
EM vincenzo.gattulli@uniba.it
OI Gattulli, Vincenzo/0000-0001-9974-9414
FU This work is supported by the Italian Ministry of Education, University,
   and Research within the PRIN2017-BullyBuster project-A framework for
   bullying and cyberbullying action detection by computer vision and
   artificial intelligence methods and algorithms.; Italian Ministry of
   Education, University
FX This work is supported by the Italian Ministry of Education, University,
   and Research within the PRIN2017-BullyBuster project-A framework for
   bullying and cyberbullying action detection by computer vision and
   artificial intelligence methods and algorithms.
CR Aboo A. K., 2021, AL-RafidainJ. Comput. Sci. Math., V15, P55
   Alzahrani S, 2023, CMC-COMPUT MATER CON, V75, P651, DOI 10.32604/cmc.2023.035173
   Balducci F, 2020, MULTIMED TOOLS APPL, V79, P35909, DOI 10.1007/s11042-020-09146-4
   Castro F, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13106099
   Chimienti M, 2023, ALGORITHMS, V16, DOI 10.3390/a16010001
   Dang LM, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107561
   Gattulli V, 2023, WORLDCIST 23 11 WORL
   Gattulli V, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12020261
   Hinduja S, 2010, ARCH SUICIDE RES, V14, P206, DOI 10.1080/13811118.2010.494133
   Hu MM, 2023, COMPUT SECUR, V127, DOI 10.1016/j.cose.2023.103122
   Impedovo D., 2022, CEUR Workshop Proc, V3260, P114
   Impedovo D, 2022, IT C CYB
   Impedovo D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9245504
   istat, Indagine conoscitiva su bullismo e cyberbullismo
   Lopez-Fernandez O, 2019, CYBERPSYCH BEH SOC N, V22, P451, DOI 10.1089/cyber.2018.0731
   Luo F, 2023, IEEE INTERNET THINGS, V10, P1711, DOI 10.1109/JIOT.2022.3209084
   MAKHOUL J, 1980, IEEE T ACOUST SPEECH, V28, P27, DOI 10.1109/TASSP.1980.1163351
   Nagwani NK, 2017, J INF SCI, V43, P75, DOI 10.1177/0165551515616310
   Nerini M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22134857
   Özkul D, 2022, J COMPUT-MEDIAT COMM, V27, DOI 10.1093/jcmc/zmac015
   Palladino BE, 2016, AGGRESSIVE BEHAV, V42, P194, DOI 10.1002/ab.21636
   Palladino BE, 2015, CYBERPSYCH BEH SOC N, V18, P112, DOI 10.1089/cyber.2014.0366
   Ptaszynski M, 2010, LING COGN APPR DIAL
   Rayani PK, 2023, MICROPROCESS MICROSY, V96, DOI 10.1016/j.micpro.2022.104750
   Reynolds K., 2011, Proceedings of the 2011 Tenth International Conference on Machine Learning and Applications (ICMLA 2011), P241, DOI 10.1109/ICMLA.2011.152
   Sharaff Aakanksha., 2016, Emerging Research in Computing, Information. Communication and Applications, P237, DOI DOI 10.1007/978-81-322-2553-9_23
   Slonje R, 2013, COMPUT HUM BEHAV, V29, P26, DOI 10.1016/j.chb.2012.05.024
   Straczkiewicz M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-022-00745-z
   Teh PS, 2020, J AMB INTEL HUM COMP, V11, P4019, DOI 10.1007/s12652-019-01654-y
   Teh PS, 2016, COMPUT SECUR, V59, P210, DOI 10.1016/j.cose.2016.03.003
   Uddin MZ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-95947-y
   Wang Q, 2023, EURASIP J ADV SIG PR, V2023, DOI 10.1186/s13634-023-00984-6
   Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386
   Zaccagnino R, 2021, MULTIMED TOOLS APPL, V80, P15803, DOI 10.1007/s11042-020-10446-y
NR 34
TC 2
Z9 2
U1 12
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 11
PY 2023
DI 10.1007/s11042-023-17609-7
EA NOV 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y0ZQ9
UT WOS:001102641900004
OA hybrid
DA 2024-07-18
ER

PT J
AU Rajasekar, P
   Santhiya, P
AF Rajasekar, P.
   Santhiya, P.
TI Budget-based resource provisioning and scheduling algorithm for
   scientific workflows on IaaS cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Scientific workflows; Scheduling; Resource provisioning; IaaS cloud
ID CONCURRENT WORKFLOWS; TIME
AB The deployment of cloud computing, specifically Infrastructure as a Service (IaaS) clouds, have become an interested topic in recent years for the execution of compute-intensive scientific workflows. These platforms deliver on-demand connectivity to those infrastructure needed for workflow execution, providing customers to pay only for the service they utilize. As a result schedulers are forced to meet a quid-pro-quo among two main QoS criteria: cost and time. The maximum of this research work has been on making scheduling algorithms with the goal of reducing infrastructure costs as fulfilling a user-specified deadline. Few algorithms, on the other hand, have considered the problem of reducing workflow execution time while staying within a budget. This work consider on the latter scenario. We offer a Budget-based resource Provisioning and Scheduling (BPS) algorithm for scientific workflows used in IaaS service. This proposal was developed to face challenges specifically to clouds like resource performance variation, resource heterogeneity, infinite on-demand connectivity, and pay-as-you-go type (i.e. per-minute pricing). It is efficient of responding to the cloud dynamics, and is powerful in creating suitable solutions that fulfill a user-specified budget and reduce the makespan of the leveraged environment. At last, the experimental events confirms that it runs a workflow efficiently with respect to achieving budget of 94% and minimizing makespan of 29% than the state-of-the-art budget-aware algorithms.
C1 [Rajasekar, P.; Santhiya, P.] Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, Tamilnadu, India.
C3 Sathyabama Institute of Science & Technology
RP Rajasekar, P (corresponding author), Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, Tamilnadu, India.
EM rajasekar.cse@sathyabama.ac.in; santhiya.cse@sathyabama.ac.in
RI P, Santhiya/GZK-4830-2022
OI P, Santhiya/0000-0002-4818-3075
CR Ahmad W, 2021, CLUSTER COMPUT, V24, P249, DOI 10.1007/s10586-020-03100-7
   Alkhanak EN, 2018, FUTURE GENER COMP SY, V86, P480, DOI 10.1016/j.future.2018.03.055
   Andonov R., 1994, Proceedings. The International Conference on Application Specific Array Processors (Cat. No.94TH0687-4), P302, DOI 10.1109/ASAP.1994.331794
   Andonov R, 2000, EUR J OPER RES, V123, P394, DOI 10.1016/S0377-2217(99)00265-9
   [Anonymous], 1992, Data networks
   Arabnejad H, 2017, J COMPUT SCI-NETH, V23, P120, DOI 10.1016/j.jocs.2016.10.013
   Arabnejad H, 2017, FUTURE GENER COMP SY, V68, P211, DOI 10.1016/j.future.2016.10.003
   Arabnejad H, 2014, J GRID COMPUT, V12, P665, DOI 10.1007/s10723-014-9294-7
   Arabnejad V, 2019, IEEE T PARALL DISTR, V30, P29, DOI 10.1109/TPDS.2018.2849396
   Arabnejad V, 2016, P IEEE INT C E-SCI, P137, DOI 10.1109/eScience.2016.7870894
   Bharathi S, 2008, 2008 THIRD WORKSHOP ON WORKFLOWS IN SUPPORT OF LARGE-SCALE SCIENCE (WORKS 2008), P11
   Chakravarthi KK, 2020, CLUSTER COMPUT, V23, P3405, DOI 10.1007/s10586-020-03095-1
   Chen WH, 2017, FUTURE GENER COMP SY, V74, P1, DOI 10.1016/j.future.2017.03.008
   Chen WW, 2012, P IEEE INT C E-SCI
   Deldari A, 2017, J SUPERCOMPUT, V73, P756, DOI 10.1007/s11227-016-1789-5
   Doostali S, 2021, CLUSTER COMPUT, V24, P3607, DOI 10.1007/s10586-021-03351-y
   Garg N, 2021, CLUSTER COMPUT, V24, P767, DOI 10.1007/s10586-020-03149-4
   Geng XZ, 2019, CLUSTER COMPUT, V22, pS7539, DOI 10.1007/s10586-018-1856-1
   Ghafouri R, 2019, PEER PEER NETW APPL, V12, P241, DOI 10.1007/s12083-018-0662-0
   GILMORE PC, 1966, OPER RES, V14, P1045, DOI 10.1287/opre.14.6.1045
   GILMORE PC, 1963, OPER RES, V11, P863, DOI 10.1287/opre.11.6.863
   Hilman MH, 2020, Arxiv, DOI [arXiv:1903.01113, 10.48550/arXiv.1903.01113, DOI 10.48550/ARXIV.1903.01113]
   Hilman MH, 2017, P IEEE INT C E-SCI, P128, DOI 10.1109/eScience.2017.25
   Iranmanesh A, 2021, CLUSTER COMPUT, V24, P667, DOI 10.1007/s10586-020-03145-8
   Jackson K. R., 2010, Proceedings of the 2010 IEEE 2nd International Conference on Cloud Computing Technology and Science (CloudCom 2010), P159, DOI 10.1109/CloudCom.2010.69
   Toussi GK, 2021, CLUSTER COMPUT, V24, P1711, DOI 10.1007/s10586-020-03223-x
   Khorsand R, 2017, J SUPERCOMPUT, V73, P2430, DOI 10.1007/s11227-016-1928-z
   Leitner P, 2016, ACM T INTERNET TECHN, V16, DOI 10.1145/2885497
   Lin WW, 2017, INFORM SCIENCES, V397, P168, DOI 10.1016/j.ins.2017.02.054
   Lin WW, 2017, SOFT COMPUT, V21, P1301, DOI 10.1007/s00500-015-1862-7
   Liu L, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3942
   Medara R, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6922
   Menaka M, 2022, Meas Sens, DOI DOI 10.1016/J.MEASEN.2022.100436
   Ming Mao, 2012, 2012 IEEE 5th International Conference on Cloud Computing (CLOUD), P423, DOI 10.1109/CLOUD.2012.103
   Nik SSM, 2020, COMPUTING, V102, P477, DOI 10.1007/s00607-019-00740-5
   Nik SSM, 2021, CLUSTER COMPUT, V24, P343, DOI 10.1007/s10586-020-03109-y
   Nirmala SJ, 2016, COMPUTING, V98, P1091, DOI 10.1007/s00607-016-0494-9
   Patra SS, 2018, INT J CLOUD APPL COM, V8, P117, DOI 10.4018/IJCAC.2018010106
   Prakash V, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111320
   Prakash V, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROPAGATION AND COMPUTER TECHNOLOGY (ICSPCT 2014), P610, DOI 10.1109/ICSPCT.2014.6884887
   Rajasekar P, 2022, J SUPERCOMPUT, V78, P8025, DOI 10.1007/s11227-021-04225-1
   Rajasekar P, 2021, J AMB INTEL HUM COMP, V12, P7621, DOI 10.1007/s12652-020-02483-0
   Rajasekar P, 2021, SN Comput Sci, V2, P1, DOI [10.1007/s42979-021-00852-w, DOI 10.1007/S42979-021-00852-W]
   Rodriguez MA, 2018, FUTURE GENER COMP SY, V79, P739, DOI 10.1016/j.future.2017.05.009
   Rodriguez MA, 2017, ACM T AUTON ADAP SYS, V12, DOI 10.1145/3041036
   Rodriguez MA, 2015, PROC INT CONF PARAL, P839, DOI 10.1109/ICPP.2015.93
   Saeedi S, 2020, COMPUT IND ENG, V147, DOI 10.1016/j.cie.2020.106649
   Saeedizade E, 2021, J SUPERCOMPUT, V77, P14525, DOI 10.1007/s11227-021-03858-6
   Stadill S, 2013, By the numbers: How google compute engine stacks up to amazon ec2
   Stavrinides GL, 2021, MULTIMED TOOLS APPL, V80, P16781, DOI 10.1007/s11042-020-08974-8
   Stavrinides GL, 2019, MULTIMED TOOLS APPL, V78, P24639, DOI 10.1007/s11042-018-7051-9
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Sun T, 2019, CLUSTER COMPUT, V22, pS5987, DOI 10.1007/s10586-018-1751-9
   Taghinezhad-Niar A, 2022, CLUSTER COMPUT, V25, P3767, DOI 10.1007/s10586-022-03600-8
   Taghinezhad-Niar A, 2021, CLUSTER COMPUT, V24, P3449, DOI 10.1007/s10586-021-03314-3
   Verma A, 2017, PARALLEL COMPUT, V62, P1, DOI 10.1016/j.parco.2017.01.002
   Wu FH, 2016, FUTURE GENER COMP SY, V60, P22, DOI 10.1016/j.future.2016.01.004
   Xue SJ, 2019, CLUSTER COMPUT, V22, P693, DOI 10.1007/s10586-017-1189-5
   Zeedan M, 2023, COMPUTING, V105, P217, DOI 10.1007/s00607-022-01116-y
   Zhou NQ, 2023, CLUSTER COMPUT, V26, P1737, DOI 10.1007/s10586-020-03176-1
NR 60
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 9
PY 2023
DI 10.1007/s11042-023-17549-2
EA NOV 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9MX6
UT WOS:001101620700012
DA 2024-07-18
ER

PT J
AU Fernandez, JJ
   Nithyanandam, P
AF Fernandez, Jincy J.
   Nithyanandam, P.
TI Protection of online images against theft using robust multimodal
   biometric watermarking and T-norms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lifting wavelet transform; Triangular norms; Core point; Watermarking;
   Minutiae
ID QUALITY ASSESSMENT; ALGORITHM; SCHEME
AB Online image theft is a severe concern faced by many photographers. It occurs when someone uses the photo they took accidentally or deliberately without getting the permission of the owner of the photo. One of the solutions to prevent online image theft is to use biometric watermarking on the photo to be protected. The proposed work integrates multimodal biometric watermarking, Lifting Wavelet Transform (LWT), and score-level fusion using Triangular Norms to achieve better accuracy. Using block-based representatives from LWT coefficients for embedding preserves the visual quality of the watermarked image. By considering the iris and fingerprint images from the multimodal biometric database, SDUMLA-HMT, the proposed approach tests the watermarked images against many attacks and is proven to attack resilience. Moreover, the proposed system tests watermark imperceptibility and are proven not to affect the watermarked image's visual quality. The proposed system has also achieved a better accuracy rate regarding low False Acceptance Rate and False Rejection Rate.
C1 [Fernandez, Jincy J.; Nithyanandam, P.] VIT Univ, Chennai, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Fernandez, JJ (corresponding author), VIT Univ, Chennai, Tamil Nadu, India.
EM jincyj.fernandez2015@vit.ac.in; nithyanandam.p@vit.ac.in
CR Abdul W, 2020, COMPUT J, V63, P479, DOI 10.1093/comjnl/bxz047
   [Anonymous], 2016, How to protect images: 9 ways to reduce image Theft
   Aparna P., 2020, International Journal of Computational Vision and Robotics, V10, P1
   Awasthi Y, 2019, PROCEEDINGS OF THE 2019 8TH INTERNATIONAL CONFERENCE ON SYSTEM MODELING & ADVANCEMENT IN RESEARCH TRENDS (SMART-2019), P250, DOI [10.1109/smart46866.2019.9117522, 10.1109/SMART46866.2019.9117522]
   Bonissone P. P., 1987, International Journal of Approximate Reasoning, V1, P71, DOI 10.1016/0888-613X(87)90005-3
   Clark M, Iris recognition scanners vs. fingerprint scanners: compare and contrast
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Dholu P., 2017, Int J Eng Technol Sci Res, V4, P552
   Federal Bureau of Investigation, 1984, The science of fingerprints: classification and uses
   Fernandez J., 2017, Asian Journal of Pharmaceutical and Clinical Research, V10, P385
   Fernandez Jincy J., 2023, International Journal of Information Privacy, Security and Integrity, P211, DOI 10.1504/IJIPSI.2023.131546
   Fernandez Jincy J., 2021, Advances in Computing and Network Communications. Proceedings of CoCoNet 2020. Lecture Notes in Electrical Engineering (LNEE 736), P15, DOI 10.1007/978-981-33-6987-0_2
   Fernandez JJ, 2022, INT J INF COMPUT SEC, V19, P321, DOI 10.1504/IJICS.2022.127172
   Fernandez JJ, 2021, INT J BIOMETRICS, V13, P409, DOI 10.1504/IJBM.2021.117860
   Fernandez JJ, 2013, 2013 IEEE INTERNATIONAL MULTI CONFERENCE ON AUTOMATION, COMPUTING, COMMUNICATION, CONTROL AND COMPRESSED SENSING (IMAC4S), P155, DOI 10.1109/iMac4s.2013.6526399
   Gnanasivam P, 2010, PROCEDIA COMPUT SCI, V2, P133, DOI 10.1016/j.procs.2010.11.017
   Hill K., 2016, Stolen Images: Limestone Coast Photographers Fighting Back Against Online Theft
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Islam M, 2020, NEURAL COMPUT APPL, V32, P1379, DOI 10.1007/s00521-018-3647-2
   Kang XG, 2009, SCI CHINA SER F, V52, P276, DOI 10.1007/s11432-009-0043-7
   Kant C, 2020, PROCEDIA COMPUT SCI, V167, P932, DOI 10.1016/j.procs.2020.03.392
   Klement P. E., 1997, Tatra Mountains Mathematical Publications, V13, P169
   Ko JG, 2007, ETRI J, V29, P399, DOI 10.4218/etrij.07.0206.0141
   Liao X, 2021, INFORM SCIENCES, V575, P231, DOI 10.1016/j.ins.2021.06.045
   Mehra N., 2017, Int J Sci Res Dev, V5, P835
   Mn-Ta Lee, 2010, 2010 International Symposium on Computer, Communication, Control and Automation (3CA), P201, DOI 10.1109/3CA.2010.5533851
   Mohammed NF, 2020, KUWAIT J SCI, V47
   Mokashi B, 2022, CONTRAST MEDIA MOL I, V2022, DOI 10.1155/2022/2918126
   Najafi E, 2017, MATH SCI, V11, P307, DOI 10.1007/s40096-017-0233-1
   Nakirya B.K., 2018, ASCENT INT C P INF S, P1
   Nature TTL, 2018, Website stealing and selling 100s of wildlife photos without permission
   Nithyanandam P., 2011, International Journal of Computer Science and Security, V5, P456
   Okokpujie K., 2021, IAES Int J Artif Intell, V10, P1
   Olaniyi Olayemi M., 2016, International Journal of Information Engineering and Electronic Business, V8, P9, DOI 10.5815/ijieeb.2016.05.02
   Olufowobi H, 2019, PROCEEDINGS OF THE ACM WORKSHOP ON AUTOMOTIVE CYBERSECURITY (AUTOSEC '19), P25, DOI 10.1145/3309171.3309178
   PAGE ES, 1961, TECHNOMETRICS, V3, P1, DOI 10.2307/1266472
   Pandian N, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI'12), P1123
   Patel M., 2015, Int. J. Innov. Res. Comput. Commun. Eng, V3, P3943
   Radford S, 2017, Horse and hound
   Roy R, 2018, VIS INFORM, V2, P125, DOI 10.1016/j.visinf.2018.03.001
   Roy SS, 2021, MULTIMED TOOLS APPL, V80, P27245, DOI 10.1007/s11042-021-11046-0
   Sharma S, 2023, MULTIMED TOOLS APPL, V82, P2207, DOI 10.1007/s11042-022-13207-1
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Shen Wenbing, 2022, Arabian Journal of Geosciences, V15, DOI 10.1007/s12517-021-09268-5
   Singh P, 2017, MULTIMED TOOLS APPL, V76, P3871, DOI 10.1007/s11042-016-4048-0
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Thanki RM, 2020, J AMB INTEL HUM COMP, V11, P1835, DOI 10.1007/s12652-019-01295-1
   Din SU, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9122013
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wojtowicz W., 2013, Czasopismo Techniczne, V110, P409
   Yin YL, 2011, LECT NOTES COMPUT SC, V7098, P260, DOI 10.1007/978-3-642-25449-9_33
NR 53
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 7
PY 2023
DI 10.1007/s11042-023-17497-x
EA NOV 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3TF7
UT WOS:001097705200003
DA 2024-07-18
ER

PT J
AU Domínguez-Lloria, S
   Oliveira, LR
   Diz-Otero, M
   Pino-Juste, M
AF Dominguez-Lloria, Sara
   Oliveira, Lia Raquel
   Diz-Otero, Mario
   Pino-Juste, Margarita
TI Content evaluation of mobile device applications for teaching music in
   elementary education
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Educational application; Informal learning; Mobile learning; Ubiquitous
   learning; Digital skill; Music
ID IPAD
AB Nowadays, the use of mobile devices has substantially changed the way in which we relate to each other. This has undoubtedly influenced the way in which the teaching-learning processes take place, where one of the tools of maximum development has been the apps. The aim of this study is to analyze the content of 50 Apps for teaching music in primary education. A retrospective descriptive study has been carried out, gathering the most relevant information on the main characteristics of music Apps at different levels: technical, descriptive, pedagogical, and psychological. Among the main results we highlight that most of the Apps do not have solid pedagogical design criteria, belong to the curricular block of listening and interpretation and do not offer game strategies that serve to motivate users. Based on our analysis, we have described a series of criteria that allow teachers and parents to select music learning Apps in both formal and informal contexts. We also conclude that it is important to continue conducting research to guide developers when developing educational digital content for children in the field of music education.
C1 [Dominguez-Lloria, Sara; Pino-Juste, Margarita] Univ Vigo, Fac Educ & Sport Sci, Fac Ciencias Educ & Deporte, Pontevedra 36005, Spain.
   [Oliveira, Lia Raquel] Univ Minho, Inst Educ & Psychol, Campus Gualtar, P-4710057 Braga, Portugal.
   [Diz-Otero, Mario] Univ Santiago de Compostela, Fac Educ Sci, Santiago De Compostela 15705, Spain.
C3 Universidade de Vigo; Universidade do Minho; Universidade de Santiago de
   Compostela
RP Domínguez-Lloria, S (corresponding author), Univ Vigo, Fac Educ & Sport Sci, Fac Ciencias Educ & Deporte, Pontevedra 36005, Spain.
EM saradominguez.lloria@uvigo.es; lia@ie.uminho.pt; mario.diz@usc.es;
   mpino@uvigo.es
RI Pino-Juste, Margarita/K-9242-2014; Oliveira, Lia R/B-1266-2018
OI Pino-Juste, Margarita/0000-0002-2551-5903; Oliveira, Lia
   R/0000-0002-9939-7612; Dominguez-Lloria, Sara/0000-0002-4318-3017;
   Diz-Otero, Mario/0000-0002-5011-7819
CR Al-Bashayreh M, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14074325
   Alises-Camacho ME., 2017, SEECI J Commun, V43, P29, DOI [10.15198/seeeci.2017.43.29-51, DOI 10.15198/SEEECI.2017.43.29-51]
   [Anonymous], 2009, Aula de innovacion educativa
   [Anonymous], 2018, Estudios Pedagogicos, DOI DOI 10.4067/S0718-07052017000400006
   Ates H, 2022, EDUC INF TECHNOL, V27, P2521, DOI 10.1007/s10639-021-10671-4
   Brazuelo F., 2011, Mobile learning: Mobile devices as an educational resource
   Burbules NC, 2014, Archives of educational policy analysis, V22, P1
   Chandran VP, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0265927
   Crescenzi-Lanna L, 2016, COMUNICAR, V24, P77, DOI 10.3916/C46-2016-08
   Crespo F, 2018, Hum Comput Interact, P1
   Day R., 2005, How to Write Publish a Scientific Paper
   Gallardo-Montes CD, 2022, EDUC INF TECHNOL, V27, P4087, DOI 10.1007/s10639-021-10773-z
   Educational AppStore, 2021, How do we certify Apps?
   Giraldez A, 2012, 2 C CEIMUS ED INV MU
   Hanna N, 2022, REV J AUTISM DEV DIS, V9, P453, DOI 10.1007/s40489-021-00271-w
   Herrera SI, 2011, 17 ARG C COMP SCI U
   Aguaded-Gómez JI, 2011, COMUNICAR, V18, P7, DOI 10.3916/C36-2011-01-01
   Jonhnson L, 2012, The NMC Horizon Report 2012 Higher Education Edition
   Jorrin-Abellan I M., 2009, Ubiquitous Learning: An International Journal, V1, P71, DOI DOI 10.18848/1835-9795/CGP/V01I03/40240
   Kolb BM, 2013, Marketing for cultural organizations: New strategies for attracting audiences, V1st, DOI [10.4324/9780203102367, DOI 10.4324/9780203102367]
   Kucirkova N, 2014, COMPUT EDUC, V71, P175, DOI 10.1016/j.compedu.2013.10.003
   Lopez Gil M. M., 2016, RIFOP. Revista Interuniversitaria de Formacion del Profesorado, V30, P103
   Marta-Lazo C., 2016, COMUNICACION DIGITAL
   McKnight L, 2010, INT J MOB HUM COMPUT, V2, P1, DOI 10.4018/jmhci.2010040101
   Miralpeix A, 2013, ALOMA, V31, P33
   Moreira D, 2020, Revista Arte, Educacao, Comunicacao Des, V1, P1, DOI [10.29327/216572.1.1-1, DOI 10.29327/216572.1.1-1]
   Official Gazette of Spain, 2014, BOE
   Ortiz-Colón Ana-M., 2018, Educ. Pesqui., V44, pe173773
   Osuna S, 2012, Razon y Palabra, V17
   Prendes-Espinosa MP., 2020, Bullying and cyberbullying at school: the vulnerability of people with special educational needs
   Rodriguez F., 2015, Gamificacion: Como motivar a tu Alumnado y Mejorar el Clima en el Aula
   Silva N, 2016, 9 ANN INT C ED RES I
   Specht M, 2013, CAMPUS VIRTUALES, V2, P30
   Vazquez- Cano E., 2015, Mobile digital devices in education
   Gómez CV, 2015, PIXEL-BIT, P137
   Xanthopoulou M., 2019, International Journal of Recent Contributions from Engineering, Science IT (iJES), V7, P4, DOI DOI 10.3991/IJES.V7I2.10335
   Zabala A., 2014, Methods for teaching competencies
NR 37
TC 0
Z9 0
U1 6
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 28
PY 2023
DI 10.1007/s11042-023-17522-z
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W7FP7
UT WOS:001093249700006
DA 2024-07-18
ER

PT J
AU Upadhyay, DK
   Mohapatra, S
   Singh, NK
AF Upadhyay, Devesh Kumar
   Mohapatra, Subrajeet
   Singh, Niraj Kumar
TI An early assessment of Persistent Depression Disorder using machine
   learning algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Psychological Disorder; Dysthymia; Persistent Depression Disorder (PDD);
   Cognitive psychology; Support Vector Machine; Multi-kernel; Confusion
   matrix; Stacked ensemble SVM
ID ASYMMETRY; SEVERITY
AB Although various algorithms and strategies have been proposed for predicting depression and anxiety, none of the work is still suggested for an automated system for an early assessment of Dysthymia. This study aimed to enhance the accuracy of early diagnosis for Persistent Depression Disorder (PDD) through an improved machine learning technique utilizing the stacking SVM ensemble approach. To expedite the initial screening of dysthymia in students, a quantitative analysis of behavioral data based on machine learning was employed. The research collected behavioral data from 137 college students, and the gathered data was used for model development and experimentation. The findings revealed that PDD was predominantly prevalent among middle-class undergraduates majoring in non-technical fields. Notably, PDD rates were higher among rural undergraduates from both high- and low-income backgrounds. The proposed stacked SVM model demonstrated superior performance, achieving an accuracy of 89.4%. Detecting PDD early among undergraduates is crucial for mental health professionals, and the stacked SVM method proved effective in this aspect.
C1 [Upadhyay, Devesh Kumar; Mohapatra, Subrajeet; Singh, Niraj Kumar] Birla Inst Technol Mesra, Dept Comp Sci & Engn, Ranchi, Jharkhand, India.
C3 Birla Institute of Technology Mesra
RP Upadhyay, DK (corresponding author), Birla Inst Technol Mesra, Dept Comp Sci & Engn, Ranchi, Jharkhand, India.
EM deveshupadhyay3@gmail.com
RI Mohapatra, Subrajeet/KHW-6307-2024
OI UPADHYAY, DEVESH/0000-0002-2399-1850; Singh, Niraj/0000-0001-5267-3547
CR Ahmadlou M, 2013, CLIN EEG NEUROSCI, V44, P175, DOI 10.1177/1550059413480504
   Alickovic E, 2018, IEEE T INSTRUM MEAS, V67, P1258, DOI 10.1109/TIM.2018.2799059
   alliancecan, About us
   Brown AM, 2005, COMPUT METH PROG BIO, V79, P89, DOI 10.1016/j.cmpb.2005.02.007
   Carter R., 2014, The brain book, V2nd
   Chen Z, 2018, INT CONF BIG DATA, P251, DOI 10.1109/BigComp.2018.00044
   Choudhury AA, 2019, IEEE REGION 10 SYMP, P789, DOI [10.1109/TENSYMP46218.2019.8971369, 10.1109/tensymp46218.2019.8971369]
   Cohn Jeffrey F., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204260
   Cummins N, 2015, SPEECH COMMUN, V71, P10, DOI 10.1016/j.specom.2015.03.004
   Cvetkovic J, 2017, CANCER INVEST, V35, P569, DOI 10.1080/07357907.2017.1363892
   De Choudhury Munmun, 2013, ICWSM, P128, DOI [10.1109/IRI.2012.6302998, DOI 10.1109/IRI.2012.6302998, DOI 10.3109/01460862.2013.798190]
   depressionfree, Non-clinical depression
   depressionfree, Clinical depression
   Faust O, 2014, J MECH MED BIOL, V14, DOI 10.1142/S0219519414500353
   Friston K.J., 2004, HUMAN BRAIN FUNCTION, V2nd
   Goyal S, 2022, MULTIMED TOOLS APPL, V81, P37033, DOI 10.1007/s11042-021-11488-6
   HAMILTON M, 1960, J NEUROL NEUROSUR PS, V23, P56, DOI 10.1136/jnnp.23.1.56
   Hosseinifard B, 2013, COMPUT METH PROG BIO, V109, P339, DOI 10.1016/j.cmpb.2012.10.008
   Kiss G, 2017, INT CONF COGN INFO, P213, DOI 10.1109/CogInfoCom.2017.8268245
   Knott V, 2001, PSYCHIAT RES-NEUROIM, V106, P123, DOI 10.1016/S0925-4927(00)00080-9
   Krishni, 2018, K-fold cross validation
   Lam R.W., 2006, Assessment Scales in Depression and Anxiety-CORPORATE: (Servier Edn)
   Mantri S, 2013, INT CONF EMERG TR, P111, DOI 10.1109/ICETET.2013.32
   MASON BJ, 1993, PSYCHIAT ANN, V23, P625, DOI 10.3928/0048-5713-19931101-09
   Meftah T, 2012, INT C COMPL SYST ICC
   Mohapatra S, 2008, Development of impulse noise detection schemes for selective filtering
   Morales MR, 2016, IEEE W SP LANG TECH, P136, DOI 10.1109/SLT.2016.7846256
   Na KS, 2020, NEUROSCI LETT, V721, DOI 10.1016/j.neulet.2020.134804
   NCBI, About Us
   Puthankattil SD, 2012, J MECH MED BIOL, V12, DOI 10.1142/S0219519412400192
   Salman A. O., 2022, Int. J. Math., Stat., Comput. Sci., V1, P1, DOI [10.59543/ijmscs.v1i.7693, DOI 10.59543/IJMSCS.V1I.7693]
   Sansone Randy A, 2009, Psychiatry (Edgmont), V6, P46
   Sau A, 2017, HEALTHC TECHNOL LETT, V4, P238, DOI 10.1049/htl.2016.0096
   simplilearn, Classification-Machine Learning
   Stewart JL, 2014, PSYCHOPHYSIOLOGY, V51, P446, DOI 10.1111/psyp.12191
   Suslow T, 2001, PERCEPT MOTOR SKILL, V92, P857, DOI 10.2466/PMS.92.3.857-868
   Upadhyay DK., 2023, Data Science and AI, Selected Papers from CIAIS-2021, V1, P183
   Upadhyay DK, 2023, J Harbin Eng Univ, V44
   Yadav A, 2020, A Multilingual Framework of CNN and Bi-LSTM for Emotion Classification, DOI [10.1109/ICCCNT49239.2020.9225614, DOI 10.1109/ICCCNT49239.2020.9225614]
   Yang Y, 2013, IEEE T AFFECT COMPUT, V4, P142, DOI 10.1109/T-AFFC.2012.38
NR 40
TC 1
Z9 1
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-17369-4
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300015
DA 2024-07-18
ER

PT J
AU Sun, K
   Yin, YL
   Dong, FX
   Sun, XM
AF Sun, Kun
   Yin, Yanli
   Dong, Fuxuan
   Sun, Xiaoming
TI Hyperspectral classification method based on M-ResHSDC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hyperspectral Image Classification; Convolutional Neural Network; Mix-up
   algorithm; Hybrid spectral dilated convolution
AB The hyperspectral image (HSI) classification method based on a three-dimensional convolutional neural network (3DCNN) has problems with overfitting in the training process, and difficulty in interacting with long-distance features, which decreases the classification accuracy. This paper proposes a hyperspectral classification method based on a mix-up algorithm and residual hybrid spectral dilated convolution (M-ResHSDC) to deal with the above problems. Firstly, the mix-up algorithm is utilized for increasing the original dataset to a larger number to alleviate the overfitting problem. Secondly, the hybrid spectral dilated convolution (HSDC) is built up through the combination of the spectral dilated convolution operators with different dilated rates. Each branch of HSDC has a different dilated rate, facilitating the extraction of spectral-spatial features at multiple scales. The ability to capture multiple scales could significantly enhance classification accuracy. On this basis, residual hybrid spectral dilated convolution (ResHSDC) is proposed by replacing the convolution layer of the residual block with HSDC. Thirdly, three ResHSDCs are introduced to replace the three convolution layers of 3DCNN respectively to solve the difficult interaction of long-distance features. Finally, the experiments are conducted on three HSI datasets (Indian Pines, University of Pavia, and Salinas). The results show a higher accuracy of 98.87%, 99.32%, and 99.47% respectively than the traditional methods.
C1 [Sun, Kun; Yin, Yanli; Dong, Fuxuan; Sun, Xiaoming] Harbin Univ Sci & Technol, Higher Educ Key Lab Measuring & Control Technol &, Harbin 150000, Peoples R China.
   [Sun, Kun; Yin, Yanli; Dong, Fuxuan; Sun, Xiaoming] Harbin Univ Sci & Technol, Demonstrat Ctr Measurement & Control Technol & Ins, Natl Expt Teaching, Harbin 150000, Peoples R China.
C3 Harbin University of Science & Technology; Harbin University of Science
   & Technology
RP Sun, K (corresponding author), Harbin Univ Sci & Technol, Higher Educ Key Lab Measuring & Control Technol &, Harbin 150000, Peoples R China.; Sun, K (corresponding author), Harbin Univ Sci & Technol, Demonstrat Ctr Measurement & Control Technol & Ins, Natl Expt Teaching, Harbin 150000, Peoples R China.
EM sunkun1982@126.com
CR Ahmad M, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3043710
   Bioucas-Dias JM, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2244672
   Bo CJ, 2018, MULTIMED TOOLS APPL, V77, P10419, DOI 10.1007/s11042-017-4403-9
   Chen ST, 2021, MULTIMED TOOLS APPL, V80, P1859, DOI 10.1007/s11042-020-09480-7
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen YS, 2015, IEEE J-STARS, V8, P2381, DOI 10.1109/JSTARS.2015.2388577
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Cui BL, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3062372
   Guo YH, 2018, IEEE ACCESS, V6, P18582, DOI 10.1109/ACCESS.2018.2820043
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kemker R, 2017, IEEE T GEOSCI REMOTE, V55, P2693, DOI 10.1109/TGRS.2017.2651639
   Khodadadzadeh M, 2014, IEEE GEOSCI REMOTE S, V11, P2105, DOI 10.1109/LGRS.2014.2320258
   Li CM, 2021, MICROMACHINES-BASEL, V12, DOI 10.3390/mi12050545
   Li MT, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23063190
   Li X, 2020, IEEE T GEOSCI REMOTE, V58, P2615, DOI 10.1109/TGRS.2019.2952758
   Liang DJ, 2018, IEEE ACCESS, V6, P58774, DOI 10.1109/ACCESS.2018.2872698
   Liu GX, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14102447
   Lu B, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12162659
   Makantasis K, 2015, INT GEOSCI REMOTE SE, P4959, DOI 10.1109/IGARSS.2015.7326945
   Rao TCM, 2012, J INDIAN SOC REMOTE, V40, P191, DOI 10.1007/s12524-011-0149-4
   Roy SK, 2021, IEEE T GEOSCI REMOTE, V59, P7831, DOI 10.1109/TGRS.2020.3043267
   Roy SK, 2020, IEEE GEOSCI REMOTE S, V17, P277, DOI 10.1109/LGRS.2019.2918719
   SHAHSHAHANI BM, 1994, IEEE T GEOSCI REMOTE, V32, P1087, DOI 10.1109/36.312897
   Shi CP, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3174015
   Song WW, 2016, INT GEOSCI REMOTE SE, P2411, DOI 10.1109/IGARSS.2016.7729622
   Tu C, 2023, INFRARED PHYS TECHN, V131, DOI 10.1016/j.infrared.2023.104706
   Wang TY, 2017, PROC INT C TOOLS ART, P1272, DOI 10.1109/ICTAI.2017.00192
   Wu PD, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12122035
   Xu H, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13071248
   Yao W, 2021, IEEE GEOSCI REMOTE S, V18, P1991, DOI 10.1109/LGRS.2020.3010837
   Zhang CJ, 2019, IEEE T GEOSCI REMOTE, V57, P9201, DOI 10.1109/TGRS.2019.2925615
   Zhang XX, 2023, IEEE ACCESS, V11, P32648, DOI 10.1109/ACCESS.2023.3262992
NR 32
TC 0
Z9 0
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 24
PY 2023
DI 10.1007/s11042-023-17515-y
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0VW7
UT WOS:001088903700011
DA 2024-07-18
ER

PT J
AU Dong, CA
   Tang, YH
   Zhang, LY
AF Dong, Chengang
   Tang, Yuhao
   Zhang, Liyan
TI Higher efficient YOLOv7: a one-stage method for non-salient object
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Non-salient; Object Detection; Attention Mechanisms; YOLOv7
AB Compared to the remarkable progress within the discipline of object detection in recent years, real-time detection of non-salient objects remains a challenging research task. However, most existing detection methods fail to adequately extract the global features of targets, leading to suboptimal performance when dealing with non-salient objects. In this paper, we propose a unified framework called Higher efficient (He)-YOLOv7 to enhance the detection capability of YOLOv7 for non-salient objects.Firstly, we introduce an refined Squeeze and Excitation Network (SENet) to dynamically adjust the weights of feature channels, thereby enhancing the model's perception of non-salient objects. Secondly, we design an Angle Intersection over Union (AIoU) loss function that considers relative positional information, optimizing the widely used Complete Intersection over Union (CIoU) loss function in YOLOv7. This significantly accelerates the model's convergence. Moreover, He-YOLOv7 adopts a blended data augmentation strategy to simulate occlusion among objects, further improving the model's ability to filter out noise information and enhancing its robustness. Comparison of experimental results demonstrates a significant improvement of 2.4% mean Average Precision (mAP) on the Microsoft Common Objects in Context (MS COCO) dataset and a notable enhancement of 1.2% mAP on the PASCAL VOC dataset. Simultaneously, our approach demonstrates comparable performance to state-of-the-art real-time object detection methods.
C1 [Dong, Chengang; Tang, Yuhao; Zhang, Liyan] Nanjing Univ Aeronaut & Astronaut, Nanjing 210000, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Zhang, LY (corresponding author), Nanjing Univ Aeronaut & Astronaut, Nanjing 210000, Peoples R China.
EM dcg18600012570@nuaa.edu.cn; bx2016006@nuaa.edu.cn;
   zhangliyan@nuaa.edu.cn
OI Dong, Chengang/0009-0005-9234-121X
FU National Natural Science Foundation of China [62172212]; Natural Science
   Foundation of Jiangsu Province [BK20230031]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62172212, in part by the Natural Science
   Foundation of Jiangsu Province under Grant BK20230031.
CR Ali H, 2019, INT C INF SCI COMM T, P1
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Breger A, 2019, Arxiv, DOI arXiv:1910.13422
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Cen H, 2023, INT J SYST ASSUR ENG, V14, P728, DOI 10.1007/s13198-021-01514-z
   Chen K, 2018, P IEEE C COMP VIS PA, P6298
   Chen Y., 2020, Proc. Adv. Neural Inf. Process. Syst., NeurIPS, V33, P5621
   Cheng X, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3040485
   Chowdhury PN, 2022, LECT NOTES COMPUT SC, V13668, P253, DOI 10.1007/978-3-031-20074-8_15
   Christlein Vincent, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1090, DOI 10.1109/ICDAR.2019.00177
   Dai XY, 2021, PROC CVPR IEEE, P7369, DOI 10.1109/CVPR46437.2021.00729
   Ding J, 2019, PROC CVPR IEEE, P2844, DOI 10.1109/CVPR.2019.00296
   Ding XH, 2021, PROC CVPR IEEE, P13728, DOI 10.1109/CVPR46437.2021.01352
   Fu C.-Y., 2017, arXiv
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hossain MS, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-38109-6
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang L., 2020, ADV NEURAL INF PROCE, V33, P19365
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li C, 2023, arXiv, DOI 10.48550/arXiv.2301.05586
   Li CY, 2022, Arxiv, DOI [arXiv:2209.02976, 10.48550/arXiv.2209.02976]
   Li X., 2020, IEEE Trans Pattern Anal Mach Intell, V43, P1941
   Liang TT, 2022, Arxiv, DOI arXiv:2107.00420
   Lin M, 2014, Arxiv, DOI [arXiv:1312.4400, DOI 10.48550/ARXIV.1312.4400]
   Liu MY, 2019, P IEEE CVF C COMP VI, P5179
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2022, PROC CVPR IEEE, P11999, DOI 10.1109/CVPR52688.2022.01170
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren ZY, 2021, IEEE INT CONF AUTOMA
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shen YY, 2022, NEUROCOMPUTING, V500, P99, DOI 10.1016/j.neucom.2022.05.052
   Sriram S, 2020, IEEE CONF COMPUT, P740, DOI 10.1109/INFOCOMWKSHPS50562.2020.9162661
   Su Y, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105866
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Sun ZQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3591, DOI 10.1109/ICCV48922.2021.00359
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Terven JR, 2024, Arxiv, DOI arXiv:2304.00501
   Ukwuoma Chiagoziem C., 2021, 2021 4th International Conference on Pattern Recognition and Artificial Intelligence (PRAI), P378, DOI 10.1109/PRAI53619.2021.9551094
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang CY, 2021, Arxiv, DOI arXiv:2105.04206
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang H, 2022, J REAL-TIME IMAGE PR, V19, P1023, DOI 10.1007/s11554-022-01241-z
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xingyi Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P474, DOI 10.1007/978-3-030-58548-8_28
   Xu SL, 2022, Arxiv, DOI [arXiv:2203.16250, 10.48550/arXiv.2203.16250]
   Xu XZ, 2022, Arxiv, DOI arXiv:2211.15444
   Zhang S., 2020, IEEE Trans Image Process, V29, P3702
   Zhao Y, 2024, Arxiv, DOI [arXiv:2304.08069, 10.48550/arXiv.2304.08069, DOI 10.48550/ARXIV.2304.08069]
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
   Zhu X, 2019, P IEEE C COMP VIS PA, P424
   Zhu XZ, 2021, Arxiv, DOI arXiv:2010.04159
NR 61
TC 1
Z9 1
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17185-w
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400026
DA 2024-07-18
ER

PT J
AU Rahman, S
   Ali, N
   Hussain, T
   Yang, BL
   Hussain, A
AF Rahman, Saifur
   Ali, Numan
   Hussain, Tariq
   Yang, Bailin
   Hussain, Altaf
TI The effect of image-cyclic-based guidance on user's skill enhancement in
   virtual assembly task
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Virtual Reality; Virtual Assembly Task; Augmented Reality; Online
   Distanced Learning using 3D approach; Image Cyclic Based Guidance
AB The concept of 2 Dimensional (2D) and 3 Dimensional (3D) are represented by different bodies for diverse applications. The 2D is an old concept of image representation as it displays only the x and y axis, whereas the 3D image displays the x, y, and z axis simultaneously. The image of 3D on a screen looks like an image in the real world. With the rapid development of virtual technology, the virtual assembly task is used for a user the check the clear view, just like a real-world view. Various cognitive aids (such as change of color, arrows, etc.) are provided in virtual assembly tasks to assist users in task realization. These aids increase users' performance but lead to reduce learning because there is less cognitive load on the users. In this research, we propose the development of Image Cyclic Based Guidance (ICBG) on users' skills enhancement in virtual electric motor assembly tasks for poly-technical students who enable them to assemble the electric motor according to the correct course of action in a 3D-friendly environment without any mental load or expert. We describe the potential contribution of VEM (Virtual Electric Motor) for enhancing student learning based on ICBG, where students assist in assembling an electric motor and its different parts and accurately assemble these parts using VEM. We evaluated our proposed system through polytechnical students. During the evaluation, it revealed that ICBG showed a significant difference that the performance of students was considerably better than the others who did not use it.
C1 [Rahman, Saifur] Univ Agr Peshawar, Inst Comp Sci & Informat Technol, Peshawar 25130, Pakistan.
   [Ali, Numan] Air Univ Islamabad, Dept Comp Games Dev, FCAI, Islamabad 45000, Pakistan.
   [Hussain, Tariq; Yang, Bailin] Zhejiang Gongshang Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
   [Hussain, Tariq; Yang, Bailin] Zhejiang Gongshang Univ, Sch Math & Stat, Hangzhou 310018, Peoples R China.
   [Hussain, Altaf] Chongqing Univ Posts & Telecommun, Sch Comp Sci & Technol, Chongqing 400065, Peoples R China.
C3 Quaid I Azam University; Air University Islamabad; Zhejiang Gongshang
   University; Zhejiang Gongshang University; Chongqing University of Posts
   & Telecommunications
RP Yang, BL (corresponding author), Zhejiang Gongshang Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.; Yang, BL (corresponding author), Zhejiang Gongshang Univ, Sch Math & Stat, Hangzhou 310018, Peoples R China.
EM saif_tigere@yahoo.com; numan.chk@gmail.com; uom.tariq@gmail.com;
   ybl@zjgsu.edu.cn; altafkfm74@gmail.com
RI Hussain, Tariq/AAO-1864-2020
OI Hussain, Tariq/0000-0002-4761-0346
FU National Natural Science Foundation of China [62172366]; The "Pioneer"
   and "Leading Goose" R & D. Program of Zhejiang Province [2023C01150]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 62172366), and "Pioneer" and "Leading Goose" R & D.
   Program of Zhejiang Province (2023C01150)
CR Auyeskhan U, 2023, J COMPUT DES ENG, V10, P1126, DOI 10.1093/jcde/qwad041
   Blume BD, 2010, J MANAGE, V36, P1065, DOI 10.1177/0149206309352880
   Borrego A, 2018, GAMES HEALTH J, V7, P151, DOI 10.1089/g4h.2017.0114
   Büttner S, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P433, DOI 10.1145/3056540.3076193
   Carlson P, 2015, IEEE T VIS COMPUT GR, V21, P770, DOI 10.1109/TVCG.2015.2393871
   Jimenez IAC, 2023, INT J INTERACT DES M, V17, P45, DOI 10.1007/s12008-022-01087-6
   Chittaro L., 2006, Proceeding of Virtual Reality Software and Technology, V06, P227
   Dalgarno B, 2003, P AUSTR C SCI MATH E
   Feng S, 2023, VIRTUAL REAL-LONDON, V27, P591, DOI 10.1007/s10055-022-00680-0
   Funk M., 2018, Assistive Augmentation, P49
   Gick M.L., 1987, Transfer of Learning: Contemporary Research and Applications, P9, DOI [10.1016/B978-0-12-188950-0.50008-4, DOI 10.1016/B978-0-12-188950-0.50008-4]
   Gray R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02183
   Gupta A, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P389
   Hitomi K., 2017, Manufacturing systems engineering: a unified approach to manufacturing technology, production management and industrial economics
   Hoareau C, 2017, INT J HUM-COMPUT INT, V33, P786, DOI 10.1080/10447318.2017.1286768
   Huang K, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P791
   Irfanullah, 2022, MULTIMED TOOLS APPL, V81, P38151, DOI 10.1007/s11042-022-13169-4
   Jantti M, 2023, EDULEARN23 P, P6745
   Juraschek M, 2018, PROCEDIA MANUF, V23, P153, DOI 10.1016/j.promfg.2018.04.009
   Kase H, 2023, J INSTRUM, V18, DOI 10.1088/1748-0221/18/03/P03032
   Nocua ACL, 2021, EDUC SCI, V11, DOI 10.3390/educsci11090540
   Lee YS, 2023, Virtual Worlds, P36, DOI DOI 10.3390/VIRTUALWORLDS2010003
   Lorenz M, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0283565
   McAnally K, 2023, VIRTUAL REAL-LONDON, V27, P1187, DOI 10.1007/s10055-022-00724-5
   Merriam S.B., 2020, LEARNING ADULTHOOD C
   Michel N, 2009, HUM RESOUR DEV Q, V20, P397, DOI 10.1002/hrdq.20025
   Nguyen TTH, 2013, GRAPP INT C COMP GRA, P327
   Rehman IU, 2014, 2014 INTERNATIONAL CONFERENCE ON OPEN SOURCE SYSTEMS AND TECHNOLOGIES (ICOSST), P87, DOI 10.1109/ICOSST.2014.7029326
   Reyes-Zarate GG, 2023, Artificial Intelligence and Future Applications, V70
   Ruffaldi E, 2015, P I MECH ENG P-J SPO, V229, P92, DOI 10.1177/1754337115583199
   Sáiz-Manzanares MC, 2024, INT J HUM-COMPUT INT, V40, P3263, DOI 10.1080/10447318.2023.2188532
   Soori M, 2023, Journal of Advanced Manufacturing Science and Technology
   TN V., 2023, Grenze International Journal of Engineering & Technology (GIJET), V9
   Trebuna P, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095469
   Tsovaltzi D, 2010, INT J TECHNOL ENHANC, V2, P91, DOI 10.1504/IJTEL.2010.031262
   Van Merrienboer J.J., 2017, Ten steps to complex learning: A systematic approach to four-component instructional design
   Wolfartsberger J, 2023, COMPUT IND, V147, DOI 10.1016/j.compind.2022.103838
   Zhang C, 2023, ROBOT CIM-INT MANUF, V83, DOI 10.1016/j.rcim.2023.102571
NR 38
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17175-y
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW2V2
UT WOS:001155653100006
DA 2024-07-18
ER

PT J
AU Naeem, AB
   Soomro, AM
   Saim, HM
   Malik, H
AF Naeem, Awad Bin
   Soomro, Abdul Majid
   Saim, Hafiz Muhammad
   Malik, Hassaan
TI Smart road management system for prioritized autonomous vehicles under
   vehicle-to-everything (V2X) communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Vehicle-To-Everything Communication; Emergence Autonomous Vehicles;
   Smart Transportation System; SUMO
AB This paper works on smart transportation strategy for emergency autonomous and normal autonomous vehicles under the vehicle-to-every-things circumstance. All vehicles are fully autonomous, and all EAV communicate with the help of autonomous intersection management to handle traffic situations. When an autonomous emergency vehicle enters the road, then an autonomous intersection management system assigns this vehicle a high priority and all other autonomous vehicles with low priority. Following the priority queue principle and FIFO rule, all vehicles run smoothly so that there will not be too many collisions occurring on the road. Simulation works are conducted by using Simulation of Urban Mobility (SUMO), in which all proposed strategies are performed on different Pakistani routes By-pass Multan, M2-motorway, and Nishtar routes. According to our strategy Simulation result, the M2-motorway route takes 8.50 sec to complete its route for autonomous emergency vehicles, and normal autonomous vehicles take 10.55 sec to complete the route. The results identify that the proposed algorithm for different autonomous vehicles significant in reducing the average time delay caused by the algorithms and the corresponding variance, which shows the efficiency and fairness of the proposed strategy in autonomous intersection management.
C1 [Naeem, Awad Bin; Soomro, Abdul Majid; Malik, Hassaan] Natl Coll Business Adm & Econ, Dept Comp Sci, Multan 60000, Pakistan.
   [Saim, Hafiz Muhammad] Riphah Int Univ, Coll Sci, Dept Math, Lahore, Pakistan.
RP Naeem, AB (corresponding author), Natl Coll Business Adm & Econ, Dept Comp Sci, Multan 60000, Pakistan.
EM awadbinnaeem@gmail.com
RI binnaeem, awad/JRY-2119-2023
OI binnaeem, awad/0000-0002-1634-7653
NR 0
TC 3
Z9 3
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-16950-1
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ4S3
UT WOS:001142752200006
DA 2024-07-18
ER

PT J
AU Thomas, NM
   Jerome, SA
AF Thomas, Neetha Merin
   Jerome, S. Albert
TI Eisoc with ifodpso and dcnn classifier for diabetic retinopathy
   recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Diabetic Retinopathy (DR); Extended Iterative Self-Organizing clustering
   (EISOC); Improved Fractional-Order Darwinian Particle Swarm Optimization
   (IFODPSO); Deep Convolutional Neural Network (DCNN)
ID MICROANEURYSMS
AB Diabetic patients are tremendously increasing worldwide and it is a chronic disease that may cause complications in Eye, Heart, and Kidneys. Diabetic retinopathy (DR) plays a vital role that causing vision loss in diabetic patients, if not treated at an earlier stage. Nowadays, a lot of patients undergo eye screening per day, therefore ophthalmologists face a lot of challenges during the screening of Diabetic retinopathy. Also, manual screening leads to errors and is more time-consuming, the patients have to wait for much time in the clinic. Hence an automated system is essential to help the ophthalmologist as a secondary opinion in retinal screening. Normally, clinicians will detect the different signs of DR from the retinal images taken through fundus photography, may leads manual error. Here, this research work proposes a novel automated system through the implementation of deep learning techniques in biomedical analysis. This system includes the following stages pre-processing, segmentation, and classification. For analysis, the proposed research article work on retina fundus images is taken from the both Public dataset and the in-house clinical dataset from Chaithanya Eye Hospital Kerala. The first stage is to remove noise from the input image and enhance the contrast of the images. For noise reduction, a Bilateral Filter is utilized first, followed by enhancement utilizing Contrast Limited Adaptive Histogram Equalization with an unsharp technique. Then Thick Blood vessels are segmented from the enhanced image using the Extended Iterative Self-Organizing clustering (EISOC) Method. From the segmented image, GLCM features are extracted and then features are selected using the Improved Fractional-Order Darwinian Particle Swarm Optimization (IFODPSO) technique. Finally, a Deep CNN classifier is used which classifies the image as Diabetic Retinopathy (DR) or Normal case. Using IFODPSO with a DCNN classifier, 96.6% of the predictions are correct, 3.4% are wrong and the parameter such as Sensitivity is 92.5%, Specificity is 98.9%, Precision is 95.9% values are obtained. By way of classifier efficiency estimation, IFODPSO with DCNN classifier is higher than most other standard classifiers in the literature.
C1 [Thomas, Neetha Merin] Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kumaracoil, Tamil Nadu, India.
   [Jerome, S. Albert] Noorul Islam Ctr Higher Educ, Dept Biomed Engn, Kumaracoil, Tamil Nadu, India.
RP Thomas, NM (corresponding author), Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kumaracoil, Tamil Nadu, India.
EM neethathomas156@gmail.com; albertjerome@niuniv.com
RI Thomas, Neetha Merin/KCJ-4830-2024; JEROME, S ALBERT/AAJ-5555-2021
OI JEROME, S ALBERT/0009-0008-0155-8053; Thomas, Neetha
   Merin/0000-0002-6309-402X
FU The Authors thank the management of the Noorul Islam Center for Higher
   Education for their continuous support and encouragement. Also, we
   acknowledge the creator of freely-accessible public Messidor database of
   diabetic retinopathy. Then we would like to a; Noorul Islam Center for
   Higher Education
FX The Authors thank the management of the Noorul Islam Center for Higher
   Education for their continuous support and encouragement. Also, we
   acknowledge the creator of freely-accessible public Messidor database of
   diabetic retinopathy. Then we would like to acknowledge Chaithanya Eye
   hospital Kerala for providing the in-house clinical data. Finally, we
   would like to thank the anonymous reviewers for helping to organize this
   text.
CR Abràmoff MD, 2010, OPHTHALMOLOGY, V117, P1147, DOI 10.1016/j.ophtha.2010.03.046
   Adal KM, 2014, COMPUT METH PROG BIO, V114, DOI 10.1016/j.cmpb.2013.12.009
   Akram MU, 2013, PATTERN RECOGN, V46, P107, DOI 10.1016/j.patcog.2012.07.002
   Jerome SA, 2023, IETE J RES, V69, P5052, DOI 10.1080/03772063.2021.1978876
   Alyoubi WL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113704
   Aziz T, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-28680-3
   Bajwa A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13030393
   Butt MM, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12071607
   Das D, 2023, MULTIMED TOOLS APPL, V82, P29943, DOI 10.1007/s11042-022-14165-4
   Das D, 2022, MULTIMED TOOLS APPL, V81, P25613, DOI 10.1007/s11042-022-12642-4
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Graham B., 2015, Diabetic Retinopathy Detection
   Gu K, 2014, IEEE IMAGE PROC, P511, DOI 10.1109/ICIP.2014.7025102
   He AL, 2021, IEEE T MED IMAGING, V40, P143, DOI 10.1109/TMI.2020.3023463
   Khan KB, 2020, BIOMED RES INT, V2020, DOI 10.1155/2020/8365783
   Li T, 2019, INFORM SCIENCES, V501, P511, DOI 10.1016/j.ins.2019.06.011
   Li YH, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6142839
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Malhi A, 2023, INT J INTELL ROBOT, V7, P426, DOI 10.1007/s41315-022-00269-5
   Monteiro Fernando C., 2023, Procedia Computer Science, P1097, DOI 10.1016/j.procs.2023.01.389
   Nahiduzzaman M, 2023, EXPERT SYST APPL, V217, DOI 10.1016/j.eswa.2023.119557
   do Rio JMN, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-28347-z
   Oh K, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-81539-3
   Qin ZY, 2023, IEEE-CAA J AUTOMATIC, V10, P1192, DOI 10.1109/JAS.2023.123456
   Rani KV, 2022, IETE J RES, V68, P1485, DOI 10.1080/03772063.2019.1654935
   Rani KV, 2023, SIGNAL IMAGE VIDEO P, V17, P4571, DOI 10.1007/s11760-023-02693-x
   Rani KV, 2021, J AMB INTEL HUM COMP, V12, P7667, DOI 10.1007/s12652-020-02485-y
   Rani KV, 2021, IETE J RES, V67, P699, DOI 10.1080/03772063.2019.1565955
   Saha R, 2016, LECT NOTES ARTIF INT, V9693, P734, DOI 10.1007/978-3-319-39384-1_65
   Sahoo M, 2017, MEASUREMENT, V101, P138, DOI 10.1016/j.measurement.2017.01.027
   Saxena G., 2020, Intell.-Based Med., V3, DOI [10.1016/j.ibmed.2020.100022, DOI 10.1016/J.IBMED.2020.100022]
   Shaban M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0233514
   Shiney TSS, 2023, IETE J RES, V69, P4066, DOI 10.1080/03772063.2021.1958075
   Srivastava R, 2017, COMPUT METH PROG BIO, V138, P83, DOI 10.1016/j.cmpb.2016.10.017
   Tillett J., 2005, Proceedings of the 2nd Indian International Conference on Artificial Intelligence, P1474
   Ting DSW, 2019, BRIT J OPHTHALMOL, V103, P167, DOI 10.1136/bjophthalmol-2018-313173
   Toto L, 2019, J CLIN MED, V8, DOI 10.3390/jcm8040474
   Tsiknakis N, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104599
   Usman T.M., 2023, Int. J. Cogn. Comput. Eng, V4, P78, DOI [10.1016/j.ijcce.2023.02.002, DOI 10.1016/J.IJCCE.2023.02.002]
   Rani KV, 2020, IET IMAGE PROCESS, V14, P3355, DOI 10.1049/iet-ipr.2020.0407
   Wang GG, 2019, NEURAL COMPUT APPL, V31, P1995, DOI 10.1007/s00521-015-1923-y
   Wang JL, 2020, IET COMPUT VIS, V14, P1, DOI 10.1049/iet-cvi.2018.5508
   Wong RLM, 2021, EUR J OPHTHALMOL, V31, P536, DOI 10.1177/1120672120908719
   Yasashvini R, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14091932
   Zhou M, 2018, IEEE T BIO-MED ENG, V65, P521, DOI 10.1109/TBME.2017.2700627
NR 46
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 9
PY 2023
DI 10.1007/s11042-023-17244-2
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2OJ4
UT WOS:001083245400001
DA 2024-07-18
ER

PT J
AU Rani, J
   Anand, A
   Shivani, S
AF Rani, Jyoti
   Anand, Ashima
   Shivani, Shivendra
TI VMD-based ECG signal watermarking using image fusion: a robust and
   versatile approach for secure telemedical services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE ECG; VMD (variational mode decomposition); Watermarking; Pan tompkins;
   RDWT; MSVD; NSST; DtcwT; Image fusion
AB Presently, telemedical services in different forms are being exploited for the distribution of medical amenities. Security necessities including privacy, integrity, and authenticity require close attention and remedial actions. In this respect, watermarking techniques are providing a probable way to adequately handle the issues mentioned earlier. High embedding capacity and strong recovery are challenging issues for watermarking schemes. In addition, current techniques lack resilience against a variety of signal-processing assaults. This study presents a high embedding capacity-based ECG signal watermarking approach that embeds a fused watermark image, which is a composite of two medical images of the same dimensions, into the host ECG signal. Initially, VMD (Variational Mode Decomposition) is utilized to reduce the MA (Muscle Artifacts) noise. A hybridization of RDWT (redundant discrete wavelet transform)-MSVD (Multiresolution singular valued transform) is used to hide the fused image in the denoised carrier signal. The combination of transforms used provides shift-invariance, large embedding capacity, and computational efficiency. The imperceptibility of the suggested scheme has been measured in terms of peak signal-to-noise ratio and similarity structure index mode, whereas the scheme's robustness has been determined using NC (Normalized correlation). Finally, an experimental and comparative evaluation of the proposed framework justifies its versatility, robustness, and imperceptibility with the best improvement with other existing techniques.
C1 [Rani, Jyoti; Anand, Ashima; Shivani, Shivendra] Thapar Inst Engn & Technol, Comp Sci & Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Anand, A (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn, Patiala, Punjab, India.
EM ashima.anand@thapar.edu
CR Algarni AD, 2021, MULTIMED TOOLS APPL, V80, P10679, DOI 10.1007/s11042-020-09369-5
   Alseelawi N, 2022, INT J ONLINE BIOMED, V18, P114, DOI 10.3991/ijoe.v18i03.28011
   Amine K, 2022, CIRC SYST SIGNAL PR, V41, P5856, DOI 10.1007/s00034-022-02063-x
   Anand A, 2022, SUSTAIN COMPUT-INFOR, V33, DOI 10.1016/j.suscom.2021.100621
   Anand A, 2022, IEEE T COMPUT SOC SY, V9, P1265, DOI 10.1109/TCSS.2021.3125025
   Asha CS, 2019, IEEE ACCESS, V7, P40782, DOI 10.1109/ACCESS.2019.2908076
   Bhalerao S, 2022, CIRC SYST SIGNAL PR, V41, P5134, DOI 10.1007/s00034-022-02024-4
   Bhalerao S, 2019, PATTERN RECOGN LETT, V125, P463, DOI 10.1016/j.patrec.2019.06.004
   Civera M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051825
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Goyal LM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102941
   Hemdan EE, 2021, MULTIMED TOOLS APPL, V80, P1749, DOI 10.1007/s11042-020-09769-7
   Ibrahim SI, 2023, MED BIOL ENG COMPUT, V61, P155, DOI 10.1007/s11517-022-02697-8
   Jain N., 2021, Open Biomed. Eng. J., V15
   Johnson KA, 2023, WHOLE BRAIN ATLAS
   Khaldi A, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103540
   Kumar S, 2022, DIGIT SIGNAL PROCESS, V129, DOI 10.1016/j.dsp.2022.103648
   Ma WH, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020599
   Malghan PG, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103437
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Natgunanathan I, 2020, IEEE ACCESS, V8, P181233, DOI 10.1109/ACCESS.2020.3025533
   Nazari M, 2018, IEEE J BIOMED HEALTH, V22, P1059, DOI 10.1109/JBHI.2017.2734074
   Pallaw VK, 2022, JUCS: Journal of Universal Computer Science, V28
   Pei Gaole, 2022, IMIP 2022: 2022 4th International Conference on Intelligent Medicine and Image Processing., P24, DOI 10.1145/3524086.3524090
   Polinati S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112210975
   Sajedi Hedieh, 2020, Smart Health, V15, P15, DOI 10.1016/j.smhl.2019.100104
   Sanivarapu PV, 2020, PHYS ENG SCI MED, V43, P213, DOI 10.1007/s13246-019-00838-2
   Sharma N, 2021, Multimed Tools Appl, P1
   Sharma N, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.4.041207
   Sharma NK, 2023, BIOMED SIGNAL PROCES, V83, DOI 10.1016/j.bspc.2023.104633
   Singh Om Prakash, 2022, Advanced Machine Intelligence and Signal Processing. Lecture Notes in Electrical Engineering (858), P163, DOI 10.1007/978-981-19-0840-8_12
   Tang LF, 2022, IEEE-CAA J AUTOMATIC, V9, P2121, DOI 10.1109/JAS.2022.106082
   Tseng K-K., 2020, Int J Netw Secur, V22, P1
   Zhao XY, 2023, J MAR SCI ENG, V11, DOI 10.3390/jmse11071291
   Zhu ZQ, 2019, IEEE ACCESS, V7, P20811, DOI 10.1109/ACCESS.2019.2898111
NR 35
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-17087-x
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U0GP6
UT WOS:001081680200006
DA 2024-07-18
ER

PT J
AU Singh, KN
   Mantri, JK
AF Singh, Kamakhya Narain
   Mantri, Jibendu Kumar
TI Clinical decision support system based on RST with machine learning for
   medical data classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Classifier; Machine learning; Medical data; Recommendation; Rough set
ID ROUGH SET-THEORY; FEATURE-SELECTION
AB In the modern era of the digital world, digital devices have taken over many aspects of our lives, and the healthcare industry is no exception. Clinicians are also increasingly migrating patient healthcare data from paper to electronic formats. With the advancement of recent technology, the automated Clinical Decision Support System (CDSS) aims to make better prognoses and improve the quality of healthcare delivery. The proposed system focuses on significant improvement to satisfy the expectation of patients and doctors. In this work, we propose a framework to classify different diseases and provide outcomes to the patient in the form of recommendations. We focused on preprocessing and feature selection techniques to improve the performance and quality of care. Firstly, data is collected and preprocessed using encoding categorical features, min-max scaling and removing null and duplicate entries. After that, a Rough Set Theory (RST) is applied to select highly relevant and nonredundant features to reduce the dimension of the datasets. Then, six popular machine learning classifiers viz., K Nearest Neighbors (KNN), Linear Support Vector Machine (LSVM), Radial Basis Function Support Vector Machine (RBF SVM), Decision Tree (DT), Random Forest (RF) and Naive Bayes (NB) were employed on four different medical datasets such as breast cancer, heart failure, post-operative patient data and thyroid collected from UCI repository. Performance was compared with proposed classifiers and existing state-of-the-art classifiers in terms of accuracy, precision, recall and f1-score. Our proposed classifier DT achieved better accuracy for breast cancer, post-operative patient and thyroid while KNN achieved better accuracy for heart failure. Hence, overall performance strongly suggests that the proposed framework may help medical experts to diagnose various diseases more accurately.
C1 [Singh, Kamakhya Narain; Mantri, Jibendu Kumar] Maharaja Sriram Chandra Bhanja Deo Univ, Dept Comp Applicat, Baripada, India.
RP Singh, KN (corresponding author), Maharaja Sriram Chandra Bhanja Deo Univ, Dept Comp Applicat, Baripada, India.
EM kamakhya.vphcu@gmail.com; jkmantri@gmail.com
CR Abuaqel I, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATICS, HEALTH & TECHNOLOGY (ICIHT)
   Al Mehedi Hasan Md, 2021, ICBET '21: 2021 11th International Conference on Biomedical Engineering and Technology., P40, DOI 10.1145/3460238.3460245
   Ali SH, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE & COMPUTATIONAL INTELLIGENCE (CSCI), P1113, DOI [10.1109/CSCI.2016.211, 10.1109/CSCI.2016.0212]
   Bania RK, 2021, ARTIF INTELL MED, V114, DOI 10.1016/j.artmed.2021.102049
   Bania RK, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105122
   Bikku T, 2018, EGYPT INFORM J, V19, P191, DOI 10.1016/j.eij.2018.03.003
   Bolón-Canedo V, 2012, PATTERN RECOGN, V45, P531, DOI 10.1016/j.patcog.2011.06.006
   Bolón-Canedo V, 2019, INFORM FUSION, V52, P1, DOI 10.1016/j.inffus.2018.11.008
   Chouchoulas A, 2001, APPL ARTIF INTELL, V15, P843, DOI 10.1080/088395101753210773
   DIEBOLD FX, 1995, J BUS ECON STAT, V13, P253, DOI 10.2307/1392185
   Elhoseny M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46074-2
   Elshazly HI, 2012, PROCEEDINGS OF THE 2012 WORLD CONGRESS ON INFORMATION AND COMMUNICATION TECHNOLOGIES, P260, DOI 10.1109/WICT.2012.6409085
   Forghani Y, 2015, NEURAL PROCESS LETT, V42, P317, DOI 10.1007/s11063-014-9359-4
   Hall M. A., 1999, Correlation-based feature subset selection for machine learning
   Hamouda SKM, 2018, COMPUT METH PROG BIO, V153, P259, DOI 10.1016/j.cmpb.2017.10.016
   Han J, 2012, MOR KAUF D, P1
   Hansen JV, 2001, J EXP THEOR ARTIF IN, V13, P307, DOI 10.1080/09528130110067142
   Hoque N, 2018, COMPLEX INTELL SYST, V4, P105, DOI 10.1007/s40747-017-0060-x
   Inbarani HH, 2014, COMPUT METH PROG BIO, V113, P175, DOI 10.1016/j.cmpb.2013.10.007
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Lavanya B., 2022, International Journal of Sociotechnology and Knowledge Development, V14, P1, DOI 10.4018/IJSKD.289041
   Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66
   Moreno-Serra R, 2012, LANCET, V380, P917, DOI 10.1016/S0140-6736(12)61039-3
   Nahato KB, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/460189
   Newaz A., 2021, Informatics in Medicine Unlocked, V26, DOI [DOI 10.1016/J.IMU.2021.100772, 10.1016/j.imu.2021.100772]
   Parisi L, 2018, KNOWL-BASED SYST, V152, P1, DOI 10.1016/j.knosys.2018.03.033
   Parthaláin NM, 2010, IEEE T KNOWL DATA EN, V22, P305, DOI 10.1109/TKDE.2009.119
   Pawlak Z., 1991, ROUGH SETS THEORETIC, DOI DOI 10.1007/978-94-011-3534-4
   Roccetti M, 2020, MOBILE NETW APPL, V25, P1075, DOI 10.1007/s11036-020-01530-6
   Saeys Y, 2008, LECT NOTES ARTIF INT, V5212, P313, DOI 10.1007/978-3-540-87481-2_21
   Santos V, 2014, PROC TECH, V17, P223, DOI 10.1016/j.protcy.2014.10.232
   Seera M, 2014, EXPERT SYST APPL, V41, P2239, DOI 10.1016/j.eswa.2013.09.022
   Shamery ESA., 2018, J Babylon Univ/Pure Appl Sci, V2, P15
   Shilaskar S, 2013, EXPERT SYST APPL, V40, P4146, DOI 10.1016/j.eswa.2013.01.032
   Singh KN, 2022, AMBIENT INTELLIGENCE, P371
   Singh KN, 2021, Applications of Artificial Intelligence in COVID-19, P307
   Spencer R, 2020, DIGIT HEALTH, V6, DOI 10.1177/2055207620914777
   Suguna N., 2010, Journal of Computing, V2, P49
   Sun BZ, 2011, APPL MATH MODEL, V35, P1798, DOI 10.1016/j.apm.2010.10.010
   Sun YQ, 2018, GENES-BASEL, V9, DOI 10.3390/genes9050258
   Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4
   Temurtas F, 2009, EXPERT SYST APPL, V36, P944, DOI 10.1016/j.eswa.2007.10.010
   UCI Machine Learning Repository, About us
   Velayutham C., 2011, Journal of Electronic Science and Technology, V9, P193, DOI 10.3969/j.issn.1674-862X.2011.03.001
   Velayutham C., 2011, Int J Comput Intell Inform, V1, P64
   Wang J, 2019, SYST SCI CONTROL ENG, V7, P32, DOI 10.1080/21642583.2019.1620658
   Wang Y, 2009, ELE COM ENG, P68
   Xue B, 2016, IEEE T EVOLUT COMPUT, V20, P606, DOI 10.1109/TEVC.2015.2504420
   Zhang PF, 2021, INFORM FUSION, V68, P85, DOI 10.1016/j.inffus.2020.11.004
   Zhang Y, 2017, IEEE ACM T COMPUT BI, V14, P64, DOI 10.1109/TCBB.2015.2476796
   Zou F, 2020, SWARM EVOL COMPUT, V59, DOI 10.1016/j.swevo.2020.100749
NR 51
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-16802-y
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX9N7
UT WOS:001142351700003
DA 2024-07-18
ER

PT J
AU Altaf, I
   Kaul, A
AF Altaf, Insha
   Kaul, Ajay
TI Classifying collisions in road accidents using XGBOOST, CATBOOST and
   SALP SWARM based optimization algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Type of collision; Nature inspired algorithm; Improved salp swarm
   algorithm; Enhanced salp swarm algorithm; Time-varying binary salp swarm
   algorithm
ID FEATURE-SELECTION; CRASH-PREDICTION; MACHINE; TREE
AB Traffic accidents are the leading cause of death and injury in many developed nations. Anyone utilizing the road can meet an accident at any moment of time. The type of collision also plays a role in determining who is accountable for the accident. The biggest advantage of classifying collisions in road accidents can pave a way for safer roads and reduced accident rates. A novel approach is proposed for classifying the type of collisions that might take place between vehicles and near by pedestrians, obstacles etc. on roads. A total of six hybrid classifiers are introduced in this article namely ``XGBoostclassifierusingISSA ''\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$``{} \textit{XGBoost}\; classifier\; using\;ISSA''$$\end{document}, ``XGBoostclassifierusingESSA ''\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$``{} \textit{XGBoost}\; classifier\; using\; ESSA''$$\end{document}, ``XGBoostclassifierusing\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$``{} \textit{XGBoost}\; classifier\; using\;$$\end{document}TVBSSA ''\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ \textit{TVBSSA}''$$\end{document}, ``CatBoostclassifierusing\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$``{} \textit{CatBoost}\; classifier\; using$$\end{document}ISSA ''\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$ISSA''$$\end{document}, ``CatBoostclassifierusingESSA ''\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$``{} \textit{CatBoost}\; classifier\; using\; ESSA''$$\end{document}, and ``CatBoostclassifierusingTVBSSA ''\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$``{} \textit{CatBoost}\; classifier\; using\; \textit{TVBSSA}''$$\end{document}, The dataset considered in this article is the SWITRS dataset for classifying ``Type_of_Collision ''\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$``Type\_of\_Collision''$$\end{document}.
   A total of 103000 accidents are considered when determining the ``Type_of_Collision ''\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$``Type\_of\_Collision''$$\end{document}. It classifies the type of collisions using XGBoost algorithm, CatBoost Algorithm and three Nature Inspired Algorithms (NIA's) have been used at the feature selection stage. The NIA's considered for feature selection includes Improved Salp Swarm Algorithm (ISSA), Enhanced Salp Swarm Algorithm (ESSA), and Time-Varying Binary Salp Swarm Algorithm (TVBSSA). It is concluded that XGBoostclassifierusingISSA\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\textit{XGBoost}\; classifier\; using\; ISSA$$\end{document} presents good stability with fewer hyper-parameters and the highest accuracy under different levels of training data volume. The value of Accuracy, Mean Square Error, and ROC-Auc in XGBoost using ISSA is 90.40, 0.1624 and 97.75, respectively. Moreover, the confusion matrix and evaluation metrics of XGBoostclassifierusingISSA\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\textit{XGBoost}\; classifier\; using\; ISSA$$\end{document} performed better than the other two approaches. The findings of this study would be helpful in classifying the "type of collision". These findings are highly significant in smart city projects to effectively establish timely proactive strategies and improve road traffic safety.
C1 [Altaf, Insha] Univ Kashmir, DoCSE, Srinagar, Jammu And Kashm, India.
   [Kaul, Ajay] Natl Forens Sci Univ, Jinja, Uganda.
C3 University of Kashmir
RP Altaf, I (corresponding author), Univ Kashmir, DoCSE, Srinagar, Jammu And Kashm, India.
EM insha.altaf39@gmail.com; ajay.kaul@smvdu.ac.in
OI altaf, insha/0000-0003-1682-1076
CR Ahmadi A, 2020, J TRANSP SAF SECUR, V12, P522, DOI 10.1080/19439962.2018.1505793
   Al-Fakih AM, 2019, SAR QSAR ENVIRON RES, V30, P131, DOI 10.1080/1062936X.2019.1568298
   Al-Tashi Q, 2019, IEEE ACCESS, V7, P39496, DOI 10.1109/ACCESS.2019.2906757
   Algamal ZY, 2020, SAR QSAR ENVIRON RES, V31, P803, DOI 10.1080/1062936X.2020.1818616
   Algamal ZY, 2019, ADV DATA ANAL CLASSI, V13, P753, DOI 10.1007/s11634-018-0334-1
   Bahiru TK, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P1655, DOI 10.1109/ICICCT.2018.8473265
   Beshah Tibebe, 2013, International Journal of Tomography and Simulation, V22, P73
   Caliendo C, 2007, ACCIDENT ANAL PREV, V39, P657, DOI 10.1016/j.aap.2006.10.012
   Chong M., 2004, arXiv
   Cigdem A., 2018, International Journal of Intelligent Systems and Applications in Engineering, V6, P72, DOI [https://doi.org/10.18201/ijisae.2018637934, 10.18201/ijisae.2018637934]
   Emary E, 2015, PROCEDIA COMPUT SCI, V65, P623, DOI 10.1016/j.procs.2015.09.006
   Feng YH, 2018, IEEE ACCESS, V6, P10708, DOI 10.1109/ACCESS.2018.2809445
   Gicquel L, 2017, FRONT PSYCHIATRY, V8, DOI 10.3389/fpsyt.2017.00094
   Gude A, 2020, California traffic collision data from switrs
   Guozheng L., 2004, An introduction to support vector machines and other kernel-based learning methods, P3
   He ZY, 2010, COMPUT BIOL CHEM, V34, P215, DOI 10.1016/j.compbiolchem.2010.07.002
   Hegazy AE, 2020, J KING SAUD UNIV-COM, V32, P335, DOI 10.1016/j.jksuci.2018.06.003
   Hichem H, 2019, A new binary grasshopper optimization algorithm for feature selection problem
   Hossain M, 2012, ACCIDENT ANAL PREV, V45, P373, DOI 10.1016/j.aap.2011.08.004
   Hu P, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105746
   Kahya MA, 2021, NUMER ALGEBR CONTROL, V11, P87, DOI 10.3934/naco.2020017
   Kalina J, 2014, BIOCYBERN BIOMED ENG, V34, P10, DOI 10.1016/j.bbe.2013.09.007
   Karthik L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090972
   Karthikeyan S, 2014, INT J ADV MANUF TECH, V72, P1567, DOI 10.1007/s00170-014-5753-3
   Liao YP, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7120381
   Lin L, 2015, TRANSPORT RES C-EMER, V55, P444, DOI 10.1016/j.trc.2015.03.015
   Lv YS, 2009, 2009 INTERNATIONAL CONFERENCE ON MEASURING TECHNOLOGY AND MECHATRONICS AUTOMATION, VOL III, P547, DOI 10.1109/ICMTMA.2009.657
   Mafarja M, 2019, EXPERT SYST APPL, V117, P267, DOI 10.1016/j.eswa.2018.09.015
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirri S, 2020, COMPUTATION, V8, DOI 10.3390/computation8030074
   Osman AIA, 2021, AIN SHAMS ENG J, V12, P1545, DOI 10.1016/j.asej.2020.11.011
   Park Y, 2020, INT J SUSTAIN TRANSP, V14, P860, DOI 10.1080/15568318.2019.1641577
   Petrescu L, 2017, IOP CONF SER-MAT SCI, V252, DOI 10.1088/1757-899X/252/1/012001
   Petrovic Dorde, 2020, Transportation Research Procedia, V45, P161, DOI 10.1016/j.trpro.2020.03.003
   Priyanka A., 2014, International Journal of Computer Science Engineering Technology, V3, P1018
   Pu ZY, 2021, IEEE T INTELL TRANSP, V22, P964, DOI 10.1109/TITS.2019.2961699
   Qasim OS, 2020, INT J MATH ENG MANAG, V5, P697, DOI 10.33889/IJMEMS.2020.5.4.056
   Qasim OS, 2018, CHEMOMETR INTELL LAB, V182, P41, DOI 10.1016/j.chemolab.2018.08.016
   Qiu CY, 2019, GENET PROGRAM EVOL M, V20, P503, DOI 10.1007/s10710-019-09358-0
   Rezapour Mahdi, 2020, International Journal of Transportation Science and Technology, V9, P89, DOI 10.1016/j.ijtst.2019.10.002
   Rolison JJ, 2018, ACCIDENT ANAL PREV, V115, P11, DOI 10.1016/j.aap.2018.02.025
   Sachelarie A., 2020, IOP Conference Series: Materials Science and Engineering, V997, DOI 10.1088/1757-899X/997/1/012131
   Sayed GI, 2018, J CLASSIF, V35, P300, DOI 10.1007/s00357-018-9261-2
   Shang RH, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.07.001
   Shang RH, 2019, PATTERN RECOGN, V92, P219, DOI 10.1016/j.patcog.2019.03.026
   Shang RH, 2018, IEEE T CYBERNETICS, V48, P793, DOI 10.1109/TCYB.2017.2657007
   Shiau YR, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/170635
   Shrivastava P, 2017, COMPUT METH PROG BIO, V139, P171, DOI 10.1016/j.cmpb.2016.07.029
   Thomas P, 1999, P ANN C ASS, P101
   Tiwari G, 2020, INT J INJ CONTROL SA, V27, P35, DOI 10.1080/17457300.2020.1720255
   Wang JH, 2019, ACCIDENT ANAL PREV, V130, P160, DOI 10.1016/j.aap.2018.01.024
   Wood DP, 2005, P I MECH ENG D-J AUT, V219, P183, DOI 10.1243/095440705X6703
   Yan CK, 2019, HUM HERED, V84, P34, DOI 10.1159/000501652
   Yu RJ, 2013, ACCIDENT ANAL PREV, V51, P252, DOI 10.1016/j.aap.2012.11.027
   Zhang J, 2018, IEEE ACCESS, V6, P60079, DOI 10.1109/ACCESS.2018.2874979
   Zhang XF, 2013, CAN CON EL COMP EN, P775
   Zong F, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/475194
NR 57
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-16969-4
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900019
DA 2024-07-18
ER

PT J
AU Kang, SL
   Huo, H
AF Kang, Shilu
   Huo, Hua
TI Segmented selection networks for action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Action recognition; Significant features; Two-stream ConvNets; Selection
   function
AB In video-based action recognition tasks, effective and efficient utilization of spatial and temporal information remains challenging. To alleviate this issue, we propose a Segmented Selection Networks (SSN) that focus on selecting significant features for action recognition. This framework uses the improved two-stream ConvNets to learn the spatial and temporal features of different locations in the video, and obtain local classification scores corresponding to each location. However, some local classification scores are inconsistent with the ground-truth label of the video, which are counted as distractors. Therefore, we devise a selection function in segmented selection networks to discard these distractors according to the difference between local classification scores. Segmented selection networks is a framework for learning action features from the entire video, and can also weaken the influence of distractors on video prediction. In addition, this paper presents a re-optimize parameters method, which is able to re-optimize the parameters of network based on the ground-truth labels of video and the classification scores of the other modality. Through this method, the temporal stream network and the spatial stream network can be connected during training to learn the interaction of the two modalities. The segmented selection networks are trained and evaluated on the standard video actions benchmarks of UCF101 and HMDB51, and the experimental results are satisfactory, which confirms the effectiveness of the proposed approaches.
C1 [Kang, Shilu; Huo, Hua] Henan Univ Sci & Technol, Coll Informat Engn, Luoyang 471023, Peoples R China.
C3 Henan University of Science & Technology
RP Huo, H (corresponding author), Henan Univ Sci & Technol, Coll Informat Engn, Luoyang 471023, Peoples R China.
EM ksl_life@163.com; pacific_huo@126.com
OI Huo, Hua/0000-0001-9545-5443
FU National Natural Science Foundation of China [61672210]; National
   Natural Science Foundation of China [2017YFB 0306403]; National Key
   Research and Development Program of China [162300410183]; Research
   Program of Foundation and Advanced Technology of Henan in China
FX This research is supported by the National Natural Science Foundation of
   China (61672210), the National Key Research and Development Program of
   China (2017YFB 0306403), and the Research Program of Foundation and
   Advanced Technology of Henan in China (162300410183).
CR Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chéron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368
   Diba A, 2018, LECT NOTES COMPUT SC, V11208, P299, DOI 10.1007/978-3-030-01225-0_18
   Diba A, 2017, PROC CVPR IEEE, P1541, DOI 10.1109/CVPR.2017.168
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du WB, 2017, IEEE I CONF COMP VIS, P3745, DOI 10.1109/ICCV.2017.402
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Girdhar R, 2019, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2019.00033
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li J, 2020, IEEE T MULTIMEDIA, V22, P2990, DOI 10.1109/TMM.2020.2965434
   Li Y, 2020, PROC CVPR IEEE, P906, DOI 10.1109/CVPR42600.2020.00099
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Ma CY, 2019, SIGNAL PROCESS-IMAGE, V71, P76, DOI 10.1016/j.image.2018.09.003
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Omi K, 2022, IEICE T INF SYST, VE105D, P2119, DOI 10.1587/transinf.2022EDP7058
   Pan X., 2022, arXiv
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Piergiovanni AJ, 2021, PROC CVPR IEEE, P4122, DOI 10.1109/CVPR46437.2021.00411
   Piergiovanni AJ, 2019, PROC CVPR IEEE, P9937, DOI 10.1109/CVPR.2019.01018
   Ranasinghe K, 2022, PROC CVPR IEEE, P2864, DOI 10.1109/CVPR52688.2022.00289
   Sharif M, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0236-8
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Truong TD, 2022, PROC CVPR IEEE, P19998, DOI 10.1109/CVPR52688.2022.01940
   Thatipelli A, 2022, PROC CVPR IEEE, P19926, DOI 10.1109/CVPR52688.2022.01933
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Wang H, 2020, PROC CVPR IEEE, P349, DOI 10.1109/CVPR42600.2020.00043
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2021, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR46437.2021.00193
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wang LM, 2016, INT J COMPUT VISION, V119, P254, DOI 10.1007/s11263-015-0859-0
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Yue Meng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P86, DOI 10.1007/978-3-030-58571-6_6
   Zong M, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104108
NR 46
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-17001-5
EA OCT 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900006
DA 2024-07-18
ER

PT J
AU Sumalakshmi, C
   Vasuki, P
AF Sumalakshmi, Ch
   Vasuki, P.
TI Ameliorate grasshopper optimization algorithm based long short term
   memory classification for face emotion recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ameliorate grasshopper optimization algorithm; Convolution neural
   network; Face emotion recognition; Long short term memory classifier and
   feature optimization
AB Face Emotion Recognition (FER) has become a vital need for human interaction with machines in the virtual world. In virtual classroom, the emotional states of the students are necessary for better learning and communication. In this work, Ameliorate Grasshopper Optimization Algorithm (AGOA) based Long Short Term Memory (LSTM) classification for Face emotion recognition system is presented. AGOA is proposed by enhancing the conventional Grasshopper Optimization Algorithm (GOA) with opposition-based learning, levy flight mechanism and Gaussian mutation for the selection of optimized features. Convolution Neural Network (CNN) based feature extraction is adopted and the LSTM unit classifies the basic human emotions such as fear, happy, disgust, anger, sad, surprise and normal. The exploratory work is done using the YALE face database and it resulted in 93.90% recognition accuracy. The results attained shows that the performance measures such as precision, recall, specificity, F-Measure, sensitivity and Area under Curve (AUC) are higher in AGOA-LSTM based system rather than the system without AGOA and it also resulted in reduced error rate.
C1 [Sumalakshmi, Ch] Koneru Lakshmaiah Educ Fdn, Comp Sci & Engn, Hyderabad 500075, Telangana, India.
   [Vasuki, P.] Bharath Inst Higher Educ & Res, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Bharath Institute of Higher Education & Research
RP Sumalakshmi, C (corresponding author), Koneru Lakshmaiah Educ Fdn, Comp Sci & Engn, Hyderabad 500075, Telangana, India.
EM sumascarlet@gmail.com
CR Ahmady M, 2022, FUZZY SET SYST, V443, P155, DOI 10.1016/j.fss.2022.03.013
   Ayeche F, 2021, PATTERN ANAL APPL, V24, P1095, DOI 10.1007/s10044-021-00972-2
   Bendjillali RI, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030324
   Benkaddour MK, 2021, INFORM-INT J COMPUT, V45, P697, DOI 10.31449/inf.v45i5.3262
   Boughida A, 2022, EVOL SYST-GER, V13, P331, DOI 10.1007/s12530-021-09393-2
   Buhari AM, 2022, MULTIMED TOOLS APPL, V81, P9151, DOI 10.1007/s11042-021-11625-1
   Dantas AC, 2022, MULTIMED TOOLS APPL, V81, P25947, DOI 10.1007/s11042-022-12810-6
   Ewees AA, 2018, EXPERT SYST APPL, V112, P156, DOI 10.1016/j.eswa.2018.06.023
   Gan CQ, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104342
   Hammouche R, 2022, EXPERT SYST APPL, V197, DOI 10.1016/j.eswa.2022.116743
   Jampour M, 2021, 2021 5 INT C PATT RE, P1
   Kim CM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082956
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Krumhuber EG, 2021, EMOTION, V21, P447, DOI 10.1037/emo0000712
   Kuang Q, 2021, Journal of Physics: Conference Series, V3
   Lestariningati SI, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11172723
   Li J, 2020, NEUROCOMPUTING, V411, P340, DOI 10.1016/j.neucom.2020.06.014
   Li SL, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/1027735
   Meraihi Y, 2021, IEEE ACCESS, V9, P50001, DOI 10.1109/ACCESS.2021.3067597
   Muazu A., 2021, Int J Adv Res, V9, P1141, DOI DOI 10.21474/IJAR01/12951
   Muhammad G, 2021, IEEE INTERNET THINGS, V8, P16894, DOI 10.1109/JIOT.2021.3058587
   Mungra D, 2020, MULTIMED TOOLS APPL, V79, P2285, DOI 10.1007/s11042-019-08397-0
   Nasim S., 2022, KIET J Comput Inform Sci, V5, P62
   Panichkriangkrai C, 2021, Sci Eng Health Tudies
   Patel Hiral A., 2022, International Conference on Innovative Computing and Communications: Proceedings of ICICC 2021. Advances in Intelligent Systems and Computing (1389), P95, DOI 10.1007/978-981-16-3071-2_9
   Raeesi F, 2020, STRUCTURES, V26, P406, DOI 10.1016/j.istruc.2020.04.026
   S.D. Learning, 2016, CS231n: Convolutional Neural Networks for Visual Recognition
   Sajjad M, 2020, MOBILE NETW APPL, V25, P1611, DOI 10.1007/s11036-019-01366-9
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Sreedharan NPN, 2018, IET BIOMETRICS, V7, P490, DOI 10.1049/iet-bmt.2017.0160
   Vrij A, 2019, ANNU REV PSYCHOL, V70, P295, DOI 10.1146/annurev-psych-010418-103135
   Zhang HM, 2019, POWER ELECTRON POWER, P217, DOI 10.1007/978-3-319-89378-5_9
NR 32
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-16837-1
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500010
DA 2024-07-18
ER

PT J
AU Shingade, SD
   Mudhalwadkar, RP
AF Shingade, Sachin Dattatraya
   Mudhalwadkar, Rohini Prashant
TI Analysis of crop prediction models using data analytics and ML
   techniques: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Agriculture; Crop prediction; Deep learning; Machine learning;
   Recommendation; Crop varieties; Environmental factors
ID AGRICULTURAL RECOMMENDATION SYSTEM; YIELD; SOIL
AB One of the essential fields contributing to a nation's development is Agriculture. An efficient recommendation of crops is essential for strategic plan determination in the agricultural sector for promoting the farmer's income and import-export policies. Crop prediction techniques are undertaken to suggest the types of crops to be grown in the specified field through the utilization of machine and deep learning approaches. Accurately predicting crops with minimized error has been highly challenging in recent trends. The proposed article provides a comprehensive review using machine and deep learning approaches to fulfil the increased importance of effective crop prediction. Initially, the recent scenario of crops is presented along with the short-term discussion over global need, worldwide demand and supply. Then the critical evaluation based on the existing reviews is made, and a comparative analysis is provided with a lack of review. Different machine and deep learning approaches are surveyed to analyze the performance variations and suggest suitable crops. Accordingly, the merits and demerits of various crop recommendation systems are analyzed. The analysis corresponds to crop varieties used for recommendation and diverse environmental factors considered in different datasets. Through this research, effective analysis of ML and DL methodologies in suitable crop recommendations can be analyzed. The different forms of crop varieties and environmental factors considered for better prediction of crops can be noticed. Also, the different forms of dataset used, challenges analyzed, and applications to be utilized are described. The reviews undertaken have represented an effective inclination towards learning models in predicting crops. The challenges can be identified through this survey, and it paves the way for developing an effective crop prediction model in future works.
C1 [Shingade, Sachin Dattatraya] SPPU Pune, Dept Technol DOT SPPU, Maharashtra 411007, India.
   [Shingade, Sachin Dattatraya] SPPU Pune, MIT Acad Engn, Maharashtra 411007, India.
   [Mudhalwadkar, Rohini Prashant] SPPU Pune, Govt Coll Engn COEP, DOT, Dept Instrumentat & Control Engn, Maharashtra, India.
RP Shingade, SD (corresponding author), SPPU Pune, Dept Technol DOT SPPU, Maharashtra 411007, India.; Shingade, SD (corresponding author), SPPU Pune, MIT Acad Engn, Maharashtra 411007, India.
EM sachin.shingade@mitaoe.ac.in
CR Ahila SS., 2020, Eur J Mol Clin Med, V7, P2075
   Akshatha K. R., 2018, International Journal of Research in Engineering, Science and Management (IJRESM), V1, P58
   Angular K., 2021, Turkish Journal of Computer and Mathematics Education, V12, P1784
   Anupama CG, 2021, MATER TODAY-PROC
   Arifin O., 2021, Sci J Inform, V8, P43
   Attaluri SS., 2020, J Appl Technol Innov, V4, P1
   Bandara P., 2020, Int J Comput Appl, V975, P8887
   Chelliah BJ, 2024, ENVIRON DEV SUSTAIN, V26, P1731, DOI 10.1007/s10668-022-02783-9
   Choudhari S, Crop recommendation based on soil analysis using deep learning
   Chougule Archana, 2019, Progress in Advanced Computing and Intelligent Engineering. Proceedings of ICACIE 2017. Advances in Intelligent Systems and Computing (AISC 714), P205, DOI 10.1007/978-981-13-0224-4_19
   Elbasi E, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13169288
   Garanayak M, 2021, INT J AGRIC ENVIRON, V12, P1, DOI 10.4018/IJAEIS.20210101.oa1
   Goldstein A, 2018, PRECIS AGRIC, V19, P421, DOI 10.1007/s11119-017-9527-4
   Gopi PSS, 2023, INTELL AUTOM SOFT CO, V36, P313, DOI 10.32604/iasc.2023.029756
   Gosai D., 2021, Int. J. Sci. Res. Comput. Sci. Eng. Inf. Technol, DOI [10.32628/CSEIT2173129, DOI 10.32628/CSEIT2173129]
   Gupta R, 2021, IEEE ACCESS, V9, P137869, DOI 10.1109/ACCESS.2021.3117247
   Hatem Y, 2022, EGYPT J BOT, V62, P291, DOI 10.21608/ejbo.2022.83200.1731
   Jadhav R., 2022, J Algebr Stat, V13, P426
   Jain N., 2017, International Research Journal of Engineering and Technology, V4, P1530
   Joshi H., 2018, International Research Journal of Engineering and Technology (IRJET), V5, P476
   Jyothika P, Crop recommendation system to maximize crop yield using deep neural network, V12, P119
   Keerthan Kumar T.G., 2019, Int. J. Innov. Technol. Explor. Eng., V9, P1301
   Kuanr M., 2018, International Journal of Engineering & Technology, V7, P277, DOI 10.14419/ijet.v7i4.15.23006
   Kumar A, Intelligent Crop Recommendation System Using ML
   Lacasta J, 2018, COMPUT ELECTRON AGR, V152, P82, DOI 10.1016/j.compag.2018.06.049
   Madhuri J., 2021, INDIAN J SCI TECHNOL, V14, P1587, DOI DOI 10.17485/IJST/v14i19.64
   Mohan P., 2018, Int. J. Intell. Eng. Syst, V11, P167, DOI DOI 10.22266/IJIES2018.0831.17
   Motwani A., 2022, INT C ADVANCEMENT TE, P1
   Mythili K., 2021, INDIAN J SCI TECHNOL, V14, P1325, DOI [10.17485/IJST/v14i17.450, DOI 10.17485/IJST/v14i17.450]
   Mythili K., 2021, Annals of the Romanian Society for Cell Biology, V25, P4783
   Nischitha K., 2020, Int J Eng Res Technol (IJERT), V9, P23
   Parikh Dhruv Piyush, 2021, International Journal of Advanced Research in Science, Communication, and Technology(IJARSCT), V6, DOI [10.48175/IJARSCT-1509, DOI 10.48175/IJARSCT-1509]
   Patel K, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105779
   Patil D, 2020, Neural Networks and Crop Recommendation based on DecisionTree, V09, P394
   Patil S, 2018, METHODOLOGY, V3
   Raja SKS, 2017, 2017 IEEE TECHNOLOGICAL INNOVATIONS IN ICT FOR AGRICULTURE AND RURAL DEVELOPMENT (TIAR), P194, DOI 10.1109/TIAR.2017.8273714
   Rajak RK., 2017, Int Res J Eng Technol, V4, P950
   Rajeswari S, 2019, COMPUT ELECTRON AGR, V156, P530, DOI 10.1016/j.compag.2018.12.013
   Ramachandran V, 2022, WATER-SUI, V14, DOI 10.3390/w14050719
   Reddy D. A., 2019, International Journal of Scientific Research in Science and Technology, V6, P485, DOI DOI 10.32628/IJSRST196172
   Rehman M, 2022, APPL ARTIF INTELL, V36, DOI 10.1080/08839514.2021.2012055
   Saranya N., 2020, Int J Eng Res Technol, V9, P671, DOI [10.17577/IJERTV9IS020315, DOI 10.17577/IJERTV9IS020315]
   Satam P, 2023, Smart crop prediction using Ml, V05, P6901
   Selvi DP, 2021, Int J Eng Trends Appl (IJETA), V8, P1
   Setiadi T., 2020, Int. J. Sci. Technol. Res, V9, P4750
   Simo WF, 2021, A fuzzy logic approach on selecting crop and identifying planting methodology using environment and spatial factors, P806
   Sinha A., 2022, Int J Res Eng Sci Manag, V5, P130
   Suresh G., 2021, Int. J. Modern Agric., V10, P906
   Suruliandi A, 2021, MATH COMP MODEL DYN, V27, P117, DOI 10.1080/13873954.2021.1882505
   Taher KI, 2021, Asian J Res Comput, VSci8, P17
   Thorat T, 2023, SMART AGR TECHNOL, V3, DOI 10.1016/j.atech.2022.100114
   Ujjainia S, A Crop Recommendation System to Improve Crop Productivity using Ensemble Technique
   Varsha A, 2020, Int J Sci Res Eng Trends, V6
   Wang H, 2020, CURR OPIN PLANT BIOL, V54, P34, DOI 10.1016/j.pbi.2019.12.010
   Xiong YH, 2020, COMPUT ELECTRON AGR, V177, DOI 10.1016/j.compag.2020.105712
   Yamaç SS, 2020, AGR WATER MANAGE, V228, DOI 10.1016/j.agwat.2019.105875
   Yan L, 2021, MOB INF SYST, V2021, DOI 10.1155/2021/5046244
   Zhou SW, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su141711086
NR 58
TC 0
Z9 0
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-17038-6
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100015
DA 2024-07-18
ER

PT J
AU Karnani, S
   Agrawal, N
   Kumar, R
AF Karnani, Suruchi
   Agrawal, Neha
   Kumar, Rohit
TI A comprehensive survey on low-rate and high-rate DDoS defense approaches
   in SDN: taxonomy, research challenges, and opportunities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Software defined networking; Distributed denial of service attacks;
   High-rate DDoS (HR-DDoS) attacks; Low-rate DDoS (LR-DDoS) attacks;
   Defense approaches; Performance metrics
ID SOFTWARE-DEFINED NETWORKING; ATTACK DETECTION; INTRUSION DETECTION;
   ANOMALY DETECTION; MITIGATION; SECURITY; MACHINE; COUNTERMEASURE
AB Software Defined Networking (SDN) expands the networking capabilities using abstraction, open-source protocols, energy efficiency, and programmable features for controlling the forwarding devices at the network edges and intensifying the network performance. Despite all the unprecedented features, SDN still might get exploited by an attacker to launch Distributed Denial of Service (DDoS) attacks at SDN planes i.e. Application, Control, and Data planes. Substantially, the DDoS attacks have been implemented by sending volumetric malicious traffic to exhaust the targeted resources. Such attacks can be easily observed and detected due to their high packet rates. Thus, now attackers are fascinated by the Low-Rate DDoS (LR-DDoS) attacks. In recent years, many efforts have been devoted to defending against the DDoS attacks in SDN. As the attackers benefit from the programmable nature of SDN, an in-detail review of various DDoS attacks and their corresponding defense approaches are essential. Initially, this paper presents a conceptual architecture of SDN and discusses the vulnerable locations in each plane that are exploited by the attacker for launching the DDoS attacks. Secondly, the work offers a detailed classification of DDoS attacks (HR-DDoS and LR-DDoS) concerning the SDN planes and the corresponding defense solutions. The convergence point of this research work is to discover the related security issues and stimulate the network researchers to counter these issues by employing the respective SDN DDoS defense solutions efficiently. Finally, the work gets concluded with a focus on the respective future challenges.
C1 [Karnani, Suruchi] Amity Univ Gwalior, CSE Dept, Gwalior, Madhya Pradesh, India.
   [Agrawal, Neha] Indian Inst Informat Technol Sri City, CSE Grp, Chittoor, Andhra Pradesh, India.
   [Kumar, Rohit] Shiv Nadar Univ, CSE Dept, Chennai, Tamil Nadu, India.
C3 Shiv Nadar University
RP Agrawal, N (corresponding author), Indian Inst Informat Technol Sri City, CSE Grp, Chittoor, Andhra Pradesh, India.
EM suruchi.baori@gmail.com; nehaiiitm345@gmail.com;
   rohitkumar@snuchennai.edu.in
RI Agrawal, Neha/AAS-9360-2020; Kumar, Rohit/AES-6893-2022
OI Agrawal, Neha/0000-0002-7254-079X; Kumar, Rohit/0000-0002-9670-0671;
   Karnani Baori, Suruchi/0000-0002-9826-9985
CR Agrawal N, 2019, IEEE COMMUN SURV TUT, V21, P3769, DOI 10.1109/COMST.2019.2934468
   Agrawal N, 2017, INF SECUR J, V26, P61, DOI 10.1080/19393555.2017.1282995
   Akyildiz IF, 2016, IEEE NETWORK, V30, P52, DOI 10.1109/MNET.2016.7474344
   Al-Duwairi B, 2020, J NETW SYST MANAG, V28, P1366, DOI 10.1007/s10922-020-09540-1
   Alhijawi B, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107706
   Ali A, 2020, IEEE ACCESS, V8, P109662, DOI 10.1109/ACCESS.2020.3002333
   Alimohammadifar A, 2018, LECT NOTES COMPUT SC, V11099, P463, DOI 10.1007/978-3-319-98989-1_23
   Alshraa AS, 2019, P 3 INT C FUT NETW D, P1, DOI [10.1145/3341325.3342016, DOI 10.1145/3341325.3342016]
   Ambrosin M, 2017, IEEE ACM T NETWORK, V25, P1206, DOI 10.1109/TNET.2016.2626287
   Viet AN, 2017, 2017 14TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY (ECTI-CON), P660, DOI 10.1109/ECTICon.2017.8096324
   Pérez-Díaz JA, 2020, IEEE ACCESS, V8, P155859, DOI 10.1109/ACCESS.2020.3019330
   Bakhshi T, 2017, WIREL COMMUN MOB COM, P1, DOI 10.1155/2017/7191647
   Balarezo JF, 2022, ENG SCI TECHNOL, V31, DOI 10.1016/j.jestch.2021.09.011
   Bawany NZ, 2017, ARAB J SCI ENG, V42, P425, DOI 10.1007/s13369-017-2414-5
   Braga R, 2010, C LOCAL COMPUT NETW, P408, DOI 10.1109/LCN.2010.5735752
   Camp LJ, 2019, login Usenix Mag, V44
   Catillo M, 2019, J HIGH SPEED NETW, V25, P349, DOI 10.3233/JHS-190620
   Chung CJ, 2013, IEEE T DEPEND SECURE, V10, P198, DOI 10.1109/TDSC.2013.8
   Conti M, 2019, WIREL NETW, V25, P2751, DOI 10.1007/s11276-019-01991-y
   Corbett C, 2014, IEEE SECUR PRIV, V12, P44, DOI 10.1109/MSP.2013.136
   Dabbagh M, 2015, IEEE COMMUN MAG, V53, P73, DOI 10.1109/MCOM.2015.7120048
   Dalmazo BL, 2021, INT J NETW MANAG, V31, DOI 10.1002/nem.2163
   Dantas YG, 2014, 2014 IEEE JOINT INTELLIGENCE AND SECURITY INFORMATICS CONFERENCE (JISIC), P75, DOI 10.1109/JISIC.2014.21
   Dayal N, 2023, COMPUT SECUR, V130, DOI 10.1016/j.cose.2023.103269
   Dayal N, 2017, INT CONF COMMUN SYST, P274, DOI 10.1109/COMSNETS.2017.7945387
   Dayal N, 2016, SECUR COMMUN NETW, V9, P6386, DOI 10.1002/sec.1759
   Dehkordi AB, 2021, J SUPERCOMPUT, V77, P2383, DOI 10.1007/s11227-020-03323-w
   Dodia P, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P2645, DOI 10.1145/3319535.3363277
   Dong P, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7510992
   Dong S, 2019, IEEE ACCESS, V7, P80813, DOI 10.1109/ACCESS.2019.2922196
   Feamster N, 2014, ACM SIGCOMM COMP COM, V44, P87, DOI 10.1145/2602204.2602219
   Fichera S, 2015, COMPUT NETW, V92, P89, DOI 10.1016/j.comnet.2015.08.038
   Ghasabi M, 2021, INTELL DATA ANAL, V25, P155, DOI 10.3233/IDA-194796
   Gkounis D, 2016, ACM SIGCOMM COMP COM, V46, P5, DOI 10.1145/2935634.2935636
   Gong CQ, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5264
   Gupta V, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P392, DOI 10.1109/ICACCI.2018.8554459
   Gurusamy U, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.5326
   Han BA, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/9649643
   Hong K, 2018, IEEE COMMUN LETT, V22, P688, DOI 10.1109/LCOMM.2017.2766636
   Houda ZA, 2020, IEEE T NETW SERV MAN, V17, P2523, DOI 10.1109/TNSM.2020.3014870
   Hua JY, 2021, IEEE T INF FOREN SEC, V16, P1029, DOI 10.1109/TIFS.2020.3013093
   Huang XL, 2020, COMPUT NETW, V170, DOI 10.1016/j.comnet.2020.107119
   Jaafar GA, 2019, J COMPUT NETW COMMUN, V2019, DOI 10.1155/2019/1283472
   Jarraya Y, 2014, IEEE COMMUN SURV TUT, V16, P1955, DOI 10.1109/COMST.2014.2320094
   Kalkan K, 2018, IEEE J SEL AREA COMM, V36, P2358, DOI 10.1109/JSAC.2018.2869997
   Kalkan K, 2017, IEEE SYMP COMP COMMU, P669, DOI 10.1109/ISCC.2017.8024605
   Kang MS, 2016, 23RD ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2016), DOI 10.14722/ndss.2016.23147
   Karakus M, 2017, J NETW COMPUT APPL, V80, P200, DOI 10.1016/j.jnca.2016.12.019
   Karnani S, 2023, INF SECUR J, V32, P444, DOI 10.1080/19393555.2022.2111004
   Kaur N, 2017, SIN'17: PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON SECURITY OF INFORMATION AND NETWORKS, P179, DOI 10.1145/3136825.3136881
   Kaur S, 2021, COMPUT SECUR, V110, DOI 10.1016/j.cose.2021.102423
   Kim S, 2017, LECT NOTES COMPUT SC, V10493, P135, DOI 10.1007/978-3-319-66399-9_8
   Klöti R, 2013, I C NETWORK PROTOCOL
   Kramer Lukas, 2015, Research in Attacks, Intrusions and Defenses. 18th International Symposium, RAID 2015. Proceedings: LNCS 9404, P615, DOI 10.1007/978-3-319-26362-5_28
   Kreutz D, 2015, P IEEE, V103, P14, DOI 10.1109/JPROC.2014.2371999
   Kumar P, 2018, IEEE T NETW SERV MAN, V15, P1545, DOI 10.1109/TNSM.2018.2861741
   Lee S, 2016, SDN-NFV SECURITY'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL WORKSHOP ON SECURITY IN SOFTWARE DEFINED NETWORKS & NETWORK FUNCTION VIRTUALIZATION, P23, DOI 10.1145/2876019.2876024
   Lee SB, 2013, PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES (CONEXT '13), P417, DOI 10.1145/2535372.2535398
   Li HD, 2019, PROCEEDINGS OF THE ACM INTERNATIONAL WORKSHOP ON SECURITY IN SOFTWARE DEFINED NETWORKS & NETWORK FUNCTION VIRTUALIZATION (SDN-NFV '19), P13, DOI 10.1145/3309194.3309199
   Li P, 2023, COMPUT NETW, V228, DOI 10.1016/j.comnet.2023.109755
   Li SF, 2019, CHINESE J ELECTRON, V28, P404, DOI 10.1049/cje.2019.01.017
   Lim S, 2014, INT CONF UBIQ FUTUR, P63, DOI 10.1109/ICUFN.2014.6876752
   Lukaseder T, 2018, L N INST COMP SCI SO, V255, P102, DOI 10.1007/978-3-030-01704-0_6
   Lukaseder T, 2018, C LOCAL COMPUT NETW, P299, DOI 10.1109/LCN.2018.8638036
   Maleh Yassine, 2023, Journal of Reliable Intelligent Environments, P201, DOI 10.1007/s40860-022-00171-8
   Marin E, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P1101, DOI 10.1145/3319535.3354194
   Mohammadi R, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.4061
   Mohammadi R, 2017, IEEE T NETW SERV MAN, V14, P487, DOI 10.1109/TNSM.2017.2701549
   Nagarathna R, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATION AND NETWORKING (ICSCN)
   Nayak J, 2022, J SUPERCOMPUT, V78, P14866, DOI 10.1007/s11227-022-04453-z
   Nehra A, 2017, 2017 IEEE 7TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE IEEE CCWC-2017
   Novaes MP, 2020, IEEE ACCESS, V8, P83765, DOI 10.1109/ACCESS.2020.2992044
   Oo MM, 2019, J COMPUT NETW COMMUN, V2019, DOI 10.1155/2019/8012568
   opennetworking, Analysis for the SDN Architecture
   Pascoal TA, 2020, COMPUT NETW, V173, DOI 10.1016/j.comnet.2020.107223
   Pascoal TA, 2017, IFIP ADV INF COMM TE, V502, P17, DOI 10.1007/978-3-319-58469-0_2
   Phan TV, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9013585
   Phan TV, 2020, IEEE T NETW SERV MAN, V17, P1349, DOI 10.1109/TNSM.2020.3004415
   Pradeepa RR, 2020, SOFT COMPUT, V24, P10205, DOI 10.1007/s00500-019-04534-x
   Pradhan Aayush, 2020, Procedia Computer Science, V171, P2581, DOI 10.1016/j.procs.2020.04.280
   Ramprasath J, 2024, IETE J RES, V70, P70, DOI 10.1080/03772063.2022.2142163
   Ravi N, 2020, IEEE T NETW SERV MAN, V17, P1715, DOI 10.1109/TNSM.2020.2997734
   Saharan S, 2019, INT CONF COMMUN SYST, P606, DOI [10.1109/COMSNETS.2019.8711258, 10.1109/comsnets.2019.8711258]
   Sahoo KS, 2020, IEEE ACCESS, V8, P132502, DOI 10.1109/ACCESS.2020.3009733
   Sahoo KS, 2018, FUTURE GENER COMP SY, V89, P685, DOI 10.1016/j.future.2018.07.017
   Salman O, 2016, IEEE MEDITERR ELECT, DOI 10.1109/melcon.2016.7495430
   Sanguankotchakorn T, 2019, ASIA-PAC NETW OPER M, DOI 10.23919/apnoms.2019.8893030
   Sardana A, 2008, J INF ASSUR SECUR, V3, P1
   Sebbar A, 2019, INT WIREL COMMUN, P90, DOI 10.1109/iwcmc.2019.8766552
   Sen Baidya S, 2020, WIRELESS OPTIC COMM, P80, DOI 10.1109/wocc48579.2020.9114932
   Shafi Q, 2019, INT BHURBAN C APPL S, P624, DOI 10.1109/IBCAST.2019.8667147
   Shan-Hsiang Shen, 2018, ACM SIGMETRICS Performance Evaluation Review, V46, P95, DOI 10.1145/3305218.3305255
   Shang G, 2017, IEEE INFOCOM SER
   Shtern M, 2014, INT CONF CLOUD ENG, P604, DOI 10.1109/IC2E.2014.38
   Singh AK, 2020, INT C ULTRA MOD TELE, P236, DOI [10.1109/ICUMT51630.2020.9222443, 10.1109/icumt51630.2020.9222443]
   Singh J, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100279
   Singh K, 2018, J NETW COMPUT APPL, V112, P97, DOI 10.1016/j.jnca.2018.03.030
   Singh MP, 2020, COMPUT COMMUN, V154, P509, DOI 10.1016/j.comcom.2020.02.085
   Souri A, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3788
   Sudar KM, 2020, J HIGH SPEED NETW, V26, P55, DOI 10.3233/JHS-200630
   Swami R, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3301614
   Tan L, 2020, IEEE ACCESS, V8, P161908, DOI 10.1109/ACCESS.2020.3021435
   Tang D, 2023, IEEE T SERV COMPUT, V16, P3373, DOI 10.1109/TSC.2023.3266757
   Valdovinos IA, 2021, J NETW COMPUT APPL, V187, DOI 10.1016/j.jnca.2021.103093
   Wang HP, 2015, I C DEPEND SYS NETWO, P239, DOI 10.1109/DSN.2015.27
   Wang L, 2018, COMPUT NETW, V147, P1, DOI 10.1016/j.comnet.2018.09.021
   Wang R, 2015, 2015 IEEE TRUSTCOM/BIGDATASE/ISPA, VOL 1, P310, DOI [10.1109/Trustcom-2015.389, 10.1109/Trustcom.2015.389]
   Wang S, 2018, NOMS IEEE IFIP NETW, P1, DOI [10.1109/NOMS.2018.8406196, DOI 10.1109/NOMS.2018.8406196]
   Wang W, 2013, 2013 22ND WIRELESS AND OPTICAL COMMUNICATIONS CONFERENCE (WOCC 2013), P410, DOI 10.1109/WOCC.2013.6676402
   Wu ZJ, 2020, IEEE ACCESS, V8, P17404, DOI 10.1109/ACCESS.2020.2967478
   Xia J, 2019, CHINESE J ELECTRON, V28, P172, DOI 10.1049/cje.2017.12.002
   Xia WF, 2015, IEEE COMMUN SURV TUT, V17, P27, DOI 10.1109/COMST.2014.2330903
   Xie JF, 2019, IEEE COMMUN SURV TUT, V21, P393, DOI 10.1109/COMST.2018.2866942
   Xie RJ, 2019, IEEE ICC, DOI 10.1109/icc.2019.8761806
   Xu T, 2017, IEEE T NETW SERV MAN, V14, P1086, DOI 10.1109/TNSM.2017.2758796
   Xu YH, 2019, IEEE ACCESS, V7, P160536, DOI 10.1109/ACCESS.2019.2950945
   Xue L, 2018, IEEE T INF FOREN SEC, V13, P2423, DOI 10.1109/TIFS.2018.2815555
   Yan Q, 2017, ELECTRON LETT, V53, DOI 10.1049/el.2016.2234
   Yan Q, 2016, IEEE COMMUN SURV TUT, V18, P602, DOI 10.1109/COMST.2015.2487361
   Yoon C, 2015, COMPUT NETW, V85, P19, DOI 10.1016/j.comnet.2015.05.005
   You W., 2016, International Journal of Soft Computing and Networking, V1, P70, DOI [10.1109/EuCNC.2016.7561033, DOI 10.1109/EUCNC.2016.7561033]
   Yu W, 2007, P IEEE S SECUR PRIV, P18, DOI 10.1109/SP.2007.14
   Yuan B, 2019, IEEE T SERV COMPUT, V12, P231, DOI 10.1109/TSC.2016.2602861
   Yungaicela-Naula NM, 2022, J NETW COMPUT APPL, V205, DOI 10.1016/j.jnca.2022.103444
   Zhang H, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/2459154
   Zhao XL, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/6679304
   Zheng J, 2018, IEEE T INF FOREN SEC, V13, P1838, DOI 10.1109/TIFS.2018.2805600
   Zhou L, 2019, IEEE COMMUN LETT, V23, P1700, DOI 10.1109/LCOMM.2019.2931832
   Zhou YD, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/4760632
NR 129
TC 1
Z9 1
U1 11
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-16781-0
EA SEP 2023
PG 54
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600013
DA 2024-07-18
ER

PT J
AU Tseng, CH
   Lin, HCK
   Huang, ACW
   Chen, YH
   Lin, JR
AF Tseng, Chun-Hsiung
   Lin, Hao-Chiang Koong
   Huang, Andrew Chih-Wei
   Chen, Yung-Hui
   Lin, Jia-Rou
TI MindMe: an AI-Powered personality assessment tool
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Personality_Traits; Multimedia_Tool; Physiological_Signals
ID SELF-EFFICACY; SCALE
AB Personality assessment plays a crucial role in various domains, such as clinical diagnosis, organizational settings, and academic achievement. While most existing assessment models rely on questionnaires or scales, this manuscript proposes an AI-based assessment application that utilizes physiological signals as input. The underlying model is developed in our previous research work and was built upon the big five personality model, encompassing extraversion, agreeableness, conscientiousness, emotional stability, and openness to experience. The manuscript presents the development of a user-friendly GUI application that simplifies the usage of this assessment model. The application supports real-time personality assessment by automatically connecting to physiological sensors and providing real-time signal visualization. It also generates comprehensive reports for offline analysis. The manuscript further discusses the related works on personality trait models and assessment methods, as well as the system analysis, design, and implementation. The proposed tool shows promise in simplifying the assessment process and enabling real-time personality assessment.
C1 [Tseng, Chun-Hsiung; Lin, Jia-Rou] YuanZe Univ, Dept Elect Engn, Taoyuan City, Peoples R China.
   [Lin, Hao-Chiang Koong] Natl Univ Tainan, Dept Informat & Learning Technol, Tainan, Taiwan.
   [Huang, Andrew Chih-Wei] Fo Guang Univ, Dept Psychol, Jiaoxi, Taiwan.
   [Chen, Yung-Hui] Lunghwa Univ Sci & Technol, Dept Comp Informat & Network Engn, Taoyuan, Taiwan.
C3 National University Tainan; Fo Guang University
RP Tseng, CH (corresponding author), YuanZe Univ, Dept Elect Engn, Taoyuan City, Peoples R China.
EM lendle.tseng.archive@gmail.com
RI Huang, Andrew Chih-Wei/AAT-3512-2021
OI Huang, Andrew Chih-Wei/0000-0001-9794-7302; Tseng,
   Chun-Hsiung/0000-0003-4352-5547
FU This research is partially supported by the "Judging personality traits
   by physiological signals and constructing a digital learning environment
   that adapts to individual personality traits: the impact on learning
   effectiveness, achievement emotions, and s [110-2511-H-155-004,
   111-2410-H-155-002]; "Judging personality traits by physiological
   signals and constructing a digital learning environment - Ministry of
   Science and Technology, Taiwan, R.O.C.
FX This research is partially supported by the "Judging personality traits
   by physiological signals and constructing a digital learning environment
   that adapts to individual personality traits: the impact on learning
   effectiveness, achievement emotions, and student engagement." project,
   which was funded by the Ministry of Science and Technology, Taiwan,
   R.O.C. under Grant no. 110-2511-H-155-004 and 111-2410-H-155-002.
CR Allemand M, 2022, CURR DIR PSYCHOL SCI, V31, P41, DOI 10.1177/09637214211067782
   BANDURA A, 1993, EDUC PSYCHOL, V28, P117, DOI 10.1207/s15326985ep2802_3
   BANDURA A, 1977, PSYCHOL REV, V84, P191, DOI 10.1037/0033-295X.84.2.191
   Butt AR, 2020, IEEE SENS J, V20, P6532, DOI 10.1109/JSEN.2020.2976159
   Costa P. T., 1992, PSYCHOL ASSESSMENT, V4, P5, DOI DOI 10.1037/1040-3590.4.1.5
   Diseth Å, 2003, EUR J PERSONALITY, V17, P143, DOI 10.1002/per.469
   Goldberg L.R., 1992, PsycTESTS Dataset, DOI DOI 10.1037/T03713-000
   GOLDBERG LR, 1990, J PERS SOC PSYCHOL, V59, P1216, DOI 10.1037/0022-3514.59.6.1216
   Harari GM, 2015, EUR J PERSONALITY, V29, P509, DOI 10.1002/per.2032
   Judge TA, 2008, SOC PERSONAL PSYCHOL, V2, P1982, DOI 10.1111/j.1751-9004.2008.00136.x
   Kerr SariPekkala., 2018, FOUND TRENDS ENTREP, V14, P279, DOI DOI 10.3386/W24097
   Mohammed MTS, 2021, J KOMUN, V37, P227, DOI 10.17576/JKMJC-2021-3701-13
   NOWICKI S, 1973, J CONSULT CLIN PSYCH, V40, P148, DOI 10.1037/h0033978
   Ones DS, 2007, PERS PSYCHOL, V60, P995, DOI 10.1111/j.1744-6570.2007.00099.x
   Rotter J.B., 1954, Social learning and clinical psychology, DOI DOI 10.1037/10788-000
   SHERER M, 1982, PSYCHOL REP, V51, P663, DOI 10.2466/pr0.1982.51.2.663
   Spector PE, 1988, PsycTESTS Dataset, V61, DOI [10.1037/t08314-000, DOI 10.1037/T08314-000]
   Tseng C-H, 2022, 2022 IEEE 5 EUR C ED, DOI [10.1109/ecei53102.2022.9829428, DOI 10.1109/ECEI53102.2022.9829428]
   Tseng CH, 2022, COGENT EDUC, V9, DOI 10.1080/2331186X.2022.2138052
   Wache J., 2014, P 16 INT C MULT INT, P389, DOI DOI 10.1145/2663204.2666290
NR 20
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16803-x
EA SEP 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200013
DA 2024-07-18
ER

PT J
AU Dai, XW
   Lin, JC
   Nai, K
   Li, QP
   Li, ZY
AF Dai, Xianwen
   Lin, Jiacheng
   Nai, Ke
   Li, Qingpeng
   Li, Zhiyong
TI Multiscale deep feature selection fusion network for referring image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Referring image segmentation; Semantic segmentation; Multi-modal fusion;
   Deep learning
AB Referring image segmentation has attracted extensive attention in recent years. Previous methods have explored the difficult alignment between visual and textual features, but this problem has not been effectively addressed. This leads to the problem of insufficient interaction between visual features and textual features, which affects model performance. To this end, we propose a language-aware pixel feature fusion module (LPFFM) based on self-attention mechanism to ensure that the features of the two modalities have sufficient interaction in the space and channels. Then we apply it in the shallow to deep layers of the encoder to gradually select visual features related to the text. Secondly, we propose a second selection mechanism to further select visual features that only contain the target. For this mechanism, we design an attention contrastive loss to better suppress irrelevant background information. Further, we propose a multi-scale deep features selection fusion network (MDSFNet) based on the U-net architecture. Finally, the experimental results show that our proposed method is competitive with previous methods, improving the performance by 2.87%, 3.17%, and 3.81% on three benchmark datasets, RefCOCO, RefCOCO+, and G-ref, respectively.
C1 [Dai, Xianwen; Lin, Jiacheng; Nai, Ke; Li, Zhiyong] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Peoples R China.
   [Li, Qingpeng] Hunan Univ, Sch Robot, Changsha, Hunan, Peoples R China.
C3 Hunan University; Hunan University
RP Li, ZY (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Peoples R China.; Li, QP (corresponding author), Hunan Univ, Sch Robot, Changsha, Hunan, Peoples R China.
EM xianwendai@hnu.edu.cn; jcheng_lin@hnu.edu.cn; kenai_hnu@hnu.edu.cn;
   liqingpeng@hnu.edu.cn; zhiyong.li@hnu.edu.cn
RI Lin, Jiacheng/JDM-3320-2023; Li, Zhiyong/ABE-2142-2020
OI Lin, Jiacheng/0000-0003-1393-5027; 
FU This work was partially supported by the National Natural Science
   Foundation of China (No.U21A20518, No.61976086, No.62106071). [61976086,
   62106071]; National Natural Science Foundation of China
FX This work was partially supported by the National Natural Science
   Foundation of China (No.U21A20518, No.61976086, No.62106071).
CR Chen DJ, 2019, IEEE I CONF COMP VIS, P7453, DOI 10.1109/ICCV.2019.00755
   Chen J, 2023, EPCFormer: expression prompt collaboration transformer for universal referring video object segmentation
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chung JY, 2014, Arxiv, DOI arXiv:1412.3555
   Ding HH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16301, DOI 10.1109/ICCV48922.2021.01601
   Ding HH, 2018, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2018.00254
   Vo DM, 2018, MULTIMED TOOLS APPL, V77, P18689, DOI 10.1007/s11042-018-5653-x
   Feng G, 2021, PROC CVPR IEEE, P15501, DOI 10.1109/CVPR46437.2021.01525
   Feng G, 2023, IEEE T NEUR NET LEAR, V34, P2246, DOI 10.1109/TNNLS.2021.3106153
   Fu KR, 2019, IEEE T MULTIMEDIA, V21, P457, DOI 10.1109/TMM.2018.2859746
   Gen Luo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10031, DOI 10.1109/CVPR42600.2020.01005
   Hu RH, 2016, LECT NOTES COMPUT SC, V9905, P108, DOI 10.1007/978-3-319-46448-0_7
   Huang S, 2020, P IEEE CVF C COMP VI
   Hui T., 2020, COMPUTER VISION ECCV, P59
   Jing Y, 2021, PROC CVPR IEEE, P9853, DOI 10.1109/CVPR46437.2021.00973
   Kazemzadeh S., 2014, EMNLP, P787, DOI DOI 10.3115/V1/D14-1086
   Kim N, 2022, PROC CVPR IEEE, P18124, DOI 10.1109/CVPR52688.2022.01761
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Li QZ, 2022, NEUROCOMPUTING, V467, P99, DOI 10.1016/j.neucom.2021.09.066
   Li RY, 2018, PROC CVPR IEEE, P5745, DOI 10.1109/CVPR.2018.00602
   Lin JC, 2023, EXPERT SYST APPL, V233, DOI 10.1016/j.eswa.2023.120960
   Lin JC, 2021, NEURAL NETWORKS, V133, P132, DOI 10.1016/j.neunet.2020.09.001
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu C, 2023, IEEE T MULTIMEDIA, V25, P3657, DOI 10.1109/TMM.2022.3163578
   Liu CX, 2017, IEEE I CONF COMP VIS, P1280, DOI 10.1109/ICCV.2017.143
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mao JH, 2016, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2016.9
   Margffoy-Tuay E, 2018, LECT NOTES COMPUT SC, V11215, P656, DOI 10.1007/978-3-030-01252-6_39
   Moradi M, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114428
   Nagaraja VK, 2016, LECT NOTES COMPUT SC, V9908, P792, DOI 10.1007/978-3-319-46493-0_48
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi HC, 2018, LECT NOTES COMPUT SC, V11210, P38, DOI 10.1007/978-3-030-01231-1_3
   Yang SB, 2021, PROC CVPR IEEE, P11261, DOI 10.1109/CVPR46437.2021.01111
   Ye LW, 2020, IEEE T MULTIMEDIA, V22, P3224, DOI 10.1109/TMM.2020.2971171
   Ye LW, 2019, PROC CVPR IEEE, P10494, DOI 10.1109/CVPR.2019.01075
   Yin CX, 2022, IEEE T MULTIMEDIA, V24, P4183, DOI 10.1109/TMM.2021.3114541
   Yu J, 2021, IEEE T CYBERNETICS, V51, P1731, DOI 10.1109/TCYB.2020.2969046
   Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5
   Zhang H, 2020, Arxiv, DOI arXiv:2004.08955
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 43
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-16913-6
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000018
DA 2024-07-18
ER

PT J
AU Watni, D
   Chawla, S
AF Watni, Dipti
   Chawla, Sonal
TI Impact of various image formats supported by android smartphones on
   image steganography: a preliminary study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image formats; Image steganography; LSB technique; MSE; PSNR
ID NASAL CAVITY; SEGMENTATION
AB Security of the information stored in android-based smartphones is a hot research topic. Image steganography can be employed to increase the security of the confidential data. Images are available in various image formats. Performance of image steganography can get affected by the choice of the image format chosen owing to their different characteristics. However, the analysis of image formats has been neglected in the existing studies. Therefore, this research paper attempts to analyze the behavior and impact of various image formats (natively supported by android smartphones) on image steganography which led to better security. The objective of this research paper is threefold. Firstly, it compares and contrasts various image steganography algorithms and identifies the most appropriate for this research study. Secondly, it discusses the characteristics of image formats supported by Android smartphones and narrows down the characteristics which can affect the efficiency of image steganography. Thirdly, the research paper applies the identified algorithm on grayscale and colored images and evaluates using two different datasets. It then uses MSE and PSNR metrics to compare original images and stego images.
C1 [Watni, Dipti] Panjab Univ, Mehr Chand Mahajan DAV Coll Women, Chandigarh, India.
   [Chawla, Sonal] Panjab Univ, Dept Comp Sci & Applicat, Chandigarh, India.
C3 Panjab University; Panjab University
RP Watni, D (corresponding author), Panjab Univ, Mehr Chand Mahajan DAV Coll Women, Chandigarh, India.
EM deepti.sharda@mcmdavcwchd.in; sonal_chawla@pu.ac.in
OI Watni, Dipti/0000-0001-8702-0861
CR Abed Elgabar EE, 2013, International Journal of Soft Computing and Engineering (IJSCE), P2231
   Akhtar N, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P749, DOI 10.1109/ICICICT.2014.6781374
   Alhomoud AM, 2021, INTELL AUTOM SOFT CO, V27, P69, DOI 10.32604/iasc.2021.014773
   Amin MM., 2003, 4th National Conference of Telecommunication Technology
   andreearaicu, About Us
   Ansari Arshiya Sajid, 2017, International Journal of Image, Graphics and Signal Processing, V9, P14, DOI 10.5815/ijigsp.2017.06.02
   Ansari Mohammadi, 2019, International Journal of Computer Network and Information Security, V11, P11, DOI DOI 10.5815/IJCNIS.2019.01.02
   Apau R., 2017, Int J Comput Appl, V164, P0975
   Bas P, 2016, Arxiv, DOI arXiv:1607.07824
   Burguera I., 2011, P 1 ACM WORKSH SEC P, P15, DOI DOI 10.1145/2046614.2046619
   Carvajal-Gamez BE, 2013, EXPERT SYST APPL, V40, P1132, DOI 10.1016/j.eswa.2012.08.024
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chen Y-F, 2009, P MATH COMPUTERS SCI, V3
   Chen Y-F., 2009, WSEAS INT C P MATH C
   Currie DL, 1996, 19 NAT INF SYST SEC
   Danuputri C., 2015, 2015 4 INT C CYB SEC
   Dewangga IGAP., 2017, Int J Appl Eng Res, V12, P10626
   Do Q., 2014, 2014 47 HAW INT C SY
   El Rahman Sahar A., 2015, International Journal of Image, Graphics and Signal Processing, V7, P10, DOI 10.5815/ijigsp.2015.06.02
   .forestryimages, About us
   Fridrich J, 1999, PICS 1999 P C IM PRO, P285
   Ha Kaur, 2017, 2017 4 INT C SIGN PR
   Hashim MM., 2018, International Journal of Engineering & Technology, V7, P3505, DOI DOI 10.14419/IJET.V7I4.17294
   Hong W., 2004, Inf Technol J, V9, P1147
   Huang FJ, 2012, IEEE T INF FOREN SEC, V7, P1181, DOI 10.1109/TIFS.2012.2198213
   Ibrahim R., 2012, ICCGI 2012 7 INT MUL
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Johnson NF, 2000, ART H COMP SCI LIBR, P43
   Juzar MT, 2016, 2016 INTERNATIONAL SYMPOSIUM ON ELECTRONICS AND SMART DEVICES (ISESD), P225, DOI 10.1109/ISESD.2016.7886723
   Behera SK, 2010, Arxiv, DOI arXiv:1010.4007
   La Polla M, 2013, IEEE COMMUN SURV TUT, V15, P446, DOI 10.1109/SURV.2012.013012.00028
   Lenti J., 2000, Periodica Polytechnica Electrical Engineering, V44, P249
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Neeta D, 2006, 2006 1ST INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT, P173
   Niimi M, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P917
   Owens M., 2002, A discussion of covert channels and steganography
   Pan YF, 2016, LECT NOTES COMPUT SC, V10039, P125, DOI 10.1007/978-3-319-48671-0_12
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Pradhan A, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/1924618
   Rawat D., 2013, Int J Comput Appl, V67, P1
   Reddy V. Lokeswara, 2011, International Journal of Advanced Networking and Applications, V2, P868
   Reza H., 2016, J Inf Secur, V7, P249
   Rojali AG., 2017, AIP C P
   Shahida T., 2014, Proceedings of International Conference on Internet Computing and Information Communications
   Sharda S, International Journal of Emerging Technology and Advanced Engineering (IJETAE), V3, P707
   Sharma A., 2017, Int J Emerg Res Manag Technol, V6, P208, DOI [10.23956/ijermt.v6i6.270, DOI 10.23956/IJERMT.V6I6.270]
   Shehab M, 2014, IEEE INT CONF MO, P39, DOI 10.1109/MobServ.2014.15
   Solanki R., 2017, Survey of image steganography techniques
   Sujitha P, 2013, Int J Sci Res, P2319
   Tiwari N., 2010, International Journal of Computer Applications, V6, P1
   Umbarkar AJ., 2016, ICTACT Journal on Image Video Processing (IJIVP), V6, P3
   Upham D., 1999, Jsteg steganographic algorithm
   usc, About us
   Venkatraman S, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 2, PROCEEDINGS, P347
   Wang C, 2012, INT CONF ACOUST SPEE, P1785, DOI 10.1109/ICASSP.2012.6288246
   Watni D., 2020, Comparison of image formats to apply image steganography in smartphones: a preliminary study
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HY, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217820
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zin WW., 2013, Int J Sci Res, V2, P1
NR 60
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33031
EP 33050
DI 10.1007/s11042-023-16343-4
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400014
DA 2024-07-18
ER

PT J
AU Madhu, G
   Kautish, S
   Gupta, Y
   Nagachandrika, G
   Biju, SM
   Kumar, M
AF Madhu, G.
   Kautish, Sandeep
   Gupta, Yogita
   Nagachandrika, G.
   Biju, Soly Mathew
   Kumar, Manoj
TI XCovNet: An optimized xception convolutional neural network for
   classification of COVID-19 from point-of-care lung ultrasound images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Depth-wise Convolution; POCUS; Separable Convolution;
   Xception; Ultrasound Images
AB Global livelihoods are impacted by the novel coronavirus (COVID-19) disease, which mostly affects the respiratory system and spreads via airborne transmission. The disease has spread to almost every nation and is still widespread worldwide. Early and reliable diagnosis is essential to prevent the development of this highly risky disease. The computer-aided diagnostic model facilitates medical practitioners in obtaining a quick and accurate diagnosis. To address these limitations, this study develops an optimized Xception convolutional neural network, called "XCovNet," for recognizing COVID-19 from point-of-care ultrasound (POCUS) images. This model employs a stack of modules, each of which has a slew of feature extractors that enable it to learn richer representations with fewer parameters. The model identifies the presence of COVID-19 by classifying POCUS images containing Coronavirus samples, viral pneumonia samples, and healthy ultrasound images. We compare and evaluate the proposed network with state-of-the-art (SOTA) deep learning models such as VGG, DenseNet, Inception-V3, ResNet, and Xception Networks. By using the XCovNet model, the previous study's problems are cautiously addressed and overhauled by achieving 99.76% accuracy, 99.89% specificity, 99.87% sensitivity, and 99.75% F1-score. To understand the underlying behavior of the proposed network, different tests are performed on different shuffle patterns. Thus, the proposed "XCovNet" can, in regions where test kits are limited, be used to help radiologists detect COVID-19 patients through ultrasound images in the current COVID-19 situation.
C1 [Madhu, G.; Nagachandrika, G.] VNR Vignana Jyothi Inst Engn & Technol, Dept Informat Technol, Hyderabad 90, TS, India.
   [Kautish, Sandeep] Asia Pacific Univ Technol & Innovat Malaysia, LBEF Campus, Kathmandu 44600, Nepal.
   [Gupta, Yogita] Thapar Inst Engn & Technol, Patiala, Punjab, India.
   [Biju, Soly Mathew; Kumar, Manoj] Univ Wollongong Dubai, Sch Comp Sci, Dubai Knowledge Pk, Dubai, U Arab Emirates.
   [Kumar, Manoj] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
C3 Vallurupalli Nageswara Rao Vignana Jyothi Institute of Engineering
   &Technology (VNR VJIET); Thapar Institute of Engineering & Technology;
   University of Wollongong; Middle East University
RP Kumar, M (corresponding author), Univ Wollongong Dubai, Sch Comp Sci, Dubai Knowledge Pk, Dubai, U Arab Emirates.; Kumar, M (corresponding author), Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
EM madhu_g@vnrvjiet.in; dr.skautish@gmail.com; Yogita.gt@gmail.com;
   madhu_g@vnrvjiet.in; SolyMathewBiju@uowdubai.ac.ae;
   wss.manojkumar@gmail.com
RI Kumar, Manoj/AFS-0700-2022; Golla, Madhu/F-3654-2012
OI Kumar, Manoj/0000-0001-9598-0280; Golla, Madhu/0000-0002-4170-3146;
   Gogulamudi, Naga Chandrika/0000-0002-8991-5930
FU The University of Wollongong
FX No Statement Available
CR Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642
   Arntfield R, 2021, BMJ OPEN, V11, DOI 10.1136/bmjopen-2020-045120
   Awasthi N, 2021, IEEE T ULTRASON FERR, V68, P2023, DOI 10.1109/TUFFC.2021.3068190
   Bai Y, 2020, JAMA-J AM MED ASSOC, V323, P1406, DOI 10.1001/jama.2020.2565
   Barros B, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165486
   Berce V, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-54499-y
   Berrar D., 2019, Encyclopedia of Bioinformatics and Computational Biology, P542, DOI [DOI 10.1016/B978-0-12-809633-8.20349-X, 10.1016/B978-0-12-809633-8.203 49-X]
   Born J, 2020, PREPRINT
   Born J, 2020, AUTOMATIC DETECTION
   Born J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11020672
   Buonsenso D, 2020, LANCET RESP MED, V8, pE27, DOI 10.1016/S2213-2600(20)30120-X
   Che H, 2021, IEEE ENG MED BIO, P2618, DOI 10.1109/EMBC46164.2021.9631069
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Dastider AG, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104296
   Diaz-Escobar J, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255886
   Ding W, 2023, IEEE T EM TOP COMP I, ppp1
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI DOI 10.5121/IJDKP.2015.5201
   Hu ZY, 2021, BIOMED ENG ONLINE, V20, DOI 10.1186/s12938-021-00863-x
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Khan U, 2022, IEEE T ULTRASON FERR, V69, P1661, DOI 10.1109/TUFFC.2022.3161716
   Kingma D. P., 2014, arXiv
   Kulhare S, 2018, LECT NOTES COMPUT SC, V11042, P65, DOI 10.1007/978-3-030-01045-4_8
   Kundu R, 2022, MULTIMED TOOLS APPL, V81, P31, DOI 10.1007/s11042-021-11319-8
   Kundu R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93658-y
   Li Q, 2020, NEW ENGL J MED, V382, P1199, DOI 10.1056/NEJMoa2001316
   Lindsey Tony, 2019, Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications. 23rd Iberoamerican Congress, CIARP 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11401), P723, DOI 10.1007/978-3-030-13469-3_84
   Madhu G, 2022, CMC-COMPUT MATER CON, V70, P5467, DOI 10.32604/cmc.2022.020455
   Maier A, 2019, Z MED PHYS, V29, P86, DOI 10.1016/j.zemedi.2018.12.003
   Masood A, 2018, J BIOMED INFORM, V79, P117, DOI 10.1016/j.jbi.2018.01.005
   Mehanian C, 2019, LECT NOTES COMPUT SC, V11798, P74, DOI 10.1007/978-3-030-32875-7_9
   Mojoli F, 2019, AM J RESP CRIT CARE, V199, P701, DOI 10.1164/rccm.201802-0236CI
   Roy S, 2020, IEEE T MED IMAGING, V39, P2676, DOI 10.1109/TMI.2020.2994459
   Saif A F M, 2021, IEEE Trans Artif Intell, V2, P608, DOI 10.1109/TAI.2021.3104791
   Shea D., 2023, P IEEE CVF C COMP VI, P3102
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Song JSY, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23052621
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Ulhaq A, 2020, IEEE ACCESS, V8, P179437, DOI 10.1109/ACCESS.2020.3027685
   Vasquez C, 2023, SPIE, V12567, P336
   Wang J, 2022, J IMAGING, V8, DOI 10.3390/jimaging8030065
   World Health Organization, COR DIS COVID 19 PAN
   Xing WY, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103561
   Xirouchaki N, 2011, INTENS CARE MED, V37, P1488, DOI 10.1007/s00134-011-2317-y
   Yang Y, 2020, INTENS CARE MED, V46, P1761, DOI 10.1007/s00134-020-06096-1
   Yu KH, 2018, NAT BIOMED ENG, V2, P719, DOI 10.1038/s41551-018-0305-z
   Zhao L, 2022, BME FRONT, V2022, DOI 10.34133/2022/9780173
   Zheng WB, 2021, INFORM FUSION, V75, P168, DOI 10.1016/j.inffus.2021.05.015
NR 48
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33653
EP 33674
DI 10.1007/s11042-023-16944-z
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001078145100009
OA hybrid
DA 2024-07-18
ER

PT J
AU Abdulhasan, RA
   Abd Al-latief, ST
   Kadhim, SM
AF Abdulhasan, Raed Abdulkareem
   Abd Al-latief, Shahad Thamear
   Kadhim, Saif Mohanad
TI Instant learning based on deep neural network with linear discriminant
   analysis features extraction for accurate iris recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris recognition; Gaussian blur; Image contour; Linear discriminate
   analysis LDA; Deep neural network DNN
ID ENHANCEMENT; SEGMENTATION; FUSION; IMAGES
AB Biometric-based identity verification systems have gained substantial attention due to their ability to provide high-level security. Among these systems, iris recognition systems have emerged as one of the most accurate and complex verification approaches. However, an ideal recognition system with a short processing time has not yet been reported in the literature because of the trade-offs involved. In this article, a novel framework for an iris recognition system is proposed based on hybrid deep neural network (DNN) classification-based Linear Discriminant Analysis (LDA) for feature extraction. The developed system includes unique pre-processing steps for both training and testing datasets, which are modulated by greyscale conversation, Gaussian blurring, binary imaging, contour segmentation and resizing. The proposed LDA-DNN provides high accuracy and stability for human identity verification with a short processing time. The proposed model accomplishes this task perfectly without any loss, which is unique among this type of approach. The results are validated via five computed measurement parameters. Experimental results are obtained by applying the model to four typical existing databases for powerful validation. Moreover, the proposed LDA-DNN framework results are compared with outcome measures obtained for state-of-the-art iris recognition approaches. The experimental results illustrate the success and power of the proposed LDA-DNN model, which attains an accuracy of 100% within a time of 70 ms, corresponding to an ideal recognition result that validated using several databases. Furthermore, this work provides a model within a unique property, in which it does not require a specific database or measurement parameters for evaluation.
C1 [Abdulhasan, Raed Abdulkareem] Univ Tun Hussein Onn Malaysia, Fac Elect & Elect Engn, Dept Commun Engn, Parit Raja, Johor, Malaysia.
   [Abdulhasan, Raed Abdulkareem] Mustansiriyah Univ, Fac Engn, Dept Elect Engn, Baghdad, Iraq.
   [Abd Al-latief, Shahad Thamear] Univ Tenaga Nas, Fac Informat & Commun Technol, Kajang, Selangor, Malaysia.
   [Kadhim, Saif Mohanad] Univ Tenaga Nas, Fac Engn, Kajang, Selangor, Malaysia.
C3 University of Tun Hussein Onn Malaysia; Mustansiriya University;
   Universiti Tenaga Nasional; Universiti Tenaga Nasional
RP Abdulhasan, RA (corresponding author), Univ Tun Hussein Onn Malaysia, Fac Elect & Elect Engn, Dept Commun Engn, Parit Raja, Johor, Malaysia.; Abdulhasan, RA (corresponding author), Mustansiriyah Univ, Fac Engn, Dept Elect Engn, Baghdad, Iraq.
EM raadabd39@gmail.com
RI Abdulatief, Shahad Thamear/JGE-4095-2023; Kadhim, Saif
   Mohanad/JNT-1321-2023
OI Abdulatief, Shahad Thamear/0009-0003-9141-7951; Kadhim, Saif
   Mohanad/0009-0009-5090-8942; Abdulhasan, Raed
   Abdulkareem/0000-0001-6478-8990
CR Ahmadi N, 2019, OPT LASER TECHNOL, V120, DOI 10.1016/j.optlastec.2019.105701
   Ahmadi N, 2018, IET BIOMETRICS, V7, P153, DOI 10.1049/iet-bmt.2017.0041
   Alay N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195523
   [Anonymous], 2012, Second Generation Biometrics: the Ethical, Legal and Social Context
   [Anonymous], 2011, VISUAL COMMUN-US, DOI DOI 10.1109/VCIP.2011.6115989
   Bovik AC, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P69, DOI 10.1016/B978-0-12-374457-9.00004-4
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Chaturvedi R., 2019, INT J APPL ENG RES, V14, P3987
   Chen CH, 2009, EXPERT SYST APPL, V36, P10351, DOI 10.1016/j.eswa.2009.01.033
   Chen YF, 2020, IEEE ACCESS, V8, P32365, DOI 10.1109/ACCESS.2020.2973433
   Chinese Academy of Sciences Institute of Automation, 2003, DAT 756 GREYSC EYE I
   Chowhan S, 2011, INT J ADV COMPUT SC, V2
   Deng L., 2011, P AS SUMM C APSIPA A, P1
   Dhage SS, 2015, PROCEDIA COMPUT SCI, V45, P256, DOI 10.1016/j.procs.2015.03.135
   Dong WB, 2011, IEEE T PATTERN ANAL, V33, P1744, DOI 10.1109/TPAMI.2010.227
   Farouk RH, 2022, INT J COMPUT INT SYS, V15, DOI 10.1007/s44196-022-00135-z
   Gedraite ES, 2011, ELMAR PROC, P393
   Ghassabeh YA, 2015, PATTERN RECOGN, V48, P1999, DOI 10.1016/j.patcog.2014.12.012
   HAJARI K, 2015, 2015 INT C PERVASIVE, P1
   He F, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.2.023005
   He ZF, 2009, IEEE T PATTERN ANAL, V31, P1670, DOI 10.1109/TPAMI.2008.183
   Hsiao YT, 2005, IEEE SYS MAN CYBERN, P2962
   Jayanthi J, 2021, J AMB INTEL HUM COMP, V12, P3271, DOI 10.1007/s12652-020-02172-y
   Jyothi P, 2023, J SCI IND RES INDIA, V82, P151, DOI 10.56042/jsir.v82i1.70253
   Kresimir D, 2004, 46 INT S EL MAR
   Lee MB, 2021, IEEE ACCESS, V9, P10120, DOI 10.1109/ACCESS.2021.3050788
   Lee MB, 2019, IEEE ACCESS, V7, P122134, DOI 10.1109/ACCESS.2019.2937809
   Lee YW, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040842
   Li C, 2014, CCIS NE U, V6
   Li CC, 2015, VISUAL COMPUT, V31, P1419, DOI 10.1007/s00371-014-1023-5
   Liu GY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113721
   Liu J, 2014, NEUROCOMPUTING, V144, P484, DOI 10.1016/j.neucom.2014.05.016
   Liu M, 2020, IEEE T FUZZY SYST, V28, P92, DOI 10.1109/TFUZZ.2019.2912576
   Liu NAF, 2016, PATTERN RECOGN LETT, V82, P154, DOI 10.1016/j.patrec.2015.09.016
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Mane Vijay M., 2009, International Journal of Biometrics and Bioinformatics (IJBB), V3, P90
   Matey JR, 2006, P IEEE, V94, P1936, DOI 10.1109/JPROC.2006.884091
   Moazed KT., 2020, IRIS, P15, DOI [10.1007/978-3-030-45756-3_2, DOI 10.1007/978-3-030-45756-3_2]
   Nabti M, 2008, PATTERN RECOGN, V41, P868, DOI 10.1016/j.patcog.2007.06.030
   Nguyen K, 2018, IEEE ACCESS, V6, P18848, DOI 10.1109/ACCESS.2017.2784352
   Othman N, 2016, PATTERN RECOGN LETT, V82, P124, DOI 10.1016/j.patrec.2015.09.002
   Park HA, 2007, PATTERN RECOGN LETT, V28, P2019, DOI 10.1016/j.patrec.2007.05.017
   Pillai JK, 2014, IEEE T PATTERN ANAL, V36, P73, DOI 10.1109/TPAMI.2013.98
   Proença H, 2012, COMPUT VIS IMAGE UND, V116, P167, DOI 10.1016/j.cviu.2011.10.008
   Rahulkar AD, 2012, NEUROCOMPUTING, V81, P12, DOI 10.1016/j.neucom.2011.09.025
   Roy K, 2011, PATTERN ANAL APPL, V14, P329, DOI 10.1007/s10044-011-0229-7
   Sajjad M, 2016, KSII T INTERNET INF, V10, P1904, DOI 10.3837/tiis.2016.04.025
   Saravanan G, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P462, DOI 10.1109/ICCSP.2016.7754179
   Sharma A, 2015, INT J MACH LEARN CYB, V6, P443, DOI 10.1007/s13042-013-0226-9
   Sibai FN, 2011, EXPERT SYST APPL, V38, P5940, DOI 10.1016/j.eswa.2010.11.029
   Tan CW, 2013, IEEE T IMAGE PROCESS, V22, P3751, DOI 10.1109/TIP.2013.2260165
   Taneja Arti, 2015, 2015 4th International Conference on Reliability, Infocom Technologies and Optimization (ICRITO) (Trends and Future Directions), P1, DOI 10.1109/ICRITO.2015.7359305
   Umer S, 2020, NEURAL NETWORKS, V122, P407, DOI 10.1016/j.neunet.2019.11.009
   Umer S, 2016, PATTERN ANAL APPL, V19, P283, DOI 10.1007/s10044-015-0482-2
   Vatsa M, 2008, IEEE T SYST MAN CY B, V38, P1021, DOI 10.1109/TSMCB.2008.922059
   Vijaykumar Vinolyn, 2022, 2022 3rd International Conference on Smart Electronics and Communication (ICOSEC), P997, DOI 10.1109/ICOSEC54921.2022.9951932
   Wang K, 2019, IEEE T INF FOREN SEC, V14, P3233, DOI 10.1109/TIFS.2019.2913234
   Wang W., 2022, ARXIV
   Wang Z, 2018, IEEE ACCESS, V6, P17905, DOI 10.1109/ACCESS.2018.2812208
   Wilson C. G., 2007, Enhancement in Drug Delivery, P473
   Zhang M, 2012, IET BIOMETRICS, V1, P37, DOI 10.1049/iet-bmt.2012.0002
   Zhao TM, 2019, IEEE ACCESS, V7, P49691, DOI 10.1109/ACCESS.2019.2911056
   Zhao ZJ, 2019, PATTERN RECOGN, V93, P546, DOI 10.1016/j.patcog.2019.04.010
   Zhou RG, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2377-4
NR 66
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32099
EP 32122
DI 10.1007/s11042-023-16751-6
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900001
DA 2024-07-18
ER

PT J
AU Kumar, C
AF Kumar, Chandan
TI Hybrid optimization for secure and robust digital image watermarking
   with DWT, DCT and SPIHT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual watermarking; DWT; SVD; Arnold transform; SPIHT; PSNR; SSIM; NC;
   BER; Attacks; Hybrid optimization; Copyright protection; Authentication
ID PARTICLE SWARM OPTIMIZATION; SINGULAR-VALUE DECOMPOSITION; SVD; SCHEME;
   ALGORITHM
AB In this paper, we present a novel and robust watermarking method that combines the Discrete Wavelet Transform (DWT), Discrete Cosine Transform (DCT), and Set Partitioning in Hierarchical Trees (SPIHT) algorithm. The proposed method is designed to embed two different types of watermarks, Watermark 1 and Watermark 2, in different sub-bands of the decomposed host image. Initially cover image and watermark1 is optimized using hybrid optimization techniques (combination of whale and Cookoo optimization techniques). To ensure the security and robustness of the embedded watermarks, Watermark 1 is encrypted using the Arnold transform, while Watermark 2 is encoded using a Hamming encoder. Both encrypted watermarks are then embedded in their respective sub-bands. Finally, to compress the watermarked image without losing the embedded watermarks, we apply the SPIHT compression algorithm. Further, performance of the proposed method is evaluated against various watermarking attacks, including JPEG compression, Gaussian noise, and salt and pepper noise. Our experimental results demonstrate the high robustness of the proposed method against various watermarking attacks, including JPEG compression, Gaussian noise, and salt and pepper noise. The peak signal-to-noise ratio (PSNR), normalized correlation (NC), bit error rate (BER), and structured similarity index (SSIM) values were used as performance metrics. The proposed method achieves a maximum PSNR value of 42.52 dB and a maximum NC value of 0.9999, indicating the high fidelity and similarity between the original and watermarked images. The BER values were found to be consistently low, indicating the accuracy of watermark retrieval. Additionally, the proposed method maintains the quality of the cover image with minimal distortion. Overall, the proposed method offers a secure and robust solution for digital image watermarking, which can be applied in various applications, such as copyright protection and authentication.
C1 [Kumar, Chandan] Career Point Univ, Dept CSE, Hamirpur, Himachal Prades, India.
RP Kumar, C (corresponding author), Career Point Univ, Dept CSE, Hamirpur, Himachal Prades, India.
EM chandansharmahmr@gmail.com
OI Kumar, Chandan/0000-0001-9163-3206
CR Ahmadi M., 2012, MULTIMED TOOLS APPL, V58, P537
   Ansari IA, 2016, OPTIK, V127, P5711, DOI 10.1016/j.ijleo.2016.03.070
   Arrasyid Adli Azhar, 2018, 2018 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI), P522, DOI 10.1109/ISRITI.2018.8864461
   Awasthi D, 2022, DUAL IMAGE EFFICIENT, DOI [10.21203/rs.3.rs-1515620/v1, DOI 10.21203/RS.3.RS-1515620/V1]
   Barlaskar SA., 2022, MULTIMED TOOLS APPL, V254, P1097
   Chacko A, 2022, INT J INTELL SYST, V37, P4810, DOI 10.1002/int.22742
   Chukwuchekwa N., 2019, RES J APPL SCI, V13, P1097
   Cox I. J., 2002, Digital Watermarking
   Devi KJ, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10163015
   Garg P., 2022, VISUAL COMPUT, V58, P1097
   Garg P, 2020, J INFORM OPTIM SCI, V41, P1499, DOI 10.1080/02522667.2020.1802124
   Hassan Omer Mohammed Salih, 2021, 2021 IEEE 11th International Conference on System Engineering and Technology (ICSET), P90, DOI 10.1109/ICSET53708.2021.9612547
   Iwut I., 2016, INDONESIAN J ELECT E, V4, P91
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   Kang XB, 2020, SOFT COMPUT, V24, P10561, DOI 10.1007/s00500-019-04563-6
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P7339, DOI 10.1007/s11042-019-08314-5
   Kumar C, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4912
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P11069, DOI 10.1007/s11042-018-6177-0
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Liu, 2019, IEEE T IND INFORM, V15, P3364
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Maloo S, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00291-6
   Moosazadeh M, 2019, J INF SECUR APPL, V47, P28, DOI 10.1016/j.jisa.2019.04.001
   Rajani D, 2022, J APPL SEC RES, V17, P103, DOI 10.1080/19361610.2020.1838251
   Shaik A., 2021, COMPUT ELECTR ENG, V58, P1097
   Sharma S, 2021, OPEN COMPUT SCI, V11, P330, DOI 10.1515/comp-2019-0023
   Sharma S, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105696
   Sharma V., 2022, J KING SAUD UNIV-COM, V45, P1097
   Shivani JLD, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9030033
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh KS, 2022, IEEE 7 INT C SIGN PR, P1097
   Soliman MM, 2016, NEURAL COMPUT APPL, V27, P469, DOI 10.1007/s00521-015-1868-1
   Thakkar F, 2017, TURK J ELECTR ENG CO, V25, P3273, DOI 10.3906/elk-1603-17
   Zear A., 2018, MULTIMED TOOLS APPL, V254, P1097
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
   Zheng ZG, 2018, FUTURE GENER COMP SY, V88, P92, DOI 10.1016/j.future.2018.05.027
NR 37
TC 0
Z9 0
U1 6
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31911
EP 31932
DI 10.1007/s11042-023-16903-8
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900005
DA 2024-07-18
ER

PT J
AU Lanjewar, MG
   Parab, JS
AF Lanjewar, Madhusudan G.
   Parab, Jivan S.
TI CNN and transfer learning methods with augmentation for citrus leaf
   diseases detection using PaaS cloud on mobile
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN; Citrus leaf diseases; DenseNet201; InceptionResNetV2; Platform as a
   service
ID IMAGE-PROCESSING TECHNIQUES; NEURAL-NETWORK; CLASSIFICATION; FRUIT;
   IDENTIFICATION; SEGMENTATION
AB Leaf and fruit infections are the primary cause of the maximum harm to the crop, which decreases the quality and amount of the goods. To improve the productivity of plants, the timely identification of the infection is vital, which is a highly challenging task. Deep learning (DL) with image processing allows farmers to distinguish between healthy and infected crops. This work intends to identify healthy and diseased citrus leaf images using a convolutional neural network (CNN) on the Platform as a Service (PaaS) cloud. The dataset of five types of healthy and unhealthy citrus images was used, namely, black spot, melanose, canker, greening, and healthy. Furthermore, the four-transfer learning (TL) pre-trained deep CNN (DCNN) models, namely, ResNet152V2, InceptionResNetV2, DenseNet121, and DenseNet201, were used to classify the leaf type. The performance of the CNN and four DCNNs were assessed using the confusion matrix (accuracy, precision, recall, and F1-score) and receiver operating characteristic-area under the curve (ROC-AUC) curve. An augmentation technique was utilised to enhance the dataset images, which helped to improve the model's performance and achieved an accuracy of 98% precision and recall and an F1 score of 99% and an ROC-AUC score of 0.99. Moreover, the suggested CNN has only 15 layers, 427317 parameters, and 1.68MB size, while DCNN models have more layers, parameters, and large size. The small-size CNN was deployed to the Platform as a Service (PaaS) cloud. The deployed model link is available on a smartphone to upload a citrus leaf image to the cloud, and the result is instantly available on a mobile screen.
C1 [Lanjewar, Madhusudan G.; Parab, Jivan S.] Goa Univ, Sch Phys & Appl Sci, Taleigao Plateau, Goa, India.
C3 Goa University
RP Lanjewar, MG (corresponding author), Goa Univ, Sch Phys & Appl Sci, Taleigao Plateau, Goa, India.
EM madhusudan@unigoa.ac.in; jsparab@unigoa.ac.in
OI Lanjewar, Madhusudan/0000-0002-9670-3020
CR Al Bashish Dheeb, 2011, Information Technology Journal, V10, P267, DOI 10.3923/itj.2011.267.275
   Alom MZ, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-020-01157-3
   Bloice M.D., 2017, ARXIV170804680, V2, P1, DOI DOI 10.21105/JOSS.00432
   Boeing H, 2012, EUR J NUTR, V51, P637, DOI 10.1007/s00394-012-0380-y
   Chouhan SS, 2018, IEEE ACCESS, V6, P8852, DOI 10.1109/ACCESS.2018.2800685
   Dananjayan S, 2022, COMPUT ELECTRON AGR, V193, DOI 10.1016/j.compag.2021.106658
   Deepalakshmi P, 2021, INT J INF SYST MODEL, V12, P1, DOI 10.4018/IJISMD.2021010101
   Elaraby A, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/9153207
   Elgamal T, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), P1, DOI 10.1109/CLOUD.2018.00008
   Ellis B., 2009, Manual of Leaf Architecture
   Gorinstein S, 2006, J AGR FOOD CHEM, V54, P1887, DOI 10.1021/jf058171g
   Guo Y, 2020, DISCRETE DYN NAT SOC, V2020, DOI 10.1155/2020/2479172
   Hamuda E, 2016, COMPUT ELECTRON AGR, V125, P184, DOI 10.1016/j.compag.2016.04.024
   Hanh DN, 2021, INT SYMP ELECTR ELEC, P69, DOI 10.1109/ISEE51682.2021.9418680
   Hauberg S, 2015, ARXIV, DOI DOI 10.48550/ARXIV.1510.02795
   ifpri, ATLAS AFRICAN AGR RE
   Iqbal Z, 2018, COMPUT ELECTRON AGR, V153, P12, DOI 10.1016/j.compag.2018.07.032
   Janarthan S, 2020, IEEE ACCESS, V8, P162588, DOI 10.1109/ACCESS.2020.3021487
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Khattak A, 2021, IEEE ACCESS, V9, P112942, DOI 10.1109/ACCESS.2021.3096895
   Kolivand H, 2019, ARAB J SCI ENG, V44, P3315, DOI 10.1007/s13369-018-3504-8
   Lanjewar Madhusudan G., 2023, Third Congress on Intelligent Systems: Proceedings of CIS 2022. Lecture Notes in Networks and Systems (613), P117, DOI 10.1007/978-981-19-9379-4_10
   Lanjewar MG, 2022, MULTIMED TOOLS APPL, V81, P10313, DOI 10.1007/s11042-022-12200-y
   Lanjewar MG, 2023, EXPERT SYST APPL, V224, DOI 10.1016/j.eswa.2023.119961
   Lanjewar MG, 2023, MULTIMED TOOLS APPL, V82, P29883, DOI 10.1007/s11042-022-14232-w
   Lanjewar MG, 2023, CLUSTER COMPUT, V26, P3657, DOI 10.1007/s10586-022-03752-7
   Lanjewar MG, 2023, MULTIMED TOOLS APPL, V82, P12699, DOI 10.1007/s11042-022-13935-4
   Lanjewar MG, 2023, NEURAL COMPUT APPL, V35, P2755, DOI 10.1007/s00521-022-07743-y
   Lanjewar MG, 2022, MULTIMED TOOLS APPL, V81, P16537, DOI 10.1007/s11042-022-12392-3
   Luaibi A.R., 2021, International Journal of Electrical and Computer Engineering, V11, P1719, DOI [10.11591/ijece.v11i2.pp1719-1727, DOI 10.11591/IJECE.V11I2.PP1719-1727]
   Meshram V., 2021, Artif Intell Life Sci, V1, P100010, DOI DOI 10.1016/J.AILSCI.2021.100010
   Miller SA, 2009, ANNU REV PHYTOPATHOL, V47, P15, DOI 10.1146/annurev-phyto-080508-081743
   Pan WY, 2019, IEEE ACCESS, V7, P87534, DOI 10.1109/ACCESS.2019.2924973
   Parraga-Alava J., 2021, SYSTEMS INFORM SCI, P16, DOI [10.1007/978-3-030-59194-6_2, DOI 10.1007/978-3-030-59194-6_2]
   Patil SB., 2011, Int. J. Eng. Technol, V3, P297, DOI DOI 10.7763/IJET.2011.V3.241
   Prajapati BS, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P2499, DOI 10.1109/ICEEOT.2016.7755143
   Prilianti KR, 2020, J AGRIC ENG-ITALY, V51, P220, DOI 10.4081/jae.2020.1082
   Priyadharshini RA, 2019, NEURAL COMPUT APPL, V31, P8887, DOI 10.1007/s00521-019-04228-3
   Puri Diksha, 2022, International Journal of Information Technology, V14, P931, DOI 10.1007/s41870-019-00353-3
   Pydipati R, 2006, COMPUT ELECTRON AGR, V52, P49, DOI 10.1016/j.compag.2006.01.004
   Qadri S, 2019, INT J FOOD PROP, V22, P2071, DOI 10.1080/10942912.2019.1703738
   Radhika G, 2008, BRIT J NUTR, V99, P398, DOI 10.1017/S0007114507803965
   Rauf HT, 2019, DATA BRIEF, V26, DOI 10.1016/j.dib.2019.104340
   Revathi P., 2012, INT C EM TRENDS SCI, P169, DOI [10.1109/INCOSET.2012.6513900, DOI 10.1109/INCOSET.2012.6513900]
   Santos L, 2020, ADV INTELL SYST COMP, V1092, P139, DOI 10.1007/978-3-030-35990-4_12
   Siddiqi MH, 2009, INT J AGR BIOL PAKIS
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh UP, 2019, IEEE ACCESS, V7, P43721, DOI 10.1109/ACCESS.2019.2907383
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Srinivasu PN, 2021, J REAL-TIME IMAGE PR, V18, P1773, DOI 10.1007/s11554-021-01122-x
   Szczypinski PM, 2015, COMPUT ELECTRON AGR, V110, P1, DOI 10.1016/j.compag.2014.09.016
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Thangaraj R, 2021, J PLANT DIS PROTECT, V128, P73, DOI 10.1007/s41348-020-00403-0
   Thomas S, 2018, J PLANT DIS PROTECT, V125, P5, DOI 10.1007/s41348-017-0124-6
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Tsolakidis DG, 2014, LECT NOTES ARTIF INT, V8445, P406, DOI 10.1007/978-3-319-07064-3_33
   Uguz S, 2021, NEURAL COMPUT APPL, V33, P4133, DOI 10.1007/s00521-020-05235-5
   Vilasini M, 2020, CMC-COMPUT MATER CON, V62, P1445, DOI 10.32604/cmc.2020.08857
   Vishnoi VK, 2021, J PLANT DIS PROTECT, V128, P19, DOI 10.1007/s41348-020-00368-0
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120
   Xiang S, 2021, J PLANT DIS PROTECT, V128, P557, DOI 10.1007/s41348-020-00423-w
   Yang KL, 2020, AGRONOMY-BASEL, V10, DOI 10.3390/agronomy10111721
   Zhang M, 2019, IEEE ACCESS, V7, P49680, DOI 10.1109/ACCESS.2019.2900327
   Zhang SW, 2019, NEURAL COMPUT APPL, V31, P1225, DOI 10.1007/s00521-017-3067-8
NR 65
TC 3
Z9 3
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31733
EP 31758
DI 10.1007/s11042-023-16886-6
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001067933300001
DA 2024-07-18
ER

PT J
AU Pan, Q
   Wei, Q
   Tian, NL
   Liang, XC
AF Pan, Qing
   Wei, Qi
   Tian, Nili
   Liang, Xiaochuan
TI An improved gaitgraph via locally non-shared human skeleton joint
   partitioning strategy and multi-scale temporal convolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; Graph convolutional network; Temporal enhancement;
   Multi-scale
ID GAIT RECOGNITION; SIMILARITY
AB In gait recognition (GR) based on graph convolutional network (GCN), both the limitation of existing human skeleton joint partitioning strategies (HSJPSs) and the ignorance of the difference between frames result in a deterioration of recognition performance. Therefore, an improved GaitGraph method via a new HSJPS and multi-scale temporal convolution (MSTC) is proposed to solve the problems. First, the new HSJPS with the locally non-shared joint (LNS-HSJPS) is designed to acquire the corresponding spatial graph convolutional model, which is employed to replace that of the GaitGraph. Then, the temporal enhancement module (TEM) is introduced into the shallow layer of the network to generate a temporal attention matrix, in order to obtain the most informative skeleton frames in the gait sequence. Finally, an improved spatial temporal block (IST-Block) with MSTC is proposed in the subsequent feature extraction process. Specifically, the MSTC is integrated into the bottleneck structure to sufficiently extract the gait features from both adjacent and non-adjacent frames. The experiments not only validate that the LNS-HSJPS can significantly improve the recognition accuracy of the baseline GaitGraph, but also indicate that our method can achieve superior performance and better robustness under cross-view and cross-walk conditions.
C1 [Pan, Qing; Wei, Qi; Tian, Nili; Liang, Xiaochuan] Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Peoples R China.
C3 Guangdong University of Technology
RP Tian, NL (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Peoples R China.
EM panqing@gdut.edu.cn; 1007491241@qq.com; tiannili@gdut.edu.cn;
   2650489841@qq.com
OI Tian, Nili/0000-0001-6908-0852
FU Young Scientists Fund
FX No Statement Available
CR Ali W, 2021, MULTIMED TOOLS APPL, V80, P4825, DOI 10.1007/s11042-020-09850-1
   Binsaadoon AG, 2016, UKSIM EURO SYMP COMP, P35, DOI 10.1109/EMS.2016.15
   Binsaadoon AG, 2015, UKSIM EURO SYMP COMP, P137, DOI 10.1109/EMS.2015.30
   Bouchrika Imed, 2018, SURVEILLANCE ACTION, P1, DOI DOI 10.1007/978-3-319-68533-5_1
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chao Fan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14213, DOI 10.1109/CVPR42600.2020.01423
   Chao HQ, 2019, AAAI CONF ARTIF INTE, P8126
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   He YW, 2019, IEEE T INF FOREN SEC, V14, P102, DOI 10.1109/TIFS.2018.2844819
   Heidari N, 2021, INT C PATT RECOG, P7907, DOI 10.1109/ICPR48806.2021.9412091
   Khosla Prannay, 2020, ADV NEURAL INFORM PR, V33, P18661
   Lee S, 2021, MULTIMED TOOLS APPL, V80, P34121, DOI 10.1007/s11042-020-09157-1
   Li N, 2020, ARXIV
   Liao RJ, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107069
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Luo J, 2022, MULTIMED TOOLS APPL, V81, P34295, DOI 10.1007/s11042-021-11248-6
   Mendoza O, 2022, MULTIMED TOOLS APPL, V81, P30733, DOI 10.1007/s11042-022-12280-w
   Pan HH, 2023, IEEE T INF FOREN SEC, V18, P2104, DOI 10.1109/TIFS.2023.3254449
   Rijun Liao, 2017, Biometric Recognition. 12th Chinese Conference, CCBR 2017. Proceedings: LNCS 10568, P474, DOI 10.1007/978-3-319-69923-3_51
   Sepas-Moghaddam Alireza, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P124, DOI 10.1109/TBIOM.2020.3031470
   Sepas-Moghaddam A, 2023, IEEE T PATTERN ANAL, V45, P264, DOI 10.1109/TPAMI.2022.3151865
   Shen C, 2022, ARXIV
   Smith LN, 2019, PROC SPIE, V11006, DOI 10.1117/12.2520589
   Sun J, 2022, MULTIMED TOOLS APPL, V81, P33051, DOI 10.1007/s11042-022-13098-2
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Teepe T, 2021, IEEE IMAGE PROC, P2314, DOI 10.1109/ICIP42928.2021.9506717
   Thakkar K, 2018, ARXIV
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wen JQ, 2021, MULTIMED TOOLS APPL, V80, P28777, DOI 10.1007/s11042-021-11107-4
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Xu K, 2021, IEEE T MULTIMEDIA, V24, P3265, DOI 10.1109/TMM.2021.3095809
   Xue Wenqian, 2022, 2022 3rd International Conference on Pattern Recognition and Machine Learning (PRML), P77, DOI 10.1109/PRML56267.2022.9882242
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang JJ, 2022, MED BIOL ENG COMPUT, V60, P2665, DOI 10.1007/s11517-022-02595-z
   Yang SXM, 2014, J FORENSIC SCI, V59, P494, DOI 10.1111/1556-4029.12322
   Yao LX, 2021, INT C PATT RECOG, P2057, DOI 10.1109/ICPR48806.2021.9412714
   Yoshino K, 2022, IEEE/SICE I S SYS IN, P596, DOI 10.1109/SII52469.2022.9708776
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhang W., 2021, IEEE 6 INT C SIGN IM, P19
NR 41
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33923
EP 33940
DI 10.1007/s11042-023-16857-x
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001067934200008
DA 2024-07-18
ER

PT J
AU Cheng, YS
   Shao, MW
   Wan, YC
AF Cheng, Yuanshuo
   Shao, Mingwen
   Wan, Yecong
TI Mutually guided learning of global semantics and local representations
   for image restoration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Image restoration; Convolutional neural network;
   Transformer; Hybrid framework
ID ILLUMINATION
AB The global semantics and the local scene representation are crucial for image restoration. Although existing methods have proposed various hybrid frameworks of convolutional neural networks (CNNs) and Transformers to take into account both, they only focus on the complementarity of their capabilities. On the one hand, these works neglect the mutual guiding role of the two information, and on the other hand, they also ignore that the semantic gap caused by the two different modeling systems of convolution and Self-Attention seriously impede the feature fusion. In this work, we propose to establish entanglement between the global and the local to bridge the semantic gap and achieve mutual-guided modeling of the two features. In the proposed hybrid framework, the modeling of convolution and Self-Attention is no longer independent of each other, but through the proposed Mutual Transposed Cross Attention (MTCA), the mutual dependence of the two is realized, thereby strengthening the joint modeling of local and global. Further, we propose Bidirectional Injection Module (BIM), which makes the global and local features adapt to each other in parallel before fusion and greatly reduces interference in the fusion process caused by semantic gap. The proposed method is qualitatively and quantitatively evaluated on multiple benchmark datasets, and extensive experiments show that our method reaches the state-of-the-art with low computational consumption.
C1 [Cheng, Yuanshuo; Shao, Mingwen; Wan, Yecong] China Univ Petr East China, Sch Comp Sci & Technol, 66 West Changjiang Rd, Qingdao 266580, Shandong, Peoples R China.
C3 China University of Petroleum
RP Shao, MW (corresponding author), China Univ Petr East China, Sch Comp Sci & Technol, 66 West Changjiang Rd, Qingdao 266580, Shandong, Peoples R China.
EM cys1294414023@gmail.com; smw278@126.com; yecongwan@gmail.com
FU National Key Research and development Program of China [2021YFA1000102];
   National Natural Science Foundation of China [62376285, 62272375,
   61673396]; Natural Science Foundation of Shandong Province, China
   [ZR2022MF260]
FX The authors are very indebted to the anonymous referees for their
   critical comments and suggestions for the improvement of this paper.
   This work was supported by National Key Research and development Program
   of China (2021YFA1000102), and in part by the grants from the National
   Natural Science Foundation of China (Nos. 62376285, 62272375, 61673396),
   Natural Science Foundation of Shandong Province, China (No.
   ZR2022MF260).
CR Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti C, 2018, LECT NOTES COMPUT SC, V11182, P620, DOI 10.1007/978-3-030-01449-0_52
   CHARBONNIER P, 1994, IEEE IMAGE PROC, P168
   Chen JP, 2021, NAT PHOTONICS, V15, P570, DOI 10.1038/s41566-021-00828-5
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen YP, 2022, PROC CVPR IEEE, P5260, DOI 10.1109/CVPR52688.2022.00520
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Cun XD, 2020, AAAI CONF ARTIF INTE, V34, P10680
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Ding M., 2022, arXiv
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Du YJ, 2020, IEEE WINT CONF APPL, P2395, DOI 10.1109/WACV45572.2020.9093393
   Feng X., 2022, ARXIV
   Fu L, 2021, PROC CVPR IEEE, P10566, DOI 10.1109/CVPR46437.2021.01043
   Fu XY, 2017, IEEE T IMAGE PROCESS, V26, P2944, DOI 10.1109/TIP.2017.2691802
   Gong H., 2014, P BRIT MACH VIS C BM, P1
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Guo JY, 2022, PROC CVPR IEEE, P12165, DOI 10.1109/CVPR52688.2022.01186
   Guo RQ, 2013, IEEE T PATTERN ANAL, V35, P2956, DOI 10.1109/TPAMI.2012.214
   Hai J., 2021, ARXIV
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hu XW, 2018, PROC CVPR IEEE, P7454, DOI 10.1109/CVPR.2018.00778
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Jiang Z., TOKEN LABELING TRAIN, V85, P4
   Kui Jiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8343, DOI 10.1109/CVPR42600.2020.00837
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Liu RS, 2021, PROC CVPR IEEE, P10556, DOI 10.1109/CVPR46437.2021.01042
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Liu X, 2019, PROC CVPR IEEE, P7000, DOI 10.1109/CVPR.2019.00717
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu Z, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00708-7
   Ma L, 2022, PROC CVPR IEEE, P5627, DOI 10.1109/CVPR52688.2022.00555
   Mehta S., 2021, ARXIV
   Pan XG, 2022, IEEE T PATTERN ANAL, V44, P7474, DOI 10.1109/TPAMI.2021.3115428
   Peng ZL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P357, DOI 10.1109/ICCV48922.2021.00042
   Purohit K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2289, DOI 10.1109/ICCV48922.2021.00231
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Ren DW, 2019, PROC CVPR IEEE, P3932, DOI 10.1109/CVPR.2019.00406
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi CY, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14040773
   Steiner A., 2021, arXiv
   Touvron H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P32, DOI 10.1109/ICCV48922.2021.00010
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Varga D, 2022, SIGNALS-BASEL, V3, P483, DOI 10.3390/signals3030028
   Vaswani A, 2017, ADV NEUR IN, V30
   Wan YC, 2022, KNOWL-BASED SYST, V252, DOI 10.1016/j.knosys.2022.109244
   Wang JF, 2018, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR.2018.00192
   Wang L.-T., 1987, 24th ACM/IEEE Design Automation Conference Proceedings 1987, P2, DOI 10.1145/37888.37889
   Wang ZD, 2022, PROC CVPR IEEE, P17662, DOI 10.1109/CVPR52688.2022.01716
   Wei C, 2018, ARXIV
   Wei W, 2019, PROC CVPR IEEE, P3872, DOI 10.1109/CVPR.2019.00400
   Weng Z., 2021, ARXIV
   Wu HP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P22, DOI 10.1109/ICCV48922.2021.00009
   Wu HY, 2021, PROC CVPR IEEE, P10546, DOI 10.1109/CVPR46437.2021.01041
   Xiao CX, 2013, COMPUT GRAPH FORUM, V32, P207, DOI 10.1111/cgf.12198
   Xu K, 2020, PROC CVPR IEEE, P2278, DOI 10.1109/CVPR42600.2020.00235
   Yang QX, 2012, IEEE T IMAGE PROCESS, V21, P4361, DOI 10.1109/TIP.2012.2208976
   Yang W., 2017, PROC CVPR IEEE, P1685, DOI DOI 10.1109/CVPR.2017.183
   Yang WH, 2020, PROC CVPR IEEE, P3060, DOI 10.1109/CVPR42600.2020.00313
   Yasarla R, 2020, PROC CVPR IEEE, P2723, DOI 10.1109/CVPR42600.2020.00280
   Yasarla R, 2019, PROC CVPR IEEE, P8397, DOI 10.1109/CVPR.2019.00860
   Ye YT, 2021, PROC CVPR IEEE, P2053, DOI 10.1109/CVPR46437.2021.00209
   Zamir Syed Waqas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P492, DOI 10.1007/978-3-030-58595-2_30
   Zamir SW, 2022, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR52688.2022.00564
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zamir SW, 2020, PROC CVPR IEEE, P2693, DOI 10.1109/CVPR42600.2020.00277
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
   Zhang L, 2020, AAAI CONF ARTIF INTE, V34, P12829
   Zhang WQ, 2022, PROC CVPR IEEE, P12073, DOI 10.1109/CVPR52688.2022.01177
   Zhang YH, 2021, INT J COMPUT VISION, V129, P1013, DOI 10.1007/s11263-020-01407-x
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zheng ZR, 2021, PROC CVPR IEEE, P16180, DOI 10.1109/CVPR46437.2021.01592
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 78
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30019
EP 30044
DI 10.1007/s11042-023-16724-9
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066065600005
DA 2024-07-18
ER

PT J
AU Varshney, D
   Singh, A
   Ekbal, A
AF Varshney, Deeksha
   Singh, Anushkha
   Ekbal, Asif
TI Aspect-level sentiment-controlled knowledge grounded multimodal dialog
   generation using generative models for reviews
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aspect; Multimodal; Sentiment; Dialog generation; Knowledge-grounded
AB During a conversation, it is critical for participants to establish what they both agree on, also known as the common ground. Grounding implies recognizing that the listener has understood what the speaker has said, considering several factors. This can be accomplished by basing dialog models on various features like aspects, sentiments, images, and unstructured knowledge documents. The key innovation lies in our novel multi-modal knowledge-grounded context-aware transformer model, which enables a seamless fusion of textual and visual information. We introduce an effective technique for generating reviews based on the user's aspect and sentiment (i.e., aspect-level sentiment-controllable reviews), which serves as the relevant external knowledge for the dialog systems. Our work highlights the importance of incorporating review expertise in knowledge-based multi-modal dialog generation. We utilize the Knowledge Grounded Multi-Modal Dialog (KGMMD) dataset, which includes dial og utterances accompanied by images, aspects, sentiment, and unstructured knowledge in the form of several long hotel reviews for different hotels mentioned in the dataset. The overall framework consists of a dialog encoder, a review generator, and a response decoder, all of which complement one another by generating appropriate reviews, which eventually assist in generating an adequate response. The proposed model outperforms the baseline models for aspect-level sentiment-controlled knowledge-based multimodal response generation with a significant increase in F1-score (13.3%) and BLEU-4 (5.3%) on the KGMMD dataset.
C1 [Varshney, Deeksha; Singh, Anushkha; Ekbal, Asif] IIT Patna, Dept Comp Sci & Engn, Patna 801103, Bihar, India.
   [Varshney, Deeksha; Singh, Anushkha; Ekbal, Asif] IIT Patna, Dept Mech Engn, Patna 801103, Bihar, India.
C3 Indian Institute of Technology (IIT) - Patna; Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Patna; Indian Institute of Technology System (IIT System)
RP Varshney, D (corresponding author), IIT Patna, Dept Comp Sci & Engn, Patna 801103, Bihar, India.; Varshney, D (corresponding author), IIT Patna, Dept Mech Engn, Patna 801103, Bihar, India.
EM 1821cs13@iitp.ac.in; anushkhasingh30@gmail.com; asif@iitp.ac.in
RI Varshney, Deeksha/HJI-5756-2023; Ekbal, Asif/JKI-7638-2023
OI Varshney, Deeksha/0000-0002-2924-5373; 
CR Agarwal Shubham, 2018, P 11 INT C NAT LANG, P129
   Agarwal Shubham, 2018, P 2 INT WORKSH SEARC, P59
   Alamri H, 2018, DSTC7 AAAI2019 WORKS
   [Anonymous], 2019, DSTC7 AAAI2019 WORKS
   Chauhan H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5437
   Chen HM, 2021, AAAI CONF ARTIF INTE, V35, P12639
   Chen XY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2687
   Cui C, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P445, DOI 10.1145/3331184.3331226
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   de Vries H, 2017, PROC CVPR IEEE, P4466, DOI 10.1109/CVPR.2017.475
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Firdaus M., 2020, IEEE Transactions on Affective Computing
   Firdaus M, 2023, Arxiv, DOI arXiv:2305.17433
   Firdaus M, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2318
   Firdaus M, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3430752
   Firdaus M, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207529
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Gan Z, 2019, Arxiv, DOI arXiv:1902.00579
   Gao S, 2021, arXiv
   Golchha H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P851
   Kingma D. P., 2014, arXiv
   Kong X, 2019, Arxiv, DOI arXiv:1901.07129
   Le H, 2019, Arxiv, DOI [arXiv:1907.01166, DOI 10.18653/V1/P19-1564, 10.18653/v1/P19-1564]
   Lee YJ, 2024, Arxiv, DOI arXiv:2212.04119
   Li Z, 2019, arXiv
   Liao LZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P801, DOI 10.1145/3240508.3240605
   Lin KY, 2019, Arxiv, DOI arXiv:1908.08191
   Liu Chia-Wei, 2016, P 2016 C EMPIRICAL M, P2122, DOI [10.18653/v1/D16-1230, DOI 10.18653/V1/D16-1230]
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   Madotto A, 2018, Arxiv, DOI arXiv:1804.08217
   Meng FD, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2574
   Mostafazadeh Nasrin, 2017, arXiv
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Raghu D, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1239
   Reddy R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3744
   Saha A, 2018, AAAI CONF ARTIF INTE, P696
   Saha T, 2021, MULTIMED TOOLS APPL, V80, P35025, DOI 10.1007/s11042-020-09070-7
   Serban IV, 2016, AAAI CONF ARTIF INTE, P3776
   Serban IV, 2017, AAAI CONF ARTIF INTE, P3295
   Shang LF, 2015, Arxiv, DOI arXiv:1503.02364
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sordoni Alessandro, 2015, A hierarchical recurrent encoder-decoder for generative context-aware query suggestion, P553
   Tian Zhiliang, 2023, WWW '23: Proceedings of the ACM Web Conference 2023, P1938, DOI 10.1145/3543507.3583548
   Serban IV, 2016, Arxiv, DOI [arXiv:1507.04808, 10.1017/CBO9781107415324.004]
   Varshney Deeksha, 2021, PACLIC, P425
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O, 2015, Arxiv, DOI arXiv:1506.05869
   Wang J., 2020, P INT C COMPUTATIONA, P4100, DOI 10.18653/v1/2020.coling-main.362
   Wang YF, 2020, MULTIMED TOOLS APPL, V79, P4553, DOI 10.1007/s11042-019-7678-1
   Wu CS, 2019, Arxiv, DOI arXiv:1901.04713
   Xu H, 2019, World Wide Web, ppp1
   Xu Y, 2022, Arxiv, DOI arXiv:2105.06232
   Yang MH, 2015, MULTIMED TOOLS APPL, V74, P10025, DOI 10.1007/s11042-014-2161-5
   Yoshino K, 2019, Arxiv, DOI arXiv:1901.03461
   Zang Hongyu., 2017, Proceedings of the 10th International Conference on Natural Language Generation, P168
   Zang XX, 2021, Arxiv, DOI arXiv:2108.01453
   Zhang B, 2023, Arxiv, DOI arXiv:2308.00400
   Zhang WJ, 2021, Arxiv, DOI arXiv:2106.14444
   Zhou J, 2023, Expert Systems with Applications
NR 59
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29197
EP 29219
DI 10.1007/s11042-023-16720-z
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001063370800004
DA 2024-07-18
ER

PT J
AU Shukla, SSP
   Jain, VK
   Yadav, AK
   Pandey, SK
AF Shukla, Shiv Shankar Prasad
   Jain, Vikas Kumar
   Yadav, Anil Kumar
   Pandey, Samir Kumar
TI Fourth wave Covid19 analyzing using mathematical seirs epidemic model &
   deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SEIRS epidemic model; LSTM; RNN; Soft Max; Adam; Mean Square Error
AB The novel coronavirus (COVID-19) is caused by severe acute respiratory syndrome coronavirus 2 and becomes a global pandemic in a few months. Due to this, many of the country has taken harsh measures such as a complete lockdown, which has severely affected the country's economic growth. Thus, predicting the 4(th) wave of Covid 19 cases in India and knowing the forecast on the Covid19 cases like confirmed cases, death cases and recovered Cases helps the country to pre-planned the measures to be taken. Mathematical modelling and trending AI algorithms can analyze data to trace the spread of diseases or predict future trends, enabling proactive measures and resource allocation. For analyzing the fourth wave Covid19 the SEIRS epidemic model analyze the ideation of epidemics flow and deep neural network model, i.e., optimized LSTM model supports the ideation with trained on the pre-processed featured datasets and predicting or forecasting the confirmed cases, recovered cases and death cases due to Covid19. The model has been trained and tested on real datasets from genuine government sites. The model produces the RSME as 967.94 and R-squared as 0.6. The model also has forecasted confirmed cases from Jan to April 2022 in India, which is very close to the real datasets. Cross-validation has been applied to ensure the performance of the optimized model.
C1 [Shukla, Shiv Shankar Prasad; Jain, Vikas Kumar; Yadav, Anil Kumar] VIT Bhopal Univ, Bhopal Indore Highway, Sehore 466114, Madhya Pradesh, India.
   [Pandey, Samir Kumar] ICFAI Univ Jharkhand, Fac Sci & Technol, Ranchi, Jharkhand, India.
C3 VIT Bhopal University
RP Shukla, SSP (corresponding author), VIT Bhopal Univ, Bhopal Indore Highway, Sehore 466114, Madhya Pradesh, India.
EM shukla.ssp@gmail.com; vikasjainrtu@gmail.com; aky125@gmail.com;
   samirpandey2009@gmail.com
RI Yadav, Anil Kumar/AAP-4332-2021
OI Yadav, Anil Kumar/0000-0001-9264-0977; Yadav, Dr. Anil
   Kumar/0000-0003-4027-8229
CR Adiga A, 2021, MEDRXIV
   Al-qaness MAA, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17103520
   Al-qaness MAA, 2020, J CLIN MED, V9, DOI 10.3390/jcm9030674
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Alsayed A, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17114076
   Alzahrani SI, 2020, J INFECT PUBLIC HEAL, V13, P914, DOI 10.1016/j.jiph.2020.06.001
   Ameet Rana C, 2023, 2023 3 INT C INNOVAT, P1, DOI [10.1109/ICIPTM57143.2023.10118085, DOI 10.1109/ICIPTM57143.2023.10118085]
   Awan N, 2021, IEEE ACCESS, V9, P26502, DOI 10.1109/ACCESS.2021.3056926
   Behnood A, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110051
   Cappi R, 2022, BMJ OPEN, V12, DOI 10.1136/bmjopen-2022-061602
   Car Z, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/5714714
   Chakraborty T, 2020, CHAOS SOLITON FRACT, V135, DOI 10.1016/j.chaos.2020.109850
   Ghafouri-Fard S, 2020, BIOMED PHARMACOTHER, V128, DOI 10.1016/j.biopha.2020.110296
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ivanov D, 2020, INT J PROD RES, V58, P3252, DOI 10.1080/00207543.2019.1634850
   Karaboga D, 2019, ARTIF INTELL REV, V52, P2263, DOI 10.1007/s10462-017-9610-2
   Kermack WO, 1932, P R SOC LOND A-CONTA, V138, P55, DOI 10.1098/rspa.1932.0171
   Kermack WO, 1927, P R SOC LOND A-CONTA, V115, P700, DOI 10.1098/rspa.1927.0118
   Kermack WO., 1933, PROC ROYAL SOC LONDO, V141, P94
   Khan FM, 2020, J SAF SCI RESIL, V1, P12, DOI 10.1016/j.jnlssr.2020.06.007
   Kumar U., 2016, P WORLD C ENG ASS MA, P1, DOI DOI 10.1007/S40011-016-0792-1
   Mirri S, 2020, COMPUTATION, V8, DOI 10.3390/computation8030074
   Otshudiema JO, 2022, J EPIDEMIOL GLOB HEA, V12, P316, DOI 10.1007/s44197-022-00052-6
   Pandey Samir Kumar, 2021, IC3 '21: 2021 Thirteenth International Conference on Contemporary Computing (IC3-2021), P328, DOI 10.1145/3474124.3474173
   Pinter G, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8060890
   Ramanuja E, 2022, J INF TECHNOL RES, V15, DOI 10.4018/JITR.299376
   Rosenblatt F., 1961, AD0256582 CORN AER L
   Sun JC, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-78084-w
   Tricco AC, 2018, ANN INTERN MED, V169, P467, DOI 10.7326/M18-0850
   Yadav Anil Kumar, 2021, Journal of Physics: Conference Series, V1714, DOI 10.1088/1742-6596/1714/1/012010
   Yang MJ, 2020, ONCOTARGETS THER, V13, P8941, DOI 10.2147/OTT.S255126
   Zheng NN, 2020, IEEE T CYBERNETICS, V50, P2891, DOI 10.1109/TCYB.2020.2990162
NR 35
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27507
EP 27526
DI 10.1007/s11042-023-16609-x
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001059026300007
DA 2024-07-18
ER

PT J
AU Boudouh, SS
   Bouakkaz, M
AF Boudouh, Saida Sarra
   Bouakkaz, Mustapha
TI New enhanced breast tumor detection approach in mammogram scans based on
   pre-processing and deep transfer learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Mammography; Deep transfer learning; Pre-processing; DDSM
ID CANCER; SEGMENTATION
AB Breast cancer has surpassed heart disease as the second most common cause of mortality among women. Amongst several imaging techniques, mammogram scans are considered the most accurate and effective technique for detecting and diagnosing breast cancer. In this study, we propose an effective mammography pre-processing strategy that has been proven through a classification stage to evaluate its effectiveness. Hence, propose an accurate breast tumor detection model as the first step toward cancer detection. Several filters were used in the first stage, which is the pre-processing. In the second phase, which is tumor detection, various deep learning techniques were employed, including transfer learning, data augmentation, and global pooling techniques. To achieve that, we proposed a CNN architecture for mammogram scan classification, where for the feature extraction phase we used transfer learning techniques, in which six pre-trained CNN models were used for feature extraction: InceptionResNetV2, EfficientNetB7, DenseNet201, MobileNetV2, ResNet152V2, and VGG16. Meanwhile, for the classification phase, instead of using traditional ML algorithms or fully connected layers, we used global pooling techniques. The obtained results were satisfying, putting InceptionResNetV2 and VGG16 trials ahead of the other feature extractors with 99.83% accuracy, followed by the MobileNetV2 trial with 99.42%. That was due to the well-chosen pre-processing filters. Meanwhile, the other models establish good results as well regarding the previous studies. As for the classification phase influence, using global average pooling was more suitable for the majority of the models, except for InceptionResNetV2 and MobileNetV2 feature extractors where global max pooling achieved better results. Additionally, we were able to determine the best parameters for each model, as well as the influencing criteria.
C1 [Boudouh, Saida Sarra; Bouakkaz, Mustapha] Univ Laghouat Amar Telidji, LIM Lab, Laghouat, Algeria.
RP Boudouh, SS (corresponding author), Univ Laghouat Amar Telidji, LIM Lab, Laghouat, Algeria.
EM s.boudouh@lagh-univ.dz; m.bouakkaz@lagh-univ.dz
RI Boudouh, Saida Sarra/HOF-0638-2023
OI Boudouh, Saida Sarra/0000-0002-2608-747X
CR Ahmed AA., 2021, Tumor detection and classification in breast mammography based on fine-tuned convolutional neural networks, DOI [10.21608/ijci.2021.103605.1063, DOI 10.21608/IJCI.2021.103605.1063]
   Al-Najdawi N, 2015, APPL SOFT COMPUT, V35, P175, DOI 10.1016/j.asoc.2015.06.029
   Albalawi U., 2020, Classification of breast cancer mammogram images using convolution neural network
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Babu A, 2022, 2022 1 INT C EL EL I, P1, DOI [10.1109/ICEEICT53079.2022.9768548, DOI 10.1109/ICEEICT53079.2022.9768548, 10.1109/iceeict53079.2022.9768548]
   Boudouh SS, 2023, MULTIMED TOOLS APPL, V82, P34913, DOI 10.1007/s11042-023-14410-4
   Boudouh SS, 2022, PROCEEDING OF THE 2ND 2022 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND SOFTWARE ENGINEERING (CSASE 2022), P289, DOI 10.1109/CSASE51777.2022.9759702
   Boudouh SS, 2022, 2022 7 INT C IM SIGN, P1, DOI [10.1109/ISPA54004.2022.9786351, DOI 10.1109/ISPA54004.2022.9786351]
   Charan SG, 2018, 2018 INT C COMPUTING, P1
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   DeSantis CE, 2019, CA-CANCER J CLIN, V69, P211, DOI 10.3322/caac.21555
   Dong L., 2020, J Inst Ind Appl Eng, V8, P117
   Gardezi SJS, 2019, J MED INTERNET RES, V21, DOI 10.2196/14464
   Gumaei A., 2012, 2012 Symposium on Broadband Networks and Fast Internet (RELABIRA), P97, DOI 10.1109/RELABIRA.2012.6235102
   He KM, 2016, Arxiv, DOI arXiv:1603.05027
   Heath M, 2022, THE DIGITAL DATABASE FOR SCREENING MAMMOGRAPHY, P10
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jafari SH, 2018, J CELL PHYSIOL, V233, P5200, DOI 10.1002/jcp.26379
   Kamil MY., 2021, Indonesian J Electr Eng Comput Sci, V22, P809, DOI [10.11591/ijeecs.v22.i2.pp809-817, DOI 10.11591/IJEECS.V22.I2.PP809-817]
   Keras documentation, 2022, Keras applications
   Khamparia A, 2021, MULTIDIM SYST SIGN P, V32, P747, DOI 10.1007/s11045-020-00756-7
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Liu Q, 2020, AUTOMATIKA-UK, V61, P496, DOI 10.1080/00051144.2020.1785784
   Mahmood T, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0263126
   Mohiyuddin A, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/1359019
   Mustafa M., 2017, Indonesian J Electr Eng Comput Sci, V5, P577, DOI [10.11591/ijeecs.v5.i3.pp577-583, DOI 10.11591/IJEECS.V5.I3.PP577-583]
   Omonigho EL, 2020, 2020 INT C MATH COMP, P1
   Rasheed A, 2021, Arxiv, DOI arXiv:2103.03602
   Saber A, 2021, IEEE ACCESS, V9, P71194, DOI 10.1109/ACCESS.2021.3079204
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shrivastava N, 2020, MULTIMED TOOLS APPL, V79, P26467, DOI 10.1007/s11042-020-09220-x
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan MX, 2020, Arxiv, DOI arXiv:1905.11946
   Tarique M., 2015, J BIOMED ENG MED IMA, V2, DOI [10.14738/jbemi.24.1308, DOI 10.14738/JBEMI.24.1308]
   Tensorflow, 2022, About us
   Waks AG, 2019, JAMA-J AM MED ASSOC, V321, P288, DOI 10.1001/jama.2018.19323
   Wellings E, 2016, CUREUS J MED SCIENCE, V8, DOI 10.7759/cureus.945
   Zhang C, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237674
   Zhou JY, 2020, SHOCK VIB, V2020, DOI 10.1155/2020/8863388
   Zhou TF, 2023, MED IMAGE ANAL, V83, DOI 10.1016/j.media.2022.102599
NR 42
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27357
EP 27378
DI 10.1007/s11042-023-16545-w
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001059921400009
DA 2024-07-18
ER

PT J
AU Kong, R
   Li, XY
   Wang, JK
   Wang, XL
AF Kong, Rui
   Li, Xianyong
   Wang, Jiankun
   Wang, Xiaoling
TI Image segmentation based on U-Net plus plus ?network method to identify
   <i>Bacillus Subtilis</i> cells in micro-droplets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE U-Net plus plus; Microfluidics; Micro-droplets; Bacillus subtilis; Image
   segmentation
AB The study of the formation of Bacillus subtilis biofilms in microdroplets has great significance for understanding the biofilms growth in extreme environments. Due to the cell motion, cells observed by microscope have the characteristics of fuzzy edge information, low contrast and noise. it is difficult to segment targets from the background by traditional segmentation methods, but artificial intelligence has a better performance in the field of biological images. In the experiment, a two-stage cross microfluidic tube control system is used to obtain mono-disperse droplets containing Bacillus subtilis, and the image data are captured by a fast camera through a dark field microscope. In this paper, U-Net++ neural network model is used to identify cells. The encoder is used to extract high-level features of images. The decoder restores the features extracted by the encoder. Dense jump connection reduces the semantic gap between encoder and decoder, captures details and improves segmentation performance. Compared with the traditional segmentation methods, the U-Net++ model can be applied even in cases of low contrast and noise, and improves the accuracy and robustness of image segmentation. The U-Net++ method is compared with the traditional threshold segmentation method in terms of a series of metrics (accuracy, recall, F1 score, Intersection over Union). It is demonstrated that this method can extract target information of cells effectively. The U-Net++ method can be further used to analyze the movement of cells and help understanding the biofilm formation in micro-droplets.
C1 [Kong, Rui; Li, Xianyong; Wang, Jiankun; Wang, Xiaoling] Univ Sci & Technol Beijing, Sch Mech Engn, Beijing 100083, Peoples R China.
   [Wang, Xiaoling] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
C3 University of Science & Technology Beijing; Harvard University
RP Wang, XL (corresponding author), Univ Sci & Technol Beijing, Sch Mech Engn, Beijing 100083, Peoples R China.; Wang, XL (corresponding author), Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
EM xiaoling@me.ustb.edu.cn
RI zhang, yingying/KGM-8162-2024; Wang, Xiaoling/GNP-7602-2022
OI zhang, yingying/0000-0001-7479-3398; 
FU National Natural Science Foundation of China [11972074, 11772047,
   11620101001]
FX The authors would like to thank Professor David A. Weitz of Harvard
   University and Professor Shmuel Rubinstein of the Hebrew University for
   their experimental support; and the National Natural Science Foundation
   of China for funding support (11972074, 11772047 and 11620101001).
CR Ali S, 2012, IEEE T MED IMAGING, V31, P1448, DOI 10.1109/TMI.2012.2190089
   Chenyue Wu B., 2018, J OPT, V38, P125
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Kingma D. P., 2014, arXiv
   Kumar N, 2020, IEEE T MED IMAGING, V39, P1380, DOI 10.1109/TMI.2019.2947628
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ronneberger O., 2015, CELL, V11, P648
   Schmitt O, 2009, COMPUT VIS IMAGE UND, V113, P188, DOI 10.1016/j.cviu.2008.08.011
   Ssong H., 2003, ANGEW CHEM, V115, P792, DOI [10.1002/ange.200390172, DOI 10.1002/ANGE.200390172]
   Tingyue Zheng C., 2019, J OPT, V39, P0211002
   Wu Peng, APPL IMAGE FEATURE E
   Xiao ZL, 2011, CHIN J CHROMATOGR, V29, P949, DOI 10.3724/SP.J.1123.2011.00949
   Yi JR, 2019, MED IMAGE ANAL, V55, P228, DOI 10.1016/j.media.2019.05.004
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
   Zhu J, 2019, LASER OPTOELECTRON P, V56, P67
   Zhu S, 2014, An Image segmentation method based on the combination of graph theory and semi-supervised learning, Patent No. [CN103942779A, 103942779]
   Zunair H, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104699
NR 19
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27747
EP 27759
DI 10.1007/s11042-023-16509-0
EA SEP 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001059921400003
DA 2024-07-18
ER

PT J
AU Agarwal, L
   Verma, B
AF Agarwal, Lakshita
   Verma, Bindu
TI From methods to datasets: A survey on Image-Caption Generators
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image- Caption Generator; Natural language processing; Computer vision;
   Intelligent exploration; Deep learning
AB Image - Caption Generator is a popular Artificial Intelligence research tool that works with image comprehension and language definition. Creating well-structured sentences requires a thorough understanding of language in a systematic and semantic way. Being able to describe the substance of an image using well-structured phrases is a difficult undertaking, but it can have a significant impact in terms of assisting visually impaired people in better understanding the images' content. Image captions has gained a lot of attention as a study subject for various computer vision and natural language processing (NLP) applications. The goal of image captions is to create logical and accurate natural language phrases that describes an image. It relies on the caption model to see items and appropriately characterise their relationships. Intuitively, it is also difficult for a machine to see a typical image in the same way that humans do. It does, however, provide the foundation for intelligent exploration in deep learning. In this review paper, we will focus on the latest in-depth advanced captions techniques for image captioning. This paper highlights related methodologies and focuses on aspects that are crucial in computer recognition, as well as on the numerous strategies and procedures being developed for the development of image captions. It was also observed that Recurrent neural networks (RNNs) are used in the bulk of research works (45%), followed by attention-based models (30%), transformer-based models (15%) and other methods (10%). An overview of the approaches utilised in image captioning research is discussed in this paper. Furthermore, the benefits and drawbacks of these methodologies are explored, as well as the most regularly used data sets and evaluation processes in this sector are being studied.
C1 [Agarwal, Lakshita; Verma, Bindu] Delhi Technol Univ, Dept Informat Technol, Delhi 110042, India.
C3 Delhi Technological University
RP Verma, B (corresponding author), Delhi Technol Univ, Dept Informat Technol, Delhi 110042, India.
EM lakshitaagarwal_2k21phdit05@dtu.ac.in; bindu.cvision@gmail.com
FU Department of Information Technology, Delhi Technological University,
   New Delhi, India
FX The author would like to acknowledge Department of Information
   Technology, Delhi Technological University, New Delhi, India for
   providing me necessary resources to carry out the research.
CR Agrawal H, 2019, IEEE I CONF COMP VIS, P8947, DOI 10.1109/ICCV.2019.00904
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Aneja J, 2018, PROC CVPR IEEE, P5561, DOI 10.1109/CVPR.2018.00583
   Anitha Kumari K, 2019, INT C ART INT SMART, P679
   [Anonymous], 2013, P 2013 C EMP METH NA
   Bai S, 2018, NEUROCOMPUTING, V311, P291, DOI 10.1016/j.neucom.2018.05.080
   Changpinyo S, 2021, PROC CVPR IEEE, P3557, DOI 10.1109/CVPR46437.2021.00356
   Chen C, 2019, AAAI CONF ARTIF INTE, P8142
   Chen F., 2021, J. Phys. Conf. Ser., V1914
   Chen J, 2022, PROC CVPR IEEE, P18009, DOI 10.1109/CVPR52688.2022.01750
   Chen XL, 2014, Arxiv, DOI arXiv:1411.5654
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Choi Y, 2011, P 15 C COMPUTATIONAL, P220
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Demner-Fushman D, 2016, J AM MED INFORM ASSN, V23, P304, DOI 10.1093/jamia/ocv080
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Devlin J, 2015, Arxiv, DOI arXiv:1505.04467
   Elhagry A, 2021, A thorough review on recent deep learning methodologies for image captioning
   Feng Y, 2019, PROC CVPR IEEE, P4120, DOI 10.1109/CVPR.2019.00425
   Gonog L, 2019, C IND ELECT APPL, P505, DOI [10.1109/ICIEA.2019.8833686, 10.1109/iciea.2019.8833686]
   Guo LT, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P765, DOI 10.1145/3343031.3350943
   Han SH, 2020, INT CONF BIG DATA, P526, DOI 10.1109/BigComp48618.2020.00-12
   He S., 2020, P ASIAN C COMPUTER V
   Hede P., 2004, RIAO, P306
   Hendricks LA, 2016, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2016.8
   Hessel J, 2015, Arxiv, DOI arXiv:1508.02091
   Hsu T. -Y., 2021, arXiv
   Hu R., 2020, COMPUTER VISION ECCV, P742
   Hu X., 2022, IEEE C COMP VIS PATT, P17980
   Hu XW, 2021, Arxiv, DOI arXiv:2009.13682
   Ilse M., 2018, Attention-based deep multiple instance learning, P2127
   Escalante HJ, 2010, COMPUT VIS IMAGE UND, V114, P419, DOI 10.1016/j.cviu.2009.03.008
   Janakiraman J., 1992, IJCNN International Joint Conference on Neural Networks (Cat. No.92CH3114-6), P541, DOI 10.1109/IJCNN.1992.227117
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Khan R, 2022, Arxiv, DOI arXiv:2203.01594
   Kim DJ, 2022, IEEE T PATTERN ANAL, V44, P7348, DOI 10.1109/TPAMI.2021.3119754
   Kim DJ, 2019, PROC CVPR IEEE, P6264, DOI 10.1109/CVPR.2019.00643
   Kinghorn P, 2018, NEUROCOMPUTING, V272, P416, DOI 10.1016/j.neucom.2017.07.014
   Kumar D, 2020, A review of deep learning based image captioning models
   Kuznetsova P., 2012, Long Papers, P359
   Lebret R, 2015, Arxiv, DOI arXiv:1412.8419
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li NN, 2019, AAAI CONF ARTIF INTE, P8626
   Li X J., 2020, P EUR C COMP VIS, P121, DOI DOI 10.1007/978-3-030-58577-8_8
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu SQ, 2017, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2017.100
   Luo YP, 2021, AAAI CONF ARTIF INTE, V35, P2286
   Mao JH, 2015, Arxiv, DOI arXiv:1412.6632
   Mao JH, 2016, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2016.9
   Mao JH, 2015, IEEE I CONF COMP VIS, P2533, DOI 10.1109/ICCV.2015.291
   Mason Rebecca., 2014, P 18 C COMPUTATIONAL, P11
   Mathews A, 2016, AAAI CONF ARTIF INTE, P3574
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Mun J, 2017, AAAI CONF ARTIF INTE, P4233
   Ordonez V., 2011, ADV NEURAL INFORM PR, P1143
   Pan JY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1987, DOI 10.1109/ICME.2004.1394652
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Saheel S., Baby talk: Understanding and generating image descriptions
   Seo PH, 2020, AAAI CONF ARTIF INTE, V34, P2693
   Shao Z, 2023, IEEE T MULTIMEDIA
   Shao Zhuang, 2022, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2022.3152990
   Sharma G, 2019, 2 INT C ADV SCI TECH
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Song ZL, 2021, AAAI CONF ARTIF INTE, V35, P2584
   Spratling MW, 2004, J COGNITIVE NEUROSCI, V16, P219, DOI 10.1162/089892904322984526
   Stefanini M, 2021, arXiv
   Stefanini M., 2022, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Sundaramoorthy C, 2021, Arxiv, DOI arXiv:2104.14721
   Tan YH, 2019, NEUROCOMPUTING, V333, P86, DOI 10.1016/j.neucom.2018.12.026
   Tan YH, 2017, LECT NOTES COMPUT SC, V10115, P101, DOI 10.1007/978-3-319-54193-8_7
   Tanti M, 2017, Arxiv, DOI arXiv:1708.02043
   van Miltenburg E, 2016, Arxiv, DOI arXiv:1605.06083
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2017, PROC CVPR IEEE, P1170, DOI 10.1109/CVPR.2017.130
   Wang H., 2020, Computational intelligence and neuroscience: An overview of image caption generation methods
   Wang JN, 2023, IEEE T PATTERN ANAL, V45, P2088, DOI 10.1109/TPAMI.2022.3159811
   Wikipedia contributors, 2022, Photo caption-Wikipedia, The Free Encyclopedia
   Xiao XY, 2019, PATTERN RECOGN, V90, P285, DOI 10.1016/j.patcog.2019.01.028
   Xiong YX, 2019, LECT NOTES COMPUT SC, V11861, P673, DOI 10.1007/978-3-030-32692-0_77
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang M, 2020, IEEE T IMAGE PROCESS, V29, P9627, DOI 10.1109/TIP.2020.3028651
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   Yoshikawa Y, 2017, arXiv
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
   Zhang PC, 2021, PROC CVPR IEEE, P5575, DOI 10.1109/CVPR46437.2021.00553
   Zheng Y, 2019, PROC CVPR IEEE, P8387, DOI 10.1109/CVPR.2019.00859
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
   Zhou LW, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P305, DOI 10.1145/3126686.3126717
   Zhou YAN, 2020, PROC CVPR IEEE, P4776, DOI 10.1109/CVPR42600.2020.00483
NR 103
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 28077
EP 28123
DI 10.1007/s11042-023-16560-x
EA AUG 2023
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062556300005
DA 2024-07-18
ER

PT J
AU Xiao, BJ
   Nguyen, M
   Yan, WQ
AF Xiao, Bingjie
   Nguyen, Minh
   Yan, Wei Qi
TI Fruit ripeness identification using YOLOv8 model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE YOLOv8; CenterNet; Visual object detection
AB Deep learning-based visual object detection is a fundamental aspect of computer vision. These models not only locate and classify multiple objects within an image, but they also identify bounding boxes. The focus of this paper's research work is to classify fruits as ripe or overripe using digital images. Our proposed model extracts visual features from fruit images and analyzes fruit peel characteristics to predict the fruit's class. We utilize our own datasets to train two "anchor-free" models: YOLOv8 and CenterNet, aiming to produce accurate predictions. The CenterNet network primarily incorporates ResNet-50 and employs the deconvolution module DeConv for feature map upsampling. The final three branches of convolutional neural networks are applied to predict the heatmap. The YOLOv8 model leverages CSP and C2f modules for lightweight processing. After analyzing and comparing the two models, we found that the C2f module of the YOLOv8 model significantly enhances classification results, achieving an impressive accuracy rate of 99.5%.
C1 [Xiao, Bingjie; Nguyen, Minh; Yan, Wei Qi] Auckland Univ Technol, Auckland 1010, New Zealand.
C3 Auckland University of Technology
RP Xiao, BJ (corresponding author), Auckland Univ Technol, Auckland 1010, New Zealand.
EM bingjie.xiao@autuni.ac.nz
RI Nguyen, Minh/KLD-0648-2024
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions
CR Alzahrani MS, 2023, AGRONOMY-BASEL, V13, DOI 10.3390/agronomy13051184
   Basri H, 2018, 2018 INTERNATIONAL ELECTRONICS SYMPOSIUM ON KNOWLEDGE CREATION AND INTELLIGENT COMPUTING (IES-KCIC), P337, DOI 10.1109/KCIC.2018.8628566
   Egi Y, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12091290
   Fu LH, 2022, AGRONOMY-BASEL, V12, DOI 10.3390/agronomy12020391
   Gao FF, 2022, COMPUT ELECTRON AGR, V197, DOI 10.1016/j.compag.2022.107000
   Gao JB, 2022, AGRONOMY-BASEL, V12, DOI 10.3390/agronomy12092081
   Häni N, 2020, J FIELD ROBOT, V37, P263, DOI 10.1002/rob.21902
   Huang HQ, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22010059
   Jaju S, 2022, 2022 INT C APPL ART, P307, DOI DOI 10.1109/ICAAIC53929.2022.9792697
   Ji W, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12060856
   Kang HW, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105108
   Kim Jun-Hwa, 2023, ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1, DOI 10.1109/ICASSP49357.2023.10095516
   Latha R. S., 2022, 2022 INT C COMPUTER, DOI [10.1109/ICCCI54379.2022.9740820, DOI 10.1109/ICCCI54379.2022.9740820]
   Lee J, 2022, MULTIMED TOOLS APPL, V81, P36375, DOI 10.1007/s11042-021-11480-0
   Li G, 2022, COMPUT ELECTRON AGR, V201, DOI 10.1016/j.compag.2022.107342
   Li K, 2022, BIOSYST ENG, V222, P29, DOI 10.1016/j.biosystemseng.2022.07.014
   Li T, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14030482
   Liu GX, 2022, FRONT PLANT SCI, V13, DOI 10.3389/fpls.2022.942875
   Liu TH, 2023, PRECIS AGRIC, V24, P139, DOI 10.1007/s11119-022-09935-x
   Mai XC, 2018, IEEE INT CONF ROBOT, P7166
   Nguyen M., 2022, Lecture Notes in Computer Science, V13836, P48, DOI [10.1007/978-3-031-25825-1_4, DOI 10.1007/978-3-031-25825-1_4]
   Qi J., 2022, Introduction to adaptation in the Global Stocktake Issue April, P1
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Sun ML, 2023, COMPUT ELECTRON AGR, V205, DOI 10.1016/j.compag.2022.107609
   Tang YC, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118573
   Tian YN, 2019, COMPUT ELECTRON AGR, V157, P417, DOI 10.1016/j.compag.2019.01.012
   Ukwuoma CCC, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/9210947
   Ullah KR, 2019, International Journal of Image, Graphics and Signal Processing, V8, P1, DOI DOI 10.5815/IJIGSP.2019.08.01
   Villacrés J, 2023, COMPUT ELECTRON AGR, V204, DOI 10.1016/j.compag.2022.107513
   Wan SH, 2020, COMPUT NETW, V168, DOI 10.1016/j.comnet.2019.107036
   Wang C, 2023, J INTELL FUZZY SYST, V44, P8585, DOI 10.3233/JIFS-222954
   Wang Q, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107884
   Wang XL, 2020, IEEE ACCESS, V8, P110227, DOI 10.1109/ACCESS.2020.3001279
   Wang ZP, 2022, POSTHARVEST BIOL TEC, V185, DOI 10.1016/j.postharvbio.2021.111808
   Xiao B., 2021, Commun. Comput. Inf. Sci, P53, DOI [10.1007/978-3-030-72073-5_5, DOI 10.1007/978-3-030-72073-5_5]
   Yang R., 2022, Mobile Information Systems, V2022, P1
   Yao J, 2022, PLANTS-BASEL, V11, DOI 10.3390/plants11060768
   Zeng NY, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3153997
   Zhang F, 2022, COMPUT ELECTRON AGR, V195, DOI 10.1016/j.compag.2022.106824
   Zhang WL, 2022, HORTIC RES-ENGLAND, V9, DOI 10.1093/hr/uhac003
   Zhao K., 2021, ISGV 2021, V1386, P313, DOI DOI 10.1007/978-3-030-72073-5_24
   Zhou JC, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12070993
NR 42
TC 15
Z9 15
U1 331
U2 705
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 28039
EP 28056
DI 10.1007/s11042-023-16570-9
EA AUG 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062556300004
OA hybrid
DA 2024-07-18
ER

PT J
AU Dubey, RK
   Choubey, DK
AF Dubey, Ratnesh Kumar
   Choubey, Dilip Kumar
TI Adaptive feature selection with deep learning MBi-LSTM model based paddy
   plant leaf disease classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Paddy leaf plant; Deep learning; Gaussian filter; SV-RFE; MBi-LSTM; And
   rain optimization algorithm
ID NETWORK
AB For some nations, including India, agriculture is the main source of income. Crop/plant infections are important factors in reduced production quantity and quality, which leads to economic loss. Therefore, it is essential to detect crop diseases as soon as possible. The symptoms of plant diseases can be seen in several parts of a plant. Plant leaves, however, are frequently used to diagnose infections. Therefore, in this paper, we focus on using the deep learning model to automatically detect leaf disease. The pre-processing, feature extraction, feature selection, and classification phases constituents of the presented model. The images of the paddy leaf are first converted into an RGB color model, and the noise in the green band is subsequently removed using a Gaussian filter. The green band is then used to extract the texture and color features. Important features are selected using a combination of machine learning and optimization algorithms after feature extraction. Here, support vector machine-recursive feature elimination (SV-RFE) and an adaptive red fox algorithm (ARFA) are used to initially select the features. Then, the common features are selected. The selected features are given to the modified bi-long short-term memory (MBi-LSTM) classifier to classify an image as Blast disease, Bacterial Leaf Blight disease, Tungro, or normal image. The experimental results shows, the proposed method achieves the better accuracy of 97.16% which is high compared to state-of-the-art-techniques.
C1 [Dubey, Ratnesh Kumar; Choubey, Dilip Kumar] Indian Inst informat technol Bhagalpur, Dept CSE, Bhagalpur, Bihar, India.
RP Dubey, RK (corresponding author), Indian Inst informat technol Bhagalpur, Dept CSE, Bhagalpur, Bihar, India.
EM ratneshdub@gmail.com; dilipchoubey_1988@yahoo.in
RI dubey, ratnesh/IVH-1489-2023; Choubey, Dilip Kumar/D-2497-2018
OI dubey, ratnesh/0000-0002-2749-0949; Choubey, Dilip
   Kumar/0000-0002-1233-7159
CR Alruwaili M., 2019, Int. J. Adv. Technol. Eng. Explor., V19, P7159, DOI [10.35940/ijeat.a1907.109119, DOI 10.35940/IJEAT.A1907.109119]
   Atole RR, 2018, INT J ADV COMPUT SC, V9, P67
   Azim MA., 2021, Telecommun. Comput. Electronics Control TELKOMNIKA, V19, P463, DOI [10.12928/telkomnika.v19i2.16488, DOI 10.12928/TELKOMNIKA.V19I2.16488]
   Bari BS, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.432
   Cerveny J, DIRECTIONALPREFERENC
   Fischer RA, 2018, FIELD CROP RES, V222, P121, DOI 10.1016/j.fcr.2018.03.008
   Iqbal Z, 2018, COMPUT ELECTRON AGR, V153, P12, DOI 10.1016/j.compag.2018.07.032
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Kiruba B., 2023, P 6 JOINT INT C DAT, P203, DOI DOI 10.1145/3570991.3570994
   Kumar S, 2021, J INTERNET TECHNOL, V22, P891, DOI 10.53106/160792642021072204016
   Leelavathy B, 2020, P INT C COMP INT DAT, P337, DOI DOI 10.1007/978-981-15-8767-2_29
   Mohammadi H, 2023, ACTA CARDIOL, V78, P813, DOI 10.1080/00015385.2022.2148896
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Prottasha SI, 2022, INT J ELECT COMPUT E, V12
   Senan N, 2020, INT J ADV COMPUT SC, V11, P116
   Sethy PK., 2020, INDONESIAN J ELECT E, V19, P1590, DOI [DOI 10.11591/IJEECS.V19.I3.PP1590-1595, 10.11591/ijeecs.v19.i3.pp1590-1595]
   Shrivastava V.K., 2019, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, V42, P631, DOI 10.5194/isprs-archives-XLII-3-W6-631-2019
   Singh UP, 2019, IEEE ACCESS, V7, P43721, DOI 10.1109/ACCESS.2019.2907383
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Tabbakh A., 2023, IEEE Access
   Tamilvizhi T, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/3452413
NR 22
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25543
EP 25571
DI 10.1007/s11042-023-16475-7
EA AUG 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001054228300001
DA 2024-07-18
ER

PT J
AU Bicer, MB
   Aydin, EA
AF Bicer, Mustafa Berkan
   Aydin, Emine Avsar
TI Analyzing equilateral triangle compact microstrip antennas using
   Gaussian process regression for telemedicine and mobile biomedical
   imaging systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artificial neural networks; Equilateral triangle microstrip antennas;
   Flexible antennas; Healthcare; Gaussian process regression; Resonant
   frequency estimation; Support vector machines; Telemedicine
ID WIDE-BAND ANTENNA; RESONANT FREQUENCIES; BREAST-CANCER; PATCH ANTENNA;
   DESIGN; MODEL
AB Antennas are vital in the internet of things (IoT) for enabling telemedicine and healthcare communication between devices and networks. They receive and transmit signals, extending range, improving efficiency, and reducing power consumption. Antennas are versatile and can be integrated into devices or added as external modules. Their flexibility and adaptability are important in applications involving humans, as they can bend and conform to the shape of the body. Overall, antennas are a crucial and adaptable component of IoT technology. The first thing that needs to be done is to determine the frequency at which the antenna should operate for the problem at hand and design an antenna that can work at those resonant frequencies. In this study, equilateral triangular-shaped compact microstrip antennas (ETMAs) were chosen, and their resonance frequencies were calculated using the Gaussian process regression method (GPR). For this purpose, 630 ETMA were simulated, and a dataset was created utilizing the antenna characteristics and resonant frequencies. Support vector machines (SVM), artificial neural networks (ANN), and GPR models were trained on the obtained data set. To validate the performance of the trained models, two ETMAs with an outer length of 50 mm and an inner slot length of 5 mm were fabricated utilizing polylactic acid (PLA) and felt-based substrates with copper tape as the conducting material. The accuracy of the resonant frequency estimation using the GPR approach for the fabricated antennas is 2.833% and 1.706% for the PLA- and felt-based antennas, respectively, when compared to the measurement results. The GPR model trained in this study has an accuracy of 0.470% and 0.662% when compared to simulations in the literature and measurement results, respectively. In addition, one of the designed antennas is in wearable form, and the other is PLA, produced with a low-cost 3D printer, allowing continuous monitoring of patients with high cancer risk. In this article, an easier and cheaper microstrip patch antenna that can be used for imaging and telemedicine applications is designed with a copper band on one flexible and one rigid substrate, and its performance is analyzed experimentally.
C1 [Bicer, Mustafa Berkan] Tarsus Univ, Dept Elect Elect Engn, Tarsus, Mersin, Turkiye.
   [Aydin, Emine Avsar] Adana Alparslan Turkes Sci & Technol Univ, Dept Aerosp Engn, Adana, Turkiye.
C3 Tarsus University; Adana Alparslan Turkes Science & Technology
   University
RP Aydin, EA (corresponding author), Adana Alparslan Turkes Sci & Technol Univ, Dept Aerosp Engn, Adana, Turkiye.
EM mberkanbicer@tarsus.edu.tr; eaydin@atu.edu.tr
RI BICER, Mustafa Berkan/F-7742-2015
OI BICER, Mustafa Berkan/0000-0003-3278-6071
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [122E093]
FX This study is supported by The Scientific and Technological Research
   Council of Turkey (TUBITAK) with project number of 122E093.
CR Akalya CG, 2017, INT J COMMUN-US, V02
   Alagarsamy M, 2016, COMPEL, V35, P1538, DOI 10.1108/COMPEL-11-2015-0424
   AlShehhi H, 2018, Arxiv, DOI arXiv:1809.07475
   BAHL IJ, 1981, AEU-ARCH ELEKTRON UB, V35, P214
   Bahl IJ, 1980, MICROSTRIP ANTENNAS, P348
   Balanis C., 2012, ANTENNA THEORY ANAL
   Bhargava D, 2022, CASE STUD THERM ENG, V31, DOI 10.1016/j.csite.2022.101843
   Bisio I, 2018, MULTIMED TOOLS APPL, V77, P9341, DOI 10.1007/s11042-017-4867-7
   Biswas M, 2013, MICROW OPT TECHN LET, V55, P2271, DOI 10.1002/mop.27869
   Boissinot G, 1961, Flat Aerial for Ultra High Frequencies, Patent No. [CA627967A, 627967]
   Byrne D, 2015, IEEE T ANTENN PROPAG, V63, P1725, DOI 10.1109/TAP.2015.2398125
   Cai Run-nan, 2010, 2010 12th IEEE International Conference on Communication Technology (ICCT 2010), P500, DOI 10.1109/ICCT.2010.5688875
   Caorsi S, 2003, IEEE T GEOSCI REMOTE, V41, P2745, DOI 10.1109/TGRS.2003.815676
   Chahat N., 2010, 2010 Loughborough Antennas & Propagation Conference (LAPC 2010), P461, DOI 10.1109/LAPC.2010.5666209
   Chen BX, 2017, AUSTRALAS PHYS ENG S, V40, P21, DOI 10.1007/s13246-017-0522-x
   Chen Q., 2016, 2016 IEEE RADAR C RA, P1, DOI DOI 10.1109/RADAR.2016.7485313
   CHEN W, 1992, IEEE T ANTENN PROPAG, V40, P1253, DOI 10.1109/8.182460
   Clemens M., 2001, Journal of Electromagnetic Waves and Applications, V15, P79, DOI 10.1163/156939301X00661
   DAHELE JS, 1987, IEEE T ANTENN PROPAG, V35, P100, DOI 10.1109/TAP.1987.1143960
   Deschamps GA, 1953, 3 USAF S ANT
   Deshmukh AA., 2010, Wireless Engineering and Technology, V01, P55, DOI 10.4236/wet.2010.12009
   Donnell KM, 2012, IEEE T INSTRUM MEAS, V61, P2320, DOI 10.1109/TIM.2012.2200822
   Elshaboury N, 2023, ENG BASEL, V4, P984, DOI 10.3390/eng4010059
   Faria JV, 2015, THESIS TECNICO LISB
   Fear EC, 2013, IEEE T MICROW THEORY, V61, P2119, DOI 10.1109/TMTT.2013.2255884
   Geneva: World Health Organization, 2020, WHO REP CANC SETT PR
   George YM, 2014, IEEE SYST J, V8, P949, DOI 10.1109/JSYST.2013.2279415
   Guney K, 2016, INT J ELECTRON, V103, P261, DOI 10.1080/00207217.2015.1036366
   Guo L, 2018, BIOELECTROMAGNETICS, V39, P312, DOI 10.1002/bem.22118
   Guo L, 2015, IEEE T ANTENN PROPAG, V63, P4877, DOI 10.1109/TAP.2015.2473000
   Hacke W, 2008, NEW ENGL J MED, V359, P1317, DOI 10.1056/NEJMoa0804656
   Harrington R. F., 1993, FIELD COMPUTATION MO, DOI 10.1109/9780470544631
   HELSZAJN J, 1978, IEEE T MICROW THEORY, V26, P95, DOI 10.1109/TMTT.1978.1129320
   Hossain MD, 2013, IEEE ANTENN WIREL PR, V12, P241, DOI 10.1109/LAWP.2013.2247018
   HOWELL JQ, 1975, IEEE T ANTENN PROPAG, VAP23, P90, DOI 10.1109/TAP.1975.1141009
   Husein MJ, 2018, J SCI ENG RES, V5, P112
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Kapusuz KY, 2013, TEH VJESN, V20, P955
   Kayabasi A, 2021, APPL COMPUT ELECTROM, V36, P1412, DOI 10.13052/2021.ACES.J.361104
   Kayabasi A, 2018, APPL COMPUT ELECTROM, V33, P616
   Kayabasi A, 2015, COGENT ENG, V2, DOI 10.1080/23311916.2014.981944
   Kirtania SG, 2020, MICROMACHINES-BASEL, V11, DOI 10.3390/mi11090847
   Kumar Bhatnagar S, 2020, INT RES J ENG TECHNO
   Kumar M, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P287, DOI 10.1109/ICACCI.2016.7732061
   Kurnaz C., 2018, 2018 41 INT C TEL SI, P1, DOI [10.1109/TSP.2018.8441335, DOI 10.1109/TSP.2018.8441335]
   Kwatkowski TG, 1999, NEW ENGL J MED, V340, P1781
   Lakshmanan R, 2016, PROC TECH, V24, P880, DOI 10.1016/j.protcy.2016.05.149
   Manoufali M, 2017, APMC, V0, P22, DOI [10.1109/APMC.2016.7931363, DOI 10.1109/APMC.2016.7931363]
   Migowski A, 2015, CIENC SAUDE COLETIVA, V20, P1309, DOI 10.1590/1413-81232015204.17772014
   Mohamadzade B, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091375
   Monleone RD, 2012, IEEE T INSTRUM MEAS, V61, P140, DOI 10.1109/TIM.2011.2159144
   MUNSON RE, 1974, IEEE T ANTENN PROPAG, VAP22, P74, DOI 10.1109/TAP.1974.1140723
   NIH National Cancer Institute, 2020, CANC FACTS FIGURES 2
   Nikolova NK, 2011, IEEE MICROW MAG, V12, P78, DOI 10.1109/MMM.2011.942702
   Rahiman MHF, 2019, COMPUT ELECTRON AGR, V164, DOI 10.1016/j.compag.2019.104901
   Rajkamal K, 2018, J THEOR APPL INF TEC, V96, P2015
   Rao PK, 2019, 2019 IEEE 5TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/i2ct45611.2019.9033875
   Rasmussen C.E, 2006, Gaussian Processes for Machine Learning, DOI DOI 10.7551/MITPRESS/3206.001.0001
   Ren K, 2016, IEEE T ANTENN PROPAG, V64, P5198, DOI 10.1109/TAP.2016.2617358
   Sankaralingam S., 2010, Progress In Electromagnetics Research B, V22, P53, DOI 10.2528/PIERB10032705
   Saraswat S, 2015, 2015 4 INT C REL INF, P2, DOI [10.1109/ICRITO.2015.7359238, DOI 10.1109/ICRITO.2015.7359238]
   Singh N, 2015, OPEN ENG, V5, P117, DOI 10.1515/eng-2015-0012
   Singh VK, 2017, WIRELESS PERS COMMUN, V95, P1075, DOI 10.1007/s11277-016-3814-7
   Sun YY, 2014, IET MICROW ANTENNA P, V8, P1363, DOI 10.1049/iet-map.2013.0658
   Taflove A, 2005, ELECTRICAL ENGINEERING HANDBOOK, P629, DOI 10.1016/B978-012170960-0/50046-3
   Tesic K, 2021, MATERIALS, V14, DOI 10.3390/ma14040975
   Toktas A, 2011, J ELECTROMAGNET WAVE, V25, P1718, DOI 10.1163/156939311797164855
   Tripathi A, 2013, INT J ADV INNOV THOU, V2, P1
   Tuovinen T, 2013, INT SYM MED INFORM, P149, DOI 10.1109/ISMICT.2013.6521719
   Ustun D, 2019, AEU-INT J ELECTRON C, V102, P54, DOI 10.1016/j.aeue.2019.02.011
   Volakis J., 1998, FINITE ELEMENT METHO
   Wang J, 2024, Arxiv, DOI [arXiv:2009.10862, 10.48550/arXiv.2009.10862]
   WCRF International, CANC TRENDS
   World Health Organization, Preventing cancer
   Yigit E, 2019, MICROW OPT TECHN LET, V61, P1590, DOI 10.1002/mop.31831
   Zasowski T, 2003, 2003 IEEE CONFERENCE ON ULTRA WIDEBAND SYSTEMS AND TECHNOLOGIES, CONFERENCE PROCEEDINGS, P285
NR 76
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 16
PY 2023
DI 10.1007/s11042-023-16470-y
EA AUG 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2QW4
UT WOS:001049147100007
DA 2024-07-18
ER

PT J
AU Boudouh, SS
   Bouakkaz, M
AF Boudouh, Saida Sarra
   Bouakkaz, Mustapha
TI Breast cancer: new mammography dual-view classification approach based
   on pre-processing and transfer learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Breast cancer; Deep learning; Transfer learning; Pre-processing
AB Breast cancer has surpassed heart diseases as the second most common cause of death among women. In order to correctly detect early breast cancer, which can considerably enhance the patient's chance of survival, mammography scans must precisely identify the specific type and sub-type of breast cancer. However, it remains a serious problem, nonetheless, because of the variety of breast tumor types and sub-types and the intricacy of their microenvironment. Therefore, a problem that needs further investigation is how to develop a reliable breast cancer detection strategy in an efficient factor application to raise patient survival. Hence, in this paper, we provided a two-stage classification strategy to address these problems. Despite the existence of numerous studies conducted in the field, in this work, we investigated the two views of mammography for classification. We presented a pre-processing stage with three sub-strategies and several noise-removal filters. Following that, a classification stage using transfer learning techniques to support the training process. Yet, rather than adjusting a pre-trained CNN model, we developed a new dual-branch model, which is a combination of two pre-trained CNNs. Therefore, we created a dual-view architecture that examines the Cranial Caudal (CC) and Mediolateral Oblique (MLO) views of a mammogram simultaneously. We were able to significantly improve each of the accuracy, sensitivity, and specificity using the CBIS-DDSM dataset, with the best accuracy of 95,86% using the Gaussian filter, followed by the Median filter of 95.43%. Meanwhile, the winner filter attained the lowest accuracy of 81.02%. The experimental results indicated that the suggested approach could perform better in terms of classification than the top-ranked techniques currently in use for breast cancer detection.
C1 [Boudouh, Saida Sarra; Bouakkaz, Mustapha] Univ Laghouat, LIM Lab, Laghouat, Algeria.
C3 Universite Amar Telidji de Laghouat
RP Boudouh, SS (corresponding author), Univ Laghouat, LIM Lab, Laghouat, Algeria.
EM s.boudouh@lagh-univ.dz; m.bouakkaz@lagh-univ.dz
RI Boudouh, Saida Sarra/HOF-0638-2023
OI Boudouh, Saida Sarra/0000-0002-2608-747X
CR Al-Najdawi N, 2015, APPL SOFT COMPUT, V35, P175, DOI 10.1016/j.asoc.2015.06.029
   Babu A, 2022, 2022 1 INT C EL EL I, P1, DOI [10.1109/ICEEICT53079.2022.9768548, DOI 10.1109/ICEEICT53079.2022.9768548, 10.1109/iceeict53079.2022.9768548]
   Bhateja V, 2019, 2022 INT C COMPUTER, P289, DOI [10.1109/csase51777.2022.9759702, DOI 10.1109/CSASE51777.2022.9759702]
   Boudouh SS, 2023, MULTIMED TOOLS APPL, V82, P34913, DOI 10.1007/s11042-023-14410-4
   Boudouh SS, 2022, PROCEEDING OF THE 2ND 2022 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND SOFTWARE ENGINEERING (CSASE 2022), P289, DOI 10.1109/CSASE51777.2022.9759702
   Boudouh SS, 2022, 2022 7 INT C IM SIGN, P1, DOI [10.1109/ISPA54004.2022.9786351, DOI 10.1109/ISPA54004.2022.9786351]
   Buades A, 2011, IMAGE PROCESS ON LIN, V1, P208, DOI 10.5201/ipol.2011.bcm_nlm
   Cao HC, 2021, COMPUT METH PROG BIO, V205, DOI 10.1016/j.cmpb.2021.106033
   DeSantis CE, 2019, CA-CANCER J CLIN, V69, P211, DOI 10.3322/caac.21555
   Divyashree B., 2021, SN COMPUT SCI, V2, P1, DOI [DOI 10.1007/S42979-021-00452-8, 10.1007/s42979-021-00452-8]
   Gozdzialski S, 2019, SIMULTANEOUS DETECTI
   Harbeck N, 2019, NAT REV DIS PRIMERS, V5, DOI [10.1038/s41572-019-0111-2, 10.1038/s41572-019-0122-z]
   Heath M., THE DIGITAL DATABASE FOR SCREENING MAMMOGRAPHY, P10
   Hoteit Hawraa, 2022, 2022 International Conference on Smart Systems and Power Management (IC2SPM), P25, DOI 10.1109/IC2SPM56638.2022.9988854
   Huang Y, 2022, J PHYS C SERIES, V2400
   Jaamour A, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0280841
   Jafari SH, 2018, J CELL PHYSIOL, V233, P5200, DOI 10.1002/jcp.26379
   Jiang XJ, 2020, ADV METROLOGY, P195, DOI [10.1016/B978-0-12-821815-0.00009-5, DOI 10.1016/B978-0-12-821815-0.00009-5]
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Khan MH-M, 2021, PLoS One, V16
   Kim HJ, 2022, J MED PHARM ALLIED S
   Loizidou K, 2020, IEEE ACCESS, V8, P52785, DOI 10.1109/ACCESS.2020.2980616
   Mahmood T, 2022, PLoS One, V17
   Manjón JV, 2010, J MAGN RESON IMAGING, V31, P192, DOI 10.1002/jmri.22003
   Sagayam KM, 2021, COGNITIVE PERCEPTION
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Silalahi A. R. J., 2021, IOP Conference Series: Materials Science and Engineering, V1115, DOI 10.1088/1757-899X/1115/1/012018
   society medical and editorial content team T.A.C, 2019, BREAST CANC
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan MX, 2020, Arxiv, DOI arXiv:1905.11946
   Tiryaki VM, 2023, BITLIS EREN U FEN BI
   Wang Y-P, 2023, MICROSCOPE IMAGE PRO, P55, DOI [10.1016/B978-0-12-821049-9.00006-X.https://www.sciencedirect.com/science/article/pii/, DOI 10.1016/B978-0-12-821049-9.00006-X.HTTPS://WWW.SCIENCEDIRECT.COM/SCIENCE/ARTICLE/PII]
   Zhou JY, 2020, SHOCK VIB, V2020, DOI 10.1155/2020/8863388
NR 33
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 14
PY 2023
DI 10.1007/s11042-023-16431-5
EA AUG 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2HF6
UT WOS:001048894900002
DA 2024-07-18
ER

PT J
AU Dubey, RK
   Choubey, DK
AF Dubey, Ratnesh Kumar
   Choubey, Dilip Kumar
TI An efficient adaptive feature selection with deep learning model-based
   paddy plant leaf disease classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Paddy leaf plant; Deep learning; Median filter; SV-RFE; ABi-LSTM; Rain
   optimization algorithm
ID NETWORK
AB Agriculture is the essential source of national income for some nations including India. Infections in crops/plants are serious causes of reduced quantity and quality of production, resulting in economic loss. Therefore, the detection of diseases in crops is very essential. Plant disease symptoms are evident in different parts of plants. However, plant leaves are commonly used to diagnose infection. Therefore, in this paper, we focus on automatic leaf disease detection using the deep learning model. The presentedmodel consists of four phases namely, pre-processing, feature extraction, feature selection, and classification. At first, the captured paddy leaf images are converted into an RGB color modelthe median filter is used to remove the noise present in the green band. Then, the texture and color features are extracted from the green band. After the feature extraction, important features are selected using a combination of machine learning and optimization algorithm. Here, initially, the features are selected using support vector machine-recursive feature elimination (SV-RFE) and an adaptive rain optimization algorithm (ARO). Then, the common features are selected. The selected features are given to the adaptive bi-long short-term memory (ABi-LSTM) classifier to classify an image as Blast disease, Bacterial Leaf Blight disease, Tungro, or normal image. The efficiency of the presented technique is estimatedbased on the accuracy, sensitivity, specificity, and performance compared with state-of-the-art works.
C1 [Dubey, Ratnesh Kumar; Choubey, Dilip Kumar] Indian Inst Informat Technol Bhagalpur, Dept Comp Sci & Engn, Bhagalpur, Bihar, India.
RP Dubey, RK (corresponding author), Indian Inst Informat Technol Bhagalpur, Dept Comp Sci & Engn, Bhagalpur, Bihar, India.
EM ratneshdub@gmail.com; dilipchoubey_1988@yahoo.in
RI Choubey, Dilip Kumar/D-2497-2018; dubey, ratnesh/IVH-1489-2023
OI Choubey, Dilip Kumar/0000-0002-1233-7159; dubey,
   ratnesh/0000-0002-2749-0949
CR Azim MA., 2021, Telecommun. Comput. Electronics Control TELKOMNIKA, V19, P463, DOI [10.12928/telkomnika.v19i2.16488, DOI 10.12928/TELKOMNIKA.V19I2.16488]
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Dewangan DK, 2023, MULTIMED TOOLS APPL, V82, P7293, DOI 10.1007/s11042-022-13425-7
   Dewangan DK, 2022, INT J PATTERN RECOGN, V36, DOI 10.1142/S0218001422520024
   Dewangan DK, 2023, EVOL INTELL, V16, P759, DOI 10.1007/s12065-022-00713-2
   Dubey RK, 2023, IETE J RES, DOI 10.1080/03772063.2023.2195842
   Dubey RK, 2023, MULTIMED TOOLS APPL, V82, P34147, DOI 10.1007/s11042-023-15107-4
   Elbasiouny H, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14020914
   Han HY, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18094978
   Islam MA, 2021, INT J ADV COMPUT SC, V12, P280
   Jain A, 2019, BIOENGINEERED, V10, P409, DOI 10.1080/21655979.2019.1649520
   Kalia A, 2020, J FUNGI, V6, DOI 10.3390/jof6040222
   Kumhar KC, 2022, J PLANT BIOINFORM BI, V2, P1
   Malhi GS, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13031318
   Oo Y.M., 2018, International Journal of Research and Engineering, V5, P516, DOI DOI 10.21276/IJRE.2018.5.9.4
   Patil Nilam Sachin, 2021, Turkish Journal of Computer and Mathematics Education, V12, P1672
   Petchiammal A, 2022, Arxiv, DOI arXiv:2205.11108
   Ramchandani Monica, 2023, 2022 OPJU International Technology Conference on Emerging Technologies for Sustainable Development (OTCON), P1, DOI 10.1109/OTCON56053.2023.10113992
   Ramesh S., 2020, Information Processing in Agriculture, V7, P249, DOI 10.1016/j.inpa.2019.09.002
   Rani PAS., 2022, INT J ADV SCI COMPUT, V4, P88, DOI [10.30630/ijasce.4.2.83, DOI 10.30630/IJASCE.4.2.83, 10.30630/ijasce.4.3.100, DOI 10.30630/IJASCE.4.3.100]
   Sakhamuri S, 2022, J THEOR APPL INF TEC, V100
   Senan N, 2020, INT J ADV COMPUT SC, V11, P116
   Sethy PK, 2020, PROCEDIA COMPUT SCI, V167, P516, DOI 10.1016/j.procs.2020.03.308
   Sultana S, 2022, INT J FOOD PROP, V25, P1063, DOI 10.1080/10942912.2022.2071295
   Vasavi P., 2022, INT J EL COMP ENG SY, V12, P2079, DOI [10.11591/ijece.v12i2.pp2079-2086, DOI 10.11591/IJECE.V12I2.PP2079-2086]
   Wanniarachchi S, 2022, HYDROLOGY-BASEL, V9, DOI 10.3390/hydrology9070123
   Yin HY, 2021, ADV MATER, V33, DOI 10.1002/adma.202007764
NR 28
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-16247-3
EA AUG 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O3TQ7
UT WOS:001043079400001
DA 2024-07-18
ER

PT J
AU Hao, SH
   Huang, CC
   Heidari, AA
   Shao, QK
   Chen, HL
AF Hao, Shuhui
   Huang, Changcheng
   Heidari, Ali Asghar
   Shao, Qike
   Chen, Huiling
TI Performance optimization of hunger games search for multi-threshold
   COVID-19 image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hunger games search; Meta-heuristic algorithms; Multi-threshold image
   segmentation; Global optimization; COVID-19
ID PARTICLE SWARM OPTIMIZATION; GLOBAL OPTIMIZATION; DIFFERENTIAL
   EVOLUTION; INSPIRED OPTIMIZER; ALGORITHM; ENTROPY; 2D; INTELLIGENCE;
   DIAGNOSIS; DESIGN
AB COVID-19 X-ray images are a vital approach for diagnosing whether a patient has an infection. By using multi-threshold image segmentation (MIS) technology to segment the target area of the COVID-19 X-ray image automatically, doctors can more efficiently determine whether the patient is infected with the virus and the current course of the disease. Nevertheless, as the threshold value rises, the computing cost of MIS approaches grows considerably, and for this reason, many researchers utilize meta-heuristic algorithms (MAs) as optimizers to select the optimal thresholds. Yet some issues cause slow convergence and local optimum solutions stalling. To revise the drawbacks, this paper proposes a strengthened version of the hunger games search (HGS), titled CDHGS. CDHGS introduces crisscross optimizer (CSO) and dimension learning-based hunting (DLH) mechanisms to HGS. First, CSO allows different individuals to exchange information, which speeds up convergence. Then, DLH mines more details on an individual's surrounding neighbors, thus alleviating the local optimum problem of the algorithm. A series of comparative experiments completed at CEC2014 showed that the proposed CDHGS has superior performance in respect of optimization than other advanced algorithms. Besides, a CDHGS-based MIS method is presented and employed to segment COVID-19 X-ray images. Specifically, we build a two-dimensional (2D) histogram utilizing non-local mean and grayscale images to illustrate the information of images, use Renyi's entropy as the objective function, and maximize Renyi's entropy to find the optimal thresholds. The COVID-19 X-ray image segmentation (IS) results of the evaluation display that the CDHGS-based MIS can obtain considerably exceptional segmentation results and stronger robustness than other segmentation methods. In all, CDHGS is a competitive approach in both global optimization (GO) and IS.
C1 [Hao, Shuhui; Huang, Changcheng; Shao, Qike; Chen, Huiling] Wenzhou Univ, Dept Comp Sci & Artificial Intelligence, Wenzhou 325035, Peoples R China.
   [Heidari, Ali Asghar] Univ Tehran, Coll Engn, Sch Surveying & Geospatial Engn, Tehran, Iran.
C3 Wenzhou University; University of Tehran
RP Huang, CC; Shao, QK; Chen, HL (corresponding author), Wenzhou Univ, Dept Comp Sci & Artificial Intelligence, Wenzhou 325035, Peoples R China.
EM haoshuhui2021@163.com; cchuang@126.com; as_heidari@ut.ac.ir;
   shaoqike@wzu.edu.cn; chenhuiling.jlu@gmail.com
RI Heidari, Ali Asghar/M-6255-2018; Chen, Huiling/N-8510-2019
OI Heidari, Ali Asghar/0000-0001-6938-9948; Chen,
   Huiling/0000-0002-7714-9693
FU Natural Science Foundation of Zhejiang Province [LZ22F020005]; National
   Natural Science Foundation of China [62076185]
FX AcknowledgmentsThe authors extend their appreciation to the journal
   editor and reviewers for their comments. This work was supported in part
   by the Natural Science Foundation of Zhejiang Province (LZ22F020005),
   National Natural Science Foundation of China (62076185).
CR Abd Elaziz M, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9192383
   Abdulkareem KH, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/5329014
   ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0
   Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   Ahilan A, 2019, IEEE ACCESS, V7, P89570, DOI 10.1109/ACCESS.2019.2891632
   Ahmadianfar I, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116516
   Ahmadianfar I, 2021, EXPERT SYST APPL, V181, DOI 10.1016/j.eswa.2021.115079
   Aja-Fernández S, 2006, 2006 28TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-15, P4053
   Allioui H, 2022, J PERS MED, V12, DOI 10.3390/jpm12020309
   Althubiti SA, 2022, CMC-COMPUT MATER CON, V73, P2423, DOI 10.32604/cmc.2022.028878
   Borjigin S, 2019, PATTERN RECOGN, V92, P107, DOI 10.1016/j.patcog.2019.03.011
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cai WW, 2021, DISPLAYS, V70, DOI 10.1016/j.displa.2021.102106
   Cai ZN, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.07.031
   Chen HL, 2020, EXPERT SYST APPL, V154, DOI 10.1016/j.eswa.2019.113018
   Chen P, 2020, CONCURR COMP-PRACT E, V34
   Chen X, 2017, SOFT COMPUT, V21, P7519, DOI 10.1007/s00500-016-2307-7
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Devi RM, 2022, COMPUT MAT CONTIN, V70
   Dong B, 2019, SIGNAL PROCESS-IMAGE, V78, P187, DOI 10.1016/j.image.2019.07.001
   Elsisi M, 2023, APPL INTELL, V53, P11997, DOI 10.1007/s10489-022-04059-1
   Fan Y, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106704
   Feng Q, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/7149631
   García S, 2010, INFORM SCIENCES, V180, P2044, DOI 10.1016/j.ins.2009.12.010
   García-Martínez C, 2008, EUR J OPER RES, V185, P1088, DOI 10.1016/j.ejor.2006.06.043
   Gupta S, 2020, APPL INTELL, V50, P993, DOI 10.1007/s10489-019-01570-w
   Hasoon JN, 2021, RESULTS PHYS, V31, DOI 10.1016/j.rinp.2021.105045
   Heidari AA, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105521
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Hemdan E. E. D., 2020, arXiv, DOI [DOI 10.48550/ARXIV.2003.11055, 10.48550/arXiv.2003.11055]
   Hu F, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.691746
   Hu J, 2022, INT J INTELL SYST, V37, P4864, DOI 10.1002/int.22744
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Ibrahim DA, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.13010
   Ismael AM, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114054
   Jin K, 2023, J CLIN MED, V12, DOI 10.3390/jcm12020400
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Karaboga D., 2006, P IEEE SWARM INT S
   Kaushal C, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/7935346
   Kumar M, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105641
   Li B, 2023, MULTIMED TOOLS APPL, V82, P21641, DOI 10.1007/s11042-023-14675-9
   Li CY, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2020.114529
   Li HW, 2019, J SYST ENG ELECTRON, V30, P1144, DOI 10.21629/JSEE.2019.06.10
   Li MJ, 2023, NEUROCOMPUTING, V518, P165, DOI 10.1016/j.neucom.2022.11.001
   Li QM, 2020, J AFFECT DISORDERS, V277, P153, DOI 10.1016/j.jad.2020.08.017
   Li S, 2020, 2020 INT C HIGH PERF
   Li SM, 2020, FUTURE GENER COMP SY, V111, P300, DOI 10.1016/j.future.2020.03.055
   Li YY, 2014, NAT COMPUT, V13, P39, DOI 10.1007/s11047-013-9399-0
   Liang J, 2013, CEC2014
   Liang R, 2022, J BUILD ENG, V59, DOI 10.1016/j.jobe.2022.105087
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Liu GM, 2020, IEEE ACCESS, V8, P46895, DOI 10.1109/ACCESS.2020.2978102
   Liu L, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104910
   Liu RJ, 2021, MOBILE NETW APPL, V26, P3, DOI 10.1007/s11036-020-01717-x
   Liu S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12062828
   Liu Y, 2020, ENERG CONVERS MANAGE, V223, DOI 10.1016/j.enconman.2020.113211
   Luo J, 2019, J ELECTRON INF TECHN, V41, P2017, DOI 10.11999/JEIT180949
   Ma BJ, 2022, KNOWL-BASED SYST, V248, DOI 10.1016/j.knosys.2022.108787
   Mafarja M, 2018, APPL SOFT COMPUT, V62, P441, DOI 10.1016/j.asoc.2017.11.006
   Maguolo G, 2020, ARXIV
   Mahmoudi R, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12104825
   Mansour RF, 2021, PATTERN RECOGN LETT, V151, P267, DOI 10.1016/j.patrec.2021.08.018
   Michetti J, 2015, DENTOMAXILLOFAC RAD, V44, DOI 10.1259/dmfr.20140413
   Mijwil MM, 2021, Iraqi J. Sci., P2099, DOI 10.24996/ijs.2021.62.6.35
   Mirjalili S., 2019, Nature-inspired optimizers: theories, literature reviews and applications
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mittal H, 2021, MULTIMED TOOLS APPL, V80, P7581, DOI 10.1007/s11042-020-09831-4
   Mohammed MA, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/1307944
   Mousavirad SJ, 2022, KNOWL-BASED SYST, V245, DOI 10.1016/j.knosys.2022.108610
   Mugemanyi S, 2020, IEEE ACCESS, V8, P65830, DOI 10.1109/ACCESS.2020.2982988
   Nadimi-Shahraki MH, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.113917
   Nagi AT, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136364
   Namburu A, 2019, IETE J RES, DOI 10.1080/03772063.2019.1604176
   Narappanawar N, 2011, COMPUT VIS IMAGE UND, V115, P1552, DOI 10.1016/j.cviu.2011.07.002
   Nenavath H, 2018, SWARM EVOL COMPUT, V43, P1, DOI 10.1016/j.swevo.2018.02.011
   Olorunda O, 2008, IEEE C EVOL COMPUTAT, P1128, DOI 10.1109/CEC.2008.4630938
   Onay FK, 2022, MATH COMPUT SIMULAT, V192, P514, DOI 10.1016/j.matcom.2021.09.014
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pare S, 2020, IJST-T ELECTR ENG, V44, P1, DOI 10.1007/s40998-019-00251-1
   Parikh BH, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30474-6
   Preeti, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-18001-5
   Qi AL, 2022, COMPUT BIOL MED, V148, DOI 10.1016/j.compbiomed.2022.105810
   Qu CW, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/4231647
   Reisenhofer R, 2018, SIGNAL PROCESS-IMAGE, V61, P33, DOI 10.1016/j.image.2017.11.001
   Renyi Alfred., 1960, 4th Berkeley Symposium on Mathematics, Statistics and Probability, V547, P547
   Shamim S, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/6566982
   Shirly S, 2019, CURR MED IMAGING REV, V15, P150, DOI 10.2174/1573405613666171123160609
   Singh RP, 2016, APPL SOFT COMPUT, V40, P161, DOI 10.1016/j.asoc.2015.11.027
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Su H, 2023, J COMPUT DES ENG, V10, P36, DOI 10.1093/jcde/qwac112
   Sun TY, 2011, IEEE T EVOLUT COMPUT, V15, P798, DOI 10.1109/TEVC.2010.2049361
   Tian J, 2023, COMPLEX INTELL SYST, V9, P3887, DOI 10.1007/s40747-022-00910-7
   Tsai CY, 2012, INT J ADV ROBOT SYST, V9, DOI 10.5772/52851
   Upadhyay P, 2021, J AMB INTEL HUM COMP, V12, P1081, DOI 10.1007/s12652-020-02143-3
   Venter G, 2003, AIAA J, V41, P1583, DOI 10.2514/2.2111
   Vijh S, 2023, MULTIMED TOOLS APPL, V82, P4979, DOI 10.1007/s11042-022-12168-9
   Wang WC, 2022, SIGNAL PROCESS-IMAGE, V106, DOI 10.1016/j.image.2022.116742
   Wang X, 2022, OXID MED CELL LONG, V2022
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Xia JF, 2022, J BIONIC ENG, V19, P240, DOI 10.1007/s42235-021-00114-8
   Xu BY, 2022, INT J ENERG RES, V46, P12417, DOI 10.1002/er.8011
   Xu YT, 2019, EXPERT SYST APPL, V129, P135, DOI 10.1016/j.eswa.2019.03.043
   Xu YT, 2019, INFORM SCIENCES, V492, P181, DOI 10.1016/j.ins.2019.04.022
   Xu ZY, 2020, OPEN MED-WARSAW, V15, P860, DOI 10.1515/med-2020-0131
   Yang D, 2022, FRONT ENV SCI-SWITZ, V10, DOI 10.3389/fenvs.2022.996513
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yang YB, 2000, PATTERN RECOGN, V33, P787, DOI 10.1016/S0031-3203(99)00094-1
   Yang YT, 2021, EXPERT SYST APPL, V177, DOI 10.1016/j.eswa.2021.114864
   Yin PY, 2007, APPL MATH COMPUT, V184, P503, DOI 10.1016/j.amc.2006.06.057
   Zhang CJ, 2023, IEEE ACCESS, V11, P13738, DOI 10.1109/ACCESS.2023.3240576
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Q, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104941
   Zhang Q, 2019, IEEE ACCESS, V7, P31243, DOI 10.1109/ACCESS.2019.2902306
   Zhao D, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114122
   Zhao SW, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.105015
   Zhao SW, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104427
   Zhu BZ, 2018, COMPUT ECON, V52, P105, DOI 10.1007/s10614-017-9664-x
NR 124
TC 2
Z9 2
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-16116-z
EA AUG 2023
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4RY6
UT WOS:001043714700014
DA 2024-07-18
ER

PT J
AU Pavithra, P
   Aishwarya, P
AF Pavithra, P.
   Aishwarya, P.
TI Plant leaf disease detection using hybrid grasshopper optimization with
   modified artificial bee colony algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Plant diseases; Crop farming; Classification; Optimization techniques;
   Noise signal; Feature extraction
AB The importance of plants is acknowledged because they provide the majority of human energy. due to their medicinal, nutritional, & other benefits. Any time during growing crops, plant diseases can affect the leaf, which can cause significant crop production losses and market value reduction. In this paper, three optimization techniques are utilized to detect plant leaf disease. The input image has some noise signal which is removed by using the Modified Wiener Filter (MWF), this is the pre-processing stage of the proposed methodology. Feature Extraction is performed using Improved Ant Colony Optimization (IACO), this will extract the important features. The proposed model is described as Hybrid Grasshopper Optimization with a modified Artificial Bee Colony Algorithm (HyGmABC), which is used for classification. This will check whether the disease is present in the leaf region or not. The performance of the proposed methodology is evaluated using the performance metrics like accuracy, precision, recall, False Negative Ratio (FNR), Negative Prediction Value (NPV), and Matthews correlation coefficient (MCC). The plant village dataset is chosen for implementation. The proposed methodology produces high accuracy of 98.53% which is higher than the existing techniques.
C1 [Pavithra, P.] VTU, Belagavi 590018, Karnataka, India.
   [Aishwarya, P.] Atria IT, Dept CSE, Bangalore, India.
C3 Visvesvaraya Technological University
RP Pavithra, P (corresponding author), VTU, Belagavi 590018, Karnataka, India.
EM pavithrap8765@gmail.com
CR Abbas A, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106279
   Andrushia AD, 2020, EVOL SYST-GER, V11, P105, DOI 10.1007/s12530-019-09289-2
   Ashwini C, 2022, CORN DIS DETECTION B
   Brahimi M, 2019, SIG P ALGO ARCH ARR, P111, DOI [10.23919/SPA.2019.8936759, 10.23919/spa.2019.8936759]
   Brahimi M, 2018, HUM-COMPUT INT-SPRIN, P93, DOI 10.1007/978-3-319-90403-0_6
   Chowdhury MEH, 2021, AGRIENGINEERING, V3, P294, DOI 10.3390/agriengineering3020020
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Hassan SM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121388
   Kamal KC, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104948
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Kumar S, 2020, SUSTAIN COMPUT-INFOR, V28
   Mahmoud MAB, 2020, MULTIMED TOOLS APPL, V79, P26245, DOI 10.1007/s11042-020-09239-0
   Nandhini S., 2022, Appl. Math. Inf. Sci., V16, P149, DOI [10.18576/amis/160202, DOI 10.18576/AMIS/160202]
   Nandhini SA, 2018, WIRELESS PERS COMMUN, V102, P725, DOI 10.1007/s11277-017-5092-4
   Nanehkaran YA, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02505-x
   Ozguven MM, 2019, PHYSICA A, V535, DOI 10.1016/j.physa.2019.122537
   Pantazi XE, 2019, COMPUT ELECTRON AGR, V156, P96, DOI 10.1016/j.compag.2018.11.005
   Rauf HT, 2019, DATA BRIEF, V26, DOI 10.1016/j.dib.2019.104340
   Sharma Parul, 2020, Information Processing in Agriculture, V7, P566, DOI 10.1016/j.inpa.2019.11.001
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Singh V, 2019, ARTIF INTELL AGR, V3, P62, DOI 10.1016/j.aiia.2019.09.002
   Sowmyalakshmi R, 2021, CMC-COMPUT MATER CON, V68, P1751, DOI 10.32604/cmc.2021.016825
   Sujatha R, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103615
   Vallabhajosyula S, 2022, J PLANT DIS PROTECT, V129, P545, DOI 10.1007/s41348-021-00465-8
   Warke PS, 2020, INT RES J ENG TECHNO
NR 26
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-16148-5
EA AUG 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4RY6
UT WOS:001043714700013
DA 2024-07-18
ER

PT J
AU Biswas, S
   Kruijff, E
   Veas, E
AF Biswas, Saugata
   Kruijff, Ernst
   Veas, Eduardo
TI View recommendation for multi-camera demonstration-based training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-camera; Camera view analysis; View selection; Camera selection;
   Demonstration-based training; Instruction design; Entropy; Recommender
   systems
ID VIDEO MODELING EXAMPLES; VIEWPOINT SELECTION; ATTENTION; GESTURE; SYSTEM
AB While humans can effortlessly pick a view from multiple streams, automatically choosing the best view is a challenge. Choosing the best view from multi-camera streams poses a problem regarding which objective metrics should be considered. Existing works on view selection lack consensus about which metrics should be considered to select the best view. The literature on view selection describes diverse possible metrics. And strategies such as information-theoretic, instructional design, or aesthetics-motivated fail to incorporate all approaches. In this work, we postulate a strategy incorporating information-theoretic and instructional design-based objective metrics to select the best view from a set of views. Traditionally, information-theoretic measures have been used to find the goodness of a view, such as in 3D rendering. We adapted a similar measure known as the viewpoint entropy for real-world 2D images. Additionally, we incorporated similarity penalization to get a more accurate measure of the entropy of a view, which is one of the metrics for the best view selection. Since the choice of the best view is domain-dependent, we chose demonstration-based training scenarios as our use case. The limitation of our chosen scenarios is that they do not include collaborative training and solely feature a single trainer. To incorporate instructional design considerations, we included the trainer's body pose, face, face when instructing, and hands visibility as metrics. To incorporate domain knowledge we included predetermined regions' visibility as another metric. All of those metrics are taken into account to produce a parameterized view recommendation approach for demonstration-based training. An online study using recorded multi-camera video streams from a simulation environment was used to validate those metrics. Furthermore, the responses from the online study were used to optimize the view recommendation performance with a normalized discounted cumulative gain (NDCG) value of 0.912, which shows good performance with respect to matching user choices.
C1 [Biswas, Saugata; Kruijff, Ernst] Bonn Rhein Sieg Univ Appl Sci, Dept Comp Sci, Grantham Allee 20, D-53757 St Augustin, Germany.
   [Veas, Eduardo] Graz Univ Technol, Inst Interact Syst & Data Sci, Sandgasse 36-3, A-8010 Graz, Austria.
C3 Hochschule Bonn Rhein Sieg; Graz University of Technology
RP Biswas, S (corresponding author), Bonn Rhein Sieg Univ Appl Sci, Dept Comp Sci, Grantham Allee 20, D-53757 St Augustin, Germany.
EM saugata.biswas@h-brs.de; ernst.kruijff@h-brs.de; eveas@tugraz.at
OI Veas, Eduardo/0000-0002-0356-4034; Biswas, Saugata/0000-0002-2678-0928;
   Kruijff, Ernst/0000-0003-1625-0955
FU Campus to World project (Innovative Hochschule, BMBF, FKZ) [03IHS092A]
FX This work was partly funded through the Campus to World project
   (Innovative Hochschule, BMBF, FKZ: 03IHS092A). We would like to thank
   all participants who took part in the user study.
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Aggarwal S, 2020, LECT NOTE DATA ENG, V32, P23, DOI 10.1007/978-3-030-25797-2_2
   Alamdari PM, 2020, IEEE ACCESS, V8, P115694, DOI 10.1109/ACCESS.2020.3002803
   Alem L., 2011, ADV HUM-COMPUT INTER, V2011
   Alibali MW, 2014, COGNITION INSTRUCT, V32, P65, DOI 10.1080/07370008.2013.858161
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Bandura A., 1986, Social foundations of thought and action: A social cognitive theory, V1986, P23
   Bandura A., 2008, The international encyclopedia of communication, V10, P4654
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   Bétrancourt M, 2018, COMPUT HUM BEHAV, V89, P471, DOI 10.1016/j.chb.2018.08.035
   Bonaventura X, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20050370
   Boucheix JM, 2018, COMPUT HUM BEHAV, V89, P418, DOI 10.1016/j.chb.2018.01.017
   Buckingham G, 2014, CORTEX, V50, P115, DOI 10.1016/j.cortex.2013.07.004
   Burris A, 2017, VISIT STUD, V20, P218, DOI 10.1080/10645578.2017.1404352
   Cerneková Z, 2006, IEEE T CIRC SYST VID, V16, P82, DOI 10.1109/TCSVT.2005.856896
   CLARK HH, 1991, PERSPECTIVES ON SOCIALLY SHARED COGNITION, P127, DOI 10.1037/10096-006
   Da'u A, 2020, ARTIF INTELL REV, V53, P2709, DOI 10.1007/s10462-019-09744-1
   de Koning B.B., 2018, COMPUT HUM BEHAV
   de Koning BB, 2019, COMPUT EDUC, V141, DOI 10.1016/j.compedu.2019.103636
   Deinzer F, 2003, LECT NOTES COMPUT SC, V2756, P65
   ENDSLEY MR, 1995, HUM FACTORS, V37, P32, DOI 10.1518/001872095779049543
   Feixas M, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1462055.1462056
   Fiorella L., 2018, WHAT WORKS DOESNT W, DOI [10.1016/j.chb.2018.07.015, DOI 10.1016/J.CHB.2018.07.015]
   Fiorella L., 2018, WHAT WORKS DOESNT WO
   Fiorella L, 2017, J EDUC PSYCHOL, V109, P653, DOI 10.1037/edu0000161
   Freitag S., 2015, INT C ART REAL TEL E, P53, DOI DOI 10.2312/EGVE.20151310
   Fussell SR, 2004, HUM-COMPUT INTERACT, V19, P273, DOI 10.1207/s15327051hci1903_3
   Graf S, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0277-z
   Guo P. J., 2014, P 1 ACM C LEARN SCAL, P41, DOI DOI 10.1145/2556325.2566239
   Harris DJ, 2018, BRIT J SURG, V105, P1713, DOI 10.1002/bjs.10991
   HART S G, 1988, P139
   Henderson ML, 2021, COMPUT EDUC OPEN, V2, DOI 10.1016/j.caeo.2021.100059
   Heyes CM, 2002, Q J EXP PSYCHOL-A, V55, P593, DOI 10.1080/02724980143000389
   Hodges NJ, 2007, J SPORT SCI, V25, P531, DOI 10.1080/02640410600946860
   Huang C, 2018, IEEE INT CONF ROBOT, P7039, DOI 10.1109/ICRA.2018.8460703
   Huang K, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517468
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Jiang HD, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392427
   Joo H, 2019, IEEE T PATTERN ANAL, V41, P190, DOI 10.1109/TPAMI.2017.2782743
   KAMADA T, 1988, COMPUT VISION GRAPH, V41, P43, DOI 10.1016/0734-189X(88)90116-8
   Key M.R., 2011, RELATIONSHIP VERBAL, DOI DOI 10.1515/9783110813098
   KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644
   Kumar Pushpendra, 2018, International Journal of Information Technology, V10, P495, DOI 10.1007/s41870-018-0138-8
   Laporte C, 2006, INT J COMPUT VISION, V68, P267, DOI 10.1007/s11263-005-4436-9
   Larkin K.G., 2016, ARXIV
   Leu MC, 2013, CIRP ANN-MANUF TECHN, V62, P799, DOI 10.1016/j.cirp.2013.05.005
   LINO C, 2011, P 19 ACM INT C MULT, P323, DOI DOI 10.1145/2072298.2072341
   LIPOWSKI ZJ, 1975, COMPR PSYCHIAT, V16, P199, DOI 10.1016/0010-440X(75)90047-4
   Mason S, 1997, PHOTOGRAMM ENG REM S, V63, P1093
   Mavlankar A., 2010, 2010 18th International Packet Video Workshop (PV 2010), P64, DOI 10.1109/PV.2010.5706821
   Mayer R.E., 2021, J APPL RES MEM COGN
   Mayer R. E., 2014, The Cambridge handbook of multimedia learning, P43, DOI [10.1017/CBO9781139547369.017, DOI 10.1017/CBO9781139547369.017]
   Mayer R.E., 2014, Introduction to multimedia learning
   Mayer RE, 2020, ETR&D-EDUC TECH RES, V68, P837, DOI 10.1007/s11423-020-09749-6
   McNeill David, 2011, HAND MIND
   Mittelberg I., 2014, Body - Language - communication: An international handbook on multimodality in human interaction, Volume 2, V2, P1732
   Monteiro J., 2019, 2019 IEEE 29th International Workshop on Machine Learning for Signal Processing (MLSP), P1
   Munea TL, 2020, IEEE ACCESS, V8, P133330, DOI 10.1109/ACCESS.2020.3010248
   Nocedal J, 2006, SPRINGER SER OPER RE, P135
   Novack MA, 2017, PSYCHON B REV, V24, P652, DOI 10.3758/s13423-016-1145-z
   Olagoke AS, 2020, IEEE ACCESS, V8, P172892, DOI 10.1109/ACCESS.2020.3024568
   Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009
   Ou C, 2019, ONLINE LEARN, V23, P82, DOI 10.24059/olj.v23i2.1449
   Pareek P, 2021, ARTIF INTELL REV, V54, P2259, DOI 10.1007/s10462-020-09904-8
   Pi Z, 2017, J COMPUT ASSIST LEAR, V33, P347, DOI 10.1111/jcal.12183
   Pi ZL, 2020, COMPUT EDUC, V144, DOI 10.1016/j.compedu.2019.103713
   Rahimian P, 2017, IEEE T VIS COMPUT GR, V23, P1209, DOI 10.1109/TVCG.2016.2637334
   Rahnert K, 2022, ACCOUNT EDUC, V31, P482, DOI 10.1080/09639284.2021.2015409
   Razlighi Q., 2009, VISUAL COMMUN-US, V7257, P72571
   Rehatschek H., 2018, INT C INT COLL LEARN, P151, DOI DOI 10.1007/978-3-030-11935
   Ristad ES, 1998, IEEE T PATTERN ANAL, V20, P522, DOI 10.1109/34.682181
   Rosen MA, 2010, HUM FACTORS, V52, P596, DOI 10.1177/0018720810381071
   Rust NC, 2010, CURR OPIN NEUROBIOL, V20, P382, DOI 10.1016/j.conb.2010.04.013
   Sablic M, 2021, TECHNOL KNOWL LEARN, V26, P1061, DOI 10.1007/s10758-020-09455-5
   Sakane S., 1992, Advanced Robotics, V6, P461, DOI 10.1163/156855392X00295
   Sakane S., 1987, Advanced Robotics, V2, P149, DOI 10.1163/156855387X00138
   Sasikumar P, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.698523
   Schurgin MW, 2017, J EXP PSYCHOL GEN, V146, P362, DOI 10.1037/xge0000270
   Secord A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019628
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Takeuchi Y., 1998, Systems and Computers in Japan, V29, P31, DOI 10.1002/(SICI)1520-684X(199810)29:11<31::AID-SCJ4>3.0.CO;2-T
   Tang R, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P4123, DOI 10.1145/2702123.2702401
   TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P86, DOI 10.1109/70.345940
   TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P72, DOI 10.1109/70.345939
   van der Meij H, 2017, COMPUT EDUC, V114, P164, DOI 10.1016/j.compedu.2017.07.002
   van Wermeskerken M, 2018, COMPUT HUM BEHAV, V89, P430, DOI 10.1016/j.chb.2017.11.038
   van Wermeskerken M, 2017, COMPUT EDUC, V113, P98, DOI 10.1016/j.compedu.2017.05.013
   Vazquez P.-P., 2001, Vision, Modeling, and Visualization 2001. Proceedings, P273
   Vazquez P.-P., 2002, P VISSYM, V22, P183, DOI DOI 10.2312/VISSYM/VISSYM02/183-188
   Vazquez P.-P., 2003, P 6 INT C COMP GRAPH, P13
   Vázquez PP, 2006, COMPUT GRAPH-UK, V30, P98, DOI 10.1016/j.cag.2005.10.022
   Vázquez PP, 2002, ADVANCES IN MODELLING, ANIMATION AND RENDERING, P267
   Wang Yining, 2013, P 26 ANN C LEARN THE, DOI [DOI 10.1371/JOURNAL.PONE.0067335, DOI 10.16619/J.CNKI.RMLT.2013.23.018]
   Wang Z, 2022, ROBOT CIM-INT MANUF, V78, DOI 10.1016/j.rcim.2022.102407
   Yang XW, 2014, COMPUT COMMUN, V41, P1, DOI 10.1016/j.comcom.2013.06.009
   Yoo J.E., 2021, P 2021 CHI C HUMAN F, P1
   Zhang C, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1324287.1324293
   Zhang XL, 2013, IEEE T AUDIO SPEECH, V21, P697, DOI 10.1109/TASL.2012.2229986
NR 98
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21765
EP 21800
DI 10.1007/s11042-023-16169-0
EA AUG 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042601200012
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Dehghani, R
   Kheiri, H
AF Dehghani, Roghayeh
   Kheiri, Hossein
TI Chaotic-based color image encryption using a hybrid method of reversible
   cellular automata and DNA sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Hyper-chaotic system; DNA sequences; Recursive
   cellular automata
ID MAP; COMPRESSION; GENERATOR; SYSTEM
AB In this manuscript, a new image cryptography algorithm based on new second-order recursive cellular automata (RCA), DNA sequences, and hyper-chaotic system is suggested. Different from the customary permutation-diffusion structure, this manuscript uses a newly three-layer structure, that is, diffusion-permutation-diffusion. Due to the characteristics of high correlation among image pixels that lead to statistical attacks, the aim of this initial diffusion that based on new recursive cellular automata is random redistribution of pixels through assigning a value new for each pixel. The next stage is to perform permutation based on Arnold cat's map, which aims to remove the high correlation among adjacent pixels in the image. The final step, which is based on DNA sequences and key stream, is to increase the complexity and security of the proposed algorithm. In addition, the initial values of the Chen hyper-chaotic system depend on the secret keys and pixels of the original image, which causes completely different chaotic sequences to be created when we encrypt different images. The simulation and empirical results show that the given algorithm has a proper key space and is resistant to various attacks that we test.
C1 [Dehghani, Roghayeh; Kheiri, Hossein] Univ Tabriz, Fac Math Sci, Tabriz, Iran.
C3 University of Tabriz
RP Kheiri, H (corresponding author), Univ Tabriz, Fac Math Sci, Tabriz, Iran.
EM k1rd9607@gmail.com; h-kheiri@tabrizu.ac.ir
RI Kheiri, Hossein/D-5407-2017
OI Kheiri, Hossein/0000-0002-2598-7820
CR Abbassi Nessrine, 2022, Integration, The VLSI Journal, P49, DOI 10.1016/j.vlsi.2022.06.007
   Babaei A, 2020, OPTIK, V203, DOI 10.1016/j.ijleo.2019.164000
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   GAO H, 2022, IEEE T NEURAL NETW L, P1
   García-Guerrero EE, 2020, CHAOS SOLITON FRACT, V133, DOI 10.1016/j.chaos.2020.109646
   Ghanbari H, 2022, MULTIMED TOOLS APPL, V81, P31815, DOI 10.1007/s11042-022-12188-5
   Guesmi R, 2021, MULTIMED TOOLS APPL, V80, P1925, DOI 10.1007/s11042-020-09672-1
   Gupta MD, 2021, INTEGRATION, V81, P137, DOI 10.1016/j.vlsi.2021.07.002
   Hajjaji MA, 2019, MULTIMED TOOLS APPL, V78, P14379, DOI 10.1007/s11042-018-6795-6
   Hanis S, 2018, MULTIMED TOOLS APPL, V77, P6897, DOI 10.1007/s11042-017-4606-0
   Kang YL, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12091393
   Kari J, 2018, NEW GENERAT COMPUT, V36, P145, DOI 10.1007/s00354-018-0034-6
   Kumar V, 2021, MULTIMED TOOLS APPL, V80, P3749, DOI 10.1007/s11042-020-09854-x
   Li T, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.5902
   Luo YL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105836
   Maazouz M, 2022, J KING SAUD UNIV-COM, V34, P9926, DOI 10.1016/j.jksuci.2021.12.022
   Masood F, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030274
   Mondal B, 2019, J INF SECUR APPL, V45, P117, DOI 10.1016/j.jisa.2019.01.010
   Morita K., 2017, THEORY REVERSIBLE CO, P261, DOI [10.1007/978-4-431-56606-9, DOI 10.1007/978-4-431-56606-9]
   Naskar PK, 2020, NONLINEAR DYNAM, V100, P2877, DOI 10.1007/s11071-020-05625-3
   Nazari M, 2021, MULTIMED TOOLS APPL, V80, P10615, DOI 10.1007/s11042-020-10032-2
   Nematzadeh H, 2020, OPTIK, V202, DOI 10.1016/j.ijleo.2019.163505
   Niyat AY, 2020, MULTIMED TOOLS APPL, V79, P1497, DOI 10.1007/s11042-019-08247-z
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Peng XN, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110044
   Peterson G, 1997, ARNOLD CATS MAP
   Kari AP, 2021, MULTIMED TOOLS APPL, V80, P2753, DOI 10.1007/s11042-020-09648-1
   Rajagopalan S, 2018, MICROPROCESS MICROSY, V61, P257, DOI 10.1016/j.micpro.2018.06.011
   Roy S, 2020, J AMB INTEL HUM COMP, V11, P5083, DOI 10.1007/s12652-020-01813-6
   Sahari ML, 2018, NONLINEAR DYNAM, V94, P723, DOI 10.1007/s11071-018-4390-z
   Sarosh P, 2022, MULTIMED TOOLS APPL, V81, P7253, DOI 10.1007/s11042-021-11812-0
   Trujillo-Toledo DA, 2021, CHAOS SOLITON FRACT, V153, DOI 10.1016/j.chaos.2021.111506
   Wang LY, 2016, OPT LASER ENG, V77, P118, DOI 10.1016/j.optlaseng.2015.07.015
   Wang XY, 2021, CHAOS SOLITON FRACT, V147, DOI 10.1016/j.chaos.2021.110962
   Wang XY, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106501
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2016, OPT LASER ENG, V82, P79, DOI 10.1016/j.optlaseng.2015.12.006
   Wang Y, 2018, NEUROCOMPUTING, V275, P1318, DOI 10.1016/j.neucom.2017.09.068
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   WOLFRAM S, 1984, NATURE, V311, P419, DOI 10.1038/311419a0
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013021
   Zhou S, 2020, CHAOS SOLITON FRACT, V141, DOI 10.1016/j.chaos.2020.110225
NR 48
TC 4
Z9 4
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17429
EP 17450
DI 10.1007/s11042-023-16118-x
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035725700016
DA 2024-07-18
ER

PT J
AU Devulapalli, PK
   Kumar, GAES
   Maganti, SB
   Rachapogula, S
AF Devulapalli, Praveen Kumar
   Kumar, G. A. E. Satish
   Maganti, Sushanth Babu
   Rachapogula, Sumalatha
TI Image transmission in mobile wireless multimedia sensor networks using
   cat swarm optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile Multimedia sensor network; Cooperative image transmission;
   Dimension-based Cat Swarm Optimization; Multi-Radio Multi-Hop
ID PHYSICAL LAYER SECURITY; OPTIMAL TASK ALLOCATION; RELAY-SELECTION;
   COOPERATIVE NETWORKS; EFFICIENT; DECODE
AB High-quality picture transmission over intelligent devices in Mobile Multimedia Sensor Networks (MWMSN) requires fast transmission rates, throughput, and a low Bit Error Rate (BER). Energy efficiency is always a top priority for battery-powered intelligent devices like smartphones and tablets. The Multiple Input and Multiple Output (MIMO) technology is extensively used in MWMSN with cooperative communication (CC). In order to increase the effectiveness of multimedia sensor networks, diverse network techniques are driven by cooperative communications because these systems are more likely to be built with traditional limited resources and scattered hardware. Since each node in the network is mobile, energy consumption and routing pose significant problems for cooperative mobile multimedia sensor networks. An optimisation model is developed to select the minimum number of multi-hops between the source and destination for the cooperative MWMSN network to address these challenges. This paper adopts a new Modified Cat Swarm Optimisation (MCSO) to solve a multi-objective function involving target throughput, mobility, energy consumption and outage probability. The simulation shows that the proposed approach has achieved better performance against state-of-art approaches regarding aggregate throughput, peak signal-to-noise ratio and structural similarity index.
C1 [Devulapalli, Praveen Kumar; Kumar, G. A. E. Satish; Rachapogula, Sumalatha] Vardhaman Coll Engn, Dept Elect & Commun Engn, Hyderabad, Telangana, India.
   [Maganti, Sushanth Babu] Matrusri Engn Coll, Dept Elect & Commun Engn, Hyderabad, Telangana, India.
C3 Vardhaman College of Engineering
RP Devulapalli, PK; Kumar, GAES (corresponding author), Vardhaman Coll Engn, Dept Elect & Commun Engn, Hyderabad, Telangana, India.
EM praveenkumarpd192538@gmail.com; gaesathish.vardhaman@gmail.com
RI Devulapalli, Dr. Praveen Kumar/AAX-1975-2021; Kumar, G A E
   Satish/AAY-6068-2021
OI Devulapalli, Dr. Praveen Kumar/0000-0002-3003-2420; Kumar, G A E
   Satish/0000-0002-0263-2402; maganti, Sushanth babu/0000-0003-0568-1637
CR Abazeed M, 2019, WIREL NETW, V25, P4887, DOI 10.1007/s11276-018-1829-6
   Abbas ST, 2021, APPL NANOSCI, DOI 10.1007/s13204-021-02100-2
   Abdulhadi S, 2012, WIRELESS PERS COMMUN, V63, P917, DOI 10.1007/s11277-010-0174-6
   Achour I, 2021, WIREL NETW, V27, P4497, DOI 10.1007/s11276-021-02726-8
   Adam H, 2014, IEEE T MOBILE COMPUT, V13, P2042, DOI 10.1109/TMC.2013.97
   Akin AI, 2015, EURASIP J WIREL COMM, DOI 10.1186/s13638-015-0251-3
   Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Al Hayani B, 2020, J MED IMAG HEALTH IN, V10, P160, DOI 10.1166/jmihi.2020.2691
   Al-Hayani B, 2020, INT J ELEC ENG EDUC, V57, P321, DOI 10.1177/0020720918816009
   Borawake-Satao R, 2019, MULTIMED TOOLS APPL, V78, P32659, DOI 10.1007/s11042-019-7619-z
   Bouchemel A, 2018, IEEE COMMUN LETT, V22, P934, DOI 10.1109/LCOMM.2018.2812821
   Bouzidi Abdelhamid, 2019, Journal of Industrial Engineering International, V15, P367, DOI 10.1007/s40092-018-0297-z
   Cui ZY, 2019, IEEE ACCESS, V7, P42255, DOI 10.1109/ACCESS.2019.2907728
   Devulapalli PK, 2022, CYBERNET SYST, DOI 10.1080/01969722.2022.2157602
   Dong L, 2010, IEEE T SIGNAL PROCES, V58, P1875, DOI 10.1109/TSP.2009.2038412
   El Alami H, 2019, IEEE ACCESS, V7, P107142, DOI 10.1109/ACCESS.2019.2933052
   Feng H, 2014, IEEE WIREL COMMUN LE, V3, P477, DOI 10.1109/LWC.2014.2331071
   Guo WZ, 2015, SECUR COMMUN NETW, V8, P1865, DOI 10.1002/sec.1026
   Guo WZ, 2015, IEEE T PARALL DISTR, V26, P3236, DOI 10.1109/TPDS.2014.2386343
   Guo Y, 2019, AD HOC NETW, V89, P107, DOI 10.1016/j.adhoc.2019.03.006
   Heiniger R. W., 2000, Proceedings of the 5th International Conference on Precision Agriculture, Bloomington, Minnesota, USA, 16-19 July, 2000, P1
   Huang WD, 2018, J MULTIMODAL USER IN, V12, P77, DOI 10.1007/s12193-017-0250-2
   Indumathi K, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P1607, DOI 10.1109/WiSPNET.2017.8300032
   Jin Y, 2015, EURASIP J WIREL COMM, DOI 10.1186/s13638-015-0407-1
   Kandris D, 2011, AD HOC NETW, V9, P591, DOI 10.1016/j.adhoc.2010.09.001
   Kim S, 2018, COMPUT SUPP COOP W J, V27, P569, DOI 10.1007/s10606-018-9324-2
   Kong F., 2019, MULTIMED TOOLS APPL, V4, P1, DOI DOI 10.1007/S11042-019-7614-4
   Krikidis I, 2009, IEEE T WIREL COMMUN, V8, P5003, DOI 10.1109/TWC.2009.090323
   Kumar Devulapalli P, 2022, INT J INTELL ENG SYS, V15
   Lee JS, 2017, IEEE INTERNET THINGS, V4, P1095, DOI 10.1109/JIOT.2017.2711248
   Li JY, 2011, IEEE T SIGNAL PROCES, V59, P4985, DOI 10.1109/TSP.2011.2159598
   Li S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010199
   Liu TT, 2019, IEEE ACCESS, V7, P122354, DOI 10.1109/ACCESS.2019.2914942
   Ma BJ, 2016, IEEE T WIREL COMMUN, V15, P4826, DOI 10.1109/TWC.2016.2547378
   Ma N, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1571-5
   Margi CB, 2006, P IEEE CREAT NET INT
   Nam E, 2015, IEEE COMMUN LETT, V19, P1378, DOI 10.1109/LCOMM.2015.2441056
   Nandhini SA, 2017, COMPUT ELECTR ENG, V60, P175, DOI 10.1016/j.compeleceng.2017.01.027
   Nguyen BV, 2013, IEEE COMMUN LETT, V17, P2060, DOI 10.1109/LCOMM.2013.090313.131263
   Okeke GO, 2015, IEEE WIREL COMMUN LE, V4, P309, DOI 10.1109/LWC.2015.2411657
   Redondi A, 2015, AD HOC NETW, V28, P38, DOI 10.1016/j.adhoc.2015.01.008
   Sheng ZG, 2018, IEEE T CLOUD COMPUT, V6, P114, DOI 10.1109/TCC.2015.2458272
   Sheu TL, 2014, WIREL COMMUN MOB COM, V14, P1720, DOI 10.1002/wcm.2312
   Song Y, 2019, IEEE SYST J, V13, P1386, DOI 10.1109/JSYST.2018.2826004
   Su YH, 2019, IEEE SENS J, V19, P9561, DOI 10.1109/JSEN.2019.2925719
   Sun F, 2018, IEEE T VEH TECHNOL, V67, P11049, DOI 10.1109/TVT.2018.2868013
   Tang LJ, 2018, MULTIMED TOOLS APPL, V77, P5637, DOI 10.1007/s11042-017-4477-4
   Tian Y., 2005, IEEE International Conference on Mobile Adhoc and Sensor Systems Conference, P211
   Wang F, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/286589
   Wang W, 2016, IEEE WIREL COMMUN LE, V5, P28, DOI 10.1109/LWC.2015.2488660
   Wu Chun-ming, 2018, Transactions of Beijing Institute of Technology, V38, P545, DOI 10.15918/j.tbit1001-0645.2018.05.017
   Xia MH, 2015, IEEE COMMUN LETT, V19, P1249, DOI 10.1109/LCOMM.2015.2418780
   Xu HL, 2012, IEEE T WIREL COMMUN, V11, P1532, DOI 10.1109/TWC.2012.020812.111265
   Yang H, 2018, MULTIMED TOOLS APPL, V77, P4453, DOI 10.1007/s11042-016-4245-x
   Yang MQ, 2016, IEEE T COMMUN, V64, P5189, DOI 10.1109/TCOMM.2016.2606396
   Yang X, 2018, ELECTRON LETT, V54, P323, DOI 10.1049/el.2017.2515
   Yu WL, 2019, IEEE SENS J, V19, P7744, DOI 10.1109/JSEN.2019.2916591
   Yu ZJ, 2019, PEER PEER NETW APPL, V12, P1585, DOI 10.1007/s12083-019-00802-7
   Zhang L., 2007, EURASIP J ADV SIG PR, V2008, P362809
   Zhao DW, 2014, IEEE COMMUN LETT, V18, P74, DOI 10.1109/LCOMM.2013.112513.132216
   Zheng ZY, 2012, WIREL NETW, V18, P653, DOI 10.1007/s11276-012-0425-4
   Zhou L, 2019, EVID-BASED COMPL ALT, VNetw2019, P1
   Zhu C, 2019, IEEE INTERNET THINGS, V6, P4150, DOI 10.1109/JIOT.2018.2875520
   Zhu XM, 2018, IEEE J SEL AREA COMM, V36, P981, DOI 10.1109/JSAC.2018.2832780
NR 64
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17557
EP 17578
DI 10.1007/s11042-023-16302-z
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001033666900001
DA 2024-07-18
ER

PT J
AU Nezhad, SA
   Khatibi, T
   Sohrabi, M
AF Nezhad, Shima Ayyoubi
   Khatibi, Toktam
   Sohrabi, Masoudreza
TI Combining CNNs and 2-D visualization method for GI tract lesions
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image analysis; Endoscopy; Deep neural networks; Auto-encoders;
   Data visualization
AB In recent years, artificial intelligence and its tools are demonstrated enough potential for analyzing medical images. Several deep learning models have been proposed in previous studies for gastrointestinal (GI) tract like ulcers, polyps, bleeding, and other lesions. Hand-operated investigation of these lesions requires time, cost, and an expert physician. Automatic detection and classification of GI tract lesions are vital because misdiagnosis of them can affect the quality of human life. In our study, an effective model is proposed for a GI tract classification with the best performance. The proposed method's main aim is to classify GI tract lesions precisely from endoscopic video frames automatically. The different scenarios are designed, assessed, and compared by implementing 5-fold cross-validation on the KVASIR V1 dataset to achieve this aim. This dataset includes anatomical landmarks (pylorus, z-line, and cecum), pathological findings (esophagitis, ulcerative colitis, and polyp), and polyp removals (dyed lifted polyps, and dyed resection margins) as output classes. Each class includes 500 images, and an image's resolution varies from 750 x 576 to 1920 x 1072 pixels. These first and second scenarios are based on deep neural networks (DNNs). However, in the first scenario, a novel approach is proposed for visualizing 2-D data maps from features extracted from the convolutional auto-encoder (CAE). The last one is schemed based on pre-trained convolutional neural networks (CNNs). The experimental results illustrate the average accuracy of the first, second, and third scenarios is 99.87 & PLUSMN; 0.001, 92.07 & PLUSMN; 0.086, and 90.55 & PLUSMN; 0.111, respectively. The first scenario outperforms the compared ones with an average accuracy of 99.87 & PLUSMN; 0.001 and an AUC of 100.00 & PLUSMN; 0.000.
C1 [Nezhad, Shima Ayyoubi; Khatibi, Toktam] Tarbiat Modares Univ TMU, Sch Ind & Syst Engn, Tehran 1411713114, Iran.
   [Sohrabi, Masoudreza] Iran Univ Med Sci IUMS, Gastrointestinal & Liver Dis Res Ctr, Tehran, Iran.
C3 Tarbiat Modares University; Iran University of Medical Sciences
RP Khatibi, T (corresponding author), Tarbiat Modares Univ TMU, Sch Ind & Syst Engn, Tehran 1411713114, Iran.
EM shima.ayyoubinezhad@modares.ac.ir; toktam.khatibi@modares.ac.ir;
   sohrab_r@yahoo.com
OI Khatibi, Toktam/0000-0001-5824-9798
CR Ahmad J, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0836-y
   Asperti, 2017, ARXIV, DOI DOI 10.1016/J.COMPMEDIMAG.2020.101852
   Borgli H, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00622-y
   Caroppo A, 2021, COMPUT MED IMAG GRAP, V88, DOI 10.1016/j.compmedimag.2020.101852
   Chauhan NK, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTING, POWER AND COMMUNICATION TECHNOLOGIES (GUCON), P340
   Chenxi Zhang, 2020, 2020 Second International Conference on Transdisciplinary AI (TransAI), P1, DOI 10.1109/TransAI49837.2020.00007
   Elhami G, 2019, P INT C AC SPEECH SI
   Ghosh T, 2021, J DIGIT IMAGING, V34, P404, DOI 10.1007/s10278-021-00428-3
   Guo XQ, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101733
   Han J, 2012, MOR KAUF D, P1
   Hasan MM, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-12250-2
   Heidari M, 2020, INT J MED INFORM, V144, DOI 10.1016/j.ijmedinf.2020.104284
   Hu HY, 2021, INT J IMAG SYST TECH, V31, P439, DOI 10.1002/ima.22470
   Hwang M, 2020, COMPUT MED IMAG GRAP, V84, DOI 10.1016/j.compmedimag.2020.101763
   Jain S, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104789
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Khan MA, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12112718
   Kingma D. P., 2014, arXiv
   Leung WK, 2021, ALIMENT PHARM THER, V53, P864, DOI 10.1111/apt.16272
   Li LQ, 2020, MULTIMED TOOLS APPL, V79, P14509, DOI 10.1007/s11042-018-6970-9
   Maggipinto M, 2018, PROCEDIA MANUF, V17, P126, DOI 10.1016/j.promfg.2018.10.023
   McClelland James, 1986, Parallel Distributed Processing. Explanations in the Microstructure of Cognition, V1, P3, DOI DOI 10.1016/B978-1-4832-1446-7.50010-8
   Mohapatra S, 2021, INTERDISCIP SCI, V13, P212, DOI 10.1007/s12539-021-00417-8
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Owais M, 2019, J CLIN MED, V8, DOI 10.3390/jcm8070986
   Öztürk S, 2020, MULTIMED TOOLS APPL, V79, P28825, DOI 10.1007/s11042-020-09468-3
   Pannu HS, 2020, MULTIMED TOOLS APPL, V79, P21941, DOI 10.1007/s11042-020-08905-7
   Pogorelov K., 2017, KVASIR: A Multi-Class Image Dataset for Computer Aided Gastrointestinal Disease Detection, DOI [10.1145/3193289, DOI 10.1145/3193289]
   Ponnusamy, 2019, INT J RECENT TECHNOL, V8, P6024, DOI [10.35940/ijrte.C5568.098319, DOI 10.35940/IJRTE.C5568.098319]
   Raksasat R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84396-2
   Rau A, 2019, INT J COMPUT ASS RAD, V14, P1167, DOI 10.1007/s11548-019-01962-w
   Safarov S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041441
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x
   Vieira PM, 2020, MED PHYS, V47, P52, DOI 10.1002/mp.13709
   Xing XH, 2020, IEEE T MED IMAGING, V39, P4047, DOI 10.1109/TMI.2020.3010102
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
NR 39
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15825
EP 15844
DI 10.1007/s11042-023-15347-4
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035725700015
DA 2024-07-18
ER

PT J
AU Çelik, H
   Dogan, N
AF Celik, Hidayet
   Dogan, Nurettin
TI A hybrid color image encryption method based on extended logistic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; Color image encryption; Affine cipher; Chaotic map; Data
   security
ID CHAOTIC SYSTEM; CHAOTIFICATION
AB The existence of images containing our personal data or strategic information of states in the developing digital world is an indication that there will be malicious people who want to access this information. Undoubtedly, the attackers' job will be a little more difficult if the valuable information of importance is transmitted by encrypting on common channels. In this regard, traditional and modern methods are used for encryption. Although traditional cryptosystems are widely used in text encryption processes, they are rarely used in image encryption processes for two reasons. The first is that the encryption process takes a long time due to the fact that the image size is larger than the text size. The second is that, while there are fewer data losses on the text in the decryption process, data losses on the image may cause the image's structure to be disrupted. In this study, after giving brief information about encryption, the proposed hybrid image encryption method has been explained. In this method, firstly, an encryption process performed with affine and substitution methods from traditional cryptosystems has been applied, then an extended one-dimension (1D) chaotic map has been used to strengthen the encryption process. The superiority of the proposed method has been evaluated with performance analysis.
C1 [Celik, Hidayet; Dogan, Nurettin] Selcuk Univ, Technol Fac, Comp Engn Dept, Konya, Turkiye.
C3 Selcuk University
RP Dogan, N (corresponding author), Selcuk Univ, Technol Fac, Comp Engn Dept, Konya, Turkiye.
EM celikhidayet@gmail.com; ndogan@ymail.com
RI DOĞAN, Nurettin/C-1090-2013
OI DOĞAN, Nurettin/0000-0002-8267-8469
CR Abd Elminaam DiaaSalama., 2010, IJ NETWORK SECURITY, V10, P216
   Abdulridha Taha A., 2018, FAR E J ELECT COMMUN, V18, P521, DOI [10.17654/EC018040521, DOI 10.17654/EC018040521]
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Benssalah M, 2021, MULTIMED TOOLS APPL, V80, P2081, DOI 10.1007/s11042-020-09775-9
   Cheng GF, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501153
   Das AK, 2021, MICROSYST TECHNOL, V27, P409, DOI 10.1007/s00542-018-3980-5
   Demir N., 2018, AVRUPA BILIM TEKNOLO, V14, P334, DOI [10.31590/ejosat.487931, DOI 10.31590/EJOSAT.487931]
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Hua ZY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107998
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P4505, DOI 10.1007/s11071-021-06472-6
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P807, DOI 10.1007/s11071-021-06308-3
   Hua ZY, 2020, IEEE T SIGNAL PROCES, V68, P1937, DOI 10.1109/TSP.2020.2979596
   Huang LQ, 2019, OPT LASER ENG, V115, P7, DOI 10.1016/j.optlaseng.2018.11.015
   Hussain I, 2012, NONLINEAR DYNAM, V70, P181, DOI 10.1007/s11071-012-0440-0
   IEEE Computer Society, 1985, IEEE STAND BIN FLOAT, V754
   Iqbal N, 2020, IEEE ACCESS, V8, P178167, DOI 10.1109/ACCESS.2020.3025241
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Khalil N, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107326
   Khan M, 2021, INTEGRATION, V81, P108, DOI 10.1016/j.vlsi.2021.05.007
   Liang HR, 2016, QUANTUM INF PROCESS, V15, P2701, DOI 10.1007/s11128-016-1304-1
   Liu HJ, 2015, OPT COMMUN, V338, P340, DOI 10.1016/j.optcom.2014.10.021
   Liu HJ, 2013, OPTIK, V124, P3527, DOI 10.1016/j.ijleo.2012.10.068
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Lone PN, 2021, J MOD OPTIC, V68, P507, DOI 10.1080/09500340.2021.1924885
   Lone PN, 2020, OPTIK, V218, DOI 10.1016/j.ijleo.2020.165155
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Mollaeefar M, 2017, MULTIMED TOOLS APPL, V76, P607, DOI 10.1007/s11042-015-3064-9
   Munir R., 2012, 2012 7th International Conference on Telecommunications, Systems, Services, and Applications (TSSA 2012), P142, DOI 10.1109/TSSA.2012.6366039
   Muthukumar P, 2015, NONLINEAR DYNAM, V80, P1883, DOI 10.1007/s11071-014-1583-y
   Naveenkumar SK, 2013, 2013 INT C OPTICAL I, P1, DOI 10.1109/ICOISS.2013.6678416
   Pak C, 2020, MULTIMED TOOLS APPL, V79, P1409, DOI 10.1007/s11042-019-08103-0
   Palathingal AG, 2018, INT RES J ENG TECHNO, V5
   Purnama B, 2015, PROCEDIA COMPUT SCI, V59, P195, DOI 10.1016/j.procs.2015.07.552
   Ray A, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN SIGNAL PROCESSING AND EMBEDDED SYSTEMS (RISE), P274, DOI 10.1109/RISE.2017.8378166
   Sabir S, 2021, MULTIMED TOOLS APPL, V80, P27829, DOI 10.1007/s11042-021-11003-x
   Sahin S, 2010, IEEE ANTENN PROPAG M, V52, P222, DOI 10.1109/MAP.2010.5723275
   Sari RN, 2018, 2018 6 INT S DIG FOR, P1, DOI [10.1109/ICTSS.2018.8549983, DOI 10.1109/ICTSS.2018.8549983, 10.1109/CITSM.2018.8674368, DOI 10.1109/ISDFS]
   Sayed WS, 2021, EGYPT INFORM J, V22, P155, DOI 10.1016/j.eij.2020.07.002
   Shah D, 2020, MULTIDIM SYST SIGN P, V31, P885, DOI 10.1007/s11045-019-00689-w
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Singh G., 2013, Int. J. Comput. Appl., V67
   Tong XJ, 2013, COMMUN NONLINEAR SCI, V18, P1725, DOI 10.1016/j.cnsns.2012.11.002
   Wang XY, 2016, OPT LASER ENG, V82, P79, DOI 10.1016/j.optlaseng.2015.12.006
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xiong ZG, 2019, MULTIMED TOOLS APPL, V78, P31035, DOI 10.1007/s11042-018-7081-3
   Zaidan BB., 2009, INT J COMPUT SCI ENG, V1, P263
   Zhou J, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106437
   Zhu HG, 2014, OPTIK, V125, P6672, DOI 10.1016/j.ijleo.2014.06.149
NR 52
TC 7
Z9 7
U1 11
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12627
EP 12650
DI 10.1007/s11042-023-16215-x
EA JUL 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001027813700010
DA 2024-07-18
ER

PT J
AU Patil, GG
   Banyal, RK
AF Patil, Ganesh Gopalrao
   Banyal, Rohitash Kumar
TI Improved FCN for partial face recognition with gallery, probe, and
   modified LBP-based texture features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic feature matching; Sparse representation classification; Improved
   fully convolutional network; Partial face recognition; Optimization
ID ALGORITHM; CLASSIFICATION; OPTIMIZER
AB Several researchers are currently investigating the subject of person recognition; however there are some areas that even the researchers have not explored. One of these areas is Partial Face Recognition (PFR). In the area of computer vision, a standard research direction is the PFR approach based on machine learning. However, the PFR technique does possess significant difficulties, owing to nonrigid characteristics as well as the effect of a complicated background. Therefore, to overcome such challenges, a novel PFR scheme is implemented in this research work with the aid of an improved FCN model and Sparse Representation Classification (SRC). Initially, the dynamic features like galley and the probe features of the input image are mapped using a new Improved Fully Convolutional Network (IFCN) model. Along with the dynamic features, the improved Local Binary Pattern (ILBP) features are also extracted, to enhance the detection performance. The Structural Similarity Index metric is also used to calculate the similarity scores between the probing map of features and the collection of sub-feature map. Moreover, the sparse coefficient of Dynamic Feature Matching (DFM) is optimally tuned via new Flower Pollination Algorithm with Adaptive mutation (FPAAM) model, to minimize the reconstruction error. This FPAAM model is an improved version of standard Flower Pollination Algorithm (FPA). Subsequently, the performance of the proposed scheme is compared to the existing models using various measures. The projected model achieves an accuracy of 98% while the learning percentage is 60. The cost function of the adopted model attains the lowest value of 0.2 when compared to existing approaches Cat Mouse Based Optimization (CMBO), Butterfly Optimization Algorithm (BOA), Slap Swarm Algorithm (SSA), Sail Fish Optimization (SFO), FPA, and Sea-Lion Updated Grey Wolf Optimization (SUGWO).
C1 [Patil, Ganesh Gopalrao; Banyal, Rohitash Kumar] Rajasthan Tech Univ, Dept Comp Sci & Engn, Kota 324010, Rajasthan, India.
C3 Rajasthan Technical University
RP Patil, GG (corresponding author), Rajasthan Tech Univ, Dept Comp Sci & Engn, Kota 324010, Rajasthan, India.
EM gopalraoganesh09@gmail.com
CR Akheel TS, 2022, EVOL INTELL, V15, P1729, DOI 10.1007/s12065-021-00585-y
   Alenazy WM, 2021, MULTIMED TOOLS APPL, V80, P7411, DOI 10.1007/s11042-020-09976-2
   Aminu M, 2020, IEEE ACCESS, V8, P166703, DOI 10.1109/ACCESS.2020.3022784
   Arora S, 2019, SOFT COMPUT, V23, P715, DOI 10.1007/s00500-018-3102-4
   Bommidi K, 2021, MULTIMEDIA SYST, V27, P191, DOI 10.1007/s00530-020-00727-9
   Dehghani M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155214
   Du Q, 2021, VISUAL COMPUT, V37, P663, DOI 10.1007/s00371-020-01802-y
   Duan YQ, 2018, IEEE T INF FOREN SEC, V13, P1823, DOI 10.1109/TIFS.2018.2804919
   Elmahmudi A, 2019, FUTURE GENER COMP SY, V99, P213, DOI 10.1016/j.future.2019.04.025
   Fan ZZ, 2020, MULTIMED TOOLS APPL, V79, P7319, DOI 10.1007/s11042-019-08211-x
   Gangonda Siddheshwar S., 2022, International Journal of Information Technology, V14, P1823, DOI 10.1007/s41870-021-00703-0
   Gao Y, 2019, NEURAL COMPUT APPL, V31, P607, DOI 10.1007/s00521-017-3035-3
   Hamid Karimi-Rouzbahani, 2021, NEUROIMAGE, V233
   He LX, 2019, IEEE T IMAGE PROCESS, V28, P791, DOI 10.1109/TIP.2018.2870946
   He QQ, 2019, MULTIMED TOOLS APPL, V78, P24035, DOI 10.1007/s11042-019-7209-0
   Hu WP, 2019, NEURAL PROCESS LETT, V50, P1465, DOI 10.1007/s11063-018-9942-1
   Juneja K, 2021, WIRELESS PERS COMMUN, V118, P3075, DOI 10.1007/s11277-021-08170-3
   Kamal A, 2022, COGN COMPUT, V14, P91, DOI 10.1007/s12559-021-09821-0
   Kamarajugadda KK, 2019, MULTIMED TOOLS APPL, V78, P27639, DOI 10.1007/s11042-019-7741-y
   Krishnaveni B, 2019, MULTIMED TOOLS APPL, V78, P27511, DOI 10.1007/s11042-019-07831-7
   Lahasan B, 2018, INFORM SCIENCES, V429, P194, DOI 10.1016/j.ins.2017.11.013
   Le Qin, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P72, DOI 10.1109/TBIOM.2020.3022007
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Mahbub U, 2020, IEEE T AFFECT COMPUT, V11, P601, DOI 10.1109/TAFFC.2018.2820048
   Mahbub U, 2019, IMAGE VISION COMPUT, V82, P1, DOI 10.1016/j.imavis.2018.12.003
   Ming ZH, 2021, INT J DOC ANAL RECOG, V24, P33, DOI 10.1007/s10032-021-00364-6
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Nadeem MF, 2020, P 2020 INT C ENG EM, P1, DOI DOI 10.1109/ICEET48479.2020.9048215
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Patil GG, 2021, TECHN SOC 2020 P 3 I, V1
   Shadravan S, 2019, ENG APPL ARTIF INTEL, V80, P20, DOI 10.1016/j.engappai.2019.01.001
   Shan XX, 2021, IEEE T CIRC SYST VID, V31, P4347, DOI 10.1109/TCSVT.2020.3047140
   Shaw R, 2023, COGN COMPUT, V15, P1243, DOI 10.1007/s12559-022-10023-5
   Tavoosi J., 2021, IRAN J COMPUTER SCI, V4, P185, DOI [10.1007/s42044-020-00076-w, DOI 10.1007/S42044-020-00076-W]
   Yang Zhou, 2021, J VIS COMMUN IMAGE R, V78
   Yu NG, 2020, IEEE ACCESS, V8, P4700, DOI 10.1109/ACCESS.2019.2963201
   Zhang BP, 2019, CLUSTER COMPUT, V22, P827, DOI 10.1007/s10586-017-1330-5
   Zhou XL, 2020, NEUROCOMPUTING, V390, P217, DOI 10.1016/j.neucom.2019.04.099
NR 38
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13953
EP 13976
DI 10.1007/s11042-023-16086-2
EA JUL 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001027813700004
DA 2024-07-18
ER

PT J
AU Jiang, N
   Zhuang, Y
   Chiu, DKW
AF Jiang, Nan
   Zhuang, Yi
   Chiu, Dickson K. W.
TI An effective and efficient parallel large-scale cross-media retrieval in
   mobile cloud network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-media; Cross reference graph; Cross storage; Data allocation;
   High-dimensional indexing
ID PERFORMANCE; IMAGE; QUERY; WEB
AB With the rapid growth of multimedia data (e.g., text, image, video, audio and 3D model, etc) in the web, there are a large number of media objects with different modalities in the multimedia documents such as webpages, which exhibit latent semantic correlation. As a new type of multimedia retrieval method, cross-media retrieval is becoming increasingly attractive, through which users can get the results with various media types with the same semantic information by submitting a retrieval of any media type. The explosive increasing of the number of media objects, however, makes it difficult for the traditional local standalone mode to process efficiently. So the powerful parallel processing capability of cloud computing is accommodated to facilitate the efficient large-scale cross-media retrieval. In this paper, based on a Multi-Layer-Cross-Reference-Graph(MLCRG) model, we propose an efficient parallel cross-media retrieval (PCMR) method in which two enabling techniques (i.e., 1) the adaptive cross-media data allocation algorithm and 2) the PCIndex scheme) are accommodated to effectively speedup the retrieval performance. To the best of our knowledge, there is little research on the parallel retrieval processing of the large-scale cross-media databases in the mobile cloud network. Extensive experiments are conducted to testify that our proposed PCIndex method outperform the three competitors (e.g., the PFAR (Mao et al, 22), the MBSR (Retrieval 4(2):153-164, 42) and the SPECH (Knowl Based Syst 251(5):1-13, 40)) in terms of the effectiveness and efficiency, respectively.
C1 [Jiang, Nan] Zhejiang Univ, Sch Med, Affiliated Hangzhou Peoples Hosp 1, Zhejiang, Peoples R China.
   [Zhuang, Yi] Zhejiang Gongshang Univ, Sch Comp Sci & Technol, Zhejiang, Peoples R China.
   [Chiu, Dickson K. W.] Univ Hong Kong, Fac Educ, HKSAR, Hong Kong, Peoples R China.
C3 Zhejiang University; Zhejiang Gongshang University; University of Hong
   Kong
RP Zhuang, Y (corresponding author), Zhejiang Gongshang Univ, Sch Comp Sci & Technol, Zhejiang, Peoples R China.
EM zhuang@mail.zjgsu.edu.cn
RI wang, nan/KHW-4897-2024; Chiu, Dickson K. W./B-9630-2017
OI Chiu, Dickson K. W./0000-0002-7926-9568
FU Zhejiang Province Philosophy and Social Science Planning Project
   [23NDJC165YB]; Zhejiang Provincial Natural Science Foundation of China
   [LGF19F020004, LY22F020010, LGF22H180039, LTGY23F020002]; Zhejiang
   Traditional Chinese Medicine Science and Technology Project [2023ZL119]
FX The authors would like to thank the editors and anonymous reviewers for
   their helpful comments. This work is partially supported by Zhejiang
   Province Philosophy and Social Science Planning Project under Grant No.
   23NDJC165YB; Zhejiang Provincial Natural Science Foundation of China
   under Grant No. LGF19F020004, LY22F020010, LGF22H180039 and
   LTGY23F020002; the Zhejiang Traditional Chinese Medicine Science and
   Technology Project under grant No. 2023ZL119.
CR [Anonymous], 2000, P 26 INT C VER LARG
   BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93605.98741
   Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28
   Berchtold S., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), P577, DOI 10.1109/ICDE.2000.839456
   Berchtold S, 1998, P ACM SIGMOD
   Böhm C, 2001, ACM COMPUT SURV, V33, P322, DOI 10.1145/502807.502809
   Bozkaya T., 1997, SIGMOD Record, V26, P357, DOI 10.1145/253262.253345
   Chang SF, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P313, DOI 10.1145/266180.266382
   Chávez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808
   Chen FY, 2021, IEEE T MULTIMEDIA, V23, P3073, DOI 10.1109/TMM.2020.3019710
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   encarta, 2006, MICROSOFT ENCARTA
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Fonseca MJ, 2003, EIGHTH INTERNATIONAL CONFERENCE ON DATABASE SYSTEMS FOR ADVANCED APPLICATIONS, PROCEEDINGS, P267, DOI 10.1109/DASFAA.2003.1192391
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266
   Jagadish HV, 2006, IEEE T KNOWL DATA EN, V18, P350, DOI 10.1109/TKDE.2006.51
   Jagadish HV, 2005, ACM T DATABASE SYST, V30, P364, DOI 10.1145/1071610.1071612
   Katamaya N, 1997, PROC ACM SIGMOD, P32
   Li Z., 2021, P 25 INT C PATT REC, P1
   Lin K, 1994, VLDB J
   Lu B, 2012, J COMPUT SCI TECH-CH, V27, P1140, DOI 10.1007/s11390-012-1292-2
   Mao X, 2013, P 21 ACM MULT
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Peng Y, 2020, IEEE T CIRCUITS SYST, V30
   Peng YX, 2018, IEEE T CIRC SYST VID, V28, P2372, DOI 10.1109/TCSVT.2017.2705068
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Santos RF, 2001, PROC INT CONF DATA, P623, DOI 10.1109/ICDE.2001.914877
   Shen HT, 2006, WORLD WIDE WEB, V9, P343, DOI 10.1007/s11280-006-8560-4
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Smith JR, 1997, IEEE MULTIMEDIA, V4, P12, DOI 10.1109/93.621578
   Traina C, 2000, LECT NOTES COMPUT SC, V1777, P51
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   White DA, 1996, PROC INT CONF DATA, P516, DOI 10.1109/ICDE.1996.492202
   Wu F, 2006, IEEE IMAGE PROC, P1465, DOI 10.1109/ICIP.2006.312707
   Wu GS, 2019, IEEE T IND ELECTRON, V66, P9868, DOI 10.1109/TIE.2018.2873547
   Xu XL, 2021, ACM T SENSOR NETWORK, V17, DOI 10.1145/3447032
   Yang F, 2022, KNOWL-BASED SYST, V251, DOI 10.1016/j.knosys.2022.109176
   Yang J, 2005, WORLD WIDE WEB, V8, P495, DOI 10.1007/s11280-005-0905-x
   Yang J, 2002, P 11 INT C WORLD WID, P54, DOI DOI 10.1145/511446.511454
   Zhai XH, 2013, MULTIMEDIA SYST, V19, P395, DOI 10.1007/s00530-012-0297-6
   Zhao XY, 2015, INT J MULTIMED INF R, V4, P153, DOI 10.1007/s13735-015-0081-4
   Zhuang Y, 2009, P DASFAA 09 BRISB AU
   Zhuang YT, 2008, IEEE T MULTIMEDIA, V10, P221, DOI 10.1109/TMM.2007.911822
NR 44
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13821
EP 13850
DI 10.1007/s11042-023-16060-y
EA JUL 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001026613700005
DA 2024-07-18
ER

PT J
AU Hoang, TM
AF Hoang, Thang Manh
TI A novel structure of fast and efficient multiple image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital perturbed chaos; Perturbed chaotic map (PCM); Chaos-based image
   encryption; Multiple image encryption (MIE)
ID ALGORITHM; PERMUTATION; SCHEME; CRYPTANALYSIS; RETRIEVAL
AB A huge volume of image data is created every day, and it requires a fast and efficient encryption to keep them confidential. A chaos-based encryption is considered as the most suitable one for image encryption, and multiple image encryption is one of approaches to achieve the fast and efficient performance. However, the existing methods of multiple image encryption is with a lack of diffusion effect, inefficiency in using random number generated by chaotic map, and low speed. In this paper, a novel structure of chaos-based encryption is proposed to encrypt multiple images at the same time, in which the permutation and diffusion are integrated and they share the same chaotic map. The exclusive-OR operation is chosen for calculation and data manipulation during encryption. Therefore, the proposed structure allows to improve the efficiency and to reduce the time consumption for the encryption. In addition, the chaotic map is perturbed frequently and its dynamics is dependent on the content of images. It creates the dynamical session key, so the proposed structure can resist from the types of chosen-plaintext and chosen-ciphertext attacks. Two exemplar ciphers employing the proposed structure are demonstrated with the use of Logistic and Standard maps. The simulation results will be analysed and compared with those of existing methods to show the feasibility and effectiveness of the proposed structure of multiple image encryption.
C1 [Hoang, Thang Manh] Hanoi Univ Sci & Technol, Sch Elect & Elect Engn, 1 Dai Co Viet, Hanoi, Vietnam.
   [Hoang, Thang Manh] Hanoi Univ Sci & Technol, Vietnam Japan Int Inst Sci Technol, 1 Dai Co Viet, Hanoi, Vietnam.
C3 Hanoi University of Science & Technology (HUST); Hanoi University of
   Science & Technology (HUST)
RP Hoang, TM (corresponding author), Hanoi Univ Sci & Technol, Sch Elect & Elect Engn, 1 Dai Co Viet, Hanoi, Vietnam.; Hoang, TM (corresponding author), Hanoi Univ Sci & Technol, Vietnam Japan Int Inst Sci Technol, 1 Dai Co Viet, Hanoi, Vietnam.
EM thang.hoangmanh@hust.edu.vn
OI Manh Hoang, Thang/0000-0003-3555-5682
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Alvarez G, 2011, STUD COMPUT INTELL, V354, P257
   Arroyo D, 2013, SIGNAL PROCESS, V93, P1358, DOI 10.1016/j.sigpro.2012.11.019
   Ayoup AM, 2016, MULTIMED TOOLS APPL, V75, P17171, DOI 10.1007/s11042-015-2985-7
   Banik A, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102398
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Bhatnagar G, 2012, DIGIT SIGNAL PROCESS, V22, P648, DOI 10.1016/j.dsp.2012.02.005
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P15561, DOI 10.1007/s11042-016-3858-4
   Chen JX, 2015, NONLINEAR DYNAM, V81, P1151, DOI 10.1007/s11071-015-2057-6
   Cheng PG, 2015, NONLINEAR DYNAM, V79, P2121, DOI 10.1007/s11071-014-1798-y
   Cheng SL, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030332
   Deepak M, 2014, 2014 FIRST INTERNATIONAL CONFERENCE ON NETWORKS & SOFT COMPUTING (ICNSC), P360, DOI 10.1109/CNSC.2014.6906665
   Diab H, 2018, IEEE ACCESS, V6, P42227, DOI 10.1109/ACCESS.2018.2858839
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Farajallah M, 2016, INT J BIFURCAT CHAOS, V26, DOI 10.1142/S0218127416500218
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gayathri J, 2018, MULTIMED TOOLS APPL, V77, P24751, DOI 10.1007/s11042-018-5675-4
   Hanis S, 2019, NONLINEAR DYNAM, V95, P421, DOI 10.1007/s11071-018-4573-7
   Hosny KM, 2022, J AMB INTEL HUM COMP, V13, P973, DOI 10.1007/s12652-021-03675-y
   Jahangir S, 2021, J INF SECUR APPL, V59, DOI 10.1016/j.jisa.2021.102831
   Karawia AA, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20100801
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Kocarev L, 2011, STUD COMPUT INTELL, V354, P1, DOI 10.1007/978-3-642-20542-2
   Kocarev L., 2001, IEEE CIRC SYST MAG, V1, P6, DOI DOI 10.1109/7384.963463
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Kumar M, 2020, SURVEY CHAOS BASED I, P1
   Kumar M, 2021, MULTIMED TOOLS APPL, V80, P18941, DOI 10.1007/s11042-020-10325-6
   Li XY, 2017, OPT LASER ENG, V96, P7, DOI 10.1016/j.optlaseng.2017.04.005
   Liu LF, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500591
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Malik DS, 2020, MATH COMPUT SIMULAT, V178, P646, DOI 10.1016/j.matcom.2020.07.007
   Patro KAK, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102470
   Patro KAK, 2020, MULTIMED TOOLS APPL, V79, P12959, DOI 10.1007/s11042-019-08470-8
   Patro KAK, 2018, J INF SECUR APPL, V40, P111, DOI 10.1016/j.jisa.2018.03.006
   Sahasrabuddhe A, 2020, INFORM SCIENCES
   Sang T, 1998, ELECTRON LETT, V34, P873, DOI 10.1049/el:19980680
   Shen Q, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417502042
   Situ G, 2006, J OPT A-PURE APPL OP, V8, P391, DOI 10.1088/1464-4258/8/5/005
   Som Sukalyan, 2014, 2014 2nd International Conference on Business and Information Management (ICBIM), P58, DOI 10.1109/ICBIM.2014.6970933
   Strogatz S.H., 2018, Nonlinear dynamics and chaos: with applications to physics, biology, chemistry, and engineering, DOI [10.1201/9780429492563, DOI 10.1201/9780429492563]
   Sui LS, 2014, OPT LASERS ENG, V62
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Hoang TM, 2021, IEEE ICCE 2020: 2020 IEEE EIGHTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P413, DOI 10.1109/ICCE48956.2021.9352070
   Hoang TM, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22050548
   Hoang TM, 2018, OPTIK, V155, P366, DOI 10.1016/j.ijleo.2017.10.072
   Tong XJ, 2015, NONLINEAR DYNAM, V80, P1493, DOI 10.1007/s11071-015-1957-9
   ul Haq T, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102592
   Wang XG, 2011, OPT COMMUN, V284, P148, DOI 10.1016/j.optcom.2010.09.034
   Wang Y, 2014, OPT COMMUN, V330, P91, DOI 10.1016/j.optcom.2014.05.032
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Yang ZL, 2021, EUR PHYS J-SPEC TOP, V230, P1785, DOI 10.1140/epjs/s11734-021-00117-w
   Zarebnia M, 2019, OPTIK, V179, P761, DOI 10.1016/j.ijleo.2018.10.025
   Zhang L, 2020, MULTIMED TOOLS APPL, V79, P20753, DOI 10.1007/s11042-020-08835-4
   Zhang XQ, 2019, MULTIMED TOOLS APPL, V78, P7841, DOI 10.1007/s11042-018-6496-1
   Zhang XQ, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10110660
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang XQ, 2017, OPT LASER ENG, V92, P6, DOI 10.1016/j.optlaseng.2016.12.005
   Zhou NR, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-020-02794-3
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2104-6
NR 63
TC 1
Z9 1
U1 16
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12985
EP 13028
DI 10.1007/s11042-023-15880-2
EA JUL 2023
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001020441500001
DA 2024-07-18
ER

PT J
AU Rafidison, MA
   Rakotomihamina, AH
   Rajaonarison, FTM
   Rafanantenana, SHJ
   Ramafiarisona, HM
AF Rafidison, M. A.
   Rakotomihamina, A. H.
   Rajaonarison, F. T. M.
   Rafanantenana, S. H. J.
   Ramafiarisona, H. M.
TI Intervention of light convolutional neural network in document survey
   form processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Entropy; Form processing; Intersecting cortical model; Lite
   convolutional neural network; Survey
ID TEXT; RECOGNITION
AB Public survey is popular in different domain to have a feedback from service users in the aim to improve the quality of service provided or to figure out what they think. In general, the data processing takes time due of manual intervention and it may distort the result because an error of processing may occur, so the aim of this research is to propose a new finding how to process rapidly a paper survey form to have the statistic result on time. The paper template design must have at least one question with "Yes" and "No" check box or radio button as response field. People have a liberal choice to reply: normal, no response or both. In each box in form can contain a different type of handwriting and the way to recognize them is within mathematics tools combined with neural networks. First of all, the physical paper which contents the information must be converted to image by digitization operation. Any type format of image is accepted then it will be handled by preprocessing module before coming to the Lite Convolutional Neural Network. Once the neural networks finish the treatment, a postprocessing module computes the information and insert into database. The singularity of this technique is the intervention of Lite Convolutional Neural Network as recognition tool which has more advantage compared with standard deep learning in terms of computation time, accuracy/precision and number of parameters. The validation of this approach is done with RVL-CDIP dataset, real survey of mobile money and satellite TV service, the accuracy reaches 96%, 97% and 98% respectively.
C1 [Rafidison, M. A.; Rakotomihamina, A. H.; Rajaonarison, F. T. M.; Rafanantenana, S. H. J.; Ramafiarisona, H. M.] Univ Antananarivo, Lab Doctoral Sch Sci & Technol Engn & Innovat, Telecommun Automat Signal Image Res, Antananarivo 101, Madagascar.
C3 University Antananarivo
RP Rafidison, MA (corresponding author), Univ Antananarivo, Lab Doctoral Sch Sci & Technol Engn & Innovat, Telecommun Automat Signal Image Res, Antananarivo 101, Madagascar.
EM mamynyaina@gmail.com
OI TOKY, Rajaonarison Faniriharisoa Maxime/0000-0001-7975-905X; RAFIDISON,
   Maminiaina Alphonse/0000-0001-7734-4563
CR Afzal MZ, 2015, PROC INT CONF DOC, P1111, DOI 10.1109/ICDAR.2015.7333933
   Aldoski J, 2022, IMAGE CLASSIFICATION
   Appalaraju S., 2021, P IEEECVF INT C COMP, P993
   Asgher U, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00584
   Baek J, 2019, IEEE I CONF COMP VIS, P4714, DOI 10.1109/ICCV.2019.00481
   Baek Y, 2019, PROC CVPR IEEE, P9357, DOI 10.1109/CVPR.2019.00959
   Bunke H., 1997, ANAL PRINTED FORMS, DOI [10.1142/9789812830968_0018, DOI 10.1142/9789812830968_0018]
   Casey R., 1992, Machine Vision and Applications, V5, P143, DOI 10.1007/BF02626994
   Chen JL, 1998, PATTERN RECOGN, V31, P1353, DOI 10.1016/S0031-3203(97)00156-8
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ekblad U, 2004, NUCL INSTRUM METH A, V525, P392, DOI 10.1016/j.nima.2004.03.102
   Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345
   Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254
   Harley AW, 2015, PROC INT CONF DOC, P991, DOI 10.1109/ICDAR.2015.7333910
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33
   Hwang W, 2019, DOCUMENT INTELLIGENC
   Hwang W, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3375
   Hwang W, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P330
   Jaderberg M., 2014, ARXIV
   Kang L, 2014, INT C PATT RECOG, P3168, DOI 10.1109/ICPR.2014.546
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Kastrati Z, 2019, INFORM PROCESS MANAG, V56, P1618, DOI 10.1016/j.ipm.2019.05.003
   Kathait S., 2018, INT J COMPUT APPL, V179, P7, DOI [10.5120/ijca2018915460, DOI 10.5120/IJCA2018915460]
   Kim G, 2022, LECT NOTES COMPUT SC, V13688, P498, DOI 10.1007/978-3-031-19815-1_29
   Kingma D.P., 2014, ARXIV14126980
   Li PZ, 2021, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR46437.2021.00560
   Li XJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102764
   Li Xingyuan, 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P531, DOI 10.1109/ICDAR.1999.791842
   Liao MH, 2017, AAAI CONF ARTIF INTE, P4161
   Lindblad T., 2005, IMAGE PROCESSING USI, V2, P11
   Liu W., 2016, BMVC, V2, P7, DOI [10.5244/C.30.43, DOI 10.5244/C.30.43]
   Mahgoub A, 2008, J SYSTEMICS CYBERN I, V6
   Mahum R, 2021, GENERIC FRAMEWORK GE, P1, DOI [10.1109/MAJICC53071.2021.9526264, DOI 10.1109/MAJICC53071.2021.9526264]
   Majumder Bodhisattwa Prasad, 2020, P 58 ANN M ASS COMP, P6495, DOI 10.18653/v1/2020.acl-main.580
   Mathew M, 2021, IEEE WINT CONF APPL, P2199, DOI 10.1109/WACV48630.2021.00225
   Mondal Ajoy, 2022, DEEP NEURAL FEATURES, DOI [10.21203/rs.3.rs-1576151/v1, DOI 10.21203/RS.3.RS-1576151/V1]
   Rafidison MA., 2021, INT J INNOV ENG RES, V8, P62
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shi BG, 2016, PROC CVPR IEEE, P4168, DOI 10.1109/CVPR.2016.452
   Sruthi PS, 2015, GRID INFRASTRUCTURE
   Stephane T, 2018, ABOUT US
   Subashini MM, 2014, EXPERT SYST APPL, V41, P3965, DOI 10.1016/j.eswa.2013.12.027
   Tanaka M., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P559, DOI 10.1109/ICSMC.1999.814153
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Phan TQ, 2013, IEEE I CONF COMP VIS, P569, DOI 10.1109/ICCV.2013.76
   Wang D., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P1031, DOI 10.1142/S0218001494000528
   Wang MZ, 2017, ADV NEUR IN, V30
   Wang ZB, 2014, IEEE IJCNN, P975, DOI 10.1109/IJCNN.2014.6889656
   Xu Y, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P2579
   Xu YH, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1192, DOI 10.1145/3394486.3403172
   Yide M, 2010, APPL PULSE COUPLED N, DOI [10.1007/978-3-642-13745-7, DOI 10.1007/978-3-642-13745-7]
   Zhang Z, 2016, PROC CVPR IEEE, P4159, DOI 10.1109/CVPR.2016.451
   Zhao ZH, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P1730, DOI 10.1109/ICMLC.2002.1175332
NR 54
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32583
EP 32605
DI 10.1007/s11042-023-16076-4
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:001020195700001
DA 2024-07-18
ER

PT J
AU Pourkeshavarz, M
   Nabavi, S
   Moghaddam, ME
   Shamsfard, M
AF Pourkeshavarz, Mozhgan
   Nabavi, Shahabedin
   Moghaddam, Mohsen Ebrahimi
   Shamsfard, Mehrnoush
TI Stacked cross-modal feature consolidation attention networks for image
   captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contextual representation; Cross-modal feature fusion; Image captioning;
   Stacked attention network; Visual and semantic information
AB The attention-enriched encoder-decoder framework has recently aroused great interest in image captioning due to its overwhelming progress. Many visual attention models directly leverage meaningful regions to generate image descriptions. However, seeking a direct transition from visual space to text is not enough to generate fine-grained captions. This paper exploits a feature-compounding approach to bring together high-level semantic concepts and visual information regarding the contextual environment fully end-to-end. Thus, we propose a stacked cross-modal feature consolidation (SCFC) attention network for image captioning in which we simultaneously consolidate cross-modal features through a novel compounding function in a multi-step reasoning fashion. Besides, we jointly employ spatial information and context-aware attributes (CAA) as the principal components in our proposed compounding function, where our CAA provides a concise context-sensitive semantic representation. To better use consolidated features potential, we propose an SCFC-LSTM as the caption generator, which can leverage discriminative semantic information through the caption generation process. The experimental results indicate that our proposed SCFC can outperform various state-of-the-art image captioning benchmarks in terms of popular metrics on the MSCOCO and Flickr30K datasets.
C1 [Pourkeshavarz, Mozhgan; Nabavi, Shahabedin; Moghaddam, Mohsen Ebrahimi; Shamsfard, Mehrnoush] Shahid Beheshti Univ, Fac Comp Sci & Engn, Tehran, Iran.
C3 Shahid Beheshti University
RP Moghaddam, ME (corresponding author), Shahid Beheshti Univ, Fac Comp Sci & Engn, Tehran, Iran.
EM m_moghadam@sbu.ac.ir
RI Shamsfard, Mehrnoush/Q-7671-2019; Nabavi, Shahabedin/AAA-3041-2022
OI Shamsfard, Mehrnoush/0000-0002-7027-7529; Nabavi,
   Shahabedin/0000-0001-7240-0239
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Buschman TJ, 2007, SCIENCE, V315, P1860, DOI 10.1126/science.1138071
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Fu K, 2017, IEEE T PATTERN ANAL, V39, P2321, DOI 10.1109/TPAMI.2016.2642953
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   Gers FA, 2000, IEEE IJCNN, P189, DOI 10.1109/IJCNN.2000.861302
   Graves A., 2013, GENERATING SEQUENCES
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   He C, 2019, NEURAL PROCESS LETT, V49, P177, DOI 10.1007/s11063-018-9807-7
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu X., 2022, IEEE C COMP VIS PATT, P17980
   Huang YQ, 2020, IEEE T IMAGE PROCESS, V29, P4013, DOI 10.1109/TIP.2020.2969330
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Karpathy A, 2014, ADV NEUR IN, V27
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kingma D. P., 2014, arXiv
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Li Yehao, 2022, P IEEE CVF C COMPUTE, P17990
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu H., 2016, ARXIV
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Mao, 2015, ARXIV
   Mao J, 2014, ARXIV
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pedersoli M, 2017, IEEE I CONF COMP VIS, P1251, DOI 10.1109/ICCV.2017.140
   Qin Y, 2019, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2019.00856
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Shao Z, 2023, IEEE T MULTIMEDIA
   Shao Zhuang, 2022, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2022.3152990
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Su Y, 2019, NEURAL PROCESS LETT, P1
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang JB, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107075
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Zha ZJ, 2022, IEEE T PATTERN ANAL, V44, P710, DOI 10.1109/TPAMI.2019.2909864
   Zheng Y., 2019, IEEE ICC, P1, DOI [DOI 10.1109/icc.2019.8761643, DOI 10.1109/ICC.2019.8761643, DOI 10.1109/MITS.2018.2889654]
   Zohourianshahzadi Z, 2022, ARTIF INTELL REV, V55, P3833, DOI 10.1007/s10462-021-10092-2
NR 57
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 12209
EP 12233
DI 10.1007/s11042-023-15869-x
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001014722500005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kumar, K
   Ghosh, R
AF Kumar, Kaushal
   Ghosh, Rajib
TI Parkinson's disease diagnosis using recurrent neural network based deep
   learning model by analyzing online handwriting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parkinson's disease; Kinematics features; Deep learning; Recurrent
   neural network; BLSTM
ID WORD RECOGNITION; COMPUTER VISION; KINEMATICS
AB Parkinson's disease is an escalating neurodegenerative disorder that adversely affects movement, muscle flexibility, speech, and writing skills. Early diagnosis can reduce its severity as well as the expenditure incurred for the treatment. Although several works exist using machine learning techniques to detect parkinson's disease, very few have focused to detect this disease by analyzing online handwritten tasks. This article proposes bi-directional long short-term memory [a variant of recurrent neural network (RNN)] based method to develop a parkinson's disease diagnosis system by analyzing online handwritten tasks. The aim of this work is twofold: (a) to find out the best task/tasks capable to discriminate between PD patient and healthy person and (b) to develop a robust method to detect the PD patient. Various kinematics features have been extracted from different handwritten tasks and the extracted features have been studied by three different machine learning techniques named support vector machine (SVM), adaboost classifier, and bagged random forest (BRF) as well as two different variants of deep learning model RNN known as long short-term memory (LSTM) and bi-directional long short-term memory (BLSTM). The parkinson's disease classification performance of the proposed method has been evaluated on a very popular publicly available dataset parkinsion disease handwriting database (PaHaW). The experimental results show that the proposed method outperforms the state-of-the-art methods in this regard.
C1 [Kumar, Kaushal; Ghosh, Rajib] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Ghosh, R (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, India.
EM rajib.ghosh@nitp.ac.in
RI GHOSH, RAJIB/C-9927-2017
OI GHOSH, RAJIB/0000-0002-8553-8656
CR Abdullah SM, 2023, IEEE ACCESS
   Ali L, 2019, IEEE ACCESS, V7, P116480, DOI 10.1109/ACCESS.2019.2932037
   Alissa M, 2022, NEURAL COMPUT, VAppl, P1
   Bidet-Ildei C, 2011, HUM MOVEMENT SCI, V30, P783, DOI 10.1016/j.humov.2010.08.008
   Burke RE, 2010, MOVEMENT DISORD, V25, pS76, DOI 10.1002/mds.22783
   de Lau LML, 2006, LANCET NEUROL, V5, P525, DOI 10.1016/S1474-4422(06)70471-9
   De Stefano C, 2019, PATTERN RECOGN LETT, V121, P37, DOI 10.1016/j.patrec.2018.05.013
   Derkinderen P, 2002, MOVEMENT DISORD, V17, P835, DOI 10.1002/mds.10189
   Diaz M, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114405
   Diaz M, 2019, PATTERN RECOGN LETT, V128, P204, DOI 10.1016/j.patrec.2019.08.018
   Drotár P, 2016, ARTIF INTELL MED, V67, P39, DOI 10.1016/j.artmed.2016.01.004
   Drotár P, 2015, IEEE T NEUR SYS REH, V23, P508, DOI 10.1109/TNSRE.2014.2359997
   Drotár P, 2014, COMPUT METH PROG BIO, V117, P405, DOI 10.1016/j.cmpb.2014.08.007
   Ghosh R, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114249
   Ghosh R, 2019, PATTERN RECOGN, V92, P203, DOI 10.1016/j.patcog.2019.03.030
   Ghosh R, 2018, INT J INF SYST MODEL, V9, P21, DOI 10.4018/IJISMD.2018010102
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Ho AK, 1998, BEHAV NEUROL, V11, P131, DOI 10.1155/1999/327643
   Jaeger S., 2001, International Journal on Document Analysis and Recognition, V3, P169, DOI 10.1007/PL00013559
   Johri A., 2019, 2019 Twelfth International Conference on Contemporary Computing (IC3), P1, DOI DOI 10.1109/IC3.2019.8844941
   Kingma D. P., 2014, arXiv
   Lange KW, 2006, HUM MOVEMENT SCI, V25, P492, DOI 10.1016/j.humov.2006.05.006
   Loconsole C, 2019, PATTERN RECOGN LETT, V121, P28, DOI 10.1016/j.patrec.2018.04.006
   Ma CB, 2022, EXPERT SYST APPL, V203, DOI 10.1016/j.eswa.2022.117400
   Moetesum M, 2019, PATTERN RECOGN LETT, V121, P19, DOI 10.1016/j.patrec.2018.04.008
   Mucha J, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122566
   Naseer A, 2020, NEURAL COMPUT APPL, V32, P839, DOI 10.1007/s00521-019-04069-0
   Pereira CR, 2016, COMPUT METH PROG BIO, V136, P79, DOI 10.1016/j.cmpb.2016.08.005
   Sakar BE, 2013, IEEE J BIOMED HEALTH, V17, P828, DOI 10.1109/JBHI.2013.2245674
   Shah P., 2018, 2018 4th International Conference on Computing Communication and Automation, ICCCA 2018, P1, DOI [DOI 10.23919/ICONAC.2018.8749023, 10.1109/CCAA.2018.8777602, DOI 10.1109/CCAA.2018.8777602]
   Toffoli S, 2023, FRONT NEUROL, V14, DOI 10.3389/fneur.2023.1093690
   TSENG MH, 1993, AM J OCCUP THER, V47, P919, DOI 10.5014/ajot.47.10.919
   Valla E, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103551
   von Campenhausen S, 2005, EUR NEUROPSYCHOPHARM, V15, P473, DOI 10.1016/j.euroneuro.2005.04.007
NR 34
TC 1
Z9 1
U1 11
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11687
EP 11715
DI 10.1007/s11042-023-15811-1
EA JUN 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019116600012
DA 2024-07-18
ER

PT J
AU Wang, SM
   Sun, BC
   Wang, YM
   Du, BX
AF Wang, Simiao
   Sun, Baichao
   Wang, Yiming
   Du, Baoxiang
TI Image encryption algorithm using multi-base diffusion and a new
   four-dimensional chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bit plane; Diffusion; 4D chaotic system; Image encryption
ID SCHEME; MAP; DECOMPOSITION; PROTECTION
AB Information security is very important in the era of rapid development of science and technology. People often use multimedia to communicate in their daily life. Image plays an important role in multimedia communication, so it is urgent to protect image information. In order to improve the security of images in transmission, an image encryption algorithm using multi-base diffusion and a new four-dimensional chaotic system is designed in this paper. The algorithm decomposes each pixel value into multi-based. After decomposition, the coefficient matrix and base matrix are scrambled by FYTS using the sequence generated by the new four-dimensional chaotic system, and finally recombined to perform pixel-level and bit-level scrambling respectively. After simulation with MATLAB, it is obvious that the final encrypted image does not have the contour of the original image, which meets the requirements of encryption. Through histogram, entropy analysis, anti-differential attack analysis and other experimental results, it is proved that the proposed algorithm has high security.
C1 [Wang, Simiao; Sun, Baichao; Wang, Yiming; Du, Baoxiang] Heilongjiang Univ, Elect Engn Coll, Harbin, Peoples R China.
C3 Heilongjiang University
RP Du, BX (corresponding author), Heilongjiang Univ, Elect Engn Coll, Harbin, Peoples R China.
EM dubaoxiang@hlju.edu.cn
RI Baoxiang, Du/ABF-5445-2021; Wang, Yiming/AAZ-4928-2021
OI Baoxiang, Du/0000-0001-6300-5907; Wang, Yiming/0000-0002-5588-8241
CR Askar SS, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21010044
   Broumandnia A, 2019, FUTURE GENER COMP SY, V99, P489, DOI 10.1016/j.future.2019.04.005
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chen LF, 2013, OPT COMMUN, V291, P98, DOI 10.1016/j.optcom.2012.10.080
   Cun QQ, 2021, OPTIK, V243, DOI 10.1016/j.ijleo.2021.167286
   Gao XH, 2021, OPT LASER TECHNOL, V142, DOI 10.1016/j.optlastec.2021.107252
   Girdhar A, 2018, MULTIMED TOOLS APPL, V77, P27017, DOI 10.1007/s11042-018-5902-z
   Gong LH, 2022, PHYSICA A, V591, DOI 10.1016/j.physa.2021.126793
   Hua ZY, 2019, IEEE T IND ELECTRON, V66, P1273, DOI 10.1109/TIE.2018.2833049
   Huang LQ, 2019, OPT LASER ENG, V115, P7, DOI 10.1016/j.optlaseng.2018.11.015
   Khalil N, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107326
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V160, P584, DOI 10.1016/j.procs.2019.11.043
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V160, P503, DOI 10.1016/j.procs.2019.11.057
   Kumar CM, 2022, APPL INTELL, V52, P2556, DOI 10.1007/s10489-021-02508-x
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Malik DS, 2020, MATH COMPUT SIMULAT, V178, P646, DOI 10.1016/j.matcom.2020.07.007
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Morris B, 2009, LECT NOTES COMPUT SC, V5677, P286, DOI 10.1007/978-3-642-03356-8_17
   Ni ZC, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P156, DOI 10.1109/SIPROCESS.2016.7888243
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Rakheja P, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106177
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Sang YP, 2022, PATTERN RECOGN LETT, V153, P59, DOI 10.1016/j.patrec.2021.11.025
   Shahna K, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106162
   Shifa A, 2018, IEEE ACCESS, V6, P16189, DOI 10.1109/ACCESS.2018.2815037
   Talhaoui MZ, 2021, INFORM SCIENCES, V550, P13, DOI 10.1016/j.ins.2020.10.048
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   ul Haq T, 2021, J INF SECUR APPL, V61, DOI 10.1016/j.jisa.2021.102931
   Wang SM, 2022, OPT LASER TECHNOL, V148, DOI 10.1016/j.optlastec.2021.107753
   Wang XY, 2022, OPTIK, V258, DOI 10.1016/j.ijleo.2022.168955
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wang XY, 2021, SENS IMAGING, V22, DOI 10.1007/s11220-021-00357-z
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Xiong Y, 2018, OPT LASER ENG, V101, P113, DOI 10.1016/j.optlaseng.2017.10.010
   Yang YG, 2021, INFORM SCIENCES, V580, P174, DOI 10.1016/j.ins.2021.08.073
   Yang YG, 2020, OPTIK, V213, DOI 10.1016/j.ijleo.2020.164422
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YP, 2009, IEEE SYS MAN CYBERN, P474, DOI 10.1109/ICSMC.2009.5346839
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
   Zhou WJ, 2022, OPT LASER ENG, V149, DOI 10.1016/j.optlaseng.2021.106782
   Zhu HG, 2022, MATH COMPUT SIMULAT, V198, P188, DOI 10.1016/j.matcom.2022.02.029
NR 43
TC 3
Z9 3
U1 5
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10039
EP 10060
DI 10.1007/s11042-023-16025-1
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001015589400002
DA 2024-07-18
ER

PT J
AU Khero, K
   Usman, M
   Fong, A
AF Khero, Kainat
   Usman, Muhammad
   Fong, Alvis
TI Deep learning framework for early detection of COVID-19 using X-ray
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Covid-19; Deep learning; Prediction; Transfer learning; Chest X-ray
ID FEATURES
AB The whole world is imposing efforts to combat the deadly COVID-19 virus that continues to have a disastrous effect on health, economy, education, transport & communication, and many other sectors. The crucial action taken to control its rapid spread is first to detect the infected person. Deep learning-based algorithms utilize mathematical models to detect Covid-19 cases. Deep learning approach is applied to track and diagnose Covid-19 and help radiologists and medical doctors enhance prognosis performance. X-ray images are popularly used deep learning methods for Covid-19 detection. However, the existing techniques suffer from several limitations that need to be addressed to detect Covid-19 cases more accurately: Firstly, there is a small number of Covid-19 images. Secondly, an unbalanced dataset. Thirdly, model overfitting, and fourthly, correct detection of Covid-19 and pneumonia cases sometimes does not provide accurate results because COVID-19 and pneumonia symptoms are similar. Therefore, this paper aimed to develop an automated solution to classify the detected Covid-19 into two classes to overcome the small and unbalanced dataset, and model overfitting problems. This study compared nine state-of-the-art CNN architectures through a transfer learning approach. Our approach achieved better results in comparison to the work done on this benchmark dataset yielding 99.86% accuracy with 99.9% recall using VGG-16 using deep learning model. The proposed framework presents a transfer learning technique to increase the performance of the deep learning-based Covid-19 detection method. Moreover, the Comparative evaluation presents that the proposed framework outperforms existing methods. Close results show that VGG-16 on a large dataset correctly identified COVID-19.
C1 [Khero, Kainat; Usman, Muhammad] Shaheed Zulfikar Ali Bhutto Inst Sci & Technol SZA, Dept Comp Sci, Islamabad Campus, St 09, Plot 67, Sect H-8-4, Islamabad, Pakistan.
   [Fong, Alvis] Western Michigan Univ, Dept Comp Sci, 1903 W Michigan Ave, Kalamazoo, MI 49008 USA.
C3 Western Michigan University
RP Fong, A (corresponding author), Western Michigan Univ, Dept Comp Sci, 1903 W Michigan Ave, Kalamazoo, MI 49008 USA.
EM dr.usman@szabist-isb.edu.pk; alvis.fong@wmich.edu
CR Alimadadi A, 2020, PHYSIOL GENOMICS, V52, P200, DOI 10.1152/physiolgenomics.00029.2020
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Barstugan M, 2020, ARXIV200309424
   Brunese L, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105608
   Carbonneau MA, 2018, PATTERN RECOGN, V77, P329, DOI 10.1016/j.patcog.2017.10.009
   Cohen JP, 2020, OPEN DATABASE COVID
   Farid A. A., 2020, Int. J. Sci. Eng. Res, V11, P82, DOI DOI 10.14299/IJSER.2020.03.02
   Ghoshal B., 2020, ARXIV200310769
   Gozes O, 2021, ARXIV
   Gunraj H, 2020, COVIDNET CT TAILORED, P1
   Hall L. O., 2020, arXiv, P8
   Han ZY, 2020, IEEE T MED IMAGING, V39, P2584, DOI 10.1109/TMI.2020.2996256
   Hasan Md Jahid, 2021, Proceedings of 2021 International Conference on Information and Communication Technology for Sustainable Development (ICICT4SD), P210, DOI 10.1109/ICICT4SD50815.2021.9396878
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Jia Wu, 2019, Journal of Electronic Science and Technology, V17, P26, DOI 10.11989/JEST.1674-862X.80904120
   Kassania SH, 2020, ARXIV PREPRINT ARXIV
   Liao LZ, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3506695
   Mooney P, 2020, Chest x-ray images (pneumonia)
   Narin A, 2021, PREPRINT
   Nour M, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106580
   Oh Y, 2020, IEEE T MED IMAGING, V39, P2688, DOI 10.1109/TMI.2020.2993291
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Saha Prottoy, 2021, Inform Med Unlocked, V22, P100505, DOI 10.1016/j.imu.2020.100505
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Singh D, 2020, EUR J CLIN MICROBIOL, V39, P1379, DOI 10.1007/s10096-020-03901-z
   Ucara F, 2020, JANUARY 2020 ELSEVIE
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   Yang L, 2020, NEUROCOMPUTING, V415, P295, DOI 10.1016/j.neucom.2020.07.061
   Zhong L, 2012, CORRELATION CHEST CT, V78, P1
   Zhou TF, 2023, MED IMAGE ANAL, V83, DOI 10.1016/j.media.2022.102599
NR 31
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6883
EP 6908
DI 10.1007/s11042-023-15995-6
EA JUN 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001010008600002
DA 2024-07-18
ER

PT J
AU Rani, P
   Dutta, K
   Kumar, V
AF Rani, Pooja
   Dutta, Kamlesh
   Kumar, Vijay
TI Performance evaluation of drug synergy datasets using computational
   intelligence approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Datasets; Drug synergy; Computational techniques; Prediction; Malignant
   diseases
ID SYSTEMATIC IDENTIFICATION; COMMUNITY EFFORT; CANCER; PREDICTION;
   SENSITIVITY; DATABASE; DISCOVERY; NETWORKS; RESOURCE; THERAPY
AB Drug synergy has become a promising approach for malignant diseases. This approach can increase therapeutic efficacy, reduce toxicity, and overcome drug resistance compared with single-drug administrations. Thus, it has attracted a lot of interest from researchers and pharmaceutical companies. It is critical for scholars interested in this field to be aware of relevant datasets to discern their findings and (i) understand how to use them (ii) instead of creating custom datasets, they can speed up their research by utilizing the pre-existing datasets. In this study, the combined activity of anticancer drugs are modelled with computational techniques random forest, linear regressor, decision tree, and adaBoost regressor. The drug pairs screening data from NCI-ALMANAC and Merck is used for training computational techniques. Using the root mean squared error (RMSE), mean absolute percentage error (MAPE), Pearson's correlation coefficient, and coefficient of determination (R2) for various computational intelligence techniques were analyzed. All these measures are used to understand the behaviour of the computational techniques and the characteristics of the datasets. The performance metric RMSE and MAPE focus on synergy score, whereas Pearson, R2 focuses on the feature set. The R2 metric is a good choice for the selection of computational technique. The analysis of computational techniques presented in this paper shows the promising direction in the study related to drug synergy using existing datasets which have been created by reliable and authenticated national cancer institute (NCI) and O'Neil study. By using computational techniques, researchers can shorten the delivery time for new drugs thereby saving money as well as time.
C1 [Rani, Pooja; Dutta, Kamlesh] Natl Inst Technol, Comp Sci & Engn Dept, Hamirpur 177005, HP, India.
   [Kumar, Vijay] Dr BR Ambedkar Natl Inst Technol Jalandhar, Informat Technol Dept, Jalandhar 144027, Punjab, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur; National Institute of Technology (NIT System); Dr B
   R Ambedkar National Institute of Technology Jalandhar
RP Kumar, V (corresponding author), Dr BR Ambedkar Natl Inst Technol Jalandhar, Informat Technol Dept, Jalandhar 144027, Punjab, India.
EM vijaykumarchahar@gmail.com
RI Rani, Pooja/JBR-8934-2023; Chahar, Vijay Kumar/A-2782-2015
OI Rani, Pooja/0000-0003-4783-7062; Chahar, Vijay Kumar/0000-0002-3460-6989
CR Al-Lazikani B, 2012, NAT BIOTECHNOL, V30, P679, DOI 10.1038/nbt.2284
   [Anonymous], 2022, CANC SUMM DAT VIS
   [Anonymous], 2020, SIRUR S
   [Anonymous], 2022, Cancer
   Athar A, 2019, NUCLEIC ACIDS RES, V47, pD711, DOI 10.1093/nar/gky964
   Bajorath F, 2002, NAT REV DRUG DISCOV, V1, P882, DOI 10.1038/nrd941
   Barretina J, 2012, NATURE, V483, P603, DOI 10.1038/nature11003
   Berahmand K, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104933
   Bisong E., 2019, Building Machine Learning and Deep Learning Models on Google Cloud Platform
   Bleicher KH, 2003, NAT REV DRUG DISCOV, V2, P369, DOI 10.1038/nrd1086
   Bliss CI, 1939, ANN APPL BIOL, V26, P585, DOI 10.1111/j.1744-7348.1939.tb06990.x
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chandrasekaran B, 2018, ADV PHARM PROD DEVL, P731, DOI 10.1016/B978-0-12-814421-3.00021-X
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen X, 2002, NUCLEIC ACIDS RES, V30, P412, DOI 10.1093/nar/30.1.412
   Chen X, 2016, BRIEF BIOINFORM, V17, P696, DOI 10.1093/bib/bbv066
   Chen X, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086499
   Correia AS, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e05948
   Costello JC, 2014, NAT BIOTECHNOL, V32, P1202, DOI 10.1038/nbt.2877
   Csermely P, 2005, TRENDS PHARMACOL SCI, V26, P178, DOI 10.1016/j.tips.2005.02.007
   David L, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-00460-5
   Day D, 2016, GENOME MED, V8, DOI 10.1186/s13073-016-0369-x
   ElHami A, 2020, MODELING SIMULATION, V2
   Friedman AA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140310
   Garnett MJ, 2012, NATURE, V483, P570, DOI 10.1038/nature11005
   Gaulton A, 2017, NUCLEIC ACIDS RES, V45, pD945, DOI 10.1093/nar/gkw1074
   Greshock J, 2010, CANCER RES, V70, P3677, DOI 10.1158/0008-5472.CAN-09-3788
   He LY, 2018, METHODS MOL BIOL, V1711, P351, DOI 10.1007/978-1-4939-7493-1_17
   Hecker N, 2012, NUCLEIC ACIDS RES, V40, pD1113, DOI 10.1093/nar/gkr912
   Holbeck SL, 2017, CANCER RES, V77, P3564, DOI 10.1158/0008-5472.CAN-17-0489
   Iadevaia S, 2010, CANCER RES, V70, P6704, DOI 10.1158/0008-5472.CAN-10-0460
   Ianevski A, 2019, NAT MACH INTELL, V1, P568, DOI 10.1038/s42256-019-0122-4
   Ianevski A, 2017, BIOINFORMATICS, V33, P2413, DOI 10.1093/bioinformatics/btx162
   Iorio F, 2016, CELL, V166, P740, DOI 10.1016/j.cell.2016.06.017
   Irwin JJ, 2012, J CHEM INF MODEL, V52, P1757, DOI 10.1021/ci3001277
   Jarada TN, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106585
   Jia J, 2009, NAT REV DRUG DISCOV, V8, P111, DOI 10.1038/nrd2683
   Jiang PR, 2020, COMPUT STRUCT BIOTEC, V18, P427, DOI 10.1016/j.csbj.2020.02.006
   Kaur J, 2019, INT J ADV COMPUT SC, V10, P601
   Kaur M, 2021, CURR PHARM DESIGN, V27, P1103, DOI 10.2174/1381612826666201106090938
   Kim N, 2014, INT J ONCOL, V44, P371, DOI 10.3892/ijo.2013.2202
   Kim Sunghwan, 2019, Nucleic Acids Res, V47, pD1102, DOI 10.1093/nar/gky1033
   Kim Y, 2021, J AM MED INFORM ASSN, V28, P42, DOI 10.1093/jamia/ocaa212
   Kolesnikov N, 2015, NUCLEIC ACIDS RES, V43, pD1113, DOI 10.1093/nar/gku1057
   Kuenzi BM, 2020, CANCER CELL, V38, P672, DOI 10.1016/j.ccell.2020.09.014
   Kuru HI, 2021, IEEE ACM T COMPUTATI
   Licciardello MP, 2017, NAT CHEM BIOL, V13, P771, DOI 10.1038/nchembio.2382
   Liu H, 2020, NUCLEIC ACIDS RES, V48, pD871, DOI 10.1093/nar/gkz1007
   Liu Q, 2021, PLOS COMPUT BIOL, V17, DOI 10.1371/journal.pcbi.1008653
   Liu TQ, 2007, NUCLEIC ACIDS RES, V35, pD198, DOI 10.1093/nar/gkl999
   Liu YB, 2014, DATABASE-OXFORD, DOI 10.1093/database/bau124
   LOEWE S, 1953, ARZNEIMITTEL-FORSCH, V3, P285
   Ma J, 2021, BMC MED GENOMICS, V14, DOI 10.1186/s12920-021-00905-2
   Magariños MP, 2012, NUCLEIC ACIDS RES, V40, pD1118, DOI 10.1093/nar/gkr1053
   Mauri A., 2016, HDB COMPUTATIONAL CH, V2, P2065
   Mauri A, 2006, MATCH-COMMUN MATH CO, V56, P237
   Mayr A, 2016, FRONT ENV SCI-SWITZ, V3, DOI 10.3389/fenvs.2015.00080
   Menden MP, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-09799-2
   Morris MK, 2016, CPT-PHARMACOMET SYST, V5, P544, DOI 10.1002/psp4.12104
   Nadimi-Shahraki MH, 2022, COMPUT BIOL MED, V148, DOI 10.1016/j.compbiomed.2022.105858
   O'Neil J, 2016, MOL CANCER THER, V15, P1155, DOI 10.1158/1535-7163.MCT-15-0843
   Pang KF, 2014, BIOINFORMATICS, V30, P1456, DOI 10.1093/bioinformatics/btu046
   Patterson JC, 2019, CELL SYST, V9, P74, DOI 10.1016/j.cels.2019.05.009
   Peri S, 2003, GENOME RES, V13, P2363, DOI 10.1101/gr.1680803
   Prasad TSK, 2009, NUCLEIC ACIDS RES, V37, pD767, DOI 10.1093/nar/gkn892
   Preto AJ, 2021, SYNPRED PREDICTION D
   Preuer K, 2018, BIOINFORMATICS, V34, P1538, DOI 10.1093/bioinformatics/btx806
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Saberi-Movahed F, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105426
   Seashore-Ludlow B, 2015, CANCER DISCOV, V5, P1210, DOI 10.1158/2159-8290.CD-15-0235
   Seo H, 2020, NUCLEIC ACIDS RES, V48, pW494, DOI 10.1093/nar/gkaa421
   Shim Y, 2022, BMC BIOINFORMATICS, V23, DOI 10.1186/s12859-022-04698-8
   Shoemaker RH, 2006, NAT REV CANCER, V6, P813, DOI 10.1038/nrc1951
   Sidorov P, 2019, FRONT CHEM, V7, DOI 10.3389/fchem.2019.00509
   Sun ZX, 2020, BIOINFORMATICS, V36, P4483, DOI 10.1093/bioinformatics/btaa287
   Swamidass P.M., 2000, Encyclopedia of Production and Manufacturing Management, P462, DOI [DOI 10.1007/1-4020-0612-8_580, 10.1007/1-4020-0612-8_580]
   Szklarczyk D, 2016, NUCLEIC ACIDS RES, V44, pD380, DOI 10.1093/nar/gkv1277
   Tan X, 2012, NAT BIOTECHNOL, V30, P1125, DOI 10.1038/nbt.2391
   Tang J, 2018, CELL CHEM BIOL, V25, P224, DOI 10.1016/j.chembiol.2017.11.009
   Tang J, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003226
   Tate JG, 2019, NUCLEIC ACIDS RES, V47, pD941, DOI 10.1093/nar/gky1015
   Wali VB, 2017, CANCER RES, V77, P566, DOI 10.1158/0008-5472.CAN-16-1901
   Wang JX, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab390
   White RE, 2000, ANNU REV PHARMACOL, V40, P133, DOI 10.1146/annurev.pharmtox.40.1.133
   Wilks C, 2014, DATABASE-OXFORD, DOI 10.1093/database/bau093
   Wishart DS, 2018, NUCLEIC ACIDS RES, V46, pD608, DOI 10.1093/nar/gkx1089
   Wu LL, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab355
   Yadav B, 2015, COMPUT STRUCT BIOTEC, V13, P504, DOI 10.1016/j.csbj.2015.09.001
   Yang WJ, 2013, NUCLEIC ACIDS RES, V41, pD955, DOI 10.1093/nar/gks1111
   Yang YD, 2015, GENOM PROTEOM BIOINF, V13, P46, DOI 10.1016/j.gpb.2015.01.005
   Zeeberg BR, 2012, CONCORDANCE GENE EXP
   Zhang H, 2021, bioRxiv
   Zhang Tianyu, 2021, Methods Mol Biol, V2194, P223, DOI 10.1007/978-1-0716-0849-4_12
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
   ZUBROD CG, 1984, CANCER TREAT REP, V68, P9
NR 95
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8971
EP 8997
DI 10.1007/s11042-023-15723-0
EA JUN 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001014975000010
DA 2024-07-18
ER

PT J
AU Zhu, XZ
   Xiang, GQ
   Zhang, P
   Xie, XD
AF Zhu, Xizhong
   Xiang, Guoqing
   Zhang, Peng
   Xie, Xiaodong
TI A hardware-friendly algorithm for LCU-level pipe-lined integer motion
   estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video coding; Integer motion estimation; Hardware-friendly; Data
   dependency; Pipeline; AVS3
ID SEARCH ALGORITHM; ARCHITECTURE
AB The latest video coding standards such as AVS3 adopts numerous novel coding tools and new partition mechanisms to achieve a better coding performance. But they also massively increase the computation overhead. Integer motion estimation (IME) is one of the most important and complex coding tools. The growing complexity of these video coding standards brings up severe challenges for both software and hardware implemented IME. Different from the software oriented IME algorithms, hardware-friendly IME algorithms often require low data dependency, regular data access and reasonable trade-off among compression performance, latency and resources. The challenges also highly relate to the hardware encoder architecture applying the IME algorithm. We propose a novel hardware-friendly integer motion estimation algorithm for AVS3 targeted for the Largest Coding Unit (LCU) level pipe-lined encoder architectures. The proposed algorithm consists of three parts, namely, a predictive motion vector prediction (PMVP) algorithm to derive predictive motion vectors (PMV) in advance to avoid the data dependency, a multi-resolution hierarchical motion estimation method that generates motion vectors (MVs) for 60% of the divided coding units (CUs) and a motion vector inference (MVI) method to infer MVs for the rest of the CUs. The proposed algorithms reduce the computation complexity by 88.64% for IME and only suffers 0.11% performance degradation for the IPPP configuration.
C1 [Zhu, Xizhong; Xiang, Guoqing; Xie, Xiaodong] Peking Univ, Sch Comp Sci, Beijing, Peoples R China.
   [Zhu, Xizhong; Xiang, Guoqing; Zhang, Peng] Peking Univ, Adv Inst Informat Technol, Hangzhou, Peoples R China.
C3 Peking University; Peking University
RP Zhu, XZ (corresponding author), Peking Univ, Sch Comp Sci, Beijing, Peoples R China.; Zhu, XZ (corresponding author), Peking Univ, Adv Inst Informat Technol, Hangzhou, Peoples R China.
EM zhuxizhong@pku.edu.cn; gqxiang@pku.edu.cn; pzhang@aiit.org.cn;
   donxie@pku.edu.cn
OI Zhu, Xizhong/0000-0002-7618-346X
CR Bao XN, 2012, IEEE T MULTIMEDIA, V14, P237, DOI 10.1109/TMM.2011.2171677
   Fan YB, 2018, IEEE T CIRC SYST VID, V28, P2048, DOI 10.1109/TCSVT.2017.2702194
   Gogoi S, 2021, IEEE T CONSUM ELECTR, V67, P319, DOI 10.1109/TCE.2021.3126670
   He ZC, 2013, IEEE IMAGE PROC, P1515, DOI 10.1109/ICIP.2013.6738311
   Jia LH, 2019, IEEE T MULTIMEDIA, V21, P835, DOI 10.1109/TMM.2018.2866762
   Jie C, 2021, N2983 AVS
   Kim TS, 2020, IEEE T CIRC SYST VID, V30, P1732, DOI 10.1109/TCSVT.2019.2909693
   Lai Y-K, 2019, I SYMP CONSUM ELECTR, P1, DOI [10.1109/ICCE.2019.8661956, DOI 10.1109/icce.2019.8661956]
   Lee D, 2018, PROC INT WORKSH ADV
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Mochizuki S, 2008, IEEE J SOLID-ST CIRC, V43, P2354, DOI 10.1109/JSSC.2008.2004534
   Ndili O, 2014, J SIGNAL PROCESS SYS, V75, P55, DOI 10.1007/s11265-013-0793-8
   Thang NV, 2019, PROCEEDINGS OF 2019 6TH NATIONAL FOUNDATION FOR SCIENCE AND TECHNOLOGY DEVELOPMENT (NAFOSTED) CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), P160, DOI [10.1109/nics48868.2019.9023823, 10.1109/NICS48868.2019.9023823]
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Qian Liu, 2018, 2018 IEEE 4th International Conference on Computer and Communications (ICCC). Proceedings, P6, DOI 10.1109/CompComm.2018.8780609
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tsai S-F, 2013, 2013 S VLSIC, P188
   Vayalil NC, 2019, IEEE T CIRC SYST VID, V29, P572, DOI 10.1109/TCSVT.2017.2787194
   Wang M, 2019, IEEE DATA COMPR CONF, P300, DOI 10.1109/DCC.2019.00038
   Wei KJ, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P373, DOI 10.1109/PCS.2012.6213368
   Yin HB, 2010, IEEE T CIRC SYST VID, V20, P1242, DOI 10.1109/TCSVT.2010.2058476
   Zhang J, 2019, PICT COD SYMP, DOI 10.1109/pcs48520.2019.8954503
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu S, 1997, ICICS - PROCEEDINGS OF 1997 INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING, VOLS 1-3, P292, DOI 10.1109/ICICS.1997.647106
NR 24
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6685
EP 6709
DI 10.1007/s11042-023-15669-3
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001010465000007
DA 2024-07-18
ER

PT J
AU Deng, HX
   Luo, DS
   Zhou, ZJ
   Hou, JX
   Qian, GY
   Li, HF
AF Deng, Hongxia
   Luo, Dongsheng
   Zhou, Zijing
   Hou, Jinxiu
   Qian, Guanyu
   Li, Haifang
TI Leaf disease recognition based on channel information attention network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Identification of leaf disease; Channel information attention network;
   Model fusion; CNN
AB Aiming at the problem of the variety of plant leaf diseases and how to extract effective features, an attention network model fused with channel information is proposed to identify a variety of plant leaf diseases. Firstly, a residual structure based basic network is built for feature extraction, and in order to extract effective information, the feature is re-calibrated by integrating multiple channel information through the attention network. Then, the constraint information is added into the cross entropy function to accelerate the convergence of the model. Finally, the model is tested on the data sets of 16 diseases of four different plants. The results show that the recognition accuracy of the basic network model is 83.13%, while the accuracy increased by 4.64% after fusing the channel information network. Compared with other models, the fusion model improves the recognition accuracy by 9.72% and the model complexity is less than twice that of the optimal model in the comparison experiment.
C1 [Deng, Hongxia; Luo, Dongsheng; Hou, Jinxiu; Qian, Guanyu; Li, Haifang] Taiyuan Univ Technol, Dept Informat & Comp, 209 Univ St, Jinzhon 030600, Peoples R China.
   [Zhou, Zijing] Taiyuan Univ Technol, Dept Software, 209, Univ St, Jinzhon 030600, Peoples R China.
C3 Taiyuan University of Technology; Taiyuan University of Technology
RP Deng, HX (corresponding author), Taiyuan Univ Technol, Dept Informat & Comp, 209 Univ St, Jinzhon 030600, Peoples R China.
EM denghongxia@tyut.edu.cn; luodongsheng0369@link.tyut.edu.cn;
   2361553935@qq.com; 1096487173@qq.com; 695875187@qq.com;
   lihaifang@tyut.edu.cn
OI Hongxia, Deng/0000-0001-9738-1310
FU National Natural Science Foundation of China [61976150]; Key Research
   and Development Projects of Shanxi Province [Y192006]; Key R & D
   projects in Jinzhong City, China [YDZJSX2021C005]; Central Guidance on
   Local Science and Technology Development Fund of Shanxi; Shanxi
   Provincial Central Guide local Science and technology development fund
   project [YDZJSX2022A016, A2221]; CAD & CG State Key Laboratory of
   Zhejiang University [61873178];  [201803D31038]
FX This study was supported by research grants from the National Natural
   Science Foundation of China(61873178,61976150), Key Research and
   Development Projects of Shanxi Province(201803D31038), Key R & D
   projects in Jinzhong City, China grant number Y192006, the Central
   Guidance on Local Science and Technology Development Fund of Shanxi.
   Shanxi Provincial Central Guide local Science and technology development
   fund project (YDZJSX2021C005,YDZJSX2022A016). The open project of CAD &
   CG State Key Laboratory of Zhejiang University in 2022 (A2221).
CR Al Bashish Dheeb, 2011, Information Technology Journal, V10, P267, DOI 10.3923/itj.2011.267.275
   Arivazhagan S., 2013, Agricultural Engineering International: CIGR Journal, V15, P211
   Ashwini K, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.670352
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Chaudhari S., 2019, ARXIV
   Chorowski J, 2015, ADV NEUR IN, V28
   Cui YM, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P593, DOI 10.18653/v1/P17-1055
   Fang C., 2020, COMPUTER APPL, V40, P203
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He X, 2020, COMPUT ENG, P1000
   Hou Q., 2021, ARXIV
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Joseph I A, 2019, INT S INT COMP APPL, P360, DOI [10.1109/ICIIECS.2017.8275951, DOI 10.1109/ICIIECS.2017.8275951]
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Kim S, 2017, INT CONF ACOUST SPEE, P4835, DOI 10.1109/ICASSP.2017.7953075
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lee SH, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.601250
   Li GL, 2012, IFIP ADV INF COMM TE, V370, P151
   Li J., 2015, RES AUTOMATIC IDENTI
   Liu Y., 2021, ARXIV
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Lv MJ, 2020, IEEE ACCESS, V8, P57952, DOI 10.1109/ACCESS.2020.2982443
   Ma W, 2019, P 23 C COMPUTATIONAL, DOI [10.18653/v1/k19-1069, DOI 10.18653/V1/K19-1069]
   Miaomiao Ji, 2020, Information Processing in Agriculture, V7, P418, DOI 10.1016/j.inpa.2019.10.003
   Mnih V, 2014, ADV NEUR IN, V27
   Mokhtar U, 2015, ADV INTELL SYST, V323, P641, DOI 10.1007/978-3-319-11310-4_55
   Abirami RN, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5541134
   Pallagani V, 2019, 2019 IEEE INTERNATIONAL SYMPOSIUM ON SMART ELECTRONIC SYSTEMS (ISES 2019), P29, DOI 10.1109/iSES47678.2019.00020
   Patil J.K., 2017, Engineering in agriculture, environment and food, V10, P69
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Saleem MH, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9101319
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Srinivasan K, 2021, CMC-COMPUT MATER CON, V68, P4109, DOI 10.32604/cmc.2021.016736
   Vaswani A, 2017, ADV NEUR IN, V30
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 40
TC 0
Z9 0
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6601
EP 6619
DI 10.1007/s11042-023-15512-9
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001006598900009
DA 2024-07-18
ER

PT J
AU Gamel, SA
   Hassan, E
   El-Rashidy, N
   Talaat, FM
AF Gamel, Samah A.
   Hassan, Esraa
   El-Rashidy, Nora
   Talaat, Fatma M.
TI Exploring the effects of pandemics on transportation through
   correlations and deep learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Prediction; Deep Learning (DL); COVID-19; Convolutional Neural Network
   (CNN)
ID COVID-19; LOCKDOWN
AB The COVID-19 pandemic has had a significant impact on human migration worldwide, affecting transportation patterns in cities. Many cities have issued "stay-at-home" orders during the outbreak, causing commuters to change their usual modes of transportation. For example, some transit/bus passengers have switched to driving or car-sharing. As a result, urban traffic congestion patterns have changed dramatically, and understanding these changes is crucial for effective emergency traffic management and control efforts. While previous studies have focused on natural disasters or major accidents, only a few have examined pandemic-related traffic congestion patterns. This paper uses correlations and machine learning techniques to analyze the relationship between COVID-19 and transportation. The authors simulated traffic models for five different networks and proposed a Traffic Prediction Technique (TPT), which includes an Impact Calculation Methodology that uses Pearson's Correlation Coefficient and Linear Regression, as well as a Traffic Prediction Module (TPM). The paper's main contribution is the introduction of the TPM, which uses Convolutional Neural Network to predict the impact of COVID-19 on transportation. The results indicate a strong correlation between the spread of COVID-19 and transportation patterns, and the CNN has a high accuracy rate in predicting these impacts.
C1 [Gamel, Samah A.] Horus Univ, Fac Engn, Dumyat, Egypt.
   [Hassan, Esraa; El-Rashidy, Nora; Talaat, Fatma M.] Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh, Egypt.
C3 Egyptian Knowledge Bank (EKB); Kafrelsheikh University
RP Gamel, SA (corresponding author), Horus Univ, Fac Engn, Dumyat, Egypt.; Talaat, FM (corresponding author), Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh, Egypt.
EM s.adel.gamel@gmail.com; fatma.nada@ai.kfs.edu.eg
RI M. Talaat, Fatma/IYS-7614-2023; Adel Gamel, Samah/AAZ-9335-2021; El
   Rashidy, Nora/GRJ-8142-2022
OI Adel Gamel, Samah/0000-0003-1753-030X; El Rashidy,
   Nora/0000-0001-8177-9439; M. Talaat, Fatma/0000-0001-6116-2191
FU Science, Technology & Innovation Funding Authority (STDF)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Albawi S, 2017, I C ENG TECHNOL
   Alshathri S, 2022, CMC-COMPUT MATER CON, V73, P5863, DOI 10.32604/cmc.2022.026547
   Arimura M, 2020, TRANSP RES INTERDISC, V7, DOI 10.1016/j.trip.2020.100212
   Chinazzi M, 2020, SCIENCE, V368, P395, DOI [10.1126/science.aba9757, 10.1101/2020.02.09.20021261]
   Chung Y, 2012, TRANSPORT POLICY, V19, P167, DOI 10.1016/j.tranpol.2011.10.001
   de Haas M, 2020, TRANSP RES INTERDISC, V6, DOI 10.1016/j.trip.2020.100150
   Engle S., 2020, Staying at home: mobility effects of COVID-19, DOI DOI 10.2139/SSRN.3565703
   FORBES, 2020, FORBES
   Gamel SA, 2022, NEURAL COMPUT APPL, P1
   Gan T, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9120715
   Google, 2020, COMMN MOB REP
   Hara Y, 2015, TRANSPORT RES A-POL, V75, P1, DOI 10.1016/j.tra.2015.03.002
   Hassan E, 2022, Review: Mask R-CNN Models, DOI [10.21608/njccs.2022.280047, DOI 10.21608/NJCCS.2022.280047]
   Hu XB, 2019, J INTELL TRANSPORT S, V23, P133, DOI 10.1080/15472450.2018.1488133
   Huang JZ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3443, DOI 10.1145/3394486.3412856
   Ikidid, 2021, MULTIAGENT FUZZY INF
   Jie Li, 2014, International Efforts in Lifeline Earthquake Engineering. Sixth China-Japan-US Trilateral Symposium on Lifeline Earthquake Engineering. Proceedings, P1
   Khater Hatem A., 2015, International Journal of Engineering Inventions, V5, P14
   Li J, 2021, INT J TRANSP SCI TEC, V10, P212, DOI 10.1016/j.ijtst.2021.03.001
   Li J, 2015, NAT HAZARDS, V78, P2081, DOI 10.1007/s11069-015-1820-9
   Mostafa MZ, 2019, IET RADAR SONAR NAV, V13, P1616, DOI 10.1049/iet-rsn.2019.0015
   MS2, 2020, DAIL TRAFF VOL TREND
   Murray-Tuite P, 2013, TRANSPORT RES C-EMER, V27, P25, DOI 10.1016/j.trc.2012.11.005
   Neuburger L, 2021, CURR ISSUES TOUR, V24, P1003, DOI 10.1080/13683500.2020.1803807
   Oum TH, 2020, TRANSPORT POLICY, V96, P94, DOI 10.1016/j.tranpol.2020.07.003
   Prada J, 2021, INT J INTERACT MULTI, V6, P7, DOI 10.9781/ijimai.2021.04.001
   Siam AI, 2023, NEURAL COMPUT APPL, V35, P12891, DOI 10.1007/s00521-023-08428-w
   Silva F, 2014, INT J INTERACT MULTI, V3, P20, DOI 10.9781/ijimai.2014.313
   Talaat Fatma M., 2023, Journal of Ambient Intelligence and Humanized Computing, P8499, DOI 10.1007/s12652-022-03882-1
   Talaat FM, 2022, MULTIMED TOOLS APPL, V81, P39945, DOI 10.1007/s11042-022-13000-0
   Talaat FM, 2022, MULTIMED TOOLS APPL, V81, P8235, DOI 10.1007/s11042-022-12223-5
   Talaat FM, 2020, CLUSTER COMPUT, V23, P3309, DOI 10.1007/s10586-020-03089-z
   Talaat FM, 2020, J AMB INTEL HUM COMP, V11, P4951, DOI 10.1007/s12652-020-01768-8
   Tian HY, 2020, SCIENCE, V368, P638, DOI 10.1126/science.abb6105
NR 34
TC 11
Z9 11
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7295
EP 7316
DI 10.1007/s11042-023-15803-1
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001004157400005
PM 37362732
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Mahboob, A
   Siddique, I
   Asif, M
   Nadeem, M
   Saleem, A
AF Mahboob, Abid
   Siddique, Imran
   Asif, Muhammad
   Nadeem, Muhammad
   Saleem, Aysha
TI Construction of highly non linear component of block cipher based on
   mclaurin series and mellin transformation with application in image
   encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block Cipher; Substitution box; McLaurin series; Mellin transformation;
   Symmetric group S-n
ID DESIGN; BOXES
AB A substitution box (S-box) in data encryption is a non-linear tool that conducts substitution to assure the overall security of the system. S-box is the most important part of the block cipher. The non-linearity trait is critical for the construction of more reliable substitution boxes in data encryption. As a result, new approaches for generating high no n-linear S-boxes are required. Using the Mellin transformation and the McLaurin series, this work suggests an approach for creating Substitution boxes with a high non-linearity value of 112.5. S-box construction consists of three phases. In step 1, we build a sequence from a function's McLaurin series and then apply Mellin transformation to the sequence's terms without substituting limits. In the second phase, we solved all of the coefficients under mod 257, and in the third step, we improved the unpredictability of the initial S-box by using a particular permutation of Symmetric group S-256 . Furthermore, the algebraic characteristics of S-box are evaluated using various tests, including non-linearity (NL), Bit Independent Criterion (BIC), Strict Avalanche Criterion (SAC), Linear Approximation Probability (LAP), and Differential Uniformity (DU), all of which certify the algebraic properties of the S-box.
C1 [Mahboob, Abid] Univ Educ, Dept Math, Div Sci & Technol, Lahore, Pakistan.
   [Siddique, Imran] Univ Management & Technol, Dept Math, Lahore 54770, Pakistan.
   [Asif, Muhammad] Univ Management & Technol, Dept Math, Sialkot Campus, Sialkot, Pakistan.
   [Nadeem, Muhammad; Saleem, Aysha] Univ Educ, Dept Math, Vehari Campus, Vehari, Pakistan.
C3 University of Management & Technology (UMT); University of Management &
   Technology (UMT)
RP Siddique, I (corresponding author), Univ Management & Technol, Dept Math, Lahore 54770, Pakistan.
EM abid.mahboob@ue.edu.pk; imransmsrazi@gmail.com;
   muhammad.asif@math.qau.edu.pk; muhammadnadeem4464647@gmail.com;
   ayeshasaleemch@gmail.com
RI Nadeem, Muhammad/HOC-6185-2023
OI Asif, Muhammad/0000-0001-5684-4737
CR Abd El-Latif AA, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58636-w
   Abramowitz M., 1964, Handbook of mathematical functions with formulas, graphs, and mathematical tables, V55, DOI DOI 10.1119/1.15378
   Ahmad M, 2020, IEEE ACCESS, V8, P116132, DOI 10.1109/ACCESS.2020.3004449
   Alanazi AS, 2021, IEEE ACCESS, V9, P93795, DOI 10.1109/ACCESS.2021.3092512
   Alhadawi HS, 2021, MULTIMED TOOLS APPL, V80, P7333, DOI 10.1007/s11042-020-10048-8
   Alshammari BM, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13010129
   Asif M, 2019, J INTELL FUZZY SYST, V37, P3925, DOI 10.3233/JIFS-190137
   Asif Muhammad, 2021, COMPUTATIONAL INTELL
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Ben Farah MA, 2020, MULTIMED TOOLS APPL, V79, P19129, DOI 10.1007/s11042-020-08718-8
   Bhanot R, 2015, INT J SECUR APPL, V9, P289, DOI 10.14257/ijsia.2015.9.4.27
   Bhatti S., 2020, PAKISTAN J MULTIDISC, V1, P259
   Daemen J., 1999, AES proposal: Rijndael
   Daemen J., 2002, DESIGN RIJNDAEL, V1, P1
   debnath Lokenath, 2016, INTEGRAL TRANSFORMS, P19
   Faheem ZB, 2020, ETRI J, P1
   Feng D, 2000, DESIGN ANAL BLOCK CI
   Firdousi F, 2019, INT J THEOR PHYS, V58, P3871, DOI 10.1007/s10773-019-04254-w
   Gao W, 2020, IEEE ACCESS
   Hussain I, 2011, WORLD APPL SCI J, V13, P2389
   Hussain I, 2013, NEURAL COMPUT APPL, V23, P97, DOI 10.1007/s00521-012-0914-5
   Hussain S, 2020, IEEE ACCESS, V8, P123492, DOI 10.1109/ACCESS.2020.3005087
   Kazlauskas K, 2009, INFORMATICA-LITHUAN, V20, P23
   Lambic D, 2020, NONLINEAR DYNAM, V100, P699, DOI 10.1007/s11071-020-05503-y
   Liu HJ, 2020, APPL MATH COMPUT, V376, DOI 10.1016/j.amc.2020.125153
   Lu Q, 2020, IEEE ACCESS, V8, P25664, DOI 10.1109/ACCESS.2020.2970806
   Mar P.P., 2008, World Acad. Sci. Eng. Technol, V48, P25
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   Patro KAK, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102470
   PIEPRZYK J, 1988, IEE PROC-E, V135, P325, DOI 10.1049/ip-e.1988.0044
   Pub F., 1999, FIPS PUB, P46
   Saha M., 2017, RAI J TECHNOLOGY RES, V5, P12
   Santana YC, 2014, ARXIV
   Shafique A, 2020, EUR PHYS J PLUS, V135, DOI 10.1140/epjp/s13360-020-00187-0
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Siddiqui N, 2020, IEEE ACCESS, V8, P197630, DOI 10.1109/ACCESS.2020.3034832
   Siddiqui N, 2021, WIRELESS PERS COMMUN, V116, P3015, DOI 10.1007/s11277-020-07832-y
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Ye Tian, 2017, Mathematical Problems in Engineering, V2017, DOI 10.1155/2017/6969312
   Zahid AH, 2020, IEEE ACCESS, V8, P150326, DOI 10.1109/ACCESS.2020.3016401
   Zhang T, 2018, IEEE T CYBERNETICS, V48, P3349, DOI 10.1109/TCYB.2018.2846186
   Zhang YQ, 2020, IEEE ACCESS, V8, P54175, DOI 10.1109/ACCESS.2020.2979827
   Zhu D, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12122087
NR 44
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7159
EP 7177
DI 10.1007/s11042-023-15965-y
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003562600011
DA 2024-07-18
ER

PT J
AU Javan, AAK
   Zare, A
   Mosavi, A
AF Javan, Ali Akbar Kekha
   Zare, Assef
   Mosavi, Amir
TI Images encryption based on robust multi-mode finite time synchronization
   of fractional-order hyper-chaotic Rikitake systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-mode synchronization; Robust finite time; Fractional order
   hyper-chaotic system; Lyapunov stability; Secure communication
ID COMBINATION SYNCHRONIZATION; CIRCUIT REALIZATION; COMMUNICATION;
   UNCERTAINTIES; MANAGEMENT; NETWORKS
AB The main goal of this paper is to design a finite time multiple synchronization controller for fractional order hyper chaotic Rikitate systems. In this article, systems are considered with unknown delays and unknown parameters and synchronization is performed in the presence of disturbance and uncertainty. In the proposed method, adaptive rules for estimating unknown parameters, disturbance bounds and uncertainties as well as control efforts for synchronization in finite time are obtained with the help of Lyapunov's stability theorem. Synchronization errors have converged to zero in finite time. Also, the encryption performance of images and their transmission was investigated based on the proposed multi-mode synchronization algorithm. Additionally, the histogram diagram of several encrypted images was shown based on the synchronization techniques of the fractional-order Rikitake system. A number of statistical parameters including histogram, correlation, NPCR, UACI, PSNR, and information entropy were calculated for the encrypted images in order to indicate the performance and compare the two proposed synchronization methods. Finally, satisfactory results in different image encryption were achieved based on the synchronization technique of the fractional-order Rikitake chaotic system.
C1 [Javan, Ali Akbar Kekha] Islamic Azad Univ, Zabol Branch, Fac Elect Engn, Zabol, Iran.
   [Zare, Assef] Islamic Azad Univ, Gonabad Branch, Fac Elect Engn, Gonabad, Iran.
   [Zare, Assef] Islamic Azad Univ, Gonabad Branch, Res Ctr Intelligent Technol Elect Ind RCITEI, Gonabad, Iran.
   [Mosavi, Amir] Obuda Univ, KandoKalman Fac Elect Engn, Inst Automat, H-1034 Budapest, Hungary.
   [Mosavi, Amir] Norwegian Univ Life Sci, Sch Econ & Business, N-1430 As, Norway.
   [Mosavi, Amir] J Selye Univ, Dept Informat, Komarno 94501, Slovakia.
C3 Islamic Azad University; Islamic Azad University; Islamic Azad
   University; Obuda University; Norwegian University of Life Sciences; J.
   Selye University
RP Zare, A (corresponding author), Islamic Azad Univ, Gonabad Branch, Fac Elect Engn, Gonabad, Iran.; Zare, A (corresponding author), Islamic Azad Univ, Gonabad Branch, Res Ctr Intelligent Technol Elect Ind RCITEI, Gonabad, Iran.
EM assefzare@gmail.com
RI Zare, Assef/AFH-0960-2022
OI Zare, Assef/0000-0003-4983-3698; Kekha Javan, Ali
   Akbar/0000-0002-2117-8962
CR Alam Z, 2016, IEEE-CAA J AUTOMATIC, V3, P157, DOI 10.1109/JAS.2016.7451103
   Bhalekar S, 2010, COMMUN NONLINEAR SCI, V15, P3536, DOI 10.1016/j.cnsns.2009.12.016
   Bhat MA, 2018, INT J MODEL SIMUL, V38, P254, DOI 10.1080/02286203.2018.1442988
   Bulut GG, 2019, 2019 IEEE 1ST GLOBAL POWER, ENERGY AND COMMUNICATION CONFERENCE (GPECOM2019), P30, DOI 10.1109/GPECOM.2019.8778568
   Chen XY, 2017, APPL MATH COMPUT, V308, P161, DOI 10.1016/j.amc.2017.03.032
   Harshavarthini S, 2020, CHAOS SOLITON FRACT, V134, DOI 10.1016/j.chaos.2020.109683
   Hosny KM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091066
   Ibraheem A, 2020, ARAB J SCI ENG, V45, P6911, DOI 10.1007/s13369-020-04529-z
   Jahanshahi H, 2021, CHAOS SOLITON FRACT, V144, DOI 10.1016/j.chaos.2021.110698
   Jahanzaib LS, 2021, ARAB J SCI ENG, V46, P1729, DOI 10.1007/s13369-020-04939-z
   Javan AAK, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6030082
   Javan AAK, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6020051
   Javan AAK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113925
   Jia H, 2020, ALGORITHMS, V13, DOI 10.3390/a13120346
   Javan AAK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010254
   Khan A, 2020, J CONTROL AUTOM ELEC, V31, P885, DOI 10.1007/s40313-020-00613-9
   Khan A, 2017, MATH METHOD APPL SCI, V40, P5654, DOI 10.1002/mma.4416
   Kumar S, 2019, MED BIOL ENG COMPUT, V57, P2517, DOI 10.1007/s11517-019-02037-3
   Lai Q, 2022, CHAOS SOLITON FRACT, V158, DOI 10.1016/j.chaos.2022.112017
   Lai Q, 2023, IEEE T NEUR NET LEAR, V34, P7824, DOI 10.1109/TNNLS.2022.3146570
   Lai Q, 2018, CHAOS SOLITON FRACT, V114, P230, DOI 10.1016/j.chaos.2018.07.011
   Li B, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/5184032
   Li SH, 2003, CHAOS SOLITON FRACT, V15, P303, DOI 10.1016/S0960-0779(02)00100-5
   Li WH, 2020, J CONTROL AUTOM ELEC, V31, P1375, DOI 10.1007/s40313-020-00650-4
   Liu JZ, 2019, MULTIDIM SYST SIGN P, V30, P1637, DOI 10.1007/s11045-018-0622-0
   Liu SR, 2021, INT J INF SECUR PRIV, V15, P54, DOI 10.4018/IJISP.2021100104
   Liu ZW, 2020, AUTOMATICA, V119, DOI 10.1016/j.automatica.2020.109041
   Luo RZ, 2017, CHINESE J PHYS, V55, P342, DOI 10.1016/j.cjph.2016.10.024
   Mahmoud GM, 2018, J COMPUT NONLIN DYN, V13, DOI 10.1115/1.4041033
   Mohammadpour S, 2018, SYST SCI CONTROL ENG, V6, P28, DOI 10.1080/21642583.2018.1428695
   Nabutovsky I, 2020, TELEMED E-HEALTH, V26, P34, DOI 10.1089/tmj.2018.0302
   Nemati HR, 2010, APPL ENCRYPTION CYBE
   Pone JRM, 2019, AUTOMATIKA, V60, P149, DOI 10.1080/00051144.2019.1600109
   RATIB O, 1994, COMPUT MED IMAG GRAP, V18, P73, DOI 10.1016/0895-6111(94)90016-7
   Rosset C, 2005, J DIGIT IMAGING, V18, P270, DOI 10.1007/s10278-005-6703-2
   Saadaoui S, 2019, INFORMATION, V10, DOI 10.3390/info10030104
   Safi S, 2018, JMIR RES PROTOC, V7, DOI 10.2196/11072
   Ben Mahmoud MS, 2014, COMPUT SCI REV, V11-12, P1, DOI 10.1016/j.cosrev.2014.02.001
   Sun ZF, 2018, OPTIK, V157, P43, DOI 10.1016/j.ijleo.2017.09.057
   Sweetha S, 2021, CHAOS SOLITON FRACT, V142, DOI 10.1016/j.chaos.2020.110312
   Vincent UE, 2011, PHYS LETT A, V375, P2322, DOI 10.1016/j.physleta.2011.04.041
   Wang H, 2009, NONLINEAR ANAL-REAL, V10, P2842, DOI 10.1016/j.nonrwa.2008.08.010
   Wang LM, 2019, APPL MATH COMPUT, V347, P293, DOI 10.1016/j.amc.2018.11.017
   Wang YW, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P1845
   Yadav VK, 2018, STUD SYST DECIS CONT, V133, P115, DOI 10.1007/978-3-319-71243-7_5
   Yadav VK, 2019, CHINESE J PHYS, V57, P282, DOI 10.1016/j.cjph.2018.12.001
   Yao Q, 2020, CHAOS SOLITON FRACT
   Yu JP, 2011, NONLINEAR ANAL-REAL, V12, P671, DOI 10.1016/j.nonrwa.2010.07.009
   Yu JY, 2017, OPTIK, V130, P1053, DOI 10.1016/j.ijleo.2016.11.108
   Zheng CD, 2020, NEUROCOMPUTING, V410, P151, DOI 10.1016/j.neucom.2020.05.061
NR 50
TC 1
Z9 1
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 1
PY 2023
DI 10.1007/s11042-023-15783-2
EA JUN 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0CF9
UT WOS:000999534000001
DA 2024-07-18
ER

PT J
AU Verma, A
   Yadav, AK
   Kumar, M
   Yadav, D
AF Verma, Akash
   Yadav, Arun Kumar
   Kumar, Mohit
   Yadav, Divakar
TI Automatic image caption generation using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image; Neural network; Caption; CNN (Convolutional Neural Network);
   Feature extraction; RNN (Recurrent Neural Network); LSTM (Long
   Short-Term Memory)
ID ATTENTION
AB Image captioning is an interesting and challenging task with applications in diverse domains such as image retrieval, organizing and locating images of users' interest, etc. It has huge potential for replacing manual caption generation for images and is especially suitable for large-scale image data. Recently, deep neural network based methods have achieved great success in the field of computer vision, machine translation, and language generation. In this paper, we propose an encoder-decoder based model that is capable of generating grammatically correct captions for images. This model makes use of VGG16 Hybrid Places 1365 as an encoder and LSTM as a decoder. To ensure the complete ground truth accuracy, the model is trained on the labeled Flickr8k and MS-COCO Captions datasets., Further, the model is evaluated using all popular standard metrics such as BLEU, METEOR, GLEU, and ROUGE_L. Experimental results indicate that the proposed model obtained a BLEU-1 score of 0.6666, METEOR score of 0.5060, and GLEU score of 0.2469 on the Flickr8k dataset and BLEU-1 score 0.7350, METEOR score of 0.4768 and GLEU score 0.2798 on MS-COCO Caption dataset. Thus, the proposed method achieved a significant performance as compared to the state-of-art approaches. To evaluate the efficacy of the model further, we also show the results of caption generation from live sample images that reinforce the validity of the proposed approach.
C1 [Verma, Akash; Yadav, Arun Kumar; Kumar, Mohit] NIT Hamirpur HP, Dept Comp Sci & Engn, Hamirpur, India.
   [Yadav, Divakar] IGNOU New Delhi, Sch Comp & Informat Sci, New Delhi, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Yadav, D (corresponding author), IGNOU New Delhi, Sch Comp & Informat Sci, New Delhi, India.
EM akashverma673@gmail.com; ayadav@nith.ac.in; mohit@nith.ac.in;
   dsy99@rediffmail.com
RI Kumar, Mohit/AAD-9020-2022; Yadav, DIVAKAR/AAF-1777-2020
OI Yadav, DIVAKAR/0000-0001-6051-479X; Verma, Akash/0009-0009-8811-8276;
   YADAV, ARUN KUMAR/0000-0001-9774-7917
CR Aggarwal Ashwani Kumar, 2022, WSEAS Transactions on Signal Processing, P60, DOI 10.37394/232014.2022.18.8
   Albawi S, 2017, I C ENG TECHNOL
   Amritkar C, 2018, P 2018 4 INT C COMP, P1
   [Anonymous], 2014, Transactions of the Association for Computational Linguistics
   Arora K., 2018, Handbook of Research on Advanced Concepts in Real-time Image and Video Processing, P28, DOI 10.4018/978-1-5225-2848-7.ch002
   Bai S, 2018, NEUROCOMPUTING, V311, P291, DOI 10.1016/j.neucom.2018.05.080
   Barlas G, 2021, VISUAL COMPUT, V37, P1309, DOI 10.1007/s00371-020-01867-9
   Bayoudh K, 2022, VISUAL COMPUT, V38, P2939, DOI 10.1007/s00371-021-02166-7
   Biswas R, 2020, KUNSTL INTELL, V34, P571, DOI 10.1007/s13218-020-00679-2
   Cao PF, 2019, NEURAL PROCESS LETT, V50, P103, DOI 10.1007/s11063-018-09973-5
   Chen H, 2021, COGN COMPUT, V13, P807, DOI 10.1007/s12559-019-09656-w
   Chu Y., 2020, WIREL COMMUN MOB COM, V2020
   Ding GG, 2019, COGN COMPUT, V11, P763, DOI 10.1007/s12559-018-9581-x
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Dong XZ, 2021, Arxiv, DOI arXiv:2108.02366
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Ghosh A, 2020, NEURAL NETWORK FRAME, P171
   Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Gupta N, 2020, NEURAL COMPUT APPL, V32, P17899, DOI 10.1007/s00521-019-04515-z
   He C, 2019, NEURAL PROCESS LETT, V49, P177, DOI 10.1007/s11063-018-9807-7
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hodosh M, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4188
   Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748
   Huang FC, 2020, MACH LEARN, V109, P2313, DOI 10.1007/s10994-020-05919-y
   Jiang T, 2019, VISUAL COMPUT, V35, P1655, DOI 10.1007/s00371-018-1565-z
   Karpathy A, 2017, IEEE T PATTERN ANAL, V39, P664, DOI 10.1109/TPAMI.2016.2598339
   Katiyar Sulabh, 2021, INT J ADV COMPUT SC
   Katpally H, 2020, IEEE INT C SEMANT CO, P61, DOI 10.1109/ICSC.2020.00016
   Kaur A, 2022, IEEE ACM T COMPUTATI
   Khan M.J., 2020, CIKM WORKSHOPS
   Khan MJ, 2022, VISUAL COMPUT, V38, P509, DOI 10.1007/s00371-020-02031-z
   Kiros R, 2014, 31 INT C MACHINE LEA, V3, P2012
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Lavie A., 2007, P 2 WORKSH STAT MACH, P228
   Liu XX, 2019, VISUAL COMPUT, V35, P445, DOI 10.1007/s00371-018-1566-y
   Mao JH, 2014, Arxiv, DOI arXiv:1410.1090
   Mao JH, 2015, Arxiv, DOI arXiv:1412.6632
   Mason R, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P592
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Mutton A., 2007, GLEU: Automatic Evaluation of Sentence-Level Fluency, P344
   Nursikuwagus A, 2022, J IMAGING, V8, DOI 10.3390/jimaging8110294
   Ordonez V., 2011, NEURIPS
   Ordonez V, 2016, INT J COMPUT VISION, V119, P46, DOI 10.1007/s11263-015-0840-y
   Peng Y, 2021, VLDB J, V30, P799, DOI 10.1007/s00778-021-00674-5
   Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.5555/1866696.1866717
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Su YT, 2020, NEURAL PROCESS LETT, V52, P1057, DOI 10.1007/s11063-019-09997-5
   Sun C, 2015, IEEE I CONF COMP VIS, P2596, DOI 10.1109/ICCV.2015.298
   Sun J, 2016, IEEE C COMPUTER VISI
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   TSUCHIYA G, 1970, JPN CIRCULATION J, V34, P1213
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wentzel G., 1922, 40 ANN M ASS COMP LI, V371, P437, DOI DOI 10.1002/ANDP.19223712302
   Xiao F, 2019, NEUROCOMPUTING, V364, P322, DOI 10.1016/j.neucom.2019.06.085
   Yang Y., 2011, P C EMP METH NAT LAN, P444
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zhang WQ, 2021, MULTIMED TOOLS APPL, V80, P16267, DOI 10.1007/s11042-020-08832-7
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 60
TC 0
Z9 0
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 1
PY 2023
DI 10.1007/s11042-023-15555-y
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0CF9
UT WOS:000999534000004
DA 2024-07-18
ER

PT J
AU Yadava, GT
   Nagaraja, BG
   Jayanna, HS
AF Yadava, G. Thimmaraja
   Nagaraja, B. G.
   Jayanna, H. S.
TI Improvements in ASR system to access the real-time agricultural
   commodity prices and weather information in Kannada language/dialects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Kannada ASR; Isolated Kannada speech data; WER; Kaldi; SQS
ID SPEECH; NOISE
AB This research work showcases advancements in an isolated Kannada automatic speech recognition (ASR) system designed for accessing agricultural commodity prices and weather information in uncontrolled environments. The system includes an interactive voice response system (IVRS), models of ASR, and databases of weather and agricultural commodity prices information. However, the previous system suffered from reduced accuracy due to the presence of various background noises during offline and online speech recognition. To address this issue, the proposed system includes a background noise reduction module that is introduced before the part of speech feature extraction. The investigation results indicate that the proposed noise reduction algorithm outperforms traditional signal processing algorithms, resulting in no audibility of musical and other background noises in the enhanced NOIZEUS speech corpora and isolated Kannada speech data. The use of this noise suppression algorithm and time delay neural network (TDNN) ASR modeling technique in the system results in a 1.1% improvement in speech recognition accuracy compared to the previous deep neural network - hidden Markov model (DNN-HMM) based system. The enhanced isolated Kannada system was tested online by 500 speakers/users for accessing real-time agricultural commodity prices and weather information in Kannada language/dialects under corrupted environments. The algorithms source code and ASR models are made publicly available.
C1 [Yadava, G. Thimmaraja] Nitte Meenakshi Inst Technol, E&CE, Bengaluru 560064, Karnataka, India.
   [Nagaraja, B. G.] Vidyavardhaka Coll Engn, E&CE, Gokulam 3 Stage, Mysuru 570002, Karnataka, India.
   [Jayanna, H. S.] Siddaganga Inst Technol, IS&E, BH Rd, Tumkur 572103, Karnataka, India.
C3 Nitte Meenakshi Institute of Technology; Vidyavardhaka College of
   Engineering; Siddaganga Institute of Technology
RP Yadava, GT (corresponding author), Nitte Meenakshi Inst Technol, E&CE, Bengaluru 560064, Karnataka, India.
EM thimrajyadav@gmail.com; nagarajbg@gmail.com; jayannahs@gmail.com
RI Yadava G, Thimmaraja/AEO-3181-2022
OI Yadava G, Thimmaraja/0000-0002-3266-9732
CR Al-Anzi FS, 2022, FRACTALS, V30, DOI 10.1142/S0218348X22402277
   [Anonymous], 2001, Probability, Random Variables, and Stochas- tic Processes
   Bhable S., 2021, Int. J. Res. Appl. Sci. Eng. Technol., V9, P260
   Boumehdi A, 2020, 2020 4 INT C INT, P1
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   Hu Y, 2007, SPEECH COMMUN, V49, P588, DOI 10.1016/j.specom.2006.12.006
   Hu Y, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1447
   ITU-T, 2001, PERC EV SPEECH QUAL, P862
   Kumar A, 2022, INFLAMMOPHARMACOLOGY, V30, P23, DOI 10.1007/s10787-021-00903-x
   Liu F, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082811
   Loizou PC, 2005, IEEE T SPEECH AUDI P, V13, P857, DOI 10.1109/TSA.2005.851929
   Lu Y, 2008, SPEECH COMMUN, V50, P453, DOI 10.1016/j.specom.2008.01.003
   Maruf MR, 2020, IEEE REGION 10 SYMP, P1564
   Nagaraja B. G., 2013, International Journal of Image, Graphics and Signal Processing, V5, P14, DOI 10.5815/ijigsp.2013.09.03
   Nagaraja BG., 2013, INPROCEEDINGS 4 INT, V1, P143
   Povey D., 2011, IEEE 2011 WORKSH AUT
   Kumar PSP, 2020, CIRC SYST SIGNAL PR, V39, P391, DOI 10.1007/s00034-019-01189-9
   Shahnawazuddin S, 2017, J SIGNAL PROCESS SYS, V88, P91, DOI 10.1007/s11265-016-1133-6
   Shahnawazuddin S, 2015, J SIGNAL PROCESS SYS, V81, P83, DOI 10.1007/s11265-014-0906-z
   Shareef SR., 2021, J PHYS C SER, V1897, P012
   Slivova M, 2022, MULTIMED TOOLS APPL, V81, P9445, DOI 10.1007/s11042-021-11150-1
   Tejedor-García C, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11156695
   Yadava GT, 2020, INT J SPEECH TECHNOL, V23, P149, DOI 10.1007/s10772-020-09671-5
   Yoma NB, 1998, IEEE T SPEECH AUDI P, V6, P579, DOI 10.1109/89.725325
   Zada B, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e03372
NR 26
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 23
PY 2023
DI 10.1007/s11042-023-15350-9
EA MAY 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H1DL6
UT WOS:000993432500001
DA 2024-07-18
ER

PT J
AU Alsadoon, A
   AlSallami, N
   Rashid, TA
   Gosper, J
   Prasad, PWC
   Haddad, S
AF Alsadoon, Abeer
   AlSallami, Nada
   Rashid, Tarik A. A.
   Gosper, Jeff
   Prasad, P. W. C.
   Haddad, Sami
TI DVT: a recent review and a taxonomy for oral and maxillofacial
   visualization and tracking based augmented reality: image guided surgery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Augmented reality (AR); Oral and maxillofacial surgery (OMS); 3D image;
   Classification; DDVT; Visualization; Tracking
ID PEDICLE SCREW PLACEMENT; SURGICAL NAVIGATION; REGISTRATION; HEAD;
   ACCURACY; IMPLANT; ROBOT
AB Augmented reality (AR) navigation system is increasingly being integrated into Image Guided Surgery systems. The use of AR registration and tracking system in operating rooms (OR) for oral and maxillofacial surgery (OMS) can result in reducing medical errors and decreasing total operation times. As such, AR systems are assisting to reduce some of the surgical complexities associated with OMS, making it easier for the surgeons to view the operation. Although AR systems has been implemented in OR for many years, there are still several factors that are less than optimal and can cause complications, such as inadequate system accuracy, poor image and video quality, high operating time and cost, and significant complexity of the system required to achieve accurate views of the surgical target of OMS. The aim of this research is to improve the use of AR in OMS using the proposed review taxonomy which incorporated Data, Visualization, and Tracking (DVT). DVT taxonomy defines the major components that are required to implement in an AR navigation system. Those components are validated and evaluated considering the clear and accurate output or view during craniofacial surgery for the end user. The proposed DVT taxonomy have been considered comparison of system, completeness of system and acceptance of the system as the major criteria. DVT is evaluated and validated our DTV taxonomy by analysing and classifying the 33 state of art publications which work in the AR navigation. This work presents a review over navigational approach towards surgery through AR which highlights the features and usefulness of AR compared to the existing surgical process in terms of processing time, accuracy, efficiency, and feasibility in surgery.
C1 [Alsadoon, Abeer; Gosper, Jeff; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp Math & Engn, Albury Wodonga, Australia.
   [Alsadoon, Abeer] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Sydney, Australia.
   [AlSallami, Nada] Worcester State Univ WSU, Comp Sci Dept, Worcester, MA USA.
   [Rashid, Tarik A. A.] Univ Kurdistan Hewler, Comp Sci & Engn, Erbil, Krg, Iraq.
   [Haddad, Sami] Greater Western Sydney Area Hlth Serv, Dept Oral & Maxillofacial Serv, Mt Druitt, Australia.
   [Haddad, Sami] Cent Coast Area Hlth, Dept Oral & Maxillofacial Serv, Gosford, Australia.
C3 Charles Sturt University; Western Sydney University; University of
   Kurdistan Hewler; Florey Institute of Neuroscience & Mental Health
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Albury Wodonga, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, Australia.
EM abalsadoon@csu.edu.au
CR Badiali G, 2014, J CRANIO MAXILL SURG, V42, P1970, DOI 10.1016/j.jcms.2014.09.001
   Basnet BR, 2018, ORAL MAXILLOFAC SURG, V22, P385, DOI 10.1007/s10006-018-0719-5
   Bong JH, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1886
   Bosc R, 2019, INT J ORAL MAX SURG, V48, P132, DOI 10.1016/j.ijom.2018.09.010
   Chen XJ, 2016, COMPUT METH PROG BIO, V125, P66, DOI 10.1016/j.cmpb.2015.10.020
   Chen XJ, 2015, J BIOMED INFORM, V55, P124, DOI 10.1016/j.jbi.2015.04.003
   Chu YK, 2017, MED IMAGE ANAL, V42, P241, DOI 10.1016/j.media.2017.08.003
   Crafts TD, 2017, OTOLARYNG HEAD NECK, V156, P999, DOI 10.1177/0194599816678372
   Cutolo F, 2015, LECT NOTES COMPUT SC, V9365, P50, DOI 10.1007/978-3-319-24601-7_6
   Dai JW, 2016, SCI REP-UK, V6, DOI 10.1038/srep28242
   Diotte B, 2015, IEEE T MED IMAGING, V34, P487, DOI 10.1109/TMI.2014.2361155
   Dixon BJ, 2014, AM J RHINOL ALLERGY, V28, P433, DOI 10.2500/ajra.2014.28.4067
   Dixon BJ, 2013, SURG ENDOSC, V27, P454, DOI 10.1007/s00464-012-2457-3
   EDGERTON MT, 1977, PLAST RECONSTR SURG, V59, P653, DOI 10.1097/00006534-197705000-00006
   Hassfeld S, 2001, INT J ORAL MAX SURG, V30, P2, DOI 10.1054/ijom.2000.0024
   Hayashi Y, 2016, INT J COMPUT ASS RAD, V11, P827, DOI 10.1007/s11548-015-1293-z
   He C, 2016, 2016 IEEE INT INSTR, P1, DOI [10.1109/I2MTC.2016.7520404, DOI 10.1109/I2MTC.2016.7520404]
   Hung KF, 2017, CLIN IMPLANT DENT R, V19, P458, DOI 10.1111/cid.12475
   Kilgus T, 2015, INT J COMPUT ASS RAD, V10, P573, DOI 10.1007/s11548-014-1106-9
   Kim Geon Woo, 2018, Arch Craniofac Surg, V19, P194, DOI 10.7181/acfs.2018.02012
   Liao HE, 2010, IEEE T BIO-MED ENG, V57, P1476, DOI 10.1109/TBME.2010.2040278
   Lin L, 2016, J CRANIO MAXILL SURG, V44, P215, DOI 10.1016/j.jcms.2015.10.024
   Lin PT, 2013, HIGH PERFORMANCE MEG, DOI [10.5772/54550, DOI 10.5772/54550]
   Lin YK, 2015, CLIN IMPLANT DENT R, V17, P543, DOI 10.1111/cid.12119
   Luther N, 2015, J SPINAL DISORD TECH, V28, pE298, DOI 10.1097/BSD.0b013e31828af33e
   Ma LF, 2019, MED BIOL ENG COMPUT, V57, P47, DOI 10.1007/s11517-018-1861-9
   Ma LF, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1909
   Ma LF, 2017, INT J COMPUT ASS RAD, V12, P2205, DOI 10.1007/s11548-017-1652-z
   Mahmoud N, 2017, INT J COMPUT ASS RAD, V12, P1, DOI 10.1007/s11548-016-1444-x
   Meulstee JW, 2019, SURG INNOV, V26, P86, DOI 10.1177/1553350618799552
   Murugesan YP, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1889
   Nakao M, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161815
   Pokhrel S, 2019, INT J MED ROBOT COMP, V15, DOI 10.1002/rcs.1958
   Profeta AC, 2016, BRIT J ORAL MAX SURG, V54, P694, DOI 10.1016/j.bjoms.2015.11.008
   Qu M, 2015, J CRANIO MAXILL SURG, V43, P106, DOI 10.1016/j.jcms.2014.10.019
   Reichard D, 2017, INT J COMPUT ASS RAD, V12, P1101, DOI 10.1007/s11548-017-1613-6
   Shi YY, 2017, MINIM INVASIV THER, V26, P23, DOI 10.1080/13645706.2016.1216864
   Suenaga H, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0089-5
   Suenaga H, 2013, INT J ORAL SCI, V5, P98, DOI 10.1038/ijos.2013.26
   Tuladhar S, 2020, INT J MED ROBOT COMP, V16, DOI 10.1002/rcs.2120
   Valenti M, 2016, MED BIOL ENG COMPUT, V54, P1727, DOI 10.1007/s11517-016-1460-6
   Wang JC, 2017, INT J MED ROBOT COMP, V13, DOI 10.1002/rcs.1754
   Wang JC, 2015, COMPUT MED IMAG GRAP, V40, P147, DOI 10.1016/j.compmedimag.2014.11.003
   Wang JC, 2014, IEEE T BIO-MED ENG, V61, P1295, DOI 10.1109/TBME.2014.2301191
   Wild E, 2016, INT J COMPUT ASS RAD, V11, P899, DOI 10.1007/s11548-016-1385-4
   Xiao YM, 2018, MULTIMED TOOLS APPL, V77, P27789, DOI 10.1007/s11042-018-5990-9
   Zhang XR, 2017, IEEE T BIO-MED ENG, V64, P1815, DOI 10.1109/TBME.2016.2624632
   Zhu M, 2018, J PLAST RECONSTR AES, V71, P1188, DOI 10.1016/j.bjps.2018.03.018
   Zhu M, 2017, SCI REP-UK, V7, DOI 10.1038/srep42365
   Zhu M, 2011, J CRANIOFAC SURG, V22, P1806, DOI 10.1097/SCS.0b013e31822e8064
   Zinser MJ, 2013, BRIT J ORAL MAX SURG, V51, P827, DOI 10.1016/j.bjoms.2013.06.014
   Zorina ZA, 2005, ZOOL ZH, V84, P134
NR 52
TC 3
Z9 3
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 22
PY 2023
DI 10.1007/s11042-023-15581-w
EA MAY 2023
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G9PW0
UT WOS:000992398700004
DA 2024-07-18
ER

PT J
AU Zainab, HE
   Bawany, NZ
   Rehman, W
   Imran, J
AF Zainab, Hijab e
   Bawany, Narmeen Zakaria
   Rehman, Wajiha
   Imran, Jaweria
TI Design and development of virtual reality exposure therapy systems:
   requirements, challenges and solutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Virtual reality exposure therapy; Phobia; Therapist; Virtual reality;
   Exposure therapy; Psychologist
ID ANXIETY DISORDERS; INTERVENTIONS; MEDITATION; BENEFITS
AB Virtual Reality technology is being utilized to administer psychotherapy treatments. Virtual Reality Exposure Therapy (VRET) provides a safer and less expensive platform for the exposure therapy treatment of numerous anxiety disorders such as phobias. Though, research studies have demonstrated the effectiveness of VRET, its large scale adoption is yet to be realized. Many VRET solutions have been designed, however, few are widely used or commercially available. Moreover, these solutions lack standardization as there are no significant guidelines available for developing them. Consequently, it prevents the existing VRET systems from being adopted for clinical treatment. Thus, there is a need for determining the critical design requirements to create practically effective, safe and commercially viable VRET solutions. To this end, we put forward key design considerations in designing VRETs. Keeping in view these considerations, we present Defear, a therapist-led VRET solution to facilitate the treatment of phobias. Defear not only provides VRET solutions but also includes wide-ranging features including patient management, meditation, and progress tracking to support therapists in their exposure therapy treatments. Usability assessment showed that Defear was positively and highly rated by the users. Moreover, we also present the challenges in the planning, development, evaluation, and dissemination of VRET applications.
C1 [Zainab, Hijab e; Bawany, Narmeen Zakaria; Rehman, Wajiha; Imran, Jaweria] Jinnah Univ Women, Dept Comp Sci & Software Engn, Karachi, Pakistan.
RP Zainab, HE (corresponding author), Jinnah Univ Women, Dept Comp Sci & Software Engn, Karachi, Pakistan.
EM hijabz80@gmail.com; narmeen.bawany@juw.edu.pk; wajiha@csse-juw.com;
   kjaweria62@gmail.com
RI Zainab, Hijab/JJE-0268-2023; Bawany, Narmeen/AAF-5498-2020
OI Zainab, Hijab/0000-0001-9894-1578; imran, jaweria/0000-0003-2261-4022;
   Bawany, Narmeen/0000-0003-2975-6824
CR Alalwan N, 2020, STUD EDUC EVAL, V66, DOI 10.1016/j.stueduc.2020.100876
   Assila A., 2016, Electronic Journal of Computer Science and Information Technology, V6, DOI DOI 10.1016/B978-0-12-384968-7.00008-4
   Bandelow B, 2015, DIALOGUES CLIN NEURO, V17, P327
   Bates TJD, 2016, METHODS MOL BIOL, V1467, P133, DOI 10.1007/978-1-4939-4023-3_12
   Boeldt D, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00773
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Charoensukmongkol P, 2014, J SPIRITUAL MENT HE, V16, P171, DOI 10.1080/19349637.2014.925364
   Cheng L, 2017, WIRES DATA MIN KNOWL, V7, DOI 10.1002/widm.1211
   Christopoulou E, 2017, INT J SERIOUS GAMES, V4, P21, DOI 10.17083/ijsg.v4i4.194
   Cruz-Neira C., 2018, Multimodal Technol. Interact, V2, DOI [DOI 10.3390/MTI2010008, 10.3390/MTI2010008]
   Deng WR, 2019, J AFFECT DISORDERS, V257, P698, DOI 10.1016/j.jad.2019.07.086
   Geraets CNW, 2021, CURR OPIN PSYCHOL, V41, P40, DOI 10.1016/j.copsyc.2021.02.004
   Glegg SMN, 2018, PM&R, V10, P1237, DOI 10.1016/j.pmrj.2018.07.004
   HELLSTROM K, 1995, BEHAV RES THER, V33, P959, DOI 10.1016/0005-7967(95)00028-V
   Jia JD, 2017, IEEE INT C COMPUT, P696, DOI 10.1109/CSE-EUC.2017.134
   Kaminska D, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041342
   Kiryu T, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-34
   Kramer TL, 2010, PSYCHIAT SERV, V61, P1153, DOI 10.1176/ps.2010.61.11.1153
   Lang AJ, 2000, BEHAV RES THER, V38, P1, DOI 10.1016/S0005-7967(99)00031-5
   Lindner P, 2017, COGN BEHAV THERAPY, V46, P404, DOI 10.1080/16506073.2017.1280843
   Madary M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00003
   Maples-Keller JL, 2017, NEUROTHERAPEUTICS, V14, P554, DOI 10.1007/s13311-017-0534-y
   Miloff A, 2019, BEHAV RES THER, V118, P130, DOI 10.1016/j.brat.2019.04.004
   Mitrousia V, 2016, Psychiatriki, V27, P276, DOI 10.22365/jpsych.2016.274.276
   Monk-Turner E, 2003, SOC SCI J, V40, P465, DOI 10.1016/S0362-3319(03)00043-0
   Papachristos NM, 2017, IEEE INT CONF ADV LE, P477, DOI 10.1109/ICALT.2017.145
   Papanastasiou G, 2019, VIRTUAL REAL-LONDON, V23, P425, DOI 10.1007/s10055-018-0363-2
   Perez-De-Albeniz A., 2000, INT J PSYCHOTHER, V5, P49, DOI [10.1080/13569080050020263, DOI 10.1080/13569080050020263]
   Pettey C, 2010, GARTNER
   Raudonis V, 2017, LECT NOTES COMPUT SC, V10408, P248, DOI 10.1007/978-3-319-62404-4_19
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Salkevicius J, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8091039
   Salkevicius J, 2019, INFORMATION, V10, DOI 10.3390/info10020062
   Shakirova N, 2020, INT J EMERG TECHNOL, V15, P59, DOI 10.3991/ijet.v15i20.15433
   Smokowski P.R., 2003, J TECHNOL HUMAN SERV, V21, P5, DOI DOI 10.1300/J017V21N01_02
   Tahir M, 2019, 3C TECNOL, P11, DOI 10.17993/3ctecno.2019.specialissue.02
   Thangavelu K, 2022, CLIN GERONTOLOGIST, V45, P235, DOI 10.1080/07317115.2019.1709597
   Thistle VG., 2016, PHYS THER REHABIL, V3, P7, DOI [10.7243/2055-2386-3-7, DOI 10.7243/2055-2386-3-7]
   Thng Christabel E W, 2020, F1000Res, V9, DOI 10.12688/f1000research.20082.1
   Tomasino B, 2013, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00346
   Trappey A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10144860
   Vinson N, 2012, CYBERSICKNESS INDUCE, P69
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wiederhold BK, 2018, HEALTH INFORM SER, P123, DOI 10.1007/978-3-319-61446-5_9
NR 44
TC 0
Z9 0
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 17
PY 2023
DI 10.1007/s11042-023-15756-5
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7EQ1
UT WOS:000990751100015
DA 2024-07-18
ER

PT J
AU Li, XS
   Li, QL
   Anisetti, M
   Jeon, G
   Gao, ML
AF Li, Xuesong
   Li, Qilei
   Anisetti, Marco
   Jeon, Gwanggil
   Gao, Mingliang
TI A structure and texture revealing retinex model for low-light image
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Low-light image enhancement; Retinex decomposition; Illumination
   adjustment; Structure estimation; Texture estimation
ID ILLUMINATION; FRAMEWORK; ALGORITHM; FUSION
AB Low-light image enhancement is a crucial yet challenging task in computer vision and multimedia applications. Retinex-based approaches have been continuously explored in this domain. However, the Retinex decomposition is an ill-posed problem, as the proper constraints of illumination and reflectance should be considered to regularize the solution space. Aiming at a faithful enhancement, we develop a Structure and Texture Revealing Retinex (STR2) model to accurately estimate the illumination and reflectance components. The proposed STR2 model utilizes an exponential relative total variation method to draw structure and texture maps by analyzing the difference in gradient distribution between the illumination and reflectance components. The resulting structure and texture maps are used to regularize the illumination and reflectance components. With a tailored alternating optimization algorithm, the STR2 model can jointly update the illumination and reflectance efficiently to produce a faithful enhanced image. Experimental results on several public datasets verify the effectiveness of the proposed model in low-light image enhancement.
C1 [Li, Xuesong; Gao, Mingliang] Shandong Univ Technol, Sch Elect & Elect Engn, Zibo 255000, Peoples R China.
   [Li, Qilei] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.
   [Anisetti, Marco] Univ Milan, Dept Comp Sci, I-20133 Milan, Italy.
   [Jeon, Gwanggil] Incheon Natl Univ, Dept Embedded Syst Engn, Incheon 22012, South Korea.
C3 Shandong University of Technology; University of London; Queen Mary
   University London; University of Milan; Incheon National University
RP Gao, ML (corresponding author), Shandong Univ Technol, Sch Elect & Elect Engn, Zibo 255000, Peoples R China.
EM mlgao@sdut.edu.cn
RI Anisetti, Marco/AAC-9656-2021; , 李启磊/K-7546-2019
OI Anisetti, Marco/0000-0002-5438-9467; , 李启磊/0000-0002-9675-9016
FU National Natural Science Foundation of Shandong Province [ZR2021QD041,
   ZR2020MF127]
FX AcknowledgementsThis work is supported in part by the National Natural
   Science Foundation of Shandong Province (Nos. ZR2021QD041 and
   ZR2020MF127).
CR Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   BRAINARD DH, 1986, J OPT SOC AM A, V3, P1651, DOI 10.1364/JOSAA.3.001651
   Bychkovsky V, 2011, PROC CVPR IEEE, P97
   Cai BL, 2017, IEEE I CONF COMP VIS, P4020, DOI 10.1109/ICCV.2017.431
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Chen JY, 2020, J INTELL TRANSPORT S, V24, P290, DOI 10.1080/15472450.2019.1642753
   Chen LH, 2020, ARTIF INTELL MED, V106, DOI 10.1016/j.artmed.2020.101857
   Chen SH, 2009, IEEE IMAGE PROC, P1813, DOI 10.1109/ICIP.2009.5413362
   Dong X, 2011, IEEE INT CON MULTI
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701
   Gao YY, 2018, IEEE T MULTIMEDIA, V20, P335, DOI 10.1109/TMM.2017.2740025
   Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592
   Gonzalez RC., 1981, IEEE Trans. Patt. Anal Mach Intll, V3, P242
   Gu K, 2017, IEEE T CYBERNETICS, V47, P4559, DOI 10.1109/TCYB.2016.2575544
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gu ZH, 2020, IEEE T IMAGE PROCESS, V29, P3239, DOI 10.1109/TIP.2019.2958144
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, P53
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Khan MF, 2015, OPTIK, V126, P4868, DOI 10.1016/j.ijleo.2015.09.161
   Kim G, 2021, IEEE T IMAGE PROCESS, V30, P5452, DOI 10.1109/TIP.2021.3084743
   Kim G, 2019, IEEE IMAGE PROC, P2811, DOI [10.1109/icip.2019.8803328, 10.1109/ICIP.2019.8803328]
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lee CH, 2013, 2013 INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P43, DOI 10.1109/SITIS.2013.19
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Li CY, 2022, IEEE T PATTERN ANAL, V44, P4225, DOI 10.1109/TPAMI.2021.3063604
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Liang JW, 2015, J MATH IMAGING VIS, V52, P345, DOI 10.1007/s10851-015-0568-x
   Liu B, 2011, IEEE T CONSUM ELECTR, V57, P583, DOI 10.1109/TCE.2011.5955195
   Liu JY, 2021, INT J COMPUT VISION, V129, P1153, DOI 10.1007/s11263-020-01418-8
   Liu YF, 2017, IEEE T CIRC SYST VID, V27, P1171, DOI 10.1109/TCSVT.2016.2527338
   Liu YF, 2013, INT CONF ACOUST SPEE, P2444, DOI 10.1109/ICASSP.2013.6638094
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Ma KD, 2018, IEEE T COMPUT IMAG, V4, P60, DOI 10.1109/TCI.2017.2786138
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Ng MK, 2011, SIAM J IMAGING SCI, V4, P345, DOI 10.1137/100806588
   Pang JH, 2017, IEEE SYMP COMP COMMU, P1366, DOI 10.1109/ISCC.2017.8024714
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   Provenzi E, 2005, J OPT SOC AM A, V22, P2613, DOI 10.1364/JOSAA.22.002613
   Rahman Z, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10120718
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   Ren XT, 2020, IEEE T IMAGE PROCESS, V29, P5862, DOI 10.1109/TIP.2020.2984098
   Shan Q, 2010, IEEE T VIS COMPUT GR, V16, P663, DOI 10.1109/TVCG.2009.92
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Singh R.P., 2015, International Journal of Signal Processing, Image Processing and Pattern Recognition, V8, P345, DOI DOI 10.14257/IJSIP.2015.8.8.35
   Tao L, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang Y, 2019, J SCI COMPUT, V78, P29, DOI 10.1007/s10915-018-0757-z
   Wei Cui, 2018, 2018 Photonics North (PN), DOI 10.1109/PN.2018.8438843
   Wu YH, 2020, INT CONF SIGN PROCES, P160, DOI 10.1109/ICSP48669.2020.9321010
   Xu J, 2020, IEEE T IMAGE PROCESS, V29, P5022, DOI 10.1109/TIP.2020.2974060
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Xu YY, 2012, FRONT MATH CHINA, V7, P365, DOI 10.1007/s11464-012-0194-5
   Yan JZ, 2014, PROC CVPR IEEE, P2987, DOI 10.1109/CVPR.2014.382
   Ying ZQ, 2017, Arxiv, DOI arXiv:1711.00591
   Yu R., 2018, NEURIPS
   Yuan LT, 2015, PATTERN RECOGN LETT, V54, P103, DOI 10.1016/j.patrec.2014.09.011
   Zhang YH, 2021, INT J COMPUT VISION, V129, P1013, DOI 10.1007/s11263-020-01407-x
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zhao ZJ, 2022, IEEE T CIRC SYST VID, V32, P1076, DOI 10.1109/TCSVT.2021.3073371
   Zheng S, 2022, IEEE WINT CONF APPL, P581, DOI 10.1109/WACVW54805.2022.00064
NR 69
TC 0
Z9 0
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 13
PY 2023
DI 10.1007/s11042-023-15242-y
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F9TU9
UT WOS:000985707500001
DA 2024-07-18
ER

PT J
AU Jocovic, V
   Marinkovic, M
   Stojanovic, S
   Nikolic, B
AF Jocovic, Vladimir
   Marinkovic, Milan
   Stojanovic, Sasa
   Nikolic, Bosko
TI Automated assessment of pen and paper tests using computer vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artificial intelligence; Computer vision; Image analysis; Automated test
   assessment
ID MULTIPLE-CHOICE QUESTIONS; ALGORITHM
AB Computer vision is one of the artificial intelligence's most challenging fields, enabling computers to interpret, analyse and derive meaningful information from the visual world. There are various utilizations of computer vision algorithms, and most of them, from simpler to more complicated, have an object and shape recognition in common. Traditional pen and paper tests are designed in a pre-established format and consist of numerous basic shapes, which designate the important parts of the test itself. With that in mind, many computer vision applications regarding pen and paper tests arise as an opportunity. Massive courses and large schooling organizations mostly conduct their exams in paper format and assess them manually, which imposes a significant burden on the teaching staff. Any kind of automatization that will facilitate the grading process is highly desirable. Hence, an automated answer recognition system in assessment was developed to mitigate the problems above. The system uses images of scanned test pages obtained from the test scanning process and performs the necessary image manipulation steps to increase target recognition accuracy. Further, it manages to identify regions of interest containing multiple-choice questions and contours. Finally, the system verifies obtained results using the knowledge of the whereabouts of the test template regions of interest.
C1 [Jocovic, Vladimir; Marinkovic, Milan; Stojanovic, Sasa; Nikolic, Bosko] Univ Belgrade, Sch Elect Engn, Bulevar Kralja Aleksandra 73, Belgrade 11000, Serbia.
C3 University of Belgrade
RP Nikolic, B (corresponding author), Univ Belgrade, Sch Elect Engn, Bulevar Kralja Aleksandra 73, Belgrade 11000, Serbia.
EM nbosko@etf.bg.ac.rs
OI Nikolic, Bosko/0000-0003-1142-9243; Marinkovic,
   Milan/0009-0008-7213-0310; Jocovic, Vladimir/0000-0002-7140-5043
FU Science Fund of the Republic of Serbia [6526093]
FX AcknowledgementsThis research was supported by the Science Fund of the
   Republic of Serbia, grant no. 6526093, AI-AVANTES
   (www.fondzanauku.gov.rs). The authors gratefully acknowledge the
   support.
CR Bacanin N, 2021, J REAL-TIME IMAGE PR, V18, P1085, DOI 10.1007/s11554-021-01106-x
   Bacanin N, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8060936
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   BARBOSA W.O., 2019, TEMA (São Carlos), V20, P331, DOI 10.5540/tema.2019.020.02.0331
   Borade JG, 2021, LECT NOTES COMPUT SC, V12615, P238, DOI 10.1007/978-3-030-68449-5_25
   Catalan J. A., 2017, DLSU RES C 2017, P1
   Chamorro MEG, 2022, ASSESS WRIT, V51, DOI 10.1016/j.asw.2021.100594
   Chen TC, 2001, COMPUT VIS IMAGE UND, V83, P172, DOI 10.1006/cviu.2001.0923
   Dansena P, 2022, MULTIMED TOOLS APPL, V81, P30881, DOI 10.1007/s11042-022-12843-x
   Djekoune AO, 2017, OPTIK, V133, P17, DOI 10.1016/j.ijleo.2016.12.064
   Golekar D., 2022, INT RES J MOD ENG TE, V4, P1
   González-López S, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10132259
   Grade Scanner, GRADESCANNER MOB APP
   Kumar M, 2022, SADHANA-ACAD P ENG S, V47, DOI 10.1007/s12046-022-01847-w
   Kumar M, 2022, NEURAL COMPUT APPL, V34, P4957, DOI 10.1007/s00521-021-06686-0
   Kumar M, 2022, ARCH COMPUT METHOD E, V29, P1107, DOI 10.1007/s11831-021-09608-4
   Lopez-Fuentes L, 2018, MULTIMED TOOLS APPL, V77, P17069, DOI 10.1007/s11042-017-5276-7
   Lopez-Martinez A, 2019, APPL INTELL, V49, P2001, DOI 10.1007/s10489-018-1372-2
   Loudon C, 2018, ADV PHYSIOL EDUC, V42, P565, DOI 10.1152/advan.00186.2016
   Manzanera A, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0149-y
   Nardi A, 2019, BRIT J EDUC TECHNOL, V50, P1495, DOI 10.1111/bjet.12644
   Odeh N, 2020, MULTIMED TOOLS APPL, V79, P30151, DOI 10.1007/s11042-020-09481-6
   Santosh KC, 2020, MULTIMED TOOLS APPL, V79, P34697, DOI 10.1007/s11042-020-10093-3
   Shaheed K, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116786
   smartgrade, SMARTGRADE MOB APPL
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tirpude P., 2022, INT RES J MODERNIZAT, V4, P1
   Tractenberg RE, 2013, ADV HEALTH SCI EDUC, V18, P945, DOI 10.1007/s10459-012-9434-4
   Vaidya R, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P772, DOI 10.1109/ICICCT.2018.8473291
   Velasco JS, 2020, EAI SPRINGER INNOVAT, P119, DOI 10.1007/978-3-030-20904-9_9
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Xiao S, 2020, MULTIMED TOOLS APPL, V79, P17245, DOI 10.1007/s11042-019-7423-9
   Yao ZJ, 2016, EXPERT SYST APPL, V51, P26, DOI 10.1016/j.eswa.2015.12.019
   Zhao MY, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107588
NR 34
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 11
PY 2023
DI 10.1007/s11042-023-15767-2
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G1LI4
UT WOS:000986851800013
OA hybrid
DA 2024-07-18
ER

PT J
AU Loukil, H
   Mayet, AM
AF Loukil, Hassen
   Mayet, Abdulilah Mohammad
TI Hardware implementation and validation of the fast variable block size
   motion estimation architecture for HEVC Standard
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Motion estimation; Diamond search pattern; Embedded video; VHDL;
   FPGA
ID DIAMOND SEARCH ALGORITHM
AB High-Efficiency Video Coding (HEVC) has become popular according to its excellent coding performance, in particular in the case of high-resolution video applications. However, the significant gain in performance is accompanied by a higher encoding complexity compared to the H.264/AVC standard. The motion estimation (ME) is the most time-consuming part that removes temporal redundancy. To reduce the motion estimation complexity, many fast algorithms have been developed in order to minimize search positions and speed up computation but they do not take into account how they can be effectively implemented by hardware. This paper presents a design for the fast ME algorithm with a variable block size of HEVC standard which is the "TZ search". The design is described in VHDL language and synthesized to Altera Stratix III FPGA. The hardware architecture throughput reaches a processing rate up to 78 million pixels per second at 100 MHz. For the validation proposed design, an IP core is presented using the embedded video system on a programmable chip (SoPC). Finally, compared to other designs existing in the literature, the proposed architecture shows more efficiency in terms of hardware cost and improved performance. This design can be used in ultra-high-definition real-time TV coding (UHD) applications.
C1 [Loukil, Hassen; Mayet, Abdulilah Mohammad] King Khalid Univ, Coll Engn, Elect Engn Dept, Abha 61411, Saudi Arabia.
   [Loukil, Hassen] Univ Sfax, Natl Engn Sch Sfax, Elect & Informat Technol Lab, Sfax, Tunisia.
C3 King Khalid University; Universite de Sfax; Ecole Nationale dIngenieurs
   de Sfax (ENIS)
RP Loukil, H (corresponding author), King Khalid Univ, Coll Engn, Elect Engn Dept, Abha 61411, Saudi Arabia.; Loukil, H (corresponding author), Univ Sfax, Natl Engn Sch Sfax, Elect & Informat Technol Lab, Sfax, Tunisia.
EM hloukil@kku.edu.sa
RI Mayet, Abdulilah/GSI-6875-2022; HASSEN, LOUKIL/HTO-1134-2023
OI HASSEN, LOUKIL/0000-0002-2028-3517
FU Deanship of Scientific Research at King Khalid University [RGP2/39/44]
FX The authors extend their appreciation to the Deanship of Scientific
   Research at King Khalid University for funding this work through large
   group Research Project under grant number~RGP2/39/44.
CR Alcocer E, 2019, J REAL-TIME IMAGE PR, V16, P547, DOI 10.1007/s11554-016-0572-4
   [Anonymous], SOPC BUILDER
   [Anonymous], ALTERA DE1 SOC DEV K
   [Anonymous], MODELSIM
   [Anonymous], NIOS 2 INTEGRATED DE
   Bross B, 2012, 003 JCT VCHI
   Byun J, 2013, ELECTRON LETT, V49, P1142, DOI 10.1049/el.2013.0936
   Cheung CH, 2002, IEEE T CIRC SYST VID, V12, P1168, DOI 10.1109/TCSVT.2002.806815
   Dinh C., 2017, J TELECOMMUN ELECT C, V9, P1
   Dinh C, 2017, J TELECOMMUN ELECT C
   Gallant M, 1999, IEEE T IMAGE PROCESS, V8
   Gogoi S, 2021, J REAL-TIME IMAGE PR, V18, P953, DOI 10.1007/s11554-020-01056-w
   Hosur P, 1999, P 2 INT C INF COMM S, P7
   Jia L., 2018, IEEE T CIRC SYST VID, V1, P1
   Joginipelly AK, 2020, INT J CIRC THEOR APP, V48, P809, DOI 10.1002/cta.2775
   Joginipelly AK, 2019, MICROPROCESS MICROSY, V71, DOI 10.1016/j.micpro.2019.102852
   Joint Collaborative Team on Video Coding (JCT-VC), 2017, HIGH EFF VID COD HEV
   Khemiri R, 2018, ANALOG INTEGR CIRC S, V94, P259, DOI 10.1007/s10470-017-1072-6
   Kibeya H, 2014, 2014 1ST INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP 2014), P95, DOI 10.1109/ATSIP.2014.6834584
   Kim T, 2020, INFECT DIS-NOR, V52, P207, DOI 10.1080/23744235.2019.1701198
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Lian ZC, 2014, I S BIOMED IMAGING, P17, DOI 10.1109/ISBI.2014.6867798
   Medhat A, 2015, MIDWEST SYMP CIRCUIT
   Medhat A, 2014, 2014 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P280, DOI 10.1109/APCCAS.2014.7032774
   Mukherjee A., 2021, PROC 2021 IEEE 18 IN, P1, DOI [10.1109/INDICON52576.2021.9691531, DOI 10.1109/INDICON52576.2021.9691531]
   Nalluri P, 2014, IEEE IMAGE PROC, P1233, DOI 10.1109/ICIP.2014.7025246
   Nalluri P, 2013, INTERNATIONAL SYMPOSIUM ON SYSTEM-ON-CHIP (SOC)
   Thang NV, 2017, 2017 4TH NAFOSTED CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), P319, DOI 10.1109/NAFOSTED.2017.8108085
   Pakdaman F, 2018, P 7 EUR WORKSH VIS I, P1
   Nguyen P, 2014, 2014 IEEE FIFTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P434, DOI 10.1109/CCE.2014.6916744
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Purnachand N., 2012, 2012 IEEE Second International Conference on Consumer Electronics - Berlin (ICCE-Berlin), P34, DOI 10.1109/ICCE-Berlin.2012.6336494
   Richardson IE., 2002, VIDEO CODEC DESIGN, P99, DOI 10.1002/0470847832
   Samet, 2006, 2 S COMM CONTR SIGN, P13
   Sampaio F., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P657, DOI 10.1109/ICME.2012.37
   Singh K, 2018, IEEE T CONSUM ELECTR, V64, P267, DOI 10.1109/TCE.2018.2867823
   Tourapis AM, 2002, PROC SPIE, V4671, P1069, DOI 10.1117/12.453031
   Tourapis AM, 2001, P VIS COMM FRAM PROC
   Tseng YH, 2019, IEEE INT SYMP CIRC S
   VIDYALEKSHMI VG, 2014, INT C REC ADV INN EN, P1, DOI DOI 10.1109/ICRAIE.2014.6909136
   Werda I, 2007, IJCSNS INT J COMP SC, V7
   Ye X, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P205, DOI 10.1109/VCIP.2014.7051540
   Yoo HM, 2013, IEEE ICCE, P300, DOI 10.1109/ICCE.2013.6486903
   Yuan X, 2013, P IEEE INT S IND EL, P1, DOI DOI 10.1109/ASICON.2013.6811845
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 46
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46331
EP 46349
DI 10.1007/s11042-023-15628-y
EA MAY 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000985378600001
DA 2024-07-18
ER

PT J
AU Vanambathina, SD
   Anumola, V
   Tejasree, P
   Divya, R
   Manaswini, B
AF Vanambathina, Sunny Dayal
   Anumola, Vaishnavi
   Tejasree, Ponnapalli
   Divya, R.
   Manaswini, B.
TI Convolutional gated recurrent unit networks based real-time monaural
   speech enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech enhancement; Deep learning; Discrete cosine transform; Signal to
   noise ratio
ID MASKING; NOISE
AB Deep-learning based speech enhancement included many applications like improving speech intelligibility and perceptual quality. There are many methods which focus on amplitude spectrum enhancement. In the existing models, computation of the complex layer is huge which leads to a very big challenge to the device. DFT data is complex valued, so computation is difficult since we need to deal with the both real and imaginary parts of the signal at the same time. To reduce the computation, some researchers use the variants of STFT as input, such as amplitude/energy spectrum, Log-Mel spectrum, etc. They all enhance amplitude spectrum without estimating clean phase, this would limit the enhancement performance. In the proposed method DCT is used which is real-valued transformation without information lost and contains implicit phase. This avoids the problem of manually design a complex network to estimate the explicit phase and it will improve the enhancement performance. More research have done on phase spectrum estimation directly and indirectly, but it is not ideal. Recently, complex valued models are proposed like deep complex convolution recurrent network (DCCRN). The computation of the model is very huge. So a Deep Cosine transform convolutional Gated recurrent Unit (DCTCGRU) is proposed to reduce the complexity and improve further performance. GRU can well model the correlation between adjacent frames of noisy speech. The results from the experiment show that DCTCGRU achieves better results in terms of SNR, PESQ and STOI compared with the state-of-the-art algorithms.
C1 [Vanambathina, Sunny Dayal; Anumola, Vaishnavi; Tejasree, Ponnapalli; Divya, R.] Vellore Inst Technol, Dept Elect & Commun Engn, Andhra Pradesh VIT AP, Amaravathi 522237, India.
   [Manaswini, B.] Lakireddy Balireddy Coll Engn, Comp Sci & Engn Dept, Myalavaram, India.
C3 VIT-AP University
RP Vanambathina, SD (corresponding author), Vellore Inst Technol, Dept Elect & Commun Engn, Andhra Pradesh VIT AP, Amaravathi 522237, India.
EM sunny.dayal@vitap.ac.in; vaishnavi.19bes7016@vitap.ac.in;
   tejasree.19bec7002@vitap.ac.in; divya.19bev7039@vitap.ac.in;
   manaswini.burra@gmail.com
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599
   [Anonymous], 1993, NASA STIRECON TECH R, V93, DOI DOI 10.6028/NIST.IR.4930
   Chen D, 2021, IEEE T NEUR NET LEAR, P12
   Choi H.-S., 2018, INT C LEARN REPR
   Delfarah M, 2017, IEEE-ACM T AUDIO SPE, V25, P1085, DOI 10.1109/TASLP.2017.2687829
   Erdogan H, 2015, INT CONF ACOUST SPEE, P708, DOI 10.1109/ICASSP.2015.7178061
   Geng C., 2020, 2020 IEEE INT C ARTI, P379
   Hao X, 2020, IEEE INT C AC SPEECH, P312
   Hu GN, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P79, DOI 10.1109/ASPAA.2001.969547
   Hu YX, 2020, INTERSPEECH, P2472, DOI 10.21437/Interspeech.2020-2537
   Khan AT, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-020-3073-5
   Kolbæk M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5059, DOI 10.1109/ICASSP.2018.8462040
   Kumar A., 2017, P INT SOC MUS INF RE, P745
   Kumar S, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Kumari Shreya, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P339, DOI 10.1007/978-3-030-67187-7_35
   Kutner M.H., 2004, APPL LINEAR STAT MOD
   Le Roux J, 2019, INT CONF ACOUST SPEE, P626, DOI 10.1109/ICASSP.2019.8683855
   Lei YM, 2022, IEEE-CAA J AUTOMATIC, V9, P1233, DOI 10.1109/JAS.2022.105668
   Li ZB, 2023, IEEE T NEUR NET LEAR, V34, P8778, DOI 10.1109/TNNLS.2022.3153039
   Li ZB, 2021, IEEE-CAA J AUTOMATIC, V8, P23, DOI 10.1109/JAS.2020.1003381
   Liu QJ, 2017, EUR SIGNAL PR CONF, P1270, DOI 10.23919/EUSIPCO.2017.8081412
   Lu HY, 2019, IEEE T IND INFORM, V15, P5931, DOI 10.1109/TII.2019.2909142
   Luo Y, 2019, IEEE-ACM T AUDIO SPE, V27, P1256, DOI 10.1109/TASLP.2019.2915167
   Macartney Weyde T, 2018, ARXIV
   Martín-Doñas JM, 2018, IEEE SIGNAL PROC LET, V25, P1680, DOI 10.1109/LSP.2018.2871419
   Negi A., 2021, INT C BIG DATA ANALY, P296, DOI DOI 10.1007/978-3-030-93620-4_21
   Paliwal K, 2011, SPEECH COMMUN, V53, P465, DOI 10.1016/j.specom.2010.12.003
   Pandey A, 2021, IEEE-ACM T AUDIO SPE, P29
   Pascual S., 2017, arXiv
   Reddy C. K., 2020, arXiv
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandhya Pasala, 2022, 2022 6th International Conference on Computing Methodologies and Communication (ICCMC), P1723, DOI 10.1109/ICCMC53470.2022.9753764
   Scalart P, 1996, INT CONF ACOUST SPEE, P629, DOI 10.1109/ICASSP.1996.543199
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Sharma S, 2019, ADV INTELL SYST COMP, V748, P423, DOI 10.1007/978-981-13-0923-6_37
   Shivakumar PG, 2016, INTERSPEECH, P3743, DOI 10.21437/Interspeech.2016-1284
   Srinivasan S, 2006, SPEECH COMMUN, V48, P1486, DOI 10.1016/j.specom.2006.09.003
   Srinivasu PN, 2021, J REAL-TIME IMAGE PR, V18, P1773, DOI 10.1007/s11554-021-01122-x
   Srinivasu PN, 2022, MOB INF SYST, P36
   Tan K, 2019, INT CONF ACOUST SPEE, P6865, DOI 10.1109/ICASSP.2019.8682834
   Tan K, 2018, INTERSPEECH, P3229
   TUKEY JW, 1949, BIOMETRICS, V5, P99, DOI 10.2307/3001913
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Vijayvergia A, 2018, C INF COMM TECHN CIC, P26
   Vijayvergia A, 2021, MULTIMED TOOLS APPL, V80, P28349, DOI 10.1007/s11042-021-10997-8
   Wang Huaqing, 2022, IEEE T INSTRUM MEAS, V71
   Wang W, 2022, IEEE GEOSCI REMOTE S, V19
   Wang YX, 2014, IEEE-ACM T AUDIO SPE, V22, P1849, DOI 10.1109/TASLP.2014.2352935
   Williamson DS, 2016, IEEE-ACM T AUDIO SPE, V24, P483, DOI 10.1109/TASLP.2015.2512042
   Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240
   Yang X, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3122330
   Zhang OBY, 2017, DEEP COMPLEX NETWORK
NR 53
TC 0
Z9 0
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45717
EP 45732
DI 10.1007/s11042-023-15639-9
EA MAY 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000983956900001
DA 2024-07-18
ER

PT J
AU Sehrawat, P
   Chawla, M
AF Sehrawat, Preeti
   Chawla, Mridul
TI Performance Evaluation of Machine Learning Algorithms applied in
   SD-VANET for Efficient Transmission of Multimedia Information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SDVANET; ML Algorithms; Multimedia information; Confusion matrix; AUC
AB For the advancement of technologies in vehicular industry, an intelligent Software Defined Vehicular Ad-hoc Network (SDVANET) which decoupled its data and control plane providing a golden opportunity to the researchers and academicians working in the related field. The limitation associated with SDVANET lies in the fact that it has problem in transferring reliable multimedia information among different users. To address this limitation, researchers of the domain tried to provide more intelligence to SDVANET by deploying Machine Learning (ML) algorithms to this network. This deployment of ML algorithms provided a safe, reliable, secure, optimal methodology for transferring multimedia information among SDVANET networks. In this work, researchers have used two datasets: small dataset and big dataset according to number of iterations used for collection. Total six supervised ML algorithms: Random Forest (RF), Decision-Tree (DT), Logistic Regression (LR), Naive-Bayes (NB), Support Vector Machine (SVM), K-Nearest Neigbour (kNN) are chosen to participate in the training and testing process. For result analysis, two simulation parameters: Receiver operating characteristic-Area under the ROC curve (ROC-AUC) and Confusion matrix are utilized. Numerical Results: Classification Accuracy (CA) (88.3%), F1-Measure (89.3%), precision (94.3%), recall (93.3%), AUC (92.3%) indicate that ML algorithms used for small dataset (LR, SVM and NB), NB is outperforming and ones used for big dataset (DT, RF and kNN), DT gives best performance based on numerical results: CA (95.4%), F1-Measure (93.4%), precision (92.3%), recall (98.2%), AUC (94.9%). So, NB and DT are the best ML algorithms for transferring the secure multimedia information, avoiding accidents among SDVANET networks.
C1 [Sehrawat, Preeti] MSIT, Dept ECE, DCRUST Murthal, New Delhi, India.
   [Chawla, Mridul] Dept ECE, DCRUST, Murthal, India.
C3 Maharaja Surajmal Institute of Technology; Deenbandhu Chhotu Ram
   University of Science & Technology; Deenbandhu Chhotu Ram University of
   Science & Technology
RP Sehrawat, P (corresponding author), MSIT, Dept ECE, DCRUST Murthal, New Delhi, India.
EM preeti.sehrawat89@gmail.com; mridulchawla.ece@dcrustm.org
CR Abdullah D.M., 2021, Qubahan Academic Journal, V1, P81, DOI DOI 10.48161/QAJ.V1N2A50
   Adbeb T, 2020, INT J ADV COMPUT SC, V11, P706
   Ahuja N, 2021, J NETW COMPUT APPL, V187, DOI 10.1016/j.jnca.2021.103108
   Ali J, 2020, I C INF COMM TECH CO, P515, DOI 10.1109/ICTC49870.2020.9289504
   Alsarhan A, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-02963-x
   Anbalagan S, 2021, IEEE INTERNET THINGS, V8, P13950, DOI 10.1109/JIOT.2021.3069642
   Balkus SV, 2022, IEEE COMMUN SURV TUT, V24, P1280, DOI 10.1109/COMST.2022.3149714
   Bangui H, 2022, COMPUTING, V104, P503, DOI 10.1007/s00607-021-01001-0
   Bonaccorso G., 2017, MACHINE LEARNING ALG
   Chen JN, 2009, EXPERT SYST APPL, V36, P5432, DOI 10.1016/j.eswa.2008.06.054
   Ghonge MM, 2022, 2021 IFIPIEEE INT S, P33, DOI [10.1007/978-3-030-91149-2_2, DOI 10.1007/978-3-030-91149-2_2]
   GUPTA B, 2022, 2022 IEEE INT C CONS, P1, DOI DOI 10.1109/TITS.2022.3174333
   Huang J, 2005, IEEE T KNOWL DATA EN, V17, P299, DOI 10.1109/TKDE.2005.50
   Islam MM, 2021, J SYST ARCHITECT, V114, DOI 10.1016/j.sysarc.2020.101961
   Jaballah WB, 2019, ARXIV PREPRINT ARXIV, p1904.04577, DOI [10.48550/arXiv.1904.04577, DOI 10.48550/ARXIV.1904.04577]
   Javaheri D, 2023, INFORM SCIENCES, V626, P315, DOI 10.1016/j.ins.2023.01.067
   Jiang T, 2020, BEHAV THER, V51, P675, DOI 10.1016/j.beth.2020.05.002
   Jordan SM, 2020, PR MACH LEARN RES, V119
   Khatri S, 2021, PEER PEER NETW APPL, V14, P1778, DOI 10.1007/s12083-020-00993-4
   Lee W.-M., 2019, PYTHON MACHINE LEARN, P269, DOI [10.1002/9781119557500.ch12, DOI 10.1002/9781119557500.CH12]
   Liang L, 2019, IEEE INTERNET THINGS, V6, P124, DOI 10.1109/JIOT.2018.2872122
   Mahalakshmi G, 2020, INT C ART INT NETW S
   Nayak RP, 2023, MULTIMED TOOLS APPL, V82, P3931, DOI 10.1007/s11042-022-13440-8
   Anyanwu GO, 2023, IEEE INTERNET THINGS, V10, P8477, DOI 10.1109/JIOT.2022.3199712
   Osisanwo F., 2017, Int. J. Comput. Trends Technol., V48, P128, DOI [DOI 10.14445/22312803/IJCTT-V48P126, 10.14445/22312803/ijctt-v48p126]
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Raju MA, 2022, MOBILE COMPUTING SUS, P641, DOI [10.1007/978-981-19-2069-1_44, DOI 10.1007/978-981-19-2069-1_44]
   Raw RS, 2021, CLOUD BASED BIG DATA, P141, DOI [10.4018/978-1-7998-2764-1.ch007, DOI 10.4018/978-1-7998-2764-1.CH007]
   Schein AI, 2007, MACH LEARN, V68, P235, DOI 10.1007/s10994-007-5019-5
   Sehrawat P, 2020, NAT C MED INSTR BIOM, P130
   Sehrawat P, 2022, ADV COMPUT ELECTR EN, P1
   Sehrawat P, 2021, 2021 26 IEEE INT C E, P1
   Seth I., 2022, ECS T, V107, P8395, DOI [10.1149/10701.8395ecst, DOI 10.1149/10701.8395ECST]
   Shobowale KO., 2023, INT J SOFTWARE ENG C, V9, P27, DOI [10.15282/ijsecs.9.1.2023.3.0107, DOI 10.15282/IJSECS.9.1.2023.3.0107]
   Singh A, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P1310
   Somvanshi M., 2016, INT C COMPUT COMMUN, P748
   Sultana R, 2020, IEEE I C ADV NETW TE, DOI 10.1109/ANTS50601.2020.9342778
   Teixeira Daniel, 2022, Advances in Information and Communication: Proceedings of the 2022 Future of Information and Communication Conference (FICC). Lecture Notes in Networks and Systems (439), P339, DOI 10.1007/978-3-030-98015-3_23
   Usama M, 2019, IEEE ACCESS, V7, P65579, DOI 10.1109/ACCESS.2019.2916648
   Visa S., 2011, Maics, V710, P120
   Wang J, 2022, CITIES, V129, DOI 10.1016/j.cities.2022.103925
   Xie JF, 2019, IEEE COMMUN SURV TUT, V21, P393, DOI 10.1109/COMST.2018.2866942
   Yanli Liu, 2012, Information Computing and Applications. Proceedings of the Third International Conference, ICICA 2012, P246, DOI 10.1007/978-3-642-34062-8_32
   Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508
   Zhang SY, 2021, COMPUT COMMUN, V180, P126, DOI 10.1016/j.comcom.2021.09.005
NR 45
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45317
EP 45344
DI 10.1007/s11042-023-15244-w
EA APR 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000978477000001
DA 2024-07-18
ER

PT J
AU Lal, KN
AF Lal, Kumari Nidhi
TI A lung sound recognition model to diagnoses the respiratory diseases by
   using transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Energy; Wireless sensor network; Performance
   analysis
ID CLASSIFICATION
AB Respiratory disease is one of the leading causes of death in the world. Through advances in Artificial Intelligence, it appears possible for the days of misdiagnosis and treatment of respiratory disease symptoms rather than their root cause to move behind us. The traditional convolutional neural network cannot extract the temporal features of lung sounds. To solve the problem, a lung sounds recognition algorithm based on VGGish- stacked BiGRU is proposed which combines the VGGish network with the stacked bidirectional gated recurrent unit neural network. A lung Sound Recognition Algorithm Based on VGGish-Stacked BiGRU is used as a feature extractor which is a pre-trained model used for transfer learning. The target model is built with the same structure as the source model which is the VGGish model and parameter transfer is done from the source model to the target model. The multi-layer BiGRU stack is used to enhance the feature value and retain the model. While fine-tuning of the parameter of VGGish is frozen which successfully improves the model. The experimental results show that the proposed algorithm improves the recognition accuracy of lung sounds and the recognition accuracy of respiratory diseases.
C1 [Lal, Kumari Nidhi] Visvesvaraya Natl Inst Technol VNIT Nagpur, Dept Comp Sci Engn, Nagpur, Maharashrta, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur
RP Lal, KN (corresponding author), Visvesvaraya Natl Inst Technol VNIT Nagpur, Dept Comp Sci Engn, Nagpur, Maharashrta, India.
EM nidhilal@cse.vnit.ac.in
CR Ahmed J., 2020, BILDVERARBEITUNG F U, V1, P39, DOI [DOI 10.1007/978-3-658-29267-6_8, 10.1007/978-3-658-29267-6_8]
   Amaral JLM, 2011, COMPUT METH PROG BIO
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   Fernandez-Granero MA, 2018, BIOTECHNOL BIOTEC EQ, V32, P778, DOI 10.1080/13102818.2018.1437568
   Aydin N, 2000, Eur J Ultrasound, V12, P69, DOI 10.1016/S0929-8266(00)00104-X
   Aykanat M, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0213-2
   Bardou D, 2018, ARTIF INTELL MED, V88, P58, DOI 10.1016/j.artmed.2018.04.008
   Bargshady G, 2022, PATTERN RECOGN LETT, V153, P67, DOI 10.1016/j.patrec.2021.11.020
   Dredge S, 2009, AUSCULTATION
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Haider NS, 2020, INT J INNOV TECHNOL, V10, P10
   Hirra I, 2021, IEEE ACCESS, V9, P24273, DOI 10.1109/ACCESS.2021.3056516
   Huang RQ, 2006, IEEE T AUDIO SPEECH, V14, P907, DOI 10.1109/TSA.2005.858057
   KANDASWAMY A, 2004, NEURAL CLASSIFICATIO
   Li Longsheng., 2017, Opto-Electronics and Communications Conference (OECC) and Photonics Global Conference (PGC), 2017, P1
   Mansi G, 2022, ARXIV
   Nagabandi A, 2018, IEEE INT CONF ROBOT, P7579
   Palaniappan R, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-223
   Rekha M, 2019, CHURNING CONFUSION O
   Roda CAN, 2019, B C MED J, V61, P128
   Ruder S., 2016, ARXIV
   Sai AL, 2021, AMCIS 2021 P, V11
   Sai Ambati L., 2020, Issues Inform Syst, V21, P103
   Sarkar D.D, 2018, DATA SCI
   Sharma Neha., 2021, GLOBAL TRANSITIONS P, V2, P24, DOI [DOI 10.1016/J.GLTP.2021.01.004, 10.1016/j.gltp.2021.01.004]
   Shewalkar A, 2019, J ARTIF INTELL SOFT, V9, P235, DOI 10.2478/jaiscr-2019-0006
   SHI L, 2019, LUNG SOUND RECOGNITI
   Nguyen T, 2022, IEEE T BIO-MED ENG, V69, P2872, DOI 10.1109/TBME.2022.3156293
   Nguyen T, 2021, IEEE ENG MED BIO, P80, DOI 10.1109/EMBC46164.2021.9630577
   Yang X-K, 2018, DIGIT SIGNAL PROCESS
   Yin X, 2021, J PHYS C SER
NR 31
TC 4
Z9 4
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36615
EP 36631
DI 10.1007/s11042-023-14727-0
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000960423600014
PM 37362727
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Laxmisagar, HS
   Hanumantharaju, MC
AF Laxmisagar, H. S.
   Hanumantharaju, M. C.
TI FPGA implementation of breast cancer detection using SVM linear
   classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast Cancer; SVM; IEEE 754 format; Vivado tool; Verilog HDL; FPGA
ID ARCHITECTURE
AB The Support Vector Machine (SVM) can be used to perform linear and nonlinear operations to solve regression and classification problems. The SVM algorithm is straightforward, generating a line or a hyperplane that can be used for separating different classes of data. However, due to its high computational complexity, SVM is a time-consuming algorithm when modeled solely with software. Various researchers attempted to implement SVM in hardware particularly on field-programmable gate array (FPGA) platforms in order to achieve high performance at lower cost and power consumption. As a result, the algorithm is unsuitable for embedded real-time applications. Therefore, SVM linear classifier is implemented on hardware which decreases the latency and executes the task in real time. In this paper, an SVM linear classifier with pipeline architecture is proposed for fast processing in Verilog HDL using a single-precision IEEE standard 754 number format. In order to perform a study related to hardware resource utilization and timing for the WBCD breast cancer datasets. The various performance metrics such as resource utilization, on-chip power consumption, and static timing analysis with constraints are evaluated. The accuracy rate is computed both using software and hardware for performance evaluation. The pipelined SVM architecture is designed using Verilog HDL, and then it is synthesized using the Vivado simulation tool. The design is configured to the Xilinx KC705 Kintex-7 evaluation board for implementation. This paper mainly focuses on the design of an SVM linear classifier with pipelined architecture for FPGA implementation. The FPGA-based two-class SVM classifier can perform fast data classification due to the advanced parallel calculation feature provided by FPGA. The classification system operates in a linear fashion. The simulation and synthesis results show that the SVM linear classification system can be able to classify data effectively.
C1 [Laxmisagar, H. S.] BMS Inst Technol Management, Dept Elect & Commun Engn, Bengaluru, India.
RP Laxmisagar, HS (corresponding author), BMS Inst Technol Management, Dept Elect & Commun Engn, Bengaluru, India.
EM sagar8.hs@bmsit.in
RI Raju, Hanumantha/N-9205-2017
OI Raju, Hanumantha/0000-0001-5549-2522
CR Adamowicz E, 2002, SUPPORT VECTOR MACHI
   Afifi S., 2020, SN Comput. Sci., V1, P133, DOI [10.1007/ s42979-020-00128-9, DOI 10.1007/S42979-020-00128-9, 10.1007/s42979-020-00128-9]
   Afifi S, 2019, MICROPROCESS MICROSY, V65, P57, DOI 10.1016/j.micpro.2018.12.005
   Amezzane I, 2020, APPL NUMER HARMON AN, P131, DOI 10.1007/978-3-030-35202-8_7
   Baez A, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121494
   Bassoli M, 2019, LECT NOTES ELECT ENG, P1
   Bassoli M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051362
   Batista GC, MICROELECTRON J
   Blaiech AG, 2019, J SYST ARCHITECT, V98, P331, DOI 10.1016/j.sysarc.2019.01.007
   Carmichael Z, 2019, CONFERENCE FOR NEXT GENERATION ARITHMETIC 2019 (CONGA), DOI 10.1145/3316279.3316282
   Carmichael Z, 2019, DES AUT TEST EUROPE, P1421, DOI [10.23919/date.2019.8715262, 10.23919/DATE.2019.8715262]
   Chen W, 2017, GEODERMA, V305, P314, DOI 10.1016/j.geoderma.2017.06.020
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dou YF, 2021, FRONT BIOENG BIOTECH, V9, DOI 10.3389/fbioe.2021.698390
   Fiolhais L, 2018, I C FIELD PROG LOGIC, P327, DOI 10.1109/FPL.2018.00062
   kaggle, Breast Cancer Wisconsin (Diagnostic) Data Set
   Khan F, 2020, J HEALTHC ENG, V2020, DOI 10.1155/2020/8017496
   Kim S, 2019, PR GR LAK SYMP VLSI, P87, DOI 10.1145/3299874.3318002
   Lopes FE, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8060631
   Louca L, 1996, IEEE SYMPOSIUM ON FPGAS FOR CUSTOM COMPUTING MACHINES, PROCEEDINGS, P107, DOI 10.1109/FPGA.1996.564761
   Mavroforakis ME, 2006, IEEE T NEURAL NETWOR, V17, P671, DOI 10.1109/TNN.2006.873281
   Mohammadi M, 2018, IEEE T PARALL DISTR, V29, P481, DOI 10.1109/TPDS.2017.2768366
   Nadikattu RR, 2020, 3615092 SSRN
   Papadonikolakis M., 2010, Proceedings 2010 International Conference on Field-Programmable Technology (FPT 2010), P283, DOI 10.1109/FPT.2010.5681485
   Papadonikolakis M, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY, P337, DOI 10.1109/FPT.2008.4762412
   Patil PP., 2020, NOVEL APPROACH DETEC
   Pietron M, 2013, LECT NOTES COMPUT SC, V7767, P292, DOI 10.1007/978-3-642-36424-2_25
   Baccarini LMR, 2011, EXPERT SYST APPL, V38, P6980, DOI 10.1016/j.eswa.2010.12.017
   Ragab DA, 2021, COMPUT BIOL MED, V131, DOI 10.1016/j.compbiomed.2021.104245
   Selvathi D, 2016, INTELL DECIS TECHNOL, V10, P341, DOI 10.3233/IDT-160261
   Siddiqui F, 2019, J IMAGING, V5, DOI 10.3390/jimaging5010016
   Subasi A., 2020, Practical Machine Learning for Data Analysis Using Python, DOI DOI 10.1016/C2019-0-03019-1
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Yao YK, 2013, J COMPUT, V8, P2632, DOI 10.4304/jcp.8.10.2632-2639
   [Yue Shihong 岳士弘], 2003, Applied Mathematics. Series B, A Journal of Chinese Universities, V18, P332, DOI 10.1007/s11766-003-0059-5
NR 35
TC 0
Z9 0
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41105
EP 41128
DI 10.1007/s11042-023-15121-6
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000960423600009
DA 2024-07-18
ER

PT J
AU Rajitha, B
   Makhija, N
AF Rajitha, B.
   Makhija, Nishkarsh
TI Secured image storage and transmission technique suitable for IoT using
   Tangle and a novel image encryption technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; Blockchain; Tangle; NPCR; Correlation; UACI; RC4
   algorithm; S-Box
ID CHAOTIC SYSTEM; ALGORITHM; BLOCKCHAIN; TRANSFORM; INTERNET; THINGS;
   MODEL; MAP
AB In the recent years, there has been tremendous growth in the use of IoT based applications. It is making its footprint strong with day to day life uses as well as industrial uses. IoT has vast applications ranging from medical, automobile industry, daily task automation, security surveillance and a lot more. Surveillance based IoT system shares images over internet for information exchange between filed experts and technical members for faster analysis about the locations and if it has any unauthorized activity. So these image information exchange should be secured. Thus this paper proposes a new technique for achieving this task in two phases. In first phase the secret/informative image is encrypted using a novel encryption technique. In second phase this encrypted image is shared to receiver team using a highly secured Tangle(latest secured transmission model advanced from Blockchain).Tangle eliminates the drawback of the traditional blockchain while providing its security features like decentralization, high reliability, and low cost to transfer and store users image information data. Tangle can be combined with IoT to make it more stronger. The proposed method has been tested on various images and its performance has been compared using standard metrics such as Correlation, number of pixels change rate (NPCR), the unified average changed intensity(UACI), information entropy analysis, key space analysis, etc. The proposed technique was found to be better than literature methods like the entropy value is near to an ideal value 8, which is considered safe from brute force attack.
C1 [Rajitha, B.; Makhija, Nishkarsh] Motilal Nehru Natl Inst Technol Allahabad, Allahabad, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Rajitha, B (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Allahabad, India.
EM rajitha@mnnit.ac.in; nishkarsh.makhija@gmail.com
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Arroyo D, 2008, CHAOS, V18, DOI 10.1063/1.2959102
   Bauer DP, 2022, GETTING STARTED ETHE, P83
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Dai HN, 2019, IEEE INTERNET THINGS, V6, P8076, DOI 10.1109/JIOT.2019.2920987
   Elkandoz MT, 2022, MULTIMED TOOLS APPL, V81, P25497, DOI 10.1007/s11042-022-12595-8
   Farwa S, 2017, INT J ADV COMPUT SC, V8, P360
   Fu C, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/2708532
   Geetha S, 2018, INT J INF SECUR PRIV, V12, P42, DOI 10.4018/IJISP.2018070104
   Hu XC, 2020, IEEE ACCESS, V8, P12452, DOI 10.1109/ACCESS.2020.2965740
   Hua ZY, 2019, IEEE T IND ELECTRON, V66, P1273, DOI 10.1109/TIE.2018.2833049
   Hua ZY, 2018, IEEE T IND ELECTRON, V65, P2557, DOI 10.1109/TIE.2017.2736515
   Javan AAK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113925
   Javan AAK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010254
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Khan PW, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020175
   Lerner S, 2015, DAGCOIN DRAFT UNPUB
   Li CQ, 2013, NONLINEAR DYNAM, V73, P2083, DOI 10.1007/s11071-013-0924-6
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1371, DOI 10.1016/j.imavis.2008.12.008
   Li YX, 2020, Arxiv, DOI arXiv:1905.10925
   Liu LF, 2017, MULTIMED TOOLS APPL, V76, P16511, DOI 10.1007/s11042-016-3925-x
   Lu Q, 2020, IEEE ACCESS, V8, P25664, DOI 10.1109/ACCESS.2020.2970806
   Mohanty SN, 2020, FUTURE GENER COMP SY, V102, P1027, DOI 10.1016/j.future.2019.09.050
   Nkandeu YPK, 2019, MULTIMED TOOLS APPL, V78, P10013, DOI 10.1007/s11042-018-6612-2
   Orhan K, 2021, IMAGNG SCI DENT, V51, P337, DOI 10.5624/isd.20210144
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Popov S., 2018, The tangle white paper
   Qian XL, 2021, IEEE ACCESS, V9, P61334, DOI 10.1109/ACCESS.2021.3073514
   Sadeghi D, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105554
   Shen M, 2019, IEEE NETWORK, V33, P27, DOI 10.1109/MNET.001.1800503
   Shoeibi A, 2022, Arxiv, DOI [arXiv:2205.15858, 10.1007/s11571-022-09897-w]
   Shoeibi A, 2022, LECT NOTES COMPUT SC, V13258, P145, DOI 10.1007/978-3-031-06242-1_15
   Silvano WF, 2020, FUTURE GENER COMP SY, V112, P307, DOI 10.1016/j.future.2020.05.047
   Singh P, 2017, OPT LASER ENG, V91, P187, DOI 10.1016/j.optlaseng.2016.11.022
   Szydlo M, 2004, LECT NOTES COMPUT SC, V3027, P541
   Wang XY, 2019, OPT LASER TECHNOL, V115, P42, DOI 10.1016/j.optlastec.2019.02.009
   Wang XY, 2018, OPT LASER ENG, V107, P370, DOI 10.1016/j.optlaseng.2017.06.015
   Wang XY, 2018, IEEE ACCESS, V6, P23733, DOI 10.1109/ACCESS.2018.2805847
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Yi LT, 2019, IEEE ACCESS, V7, P53079, DOI 10.1109/ACCESS.2019.2911395
   Zhou NR, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1612-0
   Zhu CX, 2018, IEEE ACCESS, V6, P18759, DOI 10.1109/ACCESS.2018.2817600
NR 46
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 21
PY 2023
DI 10.1007/s11042-023-14794-3
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A3XA1
UT WOS:000954480900007
DA 2024-07-18
ER

PT J
AU Suganya, S
   Meyyappan, T
AF Suganya, S.
   Meyyappan, T.
TI Prediction of the level of air pollution using adaptive neuro-fuzzy
   inference system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Air quality; Adaptive neuro-fuzzy inference system (ANFIS); Recurrent
   neural network (RNN); CO; NO2; O-3; PM2 5 and PM(10)grade
ID QUALITY IMPROVEMENT; TIME-SERIES; NETWORK; MODEL
AB Air pollution is a severe environmental issue that has garnered international attention. Air pollution forecasting is critical for daily health monitoring and government decision-making. Current study methodologies, on the other hand, have been unable to adequately separate the geographical features of air pollution concentration data, resulting in fast changes in long-term accuracy and air quality. Many techniques of air pollution detection are available which developed by researchers. However, these techniques are not achieved efficient accuracy. Hence, in this paperis develop a hybrid adaptive neuro-fuzzy inference system (ANFIS) and a recurrent neural network (RNN). The RNN technique used to calculate pollution load has a direct influence on quantifying pollution's impact on air quality and on the overall assessment results. As a result, the weight of each assessment criteria must be determined in a convoluted and thorough manner. This Fuzzy is engaged in air pollution assessments for CO, NO2, O-3, PM2.5 and PM10. In five types of hybrid model investigations, the suggested system's similarity was utilized to separate the three most acceptable climatic factors from six typical climatic characteristics (atmospheric pressure, relative humidity, air temperature, wind speed, wind direction, and total precipitation). The selected form, which included humidity, wind speed, and wind direction, provided high forecast accuracy. For each level of CO, NO2, O-3, PM2.5 and PM10, we also presented the accuracy, sensitivity, specificity, accuracy, susceptibility, and F1 scores to assess the ANFIS-RNN prediction outcomes. On Python platforms, design and deploy unique air pollution coding systems. Simultaneously, comparative investigations revealed that ANFIS-RNN outperforms ANN and RNN samples. The collected findings indicate the efficacy of air pollution forecast analysis for an effective air quality forecast.
C1 [Suganya, S.; Meyyappan, T.] Alagappa Univ, Dept Comp Sci, Karaikkudi, India.
C3 Alagappa University
RP Suganya, S (corresponding author), Alagappa Univ, Dept Comp Sci, Karaikkudi, India.
EM suganyasudhakar04@gmail.com; meyyappant@alagappauniversity.ac.in
FU RUSA-Phase 2.0 grant, Policy (TN Multi-Gen),Dept of Edn. Govt of India
   [F,24-51/2014-U]
FX This article has been written with the financial Support of RUSA-Phase
   2.0 grant sanctioned vide Letter NO.F,24-51/2014-U,Policy (TN
   Multi-Gen),Dept of Edn. Govt of India, Dt. 09.10.2018.
CR Athira V., 2018, Procedia Computer Science, V132, P1394, DOI 10.1016/j.procs.2018.05.068
   Chen W, 2019, J HYDROL, V572, P435, DOI 10.1016/j.jhydrol.2019.03.013
   Dincer NG, 2018, ECOL INFORM, V43, P157, DOI 10.1016/j.ecoinf.2017.12.001
   Fan C, 2019, APPL ENERG, V236, P700, DOI 10.1016/j.apenergy.2018.12.004
   Fan H, 2020, ATMOS ENVIRON, V220, DOI 10.1016/j.atmosenv.2019.117066
   Fan JL, 2018, RENEW SUST ENERG REV, V94, P732, DOI 10.1016/j.rser.2018.06.029
   Gu K, 2018, IEEE T IND INFORM, V14, P3946, DOI 10.1109/TII.2018.2793950
   Hao Y, 2019, APPL SOFT COMPUT, V74, P729, DOI 10.1016/j.asoc.2018.09.005
   Jiang P, 2019, KNOWL-BASED SYST, V164, P174, DOI 10.1016/j.knosys.2018.10.036
   Larkin A, 2017, Curr Environ Health Rep, V4, P463, DOI 10.1007/s40572-017-0163-y
   Li HM, 2019, J CLEAN PROD, V208, P1365, DOI 10.1016/j.jclepro.2018.10.129
   Li RR, 2019, APPL MATH MODEL, V65, P52, DOI 10.1016/j.apm.2018.07.052
   Li X, 2017, J CLEAN PROD, V168, P1381, DOI 10.1016/j.jclepro.2017.08.164
   Ma J, 2020, J CLEAN PROD, V244, DOI 10.1016/j.jclepro.2019.118955
   Mao WJ, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102567
   Qi ZG, 2018, IEEE T KNOWL DATA EN, V30, P2285, DOI 10.1109/TKDE.2018.2823740
   Shaddick G, 2018, J ROY STAT SOC C, V67, P231, DOI 10.1111/rssc.12227
   Sun D, 2018, RESOUR CONSERV RECY, V129, P416, DOI 10.1016/j.resconrec.2016.09.021
   Sun W, 2017, J ENVIRON MANAGE, V188, P144, DOI 10.1016/j.jenvman.2016.12.011
   Wang JZ, 2018, APPL SOFT COMPUT, V71, P783, DOI 10.1016/j.asoc.2018.07.030
   Wang JZ, 2017, EXPERT SYST APPL, V84, P102, DOI 10.1016/j.eswa.2017.04.059
   Wang JS, 2018, NEUROCOMPUTING, V314, P198, DOI 10.1016/j.neucom.2018.06.049
   Wu LF, 2018, J CLEAN PROD, V196, P682, DOI 10.1016/j.jclepro.2018.06.068
   Wu QL, 2019, SCI TOTAL ENVIRON, V683, P808, DOI 10.1016/j.scitotenv.2019.05.288
   Yang ZS, 2017, ENVIRON RES, V158, P105, DOI 10.1016/j.envres.2017.06.002
   Ye JB, 2022, ENG COMPUT-GERMANY, V38, P497, DOI 10.1007/s00366-020-01085-w
   Yu MF, 2019, J ENVIRON MANAGE, V244, P127, DOI 10.1016/j.jenvman.2019.05.046
   Yu WN, 2019, MECH SYST SIGNAL PR, V129, P764, DOI 10.1016/j.ymssp.2019.05.005
   Zhang Y, 2020, ISA T, V100, P210, DOI 10.1016/j.isatra.2019.11.023
   Zhao GY, 2019, IEEE ACCESS, V7, P134903, DOI 10.1109/ACCESS.2019.2941732
   Zhou YL, 2019, J CLEAN PROD, V209, P134, DOI 10.1016/j.jclepro.2018.10.243
NR 31
TC 3
Z9 3
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 18
PY 2023
DI 10.1007/s11042-023-15046-0
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A0QJ4
UT WOS:000952258900004
DA 2024-07-18
ER

PT J
AU Hore, S
   Bhattacharya, T
AF Hore, Sirshendu
   Bhattacharya, Tanmay
TI Impact of lockdown on Generation-Z: a fuzzy based multimodal emotion
   recognition approach using CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic information; CNN; Emotion; Facial expressions; Fuzzy;
   Generation-Z
ID FACIAL EXPRESSION RECOGNITION; NEURAL-NETWORK; SPEECH; ROBUST; MODEL;
   FACE
AB The primary direction of most of the research done so far on the effects of Lockdown due to pandemic have been limited to areas such as clinical studies, possible impact on the global economy, or issues related to migrant workers. However, during this period, little attempt has been made to understand the emotions of Generation Z, one of the prime victims of this pandemic. Members of this generation were born after 1996. So, most of them are studying in various schools, colleges, or universities. In the proposed work, the emotions of some students of an engineering college in West Bengal, India, have been analyzed. A multimodal approach has been applied to obtain vivid pictures of 74 students' minds. The valence-arousal inspired Organize-Split-Fuse (OSF) model has been proposed to achieve this objective. Two conventional Convolutional Neural Network (CNN) models have been employed separately, to classify human emotions using Acoustic Information (AcI) and Facial Expressions (FE) from the generated dataset. The employed models have achieved satisfactory performance (91% and 72.7% accuracy respectively) on the benchmark dataset. Afterward, classified emotions have been organized and split successfully. Finally, a fuzzy rule-based classification system has been used to fuse both emotions at the decision level. The results show that junior students have higher positivity and less Neutral emotions than the senior. In-depth analysis shows that boys are more apprehensive than girls while girls have a more optimistic outlook for the future. The year-wise observations show the chaotic state of students' minds.
C1 [Hore, Sirshendu] HETC, Dept CSE, Hooghly, India.
   [Bhattacharya, Tanmay] Techno Main Salt Lake, Dept IT, Kolkata, India.
RP Hore, S (corresponding author), HETC, Dept CSE, Hooghly, India.
EM shirshendu.hore@gmail.com; dr.tb1029@gmail.com
OI Hore, Sirshendu/0000-0002-6045-5352
CR Ali MNY, 2019, INT J AMBIENT COMPUT, V10, P92, DOI 10.4018/IJACI.2019070106
   Alizadeh S., 2017, Convolutional neural networks for facial expression recognition, DOI 10.48550/arXiv.1704.06756
   [Anonymous], Surrey Audio-Visual Expressed Emotion (SAVEE) Database
   Benitez-Quiroz CF, 2016, PROC CVPR IEEE, P5562, DOI 10.1109/CVPR.2016.600
   Boulmaiz A, 2017, INT J AMBIENT COMPUT, V8, P98, DOI 10.4018/IJACI.2017010105
   Breuer R., 2017, A deep learning perspective on the origin of facial expressions. arXiv preprint arXiv:1705.01842, DOI DOI 10.48550/ARXIV.1705.01842
   Chakraborty I, 2020, SCI TOTAL ENVIRON, V728, DOI 10.1016/j.scitotenv.2020.138882
   Chandrasekar R., 2016, Research Journal of Pharmacy and Technology, V9, P1299, DOI 10.5958/0974-360X.2016.00247.X
   Chen CR, 2011, IEEE T VLSI SYST, V19, P1937, DOI 10.1109/TVLSI.2010.2069575
   Covid-19 impact on young people and the youth sector, 2020, KNOWL HUB COVID 19 I
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Damasio A, 2003, NEW SCI, V180, P48
   Darwin C., 1872, P374
   de Pinto MG, 2020, IEEE CONF EVOL ADAPT, DOI 10.1109/eais48028.2020.9122698
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Fathallah A, 2017, I C COMP SYST APPLIC, P745, DOI 10.1109/AICCSA.2017.124
   Fong SJ, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106282
   Fong SJ, 2020, ARTIF INTELL, P23, DOI [10.1007/978-981-15-5936-5_2, DOI 10.1007/978-981-15-5936-5_2]
   Gasper K, 2018, EMOT REV, V10, P255, DOI 10.1177/1754073918765660
   Goodfellow IJ, 2015, NEURAL NETWORKS, V64, P59, DOI 10.1016/j.neunet.2014.09.005
   Gupta P, 2007, INTERSPEECH 2007: 8TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION, VOLS 1-4, P1037
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Iqbal A, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8852121
   Izard CE, 2007, PERSPECT PSYCHOL SCI, V2, P260, DOI [10.1111/j.1745-6916.2007.00044.x, 10.1111/j.1745-6916.2007.00053.x]
   Jain DK, 2019, PATTERN RECOGN LETT, V120, P69, DOI 10.1016/j.patrec.2019.01.008
   Jannat R, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC'18 ADJUNCT), P956, DOI 10.1145/3267305.3267689
   Kim DH, 2019, IEEE T AFFECT COMPUT, V10, P223, DOI 10.1109/TAFFC.2017.2695999
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Kuang YX, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106775
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Low LSA, 2011, IEEE T BIO-MED ENG, V58, P574, DOI 10.1109/TBME.2010.2091640
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Minaee S, 2019, Arxiv, DOI [arXiv:1902.01019, DOI 10.48550/ARXIV.1902.01019]
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Mohammadpour RA, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/564867
   Mohan K, 2021, NEURAL COMPUT APPL, V33, P9125, DOI 10.1007/s00521-020-05676-y
   Mohan K, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3031835
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Muda L, 2010, Arxiv, DOI arXiv:1003.4083
   Pichora-Fuller Kathleen M, 2020, Borealis, V1
   Pons G, 2018, IEEE T AFFECT COMPUT, V9, P343, DOI 10.1109/TAFFC.2017.2753235
   Robinson D.L., 2008, Neth. J. Psychol., V64, P152, DOI DOI 10.1007/BF03076418
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shao J, 2019, NEUROCOMPUTING, V355, P82, DOI 10.1016/j.neucom.2019.05.005
   Shinde Gitanjali R, 2020, SN Comput Sci, V1, P197, DOI 10.1007/s42979-020-00209-9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Socio-economic impact of COVID-19, 2020, BRIEFS REP
   Sun N, 2019, PATTERN RECOGN LETT, V119, P49, DOI 10.1016/j.patrec.2017.10.022
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Tzirakis P, 2019, COMPUT VIS PATT REC, P387, DOI 10.1016/B978-0-12-814601-9.00028-6
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang D, 2018, NEURAL COMPUT APPL, V29, P1087, DOI 10.1007/s00521-016-2512-4
   Watson D, 1999, J PERS SOC PSYCHOL, V76, P820, DOI 10.1037/0022-3514.76.5.820
   Whissell C., 1989, Emotion: Theory, Research and Experience: vol. 4, V4
   Yang NN, 2020, J INTELL FUZZY SYST, V39, P1925, DOI 10.3233/JIFS-179963
   Youth and COVID-19: Response Recovery and Resilience, 2020, OECD SURV COVID 19 Y
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang BQ, 2015, INT CONF AFFECT, P139, DOI 10.1109/ACII.2015.7344563
   Zhang D, 2009, IGI GLOBAL, P328, DOI [10.4018/978-1-60566-200-8.ch015, DOI 10.4018/978-1-60566-200-8.CH015]
   Zhao XY, 2016, LECT NOTES COMPUT SC, V9906, P425, DOI 10.1007/978-3-319-46475-6_27
   Zhong L, 2015, IEEE T CYBERNETICS, V45, P1499, DOI 10.1109/TCYB.2014.2354351
NR 69
TC 1
Z9 1
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33835
EP 33863
DI 10.1007/s11042-023-14543-6
EA MAR 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000945792800008
DA 2024-07-18
ER

PT J
AU Ge, ZK
   Ma, C
   Fu, ZM
   Song, SZ
   Si, PJ
AF Ge, Zekun
   Ma, Chao
   Fu, Zhumu
   Song, Shuzhong
   Si, Pengju
TI End-to-end lane detection with convolution and transformer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lane detection system; Transformer; Self-attention mechanism;
   Global-Local training strategy
ID LINE DETECTION; ALGORITHM; NETWORK; FUSION
AB In this paper, an end-to-end lane detection method based on the polynomial regression is proposed, combining CNNs and Transformer. Transformer proposes a self-attentive mechanism to model nonlocal interactions to capture global context. Then, an effective Global-Local training strategy is presented to capture a multi-scale feature, which is capable of capturing richer lane information involving structure and context, especially as the lane marking point is remote. And the obtained multi-scale feature map can be fused by utilizing different scale guidance. Finally, the proposed method is validated on the TuSimple benchmark, whose results show the accuracy can achieve 96.33% in models, and 11.1x faster than the popular Line-CNN model in "compute" time.
C1 [Ge, Zekun; Ma, Chao; Fu, Zhumu; Song, Shuzhong; Si, Pengju] Henan Univ Sci & Technol, Coll Informat Engn, Kaiyuan Ave, Luoyang 471023, Henan, Peoples R China.
   [Ma, Chao; Fu, Zhumu; Song, Shuzhong; Si, Pengju] Henan Univ Sci & Technol, Henan Key Lab Robot & Intelligent Syst, Kaiyuan Ave, Luoyang 471023, Henan, Peoples R China.
C3 Henan University of Science & Technology; Henan University of Science &
   Technology
RP Fu, ZM (corresponding author), Henan Univ Sci & Technol, Coll Informat Engn, Kaiyuan Ave, Luoyang 471023, Henan, Peoples R China.; Fu, ZM (corresponding author), Henan Univ Sci & Technol, Henan Key Lab Robot & Intelligent Syst, Kaiyuan Ave, Luoyang 471023, Henan, Peoples R China.
EM gezekun@163.com; eidinglan@163.com; fuzhumu@haust.edu.cn;
   sszhong@haust.edu.cn; sipengju@haust.edu.cn
FU National Natural Science Foundation of China [61473115]; Natural Science
   Foundation of Henan Province [202300410149]; Key Scientific Research
   Projects of Universities in Henan Province [20A120008, 22A413002];
   Scientific and Technological project of Henan Province [212102210153];
   Aeronautical Science Foundation of China [20200051042003]
FX This work was partially supported by National Natural Science Foundation
   of China (Grant Nos.61473115), the Natural Science Foundation of Henan
   Province (Grant Nos. 202300410149), the Key Scientific Research Projects
   of Universities in Henan Province(Grant No. 20A120008, 22A413002), the
   Scientific and Technological project of Henan Province (Grant Nos.
   212102210153), and the Aeronautical Science Foundation of China (Grant
   No. 20200051042003).
CR Badue C, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113816
   Behrendt K, 2019, IEEE INT CONF COMP V, P832, DOI 10.1109/ICCVW.2019.00111
   BORENSTEIN J, 1995, IEEE T ROBOTIC AUTOM, V11, P21, DOI 10.1109/70.345935
   Caltagirone L, 2019, ROBOT AUTON SYST, V111, P125, DOI 10.1016/j.robot.2018.11.002
   Campion G, 1996, IEEE T ROBOTIC AUTOM, V12, P47, DOI 10.1109/70.481750
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chen Z, 2019, IEEE-CAA J AUTOMATIC, V6, P693, DOI 10.1109/JAS.2019.1911459
   Dai Z, 2021, ADV NEUR IN, V34
   Ghafoorian M, 2019, LECT NOTES COMPUT SC, V11129, P256, DOI 10.1007/978-3-030-11009-3_15
   github, 2017, TUSIMPLE BENCHMARK
   Hou YN, 2019, IEEE I CONF COMP VIS, P1013, DOI 10.1109/ICCV.2019.00110
   Huval B., 2015, ARXIV
   Kim J, 2014, LECT NOTES COMPUT SC, V8834, P454, DOI 10.1007/978-3-319-12637-1_57
   Kim J, 2017, IEEE COMPUT SOC CONF, P1194, DOI 10.1109/CVPRW.2017.158
   Ko Y, 2022, IEEE T INTELL TRANSP, V23, P8949, DOI 10.1109/TITS.2021.3088488
   Kreucher C, 1999, IEEE T ROBOTIC AUTOM, V15, P343, DOI 10.1109/70.760356
   Li QQ, 2014, IEEE T VEH TECHNOL, V63, P540, DOI 10.1109/TVT.2013.2281199
   Li X, 2020, IEEE T INTELL TRANSP, V21, P248, DOI 10.1109/TITS.2019.2890870
   Liu RJ, 2021, IEEE WINT CONF APPL, P3693, DOI 10.1109/WACV48630.2021.00374
   Low CY, 2014, INT CONF ADV ROBOT
   Lv H, 2021, IEEE T INTELL VEHICL, V6, P47, DOI 10.1109/TIV.2020.3009366
   Neven D, 2018, IEEE INT VEH SYM, P286
   Pan XG, 2018, AAAI CONF ARTIF INTE, P7276
   Philion J, 2019, PROC CVPR IEEE, P11574, DOI 10.1109/CVPR.2019.01185
   Ruyi J, 2011, MACH VISION APPL, V22, P721, DOI 10.1007/s00138-010-0307-7
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Satzoda RK, 2010, IEEE EMBED SYST LETT, V2, P23, DOI 10.1109/LES.2010.2051412
   Tabelini L, 2021, INT C PATT RECOG, P6150, DOI 10.1109/ICPR48806.2021.9412265
   Tan MX, 2021, PR MACH LEARN RES, V139, P7102
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang GJ, 2021, IEEE-CAA J AUTOMATIC, V8, P1210, DOI 10.1109/JAS.2020.1003414
   Wang Q, 2022, IEEE T NEUR NET LEAR, V33, P1066, DOI 10.1109/TNNLS.2020.3039675
   Xiao DG, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105584
   Yim YU, 2003, IEEE T INTELL TRANSP, V4, P219, DOI 10.1109/TITS.2003.821339
   Yu CQ, 2021, INT J COMPUT VISION, V129, P3051, DOI 10.1007/s11263-021-01515-2
   Yu F., 2018, ARXIV
   Zhang YC, 2021, IEEE T INTELL TRANSP, V22, P1532, DOI 10.1109/TITS.2020.2971728
NR 37
TC 0
Z9 0
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29607
EP 29627
DI 10.1007/s11042-023-14622-8
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000941926100015
DA 2024-07-18
ER

PT J
AU Komal
   Sethi, GK
   Bawa, RK
AF Komal, Ganesh Kumar
   Sethi, Ganesh Kumar
   Bawa, Rajesh Kumar
TI Automatic Rice Variety Identification System: state-of-the-art review,
   issues, challenges and future directions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Neural networks; Computer vision; Support vector
   machine; Discriminant analysis
ID COMPUTER VISION; IMAGE-ANALYSIS; CLASSIFICATION; CULTIVARS
AB Automatic rice variety identification or quality analysis is a challenging task in image processing and reflects advanced insights into agricultural research with the help of emerging computational technologies. It is the process of identifying the variety of the rice grains by matching them with the training dataset. It is an arduous task because the quality of rice grains is distinct from each other due to the availability of their numerous varieties in the market and unique inherent characteristics. Therefore, customers must identify the superior quality of rice from different available types in the market. This paper demonstrates an exhaustive and transparent perspective on the recent research studies for developing various identification systems using other techniques and a broad view towards this peculiar research area. The paper's main aim is to present in an organized way the related works on identification systems of rice and finally throws exposure on the synthesis analysis based on the research findings. This research study provides valuable and valuable assistance to novice researchers in the agricultural field by amalgamating the studies of various methods and techniques of feature extractions and classification required for automatic variety identification of rice. It is evident from the study that research work carried out on the automated variety identification systems with higher accuracy rates in deep learning using a conjunction of various features of rice is minimal as compared to other techniques and indeed presents a future direction.
C1 [Komal, Ganesh Kumar] Punjabi Univ, Patiala, India.
   [Sethi, Ganesh Kumar] MM Modi Coll, Dept Comp Sci, Patiala, India.
   [Bawa, Rajesh Kumar] Punjabi Univ, Dept Comp Sci, Patiala, India.
C3 Punjabi University; Punjabi University
RP Komal (corresponding author), Punjabi Univ, Patiala, India.
EM komalsharma00061@gmail.com; ganeshsethi147@gmail.com;
   rajesh.k.bawa@gmail.com
RI Chen, H.Y./JSL-7102-2023
OI Chen, H.Y./0009-0009-5542-0460; , KOMAL/0000-0001-6252-2208
CR Abirami S, 2014, AN RIC GRAN US IM PR
   Ai-Guo OuYang, 2010, Proceedings 2010 Sixth International Conference on Natural Computation (ICNC 2010), P84, DOI 10.1109/ICNC.2010.5583370
   Ajay G., 2013, Int. J. Soft Comput. Eng, V2, P35
   Anami B.S., 2015, Int. J. Signal Proc. Ima. Proc. Pattern Recogn., V8, P19, DOI [10.14257/ijsip.2015.8.4.02, DOI 10.14257/IJSIP.2015.8.4.02]
   Asif MJ, 2018, 2018 INT S RECENT AD, P1, DOI DOI 10.1109/DICTA.2018.8615832
   Auttawaitkul Y, 2014, JICTEE, P1, DOI DOI 10.1109/JICTEE.2014.6804100
   Aznan A.A., 2017, Int. J. Adv. Sci. Eng. Inf. Technol., V7, P2220
   Bandumula Nirmala, 2018, Proceedings of the Indian National Science Academy Part B Biological Sciences, V88, P1323, DOI 10.1007/s40011-017-0867-7
   Brandolini V, 2006, J AGR FOOD CHEM, V54, P9985, DOI 10.1021/jf061799m
   Chang RK, 2010, IFIP ADV INF COMM TE, V317, P523
   Chatnuntawech I, 2018, ARXIV
   Chaugule A, J ENG-NY
   Chauhan B.S., 2017, Rice production worldwide, V247
   Cheng Fang, 2004, J Zhejiang Univ Sci, V5, P663, DOI 10.1631/jzus.2004.0663
   Cinar I., 2019, International Journal of Intelligent Systems and Applications in Engineering, V7, P188, DOI DOI 10.18201/IJISAE.2019355381
   Desai S., 2017, INT J TREND SCI RES, V1, P2456
   Devi TG, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON POWER, CONTROL, SIGNALS AND INSTRUMENTATION ENGINEERING (ICPCSI), P1052, DOI 10.1109/ICPCSI.2017.8391871
   Dheer P., 2019, Plant Archives, V19, P155
   Dou Y, 2017, AGR GEOINF 2017 6 IN, P1
   Fayyazi S, 2017, INT J FOOD ENG, V13, DOI 10.1515/ijfe-2016-0121
   Golpour I, 2014, CZECH J FOOD SCI, V32, P280, DOI 10.17221/238/2013-CJFS
   Gujjar HS, 2013, INT J ENG RES APPL, V3, P268
   Gupta N, INT J SCI RES PUBL, V5
   Gurmessa, 2017, PREDICTIVE MODEL PRE
   Guzman J. D., 2008, World conference on agricultural information and IT, IAALD AFITA WCCA 2008, Tokyo University of Agriculture, Tokyo, Japan, 24 - 27 August, 2008, P41
   Hobson DM, 2007, IEEE IMTC P, P1883
   Hu YD, 2019, CONFERENCE PROCEEDINGS OF 2019 5TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P300, DOI [10.1109/iccar.2019.8813449, 10.1109/ICCAR.2019.8813449]
   Huang C, 2015, INT C COMPUT COMPUT, P390
   Huang KY, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040809
   Duong HT, 2019, PROCEEDINGS OF THE 2019 4TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (INCIT), P199, DOI [10.1109/incit.2019.8912121, 10.1109/INCIT.2019.8912121]
   Jiang T., 2010, IEEE CUSTOM INTEGRAT, P1
   Kambo R, 2014, ARXIV
   Kambo R., 2014, DIMENSIONS-NBS, V1000, P1
   Kawamura S, 2003, COMPUT ELECTRON AGR, V40, P115, DOI 10.1016/S0168-1699(03)00015-2
   Khunkhett S, 2014, 2014 4 JOINT INT C I, P1, DOI DOI 10.1109/JICTEE.2014.6804096
   Kiruthika R., 2013, INT J ADV RES ELECT, V2, P2937
   Kong WW, 2013, SENSORS-BASEL, V13, P8916, DOI 10.3390/s130708916
   Kuchekar NA, 2018, IOSR J ELECT COMMUN, V13, P84
   Kumar, 2019, INT J ENG ADV TECHNO, V8, P3629, DOI [10.35940/ijeat.F9362.088619, DOI 10.35940/IJEAT.F9362.088619]
   Kumbharkar P, 2017, INT J INNOV RES SCI, V6, P9601, DOI [10.15680/IJIRSET.2017.0605289, DOI 10.15680/IJIRSET.2017.0605289]
   Kuo T.-Y., 2015, 2015 ASABE ANN INT M, V1
   Kuo TY, 2016, COMPUT ELECTRON AGR, V127, P716, DOI 10.1016/j.compag.2016.07.020
   Lilhare SF, 2012, NATL C INNOVATIVE PA, P33
   Lin P, 2017, INT SYM COMPUT INTEL, P169, DOI 10.1109/ISCID.2017.208
   Liu Zhao-yan, 2005, J Zhejiang Univ Sci B, V6, P1095, DOI 10.1631/jzus.2005.B1095
   Mahale B, 2014, 2014 INTERNATIONAL CONFERENCE FOR CONVERGENCE OF TECHNOLOGY (I2CT)
   Maheswari S., 2019, INT J ENG ADV TECHNO, V9, P2682, DOI [10.35940/ijeat.a9879.129219, DOI 10.35940/IJEAT.A9879.129219]
   Mousavirad S., 2012, Int J Appl Inf Syst, V3, P33
   Mousavirad S., 2011, 7 IR C MACH VIS IM P, P1, DOI [DOI 10.1109/IRANIANMVIP.2011.6121583, 10.1109/iranianmvip.2011.]
   MousaviRad SJ, 2012, MAJLESI J MULTIMED P, V1
   Mousavirad SJ., 2012, Int J Comput Appl, V40, P41
   Nagoda Nadeesha, 2018, 2018 IEEE 13th International Conference on Industrial and Information Systems (ICIIS), P179, DOI 10.1109/ICIINFS.2018.8721312
   Neelamegam P, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P879
   Nugegoda, RICE GRAINS CLASSIFI
   Ozan A.K.I., 2015, INT SCI C NOV, P20
   Pandey N., 2013, International Journal of Computer Applications Technology and Research, V2, P208, DOI DOI 10.7753/IJCATR0202.1023
   Parmar RR, 2011, COMM COM INF SC, V192, P239
   Parveen Z, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION, COMPUTING AND DIGITAL SYSTEMS (C-CODE), P265, DOI 10.1109/C-CODE.2017.7918940
   Patel N, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P42, DOI 10.1109/RTEICT.2017.8256555
   Patil V, 2015, INT J INNOV RES COMP, V3
   Pazoki AR, 2014, J ANIM PLANT SCI-PAK, V24, P336
   Pratibha N, ANAL IDENTIFICATION, V10, P25
   Punthumast P, 2012, EL ENG EL COMP TEL I, P1, DOI [DOI 10.1109/ECTICON.2012.6254334, 10.1109/ECTICon.2012.6254334]
   Qiu ZJ, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8020212
   Rekha TSV, TURKISH J PHYSIOTHER, V32, P2
   Rexce J., 2017, INT J SCI ENG RES, V8, P10
   RIC, 2020, ABOUT US
   Sethy PK., 2018, INT J APPL ENG RES, V13, P35
   Shantaiya Sanjivani, 2010, IEEE INT C COMMUNICA
   Sharma D, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P1118, DOI 10.1109/ICCONS.2017.8250640
   Siddagangappa M. R., 2014, IOSR J COMPUTER ENG, V16, P1, DOI DOI 10.9790/0661-16430110
   Sidnal N., 2013, INT J RES ENG TECHNO, V2, P545, DOI [10.15623/ijret.2013.0211082, DOI 10.15623/IJRET.2013.0211082]
   Silva CS, 2013, CLASSIFICATION RICE
   Sumaryanti L., 2015, TELKOMNIKA INDONESIA, V16, P182, DOI DOI 10.11591/TIJEE.V16I1.1602
   Tahir WPNWM., 2015, ARPN J ENG APPL SCI, V10, P10131
   Tanck P., 2014, IJITEE, V3, P83
   Tharanidharan RS, 2017, J ACM, V1
   Tiwari JK., 2013, SEED RES, V41, P83
   Veena H, 2014, EFFICIENT METHOD CLA
   Verma B., 2010, 2010 International Conference on Computer and Communication Technology (ICCCT 2010), P220, DOI 10.1109/ICCCT.2010.5640428
   Wah T.N., 2018, Int. J. Sci. Res. Publ, V8, P603, DOI [10.29322/IJSRP.8.8.2018.p8078, DOI 10.29322/IJSRP.8.8.2018.P8078]
   Wan YN, 2002, T ASAE, V45, P379
   Watanachaturaporn P, 2016, 2016 8 INT C INFORM, P1
   Wu J, 2012, ACTA BIOCH BIOPH SIN, V44, P650, DOI 10.1093/abbs/gms043
   Wu LL, 2013, ADV MATER RES-SWITZ, V605-607, P2179, DOI 10.4028/www.scientific.net/AMR.605-607.2179
   Yammen S, 2016, LECT NOTES ELECTR EN, V345, P91, DOI 10.1007/978-3-319-17314-6_12
   Yao Q, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL IV, P274, DOI 10.1109/GCIS.2009.91
   Zareiforoush H, 2016, J FOOD SCI TECH MYS, V53, P118, DOI 10.1007/s13197-015-1947-4
NR 88
TC 2
Z9 2
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27305
EP 27336
DI 10.1007/s11042-023-14487-x
EA FEB 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000933104800007
DA 2024-07-18
ER

PT J
AU Tembhurne, JV
   Gajbhiye, SM
   Gannarpwar, VR
   Khandait, HR
   Goydani, PR
   Diwan, T
AF Tembhurne, Jitendra V.
   Gajbhiye, Saurav M.
   Gannarpwar, Vedant R.
   Khandait, Harshal R.
   Goydani, Purva R.
   Diwan, Tausif
TI Plant disease detection using deep learning based Mobile application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Plant disease detection; Multi-classifier
   deep learning model; Deep neural network; Plantscape android application
AB Crop disease serves as a major threat to the farming sector. Due to the increased utilization of smartphones, it is now possible to leverage the technology and apply it for the betterment of the farming sector. The agricultural sector struggles in supporting the ever-growing global population, moreover, plant disease reduces the amount of food production and quality of the food. Losses may be a cataclysm, but on an average, it affects almost 45% of the production of major crops. Farmers often spend a lots of money on disease management of the crops and each crop is vulnerable to a particular disease that affects the quality and final yield. But, lack of proper technology, results in poor disease management, soil pollution, and the outcome may be devastating. In addition, plant diseases also affect the food chain supply, destroy the natural ecosystem and contribute to exacerbating environmental issues. These problems can be eradicated by adopting deep learning algorithms to analyze and visualize the current condition of the crops. With application built using deep learning, it is now possible to accurately detect crop diseases thereby reducing the effects of crop disease on food supply. Thus, correct disease detection followed by the management of identified diseases, thereby increasing food production and maintaining the quality of the food is achieved by deep neural networks. The proposed model uses MobileNet architecture along with complex hidden layers fine-tuned with Keras tuner on the dataset containing 12,318 images. We proposed an enhanced MobileNet scalable model with better generalization on large sized unified dataset constructed from various smaller sized dataset for better features' extraction and representation. The proposed model classifies the input in 64 different classes for 22 different sets of crops and achieved an accuracy of 95.94%. Further, the model is inculcated with our Android application - Plantscape for a better user experience fusioned with serene user interactions.
C1 [Tembhurne, Jitendra V.; Gajbhiye, Saurav M.; Gannarpwar, Vedant R.; Khandait, Harshal R.; Goydani, Purva R.; Diwan, Tausif] Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur 441108, Maharashtra, India.
RP Tembhurne, JV (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur 441108, Maharashtra, India.
EM jtembhurne@iiitn.ac.in; saurav.gajbhiye24@gmail.com;
   vedantrgannarpwar@gmail.com; harshalkhandait799@gmail.com;
   goydanipurva@gmail.com; tdiwan@iiitn.ac.in
RI Tembhurne, Jitendra/AGI-1097-2022; Diwan, Tausif/AFN-9746-2022
OI Tembhurne, Jitendra/0000-0002-1389-3456; 
CR [Anonymous], FLOWERS RECOGNITION
   Barbedo JGA, 2016, BIOSYST ENG, V147, P104, DOI 10.1016/j.biosystemseng.2016.03.012
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chouhan Siddharth Singh, 2019, 2019 4th International Conference on Information Systems and Computer Networks (ISCON), P700, DOI 10.1109/ISCON47742.2019.9036158
   Cortes E., 2017, PLANT DIS CLASSIFICA
   DeChant C, 2017, PHYTOPATHOLOGY, V107, P1426, DOI 10.1094/PHYTO-11-16-0417-R
   Duth PS, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P602, DOI [10.1109/iciccs48265.2020.9121164, 10.1109/ICICCS48265.2020.9121164]
   Food and Agriculture Organization of United Nation, 2017, FUT FOOD AGR TRENDS, P58
   Gogul I, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATION AND NETWORKING (ICSCN)
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Iandola F., 2014, DenseNet: Implementing efficient convnet descriptor pyramids
   Jiang H, 2020, J PHYS C SERIES, V1576
   Johannes A, 2017, COMPUT ELECTRON AGR, V138, P200, DOI 10.1016/j.compag.2017.04.013
   Rojas-Aranda JL, 2020, LECT NOTES COMPUT SC, V12088, P3, DOI 10.1007/978-3-030-49076-8_1
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Mwebaze E., 2019, ARXIV
   Nagasubramanian K, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0479-8
   Nguyen TTN, 2016, AUNSEED NET REGIONAL
   Oppenheim D., 2020, Tomato flower detection using deep learning
   Parvathy SN., 2020, RSF-RUS SAGE J SOC S, V7, P6609
   Ramesh Shima, 2018, 2018 International Conference on Design Innovations for 3Cs Compute Communicate Control (ICDI3C). Proceedings, P41, DOI 10.1109/ICDI3C.2018.00017
   Rao A, 2020, INT J ELEC ENG EDUC, DOI 10.1177/0020720920953126
   Saha M, 2020, International Journal of Advanced Science and Technology, V29, P2900
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wu DZ, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/2015017
   Wu H., 2019, Plant Phenome Journal, Volume, V2, P1, DOI DOI 10.2135/TPPJ2019.03.0006
   Zeng GX, 2017, 2017 IEEE 3RD INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC), P613, DOI 10.1109/ITOEC.2017.8122370
   Zhang SW, 2017, COMPUT ELECTRON AGR, V134, P135, DOI 10.1016/j.compag.2017.01.014
   Zhu L, 2018, INT J AGR BIOL ENG, V11, P217, DOI 10.25165/j.ijabe.20181104.2690
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 32
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27365
EP 27390
DI 10.1007/s11042-023-14541-8
EA FEB 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000933104800008
DA 2024-07-18
ER

PT J
AU Cinar, AC
   Kara, TB
AF Cinar, Ahmet Cevahir
   Kara, Turkan Beyza
TI The current state and future of mobile security in the light of the
   recent mobile security threat reports
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile threat report; Mobile security; Smartphone security; Security;
   Mobile applications
ID MALWARE DETECTION
AB Smartphones have become small computers that meet many of our needs, from e-mail and banking transactions to communication and social media use. In line with these attractive functions, the use of smartphones has greatly increased over the years. One of the most important features of these mobile devices is that they offer users many mobile applications that they can install. However, hacker attacks and the spread of malware have also increased. Today, current mobile malware detection and defense technologies are still inadequate. Mobile security is not only directly related to the operating system and used device but also related with communication over the internet, data encryption, data summarization, and users' privacy awareness. The main aim and contribution of this study are to collect the current state of mobile security and highlight the future of mobile security in light of the recent mobile security threat reports. The studies in the field of malware, attack types, and security vulnerabilities concerning the usage of smartphones were analyzed. The malware detection techniques were analyzed into two categories: signature-based and machine learning (behavior detection)-based techniques. Additionally, the current threats and prevention methods were described. Finally, a future direction is highlighted in the light of the current mobile security reports.
C1 [Cinar, Ahmet Cevahir; Kara, Turkan Beyza] Selcuk Univ, Fac Technol, Dept Comp Engn, Konya, Turkiye.
C3 Selcuk University
RP Cinar, AC; Kara, TB (corresponding author), Selcuk Univ, Fac Technol, Dept Comp Engn, Konya, Turkiye.
EM accinar@selcuk.edu.tr; 218273001009@lisansustu.selcuk.edu.tr
CR Alvarez-Cedillo, 2012, INT J COMPUTER SCI I, V2, P208
   [Anonymous], POINT C
   [Anonymous], NIST CVSS SEV DISTR
   Arif JM, 2021, J INF SECUR APPL, V61, DOI 10.1016/j.jisa.2021.102929
   Berghof, 2020, MALWARE TOP 10 2019
   Bosaeed S, 2020, 2020 FIFTH INTERNATIONAL CONFERENCE ON FOG AND MOBILE EDGE COMPUTING (FMEC), P325, DOI [10.1109/FMEC49853.2020.9144833, 10.1109/fmec49853.2020.9144833]
   Breve B, 2020, ITASEC, P71
   Breve B, 2019, IEEE INT CON INF VIS, P255, DOI 10.1109/IV.2019.00050
   Campbell, WANDERA
   Chebyshev V., 2021, Kaspersky
   Chen L, 2021, IEEE ACCESS, V9, P14576, DOI 10.1109/ACCESS.2021.3049819
   Chen ZX, 2018, INFORM SCIENCES, V433, P346, DOI 10.1016/j.ins.2017.04.044
   ( CyRC) CRC, 2021, 2021 SOFTW VULN SNAP
   Das A, 2016, INF COMPUT SECUR, V24, P116, DOI 10.1108/ICS-04-2015-0018
   Dimolianis M, 2021, IEEE ACCESS, V9, P113061, DOI 10.1109/ACCESS.2021.3104115
   Feizollah A, 2013, MALAYS J COMPUT SCI, V26, P251
   Grelg, 2021, RANSOMWARE ATTEMPT V
   Guo D.F., 2012, IEEE C PUBLICATIONS, P1
   Gupta BB, 2018, MULTIMED TOOLS APPL, V77, P9203, DOI 10.1007/s11042-017-5301-x
   Gupta RK, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/7291250
   Hatcher WG, 2016, 2016 IEEE/ACIS 14TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS (SERA), P67, DOI 10.1109/SERA.2016.7516130
   Jayapandian N, 2021, WIRELESS PERS COMMUN, V120, P2427, DOI 10.1007/s11277-021-08562-5
   Jeong ES, 2017, MULTIMED TOOLS APPL, V76, P18153, DOI 10.1007/s11042-016-4189-1
   Kim H, 2018, MULTIMED TOOLS APPL, V77, P5027, DOI 10.1007/s11042-017-4756-0
   Koppanati RK, 2021, IEEE CONSUM ELECTR M, V10, P41, DOI 10.1109/MCE.2020.3003127
   Kumar K, 2021, MULTIMED TOOLS APPL, V80, P11079, DOI 10.1007/s11042-020-10157-4
   Kumar M, 2017, BAD RABBIT NEW RANSO
   lab. K, 2016, MOBILE MALWARE EVOLU
   Lalotra GS, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/9149164
   Lee KC, 2017, SOFT COMPUT, V21, P2883, DOI 10.1007/s00500-016-2265-0
   Li T, 2020, COMPUT COMMUN, V152, P109, DOI 10.1016/j.comcom.2020.01.034
   Martinelli F, 2020, SIMUL MODEL PRACT TH, V105, DOI 10.1016/j.simpat.2020.102169
   Micro, 2016, GODLESS MOBILE MALWA
   Naik N, 2020, 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P1146, DOI 10.1109/SSCI47803.2020.9308179
   Needham, 2021, GLOBAL SMARTPHONE MA
   Patil R, 2020, INT J INF SECUR, V19, P147, DOI 10.1007/s10207-019-00447-w
   Point C, SEPTEMBER 2020 S MOS
   Rayappan D, 2021, WIREL NETW, V27, P981, DOI 10.1007/s11276-020-02486-x
   Sadiku M.N., 2016, Journal of Scientific and Engineering Research, V3, P64
   SAN CARLOS C, 2021, SEPTEMBER 2021 S MOS
   Sarker IH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050754
   Savenko O., 2019, ICTERI WORKSHOPS, V2393, P633
   Shishkova T., 2021, Securelist, V26
   Shrivastava G, 2019, MULTIMED TOOLS APPL, V78, P35713, DOI 10.1007/s11042-019-07899-1
   Staff, 2021, REPORT APPL CRITICAL
   Suastegui Jaramillo LuisEduardo., 2018, J INFORM SYSTEMS ENG, V3
   Tchakounte F., 2021, Iran J. Comput. Sci, V4, P95, DOI DOI 10.1007/S42044-020-00068-W
   Venugopal D, 2008, MOB INF SYST, V4, P33, DOI 10.1155/2008/712353
   Wang F, 2024, T EMERG TELECOMMUN T, V35, DOI 10.1002/ett.4226
NR 49
TC 2
Z9 2
U1 6
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20269
EP 20281
DI 10.1007/s11042-023-14400-6
EA JAN 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000921784900001
PM 36743997
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Fan, SH
   Chen, X
   He, C
   Huang, Y
   Chen, KH
AF Fan, Shenghua
   Chen, Xi
   He, Chu
   Huang, Yan
   Chen, Kehan
TI Cross-scale content-based full Transformer network with Bayesian
   inference for object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Bayesian inference; Full Transformer; Content-based
   bias; Cross-scale
AB Visual tracking is fundamentally the problem of conditional probability regressing of the target location in each video frame. Convolutional neural network (CNN) have been dominant in visual tracking these years, but CNN-based trackers neglect long-range dependency in likelihood representation and prior information, these destroy the spatial consistency of target. Recently emerging Transformer-based trackers mitigate these, however, they do not possess the ability to build interactions among features of cross-scale. Moreover, the sine position encoding prior in Transformer-based tracker is content-unaware and fails to reflect the relative index of different positions. To address these issues and inspired by Bayesian probabilistic formulation, we propose a cross-scale full Transformer tracker with content-based prior bias (named BTT). There are four main contributions of the method, (i) we propose a hierarchical full Transformer tracking architecture to introduce long-range dependency, which enriches the likelihood representation of model, and alleviates the destruction of spatial consistency. (ii) An expanding layer without using convolution or interpolation operation is proposed to aggregate layer information of different scales to construct cross-scale likelihood estimation. (iii) We further demonstrate the defect of sine position encoding with mathematical derivation, and introduce a content-based positional encoding bias as prior in the Transformer architecture to reflect the relative index of inputs. (iv) And extensive experiments show that the proposed tracker achieves better performance compared with CNN-based trackers in cases of illumination, low resolution, deformation on various datasets, and achieves superior performance on others attributes. The proposed tracker obtains 70.3%, 69.1%, 63.4% on OTB2015, UAV123, and LaSOT, respectively.
C1 [Fan, Shenghua; Chen, Xi] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
   [He, Chu] Wuhan Univ, Sch Elect Informat, Wuhan 430072, Hubei, Peoples R China.
   [Huang, Yan] ZMVis Technol, Wuhan 430072, Hubei, Peoples R China.
   [Chen, Kehan] Shanghai Acad Spaceflight Technol, Shanghai 200000, Peoples R China.
C3 Wuhan University; Wuhan University
RP Chen, X (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
EM 2018282110301@whu.edu.cn; robertcx@whu.edu.cn; chuhe@whu.edu.cn;
   huangyan@zmvision.cn; chenkehan71_0207@sina.com
OI Chen, Xi/0000-0002-0735-9919
CR Abuhussein A, 2021, IEEE ACCESS, V9, P19882, DOI 10.1109/ACCESS.2021.3054366
   Babaee M, 2021, THESIS TU MUNICH GER
   Bertinetto L., 2016, ARXIV
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Beshara P, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21248186
   Bevilacqua M., 2019, P INT C RECENT ADV N, P122
   Bingyan Liao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P429, DOI 10.1007/978-3-030-58542-6_26
   Cao Hu, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P205, DOI 10.1007/978-3-031-25066-8_9
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chen JP, 2021, NAT PHOTONICS, V15, P570, DOI 10.1038/s41566-021-00828-5
   Chen X, 2021, PROC CVPR IEEE, P8122, DOI 10.1109/CVPR46437.2021.00803
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Cui ZJ, 2020, IEEE ACCESS, V8, P154800, DOI 10.1109/ACCESS.2020.3017179
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2020, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR42600.2020.00721
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Fan X., 2020, ARXIV
   Fernandes FE Jr, 2019, SWARM EVOL COMPUT, V49, P62, DOI 10.1016/j.swevo.2019.05.010
   Fu ZH, 2021, PROC CVPR IEEE, P13769, DOI 10.1109/CVPR46437.2021.01356
   Geirhos R, 2019, 7 INT C LEARN REPR I
   Ghoshal B, 2021, LECT NOTES COMPUT SC, V12695, P3, DOI 10.1007/978-3-030-74251-5_1
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans KSFM, 2021, PSYCHOL MED, V51, P2599, DOI 10.1017/S0033291720001154
   Hssayni E, 2022, NEURAL COMPUT APPL, V34, P2443, DOI 10.1007/s00521-021-06540-3
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Islam M. A., 2021, INT C LEARN REPR
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kim C, 2018, LECT NOTES COMPUT SC, V11212, P208, DOI 10.1007/978-3-030-01237-3_13
   Kim W, 2018, MULTIMEDIA SYST, V24, P611, DOI 10.1007/s00530-018-0586-9
   Le NQK, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbab005
   Li B., 2018, ARXIV
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li PX, 2019, IEEE I CONF COMP VIS, P6161, DOI 10.1109/ICCV.2019.00626
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu LW, 2012, INT C PATT RECOG, P565
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   Lu XK, 2018, IEEE ACCESS, V6, P18031, DOI 10.1109/ACCESS.2018.2820004
   Lukezic A, 2020, PROC CVPR IEEE, P7131, DOI 10.1109/CVPR42600.2020.00716
   Mbelwa JT, 2019, VISUAL COMPUT, V35, P371, DOI 10.1007/s00371-018-1470-5
   Meinhardt T., 2021, arXiv
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Nam H, 2015, ARXIV
   Polson N, 2017, ARXIV
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sha Y., 2021, arXiv
   Shen ZL, 2021, PROC CVPR IEEE, P13901, DOI 10.1109/CVPR46437.2021.01369
   Sun P., 2020, arXiv
   Tao R., 2016, ARXIV
   Tian SS, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.3.033008
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Wang N, 2021, PROC CVPR IEEE, P1571, DOI 10.1109/CVPR46437.2021.00162
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xu J., 2019, arXiv
   Xu Y, 2019, IEEE I CONF COMP VIS, P7042, DOI 10.1109/ICCV.2019.00714
   Xue BY, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7378, DOI 10.1109/ICASSP39728.2021.9414046
   Yan B, 2019, IEEE I CONF COMP VIS, P2385, DOI 10.1109/ICCV.2019.00247
   Yan H., 2019, arXiv
   Zhang GC, 2015, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2015.7298743
   Zhang K, 2013, ARXIV
   Zhang S, 2021, P 38 INT C MACHINE L, V139, P12413
   Zhang Z, 2020, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR42600.2020.00227
   Zhang ZY, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2021.3139658
   ZHU W, P ICASSP 2019 2019 I, P6241, DOI DOI 10.1109/ICASSP.2019.8682953
   Zhu YP, 2022, IND ROBOT, V49, P120, DOI 10.1108/IR-02-2021-0030
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
   Zhu Z., 2021, ARXIV
NR 74
TC 0
Z9 0
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19877
EP 19900
DI 10.1007/s11042-022-14162-7
EA NOV 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000886859000001
DA 2024-07-18
ER

PT J
AU Ghosh, SK
   Rashmi, M
   Mohan, BR
   Guddeti, RMR
AF Ghosh, Sampat Kumar
   Rashmi, M.
   Mohan, Biju R.
   Guddeti, Ram Mohana Reddy
TI Deep learning-based multi-view 3D-human action recognition using
   skeleton and depth data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Deep learning; Feature fusion; Human
   action recognition; Score fusion
ID 3D HUMAN ACTION; RECOMMENDATION SYSTEM
AB Human Action Recognition (HAR) is a fundamental challenge that smart surveillance systems must overcome. With the rising affordability of capturing human actions with more advanced depth cameras, HAR has garnered increased interest over the years, however the majority of these efforts have been on single-view HAR. Recognizing human actions from arbitrary viewpoints is more challenging, as the same action is observed differently from different angles. This paper proposes a multi-stream Convolutional Neural Network (CNN) model for multi-view HAR using depth and skeleton data. We also propose a novel and efficient depth descriptor, Edge Detected-Motion History Image (ED-MHI), based on Canny Edge Detection and Motion History Image. Also, the proposed skeleton descriptor, Motion and Orientation of Joints (MOJ), represent the appropriate action by using joint motion and orientation. Experimental results on two datasets of human actions: NUCLA Multiview Action3D and NTU RGB-D using a Cross-subject evaluation protocol demonstrated that the proposed system exhibits the superior performance as compared to the state-of-the-art works with 93.87% and 85.61% accuracy, respectively.
C1 [Ghosh, Sampat Kumar; Rashmi, M.; Mohan, Biju R.; Guddeti, Ram Mohana Reddy] Natl Inst Technol Karnataka, Dept Informat Technol, Mangalore 575025, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Ghosh, SK; Rashmi, M (corresponding author), Natl Inst Technol Karnataka, Dept Informat Technol, Mangalore 575025, Karnataka, India.
EM sampatghosh1995@gmail.com; nm.rashmi@gmail.com; biju@nitk.edu.in;
   profgrmreddy@nitk.edu.in
OI R Mohan, Biju/0000-0002-3928-8924; M, Rashmi/0000-0003-2101-5992
CR Afza F, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104090
   Ahmad Z, 2021, IEEE SENS J, V21, P3623, DOI 10.1109/JSEN.2020.3028561
   [Anonymous], 2015, PROC CVPR IEEE
   Ben Mahjoub A, 2016, INT DES TEST SYMP, P83, DOI 10.1109/IDT.2016.7843019
   Ben Tanfous A, 2018, PROC CVPR IEEE, P2840, DOI 10.1109/CVPR.2018.00300
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, V29, P14780, DOI 10.1007/s11356-021-16627-y
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen C, 2014, IEEE ENG MED BIO, P4135, DOI 10.1109/EMBC.2014.6944534
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Dhiman C, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P225, DOI [10.1109/BigMM.2019.00-21, 10.1109/BigMM.2019.00041]
   Dhiman C, 2020, IEEE T IMAGE PROCESS, V29, P3835, DOI 10.1109/TIP.2020.2965299
   Ding CY, 2021, APPL INTELL, V51, P560, DOI 10.1007/s10489-020-01803-3
   Ding WW, 2018, PATTERN RECOGN, V77, P75, DOI 10.1016/j.patcog.2017.12.004
   Fan YB, 2020, IEEE ACCESS, V8, P15280, DOI 10.1109/ACCESS.2020.2968054
   Ghosh Sampat Kumar, 2022, Advanced Machine Intelligence and Signal Processing. Lecture Notes in Electrical Engineering (858), P75, DOI 10.1007/978-981-19-0840-8_6
   Gu Y, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.10.004
   Pham HH, 2019, IET COMPUT VIS, V13, P319, DOI 10.1049/iet-cvi.2018.5014
   Islam MM, 2021, IEEE ROBOT AUTOM LET, V6, P1729, DOI 10.1109/LRA.2021.3059624
   Kamel A, 2019, IEEE T SYST MAN CY-S, V49, P1806, DOI 10.1109/TSMC.2018.2850149
   Kanjilal R, 2021, NEURAL PROCESS LETT, V53, P561, DOI 10.1007/s11063-020-10400-x
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kingma D. P., 2014, arXiv
   Li BL, 2012, PROC CVPR IEEE, P1362, DOI 10.1109/CVPR.2012.6247822
   Li RN, 2012, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR.2012.6248011
   Liu H, 2020, INT CONF ACOUST SPEE, P2583, DOI [10.1109/ICASSP40776.2020.9053939, 10.1109/icassp40776.2020.9053939]
   Maji S., 2011, Computer Vision and Pattern Recognition (CVPR)
   Megavannan V., 2012, Signal Processing and Communications (SPCOM), 2012 International Conference on, P1
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Rahmani H, 2016, PROC CVPR IEEE, P1506, DOI 10.1109/CVPR.2016.167
   Rahmani H, 2016, IEEE T PATTERN ANAL, V38, P2430, DOI 10.1109/TPAMI.2016.2533389
   Romaissa BD, 2021, INT C PATT RECOG, P5859, DOI 10.1109/ICPR48806.2021.9412863
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shahroudy Amir, 2018, IEEE Transactions on Pattern Analysis and Machine Intelligence, V40, P1045, DOI 10.1109/TPAMI.2017.2691321
   Shao ZP, 2021, IEEE T CIRC SYST VID, V31, P160, DOI 10.1109/TCSVT.2020.2965574
   Singh R, 2020, MULTIMEDIA SYST, V26, P313, DOI 10.1007/s00530-019-00645-5
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   SUN Z, 2022, IEEE T PATTERN ANAL, P1
   Thien HT, 2020, INFORM SCIENCES, V513, P112, DOI 10.1016/j.ins.2019.10.047
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang P., 2015, ARXIV
   Wei P, 2013, IEEE I CONF COMP VIS, P3136, DOI 10.1109/ICCV.2013.389
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Zhang PF, 2020, IEEE T IMAGE PROCESS, V29, P1061, DOI 10.1109/TIP.2019.2937724
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 51
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19829
EP 19851
DI 10.1007/s11042-022-14214-y
EA NOV 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000885231500006
DA 2024-07-18
ER

PT J
AU Singh, SK
   Chaturvedi, A
AF Singh, Shashank Kumar
   Chaturvedi, Amrita
TI A reliable and efficient machine learning pipeline for american sign
   language gesture recognition using EMG sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interaction; Surface electromyography; American sign
   language; Feature selection
ID NEURAL-NETWORK; MULTIPLE COMPARISONS; WORD RECOGNITION; CLASSIFICATION;
   SELECTION; SYSTEM; GLOVE; TRANSFORM; INTERFACE; FEATURES
AB Sign languages has extensive applications among differently-abled to communicate with their surroundings. With the development of different sensing technologies, several new human-computer interaction techniques (HCI) have been established to recognize hand gestures. Computer vision-based methods have shown significant utility for such applications. However, these methods are strongly dependent on the lighting conditions. The surface electromyography (sEMG) technique is invariant to lighting conditions and can easily reflect human motion intention. In this work, sEMG based sign language recognition model was developed using an efficient machine learning pipeline. Two sEMG datasets were recorded for predefined hand gestures using wireless sensors. These signals were mainly acquired against 24 manual alphabets (ASL-24) and ten digits(ASL-10) of American Sign Language (ASL). The collected data sets were preprocessed, and around 450 well-established feature was extracted from each sEMG channel. We applied an ensemble feature selection approach combining four diverse filter-based feature selection methods (ANOVA, Chi-square, Mutual Info, ReliefF). A newly proposed feature combiner that exploits feature-feature and feature-class correlation thresholds is used to combine feature subsets formed across the ensemble. The resulting features comprise reduced & most representative feature subsets and are further used in the pipeline for classifying ASL gestures. Using the CatBoost algorithm, the pipeline presented excellent average classification accuracy(99.91% on ASL-24) and other performance parameters for recognizing ASL gestures. The pipeline was also applied and validated on a benchmark dataset (Ninapro database 5, exercise A) and achieved similar outcomes. The result highlights the feasibility of using sEMG based approach as better options to computer-vision-based techniques to build an accurate and robust Sign Language Recognition system (SLRS). Moreover, efforts were made to find the optimal number of sensors and features for recognition task on (ASL-10 dataset) without impacting the overall reliability and accuracy of the system. The experiments results can be used to enhance the performance of various wearable sEMG sensor based HCI applications.
C1 [Singh, Shashank Kumar; Chaturvedi, Amrita] Indian Inst Technol BHU, CSE Dept, Varanasi 221005, UP, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Singh, SK (corresponding author), Indian Inst Technol BHU, CSE Dept, Varanasi 221005, UP, India.
EM shashankkrs.rs.cse17@itbhu.ac.in
RI Chaturvedi, Amrita/D-7823-2017
CR Aboy M, 2006, IEEE T BIO-MED ENG, V53, P2282, DOI 10.1109/TBME.2006.883696
   Ahmed MA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072208
   Ahsan M. R., 2009, European Journal of Scientific Research, V33, P480
   [Anonymous], 2011, Visual Analysis of Humans: Looking at People, DOI DOI 10.1007/978-0-85729-997-027
   [Anonymous], 2007, Information retrieval for music and motion
   Atzori M, 2014, SCI DATA, V1, DOI 10.1038/sdata.2014.53
   Barbhuiya AA, 2021, MULTIMED TOOLS APPL, V80, P3051, DOI 10.1007/s11042-020-09829-y
   Batista GEAPA, 2014, DATA MIN KNOWL DISC, V28, P634, DOI 10.1007/s10618-013-0312-3
   Battison R., 1978, Lexical borrowing in American sign language
   Bheda V., 2017, ARXIV
   Bin Munir M, 2021, P 21 INT C HUMAN COM, P1
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   Chang Y., 2008, P WORKSHOP CAUSATION, V3, P53
   Chen CW, 2020, EXPERT SYST, V37, DOI 10.1111/exsy.12553
   Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   Chowdhury RH, 2013, SENSORS-BASEL, V13, P12431, DOI 10.3390/s130912431
   Chuan CH, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P541, DOI 10.1109/ICMLA.2014.110
   Day S., 2002, Important factors in surface emg measurement, P1
   de la Rosa R, 2010, SENSORS-BASEL, V10, P11100, DOI 10.3390/s101211100
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Dinno A, 2015, STATA J, V15, P292, DOI 10.1177/1536867X1501500117
   Dorogush AV, 2018, ARXIV181011363
   DUNN OJ, 1964, TECHNOMETRICS, V6, P241, DOI 10.2307/1266041
   Erkilinc MS, 2011, ANN IEEE SYST CONF, P417
   Cardenas EJE, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102772
   Fatmi R, 2019, 2019 IEEE 9TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P290, DOI 10.1109/CCWC.2019.8666491
   FELS SS, 1993, IEEE T NEURAL NETWOR, V4, P2, DOI 10.1109/72.182690
   Feng YY, 2021, SURG INNOV, V28, P33, DOI 10.1177/1553350620947206
   Fennig, 2021, ETHNOLOGUE LANGUAGES
   Ferri C, 2009, PATTERN RECOGN LETT, V30, P27, DOI 10.1016/j.patrec.2008.08.010
   Friedrich R, 2000, PHYS LETT A, V271, P217, DOI 10.1016/S0375-9601(00)00334-0
   Garcia B., 2016, Convolutional Neural Netw. Vis. Recognit., V2, P225
   Genuer R, 2015, R J, V7, P19
   Gomez-Donoso F, 2019, EXPERT SYST APPL, V136, P327, DOI 10.1016/j.eswa.2019.06.055
   Goswami Tilottama, 2021, ICCCE 2020. Proceedings of the 3rd International Conference on Communications and Cyber Physical Engineering. Lecture Notes in Electrical Engineering (LNEE 698), P55, DOI 10.1007/978-981-15-7961-5_6
   Guler Nihal Fatma, 2005, J Med Syst, V29, P241, DOI 10.1007/s10916-005-5184-7
   Guo D, 2018, AAAI CONF ARTIF INTE, P6845
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hoque N, 2018, COMPLEX INTELL SYST, V4, P105, DOI 10.1007/s40747-017-0060-x
   HUDGINS B, 1993, IEEE T BIO-MED ENG, V40, P82, DOI 10.1109/10.204774
   Isaacs J, 2004, SE SYM SYS THRY, P132
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Jones E., 2001, SciPy: Open source scientific tools for Python
   Jurman G, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041882
   Kadhim RA, 2020, TEM J, V9, P937, DOI 10.18421/TEM93-14
   Kanoga S, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101981
   Kerber F, 2015, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2015), P218, DOI 10.1145/2836041.2836063
   Khan SA, 2014, SCI WORLD J, DOI 10.1155/2014/672630
   Khan SM, 2020, IEEE REV BIOMED ENG, V13, P248, DOI 10.1109/RBME.2019.2950897
   Kleiman R., 2019, INT C MACH LEARN, V97, P3439
   Koller O., 2020, ARXIV
   Kosmidou Vasiliki E, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P6197
   Kuroda T., 2004, Virtual Real. Assoc. Tech, P253
   Lee CKM, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114403
   Li L, 2018, ADV ROBOTICS, V32, P1112, DOI 10.1080/01691864.2018.1490666
   Liddell Scott K., 1989, SIGN LANGUAGE STUDIE, V1, P195, DOI [10.1353/sls.1989.0027, DOI 10.1353/SLS.1989.0027]
   Lundberg SM, 2017, ADV NEUR IN, V30
   Masood Sarfaraz, 2018, Intelligent Engineering Informatics. Proceedings of the 6th International Conference on FICTA. Advances in Intelligent Systems and Computing (AISC 695), P623, DOI 10.1007/978-981-10-7566-7_63
   McKinlay J, 2010, CHANDOS INF PROF SER, P1, DOI 10.1533/9781780630243
   Mehdi SA, 2002, ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, P2204
   Yeh CCM, 2016, IEEE DATA MINING, P1317, DOI [10.1109/ICDM.2016.89, 10.1109/ICDM.2016.0179]
   Miften FS, 2021, ARTIF INTELL MED, V112, DOI 10.1016/j.artmed.2020.102005
   Munib Q, 2007, EXPERT SYST APPL, V32, P24, DOI 10.1016/j.eswa.2005.11.018
   NIDCD, 2021, AM SIGN LANG
   Nishad A, 2019, FUTURE GENER COMP SY, V93, P96, DOI 10.1016/j.future.2018.10.005
   Olsson J.S., 2006, Combining feature selectors for text classification, P798
   Oz C, 2005, LECT NOTES COMPUT SC, V3497, P157
   Oz C, 2007, NEUROCOMPUTING, V70, P2891, DOI 10.1016/j.neucom.2006.04.016
   Oz C, 2011, ENG APPL ARTIF INTEL, V24, P1204, DOI 10.1016/j.engappai.2011.06.015
   Paudyal P, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P282, DOI 10.1145/2856767.2856794
   Pires R, 2019, J APPL BIOMECH, V35, P87, DOI 10.1123/jab.2017-0349
   Pizzolato S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0186132
   POIZNER H, 1987, BRAIN LANG, V30, P52, DOI 10.1016/0093-934X(87)90027-7
   Prokhorenkova L, 2018, ADV NEUR IN, V31
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Rao GA, 2018, 2018 CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION ENGINEERING SYSTEMS (SPACES), P194, DOI 10.1109/SPACES.2018.8316344
   Rashid O, 2010, LECT NOTES COMPUT SC, V6453, P253
   Rastgoo R, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113336
   Rastgoo R, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110809
   Rehman MZU, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8071126
   Remeseiro B, 2019, COMPUT BIOL MED, V112, DOI 10.1016/j.compbiomed.2019.103375
   Rivera-Acosta M, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091035
   Rodríguez-Tapia B, 2020, IEEE ACCESS, V8, P7792, DOI 10.1109/ACCESS.2019.2963881
   Salo F, 2019, INT CONF COMPUT NETW, P276, DOI [10.1109/iccnc.2019.8685636, 10.1109/ICCNC.2019.8685636]
   Savur C, 2016, IEEE SYS MAN CYBERN, P2872, DOI 10.1109/SMC.2016.7844675
   Savur C, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P497, DOI 10.1109/ICMLA.2015.212
   Schreiber T, 1997, PHYS REV E, V55, P5443, DOI 10.1103/PhysRevE.55.5443
   Sharma R, 2015, EXPERT SYST APPL, V42, P1106, DOI 10.1016/j.eswa.2014.08.030
   Starner T., 1997, Motion-Based Recognit, P227
   Suharjito, 2017, PROCEDIA COMPUT SCI, V116, P441, DOI 10.1016/j.procs.2017.10.028
   Sun C, 2013, IEEE IMAGE PROC, P4190, DOI 10.1109/ICIP.2013.6738863
   Taylor J, 2016, REAL TIME TRANSLATIO
   Too J., 2018, International Journal of Electrical and Computer Engineering, V8, P4221, DOI [10.11591/ijece.v8i6, DOI 10.11591/IJECE.V8I6]
   Ul Haq A, 2019, IEEE ACCESS, V7, P151482, DOI 10.1109/ACCESS.2019.2947701
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Visani G., 2020, ARXIV
   Wadhawan A, 2020, NEURAL COMPUT APPL, V32, P7957, DOI 10.1007/s00521-019-04691-y
   Wadhawan A, 2021, ARCH COMPUT METHOD E, V28, P785, DOI 10.1007/s11831-019-09384-2
   Wang HJ, 2012, NEUROCOMPUTING, V92, P124, DOI 10.1016/j.neucom.2011.08.040
   Wattenberg M., 2016, Distill, V1, DOI DOI 10.23915/DISTILL.00002
   Wu J, 2015, 2015 IEEE 12TH INTERNATIONAL CONFERENCE ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS (BSN)
   Wu J, 2016, IEEE J BIOMED HEALTH, V20, DOI 10.1109/JBHI.2016.2598302
   Yu EZ, 2006, COMPUT IND ENG, V51, P111, DOI 10.1016/j.cie.2006.07.004
   Zafrulla Z., 2011, Proceedings of the 13th international conference on multimodal interfaces, New York, NY, USA, P279, DOI DOI 10.1145/2070481.2070532
   Zamani M, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P398, DOI 10.1109/ICCKE.2014.6993442
   Zhang J, 2020, IEEE INTERNET THINGS, V7, P960, DOI 10.1109/JIOT.2019.2947448
   Zhang Y, 2017, IEEE ACM T COMPUT BI, V14, P64, DOI 10.1109/TCBB.2015.2476796
   Zhao WP, 2016, SCI CHINA CHEM, V59, P114, DOI 10.1007/s11426-015-5442-6
   Zheng M, 2021, ARXIV
NR 109
TC 3
Z9 3
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23833
EP 23871
DI 10.1007/s11042-022-14117-y
EA NOV 2022
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000884953400005
DA 2024-07-18
ER

PT J
AU Shamalik, R
   Koli, S
AF Shamalik, Rameez
   Koli, Sanjay
TI Effective and efficient approach for gesture detection in video through
   monocular RGB frames
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth estimation; Foreground-background separation; Gesture detection
ID DEPTH ESTIMATION
AB Detecting gestures is a difficult operation, especially when the context is dynamic or noisy. Several approaches use a bounding box for the same, which restricts the usability of the frame as well as the user's freedom of movement. This paper proposes a novel method for gesture detection in a real time video. It aims not only to simplify the process but also to extract useful and diverse information from the given gestures. The proposed approach utilizes/uses Residual Neural Network (ResNet) 101 to achieve Foreground-Background separation (FBGS) as one of the results, while the MiDas model based on broadband internet is used for Depth map Estimation (DE) of monocular RGB frames of gestures, thus increasing precision and obviating requirement for a bounding box entirely. For comparative analysis, this hierarchical model is evaluated with and without a Graphics Processing Unit (GPU). In this real-time model, the GPU saves 90% of time while simultaneously improving the accuracy of the final result. In the final frame, the noisy backdrop is removed, the gestures are enhanced, and the relative distance between the objects and gestures is highlighted. The proposed algorithm ensures to avoid duplication of gestures.
C1 [Shamalik, Rameez; Koli, Sanjay] GH Raisoni Coll Engn & Management, Pune, Maharashtra, India.
   [Shamalik, Rameez] BVCOEW, Pune, Maharashtra, India.
   [Koli, Sanjay] Dr DY Patil Sch Engn, Pune, Maharashtra, India.
RP Shamalik, R (corresponding author), GH Raisoni Coll Engn & Management, Pune, Maharashtra, India.; Shamalik, R (corresponding author), BVCOEW, Pune, Maharashtra, India.
EM shamalik1@gmail.com; sanjay.koli@dypic.in
OI Koli, Sanjay/0000-0001-5401-959X
CR Akilan T, 2020, IEEE T INTELL TRANSP, V21, P959, DOI 10.1109/TITS.2019.2900426
   Cabrera-Quiros L, 2020, IEEE T MULTIMEDIA, V22, P138, DOI 10.1109/TMM.2019.2922122
   Cao YZH, 2020, IEEE T CIRC SYST VID, V30, P2674, DOI 10.1109/TCSVT.2019.2929202
   Casser V, 2019, AAAI CONF ARTIF INTE, P8001
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Cui FW, 2021, IEEE T NEUR NET LEAR, V32, P1418, DOI 10.1109/TNNLS.2020.2985588
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Guo CL, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102829
   Guo K, 2020, INT CONF ACOUST SPEE, P1993, DOI [10.1109/ICASSP40776.2020.9053724, 10.1109/icassp40776.2020.9053724]
   Hambarde P, 2020, IEEE IMAGE PROC, P1441, DOI 10.1109/ICIP40778.2020.9190985
   Hambarde P, 2020, IEEE T COMPUT IMAG, V6, P806, DOI 10.1109/TCI.2020.2981761
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu YT, 2018, LECT NOTES COMPUT SC, V11212, P56, DOI 10.1007/978-3-030-01237-3_4
   Luong HV, 2021, EUR SIGNAL PR CONF, P1432, DOI 10.23919/Eusipco47968.2020.9287416
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Joze Hamid Reza Vaezi, 2018, arXiv
   Lee JY, 2021, IEEE T PATTERN ANAL, V43, P830, DOI 10.1109/TPAMI.2019.2946159
   LIM LA, 2018, PATTERN RECOGN LETT
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   LU X, 2020, 2020 IEEE T PATTERN
   Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594
   Mathew A, 2020, IEEE IMAGE PROC, P2810, DOI [10.1109/ICIP40778.2020.9190764, 10.1109/icip40778.2020.9190764]
   Minsoo Song, 2021, IEEE Transactions on Circuits and Systems for Video Technology, V31, P4381, DOI 10.1109/TCSVT.2021.3049869
   Nair R, 2020, INT CONF ADVAN COMPU, P671, DOI [10.1109/ICACCS48705.2020.9074226, 10.1109/icaccs48705.2020.9074226]
   Nowosielski A, 2020, IEEE SENS J, V20, P9293, DOI 10.1109/JSEN.2020.2986855
   Oh SW, 2019, IEEE I CONF COMP VIS, P9225, DOI 10.1109/iccv.2019.00932
   PARGER M, 2022, IEEE T VIS COMPUT GR
   Pathak D, 2017, PROC CVPR IEEE, P6024, DOI 10.1109/CVPR.2017.638
   Pei SL, 2020, IEEE ACCESS, V8, P88259, DOI 10.1109/ACCESS.2020.2992494
   Ranftl R, 2022, IEEE T PATTERN ANAL, V44, P1623, DOI 10.1109/TPAMI.2020.3019967
   Raza SH, 2013, IEEE C COMPUTER VISI
   Ren HY, 2020, INT CONF ACOUST SPEE, P1988, DOI [10.1109/ICASSP40776.2020.9053408, 10.1109/icassp40776.2020.9053408]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Takahashi Masakazu, 2020, 2020 International Research Conference on Smart Computing and Systems Engineering (SCSE). Proceedings, P1, DOI 10.1109/SCSE49731.2020.9313008
   Tsai YH, 2016, PROC CVPR IEEE, P3899, DOI 10.1109/CVPR.2016.423
   Hoang VT, 2020, DATA BRIEF, V30, DOI 10.1016/j.dib.2020.105676
   Voigtlaender P, 2019, PROC CVPR IEEE, P9473, DOI 10.1109/CVPR.2019.00971
   Wang AJ, 2020, IEEE T IMAGE PROCESS, V29, P4130, DOI 10.1109/TIP.2020.2968751
   Wang YL, 2020, IEEE ACCESS, V8, P157493, DOI 10.1109/ACCESS.2020.3018705
   Yang L, 2021, IEEE T IMAGE PROCESS, V30, P39, DOI 10.1109/TIP.2020.3029901
   Yang YP, 2020, IEEE ACCESS, V8, P84217, DOI 10.1109/ACCESS.2020.2992132
   Yang Zhiyong, 2022, IEEE T PATTERN ANAL
   Yuan SM, 2020, 2020 IEEE INTERNATIONAL WORKSHOP ON METROLOGY FOR INDUSTRY 4.0 & IOT (METROIND4.0&IOT), P340, DOI [10.1109/metroind4.0iot48571.2020.9138285, 10.1109/MetroInd4.0IoT48571.2020.9138285]
   Zhan HY, 2018, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2018.00043
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
NR 45
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17231
EP 17242
DI 10.1007/s11042-022-14207-x
EA NOV 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000883287200001
DA 2024-07-18
ER

PT J
AU Liu, LX
   Fan, KF
   Yang, MZ
AF Liu, Lixin
   Fan, Kefeng
   Yang, Mengzhen
TI Federated learning: a deep learning model based on resnet18 dual path
   for lung nodule detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lung nodule detection; Federated learning; Federated averaging (Luna16)
ID SEGMENTATION
AB Lung nodule detection is of vital importance in the prevention of lung cancer. In the past two decades, most machine learning and deep learning approaches have focused on training models using data collected and stored in centralised data repositories. However, as privacy security becoming more and more important, patient data is scattered in different medical institutions on a small scale and fragmented. In this study, we proposed a federated learning method for training a lung nodule detection model on horizontally distributed data from different clients. In particular, the federated averaging algorithm is used to detect lung nodules by proposing a 3D ResNet18 Dual Path Faster R-CNN model. On this basis, we firstly considered that the quality of the data affects the model training effect. Therefore, we proposed a sampling-based content diversity algorithm that is validated on luna16 data, mitigating model overfitting and improving model generalisation with better results, and also reducing the training time of model. In order to further verify 3D ResNet18 Dual Path Faster R-CNN of federated learning algorithm, we compared it with other federated learning algorithms of deep learning. The experimental results show that the 3D ResNet18 Dual Path Faster R-CNN of federated learning algorithm achieves the best results.
C1 [Liu, Lixin] Guilin Univ Elect Technol, Guilin, Peoples R China.
   [Fan, Kefeng] Chinese Elect Standardizat Inst, Beijing, Peoples R China.
   [Yang, Mengzhen] Shanghai Inst Technol, Shanghai, Peoples R China.
C3 Guilin University of Electronic Technology; Shanghai Institute of
   Technology
RP Liu, LX (corresponding author), Guilin Univ Elect Technol, Guilin, Peoples R China.
EM 18277317934@163.com; fankf@126.com; yinz8808@163.com
FU National Key Research and Development Program of China [2021ZD0200406];
   National Key Science and Technology Program [2021ZD0110601]
FX This research was funded by National Key Research and Development
   Program of China (2021ZD0200406), and National Key Science and
   Technology Program 2030 (No.2021ZD0110601).
CR Ambati L. S., 2021, AMCIS
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   Baldwin DR, 2015, LUNG CANCER, V89, P1, DOI 10.1016/j.lungcan.2015.05.004
   Chen K, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.04191
   Chunran Y, 2018, 2018 11 INT C IMAGE, P1, DOI [10.1109/CISP-BMEI.2018.8633101, DOI 10.1109/CISP-BMEI.2018.8633101]
   Cornwell WK, 2006, ECOLOGY, V87, P1465, DOI 10.1890/0012-9658(2006)87[1465:ATTFHF]2.0.CO;2
   Dou Q, 2017, IEEE T BIO-MED ENG, V64, P1558, DOI 10.1109/TBME.2016.2613502
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gupta O, 2018, J NETW COMPUT APPL, V116, P1, DOI 10.1016/j.jnca.2018.05.003
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henschke CI, 2012, RADIOLOGY, V263, P578, DOI 10.1148/radiol.12102489
   Huang X, 2019, COMPUT MED IMAG GRAP, V74, P25, DOI 10.1016/j.compmedimag.2019.02.003
   Huang XJ, 2017, I S BIOMED IMAGING, P379, DOI 10.1109/ISBI.2017.7950542
   Jacob C, 2020, INT CONF ADVAN COMPU, P1279, DOI [10.1109/ICACCS48705.2020.9074161, 10.1109/icaccs48705.2020.9074161]
   Jain P, 2020, P IEEE 6 WORLD FOR I, P1, DOI [10.1109/ICATMRI51801.2020.9398414, DOI 10.1109/ICATMRI51801.2020.9398414]
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jia Ding, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P559, DOI 10.1007/978-3-319-66179-7_64
   Jin HS, 2018, MED PHYS, V45, P2097, DOI 10.1002/mp.12846
   Konecny J, 2016, ARXIV161005492
   Konecny J, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1610.02527
   Kumar S Babu, 2020, Proceedings of Second International Conference on Inventive Research in Computing Applications (ICIRCA 2020), P590, DOI 10.1109/ICIRCA48905.2020.9183183
   Lavanya M., 2020, 2020 4th International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1423, DOI 10.1109/ICECA49313.2020.9297387
   Liao FZ, 2019, IEEE T NEUR NET LEAR, V30, P3484, DOI 10.1109/TNNLS.2019.2892409
   Liu WH, 2021, IEEE J BIOMED HEALTH, V25, P3073, DOI 10.1109/JBHI.2021.3053023
   Manoj T, 2022, 2022 IEEE DELHI SECT, P1, DOI DOI 10.1109/DELCON54057.2022.9752836
   McMahan H. B., 2016, arXiv preprint arXiv:1602.05629
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Nawreen N, 2021, 2021 INT C AUTOMATIO, P1, DOI [10.1109/ACMI53878.2021.9528297, DOI 10.1109/ACMI53878.2021.9528297]
   Nguyen CC, 2021, IEEE ACCESS, V9, P154740, DOI 10.1109/ACCESS.2021.3128942
   Nithila EE, 2016, ALEX ENG J, V55, P2583, DOI 10.1016/j.aej.2016.06.002
   Prithvika PCS, 2021, PROCEEDINGS OF THE 2021 FIFTH INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC 2021), P903, DOI 10.1109/I-SMAC52330.2021.9641051
   Qi Dou, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P630, DOI 10.1007/978-3-319-66179-7_72
   Ranzato M, 2007, PROC CVPR IEEE, P1429
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sai Ambati L., 2020, Issues Inform Syst, V21, P103
   Sreekumar Amrit, 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0209, DOI 10.1109/ICCSP48568.2020.9182258
   Tanwar VK, 2018, IEEE SYS MAN CYBERN, P2073, DOI 10.1109/SMC.2018.00357
   Ullah I, 2020, IEEE REGION 10 SYMP, P1062
   Wang Z., 2018, WACV
   Wang Z, 2017, IEEE T IMAGE PROCESS, V26, P2028, DOI 10.1109/TIP.2017.2666739
   Xie D., 2021, 2021 7 INT C COMPUTE, P980, DOI DOI 10.1109/ICCC54389.2021.9674613
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Zhang WS, 2021, IEEE INTERNET THINGS, V8, P15884, DOI 10.1109/JIOT.2021.3056185
   Zhe Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P10, DOI 10.1109/CVPRW.2015.7301330
   Zhu WT, 2018, I S BIOMED IMAGING, P847, DOI 10.1109/ISBI.2018.8363704
   Zhu WT, 2018, IEEE WINT CONF APPL, P673, DOI 10.1109/WACV.2018.00079
NR 47
TC 5
Z9 5
U1 3
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17437
EP 17450
DI 10.1007/s11042-022-14107-0
EA NOV 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000881546800005
DA 2024-07-18
ER

PT J
AU Zarifi, A
   Naghavi, M
AF Zarifi, Ali
   Naghavi, Mehdi
TI Gender identification of short text author using conceptual
   vectorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Author gender identification; Conceptual vectorization; Virtual identity
   identification; Short text mining
AB The rapid growth of technology and cyberspace has changed the scope and nature of human identity from physical to virtual. New forms of abuse, such as Internet fraud, impersonation, identity theft, and plagiarism have also emerged. Content theft and spoofing have been prevalent in various texts such as news, social network messages and email. The identity of active people in cyberspace, especially criminals, should be identified. One of the most important parts of identifying a person is their gender identity, identifying the text author gender will help to solve this problem. This Article presents a method for improving the gender identification of Persian short text author using conceptual vectorization. Due to the lack of proper data available for this research in Persian language with a valid author's name tag and their text written by the individual himself, a data set was created using valid information. The approach of this project is to use conceptual vectorization method to perform mathematical operations on vector words. Conceptual vectorization attempts to vectorize words in such a way that mathematical calculations make sense on the resulting vectors. To train a system that can identify the gender of the author of text, a neural network capable of learning complex functions was developed and implemented using artificial intelligence and machine learning algorithms. The proposed method, which is based on conceptual vectorization and using neural network for training, achieved a 22% improvement in identifying the gender of the author compared to related tasks. Based on the five-fold cross validation method, accuracy of 81.09% was obtained.
C1 [Zarifi, Ali; Naghavi, Mehdi] Amirkabir Univ Technol, 350 Hafez Ave, Tehran, Iran.
C3 Amirkabir University of Technology
RP Zarifi, A (corresponding author), Amirkabir Univ Technol, 350 Hafez Ave, Tehran, Iran.
EM ali.zarifi.mail@gmail.com; naehavi@aut.ac.ir
OI Zarifi, Ali/0000-0001-7254-2309
CR Amozade, 2017, NATL C LANGUAGE IDEN, P32
   [Anonymous], 2003, Text, DOI [10.1515/text.2003.014, DOI 10.1515/TEXT.2003.014]
   Atar Sharghi, 2021, LANG RELAT RES, V12, P185
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Burger J.D., 2011, DISCRIMINATING GENDE
   Fatima M, 2017, INFORM PROCESS MANAG, V53, P886, DOI 10.1016/j.ipm.2017.03.005
   Fekri-Ershad S, 2019, TRAIT SIGNAL, V36, P507, DOI 10.18280/ts.360605
   Gharayi, 2015, 1 NATL C NURSING PSY, P510
   Idris, 2017, NATL C PASSIVE DEFEN, P15
   KHDR AJ, 2018, 2018 INT C ART INT, pNI322
   Maleki Gorbani, 2019, 6 SCI C ED SCI PSYCH, P30
   Moeinian, 2017, J SOCIOLOGY STUDIES, V9, P83
   Moradi, 2015, AUTOMATIC GENDER IDE, P83
   Muvashah, 2021, PERSIAN NAMES EXCEL
   Peersman Claudia, 2011, P 3 INT WORKSH SEARC, P37, DOI DOI 10.1145/2065023.2065035
   Sazzad H., 2016, 3 INT C ELECT ENG IN
   Tellez ES, 2018, P 9 INT C CLEF ASS C
   Zahir J., 2019, 15 INT C SIGNAL IMAG
NR 18
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17097
EP 17113
DI 10.1007/s11042-022-14141-y
EA NOV 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000879267000002
DA 2024-07-18
ER

PT J
AU Liu, XY
   Wu, ZK
   Wang, XC
AF Liu, Xiangyuan
   Wu, Zhongke
   Wang, Xingce
TI Diffusion tensor image denoising via geometric invariant nonlocal means
   on the tensor manifold
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DTI; Riemannian manifold; Shape; DWI; Non-local means; Diffusion tensor
ID REGULARIZATION; FRAMEWORK; FILTER; NOISE
AB Diffusion tensor imaging (DTI) is an advanced magnetic resonance technology that describes subtle brain structures using a diffusion tensor at each point. The obtained DTI image is always degraded since diffusion-weighted imaging sequences, which are used to estimate DTI images, are corrupted by noise. In this paper, we propose an approach called geometric invariant nonlocal means on the tensor manifold (GINLM-TM) to reduce undesired components in the degraded DTI image. We transform the diffusion tensor into a positive definite matrix (called a tensor) to measure the intrinsic property of the diffusion tensor. Then, we directly regularise DTI images in the tensor manifold endowed with an affine invariant metric. Finally, geometrically invariant measures of patches of tensors are used to define the similarity function of patches to ensure the similarity between patches is more accurate and robust. It is experimentally demonstrated that the proposed method performs adequately in reducing undesired components without blurring the boundaries of DTI images. The results of fractional anisotropy (FA) images and fibre tracking of our restored data indicate that our method performs well in denoising the DTI image.
C1 [Liu, Xiangyuan; Wu, Zhongke; Wang, Xingce] Beijing Normal Univ, Artificial Intelligence Acad, 19 Xinjiekouwai St, Beijing 100875, Peoples R China.
C3 Beijing Normal University
RP Wu, ZK (corresponding author), Beijing Normal Univ, Artificial Intelligence Acad, 19 Xinjiekouwai St, Beijing 100875, Peoples R China.
EM liuxiangyuang@mail.bnu.edu.cn; zwu@bnu.edu.cn; wangxingce@bnu.edu.cn
RI JIANG, Peng/KGL-3427-2024; Han, Yang/JVN-5921-2024
FU National Nature Science Foundation of China [61972041, 62072045];
   National Key R& D Program of China [2020YFC1523302]; Innovation &
   Transfer Fund of Peking University Third Hospital
FX This research was partially supported by the National Nature Science
   Foundation of China (No.61972041, No.62072045), National Key R& D
   Program of China (No. 2020YFC1523302) and Innovation & Transfer Fund of
   Peking University Third Hospital(No.BYSYZHKC2021110).
CR Aja-Fernández S, 2008, IEEE T MED IMAGING, V27, P1389, DOI 10.1109/TMI.2008.920609
   Castaño-Moraga CA, 2007, SIGNAL PROCESS, V87, P263, DOI 10.1016/j.sigpro.2006.02.049
   Celledoni E, 2018, DISSIPATIVE SCHEMES
   ChefD'Hotel C, 2004, J MATH IMAGING VIS, V20, P147, DOI 10.1023/B:JMIV.0000011324.14508.fb
   Coulon O, 2004, MED IMAGE ANAL, V8, P47, DOI 10.1016/j.media.2003.06.002
   Ding ZH, 2005, MAGN RESON MED, V53, P485, DOI 10.1002/mrm.20339
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Diwakar M, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P297, DOI 10.1145/2791405.2791430
   Grassi DC, 2018, ARQ NEURO-PSIQUIAT, V76, P189, DOI [10.1590/0004-282x20180007, 10.1590/0004-282X20180007]
   Laus F, 2017, SIAM J IMAGING SCI, V10, P416, DOI 10.1137/16M1087114
   Lebrun M, 2013, SIAM J IMAGING SCI, V6, P1665, DOI 10.1137/120874989
   Lee TM., 2006, INT SOC OPT PHOTON, V6144, P61446
   Liu S Q, 2019, J CHINESE COMPUTER S
   Liu Shengzhong, 2019, J Cell Physiol, DOI 10.1002/jcp.28556
   Liu SQ, 2019, J MED IMAG HEALTH IN, V9, P1993, DOI 10.1166/jmihi.2019.2832
   Maggioni M, 2013, IEEE T IMAGE PROCESS, V22, P119, DOI 10.1109/TIP.2012.2210725
   Manjón JV, 2008, MED IMAGE ANAL, V12, P514, DOI 10.1016/j.media.2008.02.004
   Martin-Fernandez M, 2009, MED IMAGE ANAL, V13, P19, DOI 10.1016/j.media.2008.05.004
   Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z
   Pennec X., 2020, Riemannian Geometric Statistics in Medical Image Analysis, P75
   PENNEC X, 2004, RR5093 INRIA
   Pennec X, 2006, J MATH IMAGING VIS, V25, P127, DOI 10.1007/s10851-006-6228-4
   Poupon C, 2001, MED IMAGE ANAL, V5, P1, DOI 10.1016/S1361-8415(00)00030-X
   Seo Y, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49311-w
   Sijbers J, 1998, IEEE T MED IMAGING, V17, P357, DOI 10.1109/42.712125
   Su BH, 2014, EXP THER MED, V8, P447, DOI 10.3892/etm.2014.1764
   Tschumperlé D, 2001, PROC CVPR IEEE, P948
   Wang ZZ, 2005, IEEE T MED IMAGING, V24, P1267, DOI 10.1109/TMI.2005.854516
   Wang ZZ, 2004, IEEE T MED IMAGING, V23, P930, DOI 10.1109/TMI.2004.831218
   Wiest-Daesslé N, 2007, LECT NOTES COMPUT SC, V4792, P344
   Yi S, 2018, J IMAGE GRAPHICS
   Zhang XF, 2007, AIP CONF PROC, V922, P720, DOI 10.1063/1.2759777
NR 33
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15817
EP 15835
DI 10.1007/s11042-022-14025-1
EA OCT 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000876660800001
DA 2024-07-18
ER

PT J
AU Khaleel, MI
AF Khaleel, Mustafa Ibrahim
TI Hybrid cloud-fog computing workflow application placement: joint
   consideration of reliability and time credibility
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud-Fog integration; Application placement; Scheduling reliability;
   Workflow makespan
ID EDGE
AB The fast evolution of the Internet of Things (IoT) marketplace demands real-time interactive services. Cloud computing systems aim to harness remote data center-based computing resources to perform these services instantly. However, these cloud systems fall short due to the distances from users to the data source, affecting response time and scheduling reliability. The newest drift is to integrate fog resources and cloud resources to perform data analytics in proximity to the edge end-users. However, the makespan and reliability are two prime concerns in such integration that requires attention. Most application placement policies in the literature do not consider makespan and reliability simultaneously. In this paper, we propose a hybrid multi-criteria decision-making (Hybrid-MCD) model to optimize the scheduling reliability and workflow makespan simultaneously. It formulates the problem as a bi-objective task scheduling problem that enhances the scheduling reliability and improves the service delivery time ratio of workflow tasks placed on computing resources. Furthermore, we formed a Deadline-aware stepwise Reliability Optimization (DARO) algorithm that maximizes the application's execution time and reliability by adapting the reliability-recursive maximization algorithm and remapping workflow applications that are not on the critical path. The proposed algorithm's performance is evaluated in a simulated cloud-fog environment using iFogSim. The results demonstrate that the algorithm is more efficient in optimizing makespan and system reliability jointly than other comparable algorithms.
C1 [Khaleel, Mustafa Ibrahim] Univ Sulaimani, Coll Sci, Comp Dept, Sulaimani 46001, Kurdistan Regio, Iraq.
C3 University of Sulimanyah
RP Khaleel, MI (corresponding author), Univ Sulaimani, Coll Sci, Comp Dept, Sulaimani 46001, Kurdistan Regio, Iraq.
EM mustafa.khaleel@univsul.edu.iq
CR Alqahtani F, 2021, PEER PEER NETW APPL, V14, P1905, DOI 10.1007/s12083-021-01125-2
   Angel NA, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22010196
   [Anonymous], 2020, EE TIMES ASIA
   [Anonymous], 2022, CLOUD CYB SOL
   Nguyen BM, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091730
   Cao F, 2013, J SUPERCOMPUT, V66, P1462, DOI 10.1007/s11227-013-0938-3
   de Souza Toniolli JL., 2019, P 12 IEEEACM INT C U, P77, DOI DOI 10.1145/3368235.3368846
   Deng Z., 2021, J SUPERCOMPUT, V77, P11643, DOI [10.1007/s11227-021-03764-x, DOI 10.1007/s11227-021-03764-x]
   Dogan A, 2002, IEEE T PARALL DISTR, V13, P308, DOI 10.1109/71.993209
   Garg R, 2019, CLUSTER COMPUT, V22, P1283, DOI 10.1007/s10586-019-02911-7
   Goudarzi M, 2021, IEEE T MOBILE COMPUT, V20, P1298, DOI 10.1109/TMC.2020.2967041
   Huang H., 2021, IEEE T NETW SCI ENG
   Ijaz S, 2021, COMPUTING, V103, P2033, DOI 10.1007/s00607-021-00930-0
   IoT, 2020, IOT BUSINESS NEWS
   Jiang JQ, 2019, J CIRCUIT SYST COMP, V28, DOI 10.1142/S0218126619501597
   Kaur S, 2019, ARAB J SCI ENG, V44, P2867, DOI 10.1007/s13369-018-3614-3
   Lee S, 2021, IEEE WIREL COMMUN LE, V10, P2175, DOI 10.1109/LWC.2021.3095496
   Liu SQ, 2019, PHYSICA A, V521, P667, DOI 10.1016/j.physa.2019.01.036
   Liu Y, 2019, IEEE ACCESS, V7, P140875, DOI 10.1109/ACCESS.2019.2944204
   Mahmud R, 2022, J SYST SOFTWARE, V190, DOI 10.1016/j.jss.2022.111351
   Mahmud R, 2020, J PARALLEL DISTR COM, V135, P177, DOI 10.1016/j.jpdc.2019.10.001
   Mahmud R, 2018, ICDCN'18: PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING AND NETWORKING, DOI 10.1145/3154273.3154347
   Medara R, 2021, WIRELESS PERS COMMUN, V119, P1301, DOI 10.1007/s11277-021-08263-z
   Memon I, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8897098
   Ming Mao, 2012, 2012 IEEE 5th International Conference on Cloud Computing (CLOUD), P423, DOI 10.1109/CLOUD.2012.103
   Motlagh AA, 2022, INT J COMMUN SYST, V35, DOI 10.1002/dac.5022
   Nan YC, 2018, J PARALLEL DISTR COM, V112, P53, DOI 10.1016/j.jpdc.2017.09.009
   Nurelmadina N, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13010338
   Plank JS, 1998, DIG PAP INT SYMP FAU, P48, DOI 10.1109/FTCS.1998.689454
   Raji MF, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/3204695
   Rani R, 2022, COMPLEX INTELL SYST, V8, P1425, DOI 10.1007/s40747-021-00609-1
   Saeedi S, 2020, COMPUT IND ENG, V147, DOI 10.1016/j.cie.2020.106649
   Sharma R, 2020, MULTIMED TOOLS APPL, V79, P28155, DOI 10.1007/s11042-020-09347-x
   Stavrinides GL, 2019, MULTIMED TOOLS APPL, V78, P24639, DOI 10.1007/s11042-018-7051-9
   Tang J., 2022, IEEE TRANS CLOUD COM
   Tarafdar A, 2021, J GRID COMPUT, V19, DOI 10.1007/s10723-021-09548-0
   Tsai JF, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041909
   Wang PW, 2020, IEEE ACCESS, V8, P29281, DOI 10.1109/ACCESS.2020.2972963
   Xu Q, 2014, MATH PROBL ENG, V2014
   Xu QZ, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123205
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Xu QZ, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/659809
   Yousefpour A, 2019, J SYST ARCHITECT, V98, P289, DOI 10.1016/j.sysarc.2019.02.009
   Yousif A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030850
   Zhou XM, 2020, J CIRCUIT SYST COMP, V29, DOI 10.1142/S0218126620501674
NR 46
TC 4
Z9 4
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18185
EP 18216
DI 10.1007/s11042-022-13923-8
EA OCT 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000863553600006
DA 2024-07-18
ER

PT J
AU Qian, ZZ
   Mu, J
   Tian, F
   Gao, ZY
   Zhang, J
AF Qian, Zhizhe
   Mu, Jing
   Tian, Feng
   Gao, Zhiyu
   Zhang, Jie
TI Facial expression recognition based on strong attention mechanism and
   residual network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression; Attention mechanism; Residual module
ID FEATURES; MODEL
AB Most facial expression recognition (FER) algorithms are based on shallow features, and the deep networks tend to lose some key features in the expression, such as eyes, nose and mouth. To address the limitations, we present in this paper a novel approach, named CBAM-Global-Efficient Channel Attention-ResNet (C-G-ECA-R). C-G-ECA-R combines a strong attention mechanism and residual network. The strong attention enhances the extraction of important features of expressions by embedding the channel and spatial attention mechanism before and after the residual module. The addition of Global-Efficient Channel Attention (G-ECA) into the residual module strengthens the extraction of key features and reduces the loss of facial information. The extensive experiments have been conducted on two publicly available datasets, Extended Cohn-Kanade and Japanese Female Facial Expression. The results demonstrate that our proposed C-G-ECA-R, especially under ResNet34, has achieved 98.98% and 97.65% accuracy, respectively for the two datasets, that are higher than the state-of-arts.
C1 [Qian, Zhizhe; Mu, Jing; Gao, Zhiyu; Zhang, Jie] Xian Technol Univ, Sch Comp Sci & Engn, Xian 710021, Peoples R China.
   [Tian, Feng] Duke Kunshan Univ, Div Nat & Appl Sci, Suzhou, Peoples R China.
C3 Xi'an Technological University; Duke Kunshan University
RP Mu, J (corresponding author), Xian Technol Univ, Sch Comp Sci & Engn, Xian 710021, Peoples R China.
EM qzz_922@163.com; mujing@xatu.edu.cn; ft47@duke.edu
FU National Natural Science Foundation of china [62177037]; Education
   Department of Shaanxi Provincial Government Service Local Special
   Scientific Research Plan Project [22JC037]
FX This work is supported by National Natural Science Foundation of china
   under grant number (No. 62177037) and Education Department of Shaanxi
   Provincial Government Service Local Special Scientific Research Plan
   Project under grant number (No. 22JC037).
CR Arriaga O., 2017, ARXIV
   Avani VS, 2021, MULTIMED TOOLS APPL, V80, P3367, DOI 10.1007/s11042-020-09806-5
   Ayeche F, 2021, PATTERN ANAL APPL, V24, P1095, DOI 10.1007/s10044-021-00972-2
   Bystroff C, 2000, J MOL BIOL, V301, P173, DOI 10.1006/jmbi.2000.3837
   Cao S, 2020, IET IMAGE PROCESS, V14, P2417, DOI 10.1049/iet-ipr.2020.0063
   Chen DL, 2021, DIGIT SIGNAL PROCESS, V108, DOI 10.1016/j.dsp.2020.102906
   Gera D, 2021, PATTERN RECOGN LETT, V145, P58, DOI 10.1016/j.patrec.2021.01.029
   He JY, 2023, J AM STAT ASSOC, V118, P551, DOI 10.1080/01621459.2021.1942012
   Khaliluzzaman Md, 2019, 2019 IEEE International Conference on Robotics, Automation, Artificial-intelligence and Internet-of-Things (RAAICON), P98, DOI 10.1109/RAAICON48939.2019.42
   Li J, 2020, NEUROCOMPUTING, V411, P340, DOI 10.1016/j.neucom.2020.06.014
   Li K, 2020, VISUAL COMPUT, V36, P391, DOI 10.1007/s00371-019-01627-4
   Liu X, 2023, MECH BASED DES STRUC, V51, P2918, DOI [10.1080/15397734.2021.1911665, 10.1007/s11043-021-09519-8]
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Ma X., 2021, P 2021 IEEE INT C MU, P1
   Mena-Chalco JP, 2008, IEEE ACM T COMPUT BI, V5, P198, DOI 10.1109/TCBB.2007.70259
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Mnih V, 2014, ADV NEUR IN, V27
   Mohan K, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3031835
   Rao TR, 2021, IEEE MULTIMEDIA, V28, P11, DOI 10.1109/MMUL.2021.3065985
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Rubel A, 2019, IEEE IMAGE PROC, P41, DOI [10.1109/ICIP.2019.8802911, 10.1109/icip.2019.8802911]
   Sabour S, 2017, ADV NEUR IN, V30
   Sadeghi H, 2019, MULTIMED TOOLS APPL, V78, P30335, DOI 10.1007/s11042-019-07863-z
   Smolyanskiy N, 2014, IMAGE VISION COMPUT, V32, P860, DOI 10.1016/j.imavis.2014.08.005
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Vinay A, 2018, PROCEDIA COMPUT SCI, V143, P519, DOI 10.1016/j.procs.2018.10.425
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang ZN, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107694
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu F, 2021, 25 INT C PATTERN REC
   Xie SY, 2019, IEEE T MULTIMEDIA, V21, P211, DOI 10.1109/TMM.2018.2844085
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhu XL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062003
   Zou W, 2022, APPL INTELL, V52, P2918, DOI 10.1007/s10489-021-02575-0
NR 34
TC 3
Z9 3
U1 10
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 14287
EP 14306
DI 10.1007/s11042-022-13799-8
EA SEP 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000861190800001
DA 2024-07-18
ER

PT J
AU Sahu, Y
   Tripathi, A
   Gupta, RK
   Gautam, P
   Pateriya, RK
   Gupta, A
AF Sahu, Yatendra
   Tripathi, Abhishek
   Gupta, Rajeev Kumar
   Gautam, Pranav
   Pateriya, R. K.
   Gupta, Abhishek
TI A CNN-SVM based computer aided diagnosis of breast Cancer using
   histogram K-means segmentation technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural network (CNN); Support vector machine (SVM); Breast
   cancer; Computer aided diagnosis; Histogram; Pre-trained model;
   ResNet-18
ID SYSTEM
AB Breast cancer is the second most common prevalent type of cancer found in women around the world. Early detection and screening of individuals can be beneficial in helping to bring down the high mortality rate. Computer aided diagnosis (CAD), mammography, computed tomography (CT), ultrasound, and biopsy are the most common procedures to diagnose the cancer. This paper proposed a computer aided ensemble method for diagnosis of breast cancer using a ReNet18 and support vector machine (SVM) where pretrained ReNet18 model is used to extracts the features from the X-ray image and SVM is used to diagnose the cancer. In order to improve the performance, haze reduction is applied to enhance the images quality followed by tumor segmentation to separate the tumor region from the image by using histogram-based K-means technique. The experiments were analyzed over the BreakHis dataset, which contains two categories benign and malignant. The proposed model is evaluated for four (40x,100x,200x,400x) magnification factor. Experiment result shows that, proposed model gives higher accuracy of 92.6% for 200x magnification. The highest specificity and precision obtained are 93.1% and 86.5%, respectively, for the100x magnification factor. The obtained results proved that the proposed architecture is efficient in image classification of histopathological breast cancer cell images.
C1 [Sahu, Yatendra] Indian Inst Informat Technol, Bhopal, India.
   [Tripathi, Abhishek] Koneru Lakshmaiah Educ Fdn, Hyderabad, India.
   [Gupta, Rajeev Kumar] Pandit Deendayal Energy Univ, Gandhinagar, India.
   [Gautam, Pranav; Pateriya, R. K.] Maulana Azad Natl Inst Technol, Bhopal, India.
   [Gupta, Abhishek] Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra, Jammu & Kashmir, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Pandit Deendayal Energy University; National Institute of Technology
   (NIT System); Maulana Azad National Institute of Technology Bhopal; Shri
   Mata Vaishno Devi University
RP Gupta, A (corresponding author), Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra, Jammu & Kashmir, India.
EM yatensahu@gmail.com; abhishek.cse@klh.edu.in;
   Rajeevmanit12276@gmail.com; gautam.pranav09@gmail.com;
   pateriyark@gmail.com; abhishekgupta10@yahoo.co.in
RI Gupta, Rajeev Kumar/AAF-7872-2021; Gupta, Abhishek/O-3016-2019
OI Gupta, Rajeev Kumar/0000-0002-5317-9919; Gupta,
   Abhishek/0000-0002-8592-9964
CR Halim AAA, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112210753
   Akben SB, 2019, IRBM, V40, P355, DOI 10.1016/j.irbm.2019.05.007
   Alanazi SA, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5528622
   Altaf MM, 2021, MATH BIOSCI ENG, V18, P5029, DOI 10.3934/mbe.2021256
   [Anonymous], 2021, WHO director-generals' opening remarks at the media briefing on Covid 19
   Aswathy M. A., 2017, Informatics in Medicine Unlocked, V8, P74, DOI 10.1016/j.imu.2016.11.001
   Bajaj V, 2019, NEURAL COMPUT APPL, V31, P3307, DOI 10.1007/s00521-017-3282-3
   Bhatti UA, 2016, INT C SMART HLTH
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3059703
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Boughorbel S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177678
   Budak Ü, 2020, IRBM, V41, P106, DOI 10.1016/j.irbm.2020.02.001
   Chauhan A, 2021, 3 INT C INVENTIVE RE, P1
   Fan GF, 2022, INT J ELEC POWER, V139, DOI 10.1016/j.ijepes.2022.108073
   Ferlay J., GLOBAL CANC OBSERVAT
   Fernandez-Moral E, 2018, IEEE INT VEH SYM, P1051, DOI 10.1109/IVS.2018.8500497
   Filipczuk P, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P1623, DOI 10.1109/ISBI.2012.6235887
   Gupta RK, 2022, INTERDISCIP SCI, V14, P485, DOI 10.1007/s12539-022-00502-6
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang SQ, 2020, IET IMAGE PROCESS, V14, P3324, DOI 10.1049/iet-ipr.2019.0772
   Huh Minyoung, 2016, ABS160808614 CORR
   in.mathworks.com, HAZE REDUCTION
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Mishra A.K., 2019, P SAI INTELLIGENT SY, P724
   Moo TA, 2018, PET CLIN, V13, P339, DOI 10.1016/j.cpet.2018.02.006
   Nielsen F, 2014, ENTROPY-SWITZ, V16, P3273, DOI 10.3390/e16063273
   Ragab DA, 2019, PEERJ, V7, DOI 10.7717/peerj.6201
   Saritas M.M., 2019, International journal of intelligent systems and applications in engineering, V7, P88, DOI 10.18201/ijisae.2019252786
   SIBBERING M, 2016, SURGERY, V34, P25, DOI DOI 10.1016/J.MPSUR.2015.10.005
   Sivasangari A, 2022, LECT NOTE DATA ENG, V68, P693, DOI 10.1007/978-981-16-1866-6_50
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Spanhol FA, 2016, IEEE IJCNN, P2560, DOI 10.1109/IJCNN.2016.7727519
   Sudharshan PJ, 2019, EXPERT SYST APPL, V117, P103, DOI 10.1016/j.eswa.2018.09.049
   Ting FF, 2019, EXPERT SYST APPL, V120, P103, DOI 10.1016/j.eswa.2018.11.008
   Too J, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6020021
   Upasani N, 2019, APPL SOFT COMPUT, V82, DOI 10.1016/j.asoc.2019.105595
   Vapnik V.N., 2000, The Nature of Statistical Learning Theory, DOI DOI 10.1007/978-1-4757-3264-1_1
   Vijayasarveswari V, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229367
   Vijayasarveswari V, 2017, 2017 IEEE 13TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA), P238, DOI 10.1109/CSPA.2017.8064958
   Wang LL, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071572
   who.int, WHO FACTSHEETS
   Zhou X, 2020, 7 INT C BEHAVIOURAL, DOI [10.1109/BESC51023.2020.9348322, DOI 10.1109/BESC51023.2020.9348322]
NR 46
TC 6
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 14055
EP 14075
DI 10.1007/s11042-022-13807-x
EA SEP 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000860416900008
DA 2024-07-18
ER

PT J
AU Suryawanshi, S
   Chakravarthi, BR
   Arcan, M
   Buitelaar, P
AF Suryawanshi, Shardul
   Chakravarthi, Bharathi Raja
   Arcan, Mihael
   Buitelaar, Paul
TI TrollsWithOpinion: A taxonomy and dataset for predicting domain-specific
   opinion manipulation in troll memes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Troll memes classification; Offensive multimodal content; Corpora;
   Opinion manipulation
AB Memes have become a de-facto media device in online communication. Unfortunately, memes are also used for trolling, which intends to demean, harass, or bully targeted individuals. As a result of which, the targeted individual could fall prey to opinion manipulation. Trolling via Image With Text (IWT) memes which we refer to as 'troll memes', are difficult to identify due to the multimodal (image + text) nature of such memes. However, the research into the identification and classification of troll memes with opinion manipulation remains unexplored. To bridge this research gap, we introduce a three-level taxonomy that studies the effect of trolling in domain-specific opinion manipulation. On the first level, we classify the meme as troll or not troll. On the second level, we classify if the meme intends opinion manipulation. On the third level, if the opinion manipulation is present, then we classify the domain (political, product, other) of the opinion manipulation. To support the class definitions proposed in the taxonomy, we enhanced an existing dataset (Memotion) by annotating the data with our defined classes. This results in a dataset of 8,881 IWT memes in the English language (TrollsWithOpinion dataset) which we make available as open-source at Github(https://github.com/sharduls007/TrollOpinionMemes). We perform experiments on all three levels and present the classification report of the results using Machine Learning and state-of-the-art Deep Learning techniques. The classification report highlights the complex nature of the task since the models perform well on the first two levels. However, we see a degradation of the evaluation results on the third level of the taxonomy.
C1 [Suryawanshi, Shardul; Chakravarthi, Bharathi Raja; Arcan, Mihael; Buitelaar, Paul] Natl Univ Ireland Galway, Insight SFI Res Ctr Data Analyt, Data Sci Inst, Galway, Ireland.
C3 Ollscoil na Gaillimhe-University of Galway
RP Suryawanshi, S (corresponding author), Natl Univ Ireland Galway, Insight SFI Res Ctr Data Analyt, Data Sci Inst, Galway, Ireland.
EM shardul.suryawanshi@insight-centre.org
RI Chakravarthi, Bharathi Raja/ABD-4145-2020
OI Chakravarthi, Bharathi Raja/0000-0002-4575-7934
FU Science Foundation Ireland (SFI) [SFI/12/RC/2289]; European Regional
   Development Fund
FX This publication has emanated from research supported in part by a
   research grant from Science Foundation Ireland (SFI) under Grant Number
   SFI/12/RC/2289 P2 for the Insight SFI Research Centre for Data
   Analytics, co-funded by the European Regional Development Fund. We would
   like to thank all the annotators for their valuable efforts throughout
   the development of the dataset.
CR ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Atanasov Atanas, 2019, P 23 C COMP NAT LANG, P1023, DOI DOI 10.18653/V1/K19-1096
   Bishop Jonathan, 2014, International Journal of Web Based Communities, V10, P7
   Boatwright BC, 2018, TROLL FACTORIESTHE I
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Coxall M., 2013, Human manipulation: A handbook
   DAWKINS R, 1976, SELFISH GENE
   de la Vega Luis Gerardo Mojica, 2018, P 11 INT C LANG RES
   Devlin J., 2018, BERT PRE TRAINING DE
   Du Y, 2020, P INT AAAI C WEB SOC, V14, P153, DOI [DOI 10.1609/ICWSM.V14I1.7287, 10.1609/icwsm.v14i1.7287]
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Hardaker C, 2010, J POLITENESS RES-LAN, V6, P215, DOI 10.1515/JPLR.2010.011
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Karadzhov G, 2018, ARXIV
   Kiela D., 2019, arXiv
   Krippendorff K, 2011, COMPUTING KRIPPENDOR
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kumar K, 2020, M2P2 MOVIES TRAILER
   Kumar N, 2017, INT CONF ADV COMPU, P15, DOI 10.1109/ICoAC.2017.8441495
   Kumar R, 2020, IEEE WORKS SIG POW, DOI 10.1109/spi48784.2020.9218199
   Kumar S, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Kumar S, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P857, DOI 10.1145/3038912.3052677
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mihaylov T, 2015, P 19 C COMPUTATIONAL, P310
   Ordonez V., 2011, ADV NEURAL INFORM PR, P1143
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   PRAAGMAN J, 1985, EUR J OPER RES, V19, P144, DOI 10.1016/0377-2217(85)90321-2
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sanh V., 2019, P 33 C NEURAL INFORM
   Schmidt A., 2017, P 5 INT WORKSH NAT L, P1
   SHAO J, 1993, J AM STAT ASSOC, V88, P486, DOI 10.2307/2290328
   Sharma C., 2020, P 14 INT WORKSHOP SE
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Sharma S, 2017, LECT NOTES COMPUT SC, V10597, P373, DOI 10.1007/978-3-319-69900-4_47
   Syuntyurenko OV, 2015, SCI TECH INF PROCESS, V42, P205, DOI 10.3103/S014768821504005X
   Tomaiuolo M, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12020031
   VIJAYVERGIA A, 2018, 2018 C INFORM COMMUN
   Vijayvergia A, 2021, MULTIMED TOOLS APPL, V80, P28349, DOI 10.1007/s11042-021-10997-8
   Zampieri M., 2019, P 13 INT WORKSH SEM, P75, DOI DOI 10.18653/V1/S19-2010
   Zannettou S, 2018, IMC'18: PROCEEDINGS OF THE INTERNET MEASUREMENT CONFERENCE, P188, DOI 10.1145/3278532.3278550
   Zhang H, 2005, INT J PATTERN RECOGN, V19, P183, DOI 10.1142/S0218001405003983
NR 42
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9137
EP 9171
DI 10.1007/s11042-022-13796-x
EA SEP 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000857685800005
DA 2024-07-18
ER

PT J
AU Ma, ZP
   Li, TT
   Zhou, J
   Yang, K
AF Ma, Ziping
   Li, Tingting
   Zhou, Jie
   Yang, Ke
TI 3D Bessel moments for 3D model retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 3D Bessel moments; 3D Model retrieval; Invariant descriptor moments; 3D
   Shape recognition
ID IMAGE-ANALYSIS; POINT CLOUD; INVARIANT; RECOGNITION; KRAWTCHOUK
AB Three-dimensional (3D) model retrieval and shape recognition are focus of research with the development of big data technology and the increasing application of 3D model in practical application recently. However, there still exist some challenges, such as the diculties of designing more accurate and efficient description with low dimension, geometric invariance and strong robustness in feature extraction. In virtue of this, we propose 3D Bessel moments based on polar representation by the first-class Bessel polynomial. The 3D Bessel moments inherit the properties of and geometric invariance of Bessel polynomial and possess strong capability of shape describing for 3D models. Firstly, the derivation of 3D Bessel moments are constructed and its geometric invariance proofs are given theoretically. Secondly the standardized coordinate system is calculated and the principal component analysis transform is performed to eliminate the position and scale dierences between 3D models. Thereafter, 3D models in the test sets are voxelized. Finally, 3D Bessel moments are calculated to extract rotation, scaling, and translation invariance descriptors for model retrieval. The effectiveness of the proposed method is verified on the McGill 3D shape benchmark and ModelNet10 datasets. Experimental results show that the proposed method has strong robust to different simplification rates of 3D models, is invariant to rotation, scaling and translation, and performs better for model retrieval than state-of-the-art methods on test datasets.
C1 [Ma, Ziping] North Minzu Univ, Sch Math & Informat Sci, Yinchuan, Ningxia, Peoples R China.
   [Li, Tingting; Zhou, Jie; Yang, Ke] North Minzu Univ, Sch Comp Sci & Engn, Yinchuan, Ningxia, Peoples R China.
C3 North Minzu University; North Minzu University
RP Ma, ZP (corresponding author), North Minzu Univ, Sch Math & Informat Sci, Yinchuan, Ningxia, Peoples R China.
EM 2006041@nmu.edu.cn; litingting_1120@163.com; 2649403431@qq.com;
   1525932065@qq.com
RI zhang, ting/IYT-0642-2023; Ting, Zhang/KGM-5479-2024; Li,
   Tingting/HKE-0812-2023; L, J/JEF-9564-2023
OI ma, ziping/0000-0002-6764-6135
FU Basic Scientific Research in Central Universities of Northern Minzu
   University [FWNX21, 2021KJCX09]; Natural Science Foundation of Ningxia
   [2022AAC03268, 2020AAC03215]; National Natural Science Foundation of
   China [61462002]; "Computer Vision and Virtual Reality" innovation team
   of North Minzu University
FX This research is supported by Basic Scientific Research in Central
   Universities of Northern Minzu University (Nos.FWNX21, 2021KJCX09),
   Natural Science Foundation of Ningxia (No. 2022AAC03268, 2020AAC03215),
   the National Natural Science Foundation of China (No.61462002), the
   "Computer Vision and Virtual Reality" innovation team of North Minzu
   University.
CR Al-Zu'bi S, 2021, MULTIMED TOOLS APPL, V80, P16887, DOI 10.1007/s11042-020-09160-6
   AMOS DE, 1986, ACM T MATH SOFTWARE, V12, P265, DOI 10.1145/7921.214331
   Batioua I, 2017, PATTERN RECOGN, V71, P264, DOI 10.1016/j.patcog.2017.06.013
   Ben Abdallah A, 2010, PATTERN RECOGN LETT, V31, P1981, DOI 10.1016/j.patrec.2010.06.009
   Daoui A, 2020, CIRC SYST SIGNAL PR, V39, P4552, DOI 10.1007/s00034-020-01384-z
   El Mallahi M., 2018, Pattern Recognition and Image Analysis, V28, P207, DOI 10.1134/S1054661818020128
   El Mallahi M, 2018, NEURAL COMPUT APPL, V30, P2283, DOI 10.1007/s00521-016-2782-x
   El Mallahi M, 2018, MULTIMED TOOLS APPL, V77, P6583, DOI 10.1007/s11042-017-4573-5
   El Sayed AR, 2019, RAIRO-OPER RES, V53, P487, DOI 10.1051/ro/2018082
   Farokhi S, 2015, INFORM SCIENCES, V316, P234, DOI 10.1016/j.ins.2015.04.030
   Hosny KM, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/353406
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Karmouni H, 2019, CIRC SYST SIGNAL PR, V38, P3715, DOI 10.1007/s00034-019-01025-0
   Katayama K, 2020, IEICE T INF SYST, VE103D, P992, DOI 10.1587/transinf.2019DAP0010
   Lakhili Z, 2020, MULTIMED TOOLS APPL, V79, P18883, DOI 10.1007/s11042-020-08654-7
   Li ZM, 2005, LECT NOTES COMPUT SC, V3611, P483
   Li ZM, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 2, PROCEEDINGS, P565
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Ma J, 2019, ISOT ENVIRON HEALT S, V55, P272, DOI 10.1080/10256016.2019.1601090
   Ma ZP, 2022, MULTIMED TOOLS APPL, V81, P32519, DOI 10.1007/s11042-022-12041-9
   Ma ZP, 2017, NEUROCOMPUTING, V259, P140, DOI 10.1016/j.neucom.2016.09.124
   Ma Ziping, 2014, Journal of Computer Aided Design & Computer Graphics, V26, P609
   Mahdaoui A, 2020, ADV MULTIMED, V2020, DOI 10.1155/2020/8825205
   Mesbah A, 2016, INT CONF MULTIMED, P1, DOI 10.1109/ICMCS.2016.7905559
   Mesbah A, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061621
   Novotni M, 2004, COMPUT AIDED DESIGN, V36, P1047, DOI 10.1016/j.cad.2004.01.005
   Novotni M., 2003, P 8 ACM S SOL MOD AP, P216, DOI DOI 10.1145/781606.781639
   Pei Yandong, 2020, Journal of Computer Applications, V40, P1863
   Peng B, 2020, IEEE I C VI COM I PR, P185, DOI 10.1109/vcip49819.2020.9301813
   Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8
   Tang Yong, 2008, Journal of System Simulation, V20, P3089
   Wei X, 2020, PROC CVPR IEEE, P1847, DOI 10.1109/CVPR42600.2020.00192
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xiao B, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023002
   Xiao B, 2014, IMAGE VISION COMPUT, V32, P994, DOI 10.1016/j.imavis.2014.09.002
   Xiao B, 2010, PATTERN RECOGN, V43, P2620, DOI 10.1016/j.patcog.2010.03.013
   Yamni M, 2021, MULTIMED TOOLS APPL, V80, P26683, DOI 10.1007/s11042-020-10311-y
   Yang B, 2015, PATTERN RECOGN LETT, V54, P18, DOI 10.1016/j.patrec.2014.11.014
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang Hui, 2006, Journal of Southeast University (Natural Science Edition), V36, P857
   Zhang Y, 2021, IEEE T MED IMAGING
   Zhou J., 2021, COMPUT INFORM, V32, P1001
   Zl A., 2019, PROCEDIA COMPUT SCI, V148, P12
NR 43
TC 0
Z9 0
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 SEP 21
PY 2022
DI 10.1007/s11042-022-13655-9
EA SEP 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4P8AF
UT WOS:000855611900002
DA 2024-07-18
ER

PT J
AU Wang, J
   Xuan, SB
   Zhang, H
   Qin, XY
AF Wang, Jie
   Xuan, Shibin
   Zhang, Hao
   Qin, Xuyang
TI The moving target tracking and segmentation method based on space-time
   fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Target tracking; Kalman filtering; Segmentation; Elliptic fitting
ID NETWORKS
AB At present, the target tracking method based on the correlation operation mainly uses deep learning to extract spatial information from video frames and then performs correlations on this basis. However, it does not extract the motion features of tracking targets on the time axis, and thus tracked targets can be easily lost when occlusion occurs. To this end, a spatiotemporal motion target tracking model incorporating Kalman filtering is proposed with the aim of alleviating the problem of occlusion in the tracking process. In combination with the segmentation model, a suitable model is selected by scores to predict or detect the current state of the target. We use an elliptic fitting strategy to evaluate the bounding boxes online. Experiments demonstrate that our approach performs well and is stable in the face of multiple challenges (such as occlusion) on the VOT2016 and VOT2018 datasets with guaranteed real-time algorithm performance.
C1 [Wang, Jie; Xuan, Shibin; Zhang, Hao; Qin, Xuyang] Guangxi Minzu Univ, Sch Artificial Intelligence, Nanning 530006, Peoples R China.
   [Xuan, Shibin] Guangxi Key Lab Hybrid Computat & IC Design Anal, Nanning 530006, Peoples R China.
C3 Guangxi Minzu University
RP Xuan, SB (corresponding author), Guangxi Minzu Univ, Sch Artificial Intelligence, Nanning 530006, Peoples R China.; Xuan, SB (corresponding author), Guangxi Key Lab Hybrid Computat & IC Design Anal, Nanning 530006, Peoples R China.
EM xuanshibin@gxun.edu.cn
FU National Natural Science Foundation of China [61866003]
FX This research is partially supported by National Natural Science
   Foundation of China(61866003).
CR Ahrnbom M, 2021, VISAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 5: VISAPP, P777, DOI 10.5220/0010190907770784
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cheng SY, 2021, PROC CVPR IEEE, P4419, DOI 10.1109/CVPR46437.2021.00440
   Choi J, 2016, PROC CVPR IEEE, P4321, DOI 10.1109/CVPR.2016.468
   Choudhuri A., 2021, Proceedings of the IEEE/CVF International Conference on Computer Vision, Montreal, BC, Canada, P13598
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Gu Lin-zhu, 2013, Instrument Techniques and Sensor, P31
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Han K, 2021, IEEE ACCESS, V9, P91983, DOI 10.1109/ACCESS.2021.3091434
   Han W, 2022, NEURAL NETWORKS, V147, P175, DOI 10.1016/j.neunet.2021.12.018
   Han XM, 2022, LECT NOTES ARTIF INT, V13088, P251, DOI 10.1007/978-3-030-95408-6_19
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang B, 2021, IEEE INT CONF COMP V, P1204, DOI 10.1109/ICCVW54120.2021.00140
   Jiang S, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2105.03049
   Kiran M, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2202.09938
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Lukezic A, 2020, PROC CVPR IEEE, P7131, DOI 10.1109/CVPR42600.2020.00716
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Noor S, 2021, IEEE ACCESS, V9, P106550, DOI 10.1109/ACCESS.2021.3101054
   Oleksiienko I, 2022, DEEP LEARNING ROBOT, P313
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Wang J, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1904.03280
   Wang N, 2019, PROC CVPR IEEE, P1308, DOI 10.1109/CVPR.2019.00140
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Xu J, 2012, SCI CHINA INFORM SCI, V55, P530, DOI 10.1007/s11432-011-4533-z
   Yang DW, 2022, APPL NANOSCI, DOI 10.1007/s13204-021-02293-6
   Yao R, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3391743
   Yin HP, 2011, J SYST ENG ELECTRON, V22, P587, DOI 10.3969/j.issn.1004-4132.2011.04.006
   Zhang JM, 2020, MULTIMED TOOLS APPL, V79, P15095, DOI 10.1007/s11042-018-6562-8
NR 36
TC 1
Z9 1
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12245
EP 12262
DI 10.1007/s11042-022-13703-4
EA SEP 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000859342300005
OA hybrid
DA 2024-07-18
ER

PT J
AU Sharma, H
   Srivastava, S
AF Sharma, Himanshu
   Srivastava, Swati
TI Multilevel attention and relation network based image captioning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Relation network; Semantic; Attention; Encoder-decoder
AB The aim of the image captioning task is to understand various semantic concepts such as objects and their relationships in an image and combine them to generate a natural language description. Thus, it needs an algorithm to understand the visual content of a given image and translates it into a sequence of output words. In this paper, a Local Relation Network (LRN) is designed over the objects and image regions which not only discovers the relationship between the object and the image regions but also generates significant context-based features corresponding to every region in the image. Also, a multilevel attention approach is used to focus on a given image region and its related image regions, thus enhancing the image representation capability of the proposed method. Finally, a variant of traditional long-short term memory (LSTM), which uses an attention mechanism, is employed which focuses on relevant contextual information, spatial locations, and deep visual features. With these measures, the proposed model encodes an image in an improved way, which gives the model significant cues and thus leads to improved caption generation. Extensive experiments have been performed on three benchmark datasets: Flickr30k, MSCOCO, and Nocaps. On Flickr30k, the obtained evaluation scores are 31.2 BLEU@4, 23.5 METEOR, 51.5 ROUGE, 65.6 CIDEr and 17.2 SPICE. On MSCOCO, the proposed model has attained 42.4 BLEU@4, 29.4 METEOR, 59.7 ROUGE, 125.7 CIDEr and 23.2 SPICE. The overall CIDEr score on Nocaps dataset achieved by the proposed model is 114.3. The above scores clearly show the superiority of the proposed method over the existing methods.
C1 [Sharma, Himanshu; Srivastava, Swati] GLA Univ Mathura, Dept Comp Engn & Applicat, Mathura, Chaumuhan, India.
C3 GLA University
RP Sharma, H (corresponding author), GLA Univ Mathura, Dept Comp Engn & Applicat, Mathura, Chaumuhan, India.
EM himarishu.sharma@gla.ac.in; swati.srivastava@gla.ac.in
CR Aggarwal Ashwani Kumar, 2022, WSEAS Transactions on Signal Processing, P60, DOI 10.37394/232014.2022.18.8
   Agrawal H, 2019, IEEE I CONF COMP VIS, P8947, DOI 10.1109/ICCV.2019.00904
   Anderson P, 2016, ARXIV
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Barraco M, 2022, IEEE COMPUT SOC CONF, P4661, DOI 10.1109/CVPRW56347.2022.00512
   Beddiar D, 2022, 2022 11 INT C IMAGE, P1
   Castellano Giovanna, 2022, Knowledge-Based Systems, DOI 10.1016/j.knosys.2022.108859
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen XP, 2018, PROC CVPR IEEE, P7995, DOI 10.1109/CVPR.2018.00834
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Fang ZY, 2022, PROC CVPR IEEE, P17988, DOI 10.1109/CVPR52688.2022.01748
   Ghataoura D., 2021, 2021 INT C MILT COMM, P1
   Gupta N, 2020, NEURAL COMPUT APPL, V32, P17899, DOI 10.1007/s00521-019-04515-z
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He XW, 2019, PATTERN RECOGN LETT, V119, P229, DOI 10.1016/j.patrec.2017.10.018
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748
   Hu XW, 2021, AAAI CONF ARTIF INTE, V35, P1575
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Jiang SY, 2017, IEEE T EVOLUT COMPUT, V21, P329, DOI 10.1109/TEVC.2016.2592479
   Jiang WT, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3460474
   Kalimuthu Marimuthu, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12666), P381, DOI 10.1007/978-3-030-68780-9_32
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kinghorn P, 2019, PATTERN RECOGN LETT, V119, P77, DOI 10.1016/j.patrec.2017.09.013
   Kingma D. P., 2014, arXiv
   Kotsiantis SB, 2013, ARTIF INTELL REV, V39, P261, DOI 10.1007/s10462-011-9272-4
   Krasin I., 2017, Openimages: A public dataset for large-scale multi-label and multi-class image classification
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar SS., 2019, INT J RECENT TECHNOL, V8, P860, DOI [10.35940/ijrte.B1158.0982S1019, DOI 10.35940/IJRTE.B1158.0982S1019]
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li NN, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P793, DOI 10.1007/s00497-018-0333-6
   Li X., 2020, P EUR C COMP VIS, DOI DOI 10.1007/978-3-030-58577-8_8
   Li XY, 2019, IEEE T MULTIMEDIA, V21, P2117, DOI 10.1109/TMM.2019.2896516
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu AA, 2022, IEEE T CIRC SYST VID, V32, P3685, DOI 10.1109/TCSVT.2021.3107035
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Lu Y, 2022, NEUROCOMPUTING, V490, P163, DOI 10.1016/j.neucom.2022.01.068
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Paszke Adam, 2017, NIPS 2017 WORKSH AUT
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Sharma H, 2022, EXPERT SYST APPL, V190, DOI 10.1016/j.eswa.2021.116159
   Sharma H, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104327
   Sharma H, 2022, NEURAL PROCESS LETT, V54, P709, DOI 10.1007/s11063-021-10655-y
   Sharma H, 2022, MULTIMED TOOLS APPL, V81, P34775, DOI 10.1007/s11042-021-11276-2
   Sharma H, 2021, IMAGE VISION COMPUT, V110, DOI 10.1016/j.imavis.2021.104165
   Sharma H, 2020, MOD PHYS LETT B, V34, DOI 10.1142/S0217984920503157
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Wang JB, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107075
   Wang Z., 2021, ARXIV
   Wu J, 2017, ELECTRON LETT, V53, P1642, DOI 10.1049/el.2017.3159
   Wu SM, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P1180, DOI 10.1145/2998181.2998364
   Xiao F, 2022, NEURAL PROCESS LETT, V54, P3157, DOI 10.1007/s11063-022-10759-z
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Yang L, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3386725
   Yang XS, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3313873
   YanhuiWang Ning Xu, 2021, IEEE T CIRCUITS SYST
   Ye SM, 2018, IEEE T IMAGE PROCESS, V27, P5514, DOI 10.1109/TIP.2018.2855406
   Yiwu Zhong, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P211, DOI 10.1007/978-3-030-58568-6_13
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611
   Zhang PC, 2021, PROC CVPR IEEE, P5575, DOI 10.1109/CVPR46437.2021.00553
   Zhou LW, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P305, DOI 10.1145/3126686.3126717
   Zhu L, 2020, IEEE T IMAGE PROCESS, V29, P4643, DOI 10.1109/TIP.2020.2974065
NR 74
TC 10
Z9 10
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10981
EP 11003
DI 10.1007/s11042-022-13793-0
EA SEP 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000854429700002
DA 2024-07-18
ER

PT J
AU Wu, WQ
   Wang, Q
AF Wu, Wanqing
   Wang, Qiao
TI Block image encryption based on chaotic map and fractional fourier
   transformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Fractional Fourier Transform(FRFT); Baker map; 2D
   logistic map
ID ALGORITHM
AB In order to prevent others from illegally accessing sensitive image information on the Internet, image encryption has become more and more important. This paper proposes a novel image encryption scheme based on chaotic map and fractional Fourier transformation. The encryption steps are as follows. Firstly, we divide the image into blocks and select high correlation blocks to perform FRFT transformation. This is because it reduces the overall image correlation and saves time at the same time. Secondly, the key related to plain image will be used to change the pixel values. The key of the encryption algorithm relies on the plain image so that the cipher image is sensitive to both the key and the plain image to resist attacks. Finally, the Baker Map is used to scramble the entire image. The scheme has been verified with indicators such as visual inspection, keyspace, encryption time, entropy, encryption quality, histogram, differential analysis, the effect of noise and the effect of occlusion. The results show that the scheme has high security and can effectively resist different types of attacks. Compare with the other two similar image encryption schemes, the proposed encryption algorithm decreases the encryption time and obtains a better histogram.
C1 [Wu, Wanqing; Wang, Qiao] Hebei Univ, Sch Cyber Secur & Comp, Baoding 071000, Peoples R China.
C3 Hebei University
RP Wang, Q (corresponding author), Hebei Univ, Sch Cyber Secur & Comp, Baoding 071000, Peoples R China.
EM wuwanqing8888@126.com; wq096726@163.com
RI 吴, 宛青/JXM-6153-2024
FU Science and technology research project of Hebei higher education
   [ZD2021011]
FX The authors are supported by the Science and technology research project
   of Hebei higher education Nos.ZD2021011. The authors have no relevant
   financial or non-financial interests to disclose. All data generated or
   analysed during this study are included in this published article. The
   code contained in the article is available. Material preparation, data
   collection and analysis were performed by Qiao Wang and Wanqing Wu. The
   first draft of the manuscript was written by QiaoWang. WanqingWu has
   reviewed and revised the manuscript several times.
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   BOURBAKIS N, 1992, PATTERN RECOGN, V25, P567, DOI 10.1016/0031-3203(92)90074-S
   Brahim AH, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106489
   BRIGGS K, 1990, PHYS LETT A, V151, P27, DOI 10.1016/0375-9601(90)90841-B
   Bwa B, 2020, OPTIK, V225
   Dongare AS., 2017, INT RES J ENG TECHNO, V4, P3186
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Elhosany H. M., 2012, Proceedings of the 2012 29th National Radio Science Conference (NRSC), P223, DOI 10.1109/NRSC.2012.6208527
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Faragallah OS, 2020, IEEE ACCESS, V8, P42491, DOI 10.1109/ACCESS.2020.2974226
   Faragallah OS, 2020, MULTIMED TOOLS APPL, V79, P2495, DOI 10.1007/s11042-019-08190-z
   FIPS P., 2001, 197 ADV ENCRYPTION S, P26
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   Henderson H. V., 1979, CANADIAN J STATISTIC, V7, P65, DOI [10.2307/3315017, DOI 10.2307/3315017]
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Liang HR, 2016, QUANTUM INF PROCESS, V15, P2701, DOI 10.1007/s11128-016-1304-1
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Noha R, 2017, J CENT SOUTH UNIV, V24, P2049, DOI 10.1007/s11771-017-3614-6
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Pei SC, 1997, OPT LETT, V22, P1047, DOI 10.1364/OL.22.001047
   Ramadan N, 2015, J PHYS OCEANOGR
   Standard D.E., 1999, FEDERAL INFORM PROCE, P112
   Sui LS, 2019, OPT LASER ENG, V113, P29, DOI 10.1016/j.optlaseng.2018.10.002
   Tao R, 2006, SCI CHINA SER F, V49, P1, DOI 10.1007/s11432-005-0240-y
   Hoang TM, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22050548
   [王兴元 Wang Xingyuan], 2005, [应用力学学报, Chinese Journal of Applied Mechanics], V22, P501
   Wang Y, 2011, NOVEL IMAGE ENCRYPTI
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Xiao D, 2014, ELECTRON LETT, V50, P598, DOI 10.1049/el.2013.3806
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
NR 33
TC 5
Z9 5
U1 12
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10367
EP 10395
DI 10.1007/s11042-022-13675-5
EA AUG 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000844934700003
DA 2024-07-18
ER

PT J
AU Kale, M
   Dash, J
   Mukhopadhyay, S
AF Kale, Mandar
   Dash, Jatindra
   Mukhopadhyay, Sudipta
TI Efficient image retrieval system for textural images using fuzzy class
   membership
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy class membership; Content based image retrieval; Texture
   retrieval; Brodatz; Multiband texture (MBT); Describable texture
   database (DTD); Corel-10K
ID ROTATION-INVARIANT; FEATURE DESCRIPTOR; PATTERN-A; CLASSIFICATION; SCALE
AB The article describes enhancements in retrieval performance of content-based image retrieval (CBIR) system using the fuzzy class membership-based retrieval (CMR) framework. The CMR approach explores the CBIR as a classifier-based retrieval problem using a neural network classifier, accompanied by a simple distance-based retrieval method. The fuzzy class membership-based approach is known to enhance the retrieval performance along with slight variation without any constraint on the feature set to be used. Despite that, its efficacy is not known for color and multi-band textures. We have proposed several advancements in a fuzzy class membership-based retrieval framework for improved retrieval. The main contributions are the simplification of vital threshold selection process and effective use of membership values to encourage the use of appropriate classifiers, investigation of the role of the cost function in neural network and distance weighting functions for improved retrieval, a way to adapt a new classifier in fuzzy class membership-based retrieval framework in place of neural network. Experimental analysis of all proposed advancements are evaluated using benchmark gray-scale texture databases viz. three versions of Broadtz and Outex database. The p-value analysis is carried out to check if the improvements are statistically significant. The proposed method is further tested with the Describable texture database (DTD) and Multi-band texture (MBT) database to check its applicability on color textures. The comparison with recent methods using gray-scale image databases viz. AT&T face database, MIT VisTex database, Broadatz texture database, and natural-color image databases viz. Corel-1K and Corel-10K showcase the efficacy of the proposed method.
C1 [Kale, Mandar; Mukhopadhyay, Sudipta] Indian Inst Technol, Dept Elect & Elect Commun Engn, Kharagpur 721302, W Bengal, India.
   [Dash, Jatindra] SRM Univ AP, Amaravati 522503, Andhra Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; SRM University-AP
RP Mukhopadhyay, S (corresponding author), Indian Inst Technol, Dept Elect & Elect Commun Engn, Kharagpur 721302, W Bengal, India.
EM mandar9975@gmail.com; jatinkdash@gmail.com; smukho@ece.iitkgp.ac.in
RI Dash, Jatindra/JNT-5949-2023
CR Abdelmounaime S., 2013, ISRN MACHINE VISION
   Alrahhal M, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P118, DOI [10.1109/AICAI.2019.8701255, 10.1109/aicai.2019.8701255]
   [Anonymous], 2002, AT T DATABASE FACES
   Arunkumar Niveditha, 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0141, DOI 10.1109/ICCSP48568.2020.9182323
   Banerjee P, 2018, EXPERT SYST APPL, V113, P100, DOI 10.1016/j.eswa.2018.06.044
   Bedi AK, 2020, PATTERN RECOGN IMAGE, V30, P578
   Bella MIT, 2019, COMPUT ELECTR ENG, V75, P46, DOI 10.1016/j.compeleceng.2019.01.022
   Bhardwaj Shikha, 2021, Mobile Radio Communications and 5G Networks. Proceedings of MRCN 2020. Lecture Notes in Networks and Systems (LNNS 140), P667, DOI 10.1007/978-981-15-7130-5_53
   Bhatt Hardik H., 2021, Data Science and Intelligent Applications. Proceedings of ICDSIA 2020. Lectures Notes on Data Engineering and Communications Technologies (LNDECT 52), P63, DOI 10.1007/978-981-15-4474-3_7
   Bhunia AK, 2020, PATTERN ANAL APPL, V23, P703, DOI 10.1007/s10044-019-00827-x
   Bhunia AK, 2019, IEEE WINT CONF APPL, P609, DOI 10.1109/WACV.2019.00070
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Dash JK, 2015, IET IMAGE PROCESS, V9, P836, DOI 10.1049/iet-ipr.2014.0299
   Desai P., 2021, SN Comput. Sci., V2, P1, DOI [10.1007/s42979-021-00532-9, DOI 10.1007/S42979-021-00532-9]
   Dubey SR, 2022, IEEE T CIRC SYST VID, V32, P2687, DOI 10.1109/TCSVT.2021.3080920
   Duda R., 1973, Pattern Classification and Scene Analysis
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   Friedman J.H., 1996, Another approach to polychotomous classification
   Garg M, 2021, NEURAL COMPUT APPL, V33, P1311, DOI 10.1007/s00521-020-05017-z
   Ghahremani M, 2021, MULTIMED TOOLS APPL, V80, P28245, DOI 10.1007/s11042-021-10895-z
   Ghose S, 2020, MULTIMED TOOLS APPL, V79, P18527, DOI 10.1007/s11042-020-08752-6
   Golik P, 2013, INTERSPEECH, P1755
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   Gupta S, 2020, PATTERN ANAL APPL, V23, P1569, DOI 10.1007/s10044-020-00879-4
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   Hastie T, 1998, ADV NEUR IN, V10, P507
   Hatibaruah R, 2019, LECT NOTES COMPUT SC, V11941, P541, DOI 10.1007/978-3-030-34869-4_59
   Huang KZ, 2017, IEEE TETCI, V1, P454, DOI 10.1109/TETCI.2017.2751062
   Hussain S, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114545
   Jiang Z, 2020, IEEE T MULTIMEDIA, V22, P540, DOI 10.1109/TMM.2019.2929957
   Kanaparthi SK, 2020, MULTIMED TOOLS APPL, V79, P34875, DOI 10.1007/s11042-019-08029-7
   Kas M, 2020, MULTIMED TOOLS APPL, V79, P375, DOI 10.1007/s11042-019-08049-3
   Khan UA, 2021, MULTIMED TOOLS APPL, V80, P26911, DOI 10.1007/s11042-021-10530-x
   Kumar S, 2021, MULTIMED TOOLS APPL, V80, P13975, DOI 10.1007/s11042-020-10397-4
   Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu Y, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, SIGNAL PROCESSING AND COMMUNICATION (ICISPC), P90, DOI [10.1109/ICISPC.2019.8935658, 10.1109/icispc.2019.8935658]
   Luts J, 2010, ANAL CHIM ACTA, V665, P129, DOI 10.1016/j.aca.2010.03.030
   Ma WY, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P568, DOI 10.1109/ICIP.1997.647976
   Medjeded M, 2014, J MED IMAG HEALTH IN, V4, P43, DOI 10.1166/jmihi.2014.1223
   Mit vision and modeling group, 1987, CAMBR VIS TEXT
   Mukhopadhyay, 2017, MEDICAL IMAGING 2017, V10134
   Mukhopadhyay S, 2013, PATTERN RECOGN LETT, V34, P646, DOI 10.1016/j.patrec.2013.01.001
   Naghashi V, 2018, OPTIK, V157, P877, DOI 10.1016/j.ijleo.2017.11.160
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Raghuwanshi G, 2021, MULTIMED TOOLS APPL, V80, P2295, DOI 10.1007/s11042-020-09618-7
   Raghuwanshi G, 2016, DIGIT SIGNAL PROCESS, V48, P50, DOI 10.1016/j.dsp.2015.09.003
   Renita DB, 2020, MULTIMED TOOLS APPL, V79, P17227, DOI 10.1007/s11042-019-07777-w
   Shao ZF, 2020, IEEE J-STARS, V13, P318, DOI 10.1109/JSTARS.2019.2961634
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   University of sourthern california, 2011, SIGNAL IMAGE PROCESS
   Valente A C., 2019, Electronic Imaging, V2019, P406
   Venables W.N., 2013, MODERN APPL STAT S P, DOI DOI 10.1007/978-0-387-21706-2
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Vimina ER, 2020, MULTIMED TOOLS APPL, V79, P25357, DOI 10.1007/s11042-020-09207-8
   Wang H, 2020, SPIE, V11373, P254
   Wang HB, 2020, IEEE ACCESS, V8, P222611, DOI 10.1109/ACCESS.2020.3043413
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wu TF, 2004, J MACH LEARN RES, V5, P975
   Yang T., 2017, P IEEE INT C COMM IC, P1, DOI DOI 10.1109/CISP-BMEI.2017.8301967
   Zhai HJ, 2021, IEEE T CIRC SYST VID, V31, P742, DOI 10.1109/TCSVT.2020.2991171
NR 68
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37263
EP 37297
DI 10.1007/s11042-022-13529-0
EA AUG 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000840595500002
DA 2024-07-18
ER

PT J
AU Wu, SY
   Zhang, XR
   Liu, RQ
   Li, BH
AF Wu, Siyuan
   Zhang, Xinrong
   Liu, Ruqi
   Li, Binhai
TI A dataset for fire and smoke object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fire smoke detection; Object detection dataset
ID CONVOLUTIONAL NETWORKS
AB Fire and smoke object detection is of great significance due to the extreme destructive power of fire disasters. Most of the existing methods, whether traditional computer vision-based models with sensors or deep learning-based models have circumscribed application scenes with relatively poor detection speed and accuracy. This means seldom taking smoke into consideration and always focusing on classification tasks. To advance object detection research in fire and smoke detection, we introduce a dataset called DFS (Dataset for Fire and Smoke detection), which is of high quality, constructed by collecting from real scenes and annotated by strict and reasonable rules. To reduce the possibility of erroneous judgments caused by objects that are similar to fires in color and brightness, apart from annotating 'fire' and 'smoke', we annotate these objects as a new class 'other'. There are a total of 9462 images named by the fire size, which can benefit different detection tasks. Furthermore, by carrying out extensive and abundant experiments on Various object detection models, we provide a comprehensive benchmark on our dataset. Experimental results show that DFS well represents real applications in fire and smoke detection and is quite challenging. We also test models with different training and testing proportions on our dataset to find the optimal split ratio in real situations. The dataset is released at https://github.com/siyuanwu/DFS-FIRE-SMOKE-Dataset.
C1 [Wu, Siyuan] Xian Univ Technol, Coll Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.
   [Wu, Siyuan; Liu, Ruqi] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Key Lab Spectral Imaging Technol CAS, Xian 710119, Shaanxi, Peoples R China.
   [Zhang, Xinrong] NYU, Tandon Sch Engn, New York, NY 10003 USA.
   [Liu, Ruqi] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Li, Binhai] Shaanxi Avit Engn Co Ltd, Xian 710121, Shaanxi, Peoples R China.
C3 Xi'an University of Technology; Chinese Academy of Sciences; Xi'an
   Institute of Optics & Precision Mechanics, CAS; New York University; New
   York University Tandon School of Engineering; Chinese Academy of
   Sciences; University of Chinese Academy of Sciences, CAS
RP Wu, SY (corresponding author), Xian Univ Technol, Coll Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.; Wu, SY (corresponding author), Chinese Acad Sci, Xian Inst Opt & Precis Mech, Key Lab Spectral Imaging Technol CAS, Xian 710119, Shaanxi, Peoples R China.
EM wusiyuan@opt.ac.cn
RI Zhang, Xinrong/JPK-2282-2023
OI Zhang, Xinrong/0000-0002-8393-8904; wu, siyuan/0000-0002-9041-8587
CR Alexey, 2017, YOLO V4 V3 V2 WINDOW
   [Anonymous], MIDASKLR FIRESMOKEDE
   [Anonymous], 2012, INT WORKSHOP MULTISE
   Bhowmik N, 2019, ARXIV
   Bochkovskiy A., 2020, PREPRINT
   Celik T, 2007, J VIS COMMUN IMAGE R, V18, P176, DOI 10.1016/j.jvcir.2006.12.003
   Cetin NGKDE, 2017, FIRESENSE DATABASE V
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen TH, 2004, IEEE IMAGE PROC, P1707
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dunnings, 2019, FIRE SUPERPIXEL IMAG
   Dunnings A., 2018, FIRE IMAGE DATA SET
   Dunnings Andrew J., 2018, 2018 25th IEEE International Conference on Image Processing (ICIP), P1558, DOI 10.1109/ICIP.2018.8451657
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   FELZENSZWALB PF, 2010, PROC CVPR IEEE, P2241, DOI DOI 10.1109/CVPR.2010.5539906
   Ganesh Samarth C. A., 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P653, DOI 10.1109/ICMLA.2019.00119
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goyal P, 2017, IEEE I CONF COMP VIS, P5104, DOI 10.1109/ICCV.2017.545
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Jivitesh Sharma, 2017, FIRE DETECTION IMAGE
   Jocher G., 2020, YOLOV5 CODE REPOSITO
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo YM, 2018, MULTIMED TOOLS APPL, V77, P15075, DOI 10.1007/s11042-017-5090-2
   mnslarcher, 2020, K MEANS ANCHORS RATI
   Muhammad K, 2018, IEEE ACCESS, V6, P18174, DOI 10.1109/ACCESS.2018.2812835
   Qiao S, 2020, IEEECVF C COMPUTER V, DOI DOI 10.1109/CVPR46437.2021.01008
   Qiao S., 2020, ARXIV
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Russo A.U., 2018, PROC INT C COMPUT CO, P1
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang C., 2020, ARXIV
NR 46
TC 6
Z9 6
U1 13
U2 71
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6707
EP 6726
DI 10.1007/s11042-022-13580-x
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000840140800008
DA 2024-07-18
ER

PT J
AU Gupta, YP
   Mukul
   Gupta, N
AF Gupta, Yash Prakash
   Mukul
   Gupta, Nitin
TI Deep learning model based multimedia retrieval and its optimization in
   augmented reality applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Media retrieval; Augmented reality; Deep learning; Latency; Medical
   augmented reality; Cloud computation; MTCNN; OffLoading
AB With the uproar of touchless technology, the Virtual Continuum has seen some spark in the upcoming products. Today numerous gadgets support the use of Mixed Reality / Augmented Reality (AR)/ Virtual Reality. The Head Mounted Displays (HMDs) like that of Hololens, Google Lens, Jio Glass manifested reality into virtuality. Other than the HMDs many organizations tend to develop mobile AR applications to support umpteen number of industries like medicine, education, construction. Currently, the major issue lies in the performance parameters of these applications, while deploying for mobile application's graphics performance, latency, and CPU functioning. Many industries pose real-time computation requirements in AR but do not implement an efficient algorithm in their frameworks. Offloading the computation of deep learning models involved in the application to the cloud servers will highly affect the processing parameters. For our use case, we will be using Multi-Task Cascaded Convolutional Neural Network (MTCNN) which is a modern tool for face detection, using a 3-stage neural network detector. Therefore, the optimization of communication between local application and cloud computing frameworks needs to be optimized. The proposed framework defines how the parameters involving the complete deployment of a mobile AR application can be optimized in terms of retrieval of multimedia, its processing, and augmentation of graphics, eventually enhancing the performance. To implement the proposed algorithm a mobile application is created in Unity3D. The mobile application virtually augments a 3D model of a skeleton on a target face. After the mentioned experimentation, it is found that average Media Retrieval Time (1.1471 mu s) and Client Time (1.1207 mu s) in the local application are extremely low than the average API process time (288.934ms). The highest time latency is achieved at the frame rate higher than 80fps.
C1 [Gupta, Yash Prakash; Mukul] Natl Inst Technol, Dept Elect Commun & Engn, Hamirpur, Himachal Prades, India.
   [Gupta, Nitin] Natl Inst Technol, Dept Comp Sci & Engn, Hamirpur, Himachal Prades, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur; National Institute of Technology (NIT System);
   National Institute of Technology Hamirpur
RP Gupta, N (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Hamirpur, Himachal Prades, India.
EM yasharsh.28@gmail.com; mukulthakur17.mt@gmail.com; nitin@nith.ac.in
RI Gupta, Nitin/T-1624-2019; Gupta, Yash/JMC-2999-2023
OI Gupta, Nitin/0000-0001-5067-858X; 
CR Abhiwan, PORTFOLIO
   Aiborne tech, US
   [Anonymous], Amazon Lumberyard
   Arslan R., 2020, Turkish Science Education, V17, P62, DOI DOI 10.36681/TUSED.2020.13
   Barbosa IB, 2018, COMPUT VIS IMAGE UND, V167, P50, DOI 10.1016/j.cviu.2017.12.002
   cryengine, US
   Datta R, 2005, P 7 ACM SIGMM INT WO, P153, DOI [DOI 10.1145/1101826.1101866, 10.1145/1101826.1101866]
   Du J, 2020, J PHYS CONF SER, V1518, DOI 10.1088/1742-6596/1518/1/012066
   Emeras J, 2019, IEEE T CLOUD COMPUT, V7, P456, DOI 10.1109/TCC.2016.2628371
   esseract, FUTURE REALITY IS HE
   Fastai, about us
   Flask, about us
   github, PKUZHOU PKUZHOU
   Lampropoulos G, 2020, VIS INFORM, V4, P32, DOI 10.1016/j.visinf.2020.01.001
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Nowacki Pawel, 2020, Engineering in Dependability of Computer Systems and Networks. Proceedings of the Fourteenth International Conference on Dependability of Computer Systems DepCoS-RELCOMEX. Advances in Intelligent Systems and Computing (AISC 987), P358, DOI 10.1007/978-3-030-19501-4_36
   Oishi M, 2013, J NEUROSURG, V119, P94, DOI 10.3171/2013.3.JNS121109
   Peng FG, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P1049, DOI 10.1109/ICIVC.2017.7984714
   Planche B, 2017, INT CONF 3D VISION, P1, DOI 10.1109/3DV.2017.00011
   Radu I, 2014, PERS UBIQUIT COMPUT, V18, P1533, DOI 10.1007/s00779-013-0747-y
   Rice M, 2019, E LEARN WORLD C E LE, P567
   Saidin NF., 2015, International education studies, V8, P1, DOI DOI 10.5539/IES.V8N13P1
   Schuir J, 2020, LECT NOTES BUS INF P, V391, P240, DOI 10.1007/978-3-030-52306-0_15
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   unity3d, ENTITY COMPONENT SYS
   unity3d, FACE SUBSYSTEMS
   unity3d, KEEP IT COOL 3 FAST
   unity3d, COROUTINES
   unity3d, ARCORE FACE TRACKING
   Unreal Engine, about us
   Verhey JT, 2020, INT J MED ROBOT COMP, V16, DOI 10.1002/rcs.2067
   Wang XY, 2006, AUTOMAT CONSTR, V15, P314, DOI 10.1016/j.autcon.2005.06.002
   Zhang WX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P355, DOI 10.1145/3240508.3240561
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 34
TC 2
Z9 2
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8447
EP 8466
DI 10.1007/s11042-022-13555-y
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000836525000011
PM 35968406
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Ni, BB
   Bi, WH
AF Ni, Binbin
   Bi, Weihong
TI New predictor-based schemes for reversible data hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RDH; PEE; Context-based seven-star map; Variable predictor
ID EXPANSION
AB As techniques of Reversible Data Hiding based on Prediction-Error Expansion (PEE) have performed excellent, more attentions have been paid to the studies. Many PEE-based schemes increased the embedding capacity and controlled the distortion by employing different predictors. Since predictor is vital to PEE-based schemes, we propose a variable predictor which you can change whenever you find the optimized representation to the prediction for concrete image. We also propose three predictors derived from the variable predictors using Context-Based Seven-Star Map composed by seven neighboring pixels. Experiment results show that the proposed scheme performed as well as (sometimes even better than) Chang's scheme in capacity-distortion control because of variable parameters and better accuracy of the predictors.
C1 [Ni, Binbin; Bi, Weihong] Zhejiang Univ, Sch Math Sci, Hangzhou 310000, Peoples R China.
C3 Zhejiang University
RP Bi, WH (corresponding author), Zhejiang Univ, Sch Math Sci, Hangzhou 310000, Peoples R China.
EM 21835022@zju.edu.cn; bivh@zju.edu.cn
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 1997, D LIB MAGAZINE
   Anushiadevi R, 2020, J INTELL FUZZY SYST, V39, P2977, DOI 10.3233/JIFS-191478
   Anushiadevi R, 2020, J INTELL FUZZY SYST, V38, P6403, DOI 10.3233/JIFS-179721
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang KC, 2018, MULTIMED TOOLS APPL, V77, P23579, DOI 10.1007/s11042-017-5547-3
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Gandhi B, 1995, ISOIECJTC1SC29WG1N20
   Hong W, 2010, SIGNAL PROCESS, V90, P2911, DOI 10.1016/j.sigpro.2010.04.012
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Langdon GG, 1995, ISOIECJTC1SC29WG1N19
   Memon N, 1997, COMPUT J, V40, P127, DOI 10.1093/comjnl/40.2_and_3.127
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Sayood K, 2017, Introduction to data compression
   Speck D, 1995, ISOIECJTC1SC29WG1N19
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Ueno I, 1995, ISOIECJTC1SC29WG1N19
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
NR 26
TC 1
Z9 1
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5923
EP 5948
DI 10.1007/s11042-022-13396-9
EA AUG 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000834736500007
DA 2024-07-18
ER

PT J
AU Shakil, KA
   Zareen, FJ
   Alam, M
   Jabin, S
AF Shakil, Kashish Ara
   Zareen, Farhana Javed
   Alam, Mansaf
   Jabin, Suraiya
TI BAMCloud: a cloud based Mobile biometric authentication framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; BAMCloud; biometrics; Cloud computing; machine learning;
   Map Reduce; Hadoop
ID ONLINE SIGNATURE VERIFICATION; PRIVACY
AB There has been an exponential increase in the number of users switching to mobile banking. Therefore, various countries are adopting biometric solutions as security measures. Biometric technologies provide the potential security framework to make banking more convenient and secure than it has ever been. These technologies are gaining much popularity because of the ease in capturing biometric data in real-time using one's mobile phone. At the same time, the exponential growth of enrollment in the biometric system produces a massive amount of high-dimensional data. To overcome performance-related issues arising due to the resulting data deluge, this paper aims to propose a distributed mobile biometric system based on a high-performance cluster Cloud. In this paper, a Cloud-based mobile biometric authentication framework (BAMCloud) is proposed that uses dynamic signatures for authentication. The process flow of the BAMCloud system involves capturing data using any handheld mobile device, followed by its storage, preprocessing, and training of the system in a distributed manner over the Cloud. MapReduce has been implemented on the Hadoop platform to reduce the processing time. For model training, The Levenberg-Marquardt backpropagation neural network has been used. It achieves a speed of 8.5 times the original speed and performance of 96.23%. Furthermore, the cost-benefit analysis of the implemented system shows that the cost of implementation and execution of the system is less than the existing ones. The experiments demonstrate that better performance is achieved by implementing the proposed framework as compared to other methods used in recent literature.
C1 [Shakil, Kashish Ara] Princess Nourah Bint Abdulrahman Univ, Dept Comp Sci, Riyadh, Saudi Arabia.
   [Zareen, Farhana Javed; Alam, Mansaf; Jabin, Suraiya] Jamia Millia Islamia, Dept Comp Sci, New Delhi, India.
C3 Princess Nourah bint Abdulrahman University; Jamia Millia Islamia
RP Alam, M (corresponding author), Jamia Millia Islamia, Dept Comp Sci, New Delhi, India.
EM kashaldl@pnu.edu.sa; farhanazareen@yahoo.com; malam2@jmi.ae.in;
   sjabin@jrni.ac.in
RI Jabin, Suraiya/D-6363-2018; Alam, Prof. Mansaf/A-3734-2016; Shakil,
   Kashish/ABK-8677-2022
OI Jabin, Suraiya/0000-0002-0648-2616; Alam, Prof.
   Mansaf/0000-0002-6293-7005; Shakil, Kashish/0000-0003-2323-5104
FU Princess Nourah bint Abdulrahman University
FX This research was funded by the Deanship of Scientific Research at
   Princess Nourah bint Abdulrahman University through the Fast-track
   Research Funding Program. It is acknowledged that Farhana Javed Zareen
   is the corresponding author of this paper. It is further acknowledged
   that Farhana Javed Zareen and Kashish Ara Shakil share equal
   contributions for the work carried out in this article.
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Alam, 2014, NBDMMM ALGORITHM BAS
   Alhaddad M.J., 2012, World of Computer Science and Information Technology Journal (WCSIT), V2, P46
   Alsellami Belal M., 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P1359, DOI 10.1109/ICAIS50930.2021.9396007
   Apache, 2016, AP HIV
   Apache Hadoop, 2016, HDFS ARCHITECTURE GU
   Bibi K, 2020, MULTIMED TOOLS APPL, V79, P289, DOI 10.1007/s11042-019-08022-0
   Borthakur Dhruba, 2008, Hadoop Apache Project, V53, P2
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Challenges DM, AADHAAR
   Chaudhary K, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00466-2
   Daramola, INT J ENG TECHNOL IJ, V10, P04
   Fierrez J, 2007, PATTERN RECOGN LETT, V28, P2325, DOI 10.1016/j.patrec.2007.07.012
   Gruber C, 2010, IEEE T SYST MAN CY B, V40, P1088, DOI 10.1109/TSMCB.2009.2034382
   Hahn C, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1826, DOI 10.1145/2976749.2989048
   Hasan N, 2021, J DISCRET MATH SCI C, V24, P1497, DOI 10.1080/09720529.2021.1951434
   He ZH, 2016, IEEE CIRC SYST MAG, V16, P73, DOI 10.1109/MCAS.2015.2510200
   Iii, 2014, 2014 INT C SECURITY, P344
   Jabin S., 2014, Int. J. Comput. Appl, V99, P4, DOI [DOI 10.5120/17399-7959, 10.5120/17399-7959]
   Jabin S, 2015, INT J BIOMETRICS, V7, P97, DOI 10.1504/IJBM.2015.070924
   Jiang R, 2016, IEEE T INF FOREN SEC, V11, P1712, DOI 10.1109/TIFS.2016.2555792
   Kaur H, 2020, FUTURE GENER COMP SY, V102, P30, DOI 10.1016/j.future.2019.07.023
   Krish R.P., 2013, CCIS, V365, P213, DOI [10.1007/978-3-642-38061-721, DOI 10.1007/978-3-642-38061-721]
   Kumari S, 2017, FUTURE GENER COMP SY, V68, P320, DOI 10.1016/j.future.2016.10.004
   Leclerc F., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P643, DOI 10.1142/S0218001494000346
   Liu S, 2021, BIOMETRIC TECHNOLOGI
   Lyu C, 2016, IEEE T DEPEND SECURE, V13, P71, DOI 10.1109/TDSC.2015.2399297
   MACKIEWICZ A, 1993, COMPUT GEOSCI, V19, P303, DOI 10.1016/0098-3004(93)90090-R
   Mansingh PMB, 2020, INT CONF ADVAN COMPU, P1116, DOI [10.1109/ICACCS48705.2020.9074281, 10.1109/icaccs48705.2020.9074281]
   Martinez-Diaz, 2009, SPIE NEWSROOM
   Martinez-Diaz M, 2014, IET BIOMETRICS, V3, P267, DOI 10.1049/iet-bmt.2013.0081
   Memon N, 2017, IEEE SIGNAL PROC MAG, V34, P194, DOI 10.1109/MSP.2017.2697179
   Moretti C, 2010, IEEE T PARALL DISTR, V21, P33, DOI 10.1109/TPDS.2009.49
   Natgunanathan I, 2016, IEEE ACCESS, V4, P880, DOI 10.1109/ACCESS.2016.2535120
   Omar MN, 2014, 2014 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P45, DOI 10.1109/ISBAST.2014.7013092
   Ong TS., 2014, SUNWAY ACAD J, V11, P22
   Padhye V, 2015, IEEE T SERV COMPUT, V8, P121, DOI 10.1109/TSC.2013.47
   Park KW, 2013, IEEE T SERV COMPUT, V6, P300, DOI 10.1109/TSC.2012.1
   Park Y, 2022, BIOMETRICS, V78, P60, DOI 10.1111/biom.13421
   Ruiz-Blondet MV, 2016, IEEE T INF FOREN SEC, V11, P1618, DOI 10.1109/TIFS.2016.2543524
   Santos, 2015, P 13 ACM INT S MOBIL, P89
   Shakil, 2015, EFFECTIVE FRAMEWORK
   Shakil K, 2014, IJCA P 4 INT IT SUMM
   Shakil KA, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P1262
   Shan XW, 2021, IEEE ACCESS, V9, P25973, DOI 10.1109/ACCESS.2021.3057064
   Shelly, 2011, INT CONF CLOUD COMPU, P482, DOI 10.1109/CCIS.2011.6045114
   Silva R. D., 2021, Biometric Technology Today, V2021, P7, DOI DOI 10.1016/S0969-4765(21)00095-3
   Simsons, 2011, J AM SOC QUESTIONED, V14, P39
   Swetha Madireddy, 2023, Materials Today: Proceedings, P3059, DOI 10.1016/j.matpr.2021.06.462
   Uludag U, 2005, LECT NOTES COMPUT SC, V3546, P310
   van der Aalst W, 2015, IEEE T SERV COMPUT, V8, P810, DOI 10.1109/TSC.2015.2493732
   Wang C, 2022, IEEE T COMPUT SOC SY, V9, P428, DOI 10.1109/TCSS.2021.3092007
   Wang SL, 2016, IEEE T INF FOREN SEC, V11, P1661, DOI 10.1109/TIFS.2016.2549004
   Yang JC, 2011, IEEE SYST J, V5, P574, DOI 10.1109/JSYST.2011.2165600
   Zareen FJ, 2016, IET BIOMETRICS, V5, P13, DOI 10.1049/iet-bmt.2015.0017
   Zareen FJ, 2013, INT CONF CONTEMP, P354, DOI 10.1109/IC3.2013.6612219
   Zawoad S, 2016, IEEE T DEPEND SECURE, V13, P148, DOI 10.1109/TDSC.2015.2482484
NR 57
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39571
EP 39600
DI 10.1007/s11042-022-13514-7
EA JUL 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000830853400001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ismail, R
   Fattah, A
   Saqr, HM
   Nasr, ME
AF Ismail, Roayat
   Fattah, Abdel
   Saqr, Hager Mohamed
   Nasr, Mohamed E.
TI An efficient medical image encryption scheme for (WBAN) based on
   adaptive DNA and modern multi chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DNA encoding; Chaotic map (HGL); Encryption & decryption algorithm;
   Encryption tests
AB A Wireless Body Area Network (WBAN) is a network of wireless sensor nodes that can be installed inside or outside of the human body. This network is crucial in medical problems. Due to storage, battery power, and computational resource limitations, the security of medical information such as medical photographs or other information is a major concern in (WBAN). This work proposes an image encryption approach that addresses these constraints by utilizing adaptive DNA code bases and a new multi chaotic map architecture. DNA coding is used to enhances computing efficiency and gives great data transfer capabilities and the new multi chaotic map was formed by Combining Henon, Gaussian and Logistic map (HGL) To generate more chaotic pseudo-random sequences. Numerous analyses were conducted to test the proposed scheme, such as brute force, statistical, differential assaults and noise added analysis. Results indicated that this scheme has a strong level of security.
C1 [Ismail, Roayat; Fattah, Abdel; Saqr, Hager Mohamed; Nasr, Mohamed E.] Tanta Univ, Fac Engn, Dept Elect & Elect Commun, Tanta 31111, Egypt.
C3 Egyptian Knowledge Bank (EKB); Tanta University
RP Saqr, HM (corresponding author), Tanta Univ, Fac Engn, Dept Elect & Elect Commun, Tanta 31111, Egypt.
EM royat_esmaeel@f-eng.tanta.edu.eg; hager_saqr@yahoo.com;
   mohamed.nasr@f-eng.tanta.edu.eg
RI Nasr, Mohamed El Said/JKH-7025-2023; ismail, roayat/HKN-0154-2023; Nasr,
   Mohamed/HNP-9322-2023
OI Nasr, Mohamed El Said/0000-0002-2267-1863; ismail,
   roayat/0000-0003-0283-8336; Nasr, Mohamed/0000-0001-6003-4059
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Abdelfattah Roayat Ismail, 2020, Journal of Physics: Conference Series, V1447, DOI 10.1088/1742-6596/1447/1/012053
   Abo Ajeeb A, 2017, IJIRCCE, V5
   Akkasaligar P. T., 2016, 2016 IEEE INT C COMP, P1, DOI DOI 10.1109/ICCIC.2016.7919681
   Akkasaligar PT, 2018, INT C REC TRENDS IM, P143
   Chai XL, 2017, INT J MOD PHYS C, V28, DOI 10.1142/S0129183117500693
   Chen X, 2017, SAUDI J BIOL SCI, V24, P1821, DOI 10.1016/j.sjbs.2017.11.023
   Cui G, 2018, P INT C BIO INSP COM, V952, P226
   Dagadu JC, 2017, J MULTIDISCIPLINARY, V4, P8096
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   Elamrawy F., 2018, INT J SIGNAL PROCESS, V3, P27
   Hossain EMS, 2016, INT CONF COMPUT INFO, P270, DOI 10.1109/ICCITECHN.2016.7860208
   Joan D., 2002, The Design of Rijndael: AES-the Advanced Encryption Standard
   Liu Y., 2018, J COMPUTERS, V29, P43
   Marhoon AF, 2015, CHAOS, V5
   Paul S, 2017, REV COMPUTER ENG STU, V4, P70, DOI DOI 10.18280/RCES.040206
   Poriye M., 2016, INT J COMPUT APPL, V155, P323
   Raj BB., 2016, Int. J. Comput. Appl, V133, P19
   Reyad O, 2017, 2017 12TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P455, DOI 10.1109/ICCES.2017.8275351
   Sahay A, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1347, DOI 10.1109/ICCSP.2017.8286603
   Si HQ, 2014, SCI WORLD J, DOI 10.1155/2014/371045
   Sriramasubramaniam V, 2019, 2019 INT C COMPUTER, P1
   Sujarani R., 2017, INT J PURE APPL MATH, V115, P215
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Zhang XC, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/6919675
NR 25
TC 14
Z9 14
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 22213
EP 22227
DI 10.1007/s11042-022-13343-8
EA JUL 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000826131200003
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, J
   Hou, YH
   Zhang, Z
   Jin, DC
   Zhang, PH
   Li, G
AF Zhang, Jing
   Hou, Yonghong
   Zhang, Zhe
   Jin, Dengchao
   Zhang, Peihan
   Li, Ge
TI Deep region segmentation-based intra prediction for depth video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D-HEVC; Intra prediction; Depth modelling modes; Deep region
   segmentation
ID NEURAL-NETWORK
AB Depth information plays a vital role in 3D video systems. Since the depth video has large smooth areas segmented by sharp edges, preserving the sharp edges becomes a crucial task for depth video coding. Thus, depth modelling modes (DMMs) are integrated as partition prediction tools in 3D-HEVC. However, both DMM1 and DMM4 have limitations in processing diverse depth regions. To improve the performance of intra prediction for depth video coding, a novel deep region segmentation-based intra prediction (DRSIP) mode is proposed in this paper. Compared with traditional hand-crafted partition prediction methods, the proposed DRSIP mode introduces a deep region segmentation network (DRS-Net) to directly predict the segmentation result from reference texture frame. Besides, a frame-level training strategy is developed to effectively learn both local and global information for informative edge representation. Finally, the frame-level partition results are divided into block partitions to guide the reconstruction of depth blocks. Experimental results demonstrate that the proposed method achieves significant coding gains compared with the 3D-HEVC.
C1 [Zhang, Jing; Hou, Yonghong; Zhang, Zhe; Jin, Dengchao; Zhang, Peihan; Li, Ge] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Zhang, Z (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM zz300@tju.edu.cn
RI hou, yonghong/N-9255-2013
OI Zhang, Zhe/0000-0002-8772-2107
FU National Key R&D Program of China [2018YFE0203900]; National Natural
   Science Foundation of China [61931014]; Natural Science Foundation of
   Tianjin [18JCJQJC45800]
FX This work was supported in part by the National Key R&D Program of China
   (No.2018YFE0203900), National Natural Science Foundation of China (No.
   61931014), and Natural Science Foundation of Tianjin (No.18JCJQJC45800).
CR Assunçao PAA, 2017, MULTIMED TOOLS APPL, V76, P13835, DOI 10.1007/s11042-016-3766-7
   Birman R, 2020, MULTIMED TOOLS APPL, V79, P11699, DOI 10.1007/s11042-019-08572-3
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Chen YW, 2015, IEEE INT SYMP CIRC S, P1130, DOI 10.1109/ISCAS.2015.7168837
   Cong RM, 2020, IEEE T CYBERNETICS, V50, P3627, DOI 10.1109/TCYB.2019.2932005
   Cong RM, 2018, IEEE T IMAGE PROCESS, V27, P568, DOI 10.1109/TIP.2017.2763819
   Cui WX, 2017, IEEE DATA COMPR CONF, P436, DOI 10.1109/DCC.2017.53
   Duan C, 2017, ASIAPAC SIGN INFO PR, P516, DOI 10.1109/APSIPA.2017.8282087
   Helle P, 2019, IEEE DATA COMPR CONF, P448, DOI 10.1109/DCC.2019.00053
   Hu JH, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351575
   Hu YY, 2019, IEEE T MULTIMEDIA, V21, P3024, DOI 10.1109/TMM.2019.2920603
   Huang HY, 2021, IEEE T CIRC SYST VID, V31, P2100, DOI 10.1109/TCSVT.2020.3018230
   Huang H, 2019, IEEE DATA COMPR CONF, P579, DOI 10.1109/DCC.2019.00091
   Huo S, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351609
   Jia CM, 2019, IEEE T IMAGE PROCESS, V28, P3343, DOI 10.1109/TIP.2019.2896489
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jin DC, 2022, IEEE T CIRC SYST VID, V32, P3923, DOI 10.1109/TCSVT.2021.3107135
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lan CL, 2018, IEEE T CIRC SYST VID, V28, P1920, DOI 10.1109/TCSVT.2017.2689032
   LAUDE T, 2019, PICT COD SYMP, pNIL23
   Lee J, 2015, ITUTSG16WP3
   Lei JJ, 2021, IEEE T CIRC SYST VID, V31, P2686, DOI 10.1109/TCSVT.2020.3027616
   Lei JJ, 2020, IEEE T GEOSCI REMOTE, V58, P5693, DOI 10.1109/TGRS.2020.2968802
   Lei J, 2019, INT J CARDIOVAS IMAG, V35, P1221, DOI 10.1007/s10554-019-01545-5
   Li YQ, 2017, ADV SOC SCI EDUC HUM, V185, P1, DOI 10.1145/3130941
   Li Y, 2018, IEEE T CIRC SYST VID, V28, P2316, DOI 10.1109/TCSVT.2017.2727682
   Lin JP, 2019, IEEE T CIRC SYST VID, V29, P3701, DOI 10.1109/TCSVT.2018.2884203
   Lu X, 2020, IEEE DATA COMPR CONF, P382, DOI 10.1109/DCC47342.2020.00055
   Lucas LFR, 2015, IEEE T IMAGE PROCESS, V24, P4055, DOI 10.1109/TIP.2015.2456509
   Ma CY, 2020, IEEE T CIRC SYST VID, V30, P1901, DOI 10.1109/TCSVT.2019.2927027
   Merkle P, 2016, IEEE T CIRC SYST VID, V26, P570, DOI 10.1109/TCSVT.2015.2407791
   Merkle P, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P149, DOI 10.1109/PCS.2012.6213308
   Meyer M, 2019, INT CONF ACOUST SPEE, P1607, DOI [10.1109/icassp.2019.8682846, 10.1109/ICASSP.2019.8682846]
   Müller K, 2012, ASIAPAC SIGN INFO PR
   Pan ZQ, 2022, IEEE T CIRC SYST VID, V32, P345, DOI 10.1109/TCSVT.2021.3057518
   Peng B, 2021, NEUROCOMPUTING, V456, P519, DOI 10.1016/j.neucom.2020.05.123
   Schiopu I, 2020, IEEE T CIRC SYST VID, V30, P1816, DOI 10.1109/TCSVT.2019.2940092
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Yokoi R, 2021, INT J HUM-COMPUT INT, V37, P981, DOI 10.1080/10447318.2020.1861763
   Zhang K, 2017, IEEE T CIRC SYST VID, V27, P2425, DOI 10.1109/TCSVT.2016.2589819
   Zhang YH, 2017, J REAL-TIME IMAGE PR, V13, P85, DOI 10.1007/s11554-016-0589-8
   Zhang YH, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P244, DOI 10.1109/ChinaSIP.2015.7230400
   Zhao ZH, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351189
   Zhu LW, 2020, IEEE T MULTIMEDIA, V22, P45, DOI 10.1109/TMM.2019.2924591
   Zhu X, 2020, NEUROCOMPUTING, P925
NR 47
TC 3
Z9 3
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35953
EP 35964
DI 10.1007/s11042-022-13344-7
EA JUL 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000826131200001
DA 2024-07-18
ER

PT J
AU Bhatele, KR
   Bhadauria, SS
AF Bhatele, Kirti Raj
   Bhadauria, Sarita Singh
TI Multiclass classification of central nervous system brain tumor types
   based on proposed hybrid texture feature extraction methods and ensemble
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Central nervous system (CNS) brain tumors; Astrocytoma; Glioblastoma
   multiforme(GBM); Meningioma; Oligodendroglioma; Brain tumor
   segmentation(BRATS); Threshold segmentation; Discrete wavelet transform
   (DWT); Gradient Grey level co-occurrences matrix (GGLCM); Local binary
   pattern (LBP); Grey level run length matrix (GLRLM) etc
ID HEALTH-ORGANIZATION CLASSIFICATION; RUN-LENGTH; MRI; SEGMENTATION;
   IDENTIFICATION; GLIOMAS; IMAGES
AB This paper presents an automated approach to perform multiclass classification of four majorly diagnosed Central nervous system brain tumors. The Astrocytoma, Glioblastoma multiforme, Meningioma and Oligodendroglioma are the four types of central nervous system brain tumors types, whose classification is being performed with the aid of this proposed approach. In addition, this proposed approach also used to perform binary classification of Glioma brain tumors into low grade and high grade Glioma tumor. The proposed automated approach for multiclass and binary class classification is based on the threshold segmentation of fused Magnetic Resonance Imaging sequences, proposed hybrid feature extraction methods along with shape based features and ensemble learning classifier. The two hybrid feature extraction methods are proposed in this paper, one based on the Discrete wavelet transform + Gradient Grey level co-occurrences matrix and second one based on the Discrete wavelet transform + Local binary pattern + Grey level run length matrix. The extracted texture features along with the shape based features are further reduced employing Principal component analysis. The resulted selected features are finally used to train the majority voting based ensemble classifier model with the aid of Central nervous system local dataset, Brain Tumor Segmentation 2013 and 2015 global dataset. The proposed automated system delivers an accuracies of 99.12, 95.24, 97.62 and 97.62 for the correct classification of Astrocytoma, Glioblastoma multiforme, Meningioma and Oligodendroglioma over the Central nervous system local dataset. Whereas delivers an accuracy of 100 and 99.52 for the binary classification of Glioma on the Brain Tumor Segmentation 2013 and 2015 global datasets employing 10-fold cross validation.
C1 [Bhatele, Kirti Raj] BSF Acad, Rustamji Inst Technol, Gwalior, India.
   [Bhadauria, Sarita Singh] MITS, Gwalior, India.
C3 Madhav Institute of Technology & Science
RP Bhatele, KR (corresponding author), BSF Acad, Rustamji Inst Technol, Gwalior, India.
EM kirtirajbhatele8@gmail.com; saritamits61@yahoo.co.in
RI Bhatele, Kirti Raj/HIR-2424-2022
OI BHATELE, KIRTI RAJ/0000-0002-2639-367X
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Abidin AZ, 2019, PROC SPIE, V10953, DOI 10.1117/12.2512995
   Abraham P., 2020, THERAPY RESPONSE IMA, P47, DOI [10.1007/978-3-030-31171-1_4, DOI 10.1007/978-3-030-31171-1_4]
   Abu Arqub O, 2020, SOFT COMPUT, V24, P12501, DOI 10.1007/s00500-020-04687-0
   Abu Arqub O, 2017, NEURAL COMPUT APPL, V28, P1591, DOI 10.1007/s00521-015-2110-x
   Abu Arqub O, 2014, INFORM SCIENCES, V279, P396, DOI 10.1016/j.ins.2014.03.128
   [Anonymous], 2006, BERNOULLI, DOI DOI 10.1007/978-3-540-74958-5_
   Arevalo OD, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.00460
   Barker J, 2016, MED IMAGE ANAL, V30, P60, DOI 10.1016/j.media.2015.12.002
   Bashir-Gonbadi F, 2021, MULTIMED TOOLS APPL, V80, P19909, DOI 10.1007/s11042-021-10637-1
   Ben Brahim A, 2016, PATTERN RECOGN LETT, V69, P28, DOI 10.1016/j.patrec.2015.10.005
   Bhatele KR, 2020, TRAIT SIGNAL, V37, P989, DOI 10.18280/ts.370611
   Bhatele KR, 2020, ARTIF INTELL REV, V53, P3349, DOI 10.1007/s10462-019-09766-9
   Brankovic A, 2019, IEEE ACM T COMPUT BI, V16, P1802, DOI 10.1109/TCBB.2018.2833482
   Buckner JC, 2007, MAYO CLIN PROC, V82, P1271, DOI 10.4065/82.10.1271
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chaddad A, 2016, BRIT J RADIOL, V89, DOI 10.1259/bjr.20160575
   Chhabda S, 2016, QUANT IMAG MED SURG, V6, P486, DOI 10.21037/qims.2016.10.01
   David DS, 2019, BIOMED PHARMACOL J, V12, P939, DOI DOI 10.13005/bpj/1720
   Davies ER., 2018, Computer vision, V5, P93, DOI [10.1016/B978-0-12-809284-2.00004-6, DOI 10.1016/B978-0-12-809284-2.00004-6]
   Dong F, 2019, EUR RADIOL, V29, P3968, DOI 10.1007/s00330-018-5706-6
   Dorsey JF, 2020, Abeloff's Clinical Oncology, V6, P906
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Goldbrunner R, 2016, LANCET ONCOL, V17, pE383, DOI 10.1016/S1470-2045(16)30321-7
   Golshan HM, 2013, MAGN RESON IMAGING, V31, P1206, DOI 10.1016/j.mri.2013.04.004
   Gupta A, 2017, J NEUROSCI RURAL PRA, V8, P629, DOI 10.4103/jnrp.jnrp_168_17
   Gupta M, 2019, J EXP THEOR ARTIF IN, V31, P57, DOI 10.1080/0952813X.2018.1518997
   Gupta M, 2017, SIGNAL IMAGE VIDEO P, V11, P1337, DOI 10.1007/s11760-017-1091-x
   Gupta N, 2019, BIOMED SIGNAL PROCES, V47, P115, DOI 10.1016/j.bspc.2018.06.003
   Gupta N, 2018, J COMPUT SCI-NETH, V25, P213, DOI 10.1016/j.jocs.2017.02.009
   Hsieh KLC, 2017, COMPUT METH PROG BIO, V139, P31, DOI 10.1016/j.cmpb.2016.10.021
   Inano R, 2014, NEUROIMAGE-CLIN, V5, P396, DOI 10.1016/j.nicl.2014.08.001
   Khan MA, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10080565
   Kistler M, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2930
   Kono K, 2001, AM J NEURORADIOL, V22, P1081
   Kumar RL, 2021, MULTIMED TOOLS APPL, V80, P13429, DOI 10.1007/s11042-020-10335-4
   Kunimatsu A, 2019, MAGN RESON MED SCI, V18, P44, DOI 10.2463/mrms.mp.2017-0178
   Li W, 2016, PROCEDIA ENGINEER, V138, P196, DOI 10.1016/j.proeng.2016.01.250
   Lu W, 2017, COMPUT BIOL MED, V83, P157, DOI 10.1016/j.compbiomed.2017.03.002
   Ly KI, 2020, NEUROL CLIN, V38, P95, DOI 10.1016/j.ncl.2019.08.004
   Mitra A, 2020, ADV INTELL SYST, V1048, P455, DOI 10.1007/978-981-15-0035-0_36
   Mohsen H, 2017, University of Galati, Mathematics, Physics, Theoretical mechanics, Fascicle II, V40, P75
   Najrabi D., 2018, 2018 6th Iranian Joint Congress on Fuzzy and Intelligent Systems (CFIS), P152, DOI 10.1109/CFIS.2018.8336661
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Oleaga L., 2020, PRIMARY INTRAAXIAL B
   Patel AP, 2019, LANCET NEUROL, V18, P376, DOI 10.1016/S1474-4422(18)30468-X
   Pirgazi J, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-54987-1
   Polat Ö, 2021, J SUPERCOMPUT, V77, P7236, DOI 10.1007/s11227-020-03572-9
   Sachdeva J, 2016, APPL SOFT COMPUT, V47, P151, DOI 10.1016/j.asoc.2016.05.020
   Sachdeva J, 2013, J DIGIT IMAGING, V26, P1141, DOI 10.1007/s10278-013-9600-0
   Senders JT, 2018, ACTA NEUROCHIR, V160, P29, DOI 10.1007/s00701-017-3385-8
   Shukla AK, 2019, J INTELL FUZZY SYST, V36, P2247, DOI 10.3233/JIFS-169936
   Silantyev AS, 2019, CELLS-BASEL, V8, DOI 10.3390/cells8080863
   Singla C, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P1968
   Subashini MM, 2016, EXPERT SYST APPL, V43, P186, DOI 10.1016/j.eswa.2015.08.036
   Sutton O., 2012, University lectures
   Tang XO, 1998, IEEE T IMAGE PROCESS, V7, P1602, DOI 10.1109/83.725367
   Tian ZR, 2019, FRONT ONCOL, V9, DOI 10.3389/fonc.2019.00876
   Upadhyay N, 2011, BRIT J RADIOL, V84, pS107, DOI 10.1259/bjr/65711810
   Villanueva-Meyer JE, 2017, NEUROSURGERY, V81, P397, DOI 10.1093/neuros/nyx103
   Yang Y, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/579341
   Yu M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103494
   Zacharaki EI, 2009, MAGN RESON MED, V62, P1609, DOI 10.1002/mrm.22147
   Zarinbal M, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0311-6
   Zhan TM, 2017, TECHNOL HEALTH CARE, V25, pS377, DOI 10.3233/THC-171341
   Zöllner FG, 2010, MAGN RESON MED, V64, P1230, DOI 10.1002/mrm.22495
NR 67
TC 3
Z9 3
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3831
EP 3858
DI 10.1007/s11042-022-13439-1
EA JUL 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000825912900005
DA 2024-07-18
ER

PT J
AU Gupta, A
AF Gupta, Abhishek
TI RegCal: registration-based calibration method to perform linear
   measurements on PA (posteroanterior) cephalogram- a pilot study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Registration; Cephalometric analysis; Calibration; PA cephalogram;
   Linear measurements; PA X-ray image
ID BEAM COMPUTED-TOMOGRAPHY; CEPHALOMETRIC MEASUREMENTS; ACCURACY; IMAGES
AB Due to the magnification of X-ray images, calibration is required for recording linear measurements. Clinically, calibration can be performed on a lateral X-ray image, but it is difficult to perform on the PA (posteroanterior) X-ray image due to the unavailability of a calibration scale on cephalometric images. Hence, a novel registration-based method named as RegCal was proposed for the calibration of the PA X-ray image so that linear measurements can be obtained precisely for the diagnosis and treatment planning of patients in clinical practices. The method for the calibration of the PA cephalometric image is based on the lateral image of the same patient. A common distance is identified in both X-ray images, then the PA X-ray image is scaled to the number of pixels in the common distance on the lateral image. Using the scale of the lateral image, calibration was performed which is the same for the already scaled PA image. For the validation purpose, 15 linear measurements and 20 angular measurements were conducted on PA cephalometric image. The maximum and minimum linear measurement errors were found as 0.17 cm and 0 cm on the PA image. The average error on PA image was obtained as 0.06 cm and 0.70 degree for all linear measurements and angular measurements respectively. A calibration method of PA cephalometric image based on the scale of the lateral image was demonstrated which is useful for performing cephalometric analysis for diagnosis and treatment planning.
C1 [Gupta, Abhishek] Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182320, Jammu & Kashmir, India.
C3 Shri Mata Vaishno Devi University
RP Gupta, A (corresponding author), Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182320, Jammu & Kashmir, India.
EM abhishekgupta10@yahoo.co.in
RI Gupta, Abhishek/O-3016-2019
OI Gupta, Abhishek/0000-0002-8592-9964
CR Al-Azemi R, 2012, EUR J ORTHODONT, V34, P312, DOI 10.1093/ejo/cjr007
   AlBarakati SF, 2012, DENTOMAXILLOFAC RAD, V41, P11, DOI 10.1259/dmfr/37010910
   ATCHISON KA, 1991, ORAL SURG ORAL MED O, V71, P238, DOI 10.1016/0030-4220(91)90477-T
   Bajaj Kamal, 2011, Int J Clin Pediatr Dent, V4, P213, DOI 10.5005/jp-journals-10005-1112
   Bruks A, 1999, SWED DENT J, V23, P77
   Damstra J, 2013, EUR J ORTHODONT, V35, P45, DOI 10.1093/ejo/cjr045
   Devereux L, 2011, AM J ORTHOD DENTOFAC, V139, DOI 10.1016/j.ajodo.2010.09.021
   Dula Karl, 2014, Swiss Dent J, V124, P1169
   Durao AR, 2013, PROG ORTHOD, V14, DOI 10.1186/2196-1042-14-31
   Evans CA, 2013, OR SURG OR MED OR PA, V116, P238, DOI 10.1016/j.oooo.2013.06.002
   Gupta A., 2020, Int J Comput Vis Robot, V10, P360, DOI [10.1504/IJCVR.2020.108153, DOI 10.1504/IJCVR.2020.108153]
   Gupta A, 2019, US Patent, Patent No. [US10318839B2, 10318839]
   Gupta A, 2019, COMPUT SCI-AGH, V20, P389, DOI 10.7494/csci.2019.20.4.3163
   Gupta A, 2017, AM J ORTHOD DENTOFAC, V151, P118, DOI 10.1016/j.ajodo.2016.06.027
   Gupta A, 2016, INT J COMPUT ASS RAD, V11, P1297, DOI 10.1007/s11548-015-1334-7
   Gupta A, 2015, INT J COMPUT ASS RAD, V10, P1737, DOI 10.1007/s11548-015-1173-6
   Hsiao TH, 1997, ANGLE ORTHOD, V67, P137
   Huang C-S., 2018, J DENT DENT MED, DOI [10.31021/jddm.20181115, DOI 10.31021/JDDM.20181115]
   Juerchott A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-31384-8
   Michele C, 2015, J CRANIOFAC SURG, V26, pE311, DOI 10.1097/SCS.0000000000001700
   Moshiri M, 2007, AM J ORTHOD DENTOFAC, V132, P550, DOI 10.1016/j.ajodo.2006.09.046
   Neelapu BC, 2018, DENTOMAXILLOFAC RAD, V47, DOI 10.1259/dmfr.20170054
   Neelapu BC, 2017, INT J COMPUT ASS RAD, V12, P1877, DOI 10.1007/s11548-017-1650-1
   Neelapu BC, 2020, US Patent, Patent No. [US10699415B2, 10699415]
   Neto Rino., 2013, Dental Press Journal of Orthodontics, V18, P17, DOI [DOI 10.1590/S2176-94512013000200005, 10.1590/s2176-94512013000200005]
   NGH J., 2018, AL RAFIDAIN DENT J, V18, P31
   Paula Leonardo Koerich de, 2015, Dental Press J. Orthod., V20, P29, DOI 10.1590/2176-9451.20.2.029-034.oar
NR 27
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41869
EP 41879
DI 10.1007/s11042-021-11609-1
EA JUL 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000823376700016
DA 2024-07-18
ER

PT J
AU Benrhouma, O
AF Benrhouma, Oussama
TI Cryptanalysis and improvement of a semi-fragile watermarking technique
   for tamper detection and recovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptanalysis; Watermarking; Tamper detection; Attack; Chaotic functions
ID IMAGE AUTHENTICATION; SCHEME; STEGANALYSIS
AB In this paper, we analyze the security of a semi-fragile watermarking scheme recently proposed by N. Sivasubramanian et al. for tamper detection and recovery in digital images. 2D lifting wavelet transform is used to calculate and embed the authentication watermark, and 2D discrete cosine transform is used to calculate the recovery watermark. A detailed description of the scheme in question is presented and several vulnerabilities are highlighted and successful cryptanalysis is conducted. we were able to replace the embedded watermark and manipulate the images without being detected by the extraction scheme. Then an improvement of the scheme is proposed to cover the security flaws where chaotic maps are used to exploit its pseudo-random behavior. The improved scheme is tested against a variety of known attacks and showed high performance in tamper detection and recovery of the images.
C1 [Benrhouma, Oussama] Islamic Univ Madinah, Fac Comp & Informat Syst, Madinah, Saudi Arabia.
C3 Islamic University of Al Madinah
RP Benrhouma, O (corresponding author), Islamic Univ Madinah, Fac Comp & Informat Syst, Madinah, Saudi Arabia.
EM oussama.benrhoumaa@gmail.com
OI Benrhouma, Oussama/0000-0002-4540-3650
FU deanship of research at the Islamic University of Madinah, Kingdom of
   Saudi Arabia
FX The author would like to thank the deanship of research at the Islamic
   University of Madinah, Kingdom of Saudi Arabia for supporting this
   research.
CR Amsberry C., 1989, The Wall Street Journal
   [Anonymous], 1883, Journal des sciences militaires
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Benrhouma O, 2016, MULTIMED TOOLS APPL, P1
   Benrhouma O, 2016, MULTIMED TOOLS APPL, V75, P8695, DOI 10.1007/s11042-015-2786-z
   Benrhouma O, 2015, MULTIMED TOOLS APPL, V74, P3617, DOI 10.1007/s11042-013-1790-4
   Benrhouma O, 2015, NONLINEAR DYNAM, V79, P1817, DOI 10.1007/s11071-014-1777-3
   Bibhu Vimal, 2015, 2015 International Conference on Futuristic Trends on Computational Analysis and Knowledge Management (ABLAZE). Proceedings, P629, DOI 10.1109/ABLAZE.2015.7154940
   Borra S, 2020, COMP M BIO BIO E-IV, V8, P345, DOI 10.1080/21681163.2019.1595730
   Botta M, 2015, AEU-INT J ELECTRON C, V69, P242, DOI 10.1016/j.aeue.2014.09.004
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chang EC, 2003, MULTIMEDIA SYST, V9, P121, DOI 10.1007/s0530-003-0083-6
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Fridrich J, 2000, IEEE IMAGE PROC, P446, DOI 10.1109/ICIP.2000.900991
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Iqbal N, 2021, MULTIMED TOOLS APPL, V80, P36305, DOI 10.1007/s11042-021-11386-x
   Jha DP, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P86, DOI 10.1109/ICICCS.2016.7542316
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1035, DOI 10.1016/j.imavis.2008.09.004
   Li M, 2014, OPTIK, V125, P7231, DOI 10.1016/j.ijleo.2014.07.130
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lin CY, 2001, IEEE T CIRC SYST VID, V11, P153, DOI 10.1109/76.905982
   Naskar PK, 2021, NONLINEAR DYNAM, V105, P3673, DOI 10.1007/s11071-021-06761-0
   Paquet AH, 2003, SIGNAL PROCESS, V83, P2117, DOI 10.1016/S0165-1684(03)00171-3
   Rawat S, 2011, AEU-INT J ELECTRON C, V65, P840, DOI 10.1016/j.aeue.2011.01.016
   Shojanazeri H, 2017, MULTIMED TOOLS APPL, V76, P577, DOI 10.1007/s11042-015-3018-2
   Sivasubramanian N, 2020, COMPUTING, V102, P1365, DOI 10.1007/s00607-020-00797-7
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Teng L, 2013, AEU-INT J ELECTRON C, V67, P540, DOI 10.1016/j.aeue.2012.12.001
   Thanki R, 2019, MULTIMED TOOLS APPL, V78, P13905, DOI 10.1007/s11042-018-6746-2
   Wong PW, 2000, P SOC PHOTO-OPT INS, V3971, P417, DOI 10.1117/12.384996
   Wu XZ, 2021, OPT REV, V28, P589, DOI 10.1007/s10043-021-00703-2
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
   Zhang Z, 2016, INT J SECUR APPL, V10, P191, DOI 10.14257/ijsia.2016.10.10.18
   Zhu P, 2013, OPTIK, V124, P4177, DOI 10.1016/j.ijleo.2012.12.049
NR 40
TC 2
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 22149
EP 22174
DI 10.1007/s11042-022-13350-9
EA JUN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000814956000003
DA 2024-07-18
ER

PT J
AU Annadurai, S
   Arock, M
   Vadivel, A
AF Annadurai, Swaminathan
   Arock, Michael
   Vadivel, A.
TI Real and fake emotion detection using enhanced boosted support vector
   machine algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion detection; Enhanced boosted SVM; Fake emotion; False emotion;
   Genuine emotion; Real emotion; True emotion
ID GENUINE; RECOGNITION; COMMUNICATION; EXPRESSIONS; FACE
AB Differentiating real and fake emotions becomes a new challenge in facial expression recognition and emotion detection. Real and fake emotions should be taken into account when developing an application. Otherwise, a fake emotion can be categorized as real emotion thereby rendering the model as futile. Very limited research has dealt with identifying fake emotions with accuracy as results are in a range of 51-76%. Performance of the available methods in detecting fake emotions is not encouraging. Thus, in this paper, we have proposed Enhanced Boosted Support Vector Machine (EBSVM) algorithm. EBSVM is a novel technique to determine important thresholds required to understand fake emotions. We have created a new dataset named FED comprising both real and fake emotion images of 50 subjects and used them with experiments along with SASE-FE. EBSVM considers the entire data for classification at each iteration using the ensemble classifier. The EBSVM algorithm achieved 98.08% as classification accuracy for different K-fold validations.
C1 [Annadurai, Swaminathan] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 6200127, Tamil Nadu, India.
   [Arock, Michael] Natl Inst Technol, Dept Comp Applicat, Tiruchirappalli 6200015, Tamil Nadu, India.
   [Vadivel, A.] GITAM Univ, GITAM Sch Technol, Dept Comp Sci & Engn, Bengaluru 561203, Karnataka, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai; National Institute
   of Technology (NIT System); National Institute of Technology
   Tiruchirappalli; Gandhi Institute of Technology & Management (GITAM)
RP Annadurai, S (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 6200127, Tamil Nadu, India.
EM swaminathannit@gmail.com; michael@nitt.edu; vadinitt@gmail.com
RI A, Vadivel/AAX-2522-2020
OI A, Vadivel/0000-0002-0884-4676
CR ADOLPHS R, 1994, NATURE, V372, P669, DOI 10.1038/372669a0
   [Anonymous], 2020, MATLAB STAT TOOLB RE
   [Anonymous], 2012, MATLAB STAT TOOLB RE
   [Anonymous], 2018, P COGN COMP S THINK
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Bartlett MS, 2014, CURR BIOL, V24, P738, DOI 10.1016/j.cub.2014.02.009
   Besold T, 2015, KUNSTL INTELL, V29, P291, DOI 10.1007/s13218-015-0361-4
   Besold TR, 2016, KUNSTL INTELL, V30, P343, DOI 10.1007/s13218-016-0435-y
   Besold TR, 2018, ARXIV PREPRINT ARXIV
   Bhakt Neelesh, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1327, DOI 10.1109/ICECA.2018.8474594
   BVLC, 2021, DEEPL MOD
   Calvo MG, 2013, MOTIV EMOTION, V37, P202, DOI 10.1007/s11031-012-9298-1
   Confalonieri R., 2018, CONCEPT INVENTION FD
   Confalonieri R, COGSCI 2019 CREAT CO
   Confalonieri R, 2019, ARXIV PREPRINT ARXIV
   Côté S, 2013, J EXP SOC PSYCHOL, V49, P453, DOI 10.1016/j.jesp.2012.12.015
   Dawel A, 2017, BEHAV RES METHODS, V49, P1539, DOI 10.3758/s13428-016-0813-2
   Dibeklioglu H, 2015, IEEE T MULTIMEDIA, V17, P279, DOI 10.1109/TMM.2015.2394777
   Doran D., 2017, WHAT DOES EXPLAINABL
   Duchenne G., 1990, MECH HUMAN FACIAL EX
   Ekman P., 2004, BMJ-BRIT MED J, V328, DOI DOI 10.1136/SBMJ.0405184
   Ekman Paul, 1997, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression using the Facial Action Coding System (FACS)
   Ghayoumi M, 2016, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON MATHEMATICS AND COMPUTERS IN SCIENCES AND IN INDUSTRY (MCSI 2016), P178, DOI [10.1109/MCSI.2016.36, 10.1109/MCSI.2016.041]
   Ghayoumi M, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS (SIGMAP), P211
   Gunadi IGA, 2015, 2015 INTERNATIONAL CONFERENCE ON DATA AND SOFTWARE ENGINEERING (ICODSE), P103, DOI 10.1109/ICODSE.2015.7436980
   Huynh XP, 2017, IEEE INT CONF COMP V, P3065, DOI 10.1109/ICCVW.2017.362
   Karat J., 2002, HUM FAC ER, P1152
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni K, 2021, IEEE T AFFECT COMPUT, V12, P377, DOI 10.1109/TAFFC.2018.2874996
   Kumawat S, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS AND ELECTRONICS (COMPTELIX), P1, DOI 10.1109/COMPTELIX.2017.8003927
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Li LD, 2017, IEEE INT CONF COMP V, P3147, DOI 10.1109/ICCVW.2017.372
   Littlewort GC, 2009, IMAGE VISION COMPUT, V27, P1797, DOI 10.1016/j.imavis.2008.12.010
   Lopatovska I, 2011, INFORM PROCESS MANAG, V47, P575, DOI 10.1016/j.ipm.2010.09.001
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lüsi I, 2017, IEEE INT CONF AUTOMA, P809, DOI 10.1109/FG.2017.102
   Lv XQ, 2007, 2007 INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, P4, DOI 10.1109/ICIA.2007.4295687
   Matlab, DEEP LEARNING TOOLBO
   Matlab, TRANSF LEARN TOOLB
   McLellan T, 2010, COGNITION EMOTION, V24, P1277, DOI 10.1080/02699930903306181
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   Nakano M, 2002, ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, P650
   Picard RW, 2001, P SOC PHOTO-OPT INS, V4299, P518, DOI 10.1117/12.429523
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   Sander D, 2005, NEURAL NETWORKS, V18, P317, DOI 10.1016/j.neunet.2005.03.001
   Saxen F, 2017, IEEE INT CONF COMP V, P3073, DOI 10.1109/ICCVW.2017.363
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Sidera F, 2013, CURR PSYCHOL, V32, P18, DOI 10.1007/s12144-012-9159-9
   Song RT, 2016, EVOL HUM BEHAV, V37, P490, DOI 10.1016/j.evolhumbehav.2016.05.002
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Taxer JL, 2015, TEACH TEACH EDUC, V49, P78, DOI 10.1016/j.tate.2015.03.003
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Ugail H, 2019, ADV ENG INFORM, V42, DOI 10.1016/j.aei.2019.100967
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wan J, 2017, IEEE INT CONF COMP V, P3189, DOI 10.1109/ICCVW.2017.377
   Wang BX, 2010, KNOWL INF SYST, V25, P1, DOI 10.1007/s10115-009-0198-y
   Zaadnoordijk L, 2019, AAAI SPRING S CONSCI
NR 58
TC 2
Z9 2
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1333
EP 1353
DI 10.1007/s11042-022-13210-6
EA JUN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000811988300002
DA 2024-07-18
ER

PT J
AU Singh, H
   Kumar, A
   Balyan, LK
AF Singh, Himanshu
   Kumar, Anil
   Balyan, Lokendra K.
TI Fractional-order Differintegral based multiscale Retinex inspired
   texture dependent quality enhancement for remotely sensed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive filtering; Differintegration; Fractional-order calculus;
   Texture dependent processing; Multi-scale Retinex; Image fusion; Optimal
   mask designing; Quality enhancement
ID HISTOGRAM EQUALIZATION; GAMMA CORRECTION; MASKING; FRAMEWORK
AB Non-integer orders for fractional differintegral based adaptive filtering are very useful for addressing the various levels of textural discrimination in any image. This paper addresses a novel contribution for image enhancement by harvesting the collective benefits of fractional-order differentiation (FOD) as well as fractional-order integration (FOI). A 2-D fractional-order (FO) "Differintegration" (FODI) based dual-operator is proposed for imparting "on-demand adaptive-filtering" through spatial masking for adaptive textural boosting along with contrast enhancement. In addition, FODI based adaptive filtering is also employed for improving the conventional Multiscale Retinex approach. Consequently, the second novel contribution in this paper is the proposed framework for Differintegration based Fractional-order Multi-scale Retinex (DFMSR) for effective reflectance channel computation. The proposed DFMSR module is readily compatible with other image pre-processing methods for effective suppression of airborne and/or illumination based visual imperfections. An optimal fractional-order two-dimensional adaptive filtering mechanism is proposed in this paper. The proposed model is highly modular. So, it can also be pipelined in parallel manner, along with any well-established state-of-the-art contrast enhancement approach. Total quality improvement for remotely sensed textural data is achieved in this work. Being highly modular, four different possible variants of proposed approach are also discussed in this draft, so that a generalized solution can be identified for overall quality improvement for diverse variety/domains of the visual data or images.
C1 [Singh, Himanshu] Natl Inst Technol Tiruchirappalli, Dept Elect & Commun Engn, Tiruchirappalli 620015, Tamil Nadu, India.
   [Kumar, Anil; Balyan, Lokendra K.] Indian Inst Informat Technol Design & Mfg Jabalpu, Jabalpur 482005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; Indian Institute of Information Technology
   Design & Manufacturing, Jabalpur
RP Singh, H (corresponding author), Natl Inst Technol Tiruchirappalli, Dept Elect & Commun Engn, Tiruchirappalli 620015, Tamil Nadu, India.
EM himanshu.iiitj@gmail.com; anilkdee@gmail.com; lokendra.balyan@gmail.com
RI KUMAR, ANIL/ACD-8340-2022; Kumar, Anil/HJB-2850-2022; Boothapati, Anil
   Kumar/HHS-1813-2022; SINGH, HIMANSHU/AAT-6317-2020; Kumar,
   Anil/Q-6680-2016
OI Kumar, Anil/0000-0002-5817-5829; SINGH, HIMANSHU/0000-0002-0410-0602;
   Kumar, Anil/0000-0002-3945-4646
CR CRISP, 2019, CTR REM IM SENS PROC
   Demirel H, 2010, IEEE GEOSCI REMOTE S, V7, P333, DOI 10.1109/LGRS.2009.2034873
   Fu XY, 2015, IEEE GEOSCI REMOTE S, V12, P2301, DOI 10.1109/LGRS.2015.2473164
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lin SCF, 2016, OPTIK, V127, P407, DOI 10.1016/j.ijleo.2015.08.046
   Lin SCF, 2015, COMPUT ELECTR ENG, V46, P356, DOI 10.1016/j.compeleceng.2015.06.001
   Oldham K., 1974, The Fractional Calculus: Theory and Applications of Differentiation and Integration to Arbitrary Order, P1
   Pu YF, 2010, IEEE T IMAGE PROCESS, V19, P491, DOI 10.1109/TIP.2009.2035980
   Rakhshani H, 2017, APPL SOFT COMPUT, V52, P771, DOI 10.1016/j.asoc.2016.09.048
   Reddy PS, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P124, DOI 10.1109/ICCSP.2018.8524518
   Rizzi A, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.3.031201
   Samko G. S., 1993, Fractional integrals and derivatives
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Singh, 2020, RECENT ADV MEMETIC A, V873, P19, DOI [10.1007/978-981-15-1362-6_2, DOI 10.1007/978-981-15-1362-6_2]
   Singh H, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P431, DOI 10.1109/SPIN.2017.8049988
   Singh H, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P497, DOI 10.1109/ICDSP.2016.7868607
   Singh H, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P128, DOI 10.1109/ICCSP.2016.7754552
   Singh H, 2022, IEEE T SYST MAN CY-S
   Singh H, 2017, 14 IEEE IND COUNC IN, P16, DOI DOI 10.1109/INDICON.2017.8487901
   Singh H, 2020, APPL HYBRID METAHEUR, P53
   Singh H, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114884
   Singh H, 2020, ADV INTELL SYST, V1024, P483, DOI 10.1007/978-981-32-9291-8_38
   Singh H, 2019, COMPUT ELECTR ENG, V75, P245, DOI 10.1016/j.compeleceng.2017.11.014
   Singh H, 2018, COMPUT ELECTR ENG, V70, P462, DOI 10.1016/j.compeleceng.2017.06.029
   Singh H, 2019, ADV INTELL SYST, V741, P633, DOI 10.1007/978-981-13-0761-4_61
   Singh H, 2019, MULTIMED TOOLS APPL, V78, P20431, DOI 10.1007/s11042-019-7383-0
   Singh H, 2019, IEEE ACCESS, V7, P37192, DOI 10.1109/ACCESS.2019.2901292
   Singh H, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P129, DOI 10.1109/ICCSP.2018.8524564
   Singh H, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1299, DOI 10.1109/ICCSP.2017.8286592
   Singh K, 2015, OPTIK, V126, P2619, DOI 10.1016/j.ijleo.2015.06.060
   Singh K, 2014, OPTIK, V125, P4646, DOI 10.1016/j.ijleo.2014.04.093
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Wang JH, 2014, SIGNAL PROCESS, V98, P150, DOI 10.1016/j.sigpro.2013.11.024
   Wong CY, 2016, J MOD OPTIC, V63, P1618, DOI 10.1080/09500340.2016.1163428
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
NR 38
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 1593
EP 1631
DI 10.1007/s11042-022-13265-5
EA JUN 2022
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000806706500002
DA 2024-07-18
ER

PT J
AU Arora, A
   Miri, R
AF Arora, Ankit
   Miri, Rohit
TI Cryptography and Tay-Grey wolf optimization based multimodal biometrics
   for effective security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modal bio-metric system; Taylor series; Grey wolf optimization;
   Deep convolutional neural network; Cryptography
ID SCORE-LEVEL FUSION
AB Biometric recognition is very important for automatically recognizing individuals based on feature vectors from behavioral or physiological characteristics. The biometric recognition systems provide suitable personal recognition approaches for determining individuals. Biometrics are broadly employed in several commercial as well as official identification systems for automatic access control. This paper introduces the model for multi-modal biometric recognition based on the feature level fusion method. The overall procedure of the proposed method involves four steps: pre-processing, feature extraction, recognition feature-level fusion, and Bio-metric recognition. The first step is to input the images into pre-processing steps. Thus, pre-processing three traits, like face, finger knuckle, and the hand vein, is done. Then, the feature extraction is done for each modality to extract the features. After that, the feature level fusion is carried out using Elliptic-curve cryptography (ECC) and the proposed Taylor-Grey Wolf optimization (Tay-GWO). After feature fusion, the Bio-metric recognition is done based on Deep Convolutional Neural Network (DCNN), which Tay-GWO trains. The proposed Tay-GWO is designed by integrating the Taylor series and Grey Wolf Optimization (GWO). The analysis shows that the developed model achieves the maximal accuracy of 94.86%, maximal sensitivity of 96.80%, and specificity of 93.74%, respectively.
C1 [Arora, Ankit; Miri, Rohit] Dr CV Raman Inst Sci & Technol, Kargi Rd, Kota 495113, Chhattisgarh, India.
RP Arora, A (corresponding author), Dr CV Raman Inst Sci & Technol, Kargi Rd, Kota 495113, Chhattisgarh, India.
EM ankitarora1286@gmail.com; rohitmiri@gmail.com
RI Miri, Rohit Kumar/ADD-8166-2022
CR Abozaid A, 2018, MULTIMED TOOLS APPL, P1
   Alay N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195523
   Alpar O, 2017, KNOWL-BASED SYST, V116, P163, DOI 10.1016/j.knosys.2016.11.006
   Alsultan A, 2017, PATTERN RECOGN LETT, V89, P53, DOI 10.1016/j.patrec.2017.02.010
   [Anonymous], CVL FACE IMAGEDATASE
   [Anonymous], IIT Delhi Finger Knuckle Database version 1.0
   [Anonymous], BOGAZICI U HAND DATA
   Arora A, 2020, P 3 INT C INTELLIGEN
   Bojja GR, 2020, AMCIS 2020 PROCEEDINGS
   Bui TTH, 2023, J SUSTAIN FINANC INV, V13, P264, DOI 10.1080/20430795.2021.1891787
   Camara C, 2018, APPL SOFT COMPUT, V68, P784, DOI 10.1016/j.asoc.2017.07.032
   Chen YR, 2016, EXPERT SYST APPL, V64, P93, DOI 10.1016/j.eswa.2016.07.009
   Chlaoua R, 2019, EVOL SYST-GER, V10, P261, DOI 10.1007/s12530-018-9227-y
   Dwivedi R, 2020, J AMB INTEL HUM COMP, V11, P1495, DOI 10.1007/s12652-019-01437-5
   El-Bendary MAM, 2017, MULTIMED TOOLS APPL, V76, P26463, DOI 10.1007/s11042-016-4177-5
   Goswami G, 2016, INFORM FUSION, V32, P3, DOI 10.1016/j.inffus.2015.06.007
   Hung NT, 2020, P INT C HIGH ED VIET
   Kuzu RS, 2020, IEEE T INF FOREN SEC, V15, P2641, DOI 10.1109/TIFS.2020.2971144
   Lakshmi ND., 2013, Silhouette extraction of a human body based on fusion of HOG and graph-cut segmentation in dynamic backgrounds
   Lee JC, 2016, SIGNAL IMAGE VIDEO P, V10, P145, DOI 10.1007/s11760-014-0714-8
   Lumini A, 2017, INFORM FUSION, V33, P71, DOI 10.1016/j.inffus.2016.05.003
   Mangai SA., 2014, International Journal of Computer Application, V89, P41, DOI DOI 10.5120/15470-4112
   Mezai L, 2015, IEEE T HUM-MACH SYST, V45, P761, DOI 10.1109/THMS.2015.2438005
   Mills S, 2017, LOOP descriptor: Encoding repeated local patterns for fine-grained visual identification of Lepidoptera
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Miura N, 2004, MACH VISION APPL, V15, P194, DOI 10.1007/s00138-004-0149-2
   Peng JL, 2014, OPTIK, V125, P6891, DOI 10.1016/j.ijleo.2014.07.027
   Prakash A, 2019, CLUSTER COMPUT, V22, P12959, DOI 10.1007/s10586-018-1819-6
   Sabri M, 2019, J SIGNAL PROCESS SYS, V91, P163, DOI 10.1007/s11265-018-1385-4
   Shekhar S, 2014, IEEE T PATTERN ANAL, V36, P113, DOI 10.1109/TPAMI.2013.109
   Tu FB, 2017, IEEE T VLSI SYST, V25, P2220, DOI 10.1109/TVLSI.2017.2688340
   Verma D, 2020, P 3 INT C INTELLIGEN
   Verma D, 2017, J CENT SOUTH UNIV, V24, P2360, DOI 10.1007/s11771-017-3648-9
   Verma D, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417560079
   Wang YD, 2014, IET BIOMETRICS, V3, P234, DOI 10.1049/iet-bmt.2013.0042
NR 35
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44021
EP 44043
DI 10.1007/s11042-022-11993-2
EA MAY 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000803780600006
DA 2024-07-18
ER

PT J
AU Qader, SM
   Hassan, BA
   Rashid, TA
AF Qader, Shko M.
   Hassan, Bryar A.
   Rashid, Tarik A.
TI An improved deep convolutional neural network by using hybrid
   optimization algorithms to detect and classify brain tumor using
   augmented MRI images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor; Medical MRI imaging; Deep convolutional neural network;
   Harris hawks optimization; Grey wolf optimization; Medical diagnosis
ID CLASSIFICATION; FUSION
AB Automated brain tumor detection is becoming a highly considerable medical diagnosis research. In recent medical diagnoses, detection and classification are highly considered to employ machine learning and deep learning techniques. Nevertheless, the accuracy and performance of current models need to be improved for suitable treatments. In this paper, an improvement in deep convolutional learning is ensured by adopting enhanced optimization algorithms, Thus, Deep Convolutional Neural Network (DCNN) based on improved Harris Hawks Optimization (HHO), called G-HHO has been considered. This hybridization features Grey Wolf Optimization (GWO) and HHO to give better results, limiting the convergence rate and enhancing performance. Moreover, Otsu thresholding is adopted to segment the tumor portion that emphasizes brain tumor detection. Experimental studies are conducted to validate the performance of the suggested method on a total number of 2073 augmented MRI images. The technique's performance was ensured by comparing it with the nine existing algorithms on huge augmented MRI images in terms of accuracy, precision, recall, f-measure, execution time, and memory usage. The performance comparison shows that the DCNN-G-HHO is much more successful than existing methods, especially on a scoring accuracy of 97%. Additionally, the statistical performance analysis indicates that the suggested approach is faster and utilizes less memory at identifying and categorizing brain tumor cancers on the MR images. The implementation of this validation is conducted on the Python platform. The relevant codes for the proposed approach are available at: https://github.com/bryarahassan/DCNN-G-HHO.
C1 [Qader, Shko M.] Univ Coll Goizha, Informat Technol Dept, Sulaimani 46001, Iraq.
   [Qader, Shko M.] Sulaimani Polytech Univ, Comp Sci Inst, Dept Informat Technol, Sulaimani 46001, Iraq.
   [Hassan, Bryar A.] Kurdistan Inst Strateg Studies & Sci Res, Dept Informat Technol, Sulaimani, Iraq.
   [Rashid, Tarik A.] Univ Kurdistan Hewler, Comp Sci & Engn Dept, Erbil, Iraq.
C3 Sulaimani Polytechnic University; University of Kurdistan Hewler
RP Hassan, BA (corresponding author), Kurdistan Inst Strateg Studies & Sci Res, Dept Informat Technol, Sulaimani, Iraq.
EM blyar.hassan@kissr.edu.krd
RI Rashid, Tarik A./HLX-0184-2023; Rashid, Tarik A./P-3473-2019; Hassan,
   Bryar/AAX-4469-2021
OI Rashid, Tarik A./0000-0002-8661-258X; Rashid, Tarik
   A./0000-0002-8661-258X; Hassan, Dr Eng. Bryar/0000-0002-4476-9351;
   Qader, Shko/0000-0001-7520-8170
CR Akagic A, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1092, DOI 10.23919/MIPRO.2018.8400199
   Al-Tashi Q, 2020, ALGO INTELL SY, P273, DOI 10.1007/978-981-32-9990-0_13
   Amin J, 2019, COMPUT METH PROG BIO, V177, P69, DOI 10.1016/j.cmpb.2019.05.015
   Amin J, 2020, PATTERN RECOGN LETT, V139, P118, DOI 10.1016/j.patrec.2017.10.036
   Anaraki AK, 2019, BIOCYBERN BIOMED ENG, V39, P63, DOI 10.1016/j.bbe.2018.10.004
   Arasi PRE, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1266-9
   Chakrabarty N, 2019, Brain MRI Images for Brain Tumor Detection
   Chen SC, 2019, PATTERN RECOGN, V88, P90, DOI 10.1016/j.patcog.2018.11.009
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Faris H, 2018, NEURAL COMPUT APPL, V30, P413, DOI 10.1007/s00521-017-3272-5
   Ghassemi N, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101678
   Goceri E, 2020, IET IMAGE PROCESS, V14, P882, DOI 10.1049/iet-ipr.2019.0312
   Hassan, NEW FRAMEWORK ADOPT
   Hassan AB, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104866
   Hassan B., SEMANTIC WEB CHALLEN
   Hassan B.A., 2016, KURDISTAN J APPL RES, V1, P1, DOI DOI 10.24017/SCIENCE.2016.1.2.2
   Hassan BA, DCNN G HHO
   Hassan BA, 2021, ARXIV PREPR ARXIV210
   Hassan BA, 2021, COMPLEX INTELL SYST, V7, P2383, DOI 10.1007/s40747-021-00422-w
   Hassan BA, 2021, DATA BRIEF, V36, DOI 10.1016/j.dib.2021.107044
   Hassan BA, 2021, NEURAL COMPUT APPL, V33, P10987, DOI 10.1007/s00521-020-05649-1
   Hassan BA, 2021, NEURAL COMPUT APPL, V33, P7011, DOI 10.1007/s00521-020-05474-6
   Hassan BA, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.105046
   Hassan BA, 2020, APPL MATH COMPUT, V370, DOI 10.1016/j.amc.2019.124919
   Heidari AA, 2020, NEURAL COMPUT APPL, V32, P5185, DOI 10.1007/s00521-019-04015-0
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Huang P, 2021, INFORM SCIENCES, V573, P345, DOI 10.1016/j.ins.2021.05.079
   Islam MdKhairul, 2021, MACHINE LEARNING APP, V5, P1
   Kaldera H., 2019, 2019 ADV SCI ENG TEC, P1, DOI DOI 10.1109/ICASET.2019.8714263
   Kandel I, 2020, ICT EXPRESS, V6, P312
   Krishnakumar S, 2021, J AMB INTEL HUM COMP, V12, P6751, DOI 10.1007/s12652-020-02300-8
   Kumar M, 2022, IEEE T SUST COMPUT, V7, P386, DOI 10.1109/TSUSC.2021.3110245
   Kumar M, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P257, DOI 10.1109/Confluence51648.2021.9377050
   Kumar M, 2019, J NETW COMPUT APPL, V143, P1, DOI 10.1016/j.jnca.2019.06.006
   Kumar M, 2018, COMPUT ELECTR ENG, V69, P395, DOI 10.1016/j.compeleceng.2017.11.018
   Marghalani Bashayer Fouad, 2019, Procedia Computer Science, V163, P78, DOI 10.1016/j.procs.2019.12.089
   Muhammad K, 2021, IEEE T NEUR NET LEAR, V32, P507, DOI 10.1109/TNNLS.2020.2995800
   Ostrom QT, 2019, NEURO-ONCOLOGY, V21, P1357, DOI 10.1093/neuonc/noz123
   Özyurt F, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109433
   Pandiselvi T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1253-1
   Powers, 2020, ARXIV PREPR ARXIV201
   Rammurthy D, 2020, J KING SAUD U INF SC
   Rashid TA, 2020, NEURAL COMPUT APPL
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Saba T, 2020, COGN SYST RES, V59, P221, DOI 10.1016/j.cogsys.2019.09.007
   Saeed MiranHamaRahim., 2017, KURDISTAN J APPL RES, V2, P92, DOI [10.24017/science.2017.3.8, DOI 10.24017/SCIENCE.2017.3.8]
   Sahoo D.K., 2020, PALARCHS J ARCHAEOL, V17, P2319
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Sert E, 2019, MED HYPOTHESES, V133, DOI 10.1016/j.mehy.2019.109413
   Sharif M, 2020, PATTERN RECOGN LETT, V129, P150, DOI 10.1016/j.patrec.2019.11.017
   Sultan HH, 2019, IEEE ACCESS, V7, P69215, DOI 10.1109/ACCESS.2019.2919122
   Talo M, 2019, COMPUT MED IMAG GRAP, V78, DOI 10.1016/j.compmedimag.2019.101673
   Tang C, 2022, IEEE T KNOWL DATA EN, V34, P4705, DOI 10.1109/TKDE.2020.3048678
   Tang C, 2020, IEEE T KNOWL DATA EN, V32, P1747, DOI 10.1109/TKDE.2019.2911946
   Thaha MM, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1416-0
   Togaçar M, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109531
   Vijh S, 2020, LECT NOTE DATA ENG, V32, P171, DOI 10.1007/978-3-030-25797-2_8
   Vimal Kurup R., 2019, ICICCT 2019 SYSTEM R, P110
   Yin B, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101728
   Zeineldin RA, 2020, INT J COMPUT ASS RAD, V15, P909, DOI 10.1007/s11548-020-02186-z
NR 60
TC 12
Z9 12
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44059
EP 44086
DI 10.1007/s11042-022-13260-w
EA MAY 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000803780600005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, XY
   Du, XH
AF Wang, Xingyuan
   Du, Xiaohui
TI Chaotic image encryption method based on improved zigzag permutation and
   DNA rules
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; LDCML; Two-way dynamic zigzag permutation; DNA
   computing
ID SEMI-TENSOR PRODUCT; COUPLED MAP LATTICE; SPATIOTEMPORAL CHAOS;
   ALGORITHM; MATRIX
AB This paper proposes a chaotic encryption scheme, which is combining improved Zigzag scrambling and DNA coding based on random block and the Logistic-Dynamics Coupled Map Lattices (LDCML). First, we use chaotic sequences generated by LDCML system to perform index scrambling on the plain image. Then, randomly divide it into blocks and perform two-way dynamic Zigzag scrambling for each block. After that perform the two-way dynamic Zigzag scrambling for entire image. Next, convert it into DNA matrix according a coding rule, and then perform DNA addition, subtraction and XOR computing using the DNA matrix of image and the DNA sequence of chaotic sequence. Finally, decode DNA matrix and perform dynamic XOR operation on the decoded matrix. According to simulation experiments, information entropy is closer to 8, NPCR and UACI respectively reach to 99.6093% and 33.4635%, and other security analysis can also meet safety requirements. Therefore, this encryption algorithm can resist common attacks and has good security.
C1 [Wang, Xingyuan; Du, Xiaohui] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Wang, Xingyuan] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
C3 Dalian Maritime University; Guangxi Normal University
RP Wang, XY (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.; Wang, XY (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM xywang@dlmu.edu.cn; xiaohuidu98@163.com
RI Wang, Xing-yuan/I-6353-2015
OI du, xiaohui/0000-0003-4716-5702
FU National Natural Science Foundation of China [61672124]; Password Theory
   Project of the 13th Five-Year Plan National Cryptography Development
   Fund [MMJJ20170203]; Liaoning Province Science and Technology Innovation
   Leading Talents Program Project [XLYC1802013]; Key R&D Projects of
   Liaoning Province [2019020105-JH2/103]; Jinan City '20 universities'
   Funding Projects Introducing Innovation Team Program [2019GXRC031];
   Research Fund of Guangxi Key Lab of Multi-source Information Mining
   Security [MIMS20-M-02]
FX This research is supported by the National Natural Science Foundation of
   China (No: 61672124), the Password Theory Project of the 13th Five-Year
   Plan National Cryptography Development Fund (No: MMJJ20170203), Liaoning
   Province Science and Technology Innovation Leading Talents Program
   Project (No: XLYC1802013), Key R&D Projects of Liaoning Province (No:
   2019020105-JH2/103), Jinan City `20 universities' Funding Projects
   Introducing Innovation Team Program (No: 2019GXRC031), Research Fund of
   Guangxi Key Lab of Multi-source Information Mining & Security (No:
   MIMS20-M-02).
CR Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   Asgari-Chenaghlu M, 2019, SIGNAL PROCESS, V157, P1, DOI 10.1016/j.sigpro.2018.11.010
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Chai ZQ, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1167-5
   Dong H, 2020, IEEE ACCESS, V8, P163524, DOI 10.1109/ACCESS.2020.3022398
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   KANEKO K, 1989, PHYSICA D, V34, P1, DOI 10.1016/0167-2789(89)90227-3
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li RZ, 2019, IET IMAGE PROCESS, V13, P125, DOI 10.1049/iet-ipr.2018.5900
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P4363, DOI 10.1007/s11042-015-2479-7
   Liu Y, 2020, NONLINEAR DYNAM, V100, P2917, DOI 10.1007/s11071-020-05654-y
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Luo XS, 2018, INT CONF SIGN PROCES, P317, DOI 10.1109/ICSP.2018.8652390
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Rehman A.-U., 2016, MULTIMED TOOLS APPL, V75, P1, DOI DOI 10.1007/s11042-014-2221-x
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P2105, DOI 10.1007/s11042-018-6346-1
   Shakiba A, 2020, MULTIMED TOOLS APPL, V79, P32575, DOI 10.1007/s11042-020-09434-z
   Shi H, 2019, ACTA PHYS SIN-CH ED, V68, DOI 10.7498/aps.68.20190553
   Tao Y, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102650
   Wang MX, 2021, INFORM SCIENCES, V544, P1, DOI 10.1016/j.ins.2020.07.051
   Wang XY, 2022, IEEE T CIRCUITS-I, V69, P1291, DOI 10.1109/TCSI.2021.3133318
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang XY, 2021, INFORM SCIENCES, V569, P217, DOI 10.1016/j.ins.2021.04.013
   Wang XY, 2020, CHAOS SOLITON FRACT, V141, DOI 10.1016/j.chaos.2020.110309
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105581
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wen WY, 2020, NONLINEAR DYNAM, V99, P1587, DOI 10.1007/s11071-019-05378-8
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Xian YJ, 2022, IEEE T CIRC SYST VID, V32, P4028, DOI 10.1109/TCSVT.2021.3108767
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xie D, 2019, DIGIT SIGNAL PROCESS, V95, DOI 10.1016/j.dsp.2019.102587
   Yan ZY, 2005, APPL MATH COMPUT, V168, P1239, DOI 10.1016/j.amc.2004.10.016
   Yang YG, 2021, MULTIMED TOOLS APPL, V80, P691, DOI 10.1007/s11042-020-09779-5
   Yu WQ, 2019, MULTIMED TOOLS APPL, V78, P20037, DOI 10.1007/s11042-018-7110-2
   Zheng JY, 2020, IET IMAGE PROCESS, V14, P2310, DOI 10.1049/iet-ipr.2019.1340
   Zhu SQ, 2019, MULTIMED TOOLS APPL, V78, P20855, DOI 10.1007/s11042-019-7405-y
   Zhu XS, 2020, OPTIK, V224, DOI 10.1016/j.ijleo.2020.164725
NR 41
TC 12
Z9 12
U1 6
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43777
EP 43803
DI 10.1007/s11042-022-13012-w
EA MAY 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000805509400004
DA 2024-07-18
ER

PT J
AU Feng, FJ
   Huang, H
   Liu, D
   Liang, YH
AF Feng, Fujian
   Huang, Han
   Liu, Di
   Liang, Yihui
TI Local complexity difference matting based on weight map and alpha mattes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image matting; Local complexity difference matting; Weight map; Alpha
   mattes
AB Image matting is an essential image processing technology in computer vision with significant diverse practical applications, including image synthesis, webcasting, and movie production. Although some methods have been proposed to extract the alpha mattes, these methods are not sensitive enough to local complex regions with large differences between the input image and the ground-truth alpha matte. In this paper, we design a weight map generation algorithm, which extracts the local complex region of each image by measuring the local complex differences between the input image and the ground-truth alpha matte. For the weight consistency problem of the pixel-level loss function, we propose a loss function based on local complexity differences, which can strengthen the training on local regions of large complexity differences. Moreover, we design a local complexity difference matting approach on the basis of the presented loss function and weight map generation algorithm to improve the matting accuracy of local complexity difference images. To verify the validity of the proposed matting method, experiments were conducted on the composition-1 k matting evaluation data set produced by Adobe. Experimental results show that the proposed weight map generation algorithm can effectively extract the local complex regions. Our proposed matting method outperforms state-of-the-art matting methods in the cases of locally complexity difference images.
C1 [Feng, Fujian] Guizhou Minzu Univ, Guizhou Key Lab Pattern Recognit & Intelligent Sy, Guiyang 550025, Guizhou, Peoples R China.
   [Feng, Fujian; Huang, Han; Liu, Di] South China Univ Technol, Sch Software Engn, Guangzhou 510006, Peoples R China.
   [Liang, Yihui] Univ Elect Sci & Technol China, Sch Comp Sci, Zhongshan Inst, Zhongshan 528400, Peoples R China.
C3 Guizhou Minzu University; South China University of Technology;
   University of Electronic Science & Technology of China
RP Liu, D (corresponding author), South China Univ Technol, Sch Software Engn, Guangzhou 510006, Peoples R China.
EM fujian_feng@gzmu.edu.cn; hhan@scut.edu.cn; cs.dylanliu@gmail.com
RI Zhang, Can/JUU-9511-2023
OI Feng, Fujian/0000-0002-1163-3298
FU National Natural Science Foundation of China [61876207, 62002053,
   62162012]; Natural Science Foundation of Guizhou Province
   [QKHJCZK2022YB195]; Natural Science Foundation of Guizhou Minzu
   University [GZMUZK[2021]YB24]; Natural Science Foundation of Guangdong
   Province [2022A1515011491, 2021A0101180005]; Fundamental Research Funds
   for the Central Universities [2020ZYGXZR014]; Youth Science and
   Technology Talents Cultivating Object of Guizhou Province
   [QJHKY2021104]; Science and Technology Support Program of Guizhou
   [QKHZC2021YB531]; Guangdong Basic and Applied Basic Research Foundation
   [2019A1515111082]; Zhongshan Science and Technology Research Project of
   Social welfare [2019B2010]; University Young Innovative Talent Project
   of Guangdong Province [2019KQNCX186]; Key Research and Development
   Program of Zhongshan [2019A4018]
FX This work was supported in part by the National Natural Science
   Foundation of China (no. 61876207, no. 62002053 and no. 62162012), the
   Natural Science Foundation of Guizhou Province (no. QKHJCZK2022YB195),
   the Natural Science Foundation of Guizhou Minzu University (no.
   GZMUZK[2021]YB24), the Natural Science Foundation of Guangdong Province
   (no. 2022A1515011491 and no. 2021A0101180005), the Fundamental Research
   Funds for the Central Universities (no. 2020ZYGXZR014), the Youth
   Science and Technology Talents Cultivating Object of Guizhou Province
   (no. QJHKY2021104), the Science and Technology Support Program of
   Guizhou (no. QKHZC2021YB531), the Guangdong Basic and Applied Basic
   Research Foundation (no. 2019A1515111082), the Zhongshan Science and
   Technology Research Project of Social welfare (no. 2019B2010), the
   University Young Innovative Talent Project of Guangdong Province (no.
   2019KQNCX186), the Key Research and Development Program of Zhongshan
   (no. 2019A4018).
CR Aksoy Y, 2017, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2017.32
   [Anonymous], 2019, P IEEECVF INT C COMP
   Barron JT, 2019, PROC CVPR IEEE, P4326, DOI 10.1109/CVPR.2019.00446
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Cho D, 2019, IEEE T IMAGE PROCESS, V28, P1054, DOI 10.1109/TIP.2018.2872925
   Cho D, 2017, IEEE T PATTERN ANAL, V39, P1504, DOI 10.1109/TPAMI.2016.2606397
   Cho D, 2016, LECT NOTES COMPUT SC, V9906, P626, DOI 10.1007/978-3-319-46475-6_39
   [冯夫健 Feng Fujian], 2020, [中国科学. 信息科学, Scientia Sinica Informationis], V50, P424
   Feng XX, 2016, LECT NOTES COMPUT SC, V9906, P204, DOI 10.1007/978-3-319-46475-6_13
   Gong ML, 2015, IEEE T IMAGE PROCESS, V24, P1356, DOI 10.1109/TIP.2015.2401516
   He KM, 2011, PROC CVPR IEEE
   Huang H, 2019, IEEE T IMAGE PROCESS, V28, P3739, DOI 10.1109/TIP.2019.2902830
   Karacan L, 2017, IEEE T IMAGE PROCESS, V26, P4523, DOI 10.1109/TIP.2017.2718664
   Kingma D. P., 2014, arXiv
   Lee Y, 2018, IEEE T IMAGE PROCESS, V27, P594, DOI 10.1109/TIP.2017.2765827
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li LD, 2016, IEEE T IMAGE PROCESS, V25, P3775, DOI 10.1109/TIP.2016.2577891
   Liang YH, 2019, IEEE T FUZZY SYST, V27, P1100, DOI 10.1109/TFUZZ.2019.2896533
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu H, 2022, IEEE T PATTERN ANAL, V44, P242, DOI 10.1109/TPAMI.2020.3004474
   Lutz Sebastian, 2018, IEEE C COMP VIS PATT
   Porter T., 1984, Computers & Graphics, V18, P253
   Tang JW, 2019, PROC CVPR IEEE, P3050, DOI 10.1109/CVPR.2019.00317
   Wang Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P999
   Xu N, 2017, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2017.41
   Yoon D, 2020, IEEE SIGNAL PROC LET, V27, P2139, DOI 10.1109/LSP.2020.3039952
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang T, 2021, IEEE T MULTIMEDIA, V115
   Zhao MH, 2019, IEEE ACCESS, V7, P181142, DOI 10.1109/ACCESS.2019.2959004
   Zou DQ, 2020, IEEE T PATTERN ANAL, V42, P1501, DOI 10.1109/TPAMI.2019.2895331
NR 30
TC 3
Z9 4
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43357
EP 43372
DI 10.1007/s11042-022-13223-1
EA MAY 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800846300003
DA 2024-07-18
ER

PT J
AU Yusuf, AA
   Feng, C
   Mao, XL
AF Yusuf, Abdulganiyu Abdu
   Feng Chong
   Mao Xianling
TI Evaluation of graph convolutional networks performance for visual
   question answering on reasoning datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VQA; GCN; Performance measure; Fine-tuned representation; Reasoning
   datasets
AB In the recent era, graph neural networks are widely used on vision-to-language tasks and achieved promising results. In particular, graph convolution network (GCN) is capable of capturing spatial and semantic relationships needed for visual question answering (VQA). But, applying GCN on VQA datasets with different subtasks can lead to varying results. Also, the training and testing size, evaluation metrics and hyperparameter used are other factors that affect VQA results. These, factors can be subjected into similar evaluation schemes in order to obtain fair evaluations of GCN based result for VQA. This study proposed a GCN framework for VQA based on fine tune word representation to solve handle reasoning type questions. The framework performance is evaluated using various performance measures. The results obtained from GQA and VQA 2.0 datasets slightly outperform most existing methods.
C1 [Yusuf, Abdulganiyu Abdu; Feng Chong; Mao Xianling] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing, Peoples R China.
   [Yusuf, Abdulganiyu Abdu] Natl Biotechnol Dev Agcy, Abuja, Nigeria.
   [Feng Chong] Beijing Inst Technol, South East Informat Technol Inst, Beijing, Peoples R China.
   [Mao Xianling] Beijing Engn Res Ctr High Volume Language Informa, Beijing, Peoples R China.
C3 Beijing Institute of Technology; Beijing Institute of Technology
RP Feng, C (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing, Peoples R China.; Feng, C (corresponding author), Beijing Inst Technol, South East Informat Technol Inst, Beijing, Peoples R China.
EM abdulg720@gmail.com; fengchong@bit.edu.cn; maoxl@bit.edu.cn
RI Yusuf, Abdulganiyu/ABC-1247-2021
OI ABDU YUSUF, ABDULGANIYU/0000-0002-3137-2398
FU National Key R&D Program of China [2017YFB1002101]; Joint Advanced
   Research Foundation of China Electronics Technology Group Corporation
   [6141B08010102]
FX This work is supported by the National Key R&D Program of China No.
   2017YFB1002101 and the Joint Advanced Research Foundation of China
   Electronics Technology Group Corporation No. 6141B08010102.
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Gupta Deepak, 2021, Expert Systems with Applications, V164, P465, DOI 10.1016/j.eswa.2020.113993
   Gurari D, 2018, P IEEE C COMPUTER VI
   He B, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION ENGINEERING (ICRAE), P441, DOI 10.1109/ICRAE.2017.8291426
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hildebrandt M, 2020, AAAI CONF ARTIF INTE, V34, P4123
   Hudson Drew A, 2019, P IEEE CVF C COMP VI, P6700, DOI DOI 10.1109/CVPR.2019.00686
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
   Kipf TN, 2017, INT C LEARN REPR
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li DW, 2019, IEEE T IMAGE PROCESS, V28, P1575, DOI 10.1109/TIP.2018.2878349
   Narasimhan M, 2018, ADV NEUR IN, V31
   Norcliffe-Brown W, 2018, ADV NEUR IN, V31
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Probst P, 2019, J MACH LEARN RES, V20
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh AK, 2019, IEEE I CONF COMP VIS, P4601, DOI 10.1109/ICCV.2019.00470
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Teney D, 2017, PROC CVPR IEEE, P3233, DOI 10.1109/CVPR.2017.344
   Trott A., 2018, INT C LEARN REPR
   Wang XL, 2018, PROC CVPR IEEE, P6857, DOI 10.1109/CVPR.2018.00717
   Wu Z, 2022, IEEE T NEUR NET LEAR, V33, P1974, DOI 10.1109/TNNLS.2021.3098866
   Xu X, 2021, IEEE T NEUR NET LEAR, V32, P1654, DOI 10.1109/TNNLS.2020.2986029
   Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41
   Yang Z, 2018, ARXIV PREPRINT ARXIV, V3
   Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yu J, 2018, LECT NOTES COMPUT SC, V11164, P223, DOI 10.1007/978-3-030-00776-8_21
   Ze Hu, 2020, 2020 IEEE Fifth International Conference on Data Science in Cyberspace (DSC). Proceedings, P218, DOI 10.1109/DSC50466.2020.00040
   Zhang Yang, 2019, INT C LEARN REPR
   Zhou X, 2020, IEEE T CYBERNETICS, V50, P1460, DOI 10.1109/TCYB.2018.2883970
   Zhu X, 2021, MULTIMED TOOLS APPL, V80, P16247, DOI 10.1007/s11042-020-08790-0
NR 36
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40361
EP 40370
DI 10.1007/s11042-022-13065-x
EA MAY 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791885300005
DA 2024-07-18
ER

PT J
AU Singh, N
   Rathore, SS
   Kumar, S
AF Singh, Nalin
   Rathore, Santosh Singh
   Kumar, Sandeep
TI Towards a super-resolution based approach for improved face recognition
   in low resolution environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Super resolution; Video surveillance; Face detection
ID IMAGE SUPERRESOLUTION; RECONSTRUCTION; REPRESENTATION; ALGORITHM;
   FEATURES
AB The video surveillance activity generates a vast amount of data, which can be processed to detect miscreants. The task of identifying and recognizing an object in surveillance data is intriguing yet difficult due to the low resolution of captured images or video. The super-resolution approach aims to enhance the resolution of an image to generate a desirable high-resolution one. This paper develops a robust real-time face recognition approach that uses super-resolution to improve images and detect faces in the video. Many previously developed face detection systems are constrained by the severe distortion in the captured images. Further, many systems failed to handle the effect of motion, blur, and noise on the images registered on a camera. The presented approach improves descriptor count of the image based on the super-resolved faces and mitigates the effect of noise. Furthermore, it uses a parallel architecture to implement a super-resolution algorithm and overcomes the efficiency drawback increasing face recognition performance. Experimental analysis on the ORL, Caltech, and Chokepoint datasets has been carried out to evaluate the performance of the presented approach. The PSNR (Peak Signal-to-Noise-Ratio) and face recognition rate are used as the performance measures. The results showed significant improvement in the recognition rates for images where the face didn't contain pose expressions and scale variations. Further, for the complicated cases involving scale, pose, and lighting variations, the presented approach resulted in an improvement of 5%-6% in each case.
C1 [Singh, Nalin; Kumar, Sandeep] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
   [Rathore, Santosh Singh] ABV Indian Inst Informat Technol & Management, Dept Informat Technol, Gwalior, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; ABV-Indian Institute of Information
   Technology & Management, Gwalior
RP Kumar, S (corresponding author), Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.; Rathore, SS (corresponding author), ABV Indian Inst Informat Technol & Management, Dept Informat Technol, Gwalior, India.
EM nalinsingh1@gmail.com; santoshs@iiitm.ac.in; sandeep.garg@cs.iitr.ac.in
RI Kumar, Sandeep/AAW-6570-2020; Kumar, Dr Sandeep/AAW-6313-2020
OI Kumar, Sandeep/0000-0002-3250-4866; Kumar, Dr
   Sandeep/0000-0003-0747-6776; Rathore, Santosh Singh/0000-0003-2087-1666;
   Kumar, Sandeep/0000-0001-9633-407X
CR Ahsan MM, 2018, REAL TIME FACE RECOG
   Ali W, 2021, MULTIMED TOOLS APPL, V80, P4825, DOI 10.1007/s11042-020-09850-1
   Ataer-Cansizoglu E, 2018, BRIT MACH VIS C
   Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Basu DK, 2020, NEUROCOMPUTING, V408, P273, DOI [DOI 10.1016/J.NEUCOM.2019.10.117, 10.1016/j.neucom.2019.10.117]
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Biswas S, 2012, IEEE T PATTERN ANAL, V34, P2019, DOI 10.1109/TPAMI.2011.278
   Boom B. J., 2006, Control, Automation, Robotics and Vision, 2006. ICARCV'06. 9th International Conference on, IEEE, P1, DOI [10.1109/ICARCV.2006.345480, DOI 10.1109/ICARCV.2006.345480]
   Capel D, 2001, PROC CVPR IEEE, P627
   Chai T, 2014, GEOSCI MODEL DEV, V7, P1247, DOI 10.5194/gmd-7-1247-2014
   Chen CF, 2021, IEEE T IMAGE PROCESS, V30, P1219, DOI 10.1109/TIP.2020.3043093
   Chen YT, 2021, MULTIMED TOOLS APPL, V80, P30839, DOI 10.1007/s11042-020-09969-1
   Emami S., 2012, Journal of Mobile, Embedded and Distributed Systems, V4, P38
   Evangelidis GD, 2009, INT J ARTIF INTELL T, V18, P121, DOI 10.1142/S021821300900007X
   Faragallah O, 2020, COMPREHENSIVE SURVEY
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Fink M., 2003, The full images for natural knowledge caltech office db
   Fookes C, 2012, J VIS COMMUN IMAGE R, V23, P75, DOI 10.1016/j.jvcir.2011.06.004
   Fortun D, 2018, IEEE T IMAGE PROCESS, V27, P5612, DOI 10.1109/TIP.2018.2856399
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P3194, DOI 10.1109/TIP.2012.2190080
   Hennings-Yeomans PH, 2008, PROC CVPR IEEE, P3637
   Hermosilla G, 2012, PATTERN RECOGN, V45, P2445, DOI 10.1016/j.patcog.2012.01.001
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Jebadurai J, 2018, FUTURE GENER COMP SY, V83, P338, DOI 10.1016/j.future.2018.01.058
   Jiancheng Cai, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P109, DOI 10.1109/TBIOM.2019.2951063
   Ke Y, 2004, PROC CVPR IEEE, P506
   Keren D., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P742, DOI 10.1109/CVPR.1988.196317
   Kim J, 2021, NEUROCOMPUTING, V446, P11, DOI 10.1016/j.neucom.2021.03.048
   Kong YH, 2013, OPTIK, V124, P6926, DOI 10.1016/j.ijleo.2013.05.175
   Kumar A., 2017, 2016 IEEE Annual India Conference, P1, DOI DOI 10.1109/ICISC.2017.8068696
   Kumar K, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P100, DOI 10.1145/3154979.3154998
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kushwaha A, 2021, MULTIMED TOOLS APPL, V80, P32511, DOI 10.1007/s11042-021-11207-1
   Lemieux A, 2002, INT C PATT RECOG, P421, DOI 10.1109/ICPR.2002.1044743
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li B, 2010, IEEE SIGNAL PROC LET, V17, P20, DOI 10.1109/LSP.2009.2031705
   Li P, 2019, IEEE T INF FOREN SEC, V14, P2000, DOI 10.1109/TIFS.2018.2890812
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu T, 2018, IEEE ACCESS, V6, P56269, DOI 10.1109/ACCESS.2018.2872761
   Mulyono I. U. W., 2019, 2019 INT SEMINAR APP, P1, DOI DOI 10.1109/ISEMANTIC.2019.8884225
   Negi A., 2021, INT C BIG DAT AN SPR, V9, P296
   Negi A, 2020, 2020 5TH IEEE INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (IEEE - ICRAIE-2020), DOI 10.1109/ICRAIE51050.2020.9358337
   Negi A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P595, DOI 10.1109/ICCCIS51004.2021.9397196
   Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P1299, DOI 10.1109/83.941854
   Owusu E, 2019, SOFTWARE PRACT EXPER, V49, P120, DOI 10.1002/spe.2646
   Park JS, 2008, IEEE T IMAGE PROCESS, V17, P1806, DOI 10.1109/TIP.2008.2001394
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Phillips P. J., 2003, 2003 IEEE International Workshop on Analysis and Modeling of Faces and Gestures
   Phillips PJ, 2009, LECT NOTES COMPUT SC, V5558, P705, DOI 10.1007/978-3-642-01793-3_72
   Qin Z, 2019, IEEE ACCESS, V7, P152891, DOI 10.1109/ACCESS.2019.2948260
   Quevedo E, 2016, RECENT ADVANCES IN IMAGE AND VIDEO CODING, P101, DOI 10.5772/65442
   Rajput SS, 2020, MULTIMED TOOLS APPL, V79, P23909, DOI 10.1007/s11042-020-09072-5
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shamsolmoali P, 2019, MULTIMED TOOLS APPL, V78, P23815, DOI 10.1007/s11042-018-5915-7
   Sharma S, 2017, 2017 IEEE 7TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE IEEE CCWC-2017
   Singh R, 2019, MULTIMED TOOLS APPL, V78, P17165, DOI 10.1007/s11042-018-7108-9
   Solanki Akshay, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2018. Advances in Intelligent Systems and Computing (AISC 1053), P905, DOI 10.1007/978-981-15-0751-9_83
   Tian CW, 2021, IEEE T MULTIMEDIA, V23, P1489, DOI 10.1109/TMM.2020.2999182
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang J., 2004, Proceedings of Asia Conference on Computer Vision, P48
   Wang NN, 2014, INT J COMPUT VISION, V106, P9, DOI 10.1007/s11263-013-0645-9
   Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171
   Wang ZF, 2014, VISUAL COMPUT, V30, P359, DOI 10.1007/s00371-013-0861-x
   Wu W, 2011, IMAGE VISION COMPUT, V29, P394, DOI 10.1016/j.imavis.2011.02.001
   Xu J, 2021, MULTIMED TOOLS APPL, V80, P5495, DOI 10.1007/s11042-020-09964-6
   Yang CY, 2013, PROC CVPR IEEE, P1099, DOI 10.1109/CVPR.2013.146
   Yang Li, 2004, Proceedings. Third International Conference on Image and Graphics, P298
   Yongkang Wong, 2011, 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops 2011), P74, DOI 10.1109/CVPRW.2011.5981881
   Yue LW, 2016, SIGNAL PROCESS, V128, P389, DOI 10.1016/j.sigpro.2016.05.002
   Zhang W, 2008, PROC CVPR IEEE, P2038
   Zhou LG, 2019, IEEE T NEUR NET LEAR, V30, P3275, DOI 10.1109/TNNLS.2018.2890550
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 78
TC 9
Z9 9
U1 5
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38887
EP 38919
DI 10.1007/s11042-022-13160-z
EA APR 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787666500009
PM 35493417
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Zhao, AT
   Li, JB
AF Zhao, Aite
   Li, Jianbo
TI Two-channel lstm for severity rating of parkinson's disease using 3d
   trajectory of hand motion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parkinson's disease; Severity rating; 3D hand pose; Hand movements
ID CLASSIFICATION
AB Hand movement is one of the important bases for the severity rating of Parkinson's disease. While observing hand motion of patients, medical specialists evaluate the degree of motor deterioration according to established rating scales. This diagnostic procedure is inefficient and can be easily affected by different doctors' subjectivity, even though several studies showed rating scales are reliable. In this paper, we propose an automatic method based on hand exercise data including finger-tapping and fist movements, which is recorded by ordinary camera. We estimate 3D hand pose from regular RGB images and proposed a two-channel long short-term memory model to learn the patterns of 3D position changing trajectory of hand joints. Experiments on our dataset, the proposed method outperforms literature including popular machine learning methods with 95.7% of the precision, 95.8% of the sensitivity and 92.8% of the specificity respectively on average. We believe the quantitative evaluation of hand movement will benefit the clinical PD diagnosis.
C1 [Zhao, Aite] Qingdao Univ, Sch Business, Qingdao, Peoples R China.
   [Li, Jianbo] Qingdao Univ, Coll Comp Sci & Technol, Qingdao, Peoples R China.
C3 Qingdao University; Qingdao University
RP Li, JB (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao, Peoples R China.
EM zhaoaite@qdu.edu.cn; lijianbo@qdu.edu.cn
OI Zhao, Aite/0000-0003-3494-175X
FU National Key Research and Development Plan Key Special Projects
   [2018YFB2100303]; Shandong Province colleges and universities youth
   innovation technology plan innovation team project [2020KJN011];
   Shandong Provincial Natural Science Foundation [ZR2020MF060,
   ZR2021QF084]; Program for Innovative Postdoctoral Talents in Shandong
   Province [40618030001]; National Natural Science Foundation of China
   [62106117, 61802216]; Postdoctoral Science Foundation of China
   [2018M642613]
FX This research was supported in part by National Key Research and
   Development Plan Key Special Projects under Grant No. 2018YFB2100303,
   Shandong Province colleges and universities youth innovation technology
   plan innovation team project under Grant No. 2020KJN011, Shandong
   Provincial Natural Science Foundation under Grant No. ZR2020MF060,
   Program for Innovative Postdoctoral Talents in Shandong Province under
   Grant No. 40618030001, National Natural Science Foundation of China
   under Grant No. 61802216, and Postdoctoral Science Foundation of China
   under Grant No.2018M642613. National Natural Science Foundation of China
   under Grant No.62106117, and Shandong Provincial Natural Science
   Foundation under Grant No.ZR2021QF084.
CR Alty JE, 2016, INT PARK MOV DIS SOC
   [Anonymous], 2016, THESIS
   Ariyanto M, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTOMATION, COGNITIVE SCIENCE, OPTICS, MICRO ELECTRO-MECHANICAL SYSTEM, AND INFORMATION TECHNOLOGY (ICACOMIT), P12, DOI 10.1109/ICACOMIT.2015.7440146
   Arora S, 2015, PARKINSONISM RELAT D, V21, P650, DOI 10.1016/j.parkreldis.2015.02.026
   Camgöz NC, 2015, LECT NOTES COMPUT SC, V8925, P579, DOI 10.1007/978-3-319-16178-5_41
   Chen HL, 2016, NEUROCOMPUTING, V184, P131, DOI 10.1016/j.neucom.2015.07.138
   Diaz M, 2019, PATTERN RECOGN LETT, V128, P204, DOI 10.1016/j.patrec.2019.08.018
   Escalante HJ, 2016, PATTERN RECOGN LETT, V73, P91, DOI 10.1016/j.patrec.2016.01.013
   Gage H, 2003, J NEUROL NEUROSUR PS, V74, P163, DOI 10.1136/jnnp.74.2.163
   Giancardo L, 2016, SCI REP-UK, V6, DOI 10.1038/srep34468
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ireland D, 2016, STUD HEALTH TECHNOL, V227, P61, DOI 10.3233/978-1-61499-666-8-61
   Khan T, 2014, ARTIF INTELL MED, V60, P27, DOI 10.1016/j.artmed.2013.11.004
   Kim H, 2015, SENSORS-BASEL, V15, P12410, DOI 10.3390/s150612410
   Kingma D. P., 2015, PROC INT C LEARN REP, P1
   Krupicka R., 2011, P 5 EUR C INT FED ME, DOI [10.1007/978-3-642-23508-5_220, DOI 10.1007/978-3-642-23508-5_220]
   Kupryjanow Adam, 2010, 2010 21st International Conference on Database and Expert Systems Applications, P132, DOI 10.1109/DEXA.2010.87
   Li FY, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.5739
   Li YM, 2017, J MED IMAG HEALTH IN, V7, P444, DOI 10.1166/jmihi.2017.2033
   Liu X, 2020, IEEE T NEUR SYS REH, V28, P2325, DOI 10.1109/TNSRE.2020.3021410
   Mittal SO, 2018, PARKINSONISM RELAT D, V56, P65, DOI 10.1016/j.parkreldis.2018.06.019
   Molchanov Pavlo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301342
   Molchanov P, 2016, PROC CVPR IEEE, P4207, DOI 10.1109/CVPR.2016.456
   Papadopoulos A, 2020, IEEE J BIOMED HEALTH, V24, P2559, DOI 10.1109/JBHI.2019.2961748
   Parziale A, 2021, ARTIF INTELL MED, V111, DOI 10.1016/j.artmed.2020.101984
   Printy BP, 2014, IEEE ENG MED BIO, P2686, DOI 10.1109/EMBC.2014.6944176
   Sano Y, 2016, MED BIOL ENG COMPUT, V54, P953, DOI 10.1007/s11517-016-1467-z
   Shima K, 2009, SENSORS-BASEL, V9, P2187, DOI 10.3390/s90302187
   Stamatakis J, 2013, COMPUT INTEL NEUROSC, V2013, DOI 10.1155/2013/717853
   Tsironi E, 2017, NEUROCOMPUTING, V268, P76, DOI 10.1016/j.neucom.2016.12.088
   Wang YM, 2022, COGN COMPUT, V14, P1571, DOI 10.1007/s12559-021-09843-8
   Yokoe M, 2009, PARKINSONISM RELAT D, V15, P440, DOI 10.1016/j.parkreldis.2008.11.003
   Yu XY, 2022, J AMB INTEL HUM COMP, V13, P1405, DOI 10.1007/s12652-020-02638-z
   Zeng W, 2016, NEUROSCI LETT, V633, P268, DOI 10.1016/j.neulet.2016.09.043
   Zhou Y, 2018, IEEE T NEUR SYS REH, V26, P1823, DOI 10.1109/TNSRE.2018.2859793
   Zimmermann C, 2017, IEEE I CONF COMP VIS, P4913, DOI 10.1109/ICCV.2017.525
NR 36
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33851
EP 33866
DI 10.1007/s11042-022-12659-9
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300013
DA 2024-07-18
ER

PT J
AU Zhang, ZF
   Peng, Y
   Gan, CQ
   Abate, AF
   Zhu, LX
AF Zhang, Zufan
   Peng, Yue
   Gan, Chenquan
   Abate, Andrea Francesco
   Zhu, Lianxiang
TI Separable 3D residual attention network for human action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human computer interaction; Human action recognition; Residual network;
   Attention mechanism; Multi-stage training strategy
ID SPATIAL-TEMPORAL ATTENTION; FEATURES; LSTM
AB As an important research issue in computer vision, human action recognition has been regarded as a crucial mean of communication and interaction between humans and computers. To help computers automatically recognize human behaviors and accurately understand human intentions, this paper proposes a separable three-dimensional residual attention network (defined as Sep-3D RAN), which is a lightweight network and can extract the informative spatial-temporal representations for the applications of video-based human computer interaction. Specifically, Sep-3D RAN is constructed via stacking multiple separable three-dimensional residual attention blocks, in which each standard three-dimensional convolution is approximated as a cascaded two-dimensional spatial convolution and a one-dimensional temporal convolution, and then a dual attention mechanism is built by embedding a channel attention sub-module and a spatial attention sub-module sequentially in each residual block, thereby acquiring more discriminative features to improve the model guidance capability. Furthermore, a multi-stage training strategy is used for Sep-3D RAN training, which can relieve the over-fitting effectively. Finally, experimental results demonstrate that the performance of Sep-3D RAN can surpass the existing state-of-the-art methods.
C1 [Zhang, Zufan; Peng, Yue; Gan, Chenquan] Chongqing Univ Posts & Telecommun, Sch Commun & Informat Engn, Chongqing 400065, Peoples R China.
   [Abate, Andrea Francesco] Univ Salerno, Dept Comp Sci, Via Giovanni Paolo II 132, I-84084 Fisciano, SA, Italy.
   [Zhu, Lianxiang] Xian Shiyou Univ, Sch Comp Sci, Xian 710065, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; University of
   Salerno; Xi'an Shiyou University
RP Gan, CQ (corresponding author), Chongqing Univ Posts & Telecommun, Sch Commun & Informat Engn, Chongqing 400065, Peoples R China.
EM zhangzf@cqupt.edu.cn; 1056287792@qq.com; gcq2010cqu@163.com;
   abate@unisa.it; 115077078@qq.com
OI Gan, Chenquan/0000-0002-0453-5630
FU Natural Science Foundation of China [61702066, 61903056]; Major Project
   of Science and Technology Research Program of Chongqing Education
   Commission of China [KJZDM201900601]; Chongqing Research Program of
   Basic Research and Frontier Technology [cstc2021jcyj-msxmX0761,
   cstc2018jcyjAX0154]; Chongqing Municipal Key Laboratory of Institutions
   of Higher Education; Chongqing Key Laboratory of Mobile Communications
   Technology; Engineering Research Center of Mobile Communications,
   Ministry of Education [cqupt-mct202006]
FX The authors are grateful to the anonymous reviewers and the editor for
   their valuable comments and suggestions. This work is supported by
   Natural Science Foundation of China (Grant Nos. 61702066 and 61903056),
   Major Project of Science and Technology Research Program of Chongqing
   Education Commission of China (Grant No. KJZDM201900601), Chongqing
   Research Program of Basic Research and Frontier Technology (Grant Nos.
   cstc2021jcyj-msxmX0761 and cstc2018jcyjAX0154), Project Supported by
   Chongqing Municipal Key Laboratory of Institutions of Higher Education
   (Grant No. cqupt-mct-201901), Project Supported by Chongqing Key
   Laboratory of Mobile Communications Technology (Grant No.
   cqupt-mct-202002), Project Supported by Engineering Research Center of
   Mobile Communications, Ministry of Education (Grant No.
   cqupt-mct202006).
CR [Anonymous], 2020, IEEE INT SYMP CIRC S, DOI [DOI 10.1109/iscas45731.2020.9180667, DOI 10.1109/JIOT.2020.2982699.]
   Atto AM, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107353
   Bassano C, 2018, VISIGRAPP 2018: PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 2: HUCAPP, P108, DOI 10.5220/0006622701080115
   Cai JH, 2020, VISUAL COMPUT, V36, P1261, DOI 10.1007/s00371-019-01733-3
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Castiglione A, 2021, IEEE T IND INFORM, V17, P6162, DOI 10.1109/TII.2020.3026013
   Castiglione A, 2021, IEEE T IND INFORM, V17, P766, DOI 10.1109/TII.2020.2977774
   Chenarlogh VA, 2019, IET COMPUT VIS, V13, P338, DOI 10.1049/iet-cvi.2018.5088
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gu Y, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.10.004
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jin T, 2019, CONFERENCE PROCEEDINGS OF 2019 5TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P550, DOI [10.1109/iccar.2019.8813408, 10.1109/ICCAR.2019.8813408]
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W., 2017, ARXIV170506950
   Li Q, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P159, DOI 10.1145/2911996.2912001
   Lin B, 2019, NEUROCOMPUTING, V348, P145, DOI 10.1016/j.neucom.2018.05.121
   Liu QL, 2019, IEEE ACCESS, V7, P82246, DOI 10.1109/ACCESS.2019.2923651
   Meng LL, 2019, IEEE INT CONF COMP V, P1513, DOI 10.1109/ICCVW.2019.00189
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Ren FJ, 2020, INT J INF TECH DECIS, V19, P5, DOI 10.1142/S0219622019300052
   Sajjad M, 2019, PATTERN RECOGN LETT, V126, P123, DOI 10.1016/j.patrec.2018.02.015
   Sang HF, 2019, IEEE ACCESS, V7, P118388, DOI 10.1109/ACCESS.2019.2936628
   Sheng BY, 2020, NEUROCOMPUTING, V399, P65, DOI 10.1016/j.neucom.2020.02.096
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Sun SY, 2018, PROC CVPR IEEE, P1390, DOI 10.1109/CVPR.2018.00151
   Tran D, 2019, IEEE I CONF COMP VIS, P5551, DOI 10.1109/ICCV.2019.00565
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Tran Du, 2017, ARXIV170805038
   Wang L, 2018, IEEE ACCESS, V6, P17913, DOI 10.1109/ACCESS.2018.2817253
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang XK, 2021, IEEE T IND INFORM, V17, P2231, DOI 10.1109/TII.2020.2999901
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Xianyuan Wang, 2019, IOP Conference Series: Materials Science and Engineering, V569, DOI 10.1088/1757-899X/569/3/032035
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Yang H, 2019, PATTERN RECOGN, V85, P1, DOI 10.1016/j.patcog.2018.07.028
   Yanyi Zhang, 2019, 2019 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA), P216, DOI 10.1109/ICAICA.2019.8873471
   Yi Y, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115640
   Yu S, 2020, IEEE ACCESS, V8, P1840, DOI 10.1109/ACCESS.2019.2962284
   Yu TZ, 2018, PATTERN RECOGN LETT, V112, P226, DOI 10.1016/j.patrec.2018.07.034
   Zhang ZF, 2020, NEUROCOMPUTING, V410, P304, DOI 10.1016/j.neucom.2020.06.032
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
NR 46
TC 0
Z9 0
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5435
EP 5453
DI 10.1007/s11042-022-12972-3
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000781124000015
DA 2024-07-18
ER

PT J
AU Torres-Muñoz, D
   Hernández-Mejía, C
   Maldonado-Mendez, C
   Hernández-Mendez, S
AF Torres-Munoz, Delia
   Hernandez-Mejia, Carlos
   Maldonado-Mendez, Carolina
   Hernandez-Mendez, Sergio
TI Exploring a novel facial animation technique using numerical traced
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial animation; Homotopy; Numerical traced algorithm; Deformation
   image
ID EXPRESSION
AB Facial animation is a fundamental challenge that requires mathematical and computational strategies. In this paper, a novel facial animation technique using numerical traced algorithm is introduced. Homotpy-based animation methodology (HAM) uses the homotopy curve path in order to novelty generate intermediate frames for different lambda values and therefore it represents the deformations from starting image to ending image. These deformations use system of equations embedded into a single homotopy equation in order to represent intermediate frames. Moreover, a hyperspherical tracking method establishes deformations with visually consistent and smooth changes. Experimental results reveal intermediate frames that can be interpreted as facial animation. Furthermore, histogram plots, homotopic trajectories, and pixel variation tables confirm that different pixel positions vary with different rates of change as the original image is transformed into the target image. Besides, these frames do not need external filters in order to correct visual interpretation errors and therefore the homotopy-based animation method can be considered as a useful alternative for animating facial images in different applications.
C1 [Torres-Munoz, Delia] Inst Tecnol Super San Martin Texmelucan, Puebla, Mexico.
   [Hernandez-Mejia, Carlos] Inst Tecnol Super Misantla, Ciencias Ingn, Misantla, Ver, Mexico.
   [Maldonado-Mendez, Carolina; Hernandez-Mendez, Sergio] Univ Veracruzana, Artificial Intelligence Res Inst, Xalapa, Ver, Mexico.
C3 Universidad Veracruzana
RP Torres-Muñoz, D (corresponding author), Inst Tecnol Super San Martin Texmelucan, Puebla, Mexico.
EM deletsm@gmail.com; cmahernandez@gmail.com;
   carolinamaldonadomendez@gmail.com; sergihernandez@uv.mx
RI Hernández Mejía, Carlos Manuel/JAX-9935-2023
OI Hernández Mejía, Carlos Manuel/0000-0003-2481-8723; Torres-Munoz,
   Delia/0000-0001-8385-7592
CR Ahn S, 2005, IEEE SYS MAN CYBERN, P3112
   Allgower E.L., 1994, Numerical Path Following
   [Anonymous], 2008, Computer Facial Animation
   Arai K, 1996, VISUAL COMPUT, V12, P105
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Dong LF, 2011, 2011 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND CONTROL (ICECC), P2648, DOI 10.1109/ICECC.2011.6066515
   Getreuer P, 2011, IMAGE PROCESS ON LIN, V1, P238, DOI 10.5201/ipol.2011.g_Imii
   Gonzalez-Franco M, 2020, IEEE T VIS COMPUT GR, V26, P2023, DOI 10.1109/TVCG.2020.2973075
   Kang L, 2006, 2006 IEEE INT C AC S, pV
   Kouadio C, 1998, COMP ANIM CONF PROC, P128, DOI 10.1109/CA.1998.681917
   LEE Y, 1995, COMPUTER GRAPHICS, P55
   Liu K, 2006, 2006 IEEE INT C AC S
   Mahajan D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531348
   Melek Z, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P623, DOI 10.1109/ICME.2000.871440
   Obaid Mohammad, 2010, Proceedings of the 2010 Seventh International Conference on Computer Graphics, Imaging and Visualization (CGIV 2010), P9, DOI 10.1109/CGIV.2010.11
   Obaid M, 2010, 7 INT C COMP GRAPH I
   Patel Narendra, 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P203, DOI 10.1109/ICCSP.2011.5739301
   PATEL NM, 2010, J COMPUT APPL, V3, P34, DOI DOI 10.5120/719-1011
   Pighin F., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P143, DOI 10.1109/ICCV.1999.791210
   Reed K, 2019, COMPUT GRAPH FORUM, V38, P165, DOI 10.1111/cgf.13612
   Sheffer A, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000011
   SHIQIANG R, 2016, 15 INT S PARALLEL DI, P372
   Tang Y, 2010, 2010 INT C ED INF TE
   Torres D, 2014, COMPUT APPL MATH
   Torres-Mu??oz D., 2016, INT J APPL COMPUT MA, V2, P421, DOI DOI 10.1007/S40819-015-0067-1
   YAMAMURA K, 1993, IEEE T CIRCUITS-I, V40, P537, DOI 10.1109/81.242328
   Yi Z, 2020, P 28 ACM INT C MULT
   Zhang YM, 2008, IEEE T CIRC SYST VID, V18, P1383, DOI 10.1109/TCSVT.2008.928887
NR 29
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30961
EP 30976
DI 10.1007/s11042-022-12944-7
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779229700010
DA 2024-07-18
ER

PT J
AU Chazhoor, A
   Sarobin, VR
AF Chazhoor, Anisha
   Sarobin, Vergin Raja
TI Intelligent automation of invoice parsing using computer vision
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document parsing; Computer vision; Object detection; Transfer learning;
   Optical character recognition; Region-based convolutional neural network
AB Manual parsing of invoices is a tedious, arduous and error-prone task. Due to the academic and business importance of this problem, it has attracted the attention of machine learning enthusiasts. There are several complexities and challenges in the automated parsing of invoices. Some of them include a paucity of useful datasets, eclectic template formats, and poor performance of algorithms in real life scenarios. This problem can be solved by the automatic traversal of the invoices by object detection algorithms such as YOLO, SSD and R-CNN. These state-of-the-art algorithms will be trained to detect various fields or entities present in an invoice. In this paper, a dataset of 315 invoices has been generated using web testing tools. The dataset has been annotated for eight entities: billing address, shipping address, invoice date, invoice number, product name, price, quantity, and total amount. The text boxes detected by the models is converted to machine encoded text, using text extraction methods such as Optical Character Recognition (OCR). Hyperparameter tuning has been performed to improve model accuracy. The models have been evaluated on myriad metrics such as mean Average Precision (mAP), common objects in context (COCO) evaluation metrics and total loss during training and validation. The loss vs iteration graph has been visualized using Tensorboard. A front-end application encapsulates all the functions of the research paper and allows testing of various models.
C1 [Chazhoor, Anisha; Sarobin, Vergin Raja] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Sarobin, VR (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM verginraja.m@vit.ac.in
CR Aslan E, 2015, SIG PROCESS COMMUN, P1130, DOI 10.1109/SIU.2015.7130034
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chen ZG, 2019, IEEE ACCESS, V7, P80622, DOI 10.1109/ACCESS.2019.2923016
   Conway A., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P761, DOI 10.1109/ICDAR.1993.395626
   Du Y, 2020, CHIN CONTR CONF, P7294, DOI [10.23919/ccc50068.2020.9188731, 10.23919/CCC50068.2020.9188731]
   Fuyan Lin, 2020, 2020 IEEE International Conference on Advances in Electrical Engineering and Computer Applications (AEECA), P522, DOI 10.1109/AEECA49918.2020.9213538
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guo He, 2019, 2019 INT C DOCUMENT, P254, DOI 10.1109/ICDAR.2019.00049
   Kanimozhi S., 2019, 2019 2 INT C COMP, P1, DOI 10.1109/ICCIDS.2019.8862041
   Li ZS, 2019, CHIN AUTOM CONGR, P2701, DOI [10.1109/cac48633.2019.8996995, 10.1109/CAC48633.2019.8996995]
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu B, 2017, CHIN AUTOM CONGR, P6233, DOI 10.1109/CAC.2017.8243900
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2018, INT SYM COMPUT INTEL, P119, DOI 10.1109/ISCID.2018.10128
   Palm R. B., 2019, P 2019 INT C DOC AN, P329, DOI 10.1109/ICDAR.2019.00060
   Qianjun Shuai, 2020, 2020 International Conference on Culture-oriented Science & Technology (ICCST), P141, DOI 10.1109/ICCST50977.2020.00033
   Redmon J., 2018, COMPUTER VISION PATT
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saini Rajkumar, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1499, DOI 10.1109/ICDAR.2019.00241
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Takasu A., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P239, DOI 10.1109/ICDAR.1995.598985
   Wang Q, 2020, IEEE T PATTERN ANAL, V42, P46, DOI 10.1109/TPAMI.2018.2875002
   Wang Q, 2020, I C NETWORK PROTOCOL, DOI 10.1109/icnp49622.2020.9259369
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yilun Huang, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P813, DOI 10.1109/ICDAR.2019.00135
NR 27
TC 8
Z9 8
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29383
EP 29403
DI 10.1007/s11042-022-12916-x
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000778057700007
DA 2024-07-18
ER

PT J
AU Ibrahim, NM
   Gabr, DGI
   Rahman, AU
   Dash, S
   Nayyar, A
AF Ibrahim, Nehad M.
   Gabr, Dalia Goda Ibrahim
   Rahman, Atta-ur
   Dash, Sujata
   Nayyar, Anand
TI A deep learning approach to intelligent fruit identification and family
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fruits identification; Plants classification; Deep learning; Convolution
   neural network; Image analysis; fruit and plant families
ID PLANT CLASSIFICATION; RECOGNITION; SIMULATION; FRAMEWORK; SYSTEM
AB The deep learning techniques have been playing an important role in the identification and classification problems such as diseases in medical science, marketing in the industry, manufacturing in engineering, and identification in plant taxonomy science. Fruit identification and its family classification is among one of the areas that needs more emphasis for the sake of automation. With this inspiration, fruit images for 52 species belonging to four different families (Apiaceae, Brassicaceae, Asteraceae, and Apocynaceae) have been used in this study to build a deep learning analysis dataset. Further, the dataset has been augmented to 3800 images, divided to 2660 images for training and 1440 for testing, and different 14 fruit images belonging to the same families have been used for prediction of the testing module. A novel Convolution Neural Network (CNN) model architecture has been proposed to extract the fruit features, classify each image with its family, and use the trained model to predict that the new fruits belong to the same four families. The maximum accuracy obtained for the training and testing module was 99.82%. The prediction for this module succeeded by 93% since all fruits' success predicted was attained except one from the family number 2 (Brassicaceae). The same dataset was applied to two different models to evaluate our proposed model, the Deep learning model, aka Residual Neural Network, 20 layers (ResNet-20), and Support Vector Machine (SVM). The proposed CNN model achieved higher accuracy and efficiency than the ResNet-20 and SVM.
C1 [Ibrahim, Nehad M.; Rahman, Atta-ur] Imam Abdulrahman Bin Faisal Univ IAU, Coll Comp Sci & Informat Technol CCSIT, Dept Comp Sci CS, POB 1982, Dammam 31441, Saudi Arabia.
   [Gabr, Dalia Goda Ibrahim] Imam Abdulrahman Bin Faisal Univ IAU, Coll Sci, Dept Biol, POB 1982, Dammam 31441, Saudi Arabia.
   [Dash, Sujata] North Orissa Univ, Dept Comp Applicat, Baripada 757003, Odisha, India.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
C3 Imam Abdulrahman Bin Faisal University; Imam Abdulrahman Bin Faisal
   University; Duy Tan University
RP Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
EM nmaibrahim@iau.edu.sa; dggabr@iau.edu.sa; aaurrahman@iau.edu.sa;
   sujata238dash@gmail.com; anandnayyar@duytan.edu.vn
RI Rahman, Atta ur/AAD-6541-2019; Nayyar, Anand/F-3732-2015; Ibrahim,
   Nehad/AAQ-7940-2021; Gabr, Dalia/GOP-2692-2022; Dash, Sujata/I-8220-2019
OI Rahman, Atta ur/0000-0001-6696-277X; Nayyar, Anand/0000-0002-9821-6146;
   Ibrahim, Nehad/0000-0002-7681-5594; Dash, Sujata/0000-0003-2649-7652;
   Gabr, Dalia/0000-0002-8603-6877
CR Ahmad M, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01943-x
   Alhaidari F, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02448-3
   Alotaibi SM, 2021, CMC-COMPUT MATER CON, V68, P149, DOI 10.32604/cmc.2021.015976
   Atta-ur-Rahman, 2021, CMC-COMPUT MATER CON, V69, P21, DOI 10.32604/cmc.2021.013453
   Atta-ur-Rahman, 2019, J CLOUD COMPUT-ADV S, V8, DOI 10.1186/s13677-019-0144-9
   Atta-ur-Rahman, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/3461382
   Atta-ur-Rahman Dash S, 2017, International Journal of Control Theory and Applications, V10, P95
   Biswas S, 2019, COMM COM INF SC, V955, P540, DOI 10.1007/978-981-13-3140-4_49
   Boulent J, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00941
   Dash S., 2016, Int J Hybrid Intell Syst, V13, P77, DOI DOI 10.3233/HIS-160226
   Dash S., 2016, INT J KNOWLEDGE DISC, V6, P1, DOI DOI 10.4018/IJKDB.2016010101
   Dash S, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147719895210
   Dash S, 2019, INT J SWARM INTELL R, V10, P1, DOI 10.4018/IJSIR.2019040101
   Dash S, 2019, SCALABLE COMPUT-PRAC, V20, P191, DOI 10.12694/scpe.v20i2.1504
   Dileep MR, 2019, TENCON IEEE REGION, P321, DOI [10.1109/TENCON.2019.8929394, 10.1109/tencon.2019.8929394]
   Grillo O, 2017, COMPUT ELECTRON AGR, V141, P223, DOI 10.1016/j.compag.2017.07.024
   Gyires-Tóth BP, 2019, CYBERN INF TECHNOL, V19, P88, DOI 10.2478/cait-2019-0005
   Haupt J., 2018, CEUR Workshop Proc, V2125, P1
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hossain MS, 2019, IEEE T IND INFORM, V15, P1027, DOI 10.1109/TII.2018.2875149
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jana B.K., 2012, Indian Journal of Fundamental and Applied Life Sciences, V2, P51
   Johannes A, 2017, COMPUT ELECTRON AGR, V138, P200, DOI 10.1016/j.compag.2017.04.013
   Kaya A, 2019, COMPUT ELECTRON AGR, V158, P20, DOI 10.1016/j.compag.2019.01.041
   Khan MA, 2020, CMC-COMPUT MATER CON, V65, P139, DOI 10.32604/cmc.2020.011416
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le, 2015, P WORK NOT CLEF 2015
   Lee JW, 2019, 2019 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P17
   Mahmud M, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105818
   Naseem MT, 2020, NEURAL NETW WORLD, V30, P177, DOI 10.14311/NNW.2020.30.013
   Panda M, 2019, CCIS, V955, P1, DOI [10.1007/978-981-13-3140-4, DOI 10.1007/978-981-13-3140-4]
   Patra BN., 2016, INT J LATEST TRENDS, V7, P8, DOI [10.21172/1.72.502, DOI 10.21172/1.72.502]
   Picon A, 2019, COMPUT ELECTRON AGR, V161, P280, DOI 10.1016/j.compag.2018.04.002
   Rahman A, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02174-w
   Rahman A, 2019, J INTELL FUZZY SYST, V37, P553, DOI 10.3233/JIFS-162405
   Rahman A, 2019, J INTELL FUZZY SYST, V37, P1545, DOI 10.3233/JIFS-18579
   Rahman AU, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/8137436
   Rahman AU, 2021, TELECOMMUN SYST, V76, P49, DOI 10.1007/s11235-020-00700-x
   Rehman A, 2020, J AMB INTEL SMART EN, V12, P125, DOI 10.3233/AIS-200554
   Reyes AK, 2015, P WORK NOT CLEF
   Sabzi Sajad, 2018, Information Processing in Agriculture, V5, P162, DOI 10.1016/j.inpa.2017.09.002
   Shi Y, 2022, IEEE T BIG DATA, V8, P377, DOI 10.1109/TBDATA.2020.2964169
   Singh R, 2020, EMERGING TECHNOLOGIE
   Sungbin C, 2015, P WORK NOT CLEF
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tan JW, 2020, IEEE ACM T COMPUT BI, V17, P82, DOI 10.1109/TCBB.2018.2848653
   Xiong ZT, 2021, IEEE T IMAGE PROCESS, V30, P2722, DOI 10.1109/TIP.2021.3053459
   Zagrouba R, 2021, CMC-COMPUT MATER CON, V66, P2397, DOI 10.32604/cmc.2021.014042
   Zaman G, 2021, IEEE ACCESS, V9, P42111, DOI 10.1109/ACCESS.2021.3063181
   Zhang C, 2021, NEUROCOMPUTING, V449, P189, DOI 10.1016/j.neucom.2021.03.103
   Zhang HX, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P25, DOI 10.1109/MIPR.2018.00013
   Zheng Y, 2017, COMPUT ELECTRON AGR, V141, P215, DOI 10.1016/j.compag.2017.07.028
NR 53
TC 18
Z9 18
U1 6
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27783
EP 27798
DI 10.1007/s11042-022-12942-9
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000774644100011
DA 2024-07-18
ER

PT J
AU Liu, SG
   Liu, ZQ
AF Liu, Shiguang
   Liu, Ziqi
TI Style enhanced line drawings based on multi-feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Line drawing; Style; Free-hand; Multi-feature
AB Line drawing is a means of superior visual communication, which is made up of lines. Artists usually show their unique styles while creating a line drawing. However, traditional methods can not effectively simulate this free-hand style of artists. Though the data-driven method can generate abundant styles, it is complex and time-consuming. To this end, a new style enhanced line drawing method was proposed. First, lines in images were extracted based on edge detection and edge tracking methods. Then, the global drawing features were simulated, including length measurement, overlap measurement and offset measurement. Finally, the local drawing features that contain width measurement, sharpness measurement and depth measurement were simulated. The results showed that our method can generate stylized line drawings that are more similar to free-hand drawings of artists than the state-of-the-art methods.
C1 [Liu, Shiguang; Liu, Ziqi] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
C3 Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
EM lsg@tju.edu.cn
CR Ben-Zvi N, 2016, COMPUT GRAPH FORUM, V35, P18, DOI 10.1111/cgf.12729
   Berger I, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461964
   Chen C, 2016, INT CONF COMP SCI ED, P808, DOI 10.1109/ICCSE.2016.7581686
   Chen CH, 2013, IEEE INT WORKS GENET, P16, DOI 10.1109/GEFS.2013.6601050
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   Chi MT, 2006, IEEE T VIS COMPUT GR, V12, P61, DOI 10.1109/TVCG.2006.14
   Cole F, 2008, ACM T GRAPHIC, V27, DOI [10.1145/1360612.1360657, 10.1145/1360612.1360687]
   DeCarlo D, 2002, ACM T GRAPHIC, V21, P769, DOI 10.1145/566570.566650
   Fischer B, 2003, IEEE T PATTERN ANAL, V25, P513, DOI 10.1109/TPAMI.2003.1190577
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Kang H, 2009, IEEE T VIS COMPUT GR, V15, P62, DOI 10.1109/TVCG.2008.81
   Kang HW, 2006, VISUAL COMPUT, V22, P814, DOI 10.1007/s00371-006-0066-7
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Li HR, 2021, MEMET COMPUT, V13, P1, DOI 10.1007/s12293-021-00328-7
   Li HR, 2020, SOFT COMPUT, V24, P6851, DOI 10.1007/s00500-019-04324-5
   Li M, 2021, IEEE T SERV COMPUT, V14, P1902, DOI 10.1109/TSC.2019.2903060
   Li RJ, 2011, COMPUTER, V44, P62, DOI 10.1109/MC.2011.160
   Li Y, 2017, INT J COMPUT VISION, V122, P169, DOI 10.1007/s11263-016-0963-9
   [梁波 Liang Bo], 2011, [中国图象图形学报, Journal of Image and Graphics], V16, P2074
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Luo, 2006, INT C COMP GRAPH IM, P514
   Luo T, 2011, INT J COMPUT VISION, V94, P23, DOI 10.1007/s11263-010-0394-y
   Matsui Y, 2017, IEEE T VIS COMPUT GR, V23, P1852, DOI 10.1109/TVCG.2016.2554113
   Minear M, 2004, BEHAV RES METH INS C, V36, P630, DOI 10.3758/BF03206543
   Orzan A, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P103
   Saito S, 2008, VISUAL COMPUT, V24, P1, DOI 10.1007/s00371-007-0165-0
   Sheng B, 2019, IEEE T VIS COMPUT GR, V25, P3216, DOI 10.1109/TVCG.2018.2866090
   Son MJ, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P333, DOI 10.1109/PG.2007.63
   Song YB, 2014, LECT NOTES COMPUT SC, V8694, P800, DOI 10.1007/978-3-319-10599-4_51
   Tang F, 2018, IEEE T VIS COMPUT GR, V24, P3019, DOI 10.1109/TVCG.2017.2774292
   Wang NN, 2017, SIGNAL PROCESS, V130, P1, DOI 10.1016/j.sigpro.2016.06.014
   Wang SD, 2012, COMPUT GRAPH-UK, V36, P224, DOI 10.1016/j.cag.2012.02.011
   Wong FJ, 2013, VISUAL COMPUT, V29, P729, DOI 10.1007/s00371-013-0809-1
   Wu YT, 2017, J IMAGING, V3, DOI 10.3390/jimaging3020016
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yan CR, 2008, IEEE T VIS COMPUT GR, V14, P468, DOI 10.1109/TVCG.2007.70440
   Zhang Y, 2017, IEEE T IMAGE PROCESS, V26, P464, DOI 10.1109/TIP.2016.2628581
   Zhao JX, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P466, DOI 10.1109/CISP.2008.250
   Zhou J, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1027
NR 42
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26121
EP 26141
DI 10.1007/s11042-022-12727-0
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000773206100014
DA 2024-07-18
ER

PT J
AU Magdy, M
   Hosny, KM
   Ghali, NI
   Ghoniemy, S
AF Magdy, Mahmoud
   Hosny, Khalid M.
   Ghali, Neveen, I
   Ghoniemy, Said
TI Security of medical images for telemedicine: a systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Medical images; Watermarking; Steganography; Cryptography; Attacks;
   Copyright
ID SVD-BASED ROBUST; WATERMARKING SCHEME; SYMMETRIC CRYPTOGRAPHY;
   ENCRYPTION ALGORITHM; QUALITY ASSESSMENT; STEGANOGRAPHY; INFORMATION;
   DOMAIN; OPTIMIZATION; BLIND
AB Recently, there has been a rapid growth in the utilization of medical images in telemedicine applications. The authors in this paper presented a detailed discussion of different types of medical images and the attacks that may affect medical image transmission. This survey paper summarizes existing medical data security approaches and the different challenges associated with them. An in-depth overview of security techniques, such as cryptography, steganography, and watermarking are introduced with a full survey of recent research. The objective of the paper is to summarize and assess the different algorithms of each approach based on different parameters such as PSNR, MSE, BER, and NC.
C1 [Magdy, Mahmoud; Ghali, Neveen, I] Future Univ Egypt FUE, Dept Digital Media Technol, New Cairo, Egypt.
   [Hosny, Khalid M.] Zagazig Univ, Dept Informat Technol, Zagazig 44519, Egypt.
   [Ghoniemy, Said] Ain Shams Univ, Fac Comp & Informat Sci, Dept Comp Syst, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Future University in Egypt; Egyptian
   Knowledge Bank (EKB); Zagazig University; Egyptian Knowledge Bank (EKB);
   Ain Shams University
RP Hosny, KM (corresponding author), Zagazig Univ, Dept Informat Technol, Zagazig 44519, Egypt.
EM k_hosny@yahoo.com
RI Hosny, Khalid M./B-1404-2008
OI Hosny, Khalid M./0000-0001-8065-8977
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Abbas Fakhar., 2018, P IEEE INT C COMM WO, P1
   Abdel-Aziz MM, 2021, MULTIMED TOOLS APPL, V80, P12641, DOI 10.1007/s11042-020-10217-9
   Abdulhammed OY., 2021, INT J COMPUT, V20, P129, DOI DOI 10.47839/IJC.20.1.2101
   Abdulla A. A., 2015, Ph.D. dissertation
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Afandi TMK., 2021, INT SEMINAR INTELLIG, P1
   Agaian, 2016, INT J CRYPTOGR INF S, V6, P01
   Ahlem A., 2019, CELLULAR IMAGING BIO
   Al-Dmour H, 2016, COMPUT METH PROG BIO, V127, P24, DOI 10.1016/j.cmpb.2016.01.011
   Al-qdah M., 2018, SIGNAL IMAGE PROCESS, DOI 10.5121/sipij.2018.9101
   Al-Qershi OM, 2014, AEU-INT J ELECTRON C, V68, P346, DOI 10.1016/j.aeue.2013.09.008
   Alam S, 2017, ADV INTELL SYST, V516, P467, DOI 10.1007/978-981-10-3156-4_48
   Ali M., 2019, Int J Adv Res Comput Sci, V10, P9, DOI [10.26483/ijarcs.v10i1.6350, DOI 10.26483/IJARCS.V10I1.6350]
   Altaay AAJ, 2012, INT CONF ADV COMPUT, P122, DOI 10.1109/ACSAT.2012.25
   Alzahrani A, 2021, IEEE ACCESS, V9, P113714, DOI 10.1109/ACCESS.2021.3104985
   Anand A, 2021, MULTIMED TOOLS APPL, V80, P30165, DOI 10.1007/s11042-020-08801-0
   [Anonymous], 2018, SURVEILLANCE ACTION
   Aouissaoui I, 2021, IET IMAGE PROCESS, V15, P2770, DOI 10.1049/ipr2.12261
   Arunkumar S, 2019, MEASUREMENT, V139, P426, DOI 10.1016/j.measurement.2019.02.069
   Arunkumar S., 2018, INT J PURE APPL MATH, V119, P13233
   Ashour AS, 2017, STUD COMPUT INTELL, V660, P3, DOI 10.1007/978-3-319-44790-2_1
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Atee HA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0170329
   Bachrach M., 2017, WATERMARKING STEGANO, V2, P201
   Balasamy K, 2021, MULTIMED TOOLS APPL, V80, P7167, DOI 10.1007/s11042-020-09981-5
   Balasubramanian C, 2014, MULTIMED TOOLS APPL, V73, P2223, DOI 10.1007/s11042-013-1640-4
   Bamal R, 2019, MULTIMED TOOLS APPL, V78, P17899, DOI 10.1007/s11042-018-6820-9
   Banerjee Shubhendu, 2015, International Journal of Image, Graphics and Signal Processing, V7, P1, DOI 10.5815/ijigsp.2015.03.01
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Begum AAS, 2018, MULTIMED TOOLS APPL, V77, P27041, DOI 10.1007/s11042-018-5903-y
   Begum M, 2020, INFORMATION, V11, DOI 10.3390/info11020110
   Benssalah M, 2021, MULTIMED TOOLS APPL, V80, P2081, DOI 10.1007/s11042-020-09775-9
   Bhabatosh C, 1977, DIGITAL IMAGE PROCES, P469
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P7973, DOI 10.1007/s11042-016-3449-4
   Chandel G. S., 2013, International Journal of Advanced Research in Computer Science and Software Engineering, V3, P434
   Chandel R., 2013, International Journal of Advanced Research in Computer Science and Software Engineering, V3
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P12647, DOI 10.1007/s11042-017-5348-8
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Chen YP., 2021, ELECTRON, V10, P1
   Chirakkarottu S, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1685-8
   Conde JG, 2010, TELEMED J E-HEALTH, V16, P103, DOI 10.1089/tmj.2009.0152
   Dhawan S, 2021, INF SECUR J, V30, P63, DOI 10.1080/19393555.2020.1801911
   Du JX, 2006, NEUROCOMPUTING, V70, P592, DOI 10.1016/j.neucom.2006.05.003
   El-Shafai W, 2021, J AMB INTEL HUM COMP, V12, P9007, DOI 10.1007/s12652-020-02597-5
   Elbasi E, 2020, 2020 43RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P506, DOI [10.1109/tsp49548.2020.9163558, 10.1109/TSP49548.2020.9163558]
   Eze P, 2020, IEEE ENG MED BIO, P6119, DOI 10.1109/EMBC44109.2020.9176066
   Eze P, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P53, DOI 10.1145/3323873.3325020
   Eze PU., 2018, World Academy of Sci EngTechnol Int J Comput Electr Autom Control Inf Eng, V12, P107
   Fares K, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102403
   Fotopoulos V, 2008, IEEE INT C BIOINF BI, P910
   Gan DSHY., 2010, ADV INTELLIGENT COMP, P490
   Gao L, 2020, J INF TECHNOL RES, V13, P75, DOI 10.4018/JITR.2020100106
   Golea Nour El-Houda, 2019, International Journal of High Performance Computing and Networking, V13, P199
   Grajeda-Marín IR, 2016, LECT NOTES COMPUT SC, V9703, P125, DOI 10.1007/978-3-319-39393-3_13
   Guesmi R, 2021, MULTIMED TOOLS APPL, V80, P1925, DOI 10.1007/s11042-020-09672-1
   Gupta S., 2019, SURVEY REVERSIBLE WA, P826
   Hajduk V, 2017, 2017 27TH INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA), P178
   Hamid N., 2012, 2012 International Conference on Future Communication Networks (ICFCN), P141, DOI 10.1109/ICFCN.2012.6206858
   Hamza A., 2021, KSII T INTERNET INFO
   Hamza R, 2020, INFORM SCIENCES, V527, P493, DOI 10.1016/j.ins.2019.01.070
   Harshitha M., 2021, 7 INT C ADV COMP COM
   Hizukuri A, 2021, J DIGIT IMAGING, V34, P116, DOI 10.1007/s10278-020-00394-2
   Hong W, 2012, SIGNAL PROCESS-IMAGE, V27, P1123, DOI 10.1016/j.image.2012.09.002
   Hosny KM, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103007
   Hosny KM, 2021, IEEE ACCESS, V9, P47425, DOI 10.1109/ACCESS.2021.3068211
   Hosny KM, 2018, IEEE ACCESS, V6, P77212, DOI 10.1109/ACCESS.2018.2879919
   Huang DS, 2008, IEEE T NEURAL NETWOR, V19, P2099, DOI 10.1109/TNN.2008.2004370
   Huma F., 2021, P INT JOINT C ADV CO, P89
   Iskandar MW, 2019, J PHYS CONF SER, V1192, DOI 10.1088/1742-6596/1192/1/012008
   Jain M., 2018, INT J APPL ENG RES, V13, P12353
   Jain M, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P291, DOI 10.1109/IC3I.2016.7917977
   Jain Mamta, 2017, Brain Inform, V4, P95, DOI 10.1007/s40708-016-0057-z
   Jambhale T., 2021, P ICICI 2020 2021 SI
   Janani T, 2021, J INF SECUR APPL, V59, DOI 10.1016/j.jisa.2021.102832
   Jeevitha S, 2020, HEALTH TECHNOL-GER, V10, P217, DOI 10.1007/s12553-018-00285-1
   Jia SL, 2017, J APPL SCI ENG, V20, P193, DOI 10.6180/jase.2017.20.2.07
   Kabbai L, 2017, IET IMAGE PROCESS, V11, P109, DOI 10.1049/iet-ipr.2016.0349
   Kadhim IJ, 2020, COGN SYST RES, V60, P20, DOI 10.1016/j.cogsys.2019.11.002
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Kahlessenane F, 2021, J AMB INTEL HUM COMP, V12, P2931, DOI 10.1007/s12652-020-02450-9
   Kamal ST, 2021, IEEE ACCESS, V9, P37855, DOI 10.1109/ACCESS.2021.3063237
   Karar ME, 2021, COMPLEX INTELL SYST, V7, P235, DOI 10.1007/s40747-020-00199-4
   Karthik JV, 2014, INT J COMPUT SCI NET, V14, P58
   Kaur J., 2018, INT C EN COMM DAT AN, P3194
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Kelkar Vishakha, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P131, DOI 10.1007/978-981-10-7895-8_11
   Khan M, 2014, 3D RES, V5, DOI 10.1007/s13319-014-0016-5
   Khan S., 2018, Int J Electric Comput Eng (IJECE), V8, P379, DOI [10.11591/ijece.v8i1.pp379-389, DOI 10.11591/IJECE.V8I1.PP379-389]
   Konyar MZ, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12060899
   Kumar S, 2019, MED BIOL ENG COMPUT, V57, P2517, DOI 10.1007/s11517-019-02037-3
   Laiphrakpam DS, 2017, OPTIK, V147, P88, DOI 10.1016/j.ijleo.2017.08.028
   Laishram D., 2018, P 3 INT C INT THINGS, P26
   Li J, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01328-2
   Li XW, 2015, OPT LASER ENG, V66, P112, DOI 10.1016/j.optlaseng.2014.08.016
   Li XW, 2018, OPT LASER ENG, V100, P200, DOI 10.1016/j.optlaseng.2017.08.018
   Li YZ, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P904, DOI 10.1109/ISECS.2008.83
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Licks V, 2005, IEEE MULTIMEDIA, V12, P68, DOI 10.1109/MMUL.2005.46
   Lin CH, 2021, IEEE ACCESS, V9, P118624, DOI 10.1109/ACCESS.2021.3107608
   Lin CY, 2001, IEEE T CIRC SYST VID, V11, P153, DOI 10.1109/76.905982
   Liu J, 2020, IEEE ACCESS, V8, P93939, DOI 10.1109/ACCESS.2020.2995015
   Liu XY, 2018, PROC SPIE, V10579, DOI 10.1117/12.2292852
   Luo T, 2018, MULTIMED TOOLS APPL, V77, P19027, DOI 10.1007/s11042-017-5356-8
   Ma B, 2021, J MATH IMAGING VIS, V63, P1160, DOI 10.1007/s10851-021-01048-w
   Maheswari SU, 2017, MULTIMED TOOLS APPL, V76, P415, DOI 10.1007/s11042-015-3035-1
   Martiri E., 2011, Proceedings of the 2011 Third International Conference on Intelligent Networking and Collaborative Systems (INCoS 2011), P408, DOI 10.1109/INCoS.2011.149
   Mata-Mendoza D, 2022, VISUAL COMPUT, V38, P2073, DOI 10.1007/s00371-021-02267-3
   Mathkour H, 2008, I C WIREL COMM NETW, P12526
   Meryem B, 2018, 9TH INTERNATIONAL SYMPOSIUM ON SIGNAL, IMAGE, VIDEO AND COMMUNICATIONS (ISIVC 2018), P157, DOI 10.1109/ISIVC.2018.8709240
   Miri A, 2017, OPTIK, V145, P158, DOI 10.1016/j.ijleo.2017.07.043
   Mishra P, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03410-7
   Mohammed ZF, 2021, MULTIMED TOOLS APPL, V80, P6355, DOI 10.1007/s11042-020-10066-6
   Mohanarathinam A, 2020, J AMB INTEL HUM COMP, V11, P3221, DOI 10.1007/s12652-019-01500-1
   Mondal J, 2020, INT J ELECTRON SECUR, V12, P1, DOI 10.1504/IJESDF.2020.103869
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Mungmode S, 2016, PROCEDIA COMPUT SCI, V79, P912, DOI 10.1016/j.procs.2016.03.114
   Nagaraj S, 2015, PROCEDIA COMPUT SCI, V48, P276, DOI 10.1016/j.procs.2015.04.182
   Naidu CD, 2014, ARPN J ENG APPL SCI, V9
   Nazari M, 2021, MULTIMED TOOLS APPL, V80, P10615, DOI 10.1007/s11042-020-10032-2
   Novamizanti L., 2020, Int. J. Intell. Eng. Syst., V13, P266
   Özkaynak F, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P621, DOI 10.1109/UBMK.2017.8093481
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Priya S, 2021, MOBILE NETW APPL, V26, P2501, DOI 10.1007/s11036-019-01213-x
   Priyadharshini A., 2021, Proceedings of the 2021 First International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT), DOI 10.1109/ICAECT49130.2021.9392396
   Qi G, 2021, ARXIV PREPRINT ARXIV
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P6473, DOI 10.1007/s11042-016-3301-x
   Raja SP, 2019, INT J WAVELETS MULTI, V17, DOI 10.1142/S0219691319500346
   Rajendran S., 2021, IOP C SERIES MAT SCI, V1022, DOI DOI 10.1088/1757-899X/1022/1/012106
   Ran QW, 2015, OPT COMMUN, V348, P43, DOI 10.1016/j.optcom.2015.03.016
   Ravichandran D, 2021, MED BIOL ENG COMPUT, V59, P589, DOI 10.1007/s11517-021-02328-8
   Reddy PR., 2009, INT J COMPUTER ELECT, V1, P111
   Renukalatha S., 2017, ICTACT Journal on Image and Video Processing, V7, P1505, DOI 10.21917/ijivp.2017.0215
   Reshma VK, 2021, COMPUT J, V64, P731, DOI 10.1093/comjnl/bxaa017
   Rocek A, 2021, J DIGIT IMAGING, V34, P204, DOI 10.1007/s10278-020-00396-0
   Sadek E., 2020, Int. J. Intell. Comput. Inf. Sci, V20, P89, DOI DOI 10.21608/IJICIS.2020.46360.1034
   Sahoo Satyasangram, 2020, 2020 3rd International Conference on Emerging Technologies in Computer Engineering: Machine Learning and Internet of Things (ICETCE). Proceedings, P1, DOI 10.1109/ICETCE48199.2020.9091744
   Sajadi S, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113639
   Salameh JNB, 2019, INT J COMPUT SCI NET, V19, P28
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Santhi B, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3356-1
   Santoso B, 2019, J PHYS CONF SER, V1175, DOI 10.1088/1742-6596/1175/1/012057
   Sathua SK., 2017, ARXIV PREPRINT ARXIV
   Seth D., 2010, INT J COMPUTER APPL, V9, P3
   Setiawaty D.A., 2019, ICSGS 2018, P1, DOI [10.4108/eai.24-10-2018.2289659, DOI 10.4108/EAI.24-10-2018.2289659]
   Shanthan BH., 2021, MED IMAGE DETECTION
   Sharma S, 2018, MOD PHYS LETT B, V32, DOI 10.1142/S0217984918502123
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Shen SY, 2015, MULTIMED TOOLS APPL, V74, P707, DOI 10.1007/s11042-014-2016-0
   Shen YX, 2021, OPT LASER TECHNOL, V138, DOI 10.1016/j.optlastec.2020.106911
   Singh Amit Kumar, 2018, Future Generation Computer Systems, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh AK, 2017, MULTIMED SYST APPL, P125, DOI 10.1007/978-3-319-57699-2_6
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh A, 2016, 2016 39TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P511, DOI 10.1109/TSP.2016.7760932
   Singh L, 2020, MULTIMED TOOLS APPL, V79, P15901, DOI 10.1007/s11042-018-6407-5
   Singh S, 2018, STUD BIG DATA, V33, P467, DOI 10.1007/978-3-319-63639-9_20
   Song CY, 2010, CONSUM COMM NETWORK, P807
   Soualmi A, 2021, MULTIMED TOOLS APPL, V80, P2279, DOI 10.1007/s11042-020-09614-x
   Soualmi A, 2018, ARAB J SCI ENG, V43, P7893, DOI 10.1007/s13369-018-3246-7
   Stoyanov B, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22050501
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Surekha B, 2011, INT J SECUR APPL, V5, P1
   Tan Y., 2018, LNCS, P11065
   Tan Y, 2018, LECT NOTES COMPUT SC, V11065, P458, DOI 10.1007/978-3-030-00012-7_42
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thakur S, 2020, MULTIMED TOOLS APPL, V79, P4263, DOI 10.1007/s11042-018-6691-0
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Thanki R, 2021, MULTIMED TOOLS APPL, V80, P4307, DOI 10.1007/s11042-020-09941-z
   Thanki R, 2017, IMAGING SCI J, V65, P457, DOI 10.1080/13682199.2017.1367129
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Tsai HH, 2007, INFORM SCIENCES, V177, P550, DOI 10.1016/j.ins.2006.05.002
   Nguyen TD, 2016, MULTIMED TOOLS APPL, V75, P8319, DOI 10.1007/s11042-015-2752-9
   Din SU, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9122013
   Ulutas G, 2017, J DIGIT IMAGING, V30, P695, DOI 10.1007/s10278-017-9961-x
   uzcan FBM., 2020, 28 SIGN PROC COMM AP
   Venkatraman S, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 2, PROCEEDINGS, P347
   Venugopal Reddy CH., 2015, SIGNAL IMAGE PROCESS, V6, P1
   Vijayakumar Ajay, 2021, 2021 2nd International Conference on Secure Cyber Computing and Communications (ICSCCC), P34, DOI 10.1109/ICSCCC51823.2021.9478113
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Rui W, 2020, IEEE ACCESS, V8, P182391, DOI 10.1109/ACCESS.2020.3004841
   Wang XY, 2015, OPT LASER ENG, V68, P126, DOI 10.1016/j.optlaseng.2014.12.025
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu J-X., 2020, IEEE ACCESS, V8
   Xu SP, 2017, IETE TECH REV, V34, P223, DOI 10.1080/02564602.2016.1151385
   Yahya A., 2019, STEGANOGRAPHY TECHNI
   Yang Y, 2018, MULTIMED TOOLS APPL, V77, P18043, DOI 10.1007/s11042-017-4444-0
   Yangxiu Fang, 2021, Innovation in Medicine and Healthcare. Proceedings of 9th KES-InMed 2021. Smart Innovation, Systems and Technologies (SIST 242), P61, DOI 10.1007/978-981-16-3013-2_6
   Yatish, 2018, OPT ENG, V57, DOI 10.1117/1.OE.57.3.033103
   Yin S., 2020, Int. J. Netw. Secur, V22, P419
   Yuanmin Xie, 2019, Journal of Physics: Conference Series, V1314, DOI 10.1088/1742-6596/1314/1/012161
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang Y, 2020, IEEE T CIRC SYST VID, V30, P2750, DOI 10.1109/TCSVT.2019.2923980
   Zhao WB, 2004, INT J PATTERN RECOGN, V18, P1473, DOI 10.1142/S0218001404003824
   Zheng BL, 2020, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR42600.2020.00369
NR 198
TC 26
Z9 26
U1 6
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25101
EP 25145
DI 10.1007/s11042-022-11956-7
EA MAR 2022
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882300018
PM 35342327
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Shishavan, ST
   Gharehchopogh, FS
AF Shishavan, Saeid Talebpour
   Gharehchopogh, Farhad Soleimanian
TI An improved cuckoo search optimization algorithm with genetic algorithm
   for community detection in complex networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cuckoo search optimization algorithm; Genetic algorithm; Community
   detection; Complex networks
ID MODEL; GA
AB This paper improved Cuckoo Search Optimization (CSO) algorithm with a Genetic Algorithm (GA) for community detection in complex networks. CSO algorithm has problems such as premature convergence, delayed convergence, and getting trapped in the local trap. GA has been quite successful in terms of community detection in complex networks to increase exploration and exploitation. GA operators have been used dynamically in order to increase the speed and accuracy of the CSO. The number of populations is dynamically adjusted based on the amount of exploration and exploitation. Modularity objective function (Q) and Normalized Mutual Information (NMI) is used as an optimization function. It was carried out on six types of real complex networks. The proposed algorithm was tested with GA, Artificial Bee Colony (ABC), Grey Wolf Optimizer (GWO), and CSO, with different iterations in modularity and NMI criteria. The results show that in most comparisons, the proposed algorithm has been more successful than the basic comparative algorithms, and it has proven its superiority in terms of modularity and NMI. The proposed algorithm performed an average of 54% better in modularity and 88% in NMI than other algorithms. It performed on average in modularity criteria 84.3%, 58.8%, 33.7% and 38.8%, respectively, compared to CSO, ABS, GWO and GA algorithms, and in terms of NMI index, 188.7%, 39.1%, 52.3% and 73.8%, respectively in CSO, ABS, GWO and GA algorithms performed better.
C1 [Shishavan, Saeid Talebpour; Gharehchopogh, Farhad Soleimanian] Islamic Azad Univ, Dept Comp Engn, Urmia Branch, Orumiyeh, Iran.
C3 Islamic Azad University
RP Gharehchopogh, FS (corresponding author), Islamic Azad Univ, Dept Comp Engn, Urmia Branch, Orumiyeh, Iran.
EM bonab.farhad@gmail.com
RI Gharehchopogh, Farhad Soleimanian/AAX-9598-2020
OI Gharehchopogh, Farhad Soleimanian/0000-0003-1588-1659
CR Abdollahzadeh B, 2022, ENG COMPUT-GERMANY, V38, P1845, DOI 10.1007/s00366-021-01369-9
   Adamic L.A., 2005, Proceedings of the 3rd International Workshop on Link Discovery, LinkKDD'05, P3643
   Bai L, 2018, KNOWL-BASED SYST, V143, P58, DOI 10.1016/j.knosys.2017.12.007
   Bai L, 2017, INFORM SCIENCES, V388, P37, DOI 10.1016/j.ins.2017.01.026
   Dilmaghani S., 2021, COMMUNITY DETECTION
   Dong S, 2020, COMPUTING, V102, P2185, DOI 10.1007/s00607-020-00836-3
   Gharehchopogh FS, 2020, ARTIF INTELL REV, V53, P2265, DOI 10.1007/s10462-019-09733-4
   Gharehchopogh FS, 2019, SWARM EVOL COMPUT, V48, P1, DOI 10.1016/j.swevo.2019.03.004
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Guendouz M, 2017, APPL INTELL, V46, P373, DOI 10.1007/s10489-016-0840-9
   Guerrero M, 2017, NEUROCOMPUTING, V266, P101, DOI 10.1016/j.neucom.2017.05.029
   Jin H, 2013, PHYSICA A, V392, P4606, DOI 10.1016/j.physa.2013.05.039
   Karaboga D, 2009, APPL MATH COMPUT, V214, P108, DOI 10.1016/j.amc.2009.03.090
   Kaur S, 2016, NEURAL NETW WORLD, V26, P625, DOI 10.14311/NNW.2016.26.036
   Kim P, 2017, PHYSICA A, V465, P525, DOI 10.1016/j.physa.2016.08.012
   Knuth D.E, 1993, The Stanford graph base: A platform for combinatorial computing, P577
   Li ZT, 2016, PHYSICA A, V449, P336, DOI 10.1016/j.physa.2015.12.126
   Lusseau D, 2003, BEHAV ECOL SOCIOBIOL, V54, P396, DOI 10.1007/s00265-003-0651-y
   Ma HP, 2021, NEURAL COMPUT APPL, V33, P5135, DOI 10.1007/s00521-020-05311-w
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Newman MEJ, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.036104
   Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113
   Pizzuti C, 2008, LECT NOTES COMPUT SC, V5199, P1081, DOI 10.1007/978-3-540-87700-4_107
   Rabani H., 2019, J Adv Comput Res, V10, P13
   Rahimi S, 2018, SWARM EVOL COMPUT, V39, P297, DOI 10.1016/j.swevo.2017.10.009
   Rahnema N, 2020, MULTIMED TOOLS APPL, V79, P32169, DOI 10.1007/s11042-020-09639-2
   Rajabioun R, 2011, APPL SOFT COMPUT, V11, P5508, DOI 10.1016/j.asoc.2011.05.008
   Ranjbar A, 2014, COMPUT COMMUN, V41, P11, DOI 10.1016/j.comcom.2014.01.002
   Said A, 2018, APPL SOFT COMPUT, V63, P59, DOI 10.1016/j.asoc.2017.11.014
   Sedghpour AS, 2017, PROCEEDINGS OF THE 2017 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE COMPANION (GECCO'17 COMPANION), P197, DOI 10.1145/3067695.3076000
   Sani NS, 2020, J AMB INTEL HUM COMP, V11, P5, DOI 10.1007/s12652-018-1159-7
   Shayanfar H, 2018, APPL SOFT COMPUT, V71, P728, DOI 10.1016/j.asoc.2018.07.033
   Shi C, 2012, APPL SOFT COMPUT, V12, P850, DOI 10.1016/j.asoc.2011.10.005
   Sun HL, 2018, FUTURE GENER COMP SY, V89, P265, DOI 10.1016/j.future.2018.05.071
   WHITLEY D, 1994, STAT COMPUT, V4, P65, DOI 10.1007/BF00175354
   ZACHARY WW, 1977, J ANTHROPOL RES, V33, P452, DOI 10.1086/jar.33.4.3629752
   Zhang WT, 2019, PHYSICA A, V515, P130, DOI 10.1016/j.physa.2018.09.186
   Zhou HF, 2018, DATA KNOWL ENG, V117, P183, DOI 10.1016/j.datak.2018.07.009
   Zhou HF, 2017, PHYSICA A, V469, P551, DOI 10.1016/j.physa.2016.11.015
   Zhou X, 2017, SOFT COMPUT, V21, P6641, DOI 10.1007/s00500-016-2213-z
NR 40
TC 59
Z9 61
U1 9
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25205
EP 25231
DI 10.1007/s11042-022-12409-x
EA MAR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882300016
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Huo, WX
   Yan, YJ
   Zhou, MX
   Li, TP
AF Huo, Wenxiao
   Yan, Yejin
   Zhou, Maoxia
   Li, Tianping
TI An improved kernel correlation filter for complex scenes target tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Features fusion; Re-detection; Spatial regularization; Video target
   tracking
ID OBJECT TRACKING; RECOGNITION; NETWORKS
AB Video tracking technology employed to achieve efficient and accurate tracking of targets in complex scenes has often been one of the challenges to be tackled. When the target is in a complex scene similar to target interference, it will still create a series of issues, such as template drift although the current target tracking has achieved quality results in terms of accuracy, robustness, and speed. We propose an improved kernel correlation filter algorithm in response to this problem. We introduced a regularization matrix and fused properties of HOG and CN to train an improved kernel correlation filter. Furthermore, an independent scale filter is employed to regulate the scale adaptively. We have introduced a re-detection module to prevent the issue of the kernel correlation filter algorithm relying mainly on the maximum response value.A considerable number of experiments have been conducted on the aforementioned improvements. The algorithm's average tracking accuracy can attain 85.8%, in the OTB2015 dataset and its running speed can attain 198FPS. The algorithm's EAO, accuracy, and robustness, on the VOT2016 dataset, can attain 0.303, 0.553, and 0.932, respectively.Experiments demonstrate that our algorithm has satisfactory accuracy and robustness, and satisfies the real-time effect.
C1 [Huo, Wenxiao; Zhou, Maoxia; Li, Tianping] Shandong Normal Univ, Sch Phys & Elect, Shandong Key Lab Med Phys & Image Proc, Jinan 250014, Shandong, Peoples R China.
   [Yan, Yejin] Shandong Normal Univ, Sch Phys & Elect, Jinan 250014, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Normal University
RP Zhou, MX; Li, TP (corresponding author), Shandong Normal Univ, Sch Phys & Elect, Shandong Key Lab Med Phys & Image Proc, Jinan 250014, Shandong, Peoples R China.
EM huowx11@163.com; 1070060517@qq.com; 115085@sdnu.edu.cn;
   sdsdltp@sdnu.edu.cn
FU NSFC [61572286, 61472220]; NSFC Joint with Zhejiang Integration of
   Informatization and Industrializaiton [U1609218]; Fostering Project of
   Dominant Discipline a Talent Team of Shandong Province Higher Education
FX We are grateful to the editors and referees for their invaluable
   suggestions for improving the paper. This work was supported in part by
   NSFC (61572286 and 61472220), NSFC Joint with Zhejiang Integration of
   Informatization and Industrializaiton under Key Project (U1609218), and
   the Fostering Project of Dominant Discipline a Talent Team of Shandong
   Province Higher Education.
CR Ahmad T, 2021, J COMPUT SCI TECHNOL, V21, P71, DOI 10.24215/16666038.21.e08
   Baune BT, 2018, INT J NEUROPSYCHOPH, V21, P97, DOI 10.1093/ijnp/pyx070
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat PG, 2020, IEEE SENS J, V20, P2405, DOI 10.1109/JSEN.2019.2954331
   Bull DR, 2021, HUMAN VISUAL SYSTEM
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chakraborty BK, 2018, IET COMPUT VIS, V12, P3, DOI 10.1049/iet-cvi.2017.0052
   Chen YY, 2019, EARTH SCI INFORM, V12, P341, DOI 10.1007/s12145-019-00383-2
   DING W, 2018, ADV MATER TECHNOL-US
   FANG H, 2020, ADV CIV ENG, V2020
   Han K, 2017, CLUSTER COMPUT, V20, P1259, DOI 10.1007/s10586-017-0800-0
   Han YN, 2018, IEEE T NEUR NET LEAR, V29, P486, DOI 10.1109/TNNLS.2016.2635151
   He ZY, 2019, IEEE ACCESS, V7, P115368, DOI 10.1109/ACCESS.2019.2936243
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hong D, 2018, J MULTIVARIATE ANAL, V167, P435, DOI 10.1016/j.jmva.2018.06.002
   Hsia CH, 2016, J REAL-TIME IMAGE PR, V12, P183, DOI 10.1007/s11554-013-0382-x
   Janai J, 2020, FOUND TRENDS COMPUT, V12, P1, DOI 10.1561/0600000079
   Ji Y, 2020, J PHYS C SERIES, V1627
   Jiang JJ, 2018, P NATL ACAD SCI USA, V115, pE639, DOI 10.1073/pnas.1714958115
   Khatun A, 2018, IEEE WINT CONF APPL, P1292, DOI 10.1109/WACV.2018.00146
   Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14
   Leng J., 2018, IEEE ACCESS, V6, P1, DOI [10.1109/ACCESS.2018.2812929, DOI 10.1109/ACCESS.2018.2812929]
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liu S, 2021, NEURAL COMPUT APPL, V33, P1055, DOI 10.1007/s00521-020-05021-3
   Lu HM, 2017, COMPUT ELECTR ENG, V58, P444, DOI 10.1016/j.compeleceng.2017.04.024
   Mabrouki J, 2021, BIG DATA MIN ANAL, V4, P10, DOI 10.26599/BDMA.2020.9020017
   Meng X, 2018, 2018 IEEE 9 ANN INF
   Muqeet A, 2019, HYBRID RESIDUAL ATTE
   Nigam S, 2018, MULTIMED TOOLS APPL, V77, P28725, DOI 10.1007/s11042-018-6040-3
   Sethy A, 2020, R HOG FEATURE BASED
   Song D, 2021, INT J ELECT ENG ED, DOI [10.1177/00207209211013455, DOI 10.1177/00207209211013455]
   Soni R, 2019, MULTIMED TOOLS APPL, V78, P31757, DOI 10.1007/s11042-019-07998-z
   TAKAMASA S, 2020, IEICE T FUND ELECTR, VA, P278
   Tang C, 2017, LOGISTICS ENG MANAG
   Tian YM, 2019, J GEODESY, V93, P1073, DOI 10.1007/s00190-018-01226-6
   Tseng DC, AUTONOMOUS TRACKING, DOI 10.18178/ijmlc.2021.11.1.1013
   Wang T, 2020, FUTURE GENER COMP SY, V109, P573, DOI 10.1016/j.future.2018.05.049
   Wang XB, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101950
   Wang XY, 2018, OPT LASER ENG, V107, P370, DOI 10.1016/j.optlaseng.2017.06.015
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiao FY, 2018, IEEE ACCESS, V6, P25300, DOI 10.1109/ACCESS.2018.2820099
   You L, 2017, 2017 15TH INTERNATIONAL SYMPOSIUM ON MODELING AND OPTIMIZATION IN MOBILE, AD HOC, AND WIRELESS NETWORKS (WIOPT)
   Yu L, 2018, MACH VISION APPL, V29, P361, DOI 10.1007/s00138-017-0902-y
   Zhang JH, 2020, IEEE T IND ELECTRON, V67, P8659, DOI 10.1109/TIE.2019.2946557
   ZHANG Y, 2018, IEEE ACCESS PP, P1
   Zhao B, 2020, NEUROCOMPUTING, V407, P24, DOI 10.1016/j.neucom.2020.04.073
   Zhu G, 2016, PROC CVPR IEEE, P943, DOI 10.1109/CVPR.2016.108
NR 49
TC 2
Z9 2
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20917
EP 20944
DI 10.1007/s11042-022-12669-7
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767922000011
DA 2024-07-18
ER

PT J
AU Chen, JY
   Zuo, WT
   Zhan, YW
AF Chen, Jiayi
   Zuo, Wentao
   Zhan, Yinwei
TI Image restoration in the presence of impulse noise by adaptive
   equidistant median filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image restoration; Noise detection; Switching median filter; Circular
   neighborhood; Equidistant median filter
ID MEAN FILTER; REMOVAL; SALT; ALGORITHM
AB After widely studying the methods in literatures for impulse noise removal, aiming at overcoming their deficiencies and further improving the denoising performance, we propose an adaptive equidistant median filter for image restoration in the presence of impulse noise. As an improved and effective alternative to the square neighborhood, the circular neighborhood is proposed for noise detection and removal processing. A noise detector based on adaptive local statistics is proposed, followed by a noise removal technique gaining support from adaptive equidistant median proposed subsequently. Furthermore, the noise removal processing is performed adaptively so as to be robust for various noise densities. Experimental results have shown that the proposed method has substantially improved the performance in noise detection and removal, and is superior than the state-of-the-art filters with excellent capability of noise removal and structural information preservation.
C1 [Chen, Jiayi] Guangdong Med Univ, Sch Biomed Engn, Zhanjiang 524023, Guangdong, Peoples R China.
   [Zuo, Wentao] Guangzhou Coll Technol & Business, Dept Comp Sci & Engn, Guangzhou 510850, Peoples R China.
   [Zhan, Yinwei] Guangdong Univ Technol, Sch Comp Sci & Technol, Guangzhou 510006, Peoples R China.
C3 Guangdong Medical University; Guangdong University of Technology
RP Chen, JY (corresponding author), Guangdong Med Univ, Sch Biomed Engn, Zhanjiang 524023, Guangdong, Peoples R China.
EM beyond38@163.com; zuowentao306@163.com; ywzhan@gdut.edu.cn
RI chen, jia/JDW-7660-2023; Chen, Jiayi/GZM-5106-2022; chen,
   jiayi/IAP-9353-2023; Chen, Jia/HQZ-3908-2023; chen, jiayi/KHV-5520-2024;
   chen, jia/JLM-4733-2023
OI chen, jiayi/0009-0009-0528-5475; Chen, Jiayi/0000-0001-5943-4709
FU National Natural Science Foundation of China [61802074, 61705095];
   Guangdong Basic and Applied Basic Research Foundation of China
   [2018A030313802, 2020A1515010760]
FX We would like to thank the editors and anonymous reviewers for their
   constructive suggestions to the improvements of this paper. This work
   was supported by the National Natural Science Foundation of China [grant
   numbers 61802074, 61705095]; the Guangdong Basic and Applied Basic
   Research Foundation of China [grant number 2018A030313802,
   2020A1515010760].
CR Çaliskan A, 2018, TEH VJESN, V25, P679, DOI 10.17559/TV-20171220221947
   Chung-Hsun Sun, 2015, Applied Mechanics and Materials, V764-765, P1279, DOI 10.4028/www.scientific.net/AMM.764-765.1279
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   Erkan U, 2019, IEEE ACCESS, V7, P167847, DOI 10.1109/ACCESS.2019.2953924
   Faragallah OS, 2016, AEU-INT J ELECTRON C, V70, P1034, DOI 10.1016/j.aeue.2016.04.018
   Fareed SBS, 2018, IET IMAGE PROCESS, V12, P1378, DOI 10.1049/iet-ipr.2017.0199
   Goel N, 2020, MULTIMED TOOLS APPL, V79, P19739, DOI 10.1007/s11042-020-08687-y
   Hussain A, 2017, MULTIMED TOOLS APPL, V76, P22001, DOI 10.1007/s11042-017-4757-z
   Jafar IF, 2013, IEEE T IMAGE PROCESS, V22, P1223, DOI 10.1109/TIP.2012.2228496
   Jiang XD, 2012, IEEE T IMAGE PROCESS, V21, P1537, DOI 10.1109/TIP.2011.2172805
   Kishorebabu V, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0215-0
   Kuo YL, 2015, INT J FUZZY SYST, V17, P67, DOI 10.1007/s40815-015-0005-8
   Mafi M, 2018, IEEE T IMAGE PROCESS, V27, P5475, DOI 10.1109/TIP.2018.2857448
   Mokri SS, 2016, IEEE T NUCL SCI, V63, P157, DOI 10.1109/TNS.2015.2513484
   O'Connell D, 2017, BIOMED PHYS ENG EXPR, V3, DOI 10.1088/2057-1976/aa889d
   Roy A, 2018, J CIRCUIT SYST COMP, V27, DOI 10.1142/S0218126618501396
   Roy A, 2017, IET IMAGE PROCESS, V11, P352, DOI 10.1049/iet-ipr.2016.0320
   Roy A, 2017, AEU-INT J ELECTRON C, V72, P114, DOI 10.1016/j.aeue.2016.12.006
   Satti P, 2020, IEEE SIGNAL PROC LET, V27, P1475, DOI 10.1109/LSP.2020.3016868
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Vijayarajan R, 2012, INT J COMPUTER SCI I, V9, P134
   Wan Fengfeng, 2019, Journal of Zhejiang University (Science Edition), V46, P445, DOI 10.3785/j.issn.1008-9497.2019.04.010
   Wang YM, 2022, IEEE T MULTIMEDIA, V24, P1288, DOI 10.1109/TMM.2021.3062699
   Wang Y, 2017, J STAT COMPUT SIM, V87, P2538, DOI 10.1080/00949655.2017.1340474
   Wang Y, 2016, IEEE SIGNAL PROC LET, V23, P1582, DOI 10.1109/LSP.2016.2607785
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yuan GZ, 2019, IEEE T PATTERN ANAL, V41, P352, DOI 10.1109/TPAMI.2017.2783936
   Zhang Z, 2018, SIGNAL PROCESS, V147, P173, DOI 10.1016/j.sigpro.2018.01.027
NR 28
TC 2
Z9 2
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20407
EP 20423
DI 10.1007/s11042-022-12057-1
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767748600009
DA 2024-07-18
ER

PT J
AU Rahebi, J
AF Rahebi, Javad
TI Vector quantization using whale optimization algorithm for digital image
   compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression; Image processing; Vector quantization; Whale
   optimization algorithm
ID PATTERN; DECOMPOSITION
AB Today, much of the information is storing in images. To transfer information in the form of images, image compression is required. Compressing images reduces the size of images and sends them faster over the network. One of the most methods of image compression is the vector quantization. For vector quantization compression, the codebook is using in cryptography and decryption. The vector quantization compression method typically uses codebooks that are not optimized, which reduces the compression quality of the images. Choosing the optimal codebook makes compression of images with higher quality. Choosing the optimal codebook is a difficult optimization problem and therefore requires intelligent algorithms to solve it. In this paper, the whale optimization algorithm is used to find the optimal codebook in image compression. Whale Optimization Algorithm has different search strategies and is an ideal algorithm for finding the optimal codebook in images compression. Implementation of the proposed algorithm for compression on several standard images shows that the proposed method compresses images with appropriate quality. The proposed method performs more efficient compression than the proposed algorithms such as particle swarm optimization, bat, and firefly algorithms. The signal-to-noise ratio of the proposed method is higher than the compared methods. Experiments on a set of standard images show the proposed method compared to the Fire Fly, Bat, and Differential evolution, Improved Particle Swarm Optimization, and Improved Differential Evolution methods with a compression execution time of 60.48% and 10.21, respectively. %, 4.79%, 5.09% and 3.94% decreased. The proposed method in compression has a higher PSNR index of about 17% than the Linde-Buzo-Gray method.
C1 [Rahebi, Javad] Istanbul Ayvansaray Univ, Dept Software Engn, Istanbul, Turkey.
C3 Istanbul Topkapi University
RP Rahebi, J (corresponding author), Istanbul Ayvansaray Univ, Dept Software Engn, Istanbul, Turkey.
EM cevatrahebi@ayvansaray.edu.tr
CR Al Sadawi A, 2020, IEEE INT TECHNOL MAN, DOI 10.1109/ICTMOD49425.2020.9380610
   Bal R, 2019, ADV INTELL SYST COMP, V741, P879, DOI 10.1007/978-981-13-0761-4_83
   Bilal M, 2021, IEEE ACCESS, V9, P98904, DOI 10.1109/ACCESS.2021.3095287
   Chataignon J, 2020, IRAN WORKS COMMUN, DOI 10.1109/iwcit50667.2020.9163531
   Chaudhary P, 2020, PROCEDIA COMPUT SCI, V167, P244, DOI 10.1016/j.procs.2020.03.218
   Chavan PP, 2020, SADHANA-ACAD P ENG S, V45, DOI 10.1007/s12046-020-01436-9
   Chiranjeevi K, 2018, AIN SHAMS ENG J, V9, P1417, DOI 10.1016/j.asej.2016.09.009
   Chou JS, 2021, APPL MATH COMPUT, V389, DOI 10.1016/j.amc.2020.125535
   Dhannawat Rachana Avinash, 2020, 2020 3rd International Conference on Communication System, Computing and IT Applications (CSCITA). Proceedings, P146, DOI 10.1109/CSCITA47329.2020.9137796
   Fred AL, 2019, INTEL SYST REF LIBR, V150, P29, DOI 10.1007/978-3-319-96002-9_2
   Geetha K, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12508
   Gibran M. Khalil, 2020, 2020 3rd International Conference on Mechanical, Electronics, Computer, and Industrial Technology (MECnIT), P188, DOI 10.1109/MECnIT48290.2020.9166649
   Golts A, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103208
   Gottapu S. K., 2020, EAI INT C BIG DATA I, P3
   Griouz B, 2020, INT J BIOMETRICS, V12, P131
   Hai-jun Wang, 2020, Journal of Physics: Conference Series, V1550, DOI 10.1088/1742-6596/1550/2/022025
   Hassan OF, 2020, INT C ADV INT SYST I, P3
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Hong WX, 2020, IEEE T PATTERN ANAL, V42, P1783, DOI 10.1109/TPAMI.2019.2925347
   Hussain Abdullah A., 2020, IOP Conference Series: Materials Science and Engineering, V928, DOI 10.1088/1757-899X/928/3/032006
   Krishnaraj N, 2020, J REAL-TIME IMAGE PR, V17, P2097, DOI 10.1007/s11554-019-00879-6
   Lu XT, 2019, IEEE ACCESS, V7, P118815, DOI 10.1109/ACCESS.2019.2934731
   Ma SW, 2020, IEEE T CIRC SYST VID, V30, P1683, DOI 10.1109/TCSVT.2019.2910119
   Marlapalli Krishna, 2021, Communication Software and Networks. Proceedings of INDIA 2019. Lecture Notes in Networks and Systems (LNNS 134), P271, DOI 10.1007/978-981-15-5397-4_29
   Minnen D, 2020, IEEE IMAGE PROC, P3339, DOI [10.1109/icip40778.2020.9190935, 10.1109/ICIP40778.2020.9190935]
   Mirjalili S., 2020, Nature-inspired optimizers theories, literature reviews and applications, P219, DOI DOI 10.1007/978-3-030-12127-3_13
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mohindru P, 2020, IMAGE IN, V9
   Mohona SS, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123129
   Nag S, 2019, GENET PROGRAM EVOL M, V20, P187, DOI 10.1007/s10710-019-09342-8
   Padmaja M., 2020, ICIGP 2020: Proceedings of the 2020 3rd International Conference on Image and Graphics Processing, P158, DOI 10.1145/3383812.3383827
   Paira Ramkrishna, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P373, DOI 10.1007/978-981-13-7403-6_34
   Pereira PMM, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101924
   Preethi D, 2020, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT-2020), P209, DOI 10.1109/icict48043.2020.9112528
   RAVI P, 2019, NOVEL PSO ALGORITHM
   Ravi RV, 2021, J AMB INTEL HUM COMP, V12, P6677, DOI 10.1007/s12652-020-02290-7
   Roberto e Souza M, 2020, RECENT ADV HYBRID ME, P151
   Rossinelli D, 2021, IEEE T MED IMAGING, V40, P607, DOI 10.1109/TMI.2020.3033456
   Shinde A, 2019, MULTIMED TOOLS APPL, V78, P23489, DOI 10.1007/s11042-019-7697-y
   Touil DE, 2021, MULTIMED TOOLS APPL, V80, P9547, DOI 10.1007/s11042-020-09754-0
   Zhao WG, 2022, COMPUT METHOD APPL M, V388, DOI 10.1016/j.cma.2021.114194
NR 41
TC 9
Z9 9
U1 7
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 20077
EP 20103
DI 10.1007/s11042-022-11952-x
EA MAR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000767089500001
DA 2024-07-18
ER

PT J
AU Tan, XJ
   Mustafa, N
   Mashor, MY
   Ab Rahman, KS
AF Tan, Xiao Jian
   Mustafa, Nazahah
   Mashor, Mohd Yusoff
   Ab Rahman, Khairul Shakir
TI Spatial neighborhood intensity constraint (SNIC) and knowledge-based
   clustering framework for tumor region segmentation in breast
   histopathology images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; FCM; Spatial constraint; Neighborhood constraint;
   Initialization method; Histopathology
ID CANCER; CLASSIFICATION; ALGORITHM; NETWORK
AB Based on the Nottingham Histological Grading (NHG) system, precise and accurate segmentation of breast tumor regions is crucial, typically in the scoring decision in terms of tubule formation. The main purposes of this study are to propose a robust segmentation framework that could produce repeatable, reproducible, and cost-effective measurable outputs. A novel spatial neighborhood intensity constraint (SNIC) and knowledge-based clustering framework for breast tumor region segmentation are proposed in this study. The proposed clustering framework constitutes of five different stages. These stages are color normalization, segmentation and removal of nucleus cells, SNIC, FCM with knowledge-based initial centroids selection, and post-processing. The main contribution of the proposed clustering framework lies within its simplicity yet powerful clustering ability producing precise segmentation in breast tumor regions using histopathology images. The SNIC is meant to remove the original RGB intensity of the nucleus cells and replace it with new intensity using the spatial information from the neighborhood pixels. Additionally, a knowledge-based initial centroids selection method is implemented to facilitate the fuzzy clustering algorithm. The proposed SNIC and knowledge-based initial centroids selection methods are expected to ease the clustering stage producing complementary results. For hypothesis validation purposes, justifications and validations are performed to validate the applicability of the proposed SNIC and knowledge-based initial centroids selection. Both of the proposed methods are found robust and plausible. The proposed framework achieved overall Accuracy (Acc), F1 score (F1), Area Overlap Measure (AOM), and Combined Equal Importance (CEI) of 91.2%, 92.1%, 85.7%, and 90.1%, respectively. For benchmarking purposes, the output results are compared to four recent works. The proposed framework demonstrates its robustness by outperformed these works achieving better results in Acc, F1, AOM, and CEI by 5.8%, 5.9%, 8.5%, and 7.0% higher than that of the best performance work amongst the four recent works.
C1 [Tan, Xiao Jian] Tunku Abdul Rahman Univ Coll TARUC, Fac Engn & Technol, Ctr Multimodal Signal Proc, Dept Elect & Elect Engn, Jalan Genting Kelang, Kuala Lumpur 53300, Malaysia.
   [Mustafa, Nazahah; Mashor, Mohd Yusoff] Univ Malaysia Perlis, Fac Elect Engn Technol, Biomed Elect Engn Programme, Arau 02600, Perlis, Malaysia.
   [Ab Rahman, Khairul Shakir] Hosp Tuanku Fauziah, Dept Pathol, Jalan Tun Abdul Razak, Kangar 01000, Perlis, Malaysia.
C3 Universiti Malaysia Perlis
RP Tan, XJ (corresponding author), Tunku Abdul Rahman Univ Coll TARUC, Fac Engn & Technol, Ctr Multimodal Signal Proc, Dept Elect & Elect Engn, Jalan Genting Kelang, Kuala Lumpur 53300, Malaysia.; Mustafa, N (corresponding author), Univ Malaysia Perlis, Fac Elect Engn Technol, Biomed Elect Engn Programme, Arau 02600, Perlis, Malaysia.
EM tanxj@tarc.edu.my; nazahah@unimap.edu.my
RI Tan, Xiao Jian/R-5647-2016
OI Tan, Xiao Jian/0000-0003-1038-3933
FU Ministry of Higher Education Malaysia under Fundamental Research Grant
   Scheme (FRGS) [FRGS/1/2016/SKK06/UNIMAP/02/3]
FX This study was funded by the Ministry of Higher Education Malaysia under
   Fundamental Research Grant Scheme (FRGS)
   (FRGS/1/2016/SKK06/UNIMAP/02/3).
CR Amal KRG., 2017, INT J ADV RES INNOV, V2, P60
   Arai K, 2017, PHYS MEDICA, V33, P68, DOI 10.1016/j.ejmp.2016.12.006
   Arjmand A, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE 2019), P305, DOI [10.1109/ICCKE48569.2019.8964794, 10.1109/iccke48569.2019.8964794]
   Ashiba HI, 2021, MULTIMED TOOLS APPL, V80, P9333, DOI 10.1007/s11042-020-10131-0
   CebecI Z., 2015, Journal of Agricultural Informatics, V6, P13
   Das DK, 2019, COMPUT BIOL MED, V104, P29, DOI 10.1016/j.compbiomed.2018.11.001
   Vo DM, 2019, INFORM SCIENCES, V482, P123, DOI 10.1016/j.ins.2018.12.089
   Elston C W, 2002, Histopathology, V41, P154
   Farahani N, 2015, PATHOL LAB MED INT, V7, P23, DOI 10.2147/PLMI.S59826
   Fouad S, 2017, COMM COM INF SC, V723, P767, DOI 10.1007/978-3-319-60964-5_67
   Ganesan P, 2016, 2016 WORLD C FUT TRE, DOI [10.1109/STARTUP.2016.7583960, DOI 10.1109/STARTUP.2016.7583960]
   George K, 2020, COMPUT BIOL MED, V124, DOI 10.1016/j.compbiomed.2020.103954
   Gosain A, 2016, PROCEDIA COMPUT SCI, V79, P100, DOI 10.1016/j.procs.2016.03.014
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Khan Adnan M, 2013, J Pathol Inform, V4, pS1, DOI 10.4103/2153-3539.109802
   Khan AM, 2012, MED IMAGE UNDERST AN
   Li XY, 2015, IEEE T BIO-MED ENG, V62, P1862, DOI 10.1109/TBME.2015.2405791
   Linder N, 2012, DIAGN PATHOL, V7, DOI 10.1186/1746-1596-7-22
   Liu Q, 2016, ARAB J SCI ENG, V41, P807, DOI 10.1007/s13369-015-1905-5
   Majeed H, 2016, PROC SPIE, V9718, DOI 10.1117/12.2209142
   Mekhmoukh A, 2015, COMPUT METH PROG BIO, V122, P266, DOI 10.1016/j.cmpb.2015.08.001
   Monaco J, 2012, LECT NOTES COMPUT SC, V7510, P365, DOI 10.1007/978-3-642-33415-3_45
   Nickfarjam AM, 2014, ARAB J SCI ENG, V39, P753, DOI 10.1007/s13369-013-0638-6
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qu AP, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-014-5277-3
   Rakha EA, 2010, BREAST CANCER RES, V12, DOI 10.1186/bcr2607
   Ramadijanti N, 2018, 2018 INTERNATIONAL ELECTRONICS SYMPOSIUM ON KNOWLEDGE CREATION AND INTELLIGENT COMPUTING (IES-KCIC), P170, DOI 10.1109/KCIC.2018.8628467
   Salsabili S, 2019, COMPUT BIOL MED, V113, DOI 10.1016/j.compbiomed.2019.103420
   Sebai M, 2020, MED BIOL ENG COMPUT, V58, P1603, DOI 10.1007/s11517-020-02175-z
   Sebai M, 2020, IEEE ACCESS, V8, P45133, DOI 10.1109/ACCESS.2020.2978754
   Shen S, 2005, IEEE T INF TECHNOL B, V9, P459, DOI 10.1109/TITB.2005.847500
   Sigirci IO, 2022, MULTIMED TOOLS APPL, V81, P13179, DOI 10.1007/s11042-021-10539-2
   Tariq M, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114095
   Xiao Jian Tan, 2019, 10th International Conference on Robotics, Vision, Signal Processing and Power Applications. Enabling Research and Innovation Towards Sustainability. Lecture Notes in Electrical Engineering (LNEE 547), P529, DOI 10.1007/978-981-13-6447-1_67
   Yu CR, 2019, MULTIMED TOOLS APPL, V78, P21325, DOI 10.1007/s11042-019-7468-9
NR 36
TC 3
Z9 3
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18203
EP 18222
DI 10.1007/s11042-022-12129-2
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766438300014
DA 2024-07-18
ER

PT J
AU Zaib, SE
   Yamamura, M
AF Zaib, Sumaira Erum
   Yamamura, Masayuki
TI Personalized saliency prediction using color spaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personalized saliency; Universal saliency; Visual saliency; Fixation;
   Saccade
ID VISUAL-ATTENTION; MODEL
AB Saliency is the ability of being important, noticeable or attention worthy. Finding salient regions in images has important applications in automatic image cropping, image compression and advertisements. The salient regions for an individual in an image changes according to their gender, race, culture, likes, dislikes and experiences. Universal Saliency Maps point out the overall general salient regions without any considerations of personal traits of the subject. Therefore, personalized saliency maps are required for better and more personalized predictions of salient regions. In this study, using the RGB (Red, Green, Blue), CYMK (Cyan, Yellow, Magenta, Key), HSV (Hue, Saturation, Value) and HSL (Hue, Saturation, Lightness) fixation patterns of individuals, we propose a Gradient Boosted Tree Regression model to extract personalized saliency map from the universal saliency map with an average accuracy of 80% (Area Under Curve Judd Metrics). We also put forth our discussion for why some images and subjects have better saliency map predictions than others.
C1 [Zaib, Sumaira Erum; Yamamura, Masayuki] Tokyo Inst Technol, Sch Comp, Dept Comp Sci, Yamamura Lab 1706, Yokohama, Kanagawa 2268502, Japan.
C3 Tokyo Institute of Technology
RP Zaib, SE (corresponding author), Tokyo Inst Technol, Sch Comp, Dept Comp Sci, Yamamura Lab 1706, Yokohama, Kanagawa 2268502, Japan.
EM erum.s.aa@m.titech.ac.jp; my@c.titech.ac.jp
OI , Sumaira Erum Zaib/0000-0002-8019-7434
FU MEXT (Ministry of Education, Culture, Sports, Science and Technology,
   Japan) scholarship for doctoral program at Tokyo Institute of
   Technology, Japan
FX This research did not directly receive any specific grant from funding
   agencies in the public, commercial, or not-for-profit sectors. However,
   the author, Sumaira Erum Zaib, receives MEXT (Ministry of Education,
   Culture, Sports, Science and Technology, Japan) scholarship for doctoral
   program at Tokyo Institute of Technology, Japan.
CR Anderson NC, 2015, BEHAV RES METHODS, V47, P1377, DOI 10.3758/s13428-014-0550-3
   Borji A., 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247706
   Bylinskii Z, 2019, Mit saliency benchmark
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Chang MML, 2016, LECT NOTES COMPUT SC, V9768, P453, DOI 10.1007/978-3-319-40621-3_33
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Courty N, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P1065
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Frey HP, 2008, J VISION, V8, DOI 10.1167/8.14.6
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gao ZF, 2020, IEEE INTERNET THINGS, V7, P4092, DOI 10.1109/JIOT.2019.2963701
   Gao ZF, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900260
   Gelasca E. D., 2005, P 1 INT WORKSH VID P
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   JIANG M, 2015, PROC CVPR IEEE, P1072, DOI DOI 10.1109/CVPR.2015.7298710
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kawasaki M, 2012, NEUROIMAGE, V59, P808, DOI 10.1016/j.neuroimage.2011.07.042
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kümmerer M, 2017, IEEE I CONF COMP VIS, P4799, DOI 10.1109/ICCV.2017.513
   Kummerer M., 2015, INT C LEARN REPR ICL
   Kuniecki M, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00212
   Le Meur O, 2017, IEEE T IMAGE PROCESS, V26, P4777, DOI 10.1109/TIP.2017.2722238
   Lee TS, 2000, ADV NEUR IN, V12, P834
   LEMEUR O, 2016, VIS RES, V121
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mathe Stefan., 2013, Advances in Neural Information and Processing Systems
   Matthews G, 1999, PERS INDIV DIFFER, V26, P583, DOI 10.1016/S0191-8869(98)00158-5
   Nishad P.M., 2013, J GLOBAL RES COMPUTE, V4, P44
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Riche N, 2013, SIGNAL PROCESS-IMAGE, V28, P642, DOI 10.1016/j.image.2013.03.009
   Risko EF, 2012, COGNITION, V122, P86, DOI 10.1016/j.cognition.2011.08.014
   Robinson, 1985, J WASHINGTON ACAD SC, V75
   Rousselet GA, 2004, VISION RES, V44, P877, DOI 10.1016/j.visres.2003.11.014
   Setlur Vidya., 2005, MUM, V154, P59, DOI DOI 10.1145/1149488.1149499
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   SPIEGEL D, 1971, J CLIN PSYCHOL, V27, P318, DOI 10.1002/1097-4679(197107)27:3<318::AID-JCLP2270270305>3.0.CO;2-J
   't Hart BM, 2013, PHILOS T R SOC B, V368, DOI 10.1098/rstb.2013.0067
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   Walker S, 2008, J VISION, V8, DOI 10.1167/8.4.21
   Xu YY, 2019, IEEE T PATTERN ANAL, V41, P2975, DOI 10.1109/TPAMI.2018.2866563
   Yu B., 2017, ARXIV171108000
NR 43
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18181
EP 18202
DI 10.1007/s11042-022-12341-0
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766438300007
DA 2024-07-18
ER

PT J
AU Hendre, M
   Patil, S
   Abhyankar, A
AF Hendre, Manik
   Patil, Suraj
   Abhyankar, Aditya
TI Biometric recognition robust to partial and poor quality fingerprints
   using distinctive region adaptive SIFT keypoint fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SIFT; Minutia; Fingerprint; Fusion; NFIQ; Quality
ID FEATURE-DETECTORS; IMAGE QUALITY; LEVEL FUSION; IDENTIFICATION;
   DESCRIPTORS; PERFORMANCE; FEATURES
AB Quantity and the quality of detected discriminating features is very important in any recognition system. In minutia based fingerprint matching techniques, the performance depends upon the quality and quantity of the detected genuine minutia points. In this paper, we have demonstrated that using only minutia points for fingerprint matching does not give optimum results. We have proposed a feature level fusion technique using minutia and Scale Invariant Feature Transform (SIFT) keypoints. The extra step of reducing false matches is required when using the SIFT method. The proposed method adaptively selects the SIFT keypoints using the distinctive region criterion. This criterion ensures that only the SIFT keypoints which are at distinct regions from the minutia points are taken for the fusion process. The proposed fusion technique improves the recognition performance by 3.29% and 4.23% in terms of equal error rate (EER) on publicly available FVC2004 DB1A and CASIA dataset respectively. The experimental results also prove the efficacy of the proposed fusion technique in dealing with poor quality and partial fingerprints. A new partial fingerprint dataset is created by cropping the fingerprints in a FVC2004 DB1A dataset to evaluate the performance in the presence of partial fingerprints. The proposed technique reduces the equal error rate by 10.21% for the partial fingerprint dataset. The performance of the SIFT based fusion method is also compared with other multi-scale feature detectors such as BRISK, KAZE, AKAZE, and ORB.
C1 [Hendre, Manik; Patil, Suraj; Abhyankar, Aditya] Savitribai Phule Pune Univ, Dept Technol, Pune, Maharashtra, India.
C3 Savitribai Phule Pune University
RP Hendre, M (corresponding author), Savitribai Phule Pune Univ, Dept Technol, Pune, Maharashtra, India.
EM manik.hendre@unipune.ac.in; suraj.patil@unipune.ac.in;
   aditya.abhyankar@unipune.ac.in
CR Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   AlShehri H, 2018, INT J COMPUT SCI SOF, V7, P47
   Aravindan A, 2017, PATTERN ANAL APPL, V20, P963, DOI 10.1007/s10044-017-0615-x
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bellavia F, 2020, INT J COMPUT VISION, V128, P1847, DOI 10.1007/s11263-020-01297-z
   CASIA, 2019, CASIA FINGERPRINTV5
   Chen L, 2021, GEO-SPAT INF SCI, V24, P58, DOI 10.1080/10095020.2020.1843376
   Fanglin Chen, 2012, Biometric Recognition. 7th Chinese Conference, CCBR 2012. Proceedings, P104, DOI 10.1007/978-3-642-35136-5_13
   Fierrez-Aguilar J, 2006, LECT NOTES COMPUT SC, V3832, P213
   Gawande U, 2018, INT J BIOMETRICS, V10, P142, DOI 10.1504/IJBM.2018.10012749
   Grother P, 2007, IEEE T PATTERN ANAL, V29, P531, DOI 10.1109/TPAMI.2007.1019
   Jain A K, 2011, Introduction to Biometrics
   Jea TY, 2005, PATTERN RECOGN, V38, P1672, DOI 10.1016/j.patcog.2005.03.016
   Jin Q, 2005, PATTERN RECOGN LETT, V26, P2424, DOI 10.1016/j.patrec.2005.04.016
   Karim S, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042618
   Kasiselvanathan M., 2020, International Journal of Intelligence and Sustainable Computing, V1, P44, DOI DOI 10.1504/IJISC.2020.104826
   Kisku DR, 2009, COMM COM INF SC, V58, P157
   Ko K., 2007, NIST Interagency/Internal Report (NISTIR)-7392
   Krish RP, 2019, INFORM FUSION, V50, P9, DOI 10.1016/j.inffus.2018.10.001
   Leng CC, 2019, IEEE ACCESS, V7, P6424, DOI 10.1109/ACCESS.2018.2888856
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Liu X, 2016, 2016 INT C BIOM SPEC, P1
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma JY, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01359-2
   Malathi S., 2010, 2010 International Conference on Communication Control and Computing Technologies, P569, DOI 10.1109/ICCCCT.2010.5670775
   Malathi S, 2011, 2011 INT C PROC AUT, P1
   Mathur S, 2016, INT CONF BIOMETR
   Minaee S., 2019, Deep-emotion: Facial expression recognition using attentional convolutional network
   Mouats T, 2018, J INTELL ROBOT SYST, V92, P33, DOI 10.1007/s10846-017-0762-8
   Mukherjee D, 2015, MACH VISION APPL, V26, P443, DOI 10.1007/s00138-015-0679-9
   Nandakumar K, 2008, IEEE T PATTERN ANAL, V30, P342, DOI 10.1109/TPAMI.2007.70796
   NBIS, 2018, NIST BIOMETRIC IMAGE
   Park U, 2008, PROC SPIE, V6944, DOI 10.1117/12.778804
   Prabakhar S., 2003, HDB FINGERPRINT RECO
   Prabhakar S, 2002, PATTERN RECOGN, V35, P861, DOI 10.1016/S0031-3203(01)00103-0
   Rattani A, 2007, 2007 FIRST IEEE INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P85
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Saeed F, 2018, 2018 21ST SAUDI COMPUTER SOCIETY NATIONAL COMPUTER CONFERENCE (NCC)
   Shreyas K.K., 2017, A Handbook o f Food Bioengineering, P1
   Simon-Zorita D, 2003, IEE P-VIS IMAGE SIGN, V150, P402, DOI 10.1049/ip-vis:20031037
   Singh M, 2019, INFORM FUSION, V52, P187, DOI 10.1016/j.inffus.2018.12.003
   Tabassi E., 2004, FINGERPRINT IMAGE QU
   Tabassi Elham., 2009, Encyclopedia of Biometrics, P482
   Tang Y, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P108, DOI 10.1109/BTAS.2017.8272688
   Tareen Shaharyar Ahmed Khan, 2018, 2018 International Conference on Computing, Mathematics and Engineering Technologies (iCoMET). Proceedings, DOI 10.1109/ICOMET.2018.8346440
   Tico M, 2003, IEEE T PATTERN ANAL, V25, P1009, DOI 10.1109/TPAMI.2003.1217604
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Ullah Baig Wajih, 2019, 2019 International Conference on Frontiers of Information Technology (FIT), P77, DOI 10.1109/FIT47737.2019.00024
   Xin SA, 2008, INT C PATT RECOG, P2877
   Zanganeh O, 2014, 2014 INT C DIG IM CO, P1, DOI DOI 10.1109/DICTA.2014.7008121
   Zhang FD, 2019, PATTERN RECOGN LETT, V119, P139, DOI 10.1016/j.patrec.2017.09.014
   Zhou R, 2011, 2011 37 EUROPEAN C E, P1
   Zhou R, 2013, SENSORS-BASEL, V13, P3142, DOI 10.3390/s130303142
NR 57
TC 2
Z9 2
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17483
EP 17507
DI 10.1007/s11042-021-11686-2
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000765701900014
DA 2024-07-18
ER

PT J
AU Jiao, YP
   Li, JH
   Fei, SM
AF Jiao, Yiping
   Li, Junhong
   Fei, Shumin
TI Staining condition visualization in digital histopathological
   whole-slide images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Staining pattern; Whole-slide image; Computer-aided diagnosis; Digital
   pathology; Deep learning
ID COLOR; NORMALIZATION; PATHOLOGY
AB Staining condition is one of the essential properties in digital pathology for developing computer-aided diagnosis (CAD) systems; however, it is challenging to analyze the staining condition of giga-pixel whole-slide images (WSIs) due to the high data volume. In this study, we proposed an intuitive method to visualize the color style of Hematoxylin and Eosin (H&E) stained WSIs, which is scalable to large real-world cohorts. For this, representative color spectrums are obtained by K-means clustering on slide-level, and the pair-wise distance between spectrums is formulated as a matching problem. Lastly, we use multi-dimensional scaling (MDS) algorithm to obtain 2-dimensional embeddings for WSIs, which are suitable for visualization. We validated the method on lung adenocarcinoma cases and lung squamous-cell carcinoma cases in The Cancer Genome Atlas (TCGA) program. Through the well-visualized staining pattern map, slides with low staining quality or with abnormal staining conditions can be easily recognized. Furthermore, we give a demo usage of the proposed method in the context of a lung cancer segmentation task. Our main conclusions including, (1) biases in staining pattern distribution will harm the performance of CAD systems; (2) weakly stained slides are more challenging than heavily stained slides; (3) stain augmentation can deal with a certain level of staining variation, but not all of it; (4) light stain augmentation can generate more realistic training samples.
C1 [Jiao, Yiping] Nanjing Univ Informat Sci & Technol, Sch Artificial Intelligence, Nanjing, Peoples R China.
   [Jiao, Yiping; Fei, Shumin] Southeast Univ, Sch Automat, Nanjing, Peoples R China.
   [Li, Junhong] Zhengzhou Univ, Luoyang Cent Hosp, Luoyang, Peoples R China.
C3 Nanjing University of Information Science & Technology; Southeast
   University - China; Zhengzhou University
RP Fei, SM (corresponding author), Southeast Univ, Sch Automat, Nanjing, Peoples R China.
EM smfei@seu.edu.cn
CR Bándi P, 2019, PEERJ, V7, DOI 10.7717/peerj.8242
   Bándi P, 2017, I S BIOMED IMAGING, P591, DOI 10.1109/ISBI.2017.7950590
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Clarke EL, 2017, HISTOPATHOLOGY, V70, P153, DOI 10.1111/his.13079
   Di Franco C, 2017, IEEE INT CONF AUTON, P49, DOI 10.1109/ICARSC.2017.7964051
   Gadermayr M, 2019, IEEE T MED IMAGING, V38, P2293, DOI 10.1109/TMI.2019.2899364
   Gertych A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37638-9
   Hanna MG, 2019, MODERN PATHOL, V32, P916, DOI 10.1038/s41379-019-0205-0
   Jiao Yin, 2021, 2021 International Applied Computational Electromagnetics Society (ACES-China) Symposium, DOI 10.23919/ACES-China52398.2021.9582036
   Jiao YP, 2021, COMPUT METH PROG BIO, V204, DOI 10.1016/j.cmpb.2021.106047
   KHAN A, 2020, MEDICAL IMAGING 2020
   Khan AM, 2014, IEEE T BIO-MED ENG, V61, P1729, DOI 10.1109/TBME.2014.2303294
   Kingma D. P., 2014, arXiv
   Koledoye M. A., 2017, 2017 22 IEEE INT C E, P1, DOI DOI 10.1109/ETFA.2017.8247768
   Kothari S, 2011, I S BIOMED IMAGING, P657, DOI 10.1109/ISBI.2011.5872492
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lafarge MW, 2019, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00162
   Li B, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101938
   Li XY, 2015, IEEE T BIO-MED ENG, V62, P1862, DOI 10.1109/TBME.2015.2405791
   Litjens G, 2018, GIGASCIENCE, V7, DOI 10.1093/gigascience/giy065
   Macenko M, 2009, I S BIOMED IMAGING, P1107, DOI 10.1109/ISBI.2009.5193250
   Magee D, 2009, COLOUR NORMALISATION, V12
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.48550/ARXIV.1802.03426, 10.21105/joss.00861]
   Mukhopadhyay S, 2018, AM J SURG PATHOL, V42, P39, DOI 10.1097/PAS.0000000000000948
   Niethammer M, 2010, LECT NOTES COMPUT SC, V6357, P58, DOI 10.1007/978-3-642-15948-0_8
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy S, 2018, MICRON, V114, P42, DOI 10.1016/j.micron.2018.07.005
   Ruifrok AC, 2001, ANAL QUANT CYTOL, V23, P291
   Salvi M, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104129
   Salvi M, 2020, COMPUT METH PROG BIO, V193, DOI 10.1016/j.cmpb.2020.105506
   Senaras C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0205387
   Shin SJ, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105815
   Shrestha P, 2014, J MED IMAGING, V1, DOI 10.1117/1.JMI.1.2.027501
   Stacke K., 2019, ARXIV PREPRINT ARXIV
   Stacke K, 2021, IEEE J BIOMED HEALTH, V25, P325, DOI 10.1109/JBHI.2020.3032060
   Swiderska-Chadaj Z, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-71420-0
   Tellez D, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101544
   Tellez D, 2018, PROC SPIE, V10581, DOI 10.1117/12.2293048
   Tolkach Y, 2020, NAT MACH INTELL, V2, P411, DOI 10.1038/s42256-020-0200-7
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Yagi Y, 2011, DIAGN PATHOL, V6, DOI 10.1186/1746-1596-6-S1-S15
   Yang M, 2020, COMPUT MED IMAG GRAP, V84, DOI 10.1016/j.compmedimag.2020.101752
   Zarella MD, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174489
   Zhu J-Y, 2020, ARXIV170310593CS
NR 45
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17831
EP 17847
DI 10.1007/s11042-022-12559-y
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701900012
DA 2024-07-18
ER

PT J
AU Faragallah, OS
   El-Hoseny, H
   El-Shafai, W
   Abd El-Rahman, W
   El-sayed, HS
   El-Rabaie, ES
   Abd El-Samie, F
   Mahmoud, KR
   Geweid, GGN
AF Faragallah, Osama S.
   El-Hoseny, Heba
   El-Shafai, Walid
   Abd El-Rahman, Wael
   El-sayed, Hala S.
   El-Rabaie, El-Sayed
   Abd El-Samie, Fathi
   Mahmoud, Korany R.
   Geweid, Gamal G. N.
TI Optimized multimodal medical image fusion framework using multi-scale
   geometric and multi-resolution geometric analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; DWT; DT-CWT; NSST; NSCT; MCFO; Histogram equalization;
   Histogram matching
ID NONSUBSAMPLED CONTOURLET TRANSFORM; CONTRAST ENHANCEMENT; REGISTRATION
AB For proper homoeopathic identification of the medical image, image fusion has been proposed as a mandatory solution to obtain high-spectral and high-spectral spatial data. This article presents a complete fusion system for several types of medical images according to their multi-resolution, multi-scale transforms and the Modified Central Force Optimization (MCFO) technique. Four main techniques have been proposed for this purpose; Optimized Discrete Wavelet and Dual-Tree based fusion techniques as a multi-resolution transform. Besides, the optimized Non-Sub-Sampled Contourlet and Non-Sub-Sampled Shearlet as multi-scale fusion techniques. The perfect matching between input images and minimum artifacts after image registration can be achieved through four stages in the proposed fusion algorithms. First, the input medical image is initially decomposed into their coefficients, and the MCFO method establishes the optimal gain parameter values of the resulted coefficients. Finally, the adaptive histogram equalization and the histogram matching are applied for higher clearness and better visualization of information details. The proposed algorithms are evaluated using various datasets for different medical and surveillance applications through some quality metrics. The Experimental test outcomes indicate that the proposed fusion algorithms achieve good performance with high image quality and appreciated estimation metrics principles. Moreover, it provides better image visualization and minimum processing time, which helps diagnose diseases.
C1 [Faragallah, Osama S.] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 11099, At Taif 21944, Saudi Arabia.
   [El-Hoseny, Heba] Al Obour High Inst Engn & Technol, Dept Elect & Elect Commun Engn, Cairo 3036, Egypt.
   [El-Shafai, Walid; El-Rabaie, El-Sayed; Abd El-Samie, Fathi] Menoufia Univ, Fac Elect Engn, Dept Elect & Commun Engn, Menoufia 32952, Egypt.
   [Abd El-Rahman, Wael; Geweid, Gamal G. N.] Benha Univ, Fac Engn, Elect Engn Dept, Banha 13512, Egypt.
   [El-sayed, Hala S.] Menoufia Univ, Fac Engn, Dept Elect Engn, Shibin Al Kawm 32511, Egypt.
   [Mahmoud, Korany R.] Helwan Univ, Fac Engn, Dept Elect & Commun, Cairo, Egypt.
   [Geweid, Gamal G. N.] Embry Riddle Aeronaut Univ, Worldwide Coll Aeronaut, Dept Engn & Technol, Daytona Beach, FL 32114 USA.
C3 Taif University; Egyptian Knowledge Bank (EKB); Menofia University;
   Egyptian Knowledge Bank (EKB); Benha University; Egyptian Knowledge Bank
   (EKB); Menofia University; Egyptian Knowledge Bank (EKB); Helwan
   University; Embry-Riddle Aeronautical University
RP Faragallah, OS (corresponding author), Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 11099, At Taif 21944, Saudi Arabia.
EM o.salah@tu.edu.sa
RI El-Sayed, Hala S./GXG-7641-2022; Sayed, Fathi/HRA-4752-2023; El-Shafai,
   Walid/AAG-4796-2021; Mahmoud, Korany R./F-1455-2019; Faragallah, Osama
   S./AHB-8031-2022
OI El-Sayed, Hala S./0000-0002-2776-783X; Sayed, Fathi/0000-0001-8749-9518;
   El-Shafai, Walid/0000-0001-7509-2120; Mahmoud, Korany
   R./0000-0002-7113-1310; Faragallah, Osama S./0000-0003-1982-335X
FU Deanship of Scientific Research, Taif University Researchers Supporting
   Project, Taif University, Taif, Saudi Arabia [TURSP-2020/08]
FX This study was funded by the Deanship of Scientific Research, Taif
   University Researchers Supporting Project number (TURSP-2020/08), Taif
   University, Taif, Saudi Arabia.
CR [Anonymous], 2013, INT J INNOV TECHNOL
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Bick, 2015, THESIS U TOLEDO
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Daniel E, 2017, BIOMED SIGNAL PROCES, V34, P36, DOI 10.1016/j.bspc.2017.01.003
   Donia EA, 2016, 2016 FOURTH INTERNATIONAL JAPAN-EGYPT CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND COMPUTERS (JEC-ECC), P111, DOI 10.1109/JEC-ECC.2016.7518980
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Han YH, 2015, IEEE T IMAGE PROCESS, V24, P5114, DOI 10.1109/TIP.2015.2479917
   Hou RC, 2019, MED BIOL ENG COMPUT, V57, P887, DOI 10.1007/s11517-018-1935-8
   Huang B, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/8279342
   Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Kannan K, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P314, DOI 10.1109/ICCIMA.2007.143
   KoteswaraRao K., 2019, INT J INNOV TECHNOL, V9, P3075
   KoteswaraRao K, 2019, INT J INNOV TECHNOL, V9
   LEE DTL, 1994, HEWLETT-PACKARD J, V45, P44
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Li XH, 2021, J AMB INTEL HUM COMP, V12, P1995, DOI 10.1007/s12652-020-02293-4
   Liu Y, 2014, COMM COM INF SC, V484, P372
   Mahmoud KR, 2016, IET MICROW ANTENNA P, V10, P1011, DOI 10.1049/iet-map.2015.0801
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Rajalingam B., 2019, Procedia Computer Science, V152, P150, DOI 10.1016/j.procs.2019.05.037
   Shandoosti HR, 2019, BIOMED SIGNAL PROCES, V47, P63, DOI 10.1016/j.bspc.2018.08.017
   Singh A, 2016, 2016 FOURTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P291, DOI 10.1109/PDGC.2016.7913162
   Singh S, 2019, INT J IMAG SYST TECH, V29, P50, DOI 10.1002/ima.22294
   Singh T., 2013, INT J ADV ENGG TECH, V50, P52
   Song HJ, 2017, PATTERN RECOGN LETT, V94, P15, DOI 10.1016/j.patrec.2017.04.021
   Sotiras A, 2013, IEEE T MED IMAGING, V32, P1153, DOI 10.1109/TMI.2013.2265603
   Suganya R., 2010, International Journal of Computer Applications, V1, P1, DOI [10.5120/432-637, DOI 10.5120/432-637]
   Wang A, 2006, IEEE INT C NETW SENS, P270
   Wang Y, 2017, INFRARED PHYS TECHN, V86, P59, DOI 10.1016/j.infrared.2017.08.005
   Wang Z, 2006, 8 IEEE INT C SIGN PR, V2
   Wu AM, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1029
   Xing X., 2016, INT J SIGNAL PROCESS, V9, P61
   Yang HY, 2007, IEEE NUCL SCI CONF R, P3951, DOI 10.1109/NSSMIC.2007.4436982
   Yang L, 2008, NEUROCOMPUTING, V72, P203, DOI 10.1016/j.neucom.2008.02.025
   Yong Chai, 2008, 2008 2nd International Conference on Bioinformatics and Biomedical Engineering (ICBBE '08), P2064
   Zhang YY, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/807527
   Zheng YZ, 2007, PROCEEDINGS OF THE 5TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P362
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 41
TC 14
Z9 14
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14379
EP 14401
DI 10.1007/s11042-022-12260-0
EA FEB 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300006
DA 2024-07-18
ER

PT J
AU Yu, NN
   Li, JJ
   Hua, Z
AF Yu, Nana
   Li, Jinjiang
   Hua, Zhen
TI Decolorization algorithm based on contrast pyramid transform fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Decolorization; Image fusion; Contrast pyramid
ID QUALITY ASSESSMENT; IMAGE; GRAYSCALE
AB The purpose of decolorization is to convert a color image into a grayscale image while maintaining the contrast and structural characteristics of the original color image as much as possible. This paper proposes a decolorization method based on contrast pyramid transform fusion. Image fusion based on contrast tower decomposition is performed on different spatial frequency bands, so it is possible to obtain a fusion effect closer to human visual characteristics. First, we extract the R, G and B channel images of the original color image and the initial grayscale image. Then, we perform Laplacian pyramid fusion of the R, G and B channel images of the original color image with the initial grayscale image to obtain three images. Finally, the three images obtained are reconstructed by contrast pyramid fusion, and our result image is obtained. The visual comparison and quantitative experimental results show that the proposed contrast pyramid fusion decolorization method is more robust, can fully maintain image details and other information, and reduce the distortion in the process of fusion and decolorization.
C1 [Yu, Nana; Hua, Zhen] Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai, Peoples R China.
   [Li, Jinjiang] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai, Peoples R China.
   [Hua, Zhen] ICT Yantai, Inst Network Technol, Yantai, Peoples R China.
C3 Shandong Technology & Business University; Shandong Technology &
   Business University
RP Li, JJ (corresponding author), Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai, Peoples R China.
EM lijinjiang@gmail.com
RI Hua, Zhen/ABG-8734-2021
FU National Natural Science Foundation of China [61772319, 62002200,
   61976125, 61976124, 12001327]; Shandong Natural Science Foundation of
   China [ZR2020QF012]
FX The authors acknowledge the National Natural Science Foundation of China
   (61772319, 62002200, 61976125, 61976124 and 12001327), and Shandong
   Natural Science Foundation of China (Grant no. ZR2020QF012).
CR Ancuti C, 2018, IEEE ACCESS, V6, P64071, DOI 10.1109/ACCESS.2018.2876373
   Biswas, 2019, INT C COMP VIS IM PR, P73
   Cadík M, 2008, COMPUT GRAPH FORUM, V27, P1745
   Cai BL, 2018, IEEE IMAGE PROC, P2810, DOI 10.1109/ICIP.2018.8451303
   Everingham M., 2011, PATTERN ANAL STAT MO, V8, P5
   FAIRCHILD MD, 1991, COLOR RES APPL, V16, P385, DOI 10.1002/col.5080160608
   García-Fernández AF, 2020, IEEE T SIGNAL PROCES, V68, P3917, DOI 10.1109/TSP.2020.3005309
   Gooch AA, 2005, ACM T GRAPHIC, V24, P634, DOI 10.1145/1073204.1073241
   Guan XD, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22010060
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Kim Y.J., 2009, ACCESS CONTROL SERVI, P1
   Li XX, 2020, IEEE T INSTRUM MEAS, V69, P6880, DOI 10.1109/TIM.2020.2975405
   Li YW, 2019, IEEE ACCESS, V7, P91912, DOI 10.1109/ACCESS.2019.2927032
   Liu QG, 2019, VISUAL COMPUT, V35, P205, DOI 10.1007/s00371-017-1464-8
   Liu QG, 2017, IEEE T IMAGE PROCESS, V26, P5772, DOI 10.1109/TIP.2017.2745104
   Liu QG, 2017, IEEE T CIRC SYST VID, V27, P1856, DOI 10.1109/TCSVT.2016.2555779
   Liu QG, 2015, IEEE T IMAGE PROCESS, V24, P2889, DOI 10.1109/TIP.2015.2423615
   Liu SG, 2019, IEEE T MULTIMEDIA, V21, P2461, DOI 10.1109/TMM.2019.2903413
   Lu CW, 2014, INT J COMPUT VISION, V110, P222, DOI 10.1007/s11263-014-0732-6
   Peter J, 2006, FUNDAMENTAL PAPERS W, V31, P28
   Saputra I., 2017, INT J ENG RES TECHNO, V6, P266
   Seo JW, 2013, IEEE IMAGE PROC, P2279, DOI 10.1109/ICIP.2013.6738470
   Shen JB, 2014, IEEE T CYBERNETICS, V44, P1579, DOI 10.1109/TCYB.2013.2290435
   Singh S, 2020, IEEE T INSTRUM MEAS, V69, P3855, DOI 10.1109/TIM.2019.2933341
   Sirichotedumrong W., 2018, IEEE INT C MULTIMEDI, P1
   Tang RZ, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010040
   Wang Q., 2020, P IEEE CVF C COMP VI, P8326, DOI [DOI 10.1109/CVPR42600.2020.00835, 10.1109/CVPR42600.2020.00835]
   Wang W, 2020, IEEE T IMAGE PROCESS, V29, P1776, DOI 10.1109/TIP.2019.2939946
   Wang W, 2018, IEEE T IMAGE PROCESS, V27, P5464, DOI 10.1109/TIP.2018.2855424
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao RX, 2017, COMPUT METH PROG BIO, V142, P157, DOI 10.1016/j.cmpb.2017.02.008
   Yu J, 2021, MULTIMED TOOLS APPL, V80, P31753, DOI 10.1007/s11042-021-11172-9
   Yuan F, 2021, SIGNAL PROCESS-IMAGE, V91, DOI 10.1016/j.image.2020.116082
   Zhao R, 2021, IEEE T IMAGE PROCESS, V30, P6081, DOI 10.1109/TIP.2021.3091902
   Zhou M., 2014, Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific, P1, DOI 10.1109/OCEANS.2014.7003239
NR 35
TC 4
Z9 5
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15017
EP 15039
DI 10.1007/s11042-022-12189-4
EA FEB 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000761979300026
DA 2024-07-18
ER

PT J
AU Qin, XQ
   Liu, DK
   Wang, D
AF Qin, Xiaoqian
   Liu, Dakun
   Wang, Dong
TI A novel factor analysis-based metric learning method for kinship
   verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinship verification; Metric learning; Factor analysis
ID FACE; SIMILARITY; DEEP; FEATURES; SUBSPACE; SUBJECT
AB This paper presents a novel factor analysis-based metric learning (FAML) method for kinship verification. While metric learning has achieved reasonably good performance in kinship verification, most existing metric learning methods ignore to discover semantically meaningful similarity-patterns for kinship pairwise data. To address this, we propose a FAML method to seek hidden local similarity metrics, under which kin pairs would be relatively correlated and similar in certain facial regions. Particularly, to learn such local similarity metrics, we apply a series of transformations such as orthogonal rotation and thresholding to the factor loading matrix obtained through factor analysis. Moreover, instead of only seeking metrics in a local sense, we aim to simultaneously learn a set of distance metrics to integrate the locality with the globality, thus being more robust for diversified similarity-patterns that kin pairs contain. To jointly perform genetic characteristics exploiting and metric learning, we present an efficient algorithm that employs alternating optimization to integrate prior knowledge about genetic characteristics into metric learning, such that more discriminative information can be exploited in more fine-grained details for verification. Experiments are carried out on three face kinship datasets, and the results achieved clearly demonstrate the effectiveness of the proposed method.
C1 [Qin, Xiaoqian] Huaiyin Normal Univ, 111 Changjiang West Rd, Huaian 223300, Peoples R China.
   [Liu, Dakun] Yancheng Inst Technol, Hope Rd 1 Middle Rd, Yancheng 224051, Peoples R China.
   [Wang, Dong] Guangdong Univ Technol, 100 Waihuan Xi Rd, Guangzhou 510006, Peoples R China.
C3 Huaiyin Normal University; Yancheng Institute of Technology; Guangdong
   University of Technology
RP Qin, XQ (corresponding author), Huaiyin Normal Univ, 111 Changjiang West Rd, Huaian 223300, Peoples R China.
EM qinxiaoqian@hytc.edu.cn
FU National Natural Science Foundation of China [61803170, 62006046];
   Natural Science Foundation of Jiangsu Province, China [BK20181067];
   Humanities and Social Sciences Planning Foundation from the Ministry of
   Education of China [18YJAZH070]
FX We thank the anonymous reviewers for your in-depth comments,
   suggestions, and corrections, which have greatly improved the
   manuscript. This work was supported by the National Natural Science
   Foundation of China(Grant No.61803170, No.62006046), the Natural Science
   Foundation of Jiangsu Province, China(Grant No.BK20181067), and the
   Humanities and Social Sciences Planning Foundation from the Ministry of
   Education of China(Grant No.18YJAZH070).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2014, P ACCV
   [Anonymous], 2017, VISUAL COMMUN-US
   [Anonymous], 2014, IDENTITY KINSHIP REL
   [Anonymous], 2017, COMPUT VIS IMAGE UND
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Basilevsky A.T., 2009, STAT FACTOR ANAL REL, V418
   Bessaoudi M, 2020, APPL INTELL
   Chechik G, 2010, J MACH LEARN RES, V11, P1109
   Chowdary MK, 2023, NEURAL COMPUT APPL, V35, P23311, DOI 10.1007/s00521-021-06012-8
   Dehghan A, 2014, PROC CVPR IEEE, P1757, DOI 10.1109/CVPR.2014.227
   Dibeklioglu H, 2013, IEEE I CONF COMP VIS, P1497, DOI 10.1109/ICCV.2013.189
   Dornaika F., 2019, NEURAL COMPUT APPL
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Gao XY, 2014, AAAI CONF ARTIF INTE, P1206
   Gupta Surbhi, ARCH COMPUT METHOD E, P1
   Hu JL, 2019, IEEE IMAGE PROC, P1178, DOI [10.1109/ICIP.2019.8803754, 10.1109/icip.2019.8803754]
   Hu JL, 2018, IEEE T CIRC SYST VID, V28, P1875, DOI 10.1109/TCSVT.2017.2691801
   Hu JL, 2018, IEEE T PATTERN ANAL, V40, P2281, DOI 10.1109/TPAMI.2017.2749576
   Jia D, 2011, PROC CVPR IEEE, P785, DOI 10.1109/CVPR.2011.5995516
   Kohli N., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P245, DOI 10.1109/BTAS.2012.6374584
   Kou L, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/472473
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Laiadi O, 2020, NEUROCOMPUTING, V377, P286, DOI 10.1016/j.neucom.2019.10.055
   Laiadi O, 2019, APPL INTELL, V49, P3894, DOI 10.1007/s10489-019-01489-2
   Liang JQ, 2019, IEEE T IMAGE PROCESS, V28, P1149, DOI 10.1109/TIP.2018.2875346
   Liu KH, 2019, IEEE T IMAGE PROCESS, V28, P5187, DOI 10.1109/TIP.2019.2916768
   Liu Q, 2016, INT C INTEL HUM MACH, P17, DOI 10.1109/IHMSC.2016.93
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu J, 2015, 2015 IEEE INT C AUT
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Qin X., 2020, APPL SOFT COMPUT, V95, P1
   Qin XQ, 2020, NEUROCOMPUTING, V377, P213, DOI 10.1016/j.neucom.2019.09.089
   Qin XQ, 2019, APPL SOFT COMPUT, V77, P344, DOI 10.1016/j.asoc.2019.01.027
   Qin XQ, 2018, NEURAL PROCESS LETT, V47, P1253, DOI 10.1007/s11063-017-9694-3
   Qin XQ, 2016, NEUROCOMPUTING, V214, P350, DOI 10.1016/j.neucom.2016.06.027
   Qin XQ, 2015, IEEE T MULTIMEDIA, V17, P1855, DOI 10.1109/TMM.2015.2461462
   Sellam A, 2020, MULTIMED TOOLS APPL, V79, P20861, DOI 10.1007/s11042-020-08906-6
   Shao M, 2014, INT J COMPUT VISION, V109, P74, DOI 10.1007/s11263-014-0696-6
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Syed, 2014, INT J SCI RES ED, V2
   Wang SW, 2020, PATTERN RECOGN LETT, V138, P38, DOI 10.1016/j.patrec.2020.06.019
   Wang SY, 2019, IEEE T PATTERN ANAL, V41, P2783, DOI [10.1109/INTMAG.2018.8508542, 10.1109/TNNLS.2017.2771290, 10.1109/TPAMI.2018.2861871]
   Xia S., 2011, Proceedings of the 22nd International Joint Conference on Artificial Intelligence, P2539, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-422
   Xia SY, 2012, INT C PATT RECOG, P549
   Xia SY, 2012, IEEE T MULTIMEDIA, V14, P1046, DOI 10.1109/TMM.2012.2187436
   Xu M, 2016, IEEE ACCESS, V4, P10280, DOI 10.1109/ACCESS.2016.2635147
   Xu M, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/4072323
   Yan HB, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107541
   Yan HB, 2017, IMAGE VISION COMPUT, V60, P91, DOI 10.1016/j.imavis.2016.08.009
   Yan HB, 2014, IEEE T INF FOREN SEC, V9, P1169, DOI 10.1109/TIFS.2014.2327757
   Yan Huimin, 2014, ISRN Endocrinol, V2014, P864897, DOI 10.1155/2014/864897
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P3916, DOI 10.1109/ICCV.2015.446
   Zhou X., 2011, ACM Multimedia, P953
   Zhou XZ, 2019, INFORM FUSION, V48, P84, DOI 10.1016/j.inffus.2018.07.011
   Zhou Xiuzhuang, 2012, P 20 ACM INT C MULT, P725, DOI [DOI 10.1145/2393347, DOI 10.1145/2393347.2396297]
NR 57
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11049
EP 11070
DI 10.1007/s11042-022-12032-w
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757200200007
DA 2024-07-18
ER

PT J
AU Dhole, NV
   Dixit, VV
AF Dhole, Nandini Vaibhav
   Dixit, Vaibhav V.
TI Review of brain tumor detection from MRI images with hybrid approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Gliomas; Threshold based segmentation; Hybrid approach; Machine
   learning; Deep learning
ID SEGMENTATION; CLASSIFICATION; IDENTIFICATION; TRANSFORM
AB One of the most common approaches in medical research is to detect a brain tumor and its growth from an MRI of the brain. Therefore, the process of scanning brain images from the internal structure of the human brain provides information about the growth of brain tumors. The manual detection of brain tumor from the MRI is a challenging task in the medical research field because the tumor also causes high changes in internal and external structure of the brain. For that purpose, it is proposed to review the detection of brain tumor from MRI images by using hybrid computerized approaches. Therefore, brain tumor growth performance and analysis are described to generalize symptoms and guide diagnosis towards a treatment plan. Several approaches for the segmentation process of MRI are discussed from existing papers, the detection of brain tumors can be concluded.
C1 [Dhole, Nandini Vaibhav] Shri Jagdish Prasad Jhabarmal Tibrewala Univ, Churela, Rajasthan, India.
   [Dixit, Vaibhav V.] RMD Sinhgad Sch Engn, Pune, Maharashtra, India.
RP Dhole, NV (corresponding author), Shri Jagdish Prasad Jhabarmal Tibrewala Univ, Churela, Rajasthan, India.
EM nandini.dhole@gmail.com
CR Abbasi S, 2017, NEUROCOMPUTING, V219, P526, DOI 10.1016/j.neucom.2016.09.051
   Akkus Z, 2017, J DIGIT IMAGING, V30, P469, DOI 10.1007/s10278-017-9984-3
   Alam M., 2018, 4 INT C ADV COMP COM, P1
   Amin Javeria, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P983, DOI 10.1007/s12652-018-1092-9
   Amin J, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1483-2
   Amin J, 2018, FUTURE GENER COMP SY, V87, P290, DOI 10.1016/j.future.2018.04.065
   Angulakshmi M, 2018, Journal of King Saud University-Computer and Information Sciences
   Anil A., 2019, INT J INNOVATIVE RES, V3, P458, DOI [DOI 10.29027/IJIRASE.V3.I2.2019, 10.29027/IJIRASE.v3.i2.2019.458-465]
   Anitha R, 2018, INT J IMAG SYST TECH, V28, P48, DOI 10.1002/ima.22255
   [Anonymous], 2016, J BIOMEDICAL ENG MED, DOI DOI 10.14738/jbemi.31.1696
   Ansari MA, 2020, J INTERDISCIP MATH, V23, P955, DOI 10.1080/09720502.2020.1723921
   Arce-Santana ER, 2019, MED BIOL ENG COMPUT, V57, P565, DOI 10.1007/s11517-018-1896-y
   Aruna SK, 2020, SOFT COMPUT, V24, P7827, DOI 10.1007/s00500-019-04403-7
   Aswathy SU, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P871, DOI 10.1109/ICCICCT.2014.6993081
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Bhattacharyya D, 2011, COMM COM INF SC, V151, P307
   Bourouis S, 2020, INFORMATION, V11, DOI 10.3390/info11030155
   Chaddad A, 2015, INT J BIOMED IMAGING, V2015, DOI 10.1155/2015/868031
   Chauhan S, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN SIGNAL PROCESSING AND EMBEDDED SYSTEMS (RISE), P223, DOI 10.1109/RISE.2017.8378158
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Chengliang Dai, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P156, DOI 10.1007/978-3-030-59719-1_16
   Çinar A, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109684
   Deb D, 2021, MULTIMED TOOLS APPL, V80, P2621, DOI 10.1007/s11042-020-09810-9
   Duffau H, 2016, ACTA NEUROCHIR, V158, P51, DOI 10.1007/s00701-015-2621-3
   Eide PK, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25666-4
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   Fernandes SL, 2020, NEURAL COMPUT APPL, V32, P15897, DOI 10.1007/s00521-019-04369-5
   Gautam A, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102178
   George D.N, 2015, Int J Sci Eng Res, V6, P454
   Gholami A, 2016, J MATH BIOL, V72, P409, DOI 10.1007/s00285-015-0888-x
   Grist JT, 2019, NEUROIMAGE, V189, P171, DOI 10.1016/j.neuroimage.2019.01.027
   Hands JR, 2016, J NEURO-ONCOL, V127, P463, DOI 10.1007/s11060-016-2060-x
   Hemanth G., 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1289, DOI 10.1109/ICOEI.2019.8862553
   Hu TY, 2017, ONCOTARGETS THER, V10, P5463, DOI 10.2147/OTT.S139243
   Ilhan U, 2017, PROCEDIA COMPUT SCI, V120, P580, DOI 10.1016/j.procs.2017.11.282
   Kabir MA, 2020, IEEE REGION 10 SYMP, P1828
   Kanmani P, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0915-8
   Kaur Chahal P, 2020, EFFICIENT HADOOP BAS
   Kharlov A. V., 2009, 2009 IEEE 36th International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2009.5227445
   Kondyli M, 2018, J NEURO-ONCOL, V140, P435, DOI 10.1007/s11060-018-2971-9
   Kumar DM, 2021, J AMB INTEL HUM COMP, V12, P2867, DOI 10.1007/s12652-020-02444-7
   Kumar S, 2017, PROCEDIA COMPUT SCI, V122, P510, DOI 10.1016/j.procs.2017.11.400
   Lipp ES, 2019, J NEUROPATH EXP NEUR, V78, P57, DOI 10.1093/jnen/nly110
   Liu Luyan, 2016, Med Image Comput Comput Assist Interv, V9901, P26, DOI 10.1007/978-3-319-46723-8_4
   M Malathi, 2018, Asian Pac J Cancer Prev, V19, P3257
   Machhale K, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P60, DOI 10.1109/IIC.2015.7150592
   Mano A, 2020, IET IMAGE PROCESS, V14, P2901, DOI 10.1049/iet-ipr.2019.1234
   Moraru LA, 2017, IEEE SENS J, V17, P4886, DOI 10.1109/JSEN.2017.2714701
   Myronenko A, 2019, LECT NOTES COMPUT SC, V11384, P311, DOI 10.1007/978-3-030-11726-9_28
   Nandi A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, VISION AND INFORMATION SECURITY (CGVIS), P55, DOI 10.1109/CGVIS.2015.7449892
   Narayana T. Lakshmi, 2018, 2018 International Conference on Smart Systems and Inventive Technology (ICSSIT), P168, DOI 10.1109/ICSSIT.2018.8748288
   Nasor M, 2020, INT J BIOMED IMAGING, V2020, DOI 10.1155/2020/9035096
   Nazir M, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P434, DOI 10.1109/iccisci.2019.8716413
   Ozawa M, 2018, FAM PRACT, V35, P551, DOI 10.1093/fampra/cmx139
   Özyurt F, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109433
   Ozyurt F, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.07.058
   Petovari G, 2019, PATHOL ONCOL RES, V26, P1
   Praveen GB, 2015, 2015 COMMUNICATION, CONTROL AND INTELLIGENT SYSTEMS (CCIS), P162, DOI 10.1109/CCIntelS.2015.7437900
   Reddy Nanda Gopal, 2018, International Journal of Reasoning-based Intelligent Systems, V10, P252
   Roy S, 2015, IEEE J BIOMED HEALTH, V19, P1598, DOI 10.1109/JBHI.2015.2439242
   Sajid S, 2019, ARAB J SCI ENG, V44, P9249, DOI 10.1007/s13369-019-03967-8
   Sawant Aaswad., 2018, BRAIN, V5
   Sayah B, 2014, INT J BIOMED ENG TEC, V14, P71, DOI 10.1504/IJBET.2014.059060
   Sharma K., 2014, IOSR J. Eng., V4, P06
   Sharma M, 2018, LECT NOTE DATA ENG, V4, P145, DOI 10.1007/978-981-10-4600-1_14
   Sheeba SL, DETECTION EXACT LOCA
   Shekhar S, 2018, 2018 INTERNATIONAL CONFERENCE ON POWER ENERGY, ENVIRONMENT AND INTELLIGENT CONTROL (PEEIC), P670, DOI 10.1109/PEEIC.2018.8665627
   Singh A, 2016, INT J ENG APPL SCI T
   Soltaninejad M, 2017, INT J COMPUT ASS RAD, V12, P183, DOI 10.1007/s11548-016-1483-3
   Sreedhanya S., 2017, INT J APPL INFORM SY, V11, P6
   Subudhi BN, 2016, MAGN RESON IMAGING, V34, P1292, DOI 10.1016/j.mri.2016.07.002
   Suganya, 2016, BRAIN, V5, P68
   Tarhini GM., 2020, INT J SIGNAL PROCESS, V8, P19, DOI [10.18178/ijsps.8.1.19-25, DOI 10.18178/IJSPS.8.1.19-25]
   Varuna Shree N, 2018, BRAIN INFORM, V5, P23, DOI DOI 10.1007/S40708-017-0075-5
   Vigneshwari K., 2021, TURKISH J COMPUTER M, V12, P5639
   Wan C., 2017, 2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI), P1
   Yanagihara TK, 2016, AM J NEURORADIOL, V37, P2019, DOI 10.3174/ajnr.A4873
   Zotin A, 2018, PROCEDIA COMPUT SCI, V126, P1261, DOI 10.1016/j.procs.2018.08.069
NR 78
TC 9
Z9 9
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 10189
EP 10220
DI 10.1007/s11042-022-12162-1
EA FEB 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800001
DA 2024-07-18
ER

PT J
AU Das, S
   Saha, SK
AF Das, Sayan
   Saha, Sanjoy Kumar
TI Diabetic retinopathy detection and classification using CNN tuned by
   genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal fundus images; Diabetic retinopathy detection; Design of CNN
   parameters; Genetic algorithm
ID FUNDUS IMAGES; SEGMENTATION; FRAMEWORK
AB The Proposed work intends to automate the detection and classification of diabetic retinopathy from retinal fundus image which is very important in ophthalmology. Most of the existing methods use handcrafted features and those are fed to the classifier for detection and classification purpose. Recently convolutional neural network (CNN) is used for this classification problem but the architecture of CNN is manually designed. In this work, a genetic algorithm based technique is proposed to automatically determine the parameters of CNN and then the network is used for classification of diabetic retinopathy. The proposed CNN model consists of a series of convolution and pooling layer used for feature extraction. Finally support vector machine (SVM) is used for classification. Hyper-parameters like number of convolution and pooling layer, number of kernel and kernel size of convolution layer are determined by using the genetic algorithm. The proposed methodology is tested on publicly available Messidor dataset. The proposed method has achieved accuracy of 0.9867 and AUC of 0.9933. Experimental result shows that proposed auto-tuned CNN performs significantly better than the existing methods. Use of CNN takes away the burden of designing the image features and on the other hand genetic algorithm based methodology automates the design of CNN hyper-parameters.
C1 [Das, Sayan; Saha, Sanjoy Kumar] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, W Bengal, India.
C3 Jadavpur University
RP Das, S (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, W Bengal, India.
OI Das, Sayan/0000-0003-0505-8589
CR Agurto C, 2010, IEEE T MED IMAGING, V29, P502, DOI 10.1109/TMI.2009.2037146
   Antal B, 2012, J COMPUT SCI-NETH, V3, P262, DOI 10.1016/j.jocs.2012.01.001
   Araújo T, 2020, IEEE ACCESS, V8, P182462, DOI 10.1109/ACCESS.2020.3028960
   Baliarsingh SK, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107009
   Baliarsingh SK, 2020, COMPUT METH PROG BIO, V195, DOI 10.1016/j.cmpb.2020.105625
   Baliarsingh SK, 2020, IET SYST BIOL, V14, P85, DOI 10.1049/iet-syb.2019.0028
   Barriga ES, 2010, I S BIOMED IMAGING, P1349, DOI 10.1109/ISBI.2010.5490247
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   COSTA P, 2017, IPSJ T COMPUTER VISI, P165
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Fageeri SO, 2017, 2017 INT C COMM CONT, P1
   Hacisoftaoglu RE, 2020, PATTERN RECOGN LETT, V135, P409, DOI 10.1016/j.patrec.2020.04.009
   Hall Anthony, 2011, Community Eye Health, V24, P5
   HARDY KJ, 1994, BRIT J OPHTHALMOL, V78, P754, DOI 10.1136/bjo.78.10.754
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   JayaKumari C, 2012, PROCEDIA ENGINEER, V30, P297, DOI 10.1016/j.proeng.2012.01.864
   Jebari K., 2013, International Journal of Emerging Sciences, V3, P333, DOI DOI 10.14355/ijes.2013.0305.05
   Kalpic D., 2011, International encyclopedia of statistical science, P1559, DOI DOI 10.1007/978-3-642-04898-2_641
   Kamble VV, 2020, PROCEDIA COMPUT SCI, V167, P799, DOI 10.1016/j.procs.2020.03.429
   Köse C, 2012, COMPUT METH PROG BIO, V107, P274, DOI 10.1016/j.cmpb.2011.06.007
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazar I, 2013, IEEE T MED IMAGING, V32, P400, DOI 10.1109/TMI.2012.2228665
   Leng JB, 2016, PROC INT C TOOLS ART, P1027, DOI [10.1109/ICTAI.2016.155, 10.1109/ICTAI.2016.0158]
   Mrunalini M. M., 2016, Int. Res. J. Eng. Technol, V3, P547
   Parul NS., 2015, INT J COMPUTER SCI M, V4, P158
   Patel P, 2016, NAT C EM RES TRENDS, P406
   Priya R., 2013, ICTACT J. Soft Comput., V3, P563, DOI [10.21917/ijsc.2013.0083, DOI 10.21917/IJSC.2013.0083]
   Qomariah DUN, 2019, PROCEEDINGS OF 2019 12TH INTERNATIONAL CONFERENCE ON INFORMATION & COMMUNICATION TECHNOLOGY AND SYSTEM (ICTS), P152, DOI [10.1109/ICTS.2019.8850940, 10.1109/icts.2019.8850940]
   Quellec G, 2012, MED IMAGE ANAL, V16, P1228, DOI 10.1016/j.media.2012.06.003
   Rocha A, 2012, IEEE T BIO-MED ENG, V59, P2244, DOI 10.1109/TBME.2012.2201717
   Roychowdhury S, 2014, IEEE J BIOMED HEALTH, V18, P1717, DOI 10.1109/JBHI.2013.2294635
   Sánchez CI, 2011, INVEST OPHTH VIS SCI, V52, P4866, DOI 10.1167/iovs.10-6633
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sopharak A, 2009, SCIENCEASIA, V35, P80, DOI 10.2306/scienceasia1513-1874.2009.35.080
   Sopharak A, 2008, COMPUT MED IMAG GRAP, V32, P720, DOI 10.1016/j.compmedimag.2008.08.009
   Sun JG, 2018, INT CONF DIGIT SIG
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang L, 2013, IEEE T MED IMAGING, V32, P364, DOI 10.1109/TMI.2012.2227119
   Tavakoli M, 2013, PATTERN RECOGN, V46, P2740, DOI 10.1016/j.patcog.2013.03.011
   Vert JP., 2004, Kernel methods in computational biology, V47, P35
   Vijayan T., 2020, Microprocess. Microsyst, P103353, DOI [10.3390/s22145103, DOI 10.1016/J.MICPRO.2020.103353, 10.1016/j.micpro.2020.103353]
   Wankhade, 2016, INT J ENG COMPUT SCI, V5, P12
   Yazid H, 2012, MEASUREMENT, V45, P1599, DOI 10.1016/j.measurement.2012.02.016
NR 46
TC 25
Z9 26
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8007
EP 8020
DI 10.1007/s11042-021-11824-w
EA JAN 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749055500006
DA 2024-07-18
ER

PT J
AU Liu, BS
   Liu, XL
   Ren, H
   Qian, JB
   Wang, YY
AF Liu, Baisong
   Liu, Xiaoling
   Ren, Hao
   Qian, Jiangbo
   Wang, YangYang
TI Text multi-label learning method based on label-aware attention and
   semantic dependency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-label Learning; Label Correlations; Attention mechanism; Deep
   Learning; Graph Convolutional Networks
ID INFORMATION ENTROPY; CLASSIFICATION
AB Text multi-label learning deals with examples having multiple labels simultaneously. It can be applied to many fields, such as text categorization, medical diagnosis recognition and topic recommendation. Existing multi-label learning methods treat a label as an atomic symbol without considering semantic information, while labels are texts with semantic information composed of words, which can guide to obtain discriminative text features. In order to select discriminatory features from redundant content, we consider the semantic labels and establish the relationship between labels and texts based on the attention mechanism. Label relationship modeling helps to further improve the model's effectiveness and we model the high label relationship based on the principle of graph convolutional networks (GCN). Then the LAA_SD method is proposed, which combines enhanced text feature representation with label semantic dependency to perform text multi-label learning. A comparative study with state-of-the-art approaches manifests the competitive performance of the proposed model.
C1 [Liu, Baisong; Liu, Xiaoling; Ren, Hao; Qian, Jiangbo; Wang, YangYang] Ningbo Univ, Dept Comp Sci & Engn, Ningbo 315211, Peoples R China.
C3 Ningbo University
RP Liu, BS (corresponding author), Ningbo Univ, Dept Comp Sci & Engn, Ningbo 315211, Peoples R China.
EM lbs@nbu.edu.cn
RI liu, xiao/HMD-7454-2023; Qian, Jiangbo/AAY-9587-2021; liu,
   xiao/HKE-9880-2023; Liu, Xiaoling/HGD-3566-2022
OI Qian, Jiangbo/0000-0003-4245-3246; 
FU Zhejiang NSF [LZ20F020001]; China NSF [61472194]; K.C. Wong Magna Fund
   in Ningbo University
FX I would like to express my gratitude to my supervisor, Prof.Liu, who has
   given the most scientific suggestions and supervision. He also
   critically reviewed the study proposal and made necessary writing
   assistance. Then I am greatly indebted to the postgraduate Hao Ren for
   participating in technical editing and necessary corrections. And I also
   owe a lot to Prof.Qian, who has shown much consideration for the
   research and has helped with the acquisition of funding. Finally, I
   would like to express my thanks to engineer Wang for his excellent
   technical assistance and data curation. This work was supported in part
   by Zhejiang NSF Grant No. LZ20F020001, China NSF Grants No. 61472194 as
   well as programs sponsored by K.C. Wong Magna Fund in Ningbo University.
CR Cheng YS, 2018, NEUROCOMPUTING, V321, P92, DOI 10.1016/j.neucom.2018.09.033
   Chu H M, 2018, DEEP GENERATIVE MODE, P400
   Dai L, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4634
   Dong H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1348
   Du CX, 2019, AAAI CONF ARTIF INTE, P6359
   Gan Y, 2018, INT C COLL COMP NETW, P133
   Guo L, 2018, LECT NOTES COMPUT SC, V11157, P571, DOI 10.1007/978-3-030-00847-5_42
   Ho Y, 2020, IEEE ACCESS, V8, P4806, DOI 10.1109/ACCESS.2019.2962617
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Huang J, 2019, INFORM SCIENCES, V492, P124, DOI 10.1016/j.ins.2019.04.021
   Huang SJ, 2019, IEEE T PATTERN ANAL, V41, P2614, DOI 10.1109/TPAMI.2018.2861732
   Lian SM, 2019, APPL SOFT COMPUT, V74, P709, DOI 10.1016/j.asoc.2018.10.035
   Liu JZ, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P115, DOI 10.1145/3077136.3080834
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Madroual D., 2018, J SYST ARCHITECT, V30, P40
   Pereira RB, 2018, ARTIF INTELL REV, V49, P57, DOI 10.1007/s10462-016-9516-4
   Prabhu Y, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P441, DOI 10.1145/3159652.3159660
   Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   [宋攀 Song Pan], 2018, [计算机研究与发展, Journal of Computer Research and Development], V55, P1751
   Teisseyre P, 2017, NEUROCOMPUTING, V235, P98, DOI 10.1016/j.neucom.2017.01.004
   Wang HW, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3307, DOI 10.1145/3308558.3313417
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wu MC, 2020, J SYST ARCHITECT, V103, DOI 10.1016/j.sysarc.2019.101695
   Yan Y, 2018, NEURAL PROCESS LETT, V47, P117, DOI 10.1007/s11063-017-9636-0
   Yang P C, 2018, SGM SEQUENCE GENERAT, P3915
   Yang WY, 2017, J NETW COMPUT APPL, V86, P59, DOI 10.1016/j.jnca.2016.10.002
   You XD, 2019, L N INST COMP SCI SO, V290, P96, DOI [10.1007/9.78-3-030-28468-8_8, 10.1007/978-3-030-28468-8_8]
   Zaiane O, 2016, INT C HYBRID INTELLI, P244
   Zhang Q, 2018, INT C PATT RECOG, P1018, DOI 10.1109/ICPR.2018.8545106
   Zhang Z., 2018, NEURIPS
   Zhao B, 2018, NEUROCOMPUTING, V322, P47, DOI 10.1016/j.neucom.2018.09.048
   Zheng KF, 2018, PATTERN RECOGN, V77, P20, DOI 10.1016/j.patcog.2017.12.008
NR 34
TC 3
Z9 5
U1 0
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7219
EP 7237
DI 10.1007/s11042-021-11663-9
EA JAN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000746780700011
DA 2024-07-18
ER

PT J
AU Mishra, S
   Beheshti, I
   Tanveer, M
   Khanna, P
AF Mishra, Shiwangi
   Beheshti, Iman
   Tanveer, M.
   Khanna, Pritee
TI 3D Supervoxel based features for early detection of AD: A microscopic
   view to the brain MRI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's disease; AD detection; Brain MRI; Brain region selection;
   Hippocampus; Amygdala; VBM; Supervoxel; Volumetric features
ID ALZHEIMERS-DISEASE DIAGNOSIS; STRUCTURAL MRI; CLASSIFICATION; IMAGES;
   SEGMENTATION; DESCRIPTORS; HIPPOCAMPUS; PREDICTION; SELECTION; MODELS
AB Introduction: Alzheimer's disease (AD) is a chronic form of the neurodegenerative disease marked by atrophy in different brain regions. A region-wise analysis is essential for performing AD detection, as each brain region has different functionalities depending on its location. This work aims to investigate supervoxel based volumetric features in place of traditional voxel-based features from the vital brain regions. Methods: In this work, the whole brain structural magnetic resonance imaging (MRI) is segmented into 116 regions using atlas-based segmentation. Important atrophic regions are used for further analysis based on a region ranking procedure from these segmented regions. The focus of this study is to perform supervoxel based partitioning for attaining features prominent for AD detection. Volumetric features are extracted from supervoxels belonging to the selected regions. An optimal feature set is obtained by using the support vector machine recursive elimination (SVM-RFE) method, and classification is performed using SVM. Results: ADNI dataset is used for experimentation. Results are obtained by iteratively fusing the features extracted from vital brain regions. The highest classification accuracy of 90.11%, the sensitivity of 86.11%, and the specificity of 93.4% are obtained by fusing features extracted from hippocampus and amygdala regions. Discussion: The highest classification accuracy reported in this work for AD detection is obtained by fusing features of the four most important regions, i.e., hippocampus and amygdala, in both left and right hemispheres. These regions are also known to affect the consolidation of memory and decision-making in medical science. Experimental results evaluated on the standard dataset depict that the proposed method performs better than the traditional as well as state-of-the-art methods.
C1 [Mishra, Shiwangi; Khanna, Pritee] PDPM Indian Inst Informat Technol Design & Mfg, Jabalpur, India.
   [Mishra, Shiwangi] Jabalpur Engn Coll, Jabalpur, India.
   [Beheshti, Iman] Univ Manitoba, Winnipeg, MB, Canada.
   [Tanveer, M.] Indian Inst Technol Indore, Dept Math, Simrol, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; University of Manitoba; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (IIT) - Indore
RP Khanna, P (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Jabalpur, India.
EM pkhanna@iiitdmj.ac.in
RI Tanveer, Mohammad/I-4585-2013; Beheshti, Iman/GQZ-3345-2022; Khanna,
   Pritee/V-5418-2019
OI Tanveer, Mohammad/0000-0002-5727-3697; Beheshti,
   Iman/0000-0003-4750-3433; Khanna, Pritee/0000-0003-0518-2133
FU Collaborative Research Scheme (CRS) of TEQIP III, a Government of India
   [1-5739421811]; Alzheimer's Disease Neuroimaging Initiative (ADNI)
   (National Institutes of Health) [U01 AG024904]; DOD ADNI (Department of
   Defense award) [W81XWH-12-2-0012]
FX This research is supported by the Collaborative Research Scheme (CRS) of
   TEQIP III, a Government of India project assisted by the World Bank,
   with CRS Project ID 1-5739421811. Data used in this study
   (www.adni-info.org) is a collection funded by the Alzheimer's Disease
   Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01
   AG024904) and DOD ADNI (Department of Defense award number
   W81XWH-12-2-0012).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alzheimer's Assoc, 2018, ALZHEIMERS DEMENT, V14, P367, DOI 10.1016/j.jalz.2018.02.001
   Ashburner, VBM TUTORIAL TECH RE
   Beheshti I, 2015, COMPUT BIOL MED, V64, P208, DOI 10.1016/j.compbiomed.2015.07.006
   Ben Ahmed O, 2015, COMPUT MED IMAG GRAP, V44, P13, DOI 10.1016/j.compmedimag.2015.04.007
   Bland JM, 1999, STAT METHODS MED RES, V8, P135, DOI 10.1177/096228029900800204
   Cai J-H, ACAD RADIOL
   Chupin M, 2009, HIPPOCAMPUS, V19, P579, DOI 10.1002/hipo.20626
   Dekosky ST, 2003, SCIENCE, V302, P830, DOI 10.1126/science.1090349
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Fan Y, 2008, NEUROIMAGE, V39, P1731, DOI 10.1016/j.neuroimage.2007.10.031
   Ferri R, 2021, CLIN NEUROPHYSIOL, V132, P232, DOI 10.1016/j.clinph.2020.09.015
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hu K, 2016, NEUROCOMPUTING, V175, P132, DOI 10.1016/j.neucom.2015.10.043
   Humeau-Heurtier A, 2019, IEEE ACCESS, V7, P8975, DOI 10.1109/ACCESS.2018.2890743
   Martinez-Murcia FJ, 2017, COMM COM INF SC, V723, P470, DOI 10.1007/978-3-319-60964-5_41
   Jha Debesh, 2016, [Journal of Korean Institute of Information Technology, 한국정보기술학회논문지], V14, P121, DOI 10.14801/jkiit.2016.14.8.121
   Khedher L, 2015, NEUROCOMPUTING, V151, P139, DOI 10.1016/j.neucom.2014.09.072
   Kohavi R., 1995, STUDY CROSS VALIDATI, DOI DOI 10.1067/MOD.2000.109031
   Krashenyi I, 2016, CURR ALZHEIMER RES, V13, P545, DOI 10.2174/1567205013666160314145008
   Kumar CTS, 2019, INDIAN J PSYCHOL MED, V41, P476, DOI 10.4103/IJPSYM.IJPSYM_25_19
   Lancaster JL, 2000, HUM BRAIN MAPP, V10, P120, DOI 10.1002/1097-0193(200007)10:3<120::AID-HBM30>3.0.CO;2-8
   Liu CF, 2019, MAGN RESON IMAGING, V64, P190, DOI 10.1016/j.mri.2019.07.003
   Livens S., 1997, Sixth International Conference on Image Processing and its Applications (Conf. Publ. No.443), P581, DOI 10.1049/cp:19970958
   Luk Collin C, 2018, Alzheimers Dement (Amst), V10, P755, DOI 10.1016/j.dadm.2018.09.002
   Maldjian JA, 2003, NEUROIMAGE, V19, P1233, DOI 10.1016/S1053-8119(03)00169-1
   Matsuda H, 2012, AM J NEURORADIOL, V33, P1109, DOI 10.3174/ajnr.A2935
   Mishra S, 2020, MODELLING ANAL ACTIV, V1, P2053, DOI [10.1088/978-0-7503-3279-8ch15, DOI 10.1088/978-0-7503-3279-8CH15]
   Mishra S, 2018, INT J IMAG SYST TECH, V28, P302, DOI 10.1002/ima.22290
   MOHS RC, 1983, PSYCHOPHARMACOL BULL, V19, P448
   Nanni L, 2019, ARTIF INTELL MED, V97, P19, DOI 10.1016/j.artmed.2019.05.003
   Nazeri A, 2014, NEUROIMAGE, V102, P657, DOI 10.1016/j.neuroimage.2014.08.041
   Toro CAO, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061752
   Simoes R, 2014, NEURORADIOLOGY, V56, P709, DOI 10.1007/s00234-014-1385-4
   Soltaninejad M, 2018, COMPUT METH PROG BIO, V157, P69, DOI 10.1016/j.cmpb.2018.01.003
   Spillantini MG, 1998, TRENDS NEUROSCI, V21, P428, DOI 10.1016/S0166-2236(98)01337-X
   Taki Y, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0022734
   Tian ZQ, 2017, MED PHYS, V44, P558, DOI 10.1002/mp.12048
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Vaithinathan K, 2019, J NEUROSCI METH, V318, P84, DOI 10.1016/j.jneumeth.2019.01.011
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Wei TY, 2018, TRENDS BIOTECHNOL, V36, P290, DOI 10.1016/j.tibtech.2017.11.004
   Yigit A, 2020, TURK J ELECTR ENG CO, V28, P196, DOI 10.3906/elk-1904-172
   Zhang J, 2012, BRAIN IMAGING BEHAV, V6, P61, DOI 10.1007/s11682-011-9142-3
   Zhang YD, 2015, BIOMED SIGNAL PROCES, V21, P58, DOI 10.1016/j.bspc.2015.05.014
NR 46
TC 0
Z9 0
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22481
EP 22496
DI 10.1007/s11042-021-11871-3
EA JAN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000745425000002
DA 2024-07-18
ER

PT J
AU Ravi, S
   Shreenidhi, S
   Shahina, A
   Ilakiyaselvan, N
   Khan, AN
AF Ravi, Sriya
   Shreenidhi, S.
   Shahina, A.
   Ilakiyaselvan, N.
   Khan, A. Nayeemulla
TI Epileptic seizure detection using convolutional neural networks and
   recurrence plots of EEG signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Epilepsy; Seizure detection; Electroencephalogram; Non-linear dynamic
   analysis; Pre-ictal & Ictal activity detection; Recurrence plots;
   Convolutional neural networks; ResNet
AB Epilepsy is a neurological disorder causing abnormal activities in the brain such as seizures, unusual behavior, sensations and loss of awareness. This disorder can be diagnosed with help of the Electroencephalogram (EEG) which evaluates the electrical activity in the brain, which is considered a dynamical system. The epileptic neuronal networks are made up of complex non-linear structures whose non-linear behavior manifests in the EEG signal. Due to the chaotic and non-linear nature of the EEG signal, we propose the use of Recurrence Plots (RP) to capture the non-linear dynamics in the EEG. Recurrence is a fundamental property of dynamical systems and contains information about the system behavior. The Recurrence Plots are a tool for the visualization and analysis of the dynamic system's behavior. The ResNet ensemble trained on these Recurrence Plots attains cent percent accuracy in most class combination scenarios such as normal vs epileptic or pre-ictal vs ictal. Likewise, the sensitivity and specificity are also 100% in most class combination scenarios. Such a model can assist in the diagnosis of the disease and can also give an early alert to the patient on the onset of seizure.
C1 [Ravi, Sriya; Shreenidhi, S.; Ilakiyaselvan, N.; Khan, A. Nayeemulla] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
   [Shahina, A.] Sri Sivasubramanya Nadar Coll Engn, Dept IT, Kalavakkam 603110, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Ilakiyaselvan, N (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
EM sriya.r2017@vitstudent.ac.in; s.shreenidhi2017@vitstudent.ac.in;
   shahinaa@ssn.edu.in; ilakiyaselvan.n@vit.ac.in;
   nayeemulla.khan@vit.ac.in
OI A, Shahina/0000-0003-4862-6611
CR Acharya UR, 2011, INT J NEURAL SYST, V21, P199, DOI 10.1142/S0129065711002808
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   Brenner RJ, 2000, RADIOL CLIN N AM, V38, P741, DOI 10.1016/S0033-8389(05)70198-6
   Carrington AM, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-019-1014-6
   Dias D, 2019, INT GEOSCI REMOTE SE, P1310, DOI [10.1109/IGARSS.2019.8898128, 10.1109/igarss.2019.8898128]
   Frid-Adar M, 2017, LECT NOTES COMPUT SC, V10530, P129, DOI 10.1007/978-3-319-67434-6_15
   Gao XZ, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101711
   Goebel R, 2018, LECT NOTES COMPUT SC, V11015, P295, DOI 10.1007/978-3-319-99740-7_21
   Hatami N, 2018, PROC SPIE, V10696, DOI 10.1117/12.2309486
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Ilakiyaselvan N, 2020, J BIOMED RES, V34, P240, DOI 10.7555/JBR.34.20190043
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim S, 2018, 2018 INTERNATIONAL CONFERENCE ON CONTROL AND ROBOTS (ICCR), P78, DOI 10.1109/ICCR.2018.8534487
   Kumar Y, 2014, SIGNAL IMAGE VIDEO P, V8, P1323, DOI 10.1007/s11760-012-0362-9
   Liu L, 2019, INT J COMPUT VISION, V127, P74, DOI 10.1007/s11263-018-1125-z
   Liu YZ, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P1025
   Obeid I, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00196
   Obot IB, 2019, J ADHES SCI TECHNOL, V33, P1453, DOI 10.1080/01694243.2019.1587224
   QUESNEY LF, 1988, ACTA NEUROL SCAND, V78, P52, DOI 10.1111/j.1600-0404.1988.tb08004.x
   Rodriguez-Bermudez G., 2015, Applied Mathematics and Information Science, V9, P2309, DOI DOI 10.12785/AMIS/090512
   SAMMARITANO M, 1987, ANN NEUROL, V21, P361, DOI 10.1002/ana.410210408
   Sharma M, 2017, PATTERN RECOGN LETT, V94, P172, DOI 10.1016/j.patrec.2017.03.023
   Sharmila A, 2016, IEEE ACCESS, V4, P7716, DOI 10.1109/ACCESS.2016.2585661
   Stam CJ, 2005, CLIN NEUROPHYSIOL, V116, P2266, DOI 10.1016/j.clinph.2005.06.011
   Swami P, 2016, EXPERT SYST APPL, V56, P116, DOI 10.1016/j.eswa.2016.02.040
   Torse Dattaprasad A., 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0611, DOI 10.1109/ICCSP.2019.8697989
   Valente A C., 2019, Electronic Imaging, V2019, P406
NR 27
TC 7
Z9 7
U1 3
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6585
EP 6598
DI 10.1007/s11042-021-11608-2
EA JAN 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000742803700004
DA 2024-07-18
ER

PT J
AU Kwon, H
   Kim, Y
AF Kwon, Hyun
   Kim, Yongchul
TI BlindNet backdoor: Attack on deep neural network using blind watermark
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural network; Poisoning attack; Backdoor attack; Machine learning
   security; Causative attack
AB Deep neural network (DNNs) provide excellent performance in image recognition, speech recognition, video recognition, and pattern analysis. However, DNNs are vulnerable to backdoor attacks. A backdoor attack allows a DNN to correctly recognize normal data that do not contain a specific trigger but induces it to incorrectly recognize data that do contain the trigger. An advantage of the backdoor attack is that the attacker can determine the time of attack by using a specific trigger. In this paper, we propose a blind-watermark backdoor method whose results are imperceptible to humans. Unlike existing methods, the proposed method avoids the human detectability of the backdoor sample attack by making the trigger invisible. In this method, a blind-watermarked sample is generated by inserting a trigger consisting of a specific image in a frequency band into input data by using a Fourier transform. By additionally training on the blind-watermarked sample during the training process, the target model learns to incorrectly classify any sample with the specific watermark. For testing, we used the CIFAR10 dataset and the Tensorflow machine learning library. In the experiment, when the proportion of blind-watermarked samples in the training data was 10%, the proposed method resulted in 88.9% classification accuracy by the model on the original samples and a 99.3% attack success rate via training with the blind-watermarked samples.
C1 [Kwon, Hyun; Kim, Yongchul] Korea Mil Acad, Dept Elect Engn, 574 Hwarang Ro, Seoul 01819, South Korea.
RP Kwon, H (corresponding author), Korea Mil Acad, Dept Elect Engn, 574 Hwarang Ro, Seoul 01819, South Korea.
EM hkwon.cs@gmail.com; kyc6454@mnd.go.kr
RI Kwon, Hyun/M-1140-2018
OI Kwon, Hyun/0000-0003-1169-9892
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2021R1I1A1A01040308]
FX This work was supported By Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (2021R1I1A1A01040308).
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   [Anonymous], 2017, ARXIV170904114
   Barreno M, 2010, MACH LEARN, V81, P121, DOI 10.1007/s10994-010-5188-5
   Bhunia S, 2014, P IEEE, V102, P1229, DOI 10.1109/JPROC.2014.2334493
   Biggio B., 2012, ARXIV12066389, P1467
   Bracewell R. N., 1986, The Fourier Transform and Its Applications, Part of McGraw-Hill Series on Electrical Engineering, Networks and Systems
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Clements Joseph, 2018, arXiv preprint arXiv: 1806.05768
   COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding SH, 2019, L N INST COMP SCI SO, V304, P299, DOI 10.1007/978-3-030-37228-6_15
   GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Gu Tianyu, 2017, P MACH LEARN COMP SE
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Krizhevsky A., 2014, The CIFAR-10 dataset, V55
   Kumar A, 2019, INT J CLOUD APPL COM, V9, P22, DOI 10.4018/IJCAC.2019070102
   Kurakin Alexey, 2017, INT C LEARN REPR
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Liu YQ, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23291
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Mozaffari-Kermani M, 2015, IEEE J BIOMED HEALTH, V19, P1893, DOI 10.1109/JBHI.2014.2344095
   Nuding F, 2020, PROCEEDINGS OF THE TENTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY, CODASPY 2020, P168, DOI 10.1145/3374664.3379534
   Nussbaumer HJ, 1981, FAST FOURIER TRANSFO, P80, DOI DOI 10.1007/978-3-662-00551-4_4
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Rehman H, 2019, LECT NOTES COMPUT SC, V11713, P285, DOI 10.1007/978-3-030-29726-8_18
   Rozsa A, 2019, PATTERN RECOGN LETT, V124, P100, DOI 10.1016/j.patrec.2017.10.024
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang B., 2019, INT J HIGH PERFORM C, V14, P265, DOI [10.1504/IJHPCN.2019.102126, DOI 10.1504/IJHPCN.2019.102126]
   Wang BL, 2019, P IEEE S SECUR PRIV, P707, DOI 10.1109/SP.2019.00031
   Xia J, 2020, MOL INFORM, V39, DOI 10.1002/minf.201900151
   Yang C, 2017, Generative poisoning attack method against neural networks
   Zhou Z, 2019, INT J HIGH PERFORM C, V14, P1, DOI [10.1504/IJHPCN.2019.10025200, DOI 10.1504/IJHPCN.2019.099740]
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 41
TC 27
Z9 28
U1 3
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6217
EP 6234
DI 10.1007/s11042-021-11135-0
EA JAN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000739790700001
DA 2024-07-18
ER

PT J
AU Keskinarkaus, A
   Yang, RJ
   Fylakis, A
   Surat-E-Mostafa, M
   Hautala, A
   Hu, Y
   Peng, JY
   Zhao, GY
   Seppänen, T
   Karppinen, J
AF Keskinarkaus, Anja
   Yang, Ruijing
   Fylakis, Angelos
   Surat-E-Mostafa, Md
   Hautala, Arto
   Hu, Yong
   Peng, Jinye
   Zhao, Guoying
   Seppanen, Tapio
   Karppinen, Jaro
TI Pain fingerprinting using multimodal sensing: pilot study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low back pain; Machine learning; Facial expression; Audio analysis;
   Heart rate; Electroencephalography
ID RECOGNITION; MECHANISMS
AB Pain is a complex phenomenon, the experience of which varies widely across individuals. At worst, chronic pain can lead to anxiety and depression. Cost-effective strategies are urgently needed to improve the treatment of pain, and thus we propose a novel home-based pain measurement system for the longitudinal monitoring of pain experience and variation in different patients with chronic low back pain. The autonomous nervous system and audio-visual features are analyzed from heart rate signals, voice characteristics and facial expressions using a unique measurement protocol. Self-reporting is utilized for the follow-up of changes in pain intensity, induced by well-designed physical maneuvers, and for studying the consecutive trends in pain. We describe the study protocol, including hospital measurements and questionnaires and the implementation of the home measurement devices. We also present different methods for analyzing the multimodal data: electroencephalography, audio, video and heart rate. Our intention is to provide new insights using technical methodologies that will be beneficial in the future not only for patients with low back pain but also patients suffering from any chronic pain.
C1 [Keskinarkaus, Anja; Yang, Ruijing; Fylakis, Angelos; Surat-E-Mostafa, Md; Hautala, Arto; Zhao, Guoying; Seppanen, Tapio] Univ Oulu, Fac Informat Technol & Elect Engn, Ctr Machine Vis & Signal Anal CMVS, Oulu, Finland.
   [Yang, Ruijing; Peng, Jinye] Northwest Univ, Sch Informat Sci & Technol, Xian, Peoples R China.
   [Hautala, Arto] Univ Jyvaskyla, Fac Sport & Hlth Sci, Jyvaskyla, Finland.
   [Hu, Yong] Univ Hong Kong, Li Ka Shing Fac Med, Dept Orthopaed & Traumatol, Neural Engn & Clin Electrophysiol Lab,Pok Fu Lam, Hong Kong, Peoples R China.
   [Karppinen, Jaro] Oulu Univ Hosp, Med Res Ctr Oulu, Oulu, Finland.
   [Karppinen, Jaro] Univ Oulu, Oulu, Finland.
C3 University of Oulu; Northwest University Xi'an; University of Jyvaskyla;
   University of Hong Kong; University of Oulu; University of Oulu
RP Keskinarkaus, A (corresponding author), Univ Oulu, Fac Informat Technol & Elect Engn, Ctr Machine Vis & Signal Anal CMVS, Oulu, Finland.
EM anja.keskinarkaus@oulu.fi; ruijing.yang@oulu.fi;
   angelos.fylakis@oulu.fi; mmostafa@student.oulu.fi;
   arto.j.hautala@jyu.fi; yhud@hku.hk; pjy@nwu.edu.cn;
   guoying.zhao@oulu.fi; tapio.seppanen@oulu.fi; jaro.karppinen@oulu.fi
RI Hu, Yong/KDM-6411-2024; Peng, Jin/HZH-6965-2023; Hautala,
   Arto/AAF-4669-2021
OI Hautala, Arto/0000-0002-7648-0130; Keskinarkaus,
   Anja/0000-0002-1304-1413
FU University of Oulu; Oulu University Hospital; National Technology Agency
   of Finland (Business Finland)
FX Open Access funding provided by University of Oulu including Oulu
   University Hospital. University of Oulu, The National Technology Agency
   of Finland (Business Finland).
CR Al-Eidan RM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175984
   [Anonymous], 1997, IPO ANN PROGR REPORT
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Apkarian AV, 2005, EUR J PAIN, V9, P463, DOI 10.1016/j.ejpain.2004.11.001
   Aung MSH, 2016, IEEE T AFFECT COMPUT, V7, P435, DOI 10.1109/TAFFC.2015.2462830
   Bijur PE, 2001, ACAD EMERG MED, V8, P1153, DOI 10.1111/j.1553-2712.2001.tb01132.x
   Caraceni A, 2002, J PAIN SYMPTOM MANAG, V23, P239, DOI 10.1016/S0885-3924(01)00409-2
   Chang YT, 2015, FRONT MICROBIOL, V6, DOI 10.3389/fmicb.2015.00893
   Chu Y., 2014, IFAC Proceedings Volumes, V47, P2981
   Fairbank JCT, 2000, SPINE, V25, P2940, DOI 10.1097/00007632-200011150-00017
   Garland EL, 2012, PRIMARY CARE, V39, P561, DOI 10.1016/j.pop.2012.06.013
   Gawande A., 2010, The checklist manifesto: how to get things right
   Gruss S, 2019, JOVE-J VIS EXP, DOI 10.3791/59057
   Haefeli M, 2006, EUR SPINE J, V15, pS17, DOI 10.1007/s00586-005-1044-x
   Haque MA, 2018, IEEE INT CONF AUTOMA, P250, DOI 10.1109/FG.2018.00044
   Kuner R, 2010, NAT MED, V16, P1258, DOI 10.1038/nm.2231
   Kunz M, 2019, PAIN, V160, P535, DOI 10.1097/j.pain.0000000000001424
   Lee J, 2019, PAIN, V160, P550, DOI 10.1097/j.pain.0000000000001417
   Li JL, 2018, INTERSPEECH, P3438, DOI 10.21437/Interspeech.2018-1298
   Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Oshrat Y., 2016, C PROC 8 SPEECH PROS, P420, DOI DOI 10.21437/SPEECHPROSODY.2016-86
   Osterweis M., 1987, PAIN DISABILITY CLIN, DOI 10.17226/991
   Schmidt B, 2009, NEUROSCI LETT, V460, P237, DOI 10.1016/j.neulet.2009.05.068
   Shu L, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072074
   Södervall J, 2013, BMC MUSCULOSKEL DIS, V14, DOI 10.1186/1471-2474-14-149
   Tarvainen MP, 2008, USERS GUIDE KUBIOS H
   Thiam P, 2021, IEEE T AFFECT COMPUT, V12, P743, DOI 10.1109/TAFFC.2019.2892090
   Toivanen J, 2004, LANG SPEECH, V47, P383, DOI 10.1177/00238309040470040301
   Tsai FS, 2017, INT CONF AFFECT, P313, DOI 10.1109/ACII.2017.8273618
   Velana Maria., 2016, IAPR Workshop on Multimodal Pattern Recognition of Social Signals in Human-Computer Interaction, P127
   Walter Steffen, 2013, 2013 IEEE International Conference on Cybernetics (CYBCO), P128, DOI 10.1109/CYBConf.2013.6617456
   Werner P, 2022, IEEE T AFFECT COMPUT, V13, P530, DOI 10.1109/TAFFC.2019.2946774
   Werner P, 2017, IEEE T AFFECT COMPUT, V8, P286, DOI 10.1109/TAFFC.2016.2537327
   Zhang Z, 2016, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2016.374
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 35
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5717
EP 5742
DI 10.1007/s11042-021-11761-8
EA DEC 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000735722700002
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Mandal, PC
   Mukherjee, I
AF Mandal, Pratap Chandra
   Mukherjee, Imon
TI High capacity data hiding based on multi-directional pixel value
   differencing and decreased difference expansion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Steganography; Multi-directional pixel value differencing;
   Decreased difference expansion; Steganalysis
ID ATTACKS
AB Data hiding is an important research topic over the years. The PVD based techniques embed secret data into the cover image on the difference between the two neighboring pixels. Most of the PVD based techniques are unidirectional that signifies less embedding capacity. The embedding capacity of the PVD technique is utilized in this article to embed the data in multi-directions. To improve the embedding capacity, a new high capacity data hiding technique based on decreased difference expansion (DDE) method and the multidirectional pixel value differencing (MPVD) is proposed. It is based on the block embedding technique for embedding data in the non-sequential locations. The cover image is divided into 2 x 2 non-overlapping blocks. A basic pixel is selected and data hiding takes place in three pixel pairs containing the basic pixel. Distortion due to message embedding is high in the difference expansion (DE) based data hiding techniques. DDE method improves the DE method by reducing the difference between two pixels with a logarithm function and hence increases the quality of the images compared to the DE method. The proposed technique achieves an average embedding capacity of 2.88 bpp which is higher than several recent state-of-the-art works. It withstands the tests of StirMark Benchmark 4.0, and the steganalysis attacks.
C1 [Mandal, Pratap Chandra] BP Poddar Inst Management & Technol, Dept Comp Sci & Engn, Kolkata 700059, India.
   [Mandal, Pratap Chandra; Mukherjee, Imon] Indian Inst Informat Technol Kalyani, Dept Comp Sci & Engn, Kalyani 741235, W Bengal, India.
C3 B. P. Poddar Institute of Management & Technology
RP Mukherjee, I (corresponding author), Indian Inst Informat Technol Kalyani, Dept Comp Sci & Engn, Kalyani 741235, W Bengal, India.
EM imon@iiitkalyani.ac.in
RI Mandal, Pratap/ABF-8743-2021; Mukherjee, Imon/AFP-2409-2022
OI Mandal, Pratap/0000-0003-4777-9288; Mukherjee, Imon/0000-0002-8598-148X
CR Al-Dhamari A. K., 2017, J SOFTWARE ENG APPL, V10, P56, DOI DOI 10.4236/JSEA.2017.101004
   [Anonymous], IM BOSSBASE 1 01 DAT
   Arham A, 2017, SIGNAL PROCESS, V137, P52, DOI 10.1016/j.sigpro.2017.02.001
   Boehmm E, 2014, Stegexpose: A Tool for Detecting LSB Steganography
   Das Debashis, 2020, Proceedings of the Global AI Congress 2019. Advances in Intelligent Systems and Computing (AISC 1112), P501, DOI 10.1007/978-981-15-2188-1_39
   Das S, 2019, PATTERN RECOGN LETT, V126, P102, DOI 10.1016/j.patrec.2018.06.026
   Mukherjee N, 2020, MULTIMED TOOLS APPL, V79, P13449, DOI 10.1007/s11042-019-08178-9
   Grajeda-Marín IR, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418600108
   Hassaballah M., 2020, Digital Media Steganography, P17, DOI [DOI 10.1016/B978-0-12-819438-6.00010-4, 10.1016/b978-0-12-819438-6.00010-4]
   Hu Yi, 2009, Proceedings of the 2009 9th International Conference on Electronic Measurement & Instruments (ICEMI 2009), P4, DOI 10.1109/ICEMI.2009.5274054
   Hussain M, 2021, MULTIMED TOOLS APPL, V80, P20381, DOI 10.1007/s11042-021-10652-2
   Images: University of Southern California, 2019, USC SIPI IMAGE DATAB
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2179, DOI 10.1007/s11042-014-2081-4
   Kang S, 2020, MULTIMED TOOLS APPL, V79, P21155, DOI 10.1007/s11042-020-08925-3
   Kharrazi M, 2006, LECT NOTES COMPUT SC, V4300, P123
   Kim C, 2014, MULTIMED TOOLS APPL, V69, P569, DOI 10.1007/s11042-012-1114-0
   Kim C, 2011, COMM COM INF SC, V186, P130
   Kumar N, 2022, MULTIMED TOOLS APPL, V81, P35027, DOI 10.1007/s11042-021-10832-0
   Kumar R, 2019, J INF SECUR APPL, V47, P94, DOI 10.1016/j.jisa.2019.04.007
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Li ZT, 2018, J INF SECUR APPL, V43, P47, DOI 10.1016/j.jisa.2018.10.006
   Liu HH, 2019, MULTIMED TOOLS APPL, V78, P12157, DOI 10.1007/s11042-018-6766-y
   Mandal PC, 2021, MULTIMED TOOLS APPL, P1
   Paul G, 2017, MULTIMED TOOLS APPL, V76, P7445, DOI 10.1007/s11042-016-3319-0
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Provos N., 2001, Detecting steganographic content on the internet
   Sahu AK, 2019, INT J ELECTRON SECUR, V11, P458, DOI 10.1504/IJESDF.2019.102567
   Sahu AK, 2019, WIRELESS PERS COMMUN, V108, P159, DOI 10.1007/s11277-019-06393-z
   Sahu AK, 2020, Digital Media Steganography, P41, DOI [10.1016/B978-0-12-819438-6.00011-6, DOI 10.1016/B978-0-12-819438-6.00011-6]
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Singh S, 2020, MULTIMED TOOLS APPL, V79, P18815, DOI 10.1007/s11042-020-08745-5
   Sonar R, 2021, SENS IMAGING, V22, DOI 10.1007/s11220-021-00334-6
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang WQ, 2020, MULTIMED TOOLS APPL, V79, P5965, DOI 10.1007/s11042-019-08255-z
   Wang YT, 2020, OPTIK, V213, DOI 10.1016/j.ijleo.2020.164685
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Zeng JS, 2014, AUTOMATICA, V50, P2777, DOI 10.1016/j.automatica.2014.09.005
   Zhou K, 2021, MULTIMED TOOLS APPL, V80, P1123, DOI 10.1007/s11042-020-09374-8
NR 39
TC 9
Z9 9
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5325
EP 5347
DI 10.1007/s11042-021-11605-5
EA DEC 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000731372100002
DA 2024-07-18
ER

PT J
AU Barbon, S Jr
   Pinto, A
   Barroso, JV
   Caetano, FG
   Moura, FA
   Cunha, SA
   Torres, RD
AF Barbon Junior, Sylvio
   Pinto, Allan
   Barroso, Joao Vitor
   Caetano, Fabio Giuliano
   Moura, Felipe Arruda
   Cunha, Sergio Augusto
   Torres, Ricardo da Silva
TI Sport action mining: Dribbling recognition in soccer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dribbling action detection; Soccer analysis; Association rules; Machine
   learning
ID PROFESSIONAL SOCCER; PLAYING TACTICS; MOVEMENT; TRACKING; VIDEOS
AB Recent advances in Computer Vision and Machine Learning empowered the use of image and positional data in several high-level analyses in Sports Science, such as player action classification, recognition of complex human movements, and tactical analysis of team sports. In the context of sports action analysis, the use of positional data allows new developments and opportunities by taking into account players' positions over time. Exploiting the positional data and its sequence in a systematic way, we proposed a framework that bridges association rule mining and action recognition. The proposed Sports Action Mining (SAM) framework is grounded on the usage of positional data for recognising actions, e.g., dribbling. We hypothesise that different sports actions could be modelled using a sequence of confidence levels computed from previous players' locations. The proposed method takes advantage of an association rule mining algorithm (e.g., FPGrowth) to generate displacement sequences for modelling actions in soccer. In this context, transactions are sequences of traces representing player displacements, while itemsets are players' coordinates on the pitch. The experimental results pointed out the Random Forest classifier achieved a balanced accuracy value of 93.3% for detecting dribbling actions, which are considered complex events in soccer. Additionally, the proposed framework provides insights on players' skills and player's roles based on a small amount of positional data.
C1 [Barbon Junior, Sylvio; Barroso, Joao Vitor] Londrina State Univ UEL, Dept Comp Sci, Londrina, Parana, Brazil.
   [Pinto, Allan; Cunha, Sergio Augusto] Univ Campinas Unicamp, Sch Phys Educ, Campinas, SP, Brazil.
   [Pinto, Allan] Univ Campinas Unicamp, Inst Comp, Campinas, SP, Brazil.
   [Caetano, Fabio Giuliano; Moura, Felipe Arruda] State Univ Londrina UEL, Sport Sci Dept, Londrina, Parana, Brazil.
   [Torres, Ricardo da Silva] NTNU Norwegian Univ Sci & Technol, Dept ICT & Naural Sci, Alesund, Norway.
C3 Universidade Estadual de Londrina; Universidade Estadual de Campinas;
   Universidade Estadual de Campinas; Universidade Estadual de Londrina;
   Norwegian University of Science & Technology (NTNU)
RP Barbon, S Jr (corresponding author), Londrina State Univ UEL, Dept Comp Sci, Londrina, Parana, Brazil.
EM barbon@uel.br; allan.pinto@ic.unicamp.br; barroso@uel.br;
   felipemoura@uel.br; scunha@unicamp.br; ricardo.torres@ntnu.no
RI Barbon Junior, Sylvio/L-6137-2013; Torres, Ricardo da S./C-4526-2012;
   Moura, Felipe/F-7128-2012; Caetano, Fabio Giuliano/AAF-1880-2020; Cunha,
   Sergio A./G-3210-2012
OI Barbon Junior, Sylvio/0000-0002-4988-0702; Moura,
   Felipe/0000-0002-0108-7246; Caetano, Fabio Giuliano/0000-0003-3602-9684;
   
FU Coordination for the National Council for Scientific and Technological
   Development (CNPq) of Brazil [420562/2018-4]; Fundacao Araucaria
   (Parana, Brazil); FAPESP [2016/50250-1, 2017/20945-0, 2018/19007-9,
   2019/16253-1, 2019/17729-0, 2019/22262-3]
FX This study was financed in part by Coordination for the National Council
   for Scientific and Technological Development (CNPq) of Brazil - Grant of
   Project 420562/2018-4 and FundacAo Araucaria (Parana, Brazil). We also
   thank the financial support of FAPESP (Grants #2016/50250-1,
   #2017/20945-0, #2018/19007-9, #2019/16253-1, #2019/17729-0, and
   #2019/22262-3).
CR Agrawal R., 1994, P INT VLDB C VLDB 94, P487, DOI DOI 10.5555/645920.672836
   Baccouche M, 2010, LECT NOTES COMPUT SC, V6353, P154
   Barros RML, 2007, J SPORT SCI MED, V6, P233
   Batista J, 2019, MONTENEGRIN J SPORT, V8, P29, DOI 10.26773/mjssm.190305
   Borgelt C., 2005, P 1 INT WORKSHOP OPE, P1, DOI DOI 10.1145/1133905.1133907
   Chawla S, 2017, ACM TRANS SPAT ALGOR, V3, DOI 10.1145/3105576
   Cioppa Anthony, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13123, DOI 10.1109/CVPR42600.2020.01314
   Connolly GJ., 2021, STRATEGIES, V34, P45, DOI [10.1080/08924562.2021.1896935, DOI 10.1080/08924562.2021.1896935]
   Cuevas C, 2020, MULTIMED TOOLS APPL, V79, P29685, DOI 10.1007/s11042-020-09409-0
   Cunha SA, 2011, FUTEBOL ASPECTOS MUL
   Cust EE, 2019, J SPORT SCI, V37, P568, DOI 10.1080/02640414.2018.1521769
   Davids K, 2013, EXERC SPORT SCI REV, V41, P154, DOI 10.1097/JES.0b013e318292f3ec
   de Barros RML, 2006, J BIOMECH, V39, P776, DOI 10.1016/j.jbiomech.2004.12.025
   Decroos T, 2017, AAAI CONF ARTIF INTE, P1302
   Duda R., 1973, Pattern Classification and Scene Analysis
   Fakhar B, 2019, MULTIMED TOOLS APPL, V78, P16995, DOI 10.1007/s11042-018-7083-1
   Feng N, 2020, MULTIMED TOOLS APPL, V79, P28971, DOI 10.1007/s11042-020-09414-3
   Figueroa PJ, 2003, COMPUT METH PROG BIO, V72, P155, DOI 10.1016/S0169-2607(02)00122-0
   Gan WS, 2019, ACM T KNOWL DISCOV D, V13, DOI 10.1145/3314107
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Giancola S, 2018, IEEE COMPUT SOC CONF, P1792, DOI 10.1109/CVPRW.2018.00223
   Goes FR, 2021, EUR J SPORT SCI, V21, P481, DOI 10.1080/17461391.2020.1747552
   Hosseini Monireh-Sadat, 2012, 2012 16th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP), P080, DOI 10.1109/AISP.2012.6313722
   Huang LC, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9014004
   Janetzko H, 2014, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2014.7042477
   Jiawei Han, 2000, SIGMOD Record, V29, P1, DOI 10.1145/335191.335372
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kim HJ, 2019, IEEE INT CONF CLOUD, P487, DOI 10.1109/CLOUD.2019.00086
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leal K, 2022, HUM MOV, V23, P10, DOI 10.5114/hm.2021.104182
   Li CY, 2020, MULTIMED TOOLS APPL, V79, P16771, DOI 10.1007/s11042-019-08361-y
   Li KP, 2019, ENERG CONVERS MANAGE, V197, DOI 10.1016/j.enconman.2019.111891
   Li XF, 2019, IEEE ACCESS, V7, P141319, DOI 10.1109/ACCESS.2019.2943817
   Link D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168768
   Lo TY, 2019, INT J PERF ANAL SPOR, V19, P216, DOI 10.1080/24748668.2019.1586504
   Maddala TKK, 2019, IEEE T MULTIMEDIA, V21, P2492, DOI 10.1109/TMM.2019.2904880
   Martin PE, 2020, MULTIMED TOOLS APPL, V79, P20429, DOI 10.1007/s11042-020-08917-3
   Memmert D, 2017, SPORTS MED, V47, P1, DOI 10.1007/s40279-016-0562-5
   Moura FA, 2014, J SPORT SCI, V32, P1881, DOI 10.1080/02640414.2013.853130
   Moura FA, 2012, SPORT BIOMECH, V11, P85, DOI 10.1080/14763141.2011.637123
   Raghunathan A., 2010, INT J COMPUTER APPL, V1, P20, DOI [10.5120/504-821, DOI 10.5120/504-821]
   Rein R, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3108-2
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Scheffer T., 2001, EUR C PRINC DAT MIN, P424, DOI DOI 10.1007/3-540-44794-6_35
   Stein M, 2019, LECT NOTES COMPUT SC, V11295, P130, DOI 10.1007/978-3-030-05710-7_11
   Stein M, 2015, ISPRS INT J GEO-INF, V4, P2159, DOI 10.3390/ijgi4042159
   Tenga A, 2010, J SPORT SCI, V28, P245, DOI 10.1080/02640410903502766
   Tenga A, 2010, J SPORT SCI, V28, P237, DOI 10.1080/02640410903502774
   Thurachon W, 2021, IEEE ACCESS, V9, P55726, DOI 10.1109/ACCESS.2021.3071777
   Tsunoda T, 2017, IEEE COMPUT SOC CONF, P155, DOI 10.1109/CVPRW.2017.25
   Vats K, 2019, 2019 16TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2019), P181, DOI 10.1109/CRV.2019.00032
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Wilson RS, 2019, J SPORT SCI, V37, P1072, DOI 10.1080/02640414.2018.1544110
   Zhu, 2003, FIMI, V90, P65
NR 55
TC 7
Z9 9
U1 6
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4341
EP 4364
DI 10.1007/s11042-021-11784-1
EA DEC 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000728243900002
DA 2024-07-18
ER

PT J
AU Zhao, MY
   Hu, ZP
   Li, SF
   Bi, S
   Sun, Z
AF Zhao, Mengyao
   Hu, Zhengping
   Li, Shufang
   Bi, Shuai
   Sun, Zhe
TI Mask attention-guided graph convolution layer for weakly supervised
   temporal action detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Temporal action detection; Graph convolutional network; Mask attention;
   Overall action distribution; Temporal relation; Feature fusion
ID SYSTEM
AB Graph convolutional network has been applied for temporal action detection. However, it is performed on the temporal context from the local view of segments containing incomplete actions, which weakens its ability to learn global representation. To alleviate this problem, a novel mask attention-guided graph convolution layer with the cooperation of local and global views is introduced. The graph weighted by feature similarity between segments is regarded as local view, while the global view takes the overall action distribution of the video as a guide to establish the relevance of all actions in a video. Via adding such a global guide, graph convolutional network can learn more discriminative spatio-temporal correlation representation, therefore, we propose mask attention-guided graph convolution layer for weakly supervised temporal action detection. Taking the segments features as the graph nodes, the mask attention-guided foreground-background graph and the transition-aware temporal mask graph are constructed, and then the segments association features and temporal context features are obtained, and finally cascaded and used for action detection. Experiments on the Thumos14 and Activitynet1.2 datasets achieve a mean average precision of 29.7% and 32.7% under the tIoU threshold 0.5, respectively. The results show that the proposed approach can effectively improve the performance of action detection.
C1 [Zhao, Mengyao; Hu, Zhengping; Li, Shufang; Bi, Shuai; Sun, Zhe] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao, Hebei, Peoples R China.
   [Hu, Zhengping; Sun, Zhe] Hebei Key Lab Informat Transmiss & Signal Proc, Qinhuangdao, Hebei, Peoples R China.
   [Li, Shufang] Hebei Univ Environm Engn, Dept Informat Engn, Qinhuangdao, Hebei, Peoples R China.
C3 Yanshan University; Hebei University of Environmental Engineering
RP Hu, ZP (corresponding author), Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao, Hebei, Peoples R China.; Hu, ZP (corresponding author), Hebei Key Lab Informat Transmiss & Signal Proc, Qinhuangdao, Hebei, Peoples R China.
EM hzp_ysu@163.com
FU National Natural Science Foundation of China [61771420, 62001413];
   Natural Science Foundation of Hebei Province [F2020203064]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61771420 and 62001413, as well as the Natural Science
   Foundation of Hebei Province under Grants F2020203064.
CR Fernando B, 2020, IEEE WINT CONF APPL, P526, DOI [10.1109/WACV45572.2020.9093263, 10.1109/wacv45572.2020.9093263]
   Ge YX, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107686
   HEILBRON FC, 2015, PROC CVPR IEEE, P961, DOI DOI 10.1109/CVPR.2015.7298698
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Huang LJ, 2020, AAAI CONF ARTIF INTE, V34, P11053
   Idrees H, 2017, COMPUT VIS IMAGE UND, V155, P1, DOI 10.1016/j.cviu.2016.10.018
   Islam A, 2020, IEEE WINT CONF APPL, P536, DOI 10.1109/WACV45572.2020.9093620
   Kang SJ, 2013, MULTIMED TOOLS APPL, V66, P383, DOI 10.1007/s11042-012-1052-x
   Lee P, 2020, AAAI CONF ARTIF INTE, V34, P11320
   Lei Y, 2019, MULTIMED TOOLS APPL, V78, P11047, DOI 10.1007/s11042-018-6665-2
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   Liu DC, 2019, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2019.00139
   Liu Z, 2021, PATTERN ANAL APPL, V24, P1793, DOI 10.1007/s10044-021-00987-9
   Lu X., 2020, ECCV, V12348, P661, DOI DOI 10.1007/978-3-030-58580-8_39
   Paul S, 2018, LECT NOTES COMPUT SC, V11208, P588, DOI 10.1007/978-3-030-01225-0_35
   Rashid M, 2020, IEEE WINT CONF APPL, P604, DOI [10.1109/wacv45572.2020.9093404, 10.1109/WACV45572.2020.9093404]
   Shi BF, 2020, PROC CVPR IEEE, P1006, DOI 10.1109/CVPR42600.2020.00109
   Shou Z, 2018, LECT NOTES COMPUT SC, V11220, P162, DOI 10.1007/978-3-030-01270-0_10
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Xiong Y., 2017, CoRR
   Xu YL, 2019, AAAI CONF ARTIF INTE, P9070
   Yuanhao Zhai, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P37, DOI 10.1007/978-3-030-58539-6_3
   Zeng RH, 2019, IEEE I CONF COMP VIS, P7093, DOI 10.1109/ICCV.2019.00719
   ZHAI Y, 2021, IEEE T MULT EARL ACC
   Zhang XY, 2019, AAAI CONF ARTIF INTE, P9227
   Zhang XQ, 2021, IEEE T NEUR NET LEAR, V32, P3005, DOI 10.1109/TNNLS.2020.3009209
   Zhao Y, 2020, INT J COMPUT VISION, V128, P74, DOI 10.1007/s11263-019-01211-2
   Zhuang Z., 2018, Advances in Neural Information Processing Systems, P875
NR 30
TC 1
Z9 1
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4323
EP 4340
DI 10.1007/s11042-021-11768-1
EA DEC 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000727165900002
DA 2024-07-18
ER

PT J
AU Chu, SL
   Chen, CF
   Zheng, YC
AF Chu, Slo-Li
   Chen, Chien-Fang
   Zheng, Yu-Chen
TI CFSM: a novel frame analyzing mechanism for real-time face recognition
   system on the embedded system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Face recognition; Embedded system; Real-time; Frame
   analysis
AB The development of web cameras and smart phones is mature, and more and more facial recognition-related applications are implemented on embedded systems. The demand for real-time face recognition on embedded systems is also increasing. In order to improve the accuracy of face recognition, most of the modern face recognition systems consist of multiple deep neural network models for recognition. However, in an embedded system, integrating these complex neural network models and execute simultaneously is not easy to achieve the goal of real-time recognition of human faces and their identities. In view of this, this study proposes a new frame analysis mechanism, continuous frames skipping mechanism (CFSM), which can analyze the frame in real time to determine whether it is necessary to perform face recognition on the current frame. Through the analysis of CFSM, the frames that do not need to be re-recognized for face are omitted. In this way, the workload of the face recognition system will be greatly reduced to achieve the goal of real-time face recognition in the embedded system. The experimental results show that the proposed CFSM mechanism can greatly increase the speed of face recognition in the video on the embedded system, achieving the goal of real-time face recognition.
C1 [Chu, Slo-Li; Chen, Chien-Fang; Zheng, Yu-Chen] Chung Yuan Christian Univ, Dept Informat & Comp Engn, Taoyuan, Taiwan.
C3 Chung Yuan Christian University
RP Chu, SL (corresponding author), Chung Yuan Christian Univ, Dept Informat & Comp Engn, Taoyuan, Taiwan.
EM slchu@cycu.edu.tw; ticks0628@gmail.com; blacktea1031@gmail.com
OI Chen, Chien-Fang/0000-0003-1321-8271
FU Ministry of Science and Technology of Republic of China, Taiwan [MOST
   105-2221-E-033-047]
FX This work is supported in part by the Ministry of Science and Technology
   of Republic of China, Taiwan under Grant MOST 105-2221-E-033-047.
CR Abu-El-Haija Sami, 2016, arXiv
   Chen S, 2018, LECT NOTES COMPUT SC, V10996, P428, DOI 10.1007/978-3-319-97909-0_46
   Dabhade SB, 2017, 2017 INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN COMPUTER, ELECTRICAL, ELECTRONICS AND COMMUNICATION (CTCEEC), P289, DOI 10.1109/CTCEEC.2017.8455113
   Dadi H.S., 2016, IOSR J. Electron. Commun.Eng., V11, P34, DOI 10.9790/2834-1104013444
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dhamecha TejasI., 2016, Advances in Face Detection and Facial Image Analysis, P279
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Gygli M., 2018, 2018 INT C CONT BAS, P1
   Hassanien A., 2017, Large-scale, fast and accurate shot boundary detection through spatio-temporal convolutional neural networks
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He QQ, 2019, MULTIMED TOOLS APPL, V78, P24035, DOI 10.1007/s11042-019-7209-0
   Holmes SA, 2009, IEEE T PATTERN ANAL, V31, P1251, DOI 10.1109/TPAMI.2008.189
   Jain Anil K., 2011, Introduction to Biometrics, DOI [DOI 10.1007/978-0-387-77326-1, 10.1007/978-0-387-77326-1_1]
   Jin X, 2020, MULTIMED TOOLS APPL, V79, P12533, DOI 10.1007/s11042-019-08280-y
   Jose E, 2019, INT CONF ADVAN COMPU, P608, DOI [10.1109/icaccs.2019.8728466, 10.1109/ICACCS.2019.8728466]
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Mengyue Zhang, 2019, 2019 IEEE International Conference of Intelligent Applied Systems on Engineering (ICIASE). Proceedings, P132, DOI 10.1109/ICIASE45644.2019.9074104
   Murray S, 2017, ARXIV170903572
   Parveen P, 2016, 18 IEEE INT C TOOLS, P179
   Qi X, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE & COMPUTATIONAL INTELLIGENCE (CSCI), P682, DOI [10.1109/CSCI.2016.0134, 10.1109/CSCI.2016.133]
   Saez-Trigueros D, 2018, ABS181100116 ARXIV
   Sajjad M, 2020, FUTURE GENER COMP SY, V108, P995, DOI 10.1016/j.future.2017.11.013
   Saypadith S, 2018, ASIAPAC SIGN INFO PR, P1318, DOI 10.23919/APSIPA.2018.8659751
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shi XP, 2018, PROC CVPR IEEE, P2295, DOI 10.1109/CVPR.2018.00244
   Sinha D, 2019, 2019 IEEE 10TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P280, DOI 10.1109/uemcon47517.2019.8993089
   Stekas N, 2016, IEEE SYM PARA DISTR, P300, DOI 10.1109/IPDPSW.2016.67
   Sujay SN, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER, AND OPTIMIZATION TECHNIQUES (ICEECCOT), P713
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Yang F, 2003, IEEE T NEURAL NETWOR, V14, P1162, DOI 10.1109/TNN.2003.816035
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang SF, 2019, NEUROCOMPUTING, V364, P297, DOI 10.1016/j.neucom.2019.07.064
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 38
TC 2
Z9 2
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1867
EP 1891
DI 10.1007/s11042-021-11599-0
EA OCT 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000707292900002
DA 2024-07-18
ER

PT J
AU Oufqir, Z
   El Abderrahmani, A
   Satori, K
AF Oufqir, Zainab
   El Abderrahmani, Abdellatif
   Satori, Khalid
TI Inserting and tracking a plane object in a three-dimensional scene
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real 3D scene; Homography; Camera pose; Abstract marker; Augmented
   reality
ID AUGMENTED REALITY; POSE ESTIMATION; ACCURATE; ROBUST
AB This article introduces the basic element to build an augmented reality system allowing to insert a 2D object in a real 3D scene in real time. The first step consists in locating the place where to insert the object using an abstract marker, this marker is a rectangle that surrounds the minimum area of the object's contour detected through its color. This rectangle is a plane surface that provides the position of its four points in the images acquired in real time which allows to have a real time tracking of the detected object. Planar homography describes exactly the relationship between the key points if the scene is flat and only requires four key points to produce an exact solution of the camera position to align a 2D virtual object in a 3D real scene.
C1 [Oufqir, Zainab; El Abderrahmani, Abdellatif; Satori, Khalid] USMBA, Fac Sci Fes, LIIAN, Dept Math & Informat, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Oufqir, Z (corresponding author), USMBA, Fac Sci Fes, LIIAN, Dept Math & Informat, Fes, Morocco.
EM zainab.oufkir@usmba.ac.ma; abdellatif.elabderrahmani@usmba.ac.ma;
   khalid.satori@usmba.ac.ma
RI satori, khalid/GSE-3077-2022; OUFKIR, ZAINAB/IQU-7643-2023
OI SATORI, khalid/0000-0001-6055-4169
CR ABIDI MA, 1995, IEEE T PATTERN ANAL, V17, P534, DOI 10.1109/34.391388
   Agarwal A., 2005, SURVEY PLANAR HOMOGR
   Ajanki A, 2011, VIRTUAL REAL-LONDON, V15, P161, DOI 10.1007/s10055-010-0183-5
   Amin Dhiraj, 2015, International Journal on Computational Science & Applications, V5, P11, DOI DOI 10.5121/IJCSA.2015.5102
   Annich A, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0139-6
   [Anonymous], 2002, P VIS INT CALG ALB C
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Basori AH, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0072-5
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Benhimane S, 2007, INT J ROBOT RES, V26, P661, DOI 10.1177/0278364907080252
   Cabero-Almenara J, 2016, J NEW APPROACHES EDU, V5, P44, DOI 10.7821/naer.2016.1.140
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Caudell T. P., 1992, P HAW INT C SYST SCI, V2, P659, DOI [10.1109/HICSS.1992.183317, DOI 10.1109/HICSS.1992.183317]
   Chalhoub J, 2019, MULTIMED TOOLS APPL, V78, P35075, DOI 10.1007/s11042-019-08063-5
   El Batteoui I, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0065-4
   El Hazzat S, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0041-z
   Gauglitz S, 2011, INT J COMPUT VISION, V94, P335, DOI 10.1007/s11263-011-0431-5
   Geng, 2017, EUR S ART NEUR  NETW
   GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027
   Grasset R, 2001, ENV REALITE AUGMENTE
   Gribaudo M, 2020, LECT N MECH ENG, P95, DOI 10.1007/978-3-030-31154-4_9
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Kenngott HG, 2018, SURG ENDOSC, V32, P2958, DOI 10.1007/s00464-018-6151-y
   Kim TJ, 2018, MULTIMED TOOLS APPL, V77, P30089, DOI 10.1007/s11042-018-6181-4
   Koller D., 1997, VRST'97. ACM Symposium on Virtual Reality Software and Technology 1997, P87, DOI 10.1145/261135.261152
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Lima JP, 2017, EXPERT SYST APPL, V82, P100, DOI 10.1016/j.eswa.2017.03.060
   Liu LY, 2019, MOBICOM'19: PROCEEDINGS OF THE 25TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, DOI 10.1145/3300061.3300116
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mackay WE, 1998, AUGMENTED REALITY LI
   Marchand E, 2016, IEEE T VIS COMPUT GR, V22, P2633, DOI 10.1109/TVCG.2015.2513408
   Mooser J, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2226
   Nagymáté G, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212319
   Nóbrega R, 2017, MULTIMED TOOLS APPL, V76, P163, DOI 10.1007/s11042-015-3031-5
   Oufqir Zainab, 2020, Embedded Systems and Artificial Intelligence. Proceedings of ESAI 2019. Advances in Intelligent Systems and Computing (AISC 1076), P599, DOI 10.1007/978-981-15-0947-6_57
   Oufqir Z, 2019, IMPORTANT METHOD DET, V8, P5
   Prince SJD, 2002, IEEE COMPUT GRAPH, V22, P39, DOI 10.1109/MCG.2002.1046627
   Rambach J, 2018, COMPUTERS, V7, DOI 10.3390/computers7010006
   Rusiñol M, 2018, MULTIMED TOOLS APPL, V77, P13773, DOI 10.1007/s11042-017-4991-4
   Satori, 2018, COMP STUDY OBJECT IN, P5
   Shoaib H, 2015, INT C VIRT AUGM REAL
   Simon G, 2002, IEEE COMPUT GRAPH, V22, P46, DOI 10.1109/MCG.2002.1046628
   Simon G, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P120, DOI 10.1109/ISAR.2000.880935
   Tarko J, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365708
   Tobias HH, 2004, LOCATION BASED SERVI
   Uchiyama H, 2011, VIRTUAL REAL-LONDON, V15, P109, DOI 10.1007/s10055-010-0173-7
   Villegas-Hernandez YS, 2017, INT J INTERACT DES M, V11, P727, DOI 10.1007/s12008-016-0356-x
   WEDYAN M, 2020, MULTIMED TOOLS APPL
   Zhang GH, 2018, LECT NOTES ARTIF INT, V10956, P134, DOI 10.1007/978-3-319-95957-3_15
   Zhang GH, 2017, LECT NOTES COMPUT SC, V10585, P1, DOI 10.1007/978-3-319-68935-7_1
   Zhang WX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P355, DOI 10.1145/3240508.3240561
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zonglei Huang, 2002, 2002 IEEE International Conference on Systems, Man and Cybernetics. Conference Proceedings (Cat. No.02CH37349), DOI 10.1109/ICSMC.2002.1173372
NR 57
TC 1
Z9 1
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1357
EP 1373
DI 10.1007/s11042-021-11536-1
EA SEP 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000702205100001
DA 2024-07-18
ER

PT J
AU Singh, D
   Srivastava, R
AF Singh, Divya
   Srivastava, Rajeev
TI Channel spatial attention based single-shot object detector for
   autonomous vehicles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attention mechanism; Filter response normalization; Single-shot object
   detection; Autonomous vehicle
AB Real-time object detection with high accuracy is the measure concern for the autonomous vehicle to provide safety. Recently many state-of-the-art methods used Convolutional Neural Network (CNN) for object detection. Although these methods provide better results but still provide a trade-off between accuracy and real-time detection becomes challenging tasks. High accuracy ensures the vehicle for avoiding collisions and abide the traffic rules while the faster speed helps to make the decision quickly. In this paper, the single-shot object detection is provided faster results and the attention module helps to provide more accurate detection. The channel attention mechanism provides more grained refine features and emphasizes 'what' is a semantic part from a given input. Apart from the channel attention mechanisms, spatial attention emphasizes 'where' is meaningful information which is working as a booster for the attention block. The proposed model incorporates these two attention mechanisms sequentially such as channel (RGB-wise) as well spatial attention for single-shot object detection (CSA-SS). The proposed model is trained and tested using challenging datasets such as KITTI and Berkeley Deep Drive (BDD). The experimental result shows that the proposed model surpasses the state-of-the-art techniques by 1.66 and 1.13 mAP for the KITTI and BDD datasets.
C1 [Singh, Divya; Srivastava, Rajeev] Banaras Hindu Univ, Indian Inst Technol, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
C3 Banaras Hindu University (BHU); Indian Institute of Technology System
   (IIT System); Indian Institute of Technology BHU Varanasi (IIT BHU
   Varanasi)
RP Singh, D (corresponding author), Banaras Hindu Univ, Indian Inst Technol, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
EM divyasingh.rs.cse18@itbhu.ac.in; rajeev.cse@iitbhu.ac.in
RI singh, Divya/AHB-2324-2022; Singh, Divya/IUM-7944-2023; Srivastava,
   Rajeev/C-7906-2016
OI Srivastava, Rajeev/0000-0002-0165-1556; Singh, Divya/0000-0002-6715-9310
CR Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Casanova A, 2018, IEEE COMPUT SOC CONF, P1091, DOI 10.1109/CVPRW.2018.00144
   Chen GC, 2022, VISUAL COMPUT, V38, P1051, DOI 10.1007/s00371-021-02067-9
   Choi J, 2019, IEEE I CONF COMP VIS, P502, DOI 10.1109/ICCV.2019.00059
   Gao ZL, 2019, PROC CVPR IEEE, P3019, DOI 10.1109/CVPR.2019.00314
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hu J, 2018, ADV NEURAL INFORM PR, P9401, DOI DOI 10.5555/3327546.3327612
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu XW, 2019, IEEE T INTELL TRANSP, V20, P1010, DOI 10.1109/TITS.2018.2838132
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu JS, 2016, ADV NEUR IN, V29
   Redmon J., 2016, P IEEE C COMP VIS PA, P779, DOI DOI 10.1109/CVPR.2016.91
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roy AG, 2019, IEEE T MED IMAGING, V38, P540, DOI 10.1109/TMI.2018.2867261
   Seo PH, 2017, ADV NEURAL INF PROCE, V2017, P3720
   Seo PH, 2019, BMVC 2018 BMVC 2018, P1
   Singh S., 2019, Filter Response Normalization Layer: Eliminating Batch Dependence in the Training of Deep Neural Networks
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wang Q, 2019, ECA NET EFFICIENT CH
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhao QJ, 2019, LECT NOTES COMPUT SC, V11365, P325, DOI 10.1007/978-3-030-20873-8_21
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540
NR 32
TC 0
Z9 0
U1 3
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22289
EP 22305
DI 10.1007/s11042-021-11267-3
EA SEP 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000696768700005
DA 2024-07-18
ER

PT J
AU Ghassab, VK
   Maanicshah, K
   Green, P
   Bouguila, N
AF Ghassab, Vahid Khorasani
   Maanicshah, Kamal
   Green, Paul
   Bouguila, Nizar
TI Content modification of soccer videos using a supervised deep learning
   framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content replacement; Segmentation; Key-out; UNET; Adversarial network
ID TRIANGLE INEQUALITY
AB In this paper, we initially propose a novel framework for replacing advertisement contents in soccer videos in an automatic way by using deep learning strategies. For this purpose, we begin by applying UNET (an image segmentation convolutional neural network technique) for content segmentation and detection. Subsequently, after reconstructing the segmented content in the video frames (considering the apparent loss in detection), we will replace the unwanted content by new one using a homography mapping procedure. Furthermore, the replacement key points will be tracked into the next frames considering the zoom-in and zoom-out controlling using multiplication of the key point coordinates by the homography matrix between each two consecutive frames. Since the movement of objects in video can disrupt the alignment between frames and correspondingly make the homography matrix calculation erroneous, we use Mask R-CNN algorithm to mask and remove the moving objects from the scene. Accordingly, the replacement will be consistent to the video motion of scene. Such framework is denominated as REP-Model which stands for a replacing model. In addition, we have examined the REP-Model over a large database regarding soccer match videos for removing and replacing the playground billboard contents and the results reveal the discriminative nature of our proposed framework. Furthermore, in order to key out the covered object beneath the new content, we use an unsupervised approach in an adversarial learning set-up by learning object masks with playing a game of cut-and-paste, using a discriminator model to find out whether the covered object has been revealed correctly.
C1 [Ghassab, Vahid Khorasani; Maanicshah, Kamal; Bouguila, Nizar] Concordia Univ, Montreal, PQ, Canada.
   [Green, Paul] Mtl Ai Inc, Montreal, PQ, Canada.
C3 Concordia University - Canada
RP Ghassab, VK (corresponding author), Concordia Univ, Montreal, PQ, Canada.
EM vahid.khorasani@concordia.ca; kamal.maanicshah@concordia.ca;
   paul.green@mtl.ai; nizar.bouguila@concordia.ca
OI Khorasani Ghassab, Vahid/0000-0001-7697-9364
FU Natural Sciences and Engineering research Council of Canada (NSERC)
FX The completion of this research was made possible thanks to the Natural
   Sciences and Engineering research Council of Canada (NSERC). In
   addition, the authors would like to thank Edouard Geze, Adam Alcolado
   and Robert Graham for their assistance during the project.
CR Abhishek, 2021, MULTIMED TOOLS APPL, V80, P3571, DOI 10.1007/s11042-020-09816-3
   Aldershoff F, 2004, PROC SPIE, V5307, P408
   Algarni AD, 2020, MULTIMED TOOLS APPL, V79, P13403, DOI 10.1007/s11042-020-08616-z
   [Anonymous], 2018, ARXIV181205484
   Bengani S, 2021, MULTIMED TOOLS APPL, V80, P3443, DOI 10.1007/s11042-020-09778-6
   Brock Andrew, 2018, ARXIV180911096
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Burgess Christopher P, 2019, Monet: Unsupervised scene decomposition and representation
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Cai GC, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 1, PROCEEDINGS, P537, DOI 10.1109/ISSPA.2003.1224759
   Cao XF, 2020, MULTIMED TOOLS APPL, V79, P9177, DOI 10.1007/s11042-018-7138-3
   Chen M, 2019, ADV NEUR IN, V32
   Cheng JC, 2018, PROC CVPR IEEE, P7415, DOI 10.1109/CVPR.2018.00774
   Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787
   Dean J., 2012, ADV NEURAL INFORM PR, P1223
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dewi C, 2020, MULTIMED TOOLS APPL, V79, P32897, DOI 10.1007/s11042-020-09509-x
   Egilmez HE, 2020, IEEE T IMAGE PROCESS, V29, P9330, DOI 10.1109/TIP.2020.3026627
   Eslami SMA, 2016, 30 C NEURAL INFORM P, V29
   Feng Z, 2013, REAL TIME COMMERCIAL
   Gao ZF, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900260
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gruosso M, 2021, MULTIMED TOOLS APPL, V80, P1175, DOI 10.1007/s11042-020-09425-0
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Hossari M, 2018, ARXIV181104115
   Hou SJ, 2018, MULTIMED TOOLS APPL, V77, P25475, DOI 10.1007/s11042-018-5801-3
   Hu P, 2018, PROC CVPR IEEE, P1400, DOI 10.1109/CVPR.2018.00152
   Hu YT, 2017, ADV NEUR IN, V30
   Hussain Z, 2017, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.2017.123
   Jang SW., 2019, MULTIMED TOOLS APPL, V79, P1
   Ji X, 2018, ARXIV180706653
   Jiang Y, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149440
   Kanezaki A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1543, DOI 10.1109/ICASSP.2018.8462533
   Khoreva Anna, 2017, The DAVIS challenge on video object segmentation
   Kim D Y, 2020, MULTIMED TOOLS APPL, P1
   Kim Y, 2019, MULTIMED TOOLS APPL, V78, P3009, DOI 10.1007/s11042-018-5610-8
   Kosub S, 2019, PATTERN RECOGN LETT, V120, P36, DOI 10.1016/j.patrec.2018.12.007
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee H, 2020, IEEE T IMAGE PROCESS, V29, P1030, DOI 10.1109/TIP.2019.2938879
   LEVANDOWSKY M, 1971, NATURE, V234, P34, DOI 10.1038/234034a0
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P5881, DOI 10.1109/TIP.2019.2922854
   Lim J. H., 2017, Geometric gan
   Lipkus AH, 1999, J MATH CHEM, V26, P263, DOI 10.1023/A:1019154432472
   Liu JH, 2020, IEEE T IMAGE PROCESS, V29, P3388, DOI 10.1109/TIP.2019.2959741
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lucas A, 2019, IEEE T IMAGE PROCESS, V28, P3312, DOI 10.1109/TIP.2019.2895768
   Maninis KK, 2019, IEEE T PATTERN ANAL, V41, P1515, DOI 10.1109/TPAMI.2018.2838670
   Miyato T, 2018, INT C LEARN REPR
   Moulton R, 2018, ARXIV180904052
   Ostyakov Pavel, 2018, ARXIV181107630
   Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372
   Pham TT, 2018, IEEE INT CONF ROBOT, P3213
   Remez T, 2018, LECT NOTES COMPUT SC, V11211, P39, DOI 10.1007/978-3-030-01234-2_3
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sakthivelan RG, 2020, MULTIMED TOOLS APPL, V79, P3847, DOI 10.1007/s11042-019-7293-1
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Tran D, 2017, ARXIV17020889673
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Voigtlaender P, 2017, 2017 DAVIS CHALL VID, V5
   Voigtlaender P., 2017, BMVC, P1000
   Voigtlaender P, 2019, PROC CVPR IEEE, P9473, DOI 10.1109/CVPR.2019.00971
   Watve A, 2008, PATTERN RECOGN LETT, V29, P994, DOI 10.1016/j.patrec.2008.01.022
   Wei W, 2019, MULTIMED TOOLS APPL, V78, P27109, DOI 10.1007/s11042-017-5083-1
   Xia Xide, 2017, W-net: A deep model for fully unsupervised image segmentation
   Xiao YZ, 2020, MULTIMED TOOLS APPL, V79, P23729, DOI 10.1007/s11042-020-08976-6
   Yang LJ, 2018, PROC CVPR IEEE, P6499, DOI 10.1109/CVPR.2018.00680
   Yong BB, 2021, MULTIMED TOOLS APPL, V80, P34103, DOI 10.1007/s11042-020-08911-9
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 72
TC 1
Z9 1
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 481
EP 503
DI 10.1007/s11042-021-11383-0
EA SEP 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000695102000002
DA 2024-07-18
ER

PT J
AU Goyal, S
   Bhatia, PK
AF Goyal, Somya
   Bhatia, Pradeep Kumar
TI Heterogeneous stacked ensemble classifier for software defect prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Software defect prediction (SDP); Heterogenous ensemble; Stacking;
   Artificial neural network; ROC
ID OVERLAP
AB Software defect prediction (SDP) plays an important role to ensure that software meets quality standards; by highlighting the modules which are prone to errors and hence allows to focus the test efforts on them. Class imbalance nature of the defect dataset hinders the defect predictors to correctly classify the buggy modules. Here, we introduce a novel heterogenous ensemble classifier built with stacking methodology to overcome this problem of imbalanced datasets and hence, significant improvement in the prediction power is being proposed. Stacked ensemble is achieved with the best known classifiers from SDP literature as base classifiers (artificial neural network, nearest neighbor, tree based classifier, Bayesian classifier and support vector machines). For experimental work, five public datasets from NASA corpus are used. A comparative analysis for the proposed heterogenous stacking based ensemble method is made with the base classifiers and with the state-of-the art ensemble based SDP models over the evaluation criteria of ROC, AUC and accuracy. It is found that the proposed heterogenous stacking based ensemble classifier outperforms the base classifiers by 12% in terms of AUC score and by 8% in terms of Accuracy. It improves the performance of state-of-the-art ensemble methods by 4% in terms of AUC score and by 9% in terms of Accuracy. It can be concluded from the comparative analysis that the proposed SDP classifier is best performer among the candidate SDP classifiers statistically.
C1 [Goyal, Somya] Manipal Univ Jaipur, Jaipur 303007, Rajasthan, India.
   [Goyal, Somya; Bhatia, Pradeep Kumar] Guru Jambheshwar Univ Sci & Technol, Hisar 125001, Haryana, India.
C3 Manipal University Jaipur; Guru Jambheshwar University of Science &
   Technology
RP Goyal, S (corresponding author), Manipal Univ Jaipur, Jaipur 303007, Rajasthan, India.; Goyal, S (corresponding author), Guru Jambheshwar Univ Sci & Technol, Hisar 125001, Haryana, India.
EM somyagoyal1988@gmail.com; pkbhatia.gju@gmail.com
RI bhatia, pradeep kumar/AAJ-5907-2020
OI goyal, somya/0000-0002-0113-7733
CR Balogun AO, 2020, LECT NOTES COMPUT SC, V12254, P615, DOI 10.1007/978-3-030-58817-5_45
   Boucher A, 2018, INFORM SOFTWARE TECH, V96, P38, DOI 10.1016/j.infsof.2017.11.005
   Chen L, 2018, SOFTWARE QUAL J, V26, P97, DOI 10.1007/s11219-016-9342-6
   Erturk E, 2015, EXPERT SYST APPL, V42, P1872, DOI 10.1016/j.eswa.2014.10.025
   Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285
   Goyal S., 2020, COMPUTATIONAL INTELL, P49
   Goyal S, 2020, INT J KNOWL SYST SCI, V11, P20, DOI 10.4018/IJKSS.2020040102
   Guo HX, 2017, EXPERT SYST APPL, V73, P220, DOI 10.1016/j.eswa.2016.12.035
   Haykin S., 2010, Neural Networks and Learning Machines
   Huda S, 2018, IEEE ACCESS, V6, P24184, DOI 10.1109/ACCESS.2018.2817572
   Khuat TT., 2020, SN COMPUT SCI, V1, P108, DOI [10.1007/s42979-020-0119-4, DOI 10.1007/S42979-020-0119-4]
   Laradji IH, 2015, INFORM SOFTWARE TECH, V58, P388, DOI 10.1016/j.infsof.2014.07.005
   Son LH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020212
   Lee HK, 2018, EXPERT SYST APPL, V98, P72, DOI 10.1016/j.eswa.2018.01.008
   LEHMANN E. L., 2006, Springer Texts in Statistics
   Miholca DL, 2018, INFORM SCIENCES, V441, P152, DOI 10.1016/j.ins.2018.02.027
   Özakinci R, 2018, J SYST SOFTWARE, V144, P216, DOI 10.1016/j.jss.2018.06.025
   Rathore SS, 2019, ARTIF INTELL REV, V51, P255, DOI 10.1007/s10462-017-9563-5
   Rathore SS, 2017, EXPERT SYST APPL, V82, P357, DOI 10.1016/j.eswa.2017.04.014
   Sayyad Shirabad J., 2005, The PROMISE Repository of Software Engineering Databases
   Siers MJ, 2015, INFORM SYST, V51, P62, DOI 10.1016/j.is.2015.02.006
   Tong HN, 2018, INFORM SOFTWARE TECH, V96, P94, DOI 10.1016/j.infsof.2017.11.008
   Wang S, 2013, IEEE T RELIAB, V62, P434, DOI 10.1109/TR.2013.2259203
   Wang TJ, 2016, AUTOMAT SOFTW ENG, V23, P569, DOI 10.1007/s10515-015-0179-1
   Xia X, 2015, INFORM SOFTWARE TECH, V61, P93, DOI 10.1016/j.infsof.2014.12.006
   Yang XL, 2017, INFORM SOFTWARE TECH, V87, P206, DOI 10.1016/j.infsof.2017.03.007
NR 26
TC 12
Z9 12
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37033
EP 37055
DI 10.1007/s11042-021-11488-6
EA SEP 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000695102100003
DA 2024-07-18
ER

PT J
AU Fatima, T
   Farid, MS
AF Fatima, Tehreem
   Farid, Muhammad Shahid
TI Quality assessment of 3D synthesized images based on structural and
   textural distortion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D quality assessment; Autostereoscopy; Depth image-based rendering;
   DIBR image quality assessment
ID STEREOSCOPIC 3D; VIDEO; COMPRESSION; INFORMATION; VIEW; PERCEPTION
AB Depth image based rendering (DIBR) is a popular technique for rendering virtual 3D views in stereoscopic and autostereoscopic displays. The quality of DIBR-synthesized images may decrease due to various factors, e.g., imprecise depth maps, poor rendering techniques, inaccurate camera parameters. The quality of synthesized images is important as it directly affects the overall user experience. Therefore, the need arises for designing algorithms to estimate the quality of the DIBR-synthesized images. The existing 2D image quality assessment metrics are found to be insufficient for 3D view quality estimation because the 3D views not only contain color information but also make use of disparity to achieve the real depth sensation. In this paper, we present a new algorithm for evaluating the quality of DIBR generated images in the absence of the original references. The human visual system is sensitive to structural information; any deg radation in structure or edges affects the visual quality of the image and is easily noticeable for humans. In the proposed metric, we estimate the quality of the synthesized view by capturing the structural and textural distortion in the warped view. The structural and textural information from the input and the synthesized images is estimated and used to calculate the image quality. The performance of the proposed quality metric is evaluated on the IRCCyN IVC DIBR images dataset. Experimental evaluations show that the proposed metric outperforms the existing 2D and 3D image quality metrics by achieving a high correlation with the subjective ratings.
C1 [Fatima, Tehreem; Farid, Muhammad Shahid] Univ Punjab, Dept Comp Sci, Lahore 54000, Pakistan.
C3 University of Punjab
RP Farid, MS (corresponding author), Univ Punjab, Dept Comp Sci, Lahore 54000, Pakistan.
EM shahid@pucit.edu.pk
RI Farid, Muhammad Shahid/AAF-1825-2019
OI Farid, Muhammad Shahid/0000-0002-8384-2830; Fatima,
   Tehreem/0000-0002-0146-1939
CR [Anonymous], 2010, P INT WORKSH VID PRO
   Banitalebi-Dehkordi A, 2018, MULTIMED TOOLS APPL, V77, P26055, DOI 10.1007/s11042-018-5837-4
   Battisti F, 2015, SIGNAL PROCESS-IMAGE, V30, P78, DOI 10.1016/j.image.2014.10.005
   Benoit A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/659024
   Bosc E, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P249, DOI 10.1109/PCS.2012.6213339
   Bosc E, 2011, IEEE J-STSP, V5, P1332, DOI 10.1109/JSTSP.2011.2166245
   Campisi Patrizio, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P2110
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chen L, 2019, MULTIMED TOOLS APPL, V78, P12139, DOI 10.1007/s11042-018-6759-x
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Domanski M, 2013, IEEE T IMAGE PROCESS, V22, P3517, DOI 10.1109/TIP.2013.2266580
   Fan Y, 2019, IEEE ACCESS, V7, P8621, DOI 10.1109/ACCESS.2018.2887276
   Farid MS, 2020, SIGNAL IMAGE VIDEO P, V14, P195, DOI 10.1007/s11760-019-01542-0
   Farid MS, 2018, INFORM FUSION, V43, P47, DOI 10.1016/j.inffus.2017.11.007
   Farid MS, 2017, IEEE INT CON MULTI, P505, DOI 10.1109/ICME.2017.8019307
   Farid MS, 2015, IEEE IMAGE PROC, P3720, DOI 10.1109/ICIP.2015.7351499
   Farid MS, 2014, IEEE IMAGE PROC, P5452, DOI 10.1109/ICIP.2014.7026103
   Farid MS, 2015, IEEE T IMAGE PROCESS, V24, P205, DOI 10.1109/TIP.2014.2374533
   Farid MS, 2013, IEEE INT WORKSH MULT, P135, DOI 10.1109/MMSP.2013.6659277
   Farid MS, 2013, IEEE INT WORKSH MULT, P406, DOI 10.1109/MMSP.2013.6659323
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Gorley P., 2008, P SPIE STEREOS DISPL, V6803
   Gu ZJ, 2019, APPL OPTICS, V58, P340, DOI 10.1364/AO.58.000340
   Heo YS, 2013, IEEE T PATTERN ANAL, V35, P1094, DOI 10.1109/TPAMI.2012.167
   Joveluro P, 2010, 3DTV CONF
   JULESZ B, 1972, INVEST OPHTH VISUAL, V11, P540
   Karimi M, 2019, DIGIT SIGNAL PROCESS, V91, P91, DOI 10.1016/j.dsp.2019.03.004
   Kim D, 2012, IEEE INT SYM BROADB
   Köppel M, 2010, IEEE IMAGE PROC, P1809, DOI 10.1109/ICIP.2010.5652138
   Ling SY, 2017, IEEE INT CON MULTI, P79, DOI 10.1109/ICME.2017.8019431
   Liu XK, 2015, IEEE T IMAGE PROCESS, V24, P4847, DOI 10.1109/TIP.2015.2469140
   Mitsa T., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P301, DOI 10.1109/ICASSP.1993.319807
   Mori Y, 2009, SIGNAL PROCESS-IMAGE, V24, P65, DOI 10.1016/j.image.2008.10.013
   Müller K, 2010, IEEE IMAGE PROC, P2389, DOI 10.1109/ICIP.2010.5652030
   Ndjiki-Nya P, 2010, IEEE INT CON MULTI, P424, DOI 10.1109/ICME.2010.5583559
   Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862
   Rahaman DMM, 2018, IEEE T IMAGE PROCESS, V27, P1190, DOI 10.1109/TIP.2017.2772858
   Ryu S, 2012, IEEE IMAGE PROC, P609, DOI 10.1109/ICIP.2012.6466933
   Sandic-Stankovic D, 2015, INT WORK QUAL MULTIM
   Sandic-Stankovic D, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0124-7
   Sandwell D.T., 2016, 2016 SCEC Annual Report Assembly of the Community Geodetic Model and GPS Survey of the Cerro Prieto Fault: Proposal 16072, P1, DOI 10.1109/QoMEX.2016.7498949
   Shao F, 2016, APPL OPTICS, V55, P5488, DOI 10.1364/AO.55.005488
   Shao F, 2014, DIGIT SIGNAL PROCESS, V29, P45, DOI 10.1016/j.dsp.2014.03.003
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Su GM, 2011, INT J COMMUN SYST, V24, P1261, DOI 10.1002/dac.1190
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tian SS, 2017, INT CONF ACOUST SPEE, P1248, DOI 10.1109/ICASSP.2017.7952356
   Tsai CT, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON VISUAL COMMUNICATIONS AND IMAGE PROCESSING (IEEE VCIP 2013)
   Video Quality Experts Group, 2003, FINAL REPORT VIDEO Q
   Voo KHB, 2018, MULTIMED TOOLS APPL, V77, P2313, DOI 10.1007/s11042-017-4361-2
   Wan ZL, 2017, IEEE INT CON MULTI, P73, DOI 10.1109/ICME.2017.8019337
   Wang JH, 2015, IEEE T IMAGE PROCESS, V24, P3400, DOI 10.1109/TIP.2015.2446942
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Zhou J, 2019, DIGIT SIGNAL PROCESS, V91, P41, DOI 10.1016/j.dsp.2018.12.008
   Zhou WJ, 2019, DIGIT SIGNAL PROCESS, V93, P128, DOI 10.1016/j.dsp.2019.07.008
   Zhou WJ, 2016, IEEE T MULTIMEDIA, V18, P1077, DOI 10.1109/TMM.2016.2542580
NR 62
TC 0
Z9 0
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36443
EP 36463
DI 10.1007/s11042-021-11382-1
EA SEP 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000692967600006
DA 2024-07-18
ER

PT J
AU Saidani, T
   El Touati, Y
AF Saidani, Taoufik
   El Touati, Yamen
TI A vehicle plate recognition system based on deep learning algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE License plate detection; Faster R-CNN; Adaptive Attention network;
   Convolutional neural networks
AB In modern life, the massive number of vehicles makes it hard for a human being to process its related information. So, it is important to build an automatic system to collect information about vehicles. The license plate is the unique identifier of a vehicle. In this paper, we propose an automatic license plate recognition system. The proposed system was based on the Faster R-CNN improved by adding an adaptive attention network for the segmentation of the license plate to retrieve the numbers and the letters of identification. Also, we add a deconvolution layer at the top of the features extraction network to detect the small size of the target license plate. To train and evaluate the proposed system, a dataset was collected for Arabic countries such as Egypt, KSA, and UAE that have similar license plates with Arabic and Indian numbers, Arabic and Latin alphabets. The dataset was collected from the internet using a python script then it was filtered and annotated manually. The evaluation of the proposed model dataset results in achieving a recall of 98.65 % and a precision of 97.46 %. The developed system was able to process images in real-time with a processing speed of 23 FPS.
C1 [Saidani, Taoufik] Northern Border Univ, Fac Comp & Informat Technol, Dept Comp Sci, Rafha, Saudi Arabia.
   [Saidani, Taoufik] Univ Monastir, Fac Sci Monastir, Lab Elect & Microelect EuE, Monastir, Tunisia.
   [El Touati, Yamen] El Manar Univ, Natl Engn Sch, Oasis Lab, Tunis, Tunisia.
C3 Northern Border University; Universite de Monastir; Universite de
   Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis (ENIT)
RP Saidani, T (corresponding author), Northern Border Univ, Fac Comp & Informat Technol, Dept Comp Sci, Rafha, Saudi Arabia.; Saidani, T (corresponding author), Univ Monastir, Fac Sci Monastir, Lab Elect & Microelect EuE, Monastir, Tunisia.
EM Taoufik.Saidan@nbu.edu.sa; Yamen.Touati@nbu.edu.sa
RI El Touati, Yamen/KCY-2921-2024; Saidani, Taoufik/KFS-6384-2024; Saidani,
   Taoufik/AAG-3656-2019
OI El Touati, Yamen/0000-0003-2371-3647; Saidani,
   Taoufik/0000-0002-3707-6135; 
FU Northern Border University, Arar, KSA [CIT-2018-3-9-F-7617]
FX The authors wish to acknowledge the approval and the support of this
   research study by the grant N_. CIT-2018-3-9-F-7617 from the Deanship of
   the Scientific Research in Northern Border University, Arar, KSA.
CR Afif M, 2020, NEURAL PROCESS LETT, V51, P2827, DOI 10.1007/s11063-020-10231-w
   Afif M, 2020, MULTIMED TOOLS APPL, V79, P31645, DOI 10.1007/s11042-020-09662-3
   [Anonymous], LABELIMG IS GRAPHICA
   Arafat MY, 2019, IET INTELL TRANSP SY, V13, P745, DOI 10.1049/iet-its.2018.5151
   Ayachi R, 2019, Artificial Intelligence Advances, V1, P1, DOI DOI 10.30564/AIA.V1I1.569
   Ayachi R, 2020, NEURAL PROCESS LETT, V51, P837, DOI 10.1007/s11063-019-10115-8
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Balaban S, 2015, PROC SPIE, V9457, DOI 10.1117/12.2181526
   Dai Jifeng, 2016, Advances in Neural Information Processing Systems, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendry, 2019, IMAGE VISION COMPUT, V87, P47, DOI 10.1016/j.imavis.2019.04.007
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurpiel FD, 2017, IEEE IMAGE PROC, P3395, DOI 10.1109/ICIP.2017.8296912
   Li H, 2018, IMAGE VISION COMPUT, V72, P14, DOI 10.1016/j.imavis.2018.02.002
   Li Q, 2014, I C CONT AUTOMAT ROB, P844, DOI 10.1109/ICARCV.2014.7064414
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   McCann MT, 2017, IEEE SIGNAL PROC MAG, V34, P85, DOI 10.1109/MSP.2017.2739299
   OShea K., 2015, ARXIV151108458, DOI DOI 10.48550/ARXIV.1511.08458
   Peker M, 2019, 2019 IEEE 1ST GLOBAL POWER, ENERGY AND COMMUNICATION CONFERENCE (GPECOM2019), P101, DOI 10.1109/GPECOM.2019.8778602
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shen S, 2020, J PHYS C SERIES, V1544
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Yonetsu S, 2019, I SYMP CONSUM ELECTR
NR 31
TC 6
Z9 6
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36237
EP 36248
DI 10.1007/s11042-021-11233-z
EA SEP 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000692075600003
DA 2024-07-18
ER

PT J
AU Gelsomini, M
   Spitale, M
   Garzotto, F
AF Gelsomini, Mirko
   Spitale, Micol
   Garzotto, Franca
TI Phygital interfaces for people with intellectual disability: an
   exploratory study at a social care center
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intellectual disability; Tangible interfaces; Phygital interaction;
   Autism spectrum disorder; Comparative study
ID TANGIBLE USER-INTERFACE; CHILDREN
AB Phygital interaction is a form of tangible interaction where digital and physical contents are combined in such a way that the locus of multimedia information is detached from the physical material(s) manipulated by the user. The use of phygital interaction is supported by several theoretical approaches that emphasize the development of cognitive skills dependent upon embodied interactions with the physical environment. Several studies demonstrate the potential of using phygital technologies for supporting people with intellectual disabilities (ID) in the development of cognitive, sensorimotor, social and behavioral skills. Our research aims at exploring the potential of phygital interaction for (young) adults with ID in a real setting, using a research platform called Reflex as a case study. For this purpose, we ran an empirical study involving 17 participants with ID and 8 specialists, and compared Reflex with approaches making use of only digital contents or paper-based materials. Our findings highlighted the potentials of phygital approaches to perform interventions with people with ID, enhancing their performances with an appreciated interaction method. In addition, the post-study interviews with specialists favoured the adoption of phygital technologies in a social care context.
C1 [Gelsomini, Mirko; Spitale, Micol; Garzotto, Franca] Politecn Milan, Piazza Leonardo da Vinci 32, Milan, Italy.
C3 Polytechnic University of Milan
RP Gelsomini, M (corresponding author), Politecn Milan, Piazza Leonardo da Vinci 32, Milan, Italy.
EM phd.mirko.gelsomini@gmail.com
RI Gelsomini, Mirko/AAG-9874-2019; Spitale, Micol/HJI-1823-2023
OI Gelsomini, Mirko/0000-0001-8421-6850; SPITALE, MICOL/0000-0002-3418-1933
FU Politecnico di Milano within the CRUI-CARE Agreement
FX Open access funding provided by Politecnico di Milano within the
   CRUI-CARE Agreement.
CR Al Mahmud A, 2020, INT J HUM-COMPUT ST, V144, DOI 10.1016/j.ijhcs.2020.102486
   Antle A.N., 2007, Proceedings of the 1st international conference on Tangible and embedded interaction, P195, DOI DOI 10.1145/1226969.1227010
   Antle AN, 2013, INTERACT COMPUT, V25, P1, DOI 10.1093/iwc/iws007
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   Beaudouin-Lafon M., 2000, Proc. of the SIGCHI Conference on Human Factors in Computing Systems, P446, DOI DOI 10.1145/332040.332473
   Bell BS, 2008, J APPL PSYCHOL, V93, P296, DOI 10.1037/0021-9010.93.2.296
   Bernardo B, 2016, LECT NOTES ARTIF INT, V10011, P500, DOI 10.1007/978-3-319-47665-0_63
   Borg J, 2015, UNIVERSAL ACCESS INF, V14, P547, DOI 10.1007/s10209-014-0351-6
   Caruso F, 2020, 4 EUROPEAN TANGIBLE
   Cerezo E., 2015, MORE PLAYFUL USER IN, P17, DOI [10.1007/978-981-287-546-4_2, DOI 10.1007/978-981-287-546-4_2]
   Chipman G, 2011, PROCEEDINGS OF IDC 2011: THE 10TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2011), P29
   Dandashi A, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/165165
   Dulcan MK., 2006, Essentials of child and adolescent psychiatry
   Eisenberg M., 2003, Proceedings of the 2003 conference on Interaction design and children, IDC '03, P31
   Falcao TP, 2017, INT J LEARN TECHNOL, V12, P294, DOI 10.1504/IJLT.2017.089908
   Falcao TP, 2012, PROCEEDINGS OF IDC 2012: THE 11TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN, P371
   Fiangga, 2014, P INT C RES IMPL ED
   Foglia L, 2013, WIRES COGN SCI, V4, P319, DOI 10.1002/wcs.1226
   Frohlich A, 2015, STIMOLAZIONE BASALE
   Frutos-Pascual M, 2012, COMM COM INF SC, V351, P68
   Garzotto F, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P79
   GELSOMINI M, 2018, EXT ABSTR 2018 CHI C
   Gelsomini M, 2019, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES: COMPANION (IUI 2019), P29, DOI 10.1145/3308557.3308689
   Gibbs G.R., 2007, Analyzing qualitative data, DOI [10.4135/9781849208574, DOI 10.4135/9781849208574.N4, DOI 10.4135/9781849208574]
   Hagerman RJ, 2015, CURR OPIN PSYCHIATR, V28, P107, DOI 10.1097/YCO.0000000000000131
   Herrero L, 2019, BRIT J EDUC TECHNOL, V50, P2055, DOI 10.1111/bjet.12665
   Hornecker E, 2006, P SIGCHI C HUM FACT, P437, DOI [10.1145/1124772.1124838, DOI 10.1145/1124772.1124838]
   Jones B, 2014, DESIGN ANAL CROSS OV
   Joosten AV, 2010, AUST OCCUP THER J, V57, P366, DOI 10.1111/j.1440-1630.2009.00835.x
   Jorda S., 2005, P 2005 INT COMPUTER, P379
   Kerr N L, 1998, Pers Soc Psychol Rev, V2, P196, DOI 10.1207/s15327957pspr0203_4
   Kientz Julie A, 2019, Synthesis Lectures on Assistive, Rehabilitative, and Health -Preserving Technologies, V9, pi
   Kostanjsek N, 2011, BMC PUBLIC HEALTH, V11, DOI 10.1186/1471-2458-11-S4-S3
   Kremelberg D., 2010, PRACTICAL STAT QUICK
   Levy S, 2017, GRAPHICAL USER INTER
   Marco J, 2013, J UNIVERS COMPUT SCI, V19, P2266
   Marshall P., 2007, P 1 ST INT C TANGIBL, P163, DOI DOI 10.1145/1226969.1227004
   Masran MN, 2018, ADV SCI LETT, V24, P5338, DOI 10.1166/asl.2018.11730
   Menendez C, 2020, COMPUTER VISION BASE, P61
   O'Malley C., 2004, Literature Review in Learning with Tangible Technologies
   Olesen J, 2012, EUR J NEUROL, V19, P155, DOI 10.1111/j.1468-1331.2011.03590.x
   Petrelli D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173686
   Renavitasari IRD, 2018, PROCEEDINGS OF 2018 3RD INTERNATIONAL CONFERENCE ON SUSTAINABLE INFORMATION ENGINEERING AND TECHNOLOGY (SIET 2018), P174, DOI 10.1109/SIET.2018.8693164
   Resnick M, 1998, ETR&D-EDUC TECH RES, V46, P43, DOI 10.1007/BF02299672
   Resnick M, 1996, IBM SYST J, V35, P443, DOI 10.1147/sj.353.0443
   RESNICK M, 1998, P SIGCHI C HUM FACT, P281, DOI DOI 10.1145/274644.274684
   Sánchez-Morales A, 2020, INT J ADV COMPUT SC, V11, P486
   Schalock RL, 2010, Intellectual Disability: Definition, Classification, and Systems of Supports, V11th
   Schneider B, 2011, IEEE T LEARN TECHNOL, V4, P222, DOI 10.1109/TLT.2010.36
   Sharma PK, 2017, US Patent App., Patent No. 15081739
   Sitdhisanguan K, 2012, PERS UBIQUIT COMPUT, V16, P143, DOI 10.1007/s00779-011-0382-4
   Sitdhisanguan K, 2008, DIGITEL 2008: SECOND IEEE INTERNATIONAL CONFERENCE ON DIGITAL GAME AND INTELLIGENT TOY ENHANCED LEARNING, PROCEEDINGS, P70, DOI 10.1109/DIGITEL.2008.28
   Song K, 2016, LECT NOTES COMPUT SC, V9739, P414, DOI 10.1007/978-3-319-40238-3_40
   Spitale M, 2019, M NEEDS PEOPLE NEURO
   Starcic AI, 2013, BRIT J EDUC TECHNOL, V44, P729, DOI 10.1111/j.1467-8535.2012.01341.x
   Tam V, 2017, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'17), P11, DOI 10.1145/3024969.3025006
   Tangible P., 2014, TANGRAM OSMO
   Tangible P., 2016, OSMO AWARD WINNING E
   Ullmer Brygg Anders, 2002, THESIS
   Urturi ZS, NATURAL TANGIBLE USE
   Vicente KJ, 1998, PSYCHOL REV, V105, P33, DOI 10.1037/0033-295X.105.1.33
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   Zajc Matej, 2012, Agent and Multi-Agent Systems. Technologies and Applications. Proceedings 6th KES International Conference, KES-AMSTA 2012, P261, DOI 10.1007/978-3-642-30947-2_30
   Zhang L, 2018, J AUTISM DEV DISORD, V48, P2779, DOI 10.1007/s10803-018-3544-7
   Zuckerman O., 2005, P C HUMAN FACTORS CO, P859, DOI [10.1145/1054972.1055093, DOI 10.1145/1054972.1055093]
   Zuckerman O, 2010, INT J ARTS TECHNOL, V3, P124, DOI 10.1504/IJART.2010.030497
NR 66
TC 4
Z9 4
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34843
EP 34874
DI 10.1007/s11042-021-11164-9
EA AUG 2021
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000687926200002
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Jena, JJ
   Satapathy, SC
AF Jena, Junali Jasmine
   Satapathy, Suresh Chandra
TI A new adaptive tuned Social Group Optimization (SGO) algorithm with
   sigmoid-adaptive inertia weight for solving engineering design problems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sigmoid-adaptive inertia weight; Social group optimization; Single
   objective optimization; Engineering design problems; Evolutionary
   algorithms
ID STRATEGIES
AB Evolutionary algorithms have found enormous applications in solving real-world problems due to their stochastic nature. They have a set of control parameters, which are used to perform certain operations to induce randomness, scalar displacement etc. Various works have been done for tuning these parameters, as appropriate parameter tuning can enhance the performance of algorithm greatly. Inertia weights based parameter tuning is one of the widely used techniques for this purpose. In this paper, we have reviewed some of the inertia weight strategies and applied them to Social Group Optimization (SGO) to study the changes in its performance and have performed a thorough analysis on the same. Following the analysis, the need of a more generalized inertia weight strategy was felt which could be used in parameter tuning for different variety of problems and hence Sigmoid adaptive inertia weight have been proposed. SGO with sigmoid-adaptive inertia weight (SGOSAIW) has been simulated on twenty-seven benchmark functions suite and further simulated on few mechanical and chemical engineering problems and compared to other similar algorithms for performance analysis. In eight-benchmark function suite, SGOSAIW obtained better minima except one i.e. 'Schwefel 2.26' with respect to other algorithms investigated in this work. In nineteen-benchmark function suite, SGOSAIW obtained better minima except one i.e. 'Noisy function'. Thus, the proposed algorithm yielded promising results which are well represented with suitable tables and graphs in the paper.
C1 [Jena, Junali Jasmine; Satapathy, Suresh Chandra] Kalinga Inst Ind Technol, Sch Comp Engn, Bhubaneswar, India.
C3 Kalinga Institute of Industrial Technology (KIIT)
RP Satapathy, SC (corresponding author), Kalinga Inst Ind Technol, Sch Comp Engn, Bhubaneswar, India.
EM junali.jenafcs@kiit.ac.in; suresh.satapathyfcs@kiit.ac.in
RI Jena, Junali/GQQ-3202-2022
CR [Anonymous], 2008, Firefly algorithm, nature-inspired metaheuristic algorithms
   Azqandi MS, 2020, ENG COMPUT-GERMANY, V36, P763, DOI 10.1007/s00366-019-00729-w
   Bansal J C, 2011, 3 WORLD C NAT BIOL I, P633, DOI [10.1109/NaBIC.2011.6089659, DOI 10.1109/NABIC.2011.6089659]
   Chauhan P, 2013, MEMET COMPUT, V5, P229, DOI 10.1007/s12293-013-0111-9
   Chen HL, 2019, APPL MATH MODEL, V71, P45, DOI 10.1016/j.apm.2019.02.004
   Chen M, 2019, INT C BIOINSP COMP T, P177
   Chen ZR, 2019, PR ELECTROMAGN RES S, P207, DOI 10.1109/PIERS-Fall48861.2019.9021919
   Chou JS, 2017, STRUCT MULTIDISCIP O, V55, P2013, DOI 10.1007/s00158-016-1624-x
   Coello C. A. C., 2007, EVOLUTIONARY ALGORIT, DOI DOI 10.1007/978-0-387-36797-2
   Das S, 2021, ENG OPTIMIZ, V53, P1651, DOI 10.1080/0305215X.2020.1808974
   Dey N, 2019, BIOCYBERN BIOMED ENG, V39, P843, DOI 10.1016/j.bbe.2019.07.005
   Dey N, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10020051
   Dhiman G, 2017, 2017 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND DATA SCIENCE (MLDS 2017), P114, DOI 10.1109/MLDS.2017.5
   Dorigo M., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1470, DOI 10.1109/CEC.1999.782657
   Duan HB, 2014, INT J INTELL COMPUT, V7, P24, DOI 10.1108/IJICC-02-2014-0005
   Eberhart RC, 2000, IEEE C EVOL COMPUTAT, P84, DOI 10.1109/CEC.2000.870279
   Fan Z, 2018, IEEE C EVOL COMPUTAT, P431, DOI 10.1109/CEC.2018.8477943
   Fang JK, 2018, ENERGIES, V11, DOI 10.3390/en11081922
   Gandomi AH, 2013, ENG COMPUT-GERMANY, V29, P245, DOI 10.1007/s00366-012-0308-4
   Garcia RD, 2017, COMPUT STRUCT, V187, P77, DOI 10.1016/j.compstruc.2017.03.023
   Harrison KR, 2016, SWARM INTELL-US, V10, P267, DOI 10.1007/s11721-016-0128-z
   Hellwig M, 2018, IEEE C EVOL COMPUTAT, P749, DOI 10.1109/CEC.2018.8477950
   Hongping Hu, 2017, International Journal of Circuits, Systems and Signal Processing, V11, P12
   Huang XW, 2020, CLUSTER COMPUT, V23, P1137, DOI 10.1007/s10586-019-02983-5
   Imran M, 2013, PROCEDIA ENGINEER, V53, P491, DOI 10.1016/j.proeng.2013.02.063
   Karaboga D., 2010, Scholarpedia, V5, P6915, DOI [DOI 10.4249/SCHOLARPEDIA.6915, 10.4249/scholarpedia.6915]
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kentzoglanakis K., 2009, Proceedings of the 11th Annual Conference on Genetic and Evolutionary Computation, GECCO'09, P1749, DOI DOI 10.1145/1569901.1570140
   Kiani A. T., 2020, 2020 20 IEEE INT C, P1, DOI DOI 10.1109/eeeic/icpseurope49358.2020.9160531
   Kumar A, 2020, SWARM EVOL COMPUT, V56, DOI 10.1016/j.swevo.2020.100693
   Liu H, 2020, EXPERT SYST APPL, V152, DOI 10.1016/j.eswa.2020.113353
   Malik RezaFirsandaya., 2007, International Journal of Computer Science and Security, V1, P35
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Naik A, 2020, APPL SOFT COMPUT, V95, DOI 10.1016/j.asoc.2020.106524
   Naik A, 2018, NEURAL COMPUT APPL, V30, P271, DOI 10.1007/s00521-016-2686-9
   Nickabadi A, 2011, APPL SOFT COMPUT, V11, P3658, DOI 10.1016/j.asoc.2011.01.037
   Olivas F, 2017, APPL SOFT COMPUT, V53, P74, DOI 10.1016/j.asoc.2016.12.015
   Orouskhani M, 2011, LECT NOTES COMPUT SC, V6728, P321, DOI 10.1007/978-3-642-21515-5_38
   Pawan YVRN, 2020, ADV INTELL SYST COMP, V1057, P197, DOI 10.1007/978-981-15-0184-5_18
   Praveen SP, 2018, ARAB J SCI ENG, V43, P4265, DOI 10.1007/s13369-017-2926-z
   Rajinikanth V, 2018, ARAB J SCI ENG, V43, P4365, DOI 10.1007/s13369-017-3053-6
   Rani K. N. Abdul, 2012, 2012 IEEE Symposium on Wireless Technology & Applications (ISWTA 2012), P210, DOI 10.1109/ISWTA.2012.6373845
   Rao RV, 2020, APPL ARTIF INTELL, V34, P187, DOI 10.1080/08839514.2020.1712789
   Rao V., 2011, EPPM Singap, V20, P21
   Rathore A, 2017, ADV INTELL SYST, V547, P76, DOI 10.1007/978-981-10-3325-4_9
   Rauf HT, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106159
   Satapathy S, 2016, COMPLEX INTELL SYST, V2, P173, DOI 10.1007/s40747-016-0022-8
   Shukla AK, 2020, APPL MATH MODEL, V77, P309, DOI 10.1016/j.apm.2019.07.046
   Trivedi A, 2018, P 2018 IEEE C EV COM, P1
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yong Feng, 2007, 2007 Second International Conference on Innovative Computing, Information and Control, P1899
   Yue XF, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106157
   Zheng YL, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P1802, DOI 10.1109/ICMLC.2003.1259789
NR 55
TC 11
Z9 11
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2021 AUG 24
PY 2021
DI 10.1007/s11042-021-11266-4
EA AUG 2021
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UE5KF
UT WOS:000687926200008
DA 2024-07-18
ER

PT J
AU Ghazali, R
   Ali, FHM
   Bakar, HA
   Ahmad, MN
   Haron, NS
   Omar, AH
   Ahmadian, A
AF Ghazali, Razatulshima
   Ali, Faizura Haneem Mohamed
   Bakar, Hussin Abu
   Ahmad, Mohammad Nazir
   Haron, Nazleeni Samiha
   Omar, Abdullah Hisam
   Ahmadian, Ali
TI Blockchain for record-keeping and data verifying: proof of concept
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ethereum blockchain; Proof of concept; Muslim marriage record;
   Record-keeper
AB The paper aims to show how blockchain, particularly Ethereum private blockchain, performs as a record keeper for Malaysian Muslim marriage records as a case study. The study also aims to demonstrate how blockchain technology conserves marriage data and improves data sharing efficiency involves accessing data from the blockchain and multiple users through proof of concept (POC). This POC also intended to seek evidence of immutability, transparency, and authenticity claims by the technology to ensure the record's security is a high priority. The study implements a smart contract on the Ethereum platform in the Government of Malaysia network environment and, the results provide significant evidence of private Ethereum blockchain principles of high availability, efficiency, immutability, transparency, and truthfulness particularly in record keeping. Future research can investigate other blockchain technology for other blockchain initiatives, such as blockchain disruptors. This paper is useful for management researchers and guides management practice for decision-making when determining whether the technology can use as a record-keeper. This paper proposes POC to design and develop record-keeping of Malaysian Muslim marriage records using Ethereum blockchain technology.
C1 [Ghazali, Razatulshima; Ali, Faizura Haneem Mohamed; Bakar, Hussin Abu] Malaysian Adm Modernizat & Management Planning Un, MKN Embassy Techzone Bldg,Block BJalan Teknokrat, Cyberjaya 63000, Selangor, Malaysia.
   [Ahmad, Mohammad Nazir] Univ Kebangsaan Malaysia, Inst IR4 0, Bangi 43600, Selangor, Malaysia.
   [Haron, Nazleeni Samiha] Univ Teknol PETRONAS, Univ Teknol Petronas, Ctr Res Data Sci, Bandar Seri Iskandar 32610, Perak, Malaysia.
   [Omar, Abdullah Hisam] Univ Teknol Malaysia, Fac Built Environm & Surveying, Skudai 81310, Kagawa, Malaysia.
   [Ahmadian, Ali] Univ Kebangsaan Malaysia, Bangi 43600, Selangor, Malaysia.
   [Ahmadian, Ali] Near East Univ, TRNC, Dept Math, Mersin 10, Turkey.
C3 Universiti Kebangsaan Malaysia; Universiti Teknologi Petronas;
   Universiti Teknologi Malaysia; Universiti Kebangsaan Malaysia; Near East
   University
RP Ahmad, MN (corresponding author), Univ Kebangsaan Malaysia, Inst IR4 0, Bangi 43600, Selangor, Malaysia.
EM mnazir@ukm.edu.my
RI Ahmadian, Ali/N-3697-2015; AHMAD, Mohammad Nazir/AAU-7449-2020
OI Ahmadian, Ali/0000-0002-0106-7050; AHMAD, Mohammad
   Nazir/0000-0003-3639-1157; Haron, Nazleeni/0000-0002-8028-3033
FU Malaysian Administrative Modernisation and Management Planning Unit
   (MAMPU), ICT Consulting Division, Prime Minister Department of Malaysia;
   Industrial Research Grant, Integrasi Erat Sdn. Bhd [ZG-2021-001]
FX This work is supported by the Malaysian Administrative Modernisation and
   Management Planning Unit (MAMPU), ICT Consulting Division, Prime
   Minister Department of Malaysia, and Industrial Research Grant,
   Integrasi Erat Sdn. Bhd, Vot. No: ZG-2021-001. High appreciation goes to
   the above sponsors. The authors gratefully acknowledge ICT Consulting
   Division blockchain team members for their sheer dedication to this POC.
CR Abeyratne S. A., 2016, INT J RES ENG TECHNO, V5, P1, DOI [10.15623/ijret.2016.0509001, DOI 10.15623/IJRET.2016.0509001]
   Alghamdi TA, 2020, IEEE ACCESS, V8, P1048, DOI 10.1109/ACCESS.2019.2961612
   Androulaki E, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190538
   Aziz AA., 2020, ETHEREUM PRIVATE NET
   Dorri A, 2017, IEEE COMMUN MAG, V55, P119, DOI 10.1109/MCOM.2017.1700879
   Furlonger D, 2018, PAY ATTENTION THESE
   Golosova J, 2018, 2018 IEEE 6TH WORKSHOP ON ADVANCES IN INFORMATION, ELECTRONIC AND ELECTRICAL ENGINEERING (AIEEE)
   Guegan D., 2017, Public Blockchain Versus Private Blockchain
   Ismail WAFW., 2015, GEOGRAFIA MALAYS J S, V11, P32
   Kamaruzaman N, 2018, INT J ENG TECHNOLOGY, V7, P193, DOI [10.14419/ijet.v7i4.11.20802, DOI 10.14419/IJET.V7I4.11.20802]
   Leising M, 2020, BLOOMBERG
   Makhdoom I, 2020, COMPUT SECUR, V88, DOI 10.1016/j.cose.2019.101653
   Mohamad M, 2017, J POLIT LAW, V10, P140, DOI 10.5539/jpl.v10n5p140
   Review B, 2018, ETHEREUM WHITE PAPER, P1
   Salleh AZ, 2016, SCI INT LAHORE, V28, P1753
   Shuaib F.S., 2012, Pacific Rim Law & Policy Journal, V21, P85
   Sicilia MA, 2019, LIBR HI TECH, V37, P30, DOI 10.1108/LHT-12-2017-0276
   Sun ML, 2020, COMPUT COMMUN, V149, P332, DOI 10.1016/j.comcom.2019.10.031
   Tith D, 2020, HEALTHC INFORM RES, V26, P3, DOI 10.4258/hir.2020.26.1.3
   Vazirani AA, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-019-0211-0
   Viriyasitavat W, 2019, J IND INF INTEGR, V13, P32, DOI 10.1016/j.jii.2018.07.004
   Wang S, 2019, IEEE T SYST MAN CY-S, V49, P2266, DOI 10.1109/TSMC.2019.2895123
   Wang YL, 2019, SUPPLY CHAIN MANAG, V24, P62, DOI 10.1108/SCM-03-2018-0148
   Wei, 2019, WHICEB 2019 P WUH CH
   Zhao XF, 2017, INT CONF SYST INFORM, P1743, DOI 10.1109/ICSAI.2017.8248566
   Zhu Y, 2019, FRONT COMPUT SCI-CHI, V13, P1182, DOI 10.1007/s11704-017-6338-8
NR 26
TC 2
Z9 2
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36587
EP 36605
DI 10.1007/s11042-021-11336-7
EA AUG 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000684067200002
DA 2024-07-18
ER

PT J
AU Soundrapandiyan, R
   Satapathy, SC
   Mouli, PVSSRC
   Nhu, NG
AF Soundrapandiyan, Rajkumar
   Satapathy, Suresh Chandra
   Mouli, P. V. S. S. R. Chandra
   Nhu, Nguyen Gia
TI A comprehensive survey on image enhancement techniques with special
   emphasis on infrared images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Infrared imagery; Image enhancement; Histogram based method; Filter
   based method; Morphology based method; Fuzzy based method; Learning
   method
ID BI-HISTOGRAM EQUALIZATION; CONTRAST ENHANCEMENT; SMALL TARGET;
   ALGORITHM; EXTRACTION; OPERATOR; FUSION
AB Capturing of infrared images is an easy task but perceptual visualization is difficult due to environmental conditions such as light rain, partly cloudy, mostly cloudy, haze, poor lightening conditions, noise generated by the sensors, geographical distance and appearances of the objects. To improve the human perception and quality of the infrared images for further processing like image analysis, image enhancement is an essential process. This paper provides a detailed review of various image enhancement techniques from contrast stretching to optimization methods used in infrared images. It also discusses the existing infrared image enhancement techniques as group such as histogram based methods, filter based methods, transform domain based methods, morphological based methods, saliency extraction methods, fuzzy based methods, learning methods, optimization methods and its popular algorithms also address the countless issues. Some of the existing image enhancement methods (Histogram Equlization, Max-median filter, Top-Hat transform) and infrared image enhancement methods (multi-scale top-hat transform, adaptive infrared image enhancement) are implemented along with the adaptive fuzzy based infrared image enhancement method and its obtained results evaluation is done on subjective and objective ways. From the results observed that the fuzzy based method works well for both subjective and objective evaluation. The paper aims to provide a complete study on image enhancement techniques and how they specially utilized while dealing with infrared images. In addition, the paper helps the researchers to select the suitable infrared image enhancement techniques for their infrared image application needs.
C1 [Soundrapandiyan, Rajkumar] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
   [Satapathy, Suresh Chandra] Kalinga Inst Ind Technol Deemed Be Univ, Sch Comp Sci & Engn, Bhubaneswar, Odisha, India.
   [Mouli, P. V. S. S. R. Chandra] Cent Univ Tamil Nadu, Dept Comp Sci, Thiruvarur, Tamil Nadu, India.
   [Nhu, Nguyen Gia] Duy Tan Univ, Grad Sch, Danang, Vietnam.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Kalinga Institute of
   Industrial Technology (KIIT); Central University of Tamil Nadu; Duy Tan
   University
RP Satapathy, SC (corresponding author), Kalinga Inst Ind Technol Deemed Be Univ, Sch Comp Sci & Engn, Bhubaneswar, Odisha, India.
EM rajkumarsrajkumar@gmail.com; sureshsatapathy@ieee.org;
   chandramouli@cutn.ac.in; nguyengianhu@duytan.edu.vn
RI Nhu, Nguyen Gia/E-4331-2016; Soundrapandiyan, Rajkumar/ABA-1411-2021
OI Nhu, Nguyen Gia/0000-0003-4267-3900; Soundrapandiyan,
   Rajkumar/0000-0001-5701-9325; P.V.S.S.R., Chandra
   Mouli/0000-0001-7909-9733; satapathy, suresh chandra/0000-0001-8236-4104
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 1991, Computer and Robot Vision
   Ashiba H. I., 2008, Progress In Electromagnetics Research C, V1, P123, DOI 10.2528/PIERC08012301
   Bai XZ, 2014, OPTIK, V125, P3697, DOI 10.1016/j.ijleo.2014.01.130
   Bai XZ, 2013, INFRARED PHYS TECHN, V60, P81, DOI 10.1016/j.infrared.2013.03.002
   Bai XZ, 2013, OPTIK, V124, P1614, DOI 10.1016/j.ijleo.2012.06.016
   Bai XZ, 2010, COMPUT ELECTR ENG, V36, P1193, DOI 10.1016/j.compeleceng.2010.05.008
   Bai XZ, 2011, INFRARED PHYS TECHN, V54, P61, DOI 10.1016/j.infrared.2010.12.001
   Bai XZ, 2010, PATTERN RECOGN, V43, P2145, DOI 10.1016/j.patcog.2009.12.023
   Bai XZ, 2010, SIGNAL PROCESS, V90, P1643, DOI 10.1016/j.sigpro.2009.11.014
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Davis James W, 2007, OTCBVS Benchmark Dataset Collection
   Deshpande SD, 1999, P SOC PHOTO-OPT INS, V3809, P74, DOI 10.1117/12.364049
   Dougherty, 2003, OPTICAL ENG SPIE T I, DOI 10.1117/3.501104
   Ein-shoka AA, 2018, OPTIK, V160, P146, DOI 10.1016/j.ijleo.2017.12.056
   Fan ZL, 2017, INFRARED PHYS TECHN, V86, P44, DOI 10.1016/j.infrared.2017.08.015
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   Gupta KK, 2012, ARXIV12013972
   HADHOUD MM, 1988, IEEE T CIRCUITS SYST, V35, P485, DOI 10.1109/31.1775
   Haykin Simon, 2003, Least-mean-square adaptive filters, V31
   Horn B.K.P, 1986, Robot Vision
   Huang ZH, 2016, INFRARED PHYS TECHN, V79, P205, DOI 10.1016/j.infrared.2016.11.001
   Jackway PT, 1996, IEEE T PATTERN ANAL, V18, P38, DOI 10.1109/34.476009
   Kara AO, 2011, INFRARED PHYS TECHN, V54, P382, DOI 10.1016/j.infrared.2011.05.003
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kuang XD, 2019, NEUROCOMPUTING, V332, P119, DOI 10.1016/j.neucom.2018.11.081
   Lewis J.P., 1995, Vision, Interface, V95, P120
   Li S, 2018, INFRARED PHYS TECHN, V90, P164, DOI 10.1016/j.infrared.2018.03.010
   Li Y., 2019, OPTIK, V199, P1
   Lin CL, 2011, INFRARED PHYS TECHN, V54, P84, DOI 10.1016/j.infrared.2011.01.001
   Liu N, 2016, INFRARED PHYS TECHN, V77, P405, DOI 10.1016/j.infrared.2016.06.017
   Liu N, 2014, INFRARED PHYS TECHN, V67, P138, DOI 10.1016/j.infrared.2014.07.013
   Menotti D, 2007, IEEE T CONSUM ELECTR, V53, P1186, DOI 10.1109/TCE.2007.4341603
   Mukhopadhyay S, 2000, SIGNAL PROCESS, V80, P685, DOI 10.1016/S0165-1684(99)00161-9
   Oliveira MA, 2008, PATTERN RECOGN, V41, P367, DOI 10.1016/j.patcog.2007.05.019
   Patel S, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P167, DOI 10.1109/IC3I.2014.7019808
   Rajkumar S, 2015, INFORM COMMUNICATION, P9
   Roebuck, 2012, TERAHERTZ RAD HIGH I
   Sayood K, 2017, Introduction to data compression
   Schalko RJ., 1989, DIGITAL IMAGE PROCES
   Sengee N, 2010, IEEE T CONSUM ELECTR, V56, P2727, DOI 10.1109/TCE.2010.5681162
   Serra J., 1983, IMAGE ANAL MATH MORP
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Song Q, 2016, INFRARED PHYS TECHN, V77, P464, DOI 10.1016/j.infrared.2016.06.023
   Song YF., 2008, INFRARED LASER ENG, V2, P1
   SONI T, 1991, INT CONF ACOUST SPEE, P3029, DOI 10.1109/ICASSP.1991.151041
   Soundrapandiyan, 2015, T COMPUTATIONAL SCI, P1
   Vernon D., 1991, Machine vision-Automated visual inspection and robot vision
   Vickers VE, 1996, OPT ENG, V35, P1921, DOI 10.1117/1.601006
   Wang BJ, 2006, INFRARED PHYS TECHN, V48, P77, DOI 10.1016/j.infrared.2005.04.008
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xu FY, 2016, INFRARED PHYS TECHN, V76, P560, DOI 10.1016/j.infrared.2016.04.008
   Zhao F, 2016, INFRARED PHYS TECHN, V76, P408, DOI 10.1016/j.infrared.2016.03.022
   Zhao JC, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.703
   Zhao JF, 2014, OPTIK, V125, P4039, DOI 10.1016/j.ijleo.2014.01.117
   Zhao JF, 2014, INFRARED PHYS TECHN, V62, P86, DOI 10.1016/j.infrared.2013.11.008
   Zhao JF, 2013, OPT COMMUN, V287, P45, DOI 10.1016/j.optcom.2012.08.070
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
   Zuo C, 2013, OPTIK, V124, P425, DOI 10.1016/j.ijleo.2011.12.057
NR 62
TC 7
Z9 7
U1 16
U2 104
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9045
EP 9077
DI 10.1007/s11042-021-11250-y
EA AUG 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000681210700003
DA 2024-07-18
ER

PT J
AU Dixit, S
   Kala, R
AF Dixit, Shivam
   Kala, Rahul
TI Early detection of heart diseases using a low-cost compact ECG sensor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical expert systems; Heart diseases; Machine learning; ECG signal;
   Random forest; Gradient boosting; Oversampling; 1D convolution neural
   net
ID NEURAL-NETWORK MODEL; CLASSIFICATION; FIELDS; SMOTE
AB Heart disease patients are continuously increasing. The patients face the problem of a delayed diagnosis as the subjects do not undergo routine tests and consult a doctor only after severe symptoms. Most medical expert systems are designed to aid the doctors in making wise decisions and only such data sets exist in the literature. We attack the problem of an early-stage diagnosis that can be done at the home by the subject himself on a routine basis, using a low cost and compact ECG sensor. Machine learning tools nowadays have become important for data processing and assistance in various fields including medicine. Attributed to an absence of data, we first developed our ECG dataset by collecting ECG signal data from 300 persons including 53 cardiac patients and 247 healthy persons, using a low-cost and compact ECG sensor. To detect the heart diseases from this data, classical methods (Random forest and Gradient boosting) and state of the art Deep Learning models (1D Convolution Neural Net) were used. A problem with machine learning in the specific context is a severe data imbalance, for which oversampling of minority data was used. Since the sensor is a low cost, noise can get added up. Hence, voting across multiple time windows is done to improve the results. After a healthy comparison between all classification methods with different techniques based on their test accuracy, 1D CNN with oversampling and using voting strategy comes out as the best classifiers with a 93% test accuracy.
C1 [Dixit, Shivam; Kala, Rahul] Indian Inst Informat Technol, Ctr Intelligent Robot, Allahabad, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Dixit, S (corresponding author), Indian Inst Informat Technol, Ctr Intelligent Robot, Allahabad, Uttar Pradesh, India.
EM shivamdixit1795@gmail.com; rkala001@gmail.com
OI Dixit, Shivam/0000-0002-6058-3899
FU ASEAN-India Collaborative Research Project, AISTDF
   [IMRC/AISTDF/RD/P-6/2017]; Indian Institute of Information Technology
   (IIIT), Allahabad
FX The work is funded by the ASEAN-India Collaborative Research Project,
   AISTDF Secretariat with grant number IMRC/AISTDF/R&D/P-6/2017 and the
   Indian Institute of Information Technology (IIIT), Allahabad. The
   authors also wish to thank Dr. Piyush Saxena (M.D.) in specific and the
   entire administration and team of the Department of Cardiology, Swaroop
   Rani Nehru Hospital-Allahabad for their help in recording the data. The
   authors wish to thank Dr. Sonali Agarwal for constant help throughout
   the project. The authors also wish to thank Hemantharaj M, Tanuj Pal
   Singh, and Dharmendra Prajapat, who helped in the data collection.
CR Acharya UR, 2017, COMPUT BIOL MED, V89, P389, DOI 10.1016/j.compbiomed.2017.08.022
   Ayar Mehdi, 2018, Informatics in Medicine Unlocked, V13, P167, DOI 10.1016/j.imu.2018.06.002
   Batista G. E., 2004, ACM SIGKDD EXPL NEWS, V6, P20, DOI DOI 10.1145/1007730.1007735
   Batista GE., 2003, Balancing Training Data for Automated Annotation of Keywords: A Case Study
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   de Lannoy G, 2012, IEEE T BIO-MED ENG, V59, P241, DOI 10.1109/TBME.2011.2171037
   Dixit S, 2020, ECG DATASET
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo XJ, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 4, PROCEEDINGS, P192, DOI 10.1109/ICNC.2008.871
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Kotsiantis S., 2006, GESTS INT T COMPUTER, V30, P25
   Kotsiantis S., 2003, ANN MATH COMPUTING T, V1, P46
   Kubat M., 1997, ICML, P179
   Luz EJD, 2016, COMPUT METH PROG BIO, V127, P144, DOI 10.1016/j.cmpb.2015.12.008
   Mondéjar-Guerra V, 2019, BIOMED SIGNAL PROCES, V47, P41, DOI 10.1016/j.bspc.2018.08.007
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Patil Prithvi., 2019, IEEE, P1, DOI DOI 10.1109/ICASERT.2019.8934463
   Rajesh KNVPS, 2018, BIOMED SIGNAL PROCES, V41, P242, DOI 10.1016/j.bspc.2017.12.004
   Sannino G, 2018, FUTURE GENER COMP SY, V86, P446, DOI 10.1016/j.future.2018.03.057
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Visa S., 2005, P 16 MIDW ART INT CO, P67
   Yildirim Ö, 2018, COMPUT BIOL MED, V102, P411, DOI 10.1016/j.compbiomed.2018.09.009
   Yildirim Ö, 2018, COMPUT BIOL MED, V96, P189, DOI 10.1016/j.compbiomed.2018.03.016
   Zhai XL, 2018, IEEE ACCESS, V6, P27465, DOI 10.1109/ACCESS.2018.2833841
NR 30
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32615
EP 32637
DI 10.1007/s11042-021-11083-9
EA AUG 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000679884900001
DA 2024-07-18
ER

PT J
AU Tembhurne, JV
   Hazarika, A
   Diwan, T
AF Tembhurne, Jitendra, V
   Hazarika, Anupama
   Diwan, Tausif
TI BrC-MCDLM: breast Cancer detection using Multi-Channel deep learning
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Classification; Deep convolutional neural network;
   Multi-channel merging
ID DIAGNOSIS; BENIGN; IMAGES
AB Breast cancer (BrC) is a lethal form of cancer which causes numerous deaths in women across the world. Generally, mammograms and histopathology biopsy images are recommended for early detection of BrC as they enable a more reliable prediction than just using mammograms. However, research indicates that even the most experienced dermatologists can detect BrC in early stage with an average accuracy of less than 80%. Over the years, researchers have made significant progress in the development of automated tools and techniques to assist radiologists or medical practitioners in BrC detection. Various machine learning and deep learning based architectures are extensively experimented on different publicly available datasets to improve the performance measures. There is further scope of improvements by extracting better representative features with deep architectural variants or ensembles techniques to minimize the misclassifications. Learnt parameters of any pretrained deep models may provide a better starting point for any other architectures using transfer learning technique. In this work, we propose computer-aided transfer learning based deep model as a binary classifier for breast cancer detection. Generally, deep learning architectures are sequential, following only a single channel for features' extraction and further classification. However, fused features extracted from multiple channels may better represent features qualitatively. The novelty of our approach is the use of multi-channel merging techniques for devising a dual-architecture ensemble. The models are trained and tested on the BreakHis dataset and an improvement in comparison with the state-of-the-arts is observed in various performance metrics. Among several combinations for ensemble architectures by utilizing various pretrained models, the Xception + InceptionV3 combination achieved an average accuracy of 97.5% for multi-channelled architecture, setting benchmarking results for further research in this direction.
C1 [Tembhurne, Jitendra, V; Diwan, Tausif] Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
   [Hazarika, Anupama] Tezpur Univ, Dept Comp Sci & Engn, Tezpur, Assam, India.
C3 Tezpur University
RP Tembhurne, JV (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
EM jtembhurne@iiitn.ac.in; anupama_csb17@agnee.tezu.emet.in;
   tdiwan@iiitn.ac.in
RI Diwan, Tausif/AFN-9746-2022; Tembhurne, Jitendra/AGI-1097-2022
OI Tembhurne, Jitendra/0000-0002-1389-3456
CR Abdullah-Al Nahid, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/2362108
   Aghdam MH, 2015, J ARTIF INTELL SOFT, V5, P231, DOI 10.1515/jaiscr-2015-0031
   Ak MF, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8020111
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Allison KH, 2014, HISTOPATHOLOGY, V65, P240, DOI 10.1111/his.12387
   Alom MZ, 2019, J DIGIT IMAGING, V32, P605, DOI 10.1007/s10278-019-00182-7
   Alzubaidi L, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030445
   [Anonymous], 2017, US CANC STAT 1999 20
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2020, Breast cancer facts figures 2019-2020
   Araújo T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177544
   Arslan A.K., 2019, 2019 3 INT S MULTIDI, P1, DOI DOI 10.1109/ISMSIT.2019.8932942
   Awan R, 2018, LECT NOTES COMPUT SC, V10882, P788, DOI 10.1007/978-3-319-93000-8_89
   Bardou D, 2018, IEEE ACCESS, V6, P24680, DOI 10.1109/ACCESS.2018.2831280
   Bayramoglu N, 2016, INT C PATT RECOG, P2440, DOI 10.1109/ICPR.2016.7900002
   Chan A, 2016, ROY SOC OPEN SCI, V3, DOI 10.1098/rsos.160558
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chollet F, 2015, KERAS
   Cytecare Cancer Hopitals, 2020, STAT BREAST CANC IND
   Ferreira CA, 2018, LECT NOTES COMPUT SC, V10882, P763, DOI 10.1007/978-3-319-93000-8_86
   George YM, 2014, IEEE SYST J, V8, P949, DOI 10.1109/JSYST.2013.2279415
   Gupta K, 2020, PROCEDIA COMPUT SCI, V167, P878, DOI 10.1016/j.procs.2020.03.427
   Gupta V, 2017, IEEE COMPUT SOC CONF, P769, DOI 10.1109/CVPRW.2017.107
   Hadush S, 2020, ARXIV PREPRINT ARXIV
   Hamed Ghada, 2020, Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020). Advances in Intelligent Systems and Computing (AISC 1153), P322, DOI 10.1007/978-3-030-44289-7_30
   Hameed Z, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164373
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jiang Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214587
   Kahya M.A., 2017, J. Appl. Math. Bioinf., V7, P49
   Kassani SH, 2019, I C INF COMM TECH CO, P519, DOI 10.1109/ictc46691.2019.8939878
   Kaya Keles M, 2019, TEH VJESN, V26, P149, DOI 10.17559/TV-20180417102943
   Liu W., 2020, CLASSIFICATIONS BREA, DOI [10.1101/2020.06.13.20130633, DOI 10.1101/2020.06.13.20130633]
   López-García G, 2019, LECT NOTES COMPUT SC, V11506, P912, DOI 10.1007/978-3-030-20521-8_74
   Malon Christopher D, 2013, J Pathol Inform, V4, P9, DOI 10.4103/2153-3539.112694
   Mayo Clinic, 2019, BREAST CANCER-TOKYO
   Migowski A, 2015, CIENC SAUDE COLETIVA, V20, P1309, DOI 10.1590/1413-81232015204.17772014
   Milosevic M, 2018, TECHNOL HEALTH CARE, V26, P729, DOI 10.3233/THC-181277
   Murtaza G, 2020, MULTIMED TOOLS APPL, V79, P18447, DOI 10.1007/s11042-020-08692-1
   Nawaz M, 2018, INT J ADV COMPUT SC, V9, P316
   Nawaz W, 2018, LECT NOTES COMPUT SC, V10882, P869, DOI 10.1007/978-3-319-93000-8_99
   Patil A, 2019, PROCEEDINGS OF THE TENTH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES AND DEVELOPMENT (ICTD), DOI 10.1145/3287098.3287144
   Ragab DA, 2019, PEERJ, V7, DOI 10.7717/peerj.6201
   Rajarapollu P.R., 2017, Ijcst, V8, P23
   Rouhi R, 2015, EXPERT SYST APPL, V42, P990, DOI 10.1016/j.eswa.2014.09.020
   Samala RK, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aabb5b
   Sommer C, 2012, INT C PATT RECOG, P2306
   Spanhol FA, 2017, IEEE SYS MAN CYBERN, P1868, DOI 10.1109/SMC.2017.8122889
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tkachenko Roman, 2019, Advances in Computer Science for Engineering and Education. Advances in Intelligent Systems and Computing (AISC 754), P578, DOI 10.1007/978-3-319-91008-6_58
   Vang Yeeleng S., 2018, Image Analysis and Recognition. 15th International Conference, ICIAR 2018. Proceedings: LNCS 10882, P914, DOI 10.1007/978-3-319-93000-8_104
   Vrigazova BP, 2020, J DATA INFO SCI, V5, P62, DOI 10.2478/jdis-2020-0012
   Wang YJ, 2020, IEEE ACCESS, V8, P27779, DOI 10.1109/ACCESS.2020.2964276
   Wang ZY, 2018, LECT NOTES COMPUT SC, V10882, P745, DOI 10.1007/978-3-319-93000-8_84
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yao Guo, 2018, Image Analysis and Recognition. 15th International Conference, ICIAR 2018. Proceedings: LNCS 10882, P827, DOI 10.1007/978-3-319-93000-8_94
   Zhang YG, 2013, MACH VISION APPL, V24, P1405, DOI 10.1007/s00138-012-0459-8
   Zheng J, 2020, IEEE ACCESS, V8, P96946, DOI 10.1109/ACCESS.2020.2993536
NR 61
TC 7
Z9 7
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31647
EP 31670
DI 10.1007/s11042-021-11199-y
EA JUL 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000673927900001
DA 2024-07-18
ER

PT J
AU Breve, B
   Cirillo, S
   Cuofano, M
   Desiato, D
AF Breve, Bernardo
   Cirillo, Stefano
   Cuofano, Mariano
   Desiato, Domenico
TI Enhancing spatial perception through sound: mapping human movements into
   MIDI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Movements tracking; MIDI sound; Synthesizer sounds
ID GESTURE RECOGNITION
AB Gestural expressiveness plays a fundamental role in the interaction with people, environments, animals, things, and so on. Thus, several emerging application domains would exploit the interpretation of movements to support their critical designing processes. To this end, new forms to express the people's perceptions could help their interpretation, like in the case of music. In this paper, we investigate the user's perception associated with the interpretation of sounds by highlighting how sounds can be exploited for helping users in adapting to a specific environment. We present a novel algorithm for mapping human movements into MIDI music. The algorithm has been implemented in a system that integrates a module for real-time tracking of movements through a sample based synthesizer using different types of filters to modulate frequencies. The system has been evaluated through a user study, in which several users have participated in a room experience, yielding significant results about their perceptions with respect to the environment they were immersed.
C1 [Breve, Bernardo; Cirillo, Stefano; Desiato, Domenico] Univ Salerno, Dept Comp Sci, I-84084 Fisciano, SA, Italy.
   [Cuofano, Mariano] Royal Coll Art, MRes Architecture, London, England.
C3 University of Salerno; Royal College of Art - UK
RP Cirillo, S (corresponding author), Univ Salerno, Dept Comp Sci, I-84084 Fisciano, SA, Italy.
EM bbreve@unisa.it; scirillo@unisa.it; mariano.cuofano@alumni.rca.ac.uk;
   ddesiato@unisa.it
RI Cirillo, Stefano/ABG-6171-2020; DESIATO, Domenico/HLP-6837-2023;
   Desiato, Domenico/ISA-3303-2023
OI Cirillo, Stefano/0000-0003-0201-2753; DESIATO,
   Domenico/0000-0002-6327-459X; Desiato, Domenico/0000-0002-6327-459X;
   Breve, Bernardo/0000-0002-3898-7512
FU Universita degli Studi di Salerno within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi di Salerno within
   the CRUI-CARE Agreement.
CR [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   Aureli, 2017, ROOM ONES OWN ARCHIT
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bagdanov AD, 2012, INT C PATT RECOG, P2456
   BOHUSH R, 2019, INT C PATTERN RECOGN, P289
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Caruccio L, 2020, ACM J DATA INF QUAL, V12, DOI 10.1145/3397462
   Caruccio L, 2019, EXPERT SYST APPL, V131, P190, DOI 10.1016/j.eswa.2019.04.031
   Chin-Shyurng F, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030528
   CHOI I, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS, VOLS 1-5, P2772, DOI 10.1109/ICSMC.1995.538582
   Cook T, 2019, PSYCHOL MUSIC, V47, P144, DOI 10.1177/0305735617734627
   Costagliola G, 2009, IEEE T KNOWL DATA EN, V21, P773, DOI 10.1109/TKDE.2008.133
   Flam M, 2001, Patent, Patent No. [6,191,349, 6191349]
   Helmholtz H., 2013, On the sensations of tone
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hongyang Zhao, 2019, Smart Health, V11, P45, DOI 10.1016/j.smhl.2017.12.003
   Huber D.M., 2007, MIDI MANUAL PRACTICA
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Moccia S, 2020, IEEE T BIO-MED ENG, V67, P2370, DOI 10.1109/TBME.2019.2961448
   MOORE FR, 1988, COMPUT MUSIC J, V12, P19, DOI 10.2307/3679834
   Nikouei SeyedYahya., 2019, 2019 Wireless Days (WD), P1
   Niu W, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P719, DOI 10.1109/ICME.2004.1394293
   Overholt D., 2001, NIME'01 Proceedings of the 2001 conference on New interfaces for musical expression, P38
   Ozcan G, 2005, IEEE INT SYM MULTIM, P414
   Picard R, 1998, P INT COMP MUS C
   Polese G., 1998, ICONIC LANGUAGE DESI, P12, DOI 10.1007/BFb0055967
   Raaj Y, 2019, PROC CVPR IEEE, P4615, DOI 10.1109/CVPR.2019.00475
   Rumsey F., 1994, MIDI SYSTEMS CONTROL
   Shehzed Ahsan, 2019, 2019 International Conference on Applied and Engineering Mathematics (ICAEM), P163, DOI 10.1109/ICAEM.2019.8853756
   Theodoridis, 2008, P 16 ACM SIGSPATIAL, P1
   Vitiello G, 2018, GOODTECHS '18: PROCEEDINGS OF THE 4TH EAI INTERNATIONAL CONFERENCE ON SMART OBJECTS AND TECHNOLOGIES FOR SOCIAL GOOD (GOODTECHS), P249, DOI 10.1145/3284869.3284908
   Yildirim Mustafa E., 2014, International Journal of Computer and Communication Engineering, V3, P105, DOI 10.7763/IJCCE.2014.V3.301
NR 34
TC 9
Z9 9
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 73
EP 94
DI 10.1007/s11042-021-11077-7
EA JUN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000663271700002
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, XW
   Yue, YZ
   Han, L
   Li, F
   Yuan, XZ
   Fan, MH
   Zhang, YN
AF Zhang, Xiuwei
   Yue, Yuanzeng
   Han, Lin
   Li, Fei
   Yuan, Xiuzhong
   Fan, Minhao
   Zhang, Yanning
TI River ice monitoring and change detection with multi-spectral and SAR
   images: application over yellow river
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-temporal data; Yellow River; Ice extraction; Change detection
ID STRUCTURED SPARSITY; CLASSIFICATION; ALGORITHM; LAKES
AB Spatially detailed characterization of the distribution amount and timing of river ice are important for identifying and predicting potential ice hazards. In this paper, we present an asynchronous river ice extraction and change detection method using multi-temporal SAR image and multi-spectral image. River channel information is a strong prior knowledge for ice detection and analysis. Therefore a river channel extraction algorithm on multi-spectral image based on sparse reconstruction is proposed and adopted in our method. The extracted river channel is used as prior information to effectively eliminate most interference regions on the shore. Then an adaptive threshold segmentation method is adopted to accurately detect river ice regions in SAR image. Fuzzy C-means clustering is used to segment river ice using the infrared bands of multi-spectral image, considering temperature can provide significant information to discriminate ice, water and shore. Finally, change analysis is done based on the ice extractions results of two kinds of images. The proposed method is applied on the Yellow River ice monitoring and experiments demonstrated that this straightforward approach works well with both SAR image and multi-spectral image.
C1 [Zhang, Xiuwei; Yue, Yuanzeng; Han, Lin; Li, Fei; Yuan, Xiuzhong; Fan, Minhao; Zhang, Yanning] Natl Engn Lab Integrated Aero Space Ground Ocean, Xian 710072, Peoples R China.
RP Zhang, XW (corresponding author), Natl Engn Lab Integrated Aero Space Ground Ocean, Xian 710072, Peoples R China.
EM xwzhang@nwpu.edu.com
RI li, bo/JJC-2664-2023
FU National Natural Science Foundation of China [61971356, 61801395,
   61971273, 62071384]; National Natural Science Foundation of Shaanxi
   province [2020GM-137]
FX This research is supported by the National Natural Science Foundation of
   China (Grant No.61971356, Grant No.61801395, Grant No.61971273 and Grant
   No.62071384) and the National Natural Science Foundation of Shaanxi
   province (2020GM-137).
CR Cai HM, 2014, IEEE T IMAGE PROCESS, V23, P1038, DOI 10.1109/TIP.2014.2298981
   Chaouch N, 2014, HYDROL PROCESS, V28, P62, DOI 10.1002/hyp.9548
   Chu T, 2015, REMOTE SENS-BASEL, V7, P13664, DOI 10.3390/rs71013664
   Cooley SW, 2016, REMOTE SENS ENVIRON, V175, P310, DOI 10.1016/j.rse.2016.01.004
   Dokken S. T., 2000, CANADIAN J REMOTE SE, V26, P521, DOI DOI 10.1080/07038992.2000.10874793
   Duong, 2012, INT ARCH PHOTOGRAMM, V39, pB8
   Gauthier Y, 2010, CAN J REMOTE SENS, V36, pS168, DOI 10.5589/m10-018
   Huang H, 2019, IEEE ACCESS, V7, P12386, DOI 10.1109/ACCESS.2019.2893063
   Jiang H, 2014, REMOTE SENS-BASEL, V6, P5067, DOI 10.3390/rs6065067
   Jinwen Wu, 2018, IOP Conference Series: Materials Science and Engineering, V392, DOI 10.1088/1757-899X/392/6/062105
   Kargel JS, 2005, REMOTE SENS ENVIRON, V99, P187, DOI 10.1016/j.rse.2005.07.004
   Kraatz S, 2016, COLD REG SCI TECHNOL, V131, P116, DOI 10.1016/j.coldregions.2016.09.012
   Li F, 2018, IEEE T GEOSCI REMOTE, V56, P4050, DOI 10.1109/TGRS.2018.2821168
   Lindenschmidt KE, 2015, CAN J CIVIL ENG, V42, P675, DOI 10.1139/cjce-2014-0377
   Liu G, 2017, J GLACIOL, V63, P382, DOI 10.1017/jog.2017.4
   Lundin, 2001, SAR REMOTE SENSING S
   Muhammad P, 2016, CRYOSPHERE, V10, P569, DOI 10.5194/tc-10-569-2016
   Patra S, 2014, APPL SOFT COMPUT, V23, P122, DOI 10.1016/j.asoc.2014.06.016
   Ressel R, 2015, IEEE J-STARS, V8, P3672, DOI 10.1109/JSTARS.2015.2436993
   Sharma A, 2016, ADV INTELL SYST, V434, P663, DOI 10.1007/978-81-322-2752-6_65
   Singla A, 2017, SIGNAL IMAGE VIDEO P, V11, P243, DOI 10.1007/s11760-016-0927-0
   Sobiech J, 2013, ANN GLACIOL, V54, P65, DOI 10.3189/2013AoG62A037
   Surdu CM, 2015, REMOTE SENS-BASEL, V7, P6133, DOI 10.3390/rs70506133
   Tom, 2018, REMOTE SENSING SPATI, V4, P279
   Vala Hetal J., 2013, INT J ADV RES COMPUT, V2, P387, DOI DOI 10.1007/S11548-009-0389-8
   Weber F, 2003, CAN J CIVIL ENG, V30, P11, DOI 10.1139/L02-073
   Yang XJ, 2019, J ADV COMPUT INTELL, V23, P107, DOI 10.20965/jaciii.2019.p0107
   Yommy AS, 2015, INT C INTEL HUM MACH, DOI 10.1109/IHMSC.2015.236
   Zhang L, 2016, IEEE T IMAGE PROCESS, V25, P4974, DOI 10.1109/TIP.2016.2598652
   Zhang YD, 2011, ENTROPY-SWITZ, V13, P841, DOI 10.3390/e13040841
   Zhao F, 2019, IEEE T FUZZY SYST, V27, P387, DOI 10.1109/TFUZZ.2018.2852289
NR 31
TC 8
Z9 8
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28989
EP 29004
DI 10.1007/s11042-021-11054-0
EA JUN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000662111500002
DA 2024-07-18
ER

PT J
AU Nawaz, M
   Masood, M
   Javed, A
   Iqbal, J
   Nazir, T
   Mehmood, A
   Ashraf, R
AF Nawaz, Marriam
   Masood, Momina
   Javed, Ali
   Iqbal, Javed
   Nazir, Tahira
   Mehmood, Awais
   Ashraf, Rehan
TI Melanoma localization and classification through faster region-based
   convolutional neural network and SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep-learning; Faster-RCNN; Melanoma; Medical imaging; SVM; Skin lesion
ID PIGMENTED SKIN-LESIONS; SEGMENTATION; DIAGNOSIS; SYSTEM; SUPPORT
AB Melanoma is a lethal skin cancer disease affecting millions of people around the globe and has a high mortality rate. Dermatologists perform the manual inspection through visual analysis of pigmented skin lesions for melanoma identification at the early stage. However, manual inspection for melanoma detection is limited due to variable accuracy and lesser availability of dermatologists. Therefore, there exists an urgent need to develop automated melanoma detection methods that can effectively localize and classify skin lesions. Accurate localization and classification of the melanoma lesions is a challenging task due to the presence of low contrast information between the moles and skin part, the massive color similarity between the infected and non-infected skin portions, presence of noise, hairs, and tiny blood vessels, variations in color, texture, illumination, contrast, blurring, and melanoma size. To address these afore-mentioned challenges, we propose an effective and efficient melanoma detection method. The proposed method consists of three steps: i) image preprocessing, ii) employing Faster Region-based Convolutional Neural Network (Faster-RCNN) for melanoma localization, and iii) application of Support Vector Machine (SVM) for the classification of localized melanoma region into benign and malignant classes. Performance of the proposed method is evaluated on the benchmark ISIC-2016 dataset launched by ISBI challenge-2016 that is diverse in terms of variations in illumination, color, texture, and size of melanoma, and presence of blurring, noise, hairs, and tiny blood vessels, etc. Moreover, we have also performed a cross-dataset validation over the ISIC-2017 dataset to show the efficacy of our method in real-world scenarios. Our experimental results illustrate that the proposed framework is efficient and able to effectively localize and classify the melanoma lesion than state-of-the-art techniques.
C1 [Nawaz, Marriam; Masood, Momina; Javed, Ali; Iqbal, Javed; Nazir, Tahira; Mehmood, Awais] Univ Engn & Technol, Dept Comp Sci, Taxila 47050, Pakistan.
   [Ashraf, Rehan] Natl Text Univ, Dept Comp Sci, Faisalabad 37610, Pakistan.
C3 University of Engineering & Technology Taxila; National Textile
   University - Pakistan
RP Ashraf, R (corresponding author), Natl Text Univ, Dept Comp Sci, Faisalabad 37610, Pakistan.
EM rehan@ntu.edu.pk
RI Iqbal, Muhammad Javed/AAT-8292-2021; Nawaz, Marriam/JVD-9229-2023;
   JAVED, ALI/X-3334-2019; Masood, Momina/M-6979-2017
OI Masood, Momina/0000-0003-1977-1481; Ashraf, Rehan/0000-0002-6627-9820;
   Nawaz, Marriam/0000-0002-2238-4645; Nazir, Tahira/0000-0001-8130-3721
CR Al-masni MA, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105351
   Alcón JF, 2009, IEEE J-STSP, V3, P14, DOI 10.1109/JSTSP.2008.2011156
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, SIIM (Society for Imaging Informatics in Medicine) 2017 Annual Meeting, Pittsburgh, PA, June 1-3, 2017
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Attia M, 2017, I S BIOMED IMAGING, P292, DOI 10.1109/ISBI.2017.7950522
   Badrinarayanan V., 2017, TPAMI, DOI DOI 10.1109/TPAMI.2016.2644615
   Ballerini L., 2013, Color medical image analysis, P63
   Barata C, 2017, PATTERN RECOGN, V69, P270, DOI 10.1016/j.patcog.2017.04.023
   Barata C, 2014, IEEE SYST J, V8, P965, DOI 10.1109/JSYST.2013.2271540
   Bi L, 2017, I S BIOMED IMAGING, P561, DOI 10.1109/ISBI.2017.7950583
   Cavalcanti PG, 2013, EXPERT SYST APPL, V40, P4054, DOI 10.1016/j.eswa.2013.01.002
   Cavalcanti PG, 2011, COMPUT MED IMAG GRAP, V35, P481, DOI 10.1016/j.compmedimag.2011.02.007
   Cheng YI, 2008, SKIN RES TECHNOL, V14, P53, DOI 10.1111/j.1600-0846.2007.00261.x
   Codella NCF, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2708299
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297
   Ganster H, 2001, IEEE T MED IMAGING, V20, P233, DOI 10.1109/42.918473
   Garnavi R., 2010, Int J Med Med Sci, V1, P126
   Giotis I, 2015, EXPERT SYST APPL, V42, P6578, DOI 10.1016/j.eswa.2015.04.034
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gulati S., 2019, INT C ADV COMP DAT S, P312, DOI DOI 10.1007/978-981-13-9939-8_28
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   Hosny KM, 2018, CAIRO INT BIOM ENG, P90, DOI 10.1109/CIBEC.2018.8641762
   Hu K, 2019, BIOMED SIGNAL PROCES, V51, P200, DOI 10.1016/j.bspc.2019.02.018
   Lewis D.D, 1998, EUR C MACH LEARN, P4
   Li YX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020556
   Liao PS, 2001, J INF SCI ENG, V17, P713
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahbod A, 2019, INT CONF ACOUST SPEE, P1229, DOI [10.1109/ICASSP.2019.8683352, 10.1109/icassp.2019.8683352]
   NACHBAR F, 1994, J AM ACAD DERMATOL, V30, P551, DOI 10.1016/S0190-9622(94)70061-3
   Nida N, 2019, INT J MED INFORM, V124, P37, DOI 10.1016/j.ijmedinf.2019.01.005
   Nijeweme-d'Hollosy WO, 2018, INT J MED INFORM, V110, P31, DOI 10.1016/j.ijmedinf.2017.11.010
   Okur E, 2018, ENG APPL ARTIF INTEL, V73, P50, DOI 10.1016/j.engappai.2018.04.028
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Rehman A, 2020, MICROSC RES TECHNIQ, V83, P410, DOI 10.1002/jemt.23429
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   RIDLER TW, 1978, IEEE T SYST MAN CYB, V8, P630, DOI 10.1109/tsmc.1978.4310039
   Rogers HW, 2015, JAMA DERMATOL, V151, P1081, DOI 10.1001/jamadermatol.2015.1187
   Schaefer G, 2014, MEMET COMPUT, V6, P233, DOI 10.1007/s12293-014-0144-8
   Siegel RL, 2017, CA-CANCER J CLIN, V67, P177, DOI [DOI 10.3322/CAAC.21395, 10.3322/caac.21395]
   Silveira M, 2009, IEEE J-STSP, V3, P35, DOI 10.1109/JSTSP.2008.2011119
   Singh S, 2020, J INFORM OPTIM SCI, V41, P195, DOI 10.1080/02522667.2020.1721585
   Society A C, 2016, CANC FACTS FIG
   Stanley RJ, 2007, SKIN RES TECHNOL, V13, P62, DOI 10.1111/j.1600-0846.2007.00192.x
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tan TY, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.06.015
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Uricchio T., 2015, Proceedings of the IEEE International Conference on Computer Vision (CVPR) Workshops, P9
   Walter, 2016, GOO GIIM9X3SF, pL3
   Yang JW, 2018, IEEE ACCESS, V6, P65130, DOI 10.1109/ACCESS.2018.2877587
   Yap J, 2018, EXP DERMATOL, V27, P1261, DOI 10.1111/exd.13777
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yu Z, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106281
   Zhang JP, 2019, MED IMAGE ANAL, V54, P10, DOI 10.1016/j.media.2019.02.010
NR 57
TC 26
Z9 26
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28953
EP 28974
DI 10.1007/s11042-021-11120-7
EA JUN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000661366700002
DA 2024-07-18
ER

PT J
AU Priyadarshini, I
   Mohanty, P
   Kumar, R
   Sharma, R
   Puri, V
   Singh, PK
AF Priyadarshini, Ishaani
   Mohanty, Pinaki
   Kumar, Raghvendra
   Sharma, Rohit
   Puri, Vikram
   Singh, Pradeep Kumar
TI A study on the sentiments and psychology of twitter users during
   COVID-19 lockdown period
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Coronavirus; Sentiment analysis; Lockdown; COVID-19; Cognitive study;
   Human psychology
ID CHINA; CORONAVIRUS; IMPACT
AB The outbreak of the novel Coronavirus in late 2019 brought severe devastation to the world. The pandemic spread across the globe, infecting more than ten million people and disrupting several businesses. Although social distancing and the use of protective masks were suggested all over the world, the cases seem to rise, which led to worldwide lockdown in different phases. The rampant escalation in the number of cases, the global effects, and the lockdown may have a severe effect on the psychology of people. The emergency protocols implemented by the authorities also lead to increased use in the number of multimedia devices. Excessive use of such devices may also contribute to psychological disorders. Hence, hence it is necessary to analyze the state of mind of people during the lockdown. In this paper, we perform a sentiment analysis of Twitter data during the pandemic lockdown, i.e., two weeks and four weeks after the lockdown was imposed. Investigating the sentiments of people in the form of positive, negative, and neutral tweets would assist us in determining how people are dealing with the pandemic and its effects on a psychological level. Our study shows that the lockdown witnessed more number positive tweets globally on multiple datasets. This is indicative of the positivity and optimism based on the sentiments and psychology of Twitter users worldwide. The study will be effective in determining people's mental well-being and will also be useful in devising appropriate lockdown strategies and crisis management in the future.
C1 [Priyadarshini, Ishaani] Univ Delaware, Dept Elect & Comp Sci, Newark, DE 19716 USA.
   [Mohanty, Pinaki] Purdue Univ, Dept Comp Sci, 610 Purdue Mall, W Lafayette, IN 47907 USA.
   [Kumar, Raghvendra] GIET Univ, Dept Comp Sci & Engn, Gunupur, India.
   [Sharma, Rohit] SRM Inst Sci & Technol, Fac Engn & Technol, Dept Elect & Commun Engn, NCR Campus,Delhi NCR Campus,Delhi Meerut Rd, Ghaziabad, UP, India.
   [Puri, Vikram] Duy Tan Univ, Ctr Visualizat & Simulat, Da Nang, Vietnam.
   [Singh, Pradeep Kumar] ABES Engn Coll, Ghaziabad, UP, India.
C3 University of Delaware; Purdue University System; Purdue University;
   GIET University; SRM Institute of Science & Technology Delhi NCR
   (Ghaziabad); Duy Tan University
RP Singh, PK (corresponding author), ABES Engn Coll, Ghaziabad, UP, India.
EM ishaani@udel.edu; mohantypinakiranjan@gmail.com;
   raghvendraagrawal7@gmail.com; rohitapece@gmail.com;
   purivikram@duytan.edu.vn; pradeep_84cs@yahoo.com
RI priyadarshini, ishaani/AAW-3437-2020; Singh, Pradeep Kumar/M-4363-2016;
   sharma, rohit/AAM-7855-2020
OI priyadarshini, ishaani/0000-0002-8826-8065; Singh, Pradeep
   Kumar/0000-0002-7676-9014; sharma, rohit/0000-0002-1600-5039
CR Abd-Alrazaq A, 2020, J. Med. Internet Res., V22, DOI [10.2196/19016, DOI 10.2196/19016]
   Barkur G, 2020, ASIAN J PSYCHIATR, V51, DOI 10.1016/j.ajp.2020.102089
   Block P, 2020, NAT HUM BEHAV, V4, P588, DOI 10.1038/s41562-020-0898-6
   Boldog P, 2020, J CLIN MED, V9, DOI 10.3390/jcm9020571
   Cao WJ, 2020, PSYCHIAT RES, V287, DOI 10.1016/j.psychres.2020.112934
   Cucinotta Domenico, 2020, Acta Biomed, V91, P157, DOI 10.23750/abm.v91i1.9397
   Dansana D, 2020, FRONT PUBLIC HEALTH, V8, DOI 10.3389/fpubh.2020.580327
   de las Heras-Pedrosa C, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17155542
   Dhar BK, 2020, GLOB CHALL, V4, DOI 10.1002/gch2.202000038
   Dsouza DD, 2020, PSYCHIAT RES, V290, DOI 10.1016/j.psychres.2020.113145
   Dubey Akash Dutt, 2020, TWITTER SENTIMENT AN, DOI [10.2139/ssrn.3572023, DOI 10.2139/SSRN.3572023]
   Fanelli D, 2020, CHAOS SOLITON FRACT, V134, DOI 10.1016/j.chaos.2020.109761
   Gautret P, 2020, TRAVEL MED INFECT DI, V34, DOI 10.1016/j.tmaid.2020.101663
   Iyengar K, 2020, DIABETES METAB SYND, V14, P733, DOI 10.1016/j.dsx.2020.05.033
   Jiang F, 2020, J GEN INTERN MED, V35, P1545, DOI 10.1007/s11606-020-05762-w
   Jung SM, 2020, J CLIN MED, V9, DOI 10.3390/jcm9020523
   Kazak AE, 2020, AM PSYCHOL, V75, P605, DOI 10.1037/amp0000682
   Ke YY., 2020, BIOMETR J, V43, P85
   Koh D, 2020, OCCUP MED-STATE ART, P47
   Kumar A, 2020, DIABETES METAB SYND, V14, P569, DOI 10.1016/j.dsx.2020.05.008
   Lee HS, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12166648
   Lewnard JA, 2020, LANCET INFECT DIS, V20, P631, DOI 10.1016/S1473-3099(20)30190-0
   Li Q, 2020, NEW ENGL J MED, V382, P1199, DOI 10.1056/NEJMoa2001316
   Linka K, 2020, COMPUT METHOD BIOMEC, V23, P710, DOI 10.1080/10255842.2020.1759560
   Lowenthal P., 2020, Journal of Technology and Teacher Education, V28, P383, DOI DOI 10.24252/ELITE.V7I1A6
   Mahato S, 2020, SCI TOTAL ENVIRON, V730, DOI 10.1016/j.scitotenv.2020.139086
   Meng H, 2020, PSYCHIAT RES, V289, DOI 10.1016/j.psychres.2020.112983
   Mostafa L., 2020, P INT C ADV INT SYST, P195, DOI DOI 10.1007/978-3-030-58669-0_18
   Pastor CK. L., 2020, Asian J. Multi. Stud, V3, P1, DOI DOI 10.31838/JCR.07.07.15
   Petrosillo N, 2020, CLIN MICROBIOL INFEC, V26, P729, DOI 10.1016/j.cmi.2020.03.026
   Pirouz B, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12062427
   Priyadarshini I, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8020148
   Samuel J, 2020, INFORMATION, V11, DOI 10.3390/info11060314
   Sarma P, 2020, J MED VIROL, V92, P776, DOI 10.1002/jmv.25898
   Serrano G., 2020, HLTH SCI, V8, P8
   Sharif A, 2020, INT REV FINANC ANAL, V70, DOI 10.1016/j.irfa.2020.101496
   Rao ASRS, 2020, INFECT CONT HOSP EP, V41, P826, DOI 10.1017/ice.2020.61
   Suryawanshi R., 2020, STUDIES INDIAN PLACE, V40, P984
   Vo T, 2020, J INTELL FUZZY SYST, V38, P4287, DOI 10.3233/JIFS-190870
   Viner RM, 2020, LANCET CHILD ADOLESC, V4, P397, DOI 10.1016/S2352-4642(20)30095-X
   Wang TY, 2020, IEEE ACCESS, V8, P138162, DOI 10.1109/ACCESS.2020.3012595
   Wu F, 2020, NATURE, V579, P265, DOI 10.1038/s41586-020-2008-3
   Yamaguchi K, 2020, PSYCHOL TRAUMA-US, V12, pS49, DOI 10.1037/tra0000807
   Zhou P, 2020, NATURE, V579, P270, DOI 10.1038/s41586-020-2012-7
   Liu 刘茜玮 Qianwei, 2020, World J Acupunct Moxibustion, DOI 10.1016/j.wjam.2020.06.007
NR 46
TC 19
Z9 19
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27009
EP 27031
DI 10.1007/s11042-021-11004-w
EA JUN 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000661366900002
PM 34149302
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Zong, YS
   Huang, GY
AF Zong, Yongsheng
   Huang, Guoyan
TI A feature dimension reduction technology for predicting DDoS intrusion
   behavior in multimedia internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia internet of things; DDoS attacks; Rough sets; Principal
   component analysis; Feature reduction; Computing efficiency
ID ENSEMBLES
AB Due to massive data flow and complexity of changeable data characteristics, the dimension disasters problems is ordinary existed in the prediction of the Distributed Denial of Services (DDoS) large-flow attack for multimedia Internet of Things, which will result in the following deficiency such as excessive consumption of computing, and storage resources, reduced analysis efficiency. In this paper, a novel method with the combination of matrix diversity and principal component analysis is proposed for DDoS feature reduction. Firstly, matrix diversity is used to reduce the multiple feature properties of DDoS, and then principal component analysis is used to reduce these features further. Then, the statistical characteristics of these correlations are analyzed. Finally, real-time attack detection is carried out based on mahalanobis distance (MD). It is obvious demonstrated that the proposed method has higher prediction accuracy and more computational efficiency than the traditional method.
C1 [Zong, Yongsheng; Huang, Guoyan] Yanshan Univ, Coll Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
   [Zong, Yongsheng] Qinhuangdao Vocat & Tech Coll, Qinhuangdao 066100, Hebei, Peoples R China.
C3 Yanshan University
RP Zong, YS (corresponding author), Yanshan Univ, Coll Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.; Zong, YS (corresponding author), Qinhuangdao Vocat & Tech Coll, Qinhuangdao 066100, Hebei, Peoples R China.
EM yongshengzong@yeah.net
OI zong, yongsheng/0000-0002-6755-680X
CR Bhuyan MH, 2014, IEEE COMMUN SURV TUT, V16, P303, DOI 10.1109/SURV.2013.052213.00046
   Bouzida Y, 2003, P WORLD MULT SYST CY, P235
   Chen RC, 2009, 2009 FIRST ASIAN CONFERENCE ON INTELLIGENT INFORMATION AND DATABASE SYSTEMS, P465, DOI 10.1109/ACIIDS.2009.59
   Gu P, 2018, INT S MOD OPT MOB AD, P1
   Nguyen HT, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS), P271, DOI 10.1109/HIS.2012.6421346
   Kausar N., 2012, Proceedings of the 2012 International Conference on Computer & Information Science (ICCIS), P569, DOI 10.1109/ICCISci.2012.6297095
   Kayacik HG, 2005, C PRIV, P201
   Kuncheva LI, 2007, LECT NOTES COMPUT SC, V4472, P459
   Kuncheva LI, 2007, IEEE T KNOWL DATA EN, V19, P500, DOI 10.1109/TKDE.2007.1016
   Lee W, 1999, P IEEE S SECUR PRIV, P120, DOI 10.1109/SECPRI.1999.766909
   Mishra A, 2004, IEEE WIREL COMMUN, V11, P48, DOI 10.1109/MWC.2004.1269717
   Moore D, 2006, ACM T COMPUT SYST, V24, P115, DOI 10.1145/1132026.1132027
   Osanaiye O, 2016, J NETW COMPUT APPL, V67, P147, DOI 10.1016/j.jnca.2016.01.001
   Qin AM, 2012, 2012 7TH INTERNATIONAL CONFERENCE ON COMPUTING AND CONVERGENCE TECHNOLOGY (ICCCT2012), P731
   Sharma A, 2007, COMPUT SECUR, V26, P488, DOI 10.1016/j.cose.2007.10.003
   Tsang CH, 2007, PATTERN RECOGN, V40, P2373, DOI 10.1016/j.patcog.2006.12.009
   Tumer K, 1998, IEEE T BIO-MED ENG, V45, P953, DOI 10.1109/10.704864
   Xu W., 2005, MOBIHOC, P46, DOI DOI 10.1145/1062689.1062697
NR 18
TC 8
Z9 8
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22671
EP 22684
DI 10.1007/s11042-019-7591-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000669314100016
DA 2024-07-18
ER

PT J
AU Shen, PY
   Zhang, LG
   Wang, MH
   Yin, GS
AF Shen, Pengyang
   Zhang, Liguo
   Wang, Minghao
   Yin, Guisheng
TI Deeper super-resolution generative adversarial network with gradient
   penalty for sonar image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution reconstruction; Sonar image; Generative adversarial
   network; Gradient penalty
ID RESOLUTION
AB In the field of underwater wireless communication, the acoustic signal has the advantages of low attenuation, long propagation distance, and high fidelity compared with electromagnetic wave signals. Therefore, as an important acoustic sensor, the sonar has been widely used in underwater topographical surveying, underwater search and rescue, ship navigation, etc. The sonar image also faces challenge of low-resolution due to its imaging mechanism, like ultrasonic image and synthetic aperture radar image. In this paper, we propose a deeper super-resolution generative adversarial network (DGP-SRGAN) with gradient penalty. It can be used to produce the sonar image with high-resolution. The main contribution of our method is that the gradient penalty is added to the loss function for a more stable and faster training network. The deep of the generator network is doubled from the original 16 layers to 32 layers to make the network more expressive, achieving its better performance. The loss function of the discriminator network increases the gradient penalty term. It can insure a faster network converge and then reach a stable state in less time. Thus the proposed network model achieves a better super-resolution reconstruction effect. The experimental results show that DGP-SRGAN can control the output of super-resolution images well based on input conditions. Meanwhile, the quality of the output image has improved significantly when compared with the other methods.
C1 [Shen, Pengyang; Zhang, Liguo; Wang, Minghao; Yin, Guisheng] Harbin Engn Univ, Harbin, Peoples R China.
C3 Harbin Engineering University
RP Zhang, LG (corresponding author), Harbin Engn Univ, Harbin, Peoples R China.
EM zhangliguo@hrbeu.edu.cn
RI LIGUO, ZHANG/AAC-8765-2021
FU National Natural Science Foundation of China [61501132]; China
   Postdoctoral Science Foundation [2019M661319]; Heilongjiang Postdoctoral
   Scientic Research Developmental Foundation [LBH-Q17042]; Fundamental
   Research Funds for the Central Universities [3072020CFQ0602,
   3072020CF0604]
FX This work is supported by by National Natural Science Foundation of
   China (61501132), China Postdoctoral Science Foundation (2019M661319),
   Heilongjiang Postdoctoral Scientic Research Developmental Foundation
   (LBH-Q17042), and Fundamental Research Funds for the Central
   Universities (3072020CFQ0602, 3072020CF0604).
CR Chen Zhengdao, 2017, arXiv preprint arXiv:1705.02438
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   Gao ZF, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900260
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guanying H., 2010, P 2 INT C INF SCI EN, P3412
   Han W, 2018, PROC CVPR IEEE, P1654, DOI 10.1109/CVPR.2018.00178
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   HARRIS JL, 1964, J OPT SOC AM, V54, P931, DOI 10.1364/JOSA.54.000931
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Gulrajani I, 2017, ADV NEUR IN, V30
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Liu SS, 2019, INT J INTELL COMPUT, V12, P400, DOI 10.1108/IJICC-10-2018-0135
   Ma C, 2017, COMPUT VIS IMAGE UND, V158, P1, DOI 10.1016/j.cviu.2016.12.009
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Park J, 2019, IEICE T INF SYST, VE102D, P210, DOI 10.1587/transinf.2018EDL8170
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   SCHULTZ RR, 1995, INT CONF ACOUST SPEE, P2169, DOI 10.1109/ICASSP.1995.479905
   SCHULTZ RR, 1994, IEEE T IMAGE PROCESS, V3, P233, DOI 10.1109/83.287017
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   Sung M, 2018, TENCON IEEE REGION, P0457, DOI 10.1109/TENCON.2018.8650176
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Valsesia D, 2020, IEEE T IMAGE PROCESS, V29, P8226, DOI 10.1109/TIP.2020.3013166
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Yu J, 2006, IEEE INT C SIGN PROC, pS262
   Zhang W, 2018, IEEE CONF COMPUT
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 38
TC 9
Z9 9
U1 4
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28087
EP 28107
DI 10.1007/s11042-021-10888-y
EA MAY 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000655960200003
DA 2024-07-18
ER

PT J
AU Munirathinam, R
   Ponnan, S
   Chakraborty, C
   Umathurai, S
AF Munirathinam, Revathi
   Ponnan, Suresh
   Chakraborty, Chinmay
   Umathurai, Saravanakumar
TI Improved performance on seizure detection in an automated
   electroencephalogram signal under evolution by extracting entropy
   feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial neural network; Algorithm; EEG signal; Seizure detection;
   Performance evolution
ID ARTIFICIAL NEURAL-NETWORK; EPILEPTIC SEIZURES; EEG; CLASSIFICATION;
   IDENTIFICATION
AB In recent years, enormous people in all age category were affected with epilepsy throughout the world. To detect and evaluate the epilepsy seizure, the measurable component Electroencephalography (EEG) plays a major role in it. In the olden days, manual detection by the following medical process is carried, the accuracy of the detection is good, but some human error may occur which leads to the critical situation. The EEG plays a major role in the medical field to analyze the instant health condition of the subject under monitoring. The manual detection of EEG consumes much time and have to face the critical consequence, to avoid this situation world need alternate detecting methods. For more than a decade, to help medical specialists, many techniques, methodologies have been followed to detect with technology advancement. The detection of EEG signal was automated with various methods which reduce the detection time and gives the earlier response which is useful for medical diagnosis. During automated signaling the device also generates a noisy signal that causes difficulty in detection and prediction. In this paper, a new technique is proposed with an adaptive artificial neural network (AANN) to detect a normal and epileptic signal. The optimized proposed oppositional crow search algorithm (OCSA) gives better performance in the detection of epileptic seizures with an accuracy of 96.45% over others and the same has been reported.
C1 [Munirathinam, Revathi] Sci Soc, Engn Dept, Tiruvannamalai 6006805, Tamil Nadu, India.
   [Ponnan, Suresh] Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci &, Dept ECE, Chennai 600062, Tamil Nadu, India.
   [Chakraborty, Chinmay] Birla Inst Technol, Elect & Commun Engn, Ranchi, Jharkhand, India.
   [Umathurai, Saravanakumar] Muthayammal Engn Coll, Dept ECE, Rasipuram, Tamil Nadu, India.
C3 Vel Tech Rangarajan Dr Sagunthala R&D Institute of Science & Technology;
   Birla Institute of Technology Mesra; Muthayammal Engineering College
RP Ponnan, S (corresponding author), Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci &, Dept ECE, Chennai 600062, Tamil Nadu, India.
EM suresh3982@yahoo.co.in
RI Chakraborty, Chinmay/N-3608-2017; P, SURESH/D-2981-2014; K P,
   Suresh/AAK-4725-2021; U, SARAVANAKUMAR/G-2751-2012
OI Chakraborty, Chinmay/0000-0002-4385-0975; P, SURESH/0000-0002-0488-972X;
   K P, Suresh/0000-0002-4672-8334; U, SARAVANAKUMAR/0000-0002-2520-4945;
   M, Revathi/0000-0002-9482-9439
CR Acharya UR, 2009, J MECH MED BIOL, V9, P539, DOI 10.1142/S0219519409003152
   Alotaiby TN, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-183
   Bajaj V, 2013, BIOMED ENG LETT, V3, P17
   Bogaarts JG, 2016, MED BIOL ENG COMPUT, V54, P1285, DOI 10.1007/s11517-016-1468-y
   Chen GY, 2017, J MED BIOL ENG, V37, P123, DOI 10.1007/s40846-016-0214-0
   Fasil OK, 2019, NEUROSCI LETT, V694, P1, DOI 10.1016/j.neulet.2018.10.062
   Giri D, 2013, KNOWL-BASED SYST, V37, P274, DOI 10.1016/j.knosys.2012.08.011
   Hassan AR, 2016, COMPUT METH PROG BIO, V137, P247, DOI 10.1016/j.cmpb.2016.09.008
   Hosseini MP, 2018, ARTIF INTELL MED, V84, P146, DOI 10.1016/j.artmed.2017.12.004
   Jaiswal AK, 2017, BIOMED SIGNAL PROCES, V34, P81, DOI 10.1016/j.bspc.2017.01.005
   Kabir Enamul, 2016, Brain Inform, V3, P93, DOI 10.1007/s40708-015-0030-2
   Kumar SD, 2018, IEEE T COMPUT AID D, V37, P110, DOI 10.1109/TCAD.2017.2685588
   Kumar SP, 2010, EXPERT SYST APPL, V37, P3284, DOI 10.1016/j.eswa.2009.09.051
   Li Y, 2016, NEUROCOMPUTING, V193, P106, DOI 10.1016/j.neucom.2016.01.062
   Meier R, 2008, J CLIN NEUROPHYSIOL, V25, P119, DOI 10.1097/WNP.0b013e3181775993
   Molina-Picó A, 2011, ARTIF INTELL MED, V53, P97, DOI 10.1016/j.artmed.2011.06.007
   Mormann F, 2007, BRAIN, V130, P314, DOI 10.1093/brain/awl241
   Orhan U, 2012, J MED SYST, V36, P2219, DOI 10.1007/s10916-011-9689-y
   PONNAN S, 2021, IEEE SENS J
   Rizvi SA, 2013, EPILEPSY BEHAV CASE, V1, P39, DOI 10.1016/j.ebcr.2013.01.001
   Robertson J, 2015, SEIZURE-EUR J EPILEP, V29, P46, DOI 10.1016/j.seizure.2015.03.016
   Saini R, 2018, INFORM SCIENCES, V430, P163, DOI 10.1016/j.ins.2017.11.045
   Sargolzaei S, 2015, COMPUT BIOL MED, V56, P158, DOI 10.1016/j.compbiomed.2014.10.018
   Selvakumari RS, 2019, MULTIDIM SYST SIGN P, V30, P1029, DOI 10.1007/s11045-018-0585-1
   Suresh P, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2021.106996
   Valentinuzzi, 2017, J PHYS C SER, V90
   Yang JH, 2012, ARTIF INTELL MED, V55, P117, DOI 10.1016/j.artmed.2012.02.001
NR 27
TC 16
Z9 16
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13355
EP 13370
DI 10.1007/s11042-021-11069-7
EA MAY 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000654112900004
DA 2024-07-18
ER

PT J
AU Cui, XP
   Zou, C
   Wang, ZS
AF Cui, Xianping
   Zou, Cui
   Wang, Zesong
TI Remote sensing image recognition based on dual-channel deep learning
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local and global features; Remote sensing; Multi-access convolutional;
   Deep learning; Convolution and dilated convolution
ID CONVOLUTIONAL NEURAL-NETWORK; CLASSIFICATION; FEATURES; SEGMENTATION
AB In the face of remote sensing images with diversified information, the recognition of remote sensing images only through local features or global features is limited. Traditionally, it is difficult to achieve good image modeling. To solve this problem, this paper proposes a recognition framework based on dual-channel deep learning(DCDL). The purpose of this framework is to mine global feature information and local feature information at the same time. On the first channel, this paper uses a multi-scale convolution residual network to perform local mining and residual calculations on the image to generate local features; secondly, the local attention mechanism is used to assign weight coefficients to the local features to make the information more contained. More features are more prominent; finally, after several times of mining features and assigning weights, more representative deep features are produced. On the other channel, we introduce the global attention mechanism to realize the weight coefficient distribution of global features; then use the multi-scale dilated convolution to expand the receptive field to obtain a larger range of feature information; then, use the Sigmoid function to achieve 0 to 1 for all features The weight distribution of, further expands the difference between global features; finally, the deep mining of features is realized through 2-layer convolution. In this paper, through the experimental results of the three sub-data sets in the NWPU-RESISC45 data set, we can see that our proposed algorithm has achieved higher recognition accuracy.
C1 [Cui, Xianping; Zou, Cui; Wang, Zesong] Gdao Huanghai Univ, Qingdao, Peoples R China.
RP Cui, XP (corresponding author), Gdao Huanghai Univ, Qingdao, Peoples R China.
EM qdhhxyc@163.com
CR CAI W, IEEE GEOSCI REMOTE S
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Chen FQ, 2015, 2015 12TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P214, DOI 10.1109/ICCWAMTIP.2015.7493978
   Chen GS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091816
   Chen LL, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P349, DOI 10.1145/3126686.3126723
   Chen ZZ, 2019, IEEE T GEOSCI REMOTE, V57, P4577, DOI 10.1109/TGRS.2019.2891679
   Gao H, 2021, IEEE ACCESS, V9, P11644, DOI 10.1109/ACCESS.2021.3052021
   Gao H, 2020, IEEE ACCESS, V8, P142483, DOI 10.1109/ACCESS.2020.3013898
   Imbriaco R, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11050493
   Kim S., 2019, INT SOC OPTICS PHOTO, V11155
   Lei XY, 2019, IEEE ACCESS, V7, P124087, DOI 10.1109/ACCESS.2019.2927169
   Li T, 2020, IEEE ACCESS, V8, P62561, DOI 10.1109/ACCESS.2020.2984130
   Lin YF, 2019, MULTIMED TOOLS APPL, V78, P29197, DOI 10.1007/s11042-018-6687-9
   Liu QH, 2019, JOINT URB REMOTE SEN, DOI 10.1109/jurse.2019.8809046
   Lobachev, 2019, INT SOC OPTICS PHOTO, V11041
   Ma W, 2019, IEEE T GEOSCI REMOTE, V57, P3512, DOI 10.1109/TGRS.2018.2885506
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mannan SK, 1996, SPATIAL VISION, V10, P165, DOI 10.1163/156856896X00123
   Mishra S, 2019, I S BIOMED IMAGING, P57
   Ran Q, 2020, MULTIMED TOOLS APPL, V79, P8985, DOI 10.1007/s11042-018-7091-1
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shubham S, 2019, MULTIMED TOOLS APPL, V78, P17197, DOI 10.1007/s11042-018-7034-x
   Unnikrishnan A, 2019, MULTIMED TOOLS APPL, V78, P18379, DOI 10.1007/s11042-019-7179-2
   Wang, 2019, P INT C FRONT COMP, P913
   Wang ZS, 2020, IEEE ACCESS, V8, P71353, DOI 10.1109/ACCESS.2020.2986267
   Wang ZY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224890
   Xie J, 2019, IEEE T GEOSCI REMOTE, V57, P6916, DOI 10.1109/TGRS.2019.2909695
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Yu LL, 2019, SIGNAL PROCESS, V155, P358, DOI 10.1016/j.sigpro.2018.09.006
   Zhang GJ, 2019, IEEE T GEOSCI REMOTE, V57, P10015, DOI 10.1109/TGRS.2019.2930982
   Zhang RN, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.038501
   Zhao W, 2019, IEEE ACCESS, V7, P43607, DOI 10.1109/ACCESS.2019.2908016
   Zhu DH, 2019, IEEE J-STARS, V12, P1254, DOI 10.1109/JSTARS.2019.2902430
   Zhu RX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11171996
NR 34
TC 7
Z9 6
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27683
EP 27699
DI 10.1007/s11042-021-11079-5
EA MAY 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000652940300002
DA 2024-07-18
ER

PT J
AU Roy, SS
   Basu, A
   Chattopadhyay, A
   Kamal, R
AF Roy, Subhrajit Sinha
   Basu, Abhishek
   Chattopadhyay, Avik
   Kamal, Rajeev
TI Hardware execution of a saliency map based digital image watermarking
   framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive digital watermarking; Saliency; Hardware implementation; Image
   signature; Payload capacity
ID SCHEME; ALGORITHM; SYSTEM
AB In this paper, human visual system based adaptive LSB replacement process has been used to develop an image watermarking scheme. A saliency map of the cover image is built up and the watermark is adaptively embedded into that cover image pixels to get a better visual transparency with increased payload. In this approach, the saliency map is generated by using a binary and holistic image descriptor, termed as Image Signature. The hardware execution of this proposed methodology has been set up through Virtex6 FPGA board (xc6vlx760). The experimental results divulge that the proposed framework provides less perceptual inaccuracy with improved payload capacity.
C1 [Roy, Subhrajit Sinha; Basu, Abhishek] RCC Inst Informat Technol, Elect & Commun Engn Dept, South Canal Rd, Kolkata 700015, India.
   [Roy, Subhrajit Sinha; Chattopadhyay, Avik] Univ Calcutta, Inst Radio Phys & Elect, 92 Acharya Prafulla Chandra Rd, Kolkata 700009, India.
   [Kamal, Rajeev] Samsung Semicond India Res, Bangalore 560037, Karnataka, India.
C3 RCC Institute of Information Technology (RCCIIT); University of Calcutta
RP Roy, SS (corresponding author), RCC Inst Informat Technol, Elect & Commun Engn Dept, South Canal Rd, Kolkata 700015, India.; Roy, SS (corresponding author), Univ Calcutta, Inst Radio Phys & Elect, 92 Acharya Prafulla Chandra Rd, Kolkata 700009, India.
EM subhrajitkcs@gmail.com
RI Roy, Subhrajit Sinha/AAU-3651-2021; Basu, Abhishek/S-6016-2019
OI Basu, Abhishek/0000-0003-4167-3722
CR Akhtarkavan E, 2020, MULTIMED TOOLS APPL, V79, P13427, DOI 10.1007/s11042-020-08662-7
   Andalibi M, 2015, IEEE T IMAGE PROCESS, V24, P5060, DOI 10.1109/TIP.2015.2476961
   [Anonymous], 2015, INT C EL EL SIGN COM
   [Anonymous], 2014, APPL MECH MAT, DOI DOI 10.4028/WWW.SCIENTIFIC.NET/AMM.602-605.330
   Bhattacharya S, 2014, INDIAN J PSYCHOL SCI, V4, P1
   Chattopadhyay, 2019, PERSPECTIVES DIGITAL
   Chattopadhyay, 2017, RECENT TRENDS RENEWA
   Darabkh KA, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1182, DOI 10.1109/MIPRO.2014.6859747
   Dong Ml, 2012, IEEE 14 INT C COMM T
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Field DJ, 1997, VISION RES, V37, P3367, DOI 10.1016/S0042-6989(97)00181-8
   Fordjour P. A., 2003, Journal of Shanghai University, V7, P384, DOI 10.1007/s11741-003-0015-x
   Guo L, 2017, MULTIMED TOOLS APPL, V76, P16949, DOI 10.1007/s11042-016-3597-6
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Khoshki RM, 2014, INT J ADV RES COMPUT, V3, P6400
   Kutter M, 2000, J ELECTRON IMAGING, V9, P445, DOI 10.1117/1.1287594
   Li JY, 2020, MULTIMED TOOLS APPL, V79, P1373, DOI 10.1007/s11042-019-08213-9
   Liu H, 2016, SIGNAL PROCESS-IMAGE, V45, P41, DOI 10.1016/j.image.2016.04.002
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Mishra A, 2015, P ELM 2014, V2, P145
   Niu PP, 2020, MULTIMED TOOLS APPL, V79, P13351, DOI 10.1007/s11042-019-08504-1
   Pareek R, 2012, INT J ENG ADV TECHNO, V1
   Phadikar A, 2020, MULTIMED TOOLS APPL, V79, P12507, DOI 10.1007/s11042-019-08392-5
   Roy SS, 2020, MULTIMED TOOLS APPL, V79, P13125, DOI 10.1007/s11042-020-08652-9
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Shi J, 2013, INT CONF MANIP MANU, P1, DOI 10.1109/3M-NANO.2013.6737376
   Sinha Roy S, 2015, P FRCCD 2015, P50
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Huynh-The T, 2017, IEEE SYS MAN CYBERN, P1333, DOI 10.1109/SMC.2017.8122798
   Tsai HH, 2014, INFORMATICA-LITHUAN, V25, P113, DOI 10.15388/Informatica.2014.07
   Wu Q, 2016, J INF SECUR APPL, V26, P1, DOI 10.1016/j.jisa.2015.08.003
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
   Zheng H, 2020, SIGNAL PROCESS-IMAGE, P81
   Zheng HC, 2019, SIGNAL PROCESS, V164, P74, DOI 10.1016/j.sigpro.2019.05.035
NR 38
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27245
EP 27258
DI 10.1007/s11042-021-11046-0
EA MAY 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000650816400003
DA 2024-07-18
ER

PT J
AU Tiwari, V
   Bhatnagar, C
AF Tiwari, Vasudha
   Bhatnagar, Charul
TI A survey of recent work on video summarization: approaches and
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Video summarization; Dynamic summaries; Hierarchical
   summaries; Multi-view summaries; User oriented summaries; Multi-video
   summarization
ID EVENT DETECTION; FRAMEWORK; VISUALIZATION; FEATURES
AB The volume of video data generated has seen an exponential growth over the years and video summarization has emerged as a process that can facilitate efficient storage, quick browsing, indexing, fast retrieval and quick sharing of the content. In view of the vast literature available on different aspects of video summarization approaches and techniques, a need has arisen to summarize and organize various recent research findings, future research focus and trends, challenges, performance measures and evaluation and datasets for testing and validations. This paper investigates into the existing video summarization frameworks and presents a comprehensive view of the existing approaches and techniques. It highlights the recent advances in the techniques and discusses the paradigm shift that has occurred over the last two decades in the area, leading to considerable improvement. Attempts are made to consolidate the most significant findings right from the basic summarization structure to the classification of summarization techniques and noteworthy contributions in the area. Additionally, the existing datasets categorized domain-wise for the purpose of video summarization and evaluation are enumerated. The present study would be helpful in: assimilating important research findings and data for ready reference, identifying groundwork and exploring potential directions for further research.
C1 [Tiwari, Vasudha; Bhatnagar, Charul] GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
C3 GLA University
RP Tiwari, V (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
EM vasudhatiwari1608@gmail.com; charul@gla.ac.in
RI Tiwari, Vasudha/AAW-2298-2020
OI Tiwari, Vasudha/0000-0002-0087-3069
CR Ajmal M, 2012, LECT NOTES COMPUT SC, V7594, P1, DOI 10.1007/978-3-642-33564-8_1
   Angadi S, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P271, DOI 10.1109/ICSIP.2014.49
   [Anonymous], 2014, ICMR 2014 P ACM INT, DOI DOI 10.1145/2578726.2578800
   [Anonymous], 2006, 2006 IEEE COMP SOC C
   [Anonymous], 2014, INT J COMPUT VIS ROB, DOI DOI 10.1504/IJCVR.2014.062936
   Aparício M, 2016, PATTERN RECOGN LETT, V73, P7, DOI 10.1016/j.patrec.2015.12.016
   Atencio P, 2019, IET COMPUT VIS, V13, P569, DOI 10.1049/iet-cvi.2018.5436
   Basavarajaiah M, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355398
   Baskurt KB, 2019, COMPUT VIS IMAGE UND, V181, P26, DOI 10.1016/j.cviu.2019.02.004
   Cao Y, 2013, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2013.343
   Chang SF, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P494
   Chen, 2017, P BRIT MACH VIS C BM, V118, DOI 10.5244/C.31.118
   Chen T, 2012, COMPUT GRAPH-UK, V36, P241, DOI 10.1016/j.cag.2012.02.010
   Choudary C, 2007, IEEE T MULTIMEDIA, V9, P1443, DOI 10.1109/TMM.2007.906602
   Chu WS, 2015, PROC CVPR IEEE, P3584, DOI 10.1109/CVPR.2015.7298981
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Coppola C, 2020, INT J SOC ROBOT, V12, P201, DOI 10.1007/s12369-019-00541-y
   Cosar S, 2017, IEEE T CIRC SYST VID, V27, P683, DOI 10.1109/TCSVT.2016.2589859
   Dang CT, 2014, IEEE T IMAGE PROCESS, V23, P2704, DOI 10.1109/TIP.2014.2320814
   de Silva G. C., 2005, 13th Annual ACM International Conference on Multimedia, P820, DOI 10.1145/1101149.1101329
   del Molino AG, 2017, IEEE T HUM-MACH SYST, V47, P65, DOI 10.1109/THMS.2016.2623480
   Duque D, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, VOLS 1 AND 2, P362, DOI 10.1109/CIDM.2007.368897
   Evangelopoulos G, 2008, IEEE IMAGE PROC, P2528, DOI 10.1109/ICIP.2008.4712308
   Evangelopoulos G, 2013, IEEE T MULTIMEDIA, V15, P1553, DOI 10.1109/TMM.2013.2267205
   Fakhar B, 2019, MULTIMED TOOLS APPL, V78, P16995, DOI 10.1007/s11042-018-7083-1
   Fei MJ, 2017, J VIS COMMUN IMAGE R, V42, P207, DOI 10.1016/j.jvcir.2016.12.001
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Fu YW, 2010, IEEE T MULTIMEDIA, V12, P717, DOI 10.1109/TMM.2010.2052025
   Goldman DB, 2006, ACM T GRAPHIC, V25, P862, DOI 10.1145/1141911.1141967
   Gong BQ, 2014, ADV NEUR IN, V27
   Goularte R, 2020, INT J DIGIT LIBRARIE, P1
   Gowsikhaa D, 2014, ARTIF INTELL REV, V42, P747, DOI 10.1007/s10462-012-9341-3
   Guo Z, 2016, NEUROCOMPUTING, V208, P299, DOI 10.1016/j.neucom.2016.03.083
   Gygli M, 2015, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR.2015.7298928
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Herranz L, 2010, IEEE T CIRC SYST VID, V20, P1265, DOI 10.1109/TCSVT.2010.2057020
   Hesham M, 2018, PROCEEDINGS OF 2018 FIRST INTERNATIONAL WORKSHOP ON DEEP AND REPRESENTATION LEARNING (IWDRL), P26, DOI 10.1109/IWDRL.2018.8358211
   Ide I, 2017, IEEE INT SYM MULTIM, P193, DOI 10.1109/ISM.2017.33
   Javed A, 2019, IET IMAGE PROCESS, V13, P615, DOI 10.1049/iet-ipr.2018.5589
   Ji H, 2019, J INF SCI, V45, P833, DOI 10.1177/0165551518819964
   Ji Z, 2020, PATTERN RECOGN LETT, V135, P131, DOI 10.1016/j.patrec.2020.04.011
   Ji Z, 2020, IEEE T CIRC SYST VID, V30, P1709, DOI 10.1109/TCSVT.2019.2904996
   Ji Z, 2018, SIGNAL PROCESS, V148, P114, DOI 10.1016/j.sigpro.2018.01.028
   Jiang YD, 2019, IEEE INT CONF COMP V, P1562, DOI 10.1109/ICCVW.2019.00195
   Joho H., 2009, Proceedings of the ACM international conference on image and video retrieval, page, P31
   Kanehira A, 2018, PROC CVPR IEEE, P7435, DOI 10.1109/CVPR.2018.00776
   Kavitha J, 2015, PROCEDIA COMPUT SCI, V47, P292, DOI 10.1016/j.procs.2015.03.209
   Khan AA, 2020, NEURAL PROCESS LETT, V52, P1945, DOI 10.1007/s11063-020-10200-3
   Khan G, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106524
   Khosla A, 2015, IEEE I CONF COMP VIS, P2390, DOI 10.1109/ICCV.2015.275
   Khosla A, 2013, PROC CVPR IEEE, P2698, DOI 10.1109/CVPR.2013.348
   Kim C, 2002, IEEE T CIRC SYST VID, V12, P1128, DOI 10.1109/TCSVT.2002.806813
   Kim G, 2014, PROC CVPR IEEE, P4225, DOI 10.1109/CVPR.2014.538
   Klaser A., 2008, P BRIT MACHINE VISIO, V99, DOI 10.5244/C.22.99
   Kota BU, 2019, PROC INT CONF DOC, P13, DOI 10.1109/ICDARW.2019.30058
   Kwon J, 2015, IEEE T PATTERN ANAL, V37, P1737, DOI 10.1109/TPAMI.2014.2385695
   Lai PK, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P286, DOI 10.1109/AVSS.2016.7738018
   Lee S, 2018, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2018.00153
   Lee YJ, 2015, INT J COMPUT VISION, V114, P38, DOI 10.1007/s11263-014-0794-5
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li BX, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P169
   Li YB, 2016, MULTIMED TOOLS APPL, V75, P199, DOI 10.1007/s11042-014-2287-5
   Lie WN, 2004, LECT NOTES COMPUT SC, V3332, P246
   Liu TC, 2002, IEEE IMAGE PROC, P601
   Lu GL, 2017, MULTIMED TOOLS APPL, V76, P6309, DOI 10.1007/s11042-016-3263-z
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Ma MY, 2020, NEUROCOMPUTING, V378, P197, DOI 10.1016/j.neucom.2019.07.108
   Mademlis I, 2017, INT CONF ACOUST SPEE, P1627, DOI 10.1109/ICASSP.2017.7952432
   Mademlis I, 2016, IEEE T IMAGE PROCESS, V25, P5828, DOI 10.1109/TIP.2016.2615289
   Mahasseni B, 2017, PROC CVPR IEEE, P2077, DOI 10.1109/CVPR.2017.224
   Matthews CE, 2019, MACH VISION APPL, V30, P507, DOI 10.1007/s00138-019-01007-x
   Mendi E, 2013, COMPUT ELECTR ENG, V39, P790, DOI 10.1016/j.compeleceng.2012.11.020
   Meng JJ, 2018, IEEE T IMAGE PROCESS, V27, P2134, DOI 10.1109/TIP.2017.2789332
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Moses TM, 2017, 2017 INTERNATIONAL CONFERENCE ON ALGORITHMS, METHODOLOGY, MODELS AND APPLICATIONS IN EMERGING TECHNOLOGIES (ICAMMAET)
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Oh S., 2011, P CVPR, P3153, DOI DOI 10.1109/CVPR.2011.5995586
   Otani M, 2019, PROC CVPR IEEE, P7579, DOI 10.1109/CVPR.2019.00778
   Ouyang JQ, 2013, IET IMAGE PROCESS, V7, P324, DOI 10.1049/iet-ipr.2012.0495
   Panda R, 2018, IEEE T CYBERNETICS, V48, P836, DOI 10.1109/TCYB.2017.2657692
   Panda R, 2017, IEEE T MULTIMEDIA, V19, P2010, DOI 10.1109/TMM.2017.2708981
   Panda R, 2017, IEEE T IMAGE PROCESS, V26, P4712, DOI 10.1109/TIP.2017.2708902
   Paul M, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-11
   Peng WT, 2011, IEEE T MULTIMEDIA, V13, P539, DOI 10.1109/TMM.2011.2131638
   Pereira MHR, 2019, MULTIMED TOOLS APPL, V78, P23783, DOI 10.1007/s11042-019-7691-4
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Rahman MR, 2020, IEEE INT SYM MULTIM, P154, DOI 10.1109/ISM.2020.00033
   Rani S, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102190
   Safdarnejad Seyed Morteza, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163105
   Sah S, 2017, IEEE WINT CONF APPL, P989, DOI 10.1109/WACV.2017.115
   Sasithradevi A, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102754
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Sharghi A, 2017, PROC CVPR IEEE, P2127, DOI 10.1109/CVPR.2017.229
   Sharghi A, 2016, LECT NOTES COMPUT SC, V9912, P3, DOI 10.1007/978-3-319-46484-8_1
   Smeulders AW, 2019, ARXIV PREPRINT ARXIV
   Song YL, 2015, PROC CVPR IEEE, P5179, DOI 10.1109/CVPR.2015.7299154
   Sreeja MU, 2019, J VIS COMMUN IMAGE R, V62, P340, DOI 10.1016/j.jvcir.2019.06.004
   Tejero-de-Pablos A, 2018, IEEE T MULTIMEDIA, V20, P2000, DOI 10.1109/TMM.2018.2794265
   Thomas SS, 2019, IEEE T CIRC SYST VID, V29, P3132, DOI 10.1109/TCSVT.2018.2873185
   Thomas SS, 2018, IEEE T INTELL TRANSP, V19, P2944, DOI 10.1109/TITS.2017.2769719
   Thomas SS, 2017, IEEE T CIRC SYST VID, V27, P1790, DOI 10.1109/TCSVT.2016.2556558
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Tsai CM, 2013, IEEE T CIRC SYST VID, V23, P1927, DOI 10.1109/TCSVT.2013.2269186
   Ul Haq I, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719845277
   Ul Haq I, 2019, COMPLEXITY, DOI 10.1155/2019/3581419
   Vaca-Castano G, 2017, COMPUT VIS IMAGE UND, V156, P92, DOI 10.1016/j.cviu.2016.10.016
   Varini P, 2017, IEEE T MULTIMEDIA, V19, P2832, DOI 10.1109/TMM.2017.2705915
   Vasudevan AB, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P582, DOI 10.1145/3123266.3123297
   Wu JX, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107382
   Xiong B, 2015, IEEE I CONF COMP VIS, P4525, DOI 10.1109/ICCV.2015.514
   Xu J, 2015, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2015.7298836
   Yu Y, 2018, AAAI CONF ARTIF INTE, P7525
   Zhang K, 2016, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2016.120
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhang S, 2016, IEEE T IMAGE PROCESS, V25, P5469, DOI 10.1109/TIP.2016.2601493
   Zhang Y, 2016, PATTERN RECOGN, V59, P302, DOI 10.1016/j.patcog.2015.11.018
   Zhang YJ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040750
   Zhang YZ, 2017, IEEE T CIRC SYST VID, V27, P1340, DOI 10.1109/TCSVT.2016.2539638
   Zhao B, 2018, PROC CVPR IEEE, P7405, DOI 10.1109/CVPR.2018.00773
   Zhao B, 2014, PROC CVPR IEEE, P2513, DOI 10.1109/CVPR.2014.322
   Zhong H, 2004, PROC CVPR IEEE, P819
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou Kaiyang, 2017, ARXIV PREPRINT ARXIV
   Zhu XT, 2016, INT J COMPUT VISION, V117, P247, DOI 10.1007/s11263-015-0864-3
   Zhu XQ, 2005, IEEE T MULTIMEDIA, V7, P648, DOI 10.1109/TMM.2005.850977
   Zhu XQ, 2004, MULTIMEDIA SYST, V10, P98, DOI 10.1007/s00530-004-0142-7
   Zhukov D, 2019, PROC CVPR IEEE, P3532, DOI 10.1109/CVPR.2019.00365
NR 129
TC 19
Z9 20
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27187
EP 27221
DI 10.1007/s11042-021-10977-y
EA MAY 2021
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000650816400001
DA 2024-07-18
ER

PT J
AU Ahmad, P
   Jin, H
   Qamar, S
   Zheng, R
   Saeed, A
AF Ahmad, Parvez
   Jin, Hai
   Qamar, Saqib
   Zheng, Ran
   Saeed, Adnan
TI RD<SUP>2</SUP>A: densely connected residual networks using ASPP for
   brain tumor segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Residual network; Dense connections; Brain tumors;
   Atrous-spatial pyramid pooling
ID CONVOLUTIONAL NEURAL-NETWORKS; U-NET
AB The variations among shapes, sizes, and locations of tumors are obstacles for accurate automatic segmentation. U-Net is a simplified approach for automatic segmentation. Generally, the convolutional or the dilated convolutional layers are used for brain tumor segmentation. However, existing segmentation methods of the significant dilation rates degrade the final accuracy. Moreover, tuning parameters and imbalance ratio between the different tumor classes are the issues for segmentation. The proposed model, known as Residual-Dilated Dense Atrous-Spatial Pyramid Pooling (RD(2)A) 3D U-Net, is found adequate to solve these issues. The RD(2)A is the combination of the residual connections, dilation, and dense ASPP to preserve more contextual information of small sizes of tumors at each level encoder path. The multi-scale contextual information minimizes the ambiguities among the tissues of the white matter (WM) and gray matter (GM) of the infant's brain MRI. The BRATS 2018, BRATS 2019, and iSeg-2019 datasets are used on different evaluation metrics to validate the RD(2)A. In the BRATS 2018 validation dataset, the proposed model achieves the average dice scores of 90.88, 84.46, and 78.18 for the whole tumor, the tumor core, and the enhancing tumor, respectively. We also evaluated on iSeg-2019 testing set, where the proposed approach achieves the average dice scores of 79.804, 77.925, and 80.569 for the cerebrospinal fluid (CSF), the gray matter (GM), and the white matter (WM), respectively. Furthermore, the presented work also obtains the mean dice scores of 90.35, 82.34, and 71.93 for the whole tumor, the tumor core, and the enhancing tumor, respectively on the BRATS 2019 validation dataset. Experimentally, it is found that the proposed approach is ideal for exploiting the full contextual information of the 3D brain MRI datasets.
C1 [Ahmad, Parvez; Jin, Hai; Qamar, Saqib; Zheng, Ran] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Cluster & Grid Comp Lab, Serv Comp Technol & Syst Lab,Natl Engn Res Ctr Bi, Wuhan, Peoples R China.
   [Saeed, Adnan] Huazhong Univ Sci & Technol, Sch Hydropower & Informat Technol, Wuhan, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology
RP Jin, H (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Cluster & Grid Comp Lab, Serv Comp Technol & Syst Lab,Natl Engn Res Ctr Bi, Wuhan, Peoples R China.
EM hjin@hust.edu.cn
RI Qamar, Saqib/AAP-2938-2021; SAEED, ADNAN/GXA-0391-2022; AHMAD,
   PARVEZ/AEB-0771-2022
OI AHMAD, PARVEZ/0000-0003-1409-3175
FU National Natural Science Foundation of China [61672250]; Hubei
   Provincial Development and Reform Commission Project in China
FX This work is supported by the National Natural Science Foundation of
   China under Grant No.61672250 and the Hubei Provincial Development and
   Reform Commission Project in China.
CR Ahmad Parvez, 2020, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. 5th International Workshop, BrainLes 2019. Held in Conjunction with MICCAI 2019. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 11993), P158, DOI 10.1007/978-3-030-46643-5_15
   Albiol A, 2019, LECT NOTES COMPUT SC, V11384, P73, DOI 10.1007/978-3-030-11726-9_7
   [Anonymous], 2019, CT Semantic Segmentations, and Surgical Outcomes
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Bakas Spyridon, 2018, ARXIV181102629, DOI DOI 10.17863/CAM.38755
   Carver E, 2019, LECT NOTES COMPUT SC, V11384, P406, DOI 10.1007/978-3-030-11726-9_36
   Chandra S, 2019, LECT NOTES COMPUT SC, V11384, P299, DOI 10.1007/978-3-030-11726-9_27
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen W, 2019, LECT NOTES COMPUT SC, V11384, P358, DOI 10.1007/978-3-030-11726-9_32
   Choudhury AR, 2019, LECT NOTES COMPUT SC, V11384, P154, DOI 10.1007/978-3-030-11726-9_14
   Crimi A., 2019, BRAINLESION GLIOMA M
   Devalla, 2018, ARXIV180300232 CORR
   Dolz, 2018, ARXIV180510720 CORR
   Dolz, 2018, ARXIV181007003 CORR
   Feng X, 2019, LECT NOTES COMPUT SC, V11384, P279, DOI 10.1007/978-3-030-11726-9_25
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hu Y, 2019, LECT NOTES COMPUT SC, V11384, P168, DOI 10.1007/978-3-030-11726-9_15
   Hua R, 2019, LECT NOTES COMPUT SC, V11384, P49, DOI 10.1007/978-3-030-11726-9_5
   Huang G., 2016, ARXIV160806993 CORR
   Isensee, 2018, ARXIV180210508 CORR
   Isensee F, 2019, LECT NOTES COMPUT SC, V11384, P234, DOI 10.1007/978-3-030-11726-9_21
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Kamnitsas, 2017, ARXIV171101468 CORR
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kao PY, 2019, LECT NOTES COMPUT SC, V11384, P128, DOI 10.1007/978-3-030-11726-9_12
   Kermi A, 2019, LECT NOTES COMPUT SC, V11384, P37, DOI 10.1007/978-3-030-11726-9_4
   Kirby J., 2017, CANC IMAGING ARCH, V286, DOI [DOI 10.7937/K9/TCIA.2017.GJQ7R0EF, 10.1038/sdata.2017.117, DOI 10.1038/SDATA.2017.117]
   Kori A, 2019, LECT NOTES COMPUT SC, V11384, P485, DOI 10.1007/978-3-030-11726-9_43
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu LL, 2020, NEUROCOMPUTING, V409, P244, DOI 10.1016/j.neucom.2020.05.070
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma J, 2019, LECT NOTES COMPUT SC, V11384, P25, DOI 10.1007/978-3-030-11726-9_3
   Mehta R, 2019, LECT NOTES COMPUT SC, V11384, P254, DOI 10.1007/978-3-030-11726-9_23
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nuechterlein N, 2019, LECT NOTES COMPUT SC, V11384, P245, DOI 10.1007/978-3-030-11726-9_22
   Rezaei M, 2019, LECT NOTES COMPUT SC, V11384, P321, DOI 10.1007/978-3-030-11726-9_29
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Samanta A, 2020, PATTERN RECOGN LETT, V135, P293, DOI 10.1016/j.patrec.2020.04.026
   Sarker, 2018, ARXIV180510241 CORR
   Sun L, 2019, LECT NOTES COMPUT SC, V11384, P83, DOI 10.1007/978-3-030-11726-9_8
   Sun Y, 2020, MULTISITE INFANT BRA
   Tuan TA, 2019, LECT NOTES COMPUT SC, V11384, P466, DOI 10.1007/978-3-030-11726-9_41
   Wang GT, 2019, LECT NOTES COMPUT SC, V11384, P61, DOI 10.1007/978-3-030-11726-9_6
   Wang GT, 2018, LECT NOTES COMPUT SC, V10670, P178, DOI 10.1007/978-3-319-75238-9_16
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Weninger L, 2019, LECT NOTES COMPUT SC, V11384, P3, DOI 10.1007/978-3-030-11726-9_1
   Xie, 2017, ARXIV171204851 CORR
   Xu YW, 2019, LECT NOTES COMPUT SC, V11384, P222, DOI 10.1007/978-3-030-11726-9_20
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Yu, 2016, ARXIV15110 CORR
   Yu F., 2017, PROC CVPR IEEE, P472, DOI [DOI 10.1109/CVPR.2017.75, 10.1109/CVPR.2017.75]
   Zemel RS, 2017, ARXIV170104128 CORR
   Zhang, 2018, ARXIV181200352 CORR
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 55
TC 12
Z9 12
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27069
EP 27094
DI 10.1007/s11042-021-10915-y
EA MAY 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000650124300004
DA 2024-07-18
ER

PT J
AU Shivhare, SN
   Kumar, N
AF Shivhare, Shiv Naresh
   Kumar, Nitin
TI Tumor bagging: a novel framework for brain tumor segmentation using
   metaheuristic optimization algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor segmentation; Magnetic resonance imaging; Training neural
   network; Gray wolf optimizer; Artificial electric field optimization
   algorithm; Spider monkey optimization
ID TEXTURE; CLASSIFICATION; NETWORKS; FEATURES
AB Brain tumor segmentation is a challenging research problem and several methods in literature have been suggested for addressing the same. In this paper, we propose a novel framework called Tumor Bagging whose objective is to enhance the performance of brain tumor segmentation by combining more than one segmentation methods based on Multilayer Perceptron (MLP). For this purpose, three metaheuristic optimization algorithms viz. Gray Wolf Optimizer, Artificial Electric Field Optimization Algorithm and Spider Monkey Optimization have been exploited for learning the network parameters of MLP. The results from these three models are further combined based on majority voting method. We have exploited three different magnetic resonance modalities i.e. Fluid-Attenuated Inversion Recovery (FLAIR), contrast-enhanced T1, and T2 for experiments. Three brain tumor regions i.e. complete tumor, enhancing tumor, and tumor core are segmented. The advantage of the proposed method is its simplicity as well as it gives significant and improved performance using the bagging approach on the publicly available and benchmark BRATS dataset. Dice Similarity Coefficient (DSC) is a performance measure which combines positive predictive value and sensitivity. We have achieved a DSC score of more than 92% for detection of complete tumor region in high-grade as well as low-grade glioma subjects that is better than several state-of-the-art methods.
C1 [Shivhare, Shiv Naresh; Kumar, Nitin] Natl Inst Technol Uttarakhand, Dept Comp Sci & Engn, Srinagar, India.
   [Shivhare, Shiv Naresh] Univ Petr & Energy Studies, Sch Comp Sci, Dehra Dun, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand; University of Petroleum & Energy Studies (UPES)
RP Shivhare, SN (corresponding author), Natl Inst Technol Uttarakhand, Dept Comp Sci & Engn, Srinagar, India.; Shivhare, SN (corresponding author), Univ Petr & Energy Studies, Sch Comp Sci, Dehra Dun, Uttarakhand, India.
EM shiv827@gmail.com; nitin@nituk.ac.in
RI Shivhare, Shiv Naresh/V-9384-2019
OI Shivhare, Shiv Naresh/0000-0002-6306-1113
CR Alex V, 2017, PROC SPIE, V10133, DOI 10.1117/12.2254487
   Aljarah I, 2018, SOFT COMPUT, V22, P1, DOI 10.1007/s00500-016-2442-1
   Amin J, 2019, COMPUT METH PROG BIO, V177, P69, DOI 10.1016/j.cmpb.2019.05.015
   Anita, 2019, SWARM EVOL COMPUT, V48, P93, DOI 10.1016/j.swevo.2019.03.013
   Ayache, 2012, MICCAI CHALLENGE MUL, P34
   Bansal JC, 2014, MEMET COMPUT, V6, P31, DOI 10.1007/s12293-013-0128-0
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Bauer S, 2011, LECT NOTES COMPUT SC, V6893, P354, DOI 10.1007/978-3-642-23626-6_44
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Damodharan S, 2015, INT ARAB J INF TECHN, V12, P42
   DeAngelis LM, 2001, NEW ENGL J MED, V344, P114, DOI 10.1056/NEJM200101113440207
   Demirhan A, 2015, IEEE J BIOMED HEALTH, V19, P1451, DOI 10.1109/JBHI.2014.2360515
   Drevelegas A., 2010, Imaging of Brain Tumors with Histological Correlations
   Fan JP, 2015, IEEE T IMAGE PROCESS, V24, P4172, DOI 10.1109/TIP.2015.2457337
   Fletcher-Heath LM, 2001, ARTIF INTELL MED, V21, P43, DOI 10.1016/S0933-3657(00)00073-7
   Gordillo N, 2013, MAGN RESON IMAGING, V31, P1426, DOI 10.1016/j.mri.2013.05.002
   Gupta N, 2019, BIOMED SIGNAL PROCES, V47, P115, DOI 10.1016/j.bspc.2018.06.003
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Harris C., 1988, ALVEY VISION C, P147151
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Jolliffe IT, 2002, CHOOSING SUBSET PRIN
   Kamnitsas K, 2018, LECT NOTES COMPUT SC, V10670, P450, DOI 10.1007/978-3-319-75238-9_38
   Kim J., 2002, Nuclear Science Symposium Conference Record, V3, P1580
   Kistler M, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2930
   Mazurowski MA, 2019, J MAGN RESON IMAGING, V49, P939, DOI 10.1002/jmri.26534
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mirjalili S, 2015, APPL INTELL, V43, P150, DOI 10.1007/s10489-014-0645-7
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Nabizadeh N, 2017, EXPERT SYST APPL, V77, P1, DOI 10.1016/j.eswa.2017.01.036
   Padlia Minal, 2019, Nanoelectronics, Circuits and Communication Systems. Proceeding of NCCS 2017. Lecture Notes in Electrical Engineering (LNEE 511), P161, DOI 10.1007/978-981-13-0776-8_15
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Prastawa M, 2004, MED IMAGE ANAL, V8, P275, DOI 10.1016/j.media.2004.06.007
   Ryan M, 2013, NCI MICCAI CHALLENGE, P43
   Sachdeva J, 2016, APPL SOFT COMPUT, V47, P151, DOI 10.1016/j.asoc.2016.05.020
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Shen JL, 2015, PATTERN RECOGN, V48, P3227, DOI 10.1016/j.patcog.2015.02.027
   Shi YX, 2021, IEEE T MULTIMEDIA, V23, P3264, DOI 10.1109/TMM.2020.3023272
   Shivhare SN, 2019, MULTIMED TOOLS APPL, V78, P34207, DOI 10.1007/s11042-019-08048-4
   Soltaninejad M, 2018, COMPUT METH PROG BIO, V157, P69, DOI 10.1016/j.cmpb.2018.01.003
   Tustison NJ, 2015, NEUROINFORMATICS, V13, P209, DOI 10.1007/s12021-014-9245-2
   Wadhwa A, 2019, MAGN RESON IMAGING, V61, P247, DOI 10.1016/j.mri.2019.05.043
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wu W, 2014, INT J COMPUT ASS RAD, V9, P241, DOI 10.1007/s11548-013-0922-7
   Zacharaki EI, 2009, MAGN RESON MED, V62, P1609, DOI 10.1002/mrm.22147
   Zhao TY, 2018, IEEE T IMAGE PROCESS, V27, P4740, DOI 10.1109/TIP.2018.2845118
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
   Zikic D, 2012, P MICCAI BRATS 2012
   Zikic D, 2012, LECT NOTES COMPUT SC, V7512, P369, DOI 10.1007/978-3-642-33454-2_46
NR 48
TC 11
Z9 11
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26969
EP 26995
DI 10.1007/s11042-021-10969-y
EA MAY 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000650124400005
DA 2024-07-18
ER

PT J
AU Said, Y
   Barr, M
AF Said, Yahia
   Barr, Mohammad
TI Human emotion recognition based on facial expressions via deep learning
   on high-resolution images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Facial expressions; Deep learning; Face-sensitive
   convolutional neural network (FS-CNN); High-resolution images
AB Detecting human emotion based on facial expression is considered a hard task for the computer vision community because of many challenges such as the difference of face shape from a person to another, difficulty of recognition of dynamic facial features, low quality of digital images, etc. In this paper, we propose a face-sensitive convolutional neural network (FS-CNN) for human emotion recognition. The proposed FS-CNN is used to detect faces on large scale images then analyzing face landmarks to predict expressions for emotion recognition. The FS-CNN is composed form two stages, patch cropping, and convolutional neural networks. The first stage is used to detect faces in high-resolution images and crop the face for further processing. The second stage is a convolutional neural network used to predict facial expression based on landmarks analytics, it was applied on pyramid images to process scale invariance. The proposed FS-CNN was trained and evaluated on the UMD Faces dataset. High performance was achieved with a mean average precision of about 95%.
C1 [Said, Yahia; Barr, Mohammad] Northern Border Univ, Coll Engn, Elect Engn Dept, Ar Ar, Saudi Arabia.
   [Said, Yahia] Univ Monastir, Fac Sci Monastir, Lab Elect & Microelectron LR99ES30, Monastir, Tunisia.
C3 Northern Border University; Universite de Monastir
RP Said, Y (corresponding author), Northern Border Univ, Coll Engn, Elect Engn Dept, Ar Ar, Saudi Arabia.; Said, Y (corresponding author), Univ Monastir, Fac Sci Monastir, Lab Elect & Microelectron LR99ES30, Monastir, Tunisia.
EM Said.yahia1@gmail.com
RI Said, Yahia/A-7333-2018; Barr, Mohammad Abdulmanan/AAO-2527-2021
OI Said, Yahia/0000-0003-0613-4037; Barr, Mohammad/0000-0003-4792-5759
FU Northern Border University, Arar, KSA [ENG-2019-1-10-F-1113]
FX The authors wish to acknowledge the approval and the support of this
   research study by the grant N degrees ENG-2019-1-10-F-1113 from the
   Deanship of the Scientific Research in Northern Border University, Arar,
   KSA.
CR AFIF M, 2018, INT C SCI EL TECHN I, P364, DOI DOI 10.1007/978-3-030-21005-2_35
   [Anonymous], 2019, FUT INF COMM C
   Arshad H, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12541
   Atri M, ARTIF INTELL ADV
   Ayachi Riadh, 2020, Proceedings of the 8th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT18). Smart Innovation, Systems and Technologies (SIST 146), P234, DOI 10.1007/978-3-030-21005-2_23
   Bansal Ankan, 2017, 2017 IEEE International Joint Conference on Biometrics (IJCB), P464, DOI 10.1109/BTAS.2017.8272731
   Bargal SA, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P433, DOI 10.1145/2993148.2997627
   Bhowmik MK, 2011, REVIEWS, REFINEMENTS AND NEW IDEAS IN FACE RECOGNITION, P113
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Dandil E., 2019, Int J Data Sci Appl, V2, P13
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goodfellow IJ, 2015, NEURAL NETWORKS, V64, P59, DOI 10.1016/j.neunet.2014.09.005
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Jaiswal S, 2020, NEURAL COMPUT APPL, V32, P11253, DOI 10.1007/s00521-019-04564-4
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Jose E, 2019, INT CONF ADVAN COMPU, P608, DOI [10.1109/icaccs.2019.8728466, 10.1109/ICACCS.2019.8728466]
   Jumani SZ., 2019, INDIAN J SCI TECHNOL, V12, P1, DOI [10.17485/ijst/2019/v12i24/145, DOI 10.17485/ijst/2019/v12i24/145093, 10.17485/ijst/2019/v12i24/145093]
   Kavitha SN, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2018), P743, DOI 10.1109/ICCMC.2018.8487558
   Khan MA, 2024, MULTIMED TOOLS APPL, V83, P14885, DOI 10.1007/s11042-020-08806-9
   Kollias Dimitrios, 2019, P BRIT MACH VIS C
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z., 2018, LARGE SCALE CELEBFAC
   Mehendale N, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2234-1
   Mehmood A, 2024, MULTIMED TOOLS APPL, V83, P14979, DOI 10.1007/s11042-020-08928-0
   Mouna Afif, 2020, NEURAL PROCESSING LE, P1
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Rashid M, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12125037
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wu WY, 2018, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2018.00227
   Yitzhak N, 2020, CORTEX, V126, P343, DOI 10.1016/j.cortex.2020.01.019
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
NR 35
TC 25
Z9 26
U1 1
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 25241
EP 25253
DI 10.1007/s11042-021-10918-9
EA APR 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000640172500003
DA 2024-07-18
ER

PT J
AU Avola, D
   Cinque, L
   Fagioli, A
   Foresti, GL
   Pannone, D
   Piciarelli, C
AF Avola, Danilo
   Cinque, Luigi
   Fagioli, Alessio
   Foresti, Gian Luca
   Pannone, Daniele
   Piciarelli, Claudio
TI Automatic estimation of optimal UAV flight parameters for real-time wide
   areas monitoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unmanned Aerial Vehicles (UAVs); Parameters estimation; Aerial
   mosaicking; Aerial change detection; Aerial object detection
AB In the last few years, small-scale Unmanned Aerial Vehicles (UAVs) have been used in many video-based monitoring applications, such as search and rescue (SAR) operations, border control, precision agriculture, and many others. Usually, during these missions, a human operator manually selects UAV flight parameters according to the specific monitoring application to be performed. Anyway, regardless a particular mission, some main tasks can be considered common preprocessing steps that require to be accomplished. These tasks include the mosaicking of areas of interest, the detection of changes over time on these areas, finally, the classification of what is present on the ground. The success of these tasks strictly depends on flight and video sensor parameters. In this paper, for the first time in the literature, a method to automatically estimate the optimal parameters, in particular altitude and frame rate, to accomplish the three main tasks reported above is presented and tested. The parameters are estimated according to several factors, including size of the target to be analysed, cruise speed of UAVs, and main internal parameters of the video sensor, i.e., focal length, field of view, and size of the pixel. The full effectiveness of the proposed method, on the three case studies (i.e., main tasks), was proven both by synthetic videos generated with the Aerial Informatics and Robotics Simulation (AirSim) and by real video sequences reported in the UAV Mosaicking and Change Detection (UMCD) and NPU Drone-Map datasets.
C1 [Avola, Danilo; Cinque, Luigi; Fagioli, Alessio; Pannone, Daniele] Sapienza Univ, Dept Comp Sci, Via Salaria 113, I-00198 Rome, Italy.
   [Foresti, Gian Luca; Piciarelli, Claudio] Univ Udine, Dept Math Comp Sci & Phys, Via Sci 206, I-33100 Udine, Italy.
C3 Sapienza University Rome; University of Udine
RP Avola, D (corresponding author), Sapienza Univ, Dept Comp Sci, Via Salaria 113, I-00198 Rome, Italy.
EM avola@di.uniroma1.it; cinque@di.uniroma1.it; fagioli@di.uniroma1.it;
   gianluca.foresti@uniud.it; pannone@di.uniroma1.it;
   claudio.piciarelli@uniud.it
RI Piciarelli, Claudio/E-5532-2012; Fagioli, Alessio/GNH-3883-2022;
   Pannone, Daniele/ABD-2058-2021
OI Fagioli, Alessio/0000-0002-8111-9120; PANNONE,
   DANIELE/0000-0001-6446-6473
FU "PREscriptive Situational awareness for cooperative auto-organizing
   aerial sensor NETworks (PRESNET)" project; MIUR of the Department of
   Computer Science of Sapienza University
FX This work was partially supported both by the "PREscriptive Situational
   awareness for cooperative auto-organizing aerial sensor NETworks
   (PRESNET)" project and by the MIUR under grant "Departments of
   Excellence 2018-2022" of the Department of Computer Science of Sapienza
   University.
CR [Anonymous], 1958, IMAGE INTENSIFIER S
   Araar O, 2017, J INTELL ROBOT SYST, V85, P369, DOI 10.1007/s10846-016-0399-z
   Avola D., 2017, 2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS), P1
   Avola D, 2019, LECT NOTES COMPUT SC, V11752, P457, DOI 10.1007/978-3-030-30645-8_42
   Avola D, 2020, MULTIMED TOOLS APPL, V79, P18387, DOI 10.1007/s11042-020-08758-0
   Avola D, 2020, MULTIMED TOOLS APPL, V79, P13533, DOI 10.1007/s11042-019-08590-1
   Avola D, 2020, IEEE T SYST MAN CY-S, V50, P2139, DOI 10.1109/TSMC.2018.2804766
   Avola D, 2018, MULTIMED TOOLS APPL, V77, P24955, DOI 10.1007/s11042-018-5730-1
   Avola D, 2017, LECT NOTES COMPUT SC, V10484, P694, DOI 10.1007/978-3-319-68560-1_62
   Avola D, 2017, PATTERN RECOGN LETT, V100, P110, DOI 10.1016/j.patrec.2017.10.029
   Avtar R, 2020, REMOTE SENS-BASEL, V12
   Bu SH, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4564, DOI 10.1109/IROS.2016.7759672
   Cabrera-Quiros L, 2020, IEEE T MULTIMEDIA, V22, P138, DOI 10.1109/TMM.2019.2922122
   Chan CC, 2020, IEEE ACCESS, V8, P80120, DOI 10.1109/ACCESS.2020.2988654
   Chen M, 2020, IEEE ACCESS, V8, P77089, DOI 10.1109/ACCESS.2020.2989614
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gaszczak A, 2011, P INT C INT ROB COMP, P71
   Ho Y., 2015, P 1 WORKSHOP MICROAE, P3, DOI DOI 10.1145/2750675.2750684
   Jiang R, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111850
   Kostas Daniilidis RK., 2006, IMAGING PINHOLE CAME, DOI [10.1007/978-1-4020-4894-4, DOI 10.1007/978-1-4020-4894-4]
   Lin S, 2017, AUTON ROBOT, V41, P881, DOI 10.1007/s10514-016-9564-2
   Liu W., 2016, LECT NOTES COMPUT SC, P21, DOI DOI 10.1007/978-3-319-46448-0_2
   Lu YQ, 2020, MULTIMED TOOLS APPL, V79, P18747, DOI 10.1007/s11042-020-08779-9
   Matsukawa T, 2020, IEEE T PATTERN ANAL, V42, P2179, DOI 10.1109/TPAMI.2019.2914686
   Meng XY, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P261, DOI 10.1145/2733373.2806225
   Pounds PEI, 2012, AUTON ROBOT, V33, P129, DOI 10.1007/s10514-012-9280-5
   Price A, 2006, IEEE INT CONF ROBOT, P2854, DOI 10.1109/ROBOT.2006.1642134
   Qi JT, 2016, J FIELD ROBOT, V33, P290, DOI 10.1002/rob.21615
   Reymann C, 2018, AUTON ROBOT, V42, P491, DOI 10.1007/s10514-017-9625-1
   Ruchanurucks M, 2018, J INTELL ROBOT SYST, V90, P189, DOI 10.1007/s10846-017-0657-8
   Scherer J., 2015, P 1 WORKSH MICR VEH, P33, DOI DOI 10.1145/2750675.2750683
   Shah S., 2017, Field and service robotics, DOI 10.1007/978-3-319-67361-5_40
   Simonyan K., 2014, 14091556 ARXIV
   Sohn WJ, 2019, IEEE J TRANSL ENG HE, V7, DOI 10.1109/JTEHM.2019.2953257
   Vamsikrishna KM, 2016, IEEE T BIO-MED ENG, V63, P991, DOI 10.1109/TBME.2015.2480881
   Wischounig-Strucl D, 2015, MACH VISION APPL, V26, P885, DOI 10.1007/s00138-015-0699-5
   Yahyanejad Saeed, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P329, DOI 10.1109/AVSS.2010.14
   Yang YZ, 2018, IEEE INTERNET THINGS, V5, P186, DOI 10.1109/JIOT.2017.2777820
   Zachariah D, 2011, IEEE INT CONF ROBOT, P1166
   Zengin U, 2011, ROBOT AUTON SYST, V59, P1049, DOI 10.1016/j.robot.2011.08.006
   Zhang YS, 2020, IEEE ACCESS, V8, P130367, DOI 10.1109/ACCESS.2020.3009104
   Zheng ZW, 2017, IEEE ACCESS, V5, P5556, DOI 10.1109/ACCESS.2017.2671440
   Zhou SP, 2018, PATTERN RECOGN, V76, P739, DOI 10.1016/j.patcog.2017.10.005
NR 43
TC 9
Z9 9
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 25009
EP 25031
DI 10.1007/s11042-021-10859-3
EA APR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000639743500001
DA 2024-07-18
ER

PT J
AU Spalazzi, L
   Paolanti, M
   Frontoni, E
AF Spalazzi, Luca
   Paolanti, Marina
   Frontoni, Emanuele
TI An offline parallel architecture for forensic multimedia classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parallel architecture; Machine learning; Digital forensic
ID IMAGE
AB Nowadays, the volume of the multimedia heterogeneous evidence presented for digital forensic analysis has significantly increased, thus requiring the application of big data technologies, cloud-based forensics services, as well as Machine Learning (ML) techniques. In digital forensics domain, ML algorithms have been applied for cybercrime investigation such as child abuse investigations, malware classification, and image forensics. This paper addresses this issues and deals with forensic analysis of digital images and videos. In particular, this work aims at proposing a multimedia classification tool with a parallel software architecture for a fast inspection, which is easy to use (to be used by officers during a search), requires limited hardware resources and it is built on an open-source software to limit its costs. Moreover, this tool must be able to quickly inspect multiple devices at a time. When positives are found in a device, such device will be seized for a deeper analysis later in the lab. It will not be seized otherwise, reducing the inconvenience for the suspect as well as the time required for the next analysis phase. As a case study, we focus on the identification of child pornography images. Experimental results show that the proposed architecture is capable of guaranteeing a high recall, a fast process and high performances in real scenarios.
C1 [Spalazzi, Luca; Paolanti, Marina; Frontoni, Emanuele] Univ Politecn Marche, Dept Informat Engn DII, Via Brecce Bianche, Ancona, Italy.
C3 Marche Polytechnic University
RP Paolanti, M (corresponding author), Univ Politecn Marche, Dept Informat Engn DII, Via Brecce Bianche, Ancona, Italy.
EM l.spalazzi@univpm.it; m.paolanti@univpm.it; e.frontoni@univpm.it
RI Frontoni, Emanuele/D-9838-2013; Spalazzi, Luca/A-9983-2013
OI Frontoni, Emanuele/0000-0002-8893-9244; SPALAZZI,
   Luca/0000-0002-4807-6632
FU Universita Politecnica delle Marche within the CRUI-CARE Agreement
FX Open access funding provided by Universita Politecnica delle Marche
   within the CRUI-CARE Agreement.
CR Al Mutawa N, 2015, PROCEEDINGS 10TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY ARES 2015, P293, DOI 10.1109/ARES.2015.49
   Amerini I, 2017, SIGNAL PROCESS-IMAGE, V57, P1, DOI 10.1016/j.image.2017.04.009
   [Anonymous], 2006, IADIS International Journal on Computer Science and Information Systems
   [Anonymous], 2006, 2006 CAN C EL COMP E
   Basilio J.A.M., 2011, International Conference on Applied Mathematics on Computer Engineering and Applications, P123
   Bissias G, 2016, CHILD ABUSE NEGLECT, V52, P185, DOI 10.1016/j.chiabu.2015.10.022
   Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122
   Chatzis V, 2016, 2016 DIGITAL MEDIA INDUSTRY AND ACADEMIC FORUM (DMIAF), P121, DOI 10.1109/DMIAF.2016.7574915
   Choi B, 2009, ICCIT: 2009 FOURTH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND CONVERGENCE INFORMATION TECHNOLOGY, VOLS 1 AND 2, P659, DOI 10.1109/ICCIT.2009.43
   Fanchang, 2020, MULTIMED TOOLS APPL, P1
   Villalba LJG, 2016, EXPERT SYST APPL, V55, P59, DOI 10.1016/j.eswa.2016.01.025
   Giudice O, 2017, LECT NOTES COMPUT SC, V10485, P625, DOI 10.1007/978-3-319-68548-9_57
   Grega M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010047
   Grega M, 2014, MULTIMED TOOLS APPL, V68, P95, DOI 10.1007/s11042-012-1164-3
   Hsieh IS, 2002, PATTERN RECOGN, V35, P1583, DOI 10.1016/S0031-3203(01)00146-7
   Iuliani M, 2019, IEEE T INF FOREN SEC, V14, P635, DOI 10.1109/TIFS.2018.2859760
   Jang D.M., 2011, IEEE WORKSHOP APPL C, P599
   Jang EG, 2012, MULTIMED TOOLS APPL, V57, P407, DOI 10.1007/s11042-011-0738-9
   Jenkins R, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083325
   Kamenicky J, 2016, FORENSIC SCI INT, V264, P153, DOI 10.1016/j.forsciint.2016.04.027
   Kovac J, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P144
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P25427, DOI 10.1007/s11042-019-7734-x
   Li J, 2018, J VIS COMMUN IMAGE R, V57, P183, DOI 10.1016/j.jvcir.2018.10.023
   Lin Y.C., 2003, International Conference on Computer Vision, Graphics and Image Processing, P123
   Maksymowicz K, 2014, FORENSIC SCI INT, V242, pE6, DOI 10.1016/j.forsciint.2014.07.004
   Mofaddel M. A., 2010, 2nd International Conference on Computer Technology and Development (ICCTD 2010), P682, DOI 10.1109/ICCTD.2010.5646444
   Moré LG, 2015, IEEE IMAGE PROC, P4644, DOI 10.1109/ICIP.2015.7351687
   Pandey RC, 2016, DIGIT INVEST, V19, P1, DOI 10.1016/j.diin.2016.08.002
   Peersman C, 2014, IEEE SEC PRIV WORKS, P124, DOI 10.1109/SPW.2014.27
   Platzer C, 2014, SFCS'14: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON SECURITY AND FORENSICS IN COMMUNICATION SYSTEMS, P45, DOI 10.1145/2598918.2598920
   Ricanek K, 2012, COMPUTER, V45, P95, DOI 10.1109/MC.2012.308
   Sae-Bae N, 2014, IEEE IMAGE PROC, P5332, DOI 10.1109/ICIP.2014.7026079
   Sayed U., 2009, International Conference on Sciences of Electronic, Technologies of Information and Telecommunications: IEEE, P1
   Schulze C., 2014, Proceedings of International Conference on Multimedia Retrieval, P353
   Smolka B, 2003, PATTERN RECOGN LETT, V24, P1767, DOI 10.1016/S0167-8655(02)00331-8
   Ulges A, 2011, IEEE INT CON MULTI
   Vapnik V., 1999, NATURE STAT LEARNING
   Wang DP, 2018, MULTIMED TOOLS APPL, V77, P23411, DOI 10.1007/s11042-018-5651-z
   Wang F, 2016, MULTIMED TOOLS APPL, V75, P10097, DOI 10.1007/s11042-015-2798-8
   Xuanjing Shen, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P2473, DOI 10.1109/CISP.2010.5647823
   Zaidan AA, 2014, NEUROCOMPUTING, V131, P397, DOI 10.1016/j.neucom.2013.10.003
   Zeng L, 2013, PROCEEDINGS OF 2013 IEEE INTERNATIONAL CONFERENCE ON MEDICAL IMAGING PHYSICS AND ENGINEERING (ICMIPE), P269, DOI 10.1109/ICMIPE.2013.6864549
   Zhicheng Zhao, 2010, 2010 2nd IEEE International Conference on Network Infrastructure and Digital Content (IC-NIDC 2010), P149, DOI 10.1109/ICNIDC.2010.5657916
   Zuo H., 2010, International Conference on World Wide Web: ACM, P1227
NR 44
TC 3
Z9 3
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22715
EP 22730
DI 10.1007/s11042-021-10819-x
EA APR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000636147400001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Sarkar, A
   Sarkar, M
AF Sarkar, Arindam
   Sarkar, Moumita
TI Tree parity machine guided patients' privileged based secure sharing of
   electronic medical record: cybersecurity for telehealth during COVID-19
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Telehealth; Security; COVID-19; Artificial Neural Networks (ANN); Secret
   share
ID ENCRYPTION ALGORITHM; STORAGE; SCHEME; IMAGES
AB In the COVID-19 pandemic, telehealth plays a significant role in the e-healthcare. E-health security risks have also risen significantly with the rise in the use of telehealth. This paper addresses one of e-health's key concerns, namely security. Secret sharing is a cryptographic method to ensure reliable and secure access to information. To eliminate the constraint that in the existing secret sharing schemes, this paper presents Tree Parity Machine (TPM) guided patients' privileged based secure sharing. This is a new secret sharing technique that generates the shares using a simple mask based operation. This work considers addressing the challenges presents in the original secret sharing scheme. This proposed technique enhances the security of the existing scheme. This research introduces a concept of privileged share in which among k number of shares one share should come from a specific recipient (patient) to whom a special privilege is given to recreate the original information. In the absence of this privileged share, the original information cannot be reconstructed. This technique also offers TPM based exchange of secret shares to prevent Man-In-The-Middle-Attack (MITM). Here, two neural networks receive common inputs and exchange their outputs. In some steps, it leads to full synchronization by setting the discrete weights according to the specific rule of learning. This synchronized weight is used as a common secret session key for transmitting the secret shares. The proposed method has been found to produce attractive results that show that the scheme achieves a great degree of protection, reliability, and efficiency and also comparable to the existing secret sharing scheme.
C1 [Sarkar, Arindam] Ramakrishna Mission Vidyamandira, Dept Comp Sci & Elect, Howrah 711202, W Bengal, India.
   [Sarkar, Moumita] Univ Burdwan, Dept Comp Sci, Burdwan 713104, W Bengal, India.
C3 University of Burdwan
RP Sarkar, A (corresponding author), Ramakrishna Mission Vidyamandira, Dept Comp Sci & Elect, Howrah 711202, W Bengal, India.
EM arindam.vb@gmail.com; kar.moumi@gmail.com
OI Sarkar, Arindam/0000-0002-4951-4729
CR Acharya R, 2004, COMPUT METH PROG BIO, V76, P13, DOI 10.1016/j.cmpb.2004.02.009
   Acharya R, 2003, COMPUT BIOL MED, V33, P303, DOI 10.1016/S0010-4825(02)00083-5
   Acharya UR, 2001, IEEE T INF TECHNOL B, V5, P320, DOI 10.1109/4233.966107
   Adams S, 2019, ANN ONCOL, V30, P397, DOI [10.1093/annonc/mdy517, 10.1093/annonc/mdy518]
   Ahmad Musheer, 2011, 2011 4th International Conference on Biomedical Engineering and Informatics, P1471, DOI 10.1109/BMEI.2011.6098594
   AlKhodaidi T, 2021, MULTIMED TOOLS APPL, V80, P1143, DOI 10.1007/s11042-020-09720-w
   Blesswin AJ, 2020, MULTIMED TOOLS APPL, V79, P17057, DOI 10.1007/s11042-019-7535-2
   CDC, 2020, COVID 19 SIT SUMM
   Chattopadhyay AK, 2021, MULTIMED TOOLS APPL, V80, P35051, DOI 10.1007/s11042-020-09174-0
   De Capua C, 2010, IEEE T INSTRUM MEAS, V59, P2530, DOI 10.1109/TIM.2010.2057652
   Gupta M, 2020, MULTIMED TOOLS APPL, V79, P12183, DOI 10.1007/s11042-019-08454-8
   HIPAA, 2020, CISA ISS FRESH AL ON
   HIPAA, 2020, FBI WARNS INCR COVID
   HIPAA, 2020, EFF WARNS PRIV SEC R
   HIPAA, 2020, HACK TARG WHO HHS CO
   HIPAA, 2020, SCAMM TARG HEALTHC B
   HIPAA, 2020, ZOOM SEC PROBL RAIS
   HIPAA, 2020, GOV HEALTHC AG COVID
   HIPAA, 2020, INTERPOL ISS WARN OV
   HIPAA, 2020, FBI ISS FLASH AL COV
   HIPAA, 2020, ADV HEALTHC ORG PREV
   Huang CL, 2020, LANCET, V395, P497, DOI [10.1016/S0140-6736(20)30183-5, 10.1016/S0140-6736(20)30211-7]
   Jakovljevic M, 2020, PSYCHIAT DANUB, V32, P6, DOI 10.24869/psyd.2020.6
   Katz J., 2014, Introduction to modern cryptography
   Liaqat RM, 2016, PROCEDIA COMPUT SCI, V98, P368, DOI 10.1016/j.procs.2016.09.056
   Lin C, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0446-0
   Lin CF, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0049-6
   Lucey DR, 2016, JAMA-J AM MED ASSOC, V315, P865, DOI 10.1001/jama.2016.0904
   McKibbin W, 2021, ASIAN ECON PAP, V20, P1, DOI 10.1162/asep_a_00796
   Meneses F, 2016, INT J COMPUT SCI NET, V16, P55
   Mulyadi IH., 2019, INDONES J ELECT ENG, V7, P2089, DOI [10.11591/ijeei.v7i1.937, DOI 10.11591/IJEEI.V7I1.937]
   Murillo-Escobar MA, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0698-3
   Nabiyev Vasif V., 2010, 2010 IEEE 18th Signal Processing and Communications Applications Conference (SIU 2010), P820, DOI 10.1109/SIU.2010.5653474
   Nag A, 2020, MULTIMED TOOLS APPL, V79, P16219, DOI 10.1007/s11042-019-07807-7
   Nayak J, 2004, BIOMED ENG ONLINE, V3, DOI 10.1186/1475-925X-3-17
   Nayak J, 2009, J MED SYST, V33, P163, DOI 10.1007/s10916-008-9176-2
   NIST, 2020, NIST STAT TEST
   PhysioBank, 2020, PHYS ATM
   Raeiatibanadkooki M, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0433-5
   Shivani S, 2017, MULTIMED TOOLS APPL, V76, P3851, DOI 10.1007/s11042-016-4012-z
   Spencer Aleksandra, 2019, Nurs Manag (Harrow), DOI 10.7748/nm.2019.e1806
   WHO, 2020, CRITICAL PREPAREDNES
   Williams Aaron M, 2018, Mhealth, V4, P11, DOI 10.21037/mhealth.2018.04.03
   Zhu N, 2020, NEW ENGL J MED, V382, P727, DOI [10.1056/NEJMoa2001017, 10.1172/JCI89857]
NR 44
TC 6
Z9 7
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21899
EP 21923
DI 10.1007/s11042-021-10705-6
EA MAR 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000630848000002
PM 33776546
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Abdelbaky, A
   Aly, S
AF Abdelbaky, Amany
   Aly, Saleh
TI Human action recognition using three orthogonal planes with unsupervised
   deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Unsupervised convolutional architectures;
   Principal component analysis network (PCANet); Three orthogonal
   planes(TOP)
ID FEATURES; PERFORMANCE
AB Deep learning models have attained great success for an extensive range of computer vision applications including image and video classification. However, the complex architecture of the most recently developed networks imposes certain memory and computational resource limitations, especially for human action recognition applications. Unsupervised deep convolutional neural networks such as PCANet can alleviate these limitations and hence significantly reduce the computational complexity of the whole recognition system. In this work, instead of using 3D convolutional neural network architecture to learn temporal features of video actions, the unsupervised convolutional PCANet model is extended into (PCANet-TOP) which effectively learn spatiotemporal features from Three Orthogonal Planes (TOP). For each video sequence, spatial frames (XY) and temporal planes (XT and YT) are utilized to train three different PCANet models. Then, the learned features are fused after reducing their dimensionality using whitening PCA to obtain spatiotemporal feature representation of the action video. Finally, Support Vector Machine (SVM) classifier is applied for action classification process. The proposed method is evaluated on four benchmarks and well-known datasets, namely, Weizmann, KTH, UCF Sports, and YouTube action datasets. The recognition results show that the proposed PCANet-TOP provides discriminative and complementary features using three orthogonal planes and able to achieve promising and comparable results with state-of-the-art methods.
C1 [Abdelbaky, Amany; Aly, Saleh] Aswan Univ, Fac Engn, Elect Engn Dept, Aswan, Egypt.
   [Aly, Saleh] Majmaah Univ, Dept Informat Technol, Coll Comp & Informat Sci, Al Majmaah 11952, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Aswan University; Majmaah University
RP Aly, S (corresponding author), Aswan Univ, Fac Engn, Elect Engn Dept, Aswan, Egypt.; Aly, S (corresponding author), Majmaah Univ, Dept Informat Technol, Coll Comp & Informat Sci, Al Majmaah 11952, Saudi Arabia.
EM amany.abdelbaki@aswu.edu.eg; saleh@aswu.edu.eg
RI Aly, Saleh/B-9095-2019
OI Aly, Saleh/0000-0002-1772-4254
FU Deanship of Scientific Research at Majmaah University [R-2021-21]
FX Saleh Aly would like to thank the Deanship of Scientific Research at
   Majmaah University for supporting this work under Project No. R-2021-21
CR Abdelbaky A, 2021, VISUAL COMPUT, V37, P1821, DOI 10.1007/s00371-020-01940-3
   Abdelbaky A, 2020, PROCEEDINGS OF 2020 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMMUNICATION AND COMPUTER ENGINEERING (ITCE), P257, DOI [10.1109/itce48509.2020.9047769, 10.1109/ITCE48509.2020.9047769]
   Abdelbaky A, 2020, NEURAL COMPUT APPL, V32, P12561, DOI 10.1007/s00521-020-04712-1
   Ahmad M, 2008, PATTERN RECOGN, V41, P2237, DOI 10.1016/j.patcog.2007.12.008
   Aly S, 2020, IEEE ACCESS, V8, P83199, DOI 10.1109/ACCESS.2020.2990699
   Aly S, 2019, MULTIMED TOOLS APPL, V78, P24923, DOI 10.1007/s11042-019-7674-5
   Aly W, 2019, IEEE ACCESS, V7, P123138, DOI 10.1109/ACCESS.2019.2938829
   Andrearczyk V, 2018, PATTERN RECOGN, V76, P36, DOI 10.1016/j.patcog.2017.10.030
   Anh-Phuong Ta, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3224, DOI 10.1109/ICPR.2010.788
   [Anonymous], 4 UK COMP VIS STUD W
   [Anonymous], 2018, 2018 International Joint Conference on Neural Networks (IJCNN), DOI 10.1145/2851141.2851145
   Arashloo SR, 2017, J VIS COMMUN IMAGE R, V43, P89, DOI 10.1016/j.jvcir.2016.12.015
   Aslan MF, 2020, NEURAL COMPUT APPL, V32, P8585, DOI 10.1007/s00521-019-04365-9
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Hasan M, 2014, PROC CVPR IEEE, P796, DOI 10.1109/CVPR.2014.107
   Hou R, 2017, IEEE I CONF COMP VIS, P5823, DOI 10.1109/ICCV.2017.620
   Ibrahim MS, 2016, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2016.217
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jia K., 2008, 2008 IEEE C COMP VIS, P1, DOI DOI 10.1109/CVPR.2008.4587732
   Kessy A, 2018, AM STAT, V72, P309, DOI 10.1080/00031305.2016.1277159
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Koohzadi M, 2017, IET COMPUT VIS, V11, P623, DOI 10.1049/iet-cvi.2016.0355
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Li X, 2017, IEEE I CONF COMP VIS, P2895, DOI 10.1109/ICCV.2017.313
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Mangai UG, 2010, IETE TECH REV, V27, P293, DOI 10.4103/0256-4602.64604
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mota Virginia F., 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P328, DOI 10.1109/SIBGRAPI.2013.52
   Nadeem A, 2020, INT CONF ADV COMP SC, DOI 10.1109/icacs47775.2020.9055951
   Naveed H, 2019, INT J MACH LEARN CYB, V10, P2329, DOI 10.1007/s13042-018-0870-1
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Schindler K, 2008, PROC CVPR IEEE, P3025
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Simonyan K, 2014, ADV NEUR IN, V27
   Sun L, 2014, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2014.336
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Tran Du, 2017, ARXIV170805038
   Wang L, 2018, IEEE ACCESS, V6, P17913, DOI 10.1109/ACCESS.2018.2817253
   Wang T, 2017, IEEE ACCESS, V5, P17627, DOI 10.1109/ACCESS.2017.2746095
   Wang WG, 2018, PROC CVPR IEEE, P4894, DOI 10.1109/CVPR.2018.00514
   Wu JS, 2017, IEEE ACCESS, V5, P3322, DOI 10.1109/ACCESS.2017.2675478
   Yao GL, 2019, PATTERN RECOGN LETT, V118, P14, DOI 10.1016/j.patrec.2018.05.018
   Yao TT, 2017, PATTERN RECOGN, V64, P236, DOI 10.1016/j.patcog.2016.11.012
   Ye JM, 2018, PROC CVPR IEEE, P9378, DOI 10.1109/CVPR.2018.00977
   Yi Y, 2016, PATTERN RECOGN, V53, P148, DOI 10.1016/j.patcog.2015.11.022
   Yuan CF, 2013, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2013.99
   Zare A, 2020, PATTERN ANAL APPL, V23, P265, DOI 10.1007/s10044-019-00788-1
   Zhang KT, 2018, MULTIMED TOOLS APPL, V77, P16053, DOI 10.1007/s11042-017-5179-7
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 59
TC 16
Z9 17
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20019
EP 20043
DI 10.1007/s11042-021-10636-2
EA MAR 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625344600005
DA 2024-07-18
ER

PT J
AU Anushiadevi, R
   Praveenkumar, P
   Rayappan, JBB
   Amirtharajan, R
AF Anushiadevi, R.
   Praveenkumar, Padmapriya
   Rayappan, John Bosco Balaguru
   Amirtharajan, Rengarajan
TI Uncover the cover to recover the hidden secret-A separable reversible
   data hiding framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Separable reversible data hiding; Lossless data hiding; Information
   security; Image steganography; Image encryption
ID ENCRYPTED IMAGE; DIVISION
AB The volatile development in the multimedia cognitive content is changing the global set-up towards a cloud-based architecture which is helped us with a massive amount of computer storage and the highest computational platform. Cost-saving and elasticity of services will be provided by progressive cloud computing technology for users. With the advancement in multimedia technology, the data owners outsource their private multimedia data on the hybrid cloud. Meantime the cloud servers also carry out some highly computationally expensive tasks. Nevertheless, there is an opportunity for security infracts possible in the public cloud environment. It makes an alarm for a cloud environment in security aspects. Before outsourcing multimedia data, an encryption technique is needed for safeguarding against several attacks. But performing the same is a significant challenge. A new research area was recently awakened on privacy-preserving Reversible Data Hiding (RDH) especially for multimedia data over the outsourced environment. A novel RDH for an encrypted image was proposed in this paper by using the (Most Significant Bit) MSB difference of the pixel value. By using this method, any third-party people can embed the ciphertext in the cipher image without the knowledge of the cover and secret. A person with decryption keys can get back the secret and the cover without any loss. The proposed work achieves the embedding capacity up to 1 bpp (bits per pixel) with the encryption quality of near-zero correlation and uniform histogram. The decrypted image is also retrieved with infinite Peak Signal to Noise Ratio (PSNR), unit Structural Similarity Index Metric (SSIM) and zero Bit Error Rate (BER).
C1 [Anushiadevi, R.] SASTRA Deemed Univ, Sch Comp, Thanjavur 613401, India.
   [Praveenkumar, Padmapriya; Rayappan, John Bosco Balaguru; Amirtharajan, Rengarajan] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Amirtharajan, R (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM amir@ece.sastra.edu
RI Amirtharajan, Rengarajan/C-6471-2011; praveenkumar,
   padmapriya/AAH-9426-2019; Rayappan, John Bosco Balaguru/K-6842-2013
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; praveenkumar,
   padmapriya/0000-0001-8483-1538; R, Dr. Anushiadevi/0000-0002-5316-7096;
   Rayappan, John Bosco Balaguru/0000-0003-4641-9870
FU Department of Science & Technology, New Delhi [SR/FST/ET-II/2018/221]
FX Authors thank Department of Science & Technology, New Delhi for the FIST
   funding (SR/FST/ET-II/2018/221). Also, Authors wish to thank the
   Intrusion Detection Lab at School of Electrical & Electronics
   Engineering, SASTRA Deemed University for providing infrastructural
   support to carry out this research work.
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Agrawal S, 2017, OPTIK, V130, P922, DOI 10.1016/j.ijleo.2016.11.059
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Cox Ingemar, 2007, MORGAN KAUFMANN
   daMirandaNeto A, 2014, COMPUT TECHNOL APPL, V5
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Goth G., 2005, IEEE Computer Socienty, V6, P2
   Hong W, 2014, SCI WORLD J, V2014
   Jain AK, 2003, IEEE T PATTERN ANAL, V25, P1494, DOI 10.1109/TPAMI.2003.1240122
   Kumar A, 2019, INT J CLOUD APPL COM, V9, P22, DOI 10.4018/IJCAC.2019070102
   Kuribayashi M, 2005, IEEE T IMAGE PROCESS, V14, P2129, DOI 10.1109/TIP.2005.859383
   Li M, 2015, SIGNAL PROCESS-IMAGE, V39, P234, DOI 10.1016/j.image.2015.10.001
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Liu WL, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9120308
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Manikandan VM, 2018, PROCEDIA COMPUT SCI, V133, P348, DOI 10.1016/j.procs.2018.07.043
   Puech W, 2008, PROC SPIE, V6819, DOI 10.1117/12.766754
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Tai WL, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010023
   Tang ZJ, 2019, J REAL-TIME IMAGE PR, V16, P709, DOI 10.1007/s11554-018-0838-0
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang B., 2019, INT J HIGH PERFORM C, V14, P265, DOI [10.1504/IJHPCN.2019.102126, DOI 10.1504/IJHPCN.2019.102126]
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watkins J, 2001, STEGANOGRAPHY MESSAG
   Wu HT, 2016, J VIS COMMUN IMAGE R, V40, P765, DOI 10.1016/j.jvcir.2016.08.021
   Xinpeng Z, 2013, 3 INT C MULT TECHN I
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zheng SL, 2016, MULTIMED TOOLS APPL, V75, P13765, DOI 10.1007/s11042-015-2920-y
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 42
TC 13
Z9 13
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19695
EP 19714
DI 10.1007/s11042-021-10729-y
EA MAR 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000623716500001
DA 2024-07-18
ER

PT J
AU Christilin, DMAB
   Mary, MS
AF Christilin, D. M. Annie Brighty
   Mary, M. Safish
TI Residual encoder-decoder up-sampling for structural preservation in
   noise removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rician noise; Wassertein GAN; REDUPNSWGAN; Signed structural non-similar
   loss, Huber loss, AVG loss
AB While denoising 3D MRI, structural preservation is a very critical process in the medical region. However, Rician noise in MRI has affected the image quality which is complicated for diagnosing the disease like a brain tumor. So the Rician noise removal process is introduced in this article using filters based method named Residual Encoder-Decoder Up-sampling Non-Similar Wassertein Generative Adversarial Network (REDUPNSWGAN) which preserves the structural similarity between the neighborhood slices in 3D configuration is utilized as GPU. Residual auto-encoders are connected with De-convolution processes that are sent to the Generator Net (GNET). Furthermore, to reduce the level of Huber loss, the perceptual loss for similarity is implemented by the extraction of the feature space using Average-pool Net (AVGNET) which is incorporated with Huber loss, signed structural non-similar loss and Wassertein Adversarial loss to form the REDUPNSWGAN loss. Experimentally, this proposed method shows better performance quality based on mean PSNR than REDWGANVGG19 and also time complexity based on training and testing period which shows better than REDWGANVGG19. Particularly, the proposed network Residual Encoder-Decoder Upsampling Non-Similar REDUPNSWGAN reduces the noise level and preserves the structural similarity.
C1 [Christilin, D. M. Annie Brighty; Mary, M. Safish] Manonmaniam Sundaranar Univ Abishekapatti, Dept Comp Sci, St Xaviers Coll, Tirunelveli, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University
RP Christilin, DMAB (corresponding author), Manonmaniam Sundaranar Univ Abishekapatti, Dept Comp Sci, St Xaviers Coll, Tirunelveli, Tamil Nadu, India.
EM anibrighty@gmail.com
OI Mary, Safish/0000-0001-5133-106X; bright, dorathy/0000-0002-5526-6653
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Chen YH, 2018, LECT NOTES COMPUT SC, V11070, P91, DOI 10.1007/978-3-030-00928-1_11
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fu YB, 2018, MED PHYS, V45, P5129, DOI 10.1002/mp.13221
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gulrajani Ishaan, 2017, P ADV NEUR INF PROC, P5767
   Inam O., 2019, APPL MAGN RESON, P1
   Jiang DS, 2018, JPN J RADIOL, V36, P566, DOI 10.1007/s11604-018-0758-8
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Lin Zhang, 2015, 2015 2nd International Conference on Information Science and Control Engineering (ICISCE), P760, DOI 10.1109/ICISCE.2015.175
   Lone AH, 2019, GLOBAL SCI TECH, V11, P116, DOI 10.5958/2455-7110.2019.00016.8
   Pal C, 2017, INT J IMAG SYST TECH, V27, P248, DOI 10.1002/ima.22230
   Park E, 2019, IEEE T INF FOREN SEC, V14, P3016, DOI 10.1109/TIFS.2019.2907184
   Ran MS, 2019, MED IMAGE ANAL, V55, P165, DOI 10.1016/j.media.2019.05.001
   Rini C., 2019, Proceedings of the 2nd International Conference on Data Engineering and Communication Technology (ICDECT 2017). Advances in Intelligent Systems and Computing (AISC 828), P693, DOI 10.1007/978-981-13-1610-4_70
   Tolstikhin I., 2017, ARXIV PREPRINT ARXIV
   Wang QF, 2019, IEEE ACCESS, V7, P18450, DOI 10.1109/ACCESS.2019.2896409
   Yahya AA, 2019, MULTIMED TOOLS APPL, V78, P15545, DOI 10.1007/s11042-018-6955-8
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang Y., 2019, ARXIV PREPRINT ARXIV
   Zhao M, 2020, COMPUT MED IMAG GRAP, V80, DOI 10.1016/j.compmedimag.2020.101698
   Zou Y, 2019, MATH PROBL ENG
NR 23
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19441
EP 19457
DI 10.1007/s11042-021-10582-z
EA FEB 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000622668700007
DA 2024-07-18
ER

PT J
AU Zhao, JH
   Chen, TQ
   Cai, B
AF Zhao, Jianhui
   Chen, Tianquan
   Cai, Bo
TI A computer-aided diagnostic system for mammograms based on YOLOv3
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Deep learning; Convolutional neural network; Object
   detection and classification; YOLOv3
ID BREAST-CANCER; DIGITAL MAMMOGRAMS
AB Due to a large amount of noise in medical images, the task of detecting and classifying the lesions of mammograms remains a huge challenge. Based on the existing deep learning methods, focusing on the diversity of breast cancer lesion types, this paper proposes a computer-aided diagnosis system based on YOLOv3 (You Only Look Once version 3) convolutional neural network for mammograms. In this system, we integrate detection and multi-classification problems of breast lesions into a regression problem, thereby simultaneously accomplish the two tasks in one framework. The proposed computer-aided diagnosis system is mainly divided into three components: preprocessing part of the original mammograms, deep convolutional neural network based on YOLOv3, processing and evaluation of the network output. We use the dataset from CBIS-DDSM to train three models: general model, mass model and microcalcification model. These trained models can detect the position of the input mammograms in different situations, and then classify them into mass, microcalcification, benign, malignant, and other categories. After evaluating the performance by using test set images, the accuracy rates of the general model, mass model, and microcalcification model trained by our system reach 93.667 %, 97.767 %, 96.870 % in the detection task, and 93.927 %, 98.121 %, 97.045 % in the classification task. The computer-aided diagnosis system performs well in lesion detection and classification tasks with high-noise mammograms, reflecting well robustness.
C1 [Zhao, Jianhui; Chen, Tianquan] Wuhan Univ, Sch Comp Sci, Wuhan, Hubei, Peoples R China.
   [Cai, Bo] Wuhan Univ, Sch Cyber Sci & Engn, Wuhan, Hubei, Peoples R China.
C3 Wuhan University; Wuhan University
RP Cai, B (corresponding author), Wuhan Univ, Sch Cyber Sci & Engn, Wuhan, Hubei, Peoples R China.
EM caib@whu.edu.cn
OI Cai, Bo/0000-0001-5261-0191
CR Al-antari MA, 2018, J MED BIOL ENG, V38, P443, DOI 10.1007/s40846-017-0321-6
   Al-masni MA, 2017, IEEE ENG MED BIO, P1230, DOI 10.1109/EMBC.2017.8037053
   Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017
   Arevalo J, 2016, COMPUT METH PROG BIO, V127, P248, DOI 10.1016/j.cmpb.2015.12.014
   Ben-Ari R, 2017, I S BIOMED IMAGING, P552, DOI 10.1109/ISBI.2017.7950581
   BRIA A, LECT NOTES COMPUT SC, V485, P288
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   GOTZSCHE PC, 2013, COCHRANE DB SYST REV
   Heath M, 1998, COMP IMAG VIS, V13, P457
   Jaffar MA, 2017, INT J ADV COMPUT SC, V8, P286
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jung H, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203355
   Kingma D. P., 2017, 14126980 ARXIV
   Kooi T, 2016, LECT NOTES COMPUT SC, V9699, P51, DOI 10.1007/978-3-319-41546-8_7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee CH, 2010, J AM COLL RADIOL, V7, P18, DOI 10.1016/j.jacr.2009.09.022
   Ma J, 2019, ARXIV190700528CS
   Mordang JJ, 2016, LECT NOTES COMPUT SC, V9699, P35, DOI 10.1007/978-3-319-41546-8_5
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Omonigho EL, 2020, 2020 INT C MATH COMP, P1
   Platania R, 2017, ACM-BCB' 2017: PROCEEDINGS OF THE 8TH ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY,AND HEALTH INFORMATICS, P536, DOI 10.1145/3107411.3107484
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sarath CK, 2020, ARXIV200411726CS
   Sawyer-Lee R., 2016, Curated breast imaging subset of digital database for screening mammography (CBIS-DDSM)
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Sun LL, 2019, IEEE ACCESS, V7, P126273, DOI 10.1109/ACCESS.2019.2939167
   Sun WQ, 2017, COMPUT MED IMAG GRAP, V57, P4, DOI 10.1016/j.compmedimag.2016.07.004
   Suzuki S, 2016, 2016 55TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P1382, DOI 10.1109/SICE.2016.7749265
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
NR 32
TC 8
Z9 8
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19257
EP 19281
DI 10.1007/s11042-021-10505-y
EA FEB 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000620422600003
DA 2024-07-18
ER

PT J
AU Mousavi, S
   Charmi, M
   Hassanpoor, H
AF Mousavi, Shokoufeh
   Charmi, Mostafa
   Hassanpoor, Hossein
TI Recognition of identical twins based on the most distinctive region of
   the face: Human criteria and machine processing approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; Mismatched keypoints; Identical twins;
   Crowdsourcing; Modified SIFT; Face regions
ID FEATURES
AB Face recognition domain has been well advanced and has achieved high accuracies in identification of individuals in recent years. But in practice, distinguishing similar faces such as an identical twin still is a great challenge for face recognition systems. It happens due to very small differences in the facial features of them. Therefore, extracting common face features is not proper for differentiating identical twins. A solution to this problem is to find the most distinctive regions in the face of identical twins. In this paper, two procedures used to find these specific regions: 1) Machine Processing: A Modified SIFT (M-SIFT) algorithm has been implemented on Identical twins' face images. Each face image has been segmented into five regions contain eyes, eyebrows, nose, mouth, and face curve. The location and number of mismatched keypoints represented the most distinctive face region in the face of identical twins. 2) Crowdsourcing: We have recognized differences between identical twins faces from human criteria viewpoint by enlisting crowd intelligence. Several questionnaires were designed and completed by 120 participants. The dataset of this study collected by ourselves and include 650 images for 115 pairs of identical twins and 120 non-twin individuals. The results of Machine Processing and Crowdsourcing methods showed that the face curve is the most discriminant region among every five regions in most of identical twins. Several features proposed and extracted based on the keypoints of the M-SIFT algorithm and face landmarks. The experimental results demonstrated the lowest equal error rate of identical twins recognition as 7.8, 8.1 and 10.1% for using the whole images, only frontal images and only images with PAN motions, respectively.
C1 [Mousavi, Shokoufeh; Charmi, Mostafa] Univ Zanjan, Dept Elect Engn, Zanjan, Iran.
   [Hassanpoor, Hossein] Dade Pardazi Shenakht Mehvare Atynegar Inst, Dept Computat Neurosci, Tehran, Iran.
C3 University Zanjan
RP Charmi, M (corresponding author), Univ Zanjan, Dept Elect Engn, Zanjan, Iran.
EM sh.mousavi@alumni.znu.ac.ir; charmi.mostafa@znu.ac.ir;
   h.hassanpoor@aut.ac.ir
RI Charmi, Mostafa/I-8402-2018
OI Charmi, Mostafa/0000-0002-5166-1779
CR Abudarham N, 2019, COGNITION, V182, P73, DOI 10.1016/j.cognition.2018.09.002
   Afaneh A, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0231-0
   Ahmad B, 2019, IEEE GLOBE WORK, DOI 10.1109/gcwkshps45667.2019.9024704
   [Anonymous], 2011, Biometrics (IJCB), 2011 International Joint Conference on
   [Anonymous], 2011, 2011 19 IRANIAN C EL
   Biswas S., 2011, Proc. IEEE International Workshop on Information Forensics and Security (WIFS), P1, DOI DOI 10.1109/WIFS.2011.6123126
   Bowyer KevinW., 2016, 2016 IEEE 8th International Conference on Biometrics Theory, Applications and Systems (BTAS), P1, DOI [DOI 10.1109/BTAS.2016.7791176, 10.1109/BTAS.2016.7791176]
   Brabham D. C, 2008, Convergence, V14, P75, DOI DOI 10.1177/1354856507084420
   Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122
   Chen C., 2017, 2017 IEEE International Conference on Identity, Security and Behavior Analysis, P1
   Dal Martello MF, 2006, J VISION, V6, P1356, DOI 10.1167/6.12.2
   Devi HS, 2015, PROCEDIA COMPUT SCI, V54, P532, DOI 10.1016/j.procs.2015.06.061
   Eskandari M, 2015, COMPUT VIS IMAGE UND, V137, P63, DOI 10.1016/j.cviu.2015.02.011
   Fleenor JW, 2006, PERS PSYCHOL, V59, P982
   Hezil N, 2017, IET BIOMETRICS, V6, P351, DOI 10.1049/iet-bmt.2016.0072
   Jeff Howe., 2006, WIRED
   Juefei-Xu F, 2013, IEEE COMPUT SOC CONF, P56, DOI 10.1109/CVPRW.2013.16
   Kae A, 2013, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2013.263
   Kalyoncu C, 2016, IET COMPUT VIS, V10, P700, DOI 10.1049/iet-cvi.2015.0414
   Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63
   Klare B., 2011, 2011 INT JOINT C BIO, P1, DOI DOI 10.1109/IJCB.2011.6117548
   Klare Brendan., 2010, Fourth IEEE International Conference on Biometrics: Theory Applications and Systems (BTAS). IEEE, P1, DOI DOI 10.1109/BTAS.2010.5634533
   Le T. H. N., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P91, DOI 10.1109/BTAS.2012.6374562
   Le THN, 2015, PATTERN RECOGN, V48, P3843, DOI 10.1016/j.patcog.2015.05.021
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Mahalingam G, 2013, NAT CONF COMPUT VIS
   Paone JR, 2014, IEEE T INF FOREN SEC, V9, P285, DOI 10.1109/TIFS.2013.2296373
   Park U, 2010, IEEE T PATTERN ANAL, V32, P947, DOI 10.1109/TPAMI.2010.14
   Peng JL, 2014, OPTIK, V125, P6891, DOI 10.1016/j.ijleo.2014.07.027
   Phillips P. J., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P185, DOI 10.1109/FG.2011.5771395
   Priya BL, 2017, 2017 2ND WORLD CONGRESS ON COMPUTING AND COMMUNICATION TECHNOLOGIES (WCCCT), P30, DOI 10.1109/WCCCT.2016.17
   Pruitt M.T., 2011, IJCB, P1, DOI [DOI 10.1109/IJCB.2011.6117476, 10.1109/IJCB.2011.6117476]
   Segundo MP, 2010, IEEE T SYST MAN CY B, V40, P1319, DOI 10.1109/TSMCB.2009.2038233
   Srinivas N, 2012, IEEE T INF FOREN SEC, V7, P1536, DOI 10.1109/TIFS.2012.2206027
   Sun Xiaoxia, 2018, Deep Learning in Biometrics, P65
   Sun ZN, 2010, PROC SPIE, V7667, DOI 10.1117/12.851369
   Tharwat A, 2012, 2012 SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES'2012), P176, DOI 10.1109/ICCES.2012.6408507
   Uddin J, 2018, PROC INT C COMPUT CO, P1, DOI DOI 10.1109/IC4ME2.2018.8465615
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wu Y, 2019, INT J COMPUT VISION, V127, P115, DOI 10.1007/s11263-018-1097-z
   Xiao ST, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P986, DOI 10.1109/ICCVW.2015.130
   Young Ho Park, 2011, 2011 International Conference on Multimedia and Signal Processing (CMSP), P247, DOI 10.1109/CMSP.2011.57
NR 46
TC 4
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15765
EP 15802
DI 10.1007/s11042-020-10360-3
EA FEB 2021
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615564900012
DA 2024-07-18
ER

PT J
AU Mishra, R
   Tripathi, SP
AF Mishra, Richa
   Tripathi, Surya Prakash
TI Deep learning based search engine for biomedical images using
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Search engine; Biomedical images; Deep learning; Websites
AB The development of efficient search engine queries for biomedical images, especially in case of query-mismatch is still defined as an ill-posed problem. Vector-space model is found to be useful for handling the query-mismatch issue. However, vector-space model does not consider the relational details among the keywords and biomedical image search space is not evaluated. Therefore, in this paper, we have proposed a deep learning based fusion vector-space based model. The proposed model enhances the biomedical image query similarity matching approach by fusing the vector space model and convolutional neural networks. Deep learning model is defined by converting the vector-space model to a classification model. Finally, deep learning model is trained to implement the search engine for biomedical images. Extensive experiments reveal that the proposed model achieves significant improvement over the existing models.
C1 [Mishra, Richa; Tripathi, Surya Prakash] Inst Engn & Technol, Comp Sci & Engn Dept, Lucknow 226021, Uttar Pradesh, India.
   [Tripathi, Surya Prakash] RR Inst Modern Technol, Lucknow 226201, Uttar Pradesh, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Institute of
   Engineering & Technology Lucknow
RP Mishra, R (corresponding author), Inst Engn & Technol, Comp Sci & Engn Dept, Lucknow 226021, Uttar Pradesh, India.
EM mishraricha315@gmail.com; tripathee_sp@yahoo.co.in
RI y, usharani/O-6754-2016; Mishra, Richa/GXN-2568-2022
OI y, usharani/0000-0002-8905-0615; 
CR [Anonymous], 2008, INTRO INFORM RETRIEV
   Basavegowda HS, 2020, CAAI T INTELL TECHNO, V5, P22, DOI 10.1049/trit.2019.0028
   Bigelow JL, 2016, CYBERSAFETY 2016 WORKSHOP, P11, DOI 10.1145/3002137.3002144
   Cimiano P, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1513
   Doulani A, 2020, PAYAVARD-SALAMAT, V14, P53
   Fagroud FZ, 2019, P 4 INT C BIG DAT IN, P1
   Faroo, 2017, RECONSTRUCT REV, V7
   Furnas G. W., 2017, SIGIR FORUM, V51, P9, DOI DOI 10.1145/3130348.3130358
   Gao W, 2016, CLUSTER COMPUT, V19, P2201, DOI 10.1007/s10586-016-0651-0
   Ghosh S, 2020, CAAI T INTELL TECHNO, V5, P55, DOI 10.1049/trit.2019.0051
   Gupta A, 2020, J AMB INTEL HUM COMP, V11, P1309, DOI 10.1007/s12652-019-01493-x
   Gupta B, 2019, CAAI T INTELL TECHNO, V4, P73, DOI 10.1049/trit.2018.1006
   Hochberg I, 2019, ACTA DIABETOL, V56, P1149, DOI 10.1007/s00592-019-01350-5
   Kaur M, 2020, APPL PHYS B-LASERS O, V126, DOI 10.1007/s00340-020-07480-x
   Kaur M, 2020, IET IMAGE PROCESS, V14, P1015, DOI 10.1049/iet-ipr.2019.0587
   Kaur M, 2020, FUTURE GENER COMP SY, V107, P333, DOI 10.1016/j.future.2020.02.029
   Kaur M, 2020, INFORM SCIENCES, V521, P326, DOI 10.1016/j.ins.2020.02.048
   Kopanos C, 2019, BIOINFORMATICS, V35, P1978, DOI 10.1093/bioinformatics/bty897
   Lee DL, 1997, IEEE SOFTWARE, V14, P67, DOI 10.1109/52.582976
   Long Bradley A., 2017, Journal of Electronic Resources in Medical Libraries, V14, P101, DOI 10.1080/15424065.2017.1368425
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Osterland S, 2019, INT J HYDROMECHATRON, V2, P32
   Pinho E, 2017, J DIGIT IMAGING, V30, P39, DOI 10.1007/s10278-016-9903-z
   Ross NCM, 2000, J AM SOC INFORM SCI, V51, P949, DOI 10.1002/1097-4571(2000)51:10<949::AID-ASI70>3.0.CO;2-5
   Schutze H., 1995, SIGIR Forum, P229
   Singhal A., 2001, IEEE DATA ENG B, V24, P35
   Spink A, 2001, J AM SOC INF SCI TEC, V52, P226, DOI 10.1002/1097-4571(2000)9999:9999<::AID-ASI1591>3.0.CO;2-R
   Voorhees E. M., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P61
   Wang RZ, 2019, INT J HYDROMECHATRON, V2, P189
   Wiens T, 2019, INT J HYDROMECHATRON, V2, P16
   Xing Wei, 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P178
   Ye Ziyi, 2020, Proc Assoc Inf Sci Technol, V57, pe424, DOI 10.1002/pra2.424
   Young SD, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199527
   Zobel J, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1132956.1132959
NR 34
TC 5
Z9 5
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15057
EP 15065
DI 10.1007/s11042-020-10391-w
EA FEB 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613628000010
PM 33551666
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Mohsin, AH
   Zaidan, AA
   Zaidan, BB
   Mohammed, KI
   Albahri, OS
   Albahri, AS
   Alsalem, MA
AF Mohsin, A. H.
   Zaidan, A. A.
   Zaidan, B. B.
   Mohammed, K. I.
   Albahri, O. S.
   Albahri, A. S.
   Alsalem, M. A.
TI PSO-Blockchain-based image steganography: towards a new method to secure
   updating and sharing COVID-19 data in decentralised hospitals
   intelligence architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Medical data; Steganography; Blockchain; Particle swarm
   optimisation; Integrity; Availability; High capacity; Spatial domain
AB Secure updating and sharing for large amounts of healthcare information (such as medical data on coronavirus disease 2019 [COVID-19]) in efficient and secure transmission are important but challenging in communication channels amongst hospitals. In particular, in addressing the above challenges, two issues are faced, namely, those related to confidentiality and integrity of their health data and to network failure that may cause concerns about data availability. To the authors' knowledge, no study provides secure updating and sharing solution for large amounts of healthcare information in communication channels amongst hospitals. Therefore, this study proposes and discusses a novel steganography-based blockchain method in the spatial domain as a solution. The novelty of the proposed method is the removal and addition of new particles in the particle swarm optimisation (PSO) algorithm. In addition, hash function can hide secret medical COVID-19 data in hospital databases whilst providing confidentiality with high embedding capacity and high image quality. Moreover, stego images with hash data and blockchain technology are used in updating and sharing medical COVID-19 data between hospitals in the network to improve the level of confidentiality and protect the integrity of medical COVID-19 data in grey-scale images, achieve data availability if any connection failure occurs in a single point of the network and eliminate the central point (third party) in the network during transmission. The proposed method is discussed in three stages. Firstly, the pre-hiding stage estimates the embedding capacity of each host image. Secondly, the secret COVID-19 data hiding stage uses PSO algorithm and hash function. Thirdly, the transmission stage transfers the stego images based on blockchain technology and updates all nodes (hospitals) in the network. As proof of concept for the case study, the authors adopted the latest COVID-19 research published in the Computer Methods and Programs in Biomedicine journal, which presents a rescue framework within hospitals for the storage and transfusion of the best convalescent plasma to the most critical patients with COVID-19 on the basis of biological requirements. The validation and evaluation of the proposed method are discussed.
C1 [Mohsin, A. H.; Zaidan, A. A.; Zaidan, B. B.; Mohammed, K. I.; Albahri, O. S.; Albahri, A. S.; Alsalem, M. A.] Univ Pendidikan Sultan Idris, Dept Comp, Tanjong Malim, Perak, Malaysia.
   [Mohsin, A. H.] Republ Iraq Presidency Minist Estab Martyrs, Baghdad, Iraq.
   [Albahri, A. S.] Iraqi Commiss Comp & Informat ICCI, Informat Inst Postgrad Studies IIPS, Baghdad, Iraq.
C3 Universiti Pendidikan Sultan Idris
RP Zaidan, AA (corresponding author), Univ Pendidikan Sultan Idris, Dept Comp, Tanjong Malim, Perak, Malaysia.
EM ali_hadi182@yahoo.com; aws.alaa@fskik.upsi.edu.my;
   bilalbahaa@fskik.upsi.edu.my; khalid_ib1@fskik.upsi.edu.my;
   osamah@fskik.upsi.edu.my; ahmed.bahri1978@gmail.com;
   mohammed.asum@gmail.com
RI Albahri, A.S./E-7428-2018; Albahrey, Osamah Shihab/D-5150-2018;
   Albahri,, A. S./F-7289-2010; zaidan, bilal/AAJ-7841-2021; Mohammed,
   Khalid Ibrahim/AAC-8428-2020
OI Albahri, A.S./0000-0003-3335-457X; Albahrey, Osamah
   Shihab/0000-0002-7844-3990; Mohammed, Khalid
   Ibrahim/0000-0001-7214-5258; zaidan, bilal/0000-0001-7412-8267
CR Abdulkareem KH, 2020, INT J INF TECH DECIS, V19, P909, DOI 10.1142/S0219622020500169
   Abdulkareem KH, 2021, NEURAL COMPUT APPL, V33, P1029, DOI 10.1007/s00521-020-05020-4
   Abdulnabi M, 2017, J BIOMED INFORM, V69, P230, DOI 10.1016/j.jbi.2017.04.013
   Ahmed Mohamed A., 2010, Journal of Applied Sciences, V10, P59, DOI 10.3923/jas.2010.59.64
   Al-Frajat A. K., 2010, Journal of Applied Sciences, V10, P1644, DOI 10.3923/jas.2010.1644.1649
   AL-Nabhani Y, 2010, INT CONF COMP SCI, P9, DOI 10.1109/ICCSIT.2010.5564461
   Alaa M, 2019, IEEE ACCESS, V7, P126201, DOI 10.1109/ACCESS.2019.2936898
   Alam GM, 2010, SCI RES ESSAYS, V5, P3254
   Alanazi Hamdan O., 2010, International Journal of Computer and Network Security, V2, P46
   Alanazi HO, 2010, INT J PHARMACOL, V6, P954
   Albahri AS, 2021, J NETW COMPUT APPL, V173, DOI 10.1016/j.jnca.2020.102873
   Albahri AS, 2020, INT J INF TECH DECIS, V19, P1247, DOI 10.1142/S0219622020500285
   Albahri AS, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01582-x
   Albahri AS, 2019, IEEE ACCESS, V7, P37269, DOI 10.1109/ACCESS.2019.2898214
   Albahri AS, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0983-9
   Albahri OS, 2020, J INFECT PUBLIC HEAL, V13, P1381, DOI 10.1016/j.jiph.2020.06.028
   Albahri OS, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105617
   Albahri OS, 2019, IEEE ACCESS, V7, P50052, DOI 10.1109/ACCESS.2019.2910411
   Albahri OS, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1006-6
   Albahri OS, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0943-4
   Ali AH, 2018, MULTIMED TOOLS APPL, V77, P31487, DOI 10.1007/s11042-018-6213-0
   Almahdi EM, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1339-9
   Almahdi EM, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1336-z
   Alsalem MA, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1338-x
   Alsalem MA, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1064-9
   Alsattar HA, 2020, ARTIF INTELL REV, V53, P2237, DOI 10.1007/s10462-019-09732-5
   [Anonymous], 2010, ARXIV PREPRINT ARXIV
   [Anonymous], 2010, ARXIV PREPRINT ARXIV
   [Anonymous], 2009, CITESEER
   [Anonymous], 2009, INT J COMPUTER NETWO
   [Anonymous], 2010, ARXIV PREPRINT ARXIV
   [Anonymous], 2009, INT J COMPUT SCI INF
   [Anonymous], 2009, INT J COMPUTER SCI I
   [Anonymous], 2008, ENHANCEMENT AMOUNT H
   [Anonymous], 2009, ICFCC09
   Aos AZ, 2009, IACSIT-SC 2009: INTERNATIONAL ASSOCIATION OF COMPUTER SCIENCE AND INFORMATION TECHNOLOGY - SPRING CONFERENCE, P437, DOI 10.1109/IACSIT-SC.2009.103
   Bai Y, 2020, JAMA-J AM MED ASSOC, V323, P1406, DOI 10.1001/jama.2020.2565
   Basuki AI, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P41, DOI [10.1109/ic3ina48034.2019.8949606, 10.1109/IC3INA48034.2019.8949606]
   Bonino D, 2010, WORLD PAT INF, V32, P30, DOI 10.1016/j.wpi.2009.05.008
   Caplan Robin M, 2003, Dent Assist, V72, P6
   Chang MC, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01577-8
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Elshoura SM, 2013, SIGNAL PROCESS-IMAGE, V28, P531, DOI 10.1016/j.image.2012.12.005
   Eltahir ME, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P550, DOI 10.1109/ICIME.2009.13
   Enaizan O, 2020, HEALTH TECHNOL-GER, V10, P795, DOI 10.1007/s12553-018-0278-7
   Hmood Ali K., 2010, Journal of Applied Sciences, V10, P2094, DOI 10.3923/jas.2010.2094.2100
   Hmood Ali K., 2010, Journal of Applied Sciences, V10, P1825, DOI 10.3923/jas.2010.1825.1833
   Hmood AK, 2010, INT J PHYS SCI, V5, P1054
   Hussain M, 2018, TELEMAT INFORM, V35, P1335, DOI 10.1016/j.tele.2018.03.005
   Hussain M, 2018, COMPUT SECUR, V75, P191, DOI 10.1016/j.cose.2018.02.003
   Hussien HM, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1445-8
   Ibrahim NK, 2019, IEEE ACCESS, V7, P146620, DOI 10.1109/ACCESS.2019.2941640
   Iqbal S, 2019, HEALTH TECHNOL-GER, V9, P93, DOI 10.1007/s12553-018-0252-4
   Jalab H., 2009, Journal of Computing, V1, P108
   Jalab HA, 2010, NEW DESIGN INFORM HI, V2
   Kalid N, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0916-7
   Kalid N, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0883-4
   Khalifa O.-O., 2010, International Journal of Computer Science and Network Security (IJCSNS), V9, P294
   Khatari M, 2019, INT J INF TECH DECIS, V18, P1187, DOI 10.1142/S0219622019300039
   Kiah M. M., 2011, International Journal of Physicial Sciences, V6, P3837
   Liang XP, 2018, LECT NOTES COMPUT SC, V10631, P387, DOI 10.1007/978-3-319-89500-0_34
   Malik A, 2017, ENG SCI TECHNOL, V20, P72, DOI 10.1016/j.jestch.2016.06.005
   Mashamba-Thompson TP, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10040198
   Mat Kiah M L, 2014, J Med Syst, V38, P133, DOI 10.1007/s10916-014-0133-y
   Mohammed, 2019, COMPUT METHODS PROG
   Mohammed KI, 2020, IEEE ACCESS, V8, P91521, DOI 10.1109/ACCESS.2020.2994746
   Mohammed KI, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1362-x
   Mohsin AH, 2020, IEEE ACCESS, V8, P9821, DOI 10.1109/ACCESS.2020.2964788
   Mohsin AH, 2019, IEEE ACCESS, V7, P168994, DOI 10.1109/ACCESS.2019.2949622
   Mohsin AH, 2019, COMPUT STAND INTER, V66, DOI 10.1016/j.csi.2019.04.002
   Mohsin AH, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1264-y
   Mohsin AH, 2019, COMPUT STAND INTER, V64, P41, DOI 10.1016/j.csi.2018.12.002
   Mohsin AH, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1103-6
   Mohsin AH, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1104-5
   Murthy S, 2020, JAMA-J AM MED ASSOC, V323, P1499, DOI 10.1001/jama.2020.3633
   Muthamilselvan S, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON COMMUNICATION AND ELECTRONICS SYSTEMS (ICCES 2018), P989, DOI 10.1109/CESYS.2018.8724054
   Nabi MSA, 2010, INT J PHARMACOL, V6, P959
   Naji AW, 2009, INT J COMPUT SCI NET, V9, P218
   Naji A. W., 2009, Journal of Computer Sciences, V5, P890, DOI 10.3844/jcssp.2009.890.897
   Naji AW, 2009, IACSIT-SC 2009: INTERNATIONAL ASSOCIATION OF COMPUTER SCIENCE AND INFORMATION TECHNOLOGY - SPRING CONFERENCE, P405, DOI 10.1109/IACSIT-SC.2009.105
   Naji AW, 2009, IACSIT-SC 2009: INTERNATIONAL ASSOCIATION OF COMPUTER SCIENCE AND INFORMATION TECHNOLOGY - SPRING CONFERENCE, P410, DOI 10.1109/IACSIT-SC.2009.104
   Naji A. W., 2009, World Academy of Science Engineering and Technology, V56, P493
   Napi NM, 2019, HEALTH TECHNOL-GER, V9, P679, DOI 10.1007/s12553-019-00357-w
   Othman F, 2009, INTERNATIONAL CONFERENCE ON FUTURE COMPUTER AND COMMUNICATIONS, PROCEEDINGS, P477, DOI 10.1109/ICFCC.2009.154
   Partala J, 2018, CRYPTOGRAPHY-BASEL, V2, DOI 10.3390/cryptography2030018
   Ranney ML, 2020, NEW ENGL J MED, V382, DOI 10.1056/NEJMp2006141
   Richardson Safiya, 2020, JAMA, Journal of the American Medical Association, V323, P2052, DOI 10.1001/jama.2020.6775
   Salman OH, 2017, INT J INF TECH DECIS, V16, P1211, DOI 10.1142/S0219622017500225
   Shuwandy ML, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1149-5
   Talal M, 2019, TELECOMMUN SYST, V72, P285, DOI 10.1007/s11235-019-00575-7
   Talal M, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1158-z
   Tang MW, 2015, OPTIK, V126, P4136, DOI 10.1016/j.ijleo.2015.07.200
   Taqa A., 2009, International Journal of Computer and Electrical Engineering, V5, P566
   Tariq I, 2020, NEURAL COMPUT APPL, V32, P3101, DOI 10.1007/s00521-018-3808-3
   Wang CJ, 2020, JAMA-J AM MED ASSOC, V323, P1341, DOI 10.1001/jama.2020.3151
   Wang Jiaxin, 2019, JIHPP, V2019, DOI 10.32604/jihpp.2019.07189
   Wu ZD, 2018, INFORM SCIENCES, V433, P431, DOI 10.1016/j.ins.2016.12.048
   Zaidan A., 2010, International Journal of Computer Theory and Engineering, P218
   Zaidan AA, 2020, INT J INF TECH DECIS, V19, P775, DOI 10.1142/S0219622020500121
   Zaidan AA, 2020, NEURAL COMPUT APPL, V32, P8315, DOI 10.1007/s00521-019-04325-3
   Zaidan AA, 2019, NEURAL COMPUT APPL, V31, P1823, DOI 10.1007/s00521-017-3159-5
   Zaidan AA, 2018, HEALTH TECHNOL-GER, V8, P223, DOI 10.1007/s12553-018-0223-9
   Zaidan AA, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0201-y
   Zaidan AA, 2010, INT J PHYS SCI, V5, P1776
   Zaidan AA, 2010, SCI RES ESSAYS, V5, P1965
   Zaidan A. A., 2010, Journal of Applied Sciences, V10, P1916, DOI 10.3923/jas.2010.1916.1922
   Zaidan AA, 2009, LECT NOTES ENG COMP, P259
   Zaidan A. A., 2009, International Journal of Engineering Technology, V1, P63
   Zaidan A. A., 2009, International Journal of Computer and Electrical Engineering, V5, P642
   Zaidan A. A., 2009, World Academy of Science Engineering and Technology, V54, P468
   Zaidan BB, 2024, INT J INF TECH DECIS, V23, P1017, DOI 10.1142/S0219622017500183
   Zaidan BB, 2018, MEASUREMENT, V117, P277, DOI 10.1016/j.measurement.2017.12.019
   Zaidan BB, 2017, SOFTWARE PRACT EXPER, V47, P1365, DOI 10.1002/spe.2465
   Zaidan BB, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S021812661750116X
   Zaidan BB, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0235-1
   Zaidan BB, 2010, INT J PHYS SCI, V5, P1796
   Zaidan B. B., 2010, Journal of Applied Sciences, V10, P1650, DOI 10.3923/jas.2010.1650.1655
   Zaidan B. B., 2009, Proceedings of the 2009 International Conference on Image Processing, Computer Vision, & Pattern Recognition. IPCV 2009, P343
   Zhao HG, 2018, LECT NOTES COMPUT SC, V11373, P99, DOI 10.1007/978-3-030-05764-0_11
   Zughoul O, 2018, IEEE ACCESS, V6, P73245, DOI 10.1109/ACCESS.2018.2881282
NR 120
TC 25
Z9 25
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14137
EP 14161
DI 10.1007/s11042-020-10284-y
EA JAN 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000610019400018
PM 33519293
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Barello, P
   Hossain, MS
AF Barello, Philip
   Hossain, Md Shafaeat
TI Multimodal person detection system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person detection; Multisensor data acquisition; Multimodal fusion;
   Distributed sensory decision systems
ID TRACKING
AB Person detection is often critical for personal safety, property protection, and national security. Most person detection technologies implement unimodal classification, making predictions based on a single sensor data modality, which is most often vision. There are many ways to defeat unimodal person detectors, and many more reasons to ensure technologies responsible for detecting the presence of a person are accurate and precise. In this paper, we design and implement a multimodal person detection system which can acquire data from multiple sensors and detect persons based on a variety of unimodal classifications and multimodal fusions. We present two methods of generating system-level predictions: (1) device perspectives which makes a final decision based on multiple device-level predictions and (2) system perspectives which combines data samples from multiple devices into a single data sample and then makes a decision. Our experimental results show that system-level predictions from system perspectives are generally more accurate than system-level predictions from device perspectives. We achieve an accuracy of 100%, zero false positive rate and zero false negative rate with fusion of system perspectives motion and distance data.
C1 [Barello, Philip; Hossain, Md Shafaeat] Southern Connecticut State Univ, Dept Comp Sci, New Haven, CT 06515 USA.
C3 Connecticut State University System; Southern Connecticut State
   University
RP Hossain, MS (corresponding author), Southern Connecticut State Univ, Dept Comp Sci, New Haven, CT 06515 USA.
EM barellop1@southernct.edu; hossainm3@southernct.edu
CR Ahmedali T, 2006, P 3 CAN C COMP ROB V
   [Anonymous], 2007, IEEE C COMP VIS PATT
   Bellotto N, 2009, IEEE T SYST MAN CY B, V39, P167, DOI 10.1109/TSMCB.2008.2004050
   Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47
   Boran T, 2020, COMPUT SECUR, V97, DOI 10.1016/j.cose.2020.101943
   Briggs F, 2012, J ACOUST SOC AM, V131, P4640, DOI 10.1121/1.4707424
   Chandrakala, 2014, INT J ENG TECHNOL
   Chen Y, 2016, MULTIISCALE CONVOLUT
   Cho H, 2014, IEEE INT CONF ROBOT, P1836, DOI 10.1109/ICRA.2014.6907100
   Ciesielski, 2012, AI 2012 ADV ARTIFICI
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Frossard D, 2018, IEEE INT CONF ROBOT, P635, DOI 10.1109/ICRA.2018.8462884
   Giannakopoulos T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144610
   Glaser JI, 2016, FRONT COMPUT NEUROSC, V10, DOI [10.3389/fncern.2010.00011, 10.3389/fncom.2016.00011]
   Howard A, 2007, P 13 INT S ROB RES, P1
   Hsiao, 2011, IEEE VEH TECHN SOC A
   Ivanovs A, 2019, 2019 THIRD IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2019), P254, DOI 10.1109/IRC.2019.00047
   Kahng SJ, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010017
   Kiani H, 2014, IEEE IMAGE PROC, P1485, DOI 10.1109/ICIP.2014.7025297
   Kim B, 2020, SOFT COMPUT, V24, P17081, DOI 10.1007/s00500-020-04999-1
   Knill D.C., 2007, Bayesian brain: Probabilistic approaches to neural coding, P189, DOI DOI 10.7551/MITPRESS/9780262042383.003.0009
   Mangai UG, 2010, IETE TECH REV, V27, P293, DOI 10.4103/0256-4602.64604
   Mateus A, 2019, ROBOT AUTON SYST, V113, P23, DOI 10.1016/j.robot.2018.12.007
   Metze F., 2016, P 2016 ACM INT C MUL
   Nair, 2015, IEEE INT C EV AD INT
   Papert, 1966, ARTIF INTELL, P1
   PETERSON WW, 1954, IRE T INFORM THEOR, P171, DOI 10.1109/TIT.1954.1057460
   Ramakrishnan Anusha, 2016, CORRABS160700148
   Ray S, 2004, IEEE J SEL AREA COMM, V22, P1016, DOI 10.1109/JSAC.2004.830895
   Roberts, 1963, MACHINE PERCEPTION 3, P1
   Töreyin BU, 2006, 2006 IEEE 14TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS, VOLS 1 AND 2, P505
   Toreyin BU, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/149304
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Yang B., 2014, IEEE INT JOINT C BIO, P1
   Yang LL, 2012, COMPUT ELECTRON AGR, V89, P116, DOI 10.1016/j.compag.2012.08.011
   Yang MT, 2014, SENSORS-BASEL, V14, P14253, DOI 10.3390/s140814253
NR 37
TC 1
Z9 1
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13389
EP 13406
DI 10.1007/s11042-020-10307-8
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607503800001
DA 2024-07-18
ER

PT J
AU Moral, C
   de Antonio, A
   Ferre, X
   Ramirez, J
AF Moral, Cristian
   de Antonio, Angelica
   Ferre, Xavier
   Ramirez, Jaime
TI A proposed UML-based common model for information visualization systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data visualization; Human computer interaction; Information
   visualization modelling; User interfaces
ID DESIGN SPACE; SEEKING; SCIENCE
AB Nowadays, visualization of large amounts of data has become a key issue for processing data in many fields. This paper presents a conceptual model for describing information visualization systems. This conceptual model has been represented using the Unified Modeling Language, therefore it takes advantage of the understandability, unambiguity, flexibility, and adaptability provided by this notation. The proposed model outlines concepts such as visualization workspace, device, visual representation and its features, information visualization task and its effects on visualization, inter-item relationship, etc. The main applications of the proposed model are: (1) to guide the development of a new visualization system by specifying which are the main concepts that have to be considered and how they relate to each other; (2) to characterize or describe an already existing visualization system; and (3) to thoroughly compare existing visualization systems. To illustrate the use and applications of the model, several examples of information visualization systems are provided.
C1 [Moral, Cristian; de Antonio, Angelica; Ferre, Xavier; Ramirez, Jaime] Univ Politecn Madrid, ETS Ingn Informat, Madrid, Spain.
C3 University of Sevilla; Universidad Politecnica de Madrid
RP Moral, C (corresponding author), Univ Politecn Madrid, ETS Ingn Informat, Madrid, Spain.
EM cmoral@fi.upm.es; angelica@fi.upm.es; xavier.ferre@upm.es;
   jramirez@fi.upm.es
RI Moral, Cristian/AAJ-6825-2021; Ramírez, Jaime/AAY-6253-2021; FERRE,
   XAVIER/L-9925-2014
OI Moral, Cristian/0000-0002-8429-8822; Ramírez, Jaime/0000-0003-4006-698X;
   FERRE, XAVIER/0000-0003-3474-9784
CR Aaltonen A, 2005, PERS UBIQUIT COMPUT, V9, P381, DOI 10.1007/s00779-005-0349-4
   Agus M, 2009, VISUAL COMPUT, V25, P883, DOI 10.1007/s00371-009-0311-y
   AHLBERG C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P313, DOI 10.1145/191666.191775
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Amar R, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P143, DOI 10.1109/INFVIS.2004.10
   ANDERSON EDGAR, 1936, ANN MISSOURI BOT GARD, V23, P457, DOI 10.2307/2394164
   [Anonymous], 2009, DESIGNING USER INTER
   [Anonymous], 1981, Graphics and Graphic Information-Processing
   [Anonymous], 2015, Interaction design: Beyond human-computer interaction
   [Anonymous], 2005, Proceedings of the SIGCHI conference on Human factors in computing systems
   [Anonymous], 1996, ACM Transactions, DOI DOI 10.1145/230562.230563
   [Anonymous], 2014, Proceedings of the Fifth Workshop on Beyond Time and Errors: Novel Evaluation Methods for Visualization, DOI [DOI 10.1145/2669557.2669579, 10.1145/2669557.26695792,9, DOI 10.1145/2669557.26695792,9]
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   BENFORD S, 1995, COMPUT GRAPH FORUM, V14, pC349, DOI 10.1111/j.1467-8659.1995.cgf143_0349.x
   Benford S, 1995, INTERFACES DATABASE, P168, DOI 10.1007/978-1-4471-3818-1_9
   Blach R, 2007, LECT NOTES COMPUT SC, V4555, P750
   Bostock M., 2020, DATA DRIVEN DOCUMENT
   Bouali F, 2016, VISUAL COMPUT, V32, P1447, DOI 10.1007/s00371-015-1132-9
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Bugajska M, 2005, Ninth International Conference on Information Visualisation, Proceedings, P713, DOI 10.1109/IV.2005.51
   Bugajska M, 2003, THESIS
   Card S. K., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P181, DOI 10.1145/108844.108874
   Card S K., 1999, READINGS INFORM VISU
   Card SK, 1997, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P92, DOI 10.1109/INFVIS.1997.636792
   Carr D.A., 1999, Proceedings of ECUE, V99, P1
   Chi EH, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P69, DOI 10.1109/INFVIS.2000.885092
   Craig P, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P2236, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.330
   Davies J, 2014, COUNTRIES ANTARCTICA
   de Antonio Angelica, 2013, Information Services & Use, V33, P139, DOI 10.3233/ISU-130698
   De Antonio A, 2013, P 17 INT C EL, P13, DOI [10.3233/978-1-61499-270-7-13, DOI 10.3233/978-1-61499-270-7-13]
   De Antonio A, 2012, GESTURE BASED INTERA
   Einsfeld K, 2006, INFORMATION VISUALIZATION-BOOK, P569
   FAIRCHILD KM, 1988, COGNITIVE SCI ITS AP, P201
   Fernandez R, 2018, RECENT TRENDS COMPUT, P279, DOI [10.1007/978-3-319-89914-5_17, DOI 10.1007/978-3-319-89914-5_17]
   Google Inc, 2020, GOOGL SCHOL
   Irshad S, 2019, 17TH INTERNATIONAL CONFERENCE ON ADVANCES IN MOBILE COMPUTING & MULTIMEDIA (MOMM2019), P200, DOI 10.1145/3365921.3365939
   Jaeschke G, 2005, LECT NOTES COMPUT SC, V3426, P119
   Järvelin K, 2003, INFORM RES, V9
   Joblove G.H., 1978, P 5 ANN C COMP GRAPH, VVolume 12, P20, DOI DOI 10.1145/965139.807362
   Kirste T, 1996, COMPUT GRAPH, V20, P669, DOI 10.1016/S0097-8493(96)00041-6
   Liu SX, 2014, VISUAL COMPUT, V30, P1373, DOI 10.1007/s00371-013-0892-3
   Liu ZC, 2010, IEEE T VIS COMPUT GR, V16, P999, DOI 10.1109/TVCG.2010.177
   Lu M, 2017, J VISUAL-JAPAN, V20, P667, DOI 10.1007/s12650-017-0431-9
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   MacEachren AM, 1995, MAPS WORK REPRESENTA, V3
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mackinlay J., 1991, P SIGCHI C HUMAN FAC, P173, DOI DOI 10.1145/108844.108870
   Mazza R., 2009, INTRO INFORM VISUALI
   McNabb L, 2017, COMPUT GRAPH FORUM, V36, P589, DOI 10.1111/cgf.13212
   Mei HH, 2018, VIS INFORM, V2, P71, DOI 10.1016/j.visinf.2018.04008
   Mei HH, 2018, J VISUAL LANG COMPUT, V44, P120, DOI 10.1016/j.jvlc.2017.10.001
   Meyer M, 2015, INFORM VISUAL, V14, P234, DOI 10.1177/1473871613510429
   Momma K, 2008, J APPL CRYSTALLOGR, V41, P653, DOI 10.1107/S0021889808012016
   Moral C, 2016, THESIS
   Moral C, 2015, INFORM RES, V20, P699
   Moral C, 2017, INFORM PROCESS MANAG, V53, P963, DOI 10.1016/j.ipm.2016.10.005
   Morgan R, 2018, LECT NOTES COMPUT SC, V10816, P440, DOI 10.1007/978-3-319-91563-0_27
   Munzner T., 2014, Visualization analysis and design: principles, techniques, and practice
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Nowell L, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P43, DOI 10.1109/INFVIS.2002.1173146
   Object Management Group, 2017, UN MOD LANG
   Oliveira EC, 2017, UNIVERSAL ACCESS INF, V16, P903, DOI 10.1007/s10209-016-0477-9
   Perez C, 2004, IEEE INFOR VIS, P317, DOI 10.1109/IV.2004.1320163
   Perez C, 2003, WORKSH KNOWL INF VIS, P103
   Pike WA, 2009, INFORM VISUAL, V8, P263, DOI 10.1057/ivs.2009.22
   Rekimoto Jun., 1993, Proceedings of the Third Annual Workshop on Information Technologies Systems (WITSa?AZ'93), P125
   Ren L, 2010, J VISUAL LANG COMPUT, V21, P209, DOI 10.1016/j.jvlc.2010.05.003
   Richter H, 2000, PROCEEDINGS OF THE 2000 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P394, DOI 10.1109/WSC.2000.899744
   Risch SS, 1997, IEEE INFOR VIS, P42, DOI 10.1109/IV.1997.626486
   Robertson G. G., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P189, DOI 10.1145/108844.108883
   Roth RE, 2013, IEEE T VIS COMPUT GR, V19, P2356, DOI 10.1109/TVCG.2013.130
   Satyanarayan A., 2014, Symposium on User Interface Software and Technology, P669, DOI DOI 10.1145/2642918.2647360
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Schulz HJ, 2013, IEEE T VIS COMPUT GR, V19, P2366, DOI 10.1109/TVCG.2013.120
   Semiu AA, 2013, PROC INT CONF COMP, P247
   Shneiderman B., 2000, ACM 2000. Digital Libraries. Proceedings of the Fifth ACM Conference on Digital Libraries, P57, DOI 10.1145/336597.336637
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Siirtola H, 2010, P 1 ITN WORKSH INT V, P33, DOI [10.1145/2002353.2002365, DOI 10.1145/2002353.2002365]
   Spoerri A., 1993, CIKM 93. Proceedings of the Second International Conference on Information and Knowledge Management, P11, DOI 10.1145/170088.170095
   Sprenger T. C., 1997, Visualization in Scientific Computing'97. Proceedings of the Eurographics Workshop, P71
   STEVENS P, 2006, USING UML SOFTWARE E
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Sugibuchi T, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P18, DOI 10.1109/IV.2009.56
   van Wijk JJ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P79
   Wang XM, 2016, J COMPUT SCI TECH-CH, V31, P787, DOI 10.1007/s11390-016-1663-1
   Ware Colin, 2020, INFORM VISUALIZATION
   Wilkinson L, 2005, The Grammar of Graphics, V2nd
   Wiss U, 1998, IEEE INFOR VIS, P137, DOI 10.1109/IV.1998.694211
   Wu JX, 2010, INT CONF COMPUT AUTO, P734, DOI 10.1109/ICCAE.2010.5451266
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zhang J, 2005, INFORM PROCESS MANAG, V41, P1003, DOI 10.1016/j.ipm.2004.03.005
   Zhang J, 2001, INFORM PROCESS MANAG, V37, P639, DOI 10.1016/S0306-4573(00)00042-X
   Zhou MX, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P23, DOI 10.1109/INFVIS.2002.1173143
NR 93
TC 3
Z9 3
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12541
EP 12579
DI 10.1007/s11042-020-10306-9
EA JAN 2021
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607369100010
DA 2024-07-18
ER

PT J
AU Taimori, A
   Razzazi, F
   Behrad, A
   Ahmadi, A
   Babaie-Zadeh, M
AF Taimori, Ali
   Razzazi, Farbod
   Behrad, Alireza
   Ahmadi, Ali
   Babaie-Zadeh, Massoud
TI A part-level learning strategy for JPEG image recompression detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Double JPEG compression; Information visualization; Middle-out process;
   Part-based detection; Quality level; Sparse coding
ID COMPRESSION
AB Recompression is a prevalent form of multimedia content manipulation. Different approaches have been developed to detect this kind of alteration for digital images of well-known JPEG format. However, they are either limited in performance or complex. These problems may arise from different quality level options of JPEG compression standard and their combinations after recompression. Inspired from semantic and perceptual analyses, in this paper, we suggest a part-level middle-out learning strategy to detect double compression via an architecturally efficient classifier. We first demonstrate that singly and doubly compressed data with different JPEG coder settings lie in a feature space representation as a limited number of coherent clusters, called parts. To show this, we visualize behavior of a set of prominent Benford-based features. Then, by leveraging such discovered knowledge, we model the issue of double JPEG compression detection in the family of feature engineering-based approaches as a part-level classification problem to cover all possible JPEG quality level combinations. The proposed strategy exhibits low complexity and yet comparable performance in comparison to related methods in that family. For reproducibility, our codes are available upon request to fellows.
C1 [Taimori, Ali; Razzazi, Farbod] Islamic Azad Univ, Sci & Res Branch, Dept Elect & Comp Engn, Tehran 1477893855, Iran.
   [Behrad, Alireza] Shahed Univ, Fac Engn, Tehran 1865133191, Iran.
   [Ahmadi, Ali] KN Toosi Univ Technol, Dept Elect & Comp Engn, Tehran 1431714191, Iran.
   [Babaie-Zadeh, Massoud] Sharif Univ Technol, Dept Elect Engn, Tehran 1458889694, Iran.
C3 Islamic Azad University; Shahed University; K. N. Toosi University of
   Technology; Sharif University of Technology
RP Taimori, A (corresponding author), Islamic Azad Univ, Sci & Res Branch, Dept Elect & Comp Engn, Tehran 1477893855, Iran.
EM alitaimori@yahoo.com; razzazi@srbiau.ac.ir; behrad@shahed.ac.ir;
   ahmadi@eetd.kntu.ac.ir; mbzadeh@sharif.edu
RI ahmadi, ali/JMC-5690-2023; Behrad, Alireza/F-8795-2018; Razzazi,
   Farbod/AAO-8522-2021
OI Razzazi, Farbod/0000-0003-4970-8117; Taimori, Ali/0000-0001-9550-7434
CR Alipour N, 2020, MULTIMED TOOLS APPL, V79, P8249, DOI 10.1007/s11042-019-08597-8
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cheng H, 2013, SIGNAL PROCESS, V93, P1408, DOI 10.1016/j.sigpro.2012.09.011
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fridrich J, 2009, IEEE SIGNAL PROC MAG, V26, P26, DOI 10.1109/MSP.2008.931078
   Galvan F, 2014, IEEE T INF FOREN SEC, V9, P1299, DOI 10.1109/TIFS.2014.2330312
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Huang XS, 2018, IEEE IMAGE PROC, P3813, DOI 10.1109/ICIP.2018.8451569
   Li B, 2019, MULTIMED TOOLS APPL, V78, P8577, DOI 10.1007/s11042-018-7073-3
   Lisha Dong, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P234, DOI 10.1109/ICIG.2011.100
   Liu J., 2011, SLEP SPARSE LEARNING
   Liu QZ, 2011, LECT NOTES COMPUT SC, V6676, P466, DOI 10.1007/978-3-642-21090-7_55
   Liu QZ, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899420
   Luka J, 2003, DFRWS
   Milani S, 2014, APSIPA T SIGNAL INF, V3
   Olmos A, 2004, PERCEPTION, V33, P1463, DOI 10.1068/p5321
   Piva A., 2013, ISRN SIGNAL PROCESS, V2013, DOI [10.1155/2013/496701, DOI 10.1155/2013/496701]
   Popescu AC, 2004, LECT NOTES COMPUT SC, V3200, P128
   Richtsfeld A, 2014, J VIS COMMUN IMAGE R, V25, P64, DOI 10.1016/j.jvcir.2013.04.006
   Taimori A, 2017, MULTIMED TOOLS APPL, V76, P7749, DOI 10.1007/s11042-016-3409-z
   Taimori A, 2016, J MATH IMAGING VIS, V54, P269, DOI 10.1007/s10851-015-0602-z
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang JY, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P433
   Yang JQ, 2014, IEEE T INF FOREN SEC, V9, P1933, DOI 10.1109/TIFS.2014.2359368
   Zhang CJ, 2014, NEUROCOMPUTING, V142, P248, DOI 10.1016/j.neucom.2014.03.059
NR 27
TC 1
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12235
EP 12247
DI 10.1007/s11042-020-10200-4
EA JAN 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000606409000004
DA 2024-07-18
ER

PT J
AU Anu, S
   Muthukkumaran, K
   Punniyamoorthy, M
   Veerapandian, SA
   Sangeetha, G
AF Anu, S.
   Muthukkumaran, K.
   Punniyamoorthy, M.
   Veerapandian, S. A.
   Sangeetha, G.
TI A methodology for the transformation of architectural forms into music
   and vice-versa for the enhancement of the musical and architectural
   libraries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Design library; Musical library; Deciphering logic; Transformations
AB Every architectural building design is a combination of various geometrical forms. These forms are generated from the geometrical shapes such as circles, squares, and triangles which undergoes transformations to form substructures. These substructures are then organized to form an architectural design. Similarly, in music a substructure may involve one or more notes in the chosen musical scale, which undergoes transformations to form substructures. These musical substructures are then organized in appropriate musical measures to compose music. A methodology has been employed to transformed architectural substructures to form respective musical substructures and vice-versa. The methodology includes deciphering architectural building design from music and vice-versa using a grid-based logic. This grid-based logic involves the visual parameters: length, height and width in architecture and the aural parameters: time, frequency and loudness in music; for X, Y, Z axes in the respective visual and musical grid. This method has been evaluated using the transformations involved in both architecture and music. Thus, the output of the above process enhances the existing libraries in both building design and music through the transformation of substructures.
C1 [Anu, S.; Muthukkumaran, K.; Veerapandian, S. A.] Natl Inst Technol, Dept Civil Engn, Tiruchirapalli 620015, Tamil Nadu, India.
   [Punniyamoorthy, M.] Natl Inst Technol, Dept Management Studies, Tiruchirapalli 620015, Tamil Nadu, India.
   [Sangeetha, G.] Natl Inst Technol, Dept Architecture, Tiruchirapalli 620015, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; National Institute of Technology (NIT
   System); National Institute of Technology Tiruchirappalli; National
   Institute of Technology (NIT System); National Institute of Technology
   Tiruchirappalli
RP Punniyamoorthy, M (corresponding author), Natl Inst Technol, Dept Management Studies, Tiruchirapalli 620015, Tamil Nadu, India.
EM anusndhl@gmail.com; kmk@nitt.edu; punniya@nitt.edu;
   pannpadini@gmail.com; gsangs@nitt.edu
RI hakim, luqmanul/AAL-2576-2021; Ganesan, Sangeetha/HOH-6833-2023; M,
   punniyamoorthy/IZE-0883-2023; M, punniyamoorthy/AAO-9180-2020;
   Muthukkumaran, Kasinathan/AAM-5562-2020
OI Ganesan, Sangeetha/0000-0001-7347-2162; Muthukkumaran,
   Kasinathan/0000-0002-7664-7068
CR Asefi M, 2012, PROCD SOC BEHV, V51, P1005, DOI 10.1016/j.sbspro.2012.08.278
   Bacon E.N., 1976, Design of Cities: Revised Edition
   Berry Wallace., 1986, Form in Music, V2nd
   Burkat L, 1944, NOTES, V2, P54, DOI [10.2307/891024, DOI 10.2307/891024]
   Capanna A, 2009, NEXUS NETW J, V11, P257, DOI 10.1007/s00004-008-0092-Z
   Celani G, 2007, GEOMETRIC TRANSFORMA
   Ching FrancisD.K., 2007, Architecture: Form, Space, and Order
   Cole J, 2007, MUSIC ARCHITECTURE C
   Cook P, 1999, ARCHIGRAM ILLUSTRATE
   Durmus S., 2012, GBER, V8, P23
   López GG, 2017, NUMANITIES ART HUMAN, V2, P157, DOI 10.1007/978-3-319-47060-3_12
   Hankinson JCK, 2000, MUSICAL PHRASE STRUC
   Hart V., 2009, Proceedings of Bridges 2009, P169
   Hersey GL, 2002, ARCHITECTURE GEOMETR, DOI [10.2307/991849, DOI 10.2307/991849]
   JENCKS Charles., 2013, Architecture Becomes Music
   Kamien Roger., 2011, Music: An Appreciation, V10th
   Khalil K.F., 2013, International Journal of Scientific and Research Publications, V3, P1
   Kiliçaslan H, 2012, PROCD SOC BEHV, V51, P635, DOI 10.1016/j.sbspro.2012.08.215
   Knott R., 2010, FIBONACCI NUMBERS GO
   Kolb T, 2005, GUITAR METHOD MUSIC
   Leopold C, 2003, J GEOMETRY GRAPHICS, V7, P101
   Leopold C, 2006, NEXUS NETW J, V8, P123, DOI [10.1007/S00004-006-0012-Z, DOI 10.1007/S00004-006-0012-Z]
   Levinton JS, 2003, SCIENCE, V301, P767, DOI 10.1126/science.1085864
   Ockelford A, 2019, ZYGONIC THEORY INTRO, P1, DOI [10.31751/400, DOI 10.31751/400]
   Pentcheva BV, 2011, ART BULL, V93, P489
   Prabakar NS, 2016, J MIDAS ARCHIT COLL, V1, P38
   Riad MM, 2009, THE CHRONICLES, P69
   Rohrmeier M, 2014, PRINCIPLES STRUCTURE, DOI [10.1098/rstb.2014.0097, DOI 10.1098/RSTB.2014.0097]
   ROSNER BS, 1986, MUSIC PERCEPT, V4, P1
   Samuel F, 2007, CORBUSIER DETAIL, DOI [10.4324/9780080550626, DOI 10.4324/9780080550626]
   Schoenberg Arnold., 1970, FUNDAMENTALMUSICAL
   Sendhil A, 2020, MULTIMED TOOLS APPL, V79, P13501, DOI 10.1007/s11042-019-08316-3
   Trachtenberg M, 2001, RENAISSANCE QUART, V54, P740, DOI 10.2307/1261923
   Variego JE(2015, 2015, ICMC 2015 SEPT 25 OC, P22
   Veerapandian SA, 2014, J TAMIL STUDIES, V084, P81
   Vitruvius, 2006, Ten Books on Architecture
   Whalley JH, 2014, TRANSFORMATIONS THEI
   Wittkower Rudolf., 1937, Art Bulletin, V19, P242, DOI [10.1080/00043079.1937.11409151, DOI 10.1080/00043079.1937.11409151]
NR 38
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10901
EP 10926
DI 10.1007/s11042-020-10201-3
EA JAN 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604479100003
DA 2024-07-18
ER

PT J
AU Mukherjee, H
   Dhar, A
   Obaidullah, SM
   Santosh, KC
   Phadikar, S
   Roy, K
AF Mukherjee, Himadri
   Dhar, Ankita
   Obaidullah, Sk. Md.
   Santosh, K. C.
   Phadikar, Santanu
   Roy, Kaushik
TI Identifying language from songs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Language identification; Song; LSF-AG; Ensemble learning
ID IDENTIFICATION
AB Audio signal-based applications have significantly evolved over the last decade from speech recognizers to audio-based search engines, and healthcare is no exception. It also holds true when multimedia content needs to be analyzed. One of the most popular and rapidly increasing sources of multimedia is music that can be in either audio or video format. To efficiently retrieve data, such ever-increasing information demands for different indexing and categorization techniques. The automated song search engines can benefit largely from a language identifier that can segregate songs by the language used. In this paper, we propose to identify the language of songs using Line Spectral Frequency-Approximation Gradation (LSF-AG) features and an ensemble learning-based classification technique. Ensemble learning was used due to its better generalization ability. Using 70+ hours of data for three different languages: English, Bangla, and Hindi, in our experiments, we achieved the highest average accuracy of 98.61% that outperforms standard techniques. Further, the robustness of the system was tested by taking noisy datasets into account.
C1 [Mukherjee, Himadri; Dhar, Ankita; Roy, Kaushik] West Bengal State Univ, Dept Comp Sci, Kolkata, India.
   [Obaidullah, Sk. Md.] Aliah Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Santosh, K. C.] Univ South Dakota, Dept Comp Sci, Vermillion, SD USA.
   [Phadikar, Santanu] Maulana Abul Kalam Azad Univ Technol, Dept Comp Sci & Engn, Kolkata, India.
C3 West Bengal State University; Aliah University; University of South
   Dakota; Maulana Abul Kalam Azad University of Technology
RP Phadikar, S (corresponding author), Maulana Abul Kalam Azad Univ Technol, Dept Comp Sci & Engn, Kolkata, India.
EM himadrim027@gmail.com; ankita.ankie@gmail.com; sk.obaidullah@gmail.com;
   santosh.kc@ieee.org; sphadikar@yahoo.com; kaushik.mrg@gmail.com
RI Roy, Kaushik/O-7021-2019; Santosh, K.C./H-1363-2012
OI Roy, Kaushik/0000-0002-3360-7576; Sk, Md Obaidullah/0000-0002-5207-3709
CR [Anonymous], 2003, 8 EUR C SPEECH COMM
   Bhanja CC, J KING SAUD U COMPUT
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chandrasekhar V, 2011, INT CONF ACOUST SPEE, P5724
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Deshwal D, 2020, APPL ACOUST, V164, DOI 10.1016/j.apacoust.2020.107289
   Dietterich TG., 2002, NEURAL NETWORKS, V2, P125
   Dutta AK, 2018, INT J SPEECH TECHNOL, V21, P509, DOI 10.1007/s10772-017-9482-5
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Irtza S, 2018, SPEECH COMMUN, V100, P30, DOI 10.1016/j.specom.2018.04.004
   Irtza S, 2016, INT CONF ACOUST SPEE, P5820, DOI 10.1109/ICASSP.2016.7472793
   Jin M, 2018, IEEE-ACM T AUDIO SPE, V26, P171, DOI 10.1109/TASLP.2017.2766023
   Manwani N, 2007, LECT NOTES COMPUT SC, V4815, P463
   Masumura R, 2017, INT CONF ACOUST SPEE, P5260, DOI 10.1109/ICASSP.2017.7953160
   Mehrabani M, 2011, INT CONF ACOUST SPEE, P4408
   Mitra V, 2008, INT CONF ACOUST SPEE, P2109, DOI 10.1109/ICASSP.2008.4518058
   Monteiro J, 2019, COMPUT SPEECH LANG, V58, P364, DOI 10.1016/j.csl.2019.05.006
   Mukherjee H, 2020, MULTIMED TOOLS APPL, P1
   Mukherjee H, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420580069
   Mukherjee H, 2020, INT J MACH LEARN CYB, V11, P1, DOI 10.1007/s13042-019-00928-3
   Mukherjee H, 2019, NEURAL COMPUT APPL, V31, P8483, DOI 10.1007/s00521-019-04468-3
   Mukherjee H, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSPC'17), P300, DOI 10.1109/CSPC.2017.8305857
   Nagarajan T, 2006, SPEECH COMMUN, V48, P913, DOI 10.1016/j.specom.2005.12.003
   Nandi D, 2017, COMPUT SPEECH LANG, V41, P88, DOI 10.1016/j.csl.2016.05.001
   Paliwal K. K., 1992, Digital Signal Processing, V2, P80, DOI 10.1016/1051-2004(92)90028-W
   Polasi PK, 2016, INT J SPEECH TECHNOL, V19, P75, DOI 10.1007/s10772-015-9326-0
   Rouas JL, 2005, SPEECH COMMUN, V47, P436, DOI 10.1016/j.specom.2005.04.012
   Sadjadi SO, 2015, SPEECH COMMUN, V72, P138, DOI 10.1016/j.specom.2015.04.005
   Schwenninger J, 2006, 7 INT C MUS INF RETR, P377
   Srivastava BML, 2017, IEEE IJCNN, P2144, DOI 10.1109/IJCNN.2017.7966114
   Tang ZY, 2018, IEEE-ACM T AUDIO SPE, V26, P134, DOI 10.1109/TASLP.2017.2764271
   Tsai W-H, 2004, ISMIR
   Tsai WH, 2007, J NEW MUSIC RES, V36, P105, DOI 10.1080/09298210701755206
   Van Segbroeck M, 2015, IEEE-ACM T AUDIO SPE, V23, P1118, DOI 10.1109/TASLP.2015.2419978
   Veerachary M., 2018, INT J SPEECH TECHNOL, P1
   Vuddagiri RK, 2018, EXPERT SYST APPL, V110, P290, DOI 10.1016/j.eswa.2018.06.004
   Yeh CF, 2015, IEEE-ACM T AUDIO SPE, V23, P1144, DOI 10.1109/TASLP.2015.2425214
   Zissman MA, 2001, SPEECH COMMUN, V35, P115, DOI 10.1016/S0167-6393(00)00099-6
NR 38
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35319
EP 35339
DI 10.1007/s11042-020-10163-6
EA JAN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000604203000003
DA 2024-07-18
ER

PT J
AU Gu, YF
   Zhang, HF
   Zhang, Z
   Ye, QL
AF Gu, Yifan
   Zhang, Haofeng
   Zhang, Zheng
   Ye, Qiaolin
TI Unsupervised deep triplet hashing with pseudo triplets for scalable
   image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised deep triplet hashing (UDTH); Autoencoder; Image retrieval;
   Pseudo triplets
ID QUANTIZATION
AB Deep learning based hashing methods have been proven to be effective in the field of image retrieval recently. Among them, most high-performance methods are supervised frameworks, which require annotated labels by humans. Considering the difficulty of labeling large-scale image datasets, unsupervised methods, which just need images themselves for training, are more suitable for practical applications. However, how to improve the discriminative ability of hash codes generated by unsupervised models still remains as a challenging problem. In this paper, we present a novel deep framework called Unsupervised Deep Triplet Hashing (UDTH) for scalable image retrieval. UDTH builds pseudo triplets based on the neighborhood structure in the high-dimensional visual feature space, and then solves two problems through the proposed objective function: 1) Triplet network is utilized to maximize the distance between different classes of binary representation; 2) Autoencoder and Binary quantization are exploited to learn hash codes which maintain the structural information of original samples. Extensive experiments on the datasets of CIFAR-10, NUS-WIDE and MIRFLICKR-25K are conducted, and the results show that our proposed UDTH is superior to the state-of-the-art methods.
C1 [Gu, Yifan; Zhang, Haofeng] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China.
   [Zhang, Zheng] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia.
   [Ye, Qiaolin] Nanjing Forestry Univ, Coll Informat Sci & Technol, Nanjing, Peoples R China.
C3 Nanjing University of Science & Technology; University of Queensland;
   Nanjing Forestry University
RP Zhang, HF (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China.
EM guyfan@njust.edu.cn; zhanghf@njust.edu.cn; darrenzz219@gmail.com;
   yqlcom@njfu.edu.cn
RI Zhang, Zhang/JAX-2097-2023; Zhang, Zheng/M-6325-2014
OI Zhang, Zheng/0000-0003-1470-6998
CR [Anonymous], 2010, PROC ACM SIGMM INT C
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Cao ZJ, 2017, IEEE I CONF COMP VIS, P5609, DOI 10.1109/ICCV.2017.598
   Chen X., 2017, P IEEE C COMP VIS PA, P3901
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Huang S, 2017, UNSUPERVISED TRIPLET, P84
   Huang SS, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P84, DOI 10.1145/3126686.3126773
   Krizhevsky A., 2009, Tech. Rep.
   Li Q, 2017, ADV NEUR IN, V30
   Lin KV, 2016, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR.2016.133
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu W, 2014, ADV NEURAL INFORM PR
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863
   Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Simonyan K, 2015, IEEE INT C ICLR
   Song JK, 2017, LECT NOTES ARTIF INT, V10534, P223, DOI 10.1007/978-3-319-71249-9_14
   Song JK, 2018, PATTERN RECOGN, V75, P175, DOI 10.1016/j.patcog.2017.03.021
   Song JK, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P827, DOI 10.1145/2733373.2806341
   Do TT, 2016, LECT NOTES COMPUT SC, V9909, P219, DOI 10.1007/978-3-319-46454-1_14
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Yan H, 2018, PATTERN RECOGN, V74, P434, DOI 10.1016/j.patcog.2017.09.035
   Yang HF, 2018, IEEE T PATTERN ANAL, V40, P437, DOI 10.1109/TPAMI.2017.2666812
   Yang WK, 2018, IEEE ACCESS, V6, P7445, DOI 10.1109/ACCESS.2017.2784800
   Ye QL, 2018, IEEE T CIRC SYST VID, V28, P114, DOI 10.1109/TCSVT.2016.2596158
   Zhang H., 2018, PATTERN RECOGN LETT
   Zhang HF, 2019, INFORM SCIENCES, V470, P43, DOI 10.1016/j.ins.2018.08.048
   Zhang HF, 2019, IEEE T IMAGE PROCESS, V28, P506, DOI 10.1109/TIP.2018.2869696
   Zhang HF, 2018, IEEE T IMAGE PROCESS, V27, P1626, DOI 10.1109/TIP.2017.2781422
   Zheng WM, 2017, IEEE T COGN DEV SYST, V9, P281, DOI 10.1109/TCDS.2016.2587290
   Zuo ZM, 2019, APPL SYST INNOV, V2, DOI 10.3390/asi2010007
   Zuo ZM, 2018, IEEE ACCESS, V6, P12894, DOI 10.1109/ACCESS.2018.2808486
NR 43
TC 4
Z9 4
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35253
EP 35274
DI 10.1007/s11042-019-7687-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900030
DA 2024-07-18
ER

PT J
AU Lu, XD
   Han, JJ
   Ren, QB
   Dai, H
   Li, JY
   Ou, J
AF Lu, Xindai
   Han, Jiajia
   Ren, Qianbo
   Dai, Hua
   Li, Jiyuan
   Ou, Jing
TI Network threat detection based on correlation analysis of multi-platform
   multi-source alert data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Threat detection; Alert correlation; Frequent sequences; Detection rate
AB It is difficult for security administrators to detect attacks well when they are faced with large amounts of multi-platform multi-source alert data. However, most attack events are not isolated and has a certain number of steps. With the help of alert correlation, attacks can be revealed well. In our paper, we propose a PMASP (Purpose-oriented Maximum Attack Sequence Patterns) algorithm for threat detection based on alert correlation. Firstly, we format alarm records and reduce redundant alarms. Then, with the help of attack classification, we generate initial attack sequences through clustering. Later, PMASP is employed to dig out frequent sequences set. Finally, we use xml language to construct rules for detection. These rules represent some attack patterns which are helpful for security administrators. We simulate several attacks and use some rules to detect. The detection rate shows that the rule is reasonable and effectively.
C1 [Lu, Xindai; Han, Jiajia; Dai, Hua; Li, Jiyuan] State Grid ZHEJIANG Elect Power Co, Elect Power Res Inst, Hangzhou, Peoples R China.
   [Ren, Qianbo] ZHEJIANG Huayun Informat Technol Co Ltd, Hangzhou, Peoples R China.
   [Ou, Jing] ZHEJIANG Univ, Coll Comp Sci, Hangzhou, Peoples R China.
C3 State Grid Corporation of China; Zhejiang University
RP Ou, J (corresponding author), ZHEJIANG Univ, Coll Comp Sci, Hangzhou, Peoples R China.
EM 756150120@qq.com
RI jing, ou/JNS-9390-2023
CR [Anonymous], 2001, Proceedings of the 4th International Symposium on Recent Advances in Intrusion Detection
   Bray T, 2007, WORLD WIDE WEB J, V2, P29
   Daneshgar FF, 2016, SECUR COMMUN NETW, V9, P2245, DOI 10.1002/sec.1483
   Endorf C., 2004, Intrusion detection prevention
   [冯学伟 Feng Xuewei], 2014, [计算机研究与发展, Journal of Computer Research and Development], V51, P2493
   Fournier-Viger Philippe, 2013, Advanced Data Mining and Applications. 9th International Conference, ADMA 2013. Proceedings: LNCS 8346, P169, DOI 10.1007/978-3-642-53914-5_15
   Fredj O, 2015, REALISTIC GRAPH BASE, DOI [10.1002/sec.1190, DOI 10.1002/SEC.1190]
   GhasemiGol M, 2015, SECUR COMMUN NETW, V8, P822, DOI 10.1002/sec.1039
   Govindarajan M, 2011, COMPUT NETW, V55, P1662, DOI 10.1016/j.comnet.2010.12.008
   Kawakani C, 2016, 12 BRAZ S INF SYST B, P42
   [李辉 Li Hui], 2004, [计算机研究与发展, Journal of Computer Research and Development], V41, P1911
   Lichodzijewski P, 2002, IEEE IJCNN, P1714, DOI 10.1109/IJCNN.2002.1007776
   Lippmann R, 2002, 5 INT S REC ADV INTR
   Liu XJ, 2016, J COMPUT SYST SCI, V82, P1316, DOI 10.1016/j.jcss.2016.05.006
   Liu XJ, 2014, SECUR COMMUN NETW, V7, P1570, DOI 10.1002/sec.855
   Liu XL, 2016, MULTIMED TOOLS APPL, V75, P1495, DOI 10.1007/s11042-014-2085-0
   Ma Jin, 2012, Journal of Tsinghua University (Science and Technology), V52, P1427
   Ning P., 2004, ACM Transactions on Information and Systems Security, V7, P274, DOI 10.1145/996943.996947
   Ramaki A, 2016, INT IR SOC CRYPT C I
   Sekar R, 2001, P IEEE S SECUR PRIV, P144, DOI 10.1109/SECPRI.2001.924295
   [田志宏 Tian Zhihong], 2009, [计算机研究与发展, Journal of Computer Research and Development], V46, P1304
   WANG Zheyuan, 2016, REMOTE SENSING INFOR, V31, P1, DOI [10.3969/j.issn.1000-3177.2016.05.001, DOI 10.3969/J.ISSN.1000-3177.2016.05.001]
   Xia YJ, 2016, THEOR COMPUT SCI, V618, P1, DOI 10.1016/j.tcs.2015.12.025
   Xia YJ, 2014, KSII T INTERNET INF, V8, P3607, DOI 10.3837/tiis.2014.10.019
   Xiaoyun Ye, 2018, Journal of Theoretical and Applied Information Technology, V96, P400
   Xu Y, 2011, C IND ELECT APPL, P1090, DOI 10.1109/ICIEA.2011.5975749
   Yan H, 2016, 8TH INTERNATIONAL CONFERENCE ON INTERNET MULTIMEDIA COMPUTING AND SERVICE (ICIMCS2016), P110, DOI 10.1145/3007669.3007706
   YCCH Wang, ALERT CORRELATION SY
   Zhang J, J COMPUT APPL, V36, P1538
NR 29
TC 1
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33349
EP 33363
DI 10.1007/s11042-018-6689-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000594855000002
DA 2024-07-18
ER

PT J
AU Ul Islam, I
   Ullah, K
   Afaq, M
   Iqbal, J
   Ali, A
AF Ul Islam, Ihtesham
   Ullah, Khalil
   Afaq, Muhammad
   Iqbal, Javed
   Ali, Amjad
TI Towards the automatic segmentation of HEp-2 cells in indirect
   immunofluorescence images using an efficient filtering based approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convergence filters; Indirect immunofluorescence; Fluorescence pattern;
   Classification; K-means clustering
ID MODEL
AB The computer aided analysis of Indirect-Immunofluorescence (IIF) images is important for the differential diagnosis of several autoimmune diseases. A fully automatic approach consists in segmentation of individual cells in IIF images and subsequently its classification into various pattern types. This paper explores the segmentation of HEp2 cell in IIF images through the use of a filtering based approach. Our algorithm is based on a local convergence filter named as Sliding Band Filter (SBF). We propose a modified SBF that is capable of handling the low contrast, noise and illumination variations peculiar to IIF images. In addition, we follow a simple algorithmic pipeline and achieve better accuracy as compared to several state of the art segmentation algorithms on standard HEp2 image dataset.
C1 [Ul Islam, Ihtesham; Iqbal, Javed] Sarhad Univ Sci & IT, Peshawar 25000, Pakistan.
   [Ullah, Khalil] Univ Malakand, Dir L, Pakistan.
   [Afaq, Muhammad] Jeju Natl Univ, Dept Comp Engn, Jeju Si, South Korea.
   [Ali, Amjad] Univ Swat, Mingora, Pakistan.
C3 University of Malakand; Jeju National University
RP Ul Islam, I (corresponding author), Sarhad Univ Sci & IT, Peshawar 25000, Pakistan.
EM ihtesham.csit@suit.edu.pk; khalil.ullah@uom.edu.pk; afaq@jejunu.ac.kr;
   javed.ee@suit.edu.pk; amjad@uswat.edu.pk
RI Ullah, Khalil/GSD-4920-2022; Iqbal, Javed/K-6084-2019
OI Ullah, Khalil/0000-0001-7265-7325; Iqbal, Javed/0000-0001-7747-8801;
   Muhammad, Afaq/0000-0001-8678-0754
CR [Anonymous], 2012, ICPR WORKSH PATT REC
   [Anonymous], 2012, INT J MICROSYST TECH
   Bleau A, 2000, COMPUT VIS IMAGE UND, V77, P317, DOI 10.1006/cviu.2000.0822
   Conte D, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P76, DOI 10.1109/AVSS.2012.9
   Creemers C, 2011, P 4 INT S APPL SCI B, P28
   Di Cataldo S, 2016, COMPUT METH PROG BIO, V128, P86, DOI 10.1016/j.cmpb.2016.02.005
   Di Cataldo S, 2014, PATTERN RECOGN, V47, P2389, DOI 10.1016/j.patcog.2013.09.024
   Egerer K, 2010, ARTHRITIS RES THER, V12, DOI 10.1186/ar2949
   Esteves T, 2012, MACH VISION APPL, V23, P623, DOI 10.1007/s00138-012-0407-7
   Foggia P, 2014, PATTERN RECOGN, V47, P2305, DOI 10.1016/j.patcog.2014.01.010
   Islam IU, 2013, INT JOINT C BIOM ENG, P176
   Islam IU, CLASSIFICATION HEP 2
   Malpica N, 1997, CYTOMETRY, V28, P289, DOI 10.1002/(SICI)1097-0320(19970801)28:4<289::AID-CYTO3>3.0.CO;2-7
   Perner P, 2002, ARTIF INTELL MED, V26, P161, DOI 10.1016/S0933-3657(02)00057-X
   Quelhas P, 2010, IEEE T MED IMAGING, V29, P1463, DOI 10.1109/TMI.2010.2048253
   Rigon A, 2007, CYTOM PART B-CLIN CY, V72B, P472, DOI 10.1002/cyto.b.20356
   Sack U, 2003, AUTOIMMUN REV, V2, P298, DOI 10.1016/S1568-9972(03)00067-3
   Tonti S, 2015, COMPUT MED IMAG GRAP, V40, P62, DOI 10.1016/j.compmedimag.2014.12.005
   Ullah H, 2019, NEURAL COMPUT APPL, V31, P7317, DOI 10.1007/s00521-018-3527-9
   Ullah H, 2017, NEUROCOMPUTING, V242, P28, DOI 10.1016/j.neucom.2017.02.023
   Uzair M, 2018, NEURAL COMPUT APPL, V30, P1211, DOI 10.1007/s00521-016-2758-x
   Yu-Len Huang, 2008, 2008 IEEE International Conference on Sensor Networks, Ubiquitous, and Trustworthy Computing (SUTC '08), P423
NR 22
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34325
EP 34337
DI 10.1007/s11042-020-08651-w
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000594855000052
DA 2024-07-18
ER

PT J
AU Yang, ZH
   Liu, GS
   Xie, XR
   Cai, Q
AF Yang, Zeheng
   Liu, Guisong
   Xie, Xiurui
   Cai, Qing
TI Efficient dynamic domain adaptation on deep CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Domain adaptation; Maximum mean discrepancy; Convolutional neural
   networks; Transfer learning
AB Domain adaptation is widely-used in deep neural networks to address the problem of data distribution shift. Most of the deep CNN models use the Maximum Mean Discrepancy(MMD) to measure the distribution difference between the source and task domains, which have achieved great success on transfer learning tasks. However, these conventional domain adaptation methods have limited use in dynamic knowledge adaptation due to the constant transfer coefficient for all adaptation layers. In this paper, we propose an efficient dynamic domain adaptation method on deep CNN models, which transfers knowledge dynamically according to different layers and training extent. Specifically, we first present a deep understanding of how transferable each layer in various deep CNN models is, including the different VGG and AlexNet architectures. Then, a dynamic transfer coefficient is proposed based on the deep understanding. By doing this, our paper gives guidance on how to choose transferring layers and adaptation coefficients aptly instead of using empirical constant transfer parameters in conventional methods. Extensive experiments conducted on standard benchmark datasets demonstrate that the proposed method achieves the state-of-the-art results by using dynamic domain adaptation parameters compared with conventional methods.
C1 [Yang, Zeheng; Liu, Guisong] Univ Elect Sci & Technol China, Sch Comp Sci, Zhongshan Inst, Zhongshan 528402, Peoples R China.
   [Yang, Zeheng; Liu, Guisong; Xie, Xiurui] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
   [Xie, Xiurui] Agcy Sci Technol & Res, Inst Infocomm Res, Singapore 138632, Singapore.
   [Cai, Qing] Natl Univ Singapore, Sch Elect & Comp Engn, Singapore 119077, Singapore.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China; Agency for Science Technology
   & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R);
   National University of Singapore
RP Liu, GS (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci, Zhongshan Inst, Zhongshan 528402, Peoples R China.; Liu, GS; Xie, XR (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.; Xie, XR (corresponding author), Agcy Sci Technol & Res, Inst Infocomm Res, Singapore 138632, Singapore.
EM lgs@uestc.edu.cn; xiex@i2r.a-star.edu.sg
RI Liu, Guisong/S-1263-2019
OI Liu, Guisong/0000-0003-2360-0466
CR [Anonymous], 2017, DEEP CASCADE NETWORK
   Chen C, 2018, JOINT DOMAIN ALIGNME
   Dai Wenyuan, 2007, P 24 INT C MACHINE L, P193
   Darrell T, 2015, SIMULTANEOUS DEEP TR
   Ding ZM, 2018, IEEE T NEUR NET LEAR, V29, P310, DOI 10.1109/TNNLS.2016.2618765
   Donahue J., 2013, Decaf: A deep convolutional activation feature for generic visual recognition
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Gong B, 2012, 2012 IEEE C IEEE COM
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Guo Yunhui, 2018, SpotTune: Transfer Learning through Adaptive Fine-tuning
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JJ, 2019, IEEE T NEUR NET LEAR, V30, P1381, DOI 10.1109/TNNLS.2018.2868854
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Li S, 2018, FRONT INFORM TECH EL, V19, P91, DOI 10.1631/FITEE.1700774
   Liu GS, 2015, NEUROCOMPUTING, V149, P1162, DOI 10.1016/j.neucom.2014.09.012
   Long M., 2017, CONDITIONAL ADVERSAR
   Long M, 2016, INT C MACH LEARN
   Long M, 2014, IEEE INT C COMP VIS
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Najafabadi MM, 2015, Journal of big data, V2, P1, DOI [10.1186/s40537-014-0007-7, DOI 10.1186/S40537-014-0007-7]
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Qiu S, 2018, DEEP LOCAL DESCRIPTO
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saenko K, 2010, EUR C COMP VIS
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Scholkopf B, 2006, INT C NEUR INF PROC
   Sun B, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P161, DOI 10.1109/ROBIO.2016.7866315
   Tzeng E., 2014, ARXIV14123474
   Wen J., 2018, IEEE transactions on cybernetics
   Xie XR, 2019, SOFT COMPUT, V23, P10187, DOI 10.1007/s00500-018-3576-0
   Xie XR, 2017, IEEE T NEUR NET LEAR, V28, P1411, DOI 10.1109/TNNLS.2016.2541339
   Xie XR, 2017, NEUROCOMPUTING, V241, P152, DOI 10.1016/j.neucom.2017.01.086
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhang Y, 2018, PARAMETER TRANSFER U
   Zhang Z, 2018, ACTA POLYM SIN, P99, DOI 10.11777/j.issn1000-3304.2018.17221
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 41
TC 3
Z9 3
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33853
EP 33873
DI 10.1007/s11042-019-08584-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000594855000027
DA 2024-07-18
ER

PT J
AU Melbin, K
   Raj, YJV
AF Melbin, K.
   Raj, Y. Jacob Vetha
TI Integration of modified ABCD features and support vector machine for
   skin lesion types classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin lesion; Dermoscopic images; Cumulative level difference mean;
   Eigen-vector centrality; Support vector machine
ID IMAGE SEGMENTATION; FEATURE-EXTRACTION; EDGE
AB The abnormal growth of skin cells often leads to skin cancer due to the exposure of skin cells to the sun. The skin disease is primarily caused by bacteria, fungus, viruses, UV radiation, and chemical substances. Generally, clinicians have been a trouble to categorize melanoma, seborrheic keratosis and lupus Erythematosus diseases due to the resemblance in the features of pigmented diseases. The paper presents an integrated approach for detecting the skin lesion from the dermoscopic images. The proposed integrated cumulative level difference mean (CLDM) based modified ABCD features and Support vector machine (SVM) have used for the detection and classification of skin lesion images. The proposed modified ABCD features employed for extracting the skin features like shape, size, color, and texture from the skin lesion images. Prior to the classification method, the Eigenvector Centrality feature ranking and selection (ECFS) method has utilized for better classification. After the feature selection method, a skin lesion image is classified by the Support vector machine (SVM). The performance of segmentation has been assessed by evaluating the Jaccard Similarity Index (JSI), Dice similarity coefficient (DSC), sensitivity, specificity, and accuracy. The proposed SVM method classifies the three skin lesion classes and produces excellent classification results with the classification accuracy is 97%, specificity is 98%, sensitivity is 97%, JSI is 97% and DSC is 98% for melanoma, seborrheic keratosis, and lupus Erythematosus respectively. The proposed approach classifies the three skin lesion classes (melanoma, seborrheic keratosis and lupus Erythematosus) with high accuracy. The integrated method not only enhances the accuracy level but also delivers significant information for better classification.
C1 [Melbin, K.; Raj, Y. Jacob Vetha] Nesamony Mem Christian Coll, Dept Comp Sci, Marthandam, India.
RP Melbin, K (corresponding author), Nesamony Mem Christian Coll, Dept Comp Sci, Marthandam, India.
EM melbink432@gmail.com
CR Adegun A, 2021, ARTIF INTELL REV, V54, P811, DOI 10.1007/s10462-020-09865-y
   Akar M, 2019, APPL MATH-CZECH, V64, P581, DOI 10.21136/AM.2019.0292-18
   Akram T, 2020, HUM-CENT COMPUT INFO, V10, DOI 10.1186/s13673-020-00216-y
   Alcón JF, 2009, IEEE J-STSP, V3, P14, DOI 10.1109/JSTSP.2008.2011156
   [Anonymous], 2018, ARXIV181202316
   [Anonymous], 2009, IMAGAPP
   Ansari M. A., 2007, IET-UK International Conference on Information and Communication Technology in Electrical Sciences (ICTES 2007), P724, DOI 10.1049/ic:20070707
   Baoan Han, 2015, 2015 2nd International Conference on Information Science and Control Engineering (ICISCE), P533, DOI 10.1109/ICISCE.2015.124
   Barata C, 2015, IEEE J BIOMED HEALTH, V19, P1146, DOI 10.1109/JBHI.2014.2336473
   Barata C, 2014, IEEE SYST J, V8, P965, DOI 10.1109/JSYST.2013.2271540
   Bodasingi N., 2017, J ENG, V4, P110
   Chatterjee S, 2015, 2015 International Conference on Condition Assessment Techniques in Electrical Systems (CATCON), P200, DOI 10.1109/CATCON.2015.7449534
   Chatterjee S, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101581
   Chatterjee S, 2019, COMPUT METH PROG BIO, V178, P201, DOI 10.1016/j.cmpb.2019.06.018
   Cula OG, 2004, IEEE T BIO-MED ENG, V51, P2148, DOI 10.1109/TBME.2004.836520
   Ferreira A, 2014, COMPUT METHOD BIOMEC, V17, P888, DOI 10.1080/10255842.2012.723700
   Gupta C, 2019, IEEE ACCESS, V7, P99407, DOI 10.1109/ACCESS.2019.2929857
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   Jiji GW, 2015, IET IMAGE PROCESS, V9, P306, DOI 10.1049/iet-ipr.2013.0501
   Khan MQ, 2019, IEEE ACCESS, V7, P90132, DOI 10.1109/ACCESS.2019.2926837
   Kia S, 2013, NEURAL COMPUT APPL, V22, P1049, DOI 10.1007/s00521-012-0864-y
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee I, 2017, COMPUT BIOL MED, V89, P314, DOI 10.1016/j.compbiomed.2017.08.020
   Lu J, 2013, IEEE T MED IMAGING, V32, P719, DOI 10.1109/TMI.2012.2236349
   Mirzaalian H., 2013, IEEE JBHI, V18, P1494
   Mower WR, 2019, ANN EMERG MED, V73, P366, DOI 10.1016/j.annemergmed.2018.09.020
   Mullangi P., 2018, TEXTURE CLUSTERING B, P103, DOI [10.1007/978-981-10-6614-6_11, DOI 10.1007/978-981-10-6614-6_11]
   Oliveira RB, 2016, COMPUT METH PROG BIO, V131, P127, DOI 10.1016/j.cmpb.2016.03.032
   Padmapriya B, 2012, PROCEDIA ENGINEER, V30, P828, DOI 10.1016/j.proeng.2012.01.934
   Rejeesh MR, 2019, MULTIMED TOOLS APPL, V78, P22691, DOI 10.1007/s11042-019-7577-5
   Sarkar R, 2019, IET IMAGE PROCESS, V13, P2130, DOI 10.1049/iet-ipr.2018.6669
   Sarpe Adelina-Iulia, 2010, Proceedings of the Second International Conference on Advances in Multimedia (MMEDIA 2010), P13, DOI 10.1109/MMEDIA.2010.31
   Seeja RD, 2019, ASIAN PAC J CANC PRE, V20
   Sundararaj, 2016, INT J INTELL ENG SYS, V9, P117, DOI [10.22266/ijies2016.0930.12, DOI 10.22266/IJIES2016.0930.12]
   Sundararaj V, 2020, PROG PHOTOVOLTAICS, V28, P1128, DOI 10.1002/pip.3315
   Sundararaj V, 2019, INT J BIOMED ENG TEC, V31, P325, DOI 10.1504/IJBET.2019.103242
   Sundararaj V, 2019, WIRELESS PERS COMMUN, V104, P173, DOI 10.1007/s11277-018-6014-9
   Sundararaj V, 2018, COMPUT SECUR, V77, P277, DOI 10.1016/j.cose.2018.04.009
   Valavanis I, 2015, IEEE J BIOMED HEALTH, V19, P190, DOI 10.1109/JBHI.2014.2336617
   Verma A.K., 2019, Informatics in Medicine Unlocked, V16, P100202, DOI [10.1016/j.imu.2019.100202, DOI 10.1016/J.IMU.2019.100202]
   Wahba MA, 2018, COMPUT METH PROG BIO, V165, P163, DOI 10.1016/j.cmpb.2018.08.009
   Wu Z, 2019, IEEE ACCESS, V7, P66505, DOI 10.1109/ACCESS.2019.2918221
   Zhang X, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071474
   Zien A, 2000, BIOINFORMATICS, V16, P799, DOI 10.1093/bioinformatics/16.9.799
NR 44
TC 19
Z9 19
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8909
EP 8929
DI 10.1007/s11042-020-10056-8
EA NOV 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000586377600003
DA 2024-07-18
ER

PT J
AU Xiao, LW
   Hu, XH
   Chen, YN
   Xue, Y
   Chen, BL
   Gu, DH
   Tang, BX
AF Xiao, Luwei
   Hu, Xiaohui
   Chen, Yinong
   Xue, Yun
   Chen, Bingliang
   Gu, Donghong
   Tang, Bixia
TI Multi-head self-attention based gated graph convolutional networks for
   aspect-based sentiment classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aspect-based sentiment classification; Multi-head Self-Attention; Gated
   graph convolutional networks; Syntax-aware Context Dynamic Weighted
AB Aspect-based sentiment classification aims to predict the sentiment polarity of specific aspects appeared in a sentence. Nowadays, most current methods mainly focus on the semantic information by exploiting traditional attention mechanisms combined with recurrent neural networks to capture the interaction between the contexts and the targets. However, these models did not consider the importance of the relevant syntactical constraints. In this paper, we propose to employ a novel gated graph convolutional networks on the dependency tree to encode syntactical information, and we design a Syntax-aware Context Dynamic Weighted layer to guide our model to pay more attention to the local syntax-aware context. Moreover, Multi-head Attention is utilized for capturing both semantic information and interactive information between semantics and syntax. We conducted experiments on five datasets and the results demonstrate the effectiveness of the proposed model.
C1 [Xiao, Luwei; Hu, Xiaohui; Xue, Yun; Chen, Bingliang; Gu, Donghong; Tang, Bixia] South China Normal Univ, SPTE, GPETR Ctr Quantum Precis Measurement, Guangdong Prov Key Lab Quantum Engn & Quantum Mat, Guangzhou 510006, Peoples R China.
   [Chen, Yinong] Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85287 USA.
C3 South China Normal University; Arizona State University; Arizona State
   University-Tempe
RP Hu, XH (corresponding author), South China Normal Univ, SPTE, GPETR Ctr Quantum Precis Measurement, Guangdong Prov Key Lab Quantum Engn & Quantum Mat, Guangzhou 510006, Peoples R China.
EM louisshaw008@gmail.com; huxh@scnu.edu.cn
RI Huang, Liping/KIB-4430-2024; Zhao, YuHan/KIE-0813-2024; Xiao,
   Luwei/JHT-4685-2023
OI Xiao, Luwei/0000-0001-7229-2741; Gu, donghong/0000-0003-1481-645X
FU China Scholarship Council; National Statistical Science Research Project
   of China [2016LY98]; Science and Technology Department of Guangdong
   Province in China [2016A010101020, 2016A010101021, 2016A010101022];
   Characteristic Innovation Projects of Guangdong Colleges and
   Universities [2018KTSCX049, 2018GKTSCX069]; Science and Technology Plan
   Project of Guangzhou [201802010033, 201903010013]
FX This work was supported by China Scholarship Council, the National
   Statistical Science Research Project of China under Grant No. 2016LY98,
   the Science and Technology Department of Guangdong Province in China
   under Grant Nos. 2016A010101020, 2016A010101021 and 2016A010101022, the
   Characteristic Innovation Projects of Guangdong Colleges and
   Universities (Nos. 2018KTSCX049 and 2018GKTSCX069), the Science and
   Technology Plan Project of Guangzhou under Grant Nos. 201802010033 and
   201903010013.
CR [Anonymous], 2019, ARXIV190604501
   [Anonymous], 2014, P 8 INT WORKSH SEM E
   Aoki R, 2015, PROC IEEE MICR ELECT, P925, DOI 10.1109/MEMSYS.2015.7051111
   Chen Z, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P547
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   Denton E, 2014, ADV NEUR IN, V27
   Dong L, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P49
   Dong XP, 2021, IEEE T PATTERN ANAL, V43, P1515, DOI 10.1109/TPAMI.2019.2956703
   Dong XW, 2018, IEEE CONF COMPUT
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   He Ruidan, 2018, P 27 INT C COMP LING, P1121, DOI [10.18653/v1/P18-2092, DOI 10.18653/V1/P18-2092]
   Hu J, 2020, ARXIV LEARNING
   Huang BX, 2018, LECT NOTES COMPUT SC, V10899, P197, DOI 10.1007/978-3-319-93372-6_22
   Huang BX, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1091
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kipf TN, 2017, INT C LEARN REPR
   Kiritchenko S., 2014, P 8 INT WORKSH SEM E, P437, DOI DOI 10.3115/V1/S14-2076
   Li L., 2018, P 22 C COMP NAT LANG, P181, DOI DOI 10.18653/V1/K18-1018
   Li L, 2016, IEEE IND ELEC, P3294, DOI 10.1109/IECON.2016.7793303
   Li X, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P946
   Lin PQ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5088
   Ma DH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4068
   Marcheggiani Diego, 2017, EMNLP, DOI DOI 10.18653/V1/D17-1159
   Nicola DC, 2018, ARXIV 180809920
   Pang B., 2008, INFORM RETRIEVAL, V2, P1, DOI [10.1561/1500000011, DOI 10.1561/1500000011, https://doi.org/10.1561/1500000011]
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pfeifer C, 2014, J LABOUR MARK RES, V47, P223, DOI 10.1007/s12651-013-0137-y
   Pontiki M., 2015, P 9 INT WORKSH SEM E, P486
   Pontiki M., 2016, P 10 INT WORKSH SEM, P19, DOI 10.18653/v1/S16-1002
   Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Sheng J, 2019, IEEE T APPL SUPERCON, V29, DOI 10.1109/TASC.2019.2903269
   Song Y, 2019, ARXIV 190209314
   Tang D, 2016, ARXIV 150203167
   Wang JJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3548
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wang Y, 2016, PROCEEDINGS OF THE 2016 SECOND CONFERENCE ON MOBILE AND SECURE SERVICES (MOBISECSERV)
   Wu DM, 2020, IEEE T NEUR NET LEAR, V31, P4933, DOI 10.1109/TNNLS.2019.2959129
   Xiao LW, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10030957
   Xu H, 2019, ARXIV 190402232
   Xue W, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2514
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Zeng BQ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163389
   Zhang C, 2018, ARXIV190903477
   Zhang Y, 2018, ARXIV 180910185
NR 48
TC 17
Z9 17
U1 4
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19051
EP 19070
DI 10.1007/s11042-020-10107-0
EA OCT 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000583128600002
DA 2024-07-18
ER

PT J
AU Huang, WJ
   Cheng, B
   Zhang, G
   Sui, YX
   Jiang, L
   Xu, Y
   Li, HT
   Yang, Z
AF Huang, Weijun
   Cheng, Bo
   Zhang, Gang
   Sui, Yuexin
   Jiang, Li
   Xu, Yuan
   Li, Hongting
   Yang, Zhen
TI Ergonomics research on eye-hand control dual channel interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human computer interaction; Usability testing; Interaction device
ID HUMAN-COMPUTER INTERACTION
AB Eye-control interfaces are human-computer interfaces in which interaction is mediated by the user's gaze. Using dwell time for target selection may be hindered by the "Midas Touch" problem, which posits that intentional selection and perceptual processes cannot be separated. To solve this problem, we investigated the influence of different dwell times on task performance. Results suggest that the optimal dwell time to trigger a click in eye-control movement plus eye-control click and hand-control movement plus eye-control click are 700 and 200 ms, respectively. In addition, the eye-control movement plus eye-control click mode has a lower completion rate than the hand-control movement plus eye-control click mode.
C1 [Huang, Weijun; Cheng, Bo; Zhang, Gang] China Nucl Power Engn Co Ltd, State Key Lab Nucl Power Safety Monitoring Techno, Shenzhen, Guangdong, Peoples R China.
   [Sui, Yuexin; Jiang, Li; Xu, Yuan; Li, Hongting; Yang, Zhen] Zhejiang Sci Tech Univ, Dept Psychol, Hangzhou, Zhejiang, Peoples R China.
C3 China Nuclear Power Engineering Co Ltd.; Zhejiang Sci-Tech University
RP Yang, Z (corresponding author), Zhejiang Sci Tech Univ, Dept Psychol, Hangzhou, Zhejiang, Peoples R China.
EM yangzhen@zstu.edu.cn
RI Yang, Zhen/JFK-8720-2023; chen, qy/JXM-3217-2024; Chen, Qi/GVU-3024-2022
OI Chen, Qi/0000-0002-6568-7267; Yang, Zhen/0000-0002-0623-9712
FU National Nature Science Foundation of China [31900768]; scientific
   research starting foundation of Zhejiang Sci-Tech University
   [16062022-Y]; open fund of the State Key Laboratory of Nuclear Power
   Safety Monitoring Technology and Equipment [KA2019.428]
FX This work was supported by the National Nature Science Foundation of
   China under Grant (31900768), the scientific research starting
   foundation of Zhejiang Sci-Tech University [16062022-Y], and the open
   fund of the State Key Laboratory of Nuclear Power Safety Monitoring
   Technology and Equipment (KA2019.428).
CR Anliker J., 1976, EYE MOVEMENTS PSYCHO, P185
   [Anonymous], 2010, EYE MOVEMENT BASED H
   [Anonymous], 2006, P S EYE TRACK RES AP, DOI DOI 10.1145/1117309.1117349
   Benligiray B, 2019, J MULTIMODAL USER IN, V13, P321, DOI 10.1007/s12193-018-0285-z
   Chatterjee I, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P131, DOI 10.1145/2818346.2820752
   Chin CA, 2007, BIOMED SCI INSTRUM, V43, P152
   Cleveland N. R., 1994, P 1 AUT TECHN HUM PE
   CORNSWEET TN, 1973, J OPT SOC AM, V63, P921, DOI 10.1364/JOSA.63.000921
   Dorr M, 2009, PSYCHNOLOGY J, V7, P197
   Drewes H., 2010, Eye Gaze Tracking for Human Computer Interaction
   Ghani MU, 2013, 2013 16TH INTERNATIONAL MULTI TOPIC CONFERENCE (INMIC), P154, DOI 10.1109/INMIC.2013.6731342
   Grauman K, 2001, PROC CVPR IEEE, P1010
   Guo Xiaobo, 2009, RES EYE CONTROLLED M
   Hansen J.P., 2001, P UNIVERSAL ACCESS H, P325
   Herbold A.-K., 2008, J EYE MOVEMENT RES, V2
   Huang Qiao, 2008, COMPUT SYST APPL, V17, P14, DOI [10.1016/j.cam.2006.12.026, DOI 10.1016/J.CAM.2006.12.026]
   HUTCHINSON TE, 1989, IEEE T SYST MAN CYB, V19, P1527, DOI 10.1109/21.44068
   Hyrskykari A., 1997, Proceedings of ACHCI'97, P22
   ISTANCE HO, 1996, P 1 EUR C DIS VIRT R, P109
   Jacob R.J., 1990, P SIGCHI C HUM FACT, P11, DOI DOI 10.1145/97243.97246
   Jacob R.J. K., 1995, Eye tracking in advanced Interface Design
   KENYON RV, 1985, VISION RES, V25, P1629, DOI 10.1016/0042-6989(85)90133-6
   Koesling H, 2009, COGN SYST MONOGR, V6, P83
   Kumar M, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P421
   Majaranta P., 2002, Proceedings ETRA 2002. Eye Tracking Research and Applications Symposium, P15, DOI 10.1145/507072.507076
   Park KS, 1996, COMPUT IND ENG, V30, P463, DOI 10.1016/0360-8352(96)00018-6
   Rasmusson D, 1999, P 14 INT C TECHN PER
   Ryu K, 2019, J MULTIMODAL USER IN, V13, P383, DOI 10.1007/s12193-019-00305-y
   Selvamuthu D, 2018, SINGLE FACTOR EXPT D, DOI 10.1007/978-981-13-1736-1_7
   Sol R, 2013, ACHI 2013 6 INT C AD, P440
   van Schaik P, 2005, INT J HUM-COMPUT INT, V18, P309, DOI 10.1207/s15327590ijhc1803_4
   Zhai Shumin., 1999, Proceedings of CHI, P246, DOI [10.1145/302979.303053 10.1145/302979.303053, DOI 10.1145/302979.3030532, DOI 10.1145/302979.303053]
   Zhang YX, 2015, LECT NOTES COMPUT SC, V9298, P570, DOI 10.1007/978-3-319-22698-9_39
   张丽川, 2009, [人类工效学, Chinese Ergonomics], V15, P67
NR 34
TC 1
Z9 1
U1 4
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7833
EP 7851
DI 10.1007/s11042-020-10097-z
EA OCT 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000016
DA 2024-07-18
ER

PT J
AU Peng, T
   Zhou, XZ
   Liu, JP
   Hu, XR
   Chen, CN
   Wu, ZH
   Peng, D
AF Peng, Tao
   Zhou, Xianzi
   Liu, Junping
   Hu, Xinrong
   Chen, Changnian
   Wu, Zhonghua
   Peng, Di
TI A textile fabric classification framework through small motions in
   videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Textile material properties; Small motion; Two-stream architecture;
   Dense trajectories
AB In the field of computer visions, it is demanding and challenging to determine fabric categories in accordance with appearance changes and multi-frame motion information from a video. Investigating recent impressive results on textile fabric classification techniques, we observed that motion-based video analytics were overlooked in the prior studies. To address this technological gap, a framework called Two-Stream+, which employs deep neural networks to classify textile fabrics through small motions in videos is proposed. At the heart of the Two-Stream+ framework, the motion information of textile (e.g., flow trajectories and dense trajectories) was used to expose the material properties. More specifically, we advocate for fusing spatial and temporal Convolutional Neural Networks (i.e., ConvNets) towers at the first fully connected layer. In addition, deformable convolution is used in Residual Networks (i.e., ResNet) to enhance the transformation modeling capability of ConvNets. Testing a publicly available database, a conducted experiments is used to illustrate that the Two-Stream+ architecture has distinct advantages over the state-of-the-art architectures for classifying textile fabrics.
C1 [Peng, Tao; Zhou, Xianzi; Liu, Junping; Hu, Xinrong; Chen, Changnian; Peng, Di] Wuhan Text Univ, Sch Math & Comp Sci, Wuhan, Peoples R China.
   [Wu, Zhonghua] Wuhan Aopu Informat Ltd, Wuhan, Peoples R China.
C3 Wuhan Textile University
RP Peng, T (corresponding author), Wuhan Text Univ, Sch Math & Comp Sci, Wuhan, Peoples R China.
EM pt@wtu.edu.cn
RI Hu, Xinrong/HGA-1351-2022
FU Science Foundation of Hubei [2014CFB764]; Department of Education of the
   Hubei Province of China [Q20131608]; U.S. National Science Foundation
   [IIS-1618669, OAC-1642133, CCF0845257]
FX This work is supported in part by the Science Foundation of Hubei under
   Grant No. 2014CFB764 and Department of Education of the Hubei Province
   of China under Grant No. Q20131608, and Engineering Research Center of
   Hubei Province for Clothing Information. Xiao Qin's work is supported by
   the U.S. National Science Foundation under Grants IIS-1618669,
   OAC-1642133, and CCF0845257 (CAREER).
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Aliaga C, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P41, DOI 10.1145/2804408.2804412
   [Anonymous], 2017, ARXIV170304101
   [Anonymous], 2009, TREC VID RETR EV WOR
   Bouman KL, 2013, IEEE I CONF COMP VIS, P1984, DOI 10.1109/ICCV.2013.455
   Chowdhary C.L., 2018, Nature inspired computing, P75
   Chowdhary CL, 2020, PROCEDIA COMPUT SCI, V167, P26, DOI 10.1016/j.procs.2020.03.179
   Chowdhary CL, 2017, J BIOMIM BIOMATER BI, V30, P12, DOI 10.4028/www.scientific.net/JBBBE.30.12
   Chowdhary CL, 2016, INT J HEALTHC INF SY, V11, P38, DOI 10.4018/IJHISI.2016040103
   Chowdhary CL, 2016, ADV INTELL SYST, V411, P325, DOI 10.1007/978-81-322-2731-1_30
   Chung J., 2017, ICLR
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Davis A, 2015, PROC CVPR IEEE, P5335, DOI 10.1109/CVPR.2015.7299171
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan KC, 1998, TEXT RES J, V68, P179, DOI 10.1177/004051759806800305
   Fleming RW, 2003, J VISION, V3, P347, DOI 10.1167/3.5.3
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065
   Ho YX, 2006, J VISION, V6, P634, DOI 10.1167/6.5.8
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jing JF, 2014, FIBER POLYM, V15, P1092, DOI 10.1007/s12221-014-1092-0
   Jueliang H, 2004, TEXTILE J, P47
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kuo CFJ, 2010, TEXT RES J, V80, P2144, DOI 10.1177/0040517510373630
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu C, 2010, PROC CVPR IEEE, P239, DOI [10.1109/CVPR.2010.5540207, 10.1109/ICCET.2010.5485248]
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Ning F, 2005, IEEE T IMAGE PROCESS, V14, P1360, DOI 10.1109/TIP.2005.852470
   Salakhutdinov, 2015, ARXIV151104119
   Show A, 2015, 8389 ARXIV, V83, P89
   Simonyan K, 2014, ADV NEUR IN, V27
   Sun JJ, 2011, TEXT RES J, V81, P902, DOI 10.1177/0040517510391702
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Vinit Bodhwani DPAcharjyaU, 2019, PROCEDIA COMPUTER SC, V152, P86
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI [10.1109/CSTIC.2018.8369274, 10.1007/s11263-019-01198-w]
   Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222
   Yang S, 2017, IEEE I CONF COMP VIS, P4393, DOI 10.1109/ICCV.2017.470
NR 41
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7567
EP 7580
DI 10.1007/s11042-020-10085-3
EA OCT 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584947400003
DA 2024-07-18
ER

PT J
AU Alhadawi, HS
   Majid, MA
   Lambic, D
   Ahmad, M
AF Alhadawi, Hussam S.
   Majid, Mazlina Abdul
   Lambic, Dragan
   Ahmad, Musheer
TI A novel method of S-box design based on discrete chaotic maps and cuckoo
   search algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE S-boxes; CS optimization; Chaos; Cryptography
ID LEVY FLIGHTS; ENCRYPTION SCHEME; BOOLEAN FUNCTIONS; SUBSTITUTION BOX;
   CONSTRUCTION; OPTIMIZATION
AB Substitution-boxes (S-boxes) are unique nonlinear elements, which are used to achieve the property of confusion in modern symmetric ciphers and offer resistance to cryptanalysis. The construction of strong S-boxes has gained considerable attention in the area of cryptography. In fact, the security of transmitted data is highly dependent on the strength of the S-boxes for the prevention of unauthorised access. Therefore, the creation of strong S-box with high nonlinearity score has been considered a significant challenge. This study presented a novel method for the designing of 8 x 8 S-boxes with selected cryptographic characteristics based on a cuckoo search (CS) algorithm and discrete-space chaotic map. Notably, the advantage of the proposed approach is indicated through the efficient randomisation and lower adjustable parameters in CS compared to GA and PSO. Also, this approach utilised a 1D discrete-space chaotic map with virtually unlimited key space to design initial S-boxes, which is another advantage over the methods based on continuous-space chaotic maps, which consist of the limited key space. Moreover, chaotic maps have a potential to overcome the trapping problem of a standard CS in the local optima, and they were used to generate initial S-boxes to achieve the desired quality and facilitate the metaheuristic search. Accordingly, the metaheuristic CS was used to find a notable S-box configuration which fulfilled the established criteria. This objective was achieved by searching for the optimal or near-optimal features which maximised the given fitness function. The performance of the proposed method was evaluated based on the established performance evaluation criteria, including bijectivity, nonlinearity, strict avalanche criteria, bit independence criteria, differential uniformity, and linear probability. Based on the results of proposed method performance was benchmarked against the results of the recently developed S-boxes, it was indicated that the S-boxes exhibited good cryptographic features and could resist various cryptanalysis attacks.
C1 [Alhadawi, Hussam S.] Ton Duc Thang Univ, Informetr Res Grp, Ho Chi Minh City, Vietnam.
   [Alhadawi, Hussam S.] Ton Duc Thang Univ, Fac Informat Technol, Ho Chi Minh City, Vietnam.
   [Majid, Mazlina Abdul] Univ Malaysia Pahang, Fac Comp Syst & Software Engn, Kuantan, Pahang, Malaysia.
   [Lambic, Dragan] Univ Novi Sad, Fac Educ, Podgoricka 4, Sombor, Serbia.
   [Ahmad, Musheer] Jamia Millia Islamia, Dept Comp Engn, New Delhi, India.
C3 Ton Duc Thang University; Ton Duc Thang University; Universiti Malaysia
   Pahang Al-Sultan Abdullah (UMPSA); University of Novi Sad; Jamia Millia
   Islamia
RP Alhadawi, HS (corresponding author), Ton Duc Thang Univ, Informetr Res Grp, Ho Chi Minh City, Vietnam.; Alhadawi, HS (corresponding author), Ton Duc Thang Univ, Fac Informat Technol, Ho Chi Minh City, Vietnam.
EM hussam.alhadawi@tdtu.edu.vn
RI Lambić, Dragan/D-6460-2018; Ahmad, Musheer/H-9587-2018; Alhadawi, Hussam
   S./W-2674-2019
OI Ahmad, Musheer/0000-0002-4915-9325; Alhadawi, Hussam
   S./0000-0003-2179-4383
CR Abd El-Latif A. A., 2012, RES J APPL SCI ENG T, V4, P322
   Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Ahmad M, 2015, PROCEDIA COMPUT SCI, V57, P572, DOI 10.1016/j.procs.2015.07.394
   Ahmed HA, 2019, NEURAL COMPUT APPL, V31, P7201, DOI 10.1007/s00521-018-3557-3
   Al Solami E, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20070525
   Alhadawi HS, 2019, CRYPTOLOGIA, V43, P190, DOI 10.1080/01611194.2018.1548390
   Alzaidi AA, 2018, IEEE ACCESS, V6, P55405, DOI 10.1109/ACCESS.2018.2871557
   [Anonymous], 2018, SOFT COMPUTING THEOR
   [Anonymous], 2017, J CHEM-NY, DOI DOI 10.1155/2017/5208915
   Baronchelli A, 2013, CHAOS SOLITON FRACT, V56, P101, DOI 10.1016/j.chaos.2013.07.013
   Barthelemy P, 2008, NATURE, V453, P495, DOI 10.1038/nature06948
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Belazi A, 2015, INT WIREL COMMUN, P606, DOI 10.1109/IWCMC.2015.7289152
   Benrhouma O, 2015, SIGNAL IMAGE VIDEO P, V9, P1281, DOI 10.1007/s11760-013-0570-y
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Brown CT, 2007, HUM ECOL, V35, P129, DOI 10.1007/s10745-006-9083-4
   Carlet C, 2005, LECT NOTES COMPUT SC, V3797, P49
   Carlet C, 2008, LECT NOTES COMPUT SC, V5203, P345, DOI 10.1007/978-3-540-85912-3_31
   Çavusoglu Ü, 2017, NONLINEAR DYNAM, V87, P1081, DOI 10.1007/s11071-016-3099-0
   Chen G, 2008, CHAOS SOLITON FRACT, V36, P1028, DOI 10.1016/j.chaos.2006.08.003
   Cui LG, 2007, INT J INNOV COMPUT I, V3, P751
   Daemen J., 2013, DESIGN RIJNDAEL AES
   Dawson M, 1991, WORKSH THEOR APPL CR, P352
   El-Latif A. A. A., 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P369, DOI 10.1109/IIHMSP.2011.67
   El-Latif AAA, 2012, 4 INT C DIG IM PROC, p3343F
   Farah T, 2017, NONLINEAR DYNAM, V88, P1059, DOI 10.1007/s11071-016-3295-y
   Huang L, 2016, APPL MATH MODEL, V40, P3860, DOI 10.1016/j.apm.2015.10.052
   Hussain I, 2012, NONLINEAR DYNAM, P1
   Hussain I, 2012, NONLINEAR DYNAM, V70, P1791, DOI 10.1007/s11071-012-0573-1
   Ibrahim I, 2015, PROCEEDINGS 7TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, COMMUNICATION SYSTEMS AND NETWORKS CICSYN 2015, P3, DOI 10.1109/CICSyN.2015.11
   Ivanov G, 2016, CRYPTOGR COMMUN, V8, P247, DOI 10.1007/s12095-015-0170-5
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Jamal SS, 2016, WIRELESS PERS COMMUN, V90, P2033, DOI 10.1007/s11277-016-3436-0
   Kanagaraj G, 2013, COMPUT IND ENG, V66, P1115, DOI 10.1016/j.cie.2013.08.003
   Kazakevicius R, 2014, PHYSICA A, V411, P95, DOI 10.1016/j.physa.2014.06.020
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Khan M, 2015, SIGNAL IMAGE VIDEO P, V9, P1335, DOI 10.1007/s11760-013-0577-4
   Khan M, 2013, NONLINEAR DYNAM, V73, P1795, DOI 10.1007/s11071-013-0904-x
   Khan M, 2012, NONLINEAR DYNAM, V70, P2303, DOI 10.1007/s11071-012-0621-x
   Lambic D, 2017, NONLINEAR DYNAM, V87, P2407, DOI 10.1007/s11071-016-3199-x
   Lambic D, 2015, CHAOS SOLITON FRACT, V78, P245, DOI 10.1016/j.chaos.2015.08.001
   Lambic D, 2014, CHAOS SOLITON FRACT, V58, P16, DOI 10.1016/j.chaos.2013.11.001
   Lehmer D. H., 1960, Combinatorial Analysis, V10, P179
   Liu GJ, 2015, NONLINEAR DYNAM, V82, P1867, DOI 10.1007/s11071-015-2283-y
   Manjula G, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P613, DOI 10.1109/ICATCCT.2016.7912073
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Mohamed NA, 2015, INT CONF SOFT COMPUT, P230, DOI 10.1109/SOCPAR.2015.7492812
   Mohanty PK, 2013, LECT NOTES COMPUT SC, V8297, P527, DOI 10.1007/978-3-319-03753-0_47
   Murphy S, 2002, DESIGN CODE CRYPTOGR, V27, P229, DOI 10.1023/A:1019991004496
   Ouaarab A, 2014, NEURAL COMPUT APPL, V24, P1659, DOI 10.1007/s00521-013-1402-2
   Özkaynak F, 2019, NEURAL COMPUT APPL, V31, P3317, DOI 10.1007/s00521-017-3287-y
   Özkaynak F, 2017, SIGNAL IMAGE VIDEO P, V11, P659, DOI 10.1007/s11760-016-1007-1
   Özkaynak F, 2013, NONLINEAR DYNAM, V74, P551, DOI 10.1007/s11071-013-0987-4
   Özkaynak F, 2010, PHYS LETT A, V374, P3733, DOI 10.1016/j.physleta.2010.07.019
   Pavlyukevich I, 2007, J COMPUT PHYS, V226, P1830, DOI 10.1016/j.jcp.2007.06.008
   Payne R.B., 2005, The cuckoos, V15
   Peng JL, 2017, INT CONF UBIQ FUTUR, P989
   Picek S, 2014, LECT NOTES COMPUT SC, V8672, P822
   PIEPRZYK J, 1988, IEE PROC-E, V135, P325, DOI 10.1049/ip-e.1988.0044
   Reynolds AM, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000354
   Rodrigues D, 2013, IEEE INT SYMP CIRC S, P465, DOI 10.1109/ISCAS.2013.6571881
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shehab M, 2017, APPL SOFT COMPUT, V61, P1041, DOI 10.1016/j.asoc.2017.02.034
   Shlesinger MF, 2006, NATURE, V443, P281, DOI 10.1038/443281a
   Tang GP, 2005, CHAOS SOLITON FRACT, V23, P413, DOI 10.1016/j.chaos.2004.04.023
   Tian Y, 2016, J SYST ENG ELECTRON, V27, P232, DOI 10.1109/JSEE.2016.00023
   ul Islam F, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0119-x
   Wang GG, 2016, SOFT COMPUT, V20, P3349, DOI 10.1007/s00500-015-1726-1
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   Wang Y, 2009, ECBI: 2009 INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE AND BUSINESS INTELLIGENCE, PROCEEDINGS, P125, DOI 10.1109/ECBI.2009.15
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Xin-She Yang, 2010, International Journal of Mathematical Modelling and Numerical Optimisation, V1, P330, DOI 10.1504/IJMMNO.2010.035430
   Yang H, 2013, INT C COMP AID DES C, P421, DOI 10.1109/CADGraphics.2013.77
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Zaghloul A, 2014, INT J SECUR APPL, V8, P89, DOI 10.14257/ijsia.2014.8.4.09
   Zahid AH, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030245
   Zhang TJ, 2015, INT J SECUR APPL, V9, P217, DOI 10.14257/ijsia.2015.9.7.19
   Zhang T, 2018, IEEE T CYBERNETICS, V48, P3349, DOI 10.1109/TCYB.2018.2846186
NR 82
TC 73
Z9 74
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7333
EP 7350
DI 10.1007/s11042-020-10048-8
EA OCT 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584568200002
DA 2024-07-18
ER

PT J
AU Balasamy, K
   Suganyadevi, S
AF Balasamy, K.
   Suganyadevi, S.
TI A fuzzy based ROI selection for encryption and watermarking in medical
   image using DWT and SVD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy ROI; Wavelet transform; Encryption; Key component; Watermarking
ID REVERSIBLE WATERMARKING; CONTRAST ENHANCEMENT; LOSSLESS WATERMARKING;
   DIGITAL WATERMARKING; TAMPER DETECTION; SCHEME; ROBUST; AUTHENTICATION;
   PROTECTION; SECURITY
AB Nowadays secure medical image watermarking had become a stringent task in telemedicine. This paper presents a novel medical image watermarking method by fuzzy based Region of Interest (ROI) selection and wavelet transformation approach to embed encrypted watermark. First, the source image will undergo fuzzification to determine the critical points through central and final intensity along the radial line for selecting region of interest (ROI). Second, watermark image is altered to time-frequency domain through wavelet decomposition where the sub-bands are swapped based on the magnitude value obtained through logistic mapping. In the each sub-band all the pixels get swapped, results in fully encrypted image which guarantees the watermark to a secure, reliable and an unbreakable form. In order to provide more robustness to watermark image, singular values are obtained for encrypted watermark image and key component is calculated for avoiding false positive error. Singular values of the source and watermark image are modified through key component. Experimental results reveal that the proposed algorithm attains high robustness and improved security to the watermarked image against various kinds of attacks.
C1 [Balasamy, K.] Dr Mahalingam Coll Engn & Technol, Dept Informat Technol, Pollachi, India.
   [Suganyadevi, S.] Avinashilingam Inst Home Sci & Higher Educ Women, Sch Engn, Dept ECE, Coimbatore, Tamil Nadu, India.
C3 Avinashilingam University for Women
RP Balasamy, K (corresponding author), Dr Mahalingam Coll Engn & Technol, Dept Informat Technol, Pollachi, India.
EM balasamyk@gmail.com
RI s, suganyadevi/AAB-9143-2022; Krishnasamy, Balasamy/ABE-1237-2021
OI s, suganyadevi/0000-0001-6096-7510; Krishnasamy,
   Balasamy/0000-0003-0973-5698
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Al-Haj A, 2014, J DIGIT IMAGING, V27, P737, DOI 10.1007/s10278-014-9709-9
   Al-Qershi OM, 2011, J DIGIT IMAGING, V24, P114, DOI 10.1007/s10278-009-9253-1
   [Anonymous], 2012, INT J COMPUT COMMUN, DOI 10.5281/zenodo.1331913
   Araghi TK, 2019, FUTURE GENER COMP SY, V101, P1223, DOI 10.1016/j.future.2019.07.064
   Balakrishnan M, 2021, ADV INTELLIGENT SYST, V1177, DOI 10.1007/978-981-15-5679-1_27
   Balasamy K, 2019, CLUSTER COMPUT, V22, pS4431, DOI 10.1007/s10586-018-1991-8
   Bensaid AM, 1996, PATTERN RECOGN, V29, P859, DOI 10.1016/0031-3203(95)00120-4
   Bouslimi D, 2012, COMPUT METH PROG BIO, V106, P47, DOI 10.1016/j.cmpb.2011.09.015
   Campisi P, 2004, IEEE SIGNAL PROC LET, V11, P826, DOI 10.1109/LSP.2004.835463
   Cao F, 2003, COMPUT MED IMAG GRAP, V27, P185, DOI 10.1016/S0895-6111(02)00073-3
   Das S, 2011, LECT NOTES COMPUT SC, V6744, P286
   Eswaraiah R, 2014, INT J TELEMED APPL, V2014, DOI 10.1155/2014/984646
   Favorskaya M, 2019, PROCEDIA COMPUT SCI, V159, P1267, DOI 10.1016/j.procs.2019.09.296
   Gangadhar Y, 2018, BIOMED SIGNAL PROCES, V43, P31, DOI 10.1016/j.bspc.2018.02.007
   Ganic E, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2137650
   Gao GY, 2017, INFORM SCIENCES, V385, P250, DOI 10.1016/j.ins.2017.01.009
   Giakoumaki A, 2006, IEEE T INF TECHNOL B, V10, P722, DOI 10.1109/TITB.2006.875655
   Guo XT, 2009, J DIGIT IMAGING, V22, P620, DOI 10.1007/s10278-008-9120-5
   Guo XT, 2009, J DIGIT IMAGING, V22, P53, DOI 10.1007/s10278-007-9043-6
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Ji ZX, 2015, INFORM SCIENCES, V301, P285, DOI 10.1016/j.ins.2015.01.006
   Jung H, 2009, MAGN RESON MED, V61, P103, DOI 10.1002/mrm.21757
   Keshavarzian R, 2016, AEU-INT J ELECTRON C, V70, P278, DOI 10.1016/j.aeue.2015.12.003
   Kundu M. K., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1457, DOI 10.1109/ICPR.2010.360
   Lavanya A, 2012, SADHANA-ACAD P ENG S, V37, P723, DOI 10.1007/s12046-012-0107-z
   Li CQ, 2011, SIGNAL PROCESS, V91, P949, DOI 10.1016/j.sigpro.2010.09.014
   Lin CH, 2010, LECT NOTES ARTIF INT, V6422, P278, DOI 10.1007/978-3-642-16732-4_30
   Liu XY, 2019, IEEE ACCESS, V7, P76580, DOI 10.1109/ACCESS.2019.2921894
   Liu YL, 2015, IEICE T INF SYST, VE98D, P769, DOI 10.1587/transinf.2014ICP0001
   Mothi R, 2019, MEASUREMENT, V136, P67, DOI 10.1016/j.measurement.2018.12.030
   Mousavi SM, 2015, J DIGIT IMAGING, V28, P417, DOI 10.1007/s10278-015-9770-z
   Nambakhsh MS, 2011, COMPUT METH PROG BIO, V104, P418, DOI 10.1016/j.cmpb.2010.08.016
   Pan W, 2018, COMPUT METH PROG BIO, V160, P119, DOI 10.1016/j.cmpb.2018.03.011
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Radwan AG, 2016, J ADV RES, V7, P193, DOI 10.1016/j.jare.2015.07.002
   Ramakrishnan S, 2011, CS IT, P155
   Rastegar S, 2011, AEU-INT J ELECTRON C, V65, P658, DOI 10.1016/j.aeue.2010.09.008
   Rayachoti E, 2020, CLUSTER COMPUT, V23, P3175, DOI 10.1007/s10586-020-03078-2
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   Singh P, 2017, AEU-INT J ELECTRON C, V76, P18, DOI 10.1016/j.aeue.2017.03.005
   Tan CK, 2011, J DIGIT IMAGING, V24, P528, DOI 10.1007/s10278-010-9295-4
   Tsougenis ED, 2012, J SYST SOFTWARE, V85, P1864, DOI 10.1016/j.jss.2012.02.045
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Wu JHK, 2008, J DIGIT IMAGING, V21, P59, DOI 10.1007/s10278-007-9011-1
   Yang Y, 2018, MULTIMED TOOLS APPL, V77, P18043, DOI 10.1007/s11042-017-4444-0
   Zain Jasni M, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P3270
   Zain JM, 2004, P ANN INT IEEE EMBS, V26, P3237
   Zhang XP, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P826, DOI 10.1109/ChinaSIP.2015.7230520
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhou YC, 2013, IEEE T CYBERNETICS, V43, P515, DOI 10.1109/TSMCB.2012.2210706
NR 51
TC 51
Z9 53
U1 1
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7167
EP 7186
DI 10.1007/s11042-020-09981-5
EA OCT 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000583943700003
DA 2024-07-18
ER

PT J
AU Kumari, N
   Bhatt, AK
   Dwivedi, RK
   Belwal, R
AF Kumari, Neeraj
   Kr. Bhatt, Ashutosh
   Kr. Dwivedi, Rakesh
   Belwal, Rajendra
TI Hybridized approach of image segmentation in classification of fruit
   mango using BPNN and discriminant analyzer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mango fruit grading; Enhanced fuzzy based K-means clustering algorithm;
   Texture; geometric and colour based features; Maximally correlated
   principal component analysis; Backpropagation based discriminant
   classifier
ID MATURITY; YIELD
AB In machine learning, image classification accuracy generally depends on image segmentation and feature extraction methods with the extracted features and its qualities. The main focus of this paper is to determine the defected area of mangoes using image segmentation algorithm for improving the classification accuracy. The Enhanced Fuzzy based K-means clustering algorithm is designed for increasing the efficiency of segmentation. Proposed segmentation method is compared with K-means and Fuzzy C-means clustering methods. The geometric, texture and colour based features are used in the feature extraction. Process of feature selection is done by Maximally Correlated Principal Component Analysis (MCPCA). Finally, in the classification step, severe portions of the affected area are analyzed by Backpropagation Based Discriminant Classifier (BBDC). Proposed classifier is compared with BPNN and Naive Bayes classifiers. The images are classified into three classes in final output like Class A -good quality mango, Class B-average quality mango, and Class C-poor quality mango. Finally, the evaluated results of the proposed model examine various defected and healthy mango images and prove that the proposed method has the highest accuracy when compared with existing methods.
C1 [Kumari, Neeraj] UK Tech Univ, Dehra Dun, Uttarakhand, India.
   [Kr. Bhatt, Ashutosh] Birla Inst, Bhimtal, India.
   [Kr. Dwivedi, Rakesh] TMU, CCSIT, Moradabad, India.
   [Belwal, Rajendra] Amrapali Inst Haldwani, Haldwani, India.
C3 Uttarakhand Technical University; Teerthanker Mahaveer University
RP Kumari, N (corresponding author), UK Tech Univ, Dehra Dun, Uttarakhand, India.
EM neerajkuamri01@outlook.com
RI Kumari, Neeraj/AAW-6113-2021; Kr DWIVEDI, PROF. RAKESH Kr/AAW-4239-2021
OI Kr DWIVEDI, PROF. RAKESH Kr/0000-0003-0745-9706
CR Agarwal A, 2019, P ICSICCS, P105
   Ahmed M, 2019, 2019 14TH IEEE INTERNATIONAL CONFERENCE ON DESIGN & TECHNOLOGY OF INTEGRATED SYSTEMS IN NANOSCALE ERA (DTIS 2019), DOI 10.1109/dtis.2019.8735046
   Al Ohali Y, 2011, J KING SAUD UNIV-COM, V23, P29, DOI 10.1016/j.jksuci.2010.03.003
   Awate A, 2015, 2015 International Conference on Green Computing and Internet of Things (ICGCIoT), P970, DOI 10.1109/ICGCIoT.2015.7380603
   Azarmdel H, 2020, POSTHARVEST BIOL TEC, V166, DOI 10.1016/j.postharvbio.2020.111201
   Behera Santi Kumari, 2019, Advances in Computer, Communication and Control. Proceedings of ETES 2018. Lecture Notes in Networks and Systems (LNNS 41), P469, DOI 10.1007/978-981-13-3122-0_47
   Bhange M, 2015, PROCEDIA COMPUT SCI, V58, P280, DOI 10.1016/j.procs.2015.08.022
   Bhatt AK, 2013, AI SOC, P45
   Bhatt AK, 2014, AI SOC, V29, P103, DOI 10.1007/s00146-012-0425-z
   Bielza C, 2003, COMPUT ELECTRON AGR, V39, P95, DOI 10.1016/S0168-1699(03)00021-8
   Blasco J, 2003, BIOSYST ENG, V85, P415, DOI 10.1016/S1537-5110(03)00088-6
   Dhakate M, 2015, NAT CONF COMPUT VIS
   Dorj UO, 2017, COMPUT ELECTRON AGR, V140, P103, DOI 10.1016/j.compag.2017.05.019
   Gavhale KR, 2014, IOSR journal of computer engineering (iosr-jce), V16, P10, DOI [DOI 10.9790/0661-16151016, 10.9790/0661-16151016]
   Geng Y, 2016, ESANN 2017 P, P589
   Gonzalez R.C., 2002, Digital Image Processing, V2nd
   Gurubelli Y, 2019, COMPUT ELECTRON AGR, V162, P95, DOI 10.1016/j.compag.2019.03.036
   Hung C, 2015, SPRINGER TRAC ADV RO, V105, P485, DOI 10.1007/978-3-319-07488-7_33
   Iqbal Z, 2018, COMPUT ELECTRON AGR, V153, P12, DOI 10.1016/j.compag.2018.07.032
   Kondo N, 2010, TRENDS FOOD SCI TECH, V21, P145, DOI 10.1016/j.tifs.2009.09.002
   Kumari N, 2018, PHYS PARAMETER EXTRA
   Lee DJ, 2011, IEEE T AUTOM SCI ENG, V8, P292, DOI 10.1109/TASE.2010.2087325
   Liang N, 2018, COMPUT ELECTRON AGR, V150, P134, DOI 10.1016/j.compag.2018.04.006
   Matteoli S, 2015, IEEE SENS J, V15, P5455, DOI 10.1109/JSEN.2015.2442337
   Momin M. A., 2017, Information Processing in Agriculture, V4, P150, DOI 10.1016/j.inpa.2017.03.003
   N Kumari, 2019, IJEAT, P1563
   Nambi VE, 2015, SCI HORTIC-AMSTERDAM, V193, P90, DOI 10.1016/j.scienta.2015.05.031
   Nandi CS, 2016, IEEE SENS J, V16, P6387, DOI 10.1109/JSEN.2016.2580221
   Pujari JD, 2015, PROCEDIA COMPUT SCI, V46, P1802, DOI 10.1016/j.procs.2015.02.137
   Qiao J, 2005, BIOSYST ENG, V90, P135, DOI 10.1016/j.biosystemseng.2004.10.002
   Ronald M., 2016, Ind. J. Comput. Sci. Eng. (IJCSE), V7, P13
   Sa'ad FSA, 2015, COMPUT ELECTRON AGR, V115, P51, DOI 10.1016/j.compag.2015.05.006
   Sajjad M, 2020, MOBILE NETW APPL, V25, P1611, DOI 10.1007/s11036-019-01366-9
   Sajjad M, 2018, MULTIMED TOOLS APPL, V77, P4769, DOI 10.1007/s11042-017-5010-5
   Vishnu S., 2015, Int. J. Innov. Sci., Eng. Technol., V2, P774
   Yan Z, 2018, J INTEGR AGR, V17, P994, DOI 10.1016/S2095-3119(17)61795-7
   Zhang G, 2017, INT C INT DAT ENG AU, P1
   Zhang GH, 2018, LECT NOTES ARTIF INT, V10956, P134, DOI 10.1007/978-3-319-95957-3_15
NR 38
TC 19
Z9 19
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 4943
EP 4973
DI 10.1007/s11042-020-09747-z
EA OCT 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000574727600003
DA 2024-07-18
ER

PT J
AU Kumar, V
   Girdhar, A
AF Kumar, Vijay
   Girdhar, Ashish
TI A 2D logistic map and Lorenz-Rossler chaotic system based RGB image
   encryption approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2D logistic map; DNA crypto system; Image encryption; Lorenz Rossler
   chaotic system
ID ALGORITHM; SCHEME; PERMUTATION; EFFICIENT
AB This paper presents a novel color image encryption approach. The proposed approach utilizes the basic concepts of DNA cryptography along with Lorenz and Rossler chaotic system and 2D logistic map. The proposed approach encrypts RGB images using DNA cryptography techniques. In diffusion phase, at pixel level Lorenz and Rossler chaotic system is used to encrypt the three channels of test images. Afterwards, at bit level 2D logistic map is used for performing bitwise chaotic ponytail process on these diffused Red, Green, and Blue channels in confusion phase. Simulation of the proposed approach on test images reveals that the color images have been encrypted very efficiently.
C1 [Kumar, Vijay] Natl Inst Technol, Comp Sci & Engn Dept, Hamirpur, Himachal Prades, India.
   [Girdhar, Ashish] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur; Thapar Institute of Engineering & Technology
RP Kumar, V (corresponding author), Natl Inst Technol, Comp Sci & Engn Dept, Hamirpur, Himachal Prades, India.
EM vijaykumarchahar@gmail.com
RI Chahar, Vijay Kumar/A-2782-2015
OI Chahar, Vijay Kumar/0000-0002-3460-6989
CR Alsafasfeh, 2011, CIRCUITS SYST, V2, P101, DOI DOI 10.4236/CS.2011.22015
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Amina S, 2018, COMMUN NONLINEAR SCI, V60, P12, DOI 10.1016/j.cnsns.2017.12.017
   [Anonymous], 2017, SIPI IMAGE DATABASE
   [Anonymous], 2017, IEEE STAND FLOAT POI
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Cao YY, 2008, International Conference on Intelligent Computation Technology and Automation, Vol 2, Proceedings, P104, DOI 10.1109/ICICTA.2008.397
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Elabady NF, 2015, ICET 2 INT C ENG TEC, P851
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Gao TG, 2006, INT J MOD PHYS C, V17, P471, DOI 10.1142/S0129183106008625
   Ghoneim A, 2018, IEEE COMMUN MAG, V56, P33, DOI 10.1109/MCOM.2018.1700817
   Girdhar A, 2019, J AMB INTEL HUM COMP, V10, P4947, DOI 10.1007/s12652-019-01179-4
   Girdhar A, 2018, MULTIMED TOOLS APPL, V77, P27017, DOI 10.1007/s11042-018-5902-z
   Golea Nour El-Houda, 2019, International Journal of High Performance Computing and Networking, V13, P199
   Gupta R., 2014, INT J COMPUTER APPL, V85, P27
   Gupta S, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P726
   Hu XC, 2020, IEEE ACCESS, V8, P12452, DOI 10.1109/ACCESS.2020.2965740
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Kadhim F.A., 2016, 2016 AL SADEQ INT C, P1
   Kumar A, 2019, INT J CLOUD APPL COM, V9, P22, DOI 10.4018/IJCAC.2019070102
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Kumar M, 2015, J INF SECUR APPL, V21, P20, DOI 10.1016/j.jisa.2014.11.003
   Li X, 2016, OPTIK, V127, P2558, DOI 10.1016/j.ijleo.2015.11.221
   Liu HJ, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P3016, DOI 10.1109/ICYCS.2008.449
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Del Rey AM, 2015, INT J MOD PHYS C, V26, DOI 10.1142/S0129183114500697
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mills AP, 1999, BIOSYSTEMS, V52, P175, DOI 10.1016/S0303-2647(99)00044-1
   Mishra DC, 2014, FRACTALS, V22, DOI 10.1142/S0218348X1450011X
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Musanna F, 2019, MULTIMED TOOLS APPL, V78, P14867, DOI 10.1007/s11042-018-6827-2
   Nien HH, 2007, CHAOS SOLITON FRACT, V32, P1070, DOI 10.1016/j.chaos.2005.11.057
   Niu Y, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/4079793
   Niyat A, 2015, INT C TECHN C KNOWL
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Ping P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P429, DOI 10.1109/ICInfA.2015.7279326
   Ping P, 2013, INT J MOD PHYS C, V24, DOI 10.1142/S012918311350071X
   Qi DX, 2000, SCI CHINA SER E, V43, P304, DOI 10.1007/BF02916835
   Radwan AG, 2016, J ADV RES, V7, P193, DOI 10.1016/j.jare.2015.07.002
   Ramírez-Torres MT, 2014, INT J MOD PHYS C, V25, DOI 10.1142/S0129183114500545
   Saranya MR, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P1022, DOI 10.1109/IC3I.2014.7019805
   Saranya MR, 2015, SIGN PROC INF COMM E, P1
   Srivastava N., 2017, INT C WIR COMM SIGN, DOI [10.1109/ICRAIE.2016.7939542, DOI 10.1109/ICRAIE.2016.7939542]
   Wang LY, 2016, OPT LASER ENG, V77, P118, DOI 10.1016/j.optlaseng.2015.07.015
   Wang XY, 2016, OPT LASER ENG, V82, P79, DOI 10.1016/j.optlaseng.2015.12.006
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Ye RS, 2011, OPT COMMUN, V284, P5290, DOI 10.1016/j.optcom.2011.07.070
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhang Q, 2013, IETE TECH REV, V30, P404, DOI 10.4103/0256-4602.123123
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu Z, 2020, IEEE PHOTONICS J, V12, DOI 10.1109/JPHOT.2020.2981494
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
   Zou CY, 2020, IEEE ACCESS, V8, P75728, DOI 10.1109/ACCESS.2020.2988880
NR 70
TC 43
Z9 43
U1 1
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3749
EP 3773
DI 10.1007/s11042-020-09854-x
EA SEP 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572601100002
DA 2024-07-18
ER

PT J
AU Asaker, AA
   Elsharkawy, ZF
   Nassar, S
   Ayad, N
   Zahran, O
   Abd El-Samie, FE
AF Asaker, Ahmed A.
   Elsharkawy, Zeinab F.
   Nassar, Sabry
   Ayad, Nabil
   Zahran, O.
   Abd El-Samie, Fathi E.
TI A novel cancellable Iris template generation based on salting approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Iris recognition; IrisCode; Cancellable biometrics; Advanced
   encryption standard (AES); Cover pattern; Hamming distance; Receiver
   operating characteristic (ROC) curve
ID BIOMETRICS SCHEME; RECOGNITION; FILTERS
AB The iris has been vastly recognized as one of the powerful biometrics in terms of recognition performance, both theoretically and empirically. However, traditional unprotected iris biometric recognition schemes are highly vulnerable to numerous privacy and security attacks. Several methods have been proposed to generate cancellable iris templates that can be used for recognition; however, these templates achieve lower accuracy of recognition in comparison to traditional unprotected iris templates. In this paper, a novel cancellable iris recognition scheme based on the salting approach is introduced. It depends on mixing the original binary iris code with a synthetic pattern using XOR operation. This scheme guarantees a high degree of privacy/security preservation without affecting the performance accuracy compared to the unprotected traditional iris recognition schemes. Comprehensive experiments on various iris image databases demonstrate similar accuracy to those of the original counterparts. Hence, robustness to several major privacy/security attacks is guaranteed.
C1 [Asaker, Ahmed A.; Nassar, Sabry; Ayad, Nabil] Egyptian Atom Energy Author, Nucl Res Ctr, Reactors Dept, Cairo, Egypt.
   [Elsharkawy, Zeinab F.] Egyptian Atom Energy Author, Nucl Res Ctr, Engn Dept, Cairo, Egypt.
   [Zahran, O.; Abd El-Samie, Fathi E.] Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
   [Abd El-Samie, Fathi E.] Princess Nourah Bint Abdulrahman Univ, Dept Informat Technol, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Egyptian Atomic Energy Authority (EAEA);
   Egyptian Knowledge Bank (EKB); Egyptian Atomic Energy Authority (EAEA);
   Egyptian Knowledge Bank (EKB); Menofia University; Princess Nourah bint
   Abdulrahman University
RP Elsharkawy, ZF (corresponding author), Egyptian Atom Energy Author, Nucl Res Ctr, Engn Dept, Cairo, Egypt.
EM ahmad.asaker@gmail.com; zeinab_elsharkawy@yahoo.com;
   sabrynassar39@gmail.com; n_ayad51@yahoo.com;
   osama_zahran@el-eng.menofia.edu.eg; fathi_sayed@yahoo.com
RI Sayed, Fathi/HRA-4752-2023
OI Sayed, Fathi/0000-0001-8749-9518; , ahmed/0000-0002-6725-9952;
   Elsharkawy, Zeinab/0000-0002-6167-8435
CR Aeloor D, 2013, SECURING BIOMETRIC D
   Afifi M, 2019, MULTIMED TOOLS APPL, V78, P20835, DOI 10.1007/s11042-019-7424-8
   Al Saqqa S, 2013, J AM SCI
   [Anonymous], 2008, IEEE 19 INT C PATT R
   Choudhury B, 2016, IEEE ST CONF RES DEV
   Daemen J, 2002, TECH REP
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Dwivedi R, 2015, CANCELABLE IRIS TEMP
   Essam M, 2012, IEEE JAP EG C EL COM
   Ghoradkar S, 2015, INT J COMPUTER APPL, pNational
   Hämmerle-Uhl J, 2009, LECT NOTES COMPUT SC, V5735, P135, DOI 10.1007/978-3-642-04474-8_11
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jegede A, 2018, PERTANIKA J SCI TECH, V26, P133
   Jing D, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P1156, DOI 10.1109/ICARCV.2008.4795684
   Khan MK, 2004, PROTECTING BIOMETRIC
   Lai YL, 2017, PATTERN RECOGN, V64, P105, DOI 10.1016/j.patcog.2016.10.035
   Lee D-H, 2018, 24 INT C PATT REC IC
   Lim S, 2001, ETRI J, V23, P61, DOI 10.4218/etrij.01.0101.0203
   Liu Y, 2017, FINGER VEIN SECURE B
   Nalavade R, 2012, INT J SCI RES PUBL, V2
   Ortega M., 2006, Proc. of the 5th WSEAS International Conference on Applied Computer Science, P422
   Ouda O, 2010, IEICE T INF SYST, VE93D, P1878, DOI 10.1587/transinf.E93.D.1878
   Patel V. M., 2015, IEEE SIGNAL PROCESSI
   Pillai JK, 2011, IEEE T PATTERN ANAL, V33, P1877, DOI 10.1109/TPAMI.2011.34
   Randa FSoliman, 2018, MODIFIED CANCELABLE, DOI 10.1007/s40745-018-0172-1
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Rathgeb C, 2015, INT CONF BIOMETR, P422, DOI 10.1109/ICB.2015.7139105
   Rathgeb C, 2014, IET BIOMETRICS, V3, P207, DOI 10.1049/iet-bmt.2013.0049
   Savvides M, 2004, INT C PATT RECOG, P922, DOI 10.1109/ICPR.2004.1334679
   Selvapandian A, 2018, COMPUT METH PROG BIO, V166, P33, DOI 10.1016/j.cmpb.2018.09.006
   Soliman R, 2018, APPL OPT, V57
   Soliman R, 2018, P NATL ACAD SCI IN A
   Soliman RF, 2019, MIXING IRIS CODES
   Tarek Mayada, 2017, International Journal of Network Security, V19, P498, DOI 10.6633/IJNS.201707.19(4).02
   Tarek M, 2016, IET BIOMETRICS, V5, P220, DOI 10.1049/iet-bmt.2015.0045
   Umer S, 2017, INFORM SCIENCES, V406, P102, DOI 10.1016/j.ins.2017.04.026
   Wen W, 2008, COMPUTER APPL PETROL, V16
   Zhao D, 2018, HINDAWI SECURITY COM, V2018
NR 39
TC 8
Z9 9
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3703
EP 3727
DI 10.1007/s11042-020-08663-6
EA SEP 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572335600006
DA 2024-07-18
ER

PT J
AU Bao, JQ
   Lai, ZH
   Li, XC
AF Bao, Jiaqi
   Lai, Zhihui
   Li, Xuechen
TI Relaxed local preserving regression for image feature extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image feature extraction; Label relaxation; Linear least regression
   (LSR); Manifold learning
ID LINEAR DISCRIMINANT-ANALYSIS; LEAST-SQUARES REGRESSION; FACE
   RECOGNITION; ILLUMINATION; FRAMEWORK
AB The latest linear least regression (LSR) methods improved the performance of image feature extraction effectively by relaxing strict zero-one labels as slack forms. However, these methods have the following three disadvantages: 1) LSR-based methods are sensitive to the noises and may lose effectiveness in feature extraction task; 2) they only focus on the global structures of data, but ignore locality which is important to improve the performance; 3) they suffer from small-class problem, which means the number of projections learned by methods is limited by the number of classes. To address these problems, we propose a novel method called Relaxed Local Preserving Regression (RLPR) for image feature extraction. By incorporating the relaxed label matrix and similarity graph-based regularization term, RLPR can not only explore the latent structure information of data, but also solve the small-class problem. In order to enhance the robustness to noises, we further proposed an extended version of RLPR based onl(2, 1)-norm, termed as ERLPR. The experimental results on image databases consistently show that the recognition rates of RLPR and ERLPR are superior to the compared methods and can achieve 98% in normal cases. Especially, even on the corrupted databases, the proposed methods can also achieve the classification accuracy of more than 58%.
C1 [Bao, Jiaqi; Lai, Zhihui; Li, Xuechen] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
   [Lai, Zhihui] Hong Kong Polytech Univ, Inst Text & Clothing, Hong Kong, Peoples R China.
C3 Shenzhen University; Hong Kong Polytechnic University
RP Lai, ZH (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.; Lai, ZH (corresponding author), Hong Kong Polytech Univ, Inst Text & Clothing, Hong Kong, Peoples R China.
EM lai_zhi_hui@163.com
RI Lai, Zhihui/R-1000-2019
OI Lai, Zhihui/0000-0002-4388-3080
FU Natural Science Foundation of China [61802267, 61773328, 61732011,
   61703283]; Shenzhen Municipal Science and Technology Innovation Council
   [JCYJ20180305124834854, JCYJ20190813100801664]
FX This work was supported in part by the Natural Science Foundation of
   China (Grant 61802267, Grant 61773328, Grant 61732011 and Grant
   61703283), and in part by the Shenzhen Municipal Science and Technology
   Innovation Council under Grant JCYJ20180305124834854 and
   JCYJ20190813100801664.
CR [Anonymous], 2009, P 26 ANN INT C MACH, DOI DOI 10.1145/1553374.1553388
   Bertsekas D. P., 2003, CONVEX ANAL OPTIMIZA
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Campos TE, 2009, VISAPP
   Cheng L, 2018, CCC
   De la Torre F, 2012, IEEE T PATTERN ANAL, V34, P1041, DOI 10.1109/TPAMI.2011.184
   Deng T, 2016, ICNC FSKD
   Ebied RM, 2012, INFOS
   Fang XZ, 2018, IEEE T NEUR NET LEAR, V29, P1006, DOI 10.1109/TNNLS.2017.2648880
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gui J, 2014, IJCB
   Han L, 2018, NEUROCOMPUTING, V275, P888, DOI 10.1016/j.neucom.2017.08.070
   Han N, 2020, IEEE T CIRC SYST VID, V30, P307, DOI 10.1109/TCSVT.2018.2890511
   He X, 2010, NEURAL INF PROCESS S, V16, P153
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Huang GS, 2007, 2007 7TH IEEE CONFERENCE ON NANOTECHNOLOGY, VOL 1-3, P7, DOI 10.1109/NANO.2007.4601129
   Keyhanian S, 2014, BIHTEL
   Leng L, 2012, ICWAPR
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li CN, 2019, NEUROCOMPUTING, V337, P80, DOI 10.1016/j.neucom.2019.01.049
   Liang ZZ, 2013, PATTERN RECOGN LETT, V34, P1037, DOI 10.1016/j.patrec.2013.01.030
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu H, 2017, SMARTCOMP
   Liu JX, 2016, IEEE T NANOBIOSCI, V15, P510, DOI 10.1109/TNB.2016.2574923
   Liu X, 2007, ICIP
   Lu GF, 2016, PATTERN RECOGN, V55, P207, DOI 10.1016/j.patcog.2016.01.029
   Martinez AA, 1998, AR FACT DATABASE
   Okfalisa, 2017, ICITISEE
   Pan H, 2018, IHMSC
   Pan JY, 2011, PATTERN RECOGN LETT, V32, P1822, DOI 10.1016/j.patrec.2011.07.015
   Phillips PJ, 1997, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.1997.609311
   Shao S., 2019, P INT C ARTIFICIAL I, P100
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Wang HB, 2016, NEUROCOMPUTING, V216, P286, DOI 10.1016/j.neucom.2016.07.044
   Wang L, 2017, ICASSP
   Wang LF, 2016, IEEE T NEUR NET LEAR, V27, P2711, DOI 10.1109/TNNLS.2015.2477826
   Wang N, 2014, MULTIMED TOOLS APPL, V72, P2339, DOI 10.1007/s11042-013-1551-4
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiang SM, 2012, IEEE T NEUR NET LEAR, V23, P1738, DOI 10.1109/TNNLS.2012.2212721
   Xu JH, 2018, NEUROCOMPUTING, V275, P107, DOI 10.1016/j.neucom.2017.05.008
   Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421
   Ye QL, 2018, IEEE T CIRC SYST VID, V28, P114, DOI 10.1109/TCSVT.2016.2596158
   Yi SY, 2017, PATTERN RECOGN, V61, P524, DOI 10.1016/j.patcog.2016.08.025
   Yin M, 2016, IEEE T PATTERN ANAL, V38, P504, DOI 10.1109/TPAMI.2015.2462360
   Zhang R, 2018, NEUROCOMPUTING, V273, P547, DOI 10.1016/j.neucom.2017.07.064
   Zhao HF, 2016, NEUROCOMPUTING, V216, P200, DOI 10.1016/j.neucom.2016.07.037
   Zheng YL, 2013, NEUROCOMPUTING, V103, P149, DOI 10.1016/j.neucom.2012.09.015
   Zhong FJ, 2013, IEEE T IMAGE PROCESS, V22, P3018, DOI 10.1109/TIP.2013.2253476
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 51
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3729
EP 3748
DI 10.1007/s11042-020-09802-9
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572335600001
DA 2024-07-18
ER

PT J
AU Ghosh, M
   Ghosh, KK
   Bhowmik, S
   Sarkar, R
AF Ghosh, Manosij
   Ghosh, Kushal Kanti
   Bhowmik, Showmik
   Sarkar, Ram
TI Coalition game based feature selection for text non-text separation in
   handwritten documents using LBP based features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Coalition game; Feature selection; Text non-text classification; LBP;
   Texture feature; Handwritten document
ID CLASSIFICATION; IDENTIFICATION
AB Text non-text classification is an important research problem in the domain of document image processing. Undesirably, this is an almost ignored research topic, particularly, when we consider the unconstrained offline handwritten document images. For text non-text classification, many times researchers employ high dimensional feature vectors, which not only increase the computation time and storage requirement, but also reduce the classification accuracy due to the presence of redundant or irrelevant features. Here lies the application of some feature selection (FS) algorithms in order to find out the relevant subset of the features from the original feature vector. In this paper, our aim is two-fold. Firstly, application of coalition game based FS technique to find out an optimal feature subset for classifying the components present in a handwritten document image either as text or non-text. Secondly, five variants of a popular texture based feature descriptor, called Local Binary Pattern (LBP), along with its basic version are fed to the FS module for identifying the useful patterns only which can pinpoint the regions of an image as most informative in terms of the said classification task. To the best of our knowledge, the approach is completely novel where coalition game based FS technique is applied for locating the feature-rich regions to be used for text non-text classification. For experimentation, we have prepared an in-house dataset along with its ground truth information which consists of 104 handwritten engineering class notes as well as laboratory copies that include handwritten and printed texts, graphical components and tables etc. Experimental outcomes confirm that the proposed approach not only helps in reducing the feature dimension significantly but also increases the recognition ability of all six feature vectors.
C1 [Ghosh, Manosij; Ghosh, Kushal Kanti; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Bhowmik, Showmik] Ghani Khan Choudhury Inst Engn & Technol GKCIET, Dept Comp Sci & Engn, Malda, India.
C3 Jadavpur University
RP Bhowmik, S (corresponding author), Ghani Khan Choudhury Inst Engn & Technol GKCIET, Dept Comp Sci & Engn, Malda, India.
EM manosij1996@gmail.com; kushalkanti1999@gmail.com; showmik.cse@gmail.com;
   raamsarkar@gmail.com
RI Sarkar, Ram/AAX-3822-2020; Bhowmik, Showmik/M-4248-2017
OI Sarkar, Ram/0000-0001-8813-4086; Bhowmik, Showmik/0000-0003-3971-5807;
   Ghosh, Kushal Kanti/0000-0003-0929-5928
CR [Anonymous], 2005, ADV NEURAL INF PROCE
   [Anonymous], BICH ONL TAG VAR
   Ben Brahim A, 2016, PATTERN RECOGN LETT, V69, P28, DOI 10.1016/j.patrec.2015.10.005
   Benesty J, 2009, SPRINGER TOP SIGN PR, V2, P1, DOI 10.1007/978-3-642-00296-0_1
   Bhowmik S, 2018, INT J DOC ANAL RECOG, V21, P1, DOI 10.1007/s10032-018-0296-z
   Bhowmik S, 2017, ADV INTELL SYST, V458, P507, DOI 10.1007/978-981-10-2035-3_52
   Bommert A, 2020, COMPUT STAT DATA AN, V143, DOI 10.1016/j.csda.2019.106839
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chatterjee I, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12459
   Chen YL, 2009, PATTERN RECOGN, V42, P1419, DOI 10.1016/j.patcog.2008.10.032
   Chowdhury SP, 2007, PROC INT CONF DOC, P619
   Cohen Rafi., 2013, P 2 INT WORKSHOP HIS, P110, DOI DOI 10.1145/2501115.2501117
   Davis JohnC., 1986, Statistics and Data Analysis in Geology, V2nd
   Delaye A, 2014, PATTERN RECOGN, V47, P959, DOI 10.1016/j.patcog.2013.04.017
   Forman G., 2003, Journal of Machine Learning Research, V3, P1289, DOI 10.1162/153244303322753670
   Ghosh Manosij, 2018, Intelligent Engineering Informatics. Proceedings of the 6th International Conference on FICTA. Advances in Intelligent Systems and Computing (AISC 695), P471, DOI 10.1007/978-981-10-7566-7_46
   Ghosh M, 2019, MED BIOL ENG COMPUT, V57, P159, DOI 10.1007/s11517-018-1874-4
   Ghosh S, 2018, J IMAGING, V4, DOI 10.3390/jimaging4040057
   Guha R, 2021, EVOL INTELL, V14, P357, DOI 10.1007/s12065-019-00218-5
   Guyon I, 2006, STUD FUZZ SOFT COMP, V207, P1
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Haritaoglu I, 2005, P 2001 IEEE COMPUTER, V2
   HARWOOD D, 1995, PATTERN RECOGN LETT, V16, P1, DOI 10.1016/0167-8655(94)00061-7
   Hongliang Jin, 2004, Proceedings. Third International Conference on Image and Graphics, P306
   Kavitha AS, 2016, EGYPT INFORM J
   KIRA K, 1992, MACHINE LEARNING /, P249
   Malakar S, 2020, NEURAL COMPUT APPL, V32, P2533, DOI 10.1007/s00521-018-3937-8
   Mortazavi Atiyeh, 2016, Advances in Bioinformatics, V2016, P1058305, DOI 10.1155/2016/1058305
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oyedotun OK, 2016, APPL INTELL, V45, P198, DOI 10.1007/s10489-015-0753-z
   Radovic M, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-016-1423-9
   Sah AK, 2017, 2017 IEEE CALCUTTA CONFERENCE (CALCON), P64, DOI 10.1109/CALCON.2017.8280697
   Sarkar R, 2011, ICIIP 2011 P 2011 IN, DOI [10.1109/ICIIP.2011.6108921, DOI 10.1109/ICIIP.2011.6108921]
   Shang WQ, 2007, EXPERT SYST APPL, V33, P1, DOI 10.1016/j.eswa.2006.04.001
   Singh PK, 2018, J INTELL SYST, V27, P465, DOI 10.1515/jisys-2016-0070
   Sun X, 2012, NEUROCOMPUTING, V97, P86, DOI 10.1016/j.neucom.2012.05.001
   Sun X, 2012, PATTERN RECOGN, V45, P2992, DOI 10.1016/j.patcog.2012.02.001
   Vergara JR, 2014, NEURAL COMPUT APPL, V24, P175, DOI 10.1007/s00521-013-1368-0
   Le VP, 2015, PROC INT CONF DOC, P1096, DOI 10.1109/ICDAR.2015.7333930
   Wang AG, 2018, KNOWL-BASED SYST, V146, P104, DOI 10.1016/j.knosys.2018.01.025
   Wang ZL, 2016, IEEE SENS J, V16, P3198, DOI 10.1109/JSEN.2016.2519679
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Witten IH, 2011, MOR KAUF D, P1
   Zagoris K, 2011, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2011-47
NR 44
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 3229
EP 3249
DI 10.1007/s11042-020-09844-z
EA SEP 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000571253200001
DA 2024-07-18
ER

PT J
AU Yadav, VK
   Verma, S
   Venkatesan, S
AF Yadav, Vijay Kumar
   Verma, Shekhar
   Venkatesan, S.
TI An efficient and light weight polynomial multiplication for ideal
   lattice-based cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fast fourier transform; Discrete cosine transformation; Number theoretic
   transform; Lattice-based cryptography; Ring-learning with errors
ID FAST FOURIER-TRANSFORM; SYMMETRIC CONVOLUTION; DISCRETE; ALGORITHM;
   SCHEME
AB Ring-Learning With Errors (Ring-LWE) based cryptographic schemes such as signature, key exchange, and encryption require polynomial multiplication. This multiplication operation is the most time consuming and computationally rigorous process in Ring-LWE. In order to improve the efficiency of the Ring-LWE based schemes, most of the existing schemes use Fast Fourier Transform (FFT) based polynomial multiplication algorithm. It is known that Discrete Sine Transformation (DST) and Discrete Cosine Transformation (DCT) are faster than the FFT. The combination of DCT and DST is Discrete Trigonometric Transform (DTT). When we generalize DTT in terms of FFT form, it becomes Generalized Discrete Fourier Transform (GDFT). In this paper, we propose two new polynomial multiplication techniques using DTT and GDFT. When we applycircular convolutionandskew-circular convolutionon DTT or GDFT for the polynomial multiplication, it gives us wrong results. To overcome this issue, we usesymmetric convolutionoperation on DTT and GDFT. We implemented and compared the proposed polynomial multiplication schemes with the current state-of-the-art schemes in terms of computation and communication costs. The implementation results show that the proposed schemes DTT and GDFT perform more efficiently as compared to current state-of-the-art schemes in terms of computation and communication costs.
C1 [Yadav, Vijay Kumar; Verma, Shekhar; Venkatesan, S.] Indian Inst Informat Technol Allahabad Devghat, Allahabad 211015, UP, India.
C3 Indian Institute of Information Technology Allahabad
RP Yadav, VK (corresponding author), Indian Inst Informat Technol Allahabad Devghat, Allahabad 211015, UP, India.
EM pcl2014002@iiita.ac.in; sverma@iiita.ac.in; venkat@iiita.ac.in
RI Yadav, Vijay Kumar/AAJ-7584-2021
OI Yadav, Vijay Kumar/0000-0002-6139-7350; Verma,
   Shekhar/0000-0003-3460-2707
CR Akleylek Sedat, 2016, Progress in Cryptology (AFRICACRYPT 2016). 8th International Conference in Cryptology. Proceedings: LNCS 9646, P44, DOI 10.1007/978-3-319-31517-1_3
   Alkim E, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P327
   Bai S, 2018, J CRYPTOL, V31, P610, DOI 10.1007/s00145-017-9265-9
   Bos JW, 2015, P IEEE S SECUR PRIV, P553, DOI 10.1109/SP.2015.40
   Brakerski Zvika, 2014, ACM Transactions on Computation Theory, V6, DOI 10.1145/2633600
   Britaak V, 2012, COMPUT INFORM, V17, P583
   Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   Cheng LZ, 2001, ELECTRON LETT, V37, P64, DOI 10.1049/el:20010060
   COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354
   Ding Jintai., 2012, IACR Cryptology ePrint Archive, V2012, P688
   Ducas L, 2013, LECT NOTES COMPUT SC, V8042, P40, DOI 10.1007/978-3-642-40041-4_3
   Dworkin M.J, 2015, Federal Information Processing Standards, DOI [DOI 10.6028/NIST.FIPS.202, 10.6028/NIST.FIPS.202]
   Foltz TM, 1999, IEEE T IMAGE PROCESS, V8, P640, DOI 10.1109/83.760312
   Gentleman W. M., 1966, P AFIPS FALL JOINT C, P563, DOI DOI 10.1145/1464291.1464352
   Harvey D, 2014, J SYMB COMPUT, V60, P113, DOI 10.1016/j.jsc.2013.09.002
   Hoffstein J., 1998, Algorithmic Number Theory. Third International Symposium, ANTS-III. Proceedings, P267, DOI 10.1007/BFb0054868
   HUNT BR, 1971, IEEE T ACOUST SPEECH, VAU19, P285, DOI 10.1109/TAU.1971.1162202
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jiang ZR, 1994, FAST ALGORITHMS
   LEE BG, 1984, IEEE T ACOUST SPEECH, V32, P1243
   Lindner R, 2011, LECT NOTES COMPUT SC, V6558, P319, DOI 10.1007/978-3-642-19074-2_21
   Longa P, 2016, LECT NOTES COMPUT SC, V10052, P124, DOI 10.1007/978-3-319-48965-0_8
   Lynbashevsky V, 2010, LECT NOTES COMPUT SC, V6110, P1, DOI 10.1145/2535925
   Lyubashevsky V, 2008, LECT NOTES COMPUT SC, V5086, P54
   Lyubashevsky V, 2012, LECT NOTES COMPUT SC, V7237, P738, DOI 10.1007/978-3-642-29011-4_43
   Ma C, 1988, P SPIE INT SOC OPT E, V1002, P541
   MALVAR HS, 1990, IEEE T ACOUST SPEECH, V38, P969, DOI 10.1109/29.56057
   MARTUCCI SA, 1994, IEEE T SIGNAL PROCES, V42, P1038, DOI 10.1109/78.295213
   Peikert C, 2014, LECT NOTES COMPUT SC, V8772, P197, DOI 10.1007/978-3-319-11659-4_12
   Pöppelmann T, 2015, LECT NOTES COMPUT SC, V9230, P346, DOI 10.1007/978-3-319-22174-8_19
   POLLARD JM, 1971, MATH COMPUT, V25, P365
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Regev O, 2009, J ACM, V56, DOI 10.1145/1568318.1568324
   Roy SS, 2014, LECT NOTES COMPUT SC, V8731, P371, DOI 10.1007/978-3-662-44709-3_21
   Seo H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072039
   Shoup V, 2003, NUMBER THEORY C LIB
   Stehlé D, 2011, LECT NOTES COMPUT SC, V6632, P27, DOI 10.1007/978-3-642-20465-4_4
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Tran TD, 2000, IEEE SIGNAL PROC LET, V7, P141, DOI 10.1109/97.844633
   VERNET JL, 1971, PR INST ELECTR ELECT, V59, P1531, DOI 10.1109/PROC.1971.8471
   Wu FG, 2019, MULTIMED TOOLS APPL, V78, P3511, DOI 10.1007/s11042-018-6330-9
   Yang Y, 2018, MULTIMED TOOLS APPL, V77, P9927, DOI 10.1007/s11042-017-4560-x
   Zeng YH, 2001, IEEE T SIGNAL PROCES, V49, P2774, DOI 10.1109/78.960425
   Zhang J, 2015, LECT NOTES COMPUT SC, V9057, P719, DOI 10.1007/978-3-662-46803-6_24
NR 44
TC 7
Z9 7
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 3089
EP 3120
DI 10.1007/s11042-020-09706-8
EA SEP 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000571253200007
DA 2024-07-18
ER

PT J
AU Khan, S
   Abbas, N
   Nasir, M
   Haseeb, K
   Saba, T
   Rehman, A
   Mehmood, Z
AF Khan, Saira
   Abbas, Naveed
   Nasir, Mansoor
   Haseeb, Khalid
   Saba, Tanzila
   Rehman, Amjad
   Mehmood, Zahid
TI Steganography-assisted secure localization of smart devices in internet
   of multimedia things (IoMT)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Information security; Image quality; LSB; Visual
   sensor network (VSN); Secret key; Embedding
ID IMAGES; SUBSTITUTION
AB Steganography is a secure way of communicating secret visual data/information from one place to another via multimedia carriers. Digital steganography, spatial and frequency domain has taken several methods over the past two decades. In this work, we present steganography-assisted secure localization of smart devices for Visual Sensor Network (VSN). The proposed system is based on achromatic-component (Y-Plane) of the YCbCr color space and maximum likelihood estimation algorithm (MLEA) in the spatial domain. Data/information security via multimedia carriers is the main concern in this technological era, if secret information is captured by a Visual Sensor network, (VSN) then the capture information in the case to send from one place to another needs fundamental security to keep the information confidential. In the proposed steganography-assisted Visual Sensor Network (VSN) the camera nodes are intelligent to process the image data and to extract the important information and the rich-description are provided to the system's user for further action. In the proposed technique first, the input image is rotated on 90 degrees and transformed into YCbCr color space. Furthermore, the secret data is separated into different blocks of the same size based on key giving sub-blocks in Y-Plane, secret information is then encrypted using an MLE algorithm (MLEA) and the corresponding blocks of secret data is embedded in the sub-image of Y-Plane. The experimental results authenticate that the proposed technique does not only boost the visual quality of stegno-images but also delivers good imperceptibility, robustness, and security as compared to state-of-the-art approaches.
C1 [Khan, Saira; Abbas, Naveed; Nasir, Mansoor; Haseeb, Khalid] Islamia Coll Peshawar, Dept Comp Sci, Peshawar 25120, Pakistan.
   [Saba, Tanzila; Rehman, Amjad] Prince Sultan Univ, Artificial Intelligence & Data Analyt Lab CCIS, Riyadh 11586, Saudi Arabia.
   [Mehmood, Zahid] Univ Engn & Technol, Dept Comp Engn, Taxila 47050, Pakistan.
C3 University of Peshawar; Prince Sultan University; University of
   Engineering & Technology Taxila
RP Rehman, A (corresponding author), Prince Sultan Univ, Artificial Intelligence & Data Analyt Lab CCIS, Riyadh 11586, Saudi Arabia.
EM arkhan@psu.edu.sa
RI Abbas, Naveed/JAV-9478-2023; Haseeb/J-5472-2017; Rehman,
   Amjad/GXV-0915-2022; Saba, Tanzila/D-4593-2018; Mehmood, Dr.
   Zahid/S-1709-2018
OI Abbas, Naveed/0000-0003-1204-250X; Rehman, Amjad/0000-0002-3817-2655;
   Saba, Tanzila/0000-0003-3138-3801; Mehmood, Dr.
   Zahid/0000-0003-4888-2594
FU Artificial Intelligence and Data Analytics (AIDA) Lab CCIS Prince Sultan
   University Riyadh Saudi Arabia
FX This work is partially supported by Artificial Intelligence and Data
   Analytics (AIDA) Lab CCIS Prince Sultan University Riyadh Saudi Arabia.
   The authors are thankful for the support.
CR Agaian SosS., 2006, Electronic Imaging 2006
   Agaian SS, 2004, NEW PIXEL SORTING ME
   Ahmad Kaisar, 2019, STAT METHODOLOGIES
   Al Ameen M, 2012, J MED SYST, V36, P93, DOI 10.1007/s10916-010-9449-4
   [Anonymous], 2015, ISL CAP MARK PRINC
   Baroffio L, 2015, 2015 IEEE 2 WORLD FO
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Chen WX, 2016, COMMUN STAT-SIMUL C, V45, P2232, DOI 10.1080/03610918.2014.904520
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Gonzalez R., 2002, WOODS DIGITAL IMAGE
   Grover N, 2013, 2013 2 INT C ADV COM
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Hassan A, 2008, GOOGLE PATENTS
   Hassanalieragh M, 2015, 2015 IEEE INT C SERV
   Hiary S, 2015, MULTIMED TOOLS APPL, P1
   Hossain Ismail, 2011, 14 INT C COMP INF TE
   Jafar IF, 2016, J VISUAL COMMUNICATI
   Jafar I, 2008, INTEGR COMPUT-AID E, V15, P131
   Lou DC, 2002, COMPUT SECUR, V21, P449, DOI 10.1016/S0167-4048(02)00515-1
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Mostafa G, 2019, INT SYM NETWO COMP
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Mundher M, 2014, APPL MATH INFORM SCI, V8, P2823, DOI 10.12785/amis/080618
   Qu ZG, 2019, MULTIMED TOOLS APPL, V78, P7981, DOI 10.1007/s11042-018-6476-5
   Rehman A, 2019, J INF SCI, V45, P767, DOI 10.1177/0165551518816303
   Sajjad M, 2014, SENSORS-BASEL, V14, P3652, DOI 10.3390/s140203652
   Soro S, 2009, ADV MULTIMED, V2009, DOI 10.1155/2009/640386
   Wang H-S, 2004, CHINA RAILWAY SCI, V5
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Yang F, 2019, MATH PROBL ENG, V2019
NR 35
TC 6
Z9 6
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17045
EP 17065
DI 10.1007/s11042-020-09652-5
EA SEP 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000570041000002
DA 2024-07-18
ER

PT J
AU Chen, CJ
   Huang, HN
   Tu, SY
   Lin, CH
   Chen, ST
AF Chen, Chur-Jen
   Huang, Huang-Nan
   Tu, Shu-Yi
   Lin, Che-Hao
   Chen, Shuo-Tsung
TI Digital audio watermarking using minimum-amplitude scaling on optimized
   DWT low-frequency coefficients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; Wavelet; SNR; BER; Minimum-amplitude
ID DECOMPOSITION; ROBUST
AB This work presents an audio watermarking scheme using minimum-amplitude scaling on the optimized lowest-frequency coefficients in the wavelet domain. Signal-to-noise ratio (SNR), bit-error-rate (BER) and Perceptual Evaluation of Audio Quality (PEAQ) are commonly utilized performance indexes in measuring the fidelity, robustness and quality of watermarking algorithms. However, there is a tradeoff relationship between audio quality and robustness. To overcome the drawback, this paper aims in proposing an optimization-based scaling scheme using optimal modification of low-frequency amplitude in the wavelet domain. A function connecting the multi-coefficients, composed of arbitrary scaling on the lowest DWT coefficients, and the group SNR of these coefficient is derived. Karush-Kuhn-Tucker (KKT) theorem and minimum length play two essential roles to obtain the optimal modification of low-frequency amplitude with optimal scaling factors. Furthermore, the almost invariant feature of these optimized scaling factors hold demonstrates resistance to amplitude modification manipulation. To practically evaluate the watermarked audio quality, an objective measurement using the PEAQ is also performed as well. Experimental results confirm that the embedded audio in the proposed method has high SNR, low BER, and good PEAQ, indicating strong robustness against various attacks, such as re-sampling, amplitude modification, and mp3 compression.
C1 [Chen, Chur-Jen; Huang, Huang-Nan; Lin, Che-Hao] Tunghai Univ, Dept Appl Math, Taichung 40704, Taiwan.
   [Tu, Shu-Yi] Univ Michigan, Dept Math, Flint, MI 48502 USA.
   [Chen, Shuo-Tsung] Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Touliu 64002, Yunlin, Taiwan.
C3 Tunghai University; University of Michigan System; University of
   Michigan Flint; University of Michigan; National Yunlin University
   Science & Technology
RP Chen, ST (corresponding author), Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Touliu 64002, Yunlin, Taiwan.
EM cjc@thu.edu.tw; nhuang@thu.edu.tw; sytu@umich.edu; linch@thu.edu.tw;
   shough34@yahoo.com.tw
RI Chen, Chur-jen/HNR-4748-2023
OI Huang, Huang-Nan/0000-0001-7387-0427; chen,
   shuo-tsung/0000-0002-0170-4240
CR Alaryani H, 2005, P 7 IEEE INT S MULT
   [Anonymous], 2013, Wiley Series in Discrete Mathematics and Optimization
   Attari AA, 2018, MULTIMED TOOLS APPL, V77, P25607, DOI 10.1007/s11042-018-5809-8
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Burrus CS., 1998, INTRO WAVELET THEORY
   Chen ST, 2010, IET SIGNAL PROCESS, V4, P576, DOI 10.1049/iet-spr.2009.0184
   Chen ST, 2016, MULTIMED TOOLS APPL, V75, P4735, DOI 10.1007/s11042-015-2500-1
   Chen ST, 2015, IET SIGNAL PROCESS, V9, P166, DOI 10.1049/iet-spr.2013.0399
   Chen ST, 2013, DIGIT SIGNAL PROCESS, V23, P971, DOI 10.1016/j.dsp.2012.12.013
   Çiloglu T, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1017, DOI 10.1109/ICME.2000.871532
   Dhar PK, 2017, RADIOENGINEERING, V26, P552, DOI 10.13164/re.2017.0552
   GERZON MA, 1995, J AUDIO ENG SOC, V43, P3
   Gruhl D., 1996, Information Hiding. First International Workshop Proceedings, P295
   Huang HN, 2015, J SIGNAL PROCESS SYS, V80, P197, DOI 10.1007/s11265-013-0863-y
   Jeyhoon M, 2017, MULTIMED TOOLS APPL, V76, P3343, DOI 10.1007/s11042-016-3934-9
   Kim H, 2000, INT CONF ACOUST SPEE, P1971, DOI 10.1109/ICASSP.2000.859217
   Kim HJ, 2003, PAC RIM WORKSH DIG S
   Ko BS, 2002, INT CONF ACOUST SPEE, P2001
   Lewis F.L., 1986, OPTIMAL CONTROL
   Lie WN, 2006, IEEE T MULTIMEDIA, V8, P46, DOI 10.1109/TMM.2005.861292
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Noriega R.M., 2011, J INFORM HIDING MULT, V2, P91
   S Katzenbeisser, 2000, STEGANOGRAPHY DIGITA
   Saini HS, 2019, INT J INNOVATIVE TEC, V8, P185
   Salovarda M, 2005, 18 INT C APPL EL COM, P1, DOI DOI 10.1109/ICECOM.2005.205017
   Wu C.P., 1999, P INT S MULT INF PRO, P37
   Wu QL, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050723
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
   Xiang SJ, 2017, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-017-0101-9
   Xiang SJ, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-3
NR 30
TC 2
Z9 3
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2413
EP 2439
DI 10.1007/s11042-020-08969-5
EA SEP 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569773300001
DA 2024-07-18
ER

PT J
AU Li, CM
   Liu, ZD
   Zhao, ZJ
   Dai, ZX
AF Li, Chengming
   Liu, Zhendong
   Zhao, Zhanjie
   Dai, Zhaoxin
TI A fast fusion method for multi-videos with three-dimensional GIS scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surveillance videos; Topological information; Fusion; 3-D GIS scene;
   Dynamic updating
ID MODELS
AB Techniques for the fusion of real-world videos with virtual scenes are key to the augmentation of three-dimensional (3-D) virtual geographic scenes, which greatly enhances the immersive visual experience. When a 3-D scene is updated dynamically, the existing video projection-based method for real-virtual fusion is generally slow and inefficient, as all rendered objects must be traversed in the new scene to identify the objects to be fused in the user's new field of view (FOV). To address this issue, a fast, topology-accounting method for multi-video fusion with 3-D geographic information system (GIS) scenes is proposed. First, the topological models for video object and rendered object are constructed, respectively. Second, by using the topological models, a method that considering topological relationships is proposed to realize rapid identification of rendered objects during the dynamic update of 3-D scenes. Finally, real video and 3-D scene data in Tengzhou City were used to validate the method proposed in this paper. The experiments demonstrated that the method is fast and efficient in the fusion of videos with 3-D GIS scenes, and the computational cost of the proposed method is significantly lower than that of the current method. The proposed method is highly viable and robust, facilitating the fusion of videos with virtual environments.
C1 [Li, Chengming; Liu, Zhendong; Zhao, Zhanjie; Dai, Zhaoxin] Chinese Acad Surveying & Mapping, Beijing 100830, Peoples R China.
C3 Chinese Academy of Surveying & Mapping
RP Dai, ZX (corresponding author), Chinese Acad Surveying & Mapping, Beijing 100830, Peoples R China.
EM daizx@lreis.ac.cn
OI , Liu/0000-0003-3461-7685; Dai, Zhaoxin/0000-0001-8194-9530
CR Chen C-F, 2016, SIGGRAPH 16 ACM SIGG
   Clarke B.L., 1981, Notre Dame Journal of Formal Logic, V22, P204, DOI 10.1305/ndjfl/1093883455
   Corral-Soto Eduardo R., 2012, 2012 Canadian Conference on Computer and Robot Vision, P433, DOI 10.1109/CRV.2012.64
   de Haan G, 2010, IEEE COMPUT GRAPH, V30, P20, DOI 10.1109/MCG.2010.64
   Decamp P, 2010, ACM INT C MULT
   Everitt C., 2001, CISC VIS NETW IND GL
   Ghadirian P, 2008, LANDSCAPE URBAN PLAN, V86, P226, DOI 10.1016/j.landurbplan.2008.03.004
   [龚俊 Gong Jun], 2011, [测绘学报, Acta Geodetica et Cartographica Sinica], V40, P531
   Haan GD, 2009, IEEE S 3D US INT
   Hsu S, 2000, PROC CVPR IEEE, P488, DOI 10.1109/CVPR.2000.855859
   Hu JH, 2009, INTERGRATING COMPLEM
   Jian Hong-deng, 2014, Computer Engineering and Design, V35, P3873
   Jian HD, 2017, INT J DIGIT EARTH, V10, P1177, DOI 10.1080/17538947.2017.1306126
   Lewis P, 2011, INT J GEOGR INF SCI, V25, P697, DOI 10.1080/13658816.2010.505196
   Liu Z, 2018, B SURVEYING MAPPING, V496, P52
   [马原野 Ma Yuanye], 2012, [计算机应用与软件, Computer Applications and Software], V29, P109
   Milosavljevic A, 2010, INT J GEOGR INF SCI, V24, P1415, DOI 10.1080/13658811003792213
   Milosavljevic A, 2016, INT J GEOGR INF SCI, V30, P2089, DOI 10.1080/13658816.2016.1161197
   Mower JE, 2009, INT J GEOGR INF SCI, V23, P993, DOI 10.1080/13658810802001313
   Neumann U, 2003, P IEEE VIRT REAL ANN, P61, DOI 10.1109/VR.2003.1191122
   Sawhney HS, 2002, P 13 EUR WORKSH REND
   SEGAL M, 1992, COMP GRAPH, V26, P249, DOI 10.1145/142920.134071
   Wan T, 2020, IEEE ACCESS, V8, P22225, DOI 10.1109/ACCESS.2020.2969360
   Wang Xingfeng, 2017, Geomatics and Information Science of Wuhan University, V42, P35, DOI 10.13203/j.whugis20140798
   Wang Y, 2007, IEEE T VIS COMPUT GR, V13, P1568, DOI 10.1109/TVCG.2007.70544
   Wu ZZ, 2019, PATTERN RECOGN, V93, P14, DOI 10.1016/j.patcog.2019.03.013
   Xu Q, 2016, INT CONF HIGH VOLTA
   Ying SH, 2009, IEEE T AUTOM SCI ENG, V6, P559, DOI 10.1109/TASE.2009.2021337
   [郑贵洲 Zheng Guizhou], 2003, [测绘科学, Science of surveying and mapping], V28, P71
   Zhou Y, 2018, J SYSTEM SIMULATION, V30, P133
   [朱庆 Zhu Qing], 2017, [西南交通大学学报, Journal of Southwest Jiaotong University], V52, P869
NR 31
TC 4
Z9 5
U1 4
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1671
EP 1686
DI 10.1007/s11042-020-09742-4
EA SEP 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000567642000001
DA 2024-07-18
ER

PT J
AU Perez-Navarro, A
   Garcia, V
   Conesa, J
AF Perez-Navarro, A.
   Garcia, Victor
   Conesa, Jordi
TI Students perception of videos in introductory physics courses of
   engineering in face-to-face and online environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Educational videos; Videos with hands; Non-verbal information;
   E-learning; Physics education; STEM; Sciences education
ID STREAMING VIDEO; SUPPORT STUDENT; COGNITIVE LOAD; GESTURES; MULTIMEDIA;
   EDUCATION; REPRESENTATIONS; PERFORMANCE
AB Digital videos have an important (and increasing) presence in learning processes, especially within online universities and schools. However, creating videos is a time-consuming activity for teachers, who are usually not expert in video creation. Therefore, it is important to know which kind of video is perceived as more satisfactory and useful by students, among the videos that docents usually create. In this paper we show a structural model with the relation between satisfaction, the way in which a video has been created, the kind of video (with or without the hands of the teacher and with or without the body/head of the teacher), perceived usefulness, contents of the video (theory or problems) and the potential impact of videos on passing rates. The experiment has been performed in an introductory Physics of Engineering course with over 200 first year students in both: at 100% online university, Universitat Oberta de Catalunya (UOC); and at a face-to-face university, Escola Universitaria Salesiana de Sarria (EUSS). Tests have been performed with around 100 videos of two types: videos created with a digitizing tablet and screen capture, and videos created by recording the hands of the teacher. Results have been quantitatively analysed. The research shows that results are independent of the environment and that students prefer videos with hands. On the other hand, little effect has been found regarding the content of the video in the perceived usefulness or satisfaction. The performance results show that videos can improve the chances of passing the subject. Thus, the paper shows thatvideos with handsare a useful complement to challenging subjects, like introductory physics in Engineering, to effectively assimilate scientific knowledge. The main contributions of this paper are: to analyse the perception that students have of video in a specific context, introductory course of Physics in Engineering, in different environments; and to analyse the perception of the video regarding the way in which it has been created, and the kind of content.
C1 [Perez-Navarro, A.; Garcia, Victor; Conesa, Jordi] Univ Oberta Catalunya UOC, Fac Comp Sci Multimedia & Telecommun, eLearn Ctr, Rambla Poblenou 156, Barcelona 08018, Spain.
   [Perez-Navarro, A.] Escola Univ Salesiana Sarria EUSS, Ave St Joan Bosco,Passeig St Joan Bosco 74, Barcelona 08017, Spain.
C3 UOC Universitat Oberta de Catalunya
RP Perez-Navarro, A (corresponding author), Univ Oberta Catalunya UOC, Fac Comp Sci Multimedia & Telecommun, eLearn Ctr, Rambla Poblenou 156, Barcelona 08018, Spain.; Perez-Navarro, A (corresponding author), Escola Univ Salesiana Sarria EUSS, Ave St Joan Bosco,Passeig St Joan Bosco 74, Barcelona 08017, Spain.
EM aperezn@uoc.edu; vgarciahe@uoc.edu; jconesac@uoc.edu
RI HERNÁNDEZ, VICTOR JESUS GARCÍA/R-2643-2016; Perez-Navarro,
   Antoni/I-4846-2015
OI HERNÁNDEZ, VICTOR JESUS GARCÍA/0000-0002-9868-8194; Perez-Navarro,
   Antoni/0000-0002-7037-0635; Conesa, Jordi/0000-0001-6481-3324
CR [Anonymous], 2008, ARE VIDEOED LECT EFF
   [Anonymous], 2011, P 1 INT C LEARN AN K
   Astrom R., 2011, J ACOUST SOC AM, V129, P2646, DOI [10.1121/1.3588821, DOI 10.1121/1.3588821]
   Bayraktar DM, 2014, MULTIMED TOOLS APPL, V71, P1201, DOI 10.1007/s11042-012-1257-z
   BECTA ICT Research, 2003, WHAT RES SAYS DIG VI
   Carmichael P., 2013, DIGITAL VIDEO PRESEN
   Cassell J, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P106
   Chasteen S.V., 2012, PHYS TEACH, V50, P189, DOI [10.1119/1.3685129, DOI 10.1119/1.3685129]
   Claros Gomez ID, 2013, EXPERIENCIAS INNOVAD, V22
   Cofield JL, 2002, MID S ED RES ASS ANN
   Cook MP, 2006, SCI EDUC, V90, P1073, DOI 10.1002/sce.20164
   Cook SW, 2012, LANG COGNITIVE PROC, V27, P594, DOI 10.1080/01690965.2011.567074
   Dancy M, 2010, AM J PHYS, V78, P1056, DOI 10.1119/1.3446763
   Eckert B, 2009, AM J DISTANCE EDUC, V23, P125, DOI 10.1080/08923640903076735
   Einspruch EL, 2007, RESUSCITATION, V74, P476, DOI 10.1016/j.resuscitation.2007.01.030
   Freitas IM, 2004, RES SCI EDUC, V34, P113, DOI 10.1023/B:RISE.0000021000.61909.66
   Geelan D, 2013, RES SCI EDUC, V43, P1751, DOI 10.1007/s11165-012-9336-8
   Goldin-Meadow S, 2003, DEV PSYCHOL, V39, P509, DOI 10.1037/0012-1649.39.3.509
   Goldin-Meadow S, 1999, DEVELOPMENTAL SCI, V2, P67, DOI 10.1111/1467-7687.00056
   Green SM, 2003, NURS EDUC TODAY, V23, P255, DOI 10.1016/S0260-6917(03)00014-5
   Habraken C.L., 2004, J. Sci. Educ. Technol, V13, P89, DOI DOI 10.1023/B:JOST.0000019641.93420.6F
   Herron C, 1999, MOD LANG J, V83, P518, DOI 10.1111/0026-7902.00038
   Ho AndrewDean., 2014, HarvardX and MITx: The First Year of Open Online Courses, Fall 2012-Summer 2013
   Hsu L, 2004, AM J PHYS, V72, P1147, DOI 10.1119/1.1763175
   Hubbard AL, 2009, HUM BRAIN MAPP, V30, P1028, DOI 10.1002/hbm.20565
   Huffman D, 1997, J RES SCI TEACH, V34, P551, DOI 10.1002/(SICI)1098-2736(199708)34:6<551::AID-TEA2>3.3.CO;2-X
   Khan MSL, 2015, PROCEDIA MANUF, V3, P2034, DOI 10.1016/j.promfg.2015.07.251
   Koumi J, 2006, OPEN FLEX LEARN SER, P1
   Kutas M, 2000, TRENDS COGN SCI, V4, P463, DOI 10.1016/S1364-6613(00)01560-6
   Levy Y, 2007, COMPUT EDUC, V48, P185, DOI 10.1016/j.compedu.2004.12.004
   Lichter J, 2012, J CHEM EDUC, V89, P1133, DOI 10.1021/ed200531j
   Loch B, 2014, INT J MATH EDUC SCI, V45, P256, DOI 10.1080/0020739X.2013.822581
   Lynch S.M., 2013, Using statistics in social research: A concise approach
   Mayo A, 2009, RES SCI EDUC, V39, P477, DOI 10.1007/s11165-008-9090-0
   McNeill D., 1994, Research on Language and Social Interaction, V27, P223
   Moran M., 2011, TEACHING LEARNING SH
   Muller A, 2008, J COMPUT ASSIST LEAR, V24, P144, DOI 10.1111/j.1365-2729.2007.00248.x
   Muller D., 2008, DESIGNING EFFECTIVE
   Nagy JT, 2018, INT REV RES OPEN DIS, V19, P160
   Ouwehand K, 2015, EDUC TECHNOL SOC, V18, P78
   Özyürek A, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0296
   Paivio A., 1986, Mental representations: A dual coding approach
   Pereira Marcus Vinicius, 2012, Physics Education, V47, P44, DOI 10.1088/0031-9120/47/1/44
   Pérez-Navarro A, 2012, EDULEARN PROC, P2384
   Pérez-Santiago A, 2012, PROC FRONT EDUC CONF
   Reisslein M., 2005, Internet and Higher Education, V8, P25, DOI 10.1016/j.iheduc.2004.12.002
   Santaliestra J, TRANSVERSALITY INTER
   Scharrenberg Joost, 2011, QUE SON MEDIOS SOCIA
   Scott J, 2014, S VIS LANG HUM CEN C, P45, DOI 10.1109/VLHCC.2014.6883020
   Shephard K, 2003, BRIT J EDUC TECHNOL, V34, P295, DOI 10.1111/1467-8535.00328
   Stull AT, 2018, COMPUT EDUC, V120, P146, DOI 10.1016/j.compedu.2018.02.005
   Takeda N, 2007, YAKUGAKU ZASSHI, V127, P2097, DOI 10.1248/yakushi.127.2097
   Van Cauwenberge A, 2014, COMPUT HUM BEHAV, V38, P100, DOI 10.1016/j.chb.2014.05.021
   van der Meij J, 2006, LEARN INSTR, V16, P199, DOI 10.1016/j.learninstruc.2006.03.007
   Van Petten C, 2006, BRAIN LANG, V97, P279, DOI 10.1016/j.bandl.2005.11.003
   VANHEUVELEN A, 1991, AM J PHYS, V59, P891, DOI 10.1119/1.16667
   Weinrich ML, 2017, CHEM EDUC RES PRACT, V18, P169, DOI 10.1039/c6rp00120c
   Westfall R, 2016, J GEN PSYCHOL, V143, P161, DOI 10.1080/00221309.2016.1200529
   Wray R.E., 2007, J AEROS COMP INF COM, V4, P836, DOI [10.2514/1.27099, DOI 10.2514/1.27099]
   Yap DF, 2011, COGNITIVE SCI, V35, P171, DOI 10.1111/j.1551-6709.2010.01141.x
NR 60
TC 5
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1009
EP 1028
DI 10.1007/s11042-020-09665-0
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566318900010
DA 2024-07-18
ER

PT J
AU Wang, P
   Bai, XL
   Billinghurst, M
   Zhang, SS
   Wei, SL
   Xu, GY
   He, WP
   Zhang, XY
   Zhang, J
AF Wang, Peng
   Bai, Xiaoliang
   Billinghurst, Mark
   Zhang, Shusheng
   Wei, Sili
   Xu, Guangyao
   He, Weiping
   Zhang, Xiangyu
   Zhang, Jie
TI 3DGAM: using 3D gesture and CAD models for training on mixed reality
   remote collaboration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Mixed reality; Remote collaboration; Physical tasks;
   Sharing gesture; 3D CAD models
ID RETRIEVAL APPROACH
AB As Virtual Reality(VR), Augmented Reality(AR), Mixed Reality(MR) technology becomes more accessible, it is important to explore VR/AR/MR technologies that can be used for remote collaboration on physical tasks. Previous research has shown that gesture-based interaction is intuitive and expressive for remote collaboration, and using 3D CAD models can provide clear instructions for assembly tasks. In this paper, therefore, we describe a new MR remote collaboration system which combines the use of gesture and CAD models in a complementary manner. The prototype system enables a remote expert in VR to provide instructions based on 3D gesture and CAD models (3DGAM) for a local worker who uses AR to see these instructions. Using this interface, we conducted a formal user study to explore the effect of sharing 3D gesture and CAD models in an assembly training task. We found that the combination of 3D gesture and CAD models can improve remote collaboration on an assembly task with respect to the performance time and user experience. Finally, we provide some conclusions and directions for future research.
C1 [Wang, Peng; Bai, Xiaoliang; Billinghurst, Mark; Zhang, Shusheng; Wei, Sili; Xu, Guangyao; He, Weiping; Zhang, Xiangyu; Zhang, Jie] Northwestern Polytech Univ, Cyber Phys Interact Lab, Xian, Peoples R China.
   [Billinghurst, Mark] Univ South Australia, Empath Comp Lab, Mawson Lakes, Australia.
C3 Northwestern Polytechnical University; University of South Australia
RP Wang, P; Bai, XL; Billinghurst, M (corresponding author), Northwestern Polytech Univ, Cyber Phys Interact Lab, Xian, Peoples R China.; Billinghurst, M (corresponding author), Univ South Australia, Empath Comp Lab, Mawson Lakes, Australia.
EM ilovemymfandb@163.com; bxl@nwpu.edu.cn; mark.billinghurst@gmail.com
RI Zhang, Shusheng/GRO-2963-2022; zhang, xiang/GQI-2806-2022; Billinghurst,
   Mark/AAJ-4236-2020; Zhang, Xiangyu/JDW-3961-2023
OI Billinghurst, Mark/0000-0003-4172-6759; 
FU civil aircraft special project [MJZ-2017-G73]; Dongguan Science and
   Technology Equipment Project [KZ2018-05]; National Key R&D Program of
   China [2019YFB1703800]; Natural Science Basic Research Plan in Shaanxi
   Province of China [2016JM6054]; 111 project [B13044]
FX This research was financially sponsored by the civil aircraft special
   project (MJZ-2017-G73), Dongguan Science and Technology Equipment
   Project (KZ2018-05), National Key R&D Program of China
   (2019YFB1703800),Natural Science Basic Research Plan in Shaanxi Province
   of China (2016JM6054), and 111 project (B13044). Besides, we would like
   to appreciate Professor Mark Billinghurst for carefully checking the
   English of an early version of the paper. Additionally, we would like to
   thank Yuming Zheng for donating the water pump used in our research,
   Dechuan Han and Sili Wei for developing and improving the algorithm of
   sharing gestures, respectively, Jie Zhang, Guangyao Xu and Xu Zhang for
   preparing some supplementary materials.
CR Al-khafajiy M, 2019, MULTIMED TOOLS APPL, V78, P24681, DOI 10.1007/s11042-018-7134-7
   [Anonymous], 2019, P CHI C HUM FACT COM
   Bai HD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376550
   Burova A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376405
   Chen X, 2012, COMPUT AIDED DESIGN, V44, P554, DOI 10.1016/j.cad.2012.02.001
   Chenechal LM, 2016, 2016 IEEE 3 VR INT W
   D'Angelo S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173923
   De Pace F, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00018
   Elvezio C, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P180, DOI 10.1109/ISMAR.2015.54
   Elvezio Carmine, 2017, ACM SIGGRAPH 2017 VR, DOI [10.1145/3089269.3089281, DOI 10.1145/3089269.3089281]
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   García-Pereira I, 2020, MULTIMED TOOLS APPL, V79, P6483, DOI 10.1007/s11042-019-08419-x
   Gonzalez-Franco M, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00003
   Gupta K, 2016, IEEE T VIS COMPUT GR, V22, P2413, DOI 10.1109/TVCG.2016.2593778
   Gurevich P, 2015, COMPUT SUPP COOP W J, V24, P527, DOI 10.1007/s10606-015-9232-7
   Harms C., 2004, 7 ANN INT WORKSH PRE
   Hinderks A, 2019, COMPUT STAND INTER, V65, P38, DOI 10.1016/j.csi.2019.01.007
   Huang R, 2015, COMPUT IND, V67, P38, DOI 10.1016/j.compind.2014.12.001
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Kim S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300403
   Kritzler M, 2016, P 6 INT C INT THINGS, P7, DOI 10.1145/2991561.2991571
   Oda O, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P405, DOI 10.1145/2807442.2807497
   Petrangeli S, 2019, MULTIMED TOOLS APPL, V78, P7419, DOI 10.1007/s11042-018-6460-0
   Piumsomboon T, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00005
   Piumsomboon T, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P218, DOI 10.1109/ISMAR-Adjunct.2017.72
   Pringle A, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P236, DOI 10.1109/ISMAR-Adjunct.2018.00075
   Schrepp Martin., 2019, USER EXPERIENCE QUES
   Sukan M, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P89, DOI 10.1145/2983310.2985764
   Tang A., 2004, Proceedings of the fifth Conference on Australasian User Interface, P73
   Villanueva A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376146
   Wang P, 2020, INT J HUM-COMPUT INT, V36, P1242, DOI 10.1080/10447318.2020.1732140
   Wang P, 2019, INT J ADV MANUF TECH, V105, P3031, DOI 10.1007/s00170-019-04434-2
   Wang P, 2019, INT J ADV MANUF TECH, V102, P1339, DOI 10.1007/s00170-018-03237-1
   Wang PF, 2019, EXPERT OPIN THER PAT, V29, P595, DOI 10.1080/13543776.2019.1640680
   Wang S, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102294
   Wang YL, 2019, RICE SCI, V26, P1, DOI 10.1016/j.rsci.2018.06.009
   Wu TY, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P121, DOI 10.1145/3332165.3347938
   Young J, 2019, IEEE T VIS COMPUT GR, V25, P1908, DOI 10.1109/TVCG.2019.2898737
NR 38
TC 33
Z9 36
U1 2
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31059
EP 31084
DI 10.1007/s11042-020-09731-7
EA SEP 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000565480700006
DA 2024-07-18
ER

PT J
AU Mishra, K
   Kavala, S
   Singh, SK
   Nagabhushan, P
AF Mishra, Kapil
   Kavala, Sannihith
   Singh, Satish Kr.
   Nagabhushan, P.
TI Efficient collusion resistant multi-secret image sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-secret image sharing; Secret sharing; Visual cryptography;
   Multimedia security
ID VISUAL CRYPTOGRAPHY; SCHEMES; XOR
AB Multi-secret image sharing techniques (MSS) extend the secret image sharing schemes. The paper reports a novel MSS scheme designed to be collusion resistant. It starts with a brief introduction of the concept thereafter discussing the related works in the domain. Security is an implicit requirement for MSS techniques. There should be no possibility of collusion among the shareholders. No less than k shareholders for (k, n) MSS scheme should be having even a slight view of the secret from their shares, n being the total number of shareholders. The paper reviews and highlights the security issues like possibility of collusion, randomness issues or robustness against tampering attack in the state-of-the-art works. It proposes a new (n, n) MSS scheme in order to rectify the issues. The algorithm encrypts N different secret images to generate N noisy share images. It resolves the existing problems in a secure, and time efficient manner. A range of experiments specifically time complexity, noise, tampering, collusion and histogram analysis are performed for rigorous security analysis. The results, thus obtained indicated that the algorithm is efficient and preserves the security requirements in a much better way than the existing MSS schemes.
C1 [Mishra, Kapil; Kavala, Sannihith; Singh, Satish Kr.; Nagabhushan, P.] Indian Inst Informat Technol, Dept Informat Technol, Allahabad, Prayagraj, India.
C3 Indian Institute of Information Technology Allahabad
RP Mishra, K (corresponding author), Indian Inst Informat Technol, Dept Informat Technol, Allahabad, Prayagraj, India.
EM kapilmishra16@gmail.com; sannihith12345@gmail.com; sk.singh@iiita.ac.in;
   pnagabhushan@hotmail.com
RI Singh, Dr Satish Kumar/JMP-6186-2023
OI Singh, Dr Satish Kumar/0000-0003-1991-7727
FU MHRD GATE junior research fellowship scheme of government of India
FX Contribution of Mr. Pruthvi Anvesh (P.G student at IIIT Allahabad) for
   his inputs and co-operation in this study is hereby acknowledged and
   highly encouraged. The work is supported by MHRD GATE junior research
   fellowship scheme of government of India.
CR Chakraborty S., 2016, INT J INF COMMUN TEC, V9, P337, DOI DOI 10.1504/IJICT.2016.079129
   Chao HC, 2018, MULTIMED TOOLS APPL, V77, P11867, DOI 10.1007/s11042-017-4836-1
   Chen CC, 2016, MULTIMED TOOLS APPL, V75, P7113, DOI 10.1007/s11042-015-2634-1
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Chen YC, 2019, IEEE T INF FOREN SEC, V14, P3332, DOI 10.1109/TIFS.2019.2914557
   Chen YF, 2007, INFORM SCIENCES, V177, P4696, DOI 10.1016/j.ins.2007.05.011
   Cheng TF, 2017, MULTIMED TOOLS APPL, V76, P9337, DOI 10.1007/s11042-016-3535-7
   Cu DH, 2015, SIGNAL PROCESS, V108, P604, DOI 10.1016/j.sigpro.2014.10.011
   Deshmukh M, 2017, SING P INT C COMP VI
   Deshmukh M, 2018, MULTIMED TOOLS APPL, V77, P89, DOI 10.1007/s11042-016-4229-x
   Gallagher AC, 2008, PROC CVPR IEEE, P1073
   He JH, 2017, MULTIMED TOOLS APPL, V76, P7677, DOI 10.1007/s11042-016-3429-8
   Hou YC, 2015, J VIS COMMUN IMAGE R, V33, P358, DOI 10.1016/j.jvcir.2015.10.005
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   Kabirirad S, 2019, J INF SECUR APPL, V47, P16, DOI 10.1016/j.jisa.2019.03.018
   Kabirirad S, 2018, J VIS COMMUN IMAGE R, V57, P39, DOI 10.1016/j.jvcir.2018.10.014
   Kang I, 2011, IEEE T IMAGE PROCESS, V20, P132, DOI 10.1109/TIP.2010.2056376
   Kumar S, 2014, SECUR COMMUN NETW, V7, P653, DOI 10.1002/sec.769
   Lee KH, 2011, OPT COMMUN, V284, P2730, DOI 10.1016/j.optcom.2011.01.077
   Meghrajani YK, 2016, IEEE SIGNAL PROC LET, V23, P1429, DOI 10.1109/LSP.2016.2599076
   Nag A, 2020, MULTIMED TOOLS APPL, V79, P16219, DOI 10.1007/s11042-019-07807-7
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Shivani S, 2018, MULTIMED TOOLS APPL, V77, P6287, DOI 10.1007/s11042-017-4536-x
   Shyu SJ, 2012, IEEE T CIRC SYST VID, V22, P769, DOI 10.1109/TCSVT.2011.2180769
   Shyu SJ, 2011, IEEE T INF FOREN SEC, V6, P960, DOI 10.1109/TIFS.2011.2158096
   Singh P, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3077140
   Wang DS, 2013, IEEE T INF FOREN SEC, V8, P2059, DOI 10.1109/TIFS.2013.2281108
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Yan XH, 2018, J REAL-TIME IMAGE PR, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yan XH, 2016, MULTIMED TOOLS APPL, V75, P8657, DOI 10.1007/s11042-015-2779-y
   Yan XH, 2015, SIGNAL IMAGE VIDEO P, V9, P1659, DOI 10.1007/s11760-014-0619-6
NR 33
TC 1
Z9 1
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 33233
EP 33252
DI 10.1007/s11042-020-09619-6
EA AUG 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564527000004
DA 2024-07-18
ER

PT J
AU Giri, KJ
   Quadri, SMK
   Bashir, R
   Bhat, JI
AF Giri, Kaiser J.
   Quadri, S. M. K.
   Bashir, Rumaan
   Bhat, Javaid Iqbal
TI DWT based color image watermarking: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Copyright protection; Digital watermarking; Discrete wavelet
   transformation; Robustness; Security
ID DIFFERENTIAL EVOLUTION; WAVELET TRANSFORM; ZERO-WATERMARKING; SVD;
   SCHEME; OPTIMIZATION; INFORMATION
AB In today's knowledge driven society and technology driven economy, when data is considered to be one of the most important corporate resource of an organization, equally important is the security of the same to prevent unauthorized users to access and manipulate it. Watermarking being an appropriate solution for claiming authorization has prompted many researchers to work in this direction and accordingly a substantial amount of research work has been done using different schemes on various media types. The main impetus in writing this paper is to provide a broader view as how much work has been carried so far and what are the different dimensions that have been taken into consideration to watermark color images using discrete wavelet transformation. The paper will help prospective researchers to gain more insight about the work that has been done and pave a way for them to design and implement better techniques.
C1 [Giri, Kaiser J.; Bashir, Rumaan; Bhat, Javaid Iqbal] Islamic Univ Sci & Technol, Dept Comp Sci, Awantipora, J&K, India.
   [Quadri, S. M. K.] Jamia Millia Islamia, Dept Comp Sci, New Delhi, India.
C3 Jamia Millia Islamia
RP Giri, KJ (corresponding author), Islamic Univ Sci & Technol, Dept Comp Sci, Awantipora, J&K, India.
EM kaiser.giri@islamicuniversity.edu.in; quadrismk@hotmail.com;
   rumaan.bashir@islamicuniversity.edu.in; javaidonnet@gmail.com
RI Quadri, S M K/GVS-6474-2022; Giri, Kaiser J./ABG-6767-2020; Bhat,
   Javaid/ABG-7683-2020
OI Bashir, Rumaan/0000-0001-6656-005X; Giri, Kaiser/0000-0001-8792-5011;
   Bhat, Javaid Iqbal/0000-0003-0312-4888; QUADRI, Syed Mohammad
   Khurshaid/0000-0001-6099-9002
CR Agarwal C, 2014, INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND SOFTWARE ENGINEERING (AISE 2014), P430
   Al-Qtum HM, 2010, INT J ELECT COMMUN, V65, P619
   Ali M, 2018, INT J SYST ASSUR ENG, V9, P602, DOI 10.1007/s13198-014-0288-4
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   [Anonymous], 2010, J INF HIDING MULTIME
   [Anonymous], INT J DIGITAL CONTEN
   [Anonymous], IJCA SPECIAL ISSUE C
   Ansari IA, 2017, MULTIMED TOOLS APPL, V76, P18001, DOI 10.1007/s11042-016-3680-z
   Ansari Rahim, 2012, INT C COMM INF COMP
   Anwar Muhammad Jamil, 2010, 2010 6th International Conference on Emerging Technologies (ICET), P204, DOI 10.1109/ICET.2010.5638488
   Aslantas V, 2009, OPT COMMUN, V282, P769, DOI 10.1016/j.optcom.2008.11.024
   Chavan S., 2010, Proceedings of 2010 International Conference on Advances in Recent Technologies in Communication and Computing (ARTCom 2010), P96, DOI 10.1109/ARTCom.2010.11
   Chu SC, 2008, CIRC SYST SIGNAL PR, V27, P171, DOI 10.1007/s00034-008-9025-z
   Cong K, 2013, INT CONF QUAL SOFTW, P1, DOI 10.1109/QSIC.2013.44
   Deepika B, 2018, INT J SCI RES ENG TR, V04, P2395
   Dey A, 2020, MULTIMED TOOLS APPL, V79, P2555, DOI 10.1007/s11042-019-08372-9
   Dey N, 2014, J MED IMAG HEALTH IN, V4, P384, DOI 10.1166/jmihi.2014.1265
   El Gamal AF, 2013, INT J COMPUT APPL, V66, P15
   Elbasi E, 2006, INT J TECHNOL ENG SY, V2, P276
   Eltaweel SG, 2012, IEEE, V21, P4117
   Farhan A. A., 2011, 2011 Proceedings of the IEEE 14th International Multitopic Conference (INMIC 2011), P82, DOI 10.1109/INMIC.2011.6151516
   Findik O, 2010, OPT COMMUN, V283, P4916, DOI 10.1016/j.optcom.2010.07.020
   Ghafoor A., 2012, RADIOENGINEERING, V21, P1246
   Giri Kaiser J., 2018, International Journal of Information Technology, V10, P139, DOI 10.1007/s41870-017-0075-y
   Gunjal B, 2011, INT J EMERGING TREND, V1, P21
   Gunjal Baisa L., 2011, International Journal of Computer Science, Engineering and Information Technology (IJCSEIT), V1, P36
   Hsieh MS, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1593, DOI 10.1109/ICME.2006.262850
   Hu AF, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P1453, DOI 10.1109/ICYCS.2008.100
   Hua YN, 2010, CHIN CONT DECIS CONF, P2840, DOI 10.1109/CCDC.2010.5498711
   Imran M, 2012, IEEE SYS MAN CYBERN, P1147, DOI 10.1109/ICSMC.2012.6377886
   Islam M, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING, INSTRUMENTATION AND CONTROL TECHNOLOGIES (ICICICT), P1426, DOI 10.1109/ICICICT1.2017.8342779
   Islam M, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053008
   Jadhav Sangeeta D., 2010, 2010 IEEE Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM 2010), P162, DOI 10.1109/ICCIS.2010.5518562
   Jia SL, 2014, OPTIK, V125, P2868, DOI 10.1016/j.ijleo.2014.01.002
   Jie H, 2015, COMPUT ELECT ENG
   Jithin V.M., 2013, INT J ELECT COMMUNIC, V4, P190
   Kalaiselvan G., 2011, 2011 International Conference on Recent Trends in Information Technology (ICRTIT 2011), P1081, DOI 10.1109/ICRTIT.2011.5972355
   Kalra GS, 2015, MULTIMED TOOLS APPL, V74, P6849, DOI 10.1007/s11042-014-1932-3
   Kazemivash B, 2017, MULTIMED TOOLS APPL, V76, P20499, DOI 10.1007/s11042-016-3962-5
   Khalifa A, 2012, INT J COMPUT APPL, V37
   Khanna AK, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1140, DOI 10.1109/CCAA.2016.7813888
   Kumar Ashwani, 2020, Information and Communication Technology for Sustainable Development. Proceedings of ICT4SD 2018. Advances in Intelligent Systems and Computing (AISC 933), P595, DOI 10.1007/978-981-13-7166-0_59
   Lakrissi Y, 2018, MULTIMED TOOLS APPL, V77, P13531, DOI 10.1007/s11042-017-4974-5
   Lavanya A, 2013, ADV INTELL SYST COMP, V178, P167
   Lee JS, 2014, APPL MATH INFORM SCI, V8, P2945, DOI 10.12785/amis/080632
   Li M, 2019, MULTIMED TOOLS APPL, V78, P22727, DOI 10.1007/s11042-019-7560-1
   Liang F., 2011, J COMPUTATIONAL INFO, V6, P2013
   Liu KC, 2009, 2009 13TH INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, P65, DOI 10.1109/IMVIP.2009.19
   Liu KC, 2009, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY, VOL 2, PROCEEDINGS, P623, DOI 10.1109/IAS.2009.349
   Liu Lv-Ming, 2010, WAVELET DOMAIN WATER, P1
   Loukhaoukha K., 2013, J OPTIMIZATION, V2013, P1
   Loukhaoukha K., 2011, J Inf Hiding Multim Signal Process, V2, P303
   Maheshkar S, 2016, P 5 INT C SOFT COMP, P105
   Mir RN, 2019, J KING SAUD U COMPUT
   Mishra A, 2017, LECT NOTES COMPUTER
   Moeinaddini E, 2018, MULTIMED TOOLS APPL, V77, P26083, DOI 10.1007/s11042-018-5838-3
   Nagaraj VD, 2011, NONBLIND WATERMARKIN
   Narang M., 2013, INT J COMPUT APPL, V74, P34, DOI [10.5120/13029-0219, DOI 10.5120/13029-0219]
   Papakostas GA, 2014, APPL MATH COMPUT, V227, P222, DOI 10.1016/j.amc.2013.11.036
   Parah SA, 2018, MULTIMED TOOLS APPL, V77, P185, DOI 10.1007/s11042-016-4253-x
   Patvardhan C, 2018, MULTIMED TOOLS APPL, V77, P12655, DOI 10.1007/s11042-017-4909-1
   Priyanka Maheshkar S, 2016, P 5 INT C SOFT COMP
   Qiang Song, 2010, 2010 International Conference on Measuring Technology and Mechatronics Automation (ICMTMA 2010), P796, DOI 10.1109/ICMTMA.2010.12
   Sharma G., 2017, DIGITAL COLOR IMAGIN
   Sharma SS, 2017, LECT NOTES COMPUTER
   Shieh CS, 2004, PATTERN RECOGN, V37, P555, DOI 10.1016/j.patcog.2003.07.003
   Shih FY, 2018, MULTIMED TOOLS APPL, V77, P1623, DOI 10.1007/s11042-017-4367-9
   Singh N, 2015, INT J COMPUT SCI MOB, V4, P632
   Singh P, 2017, MULTIMED TOOLS APPL, V76, P3871, DOI 10.1007/s11042-016-4048-0
   Song XH, 2013, QUANTUM INF PROCESS, V12, P3689, DOI 10.1007/s11128-013-0629-2
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P8781, DOI 10.1007/s11042-016-3522-z
   Ula KS, 2018, INT C COMP INF TECHN, P157
   Vahedi E, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS, P58
   Vahedi E, 2012, DIGIT SIGNAL PROCESS, V22, P153, DOI 10.1016/j.dsp.2011.08.006
   Vardhini B. Vidya, 2006, Indian Journal of Plant Physiology, V11, P1
   Verma A. K., 2012, 2012 4th International Conference on Computational Intelligence and Communication Networks (CICN 2012), P778, DOI 10.1109/CICN.2012.208
   Wang X, 2019, MULTIMED TOOLS APPL, V78, P27001, DOI 10.1007/s11042-017-4666-1
   Xie F, 2009, PROCEEDINGS FOR THE 5TH EURO-ASIA CONFERENCE ON ENVIRONMENT AND CORPORATE SOCIAL RESPONSIBILITY: SOCIETY AND TOURISM MANAGEMENT, P157
   Yuh-Rau Wang, 2011, Proceedings of the 2011 International Conference on Machine Learning and Cybernetics (ICMLC 2011), P1612, DOI 10.1109/ICMLC.2011.6016987
   Zhang Y, 2012, CHIN CONT DECIS CONF, P1909, DOI 10.1109/CCDC.2012.6244307
   Zhao Mingwei, 2008, COLOR IMAGE COPYRIGH, P1
NR 81
TC 17
Z9 19
U1 3
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32881
EP 32895
DI 10.1007/s11042-020-09716-6
EA AUG 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563739900003
DA 2024-07-18
ER

PT J
AU Sajedi, H
   Mohammadipanah, F
   Pashaei, A
AF Sajedi, Hedieh
   Mohammadipanah, Fatemeh
   Pashaei, Ali
TI Image-processing based taxonomy analysis of bacterial macromorphology
   using machine-learning models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bacteria; Macromorphology; taxonomy; Bacterial colony; Bacteria
   classification; Image pattern recognition
AB Classification of bacteria is essential in the medical diagnosis of infectious agents, their phylogenetic study, and their biotechnological exploitation for healthcare, food, industry, and agricultural sectors. Nevertheless, skilled experts and professional human-effort are necessary to identify and classify the bacteria manually. With the advancement of technology, now the task of recognizing details from digital stereomicroscopes is being performed by computers based on machine learning and computer vision technologies. Besides, machine learning methods include Deep Neural Networks (NN) has attained remarkable outcomes in the field of image classification recently. Furthermore, other machine learning methods except for NN methods already have acceptable performance. In this paper, we review the publications, which investigate the discrimination between bacteria genera and suborders based on macroscopic images via image processing and machine learning methods. The published research works in this regard are summarized, and the pros and cons of them are discussed. Moreover, the related databases and resources for this purpose are surveyed, and the lack of such data points in the global catalogue of microorganisms is criticized. In addition, in this paper, we have investigated an approach to automate the process of bacteria recognition and classification with the use of the Gabor transform and XGBoost classification method. We have used a dataset that includes microscopic images of three different Myxobacterial suborders. The trained model was able to recognize and classify all members of three different categories of bacteria, while the experimental results of prediction achieved an accuracy of around 91%, which has enhancement about 2% in term of accuracy.
C1 [Sajedi, Hedieh] Univ Tehran, Pharmaceut Biotechnol Lab, Dept Microbiol, Sch Biol,Coll Sci, Tehran 141556455, Iran.
   [Sajedi, Hedieh; Mohammadipanah, Fatemeh] Univ Tehran, Coll Sci, Ctr Excellence Phylogeny Living Organisms, Tehran 141556455, Iran.
   [Mohammadipanah, Fatemeh] Univ Tehran, Coll Sci, Dept Microbial Biotechnol, Sch Biol, Tehran 141556455, Iran.
   [Pashaei, Ali] Amirkabir Univ Technol, Dept Math & Comp Sci, Tehran, Iran.
C3 University of Tehran; University of Tehran; University of Tehran;
   Amirkabir University of Technology
RP Sajedi, H (corresponding author), Univ Tehran, Pharmaceut Biotechnol Lab, Dept Microbiol, Sch Biol,Coll Sci, Tehran 141556455, Iran.; Sajedi, H; Mohammadipanah, F (corresponding author), Univ Tehran, Coll Sci, Ctr Excellence Phylogeny Living Organisms, Tehran 141556455, Iran.
EM hsajedi@ut.ac.ir; fmohammadipanah@ut.ac.ir
OI sajedi, hedieh/0000-0003-4782-9222; Pashaei, Ali/0000-0002-0559-1992
CR Almarzoqi M, 2019, 2019 INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTING TECHNOLOGIES AND APPLICATIONS (ICECTA), DOI 10.1109/icecta48151.2019.8959579
   [Anonymous], 2011, P INT C INF NETW TEC
   [Anonymous], 2014, INT J COMPUTER SCI E
   Balagurusamy V, 2019, PROC SPIE, V11087, DOI 10.1117/12.2529829
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Dong N, 2015, 6 ACM C
   Hasan MJ, 2019, INT CONF ELECTR ENG, DOI 10.1109/eict48899.2019.9068817
   Hay EA, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006628
   Huang L, 2018, THEOR BIOL MED MODEL, V15, DOI 10.1186/s12976-018-0093-x
   Kim NC, 2018, PATTERN RECOGN LETT, V112, P18, DOI 10.1016/j.patrec.2018.05.010
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Mohamed BA, 2018, CAIRO INT BIOM ENG, P86, DOI 10.1109/CIBEC.2018.8641799
   Nasip OF, 2015, BACTERIA IMAGES HOWM
   Nasip OF, 2018, BACTERIA IMAGES MICR
   Nasip OF, 2018, BACTERIA IMAGES PIXN
   Nasip OF, 2015, BACTERIA IMAGES MICR
   Nasip ÖF, 2018, 2018 2ND INTERNATIONAL SYMPOSIUM ON MULTIDISCIPLINARY STUDIES AND INNOVATIVE TECHNOLOGIES (ISMSIT), P684
   NOORDADI M, 2018, FUTURE MICROBIOL, V13
   Patsekin V, 2019, CLASSIFICATION ARCOB
   Plichta A, 2019, J TELECOMMUNICATIONS, V4, P72
   Preetha V, 2018, INT J ENG RES COMPUT, V5, P2394
   Rueden CT, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1934-z
   Sajedi H, 2019, MULTIMED TOOLS APPL, V16, P1
   Sajedi H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-54341-5
   Schindelin J, 2012, NAT METHODS, V9, P676, DOI [10.1038/NMETH.2019, 10.1038/nmeth.2019]
   Schneider CA, 2012, NAT METHODS, V9, P671, DOI 10.1038/nmeth.2089
   Szegedy C, 2019, PROC IEEE C COMPUTER
   Talo M, 2019, INT C ADV TECHN COMP
   Thompson CC, 2015, ARCH MICROBIOL, V197, P359, DOI 10.1007/s00203-014-1071-2
   Treebupachatsakul T, 2019, 2019 34TH INTERNATIONAL TECHNICAL CONFERENCE ON CIRCUITS/SYSTEMS, COMPUTERS AND COMMUNICATIONS (ITC-CSCC 2019), P499, DOI 10.1109/itc-cscc.2019.8793320
   Tronnolone H, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006629
   Vijaykumar V., 2016, Int. J. Comput. Appl., V151, P23
   Wahid MF, 2018, 2018 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE), P217, DOI 10.1109/ICECE.2018.8636750
   Wang H, 2020, EARLY DETECTION CLAS
   Wang H., 2018, DIGITAL MED, V4, P157, DOI [10.4103/digm.digm_16_18, DOI 10.4103/DIGM.DIGM_16_18]
   Wu LH, 2013, BMC GENOMICS, V14, DOI 10.1186/1471-2164-14-933
   Zhang WL, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1475, DOI [10.1145/2783258.2783304, 10.1109/tbdata.2016.2573280]
   Zielinski B, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184554
NR 39
TC 10
Z9 10
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32711
EP 32730
DI 10.1007/s11042-020-09284-9
EA AUG 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563739900005
DA 2024-07-18
ER

PT J
AU Gupta, Y
   Lama, RK
   Lee, SW
   Kwon, GR
AF Gupta, Yubraj
   Lama, Ramesh Kumar
   Lee, Sang-Woong
   Kwon, Goo-Rak
TI An MRI brain disease classification system using PDFB-CT and GLCM with
   kernel-SVM for medical decision support
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pyramidal directional filter blank contourlet transform;
   Contrast-limited adaptive histogram equalization (CLAHE); Probabilistic
   principal component; Multi-kernel support vector machine; Gray-level
   co-occurrence matrix
ID IMAGE CLASSIFICATION; TRANSFORM; DIAGNOSIS; ENTROPY
AB The automatic binary classification of normal and abnormal subjects using magnetic resonance (MR) brain images has made remarkable progress in recent years. This automation method plays a central role in the early evaluation of degenerative brain diseases in patients. In recent years, various new robust classification methods have been proposed based on families of the wavelet transform (WT). These transforms are good at capturing edge points but lack smoothness along the contour of an image. Therefore, instead of using WT in our experiment, we used a pyramid directional filter bank contourlet transform (PDFB-CT). The key characteristic of this transform is that it is likely to manage 2D singularities efficiently, i.e., edges, unlike the wavelets, which deal with point singularities exclusively, and it also efficiently implements a wavelet-like structure using iterative filter banks. Moreover, we passed the outcome obtained from the PDFB-CT to the gray-level co-occurrence matrix (GLCM) to obtain 22 texture features from each MR brain image. Furthermore, we passed these extracted features to random tree embedding (RTE) to transform low-dimensional features to high-dimensional features before passing them to probabilistic principal component analysis (PPCA) for dimensionality reduction. Here, the multi-kernel support vector machine classifier with a grid search CV (to find optimal hyperparameters) method was used to perform binary classification of abnormal and normal images. As a result, our proposed system achieved an area under the receiver operating characteristic (AU-ROC) curve and classification accuracy of 100% for abnormal vs. normal group classification using a ten-fold stratified cross-validation technique. This experiment result exemplifies the significance of our proposed method compared with recently published state-of-the-art techniques, and hence our proposed method can be effectively used by a physician as a support tool for examining a patient's brain.
C1 [Gupta, Yubraj; Lama, Ramesh Kumar; Kwon, Goo-Rak] Chosun Univ, Dept Informat & Commun Engn, 309Pilmun Daero, Gwanju 61452, South Korea.
   [Lee, Sang-Woong] Gachon Univ, Dept Software, 1342 Seongnamdaero, Seongnam 13120, Gyeonggido, South Korea.
C3 Chosun University; Gachon University
RP Kwon, GR (corresponding author), Chosun Univ, Dept Informat & Commun Engn, 309Pilmun Daero, Gwanju 61452, South Korea.
EM grkwon@chosun.ac.kr
RI Lee, Sang-Woong/ABF-6191-2020
OI Lee, Sang-Woong/0000-0001-8117-6566; Gupta, Yubraj/0000-0002-8404-5411;
   Kwon, Goo-Rak/0000-0003-3486-8812
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2019R1A4A1029769, NRF-2019R1F1A1060166]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   NRF-2019R1A4A1029769, NRF-2019R1F1A1060166).
CR Alam S, 2017, INT J IMAG SYST TECH, V27, P133, DOI 10.1002/ima.22217
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chaplot S, 2006, BIOMED SIGNAL PROCES, V1, P86, DOI 10.1016/j.bspc.2006.05.002
   Chen T, 2009, COMPUT STAT DATA AN, V53, P3706, DOI 10.1016/j.csda.2009.03.014
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Duan FF, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1054-z
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Farzan A, 2015, BEHAV BRAIN RES, V290, P124, DOI 10.1016/j.bbr.2015.04.010
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Ghannam S, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON THE APPLICATIONS OF DIGITAL INFORMATION AND WEB TECHNOLOGIES (ICADIWT 2009), P545, DOI 10.1109/ICADIWT.2009.5273921
   Greiner M, 2000, PREV VET MED, V45, P23, DOI 10.1016/S0167-5877(00)00115-X
   Gudigar A, 2019, IEEE ACCESS, V7, P28498, DOI 10.1109/ACCESS.2019.2901055
   Gudigar A, 2019, FUTURE GENER COMP SY, V90, P359, DOI 10.1016/j.future.2018.08.008
   Gupta Y, 2019, FRONT COMPUT NEUROSC, V13, DOI 10.3389/fncom.2019.00072
   Gupta Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222446
   Gupta Y, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/2492719
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Harikumar R, 2015, INT J IMAG SYST TECH, V25, P33, DOI 10.1002/ima.22118
   Jha D, 2017, J MED IMAG HEALTH IN, V7, P1744, DOI 10.1166/jmihi.2017.2269
   Kalbkhani H, 2013, BIOMED SIGNAL PROCES, V8, P909, DOI 10.1016/j.bspc.2013.09.001
   Löfstedt T, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212110
   Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822
   Nayak DR, 2020, MULTIMED TOOLS APPL, V79, P15381, DOI 10.1007/s11042-019-7233-0
   Nayak DR, 2019, COMPUT MED IMAG GRAP, V77, DOI 10.1016/j.compmedimag.2019.101656
   Nayak DR, 2018, MULTIMED TOOLS APPL, V77, P3833, DOI 10.1007/s11042-016-4171-y
   Nayak DR, 2018, NEUROCOMPUTING, V282, P232, DOI 10.1016/j.neucom.2017.12.030
   Nayak DR, 2017, EXPERT SYST APPL, V88, P152, DOI 10.1016/j.eswa.2017.06.038
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Pedregosa F, MACHINE LEARNING PYT, V6
   PHOONG SM, 1995, IEEE T SIGNAL PROCES, V43, P649, DOI 10.1109/78.370620
   Pisano ED, 1998, J DIGIT IMAGING, V11, P193, DOI 10.1007/BF03178082
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   Saritha M, 2013, PATTERN RECOGN LETT, V34, P2151, DOI 10.1016/j.patrec.2013.08.017
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P3701, DOI 10.1007/s11042-016-3401-7
   Wang SH, 2016, BIOMED ENG-BIOMED TE, V61, P431, DOI 10.1515/bmt-2015-0152
   Wang SH, 2015, INT J IMAG SYST TECH, V25, P153, DOI 10.1002/ima.22132
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Zhang Y, 2012, PROG ELECTROMAGN RES, V130, P369, DOI 10.2528/PIER12061410
   Zhang Y, 2011, PROG ELECTROMAGN RES, V116, P65, DOI 10.2528/PIER11031709
   Zhang Y, 2010, PROG ELECTROMAGN RES, V109, P325, DOI 10.2528/PIER10090105
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22629, DOI 10.1007/s11042-017-5023-0
   Zhang YD, 2016, IEEE ACCESS, V4, P5937, DOI 10.1109/ACCESS.2016.2611530
   Zhang YD, 2015, INT J IMAG SYST TECH, V25, P317, DOI 10.1002/ima.22144
   Zhang YD, 2013, SCI WORLD J, DOI 10.1155/2013/130134
   Zhang YD, 2016, TECHNOL HEALTH CARE, V24, pS641, DOI 10.3233/THC-161191
   Zhang YD, 2015, ENTROPY-SWITZ, V17, P1795, DOI 10.3390/e17041795
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
   Zhou XX, 2015, LECT N BIOINFORMAT, V9043, P201, DOI 10.1007/978-3-319-16483-0_20
NR 52
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32195
EP 32224
DI 10.1007/s11042-020-09676-x
EA AUG 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562943300012
DA 2024-07-18
ER

PT J
AU Mahmood, T
   Shah, M
   Rashid, J
   Saba, T
   Nisar, MW
   Asif, M
AF Mahmood, Toqeer
   Shah, Mohsin
   Rashid, Junaid
   Saba, Tanzila
   Nisar, Muhammad Wasif
   Asif, Muhammad
TI A passive technique for detecting copy-move forgeries by image feature
   matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgeries; Tchebichef moments; Singular values decomposition;
   digital forensics; Forgery detection; Passive authentication
ID DIGITAL IMAGES; STEGANOGRAPHY; ZERNIKE
AB Due to the recent evolutions in the technologies various digital devices and image processing tools are available in the market. Consequently, crime rates are also proliferating in the developed and developing regions of the world. One such crime is the manipulation of digital image contents that can be achieved by using commercial and open-source image manipulation tools. The most widespread approach for image contents manipulation is the copy-move forgery. While crafting the copy-move forgeries (CMFs) it is often required to conceal undesired regions or duplicate desired regions in the image. Thus, forensic applications are needed to certify the contents of an image and to expose the manipulated areas. In this study, we are presenting a technique for detecting CMFs in digital images by image feature matching. The technique segments the suspected image into overlapping blocks and Tchebichef moments are computed for every block to characterize the manipulated regions of the image. Tchebichef moments are adopted because of their ability to represent image features more effectively as compared to other moments such as Legendre and Zernike moments. Each block of Tchebichef moments is further segmented into non-overlapping blocks and processed through singular values decomposition (SVD). To obtain a reduced size feature vector largest singular values of each sub-block are used that also enhanced the performance in the feature matching process. In the experiments standard databases namely, the DVMM Columbia University dataset, COVERAGE, and CoMoFoD are utilized to assess the performance of the proposed approach. The results conclusively demonstrate that the presented technique based on Tchebichef moments and SVD transcends the other methods.
C1 [Mahmood, Toqeer] Natl Text Univ, Dept Comp Sci, Faisalabad, Pakistan.
   [Shah, Mohsin] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei, Peoples R China.
   [Shah, Mohsin] Hazara Univ, Dept Informat Technol, Mansehra, Pakistan.
   [Rashid, Junaid] Air Univ Islamabad, Dept Comp Sci, Kamra Campus, Islamabad, Pakistan.
   [Saba, Tanzila] Prince Sultan Univ, Dept Informat Syst CCIS, Riyadh, Saudi Arabia.
   [Nisar, Muhammad Wasif] COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Rawalpindi, Pakistan.
   [Asif, Muhammad] Lahore Garrison Univ, Dept Comp Sci, Lahore, Pakistan.
C3 National Textile University - Pakistan; Chinese Academy of Sciences;
   University of Science & Technology of China, CAS; Hazara University; Air
   University Islamabad; Quaid I Azam University; Prince Sultan University;
   COMSATS University Islamabad (CUI)
RP Mahmood, T (corresponding author), Natl Text Univ, Dept Comp Sci, Faisalabad, Pakistan.
EM toqeer.mahmood@yahoo.com
RI Wasif, Muhammad/IUQ-2193-2023; Rashid, Junaid/M-2114-2016; Mahmood,
   Toqeer/O-1681-2013; Asif, Muhammad/JAC-2128-2023; Saba,
   Tanzila/D-4593-2018
OI Mahmood, Toqeer/0000-0003-3125-2430; Asif, Muhammad/0000-0001-6811-0044;
   Saba, Tanzila/0000-0003-3138-3801; Shah, Mohsin/0000-0003-2227-9797;
   Rashid, Junaid/0000-0002-1485-0757
CR Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   Almohammad A, 2009, INT CON ADV INFO NET, P471, DOI 10.1109/AINA.2009.67
   Amerini I, 2017, IEEE COMPUT SOC CONF, P1865, DOI 10.1109/CVPRW.2017.233
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], WORKSH INF HID DIG W
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Asghar K, 2017, AUST J FORENSIC SCI, V49, P281, DOI 10.1080/00450618.2016.1153711
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P1759, DOI 10.1016/j.sigpro.2011.01.022
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Columbia DVMM, 2004, RES LAB COLUMBIA IMA
   Cox I. J., 2002, Digital Watermarking
   Elhaminia B, 2019, MULTIMED TOOLS APPL, V78, P25591, DOI 10.1007/s11042-019-7713-2
   Fadl SM, 2017, NEUROCOMPUTING, V265, P57, DOI 10.1016/j.neucom.2016.11.091
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Hayat K, 2017, COMPUT ELECTR ENG, V62, P448, DOI 10.1016/j.compeleceng.2017.03.013
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Islam M, 2015, INT CONF FRONT INFO, P1, DOI 10.1109/FIT.2015.12
   Kessler G, 2004, TECHNICAL REPORT, V6
   Khan A, 2012, INFORM SCIENCES, V216, P155, DOI 10.1016/j.ins.2012.06.014
   Khan S, 2016, 2016 SIXTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH), P270, DOI 10.1109/INTECH.2016.7845022
   Khan Z, 2016, INT ARAB J INF TECHN, V13, P380
   Lai YC, 2018, MULTIMED TOOLS APPL, V77, P15093, DOI 10.1007/s11042-017-5094-y
   Lee JC, 2015, J VIS COMMUN IMAGE R, V31, P320, DOI 10.1016/j.jvcir.2015.07.007
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P30081, DOI 10.1007/s11042-018-6922-4
   Liu YQ, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P85, DOI 10.1145/3206004.3206010
   Mahmood T, 2018, APPL INTELL, V48, P1791, DOI 10.1007/s10489-017-1038-5
   Mahmood T, 2017, FORENSIC SCI INT, V279, P8, DOI 10.1016/j.forsciint.2017.07.037
   Mahmood T, 2016, 2016 SIXTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH), P578, DOI 10.1109/INTECH.2016.7845040
   Mahmood T, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/8713202
   Mahmoud K, 2016, INT ARAB J INF TECHN, V13, P930
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Parveen A, 2019, J COMPUTER SCI, V2, P89, DOI [10.1007/s42044-019-00029-y, DOI 10.1007/S42044-019-00029-Y]
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Raju P. M., 2018, J KING SAUD UNIV-COM
   Rao C. S, 2016, Lecture Notes in Electrical Engineering, V372, P529
   Rao Y, 2016, IEEE INT WORKS INFOR
   Rehman A, 2019, J INF SCI, V45, P767, DOI 10.1177/0165551518816303
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Sadeghi S, 2018, PATTERN ANAL APPL, V21, P291, DOI 10.1007/s10044-017-0678-8
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Uliyan DM, 2016, EXPERT SYST APPL, V64, P1, DOI 10.1016/j.eswa.2016.07.026
   Uliyan DM, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8070062
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   Wu Y, 2018, LECT NOTES COMPUT SC, V11210, P170, DOI 10.1007/978-3-030-01231-1_11
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Yao Y, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010003
   Zhang Z, 2017, KSII T INTERNET INF, V11, P4567, DOI 10.3837/tiis.2017.09.021
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
   Zhong JL, 2017, MULTIMED TOOLS APPL, V76, P14887, DOI 10.1007/s11042-016-4201-9
   Zhou JH, 2017, LECT NOTES COMPUT SC, V10431, P65, DOI 10.1007/978-3-319-64185-0_6
NR 57
TC 10
Z9 10
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 31759
EP 31782
DI 10.1007/s11042-020-09655-2
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562360200007
DA 2024-07-18
ER

PT J
AU Hu, K
   Huang, GH
   Yang, Y
   Pun, CM
   Ling, WK
   Cheng, LL
AF Hu, Ke
   Huang, Guoheng
   Yang, Ying
   Pun, Chi-Man
   Ling, Wing-Kuen
   Cheng, Lianglun
TI Rapid facial expression recognition under part occlusion based on
   symmetric SURF and heterogeneous soft partition network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Symmetric SURF; Gradient calculation; Face inpainting; Facial expression
   recognition; Heterogeneous soft partition
ID VEHICLE
AB Recently, deep learning has made great achievements in facial expression recognition. However, occlusion and large skew will greatly affect the accuracy of facial expression recognition in practice. Therefore, we propose a novel framework based on symmetric SURF and heterogeneous soft partition network to quickly recognize facial recognition under partial occlusion. In this framework, an occlusion detection module based on symmetric SURF is presented to detect the occlusion part, which helps to locate the horizontal symmetric area of the occlusion area. After that, a face inpainting module based on mirror transition is presented to rapidly accomplish the face inpainting under the unsupervised circumstance. Moreover, a recognition network based on heterogeneous soft partitioning is proposed for the facial expression recognition. After heterogeneous soft partitioning, the weights of each part are input and to into the recognition network as more prior information for training. Finally, we feed the weighted image into the trained neural network for expression recognition. Experimental results show that the accuracy of the proposed method is respectively 7% and 8% higher than the average accuracies from the state-of-the-art methods on Cohn-Kanade (CK +) and fer2013 datasets. Besides, the run time of our method is 2.38 s faster than the most advanced.
C1 [Hu, Ke; Huang, Guoheng; Yang, Ying; Cheng, Lianglun] Guangdong Univ Technol, Sch Comp, Guangzhou 510006, Peoples R China.
   [Pun, Chi-Man] Univ Macau, Dept Comp & Informat Sci, Macau 999078, Peoples R China.
   [Ling, Wing-Kuen] Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Peoples R China.
C3 Guangdong University of Technology; University of Macau; Guangdong
   University of Technology
RP Huang, GH; Cheng, LL (corresponding author), Guangdong Univ Technol, Sch Comp, Guangzhou 510006, Peoples R China.; Pun, CM (corresponding author), Univ Macau, Dept Comp & Informat Sci, Macau 999078, Peoples R China.; Ling, WK (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Peoples R China.
EM kevinwong@gdut.edu.cn; cmpun@umac.mo; yongquanling@gdut.edu.cn;
   llcheng@gdut.edu.cn
RI Pun, Chi Man/GRJ-3703-2022
OI Huang, Guoheng/0000-0002-3640-3229
FU Key-Area Research and Development Program of Guangdong Province
   [2019B010109001, 2019B010153002, 2018B010109007]; National Natural
   Science Foundation of China [61702111]; National Nature Science
   Foundation of China-Guangdong Joint Fund [83-Y40G33-9001-18/20];
   National Key Research and Development Program of China [2017YFB1201203];
   Guangdong Provincial Key Laboratory of Cyber-Physical System
   [2016B030301008]; National Natural Science Foundation of Guangdong Joint
   Fund [U1701262, U1801263]; "Blue Fire Plan" (Huizhou)
   Industry-University-Research Joint Innovation Fund 2017 Project of the
   Ministry of Education [CXZJHZ201730]
FX Special thanks to Mr. Junan Chen and Prof. Weiwen Zhang for their
   participation in writing or technical editing of the manuscript. In
   addition, this work was supported by the Key-Area Research and
   Development Program of Guangdong Province under Grant 2019B010153002,
   the National Natural Science Foundation of China under Grant 61702111,
   the National Nature Science Foundation of China-Guangdong Joint Fund
   under Grant 83-Y40G33-9001-18/20, the National Key Research and
   Development Program of China under Grant 2017YFB1201203, the Guangdong
   Provincial Key Laboratory of Cyber-Physical System under Grant
   2016B030301008, the National Natural Science Foundation of Guangdong
   Joint Fund under Grant U1801263, the National Natural Science Foundation
   of Guangdong Joint Fund under Grant U1701262, the Key-Area Research and
   Development Program of Guangdong Province under Grant 2018B010109007,
   the "Blue Fire Plan" (Huizhou) Industry-University-Research Joint
   Innovation Fund 2017 Project of the Ministry of Education under Grant
   CXZJHZ201730, and Key-Area Research and Development Program of Guangdong
   Province under Grant 2019B010109001.
CR [Anonymous], 2002, Computer Science, DOI DOI 10.1007/978-3-642-27733-7299-3
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Cai J, 2019, ARXIV191101045
   Chang T, 2018, ARXIV180300185
   Chen LC, 2015, PATTERN RECOGN, V48, P1979, DOI 10.1016/j.patcog.2014.12.018
   Ghimire D, 2016, SENSORS-BASEL, V13, P7734
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hsieh JW, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P472, DOI 10.1109/AVSS.2013.6636685
   Hsieh JW, 2014, IEEE T INTELL TRANSP, V15, P6, DOI 10.1109/TITS.2013.2294646
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Jeong JH, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162839
   Kan M, 2014, PROC CVPR IEEE, P1883, DOI 10.1109/CVPR.2014.243
   Kim BK, 2016, J MULTIMODAL USER IN, V10, P173, DOI 10.1007/s12193-015-0209-0
   Li DY, 2019, KNOWL INF SYST, V59, P219, DOI 10.1007/s10115-018-1176-z
   Li YH, 2018, CHIN CONTR CONF, P9021, DOI 10.23919/ChiCC.2018.8483963
   Li YJ, 2017, PROC CVPR IEEE, P5892, DOI 10.1109/CVPR.2017.624
   [李勇 Li Yong], 2018, [自动化学报, Acta Automatica Sinica], V44, P176
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Meng ZB, 2017, IEEE INT CONF AUTOMA, P558, DOI 10.1109/FG.2017.140
   Ming-Wei Huang, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1750, DOI 10.1109/CISP.2010.5647898
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Patel J., 2018, IJTIMES, V4, P1230
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Qayyum H, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/9854050
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   [王坤峰 Wang Kunfeng], 2017, [自动化学报, Acta Automatica Sinica], V43, P321
   Yang Yang, 2019, ARXIV191111394
   Yao N. M., 2016, ZIDONGHUA XUEBAO, V44, P865
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Zhang J, 2016, PROC CVPR IEEE, P3428, DOI 10.1109/CVPR.2016.373
   Zhu ZY, 2013, IEEE I CONF COMP VIS, P113, DOI 10.1109/ICCV.2013.21
NR 37
TC 4
Z9 5
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30861
EP 30881
DI 10.1007/s11042-020-09566-2
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560297300013
DA 2024-07-18
ER

PT J
AU Ntalampiras, S
AF Ntalampiras, Stavros
TI Emotional quantification of soundscapes by learning between samples
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic ecology; Audio signal processing; Afffective computing
ID FRAMEWORK
AB Predicting the emotional responses of humans to soundscapes is a relatively recent field of research coming with a wide range of promising applications. This work presents the design of two convolutional neural networks, namely ArNet and ValNet, each one responsible for quantifying arousal and valence evoked by soundscapes. We build on the knowledge acquired from the application of traditional machine learning techniques on the specific domain, and design a suitable deep learning framework. Moreover, we propose the usage of artificially created mixed soundscapes, the distributions of which are located between the ones of the available samples, a process that increases the variance of the dataset leading to significantly better performance. The reported results outperform the state of the art on a soundscape dataset following Schafer's standardized categorization considering both sound's identity and the respective listening context.
C1 [Ntalampiras, Stavros] Univ Milan, Via Celoria 18, Milan, Italy.
C3 University of Milan
RP Ntalampiras, S (corresponding author), Univ Milan, Via Celoria 18, Milan, Italy.
EM name.surname@unimi.it
RI Ntalampiras, Stavros/W-5636-2019
OI Ntalampiras, Stavros/0000-0003-3482-9215
FU NVIDIA Corporation
FX We gratefully acknowledge the support of NVIDIA Corporation with the
   donation of the Titan V GPU used for this research.
CR Berglund B, 2007, SOUNDSCAPE PSYCHOPHY, V6, P3704
   Brocolini L, 2010, COMP MULTIPLE LINEAR
   Davies W.J., 2009, The Positive Soundscape Project: A Synthesis of Results from Many Disciplines
   Drossos K, 2015, IEEE T AFFECT COMPUT, V6, P27, DOI 10.1109/TAFFC.2015.2392768
   Fan J, 2018, SOUND MUS COMP C
   Fan JY, 2017, INT CONF AFFECT, P196, DOI 10.1109/ACII.2017.8273600
   Fukayama S, 2016, INT CONF ACOUST SPEE, P71, DOI 10.1109/ICASSP.2016.7471639
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Kim BH, 2020, IEEE T AFFECT COMPUT, V11, P230, DOI 10.1109/TAFFC.2018.2790939
   Lunden P., 2016, P INTERNOISE NOISE C, VVolume 253, P2017
   Moscoso P, 2018, J ECOACOUSTICS, V2, DOI 10.22261/jea.ylfj6q
   Ntalampiras S, 2020, J AUDIO ENG SOC, V68, P7, DOI 10.17743/jaes.2019.0045
   Ntalampiras S, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON COGNITIVE COMPUTING (IEEE ICCC 2019), P36, DOI 10.1109/ICCC.2019.00018
   Ntalampiras S, 2019, J ACOUST SOC AM, V145, pEL541, DOI 10.1121/1.5111975
   Ntalampiras S, 2019, IEEE J-STSP, V13, P275, DOI 10.1109/JSTSP.2019.2905431
   Ntalampiras S, 2017, IET SIGNAL PROCESS, V11, P349, DOI 10.1049/iet-spr.2015.0065
   Ntalampiras S, 2017, J ACOUST SOC AM, V141, P1694, DOI 10.1121/1.4977749
   Ntalampiras S, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/594103
   Piczak KJ, 2015, IEEE INT WORKS MACH
   Schafer R, 1993, INNER TRADITIONS BEA
   Schuller BW, 2018, COMMUN ACM, V61, P90, DOI 10.1145/3129340
   Thorogood M, 2013, COMPUTATIONALLY GENE, DOI 10.13140/2.1.4191.0084
   Tokozume Y., 2017, ARXIV171110282
   Ward T, 2014, 2014 International Conference on Interactive Mobile Communication Technologies and Learning (IMCL), P265, DOI 10.1109/IMCTL.2014.7011145
   Weninger F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00292
   Yang YH, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168754
   Zhang CS, 2017, ELECTRON LETT, V53, P1674, DOI 10.1049/el.2017.3334
   Zhang ZC, 2020, IEEE ACCESS, V8, P14642, DOI 10.1109/ACCESS.2020.2966712
NR 28
TC 6
Z9 6
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30387
EP 30395
DI 10.1007/s11042-020-09430-3
EA AUG 2020
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559953900013
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Sun, J
   Ding, Y
   Zhu, XL
   Xi, JT
   Zhang, YD
AF Sun, Jin
   Ding, Yu
   Zhu, Xinglong
   Xi, Juntong
   Zhang, Yu-Dong
TI Extended Gaussian sphere and similarity fusion method for reassembly of
   3D cultural relics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extended Gaussian sphere; Similarity; Reassembly; Broken pieces;
   Bowl-shaped
ID ALGORITHM
AB Screening of the best matching pair of broken pieces of 3D cultural relics is an important step in realizing their automatic reassembly. Herein, a reassembly framework based on an extended Gaussian sphere (EGS) and a similarity function is proposed. First, the inner surface was identified based on the proportion of the point cloud and the smoothness of the broken pieces, thereby avoiding over-segmentation. The EGS model was then used to represent the geometric and color information of the inner surface boundary. The similarity function, which was defined to describe the global characteristics of the EGS model, can help the program to automatically screen the two most similar broken pieces to be matched. In this way, the rough alignment step was completed. Finally, a fine alignment step was conducted using the iterative closest point method. This reassembly framework is effective for broken bowl-shaped pieces. The average screening accuracy of our final method is 93.87% and the calculation time is 9.7 s. Compared with a traditional Gaussian sphere model based on a normal vector and curvature, the proposed method can improve the screening accuracy and average calculation speed by 6.60% and 16.08%, respectively. Experimental results with real datasets demonstrated the validity and effectiveness of the proposed method.
C1 [Sun, Jin; Ding, Yu; Zhu, Xinglong] Yangzhou Univ, Coll Mech Engn, Yangzhou 225127, Jiangsu, Peoples R China.
   [Sun, Jin; Ding, Yu; Xi, Juntong] Shanghai Jiao Tong Univ, China State Key Lab Mech Syst & Vibrat, Shanghai 200240, Peoples R China.
   [Sun, Jin; Zhang, Yu-Dong] Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
C3 Yangzhou University; Shanghai Jiao Tong University; University of
   Leicester
RP Sun, J (corresponding author), Yangzhou Univ, Coll Mech Engn, Yangzhou 225127, Jiangsu, Peoples R China.; Sun, J (corresponding author), Shanghai Jiao Tong Univ, China State Key Lab Mech Syst & Vibrat, Shanghai 200240, Peoples R China.; Sun, J (corresponding author), Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
EM sunjin1001@126.com
RI Zhang, Yudong/I-7633-2013
FU National Natural Science Foundation of China [51475409]; Research
   Project of State Key Laboratory of Mechanical System and Vibration
   [MSV201810]; Jiangsu Province Basic Research Program Natural Science
   Foundation [BK20171287]
FX The authors would like to thank all the reviewers for their valuable
   comments. This study was supported by the National Natural Science
   Foundation of China (Grant No. 51475409), Research Project of State Key
   Laboratory of Mechanical System and Vibration (Grant No. MSV201810), and
   Jiangsu Province Basic Research Program Natural Science Foundation
   (Grant No. BK20171287).
CR Altantsetseg E, 2014, VISUAL COMPUT, V30, P929, DOI 10.1007/s00371-014-0959-9
   Cohen F, 2016, MULTIMED TOOLS APPL, V75, P3709, DOI 10.1007/s11042-014-2190-0
   Gao YZ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020427
   Ge YF, 2018, ENG GEOL, V242, P44, DOI 10.1016/j.enggeo.2018.05.007
   Hu L, 2017, J VIS COMMUN IMAGE R, V44, P106, DOI 10.1016/j.jvcir.2017.01.013
   Li JL, 2016, SPECTROSC SPECT ANAL, V36, P1500, DOI 10.3964/j.issn.1000-0593(2016)05-1500-08
   Nguyen NV, 2010, INT CONF COMPUT AUTO, P71, DOI 10.1109/ICCAE.2010.5451521
   Oxholm G, 2013, J CULT HERIT, V14, P51, DOI 10.1016/j.culher.2012.02.017
   Papaodysseus C, 2012, COMPUT MATH APPL, V64, P2712, DOI 10.1016/j.camwa.2012.08.003
   Sun JL, 2018, ASIAN J CONTROL, V20, P104, DOI 10.1002/asjc.1517
   Tsamoura E, 2010, IEEE T IMAGE PROCESS, V19, P680, DOI 10.1109/TIP.2009.2035840
   Wu MM, 2018, POWDER TECHNOL, V338, P55, DOI 10.1016/j.powtec.2018.06.045
   Zhang K, 2014, GRAPH MODELS, V76, P484, DOI 10.1016/j.gmod.2014.03.001
   Zhang M, 2017, VISUAL COMPUT, V33, P1601, DOI 10.1007/s00371-016-1303-3
   Zhang YH, 2018, J CULT HERIT, V33, P191, DOI 10.1016/j.culher.2018.03.001
   Zhao FQ, 2018, IET COMPUT VIS, V12, P76, DOI 10.1049/iet-cvi.2016.0392
NR 16
TC 1
Z9 1
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30187
EP 30203
DI 10.1007/s11042-020-09535-9
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559430000001
DA 2024-07-18
ER

PT J
AU Cheng, CH
AF Cheng, Ching-Hsue
TI A DWPT domain transform and COM statistics method combined with rough
   set for images classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rough sets (RS); Discrete wavelet packet transform (DWPT); Co-occurrence
   matrix (COM); Image classification
ID TEXTURE CLASSIFICATION; WAVELET; ENTROPY; SYSTEM
AB This paper compares the discrete wavelet packet transform combined with rough sets (DWPT-RS) and co-occurrence matrix combined with rough sets (COM-RS) for invariant pixel region image classification. In verification, the Brodatz and building material datasets were employed in experiments to verify the performances of the two methods. Moreover, the experiments have been performed recursively for over 600,000 rounds, and employed different level DWPT, different wavelet filter, and attribute data discretization to find the best results. The results show: (1) the proposed method outperforms the listing methods in accuracy, (2) the non-discretization classification accuracy is better than the discretization classification accuracy, (3) the 2-level DWPT is better than that of the 1-level DWPT, (4) the sym3 wavelet filter has better performance than the listing filters, and (5) the proposed DWPT-RS method has a fast computation time than the listing methods. The results can help people who want to perform related research in the future to choose the best method to match it more effectively.
C1 [Cheng, Ching-Hsue] Natl Yunlin Univ Sci & Technol, Dept Informat Management, Touliu, Yunlin, Taiwan.
C3 National Yunlin University Science & Technology
RP Cheng, CH (corresponding author), Natl Yunlin Univ Sci & Technol, Dept Informat Management, Touliu, Yunlin, Taiwan.
EM chcheng@yuntech.edu.tw
RI Cheng, Ching-Hsue/D-1785-2012
OI Cheng, Ching-Hsue/0000-0002-5509-6965
CR ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Amin A, 2017, NEUROCOMPUTING, V237, P242, DOI 10.1016/j.neucom.2016.12.009
   [Anonymous], 1992, R. woods digital image processing
   [Anonymous], 2005, BRODATZ TEXTURE IMAG
   [Anonymous], 2008, ELCVIA Electron. Lett. Comput. Vis. Image Anal, DOI DOI 10.5565/REV/ELCVIA.268
   Arivazhagan S, 2003, PATTERN RECOGN LETT, V24, P1513, DOI 10.1016/S0167-8655(02)00390-2
   Avci E, 2005, EXPERT SYST APPL, V29, P175, DOI 10.1016/j.eswa.2005.01.016
   Avci E., 2005, ASIAN J INFORM TECHN, V4, P133, DOI [10.3724/SP.J.1146.2007.00129, DOI 10.3724/SP.J.1146.2007.00129]
   Avci E, 2008, APPL SOFT COMPUT, V8, P225, DOI 10.1016/j.asoc.2007.01.003
   Avci E, 2007, EXPERT SYST APPL, V32, P919, DOI 10.1016/j.eswa.2006.01.025
   Chang TK, 2008, 2008 2 INT S INT INF
   Chellappa R., 1985, PROGR PATTERN RECOGN, V2, P79
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705
   Dou WB, 2007, IMAGE VISION COMPUT, V25, P164, DOI 10.1016/j.imavis.2006.01.025
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Grzymala-Busse J. W., 1997, Fundamenta Informaticae, V31, P27
   Han Y, 2007, IMAGE VISION COMPUT, V25, P1239, DOI 10.1016/j.imavis.2006.07.028
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Jahne B., 1995, Digital image processing
   Jensen R, 2007, IEEE T FUZZY SYST, V15, P73, DOI 10.1109/TFUZZ.2006.889761
   Ji ZX, 2017, NEUROCOMPUTING, V266, P550, DOI 10.1016/j.neucom.2017.05.069
   Kim Y, 2017, APPL SOFT COMPUT, V55, P127, DOI 10.1016/j.asoc.2017.02.006
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Loether H.J., 1993, DESCRIPTIVE INFERENT, V4th
   Lu XK, 2015, INT CONF ACOUST SPEE, P1498, DOI 10.1109/ICASSP.2015.7178220
   Mac Parthaláin N, 2009, PATTERN RECOGN, V42, P655, DOI 10.1016/j.patcog.2008.08.029
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Muneeswaran K, 2005, PATTERN RECOGN, V38, P1495, DOI 10.1016/j.patcog.2005.03.021
   Pan RL, 2017, NEUROCOMPUTING, V266, P619, DOI 10.1016/j.neucom.2017.05.068
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Pawlak Z., 1991, ROUGH SETS THEORETIC
   Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Romero P, 2016, EUR J OPER RES, V253, P170, DOI 10.1016/j.ejor.2015.12.054
   Simonyan K, 2015, IEEE INT C ICLR
NR 39
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29845
EP 29864
DI 10.1007/s11042-020-09517-x
EA AUG 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000567227300004
DA 2024-07-18
ER

PT J
AU Elmi, Y
   Zargari, F
   Rahmani, AM
AF Elmi, Yasser
   Zargari, Farzad
   Rahmani, Amir Masoud
TI Iterative approach for parametric PSF estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind image Deblurring; Motion blur vector; PSF estimation; No-reference
   image quality metrics
ID KERNEL ESTIMATION; MOTION; IMAGES
AB In this paper a parametric point spread function (PSF) estimation method is presented. This method can be employed for estimating the parameters of linear motion blur vector. The proposed method works on single image and estimates angle and length of motion blur vector to generate required PSF for deblurring. This method is based on step-by-step estimation of motion blur vector. In the first approximation the blind method considers short length vectors in all directions and deblurs image with PSF of these candidate vectors. The quality of deblurred image is assessed by a no-reference quality measurement metric which is proposed in this paper. The proposed no-reference image quality metric evaluates degradation in sharpness of edges and the amount of resulted artifact caused by saturated pixels, in the deblurred image. Those motion vectors that caused unacceptable deblurring results are omitted in the next iteration. The approximation is improved by increasing the length of the remaining vectors and the same process continues iteratively. The process goes on until only one vector remains as the estimation for motion blur vector. Experimental results show that in estimation of motion blur vectors, the length estimation error is less than one pixel in 85% of the cases and angle estimation error in 95% of the cases is less than one degree. Comparing with a conventional method indicates that the proposed method shows more than four times improvement in length estimation and 10% improvement in angle estimation. Moreover, the proposed method has comparatively lower computational load than other conventional deblurring methods.
C1 [Elmi, Yasser; Rahmani, Amir Masoud] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
   [Zargari, Farzad] Iran Telecom Res Ctr, Informat Technol Fac, Tehran, Iran.
C3 Islamic Azad University
RP Zargari, F (corresponding author), Iran Telecom Res Ctr, Informat Technol Fac, Tehran, Iran.
EM elmi@iaus.ac.ir; zargari@itrc.ac.ir; rahmani@srbiau.ac.ir
RI Rahmani, Amir Masoud/K-2702-2013; Elmi, Yasser/AAO-2111-2021
OI Rahmani, Amir Masoud/0000-0001-8641-6119; Elmi,
   Yasser/0000-0002-4319-9641; Zargari, Farzad/0000-0003-1585-9283
CR Adam T, 2020, SIGNAL IMAGE VIDEO P, V14, P115, DOI 10.1007/s11760-019-01531-3
   Babacan SD, 2012, LECT NOTES COMPUT SC, V7577, P341, DOI 10.1007/978-3-642-33783-3_25
   Bai YC, 2019, IEEE T IMAGE PROCESS, V28, P1404, DOI 10.1109/TIP.2018.2874290
   Ben-Ezra M, 2004, IEEE T PATTERN ANAL, V26, P689, DOI 10.1109/TPAMI.2004.1
   Brusius F., 2011, VISIGRAPP 2011. Communications in Computer and Information Science, P105, DOI DOI 10.1007/978-3-642-32350-8_7
   Dobes M, 2010, DIGIT SIGNAL PROCESS, V20, P1677, DOI 10.1016/j.dsp.2010.03.012
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gregson J, 2013, PROC CVPR IEEE, P1043, DOI 10.1109/CVPR.2013.139
   Javaran TA, 2019, MULTIMED TOOLS APPL, V78, P22555, DOI 10.1007/s11042-019-7402-1
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P14485, DOI 10.1007/s11042-018-6797-4
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Li YL, 2020, IEEE T COMPUT IMAG, V6, P666, DOI 10.1109/TCI.2020.2964202
   Liu YM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508391
   Ma CC, 2018, MULTIMED TOOLS APPL, V77, P28077, DOI 10.1007/s11042-018-6009-2
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   MESAROVIC VZ, 1995, IEEE T IMAGE PROCESS, V4, P1096, DOI 10.1109/83.403444
   Mosleh A, 2018, IEEE T IMAGE PROCESS, V27, P580, DOI 10.1109/TIP.2017.2764625
   Mosleh A, 2015, PROC CVPR IEEE, P4961, DOI 10.1109/CVPR.2015.7299130
   Mosleh A, 2014, LECT NOTES COMPUT SC, V8692, P247, DOI 10.1007/978-3-319-10593-2_17
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Oliveira JP, 2014, IEEE T IMAGE PROCESS, V23, P466, DOI 10.1109/TIP.2013.2286328
   Pan JS, 2014, PROC CVPR IEEE, P2901, DOI 10.1109/CVPR.2014.371
   Rezaie F, 2018, MULTIMED TOOLS APPL, V77, P2529, DOI 10.1007/s11042-017-4432-4
   RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055
   Sindelar O, 2014, IEEE COMPUT SOC CONF, P191, DOI 10.1109/CVPRW.2014.34
   Soe AK, 2012, INT C SYST INF ICSAI, P1855, DOI [10.1109/ICSAI.2012.6223408, DOI 10.1109/ICSAI.2012.6223408]
   Sola YE, 2019, SIGNAL PROCESS, V154, P250, DOI 10.1016/j.sigpro.2018.09.015
   Su SC, 2017, PROC CVPR IEEE, P237, DOI 10.1109/CVPR.2017.33
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Xue F, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2014.2380174
   Yu J, 2019, MULTIMED TOOLS APPL, V78, P18549, DOI 10.1007/s11042-019-7237-9
   Zhang FJ, 2018, MULTIMED TOOLS APPL, V77, P26239, DOI 10.1007/s11042-018-5847-2
   Zhu X, 2012, LECT NOTES COMPUT SC, V7576, P636, DOI 10.1007/978-3-642-33715-4_46
NR 33
TC 2
Z9 3
U1 5
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29433
EP 29450
DI 10.1007/s11042-020-09511-3
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559640400012
DA 2024-07-18
ER

PT J
AU Choi, K
   Oh, BS
   Yu, S
AF Choi, Kwontaeg
   Oh, Beom-Seok
   Yu, Sunjin
TI Memory access minimization for mean-shift tracking in mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Mobile device; Mean shift
ID TARGET TRACKING; OBJECT TRACKING; VISION
AB Due to the development of artificial intelligence and computer vision technology, many autonomous drones have been studied. However, computer vision technology requires high performance CPU due to its high complexity, and battery consumption is so high that drones are constrained to fly for a long time. Therefore, low-power mobile devices require tracking algorithms that minimize battery consumption. In this paper, we propose a mean-shift based tracking algorithm that minimizes memory access to reduce battery consumption. To accomplish this, we minimize the number of memory accesses by using an algorithm that divides the direction of the mean-shift vector into eight, and calculates the sum of the density maps only for the new area without calculating the sum of the density maps for the already calculated area. It is possible to increase the calculation efficiency by lowering the memory access cost. Experimental results show that the proposed method is more efficient than the existing method.
C1 [Choi, Kwontaeg] Kangnam Univ, Div Software Applicat, Yongin, South Korea.
   [Oh, Beom-Seok] Gyeongsang Natl Univ, Dept Comp Sci, Jinju, South Korea.
   [Yu, Sunjin] Changwon Natl Univ, Dept Culture Techno, Chang Won, South Korea.
C3 Kangnam University; Gyeongsang National University; Changwon National
   University
RP Yu, S (corresponding author), Changwon Natl Univ, Dept Culture Techno, Chang Won, South Korea.
EM kwontaeg.choi@kangnam.ac.kr; bsoh@gnu.ac.kr; sjyu@changwon.ac.kr
OI Yu, Sunjin/0000-0001-9292-4099
FU National Research Foundation of Korea(NRF) - Korea government(Ministry
   of Science, ICT & Future Planning) [NRF-2017R1C1B5017751]
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(Ministry of Science, ICT
   & Future Planning) (No. NRF-2017R1C1B5017751)
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   Baek D, 2018, I SYMPOS LOW POWER E, P279, DOI 10.1145/3218603.3218614
   Barták R, 2015, 2015 FOURTEENTH MEXICAN INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (MICAI), P35, DOI 10.1109/MICAI.2015.12
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bewley SA, 2016, ARXIV160200763
   Boudjit K, 2015, ICIMCO 2015 PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, VOL. 2, P223
   Collins RT, 2003, PROC CVPR IEEE, P234
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Faessler M, 2016, J FIELD ROBOT, V33, P431, DOI 10.1002/rob.21581
   Fotouhi A, 2017, I S WORLD WIREL MOBI
   Nguyen HD, 2019, MULTIMED TOOLS APPL, V78, P4563, DOI 10.1007/s11042-018-6141-z
   Hassija V, 2020, COMPUT COMMUN, V149, P51, DOI 10.1016/j.comcom.2019.09.021
   Hsieh M.-R., 2017, IEEE INT C COMP VIS
   Kanellakis C, 2017, J INTELL ROBOT SYST, V87, P141, DOI 10.1007/s10846-017-0483-z
   Kim J, 2019, IEEE T INTELL TRANSP, V20, P4174, DOI 10.1109/TITS.2018.2883058
   Lim H, 2015, IEEE INT CONF ROBOT, P2182, DOI 10.1109/ICRA.2015.7139487
   Liu XC, 2016, LECT NOTES COMPUT SC, V9906, P869, DOI 10.1007/978-3-319-46475-6_53
   Liu Y, 2019, IEEE T MULTIMEDIA, V21, P664, DOI 10.1109/TMM.2018.2863604
   Ning J, 2012, IET COMPUT VIS, V6, P62, DOI 10.1049/iet-cvi.2009.0075
   Paliwal N., 2019, International Journal of Social and Humanistic Computing, V3, P191, DOI [10.1504/IJSHC.2019.101602, DOI 10.1504/IJSHC.2019.101602]
   Pan S, 2019, IEEE INT C COMP VIS
   Phadke G, 2017, SIGNAL IMAGE VIDEO P, V11, P665, DOI 10.1007/s11760-016-1008-0
   Rohan A, 2019, J ELECTR ENG TECHNOL, V14, P1395, DOI 10.1007/s42835-019-00119-8
   Sanchez-Rodriguez JP, 2018, ROBOTICA, V36, P1225, DOI 10.1017/S0263574718000358
   Shin M, 2019, IEEE T VEH TECHNOL, V68, P4235, DOI 10.1109/TVT.2019.2903144
   Sun J, 2012, SENSORS-BASEL, V12, P8218, DOI 10.3390/s120608218
   Suzuki KAO, 2012, J INTELL ROBOT SYST, V65, P563, DOI 10.1007/s10846-011-9616-y
   Topkaya IS, 2019, SIGNAL IMAGE VIDEO P, V13, P61, DOI 10.1007/s11760-018-1328-3
   Unlu Eren, 2019, IPSJ Transactions on Computer Vision and Applications, V11, DOI 10.1186/s41074-019-0059-x
   Wang H, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P1114, DOI [10.1109/icma.2019.8816295, 10.1109/ICMA.2019.8816295]
   Wang N, 2019, IEEE-ASME T MECH, V24, P1064, DOI 10.1109/TMECH.2019.2906395
   Xu SB, 2020, IEEE T INTELL TRANSP, V21, P48, DOI 10.1109/TITS.2019.2892926
   Yang C, 2005, PROC CVPR IEEE, P176
   Yu HY, 2020, INT J COMPUT VISION, V128, P1141, DOI 10.1007/s11263-019-01266-1
   Yu WS, 2017, MULTIMED TOOLS APPL, V76, P10973, DOI 10.1007/s11042-016-3472-5
   Zeng HQ, 2016, NEUROCOMPUTING, V217, P3, DOI 10.1016/j.neucom.2015.11.130
   Zhang XG, 2010, ROBOT AUTON SYST, V58, P1197, DOI 10.1016/j.robot.2010.08.002
   Zhen XX, 2020, ALGORITHMS, V13, DOI 10.3390/a13010015
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
NR 41
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34173
EP 34187
DI 10.1007/s11042-020-09364-w
EA JUL 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000559382300003
DA 2024-07-18
ER

PT J
AU Huang, R
   Liao, XJ
   Dong, AH
   Sun, SY
AF Huang, Rong
   Liao, Xiaojuan
   Dong, Aihua
   Sun, Shaoyuan
TI Cryptanalysis and security enhancement for a chaos-based color image
   encryption algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptanalysis; Chosen-plaintext attack; Image encryption; Chaotic
   cryptography; Hash function
ID COMBINATION; IMPROVEMENT
AB Recently, a color image encryption scheme based on the Sine-Sine chaotic system has been proposed by Wanget al. (Signal Processing 144:444-452,2018). In their scheme, a private parameterEis defined based on global plain information in hope of resisting the chosen-plaintext attack. However, we find that the private parameter is dependent purely on average intensity of a plain image, thereby leaving an open door for cryptanalysis. In this paper, we propose a collision-based inference algorithm to effectively break Wang's image cipher. Then, in order to enhance the security, we develop a hash-based cryptosystem under the permutation-and-diffusion architecture. We conduct experiments and perform extensive comparative studies.The qualitative and quantitative results demonstrate the effectiveness of the collision-based inference algorithm, and the superiority of the proposed image cipher especially in terms of plaintext sensitivity.
C1 [Huang, Rong; Dong, Aihua; Sun, Shaoyuan] Donghua Univ, Coll Informat Sci & Technol, Shanghai, Peoples R China.
   [Huang, Rong; Dong, Aihua; Sun, Shaoyuan] Donghua Univ, Engn Res Ctr Digitized Text & Apparel Technol, Minist Educ, Shanghai, Peoples R China.
   [Liao, Xiaojuan] Chengdu Univ Technol, Sch Cyber Secur, Chengdu, Peoples R China.
C3 Donghua University; Donghua University; Chengdu University of Technology
RP Huang, R (corresponding author), Donghua Univ, Coll Informat Sci & Technol, Shanghai, Peoples R China.; Huang, R (corresponding author), Donghua Univ, Engn Res Ctr Digitized Text & Apparel Technol, Minist Educ, Shanghai, Peoples R China.
EM rong.huang@dhu.edu.cn
OI Huang, Rong/0000-0003-3248-4620
FU National Key Research and Development Program of China [2019YFC1521300];
   National Natural Science Foundation of China [61806171]; Program for the
   Fundamental Research of the Shanghai Committee of Science and Technology
   [15JC1400600]; Fundamental Research Funds of the Central Universities
   [16D110412, 17D110408]
FX This work was supported in part by the National Key Research and
   Development Program of China (2019YFC1521300), the National Natural
   Science Foundation of China (61806171), the Program for the Fundamental
   Research of the Shanghai Committee of Science and Technology
   (15JC1400600), and the Fundamental Research Funds of the Central
   Universities (16D110412,17D110408).
CR Chen JX, 2015, NONLINEAR DYNAM, V81, P1151, DOI 10.1007/s11071-015-2057-6
   Chen JX, 2015, SIGNAL PROCESS, V111, P294, DOI 10.1016/j.sigpro.2015.01.003
   Diab H, 2018, SIGNAL PROCESS, V148, P172, DOI 10.1016/j.sigpro.2018.02.011
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Fan HJ, 2018, SIGNAL PROCESS, V143, P28, DOI 10.1016/j.sigpro.2017.08.018
   Fan HJ, 2017, MATH PROBL ENG, P11
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Geetha S, 2018, INT J INF SECUR PRIV, V12, P42, DOI 10.4018/IJISP.2018070104
   Hsiao HI, 2015, SIGNAL PROCESS, V117, P281, DOI 10.1016/j.sigpro.2015.06.007
   Hu GQ, 2017, NONLINEAR DYNAM, V88, P1305, DOI 10.1007/s11071-016-3311-2
   Laiphrakpam DS, 2017, OPTIK, V135, P200, DOI 10.1016/j.ijleo.2017.01.062
   Lin ZS, 2015, IEEE T CIRC SYST VID, V25, P1203, DOI 10.1109/TCSVT.2014.2369711
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P7739, DOI 10.1007/s11042-015-2691-5
   Mandal MK, 2014, SECUR COMMUN NETW, V7, P2145, DOI 10.1002/sec.927
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P1817, DOI 10.1007/s11042-015-3085-4
   Özkaynak F, 2018, NONLINEAR DYNAM, V92, P305, DOI 10.1007/s11071-018-4056-x
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang XP, 2017, MULTIMED TOOLS APPL, V76, P15641, DOI 10.1007/s11042-016-3861-9
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhao JF, 2015, NONLINEAR DYNAM, V80, P1721, DOI 10.1007/s11071-015-1911-x
NR 26
TC 9
Z9 9
U1 3
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27483
EP 27509
DI 10.1007/s11042-020-09163-3
EA JUL 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000552591100001
DA 2024-07-18
ER

PT J
AU Wei, ZH
   Shi, F
   Song, H
   Ji, WX
   Han, GH
AF Wei, Zenghui
   Shi, Feng
   Song, Hong
   Ji, Weixing
   Han, Guanghui
TI Attentive boundary aware network for multi-scale skin lesion
   segmentation with adversarial training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attention; ASPP; GAN; Multi-scale; Skin lesion segmentation
ID DERMOSCOPY IMAGES
AB Because of the large variation in appearance, the existence of artifacts, the low contrast, skin lesion segmentation remains a challenging task. In this paper, we propose a novel Scale Attention based Atrous Spatial Pyramid Pooling (Scale-Att-ASPP) module for skin lesion segmentation with attentive boundary aware. Our network is based on the Generative Adversarial Network (GAN), which includes the segmentation network and the critic network. In the segmentation network, we design the Scale-Att-ASPP module to automatically select the optimal scale of the skin lesion feature of the intermediate convolution layer (Inter-CL) in the encoding path, meanwhile, the irrelevant artifacts features are automatically diminished without using complex pre-processing. After introducing the output of the Scale-Att-ASPP module to the same level layer in the decoding path through skip connection in pixel-wise addition way, the more meaningful semantic segmentation is gained. The Jaccard distance loss is employed to solve the problem of label imbalance in skin lesion segmentation. Our network is adversarially trained on ISBI 2017 dataset by the multi-scaleL(1)loss introduced by the critic network, which guides the Scale-Att-ASPP module learning to focus on the optimal scale of the skin lesion feature. Finally, our network significantly improves the segmentation performance compared with other state-of-the-art methods, especially for the JAC and SEN scores. Besides, our proposed network works efficiently and shows robustness for different datasets.
C1 [Wei, Zenghui; Shi, Feng; Song, Hong; Ji, Weixing] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing, Peoples R China.
   [Wei, Zenghui] Yellow River Conservancy Tech Inst, Sch Informat Engn, Kaifeng, Peoples R China.
   [Han, Guanghui] Sun Yat Sen Univ, Sch Biomed Engn, Guangzhou, Peoples R China.
C3 Beijing Institute of Technology; Yellow River Conservancy Technical
   Institute; Sun Yat Sen University
RP Wei, ZH; Song, H (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing, Peoples R China.; Wei, ZH (corresponding author), Yellow River Conservancy Tech Inst, Sch Informat Engn, Kaifeng, Peoples R China.
EM bitkf@bit.edu.cn; Songhong@bit.edu.cn
RI Han, Guanghui/AAE-9435-2022; Han, Guanghui/ABH-8627-2022; Shi,
   Feng/G-3247-2012
OI Han, Guanghui/0000-0001-9043-722X; 
FU National Natural Science Foundation of China [61771056]; National Key
   R&D Program of China [2017YFC0110700]
FX This work was supported by National Natural Science Foundation of China
   (61771056), National Key R&D Program of China (2017YFC0110700).
CR Ahn E, 2017, IEEE J BIOMED HEALTH, V21, P1685, DOI 10.1109/JBHI.2017.2653179
   Ahn E, 2015, IEEE ENG MED BIO, P3009, DOI 10.1109/EMBC.2015.7319025
   Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   [Anonymous], 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298642
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Berseth M., 2017, Isic 2017-skin lesion analysis towards melanoma detection
   Bi L., 2017, Automatic Skin Lesion Analysis using Largescale Dermoscopy Images and Deep Residual Networks
   Bi L, 2016, I S BIOMED IMAGING, P1059, DOI 10.1109/ISBI.2016.7493448
   Bissoto A, 2018, ARXIV190203253
   Celebi ME, 2008, SKIN RES TECHNOL, V14, P347, DOI 10.1111/j.1600-0846.2008.00301.x
   CHEN LC, 2017, ARXIV PREPRINT ARXIV, V1706, P5587, DOI DOI 10.48550/ARXIV.1706.05587
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Dakhia A, 2019, NEUROCOMPUTING, V333, P211, DOI 10.1016/j.neucom.2018.12.045
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Lin BS, 2017, 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P117
   Ma Z, 2016, IEEE J BIOMED HEALTH, V20, P615, DOI 10.1109/JBHI.2015.2390032
   Mendonca Teresa, 2013, 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), P5437, DOI 10.1109/EMBC.2013.6610779
   Mete Mutlu, 2010, BMC Bioinformatics, V11 Suppl 6, pS23, DOI 10.1186/1471-2105-11-S6-S23
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Oliveira RB, 2018, NEURAL COMPUT APPL, V29, P613, DOI 10.1007/s00521-016-2482-6
   Rahman M, 2016, IEEE APP IMG PAT
   Rogers HW, 2015, JAMA DERMATOL, V151, P1081, DOI 10.1001/jamadermatol.2015.1187
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salimans T, 2016, ADV NEUR IN, V29
   Sarker Md.MK, 2018, MICCAI 2018
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Tang JQ, 2017, INT J CANCER, V141, P646, DOI 10.1002/ijc.30708
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Xue Y, 2018, NEUROINFORMATICS, V16, P383, DOI 10.1007/s12021-018-9377-x
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yuan YD, 2019, IEEE J BIOMED HEALTH, V23, P519, DOI 10.1109/JBHI.2017.2787487
   Yuan YD, 2017, IEEE T MED IMAGING, V36, P1876, DOI 10.1109/TMI.2017.2695227
   Yüksel ME, 2009, IEEE T FUZZY SYST, V17, P976, DOI 10.1109/TFUZZ.2009.2018300
   Zhang JB, 2020, IEEE T KNOWL DATA EN, V32, P468, DOI [10.1109/TMI.2019.2893944, 10.1109/TKDE.2019.2891537]
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 44
TC 10
Z9 11
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27115
EP 27136
DI 10.1007/s11042-020-09334-2
EA JUL 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000551375500002
DA 2024-07-18
ER

PT J
AU Putzu, L
   Piras, L
   Giacinto, G
AF Putzu, Lorenzo
   Piras, Luca
   Giacinto, Giorgio
TI Convolutional neural networks for relevance feedback in content based
   image retrieval A Content based image retrieval system that exploits
   convolutional neural networks both for feature extraction and for
   relevance feedback
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval; Convolutional neural network; Feature
   extraction; Similarity; Relevance feedback
ID VISUAL INFORMATION-RETRIEVAL; MODEL
AB Given the great success of Convolutional Neural Network (CNN) for image representation and classification tasks, we argue that Content-Based Image Retrieval (CBIR) systems could also leverage on CNN capabilities, mainly when Relevance Feedback (RF) mechanisms are employed. On the one hand, to improve the performances of CBIRs, that are strictly related to the effectiveness of the descriptors used to represent an image, as they aim at providing the user with images similar to an initial query image. On the other hand, to reduce the semantic gap between the similarity perceived by the user and the similarity computed by the machine, by exploiting an RF mechanism where the user labels the returned images as being relevant or not concerning her interests. Consequently, in this work, we propose a CBIR system based on transfer learning from a CNN trained on a vast image database, thus exploiting the generic image representation that it has already learned. Then, the pre-trained CNN is also fine-tuned exploiting the RF supplied by the user to reduce the semantic gap. In particular, after the user's feedback, we propose to tune and then re-train the CNN according to the labelled set of relevant and non-relevant images. Then, we suggest different strategies to exploit the updated CNN for returning a novel set of images that are expected to be relevant to the user's needs. Experimental results on different data sets show the effectiveness of the proposed mechanisms in improving the representation power of the CNN with respect to the user concept of image similarity. Moreover, the pros and cons of the different approaches can be clearly pointed out, thus providing clear guidelines for the implementation in production environments.
C1 [Putzu, Lorenzo; Piras, Luca; Giacinto, Giorgio] Univ Cagliari, Dept Elect & Elect Engn, Piazza dArmi, I-09123 Cagliari, Italy.
   [Piras, Luca; Giacinto, Giorgio] Pluribus One, Via Bellini 9, I-09128 Cagliari, Italy.
C3 University of Cagliari
RP Putzu, L (corresponding author), Univ Cagliari, Dept Elect & Elect Engn, Piazza dArmi, I-09123 Cagliari, Italy.
EM lorenzo.putzu@unica.it; luca.piras@unica.it; giacinto@unica.it
RI PUTZU, LORENZO/J-5200-2019
OI PUTZU, LORENZO/0000-0001-5361-8793
FU Universita degli Studi di Cagliari within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi di Cagliari
   within the CRUI-CARE Agreement.
CR [Anonymous], 2014, P 2 INT C LEARN REPR
   [Anonymous], P 20 ACM INT C MULT
   [Anonymous], 2008, P 1 ACM INT C MULTIM
   Bagheri Mohammad Ali, 2012, 2012 16th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP), P508, DOI 10.1109/AISP.2012.6313800
   Baldominos A, 2018, NEUROCOMPUTING, V283, P38, DOI 10.1016/j.neucom.2017.12.049
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bhowmik N, 2014, IEEE IMAGE PROC, P5766, DOI 10.1109/ICIP.2014.7026166
   Bulò SR, 2011, PATTERN RECOGN, V44, P2109, DOI 10.1016/j.patcog.2011.03.016
   Cruz MHM, 2018, OPTICS PHOTONICS INF, V10751, P154
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2014, PR MACH LEARN RES, V32
   Dang-Nguyen DT, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3103613
   Erkut U, 2019, HSV COLOR HISTOGRAM
   Giacinto G., 2007, CIVR, P456, DOI [10.1145/1282280.1282347, DOI 10.1145/1282280.1282347]
   Pedronette DCG, 2014, INFORM SCIENCES, V265, P91, DOI 10.1016/j.ins.2013.12.030
   Jiang ML, 2015, IEEE T BIO-MED ENG, V62, P783, DOI 10.1109/TBME.2014.2365494
   Khaldi B, 2020, MULTIMED TOOL APPL
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Z, 2013, IMAGE VISION COMPUT, V31, P748, DOI 10.1016/j.imavis.2013.07.001
   Liang S, 2008, PATTERN RECOGN LETT, V29, P1733, DOI 10.1016/j.patrec.2008.05.004
   Lin WC, 2019, IEEE ACCESS, V7, P147553, DOI 10.1109/ACCESS.2019.2942142
   Lin WC, 2015, NEUROCOMPUTING, V166, P26, DOI 10.1016/j.neucom.2015.04.037
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MacArthur SD, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P68, DOI 10.1109/IVL.2000.853842
   Marques O, 2016, IT PROF, V18, P7, DOI 10.1109/MITP.2016.70
   Mitro J, 2016, ARXIV E PRINTS
   Mohan Kumar P, 2018, ADV INTELL SYST COMP, V652, P23
   Muller H., 2010, ImageCLEF: Experimental Evaluation in Visual Information Retrieval, V1st
   Naz F, 2020, MULTIMED TOOLS APPL, V79, P22107, DOI 10.1007/s11042-020-08897-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pinjarkar L, 2020, J INTELL SYST, V29, P894, DOI 10.1515/jisys-2018-0083
   Pinjarkar L, 2018, SMART INNOV SYST TEC, V77, P53, DOI 10.1007/978-981-10-5544-7_6
   Piras L, 2009, 2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES, P238, DOI 10.1109/WIAMIS.2009.5031477
   Putzu L., 2018, Machine Learning and Data Mining in Pattern Recognition, P117, DOI [10.1007/978-3-319-96133-0_9, DOI 10.1007/978-3-319-96133-0_9]
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   Rosdi BA, 2011, SENSORS-BASEL, V11, P11357, DOI 10.3390/s111211357
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Samantaray AK, 2020, IET IMAGE PROCESS, V14, P679, DOI 10.1049/iet-ipr.2019.1024
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singha M, 2012, IET IMAGE PROCESS, V6, P1221, DOI 10.1049/iet-ipr.2011.0453
   Sivic J, 2008, P IEEE, V96, P548, DOI 10.1109/JPROC.2008.916343
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Torres RD, 2009, PATTERN RECOGN, V42, P283, DOI 10.1016/j.patcog.2008.04.010
   Tzelepi M, 2018, SIGNAL PROCESS-IMAGE, V63, P30, DOI 10.1016/j.image.2018.01.007
   Tzelepi M, 2018, NEUROCOMPUTING, V275, P2467, DOI 10.1016/j.neucom.2017.11.022
   Tzelepi M, 2016, 9TH HELLENIC CONFERENCE ON ARTIFICIAL INTELLIGENCE (SETN 2016), DOI 10.1145/2903220.2903240
   Xu B, 2015, IEEE T KNOWL DATA EN, V27, P102, DOI 10.1109/TKDE.2013.70
   Yu J, 2013, NEUROCOMPUTING, V120, P355, DOI 10.1016/j.neucom.2012.08.061
   Zhalehpour S, 2019, J CULT HERIT, V40, P99, DOI 10.1016/j.culher.2019.05.018
NR 53
TC 25
Z9 26
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 26995
EP 27021
DI 10.1007/s11042-020-09292-9
EA JUL 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000550587200001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Sun, W
   Zhang, GC
   Zhang, XR
   Zhang, X
   Ge, NN
AF Sun, Wei
   Zhang, Guoce
   Zhang, Xiaorui
   Zhang, Xu
   Ge, Nannan
TI Fine-grained vehicle type classification using lightweight convolutional
   neural network with feature optimization and joint learning strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fine-grained vehicle type classification; Lightweight; Feature
   optimization; Contrastive-center loss
AB Vehicle type classification (VTC) plays an important role in today's intelligent transportation. Previous VTC systems usually run on a monitoring center's host machine due to the models' complexity, which consume lots of computing resources and have poor real-time performance. If these systems are deployed to embedded terminals by making the model lightweight while ensuring accuracy, then the problem can be addressed. To this end, we propose a fine-grained VTC method using lightweight convolutional neural network with feature optimization and joint learning strategy. Firstly, a lightweight convolutional network with feature optimization (LWCNN-FO) is designed. We use depthwise separable convolution to reduce network parameters. Besides, the SENet module is added to obtain the important degree of each feature channel automatically through the sample-based self-learning, which can improve recognition accuracy with less network parameters growth. In addition, considering both between-class similarity and intra-class variance, this paper adopts the joint learning strategy combining softmax loss and contrastive-center loss to class vehicle types, thereby improving model's fine-grained classification ability. We also build a dataset, called Car-159, consisting of 7998 pictures for 159 vehicle types, to evaluate our method. Compared with the state-of-the-art methods, experimental results show that our method can effectively decrease model's complexity while maintaining accuracy.
C1 [Sun, Wei; Zhang, Guoce; Zhang, Xu; Ge, Nannan] Nanjing Univ Informat Sci & Technol, Sch Automat, Nanjing 210044, Peoples R China.
   [Sun, Wei; Zhang, Xiaorui] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
   [Zhang, Xiaorui] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Nanjing University of
   Information Science & Technology
RP Sun, W (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Automat, Nanjing 210044, Peoples R China.; Sun, W (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
EM sunw0125@163.com
OI Zhang, Guoce/0000-0001-6455-4844
FU National Natural Science Foundation of China [61304205, 61502240];
   Natural Science Foundation of Jiangsu Province [BK20191401]; Innovation
   and Entrepreneurship Training Project of College Students [202010300290,
   202010300211, 202010300116E]
FX This work is supported in part by the National Natural Science
   Foundation of China (No. 61304205 and 61502240), the Natural Science
   Foundation of Jiangsu Province (BK20191401), and the Innovation and
   Entrepreneurship Training Project of College Students (202010300290,
   202010300211 and 202010300116E).
CR [Anonymous], 2002, ADV NEURAL INF PROCE
   [Anonymous], 2018, P 2018 IEEE 5 INT C
   Behley J, 2013, IEEE INT C INT ROBOT, P4195, DOI 10.1109/IROS.2013.6696957
   Bo Zhang, 2012, Proceedings of the 2012 International Symposium on Instrumentation & Measurement, Sensor Network and Automation (IMSNA), P322, DOI 10.1109/MSNA.2012.6324578
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dong Z, 2015, IEEE T INTELL TRANSP, V16, P2247, DOI 10.1109/TITS.2015.2402438
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hsieh JW, 2014, IEEE T INTELL TRANSP, V15, P6, DOI 10.1109/TITS.2013.2294646
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Kingma D. P., 2014, arXiv
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Li M, 2015, 2015 INT C INT SYST
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   QI C, 2017, IEEE T IMAGE PROCESS, V2017, P2851
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xie SN, 2015, PROC CVPR IEEE, P2645, DOI 10.1109/CVPR.2015.7298880
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
NR 20
TC 81
Z9 81
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30803
EP 30816
DI 10.1007/s11042-020-09171-3
EA JUL 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000549799000007
DA 2024-07-18
ER

PT J
AU Maji, G
   Mandal, S
AF Maji, Giridhar
   Mandal, Sharmistha
TI A forward email based high capacity text steganography technique using a
   randomized and indexed word dictionary
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text steganography; Email steganography; Indexed word dictionary; Data
   hiding in email cover; High capacity steganography; Secure and robust
   text steganography
ID COLOR
AB Text steganography is inherently difficult due to minimal redundant information space to hide secret payload. The same fact limits the hiding capacity and security too. In this study, a novel technique has been proposed using a randomized indexed word dictionary, and a list of email addresses to increase the hiding capacity and security. A forward email platform has been used as the cover, and email addresses in the carbon copy (CC) field contain secret data that are encoded using a randomized index-based word dictionary. The email username list and indexed word dictionary are both pre-shared between the communicating parties. But during every new communication, a random bitstream (temporary stego-key) is generated from the system time and communicated separately using public-key cryptography. This temporary stego-key is used to randomize the index values of the words in the dictionary. Most of the existing state-of-the-art techniques provide a hiding capacity of 6-10%. The proposed scheme achieves a capacity of 12.17% using some common secret text and email body text (cover text) as used in all other studies. The proposed technique provides higher hiding capacity and security by randomizing the word indexes every time using temporary stego-key. It is also free from statistical attacks, OCR based attacks, and does not depend on the use of any particular text processor.
C1 [Maji, Giridhar] Asansol Polytech, Dept Elect Engn, Asansol, W Bengal, India.
   [Mandal, Sharmistha] Kanyapur Polytech, Dept Comp Sci & Technol, Asansol, W Bengal, India.
RP Maji, G (corresponding author), Asansol Polytech, Dept Elect Engn, Asansol, W Bengal, India.
EM giridhar.maji@gmail.com; sharmistha.cse@gmail.com
RI Maji, Giridhar/R-4457-2019
OI Maji, Giridhar/0000-0003-4751-3471; MANDAL,
   SHARMISTHA/0000-0002-8653-565X
CR Ahmad Tohari, 2014, International Journal of e-Education, e-Business, e-Management and e-Learning, V4, P129, DOI 10.7763/IJEEEE.2014.V4.316
   Al-Nofaie S, 2019, J KING SAUD U INF SC
   [Anonymous], 1883, Journal des sciences militaires
   [Anonymous], 2004, LINGUISTIC STEGANOGR
   [Anonymous], 2018, J COMPUT SCI COMPUT, DOI DOI 10.20967/JCSCM.2018.03.002
   Banik BG, 2020, IETE J RES, V66, P384, DOI 10.1080/03772063.2018.1491807
   Biswas R, 2020, MULTIMED TOOLS APPL, V79, P7101, DOI 10.1007/s11042-019-08497-x
   Changder S, 2009, J COMPUT METHODS SCI, V9, pS111, DOI 10.3233/JCM-2009-0240
   Chaudhary S, 2018, INFORM COMMUNICATION, P393
   Desoky A, 2009, INT J INF SECUR, V8, P247, DOI 10.1007/s10207-009-0079-0
   El Rahman SA, 2019, INT J SOFTW INNOV, V7, P29, DOI 10.4018/IJSI.2019070102
   El-Khamy SE, 2017, MULTIMED TOOLS APPL, V76, P24091, DOI 10.1007/s11042-016-4113-8
   Fatema Mariya, 2018, International Conference on Wireless, Intelligent, and Distributed Environment for Communication. WIDECOM 2018. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 18), P1, DOI [10.1080/1206212X.2018.1517713, 10.1007/978-3-319-75626-4_1]
   Garg M., 2011, International Journal of Advanced Science and Technology, V35, P129
   Hamzah AA, 2019, J KING SAUD U INF SC
   Kahn D., 1996, Information Hiding. First International Workshop Proceedings, P1
   Khairullah M, 2009, INT C COMP ELEC ENG, P482, DOI 10.1109/ICCEE.2009.127
   Khan A, 2019, MULTIMED TOOLS APPL, V78, P25999, DOI 10.1007/s11042-019-7664-7
   Khosravi B, 2019, J INF SECUR APPL, V45, P61, DOI 10.1016/j.jisa.2019.01.003
   Kumar R, 2014, 2014 5TH INTERNATIONAL CONFERENCE CONFLUENCE THE NEXT GENERATION INFORMATION TECHNOLOGY SUMMIT (CONFLUENCE), P336, DOI 10.1109/CONFLUENCE.2014.6949231
   Liu J, 2019, J MED IMAG HEALTH IN, V9, P188, DOI 10.1166/jmihi.2019.2559
   Liu YL, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2094
   MAHER K, 1995, TEXTO
   Maji G., 2019, INT J INNOV TECHNOL, V8, P2828
   Maji G, 2019, 17 INT C IND INF IND
   Maji G, 2018, PROCEEDINGS OF 2018 2ND INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN SIGNAL PROCESSING, TELECOMMUNICATIONS & COMPUTING (SIGTELCOM 2018), P61, DOI 10.1109/SIGTELCOM.2018.8325806
   Miao H., 2013, SCI CHINA INFORM SCI, P1, DOI DOI 10.1007/S11432-012-4681-9
   MURPHY B, 2007, PROC SPIE, V6505
   Murugan GVK, 2020, MULTIMED TOOLS APPL, V79, P9101, DOI 10.1007/s11042-019-7507-6
   Nagarhalli TP, 2014, INT J COMPUT APPL, V975, P8887
   Narayana VL, 2018, Ingenierie des Systemes d'Information, V23, P115
   Por LY, 2012, J SYST SOFTWARE, V85, P1075, DOI 10.1016/j.jss.2011.12.023
   Rabah K., 2004, Information Technology Journal, V3, P245
   Roy KK, 2018, IEEE CONF TECHNOL ED, P174, DOI 10.1109/T4E.2018.00045
   Roy M., 2011, INT C COMMUN COMPUT, P511
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Satir E, 2014, MULTIMED TOOLS APPL, V70, P2085, DOI 10.1007/s11042-012-1223-9
   Satir E, 2012, J SYST SOFTWARE, V85, P2385, DOI 10.1016/j.jss.2012.05.027
   Shirali-Shahreza MH, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1524, DOI 10.1109/IIH-MSP.2008.6
   Shirali-Shahreza M, 2008, 10TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, P1912, DOI 10.1109/ICACT.2008.4494159
   Tan DW, 2019, PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2019), P1409, DOI [10.1109/ITNEC.2019.8729476, 10.1109/itnec.2019.8729476]
   Trithemius J., 1721, Steganographia
   Zhi-Hui Wang, 2009, 2009 Asia-Pacific Conference on Computational Intelligence and Industrial Applications (PACIIA 2009), P457, DOI 10.1109/PACIIA.2009.5406559
   Zhou X, 2016, PALEOCEANOGRAPHY, V31, P1532, DOI 10.1002/2016PA003020
NR 44
TC 4
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26549
EP 26569
DI 10.1007/s11042-020-09329-z
EA JUL 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549313700001
DA 2024-07-18
ER

PT J
AU Zeng, H
   Peng, AJ
   Lin, XD
AF Zeng, Hui
   Peng, Anjie
   Lin, Xiaodan
TI Exposing image splicing with inconsistent sensor noise levels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image splicing; Additional white Gaussian noise (AWGN); Sensor noise
   level; ISO settings; Principal component analysis (PCA); K-means
ID FORGERY
AB Splicing is a commonly used image tampering operation, where a part of one image is pasted into another image. The forged image can have completely different semantic from the original one and may mislead people in some serious occasions. To rebuild the credibility of the images, extensive forensic methods aiming to locate the spliced areas have been proposed in recent years. Among these methods, the noise based ones, which utilize the fact that images from different sources tend to have various noise levels, have drawn much attention due to their convenience to implement. However, most of the existing noise based methods are under the assumption that a synthetic additional white Gaussian noise (AWGN) is involved during the splicing. This maybe not the case in practice. In this study, we utilize the difference of the intrinsic sensor noise of the source images to expose the potential image splicing. In practice, the sensor noise level difference is common between images captured with different ISO settings. Through analyzing the characteristics of the sensor noise, a weighted noise level is proposed for reducing influences from image content thus can better localizing the splicing region. Specifically, the noise level of a questioned image is first estimated locally with principal component analysis (PCA)-based algorithm. Then, the estimated noise levels are weighted before clustering with k-means. The experimental results demonstrate the superiority of the proposed method over several state-of-the-art methods, not only for splicing localization purpose, but also for splicing detection purpose.
C1 [Zeng, Hui; Peng, Anjie] Southwest Univ Sci & Technol, Sch Comp Sci & Technol, Mianyang, Sichuan, Peoples R China.
   [Lin, Xiaodan] Huaqiao Univ, Sch Informat Sci & Engn, Xiamen, Peoples R China.
C3 Southwest University of Science & Technology - China; Huaqiao University
RP Peng, AJ (corresponding author), Southwest Univ Sci & Technol, Sch Comp Sci & Technol, Mianyang, Sichuan, Peoples R China.
EM zengh5@mail2.sysu.edu.cn; penganjie200012@163.com; xd_lin@hqu.edu.cn
RI Zeng, Hui/ABE-6533-2021
OI Zeng, Hui/0000-0002-3776-4309
FU NSFC [61702429]; China Scholarship Council [201908515095]; Research Fund
   for the Doctoral Program of Southwest University of Science and
   Technology [18zx7163]
FX This work was supported by NSFC (Grant no. 61702429), the China
   Scholarship Council (Grant no. 201908515095), and the Research Fund for
   the Doctoral Program of Southwest University of Science and Technology
   (Grant no. 18zx7163). This work was partially done when Hui Zeng was a
   visiting scholar at Binghamton University, the State University of New
   York, New York, USA.
CR Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   [Anonymous], DEPENDENCE PARAMETER
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2005, Image Sensors and Signal Processing for Digital Still Cameras
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], 2011, P 13 INF HID C PRAG
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Cozzolino D, 2014, IEEE IMAGE PROC, P5302, DOI 10.1109/ICIP.2014.7026073
   HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126
   Li S, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942097
   Lukás J, 2006, PROC SPIE, V6072, DOI 10.1117/12.640109
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Pan XY, 2011, MM&SEC 11: PROCEEDINGS OF THE 2011 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P15
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   Wang S, 2019, ARXIV190605856V1CSCV
   Yao H, 2018, MULTIMED TOOLS APPL, V77, P18139, DOI 10.1007/s11042-017-5206-8
   Zampoglou M, 2017, MULTIMED TOOLS APPL, V76, P4801, DOI 10.1007/s11042-016-3795-2
   Zeng H, 2017, MULTIMED TOOLS APPL, V76, P4783, DOI 10.1007/s11042-016-3712-8
   Zhu N, 2018, SIGNAL PROCESS-IMAGE, V68, P181, DOI 10.1016/j.image.2018.07.012
   Zhu Y, 2016, MULTIMED TOOLS APPL, V75, P3221, DOI 10.1007/s11042-014-2431-2
   Zoran D, 2009, IEEE I CONF COMP VIS, P2209, DOI 10.1109/ICCV.2009.5459476
NR 24
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26139
EP 26154
DI 10.1007/s11042-020-09280-z
EA JUL 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000547247600005
DA 2024-07-18
ER

PT J
AU Zhu, ZL
   Song, YJ
   Zhang, W
   Yu, H
   Zhao, YL
AF Zhu, Zhiliang
   Song, Yanjie
   Zhang, Wei
   Yu, Hai
   Zhao, Yuli
TI A novel compressive sensing-based framework for image
   compression-encryption with S-box
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing; Plaintext sensitivity; S-box;
   Compression-encryption; Chaos
ID ALGORITHM; PERMUTATION; CONSTRUCTION; DIFFUSION; SECURITY; CHAOS; MAP
AB In this paper, we find that compressive sensing (CS) with the chaotic measurement matrix has a strong sensitivity to plaintext. Because of the quantification executed after CS, however, the plaintext sensitivity produced by CS may be weakened greatly. Thus, we propose a novel CS-based compression-encryption framework (CS-CEF) using the intrinsic property of CS to provide a strong plaintext sensitivity for the compression-encryption scheme, which takes a low additional computation cost. Meanwhile, a simple and efficient Substitution box (S-box) construction algorithm (SbCA) based on chaos is designed. Compared with the existing S-box construction methods, the simulation results prove that the proposed S-box has stronger cryptographic characteristics. Based on the above works, we develop an efficient and secure image compression-encryption scheme using S-box (CSb-CES) under the proposed CS-CEF. The simulations and security analysis illustrate that the proposed CSb-CES has the higher efficiency and security compared with the several state-of-the-art CS-based compression-encryption schemes.
C1 [Zhu, Zhiliang; Song, Yanjie; Zhang, Wei; Yu, Hai; Zhao, Yuli] Northeastern Univ, Software Coll, Shenyang 110819, Peoples R China.
C3 Northeastern University - China
RP Song, YJ (corresponding author), Northeastern Univ, Software Coll, Shenyang 110819, Peoples R China.
EM syjneu@163.com
RI YU, Hai/E-6831-2018
OI YU, Hai/0000-0002-8024-1781; Zhao, Yuli/0000-0001-7298-7463
FU National Natural Science Foundation of China [61374178, 61402092,
   61603082]; Online Education Research Fund of the MOE Research Center for
   Online Education, China [2016ZD306]; Ph.D. Start-Up Foundation of
   Liaoning Province, China [201501141]; Fundamental Research Funds for the
   Central Universities [N171704004]
FX This work was supported by the National Natural Science Foundation of
   China [grant numbers 61374178, 61402092, 61603082]; the Online Education
   Research Fund of the MOE Research Center for Online Education, China
   [qtone education, grant number 2016ZD306]; the Ph.D. Start-Up Foundation
   of Liaoning Province, China [grant number 201501141]; and the
   Fundamental Research Funds for the Central Universities [grant number
   N171704004].
CR Adams CM, 1990, P CRYPTO 89, P612
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Çavusoglu Ü, 2017, NONLINEAR DYNAM, V87, P1081, DOI 10.1007/s11071-016-3099-0
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Chen G, 2007, CHAOS SOLITON FRACT, V31, P571, DOI 10.1016/j.chaos.2005.10.022
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Endra, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND CYBERNETICS (CYBERNETICSCOM), P122, DOI 10.1109/CyberneticsCom.2013.6865794
   Fang H, 2015, 2015 IEEE 6TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL ADVANCES IN MULTI-SENSOR ADAPTIVE PROCESSING (CAMSAP), P393, DOI 10.1109/CAMSAP.2015.7383819
   Fang H, 2014, IEEE T SIGNAL PROCES, V62, P196, DOI 10.1109/TSP.2013.2284762
   Frunzete M, 2011, SPA 2011: SIGNAL PROCESSING ALGORITHMS, ARCHITECTURES, ARRANGEMENTS, AND APPLICATIONS CONFERENCE PROCEEDINGS, P11
   Hu HT, 2020, INFORM SCIENCES, V519, P161, DOI 10.1016/j.ins.2020.01.019
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang H, 2018, SIGNAL PROCESS, V150, P183, DOI 10.1016/j.sigpro.2018.04.014
   Huang XL, 2018, MULTIMED TOOLS APPL, V77, P2611, DOI 10.1007/s11042-017-4455-x
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Hussain I, 2012, COMPUT MATH APPL, V64, P2450, DOI 10.1016/j.camwa.2012.05.017
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Khan M, 2015, SIGNAL IMAGE VIDEO P, V9, P1335, DOI 10.1007/s11760-013-0577-4
   Khan M, 2013, NONLINEAR DYNAM, V73, P1795, DOI 10.1007/s11071-013-0904-x
   Li YH, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2903717
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liu HJ, 2018, MULTIMED TOOLS APPL, V77, P1391, DOI 10.1007/s11042-016-4288-z
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Özkaynak F, 2010, PHYS LETT A, V374, P3733, DOI 10.1016/j.physleta.2010.07.019
   PIEPRZYK J, 1988, IEE PROC-E, V135, P325, DOI 10.1049/ip-e.1988.0044
   Ponuma R., 2018, MULTIMED TOOLS APPL, P1
   Rachlin Y, 2008, ANN ALLERTON CONF, P813, DOI 10.1109/ALLERTON.2008.4797641
   Shanthakumari R, 2020, MULTIMED TOOLS APPL, V79, P3975, DOI 10.1007/s11042-019-7584-6
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Waqas UA, 2020, MULTIMED TOOLS APPL, V79, P6891, DOI 10.1007/s11042-019-08570-5
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Wu Y, 2016, INFORM SCIENCES, V327, P91, DOI 10.1016/j.ins.2015.08.013
   Ye GD, 2017, NEUROCOMPUTING, V251, P45, DOI 10.1016/j.neucom.2017.04.016
   Ye GD, 2016, NONLINEAR DYNAM, V83, P2067, DOI 10.1007/s11071-015-2465-7
   Ye GD, 2014, NONLINEAR DYNAM, V75, P417, DOI 10.1007/s11071-013-1074-6
   Yu L, 2010, IEEE SIGNAL PROC LET, V17, P731, DOI 10.1109/LSP.2010.2052243
   Zhang YS, 2016, IEEE ACCESS, V4, P2507, DOI 10.1109/ACCESS.2016.2569421
   Zhang YS, 2016, NEUROCOMPUTING, V205, P472, DOI 10.1016/j.neucom.2016.04.053
   Zhang YS, 2015, NONLINEAR DYNAM, V82, P1831, DOI 10.1007/s11071-015-2280-1
   Zhang YS, 2014, INFORM SCIENCES, V289, P254, DOI 10.1016/j.ins.2014.08.005
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 55
TC 12
Z9 12
U1 3
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25497
EP 25533
DI 10.1007/s11042-020-09193-x
EA JUL 2020
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000545195600001
DA 2024-07-18
ER

PT J
AU Agarwal, A
   Deshmukh, M
   Singh, M
AF Agarwal, Ayushi
   Deshmukh, Maroti
   Singh, Maheep
TI Object detection framework to generate secret shares
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; YOLO; Secret sharing; Modular arithmetic; Quantitative
   measures
ID SHARING SCHEME; IMAGES
AB Nowadays, the sharing of images via the Internet has been widely used. The security concern during transmission of images has been a very important issue, as images contain a lot of crucial information. To prevent access to this information by any unauthorized user various encryption schemes have been developed. An image may consist of a large number of pixels and the encryption of the whole image takes more time. To overcome this problem, we proposed an algorithm that focuses on encryption of only those objects which contain the major information of an image instead of encrypting the complete image, this saves the time required in encryption as only the objects contained in the image are encrypted. The proposed algorithm exploits the use of object detection and image secret sharing. Object detection is done using the "You Only Look Once (YOLO)" algorithm. Further, the objects detected are encrypted using (n,n) modular arithmetic secret sharing scheme. The quantitative measures like correlation, SSIM, RMSE, PSNR has been used to evaluate the performance of the proposed algorithm on COCO dataset. The experimental results show that the proposed algorithm is lossless i.e. original and reconstructed images are exactly the same. The proposed algorithm is efficient and can be used in a broad range of applications.
C1 [Agarwal, Ayushi; Deshmukh, Maroti; Singh, Maheep] Natl Inst Technol, Srinagar, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand
RP Deshmukh, M (corresponding author), Natl Inst Technol, Srinagar, Uttarakhand, India.
EM ayushi16.cse@nituk.ac.in; marotideshmukh@nituk.ac.in;
   maheep.singh@nituk.ac.in
RI Deshmukh, Dr. Maroti/AAE-2889-2022
OI Deshmukh, Maroti/0000-0002-1125-5987; Singh, Maheep/0000-0002-9842-0227
CR [Anonymous], COMPUT VIS PATTERN R
   Arraziqi D., 2019, TELKOMNIKA, V17, P1417
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Brassington G., 2017, EGU GEN ASS C ABSTR
   Brodal GS, 2006, LECT NOTES COMPUT SC, V4168, P708
   Carlson JA, 2017, U.S Patent, Patent No. [9,819,656, 9819656]
   Cecotti H, 2016, IR MACH VIS IM PROC
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Cox IJ., 2007, DIGITAL WATERMARKING
   Dai Jifeng, 2016, Advances in Neural Information Processing Systems, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Deshmukh M, 2016, 2016 IEEE 30 INT C A
   Deshmukh M, 2018, KNOWLEDGE INFORM SYS, V60
   Deshmukh M, 2018, MULTIMED TOOLS APPL, V77, P89, DOI 10.1007/s11042-016-4229-x
   Deshmukh M, 2017, J VIS COMMUN IMAGE R, V49, P291, DOI 10.1016/j.jvcir.2017.09.013
   Deshmukh M, 2017, ADV INTELL SYST, V459, P149, DOI 10.1007/978-981-10-2104-6_14
   Donahue J, 2014, PR MACH LEARN RES, V32
   Dong J, 2014, LECT NOTES COMPUT SC, V8693, P299, DOI 10.1007/978-3-319-10602-1_20
   Duseja T, 2019, MULTIMED TOOLS APPL, V78, P16727, DOI 10.1007/s11042-018-7023-0
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Feng JB, 2005, J SYST SOFTWARE, V76, P327, DOI 10.1016/j.jss.2004.07.250
   Feng Jiang, 2017, International Journal of Network Security, V19, P118, DOI 10.6633/IJNS.201701.19(1).13
   Forouzan B.A., 2007, Cryptography and Network Security
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Guarino S, 2013, 2013 P IEEE INFOCOM
   Guo T, 2014, SIGNAL PROCESS, V94, P90, DOI 10.1016/j.sigpro.2013.06.003
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kanalikova A, 2019, ANN FACULTY ENG HUNE, V17.1, P181
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Pashmakov B, 2004, U.S Patent, Patent No. [6,714,954, 6714954]
   Rajput M, 2018, IEEE CONSUM ELECTR M, V7, P40, DOI 10.1109/MCE.2017.2716412
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shyu SH, 2006, PATTERN RECOGN, V39, P866, DOI 10.1016/j.patcog.2005.06.010
   SIMMONS GJ, 1979, COMPUT SURV, V11, P305, DOI 10.1145/356789.356793
   Stallings W., 2006, Cryptography and Network Security, V4th
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tanabe Y, 2017, RADIOL PHYS TECHNOL, V10, P91, DOI 10.1007/s12194-016-0372-3
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Yang CN, 2016, J SYST SOFTWARE, V116, P22, DOI 10.1016/j.jss.2015.01.031
NR 42
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24685
EP 24706
DI 10.1007/s11042-020-09169-x
EA JUN 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543285000002
DA 2024-07-18
ER

PT J
AU Senecal, S
   Nijdam, NA
   Aristidou, A
   Magnenat-Thalmann, N
AF Senecal, Simon
   Nijdam, Niels A.
   Aristidou, Andreas
   Magnenat-Thalmann, Nadia
TI Salsa dance learning evaluation and motion analysis in gamified virtual
   reality environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion analysis; Salsa dance; Virtual reality; Human computer
   interaction
ID RECOGNITION; SYSTEM
AB Learning couple dance such as salsa is challenging as it requires to understand and assimilate all the dance skills (guidance, rhythm, style) correctly. Salsa is traditionally learned by attending a dancing class with a teacher and practice with a partner, the difficulty to access such classes though, and the variability of dance environment can impact the learning process. Understanding how people learn using a virtual reality platform could bring interesting knowledge in motion analysis and can be the first step toward a complementary learning system at home. In this paper, we propose an interactive learning application in the form of a virtual reality game, that aims to help the user to improve its salsa dancing skills. The application was designed upon previous literature and expert discussion and has different components that simulate salsa dance: A virtual partner with interactive control to dance with, visual and haptic feedback, and a game mechanic with dance tasks. This application is tested on a two-class panel of 20 regular and 20 non-dancers, and their learning is evaluated and analyzed through the extraction of Musical Motion Features and the Laban Motion Analysis system. Both motion analysis frameworks were compared prior and after training and show a convergence of the profile of non-dancer toward the profile of regular dancers, which validates the learning process. The work presented here has profound implications for future studies of motion analysis, couple dance learning, and human-human interaction.
C1 [Senecal, Simon; Nijdam, Niels A.; Magnenat-Thalmann, Nadia] Univ Geneva, Geneva, Switzerland.
   [Aristidou, Andreas] Univ Cyprus, Nicosia, Cyprus.
   [Aristidou, Andreas] RISE Res Ctr, Nicosia, Cyprus.
C3 University of Geneva; University of Cyprus
RP Senecal, S (corresponding author), Univ Geneva, Geneva, Switzerland.
EM senecal@miralab.ch; nijdam@unige.ch; a.aristidou@ieee.org;
   thalmann@miralab.ch
RI Thalmann, Nadia/AAK-5195-2021
OI Thalmann, Nadia/0000-0002-1459-5960; Aristidou,
   Andreas/0000-0001-7754-0791; Nijdam, Niels/0000-0002-0172-6319; Senecal,
   Simon/0000-0002-7505-0497
FU European project MINGEI; European Union's Horizon 2020 Research and
   Innovation Programme [739578]; Government of the Republic of Cyprus
   through the Directorate General for European Programmes, Coordination
   and Development
FX This work is co-financed by the European project MINGEI. It has also
   been partly supported by the project that has received funding from the
   European Union's Horizon 2020 Research and Innovation Programme under
   Grant Agreement No 739578 (RISE-Call: H2020-WIDESPREAD
   -01-2016-2017-TeamingPhase2) and the Government of the Republic of
   Cyprus through the Directorate General for European Programmes,
   Coordination and Development.
CR Alborno Paolo., 2016, Proceedings of the International Working Conference on Advanced Visual Interfaces, P136, DOI DOI 10.1145/2909132.2909262
   [Anonymous], 2011, P 19 ACM INT C MULTI, DOI DOI 10.1145/2072298.2072412
   [Anonymous], 2018, DANCEVIRTUAL
   Aristidou A, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099566
   Aristidou A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275038
   Aristidou A, 2018, VISUAL COMPUT, V34, P1725, DOI 10.1007/s00371-017-1452-z
   Aristidou A, 2015, COMPUT GRAPH FORUM, V34, P262, DOI 10.1111/cgf.12598
   Aristidou A, 2015, ACM J COMPUT CULT HE, V8, DOI 10.1145/2755566
   Aristidou Andreas, 2013, SIGGRAPH ASIA 2013 T, P21
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bellini Rachele, 2018, Computational Visual Media, V4, P197, DOI 10.1007/s41095-018-0115-y
   Chan JCP, 2011, IEEE T LEARN TECHNOL, V4, P187, DOI 10.1109/TLT.2010.27
   Cuykendall S, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P635, DOI 10.1145/2839462.2856339
   Cuykendall S, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P234, DOI 10.1145/2901790.2901822
   Deng LQ, 2011, COMPUT ANIMAT VIRT W, V22, P229, DOI 10.1002/cav.397
   dos Santos ADP, 2017, PROCEEDINGS OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P183, DOI 10.1145/3079628.3079673
   El Raheb K., 2016, EAI Endorsed Trans. Ambient Syst, V3, pe7
   Forbes N, 2005, IMITATION OF LIFE: HOW BIOLOGY IS INSPIRING COMPUTING, P67
   Fourati N, 2015, INT CONF AFFECT, P267, DOI 10.1109/ACII.2015.7344582
   Granados DFP, 2016, IEEE-RAS INT C HUMAN, P279, DOI 10.1109/HUMANOIDS.2016.7803289
   Hajarian M, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-019-0589-3
   Ho ESL, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487274
   Kim TH, 2003, ACM T GRAPHIC, V22, P392, DOI 10.1145/882262.882283
   Kyan M, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2735951
   Laban Rudolf., 2011, MASTERY MOVEMENT
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Merom D, 2016, PLOS MED, V13, DOI 10.1371/journal.pmed.1002112
   Merom D, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00026
   Merom D, 2013, BMC PUBLIC HEALTH, V13, DOI 10.1186/1471-2458-13-477
   Mousas C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P57, DOI 10.1109/VR.2018.8446498
   Özcimder K, 2016, P AMER CONTR CONF, P6465, DOI 10.1109/ACC.2016.7526687
   Piana S., 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, CHI EA'16, page, P1629, DOI DOI 10.1145/2851581.2892478
   Powers RSU, 2020, BRIEF HIST SOCIAL DA
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Seber G.A. F., 2008, Multivariate Observations
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Senecal S, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (GRAPP), VOL 1, P100, DOI 10.5220/0007399701000109
   Senecal S, 2018, ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION, AND GAMES (MIG 2018), DOI 10.1145/3274247.3274514
   Senecal S, 2016, COMPUT ANIMAT VIRT W, V27, P311, DOI 10.1002/cav.1714
   Shiratori T, 2006, COMPUT GRAPH FORUM, V25, P449, DOI 10.1111/j.1467-8659.2006.00964.x
   Shum HPH, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409067
   Tang TR, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1598, DOI 10.1145/3240508.3240526
   Theodorou L, 2016, MOCO'16: PROCEEDINGS OF THE 3RD INTERNATIONAL SYMPOSIUM ON MOVEMENT AND COMPUTING, DOI 10.1145/2948910.2948928
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wagaj SC, 2019, INT J ELECTRON, V106, P992, DOI 10.1080/00207217.2019.1570564
   Whyatt CP, 2015, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON MOVEMENT AND COMPUTING (MOCO'17), DOI 10.1145/3077981.3078055
   Won J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661271
NR 47
TC 32
Z9 33
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24621
EP 24643
DI 10.1007/s11042-020-09192-y
EA JUN 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000542539200005
DA 2024-07-18
ER

PT J
AU Wu, CX
   Guo, SN
   Wu, Y
   Ai, J
   Xiong, NN
AF Wu, Chunxue
   Guo, Shengnan
   Wu, Yan
   Ai, Jun
   Xiong, Neal N.
TI Networked Fault Detection of Field Equipment from Monitoring System
   Based on Fusing of Motion Sensing and Appearance Information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Intelligent monitoring system; On-line fault
   detection; HOFO; OCSVM
ID BEHAVIOR RECOGNITION; FEATURES; SUPPORT; EVENTS
AB Recent development of Internet of Things (IoT) technologies has triggered a soaring application of intelligent monitoring systems. A sensitive online fault detection for industrial equipment is of utmost significance to improve industrial intelligence based on video sensor network. In this paper, we propose the Appearance and Motion SVM (AMSVM), an online fault detection method fusing multimodal information based on One-Class SVM (OCSVM), to monitor the working conditions of unsupervised equipment in the field. It utilizes multimodal features to detect faults in terms of the appearance and motion patterns of equipment. The motion pattern was generated using the OCSVM-encoded histogram of optical flow orientation (HOFO), and meanwhile we employed Local Binary Pattern Histogram (LBPH) to extract texture features to train OCSVM, depicting appearance patterns. Then, decision level information (i.e., appearance and motion patterns) are combined to produce a more precise characteristic for fault detection. The proposed method herein was validated on several industrial video surveillance data set.
C1 [Wu, Chunxue; Guo, Shengnan; Ai, Jun] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
   [Wu, Yan] Indiana Univ, ONeill Sch Publ & Environm Affairs, Bloomington, IN 47405 USA.
   [Xiong, Neal N.] Northeastern State Univ, Dept Math & Comp Sci, Tahlequah, OK 74464 USA.
C3 University of Shanghai for Science & Technology; Indiana University
   System; Indiana University Bloomington
RP Wu, CX (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
EM wcx@usst.edu.cn; Shining_Guo123@163.com; wuyan8910@126.com;
   aijun@usst.edu.cn; xiongnaixue@gmail.com
RI xiong, naixue/M-4277-2019; Ai, Jun/GQQ-3550-2022
OI xiong, naixue/0000-0002-0394-4635; 
FU National Key Research and Development Program of China [2018YFC0810204];
   Shanghai Science and Technology Innovation Action Plan Project
   [16,111,107,502, 17,511,107,203]; Shanghai key lab of modern optical
   system
FX This research was supported by the National Key Research and Development
   Program of China (No. 2018YFC0810204) and Shanghai Science and
   Technology Innovation Action Plan Project (16,111,107,502,
   17,511,107,203) and Shanghai key lab of modern optical system.
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Alvar M, 2014, MACH VISION APPL, V25, P1351, DOI 10.1007/s00138-014-0615-4
   [Anonymous], NEUROCOMPUTING
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Benezeth Y, 2012, COMP VIS PATT REC 20
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Bradley A., 1997, The use of the area under the roc curve in the evaluation of machine learning algorithms, P1145
   Chen ZY, 2015, IEEE INT CON MULTI
   Cheng KW, 2015, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2015.7298909
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Foggia P, 2013, IEEE SYS MAN CYBERN, P2910, DOI 10.1109/SMC.2013.496
   Gannot I, 2012, SYSTEM AUTOMATIC FAL
   Garcia EA, 1997, CONTROL ENG PRACT, V5, P663, DOI 10.1016/S0967-0661(97)00048-8
   Guo WH, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040739
   Hamid R, 2005, COMP VIS PATT REC 20
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hruz M, 2011, LOCAL BINARY PATTERN, P519
   Hu Y, 2013, IEEE COMPUT SOC CONF, P767, DOI 10.1109/CVPRW.2013.115
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   JOrgensen EK, 2014, FALL DETECTION ELDER
   Kim H, 2016, EXPERT SYST APPL, V45, P131, DOI 10.1016/j.eswa.2015.09.035
   Kosmopoulos D, 2010, IEEE SIGNAL PROC MAG, V27, P34, DOI 10.1109/MSP.2010.937392
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Li NN, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415550113
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Lu C, 2014, PROC SPIE, V9015, DOI 10.1117/12.2047335
   Ma C, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122741
   Martinez-Tomas R, 2015, INT WORK C INT NAT A
   Nallaivarothayan H, 2014, IEEE INT C ADV VID S
   Park D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072110
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Ramos AR, 2018, EXPERT SYST APPL, V113
   Roshtkhari MJ, 2013, PROC CVPR IEEE, P2611, DOI 10.1109/CVPR.2013.337
   Rougier C, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P875, DOI 10.1109/ainaw.2007.181
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Sonka M, 1993, IMAGE PROCESSING ANA, P685
   Uy A.C.P, 2016, INT C HUM NAN INF TE
   Wang T, 2017, OPTIK INT J LIGHT EL, V157
   Wang T, 2015, SENSORS-BASEL, V15, P7156, DOI 10.3390/s150407156
   Wang T, 2014, IEEE T INF FOREN SEC, V9, P988, DOI 10.1109/TIFS.2014.2315971
   Wang T, 2013, SENSORS-BASEL, V13, P17130, DOI 10.3390/s131217130
   Wang T, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P13, DOI 10.1109/AVSS.2012.39
   Williamson R, 1999, INT C NEUR INF PROC
   Wu CX, 2018, IEEE ACCESS, V6, P20021, DOI 10.1109/ACCESS.2018.2823979
   Xu D, 2017, DETECTING ANOMALOUS, P117
   Yu LT, 2016, NEUROCOMPUTING, V213, P48, DOI 10.1016/j.neucom.2016.03.102
   Zhang Y, 2016, PATTERN RECOGN, V51, P443, DOI 10.1016/j.patcog.2015.09.005
   Zhou CJ, 2015, IEEE T SYST MAN CY-S, V45, P1345, DOI 10.1109/TSMC.2015.2415763
   Zhu WX, 2014, KNOWL-BASED SYST, V60, P35, DOI 10.1016/j.knosys.2014.01.002
   Zin T.T, 2010, 6 INT C INT INF HID
NR 52
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16319
EP 16348
DI 10.1007/s11042-020-08885-8
EA JUN 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000539939200004
DA 2024-07-18
ER

PT J
AU Akhtar, F
   Li, JQ
   Pei, Y
   Imran, A
   Rajput, A
   Azeem, M
   Liu, B
AF Akhtar, Faheem
   Li, Jianqiang
   Pei, Yan
   Imran, Azhar
   Rajput, Asif
   Azeem, Muhammad
   Liu, Bo
TI Diagnosis of large-for-gestational-age infants using a semi-supervised
   feature learned from expert and data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Large for gestational age; Feature selection and extraction; Learning
   system; Prediction model; Machine learning
ID WEIGHT-GAIN; BIRTH-WEIGHT; FETAL WEIGHT; CHILDHOOD; OUTCOMES;
   ASSOCIATION; DELIVERY; OBESITY; INSULIN; SYSTEM
AB In recent years, a rapid rise in the incidence of Large for gestational age (LGA) neonate is reported, and health care professionals employed themselves to discover the cause. Utmost of the previous studies were cohort or observational studies that employed simple linear or multivariate regression models, and very few of them employed machine learning (ML) schemes. Therefore, this research proposes to use 1 expert-driven and 7 automated feature selection schemes with well-known ML classifiers using 10 and 30 folds cross-validation. The induced results were compared with existing baselines, and Wilcoxon signed-rank test and the Friedman test were also introduced to verify the results. The ranked 20 features of the proposed expert-driven feature selection scheme outperformed amongst 7 automated feature selection schemes with a prediction precision, accuracy, and AUC scores of 0.94606, 0.84529, and 0.86492, respectively. Out of twenty features, eleven features were found similar to twenty ranked features of the automated feature selection schemes subsets. The classification results of the extracted features were utmost identical to the results of twenty features subset proposed by the expert-driven feature selection scheme. Therefore, we suggest pediatricians to refresh LGA diagnosis process with the proposed scheme because of its practical usage and maximum expert involvement.
C1 [Akhtar, Faheem; Li, Jianqiang; Imran, Azhar; Azeem, Muhammad; Liu, Bo] Beijing Univ Technol, Sch Software Engn, Beijing 100124, Peoples R China.
   [Akhtar, Faheem; Li, Jianqiang] Beijing Engn Res Ctr IoT Software & Syst, Beijing 100124, Peoples R China.
   [Akhtar, Faheem; Rajput, Asif] Sukkur IBA Univ, Dept Comp Sci, Sukkur 65200, Pakistan.
   [Pei, Yan] Univ Aizu, Div Comp Sci, Aizu Wakamatsu, Fukushima 9658580, Japan.
C3 Beijing University of Technology; Sukkur IBA University; University of
   Aizu
RP Pei, Y (corresponding author), Univ Aizu, Div Comp Sci, Aizu Wakamatsu, Fukushima 9658580, Japan.
EM fahim.akhtar@iba-suk.edu.pk; lijianqiang@bjut.edu.cn;
   peiyan@u-aizu.ac.jp; azharimran63@gmail.com; asifali@iba-suk.edu.pk;
   mazeem.qau@hotmail.com; boliu@bjut.edu.cn
RI LI, JIAN/JAX-3092-2023; li, jian/IAQ-2794-2023; LI, Jing/HNB-5575-2023;
   Li, Jin/GYQ-5363-2022; LI, JIAN/GRY-2197-2022; Pei, Yan/B-1356-2010;
   Liu, Jing/IQX-0664-2023; Azeem, Muhammad/ABG-2938-2021; li,
   jy/HTT-1535-2023; IMRAN, AZHAR/W-2615-2018; Quispe Calcina,
   Willian/JRX-9094-2023; li, jian/GSE-0245-2022; l, j/HNC-5728-2023; Li,
   Jing/GYU-5036-2022
OI Pei, Yan/0000-0003-1545-9204; IMRAN, AZHAR/0000-0003-3598-2780; Akhtar,
   Faheem/0000-0001-6755-1972; Rajput, Asif/0000-0002-0157-129X
FU National Key Research and Development Program of China [2017YFB1400803]
FX This work is supported by the National Key Research and Development
   Program of China with project no.2017YFB1400803.
CR Adankon MM, 2009, IEEE T NEURAL NETWOR, V20, P1858, DOI 10.1109/TNN.2009.2031143
   [Anonymous], ACTA OBSTET GYNECOL
   Araujo E, 2017, BEST PRACT RES CL OB, V38, P83, DOI 10.1016/j.bpobgyn.2016.08.003
   Bammann K, 2006, BIOMETRICS, V62, P943, DOI 10.1111/j.1541-0420.2006.00588_4.x
   BATTAGLI.FC, 1967, J PEDIATR-US, V71, P159, DOI 10.1016/S0022-3476(67)80066-0
   Blue NR, 2017, AM J PERINAT, V34, P1115, DOI 10.1055/s-0037-1604059
   Boney CM, 2005, PEDIATRICS, V115, pE290, DOI 10.1542/peds.2004-1808
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen Q, 2015, J DIABETES COMPLICAT, V29, P1037, DOI 10.1016/j.jdiacomp.2015.08.017
   Chiavaroli V, 2016, ITAL J PEDIATR, V42, DOI 10.1186/s13052-016-0254-7
   Chou YH, 2001, ULTRASOUND MED BIOL, V27, P1493, DOI 10.1016/S0301-5629(01)00466-5
   Dietz WH, 2004, NEW ENGL J MED, V350, P855, DOI 10.1056/NEJMp048008
   Dyer JS, 2007, EARLY HUM DEV, V83, pS138
   Faucher MA, 2015, WOMEN BIRTH, V28, pE70, DOI 10.1016/j.wombi.2015.03.006
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   HAIPIN SS, 2015, NATL MED J CHINA, V95, P162
   Hameed SS, 2016, PROG CARDIOVASC DIS, V58, P620, DOI 10.1016/j.pcad.2016.02.009
   Hannaford KE, 2017, AM J PERINAT, V34, P147, DOI 10.1055/s-0036-1584583
   Harper LM, 2014, AM J OBSTET GYNECOL, V211, DOI 10.1016/j.ajog.2014.04.028
   Henriksen T, 2008, ACTA OBSTET GYN SCAN, V87, P134, DOI 10.1080/00016340801899289
   Khambalia AZ, 2017, J PAEDIATR CHILD H, V53, P876, DOI 10.1111/jpc.13593
   Kominiarek MA, 2018, J PERINATOL, V38, P462, DOI 10.1038/s41372-018-0051-9
   Koyanagi A, 2013, LANCET, V381, P476, DOI 10.1016/S0140-6736(12)61605-5
   KUCIENE R, 2017, EUR J NUTR, V57, P1
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Kursa MB, 2010, FUND INFORM, V101, P271, DOI 10.3233/FI-2010-288
   LAZER S, 1986, J REPROD MED, V31, P501
   LI J, 2018, 7 INT C FRONT COMP F
   Li JH, 2019, J ENVIRON SCI, V76, P267, DOI 10.1016/j.jes.2018.05.009
   Luangkwan Supawadee, 2015, Journal of the Medical Association of Thailand, V98, pS71
   Mendez-Figueroa H, 2017, AM J PERINAT, V34, P655, DOI 10.1055/s-0036-1597325
   Menze BH, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-213
   MESHARI AA, 1990, INT J GYNECOL OBSTET, V32, P215, DOI 10.1016/0020-7292(90)90348-O
   Modinat M., 2015, INT J COMPUTER APPL, V126, P975, DOI 10.5120/ijca2015905983
   Moore GS, 2012, AM J OBSTET GYNECOL, V206, DOI 10.1016/j.ajog.2012.01.044
   Murtaza Ghulam, 2019, Journal of Physics: Conference Series, V1339, DOI 10.1088/1742-6596/1339/1/012035
   Murtaza G, 2020, MULTIMED TOOLS APPL, V79, P18447, DOI 10.1007/s11042-020-08692-1
   Murtaza G, 2020, MULTIMED TOOLS APPL, V79, P15481, DOI 10.1007/s11042-019-7525-4
   Murtaza G, 2020, ARTIF INTELL REV, V53, P1655, DOI 10.1007/s10462-019-09716-5
   Pearson K, 1900, PHILOS MAG, V50, P157, DOI 10.1080/14786440009463897
   Piper L.K., 2017, Obstet. Gynaecol. Reprod. Med, V27, P171, DOI [10.1016/j.ogrm.2017.03, DOI 10.1016/J.OGRM.2017.03]
   Rana HK, 2019, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.184
   Shen Y, 2017, J CLIN ULTRASOUND, V45, P465, DOI 10.1002/jcu.22463
   Shmueli A, 2017, AM J OBSTET GYNECOL, V216, pS150, DOI 10.1016/j.ajog.2016.11.146
   Taal HR, 2013, OBESITY, V21, P1261, DOI 10.1002/oby.20116
   Van Assche FA, 2010, DIABETOLOGIA, V53, P1243, DOI 10.1007/s00125-010-1712-1
   WIKSTROM I, 1988, ACTA OBSTET GYN SCAN, V67, P259, DOI 10.3109/00016348809004216
   Wolpert DavidH., 1995, No free lunch theorems for search, V10
   Xu H, 2010, ACTA PAEDIATR, V99, P550, DOI 10.1111/j.1651-2227.2009.01674.x
   Zhang H, 2004, LECT NOTES COMPUT SC, V3201, P501
   Zhu Li, 2015, Zhonghua Er Ke Za Zhi, V53, P97
NR 51
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34047
EP 34077
DI 10.1007/s11042-020-09081-4
EA JUN 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000539519000008
DA 2024-07-18
ER

PT J
AU Nan, FZ
   Zeng, QL
   Xing, YN
   Qian, YR
AF Nan, Fangzhe
   Zeng, Qingliang
   Xing, Yanni
   Qian, Yurong
TI Single Image Super-Resolution Reconstruction based on the ResNeXt
   Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image super-resolution reconstruction; ResNeXt; WGAN; Deep
   learning
AB To solve the complex computation, unstable network and slow learning speed problems of a generative adversarial network for image super-resolution (SRGAN), we proposed a single image super-resolution reconstruction model called the Res_WGAN based on ResNeXt. The generator is constructed by the ResNeXt network, which reduced the computational complexity of the model generator to 1/8 that of the SRGAN. The discriminator was constructed by the Wasserstein GAN(WGAN), which solved the SRGAN's instability. By removing the normalization operation in the residual network, the learning rate is improved. The experimental results from the Res_WGAN demonstrated that the proposed model achieved better performance in the subjective and objective evaluations using four public data sets compared with other state-of-the-art models.
C1 [Nan, Fangzhe; Zeng, Qingliang; Xing, Yanni; Qian, Yurong] Xinjiang Univ, Coll Software, Urumqi 830046, Peoples R China.
C3 Xinjiang University
RP Qian, YR (corresponding author), Xinjiang Univ, Coll Software, Urumqi 830046, Peoples R China.
EM 1508632217@qq.com; 969533858@qq.com; 1377429024@qq.com; qyr@xju.edu.cn
CR Arjovsky M, 2017, COMPUTER VISION PATT
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fangzhe N, 2019, APPL RES COMPUTERS, P1
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Ran Q, 2019, MULTIMEDIA TOOLS APP
   Rasti P, 2016, LECT NOTES COMPUT SC, V9756, P175, DOI 10.1007/978-3-319-41778-3_18
   Saining X, 2017, PROC CVPR IEEE, p:5987
   Szegedy C, 2016, RESERACHGATE
   Talha I, 2018, J MED SYSTEMS, V42
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Weisheng L, 2017, P IEEE INT C COMP VI, P5835
   Wu S, 2018, RESEARCHGATE
   Xi JX, 2018, INT J ROBUST NONLIN, V28, P2841, DOI 10.1002/rnc.4051
   Xie C, 2019, IEEE T IND ELECTRON, V66, P8981, DOI 10.1109/TIE.2018.2868249
   Ying T, 2017, P IEEE C COMP VIS PA, ps2790
   Yulun Z., 2018, ECCV
   Yulun Z, 2018, 2018 IEEE CVF C COMP
   Zhang K., 2017, PROC CVPR IEEE, P3929, DOI [DOI 10.1109/CVPR.2017.300, 10.1109/CVPR.2017.300]
   Zhang X, 2018, INT J BIOMED IMAGING, V2018, DOI 10.1155/2018/2572431
NR 25
TC 19
Z9 21
U1 3
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34459
EP 34470
DI 10.1007/s11042-020-09053-8
EA JUN 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000539519000003
DA 2024-07-18
ER

PT J
AU Gour, N
   Khanna, P
AF Gour, Neha
   Khanna, Pritee
TI Speckle denoising in optical coherence tomography images using residual
   deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speckle denoising; Optical coherence tomography; Convolutional neural
   network; Residual network; Ocular disease diagnosis
ID NOISE-REDUCTION; ANISOTROPIC DIFFUSION; ALGORITHM; SPARSE
AB Optical Coherence Tomography (OCT) is an emerging imaging modality used for diagnosis of ocular diseases like age-related macular degeneration (AMD) and macular edema. OCT imaging is a non-invasive technique to capture cross-sectional volumes of the retinal areas of human eye. Due to coherent nature of image acquisition process, OCT images suffer from granular multiplicative speckle noise. Presence of speckle noise in OCT images makes its clinical analysis difficult for the experts. The same is the problem with the development of computer aided diagnosis (CAD) systems for detection of ocular diseases. Speckle noise is granular in nature and interferes with the diagnostic observations made using OCT images and the segmentation of different OCT layers. This work presents an efficient OCT denoising technique using residual convolutional neural network. The proposed technique will not only help experts in analysis of OCT images, but can also act as first step to construct CAD systems for ocular diseases. The performance of the proposed approach is evaluated on Duke (SD-OCT) and Topcon (3D-OCT) image databases based on visual and parametric observations. The performance of the proposed method on parameters like PSNR, SSIM, MSR, CNR, and ENL is compared with the state-of-the-art speckle denoising methods. It is observed that the proposed approach performs better as compared to the methods referred from literature on both visual and parametric evaluations.
C1 [Gour, Neha; Khanna, Pritee] PDPM Indian Inst Informat Technol Design & Mfg, Jabalpur, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Gour, N (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Jabalpur, India.
EM g.neha@iiitdmj.ac.in; pkhanna@iiitdmj.ac.in
RI gour, neha/ISB-0210-2023; Khanna, Pritee/V-5418-2019
OI Khanna, Pritee/0000-0003-0518-2133; GOUR, NEHA/0000-0002-0860-1260
CR Adabi S, 2018, J BIOMED OPT, V23, DOI 10.1117/1.JBO.23.1.016013
   Adhi M, 2013, CURR OPIN OPHTHALMOL, V24, P213, DOI 10.1097/ICU.0b013e32835f8bf8
   Adiga VS, 2018, ELEVENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2018), DOI 10.1145/3293353.3293388
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   Avanaki MRN, 2013, IEEE PHOTONIC TECH L, V25, P1439, DOI 10.1109/LPT.2013.2266660
   Bernardes R, 2010, OPT EXPRESS, V18, P24048, DOI 10.1364/OE.18.024048
   Boyat AK, ARXIV150503489
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Chong B, 2013, OPT COMMUN, V291, P461, DOI 10.1016/j.optcom.2012.10.053
   Chong GT, 2009, ARCH OPHTHALMOL-CHIC, V127, P37, DOI 10.1001/archophthalmol.2008.550
   Cincotti G, 2001, IEEE T MED IMAGING, V20, P764, DOI 10.1109/42.938244
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Du YZ, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.5.056009
   DUBEY SD, 1970, METRIKA, V16, P27, DOI 10.1007/BF02613934
   Duker JS., 2013, Handbook of Retinal OCT: Optical Coherence Tomography E-Book
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fang LY, 2012, BIOMED OPT EXPRESS, V3, P927, DOI 10.1364/BOE.3.000927
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   GOODMAN JW, 1976, J OPT SOC AM, V66, P1145, DOI 10.1364/JOSA.66.001145
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Isar CS-CA, 2015, SCI B POLITEHNICA U, V60, P3
   Jain V., 2009, PROC ADV NEURAL INFO, P769
   Jiao JB, 2017, IEEE COMPUT SOC CONF, P1034, DOI 10.1109/CVPRW.2017.140
   Kafieh R, 2015, IEEE T MED IMAGING, V34, P1042, DOI 10.1109/TMI.2014.2374354
   KUAN DT, 1987, IEEE T ACOUST SPEECH, V35, P373, DOI 10.1109/TASSP.1987.1165131
   Kumar Nalin, 2017, Oriental Journal of Computer Science and Technology, V10, P103, DOI 10.13005/ojcst/10.01.14
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee J. S., 1994, REMOTE SENSING REV, V8, P313, DOI [10.1080/02757259409532206, DOI 10.1080/02757259409532206]
   Li MXZ, 2017, BIOMED OPT EXPRESS, V8, P3903, DOI 10.1364/BOE.8.003903
   LOPES A, 1993, INT J REMOTE SENS, V14, P1735, DOI 10.1080/01431169308953999
   LOUPAS T, 1989, IEEE T CIRCUITS SYST, V36, P129, DOI 10.1109/31.16577
   Mayer MA, 2012, BIOMED OPT EXPRESS, V3, P572, DOI 10.1364/BOE.3.000572
   Murakami T, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P31, DOI 10.1109/CSPA.2018.8368680
   Pircher M, 2003, J BIOMED OPT, V8, P565, DOI 10.1117/1.1578087
   Pircher M, 2011, PROG RETIN EYE RES, V30, P431, DOI 10.1016/j.preteyeres.2011.06.003
   Puvanathasan P, 2009, OPT EXPRESS, V17, P733, DOI 10.1364/OE.17.000733
   Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349
   Schmitt JM, 1999, J BIOMED OPT, V4, P95, DOI 10.1117/1.429925
   Selesnick IW, 2004, IEEE T SIGNAL PROCES, V52, P1304, DOI 10.1109/TSP.2004.826174
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tawse KL, 2014, BRIT J OPHTHALMOL, V98, P30, DOI 10.1136/bjophthalmol-2013-304301
   Thakur I, REV NOISE REDUCTION, V3
   Thomas MG, 2011, OPHTHALMOLOGY, V118, P1653, DOI 10.1016/j.ophtha.2011.01.028
   Wang H, 2009, J BIOMED OPT, V14, DOI 10.1117/1.3155523
   Wang SH, 2018, J MED SYST, V42, DOI [10.1007/s10916-017-0845-x, 10.1007/s10916-018-0932-7]
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong A, 2010, OPT EXPRESS, V18, P8338, DOI 10.1364/OE.18.008338
   Xia SY, 2016, BIOMED OPT EXPRESS, V7, P2912, DOI 10.1364/BOE.7.002912
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang Y, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/787680
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 57
TC 23
Z9 24
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15679
EP 15695
DI 10.1007/s11042-019-07999-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900071
DA 2024-07-18
ER

PT J
AU Shao, YL
AF Shao, Yilin
TI Wireless multimedia sensor network video object detection method using
   dynamic clustering algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Target detection; Wireless multimedia; Sensor network video; Dynamic
   clustering algorithm
AB Most of the traditional tracking algorithms use the Kalman filter to predict the tracking process. Although the tracking accuracy is relatively high, the calculation is large and the time complexity is high. Based on this research, this paper proposes a dynamic clustering target tracking algorithm for motion trends. The algorithm forms a dynamic cluster in the network, and the cluster head dynamically schedules the nodes to achieve collaborative tracking of the targets. The tracking strategy is mainly divided into two stages: First, the cluster head establishes a "neighbor node set" within its communication range, and selects the neighbor node in the "neighbor node set" according to the distance between the node and the target to construct the "intra-cluster member set" to perform the target on the target. Tracking; as the target moves continuously, the cluster head updates the members in the cluster at regular intervals, removes the nodes that have lost the target monitoring from the cluster, and adds the new nodes to the cluster; secondly, elects a new cluster head; if current When the cluster head is no longer suitable to continue to serve as the cluster head, the current cluster head selects the node in the "intra-cluster member set" as the new cluster head of the next work cycle; according to the moving direction of the target, selects the node with the best moving tendency of the target For the new cluster head, this allows the new cluster head to have a longer duty cycle and avoid frequent replacement of the cluster head; the new cluster head continues to set up the dynamic cluster to track the target until the target moves out of the monitoring area. The simulation results show that the proposed algorithm is more efficient than the traditional target tracking method.
C1 [Shao, Yilin] Shangqiu Polytech, Sch Comp, Shangqiu 476100, Henan, Peoples R China.
RP Shao, YL (corresponding author), Shangqiu Polytech, Sch Comp, Shangqiu 476100, Henan, Peoples R China.
EM libghaifeiwu2@163.com
CR Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Alhilal MS, 2014, INT CONF MULTIMED, P927, DOI 10.1109/ICMCS.2014.6911274
   [Anonymous], 2014, P WAMICON 2014
   [Anonymous], WIRELESS PERSONAL CO
   Asurti N, 2015, INT J COMPUT APPL, V119, P18
   Chen YH, 2013, 2013 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P1, DOI 10.1109/ISBAST.2013.3
   Gao L, 2012, IEEE ENG MED BIO, P1077, DOI 10.1109/EMBC.2012.6346121
   Ghadi M, 2016, MULTIMED TOOLS APPL, V75, P3425, DOI 10.1007/s11042-014-2443-y
   Kamal AM, 2014, ACM T SENSOR NETWORK, V10, DOI 10.1145/2530526
   Koulali MA, 2012, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2012-158
   Liu Y, 2013, MULTIMED TOOLS APPL, V67, P97, DOI [10.1007/s11042-012-1054-8, DOI 10.1007/S11042-012-1054-8]
   Masazade E, 2012, IEEE T SIGNAL PROCES, V60, P5048, DOI 10.1109/TSP.2012.2204257
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Salunke A, 2015, IEEE INT C EL COMP C, P1
   Spachos P, 2015, IEEE ICC, P6935, DOI 10.1109/ICC.2015.7249431
   Wu HJ, 2016, TELECOMMUN SYST, V62, P43, DOI 10.1007/s11235-015-9981-0
   Zappi P, 2012, ACM T EMBED COMPUT S, V11, DOI 10.1145/2345770.2345781
NR 17
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16927
EP 16940
DI 10.1007/s11042-019-7474-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600061
DA 2024-07-18
ER

PT J
AU Wu, JY
   Huang, WL
   Xia-Hou, WM
   Zou, WP
   Gong, LH
AF Wu, Jun-Yun
   Huang, Wei-Liang
   Xia-Hou, Wei-Ming
   Zou, Wei-Ping
   Gong, Li-Hua
TI Imperceptible digital watermarking scheme combining 4-level discrete
   wavelet transform with singular value decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Robustness; Imperceptibility; Discrete wavelet
   transform; Fusion mechanism
ID DWT-SVD; ROBUST; ENCRYPTION; SECURE
AB An imperceptible digital watermarking algorithm based on 4-level discrete wavelet transform, discrete cosine transform and singular value decomposition is designed. In this method, the 4-level diagonal sub-band image is obtained by performing the 4-level two-dimensional wavelet transform on the original image, and then a coefficient matrix is produced by applying the discrete cosine transform on the 4-level diagonal sub-band image. A diagonal matrix is constructed by performing the singular value decomposition on the coefficient matrix. The watermark is scrambled by Arnold transform and Logistic map, then the scrambled watermark is processed by the singular value decomposition. Later, the encryption process is completed by embedding the scrambled watermark singular value into the singular value of the coefficient matrix. Simulation results demonstrate that the proposed digital watermarking algorithm could resist JPEG compression attack, Salt and Pepper noise attack, Gaussian noise attack, filter attack, brightness change attack, geometric attack, cut attack, etc.
C1 [Wu, Jun-Yun; Huang, Wei-Liang] Nanchang Univ, Dept Comp Sci & Technol, Nanchang 330031, Jiangxi, Peoples R China.
   [Xia-Hou, Wei-Ming; Gong, Li-Hua] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Zou, Wei-Ping] Univ Poitiers, XLIM SCI Lab, UMR CNRS 7252, Poitiers, France.
C3 Nanchang University; Nanchang University; Universite de Poitiers
RP Gong, LH (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM lhgong@ncu.edu.cn
OI Gong, Lihua/0000-0002-1180-3023
FU National Natural Science Foundation of China [61861029, 61462061];
   Department of Human Resources and Social security of Jiangxi Province;
   Major Academic Discipline and Technical Leader of Jiangxi Province
   [20162BCB22011]; Natural Science Foundation of Jiangxi Province
   [20171BAB202002]; Cultivation Plan of Applied Research of Jiangxi
   Province [20181BBE58022]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 61861029 and 61462061), the Department of Human
   Resources and Social security of Jiangxi Province, the Major Academic
   Discipline and Technical Leader of Jiangxi Province (Grant No.
   20162BCB22011), the Natural Science Foundation of Jiangxi Province
   (Grant No. 20171BAB202002), and the Cultivation Plan of Applied Research
   of Jiangxi Province (Grant no. 20181BBE58022).
CR Abd El-Latif AA, 2012, 4 INT C DIG IM PROC, P8334
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P10332, DOI 10.1109/ACCESS.2018.2799879
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P1073, DOI 10.1109/ACCESS.2017.2777869
   Abd El-Latif AA, 2013, OPT LASER TECHNOL, V54, P389, DOI 10.1016/j.optlastec.2013.04.018
   Bassel A., 2016, J ENG APPL SCI, V11, P3227, DOI DOI 10.36478/JEASCI.2016.3227.3232
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Belazi A, 2015, INT WIREL COMMUN, P606, DOI 10.1109/IWCMC.2015.7289152
   Benrhouma O, 2016, MULTIMED TOOLS APPL, V75, P8695, DOI 10.1007/s11042-015-2786-z
   Cao WQ, 2017, MULTIMED TOOLS APPL, V76, P13221, DOI 10.1007/s11042-016-3751-1
   Esgandari R, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P988, DOI 10.1109/KBEI.2015.7436179
   Gupta AK, 2012, SADHANA-ACAD P ENG S, V37, P425, DOI 10.1007/s12046-012-0089-x
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Li M, 2019, MULTIMED TOOLS APPL, V78, P22727, DOI 10.1007/s11042-019-7560-1
   Luo H, 2011, OPTIK, V122, P311, DOI 10.1016/j.ijleo.2009.12.018
   Moeinaddini E, 2018, MULTIMED TOOLS APPL, V77, P26083, DOI 10.1007/s11042-018-5838-3
   Shen CW, 2012, INT SYM COMPUT INTEL, P273, DOI 10.1109/ISCID.2012.76
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh RK, 2017, J INFORM OPTIM SCI, V38, P911, DOI 10.1080/02522667.2017.1372137
   Song XH, 2013, QUANTUM INF PROCESS, V12, P3689, DOI 10.1007/s11128-013-0629-2
   Song XH, 2014, MULTIMEDIA SYST, V20, P379, DOI 10.1007/s00530-014-0355-3
   Tang LL, 2015, MULTIMED TOOLS APPL, V74, P4397, DOI 10.1007/s11042-013-1531-8
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Xia C, 2019, IEEE ACCESS, V7, P50339, DOI 10.1109/ACCESS.2019.2910536
   Xia C, 2018, J REAL-TIME IMAGE PR, V14, P223, DOI 10.1007/s11554-016-0600-4
   Xiao D, 2017, MULTIMED TOOLS APPL, V76, P9265, DOI 10.1007/s11042-016-3532-x
   Xiao D, 2016, MULTIMED TOOLS APPL, V75, P13779, DOI 10.1007/s11042-015-2922-9
   Xiao D, 2015, MULTIMED TOOLS APPL, V74, P7729, DOI 10.1007/s11042-014-2017-z
   Yan XH, 2015, SIGNAL IMAGE VIDEO P, V9, P499, DOI 10.1007/s11760-013-0465-y
   Ye X, 2015, SIFT BASED DWT SVD B, P323
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhao ZZ, 2018, MULTIMED TOOLS APPL, V77, P14093, DOI 10.1007/s11042-017-5016-z
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
   Zhou NR, 2018, MULTIMED TOOLS APPL, V77, P30251, DOI 10.1007/s11042-018-6128-9
   ZHOU X, 2018, SYMMETRY-BASEL, V10
NR 36
TC 14
Z9 15
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22727
EP 22747
DI 10.1007/s11042-020-08987-3
EA MAY 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000554789500002
DA 2024-07-18
ER

PT J
AU Jainish, GR
   Jiji, GW
   Infant, PA
AF Jainish, G. R.
   Jiji, G. Wiselin
   Infant, P. Alwin
TI A novel automatic retinal vessel extraction using maximum entropy based
   EM algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal images; Vessel segmentation; Histogram equalization; Entropy;
   Expectation maximization
ID BLOOD-VESSELS; SEGMENTATION; IMAGES
AB The extraction of blood vessels helps in the diagnosis of diseases and to develop advances of medicine. Retinal blood vessel extraction plays a crucial role in early detection and treatment of retinal diseases. This paper provides an automatic segmentation of blood vessels in retinal images. First, the fundus images go through preprocessing steps of image acquisition, grey scale conversion, bias correction and adaptive histogram equalization to enhance the appearance of retinal blood vessels. Then the retinal blood vessels are extracted using a probabilistic modeling and maximum entropy based expectation maximization algorithm which uses maximum entropy uniform distribution as the initial condition. The vessels are more accurately confined using image profiles computed perpendicularly across each of the detected vessel centerline. The algorithm is implemented in MATLAB and the performance is tested on retinal images from DRIVE and STARE databases. When validated, we conclude that the segmentation of retinal images using the proposed method shows a sensitivity of 98.9%, a specificity of 83.74%, and an Accuracy score of 98.8%.
C1 [Jainish, G. R.] Manonmaniam Sundaranar Univ, Tirunelveli, India.
   [Jiji, G. Wiselin] Dr Sivanthi Aditanar Coll Engn, Tiruchendur, India.
   [Infant, P. Alwin] Loyola Inst Technol & Sci, Thovalai, India.
C3 Manonmaniam Sundaranar University
RP Jainish, GR (corresponding author), Manonmaniam Sundaranar Univ, Tirunelveli, India.
EM jainish.gr@gmail.com; jijivevin@yahoo.co.in; alwininfant@hotmail.com
OI Infant, Alwin/0000-0003-4336-3162
CR Al-Diri B, 2009, IEEE T MED IMAGING, V28, P1488, DOI 10.1109/TMI.2009.2017941
   CHANWIMALUANG T, 2003, P INT S CIRC SYST, V5, P21, DOI DOI 10.1109/ISCAS.2003.1206162
   CHAUDHURI S, 1989, IEEE T MED IMAGING, V8, P263, DOI 10.1109/42.34715
   Cinsdikici MG, 2009, COMPUT METH PROG BIO, V96, P85, DOI 10.1016/j.cmpb.2009.04.005
   Fritzsche KH, 2003, BIOMED EN S, P225
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Jiang XY, 2003, IEEE T PATTERN ANAL, V25, P131, DOI 10.1109/TPAMI.2003.1159954
   Jiji GW, 2015, INT J BIOMED ENG TEC, V19, P118, DOI 10.1504/IJBET.2015.072932
   Kaba D, 2014, HEALTH INF SCI SYST, V2, DOI 10.1186/2047-2501-2-2
   Kande GB, 2007, INT J COMPUT SCI NET, V7, P102
   Lam BSY, 2008, IEEE T MED IMAGING, V27, P237, DOI 10.1109/TMI.2007.909827
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Martinez-Perez ME, 2007, MED IMAGE ANAL, V11, P47, DOI 10.1016/j.media.2006.11.004
   Mendonça AM, 2006, IEEE T MED IMAGING, V25, P1200, DOI 10.1109/TMI.2006.879955
   Niemeijer M, 2004, PROC SPIE, V5370, P648, DOI 10.1117/12.535349
   Odstrcilik J, 2013, IET IMAGE PROCESS, V7, P373, DOI 10.1049/iet-ipr.2012.0455
   Roychowdhury S, 2001, IEEE J BIOMED HEALTH, V4, P99
   Salazar-Gonzalez A, 2014, IEEE J BIOMED HEALTH, V18, P1874, DOI 10.1109/JBHI.2014.2302749
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908
   Vermeer KA, 2004, COMPUT BIOL MED, V34, P209, DOI 10.1016/S0010-4825(03)00055-6
   Wu D, 2006, IEEE T BIO-MED ENG, V53, P341, DOI 10.1109/TBME.2005.862571
   Xu LL, 2010, BIOMED ENG ONLINE, V9, DOI 10.1186/1475-925X-9-14
   Zana F, 2001, IEEE T IMAGE PROCESS, V10, P1010, DOI 10.1109/83.931095
NR 25
TC 6
Z9 8
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22337
EP 22353
DI 10.1007/s11042-020-08958-8
EA MAY 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000534717000001
DA 2024-07-18
ER

PT J
AU Ilyas, M
   Othmani, A
   Nait-ali, A
AF Ilyas, Muhammad
   Othmani, Alice
   Nait-ali, Amine
TI Auditory perception based system for age classification and estimation
   using dynamic frequency sound
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Auditory perception; Age estimation; Age group classification;
   Biometrics; Forensics
ID SECONDARY DENTIN FORMATION; FEATURE-SELECTION; MODEL; DNA
AB Human age is a crucial factor in social interaction. It determines the way we interact with others. It is also a relevant forensic issue that can provide helpful information in legal and criminal investigations. Thus, human age estimation has a wide range of real-world applications related to human computer interaction and forensic sciences. Based on auditory perception, in this paper, we investigate a new biometric trait for human age classification and estimation. For this purpose, several techniques of Machine Learning, including Random Forests (RF), Support Vector Machines (SVM), Linear Regression (LR), Polynomial Regression (PR), Ridge Regression (RR) and Artificial Neural Networks (ANNs), are used to estimate the age of the volunteers. To evaluate the performances of our experiment, a dataset of 837 tests have been collected with different ages ranging from 6 to 60 years. The results show a good accuracy between 86% and 92% of reasonable classification and 98.2% of good age estimation with a root-mean-square error of 2.6 years. Results are found to be significant and show that auditory perception is one of the practical interests in real-world applications. The dataset we used will be made publicly available online.
C1 [Ilyas, Muhammad; Othmani, Alice; Nait-ali, Amine] Univ Paris Est, LISSI UPEC, F-94400 Vitry Sur Seine, France.
C3 Universite Paris-Est-Creteil-Val-de-Marne (UPEC)
RP Ilyas, M (corresponding author), Univ Paris Est, LISSI UPEC, F-94400 Vitry Sur Seine, France.
EM ilyaskhantmg@hotmail.com
CR Anguita Davide, 2009, Proceedings of the 2009 International Conference on Data Mining. DMIN 2009, P291
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Breiman L., 2011, MACH LEARN, V45, P123
   Bukar AM, 2017, IET COMPUT VIS, V11, P650, DOI 10.1049/iet-cvi.2016.0486
   Ceyhan EB, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P478, DOI 10.1109/ICMLA.2014.83
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cortes C., 2009, P 25 C UNCERTAINTY A, P109, DOI DOI 10.5555/1795114.1795128
   De Paolis A, 2017, HEARING RES, V349, P111, DOI 10.1016/j.heares.2017.01.015
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Dobry G, 2011, IEEE T AUDIO SPEECH, V19, P1975, DOI 10.1109/TASL.2011.2104955
   Dornaika F, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112942
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   Farhadian M, 2019, IMAGNG SCI DENT, V49, P19, DOI 10.5624/isd.2019.49.1.19
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Freire-Aradas A, 2017, FOREN SCI REV, V29, P2
   Guyon I, 2010, J MACH LEARN RES, V11, P61
   Haraksim R, 2019, PATTERN RECOGN, V88, P614, DOI 10.1016/j.patcog.2018.12.024
   Ilyas M, 2018, PREDICTION HEARING L
   Ilyas M., 2020, HIDDEN BIOMETRICS, P113
   Ilyas M, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8111313
   Ilyas M, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON BIO-ENGINEERING FOR SMART TECHNOLOGIES (BIOSMART)
   Jagannath A, 2003, LETT APPL MICROBIOL, V37, P399, DOI 10.1046/j.1472-765X.2003.01416.x
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Li GQ, 2019, 2019 42ND INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1049, DOI [10.23919/mipro.2019.8756740, 10.23919/MIPRO.2019.8756740]
   Li X, 2018, MULTIMED TOOLS APPL, V77, P28333, DOI 10.1007/s11042-018-6049-7
   Lima M. A. M. T., 2007, REV BRAS OTORRINOLAR, V73, P2, DOI DOI 10.1590/S0034-72992007000100001
   Liu KH, 2019, IEEE T IMAGE PROCESS, V28, P5187, DOI 10.1109/TIP.2019.2916768
   Makihara Y., 2011, 2011 INT JOINT C BIO, P1, DOI 10.1109/IJCB.2011.6117531
   Manley GA, 2016, HEARING RES, V336, P53, DOI 10.1016/j.heares.2016.04.004
   Meinl A, 2007, J FORENSIC SCI, V52, P438, DOI 10.1111/j.1556-4029.2006.00377.x
   Metze F, 2007, INT CONF ACOUST SPEE, P1089
   Moyse E, 2014, PSYCHOL BELG, V54, P255, DOI 10.5334/pb.aq
   Nabila M, 2018, IET BIOMETRICS, V7, P116, DOI 10.1049/iet-bmt.2016.0176
   Paewinsky E, 2005, INT J LEGAL MED, V119, P27, DOI 10.1007/s00414-004-0492-x
   Parson W, 2018, GERONTOLOGY, V64, P326, DOI 10.1159/000486239
   Ramlee R, 2013, INT CONF INTELL SYST, P104, DOI 10.1109/ISDA.2013.6920716
   Ramu T, 2013, MULTITOOLS APPL, P1
   Rossing T., 2007, Springer Handbook of Acoustics, P747
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Sakata Atsuya, 2019, IPSJ Transactions on Computer Vision and Applications, V11, DOI 10.1186/s41074-019-0054-2
   Scheffer T., 1999, THESIS
   Seber G. A., 2012, LINEAR REGRESSION AN, V329
   Semwal VB, 2019, ADV INTELL SYST COMP, V748, P135, DOI 10.1007/978-981-13-0923-6_12
   Semwal VB, 2017, MULTIMED TOOLS APPL, V76, P24457, DOI 10.1007/s11042-016-4110-y
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Shafran I, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU '03, P31, DOI 10.1109/ASRU.2003.1318399
   Shen W, 2018, PROC CVPR IEEE, P2304, DOI 10.1109/CVPR.2018.00245
   Statnikov A, 2005, INT J MED INFORM, V74, P491, DOI 10.1016/j.ijmedinf.2005.05.002
   STOCKWELL CW, 1969, ANN OTO RHINOL LARYN, V78, P1144, DOI 10.1177/000348946907800602
   Stuart R., 2011, Signals and Systems for Speech and Hearing, P163
   Tsimperidis I, 2017, INT J DIGIT CRIME FO, V9, P1, DOI 10.4018/IJDCF.2017010101
   Uzun Y, 2015, ARXIV151105672
   Wen J, 2018, NEURAL NETWORKS, V102, P36, DOI 10.1016/j.neunet.2018.02.002
   Willems G, 2001, J Forensic Odontostomatol, V19, P9
   Yu TT, 2019, CAAI T INTELL TECHNO, V4, P122, DOI 10.1049/trit.2019.0017
   Zhu HP, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2733-4
   Zubakov D, 2016, FORENSIC SCI INT-GEN, V24, P33, DOI 10.1016/j.fsigen.2016.05.014
   ZWICKER E, 1961, J ACOUST SOC AM, V33, P248, DOI 10.1121/1.1908630
NR 58
TC 3
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21603
EP 21626
DI 10.1007/s11042-020-08843-4
EA MAY 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000531216800004
DA 2024-07-18
ER

PT J
AU Fu, JY
   Zhao, CR
   Xia, Y
   Liu, WB
AF Fu, Jiayue
   Zhao, Cairong
   Xia, Ye
   Liu, Wenbin
TI Vehicle and wheel detection: a novel SSD-based approach and associated
   large-scale benchmark dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle and wheel detection; Optimized SSD; Large-scale dataset
AB Many vehicle and wheel detection methods based on convolutional neural networks suffer from challenges due to the lack of training data and the limitation on small object detection. To solve this problem, we present a novel optimized SSD algorithm with multi-concatenation modules, aiming to improve the performance of small object detection. In the multi-concatenation module, features from different layers are concatenated together, including feature map from shallow layer with more location information, feature map from intermediate layer, and feature map from deep layer with rich semantic information. SEBlock is employed to re-weight the new feature map to improve the quality of representation. Furthermore, to facilitate the study of vision-based vehicle and wheel detection, a large-scale benchmark dataset of 8209 images is established, comprising five object categories: truck, pickup, tractor, car, and wheel. On the Pascal VOC 2007 test set, our network achieves 78.7% mAP, which is higher than SSD by 1.5%. On KITTI dataset, the proposed method can reach 71.4% mAP, surpassing SSD by 3.5%. In addition, experimental results show that the proposed method results in better detection performance on small objects.
C1 [Fu, Jiayue; Zhao, Cairong] Tongji Univ, Dept Comp Sci & Technol, Shanghai 201804, Peoples R China.
   [Xia, Ye] Tongji Univ, Dept Bridge Engn, Shanghai, Peoples R China.
   [Liu, Wenbin] Shanghai Key Lab Crime Scene Evidence, Shanghai, Peoples R China.
   [Liu, Wenbin] Shanghai Res Inst Criminal Sci & Technol, Shanghai, Peoples R China.
C3 Tongji University; Tongji University
RP Zhao, CR (corresponding author), Tongji Univ, Dept Comp Sci & Technol, Shanghai 201804, Peoples R China.
EM zhaocairong@tongji.edu.cn
RI liu, wen/HGE-3071-2022
CR Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai Jifeng, 2016, Advances in Neural Information Processing Systems, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   FELZENSZWALB PF, 2010, PROC CVPR IEEE, P2241, DOI DOI 10.1109/CVPR.2010.5539906
   Fu C.Y., ARXIV170106659
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jaiswal A, 2019, PROC CVPR IEEE, P11322, DOI 10.1109/CVPR.2019.01159
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Yuan Y, 2019, IEEE T IMAGE PROCESS, V28, P3423, DOI 10.1109/TIP.2019.2896952
   Yuan Y, 2017, IEEE T INTELL TRANSP, V18, P1918, DOI 10.1109/TITS.2016.2614548
   Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609
   Zheng LW, 2018, PROC SPIE, V10806, DOI 10.1117/12.2503001
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 37
TC 5
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12615
EP 12634
DI 10.1007/s11042-019-08523-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400060
DA 2024-07-18
ER

PT J
AU Zhao, TY
   Chi, YY
AF Zhao, Tieyu
   Chi, Yingying
TI Hierarchical visual cryptography for multisecret images based on a
   modified phase retrieval algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret sharing; Visual cryptography; Multiple secrets sharing; Phase
   retrieval algorithm
ID ENCRYPTION; SECRETS; SHADOW
AB Visual cryptography is generally based on the base matrix scheme or the random grid scheme. These schemes may cause some problems, such as the expansion of the shares and the recovered images and the distortion of the recovered images. In this paper, we propose a modified phase retrieval algorithm and present a hierarchical visual cryptography scheme (HVCS). The scheme overcomes the problems that are mentioned and can share multiple secret images. Considering the differences in the social division of labor, there is a hierarchy between the shared images in the proposed scheme, that is, the participants have different rights. Further, to make the proposed scheme more applicable to practical needs, we propose a generalized HVCS by modifying the phase retrieval algorithm again so that each level can have more than one participant. The effectiveness and feasibility of the proposed scheme are verified by theoretical analysis and numerical simulation.
C1 [Zhao, Tieyu; Chi, Yingying] Northeastern Univ Qinhuangdao, Informat Sci Teaching & Res Sect, Qinhuangdao 064000, Hebei, Peoples R China.
C3 Northeastern University - China
RP Zhao, TY (corresponding author), Northeastern Univ Qinhuangdao, Informat Sci Teaching & Res Sect, Qinhuangdao 064000, Hebei, Peoples R China.
EM zty03y3213@163.com
OI Zhao, Tieyu/0000-0002-6199-1907
CR [Anonymous], 1998, THESIS
   Chavan PV, 2012, NIRM U INT C ENG NUI, P1
   Chen J, 2009, IMAGING SCI J, V57, P101, DOI 10.1179/174313108X384656
   Chen W, 2013, IEEE PHOTONICS J, V5, DOI 10.1109/JPHOT.2013.2258144
   Feng JB, 2008, PATTERN RECOGN, V41, P3572, DOI 10.1016/j.patcog.2008.05.031
   GERCHBERG RW, 1972, OPTIK, V35, P237
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Lee JS, 2015, DIGIT SIGNAL PROCESS, V40, P131, DOI 10.1016/j.dsp.2015.02.012
   Meng XF, 2006, APPL OPTICS, V45, P3289, DOI 10.1364/AO.45.003289
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Patel T., 2016, INT C GREEN ENG TECH, P1
   Pirbhulal S, 2019, FUTURE GENER COMP SY, V95, P382, DOI 10.1016/j.future.2019.01.008
   Pirbhulal S, 2018, INT CONF DAT MIN WOR, P136, DOI 10.1109/ICDMW.2018.00026
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Talat R., 2019, IEEE ACM T NETW, P1
   Wu HC, 2005, COMPUT STAND INTER, V28, P123, DOI 10.1016/j.csi.2004.12.006
   Wu WQ, 2020, NEURAL COMPUT APPL, V32, P11055, DOI 10.1007/s00521-018-3855-9
   Yang CN, 2013, IMAGING SCI J, V61, P334, DOI 10.1179/1743131X11Y.0000000062
   Yang CN, 2010, OPT COMMUN, V283, P4949, DOI 10.1016/j.optcom.2010.07.051
   Yu B, 2014, MULTIMED TOOLS APPL, V72, P1867, DOI 10.1007/s11042-013-1479-8
   Zhao TY, 2018, J MOD OPTIC, V65, P1072, DOI 10.1080/09500340.2017.1423409
   Zhao TY, 2016, J MOD OPTIC, V63, P771, DOI 10.1080/09500340.2015.1101171
NR 22
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12165
EP 12181
DI 10.1007/s11042-020-08632-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400040
DA 2024-07-18
ER

PT J
AU Qiu, YC
   Zhou, GZ
   Zhang, Y
   Cichocki, A
AF Qiu, Yichun
   Zhou, Guoxu
   Zhang, Yu
   Cichocki, Andrzej
TI Canonical polyadic decomposition (CPD) of big tensors with low
   multilinear rank
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tucker decompositions; Canonical polyadic decomposition (CPD); Tensor
   decomposition
ID NONNEGATIVE MATRIX; ALGORITHMS; SPEED
AB Tensor decomposition methods have been widely applied to big data analysis as they bring multiple modes and aspects of data to a unified framework, which allows us to discover complex internal structures and correlations of data. Unfortunately most existing approaches are not designed to meet the challenges posed by big data dilemma. This paper attempts to improve the scalability of tensor decompositions and makes two contributions: A flexible and fast algorithm for the CP decomposition (FFCP) of tensors based on their Tucker compression; A distributed randomized Tucker decomposition approach for arbitrarily big tensors but with relatively low multilinear rank. These two algorithms can deal with huge tensors, even if they are dense. Extensive simulations provide empirical evidence of the validity and efficiency of the proposed algorithms.
C1 [Qiu, Yichun; Zhou, Guoxu] Guangdong Univ Technol, Sch Automat, Guangzhou, Peoples R China.
   [Zhou, Guoxu] Guangdong Univ Technol, Sch Automat, Guangdong HongKong Macao Joint Lab Smart Discrete, Guangzhou 510006, Peoples R China.
   [Zhang, Yu] Stanford Univ, Dept Psychiat & Behav Sci, Stanford, CA 94305 USA.
   [Cichocki, Andrzej] Skolkovo Inst Sci & Technol SKOLTECH, Moscow 143026, Russia.
   [Cichocki, Andrzej] Polish Acad Sci, Syst Res Inst, PL-00901 Warsaw, Poland.
C3 Guangdong University of Technology; Guangdong University of Technology;
   Stanford University; Skolkovo Institute of Science & Technology; Polish
   Academy of Sciences; Systems Research Institute of the Polish Academy of
   Sciences
RP Zhou, GZ (corresponding author), Guangdong Univ Technol, Sch Automat, Guangzhou, Peoples R China.; Zhou, GZ (corresponding author), Guangdong Univ Technol, Sch Automat, Guangdong HongKong Macao Joint Lab Smart Discrete, Guangzhou 510006, Peoples R China.
EM ycqiu@gdut.edu.cn; gx.zhou@gdut.edu.cn; yzhangsu@stanford.edu
RI Zhang, Yu/J-1796-2015; Qiu, Yichun/HJA-3587-2022; Zhou,
   Guoxu/D-2040-2014
OI Zhang, Yu/0000-0003-4087-6544; Zhou, Guoxu/0000-0003-1187-577X; Qiu,
   Yichun/0000-0002-5569-6768
FU National Natural Science Foundation of China (NSFC) [61673124, 61973090,
   61727810]
FX This work was partially supported by the National Natural Science
   Foundation of China (NSFC) Grant 61673124, Grant 61973090, and Grant
   61727810.
CR Andersson CA, 2000, CHEMOMETR INTELL LAB, V52, P1, DOI 10.1016/S0169-7439(00)00071-X
   [Anonymous], LNCS, DOI DOI 10.1007/3-540-47969-4_30
   Bader B.W., 2012, Matlab tensor toolbox version 2.5
   Baraniuk RG, 2010, P IEEE, V98, P959, DOI 10.1109/JPROC.2009.2038076
   Bro R, 1998, CHEMOMETR INTELL LAB, V42, P105, DOI 10.1016/S0169-7439(98)00011-2
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Caiafa CF, 2010, LINEAR ALGEBRA APPL, V433, P557, DOI 10.1016/j.laa.2010.03.020
   Cevher V, 2014, IEEE SIGNAL PROC MAG, V31, P32, DOI 10.1109/MSP.2014.2329397
   Cichocki A., 2009, NONNEGATIVE MATRIX T, DOI 10.1002/9780470747278
   Cichocki A, 2009, IEICE T FUND ELECTR, VE92A, P708, DOI 10.1587/transfun.E92.A.708
   Cohen J, 2015, IEEE SIGNAL PROC LET, V22, P862, DOI 10.1109/LSP.2014.2374838
   Comon P, 2014, IEEE SIGNAL PROC MAG, V31, P44, DOI 10.1109/MSP.2014.2298533
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   De Lathauwer L, 2007, IEEE T SIGNAL PROCES, V55, P2965, DOI 10.1109/TSP.2007.893943
   de Silva V, 2008, SIAM J MATRIX ANAL A, V30, P1084, DOI 10.1137/06066518X
   Drineas P, 2007, LINEAR ALGEBRA APPL, V420, P553, DOI 10.1016/j.laa.2006.08.023
   Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110
   Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806
   Kang U., 2012, Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining', KDD'12, P316
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Lim LH, 2009, J CHEMOMETR, V23, P432, DOI 10.1002/cem.1244
   Nesterov Yu. E., 1983, Doklady Akademii Nauk SSSR, V269, P543
   Papalexakis Evangelos E., 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P521, DOI 10.1007/978-3-642-33460-3_39
   Papalexakis EE, 2013, IEEE T SIGNAL PROCES, V61, P493, DOI 10.1109/TSP.2012.2225052
   Phan AH, 2009, LECT NOTES COMPUT SC, V5863, P323, DOI 10.1007/978-3-642-10677-4_36
   Phan AH, 2013, IEEE T SIGNAL PROCES, V61, P4834, DOI 10.1109/TSP.2013.2269903
   Rajwade A, 2013, IEEE T PATTERN ANAL, V35, P849, DOI 10.1109/TPAMI.2012.140
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Sidiropoulos ND, 2000, J CHEMOMETR, V14, P229, DOI 10.1002/1099-128X(200005/06)14:3<229::AID-CEM587>3.0.CO;2-N
   TSOURAKAKIS C. E., 2010, P 2010 SIAM INT C DA, P689
   Vervliet N, 2014, IEEE SIGNAL PROC MAG, V31, P71, DOI 10.1109/MSP.2014.2329429
   Xu X, 2014, CELL BIOSCI, V4, DOI 10.1186/2045-3701-4-24
   Zhang Y, 2019, PATTERN RECOGN, V88, P421, DOI 10.1016/j.patcog.2018.12.001
   Zhang Y, 2019, IEEE T CYBERNETICS, V49, P3322, DOI 10.1109/TCYB.2018.2841847
   Zhang Y, 2016, NEUROCOMPUTING, V198, P148, DOI 10.1016/j.neucom.2015.08.122
   Zhang Y, 2015, J NEUROSCI METH, V244, P8, DOI 10.1016/j.jneumeth.2014.03.012
   Zhang Y, 2013, IEEE T NEUR SYS REH, V21, P887, DOI 10.1109/TNSRE.2013.2279680
   ZHOU G, 2016, IEEE T NEURAL NETWOR
   Zhou GX, 2016, P IEEE, V104, P310, DOI 10.1109/JPROC.2015.2474704
   Zhou GX, 2015, IEEE T IMAGE PROCESS, V24, P4990, DOI 10.1109/TIP.2015.2478396
   Zhou GX, 2014, IEEE SIGNAL PROC MAG, V31, P54, DOI 10.1109/MSP.2014.2298891
   Zhou GX, 2012, IEEE SIGNAL PROC LET, V19, P523, DOI 10.1109/LSP.2012.2205237
   Zhou T., 2018, IEEE T CYBERNETICS
   Zhou T, 2019, IEEE T MED IMAGING, V38, P2411, DOI 10.1109/TMI.2019.2913158
   2014, AC PRESS LIB SIGN, P1
NR 45
TC 8
Z9 11
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22987
EP 23007
DI 10.1007/s11042-020-08711-1
EA APR 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000528160700001
DA 2024-07-18
ER

PT J
AU Hussain, N
   Khan, MA
   Sharif, M
   Khan, SA
   Albesher, AA
   Saba, T
   Armaghan, A
AF Hussain, Nazar
   Khan, Muhammad Attique
   Sharif, Muhammad
   Khan, Sajid Ali
   Albesher, Abdulaziz A.
   Saba, Tanzila
   Armaghan, Ammar
TI A deep neural network and classical features based scheme for objects
   recognition: an application for machine inspection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object classification; Augmentation; Classical features; CNN features;
   Feature selection
ID FEATURE-SELECTION; CLASSIFICATION; FUSION; IMAGES
AB Computer Vision (CV) domain is widely used in the current era of automation and visual surveillance for the detection and classification of different objects in a diverse environment. The automatic machine inspection of different objects in the scenes is based on internal and external parameters like features that provide a huge amount of information related to the nature of an object in the scene. In this work, we propose a new automated method based on classical and deep learning feature selection. The proposed object classification method follows three steps. The data augmentation is performed in the first step to make the balance database. Later, Pyramid HOG (PHOG) and Central Symmetric LBP (CS-LBP) features are serially fused along with deep learning-based extracted features. The deep learning features are extracted from the pre-trained CNN model name Inception V3. In the third step, a new technique name Joint Entropy along with KNN (JEKNN) is employed to select the best features. The best-selected features are finally classified by well-known supervised learning methods and choose the best one based on higher accuracy. The proposed method is evaluated on Caltech101 balanced dataset and achieved maximum accuracy of 90.4% on Ensemble classifier which outperforms as compare to existing techniques.
C1 [Hussain, Nazar; Sharif, Muhammad] COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Islamabad, Pakistan.
   [Khan, Muhammad Attique] HITEC Univ, Dept Comp Sci, Museum Rd, Taxila, Pakistan.
   [Khan, Sajid Ali] Fdn Univ Islamabad, Dept Software Engn, Islamabad, Pakistan.
   [Albesher, Abdulaziz A.] Saudi Elect Univ, Coll Comp & Informat, Riyadh, Saudi Arabia.
   [Saba, Tanzila] Prince Sultan Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Armaghan, Ammar] Jouf Univ, Dept Elect Engn, Coll Engn, Sakaka, Saudi Arabia.
C3 COMSATS University Islamabad (CUI); NITEC University; Quaid I Azam
   University; Saudi Electronic University; Prince Sultan University; Al
   Jouf University
RP Khan, SA (corresponding author), Fdn Univ Islamabad, Dept Software Engn, Islamabad, Pakistan.
EM attique@ciitwah.edu.pk
RI khan, sajid/HGE-2406-2022; Armghan, Ammar/ABA-9560-2021; Khan, Dr.
   Muhammad Attique/AAX-2644-2021; Sharif, Muhammad/ACD-2598-2022; Saba,
   Tanzila/D-4593-2018; Hussain, Nazar/HII-7965-2022; Sharif,
   Muhammad/AAB-8376-2022
OI Armghan, Ammar/0000-0002-9062-7493; Khan, Dr. Muhammad
   Attique/0000-0002-6347-4890; Sharif, Muhammad/0000-0002-7258-8400; Saba,
   Tanzila/0000-0003-3138-3801; , Nazar Hussain/0000-0002-7882-8401
CR [Anonymous], J MED SYSTEMS
   [Anonymous], 2019, International Journal of Data Mining Science
   [Anonymous], AUTOMATIC VEHICLE TR
   [Anonymous], J INFORM SCI
   [Anonymous], IJCAI 2001 WORKSHOP
   [Anonymous], LEARNING DATA MANIPU
   [Anonymous], APPL PHYS B LASERS O
   [Anonymous], 2019, Efficient hybrid nature-inspired binary optimizers for feature selection
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2019, SUSTAINABLE COMPUTIN
   [Anonymous], 2019, INT WORKSH SOFT COMP
   [Anonymous], 2019, ARTIF INTELL REV, DOI DOI 10.1007/s10462-017-9568-0
   [Anonymous], 2019, Multi-level features fusion and selection for human gait recognition: an optimized framework of Bayesian model and binomial distribution
   Arshad H, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12541
   Bilal M, 2019, J SIGNAL PROCESS SYS, V91, P117, DOI 10.1007/s11265-018-1374-7
   Cao H, 2020, LECT NOTES COMPUT SC, V11962, P327, DOI 10.1007/978-3-030-37734-2_27
   Chaudhuri DR, 2020, ADV INTELL SYST, V1048, P573, DOI 10.1007/978-981-15-0035-0_47
   Cubuk ED, 2019, arXiv:1909.13719
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Ghodrati H, 2019, NEURAL PROCESS LETT, V49, P797, DOI 10.1007/s11063-018-9858-9
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kaur B, 2019, EXPERT SYST APPL, V124, P119, DOI 10.1016/j.eswa.2019.01.014
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P77, DOI 10.1016/j.patrec.2019.11.014
   Khan MA, 2020, PATTERN RECOGN LETT, V131, P193, DOI 10.1016/j.patrec.2019.12.024
   Khan MA, 2018, COMPUT ELECTRON AGR, V155, P220, DOI 10.1016/j.compag.2018.10.013
   Kumar B, 2019, ISPRS J PHOTOGRAMM, V147, P80, DOI 10.1016/j.isprsjprs.2018.11.006
   Liu XL, 2019, WORLD WIDE WEB, V22, P423, DOI 10.1007/s11280-018-0600-3
   Majid A, 2020, MICROSC RES TECHNIQ, V83, P562, DOI 10.1002/jemt.23447
   Mirjalili S, 2019, STUD COMPUT INTELL, V780, P43, DOI 10.1007/978-3-319-93025-1_4
   Najafabadi MM, 2015, Journal of big data, V2, P1, DOI [10.1186/s40537-014-0007-7, DOI 10.1186/S40537-014-0007-7]
   Neumann J, 2005, MACH LEARN, V61, P129, DOI 10.1007/s10994-005-1505-9
   Pan YS, 2018, MULTIMED TOOLS APPL, V77, P24891, DOI 10.1007/s11042-018-5712-3
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Rani R, 2019, MULTIMED TOOLS APPL, V78, P8965, DOI 10.1007/s11042-018-6911-7
   Rashid M, 2019, MULTIMED TOOLS APPL, V78, P15751, DOI 10.1007/s11042-018-7031-0
   Ravikumar S, 2011, EXPERT SYST APPL, V38, P3260, DOI 10.1016/j.eswa.2010.09.012
   Rehman A, 2020, MICROSC RES TECHNIQ, V83, P410, DOI 10.1002/jemt.23429
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sayed GI, 2019, NEURAL COMPUT APPL, V31, P171, DOI 10.1007/s00521-017-2988-6
   Sharif M, 2020, J ORGAN END USER COM, V32, P67, DOI 10.4018/JOEUC.2020040104
   Song J, 2018, MULTIMED TOOLS APPL, V77, P23529, DOI 10.1007/s11042-018-5682-5
   Soucy P, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P647, DOI 10.1109/ICDM.2001.989592
   Srivastava S, 2019, ADV INTELL SYST, V697, P589, DOI 10.1007/978-981-13-1822-1_55
   Sun H, 2011, NEUROCOMPUTING, V74, P797, DOI 10.1016/j.neucom.2010.10.009
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wang XC, 2019, J REAL-TIME IMAGE PR, V16, P5, DOI 10.1007/s11554-017-0712-5
   Wang Y, 2019, APPL SOFT COMPUT, V74, P40, DOI 10.1016/j.asoc.2018.10.006
   Wei GH, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0874-5
   Weibel JB, 2019, IEEE INT CONF ROBOT, P7262, DOI [10.1109/ICRA.2019.8794432, 10.1109/icra.2019.8794432]
   Wu J, 2019, IEEE INT CONF MULTI, P507, DOI 10.1109/ICMEW.2019.00093
   Wu KB, 2019, PATTERN RECOGN, V87, P130, DOI 10.1016/j.patcog.2018.09.013
   Xianbin Cao, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2421, DOI 10.1109/ICIP.2011.6116132
   Xiong F, 2019, PROC SPIE, V11069, DOI 10.1117/12.2524386
   Zhi SF, 2018, COMPUT GRAPH-UK, V71, P199, DOI 10.1016/j.cag.2017.10.007
NR 58
TC 48
Z9 48
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14935
EP 14957
DI 10.1007/s11042-020-08852-3
EA APR 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000523324400001
DA 2024-07-18
ER

PT J
AU Feng, ZQ
   He, QH
   Zhang, JN
   Wang, L
   Zhu, XJ
   Qiu, MG
AF Feng, Zhengquan
   He, Qinghua
   Zhang, Jingna
   Wang, Li
   Zhu, Xinjian
   Qiu, Mingguo
TI A hybrid BCI system based on motor imagery and transient visual evoked
   potential
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transient visual evoked; Brain-computer interface; EEG; Motor
   imagination
ID MENTAL PRACTICE; STROKE; RECOVERY; P300
AB Motion imaging (MI) refers to the psychological realization of motions without movement or muscle activity; the basis of neural rehabilitation as a brain-computer interface (BCI) technique has been extensively studied. The combination of motor imaging and brain-computer interface technology can take advantage of patients' willingness to take the initiative to assist them in rehabilitation. Studies have shown that MI combined with BCI rehabilitation training is better than traditional rehabilitation training. Transient visual evoked potentials and motor imaging constructed a hybrid BCI system. Three healthy subjects were tested. EEG signals were superimposed preprocessing according to visual stimulus superimposed frequency and motor guidance frequency respectively. Transient visual evoked EEG segmentation is used as a control signal of choice, the use of wavelet decomposition helps to extract features, and then use BP neural network recognition for classification and identification. Visual guidance, motion-oriented event-related synchronization, or desynchronization feature signals as rehabilitation exercise control signals, are using time-domain sliding energy analysis to extract features, and then using BP neural network recognition for classification and identification. EEG signals collected in the experiment were superimposed signals of transient visual evoked and motorized EEG. There were 300 transient electroencephalogram (EEG) and 100 segments Imagine EEG segmentation. According to the results of the test, the average recognition rate of visual evoked EEG reached 95.42%; the average recognition rate of motor imaginary EEG was 73.08%, but there was a large individual difference in motor imaging EEG signals except 1 Name of the test rate of 85%, the remaining two subjects were less than 70% recognition rate. There is a large individual difference between motion imaging and signal feature recognition, and it takes a long time to train. Therefore, it is necessary to study further the selection of control signals for rehabilitation training. As the threshold feedback signal, controlling the amplitude feedback of rehabilitation training can promote the motivation of participants' motivation to stimulate and enhance the rehabilitation treatment effect.
C1 [Feng, Zhengquan; Zhang, Jingna; Wang, Li; Qiu, Mingguo] Army Med Univ, Dept Med Image, Coll Biomed Engn, Chongqing 400038, Peoples R China.
   [Feng, Zhengquan; He, Qinghua; Zhu, Xinjian] Army Med Univ, Dept 5, Affiliated Hosp 3, Chongqing 400042, Peoples R China.
   [Feng, Zhengquan; He, Qinghua; Zhu, Xinjian] Army Med Univ, Res Inst Surg, Chongqing 400042, Peoples R China.
C3 Army Medical University; Army Medical University; Army Medical
   University
RP Qiu, MG (corresponding author), Army Med Univ, Dept Med Image, Coll Biomed Engn, Chongqing 400038, Peoples R China.
EM qiumg_2002@126.com
RI zhu, xin/JXN-3188-2024
CR Allison BZ, 2012, J NEUROSCI METH, V209, P299, DOI 10.1016/j.jneumeth.2012.06.022
   Gupta A, 2012, AGING DIS, V3, P414
   Hanakawa T, 2016, NEUROSCI RES, V104, P56, DOI 10.1016/j.neures.2015.11.003
   Herrmann C. S., 2005, EVENT RELATED POTENT, P229
   JANSEN BH, 1995, BIOL CYBERN, V73, P357, DOI 10.1007/BF00199471
   Kho AY, 2014, AUST OCCUP THER J, V61, P38, DOI 10.1111/1440-1630.12084
   Kim T, 2016, OCCUP THER INT, V23, P39, DOI 10.1002/oti.1403
   Lee CS, 2015, INT J E-NAVIG MARIT, V2, P47, DOI 10.1016/j.enavi.2015.06.005
   Li YQ, 2013, IEEE T BIO-MED ENG, V60, P3156, DOI 10.1109/TBME.2013.2270283
   Li YQ, 2010, IEEE T BIO-MED ENG, V57, P2495, DOI 10.1109/TBME.2010.2055564
   Liu KPY, 2009, STROKE, V40, P2222, DOI 10.1161/STROKEAHA.108.540997
   Nilsen DM, 2010, AM J OCCUP THER, V64, P695, DOI 10.5014/ajot.2010.09034
   Page SJ, 2007, STROKE, V38, P1293, DOI 10.1161/01.STR.0000260205.67348.2b
   Page SJ, 2011, CLIN REHABIL, V25, P627, DOI 10.1177/0269215510395793
   Percival DB, 2004, WAVELET METHODS TIME, P95
   Pfurtscheller G, 2006, IEEE T NEUR SYS REH, V14, P205, DOI 10.1109/TNSRE.2006.875528
   Pfurtscheller G, 2010, FRONT NEUROSCI-SWITZ, V4, DOI 10.3389/fnpro.2010.00003
   Schaechter JD, 2004, PROG NEUROBIOL, V73, P61, DOI 10.1016/j.pneurobio.2004.04.001
   Yin EW, 2013, J NEURAL ENG, V10, DOI 10.1088/1741-2560/10/2/026012
   Yuan H, 2014, IEEE T BIO-MED ENG, V61, P1425, DOI 10.1109/TBME.2014.2312397
NR 20
TC 5
Z9 7
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10327
EP 10340
DI 10.1007/s11042-019-7607-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600032
DA 2024-07-18
ER

PT J
AU Ke, JY
   Zhang, ZJ
   Ye, YZ
AF Ke, Jiangyan
   Zhang, Zhijie
   Ye Yingze
TI Image registration optimization mechanism based on reinforcement
   learning and real time denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image characteristics; Image noise; Reinforcement learning; Denoise;
   Real time control
AB Image noise has a serious impact on image transmission, image data collection and image processing. Image noise is mainly denoised by additive noise and multiplicative noise. Firstly, based on the analysis that random noise has a direct impact on image recognition accuracy and registration performance, aiming at capturing and controlling the interaction between reinforcement learning agents and noise environment, an image recognition model based on noise stimulation is proposed, which will help capture and analyze random noise. Then, in order to construct a complete image data set and its linear combination of transfer process, a denoising algorithm based on reinforcement learning is proposed, which uses the sparse vector based on noise obtained by reinforcement learning to represent a given noise signal. Finally, based on image denoising based on reinforcement learning, an image registration optimization mechanism is proposed by maximizing the similarity measure between two images or minimizing the distance measure to find the coordinate correspondence between images. The simulation results show that the proposed algorithm is credible, effective and efficient in terms of consistency of noise analysis, accuracy of correspondence between feature points, registration error and computational utility of the algorithm.
C1 [Ke, Jiangyan] Jimei Univ, Coll Mech & Energy Engn, Xiamen 361021, Fujian, Peoples R China.
   [Zhang, Zhijie] Univ Jinan, Sch Elect Engn, Jinan 250022, Peoples R China.
   [Ye Yingze] Huazhong Agr Univ, Wuhan 430070, Hubei, Peoples R China.
C3 Jimei University; University of Jinan; Huazhong Agricultural University
RP Ke, JY (corresponding author), Jimei Univ, Coll Mech & Energy Engn, Xiamen 361021, Fujian, Peoples R China.
EM top357379@163.com
CR [Anonymous], INT C VLSI DES INT C
   Chen K, 2019, NUMER ALGORITHMS, V80, P305, DOI 10.1007/s11075-018-0486-2
   Cun XD, 2018, SIGNAL PROCESS-IMAGE, V65, P201, DOI 10.1016/j.image.2018.03.021
   El-Gamal FEA, 2016, EGYPT INFORM J, V17, P99, DOI 10.1016/j.eij.2015.09.002
   Gou SP, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/4687376
   Heinrich MP, 2016, MED IMAGE ANAL, V27, P57, DOI 10.1016/j.media.2015.09.005
   Jin Y, 2018, J MED IMAG HEALTH IN, V8, P609, DOI 10.1166/jmihi.2018.2321
   Kilicarslan A, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/2/026013
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Paquin D, 2006, MATH BIOSCI ENG, V3, P389
   Paquin D, 2007, MATH BIOSCI ENG, V4, P711, DOI 10.3934/mbe.2007.4.711
   Sun Y, 2017, J ELECTR COMPUT ENG, V2017, DOI 10.1155/2017/9240407
   Viergever MA, 2016, MED IMAGE ANAL, V33, P140, DOI 10.1016/j.media.2016.06.030
   Wu Y, 2018, IEEE GEOSCI REMOTE S, V15, P242, DOI 10.1109/LGRS.2017.2783879
   Yang X, 2017, NEUROIMAGE, V158, P378, DOI 10.1016/j.neuroimage.2017.07.008
NR 15
TC 0
Z9 0
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9489
EP 9508
DI 10.1007/s11042-019-07914-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600064
DA 2024-07-18
ER

PT J
AU Malarvizhi, N
   Selvarani, P
   Raj, P
AF Malarvizhi, N.
   Selvarani, P.
   Raj, Pethuru
TI Adaptive fuzzy genetic algorithm for multi biometric authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal biometric system; Unimodal biometric system; Fuzzy system;
   Genetic algorithm; Adaptive fuzzy genetic algorithm (AFGA); Fingerprint
   recognition; Iris recognition
AB Biometric Authentication (BA) has turn out to be presently as key problem in privacy and security. Multimodal biometric system specializes in enhancing verification overall performance of the users for authentication. On this direction, biometrics which is the computer-based validation of an individuals' identification is turning into increasingly more vital, particularly for high security systems. The spirit of biometrics is the size of character's behavioral or physiological characteristics; it allows authentication of someone's identity. Biometric-based totally authentication is likewise turning into increasingly more essential in computer based applications because the quantity of touchy records saved in such structures is growing. The latest needs of biometric systems are robustness, high reputation quotes, capability to handle imprecision, uncertainties of non-statistical kind and magnanimous flexibility. Its miles precisely right here that, the role of soft computing techniques involves vital play. The primary aim of this write-up is to offer a practical view on applications of soft computing strategies in biometrics and to analyze its impact. It is found that soft computing has already made inroads in phrases of man or woman techniques or in combination. This paper additionally proposes as hybrid soft computing based optimization device named "Adaptive Fuzzy Genetic Algorithm (AFGA)" which is adaptable to all of the unimodal and multimodal biometric authentication system. The results acquired by means of this device insure high standard of verification via multi-modal biometrics fusion by means of powerful functionality of fuzzy logic. Experimental investigation under various biometric data conditions exhibits notable effects over current strategies.
C1 [Malarvizhi, N.; Selvarani, P.] Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci &, Dept Comp Sci & Engn, Chennai 600062, Tamil Nadu, India.
   [Raj, Pethuru] Reliance Jio Infocomm Ltd RJIL, Site Reliabil Engn SRE Div, SARGOD Imperial, 23 Residency Rd, Bangalore 560025, Karnataka, India.
C3 Vel Tech Rangarajan Dr Sagunthala R&D Institute of Science & Technology
RP Malarvizhi, N (corresponding author), Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci &, Dept Comp Sci & Engn, Chennai 600062, Tamil Nadu, India.
EM drnmalarvizhi@gmail.com; selvarani.meena@grnail.eom;
   peterindia@gmail.com
RI Nandagopal, Malarvizhi/AAP-7697-2021
OI Nandagopal, Malarvizhi/0000-0001-7916-6668
CR Adeoye OS, 2010, INT J COMPUT APPL 09, V9, P0975
   Alonso-Fernandez F, 2009, FINGERPRINT RECOGNIT, P51
   Alsaade F, 2009, SIGNAL IMAGE PROCESS
   Alsaade F, 2010, SCI J KING FAISAL U, V11, P1431
   Biel L, 2001, IEEE T INSTRUM MEAS, V50, P808, DOI 10.1109/19.930458
   Chan C, 2003, IEEE T CIRCUITS SYST
   ChenXing Zhao, 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P150, DOI 10.1109/BTAS.2012.6374570
   Cui F., 2011, Journal of Computational Information Systems, V7, P5723
   Dunn S, 2002, LECT NOTES ARTIF INT, V2358, P220
   Feng JJ, 2011, IEEE T PATTERN ANAL, V33, P209, DOI 10.1109/TPAMI.2010.77
   Iancu I, 2010, INT J COMPUT COMMUN, V5, P525, DOI 10.15837/ijccc.2010.4.2510
   Jain K, 2012, 2 GENERATION BIOMETR, V11, P49
   Lau CW, 2004, P 8 ICSLP
   Liu HB, 2005, 5TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, PROCEEDINGS, P332
   Malcangi M, 2011, NEURAL COMPUT APPL
   Monaco JV, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS)
   Singh YN, 2012, PATTERN RECOGN LETT, V33, P1932, DOI 10.1016/j.patrec.2012.03.010
   Song YH, 1997, IEE P-GENER TRANSM D, V144, P377, DOI 10.1049/ip-gtd:19971100
   Tsai C-H., 2012, Society for Neuroscience Abstract Viewer and Itinerary Planner, V42
   Wang YH, 2003, LECT NOTES COMPUT SC, V2688, P805
NR 20
TC 18
Z9 18
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9131
EP 9144
DI 10.1007/s11042-019-7436-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600041
DA 2024-07-18
ER

PT J
AU Mukherjee, S
   Anvitha, L
   Lahari, TM
AF Mukherjee, Snehasis
   Anvitha, Leburu
   Lahari, T. Mohana
TI Human activity recognition in RGB-D videos by dynamic images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RGB-D; Activity recognition; Dynamic image; Resnet; Gestalt based
   perception
ID SUPPORT
AB Human Activity Recognition in RGB-D videos has been an active research topic during the last decade. However, only a few efforts have been made, for recognizing human activity in RGB-D videos where several performers are performing simultaneously. In this paper we introduce such a challenging dataset with several performers performing the activities simultaniously. We present a novel method for recognizing human activities performed simultaniously in the same videos. The proposed method aims in capturing the motion information of the whole video by producing a dynamic image corresponding to the input video. We use two parallel ResNet-101 architectures to produce the dynamic images for the RGB video and depth video separately. The dynamic images contain only the motion information of the whole frame, which is the main cue for analyzing the motion of the performer during action. Hence, dynamic images help recognizing human action by concentrating only on the motion information appeared on the frame. We send the two dynamic images through a fully connected layer for classification of activity. The proposed dynamic image reduces the complexity of the recognition process by extracting a sparse matrix from a video, while preserving the motion information required for activity recognition, and produces comparable results with respect to the state-of-the-art.
C1 [Mukherjee, Snehasis] Indian Inst Informat Technol SriCity, Comp Vis Grp, Chittoor, India.
   [Anvitha, Leburu; Lahari, T. Mohana] Indian Inst Informat Technol SriCity, Chittoor, India.
RP Mukherjee, S (corresponding author), Indian Inst Informat Technol SriCity, Comp Vis Grp, Chittoor, India.
EM snehasis.mukherjee@iiits.in; anvitha.l14@iiits.in; mohana.t14@iiits.in
RI Mukherjee, Snehasis/Q-1000-2019
OI Mukherjee, Snehasis/0000-0002-2196-8980
FU Science and Engineering Research Board (SERB), the Government of India
   [ECR/2016/00652]; NVIDIA GPU grant team
FX The authors wish to acknowledge the financial support provided by the
   Science and Engineering Research Board (SERB), the Government of India,
   through the project grant numbered ECR/2016/00652. The authors wish to
   acknowledge the NVIDIA GPU grant team for providing graphics card to
   perform the necessary experiments for this work.
CR AGHBOLAGHI MA, 2017, ICCV WORKSH
   Akula A, 2018, COGN SYST RES, V50, P146, DOI 10.1016/j.cogsys.2018.04.002
   [Anonymous], ICIAR
   [Anonymous], 2015, CVPR
   [Anonymous], ECCV
   Asadi-Aghbolaghi M, 2018, MULTIMED TOOLS APPL, V77, P14115, DOI 10.1007/s11042-017-5017-y
   BAEK S, 2017, KINEMATIC LAYOUT AWA
   Bilen H, 2018, IEEE T PATTERN ANAL, V40, P2799, DOI 10.1109/TPAMI.2017.2769085
   Chen BC, 2012, IEEE GLOBE WORK, P13, DOI 10.1109/GLOCOMW.2012.6477536
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4651, DOI 10.1007/s11042-016-3284-7
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4405, DOI 10.1007/s11042-015-3177-1
   Fernando B, 2017, IEEE T PATTERN ANAL, V39, P773, DOI 10.1109/TPAMI.2016.2558148
   Gonzalez-Sanchez T, 2011, ELECTRON LETT, V47, P697, DOI 10.1049/el.2011.0967
   Guindel C, 2019, ROBOT AUTON SYST, V112, P109, DOI 10.1016/j.robot.2018.11.010
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu JF, 2019, IEEE T PATTERN ANAL, V41, P2568, DOI 10.1109/TPAMI.2018.2863279
   Ji Yanli, 2019, ARXIV190410681, P2
   Jie Chen, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1524, DOI 10.1109/ICCVW.2011.6130431
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Mukherjee S, 2013, MULTIMED TOOLS APPL, V62, P847, DOI 10.1007/s11042-011-0882-2
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Spinello L, 2011, IEEE INT C INT ROBOT, P3838, DOI 10.1109/IROS.2011.6048835
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang PC, 2018, AAAI CONF ARTIF INTE, P7404
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang PC, 2017, IEEE INT CONF COMP V, P1005, DOI 10.1109/ICCVW.2017.123
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Wilson G, 2019, COGN SYST RES, V54, P258, DOI 10.1016/j.cogsys.2018.10.032
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   YANG X, 2012, ACM MULTIMEDIA, P1057
   Zhang H., 2018, ARXIV181109908
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
   Ziaeetabar F, 2018, ROBOT AUTON SYST, V110, P173, DOI 10.1016/j.robot.2018.10.005
NR 36
TC 10
Z9 10
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19787
EP 19801
DI 10.1007/s11042-020-08747-3
EA MAR 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000522592200004
DA 2024-07-18
ER

PT J
AU Chakraborty, S
   Jalal, AS
AF Chakraborty, Soumendu
   Jalal, Anand Singh
TI A novel local binary pattern based blind feature image steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LBP; LSB; Steganography; Feature based steganography
ID PIXEL-VALUE; ALGORITHM
AB Steganography methods in general terms tend to embed more and more secret bits in the cover images. Most of these methods are designed to embed secret information in such a way that the change in the visual quality of the resulting stego image is not detectable. There exists some methods which preserve the global structure of the cover after embedding. However, the embedding capacity of these methods is very less. In this paper a novel feature based blind image steganography technique is proposed, which preserves the Local binary pattern (LBP) feature of the cover with comparable embedding rates. Local binary pattern is a well known image descriptor used for image representation. The proposed scheme computes the local binary pattern to hide the bits of the secret image in such a way that the local relationship that exists in the cover is preserved in the resulting stego image. The performance of the proposed steganography method has been tested on several images of different types to show the robustness. State of the art LSB based steganography methods are compared with the proposed method to show the effectiveness of feature based image steganography.
C1 [Chakraborty, Soumendu] Indian Inst Informat Technol, Dept Informat Technol, Lucknow, Uttar Pradesh, India.
   [Jalal, Anand Singh] GLA Univ, Dept Comp Engn & Applicat, Mathura, UP, India.
C3 GLA University
RP Chakraborty, S (corresponding author), Indian Inst Informat Technol, Dept Informat Technol, Lucknow, Uttar Pradesh, India.
EM soum.uit@gmail.com; anandsinghjalal@gmail.com
RI Chakraborty, Soumendu/ABA-2031-2020
OI Chakraborty, Soumendu/0000-0002-8778-8229; Jalal,
   Anand/0000-0002-7469-6608
CR Bai JL, 2017, DISPLAYS, V46, P42, DOI 10.1016/j.displa.2016.12.004
   Baluja S, 2017, ADV NEUR IN, V30
   BISWAS R, 2019, MULTIMED TOOLS APPL, P1
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P7973, DOI 10.1007/s11042-016-3449-4
   Douglas M, 2018, MULTIMED TOOLS APPL, V77, P17333, DOI 10.1007/s11042-017-5308-3
   HEMPSTALK K, 2006, COMP WOM C P HAM NZ
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Huang FJ, 2014, LECT NOTES COMPUT SC, V8389, P19, DOI 10.1007/978-3-662-43886-2_2
   Hwang J, 2006, LECT NOTES COMPUT SC, V4283, P348
   Jiang N, 2016, INT J THEOR PHYS, V55, P107, DOI 10.1007/s10773-015-2640-0
   Jung KH, 2016, IETE TECH REV, V33, P441, DOI 10.1080/02564602.2015.1102099
   Ker AD, 2004, LECT NOTES COMPUT SC, V3200, P97
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Meng RH, 2018, CMC-COMPUT MATER CON, V55, P1, DOI 10.3970/cmc.2018.055.001
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P18985, DOI 10.1007/s11042-017-4420-8
   MURALA S, 2009, IEEE INT C ADV COMP
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pradhan A., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI [10.17485/ijst/2016/v9i37/88557, DOI 10.17485/ijst/2016/v9i37/88557]
   Saeed MA, 2016, IEEE INT CONF INTELL, P1, DOI 10.1109/INTELSE.2016.7475142
   Sahu N, 2017, J VIS COMMUN IMAGE R, V45, P77, DOI 10.1016/j.jvcir.2017.02.013
   Sajjad M, 2017, MULTIMED TOOLS APPL, V76, P3519, DOI 10.1007/s11042-016-3811-6
   SINGHAL A, 2016, 2016 INT C ADV COMP
   Swain G, 2016, MULTIMED TOOLS APPL, V75, P13541, DOI 10.1007/s11042-015-2937-2
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tuncer T, 2019, OPTIK, V185, P972, DOI 10.1016/j.ijleo.2019.04.038
   YEUNG Y, 2019, MULTIMED TOOLS APPL, P1
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 36
TC 8
Z9 8
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19561
EP 19574
DI 10.1007/s11042-020-08828-3
EA MAR 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000521917400003
DA 2024-07-18
ER

PT J
AU Khelaifi, F
   He, HJ
AF Khelaifi, Fares
   He, HongJie
TI Perceptual image hashing based on structural fractal features of image
   coding and ring partition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceptual image hashing; Ring partition; Feature extraction; Fractal
   image coding; Hash generation
ID ROBUST; SECURE; SCHEME
AB Perceptual image hashing finds increasing attention in several multimedia security applications. However, reaching the trade-off balance between the two most important properties of image hashing- robustness and discrimination, still remains the most restive challenge in hashing schemes. In this study, a robust image hashing technique is proposed by incorporating ring partition and fractal image coding. The scheme starts by normalizing the image to help in extracting its local features. Then the concept of ring partition is introduced in order to make our hash rotation invariant by dividing the image into 5 different rings to form a secondary image that possesses the invariant property. Further, image coding is introduced by extracting the structural fractal features to exploit dimensionality reduction and compression, hence, generating a robust hash. To ensure the system's security, encryption is performed on the generated fractal elements before the final hash construction. We conduct series of experiments to evaluate the performance of our scheme. The achieved result shows that our scheme is robust against several content-preserving attacks such as image rotation, JPEG compression, gamma correction, gaussian low pass filtering, image scaling, cropping, brightness adjustment and contrast adjustment. In addition, the receiver operating characteristics is used to show the discriminative capability and robustness of our scheme as compared to other state-of-art schemes in the literature.
C1 [Khelaifi, Fares; He, HongJie] Southwest Jioatong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
RP Khelaifi, F (corresponding author), Southwest Jioatong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
EM k.fares5@hotmail.com
CR Abate A, 2018, LECT NOTES COMPUT SC, V10981, P270, DOI 10.1007/978-3-319-96145-3_15
   Abdullahi SM, 2018, INT J DIGIT CRIME FO, V10, P1, DOI 10.4018/IJDCF.2018100101
   Abdullahi SM, 2018, MULTIMED TOOLS APPL, V77, P20753, DOI 10.1007/s11042-017-5509-9
   Abdullahi SM, 2017, CONCEALING FINGERPRI
   Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   [Anonymous], 2018, OPEN SOURCE DATABASE
   Brzica H, 2018, FLUIDS BARRIERS CNS, V15, DOI 10.1186/s12987-018-0110-9
   Choi YS, 2012, MULTIMED TOOLS APPL, V61, P181, DOI 10.1007/s11042-010-0724-7
   Ghouti L, 2014, INT CONF ACOUST SPEE
   Govindaraj P, 2015, INTERNATIONAL CONFER
   Guo X, 2007, THE 8TH PACIFIC RIM
   Khelifi F, 2010, IEEE SIGNAL PROC LET, V17, P43, DOI 10.1109/LSP.2009.2032451
   Kozat SS, 2004, IEEE IMAGE PROC, P3443, DOI 10.1109/ICIP.2004.1421855
   Lefebvre F., 2002, Signal Processing Conference, 2002 11th European, P1
   Lei YQ, 2011, SIGNAL PROCESS-IMAGE, V26, P280, DOI 10.1016/j.image.2011.04.007
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Monga V, 2006, IEEE T IMAGE PROCESS, V15, P3452, DOI 10.1109/TIP.2006.881948
   Ou Y, 2009, PROC OF THE IEEE INT
   Qin C, 2018, INFORM SCIENCES, V423, P284, DOI 10.1016/j.ins.2017.09.060
   Qin C, 2018, SIGNAL PROCESS, V142, P194, DOI 10.1016/j.sigpro.2017.07.019
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2016, INFORM SCIENCES, V361, P84, DOI 10.1016/j.ins.2016.04.036
   Qin C, 2013, DIGIT SIGNAL PROCESS, V23, P578, DOI 10.1016/j.dsp.2012.11.002
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   Sun R., 2011, P 2011 INT C COMP SC, P715
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Tang Z., 2012, INT J DIGITAL CONTEN, V3, P39, DOI DOI 10.4156/JDCTA.V0L6.ISSUE23.5
   Tang Z, 2012, LECTURE NOTES ON COM
   Tang Z, 2018, IEEE TRANS ON KNOWLE, V99
   Tang ZJ, 2017, SIGNAL PROCESS, V137, P240, DOI 10.1016/j.sigpro.2017.02.008
   Tang ZJ, 2016, COMPUT SECUR, V62, P133, DOI 10.1016/j.cose.2016.07.006
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Tang ZJ, 2014, OPTIK, V125, P5102, DOI 10.1016/j.ijleo.2014.05.015
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   Tang ZJ, 2011, MULTIMED TOOLS APPL, V52, P325, DOI 10.1007/s11042-009-0437-y
   Tang Zhenjun., 2008, Journal of ubiquitous convergence technology, V2, P18, DOI DOI 10.1109/INF0P.2015.7489395
   USC-SIPI, 2018, IMAGE DATABASE
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Wu D, 2009, SIGNAL PROCESS, V89, P2415, DOI 10.1016/j.sigpro.2009.05.016
   Xiang S, 2007, ACM MULTIMEDIA AND S
   Zhang XP, 2015, MULTIMED TOOLS APPL, V74, P5767, DOI 10.1007/s11042-014-1882-9
NR 41
TC 13
Z9 13
U1 0
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19025
EP 19044
DI 10.1007/s11042-020-08619-w
EA MAR 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000519864800002
DA 2024-07-18
ER

PT J
AU Wang, H
   Liu, XB
   Nie, XS
AF Wang, Hong
   Liu, Xingbo
   Nie, Xiushan
TI Supervised discrete hashing through similarity learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Supervised hashing; Discrete hashing; Similarity learning; Mutual
   relationship
ID ITERATIVE QUANTIZATION; PROCRUSTEAN APPROACH; BINARY-CODES; ALGORITHMS
AB Supervised hashing has achieved better accuracy than unsupervised hashing in many practical applications owing to its use of semantic label information. However, the mutual relationship between semantic labels is always ignored when leveraging label information. In addition, the major challenge in learning hash is of handling the discrete constraints imposed on the hash codes, which typically transform the hash optimization into NP-hard problems. To address these issues, a form of supervised discrete hashing through learning mutual similarities is proposed. Different from the existing supervised hashing methods that learn hash codes from least-squares classification by regressing the hash codes to their corresponding labels, we leverage the mutual relation between different semantic labels to learn more stable hash codes. In addition, the proposed method can simultaneously learn the discrete hash codes for training samples and the projections between the original features and their corresponding hash codes for the out-of-sample cases. Experiments have beeen performed on two public datasets. The experimental results demonstrate the superiority of the proposed method.
C1 [Wang, Hong] Shandong Normal Univ, Sch Journalism & Commun, Jinan 250014, Peoples R China.
   [Liu, Xingbo] Shandong Univ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
   [Nie, Xiushan] Shandong Jianzhu Univ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
C3 Shandong Normal University; Shandong University; Shandong Jianzhu
   University
RP Nie, XS (corresponding author), Shandong Jianzhu Univ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
EM niexiushan@163.com
RI Nie, Xiushan/AAZ-6410-2020
CR [Anonymous], 2014, PROC ACM INT C INFOR
   [Anonymous], 2013, DISSERTATIONS THESES
   [Anonymous], 2016, DEEP CROSS MODAL HAS
   Attouch H, 2013, MATH PROGRAM, V137, P91, DOI 10.1007/s10107-011-0484-9
   Bolte J, 2014, MATH PROGRAM, V146, P459, DOI 10.1007/s10107-013-0701-9
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Dasgupta A., 2011, P 17 ACM SIGKDD INT, P1073
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Gui J, 2018, IEEE T PATTERN ANAL, V40, P490, DOI 10.1109/TPAMI.2017.2678475
   Gui J, 2018, IEEE T NEUR NET LEAR, V29, P608, DOI 10.1109/TNNLS.2016.2636870
   He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Hu ZF, 2016, IEEE T NEUR NET LEAR, V27, P875, DOI 10.1109/TNNLS.2015.2427451
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Ji JQ, 2013, IEEE DATA MINING, P301, DOI 10.1109/ICDM.2013.119
   Jiang QY, 2018, AAAI CONF ARTIF INTE, P3342
   Jiang QY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2248
   Kang WC, 2016, AAAI CONF ARTIF INTE, P1230
   Lin GS, 2015, IEEE T PATTERN ANAL, V37, P2317, DOI 10.1109/TPAMI.2015.2404776
   Lin GS, 2014, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2014.253
   Lin GS, 2013, IEEE I CONF COMP VIS, P2552, DOI 10.1109/ICCV.2013.317
   LIU CH, 2019, ARXIV190503752, P145
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu W., 2011, INTRUSION DETECTION, P1, DOI [DOI 10.1155/2011/267218, 10.1109/ISGT.2011.5759170, DOI 10.1109/ISGT.2011.5759170]
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu XB, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1662, DOI 10.1145/3240508.3240683
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P2352, DOI 10.1109/TIP.2017.2678163
   Matsushita Y, 2009, LECT NOTES COMPUT SC, V5414, P374, DOI 10.1007/978-3-540-92957-4_33
   Nie XS, 2020, IEEE T KNOWL DATA EN, V32, P1951, DOI 10.1109/TKDE.2019.2913383
   Nie XS, 2018, IEEE T INF FOREN SEC, V13, P1509, DOI 10.1109/TIFS.2018.2790953
   Nie XS, 2017, IEEE T MULTIMEDIA, V19, P785, DOI 10.1109/TMM.2016.2629758
   Sánchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504
   Shen FM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1522, DOI 10.1145/3123266.3123345
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Shen FM, 2015, IEEE T IMAGE PROCESS, V24, P1839, DOI 10.1109/TIP.2015.2405340
   Shen FM, 2013, PROC CVPR IEEE, P1562, DOI 10.1109/CVPR.2013.205
   Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103
   Tang J, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2564638
   von Luxburg U, 2010, FOUND TRENDS MACH LE, V2, P235, DOI 10.1561/2200000008
   Wang J, 2013, IEEE I CONF COMP VIS, P3032, DOI 10.1109/ICCV.2013.377
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang QF, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3911
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Wu CX, 2013, IEEE T KNOWL DATA EN, V25, P1380, DOI 10.1109/TKDE.2012.76
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Yan TK, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1271, DOI 10.1145/2983323.2983743
   Yang Y, 2015, IEEE T CYBERNETICS, V45, P1069, DOI 10.1109/TCYB.2014.2344015
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1677, DOI 10.1109/TMM.2014.2323014
   Yu Z, 2016, IEEE T KNOWL DATA EN, V28, P566, DOI 10.1109/TKDE.2015.2485224
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang GF, 2010, PROCEEDINGS OF THE 7TH NATIONAL CONFERENCE ON CHINESE FUNCTIONAL MATERIALS AND APPLICATIONS (2010), VOLS 1-3, P1127
   Zhang PC, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P173, DOI 10.1145/2600428.2609600
   Zhang Q, 2016, IEEE T KNOWL DATA EN, V28, P845, DOI 10.1109/TKDE.2015.2507127
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 59
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16215
EP 16227
DI 10.1007/s11042-020-08799-5
EA MAR 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000562592900003
DA 2024-07-18
ER

PT J
AU Wang, YL
   Yu, L
   Zhang, LZ
   Bai, LY
   Guo, XL
   Hu, JY
   Li, JG
AF Wang, Yinling
   Yu, Lei
   Zhang, Lizhen
   Bai, Liuyang
   Guo, Xiaolei
   Hu, Jingyu
   Li, Jiangong
TI Photoelectric performance analysis of infrared detector based on image
   processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Infrared detection; Performance analysis;
   Photoelectric performance; Image recognition
AB At present, the photoelectric performance of infrared detectors has been effectively improved, but the research on photoelectric performance is still less and there is a lack of stable evaluation methods. In order to improve the efficiency of evaluating the photoelectric performance of infrared detectors this study constructed an effective infrared detector test system and combined the infrared detection principle and image processing technology to improve the algorithm. According to the characteristics of infrared images, the image processing technology used in defect detection is mainly image segmentation technology, which effectively segments the recognition image and clearly displays the feature parts. In addition, this study design test to analyze the effectiveness of the method proposed in this study. The research results show that the proposed algorithm has certain effects and can provide theoretical reference for subsequent related research.
C1 [Wang, Yinling; Yu, Lei; Zhang, Lizhen; Bai, Liuyang; Guo, Xiaolei; Hu, Jingyu; Li, Jiangong] Huanghuai Univ, Ind Innovat & Res & Dev Inst Zhumadian, Zhumadian 463000, Peoples R China.
   [Yu, Lei] COMSATS Univ Islamabad, Dept Comp Sci, Abbottabad 22060, Pakistan.
C3 Huanghuai University; COMSATS University Islamabad (CUI)
RP Yu, L (corresponding author), Huanghuai Univ, Ind Innovat & Res & Dev Inst Zhumadian, Zhumadian 463000, Peoples R China.; Yu, L (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Abbottabad 22060, Pakistan.
EM yulei@huanghuai.edu.cn
RI Wang, Yinling/IUM-3668-2023; Hu, Jingyu/KHU-2823-2024
FU National Natural Science Foundation of China [51801068, 51701189];
   Science and Technology Planning Project in Henan Province [132300410476,
   192102210163, 192102210029, 172102210389]; Key Scientific Research
   projects in Colleges and Universities in Henan Province [19A430019]
FX The study was supported by "National Natural Science Foundation of China
   (Grant No. 51801068, 51701189), the Science and Technology Planning
   Project in Henan Province (Grant No. 132300410476, 192102210163,
   192102210029, 172102210389) and Key Scientific Research projects in
   Colleges and Universities in Henan Province (Grant No. 19A430019)".
CR Anyebe EA, 2017, SCI REP-UK, V7, DOI 10.1038/srep46110
   Biswas SK, 2017, IEEE T IMAGE PROCESS, V26, P4229, DOI 10.1109/TIP.2017.2705426
   Boltar KO, 2018, J COMMUN TECHNOL EL+, V63, P300, DOI 10.1134/S1064226918030026
   Cao XD, 2018, DYES PIGMENTS, V158, P319, DOI 10.1016/j.dyepig.2018.05.052
   Chen K, 2017, J OPT SOC AM A, V34, P2000, DOI 10.1364/JOSAA.34.002000
   Ding JY, 2018, APPL PHYS B-LASERS O, V124, DOI 10.1007/s00340-018-6950-9
   DONG J, 2018, J PHARM BIOMED ANAL, V155, P15
   Geum DM, 2018, OPT EXPRESS, V26, P6249, DOI 10.1364/OE.26.006249
   Guo JX, 2018, INFRARED PHYS TECHN, V89, P115, DOI 10.1016/j.infrared.2018.01.002
   Huang HX, 2017, ACS APPL MATER INTER, V9, P12743, DOI 10.1021/acsami.7b01301
   Kim T, 2017, APPL PHYS LETT, V110, DOI 10.1063/1.4984023
   Li H., 2017, IEEE T FUZZY SYST, VPP, P1, DOI DOI 10.1007/S11263-006-0002-3
   Moon E, 2017, IEEE T ELECTRON DEV, V64, P2432, DOI 10.1109/TED.2017.2681694
   Ooyama Y, 2017, RSC ADV, V7, P13072, DOI 10.1039/c7ra00799j
   Song-Tao C, 2017, ACTA PHYS SIN, V66
   Sun QM, 2018, SAUDI J BIOL SCI, V25, P452, DOI 10.1016/j.sjbs.2017.11.044
   Wang W, 2017, CHINESE J ANAL CHEM, V45, P1137, DOI 10.1016/S1872-2040(17)61030-2
   Yakimov AI, 2017, OPT EXPRESS, V25, P25602, DOI 10.1364/OE.25.025602
   Yin J, 2017, APPL PHYS LETT, V110, DOI 10.1063/1.4984092
   Zhang ZW, 2017, APPL PHYS A-MATER, V123, DOI 10.1007/s00339-017-0835-3
NR 20
TC 1
Z9 1
U1 12
U2 66
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18515
EP 18526
DI 10.1007/s11042-020-08720-0
EA MAR 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000518306100002
DA 2024-07-18
ER

PT J
AU Shan, BW
   Chen, SH
   Fang, Y
AF Shan, Bowei
   Chen, Sihua
   Fang, Yong
TI A parallel sliding-window belief propagation algorithm for<i>Q</i>-ary
   LDPC codes accelerated by GPU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SWBP; LDPC; GPU; DVC
AB In this paper, a parallel Sliding-Window Belief Propagation algorithm to decodeQ-ary Low-Density-Parity-Codes is proposed. This algorithm is accelerated by taking advantage of high parallel features of GPU, and applied to video compression under distributed video coding framework. The experiment results show that our parallel algorithm achieves 2.3x to 30.3x speedup ratio under 256 to 2048 codeword length and 69.21x to 78.31x speedup ratio under 16,384 codeword length than sequential algorithm.
C1 [Shan, Bowei; Chen, Sihua; Fang, Yong] Changan Univ, Sch Informat Engn, Xian 710064, Peoples R China.
C3 Chang'an University
RP Fang, Y (corresponding author), Changan Univ, Sch Informat Engn, Xian 710064, Peoples R China.
EM fy@chd.edu.cn
OI , Yong/0000-0002-3345-8259
CR Barnault L, 2003, 2003 IEEE INFORMATION THEORY WORKSHOP, PROCEEDINGS, P70
   Dai Y, 2016, J SUPERCOMPUT, V72, P2351, DOI 10.1007/s11227-016-1736-5
   Davey MC, 1998, IEEE COMMUN LETT, V2, P165, DOI 10.1109/4234.681360
   Fang Y, 2013, IEEE T COMMUN, V61, P5114, DOI 10.1109/TCOMM.2013.111313.130230
   Fang Y, 2012, IEEE T COMMUN, V60, P3161, DOI 10.1109/TCOMM.2012.080212.110108A
   GALLAGER RG, 1962, IRE T INFORM THEOR, V8, P21, DOI 10.1109/tit.1962.1057683
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   MacKay DJC, 1999, IEEE T INFORM THEORY, V45, P399, DOI 10.1109/18.748992
   MacKay DJC, 1997, ELECTRON LETT, V33, P457, DOI 10.1049/el:19970362
   Ploskas N, 2016, GPU programming in MATLAB
   Shan B, IEEE T WIR COMM PREP
   Shan B, 2019, 5 EAI INT C IOT AS S
   Shan B, INT J PARALLEL PROGR
   Xu Q, 2006, IEEE T IMAGE PROCESS, V15, P3791, DOI 10.1109/TIP.2006.884925
NR 14
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34287
EP 34300
DI 10.1007/s11042-020-08738-4
EA MAR 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000560968200003
DA 2024-07-18
ER

PT J
AU Anusha, R
   Jaidhar, CD
AF Anusha, R.
   Jaidhar, C. D.
TI Human gait recognition based on histogram of oriented gradients and
   Haralick texture descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Feature extraction; Gait recognition; Human identification
ID RECOGNIZING GAITS; FRAMEWORK; FEATURES; IMAGE
AB Gait recognition is an evolving technology in the biometric domain; it aims to recognize people through an analysis of their walking pattern. One of the significant challenges of the appearance-based gait recognition system is to augment its performance by using a distinctive low-dimensional feature vector. Therefore, this study proposes the low-dimensional features that are capable of effectively capturing the spatial, gradient, and texture information in this context. These features are obtained by the computation of histogram of oriented gradients, followed by sum variance Haralick texture descriptor from nine cells of gait gradient magnitude image. Further, the performance of the proposed method is validated on five widely used gait databases. They include CASIA A gait database, CASIA B gait database, OU-ISIR D gait database, CMU MoBo database, and KTH video database. The experimental results demonstrated that the proposed approach could choose significant discriminatory features for individual identification and consequently, outperform certain state-of-the-art methods in terms of recognition performance.
C1 [Anusha, R.; Jaidhar, C. D.] Natl Inst Technol Karnataka, Dept Informat Technol, Surathkal 575025, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Anusha, R (corresponding author), Natl Inst Technol Karnataka, Dept Informat Technol, Surathkal 575025, Karnataka, India.
EM it16fy01.anusha@nitk.edu.in; jaidharcd@nitk.edu.in
CR [Anonymous], 4 UK COMP VIS STUD W
   [Anonymous], TENCON 2005 IEEE REG
   [Anonymous], CASIA GAIT DATABASE
   Arora P, 2015, PROCEDIA COMPUT SCI, V58, P408, DOI 10.1016/j.procs.2015.08.049
   BARALDI A, 1995, IEEE T GEOSCI REMOTE, V33, P293, DOI 10.1109/36.377929
   Bashir K., 2009, BMVC, P1
   Chen X, 2018, IEEE T PATTERN ANAL, V40, P1697, DOI 10.1109/TPAMI.2017.2726061
   Chin-Pan Huang, 2011, Proceedings of the 2011 First International Conference on Instrumentation, Measurement, Computer, Communication and Control (IMCCC 2011), P353, DOI 10.1109/IMCCC.2011.95
   Cunningham P., 2007, MULTIPLE CLASSIFIER, V34, P1, DOI DOI 10.1145/3459665
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Gross J., 2001, Tech. Rep. CMU-RI-TR-01-18, V45, P1
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hofmann M, 2013, IEEE IMAGE PROC, P4171, DOI 10.1109/ICIP.2013.6738859
   Hofmann M, 2012, IEEE IMAGE PROC, P1389, DOI 10.1109/ICIP.2012.6467128
   Hu MD, 2013, IEEE T INF FOREN SEC, V8, P2034, DOI 10.1109/TIFS.2013.2287605
   Kellokumpu V, 2009, LECT NOTES COMPUT SC, V5558, P1000, DOI 10.1007/978-3-642-01793-3_101
   KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129
   Kusakunniran W, 2014, IMAGE VISION COMPUT, V32, P1117, DOI 10.1016/j.imavis.2014.10.004
   Kusakunniran W, 2014, IEEE T INF FOREN SEC, V9, P1416, DOI 10.1109/TIFS.2014.2336379
   Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552
   Kusakunniran W, 2010, PROC CVPR IEEE, P974, DOI 10.1109/CVPR.2010.5540113
   Lee CP, 2014, J VIS COMMUN IMAGE R, V25, P822, DOI 10.1016/j.jvcir.2014.01.012
   Lee CP, 2013, PATTERN RECOGN LETT, V34, P663, DOI 10.1016/j.patrec.2013.01.013
   Lishani AO, 2017, SIGNAL IMAGE VIDEO P, V11, P1123, DOI 10.1007/s11760-017-1066-y
   Liu Z, 2015, NEUROCOMPUTING, V168, P1144, DOI 10.1016/j.neucom.2015.05.008
   Makihara Y., 2012, IPSJ T COMPUT VISION, V4, P53, DOI DOI 10.2197/IPSJTCVA.4.53
   Medikonda J, 2018, IET BIOMETRICS, V7, P269, DOI 10.1049/iet-bmt.2016.0136
   Mogan JN, 2017, 2017 INTERNATIONAL CONFERENCE ON ROBOTICS, AUTOMATION AND SCIENCES (ICORAS)
   Rida I, 2016, SIGNAL IMAGE VIDEO P, V10, P463, DOI 10.1007/s11760-015-0766-4
   Roy A, 2012, SIGNAL PROCESS, V92, P780, DOI 10.1016/j.sigpro.2011.09.022
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Semwal VB, 2015, ROBOT AUTON SYST, V65, P65, DOI 10.1016/j.robot.2014.11.010
   Sharifi M, 2002, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P117, DOI 10.1109/ITCC.2002.1000371
   Sivapalan S, 2013, IEEE COMPUT SOC CONF, P125, DOI 10.1109/CVPRW.2013.26
   Vishwakarma DK, 2016, ROBOT AUTON SYST, V77, P25, DOI 10.1016/j.robot.2015.11.013
   Vishwakarma DK, 2017, IEEE T COGN DEV SYST, V9, P316, DOI 10.1109/TCDS.2016.2577044
   Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260
   Wang L, 2003, IEEE T IMAGE PROCESS, V12, P1120, DOI 10.1109/TIP.2003.815251
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zeng W, 2016, NEUROCOMPUTING, V175, P324, DOI 10.1016/j.neucom.2015.10.065
NR 43
TC 15
Z9 15
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 8213
EP 8234
DI 10.1007/s11042-019-08469-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100061
DA 2024-07-18
ER

PT J
AU Liu, DC
   Yuan, ZH
   Su, QT
AF Liu, Decheng
   Yuan, Zihan
   Su, Qingtang
TI A blind color image watermarking scheme with variable steps based on
   Schur decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color digital watermarking; Schur decomposition; Affine transformation;
   Security
ID ROBUST; DCT; DOMAIN; TRANSFORM; ALGORITHM
AB The widespread application of the Internet makes the protection of image copyright face serious challenges. For resolving this problem, this paper designs a blind color digital image watermarking algorithm which meets the requirements of invisibility, security and robustness. The advantages of the proposed method include the following two points: 1) the proposed method uses Affine transformation with large key space to encrypt the watermark information; 2) Schur decomposition with low complexity is selected and performed on the matrix blocks in different color channels of the host image. In this proposed method, the watermark embedding and blind extraction are completed by quantizing the eigenvalues on the diagonal of the decomposed matrix with different quantization steps. Experimental results show that the proposed method not only has good invisibility, but also has high security and strong robustness.
C1 [Liu, Decheng; Yuan, Zihan; Su, Qingtang] Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
C3 Ludong University
RP Su, QT (corresponding author), Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
EM sdytsyt@163.com
CR Agarwal C, 2013, J VIS COMMUN IMAGE R, V24, P1135, DOI 10.1016/j.jvcir.2013.07.007
   [Anonymous], CVG UGR IM DAT
   [Anonymous], USC SIPI IM DAT
   [Anonymous], COLOUR IMAGE PROCESS
   Chang CS, 2017, IEEE T IMAGE PROCESS, V26, P3921, DOI 10.1109/TIP.2017.2706502
   Chen H, 2013, OPT LASER ENG, V51, P768, DOI 10.1016/j.optlaseng.2013.01.016
   Cruz-Ramos C, 2010, J APPL RES TECHNOL, V8, P323
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Guibin Zhu, 2010, 2010 International Symposium on Information Science and Engineering (ISISE 2010), P184, DOI 10.1109/ISISE.2010.60
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Hsu LY, 2017, J VIS COMMUN IMAGE R, V46, P33, DOI 10.1016/j.jvcir.2017.03.009
   Karybali IG, 2006, IEEE T INF FOREN SEC, V1, P256, DOI 10.1109/TIFS.2006.873652
   Kincaid D., 2009, NUMERICAL ANAL MATH
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Madine F, 2018, SIGNAL PROCESS-IMAGE, V68, P229, DOI 10.1016/j.image.2018.06.015
   Moosazadeh M, 2017, OPTIK, V140, P975, DOI 10.1016/j.ijleo.2017.05.011
   Nguyen TS, 2016, AEU-INT J ELECTRON C, V70, P1055, DOI 10.1016/j.aeue.2016.05.003
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Shang ZW, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P2942, DOI 10.1109/ICYCS.2008.99
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Su QT, 2019, IEEE ACCESS, V7, P4358, DOI 10.1109/ACCESS.2018.2888857
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P24221, DOI 10.1007/s11042-016-4164-x
   Su QT, 2016, IET IMAGE PROCESS, V10, P817, DOI 10.1049/iet-ipr.2016.0048
   Su QT, 2015, SIGNAL IMAGE VIDEO P, V9, P991, DOI 10.1007/s11760-013-0534-2
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2012, OPT COMMUN, V285, P1792, DOI 10.1016/j.optcom.2011.12.065
   Wan WB, 2020, MULTIMED TOOLS APPL, V79, P4907, DOI 10.1007/s11042-018-6860-1
   Wan WB, 2019, IEEE ACCESS, V7, P39826, DOI 10.1109/ACCESS.2019.2906912
   Wan WB, 2020, PATTERN RECOGN LETT, V130, P157, DOI 10.1016/j.patrec.2018.08.009
   Wang H, 2018, CHIN CONTR CONF, P9250, DOI 10.23919/ChiCC.2018.8484184
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Yuan XC, 2018, SIGNAL PROCESS, V149, P103, DOI 10.1016/j.sigpro.2018.03.007
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 37
TC 33
Z9 35
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7491
EP 7513
DI 10.1007/s11042-019-08423-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100028
DA 2024-07-18
ER

PT J
AU Mahmood, M
   Jalal, A
   Kim, K
AF Mahmood, Maria
   Jalal, Ahmad
   Kim, Kibum
TI WHITE STAG model: wise human interaction tracking and estimation (WHITE)
   using spatio-temporal and angular-geometric (STAG) descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Full body silhouettes; Human interaction recognition; Kernel sliding
   perceptron; Spatio-temporal angular-geometric features; Skeleton joints
ID REPRESENTATION; RECOGNITION; VIDEOS
AB To understand human to human dealing accurately, human interaction recognition (HIR) systems require robust feature extraction and selection methods based on vision sensors. In this paper, we have proposed WHITE STAG model to wisely track human interactions using space time methods as well as shape based angular-geometric sequential approaches over full-body silhouettes and skeleton joints, respectively. After feature extraction, feature space is reduced by employing codebook generation and linear discriminant analysis (LDA). Finally, kernel sliding perceptron is used to recognize multiple classes of human interactions. The proposed WHITE STAG model is validated using two publicly available RGB datasets and one self-annotated intensity interactive dataset as novelty. For evaluation, four experiments are performed using leave-one-out and cross validation testing schemes. Our WHITE STAG model and kernel sliding perceptron outperformed the existing well known statistical state-of-the-art methods by achieving a weighted average recognition rate of 87.48% over UT-Interaction, 87.5% over BIT-Interaction and 85.7% over proposed IM-IntensityInteractive7 datasets. The proposed system should be applicable to various multimedia contents and security applications such as surveillance systems, video based learning, medical futurists, service cobots, and interactive gaming.
C1 [Mahmood, Maria; Jalal, Ahmad] Air Univ, E-9, Islamabad, Pakistan.
   [Kim, Kibum] Hanyang Univ, Seoul, South Korea.
C3 Air University Islamabad; Hanyang University
RP Jalal, A (corresponding author), Air Univ, E-9, Islamabad, Pakistan.
EM maria.mehmood@mail.au.edu.pk; ahmadjalal@mail.au.edu.pk;
   kibum@hanyang.ac.kr
RI Kim, Kibum/ABA-0127-2022
OI Kim, Kibum/0000-0003-2590-9600
CR Al-amri S, 2010, J COMPUT, V2, P5
   [Anonymous], 2014, P CVPR C
   Argyriou V, 2012, IEEE COMP SOC C COMP
   Aydin R, 2014, IN C IND ENG ENG MAN, P1, DOI 10.1109/IEEM.2014.7058588
   Azorin-Lopez J, 2016, IEEE IJCNN, P1585, DOI 10.1109/IJCNN.2016.7727387
   Babiker Mohanad., 2017, 2017 IEEE 4 INT C SM, P1, DOI DOI 10.1109/ICSIMA.2017.8312024
   Baldassano C, 2017, CEREB CORTEX, V27, P2276, DOI 10.1093/cercor/bhw077
   Berlin SJ, 2016, INT CARN CONF SECU, P143
   Berlin SJ, 2016, IEEE INT CARN C SEC
   Bi S., 2006, World Congress on Intelligent Control and Automation, V2, P9587
   Buys K, 2014, J VIS COMMUN IMAGE R, V25, P39, DOI 10.1016/j.jvcir.2013.03.011
   Chattopadhyay C, 2016, IET COMPUT VIS, V10, P220, DOI 10.1049/iet-cvi.2015.0189
   Cho NG, 2017, NEUROCOMPUTING, V267, P169, DOI 10.1016/j.neucom.2017.06.009
   Cho S, 2013, PATTERN RECOGN LETT, V34, P1840, DOI 10.1016/j.patrec.2012.10.022
   Deepak P, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P851, DOI 10.1109/IC3I.2014.7019631
   Desai C, 2010, COMP VIS PATT REC WO
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Duc Thanh N, 2010, IMAGE VISION COMPUTI
   Fujii T, 2014, ENG COMPUT SCI
   Gaschler A, 2012, IEEE INT C INT ROBOT, P2128, DOI 10.1109/IROS.2012.6385460
   Heo S, 2013, ASIAPAC SIGN INFO PR
   Jalal A, 2017, PATTERN RECOGNITION
   Jalal A, 2015, DEPTH SILHOUETTES CO
   Jalal A, 2015, INDIVIDUAL DETECTION
   Kim YJ, 2014, INT C PATT RECOG, P3517, DOI 10.1109/ICPR.2014.605
   Kong G, 2016, TOB PREV CESS, V2, DOI 10.18332/tpc/67967
   Kong YR, 2014, IET COMPUT VIS, V4
   Kong Y, 2012, LECT NOTES COMPUT SC, V7572, P300, DOI 10.1007/978-3-642-33718-5_22
   Kong Y, 2014, IEEE T PATTERN ANAL, V36, P1775, DOI 10.1109/TPAMI.2014.2303090
   Kong Y, 2014, IET COMPUT VIS, V8, P277, DOI 10.1049/iet-cvi.2013.0042
   Lee K, 2010, INT CONF COMP SCI, P18, DOI 10.1109/ICCSIT.2010.5564984
   Li HC, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2555, DOI 10.1145/2702123.2702178
   Li J, 2017, IET COMPUT VIS, V11, P7
   Li M., 2018, MULTIMED TOOLS APPL, P1
   Li N, 2014, PATTERN RECOGNITION
   Li NJ, 2014, INT C PATT RECOG, P2513, DOI 10.1109/ICPR.2014.434
   Liu BL, 2018, NEUROCOMPUTING, V318, P287, DOI 10.1016/j.neucom.2018.08.066
   Liu CD, 2010, IEEE T INF TECHNOL B, V14, P1236, DOI 10.1109/TITB.2010.2052061
   Liu YN, 2018, 2018 WRC SYMPOSIUM ON ADVANCED ROBOTICS AND AUTOMATION (WRC SARA), P1, DOI 10.1109/WRC-SARA.2018.8584214
   Magar A, 2015, INT J SCI RES PUBL, V5, P1
   Marcolin F, 2017, MULTIMED TOOLS APPL, V76, P13805, DOI 10.1007/s11042-016-3741-3
   Nguyen N, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P40, DOI 10.1109/ISM.2014.61
   Nikzad S, 7 INT S TEL
   Nikzad S, 2014, 2014 7TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P502, DOI 10.1109/ISTEL.2014.7000755
   Park S, 2000, RECOGNITION HUMAN IN
   Peng YN, 2017, CHIN AUTOM CONGR, P7384, DOI 10.1109/CAC.2017.8244112
   Rauber T, 2011, 24 SIBGRAPI C GRAPH
   Rodriguez C, 2018, COMP VIS WORKSH
   Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361
   Schreiber D, 2013, IEEE COMPUT SOC CONF, P614, DOI 10.1109/CVPRW.2013.93
   Shen L, 2018, P WACV
   Solar J, 2010, LECT NOTES COMPUTER
   Su Y, 2018, MULTIMED TOOLS APPL, P767
   Subetha T, 2016, INT C CIRC POW COMP
   Sun B, 2018, MULTIMED TOOLS APPL, P1
   Thanh ND, 2009, IEEE IMAGE PROC, P2549, DOI 10.1109/ICIP.2009.5413925
   Uddin MdZ, 2018, MULTIMED TOOLS APPL, P13585
   Vezzetti E, 2013, COMPUT IND, V64, P1326, DOI 10.1016/j.compind.2013.04.006
   Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387
   Wu J, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY WORKSHOPS: CIT WORKSHOPS 2008, PROCEEDINGS, P439, DOI 10.1109/CIT.2008.Workshops.24
   Xing D, 2015, COMP VIS WORKSH
   Xu R, 2010, INT CONF ACOUST SPEE, P3566, DOI 10.1109/ICASSP.2010.5495930
   Yin YF, 2013, IEEE INT C SEMANT CO, P64, DOI 10.1109/ICSC.2013.20
   Yu Kong, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P1, DOI 10.1109/ICME.2012.67
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
   Zhan S-Z, 2014, MACHINE LEARNING CYB
   Zhan SZ, 2014, INT CONF MACH LEARN, P862, DOI 10.1109/ICMLC.2014.7009722
   Zheqi Lu, 2011, 2011 International Conference on Multimedia Technology, P3547
NR 68
TC 61
Z9 61
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 6919
EP 6950
DI 10.1007/s11042-019-08527-8
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100001
DA 2024-07-18
ER

PT J
AU Caro, K
   Martínez-García, AI
   Kurniawan, S
AF Caro, Karina
   Martinez-Garcia, Ana I.
   Kurniawan, Sri
TI A performance comparison between exergames designed for individuals with
   autism spectrum disorder and commercially-available exergames
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autism spectrum disorders; ASD; Exergames; Kinect-based games
ID DEVELOPMENTAL-DISABILITIES; PHYSICAL-ACTIVITY; CHILDREN; COORDINATION;
   PREVALENCE; ATTENTION; FITNESS; ADULTS; WII
AB Individuals with Autism Spectrum Disorder (ASD) often have visual-motor coordination problems, which may affect their independence. Exergames, videogames that involve physical exertion, had been proven to support visual-motor coordination of individuals with ASD, as they can offer an interactive technological experience to engage them in different motor tasks. Several works show how exergames support individuals with ASD to practice visual-motor coordination exercises. Most of these works present exergames explicitly designed for individuals with ASD. However, works that compare exergames designed for ASD and commercially-available exergames are scarce. In this paper, we compared two exergames to support the visual-motor coordination of individuals with high-functioning ASD, the first one designed for individuals with ASD and the second one designed for neurorehabilitation. We found that both exergames sustained attention, elicited positive emotional expressions, and motivated participants to perform independent visual-motor coordination exercises (without physical assistance) at the same level. However, there was a difference in the aimed limb movements that participants performed (limb movements aimed at a visual target) with the exergame designed for ASD. Also, participants showed a better game and fun experience with the exergame designed for ASD than the other exergame. We close with a set of considerations for using commercially-available exergames for supporting the visual-motor coordination of individuals with ASD.
C1 [Caro, Karina] UABC, Mexico 1 S-N,Carlos Pacheco 7, Ensenada 22890, Baja California, Mexico.
   [Martinez-Garcia, Ana I.] CICESE, Carretera Tijuana Ensenada 3918, Ensenada 22860, Baja California, Mexico.
   [Kurniawan, Sri] Univ Calif Santa Cruz, Santa Cruz UCSC, 1156 High St, Santa Cruz, CA 95064 USA.
C3 Universidad Autonoma de Baja California; CICESE - Centro de
   Investigacion Cientifica y de Educacion Superior de Ensenada; University
   of California System; University of California Santa Cruz
RP Caro, K (corresponding author), UABC, Mexico 1 S-N,Carlos Pacheco 7, Ensenada 22890, Baja California, Mexico.
EM karina.caro.co@gmail.com; martinea@cicese.mx; skurnia@ucsc.edu
OI Caro, Karina/0000-0003-2868-9885; Jomhari, Nazean/0000-0002-1609-5353
CR Anderson-Hanley C, 2011, PSYCHOL RES BEHAV MA, V4, P129, DOI 10.2147/PRBM.S24016
   [Anonymous], EVALUATION EXERTION
   [Anonymous], J BIOENG BIOMED SCI, DOI DOI 10.4172/2155-9538.S1-002
   [Anonymous], Environmental Psychology & Nonverbal Behavior
   [Anonymous], EUROPEAN J PHYS REHA
   [Anonymous], 2013, DIAGNOSTIC STAT MANU
   [Anonymous], COMPUTERS HUMAN BEHA
   [Anonymous], J MED ENG
   [Anonymous], 1997, OBSERVING INTERACTIO
   Baio J, 2018, MMWR SURVEILL SUMM, V67, P1, DOI 10.15585/mmwr.ss6706a1
   Bartoli L., 2013, ACM INT C PROCEEDING, P102, DOI [DOI 10.1145/2485760.2485774, 10.1145/2485760.2485774]
   Bernardini S, 2014, INFORM SCIENCES, V264, P41, DOI 10.1016/j.ins.2013.10.027
   Caro K, 2018, GOODTECHS '18: PROCEEDINGS OF THE 4TH EAI INTERNATIONAL CONFERENCE ON SMART OBJECTS AND TECHNOLOGIES FOR SOCIAL GOOD (GOODTECHS), P183, DOI 10.1145/3284869.3284914
   Caro K, 2017, INT J HUM-COMPUT ST, V105, P12, DOI 10.1016/j.ijhcs.2017.03.005
   Casas Xavier, 2012, Proceedings of the International Conference on Computer Graphics Theory and Applications (GRAPP 2012) and International Conference on Information Visualization Theory and Applications (IVAPP 2012), P440
   CORBETTA M, 1991, J NEUROSCI, V11, P2383
   Deutsch JE, 2008, PHYS THER, V88, P1196, DOI 10.2522/ptj.20080062
   Fang Q, 2019, GAMES HEALTH J, V8, P74, DOI 10.1089/g4h.2018.0032
   Fombonne E, 2016, J AUTISM DEV DISORD, V46, P1669, DOI 10.1007/s10803-016-2696-6
   Fournier KA, 2010, J AUTISM DEV DISORD, V40, P1227, DOI 10.1007/s10803-010-0981-3
   Gallahue DL., 2006, UNDERSTANDING MOTOR, V6th
   Golden D, 2017, GAMES HEALTH J, V6, P97, DOI 10.1089/g4h.2016.0083
   Hernandez H.A., 2012, P 2012 ACM ANN C HUM, P2619, DOI 10.1145
   Hilgenkamp TIM, 2010, RES DEV DISABIL, V31, P1027, DOI 10.1016/j.ridd.2010.04.012
   Hilton CL, 2014, AM J OCCUP THER, V68, P57, DOI 10.5014/ajot.2014.008664
   IJsselsteijn W.A., MARKET LETT, V27, P361
   Johnson CC, 2009, AM J HEALTH PROMOT, V23, P157, DOI 10.4278/ajhp.070930103
   Kashyap M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P61, DOI 10.1109/ICRCICN.2015.7434210
   Kent L, 1999, DEV MED CHILD NEUROL, V41, P153, DOI 10.1017/S001216229900033X
   Kitago Tomoko, 2013, Handb Clin Neurol, V110, P93, DOI 10.1016/B978-0-444-52901-5.00008-3
   Krakauer JW, 2006, CURR OPIN NEUROL, V19, P84, DOI 10.1097/01.wco.0000200544.29915.cc
   Leekam SR, 2007, J AUTISM DEV DISORD, V37, P894, DOI 10.1007/s10803-006-0218-7
   Lyons EJ, 2015, GAMES HEALTH J, V4, P12, DOI 10.1089/g4h.2014.0072
   Macias A., 2017, INT C SMART OBJ TECH, P92
   Ming X, 2007, BRAIN DEV-JPN, V29, P565, DOI 10.1016/j.braindev.2007.03.002
   Mueller Florian, 2016, Foundations and Trends in Human-Computer Interaction, V10, P1, DOI 10.1561/1100000041
   Piek JP, 2004, HUM MOVEMENT SCI, V23, P475, DOI 10.1016/j.humov.2004.08.019
   Read Janet C., 2008, Cognition, Technology & Work, V10, P119, DOI 10.1007/s10111-007-0069-9
   Silva V, 2017, J INTELL DISABIL RES, V61, P755, DOI 10.1111/jir.12384
   Singh KP, 2014, CLIN EPIDEMIOL GLOB, V2, P3, DOI 10.1016/j.cegh.2013.07.007
   Tore P A., 2012, International Research Journal of Applied and Basic Sciences, P1161
   Uzuegbunam N, 2015, IEEE INT CON MULTI
   York A, 1999, J INTELL DISABIL RES, V43, P314, DOI 10.1046/j.1365-2788.1999.00219.x
NR 43
TC 5
Z9 5
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33623
EP 33655
DI 10.1007/s11042-019-08577-y
EA FEB 2020
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000515931100004
DA 2024-07-18
ER

PT J
AU Cheng, KY
   Tahir, R
   Eric, LK
   Li, MZ
AF Cheng, Keyang
   Tahir, Rabia
   Eric, Lubamba Kasangu
   Li, Maozhen
TI An analysis of generative adversarial networks and variants for image
   synthesis on MNIST dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GAN; MNIST dataset; Image synthesis; Generator; Discriminator
AB Generative Adversarial Networks (GANs) are most popular generative frameworks that have achieved compelling performance. They follow an adversarial approach where two deep models generator and discriminator compete with each other. They have been used for many applications especially for image synthesis because of their capability to generate high quality images. In past few years, different variants of GAN have proposed and they produced high quality results for image generation. This paper conducts an analysis of working and architecture of GAN and its popular variants for image generation in detail. In addition, we summarize and compare these models according to different parameters such as architecture, training method, learning type, benefits and performance metrics. Finally, we apply all these methods on a benchmark MNIST dataset, which contains handwritten digits and compare qualitative and quantitative results. The evaluation is based on quality of generated images, classification accuracy, discriminator loss, generator loss and computational time of these models. The aim of this study is to provide a comprehensive information about GAN and its various models in the field of image synthesis. Our main contribution in this work is critical comparison of popular GAN variants for image generation on MNIST dataset. Moreover, this paper gives insights regarding existing limitations and challenges faced by GAN and discusses associated future research work.
C1 [Cheng, Keyang; Tahir, Rabia; Eric, Lubamba Kasangu] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Jiangsu, Peoples R China.
   [Li, Maozhen] Brunel Univ, Dept Elect & Comp Engn, London, England.
C3 Jiangsu University; Brunel University
RP Tahir, R (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Jiangsu, Peoples R China.
EM kycheng@ujs.edu.cn; rabiatahir074@gmail.com;
   5103171302@stmail.ujs.edu.cn; maozhen.Li@brunel.ac.uk
RI Tahir, Rabia/IUN-2517-2023
OI Tahir, Rabia/0000-0001-9625-4125
FU Natural Science Foundation of China [61602215, 61672268]; science
   foundation of Jiangsu province [BK20150527]
FX This research is supported by Natural Science Foundation of China
   (No.61602215, No.61672268), and the science foundation of Jiangsu
   province (No.BK20150527).
CR [Anonymous], 2018, ARXIV180309093
   [Anonymous], 2017, ARXIV170808227
   [Anonymous], GENERATIVE ADVERSARI
   [Anonymous], 2017, ARXIV170104568
   [Anonymous], 2016, NIPS Workshop on Adversarial Training
   ANTIC J, 2018, INTRO DEOLDIFY PROGR
   Arjovsky M., 2017, ARXIV170107875
   BARRATT S, 1973, ARXIV180101973
   Berthelot David, 2017, CoRR
   Bora A., 2018, INT C LEARN REPR
   Borji A, 2019, COMPUT VIS IMAGE UND, V179, P41, DOI 10.1016/j.cviu.2018.10.009
   Cao YJ, 2019, IEEE ACCESS, V7, P14985, DOI 10.1109/ACCESS.2018.2886814
   Chen TH, 2017, IEEE I CONF COMP VIS, P521, DOI 10.1109/ICCV.2017.64
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   CHEONG B, 2018, TECHNICAL REPORT
   Chhetri SR, 2019, DES AUT TEST EUROPE, P770, DOI [10.23919/DATE.2019.8715283, 10.23919/date.2019.8715283]
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Denton Emily, 2015, Advances in Neural Information Processing Systems
   Desjardins G., 2012, ARXIV12105474
   DICKSON B, 2018, WHAT IS GAN AI TECHN
   Donahue J., 2016, ARXIV160509782
   Duarte A, 2019, INT CONF ACOUST SPEE, P8633, DOI 10.1109/icassp.2019.8682970
   Engel J., 2019, P INT C LEARN REPR, P1
   ENGEL J, 2019, GANSYNTH MAKING MUSI
   EVTIMOVA K, 2016, UNDERSTANDING MUTUAL
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hensel M, 2017, ADV NEUR IN, V30
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hitawala Saifuddin, 2018, ARXIV180104271
   Huang H., 2018, ARXIV180304469
   Huang Q, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1593, DOI 10.1109/ICASSP.2018.8461984
   Hukkelås H, 2020, LECT NOTES COMPUT SC, V11844, P565, DOI 10.1007/978-3-030-33720-9_44
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jiang CH, 2019, PROC SPIE, V10948, DOI 10.1117/12.2511818
   Jiang Y, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149440
   Kaneko T, 2017, PROC CVPR IEEE, P7006, DOI 10.1109/CVPR.2017.741
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Kim J., 2019, U GAT IT UNSUPERVISE
   King DB, 2015, ACS SYM SER, V1214, P1
   Kingma D. P., 2014, arXiv
   Li Jiwei, 2017, P 2017 C EMP METH NA, P2157, DOI DOI 10.18653/V1/D17-1230
   Liang XD, 2017, IEEE I CONF COMP VIS, P3382, DOI 10.1109/ICCV.2017.364
   Liu M.-Y., 2016, P ADV NEUR INF PROC, P469
   Lucic M, 2018, ADV NEUR IN, V31
   Makhzani A., 2015, ARXIV
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mariani G., 2018, Bagan: Data augmentation with balancing gan
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Mogren O., 2016, CORR
   NIMAVAT K, 2018, GENERATIVE ADVERSARI
   Odena A, 2017, PR MACH LEARN RES, V70
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Perarnau G., 2016, NIPS WORKSH ADV TRAI
   Radford A., 2015, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salakhutdinov R., 2009, ARTIFICIAL INTELLIGE, V5, P448, DOI DOI 10.1109/CVPRW.2009.5206577
   Salimans T, 2016, ADV NEUR IN, V29
   Samangouei P., 2018, 6 INT C LEARN REPR I
   SANJEEVI M, 2019, GENERATIVE ADVERSARI
   Saqur Raeid, 2018, ARXIV180603968V1CSCV
   Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12
   Smolensky P., 1986, Information processing in dynamical systems: Foundations of harmony theory
   Theis L., 2015, ARXIV151101844
   Turan T, 2018, J IMMUNOTHER CANCER, V6, DOI 10.1186/s40425-018-0355-5
   Vey BL, 2019, J AM COLL RADIOL, V16, P1273, DOI 10.1016/j.jacr.2019.05.040
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   VUPPULURI M, 2017, SURVEY GENERATIVE AD
   Wang KF, 2017, IEEE-CAA J AUTOMATIC, V4, P588, DOI 10.1109/JAS.2017.7510583
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Wu X, 2017, TSINGHUA SCI TECHNOL, V22, P660, DOI 10.23919/TST.2017.8195348
   Yang Li-Chia, 2017, ARXIV170310847
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yu L, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI 10.14722/ndss.2017.23241
   Yu ZK, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0682-x
   Zhao W, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P29, DOI 10.1145/3132847.3132920
NR 77
TC 34
Z9 34
U1 3
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13725
EP 13752
DI 10.1007/s11042-019-08600-2
EA FEB 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000510371400001
DA 2024-07-18
ER

PT J
AU Gao, M
   Han, XH
   Li, J
   Ji, H
   Zhang, HX
   Sun, JD
AF Gao, Min
   Han, Xian-Hua
   Li, Jing
   Ji, Hui
   Zhang, Huaxiang
   Sun, Jiande
TI Image super-resolution based on two-level residual learning CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image super-resolution; Convolutional Neural Networks (CNNs); Two-level
   residual learning CNN; Image caption
ID RESOLUTION
AB In recent years, CNN has been used for single image super-resolution (SR) with its success of in the field of computer vision. However, in the recovery process, there are always some high-frequency components that cant be recovered from low-resolution images to high-resolution ones by using existing CNN-based methods. In this paper, we propose an image super-resolution method based on CNN, which uses a two-level residual learning network to learn residual components, i.e., high-frequency components. We use the Super-Resolution Convolutional Neural Network (SRCNN) as the network structure in each level so that our proposed method can achieve the high-resolution images with high-frequency components that cant be obtained by the existing methods. In addition, we analyze the proposed method with considering three kinds of residual learning networks, which are different in the structure and superimposed layers of the residual learning network. In the experiments, we investigate the performance of the proposed method with various residual learning networks and the effect of image super-resolution to image captioning task.
C1 [Gao, Min; Li, Jing; Ji, Hui; Zhang, Huaxiang; Sun, Jiande] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Han, Xian-Hua] Yamaguchi Univ, Grad Sch Sci & Technol Innovat, Yamaguchi, Japan.
C3 Shandong Normal University; Yamaguchi University
RP Sun, JD (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.; Han, XH (corresponding author), Yamaguchi Univ, Grad Sch Sci & Technol Innovat, Yamaguchi, Japan.
EM hanxhua@yamaguchi-u.ac.jp; jiandesun@hotmail.com
RI Han, Xian-Hua/A-5563-2017; Zhang, Yuchen/GYI-8858-2022
FU Grants-in-Aid for Scientific Research [20K11867] Funding Source: KAKEN
CR Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Ma ZG, 2017, IEEE T MULTIMEDIA, V19, P1558, DOI 10.1109/TMM.2017.2659221
   Mao XJ, 2016, ADV NEUR IN, V29
   Rousseau F, 2010, MED IMAGE ANAL, V14, P594, DOI 10.1016/j.media.2010.04.005
   Shi WZ, 2013, LECT NOTES COMPUT SC, V8151, P9, DOI 10.1007/978-3-642-40760-4_2
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Tai YW, 2010, PROC CVPR IEEE, P2400, DOI 10.1109/CVPR.2010.5539933
   Thornton MW, 2006, INT J REMOTE SENS, V27, P473, DOI 10.1080/01431160500207088
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3003729
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang JC, 2013, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2013.141
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   Zhou F, 2012, IEEE T CONSUM ELECTR, V58, P891, DOI 10.1109/TCE.2012.6311333
   Zhou LW, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P305, DOI 10.1145/3126686.3126717
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 28
TC 5
Z9 6
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4831
EP 4846
DI 10.1007/s11042-018-6751-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500033
DA 2024-07-18
ER

PT J
AU Venkatasalam, K
   Rjendran, P
   Thangavel, M
AF Venkatasalam, K.
   Rjendran, P.
   Thangavel, M.
TI Fuzzy rough subset method with region based mining to improve the
   retrieval and ranking of real time images over larger image database
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image; Feature reduction; Support vector machine; Fuzzy
   neighborhood rough subset method; Hyper spectral images
ID FEATURE-SELECTION METHOD; OPTIMIZATION; ANNOTATION; REDUCTION;
   DIAGNOSIS; SYSTEM; CBIR
AB Region based image mining is considered as an interesting approach that divides the images into several regions, where the features are extracted out from it and the set of features represents the contents of image from database. However, feature dimensionality and space complexity is one of the big issues in Image Retrieval Based on Content (CBIR). In this paper, fuzzy neighborhood rough subset method is used for feature reduction in an image. This helps to reduce the irrelevant features related to given query. The Support Vector Machine (SVM) is further used with fuzzy rough subset method to classify the images related to given query. This extracts well the spectral data characteristics between the query and database images. Performance of proposed fuzzy rough subset method with SVM classifier is tested against conventional methods. The results proves that the proposed method attains better classification of hyper spectral images than the other methods.
C1 [Venkatasalam, K.] Mahendra Engn Coll Autonomous, Dept Comp Sci & Engn, Mallasamudram 637503, Namakkal, India.
   [Rjendran, P.; Thangavel, M.] Knowledge Inst Technol, Kakapalayam, India.
C3 Mahendra Engineering College, Namakkal
RP Venkatasalam, K (corresponding author), Mahendra Engn Coll Autonomous, Dept Comp Sci & Engn, Mallasamudram 637503, Namakkal, India.
EM venkispkm@gmail.com
CR Annrose J, 2018, OPTIK, V157, P1053, DOI 10.1016/j.ijleo.2017.11.179
   [Anonymous], INFORM MED UNLOCKED
   [Anonymous], PERSONAL UBIQUITOUS
   [Anonymous], 2018, J AMBIENT INTELL HUM
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2018, DES AUTOM EMBED SYST
   Arevalillo-Herráez M, 2008, SIGNAL PROCESS-IMAGE, V23, P490, DOI 10.1016/j.image.2008.04.016
   Benloucif S, 2014, P 4 INT S CONC TOOLS, P1
   Bugatti P. H., 2011, 2011 IEEE International Conference on Healthcare Informatics, Imaging and Systems Biology, P323, DOI 10.1109/HISB.2011.27
   Chandra I, 2019, CLUSTER COMPUT, V22, P2517, DOI 10.1007/s10586-018-2329-2
   Chen Y, 2012, INT C INTEL HUM MACH, P175, DOI 10.1109/IHMSC.2012.138
   Choi JY, 2016, EXPERT SYST APPL, V46, P106, DOI 10.1016/j.eswa.2015.10.014
   da Silva SF, 2011, DECIS SUPPORT SYST, V51, P810, DOI 10.1016/j.dss.2011.01.015
   Hilaire X, 2007, INT WORK CONTENT MUL, P267
   Hu QH, 2006, PATTERN RECOGN LETT, V27, P414, DOI 10.1016/j.patrec.2005.09.004
   Islam SM, 2017, APPL SOFT COMPUT, V57, P102, DOI 10.1016/j.asoc.2017.03.036
   Jensen R, 2004, FUZZY SET SYST, V141, P469, DOI 10.1016/S0165-0114(03)00021-6
   Jin C, 2015, SIGNAL PROCESS, V109, P172, DOI 10.1016/j.sigpro.2014.10.031
   Kanisha B., 2018, PERS UBIQUIT COMPUT, V22, P1
   Korn F, 2001, IEEE T KNOWL DATA EN, V13, P96, DOI 10.1109/69.908983
   Kumar PM, 2018, COMPUT NETW, V144, P154, DOI 10.1016/j.comnet.2018.07.001
   Kumar PM, 2018, FUTURE GENER COMP SY, V86, P527, DOI 10.1016/j.future.2018.04.036
   Lin WC, 2010, NEUROCOMPUTING, V73, P1774, DOI 10.1016/j.neucom.2010.01.019
   Lokesh S., 2018, NEURAL COMPUT APPL, V2018, P1
   Mosbah M, 2017, EGYPT INFORM J, V18, P1, DOI 10.1016/j.eij.2016.09.001
   Parthasarathy Panchatchram, 2018, World Review of Science, Technology and Sustainable Development, V14, P52
   Parthasarathy P., 2018, Int. J. Comput. Appl, V42, P222, DOI [10.1080/1206212X.2018.1457471, DOI 10.1080/1206212X.2018.1457471]
   Parthasarathy P, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0058-9
   Rashedi E., 2012, 2012 16th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP), P039, DOI 10.1109/AISP.2012.6313714
   Rashedi E, 2013, KNOWL-BASED SYST, V39, P85, DOI 10.1016/j.knosys.2012.10.011
   Rashno A, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA), P50, DOI 10.1109/PRIA.2017.7983063
   Rishwana SS, 2018, RIV PUB S POL SCI, P1
   Sundarasekar R, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1093-4
   Wang YH, 2017, NEUROCOMPUTING, V236, P14, DOI 10.1016/j.neucom.2016.08.106
   Xu F, 2007, PATTERN RECOGN LETT, V28, P1581, DOI 10.1016/j.patrec.2007.03.016
   Yuan LM, 2014, NEUROCOMPUTING, V129, P504, DOI 10.1016/j.neucom.2013.09.008
   Zhao TZ, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P495, DOI 10.1109/CISP.2008.90
NR 37
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3861
EP 3878
DI 10.1007/s11042-019-7289-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700042
DA 2024-07-18
ER

PT J
AU Batioua, I
   Benouini, R
   Zenkouar, K
AF Batioua, Imad
   Benouini, Rachid
   Zenkouar, Khalid
TI Image recognition using new set of separable three-dimensional discrete
   orthogonal moment invariants
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Separable discrete orthogonal moment; Invariant moment; 3D objects
   recognition
ID FAST COMPUTATION; SCALE INVARIANTS; CLASSIFICATION; NORMALIZATION;
   TRANSLATION; ALGORITHMS
AB In this paper, we propose new sets of 3D separable discrete orthogonal moment invariants, named Racah-Tchebichef-Krawtchouk Moment Invariants (RTKMI), Racah-Krawtchouk-Krawtchouk Moment Invariants (RKKMI) and Racah-Racah-Kr-awtchouk Moment Invariants (RRKMI), for 3D image recognition. The basis functions of these new sets of moment invariants are represented by multivariate discrete orthogonal polynomials. We also present theoretical framework to derive their Rotation, Scaling and Translation (RST) invariants based on the 3D geometric moment invariants. Accordingly, the performance of these proposed separable moment invariants is evaluated under heterogeneous databases and through several appropriate experiments, including 3D image invariance against geometric deformations, local feature extraction, computation time and recognition accuracy, in comparison with the traditional moment invariants. The obtained results showed that our proposed separable moment invariant are very efficient in terms of object recognition, numerical stability and local feature extraction, and can be highly useful for computer vision applications.
C1 [Batioua, Imad; Benouini, Rachid; Zenkouar, Khalid] Univ Sidi Mohamed Ben Abdellah, CED ST, BP 2202 Route Immouzer, Fes 30003, Morocco.
   [Batioua, Imad; Benouini, Rachid; Zenkouar, Khalid] Univ Sidi Mohamed Ben Abdellah, LSIA, BP 2202 Route Immouzer, Fes 30003, Morocco.
   [Batioua, Imad; Benouini, Rachid; Zenkouar, Khalid] Univ Sidi Mohamed Ben Abdellah, Fac Sci & Technol, BP 2202 Route Immouzer, Fes 30003, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez; Sidi Mohamed Ben Abdellah University of Fez
RP Batioua, I (corresponding author), Univ Sidi Mohamed Ben Abdellah, CED ST, BP 2202 Route Immouzer, Fes 30003, Morocco.; Batioua, I (corresponding author), Univ Sidi Mohamed Ben Abdellah, LSIA, BP 2202 Route Immouzer, Fes 30003, Morocco.; Batioua, I (corresponding author), Univ Sidi Mohamed Ben Abdellah, Fac Sci & Technol, BP 2202 Route Immouzer, Fes 30003, Morocco.
EM i.batioua@gmail.com; rachid.benouini@usmba.ac.ma;
   khalid.zenkouar@usmba.ac.ma
RI Benouini, Rachid/ABE-3754-2021
FU Laboratory of Intelligent Systems and Applications
FX The authors would to thank the Laboratory of Intelligent Systems and
   Applications for his support to achieve this work.
CR Abdalbari A, 2016, BIOMED ENG LETT, V6, P224, DOI 10.1007/s13534-016-0225-3
   Abramowitz M., 1964, Handbook of mathematical functions with formulas, graphs, and mathematical tables, V55, DOI DOI 10.1119/1.15378
   ABUMOSTAFA YS, 1985, IEEE T PATTERN ANAL, V7, P46, DOI 10.1109/TPAMI.1985.4767617
   BATIOUA I, 2017, 3D IMAGE ANAL SEPARA
   Batioua I, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0172-7
   Bayraktar B, 2007, PATTERN RECOGN, V40, P659, DOI 10.1016/j.patcog.2006.03.009
   BEALS R, 2016, SPECIAL FUNCTIONS OR
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Bouziane A, 2013, NEUROCOMPUTING, V100, P107, DOI 10.1016/j.neucom.2011.12.042
   Broggio D, 2013, COMPUT METH PROG BIO, V111, P740, DOI 10.1016/j.cmpb.2013.06.005
   Bujack R, 2014, PATTERN RECOGN LETT, V46, P46, DOI 10.1016/j.patrec.2014.05.005
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Cheng HN, 2016, PATTERN RECOGN, V52, P397, DOI 10.1016/j.patcog.2015.09.028
   Chong CW, 2004, PATTERN RECOGN, V37, P119, DOI 10.1016/j.patcog.2003.06.003
   Comtet, 2012, ADV COMBINATORICS AR
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   El Mallahi Mostafa, 2015, WSEAS Transactions on Computers, V14, P513
   Erdelyi A., 1953, HIGHER TRANSCENDENTA, VII
   Fang R, 2008, LECT NOTES COMPUT SC, V5358, P381, DOI 10.1007/978-3-540-89639-5_37
   Flusser J., 2016, 2D and 3D image analysis by moments, P1, DOI 10.1002/9781119039402
   GALVEZ JM, 1993, PATTERN RECOGN, V26, P667, DOI 10.1016/0031-3203(93)90120-L
   Hao Y, 2018, IEEE SIGNAL PROC LET, V25, P1064, DOI 10.1109/LSP.2018.2843296
   Hmimid A, 2015, PATTERN RECOGN, V48, P509, DOI 10.1016/j.patcog.2014.08.020
   Hosny KM, 2012, DIGIT SIGNAL PROCESS, V22, P476, DOI 10.1016/j.dsp.2012.01.002
   Karakasis EG, 2013, PATTERN RECOGN, V46, P1998, DOI 10.1016/j.patcog.2013.01.008
   Koehl P, 2012, IEEE T PATTERN ANAL, V34, P2158, DOI 10.1109/TPAMI.2012.23
   Li E, 2019, IEEE T PATTERN ANAL, V41, P1144, DOI 10.1109/TPAMI.2018.2832060
   Mangin JF, 2004, MED IMAGE ANAL, V8, P187, DOI 10.1016/j.media.2004.06.016
   Mesbah A, 2019, IMAGE VISION COMPUT, V88, P76, DOI 10.1016/j.imavis.2019.04.010
   Mukundan R, 2004, IEEE T IMAGE PROCESS, V13, P1055, DOI 10.1109/TIP.2004.828430
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   NIE L, 2012, MM 12
   NIKIFOROV AF, 1986, LETT MATH PHYS, V11, P27, DOI 10.1007/BF00417461
   Nikiforov Arnold F, 1991, Springer Series in Computational Physics
   Papakostas GA, 2008, APPL MATH COMPUT, V195, P326, DOI 10.1016/j.amc.2007.04.110
   Papakostas GA, 2014, IEEE INT FUZZY SYST, P39, DOI 10.1109/FUZZ-IEEE.2014.6891674
   Papakostas GA, 2009, IEEE T INSTRUM MEAS, V58, P2121, DOI 10.1109/TIM.2009.2015540
   PATIL S, 2005, 9 INT C COMP AID DES
   SADJADI FA, 1980, IEEE T PATTERN ANAL, V2, P127, DOI 10.1109/TPAMI.1980.4766990
   Sayyouri M, 2013, J OPT SOC AM A, V30, P2381, DOI 10.1364/JOSAA.30.002381
   Singh C, 2012, DIGIT SIGNAL PROCESS, V22, P1031, DOI 10.1016/j.dsp.2012.06.009
   Suk T, 2011, LECT NOTES COMPUT SC, V6855, P212, DOI 10.1007/978-3-642-23678-5_24
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Xiao B, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023002
   Xu D, 2008, PATTERN RECOGN, V41, P240, DOI 10.1016/j.patcog.2007.05.001
   Yang B, 2015, PATTERN RECOGN LETT, V54, P18, DOI 10.1016/j.patrec.2014.11.014
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Zhu HQ, 2007, PATTERN RECOGN, V40, P2530, DOI 10.1016/j.patcog.2006.12.003
   Zhu HQ, 2012, PATTERN RECOGN, V45, P1540, DOI 10.1016/j.patcog.2011.10.002
   Zhu HQ, 2007, SIGNAL PROCESS, V87, P687, DOI 10.1016/j.sigpro.2006.07.007
NR 51
TC 5
Z9 5
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13217
EP 13245
DI 10.1007/s11042-019-08083-1
EA JAN 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515608500002
DA 2024-07-18
ER

PT J
AU Geetha, R
   Geetha, S
AF Geetha, R.
   Geetha, S.
TI Embedding electronic patient information in clinical images: an improved
   and efficient reversible data hiding technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Pixel to block transformation; EPR; Watermark
ID HIGH-CAPACITY; WATERMARKING; SCHEME; ENCRYPTION; EXPANSION
AB Reversible Data Hiding (RDH) is one of the popular and highly recommended methods to enhance medical data security or Electronic Patient Record (EPR) privacy. In medical field, care must be taken to maintain the confidentiality of information within the clinical images without causing any degradation to the original quality of the medical image, which corresponds to the diagnosis of a patient. In this presented approach, we introduce a variation to the RDH scheme, which enables higher data capacity to be embedded without causing any significant impact on the quality of medical images. Rhombus Mean Interpolation technique is employed for predicting the interpolated points in the cover image instead of Pixel To Block (PTB) conversion procedure. We used the data related to the patient diagnosis as the secret information to be embedded in medical images, checksum for 2 x 2 non-overlapping block is also embedded for tamper detection and content authentication at the receiver. Validated the quality of the marked image after integration, in terms of PSNR and SSIM metrics. It is observed to have significant improvement in Embedding capacity up to 3 bpp and better image quality compared to the existing schemes.
C1 [Geetha, R.] MVJ Coll Engn, Dept ECE, Bangalore, Karnataka, India.
   [Geetha, S.] VIT Univ Chennai, SENSE, EPT, Chennai, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Geetha, R (corresponding author), MVJ Coll Engn, Dept ECE, Bangalore, Karnataka, India.
EM rgeetha.mariappan@gmail.com; geetha.s@vit.ac.in
RI , Dr.S.Geetha/ABI-7036-2020; R, Geetha/GXH-3505-2022
OI R, Geetha/0000-0002-4451-1844; S, Geetha/0000-0002-6850-9423
CR Abadi M. A. M., 2010, 2010 5th International Symposium on Telecommunications (IST), P840, DOI 10.1109/ISTEL.2010.5734139
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P1073, DOI 10.1109/ACCESS.2017.2777869
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 2007, DIGITAL WATER MARKIN
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Bao F, 2005, IEEE T INF TECHNOL B, V9, P554, DOI 10.1109/TITB.2005.855556
   BARTON JM, 1997, Patent No. 19975646997
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Caldelli R, 2010, EURASIP J INF SECUR, DOI 10.1155/2010/134546
   Cancellaro M, 2011, SIGNAL PROCESS-IMAGE, V26, P1, DOI 10.1016/j.image.2010.11.001
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Coltuc D., 2009, P 2009 INT S SIGNALS, P1
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Dincer AE, 2014, FUSION: DATA INTEGRATION AT ITS BEST, VOL 1, P201
   Fallahpour M, 2007, IEICE ELECTRON EXPR, V4, P205, DOI 10.1587/elex.4.205
   Fridrich J., 2009, INFORM HIDING
   Geetha R, 2018, INT C NEXT GENERATIO, V9, P601
   Geetha S, 2009, COMPUT SECUR, V28, P683, DOI 10.1016/j.cose.2009.03.006
   Goljan M., 2001, 4th Information Hiding Workshop, LNCS, V2137, P27, DOI DOI 10.1007/3-540-45496-9
   Guorong Xuan, 2007, Digital Watermarking. Proceedings 6th International Workshop, IWDW 2007, P264
   HONSINGER CW, 2001, Patent No. 20016278791
   Hwang K, 2010, IEEE INTERNET COMPUT, V14, P14, DOI 10.1109/MIC.2010.86
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Li Li, 2017, CLUSTER COMPUT, V22, P2293
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Maity HK, 2012, PROC TECH, V1, P275, DOI 10.1016/j.protcy.2012.10.033
   Ni Z, 2003, P IEEE INT S CIRC SY, pII
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Peng F, 2011, COMPUT AIDED DESIGN, V43, P1018, DOI 10.1016/j.cad.2011.03.011
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qiu YQ, 2016, IEEE SIGNAL PROC LET, V23, P130, DOI 10.1109/LSP.2015.2504464
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Schmitz Roland, 2012, Communications and Multimedia Security. 13th IFIP TC 6/TC 11 International Conference, CMS 2012. Proceedings, P117, DOI 10.1007/978-3-642-32805-3_10
   Shabir A., 2012, P IEEE SPONS INT C I, P192
   Shi YQ, 2005, LECT NOTES COMPUT SC, V3304, P1
   Shi YQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P33
   Sindhu SSS, 2009, INT J AUTOM COMPUT, V6, P406, DOI 10.1007/s11633-009-0406-y
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   Xuan GR, 2002, ELECTRON LETT, V38, P1646, DOI 10.1049/el:20021131
   Xuan GR, 2010, IEEE INT SYMP CIRC S, P1129, DOI 10.1109/ISCAS.2010.5537323
   YAN X, 2013, SIVIP, V9, P499, DOI DOI 10.1007/s11760-013-0465-y
   Yi S, 2018, SIGNAL PROCESS-IMAGE, V64, P78, DOI 10.1016/j.image.2018.03.001
NR 54
TC 19
Z9 19
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 12869
EP 12890
DI 10.1007/s11042-019-08484-2
EA JAN 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000509165900007
DA 2024-07-18
ER

PT J
AU Garcia-Lucas, D
   Cebrian-Marquez, G
   Diaz-Honrubia, AJ
   Cuenca, P
AF Garcia-Lucas, D.
   Cebrian-Marquez, G.
   Diaz-Honrubia, A. J.
   Cuenca, Pedro
TI Accelerating the CU partitioning decision in an HEVC-JEM transcoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; H; 265; JEM; Transcoding; CTU splitting
ID VIDEO; H.264
AB High Efficiency Video Coding (HEVC) is currently the latest video coding standard available on the market, and it is able to offer up to twice the coding efficiency, in the range of 50% bitrate reduction for the same video quality, of the previous standard, namely H.264/Advanced Video Coding (AVC). HEVC was standardized in 2013 for videos up to a resolution of 2K. However, the popularity of 4K videos is increasing due to the growing use of video-on-demand platforms. Therefore, the ITU-T Video Coding Expert Group (VCEG) and the ISO/IEC Moving Picture Expert Group (MPEG) created the Joint Video Exploration Team (JVET) in 2015 to design the future video coding technology under the Joint Exploration Model (JEM), which its latest version achieves an improvement in coding efficiency of 30%, but at a high cost in terms of computational complexity (10x) with respect to HEVC. The new video standard is expected to be ready in 2020, so it is necessary to find efficient mechanisms to convert current content to the new format adopted in JEM. In this regard, our proposal consists in a probabilistic classifier based on Naive-Bayes that enables the prediction of the splitting decision at the first quadtree level in JEM, reducing the computational complexity of the transcoding process from HEVC to this new standard. The experimental results show a good trade-off between coding efficiency and complexity compared with the anchor transcoder, obtaining a time reduction up to 12.71% at the expense of low coding efficiency penalties in the configurations evaluated.
C1 [Garcia-Lucas, D.; Cuenca, Pedro] Univ Castilla La Mancha, High Performance Networks & Architectures Lab, Albacete, Spain.
   [Cebrian-Marquez, G.] Univ Oviedo, Comp Sci Dept, Oviedo, Spain.
   [Diaz-Honrubia, A. J.] Univ Politecn Madrid, ETS Ingn Informat, Madrid, Spain.
C3 Universidad de Castilla-La Mancha; University of Oviedo; University of
   Sevilla; Universidad Politecnica de Madrid
RP Garcia-Lucas, D (corresponding author), Univ Castilla La Mancha, High Performance Networks & Architectures Lab, Albacete, Spain.
EM David.GarciaLucas@uclm.es; CebrianGabriel@uniovi.es;
   AntonioJesus.Diaz@upm.es; Pedro.Cuenca@uclm.es
RI Cuenca, Pedro/P-7960-2019; Márquez, Gabriel Cebrián/Q-6541-2017
OI Cuenca, Pedro/0000-0002-2791-0165; Márquez, Gabriel
   Cebrián/0000-0002-6510-7517; Garcia Lucas, David/0000-0001-6934-1901;
   Diaz-Honrubia, Antonio Jesus/0000-0001-5464-0714
CR An J., 2016, JVETB0023
   [Anonymous], HIGH EFF VID COD HEV
   [Anonymous], 2017, JVETH1010
   [Anonymous], 2015, COM16C966
   [Anonymous], ADV VID COD GEN AUD
   [Anonymous], 2017, JVETH1002
   [Anonymous], 2008, SUBJ VID QUAL ASS ME
   [Anonymous], JVETB1001
   [Anonymous], 2008, VCEG-AI11
   Bross B, 2019, Document JVET-N1001
   Chen JY, 2017, PHYS REV APPL, V7, DOI 10.1103/PhysRevApplied.7.021001
   Fayyad U, 1996, AI MAG, V17, P37
   FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022
   Fernández-Escribano G, 2008, IEEE T CIRC SYST VID, V18, P172, DOI 10.1109/TCSVT.2008.918115
   Franche JF, 2018, IEEE T CIRC SYST VID, V28, P3452, DOI 10.1109/TCSVT.2017.2754491
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Díaz-Honrubia AJ, 2016, IEEE T CIRC SYST VID, V26, P154, DOI 10.1109/TCSVT.2015.2473299
   Jiang W, 2014, MULTIMED TOOLS APPL, V73, P2179, DOI 10.1007/s11042-013-1675-6
   Networking C. V, 2016, White Paper
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Peixoto E, 2013, IEEE IMAGE PROC, P1972, DOI 10.1109/ICIP.2013.6738406
   Peixoto E, 2014, IEEE T CIRC SYST VID, V24, P99, DOI 10.1109/TCSVT.2013.2273651
   Peixoto E, 2012, IEEE IMAGE PROC, P737, DOI 10.1109/ICIP.2012.6466965
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
NR 25
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2047
EP 2067
DI 10.1007/s11042-019-08326-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000017
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Lv, ZH
   Réhman, SU
   Khan, MSL
   Li, HB
AF Lv, Zhihan
   Rehman, Shafiq Ur
   Khan, M. S. L.
   Li, Haibo
TI An anaglyph 2D-3D stereoscopic video visualization approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anaglyph; 3D video; 2D to 3D conversion; Structure from motion
AB In this paper, we propose a simple anaglyph 3D stereo generation algorithm from 2D video sequence with a monocular camera. In our novel approach, we employ camera pose estimation method to directly generate stereoscopic 3D from 2D video without building depth map explicitly. Our cost-effective method is suitable for arbitrary real-world video sequence and produces smooth results. We use image stitching based on plane correspondence using fundamental matrix. To this end, we also demonstrate that correspondence plane image stitching based on Homography matrix only cannot generate a better result. Furthermore, we utilize the structure-from-motion (with fundamental matrix) based reconstructed camera pose model to accomplish visual anaglyph 3D illusion. The anaglyph result is visualized by a contour based yellow-blue 3D color code. The proposed approach demonstrates a very good performance for most of the video sequences in the user study.
C1 [Lv, Zhihan] Qingdao Univ, Qingdao, Peoples R China.
   [Rehman, Shafiq Ur] Linkoping Univ, Linkoping, Sweden.
   [Khan, M. S. L.] Umea Univ, Umea, Sweden.
   [Li, Haibo] KTH Royal Inst Technol, Stockholm, Sweden.
C3 Qingdao University; Linkoping University; Umea University; Royal
   Institute of Technology
RP Lv, ZH (corresponding author), Qingdao Univ, Qingdao, Peoples R China.
EM lvzhihan@gmail.com
RI Lyu, Zhihan/I-3187-2014; Lv, Zhihan/GLR-6000-2022
OI Lyu, Zhihan/0000-0003-2525-3074; Lv, Zhihan/0000-0003-2525-3074
FU Shandong Provincial Natural Science Foundation [ZR2017QF015]; National
   Natural Science Foundation of China [61902203]
FX This research is supported by Shandong Provincial Natural Science
   Foundation (ZR2017QF015) and National Natural Science Foundation of
   China (No. 61902203).
CR [Anonymous], 2018 IEEE 26 INT S M
   Azzari L, 2011, PROC SPIE, V7863, DOI 10.1117/12.872926
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Do L, 2011, PROC SPIE, V7863, DOI 10.1117/12.873384
   Fradi H, 2011, PROC SPIE, V7863, DOI 10.1117/12.872544
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hartley RI, 1999, INT J COMPUT VISION, V35, P115, DOI 10.1023/A:1008115206617
   Kurz C, 2011, P 5 INT C COMP GRAPH
   Kutulakos KN, 1998, IEEE T VIS COMPUT GR, V4, P1, DOI 10.1109/2945.675647
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   Loop C, 1999, IEEE C COMP VIS PATT, V1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   McKay H.C., 1951, Three-dimensional photography principles of stereoscopy
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Niquin C, 2010, PROC SPIE, V7524, DOI 10.1117/12.838844
   Robertson D.P., 2009, PRACTICAL IMAGE PROC
   Spottiswoode R, 1993, THEORY STEREOSCOPIC
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   Yousefi S, 2011, LECT NOTES COMPUT SC, V6855, P555, DOI 10.1007/978-3-642-23678-5_66
   Zisserman A, 1999, P IEEE INT C MULT CO
NR 20
TC 1
Z9 1
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 825
EP 838
DI 10.1007/s11042-019-08172-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600034
DA 2024-07-18
ER

PT J
AU Hasanzadeh, E
   Yaghoobi, M
AF Hasanzadeh, Ehsan
   Yaghoobi, Mahdi
TI A novel color image encryption algorithm based on substitution box and
   hyper-chaotic system with fractal keys
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Fractal; Hyper-chaotic system; Substitution box;
   Scrambling
ID DNA-SEQUENCE OPERATION; S-BOX; LEVEL PERMUTATION; SCHEME; MAP; CIPHER
AB In this paper, a novel color image encryption scheme based on fractals, substitution box and hyper chaotic dynamic is proposed. In the first step, fractal images are generated by Julia fractal set as keys. Then, the substitution box is constructed by Hilbert fractal, and the original image pixels are replaced with the values of the S-box. In the next step, using the Logistic map, the location of the pixels is scrambled to reduce their correlation. In the following, Chen hyper-chaotic system is used to change the pixels values of fractal images as well as index production to select fractal images. Finally, each pixel of three original image layers with the corresponding pixels in the three selected fractal images and the previous encrypted pixel value are encrypted with XOR operation. Both experimental results and security analyses indicated that the proposed method yields high encryption effect, larger secure key space and is high sensitive to the secret key and the plain image. In addition, the algorithm could resist against diverse typical attacks.
C1 [Hasanzadeh, Ehsan; Yaghoobi, Mahdi] Islamic Azad Univ, Elect Engn Dept, Mashhad Branch, Mashhad, Razavi Khorasan, Iran.
C3 Islamic Azad University
RP Yaghoobi, M (corresponding author), Islamic Azad Univ, Elect Engn Dept, Mashhad Branch, Mashhad, Razavi Khorasan, Iran.
EM Ehssan.hasarmdeh@gmail.com; yaghoobi@mshdiau.ac.ir
OI , mahdi/0000-0003-2263-4859
CR Agarwal Swati, 2017, ACM SIGWEB NEWSLETTE, P1, DOI DOI 10.1145/3110394.3110397
   Amani HR, 2019, MULTIMED TOOLS APPL, V78, P21537, DOI 10.1007/s11042-018-6989-y
   [Anonymous], 2018, ENTROPY
   [Anonymous], 2019, SYMMETRY BASEL, DOI DOI 10.3390/SYM11030351
   Ben Slimane N, 2017, NONLINEAR DYNAM, V88, P1655, DOI 10.1007/s11071-017-3337-0
   Çavusoglu U, 2018, NONLINEAR DYNAM, V92, P1745, DOI 10.1007/s11071-018-4159-4
   Chen Y, 2006, IEEE T CIRCUITS-II, V53, P527, DOI 10.1109/TCSII.2006.875319
   Chung KL, 1998, PATTERN RECOGN LETT, V19, P461, DOI 10.1016/S0167-8655(98)00017-8
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu X, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2827059
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Hermassi H, 2014, MULTIMED TOOLS APPL, V72, P2211, DOI 10.1007/s11042-013-1533-6
   Hussain I, 2014, J VIB CONTROL, V20, P2133, DOI 10.1177/1077546313482960
   Hussain I, 2014, NONLINEAR DYNAM, V76, P1355, DOI 10.1007/s11071-013-1214-z
   Hussain I, 2012, NONLINEAR DYNAM, V70, P181, DOI 10.1007/s11071-012-0440-0
   Hussain I, 2012, OPT COMMUN, V285, P4887, DOI 10.1016/j.optcom.2012.06.011
   Hussain I, 2012, Z NATURFORSCH A, V67, P327, DOI 10.5560/ZNA.2012-0023
   Khan M, 2015, NEURAL COMPUT APPL, V26, P1137, DOI 10.1007/s00521-014-1800-0
   Khan MF, 2019, IEEE ACCESS, V7, P15999, DOI 10.1109/ACCESS.2019.2893176
   Li CQ, 2014, NONLINEAR DYNAM, V78, P1545, DOI 10.1007/s11071-014-1533-8
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Lin KT, 2012, OPT COMMUN, V285, P2335, DOI 10.1016/j.optcom.2012.01.028
   Liu H, 2014, ELSEVIER, V89, P480
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu Wen-tao, 2008, Journal of China Academy of Electronics and Information Technology, V3, P580
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Lock Abraham Jun Jiang, 2010, Proceedings Second International Conference on Computer Research and Development (ICCRD 2010), P213, DOI 10.1109/ICCRD.2010.40
   Masuda N, 2002, IEEE T CIRCUITS-I, V49, P28, DOI 10.1109/81.974872
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Özkaynak F, 2010, PHYS LETT A, V374, P3733, DOI 10.1016/j.physleta.2010.07.019
   Pisarchik AN, 2008, PHYSICA D, V237, P2638, DOI 10.1016/j.physd.2008.03.049
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   Rozouvan V, 2009, OPT LASER ENG, V47, P1, DOI 10.1016/j.optlaseng.2008.09.001
   Solak E, 2011, INFORM SCIENCES, V181, P227, DOI 10.1016/j.ins.2010.09.009
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Suri S, 2018, J AMB INTEL HUM COMP, V10, P2270
   Tian Y, 2016, J SYST ENG ELECTRON, V27, P232, DOI 10.1109/JSEE.2016.00023
   Tong XJ, 2015, ENTROPY-SWITZ, V17, P181, DOI 10.3390/e17010181
   Tong XJ, 2009, SIGNAL PROCESS, V89, P480, DOI 10.1016/j.sigpro.2008.09.011
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   Wang Y, 2009, COMMUN NONLINEAR SCI, V14, P3089, DOI 10.1016/j.cnsns.2008.12.005
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Yang FF, 2019, IEEE ACCESS, V7, P58751, DOI 10.1109/ACCESS.2019.2914722
   Yuan-yuan Sun, 2010, 2010 International Workshop on Chaos-Fractals Theories and Applications (IWCFTA 2010), P170, DOI 10.1109/IWCFTA.2010.70
   Zhang XC, 2019, IEEE ACCESS, V7, P74734, DOI 10.1109/ACCESS.2019.2921309
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhang Y, 2012, NONLINEAR DYNAM, V69, P1091, DOI 10.1007/s11071-012-0329-y
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
   Zhao JF, 2015, NONLINEAR DYNAM, V80, P1721, DOI 10.1007/s11071-015-1911-x
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1902-1
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 57
TC 43
Z9 43
U1 0
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7279
EP 7297
DI 10.1007/s11042-019-08342-1
EA DEC 2019
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000503664200002
DA 2024-07-18
ER

PT J
AU Huang, YH
   Chen, DW
AF Huang, Yun-hu
   Chen, De-wang
TI Image fuzzy enhancement algorithm based on contourlet transform domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Cyclic translation; Contourlet transform; Multi-Scale
   Retinex; Improved fuzzy contrast enhancement
ID ARROW DETECTION
AB In order to solve the problems of low contrast, global darkness and noise amplification in some hyperspectral and remote-sensing images, a new image fuzzy enhancement method based on contourlet transform (CT) domain is proposed. The algorithm includes the following four steps. Firstly, the cyclic translation method is used to suppress the pseudo-Gibbs phenomenon caused by the lack of translation invariance of the CT. Secondly, a nonlinear gain function is designed to enhance and suppress the high-frequency coefficients adaptively. Meanwhile, the multi-scale Retinex with mixed gray function is used to process the low-frequency sub-band coefficients. Then, the inverse translation and linear averaging and the inverse CT are performed on the enhanced coefficients, and finally the improved fuzzy contrast is used to enhance the texture and edge of the image globally. The experimental results show that the proposed method can make the image texture details more prominent, and enhance the overall visual effect of the images. Furthermore, the absolute mean difference and PSNR of images are also greatly improved .
C1 [Huang, Yun-hu; Chen, De-wang] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Fujian, Peoples R China.
   [Huang, Yun-hu; Chen, De-wang] Fuzhou Univ, Key Lab Intelligent Metro Univ Fujian Prov, Fuzhou, Fujian, Peoples R China.
C3 Fuzhou University; Fuzhou University
RP Huang, YH (corresponding author), Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Fujian, Peoples R China.; Huang, YH (corresponding author), Fuzhou Univ, Key Lab Intelligent Metro Univ Fujian Prov, Fuzhou, Fujian, Peoples R China.
EM 941001240@qq.com; dwchen@fzu.edu.cn
FU National Key Research and the Development Plan Project [2018YFB0104403];
   National Natural Science Foundation of China [71671044]
FX The research work was jointly by grants from the National Key Research
   and the Development Plan Project (Grant no.2018YFB0104403) and National
   Natural Science Foundation of China (Grant no.71671044).
CR ABDUKIRIM T, 2016, DYADIC WAVELET THEOR
   Asmare MH, 2015, SIGNAL IMAGE VIDEO P, V9, P1679, DOI 10.1007/s11760-014-0626-7
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Ding H, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P167, DOI 10.1145/2971648.2971699
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Feng P, 2007, PATTERN RECOGN LETT, V28, P516, DOI 10.1016/j.patrec.2006.09.007
   Garg R., 2011, International Journal of Electronics and Comunication Technologies, V2, P107
   Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592
   Hasikin K., 2012, 2012 UKSim 14th International Conference on Computer Modelling and Simulation (UKSim), P371, DOI 10.1109/UKSim.2012.60
   LENKA R, 2016, INT J ADV RES COMPUT, V6, P15
   LI J, 2001, SE U NAT SCI ED, V34, P675
   Li LL, 2018, INT J IMAG SYST TECH, V28, P124, DOI 10.1002/ima.22264
   LI P, 2018, 2018 CHIN CONTR DEC, P2381
   Liu D, 2019, MULTIMED TOOLS APPL, V78, P7381, DOI 10.1007/s11042-018-6503-6
   Ma CB, 2019, MULTIMED TOOLS APPL, V78, P1131, DOI 10.1007/s11042-018-6442-2
   MEN G, 2010, P 9 INT C MACH LEARN, V2, P293
   PAL SK, 1981, IEEE T SYST MAN CYB, V11, P494
   Pu XT, 2014, CONCURR COMP-PRACT E, V26, P742, DOI 10.1002/cpe.3041
   Qian Li, 2014, Information Technology Journal, V13, P153, DOI 10.3923/itj.2014.153.158
   Ruikar DD, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1176-x
   Santosh KC, 2018, INT J MACH LEARN CYB, V9, P993, DOI 10.1007/s13042-016-0623-y
   Santosh KC, 2016, IEEE INTELL SYST, V31, P66, DOI 10.1109/MIS.2016.24
   Spaide RF, 2008, AM J OPHTHALMOL, V146, P496, DOI 10.1016/j.ajo.2008.05.032
   TIAN S, 2010, INF TECHNOL APPL, V1, P197
   Wubuli A, 2014, J MED IMAG HEALTH IN, V4, P814, DOI 10.1166/jmihi.2014.1326
   Yun HJ, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/8598917
NR 26
TC 6
Z9 7
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35017
EP 35032
DI 10.1007/s11042-019-08308-3
EA DEC 2019
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000503664200001
DA 2024-07-18
ER

PT J
AU Li, GY
   Liu, Z
   Zhou, XF
AF Li, Gongyang
   Liu, Zhi
   Zhou, Xiaofei
TI Effective online refinement for video object segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video object segmentation; Motion cue; Online fine-tuning
AB In this paper, we propose a novel framework, which deeply explores themotion cue and the online fine-tuning strategy to tackle the task of semi-supervised video object segmentation. First, in order to filter out the irrelevant background regions in the initial segmentation results, which are generated by an existing semi-supervised segmentation model, a motion based background suppression method is exploited to obtain the purified segmentation results. Second, a set of key frames with high-quality segmentation results are selected based on several metrics of segmentation quality in the purified segmentation results. Finally, the selected key frames are combined with the manually annotated first frame to efficiently retrain the segmentation model online, so as to obtain more accurate segmentation results. Our experimental results on two challenging datasets demonstrate that the proposed framework achieves the state-of-the-art performance.
C1 [Li, Gongyang; Liu, Zhi] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Li, Gongyang; Liu, Zhi] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Zhou, Xiaofei] Hangzhou Dianzi Univ, Inst Informat & Control, Hangzhou 310018, Peoples R China.
C3 Shanghai University; Shanghai University; Hangzhou Dianzi University
RP Liu, Z (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.; Liu, Z (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM ligongyang@shu.edu.cn; liuzhisjtu@163.com; zxforchid@outlook.com
RI Xiaofei, Zhou/AAE-8347-2020; Li, Gongyang/IXD-9078-2023; LIU,
   Zhi/D-4518-2012
OI LIU, Zhi/0000-0002-8428-1131; , Gongyang Li/0000-0001-7324-1196
FU National Natural Science Foundation of China [61771301]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61771301.
CR [Anonymous], 2014, INF SOFTW TECHNOL
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Cheng JC, 2017, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2017.81
   Hu Yuan-Ting, 2018, P EUR C COMP VIS
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Jain SD, 2017, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2017.228
   Jain SD, 2014, LECT NOTES COMPUT SC, V8692, P656, DOI 10.1007/978-3-319-10593-2_43
   Jampani V, 2017, PROC CVPR IEEE, P3154, DOI 10.1109/CVPR.2017.336
   Jang WD, 2017, PROC CVPR IEEE, P7474, DOI 10.1109/CVPR.2017.790
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Koh YJ, 2017, PROC CVPR IEEE, P7417, DOI 10.1109/CVPR.2017.784
   Luo B, 2018, IEEE T CIRC SYST VID, V28, P1580, DOI 10.1109/TCSVT.2017.2682578
   Märki N, 2016, PROC CVPR IEEE, P743, DOI 10.1109/CVPR.2016.87
   Mai L, 2014, LECT NOTES COMPUT SC, V8691, P76, DOI 10.1007/978-3-319-10578-9_6
   Nagaraja NS, 2015, IEEE I CONF COMP VIS, P3235, DOI 10.1109/ICCV.2015.370
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372
   Perazzi F, 2015, IEEE I CONF COMP VIS, P3227, DOI 10.1109/ICCV.2015.369
   Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065
   Tokmakov P, 2017, IEEE I CONF COMP VIS, P4491, DOI 10.1109/ICCV.2017.480
   Tokmakov P, 2017, PROC CVPR IEEE, P531, DOI 10.1109/CVPR.2017.64
   Tsai YH, 2016, PROC CVPR IEEE, P3899, DOI 10.1109/CVPR.2016.423
   Voigtlaender Paul, 2017, ARXIV170609364
   Wang WG, 2017, IEEE I CONF COMP VIS, P1680, DOI 10.1109/ICCV.2017.185
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Yoon JS, 2017, IEEE I CONF COMP VIS, P2186, DOI 10.1109/ICCV.2017.238
   Zhang G, 2015, MULTIMED TOOLS APPL, V74, P9665, DOI 10.1007/s11042-014-2145-5
   Zhou XF, 2017, MULTIMED TOOLS APPL, V76, P23187, DOI 10.1007/s11042-016-4093-8
NR 29
TC 2
Z9 2
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33617
EP 33631
DI 10.1007/s11042-019-08146-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600048
DA 2024-07-18
ER

PT J
AU Luo, QF
   Li, J
   Zhou, YQ
AF Luo, Qifang
   Li, Jie
   Zhou, Yongquan
TI Spotted hyena optimizer with lateral inhibition for image matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spotted hyena optimizer (SHO); Lateral inhibition (LI); Imagematching;
   Bio-inspired algorithm
ID ALGORITHM; EVOLUTIONARY
AB A hybrid spotted hyena optimizer (SHO) based on lateral inhibition (LI) is proposed, it has been applied to solve complication image matching problems. Lateral inhibition mechanism is applied for image pre-process to make intensity gradient in the image contrast enhanced and has the ability to enhance the characters of image, which is able to improve the accuracy of image matching. SHO is inspired from the behavior of social relationship and collaborative of spotted hyenas. This algorithm search for the global optimum mainly through four steps: prey, encircling, attacking prey, and searching prey. In the algorithm, the computation of search location is drastically reduced by incorporating of fitness calculation strategy for solving the real-life optimization problems. The proposed LI-SHO method for image matching mixed together the advantages of SHO and lateral inhibition mechanism. The experiment shows that the proposed algorithm based on lateral inhibition is more effective and feasible in image matching than the other comparing algorithm.
C1 [Luo, Qifang; Li, Jie; Zhou, Yongquan] Guangxi Univ Nationalities, Coll Informat Sci & Engn, Nanning 530006, Peoples R China.
   [Luo, Qifang; Zhou, Yongquan] Key Lab Guangxi High Sch Complex Syst & Computat, Nanning 530006, Peoples R China.
   [Li, Jie] Jinan Univ, Dept Comp Sci, Guangzhou 510632, Peoples R China.
C3 Guangxi Minzu University; Jinan University
RP Zhou, YQ (corresponding author), Guangxi Univ Nationalities, Coll Informat Sci & Engn, Nanning 530006, Peoples R China.; Zhou, YQ (corresponding author), Key Lab Guangxi High Sch Complex Syst & Computat, Nanning 530006, Peoples R China.
EM yongquanzhou@126.com
RI Luo, Qi/ABA-7874-2021; Zhou, Yongquan/AAI-3982-2021; LUO,
   QI/GQH-7209-2022
OI Luo, Qi/0000-0002-1018-8727; Zhou, Yongquan/0000-0001-6945-4922; 
FU National Science Foundation of China [61563008]; Project of Guangxi
   University for Nationalities Science Foundation [2018GXNSFAA138146]
FX This work is supported by National Science Foundation of China under
   Grant No.61563008. Project of Guangxi University for Nationalities
   Science Foundation under Grant No. 2018GXNSFAA138146.
CR AMARI SI, 1977, BIOL CYBERN, V27, P77, DOI 10.1007/BF00337259
   [Anonymous], ADV INTELLIGENT SYST
   [Anonymous], NONPARAMETRIC STAT I
   [Anonymous], 19 KOR JAP JOINT WOR
   [Anonymous], IJICC
   [Anonymous], LECT NOTES COMPUTER
   Brunelli R., 2009, Template matching techniques in computer vision: theory and practice, DOI DOI 10.1002/9780470744055
   Cuevas E, 2013, EXPERT SYST APPL, V40, P6359, DOI 10.1016/j.eswa.2013.05.055
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Dhiman G, 2017, 2017 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND DATA SCIENCE (MLDS 2017), P114, DOI 10.1109/MLDS.2017.5
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Duan HB, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0072035
   Hartline HK, 1938, AM J PHYSIOL, V121, P400, DOI 10.1152/ajplegacy.1938.121.2.400
   Hollander M., 2014, Nonparametric Statistical Methods, Solutions Manual, Vthird
   Huang LZ, 2014, OPTIK, V125, P414, DOI 10.1016/j.ijleo.2013.06.085
   Li B, 2016, OPTIK, V127, P5430, DOI 10.1016/j.ijleo.2016.02.056
   Li B, 2014, SCI WORLD J, DOI 10.1155/2014/906861
   Liu F, 2012, OPTIK, V123, P1955, DOI 10.1016/j.ijleo.2011.09.052
   Malhotra P, 2019, J INTELL SYST, V28, P321, DOI 10.1515/jisys-2017-0127
   Naik MK, 2016, APPL SOFT COMPUT, V38, P661, DOI 10.1016/j.asoc.2015.10.039
   Sun YB, 2018, P I MECH ENG G-J AER, V232, P1571, DOI 10.1177/0954410017696110
   Wang XH, 2013, OPTIK, V124, P5447, DOI 10.1016/j.ijleo.2013.03.124
   Zhang J, 2012, APPL MECH MATER, V201-202, P65, DOI 10.4028/www.scientific.net/AMM.201-202.65
   Zhang S, 2017, OPTIK, V130, P1229, DOI 10.1016/j.ijleo.2016.11.173
   Zhang ZH, 2014, OPTIK, V125, P5757, DOI 10.1016/j.ijleo.2014.07.040
   [朱永松 Zhu Yongsong], 2003, [信号处理, Signal Processing], V19, P531
NR 26
TC 21
Z9 21
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34277
EP 34296
DI 10.1007/s11042-019-08081-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800004
DA 2024-07-18
ER

PT J
AU NagaJyothi, G
   Sridevi, S
AF NagaJyothi, Grande
   Sridevi, Sriadibhatla
TI High speed and low area decision feed-back equalizer with novel memory
   less distributed arithmetic filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed arithmetic; Decision feedback equalizer; Non-linear
   equalizer; FIR; Feed forward (FF) filter; Feed back (FB) filter; Linear
   equalizer; Inter symbol interference (ISI); Quantizer
ID REALIZATION
AB In this paper an efficient implementation of decision feed back equalizer (DFE) is carried out using novel memory less distributed arithmetic (NMLDA) filter. In wireless transmission systems, DFEs are used to mitigate the inter-symbol interference (ISI). The ISI is occurred due to multi-path propagation of the transmitted signal. High data rate systems demand higher order filters in DFE architectures which increase complexity in hardware design. In our proposed NMLDA design, we have used multiplexers and enhanced compressor adders in place of memory unit and conventional adders. The proposed design occupies lower area and gives higher throughput, when compared to MAC based filter and all other memory based DA filter architectures. By using proposed NMLDA based DFE, the ISI errors in transmission signal, will be minimized and the performance of the transmission system will be enhanced. We have synthesized the NMLDA of 32-tap, 16-tap, 8-tap and 4-tap filters and implemented them on FPGA device. The proposed design has nearly 70% less number of logical elements than OBC DA and 50% less than MDA and offers better throughput than the existing designs when implemented on Altera Cyclone III EP3C55F484C6.
C1 [NagaJyothi, Grande; Sridevi, Sriadibhatla] Vellore Inst Technol, Dept Micro & Nanoelect, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP NagaJyothi, G (corresponding author), Vellore Inst Technol, Dept Micro & Nanoelect, Vellore 632014, Tamil Nadu, India.
EM grande.nagajyothi@vit.ac.in; sridevi@vit.ac.in
RI Grande, Naga jyothi/I-6734-2019; sriadibhatla, sridevi/D-7434-2019
OI Grande, Naga jyothi/0000-0002-7732-9598; 
CR Burleson W. P., 1991, Journal of VLSI Signal Processing, V2, P235, DOI 10.1007/BF00925468
   CALLENDER CP, 1994, SIGNAL PROCESS, V40, P325, DOI 10.1016/0165-1684(94)90079-5
   Chae I, 2016, PROC IEEE MICR ELECT, P6, DOI 10.1109/MEMSYS.2016.7421543
   Chen HC, 2005, IEE P-CIRC DEV SYST, V152, P615, DOI 10.1049/ip-cds:20041173
   Croisier A., 1973, U.S. Patent, Patent No. 3777130
   Demissie B, 2016, 2016 19TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1
   DOUILLARD C, 1995, EUR T TELECOMMUN, V6, P507, DOI 10.1002/ett.4460060506
   Ghamkhari SF, 2012, 20 IR C EL ENG, V1, pi
   Hurskainen H, 2009, EURASIP J EMBEDDED S, V2009, P543
   Jyothi Grande Naga, 2019, Microelectronics, Electromagnetics and Telecommunications. Proceedings of the Fourth ICMEET 2018. Lecture Notes in Electrical Engineering (LNEE 521), P385, DOI 10.1007/978-981-13-1906-8_40
   Meher PK, 2006, IEEE T CIRCUITS-II, V53, P707, DOI 10.1109/TCSII.2006.877277
   NagaJyothi G, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2684, DOI 10.1109/WiSPNET.2017.8300250
   Prakash MS, 2016, CIRC SYST SIGNAL PR, V35, P603, DOI 10.1007/s00034-015-0076-7
   Proakis J. G., 2001, Digital Signal Processing: Principles Algorithms and Applications
   QURESHI SUH, 1985, P IEEE, V73, P1349, DOI 10.1109/PROC.1985.13298
   Regehr S, 2017, TRANSPORT RES REC, P1, DOI 10.3141/2607-01
   Shaik R, 2006, IEEE AS PAC C CIRC S
   Shaik RA, 2013, SIGNAL PROCESS, V93, P1162, DOI 10.1016/j.sigpro.2012.11.024
   Waelchli G, 2010, J ELECTR COMPUT ENG, V2010, DOI 10.1155/2010/180296
   WHITE SA, 1986, IEEE T CIRCUITS SYST, V33, P1036, DOI 10.1109/TCS.1986.1085845
   Yoo H, 2005, IEEE INT C AC SPEECH, V5, pv
   White S. A., 1989, IEEE ASSP Magazine, V6, P4, DOI 10.1109/44.41514
NR 22
TC 13
Z9 13
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 32679
EP 32693
DI 10.1007/s11042-018-7038-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600004
DA 2024-07-18
ER

PT J
AU Khan, Z
   Yang, J
AF Khan, Zubair
   Yang, Jie
TI Image segmentation via multi dimensional color transform and consensus
   based region merging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised color image segmentation; FCM; Superpixels; Multi feature
   aproach; Hybrid cues
ID UNSUPERVISED SEGMENTATION
AB Most natural scene real world images contain a lot of variations and produce a set of complex information. This complex information representation inducts difficulty in separating focal objects in the image. In this paper, hybrid cues are determined to efficiently separate the foreground objects from image background. The segmentation approach presented in our paper consists of two steps: 1) Production of clustering based super pixels 2) Consensus based optimal region merging process. First, input image is processed by mean shift as a noise removal step, then FCM clustering is employed to cluster pixels by utilising features based on extended color space transformations, following that final region labelling is done in terms of superpixel spatial connectivity. Second, hybrid cues are calculated as a tool for similarity measurement between regions, and a Consensus based region merging process is implemented by adjacent region similarity comparison with the standard deviation serving as a merging threshold, producing final segmentation. Experiments are conducted on Berkeley Segmentation Database and segmented images verify the efficiency of our approach in Natural Scene images.
C1 [Khan, Zubair; Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Yang, J (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.
EM zubairkhan@sjtu.edu.cn; jieyang@sjtu.edu.cn
RI Khan, Zubair/X-7459-2019; Yang, Jie/JCD-9867-2023
OI Khan, Zubair/0000-0002-9651-5767; 
FU NSFC, China [:61572315]; Committee of Science and Technology, Shanghai,
   China [:17JC1403000]
FX This research is partly supported by NSFC, China (No:61572315) and
   Committee of Science and Technology, Shanghai, China (No:17JC1403000).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2005, P IEEE INT C IM PROC
   Bertelli L, 2008, IEEE T PATTERN ANAL, V30, P1400, DOI 10.1109/TPAMI.2007.70785
   Carandell J, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0248-z
   Chen L, 2011, IEEE T SYST MAN CY B, V41, P1263, DOI 10.1109/TSMCB.2011.2124455
   Cheng HD, 2002, PATTERN RECOGN, V35, P373, DOI 10.1016/S0031-3203(01)00054-1
   Cho SI, 2014, IET IMAGE PROCESS, V8, P761, DOI 10.1049/iet-ipr.2013.0602
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Estrada FJ, 2005, IEEE COMP SOC C COMP
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   HARALICK RM, 1985, P SOC PHOTO-OPT INST, V548, P2
   Hettiarachchi R, 2017, PATTERN RECOGN, V65, P119, DOI 10.1016/j.patcog.2016.12.011
   Ibrahim MT, 2010, PROC SPIE, V7744, DOI 10.1117/12.863264
   Kanezaki A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1543, DOI 10.1109/ICASSP.2018.8462533
   Khan Z, 2017, INT J INNOV COMPUT I, V13, P1509
   Khelifi L, 2017, IEEE T SYST MAN CY-S, V47, P2489, DOI 10.1109/TSMC.2016.2531645
   Kim J, 2016, IEEE T IMAGE PROCESS, V25, P9, DOI 10.1109/TIP.2015.2495122
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741
   Loesdau M, 2014, LECT NOTES COMPUT SC, V8509, P203, DOI 10.1007/978-3-319-07998-1_23
   Makrogiannis S, 2005, IEEE T SYST MAN CY A, V35, P224, DOI 10.1109/TSMCA.2004.832820
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meila M., 2005, P 22 INT C MACHINE L, P577
   Mignotte M, 2008, IEEE T IMAGE PROCESS, V17, P780, DOI 10.1109/TIP.2008.920761
   Moore AP, 2010, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2010.5539890
   Mourchid Y, 2019, MULTIMEDIA TOOLS APP
   Omer I., 2004, IEEE COMPUT SOC C CO, V2, pII
   Peng B, 2011, IEEE T IMAGE PROCESS, V20, P3592, DOI 10.1109/TIP.2011.2157512
   Rhyne T-M, 2012, ACM SIGGRAPH 2012 CO, P1
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sima HF, 2018, IEEE T SYST MAN CY-S, V48, P354, DOI 10.1109/TSMC.2016.2608831
   Stutz D, 2015, LECT NOTES COMPUT SC, V9358, P555, DOI 10.1007/978-3-319-24947-6_46
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Wang XF, 2015, IEEE T IMAGE PROCESS, V24, P1399, DOI 10.1109/TIP.2015.2397313
   Xia Xide, 2017, W-net: A deep model for fully unsupervised image segmentation
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005
NR 40
TC 4
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31347
EP 31364
DI 10.1007/s11042-019-07906-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000017
DA 2024-07-18
ER

PT J
AU Nsimba, CB
   Levada, A
AF Nsimba, Cedrick Bamba
   Levada, Alexandre
TI An information-theoretic wavelet-based texture descriptor using Gaussian
   Markov random field models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture classification; Gaussian markov random field; Information
   theory; Fisher information
ID CLASSIFICATION
AB Texture characterization and identification is a key issue for a variety of computer vision and image processing applications. Current techniques developed for dealing with the purpose thereof still present performance issues when applied in the presence of noise, owing to the intrinsic properties of the image being analyzed can not be maintained. Based on the principle that data distribution of these textures form a non-deterministic complex system, mathematical tools can help to characterize them. In this paper, we propose new approaches capable of quantifying such intrinsic properties by means of the Fisher information matrix. The methodology consists in firstly defining each wavelet sub-band of the texture image as a complex system modeled by a Gaussian Markov Random Field and secondly computing their respective Fisher information matrix and Shannon entropy. Applying the proposed texture descriptor to Salzburg and Outex datasets revealed a significant superiority of the proposed method vis-a-vis the majority of traditional and novel texture descriptors presented in the literature.
C1 [Nsimba, Cedrick Bamba; Levada, Alexandre] Univ Fed Sao Carlos, Dept Comp, Sao Carlos, SP, Brazil.
C3 Universidade Federal de Sao Carlos
RP Nsimba, CB (corresponding author), Univ Fed Sao Carlos, Dept Comp, Sao Carlos, SP, Brazil.
EM cedrick.bamba@ifsp.edu.br; alexandre@dc.ufscar.br
RI Levada, Alexandre/A-8301-2010
OI Levada, Alexandre/0000-0001-8253-2729
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - Brasil
   (CAPES) [001]
FX This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior - Brasil (CAPES) - Finance Code 001.
CR [Anonymous], 1089, Statistical Science, DOI [10.1214/ss/1177012486, DOI 10.1214/SS/1177012480]
   Arivazhagan S, 2003, PATTERN RECOGN LETT, V24, P1513, DOI 10.1016/S0167-8655(02)00390-2
   Barrow D, 2016, INT J FORECASTING, V32, P11201137
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641
   Chen JZ, 2017, NEUROCOMPUTING, V266, P79, DOI 10.1016/j.neucom.2017.04.066
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Sa JJD, 2013, PATTERN RECOGN LETT, V34, P1314, DOI 10.1016/j.patrec.2013.04.013
   Dharmagunawardhana C, 2014, IMAGE VISION COMPUT, V32, P884, DOI 10.1016/j.imavis.2014.07.002
   Emerson WC, 1998, MULTISCALE FRACTAL A
   Guo GD, 2003, LECT NOTES COMPUT SC, V2888, P986
   Hafemann LG, 2014, INT C PATT RECOG, P1103, DOI 10.1109/ICPR.2014.199
   Han J., 2006, DATA MINING CONCEPTS
   Haralick R. M., 1973, IEEE T SYST MAN CYB, P3
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455
   Jensen A., 2011, RIPPLES MATH DISCRET
   Kaplan LM, 1999, IEEE T IMAGE PROCESS, V8, P1572, DOI 10.1109/83.799885
   Krishnamachari S, 1997, IEEE T IMAGE PROCESS, V6, P251, DOI 10.1109/83.551696
   Kwitt R, 2017, SALZBURG TEXTURE IMA
   Levada A, 2014, ENTROPY-SWITZ, V16, P1002, DOI 10.3390/e16021002
   Levada AL, 2016, MONTE CARLO METHODS, V22, P81, DOI 10.1515/mcma-2016-0107
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Musgrave FK, 1994, Texturing and modeling: a procedural approach
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Santafe G, 2015, ARTIF INTELL REV, V44, P467, DOI 10.1007/s10462-015-9433-y
   Shannon C. E., 1949, The Mathematical Theory of Communication
   Strang G., 1996, Wavelets and Filter Banks
   Sun YM, 2007, PATTERN RECOGN, V40, P3358, DOI 10.1016/j.patcog.2007.04.009
   Wang HX, 2020, PATTERN RECOGN LETT, V130, P64, DOI 10.1016/j.patrec.2018.08.010
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang SW, 2018, SIGNAL IMAGE VIDEO P, V12, P1035, DOI 10.1007/s11760-018-1246-4
   Zhao YD, 2007, IEEE T GEOSCI REMOTE, V45, P1458, DOI 10.1109/TGRS.2007.892602
NR 39
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31959
EP 31986
DI 10.1007/s11042-019-07916-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000043
DA 2024-07-18
ER

PT J
AU Pornpongtechavanich, P
   Daengsi, T
AF Pornpongtechavanich, Phisit
   Daengsi, Therdpong
TI Video telephony - quality of experience: a simple QoE model to assess
   video calls using subjective approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video telephony; QoE model; Audiovisual; Subjective tests; Mean opinion
   score
AB One problem about using video calls or video telephony applications is a quality issue. Therefore, this paper contributes the simple QoE model, a mathematical model, to assess quality of video calls provided by video telephony applications or services. This mathematical model has been created based on the results from 200 subjects who joined the subjective test using short conversation scenario via two applications, Skype and LINE, two popular applications/services in Thailand. Based on the subjective results, the weighted coefficients for audio quality and video quality have been found, while the coefficient for audio quality is weighted higher than the one for video quality. Nevertheless, after using ANOVA and t-test, statistical analysis tools, based on the first set of the subjective data, it has been found that there are significant differences (p-values<0.05) when compared to most previous QoE models from other research works. However, after performance evaluating using Mean Absolute Percent Error (MAPE), it has been found that its performances are better than previous models with average MAPE values of 10.4 and 5.65% in the first and the second round evaluation with the other 48 subjects and 32 subjects respectively. Therefore, these are evident that this model can be applied to evaluation quality of video calls with confidence.
C1 [Pornpongtechavanich, Phisit] Rajamangala Univ Technol Rattanakosin, Fac Ind & Technol, Wang Klai Kangwon Campus, Hua Hin, Prachuap Khiri, Thailand.
   [Daengsi, Therdpong] Rajamangala Univ Technol Phra Nakhon, North Bangkok Ctr, Fac Engn, Dept Sustainable Ind Management Engn, Bangkok, Thailand.
C3 Rajamangala University of Technology Rattanakosin; Rajamangala
   University of Technology Phra Nakhon
RP Daengsi, T (corresponding author), Rajamangala Univ Technol Phra Nakhon, North Bangkok Ctr, Fac Engn, Dept Sustainable Ind Management Engn, Bangkok, Thailand.
EM phisit.kha@rmutr.ac.th; therdpong.d@rmupt.ac.th
RI Pornpongtechavanich, Phisit/HMV-4329-2023; Daengsi,
   Therdpong/AAH-9231-2019
OI Pornpongtechavanich, Phisit/0000-0003-4464-8186; Daengsi,
   Therdpong/0000-0002-7569-8197
FU Faculty of Engineering, Rajamangala University of Technology Phra
   Nakhon; Faculty of Industry and Technology, Rajamangala University of
   Technology Rattanakosin (Wang Klai Kangwon Campus)
FX Thank you to the Faculty of Engineering, Rajamangala University of
   Technology Phra Nakhon and the Faculty of Industry and Technology,
   Rajamangala University of Technology Rattanakosin (Wang Klai Kangwon
   Campus) for supporting. Especially, thank you to all students, staff and
   lecturers who were participants or involved.
CR Alsmirat MA, 2017, J REAL-TIME IMAGE PR, V13, P527, DOI 10.1007/s11554-016-0631-x
   [Anonymous], CISC VIS NETW IND FO
   [Anonymous], 2001, ITU T REC P 862 PERC
   [Anonymous], NTT TECH REV
   [Anonymous], 2010, 21 ITC SPEC SEM MULT
   Belmudez B., 2009, 2009 IEEE International Workshop on Multimedia Signal Processing, P1
   Belmudez B, 2013, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2013-24
   Chen YJ, 2015, IEEE COMMUN SURV TUT, V17, P1126, DOI 10.1109/COMST.2014.2363139
   Daengsi T., 2014, WALAILAK J SCI TECHN, V11, P87
   Daengsi T, 2016, MULTIMEDIA SYST, V22, P575, DOI 10.1007/s00530-015-0468-3
   De Pessemier T, 2016, TELECOMMUN SYST, V61, P417, DOI 10.1007/s11235-014-9961-9
   De Rango F, 2006, INT J COMPUT SCI NET, V6, P140
   Farid F., 2013, Commun, of the IBIMA, V2013, P1
   Hands DS, 2004, IEEE T MULTIMEDIA, V6, P806, DOI 10.1109/TMM.2004.837233
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hossain MS, 2018, FUTURE GENER COMP SY, V83, P596, DOI 10.1016/j.future.2017.03.029
   IMDb, BACK FUT 2
   ITU-T, 2000, ITU T REC G 107 E MO
   ITU-T, 2012, ITU T REC G 1070 OP
   ITU-T, 2007, ITU T REC P 805 SUBJ
   ITU-T, 2017, ITU T REC P 1301 SUB
   ITU-T, 1998, ITU R REC BT 710 SUB
   ITU-T, 2003, ITU T REC J 148 REQ
   ITU-T, 2008, ITU T REC P 910 SUBJ
   ITU-T, 1998, ITU T REC P 911 SUBJ
   ITU-T, 2000, ITU T REC P 920 INT
   ITU-T, 1996, ITU T REC P 800 METH
   ITU- T Telecommunication standardization sector of ITU, 2016, ITU T REC P 913 METH
   Jana S, 2016, MULTIMED TOOLS APPL, V75, P7957, DOI 10.1007/s11042-015-2711-5
   Khalifeh A, QOS MULTIMEDIA APPL
   Le H, 2015, 2015 IEEE 26TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P1277, DOI 10.1109/PIMRC.2015.7343495
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Liu H, 2019, MULTIMED TOOLS APPL, V78, P9033, DOI 10.1007/s11042-017-5277-6
   Martinez HB, 2014, EUR SIGNAL PR CONF, P2125
   Martinez HB, 2014, PROC SPIE, V9016, DOI 10.1117/12.2042425
   Martinez-Rach M, PSNR VS QUALITY ASSE
   Mohammadi P., 2014, SUBJECTIVE OBJECTIVE
   Saidi I, 2016, IEEE INT WORKSH MULT
   Sirawongphatsara P, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P205, DOI 10.1109/ICOIN.2015.7057883
   Streijl RC, 2016, MULTIMEDIA SYST, V22, P213, DOI 10.1007/s00530-014-0446-1
   Sun L, 2015, IEEE COMSOC MMTC E L, V10, P14
   Takahara Atsushi, 2009, NTT Technical Review, V7
   Telchemy, TELCH VID QUAL METR
   Timmerer C, 2015, IEEE CONSOC MMTC E L, V10, P6
   Tsolkas D, 2017, J NETW COMPUT APPL, V77, P1, DOI 10.1016/j.jnca.2016.10.016
   Wamser F, 2013, P MONAMI 2013, DOI [10.1007/978-3-319-04277-0_14, DOI 10.1007/978-3-319-04277-0_14]
   Wang J, 2018, MULTIMED TOOLS APPL, V77, P387, DOI 10.1007/s11042-016-4254-9
   Wang Yubing., Survey of Objective Video Quality Measurements
   Wearesocial, 2019, DIG 2019 THAIL
   Winkler S, 2006, IEEE T MULTIMEDIA, V8, P973, DOI 10.1109/TMM.2006.879871
   Wu PH, 2015, IEEE T VEH TECHNOL, V64, P3233, DOI 10.1109/TVT.2014.2350002
   Wuttidittachotti Pongpisit, 2015, International Journal of Computer Network and Information Security, V7, P28, DOI 10.5815/ijcnis.2015.12.04
   Wuttidittachotti P, 2017, MULTIMED TOOLS APPL, V76, P16163, DOI 10.1007/s11042-016-3901-5
   Xu Y, 2014, IEEE ACM T NETWORK, V22, P826, DOI 10.1109/TNET.2013.2260354
   Yu CG, 2014, IEEE INFOCOM SER, P1456, DOI 10.1109/INFOCOM.2014.6848080
   Yue T, 2018, MULTIMED TOOLS APPL, V77, P27269, DOI 10.1007/s11042-018-5918-4
   Zhang W, 2014, P IEEE ICMEW 2014, DOI [10.1109/ICMEW.2014.6890640, DOI 10.1109/ICMEW.2014.6890640]
   Zhu Y, 2015, COMPUT HUM BEHAV, V49, P412, DOI 10.1016/j.chb.2015.02.054
NR 58
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31987
EP 32006
DI 10.1007/s11042-019-07928-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000044
DA 2024-07-18
ER

PT J
AU Zhang, Y
AF Zhang, Yong
TI Security analysis of a chaos triggered image encryption scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information security; Image encryption; Security analysis; Chosen
   plaintext attack
ID CRYPTANALYSIS; PERMUTATION
AB A chaos triggered image encryption scheme was recently proposed [Ramalingam et al., Multimed Tools Appl, 2018, 77(10): 11669-11,692]. In this paper, this scheme was analyzed in detail, and then some shortcomings concerning the scheme were pointed out. For example, the combined chaos systems used in the scheme possess weak chaos characteristics, the scheme is insensitive with respect to cipher images, and above all, it is vulnerable to chosen plaintext attacks. After that, a well-designed chosen plaintext attack method was suggested to attack the equivalent secret keys of the scheme, and then the scheme was successfully deciphered in a short time. So, the scheme cannot be applied to actual communication systems.
C1 [Zhang, Yong] Jiangxi Univ Finance & Econ, Sch Software & Internet Things Engn, Nanchang, Jiangxi, Peoples R China.
C3 Jiangxi University of Finance & Economics
RP Zhang, Y (corresponding author), Jiangxi Univ Finance & Econ, Sch Software & Internet Things Engn, Nanchang, Jiangxi, Peoples R China.
EM zhangyong@jxufe.edu.cn
OI Zhang, Yong/0000-0002-7428-1816
FU National Natural Science Foundation of China [61762043, 61562035,
   61702238]; Science and Technology Project of Education Department of
   Jiangxi Province, China [GJJ160426]
FX This work was fully supported by the National Natural Science Foundation
   of China (Grant Nos. 61762043, 61562035, 61702238), and the Science and
   Technology Project of Education Department of Jiangxi Province, China
   (Grant No. GJJ160426).
CR Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Cheng PG, 2015, NONLINEAR DYNAM, V79, P2121, DOI 10.1007/s11071-014-1798-y
   Fan HJ, 2018, SIGNAL PROCESS, V143, P28, DOI 10.1016/j.sigpro.2017.08.018
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P8759, DOI 10.1007/s11042-017-4772-0
   Ghebleh M, 2018, MULTIMED TOOLS APPL, V77, P7305, DOI 10.1007/s11042-017-4634-9
   Hanis S, 2018, MULTIMED TOOLS APPL, V77, P6897, DOI 10.1007/s11042-017-4606-0
   Hu GQ, 2017, NONLINEAR DYNAM, V88, P1305, DOI 10.1007/s11071-016-3311-2
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Huang XL, 2018, MULTIMED TOOLS APPL, V77, P2611, DOI 10.1007/s11042-017-4455-x
   Laiphrakpam DS, 2018, MULTIMED TOOLS APPL, V77, P8629, DOI 10.1007/s11042-017-4755-1
   Li B, 2018, MULTIMED TOOLS APPL, V77, P8911, DOI 10.1007/s11042-017-4786-7
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Liu JY, 2018, MULTIMED TOOLS APPL, V77, P10217, DOI 10.1007/s11042-017-5406-2
   Noura H, 2018, MULTIMED TOOLS APPL, V77, P15457, DOI 10.1007/s11042-017-5124-9
   Ogiela L, 2017, IEEE SYST J, V11, P405, DOI 10.1109/JSYST.2015.2409213
   Ogiela U, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4362
   Ramalingam B, 2018, MULTIMED TOOLS APPL, V77, P11669, DOI 10.1007/s11042-017-4811-x
   Su X, 2017, MULTIMED TOOLS APPL, V76, P14021, DOI 10.1007/s11042-016-3800-9
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Wang XY, 2013, COMMUN NONLINEAR SCI, V18, P3075, DOI 10.1016/j.cnsns.2013.04.008
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Wu XJ, 2018, MULTIMED TOOLS APPL, V77, P12349, DOI 10.1007/s11042-017-4885-5
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Ye GD, 2016, NONLINEAR DYNAM, V83, P2067, DOI 10.1007/s11071-015-2465-7
   Zhang D, 2018, MULTIMED TOOLS APPL, V77, P2191, DOI 10.1007/s11042-017-4370-1
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P21589, DOI 10.1007/s11042-017-5585-x
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P6647, DOI 10.1007/s11042-017-4577-1
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
NR 29
TC 6
Z9 6
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31303
EP 31318
DI 10.1007/s11042-019-07894-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000015
DA 2024-07-18
ER

PT J
AU Gupta, S
   Kumar, M
   Garg, A
AF Gupta, Surbhi
   Kumar, Munish
   Garg, Anupam
TI Improved object recognition results using SIFT and ORB feature detector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object Recognition; ORB; SIFT; K-Means; LPP; k-NN; Decision Tree; Random
   Forest
ID IMAGE RETRIEVAL; CLASSIFICATION; TEXTURE
AB Object recognition has a wide domain of applications such as content-based image classification, video data mining, video surveillance and more. Object recognition accuracy has been a significant concern. Although deep learning had automated the feature extraction but hand crafted features continue to deliver consistent performance. This paper aims at efficient object recognition using hand crafted features based on Oriented Fast & Rotated BRIEF (Binary Robust Independent Elementary Features) and Scale Invariant Feature Transform features. Scale Invariant Feature Transform (SIFT) are particularly useful for analysis of images in light of different orientation and scale. Locality Preserving Projection (LPP) dimensionality reduction algorithm is explored to reduce the dimensions of obtained image feature vector. The execution of the proposed work is tested by using k-NN, decision tree and random forest classifiers. A dataset of 8000 samples of 100-class objects has been considered for experimental work. A precision rate of 69.8% and 76.9% has been achieved using ORB and SIFT feature descriptors, respectively. A combination of ORB and SIFT feature descriptors is also considered for experimental work. The integrated technique achieved an improved precision rate of 85.6% for the same.
C1 [Gupta, Surbhi] Gokaraju Rangaraju Inst Engn & Technol, Dept Comp Sci & Engn, Hyderabad, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
   [Garg, Anupam] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
C3 Gokaraju Rangaraju Institute of Engineering & Technology; Thapar
   Institute of Engineering & Technology
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM munishcse@gmail.com
RI Kumar, Munish/P-7756-2018; gupta, surbhi/AAY-7465-2020; Gupta,
   Surbhi/HPF-6704-2023; Gupta, Surbhi/AAS-3570-2020
OI Kumar, Munish/0000-0003-0115-1620; Gupta, Surbhi/0000-0003-0618-8369;
   Gupta, Surbhi/0000-0003-0618-8369
CR ALHAIS Alexandra., 2017, CEDIS Working Papers no51, P1
   [Anonymous], P WORKSH GEN MOD BAS
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Berg AC, 2005, PROC CVPR IEEE, P26
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cestnik Bojan., 1987, EWSL, P31
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Davis JJ., 2006, PROC INT C MACHINE L, DOI DOI 10.1145/1143844.1143874
   Elnagar A, 2003, PATTERN RECOGN, V36, P625, DOI 10.1016/S0031-3203(02)00097-3
   Ferrari V, 2010, INT J COMPUT VISION, V87, P284, DOI 10.1007/s11263-009-0270-9
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   He XF, 2004, ADV NEUR IN, V16, P153
   Huang X, 2017, P 9 INT C MACH VIS I, V10341
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Leordeanu M, 2007, PROC CVPR IEEE, P928
   Liu PZ, 2017, INFORM SCIENCES, V390, P95, DOI 10.1016/j.ins.2017.01.025
   Liu XL, 2019, WORLD WIDE WEB, V22, P423, DOI 10.1007/s11280-018-0600-3
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Minut Silviu, 2001, P 5 INT C AUTONOMOUS
   Montazer GA, 2015, OPTIK, V126, P1695, DOI 10.1016/j.ijleo.2015.05.002
   Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220
   Nadernejad E., 2008, Appl. Math. Sci, V2, P1507
   PETERSON MA, 1994, PSYCHOL SCI, V5, P253, DOI 10.1111/j.1467-9280.1994.tb00622.x
   Sharma K.U., 2017, International Journal of Computational Vision and Robotics, V7, P196, DOI [10.1504/IJCVR.2017.081234, DOI 10.1504/IJCVR.2017.081234]
   SWAIN PH, 1977, IEEE T GEOSCI REMOTE, V15, P142, DOI 10.1109/TGE.1977.6498972
   Toshev A, 2010, PROC CVPR IEEE, P950, DOI 10.1109/CVPR.2010.5540114
   ULLMAN S, 1984, COGNITION, V18, P97, DOI 10.1016/0010-0277(84)90023-4
   Vinay A, 2015, PROCEDIA COMPUT SCI, V58, P614, DOI 10.1016/j.procs.2015.08.080
   Yu SX, 2003, PROC CVPR IEEE, P39
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 32
TC 46
Z9 49
U1 1
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 34157
EP 34171
DI 10.1007/s11042-019-08232-6
EA OCT 2019
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000491551600001
DA 2024-07-18
ER

PT J
AU Meng, Z
   Pan, ZZ
   Shi, Y
   Chen, ZJ
AF Meng, Zong
   Pan, Zuozhou
   Shi, Ying
   Chen, Zijun
TI Improved adaptive forward-backward matching pursuit algorithm to
   compressed sensing signal recovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Matching pursuit; Forward-backward search; Adaptive
   threshold; Signal reconstruction
AB As a novel two-stage greedy approximation algorithm, Forward-Backward Pursuit (FBP) algorithm attracts wide attention because of its high reconstruction accuracy and no need for sparsity as a priori information. However, the FBP algorithm has to spend much more time to get a higher accuracy. In view of this, an Improved Adaptive Forward-Backward Matching Pursuit (IAFBP) algorithm is proposed in this paper. In the forward stage, the IAFBP algorithm uses an adaptive threshold to select the appropriate number of atoms into support set, so that the number of selected atoms is more random. In the backward stage, the projection coefficient of the atoms is taken as the basis of rejection, and the deletion threshold is introduced to reject the atoms adaptively, so that more right atoms are retained in each iteration and the reconstruction speed can be accelerated. At the same time, it overcomes the excessive backtracking phenomenon existing in the adaptive process and improves the accuracy of the algorithm. The simulation results of one-dimensional sparse signals and two-dimensional images show that the IAFBP algorithm has more advantages than the FBP algorithm in reconstruction performance and computational time.
C1 [Meng, Zong; Pan, Zuozhou; Shi, Ying; Chen, Zijun] Yanshan Univ, Key Lab Measurement Technol & Instrumentat Hebei, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Yanshan University
RP Meng, Z (corresponding author), Yanshan Univ, Key Lab Measurement Technol & Instrumentat Hebei, Qinhuangdao 066004, Hebei, Peoples R China.
EM mzystt@ysu.edu.cn; 792807944@qq.com; 1064682611@qq.com; ivanjudd@qq.com
RI Meng, Zong/AGW-0716-2022
OI Meng, Zong/0000-0002-8480-3235
FU National Natural Science Foundation of China [51575472]; Natural Science
   Foundation of Hebei Province of China [E2019203448]; scientific research
   program of Hebei Education Department [ZD2015049]; scientific research
   program for Talents Returning from Overseas of Hebei Province
   [C2015005020]
FX The work was supported by the National Natural Science Foundation of
   China (No. 51575472), by the Natural Science Foundation of Hebei
   Province of China (No.E2019203448), the scientific research program of
   Hebei Education Department (No. ZD2015049) and the scientific research
   program for Talents Returning from Overseas of Hebei Province (No.
   C2015005020).
CR Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2011, APPL COMPUT HARMON A, V31, P59, DOI 10.1016/j.acha.2010.10.002
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fan C, 2016, MULTIMED TOOLS APPL, V75, P12201, DOI 10.1007/s11042-015-3004-8
   Karahanoglu NB, 2013, DIGIT SIGNAL PROCESS, V23, P1539, DOI 10.1016/j.dsp.2013.05.007
   Karahanoglu NB, 2012, DIGIT SIGNAL PROCESS, V22, P555, DOI 10.1016/j.dsp.2012.03.003
   KARAHANOLU NB, 2013, P 21 SIGN PROC COMM, P21
   Lu WZ, 2015, IEEE SIGNAL PROC LET, V22, P1074, DOI 10.1109/LSP.2014.2385813
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   MENG X, 2016, SIGNAL PROCESS, V32, P186
   MENG Z, 2019, CHINESE HIGH TECHNOL, V29, P110
   Needell D, 2009, FOUND COMPUT MATH, V9, P317, DOI 10.1007/s10208-008-9031-3
   Norra S, 2017, APPL GEOCHEM, V77, P1, DOI 10.1016/j.apgeochem.2017.01.006
   [彭玉楼 Peng Yulou], 2012, [仪器仪表学报, Chinese Journal of Scientific Instrument], V33, P2655
   Qaisar S, 2013, J COMMUN NETW-S KOR, V15, P443, DOI 10.1109/JCN.2013.000083
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   [王锋 Wang Feng], 2016, [电子与信息学报, Journal of Electronics & Information Technology], V38, P2538
   [王磊 Wang Lei], 2014, [电子与信息学报, Journal of Electronics & Information Technology], V36, P1299
   Wang WY, 2013, SENSORS-BASEL, V13, P11167, DOI 10.3390/s130911167
   Yan C, 2019, IN PRESS
   YAO S, 2015, MULTIMED TOOLS APPL, P1
   Zhang YJ, 2017, MULTIMED TOOLS APPL, V76, P20587, DOI 10.1007/s11042-016-3968-z
   Zheng S, 2018, MULTIMED TOOLS APPL, V77, P8711, DOI 10.1007/s11042-017-4765-z
NR 23
TC 6
Z9 6
U1 3
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33969
EP 33984
DI 10.1007/s11042-019-08161-4
EA OCT 2019
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000490223600001
DA 2024-07-18
ER

PT J
AU Cai, SL
   Huang, JB
   Chen, J
   Huang, Y
   Ding, XH
   Zeng, DL
AF Cai, Shulian
   Huang, Jiabin
   Chen, Jing
   Huang, Yue
   Ding, Xinghao
   Zeng, Delu
TI Prominent edge detection with deep metric expression and multi-scale
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Edge detection; Guide filter; Convolution encoder-decoder network;
   Metric space; Multi-scale features
AB Edge detection is one of today's hottest computer vision issues with widely applications. It is beneficial for improving the capability of many vision systems, such as semantic segmentation, salient object detection and object recognition. Deep convolution neural networks (CNNs) recently have been employed to extract robust features, and have achieved a definite improvement. However, there is still a long run to study this hotspot with the main reason that CNNs-based approaches may cause the edges thicker. To address this problem, a novel semantic edge detection algorithm using multi-scale features is proposed. Our model is deep symmetrical metric learning network, which includes 3 key parts. Firstly, the deep detail layer, as a preprocessing layer and a guide module, is employed to remove some low-frequency information and still maintain the edge. Secondly, the deep encoder-decoder networks extract multi-scale features of original image, integrated for complementing information among each level feature. Finally, metric learning is introduced to generate a metric space used to predict edge result. It is easy to distinguish different categories, such as edge space and object space. Simulations and comparisons on benchmark datasets demonstrate the proposed algorithm is superior to the others through visual and quantitative evaluation, and specifically, the score of ODS reachs 0.788.
C1 [Cai, Shulian; Huang, Jiabin; Huang, Yue; Ding, Xinghao] Xiamen Univ, Sch Informat Sci & Technol, Xiamen 361005, Fujian, Peoples R China.
   [Cai, Shulian; Chen, Jing] Huaqiao Univ, Xiamen Key Lab Mobile Multimedia Commun, Xiamen 361021, Fujian, Peoples R China.
   [Zeng, Delu] South China Univ Technol, Sch Math, Guangzhou 510641, Guangdong, Peoples R China.
C3 Xiamen University; Huaqiao University; South China University of
   Technology
RP Zeng, DL (corresponding author), South China Univ Technol, Sch Math, Guangzhou 510641, Guangdong, Peoples R China.
EM dlzeng@scut.edu.cn
FU National Science Foundation of China [6151005, 61571382, 61103121,
   81671766]; China Scholarship Council CSC [201806155037]; Xiamen Key
   Laboratory of Mobile Multimedia Communications (Huaqiao University);
   Guangdong Natural Science Foundation [2015A030313007, 2015A030313589]
FX This work was supported in part from the grants of National Science
   Foundation of China (6151005, 61571382, 61103121, 81671766) and the
   funding from China Scholarship Council CSC NO. 201806155037, and open
   funding from Xiamen Key Laboratory of Mobile Multimedia Communications
   (Huaqiao University), and Guangdong Natural Science Foundation
   (2015A030313007, 2015A030313589).
CR [Anonymous], 1970, TECHNICAL REPORT
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bertasius G, 2015, PROC CVPR IEEE, P4380, DOI 10.1109/CVPR.2015.7299067
   Cai SL, 2017, I S INTELL SIG PROC, P707, DOI 10.1109/ISPACS.2017.8266568
   Cheng MM, 2016, LECT NOTES COMPUT SC, V9907, P867, DOI 10.1007/978-3-319-46487-9_53
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dollar P., 2006, 2006 IEEE COMP SOC C, V2, P1964, DOI DOI 10.1109/CVPR.2006.298
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   Ganin Y, 2015, LECT NOTES COMPUT SC, V9004, P536, DOI 10.1007/978-3-319-16808-1_36
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goldberger J., 2004, P 17 INT C NEUR INF, P513
   Hallman S, 2015, PROC CVPR IEEE, P1732, DOI 10.1109/CVPR.2015.7298782
   Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maninis KK, 2016, LECT NOTES COMPUT SC, V9905, P580, DOI 10.1007/978-3-319-46448-0_35
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Nguyen Hieu V., 2011, P AS C COMP VIS, P709, DOI DOI 10.1007/978-3-642-19309-5_55
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Prewitt J. M., 1970, Picture processing and psychopictorics, V10, P15
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roberts L., 1963, MACHINE PERCEPTION 3
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang B, 2017, NEUROCOMPUTING, V221, P60, DOI 10.1016/j.neucom.2016.09.062
   Yang ZY, 2017, IEEE T NEUR NET LEAR, V28, P948, DOI 10.1109/TNNLS.2016.2517096
   Zhang W, 2018, IEEE T CIRC SYST VID, V28, P2768, DOI 10.1109/TCSVT.2017.2718188
   Zhang W, 2017, IEEE T IMAGE PROCESS, V26, P2042, DOI 10.1109/TIP.2017.2672440
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P2318, DOI 10.1109/TIP.2011.2170079
   Zhang Z., 2003, Proceedings of the 18th international joint conference on Artificial intelligence, V18, P1450
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
   Zou WB, 2015, IEEE I CONF COMP VIS, P406, DOI 10.1109/ICCV.2015.54
   Zou WB, 2015, IEEE T IMAGE PROCESS, V24, P3858, DOI 10.1109/TIP.2015.2456497
NR 51
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29121
EP 29135
DI 10.1007/s11042-018-6581-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700040
DA 2024-07-18
ER

PT J
AU Han, Y
   Park, E
   Park, S
AF Han, Youjeong
   Park, Eunhee
   Park, Seongchul
TI A study on emotion-labor based emotion burnout by video, questionnaires
   and structural equation model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotional labor; Emotional expression rules; Emotional intelligence;
   Structural equation model; SEM; Burnout
ID SOCIAL SUPPORT; CONSEQUENCES; PERFORMANCE; VALIDATION; NURSES
AB This study was conducted to establish a structural equation model(SEM) with the aim of providing foundations for development of strategies to reduce emotional labor and burnout of clinical nurses by identifying the effects of individual and organization characteristics on emotional labor and burnout in clinical nurses and analyze the casual relations between them. Hypothetical models were established based on the emotion regulation process model relating to emotional labor and burnout in clinical nurses. The endogenous and exogenous variables for the hypothetical models consisted of emotional labor and burnout, emotional expression rules, emotional intelligence, emotions (positive and negative emotions), social support (superior support and peer support), and job autonomy. Eleven of 19 hypothetical models were supported. The researchers suggested the following strategies to reduce emotional labor and burnout in clinical nurses: at the individual level, cultivation of emotional intelligence and positive emotions, and reduction of negative emotions; at the organizational level, alleviation of emotional expression rules, granting autonomy, and the development and application of various interventions to enhance social support.
C1 [Han, Youjeong] Mokpo Sci Univ, Dept Nursing, Mokpo, South Korea.
   [Park, Eunhee] Kyung Hee Univ, Grad Sch, Dept Biol, Seoul, South Korea.
   [Park, Seongchul] Dongguk Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Kyung Hee University; Dongguk University
RP Park, S (corresponding author), Dongguk Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM yjhan68@hanmail.net; pehmp@hanmail.net; scpark@dongguk.edu
FU Mokpo Science University
FX This study was supported by a research fund from Mokpo Science
   University, 2018.
CR Adil A., 2013, Psychological Studies, V58, P89
   Allen JA, 2010, HUM PERFORM, V23, P101, DOI 10.1080/08959281003621695
   [Anonymous], 17 ANN C SOC IND ORG
   [Anonymous], 1981, WORK STRESS SOCIAL S
   [Anonymous], NURSES WORK SATISFAC
   [Anonymous], STRUCTURAL EQUATION
   Bakker AB, 2005, J OCCUP HEALTH PSYCH, V10, P170, DOI 10.1037/1076-8998.10.2.170
   Best R.G., 1997, 12 ANN C SOC IND ORG
   Bono JE, 2007, J OCCUP HEALTH PSYCH, V12, P177, DOI 10.1037/1076-8998.12.2.177
   Brotheridge CM, 2003, J OCCUP ORGAN PSYCH, V76, P365, DOI 10.1348/096317903769647229
   김경옥, 2013, [Journal of Korea Academia-Industrial cooperation Society, 한국산학기술학회논문지], V14, P3794, DOI 10.5762/KAIS.2013.14.8.3794
   Côté S, 2005, ACAD MANAGE REV, V30, P509, DOI [10.2307/20159142, 10.5465/amr.2005.17293692]
   Diefendorff JM, 2011, J OCCUP HEALTH PSYCH, V16, P170, DOI 10.1037/a0021725
   Diefendorff JM, 2003, J ORGAN BEHAV, V24, P945, DOI 10.1002/job.230
   Grandey A A, 2000, J Occup Health Psychol, V5, P95, DOI 10.1037/1076-8998.5.1.95
   Gross JJ, 1998, J PERS SOC PSYCHOL, V74, P224, DOI 10.1037/0022-3514.74.1.224
   Hamaideh Shaher H, 2011, Issues Ment Health Nurs, V32, P234, DOI 10.3109/01612840.2010.546494
   Humphrey SE, 2007, J APPL PSYCHOL, V92, P1332, DOI 10.1037/0021-9010.92.5.1332
   Jenkins R, 2004, J ADV NURS, V48, P622, DOI 10.1111/j.1365-2648.2004.03240.x
   Kalicinska M, 2012, INT J NURS PRACT, V18, P595, DOI 10.1111/ijn.12003
   김하자, 2011, [Korean Journal of Occupational Health Nursing, 한국직업건강간호학회지], V20, P308
   Kim Joohyun, 2013, [The Journal of Fundamentals of Nursing, 기본간호학회지], V20, P157
   Lee J, 2012, INT J HOSP MANAG, V31, P1101, DOI 10.1016/j.ijhm.2012.01.007
   Maslach C., 1986, MASLACH BURNOUT INVE
   Mee Ko， Chung, 2013, [Journal of Korean Academy of Nursing Administration, 간호행정학회지], V19, P647, DOI 10.11111/jkana.2013.19.5.647
   Morris JA, 1996, ACAD MANAGE REV, V21, P986, DOI 10.2307/259161
   Shin Hye Sook, 2012, [The Journal of the Korea Contents Association, 한국콘텐츠학회 논문지], V12, P415, DOI 10.5392/JKCA.2012.12.07.415
   van der Ploeg Eleonore, 2003, J Occup Health Psychol, V8, P157, DOI 10.1037/1076-8998.8.2.157
   김수옥, 2015, [Journal of Korea Academia-Industrial cooperation Society, 한국산학기술학회논문지], V16, P1273, DOI 10.5762/KAIS.2015.16.2.1273
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Wong CS, 2002, LEADERSHIP QUART, V13, P243, DOI 10.1016/S1048-9843(02)00099-1
NR 31
TC 2
Z9 2
U1 2
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28779
EP 28803
DI 10.1007/s11042-018-6705-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700024
DA 2024-07-18
ER

PT J
AU Jain, N
   Kumar, S
   Kumar, A
AF Jain, Neha
   Kumar, Shishir
   Kumar, Amit
TI Effective approach for facial expression recognition using hybrid
   square-based diagonal pattern geometric model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Feature extraction; Image processing; Image texture
   analysis; Image sequence analysis
ID ROBUST FACE RECOGNITION; SPARSE
AB Facial expressions convey human emotions in an expressive way. The development of an automated system to recognize the facial expressions is the difficult task. Automatic Facial Expression Recognition (FER) is an imperative process that leads to next-generation Human-Machine Interaction (HMI) for clinical practice and behavioral description. Segment detection and the extraction of relevant information from the images are the major issues to design an effective FER system. The creation of the suitable system that addresses these issues is the basic stage to achieve the accurate HMI models. The in-depth information analysis and maximization of labeled database are the real problems in the domain of FER approaches. A novel framework based on Square-Based Diagonal Pattern (SBDP) method on Geometric model called Geometric Appearance Models (GAM) has been presented through this paper that extracts the in-depth detailed of the features. The framework adopts the co-training by using detailed information from RGB-D images. The performance analysis of proposed SBDP-GAM regarding identification rate, sensitivity, accuracy and error rates with the RGB-D images shows the effectiveness diagonal patterns in facial expression identification. The comparative analysis of proposed SBDP-GAM model with the traditional methods regarding the recognition rate, error rate and F-score and on RGB-D images from EURECOMM database states the effectiveness of the proposed method. Moreover, the comparison of proposed SBDP-GAM with existing Support Vector Machine (SVM) regarding the acceptance rate (FAR, FRR, GAR) measures for biographer RGB-D image database proves the effectiveness of SBDP-GAM in FER applications.
C1 [Jain, Neha; Kumar, Shishir; Kumar, Amit] Jaypee Univ Engn & Technol, Dept Comp Sci & Engn, Guna, MP, India.
RP Jain, N (corresponding author), Jaypee Univ Engn & Technol, Dept Comp Sci & Engn, Guna, MP, India.
EM neha.juet@gmail.com; dr.shishir@yahoo.com; amitrathi10@yahoo.co.in
RI Kumar, Shishir/AAE-9164-2020
CR [Anonymous], 2015, ARXIV150404548
   [Anonymous], 2010, ANN ARBOR
   [Anonymous], 2012, ARXIV12036722
   Baltrusaitis T, 2014, LECT NOTES COMPUT SC, V8692, P593, DOI 10.1007/978-3-319-10593-2_39
   Chen JH, 2015, INT CONF AFFECT, P636, DOI 10.1109/ACII.2015.7344636
   Cheng YH, 2014, INT C PATT RECOG, P2377, DOI 10.1109/ICPR.2014.412
   El Maghraby A., 2014, International Journal of Computer Applications, V101, P23, DOI [DOI 10.5120/17667-8494, 10.5120/17667-8494]
   Fulcher BD, 2014, IEEE T KNOWL DATA EN, V26, P3026, DOI 10.1109/TKDE.2014.2316504
   Ghosh D, 2015, CSNT
   Goswami G, 2013, BTAS
   Jiang B., 2013, J INF HID MULTIMED S, V4, P138
   Khoueiry BW, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P211, DOI 10.1109/ICCE.2012.6161833
   Lemaire P, 2013, FG
   Li YQ, 2013, IEEE T IMAGE PROCESS, V22, P2559, DOI 10.1109/TIP.2013.2253477
   Madhu M., 2012, INT J ENG INNOVATIVE, V2, P482
   Mengyi Liu, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P577, DOI 10.1007/978-3-642-37444-9_45
   Min R, 2014, IEEE T SYST MAN CY-S, V44, P1534, DOI 10.1109/TSMC.2014.2331215
   Nicolaou MA, 2012, IMAGE VISION COMPUT, V30, P186, DOI 10.1016/j.imavis.2011.12.005
   Reddy P, 2013, JDMT
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Romero P, 2013, WAF
   Ruan J, 2014, JICS 2013
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P683, DOI 10.1016/j.imavis.2012.06.005
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Srivastava S, 2014, INT J COMPUT SCI NET, V14, P78
   Wong YK, 2014, IET BIOMETRICS, V3, P176, DOI 10.1049/iet-bmt.2013.0033
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Yang M, 2010, LECT NOTES COMPUT SC, V6316, P448, DOI 10.1007/978-3-642-15567-3_33
   Yang WK, 2018, IEEE ACCESS, V6, P7445, DOI 10.1109/ACCESS.2017.2784800
   Yu QH, 2012, COMM COM INF SC, V321, P284
NR 31
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29555
EP 29571
DI 10.1007/s11042-019-7325-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700062
DA 2024-07-18
ER

PT J
AU Li, C
   Yuan, XR
AF Li, Chen
   Yuan, Xinrui
TI The media-oriented cross domain recommendation method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Media data; Cross-domain recommendation; Collaborative filtering
   recommendation; Matrix decomposition; Scarcity
ID AWARE
AB With the rapid development of modern high-tech, such as big data and artificial intelligence, the demand for cross-media services is also greatly improved. Since different modes of cross-media data apply different dimensions and different attributes of the underlying features to present data, many tasks need to work collaboratively to handle multiform of information (including text, audio, video, image, etc.), so as to build cross-media analysis and reasoning. Through the cross-media, the method could express the same semantic information from their own side and could reflect the specific information more fully than a single media object and its specific modal. The same information is cross spread and integrated across different kinds of media objects. Only conducting fusion analysis to these multi-modal media, can ones fully and correctly understand the content information contained in the cross-media complex, which also adds difficulty in cross-media information recommendation process. At the same time, data sparsity, cold start and scalability issues of traditional recommendation system have long been unsolved, and as such it cannot adapt to the personalized service needs in cross-media applications. Focusing on the field of media information recommendation and taking the media data, user behavior data and project attribute information as the information source, this paper aims at researching the cross-domain recommendation algorithm. With the help of the label data, matrix decomposition, the author constructs a media-oriented cross-domain recommendation model in order to improve the recommendation accuracy and solve the data sparsity, cold start problems of media information recommendation technology, exploring a high-accurate media-oriented cross-domain recommendation method.
C1 [Li, Chen; Yuan, Xinrui] Commun Univ China, Beijing, Peoples R China.
C3 Communication University of China
RP Li, C (corresponding author), Commun Univ China, Beijing, Peoples R China.
EM bjgydxdzgch@126.com
FU Fundamental Research Funds for the Central Universities; University
   Research Program of Communication University of China [3132018XNG1841]
FX The work is supported by grants from the Fundamental Research Funds for
   the Central Universities and University Research Program of
   Communication University of China (3132018XNG1841). We thank the
   reviewers and editor for their helpful comments.
CR Adomavicius G, 2015, IEEE T KNOWL DATA EN, V27, P1573, DOI 10.1109/TKDE.2014.2384502
   Anand D, 2011, EXPERT SYST APPL, V38, P5101, DOI 10.1016/j.eswa.2010.09.141
   [Anonymous], 2013, P 7 ACM C REC SYST
   [Anonymous], 2012, P 18 ACM SIGKDD INT
   Bobadilla J, 2011, KNOWL-BASED SYST, V24, P1310, DOI 10.1016/j.knosys.2011.06.005
   Chen C, 2018, IEEE INT C RFID APR, P1
   Chun-Hua YU, 2017, ACTA ELECT SIN, V45, P1530
   Cook D, 2013, KNOWL INF SYST, V36, P537, DOI 10.1007/s10115-013-0665-3
   Cremonesi P., 2011, 2011 IEEE International Conference on Data Mining Workshops, P496, DOI 10.1109/ICDMW.2011.57
   Dou YT, 2016, INT CONF SEMANT, P40, DOI [10.1109/SKG.2016.014, 10.1109/SKG.2016.23]
   Enrich M, 2013, LECT NOTES BUS INF P, V152, P101
   [范利云 Fan Liyun], 2017, [电子学报, Acta Electronica Sinica], V45, P2057
   [方耀宁 Fang Yaoning], 2013, [电子与信息学报, Journal of Electronics & Information Technology], V35, P3046
   Fernandez-Tobias Cantador I, 2014, P 1 WORKSH NEW TREND, P34
   Fernández-Tobías I, 2014, LECT NOTES BUS INF P, V188, P125
   [高全力 Gao Quanli], 2015, [计算机学报, Chinese Journal of Computers], V38, P1767
   Han TT, 2017, IEEE T MULTIMEDIA, V19, P712, DOI 10.1109/TMM.2016.2631881
   Hsieh C.-J., 2011, P 17 ACM SIGKOD INT, P1064, DOI [DOI 10.1145/2020408.2020577, 10.1145/2020408.2020577.38]
   Hu Y, 2015, IEEE T SERV COMPUT, V8, P782, DOI 10.1109/TSC.2014.2381611
   Huang Cheng-Hui, 2011, Chinese Journal of Computers, V34, P856, DOI 10.3724/SP.J.1016.2011.00856
   Huang Z, 2007, IEEE INTELL SYST, V22, P68, DOI 10.1109/MIS.2007.4338497
   Hui-Si OU, 2016, J CHIN COMPUT SYST, V37, P1411
   Jiang M, 2015, IEEE T KNOWL DATA EN, V27, P3084, DOI 10.1109/TKDE.2015.2432811
   Jie-Yue HE, 2016, CHIN J COMPUT, V1, P183
   Kim S., 2018, NAT COMMUN, V6, P1
   [孔欣欣 Kong Xinxin], 2017, [计算机学报, Chinese Journal of Computers], V40, P1440
   Koren Y, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P447
   Lei XJ, 2016, IEEE T MULTIMEDIA, V18, P1910, DOI 10.1109/TMM.2016.2575738
   Li B., 2009, P 26 ANN INT C MACH, P617, DOI DOI 10.1145/1553374.1553454
   Li B, 2015, IEEE T CYBERNETICS, V45, P1054, DOI 10.1109/TCYB.2014.2343982
   Li B, 2011, PROC INT C TOOLS ART, P1085, DOI 10.1109/ICTAI.2011.184
   Li B, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P2052
   Li J, 2014, COMPUT THERM SCI
   Li KL, 2015, IEEE T PARALL DISTR, V26, P196, DOI 10.1109/TPDS.2014.2308221
   Li L, 2015, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2757282
   Liu JX, 2016, IEEE T SERV COMPUT, V9, P686, DOI 10.1109/TSC.2015.2433251
   [刘梦娟 Liu Mengjuan], 2017, [计算机学报, Chinese Journal of Computers], V40, P634
   Liu NathanNan., 2011, RecSys, P37
   Bach NX, 2016, INFORM SCIENCES, V352, P48, DOI 10.1016/j.ins.2016.03.006
   Pan Weike, 2011, P 22 INT JOINT C ART, P2318
   Rai S, 2017, ACM, P32
   Salakhutdinov Ruslan, 2008, P INT C MACH LEARN, P880, DOI [10.1145/1390156.1390267, DOI 10.1145/1390156.1390267]
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Singh A, 2008, INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P650
   Sun Guang-Fu, 2013, Journal of Software, V24, P2721, DOI 10.3724/SP.J.1001.2013.04478
   Sun LF, 2017, IEEE T MULTIMEDIA, V19, P609, DOI 10.1109/TMM.2016.2635589
   Tan SL, 2014, NEUROCOMPUTING, V127, P124, DOI 10.1016/j.neucom.2013.08.034
   [王俊 Wang Jun], 2017, [计算机学报, Chinese Journal of Computers], V40, P2367
   Wu Q., 2018, P 14 WEB INF SYST AP, P263
   Wu S, 2016, IEEE T HUM-MACH SYST, V46, P908, DOI 10.1109/THMS.2016.2586480
   Wu XW, 2019, NAT PROD RES, V33, P204, DOI 10.1080/14786419.2018.1443095
   Xiong L, 2010, P SIAM INT C DAT MIN, P211, DOI DOI 10.1137/1.9781611972801.19
   [印桂生 Yin Guisheng], 2014, [电子学报, Acta Electronica Sinica], V42, P904
   Yuan T, 2016, MULTIMEDIA SYST, V22, P51, DOI 10.1007/s00530-014-0392-y
   [张磊 Zhang Lei], 2017, [计算机学报, Chinese Journal of Computers], V40, P1394
   Zhang Liang, 2013, Journal of University of Electronic Science and Technology of China, V42, P154, DOI 10.3969/j.issn.1001-0548.2013.01.031
   Zhang YuXia Zhang YuXia, 2010, Chinese Journal of Zoonoses, V26, P725
   Zhao WNX, 2016, IEEE T KNOWL DATA EN, V28, P1147, DOI 10.1109/TKDE.2015.2508816
   Zhao Z, 2016, IEEE T KNOWL DATA EN, V28, P2522, DOI 10.1109/TKDE.2016.2569096
   [朱坤广 Zhu Kunguang], 2016, [计算机应用与软件, Computer Applications and Software], V33, P66
NR 60
TC 2
Z9 2
U1 1
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28757
EP 28777
DI 10.1007/s11042-018-6720-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700023
DA 2024-07-18
ER

PT J
AU Li, RQ
   Tian, J
   Chua, MCH
AF Li, Ruiqi
   Tian, Jing
   Chua, Matthew Chin Heng
TI Facial expression classification using salient pattern driven integrated
   geometric and textual features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression classification; Geometric features; Textual features;
   Salient patterns
ID RECOGNITION; MODEL
AB Facial expression classification aims to recognize human emotion via face images. The major challenge of facial expression classification is how to extract discriminative features from the human face images to differentiate various emotions. To tackle this challenge, a new feature extraction approach is proposed in this paper. The proposed approach defines a new set of salient patterns at the facial keypoint locations. This is in contrast to conventional approaches that either represent the whole face image as a regular grid or use local image patches centered at all facial key point locations. Driven by the proposed salient patterns, both the geometric and textual features are extracted and then concatenated and further incorporated into a machine learning framework to perform facial expression classification. The proposed approach is evaluated in the well-known CK + benchmark dataset to demonstrate its superior performance.
C1 [Li, Ruiqi; Tian, Jing; Chua, Matthew Chin Heng] Natl Univ Singapore, Inst Syst Sci, Singapore 119615, Singapore.
C3 National University of Singapore
RP Tian, J (corresponding author), Natl Univ Singapore, Inst Syst Sci, Singapore 119615, Singapore.
EM liruiqi@u.nus.edu; liruiqi@u.nus.edu; mattchua@nus.edu.sg
RI Chua, Matthew/P-6434-2014; Tian, Jing/ABI-2886-2020
OI Tian, Jing/0000-0002-4084-6911; LI, RUIQI/0000-0003-0145-1519; Matthew,
   Chua/0000-0002-5200-5079
CR Acevedo D, 2017, IEEE INT CONF AUTOMA, P802, DOI 10.1109/FG.2017.101
   [Anonymous], 2017, MULTIMED TOOLS APPL
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Deshmukh S, 2016, IET BIOMETRICS, V5, P155, DOI 10.1049/iet-bmt.2014.0104
   Fernandes JD, 2016, SIBGRAPI, P347, DOI [10.1109/SIBGRAPI.2016.52, 10.1109/SIBGRAPI.2016.055]
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7803, DOI 10.1007/s11042-016-3418-y
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7921, DOI 10.1007/s11042-016-3428-9
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Hsieh CC, 2016, MULTIMED TOOLS APPL, V75, P6663, DOI 10.1007/s11042-015-2598-1
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Jain S., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1642, DOI 10.1109/ICCVW.2011.6130446
   Kim BK, 2016, J MULTIMODAL USER IN, V10, P173, DOI 10.1007/s12193-015-0209-0
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Majumder A, 2018, IEEE T CYBERNETICS, V48, P103, DOI 10.1109/TCYB.2016.2625419
   Martinez Brais., 2017, IEEE Trans on Affective Computing
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Sarkar S, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER, AND OPTIMIZATION TECHNIQUES (ICEECCOT), P613
   Siddiqi MH, 2018, MULTIMED TOOLS APPL, V77, P917, DOI 10.1007/s11042-016-4321-2
   Takalkar M, 2018, MULTIMED TOOLS APPL, V77, P19301, DOI 10.1007/s11042-017-5317-2
   YU J, 2017, MULTIMED TOOLS APPL, V76, P653, DOI DOI 10.1007/S11042-016-3883-3
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
NR 27
TC 7
Z9 8
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28971
EP 28983
DI 10.1007/s11042-018-6133-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700034
DA 2024-07-18
ER

PT J
AU Lin, YF
   Wu, LX
AF Lin, Yanfen
   Wu, Liuxi
TI Improved abrasive image segmentation method based on bit-plane and
   morphological reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bit-plane; Morphological reconstruction; Blanket fractal dimension;
   Image segmentation; Fixing features
ID FRACTAL ANALYSIS
AB Image segmentation, an indispensable stage of digital image processing for computer vision, plays an important role in linking up of image processing, image recognition and image analysis. The blanket fractal dimension method can help segment images with irregular objects, and has been used in different fields. Morphology is an important method in processing images through using erosion operation, dilation operation, opening operation and closing operation, which help perfect incomplete edges or contours of objects to a certain extent. The traditional fractal dimension method is poor in segmenting irregular objects from a complex background because it cannot distinguish the close grayscale between the objects and the complex background besides different sizes of the objects, which are easy to cause under-segmentation. To improve the segmentation effect, an improved image segmentation method based on bit-plane and morphological reconstruction is proposed in the present work. The traditional blanket fractal dimension method is used to make a coarse segmentation of the pending images, and the coarse segmented results are further improved through using bit-plane and morphological reconstruction. The reconstruction role is to compensate the missing features and eliminate the invalid features. Based on the fine segmented results carried out in the experiments, it is found that the proposed method can obtain more accurate segmentation effect than the traditional methods in image processing.
C1 [Lin, Yanfen; Wu, Liuxi] Xiamen Inst Technol, Sch Comp & Artificial Intelligence, Xiamen 361021, Fujian, Peoples R China.
C3 Xiamen Institute of Technology
RP Lin, YF (corresponding author), Xiamen Inst Technol, Sch Comp & Artificial Intelligence, Xiamen 361021, Fujian, Peoples R China.
EM linyanf@qq.com
FU National Natural Science Foundation of China [51675193]; project of
   Distinguished Young Scientific and Technological Talents in Fujian
   Provincial Higher Institutions (2017); Natural Science Foundation of
   Fujian Province [2016 J01235]; Fujian Provincial Department of Education
   of China [JAT160633]
FX The authors would like to thank the financial support of the projects
   from the National Natural Science Foundation of China (Grant No.
   51675193), the project of Distinguished Young Scientific and
   Technological Talents in Fujian Provincial Higher Institutions (2017),
   the project of Natural Science Foundation of Fujian Province (Grant No.
   2016 J01235), and the project of Fujian Provincial Department of
   Education of China (Grant No. JAT160633).
CR Atkociunas E., 2005, Nonlinear Analysis Modelling and Control, V10, P315
   Baba N, 1996, J ELECTRON MICROSC, V45, P298, DOI 10.1093/oxfordjournals.jmicro.a023446
   Bavier A, 2006, ACM SIGCOMM COMP COM, V36, P3, DOI 10.1145/1151659.1159916
   Chen Shili, 2014, Journal of Computer Applications, V34, P3365, DOI 10.11772/j.issn.1001-9081.2014.11.3365
   Deng X, 2016, ACSR ADV COMPUT, V50, P365
   Gong J.F, 2006, DIAM ABRAS ENG, V154, P14, DOI [10.13394/j.cnki.jgszz.2006.04.005, DOI 10.13394/J.CNKI.JGSZZ.2006.04.005]
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   Guo Heng-guang, 2014, Journal of Chinese Computer Systems, V35, P1392
   Hemachander S, 2007, PATTERN RECOGN LETT, V28, P119, DOI 10.1016/j.patrec.2006.06.005
   Kang CC, 2007, PATTERN RECOGN, V40, P609, DOI 10.1016/j.patcog.2006.03.016
   KELLER JM, 1989, COMPUT VISION GRAPH, V45, P150, DOI 10.1016/0734-189X(89)90130-8
   Kisan S., 2017, INT RES J ENG TECHNO, V4, P1102
   LI H, 1995, IEEE T IMAGE PROCESS, V4, P320, DOI 10.1109/83.366480
   Lin YF, 2015, P INT C EN ENV MAT S, P823
   Liu YN, 2017, J CHIN INST ENG, V40, P161, DOI 10.1080/02533839.2017.1294994
   [刘永学 LIU Yongxue], 2006, [遥感学报, Journal of Remote Sensing], V10, P350
   Miao Q, 2013, INT J ADV MANUF TECH, V68, P2229, DOI 10.1007/s00170-013-4823-2
   Oommen RS, 2016, PROC TECH, V24, P1452, DOI 10.1016/j.protcy.2016.05.176
   Peleg S, 1984, IEEE Trans Pattern Anal Mach Intell, V6, P518, DOI 10.1109/TPAMI.1984.4767557
   PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591
   Ricotta C, 1998, INT J REMOTE SENS, V19, P871, DOI 10.1080/014311698215766
   Shengui Huang, 2013, International Journal of Abrasive Technology, V6, P147
   Song HR, 2007, CHIN J SCI INSTRUM, V28, P467
   Sun TZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P928
   Nguyen TD, 2016, MULTIMED TOOLS APPL, V75, P8319, DOI 10.1007/s11042-015-2752-9
   [吴涛 Wu Tao], 2014, [中国图象图形学报, Journal of Image and Graphics], V19, P1
   Wu WY, 2016, J HUAQIAO U, V37, P422
   Wu YP, 2017, MULTIMED TOOLS APPL, V76, P19781, DOI 10.1007/s11042-015-3192-2
   Zahouani H, 2017, WEAR, V376, P178, DOI 10.1016/j.wear.2017.01.087
   Zhang L, 2011, SPRINGER SER DEMOGR, V27, P3, DOI 10.1007/978-90-481-8939-7_1
   [张思思 Zhang Sisi], 2015, [计算机科学, Computer Science], V42, P292
   Zhang W, 2018, NEUROCOMPUTING, V275, P781, DOI 10.1016/j.neucom.2017.09.012
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P2318, DOI 10.1109/TIP.2011.2170079
   Zhang WD, 2017, IEEE T MULTIMEDIA, V19, P935, DOI 10.1109/TMM.2016.2642780
   [朱烨 Zhu Ye], 2016, [计算机应用与软件, Computer Applications and Software], V33, P221
NR 35
TC 9
Z9 8
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29197
EP 29210
DI 10.1007/s11042-018-6687-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700044
DA 2024-07-18
ER

PT J
AU Ren, J
   Chen, G
   Li, X
   Mao, K
AF Ren, Jinxiong
   Chen, Gang
   Li, Xiaoyan
   Mao, Kuang
TI Striped-texture image segmentation with application to multimedia
   security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Multimedia modeling; Striped texture image; Image
   segmentation; Multimedia security
AB In today's rapid growth of volume of multimedia data, security is important yet challenging problem in multimedia applications. Image, which covers the highest percentage of the multimedia data, it is very important for multimedia security. Image segmentation is utilized as a fundamental preprocessing of various multimedia applications such as surveillance for security by breaking a given image into multiple salient regions. In this paper, we present a new image segmentation approach based on frequency-domain filtering for images with stripe texture, and generalize it to lattice fence images. Our method significantly reduces the impact of stripes on segmentation performance. The approach proposed in this paper consists of three phases. Given the images, we weaken the effect of stripe texture by filtering in the frequency domain automatically. Then, structure-preserving image smoothing is employed to remove texture details and extract the main image structures. Last, we use an effective threshold method to produce segmentation results. Our method achieves very promising results for the test image dataset and could benefit a number of new multimedia applications such as public security.
C1 [Ren, Jinxiong; Chen, Gang] Zhejiang Univ, Coll Comp Sci & Technol, CaoGuangBiao Bldg,38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
   [Li, Xiaoyan; Mao, Kuang] Netease Hangzhou Inc, Hangzhou Res Inst, 599 Wangshang Rd, Hangzhou 310052, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Ren, J (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, CaoGuangBiao Bldg,38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM renjx@zju.edu.cn; cg@zju.edu.cn; kricellee@gmail.com;
   hzmaokuang@corp.netease.com
FU National Natural Science Foundation of China [61472348]
FX This work was supported by the National Natural Science Foundation of
   China (grant number 61472348).
CR [Anonymous], 2009, P 17 ACM INT C MULT
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P4380, DOI 10.1109/TIP.2013.2273665
   Bouali M, 2011, IEEE T GEOSCI REMOTE, V49, P2924, DOI 10.1109/TGRS.2011.2119399
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Chang Y, 2016, IEEE T GEOSCI REMOTE, V54, P7018, DOI 10.1109/TGRS.2016.2594080
   Chen JS, 2003, IEEE T GEOSCI REMOTE, V41, P2119, DOI 10.1109/TGRS.2003.817206
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Fang MY, 2012, MULTIMED TOOLS APPL, V57, P501, DOI 10.1007/s11042-010-0655-3
   Grady L, 2012, LECT NOTES COMPUT SC, V7573, P430, DOI 10.1007/978-3-642-33709-3_31
   Hong CQ, 2016, MULTIMED TOOLS APPL, V75, P1459, DOI 10.1007/s11042-014-2305-7
   Karacan L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508403
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Lin C, 2016, MULTIMED TOOLS APPL
   Münch B, 2009, OPT EXPRESS, V17, P8567, DOI 10.1364/OE.17.008567
   Pande-Chhetri R, 2011, ISPRS J PHOTOGRAMM, V66, P620, DOI 10.1016/j.isprsjprs.2011.04.003
   Rakwatin P, 2009, IEEE T GEOSCI REMOTE, V47, P613, DOI 10.1109/TGRS.2008.2003436
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Shen HF, 2009, IEEE T GEOSCI REMOTE, V47, P1490, DOI 10.1109/TGRS.2008.2005780
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tang JH, 2014, MULTIMEDIA SYST, V20, P633, DOI 10.1007/s00530-014-0423-8
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   WEGENER M, 1990, INT J REMOTE SENS, V11, P859, DOI 10.1080/01431169008955060
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Zhang FH, 2015, IEEE I CONF COMP VIS, P361, DOI 10.1109/ICCV.2015.49
   Zhang LM, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2886775
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P535, DOI 10.1109/TCYB.2015.2408592
   Zhang LM, 2016, IEEE T IMAGE PROCESS, V25, P553, DOI 10.1109/TIP.2015.2502147
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhang SL, 2013, IEEE T IMAGE PROCESS, V22, P2889, DOI 10.1109/TIP.2013.2251650
   Zhang Z, 2005, P SOC PHOTO-OPT INS, V6027, P989
NR 35
TC 2
Z9 2
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 26965
EP 26978
DI 10.1007/s11042-017-4479-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000008
DA 2024-07-18
ER

PT J
AU Sun, JG
   Wang, WS
   Zhang, KJ
   Zhang, LG
   Lin, Y
   Han, QL
   Da, QA
   Kou, L
AF Sun, Jianguo
   Wang, Wenshan
   Zhang, Kejia
   Zhang, Liguo
   Lin, Yun
   Han, Qilong
   Da, Qingan
   Kou, Liang
TI A multi-focus image fusion algorithm in 5G communications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 5G network; Cloud computing; Region mosaicking; Contrast pyramids;
   Multi-focus images fusion
ID SEGMENTATION; FRAMEWORK
AB In this paper, we first build a mobile cloud platform that users can upload multi-focus images or download full-focus images through the 5G network. Then we design a method named Region Mosaicking on Contrast Pyramid (RMCP) for image fusion on the cloud platform. In the RMCP method, we apply the Sum-Modified-Laplacian to measure the focus of the multi-focus image, and use the density-based region growth algorithm to segment the focus region mask for each image. Finally, the mask is decomposed into a mask pyramid to monitor the mosaic region of the contrast pyramid. The experimental results show that RMCP based on 5G network outperforms other methods. In addition, RMCP is suitable for mobile devices.
C1 [Sun, Jianguo; Wang, Wenshan; Zhang, Kejia; Zhang, Liguo; Han, Qilong; Da, Qingan; Kou, Liang] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
   [Lin, Yun] Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Engineering University; Harbin Engineering University
RP Lin, Y (corresponding author), Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Heilongjiang, Peoples R China.
EM sunjianguo@hrbeu.edu.cn; wangwenshan@hrbeu.edu.cn;
   zhangkejia@hrbeu.edu.cn; zhangliguo@hrbeu.edu.cn; linyun@hrbeu.edu.cn;
   hanqilong@hrbeu.edu.cn; da_qing_an@hrbeu.edu.cn; kouliang@hrbeu.edu.cn
RI zhang, ke/AAH-8217-2019; Sun, Jianguo/AAU-2796-2020; Yun,
   Lin/C-4759-2019; Wang, wenshan/JDW-8228-2023; LIGUO, ZHANG/AAC-8765-2021
OI Yun, Lin/0000-0003-1379-9301; 
FU NSFC of China [61472096, 61771154, 61501132, 61370084, 61202455,
   61301095]; China Postdoctoral Science Foundation [2016M591515]
FX This work was supported by project of NSFC of China (61472096, 61771154,
   61501132, 61370084, 61202455, 61301095), China Postdoctoral Science
   Foundation (2016M591515).
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718
   [Anonymous], 2017, IEEE T INF FORENSICS
   Cao L, 2015, IEEE SIGNAL PROC LET, V22, P220, DOI 10.1109/LSP.2014.2354534
   Chen HY, 2012, MULTIMED TOOLS APPL, V60, P495, DOI 10.1007/s11042-011-0820-3
   Dev Dipayan, 2014, 2014 2nd IEEE International Conference on Mobile Cloud Computing, Services and Engineering (MobileCloud), P252, DOI 10.1109/MobileCloud.2014.41
   Ding GR, 2016, IEEE J SEL AREA COMM, V34, P107, DOI 10.1109/JSAC.2015.2452532
   Ding GR, 2013, IEEE SIGNAL PROC MAG, V30, P126, DOI 10.1109/MSP.2013.2251071
   Dong YB, 2014, APPL MECH MATER, V525, P711, DOI 10.4028/www.scientific.net/AMM.525.711
   Eckhorn R., 2014, NEURAL COMPUT, V2, P293
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Gupta N, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P1061
   Han S. H., 2016, ADV MULTIMEDIA UBIQU
   Hariharan H., 2007, P IEEE C COMPUTER VI, P1
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   Hung SH, 2012, COMPUT MATH APPL, V63, P573, DOI 10.1016/j.camwa.2011.10.044
   Ji XX, 2017, MULTIMED TOOLS APPL, V76, P17633, DOI 10.1007/s11042-015-2879-8
   Kitanov S, 2014, 2014 SIXTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, COMMUNICATION SYSTEMS AND NETWORKS (CICSYN), P153, DOI 10.1109/CICSyN.2014.41
   Kubota A, 2005, IEEE T IMAGE PROCESS, V14, P1848, DOI 10.1109/TIP.2005.854468
   Kumar R, 2014, INT C COMP SCI APPL, P663
   Lathey Ankita, 2015, ACM T MULTIM COMPUT, V11, P1
   Lee K, 2015, KOREAN J REMOTE SENS, V31, P1, DOI 10.7780/kjrs.2015.31.1.1
   Lei JJ, 2017, IEEE T MULTIMEDIA, V19, P1442, DOI 10.1109/TMM.2017.2660440
   Leung Y, 2014, IEEE GEOSCI REMOTE S, V11, P985, DOI 10.1109/LGRS.2013.2284282
   Li HF, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-39
   Li MJ, 2014, APPL MECH MATER, V525, P715, DOI 10.4028/www.scientific.net/AMM.525.715
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li W, 2011, ELECT SCI TECHNOL, V3
   Lin Y, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16101675
   Lin Y, 2016, J SUPERCOMPUT, V72, P2874, DOI 10.1007/s11227-016-1681-3
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   Paul S, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501231
   Saha A, 2013, DIGIT SIGNAL PROCESS, V23, P1121, DOI 10.1016/j.dsp.2013.03.001
   Saravanakumar, 2015, 3 INT C IEEE SIGN PR, P1
   Singh R., 2015, INT J INNOVATIVE RES, V1, P259
   Thakur PK, 2015, INT C ADV COMPUT COM, P530, DOI 10.1109/ACCT.2015.104
   Tian J, 2010, IEEE IMAGE PROC, P1205, DOI 10.1109/ICIP.2010.5651791
   Wang RW, 2012, TEXT RES J, V82, P352, DOI 10.1177/0040517511407377
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZB, 2010, PATTERN RECOGN, V43, P2003, DOI 10.1016/j.patcog.2010.01.011
   Wencheng Wang, 2011, Journal of Computers, V6, P2559, DOI 10.4304/jcp.6.12.2559-2566
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Zhang BH, 2014, OPTIK, V125, P296, DOI 10.1016/j.ijleo.2013.07.002
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
NR 43
TC 3
Z9 3
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28537
EP 28556
DI 10.1007/s11042-018-5790-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700011
DA 2024-07-18
ER

PT J
AU Zhu, JQ
   Du, YZ
   Hu, Y
   Zheng, LX
   Cai, CH
AF Zhu, Jianqing
   Du, Yongzhao
   Hu, Yang
   Zheng, Lixin
   Cai, Canhui
TI VRSDNet: vehicle re-identification with a shortly and densely connected
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle re-identification; Convolutional neural network; Deep learning
AB Vehicle re-identification aiming to match vehicle images captured by different cameras plays an important role in video surveillance for public security. In this paper, we solve Vehicle Re-identification with a Shortly and Densely connected convolutional neural Network (VRSDNet). The proposed VRSDNet mainly consists of a list of short and dense units (SDUs), necessary pooling and spatial normalization layers. Specifically, each SDU contains a short list of densely connected convolutional layers and each convolutional layer is of the same appropriate channels. As a result, the number of connections and the input channel of each convolutional layer are restricted in each SDU, and the architecture of VRSDNet is simple. Extensive experiments on both VeRi and VehicleID datasets show that the proposed VRSDNet is obviously superior to multiple state-of-the-art vehicle re-identification methods in terms of accuracy and speed.
C1 [Zhu, Jianqing; Du, Yongzhao; Zheng, Lixin; Cai, Canhui] Huaqiao Univ, Coll Engn, 269 Chenghua North Rd, Quanzhou, Fujian, Peoples R China.
   [Hu, Yang] Minist Publ Secur Peoples Republ China, Res Inst 1, 1 Shouti South Rd, Beijing 100048, Peoples R China.
C3 Huaqiao University; Ministry of Public Security (China)
RP Zhu, JQ (corresponding author), Huaqiao Univ, Coll Engn, 269 Chenghua North Rd, Quanzhou, Fujian, Peoples R China.
EM jqzhu@hqu.edu.cn; yongzhaodu@126.com; xdwhoyoung@gmail.com;
   zlx@hqu.edu.cn; chcai@hqu.edu.cn
RI Zhu, Jianqing/AHA-0351-2022
OI Zhu, Jianqing/0000-0001-8840-3629
FU National Natural Science Foundation of China [61602191, 61672521,
   61375037, 61473291, 61572501, 61572536, 61502491, 61372107, 61401167];
   Natural Science Foundation of Fujian Province [2018J01090, 2016J01308];
   High-level Talent Innovation Program of Quanzhou City [2017G027,
   2017G036]; Scientific and Technology Founds of Xiamen [3502Z20173045];
   Promotion Program for Young and Middle-aged Teacher in Science and
   Technology Research of Huaqiao University [ZQN-PY418, ZQN-YX403];
   Scientific Research Funds of Huaqiao University [16BS108]
FX This work was supported in part by the National Natural Science
   Foundation of China under the Grants 61602191, 61672521, 61375037,
   61473291, 61572501, 61572536, 61502491, 61372107 and 61401167, in part
   by the Natural Science Foundation of Fujian Province under the Grants
   2018J01090 and 2016J01308, in part by High-level Talent Innovation
   Program of Quanzhou City under the Grants 2017G027 and 2017G036, in part
   by the Scientific and Technology Founds of Xiamen under the Grant
   3502Z20173045, in part by the Promotion Program for Young and
   Middle-aged Teacher in Science and Technology Research of Huaqiao
   University under the Grants ZQN-PY418 and ZQN-YX403, and in part by the
   Scientific Research Funds of Huaqiao University under the Grant 16BS108.
CR [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2016, P 2016 IEEE INT C MU, DOI DOI 10.1155/2016/8191254
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   Gray D, 2007, WORKSH PERF EV TRACK
   Gupta RC, 1999, BIOMETRICAL J, V41, P431, DOI 10.1002/(SICI)1521-4036(199907)41:4<431::AID-BIMJ431>3.0.CO;2-U
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu HY, 2016, PROC CVPR IEEE, P2167, DOI 10.1109/CVPR.2016.238
   Liu XC, 2018, IEEE T MULTIMEDIA, V20, P645, DOI 10.1109/TMM.2017.2751966
   Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827
   Simonyan K., 2014, 14091556 ARXIV
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Yi D, 2014, P IEEE INT C PATT RE
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng L, 2014, PROC CVPR IEEE, P1963, DOI 10.1109/CVPR.2014.252
   Zhu J, 2018, P IEEE INT C PATT RE
   Zhu JB, 2018, IEEE T ENERGY CONVER, V33, P773, DOI 10.1109/TEC.2017.2764089
NR 21
TC 18
Z9 18
U1 1
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29043
EP 29057
DI 10.1007/s11042-018-6270-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700038
DA 2024-07-18
ER

PT J
AU Elhaminia, B
   Harati, A
   Taherinia, A
AF Elhaminia, Behnaz
   Harati, Ahad
   Taherinia, Amirhossein
TI A probabilistic framework for copy-move forgery detection based on
   Markov Random Field
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery detection; Image forensics; Markov random filed;
   Binary labeling
ID TRANSFORM
AB Copy-move forgery is one of the most common kind of image tampering where some part of an image is copied, may be with minor modifications, pasted to another area of the same image. With the growing usage of images in todays life, image authenticity has become a vital issue and consequently many image forgery detection techniques have been presented. In this paper, for the first time, we propose to treat copy-move forgery detection as labeling problem in a Markov Random Field. To gain a proper balance between precision and speed, an over segmentation is performed as a preprocessing step to obtain superpixels which are then regarded as nodes of the markov network. Intelligent selection of unary and binary potentials let the maximum a posteriori labeling to be a precise map of the forged regions. Qualitative and quantitative comparison with the state-of-the-art methods using public benchmarks demonstrate that the proposed method can improve precision while keeping the processing demands low.
C1 [Elhaminia, Behnaz; Harati, Ahad; Taherinia, Amirhossein] Ferdowsi Univ Mashhad, Dept Comp Engn, Fac Engn, Mashhad, Razavi Khorasan, Iran.
C3 Ferdowsi University Mashhad
RP Harati, A (corresponding author), Ferdowsi Univ Mashhad, Dept Comp Engn, Fac Engn, Mashhad, Razavi Khorasan, Iran.
EM behnazelhaminia@stu.um.ac.ir; a.harati@um.ac.ir; taherinia@um.ac.ir
RI Harati, Ahad/P-4468-2015; Taherinia, Amir Hossein/HTP-1792-2023;
   Taherinia, Amir Hossein/AAC-9575-2020
OI Harati, Ahad/0000-0001-7263-0309; Taherinia, Amir
   Hossein/0000-0002-5103-4812; Elhaminia, Behnaz/0000-0002-3818-7064
CR Achanta R., 2010, EPFL Technical Report 149300, V6, P15
   Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2004, Int. J. Comput. Vis., DOI [DOI 10.1023/B:VISI.0000029664.99615.94, 10.1023/B:VISI.0000029664.99615.94]
   [Anonymous], P SAT REM SENS GIS A
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bayram S, 2009, IEEE ICASSP
   BESAG J, 1986, J R STAT SOC B, V48, P259
   BhavyaBhanu MP, 2017, 11 INT C INT SYST CO, P228
   Bi XL, 2018, MULTIMED TOOLS APPL, V77, P363, DOI 10.1007/s11042-016-4276-3
   Chen Beijing, 2018, MULTIMEDIA TOOLS APP
   Dixit R, 2017, IET IMAGE PROCESS, V11, P301, DOI 10.1049/iet-ipr.2016.0537
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Haghighi BB, 2018, J VIS COMMUN IMAGE R, V50, P49, DOI 10.1016/j.jvcir.2017.09.017
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Koller D., 2009, Probabilistic graphical models: principles and techniques
   Lee J, 2015, DETECTION COPY MOVE
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Li Y, 2018, IEEE T INFORM FORENS
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Park CS, 2018, MULTIMED TOOLS APPL, V77, P16795, DOI 10.1007/s11042-017-5248-y
   Rangarajan A, 1995, MARKOV RANDOM FILEDS
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Satheesh S, 2017, INT J ENG TRENDS TEC, VV45, P285
   Sekhar R., 2016, The International Conference on Soft Computing Systems, P223
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Soni B, 2019, J INFORM SECURITY AP
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Vedaldi A, 2008, VLFEAT OPEN PORTABAL
   Yang B, 2018, MULTIMED TOOLS APPL, V77, P837, DOI 10.1007/s11042-016-4289-y
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Yeap YY, 2018, SIGNAL PROCESSING IT
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
NR 38
TC 12
Z9 13
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25591
EP 25609
DI 10.1007/s11042-019-7713-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700016
DA 2024-07-18
ER

PT J
AU Kowsalya, S
   Periasamy, PS
AF Kowsalya, S.
   Periasamy, P. S.
TI Recognition of Tamil handwritten character using modified neural network
   with aid of elephant herding optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Character recognition; Gaussian filter; Binarization; Skew detection;
   Segmentation; Spatial space detection; Horizontal histogram; Feature
   extraction; Neural network
ID ACCURATE
AB Nowadays, recognition of machine printed or hand printed document is essential part in applications. Optical character recognition is one of the techniques which are used to convert the printed or hand written file into its corresponding text format. Tamil is the south Indian language spoken widely in Tamil Nadu. It has the longest unbroken literary tradition amongst Dravidian language. Tamil character recognition (TCR) is one of the challenging tasks in optimal character recognition. It is used for recognizing the characters from scanned input digital image and converting them into machine editable form. Recognition of handwritten in Tamil character is very difficult, due to variations in size, style and orientation angle. Character editing and reprinting of text document that were printed on paper are time consuming and low accuracy. In order to overcome this problem, the proposed technique utilizes effective Tamil character recognition. The proposed method has four main process such as preprocessing process, segmentation process, feature extraction process and recognition process. For preprocessing, the input image is fed to Gaussian filter, Binarization process and skew detection technique. Then the segmentation process is carried out, here line and character segmentation is done. From the segmented output, the features are extracted. After that the feature extraction, the Tamil character is recognized by means of optimal artificial neural network. Here the traditional neural network is modified by means of optimization algorithm. In neural network, the weights are optimized by means of Elephant Herding Optimization. The performance of the proposed method is assessed with the help of the metrics namely Sensitivity, Specificity and Accuracy. The proposed approach is experimented and its results are analyzed to visualize the performance. The proposed approach will be implemented in MATLAB.
C1 [Kowsalya, S.] United Inst Technol, Dept Comp Sci & Engn, Coimbatore 641020, Tamil Nadu, India.
   [Periasamy, P. S.] KSR Coll Engn, Dept ECE, Tiruchengode 637215, India.
RP Kowsalya, S (corresponding author), United Inst Technol, Dept Comp Sci & Engn, Coimbatore 641020, Tamil Nadu, India.
EM skowsalya1885@gmail.com
RI PERIASAMY, P.S/AAI-1308-2019
OI PS, PERIASAMY/0000-0001-5670-3512
CR Ajantha Devi V, 2014, INT J COMPUTER SCI T, V2, P127
   [Anonymous], J BIOINFORM RES STUD
   [Anonymous], 2019, ADV INTELLIGENT SYST
   [Anonymous], ARXIV180410563
   Banumathi P, 2011, PROC INT C PROCESS A, P1
   Banumathi P, 2017, INT J RECENT INNOVAT, V02, P1
   Bharath A, 2012, IEEE T PATTERN ANAL, V34, P670, DOI 10.1109/TPAMI.2011.234
   Chacko BP, 2012, INT J MACH LEARN CYB, V3, P149, DOI 10.1007/s13042-011-0049-5
   Feng JS, 2017, NANO ENERGY, V36, P1, DOI 10.1016/j.nanoen.2017.04.010
   Guruprasad P, 2016, PROCEDIA COMPUT SCI, V89, P836, DOI 10.1016/j.procs.2016.06.069
   Jiaying Lin DD, 2017, CANCER CELL INT, V17, P1
   Kanimozhi V. M., 2014, INT J COMPUTER SCI I, V5, P1008
   Lee YG, 2017, J VIS COMMUN IMAGE R, V44, P148, DOI 10.1016/j.jvcir.2017.01.027
   Naz S, 2014, PATTERN RECOGN, V47, P1229, DOI 10.1016/j.patcog.2013.09.037
   Pramanik R, 2017, J VIS COMMUN IMAGE R, V20, P1
   Raj M.A.R., 2015, ADV NAT APPL SCI, V9, P367
   Sampath AK, 2017, J CENT SOUTH UNIV, V24, P2862, DOI 10.1007/s11771-017-3701-8
   Sampath AK, 2017, RES ARTICLE, V10, P1
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Semwal VB, 2015, ROBOT AUTON SYST, V65, P65, DOI 10.1016/j.robot.2014.11.010
   Shi C, 2014, ARTICLE INFORM, V31, P1
   Sohal JS, 2016, SCILAB, V10, P1
   Sureshkumar C., 2010, INT J COMPUT SCI ENG, V2, P2261
   Tian S, 2016, CANCER INFORM, V15, P1, DOI 10.4137/CIN.S40300
   Vellingiriraj EK, 2017, NOVEL HYBRID NEURAL, P152
   Venkatesh J, 2009, INT J COMPUT SCI NET, V9, P156
   Wang YL, 2020, J HEALTH PSYCHOL, V25, P416, DOI 10.1177/1359105317739100
   Xiao X, 2017, CHINESE CHARACTER RE, V0, P1
   Yang JC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145800
   Zheng S, 2016, NEW ASTRON, V45, P54, DOI 10.1016/j.newast.2015.11.001
NR 30
TC 25
Z9 25
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 25043
EP 25061
DI 10.1007/s11042-019-7624-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900062
DA 2024-07-18
ER

PT J
AU Xu, Y
   Hou, ZJ
   Liang, JZ
   Chen, C
   Jia, L
   Song, Y
AF Xu, Yan
   Hou, Zhenjie
   Liang, Jiuzhen
   Chen, Chen
   Jia, Liang
   Song, Yi
TI Action recognition using weighted fusion of depth images and skeleton's
   key frames
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth image; Skeleton image; Action recognition; Mutual information;
   Weighted voting
ID AUTOCORRELATION
AB This paper presents a new method for human action recognition fusing depth images and skeletal maps. Each depth image is represented by 2D and 3D auto-correlation of gradients features. A feature using spatial and orientational auto-correlation is extracted from depth images. Mutual information is used to define the similarity of each frame in the skeleton sequence, and then extract the key frames from the skeleton sequence. The skeleton feature extracted from the key frames as complementary features to cope with the temporal information loss in depth images. Each set of feature is used as input to two extreme learning machine classifiers and assign different weight to each set of feature. Using different classifier weights provides more flexible to different features. The final class label is determined according to the fused result. Experiments conducted on MSR_Action3D depth action data set show the accuracy of this proposed method is 1.5% higher than the state-of-the-art action recognition methods.
C1 [Xu, Yan; Hou, Zhenjie; Liang, Jiuzhen; Jia, Liang; Song, Yi] Changzhou Univ, Coll Informat Sci & Engn, Changzhou, Peoples R China.
   [Hou, Zhenjie] Jiangsu Prov Networking & Mobile Internet Technol, Huaian, Peoples R China.
   [Chen, Chen] Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75083 USA.
C3 Changzhou University; University of Texas System; University of Texas
   Dallas
RP Hou, ZJ (corresponding author), Changzhou Univ, Coll Informat Sci & Engn, Changzhou, Peoples R China.; Hou, ZJ (corresponding author), Jiangsu Prov Networking & Mobile Internet Technol, Huaian, Peoples R China.
EM xuyan429720@163.com; houzj@cczu.edu.cn; jzliang@cczu.edu.cn;
   chenchen870712@gmail.com; sanctifier@cczu.edu.cn; 779590468@qq.com
RI Hou, Zhenjie/HKW-7644-2023; Liang, Jiuzhen/HJG-9384-2022
CR [Anonymous], ACTION RECOGNITION D
   [Anonymous], 2012, RECOGNIZING ACTIONS
   [Anonymous], GRADIENT LOCAL AUTO
   [Anonymous], RES HUMAN BEHAV RECO
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], EIGENJOINTS BASED AC
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4651, DOI 10.1007/s11042-016-3284-7
   Chen C, 2016, J REAL-TIME IMAGE PR, V12, P155, DOI 10.1007/s11554-013-0370-1
   Dame A, 2012, IEEE T IMAGE PROCESS, V21, P4190, DOI 10.1109/TIP.2012.2199124
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Kobayashi T, 2012, PATTERN RECOGN LETT, V33, P1188, DOI 10.1016/j.patrec.2012.01.007
   Li W., 2010, Action recognition based on a bag of 3d points
   Liang Feng, 2015, Journal of Computer Aided Design & Computer Graphics, V27, P2419
   Liu J, 2018, IEEE T IMAGE PROCESS, VPP, P1, DOI [10.1109/TIP.2018.28283261409.94376, DOI 10.1109/TIP.2018.28283261409.94376]
   Lu Zhonggiu, 2016, Journal of Computer Applications, V36, P2979, DOI 10.11772/j.issn.1001-9081.2016.11.2979
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Shan Yanhu, 2016, STATUS PROSPECTS J C, V53, P93
   Shotton J., 2013, Real-time human pose recognition in parts from single depth images
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Xu Haining, 2016, Journal of Computer Applications, V36, P568, DOI 10.11772/j.issn.1001-9081.2016.02.0568
   Zhang HL, 2017, NEUROCOMPUTING, V230, P417, DOI 10.1016/j.neucom.2016.12.041
NR 21
TC 8
Z9 10
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 25063
EP 25078
DI 10.1007/s11042-019-7593-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900063
DA 2024-07-18
ER

PT J
AU Zhou, ZY
   Zhang, RX
   Zhu, ZF
AF Zhou, Zhiyu
   Zhang, Ruoxi
   Zhu, Zefei
TI Robust Kalman filtering with long short-term memory for image-based
   visual servo control
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual servo; Jacobian matrix estimation; Kalman filtering; Long
   short-term memory
ID NEURAL-NETWORK CONTROL; CLASSIFICATION; MANIPULATOR; MACHINE; ROBOT
AB Visual servo control systems based on Kalman filter (KF) is susceptible to noise interference, the initialization of the Jacobi matrix is difficult, and the observation value of the Jacobian matrix is not accurate. In order to address these problems, we proposed a robust KF algorithm with long short-term memory (LSTM) for an image-based visual servo control system and applied the system to an uncalibrated image-based visual servo (IBVS) control system to estimate the filtering gain error, state estimation error, and the observation error, which were then used for online training in LSTM. The visual servo control system controls the motion of the manipulator, and simultaneously updates the LSTM network. Therefore, the Jacobian matrix obtained using LSTM was employed to estimate the state volume of the robust KF, which constitutes a circulatory system, and the complementary effect was realized. The method was applied to a six-degrees-of-freedom manipulator of the eye-in-hand model to conduct experiments. The simulation results indicate that the proposed visual servo control system has strong anti-noise interference capability. Furthermore, it facilitates Jacobian matrix initialization and has high observation accuracy for the Jacobian matrix.
C1 [Zhou, Zhiyu; Zhang, Ruoxi] Zhejiang Sci Tech Univ, Sch Informat Sci & Technol, Hangzhou 310018, Zhejiang, Peoples R China.
   [Zhu, Zefei] Hangzhou Dianzi Univ, Sch Mech Engn, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Zhejiang Sci-Tech University; Hangzhou Dianzi University
RP Zhou, ZY (corresponding author), Zhejiang Sci Tech Univ, Sch Informat Sci & Technol, Hangzhou 310018, Zhejiang, Peoples R China.
EM zhouzhiyu1993@163.com
OI zhou, zhiyu/0000-0003-4487-8192
FU Zhejiang Provincial Natural Science Foundation of China [LY18F030018];
   Science Foundation of Zhejiang Sci-Tech University [18032232-Y]; Natural
   Science Foundation of China [51376055]
FX This work is supported by Zhejiang Provincial Natural Science Foundation
   of China (No. LY18F030018), Science Foundation of Zhejiang Sci-Tech
   University (No. 18032232-Y), and Natural Science Foundation of China
   (No. 51376055).
CR Agand P, 2017, ENG APPL ARTIF INTEL, V65, P1, DOI 10.1016/j.engappai.2017.07.009
   Chaumette F, 2006, IEEE ROBOT AUTOM MAG, V13, P82, DOI 10.1109/MRA.2006.250573
   Cheng ZY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3291060
   Cheng ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   Chherawala Y, 2017, PATTERN RECOGN LETT, V90, P58, DOI 10.1016/j.patrec.2017.03.012
   Cortez B, 2018, EXPERT SYST APPL, V97, P315, DOI 10.1016/j.eswa.2017.12.037
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   FAUSETT LV, 1994, 1994 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOL 1-7, P3398, DOI 10.1109/ICNN.1994.374782
   Gao J, 2017, OCEAN ENG, V142, P666, DOI 10.1016/j.oceaneng.2017.07.015
   Gu JA, 2015, OPTIK, V126, P4489, DOI 10.1016/j.ijleo.2015.07.153
   Guo YY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3295822
   He FL, 2018, MULTIMED TOOLS APPL, V77, P10701, DOI 10.1007/s11042-017-4872-x
   He W, 2018, IEEE T CYBERNETICS, V48, P2670, DOI 10.1109/TCYB.2017.2748418
   He W, 2017, IEEE T CYBERNETICS, V47, P3136, DOI 10.1109/TCYB.2017.2711961
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   How DNT, 2016, INT J ADV ROBOT SYST, V13, DOI 10.1177/1729881416663369
   Huang DG, 2017, INFORM SCIENCES, V415, P100, DOI 10.1016/j.ins.2017.06.021
   Jin L, 2018, IEEE T IND INFORM, V14, P3812, DOI 10.1109/TII.2018.2789438
   Li S, 2018, IEEE T NEUR NET LEAR, V29, P4791, DOI 10.1109/TNNLS.2017.2770172
   Li ST, 2018, INT J CONTROL AUTOM, V16, P844, DOI 10.1007/s12555-016-0720-4
   Li YJ, 2018, MULTIMED TOOLS APPL, V77, P10485, DOI 10.1007/s11042-017-4529-9
   Liu H, 2018, ENERG CONVERS MANAGE, V156, P498, DOI 10.1016/j.enconman.2017.11.053
   Miljkovic Z, 2013, EXPERT SYST APPL, V40, P1721, DOI 10.1016/j.eswa.2012.09.010
   Mitic M, 2014, SOFT COMPUT, V18, P1011, DOI 10.1007/s00500-013-1121-8
   Nadi F, 2014, RSI INT CONF ROBOT M, P405, DOI 10.1109/ICRoM.2014.6990935
   Peng Y, 2017, NEUROCOMPUTING, V261, P242, DOI 10.1016/j.neucom.2016.05.113
   Peng Y, 2017, MULTIMED TOOLS APPL, V76, P8859, DOI 10.1007/s11042-016-3510-3
   Qian Jiang, 2003, CONTROL DECISION, V1, P77
   Qin FW, 2018, COMPUT METH PROG BIO, V162, P243, DOI 10.1016/j.cmpb.2018.05.024
   Qu JD, 2017, IND ROBOT, V44, P210, DOI 10.1108/IR-06-2016-0154
   Sadeghzadeh M, 2015, J INTELL ROBOT SYST, V78, P83, DOI 10.1007/s10846-014-0151-5
   Salgado I, 2018, IEEE T NEUR NET LEAR, V29, P3499, DOI 10.1109/TNNLS.2017.2730847
   Wang F, 2019, CLUSTER COMPUT, V22, pS5799, DOI 10.1007/s10586-017-1538-4
   Wang M, 2018, MULTIMED TOOLS APPL, V77, P10773, DOI 10.1007/s11042-017-4871-y
   Zhang Q, 2017, IEEE GEOSCI REMOTE S, V14, P1745, DOI 10.1109/LGRS.2017.2733548
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P10521, DOI 10.1007/s11042-017-4554-8
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhao W, 2016, INT J CONTROL AUTOM, V9, P357
   Zhao YM, 2015, J INTELL ROBOT SYST, V78, P239, DOI 10.1007/s10846-014-0065-2
   Zhong XG, 2015, NEUROCOMPUTING, V151, P268, DOI 10.1016/j.neucom.2014.09.043
   Zhong XG, 2013, SENSORS-BASEL, V13, P13464, DOI 10.3390/s131013464
   Zhou ZY, 2019, ISA T, V92, P298, DOI 10.1016/j.isatra.2019.02.029
NR 42
TC 17
Z9 17
U1 6
U2 102
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26341
EP 26371
DI 10.1007/s11042-019-07773-0
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700049
DA 2024-07-18
ER

PT J
AU Alabady, SA
   Salleh, MFM
   Al-Turjman, F
AF Alabady, Salah A.
   Salleh, M. F. M.
   Al-Turjman, Fadi
TI Clarifications on the "comments on "a novel approach of error detection
   and correction for efficient energy in wireless networks""
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LCPC (9,4) code; Error detection and correction; Single and double bits
   error
AB This short manuscript clarifies the claims of the reference [2]. Here, we present the mistakes in comments stated in reference [2] about the claimed mistakes in reference [1]. The researchers in [2] do not produce any new or corrected information as per their claims about for the mistakes in figures and tables of reference [1].
C1 [Alabady, Salah A.] Univ Mosul, Coll Engn, Comp Engn Dept, Mosul, Iraq.
   [Salleh, M. F. M.] Univ Sains Malaysia, Sch Elect & Elect Engn, Nibong Tebal, Malaysia.
   [Al-Turjman, Fadi] Antalya Bilim Univ, Dept Comp Engn, Antalya, Turkey.
C3 University of Mosul; Universiti Sains Malaysia; Antalya Bilim University
RP Alabady, SA (corresponding author), Univ Mosul, Coll Engn, Comp Engn Dept, Mosul, Iraq.
EM eng.salah@uomosul.edu.iq; fadzlisalleh@usm.my;
   fadi.alturjman@antalya.edu.tr
RI Al-Turjman, Fadi/L-2998-2019; Abdulghani, Salah/B-6684-2018; Mohd
   Salleh, Mohd Fadzli/AAA-8518-2020; Al-Turjman, Fadi/C-7891-2019
OI Al-Turjman, Fadi/0000-0001-5418-873X; Abdulghani,
   Salah/0000-0001-9687-2724; Mohd Salleh, Mohd Fadzli/0000-0002-1801-6049;
   Al-Turjman, Fadi/0000-0001-6375-4123
CR Alabady SA, 2019, MULTIMED TOOLS APPL, V78, P1345, DOI 10.1007/s11042-018-6282-0
   Samanta J, 2019, MULTIMED TOOLS APPL, V78, P7579, DOI 10.1007/s11042-018-6481-8
NR 2
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22325
EP 22329
DI 10.1007/s11042-019-7546-z
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400007
DA 2024-07-18
ER

PT J
AU Bianchi, RG
   Neris, VPA
   Ara, AL
AF Bianchi, Renata G.
   Neris, Vania P. A.
   Ara, Anderson L.
TI Tags vs. observers - a study on emotions tagged and emotions felt with
   Flickr pictures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social tagging; Pictures; Emotions; Design; Empirical study
ID PLEASURE; ATTENTION; DISGUST; DESIGN; SCALE
AB Designers can select media from user-generated tags in social networks to improve the design with the aim of evoking certain emotions. However, can they be relied on for that? Will users feel the same emotions as those that were linked to the media? This paper aims to support the decision-making of the designers, by exploring the observers' emotions in pictures from social tags. An empirical online study was carried out with 410 volunteers who classified pictures from Flickr that were related to the five basic emotions plus neutral tag. The results suggest that there are differences between the tag and the emotion felt by this group of people for particular emotions. For instance, the findings suggest that the selection of pictures for disgust and anger needs additional criteria as well as collective indexing.
C1 [Bianchi, Renata G.; Neris, Vania P. A.] Univ Fed Sao Carlos, Dept Comp Sci, Sao Carlos, SP, Brazil.
   [Ara, Anderson L.] Univ Sao Paulo, Inst Math & Comp Sci, Sao Carlos, SP, Brazil.
C3 Universidade Federal de Sao Carlos; Universidade de Sao Paulo
RP Bianchi, RG (corresponding author), Univ Fed Sao Carlos, Dept Comp Sci, Sao Carlos, SP, Brazil.
EM renatagbianchi@gmail.com; vania@dc.ufscar.br; anderson.ara@icmc.usp.br
RI Ara, Anderson/HNP-3405-2023
OI Ara, Anderson/0000-0002-1041-2768; Bianchi, Renata/0000-0001-5527-7013;
   de Almeida Neris, Vania Paula/0000-0002-4059-8700
CR [Anonymous], 2019, GAP CAS WOM MENS MAT
   [Anonymous], 2011, P 2011 INT WORKSHOP
   [Anonymous], 2008, COGNITION EMOTION OR
   Blake TM, 2001, NEUROBIOL LEARN MEM, V75, P262, DOI 10.1006/nlme.2000.3973
   Booten K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2401, DOI 10.1145/2858036.2858398
   Boulton Mark, 2009, Designing for the web
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Dan-Glauser ES, 2011, BEHAV RES METHODS, V43, P468, DOI 10.3758/s13428-011-0064-1
   De Lera E., 2007, Proceedings of 21st British HCI Group Annual Conference on People and Computers: HCI...but not as we know it, V2, P163
   Desmet Pieter., 2003, Proceedings of the 2003 International Conference on Designing Pleasurable Products and Interfaces, P22, DOI [10.1145/782896.782903, DOI 10.1145/782896.782903]
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Garimella VRK, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5543, DOI 10.1145/2858036.2858234
   HAIDT J, 1994, PERS INDIV DIFFER, V16, P701, DOI 10.1016/0191-8869(94)90212-7
   Harmon-Jones Eddie., 2007, Handbook of emotion elicitation and assessment, P91, DOI DOI 10.2224/SBP.2007.35.7.863
   Harper ER, 2008, HUMAN COMPUTER INTER
   Hastings SK, 2007, P AM SOC INFORM SCI, V44, P1
   HOLM S, 1979, SCAND J STAT, V6, P65
   Jiang N, 2008, I C COMP AID DES CON, P91, DOI 10.1109/CAIDCD.2008.4730526
   Jordan PW, 1998, APPL ERGON, V29, P25, DOI 10.1016/S0003-6870(97)00022-7
   Jorgensen C., 2007, IMAGE ACCESS SEMANTI
   Kurdi B., 2016, BEHAV RES METHODS, P1
   Lakoff G., 1987, Fire, women and dangerous things
   Lang PJ, 2008, INT AFFECTIVE PICTUR
   Lynch P.J., 2002, WEB STYLE GUIDE BASI, V2nd
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Montgomery DC, 2013, DESIGN ANAL EXPT, V8th ed, P183
   Mori G, 2015, LECT NOTES COMPUT SC, V9296, P165, DOI 10.1007/978-3-319-22701-6_12
   Murphy FC, 2010, EMOTION, V10, P605, DOI 10.1037/a0019681
   Neal D., 2007, Bulletin of the Journal of the American Society of Information Science and Technology, V34, P7, DOI [10.1002/bult.2007.1720340104, DOI 10.1002/BULT.2007.1720340104]
   Norman D., 2002, INTERACTIONS, V9, P36, DOI [10.1145/543434.543435, DOI 10.1145/543434.543435]
   Norman D.A., 2004, EMOTIONAL DESIGN WHY
   Ornager S., 1995, SIGIR Forum, P212
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Porat T, 2012, HUM-COMPUT INTERACT, V27, P235, DOI 10.1080/07370024.2011.646927
   Rorissa A, 2008, J AM SOC INF SCI TEC, V59, P1383, DOI 10.1002/asi.20825
   ROSCH E, 1976, COGNITIVE PSYCHOL, V8, P382, DOI 10.1016/0010-0285(76)90013-X
   RUSSELL JA, 1989, J PERS SOC PSYCHOL, V57, P493, DOI 10.1037/0022-3514.57.3.493
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Santaella L, 2002, APPL SEMIOTICS
   Scherer Klaus R, 1984, APPROACHES EMOT, V2293, P31
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Schmidt S, 2009, J AM SOC INF SCI TEC, V60, P863, DOI 10.1002/asi.21043
   Schupp HT, 2000, PSYCHOPHYSIOLOGY, V37, P257, DOI 10.1017/S0048577200001530
   Silveira LM, 2011, INTRO COLOR THEORY
   Smith S. L., 1986, GUIDELINES DESIGNING
   Spillers F., 2004, EXPERIENCE DYNAMICS
   Trulia, 2019, REAL STAT LIST HOM S
   van Hooff JC, 2014, ACTA PSYCHOL, V152, P149, DOI 10.1016/j.actpsy.2014.08.009
NR 49
TC 0
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21805
EP 21826
DI 10.1007/s11042-019-7463-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400056
DA 2024-07-18
ER

PT J
AU Chang, HH
   Shih, TK
   Chang, CK
   Tavanapong, W
AF Chang, Hon-Hang
   Shih, Timothy K.
   Chang, Carl K.
   Tavanapong, Wallapak
TI CMAIR: content and mask-aware image retargeting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retargeting; Seam carving; Irregular interpolation; Image
   saliency; Region of interest
ID OBJECTIVE QUALITY ASSESSMENT; SALIENCY DETECTION; MODEL
AB In recent years, more and more image retargeting techniques have been proposed to facilitate our daily life, in particular those based on the use of seam carving, warping or the combination of them. However, these techniques can only retarget the source picture into the same shape of a square, and these approaches cannot be reshape into a circular, a polygon or other shapes. This paper focuses on creating a graphics editing system, named CMAIR (Content and Mask-Aware Image Retargeting), for image retargeting, which can retarget the source images into different shapes of image to highlight the salient objects of primary region of interest. CMAIR effectively supports removal of unimportant pixels, and frames as many surrounding objects inside the provided mask as possible. Also, we propose a unique irregular interpolation method to produce four possible target images, and an evaluation mechanism to decide the best candidate image as the final output with the consideration of image saliency. The results show that not only the source image can be placed into different targeted shapes of mask, but also the salient objects are retained and highlighted as much as possible.
C1 [Chang, Hon-Hang; Shih, Timothy K.] 300 Zhongda Rd, Taoyuan 32001, Taiwan.
   [Chang, Carl K.] Iowa State Univ, 226 Atanasoff Hall, Ames, IA 50011 USA.
   [Tavanapong, Wallapak] Iowa State Univ, 232 Atanasoff Hall, Ames, IA 50011 USA.
C3 Iowa State University; Iowa State University
RP Chang, HH (corresponding author), 300 Zhongda Rd, Taoyuan 32001, Taiwan.
EM sicachang@gmail.com; timothykshih@gmail.com; chang@iastate.edu;
   tavanapo@iastate.edu
CR [Anonymous], 2005, P 18 ANN ACM S US IN
   [Anonymous], P WORKSH DYN VIS ICC
   [Anonymous], ISANDAMP T SPIE ELEC
   [Anonymous], ISANDAMP T SPIE ELEC
   [Anonymous], 2006, P 14 ACM INT C MULT
   [Anonymous], 2016, BIOCH PHYSL OPEN ACC, DOI [10.4172/2168-9652.1000200, DOI 10.4172/2168-9652.1000200]
   [Anonymous], 2007, 2007 IEEE 11 INT C C, DOI DOI 10.1109/ICCV.2007.4409010
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Castillo S., 2011, ACM SIGGRAPH S APPLP, P7
   Cho S, 2009, IEEE IMAGE PROC, P977, DOI 10.1109/ICIP.2009.5413801
   Deng CW, 2012, IEEE T MULTIMEDIA, V14, P1127, DOI 10.1109/TMM.2012.2191270
   Dong WM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618471
   Fan Xin., 2003, P ACM MULTIMEDIA, P247
   Fang YM, 2014, IEEE J EM SEL TOP C, V4, P95, DOI 10.1109/JETCAS.2014.2298919
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   Grundmann M, 2010, PROC CVPR IEEE, P569, DOI 10.1109/CVPR.2010.5540165
   Guo YW, 2009, IEEE T MULTIMEDIA, V11, P856, DOI 10.1109/TMM.2009.2021781
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P1615, DOI 10.1109/TIP.2014.2305843
   Liang Y, 2017, IEEE T VIS COMPUT GR, V23, P1099, DOI 10.1109/TVCG.2016.2517641
   Lifang Wu, 2014, Journal of Multimedia, V9, P483, DOI 10.4304/jmm.9.4.483-492
   Lin SS, 2013, IEEE T MULTIMEDIA, V15, P359, DOI 10.1109/TMM.2012.2228475
   Liu Hao., 2003, P ACM INT C MULTIMED, P148
   Liu YJ, 2011, COMPUT GRAPH FORUM, V30, P583, DOI 10.1111/j.1467-8659.2011.01881.x
   Ma L, 2016, IEEE T MULTIMEDIA, V18, P2228, DOI 10.1109/TMM.2016.2614187
   Ma L, 2012, IEEE INT SYMP CIRC S, P2677, DOI 10.1109/ISCAS.2012.6271858
   Ma L, 2012, IEEE J-STSP, V6, P626, DOI 10.1109/JSTSP.2012.2211996
   Ni BB, 2013, IEEE T MULTIMEDIA, V15, P1138, DOI 10.1109/TMM.2013.2241042
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   Qi SY, 2016, IEEE T IMAGE PROCESS, V25, P2222, DOI 10.1109/TIP.2016.2528040
   Qu Z, 2013, IEEE T MULTIMEDIA, V15, P1677, DOI 10.1109/TMM.2013.2267727
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Santella A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P771
   Shamir Ariel, 2009, ACM SIG-GRAPH ASIA 2009 Courses, P11
   Simakov D, 2008, PROC CVPR IEEE, P3887
   Suh Bongwon, 2003, P ACM S US INT SOFTW, P95, DOI DOI 10.1145/964696.964707
   Wang YS, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618473
   Wang YS, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409071
   Wu LF, 2014, MULTIMED TOOLS APPL, V70, P721, DOI 10.1007/s11042-012-1002-7
   Yan B, 2014, IEEE T MULTIMEDIA, V16, P272, DOI 10.1109/TMM.2013.2286112
   Yan B, 2013, IEEE T CIRC SYST VID, V23, P313, DOI 10.1109/TCSVT.2012.2203740
   Yen TC, 2011, IEEE T IMAGE PROCESS, V20, P2339, DOI 10.1109/TIP.2011.2114357
   Zhang LM, 2015, IEEE T MULTIMEDIA, V17, P1538, DOI 10.1109/TMM.2015.2451954
NR 47
TC 4
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21731
EP 21758
DI 10.1007/s11042-019-7462-2
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400053
DA 2024-07-18
ER

PT J
AU Narang, SR
   Jindal, MK
   Kumar, M
AF Narang, Sonika Rani
   Jindal, Manish Kumar
   Kumar, Munish
TI Drop flow method: an iterative algorithm for complete segmentation of
   Devanagari ancient manuscripts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pattern recognition; Optical character recognition; Drop flow; Ancient
   manuscripts; Ancient documents
ID HANDWRITTEN; RECOGNITION; DOCUMENTS
AB One of the major challenges of ancient manuscripts recognition is character segmentation. Because of many distinct features of ancient documents (thick characters, overlapping and touching characters), character segmentation is a very difficult task. Devanagari ancient manuscripts consist of vowels, consonants, modifiers, conjuncts and compound characters. Using existing techniques, segmentation of overlapping and touching characters is problematic. In this paper, an iterative character segmentation algorithm is presented for ancient documents in Devanagari script. At the beginning, the lines are extracted from the ancient documents by dividing the document image into vertical stripes and then using piecewise horizontal projection profiles. After that, these lines are segmented into words using vertical projection profiles and finally, words are segmented in characters using an iterative algorithm. In each iteration, character segmentation is refined. In the present work, we have proposed a new algorithm with the name 'Drop Flow Method' to find the segmentation path between touching components. The proposed algorithm can segment touching characters and 96.0% accuracy has been achieved for complete segmentation of Devanagari ancient manuscripts.
C1 [Narang, Sonika Rani] DAV Coll, Dept Comp Sci, Abohar, Punjab, India.
   [Jindal, Manish Kumar] Panjab Univ, Reg Ctr, Dept Comp Sci & Applicat, Muktsar, Punjab, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
C3 Panjab University
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM sonikanarang@davcollegeabohar.com; manishphd@rediffmail.com;
   munishcse@gmail.com
RI Kumar, Munish/P-7756-2018; Jindal, Manish/AAU-8820-2021
OI Kumar, Munish/0000-0003-0115-1620; Narang, Sonika/0000-0002-6742-7717
CR Alaei A, 2011, PATTERN ANAL APPL, V14, P381, DOI 10.1007/s10044-011-0226-x
   Alam M, 2010, J Cases Inf Technol, V1, P30
   [Anonymous], INT J COMPUTER APPL
   Babu S, 2016, 7TH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND NETWORKING TECHNOLOGIES (ICCCNT 2016), DOI 10.1145/2967878.2967908
   Bag Soumen, 2015, Combinatorial Image Analysis. 17th International Workshop, IWCIA 2015. Proceedings, P247, DOI 10.1007/978-3-319-26145-4_18
   Bansal V, 2002, PATTERN RECOGN, V35, P875, DOI 10.1016/S0031-3203(01)00081-4
   Bar-Yosef Itay, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1161, DOI 10.1109/ICDAR.2009.191
   Brodic D, 2009, P INT SCI C INF COMM, V17, P30
   Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792
   Chen K, 2016, INT CONF FRONT HAND, P90, DOI [10.1109/ICFHR.2016.26, 10.1109/ICFHR.2016.0029]
   Chen YK, 2000, IEEE T PATTERN ANAL, V22, P1304, DOI 10.1109/34.888715
   Dogra S, 2017, IJSRD INT J SCI RES, V5, P1418
   DUNN CE, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P577, DOI 10.1109/ICPR.1992.201844
   Dutta K, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P25, DOI 10.1109/DAS.2018.69
   FUJISAWA H, 1992, P IEEE, V80, P1079, DOI 10.1109/5.156471
   Gatos B, 2014, INT CONF FRONT HAND, P464, DOI 10.1109/ICFHR.2014.84
   Jindal N, 2009, GLOB TELECOMM CONF, P1, DOI 10.1109/GLOCOM.2009.5426082
   Kim KK, 2000, INT C PATT RECOG, P594, DOI 10.1109/ICPR.2000.906144
   Kumar A., 2013, INT J ENG ADV TECHNO, V2, P569
   Likforman-Sulem L, 2007, INT J DOC ANAL RECOG, V9, P123, DOI 10.1007/s10032-006-0023-z
   Mohite RS, 2014, INT J COMPUTER TECHN, V5, P947
   Oliveira L. S., 2000, P 7 INT WORKSH FRONT, P577
   Pal U, 2003, PATTERN RECOGN LETT, V24, P261, DOI 10.1016/S0167-8655(02)00240-4
   Palacios S., 2012, P IEEE APSURSI, P1
   Panichkriangkrai Chulapong., 2013, P 2 INT WORKSHOP HIS, P118
   Rao N. Venkata, 2015, Journal of Theoretical and Applied Information Technology, V82, P311
   Rao S, 2014, J EMERGING TRENDS CO, V5, P698
   Reddy LP, 2010, INT J COMPUTER SCI I, V7, P17
   Saba Tanzila, 2010, International Journal of Research and Reviews in Computer Science, V1, P103
   Shah K, 2013, GLOBAL J RES ANAL, V2, P162
   Sharma DV, 2006, INT C PATT RECOG, P1022
   Sridevi N, 2012, IJCA, V52, P7
   Tripathy N, 2006, SADHANA-ACAD P ENG S, V31, P755, DOI 10.1007/BF02716894
NR 33
TC 8
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23255
EP 23280
DI 10.1007/s11042-019-7620-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400048
DA 2024-07-18
ER

PT J
AU Tang, GL
   Liu, ZJ
   Xiong, J
AF Tang, Guoliang
   Liu, Zhijing
   Xiong, Jing
TI Distinctive image features from illumination and scale invariant
   keypoints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LBP; SIFT; Image matching; Object recognition
ID TEXTURE CLASSIFICATION; GRAY-SCALE; REGISTRATION; PERFORMANCE
AB This paper proposes a novel local feature descriptor of the image, which is named iSIFT (illumination and Scale Invariant Feature Transform), based on SIFT (Scale Invariant Feature Transform) improved by LBP (Local Binary Pattern), in order to combine the robustness advantages of LBP descriptor for illumination change and that of SIFT for scaling. It addresses the following problems: (1) SIFT algorithm is poor in describing the local feature extraction from an image when lighting condition changes; (2) SIFT algorithm cannot accurately extract the feature points or can only extract only few of them from the blurred image and the image of an object with smooth edges. Each of the scale-space representation, namely, L(x, y, k sigma), in Gaussian pyramid of the image I(x, y) on SIFT descriptor is calculated by using LBP in order to obtain the corresponding LBP image, which is denoted by LBP(L(x, y, k sigma)). The obtained LBP(L(x, y, k sigma)) replaces the original corresponding scale-space representation L(x, y, k sigma) to construct the LBP-Gaussian pyramid, and the difference between each two neighboring LBP(L(x, y, k sigma)) in LBP-Gaussian pyramid is used to replace the original DoG pyramid in SIFT descriptor to detect extreme points. The results of the experiments suggest that iSIFT descriptor improves the precision of image feature matching and the robustness under changed lighting conditions compared with that of SIFT algorithm, and iSIFT descriptor can extract more feature points from the blurred image and the image with smooth edges as well as having stronger robustness for lighting, rotation and scaling.
C1 [Tang, Guoliang; Liu, Zhijing] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
   [Tang, Guoliang] Henan Univ Chinese Med, Sch Informat & Technol, Zhengzhou 450008, Henan, Peoples R China.
   [Xiong, Jing] Shaanxi Univ Sci & Technol, Coll Elect & Informat Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University; Henan University of Traditional Chinese Medicine;
   Shaanxi University of Science & Technology
RP Tang, GL (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.; Tang, GL (corresponding author), Henan Univ Chinese Med, Sch Informat & Technol, Zhengzhou 450008, Henan, Peoples R China.
EM Datang110@126.com; liuzhijing@vip.163.com; xiongjing_mail@163.com
RI li, jixiang/JXN-7599-2024
FU National Natural Science Foundation of China [61173091]
FX This work is supported by the National Natural Science Foundation of
   China (61173091).
CR Aanæs H, 2012, INT J COMPUT VISION, V97, P18, DOI 10.1007/s11263-011-0473-8
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 2015, VISAPP 2015
   [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], P ACM MULT
   [Anonymous], FAC FAC EXPR REC REA
   [Anonymous], BIOL CYBERNETICS
   [Anonymous], 2015, P ELM 2014
   [Anonymous], 18 IEEE INT C IM PRO
   [Anonymous], 2014, Computer Vision, DOI DOI 10.1007/978-0-387-31439-6_242
   Bai S, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416550016
   Bay H., 2006, P 9 EUR C COMP VIS
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Danfeng Zhao, 2015, Image and Graphics. 8th International Conference, ICIG 2015. Proceedings: LNCS 9217, P307, DOI 10.1007/978-3-319-21978-3_28
   Davarzani R, 2015, SIGNAL PROCESS, V111, P274, DOI 10.1016/j.sigpro.2014.11.005
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Kabbai L, 2015, 2015 IEEE 12 INT MUL, P1
   KOENDERINK JJ, 1992, IEEE T PATTERN ANAL, V14, P597, DOI 10.1109/34.141551
   Li Q, 2013, NEUROCOMPUTING, V111, P34, DOI 10.1016/j.neucom.2012.11.032
   Li X, 2013, PROC CVPR IEEE, P2419, DOI 10.1109/CVPR.2013.313
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lindeberg T., 1994, SCALE SPACE THEORY C
   Lindeberg T., J APPL STAT, V21, P224, DOI DOI 10.1080/757582976
   Lindeberg T., 2012, SCHOLARPEDIA, V7, P10491, DOI [10.4249/scholarpedia.10491, DOI 10.4249/SCHOLARPEDIA.10491]
   Lindeberg T, 2013, BIOL CYBERN, V107, P589, DOI 10.1007/s00422-013-0569-z
   Lindeberg T, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066990
   Lindeberg T, 2013, ADV IMAG ELECT PHYS, V178, P1, DOI 10.1016/B978-0-12-407701-0.00001-7
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma JY, 2015, IEEE T GEOSCI REMOTE, V53, P6469, DOI 10.1109/TGRS.2015.2441954
   Ma JY, 2015, IEEE T SIGNAL PROCES, V63, P1115, DOI 10.1109/TSP.2014.2388434
   Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Nistér D, 2008, LECT NOTES COMPUT SC, V5303, P183, DOI 10.1007/978-3-540-88688-4_14
   Nister David, 2006, CVPR
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 2000, LECT NOTES COMPUT SC, V1842, P404
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Rothe R, 2015, LECT NOTES COMPUT SC, V9003, P290, DOI 10.1007/978-3-319-16865-4_19
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Tian T, 2015, IEEE SIGNAL PROC LET, V22, P728, DOI 10.1109/LSP.2014.2352172
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28
   Yu J, 2013, NEUROCOMPUTING, V120, P355, DOI 10.1016/j.neucom.2012.08.061
   Zhang L, 2012, IEEE IMAGE PROC, P1477, DOI 10.1109/ICIP.2012.6467150
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 50
TC 15
Z9 18
U1 8
U2 117
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23415
EP 23442
DI 10.1007/s11042-019-7566-8
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400054
DA 2024-07-18
ER

PT J
AU Kim, C
   Shin, D
   Yang, CN
   Chou, YS
AF Kim, Cheonshik
   Shin, Dongkyoo
   Yang, Ching-Nung
   Chou, Yung-Shun
TI Generalizing Hamming plus k data hiding by overlapped pixels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Steganography; Hamming code; LSB; OPAP
ID COVERING CODES
AB Matrix coding based data hiding (MCDH) using linear codes (syndrome coding) is an efficient coding method for steganographic schemes to improve their embedding efficiency. Hamming code data hiding (HDH) is a well-known MCDH using a covering function COV (1, n =2(k) -1, k). Afterwards, Hamming+1 DH (H1DH) was proposed with good embedding efficiency. However, these two previous approaches, HDH and H1DH, are not efficient for a large amount of messages. To tackle this problem, Yang et al.'s proposed Hamming+ k DH (Hk DH), which enhance the extra one embedded bit in H1DH to k embedded bits in the Hk DH. In this paper, we extended the Hk DH to the Hamming+ k with m overlapped pixels (Hk_mDH). The proposed Hk_mDH adopted pixel overlapping approach, optimal pixel adjustment process (OPAP), and Least Significant Bit (LSB) substitution. Experimental results demonstrate that our Hk_mDH has better embedding rate (ER) compared with previous schemes. In addition, we have proved that our Hk_mDH has excellent theoretical estimation of average mean square error.
C1 [Kim, Cheonshik; Shin, Dongkyoo] Sejong Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Yang, Ching-Nung; Chou, Yung-Shun] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
C3 Sejong University; National Dong Hwa University
RP Kim, C; Shin, D (corresponding author), Sejong Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM mipsan@paran.com; shindk@sejong.ac.kr; cnyang@gms.ndhu.edu.tw
RI Yang, Ching-Nung/HKV-1639-2023
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) [2015R1D1A1A01059253]; Ministry of Science and Technology
   (MOST) [105-2221-E-259-015-MY2]; NRF [2016K2A9A2A05005255]
FX This work was supported by the Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by
   (2015R1D1A1A01059253), and was supported under the framework of
   international cooperation program managed by NRF (2016K2A9A2A05005255).
   Also, it was supported in part by Ministry of Science and Technology
   (MOST), under 105-2221-E-259-015-MY2.
CR Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bierbrauer J, 2008, LECT NOTES COMPUT SC, V4920, P1, DOI 10.1007/978-3-540-69019-1_1
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Crandall R., 1998, SOME NOTES STEGANOGR
   Fridrich J, 2002, P SPIE PHOTONICS W E, V4675
   Fridrich J, 2007, LECT NOTES COMPUT SC, V4437, P282
   Kim C, 2018, DIGIT SIGNAL PROCESS, V78, P284, DOI 10.1016/j.dsp.2018.03.016
   Kim C, 2016, MULTIMED TOOLS APPL, V75, P15651, DOI 10.1007/s11042-014-2355-x
   Kim C, 2010, STUD COMP INTELL, V283, P89
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Stanley C.A., 2005, Pairs of values and the chi-squared attack
   WESTFELD A., 2001, P 4 INT WORKSH INF H, V2137, P289, DOI DOI 10.1007/3-540-45496-9_21
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yang CN, 2017, COMPUT STAND INTER, V50, P209, DOI 10.1016/j.csi.2016.10.005
   Yang CN, 2011, KSII T INTERNET INF, V5, P457, DOI 10.3837/tiis.2011.02.013
   Zhang RY, 2012, IEEE T INFORM THEORY, V58, P7272, DOI 10.1109/TIT.2012.2217072
   Zhang WM, 2007, IEEE COMMUN LETT, V11, P680, DOI 10.1109/LCOMM.2007.070438
   Zhang X, 2007, ELECTRON LETT, V43, P482, DOI 10.1049/el:20070248
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang Y., 2013, International Journal of Intelligence Science, V3, P1, DOI DOI 10.4236/IJIS.2013.32009
NR 20
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17995
EP 18015
DI 10.1007/s11042-018-7101-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200030
DA 2024-07-18
ER

PT J
AU Shen, MY
   Yu, PF
   Wang, RG
   Yang, J
   Xue, LX
   Hu, M
AF Shen, Mingyu
   Yu, Pengfei
   Wang, Ronggui
   Yang, Juan
   Xue, Lixia
   Hu, Min
TI Multipath feedforward network for single image super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Convolutional neural network; Multipath feedforward
   network; Staged feature fusion
ID DEEP CNN
AB Single image super-resolution (SR) models which based on convolutional neural network mostly use chained stacking to build the network. It ignores the role of hierarchical features and relationship between layers, resulting in the loss of high-frequency components. To address these drawbacks, we introduce a novel multipath feedforward network (MFNet) based on staged feature fusion unit (SFF). By changing the connection between networks, MFNet strengthens the inter-layer relationship and improves the information flow in the network, thereby extracting more abundant high-frequency components. Firstly, SFF extracts and integrates hierarchical features by dense connection, which expands the information flow of the network. Afterwards, we use adaptive method to learn effective features in hierarchical features. Then, in order to strengthen relationship between layers and fully use the hierarchical features, we use multi-feedforward structure to connect each SFF, which enables multipath feature re-usage and explores more abundant high-frequency components on this basis. Finally, the image reconstruction is realized by combining the shallow features and the global residual. Extensive benchmark evaluation shows that the performance of MFNet has a significant improvement over the state-of-the-art methods.
C1 [Shen, Mingyu; Yu, Pengfei; Wang, Ronggui; Yang, Juan; Xue, Lixia; Hu, Min] Hefei Univ Technol, Coll Comp & Informat, Hefei, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Yang, J (corresponding author), Hefei Univ Technol, Coll Comp & Informat, Hefei, Anhui, Peoples R China.
EM shenmy@126.com; ypf716@outlook.com; wangrgui@foxmail.com;
   yangjuan6985@163.com; xlxzzm@163.com; jsjxhumin@hfut.edu.cn
RI Lin, Kuan-Yu/JXM-6653-2024
FU National Natural Science Foundation of China [61672202]
FX This study was funded by the National Natural Science Foundation of
   China under (grant number 61672202).
CR [Anonymous], 2015, 3 INT C LEARN REPR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.618
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], 2016, P ADV NEUR INF PROC
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chen Y., 2017, ADV NEURAL INFORM PR, P4467
   Cheong JY, 2017, IEEE SIGNAL PROC LET, V24, P1252, DOI 10.1109/LSP.2017.2721104
   Cho D, 2016, LECT NOTES COMPUT SC, V9906, P626, DOI 10.1007/978-3-319-46475-6_39
   Dai SY, 2009, IEEE T IMAGE PROCESS, V18, P969, DOI 10.1109/TIP.2009.2012908
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Gregor K., 2010, P 27 INT C INT C MAC, P399
   Gu SH, 2015, IEEE I CONF COMP VIS, P1823, DOI 10.1109/ICCV.2015.212
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li SM, 2018, NEUROCOMPUTING, V275, P267, DOI 10.1016/j.neucom.2017.08.041
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6
   Schulter S, 2015, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2015.7299003
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shi WZ, 2017, IEEE IMAGE PROC, P977, DOI 10.1109/ICIP.2017.8296427
   Sun JG, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MANAGEMENT OF INNOVATION AND TECHNOLOGY, VOLS 1-3, P18, DOI 10.1109/ICMIT.2008.4654330
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tang Y, 2016, NEUROCOMPUTING, V172, P38, DOI 10.1016/j.neucom.2014.12.102
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang Q, 2014, NEUROCOMPUTING, V131, P348, DOI 10.1016/j.neucom.2013.09.032
   Wang Y., 2016, IEEE ACCESS
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Xu JC, 2017, IEEE COMPUT SOC CONF, P1093, DOI 10.1109/CVPRW.2017.147
   Xu J, 2017, IEEE IMAGE PROC, P4053, DOI 10.1109/ICIP.2017.8297044
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhangyang Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301266
NR 44
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19621
EP 19640
DI 10.1007/s11042-019-7334-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800032
DA 2024-07-18
ER

PT J
AU Tseng, WY
   Chen, KH
   Huang, JW
AF Tseng, Wen-Yen
   Chen, Kai-Hsiang
   Huang, Jen-Wei
TI Crowdsourced object-labeling based on a game-based mobile application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive system; Crowd sourced; Object labelling; Data collection
AB Unparalleled growth in the sharing of media via networks has prompted a great deal of research into issues pertaining to image retrieval. The training and verification of image retrieval systems requires a large number of labelled images with ground truth; however, most researchers employ public datasets for their experiments, the results are restricted by the size and content of the dataset. In this study, we developed a system based on a mobile phone App for the collection of information pertaining to the location of objects in images. The proposed system is simple and easy to use. Experiments demonstrate the excellent performance of the proposed system with regard to accuracy and response time. This study demonstrates the feasibility of collecting image information using mobile phones.
C1 [Tseng, Wen-Yen; Huang, Jen-Wei] Natl Cheng Kung Univ, Dept Elect Engn, Tainan, Taiwan.
   [Chen, Kai-Hsiang] Natl Cheng Kung Univ, Grad Program Multimedia Syst & Intelligent Comp, Tainan, Taiwan.
   [Chen, Kai-Hsiang] Acad Sinica, Grad Program Multimedia Syst & Intelligent Comp, Taipei, Taiwan.
C3 National Cheng Kung University; National Cheng Kung University; Academia
   Sinica - Taiwan
RP Chen, KH (corresponding author), Natl Cheng Kung Univ, Grad Program Multimedia Syst & Intelligent Comp, Tainan, Taiwan.; Chen, KH (corresponding author), Acad Sinica, Grad Program Multimedia Syst & Intelligent Comp, Taipei, Taiwan.
EM wenyentseng611@gmail.com; kevin761015@gmail.com;
   jwhuang@mail.ncku.edu.tw
RI Huang, Jen-Wei/M-1161-2018
CR [Anonymous], 2012, GOOGLE NOW USING REC
   [Anonymous], 2014, CLIPPER LIB PERFORMS
   [Anonymous], 2017, RECAPTCHA IM NOT ROB
   [Anonymous], 2012, CAPTCHA FORMS GOOD E
   [Anonymous], 2012, P 21 ACM INT C INFOR
   [Anonymous], 2005, P SIGCHI C HUM FACT
   [Anonymous], 2015, DENSEBOX UNIFYING LA
   [Anonymous], 2016, CUSTOMIZING LOOK FEE
   Chen K., 2014, Journal of Computational Methods in Physics, V2014, DOI [10.1155/2014/108713, DOI 10.1155/2014/108713]
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Gao YL, 2009, IEEE T CIRC SYST VID, V19, P1851, DOI 10.1109/TCSVT.2009.2026968
   Jing PG, 2019, IEEE T CIRC SYST VID, V29, P1296, DOI 10.1109/TCSVT.2018.2832095
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Lerthirunwong N., 2012, 2012 IEEE 1st Global Conference on Consumer Electronics (GCCE 2012), P206, DOI 10.1109/GCCE.2012.6379581
   Li B, 2011, IEEE INT SYMP CIRC S, P2119
   Liu J, 2010, INT CONF COMPUT AUTO, P491, DOI 10.1109/ICCAE.2010.5451908
   Liu X., 2014, Mathematical Problems in Engineering, V2014, P1, DOI [DOI 10.1007/S11156-013-0369-5, 10.1155/2014/456818, DOI 10.1155/2014/456818]
   Liu YA, 2011, IEEE T MULTIMEDIA, V13, P280, DOI 10.1109/TMM.2010.2103931
   Liu YA, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P500, DOI 10.1145/1571941.1572027
   Rae Adam., 2010, Adaptivity, Personalization and Fusion of Heterogeneous Information, P92
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Shouhong Wan, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P1017, DOI 10.1109/ICIG.2011.165
   Su JH, 2011, IEEE T MULTIMEDIA, V13, P530, DOI 10.1109/TMM.2011.2129502
   Tang XO, 2012, IEEE T PATTERN ANAL, V34, P1342, DOI 10.1109/TPAMI.2011.242
   Tian XM, 2010, IEEE T IMAGE PROCESS, V19, P805, DOI 10.1109/TIP.2009.2035866
   Tian XM, 2011, IEEE T MULTIMEDIA, V13, P639, DOI 10.1109/TMM.2011.2111363
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   von Ahn L, 2003, LECT NOTES COMPUT SC, V2656, P294
   von Ahn L, 2008, SCIENCE, V321, P1465, DOI 10.1126/science.1160379
   Wonyong Eom, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2445, DOI 10.1109/ICIP.2011.6116154
   Yang LJ, 2013, IEEE MULTIMEDIA, V20, P13, DOI 10.1109/MMUL.2012.30
   Yang LJ, 2012, IEEE T MULTIMEDIA, V14, P871, DOI 10.1109/TMM.2012.2187778
   Yang Liu, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P417, DOI 10.1109/ICDM.2011.141
   Yao T, 2013, IEEE T IMAGE PROCESS, V22, P1642, DOI 10.1109/TIP.2012.2236341
NR 36
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18137
EP 18168
DI 10.1007/s11042-018-6944-y
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200037
DA 2024-07-18
ER

PT J
AU Alsalhi, Y
AF Alsalhi, Yahya
TI An accurate and high-efficient QuBits steganography scheme based on
   hybrid neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Qubits image steganography; NEQR; QANNs; PSNR; HVS
ID HIDING ALGORITHM
AB This paper presents a novel scheme for QuBits steganography based on adaptive neural networks. Steganography based on qubits string along with the adaptive neural networks with the recycling of the modified particle swarm optimization algorithm, and using the enhanced general controlled NOT gate and NEQR representation model with the optimal target of the quantum ANNS (QANNs).In this scheme, the cover image is trained to be more accrued. Then in the obtained stego file, coefficients are classified based on their XORs. The suggested scheme avoids attacking of the sensitive data in a way that receiver can extract the information without any errors. Considering the preformed classification, secret qubits will not be revealed in the transferring process and then with the use of inverse extracting, stego file will be obtained. The most important features that our work obtained are good adaptation with human vision system and retrieval of data without getting error. Simulation results show that our proposed scheme has a good adaptation with human vision system (HVS) and outperforms in terms of PSNR factors over recently published works. Particularly, the suggested results can easily realize optimal target value locations of the ANNs to obtain low noise and high accuracy. Additionally, the proposed scheme can separately conceal a secret message and contents of the cover file.
C1 [Alsalhi, Yahya] Minist Educ, Gen Directorate Educ Dhi Qar, Baghdad, Iraq.
RP Alsalhi, Y (corresponding author), Minist Educ, Gen Directorate Educ Dhi Qar, Baghdad, Iraq.
EM yahya_alsalhi@hust.edu.cn
RI alslahi, yahya Eneid/GZM-9186-2022
OI alslahi, yahya Eneid/0000-0002-3109-8878
FU Natural Science Foundation of China [2016CFB541]; Applied Basic Research
   Program of Wuhan Science and Technology Bureau of China
   [2016010101010003]; Science and Technology Program of Shenzhen of China
   [JCYJ20170307160458368]
FX This work is supported by the Natural Science Foundation of China under
   (Grant No. 2016CFB541), the Applied Basic Research Program of Wuhan
   Science and Technology Bureau of China under (Grant No.
   2016010101010003) and the Science and Technology Program of Shenzhen of
   China under (Grant No. JCYJ20170307160458368).
CR Al-Salhi YEA, 2017, 2017 IEEE 3RD INTERNATIONAL CONFERENCE ON BIG DATA SECURITY ON CLOUD (BIGDATASECURITY, IEEE 3RD INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE AND SMART COMPUTING, (HPSC) AND 2ND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT DATA AND SECURITY (IDS), P112, DOI 10.1109/BigDataSecurity.2017.16
   Al-Salhi YEA, 2017, INT CONF ADV COMMUN, P167, DOI 10.23919/ICACT.2017.7890078
   AL-Salhi YE, 2016, INT J THEORETICAL PH, V55, P1
   Al-Salhi YEA, 2016, INT J COMPUT SCI INF, V14, P191
   Behrman EC, 2000, INFORM SCIENCES, V128, P257, DOI 10.1016/S0020-0255(00)00056-6
   Bonnell G, 1997, INT J THEOR PHYS, V36, P2855, DOI 10.1007/BF02435714
   Cao HX, 2015, INFORM SCIENCES, V290, P1, DOI 10.1016/j.ins.2014.08.033
   da Silva AJ, 2016, NEURAL NETWORKS, V76, P55, DOI 10.1016/j.neunet.2016.01.002
   Dianbao Mu, 2013, International Journal of Computer Theory and Engineering, V5, P788, DOI 10.7763/IJCTE.2013.V5.797
   El-Emam NN, 2015, COMPUT SECUR, V55, P21, DOI 10.1016/j.cose.2015.06.012
   El-Emam NN, 2013, J SYST SOFTWARE, V86, P1465, DOI 10.1016/j.jss.2012.12.006
   Ezhov AA, 2000, STUD FUZZ SOFT COMP, V45, P213, DOI 10.1007/978-3-7908-1856-7_11
   Gupta S, 2001, J COMPUT SYST SCI, V63, P355, DOI 10.1006/jcss.2001.1769
   Hemalatha S, 2015, PROCEDIA COMPUT SCI, V47, P272, DOI 10.1016/j.procs.2015.03.207
   Jiang N, 2016, INT J THEOR PHYS, V55, P107, DOI 10.1007/s10773-015-2640-0
   Khan Imran, 2010, 2010 International Conference on Emerging Trends in Robotics and Communication Technologies (INTERACT 2010), P46, DOI 10.1109/INTERACT.2010.5706192
   Kouda N, 2005, NEURAL COMPUT APPL, V14, P114, DOI [10.1007/s00521-004-0446-8, 10.1007/S00521-004-0446-8]
   Kretzschmar R, 2000, NEURAL NETWORKS FOR SIGNAL PROCESSING X, VOLS 1 AND 2, PROCEEDINGS, P328, DOI 10.1109/NNSP.2000.889424
   Lagaris IE, 1997, COMPUT PHYS COMMUN, V104, P1, DOI 10.1016/S0010-4655(97)00054-4
   Li Q, 2014, PHYS REV A, V89, DOI 10.1103/PhysRevA.89.040302
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mihara T, 2015, PHYS LETT A, V379, P952, DOI 10.1016/j.physleta.2015.01.038
   Narayanan A, 2000, INFORM SCIENCES, V128, P231, DOI 10.1016/S0020-0255(00)00055-4
   Neukart F., 2013, SIGNAL PROCESS RES, V2, P1
   Oplatkova Z, 2008, INT WORKSHOP DATABAS, P571, DOI 10.1109/DEXA.2008.82
   Purushothaman G, 1997, IEEE T NEURAL NETWOR, V8, P679, DOI 10.1109/72.572106
   Richa K, 2014, 6 INT C
   Ricks B, 2003, ADV NEURAL INFORM PR
   Shaw BA, 2011, PHYS REV A, V83, DOI 10.1103/PhysRevA.83.022310
   Wang S, 2015, MEASUREMENT, V73, P352, DOI 10.1016/j.measurement.2015.05.038
   Zhang Y, 2013, QUANTUM INF PROCESS, V12, P2833, DOI 10.1007/s11128-013-0567-z
   Zhou RG, 2007, INT J THEOR PHYS, V46, P3209, DOI 10.1007/s10773-007-9437-8
NR 33
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 17077
EP 17093
DI 10.1007/s11042-018-7061-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500060
DA 2024-07-18
ER

PT J
AU Pathak, Y
   Arya, KV
   Tiwari, S
AF Pathak, Yadunath
   Arya, K. V.
   Tiwari, Shailendra
TI An efficient low-dose CT reconstruction technique using partial
   derivatives based guided image filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-dose CT; Dictionary learning; Partial differential equations; Guided
   image filter; Reconstruction
ID GROUND-GLASS NODULES; ITERATIVE RECONSTRUCTION; BACK-PROJECTION; MODEL;
   QUALITY; REDUCTION; CHEST; PERFORMANCE; ALGORITHM; PHANTOM
AB Low-dose Computed Tomography (CT) reconstruction techniques have been implemented to minimize the X-ray radiation in a human body. Many researchers have designed different low-dose CT reconstruction techniques to reduce the effect of radiation in a human body. However, the majority of these techniques suffer from over-smoothing, edge distortion, halo artifacts, gradient reversal artifacts etc. problems. Therefore, in this paper, novel partial differential equations and dictionary learning based reconstruction technique have been designed to reconstruct the low-dose CT images. Extensive experiments have been carried out to evaluate the effectiveness of the proposed technique that existing image reconstruction techniques. It has been observed that the proposed technique significantly preserves the radiometric information of low-dose CT images with a lesser number of edge distortion, halo and gradient reversal artifacts. Also, the proposed technique is computationally faster than existing techniques, therefore most suitable for real-time low-dose CT reconstruction systems.
C1 [Pathak, Yadunath; Arya, K. V.] Atal Bihari Vajpayee Indian Inst Informat Technol, Multimedia & Informat Secur Lab, Gwalior 474015, India.
   [Tiwari, Shailendra] Thapar Univ, Patiala, Punjab, India.
C3 ABV-Indian Institute of Information Technology & Management, Gwalior;
   Thapar Institute of Engineering & Technology
RP Pathak, Y (corresponding author), Atal Bihari Vajpayee Indian Inst Informat Technol, Multimedia & Informat Secur Lab, Gwalior 474015, India.
EM yadunath@iiitm.ac.in
RI Tiwari, Shailendra/ABF-3873-2021; PATHAK, YADUNATH/AFR-0689-2022
OI Tiwari, Shailendra/0000-0001-7209-0437; PATHAK,
   YADUNATH/0000-0002-4062-7858; Arya, Karm Veer/0000-0001-7117-1745
CR Akashita S, 2015, JPN J RADIOL, V33, P113, DOI 10.1007/s11604-014-0384-z
   Albertina B., 2016, Cancer Imaging Arch
   Azeem Ahmad VD, 2015, APPL PHYS LETT, V106
   Bournan C, 1993, IEEE T IMAGE PROCESS, V2, P296, DOI 10.1109/83.236536
   Brown AA, 2009, ANGLE ORTHOD, V79, P150, DOI 10.2319/122407-599.1
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Elbakri IA, 2002, IEEE T MED IMAGING, V21, P89, DOI 10.1109/42.993128
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fang JM, 2017, ABDOM RADIOL, V42, P742, DOI 10.1007/s00261-016-1023-1
   Gilboa G, 2004, IEEE T PATTERN ANAL, V26, P1020, DOI 10.1109/TPAMI.2004.47
   Gnahm C, 2015, NEUROIMAGE, V105, P452, DOI 10.1016/j.neuroimage.2014.11.006
   GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751
   Greffier J, 2015, DIAGN INTERV IMAG, V96, P477, DOI 10.1016/j.diii.2015.02.007
   Han-Ming Z, 2013, CHINESE PHYS B, V22
   Hara AK, 2009, AM J ROENTGENOL, V193, P764, DOI 10.2214/AJR.09.2397
   Katsura M, 2013, EUR J RADIOL, V82, P356, DOI 10.1016/j.ejrad.2012.11.004
   Kim SH, 2015, ACTA RADIOL, V56, P899, DOI 10.1177/0284185114542297
   Kim Y, 2015, AM J ROENTGENOL, V204, P1197, DOI 10.2214/AJR.14.13629
   Kojima S, 2015, RADIOL PHYS TECHNOL, V8, P295, DOI 10.1007/s12194-015-0320-7
   Kumar A., 2014, Sensors Journal, IEEE, VPP., P2505, DOI DOI 10.1109/JSEN.2014.2359794
   Lee HJ, 2018, CLIN IMAG, V51, P327, DOI 10.1016/j.clinimag.2018.06.018
   Li L, 2016, J X-RAY SCI TECHNOL, V24, P161, DOI 10.3233/XST-160540
   Liu Y, 2014, IEEE T MED IMAGING, V33, P749, DOI 10.1109/TMI.2013.2295738
   Mahmood U, 2014, MED PHYS, V41, P151, DOI 10.1118/1.4888039
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Miller K., 1970, SIAM J MATH ANAL, V1, P52, DOI DOI 10.1137/0501006
   Moloney F, 2018, RADIOGRAPHY, V24, P345, DOI 10.1016/j.radi.2018.04.010
   Nagata K, 2015, EUR RADIOL, V25, P221, DOI 10.1007/s00330-014-3350-3
   Nelson TR, 2014, J AM COLL RADIOL, V11, P292, DOI 10.1016/j.jacr.2013.10.011
   Nien H, 2015, IEEE T MED IMAGING, V34, P388, DOI 10.1109/TMI.2014.2358499
   Olcott EW, 2014, ACAD RADIOL, V21, P774, DOI 10.1016/j.acra.2014.02.012
   Padole A, 2014, AM J ROENTGENOL, V203, P772, DOI 10.2214/AJR.13.12312
   Pati YC, 1993, SIGN SYST COMP 1993, P40, DOI DOI 10.1109/ACSSC.1993.342465
   Qian WL, 2018, CLIN RADIOL, V73, DOI 10.1016/j.crad.2018.08.001
   Rampinelli C, 2015, RADIOL MED, V120, P611, DOI 10.1007/s11547-015-0505-5
   Samei E, 2015, MED PHYS, V42, P314, DOI 10.1118/1.4903899
   Takahashi M, 2016, J CARDIOVASC COMPUT, V10, P61, DOI 10.1016/j.jcct.2015.07.012
   Thibault JB, 2007, MED PHYS, V34, P4526, DOI 10.1118/1.2789499
   Vishal Srivastava SN, 2013, APPL PHYS LETT, V50, P6343
   Vishal Srivastava SN, 2013, APPL PHYS LETT, V102
   Wu WW, 2018, APPL MATH MODEL, V63, P538, DOI 10.1016/j.apm.2018.07.006
   Xu Q, 2016, MED PHYS, V43, P3701, DOI 10.1118/1.4957233
   Xu Q, 2016, MED PHYS, V43, P3389, DOI 10.1118/1.4955840
   Xu Q, 2012, IEEE T MED IMAGING, V31, P1682, DOI 10.1109/TMI.2012.2195669
   Yoon JH, 2014, J COMPUT ASSIST TOMO, V38, P859, DOI 10.1097/RCT.0000000000000145
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Yuki H, 2016, ACTA RADIOL, V57, P295, DOI 10.1177/0284185115575537
   Zhang C, 2015, COMPUT MATH METHODS, V2015
   Zhang C, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-016-0193-y
   Zhang HY, 2017, OPTIK, V131, P785, DOI 10.1016/j.ijleo.2016.11.186
   Zhang H, 2014, COMPUT MED IMAG GRAP, V38, P423, DOI 10.1016/j.compmedimag.2014.05.002
   [张红芳 Zhang Hongfang], 2014, [广东农业科学, Guangdong Agricultural Sciences], V41, P4
   Zhang YB, 2017, IEEE T MED IMAGING, V36, P142, DOI 10.1109/TMI.2016.2600249
NR 53
TC 7
Z9 7
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14733
EP 14752
DI 10.1007/s11042-018-6840-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700027
DA 2024-07-18
ER

PT J
AU Wu, WH
   Zhu, H
   Zhang, Q
AF Wu, Wenhuan
   Zhu, Hong
   Zhang, Qian
TI Oriented-linear-tree based cost aggregation for stereo matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo matching; Cost aggregation; Oriented linear tree; Cost volume;
   Edge-aware filtering
ID ADAPTIVE SUPPORT; SEGMENTATION; ALGORITHM
AB Matching cost aggregation is one of the most important steps in dense stereo correspondence, and non-local cost aggregation methods based on tree structures have been widely studied recently. In this paper, we analyze the shortcomings of both the local window-based aggregation methods and the non-local tree-based aggregation methods, and propose a novel oriented linear tree structure for each pixel to perform the non-local cost aggregation strategy. Firstly, each pixel in the image has an oriented linear tree rooted on it and each oriented linear tree consists of multiple 1D paths from different directions. Compared to other spanning trees, our oriented linear trees don't need to be additionally constructed beforeh and since they are naturally embedded in the original image. Moreover, each root pixel not only gets supports from adjacent pixels within its local support window, but also receives supports from the other pixels along all 1D paths. Secondly, for each pixel lying on the same 1D path, we can at the same time calculate their aggregated cost along their path by traversing the path back and forth twice. Finally, the final aggregated cost for each root pixel can be calculated by summing the aggregated costs from all 1D paths. Performance evaluation on the Middlebury and KITTI datasets shows that the proposed method outperforms the current state-of-the-art aggregation methods.
C1 [Wu, Wenhuan; Zhu, Hong] Xian Univ Technol, Sch Automat & Informat Engn, Xian 710048, Shaanxi, Peoples R China.
   [Wu, Wenhuan] Hubei Univ Automot Technol, Sch Elect & Informat Engn, Shiyan 442002, Peoples R China.
   [Zhang, Qian] Taishan Univ, Dept Informat Sci & Technol, Tai An 271021, Shandong, Peoples R China.
C3 Xi'an University of Technology; Hubei University of Automotive
   Technology; Taishan University
RP Zhu, H (corresponding author), Xian Univ Technol, Sch Automat & Informat Engn, Xian 710048, Shaanxi, Peoples R China.
EM zhuhong@xaut.edu.cn
RI Zhang, Qian/AAB-1715-2020
FU National Natural Science Foundation of China [61673318, 61703301,
   61771386, 61801005]; Research project of Hubei Provincial Department of
   Education, China [B2017080]
FX This work was supported by National Natural Science Foundation of China
   (No.61673318, No.61703301, No.61771386, No.61801005); by Research
   project of Hubei Provincial Department of Education (B2017080), China.
CR [Anonymous], P 32 AAAI C ART INT
   [Anonymous], 2012, AS C COMP VIS
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2012, KITTI VISION BENCHMA
   [Anonymous], P IEEE C COMP VIS PA
   Bleyer M, 2005, ISPRS J PHOTOGRAMM, V59, P128, DOI 10.1016/j.isprsjprs.2005.02.008
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Cheng FY, 2015, PATTERN RECOGN, V48, P2269, DOI 10.1016/j.patcog.2015.01.002
   Cigla C., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P696, DOI 10.1109/ICCVW.2011.6130315
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Fusiello A, 2000, INT J PATTERN RECOGN, V14, P1053, DOI 10.1142/S0218001400000696
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405
   Güney F, 2015, PROC CVPR IEEE, P4165, DOI 10.1109/CVPR.2015.7299044
   Hafner David., 2013, International_Conference_on_Scale_Space and_Variational_Methods_in_Computer_Vision, P210
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Hosni A, 2013, COMPUT VIS IMAGE UND, V117, P620, DOI 10.1016/j.cviu.2013.01.007
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   Kao CC, 2017, MULTIMED TOOLS APPL, V76, P12981, DOI 10.1007/s11042-016-3733-3
   Kappes JH, 2013, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2013.175
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2017, AAAI CONF ARTIF INTE, P4118
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mattoccia Stefano, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P371
   Mei X, 2013, PROC CVPR IEEE, P313, DOI 10.1109/CVPR.2013.47
   Mei X, 2011, PROC CVPR IEEE, P1257
   Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329
   Richardt C, 2010, LECT NOTES COMPUT SC, V6313, P510
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D., 2002, MIDDLEBURY STEREO VI
   Sengupta S, 2013, IEEE INT CONF ROBOT, P580, DOI 10.1109/ICRA.2013.6630632
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Tombari F, 2007, LECT NOTES COMPUT SC, V4872, P427
   Vanaken C, 2006, EUROGR TECH REP SER, P69
   Veksler O, 2003, PROC CVPR IEEE, P556
   Veksler O, 2005, PROC CVPR IEEE, P384
   Wang Z. F., 2008, P IEEE C COMPUTER VI, P1
   Wu WH, 2018, MULTIMED TOOLS APPL, V77, P15747, DOI 10.1007/s11042-017-5149-0
   Yamaguchi K, 2014, LECT NOTES COMPUT SC, V8693, P756, DOI 10.1007/978-3-319-10602-1_49
   Yang QX, 2015, IEEE T PATTERN ANAL, V37, P834, DOI 10.1109/TPAMI.2014.2353642
   Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827
   Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zabih R., 1994, P ECCV, P151
   Zhang C, 2015, IEEE I CONF COMP VIS, P2057, DOI 10.1109/ICCV.2015.238
   Zhang K, 2014, PROC CVPR IEEE, P1590, DOI 10.1109/CVPR.2014.206
   Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478
NR 57
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 15779
EP 15800
DI 10.1007/s11042-018-6993-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500003
DA 2024-07-18
ER

PT J
AU Du, H
   Liu, Z
   Shi, R
AF Du, Huan
   Liu, Zhi
   Shi, Ran
TI Salient object segmentation based on depth-aware image layering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth consistency integration; Depth distribution; Image layering; Depth
   histogram; Adaptive sample update and selection; Salient object
   segmentation
ID ENERGY MINIMIZATION; VISUAL-ATTENTION; EXTRACTION
AB This paper proposes an efficient salient object segmentation method via depth-aware image layering. First, based on the multiscale region segmentation results of an input color image, the depth consistency integration is utilized to generate the image pre-segmentation result. Then, under the guidance of the depth histogram division, the pre-segmented regions are divided into several different layers to differentiate salient object regions and background regions. Finally, an adaptive sample update and selection method based on layered image regions is used to select appropriate training samples for salient object segmentation. The depth information of the image is fully utilized in each step of the entire framework. Experimental results on two public datasets demonstrate that the proposed method achieves the better performance than the state-of-the-art depth-aware salient object segmentation methods.
C1 [Du, Huan; Liu, Zhi] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Du, Huan; Liu, Zhi] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Du, Huan] Minist Publ Secur, Res Inst 3, Technol Res & Dev Ctr Internet Things, Shanghai 201204, Peoples R China.
   [Shi, Ran] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
C3 Shanghai University; Shanghai University; Ministry of Public Security
   (China); Nanjing University of Science & Technology
RP Liu, Z (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.; Liu, Z (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM huan_du@163.com; liuzhisjtu@163.com; rshi@njust.edu.cn
RI LIU, Zhi/D-4518-2012
OI LIU, Zhi/0000-0002-8428-1131
FU National Natural Science Foundation of China [61771301, 61801219];
   Shanghai Science and Technology Commission Project [17595800900]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61771301 and 61801219, and by Shanghai Science and
   Technology Commission Project under Grant No. 17595800900.
CR Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Du H, 2016, IEEE ACCESS, V4, P8987, DOI 10.1109/ACCESS.2016.2632724
   Du H, 2013, J VIS COMMUN IMAGE R, V24, P499, DOI 10.1016/j.jvcir.2013.03.003
   Fan XX, 2014, INT CONF DIGIT SIG, P454, DOI 10.1109/ICDSP.2014.6900706
   FU H, 2017, TIP, V26, P1418, DOI DOI 10.1109/TIP.2017.2651369
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Hu SM, 2013, VISUAL COMPUT, V29, P393, DOI 10.1007/s00371-013-0792-6
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Ko BC, 2006, J OPT SOC AM A, V23, P2462, DOI 10.1364/JOSAA.23.002462
   Lei JJ, 2015, IEEE T MULTIMEDIA, V17, P457, DOI 10.1109/TMM.2015.2400823
   Lei JJ, 2013, NEUROCOMPUTING, V120, P24, DOI 10.1016/j.neucom.2012.08.057
   Lin SS, 2013, IEEE T MULTIMEDIA, V15, P359, DOI 10.1109/TMM.2012.2228475
   Liu HW, 2014, J VIS COMMUN IMAGE R, V25, P709, DOI 10.1016/j.jvcir.2013.03.012
   Liu Z, 2012, IEEE T MULTIMEDIA, V14, P1275, DOI 10.1109/TMM.2012.2190385
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Mishra AK, 2012, IEEE INT CONF ROBOT, P4406, DOI 10.1109/ICRA.2012.6225107
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rutishauser U., 2004, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2004.1315142
   Setlur V, 2007, IEEE COMPUT GRAPH, V27, P80, DOI 10.1109/MCG.2007.133
   Shen LQ, 2013, MULTIMED TOOLS APPL, V63, P709, DOI 10.1007/s11042-011-0893-z
   Song HK, 2017, IEEE T IMAGE PROCESS, V26, P4204, DOI 10.1109/TIP.2017.2711277
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Tang M, 2013, IEEE I CONF COMP VIS, P1769, DOI 10.1109/ICCV.2013.222
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Xingxing Fan, 2015, Graph-Based Representations in Pattern Recognition. 10th IAPR-TC-15 International Workshop, GbRPR 2015. Proceedings: LNCS 9069, P272, DOI 10.1007/978-3-319-18224-7_27
   Xue JR, 2011, IEEE T IMAGE PROCESS, V20, P1177, DOI 10.1109/TIP.2010.2077643
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1700, DOI 10.1109/TMM.2014.2326836
NR 35
TC 9
Z9 9
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12125
EP 12138
DI 10.1007/s11042-018-6736-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900047
DA 2024-07-18
ER

PT J
AU Garg, G
   Juneja, M
AF Garg, Gaurav
   Juneja, Mamta
TI A survey of denoising techniques for multi-parametric prostate MRI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Filters; Denoising; Multi-parametric; MRI; Noise; Prostate
ID SEGMENTATION TECHNIQUES; IMAGE; NOISE
AB Denoising is one of active area of research in the image-processing domain since last decade. Internal and external conditions of acquisition device are the main source of noise in an image during the procurement process, which is often impossible to avoid in practical situations. Since many different image denoising algorithms have been recommended till date, but the issue of noise elimination remains an undefended challenge. The main objective of this paper is to study and analyze the behavior of different denoising filters for multi-parametric (mp) prostate MRI so that the appropriate filter can be selected unanimously. This study evaluates the performance of fifteen denoising filters (Anisotropic, Median, Wiener, Gaussian, Mean, Wavelet, Contourlet, Bilateral, Curvelet, WHMT, NLM, GFOE, LMMSE, CURE-LET and ARF) w.r.t mp-prostate MRI i.e. T2w, DCE and DWI images in the presence of Gaussian and Rician noise. Evaluation is done in both variable and fixed level of noise. Both subjective and objective quality assessment parameters are considered for determining the final rating of filters executed over 300 mp-MRI images. This study concludes that anisotropic and NLM filter should be opted for denoising task because of their structural and other crucial details preserving capability.
C1 [Garg, Gaurav; Juneja, Mamta] Panjab Univ, Univ Inst Engn & Technol, Dept Comp Sci & Engn, Chandigarh, India.
C3 Panjab University
RP Garg, G (corresponding author), Panjab Univ, Univ Inst Engn & Technol, Dept Comp Sci & Engn, Chandigarh, India.
EM ergaurav.garg@yahoo.com; mamtajuneja@pu.ac.in
RI Garg, Gaurav/O-4916-2018
OI Garg, Gaurav/0000-0002-8257-562X; Juneja, Mamta/0000-0002-2611-9005
CR Aja-Fernández S, 2008, IEEE T IMAGE PROCESS, V17, P1383, DOI 10.1109/TIP.2008.925382
   Barbu A, 2009, IEEE T IMAGE PROCESS, V18, P2451, DOI 10.1109/TIP.2009.2028254
   Blu T, 2007, IEEE T IMAGE PROCESS, V16, P2778, DOI 10.1109/TIP.2007.906002
   BUADES A, 2008, PROC CVPR IEEE, V2, P60
   Burrus C.S., 1998, Introduction to wavelets and wavelet transforms: A primer, V1
   Cahan A, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6663
   Candes E., 1999, Curvelets
   Cattin DP, 2013, IMAGE RESTORATION IN
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dosselmann R, 2011, SIGNAL IMAGE VIDEO P, V5, P81, DOI 10.1007/s11760-009-0144-1
   Fabijanska A, 2016, COMPUT BIOL MED, V73, P119, DOI 10.1016/j.compbiomed.2016.04.010
   Garg Gaurav, 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P829, DOI 10.1007/978-981-10-6890-4_79
   GARG G, 2016, INDIAN J SCI TECHNOL, V9, pNI519, DOI DOI 10.17485/ijst/2016/v9i44/105093
   Garg G, 2018, ADV INTELL SYST, V564, P115, DOI 10.1007/978-981-10-6875-1_12
   Garg G, 2018, CURR MED IMAGING, V14, P19, DOI 10.2174/1573405613666170504145842
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   GUDBJARTSSON H, 1995, MAGNET RESON MED, V34, P910, DOI 10.1002/mrm.1910340618
   HADDAD RA, 1991, IEEE T SIGNAL PROCES, V39, P723, DOI 10.1109/78.80892
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   Kaur R, 2018, CURR MED IMAGING REV, V14, P238, DOI 10.2174/1573405613666161221164146
   LEMAITRE G, 2015, PROC SPIE, V9534
   Lemaître G, 2015, PROC SPIE, V9785, DOI 10.1117/12.2216072
   Lemaître G, 2015, COMPUT BIOL MED, V60, P8, DOI 10.1016/j.compbiomed.2015.02.009
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Luisier F, 2007, IEEE T IMAGE PROCESS, V16, P593, DOI 10.1109/TIP.2007.891064
   Luisier F, 2012, IEEE T IMAGE PROCESS, V21, P3454, DOI 10.1109/TIP.2012.2191565
   Macovski A, 1996, MAGNET RESON MED, V36, P494, DOI 10.1002/mrm.1910360327
   Manjon J.V., 2016, Imaging Biomarkers, P53, DOI 10.1007/978-3-319-43504-6_5
   Moghaddam B, 2007, IEEE I CONF COMP VIS, P2073, DOI 10.1109/cvpr.2007.383092
   Mohan J, 2014, BIOMED SIGNAL PROCES, V9, P56, DOI 10.1016/j.bspc.2013.10.007
   Oza SD, 2016, ADV COMPUTING APPL, P87, DOI [10.1007/978-981-10-2630-06, DOI 10.1007/978-981-10-2630-06]
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Redpath TW, 1998, BRIT J RADIOL, V71, P704, DOI 10.1259/bjr.71.847.9771379
   Rodríguez AO, 2004, REV MEX FIS, V50, P272
   Romberg JK, 2001, IEEE T IMAGE PROCESS, V10, P1056, DOI 10.1109/83.931100
   Roth S, 2005, PROC CVPR IEEE, P860
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Thakur N, 2017, CURR MED IMAGING REV, V13, P99, DOI 10.2174/1573405612666160606124044
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Trigui R, 2017, BIOMED SIGNAL PROCES, V31, P189, DOI 10.1016/j.bspc.2016.07.015
   Trigui R, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P113, DOI 10.1109/ATSIP.2016.7523064
   Wright GA, 1997, IEEE SIGNAL PROC MAG, V14, P56, DOI 10.1109/79.560324
   ZHU H, 1937, J AM STAT ASSOC, V104, P623
NR 44
TC 14
Z9 14
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 12689
EP 12722
DI 10.1007/s11042-018-6487-2
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900004
DA 2024-07-18
ER

PT J
AU Kumar, PB
   Sethy, M
   Parhi, DR
AF Kumar, Priyadarshi Biplab
   Sethy, Mukesh
   Parhi, Dayal R.
TI An intelligent computer vision integrated regression based navigation
   approach for humanoids in a cluttered environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Navigation; Humanoid NAO; Linear Regression; Computer Vision; V-REP
ID MOBILE ROBOT NAVIGATION; ALGORITHM; NETWORK
AB With a clear edge over the mobile robot counterparts, humanoids have become the centre of attraction for people dealing with robotics research. The enhanced use of the humanoids in industrial automation, manufacturing and other related areas has forced researchers to focus on their navigational aspects. In the current work, a computer vision integrated regression based navigational approach has been designed and implemented on a humanoid. Initially, a regression control architecture has been formulated for path planning and obstacle avoidance of a humanoid considering sensor information regarding obstacle distances as the inputs and the necessary heading angle as the output for the controller. Then, the limitations available in the regression based approach have been found out. To avoid the limitations, a computer vision based technique has been integrated with the original regression based approach. It has been observed that by the use of computer vision based technique, the robot is able to clearly distinguish between different types of obstacles, arena and target and reach the target position safely. Multiple simulations and real-time experiments have been conducted to verify the effectiveness of the proposed controller. The results obtained from both the simulation and experimental platforms have been compared against each other in terms of navigational parameters, and a good agreement between them is observed. The developed approach has also been assessed against another existing navigational technique, and a significant performance improvement has been observed. Finally, concluding remarks have been given regarding the use of both the techniques in humanoid navigation in complex environments.
C1 [Kumar, Priyadarshi Biplab; Sethy, Mukesh; Parhi, Dayal R.] Natl Inst Technol, Robot Lab, Mech Engn Dept, Rourkela 769008, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Kumar, PB (corresponding author), Natl Inst Technol, Robot Lab, Mech Engn Dept, Rourkela 769008, Odisha, India.
EM p.biplabkumar@gmail.com; mukeshatnitr@gmail.com; dayaldoc@yahoo.com
RI Parhi, Dayal/M-7935-2018
OI Parhi, Dayal/0000-0002-2073-7136
CR Abdessemed F, 2004, ROBOT AUTON SYST, V47, P31, DOI 10.1016/j.robot.2004.02.006
   [Anonymous], 2013, 13th International Conference on Autonomous Robot Systems (Robotica)
   [Anonymous], 2018, INT J COMPUTER APPL
   [Anonymous], 2002, 593598 AAAIIAAI
   Benamati L, 2005, 2005 12TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS, P103
   Bruce J, 2000, 2000 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2000), VOLS 1-3, PROCEEDINGS, P2061, DOI 10.1109/IROS.2000.895274
   Burns B, 2004, COMPUTER SCI DEP FAC, V51
   Clever D, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII
   Dahlkamp H, 2006, ROBOTICS SCI SYSTEMS, Vl, P38
   Davison A. J., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P809, DOI 10.1007/BFb0054781
   DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903
   Duchon F, 2014, PROCEDIA ENGINEER, V96, P59, DOI 10.1016/j.proeng.2014.12.098
   Engedy I., 2010, Proceedings 2010 11th International Symposium on Computational Intelligence and Informatics (CINTI 2010), P213, DOI 10.1109/CINTI.2010.5672245
   Frank B., 2011, AUTOMATED ACTION PLA
   Gorner M, 2010, 10 INT S ART INT ROB
   Gutmann JS, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1232
   Hong YD, 2015, J ELECTR ENG TECHNOL, V10, P2142, DOI 10.5370/JEET.2015.10.5.2142
   Kala R, 2010, CYBERNET SYST, V41, P435, DOI 10.1080/01969722.2010.500800
   Keshmiri S, 2012, INT J SOC ROBOT, V4, P15, DOI 10.1007/s12369-011-0102-2
   Kumar A, 2018, ARAB J SCI ENG, P1
   Kumar P.B., 2017, P 2017 NIRM U INT C, P1, DOI [10.1109/NUICONE.2017.8325611, DOI 10.1109/NUICONE.2017.8325611]
   Kumar PB, 2018, APPL SOFT COMPUT, V68, P565, DOI 10.1016/j.asoc.2018.04.023
   Kumar SM, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN RECENT TECHNOLOGIES IN COMMUNICATION AND COMPUTING (ARTCOM 2009), P727, DOI 10.1109/ARTCom.2009.119
   Lee KB, 2015, IEEE T IND ELECTRON, V62, P5586, DOI 10.1109/TIE.2015.2405901
   Lee YJ, 2002, ADV ROBOTICS, V16, P609, DOI 10.1163/15685530260390746
   Lemaire T, 2007, INT J COMPUT VISION, V74, P343, DOI 10.1007/s11263-007-0042-3
   Liu WF, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9060590
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahyuddin MN, 2014, ROBOT AUTON SYST, V62, P294, DOI 10.1016/j.robot.2013.09.013
   Meléndez A, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/55561
   Min HS, 2015, ADV MECH ENG, V7, DOI 10.1177/1687814015619276
   Mirjalili R, 2016, RSI INT CONF ROBOT M, P416, DOI 10.1109/ICRoM.2016.7886774
   Mizuuchi I, 1999, ROBOT AUTON SYST, V28, P99, DOI 10.1016/S0921-8890(99)00009-3
   Mohamed Z, 2012, PROCEDIA ENGINEER, V41, P345, DOI 10.1016/j.proeng.2012.07.183
   Mohanta JC, 2018, ARAB J SCI ENG, V43, P1395, DOI 10.1007/s13369-017-2899-y
   Mohanty PK, 2015, MEMET COMPUT, V7, P255, DOI 10.1007/s12293-015-0160-3
   Mohanty PK, 2014, J MECH SCI TECHNOL, V28, P2861, DOI 10.1007/s12206-014-0640-2
   Mohanty PK, 2014, APPL MATH INFORM SCI, V8, P2527, DOI 10.12785/amis/080551
   Mohanty PK, 2014, ADV INTELL SYST, V247, P353, DOI 10.1007/978-3-319-02931-3_40
   Ohki T, 2012, ADV ROBOTICS, V26, P1623, DOI 10.1080/01691864.2012.694648
   Pandey A., 2016, International Journal of Advanced Robot Automn, V1, P1, DOI DOI 10.15226/2473-3032/1/1/00102
   Parhi DR, 2009, INT J AUTOM CONTROL, V3, P114, DOI 10.1504/IJAAC.2009.025237
   Pham DT, 2003, ROBOTICA, V21, P79, DOI [10.1017/S0263574704526, 10.1017/S0263574702004526]
   Pothal JK, 2015, ROBOT AUTON SYST, V72, P48, DOI 10.1016/j.robot.2015.04.007
   Pun-Cheng LSC, 2007, INT J GEOGR INF SCI, V21, P175, DOI 10.1080/13658810600852206
   Qi NN, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P2603, DOI 10.1109/WCICA.2008.4593333
   Singh MK, 2011, INT J SYST SCI, V42, P107, DOI 10.1080/00207720903470155
   TAO D, 2018, TIP, V27, P325, DOI DOI 10.1109/TIP.2017.2762588
   Tao DP, 2016, IEEE T CYBERNETICS, V46, P756, DOI 10.1109/TCYB.2015.2414920
   Tuncer A, 2012, COMPUT ELECTR ENG, V38, P1564, DOI 10.1016/j.compeleceng.2012.06.016
   Xia ZY, 2011, IEEE-ASME T MECH, V16, P716, DOI 10.1109/TMECH.2010.2051679
   Xing Deng-Peng, 2011, Acta Automatica Sinica, V37, P228, DOI 10.3724/SP.J.1004.2011.00228
   Xue FZ, 2014, ADV MECH ENG, DOI 10.1155/2014/180620
   Zhang XL, 2016, INT J ADV ROBOT SYST, V13, DOI 10.5772/63484
NR 54
TC 7
Z9 7
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11463
EP 11486
DI 10.1007/s11042-018-6703-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900017
DA 2024-07-18
ER

PT J
AU Li, H
   Jiang, H
   Wang, HB
   Zeng, W
AF Li, Hui
   Jiang, Hui
   Wang, Huabin
   Zeng, Wei
TI Improving sparse representation-based image classification using
   truncated total least squares
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse representation; Truncated total least squares; Image
   classification; Face recognition
ID FACE; RECOGNITION; ALGORITHMS
AB In the field of face recognition, the Sparse Representation-based Classification (SRC) method can effectively deal with many common problems such as face occlusion, lighting and expression changes. Truncated Total Least Squares (TTLS) method is determined by using an optimal cutoff factor k. The choice of truncation factor regularization parameters directly affects the quality of the solution. The truncation of total least squares is suitable for solving the linear problems of the same kind. According to this motivation, a classification method TSRC based on the truncation representation is proposed. The truncated global least squares regularization is fused with sparse representation to optimize the representation coefficients. We performed a large number of experiments with this method on several popular benchmark datasets, and the results showed that the sparse representation can be improved if it is combined with the truncation. In most cases, the proposed truncation-based classification method has higher classification accuracy.
C1 [Li, Hui; Jiang, Hui; Wang, Huabin; Zeng, Wei] Huizhou Univ, Sch Informat Sci & Technol, Huizhou 516007, Guangdong, Peoples R China.
C3 Huizhou University
RP Jiang, H (corresponding author), Huizhou Univ, Sch Informat Sci & Technol, Huizhou 516007, Guangdong, Peoples R China.
EM zjhz_lihui@163.com; jianghui201712@163.com; whuab@hzu.edu.cn;
   weizeng@hzu.edu.cn
FU national social science fund in China [15BTJ024]; planning fund project
   of humanities and social science research in Chinese Ministry of
   Education [14YJAZH040]; teaching reform of higher education in
   undergraduate colleges and universities from Guangdong province
   [[2016]236-502, [2015]173-588]; Huizhou Municipal Science and Technology
   Project Fund [2016X0422037, 2017C0405021]; Field Scientific Research
   Project of Huizhou University [hzu201716]; Indigenous Innovation's
   Capability Development Program of Huizhou University [hzu201815];
   Guangdong Provincial Key Laboratory of Technology and Finance & Big Data
   Analysis [2017B030301010]; Guangdong Key Research Base of Technology and
   Finance [2014B030303005]; Platform of Credit Financing and Trade for
   Guangdong Technological Enterprises [2014B080807035]
FX The work is supported by the national social science fund in China
   (Grant No. 15BTJ024), the planning fund project of humanities and social
   science research in Chinese Ministry of Education (Grant No.
   14YJAZH040), the teaching reform of higher education in undergraduate
   colleges and universities from Guangdong province (Grant No.
   [2016]236-502, [2015]173-588), Huizhou Municipal Science and Technology
   Project Fund (Grant No. 2016X0422037, 2017C0405021), the Field
   Scientific Research Project of Huizhou University (Grant No. hzu201716),
   Indigenous Innovation's Capability Development Program of Huizhou
   University (Grant No. hzu201815), Guangdong Provincial Key Laboratory of
   Technology and Finance & Big Data Analysis(Grant No. 2017B030301010),
   Guangdong Key Research Base of Technology and Finance(Grant No.
   2014B030303005), Platform of Credit Financing and Trade for Guangdong
   Technological Enterprises(Grant No. 2014B080807035).
CR A. L. Cambridge, 2016, ORL DAT FAC
   [Anonymous], 2016, GEORGIA TECH FACE DA
   [Anonymous], 2016, TIP, DOI DOI 10.1109/TIP.2015.2510498
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.322
   Baglama J, 2015, EFFICIENT THRESHOLDE
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bhotto MZA, 2015, SIAM J IMAGING SCI, V8, P1640, DOI 10.1137/140970537
   Chen Y, 2008, J MATH IMAGING VIS, V30, P133, DOI 10.1007/s10851-007-0042-5
   Chen Y, 2018, IEEE T CIRC SYST VID, V28, P414, DOI 10.1109/TCSVT.2016.2615444
   Chen Y, 2016, IEEE T IMAGE PROCESS, V25, P988, DOI 10.1109/TIP.2015.2496279
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Fierro RD, 2006, SIAM JSCICOMP, V18, P124
   Gao Shenghua., 2010, COMPUTER VISION ECCV
   Gratton S, 2013, SIAM J MATRIX ANAL A, V34, P1257, DOI 10.1137/120895019
   Huang SG, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092087
   Liu J, 2018, IEEE T CIRC SYST VID, V28, P1232, DOI 10.1109/TCSVT.2016.2643009
   Liu J, 2017, IEEE T MED IMAGING, V36, P2499, DOI 10.1109/TMI.2017.2739841
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Peng Y., 2016, INT J DATABASE THEOR, V9, P183, DOI DOI 10.14257/ijdta.2016.9.2.20
   PUTTEN P, 2000, COIL CHALLENGE 2000
   Senthilkumar, 2016, SENTHIL IRTT FACE DA
   Singh G, 2016, INT J IMAGE GRAPH, V16, DOI 10.1142/S0219467816500212
   SUN T, 2016, IET, V10, P28, DOI DOI 10.1049/iet-spr.2015.0096
   T. N. I. of Standards T. (NIST), 2016, COL FER DAT
   Wang KP, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19070306
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2015, PATTERN RECOGN LETT, V68, P9, DOI 10.1016/j.patrec.2015.07.032
   Xu Y, 2013, INFORM SCIENCES, V238, P138, DOI 10.1016/j.ins.2013.02.051
   Xu Y, 2013, PATTERN RECOGN, V46, P1151, DOI 10.1016/j.patcog.2012.11.003
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeng SN, 2017, MULTIMED TOOLS APPL, V76, P20889, DOI 10.1007/s11042-016-4035-5
   Zeng SN, 2018, NEURAL COMPUT APPL, V30, P2965, DOI 10.1007/s00521-017-2900-4
   Zhang L, 2015, MULTIMED TOOLS APPL, V74, P123, DOI 10.1007/s11042-013-1457-1
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
NR 41
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12007
EP 12026
DI 10.1007/s11042-018-6740-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900041
DA 2024-07-18
ER

PT J
AU Mercado, J
   Espinosa-Curiel, I
   Escobedo, L
   Tentori, M
AF Mercado, Jose
   Espinosa-Curiel, Ismael
   Escobedo, Lizbeth
   Tentori, Monica
TI Developing and evaluating a BCI video game for neurofeedback training:
   the case of autism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autism; Brain-computer Interface; Neurofeedback; Video game; BCI;
   Attention
ID BRAIN-COMPUTER INTERFACES; SERIOUS GAME; USER EXPERIENCE; CHILDREN;
   ATTENTION; INTERVENTIONS; ANXIETY; DESIGN; ADHD; LIFE
AB BCI video games are making brain training increasingly popular and available; yet scientific evidence to support its efficacy is lacking. Real-life descriptions of BCI video games deployments in concrete scenarios are urgently needed. In this paper, we report a use case of the development and pilot-testing of a BCI video game designed to support children with autism when attending to Neurofeedback training sessions, called FarmerKeeper. Caring for children with autism may impose new cognitive, motor, behavioral, and attention challenges that current solutions targeted for other populations may not address. The goal of the game is to maintain children's attention above a threshold to control a runner who is seeking for lost farm animals. FarmerKeeper uses a consumer-grade BCI headset to read user's attention. We evaluated FarmerKeeper's usability and user experience through a 4-weeks deployment study with 12 children with autism. Our quantitative results show FarmerKeeper outperforms a commercial BCI video game used for neurofeedback training, and qualitatively, FarmerKeeper could successfully support children with autism when attending to neurofeedback training sessions by possibly improving their attention and reducing their anxiety. We close reflecting on our design aspects and discussing directions for future work.
C1 [Mercado, Jose; Tentori, Monica] CICESE, Dept Comp Sci, Ensenada, BC, Mexico.
   [Espinosa-Curiel, Ismael] CICESE UT3, Tepic, Nayarit, Mexico.
   [Escobedo, Lizbeth] CETYS Univ, Sch Engn, Tijuana, BC, Mexico.
C3 CICESE - Centro de Investigacion Cientifica y de Educacion Superior de
   Ensenada
RP Mercado, J (corresponding author), CICESE, Dept Comp Sci, Ensenada, BC, Mexico.
EM jmercado@cicese.edu.mx
RI Escobedo, Lizbeth/IUO-0306-2023; Escobedo, Lizbeth/C-9311-2018; Tentori,
   Monica/C-7852-2016
OI Escobedo, Lizbeth/0000-0003-2783-047X; Espinosa-Curiel, Ismael
   Edrein/0000-0002-3136-3256; Mercado, Jose/0000-0002-7672-1985; Tentori,
   Monica/0000-0002-1491-0043
FU CONACYT [2209]
FX We thank all the participants enrolled in this study and the researchers
   and reviewers who provide helpful comments on previous versions of this
   document. We also thank CONACYT for the first author fellowship and we
   thank to the CONACYT project #2209 of the fourth author for their
   financial support.
CR Abt Clark C., 1970, SERIOUS GAMES, P6
   Alves S, 2013, PSYCHNOLOGY J, V11, P191
   American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   [Anonymous], 1908, BIOMETRIKA, V6, P1
   [Anonymous], NY TIMES
   [Anonymous], 4 INT S APPL SCI BIO
   Antshel KM, 2016, EXPERT REV NEUROTHER, V16, P279, DOI 10.1586/14737175.2016.1146591
   Bailey R, 2009, CYBERPSYCHOL BEHAV, V12, P277, DOI 10.1089/cpb.2008.0292
   Bakhshayesh AR, 2011, EUR CHILD ADOLES PSY, V20, P481, DOI 10.1007/s00787-011-0208-y
   Bernardini S, 2013, PLANNING BASED SOCIA, P362
   Beyer Hugh, 1999, interactions, V6, P32, DOI DOI 10.1145/291224.291229
   Birk MV, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2982, DOI 10.1145/2858036.2858062
   Blandon D.Z., 2016, 2016 IEEE 11th Colombian Computing Conference (CCC), P1, DOI DOI 10.1109/COLUMBIANCC.2016.7750788
   Brain S, 2016, ATT SPAN STAT STAT B
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Cibrian FL, 2018, INT CONF PER COMP, P158, DOI 10.1145/3240925.3240958
   Coben R, 2010, APPL PSYCHOPHYS BIOF, V35, P83, DOI 10.1007/s10484-009-9117-y
   Dickey MD, 2006, ETR&D-EDUC TECH RES, V54, P245, DOI 10.1007/s11423-006-8806-y
   Escobedo L, 2014, IEEE PERVAS COMPUT, V13, P38, DOI 10.1109/MPRV.2014.19
   Friese Susanne., 2019, QUALITATIVE DATA ANA
   Fuchslocher A, 2011, ENTERTAIN COMPUT, V2, P97, DOI 10.1016/j.entcom.2010.12.001
   Garzotto Franca, 2016, P 2016 CHI C HUM FAC, P1684, DOI DOI 10.1145/2851581.2892533
   Goldstein G, 2001, J AUTISM DEV DISORD, V31, P433, DOI 10.1023/A:1010620820786
   Green CS, 2008, PSYCHOL AGING, V23, P692, DOI 10.1037/a0014345
   Hallford N., 2001, Swords and Circuitry: A Designer's Guide to Computer Role-Playing Games
   Hammond D.C., 2011, J. Neurother, V15, P305, DOI [DOI 10.1080/10874208.2011.623090, 10.1080/10874208.2011.623090]
   Hardy Joseph., 2009, The Science Behind Lumosity
   Hayes GR, 2010, PERS UBIQUIT COMPUT, V14, P663, DOI 10.1007/s00779-010-0294-8
   Hefner D, 2007, LECT NOTES COMPUT SC, V4740, P39
   Heinrich H, 2007, J CHILD PSYCHOL PSYC, V48, P3, DOI 10.1111/j.1469-7610.2006.01665.x
   Heyvaert M, 2014, RES DEV DISABIL, V35, P2463, DOI 10.1016/j.ridd.2014.06.017
   Holtzblatt K., 2004, RAPID CONTEXTUAL DES, DOI [DOI 10.1145/1066322.1066325, 10.1145/1066322.1066325]
   IJsselsteijn W, 2008, P MEASURING BEHAV, P88, DOI 10.3758/BRM.41.3.717
   Keay-Bright W., 2007, CoDesign, V3, P97, DOI 10.1080/15710880601143443
   Keehn B, 2013, NEUROSCI BIOBEHAV R, V37, P164, DOI 10.1016/j.neubiorev.2012.11.014
   Keizer AW, 2010, NEUROIMAGE, V49, P3404, DOI 10.1016/j.neuroimage.2009.11.023
   Kim S.K., 2014, Int. J. Biosci. Bio Technol, V6, P13, DOI 10.14257/ijbsbt.2014.6.4.02
   Kouijzer MEJ, 2010, RES AUTISM SPECT DIS, V4, P386, DOI 10.1016/j.rasd.2009.10.007
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Lee KooHyoung, 2009, [Science of Emotion & Sensibility, 감성과학], V12, P341
   Lim C. W., 2013, ADV SCI TECHNOLOGY L, V39, P73
   Lim CG, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0046692
   Lim CG, 2010, PSYCHOPHARMACOL BULL, V43, P73
   Lubar J.F., 1995, Biofeedback, P493
   LUBAR JF, 1976, BIOFEEDBACK SELF-REG, V1, P77, DOI 10.1007/BF00998692
   Mandryk R.L., 2016, Biometrics in a data driven world: trends, technologies, and challenges, P191, DOI DOI 10.1201/9781315317083-7
   Mandryk ReganL., P 14 INT ACM SIGACCE, DOI [DOI 10.1145/2384916.2384952, 10.1145/2384916.2384952]
   Mandryk ReganL., P 12 INT C INTERACTI, DOI [10.1145/2485760.2485762, DOI 10.1145/2485760.2485762]
   May T, 2013, J AUTISM DEV DISORD, V43, P2147, DOI 10.1007/s10803-013-1766-2
   Mihajlovic V, 2015, IEEE J BIOMED HEALTH, V19, P6, DOI 10.1109/JBHI.2014.2328317
   Nouchi R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0029676
   Ochs E, 2004, DISCOURSE STUD, V6, P147, DOI 10.1177/1461445604041766
   Owen AM, 2010, NATURE, V465, P775, DOI 10.1038/nature09042
   Patsis Georgios, 2013, User Modeling, Adaptation, and Personalization. 21th International Conference, UMAP 2013. Proceedings., P127, DOI 10.1007/978-3-642-38844-6_11
   Pineda JA, 2008, RES AUTISM SPECT DIS, V2, P557, DOI 10.1016/j.rasd.2007.12.003
   Planchon J, 2018, INJURY, V49, P86, DOI 10.1016/j.injury.2017.10.025
   Pope A., 2001, International Journal of Social Psychiatry, V54, P370
   Rauschenberger M, 2013, INT J INTERACT MULTI, V2, P39, DOI 10.9781/ijimai.2013.215
   Read J.C., 2006, P INTERACTION DESIGN, P81, DOI DOI 10.1145/1139073.1139096
   Rebolledo-Mendez G, 2009, LECT NOTES COMPUT SC, V5610, P149, DOI 10.1007/978-3-642-02574-7_17
   Rego P, 2010, SISTEMAS Y TECNOLOGIAS DE INFORMACION, P349
   Renard Y, 2010, PRESENCE-VIRTUAL AUG, V19, P35, DOI 10.1162/pres.19.1.35
   Sawyer B., 2008, SLIDES SERIOUS GAMES
   Schoneveld EA, 2016, COMPUT HUM BEHAV, V63, P321, DOI 10.1016/j.chb.2016.05.005
   Schwartz M., 2017, BIOFEEDBACK PRACTITI, V4th
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Sitaram R, 2017, NAT REV NEUROSCI, V18, P86, DOI 10.1038/nrn.2016.164
   Southam-Gerow MA, 2002, CLIN PSYCHOL REV, V22, P189, DOI 10.1016/S0272-7358(01)00087-3
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Steiner NJ, 2014, J DEV BEHAV PEDIATR, V35, P18, DOI 10.1097/DBP.0000000000000009
   Strauss E, 1998, CLIN ORTHOP RELAT R, P2
   Tan D, 2010, HUM-COMPUT INT-SPRIN, P3, DOI 10.1007/978-1-84996-272-8_1
   Tang ST, 2002, CANCER INVEST, V20, P1086, DOI 10.1081/CNV-120005928
   Tang YY, 2014, TRENDS COGN SCI, V18, P345, DOI 10.1016/j.tics.2014.04.002
   Turkay S, 2014, INT J GAMING COMPUT-, V6, P1, DOI 10.4018/ijgcms.2014010101
   van Steensel FJA, 2011, CLIN CHILD FAM PSYCH, V14, P302, DOI 10.1007/s10567-011-0097-0
   Vernon D, 2003, INT J PSYCHOPHYSIOL, V47, P75, DOI 10.1016/S0167-8760(02)00091-0
   Wang Q, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P270, DOI 10.1109/CW.2010.56
   Whyte EM, 2015, J AUTISM DEV DISORD, V45, P3820, DOI 10.1007/s10803-014-2333-1
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Wilkinson N, 2008, INT J SOC PSYCHIATR, V54, P370, DOI 10.1177/0020764008091659
   Wilkinson P, 2016, LECT NOTES COMPUT SC, V9970, P63, DOI 10.1007/978-3-319-46152-6_4
   Wingate M, 2014, MMWR SURVEILL SUMM, V63
   Yoon H, 2013, 2013 INTERNATIONAL CONFERENCE ON ICT CONVERGENCE (ICTC 2013): FUTURE CREATIVE CONVERGENCE TECHNOLOGIES FOR NEW ICT ECOSYSTEMS, P785
   Zalapa Rodrigo, 2013, Ubiquitous Computing and Ambient Intelligence. Context-Awareness and Context-Driven Interaction. 7th International Conference, UCAmI 2013. Proceedings: LNCS 8276, P127, DOI 10.1007/978-3-319-03176-7_17
   Zickefoose S, 2013, BRAIN INJURY, V27, P707, DOI 10.3109/02699052.2013.775484
   Zoefel B, 2011, NEUROIMAGE, V54, P1427, DOI 10.1016/j.neuroimage.2010.08.078
NR 87
TC 22
Z9 22
U1 5
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13675
EP 13712
DI 10.1007/s11042-018-6916-2
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900047
DA 2024-07-18
ER

PT J
AU Blanco-Pons, S
   Carrión-Ruiz, B
   Lerma, JL
AF Blanco-Pons, Silvia
   Carrion-Ruiz, Berta
   Luis Lerma, Jose
TI Augmented reality application assessment for disseminating rock art
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Archaeology; Augmented reality (AR); Mobile application (app);
   Markerless tracking; ARToolKit; Vuforia
ID INFORMATION; TRACKING; SYSTEM
AB Currently, marker-based tracking is the most used method to develop augmented reality (AR) applications (apps). However, this method cannot be applied in some complex and outdoor settings such as prehistoric rock art sites owing to the fact that the usage of markers is restricted on site. Thus, natural feature tracking methods have to be used. There is a wide range of libraries to develop AR apps based on natural feature tracking. In this paper, a comparative study of Vuforia and ARToolKit libraries is carried out, analysing factors such as distance, occlusion and lighting conditions that affect user experience in both indoor and outdoor environments, and eventually the app developer. Our analysis confirms that Vuforia's user experience indoor is better, faster and flicker-free whether the images are properly enhanced, but it does not work properly on site. Therefore, the development of AR apps for complex outdoor environments such as rock art sites should be performed with ARToolKit.
C1 [Blanco-Pons, Silvia; Carrion-Ruiz, Berta; Luis Lerma, Jose] Univ Politecn Valencia, Dept Cartog Engn Geodesy & Photogrammetry, Photogrammetry & Laser Scanning Res Grp GIFLE, E-46022 Valencia, Spain.
C3 Universitat Politecnica de Valencia
RP Blanco-Pons, S (corresponding author), Univ Politecn Valencia, Dept Cartog Engn Geodesy & Photogrammetry, Photogrammetry & Laser Scanning Res Grp GIFLE, E-46022 Valencia, Spain.
EM silblapo@doctor.upv.es; bercarru@doctor.upv.es; jllerma@cgf.upv.es
RI ; Lerma, Jose Luis/C-2986-2014
OI Blanco-Pons, Silvia/0000-0003-0764-2199; Lerma, Jose
   Luis/0000-0001-9443-9214
FU Spanish Ministerio de Economia y Competitividad [HAR2014-59873-R]
FX The authors gratefully acknowledge the support from the Spanish
   Ministerio de Economia y Competitividad to the project HAR2014-59873-R.
   Similarly, the authors want to express their gratitude to the General
   Directorate of Culture and Heritage, Conselleria d'Educacio,
   Investigacio, Cultura i Esport, Generalitat Valenciana for letting us
   access and carry out research at the archaeological site.
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Amin D., 2015, INT J COMPUT SCI APP, V5, P11, DOI [10.5121/ijcsa.2015.5102, DOI 10.5121/IJCSA.2015.5102]
   [Anonymous], CAM CAL CAM CAL APP
   ARToolkit, 2017, DOCUMENTATION
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Blanco-Novoa O, 2018, IEEE ACCESS, V6, P8201, DOI 10.1109/ACCESS.2018.2802699
   Blanco-Pons S, 2016, PROCEEDINGS OF THE 8TH INTERNATIONAL CONGRESS ON ARCHAEOLOGY, COMPUTER GRAPHICS, CULTURAL HERITAGE AND INNOVATION ( ARQUEOLOGICA 2.0): ADVANCED 3D DOCUMENTATION, MODELLING AND RECONSTRUCTION OF CULTURAL HERITAGE OBJECTS, MONUMENTS AND SITES, P176, DOI 10.4995/arqueologica8.2016.3561
   Brancati N, 2017, PERS UBIQUIT COMPUT, V21, P203, DOI 10.1007/s00779-016-0987-8
   Cagalaban G, 2010, MULTIPLE OBJECT TRAC
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Carrion-Ruiz B, 2016, PROCEEDINGS OF THE 8TH INTERNATIONAL CONGRESS ON ARCHAEOLOGY, COMPUTER GRAPHICS, CULTURAL HERITAGE AND INNOVATION ( ARQUEOLOGICA 2.0): ADVANCED 3D DOCUMENTATION, MODELLING AND RECONSTRUCTION OF CULTURAL HERITAGE OBJECTS, MONUMENTS AND SITES, P169, DOI 10.4995/arqueologica8.2016.3560
   Chen CY, 2014, PERS UBIQUIT COMPUT, V18, P315, DOI 10.1007/s00779-013-0647-1
   Domingo I., 2015, Digital Applications in Archaeology and Cultural Heritage, V2, P79, DOI [10.1016/j.daach.2015.01.001, DOI 10.1016/J.DAACH.2015.01.001, 10.1016/j.daach.2015.01, DOI 10.1016/J.DAACH.2015.01]
   dos Santos AB, 2016, SYMP VIRTUAL AUGMENT, P229, DOI 10.1109/SVR.2016.46
   DroidAR, 2017, DROIDAR BITST
   Fiala M, 2005, PROC CVPR IEEE, P590
   Fischer J, 2007, COMPUT GRAPH-UK, V31, P39, DOI 10.1016/j.cag.2006.09.007
   Gonzalez C., 2011, REV ARANZADI DOCTRIN, P2
   Haladová ZB, 2015, PROCEDIA COMPUT SCI, V67, P340, DOI 10.1016/j.procs.2015.09.278
   Jamali SS, 2015, PROCD SOC BEHV, V197, P659, DOI 10.1016/j.sbspro.2015.07.054
   Jonghoon Seo, 2011, Virtual and Mixed Reality - New Trends. Proceedings International Conference, Virtual and Mixed Reality 2011. Held as Part of HCI International 2011, P97, DOI 10.1007/978-3-642-22021-0_12
   Khan D, 2018, IEEE ACCESS, V6, P22421, DOI 10.1109/ACCESS.2018.2801028
   Khan D, 2015, COMPUT STAND INTER, V41, P56, DOI 10.1016/j.csi.2015.02.006
   Kim SL, 2014, 2014 IEEE WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P21, DOI 10.1109/WF-IoT.2014.6803110
   Kounavis CD, 2012, INT J ENG BUS MANAG, V4, DOI 10.5772/51644
   La Delfa GC, 2016, FRONT INFORM TECH EL, V17, P730, DOI 10.1631/FITEE.1500324
   Liu SM, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P547, DOI 10.1109/ICISCE.2016.123
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lytridis C, 2018, EDUC SCI, V8, DOI 10.3390/educsci8010006
   Marchand E, 2016, IEEE T VIS COMPUT GR, V22, P2633, DOI 10.1109/TVCG.2015.2513408
   Gutierrez JM, 2015, PROCEDIA COMPUT SCI, V75, P390, DOI 10.1016/j.procs.2015.12.262
   Martinez R., 2002, COVA DELS CAVALLS BA
   Marto A G. R., 2017, 12a Conferencia Iberica de Sistemas E Tecnologias de Informacao, Lisboa, V64, P852, DOI DOI 10.1016/J.PROCS.2015.08.638
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Pierdicca R, 2015, LECT NOTES COMPUT SC, V9254, P38, DOI 10.1007/978-3-319-22888-4_4
   Rabbi I., 2014, INT C RECENT TRENDS, P281
   Radkowski Rafael, 2013, Virtual, Augmented and Mixed Reality. Systems and Applications. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings, Part II: LNCS 8022, P281, DOI 10.1007/978-3-642-39420-1_30
   Ridel B, 2014, ACM J COMPUT CULT HE, V7, DOI 10.1145/2611376
   Siltanen S, 2017, VISUAL COMPUT, V33, P193, DOI 10.1007/s00371-015-1174-z
   Soros G, 2011, P 10 INT C MOB UB MU, P4, DOI [10.1145/2107596.2107597, DOI 10.1145/2107596.2107597]
   Uchiyama H., 2012, 18 KOR JAP JOINT WOR
   Vuforia, 2017, VUF VUM
   Vuforia, 2017, IM TARG
   Wang GF, 2015, VISUAL COMPUT, V31, P979, DOI 10.1007/s00371-015-1098-7
   Wang HB, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P578, DOI 10.1109/CISP.2015.7407945
   WU S, 2017, IMAGE, V59, P150, DOI DOI 10.1016/J.IMAGE.2017.06.010
   Xu Y, 2018, IEEE COMPUT SOC CONF, P1586, DOI 10.1109/CVPRW.2018.00200
NR 48
TC 13
Z9 14
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10265
EP 10286
DI 10.1007/s11042-018-6609-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400035
DA 2024-07-18
ER

PT J
AU Song, EM
   Qian, YJ
   Liu, H
   Yan, M
   Song, HM
   Hung, CC
AF Song, Enming
   Qian, Yuejing
   Liu, Hong
   Yan, Meng
   Song, Huimin
   Hung, Chih-Cheng
TI A target-oriented segmentation method for specific tissues in MRI images
   of the brain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Target segmentation; Registration; Atlas; Patch-based segmentation;
   Distribution probability; Label fusion
ID ATLAS-BASED SEGMENTATION; LABEL FUSION; BIG DATA; SPARSE; HIPPOCAMPUS;
   REPRESENTATION; ALGORITHM; MOTION
AB The multi-atlas based segmentation method can achieve the accurate segmentation of specific tissues of the human brain in the magnetic resonance imaging (MRI). The correct image registration and fusion scheme used in this method have an impact on the accuracy of segmentation. Similar to any traditional rigid registration method, we use the same method in our proposed target-oriented registration for the coarse registration between the target image and atlas image. However, to improve the registration accuracy in the area to be segmented, we propose a target-oriented image registration method for the refinement. We employ the distribution probability of the tissue (to be segmented) in the sparse patch-based label fusion process. Our aim is to determine if the proposed registration method can contribute the segmentation accuracy and which label fusion method is a good fit with this target-oriented registration. To evaluate the efficiency of our proposed method, we compare the performance of the majority voting method (MV), the nonlocal patch-based method (Nonlocal-PBM) and the sparse patch-based method (Sparse-PBM). Experimental results show that more accurate segmentation results can be obtained with the proposed registration method in this study. This result can provide more accurate clinical diagnosis information.
C1 [Song, Enming; Qian, Yuejing; Liu, Hong; Yan, Meng] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
   [Qian, Yuejing] Zhejiang Ind & Trade Vocat Coll, Wenzhou, Zhejiang, Peoples R China.
   [Song, Huimin] Cent City Brewers & Distillers Ltd, Surrey, BC, Canada.
   [Hung, Chih-Cheng] Kennesaw State Univ, Ctr Machine Vis & Secur Res, Maritetta, GA USA.
C3 Huazhong University of Science & Technology; University System of
   Georgia; Kennesaw State University
RP Liu, H (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
EM hongliu@hust.edu.cn
RI Zhang, Jing/HII-4294-2022
FU National Natural Science Foundation of China [61370179, 61370181,
   81671768]
FX The authors gratefully acknowledge the help comments and suggestions of
   the editor and reviews, which have improved the presentation. This work
   was supported by the National Natural Science Foundation of China (Grant
   Nos. 61370179, Grant Nos. 61370181 and Grant Nos. 81671768).
CR Aljabar P, 2009, NEUROIMAGE, V46, P726, DOI 10.1016/j.neuroimage.2009.02.018
   [Anonymous], 2017, Big-Data Analytics for Cloud, IoT and Cognitive Computing
   [Anonymous], TIP
   Artaechevarria X, 2009, IEEE T MED IMAGING, V28, P1266, DOI 10.1109/TMI.2009.2014372
   Bai WJ, 2015, MED IMAGE ANAL, V19, P98, DOI 10.1016/j.media.2014.09.005
   Bryt O, 2008, J VIS COMMUN IMAGE R, V19, P270, DOI 10.1016/j.jvcir.2008.03.001
   Bryt O, 2008, IEEE CONV EL ELECT I, P523
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen M, 2017, IEEE COMMUN MAG, V55, P54, DOI 10.1109/MCOM.2017.1600410CM
   Chen M, 2016, MOBILE NETW APPL, V21, P825, DOI 10.1007/s11036-016-0745-1
   Chupin M, 2015, P 10 INT C MED IM CO
   Coupé P, 2011, NEUROIMAGE, V54, P940, DOI 10.1016/j.neuroimage.2010.09.018
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Hammers A, 2003, HUM BRAIN MAPP, V19, P224, DOI 10.1002/hbm.10123
   Heckemann RA, 2006, NEUROIMAGE, V33, P115, DOI 10.1016/j.neuroimage.2006.05.061
   Hossain MS, 2016, IEEE ACCESS, V4, P7806, DOI 10.1109/ACCESS.2016.2626316
   Hossain MS, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0627-x
   Khan AR, 2011, NEUROIMAGE, V56, P126, DOI 10.1016/j.neuroimage.2011.01.078
   Khan AR, 2009, LECT NOTES COMPUT SC, V5762, P549, DOI 10.1007/978-3-642-04271-3_67
   Kwak K, 2013, MAGN RESON IMAGING, V31, P1190, DOI 10.1016/j.mri.2013.04.008
   Michopoulou SK, 2009, IEEE T BIO-MED ENG, V56, P2225, DOI 10.1109/TBME.2009.2019765
   Rao A, 2003, LECT NOTES COMPUT SC, V2674, P141
   Romero JE, 2015, MAGN RESON IMAGING, V33, P474, DOI 10.1016/j.mri.2015.02.005
   Rousseau F, 2011, IEEE T MED IMAGING, V30, P1852, DOI 10.1109/TMI.2011.2156806
   Sanroma G, 2014, LECT NOTES COMPUT SC, V8679, P207, DOI 10.1007/978-3-319-10581-9_26
   Shan L, 2014, MED IMAGE ANAL, V18, P1233, DOI 10.1016/j.media.2014.05.008
   Sjöberg C, 2013, COMPUT METH PROG BIO, V110, P308, DOI 10.1016/j.cmpb.2012.12.006
   Suh JW, 2013, I S BIOMED IMAGING, P1284
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tong T., 2012, MICCAI WORKSH SPARS
   Tong T, 2013, NEUROIMAGE, V76, P11, DOI 10.1016/j.neuroimage.2013.02.069
   Vemuri BC, 2003, MED IMAGE ANAL, V7, P1, DOI 10.1016/S1361-8415(02)00063-4
   Wang HZ, 2013, IEEE T PATTERN ANAL, V35, P611, DOI 10.1109/TPAMI.2012.143
   Wang HZ, 2011, NEUROIMAGE, V55, P968, DOI 10.1016/j.neuroimage.2011.01.006
   Wolz R, 2010, NEUROIMAGE, V49, P1316, DOI 10.1016/j.neuroimage.2009.09.069
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu GR, 2015, NEUROIMAGE, V106, P34, DOI 10.1016/j.neuroimage.2014.11.025
   Yan M, 2017, INT J IMAG SYST TECH, V27, P23, DOI 10.1002/ima.22207
NR 38
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9083
EP 9099
DI 10.1007/s11042-017-5484-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800065
DA 2024-07-18
ER

PT J
AU Chang, HY
AF Chang, Hong-Yi
TI A connectivity-increasing mechanism of ZigBee-based IoT devices for
   wireless multimedia sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless multimedia sensor networks (WMSNs); Orphan node problem; Zigbee
   networks; Recommendation scheme; Internet of things (IoT)
AB In recent years, applications of the Internet of Things (IoT) have become a part of our everyday life. Wireless multimedia sensor networks (WMSNs) are a new and emerging application of IoT that contain sensor nodes equipped with cameras, microphones, and other sensors producing multimedia content. ZigBee is the most common standard radio protocol used in WMSNs because of its lightweight standard and its low-cost and low-power characteristics. Most ZigBee network systems are constructed using the tree topology. Using the root node, intermediate nodes, and leaves of this topology, packets can be easily forwarded to the next hop by the tree routing mechanism, which calculates the packet destination address using the distributed address assignment mechanism. However, network parameter constraints cause the orphan node problem. Therefore, we proposed a novel recommendation scheme, the ZigBee connectivity enhancement mechanism (ZCEM), based on the improvement probability and improvement effect of multiparent nodes (MNs) in ZigBee networks. The ZCEM chooses MNs with better IP to connect to other parent nodes to increase the connectivity of ZigBee networks, reducing the number of orphan nodes. The ZCEM is compared to the standard ZigBee mechanism and the ZigBee connectivity-improving mechanism (ZCIM). The results show that the proposed ZCEM improves connectivity in ZigBee networks. The proposed mechanism can achieve a join ratio of 90%, approximately 3% more efficient than the ZCIM, and is 6% more efficient than the standard ZigBee mechanism.
C1 [Chang, Hong-Yi] Natl Chiayi Univ, Dept Management Informat Syst, 580 Sinmin Rd, Chiayi 60054, Taiwan.
C3 National Chiayi University
RP Chang, HY (corresponding author), Natl Chiayi Univ, Dept Management Informat Syst, 580 Sinmin Rd, Chiayi 60054, Taiwan.
EM hychang@mail.neyu.edu.tw
OI Chang, Hong-Yi/0000-0003-1249-1655
FU Ministry of Science and Technology (MOST) project of Taiwan [MOST
   105-2221-E-415-024-]
FX This work was supported by Ministry of Science and Technology (MOST)
   project of Taiwan [MOST 105-2221-E-415-024-].
CR Ahamed S. S. Riaz, 2009, Journal of Applied Information Technology, V5, P129
   Alliance Z, 2004, ZIGBEE SPEC ZIGBEE D
   Baker N, 2005, COMPUT CONTROL ENG, V16, P20, DOI 10.1049/cce:20050204
   Chang HY, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P674, DOI 10.1109/IIH-MSP.2014.174
   Chung SM, 2016, I C INF COMM TECH CO, P555, DOI 10.1109/ICTC.2016.7763532
   Ding G, 2005, 2005 SECOND ANNUAL IEEE COMMUNICATIONS SOCIETY CONFERENCE ON SENSOR AND AD HOC COMMUNICATIONS AND NETWORKS, P510
   Ding G, 2006, IEEE T MOBILE COMPUT, V5, P1561, DOI 10.1109/TMC.2006.172
   Hu SC, 2014, IEEE INT CONF COMM, P454, DOI 10.1109/ICCW.2014.6881240
   Lin TL, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/505121
   Nath SK, 2017, INT J ONLINE ENG, V13, P14, DOI 10.3991/ijoe.v13i01.5984
   Pan MS, 2009, IEEE T MOBILE COMPUT, V8, P1573, DOI 10.1109/TMC.2009.60
   Roy UK, 2017, ADV INTELL SYST, V458, P645, DOI 10.1007/978-981-10-2035-3_65
   Song TW, 2008, EUC 2008: PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING, VOL 2, WORKSHOPS, P495, DOI 10.1109/EUC.2008.71
   Sun G, 2016, J COMPUT COMMUN, V4, P48, DOI [10.4236/jcc.2016.47007, DOI 10.4236/JCC.2016.47007]
   Wu CM, 2013, J SUPERCOMPUT, V65, P136, DOI 10.1007/s11227-011-0696-z
   Xie HF, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL ASIA CONFERENCE ON INDUSTRIAL ENGINEERING AND MANAGEMENT INNOVATION: CORE THEORY AND APPLICATIONS OF INDUSTRIAL ENGINEERING, VOL 1, P891, DOI 10.2991/978-94-6239-148-2_88
NR 16
TC 9
Z9 9
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5137
EP 5154
DI 10.1007/s11042-017-4584-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100003
DA 2024-07-18
ER

PT J
AU Ke, JC
   Peng, YL
   Liu, SG
   Sun, ZG
   Wang, XL
AF Ke, Jingcheng
   Peng, Yali
   Liu, Shigang
   Sun, Zengguo
   Wang, Xili
TI A novel grouped sparse representation for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Grouped sparse representation classifications; Axis-symmetrical
   property; Framework; Virtual sample; Weighted fusion approach
ID ROBUST; ALGORITHMS; IMAGE
AB Grouped sparse representation classification methods (GSRCMs) have been attracted much attention by scholars, especially in face recognition. However, pervious literatures of GSRCMs only fuse the scores from different groups to classification the test sample, not consider relationships of the groups. Moreover, in real-world application, many methods of face recognition cannot obtain satisfied recognition accuracies because of the variation of poses, illuminations and facial representations of face image. In order to overcome above-mentioned bottlenecks, in this paper, we proposed a novel grouped fusion-based method in face recognition. The proposed method uses the axis-symmetrical property of face to designs a framework and perform it on original training set to generate a kind of virtual samples. The virtual samples are able to reflect the possible change of face images. Meanwhile, to consider the relationship of different groups and strengthen the representation capability of test sample, the proposed method exploits a novel weighted fusion approach to classify the test sample. Experimental results on five face databases demonstrate that our method is reasonable and can obtain higher recognition rate than the other 11 state-of-the-art methods.
C1 [Ke, Jingcheng; Peng, Yali; Liu, Shigang; Sun, Zengguo; Wang, Xili] Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Shaanxi, Peoples R China.
   [Ke, Jingcheng; Peng, Yali; Liu, Shigang; Sun, Zengguo; Wang, Xili] Engn Lab Teaching Informat Technol Shaanxi Prov, Xian 710119, Shaanxi, Peoples R China.
   [Ke, Jingcheng; Liu, Shigang; Sun, Zengguo; Wang, Xili] Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Shaanxi, Peoples R China.
C3 Shaanxi Normal University
RP Peng, YL (corresponding author), Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Shaanxi, Peoples R China.; Peng, YL (corresponding author), Engn Lab Teaching Informat Technol Shaanxi Prov, Xian 710119, Shaanxi, Peoples R China.
EM freedom6927@163.com; 43102898l@qq.com; shgliu@snnu.edu.cn;
   sunzg@snnu.edu.cn; wangxili@snnu.edu.cn
FU National Natural Science Foundation of China [61672333, 61402274,
   61461025]; China Postdoctoral Science Foundation Special project
   [2014T70937]; Program of Key Science and Technology Innovation Team in
   Shaanxi Province [2014KTC-18]; Key Science and Technology Program of
   Shaanxi Province, China [2016GY-081]; Fundamental Research Funds for the
   Central Universities [GK201603083]; Interdisciplinary Incubation Project
   of Learning Science of Shaanxi Normal University; Experimental
   Technology Research Project of Shaanxi Normal University [SYJS201314,
   SYJS201330]
FX This work is supported by the National Natural Science Foundation of
   China (No.61672333, 61402274, 61461025), China Postdoctoral Science
   Foundation Special project (No.2014T70937), the Program of Key Science
   and Technology Innovation Team in Shaanxi Province (No.2014KTC-18), the
   Key Science and Technology Program of Shaanxi Province, China (No.
   2016GY-081), the Fundamental Research Funds for the Central Universities
   (No.GK201603083), Interdisciplinary Incubation Project of Learning
   Science of Shaanxi Normal University, Experimental Technology Research
   Project of Shaanxi Normal University (No. SYJS201314, SYJS201330).
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Alharthi N., 2017, Scientific Modelling and Research, V2, P9, DOI 10.20448/808.2.1.9.18
   [Anonymous], 1994, P IEEE WORKSH APPL C
   [Anonymous], 2017, IEEE SIGNAL PROCESSI
   [Anonymous], 2014, INT C ADV ENG TECHN
   Asif MS, 2013, IEEE T SIGNAL PROCES, V61, P5905, DOI 10.1109/TSP.2013.2279362
   BAUM WM, 1974, J EXP ANAL BEHAV, V22, P231, DOI 10.1901/jeab.1974.22-231
   CHEN B, 1943, SOCIETY, V47, P1423, DOI DOI 10.1109/18.923725
   Chen B, 2017, CYBER PHYS SYSTEM EN
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   COVER TM, 1954, IEEE TRANS INF THEOR, V13, P21, DOI DOI 10.1109/TIT.1967.1053964
   Ding M, 2016, IEEE T IMAGE PROCESS, V25, P776, DOI 10.1109/TIP.2015.2507445
   Ding M, 2015, IEEE T CYBERNETICS, V45, P2413, DOI 10.1109/TCYB.2014.2373393
   Du B, 2017, IEEE T CYBERNETICS, V47, P14, DOI 10.1109/TCYB.2015.2496974
   EKMAN P, 1981, PSYCHOPHYSIOLOGY, V18, P101, DOI 10.1111/j.1469-8986.1981.tb02919.x
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Goel N, 2005, PROC SPIE, V5779, P426, DOI 10.1117/12.605553
   Gong C, 2017, IEEE T NEUR NET LEAR, V28, P1452, DOI 10.1109/TNNLS.2016.2514360
   Gutub A, 2016, HAJJ FOR 2016 16 SCI, P24
   Gutub A., 2015, ME SMART CIT 2015 4
   Gutub A., 2008, WoSPA 2008 - 5th IEEE International Workshop on Signal Processing and its Applications, P18
   Gutub A, 2015, 3 ANN DIGITAL GRIDS
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Ke J, 2017, J MOD OPTIC, V64, P2289, DOI 10.1080/09500340.2017.1357850
   Khan F, 2007, 4 IEEE GCC C EXH GUL, P2007
   Lai ZH, 2017, IEEE T CYBERNETICS, V47, P3733, DOI 10.1109/TCYB.2016.2578642
   Lai ZH, 2016, IEEE T NEUR NET LEAR, V27, P723, DOI 10.1109/TNNLS.2015.2422994
   Liu SG, 2016, J MOD OPTIC, V63, P1181, DOI 10.1080/09500340.2015.1133857
   Liu SG, 2016, SIGNAL PROCESS, V124, P141, DOI 10.1016/j.sigpro.2015.09.033
   LIU T, 2016, TPAMI, V38, P447, DOI DOI 10.1109/TPAMI.2015.2456899
   LIU W, 2004, ICPR, V4, P495, DOI DOI 10.1109/ICPR.2004.1333819
   Liu Z, DEEP LEARNING FACE A, P1
   Liu ZH, 2017, NEURAL PROCESS LETT, V45, P913, DOI 10.1007/s11063-016-9550-x
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Niyogi P, 1998, P IEEE, V86, P2196, DOI 10.1109/5.726787
   Norah A, 2017, J RES ENG APPL SCI J, V2, P50, DOI DOI 10.46565/JREAS.2017.V02I02.002
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Ryu YS, 2002, PATTERN RECOGN LETT, V23, P833, DOI 10.1016/S0167-8655(01)00159-3
   Sharma A, 2010, NEUROCOMPUTING, V73, P1868, DOI 10.1016/j.neucom.2009.10.027
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Song YJ, 2006, PATTERN RECOGN, V39, P1542, DOI 10.1016/j.patcog.2006.02.018
   Sun Y, DEEP LEARNING FACE R, P1
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Thian N. P. H., 2003, P IEEE INT C AC SPEE, P6
   Wen J, 2018, IEEE T CIRCUITS SYST
   Wen J, 2018, PATTERN RECOGN, V81, P326, DOI 10.1016/j.patcog.2018.04.004
   Wen J, 2018, NEURAL NETWORKS, V102, P36, DOI 10.1016/j.neunet.2018.02.002
   Wen XJ, 2016, OPTIK, V127, P883, DOI 10.1016/j.ijleo.2015.10.182
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2017, IEEE T NEUR NET LEAR, V28, P2233, DOI 10.1109/TNNLS.2016.2580572
   Xu Y, 2015, PATTERN RECOGN LETT, V68, P9, DOI 10.1016/j.patrec.2015.07.032
   Xu Y, 2014, NEUROCOMPUTING, V131, P191, DOI 10.1016/j.neucom.2013.10.025
   Xu Y, 2013, INT J INNOV COMPUT I, V9, P543
   Xu Y, 2013, PATTERN RECOGN LETT, V34, P980, DOI 10.1016/j.patrec.2013.01.028
   Xu Y, 2013, PATTERN RECOGN, V46, P1151, DOI 10.1016/j.patcog.2012.11.003
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292
   Yin J, 2012, NEUROCOMPUTING, V77, P120, DOI 10.1016/j.neucom.2011.08.018
   Yu HY, 2017, IEEE GEOSCI REMOTE S, V14, P1358, DOI 10.1109/LGRS.2017.2712200
   Zhang GY, 2017, DIGIT SIGNAL PROCESS, V62, P150, DOI 10.1016/j.dsp.2016.11.004
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang XX, 2017, J MOD OPTIC, V64, P799, DOI 10.1080/09500340.2016.1260781
   Zhang Z, 2018, IEEE T NEUR NET LEAR, V29, P3111, DOI 10.1109/TNNLS.2017.2712801
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
NR 67
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7667
EP 7689
DI 10.1007/s11042-018-6277-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700056
OA hybrid
DA 2024-07-18
ER

PT J
AU Kovac, J
   Struc, V
   Peer, P
AF Kovac, Jure
   Struc, Vitomir
   Peer, Peter
TI Frame-based classification for cross-speed gait recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric identification; Computer vision; Gait recognition; Walking
   speed invariance
ID WALKING SPEED
AB The use of human gait as the means of biometric identification has gained a lot of attention in the past few years, mostly due to its enormous potential. Such biometrics can be captured at public places from a distance without subjects collaboration, awareness and even consent. However, there are still numerous challenges caused by influence of covariate factors like changes of walking speed, view, clothing, footwear etc., that have negative impact on recognition performance. In this paper we tackle walking speed changes with a skeleton model-based gait recognition system focusing on improving algorithm robustness and improving the performance at higher walking speed changes. We achieve these by proposing frame based classification method, which overcomes the main shortcoming of distance based classification methods, which are very sensitive to gait cycle starting point detection. The proposed technique is starting point invariant with respect to gait cycle starts and as such ensures independence of classification from gait cycle start positions. Additionally, we propose wavelet transform based signal approximation, which enables the analysis of feature signals on different frequency space resolutions and diminishes the need for using feature transformation that require training. With the evaluation on OU-ISIR gait dataset we demonstrate state of the art performance of proposed methods.
C1 [Kovac, Jure; Peer, Peter] Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, Ljubljana 1000, Slovenia.
   [Struc, Vitomir] Univ Ljubljana, Fac Elect Engn, Trzaska Cesta 25, Ljubljana 1000, Slovenia.
C3 University of Ljubljana; University of Ljubljana
RP Peer, P (corresponding author), Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, Ljubljana 1000, Slovenia.
EM peter.peer@fri.uni-lj.si
RI Peer, Peter/A-2653-2008
OI Peer, Peter/0000-0001-9744-4035
FU European Union; European Social Fund; ARRS (Slovenian Research Agency)
   [P2-0214, P2-0250]
FX Research was partly financed by the European Union, European Social
   Fund. This research was supported in parts also by the ARRS (Slovenian
   Research Agency) Research Program P2-0214 (A) Computer Vision and the
   ARRS Research Program P2-0250 (B) Metrology and Biometric Systems.
CR [Anonymous], 2015, 2015 IEEE APPL IM PA
   Ariyanto Gunawan, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P354, DOI 10.1109/ICB.2012.6199832
   Aung MSH, 2013, IEEE T NEUR SYS REH, V21, P908, DOI 10.1109/TNSRE.2013.2239313
   Castro F, ARXIV160301006
   Iwashita Y, 2015, LECT NOTES COMPUT SC, V9279, P141, DOI 10.1007/978-3-319-23231-7_13
   JOHANSSON G, 1975, SCI AM, V232, P76, DOI 10.1038/scientificamerican0675-76
   Kobayashi T, 2009, PATTERN RECOGN LETT, V30, P212, DOI 10.1016/j.patrec.2008.09.006
   Kovac J, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/484320
   Kovac J, 2013, KSII T INTERNET INF, V7, P2690, DOI 10.3837/tiis.2013.11.008
   Kusakunniran Worapan, 2014, Image and Vision Computing, V32, P1117, DOI 10.1016/j.imavis.2014.10.004
   Kusakunniran W, 2012, IEEE T SYST MAN CY B, V42, P1654, DOI 10.1109/TSMCB.2012.2197823
   Kusakunniran W, 2011, IEEE IMAGE PROC, P545, DOI 10.1109/ICIP.2011.6116403
   Lee S., 2007, Celebrity Fandom and its Relationship to Tourism and Leisure Behaviors: The Case of Korean Wave, Texas AM Repository, P1
   Li W, NEUROCOMPUTING
   LIU Z, 2006, TPAMI, V28, P863, DOI DOI 10.1109/TPAMI.2006.122
   Liu ZY, 2004, INT C PATT RECOG, P211, DOI 10.1109/ICPR.2004.1333741
   LU H, 2008, SIGNAL PROCESS, V2008, P1
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Medikonda J, 2016, NEUROCOMPUTING, V207, P1, DOI 10.1016/j.neucom.2016.02.009
   Peternel M, 2004, INT C PATT RECOG, P146, DOI 10.1109/ICPR.2004.1333725
   Rahati S, 2008, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, P932, DOI 10.1109/ITNG.2008.124
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Tan DL, 2006, INT C PATT RECOG, P1000
   Tanawongsuwan R, 2004, PROC CVPR IEEE, P783
   Tsuji A, 2010, PROC CVPR IEEE, P717, DOI 10.1109/CVPR.2010.5540144
   Valcik J, 2016, COMPUT ANIMAT VIRT W, V27, P484, DOI 10.1002/cav.1674
   Veeraraghavan A, 2009, IEEE T IMAGE PROCESS, V18, P1326, DOI 10.1109/TIP.2009.2017143
   Xue ZJ, 2010, PATTERN RECOGN, V43, P2904, DOI 10.1016/j.patcog.2010.03.011
   Yoo JH, 2011, ETRI J, V33, P259, DOI 10.4218/etrij.11.1510.0068
   Yu T., 2012, MEDIAT INFLAMM, V2012, P1, DOI DOI 10.1155/2012/979105
   Zhang C, 2016, INT CONF ACOUST SPEE, P2832, DOI 10.1109/ICASSP.2016.7472194
NR 31
TC 19
Z9 20
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5621
EP 5643
DI 10.1007/s11042-017-5469-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100030
DA 2024-07-18
ER

PT J
AU Qin, GF
   Li, QT
AF Qin, Guofeng
   Li, Qiutao
TI Pavement image segmentation based on fast FCM clustering with spatial
   information in internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pavement image segmentation; Fast FCM; Spatial information; Noise
   immunity; IOT
ID FUZZY; ALGORITHM
AB Pavement image segmentation needs to deal with noise spots and has real time requirement. The original FCM method only considers the pixel's gray value and doesn't fully utilize the spatial information of the image. A new fast FCM algorithm is proposed, and it has noise immunity. By comparing with other FCM algorithms, it achieves better segmentation results through less iteration times and more rapid runtime. It is an effective and noise-resistant algorithm for pavement image segmentation from video multimedia in IOT (internet of things) platform.
C1 [Qin, Guofeng; Li, Qiutao] Tongji Univ, Dept Comp Sci & Technol, Shanghai 201804, Peoples R China.
C3 Tongji University
RP Qin, GF (corresponding author), Tongji Univ, Dept Comp Sci & Technol, Shanghai 201804, Peoples R China.
EM gfqing@aliyun.com; liqt91@qq.com
RI Qin, Guofeng/V-2929-2019
OI Qin, Guofeng/0000-0003-3217-8818
FU National 863 program in Ministry of Science and Technology of the
   People's Republic of China [2013AA040302]; Ministry of Science and
   Technology of the People's Republic of China
FX The National 863 program in Ministry of Science and Technology of the
   People's Republic of China (No.: 2013AA040302). Authors are grateful to
   the Ministry of Science and Technology of the People's Republic of China
   for financial support to carry out this work.
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   [Anonymous], 2004, MEAS SCI REV
   Benaichouche AN, 2013, DIGIT SIGNAL PROCESS, V23, P1390, DOI 10.1016/j.dsp.2013.07.005
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   Izakian H, 2013, IEEE T FUZZY SYST, V21, P855, DOI 10.1109/TFUZZ.2012.2233479
   Li Y, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND NATURAL COMPUTING, VOL I, P462, DOI 10.1109/CINC.2009.100
   Ming L, 2010, 2010 3 INT C ADV COM, P5
   Tolias YA, 1998, IEEE T SYST MAN CY A, V28, P359, DOI 10.1109/3468.668967
   Wang X. S., 2012, TELKOMNIKA INDONESIA, V10, P1610
NR 11
TC 3
Z9 5
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5181
EP 5191
DI 10.1007/s11042-017-4683-0
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100006
DA 2024-07-18
ER

PT J
AU Chen, JW
   Yao, T
   Chao, HY
AF Chen, Jingwen
   Yao, Ting
   Chao, Hongyang
TI See and chat: automatically generating viewer-level comments on images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image commenting; Cross-view embedding; Deep convolutional neural
   networks
AB Image is becoming a predominant medium for social interactions. Automatically expressing opinions on an image, which we refer to as image commenting, has great potential to improve user engagement and thus becomes an emerging yet very challenging research topic. The machine-generated comments should be both relevant to image content and natural as human language. To deal with these challenges, we propose a novel two-stage approach, consisting of similar image search and comment ranking. In the first step, given an image, visually similar images are discovered by k-nearest neighbor (k-NN) search from a large image dataset. The comments associated with these images are exploited as candidates to mimic how viewers respond to this given image. In the second step, ranking canonical correlation analysis (RCCA), which is an extension of CCA by jointly learning a cross-view embedding space and a bilinear similarity function between the views of image and comment, is exploited for ranking the candidate comments. To create a benchmark for this emerging task, we collect a dataset with 426K images with 11 million associated comments. We show that our approach achieves superior performance and can suggest viewer-level comments.
C1 [Chen, Jingwen; Chao, Hongyang] Sun Yat Sen Univ, Guangzhou 510006, Guangdong, Peoples R China.
   [Yao, Ting] Microsoft Res Asia, Beijing 100080, Peoples R China.
C3 Sun Yat Sen University; Microsoft Research Asia; Microsoft
RP Yao, T (corresponding author), Microsoft Res Asia, Beijing 100080, Peoples R China.
EM chenjw87@mail2.sysu.edu.cn; tiyao@microsoft.com;
   isschhy@mail.sysu.edu.cn
RI chen, jw/IQW-1558-2023
OI Yao, Ting/0000-0001-7587-101X
FU NSF of China [61672548, U1611461, 61173081]; Guangzhou Science and
   Technology Program, China [201510010165]
FX This work is partially supported by NSF of China under Grant 61672548,
   U1611461, 61173081, and the Guangzhou Science and Technology Program,
   China, under Grant 201510010165.
CR [Anonymous], IJCAI
   [Anonymous], 2017, ICCV
   [Anonymous], 2015, CVPR
   [Anonymous], 2017, CVPR
   [Anonymous], 2006, P LREC
   [Anonymous], CVPR
   [Anonymous], SIGIR
   [Anonymous], 2009, WWW
   [Anonymous], 2009, ICCV
   [Anonymous], 2015, ICML
   [Anonymous], 2015, ARXIV150504467
   [Anonymous], 2014, P 2014 C EMP METH NA
   [Anonymous], 2010, ECCV
   [Anonymous], 2011, CVPR
   [Anonymous], 2015, CVPR
   [Anonymous], 2014, P 31 INT C MACH LEAR
   [Anonymous], 2012, P ADV NEUR INF PROC
   Chen YY, 2014, PREDICTING VIEWER AF
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He K., 2016, P IEEE C COMP VIS PA
   Li Ying, 2016, MM
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Simonyan K., 2015, P ICLR
   Wu L, 2009, MM
   Yao Ting., 2015, ICCV
NR 26
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 2689
EP 2702
DI 10.1007/s11042-018-5746-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600004
DA 2024-07-18
ER

PT J
AU Singh, SK
   Kumar, S
   Dwivedi, JP
AF Singh, Sandip Kumar
   Kumar, Sandeep
   Dwivedi, J. P.
TI A novel soft computing method for engine RUL prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia Signals; Soft Computing; Remaining Useful (RUL); Root Mean
   Square Error (RMSE); Gradient Boosted Trees (GBT); Ensemble; Convolution
   Neural Network (CNN); Artificial Neural Networks (ANN); Support Vector
   Regression (SVR)
AB Prognostics is an engineering discipline focused on predicting the Remaining Useful Life (RUL) of a system or a component using raw multimedia (sensor) data. This paper presents a novel machine learning model for this task, which includes a smart ensemble of gradient boosted trees (GBT) and feed-forward neural networks. It incorporates discussions on the poor performance of MLPs and the need of ensemble models. Initial stages of data exploration and pre-processing are also comprehensively documented. Experiments are performed on the four run-to-failure C-MAPSS datasets defined by the 2008 PHM Data Challenge Competition. It concludes by presenting evaluations of multiple prediction models like MLP, SVR, CNN & gradient boosted trees (GBT). Gradient Boosted Trees are efficient in the sense that they produce an encouraging scoring model with minimum effort and also return feature importance information. The proposed method uses stacking ensemble of feed-forward neural networks and gradient boosted trees, as first level learner, and, a single-hidden layer- fully-connected neural network as the meta learner. This ensemble provides better results than any of the models alone or weighted average of their predictions. The proposed method outperforms MLP, SVR, CNN and GBT.
C1 [Singh, Sandip Kumar; Kumar, Sandeep; Dwivedi, J. P.] Indian Inst Technol BHU, Dept Mech Engn, Varanasi, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Singh, SK (corresponding author), Indian Inst Technol BHU, Dept Mech Engn, Varanasi, Uttar Pradesh, India.
EM sandipks.rs.mec15@itbhu.ac.in; sandeep.mec@iitbhu.ac; jpd@bhu.ac
RI Singh, Sandip Kumar/U-9209-2019; Kumar, Sandeep/IUQ-2320-2023; Kumar,
   Sandeep/IWU-7273-2023; Kumar, Santosh/JVO-5600-2024
OI Kumar, Sandeep/0000-0002-0848-632X; Kumar, Sandeep/0000-0002-7008-4735; 
CR [Anonymous], IEEE T CYBERNETICS
   [Anonymous], 1999, Greedy Function Approximation: A Gradient Boosting Machine
   [Anonymous], 1985, ICS8506 CAL U SAN DI
   [Anonymous], 2015, International Journal of prognostics and health management
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   der Laan V, 2007, STAT APPL GENET MOL, V6, P1
   Deutsch J, 2016, USING DEEP LEARNING
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Guo L, 2017, NEUROCOMPUTING, V240, P98, DOI 10.1016/j.neucom.2017.02.045
   Heimes FO, 2008, PROGN HLTH MAN 2008
   Khelif R, 2017, IEEE T IND ELECTRON, V64, P2276, DOI 10.1109/TIE.2016.2623260
   Kolen JF, 2009, A Field Guide to Dynamical Recurrent Networks, DOI [DOI 10.1109/9780470544037.CH14, 10.1109/9780470544037]
   Liao LX, 2014, IEEE T IND ELECTRON, V61, P2464, DOI 10.1109/TIE.2013.2270212
   Lim P, 2016, NEUR NETW IJCNN 2016
   Medjaher K, 2013, CONTR C ECC 2013 EUR
   Miao Q, 2013, MICROELECTRON RELIAB, V53, P805, DOI 10.1016/j.microrel.2012.12.004
   Mosallam A, 2016, J INTELL MANUF, V27, P1037, DOI 10.1007/s10845-014-0933-4
   Peel L, 2008, PROGN HLTH MAN PHM 2
   Ramasso E., 2014, International Journal of Prognostics and Health Management, V5, P1, DOI DOI 10.36001/IJPHM.2014.V5I2.2236
   Sateesh Babu Giduthuri, 2016, Database Systems for Advanced Applications. 21st International Conference, DASFAA 2016. Proceedings: LNCS 9642, P214, DOI 10.1007/978-3-319-32025-0_14
   Saxena A., 2008, PHM08 Challenge data set
   Wang T, 2008, PROGN HLTH MAN 2008
   Xinxin X, 2016, GUID NAV CONTR C CGN
   Yang Z, 2016, PROGN SYST HLTH MAN
NR 25
TC 33
Z9 34
U1 1
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4065
EP 4087
DI 10.1007/s11042-017-5204-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200011
DA 2024-07-18
ER

PT J
AU Kapsouras, I
   Nikolaidis, N
AF Kapsouras, Ioannis
   Nikolaidis, Nikos
TI Action recognition by fusing depth video and skeletal data information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinect; Bag of Words; Vector of Locally Aggregated Descriptors; Action
   recognition; Fusion; Depth video; Motion capture data; MSR Action3D
ID FEATURES; JOINTS
AB Two action recognition approaches that utilize depth videos and skeletal information are proposed in this paper. Dense trajectories are used to represent the depth video data. Skeletal data are represented by vectors of skeleton joints positions and their forward differences in various temporal scales. The extracted features are encoded using either Bag of Words (BoW) or Vector of Locally Aggregated Descriptors (VLAD) approaches. Finally, a Support Vector Machine (SVM) is used for classification. Experiments were performed on three datasets, namely MSR Action3D, MSR Action Pairs and Florence3D in order to measure the performance of the methods. The proposed approaches outperform all state of the art action recognition methods that operate on depth video/skeletal data in the most challenging and fair experimental setup of the MSR Action3D dataset. Moreover, they achieve 100% correct recognition in the MSR Action Pairs dataset and the highest classification rate among all compared methods on the Florence3D dataset.
C1 [Kapsouras, Ioannis; Nikolaidis, Nikos] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
C3 Aristotle University of Thessaloniki
RP Kapsouras, I (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
EM jkapsouras@aiia.csd.auth.gr
RI Nikolaidis, Nikos/F-1819-2010
OI Nikolaidis, Nikos/0000-0003-1515-7986
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Anirudh R, 2015, PROC CVPR IEEE, P3147, DOI 10.1109/CVPR.2015.7298934
   [Anonymous], 2011, HUMAN GESTURE BEHAV
   [Anonymous], 2011, COMPUTER ANIMATION A
   [Anonymous], 2013, P IEEE INT C COMP VI
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], P IEEE C COMP VIS PA
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Chen H, 2016, PATTERN RECOGNIT
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Deng LQ, 2012, COMPUT GRAPH FORUM, V31, P202, DOI 10.1111/j.1467-8659.2011.02095.x
   Eweiwi A, 2014, P AS C COMP VIS ACCV
   Gowayyed M.A., 2013, Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence, IJCAI '13, P1351
   Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011
   Han L, 2010, IMAGE VISION COMPUT, V28, P836, DOI 10.1016/j.imavis.2009.08.003
   Holte M.B., 2011, Proceedings of the 2011 joint ACM workshop on Human gesture and behavior understanding, J-HGBU '11, P47, DOI [10.1145/2072572.2072588, DOI 10.1145/2072572.2072588]
   Hussein, 2013, INT JOINT C ART INT
   Iosifidis A, 2012, COMPUT VIS IMAGE UND, V116, P347, DOI 10.1016/j.cviu.2011.08.008
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jia XF, 2012, INT C PATT RECOG, P3001
   Kapsouras I, 2014, J VIS COMMUN IMAGE R, V25, P1432, DOI 10.1016/j.jvcir.2014.04.007
   Li W, 2010, IEEE COMP SOC C COMP, P9, DOI DOI 10.1109/CVPRW.2010.5543273
   Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227
   Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48
   Rahmani H, 2014, IEEE WINT CONF APPL, P626, DOI 10.1109/WACV.2014.6836044
   Seidenari L, 2013, IEEE COMPUT SOC CONF, P479, DOI 10.1109/CVPRW.2013.77
   Shahroudy A, 2016, IEEE T PATTERN ANAL, V38, P2123, DOI 10.1109/TPAMI.2015.2505295
   Shariat S, 2011, P INT C COMP VIS
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Turaga P, 2009, PROC CVPR IEEE, P2427
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vieira AW, 2014, PATTERN RECOGN LETT, V36, P221, DOI 10.1016/j.patrec.2013.07.011
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Wang J, 2013, IEEE I CONF COMP VIS, P2688, DOI 10.1109/ICCV.2013.334
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang PC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1119, DOI 10.1145/2733373.2806296
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78
NR 47
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1971
EP 1998
DI 10.1007/s11042-018-6209-9
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700032
DA 2024-07-18
ER

PT J
AU Lin, CY
   Jheng, KR
   Shih, TK
AF Lin, Chih-Yang
   Jheng, Kai-Ren
   Shih, Timothy K.
TI Objective HDR image quality assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High dynamic range; Subjective preferences; HDR image quality assessment
AB Although there is a lot of literature about generating HDR images, very limited research has been conducted on the issue of HDR image quality based on people's feeling and preferences. The goal of this paper is to identify an objective quality measurement of an HDR image. The key features of HDR images that affect people's preferences are uncovered through a survey in which testers judge different sample images of different scenes. The experimental results show that the proposed quality measurement for HDR images generates scores consistent with the true feelings of observers.
C1 [Lin, Chih-Yang] Yuan Ze Univ, Dept Commun Engn, Taoyuan, Taiwan.
   [Jheng, Kai-Ren; Shih, Timothy K.] Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.
C3 Yuan Ze University; National Central University
RP Shih, TK (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.
EM timothykshih@gmail.com
RI Lin, Chih-Yang/HOF-2583-2023
OI Lin, Chih-Yang/0000-0002-0401-8473
CR [Anonymous], 2016, 8 INT WORKSHOP QUALI
   [Anonymous], 2018, PHOTOMATIX
   [Anonymous], 2017, Quality and User Experience, DOI DOI 10.1007/S41233-017-0007-4
   Debevec PE, 2008, P 24 ANN C COMP GRAP, P369
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Ghimire D, 2011, IEEE T CONSUM ELECTR, V57, P858, DOI 10.1109/TCE.2011.5955233
   Hanhart P, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0091-4
   Hu J, 2013, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2013.154
   Jia S, 2017, IEEE IMAGE PROC, P765, DOI 10.1109/ICIP.2017.8296384
   Krasula L., 2015, 2015 7 INT WORKSHOP, P1
   Kundu D, 2017, IEEE T IMAGE PROCESS, V26, P2957, DOI 10.1109/TIP.2017.2685941
   Kundu D, 2016, CONF REC ASILOMAR C, P1847, DOI 10.1109/ACSSC.2016.7869704
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   Narwaria M, 2015, SIGNAL PROCESS-IMAGE, V35, P46, DOI 10.1016/j.image.2015.04.009
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Sarmah MJ, 2017, IEEE I C COMP INT CO, P1
   Singh G, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P265, DOI 10.1109/SPIN.2016.7566701
   Zhang Y. P., 2013, TSINGHUA U ED RES, V4, P22, DOI DOI 10.1117/1.JEI.22.4.043025
NR 19
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1547
EP 1567
DI 10.1007/s11042-018-6139-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700015
DA 2024-07-18
ER

PT J
AU Lin, XY
   Zhu, C
   Liu, YP
   Zhang, Q
AF Lin, Xinyu
   Zhu, Ce
   Liu, Yipeng
   Zhang, Qian
TI Robust corner detection using altitude to chord ratio accumulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Altitude-to-chord ratio accumulation; Contour-based corner detection;
   Low-level feature detection
ID SCALE-SPACE
AB As one of the most significant image local features, corner is widely utilized in many computer vision applications. A number of contour-based corner detection algorithms have been proposed over the last decades, among which the chord-to-point distance accumulation (CPDA) corner detector is reported to produce robust performance in corner detection, especially compared with curvature scale-space (CSS) based corner detectors, which are sensitive to local variation and noise on the contour. In this paper, we investigate the CPDA algorithm in terms of its limitations, and then propose the altitude-to-chord ratio accumulation (ACRA) corner detector based on CPDA approach. Altitude-to-chord ratio is insensitive to the selection of chord length compared with chord-to-point distance, which allows us utilize a single chord instead of the three chords used in CPDA algorithm. Besides, we replace the maximum normalization used in CPDA algorithm with the linear normalization to avoid the uneven data projection. Numerical experiments demonstrate that the proposed ACRA corner detection algorithm outperforms the CPDA approach and other seven state-of-the-art methods in terms of the repeatability and localization error evaluation metrics.
C1 [Lin, Xinyu; Zhu, Ce; Liu, Yipeng; Zhang, Qian] Univ Elect Sci & Technol China, Ctr Robot, Sch Elect Engn, Chengdu 611731, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Zhu, C (corresponding author), Univ Elect Sci & Technol China, Ctr Robot, Sch Elect Engn, Chengdu 611731, Sichuan, Peoples R China.
EM eczhu@uestc.edu.cn
RI Zhu, Ce/AEN-1875-2022; Liu, Yipeng/M-5434-2016; Lin, Xinyu/HIZ-6071-2022
OI Liu, Yipeng/0000-0003-2084-8781; 
FU National Natural Science Foundation of China [61602091, 61571102];
   Fundamental Research Funds for the Central Universities [ZYGX2016J199,
   ZYGX2014Z003]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61602091 and Grant 61571102, in part by
   the Fundamental Research Funds for the Central Universities under Grant
   ZYGX2016J199 and Grant ZYGX2014Z003.
CR [Anonymous], ALV VIS C MANCH BRIT
   Awrangjeb M., 2007, IEEE INT C AC SPEECH
   Awrangjeb M, 2010, INT C DIG IM COMP TE
   Awrangjeb M, 2013, INT C DIG IM COMP TE
   Awrangjeb M, 2009, INT C DIG IM COMP TE
   Awrangjeb M, 2008, IEEE T MULTIMEDIA, V10, P1059, DOI 10.1109/TMM.2008.2001384
   Awrangjeb M, 2012, IEEE T IMAGE PROCESS, V21, P4167, DOI 10.1109/TIP.2012.2200493
   Gao XT, 2007, IMAGE VISION COMPUT, V25, P890, DOI 10.1016/j.imavis.2006.07.002
   He XC, 2008, OPT ENG, V47, DOI 10.1117/1.2931681
   Jian MW, 2011, IMAGING SCI J, V59, P219, DOI 10.1179/136821910X12867873897355
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Lin X., 2017, IEEE T INSTRUM MEAS, P1
   Lin XY, 2017, ELECTRON LETT, V53, P1354, DOI 10.1049/el.2017.1353
   Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812
   Mokhtarian F, 2001, P SCAND C IM AN BERG
   Moravec H.P., 1980, THESIS
   Paula IC, 2013, J MATH IMAGING VIS, V45, P251, DOI 10.1007/s10851-012-0365-8
   Pedrosa GV, 2010, PATTERN RECOGN LETT, V31, P1658, DOI 10.1016/j.patrec.2010.05.013
   RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   Shi J., 1994, IEEE INT C COMP VIS
   Shui PL, 2013, IEEE T IMAGE PROCESS, V22, P3204, DOI 10.1109/TIP.2013.2259834
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Teng SW, 2015, PATTERN RECOGN, V48, P2185, DOI 10.1016/j.patcog.2015.01.016
   Topal C, 2013, IEEE INT C AC SPEECH
   Tsai DM, 1999, PATTERN RECOGN LETT, V20, P31, DOI 10.1016/S0167-8655(98)00130-5
   Zhang SZ, 2015, ELECTRON LETT, V51, P1988, DOI 10.1049/el.2015.2491
   Zhang XH, 2007, PATTERN RECOGN LETT, V28, P545, DOI 10.1016/j.patrec.2006.10.006
   Zhang XH, 2015, IEEE T PATTERN ANAL, V37, P2207, DOI 10.1109/TPAMI.2015.2396074
   Zhang XH, 2010, PATTERN RECOGN, V43, P1207, DOI 10.1016/j.patcog.2009.10.017
   Zhang XH, 2009, PATTERN RECOGN LETT, V30, P449, DOI 10.1016/j.patrec.2008.11.002
   Zhong BJ, 2007, IEEE T PATTERN ANAL, V29, P508, DOI 10.1109/TPAMI.2007.50
NR 32
TC 8
Z9 10
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 177
EP 195
DI 10.1007/s11042-017-5606-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500010
DA 2024-07-18
ER

PT J
AU Pathak, Y
   Arya, KV
   Tiwari, S
AF Pathak, Yadunath
   Arya, K. V.
   Tiwari, Shailendra
TI Feature selection for image steganalysis using levy flight-based grey
   wolf optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganalysis; Feature selection; Grey wolf optimization; Swarm
   intelligence
ID LSB STEGANOGRAPHY; DIFFERENTIAL EVOLUTION; CLASSIFICATION
AB Image steganalysis is the process of detecting the availability of hidden messages in the cover images. Therefore, it may be considered as a classification problem which categorizes an image either into a cover images or a stego image. Feature selection is one of the important phases of image steganalysis which can increase its computational efficiency and performance. In this paper, a novel levy flight-based grey wolf optimization has been introduced which is used to select the prominent features for steganalysis algorithm from a set of original features. For the same, SPAM and AlexNet have been used to generate the high dimensional features. Furthermore, the random forest classifier is used to classify the images over selected features into cover images and stego images. The experimental results show that the proposed levy flight-based grey wolf optimization shows preferable convergence precision and effectively reduces the irrelevant and redundant features while maintaining the high classification accuracy as compared to other feature selection methods.
C1 [Pathak, Yadunath; Arya, K. V.] Atal Bihari Vajpayee Indian Inst Informat Technol, Multimedia & Informat Secur Lab, Gwalior, India.
   [Tiwari, Shailendra] Thapar Inst Engn & Technol, CSE Dept, Patiala, Punjab, India.
C3 ABV-Indian Institute of Information Technology & Management, Gwalior;
   Thapar Institute of Engineering & Technology
RP Pathak, Y (corresponding author), Atal Bihari Vajpayee Indian Inst Informat Technol, Multimedia & Informat Secur Lab, Gwalior, India.
EM yadunath@iiitm.ac.in; kvarya@iiitm.ac.in; shailendra@thapar.edu
RI PATHAK, YADUNATH/AFR-0689-2022; Tiwari, Shailendra/ABF-3873-2021
OI PATHAK, YADUNATH/0000-0002-4062-7858; Tiwari,
   Shailendra/0000-0001-7209-0437; Arya, Karm Veer/0000-0001-7117-1745
CR Amirsadri S., 2017, NEURAL COMPUT APPL, V30, P1
   [Anonymous], 2012, International Joint Conference on Neural Networks, DOI DOI 10.1109/IJCNN.2012.6252640
   Bhattacharyya S, 2014, MED BIOL ENG COMPUT, V52, P131, DOI 10.1007/s11517-013-1123-9
   Chechkin A. V., 2008, Introduction to the Theory of Levy Flights, P129, DOI [DOI 10.1002/9783527622979.CH5, 10.1002/9783527622979.ch5]
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   Chhikara RR, 2016, INT J MACH LEARN CYB, V7, P1195, DOI 10.1007/s13042-015-0448-0
   Chhikara RR, 2016, INT J MACH LEARN CYB, V6, P1
   Cotter SF, 2001, SIGNAL PROCESS, V81, P1849, DOI 10.1016/S0165-1684(01)00064-0
   Dash M., 1997, Intelligent Data Analysis, V1
   Deepa S, 2017, Int.J. Adv. Res. Comput. Sci., V8, P1503
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Emary E, 2016, NEUROCOMPUTING, V172, P371, DOI 10.1016/j.neucom.2015.06.083
   Emary E, 2015, ADV INTELL SYST, V334, P1, DOI 10.1007/978-3-319-13572-4_1
   Fridrich J, 2004, PROC SPIE, V5306, P23, DOI 10.1117/12.521350
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Guettari N, 2016, IEEE IMAGE PROC, P2742, DOI 10.1109/ICIP.2016.7532858
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Jamil Momin, 2013, International Journal of Mathematical Modelling and Numerical Optimisation, V4, P150
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kodovsky J, 2011, PROC SPIE, V7880, DOI 10.1117/12.872279
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu QZ, 2011, MM&SEC 11: PROCEEDINGS OF THE 2011 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P77
   Lu PZ, 2004, LECT NOTES COMPUT SC, V3200, P116
   Luo XY, 2008, SIGNAL PROCESS, V88, P2138, DOI 10.1016/j.sigpro.2008.03.016
   Massart DL, 2005, LC GC EUR, V18, P215
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mohammadi FG, 2014, ENG APPL ARTIF INTEL, V31, P35, DOI 10.1016/j.engappai.2013.09.016
   Muangkote Nipotepat, 2014, 2014 International Computer Science and Engineering Conference (ICSEC), P209, DOI 10.1109/ICSEC.2014.6978196
   Nissar A, 2010, DIGIT SIGNAL PROCESS, V20, P1758, DOI 10.1016/j.dsp.2010.02.003
   Pevny T, 2005, LECT NOTES COMPUT SC, V3710, P39
   Pevny T., 2007, P SOC PHOTO-OPT INS
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Ramezani M, 2010, CONSUM COMM NETWORK, P239
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Saraswat M, 2014, MED BIOL ENG COMPUT, V52, P1041, DOI 10.1007/s11517-014-1200-8
   Saraswat M, 2013, SWARM EVOL COMPUT, V11, P46, DOI 10.1016/j.swevo.2013.02.003
   Sheikhan M, 2012, NEURAL COMPUT APPL, V21, P1717, DOI 10.1007/s00521-011-0729-9
   Simon D., 2013, EVOLUTIONARY OPTIMIZ
   Yang XS, 2014, NATURE-INSPIRED OPTIMIZATION ALGORITHMS, P1
   Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82, DOI 10.1109/4235.771163
   Zhang T, 2003, SIGNAL PROCESS, V83, P2085, DOI 10.1016/S0165-1684(03)00169-5
NR 46
TC 54
Z9 57
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1473
EP 1494
DI 10.1007/s11042-018-6155-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700012
DA 2024-07-18
ER

PT J
AU Sui, T
   Liu, XZ
   Lu, DY
   Shao, CM
   Cheng, F
AF Sui, Tao
   Liu, Xiuzhi
   Lu, Dongya
   Shao, Changming
   Cheng, Fei
TI RETRACTED: Research on the construction of teaching case library of the
   computer simulation technology (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Professional master's degree; Teaching case library; Practice; Computer
   simulation technology
AB Using the case derived from the life or production in teaching is a very practical teaching method for training the students' comprehensive ability of the professional course, by which the students can get a lot of targeted expertise, instead of the empty preaching. With the progress of Chinese over the past years, the professional knowledge the students learned is more and more abstruse, more and more refined, how effective organization of teaching cases, the distinguished in student learning, in order to achieve the purpose of their major, this is an important task the college teachers focus on. In conjunction with the teaching task of the computer simulation technology for professional type of postgraduate student, this paper puts forward and establish three levels of the teaching case library, which include the fundament- type, the profession-type, the extended-type and so on. Using of the cases, in the course of study, the postgraduate student can not only master the main content of the course, but also be exerted their autonomy and professional development interest.
C1 [Sui, Tao; Liu, Xiuzhi; Lu, Dongya; Shao, Changming; Cheng, Fei] Shandong Univ Sci & Technol, Coll Elect Engn & Automat, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology
RP Liu, XZ (corresponding author), Shandong Univ Sci & Technol, Coll Elect Engn & Automat, Qingdao 266590, Peoples R China.
EM suitao@sdust.edu.cn; ztsui@sohu.com; 2680405138@qq.com;
   158541851@qq.com; 842398107@qq.com
RI sui, tao/V-8195-2019
CR Chew IM, 2018, COMPUT SCI TECHNOL
   Hu L, 2011, ACAD DEG POSTGRAD ED, P58
   Hua X, 2017, RES HIGH ED ENG, P100
   Kong W, 2016, RES 3D RECONSTRUCTIO
   Kong W, 2016, ELECTR WORLD, P170
   Li L, 2013, CHIN ELECT POWER ED, P79
   Li X, 2017, HYDROGEOL J, V25, P1733, DOI 10.1007/s10040-017-1574-4
   Lu XZ, 2004, AUTOMAT CONSTR, V13, P597, DOI [10.1016/j.autcon.2004.04.022, 10.1016/j.autcon.2004.04.002]
   Shu L, 2014, NAT GRAD SCH ENG GRA
   Sui T, 2013, TELKOMNIKA INDONESIA, V11
   Sun J, 2016, ED EXPLOR, P76
   Tao S, 2015, COMPUTER SIMULATION
   Wang H, 2015, COLL MATH, V31, P106
   Wei L, 2016, J HEZ U, V38, P112
   Wu X, 1998, COMPUTER SIMULATION
   Zhang J, 2018, CHIN COMPUT COMMUN
   Zhang JW, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-7, CONFERENCE PROCEEDINGS, P487
   Zubair M, 2011, ANN NUCL ENERGY, V38, P2575, DOI 10.1016/j.anucene.2011.07.020
   Zuo J, 2017, COLL ED SCI, P30
NR 19
TC 5
Z9 5
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 1183
EP 1199
DI 10.1007/s11042-018-6646-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500068
DA 2024-07-18
ER

PT J
AU Wang, FP
   Wang, WX
AF Wang Fengping
   Wang Weixing
TI Road extraction using modified dark channel prior and neighborhood FCM
   in foggy aerial images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Road extraction; Foggy aerial image; Dark channel prior; Neighborhood
   fuzzy C-means
AB It is still a challenge to accomplish road extraction from the aerial images in foggy weather. In this paper, a road extraction method based on modified dark channel prior and improved neighborhood FCM (Fuzzy C-means) is proposed for foggy aerial images. Firstly, a defogging method based on modified dark channel prior is applied to increase the image contrast and highlight the road areas. In the proposed method, a region filtering function is designed to generate the dark channel image, and an adaptive parameter is set up to adjust the defogging degree automatically. Secondly, an improved neighborhood FCM algorithm is studied to extract the road area. According to the neighborhood feature, the spatial distance and the gray level difference can be calculated as the parameters of the objective function which can eliminate noise and promote the detection accuracy. Finally, an image post-processing procedure is utilized to connect the road gaps and remove the false road areas. The experimental results verify that the proposed method can achieve satisfied road extraction effect both on completeness and correctness.
C1 [Wang Fengping; Wang Weixing] Changan Univ, Sch Informat Engn, Xian, Shaanxi, Peoples R China.
C3 Chang'an University
RP Wang, WX (corresponding author), Changan Univ, Sch Informat Engn, Xian, Shaanxi, Peoples R China.
EM 3469520500@qq.com
FU Doctoral Dissertation Foster Fund of Chang'an University [310824165003];
   International Cooperation Project in China [2013KW03]
FX The authors would like to thank the anonymous reviewers for their
   valuable remarks and suggestions. This work was supported by the
   Doctoral Dissertation Foster Fund of Chang'an University (Grant No.
   310824165003), and the International Cooperation Project in China (Grant
   No. 2013KW03).
CR Barzohar M, 1996, IEEE T PATTERN ANAL, V18, P707, DOI 10.1109/34.506793
   Bezdek James C., 1981, PATTERN RECOGN
   Burt P. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P173, DOI 10.1109/ICCV.1993.378222
   Das S, 2011, IEEE T GEOSCI REMOTE, V49, P3906, DOI 10.1109/TGRS.2011.2136381
   [丁磊 Ding Lei], 2015, [中国图象图形学报, Journal of Image and Graphics], V20, P1526
   Ding Y, 2017, MULTIMED TOOLS APPL, V76, P22979, DOI 10.1007/s11042-016-4184-6
   Duan ZG, 2016, ACTA OPT SINICA, V36, P206
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   [符喜优 Fu Xiyou], 2015, [中国图象图形学报, Journal of Image and Graphics], V20, P1403
   Gibson KB, 2012, IEEE T IMAGE PROCESS, V21, P662, DOI 10.1109/TIP.2011.2166968
   Guo Fan, 2010, Journal of Computer Applications, V30, P2417, DOI 10.3724/SP.J.1087.2010.02417
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   He YH, 2004, IEEE T INTELL TRANSP, V5, P309, DOI 10.1109/TITS.2004.838221
   [李滚 Li Gun], 2014, [激光杂志, Laser Journal], V35, P1
   LUO W, 2012, RES J APPL SCI ENG T, V4, P2590
   Ma RG, 2012, J APPL REMOTE SENS, V6, DOI 10.1117/1.JRS.6.063610
   Marikhu R, 2007, LECT NOTES COMPUT SC, V4843, P85
   McCartney EJ., 1975, Optics of Atmosphere: Scattering by Molecules and Particles
   Miao ZL, 2014, IEEE GEOSCI REMOTE S, V11, P1856, DOI 10.1109/LGRS.2014.2312000
   Mukundan R., 1998, Moment Functions in Image Analysis: Theory and Applications
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Rizvandi NB, 2008, P DICTA, P65, DOI DOI 10.1109/DICTA.2008.87
   Shang ZM, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P77, DOI 10.1109/FSKD.2014.6980810
   Song MJ, 2004, PHOTOGRAMM ENG REM S, V70, P1365, DOI 10.14358/PERS.70.12.1365
   Trinder J.C., 1998, Int. Arch. Photogramm. Remote Sens, V32, P635
   Wang WX, 2016, J TRAFFIC TRANSP ENG, V3, P271, DOI 10.1016/j.jtte.2016.05.005
   Wang WX, 2016, B ENG GEOL ENVIRON, V75, P311, DOI 10.1007/s10064-015-0747-4
   Wang WX, 2015, KSII T INTERNET INF, V9, P190, DOI 10.3837/tiis.2015.01.011
   Xiao Shengbi, 2015, Computer Engineering and Applications, V51, P176, DOI 10.3778/j.issn.1002-8331.1410-0045
   Ye J, 2018, FUTURE GENER COMP SY, V81, P433, DOI 10.1016/j.future.2017.09.030
   [占必超 Zhan Bichao], 2010, [光学学报, Acta Optica Sinica], V30, P2788
   [张小刚 Zhang Xiaogang], 2014, [自动化学报, Acta Automatica Sinica], V40, P1733
   Zhu C, 2005, INT J REMOTE SENS, V26, P5493, DOI 10.1080/01431160500300354
NR 33
TC 8
Z9 11
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 947
EP 964
DI 10.1007/s11042-018-5962-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500054
DA 2024-07-18
ER

PT J
AU Zhou, SW
   Chen, ZN
   Zhong, Q
   Li, H
AF Zhou, Siwang
   Chen, Zhineng
   Zhong, Qian
   Li, Heng
TI Block compressed sampling of image signals by saliency based adaptive
   partitioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sampling; Image; Saliency; Clustering
ID RECOVERY; MODEL
AB In recent years, block compressed sampling (BCS) has emerged as a considerable attractive sampling technology for image acquisition. However, the general BCS approaches ignore the information distribution in the same image sub-block, and may lead to unfair allocation of sampling resources. In this paper, we propose a novel compressed sampling scheme by employing the idea of adaptive partition. In the proposed scheme, images are adaptively partitioned based on their saliency information through clustering, and pixels with similar saliency are gathered in the same sub-blocks. Sampling rates for those blocks, in turn, are computed on the basis of their saliency values, respectively. Therefore the sampling resources are allocated with fairer and more equitable sharing by all sub-blocks. Experimental results show that the proposed scheme has better visual effect and obtains higher image reconstruction accuracy than existing ones.
C1 [Zhou, Siwang; Zhong, Qian; Li, Heng] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Hunan, Peoples R China.
   [Chen, Zhineng] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
C3 Hunan University; Chinese Academy of Sciences; Institute of Automation,
   CAS
RP Zhou, SW (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Hunan, Peoples R China.
EM swzhou@hnu.edu.cn; zhineng.chen@ia.ac.cn; qianzhong@hnu.edu.cn;
   lih@hnu.edu.cn
RI Lu, Wang/JVO-0416-2024; chen, zhineng/AAD-6723-2020
FU CERNET Innovation Project of China [NGII20160323]
FX This work is supported by CERNET Innovation Project of China under Grant
   Number NGII20160323.
CR Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chen C, 2011, P IEEE AS C SIGN SYS
   Chen Z, MULTIMEDIA SYSTEMS
   Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duda R., 1973, Pattern Classification and Scene Analysis
   Fowler JE, 2010, FOUND TRENDS SIGNAL, V4, P297, DOI 10.1561/2000000033
   Fowler JE, 2011, P IEEE EUR SIGN PROC
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Gao X, 2017, P IEEE DEP SYST NETW
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Hou Y, 2014, P INT C PATT REC ICP
   Hu K, 2017, EXPERT SYST APPL, V86, P135, DOI 10.1016/j.eswa.2017.05.062
   Hu K, 2011, IEEE T INSTRUM MEAS, V60, P462, DOI 10.1109/TIM.2010.2051060
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang YG, 2018, IEEE T PATTERN ANAL, V40, P352, DOI 10.1109/TPAMI.2017.2670560
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Liu N, 2017, IEEE T POWER SYST, V32, P3569, DOI 10.1109/TPWRS.2017.2649558
   Liu W, 2015, PROC CVPR IEEE, P3707, DOI 10.1109/CVPR.2015.7298994
   Liu W, 2014, IEEE T MULTIMEDIA, V16, P2242, DOI 10.1109/TMM.2014.2359332
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Wang M, 2015, IEEE T INFORM THEORY, V61, P1028, DOI 10.1109/TIT.2014.2376955
   [王蓉芳 Wang Rongfang], 2013, [电子学报, Acta Electronica Sinica], V41, P1506
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yu Y, 2010, IEEE SIGNAL PROC LET, V17, P973, DOI 10.1109/LSP.2010.2080673
   Zhang JG, 2017, MULTIMED TOOLS APPL, V76, P4227, DOI 10.1007/s11042-016-3496-x
NR 27
TC 17
Z9 18
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 537
EP 553
DI 10.1007/s11042-017-5249-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500030
DA 2024-07-18
ER

PT J
AU Zu, YR
   Tang, WZ
   Bao, XG
   Wang, YY
   Gao, K
AF Zu, Yueran
   Tang, Wenzhong
   Bao, Xiuguo
   Wang, Yanyang
   Gao, Ke
TI Context-adaptive matching for optical flow
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical flow; PatchMatch; Edge preserving; Large displacement
AB Modern sparse-to-dense optical flow estimation algorithms usually achieve state-of-art performance. Those algorithms need two steps: matching and interpolation. Matching is often unreliable for very large displacement optical flow due to illumination changes, deformations and occlusion etc. Moreover, conspicuous errors around motion discontinuities still keep serious as most methods consider edge only at interpolation step. The context-adaptive matching (CAM) is proposed for optical flow which is better at large displacement and edge preserving. The CAM is selective in feature extraction, adaptive in flow propagation and search radius adjusting. Selective features are proposed to consider edge preserving in matching step. Except for the usually used SIFT descriptor, the local directional pattern flow (LDPF) is introduced to keep more edge structure, and the oriented fast and rotated brief (ORB) is utilized to select out several most similar candidates. Unlike coarse-to-fine matching, which proposed a propagation step with only neighbors, we propose adaptive propagation to extend the matching candidates in order to improve the possibility of getting right correspondences. Furthermore, guided by prior knowledge and taking advantage of upper layers results, adaptive radius instead of constrained radius are proposed at finer layers. The CAM interpolated by EpicFlow is fast and robust for large displacements especially for fast moving objects and also preserves the edge structure well. Extensive experiments show that our algorithm is on par with the state-of-art optical flow methods on MPI-Sintel, KITTI and Middlebury.
C1 [Zu, Yueran; Tang, Wenzhong] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
   [Bao, Xiuguo] Coordinat Ctr China CNCERT, Natl Comp Network Emergency Response Tech Team, Beijing 100029, Peoples R China.
   [Wang, Yanyang] Beihang Univ, Sch Aeronaut Sci & Engn, Beijing 100191, Peoples R China.
   [Gao, Ke] Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China.
C3 Beihang University; Beihang University; Chinese Academy of Sciences;
   Institute of Computing Technology, CAS
RP Gao, K (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China.
EM yueranzu@buaa.edu.cn; tangwenzhong@buaa.edu.cn; baoxiuguo@cert.org.cn;
   wangyanyang@buaa.edu.cn; kegao@ict.ac.cn
RI li, yao/IYJ-1364-2023
FU Beijing Municipal Science and Technology Commission Project
   [Z171100000117010]; National Key Research and Development Plan
   [2016YFB0801203, 2016YFB0801200]; National Nature Science Foundation of
   China [61271428]
FX This work was supported by Beijing Municipal Science and Technology
   Commission Project Z171100000117010, the National Key Research and
   Development Plan (Nos. 2016YFB0801203, 2016YFB0801200), and National
   Nature Science Foundation of China (61271428).
CR Bailer C, 2015, IEEE I CONF COMP VIS, P4015, DOI 10.1109/ICCV.2015.457
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   Bao LC, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2359374
   Barnes C., 2010, LECT NOTES COMPUT SC, V6313, P29
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Black M. J., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P296, DOI 10.1109/CVPR.1991.139705
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Bouguet, 2001, INTEL CORP, V5, P4, DOI DOI 10.1109/HPDC.2004.1323531
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Drayer B, 2015, BMVC, P42
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Hu YL, 2016, PROC CVPR IEEE, P5704, DOI 10.1109/CVPR.2016.615
   Jabid T., 2010, Digest of Technical Papers Int. Conf. Consumer Electronics, P329, DOI DOI 10.1109/ICCE.2010.5418801
   Kanade T., 1981, P 7 INT JOINT C ARTI, V1, P674, DOI DOI 10.5555/1623264.1623280
   Kennedy R, 2015, LECT NOTES COMPUT SC, V8932, P364, DOI 10.1007/978-3-319-14612-6_27
   Li Y, 2016, LECT NOTES COMPUT SC, V9907, P717, DOI 10.1007/978-3-319-46487-9_44
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JB, 2013, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2013.242
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720
   Roth S, 2009, LECT NOTES COMPUT SC, V5604, P1, DOI 10.1007/978-3-642-03061-1_1
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x
   Timofte R, 2015, IEEE WINT CONF APPL, P1100, DOI 10.1109/WACV.2015.151
   Wang SL, 2016, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2016.21
   Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175
   Xu L, 2010, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2010.5539820
NR 35
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 641
EP 659
DI 10.1007/s11042-017-5386-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500036
DA 2024-07-18
ER

PT J
AU Fang, F
   Wang, HL
   Chen, YH
   Tang, PJ
AF Fang, Fang
   Wang, Hanli
   Chen, Yihao
   Tang, Pengjie
TI Looking deeper and transferring attention for image captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image captioning; Attention; LSTM; Stacked attention
AB Image captioning is a challenging task which requires not only to extract semantic information but also to generate descriptions with correct sentences. Most of the previous researches employ one-layer or two-layer Recurrent Neural Network (RNN) as the language model to predict sentence words. The language model may easily deal with the word information for a noun or an object, however, it may not be able to learn a verb or an adjective. To address this issue, a deep attention based language model is proposed to learn more abstract word information and three stacked approaches are designed to process attention. The proposed model makes full use of the Long Short Term Memory (LSTM) network and employs the transferred current attention to enhance extra spatial information. The experimental results on the benchmark MSCOCO and Flickr30 K datasets have verified the effectiveness of the proposed model.
C1 [Fang, Fang; Wang, Hanli; Chen, Yihao; Tang, Pengjie] Tongji Univ, Dept Comp Sci & Technol, Shanghai 201804, Peoples R China.
   [Fang, Fang; Wang, Hanli; Chen, Yihao; Tang, Pengjie] Tongji Univ, Key Lab Embedded Syst & Serv Comp, Minist Educ, Shanghai 200092, Peoples R China.
   [Fang, Fang; Wang, Hanli; Chen, Yihao; Tang, Pengjie] Shanghai Engn Res Ctr Ind Vis Percept & Intellige, Shanghai 200092, Peoples R China.
C3 Tongji University; Tongji University
RP Wang, HL (corresponding author), Tongji Univ, Dept Comp Sci & Technol, Shanghai 201804, Peoples R China.; Wang, HL (corresponding author), Tongji Univ, Key Lab Embedded Syst & Serv Comp, Minist Educ, Shanghai 200092, Peoples R China.; Wang, HL (corresponding author), Shanghai Engn Res Ctr Ind Vis Percept & Intellige, Shanghai 200092, Peoples R China.
EM hanliwang@tongji.edu.cn
RI Wang, Hanli/G-5111-2014
OI Wang, Hanli/0000-0002-9999-4871
FU National Natural Science Foundation of China [61622115, 61472281];
   Program for Professor of Special Appointment (Eastern Scholar) at
   Shanghai Institutions of Higher Learning [GZ2015005]; Shanghai
   Engineering Research Center of Industrial Vision Perception &
   Intelligent Computing [17DZ2251600]; IBM Shared University Research
   Awards Program
FX This work was supported in part by National Natural Science Foundation
   of China under Grants 61622115 and 61472281, Program for Professor of
   Special Appointment (Eastern Scholar) at Shanghai Institutions of Higher
   Learning (No. GZ2015005), Shanghai Engineering Research Center of
   Industrial Vision Perception & Intelligent Computing (17DZ2251600), and
   IBM Shared University Research Awards Program.
CR [Anonymous], 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.345
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, P ICLR 15
   [Anonymous], TECH REP
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2015, PROCIEEE CONFCOMPUT
   Banerjee S, 2005, ACL WORKSHOP INTRINS, P65
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Prakash Aaditya, 2016, P COLING 2016 26 INT
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Srivastava RK., 2015, P 28 INT C NEURAL IN, P2377, DOI DOI 10.48550/ARXIV.1507.06228
   Sutskever I, 2014, ADV NEUR IN, V27
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Xu K., 2015, COMPUTER SCI, P2048
   Yao T, 2017, P IEEE INT C COMP VI, P4894
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
NR 27
TC 7
Z9 7
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31159
EP 31175
DI 10.1007/s11042-018-6228-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600045
DA 2024-07-18
ER

PT J
AU Huo, FC
   Wang, D
   Ren, WJ
   Du, Y
AF Huo, Fengcai
   Wang, Di
   Ren, Weijian
   Du, Ying
TI Improved image matching method based on cursory search and
   detail-oriented correction with extension window
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive optimal guidance; Artificial bee Colony algorithm; Gray
   relation analysis; Extension window; SIFT algorithm; Image matching
ID SEGMENTATION; OPTIMIZATION
AB In order to achieve the fast and accurate image matching, gray matching algorithm and SIFT feature matching algorithm are combined, and an approach to the cursory search and detail-oriented correction with extension window is proposed. The cursory search is achieved by using new adaptive optimal guidance artificial bee colony algorithm (AOGABC) instead of ergodicity of the traditional gray matching algorithm. The gray correlation degree with statistical properties serves as the fitness function of the artificial colony algorithm (ABC). The extensional image window has built after cutting image according to the extension rules in extension window, detail-oriented correction accurately matches image by using the SIFT algorithm. The experiments verify that the matching method not only realizes rapidity because of performance of artificial bee colony algorithm and gray relational grade in the cursory search, but also achieves matching accuracy resulted from the combination of SIFT algorithm and extension window in this paper. By comparing the effects of different algorithms in the typical image, the results show that the purpose of the exact match is achieved.
C1 [Huo, Fengcai; Wang, Di; Ren, Weijian] Northeast Petr Univ, Sch Elect Informat Engn, Daqing 163318, Peoples R China.
   [Du, Ying] China Power Puhua Informat Technol Co Ltd, Beijing 100085, Peoples R China.
C3 Northeast Petroleum University
RP Wang, D (corresponding author), Northeast Petr Univ, Sch Elect Informat Engn, Daqing 163318, Peoples R China.
EM 718005334@qq.com
FU National Natural Science Foundation of China [61374127, 51404073];
   Outstanding Youth Science Foundation of National Natural Science
   Foundation of China [61422301]; Chinese Postdoctoral Science Foundation
   [2014 M550180]; Scientific Research Fund of Heilongjiang Provincial
   Department of Education [12541090]; Excellent Youth Foundation of
   Heilongjiang Scientific Committee [JC2015016]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61374127 and 51404073, the Outstanding
   Youth Science Foundation of National Natural Science Foundation of China
   under Grant 61422301, the Chinese Postdoctoral Science Foundation under
   Grant 2014 M550180, the Scientific Research Fund of Heilongjiang
   Provincial Department of Education under Grant 12541090, and the
   Excellent Youth Foundation of Heilongjiang Scientific Committee
   JC2015016.
CR Bulò SR, 2011, COMPUT VIS IMAGE UND, V115, P984, DOI 10.1016/j.cviu.2010.12.004
   Cappabianco FAM, 2012, COMPUT VIS IMAGE UND, V116, P1047, DOI 10.1016/j.cviu.2012.06.002
   Chi J, 2017, COMPUTER VISION IMAG
   Civicioglu P, 2013, ARTIF INTELL REV, V39, P315, DOI 10.1007/s10462-011-9276-0
   Du SL, 2017, REMOTE SENS LETT, V8, P1180, DOI 10.1080/2150704X.2017.1368097
   Geng X, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121262
   Hirschmüller H, 2009, IEEE T PATTERN ANAL, V31, P1582, DOI 10.1109/TPAMI.2008.221
   Hsu CI, 2000, EUR J OPER RES, V127, P44, DOI 10.1016/S0377-2217(99)00320-3
   Ishida T, 1999, J DIGIT IMAGING, V12, P77, DOI 10.1007/BF03168846
   Jiang J, 2016, IEEE GEOSCI REMOTE S, V13, P1716, DOI 10.1109/LGRS.2016.2605304
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Li ZW, 2015, ARTIF INTELL MED, V64, P161, DOI 10.1016/j.artmed.2015.05.002
   Lo TWR, 2009, COMPUT VIS IMAGE UND, V113, P1235, DOI 10.1016/j.cviu.2009.06.005
   Lourenço M, 2012, IEEE T ROBOT, V28, P752, DOI 10.1109/TRO.2012.2184952
   Ma JY, 2015, IEEE T GEOSCI REMOTE, V53, P6469, DOI 10.1109/TGRS.2015.2441954
   Melendez J, 2011, COMPUT VIS IMAGE UND, V115, P1121, DOI 10.1016/j.cviu.2011.03.008
   Pan B, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.3.034106
   Remondino F, 2014, PHOTOGRAMM REC, V29, P144, DOI 10.1111/phor.12063
   Robin C, 2016, AUTON ROBOT, V40, P729, DOI 10.1007/s10514-015-9491-7
   Si YS, 2015, COMPUT ELECTRON AGR, V112, P68, DOI 10.1016/j.compag.2015.01.010
   Thirion J P, 1998, Med Image Anal, V2, P243, DOI 10.1016/S1361-8415(98)80022-4
   Thorat CG, 2010, PROCEDIA COMPUT SCI, V2, P236, DOI 10.1016/j.procs.2010.11.030
   Wu YW, 2013, COMPUT VIS IMAGE UND, V117, P1421, DOI 10.1016/j.cviu.2013.05.003
   Yan L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8100799
   Zhang HZ, 2016, NEUROCOMPUTING, V218, P242, DOI 10.1016/j.neucom.2016.08.051
   Zhang S, 2011, PROCEDIA ENG, V15, P2255
   Zuo YJ, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.12.123111
NR 27
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28885
EP 28904
DI 10.1007/s11042-018-6070-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500046
DA 2024-07-18
ER

PT J
AU Abbas, NH
   Ahmad, SMS
   Parveen, S
   Wan, WA
   Bin Ramli, A
AF Abbas, Nidaa Hasan
   Ahmad, Sharifah Mumtazah Syed
   Parveen, Sajida
   Wan, Wan Azizun
   Bin Ramli, Abd. Rahman
TI Design of high performance copyright protection watermarking based on
   lifting wavelet transform and bi empirical mode decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Robust watermarking; Lifting wavelet transform
   (LWT); Bi- dimensional Empirical Mode Decomposition (BEMD)
ID SINGULAR-VALUE DECOMPOSITION; IMAGE; ROBUST; SPECTRUM
AB This paper developed new and efficient image watermarking scheme for copyright protection based on Lifting wavelet transform (LWT) and Bi- dimensional Empirical Mode Decomposition (BEMD). A LWT has been selected because it is fast, less computational cost and maintains the integrity of the recovered watermark. The BEMD transform can separate the image from the most robust to the least sensitive or fragile frequency bands. This advantage is utilised in this study for the purpose of embedding the watermark in the robust part of BEMD, i.e. the residue (r). In addition, the embedding process has been performed in the low sub-band of LWT decomposed image as the low sub-band is more robust to image processing such as JPEG compression. The robust watermark which is grey scale image is decomposed using DWT to enhance the security and select only high sub-band as it has less impact on the quality of the watermarked image. As a result, the original image's visual quality can be preserved and the concealed watermark could be successfully retrieved even if the watermarked images have undergone severe attacks like JPEG, rotation, Gamma correction, filtering, additive noise, translation, shearing, and scaling. Furthermore, the improved scheme offers greater robustness against many image processing operations, in comparison to the current schemes about copyright protection.
C1 [Abbas, Nidaa Hasan] Al Mustansiriyah Univ, Elect Dept, Fac Engn, Baghdad, Iraq.
   [Abbas, Nidaa Hasan; Ahmad, Sharifah Mumtazah Syed; Wan, Wan Azizun; Bin Ramli, Abd. Rahman] Univ Putra Malaysia, Dept Comp & Commun Syst Engn, Serdang, Selangor, Malaysia.
   [Ahmad, Sharifah Mumtazah Syed] Res Ctr Excellence Wireless & Photon Network, Serdang 43400, Malaysia.
   [Parveen, Sajida] Quaid E Awam Univ Engn Sci & Technol, Fac Elect Elect & Comp Syst Engn, Nawabshah 67450, Pakistan.
C3 Mustansiriya University; Universiti Putra Malaysia
RP Abbas, NH (corresponding author), Al Mustansiriyah Univ, Elect Dept, Fac Engn, Baghdad, Iraq.; Abbas, NH (corresponding author), Univ Putra Malaysia, Dept Comp & Commun Syst Engn, Serdang, Selangor, Malaysia.
EM nidaahasan71@uomustansiriyah.edu.iq
RI AHMAD, SHARIFAH/JJC-4353-2023
CR Abbas NH, 2015, INT REV COMPUT SOFTW, V10, P1127
   Agreste S, 2007, J COMPUT APPL MATH, V210, P13, DOI 10.1016/j.cam.2006.10.087
   Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   [Anonymous], 2016, AL SAD INT C MULT IT, DOI DOI 10.1109/PIMRC.2016.7794827
   Bhuiyan SMA, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/728356
   Bi N, 2007, IEEE T IMAGE PROCESS, V16, P1956, DOI 10.1109/TIP.2007.901206
   Cox I. J., 2002, Digital Watermarking
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Deng MH, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P36, DOI 10.1109/ICCCS.2009.19
   Du L, 2009, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON ANTI-COUNTERFEITING, SECURITY, AND IDENTIFICATION IN COMMUNICATION, P148, DOI 10.1109/ICASID.2009.5276920
   Himaja G, 2012, INT J COMPUT TECHNOL, V2, P61
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Huang W, 2007, INT C COMMUN CIRCUIT, P588
   Kovesi P, 2003, P AUSTR C PATT REC S
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Lee Y, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P583, DOI 10.1109/ISM.2009.48
   LingFei Liang, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P561, DOI 10.1109/PACIIA.2008.199
   Loukhaoukha K, 2009, 2009 11TH CANADIAN WORKSHOP ON INFORMATION THEORY, P177, DOI 10.1109/CWIT.2009.5069549
   Makbol NM, 2014, DIGIT SIGNAL PROCESS, V33, P134, DOI 10.1016/j.dsp.2014.06.012
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Nunes JC, 2003, IMAGE VISION COMPUT, V21, P1019, DOI 10.1016/S0262-8856(03)00094-5
   Parthasarathy A. K., 2006, THESIS
   Parveen S, 2016, COMPUTERS, V5, DOI 10.3390/computers5020010
   Sabri A, 2009, 5 INT C SCI EL TECHN
   Sinsha PP, 2015, INT J ENG INNOV TECH, V4, P209
   Su QT, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P70
   Taghia J, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 5, PROCEEDINGS, P674, DOI 10.1109/CISP.2008.717
   Tomar V, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON RELIABILTY, OPTIMIZATION, & INFORMATION TECHNOLOGY (ICROIT 2014), P501, DOI 10.1109/ICROIT.2014.6798375
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Yousefi S., 2007, 2007 Inaugural IEEE International Conference on Digital Ecosystems and Technologies, P487, DOI 10.1109/DEST.2007.372025
   Yuan H, 2006, IEEE T IMAGE PROCESS, V15, P3189, DOI 10.1109/TIP.2006.877310
   Yuan Y, 2006, FIRST INTERNATIONAL MULTI-SYMPOSIUMS ON COMPUTER AND COMPUTATIONAL SCIENCES (IMSCCS 2006), PROCEEDINGS, VOL 2, P175, DOI 10.1109/IMSCCS.2006.187
   Zheng QM, 2009, ICCSSE 2009: PROCEEDINGS OF 2009 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION, P716, DOI 10.1109/ICCSE.2009.5228122
NR 34
TC 11
Z9 11
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24593
EP 24614
DI 10.1007/s11042-017-5488-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Fan, XN
   Wu, JJ
   Shi, PF
   Zhang, XW
   Xie, YJ
AF Fan, Xinnan
   Wu, Jingjing
   Shi, Pengfei
   Zhang, Xuewu
   Xie, Yingjuan
TI A novel automatic dam crack detection algorithm based on local-global
   clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crack detection; Dam; CrackLG; Feature extraction; K-means clustering;
   Threshold
AB Dam crack detection is necessary to ensure the safety of dams. However, traditional detection methods always perform poorly, with a low detection rate and high false alarm rate, due to the complex underwater environment. In this paper, a novel automatic dam crack detection algorithm (CrackLG) is proposed based on local-global clustering analysis that can find cracks on dam surfaces accurately and quickly using images as well as reduce human subjectivity. First, an image shot of an underwater dam surface is divided into non-overlapping image blocks after pre-processing. Then, image blocks containing crack pixels are identified by local clustering analysis. Second, the image is binarized by adaptive bi-level thresholding based on the local gray intensity. Meanwhile, some noise is removed based on the computed optimal threshold. After extracting global 3-D features, final crack regions are obtained by global clustering analysis. The advantage of CrackLG is that the threshold for realizing image binarization is self-adaptive. Additionally, it can automatically perform crack detection without human supervision. The simulation and comparison show that the proposed CrackLG method is more effective for underwater dam crack detection.
C1 [Fan, Xinnan; Wu, Jingjing; Shi, Pengfei; Zhang, Xuewu; Xie, Yingjuan] Hohai Univ, Coll Internet Things Engn, Changzhou 213022, Peoples R China.
C3 Hohai University
RP Shi, PF (corresponding author), Hohai Univ, Coll Internet Things Engn, Changzhou 213022, Peoples R China.
EM fanxn@hhuc.edu.cn; wujj@hhu.edu.cn; shipf@hhu.edu.cn;
   zhangxw@hhuc.edu.cn; yjxie@hhu.edu.cn
RI Zhang, Xuewu/HGB-5196-2022
FU National Natural Science Foundation of China [61573128, 61671202];
   National Key Research Program of China [2016YFC0401606]; Jiangsu
   Province Natural Science Foundation [BK20170305]; Fundamental Research
   Funds for the Central Universities [2015B25214]
FX This paper has a clear division of labor. Fan Xinnan contributed to the
   conception and design of the study. Wu Jingjing wrote and performed the
   simulation. Shi Pengfei and Zhang Xuewu revised the manuscript. All
   authors have read and approved the final manuscript. The authors also
   wish to thank the National Natural Science Foundation of China (No.
   61573128 and No. 61671202), the National Key Research Program of China
   (No. 2016YFC0401606), the Jiangsu Province Natural Science Foundation
   (grant number BK20170305), and the Fundamental Research Funds for the
   Central Universities (No. 2015B25214), which provide financial aid and
   assistance for this paper.
CR Adhikari RS, 2014, AUTOMAT CONSTR, V39, P180, DOI 10.1016/j.autcon.2013.06.011
   Ahmed NB, 2017, 2017 INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND DIAGNOSIS (ICCAD), P528, DOI 10.1109/CADIAG.2017.8075714
   Amhaz R., 2015, IEEE Transactions on Intelligent Transportation Systems
   [Anonymous], 2009, FINDING GROUPS DATA
   Anzai Y., 2012, Pattern recognition machine learning
   Boutsidis C, 2013, IEEE T INFORM THEORY, V59, P6099, DOI 10.1109/TIT.2013.2255021
   Chambon S., 2009, IMAGE PROCESSING MAC, V7251
   Dewan S, 2015, 2015 IEEE/ACIS 14TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS), P313, DOI 10.1109/ICIS.2015.7166612
   Dongna Hu, 2012, 2012 Third International Conference on Intelligent Control and Information Processing (ICICIP 2012), P597, DOI 10.1109/ICICIP.2012.6391474
   Dorafshan S, 2016, THESIS
   Fasel TR, 2005, EARTHQ ENG STRUCT D, V34, P763, DOI 10.1002/eqe.454
   Kumar M, 2007, COMPUT STAT DATA AN, V51, P6084, DOI 10.1016/j.csda.2006.12.012
   Lee BY, 2013, STRUCT INFRASTRUCT E, V9, P567, DOI 10.1080/15732479.2011.593891
   Li QQ, 2008, REMOTE SENSING SPATI, P37
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Lins RG, 2016, IEEE T INSTRUM MEAS, V65, P583, DOI 10.1109/TIM.2015.2509278
   Liu QY, 2005, J WUHAN U TECHNOL
   Meng Q, 2016, INT CONF INFO SCI, P465, DOI 10.1109/ICIST.2016.7483459
   Nishikawa T, 2012, COMPUT-AIDED CIV INF, V27, P29, DOI 10.1111/j.1467-8667.2011.00716.x
   Oliveira H, 2017, EUR SIGNAL PR CONF, P2026, DOI 10.23919/EUSIPCO.2017.8081565
   Oliveira H, 2013, IEEE T INTELL TRANSP, V14, P155, DOI 10.1109/TITS.2012.2208630
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Sevim B, 2013, ADV CONCR CONSTR, V1, P227, DOI 10.12989/acc2013.1.3.227
   Sevim B, 2012, COMPUT CONCRETE, V10, P277
   Shi P, 2016, STRUCTURAL HLTH MONI
   Shi Y, 2016, IEEE T INTELL TRANSP, V17, P3434, DOI 10.1109/TITS.2016.2552248
   Wang G-r, 2015, COMPUT MODERN, V9
   Xiangan W, 1998, GEOL PROSPECT, P3
   [徐威 Xu Wei], 2013, [中国图象图形学报, Journal of Image and Graphics], V18, P69
   Yohwan Noh, 2017, 2017 International Conference on Applied System Innovation (ICASI). Proceedings, P877, DOI 10.1109/ICASI.2017.7988574
   Zarfl C, 2015, AQUAT SCI, V77, P161, DOI 10.1007/s00027-014-0377-0
   Zhang GX, 2008, SCI CHINA SER E, V51, P48, DOI 10.1007/s11431-008-6012-3
   Zhang L., 2016, J. Sensors, V2016, P1, DOI DOI 10.1155/2016/7864213
   Zhang Y, 2002, J WEIFANG U, P2
   Zhu B.F., 2006, J HYDRAUL ENG, V5, P415
NR 36
TC 25
Z9 28
U1 5
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26581
EP 26599
DI 10.1007/s11042-018-5880-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500017
DA 2024-07-18
ER

PT J
AU Kerbiche, A
   Ben Jabra, S
   Zagrouba, E
   Charvillat, V
AF Kerbiche, Asma
   Ben Jabra, Saoussen
   Zagrouba, Ezzeddine
   Charvillat, Vincent
TI A robust video watermarking based on feature regions and crowdsourcing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video watermarking; Crowdsourcing; Feature regions; Collusion attacks;
   Video mosaic
AB Video watermarking technique aims at resolving insecurity problems. Recently, many approaches have been proposed in order to satisfy the new constraints of video applications such as robustness to collusion attacks, high level of security and signature invisibility. In this paper, a new video watermarking approach based on feature regions is proposed. The originality of this approach is to use crowdsourcing technique in order to detect feature regions. First, video summary is generated. This summary is then used to detect the first type of feature regions based on crowdsourcing technique. On the other hand, mosaic is generated from original video to detect the second type of feature region browsed by the moving objects. Finally, the signature is embedded into the mosaic generated after merging these two types of feature regions using multi-frequential watermarking scheme. Experimental results have shown a high level of invisibility thanks to the efficient choice of the embedded target. Moreover, the proposed approach is robust against several attacks especially to collusion attacks.
C1 [Kerbiche, Asma; Ben Jabra, Saoussen; Zagrouba, Ezzeddine] Univ Tunis El Manar, High Inst Comp Sci, Lab LIMTIC, 2 Rue Abou Rayhane Bayrouni, Ariana 2080, Tunisia.
   [Charvillat, Vincent] Univ Toulouse, INP Toulouse, Team Res VORTEX ENSEEIHT, Lab IRIT, Toulouse, France.
C3 Universite de Tunis-El-Manar; Universite Federale Toulouse Midi-Pyrenees
   (ComUE); Universite de Toulouse; Institut National Polytechnique de
   Toulouse
RP Kerbiche, A (corresponding author), Univ Tunis El Manar, High Inst Comp Sci, Lab LIMTIC, 2 Rue Abou Rayhane Bayrouni, Ariana 2080, Tunisia.
EM asma.kerbiche@gmail.com; saoussen.bj@laposte.net;
   ezzeddine.zagrouba@fsm.rnu.tn; vincent.charvillat@enseeiht.fr
RI Zagrouba, Ezzeddine/D-7896-2014
OI Zagrouba, Ezzeddine/0000-0002-2574-9080
CR Amri S, 2009, TRAITEMENT LOMBRAGE
   [Anonymous], 23 EUR SIGN PROC C E
   [Anonymous], P ACM MULT WORKSH CR
   Azeem N, 2016, NEW ROBUST VIDEO WAT, V2
   Bayoudh I, 2015, INT COMP VIS THEOR A
   Bernstein Michael S., 2010, P 23ND ANN ACM S USE, P313, DOI 10.1145/1866029.1866078
   Bhardwaj A, 2017, Int J Eng Comput Sci (IJECS), V6, P21328, DOI [10.18535/ijecs/v6i5.23, DOI 10.18535/IJECS/V6I5.23]
   Carlier Axel, 2011, P 19 ACM INT C MULT, P43
   Carlier Axel, 2010, P 18 ACM INT C MULT, P201
   Faragallah OS, 2013, AEU-INT J ELECTRON C, V67, P189, DOI 10.1016/j.aeue.2012.07.010
   Guan GL, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2632267
   Howe J, 2006, WIRED, V14, P1, DOI DOI 10.1086/599595
   Jain K, 2015, J INFORM SECURITY RE
   Joshi AM, 2017, ADV INTELL SYST, V468, P455, DOI 10.1007/978-981-10-1675-2_45
   Kerbiche A., 2012, 2012 IEEE International Conference on Intelligent Computer Communication and Processing (ICCP 2012). Proceedings, P159, DOI 10.1109/ICCP.2012.6356180
   Kerbiche A, 2012, AFR C RES COMP SCI A, P332
   Kirthika A, 2016, MIDDLE E J SCI RES I, V24, P166
   Koubaa M, 2012, MULTIMEDIA TOOLS APP
   Li GL, 2014, IEEE CONF IMAGING SY, P1, DOI 10.1109/IST.2014.6958435
   Mao A, 2013, 1 AAAI C HUM COMP CO
   Nath Asoke, 2014, INT CONF ADV ELECTR
   Oleson D., 2011, HUMAN COMPUTATION, V11, P11
   Salvador A, 2013, ACM CROWDMM
   Srinivasa Rao Ch, 2016, P ICMEET, V372, P103
   Swati S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105613
   Tyagi S., 2017, INT C INV SYST CONTR
   Venugopala PS, 2016, INT C COMP SUST GLOB
   Verma AK, 2013, IEEE INT ADV COMPUT, P1195
   Zagrouba E, 2009, SPRINGER MACHINE VIS
NR 29
TC 9
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26769
EP 26791
DI 10.1007/s11042-018-5888-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500025
DA 2024-07-18
ER

PT J
AU Wu, X
   Du, ZK
   Guo, YK
AF Wu, Xing
   Du, Zhikang
   Guo, Yike
TI A visual attention-based keyword extraction for document classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual attention; Semantic context; Keyword extraction; Document
   classification; Long short-term memory
AB Document classification plays an important role in natural language processing. Among that, keyword extraction algorithm shows its great potential in summarizing the entire document. Attention is the process of selectively concentrating on a discrete aspect of information, while ignoring other perceivable information. A new probabilistic keyword extraction algorithm is proposed, which is inspired by the visual attention mechanism. An unsupervised neural network based pre-training method is proposed for training the semantic attention based keyword extraction algorithm, which is helpful in extracting keywords with rich contextual information from the document. A bidirectional Long short-term memory network combined with the proposed semantic keyword extraction algorithm is designed for both topic and sentiment classification tasks. Experiments on four large scale datasets show that the proposed visual attention based keyword extraction algorithm gives a better performance than the baseline methods. The semantic attention based keyword extraction method is significant in summarizing the content of a document, which is very useful for large scale document classification.
C1 [Wu, Xing; Du, Zhikang; Guo, Yike] Shanghai Univ, Sch Comp Engn & Sci, Shanghai 200444, Peoples R China.
   [Wu, Xing; Du, Zhikang; Guo, Yike] Shanghai Inst Adv Commun & Data Sci, Shanghai, Peoples R China.
C3 Shanghai University
RP Wu, X (corresponding author), Shanghai Univ, Sch Comp Engn & Sci, Shanghai 200444, Peoples R China.; Wu, X (corresponding author), Shanghai Inst Adv Commun & Data Sci, Shanghai, Peoples R China.
EM xingwu@shu.edu.cn; duzhikang@shu.edu.cn; y.guo@imperial.ac.uk
RI 郭, 伊可/GYD-3212-2022
FU National Natural Science Foundation of China [61303094]; Science and
   Technology Commission of Shanghai Municipality [16511102400,
   16111107800]; Innovation Program of Shanghai Municipal Education
   Commission [14YZ024]
FX This paper is supported by the project 61303094 supported by National
   Natural Science Foundation of China, by the Science and Technology
   Commission of Shanghai Municipality 16511102400 and 16111107800, by
   Innovation Program of Shanghai Municipal Education Commission (14YZ024).
CR [Anonymous], 2015, E SCI TECHNOL APPL
   [Anonymous], NEW TECHNOLOGY LIB I
   [Anonymous], 2014, ARXIV14085882
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2017, YELP DATASET CHALLEN
   [Anonymous], ADV NEURAL INF PROCE
   [Anonymous], IJCAI
   [Anonymous], 2016, ARXIV160307252
   Bengio Y., 2014, TECHNICAL REPORT
   Chung J., 2014, NIPS 2014 WORKSH DEE
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Guo Z, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P357, DOI 10.1145/2964284.2967242
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Jingyang, 2007, P 2007 JOINT C EMPIR, P774
   Matsuo Y., 2004, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V13, P157, DOI 10.1142/S0218213004001466
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI [DOI 10.3115/V1/D14-1162, 10.3115/v1/D14-1162]
   Tang Duyu, 2015, P 2015 C EMPIRICAL M, P1422
   Xu K., 2015, COMPUTER SCI, P2048
   Zhang X, 2015, ADV NEUR IN, V28
   Zhang YF, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P83, DOI 10.1145/2600428.2609579
NR 23
TC 9
Z9 10
U1 1
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25355
EP 25367
DI 10.1007/s11042-018-5788-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400034
DA 2024-07-18
ER

PT J
AU Hardalaç, F
   Kutbay, U
   Sahin, I
   Akyel, A
AF Hardalac, Firat
   Kutbay, Ugurhan
   Sahin, Isa
   Akyel, Anil
TI A novel method for robust object tracking with K-means clustering using
   histogram back-projection technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Objecttracking; K-means; Bhattacharyya coefficient; Moment centroid;
   Histogram equalization
ID IMAGE; ALGORITHM; SEGMENTATION; INFORMATION
AB This paper presents a novel and fast method for k-means clustering based object tracking for coloured frames, based on histogram back-projection method. The proposed method uses histogram equalization for finding centroid of the object for each frame. As from the information transfer aspect, this study improves the tracking performance using Bhattacharya Coefficient with the method of histogram back-projection including k-means clustering. Histogram back-projection computes the probability of the object of interest and the clustering process classifies high-performance regions. In addition, a mean shift tracking method is used to monitor the object after the histogram back-projection process, which provides better tracking for fast-moving objects. The proposed mean shift algorithm also provides gradient ascent. In addition, this method is invariant to clutter and camera motion; pose changes and faster tracking. Simulated results show that the proposed method gives better tracking results than other conventional methods while having a lower computational demand. Therefore it is highlighted that the proposed method would have a significant contribution in the field of object tracking.
C1 [Hardalac, Firat; Kutbay, Ugurhan; Sahin, Isa; Akyel, Anil] Gazi Univ, Fac Engn, Dept Elect & Elect Engn, Ankara, Turkey.
C3 Gazi University
RP Akyel, A (corresponding author), Gazi Univ, Fac Engn, Dept Elect & Elect Engn, Ankara, Turkey.
EM anilyumlu@gmail.com
RI Akyel, Anıl/ABD-6397-2021; KUTBAY, Ugurhan/AAP-8534-2020; Akyel,
   Anol/ABD-5456-2021
OI Akyel, Anıl/0000-0001-7393-526X; KUTBAY, Ugurhan/0000-0003-2167-9107; 
CR Ahmad R, 2012, COMPUT AIDED DESIGN, V44, P355, DOI 10.1016/j.cad.2011.12.008
   Avidan S, 2005, PROC CVPR IEEE, P494
   Balasubramanian VK, 2016, TURK J ELECTR ENG CO, V24, P1615, DOI 10.3906/elk-1310-179
   Ben Ayed I, 2012, MED IMAGE ANAL, V16, P87, DOI 10.1016/j.media.2011.05.009
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Cao J, 2013, SIGNAL PROCESS, V93, P2026, DOI 10.1016/j.sigpro.2012.07.030
   Cheng TY, 2014, INFRARED PHYS TECHN, V62, P70, DOI 10.1016/j.infrared.2013.10.009
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dai SF, 2015, NEUROCOMPUTING, V168, P799, DOI 10.1016/j.neucom.2015.05.044
   Enkelmann W, 2001, INT J COMPUT VISION, V45, P201, DOI 10.1023/A:1013658100226
   Finlayson G, 2005, PATTERN RECOGN, V38, P179, DOI 10.1016/j.patcog.2004.04.010
   Ghassabeh YA, 2013, PATTERN RECOGN, V46, P3140, DOI 10.1016/j.patcog.2013.04.014
   Göçeri E, 2015, TURK J ELECTR ENG CO, V23, P741, DOI 10.3906/elk-1304-36
   Horn B.K.P, 1986, Robot Vision
   Hsieh PC, 2010, NEUROCOMPUTING, V73, P2708, DOI 10.1016/j.neucom.2010.04.015
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hu W, 2016, INT C WAVEL ANAL PAT, P252, DOI 10.1109/ICWAPR.2016.7731649
   Intille SS, 1997, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.1997.609402
   Jian M, 2015, NEUROCOMPUTING, V161, P210, DOI 10.1016/j.neucom.2015.02.040
   Khalid M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.1.56-61
   Klette R, 2012, COMPUT VIS IMAGE UND, V116, P690, DOI 10.1016/j.cviu.2012.02.001
   Lautissier J, 2003, P ANN INT IEEE EMBS, V25, P739, DOI 10.1109/IEMBS.2003.1279870
   Leichter I, 2010, COMPUT VIS IMAGE UND, V114, P400, DOI 10.1016/j.cviu.2009.12.006
   Li J, 2008, PATTERN RECOGN, V41, P3244, DOI 10.1016/j.patcog.2008.03.018
   Li MX, 2013, NEUROCOMPUTING, V119, P41, DOI 10.1016/j.neucom.2012.02.050
   Li SX, 2010, IMAGE VISION COMPUT, V28, P424, DOI 10.1016/j.imavis.2009.06.012
   Lin CH, 2014, EXPERT SYST APPL, V41, P3276, DOI 10.1016/j.eswa.2013.11.017
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu N, 2008, IMAGE VISION COMPUT, V26, P1421, DOI 10.1016/j.imavis.2008.01.004
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Martínez A, 2011, COMPUT VIS IMAGE UND, V115, P1083, DOI 10.1016/j.cviu.2011.03.005
   Qi SX, 2015, NEUROCOMPUTING, V167, P390, DOI 10.1016/j.neucom.2015.04.055
   Quine BM, 2007, COMPUT PHYS COMMUN, V177, P700, DOI 10.1016/j.cpc.2007.06.007
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Simakov D, 2008, PROC CVPR IEEE, P3887
   Singhal N, 2009, J VIS COMMUN IMAGE R, V20, P408, DOI 10.1016/j.jvcir.2009.04.002
   Tsai DM, 2013, ROBOT CIM-INT MANUF, V29, P312, DOI 10.1016/j.rcim.2013.01.009
   Wang FL, 2010, AEU-INT J ELECTRON C, V64, P614, DOI 10.1016/j.aeue.2009.04.004
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Yao AB, 2010, PATTERN RECOGN, V43, P1244, DOI 10.1016/j.patcog.2009.09.024
   Yu J, 2017, MULTIMED TOOLS APPL, V76, P14653, DOI 10.1007/s11042-016-3883-3
NR 41
TC 4
Z9 4
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24059
EP 24072
DI 10.1007/s11042-018-5661-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900042
DA 2024-07-18
ER

PT J
AU Chowdhury, K
   Chaudhuri, D
   Pal, AK
AF Chowdhury, Kuntal
   Chaudhuri, Debasis
   Pal, Arup Kumar
TI A new image segmentation technique using bi-entropy function
   minimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustering; Homogeneity; Remote sensing; Segmentation; Shannon's
   entropy; Smoothing
ID MAXIMUM-ENTROPY; ALGORITHM; SELECTION; FEATURES
AB A Image segmentation, the splitting of a multispectral and panchromatic image into groups of homogeneous pixels based on the region of interest(ROI), is a universal step for many advanced image processing and object recognition. Image segmentation essentially affects the overall performance of any automated image analysis system due to utmost importance of its quality. Image segmentation can be performed by recursively splitting the whole image or by merging together a large number of minute regions until a specified condition is satisfied. Thresholding is an old, simple and important method in gray scale image segmentation. In this paper, we have used Shannon's entropy and proposed a new multilevel thresholding image segmentation method based on minimization of bi-entropy function. A smoothing technique based on weight value of the pixel within a w x w moving window is introduced to make the splitting result continuous and qualitative. The proposed algorithm takes full account of the spatial information and the gray information to decrease the computing quantity. Standard medical images, texture images, and remote sensing images are segmented in the experiment and compared with other related segmentation methods with different measures. Experimental results show that the proposed method can quickly converge with high computational efficiency.
C1 [Chowdhury, Kuntal] DIT Univ, Dept Informat Technol, Dehra Dun, Uttarakhand, India.
   [Chaudhuri, Debasis] DRDO Integrat Ctr, Panagarh, W Bengal, India.
   [Pal, Arup Kumar] IIT ISM, Dept Comp Sci & Engn, Dhanbad, Jharkhand, India.
C3 DIT University; Defence Research & Development Organisation (DRDO); DRDO
   Integration Centre (DIC); Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (Indian School of Mines) Dhanbad
RP Chowdhury, K (corresponding author), DIT Univ, Dept Informat Technol, Dehra Dun, Uttarakhand, India.
EM ikuntal09@gmail.com; deba_chaudhuri@yahoo.co.in; arupkrpal@gmail.com
RI Pal, Arup Kumar/I-2496-2016; CHOWDHURY, KUNTAL/AAA-5002-2021
OI Chaudhuri, Debasis/0000-0002-6895-456X
CR [Anonymous], 1974, P 2 INT JOINT C PATT
   [Anonymous], ENG TECHNOLOGY
   [Anonymous], INT J ADV RES COMPUT
   Apró M, 2013, ACTA POLYTECH HUNG, V10, P43
   Arifin AZ, 2006, PATTERN RECOGN LETT, V27, P1515, DOI 10.1016/j.patrec.2006.02.022
   Badera A, 2009, J SIGNAL PROCESS SYS, P205
   Bandyopadhyay O, 2016, INT J IMAGE GRAPH, V16, DOI 10.1142/S0219467816500017
   Barbier AL, 2010, ENTROPY BASED APPROA, P512
   BONGIOVANNI G, 1993, PATTERN RECOGN, V26, P1845, DOI 10.1016/0031-3203(93)90181-U
   Bongiovanni G, 1988, MULTICOMPUTER VISION, P1
   BRINK AD, 1995, IEE P-VIS IMAGE SIGN, V142, P128, DOI 10.1049/ip-vis:19951850
   Brink AD, 1996, PATTERN RECOGN LETT, V17, P29, DOI 10.1016/0167-8655(95)00096-8
   Celeux G, 2003, PATTERN RECOGN, V36, P131, DOI 10.1016/S0031-3203(02)00027-4
   Chang CI, 2006, IEE P-VIS IMAGE SIGN, V153, P837, DOI 10.1049/ip-vis:20050032
   Chaudhuri D, 2008, IEEE T GEOSCI REMOTE, V46, P2720, DOI 10.1109/TGRS.2008.923631
   Chaudhuri D, 2012, IEEE J-STARS, V5, P1538, DOI 10.1109/JSTARS.2012.2199085
   Chaudhuri D, 2012, IEEE J-STARS, V5, P1231, DOI 10.1109/JSTARS.2012.2186630
   Chaudhuri D, 2010, DEFENCE SCI J, V60, P290, DOI 10.14429/dsj.60.356
   Chaudhuri D, 2001, P SOC PHOTO-OPT INS, V4388, P79, DOI 10.1117/12.438244
   Costa L., 2001, SHAPE ANAL CLASSIFIC
   Cover T. M., 1991, ELEMENTS INFORM THEO
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   Dong LJ, 2008, PATTERN RECOGN LETT, V29, P1311, DOI 10.1016/j.patrec.2008.02.001
   Feldman DP, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.051104
   Feng D, 2005, PATTERN RECOGN LETT, V26, P597, DOI 10.1016/j.patrec.2004.11.002
   Fexias M, 2014, LECT COMPUTER GRAPHI
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   Guo C., 2007, LECT NOTES COMPUT SC, V4830, P1611
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang DY, 2011, INT J INNOV COMPUT I, V7, P5631
   Huang DY, 2009, PATTERN RECOGN LETT, V30, P275, DOI 10.1016/j.patrec.2008.10.003
   Jalba AC, 2003, LECT NOTES COMPUT SC, V2756, P329
   Jeon J, 2004, LECT NOTES COMPUT SC, V3115, P24
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kuijper A, 2003, J MATH IMAGING VIS, V18, P169, DOI 10.1023/A:1022168617945
   Kumar S., 2012, Advances in Mechanical Engineering and its Applications, V2, P189
   Kushwaha NK, 2013, DEFENCE SCI J, V63, P298, DOI 10.14429/dsj.63.2737
   LEE SU, 1990, COMPUT VISION GRAPH, V52, P171, DOI 10.1016/0734-189X(90)90053-X
   Lei X, 2009, 2 D MAXIMUM ENTROPY, P161
   Liao PS, 2001, J INF SCI ENG, V17, P713
   Liscano R, 1995, P VIS INT QUEB CAN M, V95, P38
   Liu LJ, 2003, IEEE IMAGE PROC, P541
   NAKAGAWA Y, 1979, PATTERN RECOGN, V11, P191, DOI 10.1016/0031-3203(79)90006-2
   Navon E, 2005, IMAGE VISION COMPUT, V23, P69, DOI 10.1016/j.imavis.2004.05.011
   Noble JA, 2006, IEEE T MED IMAGING, V25, P987, DOI 10.1109/TMI.2006.877092
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal N, 1991, IEEE T SYST MAN CYB, V21, P5
   PEREZ A, 1987, IEEE T PATTERN ANAL, V9, P742, DOI 10.1109/TPAMI.1987.4767981
   Renyi A., 1961, P 4 BERK S MATH STAT, V1, P547
   Rigau J, 2004, LECT NOTES COMPUT SC, V3216, P135
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Shin YS, 2008, US Patent, Patent No. 10817551
   Suresh Manic K, 2016, INDIAN J SCI TECHNOL, V9, P1
   TAXT T, 1989, IEEE T PATTERN ANAL, V11, P1322, DOI 10.1109/34.41371
   Tsallis C, 2001, SPRINGER LECT NOTES
   Yanowitz SD, 1996, COMP VIS GRAPH IMAGE, V46, P82
   Zhang RB, 2006, FIRST INTERNATIONAL MULTI-SYMPOSIUMS ON COMPUTER AND COMPUTATIONAL SCIENCES (IMSCCS 2006), PROCEEDINGS, VOL 2, P360, DOI 10.1109/IMSCCS.2006.280
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 59
TC 6
Z9 7
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20889
EP 20915
DI 10.1007/s11042-017-5429-8
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300026
DA 2024-07-18
ER

PT J
AU Dhingra, G
   Kumar, V
   Joshi, HD
AF Dhingra, Gittaly
   Kumar, Vinay
   Joshi, Hem Dutt
TI Study of digital image processing techniques for leaf disease detection
   and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Image analysis; Plant leaf diseases; Feature
   extraction; Segmentation; Classifiers
ID CHLOROPHYLL FLUORESCENCE; IDENTIFICATION; COLOR
AB In this paper, we address a comprehensive study on disease recognition and classification of plant leafs using image processing methods. The traditional manual visual quality inspection cannot be defined systematically as this method is unpredictable and inconsistent. Moreover, it involves a remarkable amount of expertise in the field of plant disease diagnostics (phytopathology) in addition to the disproportionate processing times. Hence, image processing has been applied for the recognition of plant diseases. The paper has been divided into two main categories viz. detection and classification of leafs. A comprehensive discussion on the diseases detection and classification performance is presented based on analysis of previously proposed state of art techniques particularly from 1997 to 2016. Finally, discussed and classify the challenges and some prospects for future improvements in this space.
C1 [Dhingra, Gittaly; Kumar, Vinay; Joshi, Hem Dutt] Thapar Univ Patiala, Elect & Commun Engn Dept, Patiala 147001, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Dhingra, G (corresponding author), Thapar Univ Patiala, Elect & Commun Engn Dept, Patiala 147001, Punjab, India.
EM gittaly@thapar.edu; vinay.kumar@thapar.edu; hemdutt.joshi@thapar.edu
RI Kumar, Vinay/AAB-8186-2019
OI Kumar, Vinay/0000-0001-9086-4782
CR Abdullah N. E., 2007, 2007 5 STUD C RES DE
   Aduwo J. R., 2010, P ICDM WORKSH, P114
   Al Bashish D., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P113, DOI 10.1109/ICSIP.2010.5697452
   Al-Hiary H., 2011, International Journal of Computer Applications, V17, P31, DOI [10.5120/2183-2754, DOI 10.5120/2183-2754]
   Al-Tarawneh M. S., 2013, World Applied Sciences Journal, V23, P1207
   [Anonymous], 2013, P 2013 4 INT C COMPU
   [Anonymous], 2011, TARIM MAKINALARI BIL
   [Anonymous], 2012, World J. Sci. Technol.
   [Anonymous], P WORLD AUT C WAC PU
   Anthonys G, 2009, 2009 INTERNATIONAL CONFERENCE ON INDUSTRIAL AND INFORMATION SYSTEMS, P403, DOI 10.1109/ICIINFS.2009.5429828
   Arivazhagan S., 2013, Agricultural Engineering International: CIGR Journal, V15, P211
   Barbedo JGA, 2013, SPRINGERPLUS, V2, DOI 10.1186/2193-1801-2-660
   Asfarian A, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P77, DOI 10.1109/IC3INA.2013.6819152
   Asraf HM, 2012, PROCEDIA ENGINEER, V41, P1353, DOI 10.1016/j.proeng.2012.07.321
   Bandi R.S., 2013, International Journal of Engineering Science and Technology, V5, P298
   Bentley JW, 2009, FOOD SECUR, V1, P371, DOI 10.1007/s12571-009-0033-z
   Billah M., 2015, Commun. Appl. Electron, V3, P1, DOI [10.5120/cae2015651943, DOI 10.5120/CAE2015651943]
   Bin MohamadAzmi MT, 2013, 2013 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS AND SYSTEM ENGINEERING (ICEESE), P37, DOI 10.1109/ICEESE.2013.6895039
   Bos L., 1970, Symptoms of Virus Diseases in Plants
   Cai HY, 2014, VET PATHOL, V51, P341, DOI 10.1177/0300985813511132
   Camargo A, 2009, BIOSYST ENG, V102, P9, DOI 10.1016/j.biosystemseng.2008.09.030
   Chaerle L, 2007, J EXP BOT, V58, P773, DOI 10.1093/jxb/erl257
   Cunlou L, 2013, J INF COMPUT SCI, V8, P316
   Da-ke Wu, 2008, 2008 IEEE Conference on Cybernetics and Intelligent Systems, P147, DOI 10.1109/ICCIS.2008.4670815
   Devereux S, 2009, FOOD SECUR, V1, P25, DOI 10.1007/s12571-008-0005-8
   Dey AK, 2016, PROCEDIA COMPUT SCI, V85, P748, DOI 10.1016/j.procs.2016.05.262
   Dong P., 2013, OPEN J APPL SCI, V3, P27, DOI DOI 10.4236/OJAPPS.2013.31B006
   Es-Saady Y, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL AND INFORMATION TECHNOLOGIES (ICEIT), P561, DOI 10.1109/EITech.2016.7519661
   Eun AJC, 2002, J VIROL METHODS, V99, P71, DOI 10.1016/S0166-0934(01)00382-2
   Fang Y, 2014, ANALYST, V139, P3804, DOI 10.1039/c4an00384e
   Figueiredo AC, 2008, FLAVOUR FRAG J, V23, P213, DOI 10.1002/ffj.1875
   Flood J, 2010, FOOD SECUR, V2, P215, DOI 10.1007/s12571-010-0072-5
   Ghaiwat S N., 2014, International Journal of Recent Advances in Engineering Technology, V2, P2347
   González-Fernández R, 2010, J BIOMED BIOTECHNOL, DOI 10.1155/2010/932527
   Gui J., 2015, INT J MULTIMED UBIQU, V10, P45, DOI [10.14257/ijmue.2015.10.6.06, DOI 10.14257/IJMUE.2015.10.6.06]
   Guru DS, 2011, 4 ANN ACM BANG C BAN
   Haferkamp M. R., 1988, ACHIEVING EFFICIENT, P27
   Haiguang Wang, 2012, 2012 8th International Conference on Natural Computation, P246, DOI 10.1109/ICNC.2012.6234701
   He Q., 2013, TELKOMNIKA Indonesian Journal of Electrical Engineering, V11, P3445, DOI [10.11591/telkomnika.v11i6.2721, DOI 10.11591/TELKOMNIKA.V11I6.2721]
   Hitimana E, 2014, 2 INT C SIGN IM PROC
   Huang KY, 2007, COMPUT ELECTRON AGR, V57, P3, DOI 10.1016/j.compag.2007.01.015
   Husin Z. B., 2012, Proceedings of the 2012 3rd International Conference on Intelligent Systems, Modelling and Simulation (ISMS 2012), P291, DOI 10.1109/ISMS.2012.33
   Jagtap SB, 2014, IOSR Journal of VLSI and Signal Processing, V4, P24, DOI [DOI 10.9790/4200-04512430, 10.9790/4200-04512430]
   Jian Z, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 5, P264, DOI 10.1109/ICACC.2010.5487242
   Kavya RM., 2016, Inte J Adv Found Res Computer Pragmatic Rev, V3, P1
   Keskar PV, 2013, INT J EMERG TRENDS E, V2, P28
   Krishnan M, 2013, 2013 IEEE MALAYSIA INTERNATIONAL CONFERENCE ON COMMUNICATIONS (MICC), P474, DOI 10.1109/MICC.2013.6805876
   Kruse OMO, 2014, COMPUT ELECTRON AGR, V108, P155, DOI 10.1016/j.compag.2014.07.010
   Kuckenberg J, 2009, PRECIS AGRIC, V10, P34, DOI 10.1007/s11119-008-9082-0
   Kurniawati NN, 2009, 2009 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION, P272, DOI 10.1109/SoCPaR.2009.62
   Kutty SB, 2013, 2013 IEEE BUSINESS ENGINEERING AND INDUSTRIAL APPLICATIONS COLLOQUIUM (BEIAC 2013), P459
   Mahlein AK, 2016, PLANT DIS, V100, P241, DOI 10.1094/PDIS-03-15-0340-FE
   Majid K, 2013, INT C ADV COMP SCI I, P403, DOI 10.1109/ICACSIS.2013.6761609
   Martinez A, 2007, U GEORGIA COOPERATIV
   Massi I.E., 2015, IEEE 3 WORLD C COMPL, P1
   Meunkaewjinda A, 2008, ECTI-CON 2008: PROCEEDINGS OF THE 2008 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P513, DOI 10.1109/ECTICON.2008.4600483
   Mohan KJ., 2016, INT J COMPUT APPL, V144, P34, DOI DOI 10.5120/IJCA2016910505
   Mokhtar U, 2015, 2015 11TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO), P246, DOI 10.1109/ICENCO.2015.7416356
   Molina J F, 2014, 19 IEEE S IM SIGN PR, P1
   Mondal Dhiman, 2015, 2015 International Conference on Soft Computing Techniques and Implementations (ICSCTI), P166, DOI 10.1109/ICSCTI.2015.7489626
   Muthukannan K., 2014, INT J COMPUT INF ENG, V8, P2103, DOI [10.5281/zenodo.1107427, DOI 10.5281/ZENODO.1107427]
   Muthukannan K, 2015, IMAGE ANAL STEREOL, V34, P209, DOI 10.5566/ias.1227
   Narvekar P.R., 2014, INT J INNOVATIVE RES, V2, P3365, DOI 10.21090/ijaerd.01099
   Orillo J. W., 2014, P INT C HUM NAN INF, P1
   Phadikar Santanu, 2008, 2008 11th International Conference on Computer and Information Technology (ICCIT), P420, DOI 10.1109/ICCITECHN.2008.4803079
   Phadikar S, 2013, COMPUT ELECTRON AGR, V90, P76, DOI 10.1016/j.compag.2012.11.001
   Pydipati R, 2006, COMPUT ELECTRON AGR, V52, P49, DOI 10.1016/j.compag.2006.01.004
   Qin F, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168274
   Rangaswami G., 1998, DIS CROP PLANTS INDI
   Ratnasari Evy Kamilah, 2014, 2014 International Conference on Information, Communication Technology and System (ICTS). Proceedings, P93, DOI 10.1109/ICTS.2014.7010564
   Revathi P., 2014, Int. J. Eng. Sci. Technol., V3, P22
   Revathi P., 2012, P 2012 INT C EM TREN, P169
   Sabrol H., 2015, International Journal of Computer Applications, V126, P44, DOI DOI 10.5120/IJCA2015905982
   Sekulska-Nalewajko J., 2011, 2011 VII-th International Conference on Perspective Technologies and Methods in MEMS Design (MEMSTECH), P172
   Sena DG, 2003, BIOSYST ENG, V85, P449, DOI 10.1016/S1537-5110(03)00098-9
   Shen Weizheng, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P491, DOI 10.1109/CSSE.2008.1649
   Shrivastava S, 2015, MULTIMED TOOLS APPL, V74, P11467, DOI 10.1007/s11042-014-2239-0
   Singh DV, 1950, T BR MYCOL SOC, V33, P154
   Song Kai, 2011, 2011 International Conference on Measuring Technology and Mechatronics Automation (ICMTMA), P246, DOI 10.1109/ICMTMA.2011.66
   SURENDRABABU V, 2014, INT J COMPUT SCI ENG, V6, P69
   Tajane V., 2014, INT J ADV RES COMPUT, V4, P530
   Thresh JM, 2004, VIRUS AND VIRUS-LIKE DISEASES OF MAJOR CROPS IN DEVELOPING COUNTRIES, P1
   Tian YW, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P262, DOI 10.1109/CISP.2008.29
   Tucker CC, 1997, J PHYTOPATHOL, V145, P273, DOI 10.1111/j.1439-0434.1997.tb00400.x
   Vijesekara HMSS., 2015, INT J SCI TECHNOL RE, V4, P215
   Ward E, 2004, ANN APPL BIOL, V145, P1, DOI 10.1111/j.1744-7348.2004.tb00354.x
   Yunpeng, 2013, J THEOR APPL INF TEC, V48, P527
   Zhang M, 2011, PATTERN RECOGN LETT, V32, P2036, DOI 10.1016/j.patrec.2011.08.003
   Zhang SW, 2016, NEUROCOMPUTING, V205, P341, DOI 10.1016/j.neucom.2016.04.034
   Zhang SW, 2013, 2013 9TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P241, DOI 10.1109/CIS.2013.57
   Zhang WD, 2013, OPTIK, V124, P1034, DOI 10.1016/j.ijleo.2013.01.014
   Zhang Z., 2014, SENSORS TRANSDUCERS, V166, P181
   Zhou R, 2013, 7 INT C AGR BIOT BIO, P204
NR 93
TC 85
Z9 88
U1 3
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19951
EP 20000
DI 10.1007/s11042-017-5445-8
PG 50
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500048
DA 2024-07-18
ER

PT J
AU Lakehal, E
   Ziou, D
AF Lakehal, Elkhamssa
   Ziou, Djemel
TI Computational color constancy from maximal projections mean assumption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computational color constancy; Scene illuminant estimation; Dichromatic
   model; Orthogonal projections; Principal component analysis
ID ILLUMINANT ESTIMATION; CHROMATICITY; IMAGES; MODEL
AB In this paper, we propose an efficient algorithm for illuminant estimation. The 2D estimator is derived based on the maximal projections' mean assumption according to which the estimated illuminant in a chromaticity subspace is the vector maximizing the sum of orthogonal projections of image colors. We show that, the illuminant estimation solution is the eigenvector corresponding to the maximal eigenvalue of the inner-product matrix of data. The 2D estimator is extended to the 3D space by minimizing the reconstruction errors from the 2D estimates obtained in the RGB color space. The evaluation of the 3D resulting estimator on three well-known image datasets generates lower estimation errors.
C1 [Lakehal, Elkhamssa] Univ Batna 2, Fac Math & Informat, LAMIE Lab, LAMIE, Fesdis Batna 05110, Algeria.
   [Ziou, Djemel] Univ Sherbrooke, Dept Informat, Sherbrooke, PQ, Canada.
C3 University of Batna 2; University of Sherbrooke
RP Lakehal, E (corresponding author), Univ Batna 2, Fac Math & Informat, LAMIE Lab, LAMIE, Fesdis Batna 05110, Algeria.
EM lakehal_elkhamssa@yahoo.fr; Djemel.Ziou@USherbrooke.ca
CR [Anonymous], 1978, COMPUTER VISION SYST
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587765
   [Anonymous], 2010, Re-processed version of the Gehler color constancy dataset of 568 images
   Barnard K, 2002, COLOR RES APPL, V27, P147, DOI 10.1002/col.10049
   Bianco S, 2014, IEEE T PATTERN ANAL, V36, P1505, DOI 10.1109/TPAMI.2013.2297710
   Bianco S, 2012, LECT NOTES COMPUT SC, V7585, P623, DOI 10.1007/978-3-642-33885-4_67
   Brainard DH, 1997, J OPT SOC AM A, V14, P1393, DOI 10.1364/JOSAA.14.001393
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Cardei VC, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P311
   Cardei VC, 2002, J OPT SOC AM A, V19, P2374, DOI 10.1364/JOSAA.19.002374
   Chakrabarti A., 2008, 2008 IEEE C COMPUTER, P1
   Ciurea F, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P160
   Drew MS, 2014, COMPUT VIS IMAGE UND, V127, P1, DOI 10.1016/j.cviu.2014.07.002
   Elfiky N, 2014, IEEE T IMAGE PROCESS, V23, P3855, DOI 10.1109/TIP.2014.2336545
   Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113
   Finlayson GD, 2006, INT J COMPUT VISION, V67, P93, DOI 10.1007/s11263-006-4100-z
   Finlayson GD, 2004, LECT NOTES COMPUT SC, V3023, P582
   Finlayson GD, 2001, INT J COMPUT VISION, V42, P127, DOI 10.1023/A:1011120214885
   Finlayson GD, 2004, SHADES GRAY COLOUR C, P37
   FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770
   Funt B, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P47
   Gijsenij A., 2007, IEEE Conference on Computer Vision and Pattern Recognition(CVPR), P1
   Gijsenij A, 2012, IEEE T IMAGE PROCESS, V21, P697, DOI 10.1109/TIP.2011.2165219
   Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224
   Gijsenij A, 2011, IEEE T PATTERN ANAL, V33, P687, DOI 10.1109/TPAMI.2010.93
   Gijsenij A, 2009, PROC CVPR IEEE, P581, DOI 10.1109/CVPRW.2009.5206497
   HEALEY G, 1989, J OPT SOC AM A, V6, P920, DOI 10.1364/JOSAA.6.000920
   HEALEY G, 1991, IMAGE VISION COMPUT, V9, P333, DOI 10.1016/0262-8856(91)90038-Q
   Hordley SD, 2006, COLOR RES APPL, V31, P303, DOI 10.1002/col.20226
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jenssen R, 2013, IEEE T NEUR NET LEAR, V24, P1553, DOI 10.1109/TNNLS.2013.2262774
   Joze HRV, 2012, COLOR IMAG CONF, P41
   Kerouh F, 2016, IVAPP LECT NOTES COM
   Lakehal E, 2016, LECT NOTES COMPUT SC, V9680, P148, DOI 10.1007/978-3-319-33618-3_16
   Land EH., 1977, The retinex theory of color vision
   LEE HC, 1986, J OPT SOC AM A, V3, P1694, DOI 10.1364/JOSAA.3.001694
   LEE HC, 1990, IEEE T PATTERN ANAL, V12, P402, DOI 10.1109/34.50626
   Lu R, 2009, IEEE I CONF COMP VIS, P1749, DOI 10.1109/ICCV.2009.5459391
   Lu R, 2009, IEEE IMAGE PROC, P685, DOI 10.1109/ICIP.2009.5414083
   MACADAM DL, 1956, J OPT SOC AM, V46, P500, DOI 10.1364/JOSA.46.000500
   Mazin B, 2015, IEEE T IMAGE PROCESS, V24, P1944, DOI 10.1109/TIP.2015.2405414
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Pillai SU, 2005, IEEE SIGNAL PROC MAG, V22, P62, DOI 10.1109/MSP.2005.1406483
   Rosenberg C., 2003, ADV NEURAL INFORM PR
   Schaefer G, 2005, PROC CVPR IEEE, P148
   Schaefer G, 2004, LECT NOTES COMPUT SC, V3212, P257
   SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409
   Shi Lilong., 2008, Conference on Colour in Graphics, Imaging, and Vision, V1, P259
   TOMINAGA S, 1989, J OPT SOC AM A, V6, P576, DOI 10.1364/JOSAA.6.000576
   Toro J, 2008, PATTERN RECOGN LETT, V29, P871, DOI 10.1016/j.patrec.2008.01.004
   Vaezi Joze H., 2014, IEEE T PATTERN ANAL, V36, P860
   Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808
   Von Kries Johann., 1905, HDB PHYSL MENSCHEN
   Yoon KJ, 2006, IEEE IMAGE PROC, P973, DOI 10.1109/ICIP.2006.312650
   Yuan XS, 2013, OPT REV, V20, P348, DOI 10.1007/s10043-013-0063-9
NR 55
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20501
EP 20517
DI 10.1007/s11042-017-5476-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300009
DA 2024-07-18
ER

PT J
AU Majid, M
   Owais, M
   Anwar, SM
AF Majid, Muhammad
   Owais, Muhammad
   Anwar, Syed Muhammad
TI Visual saliency based redundancy allocation in HEVC compatible multiple
   description video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple description coding; HEVC; Visual saliency model; Error
   resilience; Motion interpolation
ID TRANSMISSION
AB Video delivery over error prone channels suffer from packet loss, which significantly deteriorates the reconstructed video quality. Multiple description coding (MDC) is an effective error resilient coding scheme for transmission of video over unreliable networks, where video is encoded into multiple descriptions having redundancy between them. The amount of redundancy between these descriptions has an important role in MDC, because it provides error resilience. In this paper, a new redundancy allocation scheme using visual saliency model is presented with an aim of achieving high decoding quality, when one or more than one descriptions are received at the decoder. The proposed MDC method splits the input video sequence into even and odd subsequences, which are independently encoded by using high efficiency video coding (HEVC) encoder. The missing frames in each description are predicted by using pixel interpolation and motion interpolation. The residual information is generated by using the interpolated frame and its adjacent frame from the other description, which represents the redundancy in each description. Residual information is encoded based on a visual saliency mask, which is generated using a global contrast based visual saliency model. In this work, two different modes are proposed for visual saliency based redundancy allocation to provide better perceptual quality, while decoding the descriptions. The proposed scheme is implemented on HEVC reference software HM 16.2 and compared with two state-of-the-art temporal subsampling based multiple description video coding methods. Experiments show that the proposed method performs better than the reference methods, both in lossless and packet erasure channel conditions.
C1 [Majid, Muhammad; Owais, Muhammad] Univ Engn & Technol, Dept Comp Engn, Taxila, Pakistan.
   [Anwar, Syed Muhammad] Univ Engn & Technol, Dept Software Engn, Taxila, Pakistan.
C3 University of Engineering & Technology Taxila; University of Engineering
   & Technology Taxila
RP Majid, M (corresponding author), Univ Engn & Technol, Dept Comp Engn, Taxila, Pakistan.
EM m.majid@uettaxila.edu.pk; malikowais256@gmail.com;
   s.anwar@uettaxila.edu.pk
RI Owais, Muhammad/AAT-1573-2021; Owais, Muhammad/AFC-7124-2022; anwar,
   syed/AGY-3965-2022; Majid, Muhammad/Z-5667-2019
OI Owais, Muhammad/0000-0001-7679-081X; Owais,
   Muhammad/0000-0001-7679-081X; anwar, syed/0000-0002-8179-3959; Majid,
   Muhammad/0000-0003-3662-2525
CR Adedoyin S, 2008, IEEE T CONSUM ELECTR, V54, P2045, DOI 10.1109/TCE.2008.4711271
   Bai HH, 2014, IEEE T CIRC SYST VID, V24, P1390, DOI 10.1109/TCSVT.2014.2315770
   Chen J, 2016, MULTIMED TOOLS APPL, V75, P2801, DOI 10.1007/s11042-015-2546-0
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Choupani R, 2014, MULTIMED TOOLS APPL, V69, P843, DOI 10.1007/s11042-012-1150-9
   Chung DM, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P664, DOI 10.1109/ICIP.1998.723586
   Crave O, 2010, IEEE T CIRC SYST VID, V20, P769, DOI 10.1109/TCSVT.2010.2045805
   Franchi N, 2005, IEEE T CIRC SYST VID, V15, P321, DOI 10.1109/TCSVT.2004.842606
   Frank B., 2014, HEVC REFERENCE SOFTW
   Ghahremani S, 2017, MULTIMED TOOLS APPL, V76, P9033, DOI 10.1007/s11042-016-3471-6
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Goyal VK, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P674, DOI 10.1109/ICIP.1998.723588
   Hellge C, 2011, IEEE T MULTIMEDIA, V13, P551, DOI 10.1109/TMM.2011.2129499
   Heng B. A., 2006, EURASIP J APPL SIG P, V2006, P261
   Huo YK, 2015, IEEE COMMUN SURV TUT, V17, P1166, DOI 10.1109/COMST.2015.2392378
   Huo YK, 2013, IEEE T CIRC SYST VID, V23, P1622, DOI 10.1109/TCSVT.2013.2254911
   Huo YK, 2013, IEEE T VEH TECHNOL, V62, P1597, DOI 10.1109/TVT.2012.2227072
   Karim HA, 2008, IEEE T CONSUM ELECTR, V54, P745, DOI 10.1109/TCE.2008.4560156
   Kazemi M, 2015, SIGNAL PROCESS-IMAGE, V36, P95, DOI 10.1016/j.image.2015.06.006
   Kim CK, 2016, J REAL-TIME IMAGE PR, V12, P257, DOI 10.1007/s11554-015-0503-9
   Kim K, 2006, SIGNAL PROCESS-IMAGE, V21, P293, DOI 10.1016/j.image.2005.11.002
   Lin CY, 2011, IEEE T CIRC SYST VID, V21, P589, DOI 10.1109/TCSVT.2011.2129270
   Majid Muhammad, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P2268
   Majid Muhammad, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P286, DOI 10.1109/PCS.2010.5702488
   Majid M, 2009, IS T SPIE ELECT IMAG
   Majid M, 2012, IET C IM PROC IPR
   Majid M, 2012, SIGNAL PROCESS-IMAGE, V27, P496, DOI 10.1016/j.image.2012.02.011
   Servetto SD, 2000, IEEE T IMAGE PROCESS, V9, P813, DOI 10.1109/83.841528
   Stephan W., 1999, SG16 ITUT RED BANK, P2004
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun G, 2007, P IEEE INT C IM PROC, P513
   Tillo T, 2008, IEEE T CIRC SYST VID, V18, P59, DOI 10.1109/TCSVT.2007.913751
   Vaishampayan V., 1996, Proceedings of the 7th International Packet Video Workshop, P55
   VAISHAMPAYAN VA, 1993, IEEE T INFORM THEORY, V39, P821, DOI 10.1109/18.256491
   Verdicchio F, 2006, IEEE T IMAGE PROCESS, V15, P3114, DOI 10.1109/TIP.2006.877495
   Wang Y, 1997, 1997 IEEE FIRST WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P419, DOI 10.1109/MMSP.1997.602671
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   Wang Y, 2001, IEEE T IMAGE PROCESS, V10, P351, DOI 10.1109/83.908500
   Wu JY, 2015, IEEE T COMMUN, V63, P3584, DOI 10.1109/TCOMM.2015.2469296
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Xu YY, 2013, IEEE T CIRC SYST VID, V23, P1523, DOI 10.1109/TCSVT.2013.2249018
   Yang ML, 2016, SIGNAL PROCESS-IMAGE, V47, P313, DOI 10.1016/j.image.2016.05.014
   Zhang MM, 2012, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2012-265
NR 44
TC 13
Z9 14
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20955
EP 20977
DI 10.1007/s11042-017-5499-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300029
DA 2024-07-18
ER

PT J
AU Mihajlovic, Z
   Popovic, S
   Brkic, K
   Cosic, K
AF Mihajlovic, Zeljka
   Popovic, Sinisa
   Brkic, Karla
   Cosic, Kresimir
TI A system for head-neck rehabilitation exercises based on serious gaming
   and virtual reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serious game; Virtual reality; Neck; Exercise
ID WHIPLASH INJURY; PAIN; THERAPY; SPINE; BACK; INTERVENTIONS; ENVIRONMENT;
   DISORDERS; SHOULDER; MOTION
AB Acute and chronic neck pain are common medical conditions, and the treatment typically includes physical therapy involving daily exercises. Insufficient motivation of people afflicted with neck pain to adhere to the prescribed exercise regimen may delay their recovery. Accordingly, in this work, we propose a system that motivates the users to perform neck exercises by engaging them in a serious exergame within virtual reality (VR) environment. The system measures the users' neck movements via a few static and dynamic kinematic tests and a novel VR serious game, tailored to the neck range of motion of each individual user. The game is designed to make the users perform rehabilitative neck movements according to the prescribed exercise regimen while playing. The analysis of acquired data from VR hardware provides insight into flexibility of the neck during head movements and overall neck kinematics, which is valuable for assessment of pain-related stiffness, as well as for progress monitoring. In a user study performed with the proposed system and the Oculus Rift DK2 VR headset, we show that the users find exercising more interesting and engaging when using the proposed system, and that introducing visually rich VR environments makes the users more motivated to continue exercising.
C1 [Mihajlovic, Zeljka; Popovic, Sinisa; Brkic, Karla; Cosic, Kresimir] Univ Zagreb, Fac Elect Engn & Comp, Linska 3, HR-10000 Zagreb, Croatia.
C3 University of Zagreb
RP Mihajlovic, Z (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Linska 3, HR-10000 Zagreb, Croatia.
EM zeljka.mihajlovic@fer.hr; sinisa.popovic@fer.hr; karla.brkic@fer.hr;
   kresimir.cosic@fer.hr
RI Mihajlovic, Zeljka/KLZ-8450-2024; Popović, Siniša/ABZ-3508-2022
OI Mihajlovic, Zeljka/0000-0002-4866-1399; Popović,
   Siniša/0000-0001-6026-9261
CR Althoff T, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.6759
   [Anonymous], 2013, J ORTHOP SPORT PHYS, V43, P128, DOI 10.2519/jospt.2013.0502
   [Anonymous], P INT C MOB UB SYST
   Bahat HS, 2015, MANUAL THER, V20, P295, DOI 10.1016/j.math.2014.10.002
   Bahat HS, 2010, ARCH PHYS MED REHAB, V91, P1884, DOI 10.1016/j.apmr.2010.09.007
   Bassett SF., 2003, NZ J PHYSIOTHERAPY, V31, P60
   Blanpied Peter R, 2017, J Orthop Sports Phys Ther, V47, pA1, DOI 10.2519/jospt.2017.0302
   Bronfort G, 2001, SPINE, V26, P788, DOI 10.1097/00007632-200104010-00020
   BUCKWALTER JA, 1995, SPINE, V20, P1307, DOI 10.1097/00007632-199506000-00022
   Cameirao MS, 2010, J NEUROENG REHABIL, V7, DOI 10.1186/1743-0003-7-48
   Chen KB, 2017, IEEE T NEUR SYS REH, V25, P1240, DOI 10.1109/TNSRE.2016.2621886
   Childs JD, 2008, J ORTHOP SPORT PHYS, V38, pA1, DOI 10.2519/jospt.2008.0303
   Childs MJD, 2004, J ORTHOP SPORT PHYS, V34, P686, DOI 10.2519/jospt.2004.34.11.686
   Cohen SP, 2015, MAYO CLIN PROC, V90, P284, DOI 10.1016/j.mayocp.2014.09.008
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   Cosic K, 2002, VISION MODELING, AND VISUALIZATION 2002, PROCEEDINGS, P35
   Dall'Alba PT, 2001, SPINE, V26, P2090, DOI 10.1097/00007632-200110010-00009
   DeFrate LE, 1999, ASME SUMM BIOENG C 1
   Deponti D, 2011, P IEEE INT C SER GAM
   Ding M, 2016, IEEE T IMAGE PROCESS, V25, P776, DOI 10.1109/TIP.2015.2507445
   Sucar LE, 2014, IEEE T NEUR SYS REH, V22, P634, DOI 10.1109/TNSRE.2013.2293673
   Escolar-Reina P, 2010, BMC HEALTH SERV RES, V10, DOI 10.1186/1472-6963-10-60
   Eubanks JD, 2010, AM FAM PHYSICIAN, V81, P33
   Gaggi O, 2016, MULTIMED TOOLS APPL, V75, P3453, DOI 10.1007/s11042-014-2444-x
   Gormley J, 2005, EXERCISE THERAPY PRE, P228
   Hakala PT, 2006, EUR J PUBLIC HEALTH, V16, P536, DOI 10.1093/eurpub/ckl025
   Haneline MT, 2009, J CHIROPR MED, V8, P119, DOI 10.1016/j.jcm.2009.04.001
   Hurwitz EL, 2009, J MANIP PHYSIOL THER, V32, pS141, DOI 10.1016/j.jmpt.2008.11.017
   Kasch H, 2001, NEUROLOGY, V56, P1637, DOI 10.1212/WNL.56.12.1637
   Keilhauer E, 1998, United States patent, patent number, Patent No. [5,727,267, 5727267]
   Kim H, 2013, EVID-BASED COMPL ALT, V2013, DOI 10.1155/2013/570428
   Kramer M, 2008, J ELECTROMYOGR KINES, DOI [10.1016/jelekin.2008.05.005, DOI 10.1016/JELEKIN.2008.05.005]
   Kristjansson E, 2004, ARCH PHYS MED REHAB, V85, P490, DOI 10.1016/S0003-9993(03)00619-1
   Linton SJ, 2001, SPINE, V26, P778, DOI 10.1097/00007632-200104010-00019
   Love S., 1998, J CANADIAN CHIROPRAC, V42, P222
   Mihajlovic Zeljka, 2015, International Journal of Computers and Applications, V37, P53, DOI 10.1080/1206212X.2015.1079955
   Mihajlovic Z, 2012, INT J ENG EDUC, V28, P1127
   Murphy S, 2004, APPL ERGON, V35, P113, DOI 10.1016/j.apergo.2004.01.001
   SAKAKIBARA H, 1995, ERGONOMICS, V38, P700, DOI 10.1080/00140139508925141
   Sarig-Bahat H, 2003, MANUAL THER, V8, P10, DOI 10.1054/math.2002.0480
   Schonauer C., 2011, INT C VIRT REH ICVR, P1, DOI DOI 10.1109/ICVR.2011.5971855
   Sial AB, 2016, J SPORTS PHYS ED, V3, P66, DOI [10.9790/6737-03046687, DOI 10.9790/6737-03046687]
   Sjölander P, 2008, MANUAL THER, V13, P122, DOI 10.1016/j.math.2006.10.002
   Sterling M, 2003, PAIN, V103, P65, DOI 10.1016/S0304-3959(02)00420-7
   Xu X, 2015, J BIOMECH, V48, P721, DOI 10.1016/j.jbiomech.2015.01.005
   Ylinen J, 2007, Eura Medicophys, V43, P119
   Ylinen J, 2007, J REHABIL MED, V39, P126, DOI 10.2340/16501977-0015
NR 47
TC 21
Z9 22
U1 3
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19113
EP 19137
DI 10.1007/s11042-017-5328-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500011
DA 2024-07-18
ER

PT J
AU Nikzad, M
   Bohlooli, A
   Jamshidi, K
AF Nikzad, Mortaza
   Bohlooli, Ali
   Jamshidi, Kamal
TI Performance evaluation of error control schemes for distributed video
   coding over wireless multimedia sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed video coding; Error control; Wireless multimedia sensor
   networks
ID SURVEILLANCE; INFORMATION; MANAGEMENT; ALGORITHM; CHANNELS; ENERGY
AB Distributed Video Coding (DVC) is a new approach in video coding which due to low computational complexity at the encoder side, has a great potential to be used in Wireless Multimedia Sensor Networks (WMSN). However, the different architecture of this codec affects the efficiency of transmission protocols and in order to efficient transmission of DVC over WMSN, it is necessary to evaluate the performance of the transmission protocols in the presence of DVC characteristics. In the view of these protocols, error control methods are important mechanisms that provide quality of service and robust multimedia communications. For this reason, we performed a comparative performance analysis for all error control schemes that consist of Automatic Repeat Request (ARQ), Forward Error Correction (FEC), Erasure Coding (EC), hybrid link layer ARQ/FEC and multi-layer hybrid error control schemes for DVC in WMSNs. These analyses are in the terms of the most importance metrics in multimedia communications over WSNs, such as objective and subjective video quality criteria, delay, energy consumption and some DVC-specific metrics. The results show the distinct behavior of DVC in the presence of channel error and can be used to propose an effective and efficient error control scheme for DVC over WMSN.
C1 [Nikzad, Mortaza; Bohlooli, Ali; Jamshidi, Kamal] Univ Isfahan, Fac Comp Engn, Esfahan, Iran.
C3 University of Isfahan
RP Bohlooli, A (corresponding author), Univ Isfahan, Fac Comp Engn, Esfahan, Iran.
EM mrtz_azad@eng.ui.ac.ir; Bohlooli@eng.ui.ac.ir; Jamshidi@eng.ui.ac.ir
RI Bohlooli, Ali/ABG-4510-2021
OI Bohlooli, Ali/0000-0003-2678-8281; Nikzad, Mortaza/0000-0001-7318-8954
CR Aaron A, 2004, PROC SPIE, V5308, P520, DOI 10.1117/12.527204
   Aaron A, 2002, CONF REC ASILOMAR C, P240
   Altaf MFM, 2009, 5 INT ICST MOB MULT
   [Anonymous], 2010, WIRELESS SENSOR NETW
   [Anonymous], 2007, 2007 IEEE INT C MOB, DOI DOI 10.1109/MOBHOC.2007.4428620
   Arabi K, 2016, J CHIN INST ENG, V39, P493, DOI 10.1080/02533839.2015.1125793
   ARTIGAS X, 2007, PICT COD S LISB PORT, V6, P14496
   Blackard K. L., 1991, ICC 91. International Conference on Communications Conference Record (Cat. No.91CH2984-3), P28, DOI 10.1109/ICC.1991.162330
   Bohlooli A, 2012, APPL INTELL, V36, P685, DOI 10.1007/s10489-011-0289-9
   Chiasserini CF, 2004, TELECOMMUN SYST, V26, P369, DOI 10.1023/B:TELS.0000029047.09283.d2
   Chlamtac I, 1998, NINTH IEEE INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS, VOLS 1-3, P836, DOI 10.1109/PIMRC.1998.734680
   Du H., 2015, J INF SCI ENG
   Duchamp D., 1992, Proceedings. 17th Conference on Local Computer Networks (Cat. No.92TH0473-9), P494, DOI 10.1109/LCN.1992.228152
   Ghasemi M, 2015, AD HOC NETW, V25, P472, DOI 10.1016/j.adhoc.2014.08.013
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   González S, 2016, AD HOC NETW, V52, P89, DOI 10.1016/j.adhoc.2016.07.007
   Hajian E., 2010, 2010 International Conference on Information, Networking and Automation (ICINA 2010), P215, DOI 10.1109/ICINA.2010.5636403
   Hajian E., 2010, International Journal of Ad hoc, Sensor Ubiquitous Computing, V1, P1
   Imran N, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1300-4
   Jin Y, 2008, 2004 4 IEEE INT C CI, P90
   Kambhatla KKR, 2016, MULTIMED TOOLS APPL, V75, P3235, DOI 10.1007/s11042-014-2432-1
   Kim S, 2004, 2004 FIRST ANNUAL IEEE COMMUNICATIONS SOCIETY CONFERENCE ON SENSOR AND AD HOC COMMUNICATIONS AND NETWORKS, P449, DOI 10.1109/SAHCN.2004.1381947
   Kokkonis G, 2017, J SUPERCOMPUT, V73, P1044, DOI 10.1007/s11227-016-1769-9
   Kokkonis G, 2016, J REAL-TIME IMAGE PR, V12, P343, DOI 10.1007/s11554-015-0505-7
   Lin S., 1983, Error Control Coding: Fundamentals and Applications
   Liu B, 2008, IEEE ICC, P4407, DOI 10.1109/ICC.2008.827
   Memos VA, 2016, J REAL-TIME IMAGE PR, V12, P473, DOI 10.1007/s11554-015-0509-3
   Monteiro N, 2016, INT CONF ACOUST SPEE, P2807, DOI 10.1109/ICASSP.2016.7472189
   MUSHKIN M, 1989, IEEE T INFORM THEORY, V35, P1277, DOI 10.1109/18.45284
   Naderi MY, 2012, AD HOC NETW, V10, P1028, DOI 10.1016/j.adhoc.2012.01.003
   Nikzad Mortaza, 2014, International Journal of Information Technology and Computer Science, V7, P12, DOI 10.5815/ijitcs.2015.01.02
   Perkins C., 2003, AD HOC ON DEMAND DIS, DOI [DOI 10.17487/RFC3561, 10.17487/RFC3561]
   Pierre Ebert J, 1999, TKN99002 TU BERL
   Psannis KE, 2006, IEEE T CIRC SYST VID, V16, P280, DOI 10.1109/TCSVT.2005.859933
   Psannis K, 2009, IEICE ELECTRON EXPR, V6, P1497, DOI [10.1587/elex.6.1497, 10.1587/elex.6.1437]
   Psannis K, 2008, IEICE ELECTRON EXPR, V5, P827, DOI 10.1587/elex.5.827
   Psannis KE, 2006, EURASIP J WIREL COMM, DOI 10.1155/WCN/2006/24616
   Psannis KE, 2016, J REAL-TIME IMAGE PR, V12, P509, DOI 10.1007/s11554-015-0514-6
   Psannis KE, 2009, TELECOMMUN SYST, V41, P65, DOI 10.1007/s11235-009-9151-3
   Puri R., 2002, C COMM CONTR COMP AL, P1
   Puri R, 2003, P IEEE INT C IM PROC, V1, P617
   Sankarasubramaniam Y, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL WORKSHOP ON SENSOR NETWORK PROTOCOLS AND APPLICATIONS, P1, DOI 10.1109/SNPA.2003.1203351
   Sarvi B, 2017, AD HOC NETW, V56, P173, DOI 10.1016/j.adhoc.2016.12.008
   Shaheen S, 2017, MULTIMED TOOLS APPL, V76, P6663, DOI 10.1007/s11042-016-3308-3
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Tonoli C, 2009, J IMAGE VIDEO PROCES, V2009, P144
   UC Berkeley LBL USC/ ISI and Xerox PARC, NETW SIM NS 2 VINT P
   Vuran MC, 2009, IEEE ACM T NETWORK, V17, P1186, DOI 10.1109/TNET.2008.2009971
   Wang HS, 1996, IEEE T VEH TECHNOL, V45, P353, DOI 10.1109/25.492909
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Yong Jin, 2008, 2008 4th International Conference on Circuits and Systems for Communications, P90
NR 52
TC 4
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19547
EP 19568
DI 10.1007/s11042-017-5397-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500030
DA 2024-07-18
ER

PT J
AU Ren, FJ
   Li, YQ
   Hu, M
AF Ren, Fuji
   Li, Yanqiu
   Hu, Min
TI Multi-classifier ensemble based on dynamic weights
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic weights; Multi-classifier ensemble; Reliability; Decision
   credibility; Face recognition
ID LOCAL GRADIENT PATTERNS; FACE RECOGNITION; FEATURE-SELECTION; FUSION
AB In this study, a novel multi-classifier ensemble method based on dynamic weights is proposed to reduce the interference of unreliable decision information and improve the accuracy of fusion decision. The algorithm defines decision credibility to describe the real-time importance of the classifier to the current target, combines this credibility with the reliability calculated by the classifier on the training data set and dynamically assigns the fusion weight to the classifier. Compared with other methods, the contribution of different classifiers to fusion decision in acquiring weights is fully evaluated in consideration of the capability of the classifier to not only identify different sample regions but also output decision information when identifying specific targets. Experimental results on public face databases show that the proposed method can obtain higher classification accuracy than that of single classifier and some popular fusion algorithms. The feasibility and effectiveness of the proposed method are verified.
C1 [Ren, Fuji; Li, Yanqiu; Hu, Min] Hefei Univ Technol, Anhui Prov Key Lab Affect Comp & Adv Intelligent, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
   [Ren, Fuji] Univ Tokushima, Grad Sch Adv Technol & Sci, Tokushima 7708502, Japan.
C3 Hefei University of Technology; Tokushima University
RP Li, YQ (corresponding author), Hefei Univ Technol, Anhui Prov Key Lab Affect Comp & Adv Intelligent, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
EM liyanqiu2012@163.com
RI li, xiaomin/KCX-9845-2024; Hu, Min/HLH-2112-2023
FU National Natural Science Foundation of China [61432004, 61672202,
   61502141]; JSPS KAKENHI [15H01712]
FX This research has been partially supported by National Natural Science
   Foundation of China under Grant Nos. 61432004, 61672202 and 61502141 and
   by JSPS KAKENHI under Grant No. 15H01712.
CR Abdullah MFA, 2014, EXPERT SYST APPL, V41, P6131, DOI 10.1016/j.eswa.2014.04.006
   Abusham EEA, 2011, LECT NOTES COMPUT SC, V6762, P169
   [Anonymous], 2015, P 24 INT JOINT C
   [Anonymous], 2016, ARXIV161009462
   [Anonymous], IEEE INT C CLOUD COM
   [Anonymous], PERF COMP COMM C IEE
   Ban Y, 2014, PATTERN RECOGN, V47, P1573, DOI 10.1016/j.patcog.2013.11.005
   Bejani M, 2014, NEURAL COMPUT APPL, V24, P399, DOI 10.1007/s00521-012-1228-3
   Bhimani J, 2017, IEEE IPCCC
   Chakraborti T, 2014, ENG APPL ARTIF INTEL, V33, P80, DOI 10.1016/j.engappai.2014.04.006
   Chen Bo, 2015, Journal of Huazhong University of Science and Technology (Natural Science Edition), V43, P79, DOI 10.13245/j.hust.150316
   Cheon YJ, 2009, PATTERN RECOGN, V42, P1340, DOI 10.1016/j.patcog.2008.10.010
   CHO SB, 1995, IEEE T SYST MAN CYB, V25, P380, DOI 10.1109/21.364825
   Codella Noel, 2015, Machine Learning in Medical Imaging. 6th International Workshop, MLMI 2015, held in conjunction with MICCAI 2015. Proceedings: LNCS 9352, P118, DOI 10.1007/978-3-319-24888-2_15
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dai J, 2017, INT C CLOUD COMP BIG
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Eleftheriadis S, 2015, IEEE T IMAGE PROCESS, V24, P189, DOI 10.1109/TIP.2014.2375634
   Fröba B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P91, DOI 10.1109/AFGR.2004.1301514
   Guo KH, 2011, EXPERT SYST APPL, V38, P13360, DOI 10.1016/j.eswa.2011.04.161
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   [胡正平 Hu Zhengping], 2013, [仪器仪表学报, Chinese Journal of Scientific Instrument], V34, P2309
   Huang ZH, 2015, INFORM FUSION, V22, P95, DOI 10.1016/j.inffus.2014.06.001
   Jabid T., 2010, 2010 7th IEEE International Conference of Advanced Video and Signal Based Surveillance, P482
   Jin J, 2015, SIGNAL PROCESS-IMAGE, V36, P179, DOI 10.1016/j.image.2015.06.010
   Jun B, 2012, PATTERN RECOGN, V45, P3304, DOI 10.1016/j.patcog.2012.02.031
   Kumar R, 2011, IEEE I CONF COMP VIS, P2375, DOI 10.1109/ICCV.2011.6126520
   Kuncheva LI, 2014, KNOWL INF SYST, V38, P259, DOI 10.1007/s10115-012-0586-6
   Kwak KC, 2005, PATTERN RECOGN LETT, V26, P719, DOI 10.1016/j.patrec.2004.09.024
   Lee CC, 2011, SPEECH COMMUN, V53, P1162, DOI 10.1016/j.specom.2011.06.004
   Li D. Y., 1995, Comput. Res. Dev, V32, P15
   Li G, 2017, KNOWL-BASED SYST, V124, P46, DOI 10.1016/j.knosys.2017.02.034
   Li XD, 2013, NEUROCOMPUTING, V122, P266, DOI 10.1016/j.neucom.2013.06.025
   Liu Hai-jun, 2010, Acta Electronica Sinica, V38, P2797
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, P 25 INT JOINT C ART
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Luo Y, 2013, INT J COMPUT INT SYS, V6, P1108, DOI 10.1080/18756891.2013.816162
   Lv TJ, 2017, IEEE ICC
   Naik MK, 2016, APPL SOFT COMPUT, V38, P661, DOI 10.1016/j.asoc.2015.10.039
   Orrite C, 2008, LECT NOTES COMPUT SC, V5197, P340, DOI 10.1007/978-3-540-85920-8_42
   Owusu E, 2014, EXPERT SYST APPL, V41, P3383, DOI 10.1016/j.eswa.2013.11.041
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   [任福继 Ren Fuji], 2016, [中国图象图形学报, Journal of Image and Graphics], V21, P565
   Ren FJ, 2013, IEICE T INF SYST, VE96D, P2437, DOI 10.1587/transinf.E96.D.2437
   Santana MC, 2016, COMPUT VIS IMAGE UND, V156, P4
   Song Yuan-Jun, 2000, Acta Electronica Sinica, V28, P74
   Sun B, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013018
   Wang Xin-fan, 2010, Control and Decision, V25, P1494
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943
   Xu Q, 2013, MATH PROBL ENG, V2013
   Xu Q, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/543081
   Xu QZ, 2018, MULTIMED TOOLS APPL, V77, P6311, DOI 10.1007/s11042-017-4537-9
   Yang J, 2017, MULTIMED TOOLS APPL, P1, DOI DOI 10.3389/FRNICB.2017.00832
   [张洁玉 Zhang Jieyu], 2014, [电子与信息学报, Journal of Electronics & Information Technology], V36, P1327
   [张仰森 Zhang Yangsen], 2012, [中文信息学报, Journal of Chinese Information Processing], V26, P3
   Zhang YS, 2012, MULTIMED TOOLS APPL, V26, P3
NR 61
TC 8
Z9 7
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21083
EP 21107
DI 10.1007/s11042-017-5480-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300034
OA hybrid
DA 2024-07-18
ER

PT J
AU Wu, J
   Xia, ZQ
   Li, HF
   Sun, KZ
   Gu, K
   Lu, H
AF Wu, Jun
   Xia, Zhaoqiang
   Li, Huifang
   Sun, Kezheng
   Gu, Ke
   Lu, Hong
TI No-reference image quality assessment with center-surround based natural
   scene statistics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; Center-surround; Natural scene statistics;
   Difference of Gaussian; Support vector regression
AB In this paper, we propose an efficient no-reference image quality assessment (NR-IQA) method dubbed Center-Surround based Blind Image Quality Assessment (CS-BIQA). Our proposed method employs the Difference of Gaussian (DoG) model to decompose images into several frequency bands, considering the center-surround effect and multi-channel attribute of human visual system (HVS). The integrated natural scene statistics (NSS) features can be further derived from all DoG bands. After that, regression models between the integrated features and associated subjective assessment scores are learned on the training dataset. Subsequently, the learned models are used to predict the quality scores of test images. The main contribution of this paper is twofold. Firstly, the empirical distributions of DoG bands of images are proven to be a Gaussian-like distribution. And thus, the NSS features can be employed to represent the perceptual quality of images. Secondly, different types of distortions are observed to affect different frequency components of images. So, the integrated features extracted from multi-frequency bands are employed in CS-BIQA to achieve stronger distinguishable capability of image quality. Excessive experiments are conducted to indicate that our proposed CS-BIQA metric can represent the perceptual characteristics of HVS. The results on popular IQA databases demonstrate that the CS-BIQA metric is competitive with the state-of-the-art relevant IQA metrics. Furthermore, our proposed method has very low computational complexity, making it more suitable for real-time applications.
C1 [Wu, Jun; Xia, Zhaoqiang; Li, Huifang] Northwestern Polytech Univ, Sch Elect & Informat, Xian, Shaanxi, Peoples R China.
   [Sun, Kezheng] Jiangsu Vocat Coll Business, Sch Informat Technol & Elect Engn, Nantong, Peoples R China.
   [Gu, Ke; Lu, Hong] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
C3 Northwestern Polytechnical University; Nanyang Technological University
RP Xia, ZQ (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian, Shaanxi, Peoples R China.
EM wujun318@mail.nwpu.edu.cn; xiazhaoqiang@gmail.com; lhuifang@nwpu.edu.cn;
   528106tyhj@163.com; guke.doctor@gmail.com; zdhxlh@njit.edu.cn
RI Gu, Ke/AAJ-9684-2021; Xia, Zhaoqiang/AAC-4021-2019
OI Xia, Zhaoqiang/0000-0003-0630-3339
FU Doctorate Foundation of Northwestern Polytechnical University
   [CX201423]; Fundamental Research Funds of Northwestern Polytechnical
   University [G2015KY0302]; National Aerospace Science and Technology
   Foundation; National Nature Science Foundation of China [61702419]
FX This work is partly supported by the Doctorate Foundation of
   Northwestern Polytechnical University (CX201423), the Fundamental
   Research Funds of Northwestern Polytechnical University
   (NO.G2015KY0302), the National Aerospace Science and Technology
   Foundation and the National Nature Science Foundation of China (NO.
   61702419).
CR Adelson E.H., 2000, Lightness Perception and Lightness Illusion, V2nd, P339
   [Anonymous], IEEE T IND ELECT
   [Anonymous], 2016, IEEE T CYBERNETICS
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2010, J ELECT IMAG
   [Anonymous], 2008, ADV MODERN RADIOELEC
   Bovik AC, 2013, P IEEE, V101, P2008, DOI 10.1109/JPROC.2013.2257632
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Ciancio A, 2011, IEEE T IMAGE PROCESS, V20, P64, DOI 10.1109/TIP.2010.2053549
   Fu Y, 2016, ALGORITHMS, V9, DOI 10.3390/a9040087
   Ghadiyaram D, 2015, P SPIEINT SOC OPTL E, V9394
   Ghadiyaram D, 2017, J VISION, V17, DOI 10.1167/17.1.32
   Gu K., 2017, IEEE T NEURAL NETW L
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2015, IEEE T BROADCAST, V61, P520, DOI 10.1109/TBC.2015.2459851
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Jayaraman D, 2012, CONF REC ASILOMAR C, P1693, DOI 10.1109/ACSSC.2012.6489321
   Li LD, 2016, NEUROCOMPUTING, V177, P572, DOI 10.1016/j.neucom.2015.11.063
   Lin YH, 2014, IEEE T IMAGE PROCESS, V23, P1527, DOI 10.1109/TIP.2014.2302686
   Liu HT, 2010, IEEE T CIRC SYST VID, V20, P529, DOI 10.1109/TCSVT.2009.2035848
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Pei SC, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440172
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Shao F, 2015, IEEE SIGNAL PROC LET, V22, P1548, DOI 10.1109/LSP.2015.2413946
   SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779
   Tang L, 2017, MULTIMED TOOLS APPL, P1
   Wang SQ, 2015, IEEE SIGNAL PROC LET, V22, P2387, DOI 10.1109/LSP.2015.2487369
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu JT, 2016, IEEE T IMAGE PROCESS, V25, P4444, DOI 10.1109/TIP.2016.2585880
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
NR 36
TC 5
Z9 5
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20731
EP 20751
DI 10.1007/s11042-017-5483-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300020
DA 2024-07-18
ER

PT J
AU Zhao, L
   Wang, ZC
   Zhang, GX
   Qi, YZ
   Wang, XJ
AF Zhao, Lei
   Wang, Zengcai
   Zhang, Guoxin
   Qi, Yazhou
   Wang, Xiaojin
TI Eye state recognition based on deep integrated neural network and
   transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye state recognition; Deep learning; Deep integrated neural network;
   Transfer learning
ID HIGHLY PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION; PREDICTION; DECISION;
   ROBUST
AB Eye state recognition is widely used in many fields, such as driver drowsiness recognition, facial expression classification, and human-computer interface technology. This study proposes a novel framework based on the deep learning method to classify eye states in still facial images. The proposed method combines a deep neural network and a deep convolutional neural network to construct a deep integrated neural network for characterizing useful information in the eye region by use of the joint optimization method. A transfer learning strategy is applied to extract effective abstract eye features and improve the classification capability of the proposed model on small sample datasets. Experimental results on the Closed Eyes in the Wild (CEW) and Zhejiang University Eyeblink datasets show that the proposed approach outperforms other state-of-the-art methods. In addition, the effects of transfer learning methods with different pretraining datasets on classification accuracy are investigated with the CEW dataset. A driver drowsiness recognition dataset is constructed and used in an experiment to evaluate the effectiveness of the proposed method in driving environments. Experimental results demonstrate that the proposed method performs more stably and robustly than do other methods.
C1 [Zhao, Lei; Wang, Zengcai; Zhang, Guoxin; Qi, Yazhou; Wang, Xiaojin] Shandong Univ, Sch Mech Engn, Jinan, Shandong, Peoples R China.
   [Wang, Zengcai] Shandong Univ, Minist Educ, Key Lab High Efficiency & Clean Mech Mfg, Jinan, Shandong, Peoples R China.
C3 Shandong University; Shandong University
RP Wang, ZC (corresponding author), Shandong Univ, Sch Mech Engn, Jinan, Shandong, Peoples R China.; Wang, ZC (corresponding author), Shandong Univ, Minist Educ, Key Lab High Efficiency & Clean Mech Mfg, Jinan, Shandong, Peoples R China.
EM leizhao1219@163.com; wangzc@sdu.edu.cn; zhanggx@mail.sdu.edu.cn;
   transmissionqyz@163.com; wangxjsb@163.com
RI zhang, guoxin/KVX-7654-2024
OI zhang, guoxin/0000-0002-9228-6063
FU Open Foundation of State Key Laboratory of Automotive Simulation and
   Control (China) [20161105]
FX This work was supported by the Open Foundation of State Key Laboratory
   of Automotive Simulation and Control (China, Grant no. 20161105).
CR Ang Liu, 2010, 2010 Second Asia Pacific Conference on Postgraduate Research in Microelectronics & Electronics (PrimeAsia 2010), P235, DOI 10.1109/PRIMEASIA.2010.5604919
   [Anonymous], SERIES C, DOI DOI 10.1007/S40032-016
   [Anonymous], 2015, PROCIEEE CONFCOMPUT
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Bhaskar TN, 2003, TENCON IEEE REGION, P821, DOI 10.1109/TENCON.2003.1273293
   Bhimani J, 2017, IEEE INT CONF CLOUD, P359, DOI 10.1109/CLOUD.2017.53
   Breiman L., 2001, Mach. Learn., V45, P5
   Dehnavi M, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-30
   Dong YC, 2016, MULTIMED TOOLS APPL, V75, P11763, DOI 10.1007/s11042-015-2635-0
   Ejbali R, 2018, MULTIMED TOOLS APPL, V77, P6149, DOI 10.1007/s11042-017-4523-2
   Feng Yutian, 2009, 2009 IET International Communication Conference on Wireless Mobile & Computing (CCWMC 2009), P217
   Flores MJ, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/438205
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   González-Ortega D, 2013, PATTERN ANAL APPL, V16, P285, DOI 10.1007/s10044-013-0331-0
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Hassan HAH, 2016, IEEE ONL CONF GREEN, P1, DOI 10.1109/OnlineGreenCom.2016.7805398
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZY, 2008, INT C PATT RECOG, P1401
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu QH, 2016, RENEW ENERG, V85, P83, DOI 10.1016/j.renene.2015.06.034
   Huang G. B., 2007, Technical Report, DOI 10.1.1. 122.8268
   Huang JT, 2013, INT CONF ACOUST SPEE, P7304, DOI 10.1109/ICASSP.2013.6639081
   Huang Z, 2016, NEUROCOMPUTING, V218, P448, DOI 10.1016/j.neucom.2016.09.018
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Królak A, 2012, UNIVERSAL ACCESS INF, V11, P409, DOI 10.1007/s10209-011-0256-6
   Kurylyak Y., 2012, 2012 IEEE International Symposium on Medical Measurements and Applications Proceedings, P1, DOI [10.1109/MeMeA.2012.6226666, DOI 10.1109/MEMEA.2012.6226666]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu X, 2012, PROCEEDING OF THE IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P395, DOI 10.1109/ICInfA.2012.6246837
   Lubing Zhou, 2011, Proceedings of the 2011 IEEE 5th International Conference on Robotics, Automation and Mechatronics (RAM), P7, DOI 10.1109/RAMECH.2011.6070447
   Lv TJ, 2017, IEEE ICC
   Pan G, 2007, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2007.4409068
   Punitha A, 2016, ADV INTELL SYST COMP, V384, P103, DOI 10.1007/978-3-319-23036-8_9
   Radlak K, 2012, 2012 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTATIONAL TOOLS FOR ENGINEERING APPLICATIONS (ACTEA), P145, DOI 10.1109/ICTEA.2012.6462854
   Singh R, 2017, MULTIMED TOOLS APPL, V76, P19005, DOI 10.1007/s11042-016-4342-x
   Song FY, 2014, PATTERN RECOGN, V47, P2825, DOI 10.1016/j.patcog.2014.03.024
   Song FY, 2013, PATTERN RECOGN, V46, P3157, DOI 10.1016/j.patcog.2013.05.009
   Tian YL, 2000, LECT NOTES COMPUT SC, V1948, P143
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang G.S., 2016, IEEE T INTELL TRANSP, V3, P1
   Wu YM, 2010, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON EMERGENCY MANAGEMENT 2010, P1
   Xianming Lin, 2015, 2015 IEEE International Conference on Image Processing (ICIP). Proceedings, P1875, DOI 10.1109/ICIP.2015.7351126
   Xu Q, 2014, MATH PROBL ENG, V2014
   Xu Q, 2013, MATH PROBL ENG, V2013
   Xu QZ, 2018, MULTIMED TOOLS APPL, V77, P6311, DOI 10.1007/s11042-017-4537-9
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yang HY, 2012, APPL MECH MATER, V128-129, P123, DOI 10.4028/www.scientific.net/AMM.128-129.123
   Yang JF, 2018, MULTIMED TOOLS APPL, V77, P4237, DOI 10.1007/s11042-017-4752-4
   Yang ZY, 2016, IEEE IPCCC
   Yang ZY, 2016, INT CONF CLOUD COMP, P245, DOI [10.1109/CloudCom.2016.46, 10.1109/CloudCom.2016.0049]
   Yosinski J., 2014, Adv Neural Inf Process Syst, V2, P3320, DOI DOI 10.48550/ARXIV.1411.1792
   Yu S, 2017, MULTIMED TOOLS APPL, V76, P13367, DOI 10.1007/s11042-016-3768-5
   Zhang WL, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1475, DOI [10.1145/2783258.2783304, 10.1109/tbdata.2016.2573280]
   Zhao L, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.053024
NR 62
TC 30
Z9 32
U1 3
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19415
EP 19438
DI 10.1007/s11042-017-5380-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500024
DA 2024-07-18
ER

PT J
AU Bakshi, S
   Sa, PK
   Wang, HX
   Barpanda, SS
   Majhi, B
AF Bakshi, Sambit
   Sa, Pankaj K.
   Wang, Haoxiang
   Barpanda, Soubhagya Sankar
   Majhi, Banshidhar
TI Fast periocular authentication in handheld devices with reduced phase
   intensive local pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fast biometric matching; Biometric on mobile device; Periocular
   biometric; Phase intensive local pattern; Feature reduction
ID IRIS RECOGNITION; FEATURES; FACE
AB To ensure highest security in handheld devices, biometric authentication has emerged as a reliable methodology. Deployment of mobile biometric authentication struggles due to computational complexity. For a fast response from a mobile biometric authentication method, it is desired that the feature extraction and matching should take least time. In this article, the periocular region captured through frontal camera of a mobile device is considered under investigation for its suitability to produce a reduced feature that takes least time for feature extraction and matching. A recently developed feature Phase Intensive Local Pattern (PILP) is subjected to reduction giving birth to a feature termed as Reduced PILP (R-PILP), which yields a matching time speed-up of 1.56 times while the vector is 20% reduced without much loss in authentication accuracy. The same is supported by experiment on four publicly available databases. The performance is also compared with one global feature: Phase Intensive Global Pattern, and three local features: Scale Invariant Feature Transform, Speeded-up Robust Features, and PILP. The amount of reduction can be varied with the requirement of the system. The amount of reduction and the performance of the system bears a trade-off. Proposed R-PILP attempts to make periocular suitable for mobile devices.
C1 [Bakshi, Sambit; Sa, Pankaj K.; Barpanda, Soubhagya Sankar; Majhi, Banshidhar] Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, Odisha, India.
   [Wang, Haoxiang] Cornell Univ, Ithaca, NY USA.
   [Wang, Haoxiang] GoPercept Lab, New York, NY USA.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela; Cornell University
RP Bakshi, S (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, Odisha, India.
EM bakshisambit@nitrkl.ac.in; pankajksa@nitrkl.ac.in;
   hw496@goperception.com; soubhagya1984@gmail.com; bmajhi@nitrkl.ac.in
RI K, Pankaj/A-9362-2017; Bakshi, Sambit/JDC-3355-2023
OI Bakshi, Sambit/0000-0002-6107-114X
FU Department of Electronics and Information Technology, Government of
   India [12(5)/2012-ESD]
FX The research is funded by Grant no. 12(5)/2012-ESD by Department of
   Electronics and Information Technology, Government of India.
CR Adams J., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P205, DOI 10.1109/ICPR.2010.59
   Ahuja K, 2017, PATTERN RECOGN LETT, V91, P17, DOI 10.1016/j.patrec.2017.04.002
   [Anonymous], 2010, P 2010 ACM S APPL CO, DOI DOI 10.1145/1774088.1774408
   [Anonymous], 2008, HDB BIOMETRICS
   Bakshi S, 2014, ANNU IEEE IND CONF
   Bakshi S, 2015, BIOCYBERN BIOMED ENG, V35, P30, DOI 10.1016/j.bbe.2014.05.003
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Hollingsworth K., 2010, 2010 4 IEEE INT C BI, P1, DOI [10.1109/BTAS.2010.5634529, DOI 10.1109/BTAS.2010.5634529]
   Hollingsworth KP, 2012, IEEE T INF FOREN SEC, V7, P588, DOI 10.1109/TIFS.2011.2173932
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu CH, 2008, IMAGE VISION COMPUT, V26, P935, DOI 10.1016/j.imavis.2007.10.011
   Mahalingam G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-36
   Miller P.E., 2010, IEEE International Conference on Biometrics: Theory, Applications, and Systems, P1, DOI DOI 10.1109/BTAS.2010.5634536
   Oh K, 2014, NEUROCOMPUTING, V128, P185, DOI 10.1016/j.neucom.2013.01.066
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Padole C. N., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P439, DOI 10.1109/ICB.2012.6199790
   Park M, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ULTRA-WIDEBAND (ICUWB 2009), P1, DOI 10.1109/ICUWB.2009.5288737
   Patel B, 2017, COMPUT VIS IMAGE UND, V160, P24, DOI 10.1016/j.cviu.2017.04.009
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   Proença H, 2007, IEEE T PATTERN ANAL, V29, P607, DOI 10.1109/TPAMI.2007.1016
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Santos G, 2015, PATTERN RECOGN LETT, V57, P52, DOI 10.1016/j.patrec.2014.09.012
   Uzair M, 2013, INT CONF BIOMETR
   Vatsa M, 2008, IEEE T SYST MAN CY B, V38, P1021, DOI 10.1109/TSMCB.2008.922059
   Woodard Damon L., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P201, DOI 10.1109/ICPR.2010.58
   Woodard DL, 2011, SIGNAL IMAGE VIDEO P, V5, P443, DOI 10.1007/s11760-011-0248-2
   Xu J, 2010, B ENTOMOL RES, V100, P359, DOI 10.1017/S0007485310000015
   Zhao ZJ, 2017, IEEE T INF FOREN SEC, V12, P1017, DOI 10.1109/TIFS.2016.2636093
NR 29
TC 26
Z9 26
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17595
EP 17623
DI 10.1007/s11042-017-4965-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900005
DA 2024-07-18
ER

PT J
AU Burnik, U
   Zaletelj, J
   Kosir, A
AF Burnik, Urban
   Zaletelj, Janez
   Kosir, Andrej
TI Video-based learners' observed attention estimates for lecture learning
   gain evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attention metering; Observed attention estimate; Multimedia annotation
   system; Lecture efficiency; Learning management; Learning outcomes;
   Learning gain; Teaching advisory systems
ID ANNOTATION
AB A significant problem in the field of higher education is maintaining learners' attention during lectures, which is known to significantly affect their learning outcomes. Attention management is commonly associated with the individual ability of a lecturer to track and respond to the common behaviour of an auditorium; it lacks a detailed estimation of the intra-variability of individual learners' attention during the course of the lecture. This paper suggests an objective and non-intrusive evaluation of learners' attention against learning outcomes by introducing an observed attention estimate (OAE). The procedure uses human annotations based on visual cues with a supporting video recording/playback system and a web-based annotation system. This proposed procedure enables us to estimate the attention level of individual learners as observed by human annotators for given time intervals associated with specific concepts covered by the lecture. As part of the procedure, we use an inventory-based lecture gain evaluation and representation based on a novel learning gain matrix. This procedure allows for a detailed analysis of the lecture time flow with regard to learners' attention. We have verified the applicability of the procedure on a small-scale case study.
C1 [Burnik, Urban; Zaletelj, Janez; Kosir, Andrej] Univ Ljubljana, Fac Elect Engn, Trzaska 25, Ljubljana 1000, Slovenia.
C3 University of Ljubljana
RP Burnik, U (corresponding author), Univ Ljubljana, Fac Elect Engn, Trzaska 25, Ljubljana 1000, Slovenia.
EM urban.burnik@fe.uni-lj.si
RI Burnik, Urban/F-6204-2012; Zaletelj, Janez/JYP-8396-2024
OI Burnik, Urban/0000-0002-8652-4977; Zaletelj, Janez/0000-0001-5300-5663;
   Kosir, Andrej/0000-0001-6938-221X
FU Slovenian Research Agency [P2-0246 B]
FX This study was partially funded by Slovenian Research Agency (P2-0246
   B).
CR Angelo T. A., 1993, CLASSROOM ASSESSMENT, DOI [10.2307/2943957, DOI 10.2307/2943957]
   [Anonymous], 2003, Teach. High. Educ., DOI DOI 10.1080/13562510309399
   Asteriadis S, 2009, MULTIMED TOOLS APPL, V41, P469, DOI 10.1007/s11042-008-0240-1
   Bao L, 2006, AM J PHYS, V74, P917, DOI 10.1119/1.2213632
   Bligh D., 1985, Journal of Geography in Higher Education, V9, P105, DOI [DOI 10.1080/03098268508708932, 10.1080/03098268508708932]
   Cain J, 2009, AM J PHARM EDUC, V73, DOI 10.5688/aj730221
   D'Mello SK, 2016, IEEE T AFFECT COMPUT, V7, P136, DOI 10.1109/TAFFC.2015.2457413
   Giannopoulos I, 2016, MULTIMED TOOLS APPL, V75, P2913, DOI 10.1007/s11042-014-2412-5
   Gibbs G, 2011, STUDENT ATTENTION HO
   Graesser A. C., 2006, P ANN M COGN SCI SOC, P285
   Hake RR, 1998, AM J PHYS, V66, P64, DOI 10.1119/1.18809
   Hallgren Kevin A, 2012, Tutor Quant Methods Psychol, V8, P23
   HALLOUN IA, 1985, AM J PHYS, V53, P1056, DOI 10.1119/1.14031
   Johnstone A.H., 1976, EDUC CHEM, V13, P49
   Kondermann D., 2013, P INT WORKSHOP VIDEO, P1, DOI DOI 10.1145/2501105.2501114
   Krippendorff Klaus., 2004, Content Analysis: An Introduction to Its Methodology, V2nd, P413
   Malle BF, 2001, J PERS SOC PSYCHOL, V81, P278, DOI 10.1037//0022-3514.81.2.278
   Martínez HP, 2014, IEEE T AFFECT COMPUT, V5, P314, DOI 10.1109/TAFFC.2014.2352268
   Marx JD, 2007, AM J PHYS, V75, P87, DOI 10.1119/1.2372468
   Matheson C, 2008, CLIN TEACH, V5, P218, DOI 10.1111/j.1743-498X.2008.00238.x
   Perrenet J.C., 2000, Teach. High. Educ, V5, P345, DOI [DOI 10.1080/713699144, 10.1080/713699144]
   Porta M., 2012, Global Engineering Education Conference (EDUCON), 2012 IEEE, P1, DOI DOI 10.1109/EDUCON.2012.6201145
   Raykar VC, 2010, J MACH LEARN RES, V11, P1297
   Ried LD, 2011, AM J PHARM EDUC, V75, DOI 10.5688/ajpe7510196
   Risko EF, 2012, APPL COGNITIVE PSYCH, V26, P234, DOI 10.1002/acp.1814
   Ruhl K.L., 1987, TEACH EDUC SPEC EDUC, V10, P14, DOI 10.1177/088840648701000103
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Tkalcic M, 2013, INFORM SCIENCES, V249, P13, DOI 10.1016/j.ins.2013.06.006
   Von Eye A., 2005, Analyzing rater agreement manifest variable methods, V1st, DOI [10.4324/9781410611024, DOI 10.4324/9781410611024]
   Wage KE, 2005, IEEE T EDUC, V48, P448, DOI 10.1109/TE.2005.849746
   Wilcox RR, 2003, APPL CONT STAT TECHN, P608
   Wilson K, 2007, TEACH PSYCHOL, V34, P85
   Yang SM, 2015, 2015 IIAI 4TH INTERNATIONAL CONGRESS ON ADVANCED APPLIED INFORMATICS (IIAI-AAI), P379, DOI 10.1109/IIAI-AAI.2015.224
   Yannakakis GN, 2015, INT CONF AFFECT, P574, DOI 10.1109/ACII.2015.7344627
   Young M.S., 2009, Active Learning in Higher Education, V10, P41, DOI DOI 10.1177/1469787408100194
NR 35
TC 7
Z9 8
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16903
EP 16926
DI 10.1007/s11042-017-5259-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300041
DA 2024-07-18
ER

PT J
AU Park, CS
   Choeh, JY
AF Park, Chun-Su
   Choeh, Joon Yeon
TI Fast and robust copy-move forgery detection based on scale-space
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery; Digital image forensics; Keypoints; SIFT
ID FORENSICS; BLIND
AB Copy-move forgery (CMF), which copies a part of an image and pastes it into another region, is one of the most common methods for digital image tampering. For CMF detection (CMFD), we propose a fast and robust approach that can handle several geometric transformations including rotation, scaling, sheering, and reflection. In the proposed CMFD design, keypoints and their descriptors are extracted from the image based on the Scale Invariant Feature Transform (SIFT). Then, an improved matching operation that can handle multiple copy-move forgeries is performed to detect matched pairs located in duplicated regions. Next, the geometric transformation between duplicated regions is estimated using a subset of reliable matched pairs which are obtained using the SIFT scale space representation. In our simulation, we present comparative results between the proposed algorithm and state-of-the-art ones with proven performance guarantees.
C1 [Park, Chun-Su] Sungkyunkwan Univ, Dept Comp Educ, Seoul, South Korea.
   [Choeh, Joon Yeon] Sejong Univ, Dept Software, Seoul, South Korea.
C3 Sungkyunkwan University (SKKU); Sejong University
RP Choeh, JY (corresponding author), Sejong Univ, Dept Software, Seoul, South Korea.
EM zoon@sejong.ac.kr
RI Choeh, Joon Yeon/JFA-2309-2023
OI Choeh, Joon Yeon/0000-0002-6604-5944
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - the Ministry of Education, Science and Technology
   [NRF-2016R1C1B1009682]; MSIT(Ministry of Science and ICT), Korea, under
   the ITRC(Information Technology Research Center)
   [IITP-2017-2016-0-00312]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (NRF-2016R1C1B1009682). This
   research was supported by the MSIT(Ministry of Science and ICT), Korea,
   under the ITRC(Information Technology Research Center) support
   program(IITP-2017-2016-0-00312) supervised by the IITP(Institute for
   Information & communications Technology Promotion).
CR Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2013, SIGNAL PROCESS-IMAGE, DOI DOI 10.1016/j.image.2013.03.006
   [Anonymous], INT J COMPUT SCI APP
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], EXPOSING DIGITAL FOR
   [Anonymous], INT C IM PROC ICIP
   [Anonymous], 2010, International Journal on Computer Science and Engineering
   [Anonymous], 2003, P DIG FOR RES WORKSH
   [Anonymous], 2004, TR2004515 DEP COMP
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Christlein V., 2012, IEEE T INF FOREN SEC, V7, P1841, DOI DOI 10.1109/TIFS.2012.2218597
   Christlein V, 2010, IEEE INT WORKS INFOR, P1
   Cullen C.G., 1990, MATRICES LINEAR TRAN, V2nd
   Emam M, 2018, J FORENSIC SCI, V63, P102, DOI 10.1111/1556-4029.13456
   Hailing Huang, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P272, DOI 10.1109/PACIIA.2008.240
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Hwei-Jen Lin, 2009, WSEAS Transactions on Signal Processing, V5, P188
   Imran M, 2017, KSII T INTERNET INF, V11, P883, DOI 10.3837/tiis.2017.02.014
   Kirchner M, 2015, PROC SPIE, V9409, DOI 10.1117/12.2082789
   Kwon GR, 2016, MULTIMED TOOLS APPL, V75, P6697, DOI 10.1007/s11042-015-2563-z
   Langille A., 2006, CRV '06: Proceedings of the The 3rd Canadian Conference on Computer and Robot Vision, Washington, DC, USA, IEEE Computer Society, P64, DOI DOI 10.1109/CRV.2006.9
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li WH, 2010, IEEE IMAGE PROC, P2113, DOI 10.1109/ICIP.2010.5652519
   Liu B.X., 2014, PhD Thesis, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Mushtaq S., 2014, International Journal of Advanced Science and Technology, V73, P15, DOI DOI 10.14257/IJAST.2014.73.02
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Park CS, 2016, MULTIMED TOOLS APPL, V75, P16577, DOI 10.1007/s11042-016-3575-z
   Peng F, 2011, FORENSIC SCI INT, V212, pE21, DOI 10.1016/j.forsciint.2011.06.011
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Wang Jun-Wen, 2009, Acta Automatica Sinica, V35, P1488, DOI 10.3724/SP.J.1004.2009.01488
   Wang MJ, 2014, IEEE IMAGE PROC, P5382, DOI 10.1109/ICIP.2014.7026089
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P23353, DOI 10.1007/s11042-016-4140-5
   Wu Yunda, 2016, KSII Transactions on Internet and Information Systems, V10, P6206
   XiaoBing Kang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P926, DOI 10.1109/CSSE.2008.876
NR 44
TC 13
Z9 13
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16795
EP 16811
DI 10.1007/s11042-017-5248-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300036
DA 2024-07-18
ER

PT J
AU Rasipuram, S
   Jayagopi, DB
AF Rasipuram, Sowmya
   Jayagopi, Dinesh Babu
TI Automatic assessment of communication skill in interview-based
   interactions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Communication skill; Interface-based interviews; Face-to-face
   interviews; Social computing; Machine learning
ID RATINGS
AB Understanding and modeling people's behavior in social interactions is an important problem in Social Computing. In this work, we automatically predict the communication skill of a person in two kinds of interview-based social interactions namely interface-based (without an interviewer) and traditional face-to-face interviews. We investigate the differences in behavior perception and automatic prediction of communication skill when the same participant gives both interviews. Automated video interview platforms are gaining increasing attention that allows conducting interviews anywhere and anytime. Until recently, interviews were conducted face-to-face either for screening or for automatic assessment purposes. Our dataset consists of 100 dual interviews where the same participant participates in both settings. External observers rate the interviews by answering several behavioral based assessment questions (manually annotated attributes). Multimodal features related to lexical, acoustic and visual behavior are extracted automatically and trained using supervised learning algorithms like Support Vector Machines (SVM) and Logistic Regression. We make an extensive study of the verbal behavior of the participant using the spoken response obtained from manual transcriptions and an Automatic Speech Recognition (ASR) tool. We also explore early and late fusion of modalities for better prediction. Our best results indicate that automatic assessment can be done with interface-based interviews.
C1 [Rasipuram, Sowmya; Jayagopi, Dinesh Babu] Int Inst Informat Technol, Bangalore, Karnataka, India.
C3 International Institute of Information Technology Bangalore (IIIT
   Bangalore)
RP Rasipuram, S (corresponding author), Int Inst Informat Technol, Bangalore, Karnataka, India.
EM sowmya.r@iiitb.org; jdinesh@iiitb.ac.in
RI Jayagopi, Dinesh Babu/ABE-2546-2021; ARSLAN, Okan/AAA-3232-2020
OI Jayagopi, Dinesh Babu/0000-0003-0080-452X; 
FU SERB Young Scientist grant [YSS2015001074]
FX This work was funded by SERB Young Scientist grant of Dr. Jayagopi
   (Grant No. YSS2015001074). We thank Pooja Rao S. B for help in the
   extraction of verbal features and comments with the manuscript. We would
   also like to thank all the participants who accepted to use their data
   for the research purpose.
CR Ambady Nalini, 1992, THIN SLICES EXPRESSI
   [Anonymous], 2016, HASSLE FREE EFFICIEN
   [Anonymous], 2010, METHOD SILENCE REMOV
   [Anonymous], 2007, The development and psychometric properties of LIWC2007
   Batrinca L, 2013, INT WORKSH INT VIRT
   Batrinca LM, 2012, P 13 INT C MULT INT, P255
   Biel JI, 2013, IEEE T MULTIMEDIA, V15, P41, DOI 10.1109/TMM.2012.2225032
   Boersma P., 2018, Praat: doing phonetics by computer, DOI DOI 10.1097/AUD.0B013E31821473F7
   Celiktutan O, 2015, AUT FAC GEST REC FG, P1, DOI [DOI 10.1109/FG.2015.7163171, 10.1109/FG.2015.7163171]
   Cheng DS, 2014, J MULTIMODAL USER IN, V8, P151, DOI 10.1007/s12193-013-0142-z
   Chollet M, 2017, 12 IEEE INT C AUT FA
   DeGroot T, 2009, J BUS PSYCHOL, V24, P179, DOI 10.1007/s10869-009-9098-0
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI DOI 10.1145/2502081.2502224
   Fleiss J.L., 2003, The measurement of interrater agreement Statistical methods for rates and proportions, P598, DOI [10.1002/0471445428.ch18, DOI 10.1002/0471445428.CH18]
   Hayes AF, 2007, COMMUN METHODS MEAS, V1, P77, DOI 10.1080/19312450709336664
   Hecht M, 1999, NONVERBAL COMMUNICAT
   Hirschberg J., 2005, Proceedings of InterspeechEurospeech, 9th European Conference on Speech Communication and Technology, P513
   Hoque M, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P697
   Hung H, 2007, LIDIAPCONF2007016
   Hung H, 2007, LIDIAP C
   Joshi J, 2014, INT C PATT RECOG, P2855, DOI 10.1109/ICPR.2014.492
   Nguyen LS, 2014, IEEE T MULTIMEDIA, V16, P1018, DOI 10.1109/TMM.2014.2307169
   Littlewort G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P298, DOI 10.1109/FG.2011.5771414
   Mohammadi G, 2012, EPFLREPORT192770
   Murray KW, 2012, AUTOMATIC ESSAY SCOR, P45
   Naim Iftekhar, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163127
   Nguyen LS, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P51, DOI 10.1145/2818346.2820760
   Nguyen LS, 2016, IEEE T MULTIMEDIA
   Oertel C, INTERSPEECH, V2011
   Okada S, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P15, DOI 10.1145/2818346.2820757
   Park S, 2013, 2013 HUM ASS C IEEE
   Rasipuram S, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P370, DOI 10.1145/2993148.2993183
   Rasipuram S, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574733
   Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714
   Sanchez-Cortes D, 2015, ACM T INTERACT INTEL, V5, DOI 10.1145/2641577
   Sanchez-Cortes D, 2012, IEEE T MULTIMEDIA, V14, P816, DOI 10.1109/TMM.2011.2181941
   Scherer S., 2012, P 1 INT WORKSH MULT, P1
   Spitzberg B.H., 2007, CSRS: The conversational skills rating scale-An instructional assessment of interpersonal competence, V2nd
   Weninger F, 2013, INT J DIST EDUC, V11, P110, DOI 10.4018/jdet.2013040106
   Weninger F, 2012, IEEE T AFFECT COMPUT, V3, P496, DOI 10.1109/T-AFFC.2012.15
   Zechner K., 2006, P HUMAN TECHNOLOGY C, P216
NR 41
TC 10
Z9 14
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18709
EP 18739
DI 10.1007/s11042-018-5654-9
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900057
DA 2024-07-18
ER

PT J
AU Wei, QD
   Yin, ZX
   Wang, ZC
   Zhang, XP
AF Wei, Qingde
   Yin, Zhaoxia
   Wang, Zichi
   Zhang, Xinpeng
TI Distortion function based on residual blocks for JPEG steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distortion function; Residual block; JPEG steganography; Directional
   filter
ID STEGANALYSIS; SCHEME; DCT
AB Steganography aims to embed additional data into digital media secretly and minimize the distortion caused by data embedding. Up to now, the key point of minimal distortion embedding framework is to design proper distortion function. In this paper, a distortion function for JPEG steganography based on residual blocks is proposed. To obtain less statistical detectability, Residual Block Values (termed as RBVs for short) and quantization steps are both involved in the proposed distortion function. RBVs are exploited to determine the embedding risk caused by modifications in corresponding DCT block while quantization steps are exploited to determine the embedding risk of the selection channel in a block. By implementing the syndrome trellis coding (STC) to embed secret data, the modifications are constrained in hard-to-detect religions. Experiments show that the proposed method performs better than current state-of-the-art methods of JPEG steganography.
C1 [Wei, Qingde; Yin, Zhaoxia; Wang, Zichi] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Yin, Zhaoxia] Anhui Univ, Key Lab Intelligent Comp & Signal Proc, Minist Educ, Hefei, Anhui, Peoples R China.
   [Zhang, Xinpeng] Fudan Univ, Sch Comp Sci, Shanghai, Peoples R China.
C3 Shanghai University; Anhui University; Fudan University
RP Wei, QD (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM weiqingde@shu.edu.cn
RI Yin, Zhaoxia/HRD-7425-2023
OI Yin, Zhaoxia/0000-0003-0387-4806
FU Natural Science Foundation of China [U1636206, 61525203, 61502009,
   61472235]; Shanghai Dawn Scholar Plan [14SG36]; Shanghai Excellent
   Academic Leader Plan [16XD1401200]; China Postdoctoral Science
   Foundation [2016 M591650]; Natural Science Foundation of Anhui Province
   (CN) [1508085SQF216]; Key Program for Excellent Young Talents in
   Colleges and Universities of Anhui Province [gxyqZD2016011]
FX This work was supported in the Natural Science Foundation of China
   (U1636206, 61525203, 61502009, and 61472235), the Shanghai Dawn Scholar
   Plan (14SG36) and the Shanghai Excellent Academic Leader Plan
   (16XD1401200), China Postdoctoral Science Foundation (2016 M591650),
   Natural Science Foundation of Anhui Province (CN) (1508085SQF216), Key
   Program for Excellent Young Talents in Colleges and Universities of
   Anhui Province(gxyqZD2016011).
CR [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], ACM WORKSH INF HID M
   [Anonymous], 2011, P 13 INF HID C PRAG
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P102, DOI 10.1109/TIFS.2005.863487
   Guo LJ, 2015, IEEE T INF FOREN SEC, V10, P2669, DOI 10.1109/TIFS.2015.2473815
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Qian ZX, 2018, IEEE T DEPEND SECURE, V15, P1055, DOI 10.1109/TDSC.2016.2634161
   Qin C, 2016, SIGNAL PROCESS, V129, P48, DOI 10.1016/j.sigpro.2016.05.032
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P1983, DOI 10.1007/s11042-013-1733-0
   Wang C, 2012, INT CONF ACOUST SPEE, P1785, DOI 10.1109/ICASSP.2012.6288246
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang ZC, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.050501
   WESTFELD A., 2001, P 4 INT WORKSH INF H, V2137, P289, DOI DOI 10.1007/3-540-45496-9_21
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 22
TC 15
Z9 16
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17875
EP 17888
DI 10.1007/s11042-017-5053-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900017
DA 2024-07-18
ER

PT J
AU Abdi, L
   Meddeb, A
AF Abdi, Lotfi
   Meddeb, Aref
TI Driver information system: a combination of augmented reality, deep
   learning and vehicular Ad-hoc networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent transportation systems; Augmented reality; Head-up display;
   Deep learning; Cooperative safety systems
ID LANE-CHANGE
AB Improving traffic safety is one of the important goals of Intelligent Transportation Systems (ITS). In vehicle-based safety systems, it is more desirable to prevent an accident than to reduce severity of injuries. Critical traffic problems such as accidents and traffic congestion require the development of new transportation systems. Research in perceptual and human factors assessment is needed for relevant and correct display of this information for maximal road traffic safety as well as optimal driver comfort. One of the solutions to prevent accidents is to provide information on the surrounding environment of the driver. Augmented Reality Head-Up Display (AR-HUD) can facilitate a new form of dialogue between the vehicle and the driver; and enhance ITS by superimposing surrounding traffic information on the users view and keep drivers view on roads. In this paper, we propose a fast deep-learning-based object detection approaches for identifying and recognizing road obstacles types, as well as interpreting and predicting complex traffic situations. A single convolutional neural network predicts region of interest and class probabilities directly from full images in one evaluation. We also investigated potential costs and benefits of using dynamic conformal AR cues in improving driving safety. A new AR-HUD approach to create real-time interactive traffic animations was introduced in terms of types of obstacle, rules for placement and visibility, and projection of these on an in-vehicle display. The novelty of our approach is that both global and local context information are integrated into a unified framework to distinguish the ambiguous detection outcomes, enhance ITS by superimposing surrounding traffic information on the users view and keep drivers view on roads.
C1 [Abdi, Lotfi] Univ Tunis El Manar, Natl Engn Sch Tunis, Networked Objects Control & Commun Syst Lab, Tunis, Tunisia.
   [Meddeb, Aref] Univ Sousse, Natl Engn Sch Sousse, Networked Objects Control & Commun Syst Lab, Sousse, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); Universite de Sousse
RP Abdi, L (corresponding author), Univ Tunis El Manar, Natl Engn Sch Tunis, Networked Objects Control & Commun Syst Lab, Tunis, Tunisia.
EM lotfiabdi@hotmail.com; aref.meddeb@infcom.rnu.tn
RI Meddeb, Aref/T-8419-2019
CR Akhlaq M., 2010, SMART DASHBOARD AUGM
   [Anonymous], 2017, MIDDLE MIOCENE WENSH
   Batavia PH, 1997, IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, P729, DOI 10.1109/ITSC.1997.660564
   Behrisch M, 2011, 3D INT C ADV SYST SI
   Bergenhem C, 2014, SAE INT J PASSENG CA, V7, P462, DOI 10.4271/2014-01-0302
   Bradai A, 2014, VEH COMMUN, V1, P105, DOI 10.1016/j.vehcom.2014.05.002
   Caird J, 2004, VEHICLE INTELLIGENT, P236
   Cheng HT, 2011, MECH SYST SIGNAL PR, V25, P2020, DOI 10.1016/j.ymssp.2010.11.009
   Choi RA, 2015, US Patent, Patent No. [20,150,149,059, 20150149059]
   Ciresan D, 2012, NEURAL NETWORKS, V32, P333, DOI 10.1016/j.neunet.2012.02.023
   De Felice M, 2015, COMPUT COMMUN, V58, P40, DOI 10.1016/j.comcom.2014.08.009
   Donahue J., 2013, Decaf: A deep convolutional activation feature for generic visual recognition
   Fang Z, 2016, MULTI TOOLS APPL, V75
   Fu WT, 2013, INT SYM MIX AUGMENT, P59, DOI 10.1109/ISMAR.2013.6671764
   Ghoreyshi SM, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16030297
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Haklay M, 2008, IEEE PERVAS COMPUT, V7, P12, DOI 10.1109/MPRV.2008.80
   Halit L, AUGMENTED REALITY HE
   Haloi M, 2015, ARXIV050306643
   Han P, 2016, VISUAL COMPUT, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Huang CM, 2014, IET INTELL TRANSP SY, V8, P124, DOI 10.1049/iet-its.2012.0101
   Jama Abdirisaq Mohammed, 2010, International Journal of Computer and Network Security, V2, P11
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Khaled Yacine, 2009, Journal of Communications, V4, P357
   Khandelwal S. A., 2014, ACCIDENT PREVENTION
   Kim H, 2010, NETWORKED DIGITAL TE
   Kim S, 2016, MULTIMED TOOLS APPL, V75, P9587, DOI 10.1007/s11042-015-2712-4
   Kim S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P133
   Lee JW, 2015, INT CONF ADV COMMUN, P263, DOI 10.1109/ICACT.2015.7224799
   Lenc K, 2015, ARXIV150606981
   Li H, 2011, IEEE INT C INTELL TR, P242, DOI 10.1109/ITSC.2011.6083061
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Meng FX, 2015, ACCIDENT ANAL PREV, V75, P333, DOI 10.1016/j.aap.2014.12.013
   Milanés V, 2014, IEEE T INTELL TRANSP, V15, P296, DOI 10.1109/TITS.2013.2278494
   Mota S, 2004, INT J ROBOT AUTOM, V19, P190, DOI 10.2316/Journal.206.2004.4.206-2713
   Moysset B, 2015, ICDAR 2015 WORKSH HI
   Naranjo JE, 2008, IEEE T INTELL TRANSP, V9, P438, DOI 10.1109/TITS.2008.922880
   Ng-Thow-Hing V, 2013, INT SYM MIX AUGMENT, P13, DOI 10.1109/ISMAR-AMH.2013.6671262
   Ngai Daniel C. K., 2007, 2007 IEEE Intelligent Transportation Systems Conference, P818, DOI 10.1109/ITSC.2007.4357682
   Olaverri-Monreal C, 2010, IEEE INT VEH SYM, P123, DOI 10.1109/IVS.2010.5548020
   Paul B., 2012, ARXIV12041206
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren S, 2015, IEEE T PATTERN ANAL, VPP, P1
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezende C., 2014, THESIS
   Richter P, AR HUD TECHNOLOGY DI
   Schall MC, 2012, HUMAN FACTORS J HUMA
   Schofield K, 2013, US Patent App, Patent No. [13/ 919,483, 13919483]
   Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589
   Silveria M. K., 2014, ARXIV14050910
   Sivaraman S, 2014, IEEE T INTELL TRANSP, V15, P2063, DOI 10.1109/TITS.2014.2309055
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Stallkamp J, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1453, DOI 10.1109/IJCNN.2011.6033395
   Stebbins MA, 2014, US Patent App, Patent No. [14/ 453,391, 14453391]
   Tian DX, 2016, AD HOC NETW, V36, P465, DOI 10.1016/j.adhoc.2015.05.018
   Timofte R, KUL BELGIUM TRAFFIC
   Tönnis M, 2005, International Symposium on Mixed and Augmented Reality, Proceedings, P56
   Wang FH, 2009, IEEE T INTELL TRANSP, V10, P366, DOI 10.1109/TITS.2009.2020200
   Werneke J, 2012, ACCIDENT ANAL PREV, V45, P610, DOI 10.1016/j.aap.2011.09.048
   Xie H, NOVEL MULTI CHANNEL
   Yang J, 2016, MULT TOOLS APPL, V75
   Zaklouta F, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2151, DOI 10.1109/IJCNN.2011.6033494
NR 65
TC 17
Z9 23
U1 8
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14673
EP 14703
DI 10.1007/s11042-017-5054-6
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200009
DA 2024-07-18
ER

PT J
AU Javed, SG
   Majid, A
   Lee, YS
AF Javed, Syed Gibran
   Majid, Abdul
   Lee, Yeon Soo
TI Developing a bio-inspired multi-gene genetic programming based
   intelligent estimator to reduce speckle noise from ultrasound images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ultrasound images; Speckle noise; Multi-gene; Genetic programming;
   Parallel-framework; Denoising
ID ALGORITHM
AB The speckle noise commonly occurs in ultrasound imaging based applications. Due to the multiplicative nature, speckle noise deteriorates the visual quality of ultrasound images. This affects the performance of radiologists and practitioners for disease diagnosis and/or patient treatment. The current study proposes a bio-inspired multi-gene genetic programming (MGGP) based intelligent estimator to reduce the speckle noise from ultrasound images. The proposed MGGP approach is based on the parallel framework of multiple genes and has effectively utilized the evolutionary learning capabilities to develop an intelligent estimator, by exploiting the useful statistical features extracted from local neighboring pixels. The performance of the proposed novel approach is evaluated on ultrasound images of common carotid artery corrupted with different noise levels. Further, the robust performance was validated on several diverse types of ultrasound images of Breast Cyst, Kidney Cancer, Liver, Liver Cyst, and Fetal Head. The proposed bio-inspired approach showed superior denoising performance over existing approaches. The proposed intelligent estimator is capable of removing speckle noise effectively while preserving the fine lines and edges. During evolution, the MGGP framework automatically selects the useful statistical features and primitive functions from a wider solution space to develop the intelligent estimator. Further, the proposed approach does not require image-dependent optimal threshold values, as conventional speckle denoising approaches required.
C1 [Javed, Syed Gibran; Majid, Abdul] Pakistan Inst Engn & Appl Sci, Dept Comp & Informat Sci, Biomed Informat Res Lab, PO Nilore, Islamabad, Pakistan.
   [Lee, Yeon Soo] Catholic Univ Daegu Hayangro, Dept Biomed Engn, Coll Med Sci, Gyongsan, Gyoungsangbuk D, South Korea.
C3 Pakistan Institute of Engineering & Applied Science
RP Majid, A (corresponding author), Pakistan Inst Engn & Appl Sci, Dept Comp & Informat Sci, Biomed Informat Res Lab, PO Nilore, Islamabad, Pakistan.
EM abdulmajiid@pieas.edu.pk; biomechanics.yslee@gmail.com
FU Higher Education Commission, Government of Pakistan under Indigenous PhD
   Fellowship Program-Batch VII, PIN [117-3250-EG7-012]
FX This work is supported by Higher Education Commission, Government of
   Pakistan under Indigenous PhD Fellowship Program-Batch VII, PIN No.
   117-3250-EG7-012. The authors are also grateful to Dr. Dominic Searson
   for providing help regarding GPTIPS Toolbox.
CR Alvarez-Fernández JA, 2016, MED INTENSIVA, V40, P246, DOI [10.1016/j.medine.2015.10.003, 10.1016/j.medin.2015.10.008]
   [Anonymous], ATLAS ULTRASOUND IMA
   [Anonymous], 2010, P INT MULTICONFERENC
   [Anonymous], ROBUST STAT
   [Anonymous], 2011, PROCEDIA ENG, DOI DOI 10.1016/J.PROENV.2011.12.079
   Bissacco D, 2017, ANGIOLOGY, V68, P87, DOI 10.1177/0003319716664609
   Choi HH, 2015, BIO-MED MATER ENG, V26, pS1587, DOI 10.3233/BME-151458
   CRIMMINS TR, 1985, APPL OPTICS, V24, P1438, DOI 10.1364/AO.24.001438
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Gepperth A, 2016, COGN COMPUT, V8, P924, DOI 10.1007/s12559-016-9389-5
   Gholizadeh S, 2016, PROCEDIA STRUCT INTE, V1, P50, DOI 10.1016/j.prostr.2016.02.008
   Gong GH, 2015, OPT EXPRESS, V23, P24699, DOI 10.1364/OE.23.024699
   Guo YH, 2016, COMPUT METH PROG BIO, V123, P43, DOI 10.1016/j.cmpb.2015.09.007
   HECKMATT JZ, 1982, J PEDIATR-US, V101, P656, DOI 10.1016/S0022-3476(82)80286-2
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Javed SG, 2016, COGN COMPUT, V8, P776, DOI 10.1007/s12559-016-9416-6
   Javed SG, 2016, MULTIMED TOOLS APPL, V75, P5887, DOI 10.1007/s11042-015-2554-0
   Javed SG, 2015, INT CONF FRONT INFO, P18, DOI 10.1109/FIT.2015.15
   Jia ZJ, 2013, COGN COMPUT, V5, P252, DOI 10.1007/s12559-012-9186-8
   Koza J.R., 1992, GENETIC PROGRAMMING, VVolume 1
   Kurnaz MN, 2007, COMPUT METH PROG BIO, V85, P187, DOI 10.1016/j.cmpb.2006.10.010
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   LOPES A, 1990, IEEE T GEOSCI REMOTE, V28, P992, DOI 10.1109/36.62623
   Malutan R, 2015, E-HEALTH BIOENG CONF
   Medeiros FNS, 2002, FIFTH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, PROCEEDINGS, P281, DOI 10.1109/IAI.2002.999933
   Patil P, 2012, THER ADV MUSCULOSKEL, V4, P341, DOI 10.1177/1759720X12442112
   STEFFENS HD, 1981, THIN SOLID FILMS, V83, P325, DOI 10.1016/0040-6090(81)90635-0
   Tanabe M., 2011, Ultrasound Imaging
   Ungru K, 2014, COMPUT METH PROG BIO, V117, P2, DOI 10.1016/j.cmpb.2014.06.015
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
NR 32
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15657
EP 15675
DI 10.1007/s11042-017-5139-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200053
DA 2024-07-18
ER

PT J
AU Taime, A
   Riffi, J
   Saaidi, A
   Satori, K
AF Taime, Abderazzak
   Riffi, Jamal
   Saaidi, Abderrahim
   Satori, Khalid
TI Robust point matching via corresponding circles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Matching; Outliers; Putative set; Stereoscopic images
ID STEREO; OUTLIER
AB The matching points extracted from images play a very important role in many applications and particularly in computer vision. The use of point sets as being characteristics that describe the entire images brought into play, it greatly contributes to the reduction of the execution time, unlike the use of all the information contained in these images. The major problem of the matching process is the possibility to generate a large number of false correspondences, or outliers, in addition to a limited number of true correspondences (inliers). The objective of this paper is to propose a robust algorithm to eliminate or reduce the false correspondences, or outliers, among the putative set extracted from stereoscopic images. The principle of our method is based on the notion of belonging to the corresponding circles and the concept of similarity of stereoscopic images. The results largely reflect the efficiency and performance of our algorithm in comparison to the other used methods in this framework like RANSAC algorithm.
C1 [Taime, Abderazzak; Riffi, Jamal; Saaidi, Abderrahim; Satori, Khalid] Dhar Mahraz Sidi Mohamed Ben Abdellah Univ, Fac Sci, Dept Math & Comp Sci, LIIAN, BP 1796, Atlas, Fez, Morocco.
   [Saaidi, Abderrahim] Dhar Mahraz Sidi Mohamed Ben Abdellah Univ, Polydisciplinary Fac Taza, Dept Math Phys & Comp Sci, LSI, BP 1223, Taza, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Taime, A (corresponding author), Dhar Mahraz Sidi Mohamed Ben Abdellah Univ, Fac Sci, Dept Math & Comp Sci, LIIAN, BP 1796, Atlas, Fez, Morocco.
EM taime35550@gmail.com; riffi.jamal@gmail.com;
   abderrahim.saaidi@usmba.ac.ma; khalidsatorim3i@yahoo.fr
RI Saaidi, Abderrahim/R-1916-2019; riffi, jamal/GZH-2170-2022; satori,
   khalid/GSE-3077-2022
OI SATORI, khalid/0000-0001-6055-4169; Saaidi,
   Abderrahim/0000-0003-1708-0468
CR [Anonymous], 2006, 2006 IEEE COMP SOC C
   [Anonymous], P 2003 I E COMP SOC
   [Anonymous], WILEY SERIES PROBABI
   [Anonymous], 2000, 2 INT S ROBOTICS AUT
   Boyle, 2014, CENGAGE LEARNING
   Cao DS, 2010, J COMPUT CHEM, V31, P592, DOI 10.1002/jcc.21351
   Chen J, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.4.043012
   Chen YH, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P25, DOI 10.1109/IIH-MSP.2013.15
   CHEVREL M, 1981, PHOTOGRAMM ENG REM S, V47, P1163
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   FUA P, 1995, INT J COMPUT VISION, V16, P35, DOI 10.1007/BF01428192
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Imon AHMR, 2005, J APPL STAT, V32, P929, DOI 10.1080/02664760500163599
   Li XR, 2010, INT J COMPUT VISION, V89, P1, DOI 10.1007/s11263-010-0318-x
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marr David., 1991, RETINA NEOCORTEX, P263
   MASSART DL, 1986, ANAL CHIM ACTA, V187, P171, DOI 10.1016/S0003-2670(00)82910-4
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Nistér D, 2005, MACH VISION APPL, V16, P321, DOI 10.1007/s00138-005-0006-y
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D., 2007, COMPUTER VISION PATT, P1
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Torr PHS, 1997, IMAGE VISION COMPUT, V15, P591, DOI 10.1016/S0262-8856(97)00010-3
   Yang J., 2016, MEASUREMENT, V7, P448
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
   Yu L, 2007, IEEE INT C BIOINFORM, P9, DOI 10.1109/BIBM.2007.19
NR 31
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15027
EP 15046
DI 10.1007/s11042-017-5086-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200026
DA 2024-07-18
ER

PT J
AU Wang, HQ
   Yan, B
   Wang, XZ
   Zhang, YB
   Yang, Y
AF Wang, Haoqian
   Yan, Bing
   Wang, Xingzheng
   Zhang, Yongbing
   Yang, Yi
TI Accurate saliency detection based on depth feature of 3D images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Depth feature; Background region; Light field
ID VISUAL-ATTENTION
AB This paper presents an accurate saliency detection algorithm customized for 3D images which contain abundant depth cue. Firstly, depth feature is calculated based on the sharp regions' positions within the focal stack. Then, we compute the coarse saliency map by subtracting the background region from the all-focus image according to the depth feature. Finally, we employ the contrast information in the coarse saliency map to obtain the final result. Experiments on light field dataset demonstrate that our approach favorably outperforms five state-of-the-art methods in terms of precision, recall and F-Measure. Moreover, the depth feature is validated to be a valuable complement to existing visual saliency analysis under the circumstance that the background regions are complex or similar to salient object regions.
C1 [Wang, Haoqian; Yan, Bing; Wang, Xingzheng; Zhang, Yongbing] Tsinghua Univ, Key Lab Broadband Network & Multimedia, Grad Sch Shenzhen, Shenzhen 518055, Peoples R China.
   [Wang, Haoqian; Wang, Xingzheng; Zhang, Yongbing] Shenzhen Inst Future Media Technol, Shenzhen 518071, Peoples R China.
   [Yang, Yi] LUSTER LightTech Co Ltd, Beijing 100094, Peoples R China.
C3 Tsinghua University; Tsinghua Shenzhen International Graduate School
RP Wang, XZ (corresponding author), Tsinghua Univ, Key Lab Broadband Network & Multimedia, Grad Sch Shenzhen, Shenzhen 518055, Peoples R China.; Wang, XZ (corresponding author), Shenzhen Inst Future Media Technol, Shenzhen 518071, Peoples R China.
EM xingzheng.wang@sz.tsinghua.edu.cn
FU NSFC [61571259, 61531014, 61471213];  [JCYJ20160331185006518]; 
   [GGFW2017040714161462]
FX This work is partially supported by the NSFC fund (61571259, 61531014,
   61471213), and Shenzhen Research fund (JCYJ20160331185006518,
   GGFW2017040714161462).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Ali B, 2014, ARXIV14115878
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Bylinskii Z., 2016, What do different evaluation metrics tell us about saliency models
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Cheng MM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778820
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Peng QM, 2017, IEEE T SYST MAN CY-S, V47, P86, DOI 10.1109/TSMC.2016.2564922
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Rutishauser U, 2004, PROC CVPR IEEE, P37
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Sun J, 2011, IEEE I CONF COMP VIS, P1511, DOI 10.1109/ICCV.2011.6126409
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Tong N, 2014, IEEE SIGNAL PROC LET, V21, P1035, DOI 10.1109/LSP.2014.2323407
   Zhang GX, 2009, COMPUT GRAPH FORUM, V28, P1897, DOI 10.1111/j.1467-8659.2009.01568.x
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhao SC, 2020, IEEE T AFFECT COMPUT, V11, P574, DOI [10.1109/TAFFC.2018.2818685, 10.1109/TAFFC.2016.2628787]
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 31
TC 7
Z9 8
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14655
EP 14672
DI 10.1007/s11042-017-5052-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200008
DA 2024-07-18
ER

PT J
AU Wang, XH
   Yan, K
AF Wang, Xiuhui
   Yan, Ke
TI Automatic color correction for multi-projector display systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color correction; Multi-projector display system; Common achievable
   response; Hierarchical framework
AB A hierarchical color correction framework is presented to automatically calibrate multiple projectors. The proposed framework consists of two sub-methods: a simple color correction method and an advanced color correction method. An automatic selection scheme is designed to choose between the two sub-methods according to specific conditions. The simple color correction method uses a parameter model to map projected images into the Common Achievable Response (CAR) space for color consistent outputs. The advanced color correction method takes the projector properties, the display surface optical properties, and the relative distances between the screen and the projectors into consideration. A pre-processing step is designed to eliminate isolated abnormal sampling points, resulting in better quality outputs. In the experiment part, the effectiveness of the proposed framework is verified with both front projection systems and rear projection systems. The experimental results show that the proposed framework achieves better calibration results comparing with traditional methods.
C1 [Wang, Xiuhui; Yan, Ke] China Jiliang Univ, Coll Informat Engn, 258 Xueyuan St, Hangzhou 310018, Zhejiang, Peoples R China.
C3 China Jiliang University
RP Yan, K (corresponding author), China Jiliang Univ, Coll Informat Engn, 258 Xueyuan St, Hangzhou 310018, Zhejiang, Peoples R China.
EM yanke@cjlu.edu.cn
RI Yan, Keyu/IXX-0343-2023; Wang, Xiuhui/O-5616-2019
OI Wang, Xiuhui/0000-0003-1773-9760; Yan, Ke/0000-0002-1611-6636
FU National Natural Science Foundation of China [61303146, 61602431]; AQSIQ
   of China [2010QK407]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61303146, 61602431), and is performed under the auspices by
   the AQSIQ of China (No. 2010QK407).
CR Astre B, 2008, IEEE COMP SOC C COMP, P107
   Babar K, 2015, DISPLAYS, V40, P104, DOI 10.1016/j.displa.2015.05.009
   Bhasker EzekielS., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Brown M, 2005, IEEE T VIS COMPUT GR, V11, P193, DOI 10.1109/TVCG.2005.27
   Chen Guo-Dong, 2002, Chinese Journal of Computers, V25, P1001
   Chen MH, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P570, DOI 10.1109/FSKD.2014.6980897
   Debevec P.E., 2008, Recovering High Dynamic Range Radiance Maps from Photographs, P31
   Fernandez S, 2011, INT SYMP IMAGE SIG, P633
   Garcia-Dorado Ignacio., 2011, 2011 IEEE COMPUTER S, P29, DOI [10. 1109/CVPRW. 2011. 5981726, DOI 10.1109/CVPRW.2011.5981726]
   Gaur PK, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P293, DOI 10.1109/IC3I.2014.7019727
   Han Y, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P837, DOI 10.1109/SPIN.2015.7095375
   Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468
   Majumder A, 2005, ACM T GRAPHIC, V24, P118, DOI 10.1145/1037957.1037964
   Majumder A, 2004, IEEE T VIS COMPUT GR, V10, P177, DOI 10.1109/TVCG.2004.1260769
   Park S, 2015, IEEE SCI VIS C 2015, P65
   Park S, 2015, 2015 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P65, DOI 10.1109/SciVis.2015.7429493
   Pizzolato D., CXIMAGE CLASS IS LIB
   Raskar R., 1998, Computer Graphics, P179, DOI 10.1145/280814.280861
   Saeed S, 2015, DISPLAYS, V40, P78, DOI 10.1016/j.displa.2015.06.002
   Sajadi B, 2010, P IEEE VIRT REAL ANN, P155, DOI 10.1109/VR.2010.5444797
   Sajadi B, 2009, IEEE T VIS COMPUT GR, V15, P1317, DOI 10.1109/TVCG.2009.124
   SAKAUE F, 2008, P INT C PATT REC FLO, P113
   Soon-Yong Park, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P320, DOI 10.1109/ICPR.2010.87
   Wang MY, 2015, IEICE ELECTRON EXPR, V12, DOI 10.1587/elex.12.20141104
   Wang Xiu-Hui, 2007, Journal of Software, V18, P2955, DOI 10.1360/jos182955
   Wang Xiuhui, 2008, Journal of Computer Aided Design & Computer Graphics, V20, P707
   Zhong Q, 2016, J DISP TECHNOL, V12, P1745, DOI 10.1109/JDT.2016.2598059
   Zoido C, 2013, INT J INTERACT DES M, V7, P13, DOI 10.1007/s12008-012-0161-0
NR 28
TC 3
Z9 5
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13115
EP 13132
DI 10.1007/s11042-017-4934-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900003
DA 2024-07-18
ER

PT J
AU Al-Qurishi, M
   Alhuzami, S
   AlRubaian, M
   Hossain, MS
   Alamri, A
   Rahman, MA
AF Al-Qurishi, Muhammad
   Alhuzami, Saad
   AlRubaian, Majed
   Hossain, M. Shamim
   Alamri, Atif
   Rahman, Md. Abdur
TI User profiling for big social media data using standing ovation model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data processing; Big data mining; Analysis of textual content; Twitter
ID QUALITY; TWITTER; SYSTEM
AB Online Social Networks (OSNs) have recently been the subject of numerous studies that have attempted to develop effective methods for classifying and analyzing big content. Some of the key contributions of these studies to current scientific understanding include the identification of underlying topics within content (posts and messages), determination of each user's influence and contributions, c) measurement of content quality, and extraction and analysis of users' motives and preferences. We aimed to develop an integrative solution entailing a combination of these methodological advances within a single framework that could facilitate attribution and differentiate OSN members. Specifically, we examined peer effects within Twitter and assessed the propensity of members to alter their views on commonly discussed matters based on their exposure to alternative views expressed by respected and influential members. We availed of abundant available resources and tracked historical interactions of selected users to create a workable model that captured differences in opinions. The resulting solution enables peer influence within the online environment to be quantified and the level of investment of identified social media users in particular topics to be assessed.
C1 [Al-Qurishi, Muhammad; Alhuzami, Saad; AlRubaian, Majed; Hossain, M. Shamim; Alamri, Atif] King Saud Univ, Collage Comp & Informat Sci, Chair Pervas & Mobile Comp, Riyadh 11543, Saudi Arabia.
   [Hossain, M. Shamim; Alamri, Atif] King Saud Univ, Dept Software Engn, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.
   [Rahman, Md. Abdur] Univ Prince Muqrin, Dept Comp Sci, Al Munawarrah, Saudi Arabia.
C3 King Saud University; King Saud University; University of Prince Mugrin
RP Hossain, MS (corresponding author), King Saud Univ, Collage Comp & Informat Sci, Chair Pervas & Mobile Comp, Riyadh 11543, Saudi Arabia.; Hossain, MS (corresponding author), King Saud Univ, Dept Software Engn, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.
EM qurishi@ksu.edu.sa; saad4q@gmail.com; malrubaian.c@ksu.edu.sa;
   mshossain@ksu.edu.sa; atif@ksu.edu.sa
RI Rahman, Abdur/AAG-9302-2019; Hossain, M. Shamim/K-1362-2014; Guizani,
   Mohsen/AAX-4534-2021; Alamri, Atif/KFQ-0028-2024; AL-Qurishi,
   Muhammad/F-4147-2018
OI Rahman, Abdur/0000-0002-4105-0368; Hossain, M.
   Shamim/0000-0001-5906-9422; Guizani, Mohsen/0000-0002-8972-8094; Alamri,
   Atif/0000-0002-1887-5193; AL-Qurishi, Muhammad/0000-0002-7594-7325;
   Al-Rakhami, Mabrook/0000-0001-5343-8370
FU Deanship of Scientific Research, King Saud University
FX The authors are grateful to the Deanship of Scientific Research, King
   Saud University for funding through Vice Deanship of Scientific Research
   Chairs.
CR Abel F, 2011, LECT NOTES COMPUT SC, V6644, P375, DOI 10.1007/978-3-642-21064-8_26
   Adedoyin-olowe M., 2014, International Journal of Research in Computer Engineering and Electronics, V3, P1
   Alhamid Mohammed F, IEEE T HUMAN MACHINE, V46, P615
   [Anonymous], 2015, ASIA CONTROL CONF AS
   [Anonymous], 2007, P 9 WEBKDD 1 SNA KDD, DOI [10.1145/1348549.1348556, DOI 10.1145/1348549.1348556]
   Benevenuto F, 2009, IMC'09: PROCEEDINGS OF THE 2009 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P49
   Besel C, 2016, P 31 ANN ACM S APPL, P1152
   Besel C, 2016, APPL COMPUT REV, V16, P5, DOI 10.1145/3015297.3015298
   Chaudhary P, 2017, NEURAL NETW WORLD, V27, P5, DOI 10.14311/NNW.2017.27.001
   Chaudhary P, 2016, CONS EL 2016 IE 5 GL
   Chen M, 2016, IND 2016
   Chen M, 2015, IEEE NETWORK, V29, P32, DOI 10.1109/MNET.2015.7064900
   Chu Z, 2012, IEEE T DEPEND SECURE, V9, P811, DOI 10.1109/TDSC.2012.75
   Dougnon RY, 2015, LECT NOTES ARTIF INT, V9091, P84, DOI 10.1007/978-3-319-18356-5_8
   EASON G, 1955, PHILOS TR R SOC S-A, V247, P529, DOI 10.1098/rsta.1955.0005
   Fang Q, 2015, IEEE T MULTIMEDIA, V17, P2281, DOI 10.1109/TMM.2015.2491019
   Fang Q, 2015, IEEE T MULTIMEDIA, V17, P1031, DOI 10.1109/TMM.2015.2430819
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Hossain MS, 2008, MULTIMEDIA SYST, V14, P135, DOI 10.1007/s00530-008-0124-2
   Hossain MS, 2016, MOBILE NETW APPL, V21, P753, DOI 10.1007/s11036-016-0685-9
   Hossain MS, 2017, FUTUR GENER COMPUT S
   Jiang J, 2013, ACM T WEB, V7, DOI 10.1145/2517040
   Kwak H., WWW'10, DOI DOI 10.1145/1772690.1772751
   Li J, 2015, CHEM GEOL, V406, P10, DOI 10.1016/j.chemgeo.2015.04.010
   Lo SL, 2016, DECIS SUPPORT SYST, V85, P34, DOI 10.1016/j.dss.2016.02.010
   Miller JH, 2004, COMPLEXITY, V9, P8, DOI 10.1002/cplx.20033
   Min WQ, 2015, IEEE T MULTIMEDIA, V17, P1787, DOI 10.1109/TMM.2015.2463226
   Peng M, 2016, EXPERT SYST APPL, V44, P92, DOI 10.1016/j.eswa.2015.08.056
   Peng M, 2013, LECT NOTES COMPUT SC, V8181, P188, DOI 10.1007/978-3-642-41154-0_14
   Pennacchiotti M, 2011, KDD '11, P430, DOI DOI 10.1145/2020408.2020477
   Qian S, 2015, ACM T MULTIM COMPUT, P11
   Rawashdeh M, 2017, MULTIMED TOOLS APPL, V76, P21157, DOI 10.1007/s11042-016-4039-1
   Riquelme F, 2016, INFORM PROCESS MANAG, V52, P949, DOI 10.1016/j.ipm.2016.04.003
   Song J, 2017, FUTURE GENER COMP SY, V75, P200, DOI 10.1016/j.future.2016.05.040
   Tao K, 2012, LECT NOTES COMPUT SC, V7117, P269, DOI 10.1007/978-3-642-25953-1_22
   Tao Yang, 2013, 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P684
   Vosecky Jan, 2012, Database Systems for Advanced Applications. Proceedings of the 17th International Conference, DASFAA 2012, P397, DOI 10.1007/978-3-642-29038-1_29
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P346, DOI 10.1109/TMM.2015.2393635
   Yang Z, 2014, ACM T KNOWL DISCOV D, V8, P5, DOI 10.1145/2556609
   Zhang Z, 2016, MTAPD1601532
   Zhang Z, 2016, FUTUR GENER COMPUT S
NR 41
TC 12
Z9 12
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11179
EP 11201
DI 10.1007/s11042-017-5402-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900045
DA 2024-07-18
ER

PT J
AU Deng, LZ
   Zhu, H
   Zhou, Q
   Li, YS
AF Deng, Lizhen
   Zhu, Hu
   Zhou, Quan
   Li, Yansheng
TI Adaptive top-hat filter based on quantum genetic algorithm for infrared
   small target detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Infrared small target detection; Top-hat filter; Quantum genetic
   algorithm; Convergence analysis
ID DESIGN
AB With the development of infrared technology, infrared small targets detection has attracted great interest of researchers. Top-hat filter is one of widely used methods for detecting infrared small target, and the structure elements have great influence on the performance of detection. The structure elements are desired to be adjusted adaptively. To this end, an adaptive structure elements optimization method based on quantum genetic algorithm (QGA) is introduced, and the convergence of QGA reveals the effectiveness of QGA. Experimental results show that the proposed adaptive top-hat filter based on QGA can achieve more stable infrared small target detection performance compared with the traditional top-hat filter.
C1 [Deng, Lizhen; Zhu, Hu; Zhou, Quan] Nanjing Univ Posts & Telecommun, Coll Telecommun & Informat Engn, Nanjing 210003, Jiangsu, Peoples R China.
   [Li, Yansheng] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Wuhan University
RP Deng, LZ (corresponding author), Nanjing Univ Posts & Telecommun, Coll Telecommun & Informat Engn, Nanjing 210003, Jiangsu, Peoples R China.
EM alicedenglzh@gmail.com; peter.hu.zhu@gmail.com
RI Li, Yansheng/AAU-6392-2021; zhu, hu/GQQ-8365-2022
OI Li, Yansheng/0000-0001-8203-1246; 
FU National Natural Science Foundation [61501259, 61401228]; China
   Postdoctoral Science Foundation [2016 M591891, 2015 M581841];
   Postdoctoral Science Foundation of Jiangsu Province [1501019A]; Natural
   Science Foundation of Jiangsu Province [BK20140874, BK20150864]; NUPTSF
   [NY214041, NY215136, NY214145]
FX This work is sponsored by the National Natural Science Foundation (Grant
   No. 61501259, 61401228), sponsored by China Postdoctoral Science
   Foundation (Grant No. 2016 M591891, 2015 M581841), sponsored by
   Postdoctoral Science Foundation of Jiangsu Province(Grant No. 1501019A),
   sponsored by Natural Science Foundation of Jiangsu Province (Grant No.
   BK20140874, BK20150864), and sponsored by NUPTSF (Grant No. NY214041,
   NY215136, NY214145).
CR [Anonymous], P 35 ANN S FDN COMP
   [Anonymous], 2017, CONCURRENCY COMPUT P, DOI DOI 10.1002/CPE.3927
   Bae TW, 2011, INFRARED PHYS TECHN, V54, P403, DOI 10.1016/j.infrared.2011.06.006
   Bai XZ, 2010, PATTERN RECOGN, V43, P2145, DOI 10.1016/j.patcog.2009.12.023
   Caefer CE, 1998, P SOC PHOTO-OPT INS, V3373, P111, DOI 10.1117/12.324612
   Chen CLP, 2014, IEEE T GEOSCI REMOTE, V52, P574, DOI 10.1109/TGRS.2013.2242477
   Deng H, 2016, IEEE T AERO ELEC SYS, V52, P60, DOI 10.1109/TAES.2015.140878
   Deng LZ, 2015, ELECTRON LETT, V51, P626, DOI 10.1049/el.2014.4231
   Deshpande SD, 1999, P SOC PHOTO-OPT INS, V3809, P74, DOI 10.1117/12.364049
   Dong WK, 2011, INFRARED PHYS TECHN, V54, P70, DOI 10.1016/j.infrared.2010.12.037
   Gao C., 2014, PLOS ONE, V9
   Han KH, 2000, IEEE C EVOL COMPUTAT, P1354, DOI 10.1109/CEC.2000.870809
   Harvey NR, 1994, COMP IMAG VIS, V2, P53
   Hilliard CI, 2000, P SOC PHOTO-OPT INS, V4048, P74, DOI 10.1117/12.392022
   Huimin Lu, 2010, Proceedings of the 2010 International Conference on Intelligent Control and Information Processing (ICICIP 2010), P79, DOI 10.1109/ICICIP.2010.5564346
   Laboudi Z, 2012, INT ARAB J INF TECHN, V9, P243
   Li Y, 2012, SERIES CACSS GENERIC, V1, P27
   Li YS, 2016, INFORM SCIENCES, V369, P548, DOI 10.1016/j.ins.2016.07.042
   Li YS, 2016, IEEE GEOSCI REMOTE S, V13, P157, DOI 10.1109/LGRS.2015.2503142
   Li Y, 2014, MULTIMED TOOLS APPL, V71, P1179, DOI 10.1007/s11042-012-1258-y
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Liu G., APPL BIONICS BIOMECH, V2016, P2804543, DOI [10.1155/2016/2804543, DOI 10.1155/2016/2804543, DOI 10.1016/J.NUCENGDES.2016.01.021]
   Lu H., 2012, INT J ADV COMPUTING, V4, P475
   Qi SX, 2013, IEEE GEOSCI REMOTE S, V10, P495, DOI 10.1109/LGRS.2012.2211094
   Serra J., 1983, IMAGE ANAL MATH MORP
   Yang L, 2004, ELECTRON LETT, V40, P1083, DOI 10.1049/el:20045204
   Zeng M, 2006, INFRARED PHYS TECHN, V48, P67, DOI 10.1016/j.infrared.2005.04.006
   Zhu H, 2013, INFRARED PHYS TECHN, V60, P15, DOI 10.1016/j.infrared.2013.03.005
NR 28
TC 60
Z9 65
U1 0
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10539
EP 10551
DI 10.1007/s11042-017-4592-2
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900010
DA 2024-07-18
ER

PT J
AU Guo, R
   Zhu, JH
   Li, YC
   Chen, DP
   Li, ZY
   Zhang, YQ
AF Guo, Rui
   Zhu, Jihua
   Li, Yaochen
   Chen, Dapeng
   Li, Zhongyu
   Zhang, Yongqin
TI Weighted motion averaging for the registration of multi-view range scans
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view registration; Iterative closest point algorithm; Overlapping
   percentage; Motion averaging
AB Multi-view registration is a fundamental but challenging task in 3D reconstruction and robot vision. Although the original motion averaging algorithm has been introduced as an effective means to solve the multi-view registration problem, it does not consider the reliability and accuracy of each relative motion. Accordingly, this paper proposes a novel motion averaging algorithm for multi-view registration. Firstly, it utilizes the pair-wise registration algorithm to estimate the relative motion and overlapping percentage of each scan pair with a certain degree of overlap. With the overlapping percentage available, it views the overlapping percentage as the corresponding weight of each scan pair and proposes the weighted motion averaging algorithm, which can pay more attention to reliable and accurate relative motions. By treating each relative motion distinctively, more accurate registration can be achieved by applying the weighted motion averaging to multi-view range scans. Experimental results demonstrate the superiority of our proposed approach compared with the state-of-the-art methods in terms of accuracy, robustness and efficiency.
C1 [Guo, Rui; Zhu, Jihua; Li, Yaochen; Chen, Dapeng] Xi An Jiao Tong Univ, Sch Software Engn, Xian, Shaanxi, Peoples R China.
   [Li, Zhongyu] Univ North Carolina Charlotte, Dept Comp Sci, Charlotte, NC USA.
   [Zhang, Yongqin] Northwest Univ, Sch Informat Sci & Technol, Xian, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University; University of North Carolina; University of
   North Carolina Charlotte; Northwest University Xi'an
RP Zhu, JH (corresponding author), Xi An Jiao Tong Univ, Sch Software Engn, Xian, Shaanxi, Peoples R China.
EM zhujh@xjtu.edu.cn
RI li, zy/HZM-1892-2023
FU National Natural Science Foundation of China [61573273, 61573280,
   61503300]
FX This work is supported by the National Natural Science Foundation of
   China under Grant nos. 61573273, 61573280 and 61503300.
CR Arrigoni F., 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P491, DOI 10.1109/3DV.2014.48
   Arrigoni F, 2016, LECT NOTES COMPUT SC, V9908, P489, DOI 10.1007/978-3-319-46493-0_30
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007
   Curless B., The Stanford 3D scanning repository
   Fantoni S, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P73, DOI 10.1109/3DIMPVT.2012.63
   Geng N, 2016, MULTIMED TOOLS APPL, V75, P16763, DOI 10.1007/s11042-015-2941-6
   Godin G., 1994, Proceedings of the SPIE - The International Society for Optical Engineering, V2350, P279, DOI 10.1117/12.189139
   Govindu VM, 2014, IEEE T IMAGE PROCESS, V23, P1289, DOI 10.1109/TIP.2013.2246517
   Govindu VM, 2004, PROC CVPR IEEE, P684
   Guo YL, 2014, IEEE T MULTIMEDIA, V16, P1377, DOI 10.1109/TMM.2014.2316145
   He J, 2012, P IEEE C COMP VIS PA, V2012, P568
   Held D, 2016, IEEE INT CONF ROBOT, P2152, DOI 10.1109/ICRA.2016.7487365
   Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223
   Lomonosov E, 2006, PATTERN RECOGN LETT, V27, P1201, DOI 10.1016/j.patrec.2005.07.018
   Lu HM, 2016, INT J COMPUT SCI ENG, V12, P352
   Lu HM, 2016, J VIS COMMUN IMAGE R, V38, P504, DOI 10.1016/j.jvcir.2016.03.029
   Myronenko Andriy., 2006, Advances in Neural Information Processing Systems, V19, P1009
   Nakagawa Y, 2016, INT C PAR DISTRIB SY, P1237, DOI [10.1109/ICPADS.2016.0168, 10.1109/ICPADS.2016.166]
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Shih SW, 2008, IEEE T IMAGE PROCESS, V17, P968, DOI 10.1109/TIP.2008.921987
   Shiratori T, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P232, DOI 10.1109/3DV.2015.33
   Tsin Y, 2004, LECT NOTES COMPUT SC, V3023, P558
   Zheng YQ, 2012, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2012.6247828
   Zhongyu Li, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P713, DOI 10.1109/3DV.2014.23
   Zhu J, 2014, OPT ENG, V53, P2468
   Zhu JH, 2016, INT CONF 3D VISION, P102, DOI 10.1109/3DV.2016.85
   Zhu JH, 2014, IET IMAGE PROCESS, V8, P582, DOI 10.1049/iet-ipr.2013.0545
   Zhu JH, 2013, INT J ROBOT AUTOM, V28, P180, DOI 10.2316/Journal.206.2013.2.206-3831
NR 30
TC 11
Z9 16
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10651
EP 10668
DI 10.1007/s11042-017-4704-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900016
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Huang, L
   Luo, B
AF Huang, Lei
   Luo, Bin
TI Video-based salient object detection via spatio-temporal difference and
   coherence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Spatio-temporal difference; Spatio-temporal
   coherence; Saliency propagation
ID IMAGE; REPRESENTATION; TRACKING; MODEL
AB Salient object detection aims to extract the attractive objects in images and videos. It can support various robotics tasks and multimedia applications, such as object detection, action recognition and scene analysis. However, efficient detection of salient objects in videos still faces many challenges as compared to that in still images. In this paper, we propose a novel video-based salient object detection method by exploring spatio-temporal characteristics of video content, i.e., spatial-temporal difference and spatial-temporal coherence. First, we initialize the saliency map for each keyframe by deriving spatial-temporal difference from color cue and motion cue. Next, we generate the saliency maps of other frames by propagating the saliency intra and inter frames with the constraint of spatio-temporal coherence. Finally, the saliency maps of both keyframes and non-keyframes are refined in the saliency propagation. In this way, we can detect salient objects in videos efficiently by exploring their spatio-temporal characteristics. We evaluate the proposed method on two public datasets, named SegTrackV2 and UVSD. The experimental results show that our method outperforms the state-of-the-art methods when taking account of both effectiveness and efficiency.
C1 [Huang, Lei; Luo, Bin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University
RP Luo, B (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
EM leihuang@nju.edu.cn; luobin@nju.edu.cn
RI huang, lei/GQP-8739-2022; Huang, Li/IUQ-0909-2023; HUANG,
   LING/HTR-1819-2023; lu, bin/HPE-4790-2023
FU National Science Foundation of China [61202320]; Research Project of
   Excellent State Key Laboratory [61223003]
FX The authors would like to thank the anonymous reviews for their helpful
   suggestion. This work is supported by National Science Foundation of
   China (61202320) and Research Project of Excellent State Key Laboratory
   (61223003).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], AAAI C ART INT
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 2015, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2015.2487833
   [Anonymous], 2016, P IEEE INT C MULT EX
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2011, Proceedings of the 19th ACM international conference on Multimedia, DOI [DOI 10.1145/2072298.2072344, 10.1145/2072298.2072344.URL, DOI 10.1145/2072298.2072344.URL]
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2012, P 20 ACM INT C MULTI
   [Anonymous], 2016, IEEE T PATTERN ANAL
   [Anonymous], TOMCCAP
   Bao B.-K., 2013, Proceedings of the International Conference on Multimedia Retrieval, P135
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P860, DOI 10.1109/TIP.2012.2219543
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cheng ZY, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1069, DOI 10.1145/2911451.2914765
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Gao Z, 2015, NEUROCOMPUTING, V151, P554, DOI 10.1016/j.neucom.2014.06.085
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hu XL, 2014, 2014 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C 2014), P311, DOI 10.1109/IS3C.2014.88
   Huang CR, 2014, IEEE T CIRC SYST VID, V24, P1336, DOI 10.1109/TCSVT.2014.2308652
   Huang L, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P218, DOI [10.1109/CIS.2016.0058, 10.1109/CIS.2016.57]
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li SZ, 2015, IEEE IMAGE PROC, P4609, DOI 10.1109/ICIP.2015.7351680
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu HT, 2011, IEEE T CIRC SYST VID, V21, P971, DOI 10.1109/TCSVT.2011.2133770
   Liu Y., 2010, ACM Multimedia, P751
   Liu Y, 2011, COMPUT VIS IMAGE UND, V115, P300, DOI 10.1016/j.cviu.2010.10.007
   Liu Z, 2014, IEEE T CIRC SYST VID, V24, P1522, DOI 10.1109/TCSVT.2014.2308642
   Lu HM, 2016, MULTIMED TOOLS APPL, V75, P17081, DOI 10.1007/s11042-015-2977-7
   Lu Hung-Jen, 2014, Biomed Res Int, V2014, P652680, DOI 10.1155/2014/652680
   Nie LQ, 2016, IEEE T CYBERNETICS, V46, P2991, DOI 10.1109/TCYB.2015.2493558
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Ren TW, 2016, MULTIMED TOOLS APPL, V75, P2543, DOI 10.1007/s11042-015-2875-z
   Ren TW, 2009, IEEE INT CON MULTI, P406, DOI 10.1109/ICME.2009.5202520
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang LM, 2016, IEEE T AUTOM SCI ENG, V13, P894, DOI 10.1109/TASE.2015.2418223
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 52
TC 2
Z9 2
U1 5
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10685
EP 10699
DI 10.1007/s11042-017-4822-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900018
DA 2024-07-18
ER

PT J
AU Wang, XH
   Wang, J
   Yan, K
AF Wang, Xiuhui
   Wang, Jun
   Yan, Ke
TI Gait recognition based on Gabor wavelets and (2D)<SUP>2</SUP>PCA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gabor wavelets; Gait energy image; (2D)(2)PCA; Support vector machine
ID HEVC MOTION ESTIMATION; PARALLEL FRAMEWORK; SEQUENCES; WALKING
AB Gait recognition is one of the most important techniques in application areas such as video-based surveillance, human tracking and medical systems. In this study, a novel Gabor wavelets based gait recognition algorithm is proposed, which consists of three steps. First, the gait energy image (GEI) is formed by extracting different orientation and scale information from the Gabor wavelet. Secondly, A two-dimensional principal component analysis ((2D)(2)PCA) method is employed to reduce the feature space dimension. The (2D)(2)PCA method minimizes the within-class distance and maximizes the between-class distance. Last, the multi-class support vector machine (SVM) is adopted to recognize different gaits. Experimental results performed on CASIA gait database show that the proposed gait recognition algorithm is generally robust, and provides higher recognition accuracy comparing with existing methods.
C1 [Wang, Xiuhui; Wang, Jun; Yan, Ke] China Jiliang Univ, Coll Informat Engn, 258 Xueyuan St, Hangzhou 310018, Zhejiang, Peoples R China.
C3 China Jiliang University
RP Yan, K (corresponding author), China Jiliang Univ, Coll Informat Engn, 258 Xueyuan St, Hangzhou 310018, Zhejiang, Peoples R China.
EM keddiyan@gmail.com
RI Wang, Xiuhui/O-5616-2019; Yan, Keyu/IXX-0343-2023
OI Wang, Xiuhui/0000-0003-1773-9760; Yan, Ke/0000-0002-1611-6636
FU National Natural Science Foundation of China (CN) [61303146, 61602431];
   AQSIQ of China [2010QK407]
FX This work is supported by the National Natural Science Foundation of
   China (CN) (No. 61303146, 61602431), and is performed under the auspices
   by the AQSIQ of China (No. 2010QK407).
CR Aggarwal H., 2017, IEEE T COGNITIVE DEV
   [Anonymous], 2016, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Arora P, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P791, DOI 10.1109/SPIN.2015.7095388
   Chen YR, 2016, EXPERT SYST APPL, V64, P93, DOI 10.1016/j.eswa.2016.07.009
   Das Choudhury S, 2015, PATTERN RECOGN, V48, P798, DOI 10.1016/j.patcog.2014.09.022
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Donohue LK, 2012, MINN LAW REV, V97, P407
   Ekinci M, 2007, J COMPUT SCI TECH-CH, V22, P867, DOI 10.1007/s11390-007-9101-z
   Guan Y, 2014, LECT NOTES COMPUT SC, V8897, P209, DOI 10.1007/978-3-319-13386-7_17
   Gupta Jay Prakash, 2013, International Journal of Computer Vision and Image Processing, V3, P31, DOI 10.4018/ijcvip.2013070103
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hossain Emdad, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8227, P721, DOI 10.1007/978-3-642-42042-9_89
   Huang DY, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043039
   Islam MM, 2017, ARCH GYNECOL OBSTET, V295, P1305, DOI 10.1007/s00404-017-4363-3
   Iwama H, 2013, Information and Media Technologies, V5, P163
   Jang-Hee Yoo, 2008, 2008 First Workshops on Image Processing Theory, Tools and Applications (IPTA), DOI 10.1109/IPTA.2008.4743792
   Liu NN, 2010, INT CONF ACOUST SPEE, P1410, DOI 10.1109/ICASSP.2010.5495466
   Lu JW, 2014, IEEE T INF FOREN SEC, V9, P51, DOI 10.1109/TIFS.2013.2291969
   Luo Chuan, 2015, 2015 IEEE Power & Energy Society General Meeting, DOI 10.1109/PESGM.2015.7286345
   Milovanovic M, 2012, 2012 20TH TELECOMMUNICATIONS FORUM (TELFOR), P1323, DOI 10.1109/TELFOR.2012.6419460
   Nandy A, 2015, INT CONF CONTEMP, P443, DOI 10.1109/IC3.2015.7346722
   Preis J., 2012, 1st international workshop on kinect in pervasive computing, pP1
   Raheja JL, 2015, SIGNAL IMAGE VIDEO P, V9, P1357, DOI 10.1007/s11760-013-0588-1
   Ren Y, 2015, MATH PROBL ENG, V501
   Tang J, 2017, IEEE T IMAGE PROCESS, V26, P7, DOI 10.1109/TIP.2016.2612823
   Ukil A, 2007, SUPPORT VECTOR MACHI, V1, P1303
   Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246
   Vishwakarma DK, 2016, AEU-INT J ELECTRON C, V70, P341, DOI 10.1016/j.aeue.2015.12.016
   Vishwakarma DK, 2016, IEEE T COGNITIVE DEV
   [王科俊 Wang Kejun], 2013, [中国图象图形学报, Journal of Image and Graphics], V18, P257
   Yam C., 2009, Enclycopedia of Biometrics, P633, DOI DOI 10.1007/978-0-387-73003-5_37
   Yam CY, 2004, PATTERN RECOGN, V37, P1057, DOI 10.1016/j.patcog.2003.09.012
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yan K, 2017, NEUROCOMPUTING, V228, P205, DOI 10.1016/j.neucom.2016.09.076
   Yan K, 2014, ENERG BUILDINGS, V81, P287, DOI 10.1016/j.enbuild.2014.05.049
   Yu SQ, 2009, IEEE T IMAGE PROCESS, V18, P1905, DOI 10.1109/TIP.2009.2020535
   Zeng W, 2014, COGN COMPUT, V6, P218, DOI 10.1007/s12559-013-9221-4
   Zhang YT, 2015, IEEE T CYBERNETICS, V45, P1864, DOI 10.1109/TCYB.2014.2361287
   Zheng S, 2011, CASIA GAIT DATABASE
NR 40
TC 34
Z9 36
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12545
EP 12561
DI 10.1007/s11042-017-4903-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100040
DA 2024-07-18
ER

PT J
AU Wu, XJ
   Kurths, J
   Kan, HB
AF Wu, Xiangjun
   Kurths, Juergen
   Kan, Haibin
TI A robust and lossless DNA encryption scheme for color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image encryption; Lossless; OCML; DNA computing; Robustness
ID SEQUENCE OPERATION; CHAOTIC SYSTEM; ALGORITHM; MAP; CRYPTANALYSIS
AB In this paper, a new robust and lossless color image encryption algorithm is presented based on DNA sequence operation and one-way coupled-map lattices (OCML). The plain-image is firstly decomposed into three gray-level components and we randomly convert them into three DNA matrices by the DNA encoding rules. Then the XOR operation is performed on the DNA matrices for two times. Next, the shuffled DNA matrices are transformed into three gray images according to the DNA decoding rules. Finally, a diffusion process is further applied to change the image pixel's values by a key stream, and the cipher-image is attained. The key stream generated by OCML is related to the plain-image. Experimental results and security analysis demonstrate that the proposed algorithm has a good encryption effect and can withstand various typical attacks. Furthermore, it is robust against some common image processing operations such as noise adding, cropping, JPEG compression etc.
C1 [Wu, Xiangjun] Henan Univ, Coll Software, Kaifeng 475004, Peoples R China.
   [Wu, Xiangjun; Kan, Haibin] Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China.
   [Wu, Xiangjun; Kurths, Juergen] Humboldt Univ, Dept Phys, D-12489 Berlin, Germany.
   [Kurths, Juergen] Potsdam Inst Climate Impact Res PIK, D-14473 Potsdam, Germany.
C3 Henan University; Fudan University; Humboldt University of Berlin;
   Potsdam Institut fur Klimafolgenforschung
RP Wu, XJ (corresponding author), Henan Univ, Coll Software, Kaifeng 475004, Peoples R China.; Wu, XJ; Kan, HB (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China.; Wu, XJ (corresponding author), Humboldt Univ, Dept Phys, D-12489 Berlin, Germany.
EM wuhsiang@yeah.net; hbkan@fudan.edu.cn
RI Kan, Haibin/AAI-6313-2020
OI Kan, Haibin/0000-0003-3062-5004
FU National Natural Science Foundation of China [61004006, 61203094]; China
   Postdoctoral Science Foundation [2013 M530181, 2015 T80396]; Program for
   Science & Technology Innovation Talents in Universities of Henan
   Province, China [14HASTIT042]; Foundation for University Young Key
   Teacher Program of Henan Province, China [2011GGJS-025]; Shanghai
   Postdoctoral Scientific Program [13R21410600]
FX This research was jointly supported by the National Natural Science
   Foundation of China (Grant Nos 61004006 and 61203094), China
   Postdoctoral Science Foundation (Grant Nos 2013 M530181 and 2015
   T80396), Program for Science & Technology Innovation Talents in
   Universities of Henan Province, China (Grant No 14HASTIT042), the
   Foundation for University Young Key Teacher Program of Henan Province,
   China (Grant No 2011GGJS-025), Shanghai Postdoctoral Scientific Program
   (Grant No 13R21410600).
CR ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   [Anonymous], 2006, SYNTHESIS LECT IMAGE
   Benham CJ, 2005, ANNU REV BIOMED ENG, V7, P21, DOI 10.1146/annurev.bioeng.6.062403.132016
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Clelland CT, 1999, NATURE, V399, P533, DOI 10.1038/21092
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Ge X, 2011, PHYS LETT A, V375, P908, DOI 10.1016/j.physleta.2010.12.065
   Gehani A., 2000, DNA Based Computers V. DIMACS Workshop (Series in Discrete Mathematics and Theoretical Computer Science Vol.54), P233
   Gu GS, 2014, OPTIK, V125, P4700, DOI 10.1016/j.ijleo.2014.05.023
   Head T, 2000, BIOSYSTEMS, V57, P87, DOI 10.1016/S0303-2647(00)00091-5
   Hermassi H, 2012, J SYST SOFTWARE, V85, P2133, DOI 10.1016/j.jss.2012.04.031
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kocarev L., 2001, IEEE Circuits and Systems Magazine, V1, P6, DOI 10.1109/7384.963463
   Li CQ, 2012, NONLINEAR DYNAM, V70, P2383, DOI 10.1007/s11071-012-0626-5
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1035, DOI 10.1016/j.imavis.2008.09.004
   Li P, 2006, PHYS LETT A, V349, P467, DOI 10.1016/j.physleta.2005.09.060
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Liu HJ, 2013, OPTIK, V124, P3527, DOI 10.1016/j.ijleo.2012.10.068
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   MANDELKERN M, 1981, J MOL BIOL, V152, P153, DOI 10.1016/0022-2836(81)90099-1
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Özkaynak F, 2012, OPT COMMUN, V285, P4946, DOI 10.1016/j.optcom.2012.07.106
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Rhouma R, 2009, CHAOS SOLITON FRACT, V40, P309, DOI 10.1016/j.chaos.2007.07.083
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Shyam M, 2007, P 14 IEEE INT C HIGH
   Solak E, 2010, OPT COMMUN, V283, P232, DOI 10.1016/j.optcom.2009.09.070
   Sui LS, 2013, OPT LASER TECHNOL, V48, P530, DOI 10.1016/j.optlastec.2012.11.020
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Tong XJ, 2009, SIGNAL PROCESS, V89, P480, DOI 10.1016/j.sigpro.2008.09.011
   Wang W, 2016, J SENSORS, V2016, DOI 10.1155/2016/2646205
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Xiao GZ, 2006, CHINESE SCI BULL, V51, P1413, DOI 10.1007/s11434-006-2012-5
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
   Zheng XD, 2009, APPL MATH COMPUT, V212, P177, DOI 10.1016/j.amc.2009.02.011
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 58
TC 71
Z9 71
U1 1
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12349
EP 12376
DI 10.1007/s11042-017-4885-5
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100032
DA 2024-07-18
ER

PT J
AU Fritsch, D
   Klein, M
AF Fritsch, Dieter
   Klein, Michael
TI 3D preservation of buildings - Reconstructing the past
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Laser scanning; High Definition Surveying (HDS); Close-range
   photogrammetry; Aerial photogrammetry; Bundle block adjustment;
   Structure-from-Motion (SfM); Dense image matching; 3D reconstructions;
   Rendered architecture
AB The digital reconstruction of buildings is a hot topic in many fields, such as archeology, architecture, civil engineering, computer vision, computer graphics, surveying, photogrammetry and many more. A variety of approaches has been developed and is currently used, in parallel and independent from each other. This paper will bridge the gap between architectural computer graphics using just photos and photogrammetry and laser scanning, which uses digital imagery to get high density coloured point clouds for 3D modelling. It starts with the workflow of laser scanning and photogrammetry and finally delivers 3D Virtual Reality models of buildings. On the other hand, those buildings can be augmented with 3D models reconstructed from old photos using architectural computer graphics to reconstruct the past. The validation and the automation of workflows brings together both disciplines, which will definitely benefit from each other.
C1 [Fritsch, Dieter] Univ Stuttgart, Inst Photogrammetry, Geschwister Scholl Str 24D, D-70174 Stuttgart, Germany.
   [Klein, Michael] 7Reasons GmbH, Baeuerlegasse 4, A-1200 Vienna, Austria.
C3 University of Stuttgart
RP Fritsch, D (corresponding author), Univ Stuttgart, Inst Photogrammetry, Geschwister Scholl Str 24D, D-70174 Stuttgart, Germany.
EM dieter.fritsch@ifp.uni-stuttgart.de
RI Fritsch, Dieter/K-5848-2019
OI Fritsch, Dieter/0000-0001-5069-3915
FU European Union of the project "Four-Dimensional Cultural Heritage World
   (4D-CH-World)", within the Marie Curie Framework
FX This joint paper reflects the successful cooperation within the EU
   4D-CH-World project secondments of the first author at 7reasons GmbH,
   Vienna, working closely with the second author. Both authors gratefully
   acknowledge the funding provided by European Union of the project
   "Four-Dimensional Cultural Heritage World (4D-CH-World)", within the
   Marie Curie Framework.
CR Abdel-Wahab M, 2012, PHOTOGRAMM FERNERKUN, P679, DOI 10.1127/1432-8364/2012/0148
   [Anonymous], 2009, PHOTOGRAMMETRIC WEEK
   [Anonymous], 2013, INT C ADV CIV STRUCT
   [Anonymous], 2006, 2006 IEEE COMP SOC C, DOI [DOI 10.1109/CVPR.2006.12, 10.1109/CVPR.2006.12]
   BRENNER C, 1998, INT ARCH PHOTOGRAMM, V32, P77
   Bustamante A., 2013, THESIS
   Danahy J, 1999, PHOTOGRAMMETRIC WEEK '99, P351
   Debevec P.E., 1996, THESIS
   Farenzena Michela, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1489, DOI 10.1109/ICCVW.2009.5457435
   Fritsch D, 1999, PHOTOGRAMMETRIC WEEK '99, P3
   Fritsch D, 2016, HDB GEODAESIE PHOTOG
   Gibson S, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P37, DOI 10.1109/ISMAR.2002.1115068
   Gill L, 2015, COMPUT ENV URBAN SYS, DOI [10.1016/j.compenvurbs.2015.09.012, DOI 10.1016/J.COMPENVURBS.2015.09.012]
   Haala N, 2010, ISPRS J PHOTOGRAMM, V65, P570, DOI 10.1016/j.isprsjprs.2010.09.006
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hirschmüller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56
   itseez, 2015, OPENCV OP SOURC COMP
   KLOPSCHITZ M, 2010, P 3DPVT
   Moussa W., 2014, THESIS
   Moussa W, 2012, INT ARCH PHOTOGRAMM, V39-B5, P229
   Nistér D, 2000, LECT NOTES COMPUT SC, V1842, P649
   Rothermel M., 2017, THESIS
   Rothermel M., 2012, P LC3D WORKSH BERL, VVolume 8
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Tutzauer P., 2015, PHOTOGRAMMETRIC WEEK, P207
   Vosselman G, 2012, ISPRS J PHOTOGRAMM, V74, P90, DOI 10.1016/j.isprsjprs.2012.09.002
   Wenzel K, 2013, INT ARCH PHOTOGRAMM, V40-5-W1, P251
   Wenzel K, 2016, THESIS
NR 28
TC 25
Z9 26
U1 3
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 9153
EP 9170
DI 10.1007/s11042-017-4654-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800061
DA 2024-07-18
ER

PT J
AU Jung, KH
AF Jung, Ki-Hyun
TI A survey of interpolation-based reversible data hiding methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Information hiding; Reversible data hiding;
   Interpolation; Data hiding
ID IMAGE INTERPOLATION; STEGANOGRAPHIC METHOD; DIFFERENCE EXPANSION; LSB
   SUBSTITUTION; QUALITY; SCHEME; HISTOGRAM; ALGORITHM; PAYLOAD
AB It is called as a reversible data hiding method when the cover object can be restored together with extracting the secret data at a receiver. In reversible data hiding, interpolation-based data hiding methods are recently proposed, where image interpolation techniques are used before embedding the secret data. In this paper, reversible data hiding methods using interpolation techniques are described and analyzed on the embedding capacity and the visual image quality that many researchers have tried to improve these different measurements. It is concluded with the directions of research with some recommendations.
C1 [Jung, Ki-Hyun] Kyungil Univ, Dept Cyber Secur, 50 Gamasil Gil, Gyongsan 38428, Gyeongbuk, South Korea.
C3 Kyungil University
RP Jung, KH (corresponding author), Kyungil Univ, Dept Cyber Secur, 50 Gamasil Gil, Gyongsan 38428, Gyeongbuk, South Korea.
EM khanny.jung@gmail.com
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Education [2015R1D1A1A01058019]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education (No. 2015R1D1A1A01058019).
CR Al-Qershi OM, 2013, SIGNAL PROCESS, V93, P154, DOI 10.1016/j.sigpro.2012.07.012
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], J INF HIDING MULTIME
   CHANG KC, 2007, INTELLIGENT INFORM H, P449
   Chang YT, 2013, J SUPERCOMPUT, V66, P1093, DOI 10.1007/s11227-013-1016-6
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Giannoula A, 2006, IEEE T CIRCUITS-II, V53, P359, DOI 10.1109/TCSII.2006.870213
   Govind PVS, 2016, PROC TECH, V24, P1311, DOI 10.1016/j.protcy.2016.05.129
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Hsiao JY, 2009, SIGNAL PROCESS, V89, P556, DOI 10.1016/j.sigpro.2008.10.018
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Huang HC, 2013, EXPERT SYST APPL, V40, P34, DOI 10.1016/j.eswa.2012.07.010
   Huang LC, 2013, J SYST SOFTWARE, V86, P716, DOI 10.1016/j.jss.2012.11.024
   Jana B, 2016, OPTIK, V127, P3347, DOI 10.1016/j.ijleo.2015.12.055
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2143, DOI 10.1007/s11042-013-1832-y
   Jung KH, 2014, MULTIMED TOOLS APPL, V71, P1455, DOI 10.1007/s11042-012-1293-8
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Kumar M, 2016, SECUR COMMUN NETW, V9, P3703, DOI 10.1002/sec.1575
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lee CF, 2012, DIGIT SIGNAL PROCESS, V22, P941, DOI 10.1016/j.dsp.2012.05.015
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liao X, 2011, J VIS COMMUN IMAGE R, V22, P1, DOI 10.1016/j.jvcir.2010.08.007
   Liu L, 2016, INF TECHNOL J, V13, P2374
   Lu TC., 2016, INT J COMPUT SOFTW E, V1, P102, DOI [10.15344/2456-4451/2016/102, DOI 10.15344/2456-4451/2016/102]
   Lu TC, 2017, OPTIK, V130, P1377, DOI 10.1016/j.ijleo.2016.11.176
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Lu TC, 2015, SIGNAL PROCESS, V108, P77, DOI 10.1016/j.sigpro.2014.08.022
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Luo H, 2011, INFORM SCIENCES, V181, P308, DOI 10.1016/j.ins.2010.09.022
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Malik A., 2016, An image interpolation based reversible data hiding scheme using pixel value adjusting feature. Multimedia Tools and Applications
   Marin J., 2014, J INFORM HIDING MULT, V5, P451
   Nissar A, 2010, DIGIT SIGNAL PROCESS, V20, P1758, DOI 10.1016/j.dsp.2010.02.003
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Tang MW, 2015, AEU-INT J ELECTRON C, V69, P15, DOI 10.1016/j.aeue.2015.08.011
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai YY, 2016, INT J DIGIT CRIME FO, V8, P48, DOI 10.4018/IJDCF.2016040105
   Tsai YY, 2014, KSII T INTERNET INF, V8, P3286, DOI 10.3837/tiis.2014.09.019
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Yang CN, 2017, COMPUT STAND INTER, V50, P209, DOI 10.1016/j.csi.2016.10.005
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 48
TC 26
Z9 26
U1 4
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 7795
EP 7810
DI 10.1007/s11042-017-5066-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800001
DA 2024-07-18
ER

PT J
AU Collares, L
   Tavares, TF
   Gooch, A
   Tzanetakis, G
AF Collares, Leandro
   Tavares, Tiago F.
   Gooch, Amy
   Tzanetakis, George
TI Personalizing self-organizing music spaces with anchors: design and
   evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based music information retrieval; Adaptive music retrieval;
   User study; Subjective and objective metrics
ID COLLECTIONS
AB We propose and evaluate a system for content-based visualization and exploration of music collections. The system is based on a modification of Kohonen's Self-Organizing Map algorithm and allows users to choose the locations of clusters containing acoustically similar tracks on the music space. A user study conducted to evaluate the system shows that the possibility of personalizing the music space was perceived as difficult. Conversely, the user study and objective metrics derived from users' interactions with the interface demonstrate that the proposed system helped individuals create playlists faster and, under some circumstances, more effectively. We believe that personalized browsing interfaces are an important area of research in Multimedia Information Retrieval, and both the system and user study contribute to the growing work in this field.
C1 [Collares, Leandro; Gooch, Amy; Tzanetakis, George] Univ Victoria, Dept Comp Sci, 3800 Finnerty Rd, Victoria, BC V8P 5C2, Canada.
   [Tavares, Tiago F.] Univ Estadual Campinas, Sch Elect & Comp Engn, Campinas, SP, Brazil.
C3 University of Victoria; Universidade Estadual de Campinas
RP Collares, L (corresponding author), Univ Victoria, Dept Comp Sci, 3800 Finnerty Rd, Victoria, BC V8P 5C2, Canada.
EM leandro.collares@gmail.com; tavares@dca.fee.unicamp.br;
   amy.a.gooch@gmail.com; gtzan@cs.uvic.ca
RI Tzanetakis, George/I-6593-2013; Tavares, Tiago/ABG-2421-2020
OI Tzanetakis, George/0000-0002-6844-7912; Fernandes Tavares,
   Tiago/0000-0002-9104-613X
FU Sao Paulo Research Foundation, FAPESP
FX Tiago F. Tavares would like to thank Sao Paulo Research Foundation,
   FAPESP, for funding.
CR [Anonymous], P 6 SOUND MUS COMP C
   Collares L, 2013, P 2013 SOUND MUS COM, P768
   Downie JS, 2003, ANNU REV INFORM SCI, V37, P295, DOI 10.1002/aris.1440370108
   Eisemann Leatrice., 2000, PANTONES GUIDE COMMU
   Giorgetti G, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P293, DOI 10.1109/IPSN.2007.4379689
   Goto M., 2005, P ISMIR, P404
   Holm J, 2009, J NEW MUSIC RES, V38, P87, DOI 10.1080/09298210902940094
   Knees P., 2006, MULTIMEDIA 06 P 14 A, P17, DOI 10.1145/1180639.1180652
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kohonen T., 2001, INFORM SCIENCES
   Kovacevic A, 2010, MULTIMED TOOLS APPL, V47, P525, DOI 10.1007/s11042-009-0336-2
   Laplante Audrey., 2010, Proceedings of the 11th International Society for Music Information Retrieval Conference, P601
   Lee JH, 2004, ISMIR P, P441
   Lillie AS, 2008, THESIS
   Lubbers D., 2005, Proceedings of the International Conference on Music Information Retrieval, P590
   Lubbers D, 2009, P ISMIR, V2009
   Mörchen F, 2006, STUD CLASS DATA ANAL, P724, DOI 10.1007/3-540-31314-1_89
   Muelder C., 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P129, DOI 10.1109/ISM.2010.27
   Neumayer R, 2005, P ISMIR, V5
   Pampalk E., 2002, Proceedings of the tenth ACM international conference on Multimedia, P570, DOI DOI 10.1145/641007.641121
   Rauber A., 2001, Research and Advanced Technology for Digital Libraries. 5th European Conference, ECDL 2001. Proceedings (Lecture Notes in Computer Science Vol.2163), P402
   Rauber A, 1999, RES ADV TECHNOLOGY D, P852
   Sordo M., 2008, ISMIR, P255
   Stober S, 2013, MULTIMED TOOLS APPL, V65, P467, DOI 10.1007/s11042-012-1042-z
   Stober S, 2010, LECT NOTES COMPUT SC, V5811, P53
   Stober Sebastian, 2010, P 7 SOUND MUS COMP C
   Tolos M, 2005, CONSUM COMM NETWORK, P71
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Tzanetakis G., 2009, Proceedings of the seventeen ACM international conference on Multimedia, P931
   Ware C., 2020, INFORM VISUALIZATION
NR 30
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5525
EP 5545
DI 10.1007/s11042-017-4465-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800019
DA 2024-07-18
ER

PT J
AU Hassairi, S
   Ejbali, R
   Zaied, M
AF Hassairi, Salima
   Ejbali, Ridha
   Zaied, Mourad
TI A deep stacked wavelet auto-encoders to supervised feature extraction to
   pattern classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Wavelet network; Pattern classification; Feature
   extraction
ID FAST LEARNING ALGORITHM; NETWORK; AUTOENCODERS
AB The major issue in pattern classification is in the extraction of features in the training phase. The focus of this work is on combining the ability of wavelet networks and the deep learning techniques to propose a new supervised feature extraction method to pattern classification. This new approach allows the classification of all classes of the dataset by the reconstruction of a Deep Stacked wavelet Auto-Encoder. This Network is obtained after a series of wavelet Auto-Encoders followed by a Softmax classifier at the last layer. Finally, a fine-tuning is applied for the improvement of our result using a back propagation algorithm. Our approach is tested with different image datasets which are the COIL-100, the APTI and the ImageNet datasets and is also tested with two other audio corpuses that contain Arabic words and French words. The experimental test demonstrates the efficiency of our network for image and audio classification compared to other methods.
C1 [Hassairi, Salima; Ejbali, Ridha; Zaied, Mourad] RTIM, Gabes, Tunisia.
   [Hassairi, Salima; Ejbali, Ridha; Zaied, Mourad] Natl Engn Sch Sfax ENIS, 1173 BP, Sfax 3038, Tunisia.
C3 Universite de Gabes; Universite de Sfax; Ecole Nationale dIngenieurs de
   Sfax (ENIS)
RP Hassairi, S (corresponding author), RTIM, Gabes, Tunisia.; Hassairi, S (corresponding author), Natl Engn Sch Sfax ENIS, 1173 BP, Sfax 3038, Tunisia.
EM salima.hassairi.tn@ieee.org; ridha_ejbali@ieee.org;
   mourad.zaied@ieee.org
RI Ejbali, Ridha/K-4234-2012
OI Ejbali, Ridha/0000-0002-8148-1621; Hassairi, Salima/0000-0003-3281-6576
FU General Direction of Scientific Research (DGRST), Tunisia under the
   ARUBprogram
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUBprogram.
CR Amin A, 1996, PATTERN RECOGN, V29, P663, DOI 10.1016/0031-3203(95)00110-7
   [Anonymous], 2015, 15 INT C INT SYST DE
   [Anonymous], 2003, INT C SIGNAL SYSTEM
   Ben Amar C, 2005, ADV ENG SOFTW, V36, P459, DOI 10.1016/j.advengsoft.2005.01.013
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Chen ZL, 2014, IEEE INT SYMP CIRC S, P1552, DOI 10.1109/ISCAS.2014.6865444
   Dammak M, 2012, ICAART: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 1, P394, DOI 10.5220/0003775803940399
   Daubechies I., 1992, CBMS-NSF Regional Conf. Series in Appl. Math., V61
   Deng L., 2014, FOND T SIGN PROC, V7, P197, DOI [10.1561/2000000039, DOI 10.1561/2000000039, 10.1561/]
   Ejbali R., 2009, INT C SYST INF PROC
   Ejbali R, 2012, INT J ADV COMPUT SC, V3, P38
   Ejbali R, 2010, KDIR 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND INFORMATION RETRIEVAL, P518
   El Adel A., 2011, 2011 International Conference on Communications, Computing and Control Applications (CCCA), P1
   Eladel A, 2014, NEW SEMANTIC APPROAC, P378
   ElAdel A, 2014, 2014 6TH INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P232, DOI 10.1109/SOCPAR.2014.7008011
   Guedri Boulbaba, 2011, 2011 International Conference on High Performance Computing & Simulation, P369
   Hassairi S, 2015, PROC INT C TOOLS ART, P265, DOI 10.1109/ICTAI.2015.49
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jemai O, 2015, INT C MACH VIS ICMV
   Jemai O, 2010, P INT JT C NEUR NETW, DOI [10.1109/IJCNN.2010.5596876, DOI 10.1109/IJCNN.2010.5596876]
   Jemai O, 2011, INT J PATTERN RECOGN, V25, P1297, DOI 10.1142/S0218001411009111
   Jemai O, 2011, INT J WAVELETS MULTI, V9, P111, DOI 10.1142/S0219691311003967
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   LeCun Y, 2012, LECT NOTES COMPUT SC, V7583, P496, DOI 10.1007/978-3-642-33863-2_51
   Lin YQ, 2011, PROC CVPR IEEE, P1689, DOI 10.1109/CVPR.2011.5995477
   Liou CY, 2014, NEUROCOMPUTING, V139, P84, DOI 10.1016/j.neucom.2013.09.055
   Mejdoub Mahmoud, 2008, 2008 International Workshop on Content-based Multimedia Indexing - CBMI 2008, P365, DOI 10.1109/CBMI.2008.4564970
   Mejdoub M, 2013, MULTIMED TOOLS APPL, V64, P197, DOI 10.1007/s11042-011-0900-4
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   Peng X, 2015, KNOWL-BASED SYST, V90, P14, DOI 10.1016/j.knosys.2015.10.005
   PICONE JW, 1993, P IEEE, V81, P1215, DOI 10.1109/5.237532
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Said S, 2009, IEEE IMAGE PROC, P4153, DOI 10.1109/ICIP.2009.5413446
   Sermanet P, 2012, INT C PATT RECOG, P3288
   Shin HC, 2013, IEEE T PATTERN ANAL, V35, P1930, DOI 10.1109/TPAMI.2012.277
   Slimane F, 2013, PATTERN RECOGN LETT, V34, P209, DOI 10.1016/j.patrec.2012.09.012
   Smagghe P, 2013, ESANN
   Tsai CW, 2014, MOBILE UBIQUITOUS IN, DOI 10.1007/978-3-642-40675-1-93
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Witkowski B, 2015, AUTOENCODERS IMAGE C
   Zaied M., 2012, INT REV COMPUT SOFTW, V7
   Zaied M, 2011, INT J WAVELETS MULTI, V9, P923, DOI 10.1142/S0219691311004389
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   ZHANG QG, 1992, IEEE T NEURAL NETWOR, V3, P889, DOI 10.1109/72.165591
NR 48
TC 14
Z9 16
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5443
EP 5459
DI 10.1007/s11042-017-4461-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800015
DA 2024-07-18
ER

PT J
AU Kim, Y
   Jung, S
   Jung, C
   Kim, C
AF Kim, Yoonhyung
   Jung, Seungjun
   Jung, Chanho
   Kim, Changick
TI A structure-aware axis-aligned grid deformation approach for robust
   image retargeting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retargeting; Quadratic programming; Saliency
   detection; Line segment detection
ID PRESERVING APPROACH
AB Content-based image retargeting is a technique that resizes an input image to a given target resolution while minimizing distortions of important objects caused by aspect ratio variations. Conventional approaches have shared a similar methodology which aims to preserve salient regions as much as possible while allowing distortions of less important regions. Those methods have shown satisfactory results for input images whose objects are distinct and backgrounds are monotonous. However, their performance is not always guaranteed for images containing structural components such as straight lines, which are prone to be distorted after resizing and sensitive to human visual perception. In this paper, we propose a structure-aware axis-aligned grid deformation approach for robust image retargeting. Based on axis-aligned grid, our method finds the optimal grid for target image by quadratic optimization represented by two objective functions. The first one is the As-similar-as-possible (ASAP) energy function, which aims to preserve important regions while allowing distortions of trivial regions. The second one is the Adaptive Laplacian regularization (ALR) energy function, which aims to relieve structural distortions. Those two energy functions are combined into single quadratic optimization model ensuring the global convexity and solved by a quadratic programming solver for finding the optimal grid. Experimental results show that our method is robust to structural distortions while achieving the basic purpose of content-based image retargeting. For objective comparisons with other methods, we have provided objective evaluation scores by using a recent state-of-the-art image retargeting quality assessment scheme.
C1 [Kim, Yoonhyung; Jung, Seungjun; Kim, Changick] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.
   [Jung, Chanho] Hanbat Natl Univ, Dept Elect Engn, Daejeon 34158, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Hanbat
   National University
RP Kim, C (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.
EM yhkim1127@kaist.ac.kr; seungjun45@kaist.ac.kr; peterjung@hanbat.ac.kr;
   changick@kaist.ac.kr
RI Kim, Changick/C-1779-2011
FU Hancom Co., Ltd.
FX This work was supported by Hancom Co., Ltd.
CR [Anonymous], 2016, ARXIV161009462
   [Anonymous], ARXIV161101872
   [Anonymous], ISANDAMP T SPIE ELEC
   [Anonymous], 2007, 2007 IEEE 11 INT C C, DOI DOI 10.1109/ICCV.2007.4409010
   [Anonymous], 2016, ADV MATER SCI ENG
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Chang CH, 2012, PROC CVPR IEEE, P1075, DOI 10.1109/CVPR.2012.6247786
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Choi J, 2016, J SIGNAL PROCESS SYS, V85, P275, DOI 10.1007/s11265-015-1084-3
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Das BC, 2016, IEEE IMAGE PROC, P1584, DOI 10.1109/ICIP.2016.7532625
   Dong WM, 2016, IEEE T VIS COMPUT GR, V22, P1088, DOI 10.1109/TVCG.2015.2440255
   Fang Y, 2016, IEEE T SYST MAN CYBE
   Gaspero L, 2007, QUADRATIC PROGRAMMIN
   Guo YW, 2009, IEEE T MULTIMEDIA, V11, P856, DOI 10.1109/TMM.2009.2021781
   Hsu CC, 2014, IEEE J-STSP, V8, P377, DOI 10.1109/JSTSP.2014.2311884
   Hu WY, 2014, IEEE J EM SEL TOP C, V4, P70, DOI 10.1109/JETCAS.2014.2298259
   Kim W, 2012, OPT LETT, V37, P1550, DOI 10.1364/OL.37.001550
   Liang Y, 2013, IET IMAGE PROCESS, V7, P61, DOI 10.1049/iet-ipr.2012.0308
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu T, 2007, IEEE COMPUTER VISION, P353
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu Y., 2016, Sheet Met. Weld. Conf. XVII, P1, DOI DOI 10.1155/2016/8141269
   Panozzo D, 2012, COMPUT GRAPH FORUM, V31, P229, DOI 10.1111/j.1467-8659.2012.03001.x
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   Wang SF, 2009, INT CONF ACOUST SPEE, P1049, DOI 10.1109/ICASSP.2009.4959767
   Wei J, 2012, IEEE T VIS COMPUT GR, V18, P1771, DOI 10.1109/TVCG.2011.130
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Zhang GX, 2009, COMPUT GRAPH FORUM, V28, P1897, DOI 10.1111/j.1467-8659.2009.01568.x
   Zhang YC, 2016, IEEE IMAGE PROC, P1813, DOI 10.1109/ICIP.2016.7532671
NR 38
TC 13
Z9 15
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7717
EP 7739
DI 10.1007/s11042-017-4674-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700058
DA 2024-07-18
ER

PT J
AU Ma, X
   Lei, XJ
   Zhao, GS
   Qian, XM
AF Ma, Xiang
   Lei, Xiaojiang
   Zhao, Guoshuai
   Qian, Xueming
TI Rating prediction by exploring user's preference and sentiment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data mining; Recommender system; Reviews; User interest; User sentiment
ID SEARCH; NMF
AB With the development of e-commerce, shopping on-line is becoming more and more popular. The explosion of reviews have led to a serious problem, information overloading. How to mine user interest from these reviews and understand users' preference is crucial for us. Traditional recommender systems mainly use structured data to mine user interest preference, such as product category, user's tag, and the other social factors. In this paper, we firstly use LDA+Word2vec model to mine user interest. Then, we propose a social user sentimental measurement approach. At last, three factors, including user topic, user sentiment and interpersonal influence, are fused into a recommender system (RS) based on probabilistic matrix factorization. We conduct a series of experiments on Yelp dataset, and experimental results show the proposed approach outperforms the existing approaches.
C1 [Ma, Xiang] Changan Univ, Sch Informat Engn, Xian, Shaanxi, Peoples R China.
   [Lei, Xiaojiang; Zhao, Guoshuai; Qian, Xueming] Xi An Jiao Tong Univ, Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian 710049, Shaanxi, Peoples R China.
C3 Chang'an University; Xi'an Jiaotong University
RP Qian, XM (corresponding author), Xi An Jiao Tong Univ, Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian 710049, Shaanxi, Peoples R China.
EM maxiangmail@163.com; xiaolei3439@stu.xjtu.edu.cn;
   zgs2012@stu.xjtu.edu.cn; qianxm@mail.xjtu.edu.cn
RI Zhao, Guoshuai/AAN-1271-2020
OI Zhao, Guoshuai/0000-0003-4392-8450
FU NSFC [61572083]; China Fundamental Research Funds for the Central
   Universities [310824153508, 310824173401]
FX This work is partly supported by the NSFC under 61572083, the China
   Fundamental Research Funds for the Central Universities under Grant
   310824153508 and 310824173401 (Chang'an University).
CR [Anonymous], 2016, ARXIV161009462
   [Anonymous], 2006, P 5 INT C LANG RES E
   [Anonymous], 2014, P INT C INT C MACH L
   [Anonymous], P IEEE INT C MULT BI
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421
   Feng H, 2014, NEUROCOMPUTING, V129, P409, DOI 10.1016/j.neucom.2013.09.018
   Fu Z., 2016, 2016 UKACC 11 INT C, P1
   Fu ZJ, 2019, IEEE T SERV COMPUT, V12, P813, DOI 10.1109/TSC.2016.2622697
   Fu ZJ, 2016, IEEE T PARALL DISTR, V27, P2546, DOI 10.1109/TPDS.2015.2506573
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Gu B, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3532
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Gu Y, 2015, IEEE T IMAGE PROCESS, V24, P3450, DOI 10.1109/TIP.2015.2443501
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Jamali M., 2010, P 4 ACM C REC SYST, P135, DOI DOI 10.1145/1864708.1864736
   Jiang Meng, 2012, P 21 ACM INT C INFOR, P45
   Jiang SH, 2015, IEEE T MULTIMEDIA, V17, P907, DOI 10.1109/TMM.2015.2417506
   Kong Y, 2017, KNOWL-BASED SYST, V115, P123, DOI 10.1016/j.knosys.2016.10.016
   Lei XJ, 2016, IEEE T MULTIMEDIA, V18, P1910, DOI 10.1109/TMM.2016.2575738
   Li F., 2011, Proceedings of the Twenty-Second International joint Conference on Artificial Intelligence, V3, P1820
   Li XL, 2016, IEEE T IMAGE PROCESS, V25, P3329, DOI 10.1109/TIP.2016.2568752
   Li XL, 2016, IEEE T IMAGE PROCESS, V25, P740, DOI 10.1109/TIP.2015.2507942
   Lin YH, 2012, TOUR MANAG PERSPECT, V2-3, P35, DOI 10.1016/j.tmp.2012.01.002
   Lin ZY, 2017, PUBLIC TRANSPORT, V9, P137, DOI 10.1007/s12469-016-0138-7
   Ling G, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P105, DOI 10.1145/2645710.2645728
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Q, 2016, SECUR COMMUN NETW, V9, P4002, DOI 10.1002/sec.1582
   Liu Y, 2010, INT C VIRT SYST MULT
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y.-S., 2015, Sci. World J, V2015, P2, DOI DOI 10.1016/J.LINDIF.2015.02.002
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lou PL, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P33, DOI 10.1109/BigMM.2016.38
   Lu D, 2016, IEEE T MULTIMEDIA, V18, P1628, DOI 10.1109/TMM.2016.2568099
   Lu F, 2015, PROCEEDINGS OF THE 2015 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS), P167, DOI 10.1109/NAS.2015.7255214
   Lu X, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P843, DOI 10.1145/2600428.2609455
   Lu XQ, 2017, IEEE T CYBERNETICS, V47, P884, DOI 10.1109/TCYB.2016.2531179
   Lu XQ, 2017, IEEE T IMAGE PROCESS, V26, P355, DOI 10.1109/TIP.2016.2627801
   Lu XQ, 2015, IEEE T CYBERNETICS, V45, P1967, DOI 10.1109/TCYB.2014.2362959
   Lu XQ, 2014, IEEE T GEOSCI REMOTE, V52, P2746, DOI 10.1109/TGRS.2013.2265322
   Lu XQ, 2014, IEEE T CYBERNETICS, V44, P149, DOI 10.1109/TCYB.2013.2286496
   Lu XQ, 2013, IEEE T GEOSCI REMOTE, V51, P4009, DOI 10.1109/TGRS.2012.2226730
   Lu XQ, 2013, IEEE T GEOSCI REMOTE, V51, P2815, DOI 10.1109/TGRS.2012.2213825
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Luo WJ, 2014, IEEE DATA MINING, P380, DOI 10.1109/ICDM.2014.14
   Ma TH, 2015, IEICE T INF SYST, VE98D, P902, DOI 10.1587/transinf.2014EDP7283
   Martin JP, 2009, IEEE NUCL SCI CONF R, P258
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Mnih A., 2007, ADV NEURAL INFORM PR, V20
   Nakagawa T., 2010, HUMAN LANGUAGE TECHN, P786
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pang B., 2004, ANN M ASS COMP LING, P271, DOI [10.3115/1218955.1218990, DOI 10.3115/1218955.1218990]
   Qian XM, 2017, IEEE T MULTIMEDIA, V19, P813, DOI 10.1109/TMM.2016.2638207
   Qian XM, 2014, IEEE T KNOWL DATA EN, V26, P1763, DOI 10.1109/TKDE.2013.168
   Qu L., 2010, COLING, P913
   Ren YJ, 2015, J INTERNET TECHNOL, V16, P317, DOI 10.6138/JIT.2015.16.2.20140918
   Rosen-Zvi M, 2010, ACM T INFORM SYST, V28, DOI 10.1145/1658377.1658381
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Shuhui Jiang, 2016, IEEE Transactions on Big Data, V2, P43, DOI 10.1109/TBDATA.2016.2541160
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tan SL, 2014, IEEE T KNOWL DATA EN, V26, P1158, DOI 10.1109/TKDE.2013.116
   Tang DY, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1014
   Wang LX, 2013, PROCEEDINGS OF 2013 INTERNATIONAL SYMPOSIUM - WOMEN'S SURVIVAL AND DEVELOPMENT IN CURRENT CULTURAL ENVIRONMENT, P23
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Xu JN, 2012, INT CONF E BUS ENG, P9, DOI 10.1109/ICEBE.2012.12
   Yang Xiwang., 2012, P 18 ACM SIGKDD INT, P1267, DOI [10.1145/2339530.2339728, DOI 10.1145/2339530.2339728]
   Yao XW, 2016, IEEE T GEOSCI REMOTE, V54, P3660, DOI 10.1109/TGRS.2016.2523563
   Yuan Y, 2017, IEEE T IMAGE PROCESS, V26, P51, DOI 10.1109/TIP.2016.2617462
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang DW, 2016, IEEE T NEUR NET LEAR, V27, P1163, DOI 10.1109/TNNLS.2015.2495161
   Zhang W, 2013, ACM T INTEL SYST TEC, V4, P1199
   Zhang YF, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P83, DOI 10.1145/2600428.2609579
   Zhao GS, 2017, IEEE T BIG DATA, V3, P67, DOI 10.1109/TBDATA.2016.2552541
   Zhao GS, 2016, IEEE T KNOWL DATA EN, V28, P3382, DOI 10.1109/TKDE.2016.2607172
   Zhao GS, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P228, DOI 10.1109/BigMM.2015.67
   Zhao GS, 2016, IEEE T MULTIMEDIA, V18, P496, DOI 10.1109/TMM.2016.2515362
NR 81
TC 23
Z9 24
U1 2
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6425
EP 6444
DI 10.1007/s11042-017-4550-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700001
DA 2024-07-18
ER

PT J
AU Yan, DQ
   Chu, YH
   Li, LN
   Liu, DS
AF Yan, Deqin
   Chu, Yonghe
   Li, Lina
   Liu, Deshan
TI Hyperspectral remote sensing image classification with information
   discriminative extreme learning machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extreme learning machine; Pattern recognition; Hyperspectral remote
   sensing image; Discrimination information
ID SUPPORT VECTOR MACHINES; NEAREST-NEIGHBOR; REPRESENTATION; REGRESSION
AB Hyperspectral remote sensing image classification is important aspect of current research. Extreme learning machine (ELM) has been widely used in the field of pattern recognition for its efficient and good generalization performance. With the study of hyperspectral remote sensing image classification, this paper proposes an information discriminative extreme learning machine (IELM). IELM inherits the advantages of ELM, can solve the problems that ELM learning is insufficient for hyperspectral remote sensing image with limited scale of sample data. The proposed algorithm is tested by experiments for hyperspectral remote sensing image classification. The experiment results show that the proposed algorithm has better classification effect.
C1 [Yan, Deqin; Chu, Yonghe; Li, Lina; Liu, Deshan] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116081, Peoples R China.
C3 Liaoning Normal University
RP Yan, DQ (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116081, Peoples R China.
EM yandeqin@163.com
RI Li, Lina/Q-9088-2018
FU National Natural Science Foundation of China [61105085]; Science
   Foundation of education ministry of Liaoning province [L2014427]
FX The work was supported by National Natural Science Foundation of China
   (61105085) and Science Foundation of education ministry of Liaoning
   province (L2014427).
CR Baassou B, 2013, INT CONF GEOINFORM
   Bazi Y, 2014, IEEE GEOSCI REMOTE S, V11, P1066, DOI 10.1109/LGRS.2013.2286078
   Bruzzone L, 2006, IEEE T GEOSCI REMOTE, V44, P3363, DOI 10.1109/TGRS.2006.877950
   Camps-Valls G, 2006, IEEE GEOSCI REMOTE S, V3, P93, DOI 10.1109/LGRS.2005.857031
   Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154
   Di W, 2011, IEEE J-STSP, V5, P618, DOI 10.1109/JSTSP.2011.2123077
   Dias JM, 2010, INVESTIGACAO, P1, DOI 10.14195/978-989-26-0193-9
   Gualtieri JA, 1999, P SOC PHOTO-OPT INS, V3584, P221, DOI 10.1117/12.339824
   Heras DB, 2014, INT J REMOTE SENS, V35, P401, DOI 10.1080/01431161.2013.869633
   Huang GB, 2014, COGN COMPUT, V6, P376, DOI 10.1007/s12559-014-9255-2
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jun G, 2013, IEEE T GEOSCI REMOTE, V51, P273, DOI 10.1109/TGRS.2012.2198654
   Li H., 2003, Adv. Neural Inf. Process. Syst, V16
   Li J, 2013, IEEE GEOSCI REMOTE S, V10, P318, DOI 10.1109/LGRS.2012.2205216
   Li W, 2015, IEEE GEOSCI REMOTE S, V12, P389, DOI 10.1109/LGRS.2014.2343956
   Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583
   Lu XQ, 2017, IEEE T CYBERNETICS, V47, P884, DOI 10.1109/TCYB.2016.2531179
   Ma L, 2010, IEEE T GEOSCI REMOTE, V48, P4099, DOI 10.1109/TGRS.2010.2055876
   Man ZH, 2012, IEEE T NEUR NET LEAR, V23, P1974, DOI 10.1109/TNNLS.2012.2218616
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Pal M, 2013, REMOTE SENS LETT, V4, P619, DOI 10.1080/2150704X.2013.777485
   Pal M, 2009, INT J REMOTE SENS, V30, P3835, DOI 10.1080/01431160902788636
   Peng Y, 2015, NEUROCOMPUTING, V149, P340, DOI 10.1016/j.neucom.2013.12.065
   Pu HY, 2014, IEEE T GEOSCI REMOTE, V52, P7008, DOI 10.1109/TGRS.2014.2306687
   Rajan S, 2008, IEEE T GEOSCI REMOTE, V46, P1231, DOI 10.1109/TGRS.2007.910220
   Rajesh R., 2011, International Journal of Wisdom Based Computing, P35
   Rong HJ, 2009, IEEE T SYST MAN CY B, V39, P1067, DOI 10.1109/TSMCB.2008.2010506
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Samat A, 2014, IEEE J-STARS, V7, P1060, DOI 10.1109/JSTARS.2014.2301775
   Sami ul Haq Q, 2011, P INT C COMP SCI NET, P241
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Tao DP, 2013, IEEE T MULTIMEDIA, V15, P833, DOI 10.1109/TMM.2013.2238909
   Tarabalka Y, 2009, IEEE T GEOSCI REMOTE, V47, P2973, DOI 10.1109/TGRS.2009.2016214
   Wang DH, 2005, IEEE IJCNN, P1406
   Wang Q, 2016, IEEE T NEUR NET LEAR, V27, P1279, DOI 10.1109/TNNLS.2015.2477537
   Yu Q, 2013, NEUROCOMPUTING, V102, P45, DOI 10.1016/j.neucom.2012.02.040
   Yuan Y, 2016, IEEE T CYBERNETICS, V46, P2966, DOI 10.1109/TCYB.2015.2484324
   Zhao JW, 2012, NEUROCOMPUTING, V87, P79, DOI 10.1016/j.neucom.2012.02.003
   Zhou YC, 2016, IEEE T CYBERNETICS, V46, P1667, DOI 10.1109/TCYB.2015.2453359
   Zong WW, 2013, NEUROCOMPUTING, V101, P229, DOI 10.1016/j.neucom.2012.08.010
NR 41
TC 7
Z9 7
U1 9
U2 85
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5803
EP 5818
DI 10.1007/s11042-017-4494-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800030
DA 2024-07-18
ER

PT J
AU Zerrouki, N
   Houacine, A
AF Zerrouki, Nabil
   Houacine, Amrane
TI Combined curvelets and hidden Markov models for human fall detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human fall classification; Video monitoring; Curvelet transform; Hidden
   Markov Model
ID DIFFERENTIAL EVOLUTION; DETECTION SYSTEM; CLASSIFICATION; RECOGNITION;
   HEVC; INTELLIGENT; FEATURES; WAVELET; VIDEO
AB Fall events detection is one of the most crucial issues in the health care of elderly people. This paper proposes an innovative approach for reliably detecting fall incidents based on human silhouette shape variation in vision monitoring. This mission is achieved by: (i) introducing the curvelet transform and area ratios for identifying human postures in images; (ii) reducing the feature vector dimension using differential evolution technique; (iii) identifying postures by a support vector machine, and (iv) adapting a hidden Markov model for classifying video sequences into non-fall and fall events. Experimental results are obtained on several "Fall Detection" datasets. For evaluation, several assessment measures are computed. These evaluation measures demonstrate the effectiveness of the proposed methodology when compared to some state-of-the-art approaches.
C1 [Zerrouki, Nabil; Houacine, Amrane] Univ Sci & Technol Houari Boumedienne, Fac Elect & Comp Sci, LCPTS, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Zerrouki, N (corresponding author), Univ Sci & Technol Houari Boumedienne, Fac Elect & Comp Sci, LCPTS, Algiers, Algeria.
EM nzerrouki@usthb.dz; ahouacine@usthb.dz
CR Alhimale L, 2014, APPL SOFT COMPUT, V18, P59, DOI 10.1016/j.asoc.2014.01.024
   Anderson Derek, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P6388
   [Anonymous], WHO GLOB REP FALLP
   Auvinet E, 2011, IEEE T INF TECHNOL B, V15, P290, DOI 10.1109/TITB.2010.2087385
   BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196
   Bourke AK, 2007, GAIT POSTURE, V26, P194, DOI 10.1016/j.gaitpost.2006.09.012
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Charfi I, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P218, DOI 10.1109/SITIS.2012.155
   Chen YN, 2014, FALL DETECTION DUSKY, P1131
   Chien SY, 2002, IEEE T CIRC SYST VID, V12, P577, DOI 10.1109/TCSVT.2002.800516
   Das S, 2011, IEEE T EVOLUT COMPUT, V15, P4, DOI 10.1109/TEVC.2010.2059031
   Doukas C, 2009, INT FED INFO PROC, P185
   Foroughi H, 2008, 2008 11TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY: ICCIT 2008, VOLS 1 AND 2, P540
   Giannakouris K., 2008, Population and social conditions, Data in focus
   Hand DJ, 2012, INT STAT REV, V80, P400, DOI 10.1111/j.1751-5823.2012.00183.x
   Hiremath PS, 2006, INT J COMPUT SCI NET, V6, P124
   Kwolek B, 2015, NEUROCOMPUTING, V168, P637, DOI 10.1016/j.neucom.2015.05.061
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Lee T, 2005, J TELEMED TELECARE, V11, P194, DOI 10.1258/1357633054068946
   Li Y, 2012, IEEE T BIO-MED ENG, V59, P1291, DOI 10.1109/TBME.2012.2186449
   Muller Meinard., 2006, P ACM SIGGRAPHEUROGR, P137
   Ma X, 2014, IEEE J BIOMED HEALTH, V18, P1915, DOI 10.1109/JBHI.2014.2304357
   Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419
   Majumdar A, 2007, J PATTERN RECOGNIT R, V2, P17, DOI 10.13176/11.27
   Malathi T, 2016, SMART INNOV SYST TEC, V43, P181, DOI 10.1007/978-81-322-2538-6_19
   Olivieri DN, 2012, EXPERT SYST APPL, V39, P5935, DOI 10.1016/j.eswa.2011.11.109
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Rougier C, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P875, DOI 10.1109/ainaw.2007.181
   Rougier C, 2010, LECT NOTES COMPUT SC, V6134, P505, DOI 10.1007/978-3-642-13681-8_59
   Shoushtarian B, 2005, PATTERN RECOGN LETT, V26, P5, DOI 10.1016/j.patrec.2004.07.013
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Uçar A, 2016, NEURAL COMPUT APPL, V27, P131, DOI 10.1007/s00521-014-1569-1
   Vapnik V., 1998, STAT LEARNING THEORY, V3
   Vapnik V., 1999, NATURE STAT LEARNING
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yu M, 2012, IEEE T INF TECHNOL B, V16, P1274, DOI 10.1109/TITB.2012.2214786
   Yun YX, 2015, IEEE IMAGE PROC, P3280, DOI 10.1109/ICIP.2015.7351410
   Zerrouki N, 2014, LECT NOTES COMPUT SC, V8814, P329, DOI 10.1007/978-3-319-11758-4_36
   Zerrouki N, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0639-6
   Zhang D, 2009, INT J PATTERN RECOGN, V23, P521, DOI 10.1142/S0218001409007260
   Zigel Y, 2009, IEEE T BIO-MED ENG, V56, P2858, DOI 10.1109/TBME.2009.2030171
NR 44
TC 44
Z9 48
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6405
EP 6424
DI 10.1007/s11042-017-4549-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800060
DA 2024-07-18
ER

PT J
AU Hao, T
   Wang, Q
   Wu, D
   Sun, JS
AF Hao, Tong
   Wang, Qian
   Wu, Dan
   Sun, Jin-Sheng
TI Multiple person tracking based on slow feature analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple person tracking; Object tracking; Slow feature analysis
ID MODEL; EXTRACTION; OCCLUSION
AB Object tracking is one of the most important components in numerous applications of computer vision. However, it still has many challenges to be solved, such as occlusion, matching, data association, etc. In this paper, we proposed to utilize slow feature analysis (SFA) method to handle the multiple person tracking problem. First, the part-based model is utilized to detect pedestrian in each frame. Then, a set of reliable tracklets is generated by utilizing spatial-temporal information of detection results. Third, SFA method is leveraged to extract slow-feature for these reliable tracklets. Finally, the traditional graph matching method is utilized to handle data association problem and consequently generate the final trajectory for individual tracking object. Some popular datasets are used in this study. The extensive comparison experiments demonstrate the superiority of the proposed method.
C1 [Hao, Tong; Wang, Qian; Wu, Dan; Sun, Jin-Sheng] Tianjin Normal Univ, Tianjin Key Lab Anim & Plant Resistance, Coll Life Sci, Tianjin 300387, Peoples R China.
   [Sun, Jin-Sheng] Tianjin Bohai Fisheries Res Inst, Tianjin 300221, Peoples R China.
C3 Tianjin Normal University
RP Hao, T (corresponding author), Tianjin Normal Univ, Tianjin Key Lab Anim & Plant Resistance, Coll Life Sci, Tianjin 300387, Peoples R China.
EM joyht2001@163.com
FU National High-Tech Research and Development Program of China (program
   863) [2012AA10A401]; Grants of the Major State Basic Research
   Development Program of China (program 973) [2012CB114405]; National Key
   Technology RD Program [2011BAD13B07, 2011BAD13B04]; National Natural
   Science Foundation of China [31770904, 21106095]; Natural Science
   Foundation of Tianjin [15JCYBJC30700]; project of introducing one
   thousand high level talents in three years [5KQM110003]; Foundation for
   Introducing Talents to Tianjin Normal University [5RL123]; Academic
   Innovation Promotion Project of Tianjin Normal University for young
   teachers [52XC1403]; 131 Innovative Talents Cultivation of Tianjin
   [ZX110170]; Tianjin Normal University Application and Development
   Program [52XK1502]
FX This work was supported by the National High-Tech Research and
   Development Program of China (program 863, 2012AA10A401), the Grants of
   the Major State Basic Research Development Program of China (program
   973, 2012CB114405), the National Key Technology R&D Program
   (2011BAD13B07 and 2011BAD13B04), the National Natural Science Foundation
   of China (31770904, 21106095), the Natural Science Foundation of Tianjin
   (15JCYBJC30700), the project of introducing one thousand high level
   talents in three years (5KQM110003), the Foundation for Introducing
   Talents to Tianjin Normal University (5RL123), the Academic Innovation
   Promotion Project of Tianjin Normal University for young teachers
   (52XC1403), the 131 Innovative Talents Cultivation of Tianjin (ZX110170)
   and Tianjin Normal University Application and Development Program
   (52XK1502).
CR [Anonymous], 2008, 2008 IEEE COMP SOC C
   [Anonymous], 6 IEEE INT WORKSH PE
   [Anonymous], 2001, Convergence analysis of complementary candid incremental principal component analysis
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], ICPR
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   [Anonymous], 2008, CVPR
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159
   Bazzani L, 2012, PROC CVPR IEEE, P1886, DOI 10.1109/CVPR.2012.6247888
   Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Cheng Luo, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P359, DOI 10.1109/MMSP.2008.4665104
   Gall J, 2009, PROC CVPR IEEE, P1022, DOI 10.1109/CVPRW.2009.5206740
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Gorur P., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P386, DOI 10.1109/AVSS.2011.6027356
   Granström K, 2013, 2013 16TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1534
   Granström K, 2012, IEEE T SIGNAL PROCES, V60, P5657, DOI 10.1109/TSP.2012.2212888
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Leal-Taixé L, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130233
   Li Z, 2010, IEICE T INF SYST, VE93D, P1263, DOI 10.1587/transinf.E93.D.1263
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Makris A, 2014, IEEE T GEOSCI REMOTE, V52, P7684, DOI 10.1109/TGRS.2014.2316600
   Marcenaro L, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P464, DOI 10.1109/AVSS.2012.86
   Muyun Weng, 2010, 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P285, DOI 10.1109/CISP.2010.5648259
   Nie WZ, 2017, NEUROCOMPUTING, V252, P49, DOI 10.1016/j.neucom.2016.01.125
   Nie WZ, 2014, NEUROCOMPUTING, V139, P220, DOI 10.1016/j.neucom.2014.02.040
   Nie WZ, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P481, DOI 10.1109/AVSS.2012.89
   OJA E, 1992, NEURAL NETWORKS, V5, P927, DOI 10.1016/S0893-6080(05)80089-9
   OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687
   Ottlik A, 2008, INT J COMPUT VISION, V80, P211, DOI 10.1007/s11263-007-0112-6
   Pellegrini S, 2010, LECT NOTES COMPUT SC, V6311, P452, DOI 10.1007/978-3-642-15549-9_33
   Peng DZ, 2007, NEURAL NETWORKS, V20, P842, DOI 10.1016/j.neunet.2007.07.001
   Pérez P, 2004, P IEEE, V92, P495, DOI 10.1109/JPROC.2003.823147
   SCHMIDHUBER J, 1993, NEURAL COMPUT, V5, P625, DOI 10.1162/neco.1993.5.4.625
   Shu G, 2012, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2012.6247879
   Tu JL, 2006, LECT NOTES COMPUT SC, V3851, P694
   Wen LY, 2016, IEEE T PATTERN ANAL, V38, P1983, DOI 10.1109/TPAMI.2015.2509979
   Weng JY, 2003, IEEE T PATTERN ANAL, V25, P1034, DOI 10.1109/TPAMI.2003.1217609
   Yamaguchi K, 2011, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2011.5995468
   Zhu L, 2008, PATTERN RECOGN, V41, P2447, DOI 10.1016/j.patcog.2008.01.014
NR 48
TC 8
Z9 8
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3623
EP 3637
DI 10.1007/s11042-017-5218-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600039
DA 2024-07-18
ER

PT J
AU Zhang, WB
   Hou, XR
AF Zhang, Wenbo
   Hou, Xiaorong
TI Light source point cluster selection-based atmospheric light estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Statistics clustering; Atmospherice light; Transmissivity; Defogging;
   Image quality
ID RING PARTITION; IMAGE
AB The atmospheric light value is a critical parameter in defogging algorithms that are based on atmospheric scattering models. Any error in the atmospheric light value will impact directly on the accuracy of scattering computation and thus cause chromatic distortions in the restored images. To address this problem, this paper proposes a method that relies on clustering statistics to estimate the atmospheric light value. It starts by selecting in the original image some potential atmospheric light source points, which are grouped into point clusters using a clustering technique. From these clusters, several clusters containing candidate atmospheric light source points are selected; the points are then analyzed statistically, and the cluster containing the most candidate points is used for estimating the atmospheric light value. The mean brightness vector of the candidate atmospheric light points in the chosen point cluster is used as the estimate of the atmospheric light value, and their geometric center in the image is accepted as the location of atmospheric light. The experimental results suggest that this statistical clustering method produces more accurate atmosphere brightness vectors and light source locations. This accuracy translates to, from a subjective perspective, both a more natural defogging effect and improvements in various objective image quality indicators.
C1 [Zhang, Wenbo; Hou, Xiaorong] Univ Elect Sci & Technol China, Sch Energy Sci & Engn, Chengdu, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Zhang, WB (corresponding author), Univ Elect Sci & Technol China, Sch Energy Sci & Engn, Chengdu, Sichuan, Peoples R China.
EM Stroot@163.com; houxr@uestc.edu.cn
OI Zhang, Wenbo/0000-0001-8590-8832
CR Agaian S.S., 2000, IASTED INT C SIGNAL, P19
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Cozman F, 1997, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.1997.609419
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hongyu Zhao, 2015, IEEE/CAA Journal of Automatica Sinica, V2, P158, DOI 10.1109/JAS.2015.7081655
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Narasimhan SG, 2003, IEEE WORKSH COL PHOT, V1, P6
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Oakley JP, 1998, IEEE T IMAGE PROCESS, V7, P167, DOI 10.1109/83.660994
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   Wang YK, 2014, IEEE T IMAGE PROCESS, V23, P4826, DOI 10.1109/TIP.2014.2358076
   [吴迪 Wu Di], 2015, [自动化学报, Acta Automatica Sinica], V41, P221
   Zhang L, 2015, 2015 FIRST INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE THEORY, SYSTEMS AND APPLICATIONS (CCITSA 2015), P177, DOI 10.1109/CCITSA.2015.55
   Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
NR 23
TC 8
Z9 11
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 2947
EP 2958
DI 10.1007/s11042-017-4547-7
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600002
DA 2024-07-18
ER

PT J
AU Deshmukh, M
   Nain, N
   Ahmed, M
AF Deshmukh, Maroti
   Nain, Neeta
   Ahmed, Mushtaq
TI Efficient and secure multi secret sharing schemes based on boolean XOR
   and arithmetic modulo
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi secret sharing (MSS) scheme; Boolean XOR; Arithmetic modulo;
   Similarity metrics; Attacks
ID RANDOM GRIDS; OPERATIONS
AB Multi Secret Sharing (MSS) scheme is an efficient method of transmitting more than one secret securely. In (n, n)-MSS scheme n secrets are used to create n shares and for reconstruction, all n shares are required. In state of the art schemes n secrets are used to construct n or n + 1 shares, but one can recover partial secret information from less than n shares. There is a need to develop an efficient and secure (n, n)-MSS scheme so that the threshold property can be satisfied. In this paper, we propose three different (n, n)-MSS schemes. In the first and second schemes, Boolean XOR is used and in the third scheme, we used Modular Arithmetic. For quantitative analysis, Similarity metrics, Structural, and Differential measures are considered. A proposed scheme using Modular Arithmetic performs better compared to Boolean XOR. The proposed (n, n)-MSS schemes outperform the existing techniques in terms of security, time complexity, and randomness of shares.
C1 [Deshmukh, Maroti] Natl Inst Technol, NH 58, Srinagar 246174, Uttarakhand, India.
   [Deshmukh, Maroti; Nain, Neeta; Ahmed, Mushtaq] Malviya Natl Inst Technol, Jaipur 302017, Rajasthan, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand; National Institute of Technology (NIT System);
   Malaviya National Institute of Technology Jaipur
RP Deshmukh, M (corresponding author), Natl Inst Technol, NH 58, Srinagar 246174, Uttarakhand, India.; Deshmukh, M (corresponding author), Malviya Natl Inst Technol, Jaipur 302017, Rajasthan, India.
EM marotideshmukh@nituk.ac.in
RI Ahmed, Mushtaq/GSN-9818-2022; Deshmukh, Dr. Maroti/AAE-2889-2022
OI Nain, Neeta/0000-0002-0550-0376; AHMED, MUSHTAQ/0000-0002-7576-2531;
   Deshmukh, Maroti/0000-0002-1125-5987
CR Blundo Carlo, 1994, ADV CRYPTOLOGY CRYPT
   Chen C, 2015, J SENSORS, V2015, DOI 10.1155/2015/506909
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Deshmukh Maroti, 2014, INT C IM SIGN PROC I, P91
   Feng JB, 2005, J SYST SOFTWARE, V76, P327, DOI 10.1016/j.jss.2004.07.250
   Guo C, 2015, MULTIMED TOOLS APPL, V75, P1
   Guo C, 2012, PATTERN RECOGN LETT, V33, P1594, DOI 10.1016/j.patrec.2012.04.010
   Guo T, 2014, SIGNAL PROCESS, V94, P90, DOI 10.1016/j.sigpro.2013.06.003
   Hsu CF, 2014, WIRELESS PERS COMMUN, V77, P383, DOI 10.1007/s11277-013-1511-3
   Lin KS, 2014, INFORM SCIENCES, V288, P330, DOI 10.1016/j.ins.2014.07.016
   Lin TL, 2010, EXPERT SYST APPL, V37, P7858, DOI 10.1016/j.eswa.2010.04.051
   Lu S, 2008, VISUAL CRYPTOGRAPHY, P225
   Nag A, 2014, CYBERN INF TECHNOL, V14, P98, DOI 10.2478/cait-2014-0023
   Naor M., 1995, ADV CRYPTOLOGY EUROC
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang RZ, 2010, OPT COMMUN, V283, P4242, DOI 10.1016/j.optcom.2010.06.042
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei SC, 2015, COMPUT STAND INTER, V40, P53, DOI 10.1016/j.csi.2015.01.002
   Yang CN, 2016, J SYST SOFTWARE, V116, P22, DOI 10.1016/j.jss.2015.01.031
NR 22
TC 30
Z9 30
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 89
EP 107
DI 10.1007/s11042-016-4229-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400004
DA 2024-07-18
ER

PT J
AU Souza, D
   Burlamaqui, A
   Souza, G
AF Souza, Daniel
   Burlamaqui, Aquiles
   Souza Filho, Guido
TI Improving biometrics authentication with a multi-factor approach based
   on optical interference and chaotic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-factor authentication; Biometric authentication; Two-beam
   interference; Chaotic maps
ID DOUBLE-IMAGE ENCRYPTION; SECURITY SYSTEM; GYRATOR TRANSFORM;
   FOURIER-TRANSFORM; PLAINTEXT ATTACK; SCHEME; INFORMATION; KEY;
   CRYPTOSYSTEM; ALGORITHM
AB We propose a method to improve biometric authentication systems using a multifactor approach. For this security scheme a user authenticates successfully using a set of three characteristics related to physical, possession and knowledge factors. Besides biometric authentication representing the physical factor, we propose the use of an optical authentication technique based on two-beam interference and chaotic maps. In this sense, the seed of a chaotic map represents a user password corresponding to a knowledge factor and a resultant interferogram from optical authentication technique is used as a possession factor. The feasibility of our method is tested using numerical simulation. Moreover, key space and statistical analysis are performed to demonstrate the effectiveness of the solution.
C1 [Souza, Daniel] Univ Fed Rural Semiarido UFERSA, Mossoro, Brazil.
   [Burlamaqui, Aquiles] Univ Fed Rio Grande do Norte UFRN, Natal, RN, Brazil.
   [Souza Filho, Guido] Univ Fed Paraiba, Joao Pessoa, Paraiba, Brazil.
C3 Universidade Federal Rural do Semi-Arido (UFERSA); Universidade Federal
   do Rio Grande do Norte; Universidade Federal da Paraiba
RP Souza, D (corresponding author), Univ Fed Rural Semiarido UFERSA, Mossoro, Brazil.
EM danielfaustino@ufersa.edu.br; aquilesburlamaqui@ect.ufrn.br;
   guido@lavid.ufpb.br
RI de Souza Filho, Guido Lemos/AAD-1048-2019; Souza, Daniel/ITT-7469-2023
OI de Souza Filho, Guido Lemos/0000-0001-5834-5237; Faustino Lacerda de
   Souza, Daniel/0000-0002-1662-8199; Burlamaqui,
   Aquiles/0000-0001-6754-8335
CR Abraham J., 2011, FINGERPRINT MATCHING
   Abuturab MR, 2013, APPL OPTICS, V52, P5133, DOI 10.1364/AO.52.005133
   Abuturab MR, 2013, OPT LASER ENG, V51, P317, DOI 10.1016/j.optlaseng.2012.09.008
   Alfalou A, 2009, APPL OPTICS, V48, P5933, DOI 10.1364/AO.48.005933
   Amin R, 2016, COMPUT NETW, V101, P42, DOI 10.1016/j.comnet.2016.01.006
   [Anonymous], 2009, Advanced Encryption Standard
   Anzaku Esla Timothy, 2010, Proceedings of the 12th Asia Pacific Web Conference (APWEB 2010), P415, DOI 10.1109/APWeb.2010.44
   Blömer J, 2003, LECT NOTES COMPUT SC, V2742, P162
   Borujeni SE, 2013, TELECOMMUN SYST, V52, P525, DOI 10.1007/s11235-011-9458-8
   Cavoukian A., 2009, Biometric Encryption Chapter from the Encyclopedia of Biometrics
   Chen JX, 2015, OPT LASER ENG, V66, P1, DOI 10.1016/j.optlaseng.2014.08.010
   Chen JX, 2014, OPT EXPRESS, V22, P7349, DOI 10.1364/OE.22.007349
   Daemen J., 2013, DESIGN RIJNDAEL AES
   Dodis Y, 2008, SIAM J COMPUT, V38, P97, DOI 10.1137/060651380
   Elshamy AM, 2013, J LIGHTWAVE TECHNOL, V31, P2533, DOI 10.1109/JLT.2013.2267891
   Fan DS, 2015, APPL OPTICS, V54, P3204, DOI 10.1364/AO.54.003204
   Fan DS, 2013, APPL OPTICS, V52, P5645, DOI 10.1364/AO.52.005645
   Feng YC, 2010, IEEE T INF FOREN SEC, V5, P103, DOI 10.1109/TIFS.2009.2038760
   Fleischhacker N, 2014, LECT NOTES COMPUT SC, V8893, P190, DOI 10.1007/978-3-319-14054-4_12
   GEISEL T, 1984, PHYS LETT A, V105, P263, DOI 10.1016/0375-9601(84)90993-9
   Go W, 2014, J INTELL MANUF, V25, P217, DOI 10.1007/s10845-012-0669-y
   Haupt G, 2015, BIOM TECHNOL TODAY, V2015, P5
   He WQ, 2012, APPL OPTICS, V51, P7750, DOI 10.1364/AO.51.007750
   Huang XY, 2011, IEEE T PARALL DISTR, V22, P1390, DOI 10.1109/TPDS.2010.206
   Jassim S, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P562
   Javidi B, 1998, APPL OPTICS, V37, P6247, DOI 10.1364/AO.37.006247
   Javidi B, 1997, OPT ENG, V36, P935, DOI 10.1117/1.601259
   Kang J, 2014, INFORM SCIENCES, V269, P1, DOI 10.1016/j.ins.2014.02.011
   Khan MK, 2008, NEUROCOMPUTING, V71, P3026, DOI 10.1016/j.neucom.2007.12.017
   Khan MK, 2007, CHAOS SOLITON FRACT, V32, P1749, DOI 10.1016/j.chaos.2005.12.015
   Khan SH, 2015, PATTERN RECOGN, V48, P458, DOI 10.1016/j.patcog.2014.08.024
   Kim J, 2005, OPT COMMUN, V247, P265, DOI 10.1016/j.optcom.2004.11.066
   Kong DZ, 2014, OPTIK, V125, P2365, DOI 10.1016/j.ijleo.2013.10.066
   Kumar A, 2013, FUTURE INFORM COMMUN, P579
   Kumar P, 2011, APPL OPTICS, V50, P1805, DOI 10.1364/AO.50.001805
   Kwan P.W., 2006, Proceedings of The 21st Image and Vision Computing New Zealand (IVCNZ 2006) Great Barrier Island, V1, P115
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Li HJ, 2010, INFORM SCIENCES, V180, P3876, DOI 10.1016/j.ins.2010.06.040
   Li J, 2014, OPT LASER ENG, V55, P258, DOI 10.1016/j.optlaseng.2013.12.002
   Li J, 2012, OPTIK, V123, P1605, DOI 10.1016/j.ijleo.2011.08.031
   Li J, 2012, OPT COMMUN, V285, P1704, DOI 10.1016/j.optcom.2011.11.115
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu ZJ, 2013, OPT LASER ENG, V51, P8, DOI 10.1016/j.optlaseng.2012.08.004
   Nagar A, 2010, PATTERN RECOGN LETT, V31, P733, DOI 10.1016/j.patrec.2009.07.003
   Nandakumar K., 2008, Multibiometric Systems: Fusion Strategies and Template Security
   Niu CH, 2012, OPT QUANT ELECTRON, V43, P91, DOI 10.1007/s11082-011-9507-2
   Nomura T, 2000, OPT ENG, V39, P2031, DOI 10.1117/1.1304844
   Peng X, 2006, OPT LETT, V31, P1044, DOI 10.1364/OL.31.001044
   Rajput SK, 2014, J OPT SOC AM A, V31, P1233, DOI 10.1364/JOSAA.31.001233
   Rajput SK, 2014, APPL OPTICS, V53, P418, DOI 10.1364/AO.53.000418
   Rajput SK, 2013, APPL OPTICS, V52, P871, DOI 10.1364/AO.52.000871
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Rhouma R, 2009, CHAOS SOLITON FRACT, V40, P309, DOI 10.1016/j.chaos.2007.07.083
   Saini N, 2013, OPT LASER ENG, V51, P1014, DOI 10.1016/j.optlaseng.2013.03.006
   Saini N, 2011, OPT COMMUN, V284, P756, DOI 10.1016/j.optcom.2010.10.007
   Saini N, 2010, OPT COMMUN, V283, P34, DOI 10.1016/j.optcom.2009.09.002
   Situ G, 2004, OPT COMMUN, V232, P115, DOI 10.1016/j.optcom.2004.01.002
   Sui LS, 2013, OPT LASER TECHNOL, V48, P530, DOI 10.1016/j.optlastec.2012.11.020
   Nguyen TAT, 2015, LECT NOTES COMPUT SC, V9357, P77, DOI 10.1007/978-3-319-24315-3_8
   Wang H, 2012, ADV MULTIMEDIA SOFTW, V1, P671
   Wang XG, 2015, OPT EXPRESS, V23, P6239, DOI 10.1364/OE.23.006239
   Wang XG, 2014, OPT EXPRESS, V22, P28077, DOI 10.1364/OE.22.028077
   Yang YG, 2013, QUANTUM INF PROCESS, V12, P3477, DOI 10.1007/s11128-013-0612-y
   Yuan S, 2013, OPT LASER TECHNOL, V54, P120, DOI 10.1016/j.optlastec.2013.05.021
   Zhang J, 2011, CANCELABLE PALMCODE
   Zhang Y, 2008, OPT LETT, V33, P2443, DOI 10.1364/OL.33.002443
   Zhang YS, 2013, OPT LASER ENG, V51, P472, DOI 10.1016/j.optlaseng.2012.11.001
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
NR 71
TC 4
Z9 4
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2013
EP 2032
DI 10.1007/s11042-017-4374-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400025
DA 2024-07-18
ER

PT J
AU Hu, CH
   Lu, XB
   Ye, MJ
   Zeng, WL
   Du, YJ
AF Hu, Changhui
   Lu, Xiaobo
   Ye, Mengjun
   Zeng, Weili
   Du, Yijun
TI Illumination robust single sample face recognition based on ESRC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single sample face recognition; Illumination robust; Reflectance and
   illumination additive model; High and low-frequency additive model
ID IMAGE CORRUPTION; NORMALIZATION; COMPENSATION; MODELS
AB The extended sparse representation classifier (ESRC) is one of the state-of-the-art solutions for single sample face recognition, but it performs unsatisfactorily under varying illumination. There are two main reasons: one is that the mutual influences of the reflectance and illumination in intra-class variant bases of the ESRC are extreme under varying illumination, the other is that the specific identity information of the face in the generic set constrains the performance of ESRC, since the specific identity information of the generic face is redundant and should be removed. In this paper, the additive strategy is introduced to ESRC, which can efficiently eliminate aforementioned two issues. Two additive models: one is the reflectance and illumination additive (R&L) model and the other is the high-and low-frequency additive (H&L) model, are introduced to ESRC to obtain two new methods: R&L_ESRC and H&L_ESRC. Each method can be solved by a combined L1-minimization problem, and the final classification is determined by the sum of two weighting residuals: the reflectance and illumination residuals (or the high-and low-frequency residuals). In our experiments, the wavelet denoising (WDM) model and the logarithmic total variation (LTV) model are employed to extract facial features in R&L_ESRC and H&L_ESRC respectively. The performances of the proposed methods are verified on the Extended Yale B, CMU PIE, AR, ORL, and self-built Driver face databases. The experimental results illustrate that the proposed techniques outperform previous approaches under both normal and variant illumination conditions.
C1 [Hu, Changhui; Lu, Xiaobo; Zeng, Weili; Du, Yijun] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Hu, Changhui; Lu, Xiaobo; Zeng, Weili; Du, Yijun] Southeast Univ, Key Lab Measurement & Control Complex Syst Engn, Minist Educ, Nanjing 210096, Jiangsu, Peoples R China.
   [Ye, Mengjun] Hubei Normal Univ, Coll Mechatron & Control Engn, Huangshi 435002, Peoples R China.
C3 Southeast University - China; Southeast University - China; Hubei Normal
   University
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.; Lu, XB (corresponding author), Southeast Univ, Key Lab Measurement & Control Complex Syst Engn, Minist Educ, Nanjing 210096, Jiangsu, Peoples R China.
EM xblu2013@126.com
RI Hu, Chang-Hui/AAD-8822-2020
OI Zeng, Weili/0000-0002-5266-2423
FU National Key Science and Technology Pillar Program of China
   [2014BAG01B03]; National Natural Science Foundation of China [61374194,
   61403081]; Scientific Research Foundation of Graduate School of
   Southeast University [YBJJ1519]; Natural Science Foundation of Jiangsu
   Province [BK20140638]; Priority Academic Program Development of Jiangsu
   Higher Education Institutions
FX This work was supported by the National Key Science and Technology
   Pillar Program of China (No. 2014BAG01B03), National Natural Science
   Foundation of China (No. 61374194& No. 61403081), Scientific Research
   Foundation of Graduate School of Southeast University (YBJJ1519),
   Natural Science Foundation of Jiangsu Province (No. BK20140638), and a
   Project Funded by the Priority Academic Program Development of Jiangsu
   Higher Education Institutions.
CR Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229
   Cao X, 2012, PATTERN RECOGN, V45, P1299, DOI 10.1016/j.patcog.2011.09.010
   Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210
   Chen T, 2006, IEEE T PATTERN ANAL, V28, P1519, DOI 10.1109/TPAMI.2006.195
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Choi SI, 2007, PATTERN RECOGN, V40, P2118, DOI 10.1016/j.patcog.2006.11.020
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Donoho DL, 2008, IEEE T INFORM THEORY, V54, P4789, DOI 10.1109/TIT.2008.929958
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Horn BKP., 1997, ROBOT VISION
   Hu CH, 2015, MULTIMED TOOLS APPL, V74, P10313, DOI 10.1007/s11042-014-2168-y
   Hu CH, 2015, NEUROCOMPUTING, V160, P287, DOI 10.1016/j.neucom.2015.02.032
   Ji Q, 2015, MULTIMED TOOLS APPL, P1
   Jiang XD, 2015, IEEE T PATTERN ANAL, V37, P1067, DOI 10.1109/TPAMI.2014.2359453
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Kan MN, 2013, PATTERN RECOGN, V46, P2497, DOI 10.1016/j.patcog.2013.01.037
   Lai ZR, 2015, IEEE T IMAGE PROCESS, V24, P1735, DOI 10.1109/TIP.2015.2409988
   Majumdar A, 2008, INT CONF ACOUST SPEE, P989, DOI 10.1109/ICASSP.2008.4517778
   Martinez A., 1998, AR FACE DATABASE
   Ochoa-Villegas MA, 2015, IET COMPUT VIS, V9, P978, DOI 10.1049/iet-cvi.2014.0086
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shim H, 2008, IEEE T IMAGE PROCESS, V17, P1331, DOI 10.1109/TIP.2008.925390
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Vezzetti E, 2014, ROBOT AUTON SYST, V62, P1768, DOI 10.1016/j.robot.2014.07.009
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wang B, 2013, NEUROCOMPUTING, V115, P186, DOI 10.1016/j.neucom.2013.02.004
   Wang B, 2011, IEEE SIGNAL PROC LET, V18, P462, DOI 10.1109/LSP.2011.2158998
   Xie XH, 2011, IEEE T IMAGE PROCESS, V20, P1807, DOI 10.1109/TIP.2010.2097270
   Xu WK, 2015, KSII T INTERNET INF, V9, P2667, DOI 10.3837/tiis.2015.07.019
   Yang M, 2013, IEEE I CONF COMP VIS, P689, DOI 10.1109/ICCV.2013.91
   Yang M, 2013, IEEE T IMAGE PROCESS, V22, P1753, DOI 10.1109/TIP.2012.2235849
   Zhang DQ, 2005, APPL MATH COMPUT, V163, P895, DOI 10.1016/j.amc.2004.04.016
   Zhang TP, 2009, PATTERN RECOGN, V42, P251, DOI 10.1016/j.patcog.2008.03.017
   Zhang TP, 2009, IEEE T IMAGE PROCESS, V18, P2599, DOI 10.1109/TIP.2009.2028255
   Zhuang LS, 2015, INT J COMPUT VISION, V114, P272, DOI 10.1007/s11263-014-0749-x
   Zhuang LS, 2013, PROC CVPR IEEE, P3546, DOI 10.1109/CVPR.2013.455
   Zou X, 2007, 2007 FIRST IEEE INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P113
NR 38
TC 2
Z9 2
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26523
EP 26550
DI 10.1007/s11042-016-4180-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500045
DA 2024-07-18
ER

PT J
AU Ben Aicha, A
AF Ben Aicha, Anis
TI Noise estimation for speech enhancement algorithms with post-smoothness
   processor incorporating global posterior SNR
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Noise estimation; Noise smoothing; Global Posterior SNR; Perceptual
   quality
ID QUALITY MEASURES; ADDITIVE NOISE
AB Performances of speech enhancement algorithms depend greatly on the accuracy of the estimated noise. In this paper, we explain in details the relationship between noise estimation and denoised speech quality. We particularly show the importance of noise smoothing over frames on denoising quality. This study leads to the development of a new technique to smooth the estimated noise power spectrum over frequency bins of the same frame. Compared to inter-frame smoothing, experimental results show that the proposed intra-frame smoothing has a good impact on the denoised speech. Quality is evaluated over three dimensions: speech distortion, residual background noise and overall quality.
C1 [Ben Aicha, Anis] Univ Carthage, Higher Sch Commun Tunis SUPCOM, COSIM Res Lab, Ariana, Tunisia.
C3 Universite de Carthage
RP Ben Aicha, A (corresponding author), Univ Carthage, Higher Sch Commun Tunis SUPCOM, COSIM Res Lab, Ariana, Tunisia.
EM anis_ben_aicha@yahoo.fr
CR [Anonymous], 2000, ITU-T rec, P862
   Ben Aicha A, 2010, INT C INF SCI SIGN P
   Ben Aicha A, 2012, SPEECH COMMUN, V54, P517, DOI 10.1016/j.specom.2011.11.005
   Ben Aicha A, 2012, SIGNAL IMAGE VIDEO P, V6, P85, DOI 10.1007/s11760-010-0171-y
   Benesty J, 2009, SPRINGER TOP SIGN PR, V2, P1, DOI 10.1007/978-3-642-00296-0_1
   Cohen I, 2003, IEEE T SPEECH AUDI P, V11, P466, DOI 10.1109/TSA.2003.811544
   Derakhshan N, 2009, SPEECH COMMUN, V51, P1098, DOI 10.1016/j.specom.2009.04.008
   Garofolo J., 1988, Getting started with the DARPA TIMIT CD-ROM: An acoustic phonetic continuous speech database
   Hansen JHL, 2006, IEEE T AUDIO SPEECH, V14, P2049, DOI 10.1109/TASL.2006.876883
   Hu Y., 2006, IEEE INT C AC SPEECH
   Hu Y, 2007, IEEE INT C AC SPEECH
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   ITU-T Rec. P.835, 2003, ITU-T Recommendation G.114
   Klatt D. H., 1982, IEEE INT C AC SPEECH
   Loizou P. C., 2007, Speech Enhancement: Theory and Practice
   Loizou PC, 2011, IEEE T AUDIO SPEECH, V19, P47, DOI 10.1109/TASL.2010.2045180
   Martin R, 2001, IEEE T SPEECH AUDI P, V9, P504, DOI 10.1109/89.928915
   Miyazaki R, 2014, SIGNAL PROCESS, V102, P226, DOI 10.1016/j.sigpro.2014.03.010
   Quanckenbush S, 1988, OBJECTIVE MEASURES S
   Rangachari S, 2006, SPEECH COMMUN, V48, P220, DOI 10.1016/j.specom.2005.08.005
   Saxena P, 2016, INFORM SYSTEMS DESIG
   Sohn J, 1999, IEEE SIGNAL PROC LET, V6, P1, DOI 10.1109/97.736233
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Vondrásek M, 2005, RADIOENGINEERING, V14, P6
NR 24
TC 3
Z9 3
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23661
EP 23678
DI 10.1007/s11042-016-4145-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700025
DA 2024-07-18
ER

PT J
AU Fang, JT
   Day, CT
   Chang, PC
AF Fang, Jiunn-Tsair
   Day, Chi-Ting
   Chang, Pao-Chi
TI Deep feature learning for cover song identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cover song; Deep learning; Music retrieval; Sparse autoencoder
ID SIMILARITY; ALIGNMENT
AB The identification of a cover song, which is an alternative version of a previously recorded song, for music retrieval has received increasing attention. Methods for identifying a cover song typically involve comparing the similarity of chroma features between a query song and another song in the data set. However, considerable time is required for pairwise comparisons. In this study, chroma features were patched to preserve the melody. An intermediate representation was trained to reduce the dimension of each patch of chroma features. The training was performed using an autoencoder, commonly used in deep learning for dimensionality reduction. Experimental results showed that the proposed method achieved better accuracy for identification and spent less time for similarity matching in both covers80 dataset and Million Song Dataset as compared with traditional approaches.
C1 [Fang, Jiunn-Tsair] Ming Chuan Univ, Dept Elect Engn, 5 Deming Rd, Taoyuan 33348, Taiwan.
   [Day, Chi-Ting; Chang, Pao-Chi] Natl Cent Univ, Dept Commun Engn, 300 Jhongda Rd, Taoyuan 32001, Taiwan.
C3 Ming Chuan University; National Central University
RP Chang, PC (corresponding author), Natl Cent Univ, Dept Commun Engn, 300 Jhongda Rd, Taoyuan 32001, Taiwan.
EM pcchang@ce.ncu.edu.tw
CR Al-Shareef A. J., 2008, INT J ELECT COMPUTER, V3, P834
   [Anonymous], 2008, P ICML
   [Anonymous], THESIS
   [Anonymous], 2014, FINGERPRINT CLASSIFI
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bertin-Mahieux T., 2011, P ISMIR
   Bertin-Mahieux T, 2012, 13 ISMIR C
   Chang TM, 2015, MULTIMED TOOLS APPL, V74, P7921, DOI 10.1007/s11042-014-2031-1
   Ellis D., Dynamic Time Warp (DTW) in Matlab
   Ellis D. P. W., 2007, COVERS80 COVER SONG
   Ellis DPW, 2007, INT CONF ACOUST SPEE, P1429
   Ellis DPW, 2006, 2007 LABROSA COVER S
   ELLIS DPW, 2006, BEAT TRACKING DYNAMI
   Fujishima T., 1999, P INT COMP MUS C, P464
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Humphrey E. J., 2013, PROC INT SOC MUSIC I, P4
   Keogh E, 2005, KNOWL INF SYST, V7, P358, DOI 10.1007/s10115-004-0154-9
   Lee K, 2006, IDENTIFYING COVER SO
   Nieto Oriol, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P664, DOI 10.1109/ICASSP.2014.6853679
   Palm R., 2012, Deep Learning Toolbox
   Ranzato M., 2006, EFFICIENT LEARNING S
   Ranzato M., 2007, Adv Neural Inf Process Syst, V20
   Ravuri S, 2010, INT CONF ACOUST SPEE, P65, DOI 10.1109/ICASSP.2010.5496214
   Rifai S., 2011, CONTRACTIVE AUTOENCO, DOI DOI 10.5555/3104482.3104587
   Riley M., 2008, INT S MUSIC INFORM R, P295
   Sailer C, 2006, FINDING COVER SONGS
   Salakhutdinov R, NONLINEAR DIMENSIONA
   Serrà J, 2008, IEEE T AUDIO SPEECH, V16, P1138, DOI 10.1109/TASL.2008.924595
   Serrá J, 2008, INT CONF ACOUST SPEE, P61, DOI 10.1109/ICASSP.2008.4517546
   Serrà J, 2010, STUD COMPUT INTELL, V274, P307
   Shepard R.N., 1982, The psychology of music
   Smolensky P., 1986, Information processing in dynamical systems: Foundations of harmony theory
   Tralie CJ, 2015, ARXIV150705143
   Voorhees E.M., 1999, Proceedings of TREC
   WITMER R, 2006, COVER GROVE MUSIC ON
NR 37
TC 0
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23225
EP 23238
DI 10.1007/s11042-016-4107-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700005
DA 2024-07-18
ER

PT J
AU Kumaran, P
   Chitrakala, S
AF Kumaran, P.
   Chitrakala, S.
TI Social influence determination on big data streams in an online social
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rank-based sampling; Information diffusion modelling; Influence
   maximization problem; Influential spreaders ranking
ID INFLUENCE MAXIMIZATION; INFORMATION DIFFUSION
AB Social networks have become a good place to promote products and also to campaign for causes. Maximizing the spread of information in an online social network at a least cost has attracted the attention of publicist's. In general, influence user ranking methods are derived either by a network's topological features or by user features but not both. Existing Influence Maximization Problem (IMP) operates as a modification of greedy algorithms that cannot scale streaming data. Which are time consuming and cannot handle large networks because it requires heavy Monte-Carlo simulation. This is also an NP hard problem in both linear threshold and independent cascade models. Our proposed work aims to address IMP through a Rank-based sampling approach in the Map-Reduce environment. This novel technique combines user and topological features of the network enabling it to handle real-time streaming data. Our experiment of influenced rank-based sampling approach to influence maximization is compared to the greedy approach with and without sampling that exhibits an accuracy of 82%. Performance analysis in terms of running time is reduced from O(n (3)) to O(k n). Where 'k' is the size of the sample dataset and 'n' is the number of user's.
C1 [Kumaran, P.; Chitrakala, S.] Anna Univ, Coll Engn, Dept Comp Sci & Engn, Madras, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Kumaran, P (corresponding author), Anna Univ, Coll Engn, Dept Comp Sci & Engn, Madras, Tamil Nadu, India.
EM kumaran.0991@gmail.com; au.chitras@gmail.com
RI S, Chitrakala/T-9631-2019; S, C/JLK-9983-2023; P, Kumaran/AAG-1677-2019;
   s, c/Y-9655-2019
OI s, c/0000-0002-6951-5972; P, Kumaran/0000-0001-6206-6388; S,
   Chitrakala/0000-0002-1871-6037
CR [Anonymous], 2016, ARXIV161009462
   [Anonymous], ARXIV161101872
   [Anonymous], 2016, IEEE ACM T NETWORKIN
   [Anonymous], 2002, P 11 INT C WORLD WID, DOI DOI 10.1145/511446.511513
   Chen W., 2010, ACM SIGKDD INT C KNO, P1029, DOI DOI 10.1145/1835804.1835934
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Feng Wang, 2012, Proceedings of the 2012 32nd International Conference on Distributed Computing Systems Workshops (ICDCS Workshops), P133, DOI 10.1109/ICDCSW.2012.16
   Garg S, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P566, DOI 10.1109/ICICICT.2014.6781343
   Ghanem TM, 2007, IEEE T KNOWL DATA EN, V19, P57, DOI 10.1109/TKDE.2007.250585
   Gong MG, 2016, IEEE COMPUT INTELL M, V11, P23, DOI 10.1109/MCI.2016.2572538
   Guille A., 2012, WWW 12 Companion: Proceedings of the 21st International Conference on World Wide Web, V2012, P1145, DOI [DOI 10.1145/2187980.2188254, 10.1145/2187980.2188254]
   Hoffman M., 2010, P ADV NEUR INF PROC, V23:856-864
   Jiang CX, 2014, IEEE T SIGNAL PROCES, V62, P4573, DOI 10.1109/TSP.2014.2339799
   Jiang CX, 2014, IEEE J-STSP, V8, P524, DOI 10.1109/JSTSP.2014.2313024
   Kandhway K, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1515, DOI 10.1109/ICACCI.2014.6968621
   Lee JR, 2015, IEEE T KNOWL DATA EN, V27, P340, DOI 10.1109/TKDE.2014.2330833
   Liang ZW, 2014, 2014 11TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P393, DOI 10.1109/ICCWAMTIP.2014.7073434
   Liu B, 2014, IEEE T KNOWL DATA EN, V26, P1904, DOI 10.1109/TKDE.2013.106
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu XD, 2014, IEEE T PARALL DISTR, V25, P136, DOI 10.1109/TPDS.2013.41
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu Y, 2016, Multimedia Tools and Applications, P1
   Meng XF, 2014, 2014 INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS (DSAA), P505, DOI 10.1109/DSAA.2014.7058119
   Michelle GG, 2016, PROCEEDINGS OF THE 2016 IEEE 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRICAL & ELECTRONICS, INFORMATION, COMMUNICATION & BIO INFORMATICS (IEEE AEEICB-2016), P152, DOI 10.1109/AEEICB.2016.7538262
   Simmie D, 2014, J COMPLEX NETW, V2, P495, DOI 10.1093/comnet/cnu024
   Song GJ, 2015, IEEE T PARALL DISTR, V26, P1379, DOI 10.1109/TPDS.2014.2320515
   Wang GJ, 2014, IEEE T PARALL DISTR, V25, P2286, DOI 10.1109/TPDS.2013.135
   Wang XY, 2017, IEEE T KNOWL DATA EN, V29, P599, DOI 10.1109/TKDE.2016.2633472
   Weng J., 2010, P 3 ACM INT C WEB SE, P261, DOI [10.1145/1718487.1718520, DOI 10.1145/1718487.1718520]
   Wu YC, 2014, IEEE T VIS COMPUT GR, V20, P1763, DOI 10.1109/TVCG.2014.2346920
   Xiaojuan Shen, 2012, 2012 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI), P832, DOI 10.1109/BHI.2012.6211714
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Zhang HY, 2016, IEEE ACM T NETWORK, V24, P929, DOI 10.1109/TNET.2015.2394793
   Zhou C, 2015, IEEE T KNOWL DATA EN, V27, P2770, DOI 10.1109/TKDE.2015.2419659
NR 37
TC 4
Z9 4
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22133
EP 22167
DI 10.1007/s11042-017-4890-8
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200015
DA 2024-07-18
ER

PT J
AU Liu, JX
   Wen, XB
   Yuan, LM
   Xu, HX
AF Liu, Jia-Xing
   Wen, Xian-Bin
   Yuan, Li-Ming
   Xu, Hai-Xia
TI A robust approach of watermarking in contourlet domain based on
   probabilistic neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Probabilistic neural network (PNN); Contourlet transform (CT);
   Correlation; Digital watermarking
AB A novel algorithm of image watermarking in contourlet transform(CT) has been proposed based on probabilistic neural network(PNN) in this paper. In the proposed process, host image is divided into several blocks, and then each block will be decomposed by CT firstly. Then coefficients of each block will be divided into many small coefficient blocks, and the Pseudo random Noise(PN) sequence is generated for the watermarking and embedded into the coefficient blocks that we selected with certain intensity. Thirdly, the correlation between each of embedded coefficient block and same-sized PN sequence is calculated, and put as the input of the probabilistic neural network system for training. Fastly, after training, the trained system will be robust for watermarking extraction. Results show that this scheme is blind, strongly robust and perceptual invisible, which are two major characteristics for digital watermarking, and does not need the watermark in the extraction process.
C1 [Liu, Jia-Xing; Wen, Xian-Bin; Yuan, Li-Ming; Xu, Hai-Xia] Tianjin Univ Technol, Key Lab Comp Vis & Syst, Minist Educ, Binshuixidao 391, Tianjin 300384, Peoples R China.
   [Liu, Jia-Xing; Wen, Xian-Bin; Yuan, Li-Ming; Xu, Hai-Xia] Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin 300384, Peoples R China.
C3 Tianjin University of Technology; Tianjin University of Technology
RP Liu, JX (corresponding author), Tianjin Univ Technol, Key Lab Comp Vis & Syst, Minist Educ, Binshuixidao 391, Tianjin 300384, Peoples R China.; Liu, JX (corresponding author), Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin 300384, Peoples R China.
EM iwantitxing@163.com
RI liu, jiajia/IUN-0901-2023; liu, jia/JAC-7852-2023; Li, JW/HNC-1743-2023;
   liu, jia/HKE-9796-2023; Liu, Jiayu/JCO-5073-2023; Yu, Kun/IAP-9807-2023;
   liu, jiajia/ISS-0316-2023; liu, jiayu/JCP-0511-2023; li,
   jiawei/HOA-5023-2023
FU National Natural Science Foundation of China [61472278]
FX The authors would like to thank anonymous reviewers for their detailed
   comments and questions which improved the quality of the presentation of
   this paper. This research is supported in part by the National Natural
   Science Foundation of China (grant No. 61472278).
CR AL-Nabhani Y, 2015, J KING SAUD UNIV-COM, V27, P393, DOI 10.1016/j.jksuci.2015.02.002
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Do MN, 2002, 2002 36 AS C IEEE, V1, P497, DOI [10.1109/ACSSC.2002.1197232, DOI 10.1109/ACSSC.2002.1197232]
   Fu Y, 2004, ELECTRON LETT, V40, P986, DOI 10.1049/el:20040600
   Garcia-Ugalde F, 2012, INT C SIGN PROC COMM, V61, P1
   Hsu LY, 2015, J VIS COMMUN IMAGE R, V32, P130, DOI 10.1016/j.jvcir.2015.07.017
   Iounousse J, 2012, INT CONF MULTIMED, P102
   Kaviani HR, 2011, MACHINE VISION IMAGE, P1, DOI DOI 10.1109/IRANIANMVIP.2011.6121618
   Kumaran T., 2008, 2008 Second UKSIM European Symposium on Computer Modeling and Simulation (EMS), P257, DOI 10.1109/EMS.2008.79
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   [李春花 LI Chunhua], 2006, [中国图象图形学报, Journal of Image and Graphics], V11, P1322
   Piva A, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P520, DOI 10.1109/ICIP.1997.647964
   Solachidis Vassilios, 2004, EURASIP J ADV SIG PR, V2004, P1
   SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q
   Tseng CL, 2004, NEUROCOMPUTING, V61, P21, DOI 10.1016/j.neucom.2004.03.002
   Vizireanu DN, 2005, Telsiks 2005, Proceedings, Vols 1 and 2, P518
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Wen XB, 2009, SOFT COMPUT, V13, P355, DOI 10.1007/s00500-008-0331-y
   [吴一全 Wu Yiquan], 2012, [光电子·激光, Journal of Optoelectronics·Laser], V23, P336
   Zhang J., 2002, P INT C MACHINE LEAR, V3, P1405, DOI DOI 10.1109/ICMLC.2002.1167437
   Zhang Jun, 2003, Journal of Computer Aided Design & Computer Graphics, V15, P307
NR 21
TC 9
Z9 15
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24009
EP 24026
DI 10.1007/s11042-016-4178-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700040
DA 2024-07-18
ER

PT J
AU Tan, HL
   He, XF
   Wang, ZJ
   Liu, GM
AF Tan, Huailiang
   He, Xiaofei
   Wang, Zijian
   Liu, Gaoming
TI Parallel implementation and optimization of high definition video
   real-time dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dehazing; High definition; Real-time processing; Parallel implementation
   and optimization; OpenCL
ID OPENCL
AB In some warning applications, such as aircraft taking-off and landing, ship sailing, and traffic guidance in foggy weather, the high definition (HD) and rapid dehazing of images and videos is increasingly necessary. Existing technologies for the dehazing of videos or images have not completely exploited the parallel computing capacity of modern multi-core CPU and GPU, and leads to the long dehazing time or the low frame rate of video dehazing which cannot meet the real-time requirement. In this paper, we propose a parallel implementation and optimization method for the real-time dehazing of the high definition videos based on a single image haze removal algorithm. Our optimization takes full advantage of the modern CPU+GPU architecture, which increases the parallelism of the algorithm, and greatly reduces the computational complexity and the execution time. The optimized OpenCL parallel implementation is integrate into FFmpeg as an independent module. The experimental results show that for a single image, the performance of the optimized OpenCL algorithm is improved approximately 500% compared with the existing algorithm, and approximately 153% over the basic OpenCL algorithm. The 1080p (1920 x 1080) high definition hazy video can also processed at a real-time rate (more than 41 frames per second).
C1 [Tan, Huailiang; He, Xiaofei; Wang, Zijian] Hunan Univ, Coll Comp Sci & Elect Engn, Lushan Rd, Changsha 410082, Hunan, Peoples R China.
   [Liu, Gaoming] Changsha Vocat & Tech Coll, Zhengxing Rd, Changsha 410217, Hunan, Peoples R China.
C3 Hunan University
RP Tan, HL (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Lushan Rd, Changsha 410082, Hunan, Peoples R China.
EM tanhuailiang@hnu.edu.cn
RI Wang, Zijian/IQU-2128-2023
OI Wang, Zijian/0000-0001-8770-1755
FU National Natural Science Foundation of China [61672218]
FX The authors are grateful to the editors and anonymous reviewers for
   their helpful feedback. The research was supported in part by the
   National Natural Science Foundation of China (Grant No. 61672218,
   Project Name: Virtual Multi-channel Asymmetry Parallel Model and Fair
   Scheduling Scheme for GPU).
CR [Anonymous], 950901 TR U WASH
   [Anonymous], OPENCL SPECIFICATION
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P PLDI ACM
   Bin Xie, 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P848, DOI 10.1109/ISDEA.2010.141
   Chen Chao, 2016, Computer Engineering and Applications, V52, P150, DOI 10.3778/j.issn.1002-8331.1508-0098
   Fang JB, 2014, PROC INT CONF PARAL, P162, DOI 10.1109/ICPP.2014.25
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Jang B, 2011, IEEE T PARALL DISTR, V22, P105, DOI 10.1109/TPDS.2010.107
   Li XY, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON VEHICULAR ELECTRONICS AND SAFETY (ICVES), P1, DOI 10.1109/ICVES.2013.6619592
   Liu Q, 2013, CHIN CONT DECIS CONF, P3780
   Liya Zhou, 2011, 2011 Second International Conference on Mechanic Automation and Control Engineering, P5485
   NVIDIA, NVIDIA CUDA C. programming guide, version 10.0
   Qiaoling Liu, 2011, 2011 International Conference on Multimedia Technology, P467
   Seo S, 2013, INT CONFER PARA, P387
   Shen J, 2013, EUROMICRO WORKSHOP P, P38, DOI 10.1109/PDP.2013.16
   Tan R, 2008, IEEE C COMPUTER VISI, P1
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Thoman P, 2011, LECT NOTES COMPUT SC, V6853, P438, DOI 10.1007/978-3-642-23397-5_43
   Xingyong Lv, 2010, 2010 Pacific Graphics (PG). Proceedings 18th Pacific Conference on Computer Graphics and Applications, P62, DOI 10.1109/PacificGraphics.2010.16
   Xue YG, 2013, COMM COM INF SC, V207, P99
NR 22
TC 7
Z9 7
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23413
EP 23434
DI 10.1007/s11042-016-4036-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700013
DA 2024-07-18
ER

PT J
AU Hao, T
   Wang, Q
   Wu, D
   Sun, JS
AF Hao, Tong
   Wang, Qian
   Wu, Dan
   Sun, Jin-Sheng
TI A unified framework for cross-modality 3D model retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D object retrieval; Multi-view; Graph matching; Multiple modalities
ID HUMAN ACTION RECOGNITION; SEQUENCES
AB Currently, there exists diverse modalities of 3D models, such as the view set representation of 3D models, the virtual 3D model designed by CAD tools, and the 2.5D model captured by Kinect sensors. To realize flexible access to 3D models in different modalities, this paper proposes the unified framework for cross-modality 3D model retrieval. First, we develop a toolbox with OpenGL to convert 3D models in multiple modalities into the view set representation of 3D models, which are usually represented by a set of characteristic views. Then, we extract discriminative visual feature for multi-view representation. These visual features can be utilized to construct the graphical model to represent the structural characteristics of individual 3D model. Finally, we leverage the graph matching algorithm for similarity measure between pairwise 3D models. We evaluate this unified framework on several well-known 3D model datasets. The comparison experiments demonstrate that this unified framework can achieve competing performances against the state of the arts.
C1 [Hao, Tong; Wang, Qian; Wu, Dan; Sun, Jin-Sheng] Tianjin Normal Univ, Tianjin Key Lab Anim & Plant Resistance, Coll Life Sci, Tianjin 300387, Peoples R China.
   [Sun, Jin-Sheng] Tianjin Aquat Anim Infect Dis Control & Prevent C, Tianjin 300221, Peoples R China.
C3 Tianjin Normal University; Tianjin Center for Disease Control &
   Prevention
RP Sun, JS (corresponding author), Tianjin Normal Univ, Tianjin Key Lab Anim & Plant Resistance, Coll Life Sci, Tianjin 300387, Peoples R China.; Sun, JS (corresponding author), Tianjin Aquat Anim Infect Dis Control & Prevent C, Tianjin 300221, Peoples R China.
EM jinshsun@163.com
FU National High-Tech Research and Development Program of China (863
   programs) [2012AA10A401, 2012AA092205]; Grants of the Major State Basic
   Research Development Program of China (973 programs) [2012CB114405];
   National Natural Science Foundation of China [21106095]; National Key
   Technology RD Program [2011BAD13B07, 2011BAD13B04]; Tianjin Research
   Program of Application Foundation and Advanced Technology
   [15JCYBJC30700]; Project of introducing one thousand high level talents
   in three years; Foundation of Introducing Talents to Tianjin Normal
   University [5RL123]; "131" Innovative Talents cultivation of Tianjin;
   Academic Innovation Foundation of Tianjin Normal University [52XC1403]
FX This work was supported by National High-Tech Research and Development
   Program of China (863 programs, 2012AA10A401 and 2012AA092205), Grants
   of the Major State Basic Research Development Program of China (973
   programs, 2012CB114405), National Natural Science Foundation of China
   (21106095), National Key Technology R&D Program (2011BAD13B07 and
   2011BAD13B04), Tianjin Research Program of Application Foundation and
   Advanced Technology (15JCYBJC30700), Project of introducing one thousand
   high level talents in three years, Foundation of Introducing Talents to
   Tianjin Normal University(5RL123), "131" Innovative Talents cultivation
   of Tianjin, Academic Innovation Foundation of Tianjin Normal University
   (52XC1403).
CR Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   [Anonymous], NEUROCOMPUTING
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   Gao Y, 2014, IEEE MULTIMEDIA, V21, P52, DOI 10.1109/MMUL.2014.20
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Gao Z, 2016, NEUROCOMPUTING, V215, P138, DOI 10.1016/j.neucom.2016.01.113
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2015, NEUROCOMPUTING, V151, P554, DOI 10.1016/j.neucom.2014.06.085
   Gao Z, 2014, MULTIMED TOOLS APPL, V68, P641, DOI 10.1007/s11042-012-1071-7
   Guo YL, 2015, INFORM SCIENCES, V293, P196, DOI 10.1016/j.ins.2014.09.015
   Hao T, 2016, NEUROCOMPUTING, V195, P6, DOI 10.1016/j.neucom.2015.06.106
   Hu MC, 2015, IEEE T CYBERNETICS, V45, P742, DOI 10.1109/TCYB.2014.2335540
   Jilai Zhou, 2015, Applied Mechanics and Materials, V733, P931, DOI 10.4028/www.scientific.net/AMM.733.931
   Liu A. A., 2016, IEEE Trans Pattern Anal Mach Intell, P1
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu AA, 2015, SIGNAL PROCESS, V112, P74, DOI 10.1016/j.sigpro.2014.08.038
   Liu AA, 2012, IEEE T MED IMAGING, V31, P359, DOI 10.1109/TMI.2011.2169495
   Liu A, 2015, INFORM SCIENCES, V320, P429, DOI 10.1016/j.ins.2015.04.042
   Lu F, 2015, PROC CVPR IEEE, P168, DOI 10.1109/CVPR.2015.7298612
   Lu F, 2015, IEEE T PATTERN ANAL, V37, P1999, DOI 10.1109/TPAMI.2015.2389841
   Ming Y, 2015, NEUROCOMPUTING, V151, P574, DOI 10.1016/j.neucom.2014.06.088
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie WZ, 2016, J VIS COMMUN IMAGE R, V37, P40, DOI 10.1016/j.jvcir.2015.06.011
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Ning BS, 2016, BUILD ENVIRON, V102, P64, DOI 10.1016/j.buildenv.2016.03.009
   SEMENZA JC, 1990, CELL, V61, P1349, DOI 10.1016/0092-8674(90)90698-E
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   Vandeborre JP, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P644, DOI 10.1109/TDPVT.2002.1024132
   Wang XY, 2015, NEUROCOMPUTING, V151, P620, DOI 10.1016/j.neucom.2014.03.091
   Xu Q, 2014, INFORM SCIENCES, V278, P736, DOI 10.1016/j.ins.2014.03.088
   Zhang Y, 2016, NEUROCOMPUTING, V195, P40, DOI 10.1016/j.neucom.2015.09.118
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zou HY, 2015, OPTIK, V126, P898, DOI 10.1016/j.ijleo.2015.02.083
NR 38
TC 1
Z9 1
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20217
EP 20230
DI 10.1007/s11042-017-4417-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500051
DA 2024-07-18
ER

PT J
AU Ji, HK
   Sun, QS
   Yuan, YH
   Ji, ZX
   Zhang, GQ
   Feng, L
AF Ji, Hong-Kun
   Sun, Quan-Sen
   Yuan, Yun-Hao
   Ji, Ze-Xuan
   Zhang, Guo-Qing
   Feng, Lei
TI Dual structural consistency based multi-modal correlation propagation
   projections for data representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modal semi-supervised learning; Structural consistency; Feature
   extraction and fusion; Correlation analysis
ID CANONICAL CORRELATION-ANALYSIS; FACE RECOGNITION; DIMENSIONALITY
   REDUCTION; FEATURE-EXTRACTION; CLASSIFICATION; ALGORITHM; FUSION;
   FORMULATION; EXTENSIONS; EIGENFACES
AB Canonical correlation analysis (CCA) is a powerful tool for analyzing multi-dimensional paired data. However, when facing semi-supervised multi-modal data (Also called multi-view Hou et al. (Pattern Recog 43(3):720-730, 2010) or multi-represented Kailing et al. (Clustering multi-represented objects with noise. In: Proceedings of the eighth Pacific-Asia conference on knowledge discovery and data mining (PAKDD). Sydney, Australia, pp 394-403) data. For convenience, we will uniformly call them multi-modal data hereafter.) which widely exist in real-world applications, CCA usually performs poorly due to ignoring useful supervised information. Meanwhile, due to the limited labeled training samples in the semi-supervised scenario, supervised extensions of CCA suffer from overfitting. Several semi-supervised extensions of CCA have been proposed recently. Nevertheless, they either just utilize the global structural information captured from the unlabeled data, or propagate label information by discovering the affinities just between the labeled and unlabeled data points in advance. In this paper, we propose a robust multi-modal semi-supervised feature extraction and fusion framework, termed as dual structural consistency based multi-modal correlation propagation projections (SCMCPP). SCMCPP guarantees the consistency between representation structure and hypotaxis structure in each modality and ensures the consistency of hypotaxis structure between two different modalities. By iteratively propagating labels and learning affinities, discriminative information of both given labels and estimated labels is utilized to improve the affinity construction and infer the remaining unknown labels. Moreover, probabilistic within-class scatter matrices in each modality and probabilistic correlation matrix between two modalities are constructed to enhance the discriminative power of features. Extensive experiments on several benchmark face databases demonstrate the effectiveness of our approach.
C1 [Ji, Hong-Kun; Sun, Quan-Sen; Ji, Ze-Xuan; Zhang, Guo-Qing; Feng, Lei] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Ji, Hong-Kun] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 637553, Singapore.
   [Yuan, Yun-Hao] Yangzhou Univ, Dept Comp Sci & Technol, Yangzhou 225000, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology; Nanyang Technological
   University; Yangzhou University
RP Ji, HK; Sun, QS (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.; Ji, HK (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 637553, Singapore.
EM jihongkunnust@126.com; qssun@126.com
RI zhang, guoqing/GXG-4800-2022
FU Graduate Research and Innovation Foundation of Jiangsu Province, China
   [KYLX15_0379]; National Natural Science Foundation of China [61273251,
   61401209, 61402203]; Natural Science Foundation of Jiangsu Province
   [BK20140790]; China Postdoctoral Science Foundation [2014 T70525, 2013
   M531364]
FX This work is supported in part by Graduate Research and Innovation
   Foundation of Jiangsu Province, China under Grant KYLX15_0379, in part
   by the National Natural Science Foundation of China under Grants
   61273251, 61401209, and 61402203, in part by the Natural Science
   Foundation of Jiangsu Province under Grant BK20140790, and in part by
   China Postdoctoral Science Foundation under Grants 2014 T70525 and 2013
   M531364.
CR Andrew G., 2013, P ICML, P1247
   [Anonymous], 53 ANN ALL C COMM CO
   [Anonymous], 2000, NIPS
   [Anonymous], 2007, PROC IEEE INT C COMP
   [Anonymous], 2013, P AS C COMP VIS, DOI [DOI 10.1007/978-3-642-37331-2_20, 10.1007/978-3-642-37331-2_20]
   Beck A, 2009, INT CONF ACOUST SPEE, P693, DOI 10.1109/ICASSP.2009.4959678
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Camastra F, 2002, IEEE T PATTERN ANAL, V24, P1404, DOI 10.1109/TPAMI.2002.1039212
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Chen XH, 2012, PATTERN RECOGN, V45, P2005, DOI 10.1016/j.patcog.2011.11.008
   Chibelushi CC, 2002, IEEE T MULTIMEDIA, V4, P23, DOI 10.1109/6046.985551
   Chu DL, 2013, IEEE T PATTERN ANAL, V35, P3050, DOI 10.1109/TPAMI.2013.104
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fu Y, 2008, IEEE T PATTERN ANAL, V30, P2229, DOI 10.1109/TPAMI.2008.154
   Guan NY, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P51, DOI 10.1109/ICMLA.2012.18
   Hardoon DR, 2011, MACH LEARN, V83, P331, DOI 10.1007/s10994-010-5222-7
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hong M., 2013, On the linear convergence of the alternating direction method of multipliers
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hou CP, 2010, PATTERN RECOGN, V43, P720, DOI 10.1016/j.patcog.2009.07.015
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Ji HK, 2015, P 26 BRIT VIS C BMVC
   Jolliffe I., 1986, PRINCIPLE COMPONENTS
   Kimura Akisato, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2933, DOI 10.1109/ICPR.2010.719
   Lampert CH, 2010, LECT NOTES COMPUT SC, V6312, P566, DOI 10.1007/978-3-642-15552-9_41
   Li CG, 2015, P 15 INT C COMP VIS
   Lu JW, 2012, IEEE T INF FOREN SEC, V7, P944, DOI 10.1109/TIFS.2012.2188389
   Martinez A., 1998, AR FACE DATABASE
   Melzer T, 2003, PATTERN RECOGN, V36, P1961, DOI 10.1016/S0031-3203(03)00058-X
   Peng Y, 2010, NEURAL PROCESS LETT, V31, P1, DOI 10.1007/s11063-009-9123-3
   Peng Yan, 2008, Journal of Software, V19, P2822, DOI 10.3724/SP.J.1001.2008.02822
   Sargin ME, 2007, IEEE T MULTIMEDIA, V9, P1396, DOI 10.1109/TMM.2007.906583
   Shen XB, 2014, J VIS COMMUN IMAGE R, V25, P1894, DOI 10.1016/j.jvcir.2014.09.004
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Song YQ, 2008, PATTERN RECOGN, V41, P2789, DOI 10.1016/j.patcog.2008.01.001
   Sugiyama M, 2010, MACH LEARN, V78, P35, DOI 10.1007/s10994-009-5125-7
   Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Sun QS, 2005, PATTERN RECOGN, V38, P449, DOI 10.1016/j.patcog.2004.08.009
   Sun Quan-Sen, 2005, Chinese Journal of Computers, V28, P1524
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   Sun TK, 2008, IEEE DATA MINING, P1043, DOI 10.1109/ICDM.2008.28
   Ting Y, 2015, P 15 INT C COMP VIS
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Waaijenborg S, 2008, STAT APPL GENET MOL, V7
   Wang WR, 2015, INT CONF ACOUST SPEE, P4590, DOI 10.1109/ICASSP.2015.7178840
   Warfield S, 1996, PATTERN RECOGN LETT, V17, P713, DOI 10.1016/0167-8655(96)00036-0
   Witten DM, 2009, STAT APPL GENET MOL, V8, DOI 10.2202/1544-6115.1470
   Witten DM, 2009, BIOSTATISTICS, V10, P515, DOI 10.1093/biostatistics/kxp008
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528
   Yang M, 2013, IEEE I CONF COMP VIS, P689, DOI 10.1109/ICCV.2013.91
   Yu J, 2013, PATTERN RECOGN, V46, P483, DOI 10.1016/j.patcog.2012.08.006
   Zhang DQ, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P629
   Zhang GQ, 2016, NEUROCOMPUTING, V171, P1193, DOI 10.1016/j.neucom.2015.07.048
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
NR 60
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20909
EP 20933
DI 10.1007/s11042-016-3993-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400025
DA 2024-07-18
ER

PT J
AU Khokher, A
   Talwar, R
AF Khokher, Amandeep
   Talwar, Rajneesh
TI A fast and effective image retrieval scheme using color-, texture-, and
   shape-based histograms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Feature extraction; Color histogram;
   Discrete wavelet transform; Robinson compass masks; Graphical user
   interface
ID FEATURES; SYSTEM; INVARIANT
AB The rapid growth of digital image collections has prompted the need for development of software tools that facilitate efficient searching and retrieval of images from large image databases. Towards this goal, we propose a content-based image retrieval scheme for retrieval of images via their color, texture, and shape features. Using three specialized histograms (i.e. color, wavelet, and edge histograms), we show that a more accurate representation of the underlying distribution of the image features improves the retrieval quality. Furthermore, in an attempt to better represent the user's information needs, our system provides an interactive search mechanism through the user interface. Users searching through the database can select the visual features and adjust the associated weights according to the aspects they wish to emphasize. The proposed histogram-based scheme has been thoroughly evaluated using two general-purpose image datasets consisting of 1000 and 3000 images, respectively. Experimental results show that this scheme not only improves the effectiveness of the CBIR system, but also improves the efficiency of the overall process.
C1 [Khokher, Amandeep] IK Gujral Punjab Tech Univ, Elect Engn, Kapurthala, India.
   [Talwar, Rajneesh] CGC Tech Campus, Jhanjeri, India.
C3 I. K. Gujral Punjab Technical University
RP Khokher, A (corresponding author), IK Gujral Punjab Tech Univ, Elect Engn, Kapurthala, India.
EM amandeep.khokher@gmail.com
RI Talwar, Rajneesh/GPK-5841-2022; Talwar, Rajneesh/AAC-3117-2021
OI Talwar, Rajneesh/0000-0002-2109-8858; 
CR Agarwal M, 2012, INT J MULTIMED INF R, V1, P129, DOI 10.1007/s13735-012-0005-5
   Androutsos D, 1999, COMPUT VIS IMAGE UND, V75, P46, DOI 10.1006/cviu.1999.0767
   [Anonymous], 1977, Computer Graphics and Image Processing, DOI 10.1016/s0146-664x(77)80024-5
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Babu CR, 2015, ADV INTELL SYST, V340, P483, DOI 10.1007/978-81-322-2247-7_50
   Carson C., 1999, LECT NOTES COMPUTER, V1614, P509, DOI DOI 10.1007/3-540-48762-X_63
   Chun YD, 2003, IEEE T CIRC SYST VID, V13, P951, DOI 10.1109/TCSVT.2003.816507
   Chun YD, 2008, IEEE T MULTIMEDIA, V10, P1073, DOI 10.1109/TMM.2008.2001357
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Deng YN, 1999, INT CONF ACOUST SPEE, P3017, DOI 10.1109/ICASSP.1999.757476
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Fonseca MJ, 2006, LECT NOTES COMPUT SC, V3926, P291
   Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602
   GUDIVADA VN, 1995, COMPUTER, V28, P18, DOI 10.1109/2.410145
   Guldogan E, 2009, 2009 24TH INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P56, DOI 10.1109/ISCIS.2009.5291921
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   Han JW, 2003, SIGNAL PROCESS-IMAGE, V18, P141, DOI 10.1016/S0923-5965(02)00116-9
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Jegou H., 2010, Aggregating local descriptors into a compact image representation
   Jeong S, 2004, COMPUT VIS IMAGE UND, V94, P44, DOI 10.1016/j.cviu.2003.10.015
   Jiawei H., 2006, DATA MINING CONCEPTS, VSecond, DOI [10.1016/C2009-0-61819-5, DOI 10.1016/C2009-0-61819-5]
   Kokare M, 2007, PATTERN RECOGN LETT, V28, P1240, DOI 10.1016/j.patrec.2007.02.006
   Li XL, 2003, PATTERN RECOGN LETT, V24, P1935, DOI 10.1016/S0167-8655(03)00032-1
   Liapis S, 2004, IEEE T MULTIMEDIA, V6, P676, DOI 10.1109/TMM.2004.834858
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Liu F, 1996, IEEE T PATTERN ANAL, V18, P722, DOI 10.1109/34.506794
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Llorente A., 2010, P ACM INT C IM VID R, P243
   Long FH, 2003, SIG COM TEC, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu TC, 2007, INFORM PROCESS MANAG, V43, P461, DOI 10.1016/j.ipm.2006.07.014
   Ma WY, 1999, MULTIMEDIA SYST, V7, P184, DOI 10.1007/s005300050121
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Matias Y., 1998, SIGMOD Record, V27, P448, DOI 10.1145/276305.276344
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Ooi BC, 1998, VLDB J, V7, P115, DOI 10.1007/s007780050057
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681
   Pi MH, 2006, IEEE T IMAGE PROCESS, V15, P3078, DOI 10.1109/TIP.2006.877509
   Puzicha J, 1997, PROC CVPR IEEE, P267, DOI 10.1109/CVPR.1997.609331
   Rao LK, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0044-z
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith A.R., 1978, P 5 ANN C COMP GRAPH, V12, P12, DOI [10.1145/965139.807361, DOI 10.1145/965139.807361]
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Smith JR, 1996, INT CONF ACOUST SPEE, P2239, DOI 10.1109/ICASSP.1996.545867
   Subrahmanyam M, 2013, COMPUT ELECTR ENG, V39, P762, DOI 10.1016/j.compeleceng.2012.11.023
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Veltkamp R., 2002, MU SYS APPL, P47
   Wan X, 1996, P SOC PHOTO-OPT INS, V2670, P8, DOI 10.1117/12.234782
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
   Wei CH, 2009, PATTERN RECOGN, V42, P386, DOI 10.1016/j.patcog.2008.08.019
   Wu Y., 2002, P IEEE INT C IM PROC, V2, P581
   Xu XQ, 2008, IEEE T INF TECHNOL B, V12, P100, DOI 10.1109/TITB.2007.904149
   Yoo HW, 2005, EXPERT SYST APPL, V28, P347, DOI 10.1016/j.eswa.2004.10.018
   Ze Wang J., 1997, International Journal on Digital Libraries, V1, P311, DOI 10.1007/s007990050026
   Zhang Shiliang., 2009, MM 09 P 17 ACM INT C, P75, DOI DOI 10.1145/1631272.1631285
NR 70
TC 19
Z9 21
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21787
EP 21809
DI 10.1007/s11042-016-4096-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400065
DA 2024-07-18
ER

PT J
AU Lucena, M
   Fuertes, JM
   Martínez-Carrillo, AL
   Ruiz, A
   Carrascosa, F
AF Lucena, M.
   Fuertes, J. M.
   Martinez-Carrillo, A. L.
   Ruiz, A.
   Carrascosa, F.
TI Classification of archaeological pottery profiles using modal analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pottery profiles; Typologies; Shape matching; Modal analysis
ID NONLINEAR DIMENSIONALITY REDUCTION
AB We propose a new vessel profile characterization and comparison technique, based on Modal Analysis. Each profile is represented as a node chain that approximates its contour, and characterized by calculating its deformation spectrum, i.e. the amount of deformation needed to transform it into a reference shape. Two profiles can be compared by computing the Euclidean Distance between their corresponding deformation spectrum vectors. We have done our supervised classification experiments with a profile database labeled by experts. Success rates, which exceed 89 %, are better than the ones obtained by other techniques, while maintaining a low computational cost. Our results suggest that the proposed descriptor captures the morphological features of a given profile.
C1 [Lucena, M.; Fuertes, J. M.; Carrascosa, F.] Univ Jaen, Dept Comp Sci, Jaen 23071, Spain.
   [Martinez-Carrillo, A. L.; Ruiz, A.] Univ Jaen, Res Univ Inst Iberian Archaeol, Jaen 23071, Spain.
C3 Universidad de Jaen; Universidad de Jaen
RP Lucena, M (corresponding author), Univ Jaen, Dept Comp Sci, Jaen 23071, Spain.
EM mlucena@ujaen.es
RI Lucena, Manuel/I-6467-2018; Fuertes Garcia, Jose Manuel/I-8008-2018
OI Lucena, Manuel/0000-0002-5546-3745; Fuertes Garcia, Jose
   Manuel/0000-0001-6624-4102
FU Excellent Projects Program of CICE (regional government); European Union
   ERDF funds [P07-TIC-02773]; Computer Graphics and Geomatics Research
   Group of the University of Jaen [TIC-144]
FX This work was has been supported by the Excellent Projects Program of
   CICE (regional government), the European Union ERDF funds under research
   projects P07-TIC-02773, and the Computer Graphics and Geomatics Research
   Group (TIC-144) of the University of Jaen.
CR Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Chapa T, 1997, NECROPOLIS IBERICA C
   Fuertes J., 2001, 12 SCAND C IM AN SCI, V1, P646
   Fuertes JM, 2003, PROCEEDINGS EC-VIP-MC 2003, VOLS 1 AND 2, P201
   Kampel M, 2003, J VISUAL COMP ANIMAT, V14, P111, DOI 10.1002/vis.310
   Karasik A, 2011, J ARCHAEOL SCI, V38, P2644, DOI 10.1016/j.jas.2011.05.023
   Lucena M, 2016, MULTIMED TOOLS APPL, V75, P3677, DOI 10.1007/s11042-014-2063-6
   Lucena M, 2014, LECT NOTES COMPUT SC, V8495, P341, DOI 10.1007/978-3-319-07491-7_35
   Maaten L, 2009, BAR INT SERIES, V2079, P356
   Mom V, 2006, ADV DATA ANAL
   Mom V., 2007, WORLD IS YOUR EYES C, P95
   Nastar C, 1996, IEEE T PATTERN ANAL, V18, P1067, DOI 10.1109/34.544076
   Nautiyal V., 2006, EXPLORING NEW FRONTI
   PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660
   Rice PrudenceM., 1987, POTTERY ANAL
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Ruiz A., 1983, Cortes A y F. Cuadernos de Prehistoria de la Universidad de Granada, V8, P251
   Ruiz Rodriguez A, 1984, CUAD PREHIST U GRANA, V9, P195
   Saragusti I, 2005, J ARCHAEOL SCI, V32, P841, DOI 10.1016/j.jas.2005.01.002
   Shennan S., 1975, SCI ARCHAEOL, V15, P17
   Sieso J Pereira, 1989, TRABAJOS PREHIST, V46, P149, DOI DOI 10.3989/TP.1989.V46.I0.592
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154
NR 23
TC 10
Z9 10
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21565
EP 21577
DI 10.1007/s11042-016-4076-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400055
DA 2024-07-18
ER

PT J
AU Atawneh, S
   Almomani, A
   Al Bazar, H
   Sumari, P
   Gupta, B
AF Atawneh, Samer
   Almomani, Ammar
   Al Bazar, Hussein
   Sumari, Putra
   Gupta, Brij
TI Secure and imperceptible digital image steganographic algorithm based on
   diamond encoding in DWT domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Imperceptibility; Embedding payload; Diamond
   encoding (DE); Discrete wavelet transform (DWT)
ID WATERMARKING; ROBUST
AB This paper presents a new efficient embedding algorithm in the wavelet domain of digital images based on the diamond encoding (DE) scheme. Current discrete wavelet transform (DWT) steganography adds an unacceptable distortion to the images and is considered as an ineffective in terms of security. Applying the DE scheme to the current DWT steganographic methods solves the problems of these methods, and reduces the distortion added to the images, and thus improves the embedding efficiency. The proposed algorithm first converts the secret image into a sequence of base-5 digits. After that, the cover image is transformed into the DWT domain and segmented into 2 x 1 coefficient pairs. The DE scheme is used then to change at most one coefficient of each coefficient pair to embed the base-5 digits. Experimental results depict that the proposed algorithm is more efficient in embedding compared to other methods in terms of embedding payload and image quality. Moreover, the proposed algorithm is attacked by well-known steganalysis software. Results are showing that the proposed algorithm is secure against the powerful universal steganalyzer "ensemble classifier" and the histogram attack. The results also reveal that the proposed algorithm is robust against different image processing attacks such as compression, added noise, and cropping attacks.
C1 [Atawneh, Samer] Saudi Elect Univ, Coll Comp & Informat, Riyadh 11673, Saudi Arabia.
   [Almomani, Ammar] Al Balqa Appl Univ, Al Huson Univ Coll, POB 50, Irbid, Jordan.
   [Al Bazar, Hussein] Arab Open Univ, Fac Comp Studies, Dammam 32423, Saudi Arabia.
   [Sumari, Putra] Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
   [Gupta, Brij] Natl Inst Technol Kurukshetra, Dept Comp Engn, Kurukshetra, Haryana, India.
C3 Saudi Electronic University; Al-Balqa Applied University; Arab Open
   University-Saudi Arabia; Universiti Sains Malaysia; National Institute
   of Technology (NIT System); National Institute of Technology Kurukshetra
RP Atawneh, S (corresponding author), Saudi Elect Univ, Coll Comp & Informat, Riyadh 11673, Saudi Arabia.
EM satawneh@seu.edu.sa; ammarnav6@gmail.com; Halbazar@arabou.edu.sa;
   putras@cs.usm.my; gupta.brij@gmail.com
RI almomani, ammar/L-3819-2019; Gupta, Brij B/E-9813-2011; Atawneh,
   Samer/HSB-7502-2023; Sumari, Putra/I-1070-2016
OI almomani, ammar/0000-0002-8808-6114; Gupta, Brij B/0000-0003-4929-4698;
   Atawneh, Samer/0000-0001-7590-7887; Sumari, Putra/0000-0002-2644-6428
CR Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   Al-Korbi HA, 2015, IEEE JORD C APPL EL, V1, P1
   [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], 2011, INT J COMPUTER SCI C
   [Anonymous], 2014, INT J ENG TECHNOLOGY
   Antony Jisna, 2012, J COMPUTER, V52, p975 
   Atawneh S, 2013, IETE TECH REV, V30, P344, DOI 10.4103/0256-4602.116724
   Baby D, 2015, PROCEDIA COMPUT SCI, V46, P612, DOI 10.1016/j.procs.2015.02.105
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   CHAO RM, 2009, EURASIP J INFORM SEC
   Chen M., 2006, INT C INT INF HID MU
   Hemalatha S., 2013, INT J CRYPTOGRAPHY I, V3, P17
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P3287, DOI 10.1016/j.cnsns.2011.12.012
   Keyvanpour M, 2013, MATH COMPUT MODEL, V58, P56, DOI 10.1016/j.mcm.2012.07.008
   Mali SN, 2012, DIGIT SIGNAL PROCESS, V22, P314, DOI 10.1016/j.dsp.2011.09.003
   Nag A., 2011, INT J COMPUTER SCI S, V4, P561
   Ndoundam R, J INFORM SECURITY AP
   Singh A., 2016, Microscale Technologies for Cell Engineering, DOI [10.1007/978-3-319-20726-1, DOI 10.1007/978-3-319-20726-1, DOI 10.1007/S11042015-27547]
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Sun SL, 2016, INFORM PROCESS LETT, V116, P93, DOI 10.1016/j.ipl.2015.09.016
   Verma Avushi, 2013, INT J COMPUT SCI BUS, V1
NR 22
TC 105
Z9 105
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18451
EP 18472
DI 10.1007/s11042-016-3930-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800014
DA 2024-07-18
ER

PT J
AU Netto, SMB
   Silva, AC
   de Paiva, AC
   Nunes, RA
   Gattass, M
AF Barros Netto, Stelmo Magalhaes
   Silva, Aristofanes Correa
   de Paiva, Anselmo Cardoso
   Nunes, Rodolfo Acatauassu
   Gattass, Marcelo
TI Unsupervised detection of density changes through principal component
   analysis for lung lesion classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Lung lesion; Detection of changes in tissues; Principal
   component analysis; Temporal analysis and evaluation
ID TEXTURE ANALYSIS; PULMONARY NODULES; HETEROGENEITY; GROWTH; RECIST;
   IMAGES
AB Lung cancer remains one of the most common cancers worldwide. Temporal evaluation is a useful tool for analyzing the malignant behavior of a lesion during treatment or that of indeterminate lesions which may be benign. Thereby, this work proposes a methodology for analysis, quantification and visualization of unsupervised changes in lung lesions, through principal component analysis. From change regions, we extracted texture features for lesion classification as benign or malignant. To reach this purpose, two databases with distinct behavior were used, one of which concerning malign under treatment and another indeterminate, but likely benign, lesions. The results have shown that the lesion's density changes in a public database of malignant lesions under treatment were greater than the private database of benign lung nodules. From the texture analysis of the regions where the density changes occurred, we were able to discriminate lung lesions with an accuracy of 98.41 %, showing that these changes could point out the nature of the lesion. Other contribution was visualization of changes occurring in the lesions over time. Besides, we quantified these changes and analyzed the entire set through volumetry, the most commonly used technique to evaluate progression of lung lesions.
C1 [Barros Netto, Stelmo Magalhaes; Silva, Aristofanes Correa; de Paiva, Anselmo Cardoso] Fed Univ Maranho UFMA, Maranhao, Brazil.
   [Nunes, Rodolfo Acatauassu] State Univ Rio de Janeiro UERJ, Dept Gen Surg, Maracana, RJ, Brazil.
   [Gattass, Marcelo] Pontifical Catholic Univ Rio de Janeiro PUC Rio, Gavea, RJ, Brazil.
C3 Universidade do Estado do Rio de Janeiro; Pontificia Universidade
   Catolica do Rio de Janeiro
RP Netto, SMB (corresponding author), Fed Univ Maranho UFMA, Maranhao, Brazil.
EM stelmo.netto@ufma.br; ari@dee.ufma.br; paiva@deinf.ufma.br;
   rodolfoacatauassu@yahoo.com.br; mgattass@tecgraf.puc-rio.br
RI Paiva, Anselmo/L-2358-2013
OI Paiva, Anselmo/0000-0003-4921-0626
FU CAPES; CNPq; FAPEMA
FX The authors acknowledge CAPES, CNPq and FAPEMA for financial support. We
   are grateful to the PLD database for publishing the lung lesions used in
   this work and to Pedro Ernesto University Hospital, RJ, Brazil, for the
   lung nodule database.
CR Aberle DR, 2011, NEW ENGL J MED, V365, P395, DOI 10.1056/NEJMoa1102873
   Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P3537, DOI 10.1007/s11042-016-3884-2
   [Anonymous], COMPUTER AIDED DIAGN
   [Anonymous], AUTOMATIC SEGMENTATI
   [Anonymous], INT J INNOVATIVE RES
   [Anonymous], CANC BRAS DAD REG BA
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], AM SCI PUBLISH, DOI DOI 10.1007/11866565
   [Anonymous], LWA
   Netto SMB, 2017, MED BIOL ENG COMPUT, V55, P295, DOI 10.1007/s11517-016-1510-0
   Bashir U, 2016, AM J ROENTGENOL, V207, P534, DOI 10.2214/AJR.15.15864
   Böttcher J, 2014, ACTA ONCOL, V53, P759, DOI 10.3109/0284186X.2013.852688
   Chen YW, 2006, STUD FUZZ SOFT COMP, V207, P315
   CHU A, 1990, PATTERN RECOGN LETT, V11, P415, DOI 10.1016/0167-8655(90)90112-F
   Costa Patricio Soares, 2013, J Aging Res, V2013, P302163, DOI 10.1155/2013/302163
   Duindam T., 2009, The Second International Workshop on Pulmonary Image Analysis, (London, UK), P389
   Eisenhauer EA, 2009, EUR J CANCER, V45, P228, DOI 10.1016/j.ejca.2008.10.026
   El-Baz A, 2005, INT CONGR SER, V1281, P1115, DOI 10.1016/j.ics.2005.03.340
   Field JK, 2013, LANCET, V382, P732, DOI 10.1016/S0140-6736(13)61614-1
   Gu SC, 2011, MED PHYS, V38, P4406, DOI 10.1118/1.3602457
   Han H, 2015, IEEE J BIOMED HEALTH, V19, P648, DOI 10.1109/JBHI.2014.2328870
   Harrison LCV, 2010, ACAD RADIOL, V17, P696, DOI 10.1016/j.acra.2010.01.005
   Jaffe CC, 2006, J CLIN ONCOL, V24, P3245, DOI 10.1200/JCO.2006.06.5599
   Kim TY, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/536217
   Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1137
   Lai D, 2007, P ANN INT IEEE EMBS, P6524
   Lindell RM, 2007, RADIOLOGY, V242, P555, DOI 10.1148/radiol.2422052090
   Linning E, 2013, ACTA RADIOL, V54, P904, DOI 10.1177/0284185113485572
   Parikh J, 2014, RADIOLOGY, V272, P100, DOI 10.1148/radiol.14130569
   Puri M, 2005, MED BIOL ENG COMPUT, V43, P756, DOI 10.1007/BF02430954
   Rajkumar V, 2015, BRIT J CANCER, V112, P1882, DOI 10.1038/bjc.2015.166
   Reeves AP, 2009, IEEE ENG MED BIO, P3715, DOI 10.1109/IEMBS.2009.5334807
   Reeves AP, 2006, IEEE T MED IMAGING, V25, P435, DOI 10.1109/TMI.2006.871548
   Schroeder W., 2003, The ITK software guide
   Tao C, 2009, AM J ROENTGENOL, V192, P624, DOI 10.2214/AJR.08.1307
   Yip C, 2015, J THORAC IMAG, V30, P300, DOI 10.1097/RTI.0000000000000164
   Zhang LJ, 2012, RADIOLOGY, V263, P279, DOI 10.1148/radiol.11101372
   Zhang YY, 2012, INT J BIOMED IMAGING, V2012, DOI 10.1155/2012/762804
   Zhen Y, 2007, CHANDOS ASIAN STUD, P1
NR 39
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18929
EP 18954
DI 10.1007/s11042-017-4414-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800037
DA 2024-07-18
ER

PT J
AU Kar, A
   Sarkar, S
   Bhattacharjee, D
AF Kar, Arindam
   Sarkar, Sanchayan
   Bhattacharjee, Debotosh
TI Local Centre of Mass Face for face recognition under varying
   illumination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Centre of mass; Illumination invariant; Reflectance model; Gradient;
   Mass distribution; Luminosity
ID BINARY PATTERNS; QUOTIENT IMAGE; INVARIANT; COMPENSATION; NORMALIZATION;
   EIGENFACES; TRANSFORM; ALGORITHM; SUBSPACES; HISTOGRAM
AB In this work we propose a novel method to extract illumination insensitive features for face recognition called local centre of mass face (LCMF). In this LCMF approach the gradient angle between the centre of mass and centre pixel of a selected neighborhood is extracted. Theoretically it is shown that this feature is illumination invariant using the Illumination Reflectance Model (IRM) and is robust to different illumination variations. It is also shown that this method does not involve any explicit computation of Luminance (L) component and as centre of mass is an inherent feature of a mass distribution, its slope with the centre pixel of the neighborhood has local edge preserving capabilities. The angle of the slope obtained using Centre of Mass with the centre pixel of the neighborhood is used as a feature vector. This feature vector is directed from the darkest section of the neighborhood to the brightest section of the neighborhood as Centre of Mass is always positioned towards the brighter side of a mass distribution and hence encrypts the edge orientation. Using the L-1 norm distance measure, these feature vectors are used to classify the images. The method does not involve any preprocessing and training of images. The proposed method has been successfully tested under different illumination variant databases like AR, CMU-PIE, and extended Yale B using standard protocols, and performance is compared with recently published methods in terms of rank-1 recognition accuracy. The method is also applied on Sketch-Photo pair database like CUHK. For unbiased or fair performance evaluation, the Sensitivity and Specificity are also being measured for the proposed method on all the databases. The proposed method gives better accuracy performance and outperforms other recent face recognition methods.
C1 [Kar, Arindam] Indian Stat Inst, Kolkata 700108, India.
   [Sarkar, Sanchayan] Univ Calcutta, Dept Comp Sci & Engn, Kolkata, India.
   [Bhattacharjee, Debotosh] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata;
   University of Calcutta; Jadavpur University
RP Sarkar, S (corresponding author), Univ Calcutta, Dept Comp Sci & Engn, Kolkata, India.
EM kgparindamkar@gmail.com; sanchayansarkar@yahoo.com;
   debotoshb@hotmail.com
RI Bhattacharjee, Debotosh/L-8521-2015; Bhattacharjee, Debotosh/Q-4065-2019
OI Bhattacharjee, Debotosh/0000-0002-1163-6413; Bhattacharjee,
   Debotosh/0000-0002-1163-6413
CR Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], ELECT MARINE 2004
   [Anonymous], COMP VIS ANDNNNNN 20
   [Anonymous], AN MOD FAC GEST 2003
   [Anonymous], AUT FAC GEST REC 200
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], P 17 INT C ICPR 2004
   [Anonymous], 2004, Advanced astrophysics
   [Anonymous], INTERDISCIPL SYST RE
   [Anonymous], INT C AUD VID BAS BI
   [Anonymous], J COMPUT SCI ISSUES
   [Anonymous], 2005, P 2 INT C AUDIO VIDE
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], EUR C COMP VIS
   [Anonymous], NEURAL NETWORKS IEEE
   [Anonymous], ARXIV13121683
   [Anonymous], RECENT ADV MACHINE V
   [Anonymous], 2013, ICISIP
   [Anonymous], ARXIV13121512
   [Anonymous], AUT FAC GEST REC 200
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Batur AU, 2001, PROC CVPR IEEE, P296
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484
   Bhatt H S, 2010, BIOMETRICS THEORY AP, P1
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Cao X, 2012, PATTERN RECOGN, V45, P1299, DOI 10.1016/j.patcog.2011.09.010
   Chen HF, 2000, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2000.855827
   Chen T, 2006, IEEE T PATTERN ANAL, V28, P1519, DOI 10.1109/TPAMI.2006.195
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   CREWE AV, 1970, SCIENCE, V168, P1338, DOI 10.1126/science.168.3937.1338
   Du S, 2010, IEEE T CIRC SYST VID, V20, P1165, DOI 10.1109/TCSVT.2010.2045817
   Faraji MR, 2014, IEEE SIGNAL PROC LET, V21, P1457, DOI 10.1109/LSP.2014.2343213
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Flynn C, 2006, MON NOT R ASTRON SOC, V372, P1149, DOI 10.1111/j.1365-2966.2006.10911.x
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Gao XN, 2008, IEEE T CIRC SYST VID, V18, P487, DOI 10.1109/TCSVT.2008.918770
   Gao XB, 2012, IEEE T CIRC SYST VID, V22, P1213, DOI 10.1109/TCSVT.2012.2198090
   Gao YS, 2002, IEEE T PATTERN ANAL, V24, P764, DOI 10.1109/TPAMI.2002.1008383
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Goh YZ, 2011, EXPERT SYST APPL, V38, P3959, DOI 10.1016/j.eswa.2010.09.057
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Gross R, 2003, LECT NOTES COMPUT SC, V2688, P10
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Horn B.K.P, 1986, Robot Vision
   Hurley DJ, 2000, IEEE IMAGE PROC, P25, DOI 10.1109/ICIP.2000.900883
   Jain A.K., 2011, HDB FACE RECOGNITION, V1
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Klare B., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1513, DOI 10.1109/ICPR.2010.374
   Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229
   Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180
   Kundu S, 1999, PATTERN RECOGN, V32, P1149, DOI 10.1016/S0031-3203(98)00143-5
   Lai ZR, 2015, IEEE T IMAGE PROCESS, V24, P1735, DOI 10.1109/TIP.2015.2409988
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lee KC, 2001, PROC CVPR IEEE, P519
   Lee PH, 2012, IEEE T IMAGE PROCESS, V21, P4280, DOI 10.1109/TIP.2012.2202670
   Lian ZC, 2012, PATTERN RECOGN LETT, V33, P1725, DOI 10.1016/j.patrec.2012.04.020
   Lopez-Molina C, 2010, PATTERN RECOGN, V43, P3730, DOI 10.1016/j.patcog.2010.05.035
   Martinez A., 1998, AR FACE DATABASE
   Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X
   Ni JB, 2010, PATTERN RECOGN, V43, P1607, DOI 10.1016/j.patcog.2009.09.020
   Olenick R.P., 2008, The Mechanical Universe: Introduction to Mechanics and Heat
   Pankanti S, 2000, COMPUTER, V33, P46, DOI 10.1109/2.820038
   Pernkopf F, 2003, NDT&E INT, V36, P609, DOI 10.1016/S0963-8695(03)00081-1
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Roy H, 2016, APPL SOFT COMPUT, V46, P967, DOI 10.1016/j.asoc.2015.12.006
   Roy H, 2016, IEEE T INF FOREN SEC, V11, P1412, DOI 10.1109/TIFS.2016.2530043
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964
   Struc V, 2009, LECT NOTES COMPUT SC, V5707, P1, DOI 10.1007/978-3-642-04391-8_1
   Sun GY, 2007, PATTERN RECOGN, V40, P2766, DOI 10.1016/j.patcog.2007.01.006
   Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vishwakarma Virendra P., 2009, International Journal of Recent Trends in Engineering, V1, P318
   Wang B, 2011, IEEE SIGNAL PROC LET, V18, P462, DOI 10.1109/LSP.2011.2158998
   Wang HT, 2004, IEEE IMAGE PROC, P1397
   Wang HT, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P819
   Wang NN, 2013, IEEE T NEUR NET LEAR, V24, P1364, DOI 10.1109/TNNLS.2013.2258174
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   WRIGHT WE, 1977, PATTERN RECOGN, V9, P151, DOI 10.1016/0031-3203(77)90013-9
   Xie XD, 2005, PATTERN RECOGN, V38, P221, DOI 10.1016/j.patcog.2004.07.002
   Zhang TP, 2009, IEEE T IMAGE PROCESS, V18, P2599, DOI 10.1109/TIP.2009.2028255
   Zhang W, 2011, PROC CVPR IEEE, P513, DOI 10.1109/CVPR.2011.5995324
   Zhong FJ, 2013, NEUROCOMPUTING, V119, P375, DOI 10.1016/j.neucom.2013.03.020
NR 90
TC 6
Z9 6
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 19211
EP 19240
DI 10.1007/s11042-017-4579-z
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800049
DA 2024-07-18
ER

PT J
AU Suryanto, Y
   Suryadi
   Ramli, K
AF Suryanto, Yohan
   Suryadi
   Ramli, Kalamullah
TI A new image encryption using color scrambling based on chaotic
   permutation multiple circular shrinking and expanding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image encryption; Very large key space; Chaotic permutation;
   Robust to noise; Circular shrinking and expanding; Image series
ID BLOCK CIPHER; SCHEME; ALGORITHM; MAP; SYSTEM
AB In this paper, we propose a new color image encryption method using color scrambling based on the chaotic permutation multiple circular shrinking and expanding (CPMCS/ CPMCE). The plain color image with a size of m x n x 3 is arranged in two-dimensional array, where each row consists of the Red, Green, and Blue (RGB) component, forming two-dimensional array with a size of m x 3n. The arranged 2D array then permuted by CPMCS for the each row and column. To reconstruct the original image, the ciphered image is arranged in 2D array then is permuted by CPMCE for each column and row. The proposed method is characterized by very high key space that reaches 2(2,895,713) for an image size of 256x256, so that resistance to brute force attack and can anticipate the emergence of quantum computers. It also resistant to a differential attack due to change a single bit in the plain image causes a significant change in the ciphered image. The proposed encryption also yield completely difference ciphered image series from the same plain image just using arbitrary increment sequence key. It is also robust to JPEG compression so the ciphered image can be stored in smaller size, such as for the ciphered Lena image only needs 1/5.2 of the original one when compressed using JPEG 70 %. It also resistant to noise scheme (Gaussian, Poisson, Salt&Pepper, and spekle), data loss, and brightness-contrast adjustment, so the ciphered image can be transmitted in a non error free communication system.
C1 [Suryanto, Yohan] Univ Indonesia, Dept Elect Engn, Depok, Indonesia.
   [Suryadi; Ramli, Kalamullah] Univ Indonesia, Dept Math, Depok, Indonesia.
C3 University of Indonesia; University of Indonesia
RP Suryanto, Y (corresponding author), Univ Indonesia, Dept Elect Engn, Depok, Indonesia.
EM yohan.suryanto@ui.ac.id; yadi.mt@sci.ui.ac.id; k.ramli@ee.ui.ac.id
RI Ramli, Kalamullah/AAI-1405-2019
OI Ramli, Kalamullah/0000-0002-0374-4465; Suryanto,
   Yohan/0000-0001-6896-8243
FU Rambinet Digital Network [RDN_RG/III/2015]
FX Prof. Akhmad Herman Yuwono, Associate Dean for Research and Community
   Services Faculty of Engineering-Universitas Indonesia in providing higly
   valuable advice during writing our research. Yohan also acknowledges to
   Rambinet Digital Network in providing research grant (RDN_RG/III/2015).
CR Akhavan A, 2011, J FRANKLIN I, V348, P1797, DOI 10.1016/j.jfranklin.2011.05.001
   [Anonymous], CRYPT TOD
   [Anonymous], 2014, IMAGE ENCRYPTION USI, DOI DOI 10.1109/ICRTIT.2014.6996091
   [Anonymous], 2010, IJ NETWORK SECURITY
   Awad A, 2010, IAENG INT J COMPUT S, V37
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Barker  E.B., 2015, NIST SPECIAL PUBL, P800
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Bigdeli N, 2012, ENG APPL ARTIF INTEL, V25, P753, DOI 10.1016/j.engappai.2012.01.007
   Borujeni SE, 2013, TELECOMMUN SYST, V52, P525, DOI 10.1007/s11235-011-9458-8
   Elgammal A, 2008, CS443 DIGITAL IMAGIN
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   Fu C., 2013, P 2013 IEEE INT C IE, P1
   Gao TG, 2008, CHAOS SOLITON FRACT, V38, P213, DOI 10.1016/j.chaos.2006.11.009
   Howard A., 2010, ELEMENTARY LINEAR AL
   Hsiao HI, 2015, SIGNAL PROCESS, V117, P281, DOI 10.1016/j.sigpro.2015.06.007
   Jolfaei Alireza, 2010, 2010 Proceedings of International Conference on Artificial Intelligence and Computational Intelligence (AICI 2010), P369, DOI 10.1109/AICI.2010.198
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Munir R, 2014, TEL SYST SERV APPL T, P1
   N Instruments, 2013, PEAK SIGN TO NOIS RA
   NSA, 2016, CRYPT TOD
   Nurpeti E., 2014, TELKOMNIKA, V12, P675
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Patidar V, 2011, OPT COMMUN, V284, P4331, DOI 10.1016/j.optcom.2011.05.028
   Rukhin A., 2001, NIST SPECIAL PUBLICA
   Sathishkumar G. A., 2012, 2012 IEEE Symposium on Computers & Informatics, P247, DOI 10.1109/ISCI.2012.6222703
   Shujiang Xu, 2008, 2008 International Conference on Computational Intelligence and Security, P433, DOI 10.1109/CIS.2008.146
   Soleymani A, 2012, P WORLD ACAD SCI ENG
   Soleymani A, 2014, SCI WORLD J, DOI 10.1155/2014/536930
   Sui LS, 2014, OPT LASER ENG, V56, P1, DOI 10.1016/j.optlaseng.2013.12.001
   Suryanto Y, 2016, J INFORM HIDING MULT, V7, P697
   Suryanto Y, 2015, 2015 INTERNATIONAL CONFERENCE QUALITY IN RESEARCH (QIR), P65, DOI 10.1109/QiR.2015.7374896
   Tian-gong P, 2013, INT J SEC APPL, V7
   Tong XJ, 2013, COMMUN NONLINEAR SCI, V18, P1725, DOI 10.1016/j.cnsns.2012.11.002
   Volos CK, 2013, SIGNAL PROCESS, V93, P1328, DOI 10.1016/j.sigpro.2012.11.008
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wu Xiangjun, 2015, PLOS ONE, V10
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y., 2011, ARXIV11035520
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Yang HQ, 2010, COMMUN NONLINEAR SCI, V15, P3507, DOI 10.1016/j.cnsns.2010.01.004
   Ye GD, 2014, APPL SOFT COMPUT, V22, P351, DOI 10.1016/j.asoc.2014.05.025
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Zhang M, 2014, J SYST SOFTWARE, V98, P140, DOI 10.1016/j.jss.2014.08.066
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
   Zhenjun Tang, 2011, Journal of Multimedia, V6, P202, DOI 10.4304/jmm.6.2.202-206
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 52
TC 17
Z9 17
U1 1
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16831
EP 16854
DI 10.1007/s11042-016-3954-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100036
DA 2024-07-18
ER

PT J
AU Li, YF
   He, W
AF Li Yufeng
   He Wei
TI Research on SAR image change detection algorithm based on hybrid genetic
   FCM and image registration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image registration; Change detection; Synthetic aperture radar (SAR);
   Principal component analysis (PCA); Hybrid genetic; Fuzzy C-means (FCM)
ID REMOTE-SENSING IMAGES; MULTIPLE-SCLEROSIS; URBAN AREAS; SEGMENTATION;
   MRI
AB At present, image change detection technology as an important image processing technology has been widely used, and a novel synthetic aperture radar (SAR) image change detection algorithm based on hybrid genetic FCM and image registration is proposed in this paper. First of all, the algorithm performs registration with two photographs taken in the same region images at different time using Harris operator and Sift operator, then, the ratio method and logarithmic method is combined to extract the initial differences image, and then the Principal Component Analysis (PCA) method is used to reduce the dimension of the difference image. Finally the hybrid genetic fuzzy C-means (FCM) algorithm is used to determine the classification of feature vector space, and the classification results are compared with the reference image, to obtain the change information. The purpose of using hybrid genetic FCM is to divide the initial difference image clustering into the changed type and the unchanged type, so as to get the final segmentation result. The FCM algorithm improved by genetic algorithm can effectively avoid that the FCM algorithm will fall into local minimum when the initial cluster center selection is not appropriate. As the genetic algorithm is a global optimization search algorithm, it can improve the segmentation effect of FCM. The experimental results show that the proposed algorithm has the highest global correct rate of 98.10% and 99.74%.
C1 [Li Yufeng; He Wei] Shenyang Aerosp Univ, Coll Elect & Informat Engn, Shenyang 264025, Peoples R China.
C3 Shenyang Aerospace University
RP Li, YF (corresponding author), Shenyang Aerosp Univ, Coll Elect & Informat Engn, Shenyang 264025, Peoples R China.
EM 18804038409@163.com
FU National Natural Science Fund [61171081]; Natural Science Foundation of
   Liaoning Province [2013024008]
FX The National Natural Science Fund (61171081). Natural Science Foundation
   of Liaoning Province (2013024008).
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Balz T, 2010, INT J REMOTE SENS, V31, P3369, DOI 10.1080/01431161003727671
   Bosc M, 2003, NEUROIMAGE, V20, P643, DOI 10.1016/S1053-8119(03)00406-3
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Bujor F, 2004, IEEE T GEOSCI REMOTE, V42, P2073, DOI 10.1109/TGRS.2004.835304
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Dekker RJ, 2003, IEEE T GEOSCI REMOTE, V41, P1950, DOI 10.1109/TGRS.2003.814628
   Du PJ, 2012, IEEE J-STARS, V5, P1076, DOI 10.1109/JSTARS.2012.2200879
   Ho SS, 2010, IEEE T PATTERN ANAL, V32, P2113, DOI 10.1109/TPAMI.2010.48
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Marchesi S, 2010, IEEE T IMAGE PROCESS, V19, P1877, DOI 10.1109/TIP.2010.2045070
   Matsuoka M, 2004, EARTHQ SPECTRA, V20, P975, DOI 10.1193/1.1774182
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Rey D, 2002, MED IMAGE ANAL, V6, P163, DOI 10.1016/S1361-8415(02)00056-7
   RIGNOT EJM, 1993, IEEE T GEOSCI REMOTE, V31, P896, DOI 10.1109/36.239913
   Robin A, 2010, IEEE T PATTERN ANAL, V32, P1977, DOI 10.1109/TPAMI.2010.37
NR 18
TC 3
Z9 5
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 15137
EP 15153
DI 10.1007/s11042-017-4687-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400033
DA 2024-07-18
ER

PT J
AU Zhou, ZH
   Dai, M
   Zhao, RZ
   Li, B
   Zhong, HQ
   Wen, YM
AF Zhou, Zhiheng
   Dai, Ming
   Zhao, Ruzheng
   Li, Bo
   Zhong, Huiqiang
   Wen, Yiming
TI Video error concealment scheme based on tensor model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Error concealment; Tensor; Block matching; Low rank approximation
ID MOTION VECTOR RECOVERY; ALGORITHM; DECOMPOSITIONS
AB Since compressed video sequences may be corrupted or lost when transmitted over error-prone networks, error concealment techniques are very important for video communication. As a video sequence is a group of high-dimensional data, it can be considered as a big 3rd-order tensor. The methodologies that matricize high-dimensional data and then apply matrix-based method for further analysis often cause a loss of the internal structure information. Therefore, we built a tensor model to process such data, in order to preserve the natural multilinear structure. The key idea of our tensor model includes two parts. The first part is to construct a small tensor consist of the corrupted block and its several reference blocks. This part could be accomplished by block matching, but the traditional block matching might give a wrong match when the corrupted area is large and continuous. In order to overcome such situation, we proposed a flexible block matching scheme (FBM). The second part is to figure out the data in the corrupted part by tensor low rank approximation. Unlike the traditional low rank approximation, we did not fix the rank of core tensor as a constant number. Instead, the rank is flexible in our method, which is adaptive to the situation. Compared with some other error concealment method in the experiments, our method is able to achieve significantly higher PSNR (Peak Signal to Noise Ratio) as well as better visual quality.
C1 [Zhou, Zhiheng; Dai, Ming; Zhao, Ruzheng; Li, Bo; Zhong, Huiqiang; Wen, Yiming] South China Univ Technol, Guangzhou, Guangdong, Peoples R China.
C3 South China University of Technology
RP Zhou, ZH (corresponding author), South China Univ Technol, Guangzhou, Guangdong, Peoples R China.
EM zhouzh@scut.edu.cn
RI Zhou, zhiheng/HNC-4591-2023
FU National Natural Science Foundation of China [61372142, U1401252]
FX The authors would like to thank all the anonymous reviewers for their
   valuable comments. This work is supported by National Natural Science
   Foundation of China (61372142, U1401252).
CR [Anonymous], IEEE T CIRCUITS SYST
   Braman K, 2010, TENS DEC APPL IM PRO
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Chen Y, 2008, IEEE T MULTIMEDIA, V10, P2, DOI 10.1109/TMM.2007.911223
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995
   Haskell P., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P545, DOI 10.1109/ICASSP.1992.226155
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Lam W. M., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P417, DOI 10.1109/ICASSP.1993.319836
   Lee PJ, 2014, J DISP TECHNOL, V10, P560, DOI 10.1109/JDT.2014.2309988
   Lie WN, 2014, IEEE T MULTIMEDIA, V16, P216, DOI 10.1109/TMM.2013.2281587
   Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39
   Nguyen D. T., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2081, DOI 10.1109/ICIP.2011.6115891
   Persson D, 2008, IEEE T IMAGE PROCESS, V17, P145, DOI 10.1109/TIP.2007.914151
   Quan J, 2013, ABSTR APPL ANAL, DOI 10.1155/2013/342545
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Suh JW, 2002, IEEE T BROADCAST, V48, P299, DOI 10.1109/TBC.2002.806797
   SUN H, 1992, IEEE T CONSUM ELECTR, V38, P108, DOI 10.1109/30.156671
   Tsekeridou S, 1999, INT CONF ACOUST SPEE, P3397, DOI 10.1109/ICASSP.1999.757571
   Wang Z, 1998, IEEE T IMAGE PROCESS, V7, P1056, DOI 10.1109/83.701166
   Yan B, 2003, IEEE T CONSUM ELECTR, V49, P1416, DOI 10.1109/TCE.2003.1261249
   Yan B, 2010, IEEE T IMAGE PROCESS, V19, P98, DOI 10.1109/TIP.2009.2032311
   Zheng JH, 2005, IEEE T MULTIMEDIA, V7, P507, DOI 10.1109/TMM.2005.843343
   Zheng JH, 2003, IEEE T BROADCAST, V49, P383, DOI 10.1109/TBC.2003.819050
   Zhou GX, 2015, IEEE T IMAGE PROCESS, V24, P4990, DOI 10.1109/TIP.2015.2478396
NR 25
TC 9
Z9 11
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 16045
EP 16061
DI 10.1007/s11042-016-3894-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900035
DA 2024-07-18
ER

PT J
AU Bao, ZK
   Luo, XY
   Zhang, WM
   Yang, CF
   Liu, FL
AF Bao, Zhenkun
   Luo, Xiangyang
   Zhang, Weiming
   Yang, Chunfang
   Liu, Fenlin
TI Improving side-informed JPEG steganography using two-dimensional
   decomposition embedding method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Side-informed JPEG steganography; Two-dimensional
   decomposition; Adaptive steganography; Double-layer embedding
ID IMAGES
AB Side-informed JPEG steganography is a renowned technology of concealing information for the high resistance to blind detection. The existed popular side-informed JPEG steganographic algorithms use binary embedding method with the corresponding binary distortion function. Then, the embedding methods and binary distortion functions of popular side-informed JPEG steganographic algorithms are analyzed and the wasted secure capacity by using the binary embedding operation is pointed out. Thus, the detection resistance of the side-informed JPEG steganographic algorithms can be improved if the embedding operation is changed to ternary mode which causes less changes than binary embedding at same payload. The problem of using ternary embedding is to define a suitable ternary distortion function. To solve this, a two-dimensional decomposition embedding method is proposed in this paper. The proposed ternary distortion function is defined by transforming the problem into two different binary distortion functions of two layers that based on the ternary entropy decomposition. Meanwhile, the proposed method ensures the minimal value of the distortion function on each layer can be reached in theory. Several popular side-inform JPEG steganographic algorithms (NPQ, EBS, and SI-UNIWARD) are improved through defining ternary distortion function by the proposed method. The experimental results on parameters, blind detection and processing time show that the proposed method increases the blind detection resistance of side-informed steganographic algorithm with acceptable computation complexity.
C1 [Bao, Zhenkun; Luo, Xiangyang; Yang, Chunfang; Liu, Fenlin] State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Peoples R China.
   [Zhang, Weiming] Univ Sci & Technol China, CAS Key Lab Elect Space Informat, Hefei 230026, Peoples R China.
   [Yang, Chunfang] Sci & Technol Informat Assurance Lab, Beijing 100072, Peoples R China.
C3 PLA Information Engineering University; Chinese Academy of Sciences;
   University of Science & Technology of China, CAS
RP Luo, XY (corresponding author), State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Peoples R China.
EM bao13213047058@163.com; luoxy_ieu@sina.com; zhangwm@ustc.edu.cn;
   chunfangyang@126.com; liufenlin@sina.vip.com
FU National Natural Science Foundation of China [61379151, 61272489,
   61572452, 61572052]; National Natural Science Youth Foundation of China
   [61302159, 61401512]; Excellent Youth Foundation of Henan Province of
   China [144100510001]; Foundation of Science and Technology on
   Information Assurance Laboratory [KJ-14-108]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61379151, 61272489, 61572452 and 61572052), the National
   Natural Science Youth Foundation of China (No. 61302159, 61401512), the
   Excellent Youth Foundation of Henan Province of China (No.
   144100510001), and the Foundation of Science and Technology on
   Information Assurance Laboratory (No. KJ-14-108).
CR [Anonymous], MEDIA FORENSICS SECU
   [Anonymous], P SPIE EL IM SEC STE
   [Anonymous], MULTIMED TOOL APPL
   [Anonymous], 2009, P SPIE ELECT IMAGING
   Cover T. M., 2012, ELEMENTS INFORM THEO
   Crandall R., 1998, SOME NOTES STEGANOGR
   Filler T, 2010, IEEE INT WORKS INFOR
   Filler T, 2011, PROC SPIE, V7880, DOI 10.1117/12.872192
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   Fridrich J., 2009, INFORM HIDING
   Fridrich J., 2004, MMSEC 04, P4
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Guo LJ, 2012, IEEE INT WORKS INFOR, P169, DOI 10.1109/WIFS.2012.6412644
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Huang FJ, 2012, IEEE T INF FOREN SEC, V7, P1181, DOI 10.1109/TIFS.2012.2198213
   Huang JW, 2002, IEEE T CIRC SYST VID, V12, P916, DOI 10.1109/TCSVT.2002.804897
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Ker AD, 2007, LECT NOTES COMPUT SC, V4567, P204
   Ker AD, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P107, DOI 10.1145/1411328.1411349
   Kim Y, 2007, LECT NOTES COMPUT SC, V4437, P314
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kodovsky J, 2010, PROC SPIE, V7541, DOI 10.1117/12.838768
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Kodovsky Jan, 2012, P SPIE MEDIA WATERMA, V8303, P1
   Kullback S., 1968, INFORM THEORY STAT
   Lin CC, 2015, INFORM SCIENCES, V293, P314, DOI 10.1016/j.ins.2014.08.057
   Liu QZ, 2011, MM&SEC 11: PROCEEDINGS OF THE 2011 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P77
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Provos N, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 10TH USENIX SECURITY SYMPOSIUM, P323
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Sedighi V, 2015, PROC SPIE, V9409, DOI 10.1117/12.2080272
   Wang C, 2012, INT CONF ACOUST SPEE, P1785, DOI 10.1109/ICASSP.2012.6288246
   Yang Y, 2016, DIGIT SIGNAL PROCESS, V52, P13, DOI 10.1016/j.dsp.2016.02.006
NR 35
TC 0
Z9 0
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14345
EP 14374
DI 10.1007/s11042-016-3823-2
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800030
DA 2024-07-18
ER

PT J
AU El-Alfy, ESM
   Qureshi, MA
AF El-Alfy, El-Sayed M.
   Qureshi, Muhammad A.
TI Robust content authentication of gray and color images using lbp-dct
   markov-based features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia forensics; Image manipulation; Content authentication;
   Forgery detection; Markov-based features; Local binary pattern
ID CLASSIFICATION; FORGERY
AB This paper presents a robust method for passive content authentication of gray and color images. The idea is to capture local and global artifacts resulting from the image manipulation through combining intra-block Markov features in both LBP and DCT domains. An optimized support-vector machine with radial-basis kernel is then trained to classify images as being tampered or authentic. We intensively investigate the authentication capabilities of the proposed method for separate color channels and for various combinations of them. The proposed method, without and withfeature-level fusion, is evaluated on three benchmark datasets with a variety of forgery and post-processing operations. The results show that fusing Markov features from LBP and DCT modalities leads to consistent improvement in terms of detection accuracy as compared to the state-of-the-art passive methods. Furthermore, using information from all YCbCr channels help enhancing the detection rate to more than 99.7 % on CASIA TIDE v2.0 image collection.
C1 [El-Alfy, El-Sayed M.] King Fahd Univ Petr & Minerals, Informat & Comp Sci Dept, Dhahran 31261, Saudi Arabia.
   [Qureshi, Muhammad A.] King Fahd Univ Petr & Minerals, Dept Elect Engn, Dhahran 31261, Saudi Arabia.
C3 King Fahd University of Petroleum & Minerals; King Fahd University of
   Petroleum & Minerals
RP El-Alfy, ESM (corresponding author), King Fahd Univ Petr & Minerals, Informat & Comp Sci Dept, Dhahran 31261, Saudi Arabia.
EM alfy@kfupm.edu.sa
RI Qureshi, Muhammad Ali/C-3857-2012; El-Alfy, El-Sayed/G-3103-2011
OI Qureshi, Muhammad Ali/0000-0003-4390-2461; El-Alfy,
   El-Sayed/0000-0001-6279-9776
FU Deanship of Scientific Research (DSR) at King Fahd University of
   Petroleum & Minerals (KFUPM) through the Intelligent Systems Research
   Group (ISRG) [RG1113-1, RG1113-2]
FX Credits for the use of the datasets are given to DVMM Laboratory of
   Columbia University, CalPhotos Digital Library and the photographers
   listed therein, and National Laboratory of Pattern Recognition,
   Institute of Automation, Chinese Academy of Science, Corel Image
   Database and the photographers therein. The authors would like also to
   acknowledge the support provided by the Deanship of Scientific Research
   (DSR) at King Fahd University of Petroleum & Minerals (KFUPM) for
   funding this work through the Intelligent Systems Research Group (ISRG)
   under project No. RG1113-1&2.
CR [Anonymous], 2003, 2003 C COMPUTER VISI, DOI [DOI 10.1109/CVPRW.2003.10093, DOI 10.1109/CVPRW.2003.10093.27.T.-T]
   [Anonymous], IEEE INT C MULT EXP
   Barni M, 2012, SIGNAL PROCESS-IMAGE, V27, P998, DOI 10.1016/j.image.2012.07.006
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chamlawi R, 2010, COMPUT ELECTR ENG, V36, P578, DOI 10.1016/j.compeleceng.2009.12.003
   Change CC, 2010, LIBSVM LIB SUPPORT V
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   Chen W., 2007, P SPIE
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Dong J, 2009, LECT NOTES COMPUT SC, V5450, P76, DOI 10.1007/978-3-642-04438-0_7
   El-Alfy ESM, 2015, PATTERN ANAL APPL, V18, P713, DOI 10.1007/s10044-014-0396-4
   Farid H, 1999, TECHNICAL REPORT
   Fu DD, 2006, LECT NOTES COMPUT SC, V4283, P177
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   He ZW, 2011, PATTERN RECOGN LETT, V32, P1591, DOI 10.1016/j.patrec.2011.05.013
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li LD, 2014, COMPUT ELECTR ENG, V40, P1951, DOI 10.1016/j.compeleceng.2013.11.034
   Mahalakshmi SD, 2012, DIGIT INVEST, V8, P215, DOI 10.1016/j.diin.2011.06.004
   Mahdian B, 2010, SIGNAL PROCESS-IMAGE, V25, P389, DOI 10.1016/j.image.2010.05.003
   Meeker M, 2014, INTERNET TRENDS
   Muhammad G., 2013, MACH VISION APPL, P1
   Ng T.T., 2004, ADVENT Technical Report
   Ng TT, 2004, IEEE IMAGE PROC, P1169
   Ng TT, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P688
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Poynton CharlesA., 1996, TECHNICAL INTRO DIGI
   Prathap I, 2014, COMPUT ELECTR ENG, V40, P920, DOI 10.1016/j.compeleceng.2014.01.006
   Qazi T, 2013, IET IMAGE PROCESS, V7, P660, DOI 10.1049/iet-ipr.2012.0388
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Wang W, 2009, IEEE IMAGE PROC, P1257, DOI 10.1109/ICIP.2009.5413549
   Wang W, 2010, IEEE IMAGE PROC, P2101, DOI 10.1109/ICIP.2010.5652660
   Witten IH, 2011, MOR KAUF D, P1
   Xudong Zhao, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P243, DOI 10.1007/978-3-642-32205-1_20
   Zhang Y., 2012, Communications, P181, DOI DOI 10.1007/978-1-4614-5803-6_19
   Zhao XD, 2011, LECT NOTES COMPUT SC, V6526, P12, DOI 10.1007/978-3-642-18405-5_2
   Zhongwei He, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P349, DOI 10.1007/978-3-642-32205-1_28
   Zhu Y., 2015, MULTIMED TOOLS APPL, V75, P1
NR 43
TC 8
Z9 10
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14535
EP 14556
DI 10.1007/s11042-016-3855-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800037
DA 2024-07-18
ER

PT J
AU Saidi, M
   Hermassi, H
   Rhouma, R
   Belghith, S
AF Saidi, Marwa
   Hermassi, Houcemeddine
   Rhouma, Rhouma
   Belghith, Safya
TI A new adaptive image steganography scheme based on DCT and chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic data hiding; DCT embedding; Zigzag scan; DCT based steganography
ID ALGORITHM
AB In this paper, a novel steganographic scheme is proposed based on chaotic map in the DCT domain. The proposed method apply the DCT on the cover image, scan the AC coefficients in a zigzag form from the least significant to the most significant one, this scan will lead us eventually to precise the embedding positions through a chaotic function as well as the maximum allowed payload relative to a computed SSIM threshold. A quantitative study shows the check of the designed method to the requirement of imperceptibility and flexibility.
C1 [Saidi, Marwa; Hermassi, Houcemeddine; Rhouma, Rhouma; Belghith, Safya] Univ Tunis El Manar, ENIT, BP 37 Le Belvedere, Tunis 1002, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT)
RP Hermassi, H (corresponding author), Univ Tunis El Manar, ENIT, BP 37 Le Belvedere, Tunis 1002, Tunisia.
EM houcemeddine.hermassi@enit.rnu.tn
RI Hermassi, Houcemeddine/J-2352-2012; Rhouma, Rhouma/B-8018-2010;
   hermassi, houcemeddine/ADK-4317-2022; Saidi, Marwa/C-1039-2018
OI Rhouma, Rhouma/0000-0002-5715-4110; Saidi, Marwa/0000-0002-2486-9750;
   Belghith, Safya/0000-0001-7408-7848; Hermassi,
   houcemeddine/0000-0002-4681-4312
CR Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Ghebleh M, 2014, COMMUN NONLINEAR SCI, V19, P1898, DOI 10.1016/j.cnsns.2013.10.014
   Gupta S., 2012, Int. J Computat. Engine. Management, V15, P2230
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P3287, DOI 10.1016/j.cnsns.2011.12.012
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li SJ, 2005, INT J BIFURCAT CHAOS, V15, P3119, DOI 10.1142/S0218127405014052
   Lin C.-C., 2010, J. Inf. Hiding Multimed. Signal Process, V1, P220
   Parah SA, 2014, COMPUT ELECTR ENG, V40, P70, DOI 10.1016/j.compeleceng.2013.11.006
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan DQ, 2012, COMPUT SECUR, V31, P704, DOI 10.1016/j.cose.2012.04.006
   Yan DQ, 2009, FUND INFORM, V97, P1, DOI 10.3233/FI-2009-190
   Yu CM, 2011, DISPLAYS, V32, P225, DOI 10.1016/j.displa.2011.02.004
   Zeng XT, 2010, PATTERN RECOGN, V43, P1656, DOI 10.1016/j.patcog.2009.09.016
NR 15
TC 37
Z9 37
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13493
EP 13510
DI 10.1007/s11042-016-3722-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900026
DA 2024-07-18
ER

PT J
AU Budnik, M
   Gutierrez-Gomez, EL
   Safadi, B
   Pellerin, D
   Quénot, G
AF Budnik, Mateusz
   Gutierrez-Gomez, Efrain-Leonardo
   Safadi, Bahjat
   Pellerin, Denis
   Quenot, Georges
TI Learned features versus engineered features for multimedia indexing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic indexing; Engineered features; Learned features
AB In this paper, we compare "traditional" engineered (hand-crafted) features (or descriptors) and learned features for content-based indexing of image or video documents. Learned (or semantic) features are obtained by training classifiers on a source collection containing samples annotated with concepts. These classifiers are applied to the samples of a destination collection and the classification scores for each sample are gathered into a vector that becomes a feature for it. These feature vectors are then used for training another classifier for the destination concepts on the destination collection. If the classifiers used on the source collection are Deep Convolutional Neural Networks (DCNNs), it is possible to use as a new feature vector also the intermediate values corresponding to the output of all the hidden layers. We made an extensive comparison of the performance of such features with traditional engineered ones as well as with combinations of them. The comparison was made in the context of the TRECVid semantic indexing task. Our results confirm those obtained for still images: features learned from other training data generally outperform engineered features for concept recognition. Additionally, we found that directly training KNN and SVM classifiers using these features performs significantly better than partially retraining the DCNN for adapting it to the new data. We also found that, even though the learned features performed better that the engineered ones, fusing both of them performs even better, indicating that engineered features are still useful, at least in the considered case. Finally, the combination of DCNN features with KNN and SVM classifiers was applied to the VOC 2012 object classification task where it currently obtains the best performance with a MAP of 85.4 %.
C1 [Budnik, Mateusz; Gutierrez-Gomez, Efrain-Leonardo; Safadi, Bahjat; Quenot, Georges] Univ Grenoble Alpes, CNRS, LIG, F-38000 Grenoble, France.
   [Pellerin, Denis] Univ Grenoble Alpes, CNRS, GIPSA Lab, F-38000 Grenoble, France.
C3 Communaute Universite Grenoble Alpes; Institut National Polytechnique de
   Grenoble; Universite Grenoble Alpes (UGA); Centre National de la
   Recherche Scientifique (CNRS); Communaute Universite Grenoble Alpes;
   Institut National Polytechnique de Grenoble; Universite Grenoble Alpes
   (UGA); Centre National de la Recherche Scientifique (CNRS)
RP Quénot, G (corresponding author), Univ Grenoble Alpes, CNRS, LIG, F-38000 Grenoble, France.
EM mateusz.budnik@imag.fr; efrain-leonardo.gutierrez-gomez@imag.fr;
   bahjat.safadi@imag.fr; denis.pellerin@gipsa-lab.fr;
   georges.quenot@imag.fr
OI Gutierrez-Gomez, Leonardo/0000-0001-6405-3775; pellerin,
   denis/0000-0002-3792-1706
FU ANR (Agence Nationale de la Recherche, France); Rhone-Alpes region
   [CPER07 13 CIRA]; Equip@Meso project of the programme Investissements
   d'Avenir [ANR-10-EQPX-29-01]
FX This work was conducted as a part of the CHIST-ERA CAMOMILE project,
   which was funded by the ANR (Agence Nationale de la Recherche, France).
   Part of the computations presented in this paper were performed using
   the Froggy platform of the CIMENT infrastructure
   (https://ciment.ujf-grenoble.fr), which is supported by the Rhone-Alpes
   region (GRANT CPER07 13 CIRA) and the Equip@Meso project (reference
   ANR-10-EQPX-29-01) of the programme Investissements d'Avenir supervised
   by the Agence Nationale pour la Recherche. Results from the IRIM network
   were also used in these experiments [4]. The authors also wish to thank
   Florent Perronnin from XRCE for providing features based on
   classification scores from classifiers trained on ILSVRC/ImageNet data
   [28].
CR [Anonymous], 2015 13 INT WORKSH C
   [Anonymous], ADAPTIVITY PERSONALI
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], 2014, CORR
   [Anonymous], 2015, P TRECVID 2015
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], P TRECVID 2015
   [Anonymous], P TRECVID ORL
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], COMPUTER SCI
   [Anonymous], RRLIRIS2011012
   Ayache S, 2008, LECT NOTES COMPUT SC, V4956, P187
   Ayache S, 2007, EURASIP J IMAGE VIDE, DOI 10.1155/2007/56928
   Benoit A, 2010, COMPUT VIS IMAGE UND, V114, P758, DOI 10.1016/j.cviu.2010.01.011
   Deng J., 2009, CVPR09
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gosselin PH, 2008, COMPUT VIS IMAGE UND, V110, P403, DOI 10.1016/j.cviu.2007.09.018
   Hamadi A, 2015, MULTIMED TOOLS APPL, V74, P1225, DOI 10.1007/s11042-014-1937-y
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Picard D, 2013, COMPUT VIS IMAGE UND, V117, P680, DOI 10.1016/j.cviu.2013.02.004
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Safadi B., 2011, Proceedings of the 20th ACM international conference on Information and knowledge management, P2081
   Safadi B, 2015, MULTIMED TOOLS APPL, V74, P1267, DOI 10.1007/s11042-014-2071-6
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Shabou A, 2012, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2012.6248107
   Simonyan K., 2014, CORR
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smith JR, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P445
   Strat ST, 2014, EUR SIGNAL PR CONF, P1307
   Strat ST, 2014, ADV COMPUT VIS PATT, P53, DOI 10.1007/978-3-319-05696-8_3
   Strat ST, 2013, INT WORK CONTENT MUL, P201, DOI 10.1109/CBMI.2013.6576582
   Su Y, 2012, INT J COMPUT VISION, V100, P59, DOI 10.1007/s11263-012-0529-4
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Yosinski J, 2014, ADV NEUR IN, V27
NR 42
TC 7
Z9 7
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11941
EP 11958
DI 10.1007/s11042-016-4240-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000043
DA 2024-07-18
ER

PT J
AU Meng, WL
   Guo, JW
   Bonaventura, X
   Sbert, M
   Zhang, XP
AF Meng, Weiliang
   Guo, Jianwei
   Bonaventura, Xavier
   Sbert, Mateu
   Zhang, Xiaopeng
TI Shape exploration of 3D heterogeneous models based on cages
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deformation transfer; Cage coordinates; Differential coordinates; Shape
   space; Interpolation
ID DEFORMATION TRANSFER
AB Shape exploration of 3D heterogeneous models is essential for special effects in 3D animation and games. As heterogeneous models have different numbers of vertices and different topological structures,the mapping between source and target model may be ambiguous for deformation transfer. We propose a new framework for heterogeneous model shape exploration based on cages, which provides a feasible and fast solution to this open problem. Using a public cage as an intermediate medium, the deformation of the source models can be denoted as the position changing of the cage. When applying the cage change to the target model, rough deformation transfer can be achieved. After an optimization and interpolation to generate the explored shape of the heterogeneous target model, animation can be acquired. Our method is not only suitable for triangle meshes, but also for quadrilateral meshes or any other type of meshes. We demonstrate the validity of our scheme by a series of shape exploration experiments with different models.
C1 [Meng, Weiliang; Guo, Jianwei; Zhang, Xiaopeng] Chinese Acad Sci, Inst Automat, NLPR LIAMA, Beijing, Peoples R China.
   [Sbert, Mateu] Tianjin Univ, Tianjin, Peoples R China.
   [Bonaventura, Xavier; Sbert, Mateu] Univ Girona, Graph & Imaging Lab, Girona, Spain.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Tianjin
   University; Universitat de Girona
RP Meng, WL (corresponding author), Chinese Acad Sci, Inst Automat, NLPR LIAMA, Beijing, Peoples R China.
EM weiliang.meng@ia.ac.cn
RI Bonaventura, Xavier/C-6258-2014; Sbert, Mateu/G-6711-2011
OI Sbert, Mateu/0000-0003-2164-6858
FU National High-Tech Research and Development Program of China (863
   Program) [2015AA016402]; National Natural Science Foundation of China
   [61571439, 61561003, 61471261, 61372190, 61202324]
FX This work is supported in part by the National High-Tech Research and
   Development Program of China (863 Program) with No. 2015AA016402, and in
   part by National Natural Science Foundation of China with Nos. 61571439,
   61561003, 61471261,61372190, and 61202324.
CR [Anonymous], 2005, ACM SIGGRAPH 2005 CO
   [Anonymous], 2004, P 2004 EUR ACM SIGGR
   Baran I, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531342
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   Ben-Chen M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531340
   Ben-Chen Mirela, 2009, P 2009 ACM SIGGRAPH, P67
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Carmo MPD, 1976, DIFFERENTIAL GEOMETR, P16
   Chen L, 2010, COMPUT GRAPH-UK, V34, P107, DOI 10.1016/j.cag.2010.01.003
   Cohen-Or D, 2006, SCCG06 P 22 SPRING C
   Derose T, 2006, TECHNICAL REPORT
   Floater MS, 2005, COMPUT AIDED GEOM D, V22, P623, DOI 10.1016/j.cagd.2005.06.004
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   Fröhlich S, 2011, COMPUT GRAPH FORUM, V30, P2246, DOI 10.1111/j.1467-8659.2011.01974.x
   Garcia FG, 2013, CAGES MULTILEVEL MUL
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Hormann K, 2006, ACM T GRAPHIC, V25, P1424, DOI 10.1145/1183287.1183295
   Jacobson A, 2011, SIGGRAPH 11 ACM SIGG
   Joshi P, 2007, HARMONIC COORDINATES, P71
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Ju T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409075
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Kilian M, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239515, 10.1145/1276377.1276457]
   Li XY, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461917
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Lipman Yaron., 2007, Proceedings of the fifth Eurographics symposium on Geometry processing, P117
   Luebke David., 2004, GRAPH 04, P33, DOI [10.1145/ 1103900.1103933, DOI 10.1145/1103900.1103933]
   Ma CY, 2014, COMPUT GRAPH FORUM, V33, P175, DOI 10.1111/cgf.12307
   MacCracken R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P181, DOI 10.1145/237170.237247
   Ovsjanikov M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185526
   Shlens J., 2005, ARXIV
   Sorkine O., 2003, Symposium on Geometry Processing, P42
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Thiery JM, 2012, COMPUT GRAPH FORUM, V31, P2303, DOI 10.1111/j.1467-8659.2012.03159.x
   Wang Y, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766952
   Weber O., 2007, COMPUT GRAPH FORUM, V26, P3
   WEBER O., 2009, COMPUT GRAPH FORUM, V28, P2
   Winkler T, 2010, COMPUT GRAPH FORUM, V29, P309, DOI 10.1111/j.1467-8659.2009.01600.x
   Yoshiyasu Y, 2012, COMPUT ANIMAT VIRT W, V23, P225, DOI 10.1002/cav.1442
   Zhang JY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661255
   Zhao Y, 2012, COMPUT ANIMAT VIRT W, V23, P447, DOI 10.1002/cav.1466
   Zhou K, 2010, COMPUT GRAPH FORUM, V29, P319, DOI 10.1111/j.1467-8659.2009.01601.x
NR 43
TC 1
Z9 1
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12369
EP 12390
DI 10.1007/s11042-016-3642-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200009
DA 2024-07-18
ER

PT J
AU Le, TH
   Jung, SW
   Won, CS
AF Thanh-Ha Le
   Jung, Seung-Won
   Won, Chee Sun
TI A new depth image quality metric using a pair of color and depth images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth image; Image quality assessment; Reduced reference; Quality metric
AB Typical depth quality metrics require the ground truth depth image or stereoscopic color image pair, which are not always available in many practical applications. In this paper, we propose a new depth image quality metric which demands only a single pair of color and depth images. Our observations reveal that the depth distortion is strongly related to the local image characteristics, which in turn leads us to formulate a new distortion assessment method for the edge and non-edge pixels in the depth image. The local depth distortion is adaptively weighted using the Gabor filtered color image and added up to the global depth image quality metric. The experimental results show that the proposed metric closely approximates the depth quality metrics that use the ground truth depth or stereo color image pair.
C1 [Thanh-Ha Le] Vietnam Natl Univ, Univ & Engn & Technol, Hanoi, Vietnam.
   [Jung, Seung-Won] Dongguk Univ, Dept Multimedia Engn, Pildong Ro 1Gil, Seoul 100715, South Korea.
   [Won, Chee Sun] Dongguk Univ, Dept Elect & Elect Engn, Pildong Ro 1Gil, Seoul 100715, South Korea.
C3 Vietnam National University Hanoi; Dongguk University; Dongguk
   University
RP Jung, SW (corresponding author), Dongguk Univ, Dept Multimedia Engn, Pildong Ro 1Gil, Seoul 100715, South Korea.
EM ltha@vnu.edu.vn; swjung83@dongguk.edu; cswon@dongguk.edu
RI Lê, Thanh/JUV-3456-2023; Won, Chee Sun/AAI-1101-2020
OI Won, Chee Sun/0000-0002-3400-0792; Jung, Seung-Won/0000-0002-0319-4467
FU basic research projects in natural science of the National Foundation
   for Science & Technology Development (Nafosted), Vietnam
   [102.01-2012.36]; Basic Science Research Program through the National
   Research Foundation of Korea(NRF) - Ministry of Science, ICT & Future
   Planning [NRF-2014R1A1A2057970]; National Research Foundation of Korea
   [22A20130012202] Funding Source: Korea Institute of Science & Technology
   Information (KISTI), National Science & Technology Information Service
   (NTIS)
FX Dr. Thanh-Ha Le's work was supported by the basic research projects in
   natural science in 2012 of the National Foundation for Science &
   Technology Development (Nafosted), Vietnam (102.01-2012.36, Coding and
   communication of multiview video plus depth for 3D Television Systems).
   Prof. Seung-Won Jung's research was supported by Basic Science Research
   Program through the National Research Foundation of Korea(NRF) funded by
   the Ministry of Science, ICT & Future Planning (NRF-2014R1A1A2057970).
CR [Anonymous], 2012, PROC IEEE C COMPUTER
   [Anonymous], P SPIE HUMAN VISION
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], IEIE T SMART SIGNAL
   [Anonymous], 3 DIMENSIONAL SCENE
   [Anonymous], P 28 ANN C NEUR INF
   Chai BB, 2004, PATTERN RECOGN LETT, V25, P755, DOI 10.1016/j.patrec.2004.01.002
   D'Angelo A, 2010, IEEE T IMAGE PROCESS, V19, P867, DOI 10.1109/TIP.2009.2035869
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Fehn C, 2006, P IEEE, V94, P524, DOI 10.1109/JPROC.2006.870688
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   GALLANT JL, 1993, SCIENCE, V259, P100, DOI 10.1126/science.8418487
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250
   Grigorescu SE, 2002, IEEE T IMAGE PROCESS, V11, P1160, DOI 10.1109/TIP.2002.804262
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hartley RI, 1999, INT J COMPUT VISION, V35, P115, DOI 10.1023/A:1008115206617
   Jain M, 2014, J INF PROCESS SYST, V10, P223, DOI 10.3745/JIPS.02.0001
   Janoch A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1168, DOI 10.1109/ICCVW.2011.6130382
   Jianzhong Xu, 2013, 2013 IEEE Power & Energy Society General Meeting, DOI 10.1109/PESMG.2013.6672313
   Jung SW, 2014, IEEE SIGNAL PROC LET, V21, P382, DOI 10.1109/LSP.2014.2303157
   Khongkraphan K, 2014, J INF PROCESS SYST, V10, P589, DOI 10.3745/JIPS.02.0010
   Klaus A, 2006, INT C PATT RECOG, P15
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Smolic A, 2007, IEEE T CIRC SYST VID, V17, P1606, DOI 10.1109/TCSVT.2007.909972
   Smolic A, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P389
   Strecha C., 2006, IEEE Conference on Computer Vision and Pattern Recognition, V2, P2394
   Le TH, 2015, LECT NOTES ELECTR EN, V352, P117, DOI 10.1007/978-3-662-47487-7_18
   Vipparthi SK, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0006-x
   Wang Z. F., 2008, P IEEE C COMPUTER VI, P1
   Yang Q., 2007, P IEEE C COMPUTER VI, P1
NR 32
TC 6
Z9 6
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11285
EP 11303
DI 10.1007/s11042-016-3392-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000009
DA 2024-07-18
ER

PT J
AU Tu, CT
   Lin, PC
   Lien, JJ
AF Tu, Chin-Ting
   Lin, Po-Chung
   Lien, Jenn-Jier
TI Free-hand sketches for 3D model retrieval using cascaded LSDA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Principal component analysis; Locality sensitive discriminant analysis;
   Image retrieval
AB This study proposes a novel cascaded 3D model retrieval framework for automatically and accurately fitting 3D models to user freehand 2D sketches (or object contours). The matching result provides the 3D geometry hypotheses of the 2D objects, and thus it is an important and fundamental part of several computer vision tasks, such as spatial layout estimation and scene understanding. However, existing matching approaches are still restricted by the corresponding point/line matching between the 2D image and the target 3D model. The limitation may make existing matching methods not online accessible in practice, and degrade their applicability. An alternative scenario is proposed to address this problem, in this paper. We use a retrieval system to collect a 3D-2D database offline, in which the 3D models are decomposed into 2D projected contours with respective to a limited number of different viewpoints. Our approach aims to enhance matching results by leveraging the extra database. Specifically, it optimizes a transformation from 3D objects to 2D contours, by which the target 3D object pose and categorization, to be recognized can be concisely estimated by entries in such database. More importantly, we demonstrate how to use a set of training images with limited pose variation to handle test images taken under uncontrolled view.
C1 [Tu, Chin-Ting] Tamkang Univ, Dept Comp Sci & Informat Engn, 151 Yingzhuan Rd, New Taipei 25137, Taiwan.
   [Lin, Po-Chung] MediaTek Inc, Hsinchu 30078, Peoples R China.
   [Lien, Jenn-Jier] Natl Cheng Kung Univ, Tainan 70101, Peoples R China.
C3 Tamkang University; National Cheng Kung University
RP Tu, CT (corresponding author), Tamkang Univ, Dept Comp Sci & Informat Engn, 151 Yingzhuan Rd, New Taipei 25137, Taiwan.
EM cttu@mail.tku.edu.tw; BJStation@gmail.com; jjlien@csie.ncku.edu.tw
CR Alvarado C, 2008, EUROGRAPHICS WORKSH
   [Anonymous], 2012, ACM T GRAPH
   ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206
   Atanasov N, 2014, IEEE T ROBOT, V30, P1078, DOI 10.1109/TRO.2014.2320795
   Cai D, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P714
   Chang W, 2014, ACM T GRAPHICS TOG
   Chen Y, 2005, ACM SIGGRAPH 2005 SK
   Ecker A., 2007, PROC CVPR 07, P1
   Eggli L, 1997, COMPUT AIDED DESIGN, V29, P101, DOI 10.1016/S0010-4485(96)00039-5
   Fischler MA, 1981, COMMUN ACM, P391
   Gupta A., 2010, ADV NEURAL INFORM PR, P1288
   Hedau V, 2009, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2009.5459411
   Hedau Varsha, 2010, LECT NOTES COMPUT SC
   Huang Z, 2014, ACM T GRAPHIC, V33, DOI [10.1145/2661229.2661280, 10.1145/2661228.2661280]
   Hyo Jong Shin, 2007, Proceedings Graphics Interface 2007, P63, DOI 10.1145/1268517.1268530
   Karpenko OA, 2006, ACM T GRAPHIC, V25, P589, DOI 10.1145/1141911.1141928
   Khan SH, 2015, PROC CVPR IEEE, P4603, DOI 10.1109/CVPR.2015.7299091
   Lakshman L, 2000, VISION GEOMETRY, VIX, P30
   Li B, 2013, IEEE INT C MULT EXP
   Owada S, 2004, ACM T GRAPHIC, V23, P322, DOI 10.1145/1015706.1015723
   Payet N, 2011, IEEE I CONF COMP VIS, P983, DOI 10.1109/ICCV.2011.6126342
   Safar M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P141, DOI 10.1109/ICME.2000.869564
   Tanase M, 2005, MULTIMEDIA AND EXPO, P936
   Warren J., 2001, SUBDIVISION METHODS
   Xu K, 2013, ACM T GRAPH
   Zhenguo L, 2007, CHINA DAILY, P1
NR 26
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11669
EP 11685
DI 10.1007/s11042-016-3326-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000031
DA 2024-07-18
ER

PT J
AU Chen, ST
   Chiao, HT
   Chang, SY
   Sun, HM
AF Chen, Shiuan-Tung
   Chiao, Hsin-Ta
   Chang, Shih-Ying
   Sun, Hung-Min
TI Fast and low-complexity encoding of Raptor codes based on operation
   lists for known source block lengths
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Raptor codes; AL-FEC; Multimedia communications; Fountain codes
ID IMPLEMENTATION
AB Raptor codes can provide good error correction capability and efficient encoding and decoding rate. Its fountain code property is effective in avoiding packet retransmission for both unicast and multicast service delivery. Hence, there are many mobile, vehicular and broadband applications adopting it such as mobile multimedia broadcasting, multimedia communications for high-speed rails and broadband IPTV systems. In this paper, we present an efficient systematic Raptor codes encoder based on operation lists for known source block lengths. For a Raptor codes application that can frequently use one or several fixed source block lengths (i.e., the number of source symbols in a source block), we could produce the corresponding operation lists in advance and use them to generate the encoding symbols more efficiently. We first introduce the basic architecture of the proposed Raptor encoder, and then describe the details about how to generate operation lists and Raptor intermediate symbols. The simulation results show that our encoder is at least two times faster than the conventional Raptor codes encoder which is adopted by 3GPP and DVB-H. Besides, the reduction on CPU utilization for a real Raptor-based streaming server is described, which is from 11.59 % to 53.41 %, depending on the employed source block length and symbol size.
C1 [Chen, Shiuan-Tung] Natl Tsing Hua Univ, Dept Comp Sci, 2F,27,Aly 34,Ln 30,Siwei Rd, New Taipei 24874, Taiwan.
   [Chiao, Hsin-Ta] Ind Technol Res Inst, Rm 231,Bldg 11,195,Sec 4,Chung Hsing Rd, Hsinchu 31040, Taiwan.
   [Chang, Shih-Ying] Ind Technol Res Inst, Rm 300-K,Bldg 14,195,Sec 4,Chung Hsing Rd, Hsinchu 31040, Taiwan.
   [Sun, Hung-Min] Natl Tsing Hua Univ, Dept Comp Sci, 101,Sect 2,Kuang Fu Rd, Hsinchu 30013, Taiwan.
C3 National Tsing Hua University; Industrial Technology Research Institute
   - Taiwan; Industrial Technology Research Institute - Taiwan; National
   Tsing Hua University
RP Sun, HM (corresponding author), Natl Tsing Hua Univ, Dept Comp Sci, 101,Sect 2,Kuang Fu Rd, Hsinchu 30013, Taiwan.
EM rickrick@is.cs.nthu.edu.tw; Joseph.Chiao@gmail.com;
   godspeed833@gmail.com; hmsun@cs.nthu.edu.tw
CR AbdulHussein A, 2008, IEEE COMMUN LETT, V12, P444, DOI 10.1109/LCOMM.2008.080260
   [Anonymous], 1025912 ETSI TS
   [Anonymous], 2008, 5170 IETF RFC
   [Anonymous], SYSTEM METHOD LOW CO
   [Anonymous], 5053 IETF RFC
   [Anonymous], P INT C COMP COMM CO
   [Anonymous], P INT C CONS EL ICCE
   [Anonymous], IET COMMUN
   [Anonymous], 10 IEEE INT WORKSH S
   [Anonymous], ACM 11 INT C MOB SYS
   [Anonymous], 2011, 6363 IETF RFC
   [Anonymous], 102472 ETSI TS
   [Anonymous], 102993 ETSI TS
   [Anonymous], 1025911 ETSI TS
   [Anonymous], 26346 3GPP TS
   [Anonymous], 2011, P IEEE INT S BROADB
   [Anonymous], 10254232 ETSI TS
   [Anonymous], 102034 ETSI TS
   [Anonymous], IEEE GLOB TEL C GLOB, DOI DOI 10.1109/GLOCOM.2006.873
   [Anonymous], 2009, 5510 RFC IETF
   [Anonymous], P INT C CONS EL ICCE
   Casado AIV, 2007, IEEE ICC, P932, DOI 10.1109/ICC.2007.158
   Casado AIV, 2010, IEEE T COMMUN, V58, P3470, DOI 10.1109/TCOMM.2010.101910.070303
   Chang SY, 2013, 2013 IEEE 24TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P3568, DOI 10.1109/PIMRC.2013.6666768
   Chen SL, 2013, 2013 IEEE 24TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P380, DOI 10.1109/PIMRC.2013.6666165
   Chen ST, 2013, I SYMP CONSUM ELECTR, P85
   Cheng Y, 2012, SECOND INTERNATIONAL CONFERENCE ON CLOUD AND GREEN COMPUTING / SECOND INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING AND ITS APPLICATIONS (CGC/SCA 2012), P173, DOI 10.1109/CGC.2012.12
   Chiao Hsin-Ta., 2012, Broadband Multimedia Systems and Broadcasting (BMSB), 2012 IEEE International Symposium on, P1
   Gómez-Barquero D, 2009, IEEE T BROADCAST, V55, P742, DOI 10.1109/TBC.2009.2032800
   Gómez-Barquero D, 2009, IEEE T BROADCAST, V55, P396, DOI 10.1109/TBC.2008.2012024
   Heo J, 2008, IEEE T CONSUM ELECTR, V54, P390, DOI 10.1109/TCE.2008.4560104
   Hu L., 2012, Consumer Electronics (ISCE), 2012 IEEE 16th International Symposium on, P1
   Hu LJ, 2013, IEEE T CONSUM ELECTR, V59, P273, DOI 10.1109/TCE.2013.6490270
   Kim S, 2008, IEEE COMMUN LETT, V12, P578, DOI 10.1109/LCOMM.2008.080599
   Kim S, 2008, IEEE COMMUN LETT, V12, P307, DOI 10.1109/LCOMM.2008.072141
   Luby M., 2011, 6330 IETF RFC
   Mladenov T, 2010, MIDWEST SYMP CIRCUIT, P45, DOI 10.1109/MWSCAS.2010.5548557
   Mladenov T, 2010, IEEE INT SYMP CIRC S, P3741, DOI 10.1109/ISCAS.2010.5537741
   Mladenov T, 2009, MIDWEST SYMP CIRCUIT, P687, DOI 10.1109/MWSCAS.2009.5236003
   Munaretto D, 2010, 2010 5TH ANNUAL ICST WIRELESS INTERNET CONFERENCE (WICON 2010), DOI 10.4108/ICST.WICON2010.8457
   Sgardoni V, 2015, PERVASIVE MOB COMPUT, V19, P122, DOI 10.1016/j.pmcj.2014.05.002
   Shi Dongxin, 2014, 2014 International Conference on Information Science, Electronics and Electrical Engineering (ISEEE), P1287, DOI 10.1109/InfoSEEE.2014.6947879
   Shi Dongxin, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P280, DOI 10.1109/ICCSN.2011.6014051
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Thomos N, 2011, IEEE INT SYMP INFO, P2736, DOI 10.1109/ISIT.2011.6034070
   Xing YJ, 2016, INT J HUM RESOUR MAN, V27, P2550, DOI 10.1080/09585192.2015.1031156
   Zhang M, 2013, I SYMP CONSUM ELECTR, P25
   Zhang Q, 2010, J FIBER BIOENG INFOR, V3, DOI [10.3993/jfbi06201001, DOI 10.1109/ICMTMA.2010.531]
NR 48
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9219
EP 9243
DI 10.1007/s11042-016-3529-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300005
DA 2024-07-18
ER

PT J
AU Lin, C
   Pun, CM
   Huang, GH
AF Lin, Cong
   Pun, Chi-Man
   Huang, Guoheng
TI Highly non-rigid video object tracking using segment-based object
   candidates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Highly non-rigid object; Tracking; Segment-based; Objectness; Motion
   weights; Appearance model
AB A novel scheme for non-rigid video object tracking using segment-based object candidates is proposed in this paper. Rather than using a conventional bounding box, the tracker is based on segments and considers the target object to be a combination of segments, where the hierarchical hue-saturation-value histogram is extracted as a feature. The objectness method is employed and integrated into the tracker to generate candidates for a similarity measure. Moreover, segment-based motion weights are introduced to give higher weights to candidates with motion consistency. A confidence-collecting scheme is proposed for similar candidates. To validate our method, experiments were conducted using several image sequences with different non-rigid challenges. The experimental results show that the proposed scheme can achieve better performance than other state-of-the-art methods.
C1 [Lin, Cong; Pun, Chi-Man; Huang, Guoheng] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 University of Macau
RP Pun, CM (corresponding author), Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
EM cmpun@umac.mo
RI Pun, Chi Man/GRJ-3703-2022
OI Pun, Chi-Man/0000-0003-1788-3746
FU Research Committee of the University of Macau [MYRG2015-00011-FST,
   MYRG2015-00012-FST]; Science and Technology Development Fund of Macau
   SAR [008/2013/A1, 093-2014-A2]
FX This research was supported in part by the Research Committee of the
   University of Macau (MYRG2015-00011-FST, MYRG2015-00012-FST) and the
   Science and Technology Development Fund of Macau SAR (008/2013/A1,
   093-2014-A2).
CR Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 1999, P 16 INT JOINT C ART
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2010, IEEE PATTERN ANAL MA
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Chockalingam P, 2009, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2009.5459276
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Forsyth D, 2008, COMPUTER VISION, V5305, P705
   Gall J., 2010, ON LINE ADAPTION CLA
   Godec M, 2011, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2011.6126228
   Grabner H., 2006, BMVC, P47
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jang SI, 2015, PATTERN RECOGN, V48, P126, DOI 10.1016/j.patcog.2014.07.020
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kwon J, 2013, IEEE T PATTERN ANAL, V35, P2427, DOI 10.1109/TPAMI.2013.32
   Kwon J, 2009, PROC CVPR IEEE, P1208, DOI 10.1109/CVPRW.2009.5206502
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Manen S, 2013, IEEE I CONF COMP VIS, P2536, DOI 10.1109/ICCV.2013.315
   Marfil R, 2007, PATTERN RECOGN LETT, V28, P985, DOI 10.1016/j.patrec.2006.11.013
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Mori G, 2005, IEEE I CONF COMP VIS, P1417
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Tissainayagam P, 2005, PATTERN RECOGN, V38, P105, DOI 10.1016/j.patcog.2004.05.011
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Zhang K., 2012, EUR C COMP VIS ECCV
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
NR 34
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9565
EP 9586
DI 10.1007/s11042-016-3563-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300021
DA 2024-07-18
ER

PT J
AU Niu, J
   Bu, XZ
   Qian, K
AF Niu, Jie
   Bu, Xiongzhu
   Qian, Kun
TI Exploiting contrast cues for salient region detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual attention; Salient region detection; Contrast measure; Saliency
   map
ID OBJECT DETECTION
AB Visual saliency detection is an important cue used in human visual system, which can offer efficient solutions for both biological and artificial vision systems. Although there are many saliency detection models that can achieve good results on public datasets, the accuracy and reliability of salient object detection models still remains a challenge. For this reason, a novel effective salient region detection model is presented in this paper. Based on the principle that a combination of global statistics and surrounding contrast saliency operators can yield even better results than just using either alone, we use a histogram-based contrast method to calculate the global saliency values in an opponent color space. At the same time, we partition the input image into a set of regions, and the regional saliency is detected by considering the color isolation with spatial information and textural distinctness simultaneously. The final saliency is obtained based on a weighted fusion of the two saliency results. The experimental results from three widely used databases validate the efficacy of the proposed method in comparison with fourteen state-of-the-art existing methods.
C1 [Niu, Jie; Bu, Xiongzhu] Nanjing Univ Sci & Technol, Sch Mech Engn, Nanjing, Jiangsu, Peoples R China.
   [Niu, Jie] Changzhou Coll Informat Technol, Sch Elect & Elect Engn, Changzhou, Peoples R China.
   [Qian, Kun] Southeast Univ, Sch Automat, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology; Changzhou College of
   Information Technology; Southeast University - China
RP Bu, XZ (corresponding author), Nanjing Univ Sci & Technol, Sch Mech Engn, Nanjing, Jiangsu, Peoples R China.
EM njrogel@gmail.com; 213101000013@njust.edu.cn
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2014 IEEE INT C MULT
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Dooseok Kang, 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2055, DOI 10.1109/ROBIO.2011.6181594
   Einhäuser W, 2003, EUR J NEUROSCI, V17, P1089, DOI 10.1046/j.1460-9568.2003.02508.x
   Frintrop S, 2015, PROC CVPR IEEE, P82, DOI 10.1109/CVPR.2015.7298603
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   HURVICH LM, 1957, PSYCHOL REV, V64, P384, DOI 10.1037/h0041403
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Luo W, 2012, SIGNAL PROCESS-IMAGE, V27, P238, DOI 10.1016/j.image.2011.10.004
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Qingshan Li, 2011, 2011 International Conference on Multimedia Technology, P5068
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Reynolds JH, 2003, NEURON, V37, P853, DOI 10.1016/S0896-6273(03)00097-7
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Wan SH, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P172
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   YANG JM, 2012, PROC CVPR IEEE, P2296, DOI [DOI 10.1109/CVPR.2012.6247940, 10.1109/CVPR.2012.6247940]
   Yeh HH, 2014, PATTERN RECOGN, V47, P1740, DOI 10.1016/j.patcog.2013.11.015
   Yildirim G, 2015, LECT NOTES COMPUT SC, V9005, P514, DOI 10.1007/978-3-319-16811-1_34
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang WJ, 2016, VISUAL COMPUT, V32, P275, DOI 10.1007/s00371-015-1065-3
NR 37
TC 4
Z9 4
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10427
EP 10441
DI 10.1007/s11042-016-3430-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400008
DA 2024-07-18
ER

PT J
AU Wang, G
   Yan, W
   Kankanhalli, M
AF Wang, G.
   Yan, W.
   Kankanhalli, M.
TI Content based authentication of visual cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Secret sharing; Digital image processing
AB Visual Cryptography (VC) has been developed as a significant research arena in media security. Despite of its obvious strengths, recent investigations have debated this scheme from adverse aspects, its problem is lack of authentication of VC shares, VC authentication related to digital image processing and cryptography has not been fully integrated together in the past years. In this paper, we analyze both visual features and cryptographic features of VC shares and take use of them for VC authentication. Compared to those existing methods, our contribution is the first one to integrate visual features and cryptographic features of VC shares into Hash code for the purpose of VC authentication.
C1 [Wang, G.; Yan, W.] Auckland Univ Technol, Auckland, New Zealand.
   [Kankanhalli, M.] Natl Univ Singapore, Singapore, Singapore.
C3 Auckland University of Technology; National University of Singapore
RP Yan, W (corresponding author), Auckland Univ Technol, Auckland, New Zealand.
EM dcsyanwq@gmail.com
RI Kankanhalli, Mohan/Q-9284-2019
OI Kankanhalli, Mohan/0000-0002-4846-2015
CR Chen YC, 2012, IEEE T IMAGE PROCESS, V21, P3319, DOI 10.1109/TIP.2012.2190082
   Corke P, 2011, VISION CONTROL, V73, P335
   Corke P., 2011, ROBOTICS VISION CONT, V73, P335, DOI [10.1007/978-3-642-20144-8_13, DOI 10.1007/978-3-642-20144-8_13]
   DESMEDT Y, 2000, P 7 ACM C COMP COMM, P116
   Hersch RD, 2004, ACM T GRAPHIC, V23, P239, DOI 10.1145/1015706.1015709
   Hou Y, 2001, IEEE C IM AC SPEECH
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   Jin D, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1993625
   Liao SY, 2013, 6 INT C IM SIGN PROC
   Liu F., 2015, VISUAL CRYPTOGRAPHY
   Memon N., 1998, Communications of the ACM, V41, P34, DOI 10.1145/278476.278485
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Stallings W, 2013, IEEE POTENTIALS, V32, P26, DOI 10.1109/MPOT.2013.2254508
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Wang G., 2015, THESIS
   Wang G P, 2014, IEEE INT S MULT TAIC, P175
   Wang GY, 2016, MULTIMED TOOLS APPL, V75, P1223, DOI 10.1007/s11042-014-2365-8
   Weir J, 2012, DIGITAL FORENSICS WA, V7128, P196, DOI DOI 10.1007/978-3-642-32205-1_17
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Weir J, 2009, IEEE INT SYMP CIRC S, P509, DOI 10.1109/ISCAS.2009.5117797
   Weir J, 2009, LECT NOTES COMPUT SC, V5703, P136, DOI 10.1007/978-3-642-03688-0_14
   Yan WQ, 2012, DIGIT IMAG COMPUT, P381
   Yan WQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P572
NR 23
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9427
EP 9441
DI 10.1007/s11042-016-3549-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300014
DA 2024-07-18
ER

PT J
AU Deka, B
   Handique, M
   Datta, S
AF Deka, Bhabesh
   Handique, Maitrayee
   Datta, Sumit
TI Sparse regularization method for the detection and removal of
   random-valued impulse noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Random-valued impulse noise; Impulse denoising; Sparse representation;
   Overcomplete dictionary; Image inpainting
ID WEIGHTED MEDIAN FILTERS; IMAGE-ENHANCEMENT; REPRESENTATIONS;
   DICTIONARIES; DECOMPOSITION; STATISTICS; ALGORITHM; SYSTEMS
AB In this paper, we propose a novel two-stage algorithm for the detection and removal of random-valued impulse noise using sparse representations. The main aim of the paper is to demonstrate the strength of image inpainting technique for the reconstruction of images corrupted by random-valued impulse noise at high noise densities. First, impulse locations are detected by applying the combination of sparse denoising and thresholding, based on sparse and overcomplete representations of the corrupted image. This stage optimally selects threshold values so that the sum of the number of false alarms and missed detections obtained at a particular noise level is the minimum. In the second stage, impulses, detected in the first stage, are considered as the missing pixels or holes and subsequently these holes are filled-up using an image inpainting method. Extensive simulation results on standard gray scale images show that the proposed method successfully removes randomvalued impulse noise with better preservation of edges and other details compared to the existing techniques at high noise ratios.
C1 [Deka, Bhabesh; Handique, Maitrayee; Datta, Sumit] Tezpur Univ, Dept Elect & Commun Engn, Comp Vis & Image Proc Lab, Tezpur 784028, Assam, India.
C3 Tezpur University
RP Deka, B (corresponding author), Tezpur Univ, Dept Elect & Commun Engn, Comp Vis & Image Proc Lab, Tezpur 784028, Assam, India.
EM bdeka@tezu.ernet.in; maitrayee.mhw@gmail.com; sumit89@tezu.ernet.in
RI Deka, Bhabesh/O-4368-2019; DATTA, SUMIT/AAF-8993-2021
OI Deka, Bhabesh/0000-0002-9679-6159; DATTA, SUMIT/0000-0003-2481-8184
CR Abreu E, 1995, P ICASSP, V4, P2371
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], ACM SIGICE B
   Bovik A.C., 2000, HDB IMAGE VIDEO PROC
   BOVIK AC, 1983, IEEE T ACOUST SPEECH, V31, P1342, DOI 10.1109/TASSP.1983.1164247
   Boyd S., 2004, CONVEX OPTIMIZATION
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Dawood H, 2015, MULTIMED TOOLS APPL, V74, P11485, DOI 10.1007/s11042-014-2246-1
   Deka B, 2011, P NAT C COMM, P1
   DENG JL, 1982, SYST CONTROL LETT, V1, P288, DOI 10.1016/S0167-6911(82)80025-X
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1
   Fantacci R, 2010, IEEE T CNSUMER ELECT, V56
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Huang S, 2010, ELECTRON LETT, V46, P1198, DOI 10.1049/el.2010.0833
   Jianhua S, 2014, MULTI, V9, P1054
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Pati YC, 1993, SIGN SYST COMP 1993, P40, DOI DOI 10.1109/ACSSC.1993.342465
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Saikrishna P, 2012, P INT C SIGN PROC CO, P1
   Saikrishna P, 2013, IEEE IMAGE PROC, P1197, DOI 10.1109/ICIP.2013.6738247
   Sattar F, 1997, IEEE T IMAGE PROCESS, V6, P888, DOI 10.1109/83.585239
   Starck JL, 2005, IEEE T IMAGE PROCESS, V14, P1570, DOI 10.1109/TIP.2005.852206
   SUN T, 1994, PATTERN RECOGN LETT, V15, P341, DOI 10.1016/0167-8655(94)90082-5
   Tripathi AK, 2011, IET IMAGE PROCESS, V5, P598, DOI 10.1049/iet-ipr.2010.0252
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang HW, 2014, IEEE T IMAGE PROCESS, V23, P2996, DOI 10.1109/TIP.2014.2325784
   Zhang HW, 2012, PROC CVPR IEEE, P2464, DOI 10.1109/CVPR.2012.6247961
NR 37
TC 9
Z9 10
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6355
EP 6388
DI 10.1007/s11042-016-3290-9
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400014
DA 2024-07-18
ER

PT J
AU Munib, S
   Khan, A
AF Munib, Summuyya
   Khan, Asifullah
TI Robust image watermarking technique using triangular regions and Zernike
   moments for quantization based embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust watermarking; Zernike moments; Feature points; Geometric attacks
ID GEOMETRICALLY INVARIANT WATERMARKING
AB Watermarking is a tool to embed information in the image to provide authentication, copyrights protection, copy control, etc. Some watermarking techniques are robust to intentional / unintentional attacks on the watermarked image. In this study, we propose a robust watermarking approach that can resist geometrical attacks. The proposed technique exploits both the robust image feature points and local Zernike moments for embedding the information. Delaunay tessellation is employed to divide image into distinct triangular segments based on robust features. These features are identified using Harris detector. Zernike moments are calculated for each selected triangular segment, and then the watermark is embedded in the magnitude of Zernike moments using dither modulation. It can be observed from the experimental results that by using proposed approach, the watermark can be detected even in the presence of geometrical distortion, i.e. rotation, cropping, and scaling, and JPEG compression attack.
C1 [Munib, Summuyya; Khan, Asifullah] PIEAS, Dept Comp & Informat Sci, Pattern Recognit Lab, Islamabad, Pakistan.
C3 Pakistan Institute of Engineering & Applied Science
RP Khan, A (corresponding author), PIEAS, Dept Comp & Informat Sci, Pattern Recognit Lab, Islamabad, Pakistan.
EM asif@pieas.edu.pk; summuyya@pieas.edu.pk
RI Khan, ASIFULLAH/H-9617-2015
OI Khan, Asifullah/0000-0003-2039-5305
FU Higher Education Commission, Pakistan under NRPU Research Grant
   [20-1624/RD/10/4603]
FX This work is supported by Higher Education Commission, Pakistan under
   NRPU Research Grant No. 20-1624/R&D/10/4603.
CR Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Chamlawi R, 2010, COMPUT ELECTR ENG, V36, P578, DOI 10.1016/j.compeleceng.2009.12.003
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   Jifeng Zhou, 2010, 2010 2nd IEEE International Conference on Network Infrastructure and Digital Content (IC-NIDC 2010), P758, DOI 10.1109/ICNIDC.2010.5657884
   LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785
   Lee HY, 2007, MULTIMED TOOLS APPL, V34, P337, DOI 10.1007/s11042-007-0112-0
   Lian SG, 2012, MULTIMED TOOLS APPL, V57, P49, DOI 10.1007/s11042-010-0521-3
   Lin S., 2004, Error Control Coding, Vsecond
   Lu W, 2012, MULTIMED TOOLS APPL, V60, P31, DOI 10.1007/s11042-011-0794-1
   Luo HJ, 2011, RADIOENGINEERING, V20, P525
   Mair E, 2010, LECT NOTES COMPUT SC, V6312, P183, DOI 10.1007/978-3-642-15552-9_14
   Schmidt A, 2010, COMPUT VIS GRAPH
   Seo JS, 2006, IEEE T SIGNAL PROCES, V54, P1537, DOI 10.1109/TSP.2006.870581
   Singhal N, 2009, J VIS COMMUN IMAGE R, V20, P408, DOI 10.1016/j.jvcir.2009.04.002
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Usman I, 2010, APPL SOFT COMPUT, V10, P332, DOI 10.1016/j.asoc.2009.08.004
   Wang XY, 2010, COMPUT ELECTR ENG, V36, P31, DOI 10.1016/j.compeleceng.2009.04.005
   Xin Y, 2004, IEEE INT C PATT REC, P218
NR 20
TC 13
Z9 15
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8695
EP 8710
DI 10.1007/s11042-016-3485-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800047
DA 2024-07-18
ER

PT J
AU Yu, C
AF Yu, Chong
TI Steganography of digital watermark by Arnold scrambling transform with
   blind source separation morphological component analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arnold scrambling transform; Blind source separation; Digital watermark;
   Morphological component analysis; Secret key; Steganography
ID LSB STEGANOGRAPHY
AB In this paper, a novel steganography of digital watermark scheme which contains digital watermark embedding and extraction processes is proposed. The proposed scheme is based on an iterative process of Arnold scrambling transform which is controlled by secret key shared by copyright owner and authorized users, and the extension of morphological component analysis theory which utilizes morphological diversity as the kernel role in blind source separation. Since both the original cover image and watermark are not needed for recovering received watermark, the proposed scheme can be categorized into blind watermarking technique. It is the most applicable watermarking technique due to the availability of the original cover image and watermark cannot be warranted in real-world applications. The proposed scheme overcomes the problem of too narrow hidden data bandwidth in traditional Least-Significant-Bit (LSB) replacement or LSB matching schemes. Instead of only hiding limited bits is allowed, we can embed a meaningful picture into the cover image by applying proposed scheme. Compared with classic Joint Photographic Experts Group (JPEG) steganography schemes, the proposed steganography scheme has much higher embedding capacity and broader applicability scope. Images acquired in steganography experiments and the analysis of experimental results both prove the effectiveness of proposed scheme. Both subjective visual effect and objective quantitative results of the Peak Signal to Noise Ratio (PSNR) index, Structural Similarity (SSIM) index and Normalized Correlation (NC) index confirm its brilliant steganography capability as well as its fine robustness to different noise attacks through communication channel.
C1 [Yu, Chong] Intel, Asia Pacific Res & Dev Ltd, Software & Serv Grp, Shanghai 200241, Peoples R China.
C3 Intel Corporation
RP Yu, C (corresponding author), Intel, Asia Pacific Res & Dev Ltd, Software & Serv Grp, Shanghai 200241, Peoples R China.
EM dxxzdxxz@126.com
CR Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bobin J, 2007, IEEE T IMAGE PROCESS, V16, P2662, DOI 10.1109/TIP.2007.906256
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2001, SPIE MULTIMEDIA SYST, VIV
   Hetzl S, 2005, LECT NOTES COMPUT SC, V3677, P119
   Huang FJ, 2012, IEEE T INF FOREN SEC, V7, P1181, DOI 10.1109/TIFS.2012.2198213
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   SALLEE P, 2003, P INT WORKSH DIG WAT, P174
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WESTFELD A., 2001, P 4 INT WORKSH INF H, V2137, P289, DOI DOI 10.1007/3-540-45496-9_21
   Yang CF, 2008, IEEE T INF FOREN SEC, V3, P662, DOI 10.1109/TIFS.2008.2007240
   Zhang T, 2003, SIGNAL PROCESS, V83, P2085, DOI 10.1016/S0165-1684(03)00169-5
NR 15
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6821
EP 6842
DI 10.1007/s11042-015-3205-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400033
DA 2024-07-18
ER

PT J
AU De Carolis, B
   Ferilli, S
   Palestra, G
AF De Carolis, Berardina
   Ferilli, Stefano
   Palestra, Giuseppe
TI Simulating empathic behavior in a social assistive robot
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social assistive robots; Affective computing; Empathy
ID EXPRESSIONS
AB When used as an interface in the context of Ambient Assisted Living (AAL), a social robot should not just provide a task-oriented support. It should also try to establish a social empathic relation with the user. To this aim, it is crucial to endow the robot with the capability of recognizing the user's affective state and reason on it for triggering the most appropriate communicative behavior. In this paper we describe how such an affective reasoning has been implemented in the NAO robot for simulating empathic behaviors in the context of AAL. In particular, the robot is able to recognize the emotion of the user by analyzing communicative signals extracted from speech and facial expressions. The recognized emotion allows triggering the robot's affective state and, consequently, the most appropriate empathic behavior. The robot's empathic behaviors have been evaluated both by experts in communication and through a user study aimed at assessing the perception and interpretation of empathy by elderly users. Results are quite satisfactory and encourage us to further extend the social and affective capabilities of the robot.
C1 [De Carolis, Berardina; Ferilli, Stefano; Palestra, Giuseppe] Univ Bari, Dipartimento Informat, Via Orabona 4, I-70126 Bari, Italy.
C3 Universita degli Studi di Bari Aldo Moro
RP De Carolis, B (corresponding author), Univ Bari, Dipartimento Informat, Via Orabona 4, I-70126 Bari, Italy.
EM berardina.carolis@uniba.it; stefano.ferilli@uniba.it;
   giuseppe.palestra@uniba.it
RI DE CAROLIS, BERARDINA/ABD-4045-2021; Palestra, Giuseppe/HLW-6307-2023
OI DE CAROLIS, BERARDINA/0000-0002-2689-137X; PALESTRA,
   GIUSEPPE/0000-0002-0159-2672
FU project "PUGLIA@SERVICE - Italian Ministry of University and Research
   (MIUR) [PON02_00563_3489339]
FX This work fulfills the research objectives of the PON02_00563_3489339
   project "PUGLIA@SERVICE - funded by the Italian Ministry of University
   and Research (MIUR). Our thanks go to Isabella Poggi and Francesca
   D'Errico for their useful suggestions on the evaluation of the robot's
   behaviors.
CR Anderson C, 2002, BEHAV BRAIN SCI, V25, P21, DOI 10.1017/S0140525X02230010
   [Anonymous], J GERONTOL B
   [Anonymous], VISAPP, DOI DOI 10.1109/ICCVW.2013.57
   [Anonymous], P 3 INT JIONT C AUT
   BARON-COHEN SIMON., 2011, The Science of Evil: On Empathy and the Origins of Cruelty
   Boersma P., 2007, PRAAT: doing phonetics by computer
   Broekens Joost, 2009, Gerontechnology, V8, P94, DOI 10.4017/gt.2009.08.02.002.00
   Cesta A, 2007, P AAAI SPRING S INT, P18
   Coradeschi S, 2014, ADV INTELL SYST, V300, P261, DOI 10.1007/978-3-319-08491-6_22
   Cramer H, 2010, ACMIEEE INT CONF HUM, P141, DOI 10.1109/HRI.2010.5453224
   Davis M. H., 1980, JSAS CATALOG SELECTE, V10, P85, DOI DOI 10.1037/0022-3514.44.1.113
   De Carolis B, 2013, SPRINGER HCI SERIES
   De Carolis B, 2013, P WORKSH CHALL AG SO
   de Rosis F, 2004, COG TECH, P271
   EISENBERG N, 1987, PSYCHOL BULL, V101, P91, DOI 10.1037/0033-2909.101.1.91
   EKMAN P, 1979, ANNU REV PSYCHOL, V30, P527, DOI 10.1146/annurev.ps.30.020179.002523
   Elliott C., 1993, AAAI SPRING S REASON, P58
   Graf B, 2004, AUTON ROBOT, V16, P193, DOI 10.1023/B:AURO.0000016865.35796.e9
   Hoffman M.L., 1981, Altruism and helping behavior, P41
   Jensen F.V., 2001, BAYESIAN NETWORKS DE, DOI [10.1007/978-1-4757-3502-4, DOI 10.1007/978-1-4757-3502-4]
   Jiang He, 2007, Proceedings of PICMET 2006-Technology Management for the Global Future (IEEE Cat. No.06CH37823)
   Johnson DO, 2013, INT J SOC ROBOT, V5, P503, DOI 10.1007/s12369-013-0211-1
   Klein J., 1999, CHI'99 Extended Abstracts on Human Factors in Computing Systems, P242
   Leite I, 2013, INT J SOC ROBOT, V5, P291, DOI 10.1007/s12369-013-0178-y
   Mataric M, 2007, PERSONALIZED SOCIALL
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Nehmer J., 2006, 28th International Conference on Software Engineering Proceedings, P43, DOI 10.1145/1134285.1134293
   Niewiadomski R, 2008, LECT NOTES COMPUT SC, V5208, P37
   Nijholt A, 2006, TRUE VISIONS EMERGEN, P275
   Oatley K., 1987, Cogn Emot, V1, P29, DOI DOI 10.1080/02699938708408362
   Ortony A., 1988, COGNITIVE STRUCTURE
   Paiva A., 2011, INT J VIRTUAL REALIT, V10, P65
   Palestra G, 2015, LECT NOTES COMPUT SC, V9280, P518, DOI 10.1007/978-3-319-23234-8_48
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Pineau J, 2003, ROBOT AUTON SYST, V42, P271, DOI 10.1016/S0921-8890(02)00381-0
   Reeves B., 1996, MEDIA EQUATION PEOPL
   Reiter E., 2000, Building natural language generation systems
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Speigel C., 2016, CREATING BASELINE EM
   van Ruiten  A., 2007, P DOCT CONS SCOP ACI
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vogt T, 2008, LECT NOTES ARTIF INT, V5078, P188, DOI 10.1007/978-3-540-69369-7_21
NR 43
TC 35
Z9 38
U1 2
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5073
EP 5094
DI 10.1007/s11042-016-3797-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500018
DA 2024-07-18
ER

PT J
AU Geelhoed, E
   Singh-Barmi, K
   Biscoe, I
   Cesar, P
   Jansen, J
   Wang, C
   Kaiser, R
AF Geelhoed, Erik
   Singh-Barmi, Kuldip
   Biscoe, Ian
   Cesar, Pablo
   Jansen, Jack
   Wang, Chen
   Kaiser, Rene
TI Co-present and remote audience experiences: intensity and cohesion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed performances; Streaming performances; Evaluation methods;
   Media experiences; Audience evaluation; Audience feedback; Telepresence
ID EMPATHY
AB This article presents the results of modelling audience response to new types of networked theatre plays. As the main contribution of the work we introduce two types of metrics: intensity, relating to how intensively co-present and remote aspects of a performance are rated, and cohesion, relating to how a performance as a whole, the combination of co-present and remote aspects, affects an audience. In particular, we model audience response based on two in the wild evaluations, staged by a low budget theatre company, a streamed and a distributed performance. The streamed performance is similar to NT Live, where a theatre play is delivered to other theatres with an audience. The distributed performance, on the other hand, connects actors in two different theatres (with audiences) creating one single play. The streamed performance was experienced as less intense as well as less cohesive by the remote audience, whilst the distributed performance integrated co-present and remote aspects tightly. Remote aspects of the distributed performance were still experienced as less intense, but the performance as a whole was highly cohesive. Apart from the identification of these two new metrics (intensity and cohesion), based on our experiences we argue that an innovative way of bundling relevant emerging technologies is needed to give a voice to the, as yet silent, remote audience.
C1 [Geelhoed, Erik; Biscoe, Ian] Falmouth Univ, Falmouth, England.
   [Singh-Barmi, Kuldip] Falmouth Univ, Dance & Choreog Dept, Falmouth, England.
   [Cesar, Pablo; Jansen, Jack; Wang, Chen] Ctr Wiskunde & Informat, Amsterdam, Netherlands.
   [Kaiser, Rene] JOANNEUM RES, Inst Informat & Commun Technol, Graz, Austria.
RP Geelhoed, E (corresponding author), Falmouth Univ, Falmouth, England.
EM erik.geelhoed@falmouth.ac.uk; P.S.Cesar@cwi.nl; rene.kaiser@joanneum.at
RI Jansen, Jack/KHZ-0382-2024
OI Jansen, Jack/0000-0002-7006-2560; Cesar, Pablo/0000-0003-1752-6837;
   Kaiser, Rene/0000-0001-7775-4554; Geelhoed, Erik/0000-0001-7152-1186
FU European Community's Seventh Framework Program [ICT-2011-287760];
   British Telecom; National Endowment for Science, Technology and the Arts
   (NESTA); Arts and Humanities Research Council (AHRC)
FX The research leading to these results has received funding from several
   sources: the European Community's Seventh Framework Program under grant
   agreement no. ICT-2011-287760 (Vconect), British Telecom, the National
   Endowment for Science, Technology and the Arts (NESTA) and the Arts and
   Humanities Research Council (AHRC). We want to thank all at Miracle
   Theatre, Dogbite Studios, the Falmouth Maritime Museum, the JointEffort
   video crew, and all partners in these collaborative research endeavours.
CR ANDERSON NH, 1970, PSYCHOL REV, V77, P153, DOI 10.1037/h0029064
   [Anonymous], 2007, CLOSER PERFORMANCE T
   Auslander Philip., 1999, Liveness: Performance in a Mediatized Culture
   Bakhshi H., 2010, BEYOND LIVE
   Barker M, 2013, PALGRAVE PIVOT, P1, DOI 10.1057/9781137288691
   Barker M., 1998, KNOWING AUDIENCES JU
   Berry M, 2015, MIRACLE THEATRE LIVE
   Birringer Johannes., 2008, Performance, Technology and Science
   Boerner S, 2013, PSYCHOL AESTHET CREA, V7, P391, DOI 10.1037/a0034570
   Boerner S, 2010, PSYCHOL AESTHET CREA, V4, P173, DOI 10.1037/a0018460
   Brown A.S., 2007, Assessing the intrinsic impacts of a live performance
   Causey M, 1999, THEATRE J, V51, P383
   Cavendish D, 2010, N HYTNER NT LIVE TEL
   Cerratto-Pargman T, 2014, PROCEEDINGS OF THE NORDICHI'14: THE 8TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION: FUN, FAST, FOUNDATIONAL, P608, DOI 10.1145/2639189.2641213
   Chambel Teresa, 2015, P 3 INT WORKSH IMM M, P21, DOI [10.1145/2814347.2814351, DOI 10.1145/2814347.2814351]
   Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893
   CLARK HH, 1991, PERSPECTIVES ON SOCIALLY SHARED COGNITION, P127, DOI 10.1037/10096-006
   ControlBooth Thread, THREAD PEPP GHOST PR
   Corness G., 2011, P 8 ACM C CREATIVITY, P127, DOI DOI 10.1145/2069618.2069641
   Cremona C, 2011, 17 INT S EL ART IST
   DIXON Steve., 2007, DIGITAL PERFORMANCE
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Gazzola V, 2006, CURR BIOL, V16, P1824, DOI 10.1016/j.cub.2006.07.072
   Geelhoed E., 2009, HPL2009120
   Geelhoed E, 2014, REV MAPA, V1
   Geelhoed E, 2007, ECHALLENGES E 2007 C
   Jabbi M, 2007, NEUROIMAGE, V34, P1744, DOI 10.1016/j.neuroimage.2006.10.032
   Jackson PL, 2006, NEUROPSYCHOLOGIA, V44, P752, DOI 10.1016/j.neuropsychologia.2005.07.015
   Kaiser R, 2014, MEDIA PRODUCTION DEL, P209
   Kaptein M, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2391
   Kline P., 1986, HDB TEST CONSTRUCTIO
   Latulipe C, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1845
   Leslie KR, 2004, NEUROIMAGE, V21, P601, DOI 10.1016/j.neuroimage.2003.09.038
   Li J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2553
   Likert R, 1934, J SOC PSYCHOL, V5, P228, DOI 10.1080/00224545.1934.9919450
   Lin YW, 2014, NEW REV HYPERMEDIA M, V20, P207, DOI 10.1080/13614568.2014.889224
   McFarland DH, 2001, J SPEECH LANG HEAR R, V44, P128, DOI 10.1044/1092-4388(2001/012)
   Musion Eyeliner, GOR MTV EUR AW 2005
   Naugle LM, 2002, PAJ, P56
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Rizzolatti G, 1998, TRENDS NEUROSCI, V21, P188, DOI 10.1016/S0166-2236(98)01260-0
   Santana I, 2006, DANCA CULTURA DIGITA, V1, P204
   Sas C, 2003, PRESENCE-TELEOP VIRT, V12, P523, DOI 10.1162/105474603322761315
   Sermon P., 1992, TELEMATIC DREAMING
   Shockley K, 2003, J EXP PSYCHOL HUMAN, V29, P326, DOI 10.1037/0096-1523.29.2.326
   Shrader A, 2015, THESIS
   Stenslie S, 2003, EROTOGOD
   Stenton P, 2012, UBIQUITY J PERVASIVE, V1, P33
   STONE H, 1974, FOOD TECHNOL-CHICAGO, V28, P24
   Vladica V, 2013, VALUE PROPOSITIONS O
   Wang C, 2016, P INT C PHYS COMP SY
   Wang C, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1909, DOI 10.1145/2556288.2557154
   Williams D, 2015, DISTRIBUTED THEATRE
   Williams D, 2015, IEEE MULTIMEDIA, V22, P4, DOI 10.1109/MMUL.2015.65
   Wilson M, 2005, PSYCHON B REV, V12, P957, DOI 10.3758/BF03206432
   Young F. W., 1987, Multidimensional scaling: History, theory, and applications, DOI 10.2307/2348396
NR 56
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5573
EP 5606
DI 10.1007/s11042-016-3879-z
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500040
DA 2024-07-18
ER

PT J
AU Gun, L
   Ran, Z
   Chai, HL
AF Gun, Li
   Ran, Zhu
   Chai Honglei
TI A contour detector with improved corner detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contour detection; Image segmentation; Computer vision
AB This paper mainly studies the image contour detection algorithm which can distinguish edges of different strengths. Based on the study of Probability-of-Boundary operator, we find that defects such as response suppression and offset exist in the algorithm during the detection of corners and curved edges, thus an improved algorithm is proposed. This algorithm retains the advantage in Probability-of-Boundary algorithm which can effectively distinguish the edge strength, while improves the above-mentioned defects. And an improved algorithm is proposed to characterize the strength of boundary reasonably, making the test results in line with human subjective recognition results.
C1 [Gun, Li; Ran, Zhu; Chai Honglei] Univ Elect Sci & Technol China, Sch Aeronaut & Astronaut, Chengdu, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Gun, L (corresponding author), Univ Elect Sci & Technol China, Sch Aeronaut & Astronaut, Chengdu, Peoples R China.
EM ligun@uestc.edu.cn
FU National Natural Science Foundation of People's Republic of China
   [91026005]
FX This work was supported by the National Natural Science Foundation of
   People's Republic of China (Grant No. 91026005), I wish to thank
   Professor Wang LingYan who has contributed to the paper improvement.
CR Achanta Radhakrishna, 2010, Tech. Rep.
   [Anonymous], ECCV
   [Anonymous], 1970, PICTURE PROCESSING P
   [Anonymous], 2000, PAMI
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bin Z, 2004, J TRANSDUCER TECHNOL, V23, P20
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Harris C., 1988, ALVEY VISION C, P147151
   Levinshtein A., 2009, Turbopixels: Fast superpixels using geometric ows
   Maji S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2057, DOI 10.1109/CVPR.2011.5995630
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Martin C, 2004, PAMI
   PUZICHA J, 1999, P INT C COMP VIS
   Roberts L.G., 1965, Optimal and Electro-Optimal Information Processing, P99
   Rosenfeld A., 1976, DIGITAL PICTURE PROC
   RUZON M, 1999, P IEEE C COMP VIS PA
   Ruzon M. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1039, DOI 10.1109/ICCV.1999.790384
   Shen JH, 2006, APPL MATH OPT, V53, P331, DOI 10.1007/s00245-005-0850-1
   Shen JH, 2003, PHYSICA D, V175, P241, DOI 10.1016/S0167-2789(02)00734-0
   Sobel I. E., 1970, CAMERA MODELS MACHIN
   Tu ZW, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P131, DOI 10.1109/ICCV.2001.937614
NR 24
TC 5
Z9 6
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5965
EP 5984
DI 10.1007/s11042-015-2809-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500059
DA 2024-07-18
ER

PT J
AU Hamouchene, I
   Aouat, S
AF Hamouchene, Izem
   Aouat, Saliha
TI A new approach for texture segmentation based on NBP method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture analysis; Features extraction; Texture matching; Decomposing
   architecture; Pattern Recognition; Texture segmentation
AB Nowadays, image processing is an interesting research area due to the growth of the communication technologies. Matching problem, which consists of localizing one texture in an image, that contains several textures is one of the fundamental problem of image processing and pattern recognition. In this paper, a new feature extraction method and texture segmentation system are proposed. The proposed method (RINBP) is robust against rotation and improves the ability of extracting the local information. The segmentation architecture follows several steps. First, fixing a converging point alpha. After that, a Main analysis Window (MW) starting from alpha to the bottom left corner of the image is determined. Then, several possible windows are extracted and the feature extraction method is applied on each window. Finally, a similarity measure is calculated in order to decide if this window is pertinent or not. This process is stopped until the size of the MW reaches a minimum size. Each pertinent window increases the relevance of the desired texture in the output image. Finally, an image of relevance is obtained by considering the most relevant area. For the experiments, textured images generated from Brodatz album database are used. The experiments have shown the superiority of our method compared to other existing methods. The obtained results have illustrated the robustness and the efficiency of the proposed segmentation method based on the relevance of the analysis windows.
C1 [Hamouchene, Izem; Aouat, Saliha] USTHB Univ, Dept Comp Sci, LRIA Lab, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Hamouchene, I (corresponding author), USTHB Univ, Dept Comp Sci, LRIA Lab, Algiers, Algeria.
EM ihamouchene@usthb.dz; saouat@usthb.dz
OI AOUAT, Saliha/0000-0002-4022-9075
CR Armanfard N, 2012, PATTERN RECOGN, V45, P983, DOI 10.1016/j.patcog.2011.08.010
   Backes AR, 2012, PATTERN RECOGN, V45, P1984, DOI 10.1016/j.patcog.2011.11.009
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Du Q, 2006, J MATH IMAGING VIS, V24, P177, DOI 10.1007/s10851-005-3620-4
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Hamouchene I, 2013, IEEE TECHN COSP SCI
   Hamouchene I, 2014, AASRI PROC, V9, P2, DOI 10.1016/j.aasri.2014.09.002
   Hamouchene I, 2014, 2014 IEEE 13TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI-CC), P94, DOI 10.1109/ICCI-CC.2014.6921447
   Hanusiak RK, 2012, INT J DOC ANAL RECOG, V15, P213, DOI 10.1007/s10032-011-0166-4
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Izem H., 2014, INTELLIGENT SYSTEMS, P389, DOI DOI 10.1007/978-3-319-04702-7
   Long ZL, 2013, DIGIT SIGNAL PROCESS, V23, P859, DOI 10.1016/j.dsp.2012.11.009
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 1999, PATTERN RECOGN, V32, P477, DOI 10.1016/S0031-3203(98)00038-7
   Ojala T, 2000, 15 INT C PATT REC IC, V3, P3947
   Padmanabhan S, 2012, 2012 INTERNATIONAL CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P157, DOI 10.1109/MVIP.2012.6428784
   Pham DL, 1999, PATTERN RECOGN LETT, V20, P57, DOI 10.1016/S0167-8655(98)00121-4
   Qian XM, 2011, PATTERN RECOGN, V44, P2502, DOI 10.1016/j.patcog.2011.03.029
   RICHARDS W, 1974, KYBERNETIK, V16, P155, DOI 10.1007/BF00271719
   VANGOOL L, 1985, COMPUT VISION GRAPH, V29, P336, DOI 10.1016/0734-189X(85)90130-6
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
NR 25
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1921
EP 1940
DI 10.1007/s11042-015-3185-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000015
DA 2024-07-18
ER

PT J
AU Hermassi, H
   Hamdi, M
   Rhouma, R
   Belghith, SM
AF Hermassi, Houcemeddine
   Hamdi, Mimoun
   Rhouma, Rhouma
   Belghith, Safya Mdimegh
TI A joint encryption-compression codec for speech signals using the ITU-T
   G.711 standard and chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Source coding; Cryptography; Coding and information theory; Data
   encryption
AB We propose to incorporate encryption procedure into the lossy compression of voice data PCM(Pulse Code Modulation) based on the A-law approximation quantization. The proposed codec CPCM (Chaotic Pulse Code Modulaion) will join the encryption to the compression of the voice data. This scheme provides the same compression ratio given by the PCM codec, but with an unintelligible content. Comparisons with many used schemes have been made to highlight the proposed method in terms of security and rapidity. CPCM codec can be a better alternative to Compress-then-encrypt classical methods which is a time and resource consuming and non suitable for real-time multimedia secure transmission.
C1 [Hermassi, Houcemeddine; Hamdi, Mimoun; Rhouma, Rhouma; Belghith, Safya Mdimegh] ENIT, Tunis, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT)
RP Hermassi, H (corresponding author), ENIT, Tunis, Tunisia.
EM houcemeddine.hermassi@enit.rnu.tn
RI Hamdi, Mimoun/AAV-4747-2021; hermassi, houcemeddine/ADK-4317-2022;
   Rhouma, Rhouma/B-8018-2010; Hermassi, Houcemeddine/J-2352-2012
OI Hamdi, Mimoun/0000-0003-2390-0151; Rhouma, Rhouma/0000-0002-5715-4110;
   Belghith, Safya/0000-0001-7408-7848; Hermassi,
   houcemeddine/0000-0002-4681-4312
CR Abd El-Latif AA, 2013, AEU-INT J ELECTRON C, V67, P136, DOI 10.1016/j.aeue.2012.07.004
   [Anonymous], 1993, ITU T REC G711
   Bhatnagar G, 2012, DIGIT SIGNAL PROCESS, V22, P648, DOI 10.1016/j.dsp.2012.02.005
   Grangetto M, 2006, IEEE T MULTIMEDIA, V8, P905, DOI 10.1109/TMM.2006.879919
   Han XH, 2012, INFORM SCIENCES, V208, P14, DOI 10.1016/j.ins.2012.04.039
   Hermassi H, 2009, P 6 INT MULT SYST SI
   Hermassi H, 2010, COMMUN NONLINEAR SCI, V15, P2987, DOI 10.1016/j.cnsns.2009.11.022
   Hussain I, 2012, OPT COMMUN, V285, P4887, DOI 10.1016/j.optcom.2012.06.011
   ITU-T Test Signals for Telecommunication Systems, TEST VECT ASS REC IT
   Jakimoski G, 2008, IEEE T MULTIMEDIA, V10, P330, DOI 10.1109/TMM.2008.917355
   Jia DL, 2011, INFORM SCIENCES, V181, P3175, DOI 10.1016/j.ins.2011.03.018
   Khan MK, 2006, IEEE C P ICEIS 06, P289
   Kim H, 2007, IEEE T SIGNAL PROCES, V55, P2263, DOI 10.1109/TSP.2007.892710
   Kuhn DR, 2005, NAT I STAND TECHNOL, V800
   Li S., 2003, THESIS XIAN JIAOTONG
   LIAN SG, 2009, MULTIMEDIA CONTENT E
   Mosa E, 2010, INT J SPEECH TECHNOL, V13, P231, DOI 10.1007/s10772-010-9081-1
   Nagaraj N, 2009, COMMUN NONLINEAR SCI, V14, P1013, DOI 10.1016/j.cnsns.2007.12.001
   Riley M. D., 1987, THESIS
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Sheu LJ, 2011, NONLINEAR DYN, V65
   Son B, 2013, MULTIMEDIA TOOLS APP, V63
   Usama M, 2010, COMPUT MATH APPL, V60, P326, DOI 10.1016/j.camwa.2009.12.033
   Wen JT, 2006, IEEE SIGNAL PROC LET, V13, P69, DOI 10.1109/LSP.2005.861589
   Wong KW, 2010, IEEE T CIRCUITS-II, V57, P146, DOI 10.1109/TCSII.2010.2040315
   Wong KW, 2008, IEEE T CIRCUITS-II, V55, P1193, DOI 10.1109/TCSII.2008.2002565
   Wu CP, 2005, IEEE T MULTIMEDIA, V7, P828, DOI 10.1109/TMM.2005.854469
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
NR 29
TC 11
Z9 11
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1177
EP 1200
DI 10.1007/s11042-015-3030-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000052
DA 2024-07-18
ER

PT J
AU Himawan, I
   Song, W
   Tjondronegoro, D
AF Himawan, Ivan
   Song, Wei
   Tjondronegoro, Dian
TI Impact of automatic region-of-interest coding on perceived quality in
   mobile video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile video quality; Human vision system; Video coding; Subjective
   quality
ID SPATIOTEMPORAL SALIENCY DETECTION; VISUAL-ATTENTION; MODEL; IMAGE
AB At present, the most reliable method to obtain end-user perceived quality is through subjective tests. In this paper, the impact of automatic region-of-interest (ROI) coding on perceived quality of mobile video is investigated. The evidence, which is based on perceptual comparison analysis, shows that the coding strategy improves perceptual quality. This is particularly true in low bit rate situations. The ROI detection method used in this paper is based on two approaches: (1) automatic ROI by analyzing the visual contents automatically, and (2) eye-tracking based ROI by aggregating eye-tracking data across many users, used to both evaluate the accuracy of automatic ROI detection and the subjective quality of automatic ROI encoded video. The perceptual comparison analysis is based on subjective assessments with 54 participants, across different content types, screen resolutions, and target bit rates while comparing the two ROI detection methods. The results from the user study demonstrate that ROI-based video encoding has higher perceived quality compared to normal video encoded at a similar bit rate, particularly in the lower bit rate range.
C1 [Himawan, Ivan; Song, Wei; Tjondronegoro, Dian] Queensland Univ Technol, 2 George St Brisbane, Brisbane, Qld, Australia.
C3 Queensland University of Technology (QUT)
RP Himawan, I (corresponding author), Queensland Univ Technol, 2 George St Brisbane, Brisbane, Qld, Australia.
EM ivan.himawan@gmail.com; w1.song@qut.edu.au; dian@qut.edu.au
RI Tjondronegoro, Dian/AAE-4685-2022; Himawan, Ivan/ACZ-5134-2022
OI Tjondronegoro, Dian/0000-0001-7446-2839; Himawan,
   Ivan/0000-0003-3848-244X
FU Smart Services Cooperative Research Centre (CRC) through the Australian
   Government's CRC Programme (Department of Innovation, Industry, Science
   and Research)
FX This research was carried out as part of the activities of, and funded
   by, the Smart Services Cooperative Research Centre (CRC) through the
   Australian Government's CRC Programme (Department of Innovation,
   Industry, Science and Research).
CR Akamai, 2009, AK HD IPHONE ENC BES
   [Anonymous], 2004, P 2004 C HUM FACT CO
   [Anonymous], 2008, Advances in neural information processing systems
   [Anonymous], P IEEE PICT COD S MA
   [Anonymous], 1996, T180103 ANSI
   [Anonymous], THESIS
   [Anonymous], 2006, P 14 ACM INT C MULT
   [Anonymous], P NORD C HUM COMP IN
   [Anonymous], 2012, TECH REP
   Bian P, 2009, LECT NOTES COMPUT SC, V5506, P251, DOI 10.1007/978-3-642-02490-0_31
   Boccignone G, 2008, IEEE T CIRC SYST VID, V18, P1727, DOI 10.1109/TCSVT.2008.2005798
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Chan AJ, 2012, P 18 ANN INT C MOB C
   Chen MJ, 2003, IEEE T CONSUM ELECTR, V49, P724, DOI 10.1109/TCE.2003.1233810
   Ciaramello FM, 2007, P SPIE
   De Pessemier T, 2012, IEEE T BROADCAST, V58, P580, DOI 10.1109/TBC.2012.2199590
   Eichhorn A, 2009, P 2009 IEEE INT C CO, P5446
   Goldstein RB, 2007, COMPUT BIOL MED, V37, P957, DOI 10.1016/j.compbiomed.2006.08.018
   Grois D., 2011, Recent Advances in Region-of-interest Video Coding, Recent Advances on Video Coding, DOI DOI 10.5772/17789
   Gulliver SR, 2009, IEEE T SYST MAN CY A, V39, P744, DOI 10.1109/TSMCA.2009.2019893
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Hanhart P, 2014, J VIS COMMUN IMAGE R, V25, P555, DOI 10.1016/j.jvcir.2013.11.008
   Hasler D, 2003, P SOC PHOTO-OPT INS, V5007, P87, DOI 10.1117/12.477378
   Himawan I., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P79, DOI 10.1109/ICME.2012.126
   Himawan I, 2014, P IEEE INT C MULT EX, P1
   Himawan I, 2013, IEEE WORK APP COMP, P76, DOI 10.1109/WACV.2013.6475002
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jain E, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2699644
   Jain Eakta., 2012, Proceedings of the ACM Symposium on Applied Perception, SAP '12, P55, DOI [DOI 10.1145/2338676.2338688, 10.1145/2338676.2338688]
   Jumisko-Pyykko Satu., 2008, P 10 INT C HUMAN COM, P63, DOI DOI 10.1145/1409240.1409248
   Karrlson L., 2007, DISSERTATION
   Kim W, 2011, IEEE T CIRC SYST VID, V21, P446, DOI 10.1109/TCSVT.2011.2125450
   Knoche H, 2008, MULTIMED TOOLS APPL, V36, P145, DOI 10.1007/s11042-006-0076-5
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Lai W, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1315, DOI 10.1109/ICME.2004.1394469
   Larson E.C., 2009, IMAGE QUAL SYST PERF, P270, DOI DOI 10.1117/12.810071
   Le Meur O, 2010, SIGNAL PROCESS-IMAGE, V25, P597, DOI 10.1016/j.image.2010.05.008
   Lee JS, 2012, IEEE J-STSP, V6, P684, DOI 10.1109/JSTSP.2012.2215006
   Lee JS, 2011, IEEE J-STSP, V5, P1322, DOI 10.1109/JSTSP.2011.2165199
   Li ZC, 2011, IMAGE VISION COMPUT, V29, P1, DOI 10.1016/j.imavis.2010.07.001
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P134, DOI 10.1109/TCSVT.2007.913754
   Lu TR, 2010, IEEE IMAGE PROC, P1801, DOI 10.1109/ICIP.2010.5651644
   Mital PK, 2011, COGN COMPUT, V3, P5, DOI 10.1007/s12559-010-9074-z
   Moorthy AK, 2012, IEEE J-STSP, V6, P652, DOI 10.1109/JSTSP.2012.2212417
   Nyström M, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1671954.1671958
   OSHEA RP, 1991, PERCEPTION, V20, P415, DOI 10.1068/p200415
   Rerabek M, 2014, P SPIE OPT ENG APPL
   Ries M, 2007, P EUR SIGN PROC C
   Sangwine S. J., 1997, Sixth International Conference on Image Processing and its Applications (Conf. Publ. No.443), P790, DOI 10.1049/cp:19971004
   Sheikh HR, 2003, REAL-TIME IMAGING, V9, P27, DOI 10.1016/S1077-2014(02)00116-X
   Song W, 2010, P ACM INT C MULT
   Song Wei., 2011, Proceedings_of_the_19th_ACM international_conference_on_Multimedia, P403
   't Hart BM, 2009, VIS COGN, V17, P1132, DOI 10.1080/13506280902812304
   Tsapatsoulis N, 2007, INT J NEURAL SYST, V17, P289, DOI 10.1142/S0129065707001147
   Vu CT, 2008, 2008 IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS & INTERPRETATION, P73, DOI 10.1109/SSIAI.2008.4512288
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2003, IEEE T IMAGE PROCESS, V12, P243, DOI 10.1109/TIP.2003.809015
   Winkler S, 2012, IEEE J-STSP, V6, P616, DOI 10.1109/JSTSP.2012.2215007
   Wu HR, 2013, P IEEE, V101, P2025, DOI 10.1109/JPROC.2013.2262911
   Yang XK, 2005, IEEE T CIRC SYST VID, V15, P496, DOI 10.1109/TCSVT.2005.844458
   You W, 2009, P SPIE REAL TIM IM V
NR 62
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 785
EP 813
DI 10.1007/s11042-015-3054-y
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000034
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Huszák, A
AF Huszak, Arpad
TI Advanced free viewpoint video streaming techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Free viewpoint video; Multicast streaming; Viewpoint prediction;
   Distributed networks
ID MULTIVIEW VIDEO
AB Free-viewpoint video is a new type of interactive multimedia service allowing users to control their viewpoint and generate new views of a dynamic scene from any perspective. The uniquely generated and displayed views are composed from two or more high bitrate camera streams that must be delivered to the users depending on their continuously changing perspective. Due to significant network and computational resource requirements, we proposed scalable viewpoint generation and delivery schemes based on multicast forwarding and distributed approach. Our aim was to find the optimal deployment locations of the distributed viewpoint synthesis processes in the network topology by allowing network nodes to act as proxy servers with caching and viewpoint synthesis functionalities. Moreover, a predictive multicast group management scheme was introduced in order to provide all camera views that may be requested in the near future and prevent the viewpoint synthesizer algorithm from remaining without camera streams. The obtained results showed that even 42 % traffic decrease can be realized using distributed viewpoint synthesis and the probability of viewpoint synthesis starvation can be also significantly reduced in future free viewpoint video services.
C1 [Huszak, Arpad] Budapest Univ Technol & Econ, Dept Networked Syst & Serv, Dept Telecommun, Budapest, Hungary.
C3 Budapest University of Technology & Economics
RP Huszák, A (corresponding author), Budapest Univ Technol & Econ, Dept Networked Syst & Serv, Dept Telecommun, Budapest, Hungary.
EM huszak@hit.bme.hu
RI Huszák, Árpád/H-1396-2012
OI Huszák, Árpád/0000-0002-4756-9283
FU European Union's Seventh Framework Programme [288502]; Hungarian Academy
   of Sciences through the Bolyai Janos Research Fellowship
FX The research was supported by the European Union's Seventh Framework
   Programme under grant agreement no 288502 (CONCERTO project). The author
   is grateful for the support of the Hungarian Academy of Sciences through
   the Bolyai Janos Research Fellowship.
CR Adams A., 2005, 3973 RFC
   Chakareski J, 2013, IEEE COMMUN MAG, V51, P94, DOI 10.1109/MCOM.2013.6515052
   Chiariglione L, 2014, INFOCOMMUNICATIONS J, V6, P51
   CHUANG J, 1998, INET
   Domanski M., 2009, 2009 INT C IM PROC C, P1
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   FEHN C, 2004, P PICT COD S SAN FRA
   Fenner B., 2006, Protocol Independent Multicast - Sparse Mode (PIM-SM): Protocol Specification (Revised)
   Gürler CG, 2011, P IEEE, V99, P694, DOI 10.1109/JPROC.2010.2100010
   Han Z, 2007, INT CONF ACOUST SPEE, P773
   Ho Ting-Yu, 2014, ARXIV14103977
   Jo S., 2008, IEEE INT C MULT EXP, P1577
   Kellerer H., 2004, Knapsack Problems. Springer Nature Book Archives Millennium, P317
   Kimata H, 2008, IEEE INT C MULT
   Kurutepe E, 2007, P INT PACK VID WORKS, P302
   Kurutepe E, 2007, IEEE T CIRC SYST VID, V17, P1558, DOI 10.1109/TCSVT.2007.903664
   Levoy M, 1996, P COMP GRAPH SIGGRAP
   Miao D, 2011, P 19 ACM INT C MULT
   Ni Z, 2009, C IM PROC ICIP, P7
   Petrovic G, 2007, P 1 INT C IMM TEL IC
   Petrovic G, 2006, NEAR FUTURE STREAMIN
   Phillips G, 1999, SIGCOMM 99
   Smolic A, 2011, PATTERN RECOGN, V44, P1958, DOI 10.1016/j.patcog.2010.09.005
   Starck Jonathan., 2009, Journal of Graphics, GPU, and Game Tools, V14, P57
   Su GM, 2011, INT J COMMUN SYST, V24, P1261, DOI 10.1002/dac.1190
   Tanimoto M, 2011, IEEE SIGNAL PROC MAG, V28, P67, DOI 10.1109/MSP.2010.939077
   Toni L, 2015, ARXIV150900464
   Zuo L, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1225, DOI 10.1109/ICME.2006.262758
NR 28
TC 7
Z9 10
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 373
EP 396
DI 10.1007/s11042-015-3048-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000017
DA 2024-07-18
ER

PT J
AU Khosravi, MH
   Hassanpour, H
AF Khosravi, Mohammad Hossein
   Hassanpour, Hamid
TI Model-based full reference image blurriness assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image blurriness evaluation; Structural information; Low frequency
   redundancies; Singular value decomposition
ID QUALITY ASSESSMENT
AB Measuring image blurriness is an important issue in image-quality assessment. The blurriness affects the image quality by degrading the image's high frequency details in the form of some uniform redundancies in neighboring pixels. Indeed, the blurriness is accompanied with two destructions: corrupted high frequency details, and degraded image structure due to the redundancies. In this paper, we propose an approach that measures the effects of these two distortions using singular value decomposition (SVD). From the properties of SVD, the basis images corresponding to the higher singular values are associated with the structural information of the image, while the ones corresponding to the lower singular values are related to the image details. This work employs this property and splits the ordered singular values into two subsets from a non-fixed separation point, and constructs two images by stacking up the basis images corresponding to these two subsets. By moving the separation point for these two subsets and computing the energy of the two constructed images in each point, two sequences of energies will be in hand. We shows that the behavior of these two sequences can be used to assess the amount of both structural distortions and nonstructural detail degradations of an image, and hence a valuable blur metric. Experimental results illustrate that there is a well correlation between the results of our blur metric and human scores. In addition, in comparative experiments, we found that the proposed blur metric is stand among the best state-of-the-art ones in evaluating quality of images in terms of blurriness.
C1 [Khosravi, Mohammad Hossein; Hassanpour, Hamid] Univ Shahrood, Lab Image Proc & Data Min, Shahrood, Iran.
RP Khosravi, MH (corresponding author), Univ Shahrood, Lab Image Proc & Data Min, Shahrood, Iran.
EM mohokhosravi@shahroodut.ac.ir
RI Khosravi, Mohammad Hossein/AAQ-9988-2021; Hassanpour,
   Hamid/AAL-7271-2020
OI Khosravi, Mohammad Hossein/0000-0003-3595-1829; Hassanpour,
   Hamid/0000-0002-5513-9822
CR Attar A, 2016, MULTIMED TOOLS APPL, V75, P7407, DOI 10.1007/s11042-015-2663-9
   Batten CF, 2000, THESIS
   Caviedes J, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P53, DOI 10.1109/ICIP.2002.1038901
   Chung YC, 2004, CONF CYBERN INTELL S, P356
   Dijk J, 2003, LECT NOTES COMPUT SC, V2756, P149
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Group VQE, 2003, FIN REP VID QUAL EXP
   Hassen R, 2013, IEEE T IMAGE PROCESS
   Hassen R, 2010, INT CONF ACOUST SPEE, P2434, DOI 10.1109/ICASSP.2010.5496297
   Kristan M, 2006, PATTERN RECOGN LETT, V27, P1431, DOI 10.1016/j.patrec.2006.01.016
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li SN, 2011, IEEE T MULTIMEDIA, V13, P935, DOI 10.1109/TMM.2011.2152382
   Liu DB, 2009, INT WORK QUAL MULTIM, P75, DOI 10.1109/QOMEX.2009.5246974
   Narwaria M, 2012, IEEE T SYST MAN CY B, V42, P347, DOI 10.1109/TSMCB.2011.2163391
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Sang QB, 2014, J VIS COMMUN IMAGE R, V25, P1625, DOI 10.1016/j.jvcir.2014.08.002
   Sheikh H.R., 2005, LIVE IMAGE QUALITY A, V2
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shnayderman A, 2006, IEEE T IMAGE PROCESS, V15, P422, DOI 10.1109/TIP.2005.860605
   Su B, 2011, Proceedings of the 19th ACM International Conference on Multimedia. MM'11, DOI [DOI 10.1145/2072298.2072024, DOI 10.5555/1785794.1785825]
   Tsomko Elena, 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P171, DOI 10.1109/WIAMIS.2008.28
   Vu PV, 2012, IEEE SIGNAL PROC LET, V19, P423, DOI 10.1109/LSP.2012.2199980
   Wang S, 2013, 2013 20 IEEE INT C I
   Wang Shumin, 2014, Biomed Res Int, V2014, P507353, DOI 10.1155/2014/507353
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2006, SYNTHESIS LECT IMAGE, V1, P1, DOI DOI 10.1007/978-3-031-02238-8
   Wee CY, 2008, INT CONF SIGN PROCES, P840, DOI 10.1109/ICOSP.2008.4697259
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhu JY, 2012, IEEE T IMAGE PROCESS, V21, P919, DOI 10.1109/TIP.2011.2169971
   Zhu X, 2013, P 7 INT WORKSH VID P
NR 31
TC 7
Z9 8
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2733
EP 2747
DI 10.1007/s11042-015-3149-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000050
DA 2024-07-18
ER

PT J
AU Veinidis, C
   Pratikakis, I
   Theoharis, T
AF Veinidis, Christos
   Pratikakis, Ioannis
   Theoharis, Theoharis
TI On the retrieval of 3D mesh sequences of human actions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D mesh sequences; Retrieval; Human actions; Dynamic time warping
ID 3-D OBJECT RETRIEVAL; TIME-VARYING MESH; PARALLEL FRAMEWORK;
   RECOGNITION; CAPTURE
AB In this paper, the problem of unsupervised human action retrieval in 3D mesh sequences is addressed. An action is composed of a mesh sequence, wherein each frame is represented by a static shape descriptor. Six state-of-the-art static descriptors are used to extract meaningful information for each sequence. Firstly, these descriptors are examined in terms of frame-to-frame similarity by means of Receiver Operating Characteristic (ROC) curves. Then, they are utilized in the action retrieval problem, where the query is an entire 3D mesh sequence. Each action is a multidimensional curve which traverses the points defined by the vectors of each descriptor. The estimation of similarity between actions is achieved by calculating the Dynamic Time Warping (DTW) distance between the corresponding curves. The retrieval performance is further examined when the Sakoe band is used to constrain the search space in DTW. The experiments concerning the action retrieval problem were carried out by using a real dataset and an artificial dataset where the proposed retrieval framework is shown to achieve high performance for both datasets.
C1 [Veinidis, Christos; Pratikakis, Ioannis] Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi, Greece.
   [Theoharis, Theoharis] Univ Athens, Dept Informat & Telecommun, Comp Graph Lab, Athens, Greece.
   [Theoharis, Theoharis] Norwegian Univ Sci & Technol NTNU, IDI, Trondheim, Norway.
C3 Democritus University of Thrace; National & Kapodistrian University of
   Athens; Norwegian University of Science & Technology (NTNU)
RP Veinidis, C (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi, Greece.
EM cveinidi@ee.duth.gr; ipratika@ee.duth.gr; theotheo@idi.ntnu.no
RI PRATIKAKIS, IOANNIS/AAD-3387-2019; Theoharis, Theoharis/AAN-2555-2020
OI PRATIKAKIS, IOANNIS/0000-0002-4124-3688; 
FU European Union (European Social Fund ESF); Greek national funds through
   Operational Program "Education and Lifelong Learning" of the National
   Strategic Reference Framework (NSRF) - Research Funding Program: THALES
   [MIS 379516]
FX This research has been co-financed by the European Union (European
   Social Fund ESF) and Greek national funds through the Operational
   Program "Education and Lifelong Learning" of the National Strategic
   Reference Framework (NSRF) - Research Funding Program: THALES (MIS
   379516). Investing in knowledge society through the European Social
   Fund.
CR [Anonymous], 2008, EUR WORKSH 3D OBJ RE
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Huang P., 2010, P 3DPVT INT S
   Huang P, 2010, INT J COMPUT VISION, V89, P362, DOI 10.1007/s11263-010-0319-9
   Jiang YG, 2011, IEEE T CIRC SYST VID, V21, P674, DOI 10.1109/TCSVT.2011.2129870
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Jones S, 2013, INFORM SCIENCES, V236, P56, DOI 10.1016/j.ins.2013.02.018
   Kasai D, 2009, IEEE INT CON MULTI, P854, DOI 10.1109/ICME.2009.5202629
   Kilner J., 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1, DOI 10.1109/ICCVW.2009.5457724
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Papadakis P, 2007, PATTERN RECOGN, V40, P2437, DOI 10.1016/j.patcog.2006.12.026
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Ratanamahatana C, 2004, Everything you know about Dynamic Time Warping is Wrong
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Senin P., 2008, TECHNICAL REPORT SER
   Sfikas K, 2014, PARTIAL MAT IN PRESS, DOI [10. 1007/s11042-014-2069-0, DOI 10.1007/S11042-014-2069-0]
   Slama R, 2014, IMAGE VISION COMPUT, V32, P131, DOI 10.1016/j.imavis.2013.12.011
   Starck J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P915
   Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68
   Tudu B, 2008, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON SENSING TECHNOLOGY, P254, DOI 10.1109/ICSENST.2008.4757108
   Veinidis C, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON 3D VISION, VOL. 2, P33, DOI 10.1109/3DV.2014.103
   Vlachos M, 2006, VLDB J, V15, P1, DOI 10.1007/s00778-004-0144-2
   Yamasaki T, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/59535
   Yamasaki T, 2009, IEEE INT CON MULTI, P846, DOI 10.1109/ICME.2009.5202627
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
NR 27
TC 5
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2059
EP 2085
DI 10.1007/s11042-015-3137-9
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000022
DA 2024-07-18
ER

PT J
AU Carlier, A
   Salvador, A
   Cabezas, F
   Giro-i-Nieto, X
   Charvillat, V
   Marques, O
AF Carlier, Axel
   Salvador, Amaia
   Cabezas, Ferran
   Giro-i-Nieto, Xavier
   Charvillat, Vincent
   Marques, Oge
TI Assessment of crowdsourcing and gamification loss in user-assisted
   object segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GWAP; Crowdsourcing; Serious games; Object detection; Object
   segmentation
AB There has been a growing interest in applying human computation - particularly crowdsourcing techniques - to assist in the solution of multimedia, image processing, and computer vision problems which are still too difficult to solve using fully automatic algorithms, and yet relatively easy for humans. In this paper we focus on a specific problem - object segmentation within color images - and compare different solutions which combine color image segmentation algorithms with human efforts, either in the form of an explicit interactive segmentation task or through an implicit collection of valuable human traces with a game. We use Click'n'Cut, a friendly, web-based, interactive segmentation tool that allows segmentation tasks to be assigned to many users, and Ask'nSeek, a game with a purpose designed for object detection and segmentation. The two main contributions of this paper are: (i) We use the results of Click'n'Cut campaigns with different groups of users to examine and quantify the crowdsourcing loss incurred when an interactive segmentation task is assigned to paid crowd-workers, comparing their results to the ones obtained when computer vision experts are asked to perform the same tasks. (ii) Since interactive segmentation tasks are inherently tedious and prone to fatigue, we compare the quality of the results obtained with Click'n'Cut with the ones obtained using a (fun, interactive, and potentially less tedious) game designed for the same purpose. We call this contribution the assessment of the gamification loss, since it refers to how much quality of segmentation results may be lost when we switch to a game-based approach to the same task. We demonstrate that the crowdsourcing loss is significant when using all the data points from workers, but decreases substantially (and becomes comparable to the quality of expert users performing similar tasks) after performing a modest amount of data analysis and filtering out of users whose data are clearly not useful. We also show that - on the other hand - the gamification loss is significantly more severe: the quality of the results drops roughly by half when switching from a focused (yet tedious) task to a more fun and relaxed game environment.
C1 [Carlier, Axel; Charvillat, Vincent] Univ Toulouse, IRIT ENSEEIHT, Toulouse, France.
   [Salvador, Amaia; Cabezas, Ferran; Giro-i-Nieto, Xavier] Univ Politecn Cataluna, Barcelona, Catalonia, Spain.
   [Marques, Oge] Florida Atlantic Univ, Boca Raton, FL 33431 USA.
C3 Universite de Toulouse; Universite Toulouse III - Paul Sabatier;
   Universite Federale Toulouse Midi-Pyrenees (ComUE); Institut National
   Polytechnique de Toulouse; Universitat Politecnica de Catalunya; State
   University System of Florida; Florida Atlantic University
RP Carlier, A (corresponding author), Univ Toulouse, IRIT ENSEEIHT, Toulouse, France.
EM Axel.Carlier@enseeiht.fr; amaia.salvador@upc.edu;
   ferran.cabezas@upc.edu; xavier.giro@upc.edu;
   vincent.charvillat@enseeiht.fr; omarques@fau.edu
RI Giró-i-Nieto, Xavier/M-5834-2013
OI Giró-i-Nieto, Xavier/0000-0002-9935-5332
FU Spanish Ministerio de Economa y Competitividad [TEC2013-43935-R];
   European Regional Development Fund (ERDF)
FX This work has been developed in the framework of the project
   TEC2013-43935-R, financed by the Spanish Ministerio de Economa y
   Competitividad and the European Regional Development Fund (ERDF).
CR Adamek T., 2006, THESIS
   [Anonymous], 2013, ACM T GRAPH P SIGGRA
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Arbelaez Pablo., 2008, CVPR
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Cabezas F, 2015, ARXIV150500145
   Carlier A., 2014, Proceedings of the 2014 International ACM Workshop on Crowdsourcing for Multimedia, P53
   Carlier A, 2012, LECT NOTES COMPUT SC, V7583, P249, DOI 10.1007/978-3-642-33863-2_25
   Carreira J, 2010, PROC CVPR IEEE, P3241, DOI 10.1109/CVPR.2010.5540063
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen Y, 2014, P NEUR INF PROC SYST
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fathi A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.78
   Giro-i Nieto X, 2014, MTAP, V70
   Jain SD, 2013, IEEE I CONF COMP VIS, P1313, DOI 10.1109/ICCV.2013.166
   Lee HS, 2014, WCVPR 2014 W COMPUTE
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu T, 2011, PAMI, V33
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lux M, 2012, AIIDE
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   McGuinness K, 2013, ICIP
   McGuinness K, 2010, PATTERN RECOGN, V43, P434, DOI 10.1016/j.patcog.2009.03.008
   Noma A, 2012, PATTERN RECOGN, V45, P1159, DOI 10.1016/j.patcog.2011.08.017
   Oleson D., 2011, HUMAN COMPUTATION, V11, P11
   Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rupprecht C, 2015, PROC CVPR IEEE, P3314, DOI 10.1109/CVPR.2015.7298952
   Russakovsky Olga, 2015, ARXIV150602106
   Russell B.C., 2008, IJCV, V77
   Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934
   Salvador A, 2013, ACM CROWDMM
   Steggink J, 2011, MULTIMEDIA SYSTEMS, P17
   von Ahn L., 2004, ACM CHI
   von Ahn L., 2006, ACM CHI
   Wang J, 2005, ACM T GRAPHIC, V24, P585, DOI 10.1145/1073204.1073233
NR 37
TC 7
Z9 7
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15901
EP 15928
DI 10.1007/s11042-015-2897-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700045
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Castro, H
   Monteiro, J
   Pereira, A
   Silva, D
   Coelho, G
   Carvalho, P
AF Castro, H.
   Monteiro, J.
   Pereira, A.
   Silva, D.
   Coelho, G.
   Carvalho, P.
TI Cognition inspired format for the expression of computer vision metadata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Metadata; Multi-view video; Multimedia annotation; Computer vision;
   Cognition
AB Over the last decade noticeable progress has occurred in automated computer interpretation of visual information. Computers running artificial intelligence algorithms are growingly capable of extracting perceptual and semantic information from images, and registering it as metadata. There is also a growing body of manually produced image annotation data. All of this data is of great importance for scientific purposes as well as for commercial applications. Optimizing the usefulness of this, manually or automatically produced, information implies its precise and adequate expression at its different logical levels, making it easily accessible, manipulable and shareable. It also implies the development of associated manipulating tools. However, the expression and manipulation of computer vision results has received less attention than the actual extraction of such results. Hence, it has experienced a smaller advance. Existing metadata tools are poorly structured, in logical terms, as they intermix the declaration of visual detections with that of the observed entities, events and comprising context. This poor structuring renders such tools rigid, limited and cumbersome to use. Moreover, they are unprepared to deal with more advanced situations, such as the coherent expression of the information extracted from, or annotated onto, multi-view video resources. The work here presented comprises the specification of an advanced XML based syntax for the expression and processing of Computer Vision relevant metadata. This proposal takes inspiration from the natural cognition process for the adequate expression of the information, with a particular focus on scenarios of varying numbers of sensory devices, notably, multi-view video.
C1 [Castro, H.; Monteiro, J.; Pereira, A.; Silva, D.; Coelho, G.] INESC TEC, Campus FEUP,Rua Dr Roberto Frias, P-4200465 Oporto, Portugal.
   [Carvalho, P.] Inst Super Engn Porto, Oporto, Portugal.
C3 INESC TEC; Instituto Politecnico do Porto
RP Castro, H (corresponding author), INESC TEC, Campus FEUP,Rua Dr Roberto Frias, P-4200465 Oporto, Portugal.
EM hcastro@inescporto.pt; jpsm@inescporto.pt; ajrp@inescporto.pt;
   dvsilva@inescporto.pt; agcoelho@inescporto.pt;
   pedro.carvalho@inescporto.pt
RI Carvalho, Pedro/V-6468-2019
OI Carvalho, Pedro/0000-0003-4983-4316; Castro, Helder/0000-0003-3858-1616;
   Monteiro, Joao Pedro/0000-0002-5166-825X; Pereira,
   Americo/0000-0002-1939-2126
FU North Portugal Regional Operational Programme [ON. 2 - O]; National
   Strategic Reference Framework (NSRF) through European Regional
   Development Fund (ERDF) -; Fundacao para a Ciencia e a Tecnologia (FCT)
   [QREN23277 RETAIL PRO]; European Regional Development Fund (ERDF);
   Agencia de Inovacao (ADI) [QREN 33910 ARENA]
FX The Work was largely developed in the context of: project Media Arts and
   Technologies (MAT), NORTE-07-0124-FEDER-000061, financed by the North
   Portugal Regional Operational Programme (ON. 2 - O Novo Norte), under
   the National Strategic Reference Framework (NSRF), through the European
   Regional Development Fund (ERDF), and by national funds, through the
   Portuguese funding agency, Fundacao para a Ciencia e a Tecnologia (FCT);
   Project QREN23277 RETAIL PRO, a co-promotion R&D project funded by
   European Regional Development Fund (ERDF) through ON2 as part of the
   National Strategic Reference Framework (NSRF), and managed by Agencia de
   Inovacao (ADI); Project QREN 33910 ARENA, a R&D project funded by
   European Regional Development Fund (ERDF) through ON2 as part of the
   National Strategic Reference Framework (NSRF), and managed by IAPMEI -
   Agencia para a Competitividade e Inovacao, I.P.
CR [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], 2010, VISION COMPUTATIONAL
   [Anonymous], 2013, REUTERS
   [Anonymous], 2010, P IEEE C COMP VIS PA
   [Anonymous], 2011, NY TIMES
   Barrett D., 2013, TELEGRAPH
   Carvalho P, 2013, MACH VISION APPL, V24, P1149, DOI 10.1007/s00138-013-0523-z
   Carvalho P, 2012, IMAGE VISION COMPUT, V30, P630, DOI 10.1016/j.imavis.2012.06.002
   Castro H, 2009, FUNCHAL, DOI [10.5220/0002263103510358, DOI 10.5220/0002263103510358]
   Doherty AR, 2013, AM J PREV MED, V44, P320, DOI 10.1016/j.amepre.2012.11.008
   Drost B., 2010, CVPR
   Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608
   List T, 2004, INT C PATT RECOG, P789, DOI 10.1109/ICPR.2004.1334335
   Pereira Fernando., 2001, International Journal of Image and Graphics, V1, P527, DOI DOI 10.1142/S021946780100030X
   Reisslein M, 2014, COMPUTER, V47, P23, DOI 10.1109/MC.2014.134
   Saligrama V, 2010, IEEE SIGNAL PROC MAG, V27, P18, DOI 10.1109/MSP.2010.937393
   Sanes D., 2006, DEV NERVOUS SYSTEM, V2nd
   Sano M, 2013, IVMSP WORKSH 2013 IE, P1
   Schallauer P, 2009, P SPIE DEFENSE SECUR
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Volkmer T., 2005, 13th Annual ACM International Conference on Multimedia, P892, DOI 10.1145/1101149.1101341
   Yan Y., 2013, INT C COMP VIS
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
NR 23
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17035
EP 17057
DI 10.1007/s11042-015-2974-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600015
DA 2024-07-18
ER

PT J
AU Karthikeyan, P
   Vasuki, S
AF Karthikeyan, P.
   Vasuki, S.
TI Multiresolution joint bilateral filtering with modified adaptive
   shrinkage for image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Joint Bilateral filter; Image denoising; Shrinkage functions; Wavelet
   transform
ID WAVELET; INTERSCALE; REMOVAL; NOISE
AB This paper proposes an effective image denoising of gray level images in wavelet transform domain using joint bilateral filter and modified adaptive shrinkage. The input image is first decomposed using 2D-discrete wavelet transform. The multiresolution joint bilateral filtering is then applied to the approximation sub-band of the decomposed image. Flat and edge regions are obtained using the alpha-map computed from wavelet transform coefficients of LH, HL, and HH bands. Noise is removed in the flat regions by Inner Product method. After removing noise in the flat regions, further noise removal is done in the edge regions using NeighShrink SURE shrinkage functions. The modified wavelet coefficients in the flat and edge regions are combined and filtered by using Gaussian low pass filter. Finally the denoised output image is reconstructed using 2D-inverse discrete wavelet transform. Experimentation has been carried out on set of standard test images using the proposed algorithm and its performance is evaluated and compared with existing state of art methods using PSNR, EKI and Computation time. Experimental results show that the proposed algorithm can effectively reduce noise without losing sharp details in the noisy images and is suitable for commercial low-cost imaging systems.
C1 [Karthikeyan, P.; Vasuki, S.] Velammal Coll Engn & Technol, Dept Elect & Comp Engn, Madurai, Tamil Nadu, India.
RP Karthikeyan, P (corresponding author), Velammal Coll Engn & Technol, Dept Elect & Comp Engn, Madurai, Tamil Nadu, India.
EM pkn@vcet.ac.in
RI ECE0909, Dr. Vasuki.S/ABG-3155-2021; Karthikeyan,
   Pathinettampadian/ABY-9303-2022
OI ECE0909, Dr. Vasuki.S/0000-0003-0815-6424; Karthikeyan,
   Pathinettampadian/0000-0001-8515-7370
CR Acton ST, 1998, IEEE T IMAGE PROCESS, V7, P280, DOI 10.1109/83.661178
   [Anonymous], IEEE T CONSUM ELECT
   [Anonymous], 2010 IEEE INT C COMP
   Arivazhagan S, 2015, SIGNAL IMAGE VIDEO P, V9, P885, DOI 10.1007/s11760-013-0521-7
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Buades A, 2006, NUMER MATH, V105, P1, DOI 10.1007/s00211-006-0029-v
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Chatterjee P, 2012, IEEE T IMAGE PROCESS, V21, P1635, DOI 10.1109/TIP.2011.2172799
   Chen GY, 2005, PATTERN RECOGN, V38, P115, DOI 10.1016/j.patcog.2004.05.009
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.1080/01621459.1995.10476626
   Fodor IK, 2003, J ELECTRON IMAGING, V12, P151, DOI 10.1117/1.1525793
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   Jain P, 2015, VISUAL COMPUT, V31, P657, DOI 10.1007/s00371-014-0993-7
   Lee SW, 2005, IEEE T CONSUM ELECTR, V51, P648, DOI 10.1109/TCE.2005.1468014
   Liu C, 2008, IEEE T PATTERN ANAL, V30, P299, DOI 10.1109/TPAMI.20071176
   Luisier F, 2007, IEEE T IMAGE PROCESS, V16, P593, DOI 10.1109/TIP.2007.891064
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Nasri M, 2009, NEUROCOMPUTING, V72, P1012, DOI 10.1016/j.neucom.2008.04.016
   Om H, 2015, SIGNAL IMAGE VIDEO P, V9, P191, DOI 10.1007/s11760-013-0434-5
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Pizurica A, 2006, IEEE T IMAGE PROCESS, V15, P654, DOI 10.1109/TIP.2005.863698
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Rabbani H, 2009, PATTERN RECOGN, V42, P2181, DOI 10.1016/j.patcog.2009.01.005
   STEIN CM, 1981, ANN STAT, V9, P1135, DOI 10.1214/aos/1176345632
   Sudha S, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P296, DOI 10.1109/ICCIMA.2007.305
   Yan FX, 2008, IEEE SIGNAL PROC LET, V15, P139, DOI 10.1109/LSP.2007.914790
   Yu HC, 2009, IEEE T IMAGE PROCESS, V18, P2364, DOI 10.1109/TIP.2009.2026685
   Zhang Ming, 2008, IEEE T IMAGE PROCESS, V17
   Zhou DW, 2008, PATTERN RECOGN LETT, V29, P1694, DOI 10.1016/j.patrec.2008.04.014
NR 31
TC 6
Z9 8
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16135
EP 16152
DI 10.1007/s11042-015-2923-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700057
DA 2024-07-18
ER

PT J
AU Kumar, MVP
   Varma, KCRC
   Mahapatra, S
AF Kumar, Venkata Phani M.
   Varma, K. C. Ravi Chandra
   Mahapatra, Sudipta
TI Pyramid coding based rate control for constant bit rate video streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video streaming; Spatio-temporal complexity; Peak Signal to Noise Ratio
   (PSNR)
ID H.264/AVC
AB In this paper, a novel pyramid coding based rate control scheme is proposed for video streaming applications constrained by a constant channel bandwidth. To achieve the target bit rate with the best quality, the initial quantization parameter (QP) is determined by the average spatio-temporal complexity of the sequence, its resolution and the target bit rate. Simple linear estimation models are then used to predict the number of bits that would be necessary to encode a frame for a given complexity and QP. The experimental results demonstrate that the proposed rate control scheme significantly outperforms the existing rate control scheme in the Joint Model (JM) reference software in terms of Peak Signal to Noise Ratio (PSNR) and consistent perceptual visual quality while achieving the target bit rate. Finally, the proposed scheme is validated through experimental evaluation over a miniature test-bed.
C1 [Kumar, Venkata Phani M.; Varma, K. C. Ravi Chandra; Mahapatra, Sudipta] Indian Inst Technol Kharagpur, Dept E & ECE, Kharagpur, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Kumar, MVP (corresponding author), Indian Inst Technol Kharagpur, Dept E & ECE, Kharagpur, W Bengal, India.
EM venkataphanikumarm@gmail.com; kcravi912@gmail.com;
   sudipta.mahapatra@gmail.com
OI K C, Ravi Chandra Varma/0000-0001-6115-1169
CR [Anonymous], 2007, JVT W042 23 M SAN JO, P21
   Chang Kan, 2010, Journal of China Universities of Posts and Telecommunications, V17, P116, DOI 10.1016/S1005-8885(09)60516-1
   Conklin GJ, 2001, IEEE T CIRC SYST VID, V11, P269, DOI 10.1109/76.911155
   Huang KL, 2009, IEEE T IMAGE PROCESS, V18, P1004, DOI 10.1109/TIP.2009.2014259
   Kang XG, 2006, LECT NOTES COMPUT SC, V4261, P989
   Leontaris A, 2008, IEEE IMAGE PROC, P2792, DOI 10.1109/ICIP.2008.4712374
   Li M, 2009, SIGNAL PROCESS-IMAGE, V24, P177, DOI 10.1016/j.image.2008.12.009
   Li Z. G., 2003, 7 M PATT 2 THAIL, V14
   Lim K.-P., 2005, JVT0079
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P116, DOI 10.1109/TCSVT.2007.903325
   Lopez AguilarF., 2009, International Conference on Ultra Modern Telecommunications Workshops, P1
   Overmeire L, 2005, SIGNAL PROCESS-IMAGE, V20, P343, DOI 10.1016/j.image.2005.01.001
   Pai CY, 2006, SIGNAL PROCESS-IMAGE, V21, P67, DOI 10.1016/j.image.2005.06.006
   Schwarz H., 2005, JVTP014
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu Y., 2014, MATH PROBL ENG, V2014
   Xu L, 2007, IEEE INT SYMP CIRC S, P49, DOI 10.1109/ISCAS.2007.378179
   Yu Y, 2001, IEEE T CIRC SYST VID, V11, P345, DOI 10.1109/76.911160
NR 20
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17247
EP 17272
DI 10.1007/s11042-015-2993-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600024
DA 2024-07-18
ER

PT J
AU Kuo, CM
   Hsieh, CH
   Yang, NC
   Kuo, CM
   Chang, CK
   Chen, YM
AF Kuo, Chung-Ming
   Hsieh, Chaur-Heh
   Yang, Nai-Chung
   Kuo, Chang-Ming
   Chang, Chi-Kao
   Chen, Yu-Ming
TI Constructing a discriminative visual vocabulary with macro and micro
   sense of visual words
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual words; Macro-sense; Micro-sense; Retrieval; Categorization
ID COLOR
AB Visual vocabulary representation approach has been successfully applied to many multimedia and vision applications, including visual recognition, image retrieval, and scene modeling/categorization. The idea behind the visual vocabulary representation is that an image can be represented by visual words, a collection of local features of images. In this work, we will develop a new scheme for the construction of visual vocabulary based on the analysis of visual word contents. By considering the content homogeneity of visual words, we design a visual vocabulary which contains macro-sense and micro-sense visual words. The two types of visual words are appropriately further combined to describe an image effectively. We also apply the visual vocabulary to construct image retrieving and categorization systems. The performance evaluation for the two systems indicates that the proposed visual vocabulary achieves promising results.
C1 [Kuo, Chung-Ming; Yang, Nai-Chung; Kuo, Chang-Ming; Chang, Chi-Kao; Chen, Yu-Ming] I Shou Univ, Dept Informat Engn, Kaohsiung, Taiwan.
   [Hsieh, Chaur-Heh] Ming Chuan Univ, Dept Comp & Commun Engn, Taoyuan, Taiwan.
C3 I Shou University; Ming Chuan University
RP Kuo, CM (corresponding author), I Shou Univ, Dept Informat Engn, Kaohsiung, Taiwan.
EM kuocm@isu.edu.tw
FU National Science Counsel of R.O.C. [NSC. 102-2221-E-214 -040]
FX The authors would like to express their sincere thanks to the anonymous
   reviewers for their invaluable comments and suggestions. This work was
   supported by the National Science Counsel of R.O.C. Granted NSC.
   102-2221-E-214 -040.
CR Ancuti C, 2007, PROCEEDINGS OF THE 5TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P130
   [Anonymous], 2001, JTC1SC29WG11N391 ISO
   Baker L. D., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P96, DOI 10.1145/290941.290970
   Bekkerman R., 2001, SIGIR Forum, P146
   Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bolovinou A, 2013, PATTERN RECOGN, V46, P1039, DOI 10.1016/j.patcog.2012.07.024
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Cao Y, 2012, INT J DIGIT CONTENT, V6, P89
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Deng Y, 2001, IEEE T IMAGE P, V10
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Horster E., 2007, CIVR 07 P 2007 ACM I, P17, DOI DOI 10.1145/1282280.1282283
   Ji RR, 2012, IEEE T IMAGE PROCESS, V21, P2282, DOI 10.1109/TIP.2011.2176950
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Kesorn K, 2012, IEEE T MULTIMEDIA, V14, P211, DOI 10.1109/TMM.2011.2170665
   Kuo C.L., 2015, IEEE 2015 INT S NEXT, P1
   Lei Zhu, 2000, Proceedings ACM Multimedia 2000, P157
   Li T, 2011, IEEE T CIRC SYST VID, V21, P381, DOI 10.1109/TCSVT.2010.2041828
   Liu H, 2007, LECT NOTES COMPUT SC, V4740, P470
   Lopez-Sastre R., 2010, COMPUTER VISION IMAG, V115, P415
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma WY, 1997, P SOC PHOTO-OPT INS, V3016, P496, DOI 10.1117/12.274547
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mojsilovic A, 2000, IEEE T IMAGE P, V9
   Mojsilovic A, 2002, IEEE T IMAGE P, V11
   Perronnin F, 2008, IEEE T PATTERN ANAL, V30, P1243, DOI 10.1109/TPAMI.2007.70755
   Qin JZ, 2010, PATTERN RECOGN, V43, P1874, DOI 10.1016/j.patcog.2009.11.009
   Ren RD, 2012, IEEE T MULTIMEDIA, V14, P1652, DOI 10.1109/TMM.2012.2199971
   Rocha A, 2012, IEEE T BIO-MED ENG, V59, P2244, DOI 10.1109/TBME.2012.2201717
   Sudderth Erik., 2005, ADV NEURAL INFORM PR, V18, P1297
   Thibos L, 1989, P SOC PHOTO-OPT INS, V1989, P1148
   Ward M, 2010, HUM PERC INF P, P73
   Wei S, 2009, IEEE INT C COMP INT
   Wu L, 2010, IEEE T IMAGE PROCESS, V19, P1908, DOI 10.1109/TIP.2010.2045169
   Xu S, 2010, IEEE GEOSCI REMOTE S, V7, P366, DOI 10.1109/LGRS.2009.2035644
   Yang NC, 2008, J VIS COMMUN IMAGE R, V19, P92, DOI 10.1016/j.jvcir.2007.05.003
   Zhang SL, 2011, IEEE T IMAGE PROCESS, V20, P2664, DOI 10.1109/TIP.2011.2128333
   Zhou WG, 2012, IEEE T IMAGE PROCESS, V21, P4269, DOI 10.1109/TIP.2012.2199506
   Zhu L, 2002, ACM T INFORM SYST, V20, P224, DOI 10.1145/506309.506313
   Zhu L, 2001, IEEE INT C MULT EXP, P237
NR 41
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 16983
EP 17017
DI 10.1007/s11042-015-2970-1
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600013
DA 2024-07-18
ER

PT J
AU Lee, G
   Shin, D
   Shin, D
AF Lee, Gwanghyung
   Shin, Dongkyoo
   Shin, Dongil
TI Mouse operation on monitor by interactive analysis of intuitive hand
   motions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive NUI/NUX technologies; Hand mouse; Mouse operation; Hand
   mouse; Kinect
AB The natural user interface/experience (NUI/NUX) is used for a natural motion interface without using a device or tool such as a mouse, keyboard, pen, or marker. Up to now, typical motion recognition methods have used markers to receive coordinate input values as relative data and store them in a database. However, to recognize accurate motion, more markers are needed, and much time is required to attach the makers and process the data. In addition, because the NUI/NUX framework is developed using only basic intuition, use problems arise, which force users to learn many NUI/NUX framework usages. To compensate for this problem, in this paper, we design a multi-modal NUI/NUX framework controlled by voice, gesture motion, and facial expression simultaneously, and propose a new algorithm for mouse operations by analyzing intuitive hand gestures and mapping them on the monitor. We also implement a "dynamic mouse area," which enables people of all ages to handle the "hand mouse" operation easily and intuitively.
C1 [Lee, Gwanghyung; Shin, Dongkyoo; Shin, Dongil] Sejong Univ, Dept Comp Engn, 98 Gunja Dong, Seoul 143747, South Korea.
C3 Sejong University
RP Shin, D (corresponding author), Sejong Univ, Dept Comp Engn, 98 Gunja Dong, Seoul 143747, South Korea.
EM shindk@sejong.ac.kr
RI Shin, Dongil/AAB-3750-2021
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC (Information Technology Research Center)) support program
   [NIPA-2013-H0301-13-4007]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center)) support program (NIPA-2013-H0301-13-4007) supervised by the
   NIPA (National IT Industry Promotion Agency)"
CR [Anonymous], J CONVERG
   Bau O, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P37, DOI 10.1145/1449715.1449724
   Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503
   Chang SM, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-14
   Cho H., 2014, J CONVERGENCE, V5, P32
   Christou G, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-15
   Ghimire D, 2014, J INF PROCESS SYST, V10, P443, DOI 10.3745/JIPS.02.0004
   Goth G, 2012, COMMUN ACM, V54, P14
   I-Tsun Chiang, 2012, 2012 IEEE 4th International Conference on Digital Game and Intelligent Toy Enhanced Learning (DIGITEL 2012), P263, DOI 10.1109/DIGITEL.2012.69
   Ince I. F., 2010, INT J DIGIT CONTENT, V4, P40
   Jeon I, 2012, P 43 KIEE KOR I EL E, P18
   Kjeldsen R, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P151, DOI 10.1109/AFGR.1996.557257
   Nagi GM, 2013, J INF PROCESS SYST, V9, P173, DOI 10.3745/JIPS.2013.9.1.173
   Oh J, 2014, J CONVERG, V5, P21
   OHYA J, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P408, DOI 10.1109/VRAIS.1993.380751
   Forster CHQ, 2007, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, P641, DOI 10.1109/ISDA.2007.23
   Sánchez-Nielsen E, 2005, CAR C SECUR, P113, DOI 10.1109/CCST.2005.1594873
   Shahabi C, 2014, J INF PROCESS SYST, V10, P1, DOI 10.3745/JIPS.2014.10.1.001
   Shiratuddin M.F., 2011, Information Technology and Multimedia (ICIM), P1, DOI DOI 10.1109/ICIMU.2011.6122761
   Verma P, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-21
   Virpi R, 2011, USER EXPERIENCE WHIT
NR 21
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15261
EP 15274
DI 10.1007/s11042-014-2357-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700009
DA 2024-07-18
ER

PT J
AU Ahmad, J
   Hwang, SO
AF Ahmad, Jawad
   Hwang, Seong Oun
TI A secure image encryption scheme based on chaotic maps and affine
   transformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic maps; Cryptography; Key space; TD-ERCS map; PWLCM; Image
   encryption; Affine transformation; Security analysis; Secure
   communication
ID S-BOX; ALGORITHM; CRYPTANALYSIS; EFFICIENT; IMPROVEMENT
AB Due to the interesting nonlinear dynamic properties of chaotic maps, recently chaos-based encryption algorithms have gained much attention in cryptographic communities. However, many encryption schemes do not fulfil the minimum key space requirement, which is an essential concern in many secure data applications. In this paper, an efficient chaos-based image encryption scheme with higher key space is presented. Even with a single round of encryption, a significantly larger key space can be achieved. The proposed scheme removes correlation among image pixels via random chaotic sequences, simply by XOR and addition operations. In order to resist against numerous attacks, we apply the affine transformation to get the final ciphertext image. The security of the proposed scheme is proved through histogram, contrast, PSNR, entropy, correlation, key space, key sensitivity and differential attack analysis. Many significant properties of chaotic maps, sensitivity to initial condition and control parameters, structure and attack complexity, make the anticipated scheme very reliable, practical and robust in various secure communication applications.
C1 [Ahmad, Jawad] Hongik Univ, Grad Sch, Dept Elect & Comp Engn, Sejong, South Korea.
   [Hwang, Seong Oun] Hongik Univ, Dept Comp & Informat Commun Engn, Sejong, South Korea.
C3 Hongik University; Hongik University
RP Hwang, SO (corresponding author), Hongik Univ, Dept Comp & Informat Commun Engn, Sejong, South Korea.
EM jawad.saj@gmail.com; sohwang@hongik.ac.kr
RI Hwang, Seong Oun/AFN-1294-2022; Ali, Ahmad/ABI-1556-2020; Ahmad,
   Jamil/AAF-5499-2021; Ahmad, Jawad/AAC-3119-2020
OI Hwang, Seong Oun/0000-0003-4240-6255; Ali, Ahmad/0000-0002-5420-1743;
   Ahmad, Jamil/0000-0001-6618-6811; Ahmad, Jawad/0000-0001-6289-8248
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2014R1A1A2054174]; MSIP
   (Ministry of Science, ICT and Future Planning), Korea, under the Global
   IT Talent support program [NIPA-2014-H0905-14-1004]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (2014R1A1A2054174). This research was also supported by the
   MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   Global IT Talent support program (NIPA-2014-H0905-14-1004) supervised by
   the NIPA (National IT Industry Promotion Agency).
CR Ahmad J., 2012, International Journal of Video and Image Processing and Network Security, V12, P18
   Ahmad M, 2015, ADV INTELL SYST, V327, P481, DOI 10.1007/978-3-319-11933-5_53
   Ahmed F, 2014, WIRELESS PERS COMMUN, V77, P2771, DOI 10.1007/s11277-014-1667-5
   Akhavan A, 2015, OPT COMMUN, V350, P77, DOI 10.1016/j.optcom.2015.03.079
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Anees A, 2014, COMMUN NONLINEAR SCI, V19, P3106, DOI 10.1016/j.cnsns.2014.02.011
   [Anonymous], MULTIMEDIA TOOLS APP
   Ashtiyani M, 2008, 3 INT C INF COMM TEC, P1
   Askar S.S., 2015, MATH PROBLEMS ENG
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen J., 2014, COMMUNICATIONS NONLI
   Chen JX, 2014, J OPTICS-UK, V16, DOI 10.1088/2040-8978/16/12/125403
   El-lskandarani M, 2008, 42 ANN IEEE INT CARN, P5155
   Elashry IF, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3167847
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu-lai W, 2010, CHINESE PHYS B, V19
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   Hasler M, 1997, IEEE T CIRCUITS-I, V44, P856, DOI 10.1109/81.633874
   Hu Y, 2014, SCI WORLD J, V2014
   Hussain I, 2013, MATH COMPUT MODEL, V57, P2576, DOI 10.1016/j.mcm.2013.01.009
   Kanso A, 2015, COMMUN NONLINEAR SCI, V24, P98, DOI 10.1016/j.cnsns.2014.12.005
   Khan MK, 2014, SECUR COMMUN NETW, V7, P399, DOI 10.1002/sec.791
   Kun Z., 2012, 2012 INT C IMAGE ANA, P1
   Li CQ, 2014, NONLINEAR DYNAM, V78, P1545, DOI 10.1007/s11071-014-1533-8
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Lian SG, 2005, PHYSICA A, V351, P645, DOI 10.1016/j.physa.2005.01.001
   Liu HJ, 2013, J SYST SOFTWARE, V86, P826, DOI 10.1016/j.jss.2012.11.026
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Norouzi B, 2013, MULTIMEDIA TOOLS APP
   Pisarchik AN, 2008, PHYSICA D, V237, P2638, DOI 10.1016/j.physd.2008.03.049
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sheng LY, 2005, ACTA PHYS SIN-CH ED, V54, P4031, DOI 10.7498/aps.54.4031
   Sheng LY, 2004, ACTA PHYS SIN-CH ED, V53, P2871, DOI 10.7498/aps.53.2871
   Tang Z, 2014, MULTIMED TOOLS APPL, P1, DOI 10.1007/s11042-014-1861-1
   Tran MT, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P253, DOI 10.1109/CIS.2008.205
   Wang XY, 2015, OPT LASER ENG, V68, P126, DOI 10.1016/j.optlaseng.2014.12.025
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Yang Y-G, 2015, SCI REPORT
   Ye CH, 2015, INT J SECUR APPL, V9, P409, DOI 10.14257/ijsia.2015.9.1.39
   Zaibi G, 2014, SECUR COMMUN NETW, V7, P279, DOI 10.1002/sec.728
   Zhang K, 2015, MATH PROBLEMS ENG
   Zhang LB, 2015, MATH PROBLEMS ENG
   Zhang YS, 2014, NONLINEAR DYNAM, V78, P235, DOI 10.1007/s11071-014-1435-9
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
   Zhao JF, 2015, NONLINEAR DYNAM, V80, P1721, DOI 10.1007/s11071-015-1911-x
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 48
TC 66
Z9 66
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13951
EP 13976
DI 10.1007/s11042-015-2973-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800050
DA 2024-07-18
ER

PT J
AU Chen, YR
   Chen, LH
   Shyu, SJ
AF Chen, Ying-Ru
   Chen, Ling-Hwei
   Shyu, Shyong Jian
TI Secret image sharing with smaller shadow sizes for general access
   structures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shadow size; Secret image sharing; General access structure
ID SCHEMES
AB In the area of secret image sharing (SIS), most papers focused on the schemes for threshold or some special access structures. Regarding general access structures (GAS), few results have been found in the literature. Two SIS schemes for GAS were proposed in 2001 and 2010, both are based on qualified sets. However, one distorts the reconstructed secret image, and some extra information is needed in both schemes. Here, we propose three polynomial based SIS schemes for GAS. Considering either qualified or forbidden sets, these schemes can reconstruct the secret image perfectly without any extra information needed. Some proof and analysis on the shadow sizes of the three schemes are given to lead us to choose the one with the smallest size. In addition, we also give some comparisons with two existing schemes, and security issue is also addressed in conclusion.
C1 [Chen, Ying-Ru] Natl Chiao Tung Univ, Inst Comp Sci & Engn, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
   [Chen, Ling-Hwei] Natl Chiao Tung Univ, Dept Comp Sci, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
   [Shyu, Shyong Jian] Ming Chuan Univ, Dept Comp Sci & Informat Engn, 5 De Ming Rd, Taoyuan 333, Taiwan.
C3 National Yang Ming Chiao Tung University; National Yang Ming Chiao Tung
   University; Ming Chuan University
RP Chen, LH (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM cyrchen@gmail.com; lhchen@cc.nctu.edu.tw; sjshyu@mail.mcu.edu.tw
FU National Science Council [NSC 103-2221-E-009-121-MY2]
FX This work was supported in part by the National Science Council project
   under Grant NSC 103-2221-E-009-121-MY2.
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   BENALOH J, 1990, LECT NOTES COMPUT SC, V403, P27
   Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Chang CC, 2014, SIGNAL PROCESS, V99, P159, DOI 10.1016/j.sigpro.2013.12.022
   Guo C, 2013, JIH MSP, V4, P1
   Horng G, 2001, J INF SCI ENG, V17, P959
   Ito M., 1987, PROC IEEE GLOB TELEC, P99
   Iwamoto M, 2007, IEICE T FUND ELECTR, VE90A, P101, DOI 10.1093/ietfec/e90-a.1.101
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Tochikubo K, 2008, IEICE T FUND ELECTR, VE91A, P2860, DOI 10.1093/ietfec/e91-a.10.2860
   Tsai CS, 2001, LECT NOTES COMPUT SC, V2195, P963
   Yu-Ting Lin, 2010, 2010 8th IEEE International Conference on Industrial Informatics (INDIN 2010), P437, DOI 10.1109/INDIN.2010.5549704
NR 14
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13913
EP 13929
DI 10.1007/s11042-015-2734-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800048
DA 2024-07-18
ER

PT J
AU Jo, I
   Jung, IY
AF Jo, Insoon
   Jung, Im Y.
TI Smart learning of logo detection for mobile phone applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart image detection; Logo extraction; Image recognition; Mobile phone
   application; Augmented reality
ID AUGMENTED REALITY
AB With the advance of mobile phone cameras and broadband networks, gaining access to digital information and services via logo recognition has become of high industrial interest. The fundamental subsystem for logo recognition must be a logo database, whose images link real-world information to specific corporate entities. However, few attempts have been made to create and update such a logo database, i.e., how to automatically collect the latest logos. Moreover, the few existing methods are limited in their application and unattractive in terms of logo detection accuracy and performance overhead. In this article, we describe a practical system for automatic logo extraction. Websites are an optimal source of a huge number of up-to-date logos, and experts can easily find logos from webpages without rendering. For instance, an expert can locate elements with the term "logo" using the websites' entity names as attribute values, and then download images connected to them. Our system mimics this human behavior to automate logo extraction. Given a website, it learns its entity name and uses that name to locate elements that lead to the logo. Evaluation tests showed that this contextual reasoning significantly contributes to the performance of the system, which achieved high precision with negligible overhead.
C1 [Jo, Insoon] Samsung Elect Co Ltd, Hwaseong Si 445701, Gyeonggi Do, South Korea.
   [Jung, Im Y.] Kyungpook Natl Univ, Sch Elect Engn, Daegu 702701, South Korea.
C3 Samsung; Kyungpook National University
RP Jung, IY (corresponding author), Kyungpook Natl Univ, Sch Elect Engn, Daegu 702701, South Korea.
EM insoonjo@gmail.com; iyjung@ee.knu.ac.kr
OI Jung, Im/0000-0002-9713-1757
FU Institute for Information & communications Technology Promotion (IITP) -
   Korea government (MSIP) [10041145]
FX This work was supported by Institute for Information & communications
   Technology Promotion (IITP) grant funded by the Korea government (MSIP).
   [No. 10041145, Self-Organized Software platform (SoSp) for Welfare
   Devices].
CR Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baratis E, 2008, IEEE T KNOWL DATA EN, V20, P1195, DOI 10.1109/TKDE.2008.34
   Bruns E, 2007, IEEE MULTIMEDIA, V14, P16, DOI 10.1109/MMUL.2007.33
   Butters J, 2008, P 6 INT C LANG RES E
   Chen DM, 2009, INT SYM MIX AUGMENT, P181, DOI 10.1109/ISMAR.2009.5336472
   Chen XY, 2010, PROCEEDINGS OF SHANGHAI CONFERENCE ON MANAGEMENT OF TECHNOLOGY (MOT 2010), P1
   Choubassi ME, 2010, P 16 INT MULT MOD C, P588
   Choubassi ME, 2007, P 2007 IEEE INT C RO, P691
   Hartl A, 2011, P 16 IASTED INT C RO, P181
   Hesson A, 2008, P CAN C EL COMP ENG, P927
   Kim J, 2008, IEEE T CONSUM ELECTR, V54, P954, DOI 10.1109/TCE.2008.4637573
   Kleban J, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1077, DOI 10.1109/ICME.2008.4607625
   Nieto P, 2008, IEEE IMAGE PROC, P2548, DOI 10.1109/ICIP.2008.4712313
   Papagiannakis G, 2008, COMPUT ANIMAT VIRT W, V19, P2
   Psyllos AP, 2010, IEEE T INTELL TRANSP, V11, P322, DOI 10.1109/TITS.2010.2042714
   Ramachandran Sreeram., 2010, Web metrics: Size and number of resources
   Suh Y, 2009, IEEE T CONSUM ELECTR, V55, P2356, DOI 10.1109/TCE.2009.5373810
   Sun SK, 2011, J INF SCI ENG, V27, P545
   TAKACS G, 2008, P 1 ACM INT C MULT I, P427
   UKKONEN E, 1992, THEOR COMPUT SCI, V92, P191, DOI 10.1016/0304-3975(92)90143-4
   WebSiteOptimization.com, 2012, AV WEB PAG SIZ TRIPL
   Xia LF, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, VOLS 1-4, P1767, DOI 10.1109/ICINFA.2008.4608292
NR 22
TC 2
Z9 2
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13211
EP 13233
DI 10.1007/s11042-016-3293-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800015
DA 2024-07-18
ER

PT J
AU Liu, ZT
   Wang, JD
AF Liu, Zhengtao
   Wang, Jiandong
TI A fine-grained context-aware access control model for health care and
   life science linked data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Context-aware access control; Fine-grained; Semantic scope; Health care
   and life science linked data
AB Health Care and Life Sciences (HCLS) have long been a test-bed for the standards proposed by the W3C to build the Semantic Web. One of the challenges to HCLS Linked Data is access control. In this paper, we present a fine-grained context-aware access model for HCLS Linked Data based on Semantic Web tools. The model consists of two basic components: ontology base and access policy. Ontology base refers to a set of ontologies that include subject ontology, resource ontology, environment ontology, and action ontology. In the access policy module, we describe the access policy with eXtensible Access Control Markup Language (XACML) model, which allows users to achieve access rule reproduction by defining the semantic scope and inference rules among different entities. Results of the analysis indicate that indicates that our model expands the scopes of authorization rules for users. Inference of semantic authorization rules is also realized. These rules enable fine-grained access to data and meet the need for dynamic change of HCLS Linked Data. Finally, we show the process of authorization and present a system framework. Simulation experiments verify the acceptability of our model in protecting secured data.
C1 [Liu, Zhengtao; Wang, Jiandong] Nanjing Univ Aeronaut & Astronaut, Sch Comp & Technol, Nanjing 210012, Jiangsu, Peoples R China.
   [Liu, Zhengtao] Sanjiang Univ, Sch Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Sanjiang University
RP Liu, ZT (corresponding author), Nanjing Univ Aeronaut & Astronaut, Sch Comp & Technol, Nanjing 210012, Jiangsu, Peoples R China.; Liu, ZT (corresponding author), Sanjiang Univ, Sch Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.
EM liuzhengtaosky@163.com
CR [Anonymous], 2015, P ACM WORKSH FORM ME, DOI DOI 10.1145/2714576.2749229
   Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901
   Carminati B, 2009, SACMAT'09: PROCEEDINGS OF THE 14TH ACM SYMPOSIUM ON ACCESS CONTROL MODELS AND TECHNOLOGIES, P177, DOI 10.1145/1542207.1542237
   Che L, 2014, IEEE T SMART GRID, V5, P2517, DOI 10.1109/TSG.2014.2344024
   Choi C, 2014, J SUPERCOMPUT, V67, P711, DOI 10.1007/s11227-013-0980-1
   Costabello Luca, 2013, Semantic Web: Semantics and Big Data. Proceedings of 10th International Conference (ESWC 2013): LNCS 7882, P185
   Costabello L, 2012, LDOW 5 WWW WORKSHOP, V21, P14
   Hassanzadeh O, 2015, LECT NOTES COMPUT SC, V9367, P270, DOI 10.1007/978-3-319-25010-6_16
   Heath  T., 2011, SYNTHESIS LECT SEMAN, DOI [10.2200/S00334ED1V01Y201102WBE001, DOI 10.2200/S00334ED1V01Y201102WBE001, 10.2200/s00334ed1v01y201102wbe001]
   Hollenbach J, 2009, P WORKSHOP COLLABORA, V6644, P405
   Jiang DD, 2016, WIRELESS PERS COMMUN, V86, P901, DOI 10.1007/s11277-015-2961-6
   Kayes A. S. M., 2012, Information Security and Privacy. Proceedings 17th Australasian Conference, ACISP 2012, P442, DOI 10.1007/978-3-642-31448-3_34
   Li T., 2015, CONCURR COMPUT PRACT
   Li X, 2015, IEEE INT S CLUST CLO
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Lv Z, 2011, J NETW, V6
   Muhleisen H, 2010, P 2 WORKSH TRUST PRI
   Sacco O., 2011, P LINK DAT WEB WORKS
   Sahay R, 2014, HEALTHC ADM CONCEPTS, P177
   Shen H., 2011, International Journal of Computer Network and Information Security, V3, P18
   Su TY, 2016, COMPUT GRAPH-UK, V54, P65, DOI 10.1016/j.cag.2015.07.019
   Villata S, 2011, LECT NOTES COMPUT SC, V7046, P454
   Wang Ya-Zhe, 2009, Chinese Journal of Computers, V32, P516, DOI 10.3724/SP.J.1016.2009.00516
   Yagüe MI, 2003, 14TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P622
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Zhang Su., 2014, P 9 ACM S INFORM COM, P317, DOI DOI 10.1145/2590296.2590300
NR 26
TC 4
Z9 4
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14263
EP 14280
DI 10.1007/s11042-016-3269-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500016
DA 2024-07-18
ER

PT J
AU Mazurczyk, W
   Karas, M
   Szczypiorski, K
   Janicki, A
AF Mazurczyk, Wojciech
   Karas, Maciej
   Szczypiorski, Krzysztof
   Janicki, Artur
TI YouSkyde: information hiding for Skype video traffic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information hiding; Skype; Network steganography
AB In this paper a new information hiding method for Skype videoconference calls - YouSkyde - is introduced. A Skype traffic analysis revealed that introducing intentional losses into the Skype video traffic stream to provide the means for clandestine communication is the most favourable solution. A YouSkyde proof-of-concept implementation was carried out and its experimental evaluation is presented. The results obtained prove that the proposed method is feasible and offer a steganographic bandwidth as high as 0.93 kbps, while introducing negligible distortions into transmission quality and providing high undetectability.
C1 [Mazurczyk, Wojciech; Karas, Maciej; Szczypiorski, Krzysztof; Janicki, Artur] Warsaw Univ Technol, Fac Elect & Informat Technol, Inst Telecommun, 15-19 Nowowiejska Str, PL-00665 Warsaw, Poland.
C3 Warsaw University of Technology
RP Mazurczyk, W (corresponding author), Warsaw Univ Technol, Fac Elect & Informat Technol, Inst Telecommun, 15-19 Nowowiejska Str, PL-00665 Warsaw, Poland.
EM wmazurczyk@tele.pw.edu.pl; karas.maciek@gmail.com; ksz@tele.pw.edu.pl;
   A.Janicki@tele.pw.edu.pl
RI Szczypiorski, Krzysztof/A-9664-2012
OI Szczypiorski, Krzysztof/0000-0001-8638-8584; Janicki,
   Artur/0000-0002-9937-4402
CR [Anonymous], 2014, ISSE 2014 SECURING E, DOI 10.1007/978-3-658-06708-
   [Anonymous], 2013, NSA PRISM PROGRAM TA
   [Anonymous], 2005, TR2005536 DARTM COLL
   [Anonymous], 2003, P TEX WORKSH SEC INF
   Bonfiglio D, 2008, P IEEE INFOCOM 2008
   Bonfiglio D, 2007, ACM SIGCOMM COMP COM, V37, P37, DOI 10.1145/1282427.1282386
   Cheng R-G, 2008, P IEEE APWCS 2008 SE
   GIRLING CG, 1987, IEEE T SOFTWARE ENG, V13, P292, DOI 10.1109/TSE.1987.233153
   Goodin D, 2012, P2P SUPERNODES LINUX
   Hamdaqa M., 2011, Proceedings of the 2011 Fifth International Conference on Secure Software Integration and Reliability Improvement (SSIRI 2011), P189, DOI 10.1109/SSIRI.2011.24
   Korczynski M., 2012, IEEE International Conference on Communications (ICC 2012), P1064, DOI 10.1109/ICC.2012.6364024
   Ladha M, 2014, SKYPE BLOG SKYPES PU
   Mazurczyk W, 2014, SECUR COMMUN NETW, V7, P2602, DOI 10.1002/sec.388
   Mazurczyk W, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543587
   Mazurczyk W, 2013, INT J COMPUT COMMUN, V8, P432, DOI 10.15837/ijccc.2013.3.469
   Mazurczyk W, 2010, TELECOMMUN SYST, V45, P153, DOI 10.1007/s11235-009-9245-y
   Mercier J, 2014, SKYPE NUMEROLOGY
   Molnár S, 2011, INT J COMMUN SYST, V24, P94, DOI 10.1002/dac.1142
   Munsell P, 2013, SKYPE MESSENGER COMI
   On2 technologies, 2008, ON2 VP7 TECHN OV
   SERVETTO S, 2001, P IEEE INT S INF THE
   Timberg C, 2012, SKYPE MAKES CHATS US
   Wang XZ, 2005, LECT NOTES COMPUT SC, V3496, P81
   Worstall T., 2014, SKYPE IS NOW 40 ENTI
   Wright CV, 2008, P IEEE S SECUR PRIV, P35, DOI 10.1109/SP.2008.21
   Zielinska E, 2014, COMMUN ACM, V57, P86, DOI 10.1145/2566590.2566610
NR 26
TC 9
Z9 12
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13521
EP 13540
DI 10.1007/s11042-015-2740-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800029
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Shaheen, S
   Khannum, A
   Akram, MU
   Khan, SA
   Seo, S
   Javed, MY
AF Shaheen, Saima
   Khannum, Aasia
   Akram, M. Usman
   Khan, Shoab A.
   Seo, SangHyun
   Javed, M. Younas
TI Evaluating the significance of error checksums for wireless video
   streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia streaming; Unequal error protection; IEEE WLAN; Multimedia
   quality; Parameter optimization; Error checksum
ID TRANSMISSION; INTERNET
AB Efficient streaming of bandwidth intensive and delay sensitive multimedia contents over error prone wireless links has proven to be one of the most challenging problems of current era of digital communication. Applying unequal error protection strategies and avoiding unnecessary packet discard at various network levels yield valuable outcomes. In this article, we have proposed the idea of discriminating classified video streaming calls from the data packeting over IEEE WLAN through bit demarcation in network packet headers. Error computation at various network levels are evaluated and disabled in order to attain increased throughput characterized by the higher number of packets available for decoding, enhanced multimedia visual quality due to gap elimination (appears as a consequence of some frame loss), efficient utilization of link bandwidth with no re-transmissions and reduced delays with least error checksum computations and packet re-transmissions. Moreover, collaborative estimation of various layers parameters results in proficient selection of streaming parameters like group of picture structure, inter spacing of anchor frames, constellation coding and signal power. The proposed system will be helpful in future information and communication systems by providing reliable video streaming over wireless.
C1 [Shaheen, Saima; Akram, M. Usman; Khan, Shoab A.; Javed, M. Younas] Natl Univ Sci, Dept Comp Engn, Coll Elect, Mech Engn, Rawalpindi, Pakistan.
   [Khannum, Aasia] Forman Christian Coll, Dept Comp Sci, Lahore, Pakistan.
   [Seo, SangHyun] Elect & Telecommun Res Inst, Dept Multimedia, Daejeon, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI)
RP Akram, MU (corresponding author), Natl Univ Sci, Dept Comp Engn, Coll Elect, Mech Engn, Rawalpindi, Pakistan.
EM saima1282@yahoo.com; aasiakh@yahoo.com; usmakram@gmail.com;
   shoabak@yahoo.com; shseo75@gmail.com; myjaved@ceme.nust.edu.pk
RI Sanghyun, Seo/ADZ-4404-2022; Khanum, Aasia/AAR-4434-2021
OI Sanghyun, Seo/0000-0002-4824-3517; Khanum, Aasia/0000-0002-2522-7637
CR Abukharis S, MPEG 2 STREAMING IEE
   Ahmed T, 2005, IEEE J SEL AREA COMM, V23, P385, DOI 10.1109/JSAC.2004.839425
   Andreopoulos Y, 2006, IEEE J SEL AREA COMM, V24, P2104, DOI 10.1109/JSAC.2006.881614
   [Anonymous], 2003, P MSWIM 03 SEP
   [Anonymous], 9 INT S TEL BIHTEL S
   [Anonymous], 1998, RFC 2474
   Argyriou A, 2008, IEEE T MULTIMEDIA, V10, P691, DOI 10.1109/TMM.2008.922776
   der Schaar MV, 2005, IEEE WIREL COMMUN, V12, p[50, 58]
   Fu B, 2014, IEEE COMMUN SURV TUT, V16, P110, DOI 10.1109/SURV.2013.081313.00231
   Jain B.N., 1993, OPEN SYSTEMS INTERCO
   Johnson Sarah J, 2006, INTRO LOW DENSITY PA
   Khan S, 2006, IEEE COMMUN MAG, V44, P122, DOI 10.1109/MCOM.2006.1580942
   Knee M, 2002, MPEG VIDEO
   Lanon L-A, 1999, P IEEE ICC 99 C IEEE
   Malladi R, 2002, COMMUN ACM, V45, P144
   Misra S, 2008, IEEE COMMUN SURV TUT, V10, P18, DOI 10.1109/SURV.2008.080404
   Moid A, 2009, J COMPUT SYST NETW C, V2009
   Pejoski S, 2014, ADV MULTIMED, V2014, DOI 10.1155/2014/362196
   Peterson L. L., COMPUTER NETWORKS SY
   Wu DP, 2000, P IEEE, V88, P1855, DOI 10.1109/5.899055
   Xiao Y, 2011, IEEE SYST J, V5, P474, DOI 10.1109/JSYST.2011.2165596
   Zheng HT, 2001, IEEE T MULTIMEDIA, V3, P356, DOI 10.1109/6046.944478
   [No title captured]
NR 23
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14759
EP 14781
DI 10.1007/s11042-015-2636-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500044
DA 2024-07-18
ER

PT J
AU Swain, G
AF Swain, Gandharba
TI Adaptive pixel value differencing steganography using both vertical and
   horizontal edges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Pixel value differencing steganography; Adaptive
   data hiding; Adaptive PVD; Horizontal and vertical edges
ID DIGITAL IMAGES
AB This paper proposes two pixel value differencing (PVD) steganography techniques by considering adaptive ranges to improve the security. In the first technique, the image is partitioned into 2x2 pixel blocks in a non-overlapping fashion and scanned in raster-scan order. For every 2x2 pixel block the left-upper and bottom-right corner pixels are targetted based on their correlation with the other two pixels. Both horizontal and vertical edges are considered. In the second technique, the image is partitioned into blocks with 3x3 pixels in an overlapped fashion and scanned in raster-scan order. For a block the central pixel is targetted for embedding. Both the horizontal and vertical edges are inspected, but one of them is considered for data embedding at the target pixel. The ranges are adaptively calculated based upon the local statistics of the blocks. The first technique provides higher hiding capacity and the second technique provides higher peak signal-to-noise ratio value.
C1 [Swain, Gandharba] KL Univ, KL Coll Engn, Dept Comp Sci & Engn, Vaddeswaram 522502, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Swain, G (corresponding author), KL Univ, KL Coll Engn, Dept Comp Sci & Engn, Vaddeswaram 522502, Andhra Pradesh, India.
EM gswain1234@gmail.com
RI Swain, Gandharba/P-8692-2015
OI Swain, Gandharba/0000-0001-6586-1432
CR Balasubramanian C, 2014, MULTIMED TOOLS APPL, V73, P2223, DOI 10.1007/s11042-013-1640-4
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1431, DOI 10.1016/j.patrec.2004.05.006
   Chang KC, 2008, J MULTIMED, V3, P37, DOI DOI 10.4304/JMM.3.3.26-33
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Liao X, 2011, J VIS COMMUN IMAGE R, V22, P1, DOI 10.1016/j.jvcir.2010.08.007
   Luo WQ, 2011, MULTIMED TOOLS APPL, V52, P407, DOI 10.1007/s11042-009-0440-3
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   SWAIN G, 2014, INDIAN J SCI TECHNOL, V7, P1444
   Swain G., 2013, CSI Trans. ICT, V1, P127, DOI [10.1007/s40012-013-0015-3, DOI 10.1007/S40012-013-0015-3]
   Swain G., 2014, Int J Comput Sci Eng Tech, V5, P219
   Swain G, 2012, INT J SECUR APPL, V6, P1
   Swain G, 2013, INT J SECUR APPL, V7, P285, DOI 10.14257/ijsia.2013.7.6.29
   Swain G, 2015, INT J SIGNAL IMAGING, V8, P115, DOI 10.1504/IJSISE.2015.067052
   Swain G, 2012, COMM COM INF SC, V270, P479
   Tseng HW, 2013, J APPL MATH, DOI 10.1155/2013/189706
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Yang CH, 2010, J SYST SOFTWARE, V83, P1635, DOI 10.1016/j.jss.2010.03.081
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
NR 26
TC 62
Z9 62
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13541
EP 13556
DI 10.1007/s11042-015-2937-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800030
DA 2024-07-18
ER

PT J
AU Xiao, D
   Cai, HK
   Wang, Y
   Bai, S
AF Xiao, Di
   Cai, Hongkun
   Wang, Yong
   Bai, Sen
TI High-capacity separable data hiding in encrypted image based on
   compressive sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Image encryption; Compressive sensing; Discrete cosine
   transform
ID GOVERNMENT DOCUMENT IMAGES; COPYRIGHT PROTECTION; WATERMARKING SCHEME
AB A novel scheme for high-capacity separable data hiding in an encrypted image based on compressive sensing (CS) is presented. First, the original image is converted to the DC coefficient matrix, AC coefficient matrix and information embedding matrix by block discrete cosine transform. In the encryption phase, different encryption algorithms are applied on the DC matrix and the AC coefficient matrix, respectively. In the data hiding phase, the secret data is embedded in the reserved location of the encrypted image. After compressive sensing, the encrypted image with embedded data is generated. For the receiver, the way to obtain image content or/and additional data is separable according to the keys he owns. Experimental results show that the proposed method has the merits of high-capacity, anti-packet loss and cipher text compressibility.
C1 [Xiao, Di; Cai, Hongkun] Chongqing Univ, Coll Comp Sci, Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.
   [Wang, Yong] Chongqing Univ Posts & Telecommun, Key Lab Elect Commerce & Logist Chongqing, Chongqing 400065, Peoples R China.
   [Bai, Sen] Chongqing Commun Inst, Dept Informat Engn, Chongqing 400035, Peoples R China.
C3 Chongqing University; Chongqing University of Posts & Telecommunications
RP Xiao, D (corresponding author), Chongqing Univ, Coll Comp Sci, Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.
EM xiaodi_cqu@hotmail.com
OI Wang, Yong/0000-0002-5247-043X
FU National Natural Science Foundation of China [61173178, 61272043,
   61302161, 61472464, 61502399, 61572089]; Natural Science Foundation of
   Chongqing Science and Technology Commission [cstc2012jjA40017,
   cstc2013jcyjA40017, cstc2013jjB40009]; open research fund of Chongqing
   Key Laboratory of Emergency Communications [CQKLEC, 20140504];
   Fundamental Research Funds for the Central Universities
   [106112013CDJZR180005, 106112014CDJZR185501]
FX The work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61173178, 61272043, 61302161, 61472464, 61502399,
   61572089), the Natural Science Foundation of Chongqing Science and
   Technology Commission (Grant Nos. cstc2012jjA40017, cstc2013jcyjA40017,
   cstc2013jjB40009), the open research fund of Chongqing Key Laboratory of
   Emergency Communications (Grant No. CQKLEC, 20140504) and Project Nos.
   106112013CDJZR180005, 106112014CDJZR185501 supported by the Fundamental
   Research Funds for the Central Universities.
CR Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chen RJ, 2015, INT J AD HOC UBIQ CO, V18, P54, DOI 10.1504/IJAHUC.2015.067788
   Gao ZR, 2013, J VIS COMMUN IMAGE R, V24, P885, DOI 10.1016/j.jvcir.2013.06.006
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Horng SJ, 2015, INFORM SCIENCES, V317, P48, DOI 10.1016/j.ins.2015.04.033
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P2469, DOI 10.1007/s11042-013-1561-2
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Khan MK, 2011, MULTIMED TOOLS APPL, V52, P257, DOI 10.1007/s11042-011-0741-1
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Xiao D, 2014, ELECTRON LETT, V50, P598, DOI 10.1049/el.2013.3806
   Xinpeng Zhang, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P222, DOI 10.1109/IIHMSP.2011.12
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
NR 21
TC 7
Z9 7
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13779
EP 13789
DI 10.1007/s11042-015-2922-9
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800041
DA 2024-07-18
ER

PT J
AU Ahmad, J
   Sajjad, M
   Rho, S
   Baik, SW
AF Ahmad, Jamil
   Sajjad, Muhammad
   Rho, Seungmin
   Baik, Sung Wook
TI Multi-scale local structure patterns histogram for describing visual
   contents in social image retrieval systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based retrieval; Social images; Local structure patterns;
   Multi-scale; Feature histogram
ID TEXTURE CLASSIFICATION; COLOR; DESCRIPTOR; REPRESENTATION; WAVELET;
   MODEL
AB Content based image retrieval systems rely heavily on the set of features extracted from images. Effective image representation emerges as a crucial step in such systems. A key challenge in visual content representation is to reduce the so called 'semantic gap'. It is the inability of existing methods to describe contents in a human-oriented way. Content representation methods inspired by the human vision system have shown promising results in image retrieval. Considerable work has been carried out during the past two decades for developing methods to extract descriptors inspired by the human vision system and attempt to retrieve visual contents efficiently according to the user needs, thereby reducing the semantic gap. Despite the extensive research being conducted in this area, limitations in current image retrieval systems still exist. This paper presents a descriptor for personalized social image collections which utilizes the local structure patterns in salient edge maps of images at multiple scales. The human visual system at the basic level is sensitive to edges, corners, intersections, and other such intensity variations in images generating local structure patterns. Analyzing these patterns at multiple scales allow the most salient fine-grained and coarse-grained features to be captured. The features are accumulated in a local structure patterns histogram to index images allowing flexible querying of visual contents. The retrieval results show that the proposed descriptor ranks well among similar state-of-the-art methods for large social image collections.
C1 [Ahmad, Jamil; Baik, Sung Wook] Sejong Univ, Coll Elect & Informat Engn, Seoul, South Korea.
   [Sajjad, Muhammad] Islamia Coll, Dept Comp Sci, Peshawar, Pakistan.
   [Rho, Seungmin] Sungkyul Univ, Dept Multimedia, Anyang, South Korea.
C3 Sejong University; University of Peshawar; Sungkyul University
RP Baik, SW (corresponding author), Sejong Univ, Coll Elect & Informat Engn, Seoul, South Korea.
EM jamilahmad@sju.ac.kr; muhammad.sajjad@icp.edu.pk; smrho@sungkyul.edu;
   sbaik@sejong.ac.kr
RI Baik, Sung Wook/AAR-8236-2020; Ahmad, Jamil/H-6264-2019; Sajjad,
   Muhammad/L-5269-2016; Rho, Seungmin/HTP-6683-2023
OI Ahmad, Jamil/0000-0001-8407-5971; Sajjad, Muhammad/0000-0001-5646-0338;
   Baik, Sung Wook/0000-0002-6678-7788
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2013R1A1A2012904]
FX This research is supported by the Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (2013R1A1A2012904).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], P 4 ACM INT C MULT C
   [Anonymous], NEURAL MODEL EARLY V
   [Anonymous], 2008, PATTERN RECOGNIT
   [Anonymous], WORLD APPL SCI J
   [Anonymous], 18 IEEE INT C NETW B
   [Anonymous], HAMMING EMBEDDING WE
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Emerson CW, 1999, PHOTOGRAMM ENG REM S, V65, P51
   Felzenszwalb P., 2014, Advances in Neural Information Processing Systems 27, P82
   Han J, 2002, IEEE T IMAGE PROCESS, V11, P944, DOI 10.1109/TIP.2002.801585
   Hansen T, 2004, NEURAL COMPUT, V16, P1013, DOI 10.1162/089976604773135087
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Kasutani E, 2001, IEEE IMAGE PROC, P674, DOI 10.1109/ICIP.2001.959135
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Lin RJ, 2014, J VISION, V14, DOI 10.1167/14.9.1
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Lu GJ, 1999, CONCUR SYST ENGN SER, V56, P36
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Messing DS, 2001, IEEE IMAGE PROC, P670, DOI 10.1109/ICIP.2001.959134
   Mu Y., 2008, IEEE C COMPUTER VISI, P1
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007
   Ortega M, 1998, IEEE T KNOWL DATA EN, V10, P905, DOI 10.1109/69.738357
   Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983
   Rahimi M, 2015, SIGNAL IMAGE VIDEO P, V9, P691, DOI 10.1007/s11760-013-0506-6
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Subrahmanyam M, 2013, COMPUT ELECTR ENG, V39, P762, DOI 10.1016/j.compeleceng.2012.11.023
   Subrahmanyam M, 2012, EXPERT SYST APPL, V39, P5104, DOI 10.1016/j.eswa.2011.11.029
   Takala V, 2005, LECT NOTES COMPUT SC, V3540, P882
   Terzic K, 2015, NEUROCOMPUTING, V150, P227, DOI 10.1016/j.neucom.2014.09.054
   van Ginneken B, 2003, PATTERN RECOGN, V36, P899, DOI 10.1016/S0031-3203(02)00118-8
   Vinje WE, 2000, SCIENCE, V287, P1273, DOI 10.1126/science.287.5456.1273
   Vipparthi SK, 2015, OPTIK, V126, P1467, DOI 10.1016/j.ijleo.2015.04.018
   Vipparthi SK, 2014, EXPERT SYST APPL, V41, P8016, DOI 10.1016/j.eswa.2014.07.001
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Yao CH, 2003, PATTERN RECOGN, V36, P913, DOI 10.1016/S0031-3203(02)00124-3
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang JG, 2002, PATTERN RECOGN, V35, P735, DOI 10.1016/S0031-3203(01)00074-7
NR 44
TC 86
Z9 87
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12669
EP 12692
DI 10.1007/s11042-016-3436-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700022
DA 2024-07-18
ER

PT J
AU Galloso, I
   Palacios, JF
   Feijóo, C
   Santamaría, A
AF Galloso, Iris
   Palacios, Juan F.
   Feijoo, Claudio
   Santamaria, Asuncion
TI On the influence of individual characteristics and personality traits on
   the user experience with multi-sensorial media: an experimental insight
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Presence; Quality of Experience; Multi-sensorial media; Personal
   characteristics; Personality traits
ID IMMERSIVE VIRTUAL ENVIRONMENTS; MPEG-V STANDARD; PRESENCE QUESTIONNAIRE;
   SPATIAL PRESENCE; QUALITY MODEL; ODOR MEMORY; ENJOYMENT; REALITY;
   IMAGES; INVENTORY
AB Recent studies encourage the development of sensorially-enriched media to enhance the user experience by stimulating senses other than sight and hearing. Sensory effects as odor, wind, vibration and light effects, as well as an enhanced audio quality, have been found to favour media enjoyment and to have a positive influence on the sense of Presence and on the perceived quality, relevance and reality of a multimedia experience. In particular, sports is among the genres that could benefit the most from these solutions. Several works have demonstrated also the technical feasibility of implementing and deploying end-to-end solutions integrating sensory effects into a legacy system. Thus, multi-sensorial media emerges as a mean to deliver a new form of immersive experiences to the mass market in a non-disruptive manner. However, many questions remain concerning issues as the sensory effects that can better complement a given audiovisual content or the best way in which to integrate and combine them to enhance the user experience of a target audience segment. The work presented in this paper aims to gain insight into the impact of binaural audio and sensory (light and olfactory) effects on the sports media experience, both at the overall level (average effect) and as a function of users' characteristics (heterogeneous effects). To this aim, we conducted an experimental study exploring the influence of these immersive elements on the quality and Presence dimensions of the media experience. Along the quality dimension, we look for possible variations on the quality scores assigned to the overall media experience and to the media components content, image, audio and sensory effects. The potential impact on Presence is analyzed in terms of Spatial Presence and Engagement. The users' characteristics considered encompass specific personal affective, cognitive and behavioral attributes. At the overall level we found that participants preferred binaural audio over standard stereo audio and that the presence of sensory effects increased significantly the level of Spatial Presence. Several heterogeneous effects were also revealed as a result of our experimental manipulations. Whereas binaural audio was found to have a generalized impact on the majority of the quality and Presence measures considered, the effects of sensory effects concentrate mainly on the Presence dimension. Personal characteristics explained most of the variation in the dependent variables, being individuals' preferences in relation to the content, knowledge of involved technologies, tendency to emotional involvement and conscientiousness among the user variables with the most generalized influence. In particular, the former two features seem to present a conflict in the allocation of attentional resources towards the media content versus the technical features of the system, respectively. Additionally, football fans' experience seems to be modulated by emotional processes whereas for not fans cognitive processes -and in particular those related to quality judgment- prevail.
C1 [Galloso, Iris; Palacios, Juan F.; Feijoo, Claudio; Santamaria, Asuncion] Univ Politecn Madrid, Res Ctr Smart Bldg & Energy Efficiency CeDInt, CeDInt UPM, Campus Montegancedo, Madrid 28223, Spain.
C3 Universidad Politecnica de Madrid; Centro de Domotica Integral (CeDInt)
RP Galloso, I (corresponding author), Univ Politecn Madrid, Res Ctr Smart Bldg & Energy Efficiency CeDInt, CeDInt UPM, Campus Montegancedo, Madrid 28223, Spain.
EM iris@cedint.upm.es; Jpalacios@cedint.upm.es; Cfeijoo@cedint.upm.es;
   asun@cedint.upm.es
RI Santamaria, Asuncion/N-7240-2019; Feijoo, Claudio/AAR-7878-2020
OI Santamaria, Asuncion/0000-0002-4908-882X; Feijoo,
   Claudio/0000-0002-9499-7790
FU Spanish Ministry of Industry Tourism and Commerce [TSI-020302-2010-61]
FX The work presented in this manuscript was developed partially within the
   ImmersiveTV project. The authors would like to thank the Spanish
   Ministry of Industry Tourism and Commerce for its support through the
   funded project TSI-020302-2010-61.
CR Alsina-Jurnet I, 2010, INT J HUM-COMPUT ST, V68, P788, DOI 10.1016/j.ijhcs.2010.07.001
   [Anonymous], 2013, 230053 ISOIEC, P104
   [Anonymous], 1995, Psychology & Marketing
   [Anonymous], 2011, P IWSDS WORKSH PAR I, DOI DOI 10.1007/978-1-4614-1335-6_19
   [Anonymous], 2001, MASS COMMUN SOC, DOI DOI 10.1207/S15327825MCS0403_01
   [Anonymous], 1992, SENSATION PERCEPTION
   Banos R, 1999, Cyberpsychol Behav, V2, P143, DOI 10.1089/cpb.1999.2.143
   BECK AT, 1961, ARCH GEN PSYCHIAT, V4, P561, DOI 10.1001/archpsyc.1961.01710120031004
   Beerends JG, 1999, J AUDIO ENG SOC, V47, P355
   Benet-Martinez V, 1998, J PERS SOC PSYCHOL, V75, P729, DOI 10.1037/0022-3514.75.3.729
   Bey C, 2002, PERCEPT PSYCHOPHYS, V64, P844, DOI 10.3758/BF03194750
   Bleumers L, 2011, ISPR 2011 INT SOC PR
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Box G., 1987, Empirical Model-Building and Response Surfaces, DOI DOI 10.1080/00401706.1988.10488371
   Box GE., 2005, Statistics for Experimenters: Design, Innovation, and Discovery, V2nd ed.
   Bracken C, 2011, P INT SOC PRES
   Chandrasekaran C, 2011, NAT NEUROSCI, V14, P675, DOI 10.1038/nn.2843
   Coen MichaelH., 2001, Proceedings of the 17th International Joint Conference on Artificial Intelligence - Volume 2. IJCAI'01, P1417
   Cui L. C., 2003, Proceedings of the SPIE - The International Society for Optical Engineering, V5294, P132, DOI 10.1117/12.525845
   Curran T, 2009, PSYCHON B REV, V16, P390, DOI 10.3758/PBR.16.2.390
   Darken R P, 1999, Cyberpsychol Behav, V2, P337, DOI 10.1089/cpb.1999.2.337
   de Kort YAW, 2003, PRESENCE-TELEOP VIRT, V12, P360, DOI 10.1162/105474603322391604
   Decock J, 2011, ISPR 2011 INT SOC PR
   Eagly A.H., 1998, HDB SOCIAL PSYCHOL, V1, P269
   Emoto M, 2004, DISPLAYS, V25, P67, DOI 10.1016/j.displa.2004.07.001
   Galloso I., 2015, NOVEL 3D MEDIA TECHN, P9, DOI [10.1007/978-1-4939-2026-6_2, DOI 10.1007/978-1-4939-2026-6_2]
   Ghinea G, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2071396.2071398
   Hands DS, 2005, ELECTRON LETT, V41, P408, DOI 10.1049/el:20058339
   Hands DS, 2004, IEEE T MULTIMEDIA, V6, P806, DOI 10.1109/TMM.2004.837233
   Hasebe H, 1996, ERGONOMICS, V39, P1330, DOI 10.1080/00140139608964553
   Hendrix C., 1995, Proceedings. Virtual Reality Annual International Symposium '95 (Cat. No.95CH35761), P74, DOI 10.1109/VRAIS.1995.512482
   Herz RS, 1996, PSYCHON B REV, V3, P300, DOI 10.3758/BF03210754
   Hogg M.A. Vaughan., 2005, SOC PSYCHOL-GERMANY, V4th
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   Jennings JR, 2002, PSYCHOPHYSIOLOGY, V39, P496, DOI 10.1017/S0048577202394034
   John O.P., 1991, BIG 5 INVENTORY VERS
   John O. P., 2008, Handbook of Personality: Theory and Research, P114, DOI DOI 10.1016/S0191-8869(97)81000-8
   John O. P., 1999, BIG 5 TRAIT TAXONOMY
   Jumisko-Pyykko S, 2011, USER CENTERED QUALIT
   Kim J, 2013, SIGNAL PROCESS-IMAGE, V28, P151, DOI 10.1016/j.image.2012.10.010
   Knoche H., 2005, 13th Annual ACM International Conference on Multimedia, P829, DOI 10.1145/1101149.1101331
   Laarni J., 2004, P 7 ANN INT WORKSHOP, P88
   LaPiere RT, 1934, SOC FORCES, V13, P230, DOI 10.2307/2570339
   Le Callet Patrick, 2012, COST Action IC 1003) 3
   Lee S, 2008, INTERACT COMPUT, V20, P491, DOI 10.1016/j.intcom.2008.07.003
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McLeod S, 2014, ATTITUDES BEHAV
   Murray CD, 2007, COMPUT HUM BEHAV, V23, P1347, DOI 10.1016/j.chb.2004.12.010
   Murray Niall., 2013, Proceedings of the 4th ACM Multimedia Systems Conference, MMSys'13, P162, DOI [https://doi.org/10.1145/2483977.2483999, DOI 10.1145/2483977.2483999]
   Nabi RL, 2004, COMMUN THEOR, V14, P288, DOI 10.1093/ct/14.4.288
   Neisser U., 1976, COGNITION REALITY PR
   Novak TP, 2000, MARKET SCI, V19, P22, DOI 10.1287/mksc.19.1.22.15184
   Obrist M, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2843, DOI 10.1145/2556288.2557008
   Luque FP, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2617992
   Rainer B, 2012, INT WORK QUAL MULTIM, P278, DOI 10.1109/QoMEX.2012.6263842
   Raney AA, 2002, J COMMUN, V52, P402, DOI 10.1111/j.1460-2466.2002.tb02552.x
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   ROCK I, 1964, SCIENCE, V143, P594, DOI 10.1126/science.143.3606.594
   Rose CL, 2002, EUR J PERSONALITY, V16, P185, DOI 10.1002/per.451
   Royston J.P., 1989, Journal of Computation and Simulation, V31, P237, DOI DOI 10.1080/00949658908811146
   Ruyter B.D., 2004, P WORKING C ADV VISU, P203, DOI DOI 10.1145/989863.989897
   Sacau A., 2005, 8 INT WORKSHOP PRESE, P143
   Sacau A, 2008, COMPUT HUM BEHAV, V24, P2255, DOI 10.1016/j.chb.2007.11.001
   Sas C, 2003, PRESENCE-TELEOP VIRT, V12, P523, DOI 10.1162/105474603322761315
   Scheier CR, 1999, INVEST OPHTH VIS SCI, V40, pS792
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Sherry JL, 2004, COMMUN THEOR, V14, P328, DOI 10.1093/ct/14.4.328
   Shimojo S, 2001, CURR OPIN NEUROBIOL, V11, P505, DOI 10.1016/S0959-4388(00)00241-5
   Skalski P, 2010, PSYCHNOLOGY J, V8, P67
   Skalski P, 2011, NEW MEDIA SOC, V13, P224, DOI 10.1177/1461444810370949
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater MD, 2003, J COMMUN, V53, P105, DOI 10.1111/j.1460-2466.2003.tb03008.x
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Sowden PT, 2002, VISION RES, V42, P1249, DOI 10.1016/S0042-6989(02)00019-6
   Sowden PT, 2000, J EXP PSYCHOL HUMAN, V26, P379, DOI 10.1037/0096-1523.26.1.379
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Suzuki Y, 2004, JPN J OPHTHALMOL, V48, P1, DOI 10.1007/s10384-003-0001-7
   Sylaiou S, 2010, INT J HUM-COMPUT ST, V68, P243, DOI 10.1016/j.ijhcs.2009.11.002
   Takatalo J, 2008, COMPUT HUM BEHAV, V24, P1, DOI 10.1016/j.chb.2006.11.003
   Tamborini R, 2010, J COMMUN, V60, P758, DOI 10.1111/j.1460-2466.2010.01513.x
   Ukai K, 2008, DISPLAYS, V29, P106, DOI 10.1016/j.displa.2007.09.004
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Västfjäll D, 2003, CYBERPSYCHOL BEHAV, V6, P181, DOI 10.1089/109493103321640374
   Visser PS, 2006, ADV EXP SOC PSYCHOL, V38, P1, DOI 10.1016/S0065-2601(06)38001-X
   Vorderer P, 2004, COMMUN THEOR, V14, P388, DOI 10.1093/ct/14.4.388
   Waltl Markus, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P124, DOI 10.1109/QOMEX.2010.5517704
   Waltl M., 2010, P 11 INT WORKSH IM A, P1
   Waltl M, 2013, SIGNAL PROCESS-IMAGE, V28, P136, DOI 10.1016/j.image.2012.10.009
   Weibel D, 2010, CYBERPSYCH BEH SOC N, V13, P251, DOI 10.1089/cyber.2009.0171
   WELCH RB, 1980, PSYCHOL BULL, V88, P638, DOI 10.1037/0033-2909.88.3.638
   Werner S, 2000, VIS COGN, V7, P163, DOI 10.1080/135062800394748
   Willander J, 2006, PSYCHON B REV, V13, P240, DOI 10.3758/BF03193837
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wrzesniewski A, 1999, CHEM SENSES, V24, P713, DOI 10.1093/chemse/24.6.713
   Yoon K, 2013, SIGNAL PROCESS-IMAGE, V28, P127, DOI 10.1016/j.image.2012.10.008
   Zillmann Dolf., 2000, MEDIA ENTERTAINMENT
NR 102
TC 8
Z9 9
U1 2
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12365
EP 12408
DI 10.1007/s11042-016-3360-z
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700006
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Jiang, XD
   Yu, H
   Lu, Y
   Liu, HH
AF Jiang, Xiaodong
   Yu, Hui
   Lu, Yang
   Liu, Honghai
TI A fusion method for robust face tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fusion algorithm; Human face tracking; Compressive tracking; Supervised
   descend method
ID REPRESENTATION; SEQUENCES
AB Face tracking often encounters drifting problems, especially when a significant face appearance variation occurs. Many trackers suffer from the difficulty of facial feature extraction during a wide range of face turning, occlusion, and even invisibleness. In this paper, we propose a novel and efficient fusion strategy for robust face tracking. A Supervised Descent Method (SDM) and a Compressive Tracking method (CT) are employed at the same time. SDM is used to correct drifting errors of CT continuously during frontal face tracking. However, when the face orientation changes to the angle orthogonal to the view line, it results in tracking failure for the SDM method. CT is then adopted to keep the face region being tracked until SDM detects and tracks the face again. In the experiments, we test the proposed method for real-time tracking using several challenging sequences from recent literatures. The fusion strategy has achieved encouraging performance in terms of both efficiency and reliability.
C1 [Jiang, Xiaodong] Chinese Acad Sci, Changchun Inst Opt Fine Mech & Phys, Dong Nanhu Rd 3888, Changchun 130033, Jilin, Peoples R China.
   [Yu, Hui] Univ Portsmouth, Portsmouth, Hants, England.
   [Liu, Honghai] Univ Portsmouth, Sch Comp, Portsmouth, Hants, England.
   [Liu, Honghai] Univ Portsmouth, Intelligent Syst & Biomed Robot Grp ISR, Portsmouth, Hants, England.
   [Lu, Yang] Heilongjiang Bayi Agr Univ, Daqing, Heilongjiang, Peoples R China.
C3 Chinese Academy of Sciences; Changchun Institute of Optics, Fine
   Mechanics & Physics, CAS; University of Portsmouth; University of
   Portsmouth; University of Portsmouth; Heilongjiang Bayi Agricultural
   University
RP Jiang, XD (corresponding author), Chinese Acad Sci, Changchun Inst Opt Fine Mech & Phys, Dong Nanhu Rd 3888, Changchun 130033, Jilin, Peoples R China.
EM xiaodong12jiang@163.com; hui.yu@port.ac.uk; luyanga@sina.com;
   honghai.Liu@port.ac.uk
RI Lu, Yang/B-3053-2016; Yu, Hui/G-1115-2018
OI Lu, Yang/0000-0001-9887-7078; Yu, Hui/0000-0002-7655-9228; Liu,
   Honghai/0000-0002-2880-4698
FU State Scholarship Fund of China; Natural Science Foundation of
   Heilongjiang Province of China [F201428]; 12th Five-Year-Plan in Key
   Science and Technology Research of agricultural bureau in Heilongjiang
   province of China [HNK125B-04-03]
FX This work is partially supported by the State Scholarship Fund of China.
   Y. Lu is supported by the Natural Science Foundation of Heilongjiang
   Province of China under Grant F201428 and the 12th Five-Year-Plan in Key
   Science and Technology Research of agricultural bureau in Heilongjiang
   province of China under Grant HNK125B-04-03.
CR [Anonymous], 2003, TR200396 MITS EL RES
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Demirkus M, 2014, MULTIMED TOOLS APPL, V70, P495, DOI 10.1007/s11042-012-1352-1
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hu CL, 2014, MULTIMED TOOLS APPL, V73, P1863, DOI 10.1007/s11042-013-1676-5
   Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011
   Kaneko T, 2002, INT C PATT RECOG, P1, DOI 10.1109/ICPR.2002.1048221
   Li HX, 2011, PROC CVPR IEEE, P1305, DOI 10.1109/CVPR.2011.5995483
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Xu R, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P692, DOI 10.1109/ACPR.2013.90
   Yu H, 2014, IEEE T HUM-MACH SYST, V44, P386, DOI 10.1109/THMS.2014.2313912
   Zeisl B, 2010, PROC CVPR IEEE, P1879, DOI 10.1109/CVPR.2010.5539860
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34
NR 21
TC 7
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11801
EP 11813
DI 10.1007/s11042-015-2659-5
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200012
DA 2024-07-18
ER

PT J
AU Luo, XF
   Liu, YH
   Xu, Z
   Li, Q
AF Luo, Xiangfeng
   Liu, Yunhuai
   Xu, Zheng
   Li, Qing
TI Guest Editorial: Multimedia Data Sensing and Analyzing of Surveillance
   Systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
C1 [Luo, Xiangfeng] Shanghai Univ, Shanghai, Peoples R China.
   [Liu, Yunhuai; Xu, Zheng] Minist Publ Secur, Res Inst 3, Shanghai, Peoples R China.
   [Li, Qing] City Univ Hong Kong, Kowloon, Hong Kong, Peoples R China.
C3 Shanghai University; Ministry of Public Security (China); City
   University of Hong Kong
RP Luo, XF (corresponding author), Shanghai Univ, Shanghai, Peoples R China.
EM luoxf303@163.com
CR Changyuan W, MULTIMED TOOLS APPL, DOI [10.1007/s11042-016-3283-8, DOI 10.1007/S11042-016-3283-8]
   Fan C, MULTIMED TOOLS APPL, DOI [10.1007/s11042-015-3004-8, DOI 10.1007/S11042-015-3004-8]
   Fan D, MULTIMED TOOLS APPL, DOI [10.1007/s11042-016-3459-2, DOI 10.1007/S11042-016-3459-2]
   Lei J., 2016, MULTIMEDIA TOOLS APP, V75
   Liu C, MULTIMED TOOLS APPL, DOI [10.1007/s11042-016-3494-z, DOI 10.1007/S11042-016-3494-Z]
   Shi Z, MULTIMED TOOLS APPL, DOI [10.1007/s11042-016-3421-3, DOI 10.1007/S11042-016-3421-3]
   Suo A, MULTIMED TOOLS APPL, DOI [10.1007/s11042-016-3334-1, DOI 10.1007/S11042-016-3334-1]
   Wang H, MULTIMED TOOLS APPL, DOI [10.1007/s11042-016-3280-y, DOI 10.1007/S11042-016-3280-Y]
   Wu S, MULTIMED TOOLS APPL, DOI [10.1007/s11042-016-3320-7, DOI 10.1007/S11042-016-3320-7]
   Xu Z, MULTIMED TOOLS APPL, DOI [10.1007/s11042-015-3112-5, DOI 10.1007/S11042-015-3112-5]
   Yu J, MULTIMED TOOLS APPL, DOI [10.1007/s11042-016-3368-4, DOI 10.1007/S11042-016-3368-4]
   Zhai B, MULTIMED TOOLS APPL, DOI [10.1007/s11042-015-3183-3, DOI 10.1007/S11042-015-3183-3]
   Zhang Y, MULTIMED TOOLS APPL, DOI [10.1007/s11042-015-3193-1, DOI 10.1007/S11042-015-3193-1]
NR 13
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11995
EP 11997
DI 10.1007/s11042-016-3804-5
PG 3
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200023
OA Bronze
DA 2024-07-18
ER

PT J
AU Seo, S
   Kang, D
AF Seo, Sanghyun
   Kang, Dongwann
TI A photomosaic image generation method using photo annotation in a social
   network environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photomosaic; Social networks; Non-photorealistic rendering
AB With the growing use of social networking services, various applications have been developed to utilize their vast capabilities. Photomosaic techniques, which combine many images to create a new rendering of an input image, can benefit from the capabilities of social networks. In this study, we propose a method that generates a photomosaic image by considering social network context. Our algorithm creates a photomosaic that incorporates photos posted by other users in the users network . We enable the matching function to easily select photos from the albums of users who are connected to the owner of the input image, by computing the closeness of those connections. Moreover, our technique allows the photos in the albums of friends who are annotated in the source image to be matched more effectively.
C1 [Seo, Sanghyun] ETRI, Daejon, South Korea.
   [Kang, Dongwann] Bournemouth Univ, Sch Design Engn & Comp DEC, Bournemouth, Dorset, England.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Bournemouth University
RP Kang, D (corresponding author), Bournemouth Univ, Sch Design Engn & Comp DEC, Bournemouth, Dorset, England.
EM dkang@bounremouth.ac.uk
RI Sanghyun, Seo/ADZ-4404-2022
OI Sanghyun, Seo/0000-0002-4824-3517
FU Ministry of Culture, Sports and Tourism (MCST); Korea Creative Content
   Agency (KOCCA) in the Culture Technology (CT) and Research Development
   Program; National Research Foundation of Korea (NRF) - Ministry of
   Education, Science and Technology [NRF-2013R1A1A2061611]
FX This work was supported by Ministry of Culture, Sports and Tourism
   (MCST) and Korea Creative Content Agency (KOCCA) in the Culture
   Technology (CT) and Research Development Program 2015 and Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   funded by the Ministry of Education, Science and Technology
   (NRF-2013R1A1A2061611).
CR Allison W., 2002, P 2 INT S NONPHOTORE, P21
   Blasi Gd, 2005, P IASTED VIIP2005
   Blasi Gd, 2005, P ACM WSCG2005
   Finkelstein A., 1998, Electronic Publishing, Artistic Imaging, and Digital Typography. 7th International Conference on Electronic Publishing, EP'98, Held Jointly with the 4th International Conference on Raster Imaging and Digital Typography, RIDT'98 Proceedings, P11, DOI 10.1007/BFb0053259
   Hausner A, 2001, COMP GRAPH, P573, DOI 10.1145/383259.383327
   Kang D, 2013, MULTIMED TOOLS APPL, V63, P145, DOI 10.1007/s11042-012-1065-5
   Kang D, 2012, COMPUT ANIMAT VIRT W, V23, P191, DOI 10.1002/cav.1437
   Kang D, 2011, IEICE T INF SYST, VE94D, P2036, DOI 10.1587/transinf.E94.D.2036
   Kim J, 2002, ACM T GRAPHIC, V21, P657
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Orchard J., 2008, P 6 INT S NONPH AN R, P79, DOI DOI 10.1145/1377980.1377997
   Park JW, 2006, LECT NOTES COMPUTER, V4035
   Silvers R, 1997, R SILVERS INVENTOR P
   Silvers R., 1997, Photomosaics
   Tran N, 1999, P 1999 ACM S APPL CO, P105, DOI [10.1145/298151.298213, DOI 10.1145/298151.298213]
NR 15
TC 10
Z9 11
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12831
EP 12841
DI 10.1007/s11042-015-2867-z
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700031
DA 2024-07-18
ER

PT J
AU Zou, FH
   Liu, Y
   Wang, H
   Song, JK
   Shao, J
   Zhou, K
   Zheng, S
AF Zou, Fuhao
   Liu, Yu
   Wang, Hua
   Song, Jingkuan
   Shao, Jie
   Zhou, Ke
   Zheng, Sheng
TI Multi-view multi-label learning for image annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image Annotation; Ensemble learning; Multi-view learning; Multi-label
   learning
AB Image annotation is posed as multi-class classification problem. Pursuing higher accuracy is a permanent but not stale challenge in the field of image annotation. To further improve the accuracy of image annotation, we propose a multi-view multi-label (abbreviated by MVML) learning algorithm, in which we take multiple feature (i.e., view) and ensemble learning into account simultaneously. By doing so, we make full use of the complementarity among the views and the base learners of ensemble learning, leading to higher accuracy of image annotation. With respect to the different distribution of positive and negative training examples, we propose two versions of MVML: the Boosting and Bagging versions of MVML. The former is suitable for learning over balanced examples while the latter applies to the opposite scenario. Besides, the weights of base learner is evaluated on validation data instead of training data, which will improve the generalization ability of the final ensemble classifiers. The experimental results have shown that the MVML is superior to the ensemble SVM of single view.
C1 [Zou, Fuhao] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Liu, Yu; Wang, Hua; Zhou, Ke; Zheng, Sheng] Huazhong Univ Sci & Technol, Wuhan Natl Lab Optoelect, Wuhan 430074, Peoples R China.
   [Song, Jingkuan] Univ Trento, Dept Informat Engn & Comp Sci, I-38100 Trento, Italy.
   [Shao, Jie] Univ Elect Sci & Technol China, Sch Comp Sci & Technol, Wuhan 610054, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology; University of Trento; University of Electronic
   Science & Technology of China
RP Liu, Y (corresponding author), Huazhong Univ Sci & Technol, Wuhan Natl Lab Optoelect, Wuhan 430074, Peoples R China.
EM lightyear416@gmail.com
OI Liu, Yu/0000-0002-1964-9278
FU National Basic Research Program (973 Program) of China [2011CB302305];
   National Natural Science Foundation of China [61232004]
FX This work is supported in part by the National Basic Research Program
   (973 Program) of China under Grant No. 2011CB302305, the National
   Natural Science Foundation of China under Grant No. 61232004. The
   authors appreciate the valuable suggestions from the anonymous reviewers
   and the Editors.
CR Alham N. K., 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P1581, DOI 10.1109/FSKD.2012.6234316
   Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dietterich T.G., 2002, The Handbook of the Brain Theory and Neural Networks, V2, P405, DOI DOI 10.1007/978-1-4419-9326-7_1
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Freund Y., 1995, COMPUTATIONAL LEARNI
   Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285
   Gönen M, 2011, J MACH LEARN RES, V12, P2211
   Haykin S, 2004, Neural Networks, V2, P41, DOI DOI 10.5555/541500
   Hosmer DavidW., 2000, Introduction to the logistic regression model
   Khoshgoftaar TM, 2011, IEEE T SYST MAN CY A, V41, P552, DOI 10.1109/TSMCA.2010.2084081
   Kim HC, 2002, LECT NOTES COMPUT SC, V2388, P397
   Muda Z, 2007, P SUMM SCH MULT SEM, V2007, P15
   Sewell M., 2008, RN, V11, P1
   Song J., 2011, P 19 ACM INT C MULT, P423, DOI DOI 10.1145/2072298.2072354
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Valentini G., 2003, ICML, P752
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Xu X.-S., 2011, P 19 ACM INT C MULT, P1153, DOI [10.1145/2072298.2071962, DOI 10.1145/2072298.2071962]
   Yan GT, 2006, LECT NOTES COMPUT SC, V3971, P974
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1677, DOI 10.1109/TMM.2014.2323014
   Yang Y, 2011, PROC CVPR IEEE, P881, DOI 10.1109/CVPR.2011.5995499
   Yang Y, 2013, IEEE T KNOWL DATA EN, V25, P1760, DOI 10.1109/TKDE.2012.118
   Yang Y, 2013, PATTERN RECOGN, V46, P1358, DOI 10.1016/j.patcog.2012.10.026
   Zhang LF, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0099946, 10.1371/journal.pone.0084950]
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhou Z-H., 2009, Encyclopedia of Biometrics, P270, DOI [DOI 10.1007/978-0-387-73003-5_293, 10.1007/978-0-387-73003-5293, DOI 10.1007/978-0-387-73003-5293]
NR 34
TC 10
Z9 11
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12627
EP 12644
DI 10.1007/s11042-014-2423-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700019
DA 2024-07-18
ER

PT J
AU Yan, B
   Wang, YF
   Song, LY
   Yang, HM
AF Yan, Bin
   Wang, Ya-Fei
   Song, Ling-Yun
   Yang, Hong-Mei
TI Size-invariant extended visual cryptography with embedded watermark
   based on error diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extended visual cryptography; Meaningful shares; Watermark; Error
   diffusion
AB A (2, 2) extended visual cryptography scheme with meaningful shares and no pixel expansion is constructed in this paper. In addition to the secret image, an additional watermark is also embedded to serve for authentication purpose. This watermark can be recovered by stacking a shifted version of one share with the other share. More importantly, the recovered watermark and secret images are free from interferences from the cover images.
C1 [Yan, Bin; Wang, Ya-Fei; Song, Ling-Yun] Shandong Univ Sci & Technol, Coll Elect Commun & Phys, Qingdao 266590, Shandong, Peoples R China.
   [Yang, Hong-Mei] Shandong Univ Sci & Technol, Coll Informat Sci & Engn, Qingdao 266590, Shandong, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Yan, B (corresponding author), Shandong Univ Sci & Technol, Coll Elect Commun & Phys, Qingdao 266590, Shandong, Peoples R China.
EM yanbinhit@hotmail.com; yhm1998@163.com
RI Song, Lu yang/HPF-0922-2023; Yan, Bin/Y-7642-2019; song,
   ling/GQZ-5934-2022
OI Song, Lu yang/0009-0006-5587-1630; Yan, Bin/0000-0003-2929-464X
FU Natural Science Foundation of China [61272432]; Qingdao science and
   technology development plan [12-1-4-6-(10)-jch]; Shandong Provincial
   Natural Science Foundation [ZR2014JL044]; Graduate Innovation Fund of
   Shandong University of Science and Technology [YC140340]
FX This work is supported by Natural Science Foundation of China (No.
   61272432), Qingdao science and technology development plan (No.
   12-1-4-6-(10)-jch), Shandong Provincial Natural Science Foundation (No.
   ZR2014JL044). The work of Ya-Fei Wang is also supported by Graduate
   Innovation Fund of Shandong University of Science and Technology (No.
   YC140340).
CR [Anonymous], 2015, J INFORM HIDING MULT
   Chang Ch-Ch., 2014, J INF HIDING MULTIME, V5, P342
   Chen TH, 2011, IEEE T CIRC SYST VID, V21, P1693, DOI 10.1109/TCSVT.2011.2133470
   Cheng Guo, 2011, Journal of Multimedia, V6, P341, DOI 10.4304/jmm.6.4.341-348
   Cimato S, 2012, DIGIT IMAG COMPUT, P1
   Fang WP, 2006, J ELECTRON IMAGING, V15, P1
   Fu MS, 2003, SIGNAL PROCESS, V83, P2171, DOI 10.1016/S0165-1684(03)00173-7
   Hao Luo, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.680
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Huang HC, 2011, SENSORS-BASEL, V11, P9717, DOI 10.3390/s111009717
   Huang HC, 2011, IEEE T CONSUM ELECTR, V57, P779, DOI 10.1109/TCE.2011.5955222
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Liu F., 2014, VISUAL CRYPTOGRAPHY
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Lou DC, 2011, DISPLAYS, V32, P118, DOI 10.1016/j.displa.2011.02.001
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Pang WM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360688
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Yang CY, 2015, J INF HIDING MULTIME, V6, P577
   Yi-Jing Huang, 2013, 2013 2nd International Symposium on Next-Generation Electronics (ISNE 2013), P165, DOI 10.1109/ISNE.2013.6512319
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 23
TC 9
Z9 9
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11157
EP 11180
DI 10.1007/s11042-015-2838-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900015
DA 2024-07-18
ER

PT J
AU Chen, HK
   Chen, WS
AF Chen, Hung-Kuang
   Chen, Wei-Sung
TI GPU-accelerated blind and robust 3D mesh watermarking by geometry image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; 3D mesh; GPU; Geometry image
ID ALGORITHM; IMPLEMENTATION
AB The prevalence of cheap and powerful consumer level graphics accelerated hardware introduces a significant growth of 3D applications. In this paper, we have proposed a GPU-accelerated blind and robust watermarking approach to the 3D polygon meshes on the basis of the geometry image transform and image watermarking, which performs watermark embedding and detection on the basis of the geometry image derived from a spherical parametrisation of the input mesh with the help of massive-parallel processing power of the GPUs on the display card. The experimental results show that our approach is successful in at least two aspects. First, the watermark is robust, the embedded watermark survives from common geometric attacks, cropping, simplification, and re-meshing attacks. Second, with the help of parallel computations on the GPUs, the embedding and detection process is extremely fast.
C1 [Chen, Hung-Kuang] Natl Chin Yi Univ Technol, Dept Elect Engn, Taichung 41170, Taiwan.
   [Chen, Wei-Sung] Natl Chung Hsing Univ, Comp Sci & Engn Dept, Taichung 402, Taiwan.
C3 National Chin-Yi University of Technology; National Chung Hsing
   University
RP Chen, HK (corresponding author), Natl Chin Yi Univ Technol, Dept Elect Engn, Taichung 41170, Taiwan.
EM hankchentw@gmail.com; wschen213@gmail.com
RI Chen, Hung-Kuang/R-1255-2019; Chen, Wei-Sung/R-2122-2017
OI Chen, Hung-Kuang/0000-0002-3994-9745; Chen, Wei-Sung/0000-0003-1314-4487
CR Abdallah Emad E., 2007, Proceedings Graphics Interface 2007, P327, DOI 10.1145/1268517.1268570
   Ackerman MJ, 1998, P IEEE, V86, P504, DOI 10.1109/5.662875
   Agarwal P, 2009, IEEE T INF FOREN SEC, V4, P36, DOI 10.1109/TIFS.2008.2011081
   [Anonymous], 2000, Digital Watermarking
   Benedens O, 1999, IEEE COMPUT GRAPH, V19, P46, DOI 10.1109/38.736468
   Benedens O, 2003, LECT NOTES COMPUT SC, V2578, P177
   Bors AG, 2013, IEEE T IMAGE PROCESS, V22, P1822, DOI 10.1109/TIP.2012.2236345
   Brunton A., 2005, PROC CANADIAN C ELEC, P1312, DOI DOI 10.1109/CCECE.2005.1557218
   Cano ECG, 2013, INGENIO MAGNO, V3, P6
   Cotting D, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P233, DOI 10.1109/SMI.2004.1314510
   Cox I. J., 2002, Digital Watermarking
   Floater MS, 2006, ADV COMPUT MATH, V24, P311, DOI 10.1007/s10444-004-7611-6
   Garg H, 2013, ROM J INF SCI TECH, V16, P287
   Garimella A, 2004, IEEE 11TH DIGITAL SIGNAL PROCESSING WORKSHOP & 2ND IEEE SIGNAL PROCESSING EDUCATION WORKSHOP, P292
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Han Sae Song, 2004, Proceedings of 2004 International Symposium on Intelligent Signal Processing And Communication Systems ISPACS 2004 (IEEE Cat. No.04EX910), P272
   Hoashi K, 2009, IEEE INT CON MULTI, P606, DOI 10.1109/ICME.2009.5202569
   Kalivas A, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P637
   Kanai S., 1998, IFIP WG, P296
   Karthigaikumar P, 2010, INT J ELECTRON SECUR, V3, P333, DOI 10.1504/IJESDF.2010.038615
   Karthigaikumar P, 2011, MICROELECTRON J, V42, P82, DOI 10.1016/j.mejo.2010.08.023
   Koller D, 2005, COMMUN ACM, V48, P74, DOI 10.1145/1064830.1064861
   Kougianos E, 2009, COMPUT ELECTR ENG, V35, P339, DOI 10.1016/j.compeleceng.2008.06.002
   Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849
   Lin C, 2011, INT J INTELL SYST, V3, P52
   Liu Y, 2012, IEEE T INF FOREN SEC, V7, P1459, DOI 10.1109/TIFS.2012.2204251
   Luo M, 2011, IEEE T IMAGE PROCESS, V20, P2813, DOI 10.1109/TIP.2011.2142004
   Maity SP, 2009, COMPUT ELECTR ENG, V35, P415, DOI 10.1016/j.compeleceng.2008.06.003
   Maity SR, 2004, Proceedings of the IEEE INDICON 2004, P6, DOI 10.1109/INDICO.2004.1497695
   Mohanty SP, 2007, INT C CONS EL IEEE, P1, DOI DOI 10.1109/ICCE.2007.341552
   Ohbuchi R, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P261, DOI 10.1145/266180.266377
   Ohbuchi R., 2001, Graphics Interface, P9
   Petitjean G, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P597, DOI 10.1109/ICME.2002.1035852
   Praun E, 1999, COMP GRAPH, P49, DOI 10.1145/311535.311540
   Rolland-Neviere Xavier, 2014, IEEE Transactions on Information Forensics and Security, V9, P1491, DOI 10.1109/TIFS.2014.2336376
   Rolland-Neviere X, 2015, SECURITY ANAL RADIAL
   Rolland-Neviere X., 2014, THESIS
   Rolland-Nevière X, 2014, IEEE IMAGE PROC, P4777, DOI 10.1109/ICIP.2014.7025968
   ROY SD, 2013, SYSTEMS MAN CYBERN A, V23, P289, DOI DOI 10.1109/TCSVT.2012.2203738
   Shi W., 2006, P 21 ACM SIG GRAPHEU, P17, DOI DOI 10.1145/1283900.1283903
   Singh LK, 2012, NOVEL APPROACH 3D OB, V60
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Su Cai, 2011, Journal of Multimedia, V6, P83, DOI 10.4304/jmm.6.1.83-90
   Tirkel A. Z., 1993, Conference Proceedings DICTA-93 Digital Image Computing: Techniques and Applications, P666
   Uccheddu F., 2004, PROC ACM MULTIMEDIA, P143
   Vihari P. L. V., 2012, Proceedings of the 2012 International Conference on Communication Systems and Network Technologies (CSNT 2012), P874, DOI 10.1109/CSNT.2012.188
   Wagner M. G., 2000, Proceedings Geometric Modeling and Processing 2000. Theory and Applications, P201, DOI 10.1109/GMAP.2000.838252
   Wang K, 2011, COMPUT GRAPH-UK, V35, P1, DOI 10.1016/j.cag.2010.09.010
   Wang K, 2008, IEEE T MULTIMEDIA, V10, P1513, DOI 10.1109/TMM.2008.2007350
   Yi-Qiang N, 2007, I C COMP GRAPH IM VI, P335
   Yong-Jae Jeong, 2008, 2008 Second International Conference on Future Generation Communication and Networking Symposia (FGCNS), P63, DOI 10.1109/FGCNS.2008.50
   Zafeiriou S, 2005, IEEE T VIS COMPUT GR, V11, P596, DOI 10.1109/TVCG.2005.71
   Zhan YZ, 2014, J ZHEJIANG U-SCI C, V15, P351, DOI 10.1631/jzus.C1300306
NR 53
TC 7
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 10077
EP 10096
DI 10.1007/s11042-015-3062-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500030
DA 2024-07-18
ER

PT J
AU Lin, GS
   Chang, MK
   Chang, YJ
   Yeh, CH
AF Lin, Guo-Shiang
   Chang, Min-Kuan
   Chang, Yu-Jui
   Yeh, Chia-Hung
TI A gender classification scheme based on multi-region feature extraction
   and information fusion for unconstrained images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gender classification; Information fusion; Bayesian classifier; Support
   vector machine
ID RECOGNITION
AB Since gender classification has been interesting in many applications, we proposed a gender classification scheme based on multi-region feature extraction and information fusion in the paper. The proposed gender classification scheme is composed of three parts: pre-processing, multi-region feature extraction, and gender classifier. Before extracting useful information from multiple regions in a facial image, face detection and face orientation correction are performed in the pre-processing. Multi-region feature extraction measures three kinds of features from eyes, internal face, and hair. Since the three kinds of features have their particular properties, a classifier based on decision-level information fusion is utilized to combine these features for gender classification. To evaluate the proposed scheme, a large number of unconstrained images containing different-size faces are captured by using a low-cost webcam and digital cameras. Experimental results show that our proposed scheme can detect facial regions and the location of eyes well. Furthermore, the accuracy of the proposed gender classification scheme is higher than 96 %. These experimental results demonstrate that the proposed scheme can deal with unconstrained images for gender classification.
C1 [Lin, Guo-Shiang] Dayeh Univ, Dept Comp Sci & Informat Engn, Dacun 51591, Changhua, Taiwan.
   [Chang, Min-Kuan; Chang, Yu-Jui] Natl Chung Hsing Univ, Dept Elect Engn, Taichung, Taiwan.
   [Yeh, Chia-Hung] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan.
C3 Da Yeh University; National Chung Hsing University; National Sun Yat Sen
   University
RP Lin, GS (corresponding author), Dayeh Univ, Dept Comp Sci & Informat Engn, Dacun 51591, Changhua, Taiwan.; Chang, MK (corresponding author), Natl Chung Hsing Univ, Dept Elect Engn, Taichung, Taiwan.
EM khlin@mail.dyu.edu.tw; minkuanc@nchu.edu.tw; kyoperfect@gmail.com;
   yeh@mail.ee.nsysu.edu.tw
RI Chang, Min-Kuan/AAM-4077-2020
OI Chang, Min-Kuan/0000-0002-0979-0892
CR Aji S., 2009, Proceedings of the 2009 World Congress on Nature & Biologically Inspired Computing (NaBIC 2009), P1414, DOI 10.1109/NABIC.2009.5393713
   Amayeh G., 2008, 2008 IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. Work. CVPR Work, DOI [10.1109/CVPRW.2008.4563122, DOI 10.1109/CVPRW.2008.4563122]
   Andreu Y, 2008, LECT NOTES COMPUT SC, V5112, P945, DOI 10.1007/978-3-540-69812-8_94
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cellerino A, 2004, BRAIN RES BULL, V63, P443, DOI 10.1016/j.brainresbull.2004.03.010
   CHAIR Z, 1986, IEEE T AERO ELEC SYS, V22, P98, DOI 10.1109/TAES.1986.310699
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen DY, 2010, IEEE T CONSUM ELECTR, V56, P1586, DOI 10.1109/TCE.2010.5606301
   Chi MC, 2008, SIGNAL PROCESS-IMAGE, V23, P127, DOI 10.1016/j.image.2007.12.001
   Dhawan AP., 2003, MED IMAGE ANAL
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   Faundez-Zanuy M, 2005, IEEE AERO EL SYS MAG, V20, P34, DOI 10.1109/MAES.2005.1396793
   Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465
   Gutta S, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P194, DOI 10.1109/AFGR.1998.670948
   Hadid A, 2008, INT C PATT RECOG, P193
   Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P376
   Li B, 2012, NEUROCOMPUTING, V76, P18, DOI 10.1016/j.neucom.2011.01.028
   Lie WN, 2005, P IEEE INT C IM PROC
   Lin GS, 2011, IEEE T CIRC SYST VID, V21, P421, DOI 10.1109/TCSVT.2011.2125370
   Lin GS, 2009, INT J PATTERN RECOGN, V23, P1179, DOI 10.1142/S0218001409007521
   Lu HC, 2008, J REAL-TIME IMAGE PR, V3, P109, DOI 10.1007/s11554-008-0072-2
   Moghaddam B., 2002, IEEE T PATTERN ANAL
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ping-Han Lee, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1140, DOI 10.1109/ICPR.2010.285
   Poor H. Vincent, 1994, An introduction to signal detection and estimation
   Scholkopf B., 2002, Learning with Kernels
   Tzanetakis G, 2005, IEEE PACIF, P432
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong KC, 2007, IEEE T SYST MAN CY B, V37, P1138, DOI 10.1109/TSMCB.2007.895325
   Yeh CH, 2010, J COMPUT, V21
   Yeh CH, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P429, DOI 10.1109/IIH-MSP.2008.13
   Yu CY, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/485151
   Yu SQ, 2009, IEEE T IMAGE PROCESS, V18, P1905, DOI 10.1109/TIP.2009.2020535
NR 34
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9775
EP 9795
DI 10.1007/s11042-015-2797-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500016
DA 2024-07-18
ER

PT J
AU Su, KH
   Kaewwichit, T
   Tseng, CH
   Chang, CC
AF Su, Ke-Han
   Kaewwichit, Thossaporn
   Tseng, Chien-Hsun
   Chang, Chong-Ching
TI Automatic footprint detection approach for the calculation of arch index
   and plantar pressure in a flat rubber pad
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flat rubber pad; Automatic footprint detection; Plantar pressure; Arch
   index
ID FOOT TYPE; WALKING
AB To obtain the Arch Index (AI) of footprint, the operation process through a Flat Rubber Pad (FRP) is manually time consuming to realize the necessary foot contact area. To deal with the problem, this paper developed an automatic footprint detection approach by employing the Otsu's thresholding method and the three components of HSV color space to segment the foot contact boundary in a footprint image. In addition, the ink density pattern of the FRP footprint image represents the pressure with a qualitative description of plantar pressure; the higher the ink density, the higher the pressure. Based on the principle, this paper examined the relationship between the intensity of the gray footprint image and body weight so as to quantify the magnitude of plantar pressures. Therefore, the depths of ink on the footprint image are used for plantar pressure calculation. The experiments verified that the proposed approach incorporated with the FRP can simultaneously obtain both the arch index and the plantar pressure with better accuracy when compared with other existing methods. The advantages of the developed approach with the FRP are that it can help reduce operating time and cost, and automatically obtain the foot contact area for further foot-related calculation without clinical expertise.
C1 [Su, Ke-Han] Natl Chiayi Univ, Dept Mech & Energy Engn, Chiayi 60004, Taiwan.
   [Kaewwichit, Thossaporn; Chang, Chong-Ching] Natl Univ Tainan, Grad Inst Mechatron Syst Engn, Tainan 70005, Taiwan.
   [Tseng, Chien-Hsun] Kun Shan Univ, Dept Informat Engn, Tainan 71070, Taiwan.
C3 National Chiayi University; National University Tainan; Kun Shan
   University
RP Chang, CC (corresponding author), Natl Univ Tainan, Grad Inst Mechatron Syst Engn, Tainan 70005, Taiwan.
EM jeff0718@mail.nutn.edu.tw
FU Ministry of Science and Technology of the Republic of China, Taiwan
   [NSC101-2221-E-024-002, MOST 103-2221-E-415 -031]
FX The authors would like to thank the Ministry of Science and Technology
   of the Republic of China, Taiwan, for support of this research under
   Grant Nos. NSC101-2221-E-024-002 and MOST 103-2221-E-415 -031. In
   particular, the authors would like to thank Dr. Prapai Jantrasakul for
   her assistance in English writing.
CR [Anonymous], J FOOT ANKLE RES
   Bird A.R., 1999, The Foot, V9, P175, DOI [10.1054/foot.1999.0563, DOI 10.1054/FOOT.1999.0563]
   Bus SA, 2004, CLIN BIOMECH, V19, P629, DOI 10.1016/j.clinbiomech.2004.02.010
   CAVANAGH PR, 1987, J BIOMECH, V20, P547, DOI 10.1016/0021-9290(87)90255-7
   Chae SH, 2016, MULTIMED TOOLS APPL, V75, P15347, DOI 10.1007/s11042-014-2201-1
   Chen W, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1123
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   Chevalier TL, 2010, GAIT POSTURE, V31, P397, DOI 10.1016/j.gaitpost.2009.11.016
   Chuckpaiwong B, 2008, GAIT POSTURE, V28, P405, DOI 10.1016/j.gaitpost.2008.01.012
   FRANCO AH, 1987, PHYS THER, V67, P688, DOI 10.1093/ptj/67.5.688
   Gross KD, 2011, ARTHRIT CARE RES, V63, P937, DOI 10.1002/acr.20431
   Hessert Mary Josephine, 2005, BMC Geriatr, V5, P8
   Hills AP, 2001, INT J OBESITY, V25, P1674, DOI 10.1038/sj.ijo.0801785
   Huang CN, 2011, IEEE COMPUT GRAPH, V31, P74, DOI 10.1109/MCG.2011.19
   Jonely H, 2011, CLIN BIOMECH, V26, P873, DOI 10.1016/j.clinbiomech.2011.04.008
   Kellis E, 2001, GAIT POSTURE, V14, P92, DOI 10.1016/S0966-6362(01)00129-1
   Lopes NV, 2010, IEEE T IMAGE PROCESS, V19, P199, DOI 10.1109/TIP.2009.2032349
   Lucchese L., 2001, PINSA-A (Proceedings of the Indian National Science Academy) Part A (Physical Sciences), V67, P207
   Mathieson I., 1999, The Foot, V9, P145, DOI [10.1054/foot.1999.0544, DOI 10.1054/FOOT.1999.0544]
   McCrary JL., 1997, The Foot, V7, P79, DOI DOI 10.1016/S0958-2592(97)90052-3
   Mora M, 2005, LECT NOTES COMPUT SC, V3773, P311
   NIGG BM, 1993, J BIOMECH, V26, P909, DOI 10.1016/0021-9290(93)90053-H
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Razak AHA, 2012, SENSORS-BASEL, V12, P9884, DOI 10.3390/s120709884
   Razeghi M, 2002, GAIT POSTURE, V15, P282, DOI 10.1016/S0966-6362(01)00151-5
   Riaz S., 2013, MULTIMED TOOLS APPL, P1
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Tizhoosh HR, 2005, PATTERN RECOGN, V38, P2363, DOI 10.1016/j.patcog.2005.02.014
   Urry S.R., 2005, FOOT, V15, P68, DOI [10.1016/j.foot.2005.02.001, DOI 10.1016/J.FOOT.2005.02.001]
   Urry SR, 2001, J AM PODIAT MED ASSN, V91, P203, DOI 10.7547/87507315-91-4-203
   Urry SR., 2001, Foot, V11, P151, DOI DOI 10.1054/FOOT.2001.0684
   Xiong L., 2009, IEEE 9 INT C SUSTAIN, P1
NR 33
TC 8
Z9 10
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9757
EP 9774
DI 10.1007/s11042-015-2796-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500015
DA 2024-07-18
ER

PT J
AU Rosa-Pujazón, A
   Barbancho, I
   Tardón, LJ
   Barbancho, AM
AF Rosa-Pujazon, Alejandro
   Barbancho, Isabel
   Tardon, Lorenzo J.
   Barbancho, Ana M.
TI Fast-gesture recognition and classification using Kinect: an application
   for a virtual reality drumkit
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drumkit simulator; Gesture recognition; Human-computer interaction;
   Machine learning; Classification techniques
ID HMM
AB In this paper, we present a system for the detection of fast gestural motion by using a linear predictor of hand movements. We also use the proposed detection scheme for the implementation of a virtual drumkit simulator. A database of drum-hitting motions is gathered and two different sets of features are proposed to discriminate different drumhitting gestures. The two feature sets are related to observations of different nature: the trajectory of the hand and the pose of the arm. These two sets are used to train classifier models using a variety of machine learning techniques in order to analyse which features and machine learning techniques are more suitable for our classification task. Finally, the system has been validated by means of the Kinect application implemented and the participation of 12 different subjects for the experimental performance evaluation. Results showed a successful discrimination rate higher than 95 % for six different gestures per hand and good user experience.
C1 [Rosa-Pujazon, Alejandro; Barbancho, Isabel; Tardon, Lorenzo J.; Barbancho, Ana M.] Univ Malaga, ATIC Res Grp, Dept Ingn Comunicac, ETSI Telecomunicac,Andalucia Tech, E-29071 Malaga, Spain.
C3 Universidad de Malaga
RP Barbancho, AM (corresponding author), Univ Malaga, ATIC Res Grp, Dept Ingn Comunicac, ETSI Telecomunicac,Andalucia Tech, E-29071 Malaga, Spain.
EM alejandror@uma.es; ibp@ic.uma.es; lorenzo@ic.uma.es; abp@ic.uma.es
RI Tardon, Lorenzo J./M-4492-2014; Barbancho, Isabel/L-7244-2014
OI Tardon, Lorenzo J./0000-0002-5441-225X; Barbancho,
   Isabel/0000-0001-7002-9106
FU Ministerio de Economia y Competitividad of the Spanish Government
   [TIN2013-47276-C6-2-R]; Junta de Andalucia [P11-TIC-7154]
FX This work has been funded by the Ministerio de Economia y Competitividad
   of the Spanish Government under Project No. TIN2013-47276-C6-2-R and by
   the Junta de Andalucia under Project No. P11-TIC-7154. This work has
   been done at Universidad de Malaga. Campus de Excelencia Internacional
   Andalucia Tech.
CR AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470
   [Anonymous], 2012, 2012 20 SIGN PROC CO
   [Anonymous], 1993, PROGRAMS MACHINE LEA, DOI DOI 10.1016/C2009-0-27846-9
   [Anonymous], 1995, 11 C UNC ART INT SAN, DOI DOI 10.1109/TGRS.2004.834800
   Bandera JP, 2012, INT J HUM ROBOT, V9, DOI 10.1142/S0219843612500065
   Bandera JP, 2009, PATTERN RECOGN LETT, V30, P1181, DOI 10.1016/j.patrec.2009.05.017
   Barbancho I, 2013, SOUND PERCEPTION PER, P367
   Bevilacqua Frederic., 2007, P 7 INT C NEW INTERF, P124, DOI [10.1145/1279740.1279762, DOI 10.1145/1279740.1279762]
   Bouënard A, 2010, ACTA ACUST UNITED AC, V96, P668, DOI 10.3813/AAA.918321
   Calinon Sylvain, 2007, THESIS
   Cao DW, 2009, COMPUT VIS IMAGE UND, V113, P1064, DOI 10.1016/j.cviu.2009.06.002
   Caramiaux B., 2014, P INT WORKSHOP MOVEM, P76
   Castellano Ginevra, 2007, P 7 INT C NEW INTERF, P390
   Celebi S., 2013, Computer Vision Theory and Applications. Visapp
   Chen CH, 2009, IEEE T SYST MAN CY C, V39, P114, DOI 10.1109/TSMCC.2008.2001716
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   El-Baz A, 2013, NEURAL COMPUT APPL, P1
   Halpern M, 2011, P 2011 ANN C HUM FAC, P557
   Haykin S., 2007, Neural networks: a comprehensive foundation
   Holland S, 2010, TEI 2010, P21
   Hosmer D. W., 2013, APPL LOGISTIC REGRES, DOI [10.1002/9781118548387, DOI 10.1002/9781118548387]
   Howell D.C., 2011, Statistical methods for psychology
   Jacob M, 2013, PATTERN RECOGN, V36, P196, DOI DOI 10.1016/J.PATREC.2013.05.024
   Jorda Sergi, 2005, INT COMPUTER MUSIC C, DOI [10.1145/1753846.1753903, DOI 10.1145/1753846.1753903]
   Khoo ET, 2008, SANDBOX SYMPOSIUM 2008: 3RD ACM SIGGRAPH VIDEOGAME SYMPOSIUM, PROCEEDINGS, P35
   Kim D, 2007, PATTERN RECOGN, V40, P3012, DOI 10.1016/j.patcog.2007.02.010
   Lago NelsonPosse., 2004, Proceedings o f the 2004 International Computer Music Conference, P33
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Li H, 2011, PATTERN RECOGN, V44, P1614, DOI 10.1016/j.patcog.2010.12.014
   Livingston MA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P119, DOI 10.1109/VR.2012.6180911
   Mannini A, 2010, SENSORS-BASEL, V10, P1154, DOI 10.3390/s100201154
   Mühlig M, 2009, IEEE INT CONF ROBOT, P1635
   Odowichuk G, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P836, DOI 10.1109/PACRIM.2011.6033003
   Rasamimanana NH, 2006, LECT NOTES ARTIF INT, V3881, P145
   Rosa-Pujazon Alejandro, 2015, International Journal of Creative Interfaces and Computer Graphics, V6, P72, DOI 10.4018/IJCICG.2015010105
   Rosa-Pujazon A, 2013, SMAC 2013 STOCKH MUS, P284
   Rosa-Pujazon A, 2013, 1 S ESP ENTR DIG SEE, P108
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Stanton C., 2012, P AUSTR C ROB AUT
   Stierman C, 2012, THESIS
   Todoroff T, 2011, QPSR NUMEDIART RES P, V4
   Trail S, 2012, 12 INT C NEW INT MUS
   Wiener N., 1964, Extrapolation, interpolation, and smoothing of stationary time series: with engineering applications
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Yoo M, 2011, P 2011 C NEW INT MUS
   Yoon HS, 2001, PATTERN RECOGN, V34, P1491, DOI 10.1016/S0031-3203(00)00096-0
   Zhang YH, 2014, SIGNAL IMAGE VIDEO P, V8, pS173, DOI 10.1007/s11760-014-0669-9
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
NR 48
TC 8
Z9 9
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8137
EP 8164
DI 10.1007/s11042-015-2729-8
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300002
DA 2024-07-18
ER

PT J
AU Sun, SM
   Jiang, HX
   Li, B
AF Sun, Shiming
   Jiang, Hongxu
   Li, Bo
TI An efficient Markov chain-based data prefetching for motion estimation
   of HEVC on multi-core DSPs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion estimation; Data prefetching; Markov chain-based model; HEVC;
   Multi-core DSP
ID ALGORITHM
AB As one of the most time-consuming parts of video coding, Motion Estimation (ME) has always been the major issue in the embedded coding system due to its memory-intensive nature. This is even truer now as the gap between processor and memory speed continues to grow in the embedded coding system on multi-core processors. In this paper, a data prefetching algorithm based on a Markov Chain Model (MCMDP) is presented to improve the data access efficiency for the ME of High Efficiency Video Coding (HEVC) on multi-core DSPs. First, by analyzing the process and features of ME, a new method of calculating Motion Vector Predictions (MVPs) is given, in which the coding block's MVP is estimated from the MVPs of the reference picture instead of the motion vectors of the neighboring blocks. This is critical to improve the efficiency of data prefetching for ME because it eliminates the data dependencies that cause the latency of data prefetching. Second, the experimental results show that the probability distribution of the search windows in ME has continuity and locality in successive pictures, and these statistical properties are consistent with the characteristics of Markov chains. Therefore, a new model based on Markov chains is designed for predicting the prefetch window that covers the search window to improve the coverage of data prefetching. Finally, the experiments on TMS320C6678 demonstrate that the prefetching efficiency is significantly improved for the ME of HEVC on multi-core DSPs.
C1 [Sun, Shiming; Jiang, Hongxu; Li, Bo] Beihang Univ, Beijing Key Lab Digital Media, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
   [Sun, Shiming] China Univ Petr, Sch Comp Sci & Commun Engn, Qingdao 266580, Peoples R China.
C3 Beihang University; China University of Petroleum
RP Jiang, HX (corresponding author), Beihang Univ, Beijing Key Lab Digital Media, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
EM jianghx@buaa.edu.cn
RI Li, bo/IWL-9318-2023; Jiang, Hongxu/GRY-0379-2022; Li, Bo/AAA-8968-2020
OI Li, Bo/0000-0002-7294-6888
FU National Science Fund for Distinguished Young Scholars [61125206];
   National Natural Science Foundation of China [61272347]
FX This work was supported by the National Science Fund for Distinguished
   Young Scholars (no. 61125206) and National Natural Science Foundation of
   China (no. 61272347).
CR Agostini LV, 2001, 14 S INT CIRC SYST D
   Ali W., 2011, INT J ADV SOFT COMPU, V3, P19
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   CHEN TF, 1995, IEEE T COMPUT, V44, P609, DOI 10.1109/12.381947
   Chen Y, 2011, INT J HIGH PERFORM C, V25, P355, DOI 10.1177/1094342010394386
   Chi CC, 2012, IEEE T CIRC SYST VID, V22, P1827, DOI 10.1109/TCSVT.2012.2223056
   Chiu JC, 2013, COMPUT ELECTR ENG, V39, P1129, DOI 10.1016/j.compeleceng.2013.01.013
   Cong J, 2011, DES AUT CON, P960
   Dai W, 2012, IEEE INT SYMP CIRC S, P1560
   Dai W, 2012, INT CONF ACOUST SPEE, P1197, DOI 10.1109/ICASSP.2012.6288102
   [党向磊 Dang Xianglei], 2012, [电子学报, Acta Electronica Sinica], V40, P2145
   Dasygenis M, 2006, IEEE T VLSI SYST, V14, P279, DOI 10.1109/TVLSI.2006.871759
   Felix H, 2011, JCTVCE196
   Gonzalez J., 1997, Conference Proceedings of the 1997 International Conference on Supercompting, P196, DOI 10.1145/263580.263631
   Jin Huang, 2011, Proceedings of the 2011 IEEE 9th International Conference on ASIC (ASICON 2011), P192, DOI 10.1109/ASICON.2011.6157154
   Joseph D, 1999, IEEE T COMPUT, V48, P121, DOI 10.1109/12.752653
   Kim I-K, 2012, P APPL DIG IM PROC
   Kim T, 2014, P 11 ACM C COMP FRON, P321
   Lin JY, 2011, DIR DEV, P1
   Mastronarde N, 2013, IEEE T MULTIMEDIA, V15, P268, DOI 10.1109/TMM.2012.2231668
   Mishra A, 2014, APPL MATH MODEL, V38, P3456, DOI 10.1016/j.apm.2013.12.009
   Paul S, 2014, 14 P C DES AUT TEST
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Purnachand N., 2012, 2012 IEEE Second International Conference on Consumer Electronics - Berlin (ICCE-Berlin), P34, DOI 10.1109/ICCE-Berlin.2012.6336494
   Sbeyti H, 2004, DESIGN, AUTOMATION AND TEST IN EUROPE CONFERENCE AND EXHIBITION, VOLS 1 AND 2, PROCEEDINGS, P1350, DOI 10.1109/DATE.2004.1269082
   Somogyi S, 2007, 36 INT S COMP ARCH I, P69
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tang J, 2011, IEEE COMPUT ARCHIT L, V10, P8, DOI 10.1109/L-CA.2011.2
   Texas Instruments, TMS320C6678 MULT FIX
   Texas Instruments, THROUGHP PERF GUID C
   Vanderwiel SP, 2000, ACM COMPUT SURV, V32, P174, DOI 10.1145/358923.358939
   Wulf W. A., 1995, Computer Architecture News, V23, P20, DOI 10.1145/216585.216588
   Xie Lun-Guo, 2011, Chinese Journal of Computers, V34, P694, DOI 10.3724/SP.J.1016.2011.00694
   Xu ZY, 2004, IEEE T COMPUT, V53, P20, DOI 10.1109/TC.2004.1255788
   Yan C, 2005, CAN C EL COMP ENG, P2284
   Yang P, 2012, INT C COMP SCI INF P, P849
   Yemliha Taylan, 2008, 2008 IEEE/ACM International Conference on Computer-Aided Design (ICCAD), P565, DOI 10.1109/ICCAD.2008.4681632
   Yu CH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P80
   Yu Q, 2012, P VIS COMM IM PROC, P17
   Yuen JCH, 2007, MULTIMED TOOLS APPL, V32, P329, DOI 10.1007/s11042-006-0055-x
   Zhizhuo S, 2012, MULTIMED TOOLS APPL, V73, P151
NR 41
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 8019
EP 8043
DI 10.1007/s11042-015-2721-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600027
DA 2024-07-18
ER

PT J
AU Tsai, YY
AF Tsai, Yuan-Yu
TI An efficient 3D information hiding algorithm based on sampling concepts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sampling concepts; Information hiding; Surface reconstruction; 3D models
ID CAPACITY; STEGANOGRAPHY; WATERMARKING
AB This study proposes an efficient 3D information hiding algorithm based on sampling concepts. The total embedding capacity depends on the number of feature points obtained from an auxiliary polygonal model, instead of model complexity. We use sampling concepts to derive the feature points directly on each polygon of the auxiliary polygonal model. A stego model can be efficiently generated by slightly adjusting the position of each feature point with the help of the secret message and the embedding parameter. This approach has four characteristics. First, it preserves the features of high embedding capacity and flexibility. Second, this approach resolves the shortcomings of the holed effects and the dummy points in previous algorithm. Third, this approach is efficient with the time complexity O(n), where n is the number of feature points. Finally, the proposed algorithm supports point geometries as auxiliary models by adopting a surface reconstruction scheme. The above characteristics demonstrate the feasibility of the proposed algorithm.
C1 [Tsai, Yuan-Yu] Asia Univ, Dept Appl Informat & Multimedia, Taichung, Taiwan.
   [Tsai, Yuan-Yu] China Med Univ, China Med Univ Hosp, Dept Med Res, Taichung, Taiwan.
C3 Asia University Taiwan; China Medical University Taiwan; China Medical
   University Hospital - Taiwan
RP Tsai, YY (corresponding author), Asia Univ, Dept Appl Informat & Multimedia, Taichung, Taiwan.; Tsai, YY (corresponding author), China Med Univ, China Med Univ Hosp, Dept Med Res, Taichung, Taiwan.
EM yytsai@asia.edu.tw
FU National Science Council of Taiwan [NSC 100-2221-E-468-023]
FX The authors would like to thank the anonymous reviewers for their
   constructive comments. This work was supported by the National Science
   Council of Taiwan under the grant number NSC 100-2221-E-468-023.
CR Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   Bogomjakov A, 2008, COMPUT GRAPH FORUM, V27, P637, DOI 10.1111/j.1467-8659.2008.01161.x
   Chao MW, 2009, IEEE T VIS COMPUT GR, V15, P274, DOI 10.1109/TVCG.2008.94
   Cox Ingemar, 2008, DIGITAL WATERMARKING, V2
   Feng XQ, 2014, MULTIMED TOOLS APPL, V68, P497, DOI 10.1007/s11042-012-1039-7
   Huang NC, 2009, IEEE SIGNAL PROC LET, V16, P802, DOI 10.1109/LSP.2009.2024794
   Kaveh H, 2015, SECUR COMMUN NETW, V8, P159, DOI 10.1002/sec.968
   Li MT, 2011, INT J INNOV COMPUT I, V7, P1055
   Lin CH, 2013, INT J INNOV COMPUT I, V9, P1321
   Ohbuchi R, 2002, COMPUT GRAPH FORUM, V21, P373, DOI 10.1111/1467-8659.t01-1-00597
   Rencher A., 2002, METHODS MULTIVARIATE
   Tsai YY, 2014, MULTIMED TOOLS APPL, V69, P859, DOI 10.1007/s11042-012-1135-8
   Tu SC, 2012, COMPUT GRAPH-UK, V36, P767, DOI 10.1016/j.cag.2012.06.002
   Turk G., 1990, GRAPHICS GEMS GENERA, P24
   Wang CM, 2006, COMPUT GRAPH-UK, V30, P244, DOI 10.1016/j.cag.2006.01.030
   Wang CM, 2005, COMPUT GRAPH FORUM, V24, P591, DOI 10.1111/j.1467-8659.2005.00884.x
   Wang K, 2008, IEEE T INF FOREN SEC, V3, P620, DOI 10.1109/TIFS.2008.2007229
   Wang K, 2008, IEEE T MULTIMEDIA, V10, P1513, DOI 10.1109/TMM.2008.2007350
   Yang Y, 2014, ACM T MULTIM COMPUT, V1-27, P13
   Yang Y, 2014, IEEE IMAGE PROC, P4782, DOI 10.1109/ICIP.2014.7025969
   Yang Y, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2535555
   Zwicker M, 2002, ACM T GRAPHIC, V21, P322, DOI 10.1145/566570.566584
NR 22
TC 8
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7891
EP 7907
DI 10.1007/s11042-015-2707-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600021
DA 2024-07-18
ER

PT J
AU Davarpanah, SH
   Khalid, F
   Abdullah, LN
   Golchin, M
AF Davarpanah, S. Hashem
   Khalid, Fatimah
   Abdullah, Lili Nurliyana
   Golchin, Maryam
TI A texture descriptor: BackGround Local Binary Pattern (BGLBP)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LBP; Texture descriptor; Background extraction; Moving detection
ID CLASSIFICATION; SYSTEM
AB Local Binary Pattern (LBP) is invariant to the monotonic changes in the grey scale domain. This property enables LBP to present a texture descriptor being useful in applications dealing with the local illumination changes. However, the existing versions of LBP are not able to handle image illumination changes, especially in outdoor environments. The non-patterned illumination changes disturb performance of the background extraction methods. In this paper, an extended version of LBP which is called BackGround LBP (BGLBP) is presented. BGLBP is designed for the background extraction application but it is extendable to the other areas as a texture descriptor. BGLBP is an extension of D-LBP, Centre-Symmetric LBP, ULBP, and R-LBP and it has been designed to inherit the positive properties of previous versions. The performance of BGLBP as a part of background extraction method is investigated. In addition, a comparison between BGLBP as a general texture descriptor and a number of LBP versions is conducted.
C1 [Davarpanah, S. Hashem] Univ Sci & Culture, Fac Engn, Dept Comp Engn, Tehran, Iran.
   [Khalid, Fatimah; Abdullah, Lili Nurliyana] Univ Putra Malaysia, Fac Comp Sci & IT, Serdang 43300, Malaysia.
   [Golchin, Maryam] Griffith Univ, Sch ICT, Gold Coast Campus, Southport, Qld 4222, Australia.
C3 Universiti Putra Malaysia; Griffith University; Griffith University -
   Gold Coast Campus
RP Davarpanah, SH (corresponding author), Univ Sci & Culture, Fac Engn, Dept Comp Engn, Tehran, Iran.
EM davarpanah@usc.ac.ir; fatimahk@upm.edu.my; liyana@upm.edu.my;
   maryam.golchin@griffithuni.edu.au
RI Abdullah, Lili Nurliyana/AAC-6423-2020
OI Abdullah, Lili Nurliyana/0000-0001-8704-2390; Khalid,
   Fatimah/0000-0002-5791-065X; GOLCHIN, MARYAM/0000-0002-5288-0121
CR Armanfard N, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTATIONAL TOOLS FOR ENGINEERING APPLICATIONS, P369, DOI 10.1109/ACTEA.2009.5227894
   Chiu CC, 2010, IEEE T CIRC SYST VID, V20, P518, DOI 10.1109/TCSVT.2009.2035843
   Cui BX, 2009, WKDD: 2009 SECOND INTERNATIONAL WORKSHOP ON KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS, P821, DOI 10.1109/WKDD.2009.117
   Davarpanah Seyed Hashem, 2012, Journal of Computer Science, V8, P1062, DOI 10.3844/jcssp.2012.1062.1069
   Davarpanah S. H., 2012, Journal of Computer Science, V8, P1077, DOI 10.3844/jcssp.2012.1077.1084
   He XJ, 2007, 2007 CIT: 7TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, PROCEEDINGS, P639, DOI 10.1109/CIT.2007.46
   He Yan, 2011, Proceedings of the 2011 International Conference on Transportation and Mechanical & Electrical Engineering (TMEE), P1, DOI 10.1109/TMEE.2011.6199133
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Jie Luo, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1028, DOI 10.1109/ICPR.2010.257
   Kong J, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS, P464, DOI 10.1109/FSKD.2007.98
   Li Xiaofei, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P1, DOI 10.1109/CSIE.2009.406
   Mason M, 2001, 30TH APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP, PROCEEDINGS, P154, DOI 10.1109/AIPR.2001.991219
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T., 1994, 12 IAPR INT C PATT A, P582
   Quen-Zong Wu, 2004, 2004 IEEE International Conference on Networking, Sensing and Control (IEEE Cat. No.04EX761), P309
   Research I. f. I., 2000, A STAR
   Sun ZL, 2010, IEEE INT CONF ROBOT, P115, DOI 10.1109/ROBOT.2010.5509374
   Wen-Hung Liao, 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P191, DOI 10.1109/ISM.2010.35
   Wen-Hung Liao, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1003, DOI 10.1109/ICPR.2010.251
   Wu XS, 2009, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY, VOL 2, PROCEEDINGS, P361, DOI 10.1109/IAS.2009.126
   Xia D, 2010, INT C COMP APPL SYST
   Xiaohui Yang, 2010, Proceedings 2010 IEEE 2nd Symposium on Web Society (SWS 2010), P103, DOI 10.1109/SWS.2010.5607469
   Xue GJ, 2010, IEEE INT CON MULTI, P1050, DOI 10.1109/ICME.2010.5582601
   Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11
   Zhao G, 2006, INT C PATT RECOG, P211
   Zhao S, 2008, P 19 INT C PATT REC, P1, DOI DOI 10.1109/ICPR.2008.4761248
NR 27
TC 12
Z9 14
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6549
EP 6568
DI 10.1007/s11042-015-2588-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700024
OA Green Accepted, Green Published
DA 2024-07-18
ER

PT J
AU Dogra, DP
   Ahmed, A
   Bhaskar, H
AF Dogra, Debi Prosad
   Ahmed, Arif
   Bhaskar, Harish
TI Smart video summarization using mealy machine-based trajectory modelling
   for surveillance applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Trajectory analysis; Scene understanding; Tracking;
   Finite state machine
ID CLASSIFICATION
AB In this paper, we propose a smart video summarization technique that compiles a synopsis of event(s)-of-interest occurring within a segment of image frames in a video. The proposed solution space consists of extracting appropriate features that represent the dynamics of targets in surveillance environments using their motion trajectories combined with a finite state automaton model for analyzing state changes of such features to detect and localize event(s)-of-interest. We introduce the cumulative moving average (CMA) and the preceding segment average (PSA) statistical metric as features that indicate gradual and sudden changes in the instantaneous velocity of moving targets. In order to support both on-line and off-line summarization, a finite state machine, that is often referred to as Mealy Machine, has been proposed to model the trajectory of a moving target and used for detecting transitions that represents a change from one state to another when initiated by a triggering event or condition. We conduct several systematic experiments on different scenario-specific in-house videos and other publicly available datasets to demonstrate the effectiveness of our proposed approach and benchmark its performance against chosen baseline strategies. The results of our experiments highlight the superiority of our proposed method in accurately localizing the start and end of event(s)-of-interest in videos within the chosen dataset.
C1 [Dogra, Debi Prosad] IIT Bhubaneswar, Sch Elect Sci, Bhubaneswar, Orissa, India.
   [Ahmed, Arif] Haldia Inst Technol, Dept Comp Sci & Engn, Haldia, India.
   [Bhaskar, Harish] Khalifa Univ Sci Technol & Res, Dept Elect & Comp Engn, Abu Dhabi 127788, U Arab Emirates.
   [Bhaskar, Harish] Univ Bristol, Bristol Vis Inst, Bristol, Avon, England.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Bhubaneswar; Haldia Institute of Technology; Khalifa
   University of Science & Technology; University of Bristol
RP Dogra, DP (corresponding author), IIT Bhubaneswar, Sch Elect Sci, Bhubaneswar, Orissa, India.
EM dpdogra@iitbbs.ac.in; harish.bhaskar@kustar.ac.ae
RI Sk, Arif Ahmed/U-5120-2019; Bhaskar, Harish/N-1304-2014
OI Sk, Arif Ahmed/0000-0003-0706-2565; Bhaskar, Harish/0000-0001-6517-6232
CR Ajmal M, 2012, LECT NOTES COMPUT SC, V7594, P1, DOI 10.1007/978-3-642-33564-8_1
   [Anonymous], 2007, P INT WORKSHOP TRECV, DOI [10.1145/1290031.1290035, DOI 10.1145/1290031.1290035]
   Besiris D, 2009, MULTIMED TOOLS APPL, V44, P161, DOI 10.1007/s11042-009-0277-9
   Bucak SS, 2011, SPRINGER J SIGNAL IM, P1
   Chen F, 2014, IEEE T MULTIMEDIA, V16, P455, DOI 10.1109/TMM.2013.2291967
   Damnjanovic Uros, 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P63, DOI 10.1109/WIAMIS.2008.53
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Doulamis N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P297, DOI 10.1109/ICME.2002.1035777
   Fujimura K, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P49, DOI 10.1109/ICME.2002.1035715
   Furini M, 2006, CONSUM COMM NETWORK, P1209
   Habibian A, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P17, DOI 10.1145/2647868.2654913
   Irani M, 1998, P IEEE, V86, P905, DOI 10.1109/5.664279
   Jiang RM, 2009, STUD COMPUT INTELL, V231, P27
   Kang H.-W., 2006, P IEEE C COMP VIS PA, P1331, DOI [DOI 10.1109/CVPR.2006.284, 10.1109/cvpr.2006.2842, DOI 10.1109/CVPR.2006.2842, 10.1109/cvpr.2006.284]
   Khosla A, 2013, PROC CVPR IEEE, P2698, DOI 10.1109/CVPR.2013.348
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Liu D, 2011, IEEE T MULTIMEDIA, V13, P82, DOI 10.1109/TMM.2010.2087744
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Ma X, 2010, STUD COMPUT INTELL, V287, P53
   Meghdadi AH, 2013, IEEE T VIS COMPUT GR, V19, P2119, DOI 10.1109/TVCG.2013.168
   Nam J., 1999, PROC 7 ACM INT C MUL, P53
   Panagiotakis C, 2013, LECT NOTES COMPUT SC, V8047, P94, DOI 10.1007/978-3-642-40261-6_11
   Peng WT, 2011, IEEE T MULTIMEDIA, V13, P539, DOI 10.1109/TMM.2011.2131638
   Rodriguez M, 2010, PROC CVPR IEEE, P3328, DOI 10.1109/CVPR.2010.5540030
   Shafeian H, 2012, INT C PATT RECOG, P996
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Wang M, 2013, ACM T INTERNET TECHN, V12, DOI 10.1145/2492690
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wang XG, 2006, LECT NOTES COMPUT SC, V3953, P110, DOI 10.1007/11744078_9
   Xiang Xiaohong, 2011, P 19 ACM INT C MULT, P553
   Zhang YH, 2014, SIGNAL IMAGE VIDEO P, V8, pS173, DOI 10.1007/s11760-014-0669-9
   Zhao S., 2013, INT C MULT MOD MMM 2, P7732, DOI DOI 10.1007/978-3-642-35725-1_34
   Zhao SC, 2013, NEUROCOMPUTING, V119, P101, DOI 10.1016/j.neucom.2012.04.042
   Zhao Sicheng, 2011, P 19 ACM INT C MULTI, P1473, DOI [10.1145/2072298.2072043, DOI 10.1145/2072298.2072043]
NR 34
TC 18
Z9 19
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6373
EP 6401
DI 10.1007/s11042-015-2576-7
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700016
DA 2024-07-18
ER

PT J
AU Qadir, QM
   Kist, AA
   Zhang, ZW
AF Qadir, Qahhar Muhammad
   Kist, Alexander A.
   Zhang, Zhongwei
TI The probability relationship between video's instantaneous and average
   aggregate rates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video; Rate estimation; Probability; Traffic measurement
ID MULTISERVICE IP NETWORKS; ADMISSION CONTROL; SINGLE-LAYER; H.264/SVC
AB The growing demand for video applications and services has contributed substantially to the increase of video traffic on the Internet. Measurement-based admission control was proposed with the primary aim of eliminating or reducing the need of flow state information; also to control overhead for admission decision and maximize utilization at the potential cost of QoS degradation. Some of the admission algorithms depend on the instantaneous rate for its operation. On the other hand, the average aggregate rate has been proposed to better suit variable rate such as video traffic. In this paper, we investigate the probability relationship between the instantaneous and average aggregate rates for video traffic. A mathematical model has been developed to quantify the probability relationship between both rates and validated through extensive simulations using real video sequences. The average rate was found to be lower than instantaneous for a small number of flows, however there was no pronounced difference for a large number of flows. Furthermore, the difference between both rates increases for fast moving content such as sport or longer measurement time window.
C1 [Qadir, Qahhar Muhammad] Univ So Queensland, Sch Mech & Elect Engn, Toowoomba, Qld, Australia.
   [Qadir, Qahhar Muhammad] Salahaddin Univ, Dept Elect Engn, Hawler, Kurdistan Regio, Iraq.
   [Kist, Alexander A.] Univ So Queensland, Sch Agr Computat & Environm Sci, Toowoomba, Qld, Australia.
   [Zhang, Zhongwei] Univ So Queensland, Fac Hlth Engn & Sci, Toowoomba, Qld, Australia.
C3 University of Southern Queensland; Salahaddin University; University of
   Southern Queensland; University of Southern Queensland
RP Qadir, QM (corresponding author), Univ So Queensland, Sch Mech & Elect Engn, Toowoomba, Qld, Australia.; Qadir, QM (corresponding author), Salahaddin Univ, Dept Elect Engn, Hawler, Kurdistan Regio, Iraq.
EM safeen.qadir@ieee.org; kist@ieee.org; zhongwei.zhang@usq.edu.au
RI Qadir, Qahhar Muhammad/A-7033-2016; Kist, Alexander/F-2798-2010
OI Qadir, Qahhar Muhammad/0000-0002-5702-8712; Kist,
   Alexander/0000-0001-9105-7050
CR Ammar D, 2012, C LOCAL COMPUT NETW, P537, DOI 10.1109/LCN.2012.6423672
   Ammar D, 2011, C LOCAL COMPUT NETW, P215, DOI 10.1109/LCN.2011.6115192
   [Anonymous], 2007, IPTVIL0050 ITUT FG
   [Anonymous], THESIS
   [Anonymous], 1998, 2475 RFC IETF
   [Anonymous], 2014, CISCO VISUAL NETWORK
   [Anonymous], 1997, ANOVA BASICS APPL ST, DOI DOI 10.1201/B15236
   [Anonymous], THESIS
   Auge J., 2011, Proceedings of the 2011 23rd International Teletraffic Congress (ITC 2011), P206
   Breslau L., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P1233, DOI 10.1109/INFCOM.2000.832506
   Casetti C, 1997, PROTOCOLS FOR HIGH-SPEED NETWORK V, P13
   Eardley PE, 2009, 5559 RFC IETF
   Floyd S, 1996, COMMENTS MEASREMENT
   FROST VS, 1994, IEEE COMMUN MAG, V32, P70, DOI 10.1109/35.267444
   Gibbens R.J., 1997, 15 INT TEL C P
   Hamdaoui B, 2007, IEEE T WIREL COMMUN, V6, P4014, DOI 10.1109/TWC.2007.060155
   HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952
   Jamin S, 1997, IEEE ACM T NETWORK, V5, P56, DOI 10.1109/90.554722
   Jamin S, 1997, IEEE INFOCOM SER, P973, DOI 10.1109/INFCOM.1997.631035
   Jiang YM, 2005, 2005 NEXT GENERATION INTERNET NETWORKS, P318
   Khalek AA, 2012, IEEE J SEL AREA COMM, V30, P1157, DOI 10.1109/JSAC.2012.120802
   Latré S, 2011, J NETW SYST MANAG, V19, P32, DOI 10.1007/s10922-010-9183-8
   Lima SR, 2007, IEEE COMMUN MAG, V45, P114, DOI 10.1109/MCOM.2007.343620
   Menth M, 2010, IEEE COMMUN SURV TUT, V12, P357, DOI 10.1109/SURV.2010.040710.00078
   Nam SY, 2008, IEEE ACM T NETWORK, V16, P410, DOI 10.1109/TNET.2007.900403
   Nevin A, 2010, THESIS
   Nevin A, 2008, IEEE SYMP COMP COMMU, P439
   Politis I, 2012, SIGNAL PROCESS-IMAGE, V27, P814, DOI 10.1016/j.image.2012.01.006
   Qadir S, 2013, 2013 IEEE TENCON SPRING CONFERENCE, P490, DOI 10.1109/TENCONSpring.2013.6584493
   Qadir S, 2013, 2013 AUSTRALASIAN TELECOMMUNICATION NETWORKS AND APPLICATIONS CONFERENCE (ATNAC), P178, DOI 10.1109/ATNAC.2013.6705377
   Qiu JY, 2001, IEEE ACM T NETWORK, V9, P199, DOI 10.1109/90.917076
   Rengaraju P, 2012, IEEE WIREL COMMUN, V19, P89, DOI 10.1109/MWC.2012.6272428
   Seeling P, 2004, IEEE COMMUN SURV TUT, V6, P58, DOI 10.1109/COMST.2004.5342293
   Taher NC, 2014, COMPUT COMMUN, V39, P41, DOI 10.1016/j.comcom.2013.10.006
   Van der Auwera G, 2008, IEEE T BROADCAST, V54, P698, DOI 10.1109/TBC.2008.2000422
   Weller D., 2013, IEEE SPECTRUM, V50, P80, DOI DOI 10.1109/MSPEC.2013.6395331
   Wojcik R., 2013, 2013 International Conference on Computing, Networking and Communications (ICNC 2013), P922, DOI 10.1109/ICCNC.2013.6504213
   Wright S, 2007, IEEE COMMUN SURV TUT, V9, P72, DOI 10.1109/COMST.2007.382408
   Xu YW, 2013, 2013 IEEE EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SENSORS, SENSOR NETWORKS AND INFORMATION PROCESSING, P345, DOI 10.1109/ISSNIP.2013.6529814
   Yerima SY, 2013, ABS13111435 CORR
NR 40
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 6909
EP 6924
DI 10.1007/s11042-015-2617-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400011
DA 2024-07-18
ER

PT J
AU Qureshi, MA
   Deriche, M
AF Qureshi, Muhammad Ali
   Deriche, M.
TI A new wavelet based efficient image compression algorithm using
   compressive sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Discrete wavelet transform; Adaptive sampling;
   Sparse representation; Image compression; Image quality
ID SIGNAL RECOVERY; REPRESENTATION
AB We propose a new algorithm for image compression based on compressive sensing (CS). The algorithm starts with a traditional multilevel 2-D Wavelet decomposition, which provides a compact representation of image pixels. We then introduce a new approach for rearranging the wavelet coefficients into a structured manner to formulate sparse vectors. We use a Gaussian random measurement matrix normalized with the weighted average Root Mean Squared energies of different wavelet subbands. Compressed sampling is finally performed using this normalized measurement matrix. At the decoding end, the image is reconstructed using a simple a"" (1)-minimization technique. The proposed wavelet-based CS reconstruction, with the normalized measurement matrix, results in performance increase compared to other conventional CS-based techniques. The proposed approach introduces a completely new framework for using CS in the wavelet domain. The technique was tested on different natural images. We show that the proposed technique outperforms most existing CS-based compression methods.
C1 [Qureshi, Muhammad Ali; Deriche, M.] King Fahd Univ Petr & Minerals, Dept Elect Engn, Dhahran 31261, Saudi Arabia.
C3 King Fahd University of Petroleum & Minerals
RP Qureshi, MA (corresponding author), King Fahd Univ Petr & Minerals, Dept Elect Engn, Dhahran 31261, Saudi Arabia.
EM aliqureshi@kfupm.edu.sa; mderiche@kfupm.edu.sa
RI Qureshi, Muhammad Ali/C-3857-2012; Deriche, Mohamed/A-9871-2008
OI Qureshi, Muhammad Ali/0000-0003-4390-2461; Deriche,
   Mohamed/0000-0002-5287-1874
FU Deanship of Scientific Research at KFUPM [IN121012]
FX This work was supported in part by the Deanship of Scientific Research
   at KFUPM under project No. IN121012.
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   [Anonymous], 1990, DISCRETE COSINE TRAN
   [Anonymous], MULTIMED TOOLS APPL
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Baraniuk RG, 2010, P IEEE, V98, P906, DOI 10.1109/JPROC.2010.2047424
   Becker S, 2011, SIAM J IMAGING SCI, V4, P1, DOI 10.1137/090756855
   Bi X, 2011, SIGNAL PROCESS, V91, P1085, DOI 10.1016/j.sigpro.2010.10.006
   Bobin J, 2008, IEEE J-STSP, V2, P718, DOI 10.1109/JSTSP.2008.2005337
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Candès E, 2007, INVERSE PROBL, V23, P969, DOI 10.1088/0266-5611/23/3/008
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Cen Y, 2010, J COMMUN, V31, P53
   Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498
   Chen C., 2012, P INT C ADV NEUR INF, V25, P1115
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Du M, 2012, COMM COM INF SC, V346, P570
   Fan Yang, 2010, 2010 IEEE International Conference on Intelligent Computing and Intelligent Systems (ICIS 2010), P702, DOI 10.1109/ICICISYS.2010.5658507
   Gan L, 2007, 15 INT C DIG SIGN PR
   Gao ZR, 2013, J VIS COMMUN IMAGE R, V24, P885, DOI 10.1016/j.jvcir.2013.06.006
   Herrmann FJ, 2008, GEOPHYS J INT, V173, P233, DOI 10.1111/j.1365-246X.2007.03698
   Kalra M, 2012, INT CONF SIGN PROCES, P640, DOI 10.1109/ICoSP.2012.6491569
   Lustig M, 2008, IEEE SIGNAL PROC MAG, V25, P72, DOI 10.1109/MSP.2007.914728
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Man H, 2005, MULTIMED TOOLS APPL, V26, P27, DOI 10.1007/s11042-005-6848-5
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Romberg J, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2007.914729
   Sevak M. M., 2012, Proceedings of the 2012 International Conference on Communication Systems and Network Technologies (CSNT 2012), P138, DOI 10.1109/CSNT.2012.39
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang Y, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P373, DOI 10.1109/PCS.2009.5167354
   Yang Y, 2009, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2009.5202443
   Yoon YS, 2008, PROC SPIE, V6968, DOI 10.1117/12.777175
   Zhang J, 2014, 2014 IEEE WORKSHOP ON ELECTRONICS, COMPUTER AND APPLICATIONS, P941, DOI 10.1109/IWECA.2014.6845776
NR 38
TC 42
Z9 48
U1 4
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 6737
EP 6754
DI 10.1007/s11042-015-2590-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400003
DA 2024-07-18
ER

PT J
AU Su, XP
   Peng, JY
   Feng, XY
   Wu, J
AF Su, Xueping
   Peng, Jinye
   Feng, Xiaoyi
   Wu, Jun
TI Labeling faces with names based on the name semantic network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Namesemantic network; Distributed Affinity Propagation (AP); Multi-class
   SVM; Active shape model
AB In this study, we propose a method of labeling faces with names in a large number of news images with captions. Other works explored facial similarities to label faces with names that are sensitive to the intra-person appearance variations, and the captions can offer the cues for the correlations of candidate names. Our method combines textual similarity from image captions with visual similarity of face collections of candidate name to automatically recognize celebrities. It does not require any supervisory inputs. It includes two main steps. Firstly, we build a name semantic network based on textual and visual similarity. Secondly, we apply a name semantic network to label face images with names. We perform experiments on the data set which consists of approximate half a million news images from Yahoo news. The experimental results show that the performance of our method is better than the existing algorithms.
C1 [Su, Xueping; Peng, Jinye; Feng, Xiaoyi; Wu, Jun] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
   [Su, Xueping] Xian Polytech Univ, Coll Comp Sci, Xian, Peoples R China.
C3 Northwestern Polytechnical University; Xi'an Polytechnic University
RP Su, XP (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.; Su, XP (corresponding author), Xian Polytech Univ, Coll Comp Sci, Xian, Peoples R China.
EM yifeichongtian1201@163.com; jinyepeng@nwpu.edu.cn; fengxiao@nwpu.edu.cn;
   junwu@nwpu.edu.cn
RI Peng, Jin/HZH-6965-2023
FU doctorate foundation of Northwestern Polytechnical University
   [CX201114]; Ministry of Education Fund for Doctoral Students Newcomer
   Awards of China; National Natural Science Foundation of China [61075014,
   61272285, 61103062]; Research Fund for the Doctoral Program of Higher
   Education [20106102110028, 20116102110027, 20116102120031,
   20126101110022]; Science and Technology project of Shaanxi Province
   [2013 K06-29]; NPU Basic Research Foundation [JC201249]
FX This work is supported by the doctorate foundation of Northwestern
   Polytechnical University under CX201114, Ministry of Education Fund for
   Doctoral Students Newcomer Awards of China, National Natural Science
   Foundation of China under Grant 61075014, 61272285, 61103062, The
   Research Fund for the Doctoral Program of Higher Education under Grant
   20106102110028, 20116102110027, 20116102120031, 20126101110022, The
   Science and Technology project of Shaanxi Province under Grant 2013
   K06-29, and NPU Basic Research Foundation under Grant JC201249.
CR Berg TL, 2004, PROC CVPR IEEE, P848
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Forsyth, 2005, ADV NEURAL INFORM PR, V17, P137
   Frey B., 2007, MULTI DATABASE RETRI, Vvol. 315, ppp, DOI [DOI 10.1126/SCIENCE.1136800, 10.1126/science.1136800]
   Guillaumin M., 2008, Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition, P1
   Le DD, 2012, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2012.6248025
   Le DD, 2008, IEEE DATA MINING, P383, DOI 10.1109/ICDM.2008.47
   Liu W., 2011, J INF COMPUT SCI, V8, P412
   Liu WF, 2012, INT C PATT RECOG, P1839
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   [鲁伟明 Lu Weiming], 2012, [计算机研究与发展, Journal of Computer Research and Development], V49, P1762
   Medvet E., 2011, 2011 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies, P47, DOI 10.1109/WI-IAT.2011.101
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Ozkan D, 2010, PATTERN RECOGN, V43, P1717, DOI 10.1016/j.patcog.2009.10.015
   Pham PT, 2010, IEEE T MULTIMEDIA, V12, P13, DOI 10.1109/TMM.2009.2036232
   Phi TP, 2010, IEEE INT CON MULTI, P1528, DOI 10.1109/ICME.2010.5583271
   Poppe R, 2012, PATTERN RECOGN, V45, P2335, DOI 10.1016/j.patcog.2011.12.018
   Ratinov L., 2009, Proceedings of the 13th conference on computational natural language learning, P147
   Su XP, 2011, P 3 INT C INT MULT C, P120
   Su XP, 2014, MULTIMED TOOLS APPL, V73, P1643, DOI 10.1007/s11042-013-1578-6
   Xia Z. K., 2014, J SIGNAL PROCESS SYS, P1
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
NR 24
TC 8
Z9 9
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6445
EP 6462
DI 10.1007/s11042-015-2581-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700019
DA 2024-07-18
ER

PT J
AU Arshad, H
   Chowdhury, SA
   Chun, LM
   Parhizkar, B
   Obeidy, WK
AF Arshad, Haslina
   Chowdhury, Shahan Ahmad
   Chun, Lam Meng
   Parhizkar, Behrang
   Obeidy, Waqas Khalid
TI A freeze-object interaction technique for handheld augmented reality
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Handheld augmented reality; Interaction technique; User experiment;
   Touch interaction
AB This paper will present an improved freeze interaction technique in handheld augmented reality. A freeze interaction technique allows users to freeze the augmented view and interact with the virtual content while the camera image is still. In the past, the strength of the freeze interaction technique was that it was able to overcome a shaky view by enabling users to experience a comfortable interaction. However, it froze the whole augmented scene. When a virtual object is updating continuously, the real-world view from the camera remains as a still picture until the user unfreezes the scene, thus reducing the real-time augmented reality experience which, to the user, is not attractive enough. To overcome the current problem, a ` Freeze-Object' interaction technique has been implemented for handheld augmented reality. The Freeze-Object interaction technique allows the user to interact with a frozen virtual object in a live real-world scene. A comparative user study was conducted to evaluate the 'Freeze-Object' interaction technique in a handheld touch AR environment. The Freeze-Object interaction technique was compared with the existing freeze technique in terms of user performance and user preference of the interaction technique. Users were asked to perform three basic manipulation tasks (translation, rotation and scaling) using both interaction techniques. The results indicated that there was a significant difference between both techniques with regard to the translation task and that for the overall tasks, the users preferred the Freeze-Object interaction over the existing freeze interaction technique because the former technique allows users to see live the real-world view with a frozen virtual object. The improved freeze interaction technique can be used for various applications, such as interior design and maintenance.
C1 [Arshad, Haslina; Chowdhury, Shahan Ahmad; Chun, Lam Meng; Obeidy, Waqas Khalid] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Bangi 43600, Selangor, Malaysia.
   [Parhizkar, Behrang] Univ Nottingham Malaysia Campus, Sch Comp Sci, Jalan Broga, Semenyih 43500, Selangor, Malaysia.
C3 Universiti Kebangsaan Malaysia; University of Nottingham Malaysia
RP Arshad, H (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Bangi 43600, Selangor, Malaysia.
EM haslinarshad@gmail.com; bpy_07@yahoo.com; mengchun2020@gmail.com;
   hani.parhizkar@nottingham.edu.my; waquaskhalid@yahoo.com
RI Chun, Lam Meng/H-4105-2019; arshad, haslina/AAF-8737-2019
OI Chun, Lam Meng/0000-0002-9435-9473; Chowdhury, Shahan
   Ahmad/0000-0003-3372-6572
FU Ministry of Education Malaysia (MOE) [FRGS/1/2013/IC701/UKM/0219]
FX This work was supported by Ministry of Education Malaysia (MOE) under
   Grant no. FRGS/1/2013/IC701/UKM/0219.
CR Abawi DF, 2004, 1 EUR C VIS MED PROD, P289
   Arth C., 2011, ISMAR 2011 WORKSH EN
   Bai H., 2012, P 13 INT C NZ CHAPT, P101
   Bai H., 2012, Proc. 27th Conf. Image Vis. Comput. New Zeal. - IVCNZ '12, P126, DOI [10.1145/2425836.2425864, DOI 10.1145/2425836.2425864]
   Boring S, 2010, P SIGCHI C HUM FACT
   de Sa M, 2012, MOBILEHCI '12: COMPANION PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON HUMAN COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES, P225
   Gervautz M, 2012, COMPUTER, V45, P26, DOI 10.1109/MC.2012.72
   Guven Sinem, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P235, DOI 10.1109/ISMAR.2006.297821
   Henrysson A, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P187
   Hürst W, 2011, LECT NOTES COMPUT SC, V6524, P157
   Koceski S., 2011, Proceedings of the 2011 International Conference on User Science and Engineering (i-USEr 2011), P245, DOI 10.1109/iUSEr.2011.6150574
   Kurkovsky S., 2012, 2012 International Conference on Communications and Information Technology (ICCIT), P68, DOI 10.1109/ICCITechnol.2012.6285844
   Langlotz T, 2012, PERS UBIQUIT COMPUT, V16, P623, DOI 10.1007/s00779-011-0430-0
   Lee G. A., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P245, DOI 10.1109/ISMAR.2011.6092398
   Lee G.A., 2009, P 16 ACM S VIRTUAL R, P143
   Liu TY, 2010, LECT NOTES COMPUT SC, V5960, P37, DOI 10.1007/978-3-642-12349-8_3
   Mossel A., 2013, INT J VIRTUAL REAL, P1
   Robertson G. G., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P149, DOI 10.1145/263407.263535
   Schmalstieg D., 2012, 2012 IEEE Virtual Reality Workshops (VRW), P1
   Van Olst R, 2012, THESIS UTRECHT U
NR 20
TC 7
Z9 9
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5819
EP 5839
DI 10.1007/s11042-015-2543-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600022
DA 2024-07-18
ER

PT J
AU Deebak, BD
   Muthaiah, R
   Thenmozhi, K
   Swaminathan, PI
AF Deebak, Bakkiam David
   Muthaiah, Rajappa
   Thenmozhi, Karuppuswamy
   Swaminathan, Pitchai Iyer
TI Analyzing three-party authentication and key agreement protocol for real
   time IP multimedia server-client systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Three party authentication and key agreement; IP multimedia server and
   client systems; Bandwidth consumption; Signal congestion; End-to-end
   voice call delay and clock synchronization
ID EXCHANGE; EFFICIENT; CRYPTANALYSIS
AB Authenticated key agreement (AKA) is useful to preserve the secret (private) key for the data being transmitted over an insecure Thus, this paper proposes the strategies, such as short-term and long-term private keys for the three party authentication and key agreement (3PAKA) protocol. Recently, the IP Multimedia server and client systems have been sprung up for the Telecom Industry, though the systems have not had any proficient authentication mechanism for the fulfillment of security properties and mitigation of signal congestion, bandwidth consumption and end-to-end voice call delay. To address this issue, we present a novel 3PAKA that duplicates the long-term and short-term private keys to alleviate the signal congestion of the multimedia systems. It is then analyzed in the real time multimedia serverclient systems to examine the metrics realistically. Besides, we employ the strategy of random Challenge-Response (CR) technique to declare the clock synchronization as invalid.
C1 [Deebak, Bakkiam David; Muthaiah, Rajappa; Swaminathan, Pitchai Iyer] SASTRA Univ, Sch Comp, Thanjavur 613401, TN, India.
   [Thenmozhi, Karuppuswamy] SASTRA Univ, Sch Elect & Elect, Thanjavur 613401, TN, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Deebak, BD (corresponding author), SASTRA Univ, Sch Comp, Thanjavur 613401, TN, India.
EM jrvd_deebak@ymail.com; sjamuthaiah@core.sastra.edu;
   thenmozhik@ece.sastra.edu; deanpsw@sastra.edu
RI B D, Deebak/ABC-5122-2022; Bakkiam David, Deebak/B-2795-2014
OI Bakkiam David, Deebak/0000-0002-4008-6350; Karuppuswamy,
   Thenmozhi/0000-0001-9829-0189; Rajappa, Muthaiah/0000-0002-6659-1961
FU Tata Consultancy Services; SASTRA
FX The corresponding author would like to thank Tata Consultancy Services
   and SASTRA for the financial assistance under the scheme of Research
   Scholar Program (RSP).
CR Abdalla M, 2005, LECT NOTES COMPUT SC, V3386, P65
   Abdalla M, 2005, LECT NOTES COMPUT SC, V3376, P191
   [Anonymous], 1993, ACM CCS 1993, DOI DOI 10.1145/168588.168596
   [Anonymous], ADV CRYPTOLOGYCRYPTO
   Awasthi AK, 2003, IEEE T CONSUM ELECTR, V49, P1246, DOI 10.1109/TCE.2003.1261225
   Bellovin S. M., 1990, Computer Communication Review, V20, P119, DOI 10.1145/381906.381946
   Byun JW, 2006, LECT NOTES COMPUT SC, V3841, P830
   Chang C., 2008, P 2 INTERNATIONALCON, P329
   Chang TY, 2011, INFORM SCIENCES, V181, P217, DOI 10.1016/j.ins.2010.08.032
   Chien HY, 2011, J INF SCI ENG, V27, P1487
   Chun-Li Lin, 2000, Operating Systems Review, V34, P12, DOI 10.1145/506106.506108
   Diffie W., 1992, Designs, Codes and Cryptography, V2, P107, DOI 10.1007/BF00124891
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Ding Y., 1995, Operating Systems Review, V29, P77, DOI 10.1145/219282.219298
   Farash MS, 2014, NONLINEAR DYNAM, V77, P399, DOI 10.1007/s11071-014-1304-6
   Gaarder K., 1991, Journal of Cryptology, V3, P81, DOI 10.1007/BF00196790
   GONG L, 1993, IEEE J SEL AREA COMM, V11, P648, DOI 10.1109/49.223865
   Gong L., 1993, P 1 ACM C COMPUTER C, P26, DOI [10.1145/168588.168592, DOI 10.1145/168588.168592]
   Guo H, 2008, COMPUT SECUR, V27, P16, DOI 10.1016/j.cose.2008.03.001
   Hwang MS, 2000, IEEE T CONSUM ELECTR, V46, P28, DOI 10.1109/30.826377
   Jablon DP, 1997, SIXTH IEEE WORKSHOPS ON ENABLING TECHNOLOGIES: INFRASTRUCTURE FOR COLLABORATIVE ENTERPRISES, PROCEEDINGS, P248, DOI 10.1109/ENABL.1997.630822
   Jaung WS, 2004, IEEE T CONSUM ELECTR, V50, P619, DOI 10.1109/TCE.2004.1309439
   Katz J, 2001, LECT NOTES COMPUT SC, V2045, P475
   Katz J, 2007, INTRO MODERN CRYPTOG, P476
   Keung S., 1995, Proceedings Fourth International Conference on Computer Communications and Networks (ICCCN'95) (Cat. No.95TB8110), P105, DOI 10.1109/ICCCN.1995.540108
   Ku WC, 2004, IEEE T CONSUM ELECTR, V50, P204, DOI 10.1109/TCE.2004.1277863
   Kwon T, 1998, IEICE T FUND ELECTR, VE81A, P156
   Kwon T, 1999, IEICE T COMMUN, VE82B, P991
   Kwon T, 1998, IEE P-COMMUN, V145, P304, DOI 10.1049/ip-com:19982282
   Law L, 2003, DESIGN CODE CRYPTOGR, V28, P119, DOI 10.1023/A:1022595222606
   Lee TF, 2010, INFORM SCIENCES, V180, P1702, DOI 10.1016/j.ins.2010.01.005
   Li Gong, 1995, Proceedings. The Eighth IEEE Computer Security Foundations Workshop (Cat. No.95TB8076), P24, DOI 10.1109/CSFW.1995.518549
   Li XX, 2010, IEEE T IND ELECTRON, V57, P793, DOI 10.1109/TIE.2009.2028351
   Lin CL, 2001, IEEE COMMUN LETT, V5, P497, DOI 10.1109/4234.974498
   Lou DC, 2011, INT J COMMUN SYST, V24, P504, DOI 10.1002/dac.1172
   Lu RX, 2007, COMPUT SECUR, V26, P94, DOI 10.1016/j.cose.2006.08.005
   LUCKS S, 1997, P SEC PROT WORKSH 97, P79
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Nisan N, 1991, P 23 ANN ACM S THEOR, P419
   PHAN RC, 2006, LNCS, P104
   Pu Q, 2013, PEER PEER NETW APPL, V6, P15, DOI 10.1007/s12083-012-0125-y
   Steiner M., 1995, Operating Systems Review, V29, P22, DOI 10.1145/206826.206834
   Sun HM, 2000, IEEE T CONSUM ELECTR, V46, P958, DOI 10.1109/30.920446
   Tallapally S, 2012, INF TECHNOL CONTROL, V41, P15, DOI 10.5755/j01.itc.41.1.842
   Toldinas J, 2010, ELEKTRON ELEKTROTECH, P57
   Tso R, 2013, J SUPERCOMPUT, V66, P863, DOI 10.1007/s11227-013-0917-8
   WANG WJ, 2006, LNCS, P118
   Wu SH, 2013, INT ARAB J INF TECHN, V10, P215
   Wu SH, 2012, INFORM SCIENCES, V215, P83, DOI 10.1016/j.ins.2012.06.005
   Yang YJ, 2009, 25TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, P199, DOI 10.1109/ACSAC.2009.26
   Yang YJ, 2006, IEEE T DEPEND SECURE, V3, P105, DOI 10.1109/TDSC.2006.16
   Yin Y, 2006, LECT NOTES COMPUT SC, V4058, P395
   Yoon EJ, 2007, LECT NOTES COMPUT SC, V4809, P758
NR 53
TC 8
Z9 8
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5795
EP 5817
DI 10.1007/s11042-015-2542-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600021
DA 2024-07-18
ER

PT J
AU Davarzani, R
   Mozaffari, S
   Yaghmaie, K
AF Davarzani, Reza
   Mozaffari, Saeed
   Yaghmaie, Khashayar
TI Perceptual image hashing using center-symmetric local binary patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Center-symmetric local binary patterns; Perceptual image hashing;
   Singular value decomposition (SVD); Tamper detection
ID ROBUST; SECURE; CLASSIFICATION; SCALE
AB Perceptual image hashing finds increasing attention in several multimedia security applications such as image identification/authentication, tamper detection, and watermarking. Robust feature extraction is the main challenge in hashing schemes. Local binary pattern (LBP) is a new feature which is due to its simplicity, discriminative power, computational efficiency, and robustness to illumination changes has been used in various image applications. In this paper, we propose a robust image hashing scheme using center-symmetric local binary patterns (CSLBP). In the proposed image hashing, CSLBP features are extracted from each non-overlapping block within the original gray-scale image. For each block, the final hash code is obtained by inner product of its CSLBP feature vector and a pseudorandom weight vector. Furthermore, singular value decomposition (SVD) is combined with CSLBP to introduce a more robust hashing method called SVD-CSLBP. Performances of the proposed hashing schemes are evaluated with two groups of popular applications in perceptual image hashing schemes: image identification and image authentication. Experimental results show that the proposed methods are robust to a wide range of distortions and attacks such as additive noise, blurring, brightness changes and JPEG compression. Moreover, the proposed methods have this capability to localize the tampering area, which is not possible in all hashing schemes.
C1 [Davarzani, Reza; Mozaffari, Saeed; Yaghmaie, Khashayar] Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
C3 Semnan University
RP Mozaffari, S (corresponding author), Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
EM mozaffari@semnan.ac.ir
RI Davarzani, Reza/AAN-7320-2021
OI Davarzani, Reza/0000-0001-6442-0010; zy, P/0009-0006-2820-8788
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Corel, 2001, TEST SET
   Cox Ingemar, 2008, DIGITAL WATERMARKING, V2
   Davarzani R, 2015, SIGNAL PROCESS, V111, P274, DOI 10.1016/j.sigpro.2014.11.005
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fridrich J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P178, DOI 10.1109/ITCC.2000.844203
   Guo XC, 2007, LECT NOTES COMPUT SC, V4810, P755
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Kozat SS, 2004, IEEE IMAGE PROC, P3443, DOI 10.1109/ICIP.2004.1421855
   Lefbvre F, 2002, RASH RADON SOFT HASH
   Lei YQ, 2011, SIGNAL PROCESS-IMAGE, V26, P280, DOI 10.1016/j.image.2011.04.007
   Li W, 2012, THESIS KATHOLIEKE U, P208
   Li Z, 2012, IEEE T IMAGE PROCESS, V21, P2130, DOI 10.1109/TIP.2011.2173697
   Lin CY, 2001, IEEE T CIRC SYST VID, V11, P153, DOI 10.1109/76.905982
   Liu W., 2011, J INF COMPUT SCI, V8, P412
   Lv XD, 2012, IEEE T INF FOREN SEC, V7, P1081, DOI 10.1109/TIFS.2012.2190594
   Monga V, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P229, DOI 10.1109/ICME.2005.1521402
   Monga V, 2005, ELECT COMPUTER ENG E, P120
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Ng T T, 2005, 20320043 ADVENT COL
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikainen M, 2011, COMPUTER VISION USIN, pE1
   Qin C, 2013, DIGIT SIGNAL PROCESS, V23, P578, DOI 10.1016/j.dsp.2012.11.002
   Rivest R., 1992, Tech. Rep.
   Roover C. D., 2005, P 12 INT C IM PROC, V3
   Roy S, 2007, IEEE IMAGE PROC, P2913
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Sun R, 2014, MULTIMED TOOLS APPL, V70, P1651, DOI 10.1007/s11042-012-1188-8
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Tang ZJ, 2011, MULTIMED TOOLS APPL, V52, P325, DOI 10.1007/s11042-009-0437-y
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Wang Shuo-zhong, 2007, Journal of Shanghai University, V11, P323, DOI 10.1007/s11741-007-0401-2
   Wu M, 2007, 2007 IEEE/SP 14TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2, P166
   Xudong Lv, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P725, DOI 10.1109/MMSP.2008.4665170
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
NR 41
TC 68
Z9 74
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4639
EP 4667
DI 10.1007/s11042-015-2496-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700023
DA 2024-07-18
ER

PT J
AU Baniya, BK
   Lee, J
AF Baniya, Babu Kaji
   Lee, Joonwhoan
TI Importance of audio feature reduction in automatic music genre
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music genres; Dimensionality; Locality preserving projection;
   Non-negative matrix factorization
ID INFORMATION; RETRIEVAL
AB Multimedia database retrieval is rapidly growing and its popularity in online retrieval systems is consequently increasing. Large datasets are major challenges for searching, retrieving, and organizing the music content. Therefore, a robust automatic music-genre classification method is needed for organizing this music data into different classes according to specific viable information. Two fundamental components are to be considered for genre classification: audio feature extraction and classifier design. In this paper, we propose diverse audio features to precisely characterize the music content. The feature sets belong to four groups: dynamic, rhythmic, spectral, and harmonic. From the features, five statistical parameters are considered as representatives, including the fourth-order central moments of each feature as well as covariance components. Ultimately, insignificant representative parameters are controlled by minimum redundancy and maximum relevance. This algorithm calculates the score level of all feature attributes and orders them. Only high-score audio features are considered for genre classification. Moreover, we can recognize those audio features and distinguish which of the different statistical parameters derived from them are important for genre classification. Among them, mel frequency cepstral coefficient statistical parameters, such as covariance components and variance, are more frequently selected than the feature attributes of other groups. This approach does not transform the original features as do principal component analysis and linear discriminant analysis. In addition, other feature reduction methodologies, such as locality-preserving projection and non-negative matrix factorization are considered. The performance of the proposed system is measured based on the reduced features from the feature pool using different feature reduction techniques. The results indicate that the overall classification is competitive with existing state-of-the-art frame-based methodologies.
C1 [Baniya, Babu Kaji; Lee, Joonwhoan] Chonbuk Natl Univ, Dept Comp Sci & Engn, Jeonju 561756, South Korea.
C3 Jeonbuk National University
RP Lee, J (corresponding author), Chonbuk Natl Univ, Dept Comp Sci & Engn, Jeonju 561756, South Korea.
EM everwith_7@jbnu.ac.kr; chlee@jbnu.ac.kr
FU Chonbuk National University; National Research Foundation of Korea -
   Korean government [2011-0022152]
FX This paper was supported by research funds of Chonbuk National
   University in 2013 and also partially supported by the National Research
   Foundation of Korea grant funded by the Korean government
   (2011-0022152).
CR [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2007, MIR MATLAB
   [Anonymous], P INT C AC SPEECH SI
   [Anonymous], 2012, P AAAI C ART INT
   Baniya B. K., 2013, P IEEE WORKSH SIGN P
   Baniya BK, 2014, INT CONF ADV COMMUN, P96, DOI 10.1109/ICACT.2014.6778929
   Benetos E., 2008, P EUR SIGN PROC C LA
   Bergstra J, 2006, MACH LEARN, V65, P473, DOI 10.1007/s10994-006-9019-7
   Casey MA, 2008, P IEEE, V96, P668, DOI 10.1109/JPROC.2008.916370
   Cortes C., 1995, J MACH LEARN
   Dowling W.J., 1986, MUSIC COGNITION
   GROENEVELD RA, 1984, STATISTICIAN, V33, P391, DOI 10.2307/2987742
   He XF, 2004, ADV NEUR IN, V16, P153
   Li T, 2003, P 26 ANN INT ACM SIG, P282, DOI [DOI 10.1145/860435.860487, 10.1145/860484.860487, DOI 10.1145/860484.860487]
   Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65
   Lidy T, 2007, MUSIC INFORMATION RE
   Lim SC, 2012, IEEE T CONSUM ELECTR, V58, P1262, DOI 10.1109/TCE.2012.6414994
   Peng H., 2004, 36 S INT COMP BIOL B
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Seo JS, 2011, SIGNAL PROCESS, V91, P2154, DOI 10.1016/j.sigpro.2011.03.019
   Shen J, 2010, P ACMSIGIR
   Shen JL, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P455, DOI 10.1145/2348283.2348346
   Smith L.I., 2002, Statistics
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Tzanetakis G., 2001, P INT S MUSIC INFORM, P205
   Welling M., 2000, TECHNICAL REPORT
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
   Xu CS, 2005, IEEE T SPEECH AUDI P, V13, P441, DOI 10.1109/TSA.2004.840939
NR 29
TC 13
Z9 13
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3013
EP 3026
DI 10.1007/s11042-014-2418-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600005
DA 2024-07-18
ER

PT J
AU Chen, YL
   Chang, MF
   Liang, WY
AF Chen, Yen-Lin
   Chang, Ming-Feng
   Liang, Wen-Yew
TI Energy-efficient video decoding schemes for embedded handheld devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DVFS; Embedded platform; Portable devices; Low power software design
ID DYNAMIC VOLTAGE; POWER MANAGEMENT; SYSTEM
AB Dynamic voltage and frequency scaling (DVFS) is an effective technique for reducing power consumption. Because of the increasing popularity of multimedia applications for portable consumer electronic devices, the importance of reducing their power consumption has become crucial. This paper proposes a table-based DVFS mechanism for frame decoding that can effectively reduce the power consumption of a processor by exploiting the frame-decoding complexity features. This proposed table-based DVFS predictor requires no prior knowledge on video decoders, and can be flexibly applied on different video codecs. This study implemented the table-based DVFS predictor on the PXA270 embedded platform and all benchmarks were encoded into various video coding formats, including H.264, VP8 and WMV formats. In addition, the proposed DVFS predictor was also ported on a modern platform NVIDIA JETSON TK1, and has demonstrated that the proposed algorithm can provide significant energy saving performance on high definition (HD) videos. The experimental results demonstrate that the energy consumption of decoding videos can be reduced from 6 to 21 %, whereas the frame drop rate is less than 3 %.
C1 [Chen, Yen-Lin; Chang, Ming-Feng; Liang, Wen-Yew] Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
C3 National Taipei University of Technology
RP Chen, YL (corresponding author), Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
EM ylchen@csie.ntut.edu.tw
OI Chen, Yen-Lin/0000-0001-7717-9393
FU Ministry of Science and Technolgy of the Republic of China
   [MOST-103-2221-E-027-061]
FX This study was supported by the Ministry of Science and Technolgy of the
   Republic of China (Contract No. MOST-103-2221-E-027-061). The authors
   express their gratitude to Prof. Chin-Feng Lai at National Chung Cheng
   University for his valuable suggestions on this study.
CR [Anonymous], P INT S COMP ARCH
   [Anonymous], P ACM S RES APPL COM
   [Anonymous], FT DVFS OPEN SOURCE
   [Anonymous], ACM SPIE MULTIMEDIA
   [Anonymous], P IEEE REAL TIM EMB
   [Anonymous], JETS TK1 DEV KIT
   Asaduzzaman A, 2014, MULTIMED TOOLS APPL, V72, P207, DOI 10.1007/s11042-012-1350-3
   Bankoski J, 2011, IEEE INT CON MULTI
   Barnes RD, 2002, INT SYMP MICROARCH, P233, DOI 10.1109/MICRO.2002.1176253
   Choi J, 2006, IEE P-COMPUT DIG T, V153, P130, DOI 10.1049/ip-cdt:20050031
   Choi J, 2010, IET COMPUT DIGIT TEC, V4, P400, DOI 10.1049/iet-cdt.2008.0074
   Choi K, 2005, IEEE T COMPUT AID D, V24, P18, DOI 10.1109/TCAD.2004.839485
   Choi KW, 2002, IEEE/ACM INTERNATIONAL CONFERENCE ON CAD-02, DIGEST OF TECHNICAL PAPERS, P732, DOI 10.1109/ICCAD.2002.1167613
   Contreras G, 2005, ISLPED '05: Proceedings of the 2005 International Symposium on Low Power Electronics and Design, P221, DOI 10.1109/LPE.2005.195518
   Gao HL, 2012, MULTIMED TOOLS APPL, V56, P597, DOI 10.1007/s11042-010-0628-6
   Isci C, 2006, INT SYMP MICROARCH, P359
   Jha NK, 2005, IEE P-COMPUT DIG T, V152, P344, DOI 10.1049/ip-cdt:20045067
   Lee B, 2005, J SYST ARCHITECT, V51, P633, DOI 10.1016/j.sysarc.2005.01.002
   Liang WY, 2008, RTCSA 2008: 14TH IEEE INTERNATIONAL CONFERENCE ON EMBEDDED AND REAL-TIME COMPUTING SYSTEMS AND APPLICATIONS - PROCEEDINGS, P229, DOI 10.1109/RTCSA.2008.19
   Liang WY, 2013, IEEE ICCE, P344, DOI 10.1109/ICCE.2013.6486921
   Ma Z, 2011, IEEE T MULTIMEDIA, V13, P1240, DOI 10.1109/TMM.2011.2165056
   Pallipadi V., 2006, Proceedings of the Linux Symposium, V2, P215
   Park SO, 2012, IET COMMUN, V6, P1407, DOI 10.1049/iet-com.2011.0727
   Poellabauer C, 2005, RTAS 2005: 11th IEEE Real Time and Embedded Technology and Applications Symposium, Proceedings, P234
   Pouwelse J., 2001, P ACM MOBICOM, P251, DOI DOI 10.1145/381677.381701
   SAKURAI T, 1990, IEEE J SOLID-ST CIRC, V25, P584, DOI 10.1109/4.52187
   Sherwood T, 2003, CONF PROC INT SYMP C, P336, DOI 10.1109/ISCA.2003.1207012
   Snowdon Dave, 2007, WORKSH OP SYST PLATF, P58
   Snowdon DavidC., 2007, P 7 ACM IEEE INT C E, P84
   Weissel A., 2006, Proceedings of the Second International Workshop on Software Support for Portable Storage (IWSSPS 2006), P33
   Xia F, 2008, IET COMPUT DIGIT TEC, V2, P377, DOI 10.1049/iet-cdt:20070112
NR 31
TC 3
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3281
EP 3300
DI 10.1007/s11042-014-2435-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600017
DA 2024-07-18
ER

PT J
AU Xu, BH
   Cen, YG
   Wei, Z
   Cen, Y
   Zhao, RZ
   Miao, ZJ
AF Xu, Bo-Hua
   Cen, Yi-Gang
   Wei, Zhe
   Cen, Yi
   Zhao, Rui-Zhen
   Miao, Zhen-Jiang
TI Video restoration based on PatchMatch and reweighted low-rank matrix
   recovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE A Video restoration; Denoising; PatchMatch; Reweighted low-rank matrix
   recovery
ID IMAGE
AB In this paper, a new video restoration approach is proposed. By using a modified version of random PatchMatch algorithm, nearest-neighbor patches among the video frames can be grouped quickly and accurately. Then the video restoration problem can be boiled down to a low-rank matrix recovery problem, which is able to separate sparse errors from matrices that possess potential low-rank structures. Furthermore, the reweighted low-rank matrix model is used to improve the performance of video restoration by enhancing the sparsity of the sparse matrix and the low-rank property of the low-rank matrix. Experimental results show that our system achieves good performance in denosing of joint multi-frames and inpainting in the presence of small damaged areas.
C1 [Xu, Bo-Hua; Cen, Yi-Gang; Zhao, Rui-Zhen; Miao, Zhen-Jiang] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
   [Xu, Bo-Hua; Cen, Yi-Gang; Zhao, Rui-Zhen; Miao, Zhen-Jiang] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
   [Wei, Zhe] Huawei Int Pte Ltd, Singapore 117674, Singapore.
   [Cen, Yi] Minzu Univ China, Sch Informat Engn, Beijing 100081, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University; Huawei
   Technologies; Minzu University of China
RP Cen, YG (corresponding author), Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
EM ygcen@bjtu.edu.cn
RI Cen, Yigang/AAC-1999-2019
FU National Natural Science Foundation of China [61272028, 61473317,
   61273274]; Fundamental Research Funds for the Central Universities of
   China [2013JBZ003]; Specialized Research Fund for the Doctoral Program
   of Higher Education of China [20120009110008]; Program for New Century
   Excellent Talents in University [NCET-12-0768]; National Key Technology
   R&D Program of China [2012BAH01F03]; National Basic Research (973)
   Program of China [2011CB302203]; National High Technology Research and
   Development Program (863) of China [2014AA015202]; Program for
   Changjiang Scholars and Innovative Research Team in University
   [IRT201206]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61272028, 61473317, 61273274); Fundamental Research
   Funds for the Central Universities of China (Grant No. 2013JBZ003);
   Specialized Research Fund for the Doctoral Program of Higher Education
   of China (Grant No. 20120009110008); Program for New Century Excellent
   Talents in University (Grant No. NCET-12-0768); National Key Technology
   R&D Program of China (Grant No. 2012BAH01F03); National Basic Research
   (973) Program of China (Grant No. 2011CB302203); The National High
   Technology Research and Development Program (863) of China (Grant No.
   2014AA015202); Program for Changjiang Scholars and Innovative Research
   Team in University (Grant no. IRT201206).
CR Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Cen YG, 2014, SCI CHINA INFORM SCI, V57, DOI 10.1007/s11432-013-4855-0
   Cen YG, 2013, J APPL MATH, DOI 10.1155/2013/864132
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Dabov K., 2007, Proc. 15th European Signal Processing Conference, V1, P7
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Hou Junhui., 2014, 2014 IEEE International Conference on Multimedia and Expo (ICME), P1
   Ji H, 2011, SIAM J IMAGING SCI, V4, P1122, DOI 10.1137/100817206
   Lin, 2010, ARXIV10095055
   Liu B, 1993, IEEE T CIRC SYST VID, V3, P148, DOI 10.1109/76.212720
   Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509
   Peng YG, 2010, PROC CVPR IEEE, P763, DOI 10.1109/CVPR.2010.5540138
   Toh KC, 2010, PAC J OPTIM, V6, P615
   Wang HY, 2014, NEUROCOMPUTING, V145, P374, DOI 10.1016/j.neucom.2014.05.021
   Yigang Peng, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P315, DOI 10.1007/978-3-319-04114-8_27
NR 19
TC 5
Z9 5
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2681
EP 2696
DI 10.1007/s11042-015-2545-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000018
DA 2024-07-18
ER

PT J
AU Shirahama, K
   Grzegorzek, M
AF Shirahama, Kimiaki
   Grzegorzek, Marcin
TI Towards large-scale multimedia retrieval enriched by knowledge about
   human interpretation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Large-scale multimedia retrieval; Human-machine cooperation;
   Machine-based methods; Human-based methods
ID RELEVANCE FEEDBACK; IMAGE RETRIEVAL; EVENT DETECTION; SEARCH METHOD;
   VIDEO DATA; OBJECT; QUERY; INFORMATION; DISCOVERY; FRAMEWORK
AB Recent Large-Scale Multimedia Retrieval (LSMR) methods seem to heavily rely on analysing a large amount of data using high-performance machines. This paper aims to warn this research trend. We advocate that the above methods are useful only for recognising certain primitive meanings, knowledge about human interpretation is necessary to derive high-level meanings from primitive ones. We emphasise this by conducting a retrospective survey on machine-based methods which build classifiers based on features, and human-based methods which exploit user annotation and interaction. Our survey reveals that due to prioritising the generality and scalability for large-scale data, knowledge about human interpretation is left out by recent methods, while it was fully used in classical methods. Thus, we defend the importance of human-machine cooperation which incorporates the above knowledge into LSMR. In particular, we define its three future directions (cognition-based, ontology-based and adaptive learning) depending on types of knowledge, and suggest to explore each direction by considering its relation to the others.
C1 [Shirahama, Kimiaki; Grzegorzek, Marcin] Univ Siegen, Pattern Recognit Grp, D-57076 Siegen, Germany.
C3 Universitat Siegen
RP Shirahama, K (corresponding author), Univ Siegen, Pattern Recognit Grp, Hoelderlinstr 3, D-57076 Siegen, Germany.
EM kimiaki.shirahama@uni-siegen.de; marcin.grzegorzek@uni-siegen.de
RI Grzegorzek, Marcin/AAF-1647-2021
OI Grzegorzek, Marcin/0000-0003-4877-8287
CR Adams B, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P283, DOI 10.1109/ICIP.2000.899358
   Alham NK, 2011, COMPUT MATH APPL, V62, P2801, DOI 10.1016/j.camwa.2011.07.046
   Anderson ML, 2007, AI MAG, V28, P7
   Ando R., 2006, PROC 8 ACM INT WORKS, P99
   [Anonymous], P TREC VID RETR EV T
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], 2004, PRACTICAL GUIDE BUIL
   [Anonymous], P 21 ACM INT C MULT
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2007, IEEE C COMP VIS PATT
   [Anonymous], 2012, Proceedings of the 21st International Conference on World Wide Web
   [Anonymous], 2009, P ADV NEUR INF PROC
   [Anonymous], 2007, NIPS
   [Anonymous], 2010, ACM Sigkdd Explorations Newsletter
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Ayache S, 2008, LECT NOTES COMPUT SC, V4956, P187
   Barrett S, 2009, IEEE INT CON MULTI, P838, DOI 10.1109/ICME.2009.5202625
   Barrington L., 2009, PROC ACM SIGKDD WORK, P7
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bell M, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P123
   Bengio Y., 2009, P 26 ANN INT C MACH, V60, P6, DOI [DOI 10.1145/1553374.1553380, 10.1145/1553374.1553380]
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bensusan H, 2000, P ILP 2000
   Bhatt CA, 2011, MULTIMED TOOLS APPL, V51, P35, DOI 10.1007/s11042-010-0645-5
   Biswas A, 2013, PROC CVPR IEEE, P644, DOI 10.1109/CVPR.2013.89
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Catanzaro B., 2008, P 25 INT C MACHINE L, P104, DOI DOI 10.1145/1390156.1390170
   Chai Y, 2013, IEEE I CONF COMP VIS, P321, DOI 10.1109/ICCV.2013.47
   Chen XL, 2013, IEEE I CONF COMP VIS, P1409, DOI 10.1109/ICCV.2013.178
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Denoeux T, 2013, IEEE T KNOWL DATA EN, V25, P119, DOI 10.1109/TKDE.2011.201
   Djordjevic Divna, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P718
   Fan RE, 2005, J MACH LEARN RES, V6, P1889
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   François ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87
   Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355
   Gao TS, 2011, IEEE I CONF COMP VIS, P2072, DOI 10.1109/ICCV.2011.6126481
   GEMMELL DJ, 1995, COMPUTER, V28, P40, DOI 10.1109/2.384117
   Guadarrama S, 2013, IEEE I CONF COMP VIS, P2712, DOI 10.1109/ICCV.2013.337
   Hamzaoui A, 2014, MULTIMED TOOLS APPL, V68, P429, DOI 10.1007/s11042-012-1340-5
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   HongJiang Zhang, 1994, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.94TH0631-2), P45, DOI 10.1109/MMCS.1994.292432
   Hsieh C. J., 2008, P 25 INT C MACH LEAR, P408
   ImageNet, 2012, IMAGENET LARGE SCALE
   Inoue N, 2012, IEEE T MULTIMEDIA, V14, P1196, DOI 10.1109/TMM.2012.2191395
   Izquierdo E, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING WORKSHOPS, PROCEEDINGS, P131, DOI 10.1109/ICIAPW.2007.32
   Jain AK, 1999, MULTIMEDIA SYST, V7, P369, DOI 10.1007/s005300050139
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jia D, 2011, PROC CVPR IEEE, P785, DOI 10.1109/CVPR.2011.5995516
   Jiang YG, 2013, INT J MULTIMED INF R, V2, P73, DOI 10.1007/s13735-012-0024-2
   Jiang YG, 2009, IEEE I CONF COMP VIS, P1420, DOI 10.1109/ICCV.2009.5459295
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124
   Karsch K, 2012, LECT NOTES COMPUT SC, V7576, P775, DOI 10.1007/978-3-642-33715-4_56
   Kashino K, 2003, IEEE T MULTIMEDIA, V5, P348, DOI 10.1109/TMM.2003.813281
   Kim YT, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P68
   Kittur A, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P453
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krüger N, 2013, IEEE T PATTERN ANAL, V35, P1847, DOI 10.1109/TPAMI.2012.272
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Lan T, 2013, IEEE I CONF COMP VIS, P369, DOI 10.1109/ICCV.2013.53
   Le Q, 2012, P ICML 2012
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li J, 2010, INT J COMPUT VISION, V90, P150, DOI 10.1007/s11263-010-0354-6
   Li Xirong., 2007, P 6 ACM INT C IMAGE, P603
   Lin CY, 2003, P TRECVID 2003
   Litayem S, 2012, P BMVC 2012, P861
   Liu Xiaoming., 1999, P ACM INT C MULTIMED, P41, DOI [10.1145/319878.319889, DOI 10.1145/319878.319889]
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Maji S., 2008, CVPR
   Maji S, 2014, INT J COMPUT VISION, V108, P82, DOI 10.1007/s11263-014-0716-6
   Marszalek Marcin, 2007, CVPR '07. IEEE Conference on Computer Vision and Pattern Recognition, P1
   Mazloom M., 2013, Proceedings of the ACM Multimedia Conference, MM'13, P609
   Merler M, 2012, IEEE T MULTIMEDIA, V14, P88, DOI 10.1109/TMM.2011.2168948
   Monaco James., 1981, HOW TO READ A FILM
   Nam J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P353, DOI 10.1109/ICIP.1998.723496
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Naphade MilindR., 2004, P 12 ANN ACM INT C M, P660, DOI DOI 10.1145/1027527.1027680
   Natsev A., 2005, 13th Annual ACM International Conference on Multimedia, P598, DOI 10.1145/1101149.1101288
   Natsev Apostol., 2007, MULTIMEDIA 07, P991
   Ngo C.W., 2009, Proc. of TRECVID, P415
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Ogiela MR, 2010, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT AND SOFTWARE INTENSIVE SYSTEMS (CISIS 2010), P851, DOI 10.1109/CISIS.2010.49
   Oh J, 2002, P MDM KDD 2002, P23
   OOMOTO E, 1993, IEEE T KNOWL DATA EN, V5, P629, DOI 10.1109/69.234775
   Pan JY, 2001, P JOINT C DIG LIB JC, P116
   Parkash A, 2012, LECT NOTES COMPUT SC, V7574, P354, DOI 10.1007/978-3-642-33712-3_26
   Pattanasri N, 2005, LECT NOTES COMPUT SC, V3815, P119
   Pawan Kumar M., 2010, NIPS
   Peng YX, 2005, LECT NOTES COMPUT SC, V3568, P71
   Perronnin F., 2007, P IEEE CVPR, P1
   Petkovic M., 2002, CONTENT BASED VIDEO
   Quinn AJ, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1403
   Rasiwasia N, 2007, IEEE T MULTIMEDIA, V9, P923, DOI 10.1109/TMM.2007.900138
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Scherp A, 2014, MULTIMED TOOLS APPL, V70, P7, DOI 10.1007/s11042-013-1427-7
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Schoeffmann K, 2014, INT J MULTIMED INF R, V3, P113, DOI 10.1007/s13735-013-0050-8
   Shirahama K, 2008, INT J HYBRID INF TEC, V1, P21
   Shirahama K, 2014, MULTIMEDIA DATA MINI
   Shirahama K, 2013, P MMEDIA 2013, P19
   Shirahama K, 2014, P ICMR 2014, P9
   Shirahama K., 2007, BOOK MULTIMEDIA DATA, P404
   Shirahama K, 2012, MULTIMED TOOLS APPL, V57, P145, DOI 10.1007/s11042-011-0727-z
   Smeaton AF, 2008, INT J IMAG SYST TECH, V18, P195, DOI 10.1002/ima.20150
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snoek C., 2009, P TRECVID2009, P226
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Snoek CGM, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P386, DOI 10.1109/ICME.2005.1521441
   Staab S, 2008, LECT NOTES COMPUT SC, V5224, P125
   Steggink J, 2011, MULTIMEDIA SYST, V17, P367, DOI 10.1007/s00530-010-0220-y
   Sugano Y, 2013, ACM T APPL PERCEPT, V10, DOI 10.1145/2465780.2465784
   Sun C, 2013, IEEE I CONF COMP VIS, P913, DOI 10.1109/ICCV.2013.453
   Tadeusiewicz R, 2007, IEEE INT WORKSH IM S, P1
   Tadeusiewicz R, 2007, ADV SOFT COMP, V43, P3, DOI 10.1007/978-3-540-72575-6_1
   Tanaka K, 1999, IEICE T INF SYST, VE82D, P34
   Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Tesic J., 2007, CIVR '07: Proceedings of the 6th ACM international conference on Image and video retrieval, P595
   Thagard P., 2007, Cognitive Science
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Uehara K., 1996, P INT S COOP DAT SYS, P527
   Vahdat A, 2013, IEEE I CONF COMP VIS, P1185, DOI 10.1109/ICCV.2013.463
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van de Sande KEA, 2011, IEEE T MULTIMEDIA, V13, P60, DOI 10.1109/TMM.2010.2091400
   Volkmer T., 2005, 13th Annual ACM International Conference on Multimedia, P892, DOI 10.1145/1101149.1101341
   von Ahn L, 2008, COMMUN ACM, V51, P58, DOI 10.1145/1378704.1378719
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   VONAHN L, 2006, P SIGCHI C HUM FACT, P55, DOI DOI 10.1145/1124772.1124782
   Wang M, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899414
   Wang XJ, 2010, PROC CVPR IEEE, P2987, DOI 10.1109/CVPR.2010.5540046
   Wei XY, 2011, IEEE T CIRC SYST VID, V21, P62, DOI 10.1109/TCSVT.2011.2105597
   Weiss R., 1994, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.94TH0631-2), P140, DOI 10.1109/MMCS.1994.292446
   Westermann U, 2007, IEEE MULTIMEDIA, V14, P19, DOI 10.1109/MMUL.2007.23
   Wilkins P, 2007, P TRECVID 2007
   Woelk D., 1986, SIGMOD Record, V15, P311, DOI 10.1145/16856.16885
   Wu YM, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P261, DOI 10.1109/ICME.2004.1394175
   Wu YM, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P757
   Wu YM, 2003, PROC CVPR IEEE, P649
   Yan R., 2009, P 1 ACM WORKSHOP LAR, P35, DOI DOI 10.1145/1631058.1631067
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yap KH, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P1595
   Yi J, 2013, IEEE T MULTIMEDIA, V15, P1400, DOI 10.1109/TMM.2013.2250266
   Yoshitaka A, 1997, IEEE VISLANG, P310, DOI 10.1109/VL.1997.626599
   Yuan JS, 2004, INT C PATT RECOG, P866, DOI 10.1109/ICPR.2004.1334665
   Zettsu K., 1997, Database and Expert Systems Applications. 8th International Conference, DEXA '97. Proceedings, P192, DOI 10.1007/BFb0022031
   Zha ZJ, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823747
   Zhai Y, 2005, LECT NOTES COMPUT SC, V3568, P92
   Zhai Y, 2004, LECT NOTES COMPUT SC, V3115, P279
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhong D., 2001, IEEE International Conference on Multimedia and Expo, P713, DOI DOI 10.1109/ICME.2001.1237820
   Zhou HN, 2006, INT C PATT RECOG, P1161
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
   Zhu S., 2013, P 21 INT C MULT, P697
   Zhu XQ, 2005, IEEE T KNOWL DATA EN, V17, P665, DOI 10.1109/TKDE.2005.83
   Zwol RV, 2008, P WWW 2008
NR 168
TC 12
Z9 14
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 297
EP 331
DI 10.1007/s11042-014-2292-8
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500016
DA 2024-07-18
ER

PT J
AU Hu, CH
   Ye, MJ
   Zeng, WL
   Lu, XB
AF Hu, Chang-hui
   Ye, Meng-jun
   Zeng, Wei-li
   Lu, Xiao-bo
TI An adaptive approximation image reconstruction method for single sample
   problem in face recognition using FLDA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fisher linear discriminant analysis; Face recognition; Single sample
   problem; Economy singular value decomposition; Adaptive approximation
   image reconstruction method
ID TRAINING IMAGE
AB Fisher linear discriminant analysis (FLDA) algorithm is a popular subspace method for face recognition, which requires that the number of training samples for each object is not less than two. In this paper, an adaptive approximation image reconstruction method based on economy singular value decomposition (ESVD) algorithm is proposed for the single sample problem in face recognition. By using ESVD the single training sample is decomposed to a set of basis images. Then an adaptive approximation image reconstruction method is proposed to reconstruct an approximation image by using several significant basis images. The single training image and its approximation image for each object form a new training set, which can make the FLDA be applied to the single sample problem in face recognition. The major contribution of the proposed work is that the number of significant basis images for the reconstruction of an approximation image is evaluated by using a reverse thinking approach based on experimental analysis. The performance of the proposed method is verified on the Yale, FERET, ORL, UMIST and AR face databases. The experimental results indicate that the proposed method is efficient and outperforms some existing methods which are proposed to overcome the single sample problem.
C1 [Hu, Chang-hui; Zeng, Wei-li; Lu, Xiao-bo] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Hu, Chang-hui; Zeng, Wei-li; Lu, Xiao-bo] Southeast Univ, Minist Educ, Key Lab Measurement & Control CSE, Nanjing 210096, Jiangsu, Peoples R China.
   [Ye, Meng-jun] Hubei Normal Univ, Coll Mechatron & Control Engn, Huangshi 435002, Peoples R China.
C3 Southeast University - China; Southeast University - China; Hubei Normal
   University
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
EM xblu2013@126.com
RI Hu, Chang-Hui/AAD-8822-2020
OI Zeng, Weili/0000-0002-5266-2423
FU National Natural Science Foundation of China [61374194]; China
   Postdoctoral Science Foundation [2013M540405]
FX We thank the anonymous reviewers for their constructive comments and
   suggestions. This work was supported by the National Natural Science
   Foundation of China (No.61374194) and China Postdoctoral Science
   Foundation Funded Project (No.2013M540405).
CR [Anonymous], 2004, ADV NEURAL INF PROCE
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195
   Chen SC, 2004, PATTERN RECOGN LETT, V25, P1173, DOI 10.1016/j.patrec.2004.03.012
   Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010
   Fischer M, 2011, MULTIMED TOOLS APPL, V55, P83, DOI 10.1007/s11042-010-0603-2
   Gao QX, 2008, APPL MATH COMPUT, V205, P726, DOI 10.1016/j.amc.2008.05.019
   Golub G. H., 1983, MATRIX COMPUTATIONS
   GRAHAM D., 1998, COMPUTER SYSTEMS SCI, V163, P446
   Koç M, 2011, APPL MATH COMPUT, V217, P10368, DOI 10.1016/j.amc.2011.05.048
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li SZ, 2007, IEEE T PATTERN ANAL, V29, P627, DOI 10.1109/TPAMI.2007.1014
   Liu DH, 2005, PATTERN RECOGN, V38, P1705, DOI 10.1016/j.patcog.2005.03.009
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Ou F, 2012, MULTIMED TOOLS APPL, V57, P549, DOI 10.1007/s11042-010-0658-0
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Rama A, 2010, MULTIMED TOOLS APPL, V49, P545, DOI 10.1007/s11042-009-0447-9
   Sharma A, 2010, NEUROCOMPUTING, V73, P1868, DOI 10.1016/j.neucom.2009.10.027
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Wang J, 2008, PATTERN RECOGN, V41, P1528, DOI 10.1016/j.patcog.2007.10.024
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhang DQ, 2005, APPL MATH COMPUT, V163, P895, DOI 10.1016/j.amc.2004.04.016
NR 22
TC 6
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10313
EP 10334
DI 10.1007/s11042-014-2168-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700008
DA 2024-07-18
ER

PT J
AU Uddin, MZ
   Kim, TS
AF Uddin, Md. Zia
   Kim, Tae-Seong
TI 3-D body joint-specific HMM-based approach for human activity
   recognition from stereo posture image sequence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; Stereo image; Depth information; Hidden
   Markov Models
ID MODELS
AB In this paper, a stereo camera-based novel approach for Human Activity Recognition (HAR) is presented using robust 3-D human body joint features and joint-specific Hidden Markov Models (HMMs). At first, body joint angles are estimated by co-registering a 3-D body model to the stereo video information (i.e., 3-D depth) of a human posture acquired by a stereo camera. Conventionally, all joint angles are augmented followed by discriminant feature extraction from them and a HMM is modeled for each activity. Although the traditional approach is straight forward and easy to implement but dependent to unnecessary joint features which are not even used in the activity. In this study, we focus on individual 3-D body joints rather than all joints together and body joint motion information in next frame is also considered in addition to the degree of freedom values (i.e., joint angles in current frame) of a joint. We propose a new way of modeling human activities and derive joint-specific HMMs. Based on motion information of the joints in next frame and degree of freedom information of body joints in the time-sequential distinguished activity video frames, the different activity classes are determined first. Each joint features are then mapped into codewords to generate a sequence of discrete symbols for joint-specific HMM. Then, joint-specific HMMs are trained according to their use in different activities. For testing, after determining the activity class based on the time-sequential body joint features, the discrete symbol sequence from each joint is applied to the trained joint-specific HMMs of the activities from that class only. Thus, for all body joints, the likelihoods of all activities are obtained by applying all body joint features and then, likelihoods for corresponding activities are summed up. Finally, one activity has been chosen with the highest likelihood from the summed likelihoods. Using joint-specific HMMs (i.e., multiple HMMs for an activity based on active body joints), superior recognition performance is obtained than the augmented joint angle feature-based single HMM for an activity as well as the traditional silhouette-based approaches.
C1 [Uddin, Md. Zia] Sungkyunkwan Univ, Dept Comp Educ, Seoul, South Korea.
   [Kim, Tae-Seong] Kyung Hee Univ, Dept Biomed Engn, Yongin, South Korea.
C3 Sungkyunkwan University (SKKU); Kyung Hee University
RP Kim, TS (corresponding author), Kyung Hee Univ, Dept Biomed Engn, Yongin, South Korea.
EM ziauddin@skku.edu; tskim@khu.ac.kr
RI Uddin, Zia/AAC-1309-2020
OI Uddin, Zia/0000-0002-5215-1834
FU Faculty Research Fund, Sungkyunkwan University
FX This paper was supported by Faculty Research Fund, Sungkyunkwan
   University, 2013.
CR [Anonymous], IEEE COMP SOC WORKSH
   Caschera MC, 2013, IEEE T SYST MAN CY-S, V43, P911, DOI 10.1109/TSMCA.2012.2210407
   Cech J., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Gupta A, 2008, IEEE T PATTERN ANAL, V30, P493, DOI 10.1109/TPAMI.2007.1173
   Isard M, 2003, PROC CVPR IEEE, P613
   Jalal A, 2013, INDOOR BUILT ENV
   Knossow D, 2008, INT J COMPUT VISION, V79, P247, DOI 10.1007/s11263-007-0116-2
   Kupiec J., 1992, Computer Speech and Language, V6, P225, DOI 10.1016/0885-2308(92)90019-Z
   Lee MW, 2006, IEEE T PATTERN ANAL, V28, P905, DOI 10.1109/TPAMI.2006.110
   Makhoul J., 1994, HLT 94, P432
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Niu F., 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P546
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Sudderth EB, 2003, PROC CVPR IEEE, P605
   Taylor CJ, 2000, COMPUT VIS IMAGE UND, V80, P349, DOI 10.1006/cviu.2000.0878
   Uddin M.Z., 2008, P 5 INT C UB HEALTHC, P181
   Uddin MZ, 2008, LECT NOTES ARTIF INT, V5027, P245, DOI 10.1007/978-3-540-69052-8_26
   Uddin MZ, 2013, INDOOR BUILT ENVIRON, V22, P289, DOI 10.1177/1420326X12469734
   Uddin MZ, 2011, THEOR APPL
   Uddin MZ, 2011, TRI J, p[569, 579]
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
NR 21
TC 6
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11207
EP 11222
DI 10.1007/s11042-014-2225-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600012
DA 2024-07-18
ER

PT J
AU Cheng, CI
   Liu, DSM
   Lin, CCH
AF Cheng, Ching-I
   Liu, Damon Shing-Min
   Lin, Charles Chia-Hsu
TI A digital tutor for learning fashion design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fashion design knowledge; Expert system; Focus plus context; Overview;
   Detail on Demand; OpenGL
ID MARKET-SEGMENTATION
AB Computer-aided instruction (CAI) is an interactive instructional technique that effectively improves the students' understandings. However, CAI tool is currently lack of use in teaching and learning fashion design. The present research hence proposes a tool functions as a digital tutor poviding an intuitive visual aid for learning principles. The interfaces are designed based on two viewpoints: fashion style and design elements. Style Cognition Space and Style Cluster View are designed for visualizing fashion style knowledge, while Comparison View of Design Elements Effects and Elementary Attribute Space are designed for visualizing knowledge of design elements. Several skills of graphic user interface and information visualization are used, such as Details on demand, Portals, and Zoom. To obtain evaluations from users, three workshops of fashion design were held. Using questionnaires, all participants were asked to answer several questions about ease of use, effectiveness, and satisfaction. Whether professional lecturers or inexperienced novices at fashion, all users rate the system as highly satisfactory after use.
C1 [Cheng, Ching-I; Liu, Damon Shing-Min] Natl Chung Cheng Univ, Chiayi 62107, Taiwan.
   [Lin, Charles Chia-Hsu] Tainan Technol Univ, Tainan 710, Taiwan.
C3 National Chung Cheng University
RP Liu, DSM (corresponding author), Natl Chung Cheng Univ, 168 Univ Rd, Chiayi 62107, Taiwan.
EM chengcy@cs.ccu.edu.tw; damon@cs.ccu.edu.tw; t30040@mail.tut.edu.tw
CR Allison PD., 1999, MULTIPLE REGRESSION
   [Anonymous], 1992, The Visual Display of Quantitative Information
   [Anonymous], 1992, Graphics Gems III (IBM Version), DOI DOI 10.1016/B978-0-08-050755-2.50034-8
   [Anonymous], 2000, Computational Geometry Algorithms and Applications
   BEARD DV, 1990, BEHAV INFORM TECHNOL, V9, P451, DOI 10.1080/01449299008924259
   Ben-Bassat T., 2006, ACM Transactions on Computer-Human Interaction, V13, P210, DOI 10.1145/1165734.1165737
   Boyack KW, 2002, J AM SOC INF SCI TEC, V53, P764, DOI 10.1002/asi.10066
   Card S. K., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P111, DOI 10.1145/238386.238446
   Card S K., 1999, READINGS INFORM VISU
   Carians P, 2008, RES METHODS HUMAN CO
   Carpendale MST, 1997, IEEE COMPUT GRAPH, V17, P42, DOI 10.1109/38.595268
   Cheng CI, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1592, DOI 10.1109/ICMLC.2008.4620660
   Chiu CY, 2009, EXPERT SYST APPL, V36, P4558, DOI 10.1016/j.eswa.2008.05.029
   Cockburn A, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456652
   Cordier F, 2003, IEEE COMPUT GRAPH, V23, P38, DOI 10.1109/MCG.2003.1159612
   EICK SG, 1992, IEEE T SOFTWARE ENG, V18, P957, DOI 10.1109/32.177365
   Gall M. D., 2003, Educational Research: An Introduction
   Hearst M. A., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P59
   HERTER T, 1993, COMPUT GRAPH, V17, P517, DOI 10.1016/0097-8493(93)90003-R
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Inselberg A., 2009, Parallel Coordinates. Visual Multidimensional Geometry and its Applications, DOI DOI 10.1007/978-0-387-68628-8
   Inselberg A, 1985, VISUAL COMPUT, V1, P69, DOI 10.1007/BF01898350
   KELLER P, 1992, VISUAL CUES
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Kuiper J.B., 2002, Quaternions and Rotational Sequences, V5th
   Kuo RJ, 2002, COMPUT IND ENG, V42, P391, DOI 10.1016/S0360-8352(02)00048-7
   Lamping J., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P401
   Lauesen S., 2005, USER INTERFACE DESIG
   León A, 2006, J MULTIVARIATE ANAL, V97, P412, DOI 10.1016/j.jmva.2005.03.009
   Lin CC-H, 2007, KAOHSIUNG NORMAL U J, V23, P151
   Lin CC-H, 2003, J TAINAN TECHNOLOGY, V22, P1
   Lin CC-H, 2004, J NATL TAIWAN COLL A, V73, P89
   Metaaphanon N., 2005, Proceeding of ACM SIGGRAPH, P83
   North C., 2000, Proceedings of the the working conference on Advanced visual interfaces (AVI) 2000, P128, DOI [DOI 10.1145/345513.345282, 10.1145/345513.345282]
   Palais B, 2009, AM MATH MON, V116, P892, DOI 10.4169/000298909X477014
   Plaisant C., 2005, INFORM VISUALIZATION, P580
   Plumlee M. D., 2006, ACM Transactions on Computer-Human Interaction, V13, P179, DOI 10.1145/1165734.1165736
   Rhyne TM, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P611, DOI 10.1109/VISUAL.2003.1250428
   Rodrigues JF, 2006, INFORMATION VISUALIZATION-BOOK, P713
   Rohrer RM, 1998, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION - PROCEEDINGS, P121, DOI 10.1109/INFVIS.1998.729568
   Salton G, 1999, M KAUFMANN MULTIMEDI, P413
   SARKAR M, 1994, COMMUN ACM, V37, P73, DOI 10.1145/198366.198384
   Sedig Kamran, 2008, Journal of Interactive Learning Research, V19, P147
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shoemake K., 1994, Graphics Gems IV, P222, DOI [DOI 10.1016/B978-0-12-336156-1.50030-6, 10.1016/B978-0-12-336156-1.50030-6]
   Siirtola H, 2006, INTERACT COMPUT, V18, P1278, DOI 10.1016/j.intcom.2006.03.006
   Spence R., 2001, INFORM VISUAL
   Stead L, 2004, PERS UBIQUIT COMPUT, V8, P282, DOI 10.1007/s00779-004-0289-4
   Ritchey T, 2006, J OPER RES SOC, V57, P792, DOI 10.1057/palgrave.jors.2602177
   Terrace BC, TESS VERSION 1 70
   Wang CCL, 2003, COMPUT AIDED DESIGN, V35, P659, DOI 10.1016/S0010-4485(02)00091-X
   Week J, KALEIDOTILE VERSION
   Wise J. A., 1995, Proceedings. Information Visualization (Cat. No.95TB100000), P51, DOI 10.1109/INFVIS.1995.528686
   Zudilova-Seinstra E, 2009, ADV INFORM KNOWL PRO, P3, DOI 10.1007/978-1-84800-269-2_1
NR 54
TC 2
Z9 2
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9339
EP 9364
DI 10.1007/s11042-014-2084-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200013
DA 2024-07-18
ER

PT J
AU Yazid, M
   Sahki, N
   Bouallouche-Medjkoune, L
   Aïssani, D
AF Yazid, Mohand
   Sahki, Nassim
   Bouallouche-Medjkoune, Louiza
   Aissani, Djamil
TI Modeling and performance study of the packet fragmentation in an IEEE
   802.11e-EDCA network over fading channel
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IEEE 802.11e-EDCA network; Packet fragmentation; Noisy channel; Markov
   chains; Modeling; Throughput analysis
ID AD HOC NETWORKS; THROUGHPUT ANALYSIS; WIRELESS LANS; RESOURCE
   RESERVATION; IEEE-802.11 WLANS; QOS GUARANTEES; NON-SATURATION; EDCA;
   ACCESS; DIFFERENTIATION
AB Mathematical modeling and performance analysis of the IEEE 802.11e Enhanced Distributed Channel Access (EDCA) has been the subject of several research papers published in the literature. However, the Packet Fragmentation (PF) which has been proposed by the IEEE work group in the legacy IEEE 802.11 standard, has never been taken into account in the mathematical models available in the literature, in order to analyze the performance of the IEEE 802.11e-EDCA network under the influence of the Packet Error Rate (PER). Yet, the Packet Fragmentation is the only existing solution since 1999, which allows reducing the influence of the PER on the performance of IEEE 802.11 networks. In this paper, we aim at showing for the first time, how the Packet Fragmentation developed in the legacy IEEE 802.11 standard can be used to enhance the current IEEE 802.11e Quality of Service (QoS). Therefore, we propose an extension of the existing Markov chain models of the IEEE 802.11e EDCA function, in order to take into account the Packet Error Rate and Packet Fragmentation. Furthermore, we develop a mathematical model to derive the saturation throughput of a given Access Category (AC), namely: Voice (VO), Video (VI), Best Effort (BE) and Background (BK). The obtained analytical results show that, applying the Packet Fragmentation on the IEEE 802.11e-EDCA network, allows improving the utilization of the scarce wireless bandwidth under the impact of PER parameters, namely: Bit Error Rate (BER) and packet length.
C1 [Yazid, Mohand; Sahki, Nassim; Bouallouche-Medjkoune, Louiza; Aissani, Djamil] Univ Bejaia, Lab Modeling & Optimizat Syst, LAMOS, Bejaia 06000, Algeria.
C3 Universite de Bejaia
RP Yazid, M (corresponding author), Univ Bejaia, Lab Modeling & Optimizat Syst, LAMOS, Bejaia 06000, Algeria.
EM yazid.mohand@gmail.com
RI AISSANI, Djamil/N-8733-2016
OI Aissani, Djamil/0000-0002-5851-0690; Bouallouche-Medjkoune,
   Louiza/0000-0003-2849-6258
CR Al-Karaki J., 2004, Ad Hoc Networks, V2, P265
   [Anonymous], 2016, IEEE Standard 802.11-2020
   [Anonymous], 2005, 80211E IEEE 2
   Banchs A, 2007, WIRELESS PERS COMMUN, V43, P1145, DOI 10.1007/s11277-007-9290-3
   Banchs A, 2006, COMPUT NETW, V50, P1749, DOI 10.1016/j.comnet.2005.07.008
   Bianchi G, 2000, IEEE J SEL AREA COMM, V18, P535, DOI 10.1109/49.840210
   Bolch G., 2006, Queueing Networks and Markov Chains: Modeling and Performance Evaluation with Computer Science Applications, VSecond
   Camps-Mur D, 2012, COMPUT NETW, V56, P2896, DOI 10.1016/j.comnet.2012.05.004
   Casale Giuliano, 2011, Performance Evaluation of Computer and Communication Systems. Milestones and Future Challenges. IFIP WG 6.3/7.3 International Workshop, PERFORM 2010 in Honor of Gunter Haring on the Occasion of His Emeritus Celebration. Revised Selected Papers, P24, DOI 10.1007/978-3-642-25575-5_3
   Cetinkaya C, 2010, AD HOC NETW, V8, P46, DOI 10.1016/j.adhoc.2009.03.003
   Fan Z, 2007, WIRELESS PERS COMMUN, V43, P1279, DOI 10.1007/s11277-007-9301-4
   Gallardo JR, 2007, WIREL NETW, V13, P335, DOI 10.1007/s11276-006-7529-7
   Ge Y, 2007, COMPUT NETW, V51, P1955, DOI 10.1016/j.comnet.2006.07.018
   Giustiniano D, 2010, IEEE ACM T NETWORK, V18, P1516, DOI 10.1109/TNET.2010.2051038
   Hamidian A, 2006, TELECOMMUN SYST, V31, P195, DOI 10.1007/s11235-006-6520-z
   Hamidian A, 2008, TELECOMMUN SYST, V39, P187, DOI 10.1007/s11235-008-9124-y
   He Y, 2013, IEEE ACM T NETWORK, V21, P204, DOI 10.1109/TNET.2012.2202323
   Hu J, 2012, INFORM SCIENCES, V214, P20, DOI 10.1016/j.ins.2012.05.013
   Hu J, 2011, COMPUT COMMUN, V34, P1593, DOI 10.1016/j.comcom.2010.08.004
   Jeong S, 2004, LECT NOTES COMPUT SC, V3284, P304
   Kong ZN, 2004, IEEE J SEL AREA COMM, V22, P2095, DOI 10.1109/JSAC.2004.836019
   Körner U, 2011, ANN TELECOMMUN, V66, P491, DOI 10.1007/s12243-010-0209-8
   Kosek-Szott K, 2011, COMPUT NETW, V55, P622, DOI 10.1016/j.comnet.2010.10.002
   Lagkas TD, 2013, TELECOMMUN SYST, V52, P1961, DOI 10.1007/s11235-011-9477-5
   Lee JF, 2007, MOBILE NETW APPL, V12, P69, DOI 10.1007/s11036-006-0007-8
   Lee Y, 2007, LECT NOTES ARTIF INT, V4682, P1223
   Lefebvre M., 2007, Applied Stochastic Processes
   Lin WY, 2007, COMPUT COMMUN, V30, P841, DOI 10.1016/j.comcom.2006.10.013
   Liu Dong-Sheng, 2011, SENSORS, V11, P6494, DOI DOI 10.1109/W
   Lyakhov A., 2004, 2004 IEEE International Conference on Mobile Ad-hoc and Sensor Systems (IEEE Cat. No.04EX975), P204, DOI 10.1109/MAHSS.2004.1392159
   Min GY, 2011, COMPUT NETW, V55, P2545, DOI 10.1016/j.comnet.2011.04.015
   Moltchanov D, 2010, COMPUT SCI REV, V4, P153, DOI 10.1016/j.cosrev.2010.04.001
   Narayan-Bhat U., 2007, INTRO QUEUEING THEOR
   Pan SW, 2009, COMPUT COMMUN, V32, P935, DOI 10.1016/j.comcom.2008.12.021
   Park S, 2012, CONSUM COMM NETWORK, P188, DOI 10.1109/CCNC.2012.6181084
   Patras P, 2009, MOBILE NETW APPL, V14, P697, DOI 10.1007/s11036-008-0121-x
   Pocta P, 2010, PROCEEDINGS OF THE 20TH INTERNATIONAL CONFERENCE, RADIOELETRONIKA 2010, P75, DOI 10.1109/RADIOELEK.2010.5478587
   Puigjaner R, 2003, PROCEEDINGS IFIP ACM
   Serrano P, 2007, WIRELESS PERS COMMUN, V43, P467, DOI 10.1007/s11277-006-9244-1
   Sweedy A. M., 2010, Proceedings 10th International Conference on Intelligent Systems Design and Applications (ISDA 2010), P1338, DOI 10.1109/ISDA.2010.5687095
   Tao ZF, 2006, IEEE T COMMUN, V54, P596, DOI 10.1109/TCOMM.2006.873066
   Tao ZF, 2004, WRKS LOC METRO AREA, P39, DOI 10.1109/LANMAN.2004.1338397
   Thangaraj A, 2010, TELECOMMUN SYST, V45, P303, DOI 10.1007/s11235-009-9268-4
   Varposhti M, 2009, COMPUT COMMUN, V32, P985, DOI 10.1016/j.comcom.2008.12.034
   Vassis D, 2005, WIRELESS PERS COMMUN, V34, P29, DOI 10.1007/s11277-005-8725-y
   Xiao Y, 2005, IEEE T WIREL COMMUN, V4, P1506, DOI 10.1109/TWC.2005.850328
   Xiong L, 2007, COMPUT NETW, V51, P3047, DOI 10.1016/j.comnet.2007.01.002
   Yao YC, 2013, WIRELESS PERS COMMUN, V69, P413, DOI 10.1007/s11277-012-0581-y
   Yu J, 2009, MOBILE NETW APPL, V14, P470, DOI 10.1007/s11036-008-0111-z
NR 49
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9507
EP 9527
DI 10.1007/s11042-014-2131-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200021
DA 2024-07-18
ER

EF