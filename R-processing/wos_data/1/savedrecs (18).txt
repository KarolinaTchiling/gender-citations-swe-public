FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Chakraborty, S
   Mondal, R
   Singh, PK
   Sarkar, R
   Bhattacharjee, D
AF Chakraborty, Saikat
   Mondal, Riktim
   Singh, Pawan Kumar
   Sarkar, Ram
   Bhattacharjee, Debotosh
TI Transfer learning with fine tuning for human action recognition from
   still images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Transfer learning; Deep learning; Still image;
   Stanford40; PPMI action dataset
ID CONVOLUTIONAL NEURAL-NETWORKS
AB Still image-based human action recognition (HAR) is one of the most challenging research problems in the field of computer vision. Some of the significant reasons to support this claim are the availability of few datasets as well as fewer images per action class and the existence of many confusing classes in the datasets and comparing with video-based data. There is the unavailability of temporal information. In this work, we train some of the most reputed Convolutional Neural Network (CNN) based architectures using transfer learning after fine-tuned those suitably to develop a model for still image-based HAR. Since the number of images per action classes is found to be significantly less in number, we have also applied some well-known data augmentation techniques to increase the amount of data, which is always a need for deep learning-based models. Two benchmark datasets used for validating our model are Stanford 40 and PPMI, which are better known for their confusing action classes and the presence of occluded images and random poses of subjects. Results obtained by our model on these datasets outperform some of the benchmark results reported in the literature by a considerable margin. Class imbalance is deliberately introduced in the said datasets to better explore the robustness of the proposed model. The source code of the present work is available at: https://github.com/saikat021/Transfer-Learning-Based-HAR
C1 [Chakraborty, Saikat] Jadavpur Univ, Dept Elect & Telecommun Engn, Kolkata 700032, India.
   [Mondal, Riktim; Sarkar, Ram; Bhattacharjee, Debotosh] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
   [Singh, Pawan Kumar] Jadavpur Univ, Dept Informat Technol, Kolkata 700106, India.
   [Bhattacharjee, Debotosh] Univ Hradec Kralove, Fac Informat & Management, Ctr Basic & Appl Sci, Rokitanskeho 62, Hradec Kralove 50003, Czech Republic.
C3 Jadavpur University; Jadavpur University; Jadavpur University;
   University of Hradec Kralove
RP Singh, PK (corresponding author), Jadavpur Univ, Dept Informat Technol, Kolkata 700106, India.
EM chakrabortysaikat021@gmail.com; riktimrules@gmail.com;
   pawansingh.ju@gmail.com; raamsarkar@gmail.com; debotoshb@hotmail.com
RI Bhattacharjee, Debotosh/Q-4065-2019; Sarkar, Ram/AAX-3822-2020;
   Bhattacharjee, Debotosh/L-8521-2015; SINGH, PAWAN KUMAR/E-3408-2013
OI Bhattacharjee, Debotosh/0000-0002-1163-6413; Sarkar,
   Ram/0000-0001-8813-4086; Bhattacharjee, Debotosh/0000-0002-1163-6413;
   SINGH, PAWAN KUMAR/0000-0002-9598-7981
CR Banerjee A, 2021, IEEE T CIRC SYST VID, V31, P2206, DOI 10.1109/TCSVT.2020.3019293
   Bhattacharya, 2020, P 11 INT C SOFT COMP
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4405, DOI 10.1007/s11042-015-3177-1
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Clawson, 2014, HUMAN ACTION RECOGNI
   Cruciani F, 2020, CCF T PERVAS COMPUT, V2, P18, DOI 10.1007/s42486-020-00026-2
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du XY, 2015, PROCEEDINGS OF THE ASME 34TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING, 2015, VOL 8
   Gkioxari G, 2015, IEEE I CONF COMP VIS, P1080, DOI 10.1109/ICCV.2015.129
   Guha R, 2021, NEURAL COMPUT APPL, V33, P5267, DOI 10.1007/s00521-020-05297-5
   Gunawan IP, 2008, IEEE T BROADCAST, V54, P669, DOI 10.1109/TBC.2008.2000734
   Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018
   HADDAD E, 2019, IEEE PHOTON CONF, pNI187
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Igbinedion, 2016, POSE GUIDED VISUAL A
   Ikizler, 2008, P INT C PATT REC, DOI 10.1109/icpr.2008.4761663
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jalal A, 2017, INT J INTERACT MULTI, V4, P54, DOI 10.9781/ijimai.2017.447
   Jalal A, 2015, INT CONF UBIQ ROBOT, P294, DOI 10.1109/URAI.2015.7358957
   Jalal A, 2014, SENSORS-BASEL, V14, P11735, DOI 10.3390/s140711735
   Jang Y, 2019, PR MACH LEARN RES, V97
   Khan FS, 2018, MACH VISION APPL, V29, P55, DOI 10.1007/s00138-017-0871-1
   Khan FS, 2014, IEEE T IMAGE PROCESS, V23, P3633, DOI 10.1109/TIP.2014.2331759
   LAVINIA Y, 2017, IEEE INT SYM MULTIM
   Lee, 2011, ACTIVITY RECOGNITION
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mondal A, 2020, IEEE SENSOR LETT, V4, DOI 10.1109/LSENS.2020.3019279
   Mukherjee D, 2020, MULTIMED TOOLS APPL, V79, P31663, DOI 10.1007/s11042-020-09537-7
   Munoz-Organero M, 2019, IEEE ACCESS, V7, P74422, DOI 10.1109/ACCESS.2019.2921096
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Sadhukhan, 2020, COMP STUDY DIFFERENT, DOI 10.1007/978-981-15-4288-6_3
   Safaei, 2017, UCF STAR LARGE SCALE, P101
   Saini R, 2018, NEUROCOMPUTING, V311, P99, DOI 10.1016/j.neucom.2018.05.042
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sreela SR, 2018, PROCEDIA COMPUT SCI, V143, P563, DOI 10.1016/j.procs.2018.10.432
   Sulong Ghazali, 2015, Journal of Theoretical and Applied Information Technology, V71, P115
   Teja KVR, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT ,POWER AND COMPUTING TECHNOLOGIES (ICCPCT)
   Uddin MZ, 2011, INDOOR BUILT ENVIRON, V20, P120, DOI 10.1177/1420326X10391140
   Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386
   YAO BP, 2010, PROC CVPR IEEE, P9, DOI DOI 10.1109/CVPR.2010.5540234
   Yu XC, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/9428612
   Zeng GY, 2016, J CHEM TECHNOL BIOT, V91, P2322, DOI 10.1002/jctb.4820
   Zhang JG, 2016, MULTIMEDIA SYST, V22, P343, DOI 10.1007/s00530-015-0464-7
   Zhang L, 2016, INT CONF ACOUST SPEE, P1841, DOI 10.1109/ICASSP.2016.7471995
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, P5479, DOI 10.1109/TIP.2016.2605305
   Zhao ZC, 2017, PATTERN RECOGN, V64, P347, DOI 10.1016/j.patcog.2016.10.001
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
NR 49
TC 23
Z9 23
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20547
EP 20578
DI 10.1007/s11042-021-10753-y
EA MAR 2021
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000626425600001
DA 2024-07-18
ER

PT J
AU Rashid, U
   Saleem, K
   Ahmed, A
AF Rashid, Umer
   Saleem, Khalid
   Ahmed, Adeel
TI MIRRE approach: nonlinear and multimodal exploration of MIR aggregated
   search results
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aggregation; Browsing; Exploration; Multimedia documents; Multimodal;
   Search user interface; Usability
AB Nowadays, web users frequently explore multimedia contents to satisfy their information needs. The exploration approaches usually provide linear interaction mechanisms and do not exploit the multiple information modalities associated with results. They cannot treat multimedia documents as aggregated entities. The aggregation of results in multimedia documents and nonlinear navigation in them is usually not possible. The exploration of multimedia content segregated in multiple verticals is tedious. In this research, we propose an approach to address the core issues in multimedia contents exploration. We provide a nonlinear and multimodal exploration of multimedia document results. We generate result spaces by exploiting multimodal similarity and semantic relationships in results and enable their nonlinear and multimodal exploration via a search user interface (SUI) design. The result space connects retrieved multimedia documents and their aggregated media objects via multimodal similarity and semantic relationships, respectively. The SUI provides lookup, preview/view/access, browsing, and visualization of multimedia documents by introducing various types of interface components. The approach has been instantiated over a real dataset of aggregated multimedia documents and evaluated via usability tests. Our investigation reveals that 93.33% users had completed exploration tasks within time limits. The overall usability scores assessed via SUS and PUEU instruments are 72.1% and 61.6%, respectively. The user satisfaction tested via QUIS-instrument is 70.3%. The usage of elementary SUI components providing the nonlinear exploration is high. The ploy-representation of results improves the overall information gain. The evaluation reveals that approach is usable, gives a satisfactory exploration mechanism, and SUI components collectively provide exploration.
C1 [Rashid, Umer; Saleem, Khalid; Ahmed, Adeel] Quaid I Azam Univ, Dept Comp Sci, Islamabad, Pakistan.
C3 Quaid I Azam University
RP Rashid, U (corresponding author), Quaid I Azam Univ, Dept Comp Sci, Islamabad, Pakistan.
EM umerrashid@qau.edu.pk; ksaleem@qau.edu.pk; adeel.ahmed@cs.qau.edu.pk
RI Rashid, Umer/AGW-1380-2022; Ahmed, Adeel/IUP-7128-2023; Saleem,
   Khalid/ACQ-6881-2022
OI Rashid, Umer/0000-0002-2419-3172; Rashid, Umer/0000-0002-3453-7979
CR Achsas S, 2018, COGN SYST RES, V51, P61, DOI 10.1016/j.cogsys.2018.05.002
   [Anonymous], 2008, P 16 INT C MULTIMEDI, DOI [DOI 10.1145/1459359.1459577, 10.1145/1459359.1459577]
   [Anonymous], 2009, SEARCH USER INTERFAC, DOI DOI 10.1017/CBO9781139644082
   [Anonymous], 1988, Proceedings of the SIGCHI conference on Human factors in computing systems-CHI, DOI DOI 10.1145/57167.57203
   Arampatzis A, 2013, INFORM PROCESS MANAG, V49, P274, DOI 10.1016/j.ipm.2012.03.005
   Arguello J, 2016, FOUND TRENDS INF RET, V10, P366, DOI 10.1561/1500000052
   Axenopoulos A, 2012, LECT NOTES COMPUT SC, V7131, P716
   Axenopoulos Apostolos., 2012, The Future Internet, P130
   Azad HK, 2019, INFORM PROCESS MANAG, V56, P1698, DOI 10.1016/j.ipm.2019.05.009
   Azzopardi L, 2018, ACM/SIGIR PROCEEDINGS 2018, P605, DOI 10.1145/3209978.3210027
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bogdanov D., 2013, P 21 ACM INT C MULT, P855, DOI [10.1145/2502081.2502229, DOI 10.1145/2502081]
   Bracamonte, 2018, MULTIMED TOOLS APPL, P1
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Carrera CC, 2018, INT RES GEOGR ENVIRO, V27, P69, DOI 10.1080/10382046.2017.1285135
   Carrion B, 2019, MULTIMED TOOLS APPL, V78, P32919, DOI 10.1007/s11042-019-07880-y
   Chatzichristofis SA, 2010, INT J PATTERN RECOGN, V24, P207, DOI 10.1142/S0218001410007890
   Daras Petros, 2011, International Journal of Multimedia Intelligence and Security, V2, P351, DOI 10.1504/IJMIS.2011.044765
   Daras P, 2012, IEEE T MULTIMEDIA, V14, P734, DOI 10.1109/TMM.2011.2181343
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Dourado IC, 2019, INFORM PROCESS MANAG, V56, P1260, DOI 10.1016/j.ipm.2019.03.008
   Gasser R, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P391, DOI 10.1145/3323873.3326921
   Gialampoukidis I, 2017, MULTIMED TOOLS APPL, V76, P22383, DOI 10.1007/s11042-017-4797-4
   Halvey M, 2014, INFORM PROCESS MANAG, V50, P876, DOI 10.1016/j.ipm.2014.06.004
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   Heu JU, 2015, INFORM PROCESS MANAG, V51, P212, DOI 10.1016/j.ipm.2014.06.003
   Jiang D, 2019, IEEE INT CONF MOB CL, P1, DOI 10.1109/MobileCloud.2019.00008
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Kannan R, 2015, INFORM PROCESS MANAG, V51, P286, DOI 10.1016/j.ipm.2014.12.001
   Kofler C, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2954930
   Kopliku A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2523817
   Lee OJ, 2019, INFORM PROCESS MANAG, V56, P1894, DOI 10.1016/j.ipm.2019.02.005
   Lefortier Damien, 2014, Advances in Information Retrieval. 36th European Conference on IR Research, ECIR 2014. Proceedings: LNCS 8416, P184, DOI 10.1007/978-3-319-06028-6_16
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Lund A M., 2001, USABILITY INTERFACE, V8, P3, DOI DOI 10.1177/1078087402250360
   Marchionini G, 2006, COMMUN ACM, V49, P41, DOI 10.1145/1121949.1121979
   Missaoui Sondess, 2019, Personal and Ubiquitous Computing, V23, P181, DOI 10.1007/s00779-018-01194-w
   Petkos G, 2017, MULTIMED TOOLS APPL, V76, P7897, DOI 10.1007/s11042-016-3378-2
   Pinto-Caceres Sheila M., 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P335, DOI 10.1007/978-3-319-14445-0_29
   Pouyanfar S, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3150226
   Rashid Umer, 2015, 2015 Tenth International Conference on Digital Information Management (ICDIM). Proceedings, P154, DOI 10.1109/ICDIM.2015.7381866
   Rashid U, 2017, MULTIMED TOOLS APPL, V76, P25787, DOI 10.1007/s11042-017-4769-8
   Rashid U, 2016, INFORM SCIENCES, V370, P303, DOI 10.1016/j.ins.2016.07.072
   Rashid U, 2016, ADV INTELL SYST, V400, P271, DOI 10.1007/978-3-319-26154-6_21
   Ren HL, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1247, DOI 10.1145/3240508.3241392
   Rico M, 2019, J WEB SEMANT, V59, DOI 10.1016/j.websem.2019.03.001
   Rinaldi AM, 2021, MULTIMED TOOLS APPL, V80, P3885, DOI 10.1007/s11042-020-09761-1
   Rinaldi AM, 2018, IEEE INT CONF BIG DA, P2304, DOI 10.1109/BigData.2018.8622613
   Saddal M, 2019, 22 INT MULT C INMIC, P1
   Sánchez-Nielsen E, 2019, MULTIMEDIA SYST, V25, P337, DOI 10.1007/s00530-019-00610-2
   Seifert C, 2014, IEEE INT CONF INF VI, P94, DOI 10.1109/IV.2014.49
   Tian F, 2019, MULTIMED TOOLS APPL, V78, P437, DOI 10.1007/s11042-017-5068-0
   Tullis T.S., 2004, Usability professional association conference, V1, DOI 10.1.1.396.3677
   Vaizman Y, 2014, IEEE-ACM T AUDIO SPE, V22, P1483, DOI 10.1109/TASLP.2014.2337842
   Villa R, 2012, INFORM PROCESS MANAG, V48, P32, DOI 10.1016/j.ipm.2011.03.005
   Wang JH, 2019, INT J HUM-COMPUT INT, V35, P483, DOI 10.1080/10447318.2018.1464776
   Wang XZ, 2020, MULTIMED TOOLS APPL, V79, P25335, DOI 10.1007/s11042-020-09195-9
   Yang Y, 2010, PATTERN RECOGN, V43, P2927, DOI 10.1016/j.patcog.2010.02.015
   Yazici A, 2018, MULTIMED TOOLS APPL, V77, P2225, DOI 10.1007/s11042-017-4378-6
   Zhuang YT, 2008, IEEE T MULTIMEDIA, V10, P221, DOI 10.1109/TMM.2007.911822
NR 60
TC 8
Z9 8
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20217
EP 20253
DI 10.1007/s11042-021-10603-x
EA MAR 2021
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625612900004
DA 2024-07-18
ER

PT J
AU Liu, GQ
   Rehman, MU
   Wu, YH
AF Liu, Guoqi
   Rehman, Mujeeb Ur
   Wu, Yuhou
TI Toward storytelling from personal informative lifelogging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Behavior identification; Informative lifelogging; Photo data
   classification; Multiple classifications
AB The authors began collecting personal informative lifelogging data in 2011. The data collected in this article is a discontinuous data set, each of which includes one or more images, a GPS message, a description of a location, and a description of the text, we call this informative lifelogging. However, for the purposes automatically building a story from a huge collection of unstructured egocentric data presents major challenges. This paper first introduces the structure and characteristics of the collected data and uses the DB-scan algorithm to classify the data. Then a model for generating a story is proposed, and a model of story generation based on a story template is proposed in the model. The author implemented a complete software system through code, described a story generation model, and gave the key algorithm to generate stories. Through this system, 418 stories were generated automatically, of which 62% of the stories were particularly accurate. The experimental results verify that it is feasible to automatically generate stories based on personal Informative lifelogging data.
C1 [Liu, Guoqi; Wu, Yuhou] Jianzhu Univ, Shenyang, Liaoning, Peoples R China.
   [Rehman, Mujeeb Ur] Northeastern Univ, Shenyang, Liaoning, Peoples R China.
C3 Northeastern University - China
RP Wu, YH (corresponding author), Jianzhu Univ, Shenyang, Liaoning, Peoples R China.
EM liuguoqi@sjzu.edu.cn; mujeebislamian2011@gmail.com; wuyh@sjzu.edu.cn
RI Rehman, Mujeeb/AAE-7374-2019
OI Liu, Guoqi/0000-0001-6427-5650
CR ANDREW A, 2013, INT CONF PER COMP
   Belhadi A, 2020, ACM TRANS MANAG INF, V11, DOI 10.1145/3399631
   Bolaños M, 2017, IEEE T HUM-MACH SYST, V47, P77, DOI 10.1109/THMS.2016.2616296
   Cao JM, 2020, I C NETWORK PROTOCOL, DOI 10.1109/icnp49622.2020.9259358
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Gurrin Cathal, 2014, Foundations and Trends in Information Retrieval, V8, P5, DOI 10.1561/1500000033
   Hamid A., 2017, 2017 INT C WIR TECHN, P1
   Jo H, 2010, PLACEGRAM DIAGRAMMAT
   Kim PH., 2011, 2011 IEEE INT C NEXT
   KYBARTAS B, 2017, IEEE T COMP INTEL AI
   Li Zhenhui, 2010, P KDD10 P 16 ACM SIG, P1099, DOI DOI 10.1145/1835804.1835942
   Liu XL, 2016, MULTIMED TOOLS APPL, V75, P1495, DOI 10.1007/s11042-014-2085-0
   MANDLER JM, 1977, COGNITIVE PSYCHOL, V9, P111, DOI 10.1016/0010-0285(77)90006-8
   Mann S, 1997, COMPUTER, V30, P25, DOI 10.1109/2.566147
   Martin WM, 2005, AI SOC, V19, P34, DOI 10.1007/s00146-004-0300-7
   Mazimpaka JD, 2016, J SPAT INF SCI, P61, DOI 10.5311/JOSIS.2016.13.263
   Rohrbach A, 2017, INT J COMPUT VISION, V123, P94, DOI 10.1007/s11263-016-0987-1
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Venugopalan S., 2015, P ANN C N AM CHAPT A, P1494, DOI 10.3115/v1/N15-1173
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang JW, 2020, IEEE T VEH TECHNOL, V69, P2487, DOI 10.1109/TVT.2020.2967865
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wang YL, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P25, DOI 10.1145/2623330.2623656
   Xiao S, 2019, MULTIMED TOOLS APPL
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yuan J, 2013, IEEE T KNOWL DATA EN, V25, P220, DOI 10.1109/TKDE.2011.200
   Yuan NJ, 2013, IEEE T KNOWL DATA EN, V25, P2390, DOI 10.1109/TKDE.2012.153
NR 30
TC 1
Z9 1
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19649
EP 19673
DI 10.1007/s11042-020-10453-z
EA MAR 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000623716500003
DA 2024-07-18
ER

PT J
AU Kaur, S
   Randhawa, S
   Malhi, A
AF Kaur, Shubhdeep
   Randhawa, Sukhchandan
   Malhi, Avleen
TI An efficient ANFIS based pre-harvest ripeness estimation technique for
   fruits
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ripeness prediction; Adaptive neuro-fuzzy inference system; Color
   depictions; Ripeness estimation
ID NONDESTRUCTIVE PREDICTION; TOMATO MATURITY; QUALITY; MANGOES
AB The ripeness estimation of fruits plays a significant role in marketing and evaluation of quality. However, due to the subjectivity and slow speed in the case of manual assessment, the agriculture industry leads to the need for automation. In this research work, an efficient ANFIS based Pre-harvest Ripeness Estimation (APRE) technique is proposed for the ripeness estimation of fruits based on color. There are three main phases of the proposed work: Data Processing, Feature Selection and Fuzzy Logic Implementation. In the first phase, the data set of images of fruits is prepared in the image acquisition phase. Then images are pre-processed to make them equal in size. In Image Segmentation phase, a fruit is extracted from its background. In the next phase, two color features: red-green color difference and red-green color ratio are calculated based on extracted RGB color attributes and R-G is chosen based on performance comparison in terms of classification accuracy. In phase three, Adaptive Neuro-Fuzzy Inference System (ANFIS) is utilized for designing and implementing the classification system which classifies the fruits into six ripeness phases. The experimental results show that the APRE performs better than SVM, Decision Tree, and KNN in terms of accuracy, precision, recall, sensitivity and F-measure.
C1 [Kaur, Shubhdeep; Randhawa, Sukhchandan; Malhi, Avleen] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Randhawa, S (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM shubhdeepk1211@gmail.com; sukhchandan.95@gmail.com; avleen@thapar.edu
RI Randhawa, Sukhchandan/AAN-8499-2021
CR Alavi N., 2013, Journal of the Saudi Society of Agricultural Sciences, V12, P137, DOI 10.1016/j.jssas.2012.10.001
   Arefi A., 2013, Australian Journal of Crop Science, V7, P699
   Bhargava A., 2018, J KING SAUD U COMPUT, V6, P113
   Blanes C, 2015, FOOD BIOPROCESS TECH, V8, P1914, DOI 10.1007/s11947-015-1548-2
   Bloice MD., 2017, J OPEN SOURCE SOFTW, V19, P13
   Capizzi G., 2016, INT J COMPUT SCI APP, V13, P45
   Casson A, 2020, BIOSYST ENG, V189, P1, DOI 10.1016/j.biosystemseng.2019.11.003
   CHOI K, 1995, T ASAE, V38, P171, DOI 10.13031/2013.27827
   De-la-Torre M, 2019, PROCESSES, V7, DOI 10.3390/pr7120928
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Du DD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020419
   El Khaled D, 2015, SENSORS-BASEL, V15, P15363, DOI 10.3390/s150715363
   El-hariri E., 2013, 4 INT C INN BIOINSP, P13
   Gao WJ, 2019, COMPUT INTELL-US, V35, P496, DOI 10.1111/coin.12202
   Goel N, 2015, APPL SOFT COMPUT, V36, P45, DOI 10.1016/j.asoc.2015.07.009
   Gupta N, 2014, ADV INTELL SYST COMP, P121
   Hazarika S, 2018, INT J FRUIT SCI, V18, P188, DOI 10.1080/15538362.2017.1377671
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI DOI 10.5121/IJDKP.2015.5201
   Jana S., 2016, INT J COMPUTER APPL, V148, P1, DOI [10.5120/ijca2016911283, DOI 10.5120/IJCA2016911283]
   Li B, 2018, PLANTS-BASEL, V7, DOI 10.3390/plants7010003
   Mansor AR., 2014, RES ARTS SCI COMMER, V5, P101
   McCool C, 2016, IEEE INT CONF ROBOT, P2506, DOI 10.1109/ICRA.2016.7487405
   Mon KL., 2014, INT C ADV ENG TECHN, P100
   Naik S., 2017, INT J COMPUT APPL, V170, P975
   Nambi VE, 2016, J FOOD QUALITY, V39, P816, DOI 10.1111/jfq.12245
   Nambi VE, 2017, INT AGROPHYS, V31, P35, DOI 10.1515/intag-2016-0025
   Roy P, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P1182, DOI 10.1109/ICCICCT.2014.6993140
   Rungpichayapicheta P, 2016, POSTHARVEST BIOL TEC, V111, P31, DOI 10.1016/j.postharvbio.2015.07.006
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Pereira LFS, 2018, COMPUT ELECTRON AGR, V145, P76, DOI 10.1016/j.compag.2017.12.029
   Semary NA, 2015, ADV INTELL SYST, V323, P401, DOI 10.1007/978-3-319-11310-4_35
   Taghadomi-Saberi S, 2015, J AGR SCI TECH-IRAN, V17, P589
   Taofik A, 2018, IOP CONF SER-MAT SCI, V288, DOI 10.1088/1757-899X/288/1/012018
   Wang XZ, 2011, AFR J BIOTECHNOL, V10, P3616
   Xiang R, 2011, P 4 INT C IM SIGN PR, P3
   Yin HP, 2009, IEEE SYS MAN CYBERN, P2984, DOI 10.1109/ICSMC.2009.5345994
   Yin J, 2006, P AGR HYDR APPL REM, P27
NR 37
TC 4
Z9 4
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19459
EP 19489
DI 10.1007/s11042-021-10741-2
EA FEB 2021
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000622668700005
DA 2024-07-18
ER

PT J
AU Kumar, M
   Gupta, P
AF Kumar, Manish
   Gupta, Prateek
TI A new medical image encryption algorithm based on the 1D logistic map
   associated with pseudo-random numbers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Logistic map; Image encryption; Image decryption; Cryptanalysis
AB A new, fast, and secure encryption algorithm for medical images based on the 1D logistic map associated with pseudo-random numbers has been proposed. Initial values and parameters of the logistic map play an important role (as secret keys) to generate key matrices for shuffling and substituting pixels in the image. The proposed algorithm has been designed to provide the user control over the level of security required by increasing or decreasing the number of rounds of the encryption process. During the encryption process, two pseudo-random rows and two pseudo-random columns have been inserted on each side of the original image to counter chosen and known plain-image attacks. The proposed algorithm has been tested for robustness and effectiveness using the standard tests available. Further, differential and noise attacks have also been analyzed. Cryptanalysis of the proposed algorithm has been performed by testing it against most of the frequently used attacks, such as known and chosen plain-image attacks. The run time for different images has been recorded to check the efficiency of the proposed algorithm. The tests were performed on 50 grayscale and 50 RGB images. The average entropy and NPCR of encrypted images were approximately 7.99 and 99.6%, respectively, for the selected images. Some medical images, such as the human brain, MRI, and lungs, have been selected to demonstrate the output of the proposed algorithm. Similarly, the proposed algorithm has been tested for a standard non-medical test image as well. The obtained results have also been compared with existing competing algorithms. The proposed algorithm can be apt for practical use.
C1 [Kumar, Manish; Gupta, Prateek] Birla Inst Technol & Sci Pilani, Dept Math, Hyderabad Campus, Hyderabad 500078, Telangana, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani)
RP Kumar, M (corresponding author), Birla Inst Technol & Sci Pilani, Dept Math, Hyderabad Campus, Hyderabad 500078, Telangana, India.
EM manish.math.bhu@gmail.com; prateek.gupta1309@gmail.com
RI Kumar, Prof. Manish/C-9163-2012
OI Kumar, Prof. Manish/0000-0003-2925-4218
CR Ali TS, 2020, IEEE ACCESS, V8, P71974, DOI 10.1109/ACCESS.2020.2987615
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Chidambaram N, 2019, MULTIMED TOOLS APPL, V78, P33837, DOI 10.1007/s11042-019-08166-z
   Çokal C, 2009, PHYS LETT A, V373, P1357, DOI 10.1016/j.physleta.2009.02.030
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Feng W, 2019, OPTIK, V186, P449, DOI 10.1016/j.ijleo.2018.12.103
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Huang X., 2018, SECUR COMMUN NETW, V2018, P11
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Kumar M, 2019, MULTIMED TOOLS APPL, V78, P28025, DOI 10.1007/s11042-019-07893-7
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Kumar M, 2015, J INF SECUR APPL, V21, P20, DOI 10.1016/j.jisa.2014.11.003
   Kumar S, 2019, MED BIOL ENG COMPUT, V57, P2517, DOI 10.1007/s11517-019-02037-3
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Muhammad ZMZ, 2019, IEEE ACCESS, V7, P99945, DOI 10.1109/ACCESS.2019.2930606
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Roginsky, 2019, NIST SPECIAL PUBLICA, V2, P33
   Shankar K, 2018, IEEE ACCESS, V6, P77145, DOI 10.1109/ACCESS.2018.2874026
   Sivaraman R, 2020, IET IMAGE PROCESS, V14, P2987, DOI 10.1049/iet-ipr.2019.0168
   Stalin S, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1389-z
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Xiang HY, 2020, MULTIMED TOOLS APPL, V79, P30329, DOI 10.1007/s11042-020-09595-x
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 26
TC 14
Z9 14
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18941
EP 18967
DI 10.1007/s11042-020-10325-6
EA FEB 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000620422600005
DA 2024-07-18
ER

PT J
AU Wang, XF
   Li, XN
   Tang, C
   Hu, SL
AF Wang, Xiaofeng
   Li, Xinai
   Tang, Chao
   Hu, Shaolin
TI Median filtering detection using LBP encoding pattern<SUP>☆</SUP>
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Median filtering detection; Local binary pattern; Discriminating
   algorithm; Recognition algorithm
AB In recent years, median filtering detection has a widely application in many fields such as images' processing history tracking, image editing detection, image anti-forensics analyzing and anti-steganalysis analyzing. In this paper, we propose two median filtering detection algorithms. The Algorithm I is a recognition algorithm that can identify whether a given image has undergone median filtering. The Algorithm II is a discriminating algorithm that can distinguish a median (average, Gaussian) filtered image from unfiltered images. Differing from the general framework of existing median filtering detectors, the contribution of our work is that the presented methods are not based on the statistical learning model. The proposed methods do not need any classifier, or any threshold. These methods are implemented by counting the number of specific Local Binary Pattern encoding patterns of a single image. Experimental results demonstrate that the proposed methods provide high accuracy and broad-spectrum robustness for tolerating content-preserving manipulations. Compared to state-of-the-art methods, the proposed methods exhibit high efficiency, high accuracy, and strong robustness.
C1 [Wang, Xiaofeng; Li, Xinai; Tang, Chao] Xian Univ Technol, Sch Sci, Xian 710048, Shaanxi, Peoples R China.
   [Hu, Shaolin] Guangdong Univ Petrochem Technol, Maoming, Guangdong, Peoples R China.
C3 Xi'an University of Technology; Guangdong University of Petrochemical
   Technology
RP Wang, XF (corresponding author), Xian Univ Technol, Sch Sci, Xian 710048, Shaanxi, Peoples R China.
EM xfwang@xaut.edu.cn
RI Hu, Shaolin/AAN-5168-2021
OI Wang, Xiaofeng/0000-0002-0861-8193; Tang, Chao/0000-0003-2073-248X
FU National Natural Science Foundation of China [61772416, 61973094]; Key
   Laboratory Project of the Education Department of Shaanxi Province
   [17JS098]; Shaanxi province technology innovation guiding fund project
FX This work was supported by the National Natural Science Foundation of
   China, No.61772416 and No.61973094; the Key Laboratory Project of the
   Education Department of Shaanxi Province, No.17JS098; Shaanxi province
   technology innovation guiding fund project, No.2018XNCG-G-G-02.
CR [Anonymous], 2008, PROC SPIE SEC FORENS
   Bas P., 2007, Break our Watermarking System, V2nd
   BOVIK AC, 1987, IEEE T ACOUST SPEECH, V35, P493, DOI 10.1109/TASSP.1987.1165153
   Cancelli G, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P795, DOI 10.1109/MMSP.2008.4665182
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chen YS, 2009, IEEE SIGNAL PROC LET, V16, P125, DOI 10.1109/LSP.2008.2008951
   Chuang WH, 2009, INT CONF ACOUST SPEE, P1517, DOI 10.1109/ICASSP.2009.4959884
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Fridrich, 2010, MEDIA FORENSICS SECU, V7541, P1
   Gao SD, 2019, J REAL-TIME IMAGE PR, V16, P741, DOI 10.1007/s11554-019-00860-3
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Kirchner M, 2008, IEEE T INF FOREN SEC, V3, P582, DOI 10.1109/TIFS.2008.2008214
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P810, DOI 10.1109/TIFS.2010.2074195
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pasquini C, 2016, IEEE T INF FOREN SEC, V11, P1425, DOI 10.1109/TIFS.2016.2530636
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shen ZY, 2016, MULTIMED TOOLS APPL, V75, P2327, DOI 10.1007/s11042-014-2407-2
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   *USDA, NAT RES CONS SERV PH
   Yu X., 2008, PATTERN RECOGN, P1
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Zhang YJ, 2014, IEEE SIGNAL PROC LET, V21, P275, DOI 10.1109/LSP.2013.2295858
NR 32
TC 0
Z9 0
U1 4
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17721
EP 17744
DI 10.1007/s11042-021-10581-0
EA FEB 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000616915300001
DA 2024-07-18
ER

PT J
AU Krishnani, D
   Shivakumara, P
   Lu, T
   Pal, U
   Lopresti, D
   Kumar, GH
AF Krishnani, Divya
   Shivakumara, Palaiahnakote
   Lu, Tong
   Pal, Umapada
   Lopresti, Daniel
   Kumar, Govindaraju Hemantha
TI A new context-based feature for classification of emotions in
   photographs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social networking; Face detection; Hanman transform; Person emotions;
   Personality behavior
ID FACIAL EXPRESSION; RECOGNITION; IMAGES
AB A high volume of images is shared on the public Internet each day. Many of these are photographs of people with facial expressions and actions displaying various emotions. In this work, we examine the problem of classifying broad categories of emotions based on such images, including Bullying, Mildly Aggressive, Very Aggressive, Unhappy, Disdain and Happy. This work proposes the Context-based Features for Classification of Emotions in Photographs (CFCEP). The proposed method first detects faces as a foreground component, and other information (non-face) as background components to extract context features. Next, for each foreground and background component, we explore the Hanman transform to study local variations in the components. The proposed method combines the Hanman transform (H) values of foreground and background components according to their merits, which results in two feature vectors. The two feature vectors are fused by deriving weights to generate one feature vector. Furthermore, the feature vector is fed to a CNN classifier for classification of images of different emotions uploaded on social media and public internet. Experimental results on our dataset of different emotion classes and the benchmark dataset show that the proposed method is effective in terms of average classification rate. It reports 91.7% for our 10-class dataset, 92.3% for 5 classes of standard dataset and 81.4% for FERPlus dataset. In addition, a comparative study with existing methods on the benchmark dataset of 5-classes, standard dataset of facial expression (FERPlus) and another dataset of 10-classes show that the proposed method is best in terms of scalability and robustness.
C1 [Krishnani, Divya] Int Inst Informat Technol IIIT, Naya Raipur, Chhattisgarh, India.
   [Shivakumara, Palaiahnakote] Univ Malaya, Dept Comp Syst & Informat Technol, Kuala Lumpur, Malaysia.
   [Lu, Tong] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing, Peoples R China.
   [Pal, Umapada] Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Kolkata, India.
   [Lopresti, Daniel] Lehigh Univ, Comp Sci & Engn, Bethlehem, PA 18015 USA.
   [Kumar, Govindaraju Hemantha] Univ Mysore, Dept Studies Comp Sci, Mysuru, India.
C3 Universiti Malaya; Nanjing University; Indian Statistical Institute;
   Indian Statistical Institute Kolkata; Lehigh University; University of
   Mysore
RP Shivakumara, P (corresponding author), Univ Malaya, Dept Comp Syst & Informat Technol, Kuala Lumpur, Malaysia.
EM divya16100@iiitnr.edu.in; shiva@um.edu.my; lutong@nju.edu.cn;
   umapada@isical.ac.in; lopresti@cse.lehigh.edu; ghk.2007@yahoo.com
RI Palaiahnakote, Shivakumara/ITU-6488-2023; Pal, Umapada/AAC-4930-2022;
   Palaiahnakote, Shivakumara/B-6261-2013
OI Palaiahnakote, Shivakumara/0000-0001-9026-4613
FU Natural Science Foundation of China [61672273, 61832008]; Science
   Foundation for Distinguished Young Scholars of Jiangsu [BK20160021];
   University of Malaya, Malaysia [GPF014D-2019]
FX Tong Lu, Palaiahnakote Shivakumara and Umapada Pal received support for
   this work from the Natural Science Foundation of China under Grant
   61672273 and Grant 61832008, and the Science Foundation for
   Distinguished Young Scholars of Jiangsu under Grant BK20160021.
   Palaiahnakote Shivakumara received partial support for this work from
   the Faculty Grant: GPF014D-2019, University of Malaya, Malaysia. The
   authors would like to thank the authors of the paper [23] for sharing
   their dataset to facilitate experimentation and a comparative study.
   Special thanks to Swati Kanchan, Computer Vision and Patten Recognition
   Unit, Indian Statistical Institute, Kolkata for helping to conduct all
   the new experiments to revise the draft.
CR Albanie S, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P292, DOI 10.1145/3240508.3240578
   Alexandre GR, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107108
   Alzubi J, 2018, J PHYS CONF SER, V1142, DOI 10.1088/1742-6596/1142/1/012012
   [Anonymous], 2015, SYNTHESIS LECT HUMAN
   Arora R., 2012, International Journal of Computer Applications, V54, P21, DOI DOI 10.5120/8626-2492
   Avots E, 2019, MACH VISION APPL, V30, P975, DOI 10.1007/s00138-018-0960-9
   Bachrach Y, 2012, PROCEEDINGS OF THE 3RD ANNUAL ACM WEB SCIENCE CONFERENCE, 2012, P24
   Barsoum E, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P279, DOI 10.1145/2993148.2993165
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Best-Rowden L, 2014, IEEE T INF FOREN SEC, V9, P2144, DOI 10.1109/TIFS.2014.2359577
   Bharati A, 2016, IEEE T INF FOREN SEC, V11, P1903, DOI 10.1109/TIFS.2016.2561898
   Chen XJ, 2016, IEEE T CIRC SYST VID, V26, P2226, DOI 10.1109/TCSVT.2015.2511480
   Cheung M, 2015, IEEE T MULTIMEDIA, V17, P1417, DOI 10.1109/TMM.2015.2460192
   Dey S, 2018, PATTERN RECOGN LETT
   Favaretto RM, 2019, MACH VISION APPL, V30, P999, DOI 10.1007/s00138-018-0979-y
   Grover J, 2018, ENG APPL ARTIF INTEL, V67, P111, DOI 10.1016/j.engappai.2017.08.016
   Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759
   Hanmandlu M, 2015, P AIPR, P1
   Hsu S., 2018, P INT WORKSH ADV IM, P1
   Hu Y., 2014, P INT AAAI C WEB SOC, P595
   Jaiswal S, 2019, MULTIMED TOOLS APPL, V78, P14231, DOI 10.1007/s11042-018-6755-1
   Krishnani D., 2019, P ACPR, P594
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P24083, DOI 10.1007/s11042-019-7398-6
   Son LH, 2019, IEEE ACCESS, V7, P23319, DOI 10.1109/ACCESS.2019.2899260
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P356, DOI 10.1109/TIP.2018.2868382
   Liu LN, 2016, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING TECHNOLOGY (CSET2015), MEDICAL SCIENCE AND BIOLOGICAL ENGINEERING (MSBE2015), P3
   Liu SL, 2020, INFORM SCIENCES, V509, P243, DOI 10.1016/j.ins.2019.08.035
   Mukhopadhyay Moutan, 2020, ICIIT 2020: Proceedings of the 2020 5th International Conference on Intelligent Information Technology, P107, DOI 10.1145/3385209.3385231
   Mungra D, 2020, MULTIMED TOOLS APPL, V79, P2285, DOI 10.1007/s11042-019-08397-0
   Roy S, 2018, PATTERN RECOGN, V80, P64, DOI 10.1016/j.patcog.2018.02.014
   Said N, 2019, MULTIMED TOOLS APPL, V78, P31267, DOI 10.1007/s11042-019-07942-1
   Sharma M, 2019, MULTIMED TOOLS APPL, V78, P16195, DOI 10.1007/s11042-018-7030-1
   Shehab D, 2019, MACH VISION APPL, V30, P919, DOI 10.1007/s00138-018-0974-3
   Tian SX, 2015, IEEE I CONF COMP VIS, P4651, DOI 10.1109/ICCV.2015.528
   Tous R, 2018, MULTIMED TOOLS APPL, V77, P27123, DOI 10.1007/s11042-018-5910-z
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang DY, 2017, IEEE T PATTERN ANAL, V39, P1122, DOI 10.1109/TPAMI.2016.2582166
   Wang YL, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P1584, DOI 10.1109/ICDMW.2015.142
   Xie SY, 2019, IEEE T MULTIMEDIA, V21, P211, DOI 10.1109/TMM.2018.2844085
   Xu GX, 2020, FUTURE GENER COMP SY, V102, P347, DOI 10.1016/j.future.2019.07.007
   Xu XJ, 2016, BIOMED SIGNAL PROCES, V27, P103, DOI 10.1016/j.bspc.2016.02.008
   Yan Y, 2020, SIGNAL PROCESS, P169
   Zhang J, 2019, MACH VISION APPL, V30, P987, DOI 10.1007/s00138-018-0970-7
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang T, 2019, IEEE T CYBERNETICS, V49, P839, DOI 10.1109/TCYB.2017.2788081
   Zheng YC, 2019, PATTERN RECOGN, V93, P558, DOI 10.1016/j.patcog.2019.05.014
NR 46
TC 5
Z9 5
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15589
EP 15618
DI 10.1007/s11042-020-10404-8
EA FEB 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615174300001
DA 2024-07-18
ER

PT J
AU Maurya, R
   Pathak, VK
   Dutta, MK
AF Maurya, Ritesh
   Pathak, Vinay Kumar
   Dutta, Malay Kishore
TI Computer-aided diagnosis of auto-immune disease using capsule neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Capsule neural network; Human Epithelial-2 (HEp-2); Convolution neural
   network (CNN); Scalar activation; Activity vector
ID CLASSIFICATION
AB Manual analysis of the indirect-immunofluorescence (IIF) human epithelial cell Type-2 (HEp-2) cell image for the diagnosis of an auto-immune disease is a subjective and time-consuming process, and it is also prone to human-errors. The present work proposes an automatic capsule neural network (CapsNet) based framework for HEp-2 cell image classification to compensate for the deficiencies present in the prominent convolution neural network (CNN) based frameworks. In CNNs, the spatial relationship between the features present in the anti-nuclear antibodies (ANA) patterns, found in the IIF HEp-2 cell image (ANA-IIF image) is lost which increases the chance of detection of false-positives. In the proposed CapsNet based model, the max-pooling layer has been replaced with advanced dynamic routing algorithm and scalar outputs are replaced with the vector output, thus the richer representation of the same feature without the loss of spatial relationship with respect to the other features are made possible. The proposed framework recognizes ANA-IIF images with an average accuracy of 95.00% for 10-fold cross-validations. The experimental result also shows that the proposed model performs better than the other CNN based classification models for human epithelial cell image classification task.
C1 [Maurya, Ritesh; Dutta, Malay Kishore] Dr APJ Abdul Kalam Tech Univ, Ctr Adv Studies, Lucknow, Uttar Pradesh, India.
   [Pathak, Vinay Kumar] Dr APJ Abdul Kalam Tech Univ, Lucknow, Uttar Pradesh, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Centre for Advanced
   Studies (CAS, AKTU); Dr. A.P.J. Abdul Kalam Technical University (AKTU)
RP Dutta, MK (corresponding author), Dr APJ Abdul Kalam Tech Univ, Ctr Adv Studies, Lucknow, Uttar Pradesh, India.
EM ritesh@cas.res.in; vinay@vpathak.in; mkd@cas.res.in
OI Dutta, Malay Kishore/0000-0003-2462-737X; MAURYA,
   RITESH/0000-0002-5664-0328
CR Afshar P, 2018, IEEE IMAGE PROC, P3129, DOI 10.1109/ICIP.2018.8451379
   American College ofRheumatology, 2011, POS STAT METH OFT AN
   Baydilli YY, 2020, COMPUT MED IMAG GRAP, V80, DOI 10.1016/j.compmedimag.2020.101699
   Cascio D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9081618
   Feng, 2017, CELLULAR IMAGE CLASS
   Foggia P, 2013, IEEE T MED IMAGING, V32, P1878, DOI 10.1109/TMI.2013.2268163
   Gao ZM, 2017, IEEE J BIOMED HEALTH, V21, P416, DOI 10.1109/JBHI.2016.2526603
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Phan HTH, 2016, I S BIOMED IMAGING, P1208, DOI 10.1109/ISBI.2016.7493483
   Hernández G, 2020, NEUROCOMPUTING, V390, P327, DOI 10.1016/j.neucom.2019.08.095
   Hiemann R, 2009, AUTOIMMUN REV, V9, P17, DOI 10.1016/j.autrev.2009.02.033
   Hughes, 2007, BINDING SITE
   Iesmantas T, 2018, LECT NOTES COMPUT SC, V10882, P853, DOI 10.1007/978-3-319-93000-8_97
   LaLonde R., 2018, ABS180404241 ARXIV
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lei HJ, 2018, PATTERN RECOGN, V79, P290, DOI 10.1016/j.patcog.2018.02.006
   Lu MC, 2017, PROC SPIE, V10420, DOI 10.1117/12.2282033
   Majtner T, 2019, LECT NOTES COMPUT SC, V11482, P439, DOI 10.1007/978-3-030-20205-7_36
   Mobiny A, 2018, LECT NOTES COMPUT SC, V11071, P741, DOI 10.1007/978-3-030-00934-2_82
   Qi XB, 2016, PATTERN RECOGN, V60, P420, DOI 10.1016/j.patcog.2016.05.032
   Rodrigues LF, 2020, COMPUT BIOL MED, V116, DOI 10.1016/j.compbiomed.2019.103542
   Rodrigues LF, 2017, 2017 WORKSHOP OF COMPUTER VISION (WVC), P13, DOI 10.1109/WVC.2017.00010
   Rodrigues LF, 2017, SIBGRAPI, P170, DOI 10.1109/SIBGRAPI.2017.29
   Sabour S, 2017, ADV NEUR IN, V30
   Soda P, 2007, COMP MED SY, P219, DOI 10.1109/CBMS.2007.42
   Vununu C, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8010020
   Wiik AS, 2010, J AUTOIMMUN, V35, P276, DOI 10.1016/j.jaut.2010.06.019
   Wiliem A, 2013, IEEE WORK APP COMP, P95, DOI 10.1109/WACV.2013.6475005
   Zhang XQ, 2019, MED BIOL ENG COMPUT, V57, P1187, DOI 10.1007/s11517-018-01946-z
NR 29
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13611
EP 13632
DI 10.1007/s11042-021-10534-7
EA FEB 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000615174300006
DA 2024-07-18
ER

PT J
AU Bouridah, MS
   Bouden, T
   Yalçin, ME
AF Bouridah, M. S.
   Bouden, T.
   Yalcin, M. E.
TI Delayed outputs fractional-order hyperchaotic systems synchronization
   for images encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Fractional-order; Hyperchaotic; LMI's
AB Communication networks, play a major role in keeping us connected and sharing the details of our lives with each other. The main driver of multimedia data transmission is to enhance security protection of this multimedia data (speech, image and video). In this paper we addresses the synchronization problem of the masterslave type via a static error feedback. Sufficient conditions expressed by means of linear matrix inequalities (LMI) for the synchronization of fractional-order hyperchaotic systems with a known time delay between them is presented. The delay-dependent criterion is given based upon a Lyapunov function. We take the fractional-order hyperchaotic Liu system as an illustrative example to demonstrate the effectiveness of the proposed synchronization scheme. Moreover, as an application an images cryptosystem is presented. We considered two scenarios corresponding to the transmission channel, under occlusion attack and under noisse addition respectively. Results for the studied scenarios are presented and compared. The extensive simulation results prove that proposed cryptosystem has clear advantage over other proposed in the litterature.
C1 [Bouridah, M. S.; Bouden, T.] Mohammed Seddik Ben Yahia Univ Jijel, Automat Dept, Fac Sci & Technol, BP 98 Ouled Aissa, Jijel 18000, Algeria.
   [Yalcin, M. E.] Istanbul Tech Univ, Dept Elect & Commun Engn, TR-34469 Istanbul, Turkey.
C3 Istanbul Technical University
RP Bouridah, MS (corresponding author), Mohammed Seddik Ben Yahia Univ Jijel, Automat Dept, Fac Sci & Technol, BP 98 Ouled Aissa, Jijel 18000, Algeria.
EM bouridahsalah@univ-jijel.dz
RI Yalcin, Mustak Erhan/O-2257-2015
OI Yalcin, Mustak Erhan/0000-0003-3377-2560
CR Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Biham E, 1993, 12 ANN INT CRYPT C S, P487
   Bowong S, 2004, PHYS LETT A, V326, P102, DOI 10.1016/j.physleta.2004.04.004
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chapaneri S, 2014, 2014 INTERNATIONAL CONFERENCE ON CIRCUITS, SYSTEMS, COMMUNICATION AND INFORMATION TECHNOLOGY APPLICATIONS (CSCITA), P59, DOI 10.1109/CSCITA.2014.6839235
   Chen CL, 2004, PHYS LETT A, V321, P344, DOI 10.1016/j.physleta.2003.12.043
   Chen FX, 2007, NONLINEAR ANAL-THEOR, V67, P3384, DOI 10.1016/j.na.2006.10.020
   Chen HF, 2000, IEEE J QUANTUM ELECT, V36, P27, DOI 10.1109/3.817635
   Diaconu AV, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/932875
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Feng DL, 2019, PHYS LETT A, V383, P1427, DOI 10.1016/j.physleta.2019.01.056
   Firdous A, 2019, MULTIMED TOOLS APPL, V78, P24809, DOI 10.1007/s11042-019-7623-3
   Gan ZH, 2019, NEURAL COMPUT APPL, V31, P7111, DOI 10.1007/s00521-018-3541-y
   Gu KQ, 2000, IEEE DECIS CONTR P, P2805, DOI 10.1109/CDC.2000.914233
   Han Q, 2013, CHINESE PHYS B, V22, DOI 10.1088/1674-1056/22/2/020502
   HARTLEY TT, 1995, IEEE T CIRCUITS-I, V42, P485, DOI 10.1109/81.404062
   Hegazi AS, 2011, APPL MATH LETT, V24, P1938, DOI 10.1016/j.aml.2011.05.025
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Huang X, 2015, ENTROPY-SWITZ, V17, P28, DOI 10.3390/e17010028
   Huang YY, 2020, IEEE ACCESS, V8, P135308, DOI 10.1109/ACCESS.2020.3011524
   Kalpana J, 2015, OPTIK, V126, P5703, DOI 10.1016/j.ijleo.2015.09.091
   Khalil H. K., 1993, NONLINEAR SYSTEMS
   Kiani-B A, 2009, COMMUN NONLINEAR SCI, V14, P863, DOI 10.1016/j.cnsns.2007.11.011
   Kilbas A. A., 2006, THEORY APPL FRACTION
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Li, CHAOS SOLITON FRACT, V22, P77
   Liang YR, 2016, MULTIMED TOOLS APPL, V75, P6605, DOI 10.1007/s11042-015-2592-7
   Liao XX, 2003, INT J BIFURCAT CHAOS, V13, P207, DOI 10.1142/S0218127403006455
   Liu S, 2016, NONLINEAR DYNAM, V86, P65, DOI 10.1007/s11071-016-2872-4
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P17669, DOI 10.1007/s11042-020-08645-8
   Muthukumar P, 2017, MULTIMED TOOLS APPL, V76, P23517, DOI 10.1007/s11042-016-4052-4
   Muthukumar P, 2013, NONLINEAR DYNAM, V74, P1169, DOI 10.1007/s11071-013-1032-3
   Nana B, 2009, COMMUN NONLINEAR SCI, V14, P2266, DOI 10.1016/j.cnsns.2008.06.028
   Odibat ZM, 2010, INT J BIFURCAT CHAOS, V20, P81, DOI 10.1142/S0218127410025429
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Podlubny I., 1999, FRACTIONAL DIFFERENT
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P2105, DOI 10.1007/s11042-018-6346-1
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Smaoui N, 2011, COMMUN NONLINEAR SCI, V16, P3279, DOI 10.1016/j.cnsns.2010.10.023
   Vidhya R, 2020, MULTIMED TOOLS APPL, V79, P30281, DOI 10.1007/s11042-020-09462-9
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu, 2011, OPT COMMUN, V12, P89
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Wu XY, 2015, PLOS ONE, V10, DOI [10.1371/journal.pone.0118041, 10.1371/journal.pone.0119607]
   Xu Y, 2014, COMMUN NONLINEAR SCI, V19, P3735, DOI 10.1016/j.cnsns.2014.02.029
   Yalçin ME, 2001, INT J BIFURCAT CHAOS, V11, P1707, DOI 10.1142/S021812740100295X
   Zhang H, 2018, INT J SYST SCI, V49, P537, DOI 10.1080/00207721.2017.1412534
   Zhang LL, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/6/064209
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang WW, 2019, J FRANKLIN I, V356, P1522, DOI 10.1016/j.jfranklin.2018.10.024
   Zhang YQ, 2020, IEEE ACCESS, V8, P54175, DOI 10.1109/ACCESS.2020.2979827
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 55
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14723
EP 14752
DI 10.1007/s11042-020-10425-3
EA JAN 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000612593600001
DA 2024-07-18
ER

PT J
AU Guo, F
   Li, WQ
   Kuang, ZH
   Tang, J
AF Guo, Fan
   Li, Weiqing
   Kuang, Zhonghao
   Tang, Jin
TI MES-Net: a new network for retinal image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal image; Blood vessel segmentation; OC and OD segmentation;
   Multi-scale semantic features; Neural network model
ID OPTIC DISC; ARCHITECTURE; GLAUCOMA
AB Glaucoma, diabetic retinopathy, and other eye diseases have seriously threatened people's visual health. Whether it is clinical diagnosis or computer-aided diagnosis, the accurate segmentation of the retinal tissues and lesion areas (optic disc (OD), optic cup (OC), retinal blood vessels) are indispensable. In this paper, we propose a novel network MES-Net for the retinal image segmentation tasks. MES-Net adopts U-Net as the overall architecture, including three proposed modules: multi-scale feature pre-extraction (MFP) block, encoder spatial cascading encoding (ESCE) path, and decoder input SE block. We use MFP block to extract multi-scale semantic features from input images with different resolutions, and take ESCE path to extract deep features and improve the feature reuse rate. SE block can weaken the semantic gaps between the encoder paths and the decoder paths. For retinal vessel segmentation, the accuracy values of MES-Net tested on the DRIVE, STARE and CHASE datasets are 0.9667, 0.9724, and 0.9697, and AUC is 0.9853, 0.9897, and 0.9869, respectively. For OC and OD simultaneous segmentation, the overlap coefficients of OC and OD tested on the ORIGA dataset are 0.818 and 0.948, and the accuracy are 0.935 and 0.977, respectively. The experimental results show that the proposed method significantly improves the performance of the original U-Net and is superior to other state-of-the-art methods. Thus, it can be applied to retinal image segmentation tasks, and many other medical image segmentation problems can also benefit from the proposed method.
C1 [Guo, Fan; Li, Weiqing; Kuang, Zhonghao; Tang, Jin] Cent South Univ, Sch Automat, Changsha 410083, Peoples R China.
C3 Central South University
RP Tang, J (corresponding author), Cent South Univ, Sch Automat, Changsha 410083, Peoples R China.
EM tjin@csu.edu.cn
FU National Natural Science Foundation of China [61502537]; Hunan
   Provincial Natural Science Foundation of China [2018JJ3681]; Fundamental
   Research Funds for the Central Universities of Central South University
   [2020zzts567]
FX This research was funded by the National Natural Science Foundation of
   China (Grant No. 61502537), the Hunan Provincial Natural Science
   Foundation of China (Grant No. 2018JJ3681), and the Fundamental Research
   Funds for the Central Universities of Central South University
   (No.2020zzts567). We would also like to thank Pingbo Ouyang, the doctor
   of Xiangya second hospital, Changsha, P.R. China, for her support and
   guidance.
CR Agarwal A, 2015, 2015 4TH INTERNATIONAL WORK CONFERENCE ON BIOINSPIRED INTELLIGENCE (IWOBI), P139, DOI 10.1109/IWOBI.2015.7160157
   Al-Mahadin A., 2018, SOLVING PAVEMENT CON, P1, DOI DOI 10.1680/JC0MA.17.00017
   Biswas R, 2020, IJST-T ELECTR ENG, V44, P505, DOI 10.1007/s40998-019-00213-7
   Bourne RRA, 2006, BRIT J OPHTHALMOL, V90, P253, DOI 10.1136/bjo.2005.083527
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Cheng J, 2017, BIOMED OPT EXPRESS, V8, P2687, DOI 10.1364/BOE.8.002687
   Cheng J, 2013, IEEE T MED IMAGING, V32, P1019, DOI 10.1109/TMI.2013.2247770
   Chowdhary C.L., 2018, Nature inspired computing, P75
   Chowdhary CL, 2020, PROCEDIA COMPUT SCI, V167, P26, DOI 10.1016/j.procs.2020.03.179
   Chowdhary CL, 2017, J BIOMIM BIOMATER BI, V30, P12, DOI 10.4028/www.scientific.net/JBBBE.30.12
   Chowdhary CL, 2016, INT J HEALTHC INF SY, V11, P38, DOI 10.4018/IJHISI.2016040103
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Feng ST, 2020, NEUROCOMPUTING, V392, P268, DOI 10.1016/j.neucom.2018.10.098
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Guo S, 2019, INT J MED INFORM, V126, P105, DOI 10.1016/j.ijmedinf.2019.03.015
   Hassan G, 2015, PROCEDIA COMPUT SCI, V65, P612, DOI 10.1016/j.procs.2015.09.005
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Issac A, 2015, COMPUT METH PROG BIO, V122, P229, DOI 10.1016/j.cmpb.2015.08.002
   Jonas JB, 2000, INVEST OPHTH VIS SCI, V41, P1764
   Koukounis D, 2014, INTEGRATION, V47, P377, DOI 10.1016/j.vlsi.2013.11.005
   Liu Q, 2019, NEUROCOMPUTING, V359, P285, DOI 10.1016/j.neucom.2019.05.039
   Lupascu CA, 2010, IEEE T INF TECHNOL B, V14, P1267, DOI 10.1109/TITB.2010.2052282
   Lv Y, 2020, IEEE ACCESS, V8, P32826, DOI 10.1109/ACCESS.2020.2974027
   Mittapalli PS, 2016, BIOMED SIGNAL PROCES, V24, P34, DOI 10.1016/j.bspc.2015.09.003
   Nayak J, 2009, J MED SYST, V33, P337, DOI 10.1007/s10916-008-9195-z
   Ni JJ, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2019.105121
   Noor NM, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2013), P530, DOI 10.1109/ICCSCE.2013.6720022
   Ramlugun GS, 2012, EXPERT SYST APPL, V39, P1141, DOI 10.1016/j.eswa.2011.07.115
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sevastopolsky A., 2017, Pattern Recognition and Image Analysis, V27, P618, DOI 10.1134/S1054661817030269
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tang P, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103352
   Tham Yih-Chung, 2014, Ophthalmology, V121, P2081, DOI 10.1016/j.ophtha.2014.05.013
   Wu YC, 2020, NEURAL NETWORKS, V126, P153, DOI 10.1016/j.neunet.2020.02.018
   Yu F., 2015, ARXIV
   Yue KJ, 2019, J MED IMAGING, V6, DOI [10.1117/1.JMI.6.3.034004, 10.1117/1.JMI.6.3.030004]
   Zhang Z, 2010, IEEE ENG MED BIO, P3065, DOI 10.1109/IEMBS.2010.5626137
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
   Zhu CZ, 2017, COMPUT MED IMAG GRAP, V55, P68, DOI 10.1016/j.compmedimag.2016.05.004
NR 43
TC 9
Z9 11
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14767
EP 14788
DI 10.1007/s11042-021-10580-1
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000612593600005
DA 2024-07-18
ER

PT J
AU Khowaja, SA
   Khuwaja, P
AF Khowaja, Sunder Ali
   Khuwaja, Parus
TI Q-learning and LSTM based deep active learning strategy for malware
   defense in industrial IoT applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Malware classification; Android malware; Active learning; LSTM;
   Reinforcement learning
ID CLASSIFICATION; FRAMEWORK; RECOGNITION
AB Edge devices are extensively used as intermediaries between the device and the service layer in an industrial Internet of things (IIoT) environment. These devices are quite vulnerable to malware attacks. Existing studies have worked on designing complex learning algorithms or deep architectures to accurately classify malware assuming that a sufficient number of labeled examples are provided. In the real world, getting labeled examples is one of the major issues for training any classification algorithm. Recent advances have allowed researchers to use active learning strategies that are trained on a handful of labeled examples to perform the classification task, but they are based on the selection of informative instances. This study integrates the Q-learning characteristics into an active learning framework, which allows the network to either request or predict a label during the training process. We proposed the use of phase space embedding, sparse autoencoder, and LSTM with the action-value function to classify malware applications while using a handful of labeled examples. The network relies on its uncertainty to either request or predict a label. The experimental results show that the proposed method can achieve better accuracy than the supervised learning strategy while using few labeled requests. The results also show that the trained network is resilient to the adversarial attacks, which proves the robustness of the proposed method. Additionally, this study explores the tradeoff between classification accuracy and number of label requests via the choice of rewards and the use of decision-level fusion strategies to boost the classification performance. Furthermore, we also provide a hypothetical framework as an implication of the proposed method.
C1 [Khowaja, Sunder Ali] Univ Sindh, Fac Engn & Technol, Dept Telecommun, Jamshoro, Pakistan.
   [Khuwaja, Parus] Univ Sindh, Inst Business Adm, Jamshoro, Pakistan.
C3 University of Sindh; University of Sindh
RP Khowaja, SA (corresponding author), Univ Sindh, Fac Engn & Technol, Dept Telecommun, Jamshoro, Pakistan.
EM Sandar.ali@usindh.edu.pk
RI Khowaja, Sunder Ali/N-2065-2019
OI Khowaja, Sunder Ali/0000-0002-4586-4131
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   Abraham A, GITHUB
   Abu Samra AA, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING (IMIS 2013), P729, DOI 10.1109/IMIS.2013.111
   Afonso VM, 2015, J COMPUT VIROL HACKI, V11, P9, DOI 10.1007/s11416-014-0226-7
   Ahmed A, 2019, IEEE T IND APPL, V55, P6313, DOI 10.1109/TIA.2019.2928500
   Anderson H, 2017, Black Hat
   [Anonymous], 2009, Technical report
   [Anonymous], 2018, METALEARNING TRANSFE
   Arp D, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23247
   Arshad J, 2020, MECH SYST SIGNAL PR, V136, DOI 10.1016/j.ymssp.2019.106436
   Bachman P, 2017, PR MACH LEARN RES, V70
   Boche H, 2006, IEEE T INFORM THEORY, V52, P5539, DOI 10.1109/TIT.2006.885488
   Boyes H, 2018, COMPUT IND, V101, P1, DOI 10.1016/j.compind.2018.04.015
   Cao LY, 1997, PHYSICA D, V110, P43, DOI 10.1016/S0167-2789(97)00118-8
   Carter KM, 2011, IEEE SIGNAL PROC MAG, V28, P89, DOI 10.1109/MSP.2010.939536
   Caspi O, 2015, GITHUB
   Chakrabarty Shaibal, 2016, 2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC), P812, DOI 10.1109/CCNC.2016.7444889
   Cheng FZ, 2018, IEEE T IND APPL, V54, P1062, DOI 10.1109/TIA.2017.2773426
   Chu W., 2011, P 17 ACM SIGKDD INT, P195
   D'Angelo G, 2020, J PARALLEL DISTR COM, V137, P26, DOI 10.1016/j.jpdc.2019.11.001
   Dang H, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P119, DOI 10.1145/3133956.3133978
   DAXU L, 2014, INFORMAT, V10, P2233, DOI DOI 10.1109/TII.2014.2300753
   Desnos, 2016, GITHUB
   Ducoffe M., 2018, Adversarial Active Learning for Deep Networks: a Margin Based Approach
   Garcia J, 2018, ACM T SOFTW ENG METH, V26, DOI 10.1145/3162625
   Gascon Hugo, 2013, P 2013 ACM WORKSH AR, P45
   Gong, 2017, GITHUB
   Grosse Kathrin, 2017, Computer Security - ESORICS 2017. 22nd European Symposium on Research in Computer Security. Proceedings: LNCS10493, P62, DOI 10.1007/978-3-319-66399-9_4
   Torres JLG, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102388
   Hadgu AT, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2828, DOI 10.1109/BigData.2015.7364091
   Hassani-Gangaraj M, 2017, PHYS REV LETT, V119, DOI 10.1103/PhysRevLett.119.175701
   He M, 2017, IEEE T IND APPL, V53, P3057, DOI 10.1109/TIA.2017.2661250
   Huang Y, 2017, EUR J OPER RES, V258, P692, DOI 10.1016/j.ejor.2016.08.058
   Jerald AV, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P800
   Kapratwar Ankita., 2016, Static and Dynamic Analysis for Android Malware Detection"
   Karnouskos S, 2011, IEEE IND ELEC, P4490
   Kaspersky, 2017, KASP
   Khoda ME, 2020, IEEE T IND APPL, V56, P4415, DOI 10.1109/TIA.2019.2958530
   Khowaja SA, 2020, INT J COMPUT VISION, V128, P393, DOI 10.1007/s11263-019-01248-3
   Khowaja SA, 2020, NEURAL COMPUT APPL, V32, P10423, DOI 10.1007/s00521-019-04578-y
   Khowaja SA, 2019, SIGNAL IMAGE VIDEO P, V13, P379, DOI 10.1007/s11760-018-1366-x
   Khowaja SA, 2018, COMPUT NETW, V145, P190, DOI 10.1016/j.comnet.2018.09.003
   Khowaja SA, 2017, EXPERT SYST APPL, V88, P165, DOI 10.1016/j.eswa.2017.06.040
   Khuwaja P, 2020, J EXP THEOR ARTIF IN, V32, P59, DOI 10.1080/0952813X.2019.1620870
   Laskey M, 2016, IEEE INT CONF ROBOT, P462, DOI 10.1109/ICRA.2016.7487167
   Liu Y, 2004, J CHEM INF COMP SCI, V44, P1936, DOI 10.1021/ci049810a
   Lughofer E, 2012, EVOL SYST-GER, V3, P135, DOI 10.1007/s12530-012-9046-5
   Martín A, 2019, INFORM FUSION, V52, P128, DOI 10.1016/j.inffus.2018.12.006
   McLaughlin N, 2017, PROCEEDINGS OF THE SEVENTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY (CODASPY'17), P301, DOI 10.1145/3029806.3029823
   Meng SM, 2021, IEEE T IND INFORM, V17, P4219, DOI 10.1109/TII.2020.2995348
   Mnih V., 2013, PLAYING ATARI DEEP R, DOI DOI 10.1038/NATURE14236
   Mnih V, 2016, PR MACH LEARN RES, V48
   Moskovitch R., 2008, P 2 INT WORKSH PRIV, P1
   Naeem H, 2020, AD HOC NETW, V105, DOI 10.1016/j.adhoc.2020.102154
   Nissim N, 2016, J BIOMED INFORM, V61, P44, DOI 10.1016/j.jbi.2016.03.016
   Nix R, 2017, IEEE IJCNN, P1871, DOI 10.1109/IJCNN.2017.7966078
   Pi L, 2016, IEEE GLOB CONF SIG, P257, DOI 10.1109/GlobalSIP.2016.7905843
   Povinelli RJ, 2004, IEEE T KNOWL DATA EN, V16, P779, DOI 10.1109/TKDE.2004.17
   Rajesh S, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020293
   Rashidi B., 2017, 2017 13th International Conference on Network and Service Management (CNSM), P1
   Rawlinson K., 2014, HP Study Reveals 70 Percent of Internet of Things Devices Vulnerable To Attack
   Sahin D.O., 2018, 2018 6 INT S DIGITAL, P1, DOI DOI 10.1109/ISDFS.2018.8355377
   SANTOS A, 2016, P IEEE EL POW EN C O, P1, DOI DOI 10.1109/PSCC.2016.7540874
   Security, 2020, HELP NET SECUR
   Sharmeen S, 2018, IEEE ACCESS, V6, P15941, DOI 10.1109/ACCESS.2018.2815660
   Shi Y., 2018, IEEE Transactions on Automatic Control, P1
   Shrivastava G, 2019, MULTIMED TOOLS APPL, V78, P35713, DOI 10.1007/s11042-019-07899-1
   Su X, 2016, IEEE TRUST, P244, DOI [10.1109/TrustCom.2016.69, 10.1109/TrustCom.2016.0070]
   Sun H, 2017, SOFTWARE PRACT EXPER, V47, P421, DOI 10.1002/spe.2420
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Takens F, 1981, Lecture Notes in Mathematics, V898, P366, DOI [10.1007/BFb0091924, DOI 10.1007/BFB0091924]
   Terra, 2014, GITHUB
   Tong F, 2017, J PARALLEL DISTR COM, V103, P22, DOI 10.1016/j.jpdc.2016.10.012
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang Z., 2016, ARCH COMPUTATIONAL M, P1, DOI DOI 10.1007/s11831-016-9181-4
   Wang Z, 2016, IEEE SARNOFF SYMPOS, P160
   Woodward M., 2017, Active one-shot learning
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiao X, 2019, MULTIMED TOOLS APPL, V78, P3979, DOI 10.1007/s11042-017-5104-0
   Xu K, 2016, IEEE T INF FOREN SEC, V11, P1252, DOI 10.1109/TIFS.2016.2523912
   Yan L. K., 2012, P 21 USENIX SEC S US, P569
   Yang W, 2017, ANN COMPUT SECURITY, P288, DOI 10.1145/3134600.3134642
   Yerima SY, 2015, IET INFORM SECUR, V9, P313, DOI 10.1049/iet-ifs.2014.0099
   Yerima SY, 2014, IET INFORM SECUR, V8, P25, DOI 10.1049/iet-ifs.2013.0095
   Yuan ZL, 2016, TSINGHUA SCI TECHNOL, V21, P114
   Yuan ZL, 2014, SIGCOMM'14: PROCEEDINGS OF THE 2014 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P371, DOI [10.1145/2619239.2631434, 10.1145/2740070.2631434]
   Zhang Jiakai., 2016, Query-efficient imitation learning for end-to-end autonomous driving
   Zhao PL, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P919
   Zhou QG, 2019, MULTIMED TOOLS APPL, V78, P3529, DOI 10.1007/s11042-018-6498-z
   Zhou Y, 2019, LECT NOTES ARTIF INT, V11607, P77, DOI 10.1007/978-3-030-26142-9_8
   Zhu, 2017, AUTOMOTIVE MECH ELEC, P345
NR 91
TC 11
Z9 12
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14637
EP 14663
DI 10.1007/s11042-020-10371-0
EA JAN 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000612593600004
DA 2024-07-18
ER

PT J
AU Tahaoglu, G
   Ulutas, G
   Ustubioglu, B
   Nabiyev, VV
AF Tahaoglu, Gul
   Ulutas, Guzin
   Ustubioglu, Beste
   Nabiyev, Vasif V.
TI Improved copy move forgery detection method via L*a*b* color space and
   enhanced localization technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE L*a*b* color space; Copy move forgery; Dynamic localization
AB The wide availability of easy-to-use image editors has made the authenticity of images questionable. Copy-move is one of the most applied forgery types. A new copy-move forgery detection and localization technique independent from the characteristics of the forged regions is proposed in this paper. SIFT keypoints are obtained from CLAHE applied sub-images extracted from the input image by using RGB and L*a*b* color-spaces. Keypoint matching is realized on the sub-images and duplicated regions are determined roughly to create roughly marked image R. RANSAC is also applied in this stage and generated homography matrix is used to construct transformed roughly marked image R-'. The method extracts DCT based features from R and R-' to localize exact borders of the tampered regions on the roughly determined areas by using a dynamic threshold. The proposed method has a new suggestion to determine the threshold dynamically. Tamper localization procedure also utilizes from morphological operations (chosen depending on the characteristic of the image) and Connected Component Labeling to determine exact forge boundaries. Results indicate that the proposed method has a better performance compared with state-of-the-art copy-move forgery detection methods on the GRIP dataset. Scaling attack performance of the method is especially better than similar works as shown in the results.
C1 [Tahaoglu, Gul; Ulutas, Guzin; Ustubioglu, Beste; Nabiyev, Vasif V.] Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
C3 Karadeniz Technical University
RP Tahaoglu, G (corresponding author), Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
EM tahaoglugul@gmail.com
RI Nabiyev, Vasif/AAK-3768-2021; USTUBIOGLU, Beste/AAJ-8187-2021; Ulutas,
   Guzin/ABI-4484-2020; Tahaoglu, Gul/AAK-5783-2021
OI Tahaoglu, Gul/0000-0002-8828-5674
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [119E045]
FX This work was supported by the Scientific and Technological Research
   Council of Turkey (TUBITAK) with Project No: 119E045.
CR Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   Alberry Hesham A., 2018, Future Computing and Informatics Journal, V3, P159, DOI 10.1016/j.fcij.2018.03.001
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Haralick RM., 1992, CONNECTED COMPONENT
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   KASSON JM, 1992, ACM T GRAPHIC, V11, P373, DOI 10.1145/146443.146479
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Li Y, 2016, P AS PAC SIGN INF PR, P1
   LIAN S, 2009, INFORMATICA, V33, P3
   Luo WQ, 2006, INT C PATT RECOG, P746
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Pellegrini A, 2008, PR IEEE COMP DESIGN, P363, DOI 10.1109/ICCD.2008.4751886
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Pun CM, 2018, INFORM SCIENCES, V463, P33, DOI 10.1016/j.ins.2018.06.040
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Rey C, 2002, EURASIP J APPL SIG P, V2002, P613, DOI 10.1155/S1110865702204047
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Shi WC, 2016, CHINA COMMUN, V13, P139, DOI 10.1109/CC.2016.7405711
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Wang JW, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P25, DOI 10.1109/MINES.2009.142
   Wu QM, 2011, IEEE SIGNAL PROC LET, V18, P559, DOI 10.1109/LSP.2011.2163507
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Zandi M, 2014, IEEE INT WORKS INFOR, P119, DOI 10.1109/WIFS.2014.7084314
   Zhu Y., 2015, MULTIMED TOOLS APPL, V75, P1
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 38
TC 13
Z9 13
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23419
EP 23456
DI 10.1007/s11042-020-10241-9
EA JAN 2021
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000608968500004
DA 2024-07-18
ER

PT J
AU Tripathi, K
   Rao, KS
AF Tripathi, Kumud
   Rao, K. Sreenivasa
TI Robust vowel region detection method for multimode speech
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Continuous wavelet transform (CWT); Phone boundary; Vowel onset point;
   Vowel end point; Vowel region; Multilingual speech mode classification
ID SPEAKER VERIFICATION; ONSET; EXTRACTION; FEATURES; POINTS
AB The aim of this paper is to explore a robust method for vowel region detection from multimode speech. In realistic scenario, speech can be classified into three modes namely; conversation, extempore, and read. The existing method detects the vowel form the speech recorded in clean environment which may not be appropriate for the multimode speech tasks. To address this issue, we proposed an approach based on continuous wavelet transform coefficients and phone boundaries for detecting the vowel regions from different modes of the speech signal. For evaluation of the proposed vowel region (VR) detection technique, TIMIT (read speech) and Bengali (read, extempore, and conversation speech) corpora are used. The proposed VR detection technique is compared to the state-of-the-art methods. The experiments has recorded significant gain in the performance of the proposed technique than the state-of-the-art methods. The efficiency of the proposed technique is shown by extracting vocal tract and excitation source features from automatically detected VRs for developing the multilingual speech mode classification (MSMC) model. The evaluation results report that the performance of the MSMC model is significantly improved when features are extracted from the vowel regions than the entire speech utterance.
C1 [Tripathi, Kumud; Rao, K. Sreenivasa] Indian Inst Technol Kharagpur, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Tripathi, K (corresponding author), Indian Inst Technol Kharagpur, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
EM kumudtripathi.cs@gmail.com; ksrao@iitkgp.ac.in
OI Tripathi, Kumud/0000-0003-4198-7430
CR Burget L, 2010, INT CONF ACOUST SPEE, P4334, DOI 10.1109/ICASSP.2010.5495646
   FURUI S, 1986, J ACOUST SOC AM, V80, P1016, DOI 10.1121/1.393842
   Garofalo JS, 1993, DARPA TIMIT ACOUSTIC, P207
   Haykin S., 1994, NEURAL NETWORKS COMP
   Jayagopi DB, 2017, IEEE INT C SIGNAL PR, P1, DOI DOI 10.1109/SPICES.2017.8091271
   Keerthana YM, 2019, IEEE SIGNAL PROC LET, V26, P1107, DOI 10.1109/LSP.2019.2921229
   Kumar A, 2017, INTERSPEECH, P429, DOI 10.21437/Interspeech.2017-624
   Kumar A, 2017, CIRC SYST SIGNAL PR, V36, P2315, DOI 10.1007/s00034-016-0409-1
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Manjunath KE, 2015, INT J SPEECH TECHNOL, V18, P257, DOI 10.1007/s10772-014-9266-0
   Manjunath KE, 2014, 20 NAT C COMM NCC, P1
   Murty KSR, 2008, IEEE T AUDIO SPEECH, V16, P1602, DOI 10.1109/TASL.2008.2004526
   Pradhan G, 2013, IEEE T AUDIO SPEECH, V21, P854, DOI 10.1109/TASL.2013.2238529
   Prasanna SRM, 2011, IEEE T AUDIO SPEECH, V19, P2552, DOI 10.1109/TASL.2011.2155061
   Prasanna SRM, 2009, IEEE T AUDIO SPEECH, V17, P556, DOI 10.1109/TASL.2008.2010884
   Ramdinmawii E, 2017, TENCON IEEE REGION, P1562, DOI 10.1109/TENCON.2017.8228105
   Rao KS, 2019, 22 C OR COCOSDA
   Rao KS, 2016, 9 INT C CONT COMP IC, P1
   Reddy MK, 2017, IEEE SIGNAL PROC LET, V24, P1133, DOI 10.1109/LSP.2017.2712646
   Scanzio S, 2008, 9 ANN C INT SPEECH C
   Sundarkumar G G., 2013, 2013 IEEE International Conference on Computational Intelligence and Computing Research, IEEE ICCIC 2013, P1, DOI [DOI 10.1109/ICCIC.2013.6724229, DOI 10.1109/ICSDA.2013.6709901, DOI 10.1109/ICCCI.2013.6466113]
   Thirumuru R, 2018, MULTIMED TOOLS APPL, V77, P4753, DOI 10.1007/s11042-017-5044-8
   Tripathi K, 2019, VOP DETECTION READ C
   Tripathi K, 2018, INT J SPEECH TECHNOL, V21, P489, DOI 10.1007/s10772-017-9483-4
   Vainio MT, 2016, P SPEECH PROS 2016
   Vuppala AK, 2016, INT S CHINESE SPOKEN, P1
   Vuppala AK, 2013, INT J ADAPT CONTROL, V27, P781, DOI 10.1002/acs.2357
   Vuppala AK, 2012, AEU-INT J ELECTRON C, V66, P697, DOI 10.1016/j.aeue.2011.12.013
   Vuppala AK, 2012, IEEE T AUDIO SPEECH, V20, P1894, DOI 10.1109/TASL.2012.2191284
   Yadav J, 2013, IEEE SIGNAL PROC LET, V20, P299, DOI 10.1109/LSP.2013.2245647
NR 30
TC 2
Z9 2
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13615
EP 13637
DI 10.1007/s11042-020-10394-7
EA JAN 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607985400001
DA 2024-07-18
ER

PT J
AU Narciso, D
   Melo, M
   Rodrigues, S
   Cunha, JP
   Vasconcelos-Raposo, J
   Bessa, M
AF Narciso, David
   Melo, Miguel
   Rodrigues, Susana
   Paulo Cunha, Joao
   Vasconcelos-Raposo, Jose
   Bessa, Maximino
TI A systematic review on the use of immersive virtual reality to train
   professionals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Virtual reality; Multisensory stimuli; Professional training; Systematic
   review
ID ENVIRONMENTS; EDUCATION; GAMES
AB The main goal of this systematic review is to synthesize existing evidence on the use of immersive virtual reality (IVR) to train professionals as well as to identify the main gaps and challenges that still remain and need to be addressed by future research. Following a comprehensive search, 66 documents were identified, assessed for relevance, and analysed. The main areas of application of IVR-based training were identified. Moreover, we identified the stimuli provided, the hardware used and information regarding training evaluation. The results showed that the areas in which a greater number of works were published were those related to healthcare and elementary occupations. In hardware, the most commonly used equipment was head mounted displays (HMDs), headphones included in the HMDs and handheld controllers. Moreover, the results indicated that IVR training systems are often evaluated manually, the most common metric being questionnaires applied before and after the experiment, and that IVR training systems have a positive effect in training professionals. We conclude that the literature is insufficient for determining the effect of IVR in the training of professionals. Although some works indicated promising results, there are still relevant themes that must be explored and limitations to overcome before virtual training replaces real-world training.
C1 [Narciso, David; Vasconcelos-Raposo, Jose; Bessa, Maximino] Univ Tras Os Montes & Alto Douro, Vila Real, Portugal.
   [Narciso, David; Melo, Miguel; Rodrigues, Susana; Paulo Cunha, Joao; Vasconcelos-Raposo, Jose; Bessa, Maximino] INESC TEC, Porto, Portugal.
   [Paulo Cunha, Joao] Univ Porto, Fac Engn, Porto, Portugal.
C3 University of Tras-os-Montes & Alto Douro; INESC TEC; Universidade do
   Porto
RP Narciso, D (corresponding author), Univ Tras Os Montes & Alto Douro, Vila Real, Portugal.; Narciso, D (corresponding author), INESC TEC, Porto, Portugal.
EM davidgnarciso@gmail.com
RI VASCONCELOS-RAPOSO, JOSÉ/G-3743-2010; VASCONCELOS-RAPOSO,
   JOSE/JMB-6306-2023; Cunha, Joao Paulo/F-9039-2010
OI VASCONCELOS-RAPOSO, JOSÉ/0000-0002-3456-9727; Rodrigues,
   Susana/0000-0001-6546-340X; Narciso, David/0000-0001-9630-310X; Cunha,
   Joao Paulo/0000-0003-4131-9045; Bessa, Maximino/0000-0002-3002-704X;
   Melo, Miguel/0000-0003-4050-3473
FU ERDF-European Regional Development Fund through the Operational Program
   for Competitiveness and Internationalization-COMPETE 2020 Program;
   Portuguese funding agency, FCT-Fundacao para a Ciencia e a Tecnologia
   [POCI-01-0145-FEDER-028618]; FCT, Foundation for Science and Technology
   [SFRH/BD/147334/2019]; Fundação para a Ciência e a Tecnologia
   [SFRH/BD/147334/2019] Funding Source: FCT
FX This work was partially financed by the ERDF-European Regional
   Development Fund through the Operational Program for Competitiveness and
   Internationalization-COMPETE 2020 Program and by National Funds through
   the Portuguese funding agency, FCT-Fundacao para a Ciencia e a
   Tecnologia, project POCI-01-0145-FEDER-028618 entitled
   PERFECT-Perceptual Equivalence in virtual Reality For authEntiC
   Training. This work was also partially financed by the National funding
   by FCT, Foundation for Science and Technology, through the PhD Research
   Scholarship SFRH/BD/147334/2019.
CR [Anonymous], 2019, CYBERGLOVE SYSTEMS
   [Anonymous], 2019, ISCO08
   Bertrand J, 2017, IEEE SYMP 3D USER, P59, DOI 10.1109/3DUI.2017.7893318
   Burdea GC, 2003, VIRTUAL REALITY TECH
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   de Visser H, 2011, MED J AUSTRALIA, V194, pS38
   Dwivedi P, 2018, IEEE INT CONF ADV LE, P395, DOI 10.1109/ICALT.2018.00100
   Elbert R, 2018, IFAC PAPERSONLINE, V51, P686, DOI 10.1016/j.ifacol.2018.08.398
   Feelreal, 2019, MULTISENSORY VR MASK
   Feng ZA, 2018, COMPUT EDUC, V127, P252, DOI 10.1016/j.compedu.2018.09.002
   Haque S, 2006, IEEE T INF TECHNOL B, V10, P51, DOI 10.1109/TITB.2005.855529
   Hayward V., 2004, Sensor Review, V24, P16, DOI 10.1108/02602280410515770
   Hui Z, 2017, INT J MIN SCI TECHNO, V27, P717, DOI 10.1016/j.ijmst.2017.05.005
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Kinateder M, 2014, ACSIS-ANN COMPUT SCI, V2, P313
   Kumar N, 2017, INT J RECENT INNOV T, V5, P254
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Menin A, 2018, IEEE COMPUT GRAPH, V38, P57, DOI 10.1109/MCG.2018.021951633
   Moher D, 2009, J CLIN EPIDEMIOL, V62, P1006, DOI 10.1016/j.jclinepi.2009.06.005
   Nadia Zita, 2018, Journal of Computers, V13, P721, DOI 10.17706/jcp.13.6.721-732
   Pagano K, 2017, IEEE CONSUM ELECTR M, V6, P45, DOI 10.1109/MCE.2016.2614413
   Queiroz ACM, 2018, 24 AM C INF SYST, P1
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
   Sankaranarayanan G, 2018, SURG ENDOSC, V32, P3439, DOI 10.1007/s00464-018-6063-x
   Schlueter J, 2017, PROC SPIE, V10197, DOI 10.1117/12.2262718
   Schoor W, 2010, J VIRT REALITY BROAD, V6, P1
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Vi C.T., 2017, Proceedings of the 2nd ACM SIGCHI International Workshop on Multisensory Approaches to Human-Food Interaction, P29, DOI [10.1145/3141788.3141794, DOI 10.1145/3141788.3141794]
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 30
TC 15
Z9 15
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13195
EP 13214
DI 10.1007/s11042-020-10454-y
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607504000005
DA 2024-07-18
ER

PT J
AU Iqbal, M
   Riaz, MM
   Ghafoor, A
   Ahmad, A
   Ali, SS
AF Iqbal, Mehwish
   Riaz, Muhammad Mohsin
   Ghafoor, Abdul
   Ahmad, Attiq
   Ali, Syed Sohaib
TI Out of focus multi-spectral image de-blurring using texture extraction
   and modified fourier transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-spectral images; Out-of-focus de-blur; Guided filter; L0
   smoothing; Texture extraction; Fourier transform
AB Multi-spectralimages suffers from out-of-focusblur due to well focused camera at the reference imaging channel. A framework for out-of-focus images de-blurring using texture extraction and modified Fourier transform is proposed. The texture is extracted from the blurred image using region covariance. Fourier transform is modified by modification of guided image (as prior) using L-0 gradient projection followed by detail amplification which is used as an input for Fourier transform. For further enhancement, the multi-spectral de-blurred images are smooth, and ringing artifacts are minimized by combining with the textures extracted to ensure maximum edge preservation. Comparison of proposed and existing schemes on different multi-spectral images explains the advantage of the proposed scheme for de-blurring in terms of edge preservation, noise and artifacts removal.
C1 [Iqbal, Mehwish; Ghafoor, Abdul; Ahmad, Attiq] Natl Univ Sci & Technol NUST, Islamabad, Pakistan.
   [Riaz, Muhammad Mohsin; Ali, Syed Sohaib] COMSATS, Ctr Adv Studies Telecommun CAST, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan; COMSATS
   University Islamabad (CUI)
RP Ghafoor, A (corresponding author), Natl Univ Sci & Technol NUST, Islamabad, Pakistan.
EM mehwish.phd@students.mcs.edu.pk; mohsin.riaz@comsats.edu.pk;
   abdulghafoor-mcs@nust.edu.pk; attiq@mcs.edu.pk;
   sohaib.ali@comsats.edu.pk
RI Imran, Muhammad/AAS-9984-2021
OI Imran, Muhammad/0000-0002-7122-8454; Ghafoor, Abdul/0000-0002-6117-3656;
   Syed, Sohaib Ali/0000-0003-4795-7275
CR Anger J, 2019, IMAGE PROCESS ON LIN, V9, P124, DOI 10.5201/ipol.2019.243
   Bjelopera A, 2017, RADIOENGINEERING, V26, P930, DOI 10.13164/re.2017.0930
   Chen F, 2019, COMPUTER VISION PATT, P4321
   Chen L, 2019, PROC CVPR IEEE, P1742, DOI 10.1109/CVPR.2019.00184
   Chen SJ, 2015, IEEE T IMAGE PROCESS, V24, P4433, DOI 10.1109/TIP.2015.2465162
   Chouhan S., 2016, IEEE POWER ENERGY SO, P1, DOI DOI 10.1109/PESGM.2016.7741576
   Fang FM, 2017, INVERSE PROBL IMAG, V11, P65, DOI 10.3934/ipi.2017004
   Gao C, 2019, COMPLEXITY, V5, P1
   Gao W, 2017, PARAMETRIC BLUR ESTI, V24, P1
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Jeon HG, 2017, IEEE T IMAGE PROCESS, V26, P2311, DOI 10.1109/TIP.2017.2675202
   Jia J, 2013, P IEEE VTC JUN DRESD, P1
   Jiang XL, 2017, NEUROCOMPUTING, V242, P1, DOI 10.1016/j.neucom.2017.01.080
   Karacan L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508403
   Karnaukhov VN, 2016, J COMMUN TECHNOL EL+, V61, P1426, DOI 10.1134/S106422691612010X
   Kou F, 2015, IEEE SIGNAL PROC LET, V22, P211, DOI 10.1109/LSP.2014.2353774
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Kumar A, 2017, SIGNAL PROCESS-IMAGE, V55, P55, DOI 10.1016/j.image.2017.03.016
   Kwon JY, 2017, CIRCUITS SYSTEMS SIG, P1
   Li DW, 2019, J COMPUT SCI TECH-CH, V34, P569, DOI 10.1007/s11390-019-1927-7
   Li TH, 2019, PATTERN RECOGN, V90, P134, DOI 10.1016/j.patcog.2019.01.019
   Liu YQ, 2021, IEEE T CIRC SYST VID, V31, P829, DOI 10.1109/TCSVT.2020.2990623
   Ono S, 2017, IEEE T IMAGE PROCESS, V26, P1554, DOI 10.1109/TIP.2017.2651392
   Pan JS, 2018, IEEE T PATTERN ANAL, V40, P2315, DOI 10.1109/TPAMI.2017.2753804
   Pan ZW, 2016, IEEE T IMAGE PROCESS, V25, P3612, DOI 10.1109/TIP.2016.2576401
   Raina P, 2017, IEEE J SOLID-ST CIRC, V99, P1
   Ren DZ, 2020, CELL CYCLE, V19, P1067, DOI 10.1080/15384101.2020.1731651
   Shen HL, 2012, APPL OPTICS, V51, P2616, DOI 10.1364/AO.51.002616
   Wang H, 2016, ASIAN C COMPUT VIS, V10116, P3
   Xu, 2019, COMPUTER VISION PATT, P1
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Ye MY, 2020, IEEE ACCESS, V8, P18316, DOI 10.1109/ACCESS.2020.2967823
   Ye PZ, 2016, OPT REV, V23, P907, DOI 10.1007/s10043-016-0269-8
   Zhang FJ, 2018, MULTIMED TOOLS APPL, V77, P26239, DOI 10.1007/s11042-018-5847-2
   Zhang KH, 2019, IEEE T IMAGE PROCESS, V28, P291, DOI 10.1109/TIP.2018.2867733
NR 36
TC 1
Z9 1
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12671
EP 12684
DI 10.1007/s11042-020-10232-w
EA JAN 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607038000003
OA hybrid
DA 2024-07-18
ER

PT J
AU Lee, H
   Jung, J
   Lee, HK
   Yang, HS
AF Lee, Hyeopwoo
   Jung, Jinki
   Lee, Heung-Kyu
   Yang, Hyun Seung
TI Discipline vs guidance: comparison of visual engagement approaches in
   immersive virtual environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Immersive virtual environment; Virtual training;
   Learning engagement; Visual engagement; Discipline; Guidance
ID REALITY; ATTENTION; DISTRACTION; PERFORMANCE; INTERFACES; KNOWLEDGE;
   FIDELITY
AB Immersive virtual environments (IVEs) have been extensively investigated for applications in education and man-power training because of the benefits of immersion-driven experiences as immersion becomes a factor that can both accelerate and hamper learning depending on the user's area of focus, which supports the importance of engagement. In this paper, two fundamental approaches to visual engagement in IVE are compared: discipline and guidance. The approaches aim to foster the learner's engagement to predefined area to be focused by either subtracting visual stimuli (discipline) or appending visual indicators pointing to the area (guidance). The experimental results showed no significant improvement in memory recall accuracy and time. However, the guidance group showed superior performances in usability metrics. Interestingly, a significant difference was found in the objective measure of the participants' gaze pattern revealing that the discipline makes the user's gaze consistent and stable.
C1 [Lee, Hyeopwoo; Lee, Heung-Kyu; Yang, Hyun Seung] Korea Adv Inst Sci & Technol, Sch Comp, Daejeon, South Korea.
   [Jung, Jinki] Digital Maritime Consultancy Aps, HC Orstedsvej 13,1 Tv, DK-1879 Frederiksberg, Denmark.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, H (corresponding author), Korea Adv Inst Sci & Technol, Sch Comp, Daejeon, South Korea.
EM leehyeopwoo@kaist.ac.kr; your.jinki.jung@gmail.com
RI Yang, Hyun Seung/C-1984-2011
CR [Anonymous], 2014, P INT C ICT ED 2014
   Baird B, 2012, PSYCHOL SCI, V23, P1117, DOI 10.1177/0956797612446024
   Beeharee A. K, 2003, P ACM S VIRT REAL SO, P213
   Bell BS, 2002, PERS PSYCHOL, V55, P267, DOI 10.1111/j.1744-6570.2002.tb00111.x
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Bork F, 2018, IEEE T VIS COMPUT GR, V24, P2983, DOI 10.1109/TVCG.2018.2868584
   BRACEY GW, 1994, PHI DELTA KAPPAN, V75, P494
   Cho BH, 2002, CYBERPSYCHOL BEHAV, V5, P129, DOI 10.1089/109493102753770516
   Covaci A, 2015, IEEE COMPUT GRAPH, V35, P55, DOI 10.1109/MCG.2015.95
   Danieau F, 2017, P IEEE VIRT REAL ANN, P205, DOI 10.1109/VR.2017.7892248
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   Fernandez M., 2017, Higher Learning Research Communications, V7, P1, DOI [10.18870/hlrc.v7i1.373, DOI 10.18870/HLRC.V7I1.373]
   Godse A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1807, DOI [10.1109/VR.2019.8798026, 10.1109/vr.2019.8798026]
   Heininga VE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0180753
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Homer BD, 2008, COMPUT HUM BEHAV, V24, P786, DOI 10.1016/j.chb.2007.02.009
   Ifenthaler D., 2007, Technology, Instruction, Cognition and Learning, V5
   Jung JK, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1812
   Lee H, 2019, INT SYM MIX AUGMENT, P318, DOI 10.1109/ISMAR.2019.00030
   Lengenfelder J, 2002, J HEAD TRAUMA REHAB, V17, P26, DOI 10.1097/00001199-200202000-00005
   Liang S, 2016, COMPUT METH PROG BIO, V132, P63, DOI 10.1016/j.cmpb.2016.04.023
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Mania K, 2006, IEEE T VIS COMPUT GR, V12, P396, DOI 10.1109/TVCG.2006.55
   Mania K, 2003, PRESENCE-TELEOP VIRT, V12, P296, DOI 10.1162/105474603765879549
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Negut A, 2017, CHILD NEUROPSYCHOL, V23, P692, DOI 10.1080/09297049.2016.1186617
   Nguyen VT, 2019, INT J SEMANT COMPUT, V13, P343, DOI 10.1142/S1793351X19400154
   Nielsen LT, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P229, DOI 10.1145/2993369.2993405
   Niezgoda M, 2015, TRANSPORT RES F-TRAF, V32, P23, DOI 10.1016/j.trf.2015.04.012
   Renner P, 2017, IEEE SYMP 3D USER, P186, DOI 10.1109/3DUI.2017.7893338
   Rerko L, 2013, J EXP PSYCHOL LEARN, V39, P1075, DOI 10.1037/a0031172
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Stevens J.A., 2015, OPEN J MODELLING SIM, V2015, P41, DOI [DOI 10.4236/OJMSI.2015.32005, https://doi.org/10.4236/ojmsi.2015.32005]
   Studio T, 2020, DINOSAURUS ANIMALS B
   Tönnis M, 2005, International Symposium on Mixed and Augmented Reality, Proceedings, P56
   TriForge, 2019, REAL NAT ENV
   Vanacken L, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P115
   Vaughan N, 2016, COMPUT SCI REV, V22, P65, DOI 10.1016/j.cosrev.2016.09.001
   Waller D, 1998, PRESENCE-TELEOP VIRT, V7, P129, DOI 10.1162/105474698565631
   Wang M, 2011, NEUROEPIDEMIOLOGY, V36, P2, DOI 10.1159/000320847
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Ying L, 2017, 2017 IEEE FRONT ED C, P1, DOI [10.1109/FIE.2017.8190660, DOI 10.1109/FIE.2017.8190660]
NR 42
TC 6
Z9 6
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31239
EP 31261
DI 10.1007/s11042-020-10267-z
EA JAN 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000606408900001
PM 33456314
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Hsu, CY
   Lin, LE
   Lin, CH
AF Hsu, Chia-Yuan
   Lin, Lu-En
   Lin, Chang Hong
TI Age and gender recognition with random occluded data augmentation on
   facial images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Age recognition; Gender recognition; Deep learning; Pattern recognition
ID CLASSIFICATION
AB In this article, we propose the Random Occlusion, a data augmentation method on facial images using simple image processing techniques for age and gender recognition. Previous methods achieved promising results on constrained datasets with strict environmental settings, but the results on unconstrained datasets are still far from perfect. This article proposed a data augmentation method by altering the training images that resemble real-life photos to improve the performance of the networks by providing more varieties to the training samples. The proposed method adopted three simple occlusion techniques, Blackout, Random Brightness, and Blur, and each simulates a different kind of challenge that would be encountered in real-world applications. We verify the effectiveness of the proposed method by implementing the augmentation method on two convolution neural networks (CNNs), the modified AdienceNet and VGG16 to perform age and gender classification. The proposed augmentation method improves the age accuracy results of the modified AdienceNet and VGG16 by 1.0% and 0.8%, respectively; and gender accuracy results of the AdienceNet and VGG16 by 1.5% and 1.2%, respectively.
C1 [Hsu, Chia-Yuan; Lin, Lu-En; Lin, Chang Hong] Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, 43 Keelung Rd,Sect 4, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Lin, CH (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, 43 Keelung Rd,Sect 4, Taipei, Taiwan.
EM chlin@mail.ntust.edu.tw
RI Lin, Chang Hong/GRE-7807-2022
OI Lin, Chang Hong/0000-0003-3646-3261
FU Ministry of Science and Technology in Taiwan [MOST
   106-2221-E-011-153-MY2]
FX This study was funded by the Ministry of Science and Technology in
   Taiwan for supporting this research under MOST 106-2221-E-011-153-MY2.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2017, L2 Regularization versus Batch and Weight Normalization
   [Anonymous], 2008, REAL LIF IM WORKSH E
   [Anonymous], 2010, Proc. MPVA
   Chen YB, 2020, J CONTEMP CHINA, V29, P1, DOI [10.1080/10670564.2019.1621526, 10.1080/01932691.2020.1791172, 10.1007/s12652-020-02066-z]
   Chen Y, 2020, ENG COMPUTATION, V37, P1557, DOI 10.1108/EC-06-2019-0287
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   DeVries T, 2017, PREPRINT
   DUNN D, 1995, IEEE T IMAGE PROCESS, V4, P947, DOI 10.1109/83.392336
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   El Dib MY, 2010, IEEE IMAGE PROC, P1589, DOI 10.1109/ICIP.2010.5651440
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P488, DOI 10.1007/978-3-319-10605-2_32
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Ge Y, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, P12
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Günay A, 2008, 23RD INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P378
   Holland O, 2016, 2016 23RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), DOI 10.1109/ICT.2016.7500442
   Hosseini S, 2018, PROC INT WORKSH ADV
   Hu M, 2014, INT CONF CLOUD COMPU, P103, DOI 10.1109/CCIS.2014.7175711
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Jabid T, 2010, IEEE ICCE
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Lapuschkin S, 2017, IEEE INT CONF COMP V, P1629, DOI 10.1109/ICCVW.2017.191
   Le QV, 2019, Learning data augmentation strategies for object detection
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Lu WP, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102794
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Luu K, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P314
   Maldonado R., 2003, Academy of Marketing Science Review, V3, P1
   Mnih V, 2014, ADV NEUR IN, V27
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6
   Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Rodríguez P, 2017, PATTERN RECOGN, V72, P563, DOI 10.1016/j.patcog.2017.06.028
   Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Silberman Nathan., Tensorflow-slim image classification model library
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tapia JE, 2013, IEEE T INF FOREN SEC, V8, P488, DOI 10.1109/TIFS.2013.2242063
   van de Wolfshaar J, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P188, DOI 10.1109/SSCI.2015.37
   Van Rossum G., 2009, Python 3 Reference Manual
   Wang J, 2019, MATH BIOSCI ENG, V16, P5851, DOI 10.3934/mbe.2019292
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724
   Wenguan Wang, 2018, IEEE Transactions on Image Processing, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 57
TC 11
Z9 11
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11631
EP 11653
DI 10.1007/s11042-020-10141-y
EA JAN 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605548700007
DA 2024-07-18
ER

PT J
AU Wang, BL
   Meng, L
   Li, CX
AF Wang, Beilei
   Meng, Lu
   Li, Chengxin
TI A real-time object tracking algorithm based on dual feature model kernel
   correlation filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Adaptive feature; Convolutional neural networks;
   Correlation filter
AB Existing target tracking algorithms are mainly divided into two categories: (1) deep learning-based approaches that have high accuracy and low speed; (2) correlation filtering-based approaches that have high speed and low accuracy. In order to balance the real-time performance and accuracy, this paper improves the KCF algorithm. The main innovation lies in the development of an adaptive dual feature model: the main feature model uses shallow texture features (Histogram of Oriented Gradients, HOG), and the auxiliary feature model uses features from convolutional neural networks (CNNs) that contain deep semantic information. These work together in an optimal manner to produce a more stable correlation filter. In order to improve the speed of the algorithm, we use principal component analysis to reduce the dimensionality of the high-dimensional CNN features. In addition, this paper also improves the accuracy of the tracking algorithm by means of scale optimization and optimization of the solution method. Our algorithm is compared with current advanced tracking algorithms with real-time speed, such as SiamFC, MEEM, SAMF, DSST, KCF, Struck, and TLD. The OPE result using the public data set OTB-2013 shows that the algorithm in this paper ranks first in the distance precision rate. Compared with the KCF algorithm, the distance precision rate and overlap success rate are improved by 25.9% and 23.2%, respectively, and the average speed of the proposed algorithm can reach 38 FPS.
C1 [Wang, Beilei] Northeastern Univ, Coll Software, Shenyang 110000, Peoples R China.
   [Meng, Lu; Li, Chengxin] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110000, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Meng, L (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110000, Peoples R China.
EM menglu1982@gmail.com
RI Meng, Lu/GXN-0092-2022; Lu, Meng/JVO-3171-2024; LI, CHENGXIN/R-4275-2017
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   [Anonymous], 2014, P BRIT MACH VIS C, DOI DOI 10.5244/C.28.56
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hongyi Su, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P1, DOI 10.1007/978-3-319-22180-9_1
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Nam H., 2016, Modeling and propagating CNNs in a tree structure for visual tracking
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang L, 2015, IEEE T IMAGE PROCESS, V24, P1424, DOI 10.1109/TIP.2015.2403231
   Wang Naigang, Advances in Neural Information Processing Systems
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang K H, 2012, P EUR C COMP VIS, P864, DOI DOI 10.1007/978-3-642-33712-362
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
NR 26
TC 0
Z9 0
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19113
EP 19134
DI 10.1007/s11042-020-10225-9
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000604816600002
DA 2024-07-18
ER

PT J
AU Ahmadi, MA
   Dianat, R
   Amirkhani, H
AF Ahmadi, Morteza Ali
   Dianat, Rouhollah
   Amirkhani, Hossein
TI An adversarial attack detection method in deep neural networks based on
   re-attacking approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adversarial attack; Adversarial example; Adversarial attack detection;
   Re-attacking; Decision boundary
AB In this paper, we propose a new method for detecting adversarial attacks on deep neural networks. Our algorithm is based on the intuition that attacking input images results in different displacement vectors for clean and adversarial classes. For example, if the input image is an adversarial example, the re-attacking process results in a displacement vector with a short length in the feature space, but this displacement is considerable for clean images. We train our detector based on these displacement vectors. The experimental results show that compared to the current learning-based adversarial detection methods, the proposed system is capable of detecting the adversarial examples using a far simpler network. In addition, the proposed method is independent of the attack type, and is able to detect even novel attacks. It is also revealed that the proposed system learns the discrimination function even using a small amount of training data without any hyper-parameter tuning. We obtain remarkable results in detecting adversarial examples which are placed near and far from the decision boundary, improving state-of-the-art in detecting 2-norm Carlini and Wagner attack (L-2-C&W) and infinity-norm Projected Gradient Descent attack (L-infinity-PGD), where just Fast Gradient Sign Method (FGSM) is used for training the system.
C1 [Ahmadi, Morteza Ali; Dianat, Rouhollah; Amirkhani, Hossein] Univ Qom, Dept Comp Engn & Informat Technol, Qom, Iran.
C3 University of Qom
RP Dianat, R (corresponding author), Univ Qom, Dept Comp Engn & Informat Technol, Qom, Iran.
EM ma.ahmadi@qom.ac.ir; rdianat@qom.ac.ir; amirkhani@qom.ac.ir
OI Amirkhani, Hossein/0000-0002-8679-0634
CR Athalye A, 2018, PR MACH LEARN RES, V80
   Behjati M, 2019, INT CONF ACOUST SPEE, P7345, DOI [10.1109/ICASSP.2019.8682430, 10.1109/icassp.2019.8682430]
   Bhagoji Arjun Nitin, 2018, 2018 52nd Annual Conference on Information Sciences and Systems (CISS), DOI 10.1109/CISS.2018.8362326
   Buckman J, 2018, Thermometer Encoding: One Hot Way To Resist Adversarial Examples
   Cao XY, 2017, ANN COMPUT SECURITY, P278, DOI 10.1145/3134600.3134606
   Carlini N., 2017, P 10 ACM WORKSH ART, P3, DOI DOI 10.1145/3128572.3140444
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Carrara F, 2019, MULTIMED TOOLS APPL, V78, P2815, DOI 10.1007/s11042-018-5853-4
   Chakraborty A., 2018, arXiv
   Chen S, 2018, COMPUT SECUR, V73, P326, DOI 10.1016/j.cose.2017.11.007
   Chollet F, 2015, KERAS
   Dhillon GS, 2018, ARXIV PREPRINT ARXIV
   Eykholt K., 2017, ARXIV PREPRINT ARXIV
   Fan WQ, 2019, MULTIMED TOOLS APPL, V78, P20409, DOI 10.1007/s11042-019-7353-6
   Fawzi A., 2016, ADV NEURAL INFORM PR, P1632
   Feinman R., 2017, Detecting adversarial samples from artifacts
   Folz J, 2020, IEEE WINT CONF APPL, P3568, DOI [10.1109/wacv45572.2020.9093310, 10.1109/WACV45572.2020.9093310]
   Ghiasi A., 2020, INT C LEARN REPR
   Goel A, 2020, IEEE COMPUT SOC CONF, P103, DOI 10.1109/CVPRW50498.2020.00019
   Gong Zhitao, 2017, ARXIV170404960
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Grosse K., 2017, ARXIV
   Hashemi AS, 2019, COMPUT SECUR, V86, P372, DOI 10.1016/j.cose.2019.06.012
   Hendrycks Dan, 2017, INT C LEARNING REPRE
   Kandi H, 2017, COMPUT SECUR, V65, P247, DOI 10.1016/j.cose.2016.11.016
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurakin A., 2016, Adversarial machine learning at scale
   Kurakin A., 2016, WORKSHOP TRACK P
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li J., 2016, ARXIV161208220
   Li S, 2020, MECH ADV MATER STRUC, V27, P1213, DOI 10.1080/15376494.2018.1504361
   Li X, 2017, IEEE I CONF COMP VIS, P5775, DOI 10.1109/ICCV.2017.615
   Lin Z., 2018, ARXIV180902077
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Liu JX, 2017, MULTIMED TOOLS APPL, V76, P24009, DOI 10.1007/s11042-016-4178-4
   Ma X., 2018, INT C LEARN REPR
   Madry A., 2018, ARXIV
   Mao XF, 2020, INT CONF ACOUST SPEE, P2438, DOI [10.1109/ICASSP40776.2020.9052933, 10.1109/icassp40776.2020.9052933]
   Menet F, 2020, COMPUT SECUR, V88, DOI 10.1016/j.cose.2019.05.014
   Meng DY, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P135, DOI 10.1145/3133956.3134057
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Mundra Kartik, 2020, AIMS '20: Proceedings of the 1st ACM Workshop on Autonomous and Intelligent Mobile Systems, DOI 10.1145/3377283.3377285
   Osadchy M, 2017, IEEE T INF FOREN SEC, V12, P2640, DOI 10.1109/TIFS.2017.2718479
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Paszke Adam, 2017, NIPS W
   Pei XJ, 2020, COMPUT SECUR, V93, DOI 10.1016/j.cose.2020.101792
   Rashid M, 2019, MULTIMED TOOLS APPL, V78, P15751, DOI 10.1007/s11042-018-7031-0
   Rauber J, 2017, ARXIV1707041315
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren ZJ, 2020, MULTIMED TOOLS APPL, V79, P10975, DOI 10.1007/s11042-019-08310-9
   Roth K, 2019, PR MACH LEARN RES, V97
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Samangouei P., 2018, 6 INT C LEARN REPR I
   Sharma MK, 2020, MULTIMED TOOLS APPL, V79, P11237, DOI 10.1007/s11042-020-08786-w
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sitawarin C., 2019, ARXIV190609525
   Sivamani Kirthi Shankar, 2020, IEEE Letters of the Computer Society, V3, P25, DOI 10.1109/LOCS.2020.2990897
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Taheri R, 2021, MULTIMED TOOLS APPL, V80, P16713, DOI 10.1007/s11042-020-08804-x
   Tang S., 2019, IEEE T PATTERN ANAL, P1
   Theagarajan R., 2020, IEEECVF C COMPUTER V, P812
   Wang B, 2020, OPTIK, V207, DOI 10.1016/j.ijleo.2020.164477
   Xie Cihang, 2017, ARXIV171101991
   Xu J, 2020, INFORM SCIENCES, V537, P302, DOI 10.1016/j.ins.2020.05.099
   Xu WL, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23198
   Yang P, AAAI, P6639
   You W, 2020, IEEE ACCESS, V8, P1975, DOI 10.1109/ACCESS.2019.2962734
   Yu T, 2019, ADV NEUR IN, V32
   Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017
   Zhang YG, 2020, IEEE T IMAGE PROCESS, V29, P4804, DOI 10.1109/TIP.2020.2975918
   Zheng TH, 2019, AAAI CONF ARTIF INTE, P2253
   Zügner D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6246, DOI 10.1145/3219819.3220078
NR 75
TC 3
Z9 3
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10985
EP 11014
DI 10.1007/s11042-020-10261-5
EA JAN 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604479100013
DA 2024-07-18
ER

PT J
AU Saha, J
   Chowdhury, C
   Ghosh, D
   Bandyopadhyay, S
AF Saha, Jayita
   Chowdhury, Chandreyee
   Ghosh, Dip
   Bandyopadhyay, Sanghamitra
TI A detailed human activity transition recognition framework for grossly
   labeled data from smartphone accelerometer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Detailed activity; MIML; Smartphone; Activity transition; Activity
   sequence
AB Smartphone based human activity monitoring and recognition play an important role in several medical applications, such as eldercare, diabetic patient monitoring, post-trauma recovery after surgery. However, it is more important to recognize the activity sequences in terms of transitions. In this work, we have designed a detailed activity transition recognition framework that can identify a set of activity transitions and their sequence for a time window. This enables us to extract more meaningful insight about the subject's physical and behavioral context. However, precise labeling of training data for detailed activity transitions at every time instance is required for this purpose. But, due to non uniformity of individual gait, the labeling tends to be error prone. Accordingly, our contribution in this work is to formulate the activity transition detection problem as a multiple instance learning problem to deal with imprecise labeling of data. The proposed human activity transition recognition framework forms an ensemble model based on different MIML-kNN distance metrics. The ensemble model helps to find both the activity sequence as well as multiple activity transition. The framework is implemented for a real dataset collected from 8 users. It is found to be working adequately (average precision 0.94).
C1 [Saha, Jayita] Deemed Univ, Koneru Lakshmaiah Educ Fdn, Dept Artificial Intelligence & Data Sci, Hyderabad, India.
   [Chowdhury, Chandreyee] Jadavpur Univ, Dept CSE, Kolkata, India.
   [Ghosh, Dip; Bandyopadhyay, Sanghamitra] Indian Stat Inst, Machine Intelligence Unit, Kolkata, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Jadavpur University; Indian Statistical Institute; Indian Statistical
   Institute Kolkata
RP Saha, J (corresponding author), Deemed Univ, Koneru Lakshmaiah Educ Fdn, Dept Artificial Intelligence & Data Sci, Hyderabad, India.
EM gjai.2000@gmail.com; chandreyee.chowdhury@gmail.com
RI Saha, Jayita/ABD-9506-2020
OI Saha, Jayita/0000-0001-5625-3531
CR Abualigah L., 2015, INT J COMPUTER SCI E, V5, P19, DOI [10.5121/ijcsea.2015.5102, DOI 10.5121/ijcsea.2015.5102]
   Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Bayat A, 2014, PROCEDIA COMPUT SCI, V34, P450, DOI 10.1016/j.procs.2014.07.009
   BHAT G, 2018, ICCAD-IEEE ACM INT
   Chowdhury R, 2018, MEN AND FEMINISM IN INDIA, P1
   Dinakaran S., 2013, INT J SCI ENG RES, V4, P67
   Gani MO, 2017, P 41 IEEE ANN COMP S, P948
   Ghosh D, 2015, 2015 IEEE INT C FUZZ, P1
   Guan XZ, 2016, PR MACH LEARN RES, V48
   Gupta P, 2014, IEEE T BIO-MED ENG, V61, P1780, DOI 10.1109/TBME.2014.2307069
   He J, 2007, P ANN INT IEEE EMBS, P3192, DOI 10.1109/IEMBS.2007.4353008
   Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197
   Leng L., 2012, P INT C WAV AN PATT, P164, DOI DOI 10.1109/ICWAPR.2012.6294772
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li YX, 2012, IEEE ACM T COMPUT BI, V9, P98, DOI 10.1109/TCBB.2011.73
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lu YF, 2017, MATH MECH SOLIDS, V22, P1997, DOI 10.1177/1081286516653272
   Nandy A, 2020, MICROSYST TECHNOL, V26, P1889, DOI 10.1007/s00542-019-04738-z
   Peng LY, 2017, IEEE T BIO-MED ENG, V64, P1369, DOI 10.1109/TBME.2016.2604856
   Reyes-Ortiz JL, 2016, NEUROCOMPUTING, V171, P754, DOI 10.1016/j.neucom.2015.07.085
   Roy N, 2016, J AMB INTEL HUM COMP, V7, P1, DOI 10.1007/s12652-015-0294-7
   Saha J, 2018, INFORMATION, V9, DOI 10.3390/info9040094
   Saha J, 2018, MICROSYST TECHNOL, V24, P2737, DOI 10.1007/s00542-018-3802-9
   Toda T, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P863, DOI 10.1145/2638728.2641297
   Vecchio A, 2017, IEEE SENSOR LETT, V1, DOI 10.1109/LSENS.2017.2726759
   Wang JQ, 2001, APMC 2001: ASIA-PACIFIC MICROWAVE CONFERENCE, VOLS 1-3, PROCEEDINGS, P1119, DOI 10.1109/APMC.2001.985316
   Wannenburg J, 2017, IEEE T SYST MAN CY-S, V47, P3142, DOI 10.1109/TSMC.2016.2562509
   Wei-zhong Wang, 2011, 2011 Proceedings of International Symposium on Bioelectronics and Bioinformatics (ISBB 2011), P263, DOI 10.1109/ISBB.2011.6107697
   Zhang ML, 2010, PROC INT C TOOLS ART, P207, DOI 10.1109/ICTAI.2010.102
NR 34
TC 8
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 9895
EP 9916
DI 10.1007/s11042-020-10046-w
EA NOV 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000589499200001
DA 2024-07-18
ER

PT J
AU Pise, A
   Vadapalli, H
   Sanders, I
AF Pise, Anil
   Vadapalli, Hima
   Sanders, Ian
TI Facial emotion recognition using temporal relational network: an
   application to E-learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Temporal relational network; Deep learning; Segmentation; Learning
   affect; Relational reasoning; E-learning
ID EXPRESSION RECOGNITION
AB E-learning enables the dissemination of valuable academic information to all users regardless of where they are situated. One of the challenges faced by e-learning systems is the lack of constant interaction between the user and the system. This observability feature is an essential feature of a typical classroom setting and a means of detecting or observing feature reactions and thus such features in the form of expressions should be incorporated into an e-learning platform. The proposed solution is the implementation of a deep-learning-based facial image analysis model to estimate the learning affect and to reflect on the level of student engagement. This work proposes the use of a Temporal Relational Network (TRN), for identifying the changes in the emotions on students' faces during e-learning session. It is observed that TRN sparsely samples individual frames and then learns their causal relations, which is much more efficient than sampling dense frames and convolving them. In this paper, single-scale and multi-scale temporal relations are considered to achieve the proposed goal. Furthermore, a Multi-Layer Perceptron (MLP) is also tested as a baseline classifier. The proposed framework is end-to-end trainable for video-based Facial Emotion Recognition (FER). The proposed FER model was tested on the open-source DISFA+ database. The TRN based model showed a significant reduction in the length of the feature set which were effective in recognizing expressions. It is observed that the multi-scale TRN has produced better accuracy than the single-scale TRN and MLP with an accuracy of 92.7%, 89.4%, and 86.6% respectively.
C1 [Pise, Anil; Vadapalli, Hima] Univ Witwatersrand, Johannesburg, South Africa.
   [Sanders, Ian] Univ South Africa, Johannesburg, South Africa.
C3 University of Witwatersrand; University of South Africa
RP Pise, A (corresponding author), Univ Witwatersrand, Johannesburg, South Africa.
EM anil.pise7@gmail.com; hima.vadapalli@wits.ac.za; sandeid@unisa.ac.za
RI Vadapalli, Hima/AAD-2624-2022; Pise, Anil/AAH-2558-2019
CR [Anonymous], 2016, MAT CHAR MOD METH
   Bin Li, 2018, IEEE Signal Processing Letters, V25, P650, DOI 10.1109/LSP.2018.2816569
   Boughrara H, 2016, MULTIMED TOOLS APPL, V75, P709, DOI 10.1007/s11042-014-2322-6
   Byeon YH, 2014, INT J ADV COMPUT SC, V5, P107, DOI 10.14569/ijacsa.2014.051215
   Cao ZC, 2018, IEEE INT CON AUTO SC, P803, DOI 10.1109/COASE.2018.8560578
   Collins A., 2018, Rethinking education in the age of technology: The digital revolution and schooling in America
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   Gaikwad AS, 2018, THESIS
   Geron A., 2017, Hands-On Machine Learning With Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
   Hamza A, 2018, PROCEEDINGS OF THE 2018 WORKSHOP ON IOT SECURITY AND PRIVACY (IOT S&P '18), P1, DOI 10.1145/3229565.3229571
   Han B, 2018, ADV NEUR IN, V31
   Hasani B, 2017, IEEE COMPUT SOC CONF, P2278, DOI 10.1109/CVPRW.2017.282
   Hossain MS, 2016, MOBILE NETW APPL, V21, P753, DOI 10.1007/s11036-016-0685-9
   Hossain MS, 2016, J MULTIMODAL USER IN, V10, P325, DOI 10.1007/s12193-015-0207-2
   Huang XH, 2010, LECT NOTES COMPUT SC, V6475, P312, DOI 10.1007/978-3-642-17691-3_29
   Hur MH, 2013, INT REV RES OPEN DIS, V14, P191
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Jabbar H, 2015, METHODS AVOID OVERFI
   Jan A, 2018, IEEE INT CONF AUTOMA, P466, DOI 10.1109/FG.2018.00075
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Kozina A, 2017, DESIGNING EFFECTIVE
   Li HB, 2017, IEEE T MULTIMEDIA, V19, P2816, DOI 10.1109/TMM.2017.2713408
   Ly TS, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.10.003
   Mattivi R, 2009, LECT NOTES COMPUT SC, V5702, P740, DOI 10.1007/978-3-642-03767-2_90
   Mavadati M, 2016, IEEE COMPUT SOC CONF, P1452, DOI 10.1109/CVPRW.2016.182
   Mollahosseini A., 2016, P IEEE C COMP VIS PA, P58
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Oyedotun OK, 2017, IEEE INT CONF COMP V, P3161, DOI 10.1109/ICCVW.2017.374
   Pan XZ, 2019, IEEE ACCESS, V7, P48807, DOI 10.1109/ACCESS.2019.2907271
   Pan XZ, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010052
   Park SY, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P911, DOI 10.1145/2733373.2806362
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Pranav E, 2020, INT CONF ADVAN COMPU, P317, DOI [10.1109/icaccs48705.2020.9074302, 10.1109/ICACCS48705.2020.9074302]
   Razavian A. S., 2014, Workshop on IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2014), P806, DOI [10.1109/cvprw.2014.131, DOI 10.1109/CVPRW.2014.131]
   Reddy S.P.T., 2019, ARXIV190401390
   Santoro A., 2017, Advances in Neural Information Processing Systems
   Spizhevoy A. S., 2016, Pattern Recognition and Image Analysis, V26, P216, DOI 10.1134/S1054661816010247
   Sumathi CP., 2012, International Journal of Computer Science Engineering Survey, P47
   Sun WY, 2018, NEUROCOMPUTING, V296, P12, DOI 10.1016/j.neucom.2018.03.034
   Wang YD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124674
   Wang YM, 2015, C HUM SYST INTERACT, P362, DOI 10.1109/HSI.2015.7170694
   Ye H, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P435, DOI 10.1145/2671188.2749406
   Cabada RZ, 2020, SOFT COMPUT, V24, P7593, DOI 10.1007/s00500-019-04387-4
   Zhang SQ, 2018, IEEE T CIRC SYST VID, V28, P3030, DOI 10.1109/TCSVT.2017.2719043
   Zhang SQ, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P281, DOI 10.1145/2911996.2912051
   Zhao L, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/3017608
   Zheng WQ, 2015, INT CONF AFFECT, P827, DOI 10.1109/ACII.2015.7344669
NR 49
TC 20
Z9 20
U1 1
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26633
EP 26653
DI 10.1007/s11042-020-10133-y
EA NOV 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000589499300001
DA 2024-07-18
ER

PT J
AU Ahn, B
   Jang, SW
AF Ahn, Byeongtae
   Jang, Seok-Woo
TI Context-adaptive blocking for protecting personal information exposed to
   social multimedia content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Regional blurring; Surrounding situation; Object covering; Social
   multimedia data; Color image; Background region
ID HUMAN SKIN DETECTION; ACTIVATION FUNCTION; NEURAL-NETWORK; DEEP; IMAGE;
   ENHANCEMENT; EFFICIENT
AB With the development of many devices that support high-speed wired and wireless Internet, it has been universalized to upload and download various kinds of social multimedia information. However, image data including sensitive personal information are easily exposed to Internet users. In this study, the algorithm is introduced to make it possible to exclude background regions from various types of input color images, to robustly detect the target regions including personal information, and then effectively protect the detected target regions through context-adaptative blocking. In this study, the background regions are first excluded from input color images, and then only the target regions including personal information are robustly segmented on the basis of human skin color. Subsequently, the detected target regions are effectively blocked in the way of selecting regional blurring adaptively in line with surrounding situations, and therefore it is possible to prevent personal information from being exposed. The experimental result of this study reveals that the proposed method robustly blocks the target object regions including personal information of input images in line with surrounding situations. The algorithm proposed in this study is expected to be applied practically to many fields associated with image processing, such as video surveillance, video monitoring, and target object covering.
C1 [Ahn, Byeongtae] Anyang Univ, Liberal & Arts Coll, 22,37 Beongil, Anyang 14028, South Korea.
   [Jang, Seok-Woo] Anyang Univ, Dept Software, 22,37 Beongil, Anyang 14028, South Korea.
C3 Anyang University; Anyang University
RP Jang, SW (corresponding author), Anyang Univ, Dept Software, 22,37 Beongil, Anyang 14028, South Korea.
EM ahnbt@anyang.ac.kr; swjang7285@gmail.com
OI Jang, Seok-Woo/0000-0001-5580-4098
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2019R1F1A1056475]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (2019R1F1A1056475).
CR Al-Mohair HK, 2015, APPL SOFT COMPUT, V33, P337, DOI 10.1016/j.asoc.2015.04.046
   Amato F, 2019, FUTURE GENER COMP SY, V94, P444, DOI 10.1016/j.future.2018.11.035
   Amin SU, 2019, FUTURE GENER COMP SY, V101, P542, DOI 10.1016/j.future.2019.06.027
   Amina S, 2018, COMMUN NONLINEAR SCI, V60, P12, DOI 10.1016/j.cnsns.2017.12.017
   Ban F, 2018, INT J SOCIAL HUMANIS, V3, P34, DOI [DOI 10.1504/IJSHC.2018.095011, 10.1504/IJSHC.2018.095011]
   Brancati N, 2017, COMPUT VIS IMAGE UND, V155, P33, DOI 10.1016/j.cviu.2016.12.001
   Chakraborty BK, 2017, PATTERN RECOGN LETT, V88, P33, DOI 10.1016/j.patrec.2017.01.005
   Chrysos GG, 2018, INT J COMPUT VISION, V126, P198, DOI 10.1007/s11263-017-0999-5
   Dahl R, 2017, IEEE I CONF COMP VIS, P5449, DOI 10.1109/ICCV.2017.581
   Davis EK, 2015, ARXIV150200046V1CSCV
   Du B, 2017, IEEE T IMAGE PROCESS, V26, P1694, DOI 10.1109/TIP.2017.2651372
   Du DJ, 2017, INFORM SCIENCES, V380, P74, DOI 10.1016/j.ins.2016.03.033
   Eckle K, 2019, NEURAL NETWORKS, V110, P232, DOI 10.1016/j.neunet.2018.11.005
   Hamuda E, 2017, COMPUT ELECTRON AGR, V133, P97, DOI 10.1016/j.compag.2016.11.021
   Hayakawa S, 2020, NEURAL NETWORKS, V123, P343, DOI 10.1016/j.neunet.2019.12.014
   He LF, 2014, IEEE T IMAGE PROCESS, V23, P943, DOI 10.1109/TIP.2013.2289968
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Huang R, 2018, NEUROCOMPUTING, V285, P154, DOI 10.1016/j.neucom.2018.01.041
   Jang SW, 2011, J IMAGING SCI TECHN, V55, DOI 10.2352/J.ImagingSci.Technol.2011.55.2.020508
   Jiang WB, 2019, PATTERN RECOGN LETT, V128, P311, DOI 10.1016/j.patrec.2019.09.017
   Jingpan Liu, 2011, 2011 3rd International Conference on Computer Research and Development (ICCRD 2011), P237, DOI 10.1109/ICCRD.2011.5764011
   Kastrati Z, 2019, PATTERN RECOGN LETT, V128, P85, DOI 10.1016/j.patrec.2019.08.019
   Kastrati Z, 2019, INFORM PROCESS MANAG, V56, P1618, DOI 10.1016/j.ipm.2019.05.003
   Lee S, 2012, IEEE T CONSUM ELECTR, V58, P641, DOI 10.1109/TCE.2012.6227471
   Li DM, 2019, J INF SECUR APPL, V47, P59, DOI 10.1016/j.jisa.2019.03.020
   Li J, 2017, IEEE T NEUR NET LEAR, V28, P1425, DOI 10.1109/TNNLS.2016.2541681
   Lou S, 2012, PRECIS ENG, V36, P414, DOI 10.1016/j.precisioneng.2012.01.003
   Macêdo D, 2019, EXPERT SYST APPL, V124, P271, DOI 10.1016/j.eswa.2019.01.066
   Mahmud M, 2018, IEEE T NEUR NET LEAR, V29, P2063, DOI 10.1109/TNNLS.2018.2790388
   Paliwal N., 2019, International Journal of Social and Humanistic Computing, V3, P191, DOI [10.1504/IJSHC.2019.101602, DOI 10.1504/IJSHC.2019.101602]
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Sevillano X, 2020, INFORM SCIENCES, V511, P212, DOI 10.1016/j.ins.2019.09.064
   Shao L, 2014, IEEE T NEUR NET LEAR, V25, P2303, DOI 10.1109/TNNLS.2014.2308519
   Shifa A, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103859
   Silva HO, 2018, ENG APPL ARTIF INTEL, V70, P184, DOI 10.1016/j.engappai.2018.02.002
   Su R, 2014, PATTERN RECOGN, V47, P3193, DOI 10.1016/j.patcog.2014.04.024
   Tan Y, 2019, IEEE ACCESS, V7, P25026, DOI 10.1109/ACCESS.2019.2896304
   Tran HY, 2019, J PARALLEL DISTR COM, V134, P207, DOI 10.1016/j.jpdc.2019.08.007
   Wang R, 2019, SIGNAL PROCESS, V155, P73, DOI 10.1016/j.sigpro.2018.09.027
   Wang X, 2019, NEUROCOMPUTING, V363, P88, DOI 10.1016/j.neucom.2019.07.017
   Wang Y, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102399
   Xu YY, 2017, J VIS COMMUN IMAGE R, V43, P164, DOI 10.1016/j.jvcir.2017.01.006
   Yang XT, 2018, IEEE SENS J, V18, P6461, DOI 10.1109/JSEN.2018.2847332
   Yao L, 2018, IEEE T IND ELECTRON, V65, P1490, DOI 10.1109/TIE.2017.2733448
   Zhang DY, 2019, PATTERN RECOGN, V91, P281, DOI 10.1016/j.patcog.2019.02.022
   Zhang H, 2019, MULTIMED TOOLS APPL, V78, P27809, DOI 10.1007/s11042-019-07898-2
   Zhang SQ, 2019, IEEE ACCESS, V7, P32297, DOI 10.1109/ACCESS.2019.2901521
   Zhang XL, 2015, ISPRS J PHOTOGRAMM, V102, P73, DOI 10.1016/j.isprsjprs.2015.01.009
   Zhang Y, 2016, IEEE T IND ELECTRON, V63, P2330, DOI 10.1109/TIE.2015.2499728
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
   Zhou W, 2016, INFORM SCIENCES, V358, P191, DOI 10.1016/j.ins.2016.04.003
   Zhu SYY, 2019, IEEE T CIRC SYST VID, V29, P1474, DOI 10.1109/TCSVT.2018.2841642
   Ziólko B, 2015, FUZZY SET SYST, V279, P101, DOI 10.1016/j.fss.2015.03.006
   Zuo RG, 2019, EARTH-SCI REV, V192, P1, DOI 10.1016/j.earscirev.2019.02.023
NR 54
TC 0
Z9 0
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34249
EP 34267
DI 10.1007/s11042-020-10042-0
EA NOV 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000587108000001
DA 2024-07-18
ER

PT J
AU Gupta, SK
   Chattopadhyay, P
AF Gupta, Sanjay Kumar
   Chattopadhyay, Pratik
TI Exploiting pose dynamics for human recognition from their gait
   signatures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; walking speed invariant; Active energy image; Video
   surveillance
ID ENERGY IMAGE; REPRESENTATION; EXTRACTION
AB Computer vision-based gait recognition has evolved into an active area of research since the past decade, and a number of useful algorithms have been proposed over the years. Among the existing gait recognition techniques, pose-based approaches have gained more popularity due to their inherent capability of capturing the silhouette shape variation during walking at a high resolution. However, a short-coming of the existing pose-based gait recognition approaches is that their effectiveness depends on the accuracy of a pre-defined set of key poses and are, in general, not robust against varying walking speeds. In this work, we propose an improvement to the existing pose-based approaches by considering a gallery of key pose sets corresponding to varying walking speeds instead of just a single key pose set. This gallery is generic and is constructed from a large set of subjects that may/may not include the subjects present in the gait recognition data set. Comparison between a pair of training and test sequences is done by mapping each of these into the individual key pose sets present in the above gallery set, computing the Active Energy Image for each key pose, and next observing the frequency of matched key poses in all the sets. Our approach has been evaluated on two popular gait data sets, namely the CASIA B data and the TUMGAID data. A thorough experimental evaluation along with comparison with state-of-the-art techniques verify the effectiveness of our approach.
C1 [Gupta, Sanjay Kumar; Chattopadhyay, Pratik] Banaras Hindu Univ, Indian Inst Technol, Dept Comp Sci & Engn, Pattern Recognit Lab, Varanasi, Uttar Pradesh, India.
C3 Banaras Hindu University (BHU); Indian Institute of Technology System
   (IIT System); Indian Institute of Technology BHU Varanasi (IIT BHU
   Varanasi)
RP Gupta, SK (corresponding author), Banaras Hindu Univ, Indian Inst Technol, Dept Comp Sci & Engn, Pattern Recognit Lab, Varanasi, Uttar Pradesh, India.
EM sanjaykrgupta.rs.cse17@itbhu.ac.in; pratik.cse@iitbhu.ac.in
RI Gupta, Sanjay Kumar/AAS-6960-2020
OI Gupta, Sanjay Kumar/0000-0003-3171-9926
CR Aggarwal H, 2018, IEEE T COGN DEV SYST, V10, P397, DOI 10.1109/TCDS.2017.2658674
   Alotaibi M, 2017, COMPUT VIS IMAGE UND, V164, P103, DOI 10.1016/j.cviu.2017.10.004
   Babaee M, 2019, NEUROCOMPUTING, V338, P116, DOI 10.1016/j.neucom.2019.01.091
   Babaee M, 2018, IEEE IMAGE PROC, P768, DOI 10.1109/ICIP.2018.8451785
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Battistone F, 2019, PATTERN RECOGN LETT, V126, P132, DOI 10.1016/j.patrec.2018.05.004
   Ben XY, 2020, IEEE T CIRC SYST VID, V30, P734, DOI 10.1109/TCSVT.2019.2893736
   Bouchrika I, 2011, J FORENSIC SCI, V56, P882, DOI 10.1111/j.1556-4029.2011.01793.x
   Boulgouris NV, 2013, IEEE T IMAGE PROCESS, V22, P3636, DOI 10.1109/TIP.2013.2266578
   Chattopadhyay P., 2014, EUR C COMP VIS, P341
   Chattopadhyay P, 2014, J VIS COMMUN IMAGE R, V25, P53, DOI 10.1016/j.jvcir.2013.02.010
   Chaurasia P, 2017, IEEE T HUM-MACH SYST, V47, P751, DOI 10.1109/THMS.2017.2706658
   Chen CH, 2009, PATTERN RECOGN LETT, V30, P977, DOI 10.1016/j.patrec.2009.04.012
   Chen JY, 2014, SCI WORLD J, DOI 10.1155/2014/262398
   Das Choudhury S, 2015, PATTERN RECOGN, V48, P798, DOI 10.1016/j.patcog.2014.09.022
   de Lima VC, 2019, LECT NOTES COMPUT SC, V11896, P719, DOI 10.1007/978-3-030-33904-3_68
   Guan Y, 2015, IEEE T PATTERN ANAL, V37, P1521, DOI 10.1109/TPAMI.2014.2366766
   Gupta Sanjay Kumar, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P85, DOI 10.1007/978-981-13-7403-6_10
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hofmann M, 2014, J VIS COMMUN IMAGE R, V25, P195, DOI 10.1016/j.jvcir.2013.02.006
   Huang S, 2015, IEEE T INF FOREN SEC, V10, P2071, DOI 10.1109/TIFS.2015.2445315
   Huang XX, 2012, IEEE T IMAGE PROCESS, V21, P2256, DOI 10.1109/TIP.2011.2180914
   Huberty C.J., 1975, DISCRIMINANT ANAL
   Isaac ERHP, 2017, IEEE SIGNAL PROC LET, V24, P1188, DOI 10.1109/LSP.2017.2715179
   Jacoby WG, 2000, ELECT STUD, V19, P577, DOI 10.1016/S0261-3794(99)00028-1
   Lai ZH, 2014, IEEE T CIRC SYST VID, V24, P1651, DOI 10.1109/TCSVT.2014.2305495
   Lam THW, 2006, LECT NOTES COMPUT SC, V3832, P612
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   Lee H, 2009, INT J CONTROL AUTOM, V7, P638, DOI [10.1007/S12555-009-0414-2, 10.1007/s12555-009-0414-2]
   Liu JY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P663
   Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122
   Roy A, 2012, SIGNAL PROCESS, V92, P780, DOI 10.1016/j.sigpro.2011.09.022
   Shiraga K, 2016, INT CONF BIOMETR
   Sivapalan Sabesan, 2011, 2011 INT JOINT C BIO, P1, DOI [10.1109/IJCB.2011.6117504, 10.1155/2011/375897]
   Sokolova A, 2019, IET BIOMETRICS, V8, P134, DOI 10.1049/iet-bmt.2018.5046
   Syeda-Mahmood T, 2007, PROC CVPR IEEE, P132
   Takemura N, 2019, IEEE T CIRC SYST VID, V29, P2708, DOI 10.1109/TCSVT.2017.2760835
   Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Wu ZF, 2015, IEEE T MULTIMEDIA, V17, P1960, DOI 10.1109/TMM.2015.2477681
   Yang XC, 2008, SIGNAL PROCESS, V88, P2350, DOI 10.1016/j.sigpro.2008.03.006
   Yu SQ, 2019, PATTERN RECOGN, V87, P179, DOI 10.1016/j.patcog.2018.10.019
   Yu SQ, 2017, IEEE COMPUT SOC CONF, P532, DOI 10.1109/CVPRW.2017.80
   Yu SQ, 2017, NEUROCOMPUTING, V239, P81, DOI 10.1016/j.neucom.2017.02.006
   Zhang CG, 2015, AER ADV ENG RES, V41, P456
   Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024
NR 46
TC 4
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35903
EP 35921
DI 10.1007/s11042-020-10071-9
EA NOV 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000587038500009
DA 2024-07-18
ER

PT J
AU Ghadirli, HM
   Nodehi, A
   Enayatifar, R
AF Movafegh Ghadirli, Hossein
   Nodehi, Ali
   Enayatifar, Rasul
TI Color image DNA encryption using mRNA properties and non-adjacent
   coupled map lattices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; DNA encoding; NCML; mRNA encoding
ID HYPER-CHAOTIC SYSTEM; ARNOLD TRANSFORM; NUCLEOTIDE-SEQUENCE; GENETIC
   ALGORITHM; GYRATOR TRANSFORM; HYBRID MODEL; SECURE; OPERATION; BREAKING;
   CRYPTANALYSIS
AB This paper proposes a novel algorithm for encrypting color images. The innovation in this study is the use of messenger ribonucleic acid (mRNA) encoding to import into Deoxyribonucleic acid (DNA) encoding. For permutation of the plain image bits, we use Arnold's Cat Map at the bit-level. Then, using Non-Adjacent Coupled Map Lattices (NCML), we apply diffusion operations to the permuted color channels. We also provide the upgrade of the diffusion phase with DNA encoding. In the proposed algorithm, the choices are random depending on the secret key, which is implemented using a simple logistic map. Hashing the string entered by the user, the secret key, parameters, and initial values are generated by the Double MD5 method. The results of tests and security analysis showed that the results of encryption with this scheme are effective, and the key space is large enough to withstand common attacks.
C1 [Movafegh Ghadirli, Hossein; Nodehi, Ali] Islamic Azad Univ, Gorgan Branch, Dept Comp Engn, Gorgan, Golestan, Iran.
   [Enayatifar, Rasul] Islamic Azad Univ, Firoozkooh Branch, Dept Comp Engn, Firoozkooh, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Nodehi, A (corresponding author), Islamic Azad Univ, Gorgan Branch, Dept Comp Engn, Gorgan, Golestan, Iran.
EM ali.nodehi84@gmail.com
RI Nodehi, Ali/AAT-2178-2021; Enayatifar, Rasul/ABB-3490-2021
OI Enayatifar, Rasul/0000-0001-9994-5300
CR Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Abuturab MR, 2012, OPT LASER ENG, V50, P772, DOI 10.1016/j.optlaseng.2011.12.006
   Ahmed HEDH, 2007, INFORM-J COMPUT INFO, V31, P121
   Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Akhavan A, 2015, OPT COMMUN, V350, P77, DOI 10.1016/j.optcom.2015.03.079
   Babaei M, 2013, NAT COMPUT, V12, P101, DOI 10.1007/s11047-012-9334-9
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Bensikaddour E.-H., 2018, J KING SAUD UNIV-COM, V3, P1
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Bhatnagar G, 2012, IEEE T SYST MAN CY A, V42, P262, DOI 10.1109/TSMCA.2011.2147307
   CAVUSOGLU U, 2017, CHAOS SOLITON FRACT, V95, P92, DOI DOI 10.1016/J.CHAOS.2016.12.018
   Chai XL, 2016, CHINESE PHYS B, V25, DOI 10.1088/1674-1056/25/10/100503
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Chen TH, 2010, INFORM SCIENCES, V180, P1690, DOI 10.1016/j.ins.2009.12.021
   Chen W, 2009, OPT COMMUN, V282, P3680, DOI 10.1016/j.optcom.2009.06.014
   COHEN M, 1985, VIROLOGY, V147, P449, DOI 10.1016/0042-6822(85)90147-3
   Devi RS, 2020, MULTIMED TOOLS APPL, V79, P12093, DOI 10.1007/s11042-019-08562-5
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Faragallah OS, 2018, OPT QUANT ELECTRON, V50, DOI 10.1007/s11082-018-1363-x
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gan ZH, 2019, NEURAL COMPUT APPL, V31, P7111, DOI 10.1007/s00521-018-3541-y
   Ghadirli HM, 2019, SIGNAL PROCESS, V164, P163, DOI 10.1016/j.sigpro.2019.06.010
   Head T, 2000, BIOSYSTEMS, V57, P87, DOI 10.1016/S0303-2647(00)00091-5
   Hsiao HI, 2015, SIGNAL PROCESS, V117, P281, DOI 10.1016/j.sigpro.2015.06.007
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Kadir A, 2017, OPTIK, V129, P231, DOI 10.1016/j.ijleo.2016.10.036
   Khalid M, 2017, J SENSORS, V2017, DOI 10.1155/2017/7539751
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Li CQ, 2012, NONLINEAR DYNAM, V70, P2383, DOI 10.1007/s11071-012-0626-5
   Li CQ, 2011, COMMUN NONLINEAR SCI, V16, P837, DOI 10.1016/j.cnsns.2010.05.008
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1035, DOI 10.1016/j.imavis.2008.09.004
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Mahmud M, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105818
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Mondal B, 2017, J KING SAUD UNIV-COM, V29, P499, DOI 10.1016/j.jksuci.2016.02.003
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Nematzadeh H, 2018, OPT LASER ENG, V110, P24, DOI 10.1016/j.optlaseng.2018.05.009
   Ning K., 2009, COMPUTING RES REPOSI, DOI DOI 10.1016/J.COMPELECENG.2012.02.007
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Özkaynak F, 2013, SIG PROCESS COMMUN
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   SANGER F, 1977, NATURE, V265, P687, DOI 10.1038/265687a0
   Sokouti M, 2018, COMPUT SCI REV, V29, P14, DOI 10.1016/j.cosrev.2018.05.002
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Sravanthi D, 2019, ADV INTELL SYST, V758, P717, DOI 10.1007/978-981-13-0514-6_68
   Su Z., 2012, Multimedia-A Multidisciplinary Approach to Complex Issues
   Sui LS, 2013, OPT LASER TECHNOL, V48, P530, DOI 10.1016/j.optlastec.2012.11.020
   Usama M, 2010, COMPUT MATH APPL, V60, P326, DOI 10.1016/j.camwa.2009.12.033
   Wang K, 2005, PHYS LETT A, V343, P432, DOI 10.1016/j.physleta.2005.05.040
   Wang LY, 2016, OPT LASER ENG, V77, P118, DOI 10.1016/j.optlaseng.2015.07.015
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106366
   Wang Y, 2015, COMPUT ELECTR ENG, V46, P433, DOI 10.1016/j.compeleceng.2015.03.011
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu JH, 2013, OPT LASER TECHNOL, V45, P571, DOI 10.1016/j.optlastec.2012.05.030
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xiao D, 2009, CHAOS SOLITON FRACT, V40, P2191, DOI 10.1016/j.chaos.2007.10.009
   Xie T, 2014, OPTIK, V125, P7166, DOI 10.1016/j.ijleo.2014.07.111
   You SP, 2015, OPT COMMUN, V355, P419, DOI 10.1016/j.optcom.2015.07.014
   Yu WQ, 2019, MULTIMED TOOLS APPL, V78, P20037, DOI 10.1007/s11042-018-7110-2
   Zhang Q, 2010, ADV SCI LETT, V3, P447, DOI 10.1166/asl.2010.1170
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang YQ, 2016, OPT LASER ENG, V82, P95, DOI 10.1016/j.optlaseng.2016.02.002
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zheng XD, 2009, APPL MATH COMPUT, V212, P177, DOI 10.1016/j.amc.2009.02.011
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
   Zhou YC, 2013, IEEE T CYBERNETICS, V43, P515, DOI 10.1109/TSMCB.2012.2210706
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
   Zhu HG, 2014, OPTIK, V125, P6672, DOI 10.1016/j.ijleo.2014.06.149
NR 88
TC 15
Z9 15
U1 5
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8445
EP 8469
DI 10.1007/s11042-020-10014-4
EA NOV 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000584348600002
DA 2024-07-18
ER

PT J
AU Ullah, I
   Jian, MW
   Hussain, S
   Guo, J
   Lian, L
   Yu, H
   Shaheed, K
   Yin, YL
AF Ullah, Inam
   Jian, Muwei
   Hussain, Sumaira
   Guo, Jie
   Lian, Li
   Yu, Hui
   Shaheed, Kashif
   Yin, Yilong
TI DSFMA: deeply supervised fully convolutional neural networks based on
   multi-level aggregation for saliency detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Multi-level; Saliency detection;
   Short-connections; Skip-connections; Fully convolutional neural network
ID OBJECT DETECTION; CONTRAST; FEATURES
AB In recent years, the emergence of fully convolutional neural networks (FCNs) has delivered significant success in the field of saliency detection. Although the different levels of FCNs layers can hold different types of information for salient object detection, it is still a challenging issue to find a generic method while integrating all relevant information synthetically with multi-level aggregation. In this paper, we present a novel multi-level aggregation method by following a U-shaped architecture of the VGG-16 network. As the shallower layers of FCNs contain the low-level integrated features which are capable of capturing the more details of salient objects, while the more profound layers that hold the high-level integrated features have more contextual information. To exploit all the relevant information, we extend the last four side-outputs of U-Net at the encoder and decoder sides and then utilize the concept of skip and short-connections to incorporate the high-level contextual knowledge with low-level details. Besides, we also integrate the recurrent convolutional layers (RCLs) into our model, which provide more deepness and enhance the capability to integrate more contextual knowledge. At last, we combine all the side-outputs into a final saliency map together for salient object detection. We evaluate the performance of the proposed model on six broadly used saliency detection benchmarks by comparing it with the other 11 state-of-the-art approaches. Experimental outcomes determine that our method achieves a favorable performance for all compared evaluation measures.
C1 [Ullah, Inam; Hussain, Sumaira; Guo, Jie; Lian, Li; Shaheed, Kashif; Yin, Yilong] Shandong Univ, Sch Software, Jinan 250101, Peoples R China.
   [Jian, Muwei] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
   [Jian, Muwei; Yu, Hui] Univ Portsmouth, Sch Creat Technol, Portsmouth, Hants, England.
   [Hussain, Sumaira] Sindh Madressatul Islam Univ, Dept Comp Sci, Karachi 74000, Pakistan.
C3 Shandong University; Shandong University of Finance & Economics;
   University of Portsmouth
RP Yin, YL (corresponding author), Shandong Univ, Sch Software, Jinan 250101, Peoples R China.; Jian, MW (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.; Jian, MW (corresponding author), Univ Portsmouth, Sch Creat Technol, Portsmouth, Hants, England.
EM jianmuweihk@163.com; ylyin@sdu.edu.cn
RI Shaheed, Kashif/ABD-8413-2020; Yu, Hui/G-1115-2018; Ullah,
   INAM/GMX-1573-2022; Hussain, S/IQU-0327-2023; Jian, Muwei/Q-8319-2018
OI Shaheed, Kashif/0000-0002-7399-6211; Yu, Hui/0000-0002-7655-9228; Ullah,
   INAM/0000-0002-2624-8093; Jian, Muwei/0000-0002-4249-2264
FU National Natural Science Foundation of China (NSFC) [61876098, 61976123,
   61601427]; Royal Society - K. C. Wong International Fellowship
   [NIF\R1\180909]; Taishan Young Scholars Program of Shandong Province;
   China Postdoctoral Science Foundation [2019 M652433]; Natural Science
   Foundation of Shandong Province [ZR2018BF001]
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) (61876098, 61976123, 61601427); Royal Society - K. C. Wong
   International Fellowship (NIF\R1\180909), the Taishan Young Scholars
   Program of Shandong Province, the China Postdoctoral Science Foundation
   (2019 M652433), and the Natural Science Foundation of Shandong Province
   (ZR2018BF001).
CR Abu Arqub O, 2019, CHAOS SOLITON FRACT, V125, P163, DOI 10.1016/j.chaos.2019.05.025
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298642
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Borji A., 2012, 2012 IEEE COMPUTER S, P23, DOI 10.1109/CVPRW.2012.6239191
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Donoser M, 2009, IEEE I CONF COMP VIS, P817, DOI 10.1109/ICCV.2009.5459296
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   He JF, 2012, PROC CVPR IEEE, P3005, DOI 10.1109/CVPR.2012.6248030
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jian MW, 2019, APPL SOFT COMPUT, V80, P425, DOI 10.1016/j.asoc.2019.04.025
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P202, DOI 10.1016/j.jvcir.2018.11.007
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Li YB, 2015, 2015 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (FPT), P196, DOI 10.1109/FPT.2015.7393149
   LIANG M, 2015, PROC CVPR IEEE, P3367, DOI [10.1109/CVPR.2015.7298958, DOI 10.1109/CVPR.2015.7298958]
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Mahadevan V, 2013, IEEE T PATTERN ANAL, V35, P541, DOI 10.1109/TPAMI.2012.98
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Paszke A., 2017, NIPS W
   Pingping Zhang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P202, DOI 10.1109/ICCV.2017.31
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shelhamer E, 2016, ARXIV06211
   Shi KY, 2013, PROC CVPR IEEE, P2115, DOI 10.1109/CVPR.2013.275
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Simonyan K., 2013, arXiv preprint arXiv:1312.6034
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tang Y., 2016, P 24 ACM INT C MULT, P397
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Ullah I, 2020, MULTIMED TOOLS APPL, V79, P34605, DOI 10.1007/s11042-020-08849-y
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Wang X, 2018, IEEE T IMAGE PROCESS, V27, P121, DOI 10.1109/TIP.2017.2756825
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang P, 2018, ARXIV06527
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
NR 70
TC 6
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7145
EP 7165
DI 10.1007/s11042-020-10111-4
EA OCT 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000583943700001
DA 2024-07-18
ER

PT J
AU Akel, G
   Armagan, E
AF Akel, Gokhan
   Armagan, Ece
TI Hedonic and utilitarian benefits as determinants of the application
   continuance intention in location-based applications: the mediating role
   of satisfaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Location-based applications; Hedonic benefits; Utilitarian benefits;
   Satisfaction; Application continuance intention
ID INFORMATION-SYSTEMS CONTINUANCE; EXPECTATION-CONFIRMATION MODEL;
   CUSTOMER SATISFACTION; USER ACCEPTANCE; SHOPPING VALUE;
   EMPIRICAL-ANALYSIS; COMMERCE SERVICE; CONSUMER CHOICE; E-LOYALTY; MOBILE
AB The increase in the number of social media users and smartphone usage has a positive relationship with the diversity of applications. People use mobile applications that provide location-based service either directly or indirectly to share location with their smartphones. With the increase in the use of applications that determine location information by determining location information on mobile devices, mobile applications have become an important research area for user behavior. These applications are also utilized by users for communication and socialization purposes. The literature has usually focused on popular social media applications and studies on location-based applications (LBAs) have been insufficient. In this study, we investigate the impact of location-based services, such as Swarm and Foursquare. This study uses the technology acceptance model (TAM) and the expectation confirmation model (ECM) to understand why users continue using mobile applications. This article examines the role of hedonic comprised of application aesthetics and perceived enjoyment and utilitarian benefits (comprised of application quality and application utility) for consumer behavior in the development of application markets on satisfaction and application continuance intention. Besides, we show the benefits of the strongest effect on application users. By using the mediation satisfaction effect between hedonic and utilitarian benefits; we test the application continuance intention with regression analyses and the Sobel test. We surveyed young subjects as our sapling frame who regularly use mobile applications. We collected data from 400 users by convenience sampling method to test our hypotheses. Given our findings, we show that utilitarian and hedonic benefits are positively related to the application continuance intention. Besides, we show that satisfaction significantly mediates the relationship between hedonic/utilitarian benefits and application continuance intention. Since the main purpose of the application developers is using the application per se in the long term, they need to focus chiefly on user satisfaction. We also show that determining the relevant factors that affect application continuance intention positively is important for the businesses in a competitive environment.
C1 [Akel, Gokhan] Antalya AKEV Univ, Fac Econ & Business, Antalya, Turkey.
   [Armagan, Ece] Adnan Menderes Univ, Fac Econ & Business, Aydin, Turkey.
C3 Antalya Akev Universitesi; Adnan Menderes University
RP Akel, G (corresponding author), Antalya AKEV Univ, Fac Econ & Business, Antalya, Turkey.
EM gokhan.akel@akev.edu.tr; earmagan@adu.edu.tr
RI akel, gokhan/AAB-4248-2021; Armağan, Ece/AAM-1399-2021; Akel,
   Gökhan/IQW-2719-2023
OI Akel, Gökhan/0000-0003-4353-7855
CR ANDERSON EW, 1993, MARKET SCI, V12, P125, DOI 10.1287/mksc.12.2.125
   ANDERSON EW, 1994, J MARKETING, V58, P53, DOI 10.2307/1252310
   [Anonymous], 2015, ADV COMPUTER SCI INT
   BABIN BJ, 1994, J CONSUM RES, V20, P644, DOI 10.1086/209376
   Bao J., 2012, P 20 INT C ADV GEOGR, P199, DOI [DOI 10.1145/2424321.2424348, 10.1145/2424321.2424348]
   BARON RM, 1986, J PERS SOC PSYCHOL, V51, P1173, DOI 10.1037/0022-3514.51.6.1173
   Batra R., 1990, MARKET LETT, V2, P159, DOI [DOI 10.1007/BF00436035, 10.1007/BF00436035]
   Bhattacherjee A, 2001, MIS QUART, V25, P351, DOI 10.2307/3250921
   Bhattacherjee A, 2001, DECIS SUPPORT SYST, V32, P201, DOI 10.1016/S0167-9236(01)00111-7
   Carpenter JM, 2005, J FASH MARK MANAG, V9, P43, DOI 10.1108/13612020510586398
   Chang IC, 2014, INTERNET RES, V24, P21, DOI 10.1108/IntR-02-2012-0025
   Chaudhuri Arjun., 2006, 2006 AM MARKETING AS, V17, P195
   Chen L., 2012, COMMUN ASSOC INF SYS, V30, P127
   Cheol Park, 2006, International Journal of Mobile Communications, V4, P497
   Cheung CMK, 2009, J INF SCI, V35, P279, DOI 10.1177/0165551508099088
   Childers TL, 2001, J RETAILING, V77, P511, DOI 10.1016/S0022-4359(01)00056-2
   Chitturi R, 2007, J MARKETING RES, V44, P702, DOI 10.1509/jmkr.44.4.702
   Chiu CM, 2007, INFORM SYST J, V17, P271, DOI 10.1111/j.1365-2575.2007.00238.x
   Chiu CM, 2005, COMPUT EDUC, V45, P399, DOI 10.1016/j.compedu.2004.06.001
   Chong AYL, 2013, J COMPUT INFORM SYST, V53, P22, DOI 10.1080/08874417.2013.11645647
   Comito C, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106205
   CROSBY LA, 1990, J MARKETING, V54, P68, DOI 10.2307/1251817
   Cui YQ, 2013, INT J HUM-COMPUT ST, V71, P919, DOI 10.1016/j.ijhcs.2013.03.004
   Cyr D, 2006, INFORM MANAGE-AMSTER, V43, P950, DOI 10.1016/j.im.2006.08.009
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   DAVIS FD, 1992, J APPL SOC PSYCHOL, V22, P1111, DOI 10.1111/j.1559-1816.1992.tb00945.x
   Dhar R, 2000, J MARKETING RES, V37, P60, DOI 10.1509/jmkr.37.1.60.18718
   DOSSANTOS MA, 2017, J THEORETICAL APPL E, V12, P54, DOI DOI 10.4067/S0718-18762017000200005
   Ernst C. H., 2013, Working Papers in Information Systems and Business Administration
   Gao H., 2014, MOBILE SOCIAL NETWOR, P165, DOI DOI 10.1007/978-1-4614-8579-7_8
   Giese J.L., 2000, Academy of Marketing Science Review, V2000, P1, DOI DOI 10.1362/1469347002523455
   Hair J.F., 1995, MULTIVARIATE DATA AN
   Hair JF, 2010, Multivariate data analysis
   Hamari J., 2013, ECIS, V105, P18
   HIRSCHMAN EC, 1982, J MARKETING, V46, P92, DOI 10.2307/1251707
   Hoehle H, 2015, MIS QUART, V39, P435, DOI 10.25300/MISQ/2015/39.2.08
   Hong SJ, 2006, DECIS SUPPORT SYST, V42, P1819, DOI 10.1016/j.dss.2006.03.009
   Hu T, 2011, COMMUN ASSOC INF SYS, V29
   Jang YT, 2015, MULTIMED TOOLS APPL, V74, P159, DOI 10.1007/s11042-013-1430-z
   Jiang ZH, 2010, J ASSOC INF SYST, V11, P34
   Jin L, 2016, MULTIMED TOOLS APPL, V75, P8895, DOI 10.1007/s11042-014-2317-3
   Jones MA, 2006, J BUS RES, V59, P974, DOI 10.1016/j.jbusres.2006.03.006
   Joon Koh, 2007, Communications of the ACM, V50, P68, DOI 10.1145/1216016.1216023
   Kang JYM, 2015, COMPUT HUM BEHAV, V46, P210, DOI 10.1016/j.chb.2015.01.012
   Kang YS, 2010, COMPUT HUM BEHAV, V26, P353, DOI 10.1016/j.chb.2009.11.006
   Kettinger WJ, 2009, INFORM MANAGE-AMSTER, V46, P335, DOI 10.1016/j.im.2009.03.004
   Khalifa M., 2003, J ASS INFORM SYSTEMS, V4, P206
   Kim B, 2010, EXPERT SYST APPL, V37, P7033, DOI 10.1016/j.eswa.2010.03.015
   Kim Y.M., 2002, Irish Marketing Review and Journal of Korean Academy of Marketing Science, V15, P25
   Kirschner PA, 2010, COMPUT HUM BEHAV, V26, P1237, DOI 10.1016/j.chb.2010.03.024
   Kleijen M, 2004, J INTERACT MARK, V18, P51, DOI 10.1002/dir.20002
   Lee MC, 2010, COMPUT EDUC, V54, P506, DOI 10.1016/j.compedu.2009.09.002
   Li N, 2009, ICCSSE 2009: PROCEEDINGS OF 2009 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION, P1029, DOI 10.1109/ICCSE.2009.5228475
   Liao CC, 2006, INT J INFORM MANAGE, V26, P469, DOI 10.1016/j.ijinfomgt.2006.09.001
   Lien CH, 2014, COMPUT HUM BEHAV, V41, P104, DOI 10.1016/j.chb.2014.08.013
   Limayem M, 2008, INFORM MANAGE-AMSTER, V45, P227, DOI 10.1016/j.im.2008.02.005
   Lin CS, 2005, INFORM MANAGE-AMSTER, V42, P683, DOI 10.1016/j.im.2004.04.003
   Lin KM, 2011, BEHAV INFORM TECHNOL, V30, P77, DOI 10.1080/01449291003752948
   Lin KM, 2011, COMPUT EDUC, V56, P515, DOI 10.1016/j.compedu.2010.09.017
   Lin WS, 2012, COMPUT EDUC, V58, P88, DOI 10.1016/j.compedu.2011.07.008
   Lin YM, 2008, INT J MOB COMMUN, V6, P67, DOI 10.1504/IJMC.2008.016000
   Liu Q, 2017, IEEE T PARALL DISTR, V28, P1417, DOI 10.1109/TPDS.2016.2615020
   Liu YX, 2019, INFORM SCIENCES, V480, P90, DOI 10.1016/j.ins.2018.12.028
   MANO H, 1993, J CONSUM RES, V20, P451, DOI 10.1086/209361
   Mathwick C, 2001, J RETAILING, V77, P39, DOI 10.1016/S0022-4359(00)00045-2
   McGorry S.Y., 2003, INTERNET HIGH EDUC, V6, P159, DOI 10.1016/S1096-7516(03)00022-8
   McKinney V, 2002, INFORM SYST RES, V13, P296, DOI 10.1287/isre.13.3.296.76
   Munoz-Leiva F., 2017, SPAN J MARKET-ESIC, V21, P25, DOI [10.1016/j.sjme.2016.12.001, DOI 10.1016/J.SJME.2016.12.001]
   Ng EH, 2010, INT J MOB COMMUN, V8, P210, DOI 10.1504/IJMC.2010.031448
   Nysveen H, 2005, J CONSUM MARK, V22, P247, DOI 10.1108/07363760510611671
   Oghuma AP, 2016, TELEMAT INFORM, V33, P34, DOI 10.1016/j.tele.2015.05.006
   Okada EM, 2005, J MARKETING RES, V42, P43, DOI 10.1509/jmkr.42.1.43.56889
   OLIVER RL, 1989, J CONSUM RES, V16, P372, DOI 10.1086/209223
   OLIVER RL, 1980, J MARKETING RES, V17, P460, DOI 10.2307/3150499
   Oliver RL, 1999, J MARKETING, V63, P33, DOI 10.2307/1252099
   Olorunniwo F., 2006, J SERV MARK, V20, P59, DOI [10.1108/08876040610646581, DOI 10.1108/08876040610646581]
   Overby JW, 2006, J BUS RES, V59, P1160, DOI 10.1016/j.jbusres.2006.03.008
   Papangelis K, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3364997
   Qu Y, 2018, J THEOR APPL EL COMM, V13, P99, DOI 10.4067/S0718-18762018000300106
   Rao B, 2003, COMMUN ACM, V46, P61, DOI 10.1145/953460.953490
   Reichheld FF, 2000, HARVARD BUS REV, V78, P105
   Roca JC, 2006, INT J HUM-COMPUT ST, V64, P683, DOI 10.1016/j.ijhcs.2006.01.003
   Shi H, 2010, THIRD INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER-HUMAN INTERACTIONS: ACHI 2010, P1, DOI 10.1109/ACHI.2010.25
   Shin DH, 2011, COMPUT HUM BEHAV, V27, P2207, DOI 10.1016/j.chb.2011.06.017
   Spangenberg ER, 1997, ADV CONSUM RES, V24, P235
   Spreng RA, 1996, J MARKETING, V60, P15, DOI 10.2307/1251839
   Statista, 2019, NUMB MOB APP HOURS P
   Statista, 2019, TOP YOUTUBE ADV VID
   Suki NM, 2012, J INF TECHNOL RES, V5, P1, DOI 10.4018/jitr.2012040101
   Sutko DM, 2011, NEW MEDIA SOC, V13, P807, DOI 10.1177/1461444810385202
   Teo TSH, 2008, J MANAGE INFORM SYST, V25, P99, DOI 10.2753/MIS0742-1222250303
   Thong JYL, 2006, INT J HUM-COMPUT ST, V64, P799, DOI 10.1016/j.ijhcs.2006.05.001
   To PL, 2007, TECHNOVATION, V27, P774, DOI 10.1016/j.technovation.2007.01.001
   Vakratsas D, 1999, J MARKETING, V63, P26, DOI 10.2307/1251999
   van der Heijden H, 2004, MIS QUART, V28, P695, DOI 10.2307/25148660
   Venkatesh V, 2011, INFORM SYST J, V21, P527, DOI [10.1111/J.1365-2575.2011.00373.x, 10.1111/j.1365-2575.2011.00373.x]
   Vijay TS, 2019, J THEOR APPL EL COMM, V14, P1, DOI 10.4067/S0718-18762019000100102
   Voss KE, 2003, J MARKETING RES, V40, P310, DOI 10.1509/jmkr.40.3.310.19238
   Wang MM, 2019, J THEOR APPL EL COMM, V14, P17, DOI 10.4067/S0718-18762019000300103
   Wei KM, 2017, J STAT MANAG SYST, V20, P965, DOI 10.1080/09720510.2017.1338609
   Xiao Z, 2018, IEEE T MOBILE COMPUT, V17, P1397, DOI 10.1109/TMC.2017.2768360
   Xin MJ, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102125
   Xu CY, 2015, DECIS SUPPORT SYST, V79, P171, DOI 10.1016/j.dss.2015.08.008
   Yu J, 2013, ONLINE INFORM REV, V37, P711, DOI 10.1108/OIR-12-2011-0202
   Zheng YM, 2013, DECIS SUPPORT SYST, V56, P513, DOI 10.1016/j.dss.2012.11.008
   Zheng Y, 2011, COMPUTING WITH SPATIAL TRAJECTORIES, P277
   Zhou T, 2013, PERS UBIQUIT COMPUT, V17, P741, DOI 10.1007/s00779-012-0613-3
NR 107
TC 21
Z9 21
U1 10
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7103
EP 7124
DI 10.1007/s11042-020-10094-2
EA OCT 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000582308600001
DA 2024-07-18
ER

PT J
AU Wu, TZ
   Zhou, JS
   Qu, WG
   Gu, YH
   Li, B
   Zhong, HL
   Long, YF
AF Wu, Taizhong
   Zhou, Junsheng
   Qu, Weiguang
   Gu, Yanhui
   Li, Bin
   Zhong, Huilin
   Long, Yunfei
TI Improving AMR parsing by exploiting the dependency parsing as an
   auxiliary task
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abstract meaning representations; Multi-task learning;
   Dependency-auxiliary AMR parser; Neural network
AB meaning representations (AMRs) represent sentence semantics as rooted labeled directed acyclic graphs. Though there is a strong correlation between the AMR graph of a sentence and its corresponding dependency tree, the recent neural network AMR parsers do neglect the exploitation of dependency structure information. In this paper, we explore a novel approach to exploiting dependency structures for AMR parsing. Unlike traditional pipeline models, we treat dependency parsing as an auxiliary task for AMR parsing under the multi-task learning framework by sharing neural network parameters and selectively extracting syntactic representation by the attention mechanism. Particularly, to balance the gradients and focus on the AMR parsing task, we present a new dynamical weighting scheme in the loss function. The experimental results on the LDC2015E86 and LDC2017T10 dataset show that our dependency-auxiliary AMR parser significantly outperforms the baseline and its pipeline counterpart, and demonstrate that the neural AMR parsers can be greatly boosted with the help of effective methods of integrating syntax.
C1 [Wu, Taizhong; Zhou, Junsheng; Qu, Weiguang; Gu, Yanhui; Li, Bin; Zhong, Huilin] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing, Peoples R China.
   [Long, Yunfei] Univ Essex, Sch Comp Sci & Elect Engn, Colchester, Essex, England.
C3 Nanjing Normal University; University of Essex
RP Zhou, JS; Qu, WG (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing, Peoples R China.
EM zhoujs@njnu.edu.cn; wgqu_nj@163.com; longyunfei910911@gmail.com
RI zhong, huilin/KPA-2418-2024; LONG, YUNFEI/O-5784-2019
OI LONG, YUNFEI/0000-0002-4407-578X; Zhou, Junsheng/0000-0002-1919-8227;
   Gu, Yanhui/0000-0002-8838-3186
FU National Science Fundatiaon of China [61772278, 61472191]; National
   Social Science Foundation of China [18BYY127]; project for Jiangsu
   Higher Institutions' Excellent Innovative Team for Philosophy and Social
   Sciences [2017STD006]
FX This research is supported by projects 61772278 and 61472191 under the
   National Science Fundatiaon of China, project 18BYY127 under the
   National Social Science Foundation of China,project for Jiangsu Higher
   Institutions' Excellent Innovative Team for Philosophy and Social
   Sciences (2017STD006).
CR Ballesteros Miguel, 2017, P 2017 C EMPIRICAL M, P1269
   Banarescu L., 2013, P 7 LING ANN WORKSH, P178
   Chai YF, 2018, INTL CONF POWER SYST, P911, DOI 10.1109/POWERCON.2018.8602273
   Damonte M, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P536
   Dozat T., 2017, 5 INT C LEARN REPR I
   Dozat Timothy, 2017, Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, P20, DOI DOI 10.18653/V1/K17-3002
   Flanigan J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1426
   Foland WR, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P463, DOI 10.18653/v1/P17-1043
   Goodman J, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1
   Hershcovich D, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P373
   Konstas I, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P146, DOI 10.18653/v1/P17-1014
   Kuncoro A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1249
   Lyu CC, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P397
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Puzikov Y., 2016, Proceedings of the 10th International Workshop on Semantic Evaluation SemEval-2016, P1154
   Qiu J, 2019, CMC-COMPUT MATER CON, V59, P547, DOI 10.32604/cmc.2019.05892
   Strubell E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5027
   van Noord R., 2017, COMPUT LINGUIST, VJ7, P93
   Wang C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P857
   Wang Chuan, 2015, P 2015 C N AM CHAPT, DOI 10.3115/v1/N15-1040
   Wang L, 2017, EVID-BASED COMPL ALT, V2017, DOI 10.1155/2017/8721257
   Wang SZ, 2018, CMC-COMPUT MATER CON, V57, P603, DOI 10.32604/cmc.2018.03884
   Wang WZ, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON SOLID-STATE AND INTEGRATED CIRCUIT TECHNOLOGY (ICSICT), P688, DOI 10.1109/ICSICT.2016.7999012
   Werling K, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P982
   Yang KH, 2019, CMC-COMPUT MATER CON, V61, P569, DOI 10.32604/cmc.2019.05952
   Yu HT, 2013, PROCEEDINGS 2013 INTERNATIONAL CONFERENCE ON MECHATRONIC SCIENCES, ELECTRIC ENGINEERING AND COMPUTER (MEC), P1783, DOI 10.1109/MEC.2013.6885342
   Zhang S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P80
NR 27
TC 2
Z9 2
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30827
EP 30838
DI 10.1007/s11042-020-09967-3
EA OCT 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000581952100004
DA 2024-07-18
ER

PT J
AU Quan, W
   Li, TR
   Zhou, N
   Zou, D
   Zhang, WH
   Chen, JX
AF Quan, Wei
   Li, Tianrui
   Zhou, Ning
   Zou, Dong
   Zhang, Weihua
   Chen, Jim X.
TI Visual tracking with multilayer filter fusion network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Multilayer filter fusion network; Correlation filter
AB We propose the multilayer filter fusion network (MFFN) to address the problem of visual object tracking. In MFFN, the convolutional neural network (CNN) is used to extract the multilayer spatial features and then the convolutional long short-term memory (LSTM) to extract the temporal features of images. The object image centered at the target is cropped and fed into MFFN to obtain the correlation filter and the feature map to discriminate the target from background. The correlation filter is convolved with the corresponding feature map for the same layer to produce the probability map, which is then used to estimate the target position by searching its maximum value. The correlation filter corresponds to the tracked object image that is fed into MFFN and thus contains the appearance changes of target. In our multilayer filter fusion tracking (MFFT) framework, we use two MFFNs with different inputs to track the target via coarse-to-fine location approach. The first one is used to estimate the target position from the entire image and the second one to locate the target from the estimated target position. After the networks are trained off-line they do not require online learning during tracking. Experimental results on the CVPR2013 benchmark demonstrate that our tracking algorithm achieves competitive results compared with other tracking methods.
C1 [Quan, Wei] Southwest Jiaotong Univ, Sch Elect Engn, Chengdu 610031, Sichuan, Peoples R China.
   [Li, Tianrui] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Sichuan, Peoples R China.
   [Zhou, Ning; Zou, Dong; Zhang, Weihua] Southwest Jiaotong Univ, Natl Key Lab Tract Power, Chengdu 610031, Sichuan, Peoples R China.
   [Chen, Jim X.] George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.
C3 Southwest Jiaotong University; Southwest Jiaotong University; Southwest
   Jiaotong University; George Mason University
RP Quan, W (corresponding author), Southwest Jiaotong Univ, Sch Elect Engn, Chengdu 610031, Sichuan, Peoples R China.
EM wquan@swjtu.edu.cn
RI zheng, wei/IQT-9639-2023; Zou, Dong/GSE-0932-2022; zhang,
   weihua/GXV-1334-2022; WU, ZHEN/GRN-7688-2022; Li, Tianrui/F-4974-2019
OI WU, ZHEN/0000-0001-8719-057X; Quan, Wei/0000-0001-7926-9501; Li,
   Tianrui/0000-0001-7780-104X
FU National Natural Science Foundation of China [61703350]; Independent
   Research Project of National Key Laboratory of Traction Power of China
   [2019TPL-T19]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61703350) and Independent Research Project of National
   Key Laboratory of Traction Power of China (Grant No. 2019TPL-T19).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cui Z, 2016, PROC CVPR IEEE, P1449, DOI 10.1109/CVPR.2016.161
   Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kingma D. P., 2014, arXiv
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Lukezic A, 2018, INT J COMPUT VISION, V126, P671, DOI 10.1007/s11263-017-1061-3
   Ma C, 2018, INT J COMPUT VISION, V126, P771, DOI 10.1007/s11263-018-1076-4
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Mahadevan V, 2013, IEEE T PATTERN ANAL, V35, P541, DOI 10.1109/TPAMI.2012.98
   Ning G, 2016, IEEE INT S CIRC SYST, P1
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sin L, 2017, IEEE ICC
   Song Y, 2018, IEEE ICC
   Sun C, 2018, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2018.00058
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang XM, 2015, IEEE I CONF COMP VIS, P4337, DOI 10.1109/ICCV.2015.493
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
   Zuo WM, 2019, IEEE T PATTERN ANAL, V41, P1158, DOI 10.1109/TPAMI.2018.2829180
NR 43
TC 1
Z9 1
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6493
EP 6506
DI 10.1007/s11042-020-09852-z
EA OCT 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000579257300001
DA 2024-07-18
ER

PT J
AU Wu, X
   Sun, Y
   Kawanishi, T
   Kashino, K
AF Wu, X.
   Sun, Y.
   Kawanishi, T.
   Kashino, K.
TI Contrast enhancement based on discriminative co-occurrence statistics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2D Histogram; Contrast enhancement; Histogram equalization; Image
   enhancement; Reflectance; Retinex model
ID IMAGE; FRAMEWORK; RETINEX
AB Despite recent advances in contrast enhancement, it remains difficult for existing methods to simultaneously achieve consistent improvements in image brightness and contrast in both low-light and normal-light images. To address this issue, we revisit 2D histogram equalization methods and extend them to accommodate more diversified and poor lighting conditions. The extension is based on the observation that the contrast needs to be improved by increasing the intensity difference between spatially neighboring pixels, while the degree of increase should be proportional to the difference in their reflectances. On the basis of this observation, we propose to embed the inter-pixel contextual information of image reflectance into the 2D histogram of intensity co-occurrence. An intensity mapping function can thus be derived by solving optimization problems formulated with the 2D histogram, leading to two novel contrast enhancement methods. Qualitative and quantitative evaluations on more than 600 images showed that the proposed methods are superior to state-of-the-art contrast enhancement methods. It was also shown that the reflectance of an image provides important visual information on the significance and objectness of local image areas. Using this reflectance as a clue, the degree of contrast enhancement can be adaptively derived to achieve sufficient brightness improvement in low-light images and to avoid excessive enhancement in normal-light images.
C1 [Wu, X.; Kawanishi, T.; Kashino, K.] NTT Corp, Commun Sci Labs, 3-1 Morinosato Wakamiya, Atsugi, Kanagawa 2430198, Japan.
   [Sun, Y.] NTT Corp, Media Intelligence Labs, 1-1 Hikarinooka, Yokosuka, Kanagawa 2390847, Japan.
C3 Nippon Telegraph & Telephone Corporation; Nippon Telegraph & Telephone
   Corporation
RP Wu, X (corresponding author), NTT Corp, Commun Sci Labs, 3-1 Morinosato Wakamiya, Atsugi, Kanagawa 2430198, Japan.
EM xiaomeng.wu.px@hco.ntt.co.jp; yongqing.sun.fb@hco.ntt.co.jp;
   takahito.kawanishi.fx@hco.ntt.co.jp; kunio.kashino.me@hco.ntt.co.jp
OI Wu, Xiaomeng/0000-0003-2816-1781
CR Agaian SS, 2007, IEEE T IMAGE PROCESS, V16, P741, DOI 10.1109/TIP.2006.888338
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Balado F, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1413, DOI 10.1109/ICASSP.2018.8462242
   Celik T, 2012, PATTERN RECOGN, V45, P3810, DOI 10.1016/j.patcog.2012.03.019
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Chen QF, 2017, IEEE I CONF COMP VIS, P2516, DOI 10.1109/ICCV.2017.273
   Chen YS, 2018, PROC CVPR IEEE, P6306, DOI 10.1109/CVPR.2018.00660
   Chen ZY, 2006, IEEE T IMAGE PROCESS, V15, P2290, DOI 10.1109/TIP.2006.875204
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Eilertsen G, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818092
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hu YX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201353
   Ignatov A, 2017, IEEE I CONF COMP VIS, P3297, DOI 10.1109/ICCV.2017.355
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kinoshita Y, 2019, IEEE T IMAGE PROCESS, V28, P4101, DOI 10.1109/TIP.2019.2906501
   Lecca M, 2018, IEEE T IMAGE PROCESS, V27, P5802, DOI 10.1109/TIP.2018.2858541
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Li JN, 2018, ASIAPAC SIGN INFO PR, P1544, DOI 10.23919/APSIPA.2018.8659597
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liu XH, 2014, IEEE T IMAGE PROCESS, V23, P4361, DOI 10.1109/TIP.2014.2347204
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Park J, 2018, PROC CVPR IEEE, P5928, DOI 10.1109/CVPR.2018.00621
   Pu YF, 2018, IEEE T IMAGE PROCESS, V27, P1214, DOI 10.1109/TIP.2017.2779601
   Ramponi G, 1998, SIGNAL PROCESS, V67, P211, DOI 10.1016/S0165-1684(98)00038-3
   Ren XT, 2020, IEEE T IMAGE PROCESS, V29, P5862, DOI 10.1109/TIP.2020.2984098
   Ren YR, 2019, IEEE T CIRC SYST VID, V29, P968, DOI 10.1109/TCSVT.2018.2828141
   Shen XY, 2017, INT J COMPUT VISION, V125, P19, DOI 10.1007/s11263-017-1021-y
   Shibata T, 2016, PROC CVPR IEEE, P2745, DOI 10.1109/CVPR.2016.300
   Shu X, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3225219
   Su HA, 2017, INT CONF ACOUST SPEE, P1977, DOI 10.1109/ICASSP.2017.7952502
   Tang M, 2020, IEEE T IMAGE PROCESS, V29, P7217, DOI 10.1109/TIP.2020.2999858
   Wang R., 2019, P IEEECVF C COMPUTER, P6849
   Wang SH, 2018, IEEE T IMAGE PROCESS, V27, P938, DOI 10.1109/TIP.2017.2771449
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wu XM, 2017, IEEE IMAGE PROC, P3190, DOI 10.1109/ICIP.2017.8296871
   Xiao B, 2018, NEUROCOMPUTING, V275, P2798, DOI 10.1016/j.neucom.2017.11.057
   Xu J, 2020, IEEE T IMAGE PROCESS, V29, P5022, DOI 10.1109/TIP.2020.2974060
   Xu L, 2015, PR MACH LEARN RES, V37, P1669
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yu Y, 2016, ACM T GRAPHIC, DOI DOI 10.1145/2790296
   Zhang Q, 2014, PROC CVPR IEEE, P2830, DOI 10.1109/CVPR.2014.362
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zhu LF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366146
NR 54
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6413
EP 6442
DI 10.1007/s11042-020-09948-6
EA OCT 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577869200004
DA 2024-07-18
ER

PT J
AU Lincy, RB
   Gayathri, R
AF Lincy, R. Babitha
   Gayathri, R.
TI Optimally configured convolutional neural network for Tamil Handwritten
   Character Recognition by improved lion optimization model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tamil character recognition; Pre-processing; Otsu's Thresholding;
   Convolutional neural network; Optimization
ID CHINESE CHARACTERS; ALGORITHM
AB In recent data, Optical character recognition (OCR) systems have laid hands in the field of most popular language recognitions. Unlike other languages, the Tamil language is more complex to recognize, and hence considerable efforts have been laid in literature. However, the models are not yet well-organized for precise recognition of Tamil characters. Thus, the current research work develops a novel Tamil Handwritten Character Recognition approach by following two major processes, viz. pre-processing and recognition. The pre-processing phase encloses RGB to grayscale conversion, binarization with thresholding, image complementation, morphological operations, and linearization. Subsequently, the pre-processed image after linearization is subjected to recognition via an optimally configured Convolutional Neural Network (CNN). More particularly, the fully connected layer and weights are fine-tuned by a new Self Adaptive Lion Algorithm (SALA) that is the conceptual improvement of the standard Lion Algorithm (LA). The performance of the proposed work is compared and proved over other state-of-the-art models with respect to certain performance measures.
C1 [Lincy, R. Babitha] Anna Univ, Sri Venkateswara Coll Engn, ECE Informat & Commun Engn, Sriperumbudur, India.
   [Gayathri, R.] Sri Venkateswara Coll Engn, ECE, Sriperumbudur Pennalur 602117, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Lincy, RB (corresponding author), Anna Univ, Sri Venkateswara Coll Engn, ECE Informat & Commun Engn, Sriperumbudur, India.
EM rblincy@gmail.com; rgayathri@svce.ac.in
RI Rajagopal, gayathri/ABB-6110-2020
OI Rajagopal, gayathri/0000-0002-3377-0461
CR Deepa RNA, 2020, PATTERN ANAL APPL, V23, P199, DOI 10.1007/s10044-018-00776-x
   Benaddy M, 2019, SENS IMAGING, V20, DOI 10.1007/s11220-019-0231-5
   Bhattacharya U, 2007, PROC INT CONF DOC, P511
   Boothalingam R, 2018, EVOL INTELL, V11, P31, DOI 10.1007/s12065-018-0168-y
   Boufenar C, 2018, COGN SYST RES, V50, P180, DOI 10.1016/j.cogsys.2017.11.002
   Das N, 2012, APPL SOFT COMPUT, V12, P1592, DOI 10.1016/j.asoc.2011.11.030
   Guruprasad P, 2016, PROCEDIA COMPUT SCI, V89, P836, DOI 10.1016/j.procs.2016.06.069
   Jacob, RECENT ADV COMPUT SC, P497
   Kavitha BR, 2019, J KING SAUD U COMP I
   Khaire P, 2018, PATTERN RECOGN LETT, V115, P107, DOI 10.1016/j.patrec.2018.04.035
   Kowsalya S, 2019, MULTIMED TOOLS APPL, V78, P25043, DOI 10.1007/s11042-019-7624-2
   Kundu S, 2019, NEURAL COMPUT APPL, P1
   Kunwar R, 2011, PROC INT CONF DOC, P1389, DOI 10.1109/ICDAR.2011.279
   Li XL, 2019, J PARALLEL DISTR COM, V123, P223, DOI 10.1016/j.jpdc.2018.10.003
   Manjusha K, 2019, ENG SCI TECHNOL, V22, P637, DOI 10.1016/j.jestch.2018.10.011
   Pragr M., 2019, European Conference on Mobile Robots (ECMR), P1, DOI [DOI 10.1109/ECMR.2019.8870912.,33%CONTRIBUTION, DOI 10.1109/VITECON.2019.8899614]
   Prakash A. Arun, 2018, 2018 International Conference on Intelligent Computing and Communication for Smart World (I2C2SW). Proceedings, P278, DOI 10.1109/I2C2SW45816.2018.8997144
   Raj MA, 2019, MICRO NANO TECHNOL, P1, DOI 10.1016/B978-0-12-815394-9.00001-7
   Rajakumar BR, 2013, AASRI PROC, V4, P288, DOI 10.1016/j.aasri.2013.10.043
   Rajakumar BR, 2013, INT J COMPUT SCI ENG, V8, P180, DOI 10.1504/IJCSE.2013.053087
   Rajakumar BR, 2012, PROC TECH, V1, P126, DOI 10.1016/j.protcy.2012.10.016
   Rajakumar B.R., 2013, International Journal of Hybrid Intelligent Systems, V10, P11, DOI [10.3233/HIS-120161, DOI 10.3233/HIS-120161]
   Rajakumar B. R., 2012, P IEEE INT C COMP IN, P1
   Rajakumar BR, 2014, 2014 IEEE C EV COMP
   Ram Kumar S, 2020, IJARIIEISSNO23954396, V6
   Ren HQ, 2019, PATTERN RECOGN LETT, V128, P400, DOI 10.1016/j.patrec.2019.10.001
   Ren HQ, 2019, PATTERN RECOGN, V93, P179, DOI 10.1016/j.patcog.2019.04.015
   Robby GA, 2019, PROCEDIA COMPUT SCI, V157, P499, DOI 10.1016/j.procs.2019.09.006
   Sahare P, 2018, IEEE ACCESS, V6, P10603, DOI 10.1109/ACCESS.2018.2795104
   Shanthi N, 2010, PATTERN ANAL APPL, V13, P173, DOI 10.1007/s10044-009-0147-0
   Sharp TH, 2017, J STRUCT BIOL, V197, P155, DOI 10.1016/j.jsb.2016.09.008
   Sornam M., 2018, SMART INNOVATIVE TRE, P778
   Subashini A., 2011, 2011 IEEE 6th International Conference on Industrial and Information Systems (ICIIS 2011), P261, DOI 10.1109/ICIINFS.2011.6038077
   Suresh RM, 2005, ICCIMA 2005: Sixth International Conference on Computational Intelligence and Multimedia Applications, Proceedings, P291
   Swamy SM, 2013, IET CHENN 4 INT C SU, DOI [10.1049/ic.2013.0361, DOI 10.1049/IC.2013.0361]
   Usha MK, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P133, DOI 10.1109/WiSPNET.2016.7566106
   Vinotheni C., 2020, Advances in Distributed Computing and Machine Learning. Proceedings of ICADCML 2020. Lecture Notes in Networks and Systems (LNNS 127), P469, DOI 10.1007/978-981-15-4218-3_46
   Wang L, 2019, IEEE T CYBERNET
   Wei XH, 2018, PATTERN RECOGN, V76, P679, DOI 10.1016/j.patcog.2017.09.044
   Wu XP, 2019, IEEE SIGNAL PROC LET, V26, P597, DOI 10.1109/LSP.2019.2895967
   Xu L, 2019, IEEE ACCESS, V7, P102039, DOI 10.1109/ACCESS.2019.2930799
   Yuan C, 2015, OPTIK, V126, P1598, DOI 10.1016/j.ijleo.2015.05.032
   Zhang XY, 2018, IEEE T PATTERN ANAL, V40, P849, DOI 10.1109/TPAMI.2017.2695539
NR 43
TC 17
Z9 17
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5917
EP 5943
DI 10.1007/s11042-020-09771-z
EA OCT 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000578564800006
DA 2024-07-18
ER

PT J
AU Hu, YK
   Yu, SH
   Qin, SF
   Chen, DK
   Chu, JJ
   Yang, YP
AF Hu, Yukun
   Yu, Suihuai
   Qin, Shengfeng
   Chen, Dengkai
   Chu, Jianjie
   Yang, Yanpu
TI How to extract traditional cultural design elements from a set of images
   of cultural relics based on F-AHP and entropy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cultural products; Extraction of design elements; F-AHP; Entropy
ID EVALUATION MODEL; EXPERIENCE; PRODUCTS; FEATURES
AB The creative cultural product design, relating to both typical regional cultures and traditional cultural elements, is a hot issue in recent years. However, there is still a lack of systematic and efficient designing methods to guide designing practices. In order to fill this research gap, this paper proposes a new design method based on F-AHP (Fuzzy-Analytic Hierarchy Process) and entropy computation to extract traditional cultural shape design elements from a set of images of cultural relics. Firstly, we collect a set of culture object related to descriptive and adjective words that can express users' emotional perception and narrow down them into a shortlist via a fitness evaluation process. Secondly, we analyze and extract common shape elements with image processing tools and user choices. Thirdly, we create a full mapping between the shortlisted culture descriptive words and the identified common shape elements and determine the weighting of each shape element against each evaluation indicator through F-AHP. Fourthly, we construct decision-making matrix and extract key shape elements with high information entropy. Finally, we start designing products with extracted cultural elements. A case study of Han Dynasty potter figurines was conducted to verify the feasibility of the proposed approach.
C1 [Hu, Yukun; Yu, Suihuai; Chen, Dengkai; Chu, Jianjie] Northwestern Polytech Univ, Shaanxi Engn Lab Ind Design, Xian 710072, Peoples R China.
   [Qin, Shengfeng] Northumbria Univ, Sch Design, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
   [Yang, Yanpu] Changan Univ, Sch Construct Machinery, Xian 710064, Peoples R China.
C3 Northwestern Polytechnical University; Northumbria University; Chang'an
   University
RP Chen, DK (corresponding author), Northwestern Polytech Univ, Shaanxi Engn Lab Ind Design, Xian 710072, Peoples R China.
EM chendengkai@nwpu.edu.cn
OI Qin, Shengfeng/0000-0001-8538-8136
FU Fundamental Research Funds for the Central Universities [G2017KY202];
   National Natural Science Foundation of China [51805043]; 111 Project
   [B13044]
FX The authors really appreciate the experts, designers and users who offer
   great help. This study is expected to provide some references to design
   practices. This research was supported by the "Fundamental Research
   Funds for the Central Universities" (G2017KY202), National Natural
   Science Foundation of China (Grant No. 51805043) and the 111 Project
   (Grant No.B13044).
CR Alam SS, 2002, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOL I, P185, DOI 10.1109/ICIF.2002.1021149
   Amiri V, 2014, ENVIRON EARTH SCI, V72, P3479, DOI 10.1007/s12665-014-3255-0
   [Anonymous], 2008, J DESIGN
   Ares G, 2013, J SENS STUD, V28, P138, DOI 10.1111/joss.12031
   Chen LL, 2014, PROCEEDINGS OF THE 2014 20TH INTERNATIONAL CONFERENCE ON AUTOMATION AND COMPUTING (ICAC'14), P79, DOI 10.1109/IConAC.2014.6935464
   Delgado A, 2016, ENVIRON MODELL SOFTW, V77, P108, DOI 10.1016/j.envsoft.2015.12.011
   Du YX, 2019, J INTELL FUZZY SYST, V37, P4253, DOI 10.3233/JIFS-190367
   Duo TL, 2019, J VIS COMMUN IMAGE R, V58, P220, DOI 10.1016/j.jvcir.2018.11.026
   Gao Y., 2018, J ARTS HUMANIT, V7, P57, DOI DOI 10.18533/JOURNAL.V7I3.1363
   Glaholt MG, 2009, PSYCHNOLOGY J, V7, P141
   Golden BL, 2017, ANAL HIERARCHY PROCE
   Golden BL, 1989, ANAL HIERARCHY PROCE, DOI DOI 10.1007/978-3-642-50244-6
   Hassenzahl M, 2006, BEHAV INFORM TECHNOL, V25, P91, DOI 10.1080/01449290500330331
   He ZF, 2020, J INTELL FUZZY SYST, V38, P7779, DOI 10.3233/JIFS-179847
   Ho CH, 2014, INT J IND ERGONOM, V44, P436, DOI 10.1016/j.ergon.2014.01.009
   Hu HA, 2012, INT J ENVIRON SCI TE, V9, P343, DOI 10.1007/s13762-012-0037-7
   Hu Y, 2011, ADVANCED MATHEMATICAL METHODS FOR FINANCE, P367, DOI 10.1007/978-3-642-18412-3_14
   Lee YJ, 2012, PAK J STAT, V28, P617
   Lee YJ, 2010, J STAT MANAG SYST, V13, P823, DOI 10.1080/09720510.2010.10701505
   Li N, 2019, INTEGR ENVIRON ASSES, V15, P703, DOI 10.1002/ieam.4163
   Lin RT, 2007, INT J DES, V1, P45
   Obal D, 2014, MULTIMED TOOLS APPL, V71, P97, DOI 10.1007/s11042-013-1500-2
   Orquin JL, 2013, ACTA PSYCHOL, V144, P190, DOI 10.1016/j.actpsy.2013.06.003
   Pinto Y, 2013, J VISION, V13, DOI 10.1167/13.3.16
   Prabhu SR, 2019, INT J MATER PROD TEC, V58, P155, DOI 10.1504/IJMPT.2019.097667
   Prandi C, 2019, MULTIMED TOOLS APPL, V78, P3341, DOI 10.1007/s11042-018-6513-4
   Pugliese MJ, 2002, RES ENG DES, V13, P139, DOI 10.1007/s00163-002-0013-1
   Qin ZZ, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11020426
   Qu M, 2016, COMPUT IND, V77, P1, DOI 10.1016/j.compind.2015.12.004
   Saad MH, 2021, INT J PR ENG MAN-GT, V8, P57, DOI 10.1007/s40684-019-00184-4
   Seddiki M, 2019, RENEW SUST ENERG REV, V110, P101, DOI 10.1016/j.rser.2019.04.046
   Street M, 2010, 37 GAZE BIAS SELECTI, DOI DOI 10.1080/13506281003668900
   Sun CC, 2010, EXPERT SYST APPL, V37, P7745, DOI 10.1016/j.eswa.2010.04.066
   Tzeng G.H., 2011, Boca Raton, V352, DOI [10.1201/B11032, DOI 10.1201/B11032]
   van der Laan LN, 2015, FOOD QUAL PREFER, V39, P46, DOI 10.1016/j.foodqual.2014.06.015
   Wang CH, 2019, EKOLOJI, V28, P1901
   Wang Y., 2020, APPL FINANC ACC, V6
   Wu M., 2020, RESOUR ENVIRON EC, V2, P12, DOI [10.25082/REE.2020.01.003, DOI 10.25082/REE.2020.01.003]
   Wu TY, 2018, LECT NOTES COMPUT SC, V10912, P245, DOI 10.1007/978-3-319-92252-2_19
   Wu X, 2008, ASIAN SOC SCI, V4, P109
   Yeh ML, 2011, LECT NOTES COMPUT SC, V6775, P114, DOI 10.1007/978-3-642-21660-2_13
   Yousif T., 2020, ONLINE J ART DES, V8, P215
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zeleny M., 1982, MULTIPLE CRITERIA DE
   Zhi-Hong Z, 2006, J ENVIRON SCI, V18, P1020, DOI 10.1016/S1001-0742(06)60032-6
NR 45
TC 5
Z9 7
U1 9
U2 124
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5833
EP 5856
DI 10.1007/s11042-020-09348-w
EA OCT 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000576709300005
DA 2024-07-18
ER

PT J
AU Math, L
   Fatima, R
AF Math, Laxmi
   Fatima, Ruksar
TI Adaptive machine learning classification for diabetic retinopathy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy; CNN (convolution neural networks); DL (deep
   learning); Fundus images
AB Diabetic retinopathy is the main cause of the blindness worldwide. However, the diabetic retinopathy is hard to be detected in the initial stages, and the procedure of diagnostic can be time-consuming even for experienced-experts. The segment based learning approach has shown the benefits over learning technique for detection of diabetic retinopathy: only the annotation of image level is required get the lesions and detection of diabetic retinopathy. Anyways, the performance of existing methods are limited by the utilization of handcrafted features. This paper proposes the segment based learning approach for detection of diabetic retinopathy, which mutually learns classifiers and features from the data and gets significant development on recognizing the images of diabetic retinopathy and their inside the lesions. Specifically, the pre-trained CNN is adapted to get the segment level DRE (Diabetic retinopathy Estimation) and then Integrating all segment level of (DRM) is utilized to make the classification of diabetic retinopathy images. Lastly, an end-to-end segment based learning approach to deal with the irregular lesions of diabetic retinopathy. For detection of the diabetic retinopathy images obtain area under of ROC curve is 0.963 on the Kaggle dataset and also obtains sensitivity and specificity 96.37% and 96.37% on the higher specificity and sensitivity that outperforms much better than existing model.
C1 [Math, Laxmi; Fatima, Ruksar] KBN Coll Engn, Kalaburagi, Karnataka, India.
RP Math, L (corresponding author), KBN Coll Engn, Kalaburagi, Karnataka, India.
EM laxmi.math@gmail.com; ruksarf@gmail.com
RI Fatima, Dr. Ruksar/CAH-0018-2022
OI Fatima, Dr. Ruksar/0000-0003-0830-5127
CR [Anonymous], 2016, Int J Eng Res Technol
   Bankhead P, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032435
   Chen YW, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1030, DOI 10.1109/ICASSP.2018.8461427
   Chetoui M, 2018, CAN CON EL COMP EN
   Dutta S, 2018, INT J GRID DISTRIB, V11, P89, DOI 10.14257/ijgdc.2018.11.1.09
   Fraz MM, 2013, J DIGIT IMAGING, V26, P274, DOI 10.1007/s10278-012-9513-3
   García G, 2017, LECT NOTES COMPUT SC, V10614, P635, DOI 10.1007/978-3-319-68612-7_72
   García M, 2008, IEEE ENG MED BIO, P5425, DOI 10.1109/IEMBS.2008.4650441
   Gazarek J, 2011, IEEE C 2011 INT C IM, P3
   Ghaffar F, 2016, INT JOINT CONF COMP, P122
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Kalviainen R., 2007, the diaretdb1 diabetic retinopathy database and evaluation protocol
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar PNS, 2016, PROCEDIA COMPUT SCI, V93, P486, DOI 10.1016/j.procs.2016.07.237
   Lam BSY, 2010, IEEE T MED IMAGING, V29, P1369, DOI 10.1109/TMI.2010.2043259
   Li YH, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6142839
   Nagaveena DD, 2013, INT J SCI TECHNOL
   Nahid A.-A., 2018, Biomed. Res., V29, P2068, DOI DOI 10.4066/BIOMEDICALRESEARCH.29-17-3903
   Nayak J, 2008, J MED SYST, V32, P107, DOI 10.1007/s10916-007-9113-9
   Omar Z. A., 2017, 2017 7th IEEE International Conference on System Engineering and Technology (ICSET). Proceedings, P162, DOI 10.1109/ICSEngT.2017.8123439
   Prasad Deepthi K., 2015, 2015 IEEE Recent Advances in Intelligent Computational Systems (RAICS), P240, DOI 10.1109/RAICS.2015.7488421
   Pratt H, 2016, PROCEDIA COMPUT SCI, V90, P200, DOI 10.1016/j.procs.2016.07.014
   Quellec G, 2017, MED IMAGE ANAL, V39, P178, DOI 10.1016/j.media.2017.04.012
   Setiawan AW, 2013, INT CONF ICT SMART S, P215
   Sukkaew Lassada, 2007, Journal of the Medical Association of Thailand, V90, P1780
   Veerashetty S, 2020, MULTIMED TOOLS APPL, V79, P9935, DOI 10.1007/s11042-019-7345-6
   Yehui Yang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P533, DOI 10.1007/978-3-319-66179-7_61
   Zeng XL, 2019, IEEE ACCESS, V7, P30744, DOI 10.1109/ACCESS.2019.2903171
   Zhe Wang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P267, DOI 10.1007/978-3-319-66179-7_31
NR 29
TC 53
Z9 54
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5173
EP 5186
DI 10.1007/s11042-020-09793-7
EA OCT 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000574800200005
DA 2024-07-18
ER

PT J
AU Kim, KT
   Lee, B
   Choi, JY
AF Kim, Kyeong Tae
   Lee, Bumshik
   Choi, Jae Young
TI 3D-2D deep convolutional neural network (DCNN) Cascade for robust video
   face identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video face identification; Deep convolutional neural network; 3D-2D-DCNN
   cascade; Class-confidence matrix
AB This paper proposes a novel video face identification method, named "3D-2D-DCNN cascade" that serially combines 3D and 2D deep convolutional neural networks (DCNNs) for robust video face recognition (FR). In our method, an input video (face) sequence is first divided into a number of sub-video sequences and each of the sub-video sequences is then used as an input to the 3D-DCNN, aiming to obtain a set of class-confidence scores for a given input video sequence. These class-confidence scores are aggregated in a novel way, resulting in the formation of our novel class-confidence matrix. Key characteristic of our method is to make use of this class-confidence matrix for fine-tuning 2D-DCNN, which is serially linked to 3D-DCNN, to obtain the final face identification results. To verify the proposed method, two popular video identification benchmarks, COX Face and YTC databases, were used. Compared to the best reported recognition results on these two benchmarks, our proposed method achieves better or comparable recognition performances.
C1 [Kim, Kyeong Tae; Choi, Jae Young] Hankuk Univ Foreign Studies, Pattern Recognit & Machine Intelligence Lab, Div Comp & Elect Syst Engn, 81 Oedae Ro, Yongin 17305, Gyeonggi Do, South Korea.
   [Lee, Bumshik] Chosun Univ, Dept Informat & Commun Engn, Gwangju 61452, South Korea.
C3 Hankuk University Foreign Studies; Chosun University
RP Choi, JY (corresponding author), Hankuk Univ Foreign Studies, Pattern Recognit & Machine Intelligence Lab, Div Comp & Elect Syst Engn, 81 Oedae Ro, Yongin 17305, Gyeonggi Do, South Korea.
EM jychoi@hufs.ac.kr
FU Hankuk University of Foreign Studies Research Fund; Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   - Ministry of Education [2018R1D1A1A09082615]
FX This research was supported by Hankuk University of Foreign Studies
   Research Fund. This research was supported by Basic Science Research
   Program through the National Research Foundation of Korea (NRF) funded
   by the Ministry of Education under Grant 2018R1D1A1A09082615.
CR [Anonymous], 2017, ARXIV160904836
   [Anonymous], 2017, CVPR
   [Anonymous], 2018, Arcface: Additive angular margin loss for deep face recognition
   Ding CX, 2018, IEEE T PATTERN ANAL, V40, P1002, DOI 10.1109/TPAMI.2017.2700390
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Glorot X., 2010, P INT C ART INT STAT, P249
   Gong S., 2019, ARXIV190207327
   Goyal Priya, 2017, abs/1706.02677
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Hayat M, 2015, IEEE T PATTERN ANAL, V37, P713, DOI 10.1109/TPAMI.2014.2353635
   Hernández-Durán M, 2018, LECT NOTES COMPUT SC, V11047, P95, DOI 10.1007/978-3-030-01132-1_11
   Huang ZW, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493448
   Huang ZW, 2015, PROC CVPR IEEE, P140, DOI 10.1109/CVPR.2015.7298609
   Huang ZW, 2014, PROC CVPR IEEE, P1677, DOI 10.1109/CVPR.2014.217
   JIA X, 2018, ARXIV180711205
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kim M, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.1093
   Liao X, 2020, IEEE J SEL TOP QUANT, P1
   Lu JW, 2016, IEEE T CIRC SYST VID, V26, P529, DOI 10.1109/TCSVT.2015.2412831
   Lu JW, 2015, PROC CVPR IEEE, P1137, DOI 10.1109/CVPR.2015.7298717
   Luschi C., 2018, ARXIV180407612
   Parchami M, 2017, VIDEO BASED FACE REC
   Parchomiuk Marcin., 2017, 2017 PROGR APPL ELEC, P1, DOI DOI 10.1109/AVSS.2017.8078554
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Qi X, 2018, INT CONF BIOMETR, P132, DOI 10.1109/ICB2018.2018.00030
   Rao YM, 2019, INT J COMPUT VISION, V127, P701, DOI 10.1007/s11263-018-1135-x
   Wang H., 2009, World Academy of Science, Engineering and Technology, V60, P293
   Wang RP, 2009, PROC CVPR IEEE, P429, DOI 10.1109/CVPRW.2009.5206850
   Wu YX, 2018, LECT NOTES COMPUT SC, V11217, P3, DOI 10.1007/978-3-030-01261-8_1
   Yang M, 2017, IMAGE VISION COMPUT, V58, P47, DOI 10.1016/j.imavis.2016.07.008
NR 30
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4023
EP 4036
DI 10.1007/s11042-020-09495-0
EA SEP 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572719800004
DA 2024-07-18
ER

PT J
AU Anbu, T
   Joe, MM
   Murugeswari, G
AF Anbu, T.
   Joe, M. Milton
   Murugeswari, G.
TI A comprehensive survey of detecting tampered images and localization of
   the tampered region
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tampered Image Detection; Tampered Region Localization; Copy-Move
   Forgery Detection; Fake Colorized Forgery Detection
ID COPY-MOVE FORGERY; WATERMARKING SCHEME; SCALE
AB Digital image fraudulent has become a very dangerous problem because of the rapidly growing media editing software. The information on the digital image can be easily replaced by fake information. Several cybercrime activities are attempted by hacking the digital images. Due to the presence of various kinds of media editing software, the digital image authenticity is very much significant. Nowadays, the detection of the manipulated images and localization of the manipulated regions are important issues. Many efforts have been made over the past decade to detect the tampered images and localization of the tampered regions with high accuracy based on some specially designed mechanisms. This paper presents a detailed survey of existing approaches for detecting tampered images and localization of the tampered regions.
C1 [Anbu, T.; Murugeswari, G.] Manonmaniam Sundaranar Univ, Dept Comp Sci & Engn, Tirunelveli, Tamil Nadu, India.
   [Joe, M. Milton] Nagercoil Manonmaniam Sundaranar Univ, St Jeromes Coll, Dept Comp Sci, Tirunelveli, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University; Manonmaniam Sundaranar University
RP Anbu, T (corresponding author), Manonmaniam Sundaranar Univ, Dept Comp Sci & Engn, Tirunelveli, Tamil Nadu, India.
EM tl.anbuja@gmail.com; m.miltonjoe@gmail.com; gmurugeswari@msuniv.ac.in
RI Joe, Milton/K-5889-2015
OI Joe, Milton/0000-0002-2626-3023
CR Ahmed B, 2020, SIGNAL IMAGE VIDEO P, V14, P1035, DOI 10.1007/s11760-020-01636-0
   Alahmadi A, 2017, SIGNAL IMAGE VIDEO P, V11, P81, DOI 10.1007/s11760-016-0899-0
   Alahmadi AA, 2013, IEEE GLOB CONF SIG, P253, DOI 10.1109/GlobalSIP.2013.6736863
   Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Ardizzone E, 2010, IEEE IMAGE PROC, P2117, DOI 10.1109/ICIP.2010.5652490
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   Bilmes, 1997, TR97021 ICSI
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen HP, 2020, IEEE ACCESS, V8, P36863, DOI 10.1109/ACCESS.2020.2974804
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cozzolino D, 2014, IEEE IMAGE PROC, P5302, DOI 10.1109/ICIP.2014.7026073
   DI H, 2011, SYSTEMS MAN CYBERN C, V41, P765
   Gaborini L, 2014, IEEE INT WORKS INFOR, P125, DOI 10.1109/WIFS.2014.7084315
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guo YF, 2018, IEEE T INF FOREN SEC, V13, P1932, DOI 10.1109/TIFS.2018.2806926
   Hashmi MF, 2014, AASRI PROC, V9, P84, DOI 10.1016/j.aasri.2014.09.015
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hinton G. E., 2012, 12070580 ARXIV
   Hu WC, 2016, MULTIMED TOOLS APPL, V75, P3495, DOI 10.1007/s11042-015-2449-0
   Hussain M., 2011, Proceedings of the 2011 Eighth International Conference on Computer Graphics, Imaging and Visualization (CGIV 2011), P145, DOI 10.1109/CGIV.2011.31
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Kim C, 2018, PERS UBIQUIT COMPUT, V22, P11, DOI 10.1007/s00779-017-1061-x
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kohale T, 2015, INT J ADV RES COMPUT, V4
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M, 2019, AUST J FORENSIC SCI, V51, P243, DOI 10.1080/00450618.2017.1356871
   Kumar S, 2017, J STAT MANAG SYST, V20, P611, DOI 10.1080/09720510.2017.1395181
   Laouamer L, 2018, IEEE ACCESS, V6, P26144, DOI 10.1109/ACCESS.2018.2831599
   LEE BB, 1990, J OPT SOC AM A, V7, P2223, DOI 10.1364/JOSAA.7.002223
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li HD, 2017, IEEE T INF FOREN SEC, V12, P1240, DOI 10.1109/TIFS.2017.2656823
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li YM, 2019, IEEE T INF FOREN SEC, V14, P1307, DOI 10.1109/TIFS.2018.2876837
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Meenakshi Sundaram, INT J RES ENG TECHNO
   Meenakshi Sundaram A, 2017, COMP SCI LIN C
   Neubert T, 2017, FACE MORPHING DETECT
   Obara Y, 2017, ELECTR COMMUN JPN, V100, P13, DOI 10.1002/ecj.11973
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Prakash CS, 2018, COGENT ENG, V5, DOI 10.1080/23311916.2018.1523346
   Rao Y, 2016, IEEE INT WORKS INFOR
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Saleh SQ, 2013, LECT NOTES COMPUT SC, V8034, P416, DOI 10.1007/978-3-642-41939-3_40
   Seibold C., 2017, IWDW 2017
   Shi ZN, 2018, IEEE ACCESS, V6, P76437, DOI 10.1109/ACCESS.2018.2883588
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Su BN, 2012, 2012 INTERNATIONAL CONFERENCE ON INDUSTRIAL CONTROL AND ELECTRONICS ENGINEERING (ICICEE), P1773, DOI 10.1109/ICICEE.2012.469
   Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41
   Wu ML, 2017, APPL INTELL, V47, P347, DOI 10.1007/s10489-017-0893-4
   YAN YY, 2017, PROC CVPR IEEE, P6978, DOI DOI 10.1109/CVPR.2017.738
   Zhang GC, 2004, LECT NOTES COMPUT SC, V3338, P179
   Zhang Y., 2012, Communications, P181, DOI DOI 10.1007/978-1-4614-5803-6_19
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
   Zhang YB, 2020, MIN PROC EXT MET REV, V41, P75, DOI 10.1080/08827508.2018.1538986
NR 63
TC 5
Z9 5
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2713
EP 2751
DI 10.1007/s11042-020-09585-z
EA SEP 2020
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570032000002
DA 2024-07-18
ER

PT J
AU Chen, TH
   Chang, TC
   Zhu, TL
AF Chen, Tzung-Her
   Chang, Tzu-Ching
   Zhu, Ting-Le
TI Security-enhanced cloud-based image secret sharing and authentication
   using POB number system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret sharing; Image authentication; POB number system; False negative
ID DIGITAL WATERMARKING METHOD; CONTENT INTEGRITY; TAMPER DETECTION;
   ENCRYPTION
AB Recently, the image secret sharing technique based on POB (Permutation Ordered Binary) number systems has drawn attention in academia. Thanks to Singh et al.'s pioneer in combining image confidentiality and authentication to form a cloud-based image cryptosystem using the POB number system. However, for image confidentiality and integrity, there are always two main concerns of a new image cryptosystem: the protection from unauthorized disclosure and the sensitivity of tampering. To claim confidentiality and integrity guaranty of secure image cryptosystems is meaningful only when the cryptanalysis is taken into consideration. In this article, Singh et al.'s scheme has undergone the scrutiny and potential security weaknesses found. First, the secret image may leak under chosen-plain-image attacks. Second, the partial secret key deducible under cipher/share-image-only attacks is shown unneglectable. Precisely, it is potentially problematic since the security of image authentication only relies on the secrecy of the parameterrof POB number systems, but the parameter is also learned to know by a heuristic method. The main weak design has been shown by means of introducing theoretical analyses and conducting some counter experiments. As a result, in this study we have focused on proposing a security-enhanced POB-based image secret sharing scheme with five primary advantages: (1) high security to confidentiality, (2) lossless reconstructed secret image, (3) high security to integrity, (4) high detection accuracy, and (5) low time complexity. The experimental results and the further analysis demonstrate that the simple and secure improvement does work.
C1 [Chen, Tzung-Her; Chang, Tzu-Ching; Zhu, Ting-Le] Natl Chiayi Univ, Chiayi, Taiwan.
C3 National Chiayi University
RP Chen, TH (corresponding author), Natl Chiayi Univ, Chiayi, Taiwan.
EM thchen@mail.ncyu.edu.tw
OI Chen, Tzung-Her/0000-0001-5775-6034
FU Ministry of Science and Technology of Taiwan [MOST 107-2221-E-415 -001
   -MY3]
FX This work was supported in part by the Ministry of Science and
   Technology of Taiwan under grant MOST 107-2221-E-415 -001 -MY3.
CR Botta M, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2568224
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chang CC, 2008, PATTERN RECOGN, V41, P654, DOI 10.1016/j.patcog.2007.06.003
   Grangetto M, 2006, IEEE T MULTIMEDIA, V8, P905, DOI 10.1109/TMM.2006.879919
   Jakimoski G, 2008, IEEE T MULTIMEDIA, V10, P330, DOI 10.1109/TMM.2008.917355
   Lin PY, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000489
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Psannis Kostas E., 2019, IEEE Transactions on Sustainable Computing, V4, P77, DOI 10.1109/TSUSC.2018.2817043
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Singh P, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3077140
   Sreekumar A., 2009, Hack, V2009, P33
   Stergiou C., 2018, J MULTIMED INF SYST, V5, P1
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Wen JT, 2006, IEEE SIGNAL PROC LET, V13, P69, DOI 10.1109/LSP.2005.861589
   Wu CP, 2005, IEEE T MULTIMEDIA, V7, P828, DOI 10.1109/TMM.2005.854469
   Zhou JT, 2007, IEEE SIGNAL PROC LET, V14, P201, DOI 10.1109/LSP.2006.884012
NR 16
TC 5
Z9 5
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1901
EP 1924
DI 10.1007/s11042-020-09484-3
EA SEP 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568184100007
DA 2024-07-18
ER

PT J
AU Fang, T
   Zhang, MQ
   Fan, YL
   Wu, W
   Gan, HT
   She, QS
AF Fang, Tao
   Zhang, Mingqi
   Fan, Yingle
   Wu, Wei
   Gan, Haitao
   She, Qingshan
TI Developing a feature decoder network with low-to-high hierarchies to
   improve edge detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Edge detection; Convolutional features; Feature decoder; Gaussian blur
   label
AB Low-to-high hierarchical convolutional features can significantly improve edge detection. This paper proposes a feature decoder-based algorithm that employs a Feature Decoder Network (FDN) to extract more information within limited Convolutional Neural Network (CNN) features. Previous studies applied convolutional elements by weight fusion, but we measure a feature decoder as a pyramid by qualifying convolutional layers. The feature decoder fuses CNN features of adjacent layers to judge the edge and non-edge pixels, which can learn the relationship and distinction between low-level edge hierarchies and high-level semantic hierarchies. Furthermore, we use Gaussian blur labels to train the network to optimize network convergence and training. From the experimental results, our proposed algorithm performs better on the BSDS500 (average accuracy (AP) of 0.865) and NYUD (OIS F-measure of 0.775) datasets compared to the state-of-the-art algorithms, including RCF.
C1 [Fang, Tao; Zhang, Mingqi; Fan, Yingle; Wu, Wei; Gan, Haitao; She, Qingshan] Hangzhou Dianzi Univ, Lab Pattern Recognit & Image Proc, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University
RP Fan, YL (corresponding author), Hangzhou Dianzi Univ, Lab Pattern Recognit & Image Proc, Hangzhou 310018, Peoples R China.
EM fan@hdu.edu.cn
RI gan, haitao/JFA-9149-2023; fang, tao/IQU-3074-2023; gan,
   jerry/AFT-1901-2022
OI She, Qingshan/0000-0001-5206-9833
FU National Natural Science Foundation of China [61501154]
FX The work was supported in part by the National Natural Science
   Foundation of China (61501154). The authors would like to thank Yun Liu
   for his kind and help in the writing process.
CR [Anonymous], 2016, CVPR, DOI DOI 10.1109/CVPR.2016.28
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bertasius G, 2015, IEEE I CONF COMP VIS, P504, DOI 10.1109/ICCV.2015.65
   Bertasius G, 2015, PROC CVPR IEEE, P4380, DOI 10.1109/CVPR.2015.7299067
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng MM, 2016, LECT NOTES COMPUT SC, V9907, P867, DOI 10.1007/978-3-319-46487-9_53
   Chien Y, 1974, IEEE T AUTOMAT CONTR, V19, P462, DOI [10.1109/TAC.1974.1100577, DOI 10.1109/TAC.1974.1100577]
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dollar P., 2006, 2006 IEEE COMP SOC C, V2, P1964, DOI DOI 10.1109/CVPR.2006.298
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Fang T, 2020, SIGNAL IMAGE VIDEO P, V14, P1461, DOI 10.1007/s11760-020-01689-1
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   Ganin Y, 2015, LECT NOTES COMPUT SC, V9004, P536, DOI 10.1007/978-3-319-16808-1_36
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79
   Hallman S, 2015, PROC CVPR IEEE, P1732, DOI 10.1109/CVPR.2015.7298782
   He JZ, 2019, PROC CVPR IEEE, P3823, DOI 10.1109/CVPR.2019.00395
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maninis KK, 2016, LECT NOTES COMPUT SC, V9905, P580, DOI 10.1007/978-3-319-46448-0_35
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   POMA XS, 2020, P IEEE CVF WINT C AP, P1923, DOI [DOI 10.1109/WACV45572.2020.9093290, 10.1109/wacv45572.2020.9093290]
   Ren X, 2012, ADV NEURAL INFORM PR, P584, DOI DOI 10.1634/THEONCOLOGIST.8-3-252
   Ren ZL, 2013, PROC CVPR IEEE, P2011, DOI 10.1109/CVPR.2013.262
   Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sobel I, 1972, THESIS
   Tang PJ, 2017, NEUROCOMPUTING, V225, P188, DOI 10.1016/j.neucom.2016.11.023
   Wang XY, 2018, MACH VISION APPL, V29, P677, DOI 10.1007/s00138-018-0927-x
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu D, 2017, ADV NEUR IN, V30
   Yang JM, 2017, IEEE T PATTERN ANAL, V39, P576, DOI 10.1109/TPAMI.2016.2547384
   Yang KF, 2014, IEEE T IMAGE PROCESS, V23, P5020, DOI 10.1109/TIP.2014.2361210
NR 41
TC 6
Z9 6
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1611
EP 1624
DI 10.1007/s11042-020-09800-x
EA SEP 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000568765600006
DA 2024-07-18
ER

PT J
AU Shu, ZQ
   Wu, XJ
   Hu, C
   You, CZ
   Fan, HH
AF Shu, Zhen-qiu
   Wu, Xiao-jun
   Hu, Cong
   You, Cong-zhe
   Fan, Hong-hui
TI Deep semi-nonnegative matrix factorization with elastic preserving for
   data representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep matrix factorization; Geometric structure; Elasticity; High
   dimensional data; Clustering
ID RECOGNITION
AB Deep matrix factorization methods can automatically learn the hidden representation of high dimensional data. However, they neglect the intrinsic geometric structure information of data. In this paper, we propose a Deep Semi-Nonnegative Matrix Factorization with Elastic Preserving (Deep Semi-NMF-EP) method by adding two graph regularizers in each layer. Therefore, the proposed Deep Semi-NMF-EP method effectively preserves the elasticity of data and thus can learn a better representation of high-dimensional data. In addition, we present an effective algorithm to optimize the proposed model and then provide its complexity analysis. The experimental results on the benchmark datasets show the excellent performance of our proposed method compared with other state-of-the-art methods.
C1 [Shu, Zhen-qiu; You, Cong-zhe; Fan, Hong-hui] Jiangsu Univ Technol, Sch Comp Engn, Changzhou, Jiangsu, Peoples R China.
   [Shu, Zhen-qiu; Wu, Xiao-jun; Hu, Cong] Jiangnan Univ, Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi, Jiangsu, Peoples R China.
C3 Jiangsu University of Technology; Jiangnan University
RP Shu, ZQ (corresponding author), Jiangsu Univ Technol, Sch Comp Engn, Changzhou, Jiangsu, Peoples R China.; Shu, ZQ (corresponding author), Jiangnan Univ, Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi, Jiangsu, Peoples R China.
EM shuzhenqiu@126.com
FU National Natural Science Foundation of China [61603159, 61672265];
   Natural Science Foundation of Jiangsu Province [BK20160293]; China
   Postdoctoral Science Foundation [2017 M611695]; Jiangsu Province
   Postdoctoral Science Foundation [1701094B]
FX This work was supported by the National Natural Science Foundation of
   China [Grant No. 61603159, 61672265], Natural Science Foundation of
   Jiangsu Province [Grant No. BK20160293], China Postdoctoral Science
   Foundation [Grant No. 2017 M611695] and Jiangsu Province Postdoctoral
   Science Foundation [Grant No. 1701094B].
CR [Anonymous], 2012, P 25 IEEE CAN C EL C
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Carreira-Perpinan MA, 2010, ICML 10, P167
   Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277
   Gu Q., 2009, P 21 INT JOINT C ART
   Guo WW, 2013, IEEE IMAGE PROC, P2743, DOI 10.1109/ICIP.2013.6738565
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Leng L, 2012, IEEE INT C WAV AN PA
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li G., 2016, NEUROCOMPUTING, V237, P1
   Li ZC, 2013, COMPUT VIS IMAGE UND, V117, P1175, DOI 10.1016/j.cviu.2013.04.003
   Liu HF, 2014, IEEE T CYBERNETICS, V44, P1214, DOI 10.1109/TCYB.2013.2287103
   Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217
   Liu Y, 2016, NEUROCOMPUTING, V173, P224, DOI 10.1016/j.neucom.2014.11.099
   Shu ZQ, 2017, IET IMAGE PROCESS, V11, P370, DOI 10.1049/iet-ipr.2016.0391
   Shu ZQ, 2016, NEUROCOMPUTING, V175, P188, DOI 10.1016/j.neucom.2015.10.048
   Shu ZQ, 2015, NEUROCOMPUTING, V158, P1, DOI 10.1016/j.neucom.2015.02.014
   Trigeorgis G, 2017, IEEE T PATTERN ANAL, V39, P417, DOI 10.1109/TPAMI.2016.2554555
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang YX, 2013, IEEE T KNOWL DATA EN, V25, P1336, DOI 10.1109/TKDE.2012.51
   Wang ZS, 2020, IEEE ACCESS, V8, P71353, DOI 10.1109/ACCESS.2020.2986267
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Zhao HD, 2017, AAAI CONF ARTIF INTE, P2921
NR 25
TC 9
Z9 9
U1 5
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1707
EP 1724
DI 10.1007/s11042-020-09766-w
EA SEP 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568765600001
DA 2024-07-18
ER

PT J
AU Cheng, JM
   Liang, RY
   Zhao, L
AF Cheng, Jiaming
   Liang, Ruiyu
   Zhao, Li
TI DNN-based speech enhancement with self-attention on feature dimension
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech enhancement; Deep neural network; Feature fusion; Self-attention
ID NOISE; REPRESENTATIONS; RECOGNITION; ALGORITHM
AB To make full use of the key information in frame-level features, a DNN-based model for speech enhancement is proposed using self-attention on the feature dimension. Two improvement strategies are adopted to strengthen the attention of the fully connected layers to the effective information in the features. First, the model introduces the fusion of feature domains on the input features, using a 136-dimensional combination of features including the MFCC, AMS, RASTA-PLP, cochleagram, and PNCC. The fusion of features complements information from different domains, including the mel domain and gammatone domain, thus providing more effective information for self-attention. Second, a feature-level self-attention mechanism is applied to the output of the fully connected layer to obtain the information related to the task. The feature-level attention enables the fully connected layers to capture the internal correlations between different features and to reduce the redundancy brought by multiple features. The experimental results show that under the matched noisy condition, compared to the noisy signals, the proposed algorithm increased the PESQ, fwsegSNR and STOI by 40.92%, 60.2% and 8.31%, respectively, and by 23.64%, 32.55% and 3.4%, respectively, under the mismatched noisy condition. Comparisons between different neural networks indicate that the proposed algorithm is superior to the compared algorithms in both the matched and mismatched situations using fewer context frames. Therefore, the proposed model can effectively utilize the key information of the features to suppress the noise, thereby improving the speech quality and generalizing the mismatched samples.
C1 [Cheng, Jiaming; Zhao, Li] Southeast Univ, Sch Informat Sci & Engn, Nanjing 211189, Peoples R China.
   [Liang, Ruiyu] Nanjing Inst Technol, Sch Commun Engn, Nanjing 211167, Peoples R China.
C3 Southeast University - China; Nanjing Institute of Technology
RP Cheng, JM (corresponding author), Southeast Univ, Sch Informat Sci & Engn, Nanjing 211189, Peoples R China.
EM 230198469@seu.edu.cn; liangry@njit.edu.cn; zhaoli@seu.edu.cn
OI cheng, jiaming/0000-0002-7136-7876
FU National Key Research and Development Program of China [2020YFC2004002,
   2020YFC2004003]; National Natural Science Foundation of China [61871213,
   61673108, 61571106]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2020YFC2004002, Grant
   2020YFC2004003 and in part by the National Natural Science Foundation of
   China under Grant 61871213, Grant 61673108 and Grant 61571106.
CR [Anonymous], 2004, 100 NONSPEECH ENV SO
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
   Cohen I, 2003, IEEE T SPEECH AUDI P, V11, P466, DOI 10.1109/TSA.2003.811544
   Cohen I, 2001, SIGNAL PROCESS, V81, P2403, DOI 10.1016/S0165-1684(01)00128-1
   Du J, 2017, PATTERN RECOGN, V63, P149, DOI 10.1016/j.patcog.2016.10.003
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453
   Erdogan H, 2015, INT CONF ACOUST SPEE, P708, DOI 10.1109/ICASSP.2015.7178061
   Garau G, 2008, IEEE T AUDIO SPEECH, V16, P508, DOI 10.1109/TASL.2008.916519
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Healy EW, 2013, J ACOUST SOC AM, V134, P3029, DOI 10.1121/1.4820893
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   Kang TG, 2018, DIGIT SIGNAL PROCESS, V74, P102, DOI 10.1016/j.dsp.2017.12.002
   Kim C, 2016, IEEE-ACM T AUDIO SPE, V24, P1315, DOI 10.1109/TASLP.2016.2545928
   Liang RY, 2020, IEEE ACCESS, V8, P48464, DOI 10.1109/ACCESS.2020.2979554
   LIM JS, 1978, IEEE T ACOUST SPEECH, V26, P197, DOI 10.1109/TASSP.1978.1163086
   Lin Zhouhan, 2017, A structured self-attentive sentence embedding
   Loizou P. C., 2007, Speech Enhancement: Theory and Practice
   Luong M.-T., 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1166
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493
   Park SR, 2017, INTERSPEECH, P1993, DOI 10.21437/Interspeech.2017-1465
   Pascual S, 2017, INTERSPEECH, P3642, DOI 10.21437/Interspeech.2017-1428
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Shao Y, 2009, INT CONF ACOUST SPEE, P4625, DOI 10.1109/ICASSP.2009.4960661
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881
   Tan K, 2019, IEEE-ACM T AUDIO SPE, V27, P189, DOI 10.1109/TASLP.2018.2876171
   Valin JM, 2018, IEEE INT WORKSH MULT
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Veaux C, 2013, INT CONF SPEECH DATA
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   Wang YX, 2014, IEEE-ACM T AUDIO SPE, V22, P1849, DOI 10.1109/TASLP.2014.2352935
   Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P1381, DOI 10.1109/TASL.2013.2250961
   Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P270, DOI 10.1109/TASL.2012.2221459
   Williamson DS, 2016, INT CONF ACOUST SPEE, P5220, DOI 10.1109/ICASSP.2016.7472673
   Xu Y, 2015, IEEE-ACM T AUDIO SPE, V23, P7, DOI 10.1109/TASLP.2014.2364452
   Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240
   Xu Z., 2018, ARXIV181011217
NR 39
TC 8
Z9 8
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32449
EP 32470
DI 10.1007/s11042-020-09345-z
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562943200001
DA 2024-07-18
ER

PT J
AU Kaur, N
   Jindal, N
   Singh, K
AF Kaur, Navneet
   Jindal, Neeru
   Singh, Kulbir
TI A passive approach for the detection of splicing forgery in digital
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Accuracy; Discrete wavelet transform; Local binary pattern; Markov
   features; Splicing forgery
ID MARKOV FEATURES; COPY-MOVE; TRANSFORM; DWT; DCT; LBP
AB With the technology progress, a plethora of freely accessible software has questioned the authenticity of digital images. This field is continuously creating challenges for researchers to ascertain the integrity of images. Hence, there is a need to improve the performance of forgery detection algorithms from time to time. This paper is focused on the detection of splicing forgery because it is one of the most frequently used image manipulation techniques. In the proposed scheme, Markov features in both Discrete Wavelet Transform (DWT) and Local Binary Pattern (LBP) domains are extracted and combined for the detection of image splicing. Three-level DWT is applied to the source image by the means of discrete Haar wavelet. The image is split in to high and low-frequency sub-bands after applying one level DWT. Furthermore, low-frequency sub-band is decomposed twice to obtain three-level DWT, which leads to more information and less amount of noise. The efficacy of the proposed scheme has been appraised on six benchmark datasets i.e. CASIA v2.0, DVMM, IFS-TC, CASIA v1.0, Columbia, and DSO-1. Moreover, the SVM classifier is trained to classify the images as tampered or authentic. The effectiveness of the proposed scheme is evaluated based on various performance parameters such as accuracy, sensitivity, specificity, and informedness. The proposed results show improved accuracy i.e. 99.69%, 99.76%, 97.80%, 98.61%, 96.90%, and 92.50% on CASIA v1.0, CASIA v2.0, DVMM, Columbia, IFS-TC, and DSO-1, respectively, in comparison to other existing approaches.
C1 [Kaur, Navneet; Jindal, Neeru; Singh, Kulbir] Thapar Inst Engn & Technol, Elect & Commun Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, K (corresponding author), Thapar Inst Engn & Technol, Elect & Commun Engn Dept, Patiala, Punjab, India.
EM navneetbrar5@gmail.com; neeru.jindal@thapar.edu; ksingh@thapar.edu
RI Singh, Kulbir/T-7453-2019; KAUR, NAVNEET/HMP-0723-2023
OI Singh, Kulbir/0000-0001-8070-3395; , Navneet Kaur/0000-0001-9575-2982
CR Abdallah Emad E., 2007, Proceedings Graphics Interface 2007, P327, DOI 10.1145/1268517.1268570
   Abdallah EE, 2019, J APPL SEC RES, V1, P1
   Abdallah EE, 2009, SIGNAL IMAGE VIDEO P, V3, P375, DOI 10.1007/s11760-008-0079-y
   Abdallah EE, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2764466
   Agarwal S, 2016, INT CONF CONTEMP, P178
   Agarwal S, 2016, 2016 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE & COMMUNICATION TECHNOLOGY (CICT), P116, DOI 10.1109/CICT.2016.31
   Alahmadi A, 2017, SIGNAL IMAGE VIDEO P, V11, P81, DOI 10.1007/s11760-016-0899-0
   Alahmadi AA, 2013, IEEE GLOB CONF SIG, P253, DOI 10.1109/GlobalSIP.2013.6736863
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   Cozzolino D, 2014, IEEE IMAGE PROC, P5302, DOI 10.1109/ICIP.2014.7026073
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Dong J, 2009, LECT NOTES COMPUT SC, V5450, P76, DOI 10.1007/978-3-642-04438-0_7
   El-Alfy ESM, 2017, MULTIMED TOOLS APPL, V76, P14535, DOI 10.1007/s11042-016-3855-7
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   Fan JY, 2017, MULTIDIM SYST SIGN P, V28, P795, DOI 10.1007/s11045-015-0377-9
   Hakimi F, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P1074, DOI 10.1109/KBEI.2015.7436195
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Hussain M, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA 2014), P197, DOI 10.1109/INISTA.2014.6873618
   Jalab HA, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21040371
   Jayasudha A., 2016, INT J ADV SIGNAL IMA, V2, P24, DOI [10.29284/ijasis.2.1.2016.24-30, DOI 10.29284/IJASIS.2.1.2016.24-30]
   Kanwal N, 2020, MULTIMED TOOLS APPL, V79, P12829, DOI 10.1007/s11042-020-08621-2
   Kaur M, 2016, COMM COM INF SC, V625, P318, DOI 10.1007/978-981-10-2738-3_27
   Kirchner M, 2010, PROC SPIE, V7541, DOI 10.1117/12.839100
   Kumar A, 2019, ADV INTELL SYST, V670, P17, DOI 10.1007/978-981-10-8971-8_2
   Kumar V., 2012, International Journal of Emerging Technology and Advanced Engineering, V2, P56, DOI 10.1070/pu1997v040n05abeh000236.www.ijetae.com
   Li C, 2017, NEUROCOMPUTING, V228, P29, DOI 10.1016/j.neucom.2016.04.068
   Mayer O, 2018, IEEE T INF FOREN SEC, V13, P1762, DOI 10.1109/TIFS.2018.2799421
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Muqeet Mohd Abdul, 2019, Applied Computing and Informatics, V15, P163, DOI 10.1016/j.aci.2017.11.002
   Ng T.T., 2004, ADVENT Technical Report
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Prakash CS, 2018, MULTIMED TOOLS APPL, V77, P26939, DOI 10.1007/s11042-018-5899-3
   Roy A, 2018, INT C PATT RECOG, P2552, DOI 10.1109/ICPR.2018.8545527
   Sheng HD, 2018, IET IMAGE PROCESS, V12, P1815, DOI 10.1049/iet-ipr.2017.1131
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Srivastava P, 2017, J VIS COMMUN IMAGE R, V42, P78, DOI 10.1016/j.jvcir.2016.11.008
   Su B, 2014, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2014-7
   Sun Xiao-wei, 2008, Electronics Optics & Control, V15, P32
   Sutthiwan P, 2010, IEEE INT CON MULTI, P1463, DOI 10.1109/ICME.2010.5583264
   Vaishnavi D, 2016, 2016 3RD MEC INTERNATIONAL CONFERENCE ON BIG DATA AND SMART CITY (ICBDSC), P53
   Xu XK, 2013, IEEE IMAGE PROC, P4422, DOI 10.1109/ICIP.2013.6738911
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Yu HP, 2016, J ADV MECH DES SYST, V10, DOI 10.1299/jamdsm.2016jamdsm0100
   Zhang H, 2017, J INF PROCESS SYST, V13, P385, DOI 10.3745/JIPS.03.0070
   Zhang QB, 2018, MULTIMED TOOLS APPL, V77, P31239, DOI 10.1007/s11042-018-6230-z
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhang Y., 2012, Communications, P181, DOI DOI 10.1007/978-1-4614-5803-6_19
   Zhang Z, 2018, J INF PROCESS SYST, V14, P6
   Zhao XD, 2015, IEEE T CIRC SYST VID, V25, P185, DOI 10.1109/TCSVT.2014.2347513
NR 53
TC 11
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32037
EP 32063
DI 10.1007/s11042-020-09275-w
EA AUG 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562697400004
DA 2024-07-18
ER

PT J
AU Zhang, B
   Rahmatullah, B
   Wang, SL
   Zaidan, AA
   Zaidan, BB
   Liu, PH
AF Zhang, Bin
   Rahmatullah, Bahbibi
   Wang, Shir Li
   Zaidan, A. A.
   Zaidan, B. B.
   Liu, Penghui
TI A review of research on medical image confidentiality related technology
   coherent taxonomy, motivations, open challenges and recommendations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Medical image; Digital imaging and Communications in Medicine (DICOM);
   Confidentiality; Encryption; Security
ID ENCRYPTION ALGORITHM; SECURED TRANSMISSION; VISUAL CRYPTOGRAPHY; GENETIC
   ALGORITHM; SCHEME; CHAOS; WATERMARKING; EFFICIENT; COMPRESSION;
   INFORMATION
AB With the modernization of biomedical image equipment and image processing technology, the amount of medical image data increases rapidly. These medical images need to be transmitted over a public network between doctors or hospitals to provide telemedicine services and sometimes need to be uploaded to a telemedicine data center or health cloud due to limited local computing and storage resources. Medical images involve confidential and sensitive information of patients, and the confidentiality technology to protect patient privacy is becoming more and more important. These problems have been studied by many scholars, but these studies are largely limited and scattered. To the authors' knowledge, there is no systematic literature review related to medical image confidentiality technology. To provide valuable insights into the technical environment and to support researchers, the available options and gaps in this research area must be understood. Therefore, in this study, the recent 5 years' research results in the field of medical image security are reviewed to map the field of study into a coherent taxonomy. We use five major academic databases which are (1) Medline, (2) IEEE Xplore, (3) WoS, (4) Scopus, and (5) ScienceDirect, and every literature related to (1) medical images, and (2) encryption were searched with a focus in these databases. These databases contain literature about medical image confidentiality technology. According to the classification scheme, the final data set consists of 123 pieces of literature, and are divided into five categories. The first category, which also occupies the most proportion, focuses on medical image confidentiality algorithms, and most of them adopt chaotic mapping correlative technology The second category considers multiple security requirements while studying medical image confidentiality. The third category combines medical image encryption and image compression technologies. The fourth category focuses on the hardware related medical image confidentiality design. The final category is the medical image security systems design. We then identify the basic characteristics of this emerging field from the following aspects; the motivations of using medical image confidentiality technology, the challenges of medical image confidentiality technology, and the recommendations for further research and use of medical image confidentiality technologies. Finally, the quality evaluation criteria of the medical image security algorithm are summarized, including but not limited to the evaluation of security and the evaluation of speed and time complexity. The results of the reference evaluation show that most studies on medical image security algorithms lack sufficient safety evaluation. This was evident from less than 30% of the total articles that used all kinds of security evaluation methods.
C1 [Zhang, Bin; Liu, Penghui] Baoji Univ Arts & Sci, Sch Comp Sci, Baoji 721016, Shaanxi, Peoples R China.
   [Zhang, Bin; Rahmatullah, Bahbibi; Wang, Shir Li; Zaidan, A. A.; Zaidan, B. B.] Sultan Idris Educ Univ UPSI, Fac Arts Comp & Creat Ind, Comp Dept, Tanjong Malim 35900, Perak, Malaysia.
C3 Baoji University of Arts & Sciences; Universiti Pendidikan Sultan Idris
RP Rahmatullah, B (corresponding author), Sultan Idris Educ Univ UPSI, Fac Arts Comp & Creat Ind, Comp Dept, Tanjong Malim 35900, Perak, Malaysia.
EM bahbibi@fskik.upsi.edu.my
RI zaidan, bilal/AAJ-7841-2021; Rahmatullah, Bahbibi/B-3327-2015; Wang,
   Shir Li/AAC-2405-2021; Albahri,, A. S./F-7289-2010
OI Wang, Shir Li/0000-0003-4417-3213; Bin, Zhang/0000-0003-1611-6967;
   zaidan, bilal/0000-0001-7412-8267
FU project of Baoji University of Arts and Sciences [ZK2017012]
FX This paper was supported by the project of Baoji University of Arts and
   Sciences. (Grant No. ZK2017012).
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P1073, DOI 10.1109/ACCESS.2017.2777869
   Abdmouleh MK, 2017, PROCEDIA COMPUT SCI, V112, P369, DOI 10.1016/j.procs.2017.08.026
   Adeshina AM, 2017, INTERDISCIP SCI, V9, P140, DOI 10.1007/s12539-015-0140-9
   Ajili S, 2016, INT J SIGNAL IMAGING, V9, P242, DOI 10.1504/IJSISE.2016.078269
   Al-Haj A, 2015, IET INFORM SECUR, V9, P365, DOI 10.1049/iet-ifs.2014.0245
   Al-Haj A, 2015, J DIGIT IMAGING, V28, P179, DOI 10.1007/s10278-014-9734-8
   Alaa M, 2017, J NETW COMPUT APPL, V97, P48, DOI 10.1016/j.jnca.2017.08.017
   Alloghani M, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102362
   AlShaikh M, 2017, MULTIMED TOOLS APPL, V76, P8937, DOI 10.1007/s11042-016-3499-7
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Amina Souyah, 2018, Communications in Nonlinear Science and Numerical Simulation, V60, P12, DOI 10.1016/j.cnsns.2017.12.017
   Anusudha K, 2017, MULTIMED TOOLS APPL, V76, P2911, DOI 10.1007/s11042-015-3213-1
   Arumugham S, 2019, ARAB J SCI ENG, V44, P9561, DOI 10.1007/s13369-019-03883-x
   Arumugham S, 2018, J BIOMED INFORM, V86, P90, DOI 10.1016/j.jbi.2018.08.010
   Arunkumar S, 2019, MEASUREMENT, V139, P426, DOI 10.1016/j.measurement.2019.02.069
   Avudaiappan T, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1053-z
   Badr AM, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020171
   Bakshi A, 2018, INT J ADV SCI TECHNO, V117, P11, DOI [10.14257/ijast.2018.117.02, DOI 10.14257/IJAST.2018.117.02]
   Bakshi A, 2019, J INF SECUR APPL, V46, P281, DOI 10.1016/j.jisa.2019.03.004
   BALA BK, 2017, BIOMED PHARMACOL J, V10, P1793, DOI DOI 10.13005/bpj/1294
   Banik A, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102398
   Begum AAS, 2018, MULTIMED TOOLS APPL, V77, P27041, DOI 10.1007/s11042-018-5903-y
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Ben Farah MA, 2020, MULTIMED TOOLS APPL, V79, P19129, DOI 10.1007/s11042-020-08718-8
   Bhardwaj R, 2019, OPTIK, V181, P1099, DOI 10.1016/j.ijleo.2018.12.130
   Borra S, 2020, COMP M BIO BIO E-IV, V8, P345, DOI 10.1080/21681163.2019.1595730
   Bouslimi D, 2016, SIGNAL PROCESS-IMAGE, V47, P160, DOI 10.1016/j.image.2016.05.021
   Boussif M, 2017, INT J ELECTR COMPUT, V7, P3385, DOI DOI 10.11591/IJECE.V7I6
   Boussif M, 2018, IET NETW, V7, P294, DOI 10.1049/iet-net.2017.0180
   Boussif M, 2017, IET IMAGE PROCESS, V11, P1020, DOI 10.1049/iet-ipr.2017.0229
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chandrasekaran J, 2017, SECUR COMMUN NETW, P1, DOI 10.1155/2017/6729896
   Chen JX, 2015, COMMUN NONLINEAR SCI, V23, P294, DOI 10.1016/j.cnsns.2014.11.021
   Chen JX, 2019, NONLINEAR DYNAM, V96, P301, DOI 10.1007/s11071-019-04791-3
   Chen L, 2015, COMPUT BIOL MED, V65, P69, DOI 10.1016/j.compbiomed.2015.07.024
   Chen LF, 2015, OPT COMMUN, V338, P110, DOI 10.1016/j.optcom.2014.10.036
   Chen X, 2017, SAUDI J BIOL SCI, V24, P1821, DOI 10.1016/j.sjbs.2017.11.023
   Chen YC, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107286
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   Dagadu JC, 2018, MULTIMED TOOLS APPL, V77, P24289, DOI 10.1007/s11042-018-5725-y
   Dai Y, 2016, INT J SIMULATION SYS, V17, DOI [10.5013/IJSSST.a.17.27.24, DOI 10.5013/IJSSST.A.17.27.24]
   Dai Y, 2016, TECHNOL HEALTH CARE, V24, pS435, DOI 10.3233/THC-161166
   Dai Y, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416570019
   Devi RS, 2019, INT J THEOR PHYS, V58, P1937, DOI 10.1007/s10773-019-04088-6
   Dong JT, 2016, SMART INNOV SYST TEC, V60, P197, DOI 10.1007/978-3-319-39687-3_19
   Dorgham O, 2018, INT J CLOUD APPL COM, V8, P154, DOI 10.4018/IJCAC.2018010108
   Dridi M, 2016, IET IMAGE PROCESS, V10, P830, DOI 10.1049/iet-ipr.2015.0868
   Dzwonkowski M, 2019, IEEE T IMAGE PROCESS, V28, P371, DOI 10.1109/TIP.2018.2868388
   Dzwonkowski M, 2015, IEEE T IMAGE PROCESS, V24, P4614, DOI 10.1109/TIP.2015.2467317
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Gupta Ranu, 2018, Molecular & Cellular Biomechanics, V15, P63, DOI 10.3970/mcb.2018.00114
   Hajjaji MA, 2019, MULTIMED TOOLS APPL, V78, P14379, DOI 10.1007/s11042-018-6795-6
   Hamza R, 2020, INFORM SCIENCES, V527, P493, DOI 10.1016/j.ins.2019.01.070
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Hyma J., 2016, INT J APPL ENG RES, V11, P7509
   Ismail SM, 2018, J ADV RES, V10, P85, DOI 10.1016/j.jare.2018.01.009
   ISO I, 2016, 277992016EN ISOI
   Jain M, 2017, INT J MACH LEARN CYB, V8, P1695, DOI 10.1007/s13042-016-0542-y
   Kanso A, 2018, J VIS COMMUN IMAGE R, V56, P245, DOI 10.1016/j.jvcir.2018.09.018
   Kanso A, 2015, COMMUN NONLINEAR SCI, V24, P98, DOI 10.1016/j.cnsns.2014.12.005
   Ke G, 2019, MEASUREMENT, V135, P385, DOI 10.1016/j.measurement.2018.11.074
   Kester QA, 2015, PROCEDIA COMPUT SCI, V58, P538, DOI 10.1016/j.procs.2015.08.070
   Khond S., 2019, INT J ENG ADV TECHNO, V8, P1062, DOI [10.35940/ijeat.F1202.0886S19, DOI 10.35940/IJEAT.F1202.0886S19]
   Koppu S, 2017, INT J INTELL ENG SYS, V10, P104, DOI [10.22266/ijies2017.0228.12, DOI 10.22266/IJIES2017.0228.12]
   Koppu S, 2018, EVOL INTELL, V11, P53, DOI 10.1007/s12065-018-0159-z
   Kumar C. V, 2015, APPL MATH SCI, V9, P2381, DOI DOI 10.12988/AMS.2015.53219
   Kumar RM, 2018, BIOMED RES, DOI [10.4066/biomedicalresearch.29-17-1317, DOI 10.4066/BIOMEDICALRESEARCH.29-17-1317]
   Kumar S, 2018, PROCEDIA COMPUT SCI, V143, P804, DOI 10.1016/j.procs.2018.10.386
   Kumari A, 2018, BIOMED PHARMACOL J, V11, P897, DOI [10.13005/bpj/1446, DOI 10.13005/bpj/1446]
   Laiphrakpam DS, 2017, OPTIK, V147, P88, DOI 10.1016/j.ijleo.2017.08.028
   Lakshmi C, 2018, COMPUT METH PROG BIO, V159, P11, DOI 10.1016/j.cmpb.2018.02.021
   Li X, 2016, OPTIK, V127, P2558, DOI 10.1016/j.ijleo.2015.11.221
   Li-bo Zhang, 2015, Mathematical Problems in Engineering, V2015, DOI 10.1155/2015/940638
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Lima JB, 2015, SIGNAL PROCESS-IMAGE, V35, P1, DOI 10.1016/j.image.2015.03.005
   Liu HJ, 2019, OPT LASER ENG, V122, P123, DOI 10.1016/j.optlaseng.2019.05.027
   Liu HJ, 2016, OPTIK, V127, P5812, DOI 10.1016/j.ijleo.2016.04.014
   Liu JZ, 2018, MULTIMED TOOLS APPL, V77, P22787, DOI 10.1007/s11042-017-5534-8
   Liu XB, 2016, OPT COMMUN, V366, P22, DOI 10.1016/j.optcom.2015.12.024
   Liu YL, 2016, J VIS COMMUN IMAGE R, V39, P51, DOI 10.1016/j.jvcir.2016.05.008
   Manimurugan S, 2015, INT J DIGIT CRIME FO, V7, P26, DOI [10.4018/ijdcf.2015010102, 10.4018/IJDCF.2015010102]
   del Rey AM, 2016, EXPERT SYST APPL, V54, P379, DOI 10.1016/j.eswa.2016.02.001
   Marwan M, 2019, ENG LET, V27, P175
   Marwan M, 2018, J ELECTRON COMMER OR, V16, P1, DOI 10.4018/JECO.2018010101
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Nagendrababu V, 2018, J ENDODONT, V44, P903, DOI 10.1016/j.joen.2018.02.013
   Nallathambi B, 2017, INTELL AUTOM SOFT CO, V23, P345, DOI 10.1080/10798587.2016.1231475
   Natsheh QN, 2016, PROCEDIA COMPUT SCI, V90, P175, DOI 10.1016/j.procs.2016.07.018
   Nematzadeh H, 2018, OPT LASER ENG, V110, P24, DOI 10.1016/j.optlaseng.2018.05.009
   Noorbasha F, 2019, INT J INNOV TECHNOL, V8, P128
   Noura M, 2018, MULTIMED TOOLS APPL, V77, P31397, DOI 10.1007/s11042-018-6051-0
   Pareek NK, 2016, SOFT COMPUT, V20, P763, DOI 10.1007/s00500-014-1539-7
   Parvees M. Y. Mohamed, 2018, International Journal of Cloud Computing, V7, P15
   Parvees M. Y. Mohamed, 2017, International Journal of Network Security, V19, P984, DOI 10.6633/IJNS.201711.19(6).15
   Parvees MYM, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0809-1
   Parvees MYM, 2017, J MED IMAG HEALTH IN, V7, P118, DOI 10.1166/jmihi.2017.1993
   Parvees MYM, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0611-5
   Pradheep N, 2017, J ADV RES DYNAMIC CO, V9, P614
   Praneeth Kumar Reddy V, 2018, INT J MECH ENG TECHN, V9, P784
   Praveenkumar P, 2018, MULTIMED TOOLS APPL, V77, P8393, DOI 10.1007/s11042-017-4741-7
   Priya S, 2021, MOBILE NETW APPL, V26, P2501, DOI 10.1007/s11036-019-01213-x
   Priya S, 2018, PERS UBIQUIT COMPUT, V22, P1141, DOI 10.1007/s00779-018-1131-8
   Rahmatullah B., 2009, Journal of Medical Engineering & Technology, V33, P417, DOI 10.1080/03091900802451232
   Raja SP, 2019, INT J WAVELETS MULTI, V17, DOI 10.1142/S0219691319500346
   Raja SP, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-018-1013-9
   Raja SP, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500285
   Ravichandran D, 2019, J SIGNAL PROCESS SYS, V91, P475, DOI 10.1007/s11265-018-1337-z
   Ravichandran D, 2017, IEEE T NANOBIOSCI, V16, P850, DOI 10.1109/TNB.2017.2780881
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   Sah HR, 2018, BIOMED RES, DOI [10.4066/biomedicalresearch.29-17-519, DOI 10.4066/BIOMEDICALRESEARCH]
   Salama AS, 2019, J MED IMAG HEALTH IN, V9, P610, DOI 10.1166/jmihi.2019.2571
   Saravana KG, 2016, INDIAN J SCI TECHNOL, V9, P92213, DOI [10.17485/ijst/2016/v9i16/92213, DOI 10.17485/ijst/2016/v9i16/92213]
   Sasikaladevi N, 2022, J KING SAUD UNIV-COM, V34, P676, DOI 10.1016/j.jksuci.2019.01.014
   Shahzadi R, 2019, IEEE ACCESS, V7, P52858, DOI 10.1109/ACCESS.2019.2909554
   Shankar K, 2018, IEEE ACCESS, V6, P77145, DOI 10.1109/ACCESS.2018.2874026
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sheela SJ, 2019, INT J DIGIT CRIME FO, V11, P43, DOI 10.4018/IJDCF.2019070103
   Shen M, 2019, IEEE NETWORK, V33, P27, DOI 10.1109/MNET.001.1800503
   Shin SH, 2019, COMPUT ASSIST SURG, V24, P73, DOI 10.1080/24699322.2019.1649070
   Shivani S, 2017, MULTIMED TOOLS APPL, V76, P3851, DOI 10.1007/s11042-016-4012-z
   Sokouti Massoud, 2016, Open Med Inform J, V10, P11
   Subhasri P, 2015, INT J APPL ENG RES, P1951
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Thanki R, 2017, IMAGING SCI J, V65, P457, DOI 10.1080/13682199.2017.1367129
   Thenmozhi S, 2016, J MED IMAG HEALTH IN, V6, P822, DOI 10.1166/jmihi.2016.1773
   Vengadapurvaja AM, 2017, PROCEDIA COMPUT SCI, V115, P643, DOI 10.1016/j.procs.2017.09.150
   Wahballa Osman, 2017, International Journal of Network Security, V19, P776, DOI 10.6633/IJNS.201709.19(5).15
   Wang H, 2017, ADV MANUF, V5, P158, DOI 10.1007/s40436-017-0178-5
   Wang QZ, 2018, MULTIMED TOOLS APPL, V77, P1715, DOI 10.1007/s11042-017-4349-y
   Wang QZ, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-016-0239-1
   Wang W, 2018, COMPUT ELECTR ENG, V65, P282, DOI 10.1016/j.compeleceng.2017.07.026
   Wen WY, 2018, NEURAL COMPUT APPL, V29, P653, DOI 10.1007/s00521-016-2490-6
   Wu XY, 2019, DISCRETE CONT DYN-S, V12, P1441, DOI 10.3934/dcdss.2019099
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Ye CH, 2015, INT J SECUR APPL, V9, P409, DOI 10.14257/ijsia.2015.9.1.39
   Zhang LB, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/913476
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
NR 142
TC 13
Z9 13
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21867
EP 21906
DI 10.1007/s11042-020-09629-4
EA AUG 2020
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000561259300002
DA 2024-07-18
ER

PT J
AU Sharma, A
   Kumar, P
   Maddukuri, V
   Madamshetti, N
   Kishore, KG
   Kavuru, SSS
   Raman, B
   Roy, PP
AF Sharma, Ankit
   Kumar, Puneet
   Maddukuri, Vikas
   Madamshetti, Nagasai
   Kishore, K. G.
   Kavuru, Sahit Sai Sriram
   Raman, Balasubramanian
   Roy, Partha Pratim
TI Fast Griffin Lim based waveform generation strategy for text-to-speech
   synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tacotron; Vocoder; Text to speech synthesis delay; Dilated convolutional
   neural network
ID SYNTHESIS SYSTEM
AB The performance of text-to-speech (TTS) systems heavily depends on spectrogram to waveform generation, also known as the speech reconstruction phase. The time required for the same is known as synthesis delay. In this paper, an approach to reduce speech synthesis delay has been proposed. It aims to enhance the TTS systems for real-time applications such as digital assistants, mobile phones, embedded devices, etc. The proposed approach applies Fast Griffin Lim Algorithm (FGLA) instead Griffin Lim algorithm (GLA) as vocoder in the speech synthesis phase. GLA and FGLA are both iterative, but the convergence rate of FGLA is faster than GLA. The proposed approach is tested on LJSpeech, Blizzard and Tatoeba datasets and the results for FGLA are compared against GLA and neural Generative Adversarial Network (GAN) based vocoder. The performance is evaluated based on synthesis delay and speech quality. A 36.58% reduction in speech synthesis delay has been observed. The quality of the output speech has improved, which is advocated by higher Mean opinion scores (MOS) and faster convergence with FGLA as opposed to GLA.
C1 [Sharma, Ankit; Kumar, Puneet; Raman, Balasubramanian; Roy, Partha Pratim] Indian Inst Technol, Comp Sci & Engn Dept, Roorkee 247667, Uttar Pradesh, India.
   [Maddukuri, Vikas; Madamshetti, Nagasai; Kishore, K. G.; Kavuru, Sahit Sai Sriram] Indian Inst Technol, Elect & Commun Engn Dept, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee
RP Maddukuri, V (corresponding author), Indian Inst Technol, Elect & Commun Engn Dept, Roorkee 247667, Uttar Pradesh, India.
EM mvikas@ec.iitr.ac.in
RI Roy, Partha/J-2168-2019
OI Maddukuri, Vikas/0000-0001-5130-8249
CR Aaron A, 2014, US Patent, Patent No. [8,886,538, 8886538]
   [Anonymous], 2017, INT CONF ACOUST SPEE
   [Anonymous], 2015, 1511 ARXIV
   Arik S. O, 2017, P 34 INT C MACH LEAR, V70, P195
   ARIK SO, 2019, IEEE SIGNAL PROC LET, V0026, P00094, DOI DOI 10.1109/LSP.2018.2880284
   Bracewell RN, 1986, FOURIER TRANSFORM IT
   Braunschweiler N, 2010, INTERSPEECH
   CHENG ZY, 2016, ACM T INFORM SYST, V0034
   Ghate P, 2017, INT J DEV RES, V7, P15236
   Gibiansky A, 2017, ADV NEURAL INFORM PR, P2962
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V0032, P00236, DOI DOI 10.1109/TASSP.1984.1164317
   HUNT AJ, 1996, INT CONF ACOUST SPEE, P00373
   Ito K, 2017, LJ SPEECH DATASET
   Jia Y, 2018, ADV NEURAL INFORM PR, P4480
   Jones BT, 2017, US Patent, Patent No. [9,560,206, 9560206]
   Kinsella B, 2017, SPEECH SYNTHESIS BEC
   Kumar K, 2019, ADV NEURAL INFORM PR, P14881
   LEE S, 2017, MULTIMED TOOLS APPL, V0076, P24917, DOI DOI 10.1007/S11042-016-4122-7
   Levoy M, 1992, VOLUME RENDERING USI
   Leys S, 2007, US Patent, Patent No. [7,219,060, 7219060]
   MALATHI T, 2017, MULTIMED TOOLS APPL, V0076, P08449, DOI DOI 10.1007/S11042-016-3414-2
   MASUKO T, 1997, INT CONF ACOUST SPEE, P01611
   MASUYAMA Y, 2019, IEEE SIGNAL PROC LET, V0026, P00184, DOI DOI 10.1109/LSP.2018.2884026
   MASUYAMA Y, 2019, INT CONF ACOUST SPEE, P00061
   Mizuno H., 1993, IEEE INT C AC SPEECH, V2, P195
   MORISE M, 2016, IEICE T INF SYST, V0099, P01877, DOI DOI 10.1587/TRANSINF.2015EDP7457
   OYAMADA K, 2018, EUR SIGNAL PR CONF, P02514
   Perraudin N, 2013, IEEE WORKSH APPL SIG, P1
   Ping W, 2017, ARXIV171007654W
   Prahallad K, 2016, SPEECH TECHNOLOGY SP
   PRENGER R, 2019, INT CONF ACOUST SPEE, P03617
   QIAN S, 1993, IEEE T SIGNAL PROCES, V0041, P02429
   SALZA PL, 1996, ACUSTICA, V0082, P00650
   SHEN J, 2018, 2018 IEEE INT C AC, P04779
   SORENSEN HV, 1987, IEEE T ACOUST SPEECH, V0035, P00849, DOI DOI 10.1109/TASSP.1987.1165220
   Sotelo J, 2017, 5 INT C LEARN REPR W
   Sysko, 2013, TAT SPEECH DAT
   Taigman Y, 2017, P INT C LEARN REPR
   TOKUDA K, 2013, P IEEE, V0101, P01234, DOI DOI 10.1109/JPROC.2013.2251852
   TOKUDA K, 2015, INT CONF ACOUST SPEE, P04215
   van den Oord A, 2017, ARXIV171110433
   van den Oord A, 2016, WAVENET GENERATIVE M
   Wang Y, 2017, CHARACTERIZING DEPAR
   Wu Y., 2016, arXiv preprint arXiv:1609.08144
   YAMAGISHI J, 2010, IEEE T AUDIO SPEECH, V0018, P00984, DOI DOI 10.1109/TASL.2010.2045237
   ZEN H, 2009, SPEECH COMMUN, V0051, P01039, DOI DOI 10.1016/J.SPECOM.2009.04.004
   ZHAO Y, 2018, IEEE ACCESS, V0006, P60478, DOI DOI 10.1109/ACCESS.2018.2872060
NR 47
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30205
EP 30233
DI 10.1007/s11042-020-09321-7
EA AUG 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559953900012
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Odeh, N
   Direkoglu, C
AF Odeh, Nemer
   Direkoglu, Cem
TI Automated shopping system using computer vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automated shopping experiment; Computer vision; Convolutional neural
   networks; And support vector machines
AB The shopping experiment made by amazon go in USA is one of the most interesting applications of computer vision recently. They allow you to shop and automatically charge your virtual card for whatever goods you purchased using cameras and wireless systems, so no checkouts or waiting lines are required. However, amazon didn't reveal yet the details of how their system components are implemented. In this paper, we introduce a complete system for computer vision based automated shopping. The proposed system contains barcode scanning of objects, data registration, image capturing for offline training stage, motion (change) detection, CNN and SVM for object classification and charging/discharging customers. Our system can be integrated with the wireless data transmission to do the whole shopping process. First, the proposed method extracts the objects' barcodes to register their details, and take sample images of objects for classifier training. We employ a pre-trained CNN (i.e. ResNet50) for feature extraction and a multi-class SVM for training. After training our classifier, we have a real-time operation stage (i.e. test stage). We assume that a camera is embedded above products on each shelf to capture videos of the products. We employ a change detector to understand any added or removed items. If the item is removed from or added to the shelve, the moving object is input to CNN feature extractor, and then SVM classifier for identification and pricing. Results show that the proposed system is fast and effective.
C1 [Odeh, Nemer; Direkoglu, Cem] Middle East Tech Univ, Dept Elect & Elect Engn, Northern Cyprus Campus,Mersin 10, Guzelyurt, Trnc, Turkey.
C3 Middle East Technical University
RP Odeh, N (corresponding author), Middle East Tech Univ, Dept Elect & Elect Engn, Northern Cyprus Campus,Mersin 10, Guzelyurt, Trnc, Turkey.
EM odeh.nemer@metu.edu.tr; cemdir@metu.edu.tr
RI Direkoglu, Cem/H-2893-2013
OI Direkoglu, Cem/0000-0001-7709-4082; Odeh, Nemer/0000-0002-4760-4528
CR [Anonymous], 2018, FITTING MULTICLASS M
   [Anonymous], 2018, WHAT IS AMAZON GO IS
   Day M., 2018, Seattle Times
   Kim K, REAL TIME BARCODE RE
   Ma Yuxin, 2017, [Computational Visual Media, 计算可视媒体], V3, P161
   Mehta G, 2017, INT J SCI REIJSR, P25
NR 6
TC 1
Z9 1
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30151
EP 30161
DI 10.1007/s11042-020-09481-6
EA AUG 2020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559430400006
DA 2024-07-18
ER

PT J
AU Chen, XB
   Xiao, Y
AF Chen, Xiaobo
   Xiao, Yan
TI Geometric projection twin support vector machine for pattern
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Support vector machine; Quadratic programming; Reduced convex hull;
   Geometric algorithm; Multiple plane classifier
ID ALGORITHM; SVM
AB In this paper, a novel binary classifier termed as GPTSVM (projection twin support vector machine via Geometric Interpretation) is presented. In the spirit of original PTSVM, GPTSVM tries to seek two projection axes, one for each class, such that the projected samples of one class are well separated from that of the other class along its own projection axis. A pair of parameters (nu) are introduced in GPTSVM to control the bounds of the fractions of the support vectors and the error margins. Moreover, GPTSVM can be interpreted as a pair of minimum Mahalanobis norm problems on two reduced convex hulls (RCHs). Then, an efficient geometric algorithm for GPTSVM is presented based on the well-known Gilbert's algorithm. By doing so, the dual problem of GPTSVM can be solved very fast without resorting to any specialized optimization toolbox. The experimental results on several UCI benchmark data sets, traffic accident prediction data, and large scale NDCC database show the feasibility and effectiveness of the proposed algorithm.
C1 [Chen, Xiaobo; Xiao, Yan] Jiangsu Univ, Automot Engn Res Inst, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Chen, Xiaobo] Jiangsu Univ, Sch Automot & Traff Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
C3 Jiangsu University; Jiangsu University
RP Chen, XB (corresponding author), Jiangsu Univ, Automot Engn Res Inst, Zhenjiang 212013, Jiangsu, Peoples R China.; Chen, XB (corresponding author), Jiangsu Univ, Sch Automot & Traff Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
EM xbchen82@gmail.com
OI Chen, Xiaobo/0000-0001-9940-1637
FU National Key Research and Development Program of China [2018YFB0105000];
   National Science Foundation of China [61773184, 51875255, 6187444,
   U1664258, U1762264, 61601203]; Six talent peaks project of Jiangsu
   Province [2017-JXQC-007]
FX The authors would like to thank the anonymous reviewers for their
   constructive comments and suggestions. This work was partially supported
   by the National Key Research and Development Program of China
   (2018YFB0105000), National Science Foundation of China (61773184,
   51875255, 6187444, U1664258, U1762264, 61601203), Six talent peaks
   project of Jiangsu Province (Grant No. 2017-JXQC-007).
CR Bishop Christopher M, 2006, PATTERN RECOGNITION, DOI DOI 10.1117/1.2819119
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Chen XB, 2018, IEEE ACCESS, V6, P9347, DOI 10.1109/ACCESS.2018.2805299
   Chen XB, 2011, PATTERN RECOGN, V44, P2643, DOI 10.1016/j.patcog.2011.03.001
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Ding SF, 2014, ARTIF INTELL REV, V42, P245, DOI 10.1007/s10462-012-9336-0
   Franc V, 2003, PATTERN RECOGN, V36, P1985, DOI 10.1016/S0031-3203(03)00060-8
   Fu ZY, 2010, IEEE T NEURAL NETWOR, V21, P1963, DOI 10.1109/TNN.2010.2080319
   Gao B, 2019, FAST ROBUST TSVM PAT
   Gilbert EG, 1966, J CONTROL, V4, P61
   Hua XP, 2019, SOFT COMPUT, V23, P10649, DOI 10.1007/s00500-019-04002-6
   Hua XP, 2015, NEUROCOMPUTING, V160, P228, DOI 10.1016/j.neucom.2015.02.021
   Jayadeva, 2007, IEEE T PATTERN ANAL, V29, P905, DOI 10.1109/TPAMI.2007.1068
   Krizhevsky A., 2010, PROC 24 C NEURAL INF, V25, P1097
   Li K, 2019, IEEE ACCESS, V7, P36558, DOI 10.1109/ACCESS.2019.2905247
   Mangasarian OL, 2006, IEEE T PATTERN ANAL, V28, P69, DOI 10.1109/TPAMI.2006.17
   Mavroforakis ME, 2006, IEEE T NEURAL NETWOR, V17, P671, DOI 10.1109/TNN.2006.873281
   Mir A, 2018, APPL INTELL, V48, P4551, DOI 10.1007/s10489-018-1225-z
   Musicant D.R.:., 1998, NDC NORMALLY DISTRIB
   Peng XJ, 2010, INFORM SCIENCES, V180, P3863, DOI 10.1016/j.ins.2010.06.039
   Qian D, 2017, IEEE T BIO-MED ENG, V64, P743, DOI 10.1109/TBME.2016.2574812
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schölkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565
   Shao YH, 2015, KNOWL-BASED SYST, V73, P276, DOI 10.1016/j.knosys.2014.10.011
   Sun XD, 2013, T I MEAS CONTROL, V37, P826
   Sun XD, 2016, INT J APPL ELECTROM, V51, P151, DOI 10.3233/JAE-150165
   Tanveer M, 2016, APPL INTELL, V45, P174, DOI 10.1007/s10489-015-0751-1
   Tao Q, 2004, PATTERN RECOGN LETT, V25, P1165, DOI 10.1016/j.patrec.2004.03.011
   Tomar D, 2015, EGYPT INFORM J, V16, P55, DOI 10.1016/j.eij.2014.12.003
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Xiang C, 2006, IEEE T IMAGE PROCESS, V15, P2097, DOI 10.1109/TIP.2006.875225
   Xiong XX, 2018, PROMET-ZAGREB, V30, P71, DOI 10.7307/ptt.v30i1.2502
   Xiong XX, 2018, IEEE T INTELL TRANSP, V19, P699, DOI 10.1109/TITS.2017.2699191
   Xu YT, 2017, IEEE T NEUR NET LEAR, V28, P359, DOI 10.1109/TNNLS.2015.2513006
   Yan H, 2018, NEURAL PROCESS LETT, V48, P273, DOI 10.1007/s11063-017-9714-3
   Yan H, 2018, PATTERN RECOGN, V74, P434, DOI 10.1016/j.patcog.2017.09.035
   Yang LY, 2019, MULTIMED TOOLS APPL, V78, P15839, DOI 10.1007/s11042-018-6965-6
   Ye QL, 2010, PATTERN RECOGN LETT, V31, P2006, DOI 10.1016/j.patrec.2010.06.005
   Zhang Y, 2017, MINERALS-BASEL, V7, DOI 10.3390/min7060102
   Zhang Y, 2019, PATTERN RECOGN, V88, P421, DOI 10.1016/j.patcog.2018.12.001
   Zhou T, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101630
   Zhou T, 2019, IEEE T MED IMAGING, V38, P2411, DOI 10.1109/TMI.2019.2913158
NR 43
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23073
EP 23089
DI 10.1007/s11042-020-09103-1
EA JUL 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000552512800002
DA 2024-07-18
ER

PT J
AU Suresh, M
   Sam, IS
AF Suresh, Meenu
   Sam, I. Shatheesh
TI Optimal wavelet transform using Oppositional Grey Wolf Optimization for
   video steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video steganography; Scene change detection; DCT; DWT; OGWO; PSNR NC
ID SCHEME
AB Data hiding in video is a method used to hide secret information within the video which is useful for secure multimedia data communication. The main goal of any video steganographic system is to reduce distortion of video and to secure the embedded data. A novel approach of hiding data using Oppositional Grey Wolf Optimization (OGWO) is proposed to minimize distortion and to enhance security so as to get superior video quality. In this work, scene changes are used to identify the key frames to hide the secret data. The scene changes are detected using Discrete Cosine Transform (DCT). Once the key frames are detected, OGWO is used at this stage to select the optimal region to embed the secret data. Lastly, the optimal region for entrenching is construed to embed the secret data using Discrete Wavelet Transform (DWT). Then, the payload and video are normalized using Inverse DWT to boost the video quality. The performance of the proposed system is measured using Peak Signal to Noise Ratio (PSNR), Embedding Capacity and Normalized Correlation (NC). The comparison results show that the proposed method delivers more security and minimizes distortions for improved video quality.
C1 [Suresh, Meenu] Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
   [Sam, I. Shatheesh] Manonmaniam Sundaranar Univ, Dept PG Comp Sci, Nesamony Mem Christian Coll, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University; Manonmaniam Sundaranar University
RP Suresh, M (corresponding author), Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
EM meenupillai1988@gmail.com; shatheeshsam@yahoo.com
CR AlZain MA, 2018, APPL DATA STEGANOGRA, V13, P8
   [Anonymous], 2005, P INT C COMPUTATIONA
   [Anonymous], 2011, INT J COMPUTER SCI C
   Aparna R., 2016, INT J COMPUT APPL, V134, P1
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Dalal M, 2020, INF SECUR J, V29, P40, DOI 10.1080/19393555.2020.1714822
   Nguyen DC, 2019, MULTIMED TOOLS APPL, V78, P16033, DOI 10.1007/s11042-018-6976-3
   Esen E, 2011, IEEE T CIRC SYST VID, V21, P1130, DOI 10.1109/TCSVT.2011.2134770
   Gurunathan K, 2020, MULTIMED TOOLS APPL, V79, P3893, DOI 10.1007/s11042-019-7471-1
   Hashemzadeh M, 2018, COMPUT ELECTR ENG, V68, P14, DOI 10.1016/j.compeleceng.2018.03.046
   HL Nyo, 2019, SECURE DATA TRANSMIS, P10
   Hou CL, 2011, IEEE T IMAGE PROCESS, V20, P880, DOI 10.1109/TIP.2010.2072513
   Jackson E.S., 2006, X-ray detection and sorting of olives damaged by fruit fly
   Kapoor S, 2017, PROCEDIA COMPUT SCI, V115, P415, DOI 10.1016/j.procs.2017.09.100
   Kumar P, 2018, MULTIMED TOOLS APPL, V77, P24247, DOI 10.1007/s11042-018-5709-y
   Lima R., 2017, INT J COMPUT APPL, V164, P1, DOI 10.5120/ijca2017913686
   Miri A, 2017, OPTIK, V145, P158, DOI 10.1016/j.ijleo.2017.07.043
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Pathak Y, 2019, MULTIMED TOOLS APPL, V78, P1473, DOI 10.1007/s11042-018-6155-6
   Ramalingam M, 2016, COMPUT ELECTR ENG, V54, P423, DOI 10.1016/j.compeleceng.2015.10.005
   Ramalingam M, 2015, APPL SOFT COMPUT, V34, P744, DOI 10.1016/j.asoc.2015.05.040
   Subhedar MS, 2020, MULTIMED TOOLS APPL, V79, P1865, DOI 10.1007/s11042-019-08221-9
   Vinothini J., 2016, IJETST, DOI [10.18535/ijetst/v3i05.28, DOI 10.18535/IJETST/V3I05.28]
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Xiph.org, DERFS TEST MED COLL
   Yeh HL, 2014, IET SIGNAL PROCESS, V8, P579, DOI 10.1049/iet-spr.2012.0233
NR 26
TC 11
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27023
EP 27037
DI 10.1007/s11042-020-09330-6
EA JUL 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000551000700001
DA 2024-07-18
ER

PT J
AU Tyagi, A
   Mehra, R
AF Tyagi, Ankita
   Mehra, Ritika
TI An optimized CNN based intelligent prognostics model for disease
   prediction and classification from Dermoscopy images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent prognostics model; Skin lesion segmentation; Lesion hair
   removal; Convolutional neural network (CNN); Particle swarm optimization
   (PSO); Speed up robust features (SURF) descriptor
ID VASCULAR STRUCTURES; SKIN; SEGMENTATION
AB Tiny skin vessels and telangiectasia are most imperative dermoscopy configurations used to differentiate Basal Cell Carcinoma (BCC) from benign skin lesions. This research work builds off of previously developed image analysis techniques to identify vessels automatically to separate benign lesions from BCCs. In this paper, to develop a model for Intelligent Prognostics Model for Disease Prediction and Classification (IPM-DPC) from dermoscopy images is presented using the combination of Convolutional Neural Network (CNN) structure along with the Particle Swarm Optimization (PSO). Here PSO play two different roles in this proposed IPM-DPC, firstly PSO used with K-means segmentation technique to improve the segmentation accuracy then PSO is used as filter for the CNN to train the proposed IPM-DPC. Speed up Robust Features (SURF) algorithm is used as feature descriptor along with PSO as feature selection algorithm which increase the classification accuracy of the system. This study uses a dataset of 1000 dermoscopy skin lesion images of 545 BCCs and 455Non-BCCs or benign images as the input sets. This dataset is taken from ISBI-2016 Dataset and available on:. Experimental results yielded a diagnostic accuracy as high as 99.46% using the IMP-DPC approach, providing a14.94% improvement over a system without using the PSO as filter layer in CNN. When the evaluation parameters of proposed IMP-DPC is compared with a few other state-of-art methods, the proposed method achieves the best performance in terms of accuracy and detection time in differentiating BCC and Non-BCC from dermoscopy skin lesion images.
C1 [Tyagi, Ankita; Mehra, Ritika] DIT Univ, Sch Comp, Dehra Dun, Uttarakhand, India.
C3 DIT University
RP Tyagi, A (corresponding author), DIT Univ, Sch Comp, Dehra Dun, Uttarakhand, India.
EM ankita.tyagi@dituniversity.edu.in; hod.mca@dituniversity.edu.in
RI Mehra, Ritika/AAJ-5687-2021
OI Mehra, Ritika/0000-0002-2785-5856
CR Ahn E, 2017, IEEE J BIOMED HEALTH, V21, P1685, DOI 10.1109/JBHI.2017.2653179
   Benazzi C, 2014, SCI WORLD J, DOI 10.1155/2014/919570
   Cheng B, 2012, SKIN RES TECHNOL, V18, P389, DOI 10.1111/j.1600-0846.2011.00584.x
   Cheng B, AUTOMATIC TELANGIECT
   Cheng BB, 2013, SKIN RES TECHNOL, V19, pE217, DOI 10.1111/j.1600-0846.2012.00630.x
   Choi JW, 2014, BRIT J DERMATOL, V171, P252, DOI 10.1111/bjd.12769
   Codella NCF, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2708299
   Farage M, 2017, Textbook of Aging Skin, DOI [10.1007/978-3-662-47398-6, DOI 10.1007/978-3-662-47398-6]
   Hames SC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0112447
   Kharazmi P, 2017, IEEE J BIOMED HEALTH, V21, P1675, DOI 10.1109/JBHI.2016.2637342
   Kharazmi P, 2015, PROC SPIE, V9414, DOI 10.1117/12.2082720
   Nasr-Esfahani E, 2016, IEEE ENG MED BIO, P1373, DOI 10.1109/EMBC.2016.7590963
   Riaz F, 2019, IEEE J BIOMED HEALTH, V23, P489, DOI 10.1109/JBHI.2018.2832455
   Sagar M, 2016, ACMIEEE INT CONF HUM, P1, DOI 10.1109/HRI.2016.7451726
   Tan TY, 2019, IEEE ACCESS, V7, P34004, DOI 10.1109/ACCESS.2019.2903015
   Taufiq MA, 2017, L N INST COMP SCI SO, V181, P468, DOI 10.1007/978-3-319-49655-9_57
   Xie FY, 2017, IEEE T MED IMAGING, V36, P849, DOI 10.1109/TMI.2016.2633551
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yuan YD, 2017, IEEE T MED IMAGING, V36, P1876, DOI 10.1109/TMI.2017.2695227
   Zalaudek I, 2010, J AM ACAD DERMATOL, V63, P377, DOI 10.1016/j.jaad.2009.11.697
NR 20
TC 10
Z9 11
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26817
EP 26835
DI 10.1007/s11042-020-09074-3
EA JUL 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549799000002
DA 2024-07-18
ER

PT J
AU Rim, B
   Kim, J
   Hong, M
AF Rim, Beanbonyka
   Kim, Junseob
   Hong, Min
TI Fingerprint classification using deep learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fingerprint classification; Deep learning; Alexnet; VGG; Yolo; Resnet
AB The AFIS (Automatic Fingerprint Identification System) which generally processes two steps: feature extraction and matching, has challenges with a large database of fingerprint images for the real-time application due to the huge number of comparisons required. Therefore, the additional step of classifying detailed information of fingerprint can speed up the process of distinguishing for individual identification in the AFIS. In this paper, we presented a classification method to identify a detailed fingerprint information using deep learning approach. The proposed method aimed to distinguish the specific fingerprint information such as left-right hand classification, sweat-pore classification, scratch classification and fingers classification. Due to high personalization and security issue, we privately constructed our own dataset of fingerprint images. Five state-of-the-art deep learning models such as classic CNN, Alexnet, VGG-16, Yolo-v2 and Resnet-50 were adapted to be trained from scratch for those four categories. In our experimental tests, we received the results as follows. The Yolo-v2 model provided the highest accuracy of90.98%,78.68%and66.55%for the left-right hand, scratch and fingers classification, respectively. For sweat-pore classification, the Resnet-50 model provided the highest accuracy of91.29%. It is also worth noted that both Yolo-v2 and Resnet-50 took at most250.37 msper image.
C1 [Rim, Beanbonyka; Kim, Junseob] Soonchunhyang Univ, Dept Comp Sci, Asan 31538, South Korea.
   [Hong, Min] Soonchunhyang Univ, Dept Comp Software Engn, Asan 31538, South Korea.
C3 Soonchunhyang University; Soonchunhyang University
RP Hong, M (corresponding author), Soonchunhyang Univ, Dept Comp Software Engn, Asan 31538, South Korea.
EM rim.beanbonyka@sch.ac.kr; openfolder0220@gmail.com; mhong@sch.ac.kr
OI Hong, Min/0000-0001-9963-5521
FU Technology development Program [S2688148]; Soonchunhyang University
   Research Fund
FX This work was supported by the Technology development Program(S2688148)
   funded by theMinistry of SMEs and Startups (MSS, Korea) and was
   supported by the Soonchunhyang University Research Fund.
CR Fiumara Gregory P, 2019, NIST special database 302: Nail to nail fingerprint challenge
   Gan JY, 2019, LECT NOTES COMPUT SC, V11818, P28, DOI 10.1007/978-3-030-31456-9_4
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   JOHNSON J, 2019, CS231N CONVOLUTIONAL
   Kim J, 2019, POSTCOLONIAL GRIEF, P110
   Kim J, 2020, CMC-COMPUT MATER CON, V63, P17, DOI 10.32604/cmc.2020.09044
   Kim MJ, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10050175
   Komarinski P., 2005, Automated fingerprint identification systems (AFIS)
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu HZ, 2019, LECT NOTES COMPUT SC, V11818, P37, DOI 10.1007/978-3-030-31456-9_5
   Michelsanti D, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P202, DOI 10.5220/0006116502020209
   Minaee S., 2019, ARXIV191200271
   Mu RH, 2019, KSII T INTERNET INF, V13, P1738, DOI 10.3837/tiis.2019.04.001
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Shehu YI, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1161, DOI 10.1109/ICMLA.2018.00187
   SHEHU YI, 2018, ARXIV180710609
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Win KN, 2020, FUTURE GENER COMP SY, V110, P758, DOI 10.1016/j.future.2019.10.019
NR 18
TC 13
Z9 13
U1 4
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35809
EP 35825
DI 10.1007/s11042-020-09314-6
EA JUL 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000548495600004
DA 2024-07-18
ER

PT J
AU Kumar, N
   Sardana, HK
   Shome, SN
   Singh, V
AF Kumar, Nitin
   Sardana, H. K.
   Shome, S. N.
   Singh, Vishavpreet
TI Saliency-based classification of objects in unconstrained underwater
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Bag of features; SVM; KNN; Ensemble subspace KNN;
   Saliency gradient based morphological active contour models
ID TRACKING
AB Exploration of the deep-sea underwater environment is a challenging and non-trivial task. Underwater vehicles used for the exploration of such environments capture videos continuously. The processing of these videos is a major bottleneck for scientific research in this area. This paper presents a methodology for the classification of the objects in the unconstrained underwater environments into two broad classes namely - man-made and natural. The classification of the objects is achieved using the saliency gradient based morphological active contour models. A bag of features acquired from the contours of the objects is used for the classification using various classifiers. Principal Component Analysis is used for the removal of redundancy in the feature set. The proposed features classify the objects present in the unconstrained underwater environment into a man-made/natural class using the proposed features. The results show that all the classifiers performed well; though KNN and ensemble subspace KNN, performed marginally better.
C1 [Kumar, Nitin; Sardana, H. K.; Shome, S. N.] Acad Sci & Innovat Res AcSIR, Ghaziabad, India.
   [Sardana, H. K.; Singh, Vishavpreet] CSIR, Cent Sci Instruments Org, Chandigarh, India.
   [Shome, S. N.] CSIR, Cent Mech Engn Res Inst, Durgapur, W Bengal, India.
C3 Academy of Scientific & Innovative Research (AcSIR); Council of
   Scientific & Industrial Research (CSIR) - India; CSIR - Central
   Scientific Instruments Organisation (CSIO); Council of Scientific &
   Industrial Research (CSIR) - India; CSIR - Central Mechanical
   Engineering Research Institute (CMERI)
RP Sardana, HK (corresponding author), Acad Sci & Innovat Res AcSIR, Ghaziabad, India.; Sardana, HK (corresponding author), CSIR, Cent Sci Instruments Org, Chandigarh, India.
EM nitinsk_chd@yahoo.co.in; hk_sardana@csio.res.in; snshome@cmeri.res.in;
   dhanjal.vishavpreet@gmail.com
RI Singh, Vishavpreet/AAQ-6450-2021
FU CSIR-CSIO, Chandigarh
FX Nitin Kumar is thankful to the CSIR-CSIO, Chandigarh for providing the
   funding and opportunity to carry out this work under the grant UnWaR.
   The authors gratefully acknowledge ONC for providing the underwater
   videos for this research work.
CR [Anonymous], 2013, APPL LOGISTIC REGRES
   [Anonymous], 2013 INT JOINT C NEU
   Barnes CR, 2007, 2007 SYMPOSIUM ON UNDERWATER TECHNOLOGY AND WORKSHOP ON SCIENTIFIC USE OF SUBMARINE CABLES AND RELATED TECHNOLOGIES, VOLS 1 AND 2, P308, DOI 10.1109/UT.2007.370809
   Chapple P.B., 2017, P UND AC C EXH, P529
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Denos K, 2017, OCEANS-IEEE
   Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fan Deng-Ping, 2020, IEEE CVPR
   García-Pedrajas N, 2009, EXPERT SYST APPL, V36, P10570, DOI 10.1016/j.eswa.2009.02.065
   Gebali A, 2012, DETECTION F SALIENT
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Irfan M., 2020, Intelligent computing systems, P78
   Kim M, 2005, IMAGE VIDEO RETRIEVA, P592
   Kuhne G., 2001, P 9 ACM INT C MULT U, P41
   Kumar N, 2020, COGN COMPUT, V12, P115, DOI 10.1007/s12559-019-09671-x
   Kumar N, 2019, MULTIMED TOOLS APPL, V78, P15121, DOI 10.1007/s11042-018-6849-9
   Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802
   Lee D, 2012, OCEAN ENG, V48, P59, DOI 10.1016/j.oceaneng.2012.04.006
   Leibe B, 2003, PROC CVPR IEEE, P409
   Li GY, 2020, IEEE T IMAGE PROCESS, V29, P4873, DOI 10.1109/TIP.2020.2976689
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Liao SC, 2010, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR.2010.5539817
   Mahmood A, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.09.002
   Moussa M, 2010, CAN GEOM C
   Olmos A., 2002, PROC BRIT MACH VIS C, P1, DOI 10.5244/c.16.50
   Palazzo S, 2013, IEEE IMAGE PROC, P1481, DOI 10.1109/ICIP.2013.6738304
   PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591
   Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735
   Spampinato C, 2014, COMPUT VIS IMAGE UND, V122, P74, DOI 10.1016/j.cviu.2013.12.003
   Spampinato C, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P514
   Spampinato C, 2014, MACH VISION APPL, V25, P99, DOI 10.1007/s00138-013-0509-x
   Walther D, 2004, PROC CVPR IEEE, P544
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang J, 2020, ARXIV200405763
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhu J, 2019, MATH PROBLEMS ENG, V2019
NR 41
TC 1
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25835
EP 25851
DI 10.1007/s11042-020-09221-w
EA JUL 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000546222500003
DA 2024-07-18
ER

PT J
AU Al Azrak, FM
   Sedik, A
   Dessowky, MI
   El Banby, GM
   Khalaf, AAM
   Elkorany, AS
   Abd El-Samie, FE
AF Al Azrak, Faten Maher
   Sedik, Ahmed
   Dessowky, Moawad I.
   El Banby, Ghada M.
   Khalaf, Ashraf A. M.
   Elkorany, Ahmed S.
   Abd El-Samie, Fathi E.
TI An efficient method for image forgery detection based on trigonometric
   transforms and deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forgery detection; Trigonometric transforms; Copy-move forgery;
   Multimedia security; Deep learning; CNN
ID COPY-MOVE FORGERY; NEURAL-NETWORKS; ALGORITHM
AB Image forgery detection is the basic key to solve many problems, especially social problems such as those in Facebook, and court cases. The common form of image forgery is the copy-move forgery, in which a section of the image is copied and pasted in another location within the same image. In this type of image forgery, it is easy to perform forgery, but more difficult to detect it, because the features of the copied parts are similar to those of the other parts of the image. This paper presents an approach for copy-move forgery detection based on block processing and feature extraction from the transforms of the blocks. In addition, a Convolutional Neural Network (CNN) is used for forgery detection. The feature extraction is implemented with serial pairs of convolution and pooling layers, and then classification between the original and tampered images is performed with and without transforms. A comparison study between different trigonometric transforms in 1D and 2D is presented for detecting the tampered parts in the image. This comparison study is based on the completeness rate for the detection. This comparison ensures that the DFT in 1D or 2D implementations is the best choice to detect copy-move forgery compared to other trigonometric transforms. In addition, the paper presents a comparison study between ten cases using the CNN learning technique to detect the manipulated image. The basic idea is to use a CNN to detect and extract features. The proposed CNN approach can also be used for active forgery detection because of its robustness to detect the manipulation of digital watermarked images or images with signatures.
C1 [Al Azrak, Faten Maher; Dessowky, Moawad I.; Elkorany, Ahmed S.; Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
   [Sedik, Ahmed] Kafrelsheikh Univ, Fac Artificial Inteligence, Dept Robot & Inteligent Machines, Kafrelsheikh, Egypt.
   [El Banby, Ghada M.] Menoufia Univ, Dept Ind Elect & Control Engn, Fac Elect Engn, Menoufia 32952, Egypt.
   [Khalaf, Ashraf A. M.; Abd El-Samie, Fathi E.] Menia Univ, Fac Engn, Dept Elect Engn Elect & Commun Engn, Al Minya 61111, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Kafrelsheikh University; Egyptian Knowledge Bank (EKB);
   Menofia University; Egyptian Knowledge Bank (EKB); Minia University
RP Abd El-Samie, FE (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
EM Eng_fatenmaher@yahoo.com; ahmedsedik93@gmail.com; dr_moawad@yahoo.com;
   ghada.elbanby@el-eng.menofia.edu.eg; ashkhalaf@yahoo.com;
   elkoranyahmed@yahoo.com; fathi_sayed@yahoo.com
RI Elkorany, Ahmed S./HNI-8465-2023; Sayed, Fathi/HRA-4752-2023; Sedik,
   Ahmed/AAX-6150-2020; Sedik, Ahmed/GXV-6723-2022; Khalaf, Ashraf ِA.
   M./X-8289-2018; Elkorany, Ahmed S./AFS-0613-2022
OI Elkorany, Ahmed S./0000-0003-3400-2971; Sayed,
   Fathi/0000-0001-8749-9518; Sedik, Ahmed/0000-0002-7651-8362; Sedik,
   Ahmed/0000-0002-7651-8362; Khalaf, Ashraf ِA. M./0000-0003-3344-5420;
   Elkorany, Ahmed S./0000-0003-3400-2971
CR Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Acharya T, 2006, J VLSI SIG PROC SYST, V42, P321, DOI 10.1007/s11266-006-4191-3
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Amolins K, 2007, ISPRS J PHOTOGRAMM, V62, P249, DOI 10.1016/j.isprsjprs.2007.05.009
   [Anonymous], 2017, MATLAB DEEP LEARNING, DOI DOI 10.1007/978-1-4842-2845-6_5
   [Anonymous], 2004, TR2004515 DEP COMP
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   Farid H, 2004, TR2004515 DEP COMP S
   Fridrich A J., 2003, DETECTION COPY MOVE
   Fridrich J., 2003, P DIG FOR RES WORKSH, P133
   GRAPS A, 1995, IEEE COMPUT SCI ENG, V2, P50, DOI 10.1109/99.388960
   Hafed ZM, 2001, INT J COMPUT VISION, V43, P167, DOI 10.1023/A:1011183429707
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Huh JH, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10040093
   Jaberi M, 2014, MACH VISION APPL, V25, P451, DOI 10.1007/s00138-013-0522-0
   Jung SH, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11133499
   Kingma D. P., 2014, arXiv
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li GH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1750
   Li LD, 2014, COMPUT ELECTR ENG, V40, P1951, DOI 10.1016/j.compeleceng.2013.11.034
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lynch G, 2013, INFORM SCIENCES, V239, P253, DOI 10.1016/j.ins.2013.03.028
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Nath V., 2015, INT J COMPUTER SCI I, V6, P5413
   NISHANTH K, 2015, J MOL IMAGE DYNAMIC
   Patil SS., 2014, INT J SCI TECHNOL RE, V3, P356
   Ranzato MA., 2007, CVPR, DOI [10.1109/cvpr.2007.383157, 10.1109/CVPR.2007.383157]
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Seo YS, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020164
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang ZQ, 2019, INT CONF ACOUST SPEE, P71, DOI 10.1109/ICASSP.2019.8683231
   WINOGRAD S, 1978, MATH COMPUT, V32, P175, DOI 10.1090/S0025-5718-1978-0468306-4
   Zandi M, 2014, IEEE INT WORKS INFOR, P119, DOI 10.1109/WIFS.2014.7084314
NR 35
TC 29
Z9 29
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18221
EP 18243
DI 10.1007/s11042-019-08162-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800043
DA 2024-07-18
ER

PT J
AU Wang, YJ
   Wu, CC
   Kang, SQ
   Wang, QY
   Mikulovich, VI
AF Wang, Yujing
   Wu, Chenchen
   Kang, Shouqiang
   Wang, Qingyan
   Mikulovich, V. I.
TI Multi-channel chaotic encryption algorithm for color image based on DNA
   coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DNA coding; Discrete hyperchaotic system; Hash function SHA-256; Color
   image; Chaotic encryption
ID SEQUENCE OPERATION; SYSTEM; MAP
AB There are several issues with existing chaotic encryption schemes for images. These include singularity, unidirectionality, and the complexity of the algorithm. The result is that the encrypted image has low security and acquiring discrete chaotic sequences is time-consuming. In order to solve these problems, a multi-channel chaotic encryption algorithm for color images based on DNA (Deoxyribonucleic acid) coding is proposed. Firstly, a six-dimensional discrete hyperchaotic system is used to generate six sets of chaotic key sequences. Secondly, RGB color components of the color image are extracted. DNA matrices are obtained by DNA coding for each component and merged to construct a combined DNA matrix. After scrambling the DNA matrix, it is split into three same size matrices. The other three matrices are obtained by XOR of the chaotic key matrices. DNA coding is performed for the other three matrices to obtain the corresponding DNA matrices. DNA calculation is performed on two groups of DNA matrices in one-to-one correspondence. The result of DNA calculation is performed by DNA decoding. Finally, multiple round diffusion encryptions are performed on the decoding matrices. Experimental results show that, compared with other methods, the proposed encryption algorithm provides better encryption, can resist different types of attacks, and has higher security. In addition, chaotic sequences can be generated directly by the discrete chaotic system, and the algorithm execution efficiency could be improved.
C1 [Wang, Yujing; Wu, Chenchen; Kang, Shouqiang; Wang, Qingyan] Harbin Univ Sci & Technol, Sch Elect & Elect Engn, 52 Xuefu Rd, Harbin 150080, Peoples R China.
   [Mikulovich, V. I.] Belarusian State Univ, Minsk 220030, BELARUS.
C3 Harbin University of Science & Technology; Belarusian State University
RP Kang, SQ (corresponding author), Harbin Univ Sci & Technol, Sch Elect & Elect Engn, 52 Xuefu Rd, Harbin 150080, Peoples R China.
EM kangshouqiang@163.com
CR Algredo-Badillo I, 2013, MICROPROCESS MICROSY, V37, P750, DOI 10.1016/j.micpro.2012.06.007
   [Anonymous], 2002, FEDERAL INFORM PROCE, V180-2
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Ben Slimane N, 2018, MULTIMED TOOLS APPL, V77, P30993, DOI 10.1007/s11042-018-6145-8
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chen SK, 2015, REAL TIME COLOR VIDE
   Elhoseny HM, 2014, DIGIT IMAG PROCESS, V6, P118
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Feng W, 2019, EUR PHYS J-SPEC TOP, V228, P1951, DOI 10.1140/epjst/e2019-800209-3
   Girdhar A, 2018, MULTIMED TOOLS APPL, V77, P27017, DOI 10.1007/s11042-018-5902-z
   Gong LH, 2018, OPT LASER TECHNOL, V103, P48, DOI 10.1016/j.optlastec.2018.01.007
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Li Z, 2018, NONLINEAR DYNAM, V94, P1319, DOI 10.1007/s11071-018-4426-4
   Liu HJ, 2013, OPTIK, V124, P3527, DOI 10.1016/j.ijleo.2012.10.068
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu P, 2019, MULTIMED TOOLS APPL, V78, P14823, DOI 10.1007/s11042-018-6758-y
   Mollaeefar M, 2017, MULTIMED TOOLS APPL, V76, P607, DOI 10.1007/s11042-015-3064-9
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Sahari ML, 2018, NONLINEAR DYNAM, V94, P723, DOI 10.1007/s11071-018-4390-z
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Tong XJ, 2016, NONLINEAR DYNAM, V84, P2333, DOI 10.1007/s11071-016-2648-x
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P26111, DOI 10.1007/s11042-019-07794-9
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2014, NONLINEAR DYNAM, V78, P2975, DOI 10.1007/s11071-014-1639-z
   Wang XY, 2014, NONLINEAR DYNAM, V75, P567, DOI 10.1007/s11071-013-1086-2
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   WILKINS MHF, 1953, NATURE, V171, P738, DOI 10.1038/171738a0
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Yang YG, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105661
   Ye GD, 2017, NEUROCOMPUTING, V251, P45, DOI 10.1016/j.neucom.2017.04.016
   Yu SM, 2013, POWER SYSTEM ANTICON
   Yuan HM, 2017, MULTIMED TOOLS APPL, V76, P8087, DOI 10.1007/s11042-016-3454-7
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhang YS, 2015, NONLINEAR DYNAM, V82, P1831, DOI 10.1007/s11071-015-2280-1
   Zhu SQ, 2019, IEEE ACCESS, V7, P147106, DOI 10.1109/ACCESS.2019.2946208
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 44
TC 26
Z9 26
U1 6
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18317
EP 18342
DI 10.1007/s11042-020-08742-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800046
DA 2024-07-18
ER

PT J
AU Katarya, R
   Arora, Y
AF Katarya, Rahul
   Arora, Yamini
TI Capsmf: a novel product recommender system using deep learning based
   text analysis model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Matrix factorization; Capsule networks;
   Collaborative filtering
AB Researchers and data scientists have developed different Recommender System Algorithms such as Content-Based and Collaborative-Based in order to filter a large amount of information available on the internet and hence, recommend only the relevant and essential content based on the personalized interests of users. Information acquired explicitly by collecting users' ratings for an item lead to the problem of data sparsity. Many researchers have been currently working towards the improvement of rating prediction accuracy by integrating the auxiliary information along with the ratings provided by the users. This paper proposes a novel product recommender system called as "CapsMF", it applies the advanced neural network architecture Capsule Networks (Caps) for document representation, and MF represents Matrix factorization. In the proposed approach, we have enhanced a deep neural network text analysis model by adding a newly discovered neural network architecture; Capsule Networks stacked on bi-directional Recurrent Neural Network (Bi-RNN) for the robust representation of textual descriptions of items and users. The Deep Neural Network text analysis model is integrated with the Probabilistic Matrix Factorization to generate improved recommendations. The experiment has been performed on two real amazon datasets resulting in the enhancement of rating prediction accuracy, the recall, and the precision of top-n recommendations, in comparison to the basic and hybrid Recommendation System Algorithms. Also, text analysis model involving Capsule Networks stacked with Recurrent Neural Networks (RNNs) have outperformed the baseline models that have single Convolutional Neural Networks (CNN) or CNN combined with Bi-RNN in text analysis.
C1 [Katarya, Rahul] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
   [Arora, Yamini] Delhi Technol, Dept Informat Technol, Delhi, India.
C3 Delhi Technological University; Delhi Technological University
RP Katarya, R (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
EM rahulkatarya@dtu.ac.in; arorayamini08@gmail.com
OI Katarya, Prof. Rahul/0000-0001-7763-291X
CR [Anonymous], 2017, P NEURAL INF PROCESS
   [Anonymous], 2018, ROUTL HANDBK
   Belém FM, 2019, INFORM PROCESS MANAG, V56, P771, DOI 10.1016/j.ipm.2018.12.009
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Chollet F., KERAS DEEP LEARNING
   Chung Junyoung, 2014, NIPS 2014 DEEP LEARN
   Hinton G. E., 2011, LECT NOTES COMPUTER, V6791
   Jain L, 2018, PROC IEEE INT SOFT, P10
   Jaiswal A, 2018, PROC IEEE INDIAN C A, P1
   Johnson BL, 2015, CHASTITY IN EARLY STUART LITERATURE AND CULTURE, P103
   Katarya R, 2019, INT C ADV COMP COMM
   Khasmakhi NN, 2019, ENG APPL ARTIF INTEL, V82, P126, DOI 10.1016/j.engappai.2019.03.020
   Khater S, 2014, TWEETS YOU PERSONALI, P1
   Kim D, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P233, DOI 10.1145/2959100.2959165
   Kong X, 2018, IEEE ACCESS, V6, P64301, DOI [10.1109/ACCESS.2018.2877208, DOI 10.1109/ACCESS.2018.2877208]
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Ling G, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P105, DOI 10.1145/2645710.2645728
   Liphoto M, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATION AND ENGINEERING (ICACCE 2016), P276, DOI 10.1109/ICACCE.2016.8073761
   McAuley Julian, 2013, RECSYS
   Mnih A., 2007, ADV NEURAL INFORM PR, V20
   Mohan M, 2012, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2011, VOL 2, PTS A AND B, P661
   Ortega F, 2018, IEEE ACCESS, V6, P69582, DOI 10.1109/ACCESS.2018.2881074
   Pennington Jeffrey, 2014, C EMP METH NAT LANG, P1532
   Ramlatchan A, 2018, BIG DATA MIN ANAL, V1, P308, DOI 10.26599/BDMA.2018.9020008
   Razghandi M, 2017, INT CONF E BUS ENG, P208, DOI 10.1109/ICEBE.2017.40
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Srivastava S., 2018, P 1 WORKSHOP TROLLIN, P98
   Steyvers M., 2004, P 2004 ACM SIGKDD IN, DOI [DOI 10.1145/1014052.1014087, 10.1145/1014052, DOI 10.1145/1014052]
   Wang Chong, 2011, P 17 ACM SIGKDD INT, P448, DOI [DOI 10.1145/2020408.2020480, 10.1145/2020408.2020480]
   Wang H, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1235, DOI 10.1145/2783258.2783273
   Wang W, 2016, DECIS SUPPORT SYST, V87, P80, DOI 10.1016/j.dss.2016.05.002
   Wang YQ, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1165, DOI 10.1145/3178876.3186015
   Wu H, 2018, KNOWL-BASED SYST, V145, P46, DOI 10.1016/j.knosys.2018.01.003
   Zhang LB, 2018, IEEE ACCESS, V6, P9454, DOI 10.1109/ACCESS.2018.2789866
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zheng L, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P425, DOI 10.1145/3018661.3018665
NR 37
TC 30
Z9 31
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35927
EP 35948
DI 10.1007/s11042-020-09199-5
EA JUN 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000544843100001
DA 2024-07-18
ER

PT J
AU Sekh, AA
   Dogra, DP
   Choi, H
   Chae, S
   Kim, IJ
AF Sekh, Arif Ahmed
   Dogra, Debi Prosad
   Choi, Heeseung
   Chae, Seungho
   Kim, Ig-Jae
TI Person Re-identification in Videos by Analyzing Spatio-temporal Tubes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video-based Person Re-identification; Re-ranking; Person
   Re-identification
ID TRACKING
AB Typical person re-identification frameworks search forkbest matches in a gallery of images that are often collected in varying conditions. The gallery usually contains image sequences for video re-identification applications. However, such a process is time consuming as video re-identification involves carrying out the matching process multiple times. In this paper, we propose a new method that extracts spatio-temporal frame sequences or tubes of moving persons and performs the re-identification in quick time. Initially, we apply a binary classifier to remove noisy images from the input query tube. In the next step, we use a key-pose detection-based query minimization technique. Finally, a hierarchical re-identification framework is proposed and used to rank the output tubes. Experiments with publicly available video re-identification datasets reveal that our framework is better than existing methods. It ranks the tubes with an average increase in the CMC accuracy of 6-8% across multiple datasets. Also, our method significantly reduces the number of false positives. A new video re-identification dataset, named Tube-based Re-identification Video Dataset (TRiViD), has been prepared with an aim to help the re-identification research community.
C1 [Sekh, Arif Ahmed] UiT Arctic Univ Norway, Tromso, Norway.
   [Dogra, Debi Prosad] Indian Inst Technol Bhubaneswar, Bhubaneswar, Odisha, India.
   [Choi, Heeseung; Chae, Seungho; Kim, Ig-Jae] Korea Inst Sci & Technol, Seoul, South Korea.
C3 UiT The Arctic University of Tromso; Indian Institute of Technology
   System (IIT System); Indian Institute of Technology (IIT) - Bhubaneswar;
   Korea Institute of Science & Technology (KIST)
RP Sekh, AA (corresponding author), UiT Arctic Univ Norway, Tromso, Norway.
EM skarifahmed@gmail.com; dpdogra@iitbbs.ac.in; hschoi@kist.re.kr;
   seungho.chae@kist.re.kr; drjay@kist.re.kr
RI Sk, Arif Ahmed/U-5120-2019
OI Sk, Arif Ahmed/0000-0003-0706-2565
FU UiT The Arctic University of Norway; KIST Flagship Project [2E30270,
   CP152]; NVIDIA Corporation
FX Open Access funding provided by UiT The Arctic University of Norway. The
   work has been funded under KIST Flagship Project (Project No.2E30270)
   executed at IIT Bhubaneswar under the Project Code: CP152. We gratefully
   acknowledge the support of NVIDIA Corporation with the donation of the
   Quadro P5000 GPU used for this research.
CR Barman A, 2017, IEEE I CONF COMP VIS, P1124, DOI 10.1109/ICCV.2017.127
   Batchuluun G, 2018, EXPERT SYST APPL, V101, P56, DOI 10.1016/j.eswa.2018.02.016
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Cancela B, 2013, EXPERT SYST APPL, V40, P1116, DOI 10.1016/j.eswa.2012.08.025
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen DP, 2018, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2018.00128
   Chen DP, 2018, PROC CVPR IEEE, P8649, DOI 10.1109/CVPR.2018.00902
   Chung D, 2017, INT C COMP VIS
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Jensen MB, 2017, IEEE COMPUT SOC CONF, P882, DOI 10.1109/CVPRW.2017.122
   Lin HZ, 2018, ADV NEUR IN, V31
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Lv JM, 2018, PROC CVPR IEEE, P7948, DOI 10.1109/CVPR.2018.00829
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saquib Sarfraz M, 2018, COMPUTER VISION PATT
   Weng SK, 2006, J VIS COMMUN IMAGE R, V17, P1190, DOI 10.1016/j.jvcir.2006.03.004
   Soleymani R, 2018, EXPERT SYST APPL, V101, P271, DOI 10.1016/j.eswa.2018.01.023
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150
   Zhang J., 2018, IEEE CVPR
   Zhao R, 2017, IEEE T PATTERN ANAL, V39, P356, DOI 10.1109/TPAMI.2016.2544310
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
NR 37
TC 4
Z9 4
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24537
EP 24551
DI 10.1007/s11042-020-09096-x
EA JUN 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000542539200001
OA Green Published, Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU El-Bendary, MAM
   Kasban, H
   Haggag, A
   El-Tokhy, MAR
AF El-Bendary, Mohsen A. M.
   Kasban, Hany
   Haggag, Ayman
   El-Tokhy, M. A. R.
TI Investigating of nodes and personal authentications utilizing multimodal
   biometrics for medical application of WBANs security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WBAN authentication; Biometric-based authentication; Non-cryptographic
   authentication; Multimodal biometrics; Fusion
ID FACE; VOICE; SPEECH; TRANSMISSION; SCHEME
AB The authentication of the Wireless Body Area Networks (WBANs) nodes is a vital factor in its medical applications. This paper, investigates methods of authentication over these networks. Also, an effective unimodal and multimodal biometrics identification approaches based on individual face and voice recognition or combined using different fusion types are presented. The cryptography and non-cryptography-based authentication are discussed in this research work and its suitability with the medical applications. Cryptographic based authentication is not suitable for WBANs. The biometrics authentication is discussed and its challenges. In this work, different fusion types in multimodal biometric are presented. There are two unimodal schemes have been presented based on using the voice and face image individually, these two biometrics have been used in the multimodal biometric scheme. The presneted multimodal scheme is evaluated and applied using the feature and score fusion. The mechanism operation of presented algorithm starts with capturing the biometics signals 'Face/Voice', the second step is the feature extracting from each biometric individually. The Artificial Neural Network (ANN), The Support Vector Machine (SVM) and the Gaussian Mixture Model (GMM) classifiers have been employed to perform the classification process individually. The computer simulation experiments reveal that the cepstral coefficients and statistical coefficients for voice recognition performed better for the voice scenario. Also, the Eigenface and support vector machine tools in the face recognition scheme performed better than other schemes. The multimodal results better than the unimodal schemes. Also, the results of the scores fusion-based multimodal biometric scheme is better than the feature fusion-based scheme. Hence, the biometric-based authentication is effective and applicable for the WBANs authentication and personality continuous authentication on these medical applications wireless networks.
C1 [El-Bendary, Mohsen A. M.; Haggag, Ayman; El-Tokhy, M. A. R.] Helwan Univ, Fac Technol & Educ, Elect Technol Dept, Cairo, Egypt.
   [Kasban, Hany] Atom Energy Author, Engn Dept, Nucl Res Ctr, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Helwan University; Egyptian Knowledge
   Bank (EKB); Egyptian Atomic Energy Authority (EAEA)
RP El-Bendary, MAM (corresponding author), Helwan Univ, Fac Technol & Educ, Elect Technol Dept, Cairo, Egypt.
EM engmohsen2004@yahoo.com
RI El-Bendary, Mohsen A. M./P-8567-2019; Eltokhy, Mostafa/AAZ-8088-2020;
   Haggag, Ayman/AAS-3597-2020
OI El-Bendary, Mohsen A. M./0000-0002-2425-4967; Haggag,
   Ayman/0000-0003-1637-1298
CR Abdelkarim N., 2015, ASIAN J INFORM TECHN, V14, P166
   Abhishree TM, 2015, PROCEDIA COMPUT SCI, V45, P312, DOI 10.1016/j.procs.2015.03.149
   ABOUELFADL AA, 2014, LIFE SCI J, V11, P342
   Agashe NM, 2015, INT J ADV RES COMPUT, V4
   Altinok A, 2013, P WORKSH MULT US AUT, P131
   [Anonymous], 2016, PROC 8 IFIP INT C NE
   [Anonymous], 1998, DATA MINING KNOWLEDG
   [Anonymous], Proceedings of the 2Nd International Conference on Embedded Networked Sensor Systems. SenSys'04, DOI DOI 10.1145/1031495.1031515
   Asim M, 2018, J SOFTW-EVOL PROC, V30, DOI 10.1002/smr.1944
   Azzini A, 2008, LECT NOTES ARTIF INT, V5178, P371, DOI 10.1007/978-3-540-85565-1_47
   Azzini A, 2008, FUZZY OPTIM DECIS MA, V7, P243, DOI 10.1007/s10700-008-9034-1
   Baken R., 2000, Clinical measurement of speech and voice
   Baken RJ, 2016, EVALUATING DIAGNOSTI, V85, P102
   Baker T, 2015, IEEE ACM INT SYMP, P961, DOI 10.1109/CCGrid.2015.37
   Cai L., 2011, P 18 ANN NETW DISTR
   Ceccarelli A, 2013, IEEE T DEPENDABLE SE
   Chetty G, 2008, IMAGE VISION COMPUT, V26, P1249, DOI 10.1016/j.imavis.2008.02.009
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   De A, 2015, PROCEDIA COMPUT SCI, V45, P282, DOI 10.1016/j.procs.2015.03.142
   Dodangeh P, 2018, J INF SECUR APPL, V41, P62, DOI 10.1016/j.jisa.2018.06.001
   Du W., 2005, ACM Transactions on Information and Systems Security, V8, P228, DOI 10.1145/1065545.1065548
   El-Bendary MAM, 2017, MULTIMED TOOLS APPL, V76, P26463, DOI 10.1007/s11042-016-4177-5
   Elmir Y, 2014, J INF PROCESS SYST
   Fookes C, 2012, J VIS COMMUN IMAGE R, V23, P75, DOI 10.1016/j.jvcir.2011.06.004
   Gad R, 2015, INT J ADV COMPUT SC, V6, P128
   Galka J, 2014, IEEE T CONSUM ELECTR, V60, P653, DOI 10.1109/TCE.2014.7027339
   Halvi S, 2017, PROCEDIA COMPUT SCI, V115, P383, DOI 10.1016/j.procs.2017.09.095
   Hölig C, 2014, NEUROIMAGE, V103, P374, DOI 10.1016/j.neuroimage.2014.09.050
   Hussain AJ, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1422, DOI 10.1109/HPCC/SmartCity/DSS.2018.00235
   Inthavisas K, 2012, IET BIOMETRICS, V1, P46, DOI 10.1049/iet-bmt.2011.0008
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jain AK, 1999, PATTERN RECOGN LETT, V20, P1371, DOI 10.1016/S0167-8655(99)00108-7
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 2013, IEEE T INF FOREN SEC, V1, P125
   Ju MH, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P191, DOI 10.1109/ISM.2012.45
   Karam Y, 2012, UKSIM EURO SYMP COMP, P67, DOI 10.1109/EMS.2012.17
   Kasban H, 2017, ARAB J NUCL SCI APPL, V50, P120
   Kasban H, 2017, WIRELESS PERS COMMUN, V94, P1087, DOI 10.1007/s11277-016-3671-4
   Kinnunen T, 2006, IEEE T AUDIO SPEECH, V14, P277, DOI 10.1109/TSA.2005.853206
   Kumar HCS, 2016, INT J SCI ENG APPL S, V2
   Kumar S, USING CONTINUOUS BIO
   Li HJ, 2016, PATTERN RECOGN, V60, P13, DOI 10.1016/j.patcog.2016.05.014
   Liu T, 2016, NEUROCOMPUTING, V214, P944, DOI 10.1016/j.neucom.2016.06.071
   Liu ZH, 2014, DIGIT SIGNAL PROCESS, V24, P197, DOI 10.1016/j.dsp.2013.09.007
   Lu S, 2012, P 5 ACM C SEC PRIV W
   Lumini A, 2017, INFORM FUSION, V33, P71, DOI 10.1016/j.inffus.2016.05.003
   Morgen B., 2012, BIOMETRIC TECHNOLOGY, V2012, P8, DOI DOI 10.1016/S0969-4765(12)70054-1
   Nassar SS, 2016, WIRELESS PERS COMMUN, V88, P479, DOI 10.1007/s11277-015-3142-3
   Palanivel S, 2008, COMPUT VIS IMAGE UND, V109, P44, DOI 10.1016/j.cviu.2006.11.013
   Poh N, 2001, LECT NOTES COMPUT SC, V2091, P348
   Qi MP, 2018, COMPUT METH PROG BIO, V164, P101, DOI 10.1016/j.cmpb.2018.07.008
   Raghavendra R, 2010, PROCEDIA COMPUT SCI, V2, P181, DOI 10.1016/j.procs.2010.11.023
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Sim T, 2007, IEEE T PATTERN ANAL, V29, P687, DOI 10.1109/TPAMI.2007.1010
   Soltane M, 2015, INT J ENG TECHNOLOGY, V15, P41
   Soltane M, 2015, INT J ENG TECHNOL, V03, P52
   Suo X, 2012, P ANN COMP SEC APPL, P463
   Szczechowiak P, 2008, LECT NOTES COMPUT SC, V4913, P305
   Tan CC, 2008, WISEC'08: PROCEEDINGS OF THE FIRST ACM CONFERENCE ON WIRELESS NETWORK SECURITY, P148
   Tariq N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19081788
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Varun R, 2015, PROCEDIA COMPUT SCI, V46, P1491, DOI 10.1016/j.procs.2015.02.069
   Venkatasubramanian KK, 2010, ACM T SENSOR NETWORK, V6, DOI 10.1145/1777406.1777410
   Xu FY, 2011, IEEE INFOCOM SER, P1862, DOI 10.1109/INFCOM.2011.5934987
   Xuan SB, 2016, IET COMPUT VIS, V10, P493, DOI 10.1049/iet-cvi.2015.0350
   Zhang S, 2010, 2ND INTERNATIONAL SYMPOSIUM ON COMPUTER NETWORK AND MULTIMEDIA TECHNOLOGY (CNMT 2010), VOLS 1 AND 2, P565
   Zheng CH, 2016, NEUROCOMPUTING, V198, P114, DOI 10.1016/j.neucom.2015.07.146
   Zhou Z, 2012, IEEE T SYST MAN CYBE, V42
NR 69
TC 14
Z9 14
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24507
EP 24535
DI 10.1007/s11042-020-08926-2
EA JUN 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000542143000003
DA 2024-07-18
ER

PT J
AU Arya, M
   Mittal, N
   Singh, G
AF Arya, Mithlesh
   Mittal, Namita
   Singh, Girdhari
TI Three segmentation techniques to predict the dysplasia in cervical cells
   in the presence of debris
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cervical cancer; Pap smear; Debris; Seed region growing; Edge based
   detection; Moving k-means
ID PAP-SMEAR IMAGES; CLASSIFICATION
AB Cervical Cancer is one of the most pandemic causes of cancer related death in females. Pap smear test is one of the most commonly used screening test for the cervical cancer. Existing algorithms focus on the segmentation of nucleus and cytoplasm either using single-cell images or multiple cells images. Images captured from the Pap smear slides are called smear images. Smear image contains cervical cells along with debris, debris are inflammatory cells, red blood cells, dye. Debris significantly influence the outcome of image segmentation. An accurate nuclei segmentation method can improve the success rate of cervical cancer screening. Therefore, this paper reveals about three segmentation techniques which are used for automated segmentation of cervical cell nuclei in the presence of debris. Three segmentation techniques namely, Automated Seed Region Growing, Extended Edge Based Detection and Modified Moving k-means techniques are proposed to extract the cervical cell nuclei. These techniques are extracting the area of nuclei from smear images using the morphological property of nucleus. Some debris have area that corresponds with the area of nucleus of normal cells, it may interfere with outcome and may give false positive results. The empirical area threshold value demonstrate the superior performance of all proposed methods. The qualitative and quantitative analysis also done on proposed techniques. Experimental analysis shows that Modified Moving k-means give favorable result in dysplasia detection in the presence of debris. A new datasetPapsmearJPis collected during the study with the help of a pathologist for the validation of the work.
C1 [Arya, Mithlesh; Mittal, Namita; Singh, Girdhari] Malaviya Natl Inst Technol, Jaipur, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Arya, M (corresponding author), Malaviya Natl Inst Technol, Jaipur, Rajasthan, India.
EM 2015rcp9040@mnit.ac.in
RI Mittal, Namita/AAL-3336-2020
OI Mittal, Namita/0000-0001-6886-9974
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Al-amri S, 2010, J COMPUT, V2, P5
   Alias MF, 2012, INT J KNOWL-BASED IN, V16, P79, DOI [10.3233/KES-2010-0233, 10.3233/KES-2010-023]
   [Anonymous], 2015, SPRINGER 4 INT C SOF
   [Anonymous], PAP SMEAR DTU HERLEV
   Arya M, 2019, COMM COM INF SC, V985, P205, DOI 10.1007/978-981-13-8300-7_17
   Arya M, 2018, IET COMPUT VIS, V12, P1049, DOI 10.1049/iet-cvi.2018.5349
   Banavali SD, 2015, INDIAN J MED PAEDIAT, V36, P128, DOI 10.4103/0971-5851.158848
   Bora K, 2017, COMPUT METH PROG BIO, V138, P31, DOI 10.1016/j.cmpb.2016.10.001
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chankong T, 2014, COMPUT METH PROG BIO, V113, P539, DOI 10.1016/j.cmpb.2013.12.012
   Chen F, 2017, IEEE J-STARS, V10, P489, DOI 10.1109/JSTARS.2016.2569998
   Chen YF, 2014, IEEE J BIOMED HEALTH, V18, P94, DOI 10.1109/JBHI.2013.2250984
   Lu Z, 2013, LECT NOTES COMPUT SC, V8149, P452, DOI 10.1007/978-3-642-40811-3_57
   Mashor M.Y., 2000, International Journal of the computer, the Internet and Management, V8, P50, DOI DOI 10.1080/00207179208934272
   Mbaga A.H., 2015, Int. J. Comput. Appl., V118, P10, DOI [10.5120/20756-3159, DOI 10.5120/20756-3159]
   Melouah A., 2014, Recent advances in biology, biomedicine and bioengineering, P91
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Plissiti ME, 2011, IEEE T INF TECHNOL B, V15, P233, DOI 10.1109/TITB.2010.2087030
   Sajeena TA, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING AND NETWORK COMMUNICATIONS (COCONET), P663, DOI 10.1109/CoCoNet.2015.7411260
   Senthilkumaran N., 2009, International Journal of Recent Trends in Engineering, V1, P250
   Shih FY, 2005, IMAGE VISION COMPUT, V23, P877, DOI 10.1016/j.imavis.2005.05.015
   Srivastava AN, 2018, INDIAN J MED RES, V148, P687, DOI 10.4103/ijmr.IJMR_5_17
   Tan SY, 2015, SINGAP MED J, V56, P586, DOI 10.11622/smedj.2015155
   William Wasswa, 2019, Informatics in Medicine Unlocked, V14, P23, DOI 10.1016/j.imu.2019.02.001
   William W, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0634-5
   Zhang YJ, 1996, PATTERN RECOGN, V29, P1335, DOI 10.1016/0031-3203(95)00169-7
   Zhao J, 2019, I S BIOMED IMAGING, P1514, DOI [10.1109/ISBI.2019.8759262, 10.1109/isbi.2019.8759262]
NR 28
TC 6
Z9 6
U1 6
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24157
EP 24172
DI 10.1007/s11042-020-09206-9
EA JUN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000541201200007
DA 2024-07-18
ER

PT J
AU Gupta, S
   Fahad, MS
   Deepak, A
AF Gupta, Shruti
   Fahad, Md. Shah
   Deepak, Akshay
TI Pitch-synchronous single frequency filtering spectrogram for speech
   emotion recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution Neural Network (CNN); Single Frequency Filtering (SFF);
   Spectrogram; Speech Emotion Recognition (SER)
ID EPOCH EXTRACTION; FUNDAMENTAL-FREQUENCY; FEATURES
AB Convolutional neural networks (CNN) are widely used for speech emotion recognition (SER). In such cases, the short time fourier transform (STFT) spectrogram is the most popular choice for representing speech, which is fed as input to the CNN. However, the uncertainty principles of the short-time Fourier transform prevent it from capturing time and frequency resolutions simultaneously. On the other hand, the recently proposed single frequency filtering (SFF) spectrogram promises to be a better alternative because it captures both time and frequency resolutions simultaneously. In this work, we explore the SFF spectrogram as an alternative representation of speech for SER. We have modified the SFF spectrogram by taking the average of the amplitudes of all the samples between two successive glottal closure instants (GCI) locations. The duration between two successive GCI locations gives the pitch, motivating us to name the modified SFF spectrogram as pitch-synchronous SFF spectrogram. The GCI locations were detected using zero frequency filtering approach. The proposed pitch-synchronous SFF spectrogram produced accuracy values of 63.95% (unweighted) and 70.4% (weighted) on the IEMOCAP dataset. These correspond to an improvement of + 7.35% (unweighted) and + 4.3% (weighted) over state-of-the-art result on the STFT sepctrogram using CNN. Specially, the proposed method recognized 22.7% of the happy emotion samples correctly, whereas this number was 0% for state-of-the-art results. These results also promise a much wider use of the proposed pitch-synchronous SFF spectrogram for other speech-based applications.
C1 [Gupta, Shruti; Fahad, Md. Shah; Deepak, Akshay] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Gupta, S (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
EM shrgupta01@gmail.com; shah.cse16@nitp.ac.in; akshayd@nitp.ac.in
RI gupta, shruti/IQR-5576-2023
OI Gupta, Shruti/0000-0002-8571-3311
FU Young Faculty Research Fellowship (YFRF) of Visvesvaraya PhD Programme
   of Ministry of Electronics & Information Technology, MeitY, Government
   of India
FX Akshay Deepak has been awarded Young Faculty Research Fellowship (YFRF)
   of Visvesvaraya PhD Programme of Ministry of Electronics & Information
   Technology, MeitY, Government of India. In this regard, he would like to
   acknowledge that this publication is an outcome of the R&D work
   undertaken in the project under the Visvesvaraya PhD Scheme of Ministry
   of Electronics & Information Technology, Government of India, being
   implemented by Digital India Corporation (formerly Media Lab Asia).
CR Akagi M., 2014, P APSIPA, P1
   Alluri KNRKR, 2017, INTERSPEECH, P2596, DOI 10.21437/Interspeech.2017-256
   Aneeja G, 2017, IEEE-ACM T AUDIO SPE, V25, P829, DOI 10.1109/TASLP.2017.2666425
   Aneeja G, 2015, IEEE-ACM T AUDIO SPE, V23, P705, DOI 10.1109/TASLP.2015.2404035
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2015, 16 ANN C INT SPEECH
   [Anonymous], 2017, ARXIV170600612
   [Anonymous], 2012, ARXIV12022745
   [Anonymous], 2016, ARXIV160101577
   Badshah AM, 2019, MULTIMED TOOLS APPL, V78, P5571, DOI 10.1007/s11042-017-5292-7
   Badshah AM, 2017, 2017 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P125
   Bayya Y, 2013, SPEECH COMMUN, V55, P782, DOI 10.1016/j.specom.2013.02.007
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chen MY, 2018, IEEE SIGNAL PROC LET, V25, P1440, DOI 10.1109/LSP.2018.2860246
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Fayek HM, 2017, NEURAL NETWORKS, V92, P60, DOI 10.1016/j.neunet.2017.02.013
   France DJ, 2000, IEEE T BIO-MED ENG, V47, P829, DOI 10.1109/10.846676
   He L, 2010, 11 ANN C INT SPEECH
   Jiang YH, 2019, PROCEEDINGS OF 2019 THE 3RD INTERNATIONAL CONFERENCE ON CRYPTOGRAPHY, SECURITY AND PRIVACY (ICCSP 2019) WITH WORKSHOP 2019 THE 4TH INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP 2019), P28, DOI 10.1145/3309074.3309094
   KADAMBE S, 1992, IEEE T INFORM THEORY, V38, P917, DOI 10.1109/18.119752
   Kadiri SR, 2017, SPEECH COMMUN, V86, P52, DOI 10.1016/j.specom.2016.11.005
   Kekre H. B., 2012, INT J COMPUTER APPL, V50
   Khalil RA, 2019, IEEE ACCESS, V7, P117327, DOI 10.1109/ACCESS.2019.2936124
   Klasmeyer G, 1997, INT CONF ACOUST SPEE, P1615, DOI 10.1109/ICASSP.1997.598808
   Li M, 2013, COMPUT SPEECH LANG, V27, P151, DOI 10.1016/j.csl.2012.01.008
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Meinedo H, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2822
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Murty KSR, 2008, IEEE T AUDIO SPEECH, V16, P1602, DOI 10.1109/TASL.2008.2004526
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Pannala V, 2016, INTERSPEECH, P2155, DOI 10.21437/Interspeech.2016-1401
   Satt A, 2017, INTERSPEECH, P1089, DOI 10.21437/Interspeech.2017-200
   Schuller B, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P577
   Shriberg E, 2005, SPEECH COMMUN, V46, P455, DOI 10.1016/j.specom.2005.02.018
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Vikram CM, 2017, IEEE-ACM T AUDIO SPE, V25, P624, DOI 10.1109/TASLP.2017.2651391
   Wang J, 2019, ARXIV191008874
   Wang JC, 2017, MULTIMED TOOLS APPL, V76, P4055, DOI 10.1007/s11042-016-3335-0
   Wu C, 2018, MULTIMED TOOLS APPL, V77, P24353, DOI 10.1007/s11042-018-5742-x
   Yadav J, 2018, SPEECH COMMUN, V96, P142, DOI 10.1016/j.specom.2017.12.002
   Yeh T-C, 2002, uS Patent App, Patent No. [09/884,287, 09884287]
   Yenigalla P, 2018, INTERSPEECH, P3688, DOI 10.21437/Interspeech.2018-1811
   Zeng YN, 2019, MULTIMED TOOLS APPL, V78, P3705, DOI 10.1007/s11042-017-5539-3
NR 43
TC 14
Z9 14
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23347
EP 23365
DI 10.1007/s11042-020-09068-1
EA JUN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538977700008
DA 2024-07-18
ER

PT J
AU Cheng, SC
   Hsiao, KF
   Yang, CK
   Hsiao, PF
   Yu, WH
AF Cheng, Shyi-Chyi
   Hsiao, Kuei-Fang
   Yang, Chen-Kuei
   Hsiao, Po-Fu
   Yu, Wan-Hsuan
TI A novel unsupervised 3D skeleton detection in RGB-D images for video
   surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object skeleton modeling and detection; Moment-based symmetry feature
   detection; RGB-D images; Part merging; Unsupervised feature learning
ID SYMMETRY DETECTION; EXTRACTION; TIME
AB In this paper we present a novel moment-based skeleton detection for representing human objects in RGB-D videos with animated 3D skeletons. An object often consists of several parts, where each of them can be concisely represented with a skeleton. However, it remains as a challenge to detect the skeletons of individual objects in an image since it requires an effective part detector and a part merging algorithm to group parts into objects. In this paper, we present a novel fully unsupervised learning framework to detect the skeletons of human objects in a RGB-D video. The skeleton modeling algorithm uses a pipeline architecture which consists of a series of cascaded operations, i.e., symmetry patch detection, linear time search of symmetry patch pairs, part and symmetry detection, symmetry graph partitioning, and object segmentation. The properties of geometric moment-based functions for embedding symmetry features into centers of symmetry patches are also investigated in detail. As compared with the state-of-the-art deep learning approaches for skeleton detection, the proposed approach does not require tedious human labeling work on training images to locate the skeleton pixels and their associated scale information. Although our algorithm can detect parts and objects simultaneously, a pre-learned convolution neural network (CNN) can be used to locate the human object from each frame of the input video RGB-D video in order to achieve the goal of constructing real-time applications. This much reduces the complexity to detect the skeleton structure of individual human objects with our proposed method. Using the segmented human object skeleton model, a video surveillance application is constructed to verify the effectiveness of the approach. Experimental results show that the proposed method gives good performance in terms of detection and recognition using publicly available datasets.
C1 [Cheng, Shyi-Chyi; Hsiao, Po-Fu; Yu, Wan-Hsuan] Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, 2 Pei Ning Rd, Keelung 202, Taiwan.
   [Hsiao, Kuei-Fang; Yang, Chen-Kuei] Ming Chuan Univ, Dept Informat Management, 5 De Ming Rd, Taoyuan 333, Taiwan.
C3 National Taiwan Ocean University; Ming Chuan University
RP Hsiao, KF (corresponding author), Ming Chuan Univ, Dept Informat Management, 5 De Ming Rd, Taoyuan 333, Taiwan.
EM csc@mail.ntou.edu.tw; kfhsiao@mail.mcu.edu.tw
RI Cheng, Shyi-Chyi/ABD-1552-2020
CR Alexiadis DS, 2013, IEEE T MULTIMEDIA, V15, P339, DOI 10.1109/TMM.2012.2229264
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], 2012, P IEEE C COMP VIS PA
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barnachon M, 2014, PATTERN RECOGN, V47, P238, DOI 10.1016/j.patcog.2013.06.020
   Berg T, 2013, P IEEE C COMP VIS PA
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Buluc A, 2015, ARXIV13113144V3CSDS
   Cheng SC, 2016, MULTIMED TOOLS APPL, V75, P12919, DOI 10.1007/s11042-015-2548-y
   Chuan CH, 2016, P INT C ADV INF NETW
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Donahue J, 2014, PR MACH LEARN RES, V32
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Goring C, 2014, IEEE C COMP VIS PATT
   Gourgari S, 2013, IEEE COMPUT SOC CONF, P676, DOI 10.1109/CVPRW.2013.102
   Halim A, 2016, IEEE INT C IM PROC I
   Hanson RJ., 1974, SOLVING LEAST SQUARE
   Harandi MT, 2014, P EUR C COMP VIS ECC
   He Kaiming, 2018, ARXIV170306870V3CSCV
   Hsieh JW, 2014, IEEE T INTELL TRANSP, V15, P6, DOI 10.1109/TITS.2013.2294646
   Klank U, 2009, P IEEE INT C ROB AUT
   Lee TSH, 2013, IEEE I CONF COMP VIS, P1753, DOI 10.1109/ICCV.2013.220
   Levinshtein A, 2009, IEEE I CONF COMP VIS, P2162, DOI 10.1109/ICCV.2009.5459472
   Liao LC, 2017, IEEE INT C BIOINFORM, P1583, DOI 10.1109/BIBM.2017.8217896
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Loy G, 2006, LECT NOTES COMPUT SC, V3952, P508
   Lucchi A, 2011, IEEE I CONF COMP VIS, P9, DOI 10.1109/ICCV.2011.6126219
   Mitra NJ, 2013, COMPUT GRAPH FORUM, V32, P1, DOI 10.1111/cgf.12010
   Muller M., 2007, Tech. Rep. CG-2007-2
   Munaro M, 2013, PERSON REIDENTIFICAT
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   PEI SC, 1992, PATTERN RECOGN, V25, P913, DOI 10.1016/0031-3203(92)90057-P
   Pierobon M, 2007, P INT C SIGN PROC MU, P8
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Saha PK, 2016, PATTERN RECOGN LETT, V76, P3, DOI 10.1016/j.patrec.2015.04.006
   Shen DG, 1999, IEEE T PATTERN ANAL, V21, P466, DOI 10.1109/34.765657
   Shen W, 2017, IEEE T IMAGE PROCESS, V26, P5298, DOI 10.1109/TIP.2017.2735182
   Sironi A, 2014, PROC CVPR IEEE, P2697, DOI 10.1109/CVPR.2014.351
   Slnen W., 2016, P CVPR
   Su JY, 2015, SYMMETRY-BASEL, V7, P427, DOI 10.3390/sym7020427
   Tsogkas S, 2012, LECT NOTES COMPUT SC, V7578, P41, DOI 10.1007/978-3-642-33786-4_4
   Tzimiropoulos G, 2009, IEEE T IMAGE PROCESS, V18, P125, DOI 10.1109/TIP.2008.2007050
   Vainstein J, 2014, LECT NOTES COMPUT SC, V8827, P909, DOI 10.1007/978-3-319-12568-8_110
   Webb Jarrett., 2012, Beginning Kinect Programming with the Microsoft Kinect SDK
   Widynski N, 2014, IEEE T IMAGE PROCESS, V23, P5309, DOI 10.1109/TIP.2014.2365140
   Xiang Y, 2012, INT C PATT RECOG, P1403
   Yao BZ, 2014, IEEE T PATTERN ANAL, V36, P436, DOI 10.1109/TPAMI.2013.144
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang QP, 2007, IEEE T IMAGE PROCESS, V16, P310, DOI 10.1109/TIP.2006.887731
NR 51
TC 1
Z9 1
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 15829
EP 15857
DI 10.1007/s11042-018-6292-y
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600004
DA 2024-07-18
ER

PT J
AU Hu, K
   Liu, S
   Zhang, Y
   Cao, CH
   Xiao, F
   Huang, W
   Gao, XP
AF Hu, Kai
   Liu, Si
   Zhang, Yuan
   Cao, Chunhong
   Xiao, Fen
   Huang, Wei
   Gao, Xieping
TI Automatic segmentation of dermoscopy images using saliency combined with
   adaptive thresholding based on wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency map; Adaptive thresholding; Wavelet transform; Dermoscopy
   images; Segmentation
ID PIGMENTED SKIN-LESIONS; GEODESIC PROPAGATION; DIAGNOSIS
AB Segmentation is the essential requirement in automated computer-aided diagnosis (CAD) of skin diseases. In this paper, we propose an unsupervised skin lesion segmentation method to challenge the difficulties existing in the dermoscopy images such as low contrast, border indistinct, and skin lesion is close to the boundary. The proposed method combines the enhanced fusion saliency with adaptive thresholding based on wavelet transform to get the lesion regions. Firstly, a fusion saliency map increases the contract of the skin lesion and healthy skin, and then an adaptive thresholding method based on wavelet transform is used to obtain more accurate lesion regions. We compare the proposed method with seven state-of-the-art approaches using a series of evaluation metrics on both PH2 and ISBI2016 datasets. The results demonstrate the effectiveness of the proposed method superior to the state-of-the-art approaches in accordance with quantitative results and visual effects.
C1 [Hu, Kai; Liu, Si; Zhang, Yuan; Cao, Chunhong; Xiao, Fen; Gao, Xieping] Xiangtan Univ, Key Lab Intelligent Comp & Informat Proc, Minist Educ, Xiangtan 411105, Peoples R China.
   [Hu, Kai] Xiangtan Univ, Postdoctoral Res Stn Mech, Xiangtan 411105, Peoples R China.
   [Huang, Wei] First Hosp Changsha, Dept Radiol, Changsha 410005, Peoples R China.
C3 Xiangtan University; Xiangtan University
RP Hu, K (corresponding author), Xiangtan Univ, Key Lab Intelligent Comp & Informat Proc, Minist Educ, Xiangtan 411105, Peoples R China.; Hu, K (corresponding author), Xiangtan Univ, Postdoctoral Res Stn Mech, Xiangtan 411105, Peoples R China.
EM kaihu@xtu.edu.cn
RI hu, kai/HSG-5888-2023; Huang, Wei/V-2638-2018
OI Huang, Wei/0000-0002-0973-8015; Xiao, Fen/0000-0001-7511-9418
CR Abuzaghleh O, 2015, IEEE J TRANSL ENG HE, V3, DOI 10.1109/JTEHM.2015.2419612
   Ahn E, 2017, IEEE J BIOMED HEALTH, V21, P1685, DOI 10.1109/JBHI.2017.2653179
   Ahn E, 2015, IEEE ENG MED BIO, P3009, DOI 10.1109/EMBC.2015.7319025
   Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   Alcón JF, 2009, IEEE J-STSP, V3, P14, DOI 10.1109/JSTSP.2008.2011156
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   Basalamah S, 2012, INT J COMPUT SCI NET, V12, P40
   Bernard W.S., 2014, World Cancer Report 2014
   Borji A., 2012, 2012 IEEE COMPUTER S, P23, DOI 10.1109/CVPRW.2012.6239191
   Celebi ME, 2008, SKIN RES TECHNOL, V14, P347, DOI 10.1111/j.1600-0846.2008.00301.x
   Chen XW, 2012, LECT NOTES COMPUT SC, V7574, P553, DOI 10.1007/978-3-642-33712-3_40
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Fan HD, 2017, COMPUT BIOL MED, V85, P75, DOI 10.1016/j.compbiomed.2017.03.025
   Garnavi R, 2011, COMPUT MED IMAG GRAP, V35, P105, DOI 10.1016/j.compmedimag.2010.08.001
   Guo MW, 2014, NEUROCOMPUTING, V144, P184, DOI 10.1016/j.neucom.2014.04.054
   Hu K, 2018, NEUROCOMPUTING, V309, P179, DOI 10.1016/j.neucom.2018.05.011
   Hu K, 2011, IEEE T INSTRUM MEAS, V60, P462, DOI 10.1109/TIM.2010.2051060
   HUANG LK, 1995, PATTERN RECOGN, V28, P41, DOI 10.1016/0031-3203(94)E0043-K
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jahanifar M, 2019, IEEE J BIOMED HEALTH, V23, P509, DOI 10.1109/JBHI.2018.2839647
   Jin X, 2019, OPT LASER TECHNOL, V110, P191, DOI 10.1016/j.optlastec.2018.08.009
   Kasmi R, 2016, SKIN RES TECHNOL, V22, P208, DOI 10.1111/srt.12252
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Lee T, 1997, COMPUT BIOL MED, V27, P533, DOI 10.1016/S0010-4825(97)00020-6
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li Q, 2014, IEEE T IMAGE PROCESS, V23, P4812, DOI 10.1109/TIP.2014.2358193
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Mendonça T, 2013, IEEE ENG MED BIO, P5437
   Navarro F, 2019, IEEE J BIOMED HEALTH, V23, P501, DOI 10.1109/JBHI.2018.2825251
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pathan S, 2018, BIOMED SIGNAL PROCES, V39, P237, DOI 10.1016/j.bspc.2017.07.010
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Silveira M, 2009, IEEE J-STSP, V3, P35, DOI 10.1109/JSTSP.2008.2011119
   Wang L., 2016, 7 INT WORKSH MLMI 20
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang X, 2017, MED IMAGE ANAL, V42, P212, DOI 10.1016/j.media.2017.08.006
   Yüksel ME, 2009, IEEE T FUZZY SYST, V17, P976, DOI 10.1109/TFUZZ.2009.2018300
   Zeng B, 2018, 18 PAC RIM C MULT, V10736
   Zhang XP, 2001, IEEE T IMAGE PROCESS, V10, P1020, DOI 10.1109/83.931096
   Zhang Y, 2018, J NETW COMPUT APPL, V117, P10, DOI 10.1016/j.jnca.2018.05.007
   Zhao YT, 2017, IEEE T MED IMAGING, V36, P51, DOI 10.1109/TMI.2016.2593725
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zortea M, 2017, PATTERN RECOGN, V64, P92, DOI 10.1016/j.patcog.2016.10.031
NR 47
TC 17
Z9 18
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14625
EP 14642
DI 10.1007/s11042-019-7160-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900018
DA 2024-07-18
ER

PT J
AU Hu, K
   Zhang, SY
   Zhao, XY
AF Hu, Kun
   Zhang, Shuyou
   Zhao, Xinyue
TI Context-based conditional random fields as recurrent neural networks for
   image labeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image labeling; conditional Radom field; Convolutional neural network;
   recurrent neural network
AB This paper proposes new form of convolutional neural network that combines Convolutional Neural Networks (CNNs) and Conditional Random Fields (CRF) based probabilistic graphical modelling, which solve pixel level image labeling problem. In order to reduce the restrictions of deep learning techniques to delineate visual objects,the method fully integrates CRF modelling with CNNs, making it possible to train the whole deep network end-to-end with the usual back-propagation algorithm, avoiding offline post-processing methods for object delineation. Results show that the method is highly accurate and effective. The great result of the experiment have been achieved on the challenging Pascal VOC 2012 segmentation benchmark.
C1 [Hu, Kun; Zhang, Shuyou; Zhao, Xinyue] Zhejiang Univ, Dept Mech Engn, Hangzhou, Peoples R China.
   [Hu, Kun] PLA Univ Sci & Engn, Dept Informat Technol, Nanjing, Peoples R China.
C3 Zhejiang University
RP Hu, K (corresponding author), Zhejiang Univ, Dept Mech Engn, Hangzhou, Peoples R China.; Hu, K (corresponding author), PLA Univ Sci & Engn, Dept Informat Technol, Nanjing, Peoples R China.
EM nanjing_hukun@sina.com
CR [Anonymous], 2014, IEEE CVPR
   [Anonymous], 2015, P IEEE INT C COMP VI
   [Anonymous], 2015, ICLR
   He XM, 2004, PROC CVPR IEEE, P695
   Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5
   Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0
   Krahenbuhl Philipp, ADV NEURAL INFORM PR, P109
   Nematollahi M, 2014, IEEE IMAGE PROC, P5876, DOI 10.1109/ICIP.2014.7026187
   Parikh D., 2008, CVPR, P1
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Toyoda T, 2008, IEEE T PATTERN ANAL, V30, P1483, DOI 10.1109/TPAMI.2008.105
   Vineet V, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.73
   Zhang YM, 2012, PROC CVPR IEEE, P582, DOI 10.1109/CVPR.2012.6247724
NR 14
TC 4
Z9 4
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 17135
EP 17145
DI 10.1007/s11042-019-7564-x
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600074
DA 2024-07-18
ER

PT J
AU Yan-chun, G
AF Yan-chun, Guo
TI Fractional- order T- S fuzzy predictive control based free- form Surface
   reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractional; order; T; S fuzzy; Predictive control; Free; form surface;
   Reconstruction
ID MODEL
AB The modeling method is generally used to reconstruct the optical surface as a whole for the optical free- form surface with large gradient change. However, the reconstruction accuracy is limited that cannot meet the requirements, and the local characteristics of the surface cannot be accurately characterized. Therefore, a fast surface reconstruction method based on fractional- order T- S fuzzy predictive control is proposed by this paper. By constructing a hierarchical structure of a given data set and the method of layer- by- layer precision, the effect of global surface reconstruction is achieved, solving the problem caused by the use of local support radial basis functions. In addition, a strategy based on T- S fuzzy predictive control system is designed, and the asymptotic stability theorem of the T- S fuzzy predictive control system is proposed and proved. On this basis, the asymptotic stability of the fractional- order T- S fuzzy error system is proved, and the selection method of the gain matrix is given. The experimental results show that the proposed method is also suitable for the surface reconstruction of point cloud data with extremely uneven distribution or noise.
C1 [Yan-chun, Guo] Xianyang Normal Univ, Coll Math & Informat Sci, Xianyang, Peoples R China.
C3 Xianyang Normal University
RP Yan-chun, G (corresponding author), Xianyang Normal Univ, Coll Math & Informat Sci, Xianyang, Peoples R China.
EM chengyang4a@163.com
CR Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Arunkumar N, 2019, SOFT COMPUT, V23, P9083, DOI 10.1007/s00500-018-3618-7
   Arunkumar N, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4962
   Burger PC, 1998, AM J SURG PATHOL, V22, P1083, DOI 10.1097/00000478-199809000-00007
   Elamaran V, 2018, IEEE ACCESS, V6, P62874, DOI 10.1109/ACCESS.2018.2876119
   Giorgio A, 2004, AM J ROENTGENOL, V183, P1319, DOI 10.2214/ajr.183.5.1831319
   Guo Y, 2010, CANCER RES, V70, P1555, DOI 10.1158/0008-5472.CAN-09-3067
   Jiao DD, 2019, FUTURE GENER COMP SY, V92, P324, DOI 10.1016/j.future.2018.10.019
   Kalligeros E, 2002, J ELECTRON TEST, V18, P315, DOI 10.1023/A:1015039323168
   Khamparia A, 2020, NEURAL COMPUT APPL, V32, P11083, DOI 10.1007/s00521-018-3896-0
   Kim KH, 2015, J SCI COMPUT, V65, P431, DOI 10.1007/s10915-014-9970-6
   Lakshmanaprabu SK, 2019, FUTURE GENER COMP SY, V92, P374, DOI 10.1016/j.future.2018.10.009
   Lakshmi Nayak MD, 2010, CANCER, V115, P1947, DOI [10.1002/cncr.24203, DOI 10.1002/CNCR.24203]
   LEE YTNM, 1983, CANCER TREAT REV, V10, P91, DOI 10.1016/0305-7372(83)90007-5
   Li HY, 2019, FUTURE GENER COMP SY, V98, P69, DOI 10.1016/j.future.2018.12.001
   Liu JJ, 2018, IEEE ACCESS, V6, P61457, DOI 10.1109/ACCESS.2018.2876135
   Liu TQ, 2014, INT J ELECTRON, V101, P1217, DOI 10.1080/00207217.2013.828189
   Ma XQ, 2005, CANCER RES, V65, P5730, DOI 10.1158/0008-5472.CAN-04-4519
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Santamaria-Granados L, 2019, IEEE ACCESS, V7, P57, DOI 10.1109/ACCESS.2018.2883213
   Tan E, 2009, INT C COMM
   Wang ZY, 2009, J COMPUT PHYS, V228, P5819, DOI 10.1016/j.jcp.2009.04.045
   Wei-Cheng Lien, 2012, 2012 21st Asian Test Symposium (ATS 2012). Proceedings, P278, DOI 10.1109/ATS.2012.11
   Wu ZC, 2019, FUTURE GENER COMP SY, V93, P170, DOI 10.1016/j.future.2018.10.018
NR 24
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16955
EP 16966
DI 10.1007/s11042-019-7534-3
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600063
DA 2024-07-18
ER

PT J
AU Zhong, WL
   Jiang, LF
   Zhang, T
   Ji, JS
   Xiong, HL
AF Zhong, Weilin
   Jiang, Linfeng
   Zhang, Tao
   Ji, Jinsheng
   Xiong, Huilin
TI A part-based attention network for person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Part-based attention model; Global-local
   complementary effects
ID RECOGNITION
AB Person re-identification (re-id) is the task of recognizing images of the same pedestrian captured by different cameras with non-overlapping views. Person re-id is a challenging task due to the existence of large view variations, such as spatial misalignment, background clutter and human poses change. In this paper, we handle these challenges from the following two aspects: utilizing attention mechanism to alleviate misalignment problem and exploiting the complementary effects of global-local features for more stable pedestrian descriptors. Specifically, we first present a part-based attention model consisting of a channel attention block and a spatial attention block to sequentially refine the convolutional descriptors of person body parts. The channel and spatial attention blocks weight the channels and positions of body-part feature maps to spot the informative channels and regions, respectively. Then global full-body and local body-part of the refined feature maps are pooled into global and local representations, which are jointly trained using identity classification loss. We conduct extensive experiments on four standard benchmark datasets including Market1501, CUHK03, DukeMTMC-reID, and CUHK01, and the experimental results demonstrate the effectiveness of the presented method.
C1 [Zhong, Weilin; Jiang, Linfeng; Zhang, Tao; Ji, Jinsheng; Xiong, Huilin] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
   [Zhong, Weilin; Jiang, Linfeng; Zhang, Tao; Ji, Jinsheng; Xiong, Huilin] Shanghai Jiao Tong Univ, Inst Sensing & Nav, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Xiong, HL (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.; Xiong, HL (corresponding author), Shanghai Jiao Tong Univ, Inst Sensing & Nav, Shanghai, Peoples R China.
EM hlxiong@sjtu.edu.cn
RI JI, JINSHENG/KHW-3948-2024; huang, libo/JMB-4345-2023
OI JI, JINSHENG/0000-0002-5360-919X; 
FU National Natural Science Foundation of China [61673274]; Shanghai
   Science and Technology Commission Scientific Research Project
   [17DZ1100803]
FX This study is partially supported by the National Natural Science
   Foundation of China under Grant 61673274, and Shanghai Science and
   Technology Commission Scientific Research Project with project Nos.
   17DZ1100803.
CR [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   [Anonymous], 2016, NEUROCOMPUTING, DOI [DOI 10.1016/J.NEUC0M.2015.09.116, DOI 10.1016/J.NEUCOM.2015.09.116, 10. 1016/j.neucom.2015.09.116]
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davis J. V., 2007, ICML, P209
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gao MF, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1077, DOI 10.1109/FSKD.2017.8392913
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermans Alexander, 2017, ARXIV170307737
   Hirzer M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P203, DOI 10.1109/AVSS.2012.55
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Khamis S, 2015, LECT NOTES COMPUT SC, V8927, P134, DOI 10.1007/978-3-319-16199-0_10
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kviatkovsky I, 2013, IEEE T PATTERN ANAL, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Li D, 2017, INT SYM COMPUT INTEL, P338, DOI 10.1109/ISCID.2017.51
   LI W, 2012, P AS C COMP VIS, P31
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Moon H, 2001, PERCEPTION, V30, P303, DOI 10.1068/p2896
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salakhutdinov, 2015, ARXIV151104119
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Schumann A, 2017, IEEE COMPUT SOC CONF, P1435, DOI 10.1109/CVPRW.2017.186
   Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Sun ZM, 2018, INT C COMP SUPP COOP, P501, DOI 10.1109/CSCWD.2018.8465310
   Teixeira B, 2018, PROC CVPR IEEE, P9059, DOI 10.1109/CVPR.2018.00944
   TianyiZhou J., 2018, ARXIV180711042
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang Y, 2018, PROC CVPR IEEE, P8042, DOI [10.1109/CVPR.2018.00839, 10.1109/CVPR.2018.00736]
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu L., 2016, ARXIV160107255
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong WL, 2019, J VIS COMMUN IMAGE R, V62, P267, DOI 10.1016/j.jvcir.2019.06.001
   Zhong WL, 2019, NEUROCOMPUTING, V334, P68, DOI 10.1016/j.neucom.2019.01.005
   Zhong WL, 2018, INT C PATT RECOG, P1857, DOI 10.1109/ICPR.2018.8545225
   Zhong WL, 2017, IEEE IMAGE PROC, P1562, DOI 10.1109/ICIP.2017.8296544
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 78
TC 7
Z9 11
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22525
EP 22549
DI 10.1007/s11042-019-08395-2
EA MAY 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000535434200001
DA 2024-07-18
ER

PT J
AU Gupta, M
   Gupta, M
   Deshmukh, M
AF Gupta, Mayank
   Gupta, Manu
   Deshmukh, Maroti
TI Single secret image sharing scheme using neural cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret sharing; Neural cryptography; Synchronization; Boolean XOR; Tree
   parity machine; Hebbian learning; Encryption; Decryption
ID ENCRYPTION
AB The goal of the secret sharing is to share a secret information without any leakage to others. In this paper, we proposed a secure mechanism of sharing secret shares of an image between two parties generated via Shamir's scheme with the help of neural cryptography. Neural cryptography is a new source for public key cryptography schemes which are not based on number theory, and have less computation time and memory complexities. Neural cryptography can be used to generate a common secret key between two parties. Keeping all these in mind, our main focus is to share secret information over a public channel with less computation power. In the case of neural cryptography, both the parties receive an identical input vector, generate an output bit and are trained based on the output bit. The dynamics of the two networks and their weight vectors is found to exhibit a synchronization state with identical weights. These identical weights are acts as a common key between two parties. The proposed scheme is secure and does not reveal secret information.
C1 [Gupta, Mayank; Gupta, Manu; Deshmukh, Maroti] Natl Inst Technol, Srinagar, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand
RP Gupta, M (corresponding author), Natl Inst Technol, Srinagar, Uttarakhand, India.
EM gmayank386@gmail.com; guptamanu530@gmail.com; marotideshmukh@nituk.ac.in
RI Deshmukh, Dr. Maroti/AAE-2889-2022
OI Deshmukh, Maroti/0000-0002-1125-5987
CR Al-Ghamdi M, 2019, MULTIMED TOOLS APPL, V78, P16283, DOI 10.1007/s11042-018-6977-2
   Bao L, 2017, IEEE T IMAGE PROCESS, V26, P5618, DOI 10.1109/TIP.2017.2738561
   Boyd Colin., 2013, PROTOCOLS AUTHENTICA
   Chen CC, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P515
   Chen TH, 2013, J SYST SOFTWARE, V86, P1267, DOI 10.1016/j.jss.2012.12.022
   Deshmukh M, 2016, ENHANCED MODULO BASE, P212
   Deshmukh M, 2019, KNOWL INF SYST, V60, P1377, DOI 10.1007/s10115-018-1268-9
   Deshmukh M, 2018, MULTIMED TOOLS APPL, V77, P89, DOI 10.1007/s11042-016-4229-x
   Deshmukh M, 2017, J VIS COMMUN IMAGE R, V49, P291, DOI 10.1016/j.jvcir.2017.09.013
   Deshmukh M, 2016, INT CON ADV INFO NET, P690, DOI 10.1109/AINA.2016.56
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Forouzan B.A., 2011, Cryptography and Network Security (Sie)
   Ghasemi R, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3399
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gupta B.B., 2018, Computer and Cyber Security: Principles, Algorithm, Applications, and Perspectives
   Gutub A, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0216-0
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Hagan M.T., 2014, Neural Networks Design, V2nd
   Hamza Rafik, 2019, Machine Learning for Cyber Security. Second International Conference, ML4CS 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11806), P271, DOI 10.1007/978-3-030-30619-9_19
   Hamza R., 2019, INFORM SCI
   Hertz J., 1991, LECT NOTES SANTA FE
   Kanter I, 2002, EUROPHYS LETT, V57, P141, DOI 10.1209/epl/i2002-00552-9
   Klimov A, 2002, LECT NOTES COMPUT SC, V2501, P288
   Mislovaty R, 2004, ICECS 2004: 11TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS AND SYSTEMS, P219
   Nankun Mu, 2013, Advances in Neural Networks - ISNN 2013. 10th International Symposium on Neural Networks. Proceedings: LNCS 7951, P99, DOI 10.1007/978-3-642-39065-4_13
   Rajput Mohit, 2016, 2016 International Conference on Information Technology (ICIT). Proceedings, P51, DOI 10.1109/ICIT.2016.023
   Rajput M, 2016, INFORM PROCESS, V10, P2016
   Rajput M, 2018, IEEE CONSUM ELECTR M, V7, P40, DOI 10.1109/MCE.2017.2716412
   Rajput M, 2016, PROCEDIA COMPUT SCI, V89, P677, DOI 10.1016/j.procs.2016.06.034
   Reyes OM, 2009, J PHYS A-MATH THEOR, V42, DOI 10.1088/1751-8113/42/19/195002
   Riad K, 2019, IEEE ACCESS, V7, P86384, DOI 10.1109/ACCESS.2019.2926354
   Rosen-Zvi M, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.066135
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shivani S, 2018, MULTIMED TOOLS APPL, V77, P6287, DOI 10.1007/s11042-017-4536-x
   Stallings W., 2006, Cryptography and Network Security, V4th
   STALLINGS W, 2017, CRYPTOGRAPHY NETWORK, P92
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Stinson D. R., 2005, CRYPTOGRAPHY THEORY
   Tewari A, 2017, J SUPERCOMPUT, V73, P1085, DOI 10.1007/s11227-016-1849-x
   Tsai DS, 2008, IMAGING SCI J, V56, P49, DOI 10.1179/174313107X214330
   Volkmer M, 2005, IACR CRYPTOLOGY EPRI, V2005, P235
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
NR 42
TC 13
Z9 13
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12183
EP 12204
DI 10.1007/s11042-019-08454-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400041
DA 2024-07-18
ER

PT J
AU Hariss, K
   Noura, H
   Samhat, AE
AF Hariss, Khalil
   Noura, Hassan
   Samhat, Abed Ellatif
TI An efficient fully homomorphic symmetric encryption algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fully homomorphic encryption; Secure multimedia processing; Dynamic
   diffusion and permutation primitives; Polynomial resultant; Known
   plain-text attack
AB In this paper, we consider Homomorphic Encryption (HE) to process over encrypted data to achieve users privacy. We present a framework solution that provides a high level of security for the symmetric HE algorithms. The proposed solution introduces a dynamic structure and a dynamic diffusion primitives that enhance existing symmetric HE algorithms and overcome their weaknesses. Domingo Ferrer is a well known symmetric HE scheme that relies on polynomial computations but at the same time suffers from some vulnerabilities and especially sensitivity to known plain-text attack. We apply the concerned dynamic framework over the Domingo Ferrer encryption scheme to overcome its main weaknesses. Security analysis of the new encryption scheme that we called Enhanced Domingo Ferrer has shown that the latter became immune to several types of attack especially known plain-text attack. Crypt-analysis has also shown that this new implementation will be secure also with the lowest possible storage overhead. Implementation of the new scheme has shown an acceptable execution time. All the new specifications listed previously make the scheme a good candidate for efficiently preserving users privacy in a big variety of real-world modern applications.
C1 [Hariss, Khalil; Samhat, Abed Ellatif] Lebanese Univ, Fac Engn CRSI, Hadath, Lebanon.
   [Hariss, Khalil] St Joseph Univ, ESIB, Engn Sch, Beirut, Lebanon.
   [Noura, Hassan] Amer Univ Beirut, Dept Elect & Comp Engn, Beirut, Lebanon.
   [Noura, Hassan] Arab Open Univ, Dept Comp Sci, Beirut, Lebanon.
C3 Lebanese University; American University of Beirut
RP Noura, H (corresponding author), Amer Univ Beirut, Dept Elect & Comp Engn, Beirut, Lebanon.; Noura, H (corresponding author), Arab Open Univ, Dept Comp Sci, Beirut, Lebanon.
EM hn49@aub.edu.lb
RI Noura, Hassan/U-8729-2018
OI SAMHAT, Abed Ellatif/0000-0002-1137-621X; Noura,
   Hassan/0000-0002-2589-5053
CR Aguilar-Melchor C, 2013, IEEE SIGNAL PROC MAG, V30, P108, DOI 10.1109/MSP.2012.2230219
   Anggriane SM, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATICS AND COMPUTING (ICIC), P338, DOI 10.1109/IAC.2016.7905741
   [Anonymous], 2009, FULLY HOMOMORPHIC EN, DOI 10.1145/1536414.1536440
   [Anonymous], INT ASS CRYPTOGR RES
   [Anonymous], 2015, IEEE INT C ELECT COM, DOI DOI 10.1109/ICECCT.2015.7226064
   Brakerski Zvika, 2014, ACM Transactions on Computation Theory, V6, DOI 10.1145/2633600
   BRENT RP, 1987, DISCRETE MATH, V66, P35, DOI 10.1016/0012-365X(87)90117-8
   Chan ACF, 2009, IEEE ICC, P774
   Chauhan KK, 2015, 2015 14TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (ICIT 2015), P206, DOI 10.1109/ICIT.2015.39
   Chen YM, 2012, LECT NOTES COMPUT SC, V7237, P502, DOI 10.1007/978-3-642-29011-4_30
   Coron JS, 2011, LECT NOTES COMPUT SC, V6841, P487, DOI 10.1007/978-3-642-22792-9_28
   Domingo-Ferrer J, 2002, LECT NOTES COMPUT SC, V2433, P471
   Fau S, 2013, 2013 EIGHTH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND INTERNET COMPUTING (3PGCIC 2013), P284, DOI 10.1109/3PGCIC.2013.48
   Ferrer JDI, 1996, INFORM PROCESS LETT, V60, P277, DOI 10.1016/S0020-0190(96)00170-6
   Fontaine C, 2007, EURASIP J INF SECUR, DOI 10.1155/2007/13801
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   Haridas D, 2012, 2012 2ND IEEE INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P491, DOI 10.1109/PDGC.2012.6449870
   Hariss K, 2018, LECT NOTES COMPUT SC, V10694, P127, DOI 10.1007/978-3-319-76687-4_9
   Jin B, 2018, IEEE ACCESS, V6, P51140, DOI 10.1109/ACCESS.2018.2869575
   Kapusta K, 2019, ANN TELECOMMUN, V74, P157, DOI 10.1007/s12243-018-0684-x
   Kipnis A., 2012, IACR Cryptol. ePrint Arch, V2012, P637
   Kocabas O, 2014, ADV DATA MIN DATABAS, P471, DOI 10.4018/978-1-4666-5864-6.ch019
   Kwok SHM, 2008, EEE T VERY LARGE SCA, V16, P8
   Li J, 2015, IEEE T PARALL DISTR, V26, P1206, DOI 10.1109/TPDS.2014.2318320
   Li P, 2017, FUTURE GENER COMP SY, V74, P76, DOI 10.1016/j.future.2017.02.006
   Li T, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/9641273
   Mister S, 1998, SELECTED AREAS CRYPT
   Nour HF, 2015, ARKIVOC, P1, DOI 10.3998/ark.5550190.p008.875
   Noura H, 2019, AD HOC NETW, P101937
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Sharma Iti., 2013, Fully Homomorphic Encryption Scheme with Symmetric Keys
   Sylvester J., 1851, REMARKABLE DISCOVERY
   van Dijk M, 2010, LECT NOTES COMPUT SC, V6110, P24
   Vogel M, 2010, CONTEMP PHYS, V51, P283, DOI [10.1080/00107510903184414, DOI 10.1080/00107510903184414]
   Wagner D, 2003, LECT NOTES COMPUT SC, V2851, P234
   Wang LC, 2019, IEEE INTERNET THINGS, V6, P1402, DOI 10.1109/JIOT.2018.2844727
   Xiao Liangliang., 2012, IACR CRYPTOLOGY EPRI, V2012, P193
   Yang P, 2017, IMAGE PROCESS SERV S, V2017, P11
   Yi ZH, 2010, PROCEEDINGS OF THE 2010 INTERNATIONAL CONFERENCE ON MECHANICAL, INDUSTRIAL, AND MANUFACTURING TECHNOLOGIES (MIMT 2010), P1, DOI 10.1115/1.859544.paper1
NR 39
TC 10
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12139
EP 12164
DI 10.1007/s11042-019-08511-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400039
DA 2024-07-18
ER

PT J
AU Rana, S
   Mishra, D
AF Rana, Saurabh
   Mishra, Dheerendra
TI Secure and ubiquitous authenticated content distribution framework for
   IoT enabled DRM system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital content; Digital rights management systems; Key agreement;
   Security; Privacy
ID SCHEME; INTERNET; DEVICES
AB Internet of Things (IoT) is increasingly used through smart devices with internet-based networks. Communication and data sharing between these devices have also grown in several ways. It is presenting a new dimension to the whole digital right management (DRM) industry. The main focus of IoT based DRM technology is to facilitate the authorised user for using multimedia content through smart devices. However, threats of information breach between communication channels also rapidly increasing, which is making content distribution a challenging task. Moreover, the computation and communication efficiency along with user privacy also requires an ideal DRM system. To address concerns of security, efficiency and privacy over internet-based networks, we design a content key distribution framework for DRM systems. The security proof of the proposed framework is given in the random oracle model along with informal security analysis. Moreover, the security analysis performed using widely adopted simulation tool, namely, "Automated Validation of Internet Security Protocol and Application (AVISPA)". The study of performance is conducted, which indicates that it fulfils the requirements of computation and computation efficiency.
C1 [Rana, Saurabh; Mishra, Dheerendra] LNM Inst Informat Technol, Dept Math, Jaipur, Rajasthan, India.
C3 LNM Institute of Information Technology
RP Mishra, D (corresponding author), LNM Inst Informat Technol, Dept Math, Jaipur, Rajasthan, India.
EM saurabhrana.y16@lnmiit.ac.in; dheerendra.m@gmail.com
RI Mishra, Dheerendra/C-4208-2017
OI Mishra, Dheerendra/0000-0001-8115-6397
FU Science and Engineering Research Board [ECR/2015/000243]
FX This work is supported by Science and Engineering Research Board under
   File No:ECR/2015/000243.
CR [Anonymous], 2006, ERCIM NEWS
   Armando A, 2005, LECT NOTES COMPUT SC, V3576, P281
   Ashton K., 2009, RFID J, V22, P97
   Bellare M, 2000, LECT NOTES COMPUT SC, V1807, P139
   Chang CC, 2013, SECUR COMMUN NETW, V6, P972, DOI 10.1002/sec.647
   Chang CC, 2010, EXPERT SYST APPL, V37, P6176, DOI 10.1016/j.eswa.2010.02.110
   Chen CL, 2008, EXPERT SYST APPL, V35, P878, DOI 10.1016/j.eswa.2007.07.029
   Chen H, 2018, MIN TECHNOL, P1
   Chen YY, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 3, PROCEEDINGS, P11, DOI 10.1109/ISDA.2008.301
   Conrado C, 2003, 14TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P389, DOI 10.1109/DEXA.2003.1232053
   Cope WB, 2013, US Patent, Patent No. [8,353,048, 8353048]
   Das AK, 2015, SECUR COMMUN NETW, V8, P3383, DOI 10.1002/sec.1266
   Dodis Y, 2004, LECT NOTES COMPUT SC, V3027, P523
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   Jizhong Wang, 2018, International Journal of High Performance Computing and Networking, V12, P111
   Jung J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169414
   Kim H, 2007, LECT NOTES COMPUT SC, V4846, P78
   Lee CC, 2018, INF TECHNOL CONTROL, V47, P262, DOI 10.5755/j01.itc.47.2.18506
   Lee CC, 2018, J INF SECUR APPL, V39, P19, DOI 10.1016/j.jisa.2018.02.001
   Lee I, 2015, BUS HORIZONS, V58, P431, DOI 10.1016/j.bushor.2015.03.008
   Lee WB, 2007, J ORG COMP ELECT COM, V17, P247, DOI 10.1080/10919390701436390
   Li CT, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0322-3
   Odelu V, 2018, IEEE T SMART GRID, V9, P1900, DOI 10.1109/TSG.2016.2602282
   Odelu V, 2015, J INF SECUR APPL, V21, P1, DOI 10.1016/j.jisa.2015.01.001
   Peinado M, 2006, US Patent, Patent No. [7,073,063, 7073063]
   Popescu D.C., 2004, INF TECH TRANS PROCE
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   Sovio S, 2003, 2003 SYMPOSIUM ON APPLICATIONS AND THE INTERNET WORKSHOPS, PROCEEDINGS, P331, DOI 10.1109/SAINTW.2003.1210181
   Sundmaeker H., 2010, CLUSTER EUROPEAN RES, V3, P34, DOI DOI 10.2759/26127
   Tewari Aakanksha, 2017, International Journal of Advanced Intelligence Paradigms, V9, P111
   Tewari A, 2017, J SUPERCOMPUT, V73, P1085, DOI 10.1007/s11227-016-1849-x
   Wang MH, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 4, PROCEEDINGS, P221, DOI 10.1109/FSKD.2007.101
   Xiao GY, 2014, IEEE T IND INFORM, V10, P1486, DOI 10.1109/TII.2014.2306772
   Zhang Y., 2009, BMC EVOL BIOL, V9, P202
NR 34
TC 10
Z9 10
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20319
EP 20341
DI 10.1007/s11042-020-08683-2
EA APR 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000526209900001
DA 2024-07-18
ER

PT J
AU Ashraf, R
   Ahmed, M
   Ahmad, U
   Habib, MA
   Jabbar, S
   Naseer, K
AF Ashraf, Rehan
   Ahmed, Mudassar
   Ahmad, Usman
   Habib, Muhammad Asif
   Jabbar, Sohail
   Naseer, Kashif
TI MDCBIR-MF: multimedia data for content-based image retrieval by using
   multiple features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content base image retrieval; Image retrieval; ColorMoments;
   GaborWaveletdescriptor; Discrete wavelet transforms; CEDD
ID FEATURE INTEGRATION; RELEVANCE FEEDBACK; TEXTURE FEATURES; COLOR;
   DESCRIPTOR; TRANSFORM; HISTOGRAM; MODEL
AB Due to recent development in technology, the complexity of multimedia is significantly increased and the retrieval of similar multimedia content is an open research problem. In the service of multimedia service, the requirement of Multimedia Indexing Technology is increasing to retrieve and search for interesting data from huge Internet. Since the traditional retrieval method, which is using textual index, has limitation to handle the multimedia data in current Internet, alternatively, the more efficient representation method is needed. Content-Based Image Retrieval (CBIR) is a process that provides a framework for image search and low-level visual features are commonly used to retrieve the images from the image database. The basic requirement in any image retrieval process is to sort the images with a close similarity in term of visual appearance. The color, shape, and texture are the examples of low-level image features. The feature combination that is also known as feature fusion is applied in CBIR to increase the performance, a single feature is not robust to the transformations that are in the image datasets. This paper represents a new Content-Based Image Retrieval (CBIR) technique to fuse the color and texture features to extract local features as our feature vector. The features are created for each image and stored as a feature vector in the database. The proposed research is divided into three phases that feature extraction, similarities match, and performance evaluation. Color Moments (CM) are used for Color features and extract the Texture features, used Gabor Wavelet and Discrete Wavelet transform. To enhance the power of feature vector representation, Color and Edge Directivity Descriptor (CEDD) is also included in the feature vector. We selected this combination, as these features are reported intuitive, compact and robust for image representation. We evaluated the performance of our proposed research by using the Corel, Corel-1500, and Ground Truth (GT) images dataset. The average precision and recall measures are used to evaluate the performance of the proposed research. The proposed approach is efficient in term of feature extraction and the efficiency and effectiveness of the proposed research outperform the existing research in term of average precision and recall values.
C1 [Ashraf, Rehan; Ahmed, Mudassar; Habib, Muhammad Asif; Jabbar, Sohail] Natl Text Univ, Dept Comp Sci, Faisalabad, Pakistan.
   [Ahmad, Usman] Lahore Coll Women Univ, Dept Comp Sci, Lahore, Pakistan.
   [Naseer, Kashif] Bahria Univ, Dept Comp Engn, Islamabad, Pakistan.
C3 National Textile University - Pakistan
RP Jabbar, S (corresponding author), Natl Text Univ, Dept Comp Sci, Faisalabad, Pakistan.
EM rehan@ntu.edu.pk; mudassar@ntu.edu.pk; usman.ahmad82@yahoo.com;
   sjabbar.research@gmail.com; kashifnaseer85@yahoo.com
RI Jabbar, Sohail/E-3052-2012
OI Jabbar, Sohail/0000-0002-2127-1235
CR Afifi A.J., 2012, Int. Sch. Res. Not, V2012, DOI [10.5402/2012/248285, DOI 10.5402/2012/248285]
   Agarwal S, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P368, DOI 10.1109/ICICICT.2014.6781310
   Ahmad J, 2015, INT C NETWB INFO, P212, DOI 10.1109/NBiS.2015.36
   [Anonymous], 2015, ARXIV150207041
   [Anonymous], 2008, INT J COMPUT SCI SEC
   Ashraf R., 2014, J BASIC APPL SCI RES, V4, P136
   Ashraf R, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0880-7
   Ashraf R, 2016, J INF SCI ENG, V32, P245
   Ashraf R, 2015, ENTROPY-SWITZ, V17, P3552, DOI 10.3390/e17063552
   Bu HH, 2017, J INF PROCESS SYST, V13, P464, DOI 10.3745/JIPS.02.0060
   Chatzichristofis S, 2007, IASTED INT C ART INT
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Chatzichristofis SA, 2010, INT J PATTERN RECOGN, V24, P207, DOI 10.1142/S0218001410007890
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   ElAdel A, 2016, MACH VISION APPL, V27, P781, DOI 10.1007/s00138-016-0789-z
   ElAlami ME, 2014, APPL SOFT COMPUT, V14, P407, DOI 10.1016/j.asoc.2013.10.003
   Fakheri M, 2013, IET IMAGE PROCESS, V7, P1, DOI 10.1049/iet-ipr.2012.0104
   Farhan M, 2017, J REAL-TIME IMAGE PR, V13, P491, DOI 10.1007/s11554-016-0662-3
   Irtaza A., 2014, SIGNAL IMAGE VIDEO P, P1
   Kokare M, 2004, PATTERN RECOGN LETT, V25, P391, DOI 10.1016/j.patrec.2003.11.008
   Lieberman H, 2001, COMPUTER, V34, P57, DOI 10.1109/2.933504
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Liu GH, 2015, AER ADV ENG RES, V22, P838
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Pavithra L, 2017, COMPUT ELECT ENG
   Piras L, 2017, INFORM FUSION, V37, P50, DOI 10.1016/j.inffus.2017.01.003
   Sankar SP, 2017, CURR MED IMAGING REV, V13, P223, DOI 10.2174/1573405612666160617082639
   Shah DM, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIVE MECHANISMS FOR INDUSTRY APPLICATIONS (ICIMIA), P284, DOI 10.1109/ICIMIA.2017.7975620
   Shleymovich M., 2017, 14 INT SCI TECHN C O
   Singh H., 2016, Springerbriefs in Electrical and Computer Engineering, P1, DOI DOI 10.1007/978-981-287-760-4
   Srivastava P, 2017, J VIS COMMUN IMAGE R, V42, P78, DOI 10.1016/j.jvcir.2016.11.008
   Stejic Z, 2003, INFORM PROCESS MANAG, V39, P1, DOI 10.1016/S0306-4573(02)00024-9
   Tian XL, 2014, SIGNAL PROCESS-IMAGE, V29, P530, DOI 10.1016/j.image.2014.01.010
   Tzelepi M, 2016, 9TH HELLENIC CONFERENCE ON ARTIFICIAL INTELLIGENCE (SETN 2016), DOI 10.1145/2903220.2903240
   Upadhyaya N., 2016, DIGITAL IMAGE PROCES, V8, P137
   Varish N, 2017, MULTIMED TOOLS APPL, V76, P15885, DOI 10.1007/s11042-016-3882-4
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang XY, 2013, COMPUT ELECTR ENG, V39, P746, DOI 10.1016/j.compeleceng.2013.01.005
   Wei GH, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0874-5
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   Yadav S, 2017, 2017 4TH IEEE UTTAR PRADESH SECTION INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND ELECTRONICS (UPCON), P1, DOI 10.1109/UPCON.2017.8251012
   Yalavarthi A, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS AND ELECTRONICS (COMPTELIX), P339, DOI 10.1109/COMPTELIX.2017.8003990
   Youssef SM, 2012, COMPUT ELECTR ENG, V38, P1358, DOI 10.1016/j.compeleceng.2012.05.010
   Yu J, 2013, NEUROCOMPUTING, V120, P355, DOI 10.1016/j.neucom.2012.08.061
   Yue J, 2011, MATH COMPUT MODEL, V54, P1121, DOI 10.1016/j.mcm.2010.11.044
   Zeng S, 2016, NEUROCOMPUTING, V171, P673, DOI 10.1016/j.neucom.2015.07.008
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhao M, 2016, CHINA COMMUN, V13, P222, DOI 10.1109/CC.2016.7563725
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
NR 49
TC 33
Z9 33
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8553
EP 8579
DI 10.1007/s11042-018-5961-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600013
DA 2024-07-18
ER

PT J
AU Jiang, LH
   Ye, S
   Yang, XM
   Ma, X
   Lu, L
   Ahmad, A
   Jeon, G
AF Jiang, Lihua
   Ye, Shuang
   Yang, Xiaomin
   Ma, Xiao
   Lu, Lu
   Ahmad, Awias
   Jeon, Gwanggil
TI An adaptive anchored neighborhood regression method for medical image
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Enhancement; Adaptive anchored neighborhood; Hypercells
ID SUPERRESOLUTION; INTERPOLATION
AB Chinese Government has launched ambitious healthcare reform aiming to provide better healthcare services for both urban and rural residents via remote diagnosis. Recently, the requirement of high-resolution (HR) images becomes more urgent in the medical field, especially for remote diagnosis. Remote diagnosis is an important means of the Internet of Medical Things (IoMT), which senses patients' health status according to the medical images and transfers clinical data. Owing to the superiority of reconstruction speed and quality, adjusted anchored neighborhood regression has attracted much attention. However, the hypercells formed by neighborhoods may not center on atoms, and hence it is not accurate to group the neighborhood centered on atoms. In this paper, we propose an adaptive medical image enhancement method. Specifically, we cluster training samples into neighborhoods centered on patches. The LR space is re-divided by replacing dictionary atoms with cluster patch centers as the center of hypercells. By this means, the neighborhood anchored in the patch is defined by computing its K nearest patches, and then applied to pre-compute the projection to map low-resolution patch onto the HR domain. Average quantitative results show that our method is superior to the compared methods in two common medical datasets by 1.19% and 2.32%, respectively, while maintaining the similar running time.
C1 [Jiang, Lihua; Ma, Xiao] Univ Sichuan, West China Sch Publ Hlth, Chengdu, Sichuan, Peoples R China.
   [Ye, Shuang; Yang, Xiaomin; Lu, Lu] Univ Sichuan, Coll Elect & Informat Engn, Chengdu, Sichuan, Peoples R China.
   [Ahmad, Awias] Univ Milan, Dipartimento Informat DI, Via Celoria 18, I-20133 Milan, MI, Italy.
   [Jeon, Gwanggil] Xidian Univ, Sch Elect Engn, Xian, Peoples R China.
   [Jeon, Gwanggil] Incheon Natl Univ, Dept Embedded Syst Engn, Incheon, South Korea.
C3 Sichuan University; Sichuan University; University of Milan; Xidian
   University; Incheon National University
RP Yang, XM; Lu, L (corresponding author), Univ Sichuan, Coll Elect & Informat Engn, Chengdu, Sichuan, Peoples R China.
EM arielyang@scu.edu.cn; lulu19900303@126.com
RI Lu, Lu/GPX-6708-2022; LU, LU/JEZ-4760-2023; yang, xiao/HJI-7815-2023;
   wang, Xiaoming/KBB-8854-2024; lu, lu/HII-7530-2022; lu, lu/HGA-0894-2022
CR [Anonymous], 2008 IEEE COMP SOC C
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Cao FL, 2015, IEEE T CIRC SYST VID, V25, P1261, DOI 10.1109/TCSVT.2014.2372351
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chianese A, 2016, IEEE INT C SEMANT CO, P458, DOI 10.1109/ICSC.2016.50
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2011, IEEE T IMAGE PROCESS, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Dou QY, 2018, SUSTAIN CITIES SOC, V42, P1, DOI 10.1016/j.scs.2018.05.028
   Duanmu CJ, 2016, 2016 INTERNATIONAL CONFERENCE ON IDENTIFICATION, INFORMATION AND KNOWLEDGE IN THE INTERNET OF THINGS (IIKI), P150, DOI 10.1109/IIKI.2016.52
   Early DS, 2001, IEEE T GEOSCI REMOTE, V39, P291, DOI 10.1109/36.905237
   Fernandez-Granda C, 2013, IEEE I CONF COMP VIS, P3336, DOI 10.1109/ICCV.2013.414
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P3194, DOI 10.1109/TIP.2012.2190080
   Greenspan H, 2009, COMPUT J, V52, P43, DOI 10.1093/comjnl/bxm075
   Huang JJ, 2015, IEEE T IMAGE PROCESS, V24, P3232, DOI 10.1109/TIP.2015.2440751
   Huang Kebin, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P409, DOI 10.1007/978-3-319-27671-7_34
   Hussain S, 2018, J PARALLEL DISTR COM, V117, P256, DOI 10.1016/j.jpdc.2017.06.022
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P15, DOI 10.1109/TMM.2016.2599145
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P27, DOI 10.1109/TMM.2016.2601020
   Lifeng Wu, 2010, 2010 IEEE International Conference on Systems, Man and Cybernetics (SMC 2010), P26, DOI 10.1109/ICSMC.2010.5642198
   Marquina A, 2008, J SCI COMPUT, V37, P367, DOI 10.1007/s10915-008-9214-8
   Park JS, 2018, IEEE ACCESS, V6, P10966, DOI 10.1109/ACCESS.2018.2797197
   Romano Y, 2014, IEEE T IMAGE PROCESS, V23, P3085, DOI 10.1109/TIP.2014.2325774
   Timofte R, 2016, PROC CVPR IEEE, P1865, DOI 10.1109/CVPR.2016.206
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang LF, 2013, IEEE T CIRC SYST VID, V23, P1289, DOI 10.1109/TCSVT.2013.2240915
   Wei Z, 2013, IEEE T IMAGE PROCESS, V22, P4271, DOI 10.1109/TIP.2013.2271849
   Wu HP, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2018.2831791
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang WH, 2018, IEEE T CIRC SYST VID, V28, P1071, DOI 10.1109/TCSVT.2016.2638864
   Ye W, 2016, IEEE SIGNAL PROC LET, V23, P1260, DOI 10.1109/LSP.2016.2571738
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2016, IEEE SIGNAL PROC LET, V23, P102, DOI 10.1109/LSP.2015.2504121
   Zhang KB, 2015, IEEE T IMAGE PROCESS, V24, P846, DOI 10.1109/TIP.2015.2389629
   Zhangyang Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301266
   Zhao JW, 2018, IET COMPUT VIS, V12, P753, DOI 10.1049/iet-cvi.2017.0153
   Zhu SY, 2016, IEEE T MULTIMEDIA, V18, P1707, DOI 10.1109/TMM.2016.2593039
NR 37
TC 7
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10533
EP 10550
DI 10.1007/s11042-019-08353-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600044
DA 2024-07-18
ER

PT J
AU Kiran, M
   Ahmed, I
   Khan, N
   Rehman, HU
   Din, S
   Paul, A
   Reddy, AG
AF Kiran, Mehreen
   Ahmed, Imran
   Khan, Nazish
   Rehman, Hamood Ur
   Din, Sadia
   Paul, Anand
   Reddy, Alavalapati Goutham
TI Comparative analysis of segmentation techniques based on chest X-ray
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chest radiography; Survey; Computer-aided diagnosis; Codes; executable;
   Commands; Lung region extraction; Segmentation
ID MEANS CLUSTERING-ALGORITHM; CONTRAST ENHANCEMENT; K-MEANS; HISTOGRAM
   EQUALIZATION
AB The image segmentation is the basic step in the image processing involved in the processing of medical images. Over the past two decades, medical image segmentation has remained a challenge for researchers while the use of this imaging modality is rapidly growing in research studies. This article surveys the techniques and their effect on chest X-ray images. The objective of this work is to study the key similarities and differences among the different published methods while highlighting their strengths and weaknesses on chest X-ray images. The reason is to assist the researchers in the choice of an appropriate lung segmentation methodology. We additionally give a complete portrayal of the existing few basic methods when combined with preprocessing method that can be utilized as a part of the segmentation. A discussion and fair analysis justified with experimental results along with quantitative correlation of the outcomes on 247 images of JSRT through Dice coefficient exhibited.
C1 [Kiran, Mehreen; Ahmed, Imran; Khan, Nazish; Rehman, Hamood Ur] Ctr Excellence Informat Technol, Inst Management Sci, Peshawar, Pakistan.
   [Din, Sadia; Paul, Anand] Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
   [Reddy, Alavalapati Goutham] Natl Inst Technol, Dept Comp Sci & Engn, Tadepalligudem, Andhra Pradesh, India.
C3 Kyungpook National University; National Institute of Technology (NIT
   System); National Institute of Technology Andhra Pradesh
RP Reddy, AG (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Tadepalligudem, Andhra Pradesh, India.
EM mehreen.kiran89@gmail.com; imran.ahmed@imseiences.edu.pk;
   diyanoor82@yahoomail.com; hamoodurrehman@imsciences.edu.pk;
   saadia.deen@gmail.com; paul.editor@gmail.com; goutham.ace@gmail.com
RI Alavalapati, Goutham Reddy/AGN-0905-2022; Paul, Anand/V-6724-2017;
   Ahmed, Imran/HDL-7255-2022; Kiran, Mahreen/HGC-9076-2022
OI Alavalapati, Goutham Reddy/0000-0002-4335-8331; Paul,
   Anand/0000-0002-0737-2021; Paul, Anand/0000-0003-3115-2325; Din,
   Sadia/0000-0003-0921-4462
CR [Anonymous], 2007, K MEANS IMAGE SEGMEN
   [Anonymous], 2017, CONTRAST ENHANCEMENT
   [Anonymous], 2013, SIM MEAS
   [Anonymous], 1973, FUZZY RELATIVE ISODA
   [Anonymous], ACTIVE CONTOUR SEGME
   [Anonymous], 2016, ATLAS BASED LUNG SEG
   [Anonymous], 2013, PATTERN RECOGN, DOI DOI 10.1007/978-1-4757-0450-1
   [Anonymous], HISTOGRAM EQUALIZATI
   Antani S.K., 2015, AUTOMATED DETECTION
   Bin Rais N, 2004, INMIC 2004: 8th International Multitopic Conference, Proceedings, P61
   Bradley Derek, 2007, Journal of Graphics Tools, V12, P13
   Bueno S. G., 2004, 2004 IEEE Nuclear Science Symposium Conference Record (IEEE Cat. No. 04CH37604), P3777
   Camilus S., 2009, FUZZY C MEANS SEGMEN
   Chaki N, 2014, STUD COMPUT INTELL, V560, P1, DOI [10.1007/978-81-322-1907-1, 10.1007/978-81-322-1907-1_2]
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Feldman Mitchell J, 2012, J Grad Med Educ, V4, P227, DOI 10.4300/JGME-D-11-00180.1
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Garcia D., 2010, Image segmentation using Otsu thresholding
   Ghosh S, 2013, INT J ADV COMPUT SC, V4, P35
   Kamra P, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMPUTING AND CONTROL (ISPCC), P302, DOI 10.1109/ISPCC.2015.7375045
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kato Z, 2011, FOUND TRENDS SIGNAL, V5, P1, DOI 10.1561/2000000035
   Kaur N., 2011, Int. J. Comput. Sci. Eng, V3, P3441
   Khan A, 2013, IMAGE SEGMENTATION M
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   LEE J, 2015, INT J FUZZY LOGIC IN, V15, P35
   Lim SH, 2015, SIGNAL IMAGE VIDEO P, V9, P675, DOI 10.1007/s11760-013-0500-z
   Lin, 2015, IM SEGM BAS MARK RAN
   Magudeeswaran V, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/891864
   MathWorks, 2016, GRAYTHR
   Moftah HM, 2014, NEURAL COMPUT APPL, V24, P1917, DOI 10.1007/s00521-013-1437-4
   Motl J., 2015, Bradley Local Image Thresholding
   Motl J, 2013, NIBLACK
   Motl J., 2013, Sauvola local image thresholding
   Nair DMS, 2007, EDGE DETECTION SEGME
   Niblack W., 1986, An Introduction to Digital Image Processing
   Orchard P., 2007, MARKOV RANDOM FIELD
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Saad MN, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM COMPUTING AND ENGINEERING, P46, DOI 10.1109/ICCSCE.2014.7072687
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shoelson B, 2016, THRESHOLDLOCALLY
   Starck JL, 2003, IEEE T IMAGE PROCESS, V12, P706, DOI 10.1109/TIP.2003.813140
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Stolojescu-Cri C, 2013, ADV ELECT COMPUTER E, V13
   Subashini P, 2011, INT J SOFT COMPUTING, V1
   Suvanov S, CONTRAST ENHANCEMENT
   Ting CC, 2015, SENSORS-BASEL, V15, P16981, DOI 10.3390/s150716981
   van Ginneken B, 2000, MED PHYS, V27, P2445, DOI 10.1118/1.1312192
   van Ginneken B, 2006, MED IMAGE ANAL, V10, P19, DOI 10.1016/j.media.2005.02.002
   van Ginneken B, 2001, IEEE T MED IMAGING, V20, P1228, DOI 10.1109/42.974918
   Vicente S., 2008, PROC IEEE C COMPUT V, P1, DOI DOI 10.1109/CVPR.2008.4587440
   Wong L, 2005, P 3 APT TEL WORKSH K, P27
   Wong LP, 2007, SAUVOLA LOCAL IMAGE
   Xu HL, 2015, OPT REV, V22, P246, DOI 10.1007/s10043-015-0073-x
   Yao H, 2013, MATH COMPUT MODEL, V58, P784, DOI 10.1016/j.mcm.2012.12.025
NR 59
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8483
EP 8518
DI 10.1007/s11042-019-7348-3
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600010
DA 2024-07-18
ER

PT J
AU Ullah, F
   Wang, JF
   Farhan, M
   Jabbar, S
   Wu, ZM
   Khalid, S
AF Ullah, Farhan
   Wang, Junfeng
   Farhan, Muhammad
   Jabbar, Sohail
   Wu, Zhiming
   Khalid, Shehzad
TI Plagiarism detection in students' programming assignments based on
   semantics: multimedia e-learning based smart assessment methodology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Latent Semantic Analysis; Semantic Similarity; Machine Learning;
   Multimedia; e-Learning; Smart Assessment
AB The multimedia-based e-Learning methodology provides virtual classrooms to students. The teacher uploads learning materials, programming assignments and quizzes on university' Learning Management System (LMS). The students learn lessons from uploaded videos and then solve the given programming tasks and quizzes. The source code plagiarism is a serious threat to academia. However, identifying similar source code fragments between different programming languages is a challenging task. To solve the problem, this paper proposed a new plagiarism detection technique between C++ and Java source codes based on semantics in multimedia-based e-Learning and smart assessment methodology. First, it transforms source codes into tokens to calculate semantic similarity in token by token comparison. After that, it finds semantic similarity in scalar value for the complete source codes written in C++ and Java. To analyse the experiment, we have taken the dataset consists of four (4) case studies of Factorial, Bubble Sort, Binary Search and Stack data structure in both C++ and Java. The entire experiment is done in R Studio with R version 3.4.2. The experimental results show better semantic similarity results for plagiarism detection based on comparison.
C1 [Ullah, Farhan; Wang, Junfeng] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
   [Ullah, Farhan; Farhan, Muhammad] COMSATS Inst Informat Technol, Dept Comp Sci, Sahiwal 57000, Pakistan.
   [Wang, Junfeng; Wu, Zhiming] Sichuan Univ, Sch Aeronaut & Astronaut, Chengdu 610065, Peoples R China.
   [Jabbar, Sohail] Natl Text Univ, Dept Comp Sci, Faisalabad 38000, Pakistan.
   [Khalid, Shehzad] Bahria Univ, Dept Comp Sci, Islamabad 44000, Pakistan.
C3 Sichuan University; COMSATS University Islamabad (CUI); Sichuan
   University; National Textile University - Pakistan
RP Wang, JF (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.; Wang, JF (corresponding author), Sichuan Univ, Sch Aeronaut & Astronaut, Chengdu 610065, Peoples R China.
EM farhankhan.cs@yahoo.com; wangjf@scu.edu.cn; farhansajid@gmail.com;
   sjabbar.research@gmail.com; wzhm0301@163.com; shehzad_khalid@hotmail.com
RI Farhan, Muhammad/F-8071-2011; Ullah, Farhan/IUM-8973-2023; wu,
   zhi/GXH-3041-2022; Ullah, Farhan/AAM-3866-2021; Jabbar,
   Sohail/E-3052-2012
OI Farhan, Muhammad/0000-0002-3649-5717; Jabbar,
   Sohail/0000-0002-2127-1235; Ullah, Farhan/0000-0002-1030-1275
CR Abdelrahman Y. A, 2017, INT J COMPUTER SCI I, V15, P79
   Alrabaee S, 2015, DIGIT INVEST, V12, pS61, DOI 10.1016/j.diin.2015.01.011
   [Anonymous], 2005, Understanding Search Engines: Mathematical Modeling and Text Retrieval
   [Anonymous], [No title captured]
   [Anonymous], P 31 IEEE ACM INT C
   [Anonymous], 2007, QUEENS SCH COMPUT T
   Bakker T, 2014, THESIS, V7, P1
   Bandara U., 2012, INT J COMPUT THEORY, V4, P674
   Buddrus F., 1998, P 1998 ACM S APPL CO
   Chen X, 2004, IEEE T INFORM THEORY, V50, P1545, DOI 10.1109/TIT.2004.830793
   Cosma G., 2006, SOURCE CODE PLAGIARI
   Cosma G, 2012, IEEE T COMPUT, V61, P379, DOI 10.1109/TC.2011.223
   de Klerk S, 2014, INTRO NEW METHOD ASS, P39, DOI [10.3280/CAD2014-001006, DOI 10.3280/CAD2014-001006]
   Farhan M, 2018, MULTIMED TOOLS APPL, V77, P4909, DOI 10.1007/s11042-016-4212-6
   Farhan M, 2018, FUTURE GENER COMP SY, V79, P909, DOI 10.1016/j.future.2017.09.037
   Farhan M, 2017, J REAL-TIME IMAGE PR, V13, P491, DOI 10.1007/s11554-016-0662-3
   Jhi YC, 2015, IEEE T SOFTWARE ENG, V41, P925, DOI 10.1109/TSE.2015.2418777
   Kashyap V, 2017, ARXIV170602769
   Kaur Raminder, 2014, SIGSOFT SOFTW ENG NO, V39, P1
   Kawamitsu N, 2014, SOURCE CODE ANAL MAN
   Kim J, 2016, P 2016 GEN EV COMP C
   Lau RWH, 2014, WORLD WIDE WEB, V17, P189, DOI 10.1007/s11280-013-0206-8
   Lazar F-M, 2014, 2014 IE 9 INT S APPL
   Lu QM, 2017, MULTIMED TOOLS APPL, V76, P19543, DOI 10.1007/s11042-015-3228-7
   Malabarba S, 1999, P 21 INT C SOFTW ENG
   Malik KR, 2016, MULTIMED TOOLS APPL, V75, P12727, DOI 10.1007/s11042-015-2918-5
   Marshall CZ, 2017, LATENT SEMANTIC ANAL
   McGill TJ, 2014, INTERNET HIGH EDUC, V22, P24, DOI 10.1016/j.iheduc.2014.04.001
   Ohno A, 2011, INT J INNOV COMPUT I, V7, P4729
   PAWELCZAK D, 2013, P INT C FRONT ED COM, P1
   Ragkhitwetsagul C, 2016, 2016 IE INT C SOFTW
   Sajnani H, 2016, 2016 IEEE ACM 38 INT
   ShanmughaSundaram M., 2015, INT ARAB J INF TECHN, P735
   Shirota Y, 2015, 2015 IIAI 4 INT C IE
   Son JW, 2013, ENG APPL ARTIF INTEL, V26, P1911, DOI 10.1016/j.engappai.2013.06.007
   Song HJ, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/429807
   Stemler S.E., 2015, EMERGING TRENDS SOCI, P1
   Van Rysselberghe F, 2004, 19 INT C AUT SOFTW E
   Yang FP, 2014, COMPUT EDUC, V70, P161, DOI 10.1016/j.compedu.2013.08.005
   Yu B, 2008, KNOWL-BASED SYST, V21, P900, DOI 10.1016/j.knosys.2008.03.045
   Zhang DS, 2005, AM J DISTANCE EDUC, V19, P149, DOI 10.1207/s15389286ajde1903_3
   Zhang DS, 2004, COMMUN ACM, V47, P75, DOI 10.1145/986213.986216
   ZHAO X, 2017, IEEE POW ENER SOC GE
   Zhiyuan Z, 2017, LATENT SEMANTIC ANAL
NR 44
TC 22
Z9 24
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8581
EP 8598
DI 10.1007/s11042-018-5827-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600014
DA 2024-07-18
ER

PT J
AU Vijayan, M
   Mohan, R
   Raguraman, P
AF Vijayan, Midhula
   Mohan, R.
   Raguraman, Preeth
TI Contextual background modeling using deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep-convolutional neural network; Foreground segmentation; Fully
   convolutional network; Hierarchical-pooling; Skip-architecture
ID SUBTRACTION; SEGMENTATION; VIDEO
AB Moving object detection is a crucial problem in computer vision. This affects the performance of the overall system in surveillance applications. In this paper, a Deep-Convolutional Neural Network with fully convolutional approach is proposed. Convolutional networks are powerful models to extract hierarchies of non-handcrafted features. The primary objective of the paper is to build an accurate foreground segmentation system with limited user interventions. The presented work focuses to build a fully convolutional network with skip architecture to identify moving objects in complex scenarios. The network is modeled as an end-to-end fully convolutional network, and the method contains a new hierarchical pooling layer to make use of global contextual information. The presented model utilizes a pre-trained VGG-19 Net model for the construction of Deep-Convolutional Neural Network (Deep-CNN) model. The fine and coarse features are fused using skip architecture to improve the feature representation. The qualitative and quantitative performance of the Deep-CNN architecture is tested on ChangeDetection.net-2014 dataset. The results produced by the Deep-CNN method were compared with the techniques in the recent literature. The Deep-CNN method outperforms the state-of-the-art methods without relying on any post-processing techniques.
C1 [Vijayan, Midhula; Mohan, R.; Raguraman, Preeth] Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli 620015, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Vijayan, M (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli 620015, India.
EM midhula91@gmail.com; rmohan@nitt.edu; preethraguram@gmail.com
RI R, Mohan/V-6077-2019
OI Vijayan, Midhula/0000-0002-2578-6463
CR [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], FOREGROUND SEGMENTAT
   [Anonymous], 2018, EVOL INTELL
   [Anonymous], ARXIV180300663
   [Anonymous], 2017, IEEE T CIRCUITS SYST
   [Anonymous], FUTUR GENER COMPUT S
   [Anonymous], BMVC
   [Anonymous], ARXIV180102031
   [Anonymous], PATTERN RECOGN LETT
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Bakiya A, 2020, MULTIMED TOOLS APPL, V79, P11051, DOI 10.1007/s11042-018-6561-9
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Braham M, 2016, INT CONF SYST SIGNAL, P113
   Chen ZZ, 2014, COMPUT VIS IMAGE UND, V122, P35, DOI 10.1016/j.cviu.2014.01.004
   Choudhury SK, 2016, IEEE ACCESS, V4, P6133, DOI 10.1109/ACCESS.2016.2608847
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Guo JM, 2013, IEEE T CIRC SYST VID, V23, P1809, DOI 10.1109/TCSVT.2013.2269011
   Haines TSF, 2014, IEEE T PATTERN ANAL, V36, P670, DOI 10.1109/TPAMI.2013.239
   Harville M, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P3, DOI 10.1109/EVENT.2001.938860
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Hu GS, 2018, IEEE T IMAGE PROCESS, V27, P293, DOI 10.1109/TIP.2017.2756450
   Khatami A, 2018, EXPERT SYST APPL, V100, P224, DOI 10.1016/j.eswa.2018.01.056
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu CNJ, 2015, INT SOC DESIGN CONF, P1, DOI 10.1109/ISOCC.2015.7401682
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Moshe Y, 2012, PROC CVPR IEEE, P3210, DOI 10.1109/CVPR.2012.6248056
   Pinheiro PO, 2014, PR MACH LEARN RES, V32
   Radenovi F, 2018, IEEE T PATTERN ANAL
   Raza M, 2018, FUTURE GENER COMP SY, V88, P28, DOI 10.1016/j.future.2018.05.002
   Ruder S., 2016, ARXIV
   Saravanakumar S., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P79, DOI 10.1109/ICSIP.2010.5697446
   Seeliger K, 2018, NEUROIMAGE, V180, P253, DOI 10.1016/j.neuroimage.2017.07.018
   Shahbaz A., 2015, 2015 21 KOR JAP JOIN, P1, DOI DOI 10.1109/FCV.2015.7103699
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   St-Charles PL, 2016, IEEE T IMAGE PROCESS, V25, P4768, DOI 10.1109/TIP.2016.2598691
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Suresh S, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT, POWER AND COMPUTING TECHNOLOGIES (ICCPCT-2014), P1432, DOI 10.1109/ICCPCT.2014.7054915
   Vijayan M, 2018, OPTIK, V168, P963, DOI 10.1016/j.ijleo.2018.05.012
   Wang XH, 2017, IEEE SIGNAL PROC LET, V24, P510, DOI 10.1109/LSP.2016.2611485
   Wang Y., 2014, P IEEE C COMP VIS PA, P387, DOI 10.1109/ICIP40778.2020.9190887
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014
   Yang L, 2018, IEEE T INTELL TRANSP, V19, P254, DOI 10.1109/TITS.2017.2754099
   Zhu QS, 2012, IEEE T IMAGE PROCESS, V21, P3865, DOI 10.1109/TIP.2012.2199504
NR 51
TC 3
Z9 3
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 11083
EP 11105
DI 10.1007/s11042-019-07800-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600073
DA 2024-07-18
ER

PT J
AU Xie, XL
AF Xie, Xiao-lu
TI Three-dimensional reconstruction based on multi-view photometric stereo
   fusion technology in movies special-effect
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photometric stereo; Multi-view fusion; Image reconstruction; Movies
   special-effect; 3D movies; Quasi-point; Surface depth
AB 3D movies have become very popular in recent years. But there are vertical disparities between left and right views of 3D frames due to the lack of accuracy of the mechanical alignment during the shooting. In order to improve accuracy of reconstruction, a three-dimensional reconstruction technology based on multi-view photometric stereo fusion algorithm in movies special-effect production is present in this paper. The original normal is firstly replaced with the surface normal in the average normal, and the reconstructed normal is optimized so as to reduce the deviation of the original surface normal. And then, a reference-plane-based approach is applied to estimate the principle optical axis of each light source as well as its principle radiant energy. For each surface point on the target, the direction and intensity of its incident light ray can be precisely determined by the calibration parameters and the quasi-point light model. Finally, 3D reconstruction of the surface with a quasi-point light source is also implemented in two steps. By estimating the mean value of depth in the iterative process, the surface depth is projected into the physical coordinates. Qualitative and quantitative experimental results show that higher accuracy surface normal as well as better 3D reconstruction quality can be obtained by the proposed approach in comparison with conventional reconstruction methods.
C1 [Xie, Xiao-lu] Chongqing Coll Elect Engn, Coll Digital Media, Chongqing 401331, Peoples R China.
C3 Chongqing College of Electronic Engineering
RP Xie, XL (corresponding author), Chongqing Coll Elect Engn, Coll Digital Media, Chongqing 401331, Peoples R China.
EM lixiao_xie@yeah.net
CR Antensteiner D., 2017, IEEE C COMP VIS PATT
   Bony A, 2014, SIGN PROC C, P1234
   Cataldo, 2017, J PHYS C SERIES, P1
   Diego F, 2017, IEEE C COMP VIS PATT, P2122
   Fan H, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.11.113101
   Fujimura Y, 2018, IEEE T PATTERN ANAL, V24, P1601
   Gorpas D, 2013, SPIE OPTICAL METROLO, P129
   Ikeda S, 2003, LECT NOTES COMPUT SC, V2749, P1074
   Ikeda S, 2003, P IEEE INT C MULTIS, V23, P232
   Llebaria A, 2001, P SOC PHOTO-OPT INS, V4477, P265, DOI 10.1117/12.447183
   Murez Z, 2017, IEEE T PATTERN ANAL, V39, P1880, DOI 10.1109/TPAMI.2016.2613862
   Park J, 2017, IEEE T PATTERN ANAL, V39, P1591, DOI 10.1109/TPAMI.2016.2608944
   Phipps J, 2017, ADV BIOMEDICAL CLIN, P12
   Pu SH, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P238, DOI 10.1109/CIS.2017.00059
   Qian PJ, 2017, IEEE T NEUR NET LEAR, V28, P1123, DOI 10.1109/TNNLS.2015.2511179
   Qian PJ, 2016, IEEE T CYBERNETICS, V46, P181, DOI 10.1109/TCYB.2015.2399351
   Queau Y, 2017, INT C QUAL CONTR ART, P231
   Shi BX, 2014, IEEE T PATTERN ANAL, V36, P1078, DOI 10.1109/TPAMI.2013.196
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Wagenmaker AJ, 2017, IEEE T COMPUT IMAG, V44
   Woodham BKP, 1989, SHAPE SHADINGM
   Y Fujimura, 2017, COMPUTER VISION ANAL, P19
   Yeh CK, 2017, IEEE INT C E SCI, P12
   Zhang WH, 2018, COMPUT IND, V98, P56, DOI 10.1016/j.compind.2018.02.006
NR 24
TC 5
Z9 5
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9565
EP 9578
DI 10.1007/s11042-019-08034-w
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600068
DA 2024-07-18
ER

PT J
AU Zhang, DY
   Yang, GB
   Li, F
   Wang, J
   Sangaiah, AK
AF Zhang, Dengyong
   Yang, Gaobo
   Li, Feng
   Wang, Jin
   Sangaiah, Arun Kumar
TI Detecting seam carved images using uniform local binary patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Seam carving; Images retargeting; Uniform local binary patterns (ULBP);
   Support vector machine
ID CLASSIFICATION
AB Seam carving is widely used excellent content-aware image scaling method. When an image is processed by seam carving, its local texture changes. Local binary patterns is an excellent local descriptor for describing the local texture of an image. In this paper, a blind detection based uniform local binary patterns(ULBP) is proposed to detect seam-carved image. Firstly, the image is transformed into gray-scale image. Then the ULBP histogram features and seam features are extracted from the gray-scale image. Finally support vector machine (SVM) is adopted as classifier to train and test those features to identify whether an image is subjected to seam carving or not. Wei et al. (Pattern Recogn Lett 36:100-106 2014) method and Ryu et al. (IEICE Trans Inf Syst 97(5):1304-1311 2014) method are selected as the benchmark. Extensive compared experiments are conducted by the three methods, respectively. Experimental results show that the proposed method has the best performance among the three methods under a variety of setting.
C1 [Zhang, Dengyong; Li, Feng; Wang, Jin] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Hunan Prov Key Lab Intelligent Proc Big Data Tran, Changsha 410004, Peoples R China.
   [Yang, Gaobo] Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
   [Sangaiah, Arun Kumar] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
C3 Changsha University of Science & Technology; Hunan University; Vellore
   Institute of Technology (VIT); VIT Vellore
RP Sangaiah, AK (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
EM sarunkumar@vit.ac.in
RI wang, yue/ISA-4119-2023; Sangaiah, Arun Kumar/U-6785-2019; Wang,
   Jin/GYA-2019-2022; WANG, JINGYI/GSJ-1241-2022; wang, jing/HJA-5384-2022;
   wang, jie/HTQ-4920-2023; wang, jing/GVT-8700-2022; wang,
   yi/HOF-6668-2023
OI Sangaiah, Arun Kumar/0000-0002-0229-2460; 
CR [Anonymous], 2004, ELECT IMAGING
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Chang WL, 2013, 2013 INTERNATIONAL JOINT CONFERENCE ON AWARENESS SCIENCE AND TECHNOLOGY & UBI-MEDIA COMPUTING (ICAST-UMEDIA), P632, DOI 10.1109/ICAwST.2013.6765516
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Fillion C, 2010, PROC SPIE, V7541, DOI 10.1117/12.838647
   Han R, 2018, EXPERT SYST APPL, V95, P162, DOI 10.1016/j.eswa.2017.11.023
   Hsu CC, 2014, IEEE J-STSP, V8, P377, DOI 10.1109/JSTSP.2014.2311884
   Liu Q., 2012, P 12 INT WORKSH MULT, DOI [10.1145/2343862.2343864, DOI 10.1145/2343862.2343864]
   Liu QW, 2014, THORAC CANCER, V5, P63, DOI 10.1111/1759-7714.12060
   Liu QZ, 2017, PATTERN RECOGN, V65, P35, DOI 10.1016/j.patcog.2016.12.010
   Lu WJ, 2011, MM&SEC 11: PROCEEDINGS OF THE 2011 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P9
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Ryu SJ, 2014, IEICE T INF SYST, VE97D, P1304, DOI 10.1587/transinf.E97.D.1304
   Sarkar A, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P107
   Sheng GR, 2016, INT J DIGIT CRIME FO, V8, P51, DOI 10.4018/IJDCF.2016010104
   Shi YQ, 2007, LECT NOTES COMPUT SC, V4437, P249
   Wattanachote K, 2015, IEEE T INF FOREN SEC, V10, P2477, DOI 10.1109/TIFS.2015.2464776
   Wei JD, 2014, PATTERN RECOGN LETT, V36, P100, DOI 10.1016/j.patrec.2013.09.026
   Ye JY, 2017, J INF SECUR APPL, V35, P13, DOI 10.1016/j.jisa.2017.04.003
   Yin T, 2015, COMPUT SECUR, V55, P130, DOI 10.1016/j.cose.2015.09.003
NR 22
TC 33
Z9 34
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8415
EP 8430
DI 10.1007/s11042-018-6470-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600006
DA 2024-07-18
ER

PT J
AU Jiang, N
   Zhuang, Y
   Chiu, DKW
AF Jiang, Nan
   Zhuang, Yi
   Chiu, Dickson K. W.
TI Effective and efficient crowd-assisted similarity retrieval of medical
   images in resource-constraint Mobile telemedicine systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Similarity retrieval; Crowdsourcing; Mobile telemedicine
   system
ID MULTI-QUERY OPTIMIZATION
AB This paper presents an effective and efficient framework for Crowd-assisted Mobile Similarity Retrieval of the large-scale medical images in the resource-constraint mobile telemedicine systems (MTS), called the CMSR. The CMSR processing works as follows: when a user submits a retrieval medical image I-R, a buffer checking processing is first invoked to check if the full (or partial) retrieval results have been cached in the buffer previously. After that, a parallel image data filtering and refinement processing is conducted at a master node level. Finally, the candidate images are concurrently validated by a mCrowd system to derive an answer set that is transmitted to the retrieval node. To better facilitate the effective and efficient CMSR processing, three enabling techniques, i.e., category-based image data interleaving placement scheme, hindex-support image filtering algorithm and a kNN-based buffering scheme are developed. To improve the retrieval throughput, finally, we propose an extension of the CMSR method called mCMSR to optimize the multiple CMSRs. The experimental results show that the performances of the CMSR and the mCMSR methods are: 1) effective in improving the retrieval accuracy; 2) efficient in minimizing the response time by decreasing the network transmission cost while increasing the parallelism of I/O and CPU.
C1 [Jiang, Nan] Zhejiang Univ, Sch Med, Affiliated Hangzhou Peoples Hosp 1, Hangzhou, Peoples R China.
   [Zhuang, Yi] Zhejiang Gongshang Univ, Coll Comp & Informat Engn, Apart 502,Unit 2,Blg 7, Hangzhou, Peoples R China.
   [Chiu, Dickson K. W.] Univ Hong Kong, Fac Educ, Pok Fu Lam, Hong Kong, Peoples R China.
C3 Zhejiang University; Zhejiang Gongshang University; University of Hong
   Kong
RP Zhuang, Y (corresponding author), Zhejiang Gongshang Univ, Coll Comp & Informat Engn, Apart 502,Unit 2,Blg 7, Hangzhou, Peoples R China.
EM zhuang@mail.zjgsu.edu.cn
RI JIANG, NAN/AHB-1945-2022; Chiu, Dickson K. W./B-9630-2017
OI Chiu, Dickson K. W./0000-0002-7926-9568
FU Program of National Natural Science Foundation of China [61540064];
   Program of Natural Science Foundation of Zhejiang Province
   [LY18F020006]; Program of Medical and Health Science and Technology Plan
   of Zhejiang Province [2019RC070]
FX This work is partially supported by the Program of National Natural
   Science Foundation of China under Grant No. 61540064; the Program of
   Natural Science Foundation of Zhejiang Province under grant No.
   LY18F020006; the Program of Medical and Health Science and Technology
   Plan of Zhejiang Province under grant No. 2019RC070.
CR Ali M, 2018, MULTIMED TOOLS APPL, V77, P20271, DOI 10.1007/s11042-017-5453-8
   Anbarasi MS, 2009, INT C INT AG MULT SY
   Android, 2010, ANDR PLATF
   [Anonymous], 2009, 473209 MIT SLOAN SCH
   [Anonymous], 2014, P 2014 INT ACM WORKS, DOI [DOI 10.1145/2660114.2660126, 10.1145/2660114.2660126]
   Armstrong AW, 2012, AM J CLIN DERMATOL, V13, P405, DOI 10.2165/11634040-000000000-00000
   Bai C, 2018, NEUROCOMPUTING, V303, P60, DOI 10.1016/j.neucom.2018.04.034
   Brabham D. C, 2008, Convergence, V14, P75, DOI DOI 10.1177/1354856507084420
   Chang, 1997, IEEE MULTIMEDIA
   Charisi A, 2010, ACM INT HLTH INFORMA, P724
   Deselaers T., 2003, THESIS
   Deselaers T., 2009, FIRE
   Doan A, 2011, COMMUN ACM, V54, P86, DOI 10.1145/1924421.1924442
   EC2, 2009, AM EC2
   Feng A, 2011, PROC VLDB ENDOW, V4, P1387
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Foncubierta-Rodriguez A., 2012, P ACM MULT 2012 WORK, DOI [DOI 10.1145/2390803.2390808, 10.1145/2390803.2390808]
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Guo S., 2012, SIGMOD
   Huang YG, 2014, MULTIMED TOOLS APPL, V73, P1963, DOI 10.1007/s11042-013-1685-4
   Huang YG, 2014, MULTIMED TOOLS APPL, V72, P2977, DOI 10.1007/s11042-013-1589-3
   Jagadish HV, 2005, ACM T DATABASE SYST, V30, P364, DOI 10.1145/1071610.1071612
   Juusola JL, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5644
   Kaplan H, 2013, PROC VLDB ENDOW, V6, P697, DOI 10.14778/2536360.2536369
   Kasban H, 2019, MULTIMED TOOLS APPL, V78, P35211, DOI 10.1007/s11042-019-08100-3
   Kementsietsidis A, 2008, PROC VLDB ENDOW, V1, P16
   Kitanovski I, 2017, MULTIMED TOOLS APPL, V76, P2955, DOI 10.1007/s11042-016-3261-1
   Lan RS, 2018, MULTIMED TOOLS APPL, V77, P10853, DOI 10.1007/s11042-017-5341-2
   Le WC, 2012, PROC INT CONF DATA, P666, DOI 10.1109/ICDE.2012.37
   Mavandadi S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0037245
   Meyer AND, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.4887
   Parameswaran A.G., 2012, SIGMOD C, P361, DOI 10.1145/2213836.2213878
   Parameswaran A.P., 2011, Systems Research, P160
   Philbin J., 2007, INT C COMP VIS PATT
   Redi Judith., 2014, Proc. of the International ACM Workshop on Crowdsourcing for Multimedia, P25, DOI [10.1145/2660114.2660118, DOI 10.1145/2660114.2660118]
   Redi Judith., 2015, Fourth International Workshop on Crowdsourcing for Multimedia. CrowdMM'15, P33, DOI [DOI 10.1145/2810188.2810194, 10.1145/2810188.2810194]
   Roy P, 2010, SIGMOD C, P249
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   SELLIS TK, 1988, ACM T DATABASE SYST, V13, P23, DOI 10.1145/42201.42203
   Shyu CR, 1999, COMPUT VIS IMAGE UND, V75, P111, DOI 10.1006/cviu.1999.0768
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Trigoni N, 2005, LECT NOTES COMPUT SC, V3560, P307
   Wang J, 2012, PROC VLDB ENDOW, V5, P1483, DOI 10.14778/2350229.2350263
   Weltera P, 2012, COMPUT METH PROG BIO, V108, P589, DOI 10.1016/j.cmpb.2011.08.010
   Whang SE, 2013, PROC VLDB ENDOW, V6, P349, DOI 10.14778/2536336.2536337
   Zhang CJ, 2014, PROC VLDB ENDOW, V7, P2005, DOI 10.14778/2733085.2733105
   Zhuang Y, 2014, INFORM SCIENCES, V263, P60, DOI 10.1016/j.ins.2013.10.013
   Zhuang Y, 2008, INT CON DISTR COMP S, P639, DOI 10.1109/ICDCS.2008.58
NR 48
TC 4
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19893
EP 19923
DI 10.1007/s11042-020-08755-3
EA MAR 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000522711000001
DA 2024-07-18
ER

PT J
AU Bernardo, MV
   Pinheiro, AMG
   Fiadeiro, PT
   Pereira, M
AF Bernardo, Marco V.
   Pinheiro, Antonio M. G.
   Fiadeiro, Paulo T.
   Pereira, Manuela
TI Quality perception of specific chromatic impairments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality perception; Chromatic error; Mean opinion score; Fixation maps
ID VISUAL-ATTENTION
AB This work was motivated by previous studies on the perceptual influence of chromatic impairments, where was observed that specific chromatic impairments might have a different influence, related to the represented content. Hence, in this study, chromatic impairments were applied to specific color clusters and the resulting perceptual influence was analyzed. The applied chromatic impairments influence on the images naturalness was assessed using a Single Stimulus Continuous Quality Evaluation (SSCQE) and the Mean Opinion Score (MOS) was calculated. Furthermore, during the image assessment, the eye movements were registered using an eye tracking device and the Relative Fixation Time (RFT) was computed. It was concluded that the induced chromatic impairments, lead to lower MOS values than the original images, revealing a perception of quality loss. Furthermore, when nature colors are changed, subjects revealed a larger perception of the impairment, resulting in smaller MOS and producing evident changes in the RFT's. The comparative analysis between the MOS and the RFT's reveals high Pearson Correlation Coefficient (PCC) results (p = 0.79 +/- 0.14).
C1 [Bernardo, Marco V.; Pinheiro, Antonio M. G.; Pereira, Manuela] Univ Beira Interior, IT, Rua Marques d'Avila & Bolama, P-6201001 Covilha, Portugal.
   [Fiadeiro, Paulo T.] Univ Beira Interior, Fiber Mat & Environm Technol FibEnTech, Rua Marques d'Avila & Bolama, P-6201001 Covilha, Portugal.
C3 Universidade da Beira Interior; Instituto de Telecomunicacoes;
   Universidade da Beira Interior
RP Bernardo, MV (corresponding author), Univ Beira Interior, IT, Rua Marques d'Avila & Bolama, P-6201001 Covilha, Portugal.
EM mbernardo@ubi.pt; pinheiro@ubi.pt; fiadeiro@ubi.pt; mpereira@ubi.pt
RI Fiadeiro, Paulo T/J-2017-2012; Pinheiro, Antonio/B-2723-2012; Bernardo,
   Marco v./HNQ-4992-2023; Pereira, Manuela/Q-3456-2019
OI Fiadeiro, Paulo T/0000-0002-7374-3636; Pinheiro,
   Antonio/0000-0002-5968-9901; Bernardo, Marco v./0000-0003-0046-8685;
   Pereira, Manuela/0000-0002-8648-6464
FU Portuguese FCT-Foundation for Science and Technology; FEDER - PT2020
   partnership agreement [PTDC / EEI-PRO / 2849/2014 -
   POCI-01-0145-FEDER-016693, UIDB / EEA / 50008/2020]
FX This research was funded by the Portuguese FCT-Foundation for Science
   and Technology and co-fund by FEDER - PT2020 partnership agreement under
   the project PTDC / EEI-PRO / 2849/2014 - POCI-01-0145-FEDER-016693}, and
   under the UIDB / EEA / 50008/2020 project.
CR Aldaba MA, 2006, VISUAL NEUROSCI, V23, P555, DOI 10.1017/S0952523806233467
   Aldini A, 2015, ELECTRON P THEOR COM, P1, DOI 10.4204/EPTCS.194.1
   Alers H, 2011, INT WORK QUAL MULTIM, P167, DOI 10.1109/QoMEX.2011.6065697
   [Anonymous], TECH REP
   [Anonymous], 2003, STAT SERIES TXB MONO
   [Anonymous], 1998, SUBJ AUD QUAL ASS ME
   [Anonymous], REPROD COLOUR
   [Anonymous], 2004, WAVEFRONT CUSTOMIZED
   [Anonymous], 2009, World Medical Association Declaration of Helsinki - Ethical principles for medical research involving human subjects
   Babcock JS, 2003, P SOC PHOTO-OPT INS, V5007, P218, DOI 10.1117/12.477770
   Bernardo M.V., 2012, Proceedings of the 20th ACM international conference on Multimedia, P1009, DOI 10.1145/2393347.2396369
   Bernardo MV, 2016, ACM T APPL PERCEPT, V14, DOI 10.1145/2964908
   Bernardo MV, 2013, INT WORK QUAL MULTIM, P1, DOI 10.1109/QoMEX.2013.6603192
   BRAINARD DH, 1989, COLOR RES APPL, V14, P23, DOI 10.1002/col.5080140107
   CIE, 1986, CIE PUBLICATION, V15.2
   Engelke U, 2009, IEEE INT WORKSH MULT, P25
   Fliegel K, 2008, 42ND ANNUAL 2008 IEEE INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P371, DOI 10.1109/CCST.2008.4751330
   Forsyth D., 2011, Computer Vision: A Modern Approach
   Foster DH, 2006, J OPT SOC AM A, V23, P2359, DOI 10.1364/JOSAA.23.002359
   Foster DH, 2004, VISUAL NEUROSCI, V21, P331, DOI 10.1017/S0952523804213335
   Goldberg J. H., 2002, Proceedings ETRA 2002. Eye Tracking Research and Applications Symposium, P51, DOI 10.1145/507072.507082
   Huynh-Thu Q, 2011, SPIE, V7865, P15
   International Telecommunication Union, 2009, METH SUBJ ASS QUAL T
   Ishihara S., 1998, Ishihara's Tests for Colour Deficiency
   Jacob RJK, 2003, MIND'S EYE: COGNITIVE AND APPLIED ASPECTS OF EYE MOVEMENT RESEARCH, P573, DOI 10.1016/B978-044451020-4/50031-1
   Jansen L, 2009, J VISION, V9, DOI 10.1167/9.1.29
   JUST MA, 1976, COGNITIVE PSYCHOL, V8, P441, DOI 10.1016/0010-0285(76)90015-3
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   Laghari KUR, 2012, IEEE COMMUN MAG, V50, P58, DOI 10.1109/MCOM.2012.6178834
   Le Meur O, 2010, SIGNAL PROCESS-IMAGE, V25, P547, DOI 10.1016/j.image.2010.05.006
   Liu HT, 2011, IEEE T CIRC SYST VID, V21, P971, DOI 10.1109/TCSVT.2011.2133770
   Luo MR, 2001, COLOR RES APPL, V26, P340, DOI 10.1002/col.1049
   Linhares JMM, 2008, J OPT SOC AM A, V25, P2918, DOI 10.1364/JOSAA.25.002918
   Mollon J. D., 1989, J PHYSL, V414, P5
   Ninassi A, 2007, IEEE IMAGE PROC, P733
   Poole A., 2005, ENCY HUMAN COMPUTER
   Reichl P., 2008, P 18 ITC SPEC SEM QU
   Reiter U, 2014, T-LAB SER TELECOMMUN, P55, DOI 10.1007/978-3-319-02681-7_4
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Spearman C, 1910, BRIT J PSYCHOL, V3, P271, DOI 10.1111/j.2044-8295.1910.tb00206.x
   Venkatesh MV, 2010, IEEE IMAGE PROC, P1109, DOI 10.1109/ICIP.2010.5653640
   Wismeijer DA, 2010, J VISION, V10, DOI 10.1167/10.6.25
   You JY, 2010, SIGNAL PROCESS-IMAGE, V25, P482, DOI 10.1016/j.image.2010.02.002
NR 43
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19831
EP 19851
DI 10.1007/s11042-020-08766-0
EA MAR 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000522592200001
DA 2024-07-18
ER

PT J
AU Salameh, HB
   Abusamra, R
AF Salameh, Haythem Bany
   Abusamra, Rasha
TI Intelligent multicast routing for multimedia over cognitive radio
   networks: a probabilistic approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cognitive radios; ETX; Shotest-path tree; Spectrum assignment; Path
   selection; Multimedia streaming
ID ASSIGNMENT
AB Cognitive radio (CR) technology has been demonstrated as one of the key technologies that can provide the needed spectrum bands for supporting the emerging spectrum-hungry multimedia applications and services in next-generation wireless networks. Multicast routing technique plays a significant role in most of wireless networks that require multimedia data dissemination to a group of destinations through single-hop or multi-hop communication. Performing multimedia multicasting over CR networks can significantly improve the quality of multimedia transmissions by effectively exploiting the available spectrum, reducing network traffic and minimizing communication cost. An important challenge in this domain is how to perform a multi-cast transmissions over multiple hops in a dynamically varying CR environment while maintaining high-quality received video streaming to all multi-case CR receivers without affecting the performance of legacy primary radio networks (PRNs). In this paper, we investigate the problem of multicast multimedia streaming in multi-hop CR networks (CRNs). Specifically, we propose an intelligent multicast routing protocol for multi-hop ad hoc CRNs that can effectively support multimedia streaming. The proposed protocol consists of path selection and channel assignment phases for the different multi-cast receivers. It is based on the shortest path tree (SPT) that implements the expected transmission count metric (ETX). The channel selection is based on the ETX, which is a function of the probability of success (POS) over the different channels that depends on the channel-quality and availability. Simulation results verify the significant improvement achieved by the proposed protocol compared to other existing multicast routing protocols under different network conditions.
C1 [Salameh, Haythem Bany] Al Ain Univ, Network & Commun Engn Dept, Al Ain, U Arab Emirates.
   [Salameh, Haythem Bany; Abusamra, Rasha] Yarmouk Univ, Telecommun Engn Dept, Irbid, Jordan.
C3 Yarmouk University
RP Salameh, HB (corresponding author), Al Ain Univ, Network & Commun Engn Dept, Al Ain, U Arab Emirates.; Salameh, HB (corresponding author), Yarmouk Univ, Telecommun Engn Dept, Irbid, Jordan.
EM haythem.banysalameh@aau.ae.ac; rashsamra@ses.yu.edu.jo
RI Bany Salameh, Haythem/Y-1223-2018
OI Bany Salameh, Haythem/0000-0003-3429-7212
CR Al-hammouri M, 2018, I C COMP SYST APPLIC
   Al-Rubaye M, 2016, INT CONF COMP SCI
   Almajali S, 2019, MULTIMED TOOLS APPL, V78, P24617, DOI 10.1007/s11042-018-7049-3
   Almasaeid HM, 2010, GLOB TEL C GLOB COMM, p[1, 6]
   Aloqaily M, 2019, IEEE COMMUN MAG, V57, P81, DOI 10.1109/MCOM.2019.1800624
   Amjad M, 2018, IEEE COMMUN SURV TUT, V20, P1056, DOI 10.1109/COMST.2018.2794358
   [Anonymous], 2019, MULTIMED TOOLS APPL
   [Anonymous], 2003, PROC 9 ANN INT C MO, DOI DOI 10.1145/938985.939000
   Balakrishnan V. K, 1997, Schaum's Outline of Theory and Problems of Graph Theory
   Banerjee A, 2018, IEEE T COGN COMMUN, V4, P82, DOI 10.1109/TCCN.2017.2785769
   Bany Salameh H, 2019, AD HOC NETW
   Bdarneh O, 2011, IEEE GLOBECOM, p[1, 5]
   Cheng G, 2007, IEEE ICC, P6499, DOI 10.1109/ICC.2007.1075
   Ge Y, 2013, MULTIMED TOOLS APPL, P67
   Hu DL, 2009, IEEE INFOCOM SER, P2222, DOI 10.1109/INFCOM.2009.5062147
   Jararweh Y, 2014, INT CONF CLOUD ENG, P592, DOI 10.1109/IC2E.2014.88
   Khan AA, 2017, IEEE WIREL COMMUN, V24, P17, DOI 10.1109/MWC.2017.1600404
   Lin TH, 2019, IEEE COMMUN LETT, V23, P736, DOI 10.1109/LCOMM.2019.2903458
   Mhaidat Y, 2014, 7 INT WORKSH SEL TOP
   Mhaidat Y, 2014, IEEE CONF WIREL MOB, P384, DOI 10.1109/WiMOB.2014.6962199
   Nguyen HL, 2009, WIREL COMMUN MOB COM, V9, P557, DOI 10.1002/wcm.701
   Salameh HAB, 2018, IEEE INTERNET THINGS, V5, P1904, DOI 10.1109/JIOT.2018.2817339
   Salameh HAB, 2015, IEEE T VEH TECHNOL, V64, P3624, DOI 10.1109/TVT.2014.2360985
   Salameh HB, 2009, IEEE INFOCOM SER, P2322, DOI 10.1109/INFCOM.2009.5062158
   Saniya Z, 2019, COMPUT COMMUN, V148, P86, DOI [10.1016/j.comcom.2019.09.010, DOI 10.1016/J.COMCOM.2019.09.010]
   Shahbazi M, 2013, IEEE POW ENER SOC GE
   Sung-Ju Lee, 1999, WCNC. 1999 IEEE Wireless Communications and Networking Conference (Cat. No.99TH8466), P1298, DOI 10.1109/WCNC.1999.796947
   Tuan Le, 2014, 2014 13th Annual Mediterranean Ad Hoc Networking Workshop (MED-HOC-NET), P188, DOI 10.1109/MedHocNet.2014.6849123
   Wu B.Y., 2004, DIS MATH APPLICAT
   Zeng GK, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, P1, DOI 10.1109/ICNP.2007.4375831
NR 30
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16731
EP 16742
DI 10.1007/s11042-020-08732-w
EA MAR 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000521018700002
DA 2024-07-18
ER

PT J
AU Bai, W
   Zhang, YX
   Huang, WW
   Zhou, YP
   Wu, D
   Liu, G
   Xiao, L
AF Bai, Wen
   Zhang, Yuxiao
   Huang, Weiwei
   Zhou, Yipeng
   Wu, Di
   Liu, Gang
   Xiao, Liang
TI DeepFusion: predicting movie popularity via cross-platform feature
   fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Popularity prediction; Deep neural networks; Online video service
AB For online video service providers, the accurate prediction of video popularity directly impacts their advertisement revenue, bandwidth provisioning policy and copyright procurement decision. Most of previous approaches only utilize data from a single platform (e.g., view history) for prediction. However, such approaches cannot provide satisfactory prediction accuracy, as video popularity may be affected by many influential features dispersed over multiple platforms. In this paper, we focus on the popularity prediction of online movies and propose a prediction framework called DeepFusion to fuse salient features from multiple platforms so as to boost the accuracy of popularity prediction of online movies. For this purpose, we extract influential factors from Douban, which is a leading movie rating website in China, and Youku, which is one of the largest online video service providers in China. Considering the complexity incurred by numerous parameters, we choose to feed these influential factors into deep neural networks for prediction and thus avoid the limitation of traditional predictive models. Compared with previous approaches, our solution can significantly improve the prediction accuracy over 40%. Moreover, even for movies without any historical views, our approach can also well capture their popular trends and overcome the cold-start problem.
C1 [Bai, Wen; Zhang, Yuxiao; Huang, Weiwei; Wu, Di] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Peoples R China.
   [Bai, Wen; Wu, Di] Sun Yat Sen Univ, Collaborat Innovat Ctr High Performance Comp, Guangzhou, Peoples R China.
   [Zhou, Yipeng] Macquarie Univ, Dept Comp, Comp Sci, Sydney, NSW, Australia.
   [Wu, Di] Sun Yat Sen Univ, Guangdong Key Lab Big Data Anal & Proc, Guangzhou, Peoples R China.
   [Liu, Gang] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
   [Xiao, Liang] Xiamen Univ, Dept Commun Engn, Fujian, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Macquarie University;
   Sun Yat Sen University; Shenzhen University; Xiamen University
RP Wu, D (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Peoples R China.; Wu, D (corresponding author), Sun Yat Sen Univ, Collaborat Innovat Ctr High Performance Comp, Guangzhou, Peoples R China.; Wu, D (corresponding author), Sun Yat Sen Univ, Guangdong Key Lab Big Data Anal & Proc, Guangzhou, Peoples R China.
EM wudi27@mail.sysu.edu.cn
RI huang, wen/GXW-0661-2022; wu, di/IYS-9217-2023; Wu, Di/HNP-3772-2023;
   Liu, Gang/AAU-3119-2020; Huang, WW/GXH-0977-2022
OI Liu, Gang/0000-0002-0489-2638; Zhou, Yipeng/0000-0003-1533-0865; XIAO,
   LIANG/0000-0003-2402-611X
FU National Natural Science Foundation of China [U1911201]; Guangdong
   Special Support Program [2017TX04X148]; Fundamental Research Funds for
   the Central Universities [19LGZD37, 19LGYJS57]; ARC [DE180100950]
FX This work was supported by the National Natural Science Foundation of
   China under Grant U1911201, Guangdong Special Support Program under
   Grant2017TX04X148, the Fundamental Research Funds for the Central
   Universities under Grant19LGZD37 and 19LGYJS57, and ARC DE180100950.
CR Ahmed Mohamed, 2013, P 6 ACM INT C WEB SE, P607, DOI [DOI 10.1145/2433396.2433473, 10.1145/2433396.2433473]
   Alsmirat MA, 2017, J REAL-TIME IMAGE PR, V13, P527, DOI 10.1007/s11554-016-0631-x
   [Anonymous], 2016, P 2016 23 INT C TELE
   [Anonymous], 2012, ACM MM'12'
   [Anonymous], 2013, P 6 ACM INT C WEB SE, DOI DOI 10.1145/2433396.2433443
   [Anonymous], 2014, P INT C MULTIMEDIA R, DOI [DOI 10.1145/2578726.2578776, 10.1145/2578726.2578776, 10.1145]
   [Anonymous], INT J HIGH PERFORMAN
   Borghol Y., 2012, ACM SIGKDD International Knowledge Discovery and Data Mining, P1186, DOI [DOI 10.1145/2339530.2339717, 10.1145/2339530.2339717]
   Cha M, 2009, IEEE ACM T NETWORK, V17, P1357, DOI 10.1109/TNET.2008.2011358
   Famaey J., 2011, 2011 IFIP/IEEE International Symposium on Integrated Network Management (IM 2011), P17, DOI 10.1109/INM.2011.5990669
   Figueiredo Flavio, 2011, P 4 ACM INT C WEB SE, P745, DOI DOI 10.1145/1935826.1935925
   Gao S, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P107, DOI 10.1145/2684822.2685303
   Gill P, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P15
   Hossain MS, 2018, FUTURE GENER COMP SY, V83, P596, DOI 10.1016/j.future.2017.03.029
   Li CY, 2016, IEEE ACCESS, V4, P1630, DOI 10.1109/ACCESS.2016.2552218
   Li LW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1912, DOI 10.1145/3123266.3127902
   Lv JN, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1883, DOI 10.1145/3123266.3127897
   Ming He, 2016, Database Systems for Advanced Applications. 21st International Conference, DASFAA 2016. Proceedings: LNCS 9643, P351, DOI 10.1007/978-3-319-32049-6_22
   Oghina Andrei, 2012, Advances in Information Retrieval. Proceedings of the 34th European Conference on IR Research (ECIR 2012), P503, DOI 10.1007/978-3-642-28997-2_51
   Roy SD, 2013, IEEE T MULTIMEDIA, V15, P1255, DOI 10.1109/TMM.2013.2265079
   Shen HW, 2014, AAAI CONF ARTIF INTE, P291
   Szabo G, 2010, COMMUN ACM, V53, P80, DOI 10.1145/1787234.1787254
   Tan ZY, 2016, IEEE T BROADCAST, V62, P436, DOI 10.1109/TBC.2016.2540522
   Wang XT, 2010, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON PRODUCT INNOVATION MANAGEMENT, VOLS I AND II, P193
   Wu JQ, 2016, IEEE T MULTIMEDIA, V18, P1882, DOI 10.1109/TMM.2016.2579600
   Xu J, 2015, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2015.7298836
   Zink M, 2009, COMPUT NETW, V53, P501, DOI 10.1016/j.comnet.2008.09.022
NR 27
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19289
EP 19306
DI 10.1007/s11042-020-08730-y
EA MAR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000520810400001
DA 2024-07-18
ER

PT J
AU Elaskily, MA
   Elnemr, HA
   Sedik, A
   Dessouky, MM
   El Banby, GM
   Elshakankiry, OA
   Khalaf, AAM
   Aslan, HK
   Faragallah, OS
   Abd El-Samie, FE
AF Elaskily, Mohamed A.
   Elnemr, Heba A.
   Sedik, Ahmed
   Dessouky, Mohamed M.
   El Banby, Ghada M.
   Elshakankiry, Osama A.
   Khalaf, Ashraf A. M.
   Aslan, Heba K.
   Faragallah, Osama S.
   Abd El-Samie, Fathi E.
TI A novel deep learning framework for copy-moveforgery detection in images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery detection; Image authentication; Deep learning;
   Convolutional neural networks; Tampered images
ID MOVE FORGERY DETECTION; DUPLICATION FORGERY; RECOGNITION
AB In this era of technology, digital images turn out to be ubiquitous in a contemporary society and they can be generated and manipulated by a wide variety of hardware and software technologies. Copy-move forgery is considered as an image tampering technique that aims to generate manipulated tampered images by concealing unwanted objects or reproducing desirable objects within the same image. Therefore, image content authentication has become an essential demand. In this paper, an innovative design for automatic detection of copy-move forgery based on deep learning approaches is proposed. A Convolutional Neural Network (CNN) is specifically designed for Copy-Move Forgery Detection (CMFD). The CNN is exploited to learn hierarchical feature representations from input images, which are used for detecting the tampered and original images. The extensive experiments demonstrate that the proposed deep CMFD algorithm outperforms the traditional CMFD systems by a considerable margin on the three publicly accessible datasets: MICC-F220, MICC-F2000, and MICC-F600. Furthermore, the three datasets are incorporated and joined to the SATs-130 dataset to form new combinations of datasets. An accuracy of 100% has been achieved for the four datasets. This proves the robustness of the proposed algorithm against a diversity of known attacks. For better evaluation, comparative results are included.
C1 [Elaskily, Mohamed A.; Aslan, Heba K.] Elect Res Inst, Dept Informat, Cairo, Egypt.
   [Elaskily, Mohamed A.; Dessouky, Mohamed M.; Elshakankiry, Osama A.; Faragallah, Osama S.] Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia 32952, Egypt.
   [Elnemr, Heba A.] ERI, Comp & Syst Dept, Cairo, Egypt.
   [Sedik, Ahmed] Kafrelsheikh Univ, Fac Artificial Inteligence, Dept Robot & Inteligent Machines, Kafrelsheikh, Egypt.
   [El Banby, Ghada M.] Menoufia Univ, Dept Ind Elect & Control Engn, Fac Elect Engn, Menoufia 32952, Egypt.
   [Elshakankiry, Osama A.; Faragallah, Osama S.] Taif Univ, Dept Informat Technol, Coll Comp & Informat Technol, Al Hawiyah 21974, Saudi Arabia.
   [Khalaf, Ashraf A. M.] Minia Univ, Dept Elect Engn, Fac Engn, Al Minya 61111, Egypt.
   [Abd El-Samie, Fathi E.] Menoufia Univ, Dept Elect & Elect Commun, Fac Elect Engn, Menoufia 32952, Egypt.
   [Abd El-Samie, Fathi E.] Princess Nourah Bint Abdulrahman Univ, Dept Informat Technol, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Dessouky, Mohamed M.] Univ Jeddah, Dept Comp Sci & Artificial Intelligence, Coll Comp Sci & Engn, Jeddah, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Electronics Research Institute (ERI);
   Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Electronics Research Institute (ERI); Egyptian Knowledge
   Bank (EKB); Kafrelsheikh University; Egyptian Knowledge Bank (EKB);
   Menofia University; Taif University; Egyptian Knowledge Bank (EKB);
   Minia University; Egyptian Knowledge Bank (EKB); Menofia University;
   Princess Nourah bint Abdulrahman University; University of Jeddah
RP Elaskily, MA (corresponding author), Elect Res Inst, Dept Informat, Cairo, Egypt.; Elaskily, MA (corresponding author), Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia 32952, Egypt.
EM Mohamed_elaskily@eri.sci.eg; heba_elnemr@yahoo.com;
   ahmedsedik93@gmail.com; mohamed.moawad@el-eng.menofia.edu.eg;
   ghada.elbanby@el-eng.menofia.edu.eg; osama_alshakankiry@yahoo.com;
   ashkhalaf@yahoo.com; hebaaslan@yahoo.com; osam_sal@yahoo.com;
   fathi_sayed@yahoo.com
RI Elaskily, Mohamed A./AAA-8852-2022; Sedik, Ahmed/AAX-6150-2020;
   Elaskily, Mohamed A./AAK-7369-2020; Sayed, Fathi/HRA-4752-2023; Aslan,
   Heba/IUO-7942-2023; Dessouky, Mohamed M./AAS-1043-2020; Khalaf, Ashraf
   ِA. M./X-8289-2018; Faragallah, Osama S./AHB-8031-2022; Sedik,
   Ahmed/GXV-6723-2022
OI Elaskily, Mohamed A./0000-0002-9136-0970; Sedik,
   Ahmed/0000-0002-7651-8362; Sayed, Fathi/0000-0001-8749-9518; Dessouky,
   Mohamed M./0000-0003-2609-2225; Khalaf, Ashraf ِA.
   M./0000-0003-3344-5420; Faragallah, Osama S./0000-0003-1982-335X; Sedik,
   Ahmed/0000-0002-7651-8362
CR Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   BOZ A, 2016, 24 SIGN PROC COMM AP, P16
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Costanzo A, 2014, IEEE T INF FOREN SEC, V9, P1450, DOI 10.1109/TIFS.2014.2337654
   Tran DT, 2018, NEURAL NETWORKS, V105, P328, DOI 10.1016/j.neunet.2018.05.017
   DERROLL D, 2015, INT J ADV COMPUT TEC, V4
   Diane WNN, 2014, SCI WORLD J, DOI 10.1155/2014/975456
   ELASKILY MA, 2017, INT C ADV CONTR CIRC
   Elaskily MA, 2019, MULTIMED TOOLS APPL, V78, P15353, DOI 10.1007/s11042-018-6891-7
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Hosny KM, 2019, IET IMAGE PROCESS, V13, P1437, DOI 10.1049/iet-ipr.2018.5356
   Hosny KM, 2018, IMAGING SCI J, V66, P330, DOI 10.1080/13682199.2018.1461345
   Hosny KM, 2008, J REAL-TIME IMAGE PR, V3, P97, DOI 10.1007/s11554-007-0058-5
   Huang HL, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P1241
   KANG X, 2012, INT J DIGIT CONTENT, V6
   KAUR H, 2015, INT J ELECT ELECT CO, V4
   Khan MK, 2018, AUST J FORENSIC SCI, V50, P525, DOI 10.1080/00450618.2017.1296186
   Kim D.-H., 2017, International Journal of Applied Engineering Research, V12, P11640
   Kingma D. P., 2014, arXiv
   KUSHOL R, 2016, INT C DIG IM COMP TE
   LENG L, 2010, INT C INF COMM TECHN
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lin X, 2018, ENGINEERING-PRC, V4, P29, DOI 10.1016/j.eng.2018.02.008
   Liu GJ, 2011, J NETW COMPUT APPL, V34, P1557, DOI 10.1016/j.jnca.2010.09.001
   Liu Y, 2017, MULTIMED TOOLS APPL, V76, P11065, DOI 10.1007/s11042-016-3540-x
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Luo Weiqi, 2007, Frontiers of Computer Science in China, V1, P166, DOI 10.1007/s11704-007-0017-0
   MAHMOUD K, 2016, INT J COMPUT SCI INF, V14
   Mishra P, 2013, SCI WORLD J, DOI 10.1155/2013/267691
   Muhammad G., 2013, INT INFORM I, V16, P2957
   Ouyang JL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   PRAJAPATI BM, 2015, INT J TECHNOL RES EN, V2
   Rao Y, 2016, IEEE INT WORKS INFOR
   Renard BY, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-355
   Sadeghi S, 2018, PATTERN ANAL APPL, V21, P291, DOI 10.1007/s10044-017-0678-8
   SHAH H, 2013, INT J ENG INNOV RES, V2
   Sharma S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P795, DOI 10.1109/CICT.2015.88
   THAJEEL SA, 2014, J THEOR APPL INF TEC, V70
   VARTAK R, 2014, INT J RES ADVENT TEC, V2
   WANG P, 2015, MULTIMED TOOLS APPL, V75, P2879
   WARIF NBA, 2016, J NETW COMPUT APPL, V75, P259, DOI DOI 10.1016/J.JNCA.2016.09.008
   Wu Y, 2018, IEEE WINT CONF APPL, P1907, DOI 10.1109/WACV.2018.00211
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zakariah M, 2018, MULTIMED TOOLS APPL, V77, P1009, DOI 10.1007/s11042-016-4277-2
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   ZHAN Y, 2017, P 5 ACM WORKSH INF H
   ZIMBA M, 2011, INT J DIGIT CONTENT, V5
NR 55
TC 45
Z9 45
U1 2
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19167
EP 19192
DI 10.1007/s11042-020-08751-7
EA MAR 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000520811300002
DA 2024-07-18
ER

PT J
AU Dubey, SR
   Mukherjee, S
AF Dubey, Shiv Ram
   Mukherjee, Snehasis
TI LDOP: local directional order pattern for robust face retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local descriptors; Face image; Local ordering; Intensity order; Image
   retrieval; Robustness; LBP
ID BINARY PATTERNS; RECOGNITION; DESCRIPTOR; ROTATION; CLASSIFICATION;
   REPRESENTATION; HISTOGRAM; MODEL
AB The local descriptors have gained wide range of attention due to their enhanced discriminative abilities. It has been proved that the consideration of multi-scale local neighborhood improves the performance of the descriptor, though at the cost of increased dimension. This paper proposes a novel method to construct a local descriptor using multi-scale neighborhood by finding the local directional order among the intensity values at different scales in a particular direction. Local directional order is the multi-radius relationship factor in a particular direction. The proposed local directional order pattern (LDOP) for a particular pixel is computed by finding the relationship between the center pixel and local directional order indexes. It is required to transform the center value into the range of neighboring orders. Finally, the histogram of LDOP is computed over whole image to construct the descriptor. In contrast to the state-of-the-art descriptors, the dimension of the proposed descriptor does not depend upon the number of neighbors involved to compute the order; it only depends upon the number of directions. The introduced descriptor is evaluated over the image retrieval framework and compared with the state-of-the-art descriptors over challenging face databases such as PaSC, LFW, PubFig, FERET, AR, AT&T, and ExtendedYale. The experimental results confirm the superiority and robustness of the LDOP descriptor.
C1 [Dubey, Shiv Ram; Mukherjee, Snehasis] Indian Inst Informat Technol, Comp Vis Grp, Chittoor 517646, Andhra Pradesh, India.
RP Dubey, SR (corresponding author), Indian Inst Informat Technol, Comp Vis Grp, Chittoor 517646, Andhra Pradesh, India.
EM srdubey@iiits.in; snehasis.mukherjee@iiits.in
RI Dubey, Shiv Ram/T-7541-2019; Mukherjee, Snehasis/Q-1000-2019
OI Dubey, Shiv Ram/0000-0002-4532-8996; Mukherjee,
   Snehasis/0000-0002-2196-8980
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2014, PDIST2
   Arandjelovi O, 2012, BRIT MACH VIS C, P121
   Benavente R, 1998, 24 COMP VIS CTR
   Beveridge JR, 2015, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2015.7163156
   CAO ZM, 2010, PROC CVPR IEEE, P2707, DOI DOI 10.1109/CVPR.2010.5539992
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P1201, DOI 10.1007/s11042-015-3111-6
   Chan CH, 2013, IEEE T PATTERN ANAL, V35, P1164, DOI 10.1109/TPAMI.2012.199
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959
   Dubey SR, 2014, IEEE T IMAGE PROCESS, V23, P5323, DOI 10.1109/TIP.2014.2358879
   Fan B, 2012, IEEE T PATTERN ANAL, V34, P2031, DOI 10.1109/TPAMI.2011.277
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gupta R, 2010, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2010.5540195
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Jeong K, 2015, IEEE SIGNAL PROC LET, V22, P1400, DOI 10.1109/LSP.2014.2372762
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lu K, 2015, IEEE T IMAGE PROCESS, V24, P1449, DOI 10.1109/TIP.2015.2395961
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Phillips PJ, 2013, IEEE SIXTH INTERNATI
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Quellec G, 2012, IEEE T IMAGE PROCESS, V21, P1613, DOI 10.1109/TIP.2011.2180915
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Sanderson C, 2009, LECT NOTES COMPUT SC, V5558, P199, DOI 10.1007/978-3-642-01793-3_21
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   ul Hussain S, 2012, LECT NOTES COMPUT SC, V7573, P716, DOI 10.1007/978-3-642-33709-3_51
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294
   Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Yang B, 2013, NEUROCOMPUTING, V120, P365, DOI 10.1016/j.neucom.2012.10.032
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 59
TC 20
Z9 20
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6363
EP 6382
DI 10.1007/s11042-019-08370-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900041
DA 2024-07-18
ER

PT J
AU Kim, M
   Park, KB
   Choi, SH
   Lee, JY
AF Kim, Minseok
   Park, Kyeong-Beom
   Choi, Sung Ho
   Lee, Jae Yeol
TI Inside-reachable and see-through augmented reality Shell for 3D
   visualization and tangible interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; AR cube; See-through AR shell; 3D AR visualization
   and interaction
ID DESIGN
AB Augmented reality (AR) is considered as one of the most essential technologies for providing 3D information visualization superimposed in the physical object. Thus, AR has been applied to various applications such as entertainment, education, and human-computer interaction. In particular, AR cubes have also been widely used since they can provide multi-perspective and immersive 3D visualization. However, an inherent problem in current AR cubes is that they cannot support practical and tangible interactions with both virtual and physical artifacts. Thus, they can only provide simple manipulations with a limited interaction metaphor. In particular, they cannot support internal accessibility and direct manipulation with virtual and physical objects inside the cube. This paper presents a new and innovative form of an AR cube, called inside-reachable and see-through AR shell. The AR shell can support more intuitive and tangible interaction with AR objects than conventional AR cubes. One of the unique characteristics of the AR shell is that the physical tool is accessible inside the shell. To make the AR shell be inside-reachable, each face of the AR shell may have a physical hole. This fabrication of the AR shell supports not only multi-perspective views but also provides tangible and natural interaction through the physical holes. In addition, faces with holes may prevent the AR camera from tracking AR markers consistently and adequately due to the reduced tracking areas. Thus, the proposed AR shell can be made of some faces without holes and the other faces with holes. An occlusion rendering is used for showing depth cues to visualize occlusions, which makes the faces without holes see-through. Therefore, the user can interact with AR objects inside the shell through physical holes while the user views the inside of the shell through physically occluded faces. We have also extended the proposed approach to run in a mobile HMD. We have performed formal quantitative and quantitative analyses by evaluating task performance and questionnaire. Several implementations will be presented to prove the originality and advantage of the proposed AR shell.
C1 [Kim, Minseok; Park, Kyeong-Beom; Choi, Sung Ho; Lee, Jae Yeol] Chonnam Natl Univ, Dept Ind Engn, 77 Yongbong Ro, Gwangju 61186, South Korea.
C3 Chonnam National University
RP Lee, JY (corresponding author), Chonnam Natl Univ, Dept Ind Engn, 77 Yongbong Ro, Gwangju 61186, South Korea.
EM jaeyeol@jnu.ac.kr
OI choi, sungho/0000-0003-0887-0150; Park, Kyeong-Beom/0000-0003-4737-730X
CR [Anonymous], 2014 IEEE GAM MED
   [Anonymous], P ISMAR ADJ 16
   [Anonymous], P IEEE VR 04
   [Anonymous], 2004, ACM INT C P SERIES
   [Anonymous], INT J COMPUTER GAMES
   [Anonymous], P IEEE VR 17
   Avery B, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P79
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Chakraborty A., 2014, CHI '14 Extended Abstracts on Human Factors in Computing Systems. CHI EA '14, P1315, DOI DOI 10.1145/2559206.2581340
   Coma-Tatay I, 2019, MULTIMED TOOLS APPL, V78, P6093, DOI 10.1007/s11042-018-6395-5
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1095, DOI 10.1109/TVCG.2008.59
   Fenu C, 2018, INT J HUM-COMPUT ST, V114, P20, DOI 10.1016/j.ijhcs.2018.01.009
   Gabriele A, 2009, PROC ANN BUCLD, P175
   Harish P, 2013, IEEE T VIS COMPUT GR, V19, P407, DOI 10.1109/TVCG.2012.135
   Heun Valentin., 2013, PROC, P961
   HINCKLEY K, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P452, DOI 10.1145/191666.191821
   Hornecker E, 2009, INTERACT COMPUT, V21, P95, DOI 10.1016/j.intcom.2008.10.007
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   Juan C. M., 2010, 2010 IEEE 10th International Conference on Advanced Learning Technologies (ICALT 2010), P599, DOI 10.1109/ICALT.2010.170
   Juan C, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P233, DOI 10.1109/ICALT.2008.122
   Kim M, 2016, MULTIMED TOOLS APPL, V75, P16529, DOI 10.1007/s11042-016-3355-9
   Lam B., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P135, DOI 10.1109/3DUI.2011.5759242
   Lee H, 2011, VIRTUAL REAL-LONDON, V15, P133, DOI 10.1007/s10055-010-0163-9
   Lee JY, 2010, INT J ADV MANUF TECH, V51, P1069, DOI 10.1007/s00170-010-2671-x
   Lee JY, 2009, INT J ADV MANUF TECH, V45, P649, DOI 10.1007/s00170-009-2012-0
   MULDER JD, 2002, P VIRT REAL INT C VR, P73
   Park H, 2014, J COMPUT DES ENG, V1, P289, DOI 10.7315/JCDE.2014.028
   Park H, 2013, J ADV MECH DES SYST, V7, P827, DOI 10.1299/jamdsm.7.827
   Pla P., 2012, CHI 12 EXTENDED ABST, P2015, DOI [https://doi.org/10.1145/2212776.2223745, DOI 10.1145/2212776.2223745]
   Schweikardt E., 2006, P 8 INT C MULT INT, DOI DOI 10.1145/1180995.1181010
   Seo DW, 2013, EXPERT SYST APPL, V40, P3784, DOI 10.1016/j.eswa.2012.12.091
   Sharlin E., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P347, DOI 10.1145/503376.503438
   Sin AK, 2009, LECT NOTES COMPUT SC, V5857, P302, DOI 10.1007/978-3-642-05036-7_29
   Stavness I, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1381
   Terrenghi L, 2006, PERS UBIQUIT COMPUT, V10, P153, DOI 10.1007/s00779-005-0025-8
   Wang DL, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/598547
   Yonemoto S, 2007, IEEE INT CONF INF VI, P781
   You CW, 2014, INT J HUM-COMPUT ST, V72, P606, DOI 10.1016/j.ijhcs.2014.03.001
   Zhou J, 2004, I C CONT AUTOMAT ROB, P19
   Zhou Zhiying., 2005, CHI Extended Abstracts, P1156
NR 40
TC 6
Z9 6
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5941
EP 5963
DI 10.1007/s11042-019-08324-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900023
DA 2024-07-18
ER

PT J
AU Yang, Y
   Liu, XM
   Guo, WZ
   Zheng, XH
   Dong, C
   Liu, ZQ
AF Yang, Yang
   Liu, Ximeng
   Guo, Wenzhong
   Zheng, Xianghan
   Dong, Chen
   Liu, Zhiquan
TI Multimedia access control with secure provenance in fog-cloud computing
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia data; Access control; Secure provenance; Fog computing; Data
   provider trace
ID BIG DATA
AB Multimedia data, ranging from text, audio, video to animation, undergoes intellectual property protection or has high sensitivity. To deal with privacy leakage during multimedia sharing and dissemination, it is crucial to trace the origin and transformation history of multimedia data, which is called multimedia provenance. In this paper, we construct a multimedia access control system with secure provenance in fog-cloud computing networks, which is designed based on attribute based encryption (ABE) and zero of knowledge technologies. The proposed scheme realizes confidentiality of multimedia big data that is outsourced to the cloud, anonymity of data provider, fine-grained access control of encrypted data, irrefutable of the provenance data, and traceability of data provider. We utilize the fog server to reduce user's decryption burden and transfer partial decryption tasks. The suggested system is formally proved indistinguishable against chosen plaintext attack (IND-CPA). The simulation and experimental results indicate that our system has low communication overhead and low computation cost.
C1 [Yang, Yang; Liu, Ximeng; Guo, Wenzhong; Zheng, Xianghan; Dong, Chen] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Peoples R China.
   [Yang, Yang] Guangxi Key Lab Cryptog & Informat Secur, Guangnxi, Peoples R China.
   [Yang, Yang; Liu, Zhiquan] Guangdong Prov Key Lab Data Secur & Privacy Prote, Guangzhou, Peoples R China.
   [Yang, Yang] Minjiang Univ, Fujian Prov Key Lab Informat Proc & Intelligent C, Fuzhou, Peoples R China.
C3 Fuzhou University; Minjiang University
RP Guo, WZ (corresponding author), Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Peoples R China.
EM guowenzhong@fzu.edu.cn
RI Dong, Chen/AAR-4167-2021; Liu, Ximeng/AAE-2151-2019; Liu,
   Zhiquan/KMY-7613-2024
OI Liu, Ximeng/0000-0002-4238-3295; Liu, Zhiquan/0000-0002-3934-2177
FU National Natural Science Foundation of China [61872091]; Guangxi Key
   Laboratory of Cryptography and Information Security [GCIS201721];
   Opening Project of Guangdong Provincial Key Laboratory of Data Security
   and Privacy Protection [2017B030301004-13]; Fujian Provincial Key
   Laboratory of Information Processing and Intelligent Control (Minjiang
   University) [MJUKF-IPIC201908]
FX This work is supported by National Natural Science Foundation of China
   (No. 61872091); Guangxi Key Laboratory of Cryptography and Information
   Security (No. GCIS201721); Opening Project of Guangdong Provincial Key
   Laboratory of Data Security and Privacy Protection (No.
   2017B030301004-13); Fujian Provincial Key Laboratory of Information
   Processing and Intelligent Control (Minjiang University) (No.
   MJUKF-IPIC201908).
CR [Anonymous], IEEE T SERVICES COMP
   [Anonymous], 1996, SECURE SCHEMES SECRE
   [Anonymous], STANFORD PAIRING BAS
   Chang V, 2017, 2017 INT C ENG TECHN, P1
   Chang V, 2015, AD HOC NETW, V35, P65, DOI 10.1016/j.adhoc.2015.07.012
   Hallman R, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P2645, DOI 10.1145/3133956.3137043
   Hong HS, 2018, MULTIMED TOOLS APPL, V77, P4477, DOI 10.1007/s11042-017-4804-9
   Hu L, 2016, MULTIMED TOOLS APPL, V75, P12645, DOI 10.1007/s11042-015-2450-7
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Jamil F, 2018, COMPUT SECUR, V73, P34, DOI 10.1016/j.cose.2017.10.005
   Kuo CT, 2018, FUTURE GENER COMP SY, V86, P1424, DOI 10.1016/j.future.2017.12.069
   Li J, 2014, FUTURE GENER COMP SY, V37, P259, DOI 10.1016/j.future.2013.10.006
   Li YB, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2978575
   LIANG X, 2019, BLOCKCHAIN DISTRIBUT, P67
   Ma SG, 2019, IEEE ACCESS, V7, P114131, DOI 10.1109/ACCESS.2019.2935513
   Qin Z, 2018, IEEE CLOUD COMPUT, V5, P48
   Rani MMS, 2016, ADV INTELL SYST, V412, P403, DOI 10.1007/978-981-10-0251-9_38
   Ren J, 2019, MULTIMED TOOLS APPL, V78, P26965, DOI 10.1007/s11042-017-4479-2
   Rouselakis Y., 2013, P 2013 ACM SIGSAC C, P463
   Sarkar S, 2018, IEEE T CLOUD COMPUT, V6, P46, DOI 10.1109/TCC.2015.2485206
   Sultana S, 2015, IEEE T DEPEND SECURE, V12, P256, DOI 10.1109/TDSC.2013.44
   Sultana S, 2013, IEEE T KNOWL DATA EN, V25, P1890, DOI 10.1109/TKDE.2012.31
   Wang CD, 2016, IEEE T PARALL DISTR, V27, P405, DOI 10.1109/TPDS.2015.2402156
   Xia YJ, 2017, IEEE T INTELL TRANSP, V18, P2629, DOI 10.1109/TITS.2017.2653103
   Xu K, 2012, IEEE T DEPEND SECURE, V9, P173, DOI 10.1109/TDSC.2011.50
   YANG Y, 2018, IEEE T CLOUD COMPUT, V29
   YANG Y, 2017, IEEE T DEPENDABLE SE, V20
   YANG Y, 2018, IEEE T CLOUD COMPUT
   Yang Y, 2019, INFORM SCIENCES, V479, P567, DOI 10.1016/j.ins.2018.02.005
   Yang Y, 2020, IEEE T DEPEND SECURE, V17, P78, DOI 10.1109/TDSC.2017.2729556
   Yi S, 2015, INT CONF SOFTW ENG, P686, DOI 10.1109/ICSESS.2015.7339150
NR 31
TC 4
Z9 4
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10701
EP 10716
DI 10.1007/s11042-020-08703-1
EA FEB 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000516956800001
DA 2024-07-18
ER

PT J
AU Mota, VF
   de Oliveira, HN
   Scalzo, S
   Dittz, D
   Santos, RJ
   dos Santos, JA
   Araújo, AD
AF Mota, Virginia F.
   de Oliveira, Hugo N.
   Scalzo, Sergio
   Dittz, Dalton
   Santos, Reginaldo J.
   dos Santos, Jefersson A.
   Araujo, Arnaldo de A.
TI From video pornography to cancer cells: a tensor framework for
   spatiotemporal description
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Orientation tensor; Support vector machine; Video classification; Tensor
   framework; Pornography classification; Cancer cell motion; Deep features
ID IN-VITRO; REPRESENTATION; CLASSIFICATION; HISTOGRAMS; SELECTION; MODELS;
   SPACE; FLOW
AB Spatiotemporal description is a research field with applications in various areas such as video indexing, surveillance, human-computer interfaces, among others. Big Data problems in large databases are now being treated with Deep Learning tools, however we still have room for improvement in spatiotemporal handcraft description. Moreover, we still have problems that involve small data in which data augmentation and other techniques are not valid, or even, it is not worth the use of an expensive method. The main contribution of this work is the development of a framework for spatiotemporal representation using orientation tensors enabling dimension reduction and invariance. This is a multipurpose framework called Features As Spatiotemporal Tensors (FASTensor). We evaluate this framework in two different applications: Video Pornography classification and Cancer Cell classification. The latter one is also a contribution of this work, since we introduce a new dataset called Melanoma Cancer Cell (MCC). It is a small dataset with inherent difficulties in the acquisition process and its particular motion nature. The results are competitive, while also being ease to compute. Finally, our results in the MCC dataset can be used in other cancer cell treatment analysis.
C1 [Mota, Virginia F.; de Oliveira, Hugo N.; dos Santos, Jefersson A.; Araujo, Arnaldo de A.] Univ Fed Minas Gerais, Dept Comp Sci, Belo Horizonte, MG, Brazil.
   [Mota, Virginia F.; de Oliveira, Hugo N.] Univ Fed Minas Gerais, Colegio Tecn, Belo Horizonte, MG, Brazil.
   [Scalzo, Sergio; Dittz, Dalton] Univ Fed Minas Gerais, Dept Physiol & Biophys, Belo Horizonte, MG, Brazil.
   [Santos, Reginaldo J.] Univ Fed Minas Gerais, Dept Math, Belo Horizonte, MG, Brazil.
C3 Universidade Federal de Minas Gerais; Universidade Federal de Minas
   Gerais; Universidade Federal de Minas Gerais; Universidade Federal de
   Minas Gerais
RP Mota, VF (corresponding author), Univ Fed Minas Gerais, Dept Comp Sci, Belo Horizonte, MG, Brazil.; Mota, VF (corresponding author), Univ Fed Minas Gerais, Colegio Tecn, Belo Horizonte, MG, Brazil.
EM virginiaferm@dcc.ufmg.br; jefersson@dcc.ufmg.br
RI Oliveira, Hugo Neves/HLW-3162-2023; Scalzo, Sérgio/ABG-8184-2021; Dittz,
   Dalton/N-9586-2017; Mota, Virgínia/ABD-4530-2020; dos Santos,
   Jefersson/HKW-4282-2023
OI Oliveira, Hugo Neves/0000-0001-8760-9801; Dittz,
   Dalton/0000-0002-4370-0803; dos Santos, Jefersson/0000-0002-8889-1586;
   Scalzo, Sergio/0000-0002-1496-878X
FU FAPEMIG; CAPES; CNPq; NVIDIA; UFMG
FX Authors would like to thank UFMG, FAPEMIG, CAPES and CNPq for funding
   and NVIDIA for support.
CR Almeida J, 2016, PATTERN RECOGN LETT, V81, P90, DOI 10.1016/j.patrec.2015.11.028
   Andaló FA, 2007, IEEE IMAGE PROC, P3145
   [Anonymous], 1995, Signal Processing for Computer Vision
   Augereau B, 2005, THIRTEENTH COLOR IMAGING CONFERENCE, FINAL PROGRAM AND PROCEEDINGS, P130
   Avila S., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2909, DOI 10.1109/ICIP.2011.6116268
   Avila S, 2013, COMPUT VIS IMAGE UND, V117, P453, DOI 10.1016/j.cviu.2012.09.007
   Baburaj M, 2019, MULTIMED TOOLS APPL, V78, P1805, DOI 10.1007/s11042-018-6251-7
   Baeza-Yates R., 1999, Modern information retrieval
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BRADBURY RH, 2007, OVERVIEW BT CANC, P1
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Caetano C, 2016, INT C PATT RECOG, P1947, DOI 10.1109/ICPR.2016.7899921
   Caetano C, 2016, NEUROCOMPUTING, V213, P102, DOI 10.1016/j.neucom.2016.03.099
   Chengcheng Jia, 2010, 2010 2nd International Conference on Computer Engineering and Technology (ICCET), P60, DOI 10.1109/ICCET.2010.5485732
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   de Castro TK, 2009, LECT NOTES COMPUT SC, V5544, P429, DOI 10.1007/978-3-642-01970-8_42
   de Oliveira FLM, 2015, LECT NOTES COMPUT SC, V9155, P283, DOI 10.1007/978-3-319-21404-7_21
   Decaestecker C, 2007, MED RES REV, V27, P149, DOI 10.1002/med.20078
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Farnebäck G, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P171, DOI 10.1109/ICCV.2001.937514
   de Souza KJF, 2014, PATTERN RECOGN LETT, V47, P85, DOI 10.1016/j.patrec.2014.02.016
   FORSTNER W, 1994, EUR C COMP VIS, P383
   Gillet JP, 2013, JNCI-J NATL CANCER I, V105, P452, DOI 10.1093/jnci/djt007
   Goodspeed A, 2016, MOL CANCER RES, V14, P3, DOI 10.1158/1541-7786.MCR-15-0189
   Gracias N, 2005, OCEANS-IEEE, P1295
   GRUNDMANN M, 2010, PROC CVPR IEEE, P2141, DOI DOI 10.1109/CVPR.2010.5539893
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   HART IR, 1979, AM J PATHOL, V97, P587
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   JOHANSSON B, 2002, P SSAB02 S IM AN LUN, P69
   Juan Kang, 2011, 2011 International Conference on Electronic & Mechanical Engineering and Information Technology (EMEIT 2011), P3434, DOI 10.1109/EMEIT.2011.6023066
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Katira P, 2013, FRONT ONCOL, V3, DOI 10.3389/fonc.2013.00145
   Kim TK, 2007, PROC CVPR IEEE, P1275
   Krausz Barbara, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1763, DOI 10.1109/ICPR.2010.435
   Kriegel FL, 2018, CYTOM PART A, V93A, P323, DOI 10.1002/cyto.a.23279
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan XY, 2019, IEEE T IND ELECTRON, V66, P9887, DOI 10.1109/TIE.2019.2898618
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Laptev I, 2007, IEEE I CONF COMP VIS, P2165
   Laptev I, 2007, COMPUT VIS IMAGE UND, V108, P207, DOI 10.1016/j.cviu.2006.11.023
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Mak M, 2015, INTEGR BIOL-UK, V7, P1093, DOI 10.1039/c5ib00043b
   Malandrino A, 2018, ACS BIOMATER SCI ENG, V4, P294, DOI 10.1021/acsbiomaterials.7b00041
   Martin TraceyA., 2013, Cancer invasion and metastasis: molecular and cellular perspective, DOI DOI 10.1038/NATURE06757
   Masuzzo P, 2016, TRENDS CELL BIOL, V26, P88, DOI 10.1016/j.tcb.2015.09.003
   Mordohai P., 2007, TENSOR VOTING PERCEP
   Moreira D, 2016, FORENSIC SCI INT, V268, P46, DOI 10.1016/j.forsciint.2016.09.010
   Mota VF, 2014, PATTERN RECOGN LETT, V39, P85, DOI 10.1016/j.patrec.2013.08.008
   Mota Virginia F., 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P328, DOI 10.1109/SIBGRAPI.2013.52
   Mota V. F., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P298, DOI 10.1109/SIBGRAPI.2012.48
   Mota VF, 2009, IEEE IMAGE PROC, P2165, DOI 10.1109/ICIP.2009.5414074
   PASUPA K, 2016, INT C INF TECHN EL E
   Perez EA, 2012, INT C PATT RECOG, P3460
   Perez M, 2017, NEUROCOMPUTING, V230, P279, DOI 10.1016/j.neucom.2016.12.017
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Prates R, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.3.033041
   Ramnath Nithya, 2004, Curr Oncol Rep, V6, P96, DOI 10.1007/s11912-004-0020-7
   Sad Dhiego, 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P70, DOI 10.1109/SIBGRAPI.2013.19
   Saha Punam K, 2010, DICTA, V2010, P429, DOI 10.1109/DICTA.2010.79
   SANTOS RJ, 2017, MATRIZES VETORES GEO
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sze V., 2014, HIGH EFFICIENCY VIDE, DOI [10.1007/978-3-319-06895-4, DOI 10.1007/978-3-319-06895-4]
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   VILLAREAL MO, 2018, BMC CANCER, V18
   Wang T., 2018, ARXIV
   Wehrmann J, 2018, NEUROCOMPUTING, V272, P432, DOI 10.1016/j.neucom.2017.07.012
   WESTIN CF, 1994, THESIS
   Wiegand T, 2007, IEEE SIGNAL PROC MAG, V24, P148, DOI 10.1109/MSP.2007.323282
   Xu ZY, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P1032, DOI 10.1109/ISBI.2012.6235734
   Young EWK, 2013, INTEGR BIOL-UK, V5, P1096, DOI 10.1039/c3ib40076j
   Zaman MH, 2013, NAT REV CANCER, V13, P596, DOI 10.1038/nrc3564
   Zelnik-Manor L, 2001, PROC CVPR IEEE, P123
   Zhang JG, 2018, MULTIMED TOOLS APPL, V77, P29213, DOI 10.1007/s11042-018-5916-6
   Zhang J, 2019, MULTIMED TOOLS APPL, V78, P4001, DOI 10.1007/s11042-017-5173-0
NR 83
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13919
EP 13949
DI 10.1007/s11042-020-08642-x
EA FEB 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000511062200001
DA 2024-07-18
ER

PT J
AU Beena, MV
   Namboodiri, A
   Thottungal, R
AF Beena, M., V
   Namboodiri, Agnisarman
   Thottungal, Rani
TI Hybrid approaches of convolutional network and support vector machine
   for American sign language prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE American sign language; Support vector machine; Convolutional neural
   network; Segmentation
ID RECOGNITION
AB The American Gesture based communication (ASL) is expressively helped for hard of hearing correspondence. Slowly gesture based communication use for the correspondence among open and the hard of hearing network. In this proposed framework another model of ASL letters in order and numerals are utilized to effectively recognize. It comprises of train hybrid classifier and 4 stages they are Pre-processing, segmentation, feature extraction and classification. The train hybrid classifier comprises of 35 letter sets and number which is familiar to gathering intensity information onto numerous subjects. This exertion connected with existing classifier, for example, CNN and ANN classifier. The execution of proposed work is estimated about precision, specificity and sensitivity on test result. It will help to, diminishes the false positive rates and accomplishes a decent accuracy yield.
C1 [Beena, M., V] Vidya Acad Sci & Technol, Comp Sci & Engn, Trichur, Kerala, India.
   [Namboodiri, Agnisarman] Vidya Acad Sci & Technol, VAST, Trichur, Kerala, India.
   [Thottungal, Rani] Kumaraguru Coll Technol, EEE Dept, Coimbatore, Tamil Nadu, India.
C3 Kumaraguru College of Technology
RP Beena, MV (corresponding author), Vidya Acad Sci & Technol, Comp Sci & Engn, Trichur, Kerala, India.
EM beenamv2007@gmail.com; agnisarman@vidyaacademy.ac.in;
   ranithottungal@yahoo.com
RI THOTTUNGAL, RANI/P-1114-2015
OI THOTTUNGAL, RANI/0000-0003-4878-0854
CR Almeida SGM, 2014, EXPERT SYST APPL, V41, P7259, DOI 10.1016/j.eswa.2014.05.024
   [Anonymous], HISTOGRAMS ORIENTED
   [Anonymous], P IEEE RO MAN ATL GA
   [Anonymous], 2013, IEEE C AFGR
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   Dan Xu, 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P689, DOI 10.1109/ROBIO.2012.6491047
   Lahamy H, 2012, SENSORS-BASEL, V12, P14416, DOI 10.3390/s121114416
   Palacios JM, 2013, SENSORS-BASEL, V13, P11842, DOI 10.3390/s130911842
   Ramey A, 2011, ACMIEEE INT CONF HUM, P229, DOI 10.1145/1957656.1957745
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Yang HD, 2013, PATTERN RECOGN LETT, V34, P2051, DOI 10.1016/j.patrec.2013.06.022
   Yang HD, 2010, PATTERN RECOGN, V43, P2858, DOI 10.1016/j.patcog.2010.03.007
   Yang HD, 2009, IEEE T PATTERN ANAL, V31, P1264, DOI 10.1109/TPAMI.2008.172
   Zafrulla Z., 2011, Proceedings of the 13th international conference on multimodal interfaces, New York, NY, USA, P279, DOI DOI 10.1145/2070481.2070532
   Zhang S., 2012, P INT C IMAGE ANAL S, P1
   Zhang YG, 2013, J NANOPART RES, V15, P1, DOI 10.1007/s11051-013-2007-5
NR 17
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 4027
EP 4040
DI 10.1007/s11042-019-7723-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700052
DA 2024-07-18
ER

PT J
AU Menezes, J
   Poojary, N
AF Menezes, Jacintha
   Poojary, Nagesh
TI A fusion approach to classify hyperspectral oil spill data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Oil emulsion; Spectral signature; Hyperspectral imaging; Derivative
   spectrum; Spectral filtering
ID SIGNAL; SATELLITE
AB Oil spills in the ocean are one of the major environmental concerns as they pose significant threat to the ecosystem. In the recent year's hyperspectral sensors have been used to detect oil spills due to their ability to capture reflected solar signal with very narrow bandwidth, that enables to differentiate materials even with subtle signature differences. However high spectral dimensionality affects classification accuracy due to insufficient training samples. Conventional methods have dealt with this problem through band (or feature) selection or feature extraction (or transformation) approaches. In the case of an oil emulsion signal, as evident from the literature the oil characteristics are present only in certain bands of a spectral signature. Hence feature selection without focusing on right bands may lead to selecting features of less significance for target identification. Moreover, in feature extraction approaches during transformation from high dimensional space to low dimension space some of the important features could be lost. Hence, the proposed research takes advantage of different but complimentary benefits of both feature selection and feature extraction methods to obtain final features effectively. In the proposed research, features are selected by modelling the oil emulsion signal using derivative spectrum and calculation of partial sum of energies. Derivative spectrum represents variation in signal energies and calculation of partial sum of signal energies for each band facilitates the application of filters bank to capture oil sensitive signal characteristics. Feature extraction is done through wavelet transform by gradual multi-scale zooming of signals through partial analysis of time (space) frequencies. The obtained features are fused together and fed to Gaussian Mixture Model (GMM) classifier to classify oil emulsions. The proposed approach gives 5% to-10% higher classification accuracy as compared to some of the conventional techniques.
C1 [Menezes, Jacintha] Bharathiar Univ, Res & Dev Ctr, Coimbatore, Tamil Nadu, India.
   [Poojary, Nagesh] Manipal Educ Acad, Manipal 576104, Karnataka, India.
C3 Bharathiar University; Manipal Academy of Higher Education (MAHE)
RP Menezes, J (corresponding author), Bharathiar Univ, Res & Dev Ctr, Coimbatore, Tamil Nadu, India.
EM jacinthamcuc@gmail.com; nagesh.poojary@ieee.org
RI MENEZES, JACINTHA/AAH-6591-2020
OI MENEZES, JACINTHA/0000-0002-7580-2759
CR Abbriano RM, 2011, OCEANOGRAPHY, V24, P294, DOI 10.5670/oceanog.2011.80
   Alam M. S., 2012, 2012 7th International Conference on Electrical & Computer Engineering (ICECE), P858, DOI 10.1109/ICECE.2012.6471686
   [Anonymous], 2009, Atmospheric Correction Module: QUAC and FLAASH User's Guide
   [Anonymous], 2000, ISMIR
   Brekke C, 2005, REMOTE SENS ENVIRON, V95, P1, DOI 10.1016/j.rse.2004.11.015
   Byfield V., 1999, IEEE 1999 International Geoscience and Remote Sensing Symposium. IGARSS'99 (Cat. No.99CH36293), P1475, DOI 10.1109/IGARSS.1999.771992
   Cariou C, 2011, IEEE GEOSCI REMOTE S, V8, P565, DOI 10.1109/LGRS.2010.2091673
   Cheriyadat A, 2003, INT GEOSCI REMOTE SE, P3420
   Clark RN., 2010, US GEOL SURV OPEN FI, V1167, P1
   Cortés G, 2016, IEEE J-STARS, V9, P253, DOI 10.1109/JSTARS.2015.2479300
   Crone TJ, 2010, SCIENCE, V330, P634, DOI 10.1126/science.1195840
   Cryptography P, 2013, MEL FREQUENCY CEPSTR
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   Dellaert F., 2002, EXPECTATION MAXIMIZA
   DONOHO D. L., 2000, P AMS C MATH CHALL 2, V1, P32
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Hasan M.R., 2004, VARIATIONS, V1, P4
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Karathanassi V., 2014, International Journal of Remote Sensing Applications, V4, DOI [10.14355/ijrsa.2014.0401.01, DOI 10.14355/IJRSA.2014.0401.01]
   Kessler JD, 2011, SCIENCE, V331, P312, DOI 10.1126/science.1199697
   KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129
   Kirk, 1994, LIGHT PHOTOSYNTHESIS
   Kokaly RF, 2010, 20101107 US GEOL SUR, DOI [10.3133/ofr20101107, DOI 10.3133/0FR20101107]
   Lammoglia T, 2011, REMOTE SENS ENVIRON, V115, P2525, DOI 10.1016/j.rse.2011.04.038
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Leifer I, 2012, REMOTE SENS ENVIRON, V124, P185, DOI 10.1016/j.rse.2012.03.024
   Lin Cong, 2012, Proceedings of the 2012 IEEE Southwest Symposium on Image Analysis & Interpretation (SSIAI 2012), P213, DOI 10.1109/SSIAI.2012.6202491
   Plaza J, 2005, OPTICS E 2005
   Roch MA, 2007, J ACOUST SOC AM, V121, P1737, DOI 10.1121/1.2400663
   SALEM F, 2001, P 22 AS C REM SENS, V5, P9
   Shaw G, 2002, IEEE SIGNAL PROC MAG, V19, P12, DOI 10.1109/79.974715
   Sohn Y, 2002, PHOTOGRAMM ENG REM S, V68, P1271
   Solberg AHS, 2012, P IEEE, V100, P2931, DOI 10.1109/JPROC.2012.2196250
   Sun SJ, 2016, MAR POLLUT BULL, V103, P276, DOI 10.1016/j.marpolbul.2015.12.003
   Tsai F, 1998, REMOTE SENS ENVIRON, V66, P41, DOI 10.1016/S0034-4257(98)00032-7
   Walker J. S., 2008, A Primer on Wavelets and Their Scientific Applications
   Wettle M, 2009, REMOTE SENS ENVIRON, V113, P2000, DOI 10.1016/j.rse.2009.05.010
   Willett RM, 2014, IEEE SIGNAL PROC MAG, V31, P116, DOI 10.1109/MSP.2013.2279507
   Wong CP, 2005, PROCEEDINGS OF THE SEVENTH IEEE CPMT CONFERENCE ON HIGH DENSITY MICROSYSTEM DESIGN, PACKAGING AND FAILURE ANALYSIS (HDP'05), P1
   Worldmaritimenews.com, 2018, WORLD MARE NEWS IND
   Yuhas R., 1992, SUMMARIES 4 ANN JPL, P147
   Zhang LP, 2013, IEEE T GEOSCI REMOTE, V51, P242, DOI [10.1109/TGRS.2011.2180392, 10.1109/TGRS.2012.2197860]
   Zheng F, 2001, J COMPUT SCI TECHNOL, V16, P582, DOI 10.1007/BF02943243
NR 44
TC 6
Z9 6
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5399
EP 5418
DI 10.1007/s11042-018-6709-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500066
DA 2024-07-18
ER

PT J
AU Samuel, RDJ
   Kanna, BR
AF Samuel, Dinesh Jackson R.
   Kanna, Rajesh B.
TI Cybernetic microbial detection system using transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motorized microscopic stage; Microbial recognition system; CNN-SVM;
   Humanitarian nursing; TB bacilli detection
ID SERVICES; MODEL
AB Microorganisms are single or multi-cellular living organism viewed under a microscope. For pathological study, the images of these microbes are captured using microscopes and image processing is done for further analysis. The World Health Organization (WHO) recommends to view at least 300 Field-of-Views (FOV) manually, for diagnosing and reporting the level of infection. These operation involved for analysis requires skilled technician for error free results. When the number of images for diagnosis increases, it becomes cumbersome for the technicians as there is a chance of ambiguity in results, which hampers the sensitivity of the study. In this work, a Cybernetic Microbial Detection System (CMDS) has been proposed. As in the first stage, all field of views are acquired from the specimen using a programmable microscopic stage coupled with an acquisition system. Herein, the user defines a scanning pattern for the microscopic stage movement, which facilitates the data acquisition during specimen screening. In the second stage microbial recognition system is proposed, wherein a transfer learning technique is implemented by customizing Visual Geometry Group (VGG16/19) layered convolution neural network coupled to the Support Vector Machine (SVM). These modified stack layers (VGG + SVM) has been trained/tested with microscopy images of ZN stained Tuberculosis (TB) specimem obtained from a open source database [3] and also acquired microscopy images from several patients sputum smear specimen. The accuracy obtained from the TB recognition system is 83.404 and 86.6% for VGG16-SVM, VGG19-SVM respectively. Thus the proposed screening process reduces the reliance on skilled technicians and facilitates the humanitarian nursing. Hence, the proposed cybernetic system might be useful to human community in remote regions for rapid diagnosis and detection of infectious diseases.
C1 [Samuel, Dinesh Jackson R.; Kanna, Rajesh B.] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Samuel, RDJ (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM jacksoncse@gmail.com; rajeshkanna.b@vit.ac.in
RI Baskaran, Rajesh Kanna/Y-6659-2019; Samuel, Dinesh Jackson/AAG-7420-2019
OI Baskaran, Rajesh Kanna/0000-0001-5970-3702; Samuel, Dinesh
   Jackson/0000-0002-1582-7161
CR Abdelaziz A, 2018, MEASUREMENT, V119, P117, DOI 10.1016/j.measurement.2018.01.022
   [Anonymous], 2016, Technical and Operational Guidelines for TB Control in India
   [Anonymous], 2014, P INT C LEARN REPR
   [Anonymous], INT J ENG RES APPL
   Bacallao Robert, 1995, P311
   Campbell RAA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0088977
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Darwish A, 2019, J AMB INTEL HUM COMP, V10, P4151, DOI 10.1007/s12652-017-0659-1
   DUNNETTE SL, 1986, J ALLERGY CLIN IMMUN, V78, P102, DOI 10.1016/0091-6749(86)90121-1
   Eitrich B, 2005, BUWSC20057 U WUPP
   Eitrich T, 2006, J COMPUT APPL MATH, V196, P425, DOI 10.1016/j.cam.2005.09.009
   Elhoseny M, 2018, FUTURE GENER COMP SY, V86, P1383, DOI 10.1016/j.future.2018.03.005
   Elleuch M, 2016, PROCEDIA COMPUT SCI, V80, P1712, DOI 10.1016/j.procs.2016.05.512
   FREERE R. H., 1967, J ROY MICROSC SOC, V87, P25
   Gernowo R, 2013, INT J INNOVATIVE RES, V2, P5080
   Herbrich Ralf, 2001, Learning kernel classifiers: theory and algorithms
   Khutlang R, 2010, J MICROSC-OXFORD, V237, P96, DOI 10.1111/j.1365-2818.2009.03308.x
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Magboub HM, 2010, INT CONF COMP SCI, P498, DOI 10.1109/ICCSIT.2010.5563769
   Meijering E, 2009, SEMIN CELL DEV BIOL, V20, P894, DOI 10.1016/j.semcdb.2009.07.004
   Misawa S, 1999, Rinsho Biseibutshu Jinsoku Shindan Kenkyukai Shi, V10, P121
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Osman MK, 2012, ELEKTRON ELEKTROTECH, V120, P69, DOI 10.5755/j01.eee.120.4.1456
   Osman M. K., 2011, 2011 Proceedings of IEEE 7th International Colloquium on Signal Processing & its Applications (CSPA 2011), P232, DOI 10.1109/CSPA.2011.5759878
   Ouyang PR, 2007, MECHATRONICS, V17, P578, DOI 10.1016/j.mechatronics.2007.06.002
   Sajjad M, 2020, FUTURE GENER COMP SY, V108, P995, DOI 10.1016/j.future.2017.11.013
   Santiago-Mozos R, 2014, IEEE J BIOMED HEALTH, V18, P855, DOI 10.1109/JBHI.2013.2282874
   Sermanet P., 2014, PROC INT C LEARN REP
   Shah MI, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.2.027503
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
NR 32
TC 16
Z9 16
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5225
EP 5242
DI 10.1007/s11042-018-6356-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500057
DA 2024-07-18
ER

PT J
AU Wang, RH
   Zhang, B
   Bi, JN
   Zhang, XH
   Guo, XL
   Jiao, D
   Lv, JH
   Ma, SL
AF Wang, Ronghe
   Zhang, Bo
   Bi, Jianning
   Zhang, Xinhai
   Guo, Xiaolei
   Jiao, Dong
   Lv, Jianghua
   Ma, Shilong
TI Cloud rendering learning platform technology research for visual
   analysis of large scale 3D multimedia data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud rendering; 3D scene; Big data; Machine learning; Mobile internet
ID TEXTURE SYNTHESIS; DEPTH
AB This paper designs and implements a cloud rendering system. The system supports application of server cluster load balancing, static extension of rendering machine, and design architecture of parallel task scheduling. At the same time, we put forward a new design idea, and we implement a set of communication rules of multi-task renderer and cloud rendering system. On the system, users could browse 3D scene online by mobile terminal equipments. The task of PC terminal users and mobile terminal users to access remote scenes could be high speed and real-time rendering by this system. In the end of this paper, we analyze the efficiency of our algorithm. Our system can achieve a better effect on the number of concurrent users and the average response delay. The average frame rate of system can reach 30-40 frames per second. Experimental results show that the proposed algorithm performs favorably against the state-of-the-art methods on the public test datasets.
C1 [Wang, Ronghe; Zhang, Bo; Bi, Jianning; Zhang, Xinhai; Guo, Xiaolei; Jiao, Dong] China Acad Elect & Informat Technol, Natl Engn Lab Publ Secur Risk Percept & Control B, 11 Shuangyuan Rd, Beijing 100041, Peoples R China.
   [Lv, Jianghua; Ma, Shilong] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Software Developing Environm, XueYuan Rd 37, Beijing 100191, Peoples R China.
C3 Beihang University
RP Zhang, B (corresponding author), China Acad Elect & Informat Technol, Natl Engn Lab Publ Secur Risk Percept & Control B, 11 Shuangyuan Rd, Beijing 100041, Peoples R China.
EM bozhangcetc@163.com
RI Lv, Jianghua/AAO-6911-2021
CR Aldrian O, 2012, LECT NOTES COMPUT SC, V7574, P201, DOI 10.1007/978-3-642-33712-3_15
   Cheung G, 2011, IEEE T IMAGE PROCESS, V20, P3179, DOI 10.1109/TIP.2011.2158230
   Cho H, 2011, J GEOL SOC KOREA, V47, P1
   Chow SK, 2006, INT J IMAGE GRAPH, V6, P599, DOI 10.1142/S0219467806002409
   Huang H, 2011, VISUAL COMPUT, V27, P861, DOI 10.1007/s00371-011-0596-5
   Huang TY, 2015, IEEE MTTS INT MICROW, P83, DOI 10.1109/IMWS-BIO.2015.7303788
   Ishii M, 2010, J IMAGE VIDEO PROCES, V2010, P3
   Liu YW, 2011, IEEE T BROADCAST, V57, P562, DOI 10.1109/TBC.2011.2105652
   Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862
   Ning X, 2011, COMPUT GRAPH-UK, V35, P122, DOI 10.1016/j.cag.2010.11.017
   Pajak D, 2011, COMPUT GRAPH FORUM, V30, P415, DOI 10.1111/j.1467-8659.2011.01871.x
   Shi S, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348825
   Solh Mashhour, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P87, DOI 10.1109/MMSP.2010.5661999
   SuSS T., 2011, P GRAPHICS INTERFACE, P79
   Wang RH, 2018, MULTIMED TOOLS APPL, V77, P9995, DOI 10.1007/s11042-017-4591-3
   Wang Ronghe, 2017, Journal of Beijing University of Aeronautics and Astronautics, V43, P2457, DOI 10.13700/j.bh.1001-5965.2016.0906
   Wang SX, 2012, MOB COMPUT COMMUN RE, V16, P10, DOI 10.1145/2331675.2331679
   Wang SX, 2013, IEEE T MULTIMEDIA, V15, P870, DOI 10.1109/TMM.2013.2240674
   Wu WM, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348818
   Xi M, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-9
   Zang Y, 2014, VISUAL COMPUT, V30, P969, DOI 10.1007/s00371-013-0881-6
   Zeng K, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640445
NR 22
TC 0
Z9 1
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5371
EP 5398
DI 10.1007/s11042-018-6569-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500065
DA 2024-07-18
ER

PT J
AU Guo, DL
   Wen, QY
   Li, WM
   Zhang, H
   Jin, ZP
AF Guo, Dianli
   Wen, Qiaoyan
   Li, Wenmin
   Zhang, Hua
   Jin, Zhengping
TI Adaptively secure broadcast encryption with authenticated content
   distributors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Broadcast encryption; Adaptive security; Authenticated broadcaster;
   Composite order bilinear group
ID DUAL SYSTEM ENCRYPTION; SHORT CIPHERTEXTS; SCHEME; HIBE
AB In public key broadcast encryption systems, anyone could run the encryption algorithm to broadcast messages by using the public parameters. The unsupervised broadcast strategy allows malicious users (even though someone outside the system with the intentionally divulged public parameters) to distribute junk messages without responsibility. Consequently, content distributor authentication is essential for broadcast encryption systems to forbid spreading of junk information. In this work, we devise a solution for public key broadcast encryption system with adaptive security to resolve the aforementioned vicious broadcaster problem, which is neglected in the previous related works. In our scheme, any user could distribute an encryption of messages with both public parameters and his/her own secret keys, and each message is associated to its broadcaster. The construction is based on the composite order bilinear groups and its adaptive security depends on the hardness of the general subgroup decisional assumptions. Furthermore, this allows our scheme to be flexible in terms on the overhead of ciphertexts, which is constant sized. Compared with previous related broadcast encryption systems constructed in the composite order bilinear groups, our scheme inherits the superiority of adaptive security based non-interactive falsifiable assumption, and simultaneously achieves the optimal ciphertext overhead and the authentication of broadcasters.
C1 [Guo, Dianli; Wen, Qiaoyan; Li, Wenmin; Zhang, Hua; Jin, Zhengping] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
   [Guo, Dianli] China Elect Corp, Res Inst 6, Beijing 100083, Peoples R China.
C3 Beijing University of Posts & Telecommunications; China Electronics
   Corporation
RP Zhang, H (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
EM guodianli@163.com; wqy@bupt.edu.cn; liwenmin02@outlook.com;
   zhanghua_288@bupt.edu.cn; zhpjin@bupt.edu.cn
RI Zhang, Hua/HTL-8404-2023
FU NSFC [61502044]; Fundamental Research Funds for the Central Universities
   [2015RC23]
FX The authors are grateful to the editor and anonymous reviewers for their
   valuable suggestions. This work is supported by NSFC (Grant Nos.
   61502044), the Fundamental Research Funds for the Central Universities
   (Grant No. 2015RC23).
CR Bellare M, 2011, LECT NOTES COMPUT SC, V6597, P235, DOI 10.1007/978-3-642-19571-6_15
   Boneh D, 2005, LECT NOTES COMPUT SC, V3621, P258
   Boneh D, 2003, SIAM J COMPUT, V32, P586, DOI 10.1137/S0097539701398521
   Boneh D., 2006, P ACM C COMPUTER COM, P211, DOI DOI 10.1145/1180405.1180432
   Boneh D., 2003, CONT MATH, V324, P71, DOI DOI 10.1090/CONM/324/05731
   Boneh D, 2006, LECT NOTES COMPUT SC, V4004, P573
   Boneh D, 2014, LECT NOTES COMPUT SC, V8616, P480, DOI 10.1007/978-3-662-44371-2_27
   Boneh D, 2014, LECT NOTES COMPUT SC, V8616, P206, DOI 10.1007/978-3-662-44371-2_12
   Coron JS, 2013, LECT NOTES COMPUT SC, V8042, P476, DOI 10.1007/978-3-642-40041-4_26
   Delerablee C, 2007, ADV CRYPTOLOGY ASIAC, P200
   Du XJ, 2005, IEEE T BROADCAST, V51, P264, DOI 10.1109/TBC.2005.847600
   Fiat A., 1993, LECT NOTES COMPUTER, P480, DOI DOI 10.1007/3-540-48329-2
   Garg S, 2013, LECT NOTES COMPUT SC, V7881, P1, DOI 10.1007/978-3-642-38348-9_1
   Garg S, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P121, DOI 10.1145/1866307.1866322
   Gentry C, 2009, LECT NOTES COMPUT SC, V5479, P171, DOI 10.1007/978-3-642-01001-9_10
   Goodrich MT, 2004, LECT NOTES COMPUT SC, V3152, P511
   Guo DL, 2019, MULTIMED TOOLS APPL, V78, P23399, DOI 10.1007/s11042-019-7598-0
   Guo DL, 2016, IEEE T BROADCAST, V62, P709, DOI 10.1109/TBC.2016.2550759
   Hu YP, 2016, LECT NOTES COMPUT SC, V9665, P537, DOI 10.1007/978-3-662-49890-3_21
   Kim J, 2015, IEEE T INF FOREN SEC, V10, P679, DOI 10.1109/TIFS.2014.2388156
   Lewko A, 2010, P IEEE S SECUR PRIV, P273, DOI 10.1109/SP.2010.23
   Lewko A, 2010, LECT NOTES COMPUT SC, V5978, P455, DOI 10.1007/978-3-642-11799-2_27
   Li FG, 2008, COMPUT STAND INTER, V30, P89, DOI 10.1016/j.csi.2007.08.005
   Liu WR, 2016, INT J INF SECUR, V15, P35, DOI 10.1007/s10207-015-0287-8
   Mu Y, 2004, LECT NOTES COMPUT SC, V3321, P169
   Nishimaki R, 2016, LECT NOTES COMPUT SC, V9666, P388, DOI 10.1007/978-3-662-49896-5_14
   Park C, 2012, MATH COMPUT MODEL, V55, P113, DOI 10.1016/j.mcm.2011.01.056
   Park JH, 2011, J COMMUN NETW-S KOR, V13, P428, DOI 10.1109/JCN.2011.6112299
   Qin C, 2019, IEEE T CIRC SYST VID, V29, P3341, DOI 10.1109/TCSVT.2018.2878026
   Selvi S. Sharmila Deva, 2008, Information Security Applications. 9th International Workshop, WISA 2008. Revised Selected Papers, P115
   Sun MS, 2018, MULTIMED TOOLS APPL, V77, P10455, DOI 10.1007/s11042-017-4448-9
   Waters B, 2009, LECT NOTES COMPUT SC, V5677, P619, DOI 10.1007/978-3-642-03356-8_36
   Zhandry M, 2014, 757 IACR CRYPT EPRIN
   Zhang LY, 2012, MATH COMPUT MODEL, V55, P12, DOI 10.1016/j.mcm.2011.01.004
NR 34
TC 0
Z9 0
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7889
EP 7910
DI 10.1007/s11042-019-08574-1
EA JAN 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356500004
DA 2024-07-18
ER

PT J
AU Mungra, D
   Agrawal, A
   Sharma, P
   Tanwar, S
   Obaidat, MS
AF Mungra, Dhara
   Agrawal, Anjali
   Sharma, Priyanka
   Tanwar, Sudeep
   Obaidat, Mohammad S.
TI <i>PRATIT:</i> a CNN-based emotion recognition system using histogram
   equalization and data augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Convolutional neural network (CNN); Data
   augmentation; Histogram equalization
ID NEURAL-NETWORK; CLASSIFICATION; DEPRESSION
AB Emotions are spontaneous feelings that are accompanied by fluctuations in facial muscles, which leads to facial expressions. Categorization of these facial expressions as one of the seven basic emotions - happy, sad, anger, disgust, fear, surprise, and neutral is the intention behind Emotion Recognition. This is a difficult problem because of the complexity of human expressions, but is gaining immense popularity due to its vast number of applications such as predicting behavior. Using deeper architectures has enabled researchers to achieve state-of-the-art performance in emotion recognition. Motivated from the aforementioned discussion, in this paper, we propose a model named as PRATIT, used for facial expression recognition that uses specific image preprocessing steps and a Convolutional Neural Network (CNN) model. In PRATIT, preprocessing techniques such as grayscaling, cropping, resizing, and histogram equalization have been used to handle variations in the images. CNNs accomplish better accuracy with larger datasets, but there are no freely accessible datasets with adequate information for emotion recognition with deep architectures. Therefore, to handle the aforementioned issue, we have applied data augmentation in PRATIT, which helps in further fine tuning the model for performance improvement. The paper presents the effects of histogram equalization and data augmentation on the performance of the model. PRATIT with the usage of histogram equalization during image preprocessing and data augmentation surpasses the state-of-the-art results and achieves a testing accuracy of 78.52%.
C1 [Mungra, Dhara; Agrawal, Anjali; Sharma, Priyanka; Tanwar, Sudeep] Nirma Univ, Inst Technol, Dept Comp Sci & Engn, Ahmadabad, Gujarat, India.
   [Obaidat, Mohammad S.] Nazarbayev Univ, ECE Dept, Astana, Kazakhstan.
   [Obaidat, Mohammad S.] Univ Jordan, King Abdullah II Sch IT, Amman, Jordan.
   [Obaidat, Mohammad S.] Beijing Univ Sci & Technol, Beijing, Peoples R China.
C3 Nirma University; Nazarbayev University; University of Jordan;
   University of Science & Technology Beijing
RP Tanwar, S (corresponding author), Nirma Univ, Inst Technol, Dept Comp Sci & Engn, Ahmadabad, Gujarat, India.
EM 15bce031@nirmauni.ac.in; 15bce008@nirmauni.ac.in;
   priyanka.sharma@nirmauni.ac.in; sudeep.tanwar@nirmauni.ac.in;
   msobaidat@gmail.com
RI Tanwar, Sudeep/AAI-6709-2020; Obaidat, Mohammad S./KBC-2747-2024
OI Tanwar, Sudeep/0000-0002-1776-4651; 
CR Alghowinem S., 2012, FLAIRS Conference, P141
   Alghowinem Sharifa, 2015, IEEE Int Conf Autom Face Gesture Recognit Workshops, V1, DOI 10.1109/FG.2015.7163113
   Ali G, 2016, PATTERN RECOGN, V55, P14, DOI 10.1016/j.patcog.2016.01.032
   ALzubi JA, 2019, APPL SOFT COMPUT, V80, P579, DOI 10.1016/j.asoc.2019.04.031
   Anjum MA, 2005, IEEE 1 INT C INF COM, P109
   [Anonymous], 2013, FACING IMBALANCED DA
   [Anonymous], 2011, TRCS11 AUSTR NAT U
   Bhatia S, 2017, IEEE INT CONF AUTOMA, P754, DOI 10.1109/FG.2017.94
   Bista U, 2018, USPS DATASET
   Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204
   Carrier Pierre-Luc, 2013, UNIVERSIT MONTRAL, V3
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen Y, 2017, NEUROCOMPUTING, V219, P26, DOI 10.1016/j.neucom.2016.09.015
   Chrysos GG, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P954, DOI 10.1109/ICCVW.2015.126
   Chuang CF, 2006, PATTERN RECOGN, V39, P1795, DOI 10.1016/j.patcog.2006.03.017
   De Silva CR, 2008, PATTERN RECOGN, V41, P1241, DOI 10.1016/j.patcog.2007.09.015
   De Silva LC, 1997, ICICS - PROCEEDINGS OF 1997 INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING, VOLS 1-3, P397, DOI 10.1109/ICICS.1997.647126
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Dolan B, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1001, DOI 10.1109/ICMLA.2015.39
   Giannakakis G, 2017, BIOMED SIGNAL PROCES, V31, P89, DOI 10.1016/j.bspc.2016.06.020
   Guo YN, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574736
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Jain N, 2018, PATTERN RECOGN LETT, V115, P101, DOI 10.1016/j.patrec.2018.04.010
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Khorrami P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P19, DOI 10.1109/ICCVW.2015.12
   Kumar GR, 2017, FACIAL EMOTION ANAL
   Laboratory BM, 2008, TFEID TAIW FAC EXPR
   Labs L, 2017, WHAT EMOTION RECOGNI
   Levi G, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P503, DOI 10.1145/2823327.2823333
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Ma B, 2015, IEEE I CONF COMP VIS, P4400, DOI 10.1109/ICCV.2015.500
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Nicolle J, 2016, IMAGE VISION COMPUT, V52, P1, DOI 10.1016/j.imavis.2016.03.004
   Ojeme B, 2016, PROCEDIA COMPUT SCI, V96, P1294, DOI 10.1016/j.procs.2016.08.174
   Patii J, 2017, HUMAN MENTAL STATES
   Shankar K, 2019, COMPUT ELECTR ENG, V77, P230, DOI 10.1016/j.compeleceng.2019.06.001
   Simard PY, 2003, PROC INT CONF DOC, P958
   Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989
   University R, 2017, RADBOUD DAT
   Valstar M., 2013, P 3 ACM INT WORKSHOP, DOI [10.1145/2512530.2512533, DOI 10.1145/2512530.2512533]
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang SH, 2018, NEUROCOMPUTING, V272, P668, DOI 10.1016/j.neucom.2017.08.015
   Wang ZQ, 2017, 2017 17TH IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT 2017), P1958, DOI 10.1109/ICCT.2017.8359971
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Yang D, 2018, PROCEDIA COMPUT SCI, V125, P2, DOI 10.1016/j.procs.2017.12.003
   Yang Y, 2013, IEEE T AFFECT COMPUT, V4, P142, DOI 10.1109/T-AFFC.2012.38
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Zhang B, 2016, STUDY CNN RECOGNITIO
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
NR 51
TC 34
Z9 34
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2285
EP 2307
DI 10.1007/s11042-019-08397-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000025
DA 2024-07-18
ER

PT J
AU Rawat, R
   Singh, B
   Sur, A
   Mitra, P
AF Rawat, Ritvik
   Singh, Brijesh
   Sur, Arijit
   Mitra, Pinaki
TI Steganalysis for clustering modification directions steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Spatial domain steganalysis; CMD steganography
AB In recent time, most of the steganographic methods minimize the embedding cost while maximizing the embedding capacity by injecting message bits in the highly textured regions of the image. Recently, the Clustering Modification Direction (CMD) steganography has been proposed as a wrapper over the additive steganography algorithms, resulting in a substantial improvement in statistical imperceptibility against state-of-the-art steganalytic classifiers. In this paper, a steganalysis scheme, named Selective-Signal-Removal (SSR) is proposed to mount an attack on the CMD algorithm. It has been observed experimentally that the CMD scheme has a tendency to embed in a localized cluster having higher texture. The proposed scheme exploits this fact and tries to predict the embedding zones. It essentially discards the irrelevant region of the image (which may not be modified by the CMD algorithm while embedding) by using a heuristic function with an assignment algorithm to improve the steganalytic detection rate. The experimental results show that the proposed SSR scheme can detect CMD based steganography with improved accuracy.
C1 [Rawat, Ritvik; Singh, Brijesh; Sur, Arijit; Mitra, Pinaki] Indian Inst Technol Guwahati, Dept CSE, Gauhati, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Singh, B (corresponding author), Indian Inst Technol Guwahati, Dept CSE, Gauhati, India.
EM ritvik@iitg.ac.in; brijesh.singh@iitg.ac.in; arijit@iitg.ac.in;
   pinaki@iitg.ac.in
RI Singh, Brijesh/AAB-7919-2021; Sur, Arijit/AAB-4216-2020; Mitra,
   Pinaki/AAD-6785-2020
OI Singh, Brijesh/0000-0003-2661-6244; 
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2011, P 13 INF HID C PRAG
   Bae HJ, 1997, ICICS - PROCEEDINGS OF 1997 INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING, VOLS 1-3, P1065, DOI 10.1109/ICICS.1997.652144
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gujar S, 2009, MEASURES CLASSIFICAT
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Huang YL, 2005, J INF SCI ENG, V21, P181
   Iatan IF, 2010, ADV INTEL SOFT COMPU, V77, P345
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
NR 22
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1971
EP 1986
DI 10.1007/s11042-019-08263-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000014
DA 2024-07-18
ER

PT J
AU Zhang, HH
   Wang, XS
   Jiang, LT
   Xu, YB
   Jiang, GQ
AF Zhang, Hehu
   Wang, Xiushan
   Jiang, Lintao
   Xu, Yibo
   Jiang, Guoqiang
TI Near color recognition based on residual vector and SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Near color; Residual vector; Support vector machine; Machine vision
ID SEGMENTATION; PLANT; VEGETATION; ALGORITHM; CLUSTERS; FEATURES; VISION;
   ROBUST; SHAPE; CROP
AB With the extensive application of machine vision in Agriculture, plant recognition is becoming an important research territory. Due to illumination change, occlusion problem, green background and other factors, the image segmentation quality of plant is uneven. When there are significantly different colors, such as red, green and blue, between plant target and background, classical image processing methods are up to the task. However, in near color scene, for example dark green target and bright green background, plant target recognition is still a very challenging task. To segment plants in above scene, the near color recognition method based on residual vector and SVM has been developed. Firstly, the color vectors were projected to the plane that crosses the point Origin(0, 0, 0) and is perpendicular to reference color vector B0(255, 255, 255). After projection, the significantly different color vectors were distributed in different polar angle ranges, while the near color vectors were concentrated in the same polar angle range. For near color vectors, the small polar angle difference, namely roll, was regarded as redundant information. Then, the angle theta between target color vector A(r, g, b) and B0, along with the norm of A, namely A parallel to(A) over right arrow parallel to was calculated. As a result, the three-dimensional target color vector A was converted to the two-dimensional residual vector (R parallel to(A) over right arrow parallel to,theta). Finally, SVM classifier is used to identify the residual vector. The results show that the linear recognition rate is 90.25%, the average recognition speed 0.243 s, the nonlinear recognition rate 87.47%, and the average recognition speed 0.254 s. This study provides theoretical reference for plant target recognition in the near color scene.
C1 [Zhang, Hehu; Wang, Xiushan; Jiang, Lintao; Xu, Yibo; Jiang, Guoqiang] Henan Agr Univ, Coll Mech & Elect Engn, Dept Elect Engn, Zhengzhou, Henan, Peoples R China.
C3 Henan Agricultural University
RP Wang, XS (corresponding author), Henan Agr Univ, Coll Mech & Elect Engn, Dept Elect Engn, Zhengzhou, Henan, Peoples R China.
EM towxs@163.com
RI Zhang, Hehu/AAN-5588-2021; zhang, hehu/AAT-8931-2020; Jiang,
   Guoqiang/JMQ-2267-2023
OI Zhang, Hehu/0000-0003-0862-0506; 
FU Henan science and technology tackling key project [172102210678]; Key
   research projects of universities in Henan [18A416002]; Henan college
   key scientific research project [182102110249]; Henan province
   innovation and entrepreneurship training platform for University
   Students [s201810466023]
FX This research is supported by the following projects: Henan science and
   technology tackling key project (Grant: 172102210678); Key research
   projects of universities in Henan (Grant: 18A416002); Henan college key
   scientific research project (Grant: 182102110249); Henan province
   innovation and entrepreneurship training platform for University
   Students (Grant: s201810466023). The project team heartily expresses the
   full thanks to above units.
CR Abbasgholipour M, 2011, EXPERT SYST APPL, V38, P3671, DOI 10.1016/j.eswa.2010.09.023
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], J MOD OPT
   [Anonymous], OPTIK
   [Anonymous], INT S EXP ROB
   [Anonymous], 20 IEEE INT C IM PRO
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], EXPERT SYST APPL
   [Anonymous], J ELECT IMAGINING
   Bai XD, 2014, BIOSYST ENG, V125, P80, DOI 10.1016/j.biosystemseng.2014.06.015
   Caglayan A, 2013, LECT NOTES COMPUT SC, V8157, P161, DOI 10.1007/978-3-642-41184-7_17
   Chaki J, 2015, PATTERN RECOGN LETT, V58, P61, DOI 10.1016/j.patrec.2015.02.010
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dyrmann M., 2017, Advances in Animal Biosciences, V8, P842, DOI [DOI 10.1017/S2040470017000206, 10.1017/S2040470017000206]
   Dyrmann M, 2016, BIOSYST ENG, V151, P72, DOI 10.1016/j.biosystemseng.2016.08.024
   Guijarro M, 2011, COMPUT ELECTRON AGR, V75, P75, DOI 10.1016/j.compag.2010.09.013
   Guo W, 2013, COMPUT ELECTRON AGR, V96, P58, DOI 10.1016/j.compag.2013.04.010
   Hague T, 2006, PRECIS AGRIC, V7, P21, DOI 10.1007/s11119-005-6787-1
   Hunt E. Raymond Jr, 2005, Precision Agriculture, V6, P359, DOI 10.1007/s11119-005-2324-5
   Jeon HY, 2011, SENSORS-BASEL, V11, P6270, DOI 10.3390/s110606270
   Kataoka T, 2003, IEEE ASME INT C ADV, P1079, DOI 10.1109/aim.2003.1225492
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Meyer GE, 2004, COMPUT ELECTRON AGR, V42, P161, DOI 10.1016/j.compag.2003.08.002
   Sabzi S, 2017, BIOSYST ENG, V163, P167, DOI 10.1016/j.biosystemseng.2017.09.003
   Tellaeche A, 2008, PATTERN RECOGN, V41, P521, DOI 10.1016/j.patcog.2007.07.007
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120
   Xiong JT, 2018, BIOSYST ENG, V166, P44, DOI 10.1016/j.biosystemseng.2017.11.005
   Zhang Q, 2017, COMPUT ELECTRON AGR, V143, P66, DOI 10.1016/j.compag.2017.09.008
NR 31
TC 1
Z9 1
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35313
EP 35328
DI 10.1007/s11042-019-08164-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800048
DA 2024-07-18
ER

PT J
AU Zhang, YX
   Zhu, WP
   Ma, YZ
   Fan, XL
AF Zhang, Yongxin
   Zhu, Wenpeng
   Ma, Youzhong
   Fan, Xunli
TI Multi-focus image fusion based on smooth and iteratively restore filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Image decomposition; Filtering algorithms; Smooth and
   iteratively restore filtering; Saliency maps
ID EXTRACTION
AB Image fusion is the process of combining several images with different focus settings into a completely in-focus image. However, many state-of-the-art fusion methods cannot well preserve all the significant features of the source images to obtain an all-in-focus image. In this paper, an improved smooth and iteratively restore (SIR) filter is proposed to deal with the problem. The SIR filter can well smooth noise while retaining details of edges. First, SIR filtering is applied to decompose source images into base and detail layers. Second, saliency maps of the different layers of the sources are computed by a proposed salient feature filter. Third, pixel-wise maxima of the saliency maps are used to construct the binary decision maps for both source images. Then with the binary decision maps we fuse the base and detail layers respectively to yield the fused base and fused detail, which are then recombined to produce the final fused image. Spatial consistency is inherently guaranteed by this process. Tests on sets of grayscale and colour multi-focus images demonstrate that the proposed method achieves better performance than existing methods in terms of both subjective and objective evaluations.
C1 [Zhang, Yongxin; Ma, Youzhong] Luoyang Normal Univ, Luoyang 471022, Peoples R China.
   [Zhu, Wenpeng; Fan, Xunli] Northwest Univ, Sch Informat Sci, Xian 710127, Peoples R China.
C3 Luoyang Normal University; Northwest University Xi'an
RP Zhang, YX (corresponding author), Luoyang Normal Univ, Luoyang 471022, Peoples R China.
EM tabo126@126.com; 1394077672@qq.com; ma_youzhong@163.com;
   xunlfan@nwu.edu.cn
RI Ma, Youzhong/T-6647-2019; liu, jianyang/JXL-6273-2024
OI Ma, Youzhong/0000-0002-7359-6592; 
FU Scientific and Technological Project of Henan Province [192102210122];
   Postdoctoral Science Foundation of China [2015M582697]; Henan Province
   Basic and Cutting-Edge Technology Research Project of China
   [17HASTIT024]; outstanding talents of scientific and technological
   innovation in Henan [184200510011]; National Natural Science Foundation
   of China [61502219]; International Science and Technology Cooperation
   Program of China [2016YFE0104600]
FX We would like to thank Kang Xudong, Zhan kun, Zhou Zhiqiang, D. P.
   Bavirisetti, Qu Xiaobo, Alexander Toet for providing their codes. In
   addition, we would like to thank the editors and anonymous reviewers for
   their comments and suggestions. This work was supported by the
   Scientific and Technological Project of Henan Province
   (No.192102210122), the Postdoctoral Science Foundation of China
   (No.2015M582697), the Henan Province Basic and Cutting-Edge Technology
   Research Project of China (No. 17HASTIT024), the outstanding talents of
   scientific and technological innovation in Henan (No.184200510011), the
   National Natural Science Foundation of China (No. 61502219) and the
   International Science and Technology Cooperation Program of China (No.
   2016YFE0104600).
CR [Anonymous], 36 CHIN CONTR C CCC
   [Anonymous], 2015, INT J SIGNAL PROCESS, DOI DOI 10.14257/IJSIP.2015.8.2.16
   [Anonymous], SIGN INF PROC ASS SU
   [Anonymous], AS PAC SIGN INF PROC
   [Anonymous], 10 IEEE INT C COMP V
   [Anonymous], ARXIV150506702
   Azarang A, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA), P1, DOI 10.1109/PRIA.2017.7983017
   Bavirisetti DP, 2018, AIN SHAMS ENG J, V9, P1103, DOI 10.1016/j.asej.2016.06.011
   Cai JJ, 2017, INFRARED PHYS TECHN, V82, P85, DOI 10.1016/j.infrared.2017.01.026
   Cui GM, 2015, OPT COMMUN, V341, P199, DOI 10.1016/j.optcom.2014.12.032
   Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019
   Du J, 2016, NEUROCOMPUTING, V194, P326, DOI 10.1016/j.neucom.2016.02.047
   Huang W, 2015, IEEE GEOSCI REMOTE S, V12, P1037, DOI 10.1109/LGRS.2014.2376034
   Jiang Y, 2014, IET IMAGE PROCESS, V8, P183, DOI 10.1049/iet-ipr.2013.0429
   Kalantari NK, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073609
   Kou F, 2018, J VIS COMMUN IMAGE R, V53, P235, DOI 10.1016/j.jvcir.2018.03.020
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li W, 2018, OPTIK, V172, P1, DOI 10.1016/j.ijleo.2018.06.123
   Liu SQ, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/156043
   Liu Y, 2018, INFORM FUSION, V42, P158, DOI 10.1016/j.inffus.2017.10.007
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Qu Xiao-Bo, 2008, Acta Automatica Sinica, V34, P1508, DOI 10.3724/SP.J.1004.2008.01508
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Tello-Mijares S, 2018, J BIOMED OPT, V23, DOI 10.1117/1.JBO.23.5.056005
   Toet A, 2016, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.80
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang B, 2017, INT J WAVELETS MULTI, V15, DOI 10.1142/S0219691317500370
   Yang Y, 2017, IEEE T INSTRUM MEAS, V66, P691, DOI 10.1109/TIM.2017.2658098
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.6.063004
   Zhang YX, 2016, OPTIK, V127, P1291, DOI 10.1016/j.ijleo.2015.10.098
   Zhang YX, 2014, SIGNAL PROCESS, V105, P84, DOI 10.1016/j.sigpro.2014.05.015
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zhao JF, 2013, OPT COMMUN, V287, P45, DOI 10.1016/j.optcom.2012.08.070
NR 37
TC 1
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35027
EP 35052
DI 10.1007/s11042-019-08127-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800035
DA 2024-07-18
ER

PT J
AU Han, WH
   Tian, ZH
   Huang, ZZ
   Li, SD
   Jia, Y
AF Han, Weihong
   Tian, Zhihong
   Huang, Zizhong
   Li, Shudong
   Jia, Yan
TI Bidirectional self-adaptive resampling in internet of things big data
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Imbalanced big data; Resampling; Oversampling; Undersampling; Data
   learning
ID CLOUD; EFFICIENT; SMOTE; ALGORITHMS; SCHEME
AB This paper focuses on the problem of low learning algorithm accuracy caused by serious imbalance of big data in Internet of Things, and proposes a bidirectional self-adaptive resampling algorithm for imbalanced big data. Based on the sizes of data sets and imbalance ratios inputted by the user, the algorithm will process the data using a combination of oversampling for minority class and distribution sensitive undersampling for majority class. This paper proposes a new distribution-sensitive resampling algorithm. According to the distribution of samples, the majority and minority samples are divided into different categories, and different processing methods are adopted for the samples with different distribution characteristics The algorithm makes the sample set after resampling keep the same characteristics with the original data set as much as possible. The algorithm emphasizes the importance of boundary samples, that is, the samples at the boundary of majority classes and minority classes are more important than other samples for learning algorithm. The boundary minority samples will be copied, and the boundary majority samples will be reserved. Real-world application is introduced in the end, which shows that compared with the existing imbalanced data resampling algorithms, this algorithm improves the accuracy of learning algorithm, especially for the accuracy and recall rate of minority class.
C1 [Han, Weihong; Tian, Zhihong; Li, Shudong] Guangzhou Univ, Cyberspace Inst Adv Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Huang, Zizhong; Jia, Yan] Natl Univ Def Technol, Comp Sch, Changsha 410073, Hunan, Peoples R China.
C3 Guangzhou University; National University of Defense Technology - China
RP Tian, ZH (corresponding author), Guangzhou Univ, Cyberspace Inst Adv Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM tianzhihong@gzhu.edu.cn
OI tian, zhihong/0000-0002-9409-5359
FU National Natural Science Foundation of China under The National key
   research and development plan [2018YFB0803504, 61871140, U1636215,
   61872100, 61572153]
FX This work is partially funded by the National Natural Science Foundation
   of China under The National key research and development plan under
   Grant No. 2018YFB0803504 and Grant No. 61871140, U1636215, 61872100 and
   No.61572153.
CR [Anonymous], 2017, INF SCI
   [Anonymous], 2012, 2012 IEEE 26 PAR DIS
   Benni KE, 2018, IEEE T SOFTWARE ENG, V44, P534, DOI 10.1109/TSE.2017.2731766
   Bunkhumpornpat C, 2015, CORE CORE BASED SYNT
   Bunkhumpornpat C, 2012, APPL INTELL, V36, P664, DOI 10.1007/s10489-011-0287-y
   Bunkhumpornpat C, 2009, LECT NOTES ARTIF INT, V5476, P475, DOI 10.1007/978-3-642-01307-2_43
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen J, 2019, J AMB INTEL HUM COMP, V10, P3099, DOI 10.1007/s12652-018-0887-z
   Cheng HJ, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1069-6
   Cheng HJ, 2016, INFORM SCIENCES, V329, P461, DOI 10.1016/j.ins.2015.09.039
   Cheng HJ, 2012, AD HOC NETW, V10, P760, DOI 10.1016/j.adhoc.2011.02.004
   Cheng WL, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071633
   Fang WW, 2014, INFORM SCIENCES, V283, P79, DOI 10.1016/j.ins.2014.06.022
   Gui JS, 2017, IEEE ACCESS, V5, P2396, DOI 10.1109/ACCESS.2017.2672561
   Guo WZ, 2012, INT J SENS NETW, V12, P53, DOI 10.1504/IJSNET.2012.047720
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   Jiang F, IEEE T SUSTAINABLE C
   Jiang XY, 2018, IEEE ACCESS, V6, P13716, DOI 10.1109/ACCESS.2018.2812794
   Li XJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072349
   Lin B, 2016, IEEE T NETW SERV MAN, V13, P581, DOI 10.1109/TNSM.2016.2554143
   Lin C, 2009, INT J COMMUN SYST, V22, P671, DOI 10.1002/dac.989
   Liu RW, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030509
   Liu X, KNOWLEDGE AWARE PROA
   Liu X, 2018, COMPLEXITY, DOI 10.1155/2018/5429546
   Mathews Lincy, 2018, ENCY INFORM SCI TECH
   Ofek N, 2017, NEUROCOMPUTING
   Sun Z. Y., 2018, WIREL COMMUN MOB COM, V2018, P1
   Tan QF, 2019, IEEE INTERNET THINGS, V6, P1584, DOI 10.1109/JIOT.2018.2846624
   Wang YH, 2017, INFORM SCIENCES, V408, P70, DOI 10.1016/j.ins.2017.04.035
   Wang Z, 2012, J SUPERCOMPUT, V62, P227, DOI 10.1007/s11227-011-0708-z
   Weiss G.M., 2004, ACM SIGKDD Explorations Newsletter, V6, DOI DOI 10.1145/1007730.1007734
   Wu PF, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061303
   Xia ZH, 2018, IEEE ACCESS, V6, P30392, DOI 10.1109/ACCESS.2018.2845456
   Xia ZH, 2017, INFORM SCIENCES, V387, P195, DOI 10.1016/j.ins.2016.12.030
   Xiong NX, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010174
   Xiong NX, 2010, IEEE T PARALL DISTR, V21, P1254, DOI 10.1109/TPDS.2010.29
   Xiong NX, 2010, INFORM SCIENCES, V180, P2249, DOI 10.1016/j.ins.2009.12.001
   Xiong NX, 2009, IEEE J SEL AREA COMM, V27, P495, DOI 10.1109/JSAC.2009.090512
   Zeng YY, 2010, J SUPERCOMPUT, V52, P23, DOI 10.1007/s11227-009-0268-7
   Zhang YP, 2010, 2010 2ND IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND FINANCIAL ENGINEERING (ICIFE), P400, DOI 10.1109/ICIFE.2010.5609385
   Zheng HF, 2018, IEEE T SYST MAN CY-S, V48, P2315, DOI 10.1109/TSMC.2017.2734886
   Zhong P, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081881
   Zhou YZ, 2017, TSINGHUA SCI TECHNOL, V22, P714, DOI 10.23919/TST.2017.8195353
NR 43
TC 8
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30111
EP 30126
DI 10.1007/s11042-018-6938-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200027
DA 2024-07-18
ER

PT J
AU Khan, T
   Mollah, AF
AF Khan, Tauseef
   Mollah, Ayatullah Faruk
TI AUTNT - A component level dataset for text non-text classification and
   benchmarking with novel script invariant feature descriptors and D-CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text Non-text classification; Distance Transform (DT); Medial Skeleton;
   Burning Rope Algorithm; Deep Convolution Neural Network
ID IMAGES; SEGMENTATION; ALGORITHM; LOCALIZATION
AB Automated scene text recognition from camera images is considered as a pioneer research area through last few decades. Classification of foreground object components from camera images is an essential step of Text Information Extraction (TIE). Text/Non-text separation from complex document images as well as unstructured natural images is still a challenging task. Although, some works have been reported in this direction, component level standard benchmark datasets for specifically text/non-text classification are not available. In this paper, a new multi-script dataset of text and non-text components have been reported along with multi-purpose ground truth annotations. A novel feature set is also designed on the basis of distance information of medial skeleton points to set benchmark performance on this dataset. Also, a Deep Convolution Neural Network (D-CNN) based automated feature extraction and classification framework is developed for benchmarking purpose. More insight is put forward by conducting separate assessment of current two benchmark methods on component images originated from documents and natural scenes. Experimental results show that classification accuracy is over 94.00% for medial skeleton based feature descriptors and over 96.00% for D-CNN framework on both types of sources, which is pretty impressive in practical scenario.
C1 [Khan, Tauseef; Mollah, Ayatullah Faruk] Aliah Univ, Dept Comp Sci & Engn, Kolkata 700160, India.
C3 Aliah University
RP Khan, T (corresponding author), Aliah Univ, Dept Comp Sci & Engn, Kolkata 700160, India.
EM tauseef.hit2013@gmail.com; afmollah@aliah.ac.in
RI Khan, Tauseef/ISV-3635-2023
OI Mollah, Ayatullah Faruk/0000-0002-3445-7469
FU Department of Computer Science and Engineering of Aliah University;
   University Grant Commission (UGC), Govt. of India
FX The authors are thankful to the Department of Computer Science and
   Engineering of Aliah University for providing every support for carrying
   out this work. The first author is also thankful to University Grant
   Commission (UGC), Govt. of India for granting Maulana Azad National
   Fellowship (MANF) to him.
CR Agrawal Mudit, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1011, DOI 10.1109/ICDAR.2009.270
   Bai Nong, 2016, ARXIV160609002
   Bai X, 2017, PATTERN RECOGN, V66, P437, DOI 10.1016/j.patcog.2016.12.005
   Baird H. S., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P820, DOI 10.1109/ICPR.1990.118223
   Bhowmik S, 2018, INT J DOC ANAL RECOG, V21, P1, DOI 10.1007/s10032-018-0296-z
   Chen Xiangrong, 2004, Computer vision and pattern recognition, V2, pII
   Cheng H, 2001, IEEE T IMAGE PROCESS, V10, P511, DOI 10.1109/83.913586
   Cheng PR, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P152, DOI 10.1145/3206025.3206043
   Delaye A, 2014, PATTERN RECOGN, V47, P959, DOI 10.1016/j.patcog.2013.04.017
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   He DF, 2017, PROC CVPR IEEE, P474, DOI 10.1109/CVPR.2017.58
   He WH, 2017, IEEE I CONF COMP VIS, P745, DOI 10.1109/ICCV.2017.87
   Hua XS, 2004, IEEE T CIRC SYST VID, V14, P498, DOI 10.1109/TCSVT.2004.825538
   Huang R, 2013, PROC INT CONF DOC, P462, DOI 10.1109/ICDAR.2013.99
   Huang WL, 2013, IEEE I CONF COMP VIS, P1241, DOI 10.1109/ICCV.2013.157
   Jaderberg M., 2014, CORR
   Kise K, 1998, COMPUT VIS IMAGE UND, V70, P370, DOI 10.1006/cviu.1998.0684
   Koo HI, 2013, IEEE T IMAGE PROCESS, V22, P2296, DOI 10.1109/TIP.2013.2249082
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee SW, 2001, IEEE T PATTERN ANAL, V23, P1240, DOI 10.1109/34.969115
   Li Y, 2012, INT C PATT RECOG, P681
   Liao M, 2017, P 31 INT C ART INT
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YL, 2017, PROC CVPR IEEE, P3454, DOI 10.1109/CVPR.2017.368
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Lyu PY, 2018, PROC CVPR IEEE, P7553, DOI 10.1109/CVPR.2018.00788
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Maurer CR, 2003, IEEE T PATTERN ANAL, V25, P265, DOI 10.1109/TPAMI.2003.1177156
   NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436
   Nagy G., 1986, PATTERN RECOGN, VII, P149
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pan YF, 2011, IEEE T IMAGE PROCESS, V20, P800, DOI 10.1109/TIP.2010.2070803
   Park J, 2010, PATTERN RECOGN LETT, V31, P1728, DOI 10.1016/j.patrec.2010.05.024
   Paul S, 2019, MULTIMED TOOLS APPL, P1
   Qin HB, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9061054
   Sarkar R., 2011, INT C GRAPH DRAWING, P1
   SeongHun Lee, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3983, DOI 10.1109/ICPR.2010.969
   Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371
   Shivakumara P., 2008, Pattern recognition, P1
   Shivakumara P, 2011, IEEE T PATTERN ANAL, V33, P412, DOI 10.1109/TPAMI.2010.166
   Simon A, 1997, IEEE T PATTERN ANAL, V19, P273, DOI 10.1109/34.584106
   Subramanian K, 2007, PROC INT CONF DOC, P33
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Tran TA, 2015, KSII T INTERNET INF, V9, P4072, DOI 10.3837/tiis.2015.10.017
   WAHL FM, 1982, COMPUT VISION GRAPH, V20, P375, DOI 10.1016/0146-664X(82)90059-4
   Xu YC, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2900589
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Ye QX, 2005, IMAGE VISION COMPUT, V23, P565, DOI 10.1016/j.imavis.2005.01.004
   Yi Chucai, 2011, IEEE Trans Image Process, V20, P2594, DOI 10.1109/TIP.2011.2126586
   Zhang CQ, 2015, PROC INT CONF DOC, P886, DOI 10.1109/ICDAR.2015.7333889
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
   Zhao F, 2018, MULTIMED TOOLS APPL, V77, P28049, DOI 10.1007/s11042-018-5975-8
   Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P385, DOI 10.1109/34.845381
   Zhong Z. Y., 2016, ARXIV160507314
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
NR 59
TC 12
Z9 12
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32159
EP 32186
DI 10.1007/s11042-019-08028-8
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000051
DA 2024-07-18
ER

PT J
AU Malekijoo, A
   Fadaeieslam, MJ
AF Malekijoo, Amirhossein
   Fadaeieslam, Mohammad Javad
TI Convolution-deconvolution architecture with the pyramid pooling module
   for semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural network; Machine vision; Semantic pixel-wise
   segmentation; Convolution-deconvolution network; Road scene dataset
AB Recognizing the content of an image is an important challenge in machine vision. Semantic segmentation is one of the most important ways to overcome this challenge. It is utilized in different applications such as autonomous driving, indoor navigation, virtual or augmented reality systems, and recognition tasks. In this paper, a novel and practical deep fully convolutional neural network architecture was introduced for semantic pixel-wise segmentation termed as P-DecovNet. The proposed architecture combines the Convolution-Deconvolution Neural Network architecture with the Pyramid Pooling Module. In this project, the high-level features were extracted from the image using the Convolutional Neural Network. To reinforce the local information, the Pooling module was added to the architecture. CamVid road scene dataset was used to evaluate the performance of the P-DecovNet. With respect to different criteria (including - but not limited to - accuracy and mIoU), the experimental results demonstrated that P-DecovNet practically has a good performance in the domain of Convolution-Deconvolution Network. To achieve such performance, this work uses a smaller number of training images with lesser iterations compared to the existing methods.
C1 [Malekijoo, Amirhossein; Fadaeieslam, Mohammad Javad] Semnan Univ, Elect & Comp Engn Dept, Semnan, Iran.
C3 Semnan University
RP Malekijoo, A (corresponding author), Semnan Univ, Elect & Comp Engn Dept, Semnan, Iran.
EM amirhossein.maleki1990@semnan.ac.ir; fadaei@semnan.ac.ir
RI Malekijoo, Amir hossein/JLM-6898-2023; Fadaeieslam, Mohammad
   Javad/AAZ-2625-2021
OI Fadaeieslam, Mohammad Javad/0000-0002-8560-6444
CR [Anonymous], 2015, TPAMI
   [Anonymous], 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298642
   [Anonymous], 2018, ARXIV180501556
   [Anonymous], 2018, INT J COMPUTER VISIO
   [Anonymous], COMP VIS PATT REC CV
   [Anonymous], 160907009 ARXIV
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dumoulin Vincent, 2018, Distill, DOI 10.23915/distill.00011
   Garcia A, 2017, APPR DIGIT GAME STUD, V5, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jerripothula KR, 2016, IEEE T MULTIMEDIA, V18, P1896, DOI 10.1109/TMM.2016.2576283
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mortensen EN, 1998, GRAPH MODEL IM PROC, V60, P349, DOI 10.1006/gmip.1998.0480
   Mostajahi M, 2015, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2015.7298959
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Pohlen T, 2017, PROC CVPR IEEE, P3309, DOI 10.1109/CVPR.2017.353
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Thoma M., 2016, CoRR
   Wang SH, 2018, J MED SYST, V42, DOI [10.1007/s10916-017-0845-x, 10.1007/s10916-018-0932-7]
   Yang GR, 2018, LECT NOTES COMPUT SC, V11211, P660, DOI 10.1007/978-3-030-01234-2_39
   Zeiler M.D., 2013, ARXIV201313013557, P1
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
NR 31
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32379
EP 32392
DI 10.1007/s11042-019-07990-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000058
DA 2024-07-18
ER

PT J
AU Pan, XQ
   Xue, LM
   Lu, Y
   Sun, N
AF Pan, Xiuqin
   Xue, Limiao
   Lu, Yong
   Sun, Na
TI Hybrid particle swarm optimization with simulated annealing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Particle swarm optimization; Simulated annealing; Function optimization
AB While solving the optimization problems of complex functions, particle swarm optimization (PSO) would be easy to fall into trap in the local optimum. Besides that, it has slow convergence speed and poor accuracy during the late evolutionary period. So a SA-PSO algorithm would be proposed in this paper. Classically, the probability to accept bad solutions is high at the beginning. It allows the SA algorithm to escape from local minimum. As the result of that, the improved algorithm, combined SA with PSO, would be given in this paper. The given algorithm owned the abilities of both increasing the diversity of particle swarm and jumping out of the local optimum. In this paper, several classic unimodal/multimodal functions were used to simulate the SA-PSO algorithm. The results illustrated that SA-PSO had a stronger ability to avoid prematurity and get rid of local optimum. Compared with traditional PSO, the SA-PSO has improvement over effectiveness and accuracy to some extent. And it has competitive potential for solving other complicated optimization problems.
C1 [Pan, Xiuqin; Xue, Limiao; Lu, Yong; Sun, Na] Minzu Univ China, Informat Engn Sch, Beijing 100081, Peoples R China.
C3 Minzu University of China
RP Pan, XQ (corresponding author), Minzu Univ China, Informat Engn Sch, Beijing 100081, Peoples R China.
EM amycun@163.com; xuelimiao09@163.com; yl_cun@yeah.net; sunna_07@163.com
FU First-Class University [10301-017004011501]; First-Class Discipline
   [10301-017004011501]
FX This work is supported by the project of the First-Class University and
   the First-Class Discipline (No.10301-017004011501).
CR Aarts E., 1990, SIMULATED ANNEALING
   [Anonymous], 1988, Acta Appl Math, DOI DOI 10.1007/BF00047572
   Aragon CR, 1991, OPTIMIZATION SIMULAT, P215
   Bank M, 2012, ADV ENG SOFTW, V47, P1, DOI 10.1016/j.advengsoft.2011.12.001
   Ben-Ameur W, 2004, COMPUT OPTIM APPL, V29, P369, DOI 10.1023/B:COAP.0000044187.23143.bd
   Bergh F, 2001, GENET EVOL COMPUT C
   Chen SM, 2011, EXPERT SYST APPL, V38, P14439, DOI 10.1016/j.eswa.2011.04.163
   Clerc M, 2002, PARTICLE SWARM EXPLO
   Clerc M, 2010, INT J SWARM INTELL R, V1, P46, DOI 10.4018/jsir.2010100103
   Eberhart SY, 2002, EV COMP 2001 P 2001
   Gao S., 2005, COMPUT APP SOFT, V22, P103
   [高鹰 Gao Ying], 2004, [计算机工程与应用, Computer Engineering and Application], V40, P47
   Han XL, 2008, PARTICLE SWARM SIMUL
   Higashi N, 2003, PROCEEDINGS OF THE 2003 IEEE SWARM INTELLIGENCE SYMPOSIUM (SIS 03), P72, DOI 10.1109/SIS.2003.1202250
   Huang X, 2009, INT J REMOTE SENS, V30, P1977, DOI 10.1080/01431160802546837
   Jamili A, 2011, INT J ADV MANUF TECH, V54, P309, DOI 10.1007/s00170-010-2932-8
   Jantara VL, 2018, IOP CONF SER-MAT SCI, V454, DOI 10.1088/1757-899X/454/1/012094
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Lei Xiu-juan, 2008, Computer Engineering and Applications, V44, P53, DOI 10.3778/j.issn.1002-8331.2008.28.018
   Li CH, 2009, IEEE C EVOL COMPUTAT, P381, DOI 10.1109/CEC.2009.4982972
   Pan Quanke, 2006, China Mechanical Engineering, V17, P1044
   Sadati N, 2009, APPL SOFT COMPUT, V9, P652, DOI 10.1016/j.asoc.2008.09.005
   Wang Hua-qiu, 2005, Control and Decision, V20, P500
   Yan Z., 2014, AMR, V989994, P2301, DOI [10.4028/www.scientific.net/AMR.989-994.2301, DOI 10.4028/WWW.SCIENTIFIC.NET/AMR.989-994.2301]
   Yu Hai-ping, 2012, Application Research of Computers, V29, P4448, DOI 10.3969/j.issn.1001-3695.2012.12.010
   [张超 Zhang Chao], 2017, [工程科学学报, Chinese Journal of Engineering], V39, P125
   Zhang Y, 2013, ADV MECH ENG, V2013, P1, DOI DOI 10.4225/08/58B5BAAD4FCC2
   Zhu H. D., 2009, COMPUT TECHNOL DEV, V6, P32
NR 28
TC 41
Z9 44
U1 3
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29921
EP 29936
DI 10.1007/s11042-018-6602-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200016
DA 2024-07-18
ER

PT J
AU Zobeidi, S
   Naderan, M
   Alavi, SE
AF Zobeidi, Shima
   Naderan, Marjan
   Alavi, Seyyed Enayatallah
TI Opinion mining in Persian language using a hybrid feature extraction
   approach based on convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Text mining; Opinion mining; Convolutional neural
   network; Bi-LSTM; Word2vec; Character-level; Sentiment analysis
ID IMPACT
AB Nowadays, huge amounts of text data are generated due to the increase of communications, over various web sites and applications. Evaluation and extraction of information from these data is an important task, one way of which is named opinion mining. The purpose of this paper is sentiment analysis of users' opinions about various products. The proposed system classifies opinions at the sentence level based on emotions into two and multiple classes by deep learning methods. To this end, three main phases are taken: the first step contains sentences preparation for the input matrix which itself is accomplished in two levels: word-level and character-level. In word-level, each word in each sentence is given to the word2vec algorithm. In character-level, for each character in each sentence, the proposed method computes a numerical vector and creates a matrix. Next, the feature extraction part is executed which includes a Convolutional Neural Network (CNN). The generated matrices in the previous levels for each sentence are given to the CNN for embedding each sentence and therefore, utilizing both word2vec and CNN for extracting features. In the final step, the generated vectors are given to the Bidirectional Long Short Term Memory (Bi-LSTM) network for sentiment classification, not used in any of the previous methods. The performance of the proposed algorithm has been investigated on the Digikala Persian dataset on mobile and digital cameras. Results show that the proposed algorithm reaches an accuracy of 95% for two classes and 92% for multi-class classification which is comparable with previous algorithms.
C1 [Zobeidi, Shima; Naderan, Marjan; Alavi, Seyyed Enayatallah] Shahid Chamran Univ Ahvaz, Dept Comp Engn, Fac Engn, Ahvaz, Iran.
C3 Shahid Chamran University of Ahvaz
RP Naderan, M (corresponding author), Shahid Chamran Univ Ahvaz, Dept Comp Engn, Fac Engn, Ahvaz, Iran.
EM m.naderan@scu.ac.ir
RI Naderan, Marjan/AAD-8944-2019
OI Naderan, Marjan/0000-0002-3702-8977
CR Alshari EM, 2017, INT WORKSHOP DATABAS, P123, DOI 10.1109/DEXA.2017.41
   Amiri F., 2015, Proceedings of Recent Advances in Natural Language Processing, Hissar, P9
   [Anonymous], INT JOINT C NEUR NET
   [Anonymous], 7 INT C INF INT SYST
   [Anonymous], 2014, P 31 INT C MACH LEAR
   [Anonymous], IEEE 21 INT C COMP S
   [Anonymous], 2014, Learning to execute
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], IEEE INT C INF AUT I
   [Anonymous], 2013, 21 IR C EL ENG ICEE, DOI DOI 10.1109/IRANIANCEE.2013.6599671
   [Anonymous], 9 INT C KNOWL SMART
   [Anonymous], JIMS8I INT J INFORM
   [Anonymous], 2013, COMPUTATION LANGUAGE
   [Anonymous], 8 INT C KNOWL SYST E
   Anwar S, 2015, INT CONF ACOUST SPEE, P1131, DOI 10.1109/ICASSP.2015.7178146
   Basiri ME, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA), P84, DOI 10.1109/PRIA.2017.7983023
   Boudad N, 2018, AIN SHAMS ENG J, V9, P2479, DOI 10.1016/j.asej.2017.04.007
   De Mulder W, 2015, COMPUT SPEECH LANG, V30, P61, DOI 10.1016/j.csl.2014.09.005
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Enríquez F, 2016, EXPERT SYST APPL, V66, P1, DOI 10.1016/j.eswa.2016.09.005
   Gopalakrishnan Vinodhini, 2017, J. appl. res. technol, V15, P311, DOI 10.1016/j.jart.2017.02.005
   Graves A., 2013, GENERATING SEQUENCES
   LANG KJ, 1990, NEURAL NETWORKS, V3, P23, DOI 10.1016/0893-6080(90)90044-L
   Lau RYK, 2014, IEEE COMPUT INTELL M, V9, P31, DOI 10.1109/MCI.2013.2291689
   Lei XJ, 2016, IEEE T MULTIMEDIA, V18, P1910, DOI 10.1109/TMM.2016.2575738
   Li QD, 2016, KNOWL-BASED SYST, V107, P289, DOI 10.1016/j.knosys.2016.06.017
   Li X, 2017, ENVIRON POLLUT, V231, P997, DOI 10.1016/j.envpol.2017.08.114
   Li XD, 2014, KNOWL-BASED SYST, V69, P14, DOI 10.1016/j.knosys.2014.04.022
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Liu ZJ, 2015, J BIOMED INFORM, V58, pS47, DOI 10.1016/j.jbi.2015.06.009
   McLeod P, 2000, COGNITION, V74, P91, DOI 10.1016/S0010-0277(99)00067-0
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Pang L, 2015, IEEE T MULTIMEDIA, V17, P2008, DOI 10.1109/TMM.2015.2482228
   Razzaghnoori M, 2018, COGN SYST RES, V47, P16, DOI 10.1016/j.cogsys.2017.07.002
   Rill S, 2014, KNOWL-BASED SYST, V69, P24, DOI 10.1016/j.knosys.2014.05.008
   Sainath TN, 2017, IEEE-ACM T AUDIO SPE, V25, P965, DOI 10.1109/TASLP.2017.2672401
   Sangeetha T, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN DATA SCIENCE (ICCIDS)
   Saon G, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2701178
   Schouten K, 2016, IEEE T KNOWL DATA EN, V28, P813, DOI 10.1109/TKDE.2015.2485209
   Shams M., 2012, 2012 16th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP), P216, DOI 10.1109/AISP.2012.6313747
   Socher R., 2011, P C EMP METH NAT LAN, P151
   Socher Richard, 2012, P 2012 JOINT C EMPIR, DOI [10.5555/2390948.2391084, DOI 10.1162/153244303322533223]
   Sun SL, 2017, INFORM FUSION, V36, P10, DOI 10.1016/j.inffus.2016.10.004
   Sun Y, 2016, IEEE T PATTERN ANAL, V38, P1997, DOI 10.1109/TPAMI.2015.2505293
   Xu XK, 2013, CHINA COMMUN, V10, P25, DOI 10.1109/CC.2013.6488828
   Zhang Y, 2017, ADV SOC SCI EDUC HUM, V185, P253
   Zhao R, 2017, IEEE-ACM T AUDIO SPE, V25, P248, DOI 10.1109/TASLP.2016.2632521
NR 47
TC 8
Z9 8
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32357
EP 32378
DI 10.1007/s11042-019-07993-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000057
DA 2024-07-18
ER

PT J
AU Xing, ZK
   Jia, HM
AF Xing, Zhikai
   Jia, Heming
TI Modified thermal exchange optimization based multilevel thresholding for
   color image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-threshold color image segmentation; Tsallis entropy method;
   Thermal exchange optimization; Levy flight
ID ALGORITHM; NETWORK
AB This paper proposes a multi-threshold image segmentation method based on modified thermal exchange optimization (TEO). Although it is efficient and gives excellent result in the case of bi-level thresholding, but it takes a lot of computation when the number of threshold increases. To overcome this problem, the TEO algorithm is applied in this search area for searching the optimal thresholds. The Levy flight algorithm is employed to modify the original TEO and balance the exploration and exploitation of TEO. Experiments are conducted between six state-of-the-art metaheuristic algorithms and the proposed one. The benchmark functions, color nature images and stellite images are used in the experiment to test the performance of the algorithms involved. Qualitative experimental results show that the proposed segmentation approach has fewer iterations and higher segmentation accuracy.
C1 [Xing, Zhikai; Jia, Heming] Northeast Forestry Univ, Coll Mech & Elect Engn, Harbin 150040, Heilongjiang, Peoples R China.
C3 Northeast Forestry University - China
RP Jia, HM (corresponding author), Northeast Forestry Univ, Coll Mech & Elect Engn, Harbin 150040, Heilongjiang, Peoples R China.
EM jiaheming@nefu.edu.cn
RI Xing, Zhikai/AAI-5852-2020
CR Amirsadri S., 2017, NEURAL COMPUT APPL, V30, P1
   [Anonymous], IEEE T FUZZY SYS
   Askarzadeh A, 2016, COMPUT STRUCT, V169, P1, DOI 10.1016/j.compstruc.2016.03.001
   BHAMBU P, 2017, INT C REV ADV INN EN
   Bohat VK, 2019, EXPERT SYST APPL, V117, P176, DOI 10.1016/j.eswa.2018.08.045
   Bozkurt ÖÖ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175915
   CAI X, 2016, IMPROVED BAT ALGORIT
   CHAKRABORTY S, 2017, MICROSC RES TECH
   Chaudhry A., 2017, DISCOVERING CLASS SP
   Cufoglu A, 2017, INT J MODEL SIMUL SC, V8, DOI 10.1142/S1793962317500568
   DONG W, 2017, J COMPUT PHYS, V350
   Gattenlöhner S, 2016, PHYS REV LETT, V117, DOI 10.1103/PhysRevLett.117.046603
   He LF, 2017, NEUROCOMPUTING, V240, P152, DOI 10.1016/j.neucom.2017.02.040
   Huang K, 2017, ADV MULTIMED, V2017, DOI [10.1155/2017/4183986, 10.1155/2017/2895680]
   Kaveh A, 2017, ADV ENG SOFTW, V110, P69, DOI 10.1016/j.advengsoft.2017.03.014
   KOSIOROWSKI D, 2017, DETECTING STRUCTURAL
   Laux T, 2016, CALC VAR PARTIAL DIF, V55, DOI 10.1007/s00526-016-1053-0
   Li RR, 2018, IEEE J-STARS, V11, P3954, DOI 10.1109/JSTARS.2018.2833382
   Ling Y, 2017, IEEE ACCESS, V5, P6168, DOI 10.1109/ACCESS.2017.2695498
   MA M, 2017, J COMPUT THEOR NANOS, V14, P3794, DOI DOI 10.1166/jctn.2017.6675
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Muangkote N, 2016, INT JOINT CONF COMP, P460
   Niharika E, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON IOT AND ITS APPLICATIONS (IEEE ICIOT)
   Oliva D, 2017, EXPERT SYST APPL, V79, P164, DOI 10.1016/j.eswa.2017.02.042
   Pare S, 2018, SIGNAL IMAGE VIDEO P, V12, P385, DOI 10.1007/s11760-017-1170-z
   Rajinikanth V, 2018, ARAB J SCI ENG, V43, P4365, DOI 10.1007/s13369-017-3053-6
   REN W, 2017, VIDEO DEBLURRING VIA
   Sampaio FC, 2017, CHEM ENG TECHNOL, V40, P122, DOI 10.1002/ceat.201600066
   SOMWANSHI D, 2017, INT C REV ADV INN EN
   Tao PD, 1998, SIAM J OPTIMIZ, V8, P476, DOI 10.1137/S1052623494274313
   Pham TX, 2018, APPL SOFT COMPUT, V65, P230, DOI 10.1016/j.asoc.2018.01.003
   Wang ZY, 2019, MACH VISION APPL, V30, P255, DOI 10.1007/s00138-019-01008-w
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   XUE J, 2017, MULTITHRESHOLD IMAGE
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Ye ZW, 2015, APPL SOFT COMPUT, V31, P381, DOI 10.1016/j.asoc.2015.02.012
   Zhu HJ, 2017, MULTIMED TOOLS APPL, V76, P8951, DOI 10.1007/s11042-016-3486-z
NR 37
TC 21
Z9 21
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1137
EP 1168
DI 10.1007/s11042-019-08229-1
EA OCT 2019
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000491033100001
DA 2024-07-18
ER

PT J
AU Das, S
AF Das, Sayan
TI A statistical tool based binarization method for document images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document image; Statistical tools; Edge detection; Connected component
   features analysis; Image binarization
AB Binarization of document images has great importance in several applications like historical document restoration, Optical Character Recognition (OCR). It is a challenging task due to small difference between foreground and background pixel intensities, intricate font patterns and noisy background. In this article a binarization algorithm is presented for document images which has performed significantly well on handwritten document images as well as machine printed document images. First, the RGB document images are converted to a prominent gray-scale image using statistical tools like mean, variance and standard deviation. Next, the gray-scale images are binarized using edge detection. Further the noises are removed using connected component features analysis. The proposed method is experimented on publicly available DIBCO 2016 and DIBCO 2017 datasets. The performance of the proposed algorithm is satisfactory in terms of F-Measure (FM), Pseudo-FMeasure (F-ps), PSNR, Distance Reciprocal Distortion (DRD) and it also provides significant results on degraded document images.
C1 [Das, Sayan] St Thomas Coll Engn & Technol, Kolkata, India.
RP Das, S (corresponding author), St Thomas Coll Engn & Technol, Kolkata, India.
EM sayandas896@gmail.com
OI Das, Sayan/0000-0003-0505-8589
CR Sanchez JA, 2016, INT CONF FRONT HAND, P630, DOI [10.1109/ICFHR.2016.112, 10.1109/ICFHR.2016.0120]
   [Anonymous], 2013, P 2 INT WORKSH HIST, DOI [10.1145/2501115.2501130, DOI 10.1145/2501115.2501130]
   Block M, 2009, THIRD INTERNATIONAL CONFERENCE ON DIGITAL SOCIETY: ICDS 2009, PROCEEDINGS, P294, DOI 10.1109/ICDS.2009.45
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chaudhuri BB, 2017, PATTERN RECOGN, V61, P282, DOI 10.1016/j.patcog.2016.07.032
   Fiel S, 2017, PROC INT CONF DOC, P1377, DOI 10.1109/ICDAR.2017.225
   Gatos Basilis, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1375, DOI 10.1109/ICDAR.2009.246
   Gattal A, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P305, DOI 10.1109/DAS.2016.10
   Griffin LD, 2009, LECT NOTES COMPUT SC, V5567, P343, DOI 10.1007/978-3-642-02256-2_29
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Howe NR, 2013, INT J DOC ANAL RECOG, V16, P247, DOI 10.1007/s10032-012-0192-x
   Ioffe S, 2015, ARXIV150203167CSCV
   Kavallieratou E, 2006, SECOND INTERNATIONAL CONFERENCE ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P340, DOI 10.1109/DIAL.2006.23
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Makridis M, 2010, INT J PATTERN RECOGN, V24, P245, DOI 10.1142/S0218001410007889
   Monte da Silva JM, 2008, J UNIVERS COMPUT SCI, V14, P299
   Nafchi Hossein Ziaei, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P1, DOI 10.1007/978-3-642-37484-5_1
   Ntirogiannis K, 2014, PATTERN RECOGN LETT, V35, P3, DOI 10.1016/j.patrec.2012.09.026
   Ntirogiannis K, 2014, INT CONF FRONT HAND, P809, DOI 10.1109/ICFHR.2014.141
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pratikakis I., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P727, DOI 10.1109/ICFHR.2010.118
   Pratikakis I, 2017, PROC INT CONF DOC, P1395, DOI 10.1109/ICDAR.2017.228
   Pratikakis I, 2016, INT CONF FRONT HAND, P619, DOI [10.1109/ICFHR.2016.110, 10.1109/ICFHR.2016.0118]
   Pratikakis I, 2012, INT CONF FRONT HAND, P817, DOI 10.1109/ICFHR.2012.216
   Pratikakis I, 2011, PROC INT CONF DOC, P1506, DOI 10.1109/ICDAR.2011.299
   Roe E, 2015, VISUAL COMPUT, V31, P627, DOI 10.1007/s00371-014-0988-4
   Sari T, 2014, ADV MULTIMED, V2014, DOI 10.1155/2014/934656
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Singh P, 2018, 13 IAPR INT WORKSH D
   Su BL, 2013, IEEE T IMAGE PROCESS, V22, P1408, DOI 10.1109/TIP.2012.2231089
   Tensmeyer Chris., 2017, P 4 INT WORKSHOP HIS, P59, DOI DOI 10.1145/3151509.3151522
   Wigington C, 2018, LECT NOTES COMPUT SC, V11210, P372, DOI 10.1007/978-3-030-01231-1_23
   Wu Y, 2016, IEEE P INT C IM PROC
   Zagoris K, 2013, PROC INT CONF DOC, P1370, DOI 10.1109/ICDAR.2013.277
NR 35
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27449
EP 27462
DI 10.1007/s11042-019-07857-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000030
DA 2024-07-18
ER

PT J
AU Gao, MY
   Du, YJ
   Yang, YX
   Zhang, J
AF Gao, Mingyu
   Du, Yujie
   Yang, Yuxiang
   Zhang, Jing
TI Adaptive anchor box mechanism to improve the accuracy in the object
   detection system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural network; Object detection; Depth information; Anchor box
ID SCALE
AB Recently, most state-of-the-art object detection systems adopt anchor box mechanism to simplify the detection model. Neural networks only need to regress the mapping relations from anchor boxes to ground truth boxes, then prediction boxes can be calculated using information from outputs of networks and default anchor boxes. However, when the problem becomes complex, the number of default anchor boxes will increase with large risk of over-fitting during training. In this paper, we adopt an adaptive anchor box mechanism that one anchor box can cover more ground truth boxes. So networks only need a few adoptive anchor boxes to solve the same problem and the model will be more robust. The sizes of adaptive anchor boxes will be adjusted automatically according to the depth collected by a Time of Flight (TOF) camera. The network adjusts the aspect ratios of anchor boxes to get final prediction boxes. The experimental results demonstrate that the proposed method can get more accurate detection results. Specifically, using the proposed adaptive anchor box mechanism, the Mean Average Precision (mAP) of YOLO-v2 and YOLO-v3 networks increases obviously on open public datasets and our self-built battery image dataset. Moreover, the visual results of prediction comparisons also illustrate that the proposed adaptive anchor box mechanism can achieve better performance than original anchor box mechanism.
C1 [Gao, Mingyu; Du, Yujie; Yang, Yuxiang] Hangzhou Dianzi Univ, Sch Elect & Informat, Hangzhou, Zhejiang, Peoples R China.
   [Gao, Mingyu; Du, Yujie] Zhejiang Prov Key Lab Equipment Elect, Hangzhou, Zhejiang, Peoples R China.
   [Yang, Yuxiang; Zhang, Jing] Hangzhou Dianzi Univ, Sch Automat, Hangzhou, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University
RP Yang, YX (corresponding author), Hangzhou Dianzi Univ, Sch Elect & Informat, Hangzhou, Zhejiang, Peoples R China.; Yang, YX (corresponding author), Hangzhou Dianzi Univ, Sch Automat, Hangzhou, Zhejiang, Peoples R China.
EM yyx@hdu.edu.cn
RI ZHANG, JING/HKF-4837-2023
OI ZHANG, JING/0000-0001-6595-7661
FU National Natural Science Foundation of China [61873077, U1609216,
   61806062]; Zhejiang Provincial Key Lab of Equipment Electronics
FX This work was supported by National Natural Science Foundation of China
   (61873077, U1609216 and 61806062). This work was supported by Zhejiang
   Provincial Key Lab of Equipment Electronics.
CR [Anonymous], MULTIMED TOOLS APPL
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Everingham Mark, 2007, PASCAL VISUAL OBJECT
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hussain K.F., 2018, IEEE Transactions on Intelligent Transportation Systems, P1
   Karaimer HC, 2016, LECT NOTES COMPUT SC, V9905, P429, DOI 10.1007/978-3-319-46448-0_26
   Kim JU, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030882
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Liu W., 2016, LECT NOTES COMPUT SC, P21, DOI DOI 10.1007/978-3-319-46448-0_2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mao JY, 2017, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2017.639
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pogorelov K, 2017, MULTIMED TOOLS APPL, V76, P22493, DOI 10.1007/s11042-017-4989-y
   Ramanath R, 2005, IEEE SIGNAL PROC MAG, V22, P34, DOI 10.1109/MSP.2005.1407713
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Ye T, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061916
   Yoganand AV, 2018, MULTIMED TOOLS APPL, V77, P31763, DOI 10.1007/s11042-018-6191-2
   Zhang C, 2019, MULTIMED TOOLS APPL, V78, P1719, DOI 10.1007/s11042-018-6240-x
   Zhao BJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030774
NR 27
TC 22
Z9 25
U1 4
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27383
EP 27402
DI 10.1007/s11042-019-07858-w
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000027
DA 2024-07-18
ER

PT J
AU Lim, J
   Bok, K
   Yoo, J
AF Lim, Jongtae
   Bok, Kyoungsoo
   Yoo, Jaesoo
TI A continuous reverse skyline query processing scheme for multimedia data
   sharing in mobile environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia data; Reverse skyline; Location-based service; Continuous
   query
AB Recently, various query processing schemes in mobile environments have been studied. Particularly, a reverse skyline query that is the variation of a skyline query has been receiving much attention these days for multimedia data. However, the existing reverse skyline query processing schemes did not consider the mobility of devices. In this paper, we propose a continuous reverse skyline query processing scheme that considers the mobility of mobile devices. The proposed scheme removes the devices that do not affect a query by using a pruning method and continuously monitors the areas of candidate devices to update the query result incrementally.
C1 [Lim, Jongtae; Bok, Kyoungsoo; Yoo, Jaesoo] Chungbuk Natl Univ, Dept Informat & Commun Engn, Chungdae Ro 1, Cheongju 28644, Chungbuk, South Korea.
C3 Chungbuk National University
RP Yoo, J (corresponding author), Chungbuk Natl Univ, Dept Informat & Commun Engn, Chungdae Ro 1, Cheongju 28644, Chungbuk, South Korea.
EM jtlim@chungbuk.ac.kr; ksbok@chungbuk.ac.kr; yjs@chungbuk.ac.kr
OI YOO, JAESOO/0000-0001-9926-9947
FU MSIT(Ministry of Science and ICT), Korea, under the ITRC(Information
   Technology Research Center) support program [IITP-2017-2013-0-00881,
   IITP-2017-2013-0-00680]; National Research Foundation of Korea(NRF)
   grant - Korea government(MSIP) [2016R1A2B3007527]
FX This research was supported the MSIT(Ministry of Science and ICT),
   Korea, under the ITRC(Information Technology Research Center) support
   program(IITP-2017-2013-0-00881, IITP-2017-2013-0-00680) supervised by
   the IITP(Institute for Information & communications Technology
   Promotion) and the National Research Foundation of Korea(NRF) grant
   funded by the Korea government(MSIP) (No. 2016R1A2B3007527).
CR [Anonymous], 2006, P ACM SIGMOD INT C M, DOI DOI 10.1145/1142473.1142547
   [Anonymous], P INT DAT ENG APPL S
   [Anonymous], 1990, SIGMOD, DOI DOI 10.1145/93597.98741
   Börzsönyi S, 2001, PROC INT CONF DATA, P421, DOI 10.1109/ICDE.2001.914855
   Brakatsoulas S, 2004, INTERNATIONAL DATABASE ENGINEERING AND APPLICATIONS SYMPOSIUM, PROCEEDINGS, P68, DOI 10.1109/IDEAS.2004.1319779
   Chen S, 2008, ITI TREATMENT GUIDE, V3, P29
   Dellis E., 2007, Proceedings of the 33rd international conference on Very large data bases, P291
   Deshpande P. M., 2011, P 14 INT C EXT DAT T, P319
   Dik Lun Lee, 2002, IEEE Pervasive Computing, V1, P65, DOI 10.1109/MPRV.2002.1037724
   Ilyas IF, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1391729.1391730
   Lian Xiang., 2008, P ACM SIGMOD INT C M, P213
   Lim J., 2010, P ITCS 2010 AUG, P1
   NIEVERGELT J, 1984, ACM T DATABASE SYST, V9, P38, DOI 10.1145/348.318586
   Pan S., 2014, INT J DISTRIB SENS N, V2014, P1
   Papadias D, 2005, ACM T DATABASE SYST, V30, P41, DOI 10.1145/1061318.1061320
   Papadias D., 2003, QUERY PROCESSING SPA, P802
   Song ZX, 2001, LECT NOTES COMPUT SC, V2121, P79
   Wang HJ, 2011, IEEE T KNOWL DATA EN, V23, P1065, DOI 10.1109/TKDE.2010.171
   Wang YQ, 2014, INFORM SYST, V44, P1, DOI 10.1016/j.is.2014.02.003
   Zhu L, 2009, INTERNATIONAL JOINT CONFERENCE ON COMPUTATIONAL SCIENCES AND OPTIMIZATION, VOL 1, PROCEEDINGS, P735, DOI 10.1109/CSO.2009.74
NR 20
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28357
EP 28373
DI 10.1007/s11042-017-5191-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700001
DA 2024-07-18
ER

PT J
AU Yuan, D
   Zhang, XM
   Liu, JQ
   Li, DH
AF Yuan, Di
   Zhang, Xinming
   Liu, Jiaqi
   Li, Donghao
TI A multiple feature fused model for visual object tracking via
   correlation filters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Multiple feature fusion; Adaptive weighting;
   Correlation filter; Scale detection
ID WRITER IDENTIFICATION
AB Common tracking algorithms only use a single feature to describe the target appearance, which makes the appearance model easily disturbed by noise. Furthermore, the tracking performance and robustness of these trackers are obviously limited. In this paper, we propose a novel multiple feature fused model into a correlation filter framework for visual tracking to improve the tracking performance and robustness of the tracker. In different tracking scenarios, the response maps generated by the correlation filter framework are different for each feature. Based on these response maps, different features can use an adaptive weighting function to eliminate noise interference and maintain their respective advantages. It can enhance the tracking performance and robustness of the tracker efficiently. Meanwhile, the correlation filter framework can provide a fast training and accurate locating mechanism. In addition, we give a simple yet effective scale variation detection method, which can appropriately handle scale variation of the target in the tracking sequences. We evaluate our tracker on OTB2013/OTB50/OBT2015 benchmarks, which are including more than 100 video sequences. Extensive experiments on these benchmark datasets demonstrate that the proposed MFFT tracker performs favorably against the state-of-the-art trackers.
C1 [Yuan, Di; Li, Donghao] Harbin Inst Technol Shenzhen, Sch Comp Sci, Shenzhen, Peoples R China.
   [Yuan, Di; Zhang, Xinming] Harbin Inst Technol Shenzhen, Sch Sci, Shenzhen, Peoples R China.
   [Liu, Jiaqi] Hunan Univ, Coll Finance & Stat, Changsha, Hunan, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology; Hunan
   University
RP Yuan, D (corresponding author), Harbin Inst Technol Shenzhen, Sch Comp Sci, Shenzhen, Peoples R China.; Yuan, D (corresponding author), Harbin Inst Technol Shenzhen, Sch Sci, Shenzhen, Peoples R China.
EM yuandi@stu.hit.edu.cn; xinmingxueshu@hit.edu.cn; jiaqi_liu1993@163.com;
   lidh@hit.edu.cn
RI Yuan, Di/Q-6521-2019
OI Yuan, Di/0000-0001-9403-1112
FU Shenzhen Research Council [JCYJ2016040 6161948211,
   JCYJ20160226201453085, JSGG20150331152017052, JCYJ20160531194006833];
   National Natural Science Foundation of China [61672183, 61272366,
   61672444]; Science and Technology Planning Project of Guangdong Province
   [2016B090918047]
FX This research was supported by the Shenzhen Research Council (Grant No.
   JCYJ2016040 6161948211, JCYJ20160226201453085, JSGG20150331152017052,
   JCYJ20160531194006833), by the National Natural Science Foundation of
   China (Grant No. 61672183, 61272366, 61672444), by Science and
   Technology Planning Project of Guangdong Province (Grant No.
   2016B090918047).
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], MULTIMED TOOLS APPL
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bibi A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P613, DOI 10.1109/ICCVW.2015.83
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cehovin L, 2014, IEEE WINT CONF APPL, P540, DOI 10.1109/WACV.2014.6836055
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan NN, 2019, KNOWL-BASED SYST, V172, P95, DOI 10.1016/j.knosys.2019.02.017
   Galoogahi HK, 2013, IEEE I CONF COMP VIS, P3072, DOI 10.1109/ICCV.2013.381
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   He ZY, 2008, PATTERN RECOGN, V41, P1295, DOI 10.1016/j.patcog.2007.08.017
   He ZY, 2017, IEEE T CYBERNETICS, V47, P354, DOI 10.1109/TCYB.2016.2514714
   He ZY, 2016, IEEE T IMAGE PROCESS, V25, P3698, DOI 10.1109/TIP.2016.2570553
   He ZY, 2010, INTEGR COMPUT-AID E, V17, P157, DOI 10.3233/ICA-2010-0338
   He ZY, 2010, INT J COMPUT VISION, V87, P235, DOI 10.1007/s11263-009-0256-7
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hong ZB, 2013, IEEE I CONF COMP VIS, P649, DOI 10.1109/ICCV.2013.86
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li F, 2017, IEEE INT CONF COMP V, P2001, DOI 10.1109/ICCVW.2017.234
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Li X, 2019, KNOWL-BASED SYST, V166, P71, DOI 10.1016/j.knosys.2018.12.011
   Li X, 2016, KNOWL-BASED SYST, V113, P88, DOI 10.1016/j.knosys.2016.09.014
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liu Q, 2017, KNOWL-BASED SYST, V134, P189, DOI 10.1016/j.knosys.2017.07.032
   Liu S, 2016, PROC CVPR IEEE, P4312, DOI 10.1109/CVPR.2016.467
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Lu Xuan, 2010, Journal of Computer Applications, V30, P650, DOI 10.3724/SP.J.1087.2010.00650
   Ma L, 2015, IEEE I CONF COMP VIS, P3128, DOI 10.1109/ICCV.2015.358
   Ma X, 2016, KNOWL-BASED SYST, V106, P26, DOI 10.1016/j.knosys.2016.05.028
   Ou WH, 2018, MULTIMED TOOLS APPL, V77, P10569, DOI 10.1007/s11042-017-4672-3
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Tang M, 2015, IEEE I CONF COMP VIS, P3038, DOI 10.1109/ICCV.2015.348
   Tang XH, 2008, CONF P INDIUM PHOSPH, P1
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang NY, 2015, IEEE I CONF COMP VIS, P3101, DOI 10.1109/ICCV.2015.355
   Wang Q, 2018, NEUROCOMPUTING, V314, P132, DOI 10.1016/j.neucom.2018.05.102
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yi SY, 2017, PATTERN RECOGN, V61, P524, DOI 10.1016/j.patcog.2016.08.025
   Yuan D, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P88, DOI 10.1109/SPAC.2017.8304256
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang TZ, 2019, IEEE T PATTERN ANAL, V41, P365, DOI 10.1109/TPAMI.2018.2797062
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhang TZ, 2016, PROC CVPR IEEE, P3880, DOI 10.1109/CVPR.2016.421
   Zhiyu Zhou, 2014, Journal of Software, V9, P147, DOI 10.4304/jsw.9.1.147-153
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou Y., 2011, SIN FOR INT C INT SC, V7202, P145
NR 63
TC 44
Z9 47
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27271
EP 27290
DI 10.1007/s11042-019-07828-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000022
DA 2024-07-18
ER

PT J
AU Litvin, A
   Nasrollahi, K
   Escalera, S
   Ozcinar, C
   Moeslund, TB
   Anbarjafari, G
AF Litvin, Andre
   Nasrollahi, Kamal
   Escalera, Sergio
   Ozcinar, Cagri
   Moeslund, Thomas B.
   Anbarjafari, Gholamreza
TI A novel deep network architecture for reconstructing RGB facial images
   from thermal for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fully convolutional networks; FusionNet; Thermal imaging; Face
   recognition
AB This work proposes a fully convolutional network architecture for RGB face image generation from a given input thermal face image to be applied in face recognition scenarios. The proposed method is based on the FusionNet architecture and increases robustness against overfitting using dropout after bridge connections, randomised leaky ReLUs (RReLUs), and orthogonal regularization. Furthermore, we propose to use a decoding block with resize convolution instead of transposed convolution to improve final RGB face image generation. To validate our proposed network architecture, we train a face classifier and compare its face recognition rate on the reconstructed RGB images from the proposed architecture, to those when reconstructing images with the original FusionNet, as well as when using the original RGB images. As a result, we are introducing a new architecture which leads to a more accurate network.
C1 [Litvin, Andre; Anbarjafari, Gholamreza] Univ Tartu, Inst Technol, iCV Res Grp, EE-50411 Tartu, Estonia.
   [Nasrollahi, Kamal; Moeslund, Thomas B.] Aalborg Univ, Visual Anal People Lab, Aalborg, Denmark.
   [Escalera, Sergio] Univ Barcelona, Dept Math & Informat, Barcelona, Spain.
   [Escalera, Sergio] Comp Vis Ctr, Campus UAB, Barcelona, Spain.
   [Ozcinar, Cagri] Trinity Coll Dublin, Sch Comp Sci & Stat, Dublin 2, Ireland.
   [Anbarjafari, Gholamreza] Hasan Kalyoncu Univ, Dept Elect & Elect Engn, Gaziantep, Turkey.
   [Anbarjafari, Gholamreza] Loughborough Univ London, Inst Digital Technol, London, England.
C3 University of Tartu; Aalborg University; University of Barcelona;
   Autonomous University of Barcelona; Centre de Visio per Computador
   (CVC); Trinity College Dublin; Hasan Kalyoncu University; Loughborough
   University
RP Anbarjafari, G (corresponding author), Univ Tartu, Inst Technol, iCV Res Grp, EE-50411 Tartu, Estonia.
EM andre@icv.tuit.ut.ee; kn@create.aau.dk; sergio@maia.ub.es;
   ozcinarc@scss.tcd.ie; tbm@create.aau.dk; shb@icv.tuit.ut.ee
RI Anbarjafari, Gholamreza/A-3845-2010; Escalera, Sergio/L-2998-2015
OI Anbarjafari, Gholamreza/0000-0001-8460-5717; Moeslund, Thomas
   B./0000-0001-7584-5209; Escalera, Sergio/0000-0003-0617-8873; Ozcinar,
   Cagri/0000-0003-4915-2251
FU IT Academy/StudyITin.ee; Scientific and Technological Research Council
   of Turkey (TUBITAK) [116E097]; Spanish project (MINECO/FEDER, UE)
   [TIN2016-74946-P]; CERCA Programme / Generalitat de Catalunya; Estonian
   Centre of Excellence in IT (EXCITE) - European Regional Development
   Fund; NVIDIA Corporation; ICREA under ICREA Academia programme
FX This work has been partially supported by IT Academy/StudyITin.ee, the
   Scientific and Technological Research Council of Turkey (TUBITAK) 1001
   Project (116E097), by the Spanish project TIN2016-74946-P (MINECO/FEDER,
   UE) and CERCA Programme / Generalitat de Catalunya and the Estonian
   Centre of Excellence in IT (EXCITE) funded by the European Regional
   Development Fund. The authors also gratefully acknowledge the support of
   NVIDIA Corporation with the donation of a Titan X Pascal GPU. This work
   is partially supported by ICREA under the ICREA Academia programme.
CR Anbarjafari G, 2019, B POL ACAD SCI-TECH, V67, P125, DOI 10.24425/bpas.2019.127341
   Anbarjafari G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-6
   [Anonymous], 2016, ARXIV161205360
   [Anonymous], 2017, ARXIV170702937
   [Anonymous], ARXIV 1609 07093
   [Anonymous], 2014, P 16 INT C MULT INT
   [Anonymous], MODERN FACE RECOGNIT
   [Anonymous], 2018, IEEE T AFFECTIVE COM
   [Anonymous], 2017, L2 Regularization versus Batch and Weight Normalization
   [Anonymous], 2015, ARXIV150702879
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   Bebis G, 2006, IMAGE VISION COMPUT, V24, P727, DOI 10.1016/j.imavis.2006.01.017
   Bourlai T, 2016, IMAGE VISION COMPUT, V55, P14, DOI 10.1016/j.imavis.2016.03.017
   Buddharaju P, 2007, IEEE T PATTERN ANAL, V29, P613, DOI 10.1109/TPAMI.2007.1007
   Daneshmand M., 2018, ARXIV180108863
   Demirel H, 2008, IEEE SIGNAL PROC LET, V15, P537, DOI 10.1109/LSP.2008.926729
   Eleyan A, 2008, IEEE INT SYMP SIGNAL, P7, DOI 10.1109/ISSPIT.2008.4775675
   Haamer RE, 2018, IEEE INT CONF AUTOMA, P621, DOI 10.1109/FG.2018.00098
   Friedrich G, 2002, LECT NOTES COMPUT SC, V2525, P348
   Ghiass RS, 2014, PATTERN RECOGN, V47, P2807, DOI 10.1016/j.patcog.2014.03.015
   Gross R, 2006, IMAGE VISION COMPUT, V24, P593, DOI 10.1016/j.imavis.2005.08.001
   Guo JZ, 2018, IEEE ACCESS, V6, P26391, DOI 10.1109/ACCESS.2018.2831927
   Hsieh CC, 2016, MULTIMED TOOLS APPL, V75, P6663, DOI 10.1007/s11042-015-2598-1
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Lin WY, 2014, MULTIMED TOOLS APPL, V68, P877, DOI 10.1007/s11042-012-1092-2
   Liu JJ, 2018, MULTIMED TOOLS APPL, V77, P28863, DOI 10.1007/s11042-018-6071-9
   Nikisins O, 2014, INT C PATT RECOG, P1716, DOI 10.1109/ICPR.2014.302
   Nixon MS, 2015, PATTERN RECOGN LETT, V68, P218, DOI 10.1016/j.patrec.2015.08.006
   Odena A., 2016, DISTILL, V1, P3, DOI [10.23915/distill.00003., DOI 10.23915/DISTILL, 10.23915/distill.00003, DOI 10.23915/DISTILL.00003]
   Parkhi O.M., 2015, Deep Face Recognition, V1, p41.1
   Sajjadi Mehdi S. M., 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P4501, DOI 10.1109/ICCV.2017.481
   Saxe A. M., 2013, arXiv preprint arXiv:1312.6120
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Wan J., 2017, CHALEARN LAP ACTION, V4
   Wilson AC, 2017, ADV NEUR IN, V30
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zhang H, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P100
   Zhang T, 2018, INT CONF BIOMETR, P174, DOI 10.1109/ICB2018.2018.00035
NR 40
TC 9
Z9 10
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25259
EP 25271
DI 10.1007/s11042-019-7667-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700003
DA 2024-07-18
ER

PT J
AU Manohar, K
   Kieu, TD
AF Manohar, Kris
   The Duc Kieu
TI A centroid based vector quantization reversible data hiding technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Steganography; Watermarking; Vector
   quantization; Side match vector quantization; Centroid boundary vector;
   Centroid state codebook
ID STATE-CODEBOOK; SCHEME; COMPRESSION; INDEX; STRATEGY; SMVQ
AB In this paper, we propose a reversible data hiding scheme that exploits the centroid formula. Specifically, we use it to define a centroid boundary vector and a centroid state codebook CSCB. Initially, our centroid boundary vectors and CSCBs are the same as the side match vector quantization (SMVQ) algorithm's boundary vectors and state codebooks SCBs. For each VQ index, the proposed scheme exploits the centroid formula to update its centroid boundary vector and the corresponding CSCB. The updating is coupled with a heuristic to select the best state codebook (i.e., either SCB or CSCB) for each VQ index, which generates a highly compressible distribution of index values. Our experimental results show that the proposed scheme can embed n = 1, 2, 3, and 4 bit per index (bpi) at bit rates of 0.332, 0.394, 0.457, and 0.519 bit per pixel (bpp), respectively, for the main codebook size N = 256. These results confirm that the proposed scheme improves recent VQ and SMVQ based reversible data hiding schemes.
C1 [Manohar, Kris; The Duc Kieu] Univ West Indies, Dept Comp & Informat Technol, Fac Sci & Technol, St Augustine, Trinidad Tobago.
C3 University West Indies Mona Jamaica; University West Indies Saint
   Augustine
RP Kieu, TD (corresponding author), Univ West Indies, Dept Comp & Informat Technol, Fac Sci & Technol, St Augustine, Trinidad Tobago.
EM justkrismanohar@gmail.com; ktduc0323@yahoo.com.au
RI Manohar, Kris/AAR-3335-2020
CR Chang CC, 2013, J SYST SOFTWARE, V86, P389, DOI 10.1016/j.jss.2012.09.001
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Cheng PH, 2017, MULTIMED TOOLS APPL, V76, P6031, DOI 10.1007/s11042-015-3142-z
   Davis R. M., 1978, IEEE Communications Society Magazine, V16, P5, DOI 10.1109/MCOM.1978.1089771
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   He WG, 2017, J VIS COMMUN IMAGE R, V49, P351, DOI 10.1016/j.jvcir.2017.10.001
   Hou DD, 2018, SIGNAL PROCESS, V148, P41, DOI 10.1016/j.sigpro.2018.02.002
   Hsieh CH, 1996, IEEE T IMAGE PROCESS, V5, P1579, DOI 10.1109/83.541428
   Jin X, 2018, MULTIMED TOOLS APPL, V77, P15851, DOI 10.1007/s11042-017-5159-y
   Khan MK, 2007, CHAOS SOLITON FRACT, V32, P1749, DOI 10.1016/j.chaos.2005.12.015
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lin CC, 2015, INFORM SCIENCES, V293, P314, DOI 10.1016/j.ins.2014.08.057
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Liu J, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P553, DOI 10.1109/ICISCE.2017.121
   Liu YJ, 2018, DISPLAYS, V51, P51, DOI 10.1016/j.displa.2018.01.004
   Liu YJ, 2016, IET IMAGE PROCESS, V10, P130, DOI 10.1049/iet-ipr.2014.1015
   Manohar K, 2018, MULTIMED TOOLS APPL, V77, P11727, DOI 10.1007/s11042-017-4814-7
   Pan ZB, 2018, J VIS COMMUN IMAGE R, V50, P186, DOI 10.1016/j.jvcir.2017.11.020
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Rahmani P, 2018, INFORM SCIENCES, V435, P224, DOI 10.1016/j.ins.2017.12.041
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Run RS, 2011, EXPERT SYST APPL, V38, P14357, DOI 10.1016/j.eswa.2011.03.024
   Sarreshtedari S, 2014, IET IMAGE PROCESS, V8, P78, DOI 10.1049/iet-ipr.2013.0109
   Wang LF, 2017, MULTIMED TOOLS APPL, V76, P26225, DOI 10.1007/s11042-016-4108-5
   Wang LF, 2017, MULTIMED TOOLS APPL, V76, P26153, DOI 10.1007/s11042-016-4000-3
   Wang WJ, 2013, INFORM SCIENCES, V246, P69, DOI 10.1016/j.ins.2013.05.007
   Weinberger MJ, 1996, DCC '96 - DATA COMPRESSION CONFERENCE, PROCEEDINGS, P140, DOI 10.1109/DCC.1996.488319
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Xia BB, 2018, MULTIMED TOOLS APPL, V77, P20519, DOI 10.1007/s11042-017-5490-3
NR 35
TC 2
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25273
EP 25298
DI 10.1007/s11042-019-7631-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700004
DA 2024-07-18
ER

PT J
AU Zhang, J
   Shi, Y
   Jing, PG
   Liu, J
   Su, YT
AF Zhang, Jing
   Shi, Yue
   Jing, Peiguang
   Liu, Jing
   Su, Yuting
TI A structure-transfer-driven temporal subspace clustering for video
   summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Structure transter; Temporal subspace clustering;
   Video segmentation; DPP
AB With the explosively increasing of mobile phones and other oriented camera devices, more and more video data is captured and stored. This brings out an urgent need for fast browsing and understanding video contents. Automatic generation of video summarization is one of effective techniques to tackle these problems which extracts succinct summaries to represent the original long videos. It involves two problems: video segmentation and summary generation. Most previous works just focused on addressing the second problem by exploiting a simple strategy like boundary detection to segment videos. However, this type of approach leads to suboptimal result because they not only lack of learning mechanism in video segmentation stage, but also separate the whole task into two independent stages. In this paper, we proposed a novel structure-transfer-driven temporal subspace clustering segmentation (STSC) method for video summarization. We first learn the structure information from source videos and then transfer it to target videos. By the Determinantal Point Process (DPP) algorithm, we select an informative subset of shots to create the final video summary. Experimental results on SumMe and TVSum datasets demonstrate the effection of our proposed method, against state-of-the-art methods.
C1 [Zhang, Jing; Shi, Yue; Jing, Peiguang; Liu, Jing; Su, Yuting] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Jing, PG (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM zhangjing@tju.edu.cn; shiyue0330@tju.edu.com; pgjing@tju.edu.cn;
   jliutju@tju.edu.cn; ytsu@tju.edu.cn
RI Liu-Zeng, Jing/F-8582-2011
OI Jing, Peiguang/0000-0003-2648-7358
CR Affandi R.H., 2012, ARXIV12104850
   [Anonymous], ACM T INF SYST
   [Anonymous], P INT C ART INT STAT
   [Anonymous], 2009, Advances in Neural Information Processing Systems
   [Anonymous], 2010, Proceedings of Advances in Neural Information Processing Systems (NIPS)
   [Anonymous], 2010, MATH PROB ENG, DOI DOI 10.1186/1756-0500-3-309
   [Anonymous], MULTIMEDIA ANSWERING
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], 2014, 2014 INT C LEARNING
   Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chao WL, 2015, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P191
   Chu WS, 2015, PROC CVPR IEEE, P3584, DOI 10.1109/CVPR.2015.7298981
   Elhamifar E, 2009, PROC CVPR IEEE, P2782
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gong BQ, 2014, ADV NEUR IN, V27
   Gygli M, 2016, PROC CVPR IEEE, P1001, DOI 10.1109/CVPR.2016.114
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Khosla A, 2013, PROC CVPR IEEE, P2698, DOI 10.1109/CVPR.2013.348
   Kuang KX, 2014, IEEE ICC, P1131, DOI 10.1109/ICC.2014.6883473
   Kulesza A., 2011, P 28 INT C MACH LEAR, P1193
   Kulesza A., 2011, UAI, P419
   Kulesza A, 2012, FOUND TRENDS MACH LE, V5, P123, DOI 10.1561/2200000044
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Liu D, 2010, IEEE T PATTERN ANAL, V32, P2178, DOI 10.1109/TPAMI.2010.31
   Liu G., 2010, P INT C MACH LEARN, P663
   Lu CY, 2012, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON COMPUTER VISION IN REMOTE SENSING, P34
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Robards MW, 2009, IEEE DATA MINING, P438, DOI 10.1109/ICDM.2009.13
   Song YL, 2015, PROC CVPR IEEE, P5179, DOI 10.1109/CVPR.2015.7299154
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhao B, 2014, PROC CVPR IEEE, P2513, DOI 10.1109/CVPR.2014.322
   Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137
NR 40
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24123
EP 24145
DI 10.1007/s11042-018-6841-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900019
DA 2024-07-18
ER

PT J
AU Akila, K
   Chitrakala, S
AF Akila, K.
   Chitrakala, S.
TI Highly refined human action recognition model to handle intraclass
   variability & interclass similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scale-invariance; HOG descriptor; object detection; PCA transform
ID SILHOUETTE; VIDEO
AB The proliferation of network cameras leads to the increase in the usage of cameras in day-to-day life, results in the growth rate of videos increases exponentially, the demand for understanding the videos increases as well. Computer vision systems are far behind the capabilities of human vision. This has created an overriding need to build an intelligent system to analyze and categorize rich video content based on the human actions occurring in the videos. Recognizing the human action is a fascinating field and shows potential space for analysis because of its significance in a variety of applications. In recent times, the investigation is more disbursing on recognizing the human actions in unrestricted videos, as the deviations in scale, lighting, are typically are going to be the case for performance degradation. Hence, an innovative design on advanced gradient model to regularize the HOG descriptor for the scale-invariant and appearance modeling to handle Intraclass variability and Interclass similarity of actions is commenced. To resolve these major issues a discriminative approach has proposed to explore correlation between them. The complete action recognition system evaluated on a number of test videos from real-world UCF and KTH data sets.
C1 [Akila, K.] RMK Coll Engn & Technol, Dept CSE, Chennai, Tamil Nadu, India.
   [Chitrakala, S.] Anna Univ, Dept CSE, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Akila, K (corresponding author), RMK Coll Engn & Technol, Dept CSE, Chennai, Tamil Nadu, India.
EM akilmoorthy@yahoo.com; au.chitras@gmail.com
RI S, Chitrakala/T-9631-2019; K, Akila/AAE-1442-2021; S, C/JLK-9983-2023
OI K, Akila/0000-0003-0787-3130; S, Chitrakala/0000-0002-1871-6037
CR Akila K, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4856
   Arauzo-Azofra A, 2008, J INTELL INF SYST, V30, P273, DOI 10.1007/s10844-007-0037-0
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Cheng J, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2441634
   Cheng J, 2014, MACH VISION APPL, V25, P1007, DOI 10.1007/s00138-013-0581-2
   Gaglio S., 2014, HUMAN ACTIVITY RECOG, P1, DOI DOI 10.1109/THMS.2014.2377111
   Jain A, 2013, PROC CVPR IEEE, P2571, DOI 10.1109/CVPR.2013.332
   Ke SR, 2013, COMPUTERS, V2, P88, DOI 10.3390/computers2020088
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Morales J, 2013, PROCEEDINGS
   Nabian Mohsen., 2017, Journal_of_Information_Technology__Software Engineering, V7, P4
   Paul M, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-11
   Piotto N, 2010, OBJECT TRAJECTORY AN, DOI [10. 1007/978-3-642-12900-1_1, DOI 10.1007/978-3-642-12900-1_1]
   Tomasi C., 2012, Computer Vision Sampler, P1, DOI DOI 10.1109/CVPR.2005.177
   Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246
   Vishwakarma DK, 2015, EXPERT SYST APPL, V42, P6957, DOI 10.1016/j.eswa.2015.04.039
   Yao B, 2015, SOFT COMPUT, V19, P499, DOI 10.1007/s00500-014-1270-4
   Yu G, 2011, IEEE T MULTIMEDIA, V13, P507, DOI 10.1109/TMM.2011.2128301
   Yuanyuan Huang, 2012, Proceedings of the 2012 International Conference on Computer Distributed Control and Intelligent Environmental Monitoring (CDCIEM 2012), P85, DOI 10.1109/CDCIEM.2012.27
   Zhang S, 2017, REV ARTICLE REV HUMA, V2017
   Zhao WL, 2013, IEEE T IMAGE PROCESS, V22, P980, DOI 10.1109/TIP.2012.2226043
NR 22
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20877
EP 20894
DI 10.1007/s11042-019-7392-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400015
DA 2024-07-18
ER

PT J
AU Li, TP
   Zhou, PP
   Liu, H
AF Li, Tianping
   Zhou, Pingping
   Liu, Hui
TI Multiple features fusion based video face tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video face tracking; Particle filter (PF); Features fusion; Updating
   model; Template drift
ID PARTICLE FILTERS; VISUAL TRACKING; COLOR
AB With the development of monitoring equipment and artificial intelligence technology, video face tracking under the big data background has become an important research hot spot in the field of public security. In order to track robustly under the circumstances of illumination variation, background clutter, fast motion, partial occlusion and so on, this paper proposed an algorithm combining a multi-feature fusion in the frame of particle filter and an improved mechanism, which consists of three main steps. At first, the color and edge features of human face were extracted from the video sequence. Meanwhile, color histograms and edge orientation histograms (EOH) were used to describe the facial features and beneficial to improve the efficiency of calculation. Then we employed a self-adaptive features fusion strategy to calculate the particle weight, which can effectively enhance the reliability of face tracking. Moreover, in order to solve the computational efficiency problem caused by too many particles, we added the integral histogram method to simplify the calculation complexity. At last, the object model was updated between the current object model and the initial model for alleviating the model drifts. Experiments conducted on testing dataset show that this proposed approach can robustly track single face with the cases of complex backgrounds, such as similar skin color, illumination change and occlusion, and perform better than color-based and edge-based methods in terms of both quantitative metrics and visual quality.
C1 [Li, Tianping] Shandong Prov Key Lab Med Phys & Image Proc Techn, Jinan 250014, Shandong, Peoples R China.
   [Li, Tianping] Shandong Normal Univ, Dept Phys & Elect, Jinan 250014, Shandong, Peoples R China.
   [Zhou, Pingping] Yancheng Biol Engn Higher Vocat Technol Sch, Yancheng 224051, Jiangsu, Peoples R China.
   [Liu, Hui] Shandong Univ Finance & Econ, Dept Comp Sci & Technol, Jinan 250014, Shandong, Peoples R China.
   [Liu, Hui] Stanford Univ, Dept Radiat Oncol, Med Phys Div, Palo Alto, CA 94305 USA.
C3 Shandong Normal University; Shandong University of Finance & Economics;
   Stanford University
RP Liu, H (corresponding author), Shandong Univ Finance & Econ, Dept Comp Sci & Technol, Jinan 250014, Shandong, Peoples R China.; Liu, H (corresponding author), Stanford Univ, Dept Radiat Oncol, Med Phys Div, Palo Alto, CA 94305 USA.
EM liuhui78@stanford.edu
OI Liu, Hui/0000-0003-3911-7751
FU NSFC [61572286, 61472220]; NSFC Joint with Zhejiang Integration of
   Informatization and Industrializaiton [U1609218]; Fostering Project of
   Dominant Discipline a Talent Team of Shandong Province Higher Education
FX This work was supported in part by NSFC (61572286 and 61472220), NSFC
   Joint with Zhejiang Integration of Informatization and Industrializaiton
   under Key Project (U1609218), and the Fostering Project of Dominant
   Discipline a Talent Team of Shandong Province Higher Education.
CR Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bos R, 2002, IEEE T INSTRUM MEAS, V51, P1289, DOI 10.1109/TIM.2002.808031
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Dou JF, 2012, CHIN CONT DECIS CONF, P3626, DOI 10.1109/CCDC.2012.6244580
   Freeman H, 1990, ISOTROPIC 3 3 GRADIE, P376
   Gustafsson F, 2002, IEEE T SIGNAL PROCES, V50, P425, DOI 10.1109/78.978396
   Jiang XD, 2016, MULTIMED TOOLS APPL, V75, P11801, DOI 10.1007/s11042-015-2659-5
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Lee J., 2011, P ICCSA 2011 INT C C, V32, P707
   Leng L, 2015, 2013 6 INT C IM SIGN, V70, P495
   Leng L., 2013, P 2013 6 INT C IM SI, V70, P495
   Li X, 2013, IEEE T IMAGE PROCESS, V22, P3028, DOI 10.1109/TIP.2013.2253478
   Li Y, 2018, PATTERN RECOGN, V75, P51, DOI 10.1016/j.patcog.2017.10.015
   Lin Y., 2018, P COMP VIS PATT REC
   Liu Y., 2016, P 25 INT JOINT C ART, V34, P44
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu L., 2010, P 2010 INT C INF COM, V34, P44
   Sadeghian A., 2017, P COMP VIS PATT REC
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   [王娟 Wang Juan], 2012, [光电工程, Opto-Electronic Engineering], V39, P32
   Wang JQ, 2008, IEEE T IMAGE PROCESS, V17, P235, DOI 10.1109/TIP.2007.914150
   Wang LF, 2014, IEEE T CIRC SYST VID, V24, P1132, DOI 10.1109/TCSVT.2014.2302496
   Welch G., 2017, INTRO KALMAN FILTER, V8, P127
   Yang DL, 2015, ADV INTELL SYST, V329, P257, DOI 10.1007/978-3-319-12286-1_26
   Yoon JH, 2015, IEEE WINT CONF APPL, P33, DOI 10.1109/WACV.2015.12
   Zhu WY, 2000, INT C PATT RECOG, P936, DOI 10.1109/ICPR.2000.905600
NR 26
TC 6
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21963
EP 21980
DI 10.1007/s11042-019-7414-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400062
DA 2024-07-18
ER

PT J
AU Niu, K
   Wang, H
AF Niu, Ke
   Wang, Han
TI Video highlight extraction via content-aware deep transfer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video retrieval; Video summarization; Highlight detection; Convolutional
   network
ID EGOCENTRIC VIDEO
AB In this paper, we focus on detecting highlights in online videos. Given the explosive growth of online videos, it is becoming increasingly important to single out those highlights for audiences instead of requiring them browsing every tedious part of the video. It is ideally that the contents of extracted highlights can be consistent with the topic of the video as well as the preference of the individual audience. To this end, this paper introduces a novel content-aware approach by formulating the highlights detection in a transfer learning framework. Under this framework. The experimental results on three different types of videos show that our content-aware highlight extraction method is particularly useful for online videos content fetching, e.g. showing the abstraction of the entire video while playing focus on the parts that matches the user queries.
C1 [Niu, Ke] Beijing Informat Sci & Technol Univ, Comp Sch, Beijing, Peoples R China.
   [Wang, Han] Beijing Forestry Univ, Sch Informat Sci & Technol, Beijing, Peoples R China.
C3 Beijing Information Science & Technology University; Beijing Forestry
   University
RP Wang, H (corresponding author), Beijing Forestry Univ, Sch Informat Sci & Technol, Beijing, Peoples R China.
EM niuke@bistu.edu.cn; wanghan@bjfu.edu.cn
FU Natural Science Foundation of China (NSFC) [61703046]
FX The research was supported in part by the Natural Science Foundation of
   China (NSFC) under Grant No. 61703046.
CR [Anonymous], 2018, 32 AAAI C ART INT
   [Anonymous], FDN TRENDS MACHINE L
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], IJCAI
   [Anonymous], 2017, PAC RIM C MULT
   [Anonymous], 2017, PACIFIC RIM S IMAGE
   [Anonymous], 2017, C COMP VIS PATT REC
   [Anonymous], MULTIMEDIA SYSTEMS
   [Anonymous], FACES LIGHTING PROBE
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], LEARNING DETECTION D
   [Anonymous], 2015, IEEE INT C COMP VIS
   [Anonymous], J IMAGE GRAPHICS
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], ACM MULT C
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Goldman DB, 2006, ACM T GRAPHIC, V25, P862, DOI 10.1145/1141911.1141967
   Gong BQ, 2014, ADV NEUR IN, V27
   Gygli M, 2016, PROC CVPR IEEE, P1001, DOI 10.1109/CVPR.2016.114
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Joshi N, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766954
   Laganiere R, 2008, P ACM TRECVID VID SU, P144
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu TC, 2002, LECT NOTES COMPUT SC, V2353, P403
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Sharghi A, 2017, PROC CVPR IEEE, P2127, DOI 10.1109/CVPR.2017.229
   Sharghi A, 2016, LECT NOTES COMPUT SC, V9912, P3, DOI 10.1007/978-3-319-46484-8_1
   Song JK, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2737
   Sun M, 2017, IEEE T IMAGE PROCESS, V26, P3303, DOI 10.1109/TIP.2017.2666039
   Sun M, 2014, LECT NOTES COMPUT SC, V8689, P787, DOI 10.1007/978-3-319-10590-1_51
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Vasudevan AB, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P582, DOI 10.1145/3123266.3123297
   Xiong B, 2014, LECT NOTES COMPUT SC, V8693, P282, DOI 10.1007/978-3-319-10602-1_19
   Yao T, 2016, PROC CVPR IEEE, P982, DOI 10.1109/CVPR.2016.112
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
NR 41
TC 3
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21133
EP 21144
DI 10.1007/s11042-019-7442-6
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400026
DA 2024-07-18
ER

PT J
AU Tang, W
   Wo, Y
   Han, GQ
AF Tang, Wu
   Wo, Yan
   Han, Guoqiang
TI Geometrically robust video hashing based on ST-PCT for video copy
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video hashing; Video copy detection; Spatial-temporal polar cosine
   transform; Geometric invariant
ID STATISTICAL IMAGE FEATURES
AB Copy videos flooding in the network infringe the video copyright and heavy the storage pressure on the video services server, which raises a huge demand for video copy detection techniques that can accurately and quickly detect the copies of video from huge video database. This paper aims to generate a video hash which has not only high discrimination but also robustness against geometrical and spatial-temporal transformations. First, we propose Spatial-Temporal Polar Cosine Transform (ST-PCT), which considers a video as a three-dimensional matrix and performs two-dimensional Polar Cosine Transforms (PCT) after performing a one-dimensional Discrete Cosine Transform (DCT) on video. This transformation can extract features of the spatial-temporal domain and has geometric invariance. Then, based on ST-PCT, we propose a geometrically robust video hashing method for video copy detection. The video features generated by ST-PCT are compressed and quantified to a compact binary hash code. Experimental results show that compared with the state-of-the-art methods, the proposed method has better robustness, higher accuracy, and faster calculation speed.
C1 [Tang, Wu; Wo, Yan; Han, Guoqiang] South China Univ Technol, Coll Comp Sci & Engn, Guangzhou 510641, Guangdong, Peoples R China.
C3 South China University of Technology
RP Wo, Y (corresponding author), South China Univ Technol, Coll Comp Sci & Engn, Guangzhou 510641, Guangdong, Peoples R China.
EM woyan@scut.edu.cn
FU National Natural Science Foundation of Guangdong [2016A030313472,
   2017A030312008, 2018A030313994]; National Natural Science Foundation of
   China [61472145]; Science and Technology Planning Project of Guangdong
   Province, China [2016B090918042, 2016B010127003]; Young creative talents
   project of Guangdong Provincial Education Department [2016KQNCX092]
FX The authors would like to thank Qiangjiang Wang, College of Computer
   Science and Engineering, South China University of Technology, for
   collecting data, participating in writing the manuscript and
   programming. We would also like to thank anonymous reviewers for their
   insightful suggestions. This work is supported by National Natural
   Science Foundation of Guangdong [Grant No. 2016A030313472,
   2017A030312008, 2018A030313994]; National Natural Science Foundation of
   China [Grant No. 61472145]; Science and Technology Planning Project of
   Guangdong Province, China [Grant No. 2016B090918042, 2016B010127003];
   Young creative talents project of Guangdong Provincial Education
   Department [Grant No. 2016KQNCX092].
CR [Anonymous], SIGN PROC INF TECHN
   [Anonymous], INT SYST SIGN PROC I
   [Anonymous], COMM INF COMP TECHN
   [Anonymous], P 6 ACM INT C IM VID
   [Anonymous], INT ENCY STAT SCI
   [Anonymous], VLDB
   [Anonymous], DIG SIGN PROC DSP 20
   [Anonymous], 2012 IEEE INTERNATIO
   [Anonymous], 2010 INT C PATT REC
   [Anonymous], GREEN COMP INT THING
   [Anonymous], COMP VIS PATT REC CV
   [Anonymous], SIGN PROC MULT APPL
   [Anonymous], 2015 INT C PERV COMP
   [Anonymous], INT C MULT MOD
   [Anonymous], MULT BIG DAT BIGTM 2
   [Anonymous], 2012, CoRR
   [Anonymous], AUT LOG ICAL 2010 IE
   Boukhari A, 2016, J VIS COMMUN IMAGE R, V34, P50, DOI 10.1016/j.jvcir.2015.10.015
   Chen HC, 2018, MULTIMED TOOLS APPL, V77, P5303, DOI 10.1007/s11042-017-4434-2
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   Dyana A, 2009, PATTERN RECOGN LETT, V30, P877, DOI 10.1016/j.patrec.2009.04.003
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Himeur Y, 2018, MULTIMED TOOLS APPL, V77, P17309, DOI 10.1007/s11042-017-5307-4
   Hu YC, 2018, J VIS COMMUN IMAGE R, V55, P21, DOI 10.1016/j.jvcir.2018.05.013
   Guzman-Zavaleta ZJ, 2017, MULTIMED TOOLS APPL, V76, P24143, DOI 10.1007/s11042-016-4168-6
   Jin ZM, 2014, IEEE T CYBERNETICS, V44, P1362, DOI 10.1109/TCYB.2013.2283497
   Kim S, 2014, SIGNAL PROCESS-IMAGE, V29, P788, DOI 10.1016/j.image.2014.05.002
   Lee S, 2008, IEEE T CIRC SYST VID, V18, P983, DOI 10.1109/TCSVT.2008.920739
   Li J, 2018, MULTIMED TOOLS APPL, P1
   Liu H, 2013, IEEE T KNOWL DATA EN, V25, P1706, DOI 10.1109/TKDE.2012.92
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Nie XS, 2017, IEEE INT CONF MULTI
   Su PC, 2017, MULTIMED TOOLS APPL, V76, P1331, DOI 10.1007/s11042-015-3132-1
   Weiss Yair., 2009, NIPS
   Wo Yan, 2012, Journal of South China University of Technology, V40, P23, DOI 10.3969/j.issn.1000-565X.2012.04.004
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
NR 38
TC 6
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21999
EP 22022
DI 10.1007/s11042-019-7513-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400064
DA 2024-07-18
ER

PT J
AU Ustubioglu, A
   Ulutas, G
   Ustubioglu, B
AF Ustubioglu, Arda
   Ulutas, Guzin
   Ustubioglu, Beste
TI IWT-MDE based reversible thermal image watermarking enhanced with secret
   sharing mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thermal medical image watermarking; Tamper localization; Reversible
   watermarking
ID REGION; SCHEME; RECOVERY; SECURITY
AB Telemedicine systems are used to transfer medical images between hospitals and doctors for consultation in many countries recently. It is crucial to ensure integrity of medical images transferred on unencrypted channels. Many medical image watermarking techniques have been proposed in the literature to deal with this problem. Thermal imaging to detect dense vascular regions is a new medical imaging modality gaining popularity to enhance diagnosis of breast cancer. Thermal images with large smooth areas and Region of Interest (ROI) have different characteristics compared to traditional medical images and require new image watermarking methods. A new thermal image watermarking algorithm utilizing Integer Wavelet Transform (IWT), Modified Difference Expansion (MDE) and Shamir's Secret Sharing Scheme (SSSS) has been proposed for e-healthcare applications in this paper. IWT coefficients of thermal image are expanded by the MDE to make more consecutive blocks expandable. Location Map (LM) becomes more compressible if there are many consecutive blocks. Thus, larger ROI can be watermarked by the proposed method. The method also uses SSSS to share LM into meaningless shares embedded into border regions. Sharing LM by the SSSS makes it possible to reconstruct it even if some of the thermal image borders are removed inadvertently or modified on purpose to break the watermark. Experimental results indicate that the proposed method has better embedding capacity and good imperceptibility compared to similar methods reported in the literature. Besides, it has expanded ROI size and also is the first method which considers border region attacks in medical image watermarking.
C1 [Ustubioglu, Arda; Ulutas, Guzin; Ustubioglu, Beste] Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
C3 Karadeniz Technical University
RP Ustubioglu, A (corresponding author), Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
EM ardaustubioglu@ktu.edu.tr; guzin@ieee.com; bustubioglu@ktu.edu.tr
RI Ulutas, Guzin/ABI-4484-2020; ÜSTÜBİOĞLU, Arda/AAK-4472-2021; USTUBIOGLU,
   Beste/AAJ-8187-2021
CR Al-Haj A, 2014, J DIGIT IMAGING, V27, P737, DOI 10.1007/s10278-014-9709-9
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], DIG IM COMP TECHN AP
   [Anonymous], 2010, P INT C BIOM ENG COM
   Das S, 2013, COMPUT METH PROG BIO, V111, P662, DOI 10.1016/j.cmpb.2013.05.027
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Deng XH, 2013, J NANOSCI NANOTECHNO, V13, P2099, DOI 10.1166/jnn.2013.6872
   Eswaraiah R, 2014, INT J TELEMED APPL, V2014, DOI 10.1155/2014/984646
   Eswaraiah R, 2015, IET IMAGE PROCESS, V9, P615, DOI 10.1049/iet-ipr.2014.0986
   Guo XT, 2009, J DIGIT IMAGING, V22, P53, DOI 10.1007/s10278-007-9043-6
   Huang LY, 2014, J COMPUT, V9, P2043, DOI 10.4304/jcp.9.9.2043-2049
   Liew SC, 2013, J DIGIT IMAGING, V26, P316, DOI 10.1007/s10278-012-9484-4
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Silva LF, 2014, J MED IMAG HEALTH IN, V4, P92, DOI 10.1166/jmihi.2014.1226
   Thabit R, 2015, MULTIMED TOOLS APPL, P1
   Ulutas M, 2011, J SYST SOFTWARE, V84, P341, DOI 10.1016/j.jss.2010.11.928
NR 19
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22269
EP 22299
DI 10.1007/s11042-019-7529-0
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400005
DA 2024-07-18
ER

PT J
AU Zhang, DP
   Wang, XF
   Zhang, M
   Hu, JJ
AF Zhang, Depeng
   Wang, Xiaofeng
   Zhang, Meng
   Hu, Jiaojiao
TI Image splicing localization using noise distribution characteristic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image splicing detection; Image splicing localization; Simple linear
   iterative clustering; Noise distribution characteristic; Fuzzy c-means
   clustering
ID FORENSICS
AB Image splicing/compositing is common content tampering operation. In this work, we devote to improve the detection accuracy of the splicing/compositing attack for image, and propose an effective image splicing localization method based on the noise distribution characteristic in image. Firstly, the test image is divided into non-overlapping blocks by using an improved simple linear iterative clustering (SLIC) algorithm. Then block-wise local noise level estimation and noise distribution characteristic estimation are performed to generate distinguishing features. Utilizing the fact that image regions from different sources tend to have larger inter-class difference, the fuzzy c-means clustering is used to identify spliced regions. Compared to existing noise-based image splicing detection methods, experimental results on different datasets have shown that the proposed method has superior performance, especially when the noise difference between the spliced region and the original region is small. Moreover, the proposed method is robust for content-preserving manipulations.
C1 [Zhang, Depeng; Wang, Xiaofeng; Zhang, Meng; Hu, Jiaojiao] Xian Univ Technol, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Wang, XF (corresponding author), Xian Univ Technol, Xian 710048, Shaanxi, Peoples R China.
EM xfwang@xaut.edu.cn
FU National Major Research and Development Plan Program of China
   [2016YFB1001004]; National Natural Science Foundation of China
   [61772416, 91646108]; Shaanxi province technology innovation guiding
   fund project [2018XNCG-G-02]
FX This work was supported by the National Major Research and Development
   Plan Program of China under Grant No. 2016YFB1001004; the National
   Natural Science Foundation of China under Grant No. 61772416 and No.
   91646108; Shaanxi province technology innovation guiding fund project,
   No. 2018XNCG-G-02. The foundation of the State Key Laboratory of
   Astronautic Dynamics.
CR Al-Hammadi MH, 2013, LECT NOTES COMPUT SC, V8034, P503, DOI 10.1007/978-3-642-41939-3_49
   Alahmadi AA, 2013, IEEE GLOB CONF SIG, P253, DOI 10.1109/GlobalSIP.2013.6736863
   [Anonymous], 2012, J MATH IMAG VIS
   [Anonymous], COMPUTER SCI
   [Anonymous], ADV INFORM TECHNOLOG
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], 2017, INT C IM AN PROC
   [Anonymous], 2018, MIGRATION ENRICHMENT
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], P INT C IM PROC CAIR
   [Anonymous], P INT C COMM SIGN PR
   [Anonymous], J VISUAL COMMUNICATI
   [Anonymous], 1986, Curve and Surface Fitting: An Introduction
   [Anonymous], P IEEE INT WORKSH IN
   [Anonymous], P ACM MULT SEC WORKS
   [Anonymous], P INT C IM PROC HONG
   [Anonymous], P 2006 IEEE INT C MU
   [Anonymous], 2014 IEEE 11 INT C
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Cao G., 2010, Journal of Information Hiding and Multimedia Signal Processing, V1, P20
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   COLUMBIA DVMM RESEARCH LAB, 2004, COL IM SPLIC DET EV
   Fang Z, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P20, DOI 10.1109/MINES.2009.208
   Hsu YF, 2010, IEEE T INF FOREN SEC, V5, P816, DOI 10.1109/TIFS.2010.2077628
   Iakovidou C, 2018, J VIS COMMUN IMAGE R, V54, P155, DOI 10.1016/j.jvcir.2018.05.011
   Johnson M.K., 2005, Proceedings of the 7th Workshop on Multimedia and Security, P1
   Lakhani G, 2008, IEEE T IMAGE PROCESS, V17, P427, DOI 10.1109/TIP.2007.915560
   Liu QG, 2011, IEEE T INF FOREN SEC, V6, P1111, DOI 10.1109/TIFS.2011.2139209
   Liu XH, 2014, IEEE T IMAGE PROCESS, V23, P4361, DOI 10.1109/TIP.2014.2347204
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Pun CM, 2016, J VIS COMMUN IMAGE R, V38, P195, DOI 10.1016/j.jvcir.2016.03.005
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   Salloum Ronald., 2017, Image splicing localization using a multi-task fully convolutional network (mfcn)
   Shah A, 2018, PROCEEDINGS 2018 INTERNATIONAL CONFERENCE ON COMPUTING SCIENCES AND ENGINEERING (ICCSE)
   Wang P, 2018, J VIS COMMUN IMAGE R, V55, P80, DOI 10.1016/j.jvcir.2018.05.020
   Wattanachote K, 2015, IEEE T INF FOREN SEC, V10, P2477, DOI 10.1109/TIFS.2015.2464776
   Yao H, 2017, MULTIMED TOOLS APPL, V76, P12457, DOI 10.1007/s11042-016-3660-3
   Zhang QB, 2018, MULTIMED TOOLS APPL, V77, P31239, DOI 10.1007/s11042-018-6230-z
   Zhang W, 2010, IEEE T INF FOREN SEC, V5, P544, DOI 10.1109/TIFS.2010.2051666
   Zhang W, 2009, IEEE INT CON MULTI, P1042, DOI 10.1109/ICME.2009.5202676
   Zhao XD, 2011, LECT NOTES COMPUT SC, V6526, P12, DOI 10.1007/978-3-642-18405-5_2
NR 44
TC 9
Z9 11
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22223
EP 22247
DI 10.1007/s11042-019-7408-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400003
DA 2024-07-18
ER

PT J
AU Biswas, R
   Mukherjee, I
   Bandyopadhyay, SK
AF Biswas, Rajib
   Mukherjee, Imon
   Bandyopadhyay, Samir Kumar
TI Image feature based high capacity steganographic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; Data hiding; Information hiding; Path trace
ID SUBSTITUTION
AB Steganography is the growing field of research, where hiding techniques are used to secure the communicative elements (e.g., images). In this paper, the message is hidden in the color image in spatial domain, exploring multi-bit Least Significant Bit (mLSB) steganography. Path trace, based on eccentricity of pixels gives the potential pixels to capacitate more hiding scope. Perspective based technique and meticulous statistical analysis are applied to immune the algorithm from sterilization along with other attacks. The algorithm overcome different tests done by benchmark like StirMark Benchmark 4.0, Receiver Operating Characteristic (ROC) curve. Visual Steganalysis and statistical tools like Dual Statistical Method and Histogram Difference are used to test the security and imperceptibility.The algorithm also ensures security with insignificant visual disturbance/distortion. Capacity per pixel after embedding, ranges from 9-bits to 12-bits and the minimum capacity per color per pixel is 2.37 and maximum is 2.69. The time complexity of the proposed algorithm is O(n(2)). The robustness is increased by unpredictable selection of bit for embedding.
C1 [Biswas, Rajib] Heritage Inst Technol, Dept Informat Technol, Kolkata 700107, India.
   [Mukherjee, Imon] Indian Inst Informat Technol, Comp Sci & Engn, Kalyani 741235, W Bengal, India.
   [Bandyopadhyay, Samir Kumar] Calcutta Univ, Comp Sci & Engn, Kolkata 700098, India.
C3 Heritage Institute of Technology (HITK); University of Calcutta
RP Mukherjee, I (corresponding author), Indian Inst Informat Technol, Comp Sci & Engn, Kalyani 741235, W Bengal, India.
EM rajib.biswas.rd@gmail.com; imon@iiitkalyani.ac.in; 1954samir@gmail.com
RI Bandyopadhyay, Samir Kumar/AAR-8919-2020; Mukherjee, Imon/AFP-2409-2022;
   Biswas, Rajib/H-3561-2013
OI Bandyopadhyay, Samir Kumar/0000-0002-4868-3459; Mukherjee,
   Imon/0000-0002-8598-148X; 
CR [Anonymous], 2017, P 5 ACM WORKSH INF H
   [Anonymous], 2016, 4 ACMWORKSHOP INFORM
   [Anonymous], MEDIA WATERMARKING S
   [Anonymous], INT J SIGNAL PROCESS
   Chandramouli R., 2003, International Workshop on Digital Watermarking, P35
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Das S, 2018, PATTERN RECOGNITION
   Datta B, 2018, MULTIMEDIA TOOLS APP
   Dumitrescu S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P641, DOI 10.1109/ICIP.2002.1039052
   Dumitrescu S, 2003, LECT NOTES COMPUT SC, V2578, P355
   Fan Jerome, 2006, CJEM, V8, P19
   Feng BW, 2015, IEEE T INF FOREN SEC, V10, P243, DOI 10.1109/TIFS.2014.2368364
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Ge S, 2007, ACM SIGKDD WORKSH DO
   He JH, 2017, MULTIMED TOOLS APPL, V76, P7677, DOI 10.1007/s11042-016-3429-8
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Ioannidou A, 2012, EXPERT SYST APPL, V39, P11517, DOI 10.1016/j.eswa.2012.02.106
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Johnson NF, 1998, 1998 IEEE INFORMATION TECHNOLOGY CONFERENCE, PROCEEDINGS, P113, DOI 10.1109/IT.1998.713394
   Johnson NF, 1998, LECT NOTES COMPUT SC, V1525, P273
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Kim C, 2014, MULTIMED TOOLS APPL, V69, P569, DOI 10.1007/s11042-012-1114-0
   Kim C, 2011, COMM COM INF SC, V186, P130
   Lee CF, 2008, IMAGE VISION COMPUT, V26, P1670, DOI 10.1016/j.imavis.2008.05.005
   Li XL, 2009, IEEE SIGNAL PROC LET, V16, P69, DOI 10.1109/LSP.2008.2008947
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2012, FUND INFORM, V118, P281, DOI 10.3233/FI-2012-714
   Lin CC, 2011, COMPUT STAND INTER, V33, P477, DOI 10.1016/j.csi.2011.02.003
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Mukherjee N, 2018, MULTIMED TOOLS APPL, V77, P18451, DOI 10.1007/s11042-018-5720-3
   Paul G, 2017, MULTIMED TOOLS APPL, V76, P7445, DOI 10.1007/s11042-016-3319-0
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Pradhan A, 2016, 2016 INTERNATIONAL CONFERENCE ON RESEARCH ADVANCES IN INTEGRATED NAVIGATION SYSTEMS (RAINS)
   Provos N, 2001, P 10 USENIX SEC S ST
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yang CY, 2015, ADV INTELL SYST COMP, V329, P145, DOI 10.1007/978-3-319-12286-1_15
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   [No title captured]
NR 44
TC 7
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20019
EP 20036
DI 10.1007/s11042-019-7369-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800050
DA 2024-07-18
ER

PT J
AU Fan, WQ
   Sun, GL
   Su, YY
   Liu, Z
   Lu, XF
AF Fan, Weiqi
   Sun, Guangling
   Su, Yuying
   Liu, Zhi
   Lu, Xiaofeng
TI Integration of statistical detector and Gaussian noise injection
   detector for adversarial example detection in deep neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural networks; Adversarial examples; Integrated detection;
   Statistical detector; Gaussian noise injection detector
AB Deep Neural Networks (DNN) has achieved a great success in many tasks in recent years. However, researchers found that DNN is vulnerable to adversarial examples that are maliciously perturbed inputs. The elaborately designed adversarial perturbations can easily confuse the model whereas have no impacts on human perception. To counter adversarial examples, we propose an integrated detection framework for detecting adversarial examples, which involves statistical detector and Gaussian noise injection detector. The statistical detector extracts Subtractive Pixel Adjacency Matrix (SPAM) and uses the second order Markov transition probability matrix to model SPAM so as to highlight the statistical anomaly hidden in an adversarial input. Then an ensemble classifier using SPAM based feature is applied to detect the adversarial input containing large perturbation. The Gaussian noise injection detector first injects an additive Gaussian noise into the input, and then feeds both the original input and its Gaussian noise injected counterpart into a targeted network. By comparing the two outputs difference, the detector is applied to detect adversarial input containing small perturbation: if the difference exceeds a threshold, the input is adversarial; otherwise legitimate. The two detectors are adaptive to different characteristics of adversarial perturbation so that the proposed detection framework is capable of detecting multiple types of adversarial examples. In our work, we test six categories of adversarial examples produced by Fast Gradient Sign Method (FGSM, untargeted), Randomized Fast Gradient Sign Method (R-FGSM, untargeted), Basic Iterative Method (BIM, untargeted), DeepFool (untargeted), Carlini&Wagner Method (CW_UT, untargeted) and CW_T(targeted). Comprehensive empirical results show that the proposed detection framework has achieved a promising performance on ImageNet database.
C1 [Fan, Weiqi; Sun, Guangling; Su, Yuying; Liu, Zhi; Lu, Xiaofeng] Shanghai Univ, Commun & Informat Engn Sch, Shanghai 200444, Peoples R China.
C3 Shanghai University
RP Sun, GL (corresponding author), Shanghai Univ, Commun & Informat Engn Sch, Shanghai 200444, Peoples R China.
EM sunguangling@shu.edu.cn
RI LIU, Zhi/D-4518-2012
OI LIU, Zhi/0000-0002-8428-1131; Sun, Guangling/0000-0001-6440-8513
FU Shanghai Municipal Natural Science Foundation [16ZR1411100]; National
   Natural Science Foundation of China [61771301]
FX This work was supported by Shanghai Municipal Natural Science Foundation
   under Grant No. 16ZR1411100 and the National Natural Science Foundation
   of China under Grant No. 61771301.
CR [Anonymous], 2018, ARXIV180510652
   [Anonymous], NETW DISTR SYST SEC
   [Anonymous], 2017, INT C LEARN REPR ICL
   [Anonymous], 2017, INT C LEARN REPR ICL
   [Anonymous], 2016, TECHNICAL REPORT CLE
   [Anonymous], 2018, IEEE C COMP VIS PATT
   [Anonymous], P IEEE S SECUR PRIV
   Das Nilaksh, 2017, Keeping the bad guys out: Protecting and vaccinating deep learning with jpeg compression
   Dean J., 2015, NIPS DEEP LEARNING R
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dziugaite Gintare Karolina, 2016, CoRR
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Grosse K., 2017, ARXIV
   Gryllias KC, 2012, ENG APPL ARTIF INTEL, V25, P326, DOI 10.1016/j.engappai.2011.09.010
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li X, 2017, IEEE I CONF COMP VIS, P5775, DOI 10.1109/ICCV.2017.615
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu JJ, 2017, IEEE I CONF COMP VIS, P446, DOI 10.1109/ICCV.2017.56
   Madry A., 2018, ARXIV
   Meng DY, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P135, DOI 10.1145/3133956.3134057
   Miyato T., 2016, stat, V1050, P7
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Papernot N., 2016, SOK SCI SECURITY PRI, P1
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sharif M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1528, DOI 10.1145/2976749.2978392
   Shen S., 2017, arXiv
   Szegedy C., 2014, PROC INT C LEARNING
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tramer Florian, 2018, INT C LEARN REPR ICL
   Xie C., 2018, P 6 INT C LEARNING R
NR 34
TC 12
Z9 14
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20409
EP 20429
DI 10.1007/s11042-019-7353-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800066
DA 2024-07-18
ER

PT J
AU Xie, XZ
   Chang, CC
   Lin, CC
   Lin, JL
AF Xie, Xiao-Zhu
   Chang, Chin-Chen
   Lin, Chia-Chen
   Lin, Jia-Long
TI A Turtle Shell based RDH scheme with two-dimensional histogram shifting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Turtle shell; Reversible data hiding; Histogram shifting; High capacity
ID IMAGE AUTHENTICATION; DIFFERENCE EXPANSION; FRAMEWORK
AB A turtle shell (TS) based reversible data hiding (RDH) scheme with two-dimensional histogram shifting (HS) is proposed. The proposed scheme extends the embeddable set from a peak point in HS scheme to a two-dimensional region, so as to improve the embedding capacity (EC). Firstly, a threshold T is used to divide the pixel-pairs into three groups: left-shifting set without embedding (LSS), right-shifting set without embedding (RSS), and embeddable set (ES). Secondly, pixel-pairs in sets LSS and RSS are shifted outward to vacate room for embedding. Lastly, secret data are embedded into pixel-pairs in set ES. After that, the embedded data can be extracted accurately and the cover image can be recovered losslessly. Furthermore, various requirements of EC can be obtained by adjusting the threshold T. Experimental results verify that this paper can achieve a higher EC than the existing pairwise based schemes while maintaining an acceptable image quality.
C1 [Xie, Xiao-Zhu] Xiamen Univ Technol, Engn Res Ctr Software Testing & Evaluat Fujian Pr, Xiamen 361024, Fujian, Peoples R China.
   [Xie, Xiao-Zhu; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Lin, Chia-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung 43301, Taiwan.
   [Lin, Jia-Long] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
C3 Xiamen University of Technology; Feng Chia University; Providence
   University - Taiwan; Feng Chia University
RP Lin, CC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, Taichung 43301, Taiwan.
EM xz4xxz@gmail.com; ally.cclin@gmail.com; ally.cclin@gmail.com;
   komicabot@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
OI Lin, Chia-Chen/0000-0003-4480-7351
FU Natural Science Foundation of P. R. China [61503316]; Natural Science
   Foundation of Fujian Province [2018J01572]; Open Fund of Engineering
   Research Center for Software Testing and Evaluation of Fujian Province
FX This work is supported by Natural Science Foundation of P. R. China
   under Grant 61503316, Natural Science Foundation of Fujian Province
   under Grant 2018J01572 and Open Fund of Engineering Research Center for
   Software Testing and Evaluation of Fujian Province.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 2018, J INTERNET DISTRIB S
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Cao F, 2019, MULTIMED TOOLS APPL, V78, P7911, DOI 10.1007/s11042-018-6031-4
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Chang C.-C., 2008, 2008 3 INT C INN COM, P17, DOI 10.1109/ICICIC.2008.149
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P89, DOI 10.1109/IIH-MSP.2014.29
   Chen S, 2017, ADV MULTIMED, V2017, DOI 10.1155/2017/6359248
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   He W, 2019, IEEE T CONTR SYST T, V27, P790, DOI 10.1109/TCST.2017.2780055
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hsiao JY, 2017, J INF SCI ENG, V33, P289
   Ker AD, 2004, LECT NOTES COMPUT SC, V3200, P97
   Kim HJ, 2010, COMPUT MATH APPL, V60, P319, DOI 10.1016/j.camwa.2010.01.006
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Kim PH, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY - NEW GENERATIONS, P668, DOI 10.1109/ITNG.2015.112
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Lin CC, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P8, DOI 10.1109/CISP.2008.64
   Liu L, 2017, MULTIMED TOOLS APPL, V76, P12233, DOI 10.1007/s11042-016-3624-7
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang ZH, 2013, J SYST SOFTWARE, V86, P315, DOI 10.1016/j.jss.2012.08.029
   Yan YX, 2009, I W IMAG SYST TECHNI, P179, DOI 10.1109/IST.2009.5071628
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 30
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19413
EP 19436
DI 10.1007/s11042-018-7098-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800022
DA 2024-07-18
ER

PT J
AU Duseja, T
   Deshmukh, M
AF Duseja, Tejas
   Deshmukh, Maroti
TI Image compression and encryption using chinese remainder theorem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compression; Chinese remainder theorem; Extended Euclidean algorithm;
   Prime numbers; Security
AB The proposed encryption technique uses Chinese Remainder Theorem (CRT) and hash map to generate and distribute secret co-prime keys to participants. It utilizes the fact that CRT gives a unique solution for the set of congruent equations if and only if the modulus values are relatively co-prime to each other i.e., Greatest Common Divisor (GCD) of moduli is equal to 1. In this paper, we have proposed secret image sharing scheme using CRT and obtained results on grayscale images of different dimensions. The proposed technique not only increases randomness in encrypted image but also compresses the image, resulting in easy storage and fast transmission. As compression ratio is dependent on shared keys, all shared keys are essential for recovering image without any noise, absence of any key gives an image which is deviated from our original image. For r participants, r pixels are encrypted and compressed simultaneously at a time using CRT which gives one encrypted unique value corresponding to those r pixels. As this encrypted value can be greater than 255, hash map is used to store this value. The experimental results show that the encrypted image is compressed, is not disclosing any secret information and recovery of original image is loss-less.
C1 [Duseja, Tejas; Deshmukh, Maroti] Natl Inst Technol, Srinagar, Jammu & Kashmir, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Srinagar
RP Duseja, T (corresponding author), Natl Inst Technol, Srinagar, Jammu & Kashmir, India.
EM tejasduseja007@gmail.com; marotideshmukh@nituk.ac.in
RI Deshmukh, Dr. Maroti/AAE-2889-2022
OI Deshmukh, Maroti/0000-0002-1125-5987
CR Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Deshmukh M, 2016, 2016 IEEE 30 INT C A
   Deshmukh M, 2017, P INT C COMP VIS IM
   Deshmukh M, 2016, INT C INF SYST SEC
   Deshmukh M, 2018, MULTIMED TOOLS APPL, V77, P89, DOI 10.1007/s11042-016-4229-x
   Deshmukh M, 2017, J VIS COMMUN IMAGE R, V49, P291, DOI 10.1016/j.jvcir.2017.09.013
   Huang R, 2011, 7 INT C INT INF HID
   Liu Y, 2016, ACTION2ACTIVIY RECOG
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lyu W.L., 2015, J. Inf. Hiding Multimed. Signal Process., V6, P523
   Maniccam SS, 2001, PATTERN RECOGN, V34, P1229, DOI 10.1016/S0031-3203(00)00062-5
   Mao Q, 2016, J INFORM HIDING MULT, V34, P1229
   Orsdemir A, 2008, IEEE MILIT COMMUN C, P1040
   Preotiuc-Pietro D, BINARY LABELS POLITI
   Rajput M, 2016, PROCEDIA COMPUT SCI, V89, P677, DOI 10.1016/j.procs.2016.06.034
   Seeger J, 2018, 2018 GLOBAL INTERNET OF THINGS SUMMIT (GIOTS), P1
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shivani S, 2018, MULTIMED TOOLS APPL, V77, P6287, DOI 10.1007/s11042-017-4536-x
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Zhang M, 2017, OPT LASER ENG, V90, P254, DOI 10.1016/j.optlaseng.2016.10.025
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 23
TC 13
Z9 13
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16727
EP 16753
DI 10.1007/s11042-018-7023-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500044
DA 2024-07-18
ER

PT J
AU Han, L
   Li, D
   Liu, SN
   Liu, YN
   Tang, D
AF Han, Li
   Li, Dan
   Liu, Shu Ning
   Liu, Yu Nan
   Tang, Di
TI Similarity estimation based on sparse spectral correspondence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape analysis; Shape correspondence; Spectral eigenmap; Non-rigid
   shape; Sparse representation
ID SHAPE; SEGMENTATION; REGISTRATION; SYMMETRIES; FRAMEWORK
AB We present a sparse spectral correspondence method for deformable shape analysis. Our method exploits randomized sampling for sparse shape representation. By choosing a random subset of points that preserve key properties of the entire data set, it allows one to run algorithms efficiently on a small sample. First we implement random row sampling of an undirected weighted graph matrix by "Lewis weights", which can be viewed as statistical leverage scores of a reweighted matrix and used directly as sampling probabilities. Second, a sparse graph is constructed on selected sample points by using minimum spanning tree (MST). We then discover the meaningful structural correspondence based on TPS (thin-plate spline) approach in the spectral embedded space. Finally we show how we use the sparse spectral correspondence to implement similarity estimation for shape matching and classification for different topological shapes. A series of experimental results demonstrate that our method is accurate and robust for shape analysis.
C1 [Han, Li; Li, Dan; Liu, Shu Ning; Liu, Yu Nan; Tang, Di] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian, Peoples R China.
C3 Liaoning Normal University
RP Han, L (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian, Peoples R China.
EM hl_dlls@dl.cn
RI Liu, Yunan/JGM-3801-2023
OI Han, Li/0000-0002-0975-9908
FU NSFC [61702246]; CSC [201608210289]; Education project of Liaoning
   Province [2018lsktyb-084]
FX We would like to express our gratitude to the anonymous reviewers for
   their helpful comments. The research presented in this paper is
   supported by a grant from NSFC (61702246), fund of CSC (201608210289)
   and an Education. project of Liaoning Province (2018lsktyb-084). We are
   also highly thankful to Hong Kai Zhao, the Professor of department of
   Mathematics, University of California Irvine, for inspiring guidance of
   derivation of mathematic formulas. We sincerely appreciate Qiao Long
   Huang, the PhD student of IMSS, Chinese Academic of Sciences who helped
   us to verify the feasibility of our sampling algorithm, and Rui Xiang,
   the PhD student of department of Mathematics, University of California
   Irvine for his effort in analyzing the shape matching results.
CR Aflalo Y, 2016, INT J COMPUT VISION, V118, P380, DOI 10.1007/s11263-016-0883-8
   Aflalo Y, 2015, SIAM J IMAGING SCI, V8, P1141, DOI 10.1137/140977680
   Anguelov Dragomir., 2004, NIPS, P33
   [Anonymous], WORKSH NONR SHAP AN
   [Anonymous], INT S 3D DAT PROC VI
   [Anonymous], P IEEE C COMP VIS PA
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bremer P.-T., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), P47, DOI 10.1109/PBG.2005.194063
   Bridson R., 2007, Fast Poisson disk sampling in arbitrary dimensions, V10, P1, DOI DOI 10.1145/1278780.1278807
   Bronstein AM, 2010, INT J COMPUT VISION, V89, P266, DOI 10.1007/s11263-009-0301-6
   Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Clarkson KL, 2013, STOC'13: PROCEEDINGS OF THE 2013 ACM SYMPOSIUM ON THEORY OF COMPUTING, P81
   Cohen MB, 2014, ABS14120588 CORR
   Cohen MB, 2014, ABS14085099 CORR
   Drineas P, 2006, PROCEEDINGS OF THE SEVENTHEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1127, DOI 10.1145/1109557.1109682
   Drineas Petros., 2012, ICML
   Dunbar D, 2006, ACM T GRAPHIC, V25, P503, DOI 10.1145/1141911.1141915
   Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Golovinskiy A, 2009, COMPUT GRAPH-UK, V33, P262, DOI 10.1016/j.cag.2009.03.010
   Hu JX, 2009, VISUAL COMPUT, V25, P667, DOI 10.1007/s00371-009-0340-6
   Jain Varun., 2007, INT J SHAPE MODELING, V13, P101, DOI DOI 10.1142/S0218654307000968
   Kim V, 2010, P EUR S GEOM PROC SG
   Lei HP, 2013, J COMPUT SCI TECH-CH, V28, P919, DOI 10.1007/s11390-013-1387-4
   LEWIS DR, 1978, STUD MATH, V63, P207, DOI 10.4064/sm-63-2-207-212
   Lipman Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778840
   Liu R, 2009, COMPUT GRAPH FORUM, V28, P397, DOI 10.1111/j.1467-8659.2009.01379.x
   Mémoli F, 2005, FOUND COMPUT MATH, V5, P313, DOI 10.1007/s10208-004-0145-y
   Ovsjanikov M, 2008, COMPUT GRAPH FORUM, V27, P1341, DOI 10.1111/j.1467-8659.2008.01273.x
   Raviv D, 2010, INT J COMPUT VISION, V89, P18, DOI 10.1007/s11263-010-0320-3
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Reuter M, 2010, INT J COMPUT VISION, V89, P287, DOI 10.1007/s11263-009-0278-1
   Rustamov Raif M, 2007, P S GEOM PROC, V257, P225
   Sahillioglu Y, 2013, COMPUT GRAPH FORUM, V32, P177, DOI 10.1111/cgf.12007
   Shalom S, 2008, PART ANALOGIES SETS
   Shapira L, 2008, VISUAL COMPUT, V24, P249, DOI 10.1007/s00371-007-0197-5
   Sharma A., 2010, P WORKSH NONR SHAP A
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tevs A, 2009, PROC CVPR IEEE, P1185, DOI 10.1109/CVPRW.2009.5206775
   Thorstensen N., 2009, P AS C COMP VIS, P1
   VAN KAICK O., 2011, COMPUT GRAPH FORUM, V30, P2
   van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P1681, DOI 10.1111/j.1467-8659.2011.01884.x
   van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P553, DOI 10.1111/j.1467-8659.2011.01893.x
   Wang S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2231816.2231818
   Yoshiyasu Y., 2014, P COMP VIS PATT REC
   Yoshiyasu Y, 2016, COMPUT GRAPH-UK, V60, P9, DOI 10.1016/j.cag.2016.07.002
   Zaharescu A., 2009, P IEEE C COMP VIS PA
   Zhang H, 2008, COMPUT GRAPH FORUM, V27, P1431, DOI 10.1111/j.1467-8659.2008.01283.x
   Zigelman G, 2002, IEEE T VIS COMPUT GR, V8, P198, DOI 10.1109/2945.998671
NR 50
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14443
EP 14463
DI 10.1007/s11042-018-6623-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700015
DA 2024-07-18
ER

PT J
AU Zhou, ZP
   Li, CY
   Zhao, XX
   Zhou, FZ
AF Zhou, Zhiping
   Li, Chunye
   Zhao, Xiaoxiao
   Zhou, Fangzheng
TI Collaborative hashing adopted in locality-constrained linear coding for
   scene classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Approximate nearest neighbor; Locality-constrained linear coding;
   Collaborative hashing
ID FEATURES
AB Scene classification methods based on effective feature extraction and coding have obtained promising results in recent years. But the K-nearest neighbor search strategy in Locality-constrained Linear Coding (LLC) increases the complexity of the algorithm due to the exhaustive search. To solve the problem, an improved approximate nearest neighbor search strategy is proposed to improve the computational efficiency of LLC. Considering the mapping relationship between the visual words and features, a collaborative hashing method is incorporated to transform the high dimensional features into binary code form, and the original Euclidean space is transformed into the Hamming space that consists of multi similar features. The similar visual words can be queried quickly. Then the nearest neighbors can be searched efficiently through Hamming distance ranking, which can improve the coding efficiency. The experimental results on standard datasets demonstrate the effectiveness of the proposed approach, and the average classification accuracy can be improved.
C1 [Zhou, Zhiping; Li, Chunye; Zhou, Fangzheng] Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Jiangsu, Peoples R China.
   [Zhou, Zhiping] Jiangnan Univ, Engn Res Ctr Internet Things Technol Applicat, Minist Educ, Wuxi 214122, Jiangsu, Peoples R China.
   [Zhao, Xiaoxiao] Tongji Univ, Coll Elect & Informat Engn, Shanghai 201804, Peoples R China.
C3 Jiangnan University; Jiangnan University; Tongji University
RP Zhou, ZP (corresponding author), Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Jiangsu, Peoples R China.; Zhou, ZP (corresponding author), Jiangnan Univ, Engn Res Ctr Internet Things Technol Applicat, Minist Educ, Wuxi 214122, Jiangsu, Peoples R China.
EM zzp@jiangnan.edu.cn; taoliluoying@163.com; zh_xiaoxiao10@163.com;
   6141918010@vip.jiangnan.edu.cn
OI Zhao, Xiaoxiao/0000-0003-3578-0089
CR Alimjan G, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418590127
   Andoni A, 2015, ADV NEUR IN, V28
   [Anonymous], 2009, P ADV NEUR INF PROC
   Chen JY, 2018, LECT NOTES COMPUT SC, V10705, P327, DOI 10.1007/978-3-319-73600-6_28
   Jin ZM, 2013, IEEE I CONF COMP VIS, P257, DOI 10.1109/ICCV.2013.39
   Kong W., 2012, P 26 AAAI C ART INT, P634, DOI DOI 10.5555/2900728.2900819
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Liu XL, 2014, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2014.275
   Liu XL, 2013, PROC CVPR IEEE, P1570, DOI 10.1109/CVPR.2013.206
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Min HQ, 2016, NEUROCOMPUTING, V171, P1486, DOI 10.1016/j.neucom.2015.07.084
   Moran S., 2013, Book Variable Bit Quantisation for LSH, P753
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Xie L, 2016, AAAI CONF ARTIF INTE, P294
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yu J, 2013, PATTERN RECOGN, V46, P483, DOI 10.1016/j.patcog.2012.08.006
   Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18
   Zhang H., 2006, 2006 IEEE COMP SOC C, V2, P2126, DOI DOI 10.1109/CVPR.2006.301
   Zhang ZW, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P183, DOI 10.1145/2600428.2609578
   Zhou H., 2012, P 18 ACM SIGKDD INT, P498
NR 25
TC 1
Z9 1
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16329
EP 16343
DI 10.1007/s11042-018-6978-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500027
DA 2024-07-18
ER

PT J
AU Li, J
   Luo, J
   Ding, JH
   Zhao, X
   Yang, XY
AF Li, Juan
   Luo, Jing
   Ding, Jianhang
   Zhao, Xi
   Yang, Xinyu
TI Regional classification of Chinese folk songs based on CRF model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music regional classification; Conditional random field; Restricted
   boltzmann machine; Temporal characteristics; Chinese folk songs
ID GENRE CLASSIFICATION; MUSIC
AB Music regional classification, which is an important branch of music automatic classification, aims at classifying folk songs according to different regional style. Chinese folk songs have developed various regional musical styles in the process of its evolution. Regional classification of Chinese folk songs can promote the development of music recommendation systems which recommending proper style of music to users and improve the efficiency of the music retrieval system. However, the accuracy of existing music regional classification systems is not high enough, because most methods do not consider temporal characteristics of music for both features extraction and classification. In this paper, we proposed an approach based on conditional random field (CRF) which can fully take advantage of the temporal characteristics of musical audio features for music regional classification. Considering the continuity, high dimensionality and large size of the audio feature data, we employed two ways to calculate the label sequence of musical audio features in CRF, which are Gaussian Mixture Model (GMM) and Restricted Boltzmann Machine (RBM). The experimental results demonstrated that the proposed method based on CRF-RBM outperforms other existing music regional classifiers with the best accuracy of 84.71% on Chinese folk songs datasets. Besides, when the proposed methods were applied to the Greek folk songs dataset, the CRF-RBM model also performs the best.
C1 [Li, Juan] Xi An Jiao Tong Univ, Ctr Mus Educ, 28 Xianning West Rd, Xian 710049, Shaanxi, Peoples R China.
   [Luo, Jing; Ding, Jianhang; Zhao, Xi; Yang, Xinyu] Xi An Jiao Tong Univ, Dept Comp Sci & Technol, 28 Xianning West Rd, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University
RP Yang, XY (corresponding author), Xi An Jiao Tong Univ, Dept Comp Sci & Technol, 28 Xianning West Rd, Xian 710049, Shaanxi, Peoples R China.
EM lijuan@mail.xjtu.edu.cn; luojingl@stu.xjtu.edu.cn;
   jh.ding@stu.xjtu.edu.cn; xi.zhao@mail.xjtu.edu.cn;
   yxyphd@mail.xjtu.edu.cn
RI Wang, Rong/JQI-7854-2023; Luo, Jing/JCO-6120-2023
OI Wang, Rong/0009-0009-5350-5743; Luo, Jing/0000-0001-7138-3705
CR [Anonymous], ISMIR
   [Anonymous], 2001, PROC 18 INT C MACH L
   Bassiou N, 2015, INT SYMP IMAGE SIG, P238, DOI 10.1109/ISPA.2015.7306065
   Byrd R. H., 2014, SIAM JOURNAL ON OPTI, V26, P1008
   CHOUZENOUX E, 1932, ACM TRANS MULTIMED C, V162, P107, DOI DOI 10.1007/S10957-013-0465-7
   Conklin D, 2013, J NEW MUSIC RES, V42, P19, DOI 10.1080/09298215.2013.776611
   Corrêa DC, 2016, EXPERT SYST APPL, V60, P190, DOI 10.1016/j.eswa.2016.04.008
   DU Y. X., 1993, CHIN MUSIC, V1, P14
   Fotiadou E, 2016, EUR SIGNAL PR CONF, P1133, DOI 10.1109/EUSIPCO.2016.7760425
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   HAN KH, 1989, ASIAN MUSIC, V20, P107
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang YF, 2014, DATA KNOWL ENG, V92, P60, DOI 10.1016/j.datak.2014.07.005
   Hui Song, 2011, Proceedings of the 2011 International Conference on Transportation and Mechanical & Electrical Engineering (TMEE), P2441, DOI 10.1109/TMEE.2011.6199715
   Kawase A, 2017, 2017 INTERNATIONAL CONFERENCE ON CULTURE AND COMPUTING (CULTURE AND COMPUTING), P170, DOI 10.1109/Culture.and.Computing.2017.48
   KAWASE Akihiro, 2010, KANSEI ENG INT J, V10, P19, DOI [10.5057/kei.10.19, DOI 10.5057/KEI.10.19]
   Kedyte V, 2017, 2017 18 INT SOC MUS, P23
   Kereliuk C, 2015, IEEE T MULTIMEDIA, V17, P2059, DOI 10.1109/TMM.2015.2478068
   Khoo S., 2012, P 6 IEEE INT C SIGN, P1, DOI DOI 10.1109/ICSPCS.2012.6508020
   Khoo S, 2013, C IND ELECT APPL, P131
   Larochelle H., 2008, P 25 INT C MACH LEAR, P536
   Larochelle H, 2012, J MACH LEARN RES, V13, P643
   Li J, 2015, 2015 12 SOUND MUS CO, P393
   Li J., 2017, P 9THLNTEMATIONAL C, P66, DOI 10.1145/3057039.3057069
   Li Ji, 2017, 2017 IEEE PELS Workshop on Emerging Technologies: Wireless Power Transfer (WoW), P60, DOI 10.1109/WoW.2017.7959365
   Li J, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON HUMANITY AND SOCIAL SCIENCE (ICHSS 2016), P16
   Liu Y, 2008, ACTA ELECT SINICA, V36, P152
   Liu Y, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P657, DOI 10.1109/ICSC.2007.51
   Mannepalli K, 2016, INT J SPEECH TECHNOL, V19, P87, DOI 10.1007/s10772-015-9328-y
   Martel J, 2013, LECT NOTES COMPUT SC, V8131, P397, DOI 10.1007/978-3-642-40728-4_50
   Miao J, 1985, J CENTRAL CONSERVATO, V1, P26
   Nanni L, 2017, PATTERN RECOGN LETT, V88, P49, DOI 10.1016/j.patrec.2017.01.013
   Panteli M., 2016, P 17 INT SOC MUS INF, P538
   RAJAN R, 2017, IEEE S SERIES COMPUT, P1, DOI DOI 10.1109/NCC.2017.8077056
   Scaringella N, 2006, IEEE SIGNAL PROC MAG, V23, P133, DOI 10.1109/MSP.2006.1598089
   Tzanetakis G., 2000, Organised Sound, V4, P169, DOI DOI 10.1017/S1355771800003071
   Uzunbas MG, 2016, MED IMAGE ANAL, V27, P31, DOI 10.1016/j.media.2015.06.003
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   van der Maaten L, 2012, MACH LEARN, V87, P33, DOI 10.1007/s10994-011-5273-4
   WU MJ, 2015, ACM TRANS MULTIMED C, V12, P1, DOI DOI 10.1145/2801127
NR 42
TC 9
Z9 9
U1 8
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11563
EP 11584
DI 10.1007/s11042-018-6637-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900021
DA 2024-07-18
ER

PT J
AU Origlia, A
   Cutugno, F
   Rodà, A
   Cosi, P
   Zmarich, C
AF Origlia, Antonio
   Cutugno, Francesco
   Roda, Antonio
   Cosi, Piero
   Zmarich, Claudio
TI FANTASIA: a framework for advanced natural tools and applications in
   social, interactive approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human computer interaction; Game engines; Application development tools
AB With the recent availability of industry-grade, high-performing engines for video games production, researchers in different fields have been exploiting the advanced technologies offered by these artefacts to improve the quality of the interactive experiences they design. While these engines provide excellent and easy-to-use tools to design interfaces and complex rule-based systems to control the experience, there are some aspects of Human-Computer Interaction (HCI) research they do not support in the same way because of their original mission and related design patterns pointing at a different primary target audience. In particular, the more research in HCI evolves towards natural, socially engaging approaches, the more there is the need to rapidly design and deploy software architectures to support these new paradigms. Topics such as knowledge representation, probabilistic reasoning and voice synthesis demand space as possible instruments within this new ideal design environment. In this work, we propose a framework, named FANTASIA, designed to integrate a set of chosen modules (a graph database, a dialogue manager, a game engine and a voice synthesis engine) and support rapid design and implementation of interactive applications for HCI studies. We will present a number of different case studies to exemplify how the proposed tools can be deployed to develop very different kinds of interactive applications and we will discuss ongoing and future work to further extend the framework we propose.
C1 [Origlia, Antonio] Univ Naples Federico II, URBAN ECO Res Ctr, I-80138 Naples, NA, Italy.
   [Cutugno, Francesco] Univ Naples Federico II, Dept Elect Engn & Informat Technol, I-80138 Naples, NA, Italy.
   [Roda, Antonio] Univ Padua, Dept Informat Engn, I-35122 Padua, PD, Italy.
   [Cosi, Piero; Zmarich, Claudio] CNR, Inst Cognit Sci & Technol, ISTC, I-35137 Padua, Italy.
C3 University of Naples Federico II; University of Naples Federico II;
   University of Padua; Consiglio Nazionale delle Ricerche (CNR); Istituto
   di Scienze e Tecnologie della Cognizione (ISTC-CNR)
RP Origlia, A (corresponding author), Univ Naples Federico II, URBAN ECO Res Ctr, I-80138 Naples, NA, Italy.
EM antonio.origlia@unina.it; cutugno@unina.it; roda@dei.unipd.it;
   piero.cosi@cnr.it; claudio.zmarich@cnr.it
RI Cosi, Piero/AAC-8036-2019
OI Cosi, Piero/0000-0002-4091-2317; Origlia, Antonio/0000-0002-8635-1623;
   CUTUGNO, Francesco/0000-0001-9457-6243
FU Italian PRIN project Cultural Heritage Resources Orienting Multimodal
   Experience (CHROME) [B52F15000450001]
FX Antonio Origlia's work is funded by the Italian PRIN project Cultural
   Heritage Resources Orienting Multimodal Experience (CHROME)
   #B52F15000450001.
CR Andre C, 2007, ARXIV07054415
   [Anonymous], 1999, FONETICA FONOLOGIA I
   [Anonymous], 2002, P 1 INT WORDNET C MY
   [Anonymous], P 5 INT WORKSH COMB
   Byun TM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0172022
   Caselli M.C., 1995, Il primo vocabolario del bambino: guida all'uso del questionario MacArthur per la valutazione della comunicazione e del linguaggio nei primi anni di vita
   Cera V., 2018, P AVI CH WORKSH
   Cosi P, 2016, P INT, P3888
   De la Torre F, 2008, Guide to the Carnegie Mellon University Multimodal Activity (CMU-MMAC) Database". In, P1
   Di Maro M, 2017, IWCS 2017
   Dietze F, 2016, LECT NOTES COMPUT SC, V9817, P204, DOI 10.1007/978-3-319-45507-5_14
   González JD, 2017, J PHYS CONF SER, V935, DOI 10.1088/1742-6596/935/1/012069
   Hornecker E., 2006, P 18 AUSTR C COMPUTE, P135, DOI DOI 10.1145/1228175.1228201
   Irwansyah FS, 2018, IOP CONF SER-MAT SCI, V288, DOI 10.1088/1757-899X/288/1/012068
   Jiménez P, 2016, PROC CIRP, V55, P284, DOI 10.1016/j.procir.2016.08.023
   Kersten TP, 2017, INT ARCH PHOTOGRAMM, V42-2, P361, DOI 10.5194/isprs-archives-XLII-2-W3-361-2017
   Kopp S, 2005, LECT NOTES ARTIF INT, V3661, P329
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Lison P, 2016, PROCEEDINGS OF 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL-2016): SYSTEM DEMONSTRATIONS, P67
   Martinie C., 2018, P ACM SIGCHI S ENG I, P4
   McKeown G, 2010, IEEE INT CON MULTI, P1079, DOI 10.1109/ICME.2010.5583006
   Niewiadomski Radoslaw., 2009, AAMAS'09: Proceedings of The 8th International Conference on Autonomous Agents and Multiagent Systems, P1399, DOI DOI 10.1075/NLP.8.20BEV
   Origlia A., 2017, GHITALY CHITALY
   Origlia A., 2018, P 2018 AVI CH WORKSH, P1, DOI [10.1145/3206505.3206597, DOI 10.1145/3206505.3206597]
   Origlia A, 2017, P SUBS
   Origlia A, 2016, P AVI CH WORKSH
   Origlia A, 2018, P ANN C IT ASS SPEEC
   PETERSEN T, 1990, LIBR TRENDS, V38, P644
   Polka L., 1995, SPEECH PERCEPTION LI, P49
   Qiu WC, 2016, LECT NOTES COMPUT SC, V9915, P909, DOI 10.1007/978-3-319-49409-8_75
   Shah S., 2017, Field and service robotics, DOI 10.1007/978-3-319-67361-5_40
   Shrinivasan YB, 2017, ARXIV171001772
   Squire K., 2003, Educational Technology, V43, P17
   TALLAL P, 1976, J SPEECH HEAR RES, V19, P561, DOI 10.1044/jshr.1903.561
   Thiebaux Marcus., 2008, P AAMAS 08, P151
   Traum David, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P245, DOI 10.1007/978-3-642-33197-8_25
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Valentino M, 2017, P WORKSH DES IMPL EV
   Webber J., 2012, P 3 ANN C SYST PROGR, P217, DOI DOI 10.1145/2384716.2384777
   Zmarich C., 2005, Interspeech-2005, P757, DOI DOI 10.21437/INTERSPEECH.2005-351
NR 40
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13613
EP 13648
DI 10.1007/s11042-019-7362-5
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900045
DA 2024-07-18
ER

PT J
AU Trigui, O
   Zouch, W
   Ben Slima, M
   Ben Messaoud, M
AF Trigui, Omar
   Zouch, Wassim
   Ben Slima, Mohamed
   Ben Messaoud, Mohamed
TI Bispectral analysis-based approach for steady-state visual evoked
   potentials detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain-Computer Interface; Steady State Visual Evoked Potential; COMB
   filter; Spatial filter; Bi-spectral analysis
ID COMPUTER; SIGNALS
AB Brain-Computer Interface (BCI) systems are widely based on steady-state visual evoked potentials (SSVEP) detection using electroencephalography (EEG) signals. SSVEP-based BCIs are becoming attractive due to their higher signal-to-noise ratio (SNR) as well as faster information transfer rate (ITR). However, their performances are largely affected by the interference coming from the spontaneous EEG activities which intrinsically restrict their efficiency in distinguishing between SSVEPs and background EEG activities. In this paper, we introduce a new approach for the detection of SSVEP based on bispectral analysis to palliate the frequency-dependent bias. A COMB filter associated with a wavelet denoising filter is firstly used to minimize the noise while improving the SNR of phase signals. Next, the complementary orthogonal projections and the principle component analysis (PCA) are used to decompose the components related to SSVEPs and components related to brain activities. Finally, the bispectrum, a powerful tool for the analysis and the characterization of nonlinear properties of stochastic signals, is used to extract the features of the EEG signal benefiting from the information about the phase coupling of the signal components. The results of experiments, using two databases on five (or ten) subjects, show that the proposed approach significantly outperformed the standard CCA approach in distinguishing the target frequency and in average information transfer rate.
C1 [Trigui, Omar; Zouch, Wassim; Ben Slima, Mohamed; Ben Messaoud, Mohamed] Sfax Univ, ENIS, ATMS, Sfax, Tunisia.
   [Zouch, Wassim] KAU, Jeddah, Saudi Arabia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); King
   Abdulaziz University
RP Trigui, O (corresponding author), Sfax Univ, ENIS, ATMS, Sfax, Tunisia.
EM omar.trigui-phd@enis.tn
RI ZOUCH, Wassim/I-7791-2013
OI Trigui, Omar/0000-0003-1253-9970; ZOUCH, Wassim/0000-0003-1047-1968
CR Ammar S., 2017, CONTROL INTELLIGENT, V45, P29
   Chang CT, 2017, BIOMED SIGNAL PROCES, V31, P211, DOI 10.1016/j.bspc.2016.08.008
   Chella F, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00262
   Chen L, 2004, IEEE INT CONF ROBOT, P5070
   Friman O, 2007, IEEE T BIO-MED ENG, V54, P742, DOI 10.1109/TBME.2006.889160
   Gao X, 2009, J NEURAL ENG, V6
   Hairston WD, 2014, J NEURAL ENG, V11, DOI 10.1088/1741-2560/11/4/046018
   Hwang HJ, 2017, PSYCHOPHYSIOLOGY, V54, P444, DOI 10.1111/psyp.12793
   Kolodziej M, 2015, INT WORKSH INT DATA, P697, DOI 10.1109/IDAACS.2015.7341393
   Li YT, 2016, MULTIMED TOOLS APPL, V75, P7999, DOI 10.1007/s11042-015-2717-z
   Li Zhao, 2010, Proceedings of the 2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2010), P2220, DOI 10.1109/FSKD.2010.5569537
   Lin DX, 2015, CHIN CONTR CONF, P4728, DOI 10.1109/ChiCC.2015.7260370
   Lin ZL, 2007, IEEE T BIO-MED ENG, V54, P1172, DOI 10.1109/TBME.2006.889197
   Liu Q, 2014, J MED BIOL ENG, V34, P299, DOI 10.5405/jmbe.1522
   Mamun M, 2013, J APPL RES TECHNOL, V11, P156, DOI 10.1016/S1665-6423(13)71524-4
   Martis RJ, 2013, BIOMED SIGNAL PROCES, V8, P193, DOI 10.1016/j.bspc.2012.08.004
   Martisius I, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3861425
   Materka A, 2006, 3 INT C ADV MED SIGN
   Nakanishi M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140703
   Nataraj S. K, 2015, INDIAN J SCI TECHNOL, V8, P1, DOI 10.17485/ijst/2015/v8i20/78463
   Ortner R, 2011, IEEE T NEUR SYS REH, V19, P1, DOI 10.1109/TNSRE.2010.2076364
   Rui Huang, 2014, Brain Informatics and Health. International Conference, BIH 2014. Proceedings: LNCS 8609, P122, DOI 10.1007/978-3-319-09891-3_12
   Shen H, 2009, LECT NOTES COMPUT SC, V5553, P171, DOI 10.1007/978-3-642-01513-7_19
   SIGL JC, 1994, J CLIN MONITOR, V10, P392, DOI 10.1007/BF01618421
   Stamps K, 2010, LECT NOTES ARTIF INT, V6334, P336, DOI 10.1007/978-3-642-15314-3_32
   Sun GP, 2017, PROCEDIA COMPUT SCI, V107, P389, DOI 10.1016/j.procs.2017.03.123
   Trigui O, 2017, INT J COGN INFORM NA, V11, P47, DOI 10.4018/IJCINI.2017070104
   Wolpaw J R, 1998, IEEE Trans Rehabil Eng, V6, P326, DOI 10.1109/86.712231
   Xie S, 2017, BIOMECHATRONICS MED, P51
   Zhou SM, 2008, INFORM SCIENCES, V178, P1629, DOI 10.1016/j.ins.2007.11.012
NR 30
TC 7
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 12865
EP 12882
DI 10.1007/s11042-018-6029-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900010
DA 2024-07-18
ER

PT J
AU Fan, D
   Wang, Y
   Zhu, CW
AF Fan, Di
   Wang, Ying
   Zhu, Chunwei
TI A blind watermarking algorithm based on adaptive quantization in
   Contourlet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contourlet transform; Singular value decomposition; Blind digital
   watermarking; Adaptive quantization
ID ANGLE QUANTIZATION; INDEX MODULATION
AB Aiming at the copyright protection of digital works, a blind watermarking algorithm in Contourlet domain based on adaptive quantization is proposed. The algorithm adaptively regulates quantization step size in the Contourlet domain according to the mean of each sub block, so that the embedding strength of watermark can better adapt to the characteristics of each sub block. Before extracting watermark, the rotation correction algorithm has been applied in processing image, which greatly improves the ability of blind watermarking algorithm to resist rotation attacks. Many anti attack experiments are carried out on the proposed algorithm. The results show that the algorithm has good robustness, and it has distinctness advantages in anti JPEG compression, Gauss noise, shear and rotation attack.
C1 [Fan, Di; Wang, Ying; Zhu, Chunwei] Shandong Univ Sci & Technol, Qingdao 266590, Shandong, Peoples R China.
C3 Shandong University of Science & Technology
RP Fan, D (corresponding author), Shandong Univ Sci & Technol, Qingdao 266590, Shandong, Peoples R China.
EM esay698@126.com
FU Shandong Province Young Scientist Foundation [BS2012DX034]; China
   Postdoctoral Science Foundation [2012 M521361]; Shandong Province
   Natural Science Foundation [ZR2012EEM021]; Project of Shandong Province
   Higher Educational Science and Technology Program [J13LN17]; SDUST
   Research Fund [2010KYTD101]; Project of South Africa/China Research
   Collaboration in Science and Technology [2012DFG71060]
FX This paper partially aided by Shandong Province Young Scientist
   Foundation (BS2012DX034), China Postdoctoral Science Foundation (2012
   M521361), Shandong Province Natural Science Foundation (ZR2012EEM021),
   Project of Shandong Province Higher Educational Science and Technology
   Program (J13LN17), SDUST Research Fund (2010KYTD101), and Project of
   South Africa/China Research Collaboration in Science and Technology
   (2012DFG71060).
CR Baaziz N, 2005, P IEEE INT C IM PROC, P221
   Bi HB, 2010, INT CONF SIGN PROCES, P881, DOI 10.1109/ICOSP.2010.5656038
   Cai NA, 2015, SIGNAL PROCESS-IMAGE, V34, P52, DOI 10.1016/j.image.2015.03.010
   Chen ST, 2016, MULTIMED TOOLS APPL, V75, P5493, DOI 10.1007/s11042-015-2522-8
   Hosseini Seyedeh Akram, 2014, MAJLESI J ELECT ENG, V8, P63
   Huang Z, 2014, INT C MECH SCI EL EN, P874
   Huang Z, 2014, INT C MECH SCI
   Idrissi N, 2014, INT C MULT COMP SYST
   Jiang YL, 2013, AEU-INT J ELECTRON C, V67, P690, DOI 10.1016/j.aeue.2013.02.005
   Li Y, 2012, IET WIREL SENS SYST, V2, P262, DOI 10.1049/iet-wss.2012.0015
   Liu DY, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P748, DOI 10.1109/ICYCS.2008.61
   Luo P, 2013, INT C INT NETWORKING, P673
   Najih A, 2017, J KING SAUD UNIV-COM, V29, P288, DOI 10.1016/j.jksuci.2016.02.005
   Nguyen SC, ICITEE2018, P1
   Qin C., 2014, J INFORM COMPUTATION, V11, P519, DOI DOI 10.12733/jics20102841
   Ramanjaneyulu K, 2012, INT J COMPUT APPL, P81
   Seo YH, 2010, J ELECT COMPUT ENG, P5
   Wu G, 2013, APPL MECH MAT, V347-350, P2983, DOI [10.4028/www.scientific.net/AMM.347-350.2983, DOI 10.4028/WWW.SCIENTIFIC.NET/AMM.347-350.2983]
   Yong YU, 2017, PACKAGE ENG, V7, P202
   Zareian M, 2012, IEEE GLOB COMM CONF, P881, DOI 10.1109/GLOCOM.2012.6503224
   Zhang Fei-yan, 2012, Application Research of Computers, V29, P1402, DOI 10.3969/j.issn.1001-3695.2012.04.056
   Zhu XZ, 2006, INT C PATT RECOG, P651
NR 22
TC 6
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8981
EP 8995
DI 10.1007/s11042-018-7140-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800060
DA 2024-07-18
ER

PT J
AU Liu, L
   Wang, LF
   Chang, CC
AF Liu, Li
   Wang, Lifang
   Chang, Chin-chen
TI Data embedding scheme based on multi-matrix structure of turtle shell to
   avoid human eye perception
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data embedding; Turtle shell; Multi-matrix structure; Pixel pair; Image
   steganography
AB Data embedding is a technique for embedding secret information into the carrier data, such as text, audios, images, and videos. Meanwhile, it also can ensure that the changes in the carrier data are imperceptible by human eye to avoid attracting the attention of malicious attackers. In this paper, we propose a data embedding scheme based on the multi-matrix structure of turtle shell (MMS-TDH). First, weighting is introduced to divide the cover image into various regions, i.e., a smooth region, a texture region and an edge region. Second, considering that the human eye is more sensitive to changes in the pixels in the smooth region than in the other regions, the smaller turtle shell matrix was used to ensure fewer changes in the pixels of the smooth region, and the larger turtle shell matrix was used for the edge region to improve the embedding capacity. This process ensures the flexibility of our scheme in balancing embedding capacity and image quality, and it also avoids the sharp decline in image quality when the turtle shell matrix enlarges. Extensive experimental results validated the expected merits of the proposed scheme.
C1 [Liu, Li; Wang, Lifang] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
   [Liu, Li] Taiyuan Univ Sci & Technol, Coll Elect Informat & Engn, Taiyuan 030024, Shanxi, Peoples R China.
   [Chang, Chin-chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
C3 Northwestern Polytechnical University; Taiyuan University of Science &
   Technology; Feng Chia University
RP Liu, L; Wang, LF (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.; Liu, L (corresponding author), Taiyuan Univ Sci & Technol, Coll Elect Informat & Engn, Taiyuan 030024, Shanxi, Peoples R China.; Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM skies5315@sina.com; wanglf@nwpu.edu.cn; alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
FU National Natural Science Foundation of China [61540009]
FX This work was supported in part by The National Natural Science
   Foundation of China (No.61540009).
CR Aljuaid N, 2015, P 12 LEARN TECHN C W
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P89, DOI 10.1109/IIH-MSP.2014.29
   Chen J, 2014, SIGNAL PROCESS-IMAGE, V29, P375, DOI 10.1016/j.image.2014.01.003
   Chen TH, 2018, MULTIMED TOOLS APPL, V77, P7865, DOI 10.1007/s11042-017-4680-3
   Davis R. M., 1978, IEEE Communications Society Magazine, V16, P5, DOI 10.1109/MCOM.1978.1089771
   Elsheh E, 2011, EXPERT SYST APPL, V38, P13906, DOI 10.1016/j.eswa.2011.04.197
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Jiang N, 2016, INT J THEOR PHYS, V55, P107, DOI 10.1007/s10773-015-2640-0
   Kim C, 2016, MULTIMED TOOLS APPL, V75, P15651, DOI 10.1007/s11042-014-2355-x
   Kim C, 2014, MULTIMED TOOLS APPL, V69, P569, DOI 10.1007/s11042-012-1114-0
   Kim HJ, 2010, COMPUT MATH APPL, V60, P319, DOI 10.1016/j.camwa.2010.01.006
   Lee C., 2015, INT J NETW SECURITY, V17, P607
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   Liu L, 2017, MULTIMED TOOLS APPL, V76, P12233, DOI 10.1007/s11042-016-3624-7
   Liu YJ, 2016, IET IMAGE PROCESS, V10, P130, DOI 10.1049/iet-ipr.2014.1015
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mali SN, 2012, DIGIT SIGNAL PROCESS, V22, P314, DOI 10.1016/j.dsp.2011.09.003
   Marghny M., 2012, International Journal of Computer Applications, V45, P13
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Shen SY, 2018, MULTIMED TOOLS APPL, V77, P12563, DOI 10.1007/s11042-017-4905-5
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Kieu TD, 2011, EXPERT SYST APPL, V38, P10648, DOI 10.1016/j.eswa.2011.02.122
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 27
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10473
EP 10490
DI 10.1007/s11042-018-6606-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400042
DA 2024-07-18
ER

PT J
AU Sarangi, PP
   Mishra, BSP
   Dehuri, S
AF Sarangi, Partha Pratim
   Mishra, Bhabani Shankar Prasad
   Dehuri, Satchidanand
TI Fusion of PHOG and LDP local descriptors for kernel-based ear biometric
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ear recognition; Feature-level fusion; Pyramid histogram of oriented
   gradients; Local directional patterns; Kernel discriminant analysis
ID FACE
AB Achieving higher recognition performance in uncontrolled scenarios is a key issue for ear biometric systems. It is almost difficult to generate all discriminative features by using a single feature extraction method. This paper presents an efficient method by combining the two most successful local feature descriptors such as Pyramid Histogram of Oriented Gradients (PHOG) and Local Directional Patterns (LDP) to represent ear images. The PHOG represents spatial shape information and the LDP efficiently encodes local texture information. As the feature sets are curse of high dimension, we used principal component analysis (PCA) to reduce the dimension prior to normalization and fusion. Then, two normalized heterogeneous feature sets are combined to produce single feature vector. Finally, the Kernel Discriminant Analysis (KDA) method is employed to extract nonlinear discriminant features for efficient recognition using a nearest neighbor (NN) classifier. Experiments on three standard datasets IIT Delhi version (I and II) and University of Notre Dame collection E reveal that the proposed method can achieve promising recognition performance in comparison with other existing successful methods.
C1 [Sarangi, Partha Pratim; Mishra, Bhabani Shankar Prasad] KIIT Univ, Sch Comp Engn, Bhubaneswar 751024, Odisha, India.
   [Dehuri, Satchidanand] FM Univ, Dept Informat & Commun Technol, Balasore 756019, India.
C3 Kalinga Institute of Industrial Technology (KIIT); Fakir Mohan
   University
RP Sarangi, PP (corresponding author), KIIT Univ, Sch Comp Engn, Bhubaneswar 751024, Odisha, India.
EM ppsarangi@gmail.com; mishra.bsp@gmail.com; satchi.lapa@gmail.com
RI Sarangi, Partha Pratim/E-5373-2019; Dehuri, Satchidananda/AAN-7798-2021;
   Dehuri, Satchidananda/AFQ-1029-2022; Mishra, Bhabani
   ShankarPrasad/J-4690-2015
OI Sarangi, Partha Pratim/0000-0002-5628-997X; Dehuri,
   Satchidananda/0000-0003-1435-4531; Mishra, Bhabani Shankar
   Prasad/0000-0003-1656-4487
CR Abate AF, 2006, INT C PATT RECOG, P437
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], TELECOMMUN SYST J
   Anwar AS, 2015, PROCEDIA COMPUT SCI, V65, P529, DOI 10.1016/j.procs.2015.09.126
   Arbab-Zavar B, 2007, LECT NOTES COMPUT SC, V4842, P549
   Badrinath GS, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P197, DOI 10.1109/ICAPR.2009.27
   Basit A, 2014, INT J COMPUT MATH, V91, P616, DOI 10.1080/00207160.2013.800194
   Benzaoui A, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.5.053008
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Bustard JD, 2010, IEEE T SYST MAN CY A, V40, P486, DOI 10.1109/TSMCA.2010.2041652
   Chang K, 2003, IEEE T PATTERN ANAL, V25, P1160, DOI 10.1109/TPAMI.2003.1227990
   Chen S, 2012, CROSS DISCIPLINARY B, P183
   Chen S, 2011, 15 INT C IM PROC COM
   Chen S, 2014, IEEE T IMAGE PROCESS, V23, P1629, DOI 10.1109/TIP.2013.2294548
   Choras M, 2008, OPTO-ELECTRON REV, V16, P85, DOI 10.2478/s11772-007-0033-5
   Choras M, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P451
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Damer N., 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P21, DOI 10.1109/IIH-MSP.2012.12
   Emersic Z, 2017, NEUROCOMPUTING, V255, P26, DOI 10.1016/j.neucom.2016.08.139
   Guo YM, 2008, IEEE IMAGE PROC, P289, DOI 10.1109/ICIP.2008.4711748
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Huang ZX, 2013, PATTERN RECOGN, V46, P2156, DOI 10.1016/j.patcog.2013.01.022
   Hurley DJ, 2002, IMAGE VISION COMPUT, V20, P311, DOI 10.1016/S0262-8856(02)00003-3
   Iannarelli A., 1989, FORENSIC IDENTIFICAT
   Jabid T., 2010, Digest of Technical Papers Int. Conf. Consumer Electronics, P329, DOI DOI 10.1109/ICCE.2010.5418801
   Kim KI, 2002, IEEE SIGNAL PROC LET, V9, P40, DOI 10.1109/97.991133
   Kumar A, 2012, PATTERN RECOGN, V3, P56
   Kumar A, 2007, PROC SPIE, V6539, DOI 10.1117/12.720244
   Lei S., 2016, INT J SIGNAL PROCESS, V9, P33
   Li Yuan, 2006, First International Symposium on Systems and Control in Aerospace and Astronautics (IEEE Cat. No.06EX1168C)
   Li Yuan, 2012, Proceedings of the 2012 International Conference on System Science and Engineering (ICSSE), P349, DOI 10.1109/ICSSE.2012.6257205
   Liu CJ, 1998, INT C PATT RECOG, P1368, DOI 10.1109/ICPR.1998.711956
   Liu QS, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P197, DOI 10.1109/AFGR.2002.1004157
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu L, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 3, PROCEEDINGS, P353
   Marcolin F, 2017, MULTIMED TOOLS APPL, V76, P13805, DOI 10.1007/s11042-016-3741-3
   Nanni L, 2007, PATTERN RECOGN LETT, V28, P2219, DOI 10.1016/j.patrec.2007.07.004
   Nanni L, 2009, PATTERN RECOGN, V42, P1906, DOI 10.1016/j.patcog.2008.10.016
   Nosrati MS, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P616
   Pan XQ, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P965, DOI 10.1109/ICALIP.2008.4590072
   Pflug A, 2012, IET BIOMETRICS, V1, P114, DOI 10.1049/iet-bmt.2011.0003
   Rathore R., 2013, 6th International Conference on Biometrics: Theory, Applications and Systems (BTAS), P1
   Sana A, 2007, INT C ADV PATT REC
   Sarangi P., 2017, INT JNL CONTROL THEO, V10, P125
   Sarangi P.P., 2017, P INT C COMPUTER VIS, P229, DOI [10.1007/978-981-10-2107-7_21, DOI 10.1007/978-981-10-2107-7_21]
   Shailaja D, 2006, ICIT 2006: 9TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P164
   Vezzetti E, 2018, MULTIMED TOOLS APPL, V77, P14177, DOI 10.1007/s11042-017-5025-y
   Victor B, 2002, INT C PATT RECOG, P429, DOI 10.1109/ICPR.2002.1044746
   Wang YL, 2008, PPAR RES, V2008, DOI 10.1155/2008/209629
   Xie Z., 2008, PROCEEDING 19 INT C, P1
   Xu XN, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P620, DOI 10.1109/ICAL.2007.4338638
   Yazdanpanah Ali Pour, 2010, 2010 10th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA 2010), P251, DOI 10.1109/ISSPA.2010.5605477
   Yuan L, 2006, INT C PATT RECOG, P501
   Zhang HJ, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P4511
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 55
TC 21
Z9 21
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9595
EP 9623
DI 10.1007/s11042-018-6489-0
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400005
DA 2024-07-18
ER

PT J
AU Shaik, A
   Thanikaiselvan, V
AF Shaik, Ahmad
   Thanikaiselvan, V
TI High capacity reversible data hiding using 2D parabolic interpolation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parabolic interpolation; Reversible data hiding; Image interpolation;
   Interpolation-based RDH
AB Reversible data hiding (RDH) plays a key role in ensuring security of communications. Recent studies have revealed that RDH techniques based on interpolation are gaining popularity because of the ease of implementation and support for high embedding capacity. From recent literature, it is noted that the one-dimensional (1D) parabolic interpolation-based data hiding technique is suitable for high embedding capacity applications. This study aims to implement a high capacity RDH technique using a new two-dimensional (2D) parabolic interpolation and a novel embedding technique that is suitable for interpolation-based techniques. The results of this study showed that the proposed 2D parabolic interpolation maximized the utilization of the cover image pixels in up-sampling. The technique produced interpolated images of a higher quality compared to the 1D parabolic interpolation technique. Moreover, the proposed data hiding technique exploited the local redundancy and obtained the high embedding capacity with an appreciable image quality better than other state-of-the-art techniques. The results of this study support the view that the proposed parabolic interpolation has the potential to address security issues in high embedding capacity applications.
C1 [Shaik, Ahmad; Thanikaiselvan, V] VIT Univ, Sch Elect Engn SENSE, Dept Commun Engn, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Thanikaiselvan, V (corresponding author), VIT Univ, Sch Elect Engn SENSE, Dept Commun Engn, Vellore 632014, Tamil Nadu, India.
EM sk.ahmed401@gmail.com; thanikaiselvan@vit.ac.in
RI Shaik, Ahmad/ABI-1069-2020
OI Shaik, Ahmad/0000-0002-9294-5356; Thanikaiselvan, V/0000-0003-2418-5217
CR [Anonymous], ACCESS
   Govind PVS, 2015, PROCEDIA COMPUT SCI, V46, P491, DOI 10.1016/j.procs.2015.02.073
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Jung KH, 2018, MULTIMED TOOLS APPL, V77, P7795, DOI 10.1007/s11042-017-5066-2
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Zhang XQ, 2017, MULTIMED TOOLS APPL, V76, P9195, DOI 10.1007/s11042-016-3521-0
NR 14
TC 18
Z9 18
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9717
EP 9735
DI 10.1007/s11042-018-6544-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400010
DA 2024-07-18
ER

PT J
AU Wang, XH
   Li, Z
   Zhou, X
   Tao, JZ
AF Wang, Xianghai
   Li, Zhi
   Zhou, Xia
   Tao, Jingzhe
TI Segmentation model for hyperspectral remote sensing images based on
   spectral angle constrained active contour
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral remote sensing; Image segmentation; Optimal band
   selection; Spectral angle function; Chan-Vese model
AB We propose an alternative hyperspectral image segmentation method based on a geometric active contour model. First, we use a spectral angle as a measure index to measure the spectral similarity between the pixels, and the spectral angle constrained function is constructed based on spectral similarity. Then, depending on the class separability criterion, an optimal band is chosen which is suitable for image segmentation. The model retains advantages of the traditional C-V model in regional information with rich textures and edges. Its unique feature is exploiting the characteristics of hyperspectral remote sensing images in regions with abundant spectral information. As a consequence, the capture capability, segmentation speed, and accuracy are enhanced. Finally, we present experiments using WorldView and Hyperion images, from whose results demonstrate the improved attributes of the proposed method over those of the traditional C-V model. The proposed model provides better results than the traditional models both in segmentation accuracy and computational efficiency.
C1 [Wang, Xianghai; Li, Zhi; Zhou, Xia] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Liaoning, Peoples R China.
   [Wang, Xianghai; Tao, Jingzhe] Liaoning Normal Univ, Sch Urban & Environm Sci, Dalian 116029, Liaoning, Peoples R China.
C3 Liaoning Normal University; Liaoning Normal University
RP Wang, XH (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Liaoning, Peoples R China.; Wang, XH (corresponding author), Liaoning Normal Univ, Sch Urban & Environm Sci, Dalian 116029, Liaoning, Peoples R China.
EM xhwang@lnnu.edu.cn; 1300852174@qq.com; 631904159@qq.com;
   blueuranus@qq.com
RI Jingzhe, Tao/JTD-2817-2023; Wang, Xianghai/GRR-4512-2022
OI Wang, Xianghai/0000-0002-7600-9939
FU National Natural Science Foundation of China [41671439, 61402214];
   Innovation Team Support Program of Liaoning Higher Education Department
   [LT2017013]
FX This research has been funded by the National Natural Science Foundation
   of China (Grant Nos. 41671439 and 61402214), and Innovation Team Support
   Program of Liaoning Higher Education Department (LT2017013).
CR [曹建农 Cao Jiannong], 2005, [遥感学报, Journal of Remote Sensing], V9, P596
   Chai TY, 2015, 2015 CONFERENCE ON TECHNOLOGIES AND APPLICATIONS OF ARTIFICIAL INTELLIGENCE (TAAI), P506, DOI 10.1109/TAAI.2015.7407059
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   CHEN B, 2007, J IMAGE GRAPHIC, V1, P11
   Fang LL, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061405
   Fedkiw R., 2003, LEVEL SET METHODS DY
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KRUSE FA, 1993, REMOTE SENS ENVIRON, V44, P145, DOI 10.1016/0034-4257(93)90013-N
   Mercier G, 2003, INT GEOSCI REMOTE SE, P3766
   Morel JM, 1994, VARIATION METHODS IM
   Mustafa AF, 2017, COMPUT INTELL DESIGN, P1
   Nian Yong-jian, 2010, Acta Photonica Sinica, V39, P1003, DOI 10.3788/gzxb2010306.1003
   Sapiro G., 2003, GEOMETRIC PARTIAL DI
   Sethian J., 1999, LEVEL SET METHODS FA
   Silverman J, 2002, P SOC PHOTO-OPT INS, V4816, P270, DOI 10.1117/12.451537
   Tarabalka Y, 2010, IEEE T GEOSCI REMOTE, V38, P1410
   Wang XH, 2013, J IMAGE GRAPH, V18, P2
   [王相海 Wang Xianghai], 2013, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V26, P751
   Yu XC, 2012, J GEOL, V36, P33
   [张文杰 ZHANG Wenjie], 2008, [遥感技术与应用, Remote Sensing Technology and Application], V23, P351
NR 20
TC 2
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10141
EP 10155
DI 10.1007/s11042-018-6608-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400030
DA 2024-07-18
ER

PT J
AU Yang, GH
   Wang, XJ
AF Yang, Guohua
   Wang, Xiaojie
TI Cascaded deep neural network models for dialog state tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dialog state tracking; Joint model; LSTM plus LSTM; CNN plus LSTM
AB Dialog state tracking (DST) maintains and updates dialog states at each time step as the dialog progresses. It is necessary to include dialog historical information in DST. Previous word-based DST models took historical utterances as a word sequence and used n-grams in the sequence as inputs of models. It suffered from the problem of data sparseness. This paper proposes a cascaded deep neural network framework for DST. It alleviates the problem of data sparseness by making use of the hierarchical structure in dialog. The bottom layer of the cascaded framework, implemented by an Long Short Term Memory (LSTM) or a Convolutional Neural Network (CNN), encodes the word sequence into a sentence embedding in each dialog turn, and the upper layer integrates the representation of each turn gradually to get the dialog state using an LSTM. The cascaded models integrate natural language understanding into DST, and the entire network is trained as a whole. The experimental results on the DSTC2 dataset indicate that the proposed models, LSTM+LSTM and CNN+LSTM, can achieve better performance than existing models.
C1 [Yang, Guohua] Beijing Univ Posts & Telecommun, Sch Comp Sci, Ctr Intelligence Sci & Technol, Beijing, Peoples R China.
   [Wang, Xiaojie] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications
RP Yang, GH (corresponding author), Beijing Univ Posts & Telecommun, Sch Comp Sci, Ctr Intelligence Sci & Technol, Beijing, Peoples R China.
EM yangguohua@bupt.edu.cn; xjwang@bupt.edu.cn
RI wang, yi/KBB-3614-2024; liu, feng/KCL-0778-2024; XIN, WANG/KGK-5385-2024
FU 111 Project [B08004]; NSFC [61273365]; Beijing Advanced Innovation
   Center for Imaging Technology; Engineering Research Center of
   Information Networks of MOE; ZTE
FX This paper is supported by the 111 Project (no. B08004), the NSFC (no.
   61273365), the Beijing Advanced Innovation Center for Imaging
   Technology, the Engineering Research Center of Information Networks of
   MOE, and ZTE.
CR [Anonymous], 2013, P ANN SIGDIAL M DISC
   [Anonymous], 2005, PROC IJCAI WORKSHOP
   Henderson M, 2013, P 15 ANN M SPEC INT, P263
   Henderson M., 2014, P SIGDIAL
   Henderson Matthew, 2014, P IEEE SPOK LANG TEC
   Jang Y, 2017, P IEEE SPOK LANG TEC, P531
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kim S., 2017, SPOK LANG TECHN WORK, P324
   Kim Seokhwan, 2017, AI MAG, V35, P121
   Lee Byung-Jun, 2016, D&D, V7, P47
   Mrksic N, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1777, DOI 10.18653/v1/P17-1163
   Mrksic N, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P794
   Shi H, 2017, P IEEE SPOK LANG TEC, P559
   Shi H., 2017, Dialogues with Social Robots, P451
   Sun K, 2014, P SIGDIAL 2014 C 15, P318
   Vodolan M, 2016, COMPUT SCI
   Vodolan Miroslav, 2017, EACL 2017, P205
   Williams J., 2016, Dialogue Discourse, V7, P4
   Williams JD, J SELECT TOPICS SIGN, V6, P959
   Yang XH, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1800
   Young S, 2013, P IEEE, V101, P1160, DOI 10.1109/JPROC.2012.2225812
NR 21
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9625
EP 9643
DI 10.1007/s11042-018-6531-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400006
DA 2024-07-18
ER

PT J
AU Zarebnia, M
   Kianfar, R
   Parvaz, R
AF Zarebnia, M.
   Kianfar, R.
   Parvaz, R.
TI Multi-color image compression-encryption algorithm based on chaotic
   system and fuzzy transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; Compression; Chaotic system; Fuzzy transform; B-spline
AB In this paper an algorithm for multi-color image compression- encryption is introduced. For compression step fuzzy transform based on exponential b-spline function is used. In encryption step, a novel combination chaotic system based on Sine and Tent systems is proposed. Also in the encryption algorithm, 3D shift based on chaotic system is introduced. The simulation results and security analysis show that the proposed algorithm is secure and efficient.
C1 [Zarebnia, M.; Kianfar, R.; Parvaz, R.] Univ Mohaghegh Ardabili, Dept Math, Ardebil 5619911367, Iran.
C3 University of Mohaghegh Ardabili
RP Parvaz, R (corresponding author), Univ Mohaghegh Ardabili, Dept Math, Ardebil 5619911367, Iran.
EM zarebnia@uma.ac.ir; rahele.kianfar@student.uma.ac.ir; rparvaz@uma.ac.ir
RI Zarebnia, Mohammad/JUV-6820-2023; Parvaz, Reza/O-4447-2018
OI Zarebnia, Mohammad/0000-0002-2692-0943; 
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Banerjee S, 2012, OPT LASER ENG, V50, P950, DOI 10.1016/j.optlaseng.2012.02.009
   Beros I., 1999, Mathematical Communications, V4, P73
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Di Martino F, 2008, INT J APPROX REASON, V48, P110, DOI 10.1016/j.ijar.2007.06.008
   El-Samie FA, 2014, IMAGE ENCRYPTION COM
   Jindal N, 2014, IMAGING SCI J, V62, P265, DOI 10.1179/1743131X13Y.0000000062
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Koch PE, 1993, INTERPOLATION EXPONE, P173
   Kong DZ, 2014, OPTIK, V125, P2365, DOI 10.1016/j.ijleo.2013.10.066
   Li Z., 2014, INTELL DATA ANAL, V2, P509
   Liu XY, 2013, OPTIK, V124, P6590, DOI 10.1016/j.ijleo.2013.05.092
   Orsdemir A, 2008, IEEE MILIT COMMUN C, P1040
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Perfilieva I, 2006, FUZZY SET SYST, V157, P993, DOI 10.1016/j.fss.2005.11.012
   Perfilieva I, 2008, INT J APPROX REASON, V48, P36, DOI 10.1016/j.ijar.2007.06.003
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   Wang W, 2016, WIRELESS COMMUNICATION AND SENSOR NETWORK, P711
   Wang W, 2018, COMPUT ELECTR ENG, V65, P282, DOI 10.1016/j.compeleceng.2017.07.026
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Zhang L, 2015, J COMPUT THEOR NANOS, V12, P4980, DOI [10.1166/jctn.2015.4467, DOI 10.1166/JCTN.2015.4467]
   Zheng N, 2009, ADV PATTERN RECOGNIT, P1, DOI 10.1007/978-1-84882-312-9
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 24
TC 5
Z9 5
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10491
EP 10511
DI 10.1007/s11042-018-6644-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400043
DA 2024-07-18
ER

PT J
AU Park, KB
   Lee, JY
AF Park, Kyeong-Beom
   Lee, Jae Yeol
TI New design and comparative analysis of smartwatch metaphor-based hand
   gestures for 3D navigation in mobile virtual reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D navigation; Mobile virtual reality; Smartwatch metaphor-based hand
   gesture; User centric navigation; Drone flying principle
ID HEAD-MOUNTED DISPLAY
AB With the advent of various mobile VR HMDs, they have been widely used in different applications by providing a higher degree of immersion. However, in particular, due to limited input interfaces such as a click button and an inertial sensor in most mobile VR HMDs, it is very difficult for users to naturally navigate VR scenes and to effectively interact with VR contents. This paper presents a new design and comparative analysis of a smartwatch metaphor-based hand gesture interface for supporting more natural 3D navigation in mobile VR. The interaction using the smartwatch metaphor-based interface is implemented based on the drone flying principle, which can support more user-centric 3D navigation as well as 3D manipulation, regardless of the location and limited capability of the mobile device. Furthermore, quantitative and qualitative experiments are performed to compare and analyze task performances with different mobile VR interfaces, and with different desktop VR interfaces. In the first experiment, we compare the proposed approach with widely used mobile VR interfaces for evaluating 3D navigation tasks such as 1) button and inertial sensor-based interface and 2) hand gesture interface in front of the mobile HMD. In the second experiment, in particular, we compare the proposed approach with two desktop VR interfaces such as 1) desktop-based VR interface with keyboard and 2) desktop-based VR interface with the hand gesture. Experiment results proves that the proposed smartwatch metaphor for mobile VR navigation outperformed traditional mobile VR interfaces. We also confirm that the task performance with the proposed approach is good enough to be compared with desktop VR interfaces. One of the main features in the proposed approach is to decouple the degree of freedom (DOF) of navigation and the DOF of visualization in mobile VR so that it can support user's free head and body movement during the navigation and interaction.
C1 [Park, Kyeong-Beom; Lee, Jae Yeol] Chonnam Natl Univ, Dept Ind Engn, 77 Yongbong Ro, Gwangju 61186, South Korea.
C3 Chonnam National University
RP Lee, JY (corresponding author), Chonnam Natl Univ, Dept Ind Engn, 77 Yongbong Ro, Gwangju 61186, South Korea.
EM jaeyeol@jnu.ac.kr
OI Park, Kyeong-Beom/0000-0003-4737-730X
FU National Research Foundation of Korea (NRF) - Ministry of Education
   [NRF-2016R1D1A1B03934697]; "Development of IIoT-based manufacturing
   testbeds for the Korean manufacturing equipment industry" program -
   Ministry of Science and ICT [2015-0-00374]
FX This work was partly supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2016R1D1A1B03934697) and by the "Development of
   IIoT-based manufacturing testbeds for the Korean manufacturing equipment
   industry" program, funded by the Ministry of Science and ICT
   (2015-0-00374). The authors would like to thank Minseok Kim for
   designing a new experimental study and performing its evaluation.
CR [Anonymous], VISUALIZATION ENG
   [Anonymous], 2016, 2016 INT C IND INFOR, DOI DOI 10.1109/ICCSII.2016.7462401
   Beimler R., 2013, Proc. the GI Workshop on Virtual Reality and Augmented Reality. p, P69
   Bristeau Pierre-Jean, 2011, IFAC Proc., V44, P1477, DOI DOI 10.3182/20110828-6-IT-1002.02327
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Choi SH, 2018, COMPUT IND, V101, P51, DOI 10.1016/j.compind.2018.06.006
   CHRISTOU C, 2016, PROC MELECON 16, V16, P1
   Dam Peter, 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P139, DOI 10.1007/978-3-642-39405-8_17
   González-Delgado JA, 2015, ENVIRON EARTH SCI, V73, P4609, DOI 10.1007/s12665-014-3747-y
   HART S G, 1988, P139
   Hayakawa H, 2015, P 6 AUGM HUM INT C, V11, P171, DOI DOI 10.1145/2735711.2735816
   Hui Z, 2017, INT J MIN SCI TECHNO, V27, P717, DOI 10.1016/j.ijmst.2017.05.005
   Jang S-A., 2016, P 2016 ACM C COMP PU, P173, DOI DOI 10.1145/2908805.2909417
   Kim M, 2016, MULTIMED TOOLS APPL, V75, P16529, DOI 10.1007/s11042-016-3355-9
   Kumar V, 2015, IEEE-RAS INT C HUMAN, P657, DOI 10.1109/HUMANOIDS.2015.7363441
   Lam MC, 2018, MULTIMED TOOLS APPL, V77, P16367, DOI 10.1007/s11042-017-5205-9
   Lee GA, 2013, P ISMAR 13
   LEE J, THE INTERNATIONAL JO, V51, P1069, DOI DOI 10.1007/s00170-010-2671-x
   Lie L, 2016, P AAAI 16
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Maines C, 2015, P DESE 15
   Minohara T, 2015, P DASC 15, P1
   POWELL RL, 2016, P 11 INT C DIS VIRT, P73
   Slobounov SM, 2015, INT J PSYCHOPHYSIOL, V95, P254, DOI 10.1016/j.ijpsycho.2014.11.003
   Song Peng., 2012, P 2012 ACM ANN C HUM, P1297, DOI DOI 10.1145/2207676.2208585
   Sousa Santos B, 2009, MULTIMED TOOLS APPL, V41, P161, DOI 10.1007/s11042-008-0223-2
   Teriziman L, 2010, P VRST 10, P27
   Tregillus S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1250, DOI 10.1145/2858036.2858084
   Wu C, 2016, DRONE STREAMING WIF
NR 29
TC 8
Z9 8
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 6211
EP 6231
DI 10.1007/s11042-018-6403-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100057
DA 2024-07-18
ER

PT J
AU Roy, PP
   Bhunia, AK
   Bhattacharyya, A
   Pal, U
AF Roy, Partha Pratim
   Bhunia, Ayan Kumar
   Bhattacharyya, Avirup
   Pal, Umapada
TI Word searching in scene image and video frame in multi-script scenario
   using dynamic shape coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene and video text retrieval; Indic word spotting; Hidden Markov
   model; Dynamic shape code; Word spotting in multiple scripts
ID TEXT LOCALIZATION; HANDWRITTEN; RECOGNITION; MODEL; TRACKING
AB Retrieval of text information from natural scene images and video frames is a challenging task due to its inherent problems like complex character shapes, low resolution, background noise, etc. Available OCR systems often fail to retrieve such information in scene/video frames. Keyword spotting, an alternative way to retrieve information, performs efficient text searching in such scenarios. However, current word spotting techniques in scene/video images are script-specific and they are mainly developed for Latin script. This paper presents a novel word spotting framework using dynamic shape coding for text retrieval in natural scene image and video frames. The framework is designed to search query keyword from multiple scripts with the help of on-the-fly script-wise keyword generation for the corresponding script. We have used a two-stage word spotting approach using Hidden Markov Model (HMM) to detect the translated keyword in a given text line by identifying the script of the line. A novel unsupervised dynamic shape coding based scheme has been used to group similar shape characters to avoid confusion and to improve text alignment. Next, the hypotheses locations are verified to improve retrieval performance. To evaluate the proposed system for searching keyword from natural scene image and video frames, we have considered two popular Indic scripts such as Bangla (Bengali) and Devanagari along with English. Inspired by the zone-wise recognition approach in Indic scripts [37], zone-wise text information has been used to improve the traditional word spotting performance in Indic scripts. For our experiment, a dataset consisting of images of different scenes and video frames of English, Bangla and Devanagari scripts were considered. The results obtained showed the effectiveness of our proposed word spotting approach.
C1 [Roy, Partha Pratim] Indian Inst Technol Roorkee, Dept CSE, Roorkee, Uttar Pradesh, India.
   [Bhunia, Ayan Kumar; Bhattacharyya, Avirup] Inst Engn & Management, Dept ECE, Kolkata, India.
   [Pal, Umapada] Indian Stat Inst, CVPR Unit, Kolkata, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Institute of Engineering & Management (IEM),
   Kolkata; Indian Statistical Institute; Indian Statistical Institute
   Kolkata
RP Roy, PP (corresponding author), Indian Inst Technol Roorkee, Dept CSE, Roorkee, Uttar Pradesh, India.
EM proy.fcs@iitr.ac.in
RI Roy, Partha Pratim/AAV-9061-2020; Pal, Umapada/AAC-4930-2022; Roy,
   Partha Pratim/AAW-2994-2020; Roy, Partha Pratim/GPF-4253-2022
OI Roy, Partha Pratim/0000-0002-5735-5254; 
CR [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.475
   [Anonymous], TPAMI
   Banerjee P., 2013, P INT WORKSHOP MULTI
   Bhunia AK, 2018, PATTERN RECOGN, V79, P12, DOI 10.1016/j.patcog.2018.01.034
   Bhunia AK, 2018, MULTIMED TOOLS APPL, V77, P8551, DOI 10.1007/s11042-017-4750-6
   Bhunia AK, 2015, PROC INT CONF DOC, P636, DOI 10.1109/ICDAR.2015.7333839
   Bianne-Bernard AL, 2011, IEEE T PATTERN ANAL, V33, P2066, DOI 10.1109/TPAMI.2011.22
   Cao HG, 2011, PROC INT CONF DOC, P744, DOI 10.1109/ICDAR.2011.155
   Chaudhuri BB, 1998, PATTERN RECOGN, V31, P531, DOI 10.1016/S0031-3203(97)00078-2
   Chen DT, 2005, PATTERN RECOGN LETT, V26, P1386, DOI 10.1016/j.patrec.2004.11.019
   Chen H., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2609, DOI 10.1109/ICIP.2011.6116200
   Chen Xiangrong, 2004, Computer vision and pattern recognition, V2, pII
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Fischer A, 2012, PATTERN RECOGN LETT, V33, P934, DOI 10.1016/j.patrec.2011.09.009
   Frinken V, 2012, IEEE T PATTERN ANAL, V34, P211, DOI 10.1109/TPAMI.2011.113
   Gatos B, 2015, PROC INT CONF DOC, P646, DOI 10.1109/ICDAR.2015.7333841
   Giotis AP, 2017, PATTERN RECOGN, V68, P310, DOI 10.1016/j.patcog.2017.02.023
   Guo JHK, 2001, PROC INT CONF DOC, P439, DOI 10.1109/ICDAR.2001.953828
   He P, 2016, AAAI CONF ARTIF INTE, P3501
   Huang WL, 2013, IEEE I CONF COMP VIS, P1241, DOI 10.1109/ICCV.2013.157
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Krishnan P, 2016, INT CONF FRONT HAND, P289, DOI [10.1109/ICFHR.2016.57, 10.1109/ICFHR.2016.0062]
   Kumar G, 2017, PATTERN RECOGN, V64, P84, DOI 10.1016/j.patcog.2016.06.030
   Li K, 2018, J COMPUT SCI TECH-CH, V33, P223, DOI 10.1007/s11390-017-1764-5
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   LU S, 2018, TPAMI, V30, P1913, DOI DOI 10.1109/TPAMI.2008.89
   Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848
   Nakayama T., 1994, 4 C APPL NAT LANG PR, P22
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Rath TM, 2007, INT J DOC ANAL RECOG, V9, P139, DOI 10.1007/s10032-006-0027-8
   Rodríguez-Serrano JA, 2009, PATTERN RECOGN, V42, P2106, DOI 10.1016/j.patcog.2009.02.005
   Roy PP, 2017, EXPERT SYST APPL, V76, P113, DOI 10.1016/j.eswa.2017.01.027
   Roy PP, 2016, PATTERN RECOGN, V60, P1057, DOI 10.1016/j.patcog.2016.04.012
   Roy PP, 2015, IMAGE VISION COMPUT, V44, P15, DOI 10.1016/j.imavis.2015.09.006
   Roy PP, 2017, NEUROCOMPUTING
   Roy S, 2015, EXPERT SYST APPL, V42, P5554, DOI 10.1016/j.eswa.2015.02.030
   Roy S, 2012, INT C PATT RECOG, P3300
   Rusiñol M, 2015, PATTERN RECOGN, V48, P545, DOI 10.1016/j.patcog.2014.08.021
   Saidane Z, 2007, PROC INT CONF DOC, P874
   Sain A, 2018, NEUROCOMPUTING, V275, P1531, DOI 10.1016/j.neucom.2017.09.089
   Sharma N., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P74, DOI 10.1109/DAS.2012.6
   Shivakumara P, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P391, DOI 10.1109/ACPR.2015.7486532
   Srihari S. N., 2006, Vivek, V16, P2
   Sudholt S, 2016, INT CONF FRONT HAND, P277, DOI [10.1109/ICFHR.2016.0060, 10.1109/ICFHR.2016.55]
   Sun J, 2016, APPL MATH SER B, V31, P177, DOI 10.1007/s11766-016-3378-z
   Sun L, 2015, PATTERN RECOGN, V48, P2906, DOI 10.1016/j.patcog.2015.04.002
   Tarafdar Arundhati, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1989, DOI 10.1109/ICPR.2010.490
   Thomas S, 2015, PATTERN ANAL APPL, V18, P1003, DOI 10.1007/s10044-014-0433-3
   Toselli AH, 2016, INFORM SCIENCES, V370, P497, DOI 10.1016/j.ins.2016.07.063
   Phan TQ, 2013, IEEE I CONF COMP VIS, P569, DOI 10.1109/ICCV.2013.76
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang RM, 2015, NEUROCOMPUTING, V157, P153, DOI 10.1016/j.neucom.2015.01.023
   Wang T, 2012, INT C PATT RECOG, P3304
   Wshah S, 2014, PATTERN RECOGN, V47, P1039, DOI 10.1016/j.patcog.2013.09.019
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   YIN X, 1937, TPAMI, V37, P1930, DOI DOI 10.1109/TPAMI.2014.2388210
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Young SJ, 2000, CONSTRUCTION, V2009, P384
   Yu C, 2016, NEUROCOMPUTING, V175, P652, DOI 10.1016/j.neucom.2015.10.105
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zagoris K, 2017, IEEE T IMAGE PROCESS
   Zhang X, 2014, INT CONF FRONT HAND, P381, DOI 10.1109/ICFHR.2014.70
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
   Zhiwei Zhou, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P133, DOI 10.1109/ICPR.2010.41
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
NR 68
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7767
EP 7801
DI 10.1007/s11042-018-6484-5
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700061
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Nguyen, HD
   Na, IS
   Kim, SH
   Lee, GS
   Yang, HJ
   Choi, JH
AF Hai Duong Nguyen
   Na, In Seop
   Kim, Soo Hyung
   Lee, Guee Sang
   Yang, Hyung Jeong
   Choi, Jun Ho
TI Multiple human tracking in drone image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drone images; Faster R-CNN; Human tracking; Hungarian algorithm
AB Object tracking, especially human tracking is one of the challenging research problems in computer vision. Although the performance has gained some positive changes recently, there is still room for improvement. In this paper, we introduce an approach for human detection and tracking using Convolution Neural Network (CNN) and Hungarian Algorithm (HA). A CNN is used to localize multiple human beings from frame to frame in a video stream. This deep CNN is known as Faster R-CNN which achieved the state of the art performance in object detection problem. In the tracking process, we solve the data association problem in visual tracking using HA. A detected person will be assigned to a tracklet based on the data distribution in the video frame. The experimental results show that our system can deal with the videos captured from different scenarios in near real-time.
C1 [Hai Duong Nguyen; Kim, Soo Hyung; Lee, Guee Sang; Yang, Hyung Jeong] Chonnam Natl Univ, Sch Elect & Comp Engn, Gwangju, South Korea.
   [Na, In Seop] Chosun Univ, Software Convergence Educ Inst, Gwangju, South Korea.
   [Choi, Jun Ho] Chosun Univ, Div Undeclared Majors, Gwangju, South Korea.
C3 Chonnam National University; Chosun University; Chosun University
RP Na, IS (corresponding author), Chosun Univ, Software Convergence Educ Inst, Gwangju, South Korea.
EM nhduong_3010@live.com; ypencil@hanmail.net; shkim@jnu.ac.kr;
   gslee@jnu.ac.kr; hjyang@jnu.ac.kr; xdman@chosun.ac.kr
RI Yang, Hyung-Jeong/GXV-4819-2022; Na, In Seop/K-2508-2018
OI Na, In Seop/0000-0001-6471-043X
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2018R1A1A1A05022526, NRF-2017R1A4A1015559, NRF-2015R1D1A3A01019642]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT)
   (NRF-2018R1A1A1A05022526), (NRF-2017R1A4A1015559) and
   (NRF-2015R1D1A3A01019642).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.141
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2012, IEEE C COMP VIS PATT
   [Anonymous], 2016, IEEE T PATTERN ANAL
   [Anonymous], 2012, IEEE C COMP VIS PATT
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Betke M., 2016, Synthesis Lectures on Computer Vision, V6, P1, DOI [10.2200/S00726ED1V01Y201608COV009, DOI 10.2200/S00726ED1V01Y201608COV009]
   BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755
   Del Moral P., 1996, MARKOV PROCESS RELAT, V2, P555
   Gao H, 2013, IEEE SYMP COMMUN VEH
   Girshick R., 2014, P IEEE C COMP VIS PA, P580
   Grest D, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P387
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Harville M, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P3, DOI 10.1109/EVENT.2001.938860
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Muñoz-Salinas R, 2007, IMAGE VISION COMPUT, V25, P995, DOI 10.1016/j.imavis.2006.07.012
   Nguyen HT, 2006, INT J COMPUT VISION, V69, P277, DOI 10.1007/s11263-006-7067-x
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
NR 21
TC 9
Z9 9
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4563
EP 4577
DI 10.1007/s11042-018-6141-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200034
DA 2024-07-18
ER

PT J
AU Lee, J
   Seo, W
   Park, JH
   Kim, DW
AF Lee, Jaesung
   Seo, Wangduk
   Park, Jin-Hyeong
   Kim, Dae-Won
TI Compact feature subset-based multi-label music categorization for mobile
   devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music information retrieval; Mobile devices; Multi-label learning;
   Hybrid search
ID FEATURE-SELECTION; CLASSIFICATION; ALGORITHM
AB Music categorization based on acoustic features extracted from music clips and user-defined tags forms the basis of recent music recommendation applications, because relevant tags can be automatically assigned based on the feature values and their relation to tags. In practice, especially for handheld lightweight mobile devices, there is a certain limitation on the computational capacity, owing to consumers' usage behavior or battery consumption. This also limits the maximum number of acoustic features to be extracted, and results in the necessity of identifying a compact feature subset that is used for the music categorization process. In this study, we propose an approach to compact feature subset-based multi-label music categorization for mobile music recommendation services. Experimental results using various multi-labeled music datasets reveal that the proposed approach yields better performance when compared to conventional approach.
C1 [Lee, Jaesung; Seo, Wangduk; Park, Jin-Hyeong; Kim, Dae-Won] Chung Ang Univ, Seoul, South Korea.
C3 Chung Ang University
RP Kim, DW (corresponding author), Chung Ang Univ, Seoul, South Korea.
EM dwkim@cau.ac.kr
OI Lee, Jaesung/0000-0002-3757-3510
FU Chung-Ang University Research Scholarship Grants in 2018; Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   - Ministry of Science, ICT and Future Planning [NRF-2016R1C1B1014774]
FX This research was supported by the Chung-Ang University Research
   Scholarship Grants in 2018 and by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT and Future Planning (NRF-2016R1C1B1014774).
CR Bai JJ, 2016, INT J COGN INFORM NA, V10, P74, DOI 10.4018/IJCINI.2016100104
   Baltrunas L, 2011, LECT NOTES BUS INF P, V85, P89
   Blume H, 2011, IEEE SIGNAL PROC MAG, V28, P24, DOI 10.1109/MSP.2011.940880
   Cano A, 2016, INFORM SCIENCES, V330, P370, DOI 10.1016/j.ins.2015.10.032
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Doquire G, 2013, NEUROCOMPUTING, V122, P148, DOI 10.1016/j.neucom.2013.06.035
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Nguyen HB, 2016, EVOL INTELL, V9, P95, DOI 10.1007/s12065-016-0143-4
   Kaminskas M, 2011, LECT NOTES COMPUT SC, V6787, P183, DOI 10.1007/978-3-642-22362-4_16
   Kong DG, 2012, PROC CVPR IEEE, P2352, DOI 10.1109/CVPR.2012.6247947
   Lartillot O., 2007, P 10 INT C DIG AUD E, V237, P244, DOI DOI 10.1007/978-3-540-78246-9_31
   Lee J, 2015, LECT NOTES ELECT ENG, V330, P251
   Lee J, 2016, INFORM SCIENCES, V351, P101, DOI 10.1016/j.ins.2016.02.037
   Lee J, 2017, PATTERN RECOGN, V66, P342, DOI 10.1016/j.patcog.2017.01.014
   Lee J, 2015, PATTERN RECOGN, V48, P2761, DOI 10.1016/j.patcog.2015.04.009
   Lee J, 2015, INFORM SCIENCES, V293, P80, DOI 10.1016/j.ins.2014.09.020
   Liebman E, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS'15), P591
   Lin YJ, 2015, NEUROCOMPUTING, V168, P92, DOI 10.1016/j.neucom.2015.06.010
   Magalhaes-Mendes Jorge, 2013, WSEAS Transactions on Computers, V12, P164
   Min F, 2016, GRANULAR COMPUT, V1, P199, DOI 10.1007/s41066-016-0017-2
   Naula P, 2014, PATTERN RECOGN LETT, V40, P56, DOI 10.1016/j.patrec.2013.12.009
   Ness S.R., 2009, Proceedings of the ACM International Conference on Multimedia, P705, DOI 10.1145/1631272.1631393
   Papanikolaou Y, 2016, ARXIV161206083
   Read J, 2008, P 2008 NZ COMP SCI R, V143150, P41
   Spolaôr N, 2016, NEUROCOMPUTING, V180, P3, DOI 10.1016/j.neucom.2015.07.118
   Sun YM, 2009, INT J PATTERN RECOGN, V23, P687, DOI 10.1142/S0218001409007326
   Teng Y, 2013, 2013 IEEE INTERNATIONAL MULTI-DISCIPLINARY CONFERENCE ON COGNITIVE METHODS IN SITUATION AWARENESS AND DECISION SUPPORT (COGSIMA), P9, DOI 10.1109/CogSIMA.2013.6523817
   Xue B, 2016, IEEE T EVOLUT COMPUT, V20, P606, DOI 10.1109/TEVC.2015.2504420
   Yan Q, 2015, INT CONF ACOUST SPEE, P434, DOI 10.1109/ICASSP.2015.7178006
   Yang HQ, 2015, NEURAL NETWORKS, V71, P214, DOI 10.1016/j.neunet.2015.08.004
   Yin J, 2016, INT J ADV MANUF TECH, V83, P1847, DOI 10.1007/s00170-015-7609-x
   Yong Zhang, 2015, Advances in Swarm and Computational Intelligence - 6th International Conference, ICSI 2015, held in conjunction with the Second BRICS Congress, CCI 2015. Proceedings: LNCS 9140, P339, DOI 10.1007/978-3-319-20466-6
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang ML, 2015, IEEE T PATTERN ANAL, V37, P107, DOI 10.1109/TPAMI.2014.2339815
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhang ML, 2009, INFORM SCIENCES, V179, P3218, DOI 10.1016/j.ins.2009.06.010
   Zhang Y, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-00416-0
   Zhu ZX, 2007, IEEE T SYST MAN CY B, V37, P70, DOI 10.1109/TSMCB.2006.883267
   Zhu ZX, 2010, IEEE COMPUT INTELL M, V5, P41, DOI 10.1109/MCI.2010.936311
NR 39
TC 11
Z9 12
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4869
EP 4883
DI 10.1007/s11042-018-6100-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200049
DA 2024-07-18
ER

PT J
AU Sodhro, AH
   Sangaiah, AK
   Pirphulal, S
   Sekhari, A
   Ouzrout, Y
AF Sodhro, Ali Hassan
   Sangaiah, Arun Kumar
   Pirphulal, Sandeep
   Sekhari, Aicha
   Ouzrout, Yacine
TI Green media-aware medical IoT system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Green; Media transmission; MIoT; GMTA; VBR
ID CARE; CONSUMPTION; LIFETIME; INTERNET; SCHEME; POWER
AB Rapid proliferation in state-of-the art technologies has revolutionized the medical market for providing urgent, effective and economical health facilities to aging society. In this context media (i.e., video) transmission is considered as a quite significant step during first hour of the emergency for presenting a big and better picture of the event. However, the energy hungry media transmission process and slow progress in battery technologies have become a major and serious problem for the evolution of video technology in medical internet of things (MIoT) or internet of medical things (IoMT). So, promoting Green (i.e., energy-efficient) transmission during voluminous and variable bit rate (VBR) video in MIoT is a challenging and crucial problem for researchers and engineers. Therefore, the need arose to conduct research on Green media transmission techniques to cater the need of upcoming wearable healthcare devices. Thus, this research contributes in two distinct ways; first, a novel and sustainable Green Media Transmission Algorithm (GMTA) is proposed, second, a mathematical model and architecture of Green MIoT are designed by considering a 8-min medical media stream named, Navigation to the Uterine Horn, transection of the horn and re-anastomosis' to minimize transmission energy consumption in media-aware MIoT, and to develop feasible media transmission schedule for sensitive and urgent health information from physian to patients and vice vers through extremely power hungry natured wearable devices. The experimental results demonstrate that proposed GMTA saves energy up to 41%, to serve the community.
C1 [Sodhro, Ali Hassan] Sukkur IBA Univ, Elect Engn Dept, Sukkur, Sindh, Pakistan.
   [Sodhro, Ali Hassan; Sekhari, Aicha; Ouzrout, Yacine] Univ Lumiere Lyon 2, DISP LAB, Lyon, France.
   [Sangaiah, Arun Kumar] VIT Univ, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
   [Pirphulal, Sandeep] Chinese Acad Sci, SIAT, Shenzhen 518055, Peoples R China.
C3 Sukkur IBA University; Institut National des Sciences Appliquees de Lyon
   - INSA Lyon; Universite Lyon 2; Vellore Institute of Technology (VIT);
   VIT Vellore; Chinese Academy of Sciences; Shenzhen Institute of Advanced
   Technology, CAS
RP Sodhro, AH (corresponding author), Sukkur IBA Univ, Elect Engn Dept, Sukkur, Sindh, Pakistan.; Sodhro, AH (corresponding author), Univ Lumiere Lyon 2, DISP LAB, Lyon, France.; Pirphulal, S (corresponding author), Chinese Acad Sci, SIAT, Shenzhen 518055, Peoples R China.
EM ali.hassan@iba-suk.edu.pk; arunkumarsangaiah@gmail.com;
   sandeep@siat.ac.cn; aicha.sekhari@univ-lyon2.fr;
   yacine.ouzrout@univ-lyon2.fr
RI Sangaiah, Arun Kumar/U-6785-2019; Li, Wang/M-1612-2019; Sodhro, Ali
   Hassan/AAE-9467-2021; OUZROUT, Yacine/I-4679-2014; SEKHARI,
   AICHA/ITU-2654-2023; Sodhro, Ali Hassan/ABE-1975-2021
OI Sangaiah, Arun Kumar/0000-0002-0229-2460; Sodhro, Ali
   Hassan/0000-0001-5502-530X; OUZROUT, Yacine/0000-0002-8260-1111;
   SEKHARI, AICHA/0000-0002-1184-1433; Sodhro, Ali
   Hassan/0000-0001-5502-530X
CR Aborokbah MM, 2018, SUSTAIN CITIES SOC, V41, P919, DOI 10.1016/j.scs.2017.09.004
   [Anonymous], 2013, E HLTH TELECOMMUNICA
   [Anonymous], 2013, IFMBE C
   [Anonymous], 2014 CHIN INT C EL D
   [Anonymous], J IND INFORM INTEGRA
   [Anonymous], IEEE 11 C IND EL APP
   [Anonymous], 14 IEEE INT C NETW S
   Decker R., 2017, Advances in Internet of Things, V2017, P47
   Dimitrov DV, 2016, HEALTHC INFORM RES, V22, P156
   Gonzalez E, 2015, SENSORS-BASEL, V15, P11993, DOI 10.3390/s150511993
   Gope P, 2016, IEEE SENS J, V16, P1368, DOI 10.1109/JSEN.2015.2502401
   HAO YX, 2017, MDPI SENSOR, V17, DOI DOI 10.3390/S17071602
   Hassanalieragh M, 2015, 2015 IEEE 12TH INTERNATIONAL CONFERENCE ON SERVICES COMPUTING (SCC 2015), P285, DOI 10.1109/SCC.2015.47
   Jusak J, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION, NETWORKS AND SATELLITE (COMNETSAT), P75, DOI 10.1109/COMNETSAT.2016.7907420
   Kumar G, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/3243570
   Le NT, 2016, MOB INF SYST, V2016, DOI 10.1155/2016/2676589
   Martinez B, 2015, IEEE SENS J, V15, P5777, DOI 10.1109/JSEN.2015.2445094
   Mekonnen T, 2017, IEEE ACCESS, V5, P15848, DOI 10.1109/ACCESS.2017.2737078
   Militano L., 2015, EAI Endorsed Trans. Internet Things, V15, P15, DOI [10.4108/eai.26-10-2015.150598, DOI 10.4108/EAI.26-10-2015.150598]
   Mountney P, 2010, IEEE SIGNAL PROC MAG, V27, P14, DOI 10.1109/MSP.2010.936728
   Paul A, 2016, TELECOMMUN SYST, V62, P59, DOI 10.1007/s11235-015-9982-z
   Qiu T, 2017, IEEE COMMUN MAG, V55, P132, DOI 10.1109/MCOM.2017.1700033
   Sethi P, 2017, J ELECTR COMPUT ENG, V2017, DOI 10.1155/2017/9324035
   Shaikh FK, 2017, IEEE SYST J, V11, P983, DOI 10.1109/JSYST.2015.2415194
   Sodhro A.H., 2013, INDONES J ELECT ENG, V11, P3383
   Sodhro AH, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN ELECTRICAL ENGINEERING AND COMPUTATIONAL TECHNOLOGIES (ICIEECT)
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Sodhro AH, 2016, IET COMMUN, V10, P81, DOI 10.1049/iet-com.2015.0368
   Wind River System, 2015, CISC VIS NETW IND GL, P1
   Wu F, 2018, FUTURE GENER COMP SY, V82, P727, DOI 10.1016/j.future.2017.08.042
   Yoo MJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16071053
   Zhu C, 2015, IEEE ACCESS, V3, P2151, DOI 10.1109/ACCESS.2015.2497312
NR 32
TC 16
Z9 16
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3045
EP 3064
DI 10.1007/s11042-018-5634-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600020
DA 2024-07-18
ER

PT J
AU Xi, S
   Wu, CX
   Jiang, LH
AF Xi, Shang
   Wu, Chunxue
   Jiang, Linhua
TI Super resolution reconstruction algorithm of video image based on deep
   self encoding learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth learning; Self-coding learning; Video image; Super-resolution
   reconstruction; Algorithm; Experimental analysis; Framework
ID MINIMAX ESTIMATION
AB Super resolution reconstruction of video image is a research hotspot in the field of image processing, and it is widely used in video surveillance, image processing, criminal analysis and other fields. Super resolution image reconstruction can reconstruct a high resolution image from low resolution images, and this technology has become a research hotspot in the field of image processing. In recent years, deep learning has been developed rapidly in the field of multimedia processing, and image super resolution restoration technology based on deep learning has gradually become the mainstream technology. In view of the existing image super-resolution algorithm problems, such as more parameters, larger amount of calculation, longer training time, blurred image texture, we use the deep self-coding learning method to improve it. We analyze the advantages and disadvantages of the existing technology from the network type, network structure, training methods and so on, and sort out the development of the technology. The experimental results show that the improved network model achieves better super-resolution results, and the subjective visual effect and objective evaluation index are improved obviously, and the image sharpness and edge sharpness are improved obviously.
C1 [Xi, Shang] Univ Technol Sydney, Engn & IT, POB 123, Sydney, NSW 2007, Australia.
   [Wu, Chunxue; Jiang, Linhua] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai Key Lab Modern Opt Syst, Shanghai 200093, Peoples R China.
C3 University of Technology Sydney; University of Shanghai for Science &
   Technology
RP Jiang, LH (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai Key Lab Modern Opt Syst, Shanghai 200093, Peoples R China.
EM Jianglinhuahs@yandex.com
RI zhang, min/IYI-9869-2023; Yan, Jun/IXD-7801-2023
CR Abu Alsheikh M, 2016, IEEE NETWORK, V30, P22, DOI 10.1109/MNET.2016.7474340
   [Anonymous], 2010, ACM T GRAPHIC
   Chen LJ, 2015, CLUSTER COMPUT, V18, P517, DOI 10.1007/s10586-015-0422-3
   Harris J., 2016, Proceedings of Society for Information Technology Teacher Education International Conference, P2864
   Jiao JT, 2016, IEEE INT SYMP INFO, P750
   Jiao JT, 2015, IEEE T INFORM THEORY, V61, P2835, DOI [10.1109/TIT.2015.2412945, 10.1109/tit.2015.2412945]
   Monteiro A, 2017, CLUSTER COMPUT, V20, P621, DOI 10.1007/s10586-017-0727-5
   Tran NH, 2017, P NATL ACAD SCI USA, V114, P8247, DOI 10.1073/pnas.1705691114
   Peng CL, 2017, IEEE T PATTERN ANAL, V39, P301, DOI 10.1109/TPAMI.2016.2542816
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Seide F, 2017, COD GEN OPT CGO 2017, pxi
   Van Essen B, 2015, CLUSTER COMPUT, V18, P15, DOI 10.1007/s10586-013-0309-0
   Zhang KB, 2015, IEEE T IMAGE PROCESS, V24, P846, DOI 10.1109/TIP.2015.2389629
   Zhang SW, 2017, CLUSTER COMPUT, V20, P1517, DOI 10.1007/s10586-017-0859-7
   Zhou QY, 2016, CLUSTER COMPUT, V19, P1275, DOI 10.1007/s10586-016-0580-y
NR 15
TC 10
Z9 10
U1 5
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4545
EP 4562
DI 10.1007/s11042-018-6062-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200033
DA 2024-07-18
ER

PT J
AU Ma, N
   Zhao, SC
   Sun, Z
   Wu, XP
   Zhai, Y
AF Ma, Nan
   Zhao, Sicheng
   Sun, Zhen
   Wu, Xiuping
   Zhai, Yun
TI An improved ridge regression algorithm and its application in predicting
   TV ratings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ridge regression; Least Square method; TV ratings
AB U Ridge regression is a biased estimated regressive method, which is traditionally used in collinearity data analysis. It is actually a modified Least Square method, which gains more rational and reliable regression coefficient by giving up the unbiasedness of Least Squares Estimation, reducing partial information and decreasing accuracy to overcome the over-fitting problems. This article presents an improved ridge regression algorithm and utilizes it to predict the audience rating for TV ratings. It is tested by 10 - fold Cross Validation. TV rating is an important indication to measure the quality and user experience, as well as one of the vital standards to state the value of a TV channel. The improved ridge regression algorithm is used to learn the model of weight matrix, which is trained by the error algorithm to predict the TV ratings. The extensive experimental results demonstrate the effectiveness of the proposed algorithm.
C1 [Ma, Nan; Wu, Xiuping] Beijing Union Univ, Coll Robot, Beijing 100101, Peoples R China.
   [Zhao, Sicheng] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
   [Sun, Zhen] Beijing Union Univ, Coll Informat Technol, Beijing 100101, Peoples R China.
   [Zhai, Yun] Chinese Acad Governance, E Govt Res Ctr, Beijincpg 100089, Peoples R China.
C3 Beijing Union University; Tsinghua University; Beijing Union University
RP Zhao, SC (corresponding author), Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
EM schzhao@gmail.com
RI Zhang, Yuyao/KEH-7175-2024; Cheng, Lin/KFQ-3111-2024
FU National Natural Science Foundation of China [61672178, 61601458,
   61701273, 91420202]; China Postdoctoral Science Foundation [2017
   M610897]
FX This work is supported by the National Natural Science Foundation of
   China (Nos. 61672178, 61601458, 61701273 and 91420202) and the Project
   Funded by China Postdoctoral Science Foundation (No. 2017 M610897). The
   authors would also like to thank the anonymous reviewers for their
   constructive suggestions to improve the paper.
CR Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986
   Chen MH, 2017, AAAI CONF ARTIF INTE, P3981
   Chen Q, 2011, XIAN TECHNOLOGICAL U, V31, P535
   Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421
   Gao Y, 2015, LECT NOTES COMPUT SC, V9350, P78, DOI 10.1007/978-3-319-24571-3_10
   Gu YF, 2016, IEEE T GEOSCI REMOTE, V54, P3235, DOI 10.1109/TGRS.2015.2514161
   He X, 2005, MULTIVARIATE LINEAR, P16
   Hu H, 2017, IEEE J SEL AREA COMM, V35, P935, DOI 10.1109/JSAC.2017.2676598
   Hu H, 2017, IEEE J SEL AREA COMM, V35, P545, DOI 10.1109/JSAC.2017.2659478
   [李勇周 LI Yong-Zhou], 2010, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V23, P23
   Luo L, 2017, IEEE T NEUR NET LEAR, V28, P2168, DOI 10.1109/TNNLS.2016.2573644
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Nie WZ, 2016, MULTIMEDIA SYST, V22, P75, DOI 10.1007/s00530-014-0394-9
   Wu L, 2011, COMMUNICATION U CHIN, V18, P59
   Xiao Q, 2015, VIDEO ENG, V4
   Xing Y, 2005, JIANGSU SOCIAL SCI, V3, P257
   Yue Gao, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P269, DOI 10.1007/978-3-319-14445-0_24
   Zhang LY, 2017, J NUTR BIOCHEM, V44, P1, DOI 10.1016/j.jnutbio.2016.11.010
   Zhao SC, 2020, IEEE T AFFECT COMPUT, V11, P574, DOI [10.1109/TAFFC.2018.2818685, 10.1109/TAFFC.2016.2628787]
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
NR 21
TC 6
Z9 7
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 525
EP 536
DI 10.1007/s11042-017-5250-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500029
DA 2024-07-18
ER

PT J
AU Yin, MX
   Lang, CY
   Li, Z
   Feng, SH
   Wang, T
AF Yin, Mengxia
   Lang, Congyan
   Li, Zun
   Feng, Songhe
   Wang, Tao
TI Recurrent convolutional network for video-based smoke detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smoke detection; Motion context information; Deep convolution; RNNs
ID IMAGE
AB Video-based smoke detection plays an important role in the fire detection community. Such interesting topic, however, always suffers from great challenge due to the large variances of smoke texture, shape and color in the real applications. To effectively exploiting the long-range motion context, we propose a novel video-based smoke detection method via Recurrent Neural Networks (RNNs). More concretely, the proposed method first captures the space and motion context information by using deep convolutional motion-space networks. Then a temporal pooling layer and RNNs are used to effectively train the smoke model. Finally, to promote further research and evaluation of video-based smoke models, we also construct a new large database of 3000 challenging smoke video clips that cover large variations in illuminance and weather conditions. Experimental results demonstrate that our proposed method is capable of achieving state-of-the-art performance on all public benchmarks.
C1 [Yin, Mengxia; Lang, Congyan; Feng, Songhe; Wang, Tao] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
   [Li, Zun] Beijing Jiaotong Univ, Beijing, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Lang, CY (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
EM 18813172300@163.com; cylang@bjtu.edu.cn
CR [Anonymous], IEEE INT C MULT EXP
   [Anonymous], J COMPUT INF SYST
   [Anonymous], 2015, J ELECT COMPUT ENG
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], EUR C COMP VIS
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], INT J COMPUTER SCI I
   [Anonymous], 2013, 2013 Visual communications and image processing
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.532
   [Anonymous], 2014, INT C LEARN REPR
   [Anonymous], IEICE TECHNICAL REPO
   [Anonymous], 2012, INT WORKSHOP MULTISE
   Antipov G, 2016, IEEE COMPUT SOC CONF, P801, DOI 10.1109/CVPRW.2016.105
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P860, DOI 10.1109/TIP.2012.2219543
   Bao BK, 2012, IEEE T IMAGE PROCESS, V21, P3794, DOI 10.1109/TIP.2012.2192742
   Barmpoutis P, 2014, EUR SIGNAL PR CONF, P1078
   Chen TH, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P427
   Cui Y, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P95, DOI 10.1109/CISP.2008.397
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Ko B, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.1.017208
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krstinic D, 2009, INF TECHNOL CONTROL, V38, P237
   Liu S., 2016, ARXIV160407102, P2568
   Lu JW, 2015, PROC CVPR IEEE, P1137, DOI 10.1109/CVPR.2015.7298717
   Maruta H, 2010, PROC IEEE INT SYMP, P1550, DOI 10.1109/ISIE.2010.5636301
   Millan-Garcia L, 2012, SENSORS-BASEL, V12, P5670, DOI 10.3390/s120505670
   Park J, 2013, IEEE WORK APP COMP, P200, DOI 10.1109/WACV.2013.6475019
   Tian HD, 2014, INT J COMPUT VISION, V106, P192, DOI 10.1007/s11263-013-0656-6
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Tian YL, 2015, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2015.7299143
   Toreyin B. Ugur, 2005, 2005 13th European Signal Processing Conference, P1
   Vezzani R., 2008, Proceedings of the 2008 International Conference on Content-based Image and Video Retrieval, P289, DOI DOI 10.1145/1386352.1386392
   Wu JJ, 2015, PROC CVPR IEEE, P3460, DOI 10.1109/CVPR.2015.7298968
   Yuan F, 2008, PATTERN RECOGN LETT, V29, P925, DOI 10.1016/j.patrec.2008.01.013
   Yuan FN, 2015, IET IMAGE PROCESS, V9, P849, DOI 10.1049/iet-ipr.2014.1032
   Yuan FN, 2011, FIRE SAFETY J, V46, P132, DOI 10.1016/j.firesaf.2011.01.001
   Zhu Z, 2016, PROC CVPR IEEE, P2110, DOI 10.1109/CVPR.2016.232
NR 37
TC 40
Z9 47
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 237
EP 256
DI 10.1007/s11042-017-5561-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500013
DA 2024-07-18
ER

PT J
AU Zhang, WD
   He, BX
   Chen, YF
   Zhang, QF
AF Zhang, Weidong
   He, Boxin
   Chen, Yifeng
   Zhang, Qifei
TI GMR: graph-compatible MapReduce programming model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed systems; Parallel architectures; Graph theory; Systems
   programs and utilities; Performance analysis and design aids; Concurrent
   programming; Modes of computation; Performance of systems
AB The MapReduce programming model is widely used to parallelize data processing over the large scale of commodity computer clusters. However, on account of its monotonous data representation, it fails to express graph-parallel algorithms naturally and execute them efficiently. Alternatively, Pregel and PowerGraph could address these challenges. But they require users to familiarize another set of programming patterns and platforms, and at the same time the legacy MapReduce code also becomes incompatible and useless. In this paper, we proposed the Graph-compatible MapReduce (GMR) as an extension of Google's Standard MapReduce (SMR). In this way, graph-parallel algorithm will be naturally expressed without compromising the efficiency and simplicity, and meanwhile the conventional MapReduce programming pattern be preserved. Also, users could gain the convenience of Think like a vertex. Based on the experimental studying, we analyzed the ratio of the redundant computation, transmission and data caching introduced in naive iterative MapReduce platforms (e.g., HaLoop, Twister). Furthermore, we discussed the difference between GMR and the graph-targeted frameworks. The evaluation experiment results show that GMR outperforms GraphX in a series of real-world graph-parallel algorithms.
C1 [Zhang, Weidong; He, Boxin; Chen, Yifeng] Peking Univ, Beijing, Peoples R China.
   [Zhang, Qifei] Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.
C3 Peking University; Zhejiang University
RP Zhang, WD (corresponding author), Peking Univ, Beijing, Peoples R China.
EM zhangwd@pku.edu.cn; heboxin@pku.edu.cn; cyf@pku.edu.cn;
   zhangqf@cst.zju.edu.cn
RI Chen, yf/JMR-4435-2023
FU Zhejiang Engineering Research Center of Intelligent Medicine
   [2016E10011]
FX Our thanks to the Institute of Process Engineering, Chinese Academy of
   Science for their help. This research was supported by the Zhejiang
   Engineering Research Center of Intelligent Medicine(2016E10011) and the
   research and application of key technologies for rapid individualized
   sculpture manufacture and carving stone materials appraisal.
CR [Anonymous], 2010, P 19 ACM INT S HIGH, DOI DOI 10.1145/1851476.1851593
   [Anonymous], 2013, P INT ACM C MULTIMED, DOI DOI 10.1145/2502081.2502093
   Beierlein F, 2005, COMPUTER SIMULATIONS, P245
   Bu YY, 2010, PROC VLDB ENDOW, V3, P285
   Buluç A, 2009, SPAA'09: PROCEEDINGS OF THE TWENTY-FIRST ANNUAL SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, P233
   Cherkassky BV, 1996, MATH PROGRAM, V73, P129, DOI 10.1007/BF02592101
   Dean Jeffrey, 2009, COMMUN ACM, V51, P107
   Elgohary Ahmed., 2012, Stateful MapReduce
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2015, NEUROCOMPUTING, V151, P554, DOI 10.1016/j.neucom.2014.06.085
   Gonzalez Joseph E., 2012, P 10 USENIX S OP SYS, P17
   GUATTERY S, 1995, PROCEEDINGS OF THE SIXTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P233
   Karypis G, 1998, J PARALLEL DISTR COM, V48, P96, DOI 10.1006/jpdc.1997.1404
   Karypis G., 1998, International Cryogenics Monograph, P121
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Lv Q, 2007, P 33 INT C VER LARG, P950
   Malewicz Grzegorz, 2009, SIGMOD, P135
   Miller F, 1993, P BCS PAR PROC SPEC, P100
   Nie WZ, 2016, J VIS COMMUN IMAGE R, V37, P40, DOI 10.1016/j.jvcir.2015.06.011
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Nie WZ, 2016, IMAGE VISION COMPUT, V55, P109, DOI 10.1016/j.imavis.2016.04.011
   SAVAGE JE, 1991, J PARALLEL DISTR COM, V13, P257, DOI 10.1016/0743-7315(91)90074-J
   Weilenmann M, 2012, CATAL TODAY, V188, P121, DOI 10.1016/j.cattod.2011.10.002
   Xin Reynold S, 2013, INT WORKSH GRAPH DAT, P1, DOI DOI 10.1145/2484425.2484427
   Yang J, 2015, KNOWL INF SYST, V42, P181, DOI 10.1007/s10115-013-0693-z
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang HW, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P325, DOI 10.1145/2911451.2911502
   Zhang HW, 2014, IEEE T IMAGE PROCESS, V23, P2996, DOI 10.1109/TIP.2014.2325784
   Zhang YF, 2012, J GRID COMPUT, V10, P47, DOI 10.1007/s10723-012-9204-9
NR 30
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 457
EP 475
DI 10.1007/s11042-017-5102-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500024
DA 2024-07-18
ER

PT J
AU Kondylidis, N
   Tzelepi, M
   Tefas, A
AF Kondylidis, Nikolaos
   Tzelepi, Maria
   Tefas, Anastasios
TI Exploiting tf-idf in deep Convolutional Neural Networks for Content
   Based Image Retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content Based Image Retrieval; Deep Convolutional Neural Networks;
   TF-IDF
AB In this paper, a novel term frequency-inverse document frequency (tf-idf) based method that utilizes deep Convolutional Neural Networks (CNN) for Content Based Image Retrieval (CBIR) is proposed. That is, we treat the learned filters of the convolutional layers of a CNN model as detectors of visual words. Each of these filters has been trained to be activated in different visual patterns. Thus, since the activations of each filter provide information about the degree of presence of the visual pattern that the filter has learned during the training procedure, we consider the activations of these filters as the tf part. Subsequently, we propose three approaches of computing the idf part. Finally, we propose a query expansion technique on top of the formulated descriptors. The proposed approach interconnects the standard tf-idf method with the modern CNN analysis for visual content, providing a very powerful image retrieval technique with improved results as it is highlighted by extensive experiments in four challenging image datasets.
C1 [Kondylidis, Nikolaos; Tefas, Anastasios] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki, Greece.
   [Tzelepi, Maria] Aristotle Univ Thessaloniki, Dept Informat, Artificial Intelligence & Informat Anal Lab, Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki; Aristotle University of
   Thessaloniki
RP Tzelepi, M (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Artificial Intelligence & Informat Anal Lab, Thessaloniki, Greece.
EM kondilidisnikos@gmail.com; kondilidisnikos@gmail.com;
   tefas@aiia.csd.auth.gr
RI Tefas, Anastasios/ABA-2328-2020; Tefas, Anastasios/F-1899-2010
OI Tefas, Anastasios/0000-0003-1288-3667
FU General Secretariat for Research and Technology (GSRT); Hellenic
   Foundation for Research and Innovation (HFRI) [2826]
FX Maria Tzelepi was supported by the General Secretariat for Research and
   Technology (GSRT) and the Hellenic Foundation for Research and
   Innovation (HFRI) (PhD Scholarship No. 2826).
CR [Anonymous], 2016, P IEEE C COMP VIS PA
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Baeza-Yates R., 1999, MODERN INFORM RETRIE, V463
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Datta R, 2005, P 7 ACM SIGMM INT WO, P153, DOI [DOI 10.1145/1101826.1101866, 10.1145/1101826.1101866]
   Deng L, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/atsip.2013.9
   Donahue J., 2013, Decaf: A deep convolutional activation feature for generic visual recognition
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Hinami R, 2017, ARXIV170909106
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2014, PROC CVPR IEEE, P3310, DOI 10.1109/CVPR.2014.417
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   KATO T, 1992, P SOC PHOTO-OPT INS, V1662, P112, DOI 10.1117/12.58497
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1990, NeurIPS, P396
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Liu ZQ, 2016, NEUROCOMPUTING, V173, P1183, DOI 10.1016/j.neucom.2015.08.076
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mayron LM, 2008, IMAGE RETRIEVAL USIN
   Mohedano E., 2016, ARXIV160404653
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009
   Philbin J, 2008, PROC CVPR IEEE, P2285
   Razavian A. S., 2016, ITE Trans. Media Technol. Appl., V4, P251, DOI [DOI 10.3169/MTA.4.251, 10.3169/mta.4.251]
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tolias G., 2015, ARXIV151105879
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Tzelepi M, 2018, NEUROCOMPUTING, V275, P2467, DOI 10.1016/j.neucom.2017.11.022
   Tzelepi M, 2016, INT C PATT RECOG, P2918, DOI 10.1109/ICPR.2016.7900080
   Voorhees E.M., 1985, SIGIR '85 Proceedings of the 8th annual international ACM SIGIR conference on Research and development in information retrieval, P188, DOI [DOI 10.1145/253495.253524, 10.1145/253495.253524]
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Yu W, 2017, NEUROCOMPUTING, V237, P235, DOI 10.1016/j.neucom.2016.12.002
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhao WL, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.99
NR 46
TC 13
Z9 15
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30729
EP 30748
DI 10.1007/s11042-018-6212-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600027
DA 2024-07-18
ER

PT J
AU Liu, B
   Ma, YB
   Pei, Y
   Wang, C
   Wan, C
AF Liu, Bin
   Ma, Yubo
   Pei, Yu
   Wang, Chao
   Wan, Chao
TI A computer assisted automatic grenade throw training system with simple
   digital cameras
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Grenade throwing; Military training; Camera video frame; Virtual 3D
   scene; Real-time system
ID TRACKING; OBJECTS
AB Grenade throwing is a routine military training and testing subject among many armies of the world. However, the conventional manual measurement mode has many defects: poor efficiency, large training field needing and important data losing. So how to utilize simple device and simple method framework to replace the actual test procedure becomes an interesting issue. In this paper, we present a real-time computer assisted grenade throwing training system by simple digital camera and low-cost computational methods. In this system, firstly, the marked grenade is extracted from the camera video frames; Secondly, a linked list is generated to store the grenade pixel coordinate; Thirdly, after a transformation from image space to real space, the instantaneous velocity of throwing (initial speed) can be computed; Lastly, a virtual 3D scene is established to demonstrate the training activity. By using this system, an overall throwing result data (distance, height, throwing angle, throwing speed and ballistic trajectory) can be obtained. The most significant novelty of our application is achieving a real-time computer assisted grenade throwing training system by simple and low-cost computational methods. In addition, we proposed a specialized self-adapted color enhancement method in the system. This computation strategy may provide some enlightenments for other research work. From the test data of several hurlers, it can be seen that the effectiveness and the accuracy of this training system are favorable. This system may provide technical support for the modern military throwing training and may change the traditional manual measuring mode for grenade throwing.
C1 [Liu, Bin; Ma, Yubo; Pei, Yu; Wang, Chao] Dalian Univ Technol, Int Sch Informat Sci & Engn DUT RUISE, Dalian, Peoples R China.
   [Liu, Bin] Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian 116620, Liaoning, Peoples R China.
   [Wan, Chao] Peoples Liberat Army, Clin Dept 403, Dalian 116021, Liaoning, Peoples R China.
C3 Dalian University of Technology
RP Wan, C (corresponding author), Peoples Liberat Army, Clin Dept 403, Dalian 116021, Liaoning, Peoples R China.
EM chaowan_pla@163.com
RI Pei, Yu/GRI-9837-2022; Liu, Kehan/HNR-8833-2023; Pei, Yu/JJD-3994-2023
OI Pei, Yu/0000-0001-6065-6958; 
FU National Natural Science Foundation of China [61572101, 61300085];
   Scientific Research Fund of Liaoning Provincial Education Department of
   China [L2013012]; Fundamental Research Funds for the Central
   Universities of China [DUT14QY18]
FX This work is supported by the National Natural Science Foundation of
   China (Nos. 61572101, 61300085), the Scientific Research Fund of
   Liaoning Provincial Education Department of China (No. L2013012) and the
   Fundamental Research Funds for the Central Universities of China (No.
   DUT14QY18). Thanks to Prof. Bingbing Zhang, Ms. Xiuyan Peng and Mr.
   Yuxiang Liu for providing training ground and training device and for
   help with camera calibration.
CR Abulrub AHG, 2013, PROCD SOC BEHV, V75, P328, DOI 10.1016/j.sbspro.2013.04.037
   Chen C, 2016, J REAL-TIME IMAGE PR, V12, P155, DOI 10.1007/s11554-013-0370-1
   Cho K, 2011, COMPUT ANIMAT VIRT W, V22, P529, DOI 10.1002/cav.431
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Dardas NH, 2012, MULTIMED TOOLS APPL, P1
   Foley J.D., 1982, Fundamentals of interactive computer graphics
   Jordt A, 2013, INT J COMPUT VISION, V102, P239, DOI 10.1007/s11263-012-0572-1
   김민혁, 2014, [Journal of Korea Game Society, 한국게임학회 논문지], V14, P79, DOI 10.7583/JKGS.2014.14.5.79
   Korosec D, 2005, COMPUT METH PROG BIO, V80, pS61, DOI 10.1016/S0169-2607(05)80007-0
   Lampert CH, 2012, J REAL-TIME IMAGE PR, V7, P31, DOI 10.1007/s11554-010-0168-3
   Liang JS, 2012, COMPUT APPL ENG EDUC, V20, P553, DOI 10.1002/cae.20424
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Löcken A, 2012, MULTIMEDIA SYST, V18, P15, DOI 10.1007/s00530-011-0240-2
   Lok B., 2006, Virtual Reality, V10, P185, DOI [10.1007/s10055-006-0037-3, DOI 10.1007/S10055-006-0037-3]
   Ma ZG, 2014, INT J COMPUT VISION, V109, P60, DOI 10.1007/s11263-014-0717-5
   Mettin U, 2008, INTEL SERV ROBOT, V1, P289, DOI 10.1007/s11370-008-0027-2
   Nielsen M, 2003, LECT NOTES ARTIF INT, V2915, P409
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Rudoy D, 2012, INT J COMPUT VISION, V97, P243, DOI 10.1007/s11263-011-0484-5
   Saba T, 2013, APPL ARTIF INTELL, V27, P656, DOI 10.1080/08839514.2013.787779
   Shen Y, 2012, VIRTUAL REAL-LONDON, V16, P161, DOI 10.1007/s10055-011-0194-x
   Sun HM, 2009, COMPUT EDUC, V53, P1231, DOI 10.1016/j.compedu.2009.06.006
   Trigueiros P, 2014, IEEE INT CONF AUTON, P175, DOI 10.1109/ICARSC.2014.6849782
   Yeo HS, 2015, MULTIMED TOOLS APPL, V74, P2687, DOI 10.1007/s11042-013-1501-1
   Zhang GF, 2006, COMPUT ANIMAT VIRT W, V17, P305, DOI 10.1002/cav.134
   Zhang YJ, 2011, COMPUT ANIMAT VIRT W, V22, P499, DOI 10.1002/cav.427
   Zhu YM, 2014, IEEE IJCNN, P3240, DOI 10.1109/IJCNN.2014.6889481
NR 32
TC 1
Z9 1
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31693
EP 31712
DI 10.1007/s11042-018-6183-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000008
DA 2024-07-18
ER

PT J
AU Rao, TYS
   Reddy, PC
AF Rao, Thiriveedhi Yellamanda Srinivasa
   Reddy, Pakanati Chenna
TI Content and context based image retrieval classification based on
   firefly-neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scaling invariant feature transform; Fuzzy C-means clustering; Active
   appearance model; Shape surface plot; Modified neural network; Squared
   Euclidian distance
ID FEATURES; QUERY
AB In this study presents an improved classification and feature reduction techniques are newly introduced in our proposed search area of image retrieval. Especially we are including a shape feature that has been so active and successful in the past few years. In our proposed approach the texture feature is extracted by using improved multi texton technique and GLCM technique and the textual features are keywords, annotations. The Visual features are extracted with the aid of a bag of visual words (BOW) also it can be approved by employ Scaling Invariant Feature Transform (SIFT) and Fuzzy C-Means Clustering technique the features are edge detection, corner detection. Improving a performance and accuracy newly we are including a shape based features the features are Active Appearance Model (AAM) and shape surface plot (SURF). In the second phase, we are including feature reduction method is applied to reduce the features' space without losing the accuracy of classification in this reduction phases we are including an OLPP technique to perform a feature reduction phases. After that, the images are classified with the aid of modified neural network algorithm. This will classify the images in the different class in order to improve the precision and recall rate. After classification, we are including a squared Euclidian distance method to retrieve minimum distance image the similar images are retrieved from the relevant class as per the given query image.
C1 [Rao, Thiriveedhi Yellamanda Srinivasa] JNTUK, Dept Comp Sci & Engn, Kakinada, AP, India.
   [Reddy, Pakanati Chenna] JNTU, Dept Comp Sci & Engn, Anantapur, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Kakinada; Jawaharlal Nehru
   Technological University - Anantapur
RP Rao, TYS (corresponding author), JNTUK, Dept Comp Sci & Engn, Kakinada, AP, India.
EM tysr_crl@yahoo.co.in
RI Reddy, P. Chenna/ABG-7367-2020
OI Reddy, P. Chenna/0000-0001-5348-8028; T, srinivasa
   rao/0000-0002-6263-2666
CR Aggarwal G, 2002, IEEE T MULTIMEDIA, V4, P201, DOI 10.1109/TMM.2002.1017734
   Banerjee M, 2009, FUZZY SET SYST, V160, P3323, DOI 10.1016/j.fss.2009.02.024
   Baroffio L, 2014, IEEE T IMAGE PROCESS, V23, P2262, DOI 10.1109/TIP.2014.2312617
   Bhaumika H, 2016, ELSEVIER J APPL SOFT, V46, P1008, DOI [10.1016/j.asoc.2016.03.022, DOI 10.1016/J.ASOC.2016.03.022]
   Chu LY, 2013, IEEE T MULTIMEDIA, V15, P1982, DOI 10.1109/TMM.2013.2270455
   Das Gupta R, 2013, PATTERN RECOGN, V46, P3256, DOI 10.1016/j.patcog.2013.05.026
   Gosselin PH, 2008, IEEE T IMAGE PROCESS, V17, P1200, DOI 10.1109/TIP.2008.924286
   Pedronette DCG, 2014, INFORM SCIENCES, V265, P91, DOI 10.1016/j.ins.2013.12.030
   Jiang W, 2006, IEEE T IMAGE PROCESS, V15, P702, DOI 10.1109/TIP.2005.863105
   Lehmann TM, 2005, COMPUT MED IMAG GRAP, V29, P143, DOI 10.1016/j.compmedimag.2004.09.010
   Lu YJ, 2010, IEEE T MULTIMEDIA, V12, P288, DOI 10.1109/TMM.2010.2046292
   Papadias D, 2003, IEEE T MULTIMEDIA, V5, P210, DOI 10.1109/TMM.2003.811629
   Papushoy A, 2015, DIGIT SIGNAL PROCESS, V36, P156, DOI 10.1016/j.dsp.2014.09.005
   Raveaux R, 2013, J VIS COMMUN IMAGE R, V24, P1252, DOI 10.1016/j.jvcir.2013.08.010
   Squicciarini AC, 2015, IEEE T KNOWL DATA EN, V27, P193, DOI 10.1109/TKDE.2014.2320729
   Wang XJ, 2012, P IEEE, V100, P2705, DOI 10.1109/JPROC.2012.2193109
   Wen Wang, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163138
   Wu JK, 1997, IEEE T KNOWL DATA EN, V9, P978, DOI 10.1109/69.649320
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Xie LX, 2014, IEEE T IMAGE PROCESS, V23, P1994, DOI 10.1109/TIP.2014.2310117
   Yang Y, 2013, IEEE T GEOSCI REMOTE, V51, P818, DOI 10.1109/TGRS.2012.2205158
   Yu F, 2018, P ICLR WORKSH
   Zhang LN, 2016, IEEE T IMAGE PROCESS, V25, P1275, DOI 10.1109/TIP.2016.2516947
   Zhang LN, 2012, IEEE T IMAGE PROCESS, V21, P3707, DOI 10.1109/TIP.2012.2195014
NR 24
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 32041
EP 32062
DI 10.1007/s11042-018-6224-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000024
DA 2024-07-18
ER

PT J
AU Vieira, RT
   Negri, TT
   Gonzaga, A
AF Vieira, Raissa Tavares
   Negri, Tamiris Trevisan
   Gonzaga, Adilson
TI Improving the classification of rotated images by adding the signal and
   magnitude information to a local texture descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local descriptors; Rotated textures; Interpolation methods; Image
   analysis
ID BINARY PATTERN; FEATURES; SCALE; RADON
AB Texture image classification, especially for images with substantial changes in rotation, illumination, scale and point of view, is a fundamental and challenging problem in the field of computer vision. Natural images acquired under uncontrolled environments have textures with unknown orientation angles. Therefore, it is difficult to identify the same known texture at different acquisition angles. A common solution is image rotation by means of an interpolation technique. However, texture descriptors are not effective enough when two similar textures acquired at different angles are compared. In this work, we propose a simple and efficient image descriptor, called Completed Local Mapped Pattern (CLMP), and apply it to the texture classification of rotated images. This new approach is an improvement over the previously published Local Mapped Pattern (LMP) descriptor because the new approach includes the signal and the magnitude information. This innovation is more discriminating and robust for the description of rotated textures at arbitrary angles. We used two image datasets to validate the proposed descriptor: the Kylberg Sintorn Rotation Dataset and the Brodatz Texture Rotation Dataset. We also introduced a new texture dataset, which contains rotated texture images from Brodatz's Album. The database contains images of natural textures that have been rotated by both hardware and interpolation methods. We presented an evaluation of the influence of the interpolation method on image rotation, compared with different descriptors in the literature. The experimental results show that our proposed CLMP descriptor outperforms the widely used Completed Local Binary Pattern (CLBP) descriptor and the recently published Sampled Local Mapped Pattern Magnitude (SLMP_M) descriptor. Our results also demonstrate that the choice of interpolation method influences the descriptive capability of each descriptor.
C1 [Vieira, Raissa Tavares; Negri, Tamiris Trevisan; Gonzaga, Adilson] Univ Sao Paulo, Dept Elect & Comp Engn, Sao Carlos, SP, Brazil.
   [Negri, Tamiris Trevisan] Fed Inst Educ, Sci & Technol Sao Paulo, Araraquara, Brazil.
C3 Universidade de Sao Paulo; Instituto Federal de Sao Paulo (IFSP)
RP Gonzaga, A (corresponding author), Univ Sao Paulo, Dept Elect & Comp Engn, Sao Carlos, SP, Brazil.
EM agonzaga@sc.usp.br
RI Gonzaga, Adilson/B-4883-2010
OI Gonzaga, Adilson/0000-0003-2193-9394
FU Sao Paulo Research Foundation (FAPESP) [2015/20812-5]; Fundacao de
   Amparo a Pesquisa do Estado de Sao Paulo (FAPESP) [15/20812-5] Funding
   Source: FAPESP
FX The authors would like to thank the Sao Paulo Research Foundation
   (FAPESP), grant #2015/20812-5, for the financial support of this
   research.
CR Andrearczyk V, 2016, PATTERN RECOGN LETT, V84, P63, DOI 10.1016/j.patrec.2016.08.016
   Arivazhagan S, 2006, PATTERN RECOGN LETT, V27, P1976, DOI 10.1016/j.patrec.2006.05.008
   Brodatz P, 1966, DOVER PUBNS
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Charalampidis D, 2002, IEEE T IMAGE PROCESS, V11, P825, DOI 10.1109/TIP.2002.801117
   Chen C, 2016, SIGNAL IMAGE VIDEO P, V10, P745, DOI 10.1007/s11760-015-0804-2
   CIMPOI M, 2015, PROC CVPR IEEE, P3828, DOI DOI 10.1109/CVPR.2015.7299007
   Deng HW, 2004, IEEE T PATTERN ANAL, V26, P951, DOI 10.1109/TPAMI.2004.30
   Dharmagunawardhana C, 2016, PATTERN RECOGN LETT, V69, P15, DOI 10.1016/j.patrec.2015.10.006
   Do MN, 2002, IEEE T MULTIMEDIA, V4, P517, DOI 10.1109/TMM.2002.802019
   Fernández A, 2011, MACH VISION APPL, V22, P913, DOI 10.1007/s00138-010-0253-4
   Ferraz CT, 2014, P 29 ANN ACM S APPL, P39, DOI DOI 10.1145/2554850.2554895
   Ferreira CA., 2016, O movimento logico historico como possibilidade metodologica na formacao do conceito de Calculo Diferencial e Integral, P1
   Guo ZH, 2012, NEURAL COMPUT APPL, V21, P1893, DOI 10.1007/s00521-011-0586-6
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Hang C, 2015, 2015 11TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO), P223, DOI 10.1109/ICENCO.2015.7416352
   Hongliang Jin, 2004, Proceedings. Third International Conference on Image and Graphics, P306
   Huang J, 2010, NEUROCOMPUTING, V73, P883, DOI 10.1016/j.neucom.2009.09.016
   Jafari-Khouzani K, 2005, IEEE T IMAGE PROCESS, V14, P783, DOI 10.1109/TIP.2005.847302
   Jafari-Khouzani K, 2005, IEEE T PATTERN ANAL, V27, P1004, DOI 10.1109/TPAMI.2005.126
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kylberg G, 2015, KYLBERG SINTORN ROTA
   Kylberg G, 2016, EURASIP J IMAGE VIDE, P1, DOI 10.1186/s13640-016-0117-6
   Li Z, 2012, IEEE T IMAGE PROCESS, V21, P2130, DOI 10.1109/TIP.2011.2173697
   Liu K, 2014, INT J COMPUT VISION, V106, P342, DOI 10.1007/s11263-013-0634-z
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Negri TT, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 4, P378, DOI 10.5220/0006143403780388
   Nosaka R, 2014, PATTERN RECOGN, V47, P2428, DOI 10.1016/j.patcog.2013.09.018
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pillai A, 2018, FUTURE GENER COMP SY, V81, P297, DOI 10.1016/j.future.2017.09.055
   Pun CM, 2003, IEEE T PATTERN ANAL, V25, P590, DOI 10.1109/TPAMI.2003.1195993
   Rassem TH, 2017, IAENG INT J COMPUT S, V44
   Ryu J, 2015, IEEE T IMAGE PROCESS, V24, P2254, DOI 10.1109/TIP.2015.2419081
   Sánchez-Yáñez RE, 2003, PATTERN RECOGN LETT, V24, P1503, DOI 10.1016/S0167-8655(02)00389-6
   Sifre L, 2013, PROC CVPR IEEE, P1233, DOI 10.1109/CVPR.2013.163
   Song Y, 2017, IEEE I CONF COMP VIS, P4922, DOI 10.1109/ICCV.2017.526
   Souza JM, 2015, WORKSH VISAO COMP, P128
   Tamrakar D, 2016, MULTIMED TOOLS APPL, V75, P5777, DOI 10.1007/s11042-015-2541-5
   Tavares Vieira Raissa, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P268, DOI 10.1007/978-3-319-50835-1_25
   Vieira RT, 2017, 2017 WORKSHOP OF COMPUTER VISION (WVC), P1, DOI 10.1109/WVC.2017.00008
   Wan SH, 2017, MED IMAGE ANAL, V38, P104, DOI 10.1016/j.media.2017.03.002
   Yadav AR, 2017, WOOD SCI TECHNOL, V51, P909, DOI 10.1007/s00226-017-0902-0
NR 43
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31041
EP 31066
DI 10.1007/s11042-018-6204-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600040
DA 2024-07-18
ER

PT J
AU Rad, AE
   Rahim, MSM
   Kolivand, H
   Norouzi, A
AF Rad, Abdolvahab Ehsani
   Rahim, Mohd Shafry Mohd
   Kolivand, Hoshang
   Norouzi, Alireza
TI Automatic computer-aided caries detection from dental x-ray images using
   intelligent level set
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Caries detection; Image processing; Segmentation; Level set
ID HUMAN IDENTIFICATION; ACTIVE CONTOURS; SEGMENTATION; SHAPE; ALGORITHMS;
   SPEED
AB Dental diseases have high risk of affection across the globe and mostly in adult population. The analysis of dental X-ray images has some difficulties in comparison to other medical images, which makes segmentation a more challenging process. One of the most important and yet largely unsolved issues in the level set method framework is the efficiency of signed force, speed function and initial contour (IC) generation. In this paper, a new segmentation method based on level set (LS) is proposed in two phases; IC generation using morphological information of image and intelligent level set segmentation utilizing motion filtering and back propagation neural network. The segmentation results are efficient and accurate as compared to other studies. The new approach to isolate each segmented teeth image is proposed by employing integral projection technique and feature map designed for each tooth to extract the local information and therefore to detect caries area. The achieved overall performance of the proposed segmentation method was evaluated at 120 periapical dental radiograph (X-ray), with images at 90% and the detection accuracy of 98%.
C1 [Rad, Abdolvahab Ehsani] Islamic Azad Univ, Shahrood Branch, Dept Elect & Comp Engn, Shahrood, Iran.
   [Rahim, Mohd Shafry Mohd] Univ Teknol Malaysia, Fac Comp, Dept Software Engn, Skudai 81310, Johor Bahru, Malaysia.
   [Kolivand, Hoshang] Liverpool John Moores Univ, Dept Comp Sci, Liverpool L3 3AF, Merseyside, England.
   [Norouzi, Alireza] Islamic Azad Univ, Majlesi Branch, Dept Elect & Comp Engn, Esfahan, Iran.
C3 Islamic Azad University; Universiti Teknologi Malaysia; Liverpool John
   Moores University; University of Liverpool; Islamic Azad University
RP Rad, AE (corresponding author), Islamic Azad Univ, Shahrood Branch, Dept Elect & Comp Engn, Shahrood, Iran.
EM vahabehr@gmail.com; shafry@utm.my; h.kolivand@ljmu.ac.uk;
   norouzi@iaumajlesi.ac.ir
RI Kolivand, Hoshang/F-4736-2011; Ehsani Rad, Abdolvahab/K-6015-2012;
   Kolivand, Hoshang/B-2501-2016
OI Ehsani Rad, Abdolvahab/0000-0002-6729-9559; Kolivand,
   Hoshang/0000-0001-5460-5679; Norouzi, Alireza/0000-0002-1419-1771
CR [Anonymous], 2013, WMA DECL HELS ETH PR
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen YM, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P145, DOI 10.1109/VLSM.2001.938893
   Ciofolo C, 2004, LECT NOTES COMPUT SC, V3216, P310
   Fedkiw S.O. R., 2003, LEVEL SET METHODS DY
   Gao H, 2010, PATTERN RECOGN, V43, P2406, DOI 10.1016/j.patcog.2010.01.010
   Jain AK, 2004, PATTERN RECOGN, V37, P1519, DOI 10.1016/j.patcog.2003.12.016
   Keshtkar F., 2006, 2006 CAN C EL COMP E, P328, DOI [10.1109/CCECE.2006.277656, DOI 10.1109/CCECE.2006.277656]
   Kutsch VK, 2011, CARIES DETECTION INS
   Leventon M., 2000, P IEEE C COMPUTER VI, P316, DOI DOI 10.1109/CVPR.2000.855835
   Li S, 2007, PATTERN RECOGN, V40, P2861, DOI 10.1016/j.patcog.2007.01.012
   Lin PL, 2014, COMPUT METH PROG BIO, V113, P433, DOI 10.1016/j.cmpb.2013.10.015
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   MOLTENI R, 1993, ORAL SURG ORAL MED O, V76, P235, DOI 10.1016/0030-4220(93)90211-L
   Najarian Kayvan, 2009, COMPL MED ENG 2009 C, P1
   Nassar DEM, 2004, P 1 INT COMP ENG C I, P354
   Nomir O, 2007, IEEE T INF FOREN SEC, V2, P188, DOI 10.1109/TIFS.2007.897245
   Norouzi A., 2014, INT J MED HLTH BIOME, V8, P182
   Norouzi A, 2014, IETE TECH REV, V31, P199, DOI 10.1080/02564602.2014.906861
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Peng DP, 1999, J COMPUT PHYS, V155, P410, DOI 10.1006/jcph.1999.6345
   Rad AE, 2017, MULTIMED TOOLS APPL, V76, P2185, DOI 10.1007/s11042-015-3196-y
   Rad AE, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0096-5
   Rad AE, 2013, IETE TECH REV, V30, P210, DOI 10.4103/0256-4602.113498
   Rink K, 2006, LECT NOTES COMPUT SC, V4174, P152
   Said EH, 2006, PROC SPIE, V6064
   Sethian JA, 2003, ANNU REV FLUID MECH, V35, P341, DOI 10.1146/annurev.fluid.35.101101.161105
   Taheri S, 2010, IMAGE VISION COMPUT, V28, P26, DOI 10.1016/j.imavis.2009.04.005
   van Bemmel CM, 2003, IEEE T MED IMAGING, V22, P1224, DOI 10.1109/TMI.2003.817756
   Xu CY, 2000, CONF REC ASILOMAR C, P483, DOI 10.1109/ACSSC.2000.911003
   Yoon DC, 1998, US Patent, Patent No. [5742700, 5,742,700]
   Zhang Y, 2008, MEDIVIS 2008: FIFTH INTERNATIONAL CONFERENCE BIOMEDICAL VISUALIZATION - INFORMATION VISUALIZATION IN MEDICAL AND BIOMEDICAL INFORMATICS, PROCEEDINGS, P71, DOI 10.1109/MediVis.2008.12
   Zhou J, 2005, PATTERN RECOGN, V38, P2132, DOI 10.1016/j.patcog.2005.01.011
NR 35
TC 25
Z9 27
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28843
EP 28862
DI 10.1007/s11042-018-6035-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500044
DA 2024-07-18
ER

PT J
AU Xu, XY
   Sun, YF
   Wu, J
   Sun, Y
AF Xu, Xiaoyu
   Sun, Yifeng
   Wu, Jiang
   Sun, Yi
TI Steganography algorithms recognition based on match image and deep
   features verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography algorithms recognition; CNN; Match image; Deep feature
ID STEGANALYSIS
AB Steganography algorithms recognition is a sub-section of steganalysis. Analysis shows when a steganalysis detector trained on one cover source is applied to images from an unseen source, generally the detection performance decreases. To tackle with this problem, this paper proposes a steganalytic scheme for steganography algorithms recognition. For a given testing image, a match image of the testing image is achieved. The match image is generated by performing a Gaussian filtering on the testing image to remove the possible stego signal. Then the match image is embedded in with recognized steganography algorithms. A CNN model trained on a training set is used to extract deep features from testing image and match images. Computing similarity between features with inner product operation or weighted-chi (2), the final decision is made according to similarity between testing feature and each class of match feature. The proposed scheme can also detect steganography algorithms unknown in training set. Experiments show that, comparing with directly used CNN model, the proposed scheme achieves considerable improvement on testing accuracy when detecting images come from unseen source.
C1 [Xu, Xiaoyu; Sun, Yifeng; Wu, Jiang; Sun, Yi] Inst Informat Sci & Technol, Zhengzhou 450001, Henan, Peoples R China.
C3 PLA Information Engineering University
RP Sun, YF (corresponding author), Inst Informat Sci & Technol, Zhengzhou 450001, Henan, Peoples R China.
EM yfsun001@163.com
CR [Anonymous], 2016, ACM WORKSH INF HID M
   [Anonymous], INT WORKSH DIG WAT
   [Anonymous], ELECT IMAGING 2008
   [Anonymous], 2012, P MULTIMEDIA SECURIT
   [Anonymous], ELECT IMAGING 2007 I
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], IMAGE STEGANALYTIC F
   [Anonymous], RES JPEG IMAGES MISM
   [Anonymous], 2011, P 13 INF HID C PRAG
   [Anonymous], SPIE IS T ELECT IMAG
   [Anonymous], 2000, Digital Watermarking
   [Anonymous], 2014, Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific, DOI [10.1109/APSIPA.2014, 10.1109/APSIPA.2014.7041565]
   Cho SG, 2013, J VIS COMMUN IMAGE R, V24, P846, DOI 10.1016/j.jvcir.2013.05.007
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Dong J, 2009, LECT NOTES COMPUT SC, V5703, P199, DOI 10.1007/978-3-642-03688-0_19
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Fridrich J, 2013, INT CONF ACOUST SPEE, P2949, DOI 10.1109/ICASSP.2013.6638198
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Kong XW, 2016, NEUROCOMPUTING, V214, P458, DOI 10.1016/j.neucom.2016.06.037
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P635, DOI 10.1109/TIFS.2008.2002936
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Sedighi V, 2015, PROC SPIE, V9409, DOI 10.1117/12.2080272
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wang P, 2008, IEEE IMAGE PROC, P2076, DOI 10.1109/ICIP.2008.4712195
   Xu G., 2016, P 4 ACM WORKSH INF H, P103, DOI DOI 10.1145/2909827.2930798
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
NR 41
TC 2
Z9 3
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 27955
EP 27979
DI 10.1007/s11042-018-6010-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500010
DA 2024-07-18
ER

PT J
AU Banitalebi-Dehkordi, A
   Nasiopoulos, P
AF Banitalebi-Dehkordi, Amin
   Nasiopoulos, Panos
TI Saliency inspired quality assessment of stereoscopic 3D video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereoscopic video; 3D video; Saliency prediction; Quality assessment;
   Visual attention modeling
ID VISUAL-ATTENTION; OBJECT RETRIEVAL; IMAGE; INFORMATION; MODEL
AB To study the visual attentional behavior of Human Visual System (HVS) on 3D content, eye tracking experiments are performed and Visual Attention Models (VAMs) are designed. One of the main applications of these VAMs is in quality assessment of 3D video. The usage of 2D VAMs in designing 2D quality metrics is already well explored. This paper investigates the added value of incorporating 3D VAMs into Full-Reference (FR) and No-Reference (NR) quality assessment metrics for stereoscopic 3D video. To this end, state-of-the-art 3D VAMs are integrated to quality assessment pipeline of various existing FR and NR stereoscopic video quality metrics. Performance evaluations using a large scale database of stereoscopic videos with various types of distortions demonstrated that using saliency maps generally improves the performance of the quality assessment task for stereoscopic video. However, depending on the type of distortion, utilized metric, and VAM, the amount of improvement will change.
C1 [Banitalebi-Dehkordi, Amin; Nasiopoulos, Panos] Univ British Columbia, Dept Elect Engn, Vancouver, BC V6T 1Z4, Canada.
   [Banitalebi-Dehkordi, Amin; Nasiopoulos, Panos] Univ British Columbia, ICICS, Vancouver, BC V6T 1Z4, Canada.
C3 University of British Columbia; University of British Columbia
RP Banitalebi-Dehkordi, A (corresponding author), Univ British Columbia, Dept Elect Engn, Vancouver, BC V6T 1Z4, Canada.; Banitalebi-Dehkordi, A (corresponding author), Univ British Columbia, ICICS, Vancouver, BC V6T 1Z4, Canada.
EM dehkordi@ece.ubc.ca; panos@ece.ubc.ca
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
   [STPGP 447339-13]; Institute for Computing Information and Cognitive
   Systems (ICICS) at UBC
FX This work was partly supported by Natural Sciences and Engineering
   Research Council of Canada (NSERC) under Grant STPGP 447339-13 and
   Institute for Computing Information and Cognitive Systems (ICICS) at
   UBC.
CR Akamine WYL, SIBGRAPI 2012 C GRAP
   [Anonymous], 1999, SUBJECTIVE VIDEO QUA
   [Anonymous], 2008, 2008 19 INT C PATT R
   [Anonymous], 2006, GRAPH BASED VISUAL S
   [Anonymous], 3D VID DAT DIG MULT
   [Anonymous], 46 ANN AS C SIGN SYS
   [Anonymous], 2010, VIEW SYNTHESIS REFER
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2012, P IET C IM PROC IPR
   [Anonymous], P IEEE 11 IVMSP WORK
   [Anonymous], 2012, METHODOLOGY SUBJECTI
   [Anonymous], 2011, N12352 ISOIEC JTC1SC
   Appina B, 2017, ICASSP 2017
   Banitalebi-Dehkordi Amin, 2014, 2014 IEEE International Conference on Consumer Electronics (ICCE), P416, DOI 10.1109/ICCE.2014.6776065
   Banitalebi-Dehkordi A, 2016, J ELECTRON IMAGING, V25, P1
   Banitalebi-Dehkordi A., 2015, THESIS
   Banitalebi-Dehkordi A, 2017, MULTIMED TOOLS APPL, V76, P23859, DOI 10.1007/s11042-016-4155-y
   Banitalebi-Dehkordi A, 2015, 3D RES, V6, DOI 10.1007/s13319-014-0034-3
   Banitalebi-Dehkordi A, 2016, MULTIMED TOOLS APPL, V75, P4187, DOI 10.1007/s11042-015-2466-z
   Banitalebi-Dehkordi A, 2013, INT CONF ACOUST SPEE, P3731, DOI 10.1109/ICASSP.2013.6638355
   Benoit A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/659024
   Berengolts A, 2006, IEEE T PATTERN ANAL, V28, P1973, DOI 10.1109/TPAMI.2006.249
   Cai JZ, 2009, INT C WAVEL ANAL PAT, P8, DOI 10.1109/ICWAPR.2009.5207420
   Cai ZW, 2012, COMM COM INF SC, V321, P455
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chu XQ, 2014, OPTIK, V125, P704, DOI 10.1016/j.ijleo.2013.07.033
   Coria Lino, 2012, P 3DTV C TRUE VIS CA, P1
   Ding Y, 2012, INT J DIGIT CONT TEC, V6, P67, DOI [10. 4156/jdcta. vol6. issue5. 9, DOI 10.4156/JDCTA.VOL6.ISSUE5.9]
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Feng X, 2011, IEEE T BROADCAST, V57, P81, DOI 10.1109/TBC.2010.2092150
   Frintrop S, 2005, P 2 INT WORKSH ATT P
   Gabarda S, 2007, J OPT SOC AM A, V24, pB42, DOI 10.1364/JOSAA.24.000B42
   Gao DS, 2005, PROC CVPR IEEE, P282
   Gu K, 2018, IEEE T IMAGE PROCESS, V27, P394, DOI 10.1109/TIP.2017.2733164
   Gu K, 2015, IEEE SIGNAL PROC LET, V22, P1552, DOI 10.1109/LSP.2015.2413944
   Gu K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/436031
   Gu ZH, 2013, LEARNING BLIND IMAGE
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hare J.S., 2003, Distrib. Multimedia Syst./Visual Inform. Syst, P436
   Hasan M, 2014, NO REFERENCE QUALITY
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jin L., 2011, 19 EUR SIGN PROC C E
   Jin LN, 2011, IEEE IMAGE PROC
   Lee JS, 2012, IEEE J-STSP, V6, P684, DOI 10.1109/JSTSP.2012.2215006
   Li A, 2013, PROC SPIE, V8878, DOI 10.1117/12.2030719
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu HT, 2011, IEEE T CIRC SYST VID, V21, P971, DOI 10.1109/TCSVT.2011.2133770
   Lu ZK, 2005, IEEE T IMAGE PROCESS, V14, P1928, DOI 10.1109/TIP.2005.854478
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112
   Matsuyama T, 2012, D VIDEO AND ITS APPL
   Navalpakkam Vidhya, 2006, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, V2, P2049, DOI DOI 10.1109/CVPR.2006.54
   Ninassi A, 2006, TASK IMPACT VISUAL A
   Park KH, 2002, IEEE T CIRC SYST VID, V12, P106, DOI 10.1109/76.988657
   Qiuping Jiang, 2014, Journal of Software, V9, P1841, DOI 10.4304/jsw.9.7.1841-1847
   Roffet FC, 2007, SPIE EL IM S
   Rutishauser U, 2004, PROC CVPR IEEE, P37
   Ryu S, 2014, IEEE T CIRC SYST VID, V24, P591, DOI 10.1109/TCSVT.2013.2279971
   Sadaka N G, 2008, NO REFERENCE PERCEPT
   Setlur V, 2007, IEEE COMPUT GRAPH, V27, P80, DOI 10.1109/MCG.2007.133
   Shao F, 2013, IEEE T IMAGE PROCESS, V22, P1940, DOI 10.1109/TIP.2013.2240003
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Siagian C, 2004, P 1 IEEE INT WORKSH
   Smolic A., 2006, IEEE INT C MULT EXP
   Tanimoto M, 2009, MPEGM16092 ISOIEC JT
   Vu K, 2003, IEEE T KNOWL DATA EN, V15, P1045, DOI 10.1109/TKDE.2003.1209021
   Wang D, 2017, NEUROCOMPUTING, V252, P58, DOI 10.1016/j.neucom.2016.06.095
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2003, 37 AS C
   Wu HR, 1997, IEEE SIGNAL PROC LET, V4, P317, DOI 10.1109/97.641398
   Xie L, 2016, MULTIMED TOOLS APPL, V75, P9185, DOI 10.1007/s11042-016-3432-0
   Xu D, 2012, J SOC INF DISPLAY, V20, P397, DOI 10.1002/jsid.99
   You J, 2010, INT WORKSH VID PROC
   Zhang D, 2013, GLOB HIGH TECH C EL
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zhu L, 2016, 25 INT JOINT C ART I
   Zhu L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P843, DOI 10.1145/2733373.2806345
   Zhu L, 2014, IET IMAGE PROCESS, V8, P509, DOI 10.1049/iet-ipr.2013.0375
   Zhu L, 2014, J SUPERCOMPUT, V68, P820, DOI 10.1007/s11227-013-1068-7
NR 83
TC 5
Z9 5
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 26055
EP 26082
DI 10.1007/s11042-018-5837-4
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400062
DA 2024-07-18
ER

PT J
AU Rajalakshmi, K
   Mahesh, K
AF Rajalakshmi, K.
   Mahesh, K.
TI Robust secure video steganography using reversible patch-wise code-based
   embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fast fourier transform (FFT); Least significant bit (LSB); Blind pixel
   (BP); Patch code formation (PCF); Elliptic curve cryptography (ECC);
   Discrete cosine transform(DCT); Discrete wavelet transform (DWT)
ID WATERMARKING
AB During the process of data hiding for secure transmission, there is possibility of easy accessing of secret data due to availability of various issues in video steganography techniques. The large size of video file is divided into different number of frames in order to process the large amount of data. By using the embedding process, the secret data is easily embedded on the cover video for either large or small amount of information. The process of encryption and decryption is performed to provide high security in data hiding algorithm. In the transformation technique, the effective decryption process arises an issue during the video encryption process. The ineffective restoration of compression process involves in the encryption of input video frames by using Discrete Cosine Transform (DCT) or Discrete Wavelet Transform (DWT) transformation. Also, the pixel information are lost due to processing of frame conversion and encoding in transformation technique. Thus, the encryption efficiency is affected by lossy pixel information. Hence, the flexible phi-correction filtering method with Blind Pixel Algorithm (BPA) technique is proposed in this paper to hide secured data without degrading the information. The pixel grouping is performed by replacing the relevant and recurrent pixels with the message information during the encryption process in order to reduce lossy pixel information. Also, the flexible phi-correction filtering method is developed as preprocessing method to remove noise information on cover and secret video by analyzing the pixel value in terms of Fast Fourier Transform (FFT) after performing the pixel optimization with the help of different boundary coefficient value. Thus, the preprocessing and pixel grouping stage in the proposed technique reduces lossy pixel information. Based on the Least Significant Bit (LSB) concept, the pixel value of secret message embeds on pixel value of cover frame sequentially by using the BPA algorithm and the disadvantage of LSB approach is overwhelmed by embedding the set of random pixel value between cover and secret video. The Patch Wise Code Formation (PWCF) algorithm is utilized as video encoding process to provide high security during data hiding process. The BPA algorithm utilizes in reversible manner to achieve efficient working of decryption process. The performance of the proposed Blind-Pixel Based Secure Data Embedding (BPSDA) technique is evaluated for various video sequences in terms of Peak Signal Noise Ratio (PSNR), Mean Square Error (MSE), Compression Rate (CR), and Bits Per Pixel (BPP).
C1 [Rajalakshmi, K.; Mahesh, K.] Alagappa Univ, Dept Comp Applicat, Karaikkudi 600006, Tamil Nadu, India.
C3 Alagappa University
RP Rajalakshmi, K (corresponding author), Alagappa Univ, Dept Comp Applicat, Karaikkudi 600006, Tamil Nadu, India.
EM rajalakshmiphd2016@gmail.com
RI K, Rajalakshmi/AAA-9607-2021
OI K, Rajalakshmi/0000-0003-0076-3107
CR Abdallah EE, 2007, LECT NOTES COMPUT SC, V4633, P772
   Abdallah EE, 2010, SIGNAL IMAGE VIDEO P, V4, P233, DOI 10.1007/s11760-009-0114-7
   Alhaj SA, 2016, T NETWORKS COMMUNICA, V4, P53
   [Anonymous], INT J ELECT COMMUN S
   [Anonymous], INT J COMP SCI ENG T
   Devi MR, 2016, INT J ENG SCI, V4, P3725, DOI [10.4010/2016.78_9, DOI 10.4010/2016.78_9]
   Dixit S, 2016, INT J ENG SCI, V3550, P3550, DOI 10.4010/2016.822
   Elsheh E, 2011, EXPERT SYST APPL, V38, P13906, DOI 10.1016/j.eswa.2011.04.197
   Hegde R, 2016, COMPUT STAND INTER, V48, P173, DOI 10.1016/j.csi.2016.07.001
   Hong W, 2013, INFORM SCIENCES, V221, P473, DOI 10.1016/j.ins.2012.09.013
   Jindal S, 2016, INT J COMPUTER SCI I, V6, P10
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2143, DOI 10.1007/s11042-013-1832-y
   Kaur M, 2014, INT J ADV RES COMPUT, V4, P44
   KISHOR SN, 2016, INDIAN J SCI TECHNOL, V9, pN1447, DOI DOI 10.17485/ijst/2016/v9iS1/109414
   KRUTHIKA S, 2016, INDIAN J SCI TECHNOL, V9, pN1418, DOI DOI 10.17485/ijst/2016/v9i48/107957
   Liu YX, 2016, NEUROCOMPUTING, V188, P113, DOI 10.1016/j.neucom.2015.02.102
   Liu YX, 2016, NEUROCOMPUTING, V188, P63, DOI 10.1016/j.neucom.2014.10.109
   Manimegalai P., 2014, INT J COMPUT SCI MOB, V3, P300
   Mstafa RJ, 2017, THESIS
   Mstafa RJ, 2017, IEEE ACCESS
   Mundher M, 2014, APPL MATH INFORM SCI, V8, P2823, DOI 10.12785/amis/080618
   Najafi MH, 2016, ARXIV161204339
   PARNAMI P, 2016, PERFORMANCE EVALUATI, V0003, P00167
   Rajesh G.R., 2014, APPL MECH MAT, V626, P58
   RAMALINGAM M, 2014, INDIAN J SCI TECHNOL, V7, P897
   Singh TR, 2013, AEU-INT J ELECTRON C, V67, P645, DOI 10.1016/j.aeue.2013.01.008
   Soni Aditi, 2015, INT J SCI REIJSR, V4, P80
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2017, PROC IEEE MICR ELECT, P813, DOI 10.1109/MEMSYS.2017.7863532
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang YN, 2017, TSINGHUA SCI TECHNOL, V22, P198
NR 33
TC 6
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27427
EP 27445
DI 10.1007/s11042-018-5930-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500053
DA 2024-07-18
ER

PT J
AU Ye, S
   Liu, CC
   Li, ZW
   Al-Ahmari, A
AF Ye, Shuang
   Liu, Chuancai
   Li, Zhiwu
   Al-Ahmari, Abdulrahman
TI Improved frame-by-frame object pose tracking in complex environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Frame-by-frame tracking; Pose estimation; Pose
   tracking; Complex environments
AB Pose tracking is an important task in Augmented Reality (AR), interactive systems, and robotic systems. The frame-by-frame pose tracking that is effective in many cases still faces challenges in complex environments such as occlusions, illumination changes and flipping. In this paper, based on the optimization model offered by Ye et al. J Vis Commun Image Represent 44:72-81 (2017), three improvements are further proposed. First, a feature adjustment strategy based on a group of neighbors is offered to alleviate a sharp reduction of features. Then, when the features are no longer well representing the scene of interest, a score model based on a weighted histogram for result evaluations is presented to realize an adaptive interval. Besides, a forward-backward algorithm is provided to improve the accuracy by replacing the detection method with the tracking method. Experimental results manifest the effectiveness of the proposed algorithms.
C1 [Ye, Shuang; Liu, Chuancai] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Ye, Shuang] Huaqiao Univ, Sch Comp Sci & Technol, Xiamen 361021, Peoples R China.
   [Li, Zhiwu] Macau Univ Sci & Technol, Inst Syst Engn, Taipa, Macao, Peoples R China.
   [Li, Zhiwu] Xidian Univ, Sch Electromech Engn, Xian 710071, Shaanxi, Peoples R China.
   [Al-Ahmari, Abdulrahman] King Saud Univ, Adv Mfg Inst, Riyadh 11421, Saudi Arabia.
   [Al-Ahmari, Abdulrahman] King Saud Univ, Coll Engn, Ind Engn Dept, Riyadh, Saudi Arabia.
C3 Nanjing University of Science & Technology; Huaqiao University; Macau
   University of Science & Technology; Xidian University; King Saud
   University; King Saud University
RP Liu, CC (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM chcailiu@163.com
RI Al-Ahmari, Abdulrahman/E-6000-2017; Li, Zhiwu/A-7884-2010
OI Al-Ahmari, Abdulrahman/0000-0002-3079-0141; Li,
   Zhiwu/0000-0003-1547-5503
FU National Natural Science Foundation of China [61373063, 61373062,
   61473155]; Ministry of Industry and Information Technology of China
   [E0310/1112/02-1]; Research Award Fund for Young Teachers of Education
   Department of Fujian Province [JAT170037]; Natural Science Foundation
   Project of Fujian Province [2017J01110]; Science and Technology Planning
   Project of Fujian Province [2018H01010060]; Science and Technology
   Planning Project of Quanzhou City, Fujian Province [2017T003]
FX This work was supported by the National Natural Science Foundation of
   China [grant number 61373063, 61373062, 61473155]; the project of
   Ministry of Industry and Information Technology of China [grant number
   E0310/1112/02-1]; the Research Award Fund for Young Teachers of
   Education Department of Fujian Province [grant number JAT170037]; the
   Natural Science Foundation Project of Fujian Province [grant number
   2017J01110]; the Science and Technology Planning Project of Fujian
   Province [grant number 2018H01010060]; the Science and Technology
   Planning Project of Quanzhou City, Fujian Province [grant number No.
   2017T003].
CR Alldieck T., 2017, LECT NOTES COMPUT SC, P347, DOI DOI 10.1007/978-3-319-66709-6_28
   Aly M, BAG WORDS LARGE SCAL
   [Anonymous], 2008, Conference on Computer Vision and Pattern Recognition
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35
   Chen W.C., 2007, Proceedings of the 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality, P1
   Doumanoglou A, 2016, PROC CVPR IEEE, P3583, DOI 10.1109/CVPR.2016.390
   Duy-Nguyen Ta, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2937, DOI 10.1109/CVPRW.2009.5206831
   Gammeter S., 2010, CVPR Workshops, P1
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalman R.E., 1961, J BASIC ENG-T ASME, V83, P95, DOI 10.1115/1.3658902
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kanade T., 1981, P 7 INT JOINT C ARTI, V1, P674, DOI DOI 10.5555/1623264.1623280
   Ke Y, 2004, PROC CVPR IEEE, P506
   Koyama J., 2014, IEEE INT C MULT EXP, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Makar M, 2013, INT J SEMANT COMPUT, V7, P5, DOI 10.1142/S1793351X13400011
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mooser J., 2007, P 2007 6 IEEE ACM IN, P1, DOI [10.1109/ISMAR.2007.4538839, DOI 10.1109/ISMAR.2007.4538839]
   Mooser J, 2008, INT S 3D DAT PROC VI
   Nair BM, 2014, PROC SPIE, V9026, DOI 10.1117/12.2040392
   Özuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23
   Pauwels K, 2014, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2014.510
   Pauwels K, 2013, PROC CVPR IEEE, P2347, DOI 10.1109/CVPR.2013.304
   Qu X, 2014, MATH PROBLEMS ENG
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Simon G, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P120, DOI 10.1109/ISAR.2000.880935
   Skrypnyk I, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P110, DOI 10.1109/ISMAR.2004.53
   Takacs G, 2010, PROC CVPR IEEE, P934, DOI 10.1109/CVPR.2010.5540116
   Tejani A, 2014, LECT NOTES COMPUT SC, V8694, P462, DOI 10.1007/978-3-319-10599-4_30
   Thachasongtham D, 2013, LECT NOTES COMPUT SC, V7944, P512
   Ufkes A, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P226, DOI 10.1109/CRV.2013.51
   Wagner D, 2008, INT SYM MIX AUGMENT, P125, DOI 10.1109/ISMAR.2008.4637338
   Wohlhart P, 2015, PROC CVPR IEEE, P3109, DOI 10.1109/CVPR.2015.7298930
   Ye S, 2017, J VIS COMMUN IMAGE R, V44, P72, DOI 10.1016/j.jvcir.2017.01.017
   Zach C, 2015, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.2015.7298615
NR 38
TC 1
Z9 1
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24983
EP 25004
DI 10.1007/s11042-018-5736-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400018
DA 2024-07-18
ER

PT J
AU Yin, ZJ
   Dai, LH
   Xiong, HL
   Yang, F
   Yang, Z
AF Yin, Zhijian
   Dai, Linhan
   Xiong, Huilin
   Yang, Fan
   Yang, Zhen
TI Accurate target tracking via Gaussian sparsity and locality-constrained
   coding in heavy occlusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Target tracking; Sparse coding; Locality-constrained linear coding;
   Gaussian sparse representation; Cooperative model
ID ROBUST VISUAL TRACKING; OBJECT TRACKING; MODEL
AB This paper presents a Gaussian sparse representation cooperative model for tracking a target in heavy occlusion video sequences by combining sparse coding and locality-constrained linear coding algorithms. Different from the usual method of using a"" (1)-norm regularization term in the framework of particle filters to form the sparse collaborative appearance model (SCM), we employed the a"" (1)-norm and a"" (2)-norm to calculate feature selection, and then encoded the candidate samples to generate the sparse coefficients. Consequently, our method not only easily obtained sparse solutions but also reduced reconstruction error. Compared to state-of-the-art algorithms, our scheme achieved better performance in heavy occlusion video sequences for tracking a target. Extensive experiments on target tracking were carried out to show the results of our proposed algorithm compared with various other target tracking methods.
C1 [Yin, Zhijian; Dai, Linhan; Yang, Fan; Yang, Zhen] Jiangxi Sci & Technol Normal Univ, Sch Commun & Elect, 605 Fenglin Rd, Nanchang, Jiangxi, Peoples R China.
   [Xiong, Huilin] Shanghai Jiao Tong Univ, Dept Automat, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
C3 Jiangxi Science & Technology Normal University; Shanghai Jiao Tong
   University
RP Yang, Z (corresponding author), Jiangxi Sci & Technol Normal Univ, Sch Commun & Elect, 605 Fenglin Rd, Nanchang, Jiangxi, Peoples R China.
EM 13330082703@163.com; dailinhan9619@163.com; sjtu-zt@sjtu.edu.cn;
   kooyang@aliyun.com; yangzhenphd@aliyun.com
FU National Natural Science Foundation of China [61603161, 61650402];
   Natural Science Foundation of Jiangxi Province of China
   [20151BAB207049]; Key Science Foundation of Educational Commission of
   Jiangxi Province of China [GJJ160768]; scholastic youth talent support
   program of Jiangxi Science; Technology Normal University
   [2016QNBJRC004]; Natural Science Foundation of Jiangxi Province Key
   Laboratory of Water Information Cooperative Sensing and Intelligent
   Processing [2016WICSIP031]; Key Science Foundation of Jiangxi Science
   and Technology Normal University [2014XJZD002]
FX This work was supported in part by the National Natural Science
   Foundation of China of (61603161, 61650402); a Natural Science
   Foundation of Jiangxi Province of China (20151BAB207049); a Key Science
   Foundation of Educational Commission of Jiangxi Province of China
   (GJJ160768); a scholastic youth talent support program of Jiangxi
   Science and Technology Normal University (2016QNBJRC004); the Natural
   Science Foundation of Jiangxi Province Key Laboratory of Water
   Information Cooperative Sensing and Intelligent Processing
   (2016WICSIP031); and the Key Science Foundation of Jiangxi Science and
   Technology Normal University (2014XJZD002). We would like to thank
   LetPub (www.letpub.com) for providing linguistic assistance during the
   preparation of this manuscript.
CR [Anonymous], SPARSE REPRESENTATIO
   [Anonymous], 2006, ADV NEURAL INF PROCE
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], INT C COMP SCI NETW
   [Anonymous], 2016, CVPR
   [Anonymous], P SPIE INT SOC OPTIC
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bai QX, 2013, IEEE I CONF COMP VIS, P2040, DOI 10.1109/ICCV.2013.255
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Cehovin L, 2016, IEEE T IMAGE PROCESS, V25, P1261, DOI 10.1109/TIP.2016.2520370
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Han G, 2016, NEUROCOMPUTING, V184, P145, DOI 10.1016/j.neucom.2015.07.122
   Han J, 2015, IEEE T IMAGE PROCESS, V24, P5177, DOI 10.1109/TIP.2015.2447735
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Liang PP, 2016, IEEE SIGNAL PROC LET, V23, P949, DOI 10.1109/LSP.2016.2556706
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Ou W., 2017, MULTIMED TOOLS APPL, P1
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Qing Wang, 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P425, DOI 10.1109/WACV.2012.6162999
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Tang F, 2007, IEEE I CONF COMP VIS, P992
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang LJ, 2016, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2016.153
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Wu Y, 2012, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2012.6247878
   Yang YY, 2017, INT J PROD RES, V55, P3970, DOI 10.1080/00207543.2016.1223379
   Yang YH, 2015, NEUROCOMPUTING, V160, P191, DOI 10.1016/j.neucom.2014.12.060
   Zhang CC, 2014, NEUROCOMPUTING, V131, P237, DOI 10.1016/j.neucom.2013.10.020
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang LM, 2017, MULTIMEDIA SYST, V23, P1, DOI 10.1007/s00530-016-0527-4
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou Y, 2016, INT J COMPUT VISION, V118, P337, DOI 10.1007/s11263-015-0879-9
NR 45
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26485
EP 26507
DI 10.1007/s11042-018-5872-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500013
DA 2024-07-18
ER

PT J
AU Zhu, Xj
   Lu, HQ
   Rätsch, M
AF Zhu, Xin-juan
   Lu, Haiqing
   Raetsch, Matthias
TI An interactive clothing design and personalized virtual display system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personalized clothing customization; Interactive clothing design;
   Clothing virtual display; 3d face modelling; 3D Morphable model
AB An interactive clothing design and a personalized virtual display with user's own face are presented in this paper to meet the requirement of personalized clothing customization. A customer interactive clothing design approach based on genetic engineering ideas is analyzed by taking suit as an example. Thus, customers could rearrange the clothing style elements, chose available color, fabric and come up with their own personalized suit style. A web 3D customization prototype system of personalized clothing is developed based on the Unity3D and VR technology. The layout of the structure and functions combined with the flow of the system are given. Practical issues such as 3D face scanning, suit style design, fabric selection, and accessory choices are addressed also. Tests to the prototype system indicate that it could show realistic clothing and fabric effect and offer effective visual and customization experience to users.
C1 [Zhu, Xin-juan; Lu, Haiqing] Xian Polytech Univ, Coll Comp Sci, Xian, Shaanxi, Peoples R China.
   [Raetsch, Matthias] Reutlingen Univ, Dept Mechatron, Reutlingen, Germany.
C3 Xi'an Polytechnic University
RP Zhu, Xj (corresponding author), Xian Polytech Univ, Coll Comp Sci, Xian, Shaanxi, Peoples R China.
EM zhuxinjuan@xpu.edu.cn
CR Ai QS, 2013, ADV MECH ENG, DOI 10.1155/2013/489257
   Ai QS, 2012, J ADV MECH DES SYST, V6, P1234, DOI 10.1299/jamdsm.6.1234
   [Anonymous], GRAFIS CAD SOFTW PRO
   [Anonymous], 2016, MULTIMEDIA TOOLS APP
   [Anonymous], 2016, VISIGRAPP
   Balasubramanian M, 2002, SCIENCE, V295
   Begole B, 2009, P 13 INT C HUM COMP, P448
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Chen HY, 2008, I C COMP AID DES CON, P783, DOI 10.1109/CAIDCD.2008.4730680
   Cordier F, 2003, IEEE COMPUT GRAPH, V23, P38, DOI 10.1109/MCG.2003.1159612
   Grupp M, 2016, ARXIV160600474
   Huber P, 2015, FITTING 3D MORPHABLE, P1195
   Huber P, 2017, IEEE SIGNAL PROC LET, V24, P437, DOI 10.1109/LSP.2016.2643284
   Jevsnik S., 2017, Journal of Fiber Bioengineering and Informatics, V10, P51, DOI DOI 10.3993/JFBIM00253
   Jiang XM, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 1, P493, DOI 10.1109/ICACC.2010.5487152
   Lafon R, 2004, CADALYST, V12, P30
   Liu SJ, 2009, INT C COMP AID IND D, P377, DOI 10.1109/CAIDCD.2009.5375436
   Milborrow S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P378, DOI 10.1109/ICCVW.2013.57
   Nair P, 2009, IEEE T MULTIMEDIA, V11, P611, DOI 10.1109/TMM.2009.2017629
   Sabina O, 2014, PROCEDIA ENGINEER, V69, P555, DOI 10.1016/j.proeng.2014.03.026
   Tudjarov B, 2008, P 3 INT C MASS CUST, P7
   Vidya System provided by the Assyst GmbH (Human Solutions Group), VID SYST PROV ASS GM
   Violante MG, 2014, COMPUT APPL ENG EDUC, V22, P708, DOI 10.1002/cae.21564
   Xiao-Ling LI, 2007, COMPUT ENG APPL, V43, P90
   Xiaogang L., 2008, J DONGHUA U, V29, P23
   Xie X, 2017, PROC IEEE MICR ELECT, P813, DOI 10.1109/MEMSYS.2017.7863532
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Xin X, 2014, J MICROMECH MICROENG, V24
   Yang Shui Li, 2011, Proceedings 2011 Fourth International Conference on Information Management, Innovation Management and Industrial Engineering (ICIII 2011), P3, DOI 10.1109/ICIII.2011.287
   Zeng Y, 2016, IEEE T PATTERN ANAL, V38, P2416, DOI 10.1109/TPAMI.2016.2528240
   Zhang XF, 2014, INT J TECHNOL DES ED, V24, P223, DOI 10.1007/s10798-013-9247-7
   Zhu S, 2004, COTTON TEXTILE TECHN
   Zhu SS, 2007, INT C COMP SUPP COOP, P337
NR 34
TC 17
Z9 19
U1 13
U2 120
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27163
EP 27179
DI 10.1007/s11042-018-5912-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500043
DA 2024-07-18
ER

PT J
AU Martinez, HAB
   Farias, MCQ
AF Becerra Martinez, Helard A.
   Farias, Mylene C. Q.
TI Combining audio and video metrics to assess audio-visual quality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video quality metrics; Audio quality metrics; Audio-visual quality
   metrics; Qoe; Multimedia quality assessment
ID STANDARD
AB In this work, we studied the use of combination models to integrate audio and video quality estimates to predict the overall audio-visual quality. More specifically, an overall quality prediction for an audio-visual signal is obtained by combining the outputs of individual audio and video quality metrics with either a linear, a Minkowski, or a power function. A total of 7 different video quality metrics are considered, from which 3 are Full-Reference and 4 are No-Reference. Similarly, a total of 4 audio quality metrics are tested, 2 of which are Full-Reference and 2 are No-Reference. In total, we tested 18 Full-Reference audio-visual combination metrics and 24 No-Reference audio-visual combination metrics. The performance of all combination metrics are tested on two different audio-visual databases. Therefore, besides analysing the performance of a set of individual audio and video quality metrics, we analyzed the performance of the models that combine these audio and video quality metrics. This work gives an important contribution to the area of audio-visual quality assessment, since previous works either tested combination models only on subjective quality scores or used linear models to combine the outputs of a limited number of audio and video quality metrics.
C1 [Becerra Martinez, Helard A.] Univ Brasilia UnB, Dept Comp Sci, Campus Univ Darcy Ribeiro, BR-70919970 Brasilia, DF, Brazil.
   [Farias, Mylene C. Q.] Univ Brasilia UnB, Dept Elect Engn, Campus Univ Darcy Ribeiro, BR-70919970 Brasilia, DF, Brazil.
C3 Universidade de Brasilia; Universidade de Brasilia
RP Martinez, HAB (corresponding author), Univ Brasilia UnB, Dept Comp Sci, Campus Univ Darcy Ribeiro, BR-70919970 Brasilia, DF, Brazil.
EM helardb@unb.br; mylene@ieee.org
RI Farias, Mylene/C-4900-2015
OI Farias, Mylene/0000-0002-1957-9943; Becerra, Helard/0000-0003-2652-3195
FU Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq)
   Brazil; Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior
   (CAPES) - Brazil; University of Brasilia
FX This work was supported in part by Conselho Nacional de Desenvolvimento
   Cientifico e Tecnologico (CNPq) Brazil, in part by Coordenacao de
   Aperfeicoamento de Pessoal de Nivel Superior (CAPES) - Brazil, and in
   part by the University of Brasilia.
CR [Anonymous], 1998, METHODOLOGY SUBJECTI
   [Anonymous], IEEE ICIP 2005 SEPT
   Bong DBL, 2015, MULTIMED TOOLS APPL, V74, P7355, DOI 10.1007/s11042-014-1983-5
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Engelke U, 2007, 2007 NEXT GENERATION INTERNET NETWORKS, P190, DOI 10.1109/NGI.2007.371215
   García-Barriuso M, 2012, PLANT BIOSYST, V146, P291, DOI 10.1080/11263504.2011.607194
   Hands DS, 2004, IEEE T MULTIMEDIA, V6, P806, DOI 10.1109/TMM.2004.837233
   Hines A., 2012, IWAENC 2012; International Workshop on Acoustic Signal Enhancement, P1
   Hines A, 2015, INT C DRESD, P6
   Hines A, 2013, INT CONF ACOUST SPEE, P3697, DOI 10.1109/ICASSP.2013.6638348
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Malfait L, 2006, IEEE T AUDIO SPEECH, V14, P1924, DOI 10.1109/TASL.2006.883177
   Martinez HB, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.6.061108
   Martinez HB, 2014, EUR SIGNAL PR CONF, P2125
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Moorthy AK, 2011, MULTIMED TOOLS APPL, V51, P675, DOI 10.1007/s11042-010-0640-x
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Pinson MH, 2013, INT WORK QUAL MULTIM, P30, DOI 10.1109/QoMEX.2013.6603199
   Pinson MH, 2011, IEEE SIGNAL PROC MAG, V28, P60, DOI 10.1109/MSP.2011.942470
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Soh K., 2001, Transactions of the Institute of Electronics, Information and Communication Engineers A, VJ84-A, P1305
   Thiede T, 2000, J AUDIO ENG SOC, V48, P3
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Winkler S, 2006, IEEE T MULTIMEDIA, V8, P973, DOI 10.1109/TMM.2006.879871
   Yamagishi K, 2013, IEEE INT WORKSH MULT, P464, DOI 10.1109/MMSP.2013.6659333
NR 27
TC 9
Z9 10
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23993
EP 24012
DI 10.1007/s11042-018-5656-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900039
DA 2024-07-18
ER

PT J
AU Khan, NU
   Arya, KV
AF Khan, Nafis Uddin
   Arya, K. V.
TI Two stage image de-noising by SVD on large scale heterogeneous
   anisotropic diffused image data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Singular value decomposition; Anisotropic diffusion; Image de-noising;
   Edge enhancement
ID SINGULAR-VALUE DECOMPOSITION; WEIGHTED MEDIAN FILTER; EDGE-DETECTION;
   IMPULSE NOISE; ENHANCEMENT; REDUCTION; REMOVAL
AB De-noising of images along with the edge enhancement has always been a challenging task in large scale heterogeneous image data. This paper presents a two stage image de-noising as well as edge enhancement method where in the first stage two copies of input noisy image are created through diffusion. The first copy is got by using anisotropic diffusion method which employ optimal diffusion function while the second copy is generated to improve the sharp edges by applying the combination of inverse heat diffusion and Canny edge detector. In the next stage, the singular value decomposition is applied on the two copies achieved in first stage to reduce the noise and improve the quality of detected edges. The optimal number of significant singular values have been estimated by the analysis of signal to noise ratio of singular value decomposed images of first copy. The singular values extracted from the second copy of the diffused image are superimposed with non decreasing weights from linear weighting function. Finally the sharp edged and noise reduced output image is generated by taking the linear combination of two singular value decomposed images. The performance of the proposed method has been compared with existing methods based on singular value decomposition as well as anisotropic diffusion. The experimental results exhibit that the proposed method efficiently enhances the edges by reducing the noisy significantly.
C1 [Khan, Nafis Uddin] Jaypee Univ Informat Technol, Dept Elect & Commun Engn, Waknaghat 173234, India.
   [Arya, K. V.] Inst Engn & Technol, Dept Comp Sci & Engn, Lucknow 226021, Uttar Pradesh, India.
C3 Jaypee University of Information Technology; Dr. A.P.J. Abdul Kalam
   Technical University (AKTU); Institute of Engineering & Technology
   Lucknow
RP Khan, NU (corresponding author), Jaypee Univ Informat Technol, Dept Elect & Commun Engn, Waknaghat 173234, India.
EM nafisuddin.khan@juit.ac.in; kvarya@ietlucknow.ac.in
RI Khan, Nafis uddin/IAR-4272-2023
OI Arya, Karm Veer/0000-0001-7117-1745; Khan, nafis
   uddin/0000-0002-4681-5278
CR ANDREWS HC, 1976, IEEE T ACOUST SPEECH, V24, P26, DOI 10.1109/TASSP.1976.1162766
   [Anonymous], DIGITAL IMAGE PROCES
   BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chan FHY, 1998, IEEE T IMAGE PROCESS, V7, P468, DOI 10.1109/83.661196
   Chao LT, 2007, INF SCI, V177, P1073
   Chao SM, 2010, PATTERN RECOGN LETT, V31, P2012, DOI 10.1016/j.patrec.2010.06.004
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Dai F, 2008, SIGNAL PROCESS, V88, P2850, DOI 10.1016/j.sigpro.2008.05.008
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   Gilboa G, 2002, LECT NOTES COMPUT SC, V2350, P399
   Goshtasby A, 2008, COMPUT VIS IMAGE UND, V111, P155, DOI 10.1016/j.cviu.2007.09.008
   Guo Q, 2016, IEEE T CIRC SYST VID, V26, P868, DOI 10.1109/TCSVT.2015.2416631
   He YM, 2011, IEEE SIGNAL PROC LET, V18, P215, DOI 10.1109/LSP.2011.2109039
   Hossain M.F., 2008, ARPN J ENG APPL SCI, V3, P31
   Hou ZJ, 2003, PATTERN RECOGN, V36, P1747, DOI 10.1016/S0031-3203(02)00323-0
   Jha SK, 2011, IEEE SENS J, V11, P35, DOI 10.1109/JSEN.2010.2049351
   Khan, 2012, 8 INDIAN C VISION GR
   Khan NU, 2014, MULTIMED TOOLS APPL, V73, P573, DOI 10.1007/s11042-013-1620-8
   Khan NU, 2013, SIGNAL PROCESS, V93, P1684, DOI 10.1016/j.sigpro.2012.09.009
   Khan NU, 2010, IEEE SYS MAN CYBERN, P3735, DOI 10.1109/ICSMC.2010.5641838
   Khan NU, 2012, INT J COMPUT ELECT E, V4, P303
   Khan NU, 2014, IEEE INT C IND INF S
   KONSTANTINIDES K, 1988, IEEE T ACOUST SPEECH, V36, P757, DOI 10.1109/29.1585
   Konstantinides K, 1997, IEEE T IMAGE PROCESS, V6, P479, DOI 10.1109/83.557359
   Mohideen K., 2011, INT ARAB J E TECHNOL, V2, P49
   Nikpour M., 2009, INT J COMPUTING ICT, V3, P42
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pinho AJ, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P591, DOI 10.1109/ICIP.1996.560564
   Puvanathasan P, 2009, OPT EXPRESS, V17, P733, DOI 10.1364/OE.17.000733
   Yu JH, 2008, PATTERN RECOGN LETT, V29, P1496, DOI 10.1016/j.patrec.2008.03.002
   Zhijia Z, 2008, IEEE INT C IM SIGN P, P411
NR 32
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22543
EP 22566
DI 10.1007/s11042-018-6144-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500041
DA 2024-07-18
ER

PT J
AU Kumar, M
   Mishra, SK
AF Kumar, M.
   Mishra, S. K.
TI Java based functional link multilayer perceptron adaptive filter for
   Poisson noise suppression from X-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Poisson noise; X-ray image; Adaptive filter; Artificial neural network;
   Optimization; Friedman's test
ID NEURAL-NETWORK; ULTRASOUND IMAGES; RESTORATION; SEGMENTATION;
   OPTIMIZATION; ALGORITHM
AB In this paper, a parameterless Jaya optimization based neural network filter named as Jaya-functional link multilayer perceptron (Jaya-FLMLP) is proposed for the elimination of Poisson noise from X-ray images. In this proposed adaptive filter, Jaya is applied for updating the weights of the FLMLP network. The proposed neural filter is a combination of a functional link artificial neural network (FLANN) and Multilayer Perceptron (MLP) network. The performance of Jaya-FLMLP is also compared with other five competitive networks such as Wiener, MLP, Least Mean Squares based Functional Link Artificial Neural Network (LMS-FLANN), Particle Swarm Optimization based Functional Link Artificial Neural Network (PSO-FLANN) and Cat Swarm Optimization based Functional Link Artificial Neural Network (CSO-FLANN). The comparison of performance is investigated by the Structural Similarity Index (SSIM), Peak Signal to Noise Ratio (PSNR) and Noise Reduction in Decibels (NRDB) values. The simulation results and non-parametric Friedman's test reveal the superiority of the Jaya-FLMLP filter over others.
C1 [Kumar, M.] Birla Inst Technol, Ranchi, Bihar, India.
C3 Birla Institute of Technology Mesra
RP Kumar, M (corresponding author), Birla Inst Technol, Ranchi, Bihar, India.
EM manish.guptasssss007@gmail.com
RI Kumar, Manish/V-4818-2017; KUMAR, MANISH/C-3182-2019; Mishra, Sudhansu
   Kumar/AFT-7650-2022
OI Kumar, Manish/0000-0003-3247-8589; KUMAR, MANISH/0000-0003-3247-8589;
   Mishra, Sudhansu Kumar/0000-0003-1733-8270
CR [Anonymous], 2013, 6 INT C IM SIGN PROC
   [Anonymous], ENG OPTIMIZ
   Chen F, 2015, 11 INT C NAT COMP
   Chen S., 2014, COMPUT INTELL BIOMED, V9781461472, P211, DOI [10.1007/978-1-4614-7245-2_9, DOI 10.1007/978-1-4614-7245-2_9]
   Dash Prajna Parimita, 2011, International Journal of Computational Vision and Robotics, V2, P206, DOI 10.1504/IJCVR.2011.042839
   Dehuri S, 2010, EXPERT SYST APPL, V37, P4379, DOI 10.1016/j.eswa.2009.11.090
   Dokur Z, 2002, PATTERN RECOGN LETT, V23, P1825, DOI 10.1016/S0167-8655(02)00155-1
   Duan H, 2016, IEEE T NEURAL NETWOR, V27, P1
   Giakoumis I, 2006, IEEE T IMAGE PROCESS, V15, P178, DOI 10.1109/TIP.2005.860311
   He LL, 2009, IEEE T MED IMAGING, V28, P165, DOI 10.1109/TMI.2008.927338
   Kumar M, 2016, APPL COMPUT INTELL S, V2016, DOI 10.1155/2016/6304915
   Kumar M, 2017, BIOMED RES-INDIA, V28, P4159
   Kumari Manisha, 2015, Biospectra, V10, P1
   Li Y., 2007, P 3 INT C NAT COMP
   Majhi B, 2011, EXPERT SYST APPL, V38, P321, DOI 10.1016/j.eswa.2010.06.070
   Mateos-García D, 2012, PATTERN RECOGN LETT, V33, P2232, DOI 10.1016/j.patrec.2012.08.011
   Mirjalili S, 2012, APPL MATH COMPUT, V218, P11125, DOI 10.1016/j.amc.2012.04.069
   Pao YH., 1989, Adaptive Pattern Recognition and Neural Networks
   Perry SW, 2000, IEEE T NEURAL NETWOR, V11, P156, DOI 10.1109/72.822518
   Rao RV, 2016, APPL THERM ENG, V103, P572, DOI 10.1016/j.applthermaleng.2016.04.135
   Rao RV, 2016, INT J IND ENG COMPUT, V719-34, P2016
   Saadi S, 2013, MICROPROCESS MICROSY, V37, P52, DOI 10.1016/j.micpro.2012.09.013
   Sicuranza GL, 2011, IEEE T AUDIO SPEECH, V19, P2412, DOI 10.1109/TASL.2011.2136336
   SIVAKUMAR K, 1993, IEEE T SIGNAL PROCES, V41, P2018, DOI 10.1109/78.215329
   Suzuki K, 2003, IEEE T PATTERN ANAL, V25, P1582, DOI 10.1109/TPAMI.2003.1251151
   van Ginneken B, 2006, MED IMAGE ANAL, V10, P19, DOI 10.1016/j.media.2005.02.002
   Wang HN, 2018, MULTIMED TOOLS APPL, V77, P3871, DOI 10.1007/s11042-016-4242-0
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zeng W, 2015, MULTIMED TOOLS APPL, V74, P743, DOI 10.1007/s11042-013-1692-5
   Zhang D, 2010, IEEE C SYST MAN CYB
   Zhao HQ, 2008, SIGNAL PROCESS, V88, P1946, DOI 10.1016/j.sigpro.2008.01.029
   Zhao HQ, 2010, IEEE T SYST MAN CY B, V40, P162, DOI 10.1109/TSMCB.2009.2024313
   ZHOU YT, 1988, IEEE T ACOUST SPEECH, V36, P1141, DOI 10.1109/29.1641
NR 33
TC 11
Z9 11
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24405
EP 24425
DI 10.1007/s11042-017-5592-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900059
DA 2024-07-18
ER

PT J
AU Pan, GL
   Xin, Z
   Shi, S
   Jin, DW
AF Pan, Guolin
   Xin, Zhuo
   Shi, Si
   Jin, Dawei
TI Arrhythmia classification based on wavelet transformation and random
   forests
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arrhythmia classification; Wavelet transformation; Autocorrelation;
   Random forests
AB Cardiovascular disease accompanied by arrhythmia reduces an individual's lifespan and health, and long term ECG monitoring would generate large amounts of data. Fortunately, arrhythmia classification assisted by computer science would greatly improve the efficiency of doctors' diagnoses. However, due to individual differences, noise affecting the signal, the great variety of arrhythmias, and heavy computing workload, it is difficult to implement these advanced techniques for clinical context analysis. Thus, this paper proposes a comprehensive approach based on discrete wavelet and random forest techniques for arrhythmia classification. Specifically, discrete wavelet transformation is used to remove high-frequency noise and baseline drift, while discrete wavelet transformation, autocorrelation, principal component analysis, variances and other mathematical methods are used to extract frequency-domain features, time-domain features and morphology features. Furthermore, an arrhythmia classification system is developed, and its availability is verified that the proposed scheme can significantly be used for guidance and reference in clinical arrhythmia automatic classification.
C1 [Pan, Guolin] China Univ Geosci, Sch Econ & Management, Wuhan 430073, Hubei, Peoples R China.
   [Xin, Zhuo; Jin, Dawei] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Hubei, Peoples R China.
   [Shi, Si] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430073, Hubei, Peoples R China.
C3 China University of Geosciences; Zhongnan University of Economics & Law;
   Huazhong University of Science & Technology
RP Jin, DW (corresponding author), Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Hubei, Peoples R China.
EM jdw@zuel.edu.cn
FU National Social Science Foundation of China [13CTJ003]; China
   Postdoctoral Science Foundation [2014M562025]
FX This work was supported in part by the National Social Science
   Foundation of China under Grant 13CTJ003 and in part by the China
   Postdoctoral Science Foundation under Grant 2014M562025.
CR Gutiérrez-Gnecchi JA, 2017, BIOMED SIGNAL PROCES, V32, P44, DOI 10.1016/j.bspc.2016.10.005
   Chen M, 2017, IEEE COMMUN MAG, V55, P54, DOI 10.1109/MCOM.2017.1600410CM
   Chen NC, 2017, IEEE INT CONGR BIG, P1, DOI 10.1109/BigDataCongress.2017.10
   Daubechies I., 1992, COMPUT PHYS, V6, P697, DOI DOI 10.1063/1.4823127
   Jiapu P, 1985, REAL TIME QRS DETECT
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Khalaf AF, 2015, EXPERT SYST APPL, V42, P8361, DOI 10.1016/j.eswa.2015.06.046
   Kutlu Y., 2016, INT C ADV TECHN SCI
   Li C, 2002, IEEE T BIOMED ENG, V42, P21
   Li S, 2009, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE AND ENGINEERING MANAGEMENT, P146
   LinPeng JJD, 2015, SCI SINICA INFORM, V43, P398
   Natinoal Center for Cardiovascular Diseases, 2014, REP CARD DIS CHIN
   Nn AR, 2009, EURASIP J ADV SIG PR, V2008, P1
   Sathish B, 2009, INT J HEALTHCARE INF, V5, P1
   Shi XB, 2016, IEEE ACCESS, V4, P7074, DOI 10.1109/ACCESS.2016.2614541
   Van Houwelingen H C., 2004, Springer Series in Statistics, V23, P528, DOI DOI 10.1002/SIM.1616
   Yeh YC, 2008, COMPUT METH PROG BIO, V91, P245, DOI 10.1016/j.cmpb.2008.04.006
   Yu SN, 2007, PATTERN RECOGN LETT, V28, P1142, DOI 10.1016/j.patrec.2007.01.017
   Zhang YJ, 2015, IEEE T VLSI SYST, V23, P1170, DOI 10.1109/TVLSI.2014.2326797
   Zhang Y, 2017, FUTURE GENER COMP SY, V66, P30, DOI 10.1016/j.future.2015.12.001
   Zhang Y, 2015, MOBILE NETW APPL, V20, P348, DOI 10.1007/s11036-014-0537-4
   Zhao QB, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P1089
   Zhou Yu-Feng, 2008, Wuli, V37, P24
NR 23
TC 10
Z9 10
U1 2
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 21905
EP 21922
DI 10.1007/s11042-017-5225-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500006
DA 2024-07-18
ER

PT J
AU Song, J
   Yoon, G
   Cho, H
   Yoon, SM
AF Song, Jinjoo
   Yoon, Gangjoon
   Cho, Heeryon
   Yoon, Sang Min
TI Structure preserving dimensionality reduction for visual object
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dimensionality reduction; Object recognition; Structured sparse PCA
ID REPRESENTATION; FEATURES
AB Robust object recognition has drawn increasing attention in the field of computer vision and machine learning with fast development in feature extraction and classification techniques, and release of public datasets, such as Caltech datasets, Pascal Visual Object Classes, and ImageNet. Recently, deep learning based object recognition systems have shown significant performance improvements in visual object recognition tasks using innovative learning methodology. However, high dimensional space searching and recognition is time consuming, so performing point and range queries in high dimension is reconsidered for object recognition. This paper proposes optimized dimensionality reduction using structured sparse principle component analysis. The proposed method retains high dimensional feature structures, removes redundant features that do not contribute to similarity, and classifies the query image in a large database. The qualitative and quantitative experimental results, including a comparison with the current state-of-the-art visual object recognition algorithms, verify that the proposed recognition algorithm performs favorably in reducing the query image dimension and number of training images.
C1 [Song, Jinjoo; Cho, Heeryon; Yoon, Sang Min] Kookmin Univ, Coll Comp Sci, HCI Lab, Seoul, South Korea.
   [Yoon, Gangjoon] Natl Inst Math Sci, Daejeon, South Korea.
C3 Kookmin University; National Institute for Mathematical Sciences (NIMS),
   Republic of Korea
RP Yoon, SM (corresponding author), Kookmin Univ, Coll Comp Sci, HCI Lab, Seoul, South Korea.
EM decpearl@kookmin.ac.kr; gangjoon@gmail.com; heeryon@kookmin.ac.kr;
   smyoon@kookmin.ac.kr
RI Cho, Heeryon/C-9255-2013; Cho, Heeryon/E-9478-2011; Yoon,
   Gangjoon/GZM-8532-2022
OI Cho, Heeryon/0000-0001-9912-1002; Cho, Heeryon/0000-0001-9912-1002; 
FU National Research Foundation of Korea [2015R1A5A7037615,
   2016R1D1A1B04932889, 2017R1A2B4011015]; IITP by the Korean Government
   [2014-0-00501]; National Institute for Mathematical Sciences (NIMS)
FX J. Song and S.M. Yoon were supported by the National Research Foundation
   of Korea grants funded (No.2015R1A5A7037615, No.2016R1D1A1B04932889) and
   IITP (#2014-0-00501) by the Korean Government. H. Cho was support by the
   National Research Foundation of Korea (No. 2017R1A2B4011015). G.J. Yoon
   was supported by National Institute for Mathematical Sciences (NIMS).
CR Abdechiri M, 2017, SIGNAL PROCESS-IMAGE, V54, P23, DOI 10.1016/j.image.2017.02.004
   AKAIKE H, 1987, PSYCHOMETRIKA, V52, P317, DOI 10.1007/BF02294359
   [Anonymous], 2006, COMP VIS PATT REC IE
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], ARXIV151202325
   Arias RS, THESIS
   BELLMAN R, 1966, SCIENCE, V153, P34, DOI 10.1126/science.153.3731.34
   Bo L, 2013, IEEE C COMP VIS PATT
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963
   Ciresan Dan C., 2011, CORR
   Davison M.L., 1983, Multidimensional scaling
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559
   Gan GJ, 2015, PATTERN RECOGN, V48, P3703, DOI 10.1016/j.patcog.2015.05.016
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hoffmann H, 2007, PATTERN RECOGN, V40, P863, DOI 10.1016/j.patcog.2006.07.009
   Huang J., 2009, P 26 ANN INT C MACHI, P417, DOI [10.1145/1553374.1553429, DOI 10.1145/1553374.1553429]
   Huang JZ, 2010, ANN STAT, V38, P1978, DOI 10.1214/09-AOS778
   HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519
   Jenatton R, 2011, J MACH LEARN RES, V12, P2777
   Jenatton Rodolphe, 2010, PMLR, V9, P366
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kavukcuoglu K., 2010, Advances in neural information processing systems, P1
   Laming Chen, 2012, 2012 International Conference on Computing, Networking and Communications (ICNC), P897, DOI 10.1109/ICCNC.2012.6167554
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee T.-W., 1998, Independent component analysis
   Lofstedt T, 2016, ARXIV160901423
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Naikal N, 2011, IEEE I CONF COMP VIS, P818, DOI 10.1109/ICCV.2011.6126321
   Oliveira GL, 2012, IEEE INT CONF ROBOT, P2592, DOI 10.1109/ICRA.2012.6224785
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Redmon J., 2017, CVPR 2017, DOI DOI 10.1142/9789812771728_0012
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Serre T, 2005, PROC CVPR IEEE, P994
   Sohn K, 2011, IEEE I CONF COMP VIS, P2643, DOI 10.1109/ICCV.2011.6126554
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Weinberger K. Q., 2006, AAAI, P1683
   Weinberger KQ, 2006, INT J COMPUT VISION, V70, P77, DOI 10.1007/s11263-005-4939-z
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang ST, 2012, IEEE T SYST MAN CY B, V42, P838, DOI 10.1109/TSMCB.2011.2179533
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zhu PF, 2017, PATTERN RECOGN, V66, P364, DOI 10.1016/j.patcog.2017.01.016
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 50
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23529
EP 23545
DI 10.1007/s11042-018-5682-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900021
DA 2024-07-18
ER

PT J
AU Zhang, XY
   Constable, M
   Chan, KL
AF Zhang, Xiaoyan
   Constable, Martin
   Chan, Kap Luk
TI Transfer of content-aware vignetting effect from paintings to
   photographs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Style transfer; Vignetting; Contrast manipulation
ID GRADIENT DISTRIBUTION; IMAGE; ENHANCEMENT
AB This paper discusses how the vignetting effect of paintings may be transferred to photographs, with attention to center-corner contrast. First, the lightness distribution of both are analyzed. The results show that the painter's vignette is more complex than that achieved using common digital post-processing methods. It is shown to involve both the 2D and 3D geometry of the scene. Then, an algorithm is developed to transfer the vignetting effect from an example painting to a photograph. The example painting is selected as that has similar contextual geometry with the photograph. The lightness weighting pattern extracted from the selected example painting is adaptively blended with the input photograph to create vignetting effect. In order to avoid over-brightened or over-darkened regions in the enhancement result, the extracted lightness weighting pattern is corrected using a nonlinear curve. A content-aware interpolation method is also proposed to warp the lightness weighting to fit the contextual structure of the photograph. Finally, the local contrast is restored. Experiments show that the proposed algorithm can successfully perform this function. The resulting vignetting effect is more naturally presented with regard to esthetic composition as compared with vignetting achieved with popular software tools and camera models.
C1 [Zhang, Xiaoyan] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
   [Constable, Martin] RMIT Univ, Ho Chi Minh, Vietnam.
   [Chan, Kap Luk] Tolendata Singapore R&D Ctr Private Ltd, Singapore, Singapore.
C3 Shenzhen University; Royal Melbourne Institute of Technology (RMIT)
RP Zhang, XY (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
EM xyzhang15@szu.edu.cn
RI Li, Mengqi/AAG-6804-2021
FU National Natural Science Foundation of China [61602313, 61620106008,
   61602312]; Shenzhen Commission of Scientific Research Innovations
   [JCYJ20170302153632883]; Tencent "Rhinoceros Birds" - Scientific
   Research Foundation for Young Teachers of Shenzhen University; Research
   Foundation of Shenzhen University [2016051]; Startup Foundation for
   Advanced Talents, Shenzhen
FX This work was supported in part by: (i) the National Natural Science
   Foundation of China (Grant No. 61602313, 61620106008, and 61602312);
   (ii) Shenzhen Commission of Scientific Research & Innovations under the
   Grant No. JCYJ20170302153632883; (iii) Tencent "Rhinoceros Birds" -
   Scientific Research Foundation for Young Teachers of Shenzhen
   University; (iv) Research Foundation of Shenzhen University(2016051);
   (v)Startup Foundation for Advanced Talents, Shenzhen.
CR [Anonymous], ARXIV170501088V2
   [Anonymous], ARXIV160601621V2
   [Anonymous], ARXIV170800684V1
   [Anonymous], 2015, ARXIV150806576V2
   [Anonymous], CS281A STAT LEARNING
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], P INT C COMP VIS PAT
   [Anonymous], COLOR HARMONIES PAIN
   [Anonymous], COMPUTER GRAPHICS FO
   [Anonymous], COMPUTATIONAL APPROA
   [Anonymous], ARXIV170504058V1
   [Anonymous], P ACCV WORKSH
   [Anonymous], 2017, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2016.2644615
   [Anonymous], 2015, INT J DIGIT ART HIST
   Bychkovsky V, 2011, PROC CVPR IEEE, P97
   Chang Y, 2007, IEEE T IMAGE PROCESS, V16, P329, DOI 10.1109/TIP.2006.888347
   Chen W, 2016, P C NEURAL INFORM PR, P1
   Cho H, 2014, LECT NOTES COMPUT SC, V8690, P189, DOI 10.1007/978-3-319-10605-2_13
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Fiser J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073660
   Goldman DB, 2010, IEEE T PATTERN ANAL, V32, P2276, DOI 10.1109/TPAMI.2010.55
   Huang H, 2010, VISUAL COMPUT, V26, P933, DOI 10.1007/s00371-010-0498-y
   Huang W, 2018, SIGNAL PROCESS, V142, P104, DOI 10.1016/j.sigpro.2017.07.015
   Li CC, 2009, IEEE J-STSP, V3, P236, DOI 10.1109/JSTSP.2009.2015077
   Li J, 2012, IEEE T PATTERN ANAL, V34, P1159, DOI 10.1109/TPAMI.2011.203
   Liu GW, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2162
   Liu YM, 2014, COMPUT GRAPH FORUM, V33, P21, DOI 10.1111/cgf.12409
   Rigau J, 2008, IEEE COMPUT GRAPH, V28, P24, DOI 10.1109/MCG.2008.34
   Rosales R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P472
   Wang B, 2004, IEEE T VIS COMPUT GR, V10, P266, DOI 10.1109/TVCG.2004.1272726
   Wu JX, 2017, MULTIMED TOOLS APPL, V76, P9625, DOI 10.1007/s11042-016-3569-x
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Zhang XY, 2014, COMPUT GRAPH FORUM, V33, P38, DOI 10.1111/cgf.12399
   Zhang XY, 2014, IEEE T MULTIMEDIA, V16, P653, DOI 10.1109/TMM.2014.2299511
   Zhang XM, 2017, MILITARY MED RES, V4, P1, DOI 10.1186/s40779-017-0131-8
   Zhao M., 2010, PROC INT S NONPHOTOR, P99, DOI DOI 10.1145/1809939.1809951
   Zheng YJ, 2013, IEEE T PATTERN ANAL, V35, P1480, DOI 10.1109/TPAMI.2012.210
   Zheng YJ, 2009, LECT NOTES COMPUT SC, V5762, P852, DOI 10.1007/978-3-642-04271-3_103
   Zhou B, 2017, P INT C COMPUTER VIS, P1
   Zhu YY, 2018, NEUROCOMPUTING, V275, P499, DOI 10.1016/j.neucom.2017.08.055
NR 43
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23851
EP 23875
DI 10.1007/s11042-018-5629-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900034
DA 2024-07-18
ER

PT J
AU Fernández-Martínez, F
   Hernández-García, A
   Fernández-Torres, M
   González-Díaz, I
   García-Faura, A
   de María, FD
AF Fernandez-Martinez, F.
   Hernandez-Garcia, A.
   Fernandez-Torres, M. A.
   Gonzalez-Diaz, I.
   Garcia-Faura, A.
   Diaz de Maria, F.
TI Exploiting visual saliency for assessing the impact of car commercials
   upon viewers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual attention; Saliency; Scene analysis; Aesthetics assessment;
   Feature extraction; Video impact assessment
ID EYE-MOVEMENTS; ATTENTION; MODEL; SELECTION; SYSTEMS; GAZE
AB Content based video indexing and retrieval (CBVIR) is a lively area of research which focuses on automating the indexing, retrieval and management of videos. This area has a wide spectrum of promising applications where assessing the impact of audiovisual productions emerges as a particularly interesting and motivating one. In this paper we present a computational model capable to predict the impact (i.e. positive or negative) upon viewers of car advertisements videos by using a set of visual saliency descriptors. Visual saliency provides information about parts of the image perceived as most important, which are instinctively targeted by humans when looking at a picture or watching a video. For this reason we propose to exploit visual information, introducing it as a new feature which reflects high-level semantics objectively, to improve the video impact categorization results. The suggested salience descriptors are inspired by the mechanisms that underlie the attentional abilities of the human visual system and organized into seven distinct families according to different measurements over the identified salient areas in the video frames, namely population, size, location, geometry, orientation, movement and photographic composition. Proposed approach starts by computing saliency maps for all the video frames, where two different visual saliency detection frameworks have been considered and evaluated: the popular graph based visual saliency (GBVS) algorithm, and a state-of-the-art DNN-based approach. Then, frame-level salience descriptors are extracted from these maps. Next, pooled statistics are used to collapse the obtained frame-level values into video-level descriptors. Finally, a Logistic regression classifier is built upon the subset of video-level features resulting from a feature selection stage. Experimental validation, conducted on a publicly available corpus of 138 commercials collected from YouTube, shows that the proposed salience descriptors are indicative of the impact upon viewers and achieve a similar performance when compared to a method purely based on aesthetics. Besides, the combined approach, exploiting both saliency and aesthetics together, ultimately results in better performance than what can be achieved individually. In addition, the seven families of salience descriptors defined are also compared in terms of classification performance. Finally, a similar study is also performed targeting the distinct pooling techniques used in the video-level feature computation.
C1 [Fernandez-Martinez, F.; Garcia-Faura, A.] Univ Politecn Madrid, Informat Proc & Telecommun Ctr, Madrid, Spain.
   [Hernandez-Garcia, A.; Fernandez-Torres, M. A.; Gonzalez-Diaz, I.] Univ Carlos III Madrid, Signal Theory & Commun Dept, Getafe, Spain.
   [Diaz de Maria, F.] Univ Carlos III Madrid, Dept Signal Proc & Commun, Getafe, Spain.
C3 Universidad Politecnica de Madrid; Centro de I+D+I en Procesado de la
   Informacion Telecomunicaciones (IPT); Universidad Carlos III de Madrid;
   Universidad Carlos III de Madrid
RP Fernández-Martínez, F (corresponding author), Univ Politecn Madrid, Informat Proc & Telecommun Ctr, Madrid, Spain.
EM fernando.fernandezm@upm.es; ahgarcia@tsc.uc3m.es; matorres@tsc.uc3m.es;
   igonzalez@tsc.uc3m.es; agfaura@die.upm.es; fdiaz@tsc.uc3m.es
RI Díaz, Iván González/L-5103-2014; Fernández-Martínez,
   Fernando/M-2935-2014; de María, Fernando Díaz/E-8048-2011;
   Fernández-Martínez, Fernando/JAC-7715-2023; Fernández-Torres,
   Miguel-Ángel/T-6507-2018
OI Díaz, Iván González/0000-0003-4644-8479; Fernández-Martínez,
   Fernando/0000-0003-3877-0089; de María, Fernando
   Díaz/0000-0002-6437-914X; Fernández-Martínez,
   Fernando/0000-0003-3877-0089; Fernández-Torres,
   Miguel-Ángel/0000-0002-0801-199X
FU Spanish Ministry of Economy and Competitiveness [RTC-2016-5305-7,
   TEC2014-53390-P]
FX This work has been partially supported by the National Grants
   RTC-2016-5305-7 and TEC2014-53390-P of the Spanish Ministry of Economy
   and Competitiveness. We also gratefully acknowledge the support of
   NVIDIA Corporation with the donation of the Titan X Pascal GPU used for
   this research.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   [Anonymous], ELCVIA
   [Anonymous], 1987, Shifts in selective visual attention: Towards the underlying neural circuitry. matters of intelligence
   [Anonymous], IEEE T PATTERN ANAL, DOI DOI 10.1007/978-3-642-14267-3_2
   [Anonymous], 1990, SUPPORT VECTOR LEARN
   [Anonymous], 2014, COMPUT VISUAL MEDIA
   Bhattacharya S, 2013, ACM MULTIMEDIA GRAND
   Boato G, 2016, MULTIMED TOOLS APPL, V75, P5581, DOI 10.1007/s11042-015-2526-4
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Brezeale D, 2008, IEEE T SYST MAN CY C, V38, P416, DOI 10.1109/TSMCC.2008.919173
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Carmi R, 2006, VISION RES, V46, P4333, DOI 10.1016/j.visres.2006.08.019
   Cerf M, 2009, J VISION, V9, DOI 10.1167/9.12.10
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Courty N, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1024
   Culibrk D, 2011, IEEE T IMAGE PROCESS, V20, P948, DOI 10.1109/TIP.2010.2080279
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   Dorr M, 2010, J VISION, V10, DOI 10.1167/10.10.28
   Egeth HE, 1997, ANNU REV PSYCHOL, V48, P269, DOI 10.1146/annurev.psych.48.1.269
   Fathi A, 2012, LECT NOTES COMPUT SC, V7572, P314, DOI 10.1007/978-3-642-33718-5_23
   Fernández-Martínez F, 2015, EXPERT SYST APPL, V42, P293, DOI 10.1016/j.eswa.2014.07.033
   Fernandez-Martinez F, 2014, P 2 INT WORKSH SPEEC
   Friesen CK, 1998, PSYCHON B REV, V5, P490, DOI 10.3758/BF03208827
   González-Díaz I, 2014, ADV COMPUT VIS PATT, P79, DOI 10.1007/978-3-319-05696-8_4
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Haralick R. M., 1992, COMPUTER ROBOT VISIO
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hillaire S, 2010, COMPUT GRAPH FORUM, V29, P1830, DOI 10.1111/j.1467-8659.2010.01651.x
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Itti, 2007, Scholarpedia, V2, P3327, DOI DOI 10.4249/SCHOLARPEDIA.3327
   Itti L, 2005, VIS COGN, V12, P1093, DOI 10.1080/13506280444000661
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   James W, 1890, AMERICAN SCI SERIES
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang Y-G, 2013, P 27 AAAI C ART INT
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Khan S.S., 2012, P 8 ANN S COMPUTATIO, P55
   LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li QF, 2018, NEURAL COMPUT APPL, V30, P463, DOI 10.1007/s00521-016-2680-2
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Li ZX, 2013, ENG APPL ARTIF INTEL, V26, P2143, DOI 10.1016/j.engappai.2013.07.004
   Liang C, 2016, 2016 INTERNATIONAL CONFERENCE ON PROBABILISTIC METHODS APPLIED TO POWER SYSTEMS (PMAPS)
   Liang RZ, 2016, PROC INT C TOOLS ART, P299, DOI [10.1109/ICTAI.2016.50, 10.1109/ICTAI.2016.0053]
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Long Mai, 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P91, DOI 10.1109/ISM.2011.23
   Ma ZG, 2009, IEEE INT CON MULTI, P914, DOI 10.1109/ICME.2009.5202644
   Mancas M, 2011, IEEE IMAGE PROC, P229, DOI 10.1109/ICIP.2011.6116099
   Marchesotti L, 2011, IEEE I CONF COMP VIS, P1784, DOI 10.1109/ICCV.2011.6126444
   Moorthy AK, 2010, LECT NOTES COMPUT SC, V6315, P1, DOI 10.1007/978-3-642-15555-0_1
   Nguyen T.V., 2013, P 21 ACM INT C MULT, P987, DOI DOI 10.1145/2502081.2502128
   Niebur E, 1996, ADV NEUR IN, V8, P802
   Nothdurft Hans-Christoph, 2005, P233, DOI 10.1016/B978-012375731-9/50042-2
   Ogaki K., 2012, 2012 IEEE COMP SOC C, P1, DOI DOI 10.1109/CVPRW.2012.6239188
   Palmer S., 1999, VISION SCI PHOTONS P
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Parkhurst DJ, 2002, HUM FACTORS, V44, P611, DOI 10.1518/0018720024497015
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rapantzikos K, 2009, SIGNAL PROCESS-IMAGE, V24, P557, DOI 10.1016/j.image.2009.03.002
   Savakis AE, 2000, P SOC PHOTO-OPT INS, V3959, P111, DOI 10.1117/12.387147
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Smith E.E., 2013, Cognitive Psychology: Pearson New International Edition: Mind and Brain
   Su SL, 2004, 2004 MIT STUD OXYG W
   Tague N.R., 2005, The Quality Toolbox, Vsecond
   Tatler BW, 2011, J VISION, V11, DOI 10.1167/11.5.5
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Velásquez JP, 2013, ENG APPL ARTIF INTEL, V26, P1469, DOI 10.1016/j.engappai.2013.01.003
   Vig E, 2012, LECT NOTES COMPUT SC, V7578, P84, DOI 10.1007/978-3-642-33786-4_7
   Wan SH, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P172
   Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Xiao Lv, 2014, WSEAS Transactions on Computers, V13, P266
   Xu J, 2014, J VISION, V14, DOI 10.1167/14.1.28
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang CY, 2011, INT CONF ACOUST SPEE, P1165
   Yarbus A. L., 1967, Eye Movements and Vision
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao L, 2015, LECT NOTES COMPUT SC, V9005, P578, DOI 10.1007/978-3-319-16811-1_38
NR 86
TC 0
Z9 0
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 18903
EP 18933
DI 10.1007/s11042-017-5339-9
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Guo, M
   Wang, ZL
AF Guo, Ming
   Wang, Zhelong
TI Segmentation and recognition of human motion sequences using wearable
   inertial sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wearable inertial sensors; Human motion sequence; Pre-segmentation; Fine
   segmentation; Motion recognition
ID ALGORITHM; SYSTEM
AB The application of human motion monitoring technology based on wearable inertial sensors has achieved great success in the last ten years. But now the research is mainly focused on isolated motion recognition, and there is scarce research on recognition of human motion sequences. In this paper a novel monitoring framework of human motion sequences is proposed based on wearable inertial sensors. The monitoring framework is composed of data acquisition, segmentation, and recognition stages; the main work of this paper is the last two parts. At the segmentation stage, SVD is used to perform pre-segmentation of motion sequence and its purpose is to reduce time in the segmentation process as much as possible. Then a novel similarity measure named MSHsim, is proposed to accomplish the fine segmentation. At the recognition stage an HMM is used to recognize the motion sequence. We use four inertial sensors to collect the human motion data. Experiments are implemented to evaluate the performance of the proposed monitoring framework, and from the experiment results, it can be seen that the proposed method may achieve better performance compared to other methods.
C1 [Guo, Ming; Wang, Zhelong] Dalian Univ Technol, Sch Control Sci & Engn, Dalian 116024, Peoples R China.
C3 Dalian University of Technology
RP Guo, M (corresponding author), Dalian Univ Technol, Sch Control Sci & Engn, Dalian 116024, Peoples R China.
EM guoming0537@126.com; wangzl@dlut.edu.cn
RI Wang, Zilong/IQV-2260-2023; wang, z/A-4607-2016
OI Wang, Zilong/0009-0007-5784-1467; 
FU National Natural Science Foundation of China [61473058]; Fundamental
   Research Funds for the Central Universities [DUT15ZD114]; China
   Postdoctoral Science Foundation [2017M621131]
FX This work was supported by National Natural Science Foundation of China
   under Grant No.61473058, Fundamental Research Funds for the Central
   Universities (DUT15ZD114) and Project Funded by China Postdoctoral
   Science Foundation (2017M621131). The authors gratefully acknowledge the
   assistance of Mark V. Albert in correcting English language.
CR Amft Oliver, 2010, 2010 8th IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops), P298, DOI 10.1109/PERCOMW.2010.5470653
   Amft O, 2008, ARTIF INTELL MED, V42, P121, DOI 10.1016/j.artmed.2007.11.007
   Amft O, 2011, IEEE INT SYM WRBL CO, P83, DOI 10.1109/ISWC.2011.37
   Andrews J., 2010, Proc. Ann. Reliability Maintainability Symp., P1
   [Anonymous], 2015, J SOFTWARE ENG APPL
   [Anonymous], IJCAI 2001 WORKSHOP
   [Anonymous], 2013, P 21 ACM INT C MULT
   [Anonymous], 2006, 3 INT FORUM APPL WEA
   [Anonymous], 2013, Consumer Depth Cameras for Computer Vision, DOI DOI 10.1007/978-1-4471-4640-710
   Azeem A, 2014, INT ARAB J INF TECHN, V11, P1
   Bama SS, 2015, SURVEY PERFORMANCE E
   Bhimani J, 2017, IEEE INT CONF CLOUD, P359, DOI 10.1109/CLOUD.2017.53
   Blanke U, 2009, LECT NOTES COMPUT SC, V5561, P192, DOI 10.1007/978-3-642-01721-6_12
   Candes Emmanuel, 2010, 2010 IEEE Sensor Array and Multichannel Signal Processing Workshop (SAM 2010), P201, DOI 10.1109/SAM.2010.5606734
   Chen LM, 2012, IEEE T SYST MAN CY C, V42, P790, DOI 10.1109/TSMCC.2012.2198883
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Ghassemzadeh H, 2009, IEEE ENG MED BIO, P3146, DOI 10.1109/IEMBS.2009.5332589
   Guan D, 2011, IETE TECH REV, V28, P418, DOI 10.4103/0256-4602.85975
   Guo JQ, 2014, PERS UBIQUIT COMPUT, V18, P1977, DOI 10.1007/s00779-014-0800-5
   Guo M, 2015, INT C COMP SUPP COOP, P576, DOI 10.1109/CSCWD.2015.7231022
   Hammerla N.Y., 2016, P 25 INT JOINT C ART, DOI DOI 10.48550/ARXIV.1604.08880
   Ordóñez FJ, 2015, PERS UBIQUIT COMPUT, V19, P259, DOI 10.1007/s00779-014-0820-1
   Junker H, 2008, PATTERN RECOGN, V41, P2010, DOI 10.1016/j.patcog.2007.11.016
   Ladha C, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P235, DOI 10.1145/2493432.2493492
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Lee MW, 2011, PERS UBIQUIT COMPUT, V15, P887, DOI 10.1007/s00779-011-0403-3
   Leutheuser H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0075196
   Li CJ, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1236471.1236475
   Li Kang, 2014, IEEE Trans Pattern Anal Mach Intell, V36, P1644, DOI 10.1109/TPAMI.2013.2297321
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Lu Y., 2016, Sheet Met. Weld. Conf. XVII, P1, DOI DOI 10.1155/2016/8141269
   Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007
   Ogris G, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P55, DOI 10.1109/ISWC.2008.4911585
   Paradiso R, 2005, IEEE T INF TECHNOL B, V9, P337, DOI 10.1109/TITB.2005.854512
   Shi QF, 2011, INT J COMPUT VISION, V93, P22, DOI 10.1007/s11263-010-0384-0
   Singla G, 2010, J AMB INTEL HUM COMP, V1, P57, DOI 10.1007/s12652-009-0007-1
   Song Y, 2007, LECT NOTES ARTIF INT, V4702, P248
   STEWART GW, 1973, SIAM REV, V15, P727, DOI 10.1137/1015095
   van Kasteren TLM, 2010, PERS UBIQUIT COMPUT, V14, P489, DOI 10.1007/s00779-009-0277-9
   Wang L, 2008, LECT NOTES ARTIF INT, V5012, P369, DOI 10.1007/978-3-540-68125-0_33
   Wang ZL, 2016, IEEE T HUM-MACH SYST, V46, P769, DOI 10.1109/THMS.2016.2571265
   Wu DG, 2016, NEUROCOMPUTING, V190, P35, DOI 10.1016/j.neucom.2015.11.095
   [杨风召 Yang Fengzhao], 2004, [计算机研究与发展, Journal of Computer Research and Development], V41, P361
NR 43
TC 17
Z9 17
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21201
EP 21220
DI 10.1007/s11042-017-5573-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300039
DA 2024-07-18
ER

PT J
AU Kim, W
AF Kim, Wonjun
TI Background subtraction with variable illumination in outdoor scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background subtraction; Edge-aware filtering; Moving LBP; Variable
   illumination
ID LOW-RANK; FUSION
AB Background subtraction is a key prerequisite for intelligent video surveillance, but most of the methods employed are still affected by dynamic changes in the illumination conditions, e.g., shadows cast by passing clouds occur frequently in outdoor scenes. To resolve this problem, a novel approach based on the underlying structure of the difference image is introduced in this study. In particular, local binary patterns (LBPs) are computed based on the frame differencing result, i.e., moving LBP, and then compared with the background model, which is updated according to an online interpolation scheme, in order to determine whether the current pixel belongs to the background. An important advantage of the proposed method is that it efficiently smoothes unexpected noise between frames while also preserving the boundaries of the moving objects by using an edge-aware filtering technique. Experimental results obtained using two benchmark data sets demonstrated that the proposed method is more robust to variable illumination in outdoor scenes compared with previously proposed approaches.
C1 [Kim, Wonjun] Konkuk Univ, Dept Elect Engn, Seoul 05029, South Korea.
C3 Konkuk University
RP Kim, W (corresponding author), Konkuk Univ, Dept Elect Engn, Seoul 05029, South Korea.
EM wonjkim@konkuk.ac.kr
RI Kim, Wonjun/JXN-3386-2024
CR Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Cheng L, 2011, IEEE T IMAGE PROCESS, V20, P1401, DOI 10.1109/TIP.2010.2087764
   Chua TW, 2012, IEEE IMAGE PROC, P49, DOI 10.1109/ICIP.2012.6466792
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Davis JW, 2007, COMPUT VIS IMAGE UND, V106, P162, DOI 10.1016/j.cviu.2006.06.010
   Guo LL, 2016, IEEE COMPUT SOC CONF, P1159, DOI 10.1109/CVPRW.2016.148
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Joanl F. B., 1987, Statistical Science, V2, P45, DOI [10.1214/ss/1177013437, DOI 10.1214/SS/1177013437]
   Kim C, 2002, IEEE T CIRC SYST VID, V12, P122, DOI 10.1109/76.988659
   Kim W, 2017, MACH VISION APPL, V28, P49, DOI 10.1007/s00138-016-0801-7
   Kim W, 2016, IEEE SIGNAL PROC LET, V23, P634, DOI 10.1109/LSP.2016.2544778
   Kim W, 2014, IEEE SIGNAL PROC LET, V21, P1336, DOI 10.1109/LSP.2014.2334656
   Klare Brendan, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P66, DOI 10.1109/CVPR.2009.5204078
   Li Y, 2010, LECT NOTES COMPUT SC, V6313, P790
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Liu YW, 2016, ADV METEOROL, V2016, DOI 10.1155/2016/4921616
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pilet J, 2008, LECT NOTES COMPUT SC, V5305, P567, DOI 10.1007/978-3-540-88693-8_42
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Sajid H, 2017, IEEE T IMAGE PROCESS, V26, P3249, DOI 10.1109/TIP.2017.2695882
   Shen YR, 2016, IEEE T MOBILE COMPUT, V15, P406, DOI 10.1109/TMC.2015.2418775
   Sobral A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P946, DOI 10.1109/ICCVW.2015.125
   St-Charles PL, 2016, IEEE T IMAGE PROCESS, V25, P4768, DOI 10.1109/TIP.2016.2598691
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Them K, 2016, IEEE T MED IMAGING, V35, P893, DOI 10.1109/TMI.2015.2501462
   Xue GJ, 2010, IEEE IMAGE PROC, P3465, DOI 10.1109/ICIP.2010.5650111
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yin Haiyan., 2013, Multimedia and Expo Workshops (ICMEW), 2013 IEEE International Conference on, P1
   Zeng Z, 2017, IEEE T FUZZY SYST, V25, P584, DOI 10.1109/TFUZZ.2016.2566811
   Zhang SP, 2008, IEEE IMAGE PROC, P1556, DOI 10.1109/ICIP.2008.4712065
   Zhang W, 2007, IEEE T MULTIMEDIA, V9, P1202, DOI 10.1109/TMM.2007.902842
   Zhang X, 2017, IEEE T MULTIMEDIA, V19, P2425, DOI 10.1109/TMM.2017.2701645
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 43
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19439
EP 19454
DI 10.1007/s11042-017-5410-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500025
DA 2024-07-18
ER

PT J
AU Zhang, QY
   Qiao, SB
   Huang, YB
   Zhang, T
AF Zhang, Qiu-yu
   Qiao, Si-bin
   Huang, Yi-bo
   Zhang, Tao
TI A high-performance speech perceptual hashing authentication algorithm
   based on discrete wavelet transform and measurement matrix
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech authentication; Perceptual hashing; Discrete wavelet transform
   (DWT); Measurement matrix; Tampering detection
ID AUDIO
AB Aiming at the problems of existing speech authentication algorithms, such as poor robustness and discrimination, security vulnerability, low efficiency, poor ability of tamper detection and localization, a high-performance speech perceptual hashing authentication algorithm based on Discrete Wavelet Transform (DWT) and measurement matrix is proposed in this paper. Firstly, the speech signal is conducted with DWT by applying preprocessing, and the low-frequency wavelet coefficients are regarded as the perceptual feature value. Then the measurement matrix controlled by chaos map is applied to reduce the dimension of feature value. Finally, the feature value is used to generate the perceptual hash sequence by the process of hashing structure. The measurement matrix is designed as the secret key to enhance the security of the proposed algorithm. The experimental results demonstrates the proposed algorithm has high efficiency in perceptual robustness, discrimination, time consumption and security, as well as having a high accuracy of tampering detection and localization.
C1 [Zhang, Qiu-yu; Qiao, Si-bin; Zhang, Tao] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Gansu, Peoples R China.
   [Huang, Yi-bo] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Gansu, Peoples R China.
C3 Lanzhou University of Technology; Northwest Normal University - China
RP Zhang, QY (corresponding author), Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Gansu, Peoples R China.
EM zhangqylz@163.com; qiaosibin@163.com; Huangyibo1982@163.com;
   1090408922@qq.com
RI Zhang, Qiu-yu/V-9223-2019
OI Zhang, Qiu-yu/0000-0003-1488-388X
FU National Natural Science Foundation of China [61363078]; Natural Science
   Foundation of Gansu Province of China [1606RJYA274]; Open Research Fund
   of National Mobile Communications Research Laboratory, Southeast
   University [2014D13]
FX This work is supported by the National Natural Science Foundation of
   China (61363078), the Natural Science Foundation of Gansu Province of
   China (1606RJYA274), the Open Research Fund of National Mobile
   Communications Research Laboratory, Southeast University (2014D13). The
   authors would like to thank the anonymous reviewers for their helpful
   comments and suggestions.
CR Adibi S, 2014, TELEMAT INFORM, V31, P137, DOI 10.1016/j.tele.2013.02.004
   Chen N, 2013, ELECTRON LETT, V49, P7, DOI 10.1049/el.2012.3812
   Chen N, 2010, IET COMMUN, V4, P1722, DOI 10.1049/iet-com.2009.0749
   Chen N, 2013, DIGIT SIGNAL PROCESS, V23, P1216, DOI 10.1016/j.dsp.2013.01.012
   Chen N, 2010, ETRI J, V32, P345, DOI 10.4218/etrij.10.0209.0309
   Chen N, 2009, LECT NOTES COMPUT SC, V5769, P426, DOI 10.1007/978-3-642-04277-5_43
   Huang Yibo, 2015, Journal of Huazhong University of Science and Technology (Natural Science Edition), V43, P124, DOI 10.13245/j.hust.150226
   Jiao YH, 2009, IEEE SIGNAL PROC LET, V16, P818, DOI 10.1109/LSP.2009.2025827
   Kim HG, 2016, CLUSTER COMPUT, V19, P315, DOI 10.1007/s10586-015-0523-z
   [李金凤 Li Jinfeng], 2015, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V38, P89
   Li JF, 2015, CHINESE J ELECTRON, V24, P579, DOI 10.1049/cje.2015.07.024
   Lotia P, 2013, IJRCCT, V2, P579
   Lu X, 2011, MULTIMED TOOLS APPL, V52, P187, DOI 10.1007/s11042-010-0465-7
   Nouri M, 2012, 2012 SIXTH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P1136, DOI 10.1109/ISTEL.2012.6483157
   Özer H, 2005, EURASIP J APPL SIG P, V2005, P1780, DOI 10.1155/ASP.2005.1780
   Panagiotou V., 2013, DIG SIGN PROC DSP 20, P1, DOI DOI 10.1109/ICDSP.2013.6622803
   Ramona M, 2011, INT CONF ACOUST SPEE, P477
   [汪竹蓉 Wang Zhurong], 2012, [计算机研究与发展, Journal of Computer Research and Development], V49, P158
   Zhao H, 2016, NAT COMP FUZZ SYST K, DOI [10.1109/FSKD.2016.7603458, DOI 10.1109/FSKD.2016.7603458]
   Zhao Huan, 2011, INT J DIGITAL CONTEN, V5, P85
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 21
TC 13
Z9 14
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21653
EP 21669
DI 10.1007/s11042-018-5613-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300058
DA 2024-07-18
ER

PT J
AU Abazari, R
   Lakestani, M
AF Abazari, Reza
   Lakestani, Mehrdad
TI A hybrid denoising algorithm based on shearlet transform method and
   Yaroslavsky's filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Shearlet transform; Yaroslavsky's filter; Kernel
   smoothing; Minimax bounds
ID PARSEVAL FRAMES; IMAGE; REPRESENTATIONS
AB In this paper, we have proposed a hybrid denoising algorithm based on combining of the shearlet transform method, as a pre-processing step, with the Yaroslavsky's filter, as a kernel smoother, on a wide class of images with various properties such as thin features and textures. In the other word, proposed algorithm is a two-step algorithm, where in the first step the image is filtered by shearlet transform method and in the second step the weighted Yaroslavsky's filter is applied on result of first step. The weight coefficients of the Yaroslavsky's filter are achieved by pixel similarities in the denoised image from the first step. The theoretical results are confirmed via simulations for 2D images corrupted by additive white Gaussian noise. Experimental results illustrate that proposed hybrid method has good effect on suppressing the pseudo-Gibbs and shearlet-like artifacts can obtain better performance in terms of mean square error (MSE), peak signal to noise ratio (PSNR) and structural similarity (SSIM) index rather than existing state-of-the-art methods.
C1 [Abazari, Reza; Lakestani, Mehrdad] Univ Tabriz, Fac Math Sci, Dept Appl Math, Tabriz, Iran.
C3 University of Tabriz
RP Abazari, R (corresponding author), Univ Tabriz, Fac Math Sci, Dept Appl Math, Tabriz, Iran.
EM abazari.r@tabrizu.ac.ir
RI Lakestani, Mehrdad/AAE-4455-2019; Abazari, Reza/B-8134-2013
OI Lakestani, Mehrdad/0000-0002-2752-0167; Abazari,
   Reza/0000-0003-0125-2958
CR Abazari R, 2018, CURR MED IMAGING REV, V14, P477, DOI 10.2174/1573405613666170405150828
   [Anonymous], 1995, The DFT: An owner's manual for the discrete Fourier transform
   [Anonymous], 2000, CURVES SURFACES
   Arias-Castro E, 2012, SIAM J IMAGING SCI, V5, P944, DOI 10.1137/110859403
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Candes E., 1999, Curvelets
   Candes E.J., 1998, EJ RID THER AND APP
   Colonna F, 2010, APPL COMPUT HARMON A, V29, P232, DOI 10.1016/j.acha.2009.10.005
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Donoho D., 2001, BEAMLETS MULTISCALE
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Fan J., 1996, LOCAL POLYNOMIAL MOD
   Guo K, 2013, MATH MODEL NAT PHENO, V8, P82, DOI 10.1051/mmnp/20138106
   Guo K, 2007, SIAM J MATH ANAL, V39, P298, DOI 10.1137/060649781
   Guo KH, 2012, SIAM J MATH ANAL, V44, P851, DOI 10.1137/100813397
   Guo KH, 2009, SIAM J IMAGING SCI, V2, P959, DOI 10.1137/080741537
   Kutyniok G., 2005, Wavelets XI, V5914, P254, DOI DOI 10.1117/12.613494
   Kutyniok G., 2011, LECT NOTES COMPUTER, V6920
   Lakestani M., 2016, IRAN J SCI TECHNOL A, DOI [10.22099/IJSTS.2016.3677, DOI 10.22099/IJSTS.2016.3677]
   LEE JS, 1983, COMPUT VISION GRAPH, V24, P255, DOI 10.1016/0734-189X(83)90047-6
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Meyer FG, 1997, APPL COMPUT HARMON A, V4, P147, DOI 10.1006/acha.1997.0208
   Patel VM, 2009, IEEE T IMAGE PROCESS, V18, P2673, DOI 10.1109/TIP.2009.2029594
   Salmon J, 2012, 2012 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P464, DOI 10.1109/SSP.2012.6319733
   Tsybakov A. B., 1993, LECT NOTES STAT, V82
   Wang XY, 2014, DIGIT SIGNAL PROCESS, V30, P101, DOI 10.1016/j.dsp.2014.03.005
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yaroslavsky L.P, 1985, Springer Series in Information Sciences, V9
NR 30
TC 9
Z9 10
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17829
EP 17851
DI 10.1007/s11042-018-5648-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900014
DA 2024-07-18
ER

PT J
AU Harakawa, R
   Takehara, D
   Ogawa, T
   Haseyama, M
AF Harakawa, Ryosuke
   Takehara, Daichi
   Ogawa, Takahiro
   Haseyama, Miki
TI Sentiment-aware personalized tweet recommendation through multimodal FFM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Twitter; Recommendation; User modeling; Sentiment analysis; Field-aware
   factorization machines (FFM)
AB For realizing quick and accurate access to desired information and effective advertisements or election campaigns, personalized tweet recommendation is highly demanded. Since multimedia contents including tweets are tools for users to convey their sentiment, users' interest in tweets is strongly influenced by sentiment factors. Therefore, successful personalized tweet recommendation can be realized if sentiment in tweets can be estimated. However, sentiment factors were not taken into account in previous works and the performance of previous methods may be limited. To overcome the limitation, a method for sentiment-aware personalized tweet recommendation through multimodal Field-aware Factorization Machines (FFM) is newly proposed in this paper. Successful personalized tweet recommendation becomes feasible through the following three contributions: (i) sentiment factors are newly introduced into personalized tweet recommendation, (ii) users' interest is modeled by deriving multimodal FFM that enables collaborative use of multiple factors in a tweet, i.e., publisher, topic and sentiment factors, and (iii) the effectiveness of using sentiment factors as well as publisher and topic factors is clarified from results of experiments using real-world datasets related to worldwide hot topics, "#trump", "#hillaryclinton" and "#ladygaga". In addition to showing the effectiveness of the proposed method, the applicability of the proposed method to other tasks such as advertisement and social analysis is discussed as a conclusion and future work of this paper.
C1 [Harakawa, Ryosuke; Ogawa, Takahiro; Haseyama, Miki] Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido, Japan.
   [Takehara, Daichi] NTT DATA Corp, Tokyo, Japan.
C3 Hokkaido University; NTT DATA Corporation
RP Harakawa, R (corresponding author), Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido, Japan.
EM harakawa@lmd.ist.hokudai.ac.jp; daichi.takehara0730@gmail.com;
   ogawa@lmd.ist.hokudai.ac.jp; miki@ist.hokudai.ac.jp
RI Sathasivam, Prasanta/AAK-4169-2021; Haseyama, Miki/A-6163-2012
OI Ogawa, Takahiro/0000-0001-5332-8112
FU JSPS KAKENHI [JP16J02042, JP17H01744]; Grants-in-Aid for Scientific
   Research [16J02042] Funding Source: KAKEN
FX This work was partly supported by JSPS KAKENHI Grant Numbers JP16J02042
   and JP17H01744.
CR Abel F, 2011, LECT NOTES COMPUT SC, V6787, P1, DOI 10.1007/978-3-642-22362-4_1
   [Anonymous], 2016, ACM MULTIMEDIA
   [Anonymous], 2016, P 24 ACM INT C MULT
   [Anonymous], 2016, P 2016 ACM WORKSH MU
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Bird Steven, 2009, NATURAL LANGUAGE PRO, DOI DOI 10.1007/S10579-010-9124-X
   Borth D., 2013, P 21 ACM INT C MULT, P459
   Chen KL, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P661, DOI 10.1145/2348283.2348372
   Chen T., 2014, DeepSentiBank: Visual Sentiment Concept Classification with Deep Convolutional Neural Networks
   Chen T., 2013, P 21 ACM INT C MULT, P781, DOI [DOI 10.1145/2502081.2502203, 10.1145/2502081, DOI 10.1145/2502081]
   Colleoni E, 2014, J COMMUN, V64, P317, DOI 10.1111/jcom.12084
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Erkin Z, 2012, IEEE T INF FOREN SEC, V7, P1053, DOI 10.1109/TIFS.2012.2190726
   Feng W., 2013, CIKM, P577
   Harakawa R, 2017, IEEE ACCESS, V5, P16963, DOI 10.1109/ACCESS.2017.2741098
   Hoens T. R., 2010, Proceedings of the 2010 IEEE Second International Conference on Social Computing (SocialCom 2010). the Second IEEE International Conference on Privacy, Security, Risk and Trust (PASSAT 2010), P816, DOI 10.1109/SocialCom.2010.124
   Hong L., 2013, P 6 ACM INT C WEB SE, P557, DOI DOI 10.1145/2433396.2433467
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Juan YC, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P43, DOI 10.1145/2959100.2959134
   Katsurai M, 2016, INT CONF ACOUST SPEE, P2837, DOI 10.1109/ICASSP.2016.7472195
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Luo X, 2014, IEEE T IND INFORM, V10, P1273, DOI 10.1109/TII.2014.2308433
   Luo X, 2012, KNOWL-BASED SYST, V27, P271, DOI 10.1016/j.knosys.2011.09.006
   McSherry F, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P627
   O'Mahony M. P., 2006, 2006 International Conference on Intelligent User Interfaces, P109, DOI 10.1145/1111449.1111477
   OMahony M. P., 2005, P 20 NAT C ART INT, P334
   Peng M, 2018, WORLD WIDE WEB, V21, P89, DOI 10.1007/s11280-017-0456-y
   Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   Sager S, 2016, ARXIV160703766, P1
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Seltzer EK, 2015, PUBLIC HEALTH, V129, P1273, DOI 10.1016/j.puhe.2015.07.025
   Shah RR, 2016, IEEE INT SYM MULTIM, P486, DOI [10.1109/ISM.2016.108, 10.1109/ISM.2016.0109]
   Shah RR, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P185, DOI 10.1145/2733373.2809932
   Shah RR, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P607, DOI 10.1145/2647868.2654919
   Shah RR, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P209, DOI 10.1145/2647868.2656407
   Shah RR, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P423, DOI 10.1145/2911996.2912032
   Shah RR, 2016, KNOWL-BASED SYST, V108, P102, DOI 10.1016/j.knosys.2016.05.022
   Shah RR, 2017, TAG RECOMMENDATION R, P101
   Soni K, 2017, INFORM COMMUNICATION, V1, P308
   Sriram B, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P841, DOI 10.1145/1835449.1835643
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tumasjan A, 2010, 4 INT AAAI C WEBL SO, V10, P178, DOI 10.1074/jbc.M501708200
   Uysal I., 2011, CIKM, P2261, DOI DOI 10.1145/2063576.2063941
   Wang H., 2012, P ACL 2012 SYST DEM, P115, DOI DOI 10.1145/1935826.1935854
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Zhao WNX, 2011, LECT NOTES COMPUT SC, V6611, P338, DOI 10.1007/978-3-642-20161-5_34
   Zhu HS, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P951, DOI 10.1145/2623330.2623705
NR 49
TC 18
Z9 18
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18741
EP 18759
DI 10.1007/s11042-018-5876-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900058
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Jachimski, D
   Czyzewski, A
   Ciszewski, T
AF Jachimski, Dawid
   Czyzewski, Andrzej
   Ciszewski, Tomasz
TI A comparative study of English viseme recognition methods and algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE viseme; Parameterization of mouth region; Support Vector Machine; Hidden
   Markov Model; Pattern recognition; Audiovisual speech recognition
AB An elementary visual unit - the viseme is concerned in the paper in the context of preparing the feature vector as a main visual input component of Audio-Visual Speech Recognition systems. The aim of the presented research is a review of various approaches to the problem, the implementation of algorithms proposed in the literature and a comparative research on their effectiveness. In the course of the study an optimal feature vector construction and an appropriate selection of the classifier were sought. The experimental research was conducted on the basis of a spoken corpus in which speech was represented both acoustically and visually. The extracted features represented three types: geometrical, textural and mixed ones. The features were processed employing the classification algorithms based on Hidden Markov Models and Sequential Minimal Optimization. Tests were carried out employing the processed video material recorded with English native speakers who read specially prepared list of commands. The obtained results are discussed in the paper.
C1 [Jachimski, Dawid; Czyzewski, Andrzej; Ciszewski, Tomasz] Gdansk Univ Technol, ETI Fac, Multimedia Syst Dept, Ul Narutowicza 11-12, Gdansk, Poland.
C3 Fahrenheit Universities; Gdansk University of Technology
RP Czyzewski, A (corresponding author), Gdansk Univ Technol, ETI Fac, Multimedia Syst Dept, Ul Narutowicza 11-12, Gdansk, Poland.
EM ac@pg.gda.pl
RI Czyzewski, Andrzej/JXN-0946-2024
OI Czyzewski, Andrzej/0000-0001-9159-8658
FU Polish National Science Centre [2015/17/B/ST6/01874]
FX Research sponsored by the Polish National Science Centre, Dec. No.
   2015/17/B/ST6/01874.
CR Alizadeh S, 2008, SIGN PROC ICSP 2008
   [Anonymous], 2014, INT J SCI BASIC APPL
   Cappelletta L, 2011, 19 EUR SIGN PROC C B
   Cappelletta L, 2011, EUR SIGNAL PR CONF, P2109
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dalka P, 2014, INT C SIGN EL SYST I
   Dalka P, 2006, ARCH ACOUST, V31, P1
   Dong L, 2003, INF COMM SIGN PROC 2
   Fernandez-Lopez A, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P52, DOI 10.5220/0006102100520063
   Heidenreich T, 2016, 3 DIMENSIONAL APPROA
   Hojo H, 2009, TENCON 2009 2009 IEE
   Jadczyk T., 2015, P WORLD C EL ENG COM, P13
   Kaucic R, 1996, INTEGRATED AUDIO VIS
   Kaucic R, 1998, COMP VIS 1998 6 INT
   Kaynak MN, 2004, IEEE T SYSTEMS MAN A
   Koller O, 2014, LECT NOTES COMPUT SC, V8689, P281, DOI 10.1007/978-3-319-10590-1_19
   Krishnachandran M, 2014, INT C ADV COMP COMM
   Leszczynski M, 2005, IEEE C ADV VID SIGN
   Li X, 2005, SIGN SYST COMP 2005
   Lucey P, 2004, P 10 AUSTR INT C SPE
   Maeda S., 2005, ZAS Papers in Linguistics, V40, P95, DOI [10.21248/zaspil.40.2005.260, DOI 10.21248/ZASPIL.40.2005.260]
   McGowen V, 2017, THESIS
   Mengjun W, 2010, 2010 2 INT C COMP IN
   Ms Namrata D, 2014, INT J SIGNAL PROCESS
   Neti Chalapathy, 2000, TECHNICAL REPORT
   Petajan ED., 1988, P SIGCHI C HUM FACT, P19, DOI DOI 10.1145/57167.57170
   Sagheer A, 2005, ACOUSTICS SPEECH SIG
   Sargin ME, 2005, SIGN PROC C ANT
   Stafylakis T., 2017, Combining residual networks with lstms for lipreading
   Stegmann MB, 2003, IEEE T MED IMAGING, V22, P1319, DOI 10.1109/TMI.2003.817780
   Vyavahare AJ, 2012, IET C P STEV I ENG A
   Wang L, 2010, 5 INT C FRONT COMP S
   Wang X, 2008, C NEUR NETW SIGN PRO
   WenJuan Y, 2010, 3 INT C ADV COMP THE
   Williams JJ, 1997, MULT SIGN PROC IEEE
   Xu M, 2006, COMM NETW CHIN CHINA
   Yang MH, 2016, MULTIMED TOOLS APPL, V75, P5125, DOI 10.1007/s11042-016-3405-3
   Zhang X, 2002, 2002 IEEE INT C AC S
NR 38
TC 8
Z9 8
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16495
EP 16532
DI 10.1007/s11042-017-5217-5
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300024
OA hybrid
DA 2024-07-18
ER

PT J
AU Ma, X
   Zhao, YS
   Qian, XM
   Tang, YY
AF Ma, Xiang
   Zhao, Yisi
   Qian, Xueming
   Tang, Yuan Yan
TI Multi-source fusion based geo-tagging for web images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GPS estimation; Geo-graphical; Geo-tag; Image retrieval; Social media;
   SIFT
ID LOCATION ESTIMATION; RETRIEVAL; SEGMENTATION; SEARCH; PHOTOS
AB Geographic locations estimation for web images have been received a lot of attention in recent years. With the help of smart phone, it is very popular for us to capture photos and share them in our social media networks. Users often generate several tags to describe image content. Many images are embedded with with geo-tags. In this paper, we propose an effective image GPS (geo-coordinates or geo-tags) estimation approach by fusing the multi-source such as textual, temporal and visual features of web images. We propose a hierarchical strategy to inference the GPS of web image. We preselect several geographic locations of higher expected relevance and perform a deeper analysis inside the selected locations to return the coordinates most likely to be related to the input image by an enhanced language model. Experiments show the effectiveness of our proposed approach.
C1 [Ma, Xiang] Changan Univ, Sch Informat Engn, Xian, Shaanxi, Peoples R China.
   [Zhao, Yisi; Qian, Xueming] Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian 710049, Shaanxi, Peoples R China.
   [Zhao, Yisi; Qian, Xueming] Xi An Jiao Tong Univ, Xian 710049, Shaanxi, Peoples R China.
   [Qian, Xueming] Xi An Jiao Tong Univ, Res Inst, Shunde, Guangdong, Peoples R China.
   [Tang, Yuan Yan] Macau Univ, Macau, Peoples R China.
C3 Chang'an University; Xi'an Jiaotong University; Xi'an Jiaotong
   University; University of Macau
RP Ma, X (corresponding author), Changan Univ, Sch Informat Engn, Xian, Shaanxi, Peoples R China.
EM maxiangmail@163.com
FU NSFC [61572083, 61771075]; China Fundamental Research Funds for the
   Central Universities [310824153508, 310824173401]; Foundation of
   Guangdong Province [2016A010101005]
FX This work is partly supported by the NSFC under 61572083 and 61771075,
   the China Fundamental Research Funds for the Central Universities under
   Grant 310824153508 and 310824173401 (Chang'an University), and
   Foundation of Guangdong Province under Grant 2016A010101005.
CR Agarwal S, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER NETWORKS (ISCON), P19, DOI 10.1109/ICISCON.2013.6524166
   Ames M, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P971
   [Anonymous], MAPPING WORLDS PHOTO
   [Anonymous], ABS161009462 CORR
   [Anonymous], 2011, P 49 ANN M ASS COMPU
   [Anonymous], ADV MULTIMEDIA MODEL
   Chakravarti R, 2009, INT C INF TECHN NEW
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Cheng G, 2013, ISPRS J PHOTOGRAMM R, V11
   Chum O., 2007, P ICCV
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Han JW, 2014, MULTIMED TOOLS APPL, V72, P2275, DOI 10.1007/s11042-013-1509-6
   Han JW, 2005, IEEE T IMAGE PROCESS, V14, P511, DOI 10.1109/TIP.2004.841205
   Hauff Claudia, 2012, Advances in Information Retrieval. Proceedings of the 34th European Conference on IR Research (ECIR 2012), P85, DOI 10.1007/978-3-642-28997-2_8
   Hauff C, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P691, DOI 10.1145/2348283.2348376
   Hays James., 2008, IM2GPS ESTIMATING GE
   Jiang SH, 2015, IEEE T MULTIMEDIA, V17, P907, DOI 10.1109/TMM.2015.2417506
   Kinsella S, 2011, SMUC, P759
   Lei XJ, 2016, IEEE T MULTIMEDIA, V18, P1910, DOI 10.1109/TMM.2016.2575738
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li J, 2015, SIGNAL PROCESS-IMAGE, V38, P141, DOI 10.1016/j.image.2015.07.007
   Li J, 2015, MULTIMED TOOLS APPL, V74, P655, DOI 10.1007/s11042-014-2008-0
   Li J, 2013, IEEE T MULTIMEDIA, V15, P2058, DOI 10.1109/TMM.2013.2280127
   Li X, P MED 2012 WORKSH
   Li Y, 2009, LANDMARK CLASSIFICAT
   Liu H., 2012, Proceedings_of_the_20th_ACM_ International_Conference_on_Multimedia, MM'12, P9
   Liu L, 2016, RECOGNIZING COMPLEX, P1266
   Liu XY, 2014, INTERNATIONAL CONFERENCE ON HUMANITY AND SOCIAL SCIENCE (ICHSS 2014), P1
   Liu Y, 2010, INT C VIRT SYST MULT
   Liu Y, 2016, URBAN WATER QUALITY, P2576
   Liu Y, 2015, RECOGNIZING COMPLEX, P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu D, 2016, IEEE T MULTIMEDIA, V18, P1628, DOI 10.1109/TMM.2016.2568099
   Lu X., 2009, Proceedings of the 2009 International Workshop on Location Based Social Networks, LBSN '09, P65
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Ma TH, 2015, IEICE T INF SYST, VE98D, P902, DOI 10.1587/transinf.2014EDP7283
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Park M, 2010, GPS DETERMINING CAME
   Preotiuc-Pietro D, 2017, BINARY LABELS POLITI
   Qian XM, 2017, IEEE T IMAGE PROCESS, V26, P3734, DOI 10.1109/TIP.2017.2699623
   Qian XM, 2017, IEEE T MULTIMEDIA, V19, P813, DOI 10.1109/TMM.2016.2638207
   Qian XM, 2015, IEEE T CIRC SYST VID, V25, P1857, DOI 10.1109/TCSVT.2014.2369731
   Qian XM, 2015, IEEE T IMAGE PROCESS, V24, P4348, DOI 10.1109/TIP.2015.2462131
   Qian XM, 2013, NEUROCOMPUTING, V111, P144, DOI 10.1016/j.neucom.2012.12.021
   Schindler G, 2007, CITY SCALE LOCATION
   Serdyukov P, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P484, DOI 10.1145/1571941.1572025
   Shuhui Jiang, 2016, IEEE Transactions on Big Data, V2, P43, DOI 10.1109/TBDATA.2016.2541160
   Trevisiol M, 2012, P MEDIAEVAL
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xiao X, 2012, IEEE T MULTIMEDIA, V14, P1246, DOI 10.1109/TMM.2012.2190384
   Yang XY, 2015, IEEE T IMAGE PROCESS, V24, P1709, DOI 10.1109/TIP.2015.2411433
   Yuan CS, 2017, J INTERNET TECHNOL, V18, P435, DOI 10.6138/JIT.2017.18.2.20160624c
   Zha ZJ, 2012, IEEE T MULTIMEDIA, V14, P17, DOI 10.1109/TMM.2011.2174782
   ZHAI C, 2002, SIGIR, P49
   Zhang S, 2010, BUILDING CONTEXTUAL
   Zhao GS, 2017, IEEE T BIG DATA, V3, P67, DOI 10.1109/TBDATA.2016.2552541
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
   Zhou W, 2010, SPATIAL CODING LARGE
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zhou ZL, 2016, IEICE T INF SYST, VE99D, P1531, DOI 10.1587/transinf.2015EDP7341
NR 65
TC 2
Z9 2
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16399
EP 16417
DI 10.1007/s11042-017-5211-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300018
DA 2024-07-18
ER

PT J
AU Ren, J
   Xu, M
   Smith, JS
   Zhao, HM
   Zhang, R
AF Ren, Jie
   Xu, Ming
   Smith, Jeremy S.
   Zhao, Huimin
   Zhang, Rui
TI Multi-view visual surveillance and phantom removal for effective
   pedestrian detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion detection; Video surveillance; Homography
ID MULTIPLE FIXED CAMERAS; PEOPLE TRACKING
AB To increase the robustness of detection in intelligent video surveillance systems, homography has been widely used to fuse foreground regions projected from multiple camera views to a reference view. However, the intersections of non-corresponding foreground regions can cause phantoms. This paper proposes an algorithm based on geometry and colour cues to cope with this problem, in which the homography between different camera views and the Mahalanobis distance between the colour distributions of every two associated foreground regions are considered. The integration of these two matching algorithms improves the robustness of the pedestrian and phantom classification. Experiments on real-world video sequences have shown the robustness of this algorithm.
C1 [Ren, Jie] Xian Polytech Univ, Coll Elect & Informat, Xian, Shaanxi, Peoples R China.
   [Xu, Ming] Xian Jiaotong Liverpool Univ, Dept Elect & Elect Engn, Suzhou, Peoples R China.
   [Xu, Ming; Smith, Jeremy S.] Univ Liverpool, Dept Elect Engn & Elect, Liverpool, Merseyside, England.
   [Zhao, Huimin] Guangdong Polytech Normal Univ, Sch Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Zhang, Rui] Xian Jiaotong Liverpool Univ, Dept Math Sci, Suzhou, Peoples R China.
C3 Xi'an Polytechnic University; Xi'an Jiaotong-Liverpool University;
   University of Liverpool; Guangdong Polytechnic Normal University; Xi'an
   Jiaotong-Liverpool University
RP Ren, J (corresponding author), Xian Polytech Univ, Coll Elect & Informat, Xian, Shaanxi, Peoples R China.
EM renjie1984@yahoo.com
FU National Natural Science Foundation of China (NSFC) [60975082/61672008];
   Scientific Research Program - Shaanxi Provincial Education Department,
   P. R. China [15JK1310]
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) under Grants 60975082/61672008 and the Scientific Research
   Program funded by Shaanxi Provincial Education Department, P. R. China,
   under Grant 15JK1310.
CR Alahi A, 2011, J MATH IMAGING VIS, V41, P39, DOI 10.1007/s10851-010-0258-7
   [Anonymous], 2008, ACM IEEE INT C DISTR
   [Anonymous], 1999, P IEEE C COMP VIS PA
   Berclaz J, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P375
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Du W, 2007, LECT NOTES COMPUT SC, V4843, P365
   Eshel R, 2010, INT J COMPUT VISION, V88, P129, DOI 10.1007/s11263-009-0307-0
   Ge WN, 2010, LECT NOTES COMPUT SC, V6315, P324
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P663, DOI 10.1109/TPAMI.2006.80
   Jiang JM, 2011, IEEE T BROADCAST, V57, P646, DOI 10.1109/TBC.2011.2158252
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Khan SM, 2009, IEEE T PATTERN ANAL, V31, P505, DOI 10.1109/TPAMI.2008.102
   Kim K, 2006, LECT NOTES COMPUT SC, V3953, P98
   Liem Martijn, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P173, DOI 10.1007/978-3-642-23123-0_18
   Liem M., 2009, Proc. British Machine Vision Conference, P199
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Peng PX, 2015, PATTERN RECOGN, V48, P1760, DOI 10.1016/j.patcog.2014.12.004
   Ren J, 2010, IET IMAGE PROCESS, V4, P294, DOI 10.1049/iet-ipr.2009.0071
   Ren J, 2008, IEEE T CIRC SYST VID, V18, P350, DOI 10.1109/TCSVT.2008.918276
   Ren JC, 2007, SIGNAL PROCESS, V87, P541, DOI 10.1016/j.sigpro.2006.06.013
   Ren JC, 2010, IEEE T IMAGE PROCESS, V19, P1379, DOI 10.1109/TIP.2009.2039056
   Ren JC, 2009, COMPUT VIS IMAGE UND, V113, P633, DOI 10.1016/j.cviu.2008.01.007
   Ren JC, 2009, IEEE T MULTIMEDIA, V11, P906, DOI 10.1109/TMM.2009.2021782
   Santos TT, 2011, PATTERN RECOGN LETT, V32, P47, DOI 10.1016/j.patrec.2010.05.016
   Sternig S., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1689, DOI 10.1109/ICCVW.2011.6130453
   Sutherland I. E., 1974, Computing Surveys, V6, P1, DOI 10.1145/356625.356626
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Tong XM, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P349, DOI 10.1109/ICIG.2009.90
   Yang DB, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P122
   Zabalza Jaime, 2015, IEEE Transactions on Geoscience and Remote Sensing, V53, P4418, DOI 10.1109/TGRS.2015.2398468
   Zabalza J, 2016, NEUROCOMPUTING, V185, P1, DOI 10.1016/j.neucom.2015.11.044
NR 34
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18801
EP 18826
DI 10.1007/s11042-017-4939-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900062
DA 2024-07-18
ER

PT J
AU Xu, QQ
   Jin, C
   Rasid, MFB
   Veeravalli, B
   Aung, KMM
AF Xu, Quanqing
   Jin, Chao
   Rasid, Mohamed Faruq Bin Mohamed
   Veeravalli, Bharadwaj
   Aung, Khin Mi Mi
TI Blockchain-based decentralized content trust for docker images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Trust; Docker; Blockchain; Multimedia; Internet of things
ID FRAMEWORK; STORAGE; CLOUD
AB It is feasible to deploy Docker containers in IoT (Internet of Things) devices because their runtime overhead is almost zero. Default Docker installation does not verify an image authenticity. Authentication is vital for users to trust that the image is not malicious or tampered with. As Docker is currently a popular choice for developers, tightening its security is a priority for system administrators and DevOps engineers. Docker recently deployed Notary as a solution to verify authenticity of their images. Notary is a viable solution, but it has some potential threats. This paper specifically addresses its vulnerability towards Denial-of-Service (DoS) attacks, and propose a potential solution: blockchain-based Decentralized Docker Trust (DDT). The proposed solution involves decentralizing the trust via a blockchain. The solution greatly reduces the risk of DoS and at the same time provides a signature verification service for Docker images. We demonstrate the proposed blockchain-based solution's scalability and efficiency by conducting performance evaluation. At the same time, we also implemented a system prototype of Decentralized Docker Trust (DDT), and conducted performance evaluation for it on Amazon Web Services (AWS) across multiple data centers.
C1 [Xu, Quanqing; Jin, Chao; Rasid, Mohamed Faruq Bin Mohamed; Veeravalli, Bharadwaj; Aung, Khin Mi Mi] ASTAR, Data Storage Inst, Singapore, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Data Storage
   Institute
RP Xu, QQ (corresponding author), ASTAR, Data Storage Inst, Singapore, Singapore.
EM Xu_Quanqing@dsi.a-star.edu.sg; Jin_Chao@dsi.a-star.edu.sg;
   faruq@u.nus.edu; elebv@nus.edu.sg; Mi_Mi_AUNG@dsi.a-star.edu.sg
RI Jin, Chao/ACU-2916-2022
OI Jin, Chao/0000-0002-6858-1177; Aung, Khin Mi Mi/0000-0002-5652-3455
CR Amin R, 2018, MULTIMED TOOLS APPL, V77, P11041, DOI 10.1007/s11042-017-4996-z
   [Anonymous], INTRO DOCKER CONTENT
   [Anonymous], 2016, DIRTY COW CRITICAL L
   [Anonymous], 2016, AB
   [Anonymous], 2017, NO WAY DIS TRUST ON
   [Anonymous], 2016, RES HDB DIGITAL TRAN
   [Anonymous], TUF SPEC UPDATE FRAM
   [Anonymous], 2013, 2013 IEEE 29 S MASS
   Arumugam RV, 2014, INT CONF CLOUD COMP, P210, DOI 10.1109/CloudCom.2014.166
   Benet J., 2014, IPFS CONTENT ADDRESS
   Bos JW, 2014, LECT NOTES COMPUT SC, V8437, P157, DOI 10.1007/978-3-662-45472-5_11
   Brito J., 2013, Bitcoin - a primer for policymakers
   Bui Thanh, 2015, ARXIV150102967
   Chang V, 2017, J SYST SOFTWARE, V124, P195, DOI 10.1016/j.jss.2015.12.031
   Chang V, 2016, FUTURE GENER COMP SY, V57, P56, DOI 10.1016/j.future.2015.10.003
   Chang V, 2016, FUTURE GENER COMP SY, V57, P24, DOI 10.1016/j.future.2015.09.031
   Chang V, 2015, AD HOC NETW, V35, P65, DOI 10.1016/j.adhoc.2015.07.012
   Matzutt R., 2016, P 2016 ACM SIGSAC C, P1769
   Merkel D., 2014, LINUX J, V2014, P2, DOI DOI 10.5555/2600239.2600241
   Nakamoto S, 2008, BITCOIN PEER TO PEER, DOI DOI 10.1007/S10838-008-9062-0
   Quanqing X, 2017, IOTBDS: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INTERNET OF THINGS, BIG DATA AND SECURITY, P431, DOI 10.5220/0006379404310437
   Samuel J, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P61, DOI 10.1145/1866307.1866315
   Spoiala CC, 2016, 2016 13TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND APPLICATION SYSTEMS (DAS 2016), P295, DOI 10.1109/DAAS.2016.7492590
   Vasek M, 2014, LECT NOTES COMPUT SC, V8438, P57, DOI 10.1007/978-3-662-44774-1_5
   Vögler M, 2016, ACM T INTERNET TECHN, V16, DOI 10.1145/2850416
   Xu Q., 2018, New Adv. Internet Things, P119
   Xu QQ, 2016, J SUPERCOMPUT, V72, P2796, DOI 10.1007/s11227-016-1621-2
   Xu QQ, 2009, LECT NOTES COMPUT SC, V5550, P742
   Yulin Yao, 2014, International Journal of Organizational and Collective Intelligence, V4, P64, DOI 10.4018/ijoci.2014040104
   Zhang LM, 2017, MULTIMEDIA SYST, V23, P1, DOI 10.1007/s00530-016-0527-4
NR 30
TC 22
Z9 33
U1 1
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18223
EP 18248
DI 10.1007/s11042-017-5224-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900036
DA 2024-07-18
ER

PT J
AU Amir, A
   Srinivasan, B
   Khan, AI
AF Amir, Amiza
   Srinivasan, Bala
   Khan, Asad I.
TI Distributed classification for image spam detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE P2P classification; Distributed pattern recognition; Spam detection;
   Image spam; Distributed classification; Distributed data mining; P2P
   data mining
ID NETWORK
AB Spam appears in various forms and the current trend in spamming is moving towards multimedia spam objects. Image spam is a new type of spam attacks which attempts to bypass the spam filters that mostly text-based. Spamming attacks the users in many ways and these are usually countered by having a server to filter the spammers. This paper provides a fully-distributed pattern recognition system within P2P networks using the distributed associative memory tree (DASMET) algorithm to detect spam which is cost-efficient and not prone to a single point of failure, unlike the server-based systems. This algorithm is scalable for large and frequently updated data sets, and specifically designed for data sets that consist of similar occurring patterns.We have evaluated our system against centralised state-of-the-art algorithms (NN, k-NN, naive Bayes, BPNN and RBFN) and distributed P2P-based algorithms (Ivote-DPV, ensemble k-NN, ensemble naive Bayes, and P2P-GN). The experimental results show that our method is highly accurate with a 98 to 99% accuracy rate, and incurs a small number of messages-in the best-case, it requires only two messages per recall test. In summary, our experimental results show that the DAS-MET performs best with a relatively small amount of resources for the spam detection compared to other distributed methods.
C1 [Amir, Amiza] Univ Malaysia Perlis, Sch Comp & Commun Engn, Arau, Perlis, Malaysia.
   [Srinivasan, Bala; Khan, Asad I.] Monash Univ, Fac Informat Technol, Melbourne, Vic, Australia.
C3 Universiti Malaysia Perlis; Monash University
RP Amir, A (corresponding author), Univ Malaysia Perlis, Sch Comp & Commun Engn, Arau, Perlis, Malaysia.
EM amizaamir@unimap.edu.my; srini@monash.edu; asad@monash.edu
RI Khan, Asad/HNR-9080-2023
OI Khan, Asad/0000-0002-5526-0999
FU Research Acculturation Grant Scheme (RAGS) [9018-00080]
FX The research reported in this paper is supported by Research
   Acculturation Grant Scheme (RAGS) 9018-00080. The authors would also
   like to express gratitude to the Malaysian Ministry of Higher Education
   (MOHE) and University Malaysia Perlis (UniMAP) for the facilities
   provided.
CR Al-Duwairi Basheer, 2012, INT J INF SECUR, V2, P344
   Amir A, 2015, SOICT 2015, P75, DOI [10.1145/2833258.2833304, DOI 10.1145/2833258.2833304]
   Amir A, 2013, LECT NOTES COMPUT SC, V7070, P439, DOI 10.1007/978-3-642-44958-1_35
   [Anonymous], 2014, PROC IEEE C COMPUTER, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]
   [Anonymous], 2013, EMERGING PARADIGMS M, DOI DOI 10.1007/978-3-642-28699-518
   Attar A, 2013, ARTIF INTELL REV, V40, P71, DOI 10.1007/s10462-011-9280-4
   Blanzieri E, 2008, ARTIF INTELL REV, V29, P63, DOI 10.1007/s10462-009-9109-6
   Chatzichristofis Savvas A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P191, DOI 10.1109/WIAMIS.2008.24
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Chen J, 2015, BMC PLANT BIOL, V15, DOI 10.1186/s12870-015-0428-2
   Chowdhury M, 2015, INT C SEC PRIV COMM, P622, DOI [10.1007/978-3-319-28865-941, DOI 10.1007/978-3-319-28865-941]
   Dredze M, 2007, 4 C EM ANT CEAS 2007
   Filasiak R, 2014, ANN TELECOMMUN, V69, P363, DOI 10.1007/s12243-013-0412-5
   Gao Y, 2008, INT CONF ACOUST SPEE, P1765
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Gupta Rishabh, 2015, 2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA). Proceedings, P1, DOI 10.1109/WASPAA.2015.7336888
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   JFeatureLib, 2013, JFEATURELIB FREE JAV
   Jin X, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1671962.1671965
   Kapelko Rafal, 2013, Web Technologies and Applications. 15th Asia-Pacific Web Conference, APWeb 2013. Proceedings, P686, DOI 10.1007/978-3-642-37401-2_67
   Kurdi HA, 2015, J KING SAUD UNIV-COM, V27, P315, DOI 10.1016/j.jksuci.2014.10.002
   Lau, 2015, CYBERCRIME RISKS RES, P103, DOI DOI 10.1057/97811374741627
   Luo P, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P968
   Maldonado S., 2013, Pattern Recognition-Applications and Methods, P135
   Mehta B., 2008, 17 INT C WORLD WID W, P497, DOI DOI 10.1145/1367497.1367565
   Min Zuo, 2007, 2007 Third International IEEE Conference on Signal-Image Technologies and Internet-Based System (SITIS), P289, DOI 10.1109/SITIS.2007.124
   Montresor A, 2009, IEEE INT CONF PEER, P99, DOI 10.1109/P2P.2009.5284506
   Özgür L, 2004, LECT NOTES COMPUT SC, V3177, P505
   Ruan GC, 2010, SOFT COMPUT, V14, P139, DOI 10.1007/s00500-009-0440-2
   Vieira AB, 2013, COMPUT NETW, V57, P1019, DOI 10.1016/j.comnet.2012.12.001
   Zhang C, 2015, LISS 2013, P591, DOI 10.1007/978-3-642-40660-7_87
   Zhou F, 2003, LECT NOTES COMPUT SC, V2672, P1
NR 33
TC 6
Z9 6
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13249
EP 13278
DI 10.1007/s11042-017-4944-y
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900009
DA 2024-07-18
ER

PT J
AU Asadi-Aghbolaghi, M
   Kasaei, S
AF Asadi-Aghbolaghi, Maryam
   Kasaei, Shohreh
TI Supervised spatio-temporal kernel descriptor for human action
   recognition from RGB-depth videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Supervised kernel descriptor; RGB-D video; LMNN; EMK
ID POSE
AB One of the most challenging tasks in computer vision is human action recognition. The recent development of depth sensors has created new opportunities in this field of research. In this paper, a novel supervised spatio-temporal kernel descriptor (SSTKDes) is proposed from RGB-depth videos to establish a discriminative and compact feature representation of actions. To enhance the descriptive and discriminative ability of the descriptor, extracted primary kernel-based features are transformed into a new space by exploiting a supervised training strategy; i.e., large margin nearest neighbor (LMNN). The LMNN highly reduces the error of a nearest neighbor classifier by minimizing the intra-class variations and maximizing the inter-class distances. Subsequently, the efficient match kernel (EMK) is used to abstract the mid-level kernel features for a more efficient classification. The proposed approach is evaluated on five public benchmark datasets. The experimental evaluations demonstrate that the proposed method achieves superior performance to the state-of-the-art methods.
C1 [Asadi-Aghbolaghi, Maryam; Kasaei, Shohreh] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 Sharif University of Technology
RP Kasaei, S (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
EM masadia@ce.sharif.edu; skasaei@sharif.edu
RI Kasaei, Shohreh/AAD-5618-2019
OI Kasaei, Shohreh/0000-0002-3831-0878; Asadi, Maryam/0000-0001-5289-6708
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Chaaraoui AA, 2014, EXPERT SYST APPL, V41, P786, DOI 10.1016/j.eswa.2013.08.009
   [Anonymous], 2009, Advances in neural information processing systems
   [Anonymous], 2015, ACTION RECOGNITION D
   Asadi-Aghbolaghi M, 2014, 2014 7TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P66, DOI 10.1109/ISTEL.2014.7000671
   Asadi-Aghbolaghi M, 2014, IRAN CONF ELECTR ENG, P1157, DOI 10.1109/IranianCEE.2014.6999710
   Boureau Y. L., 2010, P 27 INT C MACH LEAR, P111
   Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Devanne M, 2013, LECT NOTES COMPUT SC, V8158, P456, DOI 10.1007/978-3-642-41190-8_49
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gupta A, 2014, PROC CVPR IEEE, P2601, DOI 10.1109/CVPR.2014.333
   Han F, 2016, ARXIV160101006
   Jafari R, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON ROBOTIC AND SENSORS ENVIRONMENTS (ROSE 2012), P13, DOI 10.1109/ROSE.2012.6402633
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Kang S., 2016, CoRR
   Kong Y, 2016, COMPUT VIS IMAGE UND, V144, P14, DOI 10.1016/j.cviu.2015.10.001
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Lu CW, 2014, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2014.104
   Mao Ye, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P149, DOI 10.1007/978-3-642-44964-2_8
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48
   Reyes M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1182, DOI 10.1109/ICCVW.2011.6130384
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Simonyan K, 2014, ADV NEUR IN, V27
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Tehrani AKN, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P303, DOI 10.5220/0006134903030310
   Varol G., 2016, CoRR
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vieira A. W., 2012, PROGR PATTERN RECOGN, P252, DOI [DOI 10.1007/978-3-642-33275-3, DOI 10.1007/978-3-642-33275]
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang P, 2013, PROC CVPR IEEE, P2858, DOI 10.1109/CVPR.2013.368
   Wang X, 2015, P CVPR 15
   Wei P, 2013, IEEE I CONF COMP VIS, P3272, DOI 10.1109/ICCV.2013.406
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Xiao Y, 2016, MULTIMEDIA TOOLS APP, V75
   Yang X., 2012, IEEE COMP SOC C COMP, V2012, P14, DOI [DOI 10.1109/CVPRW.2012.6239232, 10.1109/CVPRW.2012.6239232]
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Ye Gu, 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1379, DOI 10.1109/ROBIO.2012.6491161
   Yu S, 2017, MULTIMED TOOLS APPL, V76, P13367, DOI 10.1007/s11042-016-3768-5
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhou Liu, 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7286491
NR 57
TC 13
Z9 13
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14115
EP 14135
DI 10.1007/s11042-017-5017-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900045
DA 2024-07-18
ER

PT J
AU Laiche, N
   Larabi, S
AF Laiche, Nacera
   Larabi, Slimane
TI Shape retrieval through normalized B-splines curves
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Outline shape; Contour matching; Curvature points; B-spline
   approximation; Similarity measure; Shape retrieval
ID DESCRIPTOR; DISTANCE; RECOGNITION; REPRESENTATION; IDENTIFICATION;
   APPROXIMATION; CENTROIDS; CONTOUR; POINTS
AB This paper proposes a new technique for 2D shape modeling and retrieval based only on curves defined from shape boundary. Firstly, a shape representation system is build based on the decomposition of the outline into its constituent parts and their geometric description. The process decomposition is done using high curvature points located along the boundary. These obtained parts are then described by parametric curves using the B-spline approximation and normalized in order to eliminate scaling transformation. Finally, the resulting curves allow matching of shapes and retrieving that is robust to rotation, scale change and deformation. Experiments conducted on a variety of shape databases including Kimia-99, Kimia-216, MPEG-7 and our database created from a selection of ETH-80 shape database, illustrate the performance of the proposed approach when compared with existing algorithms in literature. Obtained results are presented and discussed.
C1 [Laiche, Nacera; Larabi, Slimane] USTHB, Dept Comp Sci, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Laiche, N (corresponding author), USTHB, Dept Comp Sci, Algiers, Algeria.
EM nlaiche@usthb.dz; slarabi@usthb.dz
RI Larabi, Slimane/AAD-7871-2020
OI larabi, slimane/0000-0001-8994-5980
CR Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776
   Alajlan N, 2010, ARTIF LIFE ROBOT, V15, P309, DOI 10.1007/s10015-010-0814-7
   Andaló FA, 2010, PATTERN RECOGN, V43, P26, DOI 10.1016/j.patcog.2009.06.012
   Argawal S, 2004, IEEE T PATTERN ANAL, V26, P1475
   Arica N, 2003, PATTERN RECOGN LETT, V24, P1627, DOI 10.1016/S0167-8655(03)00002-3
   Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85
   Carmona-Poyato A, 2010, PATTERN RECOGN, V43, P14, DOI 10.1016/j.patcog.2009.06.010
   Chen XD, 2010, COMPUT AIDED DESIGN, V42, P523, DOI 10.1016/j.cad.2010.01.008
   Chetvericov D, 2003, 10 INT C CAIP, P1501
   COHEN FS, 1995, IEEE T IMAGE PROCESS, V4, P1, DOI 10.1109/83.350818
   Daliri MR, 2009, COMPUT VIS IMAGE UND, V113, P1017, DOI 10.1016/j.cviu.2009.05.001
   Direkoglu C, 2011, PATTERN RECOGN, V44, P2134, DOI 10.1016/j.patcog.2011.02.016
   Ebrahim Y, 2009, PATTERN RECOGN LETT, V30, P348, DOI 10.1016/j.patrec.2008.09.013
   El-Rube I, 2004, ICIP INT C IM PROC S
   Graham R. L., 1972, Information Processing Letters, V1, P132, DOI 10.1016/0020-0190(72)90045-2
   Gu YH, 2000, PATTERN RECOGN, V33, P1411, DOI 10.1016/S0031-3203(99)00131-4
   Hayward WG, 1998, J EXP PSYCHOL HUMAN, V24, P427, DOI 10.1037/0096-1523.24.2.427
   Hu RX, 2012, PATTERN RECOGN, V45, P3348, DOI 10.1016/j.patcog.2012.02.018
   Ion A, 2011, COMPUT VIS IMAGE UND, V115, P817, DOI 10.1016/j.cviu.2011.02.006
   Juhász I, 2013, COMPUT AIDED GEOM D, V30, P85, DOI 10.1016/j.cagd.2012.06.007
   Klette R, 2012, COMPUT VIS IMAGE UND, V116, P690, DOI 10.1016/j.cviu.2012.02.001
   Krishnamoorthy R, 2013, DIGIT SIGNAL PROCESS, V23, P555, DOI 10.1016/j.dsp.2012.09.018
   Laiche N, 2011, IEEE INT C SIGN IM P, P495
   Laiche N, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P484
   Latecki L. J, 2000, IEEE TPAMI, V22, P1182
   Latecki LJ, 2000, CVPR, P1424
   LEIBE B, 2003, INT C COMP VIS PATT
   Li ZM, 2016, COMPUT GRAPH-UK, V54, P8, DOI 10.1016/j.cag.2015.07.002
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu YK, 2007, PATTERN RECOGN, V40, P2908, DOI 10.1016/j.patcog.2007.03.001
   Lu YY, 2012, COMPUT GRAPH-UK, V36, P466, DOI 10.1016/j.cag.2012.03.018
   Ma ZM, 2011, PATTERN ANAL APPL, V14, P9, DOI 10.1007/s10044-009-0171-0
   Mokhtarian F., 1996, Proceedings of International Workshop on Image Databases and Multimedia Search, P35
   Mongkolnam P, 2007, IAPR C MACH VIS APPL, P355
   Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220
   Nanni L, 2012, PATTERN RECOGN LETT, V33, P2254, DOI 10.1016/j.patrec.2012.07.007
   NIBLACK CW, 1992, CVGIP-GRAPH MODEL IM, V54, P420, DOI 10.1016/1049-9652(92)90026-T
   Park H, 2007, COMPUT AIDED DESIGN, V39, P439, DOI 10.1016/j.cad.2006.12.006
   Pedrosa GV, 2013, NEUROCOMPUTING, V120, P156, DOI 10.1016/j.neucom.2012.07.055
   Piegl L., 1997, The Nurbs Book, Vsecond
   RIVLIN E, 1995, IEEE T PATTERN ANAL, V17, P226, DOI 10.1109/34.368188
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Shi Y, 2013, OPTIK, V124, P6149, DOI 10.1016/j.ijleo.2013.04.132
   Wang JW, 2012, PATTERN RECOGN LETT, V33, P134, DOI 10.1016/j.patrec.2011.09.042
   Wang WP, 2006, ACM T GRAPHIC, V25, P214, DOI 10.1145/1138450.1138453
   Yang GY, 2006, PATTERN RECOGN, V39, P74, DOI 10.1016/j.patcog.2005.08.008
   Yang HP, 2004, COMPUT AIDED DESIGN, V36, P639, DOI 10.1016/S0010-4485(03)00140-4
   Yang JY, 2016, COMPUT VIS IMAGE UND, V145, P43, DOI 10.1016/j.cviu.2016.01.005
   Zaletelj J, 1998, EUR SIGN PROC C, V9, P1501
   Zhang DS, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P425, DOI 10.1109/ICME.2002.1035809
   Zunic J, 2011, PATTERN RECOGN, V44, P2161, DOI 10.1016/j.patcog.2011.03.003
NR 51
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13891
EP 13921
DI 10.1007/s11042-017-4998-x
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900036
DA 2024-07-18
ER

PT J
AU Huang, H
   Fu, S
   Cai, ZQ
   Li, B
AF Huang, Han
   Fu, Shen
   Cai, Zhao-Quan
   Li, Bin
TI Video abstract system based on spatial-temporal neighborhood trajectory
   analysis algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial-temporal neighborhood; Trajectory analysis; Video abstract
ID MULTITARGET TRACKING
AB In this paper, a video abstract system based on spatial-temporal neighborhood trajectory analysis algorithm which is mainly used to process surveillance videos is proposed. The algorithm uses the spatial adjacency of foreground targets and tracks the spatial-temporal neighboring moving targets to get their whole trajectories in order to meet the requirement of processing speed and accuracy. The indicators consist of trajectory detection rate, trajectory tracking average continuity and video abstract processing speed are used to evaluate the effectiveness of the system. We compare the algorithm with the other three algorithms, and the results show that spatial-temporal neighborhood trajectory analysis algorithm has sufficient trajectory detection rate and processing speed for surveillance video abstraction.
C1 [Huang, Han; Fu, Shen; Li, Bin] South China Univ Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Cai, Zhao-Quan] Coll Huizhou, Huizhou 516007, Guangdong, Peoples R China.
C3 South China University of Technology
RP Cai, ZQ (corresponding author), Coll Huizhou, Huizhou 516007, Guangdong, Peoples R China.
EM hhan@scut.edu.cn; cai@hzu.edu.cn
RI Zhang, Can/JUU-9511-2023
FU National Natural Science Foundation of China [61370102, 61370185];
   Guangdong Natural Science Funds [2014A030306050]; Ministry of Education
   - China Mobile Research Funds [MCM20160206]; Guangdong High-level
   personnel of special support program [2014TQ01X664]
FX This work is supported by National Natural Science Foundation of China
   (61370102, 61370185), Guangdong Natural Science Funds for Distinguished
   Young Scholar (2014A030306050), the Ministry of Education - China Mobile
   Research Funds (MCM20160206) and Guangdong High-level personnel of
   special support program(2014TQ01X664).
CR Al-Ayyoub M, 2016, MULTIMED TOOLS APP, P1
   Alsmirat MA, 2017, J REAL-TIME IMAGE PR, V13, P527, DOI 10.1007/s11554-016-0631-x
   Andriyenko A, 2012, PROC CVPR IEEE, P1926, DOI 10.1109/CVPR.2012.6247893
   [Anonymous], COMPUT SECUR
   [Anonymous], 2017, IEEE transactions on pattern analysis and machine intelligence
   [Anonymous], IEEE T AEROSP ELECT
   Chari V, 2015, PROC CVPR IEEE, P5537, DOI 10.1109/CVPR.2015.7299193
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Li P., 2017, Cluster Comput., P1
   Lin L, 2012, IEEE T IMAGE PROCESS, V21, P4844, DOI 10.1109/TIP.2012.2211373
   Lipowski A, 2012, PHYSICA A, V391, P2193, DOI 10.1016/j.physa.2011.12.004
   Liu N, 2015, IEEE T CYBERNETICS, V45, P89, DOI 10.1109/TCYB.2014.2320493
   Milan A., 2016, MOT16 BENCHMARK MULT
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Shi XC, 2013, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2013.309
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Vaidya J, 2013, 2013 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P571, DOI 10.1109/WI-IAT.2013.80
   Varadarajan S, 2015, PATTERN RECOGN, V48, P3488, DOI 10.1016/j.patcog.2015.04.016
   Wang XC, 2014, LECT NOTES COMPUT SC, V8689, P17, DOI 10.1007/978-3-319-10590-1_2
   Yang Y, 2003, IMAGE VISION COMPUT, V21, P459, DOI 10.1016/S0262-8856(03)00015-5
   Yu C, 2017, MULTIMED TOOLS APPL, P1
   Zhang S, 2015, PATTERN RECOGN, V48, P580, DOI 10.1016/j.patcog.2014.08.013
   Zhang X, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0050-0
NR 26
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11321
EP 11338
DI 10.1007/s11042-017-5549-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900052
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, JR
   Li, YJ
AF Li, Jianru
   Li, Yujie
TI Guided local laplacian filter-based image enhancement for deep-sea
   sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater imaging; Image Enhancement; Guided local Laplacian filter
ID UNDERWATER; RESTORATION
AB This paper describes a novel method of enhancing deep-sea optical images using guided local Laplacian filter. Absorption and are two major distortion issues for deep-sea optical imaging. While light traveling through the water, light rays are scattered and absorbed depending on the wavelength. Scattering is caused by large suspended particles, as in turbid water that contains abundant particles, which causes the degradation of the captured image. Absorption corresponds to the varying degrees of attenuation encountered by light traveling in water at different wavelengths that causing ambient underwater to be dominated by a bluish tone. Our key contributions are proposed include a novel deep-sea imaging model to compensate for the attenuation discrepancy along the propagation path and an effective underwater scene enhancement scheme. The recovered images are characterized by a reduced noised level, better exposure of the dark regions, and improved global contrast where the finest details and edges are enhanced significantly.
C1 [Li, Jianru] Tongji Univ, State Key Lab Marine Geol, Shanghai, Peoples R China.
   [Li, Yujie] Yangzhou Univ, Yangzhou, Jiangsu, Peoples R China.
C3 Tongji University; Yangzhou University
RP Li, JR (corresponding author), Tongji Univ, State Key Lab Marine Geol, Shanghai, Peoples R China.
EM lijianru@tongji.edu.cn; liyujie@yzu.edu.cn
RI Li, YuJie/JAC-4451-2023; Li, Yujie/AAH-3298-2019; Li,
   YuJie/HGT-8657-2022
OI Li, Yujie/0000-0002-0275-2797; 
CR Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   Bazeille, 2006, P CAR MIL MAR CMM 06, P1
   Carlevaris-Bianco N., 2010, OCEANS, P1, DOI DOI 10.1109/OCEANS.2010.5664428
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hou W, 2007, INT GEOSCI REMOTE SE, P1889, DOI 10.1109/IGARSS.2007.4423193
   Kocak DM, 2008, MAR TECHNOL SOC J, V42, P52, DOI 10.4031/002533208786861209
   Lu HM, 2018, MULTIMED TOOLS APPL, V77, P21847, DOI 10.1007/s11042-017-4585-1
   Lu HM, 2017, MOBILE NETW APPL, V22, P1204, DOI 10.1007/s11036-017-0863-4
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Lu HM, 2017, IEEE ACCESS, V5, P670, DOI 10.1109/ACCESS.2017.2648845
   Lu HM, 2016, MULTIMED TOOLS APPL, V75, P17081, DOI 10.1007/s11042-015-2977-7
   Lu HM, 2016, INT J COMPUT SCI ENG, V12, P352
   Lu HM, 2016, J VIS COMMUN IMAGE R, V38, P504, DOI 10.1016/j.jvcir.2016.03.029
   Lu HM, 2016, IEICE T INF SYST, VE99D, P219, DOI 10.1587/transinf.2014EDP7405
   Lu HM, 2015, J OPT SOC AM A, V32, P886, DOI 10.1364/JOSAA.32.000886
   Lu HM, 2013, IEEE IMAGE PROC, P3412, DOI 10.1109/ICIP.2013.6738704
   Lu Hung-Jen, 2014, Biomed Res Int, V2014, P652680, DOI 10.1155/2014/652680
   Ouyang B, 2012, PROC SPIE, V8372, DOI 10.1117/12.920710
   Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Yang QX, 2013, IEEE T IMAGE PROCESS, V22, P4841, DOI 10.1109/TIP.2013.2278917
NR 26
TC 3
Z9 3
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10823
EP 10834
DI 10.1007/s11042-017-5300-y
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900026
DA 2024-07-18
ER

PT J
AU Ali, IR
   Kolivand, H
   Alkawaz, MH
AF Ali, Itimad Raheem
   Kolivand, Hoshang
   Alkawaz, Mohammed Hazim
TI Lip syncing method for realistic expressive 3D face model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lip syncing; Facial expression; Mpeg-4; PCA; Plutchik's wheel
ID ANIMATION
AB Lip synchronization of 3D face model is now being used in a multitude of important fields. It brings a more human, social and dramatic reality to computer games, films and interactive multimedia, and is growing in use and importance. High level of realism can be used in demanding applications such as computer games and cinema. Authoring lip syncing with complex and subtle expressions is still difficult and fraught with problems in terms of realism. This research proposed a lip syncing method of realistic expressive 3D face model. Animated lips requires a 3D face model capable of representing the myriad shapes the human face experiences during speech and a method to produce the correct lip shape at the correct time. The paper presented a 3D face model designed to support lip syncing that align with input audio file. It deforms using Raised Cosine Deformation (RCD) function that is grafted onto the input facial geometry. The face model was based on MPEG-4 Facial Animation (FA) Standard. This paper proposed a method to animate the 3D face model over time to create animated lip syncing using a canonical set of visemes for all pairwise combinations of a reduced phoneme set called ProPhone. The proposed research integrated emotions by the consideration of Ekman model and Plutchik's wheel with emotive eye movements by implementing Emotional Eye Movements Markup Language (EEMML) to produce realistic 3D face model.
C1 [Ali, Itimad Raheem] Univ Informat Technol & Commun, Coll Business Informat, Al Nedhal St, Baghdad, Iraq.
   [Kolivand, Hoshang] Liverpool John Moores Univ, Dept Comp Sci, Liverpool L3 3AF, Merseyside, England.
   [Alkawaz, Mohammed Hazim] Management & Sci Univ, Fac Informat Sci & Engn, Shah Alam, Selangor, Malaysia.
   [Alkawaz, Mohammed Hazim] Nawroz Univ, Ctr Sci Res & Dev, Dahuk, Kurdistan Regio, Iraq.
C3 University of Information Technology & Communication; Liverpool John
   Moores University; University of Liverpool; Management Science
   University; Nawroz University
RP Ali, IR (corresponding author), Univ Informat Technol & Commun, Coll Business Informat, Al Nedhal St, Baghdad, Iraq.
EM weffee@yahoo.com
RI Kolivand, Hoshang/F-4736-2011; Alkawaz, Mohammed Hazim/KOC-6843-2024;
   ali, itimad/AAU-2747-2020; Kolivand, Hoshang/B-2501-2016; ali,
   itimad/N-2459-2017
OI Alkawaz, Mohammed Hazim/0000-0001-9715-8477; Kolivand,
   Hoshang/0000-0001-5460-5679; ali, itimad/0000-0002-9762-0534
CR Anh LQ, 2011, EXPRESSIVE GESTURE M, P224
   [Anonymous], 2009, Comput. Entertain., DOI [DOI 10.1145/1658866.1658877, 10.1145/1658866.1658877]
   Bailly G, 2010, SPEECH COMMUN, V52, P598, DOI 10.1016/j.specom.2010.02.015
   Balci K, 2007, ITCIRST COGN COMMUN
   Balci K, 2007, P 15 INT C MULT, P399
   Balci Koray., 2007, MULTIMEDIA'07: Proceedings of the 15th international conference on Multimedia, P1013
   Bao C., APSIPA ASC 2011
   Black Alan, 2001, FESTIVAL SPEEC UNPUB, P365
   Cassell J, 2001, COMP GRAPH, P477, DOI 10.1145/383259.383315
   Cerekovic A, 2010, CONTROLLER BASED ANI, P80
   Cerekovic A, 2011, MULTIMED TOOLS APPL, V54, P143, DOI 10.1007/s11042-010-0530-2
   D'Mello S, 2012, INT J HUM-COMPUT ST, V70, P377, DOI 10.1016/j.ijhcs.2012.01.004
   Ekman P., 1999, HDB COGNITION EMOTIO, P45, DOI [10.1002/0470013494.ch3, DOI 10.1002/0470013494]
   Frantz S., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P687, DOI 10.1007/BFb0055698
   Frantz S, 2000, LECT NOTES COMPUT SC, V1935, P492
   Gillies M, 2010, VIRTUAL REAL-LONDON, V14, P221, DOI 10.1007/s10055-010-0167-5
   Hong PY, 2002, IEEE T NEURAL NETWOR, V13, P916, DOI 10.1109/TNN.2002.1021892
   Kessler Brett, 2002, J MEMORY LANGUAGE
   Kolivand H, 2015, IETE, V30, P38
   Kowler E, 2011, VISION RES, V51, P1457, DOI 10.1016/j.visres.2010.12.014
   Lee CY, 2011, COMPUT ANIMAT VIRT W, V22, P177, DOI 10.1002/cav.399
   Lee SB, 2010, DESALIN WATER TREAT, V19, P64, DOI 10.5004/dwt.2010.1897
   Leone G. R., 2012, LUCIA OPEN SOURCE 3D, P193
   Leuski A, 2014, IUI 2014 DEMONSTRATI, P21
   Li B, 2013, TELKOMNIKA, V11
   Li Z, 2012, MULTIMED TOOLS APPL, V60, P181, DOI 10.1007/s11042-011-0816-z
   Pandzic Igor S., 2003, MPEG-4 facial animation: the standard, implementation and applications
   Pasquariello S., 2001, P 6 ONL WORLD C SOFT
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Raouzaiou A, 2002, EURASIP J APPL SIG P, V2002, P1021, DOI 10.1155/S1110865702206149
   Serra J, 2012, COMM COM INF SC, V328, P267
   Shapiro A., 2011, LECT NOTES COMPUTER, P98, DOI DOI 10.1007/978-3-642-25090-3_9
   Singular Inversions, 2006, FAC SOFTW
   Somasundaram A., 2006, AUDIO VISUAL SPEECH
   Sphinx Group Carnegie Mellon University, 2006, CMU SPHINX PROJ
   Taylor SL, 2012, SCA, P245
   TRueSpel, 2001, ENGL TRUESP US ACC T
   Vezzetti E., 2013, COMPUTERS IND
   Vezzetti E, 2014, MULTIMED TOOLS APPL, V68, P895, DOI 10.1007/s11042-012-1091-3
   Wei L, 2015, IEEE COMPUT GRAPH, V35, P70, DOI 10.1109/MCG.2014.105
   Xu Yiqi., 2013, HPDC, P109
   Yuencheng Lee, 1995, Computer Graphics Proceedings. SIGGRAPH 95, P55
   Zhang S., 2010, FACIAL EXPRESSION SY, P109
   Zhao X, 2013, IMAGE VISION COMPUT, V31, P231, DOI 10.1016/j.imavis.2012.10.001
NR 44
TC 5
Z9 5
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5323
EP 5366
DI 10.1007/s11042-017-4437-z
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800011
DA 2024-07-18
ER

PT J
AU Ma, Q
   Xu, L
   Xing, L
   Wu, B
AF Ma, Qiang
   Xu, Lei
   Xing, Ling
   Wu, Bin
TI Robust image authentication via locality sensitive hashing with core
   alignment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image hashing; Image robust authentication; Core alignment; Locality
   sensitive hashing; Hashing function optimization
ID TRANSFORM
AB Robust image hashing is a promising technique to represent image's perceptual content. However, when it comes to image authentication, tradeoff between robustness and discrimination is a non-negligible issue. The allowed content preserving operations and sensitive malicious manipulations on images are quite subjective to human's perception. So it needs tactics to design good hashing methods. In this paper we incorporate the novel concept of core alignment into hashing, where the proposed core alignment improves the performances of balance. First, we formulize the hashing as a supervised minimal optimization problem based on Locality Sensitive Hashing, in which p-stable distribution is exploited to maintain high dimensional locality features. Then we solve this problem by two sub-optimization problems, i.e., searching for optimal shift and searching for optimal quantization intervals. By using particle swarm optimization and simulated annealing programming approaches we develop two stochastic solutions to those two problems, respectively. Experimental results show that our proposed hashing optimizations can find optimal solutions with limited steps, and the hashing method is superior to other state-of-the-art methods in terms of authentication and robustness.
C1 [Ma, Qiang; Xing, Ling; Wu, Bin] Southwest Univ Sci & Technol, Sch Informat Engn, Mianyang 621010, Peoples R China.
   [Ma, Qiang] China Acad Engn Phys, Inst Elect Engn, Mianyang 621900, Peoples R China.
   [Xu, Lei] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
C3 Southwest University of Science & Technology - China; Chinese Academy of
   Engineering Physics; Tsinghua University
RP Ma, Q (corresponding author), Southwest Univ Sci & Technol, Sch Informat Engn, Mianyang 621010, Peoples R China.; Ma, Q (corresponding author), China Acad Engn Phys, Inst Elect Engn, Mianyang 621900, Peoples R China.
EM maqiang_my@163.com
FU National Natural Science Foundation of China [61171109]; Applied Basic
   Research Programs of Sichuan Science and Technology Department
   [2014JY0215]; Basic Research Plan in SWUST [13zx9101]
FX This research is supported by National Natural Science Foundation of
   China (Grant No. 61171109), Applied Basic Research Programs of Sichuan
   Science and Technology Department (Grant No. 2014JY0215) and Basic
   Research Plan in SWUST (Grant No. 13zx9101). The authors greatly thank
   the anonymous reviewers for their valuable comments and suggestions.
CR [Anonymous], 2008, Advances in Neural Information Processing Systems
   Bai X, 2014, IEEE T IMAGE PROCESS, V23, P5033, DOI 10.1109/TIP.2014.2352458
   Chen B., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P100, DOI 10.1109/DICTA.2010.26
   Datar Mayur, 2004, PROC 20 S COMPUTATIO, P253
   Galigekere RR, 2000, OPT ENG, V39, P1088, DOI 10.1117/1.602471
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Indyk P, 2000, ANN IEEE SYMP FOUND, P189, DOI 10.1109/SFCS.2000.892082
   Kailasanathan C., 2001, P IEEE EURASIP WORKS, P1
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Lei YQ, 2011, SIGNAL PROCESS-IMAGE, V26, P280, DOI 10.1016/j.image.2011.04.007
   Li CH, 2012, IEEE T SYST MAN CY B, V42, P627, DOI 10.1109/TSMCB.2011.2171946
   Li YN, 2015, IEEE SIGNAL PROC LET, V22, P2396, DOI 10.1109/LSP.2015.2487824
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Li YN, 2012, IEEE T IMAGE PROCESS, V21, P1963, DOI 10.1109/TIP.2011.2171698
   Mao Y, 2007, IEEE T INF FOREN SEC, V2, P462, DOI 10.1109/TIFS.2007.902260
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Monga V, 2006, IEEE T INF FOREN SEC, V1, P68, DOI 10.1109/TIFS.2005.863502
   Monga V, 2006, IEEE T IMAGE PROCESS, V15, P3452, DOI 10.1109/TIP.2006.881948
   Olmos A, KINGDOM FAA MCGILL C
   Qin C, 2016, INFORM SCIENCES, V361, P84, DOI 10.1016/j.ins.2016.04.036
   Slaney M, 2008, IEEE SIGNAL PROC MAG, V25, P128, DOI 10.1109/MSP.2007.914237
   Smith KI, 2008, IEEE T EVOLUT COMPUT, V12, P323, DOI 10.1109/TEVC.2007.904345
   Sun R, 2014, MULTIMED TOOLS APPL, V70, P1651, DOI 10.1007/s11042-012-1188-8
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Tang ZJ, 2016, AEU-INT J ELECTRON C, V70, P833, DOI 10.1016/j.aeue.2016.03.010
   Tang ZJ, 2015, DIGIT SIGNAL PROCESS, V43, P17, DOI 10.1016/j.dsp.2015.05.002
   Tang ZJ, 2014, OPTIK, V125, P5102, DOI 10.1016/j.ijleo.2014.05.015
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Xiang SJ, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-77
   Zhan ZH, 2011, IEEE T EVOLUT COMPUT, V15, P832, DOI 10.1109/TEVC.2010.2052054
   Zhang WH, 2016, KNOWL-BASED SYST, V97, P40, DOI 10.1016/j.knosys.2016.01.022
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
NR 34
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7131
EP 7152
DI 10.1007/s11042-017-4625-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700032
DA 2024-07-18
ER

PT J
AU Neycharan, JG
   Ahmadyfard, A
AF Neycharan, Jalil Ghavidel
   Ahmadyfard, Alireza
TI Edge color transform: a new operator for natural scene text localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text localization; Edge color transform; Region growing; Dictionary
   learning
ID PARALLEL FRAMEWORK; HYBRID APPROACH; IMAGES; RECOGNITION; EXTRACTION;
   SYSTEM
AB Text extraction is one of the most intuitive and natural ways in understanding of natural scene images. Localization is the first and one of the most important steps in this problem. In this paper, we propose a novel method for localizing text in natural scene images. We introduce a new operator so called Edge Color Transform (ECT) to solve this problem. After extracting the edge map of the input image, this operator follows the gradient direction (and the opposite direction) to assign the nearest color to each of the edge pixels. In the next step, each channel (Red, Green and Blue) of these color pixels are normalized to make them more robust to intensity changes. In the following step, these colored pixels are grouped together using a modified version of region growing algorithm. In this customized version of the algorithm, pixels of a region do not have to be spatially connected and their connectivity is decided based on a predefined oval-shaped neighborhood. When the regions are forged, each of them form a text candidate region. Subsequently, all of these candidates are applied to a classifier to extract text regions. Experimental results show that the proposed method performs well on both Farsi and well-known ICDAR 2013 data sets.
C1 [Neycharan, Jalil Ghavidel] Shahrood Univ Technol, Sch Comp & Informat Technol Engn, Shahrood, Iran.
   [Ahmadyfard, Alireza] Shahrood Univ Technol, Sch Elect Engn, Shahrood, Iran.
C3 Shahrood University of Technology; Shahrood University of Technology
RP Ahmadyfard, A (corresponding author), Shahrood Univ Technol, Sch Elect Engn, Shahrood, Iran.
EM Jalil_ghavidel@shahroodut.ac.ir; Ahmadyfard@shahroodut.ac.ir
RI Ghavidel Neycharan, Jalil/JWP-2049-2024
OI Ghavidel Neycharan, Jalil/0000-0003-3644-5928
CR [Anonymous], P 12 INT CSI COMP C
   [Anonymous], TEXT SPOTTER
   [Anonymous], P INT C COMP VIS THE
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], EXTRACTION TEXT OBJE
   [Anonymous], INT J COMPUT APPL
   [Anonymous], 1985, INTRO DIGITAL IMAGE
   Aydin T, 1996, IEEE T IMAGE PROCESS, V5, P1370, DOI 10.1109/83.535850
   Busta M, 2015, IEEE I CONF COMP VIS, P1206, DOI 10.1109/ICCV.2015.143
   Chan CH, 2007, LECT NOTES COMPUT SC, V4642, P809
   Chen XR, 2004, PROC CVPR IEEE, P366
   Chuang Li, 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P1069, DOI 10.1109/ICDAR.2001.953950
   Coates A, 2011, PROC INT CONF DOC, P440, DOI 10.1109/ICDAR.2011.95
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Darab M, 2012, PROCEDIA COMPUT SCI, V13, P171, DOI 10.1016/j.procs.2012.09.126
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Fabrizio J, 2013, PATTERN ANAL APPL, V16, P519, DOI 10.1007/s10044-013-0329-7
   Faghih F, 2002, IEEE T IMAGE PROCESS, V11, P1062, DOI 10.1109/TIP.2002.802526
   Ghanei S, 2016, COMPUT VIS IMAGE UND, V142, P94, DOI 10.1016/j.cviu.2015.10.002
   Ghanei S, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415550125
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Kim KC, 2004, INT C PATT RECOG, P679, DOI 10.1109/ICPR.2004.1334350
   Lafferty J., 2001, CONDITIONAL RANDOM F, V2001, P282
   Lee JJ, 2011, PROC INT CONF DOC, P429, DOI 10.1109/ICDAR.2011.93
   Li Y, 2012, INT C PATT RECOG, P681
   Li Y, 2014, IEEE T IMAGE PROCESS, V23, P1666, DOI 10.1109/TIP.2014.2302896
   Liu XQ, 2015, MULTIMED TOOLS APPL, V74, P4891, DOI 10.1007/s11042-013-1848-3
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu SJ, 2015, INT J DOC ANAL RECOG, V18, P125, DOI 10.1007/s10032-015-0237-z
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Minetto R, 2013, PATTERN RECOGN, V46, P1078, DOI 10.1016/j.patcog.2012.10.009
   Neumann L, 2016, IEEE T PATTERN ANAL, V38, P1872, DOI 10.1109/TPAMI.2015.2496234
   Neumann L, 2015, PROC INT CONF DOC, P746, DOI 10.1109/ICDAR.2015.7333861
   Neumann L, 2013, PROC INT CONF DOC, P523, DOI 10.1109/ICDAR.2013.110
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   OHYA J, 1994, IEEE T PATTERN ANAL, V16, P214, DOI 10.1109/34.273729
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pan YF, 2011, IEEE T IMAGE PROCESS, V20, P800, DOI 10.1109/TIP.2010.2070803
   Pan YF, 2008, PROCEEDINGS OF THE 8TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, P35, DOI 10.1109/DAS.2008.42
   Rahtu E, 2012, IMAGE VISION COMPUT, V30, P501, DOI 10.1016/j.imavis.2012.04.001
   Rajathilagam B, 2017, PATTERN RECOGN, V67, P1, DOI 10.1016/j.patcog.2017.01.028
   Risnumawan A, 2014, EXPERT SYST APPL, V41, P8027, DOI 10.1016/j.eswa.2014.07.008
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Shi CZ, 2013, PATTERN RECOGN LETT, V34, P107, DOI 10.1016/j.patrec.2012.09.019
   Sochman J, 2005, PROC CVPR IEEE, P150
   Takahashi H, 2005, THIRD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 1, PROCEEDINGS, P680
   Verma OP, 2017, IEEE T FUZZY SYST, V25, P114, DOI 10.1109/TFUZZ.2016.2551289
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vu TH, 2016, IEEE T MED IMAGING, V35, P738, DOI 10.1109/TMI.2015.2493530
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan JQ, 2014, NEUROCOMPUTING, V134, P3, DOI 10.1016/j.neucom.2012.12.070
   Yang Y, 2018, MULTIDIM SYST SIGN P, V29, P339, DOI 10.1007/s11045-016-0468-2
   Yao JL, 2007, INT C WAVEL ANAL PAT, P1418
   Yi-Feng Pan, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P6, DOI 10.1109/ICDAR.2009.97
   Yin XC, 2015, IEEE T PATTERN ANAL, V37, P1930, DOI 10.1109/TPAMI.2014.2388210
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Zhang HG, 2013, NEUROCOMPUTING, V122, P310, DOI 10.1016/j.neucom.2013.05.037
   Zheng Y, 2017, NEUROCOMPUTING, V238, P307, DOI 10.1016/j.neucom.2017.01.066
NR 64
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7615
EP 7636
DI 10.1007/s11042-017-4663-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700054
DA 2024-07-18
ER

PT J
AU Rao, BS
AF Rao, B. Subrahmanyeswara
TI A fuzzy fusion approach for modified contrast enhancement based image
   forensics against attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrast enhancement; CE trace hiding attack; CE trace forging attack;
   Fuzzy fusion; Artificial neural network
ID FORGERY DETECTION; COMPRESSION
AB In today's digital age the trustworthy towards image is distorting because of malicious forgery images. The issues related to the multimedia security have led to the research focus towards tampering detection. The main objective of the work is to develop robust and forensic detection framework against post processing. It is also essential to enhance the security against attacks. In this paper, a Modified Contrast Enhancement based Forensics (MCEF) method based on Fuzzy Fusion is proposed against post-processing activity. First, we check for the histogram peaks and gaps as a result of contrast enhancement which is used in the latest technique. From the standpoint of attackers, we use two types of attacks, CE trace hiding attack and CE trace forging attack, which could invalidate the forensic detector and fabricate two types of forensic errors, consequently. The CE trace hiding attack is implemented by integrating local random dithering into the form of pixel value mapping. The CE trace forging attack is proposed by modifying the grey level histogram of a target pixel region to fraudulent peak/gap artifacts. Then both attacks are added to enhanced images as a post processing activity. As a result the gaps get disappeared, but introduced sudden peaks. Then, feature selection methods in conjunction with fuzzy fusion approach is suggested to enhance the robustness of tamper detection methods. The threshold value for contrast detection is increased, so we can identify the contrast enhancement. The Artificial Neural Network (ANN) is used instead of SVM, it increases the robustness and accuracy of the digital images. The proposed methodology will be implemented using MATLAB and validated by comparing with the conventional techniques.
C1 [Rao, B. Subrahmanyeswara] MLR Inst Technol, Dept Elect & Commun Engn, Hyderabad, Andhra Pradesh, India.
C3 MLR Institute of Technology
RP Rao, BS (corresponding author), MLR Inst Technol, Dept Elect & Commun Engn, Hyderabad, Andhra Pradesh, India.
EM bsraosubrahmanyeswara@gmail.com
CR Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Bayram S, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2401138
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P842, DOI 10.1109/TIFS.2011.2170836
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Cao G, 2010, IEEE IMAGE PROC, P2097, DOI 10.1109/ICIP.2010.5652701
   Cao H, 2012, IEEE T INF FOREN SEC, V7, P992, DOI 10.1109/TIFS.2012.2185696
   Charpe J., 2015, 2015 GLOB C COMM TEC, P723
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   De Rosa A, 2015, IEEE SIGNAL PROC LET, V22, P1132, DOI 10.1109/LSP.2015.2389241
   Fan JY, 2013, IEEE T INF FOREN SEC, V8, P608, DOI 10.1109/TIFS.2013.2249064
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Mahdian B, 2010, SIGNAL PROCESS-IMAGE, V25, P389, DOI 10.1016/j.image.2010.05.003
   O'Brien JF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077345
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P247, DOI 10.1109/TIFS.2008.922456
   Popescu A., 2004, 6 INT WORKSH INF HID
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Ravi H, 2016, IEEE SIGNAL PROC LET, V23, P212, DOI 10.1109/LSP.2015.2509477
   Sornalatha STS, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1162, DOI 10.1109/ECS.2015.7124767
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
NR 23
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5241
EP 5261
DI 10.1007/s11042-017-4426-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800007
DA 2024-07-18
ER

PT J
AU Suhail, Z
   Denton, ERE
   Zwiggelaar, R
AF Suhail, Zobia
   Denton, Erika R. E.
   Zwiggelaar, Reyer
TI Tree-based modelling for the classification of mammographic benign and
   malignant micro-calcification clusters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Micro-calcifications; Benign; Malignant; Segmentation;
   Trees; Topology; Mammography
ID BREAST-CANCER
AB Computer Aided Detection (CAD) systems are being developed to assist radiologists in diagnosis. For breast cancer the emphasis is shifting from detection to classification of abnormalities. The presented work concentrates on the benign versus malignant classification of micro-calcification clusters, which are a specific type of mammographic abnormality associated with the early development of breast cancer. After segmentation (automatic or manual), tree-based representations were used to distinguish between benign and malignant clusters, which takes into account clinical criteria such as the number of micro-calcifications in the clusters and their distribution and is based on the topology of the trees and the connectivity of the micro-calcifications. The idea of using tree structure based on the distance of individual calcifications for the classification of benign and malignant micro-calcification clusters is novel and closely related to clinical perception. Tree structures used in this study are distinct from decision trees classifiers being used in many machine learning approaches. Initial evaluation on the Digital Database for Screening Mammography (DDSM) data shows promising results, with an accuracy equal to 91 %, which is comparable to state of the art CAD systems and is in line with clinical perception of the morphology and appearance of benign and malignant micro-calcification clusters.
C1 [Suhail, Zobia; Zwiggelaar, Reyer] Aberystwyth Univ, Aberystwyth, Dyfed, Wales.
   [Denton, Erika R. E.] Norfolk & Norwich Univ Hosp, Norwich, Norfolk, England.
C3 Aberystwyth University; Norfolk & Norwich University Hospitals NHS
   Foundation Trust; Norfolk & Norwich University Hospital
RP Zwiggelaar, R (corresponding author), Aberystwyth Univ, Aberystwyth, Dyfed, Wales.
EM zoa1@aber.ac.uk; erika.denton@nnuh.nhs.uk; rrz@aber.ac.uk
RI Zwiggelaar, Reyer/HGA-3089-2022
CR ALBAIN KS, 1990, J CLIN ONCOL, V8, P1563, DOI 10.1200/JCO.1990.8.9.1563
   ALBAIN KS, 1992, BREAST CANCER RES TR, V22, P273, DOI 10.1007/BF01840840
   [Anonymous], 2016, ARXIV161009462
   BAHL LR, 1989, IEEE T ACOUST SPEECH, V37, P1001, DOI 10.1109/29.32278
   Banerjee M, 2000, CANCER, V89, P404, DOI 10.1002/1097-0142(20000715)89:2<404::AID-CNCR28>3.0.CO;2-M
   Banerjee M, 2004, J CLIN ONCOL, V22, P2567, DOI 10.1200/JCO.2004.11.141
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chan HP, 1997, PHYS MED BIOL, V42, P549, DOI 10.1088/0031-9155/42/3/008
   Chandran P, 2013, INT J ELECT COMPUTER, V4, P180
   Chen Z., 2012, MED IMAGE UNDERSTAND, P37
   Chen ZL, 2015, IEEE T BIO-MED ENG, V62, P1203, DOI 10.1109/TBME.2014.2385102
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   DESILVA GL, 1994, PATTERN RECOGN, V27, P311, DOI 10.1016/0031-3203(94)90062-0
   Dheeba J., 2011, 2011 Proceedings of International Conference on Emerging Trends in Electrical and Computer Technology (ICETECT 2011), P686, DOI 10.1109/ICETECT.2011.5760205
   Dorsi CJ, 2003, BREAST IMAGING REPOR, P230
   Elmore G, 1998, NEW ENGL J MED, V338, P1089, DOI 10.1056/NEJM199804163381601
   Freund Y., 1990, Proceedings of the Third Annual Workshop on Computational Learning Theory, P202
   Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006
   Goodrich M.T., 2008, Data structures and algorithms in Java
   Guray M, 2006, ONCOLOGIST, V11, P435, DOI 10.1634/theoncologist.11-5-435
   Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212
   HOWARD J, 1987, CA-CANCER J CLIN, V37, P33, DOI 10.3322/canjclin.37.1.33
   Hussain N, 2011, SAFETY SCI, V49, P824, DOI 10.1016/j.ssci.2011.01.005
   Joshi M, 2015, INT J ADV RES COMPUT, V4
   Jotwani AC, 2009, MOL DIAGN THER, V13, P349, DOI 10.2165/11318220-000000000-00000
   Lazarus E, 2006, RADIOLOGY, V239, P385, DOI 10.1148/radiol.2392042127
   Liu Y.-S., 2015, Sci. World J, V2015, P2, DOI DOI 10.1016/J.LINDIF.2015.02.002
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Loh WY, 2011, WIRES DATA MIN KNOWL, V1, P14, DOI 10.1002/widm.8
   Marana AN, 1998, SAFETY SCI, V28, P165, DOI 10.1016/S0925-7535(97)00081-7
   Muttarak M, 2009, SINGAP MED J, V50, P907
   Najafi B, 2003, IEEE T BIO-MED ENG, V50, P711, DOI 10.1109/TBME.2003.812189
   Nalawade Yojana V, 2009, Indian J Radiol Imaging, V19, P282, DOI 10.4103/0971-3026.57208
   Oliver A, 2012, KNOWL-BASED SYST, V28, P68, DOI 10.1016/j.knosys.2011.11.021
   Schapire RE, 1998, ANN STAT, V26, P1651
   Shao YZ, 2011, J DIGIT IMAGING, V24, P764, DOI 10.1007/s10278-011-9381-2
   SHEN L, 1994, IEEE T MED IMAGING, V13, P263, DOI 10.1109/42.293919
   Siegel R, 2012, CA-CANCER J CLIN, V62, P10, DOI 10.3322/caac.20138
   SUCKLING J, 1994, INT CONGR SER, V1069, P375
   Suhail Z, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0094-8
   Walker DJ, 1997, PHYSIOL MEAS, V18, P49, DOI 10.1088/0967-3334/18/1/003
NR 46
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6135
EP 6148
DI 10.1007/s11042-017-4522-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800046
DA 2024-07-18
ER

PT J
AU Yeh, KH
   Lo, NW
   Wang, CK
AF Yeh, Kuo-Hui
   Lo, Nai-Wei
   Wang, Chun-Kai
TI A robust NFC-based personalized IPTV service system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPTV; Personalized services; Identification; NFC; HCE
ID IDENTIFICATION; AUTHENTICATION; CARD; FACE; TV
AB Internet Protocol Television (IPTV) is becoming a platform that changes the way we obtain information and entertainment, and offers interactive features and personalized services. Although IPTV service providers can perform TV viewer identification and authentication through a unique hardware identifier in the form of a set-top box (STB), it is based on STB-level identification which leads to the situation where all members of a subscriber family get the same level of access to services. This indicates that existing identification schemes are inconsistent with IPTV's main intent, namely, providing personalized services. Smartphones with NFC (Near Field Communication) capabilities have grown to become very popular over the years. In this study, we present a novel personalized IPTV service system in which NFC-based identification with HCE (Host Card Emulation) is adopted. The experiments and analyses show that the proposed system can meet the system requirements and provide great usability, deployability and service scalability for personalized IPTV services.
C1 [Yeh, Kuo-Hui] Natl Dong Hwa Univ, Dept Informat Management, Hualien 97401, Taiwan.
   [Lo, Nai-Wei; Wang, Chun-Kai] Natl Taiwan Univ Sci & Technol, Dept Informat Management, Taipei 10607, Taiwan.
C3 National Dong Hwa University; National Taiwan University of Science &
   Technology
RP Lo, NW (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Informat Management, Taipei 10607, Taiwan.
EM khyeh@mail.ndhu.edu.tw; naiweilo@yahoo.com.tw;
   m10209122@mail.ntust.edu.tw
RI Lo, Nai-Wei/K-8389-2012
FU Ministry of Science and Technology, Taiwan [MOST 105-2221-E-259-014-MY3,
   MOST 105-2221-E-011-070-MY3, MOST 105-2221-E-011-080-MY3, MOST
   105-2923-E-182-001-MY3, MOST 104-2218-E-001-002, MOST
   104-2923-E-011-005-MY3]; Taiwan Information Security Center (TWISC)
FX This work was supported by the Taiwan Information Security Center
   (TWISC) and the Ministry of Science and Technology, Taiwan, under the
   grants numbered MOST 105-2221-E-259-014-MY3, MOST
   105-2221-E-011-070-MY3, MOST 105-2221-E-011-080-MY3, MOST
   105-2923-E-182-001-MY3, MOST 104-2218-E-001-002 and MOST
   104-2923-E-011-005-MY3.
CR Alattar M, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, 2014 IEEE 6TH INTL SYMP ON CYBERSPACE SAFETY AND SECURITY, 2014 IEEE 11TH INTL CONF ON EMBEDDED SOFTWARE AND SYST (HPCC,CSS,ICESS), P506, DOI 10.1109/HPCC.2014.85
   Andersen Anders, 2013, Human Interface and the Management of Information. Information and Interaction for Health, Safety, Mobility and Complex Environments. 15th International Conference, HCI International 2013. Proceedings: LNCS 8017, P337, DOI 10.1007/978-3-642-39215-3_40
   [Anonymous], STATE ART MOBILE BIO
   [Anonymous], 2013, BTAS
   [Anonymous], IEEE ICCE
   [Anonymous], 2014 INT C WEB OP AC
   [Anonymous], P 8 INT WORKSH IM AN
   [Anonymous], INTECH INT J ADV ROB
   Bambini R, 2011, RECOMMENDER SYSTEMS HANDBOOK, P299, DOI 10.1007/978-0-387-85820-3_9
   Bisdikian C, 2001, IEEE COMMUN MAG, V39, P86, DOI 10.1109/35.968817
   Choi JH, 2007, I SYMP CONSUM ELECTR, P249
   Foina AG, 2010, IEEE IFIP NETW OPER, P825, DOI 10.1109/NOMS.2010.5488364
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Groupe Speciale Mobile Association, GSMA MOB EC 2015
   Hwang MC, 2007, IEEE T CONSUM ELECTR, V53, P218, DOI 10.1109/TCE.2007.339528
   Jabbar H, 2008, IEEE T CONSUM ELECTR, V54, P105, DOI 10.1109/TCE.2008.4470031
   Jana R, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1055
   Jiang TP, 2004, IEEE T CONSUM ELECTR, V50, P882, DOI 10.1109/TCE.2004.1341695
   Kim SC, 2011, MULTIMED TOOLS APPL, V65, P283
   Kuei-Hong Lin, 2012, 2012 International Symposium on Communications and Information Technologies (ISCIT), P626, DOI 10.1109/ISCIT.2012.6380976
   Lee H, 2014, IEEE INT CONF SERV, P271, DOI 10.1109/SOCA.2014.16
   Liu Z., 2009, 6 IEEE CONS COMM NET, P1
   Lyu J, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P305, DOI 10.1109/ICACT.2007.358361
   MORRIS R, 1979, COMMUN ACM, V22, P594, DOI 10.1145/359168.359172
   Munch-Ellingsen A, 2015, 1 C MOB SEC SERV GAI, P1
   Panigrahy S K., 2011, Proceedings of the 2011 International Conference on Communication, Computing Security, P628
   Park S, 2008, ICN 2008: SEVENTH INTERNATIONAL CONFERENCE ON NETWORKING, PROCEEDINGS, P296, DOI 10.1109/ICN.2008.8
   Park S, 2009, IEEE INTERNET COMPUT, V13, P23, DOI 10.1109/MIC.2009.65
   Park YK, 2008, ICHIT 2008: INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, PROCEEDINGS, P618, DOI 10.1109/ICHIT.2008.275
   Reveilhac M, 2009, FIRST INTERNATIONAL WORKSHOP ON NEAR FIELD COMMUNICATION, PROCEEDINGS, P75, DOI 10.1109/NFC.2009.14
   Urien P, 2014, IEEE CONF WIREL MOB, P213, DOI 10.1109/WiMOB.2014.6962173
   van Brandenburg R., 2009, THESIS
   Wang HL, 2010, IEEE INT CON MULTI, P1333, DOI 10.1109/ICME.2010.5583705
   Zeadally S, 2011, IEEE SYST J, V5, P518, DOI 10.1109/JSYST.2011.2165601
NR 34
TC 5
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5129
EP 5148
DI 10.1007/s11042-017-4380-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800002
DA 2024-07-18
ER

PT J
AU Fang, C
   Zhang, HW
   Wang, JD
   Wang, N
AF Fang, Chen
   Zhang, Hengwei
   Wang, Jindong
   Wang, Na
TI Diversified recommendation method combining topic model and random walk
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative filtering; Data sparsity; Topic model; Random walk;
   Recommendation diversity
ID SYSTEMS
AB As one of the most widely used algorithms in recommendation field, collaborative filtering (CF) predicts the unknown rating of items based on similar neighbors. Although many CF-based recommendation methods have been proposed, there still be room for improvement. Firstly, the data sparsity problem still remains a big challenge for CF algorithms to find similar neighbors. Secondly, there are many redundant similar items in the recommendation list generated by traditional CF algorithms, which cannot meet the user wide interest. Therefore, we propose a diversified recommendation method combining topic model and random walk. A weighted random walk model is presented to find all direct and indirect similar neighbors on the sparse data, improving the accuracy of rating prediction. By taking both users' behavior data and items' lags into account, we give a diversity measurement method based on the topic distribution of items discovered by Linked-LDA model. Furthermore, a diversified ranking algorithm is developed to balance the accuracy and diversity of recommendation results. We compare our method with six other recommendation methods on a real-world dataset. Experimental results show that our method outperforms the other methods and achieves the best personalized recommendation effect.
C1 [Fang, Chen; Zhang, Hengwei; Wang, Jindong; Wang, Na] Zhengzhou Informat Sci & Technol Inst, State Key Lab Math Engn & Adv Comp, Zhengzhou, Henan, Peoples R China.
C3 PLA Information Engineering University
RP Zhang, HW (corresponding author), Zhengzhou Informat Sci & Technol Inst, State Key Lab Math Engn & Adv Comp, Zhengzhou, Henan, Peoples R China.
EM 13083710760@163.com
RI Zhang, Hengwei/KBD-3945-2024
OI Zhang, Hengwei/0000-0002-1649-7336; WANG, Jin dong/0000-0002-7641-9014;
   Fang, Chen/0000-0002-0326-8737
FU National Natural Science Foundation of China [61303074, 61309013];
   Programs for Science and Technology Development of Henan province
   [12210231003, 13210231002]
FX The authors appreciate the reviewers for their valuable comments which
   have greatly improved the quality of this paper. This work was supported
   in part by the National Natural Science Foundation of China [61303074,
   61309013] and the Programs for Science and Technology Development of
   Henan province [12210231003, 13210231002].
CR [Anonymous], 2006, IEEE Trans Automat Contr, DOI [DOI 10.1109/TAC.2006.884922, 10.1109/tac.2006.884922]
   Benyu Zhang, 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P504, DOI 10.1145/1076034.1076120
   Chen MH, 2015, ADV ENG INFORM, V29, P830, DOI 10.1016/j.aei.2015.04.005
   Erosheva E, 2004, P NATL ACAD SCI USA, V101, P5220, DOI 10.1073/pnas.0307760101
   [郭弘毅 Guo Hongyi], 2016, [计算机研究与发展, Journal of Computer Research and Development], V53, P1664
   Huang Lu, 2017, Journal of Software, V28, P708, DOI 10.13328/j.cnki.jos.005163
   Huang SS, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P343, DOI 10.1145/2766462.2767693
   [贾冬艳 Jia Dongyan], 2013, [计算机研究与发展, Journal of Computer Research and Development], V50, P1076
   Kucuktunc Onur., 2013, Proceedings of the 22nd international conference on World Wide Web, P715
   Langville A.N., 2008, MATH INTELL, V30, P68, DOI DOI 10.1007/BF02985759
   Lee S., 2011, PROC RECSYS 11, P93, DOI [DOI 10.1145/2043932.2043952, 10.1145/2043932.2043952]
   [李聪 Li Cong], 2008, [计算机研究与发展, Journal of Computer Research and Development], V45, P1532
   Li RH, 2013, INT C DAT MIN, P1152
   Li Ruirui., 2012, P 21 ACM INT C INFOR, P16
   Liu JX, 2016, IEEE T SERV COMPUT, V9, P686, DOI 10.1109/TSC.2015.2433251
   Liu Q, 2012, IEEE T SYST MAN CY B, V42, P218, DOI 10.1109/TSMCB.2011.2163711
   Liu XM, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS), P185, DOI 10.1109/ICWS.2015.34
   Mei Q., 2010, KDD, P1009
   Pirasteh P, 2015, KNOWL-BASED SYST, V83, P51, DOI 10.1016/j.knosys.2015.03.006
   Qin L., 2014, P SIAM INT C DAT MIN, P461, DOI 10.1137/1.9781611973440.53
   Shah RR, 2016, IEEE INT SYM MULTIM, P486, DOI [10.1109/ISM.2016.108, 10.1109/ISM.2016.0109]
   Shi M, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS), P444, DOI 10.1109/ICWS.2016.64
   Shi Y, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P175, DOI 10.1145/2348283.2348310
   Tang J., 2008, SIGKDD, P990, DOI DOI 10.1145/1401890.1402008
   Tong Hanghang., 2011, Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, P1028
   Wang XX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P627, DOI 10.1145/2647868.2654940
   Wei J, 2017, EXPERT SYST APPL, V69, P29, DOI 10.1016/j.eswa.2016.09.040
   Wu L., 2012, Proceedings of the 21st ACM International Conference on Information and Knowledge Management', CIKM'12, P1854
   Xiao YY, 2015, CHINA COMMUN, V12, P53, DOI 10.1109/CC.2015.7385528
   Yu C, 2009, PROC INT CONF DATA, P1299, DOI 10.1109/ICDE.2009.225
   Zhang X, 2015, KNOWL-BASED SYST, V73, P161, DOI 10.1016/j.knosys.2014.09.015
   Zhang Z, 2013, ACM TRANS MANAG INF, V4, DOI 10.1145/2490860
   Ziegler Cai-Nicolas, 2005, P 14 INT C WORLD WID, P22, DOI DOI 10.1145/1060745.1060754
NR 33
TC 4
Z9 4
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4355
EP 4378
DI 10.1007/s11042-017-5504-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500018
DA 2024-07-18
ER

PT J
AU Hua, WX
   Mu, DJ
   Guo, DW
   Liu, H
AF Hua, Weixin
   Mu, Dejun
   Guo, Dawei
   Liu, Hang
TI Visual tracking based on stacked Denoising Autoencoder network with
   genetic algorithm optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Stacked denoising autoencoder; Sparsity dictionary
   encode; Genetic algorithm
ID OBJECT TRACKING; ONLINE; REPRESENTATIONS
AB Visual object tracking in dynamic environments with severe appearance variations is a significant problem in the computer vision field. This paper proposes a novel visual tracking algorithm that exploits the multiple level features learning ability of SDAE. There are two training stages for the SDAE network: Layer-wise pre-training and fine-tuning. In the pre-training stage, a two-layer sparse-coded method is used to represent the input image, then a multi-level image feature descriptor is obtained. In the fine-tuning stage, the connection weights and bias terms for back propagation are gathered via genetic algorithm. A logistic classification layer is added at the top of the encoder network to enable tracking within the well-established particle filter network. Experimental results confirm, both qualitatively and quantitatively, that the proposed method performs well in comparison against eight other state-of-the-art methods.
C1 [Hua, Weixin; Mu, Dejun; Guo, Dawei; Liu, Hang] Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.
   [Hua, Weixin] China Mobile Ltd, Co Shaanxi, Xian 710074, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University; China Mobile
RP Guo, DW (corresponding author), Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.
EM guodaw@nwpu.edu.cn
FU National Natural Science Foundation of China [61672433]
FX This work is supported by the National Natural Science Foundation of
   China (61672433). The authors would like to thank the valuable comments
   from the reviewers and editors.
CR [Anonymous], 2001, IMPROVEMENT STRATEGI, DOI DOI 10.1007/978-1-4757-3437-9_7
   [Anonymous], 2014, PROC IEEE C COMPUTER, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   [Anonymous], 2013, 131268852013 ARXIV
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Baldi P., 2012, P INT C UNS TRANSF L, P37
   Bengio S., 2009, Advances in Neural Information Processing Systems, V22, P82
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Grabner H., 2006, BMVC, P47
   Hinton GE, 2012, PRACTICAL GUIDE TRAI
   Jordan A, 2001, ADV NEURAL INFORM PR, P169
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li MQ, 2002, FUNDAMENTAL THEORY A
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Ross D, 2004, LECT NOTES COMPUT SC, V3022, P470
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Von Lehmen A., 1988, IEEE International Conference on Neural Networks (IEEE Cat. No.88CH2632-8), P335, DOI 10.1109/ICNN.1988.23865
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu K, 2011, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2011.5995732
   Zhang KH, 2013, IEEE T IMAGE PROCESS, V22, P4664, DOI 10.1109/TIP.2013.2277800
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhou XZ, 2014, IEEE IMAGE PROC, P843, DOI 10.1109/ICIP.2014.7025169
NR 32
TC 2
Z9 4
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4253
EP 4269
DI 10.1007/s11042-017-4702-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500011
DA 2024-07-18
ER

PT J
AU Juneja, A
   Rana, B
   Agrawal, RK
AF Juneja, Akanksha
   Rana, Bharti
   Agrawal, R. K.
TI fMRI based computer aided diagnosis of schizophrenia using fuzzy kernel
   feature extraction and hybrid feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer aided diagnosis; fMRI; Fuzzy kernel principal component
   analysis; Hybrid forward feature selection; Support vector machine;
   Schizophrenia
ID INDEPENDENT COMPONENT ANALYSIS; SUPPORT VECTOR MACHINE; CLASSIFICATION;
   NETWORKS; DISEASE; IMAGES
AB Functional magnetic resonance imaging (fMRI) is a useful technique for capturing deformities in brain activity patterns of several disorders. Schizophrenia is one such serious psychiatric disorder that, in absence of any standard diagnostic tests, is detected from behavioural symptoms observed externally. Thus, fMRI can be used for building an effective decision model for computer aided diagnosis of schizophrenia. However, fMRI data has huge dimension compared with the number of subjects; therefore it is essential to reduce the data dimension to avoid poor generalisation performance of the decision model. In the present work, we propose a three-phase dimension reduction that comprises of segmentation of voxels of 3-D spatial maps (independent component score-maps or beta-maps) into anatomical brain regions; feature extraction from each region using a novel fuzzy kernel principal component analysis; and a novel hybrid (filter-cum-wrapper) feature selection for determining a reduced subset of discriminative features. These features are used as input to support vector machine classifier for learning a decision model. The method is carried out within leave-one-out cross-validation. Classification accuracy, sensitivity, and specificity are utilised to estimate the performance on two different balanced datasets D1 and D2 (respectively acquired on 1.5 T and 3 T scanners). Both the datasets contain fMRI data of age-matched healthy subjects and schizophrenia patients for auditory oddball task, obtained from FBIRN multisite dataset. The proposed method attains best classification accuracy of 95.6% and 96.0% for D1 and D2 respectively. The proposed method shows enhanced performance over the state-of-the-art methods. Further, the discriminative brain regions identified are in accordance with the findings in related literature and may be used as potential biomarkers.
C1 [Juneja, Akanksha; Rana, Bharti; Agrawal, R. K.] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
C3 Jawaharlal Nehru University, New Delhi
RP Juneja, A (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
EM akankshajuneja.jnu@gmail.com; bhartirana.jnu@gmail.com; rkajnu@gmail.com
RI -, BHARTI/IQR-9133-2023; AGRAWAL, RAMESH/AAR-8896-2020
OI Agrawal, Ramesh kumar/0000-0003-3122-5096
FU National Centre for Research Resources at the National Institutes of
   Health, U.S.A.; University Grants Commission (INDIA); Department of
   Science and Technology (INDIA);  [U24-RR021992]
FX Data used for this study were downloaded from the publicly available
   Function BIRN Data Repository
   (http://fbirnbdr.birncommunity.org:8080/BDR/), supported by grants to
   the Function BIRN (U24-RR021992). Testbed funded by the National Centre
   for Research Resources at the National Institutes of Health, U.S.A.
   First author thanks University Grants Commission (INDIA) and second
   author thanks Department of Science and Technology (INDIA) for research
   fellowship. The authors are grateful to the reviewers for their valuable
   comments which helped in improving the overall quality of the
   manuscript.
CR Ashburner J, 1999, HUM BRAIN MAPP, V7, P254, DOI 10.1002/(SICI)1097-0193(1999)7:4<254::AID-HBM4>3.0.CO;2-G
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   BELLMAN R, 1966, SCIENCE, V153, P34, DOI 10.1126/science.153.3731.34
   Calhoun VD, 2001, HUM BRAIN MAPP, V14, P140, DOI 10.1002/hbm.1048
   Calhoun VD, 2006, HUM BRAIN MAPP, V27, P598, DOI 10.1002/hbm.20204
   Camps-Valls G, 2004, NEUROCOMPUTING, V62, P501, DOI 10.1016/j.neucom.2004.07.004
   Carter CS, 2001, AM J PSYCHIAT, V158, P1423, DOI 10.1176/appi.ajp.158.9.1423
   Castro E, 2014, NEUROIMAGE, V87, P1, DOI 10.1016/j.neuroimage.2013.10.065
   Castro E, 2011, NEUROIMAGE, V58, P526, DOI 10.1016/j.neuroimage.2011.06.044
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen Y, 2008, J MATH IMAGING VIS, V30, P133, DOI 10.1007/s10851-007-0042-5
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Demirci O, 2008, NEUROIMAGE, V39, P1774, DOI 10.1016/j.neuroimage.2007.10.012
   Du W, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00145
   Ford J, 2003, MED IMAGE COMPUTING
   Friston KJ, 2000, NEUROIMAGE, V12, P466, DOI 10.1006/nimg.2000.0630
   Friston KJ., 1994, HUMAN BRAIN MAPPING, V2, P189, DOI [10.1002/hbm.460020402, DOI 10.1002/HBM.460020402]
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Juneja A, 2014, 9 IND C COMP VIS GRA
   Juneja A, 2016, BIOMED SIGNAL PROCES, V27, P122, DOI 10.1016/j.bspc.2016.02.009
   Kim D, 2008, NEUROIMAGE, V42, P1560, DOI 10.1016/j.neuroimage.2008.05.065
   Kim DI, 2009, HUM BRAIN MAPP, V30, P3795, DOI 10.1002/hbm.20807
   Kim DI, 2009, SCHIZOPHRENIA BULL, V35, P67, DOI 10.1093/schbul/sbn133
   Kittler J., 1986, Handbook of Pattern Recognition and Image Processing, P59, DOI DOI 10.1007/978-1-4684-5188-7_8
   Li YO, 2007, HUM BRAIN MAPP, V28, P1251, DOI 10.1002/hbm.20359
   Maldjian JA, 2003, NEUROIMAGE, V19, P1233, DOI 10.1016/S1053-8119(03)00169-1
   Mundra PA, 2010, IEEE T NANOBIOSCI, V9, P31, DOI 10.1109/TNB.2009.2035284
   Mwangi B, 2014, NEUROINFORMATICS, V12, P229, DOI 10.1007/s12021-013-9204-3
   Ogawa S, 1990, P NATL ACAD SCI
   Orrù G, 2012, NEUROSCI BIOBEHAV R, V36, P1140, DOI 10.1016/j.neubiorev.2012.01.004
   Qu XB, 2015, ANGEW CHEM INT EDIT, V54, P852, DOI 10.1002/anie.201409291
   Qu XB, 2014, MED IMAGE ANAL, V18, P843, DOI 10.1016/j.media.2013.09.007
   Saggar M, 2014, NEUROIMAGE, V84, P648, DOI 10.1016/j.neuroimage.2013.09.046
   Scholkopf B., 1997, Artificial Neural Networks - ICANN '97. 7th International Conference Proceedings, P583, DOI 10.1007/BFb0020217
   Soria-Olivas E, 2003, IEEE T NEURAL NETWOR, V14, P1576, DOI 10.1109/TNN.2003.820444
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Ungar L, 2010, PSYCHIAT RES-NEUROIM, V181, P24, DOI 10.1016/j.pscychresns.2009.07.005
   Wang SH, 2016, PEERJ, V4, DOI 10.7717/peerj.2207
   Watanuki T, 2016, SCHIZOPHR RES, V170, P109, DOI 10.1016/j.schres.2015.11.012
   Wellcome-Trust-Centre-for-Neuroimaging, 2009, SPM8 STAT PAR MAPP
   Xie ZX, 2006, ADV NEURAL NETWORKS
   Yoon JH, 2012, SCHIZOPHR RES, V135, P28, DOI 10.1016/j.schres.2012.01.001
   Zhang YD, 2015, BIOMED SIGNAL PROCES, V21, P58, DOI 10.1016/j.bspc.2015.05.014
   Zhang YD, 2015, ENTROPY-SWITZ, V17, P1795, DOI 10.3390/e17041795
NR 46
TC 11
Z9 11
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3963
EP 3989
DI 10.1007/s11042-017-4404-8
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600059
DA 2024-07-18
ER

PT J
AU Liu, AA
   Shi, Y
   Nie, WZ
   Su, YT
AF Liu, An-An
   Shi, Yang
   Nie, Wei-Zhi
   Su, Yu-Ting
TI View-based 3D model retrieval via supervised multi-view feature learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; Multi-view; Feature learning; Feature dimensionality
   reduction; SVD; Zernike moments
ID OBJECT RETRIEVAL; SEARCH ENGINE; RECOGNITION
AB With the development of the processing technologies of 3D model and the increasing of 3D model in different application flieds, 3D model retrieval is attracting more and more people's attention. In order to handle this problem, most of approaches focus on the feature extraction form different virtual view. It is hard to guarantee the robustness and also ignore the correlation between both views. Thus, we propose an effective view-based 3D model retrieval method via supervised multi-view feature learning (SMFL). First, the subspace dimension of viusal feature is generated through Singular Value Decomposition (SVD) algorithm. This step is used to select main information from multi-view in order to reduce the final amount of calculation; Secondly, we consider the relationship of multi-view from same class and the correlation between two different classes to make the feature mapping in order to reduce the different of views from the same class and increase the different of views from the difference class; Finally, the projection mapping corresponding to the inner product of each 3D model helps to calculate the similarities between two different 3D models. The extensive experiments are conducted on popular ETH, NTU, MV-RED and PSB 3D model datasets with Zernike moments. The comparative results or The experimental results with existing 3D model retrieval methods show the superiority of the proposed method.
C1 [Liu, An-An; Nie, Wei-Zhi; Su, Yu-Ting] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
   [Shi, Yang] Tianjin Univ, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University
RP Nie, WZ (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
EM weizhinie@tju.edu.cn
RI Nie, Weizhi/ABF-5316-2021
OI nie, weizhi/0000-0002-0578-8138
CR [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 2007, ARXIV07092205
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396
   Brennecke A., 2004, SIMULATION VISUALIZA, P299
   Bufler FM, 2008, PROC EUR S-STATE DEV, P166, DOI 10.1109/ESSDERC.2008.4681725
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Conrad M, 2014, EUR CONF POW ELECTR
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110
   Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954
   Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027
   Guétat G, 2006, IEEE T INF TECHNOL B, V10, P362, DOI 10.1109/TITB.2005.863875
   Harandi M. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2705, DOI 10.1109/CVPR.2011.5995564
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Hu MC, 2015, IEEE T CYBERNETICS, V45, P742, DOI 10.1109/TCYB.2014.2335540
   Huang ZW, 2015, PROC CVPR IEEE, P140, DOI 10.1109/CVPR.2015.7298609
   Ip CY, 2002, P 7 ACM S SOL MOD AP, P273, DOI 10.1145/566282.566322
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kim T., 2011, 2011 7th International Conference on Networked Computing, P161
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leibe B, 2003, PROC CVPR IEEE, P409
   Li XX, 2017, MULTIMED TOOLS APPL, V76, P20111, DOI 10.1007/s11042-016-4250-0
   Lian ZH, 2013, PATTERN RECOGN, V46, P449, DOI 10.1016/j.patcog.2012.07.014
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu A, 2015, INFORM SCIENCES, V320, P429, DOI 10.1016/j.ins.2015.04.042
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu K, 2014, IEEE T IMAGE PROCESS, V23, P4553, DOI 10.1109/TIP.2014.2343460
   Mottaghi R., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P561, DOI 10.1109/ICCVW.2011.6130293
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Nie WZ, 2016, NEUROCOMPUTING, V215, P63, DOI 10.1016/j.neucom.2015.06.118
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Papoiu ADP, 2014, J NEUROPHYSIOL, V112, P1729, DOI 10.1152/jn.00827.2013
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Regli WC, 2000, COMPUT AIDED DESIGN, V32, P119, DOI 10.1016/S0010-4485(99)00095-0
   Rodolà E, 2015, PATTERN RECOGN LETT, V59, P41, DOI 10.1016/j.patrec.2015.03.009
   Rodolà E, 2014, PROC CVPR IEEE, P4177, DOI 10.1109/CVPR.2014.532
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   SHINAGAWA Y, 1991, IEEE COMPUT GRAPH, V11, P44, DOI 10.1109/38.103393
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Vavilov D., 2010, 2010 6th Central and Eastern European Software Engineering Conference in Russia (CEE-SECR 2010), P175, DOI 10.1109/CEE-SECR.2010.5783171
   Vogel J, 2006, PATTERN RECOGN, V39, P897, DOI 10.1016/j.patcog.2005.10.024
   Zhang S., 2012, Phys. Rev. Lett, P1
   Zhu L., 2016, IJCAI, P3959
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
   Zhu L, 2015, IEEE T MULTIMEDIA, V17, P981, DOI 10.1109/TMM.2015.2431496
NR 61
TC 3
Z9 5
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3229
EP 3243
DI 10.1007/s11042-017-5076-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600017
DA 2024-07-18
ER

PT J
AU Manogaran, G
   Varatharajan, R
   Priyan, MK
AF Manogaran, Gunasekaran
   Varatharajan, R.
   Priyan, M. K.
TI RETRACTED: Hybrid Recommendation System for Heart Disease Diagnosis
   based on Multiple Kernel Learning with Adaptive Neuro-Fuzzy Inference
   System (Retracted article. See vol. 82, pg. 3181, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Deep Learning; Multiple Kernel Learning; Adaptive Neuro-Fuzzy Inference
   System; Machine Learning; Heart Disease Diagnosis; Big Data
ID DATA-PROCESSING FRAMEWORK; BIG DATA-SECURITY; EXPERT-SYSTEM;
   CLIMATE-CHANGE; HEALTH-CARE; MODEL; CLASSIFICATION; PREDICTION; FUSION
AB Multiple Kernel Learning with Adaptive Neuro-Fuzzy Inference System (MKL with ANFIS) based deep learning method is proposed in this paper for heart disease diagnosis. The proposed MKL with ANFIS based deep learning method follows two-fold approach. MKL method is used to divide parameters between heart disease patients and normal individuals. The result obtained from the MKL method is given to the ANFIS classifier to classify the heart disease and healthy patients. Sensitivity, Specificity and Mean Square Error (MSE) are calculated to evaluate the proposed MKL with ANFIS method. The proposed MKL with ANFIS is also compared with various existing deep learning methods such as Least Square with Support Vector Machine (LS with SVM), General Discriminant Analysis and Least Square Support Vector Machine (GDA with LS-SVM), Principal Component Analysis with Adaptive Neuro-Fuzzy Inference System (PCA with ANFIS) and Latent Dirichlet Allocation with Adaptive Neuro-Fuzzy Inference System (LDA with ANFIS). The results from the proposed MKL with ANFIS method has produced high sensitivity (98%), high specificity (99%) and less Mean Square Error (0.01) for the for the KEGG Metabolic Reaction Network dataset.
C1 [Manogaran, Gunasekaran; Priyan, M. K.] VIT Univ, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
   [Varatharajan, R.] Sri Ramanujar Engn Coll, Madras, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Priyan, MK (corresponding author), VIT Univ, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
EM priyanit085@gmail.com
RI MALARVIZHI KUMAR, PRIYAN/U-3908-2018; KUMAR, PRIYAN
   MALARVIZHI/GYV-1373-2022; Manogaran, Gunasekaran/K-7621-2017
OI MALARVIZHI KUMAR, PRIYAN/0000-0001-6149-2705; Manogaran,
   Gunasekaran/0000-0003-4083-6163
CR Alamelumangai N, 2010, INT J COMPUT APPL, V7
   Alfarhan KA, 2017, J BIOMIM BIOMATER BI, V30, P1, DOI 10.4028/www.scientific.net/JBBBE.30.1
   Ananda K., 2011, INT J ADV COMPUTER S, P132, DOI DOI 10.14569/SPECIALISSUE.2011.010321
   [Anonymous], COMPUT ELECT ENG
   [Anonymous], COMPUT ELECT ENG
   [Anonymous], 2012, COMPUTER ENG INTELLI
   [Anonymous], 2012, INT J FUZZY LOGIC SY
   [Anonymous], COMPUT ELECT ENG
   Austin PC, 2013, J CLIN EPIDEMIOL, V66, P398, DOI 10.1016/j.jclinepi.2012.11.008
   Babazadeh Khameneh Nahid, 2012, Stud Health Technol Inform, V173, P30
   Cao JT, 2016, MULTIMED TOOLS APPL, V75, P11909, DOI 10.1007/s11042-015-2628-z
   Çomak E, 2007, COMPUT BIOL MED, V37, P21, DOI 10.1016/j.compbiomed.2005.11.002
   Dou WB, 2007, IMAGE VISION COMPUT, V25, P164, DOI 10.1016/j.imavis.2006.01.025
   Ephzibah EP, 2012, INT J SOFT COMPUT AR, V1
   Gijzen H, 2013, NATURE, V502, P38, DOI 10.1038/502038d
   Güler I, 2005, J NEUROSCI METH, V148, P113, DOI 10.1016/j.jneumeth.2005.04.013
   Hampton SE, 2013, FRONT ECOL ENVIRON, V11, P156, DOI 10.1890/120103
   Jang SM, 2015, GLOBAL ENVIRON CHANG, V32, P11, DOI 10.1016/j.gloenvcha.2015.02.010
   Jiang H, 2011, EXPERT SYST APPL, V38, P8515, DOI 10.1016/j.eswa.2011.01.052
   Kumar PM, 2019, CLUSTER COMPUT, V22, pS7733, DOI 10.1007/s10586-017-1323-4
   Lopez D, 2016, INT J INFECT DIS, V45, P23, DOI 10.1016/j.ijid.2016.02.084
   Lopez D, 2017, BIOMED RES, V28, P1
   Lopez D, 2016, HUMAN ELEMENT BIG DA
   Lopez D, 2017, HDB STAT, V37, P301, DOI DOI 10.1590/S0034-76122011000200003
   Lopez D, 2015, ADV INTELL SYST, V415, P195, DOI 10.1007/978-3-319-27212-2_16
   Lopez Daphne, 2014, Proc IEEE Int Conf Big Data, V2014, P19, DOI 10.1109/BigData.2014.7004422
   Luo J, 2016, BIOMED INFORM INSIGH, V8, P1, DOI 10.4137/BII.S31559
   Manogaran G., 2017, Big Data Analytics in Healthcare Internet of Things. Innovative Healthcare Systems for the 21st Century, P263, DOI DOI 10.1007/978-3-319-55774-8_10
   Manogaran G, 2018, FUTURE GENER COMP SY, V82, P375, DOI 10.1016/j.future.2017.10.045
   Manogaran G, 2018, WIRELESS PERS COMMUN, V102, P2099, DOI 10.1007/s11277-017-5044-z
   Manogaran G, 2018, CLUSTER COMPUT, V21, P189, DOI 10.1007/s10586-017-0982-5
   Manogaran G, 2017, SPRINGER SER ADV MAN, P103, DOI 10.1007/978-3-319-50660-9_5
   Manogaran G, 2017, INT J BIOMED ENG TEC, V25, P182, DOI 10.1504/IJBET.2017.087722
   Manogaran G, 2017, STUD BIG DATA, V23, P133, DOI 10.1007/978-3-319-49736-5_7
   Manogaran G, 2017, INT J AMBIENT COMPUT, V8, P88, DOI 10.4018/IJACI.2017040106
   Manogaran G, 2016, PROCEDIA COMPUT SCI, V87, P128, DOI 10.1016/j.procs.2016.05.138
   Manogaran Thota., 2018, HCI CHALLENGES PRIVA, P1, DOI DOI 10.4018/978-1-5225-2863-0.CH001
   Mastorocostas PA, 2005, IEEE IJCNN, P3023
   Mastorocostas PA, 2004, IEEE SYS MAN CYBERN, P2231
   Neagoe Victor -Emil, 2003, AMIA Annu Symp Proc, P494
   Obi J.C., 2011, INT J SOFT COMPUTING, V2, P25, DOI DOI 10.5121/IJSC.2011.2203
   Obi JC, 2011, GLOBAL J COMPUT SCI, V11
   Ovreiu M., 2010, Proceedings of the 12th Annual Conference on Genetic and Evolutionary Computation, P1235, DOI 10.1145/1830483.1830706
   Oweis R. J., 2005, Journal of Electrical Engineering, V56, P146
   Polat K, 2007, DIGIT SIGNAL PROCESS, V17, P702, DOI 10.1016/j.dsp.2006.09.005
   Priyan M. K., 2018, Cluster Computing, V21, P213, DOI 10.1007/s10586-017-0998-x
   Saeedi J, 2012, APPL SOFT COMPUT, V12, P1041, DOI 10.1016/j.asoc.2011.11.020
   Sengur A, 2008, EXPERT SYST APPL, V35, P214, DOI 10.1016/j.eswa.2007.06.012
   Son SY, 2015, MULTIMED TOOLS APPL, V74, P2321, DOI 10.1007/s11042-014-1943-0
   Stavrakoudis D, 2007, IEEE INT CONF FUZZY, P49
   Subasi A, 2006, EXPERT SYST APPL, V31, P320, DOI 10.1016/j.eswa.2005.09.027
   Thota C., 2018, Exploring the convergence of big data and the internet of things, P141
   Thota Chandu., 2017, Cybersecurity breaches and issues surrounding online threat protection, P288
   Tripoliti EE, 2017, COMPUT STRUCT BIOTEC, V15, P26, DOI 10.1016/j.csbj.2016.11.001
   Turkoglu I, 2002, EXPERT SYST APPL, V23, P229, DOI 10.1016/S0957-4174(02)00042-8
   Übeyli ED, 2009, COMPUT METH PROG BIO, V93, P313, DOI 10.1016/j.cmpb.2008.10.012
   Uguz H, 2007, PATTERN RECOGN LETT
   Varatharajan R., 2018, Cluster Computing, V21, P681, DOI 10.1007/s10586-017-0977-2
   Varatharajan R, 2018, MULTIMED TOOLS APPL, V77, P17573, DOI [10.1007/s11042-017-4768-9, 10.1007/s11042-017-5318-1]
   Vayena E, 2015, PLOS COMPUT BIOL, V11, DOI 10.1371/journal.pcbi.1003904
   Wang RM, 2014, MULTIMED TOOLS APPL, V71, P395, DOI 10.1007/s11042-013-1519-4
   Wen J, 2016, IEEE T SIGNAL PROCES
   Wen JM, 2017, IEEE T INFORM THEORY, V63, P631, DOI 10.1109/TIT.2016.2627082
   Xiao YL, 2016, MULTIMED TOOLS APPL, V75, P13041, DOI 10.1007/s11042-015-2569-6
   Yu JQ, 2013, OPTIK, V124, P3103, DOI 10.1016/j.ijleo.2012.09.033
NR 65
TC 141
Z9 147
U1 1
U2 75
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4379
EP 4399
DI 10.1007/s11042-017-5515-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500019
DA 2024-07-18
ER

PT J
AU Xiao, HX
   Ren, WY
   Wang, W
   Liu, Y
   Zhang, MJ
AF Xiao, Huaxin
   Ren, Weiya
   Wang, Wei
   Liu, Yu
   Zhang, Maojun
TI Salient object detection via robust dictionary representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Low-rank representation; Sparse
   representation; Matrix decomposition
ID LOW-RANK; REGION DETECTION
AB The theory of sparse and low-rank representation has worked competitive performance in the field of salient object detection. Generally, the salient object is represented as sparse error while the non-salient region is constrained by the property of low-rank. However, sparsity ignores the global structure which may break up the low-rank property. Besides, the outliers always lead to a poor representation. To handle these problems, this paper proposes a robust representation based on a discriminative dictionary which consists of non-salient and salient templates. Three weight measures are introduced and combined to select the proper templates. The coefficients on dictionary are restricted by a"" (2,1)-norm. Correspondingly, Frobenius norm instead of a"" (1)-norm is exploited to constrain the distribution of representation error. We compare the proposed algorithm against 17 state-of-the-art methods on 4 popular datasets by 6 evaluation metrics and demonstrate the competitive performance in terms of qualitative and quantitative results.
C1 [Xiao, Huaxin; Liu, Yu; Zhang, Maojun] Natl Univ Def Technol, Dept Syst Engn, Changsha, Hunan, Peoples R China.
   [Ren, Weiya] Chinese Armed Police Force, Dept Management Sci & Engn, Officers Coll, Chengdu, Sichuan, Peoples R China.
   [Wang, Wei] Univ Trento, Dept Informat Engn & Comp Sci, Trento, Italy.
C3 National University of Defense Technology - China; University of Trento
RP Xiao, HX (corresponding author), Natl Univ Def Technol, Dept Syst Engn, Changsha, Hunan, Peoples R China.
EM xiaohuaxin@nudt.edu.cn; weiyren.phd@gmail.com; wei.wang@unitn.it;
   jasonyuliu@nudt.edu.cn; mjzhang@nudt.edu.cn
RI Wang, Wei/AAK-5521-2021
OI Wang, Wei/0000-0002-5477-1017
FU National Natural Science Foundation of China [61403403, 71673293]; China
   Postdoctoral Science Foundation [2015M52707]
FX This research was partially supported by National Natural Science
   Foundation of China under project No. 61403403, No. 71673293 and China
   Postdoctoral Science Foundation under project No. 2015M52707.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2008, P INT C NEUR INF PRO
   [Anonymous], Technical report
   [Anonymous], MULTI TASK FEATURE L
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Chang X, 2015, P ICML
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   Gao Z, 2014, IEEE T PATTERN ANAL, V36, P1975, DOI 10.1109/TPAMI.2014.2314663
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Lang CY, 2012, IEEE T IMAGE PROCESS, V21, P1327, DOI 10.1109/TIP.2011.2169274
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Li P, 2016, J VIS COMMUN IMAGE R, V37, P46, DOI 10.1016/j.jvcir.2015.06.012
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Lin Z., 2011, ADV NEURAL INFORM PR, V24, P612, DOI DOI 10.1007/S11263-013-0611-6
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Ma ZG, 2017, IEEE T MULTIMEDIA, V19, P1558, DOI 10.1109/TMM.2017.2659221
   Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Peng H., 2016, IEEE T PATTERN ANAL, VPP, P1
   Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Souly N, 2016, INT J COMPUT VISION, V117, P93, DOI 10.1007/s11263-015-0853-6
   Sun JG, 2015, IEEE T IMAGE PROCESS, V24, P1639, DOI 10.1109/TIP.2015.2403241
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   Wang W, 2016, IEEE T IMAGE PROCESS, V25, P1465, DOI 10.1109/TIP.2016.2523340
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang M, 2013, IEEE T IMAGE PROCESS, V22, P1753, DOI 10.1109/TIP.2012.2235849
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang J, 2015, P IEEE ICCV
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
   Zhao MY, 2014, NEUROCOMPUTING, V140, P84, DOI 10.1016/j.neucom.2014.03.033
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zou WB, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.78
NR 56
TC 4
Z9 4
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3317
EP 3337
DI 10.1007/s11042-017-5118-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600023
DA 2024-07-18
ER

PT J
AU Yao, SH
   Wang, T
   Chong, YW
   Pan, SM
AF Yao, Shihong
   Wang, Tao
   Chong, Yanwen
   Pan, Shaoming
TI Sparsity estimation based adaptive matching pursuit algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image reconstruction; Matching pursuit; Sparsity estimation; Restricted
   Isometry Property
ID SIGNAL RECONSTRUCTION; INVERSE PROBLEMS
AB Compared with convex optimization algorithms and combination algorithms, greedy pursuit algorithms can balance operational efficiency and reconstruction precision, so they are widely used in the signal reconstruction step of compressed sensing. However, most existing greedy pursuit algorithms only work well if the signal sparsity is known, and their reconstruction performance is influenced by signal sparsity. To more accurately match the sparsity and obtain better reconstruction performance, we propose a greedy pursuit algorithm, the sparsity estimation based adaptive matching pursuit algorithm, which achieves image reconstruction using a signal sparsity estimation based on the Restricted Isometry Property (RIP) criterion and a flexible step size. Experimental results demonstrate that this algorithm provides better reconstruction performance and lower computation time, using different measurement matrices, when the sparsity is estimated in advance.
C1 [Yao, Shihong] China Univ Geosci, Fac Informat Engn, Wuhan, Hubei, Peoples R China.
   [Wang, Tao; Chong, Yanwen; Pan, Shaoming] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan, Hubei, Peoples R China.
   [Wang, Tao] Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, Wuhan, Hubei, Peoples R China.
C3 China University of Geosciences; Wuhan University; Wuhan University
RP Chong, YW (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan, Hubei, Peoples R China.
EM yao_shi_hong@whu.edu.cn; wangtao.mac@whu.edu.cn; apollobest@126.com;
   pansm@whu.edu.cn
RI Zhang, Can/JUU-9511-2023
FU National Natural Science Foundation of China [41271398, 41671382,
   61572372]; China Postdoctoral Science Foundation [2016 M592409];
   National Program on Key Basic Research Project [2011CB302306]; LIESMARS;
   SAST [SAST201425]; NUIST; PAPD; CICAEET
FX The research work reported in this paper is supported by the National
   Natural Science Foundation of China (No: 41271398, 41671382, 61572372),
   China Postdoctoral Science Foundation (Grant No. 2016 M592409), National
   Program on Key Basic Research Project (No: 2011CB302306). In addition,
   this work is partially supported by LIESMARS Special Research Funding,
   SAST Funding (No. SAST201425) and Open Funding of NUIST, PAPD and
   CICAEET.
CR Blumensath T, 2009, IEEE T SIGNAL PROCES, V57, P4333, DOI 10.1109/TSP.2009.2025088
   Candes E., 2005, l1-magic: Recovery of sparse signals via convex programming, P14
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Do TT, 2008, CONF REC ASILOMAR C, P581, DOI 10.1109/ACSSC.2008.5074472
   Donoho DL, 2007, J APPROX THEORY, V147, P185, DOI 10.1016/j.jat.2007.01.004
   Donoho DL, 2006, TR20062 STANDF U DEP
   Elad M, 2002, IEEE T INFORM THEORY, V48, P2558, DOI 10.1109/TIT.2002.801410
   Eldar Y. C., 2012, COMPRESSED SENSING T
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Fornasier M., 2010, HDB MATH METHODS IMA, V1, P187
   Foucart S., 2013, A Mathematical Introduction to Compressive Sensing, P133
   Gilbert A., 2007, P 39 ACM S THEOR COM
   Gilbert A. C., 2006, P ALL, P1
   Gu B., 2016, IEEE Transactions on Neural Networks and Learning Systems, DOI DOI 10.1109/TNNLS.2016.2527796
   Gu B, 2017, IEEE T NEUR NET LEAR, V28, P1646, DOI 10.1109/TNNLS.2016.2544779
   Hoyer PO, 2004, J MACH LEARN RES, V5, P1457
   Iwen MA, 2010, FOUND COMPUT MATH, V10, P303, DOI 10.1007/s10208-009-9057-1
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   NEEDELL D, 2008, APPL COMPUTATIONAL H, V26, P93
   Needell D, 2010, IEEE J-STSP, V4, P310, DOI 10.1109/JSTSP.2010.2042412
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Sharon Y, 2007, UILUENG072208 CSL
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang HY, 2011, COMPUT STAT DATA AN, V55, P2925, DOI 10.1016/j.csda.2011.04.021
   Wang J, 2012, IEEE T SIGNAL PROCES, V60, P6202, DOI 10.1109/TSP.2012.2218810
   Wen JM, 2017, IEEE T INFORM THEORY, V63, P631, DOI 10.1109/TIT.2016.2627082
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   YAO S, 2015, MULTIMED TOOLS APPL, P1
NR 31
TC 3
Z9 3
U1 2
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4095
EP 4112
DI 10.1007/s11042-016-4295-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500002
DA 2024-07-18
ER

PT J
AU Yun, Z
   Jiang, L
   Wang, S
   Huang, XJ
   Song, H
   Li, XT
AF Yun, Zhu
   Jiang, Lin
   Wang, Shuai
   Huang, Xingjie
   Song, Hui
   Li, Xueting
TI Design of reconfigurable array processor for multimedia application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reconfigurable Array processor; Multimedia retrieval; Hash;
   Fractionalmotion estimation (FME)
ID SALIENCY
AB With the rapid growth of the amount of computations and power consumption, there is a pressing need for a high power-efficiency architecture, which takes account of computational efficiency and flexibility of application. This paper proposes a type of array-processor architecture for multimedia application which is programmable and self-reconfigurable and consists of 1024 thin-core processing elements (PE). The performance and power dissipation are demonstrated with different multimedia application algorithms such as hash, and fractional motion estimation (FME). The results show that the proposed architecture can provide high performance with less energy consumption using parallel computation.
C1 [Yun, Zhu] Xidian Univ, Sch Microelect, Xian 710071, Shaanxi, Peoples R China.
   [Jiang, Lin; Wang, Shuai; Song, Hui] Xian Univ Posts & Telecommun, Sch Elect Engn, Xian 710121, Shaanxi, Peoples R China.
   [Huang, Xingjie] Northeastern Univ, Coll Comp & Informat Sci, Boston, MA 02115 USA.
   [Li, Xueting] Xian Univ Posts & Telecommun, Sch Comp Sci, Xian 710121, Shaanxi, Peoples R China.
C3 Xidian University; Xi'an University of Posts & Telecommunications;
   Northeastern University; Xi'an University of Posts & Telecommunications
RP Jiang, L (corresponding author), Xian Univ Posts & Telecommun, Sch Elect Engn, Xian 710121, Shaanxi, Peoples R China.
EM jl@xupt.edu.cn
FU National Natural Science Foundation of China [61272120, 61602377,
   61634004]; Natural Science Foundation of Shaanxi Province of China
   [2015JM6326]; Shaanxi Provincial Co-ordination Innovation Project of
   Science and Technology [2016KTZDGY02-04-02]; Project of Education
   Department of Shaanxi Provincial Government [15JK1683]
FX This work was supported by the National Natural Science Foundation of
   China (61272120, 61602377, and 61634004), the Natural Science Foundation
   of Shaanxi Province of China (2015JM6326), Shaanxi Provincial
   Co-ordination Innovation Project of Science and Technology
   (2016KTZDGY02-04-02), and the Project of Education Department of Shaanxi
   Provincial Government (15JK1683).
CR Afonso V, 2013, CIRCUITS SYSTEMS LAS, P1
   [Anonymous], 2001, IEEE EURASIP WORK NO
   [Anonymous], COMPUT SCI
   [Anonymous], CHINA SCI INF SCI
   [Anonymous], ENERGY EFFICIENCY DR
   [Anonymous], CHIN J SAF SCI
   [Anonymous], SPARSE REPRESENTATIO
   [Anonymous], CAMBITS RECONFIGURAB
   [Anonymous], 2013, 230082 ISOIEC
   [Anonymous], J ZHEJIANG U ENG ED
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Feng Y, 2011, IEEE T BROADCAST, V57, P500, DOI 10.1109/TBC.2011.2131030
   Fridrich J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P178, DOI 10.1109/ITCC.2000.844203
   Han JG, 2013, NEUROCOMPUTING, V111, P70, DOI 10.1016/j.neucom.2012.12.015
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Jafri SMAH, 2016, IEEE T COMPUT, V65, P3456, DOI 10.1109/TC.2016.2525981
   Jiang JM, 2011, IEEE T BROADCAST, V57, P646, DOI 10.1109/TBC.2011.2158252
   Kim Y, 2016, IET CIRC DEVICE SYST, V10, P251, DOI 10.1049/iet-cds.2015.0047
   León JA, 2016, INT J PHOTOENERGY, V2016, DOI 10.1155/2016/1048095
   Li H, 2013, INT CONF ACOUST SPEE, P1399, DOI 10.1109/ICASSP.2013.6637881
   Ma ZG, 2017, IEEE T MULTIMEDIA, V19, P1558, DOI 10.1109/TMM.2017.2659221
   Maich H, 2013, IEEE I C ELECT CIRC, P161, DOI 10.1109/ICECS.2013.6815379
   Pastuszak G, 2016, J REAL-TIME IMAGE PR, V11, P663, DOI 10.1007/s11554-014-0422-1
   Pellauer M, 2015, ACM T COMPUT SYST, V33, DOI 10.1145/2754930
   Qian XM, 2017, IEEE T MULTIMEDIA, V19, P813, DOI 10.1109/TMM.2016.2638207
   Ren JC, 2009, IEEE T CIRC SYST VID, V19, P1234, DOI 10.1109/TCSVT.2009.2022707
   Ren JC, 2009, IEEE T MULTIMEDIA, V11, P906, DOI 10.1109/TMM.2009.2021782
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tung-Chien Chen, 2006, 2006 IEEE International Symposium on Circuits and Systems (IEEE Cat. No. 06CH37717C), DOI 10.1109/ISCAS.2006.1693837
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yao XW, 2016, IEEE T GEOSCI REMOTE, V54, P3660, DOI 10.1109/TGRS.2016.2523563
   Yao XW, 2015, NEUROCOMPUTING, V164, P162, DOI 10.1016/j.neucom.2015.02.073
   Zabalza Jaime, 2015, IEEE Transactions on Geoscience and Remote Sensing, V53, P4418, DOI 10.1109/TGRS.2015.2398468
   Zabalza J, 2014, APPL OPTICS, V53, P4440, DOI 10.1364/AO.53.004440
NR 37
TC 3
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3639
EP 3657
DI 10.1007/s11042-017-5284-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600040
DA 2024-07-18
ER

PT J
AU Zhang, H
   Ge, DC
   Zhang, SY
AF Zhang, Hong
   Ge, Dechu
   Zhang, Siyu
TI Hybrid recommendation system based on semantic interest community and
   trusted neighbors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid recommendation system; Interest community; Trusted neighbor;
   Diversity
AB The accuracy of a recommendation is an important index to evaluate the performance of a recommendation system. The personalized recommendation system tends to pay too much attention to the accuracy of recommendation results and often neglects the diversity of the recommendation results. In this paper, domain ontology is used to construct the user interest model, and the integrated ontology-based semantic similarity algorithm is used to obtain the user ontology set. Then, the semantic interest community is constructed through the hierarchical clustering method. Users with a high degree of diversity are selected as trusted neighbors to construct a hybrid recommendation model with a combination of accuracy and diversity. The experimental results show that the hybrid model can improve the diversity of the recommendation system by adjusting the weight factor while having less influence on the accuracy.
C1 [Zhang, Hong; Ge, Dechu; Zhang, Siyu] Northeast Elect Power Univ, Sch Elect Engn, Jilin 132012, Jilin, Peoples R China.
C3 Northeast Electric Power University
RP Zhang, H (corresponding author), Northeast Elect Power Univ, Sch Elect Engn, Jilin 132012, Jilin, Peoples R China.
EM jdlzh2000@126.com
CR Adomavicius G, 2008, P 18 WORKSH INF TECH, P31
   Adomavicius G, 2011, IEEE T KNOWL DATA EN, V24, P1
   Adomavicius G, 2009, P 19 WORKSH INF TECH, P248
   Ai Cong-cong, 2014, THESIS
   Bradley K., 2001, Business, P75
   Chiang TC, 2012, LECT NOTES ARTIF INT, V6839, P49
   De Pessemier T, 2014, MULTIMED TOOLS APPL, V72, P2497, DOI 10.1007/s11042-013-1563-0
   Hu R., 2011, DiveRS@ RecSys, P43
   Hurley N, 2011, ACM T INTERNET TECHN, V10, DOI 10.1145/1944339.1944341
   Ionescu B, 2016, MULTIMED TOOLS APPL, V75, P1301, DOI 10.1007/s11042-014-2369-4
   Ionescu BE, 2014, MULTIMED TOOLS APPL, V70, P1007, DOI 10.1007/s11042-012-1097-x
   Jiang LL, 2009, NEW J PHYS, V11, DOI 10.1088/1367-2630/11/10/103001
   Kaushik T, 2013, INT J ENG COMPUT SCI, V2, P3556
   Lathia N, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P210
   Lee S, 2011, IEEE INT C BIO BIO W, P725, DOI 10.1109/BIBMW.2011.6112460
   McNee SM, 2006, CHI 06 HUM FACT COMP, P1097, DOI DOI 10.1145/1125451.1125659
   Medo M, 2009, EPL-EUROPHYS LETT, V88, DOI 10.1209/0295-5075/88/38005
   Oku Kenta, 2011, Proceedings of the Workshop on Novelty and Diversity in Recommender Systems (DiveRS 2011), at the 5th ACM International Conference on Recommender Systems (RecSys 2011), V816, P19
   Pessemier Toon De, 2016, MULTIMED TOOLS APPL, V75, P1
   Wang Guoxia, 2012, Computer Engineering and Applications, V48, P66, DOI 10.3778/j.issn.1002-8331.2012.07.018
   Wen JM, 2017, IEEE T SIGNAL PROCES, V65, P1370, DOI 10.1109/TSP.2016.2634550
   Wen JM, 2017, IEEE T INFORM THEORY, V63, P631, DOI 10.1109/TIT.2016.2627082
   Wen JM, 2015, APPL COMPUT HARMON A, V38, P161, DOI 10.1016/j.acha.2014.06.003
   Yang Xueming, 2009, J INTELLIGENCE, V28, P171
   Zhang F-g, 2014, J CHINESE COMPUT SYS, V35, P1471
   Zhang HT, 2008, EPL-EUROPHYS LETT, V83, DOI 10.1209/0295-5075/83/40003
   Zhang Hua-Qing, 2011, Journal of Computer Applications, V31, P2408, DOI 10.3724/SP.J.1087.2011.02408
   Zhang ZK, 2010, PHYSICA A, V389, P179, DOI 10.1016/j.physa.2009.08.036
   Zhou T, 2010, P NATL ACAD SCI USA, V107, P4511, DOI 10.1073/pnas.1000488107
   Ziegler Cai-Nicolas, 2005, P 14 INT C WORLD WID, P22, DOI DOI 10.1145/1060745.1060754
   Ziegler Cai-Nicolas., 2009, IEEE DATA ENG B, V32, P23
NR 31
TC 12
Z9 14
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4187
EP 4202
DI 10.1007/s11042-017-4553-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500007
DA 2024-07-18
ER

PT J
AU Jovanovic, B
   Gajin, S
AF Jovanovic, Borisa
   Gajin, Slavko
TI An efficient mechanism of cryptographic synchronization within
   selectively encrypted H.265/HEVC video stream
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Selective encryption; Randomaccess; Cryptographic synchronization
ID CODING HEVC; COMPRESSION; PROTECTION; DESIGN
AB The challenge to which the encryption of multimedia data needs to respond is ensuring the security of data intensive video stream in an efficient way. Unlike full data encryption, selective encryption manages to achieve this by encrypting only a part of the data stream, while providing a satisfactory level of video security. This optimizes the processing time and the size of encrypted data. Regardless of the encryption technique, there is a lack of cryptographic synchronization when providing random access to the selected part of the encrypted multimedia stream. In this paper we propose a novel and efficient method of cryptographic synchronization as an extension to the H.265/HEVC crypto encoder in order to support random access in selectively encrypted video stream.
C1 [Jovanovic, Borisa; Gajin, Slavko] Univ Belgrade, Sch Elect Engn, Bulevar Kralja Aleksandra 73, Belgrade 11000, Serbia.
C3 University of Belgrade
RP Jovanovic, B (corresponding author), Univ Belgrade, Sch Elect Engn, Bulevar Kralja Aleksandra 73, Belgrade 11000, Serbia.
EM borisa.jovanovic@vs.rs; slavko.gajin@rcub.bg.ac.rs
RI Gajin, Slavko/HNC-4597-2023; Jovanović, Boriša/AAX-2216-2020
OI Gajin, Slavko/0000-0002-8939-3589; Jovanović, Boriša/0000-0002-9353-724X
CR [Anonymous], P 14 ANN ACM INT C M
   [Anonymous], 2014, P JOINT COLL TEAM VI
   Baroncini V, 2010, JCTVCA204 ITUTISOIEC
   Dubois L, 2011, EUR SIGNAL PR CONF, P2185
   High Efficiency Video Coding, 2013, ISOIEC230082
   Jakimoski G, 2008, IEEE T MULTIMEDIA, V10, P330, DOI 10.1109/TMM.2008.917355
   Jiang JG, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P478, DOI 10.1109/MINES.2009.26
   Lian SG, 2005, LECT NOTES COMPUT SC, V3768, P281, DOI 10.1007/11582267_25
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Ouamri M, 2014, J COMMUN SOFTW SYST, V10
   Park SW, 2009, IEICE T INF SYST, VE92D, P851, DOI 10.1587/transinf.E92.D.851
   Shahid Z, 2014, IEEE T MULTIMEDIA, V16, P24, DOI 10.1109/TMM.2013.2281029
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Van Wallendael G, 2013, IEEE T CONSUM ELECTR, V59, P634, DOI 10.1109/TCE.2013.6626250
   Wang JD, 2007, ASICON 2007: 2007 7TH INTERNATIONAL CONFERENCE ON ASIC, VOLS 1 AND 2, PROCEEDINGS, P802, DOI 10.1109/ICASIC.2007.4415752
   Wu CP, 2005, IEEE T MULTIMEDIA, V7, P828, DOI 10.1109/TMM.2005.854469
   Yeung SKA, 2011, IEEE T CIRC SYST VID, V21, P1341, DOI 10.1109/TCSVT.2011.2125630
   YEUNG SKA, 2011, PROC IEEE INT C ACOU, P2436, DOI DOI 10.1109/ICASSP.2011.5946976
NR 19
TC 4
Z9 4
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1537
EP 1553
DI 10.1007/s11042-017-4389-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400003
DA 2024-07-18
ER

PT J
AU Li, ZH
   Fan, YY
   Liu, WH
   Wang, FQ
AF Li, Zuhe
   Fan, Yangyu
   Liu, Weihua
   Wang, Fengqin
TI Image sentiment prediction based on textual descriptions with adjective
   noun pairs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image sentiment; Textual sentiment; Concept detection; Late fusion
AB We aim to predict the sentiment related information reflected in images based on SentiBank, which is a library including Adjective Noun Pair (ANP) concept detectors for image sentiment analysis. Instead of using only ANP responses in images as mid-level features, we make full use of the ANPs' textual sentiment. We first give each ANP concept in SentiBank a sentiment value by adding together the textual sentiment value of the adjective and that of the noun. Having detected the presence of ANPs in an image, we define an image sentiment value by computing the weighted sum of the textual sentiment values of ANPs describing this image with corresponding ANP responses as weights. On the one hand, we adopt a one-dimension logistic regression model to predict the sentiment orientation according to the image sentiment value. On the other hand, we use the ANP responses detected in an image as mid-level representations to train a regularized logistic regression classifier for sentiment prediction. We finally employ a late fusion algorithm to combine the prediction results from the two schemes. Experimental results reveal that the proposed method which takes into account the textual sentiment of ANPs improves the performance of SentiBank based image sentiment prediction.
C1 [Li, Zuhe; Fan, Yangyu] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.
   [Li, Zuhe; Wang, Fengqin] Zhengzhou Univ Light Ind, Sch Comp & Commun Engn, Zhengzhou 450002, Henan, Peoples R China.
   [Liu, Weihua] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Xian 710119, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University; Zhengzhou University of Light
   Industry; Chinese Academy of Sciences; Xi'an Institute of Optics &
   Precision Mechanics, CAS
RP Li, ZH (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.; Li, ZH (corresponding author), Zhengzhou Univ Light Ind, Sch Comp & Commun Engn, Zhengzhou 450002, Henan, Peoples R China.
EM zuheli@126.com
OI Li, Zuhe/0000-0002-2511-3226
FU Science and Technology Innovation Engineering Program for Shaanxi
   Provincial Key Laboratories [2013SZS15-K02]; Basis and Cutting-Edge
   Research Project of Science and Technology Department of Henan Province
   [142300410248]; Key Scientific Research Plan of Higher Education
   Institutions of Henan Province [15A510041]
FX This work was supported by the Science and Technology Innovation
   Engineering Program for Shaanxi Provincial Key Laboratories under Grant
   2013SZS15-K02, the Basis and Cutting-Edge Research Project of Science
   and Technology Department of Henan Province under Grant 142300410248 and
   the Key Scientific Research Plan of Higher Education Institutions of
   Henan Province under Grant 15A510041.
CR [Anonymous], 2012, P 20 ACM INT C MULT
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Borth D., 2013, P 21 ACM INT C MULT, P459
   Cao DL, 2016, MULTIMED TOOLS APPL, V75, P8955, DOI 10.1007/s11042-014-2337-z
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen T., 2014, DeepSentiBank: Visual Sentiment Concept Classification with Deep Convolutional Neural Networks
   Chen TH, 2014, PR IEEE COMP DESIGN, P367, DOI 10.1109/ICCD.2014.6974707
   Chen Y.-Y., 2014, ICMR 2014 P ACM INT, P233, DOI DOI 10.1145/2578726.2578756
   Jou B, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P213, DOI 10.1145/2647868.2656408
   Koh KM, 2007, J MACH LEARN RES, V8, P1519
   Lai KT, 2015, IEEE T IMAGE PROCESS, V24, P2772, DOI 10.1109/TIP.2015.2423560
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Ng AY, 2016, UNSUPERVISED FEATURE
   Pang B., 2007, INFORM RETRIEVAL, V2, P1, DOI DOI 10.1561/1500000011
   Petz Gerald, 2012, Active Media Technology. 8th International Conference, AMT 2012. Proceedings, P618, DOI 10.1007/978-3-642-35236-2_62
   Petz G, 2015, INFORM PROCESS MANAG, V51, P510, DOI 10.1016/j.ipm.2014.07.011
   Sebastiani F., 2006, P 5 INT C LANG RES E, P417, DOI DOI 10.1155/2015/715730
   Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Yu FLX, 2013, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2013.105
   Yuan J., 2013, P 2 INT WORKSH ISS S, P1
   Zhang H, 2015, NEUROCOMPUTING, V165, P3, DOI 10.1016/j.neucom.2014.10.093
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
NR 25
TC 27
Z9 34
U1 1
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1115
EP 1132
DI 10.1007/s11042-016-4310-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400047
DA 2024-07-18
ER

PT J
AU Wang, J
   Hou, YB
AF Wang, Jin
   Hou, Yi Bin
TI Packet loss rate mapped to the quality of experience
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Packet loss; Packet loss rate; Influence; Quality of experience; Mapping
   model
ID AUDIO
AB In order to study the influence of packet loss on the users' quality of experience QoE and establish the Mapping model of the two when the video transmit in the network, building a NS2 + MyEvalvid simulation platform, by the method of modifying QoS parameters to simulate different degrees of packet loss, focus on the influence of packet loss on QoE and establish the mapping model between them. Experimental results show that, packet loss has a significant influence on Quality of experience. Packet loss rate and the Quality of experience presents a nonlinear relationship, and use Matlab to establish the mapping model, this model's accuracy is high, easy to operate, can real-time detect packet loss has influence on the user's quality of experience (QoE).
C1 [Wang, Jin; Hou, Yi Bin] Beijing Univ Technol, Sch Software Engn, Dept Informat, Software Coll Bldg,Ping Pk 100, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Wang, J (corresponding author), Beijing Univ Technol, Sch Software Engn, Dept Informat, Software Coll Bldg,Ping Pk 100, Beijing 100124, Peoples R China.
EM 805372192@qq.com; ybhou@bjut.edu.cn
FU National Natural Science Foundation of China [60963011, 61162009];
   Jiangxi Natural Science Foundation of China [2009GZS0022]; Special
   Research Foundation of Shijiazhuang Tiedao University [Z9901501,
   20133007]; Beijing University of Technology and software institute
   Doctoral scholarship
FX This work was partially supported by the National Natural Science
   Foundation of China (No: 60963011, 61162009), the Jiangxi Natural
   Science Foundation of China (No: 2009GZS0022), and the Special Research
   Foundation of Shijiazhuang Tiedao University (No: Z9901501, 20133007),
   Beijing University of Technology and software institute Doctoral
   scholarship.
CR Chen Ni, 2010, IMPACT PACKET LOSS P, P206
   Kei CH, 2008, J INF SCI ENG, V24, P425
   Khorsandroo Sajad, 2010, GENERIC QUANTITATIVE, V24, P36
   Kim HJ, 2011, 2011 INT S ANN M, P287
   Kim Hyun Jong, 2010, P 12 INT C ADV COMM
   Kuehnel C., 2008, VOIC COMM SPRACHKOMM, P1
   Leszczuk Mikoaj, 2011, IMAGE COMMUNICATION, P137
   Lin TL, 2010, IEEE T IMAGE PROCESS, V19, P722, DOI 10.1109/TIP.2009.2038834
   Liu Huayong, 2012, P 2012 IE 14 INT C C
   Ni Chen, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P282, DOI 10.1109/CISP.2011.6099995
   Qin Dai, 2010, Proceedings of the Second International Conference on Evolving Internet (INTERNET 2010). First International Conferences on Access Networks, Services and Technologies (ACCESS 2010), P206, DOI 10.1109/INTERNET.2010.51
   Raake A, 2013, INTERSPEECH, P1383
   RAMJEE R, 1994, IEEE INFOCOM SER, P680, DOI 10.1109/INFCOM.1994.337672
   Roccetti M, 2001, MULTIMED TOOLS APPL, V14, P23, DOI 10.1023/A:1011303506685
   Stalins N, 2010, IEEE T BROADCASTING
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sung Hoon Kim, 2015, 2015 International Symposium on Wireless Communication Systems (ISWCS). Proceedings, P286, DOI 10.1109/ISWCS.2015.7454347
   Tao S, 2008, IEEE ACM T NETWORK, V16, P1052, DOI 10.1109/TNET.2007.910617
   Volk M, 2008, IEEE COMMUNICATIONS
   Wang XG, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND ENGINEERING APPLICATIONS, P498, DOI 10.1109/ISDEA.2013.518
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Yu CY., 2008, INT J SOFTWARE ENG A, V2, P21
   Zecic J., 2012, 2012 35th International Convention on Information and Communication Technology, Electronics and Microelectronics, P573
NR 23
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 387
EP 422
DI 10.1007/s11042-016-4254-9
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400017
DA 2024-07-18
ER

PT J
AU Yang, B
   Sun, XM
   Guo, HL
   Xia, ZH
   Chen, XY
AF Yang, Bin
   Sun, Xingming
   Guo, Honglei
   Xia, Zhihua
   Chen, Xianyi
TI A copy-move forgery detection method based on CMFD-SIFT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Copy-move forgery detection; SIFT; Descriptor;
   Detector; Tempering
ID IMAGE; SEGMENTATION; DESCRIPTOR
AB A very common way of image tampering is the copy-move attack. When creating a copy-move forgery, it is often necessary to add or remove important objects from an image. To carry out forensic analysis of such images, various copy-move forgery detection (CMFD) methods have been developed in the literatures. In recent years, many feature-based CMFD approaches have emerged due to its excellent robustness to various transformations. However there is still place to improve performance further. Many of them would suffer from the problem of insufficient matched key-points while performing on the mirror transformed forgeries. Furthermore, many feature-based methods might hardly expose the tempering when the forged region is of uniform texture. In this paper, a novel feature-based CMFD method is proposed. Key-points are detected by using a modified SIFT-based detector. A novel key-points distribution strategy is developed for interspersing the key-points evenly throughout an image. Finally, key-points are descripted by an improved SIFT descriptor which is enhanced for the CMFD scenario. Extensive experimental results are presented to confirm the efficacy.
C1 [Yang, Bin; Guo, Honglei] Jiangnan Univ, Sch Design, Wuxi 214122, Peoples R China.
   [Sun, Xingming; Xia, Zhihua; Chen, Xianyi] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
C3 Jiangnan University; Nanjing University of Information Science &
   Technology
RP Yang, B (corresponding author), Jiangnan Univ, Sch Design, Wuxi 214122, Peoples R China.
EM yewind2002@163.com
RI Sun, Xingming/AAD-1866-2019; Xia, Zhihua/C-8581-2011
OI Xia, Zhihua/0000-0001-6860-647X; Bin, Yang/0000-0002-1170-4105
FU National Natural Science Foundation of China [U1536206, 61232016,
   U1405254, 61373133, 61502242, 61672294, 61602253]; Fundamental Research
   Funds for the Central Universities [JUSRP11534]; Priority Academic
   Program Development of Jiangsu Higher Education Institutions (PAPD);
   Jiangsu Collaborative Innovation Center on Atmospheric Environment and
   Equipment Technology (CICAEET)
FX This work is supported in part by the National Natural Science
   Foundation of China (NO. U1536206, 61232016, U1405254, 61373133,
   61502242, 61672294, 61602253); the Fundamental Research Funds for the
   Central Universities (NO. JUSRP11534); the Priority Academic Program
   Development of Jiangsu Higher Education Institutions (PAPD); Jiangsu
   Collaborative Innovation Center on Atmospheric Environment and Equipment
   Technology (CICAEET)
CR Ahmad J, 2017, J REAL-TIME IMAGE PR, V13, P431, DOI 10.1007/s11554-015-0536-0
   Amerini I, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-18
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2013, 2013 INT C EL COMP A
   [Anonymous], 2015, 2015 INT C COMM INF
   [Anonymous], CHINA COMMUN
   [Anonymous], 2016, IEEE T INF FORENSICS
   [Anonymous], J PLATFORM TECHNOLOG
   [Anonymous], IEEE T NEURAL NETW L, DOI [10.1109/TNNLS.2016.2527796, DOI 10.1109/TNNLS.2016.2527796]
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Chen YD, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-015-0957-4
   Cozzolino D., 2015, IEEE T INF FOREN SEC, V10, P2284, DOI DOI 10.1109/TIFS.2015.2455334
   Fridrich A.J., 2003, P DIGITAL FORENSIC R
   Fu ZJ, 2016, IEEE T INF FOREN SEC, V11, P2706, DOI 10.1109/TIFS.2016.2596138
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Guo JM, 2013, EXPERT SYST APPL, V40, P707, DOI 10.1016/j.eswa.2012.08.002
   Hastie T., 2001, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7_2
   Kakar P, 2012, IEEE T INF FOREN SEC, V7, P1018, DOI 10.1109/TIFS.2012.2188390
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li J, 2014, IEEE T PARALL DISTR, V25, P2201, DOI 10.1109/TPDS.2013.271
   Liao KY, 2013, PATTERN RECOGN LETT, V34, P1211, DOI 10.1016/j.patrec.2013.03.021
   Lindeberg T, 1997, IMAGE VISION COMPUT, V15, P415, DOI 10.1016/S0262-8856(97)01144-X
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo J., 2009, INT J IMAGE PROCESSI, V3, P143, DOI DOI 10.1007/S11270-006-2859-8
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Quackenbush J, 2001, NAT REV GENET, V2, P418, DOI 10.1038/35076576
   Shen J, 2015, J COMMUN NETW-S KOR, V17, P453, DOI 10.1109/JCN.2015.000083
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Wang Jinwei, 2016, MULTIMED TOOLS APPL, P1
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Xia Z., 2016, Signal, Image Video Process, V11, P1
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yang B, 2015, COMPUT J, V58, P588, DOI 10.1093/comjnl/bxu146
   Yang B, 2013, RADIOENGINEERING, V22, P1098
   Yap KH, 2015, IEEE INT SYMP CIRC S, P730, DOI 10.1109/ISCAS.2015.7168737
   Yuan CS, 2016, CHINA COMMUN, V13, P60, DOI 10.1109/CC.2016.7559076
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zhou ZL, 2016, IEICE T INF SYST, VE99D, P1531, DOI 10.1587/transinf.2015EDP7341
   Zhu Y., 2015, MULTIMED TOOLS APPL, V75, P1
NR 45
TC 49
Z9 55
U1 3
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 837
EP 855
DI 10.1007/s11042-016-4289-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400035
DA 2024-07-18
ER

PT J
AU Elmisery, AM
   Rho, S
   Sertovic, M
   Boudaoud, K
   Seo, S
AF Elmisery, Ahmed M.
   Rho, Seungmin
   Sertovic, Mirela
   Boudaoud, Karima
   Seo, Sanghyun
TI Privacy aware group based recommender system in multimedia services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia services; Privacy aware services; Recommender services
AB Recommending similar-interest users' groups in multimedia services is the problem of detecting for each registered user his/her membership to one interest-group of relevant consumers. The consumers in each interest-group share some relevant preferences which guarantee that the interest-group as a whole satisfies some desired properties of similarity. As a result, forming these interest-groups requires the availability of personal data of different consumers. This is a crucial requirement for different recommender systems. With the increasing trend of service providers to collect a large volume of personal data regarding their end-users, presumably to better serve them. However, a significant part of the data that is typically collected is not essential to the service being offered, or to the completion of the services it was presumably released for. Gathering such unnecessary data can be seen as a privacy threat, and storing it exposes the end-users to further unavoidable risks. In this paper, a privacy aware group based recommender system is proposed for the automated discovery of appropriate interest groups in multimedia services. A fog based middleware (FMCP) was introduced that runs at end-users' sides and allows exchanging of their information to facilities recommending and creating interest-groups without disclosing their real preferences to other consumers. The membership of consumers in various interest groups allows receiving highly appropriate and reliable multimedia content-related advices. The system utilizes two protocols to attain this goal. Experiments were performed on real dataset.
C1 [Elmisery, Ahmed M.] Univ Tecn Federico Santa Maria, Dept Elect Engn, Valparaiso, Chile.
   [Rho, Seungmin; Seo, Sanghyun] Sungkyul Univ, Dept Media Software, Anyang Si, South Korea.
   [Sertovic, Mirela] Svcuciliste Zagrebu, Filozofski Fak Zagrebu, Zagreb, Croatia.
   [Boudaoud, Karima] Equipe RAINBOW, Lab Informat Signaux & Syst Sophia Antipolis I3S, Sophia Antipolis, France.
C3 Universidad Tecnica Federico Santa Maria; Sungkyul University;
   University of Zagreb; Universite Cote d'Azur
RP Seo, S (corresponding author), Sungkyul Univ, Dept Media Software, Anyang Si, South Korea.
EM ahmedmisery@gmail.com; smrho@sungkyul.ac.kr; msertovic@yahoo.com;
   karima@polytech.unice.fr; shseo75@gmail.com
RI Rho, Seungmin/HTP-6683-2023; Elmisery, Ahmed M./I-9357-2017; Sanghyun,
   Seo/ADZ-4404-2022
OI Elmisery, Ahmed M./0000-0003-1077-4790; Sanghyun,
   Seo/0000-0002-4824-3517
FU "Direccion General de Investigacion, Innovacion y Postgrado" of Federico
   Santa Maria Technical University-Chile in the project Security in
   Cyber-Physical Systems for Power Grids [UTFSM-DGIP PI.L.17.15];
   Microsoft Azure for Research Grant [0518798]; National Research
   Foundation of Korea (NRF) - Ministry of Education [2013R1A1A2061978]
FX This work was partially financed by the "Direccion General de
   Investigacion, Innovacion y Postgrado" of Federico Santa Maria Technical
   University-Chile, in the project Security in Cyber-Physical Systems for
   Power Grids (UTFSM-DGIP PI.L.17.15), and by the Microsoft Azure for
   Research Grant (0518798) and by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (2013R1A1A2061978)
CR Aimeur E, EXPT DEMONSTRATION H, P161
   Alsmirat MA, 2017, J REAL-TIME IMAGE PR, V13, P527, DOI 10.1007/s11554-016-0631-x
   [Anonymous], SECURITY PRIVACY MOB
   [Anonymous], 2011, J CONVERG
   [Anonymous], 2002, P 8 ACM SIGKDD INT C, DOI DOI 10.1145/775047.775110
   Canny J, COLLABORATIVE FILTER, P45
   Cheung DW, 1996, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED INFORMATION SYSTEMS, P31, DOI 10.1109/PDIS.1996.568665
   Cuesta-Frau D, 2003, COMPUT METH PROG BIO, V72, P179, DOI 10.1016/S0169-2607(02)00145-1
   Elmesiry A. M., 2014, MACHINE LEARNING BAS
   Elmisery A.M., 2012, COMPUTER SCI ITS APP, V203, P313
   Elmisery A. M., 2011, INTELLIGENT DECISION, P821, DOI [10.1007/978-3-642-22194-1_81, DOI 10.1007/978-3-642-22194-1_81]
   Elmisery AM, 2016, IEEE ACCESS, V4, P8418, DOI 10.1109/ACCESS.2016.2631546
   Elmisery AM, 2016, MULTIMED TOOLS APPL, V75, P14927, DOI 10.1007/s11042-014-2271-0
   Elmisery AM, 2016, J SUPERCOMPUT, V72, P247, DOI 10.1007/s11227-015-1574-x
   Elmisery AM, 2014, NEW REV HYPERMEDIA M, V20, P145, DOI 10.1080/13614568.2014.889222
   Elmisery AM, 2012, FRONT ARTIF INTEL AP, V243, P519, DOI 10.3233/978-1-61499-105-2-519
   Elmisery AM, PRIVACY AWARE RECOMM, P160, DOI [10.1109/MUE.2011.70, DOI 10.1109/MUE.2011.70]
   Fung B.C.M., 2002, THESIS
   He J, INFERRING PRIVACY IN, P154
   Hofmann T, COLLABORATIVE FILTER, P791
   Huang Z., 2005, P 2005 ACM SIGMOD IN, P37, DOI DOI 10.1145/1066157.1066163
   I. Union, 2005, ITU INT REP
   Kargupta H, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P99
   Kim HD, 2009, KSII T INTERNET INF, V3, P366, DOI 10.3837/tiis.2009.04.002
   Koutsabasis P, 2008, ELECTRON COMMER RES, V8, P173, DOI 10.1007/s10660-008-9021-1
   Loureiro S., 2001, Electronic Commerce Research, V1, P119, DOI 10.1023/A:1011527713457
   McSherry F, DIFFERENTIALLY PRIVA, P627
   Miller BN, 2004, ACM T INFORM SYST, V22, P437, DOI 10.1145/1010614.1010618
   Perik E., SENSITIVITIES USER P
   Perik E, PRIVACY PERSONALIZAT
   Polat H, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P625
   Rubinstein Ira R., 2011, Berkeley Tech. LJ, V26, P1409
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
NR 33
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26103
EP 26127
DI 10.1007/s11042-017-4950-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500028
DA 2024-07-18
ER

PT J
AU Kang, S
   Park, C
AF Kang, Seokhoon
   Park, Chanhyuk
TI Motion-estimation-based stabilization of infrared video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video stabilization; Landmark; Shape correction; IR image
AB In the course of the filming of infrared (IR) video, intrinsic equipment instability incurs movement that in turn causes image blurring. For image clarity and viewing comfortability, it is required that such movement be countered. Presently, video stabilization systems perform Motion Estimation of frames that is then applied frame-by-frame to subsequent frames in order to calculate a motion vector, counter movement, and produce, thereby, a more stable image. However, frame-by-frame comparison for long-distance filming often is difficult due to lack of information. The present study determined the appropriate blocks with the most information for Motion Estimation. We also were able to differentiate between equipment movement and movement in the video itself. By these means, we were able to stabilize videos. The methods employed in the experimentation were 5 sets of 640 x 480 long-distance videos and 5 sets of 480 x 320 long-distance videos. When compared with the current motion estimation methods, our proposed method afforded a 10% increase in accuracy.
C1 [Kang, Seokhoon; Park, Chanhyuk] Univ Incheon, Dept Embedded Syst Engn, Incheon 406772, South Korea.
C3 Incheon National University
RP Kang, S (corresponding author), Univ Incheon, Dept Embedded Syst Engn, Incheon 406772, South Korea.
EM hana@incheon.ac.kr
FU Incheon National University
FX This work was supported by Incheon National University Research Grant in
   2013.
CR Ahmed Z, 2012, INT S INN INT SYST A, DOI [10.1109/INISTA.2012.6247015, DOI 10.1109/INISTA.2012.6247015]
   Alvarez LD, 2004, IEEE IMAGE PROC, P1795
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Ghoniem M, 2006, I S INTELL SIG PROC, P398
   Jing X, 2004, IEEE T MULTIMEDIA, V6, P435, DOI 10.1109/TMM.2004.827517
   Kim NJ, 2009, IEEE T CONSUM ELECTR, V55, P902, DOI 10.1109/TCE.2009.5174473
   Ko SJ, 1999, IEEE T CONSUM ELECTR, V45, P598, DOI 10.1109/30.793546
   Kumar S, 2011, IEEE T IMAGE PROCESS, V20, P3406, DOI 10.1109/TIP.2011.2156420
   탁수용, 2012, [Signal Processing, 전자공학회논문지 - SP], V49, P95
   Li THS, 2013, IEEE T CONSUM ELECTR, V59, P113, DOI 10.1109/TCE.2013.6490249
   김범수, 2015, [Journal of IKEEE, 전기전자학회논문지], V19, P244, DOI 10.7471/ikeee.2015.19.2.244
   Marius T., 2006, ICASSP, V2, P277
   Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Piamsa-nga P, 2004, IEEE IMAGE PROC, P365
   Schwendeman M, 2015, J ATMOS OCEAN TECH, V32, P164, DOI 10.1175/JTECH-D-14-00047.1
   Song J, 2015, IEEE IC COMP COM NET, DOI 10.1109/ICAwST.2015.7314026
   Wang J, 2013, NUCL SCI S MED IM C, DOI [10.1109/NSSMIC.2013.6829054, DOI 10.1109/NSSMIC.2013.6829054]
   Wang YiYan Wang YiYan, 2013, Chinese Journal of Hygienic Insecticides & Equipments, V19, P8
   Xu J, 2012, IEEE T CONSUM ELECTR, V58, P993, DOI 10.1109/TCE.2012.6311347
   이승권, 2015, [Journal of the Institute of Electronics and Information Engineers, 전자공학회논문지], V52, P29
NR 21
TC 2
Z9 2
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24635
EP 24647
DI 10.1007/s11042-017-4647-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300004
DA 2024-07-18
ER

PT J
AU Koukopoulos, Z
   Koukopoulos, D
   Jung, JJ
AF Koukopoulos, Zois
   Koukopoulos, Dimitrios
   Jung, Jason J.
TI A trustworthy multimedia participatory platform for cultural heritage
   management in smart city environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cultural heritage; Participatory systems; Web portals; Smartphone
   application; Internet of things; Smart cities
ID PARKING MANAGEMENT; CITIES; ARCHITECTURE; INTERNET; FRAMEWORK; SERVICES;
   LIFE
AB Cultural heritage applications within smart city environments are becoming extremely popular to public authorities. The success of such applications lies on several factors like user-friendliness and data presentation as well as the amount and accuracy of cultural data they can offer to users, static or mobile, on-demand. This paper presents the design and implementation of a multipurpose, multidiscipline digital platform that manages, preserves and disseminates tangible and intangible cultural heritage information, in a trustworthy manner, appropriate for the everyday use in smart city digital environments. Platform's trustworthiness is mainly ensured by applying specific authorization mechanisms based on an extended role-based access control scheme. The platform integrates a mobile services module that can host and support smartphone applications for the direct collection, digitization and dissemination of cultural heritage content. Moreover, we make an attempt to address various stakeholders who benefit from such a platform. In this direction we have designed and implemented a series of real life usage scenarios. The proposed platform is evaluated against other online digital platforms that host cultural heritage content. Evaluation results suggest that the presented platform could become a participatory system that targets not only experts and artists, but also amateurs and enthusiasts of cultural heritage. This vast and heterogeneous user base could be the only feasible way to support data-hungry ecosystems like smart city digital environments, by providing cultural information at any time and place.
C1 [Koukopoulos, Zois; Koukopoulos, Dimitrios] Univ Patras, Dept Cultural Heritage Management & New Technol, 2 G Seferi, Agrinion 30100, Greece.
   [Jung, Jason J.] Chung Ang Univ, Dept Comp Engn, Seoul, South Korea.
C3 University of Patras; Chung Ang University
RP Koukopoulos, Z (corresponding author), Univ Patras, Dept Cultural Heritage Management & New Technol, 2 G Seferi, Agrinion 30100, Greece.
EM zkoukopu@upatras.gr; dkoukopoulos@upatras.gr; j2jung@gmail.com
RI Jung, Jason J./B-9622-2012
OI Jung, Jason J./0000-0003-0050-7445
CR Al Nuaimi E, 2015, J INTERNET SERV APPL, V6, DOI 10.1186/s13174-015-0041-5
   Alvi SA, 2015, AD HOC NETW, V33, P87, DOI 10.1016/j.adhoc.2015.04.006
   Amato F, 2013, PROCEDIA COMPUT SCI, V21, P114, DOI 10.1016/j.procs.2013.09.017
   Amato F, 2012, PROCEEDINGS OF THE TWELFTH INTERNATIONAL WORKSHOP ON WEB INFORMATION AND DATA MANAGEMENT, P49
   Angelaccio M, 2012, IEEE ENABL TECHNOL, P310, DOI 10.1109/WETICE.2012.36
   [Anonymous], 2007, Situated Play: Proceedings of the Third International Conference of the Digital Games Research Association
   Anthopoulos L., 2012, Web 2.0 technologies and democratic governance: Political, policy and management implications, P79
   Anthopoulos LeonidasG., 2012, The Future Internet: Future Internet Assembly 2012: From Promises to Reality, P178, DOI DOI 10.1007/978-3-642-30241-1_16
   Ardissono L, 2012, USER MODEL USER-ADAP, V22, P73, DOI 10.1007/s11257-011-9104-x
   Barile F, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P501, DOI 10.1109/SITIS.2014.12
   Barone RE, 2014, IET INTELL TRANSP SY, V8, P445, DOI 10.1049/iet-its.2013.0045
   Basu P, 2013, INT HDB MUS STUD, V4, P337
   Beever J, 2003, MINERVA 2003
   Belanger F, 2011, MIS QUART, V35, P1017
   Blackstock M, 2012, PROCEEDINGS OF 2012 INTERNATIONAL CONFERENCE ON THE INTERNET OF THINGS, P159, DOI 10.1109/IOT.2012.6402318
   Bruns A, 2008, FIBRECULTURE J, V11
   Chianese A, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P477, DOI 10.1109/SITIS.2014.16
   Chianese A, 2014, 2014 EIGHTH INTERNATIONAL CONFERENCE ON NEXT GENERATION MOBILE APPS, SERVICES AND TECHNOLOGIES (NGMAST), P300, DOI 10.1109/NGMAST.2014.21
   Chianese A, 2013, 2013 INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P403, DOI 10.1109/SITIS.2013.73
   Chianese A, 2013, 2013 INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P217, DOI 10.1109/SITIS.2013.46
   Chourabi H., 2012, 2012 45th Hawaii International Conference on System Sciences (HICSS), P2289, DOI 10.1109/HICSS.2012.615
   Chu SKW, 2011, ONLINE INFORM REV, V35, P581, DOI 10.1108/14684521111161945
   D'Amico G, 2013, 1 INT WORKSH INT US
   Dunwell I, 2013, 1 INT WORKSH INT DIG
   Eleftheria CA, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON INFORMATION, INTELLIGENCE, SYSTEMS AND APPLICATIONS (IISA 2013), P70
   Floch J, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 2: ANALYSIS & INTERPRETATION THEORY, METHODOLOGIES, PRESERVATION & STANDARDS DIGITAL HERITAGE PROJECTS & APPLICATIONS, P503, DOI 10.1109/DigitalHeritage.2015.7419566
   Frankel T, 2015, J INTERNET SERV APPL, V6, DOI 10.1186/s13174-015-0040-6
   Garau C, 2014, J URBAN TECHNOL, V21, P77, DOI 10.1080/10630732.2014.884384
   García-Crespo A, 2016, COMPUT SCI INF SYST, V13, P395, DOI 10.2298/CSIS150620006G
   Gil-Garcia JR., 2013, 14th Annual International Conference on Digital Government Research, P296, DOI [DOI 10.1145/2479724.2479728, 10.1145/2479724.2479728]
   Giuffrè T, 2012, PROCD SOC BEHV, V53, P16, DOI 10.1016/j.sbspro.2012.09.856
   Godwin-Jones R, 2011, LANG LEARN TECHNOL, V15, P2
   Hjorth-Andersen C, 2007, J CULT ECON, V31, P235, DOI 10.1007/s10824-007-9038-7
   Hu HX, 2011, 27TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2011), P103
   Jara AJ, 2015, 2015 IEEE 29TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS WAINA 2015, P668, DOI 10.1109/WAINA.2015.169
   Jenkins H., 2009, MacArthur Foundation Reports on Digital Media
   Jin J, 2014, IEEE INTERNET THINGS, V1, P112, DOI 10.1109/JIOT.2013.2296516
   Katifori A, 2014, LECT NOTES COMPUT SC, V8832, P232, DOI 10.1007/978-3-319-12337-0_28
   Kerr A., 2003, LEV C P, P270
   Koukopoulos Dimitrios K., 2010, Journal of Multimedia, V5, P404, DOI 10.4304/jmm.5.5.404-416
   Koukopoulos D, 2014, 5TH INTERNATIONAL CONFERENCE ON INFORMATION, INTELLIGENCE, SYSTEMS AND APPLICATIONS, IISA 2014, P239, DOI 10.1109/IISA.2014.6878753
   Koukopoulos D, 2013, ELECTRON COMMER RES, V13, P129, DOI 10.1007/s10660-013-9112-5
   Krösche J, 2004, IEEE MULTIMEDIA, V11, P72, DOI 10.1109/MMUL.2004.1289043
   Lacedelli S Zardini, 2016, 104 ANN C COLL ART A
   Lee JH, 2014, TECHNOL FORECAST SOC, V89, P80, DOI 10.1016/j.techfore.2013.08.033
   Lew CL, 2013, 8 INT C CONC LIB INF, V18, P3
   LITERAT I., 2014, The Journal of Media Literacy Education, V6, P15, DOI [https://doi.org/10.23860/jmle-6-1-2, DOI 10.23860/JMLE-6-1-2]
   Mahizhnan A, 1999, CITIES, V16, P13, DOI 10.1016/S0264-2751(98)00050-X
   Mihailidis P, 2013, J INTERACT MEDIA EDU
   Nielsen J., 1993, USABILITY ENG
   Nilsson T, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2962720
   Oomen Johan., 2011, Proceedings of the 5th International Conference on Communities and Technologies, P138, DOI DOI 10.1145/2103354.2103373
   Pantelis Koutroumpis, 2013, 2013 IEEE International Conference on Big Data, P38, DOI 10.1109/BigData.2013.6691691
   Perifanou MA, 2009, COMM COM INF SC, V49, P1
   Petrinic I, 2013, SUSTAINABLE TOURISM, P147
   Raitman R, 2005, 5th IEEE International Conference on Advanced Learning Technologies, Proceedings, P702, DOI 10.1109/ICALT.2005.236
   Riedel T., 2010, 2010 Internet of Things (IOT), P1, DOI DOI 10.1109/IOT.2010.5678449
   Roes Ivo, 2009, C HUM FACT COMP SYST, P3317
   Rubino I, 2015, ACM J COMPUT CULT HE, V8, DOI 10.1145/2724723
   Shapiro JM, 2006, REV ECON STAT, V88, P324, DOI 10.1162/rest.88.2.324
   Suciu G, 2013, I C CONTR SYS COMP S, P513, DOI 10.1109/CSCS.2013.58
   Sundmaeker H., 2010, Vision and challenges for realising the internet of things, DOI DOI 10.2759/26127
   Nam T, 2012, GOV INFORM Q, V29, P12, DOI 10.1016/j.giq.2011.07.005
   Tegtmeyer R, 2013, J DIGIT HUMANIT, V2, P3
   Verma R, 2014, PROCEDIA COMPUT SCI, V32, P505, DOI 10.1016/j.procs.2014.05.454
   Wang HL, 2014, MOL MED REP, V10, P2009, DOI 10.3892/mmr.2014.2460
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   Zhou JH, 2013, INT C COMP SUPP COOP, P651, DOI 10.1109/CSCWD.2013.6581037
NR 68
TC 18
Z9 18
U1 9
U2 109
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25943
EP 25981
DI 10.1007/s11042-017-4785-8
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500022
DA 2024-07-18
ER

PT J
AU Bao, TL
   Karmoshi, S
   Ding, CH
   Zhu, M
AF Bao, Tianlong
   Karmoshi, Saleem
   Ding, Chunhui
   Zhu, Ming
TI Abnormal event detection and localization in crowded scenes based on
   PCANet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abnormal event detection; Optical flow; PCANet
ID ANOMALY DETECTION
AB Detecting and localizing abnormal events in crowded scenes still remains a challenging task among computer vision community. An unsupervised framework is proposed in this paper to address the problem. Low-level features and optical flows (OF) of video sequences are extracted to represent motion information in the temporal domain. Moreover, abnormal events usually occur in local regions and are closely linked to their surrounding areas in the spatial domain. To extract high-level information from local regions and model the relationship in spatial domain, the first step is to calculate optical flow maps and divide them into a set of non-overlapping sub-maps. Next, corresponding PCANet models are trained using the sub-maps at same spatial location in the optical flow maps. Based on the block-wise histograms extracted by PCANet models, a set of one-class classifiers are trained to predict the anomaly scores of test frames. The framework is completely unsupervised because it utilizes only normal videos. Experiments were carried out on UCSD Ped2 and UMN datasets, and the results show competitive performance of this framework when compared with other state-of-the-art methods.
C1 [Bao, Tianlong; Karmoshi, Saleem; Ding, Chunhui; Zhu, Ming] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230026, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Bao, TL (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230026, Peoples R China.
EM btl1991@mail.ustc.edu.cn; Saleem@mail.ustc.edu.cn;
   dchui@mail.ustc.edu.cn
RI Karmoshi, Saleem/ABC-6701-2020
OI Karmoshi, Saleem/0000-0002-5524-4825
FU Chinese Academy of Sciences [XDA060112030]
FX This work was supported by special funder from Chinese Academy of
   Sciences, with grant number XDA060112030.
CR Benezeth Y, 2009, PROC CVPR IEEE, P2450
   Bertini M, 2012, COMPUT VIS IMAGE UND, V116, P320, DOI 10.1016/j.cviu.2011.09.009
   Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Cong Y, 2013, IEEE T INF FOREN SEC, V8, P1590, DOI 10.1109/TIFS.2013.2272243
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fang ZJ, 2016, MULTIMED TOOLS APPL, V75, P14617, DOI 10.1007/s11042-016-3316-3
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Khalid S, 2010, PATTERN RECOGN, V43, P3636, DOI 10.1016/j.patcog.2010.05.006
   Kim J, 2009, PROC CVPR IEEE, P2913
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Raghavendra R., 2006, UNUSUAL CROWD ACTIVI
   Rasheed N, 2014, 2014 28TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P61, DOI 10.1109/WAINA.2014.18
   Sabokrou M, 2015, 151107425 CORR
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Xiao T, 2015, IEEE SIGNAL PROC LET, V22, P1477, DOI 10.1109/LSP.2015.2410031
   Xu D, 2014, NEUROCOMPUTING, V143, P144, DOI 10.1016/j.neucom.2014.06.011
   Yuan Y, 2015, IEEE T CYBERNETICS, V45, P562, DOI 10.1109/TCYB.2014.2330853
   Zhang D, 2005, PROC CVPR IEEE, P611
   Zhang YH, 2015, IEEE T CIRC SYST VID, V25, P1231, DOI 10.1109/TCSVT.2014.2355711
NR 26
TC 11
Z9 12
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23213
EP 23224
DI 10.1007/s11042-016-4100-0
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700004
DA 2024-07-18
ER

PT J
AU Lee, HY
AF Lee, Hae-Yeoun
TI Automatic photomosaic algorithm through adaptive tiling and block
   matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photomosaic; Adaptive tiling; Block matching; Euclidian distance
ID PARALLEL FRAMEWORK; HEVC
AB Mosaic refers to a technique that forms images by gathering several small materials in various colors. Because of the recent developments in digital imaging technology, photomosaic technologies that form images using photos are utilized. In this paper, we present an automatic computer algorithm that forms photomosaic images through adaptive tiling and block matching. A photo database stores photos called tiles for mosaic and their feature values. A photomosaic image is generated through separating the input image into blocks of a pre-set size, performing adaptive tiling by comparing the similarity between adjacent blocks, conducting block matching to find a similar tile in the photo database, and adjusting the intensity to enhance tile similarity within each image block. Furthermore, the quality of the photomosaic image is improved by minimizing tile redundancy in adjacent blocks and limiting the number of tiles used. In our experiment, the performance of the proposed algorithm is compared with that of Andrea mosaic, Mosaically, and Mozaika software packages. The results indicate that the proposed algorithm is excellent in quantitative and qualitative analyses.
C1 [Lee, Hae-Yeoun] Kumoh Natl Inst Technol, Dept Comp Software Engn, 1 Yangho, Gumi, Gyeongbuk, South Korea.
C3 Kumoh National University Technology
RP Lee, HY (corresponding author), Kumoh Natl Inst Technol, Dept Comp Software Engn, 1 Yangho, Gumi, Gyeongbuk, South Korea.
EM haeyeoun.lee@kumoh.ac.kr
FU Kumoh National Institute of Technology
FX This work was supported by Kumoh National Institute of Technology.
CR Allison W., 2002, P 2 INT S NONPHOTORE, P21
   [Anonymous], 2006, P EUR IT CHAPT C 200
   Battiato S, 2007, COMPUT GRAPH FORUM, V26, P794, DOI 10.1111/j.1467-8659.2007.01021.x
   Blasi GD, 2005, P INT C CENTR EUR CO, P1
   Chavan AS, 2015, P IEEE INT C INF PRO, P16
   Di Blasi G, 2005, VISUAL COMPUT, V21, P373, DOI 10.1007/s00371-005-0292-4
   Fu ZX, 2014, MULTIMED TOOLS APPL, V72, P503, DOI 10.1007/s11042-013-1387-y
   Haeberli P., 1990, P 17 ANN C COMP GRAP, P207, DOI [10.1145/97879.97902, DOI 10.1145/97879.97902]
   Hausner A, 2001, COMP GRAPH, P573, DOI 10.1145/383259.383327
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Kang D, 2013, MULTIMED TOOLS APPL, V63, P145, DOI 10.1007/s11042-012-1065-5
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Lai IJ, 2011, IEEE T INF FOREN SEC, V6, P936, DOI 10.1109/TIFS.2011.2135853
   Lama RK, 2014, MULTIMED TOOLS APPL, V73, P873, DOI 10.1007/s11042-013-1381-4
   Markus N, 2015, COMPUT GRAPH FORUM, V34, P251, DOI 10.1111/cgf.12597
   Plant W, 2013, MULTIMED TOOLS APPL, V64, P695, DOI 10.1007/s11042-011-0951-6
   Seo S, 2016, MULTIMED TOOLS APPL, V75, P12831, DOI 10.1007/s11042-015-2867-z
   Silvers R., 1997, Photomosaics
   Singh A, 2015, 2015 INTERNATIONAL CONFERENCE ON SUSTAINABLE ENERGY ENGINEERING AND APPLICATION (ICSEEA), P1, DOI 10.1109/ICSEEA.2015.7380736
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhang ZY, 2015, MULTIMED TOOLS APPL, V74, P6255, DOI [10.1007/s11042-014-2135-7, 10.1007/s11042-015-2619-0]
NR 23
TC 3
Z9 5
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24281
EP 24297
DI 10.1007/s11042-016-4175-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700051
DA 2024-07-18
ER

PT J
AU Do, MQ
   Hung, CH
   Lin, CH
AF Minh-Quoc Do
   Hung, Chien-Han
   Lin, Chang Hong
TI Robot navigation control using vision based steering wheel
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-robot interaction; Skin color fusion; Weber local descriptor;
   Support vector machine
AB Human-robot interaction has recently drawn great attention in both academic and industrial communities. Given the benefit features of human-robot interaction, this article developed a robot navigation control system with graphic user interface using user's hand positions and hand gesture recognition. A new skin color fusion of channels among several color spaces, such as RGB-H-Cr-Cb, is proposed in this research. Human face properties are taken as a reference to detect and segment the hand regions. The hand recognition module uses the Weber local descriptor cooperated with the support vector machine. In experimental results, the skin segmentation as well as hand recognition method is compared with some previous methods to demonstrate the proposed methods' flexibility and robustness to be implemented in real-time applications.
C1 [Minh-Quoc Do; Hung, Chien-Han; Lin, Chang Hong] Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei 10607, Taiwan.
C3 National Taiwan University of Science & Technology
RP Lin, CH (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei 10607, Taiwan.
EM m10202805@mail.ntust.edu.tw; m10302106@mail.ntust.edu.tw;
   chlin@mail.ntust.edu.tw
RI Lin, Chang Hong/GRE-7807-2022
OI Lin, Chang Hong/0000-0003-3646-3261
FU National Science Council [102-2221-E-011-139-]
FX This work was supported by the National Science Council under project
   No. 102-2221-E-011-139-.
CR Abdul Rahim NA, 2006, P M2USIC
   Agarwal M, 2010, 2010 INTERNATIONAL CONFERENCE ON SIGNAL ACQUISITION AND PROCESSING: ICSAP 2010, PROCEEDINGS, P310, DOI 10.1109/ICSAP.2010.51
   Basilio Jorge Alberto Marcial, 2011, Applications of Mathematics and Computer Engineering. American Conference on Applied Mathematics (AMERICAN-MATH'11). 5th WSEAS International Conference on Computer Engineering and Applications (CEA'11), P123
   Blanchette J., 2006, C++ GUI Programming with Qt 4
   Bouraoui H, 2010, P INT C COMP COMM EN, P1
   Bradski D., 2008, Learning OpenCV, V1st
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Das J, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS, P198, DOI 10.1109/CICN.2014.54
   Deng-Yuan Huang, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P1, DOI 10.1109/IIH-MSP.2009.96
   Faber Felix, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P891, DOI 10.1109/ROMAN.2009.5326326
   Gong DY, 2011, 2011 FIRST ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P589, DOI 10.1109/ACPR.2011.6166675
   Hasanuzzaman M, 2004, IEEE ROBIO 2004: PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, P413
   Issolio L, 2006, PERCEPT PSYCHOPHYS, V68, P702, DOI 10.3758/BF03208769
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Kovac J, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P144
   Lin SFD, 2013, INT J INNOV COMPUT I, V9, P3887
   Luo R. C., 2012, IECON 2012 - 38th Annual Conference of IEEE Industrial Electronics (IECON2012), P2725, DOI 10.1109/IECON.2012.6389146
   Muhammad G, 2012, INT CONF ACOUST SPEE, P1525, DOI 10.1109/ICASSP.2012.6288181
   Punchihewa A., 2011, 2011 5th International Conference on Automation, Robotics and Applications (ICARA 2011), P90, DOI 10.1109/ICARA.2011.6144862
   Raheja Jagdish Lal, 2010, Proceedings of the 2nd International Conference on Machine Learning and Computing (ICMLC 2010), P12, DOI 10.1109/ICMLC.2010.12
   Ruiz-del-Solar J, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P463, DOI 10.1109/AFGR.2004.1301576
   Takahashi S, 2011, IEEE INT CONF FUZZY, P1344
   Ullah I., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P417
   Viola P., 2001, P 2001 IEEE COMP VIS
   Wolf MT, 2013, IEEE INT CONF ROBOT, P1160, DOI 10.1109/ICRA.2013.6630718
   Yen-Ting Chen, 2007, Proceedings of the 3rd Annual IEEE Conference on Automation Science and Engineering, P527
   Zhang H, 2012, PLANT CELL TISS ORG, V110, DOI 10.1007/s11240-012-0142-9
   Zhu YM, 2014, IEEE IJCNN, P3240, DOI 10.1109/IJCNN.2014.6889481
NR 29
TC 1
Z9 1
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24569
EP 24588
DI 10.1007/s11042-016-4217-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700065
DA 2024-07-18
ER

PT J
AU Su, QT
   Chen, BJ
AF Su, Qingtang
   Chen, Beijing
TI An improved color image watermarking scheme based on Schur decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image watermark; Schur decomposition; Maximum eigenvalue
ID QR DECOMPOSITION; ROBUST WATERMARKING; ALGORITHM; SEGMENTATION; SYSTEM
AB With the rapid development of computer technology, the copyright protection of color image is becoming a more and more urgent problem. In this paper, an improved color image blind watermarking scheme based on Schur decomposition is proposed, which is different from using the binary or gray-level image as watermark. By analyzing the 4 x 4 unitary matrix U and the upper triangular matrix D of Schur decomposition, it is found that not only the embedding column c of matrix U is decided by the column of the maximum eigenvalue of the matrix D, but also the entries between the second row the c-th column and the third row the c-th column in the matrix U have strong similarity. These properties will be used for embedding watermark and extracting watermark in the blind manner. The novelty of this paper includes: 1) Using the results features obtained by Schur decomposition to embed or extract watermark with blind manner; 2) The embedded watermark is color image which has more watermark information than random sequence, binary image or gray-level image. Experimental results show that the proposed watermarking algorithm has better performance, such as in the aspects of the invisibility, robustness, computational complexity, security, capacity etc., compared with other proposed methods considered in this work.
C1 [Su, Qingtang] Ludong Univ, Sch Informat Sci & Engn, Yantai 264025, Shandong, Peoples R China.
   [Su, Qingtang; Chen, Beijing] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Ludong University; Nanjing University of Information Science &
   Technology
RP Su, QT (corresponding author), Ludong Univ, Sch Informat Sci & Engn, Yantai 264025, Shandong, Peoples R China.; Su, QT (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
EM sdytsqt@163.com
FU Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD); Jiangsu Collaborative Innovation Center on
   Atmospheric Environment and Equipment Technology (CICAEET); NNSF from
   China [61602229, 61471185, 61403180, 61572258]; Natural Science
   Foundation of Shandong Province [ZR2014FM005, ZR2016FM21, ZR2016FM13];
   Shandong Province Higher Educational Science and Technology Program
   [J14LN20]; Doctoral Foundation of Ludong University [LY2014034];
   Department of Science & Technology of Shandong Province [2013GGB01231,
   2015GSF116001]; Key Science and Technology Plan Projects of Yantai City
   [2016ZH057]
FX The research was partially supported by the Priority Academic Program
   Development of Jiangsu Higher Education Institutions (PAPD), Jiangsu
   Collaborative Innovation Center on Atmospheric Environment and Equipment
   Technology (CICAEET), NNSF from China (61602229, 61471185, 61403180,
   61572258), Natural Science Foundation of Shandong Province (ZR2014FM005,
   ZR2016FM21, ZR2016FM13), Shandong Province Higher Educational Science
   and Technology Program (J14LN20), Doctoral Foundation of Ludong
   University (LY2014034), Department of Science & Technology of Shandong
   Province (2013GGB01231, 2015GSF116001), Key Science and Technology Plan
   Projects of Yantai City (2016ZH057). The authors would like to thank
   anonymous referees for their valuable comments and suggestions which
   lead to substantial improvements of this paper.
CR [Anonymous], 2016, IEEE TIFS, DOI [10.1109/TIFS.2016.2596138, DOI 10.1109/TIFS.2016.2596138]
   [Anonymous], MATRIX COMPUTATIONS
   Chen HY, 2012, J ZHEJIANG U-SCI C, V13, P573, DOI 10.1631/jzus.C1100338
   Chen LF, 2010, OPT COMMUN, V283, P2043, DOI 10.1016/j.optcom.2010.01.009
   Chou CH, 2003, EURASIP J APPL SIG P, V2003, P32, DOI 10.1155/S1110865703211227
   Findik O, 2011, EXPERT SYST APPL, V38, P1942, DOI 10.1016/j.eswa.2010.07.126
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Guo P, 2014, J INTERNET TECHNOL, V15, P929, DOI 10.6138/JIT.2014.15.6.05
   Hu HT, 2016, AEU-INT J ELECTRON C, V70, P1374, DOI 10.1016/j.aeue.2016.07.011
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Ma TH, 2015, IEICE T INF SYST, VE98D, P902, DOI 10.1587/transinf.2014EDP7283
   Mohan B.Chandra., 2010, INT J COMPUTER ELECT, V2, P1793
   Naderahmadian Y, 2014, MULTIMED TOOLS APPL, V72, P2597, DOI 10.1007/s11042-013-1559-9
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Rawat S, 2010, 2010 IEEE 2ND INTERNATIONAL ADVANCE COMPUTING CONFERENCE, P206, DOI 10.1109/IADCC.2010.5423010
   Seddik Hassen, 2009, IECON 2009 - 35th Annual Conference of IEEE Industrial Electronics (IECON 2009), P1967, DOI 10.1109/IECON.2009.5414857
   Soleymani SH, 2017, MULTIMED TOOLS APPL, V76, P3485, DOI 10.1007/s11042-016-3734-2
   Su QT, 2014, MULTIMED TOOLS APPL, V72, P987, DOI 10.1007/s11042-013-1653-z
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2012, OPT COMMUN, V285, P1792, DOI 10.1016/j.optcom.2011.12.065
   Thorat CG, 2010, PROCEDIA COMPUT SCI, V2, P236, DOI 10.1016/j.procs.2010.11.030
   Tsai HH, 2007, INFORM SCIENCES, V177, P550, DOI 10.1016/j.ins.2006.05.002
   University of Granada. Computer Vision Group, 2012, CVG UGR IM DAT
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei-jiang Wang, 2010, 2010 Third International Workshop on Advanced Computational Intelligence (IWACI 2010), P593, DOI 10.1109/IWACI.2010.5585206
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Zhang Y, 2009, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, VOL I, P213, DOI 10.1109/ISECS.2009.207
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
NR 28
TC 32
Z9 34
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24221
EP 24249
DI 10.1007/s11042-016-4164-x
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700049
DA 2024-07-18
ER

PT J
AU Yang, CH
   Weng, CY
   Lin, YK
   Liu, KL
AF Yang, Cheng-Hsing
   Weng, Chi-Yao
   Lin, Yih-Kai
   Liu, Kuan-Liang
TI High-fidelity lossless data hiding based on predictors selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Variance; Image quality; Prediction
ID DIFFERENCE EXPANSION; SCHEME; IMAGES
AB Reversible data hiding based on prediction methods is a data hiding technique wherein secret bits can be efficiently hidden into cover images. In this paper, we propose a reversible data hiding method based on multiple prediction methods and local complexity. At each level of data hiding algorithm, we evaluate four prediction methods to decide which method should be chosen to embed secret messages. We propose two tactics to evaluate and select prediction methods. When a prediction method is chosen to perform a shifting and embedding process, a threshold based on local complexity is used to determine which pixel should join the shifting and embedding process. If the local complexity of a pixel is smaller than the threshold, the pixel will join the process; otherwise, the pixel will cease to join the process. Therefore, more pixels will avoid executing pixel shifting. Doing so results in stego-images with lower distortion. The experimental results show that our embedding capacity and quality is superior to those of other approaches.
C1 [Yang, Cheng-Hsing; Weng, Chi-Yao; Lin, Yih-Kai; Liu, Kuan-Liang] Natl Pingtung Univ, Dept Comp Sci, Pingtung 900, Taiwan.
C3 National Pingtung University
RP Weng, CY (corresponding author), Natl Pingtung Univ, Dept Comp Sci, Pingtung 900, Taiwan.
EM cyweng@mail.nptu.edu.tw
FU Ministry of Science and Technology of the Republic of China [NSC
   101-2221-E-153-002-MY2, MOST 103-2221-E-153-005, MOST
   105-2221-E-153-010]
FX This research was partially supported by the Ministry of Science and
   Technology of the Republic of China under the Grants NSC
   101-2221-E-153-002-MY2, MOST 103-2221-E-153-005, and MOST
   105-2221-E-153-010.
CR Al-Qershi Q.M., 2011, J SYST SOFTWARE, V31, P787
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Chang CC, 2010, INFORM SCIENCES, V180, P2286, DOI 10.1016/j.ins.2010.01.034
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Feng J.B., 2006, IJ Network Security, V2, P161
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fu DS, 2014, AEU-INT J ELECTRON C, V68, P933, DOI 10.1016/j.aeue.2014.04.015
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hsiao JY, 2009, SIGNAL PROCESS, V89, P556, DOI 10.1016/j.sigpro.2008.10.018
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hwang HJ, 2010, KSII T INTERNET INF, V4, P655, DOI 10.3837/tiis.2010.08.0012
   Lee CC, 2008, PATTERN RECOGN, V41, P2097, DOI 10.1016/j.patcog.2007.11.018
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Li XX, 2013, IEEE T IMAGE PROCESS, V22, P1889, DOI 10.1109/TIP.2013.2237920
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Lin CC, 2008, PATTERN RECOGN, V41, P1415, DOI 10.1016/j.patcog.2007.09.005
   Liu W, 2014, J COMPUT INF SYST, V10, P9037
   Lou DC, 2009, COMPUT STAND INTER, V31, P329, DOI 10.1016/j.csi.2008.05.009
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pan ZB, 2015, J VIS COMMUN IMAGE R, V31, P64, DOI 10.1016/j.jvcir.2015.05.005
   Shi YQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P33
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tu TY, 2015, SIGNAL PROCESS, V108, P278, DOI 10.1016/j.sigpro.2014.09.021
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Weng CY, 2013, 8 AS JOINT C INF SEC
   Yang CH, 2010, IET IMAGE PROCESS, V4, P223, DOI 10.1049/iet-ipr.2009.0316
   Yousefl S, 2007, P IEEE DEST, P487
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 33
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23699
EP 23720
DI 10.1007/s11042-016-4133-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700027
DA 2024-07-18
ER

PT J
AU Prasad, S
   Peddoju, SK
   Ghosh, D
AF Prasad, Shitala
   Peddoju, Sateesh Kumar
   Ghosh, Debashis
TI An adaptive plant leaf mobile informatics using RSSC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human mobile interaction (HMI); Best-NN; Leaf image informatics; Mobile
   vision (MV); Relative sub-image sparse coefficients (RSSC); Shape
   descriptor
ID IDENTIFICATION; CLASSIFICATION; REPRESENTATION; RETRIEVAL
AB An automated plant biometric system is now an important step in preserving nature's biodiversity. This paper presents a novel Relative Sub-image Sparse Coefficient (RSSC) algorithm for mobile devices (MDs) representing plant leaves into a mathematically compact vector for its classification. The RSSC feature vector includes local Statistical Entropy Texture (SET) information inter-related to all the sub-images within a leaf. RSSC space is merged with Gray Level Co-occurrence Matrix (GLCM) feature to refine the outputs using best-Nearest Neighbor (best-NN), designed for MDs. The experiments were performed on three different types of leaf datasets: (i) Flavia, (ii) ICL and (iii) Diseased leaf datasets. The results proves our method more accurate and better compared to other existing plant identification systems. The proposed approach is also tolerant under shape distortion caused while capturing. The mobile machine learning system for leaf image informatics is deployed on Android devices which helps botanists, agriculturists and medical biologists to recognize ubiquitously the herbs and plant species anywhere-anytime.
C1 [Prasad, Shitala; Peddoju, Sateesh Kumar] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttarakhand, India.
   [Ghosh, Debashis] Indian Inst Technol Roorkee, Dept Elect & Commun Engn, Roorkee, Uttarakhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee
RP Prasad, S (corresponding author), Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttarakhand, India.
EM shitala@ieee.org
RI Peddoju, Sateesh K/I-7249-2016; Prasad, Shitala/AAI-8449-2020
FU MHRD
FX Authors would like to thank MHRD for financially supporting S. Prasad
   throughout his PhD work at IIT Roorkee.
CR Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776
   Alajlan N, 2007, PATTERN RECOGN, V40, P1911, DOI 10.1016/j.patcog.2006.12.005
   [Anonymous], INT J ADV SCI TECHN
   [Anonymous], 2013, LECT NOTES ELECT ENG, DOI DOI 10.1007/978-94-007-6738-6_86
   Backes AR, 2010, PATTERN RECOGN, V43, P685, DOI 10.1016/j.patcog.2009.07.017
   Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85
   Barrera M, 2012, JIP, V1, P4
   C V N I, 2014, CISC VIS NETW IND GL, P1
   Clark JY, 2009, BOT J LINN SOC, V159, P300, DOI 10.1111/j.1095-8339.2008.00891.x
   Cope JS, 2012, EXPERT SYST APPL, V39, P7562, DOI 10.1016/j.eswa.2012.01.073
   Cope JS, 2010, LECT NOTES COMPUT SC, V6454, P669, DOI 10.1007/978-3-642-17274-8_65
   Deypir M, 2012, SCI IRAN, V19, P654, DOI 10.1016/j.scient.2011.09.020
   Goeau H., 2011, IMAGECLEF 2011, P0
   Goeau H., 2013, CLEF
   Govaerts R, 2001, TAXON, V50, P1085, DOI 10.2307/1224723
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hearn DJ, 2009, TAXON, V58, P934, DOI 10.1002/tax.583021
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   Laga H., 2012, 2012 INT C DIG IM CO, P1, DOI DOI 10.1109/DICTA.2012.6411702
   Lee CL, 2006, INT J IMAG SYST TECH, V16, P15, DOI 10.1002/ima.20063
   Li Y, 2006, IEEE SYS MAN CYBERN, P3890, DOI 10.1109/ICSMC.2006.384738
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Mouine S., 2013, ICMR'13 - Proceedings of the 3rd ACM International Conference on Multimedia Retrieval, P127
   Mullen RJ, 2008, LECT NOTES COMPUT SC, V5217, P251, DOI 10.1007/978-3-540-87527-7_24
   Neto JC, 2006, COMPUT ELECTRON AGR, V50, P121, DOI 10.1016/j.compag.2005.09.004
   Prasad S., 2011, 2011 2nd International Conference on Computer and Communication Technology, P646, DOI 10.1109/ICCCT.2011.6075212
   Prasad S, IEEE POTENT IN PRESS
   Prasad S., 2011, Proceedings of the Conference on Communication, Computing Security, P343, DOI 10.1145/1947940.1948012
   Prasad S, 2016, SIGNAL IMAGE VIDEO P, V10, P379, DOI 10.1007/s11760-015-0751-y
   Prasad S, 2014, IEEE WCNC, P3314, DOI 10.1109/WCNC.2014.6953083
   Prasad S, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P405, DOI 10.1109/ICIIP.2013.6707624
   Wang B, 2015, INFORM SCIENCES, V302, P132, DOI 10.1016/j.ins.2014.07.028
   Wang B, 2014, IEEE T IMAGE PROCESS, V23, P4101, DOI 10.1109/TIP.2014.2343457
   Wang Z, 2003, IEE P-VIS IMAGE SIGN, V150, P34, DOI 10.1049/ip-vis:20030160
   Warren D., 1997, Sixth International Conference on Image Processing and its Applications (Conf. Publ. No.443), P497, DOI 10.1049/cp:19970943
   White S, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P119, DOI 10.1109/TRIDUI.2006.1618281
   White S, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P291
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120
   Yanikoglu B, 2014, MACH VISION APPL, V25, P1369, DOI 10.1007/s00138-014-0612-7
   Zhao ZQ, 2015, NEUROCOMPUTING, V151, P1112, DOI 10.1016/j.neucom.2014.02.077
   Zulkifli Z., 2011, Proceedings of the 2011 11th International Conference on Hybrid Intelligent Systems (HIS 2011), P430, DOI 10.1109/HIS.2011.6122144
NR 41
TC 3
Z9 3
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21339
EP 21363
DI 10.1007/s11042-016-4040-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400046
DA 2024-07-18
ER

PT J
AU Bae, KR
   Moon, B
AF Bae, Kyeong-ryeol
   Moon, Byungin
TI An accurate and cost-effective stereo matching algorithm and processor
   for real-time embedded multimedia systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D content; Stereo matching; Algorithm cross-check; Vertical census
   transform; Hardware implementation
ID DISPARITY; IMPLEMENTATION; DESIGN; IMAGES
AB Stereo matching is a vision technique for finding three-dimensional (3D) distance information in various multimedia applications by calculating pixel disparities between the matching points of a stereo image pair captured from a stereo camera. The most important considerations in stereo matching are highly accurate results and real-time performance. Thus, this paper proposes an accurate stereo matching algorithm that uses both a census transform algorithm and the sum of absolute differences algorithm in a complementary manner and its real-time hardware architecture. In addition, the proposed algorithm uses a vertical census transform with cost aggregation (VCTCA) to reduce hardware costs while maintaining high matching accuracy. We model the proposed algorithm using C language and verify it in several environments. Using a hardware description language, we implement the proposed hardware architecture and verify it on a field-programmable gate array-based platform to confirm the cost and performance of the hardware. The experimental results show that the proposed algorithm using the VCTCA produces accurate 3D distance information in real environments and reduces the hardware complexity. Thus, the algorithm and its hardware architecture are suitable for real-time embedded multimedia systems.
C1 [Bae, Kyeong-ryeol; Moon, Byungin] Kyungpook Natl Univ, Sch Elect Engn, Daegu 41566, South Korea.
C3 Kyungpook National University
RP Moon, B (corresponding author), Kyungpook Natl Univ, Sch Elect Engn, Daegu 41566, South Korea.
EM bihmoon@knu.ac.kr
RI Moon, Byungin/ACE-5308-2022
OI Moon, Byungin/0000-0002-8102-4818
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   C-ITRC (Convergence Information Technology Research Center)
   [IITP-2015-H8601-15-1002]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the C-ITRC (Convergence Information
   Technology Research Center) (IITP-2015-H8601-15-1002) supervised by the
   IITP (Institute for Information & communications Technology Promotion).
CR [Anonymous], INT J SIGNAL PROCESS
   Banks J, 1997, TENCON IEEE REGION, P365, DOI 10.1109/TENCON.1997.647332
   Banz C, 2005, COMPUT VIS PATTERN R, V2, P807
   Chang NYC, 2010, IEEE T CIRC SYST VID, V20, P792, DOI 10.1109/TCSVT.2010.2045814
   Fife WS, 2013, IEEE T CIRC SYST VID, V23, P60, DOI 10.1109/TCSVT.2012.2203197
   Humenberger M., 2010, 2010 IEEE COMP SOC C, P77, DOI [10.1109/CVPRW.2010.5543769, DOI 10.1109/CVPRW.2010.5543769]
   Jin S, 2010, IEEE T CIRC SYST VID, V20, P15, DOI 10.1109/TCSVT.2009.2026831
   Kalomiros JA, 2011, MICROPROCESS MICROSY, V35, P496, DOI 10.1016/j.micpro.2011.04.005
   Liang CK, 2011, IEEE T CIRC SYST VID, V21, P525, DOI 10.1109/TCSVT.2011.2125570
   Ma L, 2013, P 7 INT C IM GRAPH I, P26
   MCDONNELL MJ, 1981, COMPUT VISION GRAPH, V17, P65, DOI 10.1016/S0146-664X(81)80009-3
   Minxi Jin, 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P507, DOI 10.1109/FPL.2012.6339266
   Mühlmann K, 2002, INT J COMPUT VISION, V47, P79, DOI 10.1023/A:1014581421794
   Nalpantidis L, 2011, IET IMAGE PROCESS, V5, P481, DOI 10.1049/iet-ipr.2009.0262
   Perri S, 2006, P EL CIRC SYST 2006, P10
   Tan P, 2014, IMAGE PROCESS ON LIN, V4, P252, DOI 10.5201/ipol.2014.78
   Ttofis C, 2012, DES AUT TEST EUROPE, P703
   van der Mark W, 2006, IEEE T INTELL TRANSP, V7, P38, DOI 10.1109/TITS.2006.869625
   Yang R., 2004, Computer Vision and Pattern Recognition Workshop, P36
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zhang K, 2009, IEEE T CIRCUITS SYST, V19, P533
NR 21
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17907
EP 17922
DI 10.1007/s11042-016-3248-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800018
DA 2024-07-18
ER

PT J
AU Joo, HJ
   Jeong, HY
AF Joo, Hae-Jong
   Jeong, Hwa-Young
TI Growth analysis system for IT-based plant factory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent situation recognition; Plant growth measurement; NIR;
   Reflectance
ID HEAT
AB In this paper, based on core technologies such as overcoming a place's limitations, light that can substitute for the sunlight, automation, nutrient supply system and temperature, and intelligent situation recognition for solar power generation, geothermal HVAC (heating, ventilating, and air conditioning), a plant growth analysis system for vegetation factories was designed. The system is likely to improve the freshness of agricultural products through order and planned productions, to create new markets through the convergence of the IT and BT industries, and to promote convenience in farming and comfort in workspaces through automatic control, robot development, etc. In addition, the system is expected to offer opportunities for urban residents to experience and learn the whole process of a plant's growth; to provide a leisurely life, such as a downtown oasis, to those who are tired of the dreary city life; to prevent environmental pollution through the effective use of recycled resources; and to produce and stably supply diverse agricultural products all year round, regardless of the weather. Also, we propose a medical condition measurement, including the water content of the plant leaf using the reflected light of the plant leaf in the visible light range NIR(near infrared) region. Proposed a result, the image coordinates (X, Y) for an analysis of a specific wavelength by the refractive index (Z) of a specific wavelength in a specific disease and plants having common characteristics and the refractive index distribution of the refractive index outside the selective wavelength of the plant leaf with respect to the plant were classified by using a specific disease and to predict the characteristics of a plant stress. Therefore, the visible light region and the absorption region due to the moisture including the NIR region 1.4 [mu m] by utilizing the reflectance of the wavelength was measured by the change in the abnormal activity in normal metabolic activity and diseases of the plants leaves.
C1 [Joo, Hae-Jong] Dongguk Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, Seoul, South Korea.
C3 Dongguk University; Kyung Hee University
RP Jeong, HY (corresponding author), Kyung Hee Univ, Humanitas Coll, Seoul, South Korea.
EM hjjoo@dongguk.edu; hyjeong@khu.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR Arroyo JP, 2015, BACK BASICS PHYSL O2, P1
   Bhandari AK, 2012, PROC TECH, V1, P612, DOI 10.1016/j.protcy.2012.10.074
   Chung S, 2007, APPL MICROBIOL BIOT, V76, P217, DOI 10.1007/s00253-007-0992-y
   Devices Analog, 2003, AD2S1200 12 BIT R D, P1
   Devices Analog, 1990, US ADSP 2100 FAM, V1, P51
   Dong C, 2015, ACTA ASTRONAUT, V111, P102, DOI 10.1016/j.actaastro.2015.02.021
   Ellis G., 2001, P PCIM EUR 2001 C NU
   Farokhi S, 2015, INFORM SCIENCES, V316, P234, DOI 10.1016/j.ins.2015.04.030
   Fischer T, 2012, FLORA, V207, P159, DOI 10.1016/j.flora.2012.01.001
   Gwenzi W, 2011, GEODERMA, V166, P43, DOI 10.1016/j.geoderma.2011.06.010
   Hoseinnezhad R, 2005, IEEE DECIS CONTR P, P7020
   Hu DW, 2016, ECOL MODEL, V319, P208, DOI 10.1016/j.ecolmodel.2015.06.020
   Idris EE, 2007, MOL PLANT MICROBE IN, V20, P619, DOI 10.1094/MPMI-20-6-0619
   Kim YC, 2014, KAIS C, V15, P210
   KNIPLING E B, 1970, Remote Sensing of Environment, V1, P155
   Murase H, 2015, AGRIC AGRIC SCI PROC, V3, P4, DOI 10.1016/j.aaspro.2015.01.003
   Oerke EC, 2006, J EXP BOT, V57, P2121, DOI 10.1093/jxb/erj170
   Orf GS, 2013, PHOTOSYNTH RES, V116, P315, DOI 10.1007/s11120-013-9869-3
   Slaton MR, 2001, AM J BOT, V88, P278, DOI 10.2307/2657019
   Texas Instruments, 2000, SPRA605 TEX INSTR
   Togawa T, 2014, J CLEAN PROD, V81, P60, DOI 10.1016/j.jclepro.2014.06.010
   Yang XJ, 2015, SENSOR ACTUAT B-CHEM, V220, P1361, DOI 10.1016/j.snb.2015.07.057
   Zhang P, 2015, SPECTROCHIM ACTA A, V149, P166, DOI 10.1016/j.saa.2015.04.012
NR 23
TC 6
Z9 6
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17785
EP 17799
DI 10.1007/s11042-015-3092-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800011
DA 2024-07-18
ER

PT J
AU Neto, OPS
   Silva, AC
   Paiva, AC
   Gattass, M
AF Neto, Otilio Paulo S.
   Silva, Aristofanes C.
   Paiva, Anselmo C.
   Gattass, Marcelo
TI Automatic mass detection in mammography images using particle swarm
   optimization and functional diversity indexes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Particle swarm optimization; Graph clustering; Functional
   diversity indexes
ID COMPUTER-AIDED DETECTION; FEATURES; LESIONS
AB This paper proposes a computational method to assist in detection of masses in dense and non-dense breasts on mammography images. The proposed methodology is divided into six steps. In summary, the first step consist of the images acquisition that was obtained from the Digital Database for Screening Mammography (DDSM). In the second step, a preprocessing is performed in order to remove noises and enhance the images. In the third step, the segmentation is performed to find the regions of interest (ROIs) that are candidates for masses using Particle Swarm Optimization (PSO). The fourth step consists in the first false positives reduction based on reduction by distance and Graph Clustering. The fifth step is the second false positive reduction based on texture features using functional diversity indexes. Finally, in the sixth step, the support vector machine (SVM) is used to classify ROIs in whether mass or non-mass. The best results were found in case of dense breast tissue, resulting in a sensitivity of 97.52%, specificity of 92.28%, accuracy of 94.82%, false positives rate per image of 0.38 and free-curve receiver operating characteristic of 0.98.
C1 [Neto, Otilio Paulo S.] Fed Inst Piaui, Teresina, Brazil.
   [Neto, Otilio Paulo S.; Silva, Aristofanes C.; Paiva, Anselmo C.] Univ Fed Maranhao, Sao Luis, Brazil.
   [Gattass, Marcelo] Pontifical Catholic Univ Rio de Janeiro, Rio De Janeiro, Brazil.
C3 Instituto Federal do Piaui (IFPI); Universidade Federal do Maranhao;
   Pontificia Universidade Catolica do Rio de Janeiro
RP Neto, OPS (corresponding author), Fed Inst Piaui, Teresina, Brazil.; Neto, OPS (corresponding author), Univ Fed Maranhao, Sao Luis, Brazil.
EM otilio.paulo@ifpi.edu.br
RI Paiva, Anselmo/L-2358-2013
OI Paiva, Anselmo/0000-0003-4921-0626
FU Federal Institute of Piaui (IFPI); Coordination for the Improvement of
   Higher Education Personnel (CAPES); National Council for Scientific and
   Technological Development (CNPq); Foundation for the Protection of
   Research and Scientific, Technological Development of the State of
   Maranhao (FAPEMA)
FX The authors acknowledge the Federal Institute of Piaui (IFPI),
   Coordination for the Improvement of Higher Education Personnel (CAPES),
   National Council for Scientific and Technological Development (CNPq) and
   the Foundation for the Protection of Research and Scientific,
   Technological Development of the State of Maranhao (FAPEMA) for
   financial support.
CR [Anonymous], 2014, EST INC CANC BRAS
   [Anonymous], 2000, P 5 INT WORKSH DIG M
   Bose J. Subhash Chandra, 2010, International Journal of Computer and Network Security, V2, P78
   Boyle P., 2008, WORLD CANC REPORT
   Braz JG, 2014, THESIS
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   de Sampaio WB, 2015, EXPERT SYST APPL, V42, P8911, DOI 10.1016/j.eswa.2015.07.046
   Dong M, 2015, J DIGIT IMAGING, V28, P1
   Eleyan A, 2011, TURK J ELECTR ENG CO, V19, P97, DOI 10.3906/elk-0906-27
   Gao XB, 2010, IEEE T INF TECHNOL B, V14, P266, DOI 10.1109/TITB.2009.2036167
   Giger ML, 2000, COMPUT SCI ENG, V2, P39, DOI 10.1109/5992.877391
   Gonzales R, 2010, PROCESSAMENTO DIGITA
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hu K, 2011, IEEE T INSTRUM MEAS, V60, P462, DOI 10.1109/TIM.2010.2051060
   Ke L, 2010, INT CONF BIOMED, P354, DOI 10.1109/BMEI.2010.5639515
   Kennedy James., 2010, Particle Swarm Optimization, P760, DOI DOI 10.1007/978-0-387-30164-8_630
   Liu X., 2011, J SHANDONG WOMENS U, V4, P1
   McPherson K, 2000, BMJ-BRIT MED J, V321, P624, DOI 10.1136/bmj.321.7261.624
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Petchey OL, 2006, ECOL LETT, V9, P741, DOI 10.1111/j.1461-0248.2006.00924.x
   Qian W, 2007, ACAD RADIOL, V14, P530, DOI 10.1016/j.acra.2007.01.012
   Sampaio WB, 2011, COMPUT BIOL MED, V41, P653, DOI 10.1016/j.compbiomed.2011.05.017
   Schaeffer SE, 2007, COMPUT SCI REV, V1, P27, DOI 10.1016/j.cosrev.2007.05.001
   Society AAC, 2013, LEARN BREAST CANC
   Tilman D., 2001, Functional Diversity, P109, DOI [DOI 10.1016/B0-12-226865-2/00132-2, 10.1016/B0-12-226865-2/00132-2]
   Tzikopoulos SD, 2011, COMPUT METH PROG BIO, V102, P47, DOI 10.1016/j.cmpb.2010.11.016
   van der Merwe D, 2003, IEEE C EVOL COMPUTAT, P215, DOI 10.1109/CEC.2003.1299577
   van Engeland S, 2007, MED PHYS, V34, P898, DOI 10.1118/1.2436974
   Wang XW, 2012, ACAD RADIOL, V19, P303, DOI 10.1016/j.acra.2011.10.026
   Wei J, 2011, MED PHYS, V38, P1867, DOI 10.1118/1.3560462
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Wu YT, 2007, MED PHYS, V34, P3334, DOI 10.1118/1.2756612
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 33
TC 9
Z9 9
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 19263
EP 19289
DI 10.1007/s11042-017-4710-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800051
DA 2024-07-18
ER

PT J
AU Yuan, M
   Sheng, H
AF Yuan, Min
   Sheng, Hui
TI Research on the fusion method of spatial data and multimedia information
   of multimedia sensor networks in cloud computing environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia sensor network; Spatial data; Multimedia information; Fusion;
   Cloud computing environment
ID ALGORITHM
AB In the process of fusing spatial data and multimedia information of multimedia sensor networks in cloud computing environment, prone to transmit the repeated information many times, the energy consumption of multimedia sensor networks is increased, therefore, this paper proposes a new fusion method for spatial data and multimedia information in cloud computing environment, considering the difference between spatial data and multimedia information characteristics, fusion process is performed respectively. The principle of Laplacian pyramid transform spatial data fusion is adopted and combined the spatial real image features in multimedia sensor networks, to propose a region based fusion method using image information as spatial data fusion characteristics, and the spatial data of different polarization modes are fused. For the integration of multimedia information, the SIFT algorithm is used to extract and match feature points for the image collected in adjacent multimedia sensor networks, to determine the overlap regions between images of larger relevance, the boundary of best image overlap region is selected via optimization approach, the weighted fusion method is utilized to fuse the overlap regions of multimedia information. The experimental results show that the proposed method has high fusion performance and high fusion accuracy.
C1 [Yuan, Min] Yancheng Inst Technol, Dept Informat Engn, Yancheng 224000, Jiangsu, Peoples R China.
   [Sheng, Hui] Yancheng Inst Technol, Coll English Dept, Yancheng 224051, Jiangsu, Peoples R China.
C3 Yancheng Institute of Technology; Yancheng Institute of Technology
RP Sheng, H (corresponding author), Yancheng Inst Technol, Coll English Dept, Yancheng 224051, Jiangsu, Peoples R China.
EM yuanm@ycit.cn
CR Altarawneh R, 2015, YEAST, V11, P1439
   Amiri A, 2016, CR MATH, V354, P205, DOI 10.1016/j.crma.2015.10.010
   [Anonymous], 2016, J SUPERCOMPUT
   Bera R, 2015, IAHS-AISH P, V368, P9
   Berrahou L, 2015, COMPUT GEOSCI-UK, V85, P126, DOI 10.1016/j.cageo.2015.09.012
   Bhatt R, 2015, WIREL NETW, P1
   Chen J, 2016, BIOSYSTEMS, V139, P37, DOI 10.1016/j.biosystems.2015.12.002
   D'Souza V, 2016, NEUROSCI LETT, V323, P113
   Fallahpour A, 2015, J LIGHTWAVE TECHNOL, V33, P4008, DOI 10.1109/JLT.2015.2461449
   Guruprasad H, 2014, J UROLOGY, V157, P952
   Hatton W, 2015, ANN INTERN MED, V69, P963
   Huang X, 2016, INT J GEOGR INF SCI, V30, P1426, DOI 10.1080/13658816.2015.1133819
   Kalabokidis K, 2014, INT J GEOGR INF SCI, V28, P541, DOI 10.1080/13658816.2013.858257
   Lawson AB, 2015, ENVIRONMETRICS, V26, P383, DOI 10.1002/env.2346
   Lee WP, 2014, BMC SYST BIOL, V8, DOI 10.1186/1752-0509-8-5
   Lisitsin V, 2015, ORE GEOL REV, V71, P861, DOI 10.1016/j.oregeorev.2015.05.019
   Liu X, 2015, ACTA PHYS SINICA, V64, P76201
   Mazher A, 2016, INT J REMOTE SENS, V37, P14, DOI 10.1080/2150704X.2015.1109158
   Melgar VMA, 2015, J IND ENG CHEM, V28, P1
   Mogouie K, 2015, J STRUCT GEOL, V22, P841
   Qi S, 2015, MULTIMEDIA SYSTEMS, P1
   Tang Z, 2014, J SUPERCOMPUT, V70, P1279, DOI 10.1007/s11227-014-1227-5
   Ugarte MDS, 2015, BIOMETRICS, V71, p[135, 274]
   Xu JD, 2015, COMPUT GEOSCI-UK, V85, P115, DOI 10.1016/j.cageo.2015.09.022
   Yousef A, 2015, J THEOR BIOL, V383, P12, DOI 10.1016/j.jtbi.2015.07.010
NR 25
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17037
EP 17054
DI 10.1007/s11042-016-3672-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500009
DA 2024-07-18
ER

PT J
AU Lou, J
   Zhu, W
   Wang, H
   Ren, MW
AF Lou, Jing
   Zhu, Wei
   Wang, Huan
   Ren, Mingwu
TI Small target detection combining regional stability and saliency in a
   color image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Small target detection; Stable region; Visual saliency; Color image
AB In this paper, we will address the issue of detecting small target in a color image from the perspectives of both stability and saliency. First, we consider small target detection as a stable region extraction problem. Several stability criteria are applied to generate a stability map, which involves a set of locally stable regions derived from sequential boolean maps. Second, considering the local contrast of a small target and its surroundings, we obtain a saliency map by comparing the color vector of each pixel with its Gaussian blurred version. Finally, both the stability and saliency maps are integrated in a pixel-wise multiplication manner for removing false alarms. In addition, we introduce a set of integration models by combining several existing stability and saliency methods, and use them to indicate the validity of the proposed framework. Experimental results show that our model adapts to target size variations and performs favorably in terms of precision, recall and F-measure on three challenging datasets.
C1 [Lou, Jing; Zhu, Wei; Wang, Huan; Ren, Mingwu] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Ren, MW (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM jinglou@gmail.com; zw_njust@163.com; wanghuanphd@njust.edu.cn;
   mingwuren@163.com
RI Lou, Jing/B-3258-2011
OI Lou, Jing/0000-0001-8502-7429
FU National Natural Science Foundation of China [61231014]
FX The authors thank all of the anonymous reviewers for their insights and
   suggestions, which were very helpful in improving this manuscript. They
   thank Haiyang Zhang for useful discussions. They also thank Mei Zhang
   and Huaiping Zhang for their kind proofreading of the manuscript. This
   work is supported by the National Natural Science Foundation of China
   under Grant 61231014.
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Bae TW, 2012, INFRARED PHYS TECHN, V55, P137, DOI 10.1016/j.infrared.2011.10.006
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Chen CLP, 2014, IEEE T GEOSCI REMOTE, V52, P574, DOI 10.1109/TGRS.2013.2242477
   Chen HY, 2012, MULTIMED TOOLS APPL, V60, P495, DOI 10.1007/s11042-011-0820-3
   Dragon R, 2013, LECT NOTES COMPUT SC, V8142, P425, DOI 10.1007/978-3-642-40602-7_45
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Gao CQ, 2013, IEEE T IMAGE PROCESS, V22, P4996, DOI 10.1109/TIP.2013.2281420
   Kim S, 2012, PATTERN RECOGN, V45, P393, DOI 10.1016/j.patcog.2011.06.009
   Lee E, 2015, OPT REV, V22, P659, DOI 10.1007/s10043-015-0110-9
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li W, 2009, IEEE IMAGE PROC, P957, DOI 10.1109/ICIP.2009.5414028
   Li Y, 2014, MULTIMED TOOLS APPL, V71, P1179, DOI 10.1007/s11042-012-1258-y
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qi SX, 2013, IEEE GEOSCI REMOTE S, V10, P495, DOI 10.1109/LGRS.2012.2211094
   Rumsey D., 2002, MAPPING W, P12
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang W, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P643
   Zhou CB, 2015, MULTIMED TOOLS APPL, V74, P5623, DOI 10.1007/s11042-014-1871-z
   Zhu B, 2015, INFRARED PHYS TECHN, V69, P136, DOI 10.1016/j.infrared.2015.01.020
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 27
TC 28
Z9 28
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14781
EP 14798
DI 10.1007/s11042-016-4025-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400013
DA 2024-07-18
ER

PT J
AU Adhikary, T
   Das, AK
   Razzaque, MA
   Alrubaian, M
   Hassan, MM
   Alamri, A
AF Adhikary, Tamal
   Das, Amit Kumar
   Razzaque, Md. Abdur
   Alrubaian, Majed
   Hassan, Mohammad Mehedi
   Alamri, Atif
TI Quality of service aware cloud resource provisioning for social
   multimedia services and applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia healthcare applications; Ubiquitous social media computing;
   Resource provisioning; Collaborative resource utilization; Quality of
   service
ID MANAGEMENT; GREEN
AB The increasing number of next-generation multimedia services and social media applications in cloud computing put additional challenges in efficient resource provisioning that targets to minimize under or over utilization of resources as well as to increase user satisfaction. Most of the works in the literature focused either on resource estimation and scheduling approaches or energy consumption for executing social media data processing applications. However, they do not consider energy consumption cost for communication devices and network appliances and schedule Virtual Machines (VMs) based on centralized job placement approach. In this paper, we develop a Quality of Service (QoS) aware cloud resource management system that decreases energy consumption and increases resource utilization by diverse multimedia social applications. In order to minimize the VM creation time we allow recycling of VM resources for user request with similar resource requirements. We have developed two distributed and localized resource management algorithms based on energy conservation, and requirements and availability of resources. The results of simulation experiments depict that the resource scheduling system greatly reduces the amount of energy consumption while maintaining the QoS of social multimedia applications.
C1 [Adhikary, Tamal; Das, Amit Kumar; Razzaque, Md. Abdur] Univ Dhaka, Dept Comp Sci & Engn, Green Networking Res Grp, Dhaka, Bangladesh.
   [Alrubaian, Majed; Hassan, Mohammad Mehedi; Alamri, Atif] King Saud Univ, Coll Comp & Informat Sci, Res Chair Pervas & Mobile Comp, Riyadh, Saudi Arabia.
C3 University of Dhaka; King Saud University
RP Razzaque, MA (corresponding author), Univ Dhaka, Dept Comp Sci & Engn, Green Networking Res Grp, Dhaka, Bangladesh.
EM tamal.csedu@gmail.com; amit.csedu@gmail.com; razzaque@du.ac.bd;
   malrubaian.c@ksu.edu.sa; mmhassan@ksu.edu.sa; atif@ksu.edu.sa
RI Alamri, Atif/KFQ-0028-2024; Hassan, Mohammad/KDM-9524-2024; Das, Amit
   Kumar/X-9055-2019; Hassan, Mohammad/GZA-7507-2022; Hassan, Mohammad
   Mehedi/D-4946-2016
OI Alamri, Atif/0000-0002-1887-5193; Das, Amit Kumar/0000-0002-2600-8321;
   Hassan, Mohammad/0000-0002-1712-0004; 
FU King Saud University through Vice Deanship of Research Chairs
FX This project was full financially supported by the King Saud University,
   through Vice Deanship of Research Chairs.
CR Adhikary T, 2014, P ACM IMCOM 2014 SEI
   Adhikary T, 2013, IEEE HPCC 2013
   Adhikary T, 2016, MOBILE NETW APPL, V21, P482, DOI 10.1007/s11036-015-0657-5
   [Anonymous], 2008, REVOLUTIONIZING DATA
   Baliga J, 2011, P IEEE, V99, P149, DOI 10.1109/JPROC.2010.2060451
   Beloglazov A., 2010, 10 IEEE ACM INT C CL
   Bi J., 2010, P 3 INT C CLOUD COMP
   Calheiros RN, 2011, CLOUD COMP ENV INT C
   Calheiros RN, 2011, SOFTWARE PRACT EXPER, V41, P23, DOI 10.1002/spe.995
   Chang JM, 2012, IEEE SYST J, V6, P584, DOI 10.1109/JSYST.2011.2177131
   Das AK, 2013, INT C INF NETW ICOIN
   Djemame K., 2007, 1 INT WORKSH VER EV
   Emeneker W, 2012, INT J AD HOC UBIQ CO, V10, P84, DOI 10.1504/IJAHUC.2012.048260
   Fang Q, 2015, IEEE T MULTIMEDIA, V17, P1031, DOI 10.1109/TMM.2015.2430819
   Gain B, 2016, CLOUD COMPUTING SAAS
   Hassan MM, 2014, COST EFFECTIVE RESOU
   Hassan MM, 2014, KSII T INTERNET INF, V8, P1567
   Hefeeda M, 2015, IEEE T MULTIMEDIA, V17, P420, DOI 10.1109/TMM.2015.2389628
   Hossain MS, 2016, MOBILE NETW APPL, V21, P753, DOI 10.1007/s11036-016-0685-9
   Hossain MS, 2016, COMPUT NETW, V101, P192, DOI 10.1016/j.comnet.2016.01.009
   Knauth T, 2012, INT CONF CLOUD COMP
   Lai CF, 2013, IEEE T MULTIMEDIA, V15, P747, DOI 10.1109/TMM.2013.2240270
   Lee Y., 2010, P 10 IEEE ACM INT C
   Liu L, 2013, J INTERNET TECHNOL, V14, P413, DOI 10.6138/JIT.2013.14.3.06
   Lu P, 2015, IEEE T MULTIMEDIA, V17, P1297, DOI 10.1109/TMM.2015.2441004
   Mahmud MR, 2016, WILEY INTERSCIENCE S
   Moreno IS, 2011, IEEE INT C SERV OR C
   Nathuji Ripal, 2007, Operating Systems Review, V41, P265, DOI 10.1145/1323293.1294287
   Oberheide J, 2008, EXPLOITING LIVE VIRT
   Rodero-Merino L, 2010, FUTURE GENER COMP SY, V26, P1226, DOI 10.1016/j.future.2010.02.013
   Shy O, 2011, OVERBOOKING PRICE
   Velte AT, CLOUD COMPUTING BASI, P3
   VMware, 2009, IN073PRD0101 VM WAR
   Wang LZ, 2012, INT J AD HOC UBIQ CO, V10, P96, DOI 10.1504/IJAHUC.2012.048261
   Wen Gaojin, 2011, INT C CLOUD SERV COM
   Wen YG, 2014, IEEE T MULTIMEDIA, V16, P885, DOI 10.1109/TMM.2014.2315596
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P346, DOI 10.1109/TMM.2015.2393635
   Zeng H, ACM SIGPLAN NOT, V37, P132
   Zhang P, 2011, CLOUD COMP P IEEE CC
NR 39
TC 15
Z9 15
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14485
EP 14509
DI 10.1007/s11042-016-3852-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800035
DA 2024-07-18
ER

PT J
AU Subudhi, BN
   Ghosh, S
   Nanda, PK
   Ghosh, A
AF Subudhi, Badri Narayan
   Ghosh, Susmita
   Nanda, Pradipta Kumar
   Ghosh, Ashish
TI Moving object detection using spatio-temporal multilayer compound Markov
   Random Field and histogram thresholding based change detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; MAP estimation; Modeling; Simulated annealing;
   Object detection; Tracking; Image motion analysis; Image edge analysis
ID VIDEO SEGMENTATION; LOW-RANK; IMAGE; RECOGNITION; ALGORITHM; REGIONS
AB In this article, we propose a Multi Layer Compound Markov Random Field (MLCMRF) Model to spatially segment different image frames of a given video sequence. The segmented image frames are combined with the change between the frames to detect the moving objects from a video. The proposed MLCMRF uses five Markov models in a single framework, one in spatial direction using color feature, four in temporal direction (using two color features and two edges/line fields). Hence, the proposed MLCMRF is a combination of spatial distribution of color, temporal color coherence and edge maps in the temporal frames. The use of such an edge preserving model helps in enhancing the object boundary in spatial segmentation and hence can detect moving objects with less effect of silhouette. A difference between the frames is used to generate the CDM and is subsequently updated with the previous frame video object plane (VOP) and the spatial segmentation of the consecutive frames, to detect the moving objects from the target image frames. Results of the proposed spatial segmentation approach are compared with those of the existing state-of-the-art techniques and are found to be better.
C1 [Subudhi, Badri Narayan] Natl Inst Technol Goa, Dept Elect & Commun Engn, Ponda 403401, Goa, India.
   [Ghosh, Susmita] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
   [Nanda, Pradipta Kumar] Siksha O Anusandhan Univ, Dept Elect & Telecommun Engn ITER, Bhubaneswar 751030, Orissa, India.
   [Ghosh, Ashish] Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Goa; Jadavpur University; Siksha 'O' Anusandhan University;
   Indian Statistical Institute; Indian Statistical Institute Kolkata
RP Ghosh, A (corresponding author), Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, India.
EM subudhi.badri@gmail.com; susmitaghoshju@gmail.com;
   pknanda_13@yahoo.co.in; ash@isical.ac.in
RI Nanda, Pradipta/AAV-1203-2021; Ghosh, Shamik/M-9976-2016; Nanda,
   Pradipta/CAH-2467-2022; SUBUDHI, BADRI N/B-6830-2013
OI SUBUDHI, BADRI N/0000-0002-4378-0065; GHOSH, ASHISH/0000-0003-1548-5576;
   GHOSH, SUSMITA/0000-0002-1691-761X; , prof. Pradipta Kumar
   Nanda/0000-0002-6147-5267
CR [Anonymous], 2012, HDB SOFT COMPUT VIDE
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2001, COMP SCI W
   Babacan SD, 2007, INT CONF ACOUST SPEE, P1065
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Benedek C, 2009, IEEE T IMAGE PROCESS, V18, P2303, DOI 10.1109/TIP.2009.2025808
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Bovic AL, 2000, HDB IMAGE VIDEO PROC
   Cho JH, 2004, ELECTRON LETT, V40, P1109, DOI 10.1049/el:20045316
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Ghosh A, 2014, APPL SOFT COMPUT, V15, P121, DOI 10.1016/j.asoc.2013.10.021
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   HINDS RO, 1995, INT CONF ACOUST SPEE, P2427, DOI 10.1109/ICASSP.1995.479983
   Huang SS, 2007, IEEE T IMAGE PROCESS, V16, P1446, DOI 10.1109/TIP.2007.894246
   Hwang SW, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P383, DOI 10.1109/ICIP.2001.958508
   Kim EY, 2006, PATTERN RECOGN LETT, V27, P1252, DOI 10.1016/j.patrec.2005.07.023
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Lee DS, 2010, OPT EXPRESS, V18, P10659, DOI 10.1364/OE.18.010659
   Lin WY, 2008, IEEE T CIRC SYST VID, V18, P1128, DOI 10.1109/TCSVT.2008.927111
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Liu X, 2013, NEUROCOMPUTING, V119, P439, DOI 10.1016/j.neucom.2013.03.013
   Luthon F, 1999, SIGNAL PROCESS, V76, P61, DOI 10.1016/S0165-1684(98)00247-3
   Oneata D, 2014, LECT NOTES COMPUT SC, V8691, P737, DOI 10.1007/978-3-319-10578-9_48
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Palaniappan K, 2011, P 14 INT C INF FUS, P535
   Qiao YL, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/138065
   Rapantzikos K, 2009, SIGNAL PROCESS-IMAGE, V24, P557, DOI 10.1016/j.image.2009.03.002
   Rougier C, 2011, IEEE T CIRC SYST VID, V21, P611, DOI 10.1109/TCSVT.2011.2129370
   Salembier P, 1999, IEEE T CIRC SYST VID, V9, P1147, DOI 10.1109/76.809153
   SASAKI GH, 1988, J ACM, V35, P387, DOI 10.1145/42282.46160
   Satake J., 2009, ICRA Workshop on People Detection and Tracking, P1
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Stolkin R, 2008, IMAGE VISION COMPUT, V26, P480, DOI 10.1016/j.imavis.2007.06.008
   Su T.-F., 2011, P ACCV, V6494, P535, DOI 10.1007/978-3-642-19318-7
   Teixeira Luis F., 2007, Journal of Multimedia, V2, P55, DOI 10.4304/jmm.2.5.55-65
   Tekalp A.M., 1995, DIGITAL VIDEO PROCES
   Wang R, 2014, IEEE COMPUT SOC CONF, P420, DOI 10.1109/CVPRW.2014.68
   Wu GK, 1999, IEEE T CIRC SYST VID, V9, P798, DOI 10.1109/76.780367
   Xu D, 2006, IEEE T CIRC SYST VID, V16, P896, DOI 10.1109/TCSVT.2006.877418
   Zhang Y.J., 2006, Advances in image and video segmentation
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 45
TC 11
Z9 12
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13511
EP 13543
DI 10.1007/s11042-016-3698-2
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900027
DA 2024-07-18
ER

PT J
AU Islam, MS
   Alajlan, N
AF Islam, Md Saiful
   Alajlan, Naif
TI Biometric template extraction from a heartbeat signal captured from
   fingers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heartbeat biometrics; Remote authentication; Information security;
   Privacy; Heartbeat selection; Morphology alignment
ID 3D FACE RECOGNITION; HUMAN IDENTIFICATION; TECHNOLOGY; DISTANCE
AB Authentication of remote users is very important for security and privacy of multimedia content that is often accessed online. Heartbeat signal has emerged as biometric modality suitable for remote authentication for its privacy and liveness property. In order to improve acceptability of this modality, we propose a method of biometric template extraction from a heartbeat signal captured from fingers. An unsupervised outlier detection method is employed to select the most regular heartbeats from a specimen. In order to mitigate the effect of heart rate variability (HRV), morphology of the selected heartbeat is aligned by a piecewise-uniform method. Then, a template is formed by averaging aligned heartbeats and presented in a lower dimensional space by the principal component analysis. Authentication performance of the template was evaluated using a database collected from 112 individuals in multiple sessions by a handheld ECG device. We also implemented four state-of-the-art templates and tested them by the same database. Experimental results indicate that authentication performance of the proposed template is superior to those of any of these templates. It is also suitable for remote authentication using mobile computing devices for its computational efficiency and compactness.
C1 [Islam, Md Saiful] King Saud Univ, Dept Comp Sci, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.
   [Alajlan, Naif] King Saud Univ, Dept Comp Engn, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.
C3 King Saud University; King Saud University
RP Islam, MS (corresponding author), King Saud Univ, Dept Comp Sci, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.
EM saislam@ksu.edu.sa
RI Alajlan, Naif/A-3904-2008; Islam, Saiful/B-9632-2012
OI Alajlan, Naif/0000-0003-1846-1131; Islam, Saiful/0000-0002-2670-6007
FU Deanship of Scientific Research of the King Saud University through the
   International Research Group [IRG14-20]
FX This work was supported by the Deanship of Scientific Research of the
   King Saud University through the International Research Group under
   Project IRG14-20.
CR Agrafioti F, 2009, SIGNAL IMAGE VIDEO P, V3, P329, DOI 10.1007/s11760-008-0073-4
   [Anonymous], 2007, 9 INT C E HLTH NETW
   [Anonymous], 2012, Second Generation Biometrics: the Ethical, Legal and Social Context
   Arzeno NM, 2008, IEEE T BIO-MED ENG, V55, P478, DOI 10.1109/TBME.2007.912658
   Ben-Gal I, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P117, DOI 10.1007/978-0-387-09823-4_7
   Biel L, 2001, IEEE T INSTRUM MEAS, V50, P808, DOI 10.1109/19.930458
   Boumbarov O, 2009, INT WORKSH INT DATA, P446, DOI 10.1109/IDAACS.2009.5342942
   Briassouli A., 2015, Health Monitoring and Personalized Feedback using Multimedia Data, P1
   Chan ADC, 2008, IEEE T INSTRUM MEAS, V57, P248, DOI 10.1109/TIM.2007.909996
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Fang SC, 2009, PATTERN RECOGN, V42, P1824, DOI 10.1016/j.patcog.2008.11.020
   Fatemian S.Z., 2009, 2009 16 INT C DIG SI, P1
   Fratini A, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0072-y
   Galbally J, 2012, FUTURE GENER COMP SY, V28, P311, DOI 10.1016/j.future.2010.11.024
   Gökberk B, 2009, ADV PATTERN RECOGNIT, P217, DOI 10.1007/978-1-84882-385-3_9
   Hahn C, 2016, MULTIMED TOOLS APPL, V75, P13057, DOI 10.1007/s11042-015-2593-6
   Irvine JM, 2008, PATTERN RECOGN, V41, P3427, DOI 10.1016/j.patcog.2008.04.015
   Islam MS, 2012, ELECTRON LETT, V48, P427, DOI 10.1049/el.2012.0421
   Islam MS, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/549134
   Islam MS, 2014, 2014 IEEE CONFERENCE ON BIOMEDICAL ENGINEERING AND SCIENCES (IECBES), P864, DOI 10.1109/IECBES.2014.7047634
   Islam MS, 2013, IEEE INT CONF MULTI
   Islam MS, 2013, BIOMED SIGNAL PROCES, V8, P315, DOI 10.1016/j.bspc.2012.11.006
   Islam MS, 2012, IEEE T INF TECHNOL B, V16, P445, DOI 10.1109/TITB.2012.2188535
   Kang D, 2014, PATTERN RECOGN, V47, P3750, DOI 10.1016/j.patcog.2014.06.004
   Lourenco A, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/720971
   Maria De M, 2014, FACE RECOGNITION ADV, DOI [10.4018/978-1-4666-5966-7, DOI 10.4018/978-1-4666-5966-7]
   Matyas V, 2002, INT FED INFO PROC, V100, P227
   Moon J-K, 2014, INT J CONTROL AUTOM, V7, P235, DOI 10.14257/ijca.2014.7.5.26
   Odinaka I, 2012, IEEE T INF FOREN SEC, V7, P1812, DOI 10.1109/TIFS.2012.2215324
   Plataniotis KN, 2006, BIOM S BIOM CONS C B
   Raj PS, 2014, EUR SIGNAL PR CONF, P2525
   Safie SI, 2011, IEEE T INF FOREN SEC, V6, P1315, DOI 10.1109/TIFS.2011.2162408
   Samuel A, 2015, IEEE T MULTIMEDIA, V17, P1484, DOI 10.1109/TMM.2015.2458299
   Shen J, 2011, IEEE ENG MED BIO, P5248, DOI 10.1109/IEMBS.2011.6091298
   Singh YN, 2012, PATTERN RECOGN LETT, V33, P1932, DOI 10.1016/j.patrec.2012.03.010
   Sommo L., 2005, BIOELECTRICAL SIGNAL
   Sprager S, 2015, SENSORS-BASEL, V15, P22089, DOI 10.3390/s150922089
   Tashk A, 2010, J ZHEJIANG U-SCI C, V11, P976, DOI 10.1631/jzus.C0910749
   Tashk A, 2011, AEU-INT J ELECTRON C, V65, P742, DOI 10.1016/j.aeue.2010.11.002
   Unar JA, 2014, PATTERN RECOGN, V47, P2673, DOI 10.1016/j.patcog.2014.01.016
   Venkatesh N., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3838, DOI 10.1109/ICPR.2010.935
   Vezzetti E, 2014, ROBOT AUTON SYST, V62, P1768, DOI 10.1016/j.robot.2014.07.009
   Wübbeler G, 2007, PATTERN RECOGN LETT, V28, P1172, DOI 10.1016/j.patrec.2007.01.014
   Yang J, 2011, RECENT APPL BIOMETRI, DOI [10.5772/970, DOI 10.5772/970]
   Zinner T, 2015, MULTIMED TOOLS APPL, V74, P413, DOI 10.1007/s11042-014-2072-5
NR 45
TC 34
Z9 34
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12709
EP 12733
DI 10.1007/s11042-016-3694-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200024
DA 2024-07-18
ER

PT J
AU Jung, Y
   Yoon, YI
AF Jung, Yuchae
   Yoon, Yong Ik
TI Multi-level assessment model for wellness service based on human mental
   stress level
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mental stress; Multi-level assessment; Wellness; Inspection middleware
ID HEART-RATE
AB In this paper, we measure human physiological changes from different body parts to quantify human mental stress level by using multimodal bio-sensors. By integrating these physiological responses, we generate bio-index and rule for the prediction of mental status, such as tension, normal, and relax. We also develop an inspection service middleware for analyzing health parameters such as electroencephalography (EEG), electrocardiography (ECG), oxygen saturation (SpO2), blood pressure (BP), and respiration rate (RR). In this service middleware, we use the multi-level assessment model for mental stress level that consists of three steps as follows; classification, reasoning, and decision making. The classification of datasets from bio-sensors is enabled by fuzzy logic and SVM algorithm. The reasoning uses the decision-tree model and random forest algorithm to classify the mental stress level from the health parameters. Finally, we propose a prediction model to make a decision for the wellness contents by using Expectation Maximization (EM).
C1 [Jung, Yuchae; Yoon, Yong Ik] Sookmyung Womens Univ, Dept Multimedia Sci, Seoul, South Korea.
C3 Sookmyung Women's University
RP Yoon, YI (corresponding author), Sookmyung Womens Univ, Dept Multimedia Sci, Seoul, South Korea.
EM jungjuri7@sm.ac.kr; yiyoon@sm.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT & Future Planning
   [2013015884]; Basic Science Research Program through the National
   Research Foundation of Korea (NRF) - Ministry of Education
   [NRF-2013R1A1A2058969]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT & Future Planning (2013015884).; This research was also
   supported by Basic Science Research Program through the National
   Research Foundation of Korea (NRF) funded by the Ministry of Education
   (NRF-2013R1A1A2058969)
CR Andre P, 2013, INT J PSYCHOPHYSIOL
   [Anonymous], HUM ASS C AFF COMP I
   Augusto JC, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-12
   Banaee H, 2013, SENSORS-BASEL, V13, P17472, DOI 10.3390/s131217472
   Bernardi L, 2000, J AM COLL CARDIOL, V35, P1462, DOI 10.1016/S0735-1097(00)00595-7
   Brahami M, 2013, J INF PROCESS SYST, V9, P1, DOI 10.3745/JIPS.2013.9.1.001
   Choi J, 2009, WEARABLE IMPLANT BOD
   Dishman RK, 2000, INT J PSYCHOPHYSIOL, V37, P121, DOI 10.1016/S0167-8760(00)00085-4
   Fahim M, 2014, 36 ANN INT C IEEE EN
   Feese S, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0015-9
   Hernandez J, 2011, LECT NOTES COMPUT SC, V6974, P125, DOI 10.1007/978-3-642-24600-5_16
   Homma I, 2008, EXP PHYSIOL, V93, P1011, DOI 10.1113/expphysiol.2008.042424
   INNES G, 1959, J MENT SCI, V105, P840, DOI 10.1192/bjp.105.440.840
   Jatupaiboon N, 2013, REAL TIME EEG BASED
   Jirayucharoensak S., 2014, EEG BASED EMOTION RE
   Jung Y, 2015, PROCEDIA COMPUT SCI, V52, P1179, DOI 10.1016/j.procs.2015.05.155
   Logothetis A, 2002, SIGNAL PROCESS, V82, P473, DOI 10.1016/S0165-1684(01)00198-0
   Malkawi M, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-3
   Murugappan Murugappan, 2010, Journal of Biomedical Science & Engineering, V3, P390, DOI 10.4236/jbise.2010.34054
   Omary Z., 2011, INT J INF SECURITY R, V1, P71, DOI DOI 10.20533/ijisr.2042.4639.2011.0009
   Sapolsky R, 2004, WHY ZEBRAS DONT GET, P271
   Setz C, 2010, IEEE T INF TECHNOL B, V14, P410, DOI 10.1109/TITB.2009.2036164
   Silberstein R, 1990, US Pat, Patent No. [4: 388, 4388]
   Taelman J, 2013, IFMBE P, V22, P1366
   Tylor A., 2008, INAUGURAL EDITORIAL, V1, P1
   Vrijkotte TGM, 2000, HYPERTENSION, V35, P880, DOI 10.1161/01.HYP.35.4.880
   Wang XW, 2011, LECT NOTES COMPUT SC, V7062, P734, DOI 10.1007/978-3-642-24955-6_87
   YongIk Y, 2016, BIGCOMP 2016 BIGDATA
NR 28
TC 23
Z9 25
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11305
EP 11317
DI 10.1007/s11042-016-3444-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000010
OA hybrid
DA 2024-07-18
ER

PT J
AU Kwon, D
   Yang, S
   Paek, Y
   Ko, K
AF Kwon, Donghyun
   Yang, Seungjun
   Paek, Yunheung
   Ko, Kwangman
TI Optimization techniques to enable execution offloading for 3D video
   games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile cloud computing; Execution offloading; 3D video game
ID CLOUD
AB Nowadays, mobile devices are becoming the most popular computing device as their computing capabilities increase rapidly. However, it is still challenging to execute highly sophisticated applications such as 3D video games on mobile devices due to its constrained key computational resources. Execution offloading approaches have been proposed to resolve this problem by strengthening mobile devices with powerful cloud. Unfortunately, the existing offloading approaches are not suitable for 3D video games because of the unique execution characteristics of them. In this paper, we propose a streaming-based execution offloading framework to enable execution offloading for 3D video games. The experiments show that our framework successfully guarantees 20 frames per second for our benchmark.
C1 [Kwon, Donghyun; Yang, Seungjun; Paek, Yunheung] Seoul Natl Univ, Dept Elect & Comp Engn, 1 Gwanak Ro, Seoul, South Korea.
   [Ko, Kwangman] Sangji Univ, Sch Comp & Informat Engn, 83 Sangjidae Gil, Wonju, South Korea.
C3 Seoul National University (SNU); Sangji University
RP Paek, Y (corresponding author), Seoul Natl Univ, Dept Elect & Comp Engn, 1 Gwanak Ro, Seoul, South Korea.; Ko, K (corresponding author), Sangji Univ, Sch Comp & Informat Engn, 83 Sangjidae Gil, Wonju, South Korea.
EM dhkwon@sor.snu.ac.kr; sjyang@sor.snu.ac.kr; ypaek@snu.ac.kr;
   kkman@sangji.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MSIP)
   [2014R1A2A1A10051792]; IDEC; Brain Korea 21 Plus Project;
   Inter-University Semiconductor Research Center(ISRC); Institute of
   Computer Technology(ICT) at Seoul National University
FX This work was partly supported by the National Research Foundation of
   Korea (NRF) grant funded by the Korea government (MSIP) (No.
   2014R1A2A1A10051792), IDEC, the Brain Korea 21 Plus Project in 2016,
   Inter-University Semiconductor Research Center(ISRC) and Institute of
   Computer Technology(ICT) at Seoul National University.
CR [Anonymous], 2010, PROC 8 INT C MOBILE, DOI [DOI 10.1145/1814433, 10.1145/1814433.1814441, DOI 10.1145/1814433.1814441]
   Christou G, 2013, HUMAN CTR COMPUTING, V3, P1
   Chun BG, 2011, EUROSYS 11: PROCEEDINGS OF THE EUROSYS 2011 CONFERENCE, P301
   Gartner, 2013, GARTN SAYS WORLDW VI
   Gordon M.S., 2012, Proceedings of the 10th USENIX conference on Operating Systems Design and Implementation, P93
   Gu XH, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS (PERCOM 2003), P107, DOI 10.1109/PERCOM.2003.1192732
   Kosta S, 2012, IEEE INFOCOM SER, P945, DOI 10.1109/INFCOM.2012.6195845
   Kovachev D., 2012, 2012 IEEE 10th International Symposium on Parallel and Distributed Processing with Applications (ISPA), P784, DOI 10.1109/ISPA.2012.115
   Newton R., 2009, Proc. 6th USENIX Symp. Netw. Syst. Des. Implementation, V9, P395
   Ra M.-R., 2011, P 9 INT C MOB SYST A, P43
   Satyanarayanan M, 2007, IEEE INTERNET COMPUT, V11, P16, DOI 10.1109/MIC.2007.46
   Satyanarayanan M, 2009, IEEE PERVAS COMPUT, V8, P14, DOI 10.1109/MPRV.2009.82
   Sharma R, 2014, J INF PROCESS SYST, V10, P193, DOI 10.3745/JIPS.01.0001
   Wang S., 2010, GLOB TEL C GLOBECOM, P1, DOI DOI 10.1109/GEOINFORMATICS.2010.5567608
   Wang SQ, 2009, PROCEEDINGS OF THE 2009 CHINESE CONFERENCE ON PATTERN RECOGNITION AND THE FIRST CJK JOINT WORKSHOP ON PATTERN RECOGNITION, VOLS 1 AND 2, P1, DOI 10.1109/PLASMA.2009.5227540
   Yang S, 2014, IEEE T MOBILE COMPUT, V13, P2648, DOI 10.1109/TMC.2014.2307293
   Yang S, 2013, INT CONF PERVAS COMP, P20, DOI 10.1109/PerCom.2013.6526710
NR 17
TC 3
Z9 3
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11347
EP 11360
DI 10.1007/s11042-016-3711-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000013
DA 2024-07-18
ER

PT J
AU Liu, XW
AF Liu, Xinwu
TI Alternating minimization method for image restoration corrupted by
   impulse noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image restoration; Impulse noise; Total variation; Alternating
   minimization method
ID VARIATIONAL APPROACH; ABSOLUTE NORM; ALGORITHM; DECOMPOSITION; REMOVAL;
   RECONSTRUCTION; REGULARIZATION; OUTLIERS; FILTERS; MODEL
AB This paper investigates the anisotropic total variation model for recovering image corrupted by impulse noise. To quickly deal with the proposed minimization problem, by associating with the fast relaxation method, we introduce an extremely efficient alternating minimization method at great length. Finally, provided experimental results distinctly illustrate the high efficiency and competitive performance of the resulting iterative algorithm for image restoration, both in terms of evaluating the computational speed and especially the quality of the restored images, in comparison with several current state-of-the-art numerical algorithms.
C1 [Liu, Xinwu] Hunan Univ Sci & Technol, Sch Math & Computat Sci, Xiangtan 411201, Hunan, Peoples R China.
C3 Hunan University of Science & Technology
RP Liu, XW (corresponding author), Hunan Univ Sci & Technol, Sch Math & Computat Sci, Xiangtan 411201, Hunan, Peoples R China.
EM lxinwu@163.com
OI Liu, Xinwu/0000-0003-1909-3721
FU National Natural Science Foundation of China [61402166]; Hunan
   Provincial Natural Science Foundation of China [14JJ3105]
FX This work was supported by National Natural Science Foundation of China
   (61402166) and Hunan Provincial Natural Science Foundation of China
   (14JJ3105).
CR ALLINEY S, 1992, IEEE T SIGNAL PROCES, V40, P1548, DOI 10.1109/78.139258
   Alliney S, 1997, IEEE T SIGNAL PROCES, V45, P913, DOI 10.1109/78.564179
   Alliney S, 1996, IEEE T SIGNAL PROCES, V44, P1346, DOI 10.1109/78.506602
   Aujol JF, 2006, INT J COMPUT VISION, V67, P111, DOI 10.1007/s11263-006-4331-z
   Bioucas-Dias JM, 2010, IEEE T IMAGE PROCESS, V19, P1720, DOI 10.1109/TIP.2010.2045029
   Cai JF, 2008, INVERSE PROBL IMAG, V2, P187
   Cai JF, 2009, MULTISCALE MODEL SIM, V8, P337, DOI 10.1137/090753504
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chan RH, 2004, IEEE SIGNAL PROC LET, V11, P921, DOI 10.1109/LSP.2004.838190
   Chan SH, 2011, IEEE T IMAGE PROCESS, V20, P3097, DOI 10.1109/TIP.2011.2158229
   Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297
   Chan TF, 1999, SIAM J SCI COMPUT, V20, P1964, DOI 10.1137/S1064827596299767
   Chan TF, 1999, SIAM J NUMER ANAL, V36, P354, DOI 10.1137/S0036142997327075
   Chen YM, 2012, SIAM J IMAGING SCI, V5, P90, DOI 10.1137/100792688
   Duval V, 2009, MULTISCALE MODEL SIM, V8, P154, DOI 10.1137/090757083
   Figueiredo MAT, 2010, IEEE T IMAGE PROCESS, V19, P3133, DOI 10.1109/TIP.2010.2053941
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Guo XX, 2009, SIAM J SCI COMPUT, V31, P2322, DOI 10.1137/080724435
   Huang YM, 2009, SIAM J IMAGING SCI, V2, P20, DOI 10.1137/080712593
   Huang YM, 2008, MULTISCALE MODEL SIM, V7, P774, DOI 10.1137/070703533
   Jia RQ, 2011, MULTISCALE MODEL SIM, V9, P355, DOI 10.1137/100790355
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu XW, 2014, MATH COMPUT SIMULAT, V97, P224, DOI 10.1016/j.matcom.2013.10.001
   Luo Y, 2016, IEEE T IMAGE PROCESS, V25, P414, DOI 10.1109/TIP.2015.2495116
   Luo Y, 2014, IEEE T IMAGE PROCESS, V23, P3789, DOI 10.1109/TIP.2014.2332398
   Meyer Y, 2001, LEWIS MEMORICAL LECT, V22
   Ng MK, 2007, J MATH IMAGING VIS, V27, P265, DOI 10.1007/s10851-007-0650-0
   Nikolova M, 2004, J MATH IMAGING VIS, V21, P155, DOI 10.1023/B:JMIV.0000035180.40477.bd
   Nikolova M, 2002, SIAM J NUMER ANAL, V40, P965, DOI 10.1137/S0036142901389165
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Yahya AA, 2014, MULTIMED TOOLS APPL, V73, P1843, DOI 10.1007/s11042-013-1586-6
   Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421
   Yang JF, 2009, SIAM J SCI COMPUT, V31, P2842, DOI 10.1137/080732894
   Yin W, 2007, MULTISCALE MODEL SIM, V6, P190, DOI 10.1137/060663027
   Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983
NR 41
TC 8
Z9 8
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12505
EP 12516
DI 10.1007/s11042-016-3631-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200015
DA 2024-07-18
ER

PT J
AU Yeo, SD
   Cho, TI
   Kim, JU
   Park, GM
   Kim, SK
AF Yeo, Sung-Dae
   Cho, Tae-Il
   Kim, Jong-Un
   Park, Goo-Man
   Kim, Seong-Kweon
TI Compensation of audio data with a high frequency components for
   realistic media FTV
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Realistic media; Free-viewpoint TV (FTV); Audio data compensation; High
   frequency component (HFC); 3-dimensional audio; Immersive audio
ID SYNCHRONIZATION; REPRESENTATION
AB Like the concept of free-viewpoint TV (FTV), the audio data should be rendered according to video data. However, on condition that minimum numbers of microphone are used, it is difficult to acquire accurate audio signal for rendering audio data to the image with the choice of view point. Especially, degradation of high frequency components (HFC) happens due to the characteristic of polar pattern for microphone. The degradation of HFC causes imperfection of signal restoration and leads to the degradation of clarity for hearing. In this paper, a compensation method for the degradation of HFC audio signal is proposed for producing an immersive audio effect at realistic media. Our experimental results show that low frequency components (LFC) of audio signal had a little directional degradation in spite of effect of the polar patterns of microphone and the compensation of HFC can be realized with adapting the attenuation inclination of LFC. This research is expected to be helpful for producing an immersive audio effect for a realistic media.
C1 [Yeo, Sung-Dae; Cho, Tae-Il; Kim, Jong-Un; Park, Goo-Man; Kim, Seong-Kweon] Seoul Natl Univ Sci & Technol, Grad Sch NID Fus Technol, Seoul, South Korea.
C3 Seoul National University of Science & Technology
RP Kim, SK (corresponding author), Seoul Natl Univ Sci & Technol, Grad Sch NID Fus Technol, Seoul, South Korea.
EM ysd1009@seoultech.ac.kr; jotaeil@seoultech.ac.kr;
   trywooni@seoultech.ac.kr; gmpark@seoultech.ac.kr;
   kim12632@seoultech.ac.kr
FU MSIP/IITP, Republic of Korea [B0101-15-0042]
FX The work was supported by the ICT R&D program of MSIP/IITP, Republic of
   Korea, [B0101-15-0042, Volumetric 3D Image and 3D Audio Realization
   Technology].
CR Anantrasirichai N, 2006, IEEE IMAGE PROC, P1221, DOI 10.1109/ICIP.2006.312545
   Anantrasirichai N, 2011, MULTIMED TOOLS APPL, V53, P25, DOI 10.1007/s11042-010-0484-4
   Casanovas AL, 2015, MULTIMED TOOLS APPL, V74, P1317, DOI 10.1007/s11042-014-1872-y
   Casanovas AL, 2010, IEEE T MULTIMEDIA, V12, P358, DOI 10.1109/TMM.2010.2050650
   Cho D. H, 2013, J KOREA INFORM PROCE, V2, P789, DOI DOI 10.3745/KTSDE.2013.2.11.789
   Choi T, 2008, P S KOR I COMM INF S
   Everest F. A., 2009, MASTER HDB ACOUSTIC
   Forrest S, 2012, THE FUTURE OF TV
   Han YC, 2014, MULTIMED TOOLS APPL, V73, P917, DOI 10.1007/s11042-013-1382-3
   Herre J, 2014, J AUDIO ENG SOC, V62, P821
   Jang D, 2015, J BROADCAST ENG, V20, P68, DOI [10.5909/jbe.2015.20.1.68, DOI 10.5909/JBE.2015.20.1.68]
   Kim H.G., 2006, MPEG 7 AUDIO AUDIO C
   Kim J-U, 2015, J KOREA I ELECT COMM, V10, P233, DOI 10.13067/JKIECS.2015.10.2.233
   Kim JH, 2014, KOREAN SOC BROADCAST, V19, P54, DOI [10.5909/JBE.2014.19.1.10, DOI 10.5909/JBE.2014.19.1.10]
   Kim S, 2013, C I EL ENG KOR
   Lei C, 2006, IEEE T IMAGE PROCESS, V15, P2473, DOI 10.1109/TIP.2006.877438
   Magnor M, 2003, IEEE T CIRC SYST VID, V13, P1092, DOI 10.1109/TCSVT.2003.817630
   Mori Y, 2009, SIGNAL PROCESS-IMAGE, V24, P65, DOI 10.1016/j.image.2008.10.013
   Neuendorf M, 2014, NAB BROADC ENG C BEC, V2014, P52
   Niwa K, 2007, 19 INT C AC MADR, P1
   Nour-Eddine L, 2015, J INF PROCESS SYST, V11, P22, DOI 10.3745/JIPS.02.0015
   Oldfield R, 2015, MULTIMED TOOLS APPL, V74, P2717, DOI 10.1007/s11042-013-1472-2
   Ricketts TA, 2008, J SPEECH LANG HEAR R, V51, P160, DOI 10.1044/1092-4388(2008/012)
   Seo J, 2012, C KOR SOC BROAD ENG, P170
   Sha YT, 2010, INT CONF ACOUST SPEE, P381, DOI 10.1109/ICASSP.2010.5495813
   Tanimoto M, 2012, P IEEE, V100, P905, DOI 10.1109/JPROC.2011.2182101
   Tanimoto M, 2011, IEEE SIGNAL PROC MAG, V28, P67, DOI 10.1109/MSP.2010.939077
   Tehrani M. Panahpour, 2006, INT CONF ACOUST SPEE, pv541
   Tehrani MP, 2009, 3DTV C TRUE VIS CAPT, P4, DOI [10.1109/3DTV.2009.5069681, DOI 10.1109/3DTV.2009.5069681]
   Yamamoto K, 2007, IEEE T CIRC SYST VID, V17, P1436, DOI 10.1109/TCSVT.2007.903802
   Yao Q, 2013, ITE T MEDIA TECHNOLO, V2, P23, DOI [10.1109/APSIPA.2013.6694266, DOI 10.1109/APSIPA.2013.6694266]
   Yim E, 2013, C HCI SOC KOR, P751
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 33
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11361
EP 11376
DI 10.1007/s11042-016-3713-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000014
DA 2024-07-18
ER

PT J
AU David, DB
AF David, Deebak Bakkiam
TI Mutual authentication scheme for multimedia medical information systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia medical information system; Security and privacy;
   Authentication scheme; Bilinear-pairing; Telecare medicine system
ID GROUP KEY AGREEMENT; USER AUTHENTICATION; SMART CARDS; PROTOCOL;
   NETWORKS; CRYPTOSYSTEM; ENVIRONMENT; PAIRINGS
AB For Multimedia Medical Information System (MMIS), security and privacy are the significant measures. For the guarantee of MMIS significant measures, several authentication schemes have been proposed, though the authentication schemes fail to offer the measurable features, like Repetitive Registration, Verification Table, Mutual Authenticity with Key-Sharing, and Client Anonymity. In addition, the existing authentication schemes fail to provide the reasonable bandwidth utilization and signal congestion to improve the performance of the multimedia information system. Most importantly, the existing schemes fail to withstand against the attacks, like key-impersonation, man-in-the-middle, stolen-verifier and server-spoofing. In this research article, we thus propose and present an efficient Mutual Authentication Scheme (MAS) using bilinear-pairing system to enhance the security features of multimedia information system and it is specially designed and developed for purpose of telecare medicine system. To prove the significance of MAS protocol, this paper is analyzed experimentally the security features comparison, computational cost, execution efficiencies, signal congestion and bandwidth utilization using multimedia medical information system. The examination result is proven that the proposed protocol of MAS achieves better performance comparatively than the existing authentication schemes, such as Wang et al., Chen et al., Choi et al., Wu et al. and Yoon et al.
C1 [David, Deebak Bakkiam] Mepco Schlenk Engn Coll, Dept Informat Technol, Sivakasi 626005, Tamil Nadu, India.
C3 Mepco Schlenk Engineering College
RP David, DB (corresponding author), Mepco Schlenk Engn Coll, Dept Informat Technol, Sivakasi 626005, Tamil Nadu, India.
EM jrvd_deebak@ymail.com
RI Deebak, B. D./AAJ-6133-2020; B D, Deebak/ABC-5122-2022
OI Deebak, B. D./0000-0002-4008-6350; 
CR [Anonymous], 2008, INT J NETWORK SECURI
   [Anonymous], 2006, 2006200 CRYPT EPRINT
   [Anonymous], 2014, P INT ACM SIGIR WORK
   [Anonymous], P FC FEB 19 22
   [Anonymous], 2010, 2010 IEEE INT C WIRE
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   Chang X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P581, DOI 10.1145/2733373.2806218
   Chang XJ, 2015, PR MACH LEARN RES, V37, P1348
   Chang XJ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2234
   Chen L, 2007, INT J INF SECUR, V6, P213, DOI 10.1007/s10207-006-0011-9
   Choi KY, 2005, LECT NOTES COMPUT SC, V3574, P494
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Galbraith SD, 2008, DISCRETE APPL MATH, V156, P3113, DOI 10.1016/j.dam.2007.12.010
   Hao XH, 2013, J MED SYST, V37, DOI 10.1007/s10916-012-9919-y
   He D, INFORM FUSION, V13, P223
   He DB, 2013, INF TECHNOL CONTROL, V42, P170, DOI 10.5755/j01.itc.42.2.2554
   He DB, 2013, IEICE T INF SYST, VE96D, P138, DOI 10.1587/transinf.E96.D.138
   He DB, 2012, J MED SYST, V36, P1989, DOI 10.1007/s10916-011-9658-5
   Jiang P, 2013, SCI WORLD J, DOI 10.1155/2013/419592
   Jiang Q, 2013, J MED SYST, V37, DOI 10.1007/s10916-012-9897-0
   Kumar P, 2012, SENSORS-BASEL, V12, P1625, DOI 10.3390/s120201625
   Lambrinoudakis C, 2000, J Med Syst, V24, P213, DOI 10.1023/A:1005549330655
   Lee WB, 2008, IEEE T INF TECHNOL B, V12, P34, DOI 10.1109/TITB.2007.906101
   Liao IE, 2006, J COMPUT SYST SCI, V72, P727, DOI 10.1016/j.jcss.2005.10.001
   Liu JY, 2008, COMPUT COMMUN, V31, P2205, DOI 10.1016/j.comcom.2008.02.002
   Mitsunari S, 2002, IEICE T FUND ELECTR, VE85A, P481
   Nam JH, 2005, J SYST SOFTWARE, V78, P73, DOI 10.1016/j.jss.2004.10.024
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1245, DOI 10.1145/2600428.2611176
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Schnorr C. P., 1991, Journal of Cryptology, V4, P161, DOI 10.1007/BF00196725
   Siddiqui Z, 2001, J MED SYST, V64, P201
   Tseng YM, 2006, IEE P-COMMUN, V153, P810, DOI 10.1049/ip-com:20050366
   Tseng YM, 2008, INFORMATICA-LITHUAN, V19, P285
   Tseng YM, 2007, COMPUT SECUR, V26, P331, DOI 10.1016/j.cose.2006.12.001
   Wei JH, 2012, J MED SYST, V36, P3597, DOI 10.1007/s10916-012-9835-1
   Wong DS, 2001, P ASIACRYPT 01 GOLD, P172
   Wu TY, 2010, COMPUT NETW, V54, P1520, DOI 10.1016/j.comnet.2009.12.008
   Xu J, 2009, COMPUT STAND INTER, V31, P723, DOI 10.1016/j.csi.2008.09.006
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150
   Yang CC, 2005, COMPUT SECUR, V24, P381, DOI 10.1016/j.cose.2004.10.007
   Yau WC, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9993-9
   Zhao ZG, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0013-5
NR 48
TC 9
Z9 9
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10741
EP 10759
DI 10.1007/s11042-016-3268-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400024
DA 2024-07-18
ER

PT J
AU Jung, JE
   Hong, M
   Nguyen, HL
AF Jung, Jai E.
   Hong, Minsung
   Hoang Long Nguyen
TI Serendipity-based storification: from lifelogging to storytelling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Storification; Serendipity mining; Lifelogging; Storytelling; Personal
   history; Data visualization
ID STORY
AB Storification is a theoretical technique which aims to construct the underlying relationships from discrete information for packaging them into a logical structure. In this paper, we focus on proposing the definition of serendipity-based storification in the personal history which is the combination of two-step processes: i) discovering hidden stories in the personal history and i i) representing stories using visualization techniques for easily grasping the information. MyMovieHistory Hong & Jung (Cybern Syst 46 (1-2), 69-83 ??) is used as the case study to demonstrate the effect of storification through detecting and presenting patterns in real personal data. The results can be utilized in helping people easily memorize and comprehend their histories. Moreover, additional benefits (e.g., reminding the pass, predicting the future, and communicating who you are) can be gained through the use of storification in the personal history.
C1 [Jung, Jai E.; Hong, Minsung; Hoang Long Nguyen] Chung Ang Univ, Dept Comp Sci & Engn, Seoul 156756, South Korea.
C3 Chung Ang University
RP Nguyen, HL (corresponding author), Chung Ang Univ, Dept Comp Sci & Engn, Seoul 156756, South Korea.
EM j3ung@cau.ac.kr; minsung.holdtime@gmail.com; longnh238@gmail.com
RI Nguyen, Hoang Long/K-6449-2019; Jung, Jason J./B-9622-2012
OI Nguyen, Hoang Long/0000-0002-8031-6341; Jung, Jason
   J./0000-0003-0050-7445
FU National Research Foundation of Korea (NRF) grant - Korea government
   (MSIP) [NRF-2014R1A2A2A05007154]; Ministry of Education of the Republic
   of Korea; National Research Foundation of Korea [NRF-2015S1A5B6037297]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP)
   (NRF-2014R1A2A2A05007154). Also, this work was supported by the Ministry
   of Education of the Republic of Korea and the National Research
   Foundation of Korea (NRF-2015S1A5B6037297).
CR Akkerman S, 2009, COMPUT EDUC, V52, P449, DOI 10.1016/j.compedu.2008.09.014
   [Anonymous], MULTIMEDIA IN PRESS
   [Anonymous], UNDERSTANDING SUMMAR
   Bakhtin MM, 2010, DIALOGIC IMAGINATION
   Bello-Orgaz G, 2016, INFORM FUSION, V28, P45, DOI 10.1016/j.inffus.2015.08.005
   Bruner J.S., 2009, ACTUAL MINDS
   Champagnat R, 2010, INT J TECHNOL ENHANC, V2, P4, DOI 10.1504/IJTEL.2010.031257
   Gama J, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2523813
   Haigh C, 2011, NURS EDUC TODAY, V31, P408, DOI 10.1016/j.nedt.2010.08.001
   Hermans H.J.M., 1995, SELF NARRATIVES CONS
   Nguyen HL, 2017, MULTIMED TOOLS APPL, V76, P8901, DOI 10.1007/s11042-016-3525-9
   Hong M, 2016, CYBERNET SYST, V47, P88, DOI 10.1080/01969722.2016.1128771
   Jenkins H., 2003, 1 PERSON NEW MEDIA S, P118, DOI DOI 10.1111/B.9781444331899.2011.00023.X
   Jung JJ, 2016, CONCURR COMP-PRACT E, V28, P1356, DOI 10.1002/cpe.3634
   Lee OJ, 2017, FUTURE GENER COMP SY, V66, P100, DOI 10.1016/j.future.2016.02.011
   Lee OJ, 2016, ACTA POLYTECH HUNG, V13, P179
   Liu CC, 2011, COMPUT EDUC, V57, P1544, DOI 10.1016/j.compedu.2011.02.002
   MANDLER JM, 1977, COGNITIVE PSYCHOL, V9, P111, DOI 10.1016/0010-0285(77)90006-8
   Mokhtar NH, 2011, PROCD SOC BEHV, V18, DOI 10.1016/j.sbspro.2011.05.024
   Nguyen DT, 2015, MOBILE NETW APPL, V20, P475, DOI 10.1007/s11036-014-0557-0
   Long NH, 2015, CYBERNET SYST, V46, P69, DOI 10.1080/01969722.2015.1007737
   Papacharissi Z, 2012, J COMMUN, V62, P266, DOI 10.1111/j.1460-2466.2012.01630.x
   Rumelhart D.E., 1975, Representation and understanding: Studies in cognitive science, V211, P45
   Schmidt P, 2015, LECT NOTES COMPUT SC, V9445, P282, DOI 10.1007/978-3-319-27036-4_27
   SINGER M, 1983, J VERB LEARN VERB BE, V22, P437, DOI 10.1016/S0022-5371(83)90282-7
   THORNDYKE PW, 1977, COGNITIVE PSYCHOL, V9, P77, DOI 10.1016/0010-0285(77)90005-6
   Wertsch J.V., 2002, VOICES COLLECTIVE RE
   Zliobaite I., 2010, LEARNING CONCEPT DRI
NR 28
TC 4
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10345
EP 10356
DI 10.1007/s11042-016-3682-x
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400002
DA 2024-07-18
ER

PT J
AU Li, SP
   Yu, J
   Dou, ZF
   Peng, D
   Zhou, YQ
AF Li, Suoping
   Yu, Jun
   Dou, Zufang
   Peng, Duo
   Zhou, Yongqiang
TI Delay analysis of MSW-ARQ system based on wireless multimedia services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE M-[X]/G/1 queuing model; MSW-ARQ system; Multimedia services; Mean
   service delay
ID PERFORMANCE ANALYSIS; SCHEME
AB This paper firstly analyzes the transmission mechanism of the wireless broadband multi-media services in the MSW-ARQ(Multi-channel Stop-and-Wait ARQ) system. Considering the real-time multimedia service's four features (high requirement for delay but allows some loss rate, the constraints of the delay and jitter), in order to meet with professional standard, we model the real-time multimedia service packet transmission as an M-[X]/G/1 queuing model for MSW-ARQ. The packet transition probability is derived by constructing steady state Markov Chain based on the method of selecting the reference packet. On the basis of equivalent service delay, we also solve the packet mean service delay. Then under the given condition, we analyze the influence of the channel number and channel environments on the mean delay through numerical simulating. The characteristics and superiorities of multi-channel transmission mechanism in wireless communication are checked enough by solving the M-[X]/G/1 queuing model. So this paper provides useful thought and approach for optimizing system delay and throughput by checking the change of channel environments and the used number of parallel channels.
C1 [Li, Suoping; Yu, Jun; Zhou, Yongqiang] Lanzhou Univ Technol, Sch Sci, Lanzhou 730050, Peoples R China.
   [Li, Suoping; Dou, Zufang; Peng, Duo] Lanzhou Univ Technol, Sch Elect & Informat Engn, Lanzhou 730050, Peoples R China.
C3 Lanzhou University of Technology; Lanzhou University of Technology
RP Li, SP (corresponding author), Lanzhou Univ Technol, Sch Sci, Lanzhou 730050, Peoples R China.; Li, SP (corresponding author), Lanzhou Univ Technol, Sch Elect & Informat Engn, Lanzhou 730050, Peoples R China.
EM lsuop@163.com
OI Li, Suo-ping/0000-0002-4149-0427
FU Natural Science Foundation of China [61167005]
FX This research was supported by grant 61167005 from the Natural Science
   Foundation of China. We express our thanks to Prof. Dr. Marty Warren of
   East Texas Baptist University(ETBU) who checked our manuscript.
CR Ahmed I, 2013, INT J COMPUT TECHNOL, V10, P1339
   Benelli G., 1994, Wireless Personal Communications, V1, P117, DOI 10.1007/BF01098689
   Chelli A, 2014, IEEE T WIREL COMMUN, V13, P6245, DOI 10.1109/TWC.2014.2348561
   Chiti F, 2014, IEEE T VEH TECHNOL, V63, P2450, DOI 10.1109/TVT.2013.2291432
   Cui HX, 2013, COMPUT ELECTR ENG, V39, P1399, DOI 10.1016/j.compeleceng.2013.04.004
   De Vuyst S, 2009, 4OR-Q J OPER RES, V7, P61, DOI 10.1007/s10288-008-0072-x
   Ganhao F, 2013, IEEE T COMMUN, V61, P3304, DOI 10.1109/TCOMM.2013.061913.120269
   Huang SY, 2014, AEU-INT J ELECTRON C, V68, P429, DOI 10.1016/j.aeue.2013.11.006
   Kao JC, 2014, IEEE T WIREL COMMUN, V13, P4132, DOI 10.1109/TWC.2014.2315793
   Kim K, 2014, WIRELESS PERS COMMUN, V78, P1917, DOI 10.1007/s11277-014-2053-z
   Li J, 2012, WIRELESS PERS COMMUN, V66, P235, DOI 10.1007/s11277-011-0325-4
   Li J, 2009, PERFORM EVALUATION, V66, P380, DOI 10.1016/j.peva.2009.02.004
   Li S, 2015, INT J INF ELECT ENG, V5, P158
   Li SR, 2013, ABSTR APPL ANAL, DOI 10.1155/2013/528678
   Li SP, 2014, ACTA INFORM, V51, P51, DOI 10.1007/s00236-013-0192-4
   Mai VV, 2014, IEICE T COMMUN, VE97B, P1614, DOI 10.1587/transcom.E97.B.1614
   Manoj BS, 2002, 10TH IEEE INTERNATIONAL CONFERENCE ON NETWORKS (ICON 2002), PROCEEDINGS, P335, DOI 10.1109/ICON.2002.1033334
   Pereira M, 2012, IEEE T COMMUN, V60, P735, DOI 10.1109/TCOMM.2012.013112.110096
   Wu JCS, 2001, MOBILE NETW APPL, V6, P535, DOI 10.1023/A:1011814222611
   Yin XL, 2003, COMMUN APPL MATH COM, V17, P41
   Yuanyuan Yan, 2013, Advanced Materials Research, V760-762, P634, DOI 10.4028/www.scientific.net/AMR.760-762.634
   Zhang C, 2014, OPTIK, V125, P5893, DOI 10.1016/j.ijleo.2014.07.045
NR 22
TC 0
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 10067
EP 10082
DI 10.1007/s11042-016-3598-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300043
DA 2024-07-18
ER

PT J
AU Lopez-Otero, P
   Docio-Fernandez, L
   Garcia-Mateo, C
AF Lopez-Otero, Paula
   Docio-Fernandez, Laura
   Garcia-Mateo, Carmen
TI Ensemble audio segmentation for radio and television programmes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ensemble classification; Confusion matrix; Reliability estimation; Audio
   segmentation
ID DECISION-LEVEL FUSION
AB State-of-the-art audio segmentation strategies obtain good results when performing simple tasks but its performance is degraded when segmenting real-world scenarios such as radio and television programmes; this issue can be partially solved by performing a fusion of different audio segmentation strategies. Hence, a framework to perform decision-level fusion in the audio segmentation task is presented in this paper. First, the class-conditional probabilities of each audio segmentation strategy are estimated from a confusion matrix obtained by performing audio segmentation in a training dataset. Performance measures are extracted from these class-conditional probabilities, which are used to compute different estimates of the classifier's reliability; specifically, reliability estimates based on precision, recall, accuracy, F-score and mutual information were proposed. These reliability estimates are used as weights in a weighted majority voting fusion strategy. The validity of the proposed fusion scheme and reliability estimates was assessed in the framework of Albayzin 2010, 2012 and 2014 audio segmentation evaluations, which consisted in segmenting collections of radio and television programmes. The experimental results showed that this simple fusion strategy improves the performance achieved by the individual audio segmentation strategies and by other well-known decision-level fusion strategies.
C1 [Lopez-Otero, Paula; Docio-Fernandez, Laura; Garcia-Mateo, Carmen] Univ Vigo, AtlantTIC Res Ctr, Multimedia Technol Grp, EE Telecomunicac, Campus Univ Vigo S-N, Vigo 36310, Spain.
C3 Universidade de Vigo; atlanTTic
RP Lopez-Otero, P (corresponding author), Univ Vigo, AtlantTIC Res Ctr, Multimedia Technol Grp, EE Telecomunicac, Campus Univ Vigo S-N, Vigo 36310, Spain.
EM plopez@gts.uvigo.es
RI Lopez-Otero, Paula/P-1564-2017; Docio-Fernandez, Laura/D-3189-2018;
   Garcia-Mateo, Carmen/I-4144-2015
OI Lopez-Otero, Paula/0000-0003-2859-099X; Docio-Fernandez,
   Laura/0000-0003-3838-2406; Garcia-Mateo, Carmen/0000-0001-6856-939X
FU European Regional Development Fund; Galician Regional Government
   ('Consolidation of Research Units: AtlantTIC Project') [GRC2014/024,
   CN2012/160]; Spanish Government ('SpeechTech4All Project')
   [TEC2012-38939-C03-01]
FX This work has been supported by the European Regional Development Fund,
   the Galician Regional Government (GRC2014/024, 'Consolidation of
   Research Units: AtlantTIC Project' CN2012/160) and the Spanish
   Government ('SpeechTech4All Project' TEC2012-38939-C03-01).
CR Anguera X, 2004, 3 JORN TECN HABL VAL, P237
   [Anonymous], 1998, CORRELATION BASED FE
   Butko T, 2010, 2 IB SLTECH VIG 10 1, P305
   Butko T, 2011, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2011-1
   Castán D, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0034-5
   Castanedo F, 2013, SCI WORLD J, DOI 10.1155/2013/704504
   Cettolo M, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL VI, PROCEEDINGS, P537
   CHO SB, 1995, IEEE T NEURAL NETWOR, V6, P497, DOI 10.1109/72.363487
   COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9
   Delacourt P, 2000, SPEECH COMMUN, V32, P111, DOI 10.1016/S0167-6393(00)00027-3
   Do C., 2013, P INT, P2484
   Franco-Pedroso J, 2014, P IB 2014 8 JORN TEC, P247
   Gunatilaka AH, 2001, IEEE T PATTERN ANAL, V23, P577, DOI 10.1109/34.927459
   Huang Y. S., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P347, DOI 10.1109/CVPR.1993.1626170
   Kasapoglu NG, 2012, INT GEOSCI REMOTE SE, P3355, DOI 10.1109/IGARSS.2012.6350702
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Ko AHR, 2007, PATTERN RECOGN, V40, P2198, DOI 10.1016/j.patcog.2007.01.031
   Kuncheva L, 2014, KNOWL INF SYST, V38
   Kuncheva L. I., 2004, COMBINING PATTERN CL, V390, P413
   LITTLESTONE N, 1994, INFORM COMPUT, V108, P212, DOI 10.1006/inco.1994.1009
   Lopez-Otero P, 2014, P IB 2014 8 JORN TEC, P253
   Meinedo H., 2005, INTERSPEECH, P237
   Metze F, 2014, IEEE INT CON MULTI
   Molina LC, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P306, DOI 10.1109/ICDM.2002.1183917
   Ortega A, 2014, P INT 8 JORN TECN HA, P283
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Ramona M, 2009, P EUR SIGN PROC C EU
   Rodriguez-Fuentes L, 2012, P IB 2012 7 JORN TEC, P590
   Ross A, 2005, PROC SPIE, V5779, P196, DOI 10.1117/12.606093
   Rybach D, 2009, INT CONF ACOUST SPEE, P4197, DOI 10.1109/ICASSP.2009.4960554
   Schuller B, 2010, INT CONF ACOUST SPEE, P5230, DOI 10.1109/ICASSP.2010.5494986
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Seyerlehner K., 2007, P 10 INT C DIG AUD E
   Shafer G, 1976, MATH THEORY EVIDENCE, DOI DOI 10.1080/00401706.1978.10489628
   Silvestre-Cerd`a Joan Albert, 2012, P IB 7 JORN TECN HAB, P596
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Tao Q, 2009, PATTERN RECOGN, V42, P823, DOI 10.1016/j.patcog.2008.09.036
   Tavarez D, 2014, P IB 2014 8 JORN TEC, P273
   Tuyls P, 2005, LECT NOTES COMPUT SC, V3546, P436
   Tzanetakis G., 2002, Manipulation, analysis and retrieval systems for audio signals
   Wijitha Senadeera Wijitha Senadeera, 2006, International Journal of Food Engineering, V2, P7
NR 41
TC 6
Z9 7
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7421
EP 7444
DI 10.1007/s11042-016-3386-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400059
DA 2024-07-18
ER

PT J
AU Muhammad, K
   Ahmad, J
   Rehman, NU
   Jan, Z
   Sajjad, M
AF Muhammad, Khan
   Ahmad, Jamil
   Rehman, Naeem Ur
   Jan, Zahoor
   Sajjad, Muhammad
TI CISSKA-LSB: color image steganography using stego key-directed adaptive
   LSB substitution method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Information security; Image quality; LSB; Stego
   key; Multimedia security; Data hiding
ID ENCRYPTION ALGORITHM; SUPERRESOLUTION; SCHEME
AB Information hiding is an active area of research where secret information is embedded in innocent-looking carriers such as images and videos for hiding its existence while maintaining their visual quality. Researchers have presented various image steganographic techniques since the last decade, focusing on payload and image quality. However, there is a trade-off between these two metrics and keeping a better balance between them is still a challenging issue. In addition, the existing methods fail to achieve better security due to direct embedding of secret data inside images without encryption consideration, making data extraction relatively easy for adversaries. Therefore, in this work, we propose a secure image steganographic framework based on stego key-directed adaptive least significant bit (SKA-LSB) substitution method and multi-level cryptography. In the proposed scheme, stego key is encrypted using a two-level encryption algorithm (TLEA); secret data is encrypted using a multi-level encryption algorithm (MLEA), and the encrypted information is then embedded in the host image using an adaptive LSB substitution method, depending on secret key, red channel, MLEA, and sensitive contents. The quantitative and qualitative experimental results indicate that the proposed framework maintains a better balance between image quality and security, achieving a reasonable payload with relatively less computational complexity, which confirms its effectiveness compared to other state-of-the-art techniques.
C1 [Muhammad, Khan; Ahmad, Jamil] Sejong Univ, Digital Contents Res Inst, Seoul, South Korea.
   [Muhammad, Khan; Ahmad, Jamil; Rehman, Naeem Ur; Jan, Zahoor; Sajjad, Muhammad] Islamia Coll Peshawar, Dept Comp Sci, Peshawar, Pakistan.
C3 Sejong University; University of Peshawar
RP Sajjad, M (corresponding author), Islamia Coll Peshawar, Dept Comp Sci, Peshawar, Pakistan.
EM muhammad.sajjad@icp.edu.pk; khan.muhammad.icp@gmail.com;
   jamil.ahmad@icp.edu.pk; naeembcs1@gmail.com; zahoor.jan@icp.edu.pk
RI Sajjad, Muhammad/GZL-4962-2022; Ahmad, Jamil/H-6264-2019; Muhammad,
   Khan/L-9059-2016; Sajjad, Muhammad/L-5269-2016; Khan,
   Muhammad/IXN-8470-2023
OI Sajjad, Muhammad/0000-0003-0006-1156; Ahmad, Jamil/0000-0001-8407-5971;
   Muhammad, Khan/0000-0003-4055-7412; Sajjad,
   Muhammad/0000-0001-5646-0338; Muhammad, Khan/0000-0002-5302-1150
CR [Anonymous], 2015, MULTIMEDIA TOOLS APP
   [Anonymous], INT J COMPUT INFORM
   [Anonymous], 2009, TENCON 2009 2009 IEE, DOI DOI 10.1109/ICIECS.2009.5364290
   Aziz M, 2015, NONLINEAR DYNAM, V80, P1271, DOI 10.1007/s11071-015-1943-2
   Bailey K, 2006, MULTIMED TOOLS APPL, V30, P55, DOI 10.1007/s11042-006-0008-4
   Chai T, 2014, GEOSCI MODEL DEV, V7, P1247, DOI 10.5194/gmd-7-1247-2014
   Cheddad A, 2014, ENCRYPTION METHOD
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen P.Y., 2006, INT J APPL SCI ENG, V4, P275, DOI DOI 10.6703/IJASE/2006.4(3).275
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Chen WY, 2008, APPL MATH COMPUT, V196, P40, DOI 10.1016/j.amc.2007.05.063
   Cheng WC, 2004, IEEE T CONSUM ELECTR, V50, P320, DOI 10.1109/TCE.2004.1277880
   El Hennawy HMS, 2015, AIN SHAMS ENG J, V6, P57, DOI 10.1016/j.asej.2014.08.001
   El-Emam NN, 2015, COMPUT SECUR, V55, P21, DOI 10.1016/j.cose.2015.06.012
   Emam NNE, 2015, APPL SOFT COMPUT
   Eng PMKM, 2014, INT J ELECT COMM ENG, V5, P26
   Fakhredanesh M, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043007
   Grover N, 2013, 2013 SECOND INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING, NETWORKING AND SECURITY (ADCONS 2013), P238, DOI 10.1109/ADCONS.2013.45
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Hong W, 2013, INFORM SCIENCES, V221, P473, DOI 10.1016/j.ins.2012.09.013
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Ioannidou A, 2012, EXPERT SYST APPL, V39, P11517, DOI 10.1016/j.eswa.2012.02.106
   Ishtiaq M, 2009, COMM COM INF SC, V61, P177
   Jassim FA, 2013, INT J COMPUT APPL, V72
   Jiang N., 2015, 2015 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2015.7280568
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Liu JM, 2007, J SYST ENG ELECTRON, V18, P427, DOI 10.1016/S1004-4132(07)60108-X
   Liu Q, 2015, COMMUN NONLINEAR SCI, V20, P506, DOI 10.1016/j.cnsns.2014.06.005
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Muhammad Khan, 2015, NED University Journal of Research, V12, P81
   Muhammad K., 2015, ARXIV, V19, P57
   Muhammad K, 2015, 11 INT C MULT INF TE, P165
   Muhammad K., 2015, TECHNICAL J U ENG TE, V20, P48
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Muhammad K, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0473-x
   Muhammad Khan, 2015, [The Journal of Korean Institute of Next Generation Computing, 한국차세대컴퓨팅학회 논문지], V11, P87
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Noda H, 2006, PATTERN RECOGN LETT, V27, P455, DOI 10.1016/j.patrec.2005.09.008
   Parah SA, 2014, COMPUT ELECTR ENG, V40, P70, DOI 10.1016/j.compeleceng.2013.11.006
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Qazanfari K, 2014, INFORM SCIENCES, V277, P90, DOI 10.1016/j.ins.2014.02.007
   Roy R, 2013, PROC TECH, V10, P138, DOI 10.1016/j.protcy.2013.12.346
   Sajjad M, 2016, SIGNAL IMAGE VIDEO P, V10, P181, DOI 10.1007/s11760-014-0724-6
   Sajjad M, 2014, SENSORS-BASEL, V14, P3652, DOI 10.3390/s140203652
   Tang M, 2015, OP INT J LIGHT ELECT
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu S, 2015, P 7 INT C INT MULT C, P47
   Zhang WM, 2007, IEEE SIGNAL PROC LET, V14, P848, DOI 10.1109/LSP.2007.903255
NR 53
TC 84
Z9 86
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8597
EP 8626
DI 10.1007/s11042-016-3383-5
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800043
DA 2024-07-18
ER

PT J
AU Wang, C
   Yao, HX
   Sun, XS
AF Wang, Chen
   Yao, Hongxun
   Sun, Xiaoshuai
TI Anomaly detection based on spatio-temporal sparse representation and
   visual attention analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse representation; Anomaly detection; Visual learning; Visual
   attention model; Fixation inference; Anomaly localization; ROC;
   Independent component analysis; Maximum a posterior
ID SALIENCY
AB In this paper, we proposed a unified framework for anomaly detection and localization in crowed scenes. For each video frame, we extract the spatio-temporal sparse features of 3D blocks and generate the saliency map using a block-based center-surround difference operator. Two sparse coding strategies including off-line long-term sparse representation and on-line short-term sparse representation are integrated within our framework. Abnormality of each candidate is measured using bottom-up saliency and top-down fixation inference and further used to classify the frames into normal and anomalous ones by a binary classifier. Local abnormal events are localized and segmented based on the saliency map. In the experiments, we compared our method against several state-of-the-art approaches on UCSD data set which is a widely used anomaly detection and localization benchmark. Our method outputs competitive results with near real-time processing speed compared to state-of-the-arts.
C1 [Wang, Chen; Yao, Hongxun; Sun, Xiaoshuai] Harbin Inst Technol, Sch Comp Sci & Technol, 92 West Dazhi St, Heilongjiang 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Wang, C (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, 92 West Dazhi St, Heilongjiang 150001, Peoples R China.
EM chwang@hit.edu.cn; h.yao@hit.edu.cn; xiaoshuaisun@hit.edu.cn
FU Special Social Science Foundation of Heilongjiang Province of China
   [11D083]; National Science Foundation of China [61472103,
   2015BAF32B01-4]
FX The work was supported in part by the Special Social Science Foundation
   of Heilongjiang Province of China No. 11D083, and the National Science
   Foundation of China No. 61472103, 2015BAF32B01-4.
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   [Anonymous], 2011, P 19 ACM INT C MULTI, DOI DOI 10.1145/2072298.2072042
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Cheng G., 2008, TRANSPORTATION RES B, P1
   Cong Y, 2011, IEEE C COMP VIS PATT, P1
   Duan L, 2011, CVPR, P441
   Gao V.M. D., 2007, NIPS, P497
   Haering N, 2008, MACH VISION APPL, V19, P279, DOI 10.1007/s00138-008-0152-0
   Hou X., 2006, ADV NEURAL INFORM PR, P681
   Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang F, 2009, IEEE T IMAGE PROCESS, V18, P907, DOI 10.1109/TIP.2008.2012070
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim J, 2009, PROC CVPR IEEE, P2913
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Mahadevan V, 2010, IEEE C COMP VIS PATT, P1
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Saligrama V, 2012, PROC CVPR IEEE, P2112, DOI 10.1109/CVPR.2012.6247917
   Seidenari L, 2010, P INT C MULT, P1139
   Wang W, 2011, PROC CVPR IEEE, P441, DOI 10.1109/CVPR.2011.5995423
   Wang W, 2010, PROC CVPR IEEE, P2368, DOI 10.1109/CVPR.2010.5539927
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9
NR 28
TC 11
Z9 11
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6263
EP 6279
DI 10.1007/s11042-015-3199-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400010
DA 2024-07-18
ER

PT J
AU Xia, M
   Yang, GB
   Li, LD
   Li, R
   Sun, XM
AF Xia, Min
   Yang, Gaobo
   Li, Leida
   Li, Ran
   Sun, Xingming
TI Detecting video frame rate up-conversion based on frame-level analysis
   of average texture variation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital video forensics; Frame-rate up-conversion (FRUC); Motion
   compensated interpolation (MCI); Average texture variation (ATV)
ID MOTION
AB Frame rate up-conversion (FRUC) refers to frame interpolation between adjacent video frames to increase the motion continuity of low frame rate video, which can improve the visual quality on hand-held displays. However, FRUC can also be used for video forgery purposes such as splicing two videos with different frame-rates. We found that most FRUC approaches introduce visual artifacts into texture regions of interpolated frames. Based on this observation, a two-stage blind detection approach is proposed for video FRUC based on the frame-level analysis of average texture variation (ATV). First, the ATV value is computed for each frame to obtain an ATV curve of candidate video. Second, the ATV curve is further processed to highlight its periodic property, which indicates the existence of FRUC operation and further estimates the original frame rate. Thus, the positions of interpolated frames can be inferred as well. Extensive experimental results show that the proposed forensics approach is efficient and effective for the detection of existing typical FRUC approaches such as linear frame averaging and motion-compensated interpolation (MCI). The detection performance is superior to the existing approaches in terms of time efficiency and detection accuracy.
C1 [Xia, Min; Yang, Gaobo] Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
   [Xia, Min] Southwest Univ Nationalities, Coll Elect & Informat Engn, Chengdu 610041, Peoples R China.
   [Li, Leida] China Univ Min & Technol, Sch Informat & Elect Engn, Xuzhou 221116, Peoples R China.
   [Li, Ran] Xinyang Normal Univ, Sch Comp & Informat Technol, Xinyang 464000, Peoples R China.
   [Sun, Xingming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Hunan University; Southwest Minzu University; China University of Mining
   & Technology; Xinyang Normal University; Nanjing University of
   Information Science & Technology
RP Yang, GB (corresponding author), Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
EM yanggaobo@hnu.edu.cn
RI Li, Li/AEM-3636-2022; Xia, Min/AAC-7472-2019; Sun,
   Xingming/AAD-1866-2019; li, li/HII-4157-2022
OI Xia, Min/0000-0003-4681-9129; 
FU National Natural Science Foundation of China [61379143, 61232016,
   61572183, U1405254]; Specialized Research Fund for the Doctoral Program
   of Higher Education (SRFDP) [20120161110014]; S&T Program of Xuzhou City
   [XM13B119]; PAPD fund; Southwest University for Nationalities for the
   Fundamental Research Funds for the Central Universities [82000742]
FX This work is supported in part by the National Natural Science
   Foundation of China (61379143, 61232016, 61572183, U1405254), the
   Specialized Research Fund for the Doctoral Program of Higher Education
   (SRFDP) (20120161110014) and the S&T Program of Xuzhou City (XM13B119)
   and the PAPD fund. This paper is also supported in part by Southwest
   University for Nationalities for the Fundamental Research Funds for the
   Central Universities (82000742). The authors appreciate the nice help
   from Mr Moses Odero for improving the English usages.
CR [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   Bahrami K, 2014, IEEE SIGNAL PROC LET, V21, P751, DOI 10.1109/LSP.2014.2314487
   Bestagini P, 2013, INT CONF ACOUST SPEE, P3033, DOI 10.1109/ICASSP.2013.6638215
   Bian S, 2013, IEEE IMAGE PROC, P4492, DOI 10.1109/ICIP.2013.6738925
   Bian S, 2014, IEEE T CIRC SYST VID, V24, P2144, DOI 10.1109/TCSVT.2014.2334031
   Bian S, 2014, MULTIMED TOOLS APPL, V72, P437, DOI 10.1007/s11042-013-1364-5
   Dong Q, 2012, DIGIT INVEST, V9, P151, DOI 10.1016/j.diin.2012.07.002
   Gironi A., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6226, DOI 10.1109/ICASSP.2014.6854801
   Ha T, 2004, IEEE T CONSUM ELECTR, V50, P752, DOI 10.1109/TCE.2004.1309458
   Hongmei Liu, 2014, Information Security Practice and Experience. 10th International Conference, ISPEC 2014. Proceedings: LNCS 8434, P262, DOI 10.1007/978-3-319-06320-1_20
   Kang SJ, 2007, IEEE T CONSUM ELECTR, V53, P1759, DOI 10.1109/TCE.2007.4429281
   Kaufman P, 1995, TECH ANAL STOCK COMM, V13
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lin GS, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412500176
   Liu HB, 2012, IEEE T CIRC SYST VID, V22, P1188, DOI 10.1109/TCSVT.2012.2197081
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Wang WH, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P35
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Yuxing Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2674, DOI 10.1109/ICASSP.2014.6854085
NR 21
TC 20
Z9 22
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8399
EP 8421
DI 10.1007/s11042-016-3468-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800035
DA 2024-07-18
ER

PT J
AU Alsmirat, MA
   Jararweh, Y
   Al-Ayyoub, M
   Shehab, MA
   Gupta, BB
AF Alsmirat, Mohammad A.
   Jararweh, Yaser
   Al-Ayyoub, Mahmoud
   Shehab, Mohammed A.
   Gupta, Brij B.
TI Accelerating compute intensive medical imaging segmentation algorithms
   using hybrid CPU-GPU implementations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy C-Means; Possibilistic C-Means; CUDA; Medical image processing;
   Image segmentation
ID C-MEANS ALGORITHM; FUZZY
AB Medical image processing is one of the most famous image processing fields in this era. This fame comes because of the big revolution in information technology that is used to diagnose many illnesses and saves patients lives. There are many image processing techniques used in this field, such as image reconstructing, image segmentation and many more. Image segmentation is a mandatory step in many image processing based diagnosis procedures. Many segmentation algorithms use clustering approach. In this paper, we focus on Fuzzy C-Means based segmentation algorithms because of the segmentation accuracy they provide. In many cases, these algorithms need long execution times. In this paper, we accelerate the execution time of these algorithms using Graphics Process Unit (GPU) capabilities. We achieve performance enhancement by up to 8.9x without compromising the segmentation accuracy.
C1 [Alsmirat, Mohammad A.; Jararweh, Yaser; Al-Ayyoub, Mahmoud; Shehab, Mohammed A.] Jordan Univ Sci & Technol, Dept Comp Sci, Irbid, Jordan.
   [Gupta, Brij B.] Natl Inst Technol Kurukshetra, Kurukshetra, Haryana, India.
C3 Jordan University of Science & Technology; National Institute of
   Technology (NIT System); National Institute of Technology Kurukshetra
RP Alsmirat, MA (corresponding author), Jordan Univ Sci & Technol, Dept Comp Sci, Irbid, Jordan.
EM masmirat@just.edu.jo
RI Gupta, Brij B/E-9813-2011; Jararweh, Yaser/JCO-2836-2023; Jararweh,
   Yaser/ABE-6543-2021
OI Gupta, Brij B/0000-0003-4929-4698; Jararweh, Yaser/0000-0002-4403-3846;
   Alsmirat, Mohammad/0000-0002-1071-7713
FU Jordan University of Science and Technology Deanship of Research project
   [20150310]
FX This work is supported by the Jordan University of Science and
   Technology Deanship of Research project number 20150310.
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Al-Ayyoub M, 2015, J SUPERCOMPUT, V71, P3149, DOI 10.1007/s11227-015-1431-y
   Alawneh K, 2015, 2015 6TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION SYSTEMS (ICICS), P286, DOI 10.1109/IACS.2015.7103190
   [Anonymous], 2012, CUDA PROGRAMMING DEV
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Eklund A, 2013, MED IMAGE ANAL, V17, P1073, DOI 10.1016/j.media.2013.05.008
   Hwang C, 2007, IEEE T FUZZY SYST, V15, P107, DOI 10.1109/TFUZZ.2006.889763
   Içer S, 2013, COMPUT METH PROG BIO, V112, P38, DOI 10.1016/j.cmpb.2013.06.006
   Ji ZX, 2014, NEUROCOMPUTING, V134, P60, DOI 10.1016/j.neucom.2012.12.067
   Krishnapuram R, 1996, IEEE T FUZZY SYST, V4, P385, DOI 10.1109/91.531779
   Lee VW, 2010, CONF PROC INT SYMP C, P451, DOI 10.1145/1816038.1816021
   Lei Pan, 2008, 5th International Conference on Information Technology and Applications in Biomedicine (ITAB 2008) in conjunction with 2nd International Symposium & Summer School on Biomedical and Health Engineering (IS3BHE 2008), P82, DOI 10.1109/ITAB.2008.4570542
   Lukas L, 2004, ARTIF INTELL MED, V31, P73, DOI 10.1016/j.artmed.2004.01.001
   Qiu CY, 2013, PATTERN RECOGN LETT, V34, P1329, DOI 10.1016/j.patrec.2013.04.021
   Rhee FCH, 2001, JOINT 9TH IFSA WORLD CONGRESS AND 20TH NAFIPS INTERNATIONAL CONFERENCE, PROCEEDINGS, VOLS. 1-5, P1926, DOI 10.1109/NAFIPS.2001.944361
   Rowinska Zdzislawa, 2012, Image processing & Communication, V17, P191, DOI 10.2478/v10248-012-0046-7
   Rubio E., 2014, 2014 IEEE C NORBERT, P1
   Shehab MA, 2015, 2015 6TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION SYSTEMS (ICICS), P130, DOI 10.1109/IACS.2015.7103215
   Sikka K, 2009, MAGN RESON IMAGING, V27, P994, DOI 10.1016/j.mri.2009.01.024
   Tan KS, 2011, PATTERN RECOGN, V44, P1, DOI 10.1016/j.patcog.2010.07.013
   Tang J., 2010, 2010 2 INT C COMP EN, V6, pV6, DOI [10.1109/ICCET.2010.5486012, DOI 10.1109/ICCET.2010.5486012]
   Walters JP, 2009, INT PARALL DISTRIB P, P1010
   Wang HS, 2009, MED IMAGE ANAL, V13, P193, DOI 10.1016/j.media.2008.06.014
NR 23
TC 45
Z9 45
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3537
EP 3555
DI 10.1007/s11042-016-3884-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200019
DA 2024-07-18
ER

PT J
AU Liu, JL
   Xiao, L
   Liu, GL
   Zhao, YF
AF Liu, Jinliang
   Xiao, Liang
   Liu, Guolong
   Zhao, Yifeng
TI Active authentication with reinforcement learning based on ambient radio
   signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active authentication; Ambient radio signals; Reinforcement learning;
   Game theory; Test threshold
ID PHYSICAL-LAYER AUTHENTICATION; WIRELESS; FINGERPRINTS
AB Active authentication of mobile devices such as smartphones and ipads is promising to enhance security to access confidential data or systems. In this paper, we propose an active authentication scheme, which exploits the physical-layer properties of ambient radio signals to identify mobile devices in indoor environments. More specifically, we discriminate mobile devices in different locations by analyzing the ambient radio sources, because the received signal strength indicator set of the ambient signals measured by a smartphone is usually different from that observed by its spoofer located in another area. We formulate the interactions between the legitimate mobile device and its spoofer as an active authentication game, in which the receiver chooses its test threshold in the hypothesis test in the spoofing detection, while the spoofer chooses its attack strength. In a dynamic radio environment with unknown attack parameters, we propose a learning-based authentication algorithm based on the physical-layer properties of the ambient radio environments. Simulation results show that the proposed scheme accurately detects spoofers in typical indoor environments.
C1 [Liu, Jinliang; Xiao, Liang; Liu, Guolong; Zhao, Yifeng] Xiamen Univ, Dept Commun Engn, Xiamen 361005, Peoples R China.
C3 Xiamen University
RP Xiao, L (corresponding author), Xiamen Univ, Dept Commun Engn, Xiamen 361005, Peoples R China.
EM ljlilu0627@163.com; lxiao@xmu.edu.cn; liuglong@foxmail.com;
   zhaoyf@xmu.edu.cn
OI XIAO, LIANG/0000-0003-2402-611X
FU NSFC [61271242, 61440002]
FX This work is supported in part by NSFC (61271242, 61440002).
CR Aksari Y, 2009, 2009 24TH INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P569
   Barto A.G., 1998, Reinforcement Learning: An Introduction
   Bo C., 2013, ARXIV13090073
   Chang JM, 2013, IT PROF, V15, P24, DOI 10.1109/MITP.2013.52
   Chellappa R, 2014, TECH REP
   Cuadrado F, 2012, IEEE COMMUN MAG, V50, P160, DOI 10.1109/MCOM.2012.6353696
   De Luca A., Proceedings of the 2012 AC M annual conference on Human Factors in Computing Systems, ser. CHI '12. New York, NY, USA: ACM, P987, DOI [10.1145/2208516.2208544, DOI 10.1145/2208516.2208544]
   Deutschmann I, 2013, IT PROF, V15, P12, DOI 10.1109/MITP.2013.50
   Fathy ME, 2014, PATTERN RECOGN LETT, V42, P122, DOI 10.1016/j.patrec.2014.02.007
   Frank M, 2013, IEEE T INF FOREN SEC, V8, P136, DOI 10.1109/TIFS.2012.2225048
   Guidorizzi RP, 2013, IT PROF, V15, P4, DOI 10.1109/MITP.2013.73
   Hou WK, 2014, IEEE T COMMUN, V62, P1658, DOI 10.1109/TCOMM.2014.032914.120921
   Jiang ZP, 2013, IEEE INFOCOM SER, P2544
   Li FD, 2014, INT J INF SECUR, V13, P229, DOI 10.1007/s10207-013-0209-6
   Liu FJ, 2013, IEEE ICC, P4724, DOI 10.1109/ICC.2013.6655319
   Liu FJZ, 2011, 2011 - MILCOM 2011 MILITARY COMMUNICATIONS CONFERENCE, P538, DOI 10.1109/MILCOM.2011.6127727
   Liu Hongbo., 2014, Proceedings of the 9th ACM symposium on Information, computer and communications security (ASIA CCS '14), P389
   Mathur S., 2011, P 9 INT C MOB SYST A, P211
   Nag A.K., 2014, Proceedings of the 9th Annual Cyber and Information Security Research Conference, P65, DOI [10.1145/2602087.2602112, DOI 10.1145/2602087.2602112]
   Pei-Yuan Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6028, DOI 10.1109/ICASSP.2014.6854761
   Primo A, 2014, IEEE COMPUT SOC CONF, P98, DOI 10.1109/CVPRW.2014.20
   Roy Aditi, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3789, DOI 10.1109/ICASSP.2014.6854310
   Sae-Bae N., 2012, Proceedings of the 2012 ACM Annual Conference on Human Factors in Computing Systems, P977, DOI DOI 10.1145/2207676.2208543
   Stolerman A, 2014, IFIP ADV INF COMM TE, V433, P165
   Tugnait J.K., 2010, IEEE Second International Conference on Communication Systems and Networks (COMSNETS), P1, DOI DOI 10.1109/COMSNETS.2010.5432018
   Tugnait JK, 2013, IEEE J SEL AREA COMM, V31, P1791, DOI 10.1109/JSAC.2013.130912
   Wu XF, 2015, IEEE COMMUN LETT, V19, P74, DOI 10.1109/LCOMM.2014.2375191
   Xiao L, 2007, IEEE ICC, P4646, DOI 10.1109/ICC.2007.767
   Xiao L, 2013, IEEE ICC, P1609, DOI 10.1109/ICC.2013.6654745
   Xiao L, 2013, IEEE T INF FOREN SEC, V8, P2089, DOI 10.1109/TIFS.2013.2286269
   Yang J, 2013, IEEE T PARALL DISTR, V24, P44, DOI 10.1109/TPDS.2012.104
   Yao Zheng, 2012, Computer Security - ESORICS 2012. Proceedings 17th European Symposium on Research in Computer Security, P361, DOI 10.1007/978-3-642-33167-1_21
   Yu PL, 2008, IEEE T INF FOREN SEC, V3, P38, DOI 10.1109/TIFS.2007.916273
   Zeng K, 2010, IEEE WIREL COMMUN, V17, P56, DOI 10.1109/MWC.2010.5601959
   Zhang YQ, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P176, DOI 10.1145/1866307.1866328
NR 35
TC 3
Z9 3
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3979
EP 3998
DI 10.1007/s11042-015-2958-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200038
DA 2024-07-18
ER

PT J
AU Guedes, ALV
   Azevedo, RGD
   Barbosa, SDJ
AF Vasconcelos Guedes, Alan Livio
   de Albuquerque Azevedo, Roberto Gerson
   Junqueira Barbosa, Simone Diniz
TI Extending multimedia languages to support multimodal user interactions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia languages; Multimodal user interactions; MUI; Nested context;
   language; NCL
AB Historically, the Multimedia community research has focused on output modalities, through studies on timing and multimedia processing. The Multimodal Interaction community, on the other hand, has focused on user-generated modalities, through studies on Multimodal User Interfaces (MUI). In this paper, aiming to assist the development of multimedia applications with MUIs, we propose the integration of concepts from those two communities in a unique high-level programming framework. The framework integrates user modalities-both user-generated (e.g., speech, gestures) and user-consumed (e.g., audiovisual, haptic)- in declarative programming languages for the specification of interactive multimedia applications. To illustrate our approach, we instantiate the framework in the NCL (Nested Context Language) multimedia language. NCL is the declarative language for developing interactive applications for Brazilian Digital TV and an ITU-T Recommendation for IPTV services. To help evaluate our approach, we discuss a usage scenario and implement it as an NCL application extended with the proposed multimodal features. Also, we compare the expressiveness of the multimodal NCL against existing multimedia and multimodal languages, for both input and output modalities.
C1 [Vasconcelos Guedes, Alan Livio; de Albuquerque Azevedo, Roberto Gerson; Junqueira Barbosa, Simone Diniz] Pontifical Catholic Rio de Janeiro, Dept Informat, Rio De Janeiro, Brazil.
RP Guedes, ALV (corresponding author), Pontifical Catholic Rio de Janeiro, Dept Informat, Rio De Janeiro, Brazil.
EM aguedes@inf.puc-rio.br
RI Barbosa, Simone/F-8012-2014; Guedes, Alan L. V./ABS-3947-2022; Azevedo,
   Roberto/AAE-9288-2019
OI Barbosa, Simone/0000-0002-0044-503X; Guedes, Alan L.
   V./0000-0003-0110-9975; 
FU Brazilian National Council of Technological and Scientific Development
   (CNPq) [309828/2015-5]; Foundation for Research of the State of Rio de
   Janeiro (FAPERJ)
FX First, we are strongly thankful to Prof. Luiz Fernando Gomes Soares (in
   memoriam) for the profound guidance and friendship, essential to this
   work and its authors. We also thank Carlos Salles, Marcos Roriz, and all
   TeleMidia Lab's researchers, who provided thoughtful discussions on this
   work. Finally, we thank the Brazilian National Council of Technological
   and Scientific Development (CNPq - process #309828/2015-5), and the
   Foundation for Research of the State of Rio de Janeiro (FAPERJ) for
   their financial support.
CR ABNT, 2008, 156062 ABNT NBR
   ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   Angeluci ACB, 2009, 1 S INT TEL DIG SIMT, P91
   [Anonymous], 2300532013 ISOIEC
   [Anonymous], 2009, EMMA EXT MULTIMODAL
   [Anonymous], 2008, SMIL 3 0 FLEXIBLE MU
   [Anonymous], 2004, SPEECH REC GRAMM SPE
   Beckham JL., 2001, Proceedings of Eurospeech 2001, P1363
   Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503
   Bulterman DCA, 2005, ACM T MULTIM COMPUT, V1, P89, DOI 10.1145/1047936.1047943
   Carvalho L, 2010, WEBMEDIA 10 P 16 BRA
   Carvalho LAMC, 2008, P 2008 EURO AM C TEL
   Costa D, 2011, LECT NOTES COMPUT SC, V6765, P347, DOI 10.1007/978-3-642-21672-5_38
   Coutaz J., 1995, Human-Computer Interaction. Interact '95, P115
   Duddington Jonathan, 2016, ESPEAK TEXT SPEECH E
   Dumas B., 2009, Proceedings of the 2009 international conference on Multimodal interfaces, P231
   Dumas B, 2009, LECT NOTES COMPUT SC, V5440, P3, DOI 10.1007/978-3-642-00437-7_1
   Dumas B, 2010, J MULTIMODAL USER IN, V3, P237, DOI 10.1007/s12193-010-0043-3
   Ghinea G, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2617994
   Soares LFG, 2010, IEEE COMMUN MAG, V48, P74
   Hachaj T, 2014, MULTIMEDIA SYST, V20, P81, DOI 10.1007/s00530-013-0332-2
   Huang CM, 1998, IEEE MULTIMEDIA, V5, P44, DOI 10.1109/93.735868
   Ideum Inc, 2016, GEST MARK LANG
   ISO/IEC, 2014, 2300512014 ISOIEC
   Katsurada K, 2005, TEXT SPEECH LANG TEC, V28, P133
   Kopp S, 2006, LECT NOTES ARTIF INT, V4133, P205
   Lazar J., 2010, Research Methods in Human-Computer Interaction
   Leap Motion Inc, 2016, LEAP MOT CONTR
   Lee Laboratory of Nagoya Institute of Technology, 2016, JUL SPEECH REC ENG
   Meixner B., 2012, Proceedings of the 2012 ACM symposium on Document engineering, P49
   Oviatt Sharon., 2007, The Human-Computer Interaction Handbook: Fundamentals, Evolving Technologies and Emerging Applications, V2nd, P413
   Rainer B, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2648429
   Rowe LA, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2490825
   Schnelle-Walka D, 2013, J MULTIMODAL USER IN, V7, P183, DOI 10.1007/s12193-013-0119-y
   Shneiderman B., 2010, DESIGNING USER INTER
   Soares LFG, 2009, MONOGR COMPUT SCI PU
   Soares LFG, 2015, NCL HDB MONOGR COMPU
   Turk M, 2014, PATTERN RECOGN LETT, V36, P189, DOI 10.1016/j.patrec.2013.07.003
   W3C, 2012, STAT CHART XML SCXML
   W3C, 2010, SPEECH SYNTH MARK LA
   W3C, 2003, MULT INT FRAM
   W3C, 2007, VOIC EXT MARK LANG V
   W3C, 2011, INK MARK LANG INKML
   W3C, 2001, XHTML VOIC PROF 1 0
   W3C, 2012, MULT ARCH INT
   Wang K, 2002, P INT C SPOK LANG PR
NR 46
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5691
EP 5720
DI 10.1007/s11042-016-3846-8
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500044
DA 2024-07-18
ER

PT J
AU Lee, JS
   Wei, KJ
   Wen, KR
AF Lee, Jung-San
   Wei, Kuo-Jui
   Wen, Kai-Rui
TI Image structure rebuilding technique using fractal dimension on the best
   match patch searching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Inpainting; Fractal dimension; Sparsity; Structure
AB Since most images were built with regular textures and structures, the exemplar-based inpainting technique has become a brand-new solution for renovating degraded images by searching a match patch. This characteristic has also been named as the local self-similarity. Nevertheless, traditional exemplar-based methods try to find the best match patch in the whole image with only one direction; thus, often leading to a non-ideal repairing result. In this article, we propose a novel patch matching technique to rebuild the structure and texture of image, in which the surrounding information of the patch is fully concerned. Aside from determining a more precise filling priority by the sparsity of the image structure, we have applied the difference of fractal dimension to enhance the similarity between the source patch and the target patch. Experimental results have demonstrated the superiority of the proposed technique over related works in the renovating accuracy.
C1 [Lee, Jung-San; Wei, Kuo-Jui; Wen, Kai-Rui] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 407, Taiwan.
C3 Feng Chia University
RP Lee, JS (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 407, Taiwan.
EM leejs@fcu.edu.tw
FU  [MOST104-2221-E-035-036]
FX This work is supported by MOST104-2221-E-035-036
CR [Anonymous], 1992, R. woods digital image processing
   Anupam, 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P325, DOI 10.1109/PSIVT.2010.61
   Benoit B, 1977, BMANDELBROT FRACTALS
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Cheng W.-H., 2005, P INT C COMP GRAPH I, P64
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Florinabel DJ, 2011, COMPUT GRAPH-UK, V35, P1051, DOI 10.1016/j.cag.2011.10.002
   Grossauer H, 2004, LECT NOTES COMPUT SC, V3022, P214
   Lee J, 2012, IEEE T CONSUM ELECTR, V58, P553, DOI 10.1109/TCE.2012.6227460
   Oliveira M. M., 2001, Visualization, Imaging, and Image Processing. Proceedings of the IASTED International Conference, P261
   Sankar Deepa, 2010, International Journal of Computer Information Systems and Industrial Management Applications, V2, P11
   Sun J, 2005, ACM T GRAPHIC, V24, P861, DOI 10.1145/1073204.1073274
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu XW, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P374, DOI 10.1109/CISP.2013.6744022
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
NR 15
TC 4
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1875
EP 1899
DI 10.1007/s11042-015-3184-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000013
DA 2024-07-18
ER

PT J
AU Lv, DY
   Huang, ZP
   Sun, LX
   Yu, NH
   Wu, JK
AF Lv, Dongyue
   Huang, Zhipei
   Sun, Lixin
   Yu, Nenghai
   Wu, Jiankang
TI Smart motion reconstruction system for golf swing: a DBN model based
   transportable, non-intrusive and inexpensive golf swing capture and
   reconstruction system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Golf swing reconstruction; Dynamic Bayesian Network model; Kinect; Depth
   imaging
ID TRACKING
AB In the past decade, golf has stimulated people's great interest and the number of golf players has increased significantly. Therefore, how to train a golfer to make a perfect swing has attracted extensive research attentions. Among these researches, the most important step is to capture and reconstruct the swing movement in a transportable and non-intrusive way. Restricted by the development of present depth imaging devices, the initial captured swing movement may not be acceptable due to occlusions and mixing up of body parts. In this paper, to restore motion information from self-occlusion and reconstruct 3D golf swing from low resolution data, a Dynamic Bayesian Network (DBN) model based golf swing reconstruction algorithm is proposed to increase the capture accuracy considering the spatial and temporal similarities of swing between different golfers. A Smart Motion Reconstruction system for Golf swing, SMRG, is presented based on the DBN model with a popular depth imaging device, Kinect, as capturing device. Experimental results have proved that the proposed system can achieve comparable reconstruction accuracy to the commercial optical motion caption (OMocap) system and better performance than state of art modification algorithms using depth information.
C1 [Lv, Dongyue; Sun, Lixin; Wu, Jiankang] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Huang, Zhipei] Univ Chinese Acad Sci, Sch Elect Elect & Commun Engn, Beijing, Peoples R China.
   [Lv, Dongyue; Yu, Nenghai] Chinese Acad Sci, Inst Elect, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; University of Chinese Academy of
   Sciences, CAS; Chinese Academy of Sciences; Institute of Electronics,
   CAS
RP Huang, ZP (corresponding author), Univ Chinese Acad Sci, Sch Elect Elect & Commun Engn, Beijing, Peoples R China.
EM zhphuang@ucas.ac.cn
RI Huang, Zhipei/GZH-3171-2022; liu, ting/AAA-1112-2022
OI huang, zhi bei/0000-0001-8034-939X
FU National Natural Science Foundation of China [61431017]; International
   S&T Cooperation Program of China, Ministry of Science and Technology
   [2012DFG11820]
FX This research is partially supported by National Natural Science
   Foundation of China (61431017) and International S&T Cooperation Program
   of China, the Ministry of Science and Technology (2012DFG11820).
CR Arvind D.K., 2008, BODYNETS 08, P1, DOI DOI 10.1109/TDC.2008.4517046
   Chun S, 2013, MULTIMED TOOLS APPL, P1
   Chun S, 2014, MULTIMED TOOLS APPL, V72, P253, DOI 10.1007/s11042-013-1359-2
   Coleman S, 2007, J SPORT SCI, V25, P739, DOI 10.1080/02640410601113239
   Evans K, 2012, SPORT BIOMECH, V11, P262, DOI 10.1080/14763141.2012.654502
   Hadjiminas N, 2012, 5 ANN INT C COMP GAM
   Holte MB, 2012, IEEE J-STSP, V6, P553, DOI 10.1109/JSTSP.2012.2193556
   Karliga I, 2006, AC SPEECH SIGN PROC
   Kenny I, 2012, 2012 BRIT ASS SPORT
   Kohli P, 2013, ADV COMPUTER VISION
   Kwon YH, 2009, ISBS C P ARCHIVE LIM, P31
   Lichao Zhang, 2012, Proceedings of the 2012 International Conference on Computer Science and Information Processing (CSIP), P1163, DOI 10.1109/CSIP.2012.6309065
   Lin Y.-H., 2013, INFORM TECHNOLOGY CO, P121, DOI [10.1007/978-94-007-6996-0_13, DOI 10.1007/978-94-007-6996-0_13]
   Liu H, 2011, S INTERACTIVE 3D GRA, P133
   Livingston MA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P119, DOI 10.1109/VR.2012.6180911
   MacKenzie SJ, 2009, SPORTS ENG, V11, P165, DOI 10.1007/s12283-009-0020-9
   Mackenzie SJ, 2012, SPORT BIOMECH, V11, P149, DOI 10.1080/14763141.2011.638388
   Mann R., 1998, SWING PRO BREAKTHROU
   McGuan SP, 2002, P BOOK 20 INT S BIOM, P451
   Nesbit SM, 2005, J SPORT SCI MED, V4, P499
   Nesbit SM, 2009, J SPORT SCI MED, V8, P235
   Obdrzalek S, 2012, ENG MED BIOL SOC EM
   Patsadu Orasa, 2012, COMP SCI SOFTW ENG J
   Qiong Wu, 2011, 2011 XIII Symposium on Virtual Reality (SVR), P161, DOI 10.1109/SVR.2011.35
   Seaman A, 2012, PROCEDIA ENGINEER, V34, P461, DOI 10.1016/j.proeng.2012.04.079
   Shen W, 2012, PROC CVPR IEEE, P1784, DOI 10.1109/CVPR.2012.6247875
   Shum HPH, 2013, IEEE T CYBERNETICS, V43, P1357, DOI 10.1109/TCYB.2013.2275945
   Smisek J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1154, DOI 10.1109/ICCVW.2011.6130380
   Suzuki S, 2005, P APCST2005 AS PAC C, P188
   Urtasun R, 2005, PROC CVPR IEEE, P932
   Watanabe K, 2006, IEEE T SYST MAN CY A, V36, P549, DOI 10.1109/TSMCA.2005.855777
   Zhang LC, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P711
   Zhou HY, 2008, BIOMED SIGNAL PROCES, V3, P1, DOI 10.1016/j.bspc.2007.09.001
NR 33
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1313
EP 1330
DI 10.1007/s11042-015-3102-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000057
OA hybrid
DA 2024-07-18
ER

PT J
AU Ouyang, JL
   Liu, YZ
   Shu, HZ
AF Ouyang, Junlin
   Liu, Yizhi
   Shu, Huazhong
TI Robust hashing for image authentication using SIFT feature and
   quaternion Zernike moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust image hashing; Quaternion Zernike moments; SIFT; Image
   authentication; Forgery image localization
AB A novel robust image hashing scheme based on quaternion Zernike moments (QZMs) and the scale invariant feature transform (SIFT) is proposed for image authentication. The proposed method can locate tampered region and detect the nature of the modification, including object insertion, removal, replacement, copy-move and cut-to-paste operations. QZMs considered as global features are used for image authentication while SIFT key-point features provide image forgery localization and classification. Proposed approach performance were evaluated on the color images database of UCID and compared with several recent and efficient methods. These experiments show that the proposed scheme provides a short hash length that is robust to most common image content-preserving manipulations like large angle rotations, and allows us to correctly locating forged image regions as well as detecting types of forgery image.
C1 [Ouyang, Junlin; Liu, Yizhi] Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411201, Peoples R China.
   [Ouyang, Junlin; Liu, Yizhi] Hunan Univ Sci & Technol, Coll Hunan Prov, Key Lab Knowledge Proc & Networked Mfg, Xiangtan 411201, Peoples R China.
   [Shu, Huazhong] Southeast Univ, Sch Comp Sci & Engn, Lab Image Sci & Technol, Nanjing 210096, Jiangsu, Peoples R China.
   [Shu, Huazhong] Ctr Rech Informat Med Sino Francais CRIBs, F-35000 Rennes, France.
C3 Hunan University of Science & Technology; Hunan University of Science &
   Technology; Southeast University - China; Universite de Rennes
RP Ouyang, JL (corresponding author), Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411201, Peoples R China.; Ouyang, JL (corresponding author), Hunan Univ Sci & Technol, Coll Hunan Prov, Key Lab Knowledge Proc & Networked Mfg, Xiangtan 411201, Peoples R China.
EM yangjunlin0732@163.com
OI Ouyang, Junlin/0000-0001-7155-2732
FU National Natural Science Foundation of China [61271312]; Research Fund
   for the Hunan Provincial Natural Science Foundation of china
   [2015JJ2056]; Hunan Provincial University Innovation Platform Open Fund
   Project of China [14K037]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61271312, the Research Fund for the Hunan Provincial
   Natural Science Foundation of china under Grant 2015JJ2056, and the
   Hunan Provincial University Innovation Platform Open Fund Project of
   China Grant 14K037.
CR Battiato S, 2012, IEEE T INF FOREN SEC, V7, P1105, DOI 10.1109/TIFS.2012.2194285
   Beijing Chen, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P625, DOI 10.1109/ICPR.2010.158
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Choi YS, 2012, MULTIMED TOOLS APPL, V61, P181, DOI 10.1007/s11042-010-0724-7
   De Roover C, 2005, IEEE T SIGNAL PROCES, V53, P4020, DOI 10.1109/TSP.2005.855414
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fridrich J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P178, DOI 10.1109/ITCC.2000.844203
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Kozat SS, 2004, IEEE IMAGE PROC, P3443, DOI 10.1109/ICIP.2004.1421855
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu WJ, 2010, IEEE IMAGE PROC, P989, DOI 10.1109/ICIP.2010.5650613
   Lv XD, 2012, IEEE T INF FOREN SEC, V7, P1081, DOI 10.1109/TIFS.2012.2190594
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Ouyang JL, 2015, DIGIT SIGNAL PROCESS, V41, P98, DOI 10.1016/j.dsp.2015.03.006
   Qin C, 2013, DIGIT SIGNAL PROCESS, V23, P578, DOI 10.1016/j.dsp.2012.11.002
   Roy S, 2007, IEEE IMAGE PROC, P2913
   Sangwine SJ, 1966, ELECTRON LETT, V32, P1979
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Tang Z, 2013, ABSTR APPL ANAL, DOI 10.1155/2013/946243
   Tang ZJ, 2012, APPL MATH INFORM SCI, V6, p643S
   Wang XF, 2012, J VIS COMMUN IMAGE R, V23, P782, DOI 10.1016/j.jvcir.2012.03.005
   Xiang S, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P121
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
NR 23
TC 33
Z9 41
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2609
EP 2626
DI 10.1007/s11042-015-3225-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000045
DA 2024-07-18
ER

PT J
AU Rani, A
   Raman, B
AF Rani, Asha
   Raman, Balasubramanian
TI An image copyright protection system using chaotic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermark; Visual cryptography; Singular value decomposition;
   Certified authority; Chaotic maps
ID VISUAL CRYPTOGRAPHY; WATERMARKING; SCHEME; ROBUST; TRANSFORM
AB In this paper, a simple and efficient watermarking method is proposed by using visual cryptography, singular value decomposition and chaotic maps. The proposed scheme uses a gray-level image as watermark instead of binary logo or bit sequence. The proposed scheme is a zero-watermarking scheme, where the watermark is not embedded directly in the host image. The host image is encrypted with secret watermark image by constructing two shares- master share and ownership share. The two shares separately do not give any information about the watermark but when stacked together, the watermark is revealed. Singular value decomposition has been used to select the robust features of the host image and chaotic maps have been used to improve the security. Experimental study is conducted to evaluate the robustness of the algorithm against various signal processing and geometrical attacks.
C1 [Rani, Asha; Raman, Balasubramanian] IIT Roorkee, Dept Comp Sci & Engn, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Rani, A (corresponding author), IIT Roorkee, Dept Comp Sci & Engn, Roorkee 247667, Uttar Pradesh, India.
EM asha0chaudhary@gmail.com; balarfma@iitr.ac.in
FU Council of Scientific and Industrial Research (CSIR), New Delhi
   [CSR-557-MTD]
FX This research work is supported by Council of Scientific and Industrial
   Research (CSIR), New Delhi under the grant number CSR-557-MTD.
CR Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   Bao JH, 2012, NONLINEAR DYNAM, V70, P1365, DOI 10.1007/s11071-012-0539-3
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Chang CC, 2002, PATTERN RECOGN LETT, V23, P931, DOI 10.1016/S0167-8655(02)00023-5
   Chen TH, 2009, COMPUT STAND INTER, V31, P1, DOI 10.1016/j.csi.2007.09.001
   Dyson FJ, 1992, MATH ASS AM, V99, P605
   Guitart O, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2400067
   Hardy G. H., 1980, An Introduction to the Theory of Numbers
   Horn R. A., 2012, MATRIX ANAL
   Hou YC, 2011, 2011 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P481, DOI 10.1109/SSP.2011.5967737
   Hsu CS, 2005, OPT ENG, V44, DOI 10.1117/1.1951647
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   Lin YK, 2014, COMPUT STAND INTER, V36, P855, DOI 10.1016/j.csi.2013.12.013
   Liu JL, 2006, COMPUT STAND INTER, V28, P356, DOI 10.1016/j.csi.2005.07.001
   Lou DC, 2007, COMPUT STAND INTER, V29, P125, DOI 10.1016/j.csi.2006.02.003
   Makbol NM, 2014, DIGIT SIGNAL PROCESS, V33, P134, DOI 10.1016/j.dsp.2014.06.012
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Rani A, 2011, INT C SOFT COMP PROB, P547
   Rani A, 2016, MULTIMED TOOLS APPL, V75, P1027, DOI 10.1007/s11042-014-2344-0
   Rani A, 2014, MULTIMED TOOLS APPL, V72, P2225, DOI 10.1007/s11042-013-1528-3
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Shieh JM, 2006, COMPUT STAND INTER, V28, P428, DOI 10.1016/j.csi.2005.03.006
   Su PC, 2013, IEEE T INF FOREN SEC, V8, P1897, DOI 10.1109/TIFS.2013.2282121
   Tirkel A. Z., 1993, Conference Proceedings DICTA-93 Digital Image Computing: Techniques and Applications, P666
   Voloshynovskiy S, 2001, IEEE COMMUN MAG, V39, P118, DOI 10.1109/35.940053
   Wang MS, 2009, COMPUT STAND INTER, V31, P757, DOI 10.1016/j.csi.2008.09.003
   Wu XT, 2013, APPL SOFT COMPUT, V13, P1170, DOI 10.1016/j.asoc.2012.09.028
   Yu LJ, 2005, IMAGE VISION COMPUT, V23, P807, DOI 10.1016/j.imavis.2005.05.014
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhao DW, 2004, CHAOS SOLITON FRACT, V22, P47, DOI 10.1016/j.chaos.2003.12.104
NR 30
TC 5
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 3121
EP 3138
DI 10.1007/s11042-016-3287-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000069
DA 2024-07-18
ER

PT J
AU Wang, JX
   Liu, Y
   Zhang, D
   Peng, HC
   Zhu, YH
AF Wang, Junxiang
   Liu, Ying
   Zhang, Dong
   Peng, Huacang
   Zhu, Yonghong
TI A new computer vision based multi-indentation inspection system for
   ceramics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Indentation defect; Ceramic roundness; Multi-indentation detection;
   Computer vision
AB Ceramic has been one of most important daily used items since ancient ages. As the worldwide ceramic production grows, the quality evaluation for ceramics comes into a critical task for silicate industry. Automatic evaluation of ceramic shape has the potential to improve the ceramic product quality and production efficiency. This paper proposes an online automatic inspection system and a new algorithm for defect detection and feature analysis based on computer vision technology. The hardware module of the proposed system is designed to transport ceramic products in a suitable speed, acquire images of products, and perform intelligent control. The software module of the systems detects ceramic outline and evaluates the size of defects from the acquired product images. Experimental results show the efficiency and accuracy of the proposed system.
C1 [Wang, Junxiang; Liu, Ying; Peng, Huacang; Zhu, Yonghong] Jingdezhen Ceram Inst, Sch Mech & Elect Engn, Jingdezhen Shi 333403, Jiangxi, Peoples R China.
   [Wang, Junxiang] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210000, Jiangsu, Peoples R China.
   [Zhang, Dong] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
C3 Jingdezhen Ceramic Institute; Nanjing University of Information Science
   & Technology; Sun Yat Sen University
RP Wang, JX (corresponding author), Jingdezhen Ceram Inst, Sch Mech & Elect Engn, Jingdezhen Shi 333403, Jiangxi, Peoples R China.; Wang, JX (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210000, Jiangsu, Peoples R China.
EM wjx851113851113@163.com; ly6930892@163.com; zhangd@mail.sysu.edu.cn;
   HuacangPeng@163.com; zyh_patrick@163.com
RI Zhang, Jiaqi/JCO-6818-2023
FU National Science Foundation of China [61402209, 61100170, 61164014,
   61563022]; Invention Patent Industrialization Demonstration Project of
   Jiangxi Province [20143BBM26113]; CICAEET fund; PAPD fund
FX This work is supported by the National Science Foundation of China
   (61402209, 61100170, 61164014 and 61563022), Invention Patent
   Industrialization Demonstration Project of Jiangxi Province
   (20143BBM26113) and the CICAEET fund and the PAPD fund.
CR Amenabar I, 2013, J INFRARED MILLIM TE, V34, P152, DOI 10.1007/s10762-012-9949-z
   Amenabar I, 2011, COMPOS PART B-ENG, V42, P1298, DOI 10.1016/j.compositesb.2011.01.025
   [Anonymous], 2007, THESIS
   Anton SR, 2012, IEEE T ULTRASON FERR, V59, P1085, DOI 10.1109/TUFFC.2012.2299
   Can W, 2015, MANUF AUTOM, V37, P94
   Chan FWY, 2010, NDT&E INT, V43, P210, DOI 10.1016/j.ndteint.2009.11.005
   Chotard T, 2001, CEMENT CONCRETE RES, V31, P405, DOI 10.1016/S0008-8846(00)00446-4
   Courtney P, 2003, ECVISION WHITE PAPER
   Forsyth D.S., 2006, AMMTIAC Q, V1, P7
   García-Martín J, 2011, SENSORS-BASEL, V11, P2525, DOI 10.3390/s110302525
   Greminger MA, 2004, IEEE T PATTERN ANAL, V26, P290, DOI 10.1109/TPAMI.2004.1262305
   Huang Q, 2007, NANOTECHNOLOGY, V18
   Jasiuniene E, 2009, INSIGHT, V51, P477, DOI 10.1784/insi.2009.51.9.477
   Kalinichenko NP, 2011, RUSS J NONDESTRUCT+, V47, P663, DOI 10.1134/S1061830911100081
   Kasai N, 2011, NDT&E INT, V44, P421, DOI 10.1016/j.ndteint.2011.03.004
   Leta F.R., 2006, ABCM Symposium Series in Mechatronics, V2, P645
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Momono Tatsunobu., 1999, Motion Control, V6, P29
   Oda I, 1998, JPN J APPL PHYS 1, V37, P3304, DOI 10.1143/JJAP.37.3304
   Perner P, 2001, PATTERN RECOGN LETT, V22, P47, DOI 10.1016/S0167-8655(00)00098-2
   Pratt V., 1987, COMPUTER GRAPHICS AC, V21, P145, DOI DOI 10.1145/37402.37420
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xiong W, 2008, CHINA CERAM, V44, P1001
NR 23
TC 6
Z9 6
U1 5
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2495
EP 2513
DI 10.1007/s11042-015-3223-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000039
DA 2024-07-18
ER

PT J
AU Zhao, ZQ
   Wang, TJ
   Liu, F
   Choe, G
   Yuan, CH
   Cui, ZM
AF Zhao, Zhiqiang
   Wang, Tianjiang
   Liu, Fang
   Choe, Gwangmin
   Yuan, Caihong
   Cui, Zongmin
TI Remarkable local resampling based on particle filter for visual tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remarkable local resampling; Particle filtering; Visual tracking; Double
   threshold
AB Generally, particle filters need a large number of particles to approximate the posterior for the purpose of ideal effect. Previous methods extract remarkable particles from the particles at time t-1 by nonlinear function. Those methods use the remarkable particles to reduce the number of particles and improve the accuracy of particle filter. However, the nonlinear function extracts the remarkable particles, which will weaken or even ignore useful remarkable local particles. Thus this paper presents a new resampling scheme to extract remarkable local particles. We propose a weight threshold and a distance threshold to extract remarkable local particles from particles at time t-1. Meanwhile, we use these remarkable local particles to track the target analytically. Besides, we propose a global transition model to improve the accuracy of the particle filter. Based on remarkable local resampling scheme and the global transition model, we propose a new framework of particle filter. Finally, experiments show that our framework has higher efficiency than previous methods in the case of fewer particles.
C1 [Zhao, Zhiqiang; Wang, Tianjiang; Liu, Fang; Choe, Gwangmin; Yuan, Caihong] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Intelligent & Distributed Comp Lab, Wuhan 430074, Peoples R China.
   [Zhao, Zhiqiang; Cui, Zongmin] Univ Jiujiang, Sch Informat Sci & Technol, Jiujiang 332005, Jiangxi, Peoples R China.
   [Yuan, Caihong] Henan Univ, Sch Comp & Informat Engn, Kaifeng 475004, Henan, Peoples R China.
C3 Huazhong University of Science & Technology; Jiujiang University; Henan
   University
RP Zhao, ZQ; Wang, TJ (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Intelligent & Distributed Comp Lab, Wuhan 430074, Peoples R China.; Zhao, ZQ (corresponding author), Univ Jiujiang, Sch Informat Sci & Technol, Jiujiang 332005, Jiangxi, Peoples R China.
EM zq_zhao@hust.edu.cn; tjwang@hust.edu.cn; fliu@hust.edu.cn;
   cca2005@foxmail.com; yuanch@hust.edu.cn
FU National Nature Science of China [61572214, 61462048]; Wuhan Science and
   Technology Bureau of Hubei Province, China [2014010202010110]
FX Thank the editors and the anonymous referees for their valuable
   comments. This work was supported by the National Nature Science of
   China (No. 61572214 and 61462048), and Wuhan Science and Technology
   Bureau of Hubei Province, China (No. 2014010202010110).
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bolic M, 2005, IEEE T SIGNAL PROCES, V53, P2442, DOI 10.1109/TSP.2005.849185
   Bolic M, 2004, EURASIP J APPL SIG P, V2004, P2267, DOI 10.1155/S1110865704405149
   Cappé O, 2007, P IEEE, V95, P899, DOI 10.1109/JPROC.2007.893250
   Choe G, 2014, MULTIMED TOOLS APPL, P1
   Djuric PM, 2003, IEEE SIGNAL PROC MAG, V20, P19, DOI 10.1109/MSP.2003.1236770
   Douc R, 2005, ISPA 2005: Proceedings of the 4th International Symposium on Image and Signal Processing and Analysis, P64, DOI 10.1109/ISPA.2005.195385
   Fearnhead P, 2003, J R STAT SOC B, V65, P887, DOI 10.1111/1467-9868.00421
   Godec M, 2013, COMPUT VIS IMAGE UND, V117, P1245, DOI 10.1016/j.cviu.2012.11.005
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   Guo YW, 2014, COMPUT VIS IMAGE UND, V118, P128, DOI 10.1016/j.cviu.2013.09.007
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Islam M. M., 2013, SCI WORLD J, V2013, P10, DOI 10.1155/2013/378420
   Julier Simon J., 1995, American Control Conference, Proceedings of the 1995, V3
   Li T, 2013, 2013 16 INT C IEEE I
   Li TC, 2012, SIGNAL PROCESS, V92, P1637, DOI 10.1016/j.sigpro.2011.12.019
   Liang J., 2010, Recent Patents on Electrical Engineering, V3, P43, DOI 10.2174/1874476111003010043
   Liu JS, 1998, J AM STAT ASSOC, V93, P1022
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Tang X, 2012, INT J ADAPT CONTROL, V26, P1013, DOI 10.1002/acs.2279
   Yao AB, 2012, PATTERN RECOGN, V45, P2584, DOI 10.1016/j.patcog.2012.01.016
NR 23
TC 8
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 835
EP 860
DI 10.1007/s11042-015-3075-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000036
DA 2024-07-18
ER

PT J
AU Abu Dalhoum, AL
   Madain, A
   Hiary, H
AF Abu Dalhoum, Abdel Latif
   Madain, Alia
   Hiary, Hazem
TI Digital image scrambling based on elementary cellular automata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image scrambling; Elementary cellular automata; Complex and chaotic
   rules; One-dimensional scrambling
ID ENCRYPTION; ALGORITHM
AB Image scrambling is the process of converting an image to an unintelligible format, mainly for security reasons. The scrambling is considered as a pre-process or a post-process of security related applications such as watermarking, information hiding, fingerprinting, and encryption. Cellular automata are parallel models of computation that prove an interesting concept where a simple configuration can lead to a complex behavior. Since there are a lot of parameters to configure, cellular automata have many types and these types differ in terms of complexity and behavior. Cellular automata were previously used in scrambling different types of multimedia, but only complex two-dimensional automata were explored. We propose a scheme where the simplest type of cellular automata is used that is the elementary type. We test the scrambling degree for different cellular automata rules that belong to classes three and four of Wolfram's classification which correspond to complex and chaotic behavior; we also check the effect of other parameters such as the number of generations and the boundary condition. Experimental results show that our proposed scheme outperforms other schemes based on cellular automata in terms of scrambling degree.
C1 [Abu Dalhoum, Abdel Latif; Madain, Alia; Hiary, Hazem] Univ Jordan, Amman 11942, Jordan.
C3 University of Jordan
RP Hiary, H (corresponding author), Univ Jordan, Amman 11942, Jordan.
EM hazemh@ju.edu.jo
RI ; Hiary, Hazem/C-8358-2015
OI Madain, Alia/0000-0001-8865-9755; Hiary, Hazem/0000-0002-0306-5294
CR Abu Dalhoum AL, 2012, IEEE MULTIMEDIA, V19, P28, DOI 10.1109/MMUL.2011.54
   Augustine N., 2014, 2014 IEEE INT C EL C, P1
   George SN, 2014, MULTIMED TOOLS APPL, P1
   Li H, 2009, ICEBE 2009: IEEE INTERNATIONAL CONFERENCE ON E-BUSINESS ENGINEERING, PROCEEDINGS, P165, DOI 10.1109/ICEBE.2009.30
   Li H, 2009, 2009 INTERNATIONAL CONFERENCE ON INDUSTRIAL AND INFORMATION SYSTEMS, PROCEEDINGS, P316, DOI 10.1109/IIS.2009.105
   Li H, 2009, LECT NOTES COMPUT SC, V5574, P866
   Li HJ, 2013, OPT LASER ENG, V51, P1327, DOI 10.1016/j.optlaseng.2013.05.011
   Li XW, 2014, OPTIK, V125, P2983, DOI 10.1016/j.ijleo.2013.12.036
   Liu S, 2013, OPT COMMUN, V287, P73, DOI 10.1016/j.optcom.2012.09.033
   Liu Xiangdong, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P818, DOI 10.1109/CSSE.2008.1424
   Liu ZJ, 2013, OPTIK, V124, P5391, DOI 10.1016/j.ijleo.2013.03.118
   Liu ZJ, 2012, OPT LASER ENG, V50, P248, DOI 10.1016/j.optlaseng.2011.08.006
   Madain A, 2014, MULTIMED TOOLS APPL, V71, P1803, DOI 10.1007/s11042-012-1306-7
   Maleki F, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P1266, DOI 10.1109/ARES.2008.121
   Niu Jiping, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P677, DOI 10.1109/CSSE.2008.1172
   Parah SA, 2014, COMPUT ELECTR ENG, V40, P70, DOI 10.1016/j.compeleceng.2013.11.006
   Sang-Ho Shin, 2009, 2009 International Conference on Computational Science and Engineering (CSE), P399, DOI 10.1109/CSE.2009.299
   Shang ZW, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P2942, DOI 10.1109/ICYCS.2008.99
   Wang Taiyue, 2014, Wuhan University Journal of Natural Sciences, V19, P315, DOI 10.1007/s11859-014-1019-z
   Wolfram S., 2002, A new kind of science
   Wu JH, 2014, OPTIK, V125, P4474, DOI 10.1016/j.ijleo.2014.02.026
   [向德生 Xiang Desheng], 2005, [计算机工程与应用, Computer Engineering and Application], V41, P44
   Yan W. Q., 2010, FUNDAMENTALS MEDIA S
   Ye GD, 2007, CIS: 2007 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PROCEEDINGS, P843, DOI 10.1109/CIS.2007.120
   Ye RS, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P938, DOI 10.1109/ISECS.2008.138
   Zefreh E. Zarei, 2011, 2011 CSI International Symposium on Computer Science and Software Engineering (CSSE 2011), P77, DOI 10.1109/CSICSSE.2011.5963985
   Zhang L, 2005, LECT NOTES ARTIF INT, V3802, P977
   Zhong Z, 2012, OPT COMMUN, V285, P584, DOI 10.1016/j.optcom.2011.11.025
   Zhou YC, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3695
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu LH, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P601
NR 31
TC 18
Z9 18
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17019
EP 17034
DI 10.1007/s11042-015-2972-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600014
DA 2024-07-18
ER

PT J
AU Bekhet, S
   Ahmed, A
   Altadmri, A
   Hunter, A
AF Bekhet, Saddam
   Ahmed, Amr
   Altadmri, Amjad
   Hunter, Andrew
TI Compressed video matching: Frame-to-frame revisited
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE F-2-F matching; Compressed domain; Local features; Trajectories; SIFT;
   MPEG; DC-image
AB This paper presents an improved frame-to-frame (F-2-F) compressed video matching technique based on local features extracted from reduced size images, in contrast with previous F-2-F techniques that utilized global features extracted from full size frames. The revised technique addresses both accuracy and computational cost issues of the traditional F-2-F approach. Accuracy is improved through using local features, while computational cost issue is addressed through extracting those local features from reduced size images. For compressed videos, the DC-image sequence, without full decompression, is used. Utilizing such small size images (DC-images) as a base for the proposed work is important, as it pushes the traditional F-2-F from off-line to real-time operational mode. The proposed technique involves addressing an important problem: namely the extraction of enough local features from such a small size images to achieve robust matching. The relevant arguments and supporting evidences for the proposed technique are presented. Experimental results and evaluation, on multiple challenging datasets, show considerable computational time improvements for the proposed technique accompanied by a comparable or higher accuracy than state-of-the-art related techniques.
C1 [Bekhet, Saddam; Ahmed, Amr; Hunter, Andrew] Lincoln Univ, Brayford Pool LN6 7TS, Lincoln, England.
   [Altadmri, Amjad] Univ Kent, Sch Comp, Canterbury CT2 7NF, Kent, England.
C3 University of Lincoln; University of Kent
RP Bekhet, S (corresponding author), Lincoln Univ, Brayford Pool LN6 7TS, Lincoln, England.
EM sbekhet@lincoln.ac.uk; aahmed@lincoln.ac.uk; amjad.altadmri@gmail.com;
   ahunter@lincoln.ac.uk
RI Bekhet, Saddam/U-7038-2019; Ahmed, Amr/A-4585-2009
OI Bekhet, Saddam/0000-0002-3028-6500; Altadmri, Amjad/0000-0002-9799-6638;
   Ahmed, Amr/0000-0002-7749-7911
FU SouthValley University-Egypt
FX This work is funded By SouthValley University-Egypt.
CR Abbass A., 2012, P APPL INF COMP THEO
   Adjeroh DA, 1998, INTERNATIONAL WORKSHOP ON MULTI-MEDIA DATABASE MANAGEMENT SYSTEMS- PROCEEDINGS, P72, DOI 10.1109/MMDBMS.1998.709503
   Almeida Jurandy, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3673, DOI 10.1109/ICIP.2011.6116516
   Altadmri A, 2009, VIDEO DATABASES ANNO
   Altadmri A., 2013, MULTIMEDIA APPL TOOL, V64, P1
   [Anonymous], 2011, TRECVID 2010 OVERVIE
   [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   [Anonymous], 2009, P CORIA
   Bekhet S, 2013, LECT NOTES ENG COMP, P2209
   Dimitrova N., 1999, VIDEO RETRIEVAL MPEG
   Droueche Z, 2012, IFMBE PROC, V37, P622
   Han-ping Gao, 2010, Proceedings 2010 International Symposium on Intelligence Information Processing and Trusted Computing (IPTC 2010), P689, DOI 10.1109/IPTC.2010.30
   Hua XS, 2004, IEEE IMAGE PROC, P685
   Karpenko A, 2011, IEEE T PATTERN ANAL, V33, P618, DOI 10.1109/TPAMI.2010.118
   Kogler M, 2009, CEUR WORKSHOP PROC
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2003, PROC CVPR IEEE, P257
   Ng CW, 2001, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS AND TECHNOLOGY, VOLS I AND II, P184
   Shan MK, 1998, INTERNATIONAL WORKSHOP ON MULTI-MEDIA DATABASE MANAGEMENT SYSTEMS- PROCEEDINGS, P90, DOI 10.1109/MMDBMS.1998.709508
   TrecVid, 2011, TREC VID RETR TASK B
   Yeo BL, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pB260
NR 22
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15763
EP 15778
DI 10.1007/s11042-015-2887-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700039
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Chen, H
   Ouyang, YQ
   Jiang, W
AF Chen, Hao
   Ouyang, Yueqi
   Jiang, Wen
TI An optimized data integration model based on reverse cleaning for
   heterogeneous multi-media data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-media data; Heterogeneous data integration; Reverse cleaning
ID GENERALIZED M-SET
AB With the continuous development of information technology, various multi-media data are constantly emerging and presents the characteristics of autonomous and heterogeneous, how to integrate and analysis data more correctly and efficiently has become a challenging problem. Firstly, in order to improve the quality of the integrated data, two real-time threads combined with data adapter are used to monitor and refresh necessary updates from heterogeneous data efficiently. Once the original data has been updated, the real-time data will be loaded into the data center soon. Secondly, a data reverse cleaning method is proposed to improve the data quality. It uses the data source tree that built in the data integration process to find the location of the original data quickly after reverse cleaning. finally, a data accuracy assessment algorithm is designed for data quality assessment, which is based on Bayesian network and the path condition algorithm. Experimental results show that the quality of the integrated data significantly higher than the quality of the original data.
C1 [Chen, Hao; Ouyang, Yueqi; Jiang, Wen] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Jiang, Wen] Hunan Vocat Coll Sci & Technol, Sch Software, Changsha 410118, Hunan, Peoples R China.
C3 Hunan University
RP Chen, H (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM chenhao@hnu.edu.cn
FU National Science Foundation of China [61472132, 61472131, 61300218]
FX This paper is partly supported by the National Science Foundation of
   China (Grant No. 61472132, 61472131, and 61300218).
CR Aikebaier A, 2011, HUM-CENTRIC COMPUT I, V1, DOI 10.1186/2192-1962-1-6
   [Anonymous], 1998, U.S. Patent, Patent No. [5,805,804, 5805804]
   [Anonymous], 2014, J. Converg. Inf. Technol.
   [Anonymous], J CONVERGENCE
   Chen H, 2013, TISSUE BARRIERS, V1, DOI 10.4161/tisb.27463
   Chen H, 2009, WORLD SUMMIT ON GENETIC AND EVOLUTIONARY COMPUTATION (GEC 09), P799
   Clinchant S, 2011, P 1 ACM INT C MULT R, P44
   Dong X.L., 2015, Synthesis Lectures on Data Management, V7, P1, DOI DOI 10.2200/S00578ED1V01Y201404DTM040
   GEMMELL J, 1992, ACM T INFORM SYST, V10, P51, DOI 10.1145/128756.128758
   Hao Chen, 2008, J COMPUT INF SYST BI, V4, P2641
   Huang TS, 2008, P IEEE, V96, P648, DOI 10.1109/JPROC.2008.916364
   Jiang L, 2014, INT J DISTRIB SENS N
   Katsumata M, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0017-7
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   Liu S, 2013, APPL MATH COMPUT, V220, P668, DOI 10.1016/j.amc.2013.06.096
   Naphade MR, 2002, IEEE T NEURAL NETWOR, V13, P793, DOI 10.1109/TNN.2002.1021881
   Ohm J., 2015, MULTIMEDIA SIGNAL CO, P491
   Poisel R., 2011, Proceedings of the 2011 6th International Conference on IT Security Incident Management and IT Forensics (IMF 2011), P48, DOI 10.1109/IMF.2011.14
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Yadav PK, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P541, DOI 10.1109/ICICICT.2014.6781339
   Yang GL, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/398583
NR 22
TC 3
Z9 3
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15571
EP 15586
DI 10.1007/s11042-015-2683-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700028
DA 2024-07-18
ER

PT J
AU Liu, S
   Zhang, ZB
   Qi, LY
   Ma, M
AF Liu, Shuai
   Zhang, Zhibin
   Qi, Lingyun
   Ma, Ming
TI A fractal image encoding method based on statistical loss used in
   agricultural image compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encoding; Image compression; Fractal encoding; Statistical loss;
   Agricultural images
ID GENERALIZED M-SET; CROPS
AB Nowadays, many images of cropland are photographed and transferred by wireless sensors in agricultural automation. But one contradiction is that the recognition needs images with high quality and the transmission needs images with small sizes. So, in this paper, by extracted and analyzedthe loss in the fractal encoding,we use fractal image encoding into the compression because of its high compression ratio. To solve the most important problemin fractal image encoding method,which is its high computational complexityand long encoding time, we first use statisticalanalysis to the fractal encoding method. We create its box-plot to find the distributional of loss value. Then, we partition them to several parts and map them to the given model. After that, we present a novel method to save the loss and maintain the quality in image compression. Finally, agricultural experimental results show effectiveness of the novel method.
C1 [Liu, Shuai; Zhang, Zhibin; Qi, Lingyun; Ma, Ming] Inner Mongolia Univ, Coll Comp Sci, Hohhot 010012, Peoples R China.
   [Liu, Shuai] Inner Mongolia Univ, Sch Phys Sci & Technol, Hohhot 010012, Peoples R China.
C3 Inner Mongolia University; Inner Mongolia University
RP Zhang, ZB (corresponding author), Inner Mongolia Univ, Coll Comp Sci, Hohhot 010012, Peoples R China.
EM cs_liushuai@imu.edu.cn; cszhibin@imu.edu.cn; 1223865610@qq.com;
   csmaming@imu.edu.cn
RI Liu, Shuai/AAB-1960-2019; Liu, Shuai/AAX-1239-2021; Zhang,
   Z/ABG-6120-2020; Liu, Shuai/P-3939-2017
OI Liu, Shuai/0000-0001-9909-0664; Liu, Shuai/0000-0001-9909-0664
FU Grants Programs of Higher-level talents of Inner Mongolia University
   [125126, 115117, 135103]; Scientific projects of higher school of Inner
   Mongolia [NJZY13004]; Natural Science Foundation of Inner Mongolia
   [2014BS0602, 2014BS0606]; National Natural Science Foundation of China
   [31160253, 31360289]
FX This work is supported by Grants Programs of Higher-level talents of
   Inner Mongolia University [No. 125126, 115117, 135103], Scientific
   projects of higher school of Inner Mongolia [No. NJZY13004], Natural
   Science Foundation of Inner Mongolia [No. 2014BS0602, 2014BS0606],
   National Natural Science Foundation of China [No. 31160253, 31360289].
CR Ahmed F, 2012, CROP PROT, V40, P98, DOI 10.1016/j.cropro.2012.04.024
   [Anonymous], 1980, FIXED POINT THEOREMS
   Barnsley M. F., 1988, Proceedings of the SPIE - The International Society for Optical Engineering, V1001, P122, DOI 10.1117/12.968945
   BEDFORD T, 1994, SIGNAL PROCESS-IMAGE, V6, P405, DOI 10.1016/0923-5965(94)90003-5
   Bhavani S, 2013, IET IMAGE PROCESS, V7, P686, DOI 10.1049/iet-ipr.2012.0041
   Chang HT, 2000, IEEE T IMAGE PROCESS, V9, P329, DOI 10.1109/83.826772
   Falconer K., 2003, FRACTAL GEOMETRY MAT, V2, DOI DOI 10.1002/0470013850
   Fukatsu T, 2011, COMPUT STAND INTER, V33, P565, DOI 10.1016/j.csi.2011.03.002
   GOEBEL K, 1972, P AM MATH SOC, V35, P171, DOI 10.2307/2038462
   Guo J, 2011, J INF PROCESS SYST, V7, P103, DOI 10.3745/JIPS.2011.7.1.103
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Binh HTT, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0013-y
   Huircán JI, 2010, COMPUT ELECTRON AGR, V74, P258, DOI 10.1016/j.compag.2010.08.014
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Jiang GQ, 2015, EXPERT SYST APPL, V42, P2429, DOI 10.1016/j.eswa.2014.10.033
   Kim IK, 1996, IEEE T IMAGE PROCESS, V5, P587, DOI 10.1109/83.491335
   Lai CM, 2003, IEEE T IMAGE PROCESS, V12, P1398, DOI 10.1109/TIP.2003.817246
   Li JL, 2002, IEEE T IMAGE PROCESS, V11, P636, DOI 10.1109/TIP.2002.1014995
   Liu M, CHINESE J E IN PRESS
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   Liu S, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/503924
   Liu S, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/281707
   Liu S, 2013, APPL MATH COMPUT, V220, P668, DOI 10.1016/j.amc.2013.06.096
   Mandelbrot BB, 1982, FRACTAL GEOMETRY NAT
   Marchant JA, 1996, COMPUT ELECTRON AGR, V15, P161, DOI 10.1016/0168-1699(96)00014-2
   MONRO DM, 1992, ELECTRON LETT, V28, P1053, DOI 10.1049/el:19920667
   Rao K.R, 2014, DISCRETE COSINE TRAN
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Turaga DS, 2004, SIGNAL PROCESS-IMAGE, V19, P173, DOI 10.1016/j.image.2003.09.001
   Udayan JD, 2013, J CONVERG, V4, P6
   Wang XY, 2008, COMPUT GRAPH-UK, V32, P445, DOI 10.1016/j.cag.2008.02.004
   Yang GL, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/398583
   Zhang LK, 2012, COMPUT ELECTRON AGR, V89, P1, DOI 10.1016/j.compag.2012.07.012
   Zhang Y, 2012, NONLINEAR ANAL-REAL, V13, P106, DOI 10.1016/j.nonrwa.2011.07.017
NR 34
TC 54
Z9 55
U1 0
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15525
EP 15536
DI 10.1007/s11042-014-2446-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700025
DA 2024-07-18
ER

PT J
AU Yeh, MC
   Chiu, HK
   Wang, JS
AF Yeh, Mei-Chen
   Chiu, Han-Kuen
   Wang, Jia-Shung
TI Fast medium-scale multiperson identification in aerial videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human identity recognition; Aerial video; Image matching; Video
   surveillance
AB Vision systems for unmanned aerial vehicles (UAVs) have been gaining increasing attention for surveillance and civil applications. However, aerial platforms create new challenges for several vision tasks (e.g., human tracking and identification) because UAV-mounted cameras undergo large vibration movements and capture unstable videos. Furthermore, most existing machine vision approaches use the fine details of a human figure, which are unavailable in low-quality aerial images. We propose a new blob-matching approach for human identification in aerial videos in which the identity of a human blob is estimated using an adaptive reference set of previously identified people. A target can be quickly located by matching only the target and a carefully selected candidate set. The experimental results obtained using several challenging aerial videos validated the effectiveness and computational efficiency of the proposed method.
C1 [Yeh, Mei-Chen] Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Chiu, Han-Kuen; Wang, Jia-Shung] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 National Taiwan Normal University; National Tsing Hua University
RP Yeh, MC (corresponding author), Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
EM myeh@csie.ntnu.edu.tw
CR Bak S, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P175, DOI 10.1109/AVSS.2014.6918664
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Bristeau Pierre-Jean, 2011, IFAC Proc., V44, P1477, DOI DOI 10.3182/20110828-6-IT-1002.02327
   Cohen I, 1998, DETECTION TRACKING O
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2002, IEEE IMAGE PROC, P33
   Elhamod M, 2013, IEEE T INTELL TRANSP, V14, P688, DOI 10.1109/TITS.2012.2228640
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Huang Y, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON COMPUTER TECHNOLOGY AND DEVELOPMENT, VOL 2, P320, DOI 10.1109/ICCTD.2009.67
   Kamvar Sepandar D., 2003, P 12 INT C WORLD WID, P261, DOI DOI 10.1145/775152.775190
   Kuo CH, 2011, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2011.5995384
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Oreifej O, 2010, PROC CVPR IEEE, P709, DOI 10.1109/CVPR.2010.5540147
   Park U, 2006, INT C PATT RECOG, P1204
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701
   Seo HJ, 2010, IEEE T PATTERN ANAL, V32, P1688, DOI 10.1109/TPAMI.2009.153
   Sharp CS, 2001, IEEE INT CONF ROBOT, P1720, DOI 10.1109/ROBOT.2001.932859
   Shim S, 2003, IEEE INT C IM PROC
   Yue ZF, 2009, IEEE T CIRC SYST VID, V19, P77, DOI 10.1109/TCSVT.2008.2009243
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
NR 21
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16117
EP 16133
DI 10.1007/s11042-015-2921-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700056
DA 2024-07-18
ER

PT J
AU Kim, H
   Kim, Y
   Chang, H
AF Kim, Hyeri
   Kim, Yanghoon
   Chang, Hangbae
TI Information security research classification for future multimedia
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information security; Information security research classification;
   Information security research trends; Future multimedia environment
ID NEED
AB In spite of the advancement of information security (IS) technology, information leakage incidents and accidents are continuously occurring. Its reason is because only technical countermeasures are devised rather than implementing countermeasures based on business perspective regarding IS. Accordingly, the purpose of this study is to design a classification system in the area of IS to solve such problem and seek balanced advancement, as well as examine the trend of IS researches that have been conducted. Upon designing the classification system based on the areas of IS technology and IS management for the IS academic areas, Korea domestic and international academic journals in the area of IS were selected to research and analyze theses that have been published in the last 5 years. The research result showed that there were more studies on IS technology area than IS management area, thereby confirming the greater research emphasis in the area of technology. In specific according to area, number of Korea domestic researches on infrastructure security technology was the highest in the area of IS technology. In the case of international researches, number of researches on the security of infrastructure was the highest. As for the IS management area, number of Korea domestic researches on IS level diagnosis was the highest, while number international researches on IS human resource management was the highest. The significance of this study is to contribute to the balanced advancement of IS area by designing IS classification system to present IS research trend and future research direction.
C1 [Kim, Hyeri] Chung Ang Univ, Management Technol & Secur Lab, Seoul, South Korea.
   [Kim, Yanghoon] Far East Univ, Dept Cyber Secur, Chungcheongbuk Do, South Korea.
   [Chang, Hangbae] Chung Ang Univ, Dept Ind Secur, Coll Business & Econ, Seoul, South Korea.
C3 Chung Ang University; Chung Ang University
RP Chang, H (corresponding author), Chung Ang Univ, Dept Ind Secur, Coll Business & Econ, Seoul, South Korea.
EM hyeriam@hotmail.com; yhkim@kdu.ac.kr; hbchang@cau.ac.kr
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC (Information Technology Research Center) support program
   [IITP-2015-H8501-15-1018]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (IITP-2015-H8501-15-1018) supervised by the IITP
   (Institute for Information & communications Technology Promotion).
CR Allen M, 1999, CRIT STUD MASS COMM, V16, P373, DOI 10.1080/15295039909367102
   Cockcroft S, 2002, J INF SYST ED, V13, P205
   Cooper H.M., 2009, Research synthesis and meta-analysis
   Da Veiga A, 2007, INFORM SYST MANAGE, V24, P361, DOI 10.1080/10580530701586136
   Lee MH, 2009, INT J SCI EDUC, V31, P1999, DOI 10.1080/09500690802314876
   Logan P. Y., 2002, J INF SYST ED, V13, P177
   Nelson HD, 2006, JAMA-J AM MED ASSOC, V295, P2057, DOI 10.1001/jama.295.17.2057
   Venter HS, 2003, COMPUT SECUR, V22, P299, DOI 10.1016/S0167-4048(03)00406-1
   Wallace W., 1992, METATHEORIZING, P53
   Wolf Wolf F. M F. M, Meta-analysis: Quantitative methods for research synthesis
   Wright MA, 1998, COMPUT FRAUD SECUR, P14, DOI 10.1016/S1361-3723(98)80019-5
NR 11
TC 3
Z9 3
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14795
EP 14806
DI 10.1007/s11042-015-2638-x
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500046
DA 2024-07-18
ER

PT J
AU Su, LM
   Lu, F
AF Su, Lumei
   Lu, Feng
TI Visual facial expression modeling and early predicting from 3D data via
   subtle feature enhancing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression; Feature enhancement; Adaptive wavelet spectral
   subtraction; Linear discriminant analysis-based SVM
ID RECOGNITION; DIFFUSION
AB This work investigates a new challenging problem: how to exactly recognize facial expression captured by a high-frame rate 3D sensing as early as possible, while most works generally focus on improving the recognition rate of 2D facial expression recognition. The recognition of subtle facial expressions in their early stage is unfortunately very sensitive to noise that cannot be ignored due to their low intensity. To overcome this problem, two novel feature enhancement methods, namely, adaptive wavelet spectral subtraction method and SVM-based linear discriminant analysis, are proposed to refine subtle features of facial expressions by employing an estimated noise model or not. Experiments on a custom-made dataset built using a high-speed 3D motion capture system corroborated that the two proposed methods outperform other feature refinement methods by enhancing the discriminability of subtle facial expression features and consequently make correct recognitions earlier.
C1 [Su, Lumei] Xiamen Univ Technol, Sch Elect Engn & Automat, Amoy, Fujian, Peoples R China.
   [Lu, Feng] Univ Tokyo, Inst Ind Sci, Tokyo, Japan.
C3 Xiamen University of Technology; University of Tokyo
RP Lu, F (corresponding author), Univ Tokyo, Inst Ind Sci, Tokyo, Japan.
EM sulumei@ut-vision.org; lufeng@ut-vision.org
RI Su, Lumei/HJH-3985-2023
FU Scientific Research Foundation of Xiamen University of Technology
   [YKJ13013R]
FX This research is supported by the Scientific Research Foundation of
   Xiamen University of Technology (Grant No. YKJ13013R).
CR Alexa M, 2002, SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P51, DOI 10.1109/SMI.2002.1003528
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], SUBTLE FACIAL EXPRES
   [Anonymous], P IEEE AUT FAC GEST
   [Anonymous], P 11 AUSTR INT C SPE
   [Anonymous], P INT C PATT REC
   [Anonymous], FUSION MULTICHANNEL
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Boehnen C, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P310, DOI 10.1109/3DIM.2005.13
   Calder AJ, 2001, VISION RES, V41, P1179, DOI 10.1016/S0042-6989(01)00002-5
   Chen CY, 2005, COMPUT AIDED GEOM D, V22, P376, DOI 10.1016/j.cagd.2005.04.003
   Clarenz U, 2000, IEEE VISUAL, P397, DOI 10.1109/VISUAL.2000.885721
   Cohn JF, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P396, DOI 10.1109/AFGR.1998.670981
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Ekman P., 2005, WHAT FACE REVEALS BA
   Fransens R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1289
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Lu F, 2014, IEEE T PATTERN ANAL, V36, P2033, DOI 10.1109/TPAMI.2014.2313123
   Lu F, 2014, IMAGE VISION COMPUT, V32, P169, DOI 10.1016/j.imavis.2014.01.005
   Park S, 2009, PATTERN RECOGN LETT, V30, P708, DOI 10.1016/j.patrec.2009.02.005
   Poruba J., 2002, Proceedings of the Fourth IEEE International Caracas Conference on Devices, Circuits and Systems (Cat. No.02TH8611), pT031, DOI 10.1109/ICCDCS.2002.1004114
   Song ML, 2006, IEEE IMAGE PROC, P2101, DOI 10.1109/ICIP.2006.312822
   Su LM, 2011, IEEE SYS MAN CYBERN, P3304, DOI 10.1109/ICSMC.2011.6084179
   Sun XF, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P37, DOI 10.1109/SMI.2008.4547945
   Sun Y, 2008, LECT NOTES COMPUT SC, V5303, P58, DOI 10.1007/978-3-540-88688-4_5
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   van Rhijn A, 2006, P IEEE VIRT REAL ANN, P135, DOI 10.1109/VR.2006.104
   Wen Z, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1343, DOI 10.1109/ICCV.2003.1238646
   Xiong T, 2005, IEEE IJCNN, P1455
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhou F, 2010, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2010.5539966
NR 34
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12563
EP 12580
DI 10.1007/s11042-014-2347-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700016
DA 2024-07-18
ER

PT J
AU Xiong, CS
   Huang, L
   Liu, CP
AF Xiong, Chunshui
   Huang, Lei
   Liu, Changping
TI Remote gaze estimation based on 3D face structure and iris centers under
   natural light
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaze estimation; 3D face structure; Iris center location; Head pose
   estimation
ID TRACKING; APPEARANCE; EYE
AB Remote gaze estimation under natural light is still a challenging problem. Appearance based methods are seriously sensitive to illumination variation in the visual spectrum and usually can hardly handle the problem of head movements. And most existing feature-based gaze estimation methods strongly rely on cornea reflections, which are unstable to glasses, head movements and especially useless for natural light condition. In this paper, we propose a novel feature based gaze estimation method without use of cornea reflections. A stereo camera system is built for the proposed method. Firstly, 3D Active Shape Models (ASM) is reconstructed using stereo vision to represent 3D face structure. Then, without use of cornea reflections, a 3D Iris-Eye-Contours based descriptor is proposed to represent human gaze information. Iris centers are used in natural light just like the pupil centers in condition of near-infrared light. What's more, precise estimation of head poses based on 3D face structure is employed to rectify the 3D iris centers and eye contours for improving the ability of tolerance to head movements. Experiments on several subjects show that the system is accurate and allows natural head movements under natural light.
C1 [Xiong, Chunshui] Chinese Acad Sci, Inst Automat, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
   [Huang, Lei; Liu, Changping] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; Institute of Automation, CAS
RP Xiong, CS (corresponding author), Chinese Acad Sci, Inst Automat, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
EM chunshui.xiong@ia.ac.cn; lei.huang@mail.ia.ac.cn;
   changping.liu@mail.ia.ac.cn
RI Huang, Li/IUQ-0909-2023; HUANG, LING/HTR-1819-2023; huang,
   lei/GQP-8739-2022
CR Cerrolaza JJ, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P259, DOI 10.1145/1344471.1344530
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Duchowski AT, 2002, BEHAV RES METH INS C, V34, P455, DOI 10.3758/BF03195475
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Funes Mora KennethAlberto., 2012, Computer Vision and Pattern Recognition Workshops (CVPRW), 2012 IEEE Computer Society Conference on, P25, DOI DOI 10.1109/CVPRW.2012.6239182
   GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027
   Group T, 2015, TOB TECHN PROD
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Jafari R, 2015, EXPERT SYST APPL, V42, P510, DOI 10.1016/j.eswa.2014.08.003
   Lin YT, 2013, MULTIMED TOOLS APPL, V65, P543, DOI 10.1007/s11042-012-1202-1
   Loy G, 2003, IEEE T PATTERN ANAL, V25, P959, DOI 10.1109/TPAMI.2003.1217601
   Lu F., 2011, BMVC, P1
   Lu F, 2011, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2011.6126237
   Martinez F, 2012, IEEE IMAGE PROC, P1961, DOI 10.1109/ICIP.2012.6467271
   Mora KAF, 2014, PROC CVPR IEEE, P1773, DOI 10.1109/CVPR.2014.229
   Morimoto CH, 2000, IMAGE VISION COMPUT, V18, P331, DOI 10.1016/S0262-8856(99)00053-0
   Pengfei Xiong, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3971, DOI 10.1109/ICPR.2010.966
   Pomerleau D, 1994, Advances Neural Information Processing Systems, P753
   Schneider T, 2014, IEEE INT C PATT REC
   Sesma L., 2012, Proceedings of the symposium on eye tracking research and applications, P217, DOI 10.1145/2168556.2168598
   Sesma-Sanchez L, 2012, IEEE T BIO-MED ENG, V59, P2235, DOI 10.1109/TBME.2012.2201716
   Sugano Y, 2014, IEEE INT C COMP VIS, P2667
   Sugano Y, 2008, LECT NOTES COMPUT SC, V5304, P656, DOI 10.1007/978-3-540-88690-7_49
   Sugano Y, 2013, IEEE T PATTERN ANAL, V35, P329, DOI 10.1109/TPAMI.2012.101
   Sugano Y, 2010, PROC CVPR IEEE, P2667, DOI 10.1109/CVPR.2010.5539984
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740
   Williams O., 2006, P IEEE C CVPR, V1, P230, DOI DOI 10.1109/CVPR.2006.285
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xiong CS, 2014, INT C PATT RECOG, P1156, DOI 10.1109/ICPR.2014.208
   Zhu ZW, 2004, MACH VISION APPL, V15, P139, DOI 10.1007/s00138-004-0139-4
NR 31
TC 3
Z9 3
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11785
EP 11799
DI 10.1007/s11042-015-2600-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200011
DA 2024-07-18
ER

PT J
AU Zheng, JX
   Wang, YT
   Tang, Z
AF Zheng, Jinxin
   Wang, Yongtao
   Tang, Zhi
TI Recovering solid geometric object from single line drawing image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Line drawing; 3D reconstruction; Geometric object
ID 3D OBJECT; RECONSTRUCTION; OPTIMIZATION; FACES; IDENTIFICATION; SEARCH
AB Many educational materials contain a lot of solid geometric figures. The solid geometric objects in these figures are usually drawn as 2D line drawings thus have lost their 3D information. This paper presents a method to recover the 3D information of the solid geometric object from single line drawing image taken from the geometric books, which would be used to help the users better present and understand the solid geometric object on their mobile devices. The main advantage of our method is the ability to handle inaccurately processed sketches as opposed to the previous methods which require perfect line drawings as inputs. Our method consists of three main steps as follows. First, the sketch of the input line drawing image is automatically extracted and further represented as an undirected graph. Second, candidate 3D models from the pre-built 3D model database are found by graph similarity-based searching and sub-graph isomorphism matching. Third, for each candidate 3D model, the model parameters, the rotation and the translation aligning the model with the sketch are found by minimizing an objective function which is composed of the residuals between the vertices of the sketch and the 2D projections of the candidate model's vertices, and an optimal reconstruction solution is further selected as the final result. Extensive experimental results demonstrate the effectiveness and robustness of our method for recovering the solid geometric object from single line drawing image.
C1 [Zheng, Jinxin; Wang, Yongtao; Tang, Zhi] Peking Univ, Inst Comp Sci & Technol, 5 Yiheyuan Rd, Beijing 100871, Peoples R China.
C3 Peking University
RP Wang, YT (corresponding author), Peking Univ, Inst Comp Sci & Technol, 5 Yiheyuan Rd, Beijing 100871, Peoples R China.
EM wyt@pku.edu.cn
FU National Natural Science Foundation of China [61300061]; Beijing Natural
   Science Foundation [4132033]
FX We'd like to thank all the reviewers for providing encouraging and
   valuable comments to our work. This work is supported by National
   Natural Science Foundation of China under Grant 61300061 and Beijing
   Natural Science Foundation (4132033).
CR [Anonymous], INT C COMP GRAPH THE
   [Anonymous], P SPIE
   Brown EW, 1996, P SOC PHOTO-OPT INS, V2904, P138, DOI 10.1117/12.256269
   Cordella LP, 2004, IEEE T PATTERN ANAL, V26, P1367, DOI 10.1109/TPAMI.2004.75
   Cordier F, 2013, COMPUT AIDED DESIGN, V45, P301, DOI 10.1016/j.cad.2012.10.013
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   LECLERC YG, 1992, INT J COMPUT VISION, V9, P113, DOI 10.1007/BF00129683
   Lee YT, 2012, COMPUT AIDED DESIGN, V44, P1090, DOI 10.1016/j.cad.2012.06.001
   Lee YT, 2011, COMPUT AIDED DESIGN, V43, P1025, DOI 10.1016/j.cad.2011.03.008
   Lipson H, 1996, COMPUT AIDED DESIGN, V28, P651, DOI 10.1016/0010-4485(95)00081-X
   Liu JZ, 2008, IEEE T PATTERN ANAL, V30, P315, DOI 10.1109/TPAMI.2007.1172
   Liu JZ, 2011, IEEE T PATTERN ANAL, V33, P3, DOI 10.1109/TPAMI.2010.49
   Liu JZ, 2005, IEEE T PATTERN ANAL, V27, P861, DOI 10.1109/TPAMI.2005.119
   Liu JZ, 2002, IEEE T PATTERN ANAL, V24, P1579, DOI 10.1109/TPAMI.2002.1114850
   Liu JZ, 2001, IEEE T PATTERN ANAL, V23, P1106
   MARILL T, 1991, INT J COMPUT VISION, V6, P147, DOI 10.1007/BF00128154
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Shoji K, 2001, PROC CVPR IEEE, P90
   Shpitalni M, 1996, IEEE T PATTERN ANAL, V18, P1000, DOI 10.1109/34.541409
   Tian C, 2009, COMPUT AIDED DESIGN, V41, P147, DOI 10.1016/j.cad.2009.02.002
   Xue TF, 2012, PROC CVPR IEEE, P302, DOI 10.1109/CVPR.2012.6247689
   Xue TF, 2010, PROC CVPR IEEE, P1149, DOI 10.1109/CVPR.2010.5540087
   Yang LJ, 2013, IEEE I CONF COMP VIS, P1433, DOI 10.1109/ICCV.2013.181
   Yu Chen, 2007, 2007 11th IEEE International Conference on Computer Vision, P1
   Zheng WG, 2015, IEEE T KNOWL DATA EN, V27, P964, DOI 10.1109/TKDE.2014.2349924
   Zou CQ, 2014, PROC CVPR IEEE, P692, DOI 10.1109/CVPR.2014.94
   Zou CQ, 2015, IEEE T VIS COMPUT GR, V21, P252, DOI 10.1109/TVCG.2014.2354039
NR 27
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10153
EP 10174
DI 10.1007/s11042-015-2966-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800003
DA 2024-07-18
ER

PT J
AU Hao, SY
   Wang, LG
   Bruzzone, L
   Wang, QM
AF Hao, Siyuan
   Wang, Liguo
   Bruzzone, Lorenzo
   Wang, Qunming
TI Spatial-dictionary for collaborative representation classification of
   hyperspectral images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image classification; Spatial information; Dictionary
   learning; CRC; Remote sensing
ID SPARSE REPRESENTATION; RECOGNITION
AB In this paper, we propose a spatial-dictionary (SD) for collaborative representation classification (SCRC) of hyperspectral images. The proposed method consists of four main steps. First, we extract spatial features using 2-D Gabor filters and stack them with spectral features. Second, the SD is constructed by incorporating the spatial information of sparse vectors into the dictionary optimization process. Third, a multiple-mapping kernel is exploited to further integrate spatial information into the CRC framework. Lastly, the test samples are allocated with the class labels. Experimental results obtained on two hyperspectral datasets demonstrate that the proposed SCRC method can yield higher classification accuracy with much lower computational cost when compared to other traditional classifiers.
C1 [Hao, Siyuan; Wang, Liguo] Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Heilongjiang, Peoples R China.
   [Bruzzone, Lorenzo] Univ Trento, Dept Informat Engn & Comp Sci, I-38123 Trento, Italy.
   [Wang, Qunming] Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Kowloon, Hong Kong, Peoples R China.
C3 Harbin Engineering University; University of Trento; Hong Kong
   Polytechnic University
RP Wang, LG (corresponding author), Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Heilongjiang, Peoples R China.
EM lemonbananan@163.com; 609842513@qq.com; lorenzo.bruzzone@ing.unitn.it;
   wqm11111@126.com
RI Bruzzone, Lorenzo/A-2076-2012; Bruzzone, Lorenzo/JPL-7703-2023
OI Bruzzone, Lorenzo/0000-0002-6036-459X; Wang, Qunming/0000-0002-5188-0939
FU National Natural Science Foundation of China [61275010]; Ph.D. Programs
   Foundation of Ministry of Education of China [20132304110007];
   Fundamental Research Funds for the Central Universities [HEUCFD1410];
   Heilongjiang Natural Science Foundation [F201409]
FX This work was supported by National Natural Science Foundation of China
   (Grant No 61275010), Ph.D. Programs Foundation of Ministry of Education
   of China (Grant No. 20132304110007), the Fundamental Research Funds for
   the Central Universities (Grant No. HEUCFD1410), and Heilongjiang
   Natural Science Foundation (Grant No. F201409).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Camps-Valls G, 2006, IEEE GEOSCI REMOTE S, V3, P93, DOI 10.1109/LGRS.2005.857031
   Chen Y.-H., 2012, ELECT J DIFFERENTIAL, V2012, P1, DOI DOI 10.1371/J0URNAL.P0NE.0049906
   Chen Y, 2011, IEEE T GEOSCI REMOTE, V49, P3973, DOI 10.1109/TGRS.2011.2129595
   Li JY, 2014, IEEE T GEOSCI REMOTE, V52, P3707, DOI 10.1109/TGRS.2013.2274875
   Li W, 2015, IEEE GEOSCI REMOTE S, V12, P48, DOI 10.1109/LGRS.2014.2325978
   Liu JJ, 2013, IEEE J-STARS, V6, P2462, DOI 10.1109/JSTARS.2013.2252150
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1021, DOI 10.1109/TMM.2012.2187179
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Meng L, 2015, INT C MULT RETR SHAN
   Ni BB, 2009, INT CONF ACOUST SPEE, P825, DOI 10.1109/ICASSP.2009.4959711
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Ptucha R, 2014, IEEE T IMAGE PROCESS, V23, P1737, DOI 10.1109/TIP.2014.2303648
   Wang L, 2014, IEEE INT CONF VLSI
   Wang LG, 2014, ISPRS J PHOTOGRAMM, V97, P123, DOI 10.1016/j.isprsjprs.2014.08.016
   Wang W, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P211, DOI 10.1145/2671188.2749337
   Wang ZW, 2014, IEEE T GEOSCI REMOTE, V52, P4808, DOI 10.1109/TGRS.2013.2285049
   Waqas J, 2013, PATTERN RECOGN LETT, V34, P201, DOI 10.1016/j.patrec.2012.09.024
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang LM, 2015, IEEE T MULTIMEDIA, V17, P1538, DOI 10.1109/TMM.2015.2451954
NR 27
TC 3
Z9 3
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9241
EP 9254
DI 10.1007/s11042-015-3098-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500023
DA 2024-07-18
ER

PT J
AU Sheu, JS
   Huang, YL
AF Sheu, Jia-Shing
   Huang, Ya-Ling
TI Implementation of an interactive TV interface via gesture and
   handwritten numeral recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Back-propagation neural network (BPNN); Feature extraction; Gesture
   recognition; Handwriting recognition interactive television (TV);
   Principal curves
AB In this study, a Kinect controller was used to develop control software for interactive television (ITV) and interactive multimedia, thus enabling users to intuitively and conveniently play videos and perform interactive operations. Because it lacks a button controller, the proposed design can achieve a human-machine interaction effect. The interactive control system is divided into two parts: dynamic gesture and handwriting recognition. The Kinect sensor is used as an input device to recognize the dynamic gestures of users to achieve real-time interactive control. TV channels can also be selected automatically through the recognition of handwritten digits. Furthermore, a back-propagation neural network was used to complete handwriting recognition in space to achieve the optimal recognition rate.
C1 [Sheu, Jia-Shing; Huang, Ya-Ling] Natl Taipei Univ Educ, Dept Comp Sci, 134,Sec 2,He Ping Rd, Taipei 10671, Taiwan.
C3 National Taipei University of Education
RP Sheu, JS (corresponding author), Natl Taipei Univ Educ, Dept Comp Sci, 134,Sec 2,He Ping Rd, Taipei 10671, Taiwan.
EM jiashing@tea.ntue.edu.tw; elisahuang.taipei@gmail.com
OI Sheu, Jia-Shing/0000-0002-9498-3110
CR Abbas Q, 2010, P INT C INF EM TECHN
   [Anonymous], 2002, THESIS
   Freeman W.T., 1995, IEEE INT WKSHP AUT F
   Gustafson Sean, 2010, UIST 10 P 23 ANN ACM
   Jacob R. J. K., 2008, P 26 ANN SIGCHI C HU
   Jeng TS, 2002, P 7 INT C COMP AID A
   Kégl B, 2002, IEEE T PATTERN ANAL, V24, P59, DOI 10.1109/34.982884
   Kegl B., 1999, THESIS
   Kegl B., 1998, NEURAL INFORM PROCES, p[1, 501]
   Kuhlman LM, 2009, THESIS
   Laurel B., 1991, COMPUTERS THEATRE
   Laurel Brenda., 1990, ART HUMAN COMPUTER I
   Liao C, 2008, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1314683.1314686
   Memmel T, 2008, J UNIVERS COMPUT SCI, V14, P3217
   Oviatt S, 1999, COMMUN ACM, V42, P74, DOI 10.1145/319382.319398
   Patsadu O, 2012, 2012 9 INT JOINT C C
   Ren Z., 2011, P 19 ACM INT C MULT, P759
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Song Y. P., 2012, J ACM T INTERACT INT, V2, P5
   Zhang JP, 2008, IEEE T INTELL TRANSP, V9, P666, DOI 10.1109/TITS.2008.2006780
NR 20
TC 7
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9685
EP 9706
DI 10.1007/s11042-015-2739-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500011
DA 2024-07-18
ER

PT J
AU Yadav, AK
   Mehta, R
   Kumar, R
   Vishwakarma, VP
AF Yadav, Ashok Kumar
   Mehta, Rajesh
   Kumar, Raj
   Vishwakarma, Virendra P.
TI Lagrangian twin support vector regression and genetic algorithm based
   robust grayscale image watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DCT; Genetic algorithm; Lagrangian Twin SVR; Digital Image Watermarking
ID FUZZY ENTROPY; SYSTEM; SELECTION
AB A novel imperceptible, secure and robust grayscale image watermarking scheme using Lagrangian twin support vector regression (LTSVR) and genetic algorithm (GA) in discrete Cosine transform (DCT) domain is presented in this manuscript. Fuzzy entropy is used to select the relevant blocks for embedding the watermark. Selected number of blocks based on fuzzy entropy not only reduces the dimensionality of the watermarking problem but also discards redundant and irrelevant blocks. Significant DCT coefficients having high energy compaction property of each selected block are used to form the image dataset to train LTSVR to find the non-linear regression function between the input and target vector. The adaptive watermark strength, different for each selected block, is decided by the GA process based on well defined fitness function. Due to good learning capability of image characteristics and high generalization property of LTSVR, watermark is successfully extracted from the watermarked images against a series of image processing operations. From the experimental and comparison results performed on standard and real world images, it is inferred that the proposed method is suitable for copyright protection applications where high degree of robustness is desirable.
C1 [Yadav, Ashok Kumar; Kumar, Raj] Maharshi Dayanand Univ, Univ Inst Engn & Technol, Dept Comp Sci & Engn, Rohtak, Haryana, India.
   [Mehta, Rajesh] Amity Sch Engn & Technol, 580 Delhi Palam Vihar Rd, New Delhi 110061, India.
   [Vishwakarma, Virendra P.] Guru Gobind Singh Indraprastha Univ, Univ Sch Informat & Commun Technol, Sect 16-C, New Delhi, India.
C3 Maharshi Dayanand University; GGS Indraprastha University
RP Yadav, AK (corresponding author), Maharshi Dayanand Univ, Univ Inst Engn & Technol, Dept Comp Sci & Engn, Rohtak, Haryana, India.
EM akyadav1@amity.edu; rajesh2010usit@gmail.com; rajyadav76@rediffmail.com;
   virendravishwa@rediffmail.com
RI Yadav, Ashok Kumar/P-6865-2016
OI Yadav, Ashok Kumar/0000-0003-1054-4442; Vishwakarma, Virendra
   P./0000-0003-4276-8766
CR Agarwal C, 2013, J VIS COMMUN IMAGE R, V24, P1135, DOI 10.1016/j.jvcir.2013.07.007
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   [Anonymous], 2015, INT J MACH LEARN CYB, DOI DOI 10.1007/S-13042-015-0331-Z
   [Anonymous], INT J MACH LEARN CYB
   Aslantas V, 2008, AEU-INT J ELECTRON C, V62, P386, DOI 10.1016/j.aeue.2007.02.010
   Avci E, 2009, EXPERT SYST APPL, V36, P3077, DOI 10.1016/j.eswa.2008.01.027
   Balasundaram S, 2013, NEURAL COMPUT APPL, V22, pS257, DOI 10.1007/s00521-012-0971-9
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Eyadat M, 2005, PATTERN RECOGN LETT, V26, P1405, DOI 10.1016/j.patrec.2004.11.027
   Fanman Meng, 2008, 2008 International Conference on Computational Intelligence and Security, P16, DOI 10.1109/CIS.2008.20
   Hai T, 2010, COMM COM INF SC, V87, P314
   Huang HC, 2009, SOFT COMPUT, V13, P333, DOI 10.1007/s00500-008-0333-9
   Klir G., 1995, Fuzzy sets and fuzzy logic, V4
   Kumar R, 2011, IEEE SENS J, V11, P1548, DOI 10.1109/JSEN.2010.2096209
   Lee HM, 2001, IEEE T SYST MAN CY B, V31, P426, DOI 10.1109/3477.931536
   Lingling Wu, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1164, DOI 10.1109/ICISE.2009.347
   Maity SP, 2013, J SYST SOFTWARE, V86, P47, DOI 10.1016/j.jss.2012.06.057
   Mangasaian OL, 2001, J MACH LEARN RES, V1, P161, DOI 10.1162/15324430152748218
   Mangasarian OL., 1994, Nonlinear Programming, DOI [DOI 10.1137/1.9781611971255, 10.1137/1.9781611971255]
   Mehta R, 2015, INT J APPL PATTERN R, V2, P255, DOI 10.1504/IJAPR.2015.073846
   Murphy P. M, 1992, UCI REPOSITORY MACHI
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Peng H, 2010, J SYST SOFTWARE, V83, P1470, DOI 10.1016/j.jss.2010.03.006
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Piao CR, 2006, LECT NOTES COMPUT SC, V4221, P493
   Shen RM, 2005, J SYST SOFTWARE, V78, P1, DOI 10.1016/j.jss.2005.02.013
   Su Liyun, 2006, Wuhan University Journal of Natural Sciences, V11, P1657, DOI 10.1007/BF02831844
   Tang XH, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P1509
   Yadav AK, 2015, INT CONF CONTEMP, P19, DOI 10.1109/IC3.2015.7346646
NR 30
TC 9
Z9 9
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9371
EP 9394
DI 10.1007/s11042-016-3381-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500029
DA 2024-07-18
ER

PT J
AU Mostafavi, S
   Dehghan, M
AF Mostafavi, Seyedakbar
   Dehghan, Mehdi
TI Game theoretic bandwidth procurement mechanisms in live P2P streaming
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE P2P streaming; Helper selection; Hierarchical mechanism design;
   Incentive strategy; Stackelberg game; Budget-limited reverse auction
ID PEER; ALLOCATION; INCENTIVES; CAPACITY; NETWORK
AB With the dramatic growth of Internet video streaming applications, resource provisioning for video streaming systems to satisfy their upload bandwidth deficit is a challenging task. The design of incentive mechanisms for taking advantage of unused upload capability of helper peers is proven to be a viable, cost-effective solution for this problem. The existing incentive mechanisms for video streaming systems do not consider the hierarchical nature of helper-server interactions, the limited budget of server to procure the needed bandwidth, and limited information of helpers about the other parties in the system. To address these issues, we designed cooperation mechanisms for two different cases: in the full-information case where the server has the full control over the amount of payments to each helper, a Stackelberg helping game is formulated in which the server as leader determines the amount of payment for each helper and then, helpers as followers decide on their amount of contributed bandwidth accordingly. We characterize the Stackelberg Equilibrium (SE) point of game in which the server shares the benefits of bandwidth sharing with the helpers through a market mechanism. In the partial information case where the helpers' cost and utility functions are private and unknown to the server, we propose a budget-limited reverse auction in which the helpers, in contrast to the former case, announce the lowest price at which they are willing to sell their upload bandwidth first and the server then selects a subset of the helpers and pays them proportional to their contributions. The results of extensive simulations reveal that the mechanisms are truthful and result in lower server workload and higher peers' streaming rate and delivery ratio.
C1 [Mostafavi, Seyedakbar; Dehghan, Mehdi] Amirkabir Univ Technol, Tehran Polytech, Dept Comp Engn & IT, 424 Hafez Ave, Tehran, Iran.
C3 Amirkabir University of Technology
RP Dehghan, M (corresponding author), Amirkabir Univ Technol, Tehran Polytech, Dept Comp Engn & IT, 424 Hafez Ave, Tehran, Iran.
EM a_mostafavi@aut.ac.ir; dehghan@aut.ac.ir
RI Mostafavi, Seyedakbar/AAE-6801-2021; Dehghan, Maziar/F-8525-2013
OI Mostafavi, Seyedakbar/0000-0003-3530-2642; Dehghan,
   Maziar/0000-0003-2106-6300; DehghanTakhtFooladi,
   Mehdi/0000-0002-3318-7313
CR [Anonymous], 2013, 2013 20 INT PACK VID
   [Anonymous], CISC VIS NETW IND FO
   [Anonymous], 2009, Encyclopedia of Optimization
   Belmonte MV, 2013, J NETW COMPUT APPL, V36, P484, DOI 10.1016/j.jnca.2012.04.010
   Bradai A, 2014, J NETW COMPUT APPL, V45, P1, DOI 10.1016/j.jnca.2014.07.004
   Capota M, 2014, LECT NOTES COMPUT SC, V8314, P302, DOI 10.1007/978-3-642-45249-9_20
   Chen Y, 2009, IEEE T MULTIMEDIA, V11, P1170, DOI 10.1109/TMM.2009.2026101
   Chu XW, 2009, IEEE T PARALL DISTR, V20, P1816, DOI 10.1109/TPDS.2009.40
   Despotovic Z., 2004, Proceedings of the 37th Annual Hawaii International Conference on System Sciences
   Fudenberg D., 1991, GAME THEORY
   Gao H, 2010, IEEE ICC
   GROVES T, 1973, ECONOMETRICA, V41, P617, DOI 10.2307/1914085
   Guo DD, 2011, INT C PAR DISTRIB SY, P573, DOI 10.1109/ICPADS.2011.9
   Hausheer D, 2005, IEEE ICC, P1583
   He YF, 2009, IEEE INT CON MULTI, P790, DOI 10.1109/ICME.2009.5202613
   He Y, 2012, J NETW COMPUT APPL, V35, P1568, DOI 10.1016/j.jnca.2012.02.004
   Kang X, 2015, IEEE T MOBILE COMPUT, V14, P1018, DOI 10.1109/TMC.2014.2343628
   Kim JH, 2009, ARTECH HSE METH BIOE, P1, DOI 10.1109/ICIMW.2009.5324773
   Liang C, 2010, IEEE T PARALL DISTR, V21, P1354, DOI 10.1109/TPDS.2009.167
   Liu S, 2008, PERF E R SI, V36, P313, DOI 10.1145/1384529.1375493
   Liu Y, 2008, PEER PEER NETW APPL, V1, P18, DOI 10.1007/s12083-007-0006-y
   Moltchanov D, 2011, COMPUT SCI REV, V5, P319, DOI 10.1016/j.cosrev.2011.09.003
   Nan GF, 2014, IEEE SYST J, V8, P256, DOI 10.1109/JSYST.2013.2253420
   Ogston E., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P151
   Singer Y, 2010, ANN IEEE SYMP FOUND, P765, DOI 10.1109/FOCS.2010.78
   Sun J, 2006, IEEE J SEL AREA COMM, V24, P1085, DOI 10.1109/JSAC.2006.872890
   Vakili G, 2012, J NETW COMPUT APPL, V35, P713, DOI 10.1016/j.jnca.2011.11.004
   Veloso E, 2006, IEEE ACM T NETWORK, V14, P133, DOI 10.1109/TNET.2005.863709
   Wang XB, 2010, IEEE T SYST MAN CY B, V40, P587, DOI 10.1109/TSMCB.2009.2034630
   Wei-Yu Lin, 2010, Proceedings 2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing (CCGrid), P591, DOI 10.1109/CCGRID.2010.92
   Wu C, 2008, IEEE T PARALL DISTR, V19, P806, DOI 10.1109/TPDS.2008.30
   Wu C, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2089085.2089091
   Wu C, 2011, IEEE ACM T NETWORK, V19, P1317, DOI 10.1109/TNET.2011.2107563
   Wu TY, 2014, J NETW COMPUT APPL, V41, P47, DOI 10.1016/j.jnca.2013.10.006
   Wu WJ, 2013, COMPUT NETW, V57, P1674, DOI 10.1016/j.comnet.2013.02.016
   Xin Jin, 2010, Proceedings 2010 IEEE 16th International Conference on Parallel and Distributed Systems (ICPADS 2010), P800, DOI 10.1109/ICPADS.2010.78
   Yang DJ, 2012, MOBICOM 12: PROCEEDINGS OF THE 18TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P173
   Yuan Feng, 2010, 2010 18th IEEE International Conference on Network Protocols (ICNP 2010), P275, DOI 10.1109/ICNP.2010.5762776
   Zou J., 2013, MULTIDIMENSIONAL SYS, P1
NR 39
TC 6
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8545
EP 8568
DI 10.1007/s11042-015-2771-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300019
DA 2024-07-18
ER

PT J
AU Al-Jobouri, L
   Fleury, M
   Ghanbari, M
AF Al-Jobouri, Laith
   Fleury, Martin
   Ghanbari, Mohammed
TI Broadband wireless video streaming: achieving unicast <i>and</i>
   multicast IPTV in a practical manner
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data partitioning; IPTV; Multicast; Rateless channel coding; Video
   streaming
ID DOWNLOAD DELIVERY; IMAGE QUALITY; RAPTOR CODES; DESIGN; ADAPTATION;
   DEPLOYMENT; STANDARDS; SCHEME; TIME
AB This paper proposes a versatile IPTV video-streaming scheme that provides high-quality unicast with the aid of repair packets but still supports multicast without repair packets. Prior research on wireless multicast video streaming has addressed the risk of feedback implosion when providing adaptive Forward Error Correction (FEC). This approach has not been adopted by providers, who may either prefer unicast streaming or employ a sufficient level of application-layer FEC to avoid the need for adaptation. Instead in this paper, an adaptive, unicast rateless channel-coding scheme is also run in multicast mode. The paper demonstrates the method and the operating conditions for such a joint unicast/multicast service in terms of data rates and suitable video-content type. Data-partitioned source coding with gradual decoding refresh is adopted in the given scenarios, making for a practical broadband wireless streaming scheme.
C1 [Al-Jobouri, Laith; Fleury, Martin; Ghanbari, Mohammed] Univ Essex, Colchester CO4 3SQ, Essex, England.
C3 University of Essex
RP Fleury, M (corresponding author), Univ Essex, Colchester CO4 3SQ, Essex, England.
EM lamoha@essex.ac.uk; fleum@essex.ac.uk; ghan@essex.ac.uk
RI Ghanbari, Mohammad/L-4053-2019
OI Ghanbari, Mohammad/0000-0002-5482-8378; Al-Jobouri,
   Laith/0000-0003-4600-9513
CR *3GPP, 2005, TECHN SPEC GROUP SER
   Agboma F, 2007, MOB INF SYST, V3, P153, DOI 10.1155/2007/719840
   Ahmad S, 2011, IEEE T MULTIMEDIA, V13, P92, DOI 10.1109/TMM.2010.2093511
   Ahmad S, 2010, IEEE T CIRC SYST VID, V20, P275, DOI 10.1109/TCSVT.2009.2031545
   Al-Jobouri L., 2011, WIREL ENG TECHNOL, V2, P70
   Al-Jobouri L, 2011, P IFIP IEEE WIR MOB, P1
   Al-Jobouri L, 2012, MOB INF SYST, V8, P83, DOI 10.1155/2012/845754
   Al-Jobouri L, 2012, CONSUM COMM NETWORK, P737, DOI 10.1109/CCNC.2012.6181155
   Al-Suhail G, 2011, INNOVATIONS MOBILE M, P175
   Albanese A, 1996, IEEE T INFORM THEORY, V42, P1737, DOI 10.1109/18.556670
   Ali I, 2013, IEEE WIREL COMMUN, V20, P105, DOI 10.1109/MWC.2013.6549289
   [Anonymous], 2005, 80216E2005 IEEE
   [Anonymous], 2007, Fundamentals of WiMAX: understanding broadband wireless networking
   Balachandran A, 1997, PROCEEDINGS OF THE IEEE 7TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEM SUPPORT FOR DIGITAL AUDIO AND VIDEO, P125, DOI 10.1109/NOSDAV.1997.629373
   Bing B, 2010, ARTECH HSE TELECOM S, P1
   Bormann C., 2001, IETF RFC 3095
   Byers J. W., 1998, P ACM SIGCOMM
   Cataldi P, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P263
   Côté G, 1999, SIGNAL PROCESS-IMAGE, V15, P25, DOI 10.1016/S0923-5965(99)00022-3
   Dai J, 2012, IEEE J SEL AREA COMM, V30, P458, DOI 10.1109/JSAC.2012.120226
   Degrande N, 2008, IEEE COMMUN MAG, V46, P94, DOI 10.1109/MCOM.2008.4473090
   Dhondt Y, 2007, LECT NOTES COMPUT SC, V4678, P720
   Diot C, 2000, IEEE NETWORK, V14, P78, DOI 10.1109/65.819174
   Fleury M., 2014, Recent Patents Signal Process, V4, P32, DOI DOI 10.2174/2210686304666141009230832
   Floyd S, 1997, P ACM SIGCOMM CANN F, P342
   Garrammone G, 2013, IEEE COMMUN LETT, V17, P773, DOI 10.1109/LCOMM.2013.021913.122427
   Hepsaydir E, 2007, P IEEE INT S PERS IN, P1, DOI DOI 10.1109/PIMRC.2007.4394642
   Hua KA, 2004, P IEEE, V92, P1439, DOI 10.1109/JPROC.2004.832954
   Jenkac H, 2006, EUR T TELECOMMUN, V17, P337, DOI 10.1002/ett.1125
   KARP R, 2004, P IEEE INT S INF THE
   Khan A, 2010, IET COMMUN, V4, P1337, DOI 10.1049/iet-com.2009.0422
   Kim SW, 2008, IEEE T CONSUM ELECTR, V54, P376, DOI 10.1109/TCE.2008.4560102
   Koo J, 2011, IEEE T CONSUM ELECTR, V57, P357, DOI 10.1109/TCE.2011.5955167
   Liu FM, 2012, IEEE T PARALL DISTR, V23, P1227, DOI 10.1109/TPDS.2011.283
   Liu ZY, 2007, CONFERENCE RECORD OF THE FORTY-FIRST ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1-5, P914
   Luby M, 2002, ANN IEEE SYMP FOUND, P271, DOI 10.1109/SFCS.2002.1181950
   Luby M, 2006, CONSUM COMM NETWORK, P192
   Luby M, 2008, IEEE COMMUN MAG, V46, P94, DOI 10.1109/MCOM.2008.4511656
   Luby M, 2007, IEEE T BROADCAST, V53, P235, DOI 10.1109/TBC.2007.891703
   MacKay DJC, 2005, IEE P-COMMUN, V152, P1062, DOI 10.1049/ip-com:20050237
   Majumdar A, 2002, IEEE T CIRC SYST VID, V12, P524, DOI 10.1109/TCSVT.2002.800315
   McCanne S., 1996, Computer Communication Review, V26, P117, DOI 10.1145/248157.248168
   McKay D. J. C., 2003, INFORM THEORY INFERE
   Menkovski V, 2010, INT J MOB COMPUT MUL, V2, P1, DOI 10.4018/jmcmc.2010100101
   Mitzenmacher M, 2004, 2004 IEEE INFORMATION THEORY WORKSHOP, PROCEEDINGS, P271
   Mladenov T, 2010, IEEE T CONSUM ELECTR, V56, P1264, DOI 10.1109/TCE.2010.5606257
   Mladenov T, 2010, IEEE T CONSUM ELECTR, V56, P423, DOI 10.1109/TCE.2010.5505949
   Mohr AE, 2000, IEEE J SEL AREA COMM, V18, P819, DOI 10.1109/49.848236
   Nazir S., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2205, DOI 10.1109/ICIP.2011.6116073
   Nonnenmacher J., 1996, Protocols for High-Speed Networks V. TC6 WG6.1/6.4 Fifth International Workshop on Protocols for High-Speed Networks (PfHSN '96), P134
   Nonnenmacher J, 1998, IEEE INFOCOM SER, P972, DOI 10.1109/INFCOM.1998.662906
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Palanki R., 2004, P INT S INF THEOR CH
   Park S, 2009, IEEE INTERNET COMPUT, V13, P23, DOI 10.1109/MIC.2009.65
   Pérez P, 2011, IEEE T CONSUM ELECTR, V57, P132, DOI 10.1109/TCE.2011.5735493
   Pino J., 2009, Proceedings of the SLaTE Workshop on Speech and Language Technology in Education, P1
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Puri R, 2001, IEEE T MULTIMEDIA, V3, P18, DOI 10.1109/6046.909591
   Quan HT, 2012, TELECOMMUN SYST, V49, P35, DOI 10.1007/s11235-010-9351-x
   Razavi R, 2009, IEEE IMAGE PROC, P909, DOI 10.1109/ICIP.2009.5414052
   Reibman A. R., 2007, PACKET VIDEO 2007, P307
   Reibman AR, 2004, IEEE T MULTIMEDIA, V6, P327, DOI 10.1109/TMM.2003.822785
   Richardson TJ, 2001, IEEE T INFORM THEORY, V47, P638, DOI 10.1109/18.910579
   Rizzo L., 1997, FEASIBILITY SOFTWARE
   Sgardoni V, 2015, IEEE T MOBILE COMPUT, V14, P401, DOI 10.1109/TMC.2014.2331967
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Stockhammer T, 2004, IEEE IMAGE PROC, P545
   Tan W, 1999, P INT PACKETVIDEO WO
   Thornburgh M., 2013, RFC 7016
   Tsai F. C. D., 2006, P WORKSH NS2 IP NETW
   Van Wallendael G, 2012, IEEE T BROADCAST, V58, P57, DOI 10.1109/TBC.2011.2170610
   Vu L., 2007, Proceedings of the 16th international symposium on High performance distributed computing (HPDC '07), P241
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei Dai, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7343, DOI 10.1109/ICASSP.2014.6855026
   Wu PH, 2012, IEEE INT SYMP CIRC S, P1103
   Xu XR, 1997, PROCEEDINGS OF THE IEEE 7TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEM SUPPORT FOR DIGITAL AUDIO AND VIDEO, P183, DOI 10.1109/NOSDAV.1997.629385
   Zhang B, 2011, IEEE INT CONF NETWOR, P30, DOI 10.1109/ICON.2011.6168502
NR 77
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6403
EP 6430
DI 10.1007/s11042-015-2577-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700017
DA 2024-07-18
ER

PT J
AU Chen, ST
   Huang, HN
AF Chen, Shuo-Tsung
   Huang, Huang-Nan
TI Optimization-based audio watermarking with integrated quantization
   embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; SNR; Robustness; Wavelet
ID TIME-SCALE MODIFICATION; MODULATION; SCHEME; ROBUST
AB In general, the performance of a multimedia watermarking scheme is measured in terms of signal-to-noise ratio (SNR) and robustness. However, there is a tradeoff between them which issues a challenge in the field of the watermarking. To overcome this problem, the embedding rules using amplitude quantization instead of single-coefficient quantization are first integrated as an embedding system that incorporates a state and the SNR is rewritten as a cost function which is a wavelet-based functional. Then, a nonlinear function connecting the cost function and the embedding system is derived. Finally, the Lagrange Principle is used to obtain the optimal solution which is an important formula for watermarking. Based on this formula, the synchronization code and watermark are embedded into the lowest frequency sub-band coefficients in the wavelet domain. In addition, the hidden information can be extracted without knowledge of the original audio. In the experiments, the performance of the proposed system is tested and the results verify the high SNR and strong robustness against multimedia signal processing or attacks.
C1 [Chen, Shuo-Tsung] Tunghai Univ, Sustainabil Res Ctr, Taichung 40704, Taiwan.
   [Chen, Shuo-Tsung; Huang, Huang-Nan] Tunghai Univ, Dept Appl Math, Taichung 40704, Taiwan.
C3 Tunghai University; Tunghai University
RP Huang, HN (corresponding author), Tunghai Univ, Dept Appl Math, Taichung 40704, Taiwan.
EM shough34@yahoo.com.tw; nhuang@thu.edu.tw
OI Huang, Huang-Nan/0000-0001-7387-0427
CR Al-Haj A, 2011, INT ARAB J INF TECHN, V8, P326
   Anderson B., 1990, OPTIMAL CONTROL LINE
   [Anonymous], 1976, The Elements of Real Analysis
   [Anonymous], 2000, Digital Watermarking
   Arnold M, 2009, LECT NOTES COMPUT SC, V5806, P102, DOI 10.1007/978-3-642-04431-1_8
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Burrus CS., 1998, INTRO WAVELET THEORY
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen ST, 2010, IET SIGNAL PROCESS, V4, P576, DOI 10.1049/iet-spr.2009.0184
   Chen ST, 2010, IET SIGNAL PROCESS, V4, P720, DOI 10.1049/iet-spr.2009.0187
   GERZON MA, 1995, J AUDIO ENG SOC, V43, P3
   Gruhl D., 1996, Information Hiding. First International Workshop Proceedings, P295
   Huang HN, 2015, J SIGNAL PROCESS SYS, V80, P197, DOI 10.1007/s11265-013-0863-y
   Huang JW, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, PROCEEDINGS, P627
   Khaldi K, 2013, IEEE T AUDIO SPEECH, V21, P675, DOI 10.1109/TASL.2012.2227733
   Ko BS, 2002, INT CONF ACOUST SPEE, P2001
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Satheesh K, 2013, INT J ACV AGR SCI TE, V1, P40
   Swanson MD, 1998, SIGNAL PROCESS, V66, P337, DOI 10.1016/S0165-1684(98)00014-0
   Ten Daubechies I., 1992, lecture on wavelets
   Vaidyanathan P. P., 2005, MULTIRATE SYSTEMS FI
   Wang Y, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/232616
   Wu C.P., 1999, P INT S MULT INF PRO, P37
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
   Xiang SJ, 2008, SIGNAL PROCESS, V88, P2372, DOI 10.1016/j.sigpro.2008.03.019
   Xiang SJ, 2007, IEEE T MULTIMEDIA, V9, P1357, DOI 10.1109/TMM.2007.906580
   Xiang SJ, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-3
   Yadav R, 2010, INT J COMPUTER APPL, V8, P24
NR 28
TC 18
Z9 21
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4735
EP 4751
DI 10.1007/s11042-015-2500-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700027
DA 2024-07-18
ER

PT J
AU Liao, JX
   Qi, Q
   Wang, J
   Wang, JY
   Cao, YF
AF Liao, Jianxin
   Qi, Qi
   Wang, Jing
   Wang, Jingyu
   Cao, Yufei
TI A dual mode self-adaption handoff for multimedia services in mobile
   cloud computing environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile cloud computing; Multimedia service; Heterogeneous network;
   Handoff; Self-adaption
ID SIP-BASED MOBILITY; HETEROGENEOUS WIRELESS; VOIP CALLS; OPTIMIZATION;
   BANDWIDTH; MECHANISM; NETWORK
AB Since mobile devices are becoming the primary platforms for many users who always roam around and access the cloud computing applications, the two concepts of mobile computing and cloud computing have emerged as a new widely accepted paradigm, mobile cloud computing. More and more users use cloud computing service and offload their local applications to the cloud. Unfortunately, developing mobile multimedia cloud services over heterogeneous wireless networks poses a challenge for service continuity. The degraded link quality and connection losses are likely to happen and these may affect service availability and service usage times in mobile cloud computing scenarios. To improve handoff quality and minimize utilized bandwidth, we propose a dual mode self-adaption handoff mechanism for multimedia services in mobile cloud computing environment. The new mechanism uses multipath transmission for media flows based on "make before break" technology, and consists of the duplicate mode and the effective mode, which are changed according to the network condition. Analytic model and simulation are developed to investigate our new mechanism. The results demonstrate that the self-adaption handoff mechanism can realize seamless handoff for multimedia services in cloud, reduce the packet loss rate, as well as obtain a more efficient use of the scarce wireless bandwidth and the power of mobile devices.
C1 [Liao, Jianxin; Qi, Qi; Wang, Jing; Wang, Jingyu] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Mail Box 296, Beijing 100876, Peoples R China.
   [Liao, Jianxin; Qi, Qi; Wang, Jing; Wang, Jingyu; Cao, Yufei] EBUPT Informat Technol Co Ltd, Beijing 100893, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Qi, Q (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Mail Box 296, Beijing 100876, Peoples R China.
EM qiqi8266@163.com
RI Wang, Jingyu/JFK-6346-2023; liu, jiajia/IUN-0901-2023; wangwangwang,
   yuanyaunyuan/HHN-6432-2022; Qi, Wang/KEI-7047-2024
OI Wang, Jingyu/0000-0002-2182-2228; 
FU National Basic Research Program of China [2013CB329102]; National
   Natural Science Foundation of China [61471063, 61421061, 61372120,
   61302087, 61271019, 61101119]; Key (Keygrant) Project of Chinese
   Ministry of Education [MCM20130310]; Beijing Higher Education Young
   Elite Teacher Project [YETP0473]
FX This work was jointly supported by: (1) the National Basic Research
   Program of China (No. 2013CB329102); (2) National Natural Science
   Foundation of China (No. 61471063, 61421061, 61372120, 61302087,
   61271019, 61101119); (3) the Key (Keygrant) Project of Chinese Ministry
   of Education (No. MCM20130310); (4) Beijing Higher Education Young Elite
   Teacher Project (No. YETP0473).
CR [Anonymous], 2011, NIST DEFINITION CLOU
   Banerjee N, 2006, IEEE NETWORK, V20, P6, DOI 10.1109/MNET.2006.1607890
   Barbera MV, 2013, IEEE INFOCOM SER, P1285
   Choi M, 2013, J SUPERCOMPUT, V64, P331, DOI 10.1007/s11227-011-0681-6
   Das SK, 2003, IEEE T COMPUT, V52, P742, DOI 10.1109/TC.2003.1204830
   Fathi H, 2006, IEEE T MOBILE COMPUT, V5, P1121, DOI 10.1109/TMC.2006.135
   Fernando N, 2013, FUTURE GENER COMP SY, V29, P84, DOI 10.1016/j.future.2012.05.023
   Gabner R., 2011, Proceedings of the 2011 IEEE 10th International Symposium on Network Computing and Applications (NCA 2011), P195, DOI 10.1109/NCA.2011.33
   Huang CM, 2006, IEEE J SEL AREA COMM, V24, P1682, DOI 10.1109/JSAC.2006.875113
   Kamel G, 2008, IEEE COMMUN LETT, V12, P130, DOI 10.1109/LCOMM.2008.071662
   Khan AUR, 2014, IEEE COMMUN SURV TUT, V16, P393, DOI 10.1109/SURV.2013.062613.00160
   Larosa YT, 2011, INT WIREL COMMUN, P661, DOI 10.1109/IWCMC.2011.5982625
   Leu FY, 2009, J NETW COMPUT APPL, V32, P1073, DOI 10.1016/j.jnca.2009.02.007
   Lu Y, 2011, IEEE MULTIMEDIA, V18, P4, DOI 10.1109/MMUL.2011.33
   Munasinghe KS, 2008, IEEE COMMUN MAG, V46, P184, DOI 10.1109/MCOM.2008.4623724
   Munasinghe KS, 2008, IEEE WIREL COMMUN, V15, P86, DOI 10.1109/MWC.2008.4599226
   Nakamura T, 2008, IEICE TECH REP, V108, P37
   Nishihara K., 2010, Proceedings 2010 First International Conference on Networking and Computing (ICNC 2010), P220, DOI 10.1109/IC-NC.2010.50
   Qi Q, 2010, IEEE T CONSUM ELECTR, V56, P2276, DOI 10.1109/TCE.2010.5681100
   Rey J., 2006, RFC4588
   Ryu S, 2012, J SUPERCOMPUT, V59, P658, DOI 10.1007/s11227-010-0459-2
   Salsano S, 2008, IEEE WIREL COMMUN, V15, P92, DOI 10.1109/MWC.2008.4492982
   Salsano S, 2006, IEEE ICC, P2040
   Simoens P, 2011, COMPUTER, V44, P46, DOI 10.1109/MC.2011.70
   Taleb T, 2008, IEEE T VEH TECHNOL, V57, P3801, DOI 10.1109/TVT.2008.918727
   Taleb T, 2007, GLOB TELECOMM CONF, P1912
   Verbelen T, 2013, FUTURE GENER COMP SY, V29, P451, DOI 10.1016/j.future.2012.07.003
   Vrat A, 2011, INT C REC TRENDS INF, P638
   Wältermann M, 2008, IEEE ICC, P1772, DOI 10.1109/ICC.2008.340
   Xu L., 2006, 2006 1st IEEE Conference on Industrial Electronics and Applications, P1, DOI [DOI 10.1109/ICIEA.2006.257299, 10.1109/ICIEA.2006.257299]
   Yunqi Ye, 2010, 2010 Fifth International Symposium on Service Oriented System Engineering (SOSE 2010), P236, DOI 10.1109/SOSE.2010.53
NR 31
TC 3
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4697
EP 4722
DI 10.1007/s11042-015-2498-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700025
DA 2024-07-18
ER

PT J
AU Zhang, ZH
   Bai, L
   Ren, P
   Hancock, ER
AF Zhang, Zhihong
   Bai, Lu
   Ren, Peng
   Hancock, Edwin R.
TI High-order graph matching kernel for early carcinoma EUS image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph matching; Kernel; Endoscopic ultrasonography (EUS) image
   classification
ID NEURAL-NETWORK ANALYSIS; DIFFERENTIAL-DIAGNOSIS; ENDOSCOPIC ULTRASOUND;
   CHRONIC-PANCREATITIS; LYMPH-NODES; CANCER; ADENOCARCINOMA; LESIONS
AB Endoscopic ultrasonography (EUS) is limited by variability in the examiner's subjective interpretation to differentiate between normal, leiomyoma of esophagus and early esophageal carcinoma. By using information otherwise discarded by conventional EUS systems, quantitative spectral analysis of the raw pixels (picture elements) underlying EUS image enables lesions to be characterized more objectively. In this paper, we propose to represent texture features of early esophageal carcinoma in EUS images as a graph by expressing pixels as nodes and similarity between the gray-level or local features of the EUS image as edges. Then, similarity measurements such as a high-order graph matching kernel can be constructed so as to provide an objective quantification of the properties of the texture features of early esophageal carcinoma in EUS images. This is in terms of the topology and connectivity of the analyzed graphs. Because such properties are directly related to the structure of early esophageal carcinoma lesions in EUS images, they can be used as features for characterizing and classifying early esophageal carcinoma. Finally, we use a refined SVM model based on the new high-order graph matching kernel, resulting an optimal prediction of the types of esophageal lesions. A 10-fold cross validation strategy is employed to evaluate the classification performance. After multiple computer runs of the new kernel SVM model, the overall accuracy for the diagnosis between normal, leiomyoma of esophagus and early esophageal carcinoma was 93 %. Moreover, for the diagnosis of early esophageal carcinoma, the average accuracy, sensitivity, specificity, positive predictive value, and negative predictive value were 89.4 %, 94 %, 95 %, 89 %, and 97 % respectively. The area under all the three ROC curves were close to 1.
C1 [Zhang, Zhihong] Xiamen Univ, Software Sch, Xiamen, Fujian, Peoples R China.
   [Ren, Peng] China Univ Petr, Coll Informat & Control Engn, Qingdao, Peoples R China.
   [Bai, Lu] Cent Univ Finance & Econ, Sch Informat, Beijing, Peoples R China.
   [Hancock, Edwin R.] Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.
C3 Xiamen University; China University of Petroleum; Central University of
   Finance & Economics; University of York - UK
RP Ren, P (corresponding author), China Univ Petr, Coll Informat & Control Engn, Qingdao, Peoples R China.
EM pengren@upc.edu.cn
RI bai, lu/HPG-8137-2023; Hancock, Edwin/N-7548-2019
OI Hancock, Edwin/0000-0003-4496-2028
FU National Natural Science Foundation of China [61402389]; Fundamental
   Research Funds for Central Universities [15CX05042A]; Shandong
   Outstanding Young Scientist Fund [BS2013DX006]
FX This work is supported by National Natural Science Foundation of China
   (Grant No.61402389), Fundamental Research Funds for Central Universities
   (No. 15CX05042A) and Shandong Outstanding Young Scientist Fund (No.
   BS2013DX006).
CR [Anonymous], 2011, LIBSVM: a library for support vector machines
   Bai L, 2014, THESIS U YORK
   Bai L, 2014, LECT NOTES COMPUT SC, V8621, P1, DOI 10.1007/978-3-662-44415-3_1
   Bai L, 2014, PATTERN RECOGN, V47, P1172, DOI 10.1016/j.patcog.2013.09.010
   Borgwardt K. M., 2005, ICDM, DOI DOI 10.1109/ICDM.2005.132
   Buskens CJ, 2004, GASTROINTEST ENDOSC, V60, P703, DOI 10.1016/S0016-5107(04)02017-6
   Das A, 2008, GASTROINTEST ENDOSC, V67, P861, DOI 10.1016/j.gie.2007.08.036
   De Angelis C, 2014, MINERVA MED, V105, P121
   Eriksson F., 1978, Geometriae Dedicata, V7, P71, DOI DOI 10.1007/BF00181352
   Gärtner T, 2003, LECT NOTES ARTIF INT, V2777, P129, DOI 10.1007/978-3-540-45167-9_11
   Jebara T, 2004, J MACH LEARN RES, V5, P819
   Jenssen R, 2010, IEEE T PATTERN ANAL, V32, P847, DOI 10.1109/TPAMI.2009.100
   JULESZ B, 1975, SCI AM, V232, P34, DOI 10.1038/scientificamerican0475-34
   Kolios MC, 2002, ULTRASOUND MED BIOL, V28, P589, DOI 10.1016/S0301-5629(02)00492-1
   Lerman G, 2009, J APPROX THEORY, V156, P52, DOI 10.1016/j.jat.2008.03.005
   Levman J, 2008, IEEE T MED IMAGING, V27, P688, DOI 10.1109/TMI.2008.916959
   Loren DE, 2002, GASTROINTEST ENDOSC, V56, P742, DOI 10.1067/mge.2002.128920
   Lowe DG, 2008, INT J COMPUT VISION, V60, P91
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Nagami Y, 2014, AM J GASTROENTEROL, V109, P845, DOI 10.1038/ajg.2014.94
   Nguyen VX, 2010, J ULTRAS MED, V29, P1345, DOI 10.7863/jum.2010.29.9.1345
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Norton ID, 2001, GASTROINTEST ENDOSC, V54, P625, DOI 10.1067/mge.2001.118644
   Olowe K, 2007, GASTROINTEST ENDOSC, V65, pAB194, DOI 10.1016/j.gie.2007.03.370
   Pech O, 2006, AM J GASTROENTEROL, V101, P2223, DOI 10.1111/j.1572-0241.2006.00718.x
   Ren P, 2011, LECT NOTES COMPUT SC, V6978, P1, DOI 10.1007/978-3-642-24085-0_1
   Saftoiu A, 2008, GASTROINTEST ENDOSC, V68, P1086, DOI 10.1016/j.gie.2008.04.031
   Scott GL, 1991, P ROY SOC LOND B BIO, V244, P313
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Shervashidze N., 2010, J. Mach.Learn. Res., V1, P1
   Shervashidze Nino, 2009, P INT C ART INT STAT, P488
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Tuceryan M., 1993, Handbook of Pattern Recognition and Computer Vision, P235, DOI [DOI 10.1142/9789814343138_0010, 10.1142/97898143431380010, DOI 10.1142/97898143431380010]
   Van Holsbeke C, 2007, CLIN CANCER RES, V13, P4440, DOI 10.1158/1078-0432.CCR-06-2958
   Van Holsbeke C, 2009, CLIN CANCER RES, V15, P684, DOI 10.1158/1078-0432.CCR-08-0113
   Zhang MM, 2010, GASTROINTEST ENDOSC, V72, P978, DOI 10.1016/j.gie.2010.06.042
   Zhu ML, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076964
NR 37
TC 7
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3993
EP 4012
DI 10.1007/s11042-015-3108-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200021
DA 2024-07-18
ER

PT J
AU Giannopoulos, I
   Schöning, J
   Krüger, A
   Raubal, M
AF Giannopoulos, Ioannis
   Schoening, Johannes
   Krueger, Antonio
   Raubal, Martin
TI Attention as an input modality for Post-WIMP interfaces using the viGaze
   eye tracking framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Prototype multimedia systems and platforms; Human-computer interaction;
   Eye tracking
ID VISUAL-ATTENTION; MOVEMENTS
AB Eye tracking is one of the most prominent modalities to track user attention while interacting with computational devices. Today, most of the current eye tracking frameworks focus on tracking the user gaze during website browsing or while performing other tasks and interactions with a digital device. Most frameworks have in common that they do not exploit gaze as an input modality. In this paper we describe the realization of a framework named viGaze. Its main goal is to provide an easy to use framework to exploit the use of eye gaze as an input modality in various contexts. Therefore it provides features to explore explicit and implicit interactions in complex virtual environments by using the eye gaze of a user for various interactions. The viGaze framework is flexible and can be easily extended to incorporate other input modalities typically used in Post-WIMP interfaces such as gesture or foot input. In this paper we describe the key components of our viGaze framework and additionally describe a user study that was conducted to test the framework. The user study took place in a virtual retail environment, which provides a challenging pervasive environment and contains complex interactions that can be supported by gaze. The participants performed two gaze-based interactions with products on virtual shelves and started an interaction cycle between the products and an advertisement monitor placed on the shelf. We demonstrate how gaze can be used in Post-WIMP interfaces to steer the attention of users to certain components of the system. We conclude by discussing the advantages provided through the viGaze framework and highlighting the potentials of gaze-based interaction.
C1 [Giannopoulos, Ioannis; Raubal, Martin] ETH Zurich HIL, Inst Cartog & Geoinformat, Wolfgang Pauli Str 15, CH-8093 Zurich, Switzerland.
   [Schoening, Johannes] Hasselt Univ, tUL, iMinds, Expertise Ctr Digital Media, Wetenschapspk 2, B-3590 Diepenbeek, Belgium.
   [Krueger, Antonio] DFKI GmbH, Campus D3 2,Stuhlsatzenhausweg 3, D-66123 Saarbrucken, Germany.
C3 IMEC; Hasselt University; German Research Center for Artificial
   Intelligence (DFKI)
RP Schöning, J (corresponding author), Hasselt Univ, tUL, iMinds, Expertise Ctr Digital Media, Wetenschapspk 2, B-3590 Diepenbeek, Belgium.
EM igiannopoulos@ethz.ch; Johannes.schoening@uhasselt.be; krueger@dfki.de;
   mraubal@ethz.ch
RI Schöning, Johannes/AAE-9585-2020
OI Schöning, Johannes/0000-0002-8823-4607; Giannopoulos,
   Ioannis/0000-0002-2556-5230; Kruger, Antonio/0000-0002-8055-8367
CR [Anonymous], 2009, ROOTS FUTURE AMBIENT
   [Anonymous], 2007, EYE TRACKING METHODO
   Biedert Ralf, 2010, CHI 10 EXTENDED ABST, P4003, DOI [DOI 10.1145/1753846.1754093, 10.1145/1753846.1754093]
   Bulling A, 2008, LECT NOTES COMPUT SC, V5294, P33, DOI 10.1007/978-3-540-88322-7_4
   Cauchard J.R., 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology, ACM, P451, DOI DOI 10.1145/2047196.2047256
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Daiber F, 2009, LECT NOTES COMPUT SC, V5531, P81
   Duggan GB, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1141
   Ferscha A, 2007, LECT NOTES COMPUT SC, V4397, P14
   Giannopoulos I, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P165
   Hempel J, 2011, THESIS U MAGDEBURG
   Hill R, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1151
   JACOB RJK, 1991, ACM T INFORM SYST, V9, P152, DOI 10.1145/123078.128728
   Kern D, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2093
   Komogortsev O, 2011, CHI, P1255
   Krüger A, 2011, COMPUTER, V44, P84, DOI 10.1109/MC.2011.112
   Ohno T., 2003, Proceedings of CHI. Ft, P950
   Pieters R, 1999, INT J RES MARK, V16, P1, DOI 10.1016/S0167-8116(98)00022-6
   Porta Marco., 2010, P 2010 S EYE TRACKIN, P331
   Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372
   Rensink RA, 1997, PSYCHOL SCI, V8, P368, DOI 10.1111/j.1467-9280.1997.tb00427.x
   Santella A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P771
   Stellmach Sophie., 2012, P S EYE TRACKING RES, P357, DOI DOI 10.1145/2168556.2168636
   Tanriverdi V., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P265, DOI 10.1145/332040.332443
   Treue S, 2003, CURR OPIN NEUROBIOL, V13, P428, DOI 10.1016/S0959-4388(03)00105-3
NR 25
TC 5
Z9 5
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 2913
EP 2929
DI 10.1007/s11042-014-2412-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600001
DA 2024-07-18
ER

PT J
AU Wang, H
   Lu, T
   Wang, YM
   Shivakumara, P
   Tan, CL
AF Wang, Hao
   Lu, Tong
   Wang, Yiming
   Shivakumara, Palaiahnakote
   Tan, Chew Lim
TI Weakly-supervised region annotation for understanding scene images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene image understanding; Image region annotation; TCRA; Spatial MRF
   modeling; Annotation reasoning
ID OBJECT RECOGNITION; MEAN SHIFT; SEGMENTATION; CLASSIFICATION; TEXTURE
AB Scene image understanding has drawn much attention for its intriguing applications in the past years. In this paper, we propose a unified probabilistic graphical model called Topic-based Coherent Region Annotation (TCRA) for weakly-supervised scene region annotation. The multiscale over-segmented regions within a scene image are considered as the "words" of our topic model, which impose neighborhood contextual constraints on topic level through spatial MRF modeling, and incorporate an annotation reasoning mechanism for learning and inferring region labels automatically. Mean field variational inference is provided for model learning. The proposed TCRA has the following two main advantages for understanding natural scene images. First, spatial information of multiscale over-segmented regions is explicitly modeled to obtain coherent region annotations. Second, only image-level labels are needed for automatically inferring the label of every region within the scene. This is particularly helpful in reducing human burden on manually labeling pixel-level semantics in the scene understanding research. Thus, given a scene image that has no textual prior, the regions in it can be automatically labeled using the learned TCRA model. The experimental results conducted on three benchmarks consisting of the MSRCORID image dataset, the UIUC Events image dataset and the SIFT FLOW dataset show that the proposed model outperforms the recent state-of-the-art methods.
C1 [Wang, Hao; Lu, Tong; Wang, Yiming] Nanjing Univ, Natl Key Lab Novel Software Technol, Dept Comp Sci & Technol, Nanjing 210008, Jiangsu, Peoples R China.
   [Shivakumara, Palaiahnakote] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Tan, Chew Lim] Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
C3 Nanjing University; Universiti Malaya; National University of Singapore
RP Lu, T (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Dept Comp Sci & Technol, Nanjing 210008, Jiangsu, Peoples R China.
EM wanghao0711@gmail.com; lutong@nju.edu.cn; freewym@gmail.com;
   hudempsk@yahoo.com; tancl@comp.nus.edu.sg
RI Palaiahnakote, Shivakumara/B-6261-2013; Palaiahnakote,
   Shivakumara/ITU-6488-2023; Wang, Yiming/AAZ-4928-2021
OI Wang, Yiming/0000-0002-5588-8241
FU Natural Science Foundation of China [61272218, 61321491]; Program for
   New Century Excellent Talents [NCET-11-0232]
FX The work described in this paper was supported by the Natural Science
   Foundation of China under Grant No. 61272218 and No. 61321491, and the
   Program for New Century Excellent Talents under NCET-11-0232.
CR Andreetto M, 2012, IEEE T PATTERN ANAL, V34, P1842, DOI 10.1109/TPAMI.2011.268
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], LNCS
   [Anonymous], 2007, ICCV
   [Anonymous], NIPS
   [Anonymous], 2008, CVPR
   [Anonymous], ICCV
   [Anonymous], MULTIMEDIA IN PRESS
   [Anonymous], CVPR
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Crandall DavidJ., 2007, CVPR
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Hoiem D., 2006, CVPR
   Holzinger Andreas, 2014, Brain Informatics and Health. International Conference, BIH 2014. Proceedings: LNCS 8609, P552, DOI 10.1007/978-3-319-09891-3_50
   Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0
   Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248
   Lafferty J., 2001, CONDITIONAL RANDOM F, V2001, P282
   LeCun Y, 2004, PROC CVPR IEEE, P97
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   Li N, 2003, IEEE T SYST MAN CY B, V33, P438, DOI 10.1109/TSMCB.2003.811120
   Lin WX, 2012, LECT NOTES COMPUT SC, V7131, P740
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131
   Luo JB, 2005, IEEE T SYST MAN CY B, V35, P563, DOI 10.1109/TSMCB.2005.846677
   Ma XL, 2012, INT C PATT RECOG, P2590
   Malisiewicz T., 2008, CVPR
   Meng H, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P88, DOI 10.1109/ICMA.2007.4303521
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Niu ZX, 2012, PROC CVPR IEEE, P2743, DOI 10.1109/CVPR.2012.6247997
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   SU F., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1389, DOI DOI 10.1145/2072298.2072022
   Sudderth EB, 2008, INT J COMPUT VISION, V77, P291, DOI 10.1007/s11263-007-0069-5
   Tao WB, 2007, IEEE T SYST MAN CY B, V37, P1382, DOI 10.1109/TSMCB.2007.902249
   Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26
   Torralba A., 2004, NIPS
   Vezhnevets A, 2012, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2012.6247757
   Vezhnevets A, 2011, IEEE I CONF COMP VIS, P643, DOI 10.1109/ICCV.2011.6126299
   Wang L., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1161, DOI [DOI 10.1145/2072298.2071964, 10.1145/2072298.2071964]
   Winn J, 2005, J MACH LEARN RES, V6, P661
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 47
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3027
EP 3051
DI 10.1007/s11042-014-2420-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600006
DA 2024-07-18
ER

PT J
AU Xu, X
   Mu, N
   Chen, L
   Zhang, XL
AF Xu, Xin
   Mu, Nan
   Chen, Li
   Zhang, Xiaolong
TI Hierarchical salient object detection model using contrast-based
   saliency and color spatial distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hierarchical model; Salient object detection; Contrast measure; Color
   distribution
ID VISUAL-ATTENTION
AB Visual saliency is an important cue in human visual system to detect salient objects in natural scenes. It has attracted a lot of research focus in computer vision, and has been widely used in many applications including image retrieval, object recognition, image segmentation, and etc. However, the accuracy of salient object detection model remains a challenge. Accordingly, a hierarchical salient object detection model is presented in this paper. In order to accurately interpret object saliency in image, we propose to investigate distinctive features from a global perspective. Image contrast and color distribution are calculated to generate saliency maps respectively, which are then fused using the principal component analysis. Compared with state-of-the-art models, the proposed model can accurately detect the salient object which conform with the human visual principle. The experimental results from the MSRA database validate the effectiveness of our proposed model.
C1 [Xu, Xin; Mu, Nan; Chen, Li; Zhang, Xiaolong] Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
   [Xu, Xin; Mu, Nan; Chen, Li; Zhang, Xiaolong] Wuhan Univ Sci & Technol, Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Peoples R China.
C3 Wuhan University of Science & Technology; Wuhan University of Science &
   Technology
RP Xu, X (corresponding author), Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.; Xu, X (corresponding author), Wuhan Univ Sci & Technol, Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Peoples R China.
EM xuxin0336@gmail.com
RI Mu, Nan/W-1313-2019; ZHANG, XIAOLONG/IZQ-4553-2023; Xu,
   Xin/JRW-5800-2023
FU National Natural Science Foundation of China [61440016, 61375017,
   61273225]; Natural Science Foundation of Hubei Provincial of China
   [2014CFB247]; open foundation of the key laboratory for metallurgical
   equipment and control of ministry of education [2013B08]
FX This work was supported in part by the National Natural Science
   Foundation of China (61440016, 61375017, 61273225), the Natural Science
   Foundation of Hubei Provincial of China (2014CFB247), the open
   foundation of the key laboratory for metallurgical equipment and control
   of ministry of education (2013B08)
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Aziz MZ, 2008, IEEE T IMAGE PROCESS, V17, P633, DOI 10.1109/TIP.2008.919365
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Chen LQ, 2003, MULTIMEDIA SYST, V9, P353, DOI 10.1007/s00530-003-0105-4
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Lu Y, 2011, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2011.6126247
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Santella A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P771
   Shi KY, 2013, PROC CVPR IEEE, P2115, DOI 10.1109/CVPR.2013.275
   Stentiford F., 2007, Proceedings of the International Conference on Computer Vision Systems, P1
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 22
TC 14
Z9 15
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2667
EP 2679
DI 10.1007/s11042-015-2570-0
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000017
DA 2024-07-18
ER

PT J
AU Shuai, X
   O'Hare, N
   Aiello, LM
   Jaimes, A
AF Shuai, Xin
   O'Hare, Neil
   Aiello, Luca Maria
   Jaimes, Alejandro
TI Predicting celebrity attendees at public events using stock photo
   metadata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Language model; Photo metadata; Events attendees prediction; Stock
   photos
AB The large collections of news images available from stock photo agencies provide interesting insights into how different celebrities are related to each other, in terms of the events they attend together and also in terms of how often they are photographed together. In this paper, we leverage such collections to predict which celebrities will attend future events. The main motivation for this is in the event-based indexing of online collections of multimedia content, an area that has attracted much attention in recent years. Based on the metadata associated with a corpus of stock photos, we propose a language model for predicting celebrities attending future events. A temporal hierarchical version of the language model exploits fresh data while still making use of all historical data. We extract a social network from co-appearance of public figures in the events depicted in the photographs, and combine this latent social information with the language model to further improve prediction accuracy. The experimental results show that combining textual, network and temporal information gives the best prediction performance. Our analysis also shows that the prediction models, when trained by the most recent data, are most accurate for political and sports events.
C1 [Shuai, Xin] Indiana Univ, Bloomington, IN USA.
   [O'Hare, Neil; Aiello, Luca Maria; Jaimes, Alejandro] Yahoo Res Barcelona, Barcelona, Spain.
C3 Indiana University System; Indiana University Bloomington; Yahoo! Inc;
   Yahoo! Inc Spain
RP Shuai, X (corresponding author), Indiana Univ, Bloomington, IN USA.
EM xshuai@indiana.edu; nohare@yahoo-inc.com; alucca@yahoo-inc.com;
   ajaimes@yahoo-inc.com
RI Aiello, Luca Maria/ABB-2507-2021
OI Aiello, Luca Maria/0000-0002-0654-2527
CR Ahmed A, 2007, ASIA-PACIFIC SYMPOSIUM ON VISUALISATION 2007, PROCEEDINGS, P17
   Aiello L.-M, 2010, Proceedings of the 2010 IEEE Second International Conference on Social Computing (SocialCom 2010). the Second IEEE International Conference on Privacy, Security, Risk and Trust (PASSAT 2010), P249, DOI 10.1109/SocialCom.2010.42
   Aiello LM, 2012, ACM T WEB, V6, DOI 10.1145/2180861.2180866
   Anguelov D., 2007, Computer Vision and Pattern Recognition, P1
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], 11 TEXT RETRIEVAL C
   [Anonymous], 2003, ACM Multimedia Conference
   [Anonymous], ICMR 2014 WORKSH SOC
   [Anonymous], 2010, P 3 ACM INT C WEB SE, DOI DOI 10.1145/1718487.1718524
   [Anonymous], BIOGRAPHICAL SOCIAL
   [Anonymous], 2010, P ACM WORKSH SURR ME
   [Anonymous], MEDIAEVAL 13
   [Anonymous], TECHNICAL REPORT
   [Anonymous], P 20 ACM INT C MULT
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chen L., 2009, Proceedings of the 18th ACM conference on Information and knowledge management, P523
   Cooper Matthew., 2005, ACM T MULTIM COMPUT, V1, P269, DOI [DOI 10.1145/1083314.1083317, 10.1145/1083314.1083317]
   Davis M., 2005, 13th Annual ACM International Conference on Multimedia, P483, DOI 10.1145/1101149.1101257
   Devezas Jose, 2012, Advances in Information Retrieval. Proceedings of the 34th European Conference on IR Research (ECIR 2012), P485, DOI 10.1007/978-3-642-28997-2_47
   DT PengWu., 2009, Proceedings of MM09, P709
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Jelinek F., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop, P381
   Luo J., 2008, ACM International Conference on Multimedia, P1071, DOI DOI 10.1145/1459359.1459574MULTIMEDIA-MM'PLACE
   Mantrach Amin, 2012, Advances in Information Retrieval. Proceedings of the 34th European Conference on IR Research (ECIR 2012), P512, DOI 10.1007/978-3-642-28997-2_53
   Mavridis N, 2010, COMPUT COMMUN NETW S, P453, DOI 10.1007/978-1-84882-229-0_18
   Naaman M, 2005, ACM-IEEE J CONF DIG, P178, DOI 10.1145/1065385.1065430
   O'Hare N, 2013, INFORM RETRIEVAL, V16, P30, DOI 10.1007/s10791-012-9195-y
   O'Hare N, 2009, IEEE T MULTIMEDIA, V11, P220, DOI 10.1109/TMM.2008.2009679
   Ponte JM, 1998, P 21 ANN INT ACM SIG, P275, DOI DOI 10.1145/290941.291008
   Rattenbury Tye, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P103, DOI 10.1145/1277741.1277762
   Serdyukov P, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P484, DOI 10.1145/1571941.1572025
   Singla Parag, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563047
   Sivic Josef., 2006, British Machine Vision Conference, P909
   Xie LX, 2008, P IEEE, V96, P623, DOI 10.1109/JPROC.2008.916362
   Zhao M, 2006, LECT NOTES COMPUT SC, V4071, P163
   Zickler T, 2008, IEEE COMPUTER SOC C, P1
NR 36
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2145
EP 2167
DI 10.1007/s11042-014-2399-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000019
DA 2024-07-18
ER

PT J
AU Xia, ZH
   Wang, XH
   Sun, XM
   Liu, QS
   Xiong, NX
AF Xia, Zhihua
   Wang, Xinhui
   Sun, Xingming
   Liu, Quansheng
   Xiong, Naixue
TI Steganalysis of LSB matching using differences between nonadjacent
   pixels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; LSB matching; Difference histogram; Characteristic
   function; Support vector machine
ID STEGANOGRAPHY; HISTOGRAM
AB This paper models the messages embedded by spatial least significant bit (LSB) matching as independent noises to the cover image, and reveals that the histogram of the differences between pixel gray values is smoothed by the stego bits despite a large distance between the pixels. Using the characteristic function of difference histogram (DHCF), we prove that the center of mass of DHCF (DHCF COM) decreases after messages are embedded. Accordingly, the DHCF COMs are calculated as distinguishing features from the pixel pairs with different distances. The features are calibrated with an image generated by average operation, and then used to train a support vector machine (SVM) classifier. The experimental results prove that the features extracted from the differences between nonadjacent pixels can help to tackle LSB matching as well.
C1 [Xia, Zhihua; Wang, Xinhui; Sun, Xingming] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
   [Xia, Zhihua; Wang, Xinhui; Sun, Xingming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Liu, Quansheng] Univ Bretagne Sud, UMR6205, LMBA, Campus Tohannic,BP573, F-56000 Vannes, France.
   [Xiong, Naixue] Colorado Tech Univ, Sch Comp Sci, Colorado Springs, CO 80907 USA.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Centre National de la
   Recherche Scientifique (CNRS); CNRS - National Institute for
   Mathematical Sciences (INSMI); Colorado Technical University
RP Xia, ZH (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
EM xia_zhihua@163.com; wxh_nuist@163.com; sunnudt@163.com;
   quansheng.Liu@univ-ubs.fr; xiongnaixue@gmail.com
RI Sun, Xingming/AAD-1866-2019; Xia, Zhihua/C-8581-2011; xiong,
   naixue/M-4277-2019
OI xiong, naixue/0000-0002-0394-4635; Xia, Zhihua/0000-0001-6860-647X
FU NSFC [61173141, 61232016, 61202496, 61173142, 61173136, 61103215,
   61103141, 61373132, 61373133, GYHY201206033, 201301030, 2013DFG12860,
   BC2013012]; Jiangsu Engineering Center of Network Monitoring [KJR1308];
   PAPD fund
FX This work is supported by the NSFC (61173141, 61232016, 61202496,
   61173142, 61173136, 61103215, 61103141, 61373132, 61373133),
   GYHY201206033, 201301030, 2013DFG12860, BC2013012, Open Fund of Jiangsu
   Engineering Center of Network Monitoring (KJR1308) and PAPD fund.
CR [Anonymous], 2011, NRCS PHOTO GALLERY
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cai KW, 2010, IEEE IMAGE PROC, P1761, DOI 10.1109/ICIP.2010.5651567
   Cancelli G, 2008, IEEE IMAGE PROC, P1288, DOI 10.1109/ICIP.2008.4711998
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Filler T, 2011, BOSS
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Fridrich Jessica, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P102, DOI 10.1007/978-3-642-24178-9_8
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Goljan M, 2006, PROC SPIE, V6072, DOI 10.1117/12.643254
   Gong R, 2012, OPT COMMUN, V285, P4961, DOI 10.1016/j.optcom.2012.07.121
   Guo Y-Q, 2013, DIGITAL FORENSICS WA, P34
   Harmsen JJ, 2003, PROC SPIE, V5020, P131, DOI 10.1117/12.476813
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Kodovsky J, 2013, ELECT IMAGING MEDIA
   Liu QZ, 2008, PATTERN RECOGN, V41, P56, DOI 10.1016/j.patcog.2007.06.005
   Lou DC, 2012, OPT COMMUN, V285, P2510, DOI 10.1016/j.optcom.2012.01.021
   Lou DC, 2012, INFORM SCIENCES, V188, P346, DOI 10.1016/j.ins.2011.06.003
   Lyu SW, 2006, IEEE T INF FOREN SEC, V1, P111, DOI 10.1109/TIFS.2005.863485
   Pevny T, 2012, IEEE T INF FOREN SEC, V7, P445, DOI 10.1109/TIFS.2011.2175918
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Xia ZH, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033008
   Xiong G, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.3.033015
   Zhang H, 2014, SCI CHINA INFORM SCI, V57, DOI 10.1007/s11432-013-4793-x
   Zhang J, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P385, DOI 10.1109/MMSP.2007.4412897
   Zhang J, 2009, J COMPUT, V4, P646
   Zhao Yanli, 2012, 2012 International Conference on Management of e-Commerce and e-Government (ICMeCG 2012), P68, DOI 10.1109/ICMeCG.2012.30
   Zheng EG, 2010, IEEE IMAGE PROC, P1005, DOI 10.1109/ICIP.2010.5652894
NR 30
TC 369
Z9 373
U1 3
U2 111
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 1947
EP 1962
DI 10.1007/s11042-014-2381-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000010
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Xu, X
   Shimada, A
   Nagahara, H
   Taniguchi, R
AF Xu, Xing
   Shimada, Atsushi
   Nagahara, Hajime
   Taniguchi, Rin-ichiro
TI Learning multi-task local metrics for image annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image annotation; Label prediction; Metric learning; Local metric;
   Multi-task learning
ID MULTIPLE TASKS; REPRESENTATION
AB The goal of image annotation is to automatically assign a set of textual labels to an image to describe the visual contents thereof. Recently, with the rapid increase in the number of web images, nearest neighbor (NN) based methods have become more attractive and have shown exciting results for image annotation. One of the key challenges of these methods is to define an appropriate similarity measure between images for neighbor selection. Several distance metric learning (DML) algorithms derived from traditional image classification problems have been applied to annotation tasks. However, a fundamental limitation of applying DML to image annotation is that it learns a single global distance metric over the entire image collection and measures the distance between image pairs in the image-level. For multi-label annotation problems, it may be more reasonable to measure similarity of image pairs in the label-level. In this paper, we develop a novel label prediction scheme utilizing multiple label-specific local metrics for label-level similarity measure, and propose two different local metric learning methods in a multi-task learning (MTL) framework. Extensive experimental results on two challenging annotation datasets demonstrate that 1) utilizing multiple local distance metrics to learn label-level distances is superior to using a single global metric in label prediction, and 2) the proposed methods using the MTL framework to learn multiple local metrics simultaneously can model the commonalities of labels, thereby facilitating label prediction results to achieve state-of-the-art annotation performance.
C1 [Xu, Xing; Shimada, Atsushi; Nagahara, Hajime; Taniguchi, Rin-ichiro] Kyushu Univ, Dept Adv Informat & Technol, Fukuoka 812, Japan.
C3 Kyushu University
RP Xu, X (corresponding author), Kyushu Univ, Dept Adv Informat & Technol, Fukuoka 812, Japan.
EM xing.xu@ieee.org
OI Shimada, Atsushi/0000-0002-3635-9336
CR Ando RK, 2005, J MACH LEARN RES, V6, P1817
   [Anonymous], 2010, Proceedings of the Eighteenth ACM International Conference on Multimedia, DOI DOI 10.1145/1873951.1873959
   [Anonymous], 2014, MICROCHIM ACTA
   Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8
   Binder A, 2013, COMPUT VIS IMAGE UND, V117, P466, DOI 10.1016/j.cviu.2012.09.006
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen X., 2011, P 19 ACM INT C MULT, P263
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Evgeniou T, 2005, J MACH LEARN RES, V6, P615
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Feng Z, 2013, IEEE INT C COMP VIS, P3490
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P498, DOI 10.1109/ICCV.2009.5459197
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Li XR, 2009, INT CONF ACOUST SPEE, P3717, DOI 10.1109/ICASSP.2009.4960434
   Lin ZJ, 2013, IEEE IMAGE PROC, P2567, DOI 10.1109/ICIP.2013.6738529
   Liu Y, 2009, RES REPORT
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Mensink T, 2012, LECT NOTES COMPUT SC, V7573, P488, DOI 10.1007/978-3-642-33709-3_35
   Nagel K, 2011, CLEF LABS WORKSH
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Parameswaran S., 2010, ADV NEURAL INFORM PR, P1867
   Putthividhya D, 2010, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2010.5540000
   Su Y, 2011, CLEF LABS WORKSH
   Ushiku Y, 2012, CLEF ONL WORK NOT LA
   van de Sande KEA, 2011, CLEF LABS WORKSH
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Verbeek J., 2010, Proc. ACM Multimedia Information Retrieval, P537
   Verma Y, 2013, BMVC, P251
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wu L, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899417
   Xiang Y, 2009, PROC CVPR IEEE, P1153, DOI 10.1109/CVPRW.2009.5206518
   Xu X, 2013, LECT NOTES COMPUT SC, V8156, P101
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yuan XT, 2012, IEEE T IMAGE PROCESS, V21, P4349, DOI 10.1109/TIP.2012.2205006
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
NR 40
TC 7
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2203
EP 2231
DI 10.1007/s11042-014-2402-7
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000022
DA 2024-07-18
ER

PT J
AU Gudigar, A
   Chokkadi, S
   Raghavendra, U
AF Gudigar, Anjan
   Chokkadi, Shreesha
   Raghavendra, U.
TI A review on automatic detection and recognition of traffic sign
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Detection; Image acquisition; Intelligent transport
   system; Safety; Segmentation
ID ROAD SIGNS; CLASSIFICATION; IDENTIFICATION; SEGMENTATION; ALGORITHMS;
   COLOR
AB Evidently, Intelligent Transport System (ITS) has progressed tremendously all its way. The core of ITS are detection and recognition of traffic sign, which are designated to fulfill safety and comfort needs of driver. This paper provides a critical review on three major steps in Automatic Traffic Sign Detection and Recognition(ATSDR) system i.e., segmentation, detection and recognition in the context of vision based driver assistance system. In addition, it focuses on different experimental setups of image acquisition system. Further, discussion on possible future research challenges is made to make ATSDR more efficient, which inturn produce a wide range of opportunities for the researchers to carry out the detailed analysis of ATSDR and to incorporate the future aspects in their research.
C1 [Gudigar, Anjan; Chokkadi, Shreesha; Raghavendra, U.] Manipal Univ, Dept Instrumentat & Control Engn, Manipal Inst Technol, Manipal 576104, Karnataka, India.
C3 Manipal Academy of Higher Education (MAHE)
RP Gudigar, A (corresponding author), Manipal Univ, Dept Instrumentat & Control Engn, Manipal Inst Technol, Manipal 576104, Karnataka, India.
EM anjan.gudigar@manipal.edu; shreesha.c@manipal.edu;
   raghavendra.u@manipal.edu
RI Chokkadi, Shreesha/AAT-3001-2021; Gudigar, Anjan/G-9717-2015;
   Raghavendra, U/G-8634-2015
OI Chokkadi, Shreesha/0000-0001-5966-1119; Gudigar,
   Anjan/0000-0001-5634-9103; Raghavendra, U/0000-0002-1124-089X
CR Abukhait J, 2012, 2012 IEEE INT C ELEC, P1
   [Anonymous], 2012, P 4 INT C INTERNET M
   [Anonymous], TRAFFIC SIGNS DATABA
   Barnes N, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P566
   Barnes N, 2008, IEEE T INTELL TRANSP, V9, P322, DOI 10.1109/TITS.2008.922935
   Baró X, 2009, IEEE T INTELL TRANSP, V10, P113, DOI 10.1109/TITS.2008.2011702
   Belaroussi R., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P484, DOI 10.1109/ICPR.2010.1125
   Belaroussi R., 2009, IEEE WORKSHOP APPL C, P1
   Belaroussi R, 2009, LECT NOTES COMPUT SC, V5876, P1161, DOI 10.1007/978-3-642-10520-3_111
   Bénallal M, 2003, CCECE 2003: CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, VOLS 1-3, PROCEEDINGS, P1823
   Boumediene M, 2013, MACH VISION APPL, V24, P1721, DOI 10.1007/s00138-013-0540-y
   Cardarelli E, 2009, IEEE INT VEH SYM, P376, DOI 10.1109/IVS.2009.5164307
   Creusen IM, 2010, IEEE IMAGE PROC, P2669, DOI 10.1109/ICIP.2010.5651637
   de la Escalera A, 2004, IEEE T INTELL TRANSP, V5, P57, DOI 10.1109/TITS.2004.828173
   de la Escalera A, 2003, IMAGE VISION COMPUT, V21, P247, DOI 10.1016/S0262-8856(02)00156-7
   Eichner ML, 2008, IEEE INT VEH SYM, P964
   Fang CY, 2003, IEEE T VEH TECHNOL, V52, P1329, DOI 10.1109/TVT.2003.810999
   Fleyeh H, 2011, IET INTELL TRANSP SY, V5, P190, DOI 10.1049/iet-its.2010.0159
   Fleyeh Hasan, 2008, 2008 IEEE Intelligent Vehicles Symposium (IV), P530, DOI 10.1109/IVS.2008.4621132
   Fleyeh H, 2007, 2007 IEEE INTELLIGENT VEHICLES SYMPOSIUM, VOLS 1-3, P1
   Fleyeh H, 2006, CONF CYBERN INTELL S, P1, DOI 10.1109/ICCIS.2006.252225
   Gao XW, 2006, J VIS COMMUN IMAGE R, V17, P675, DOI 10.1016/j.jvcir.2005.10.003
   Gao X. W., 2011, ICDSP, V2011, P1
   Gao XH, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/386705
   Ghica R, 1994, P CAN C EL COMP ENG
   Gil-Jimenez P., 2007, Proceedings of the 2007 IEEE Intelligent Vehicles Symposium, P375
   Gómez-Moreno H, 2010, IEEE T INTELL TRANSP, V11, P917, DOI 10.1109/TITS.2010.2054084
   Greenhalgh J, 2012, IEEE T INTELL TRANSP, V13, P1498, DOI 10.1109/TITS.2012.2208909
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P1274, DOI 10.1109/TIP.2003.816010
   Gu YL, 2011, IEEE INT VEH SYM, P1054, DOI 10.1109/IVS.2011.5940513
   Gu YL, 2010, IEEE INT VEH SYM, P7, DOI 10.1109/IVS.2010.5548005
   Gudigar A, 2012, COMM COM INF SC, V305, P153
   Han L., 2002, Proc. 1st. int. conf. mach. learn. cybern, V2, P83
   Houben S, 2011, IEEE INT VEH SYM, P124, DOI 10.1109/IVS.2011.5940429
   Hsin-Han Chiang, 2010, 2010 International Computer Symposium (ICS 2010), P246, DOI 10.1109/COMPSYM.2010.5685511
   Hsu SH, 2001, IMAGE VISION COMPUT, V19, P119, DOI 10.1016/S0262-8856(00)00050-0
   Ishizuka Y., 2004, P ITSWC, V18, P22
   Janssen H, 2003, uS Patent, Patent No. [6,560,529, 6560529]
   Jiménez PG, 2008, SIGNAL PROCESS, V88, P2943, DOI 10.1016/j.sigpro.2008.06.019
   Kastner R, 2010, IEEE INT VEH SYM, P333, DOI 10.1109/IVS.2010.5548143
   Keller CG, 2008, IEEE INT VEH SYM, P946
   Khan JF, 2011, IEEE T INTELL TRANSP, V12, P83, DOI 10.1109/TITS.2010.2073466
   Kiran CG, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P87, DOI 10.1109/ICAPR.2009.58
   Koncar A, 2007, PATTERN RECOGN LETT, V28, P260, DOI 10.1016/j.patrec.2006.07.012
   Kuo WJ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1427
   Kus MC, 2008, 23RD INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P117
   Larsson F, 2011, LECT NOTES COMPUT SC, V6688, P238, DOI 10.1007/978-3-642-21227-7_23
   Loy G., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P70
   Lu K, 2012, IEEE T INTELL TRANSP, V13, P1515, DOI 10.1109/TITS.2012.2220965
   Bascón SM, 2010, COMPUT VIS IMAGE UND, V114, P373, DOI 10.1016/j.cviu.2009.12.002
   Maldonado-Bascón S, 2007, IEEE T INTELL TRANSP, V8, P264, DOI 10.1109/TITS.2007.895311
   Mathias Markus, 2013, The 2013 International Joint Conference on Neural Networks (IJCNN), DOI 10.1109/IJCNN.2013.6707049
   Miura J, 2000, 2000 IEEE INTELLIGENT TRANSPORTATION SYSTEMS PROCEEDINGS, P52, DOI 10.1109/ITSC.2000.881017
   Mogelmose A, 2012, IEEE T INTELL TRANSP, V13, P1484, DOI 10.1109/TITS.2012.2209421
   Nguwi YY, 2008, NEURAL COMPUT APPL, V17, P265, DOI 10.1007/s00521-007-0120-z
   Paclík P, 2000, PATTERN RECOGN LETT, V21, P1165, DOI 10.1016/S0167-8655(00)00078-7
   Paclík P, 2006, IEEE T INTELL TRANSP, V7, P309, DOI 10.1109/TITS.2006.880627
   Parada-Loira F, 2010, IEEE INT VEH SYM, P1, DOI 10.1109/IVS.2010.5548008
   Pazhoumand-dar H, 2013, NEURAL COMPUT APPL, V22, P615, DOI 10.1007/s00521-011-0718-z
   Piccioli G, 1996, IMAGE VISION COMPUT, V14, P209, DOI 10.1016/0262-8856(95)01057-2
   Porikli F, 2011, uS Patent, Patent No. [8,041,080, 8041080]
   Priese L., 1994, Proceedings of the Intelligent Vehicles '94 Symposium (Cat. No.94TH8011), P249, DOI 10.1109/IVS.1994.639514
   Prieto MS, 2009, IMAGE VISION COMPUT, V27, P673, DOI 10.1016/j.imavis.2008.07.006
   RITTER W, 1995, MATH COMPUT MODEL, V22, P149, DOI 10.1016/0895-7177(95)00131-K
   Ruta A, 2011, MACH VISION APPL, V22, P359, DOI 10.1007/s00138-009-0231-x
   Ruta A, 2010, PATTERN RECOGN, V43, P416, DOI 10.1016/j.patcog.2009.05.018
   Soetedjo A., 2007, J Japan Soc Fuzzy Theory Intell Inform, V19, P457
   Souani C, 2014, J REAL-TIME IMAGE PR, V9, P79, DOI 10.1007/s11554-013-0348-z
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Stallkamp J, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1453, DOI 10.1109/IJCNN.2011.6033395
   Stein G, 2011, uS Patent, Patent No. [8,064,643, 8064643]
   Stein GP, 2010, IEEE INT VEH SYM, P723, DOI 10.1109/IVS.2010.5548019
   Stromme O, 2004, uS Patent, Patent No. [6,813,545, 6813545]
   Timofte Radu, 2009, WORKSH APPL COMP VIS, P1
   Xu S, 2009, IET INTELL TRANSP SY, V3, P10, DOI 10.1049/iet-its:20070058
   Yang HM, 2003, LECT NOTES ARTIF INT, V2871, P252
   Ying Li, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3033, DOI 10.1109/ICPR.2010.743
   Zadeh M., 1998, Proceedings of the SPIE intelligent system and automated manufacturing, P272
   Zaklouta F, 2014, ROBOT AUTON SYST, V62, P16, DOI 10.1016/j.robot.2012.07.019
   Zaklouta F, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2151, DOI 10.1109/IJCNN.2011.6033494
   Zhu YY, 2013, IEEE IMAGE PROC, P3755, DOI 10.1109/ICIP.2013.6738774
NR 81
TC 68
Z9 73
U1 2
U2 79
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 333
EP 364
DI 10.1007/s11042-014-2293-7
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500017
DA 2024-07-18
ER

PT J
AU Choensawat, W
   Nakamura, M
   Hachimura, K
AF Choensawat, Worawat
   Nakamura, Minako
   Hachimura, Kozaburo
TI GenLaban: A tool for generating Labanotation from motion capture data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dance notation; Labanotation data; Movement Analysis; LabanEditor
AB This paper presents a computer-aided tool for automatically generating Labanotation scores from motion capture data named GenLaban. GenLaban can be implemented with a low-cost equipment but an efficient method that allows users converting body motions to scores. The key components of GenLaban are the analysis of body motions, the quantization of body postures and the determination of body parts carrying the body weight. All the processes are under supervision of a Labanotation expert to ensure the notation meaning correctly as the use for the dance composition. The experiments showed that for dancers, dance instructors and choreographers, GenLaban is a potential tool for notating dance movements into Labanotation scores enabling them to be accurately interpreted. At present the system can handle a subset of Labanotation covering many of the fundamental movements. However, Labanotation is rich in symbols and new symbols are continually being introduced and will be incorporated in the GenLaban tool as time permits.
C1 [Choensawat, Worawat] Bangkok Univ, Sch Sci & Technol, Bangkok, Thailand.
   [Nakamura, Minako] Ochanomizu Univ, Grad Sch Humanities & Sci, Tokyo 112, Japan.
   [Hachimura, Kozaburo] Ritsumeikan Univ, Coll Informat Sci & Engn, Kusatsu, Shiga, Japan.
C3 Bangkok University; Ochanomizu University; Ritsumeikan University
RP Choensawat, W (corresponding author), Bangkok Univ, Sch Sci & Technol, Bangkok, Thailand.
EM worawat.c@bu.ac.th; nakamura.minako@ocha.ac.jp;
   hachimura@media.ritsumei.ac.jp
FU Institute of Research Promotion and Innovation Development at Bangkok
   University; MEXT Japan [22300039]; Grants-in-Aid for Scientific Research
   [22300039] Funding Source: KAKEN
FX This work is supported in part by the Institute of Research Promotion
   and Innovation Development at Bangkok University and the Grant-in-Aid
   for Scientific Research (B) No. 22300039 from MEXT Japan.
CR [Anonymous], 22 BIENN C INT COUNC
   [Anonymous], 2006, REV NATL CTR DIGITIZ
   Bulut E., 2007, P 20 ANN C COMP AN S
   CHEN H, 2013, CULT COMP CULT COMP, P222, DOI DOI 10.1109/CULTURECOMPUTING.2013.75
   Chien-Yen Chang, 2012, 2012 6th International Conference on Pervasive Computing Technologies for Healthcare, P159, DOI 10.4108/icst.pervasivehealth.2012.248714
   Choensawat W, 2010, DESCRIPTION REPROD S, V15
   Coyle M, TOOL TRANSLATING DAN
   Fern'ndez-Baena A., 2012, 2012 4th International Conference on Intelligent Networking and Collaborative Systems (INCoS 2012), P656, DOI 10.1109/iNCoS.2012.66
   Guest A. H., 2013, Labanotation: the system of analyzing and recording movement
   Guest A. Hutchinson, 1977, LABANOTATION
   Hachimura K, 2001, ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P122, DOI 10.1109/ROMAN.2001.981889
   Hachimura K, 2009, NEW DIRECTIONS DIGIT, P167
   Kannan R, 2010, MULTIMED TOOLS APPL, V46, P545, DOI 10.1007/s11042-009-0388-3
   Kojima K, 2002, IEEE ROMAN 2002, PROCEEDINGS, P59, DOI 10.1109/ROMAN.2002.1045598
   Lim IS, 2001, P ANN INT IEEE EMBS, V23, P1167
   Meredith M., 2001, Motion capture file formats explained
   MoCap C, 2003, DATA USED THIS PROJE
   Soga A, 2007, VISUAL COMPUT, V23, P309, DOI 10.1007/s00371-007-0110-2
   Wilke L, 2005, COMPUT ANIMAT VIRT W, V16, P201, DOI 10.1002/cav.90
   Xiao J, 2010, MULTIMED TOOLS APPL, V47, P379, DOI 10.1007/s11042-009-0329-1
NR 20
TC 31
Z9 34
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10823
EP 10846
DI 10.1007/s11042-014-2209-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700031
DA 2024-07-18
ER

PT J
AU Yang, JY
   Xiang, T
   Xiao, D
AF Yang, Jiyun
   Xiang, Tao
   Xiao, Di
TI Cryptanalysis of a secure chaotic map based block cryptosystem with
   application to camera sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera; Cryptosystem; Chaos; Cryptanalysis; Chosen ciphertext attack
AB Recently, a block cryptosystem based on iterating a chaotic map is analyzed and improved. But still four security flaws in this improved cryptosystem have been identified with careful analysis. First, the first block of ciphertext is identical to the corresponding plaintext in special circumstances. Second, an important parameter can be obtained with a chosen ciphertext attack. Third, with this parameter, a known block of ciphertext, and the corresponding block of plaintext, a block of plaintext can be recovered by chosen ciphertext attack. Forth, the relationship between every two blocks of the keystream can be determined, leading to the recovery of the entire keystream if a single block of the keystream can be obtained. Those four security flaws render the cryptosystem insecure for general use.
C1 [Yang, Jiyun; Xiang, Tao; Xiao, Di] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
C3 Chongqing University
RP Yang, JY (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
EM yangjy@cqu.edu.cn; txiang@cqu.edu.cn; dixiao@cqu.edu.cn
RI Yang, Jiyun/AAS-3937-2020; Xiang, Tao/N-3706-2016
OI Xiang, Tao/0000-0002-9439-4623
FU key scientific and technological projects of Chongqing [CSTC,
   2011AC2198]; National Natural Science Foundation of China [61070246]
FX The work was funded by the key scientific and technological projects of
   Chongqing (Grant No. CSTC, 2011AC2198) and the National Natural Science
   Foundation of China (Grant No. 61070246).
CR Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Guo C., 2013, J INF HIDING MULTIME, V4, P99
   Guo XY, 2011, SENSORS SENSORS
   Hao BL, 1993, Starting with parabolas-an introduction to chaotic dynamics
   Kocarev L, 2001, PHYS LETT A, V289, P199, DOI 10.1016/S0375-9601(01)00609-0
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Wang Y, 2007, PHYS LETT A, V363, P277, DOI 10.1016/j.physleta.2006.11.023
   Xiang T, 2006, PHYS LETT A, V349, P109, DOI 10.1016/j.physleta.2005.02.083
   Xiang T, 2008, COMMUN NONLINEAR SCI, V13, P1879, DOI 10.1016/j.cnsns.2007.04.017
   Zhou Q, 2008, CHAOS SOLITON FRACT, V38, P1081, DOI 10.1016/j.chaos.2007.01.034
NR 11
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10873
EP 10881
DI 10.1007/s11042-014-2211-z
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700033
DA 2024-07-18
ER

PT J
AU de Fez, I
   Gil, M
   Fons, J
   Guerri, JC
   Pelechano, V
AF de Fez, Ismael
   Gil, Miriam
   Fons, Joan
   Carlos Guerri, Juan
   Pelechano, Vicente
TI A personalized system for scalable distribution of multimedia content in
   multicast wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Push content download service; Personalization; Context-awareness; File
   delivery over unidirectional transport (FLUTE); Wireless networks;
   Multicast
ID MODEL
AB This paper presents a novel architecture for scalable multimedia content delivery over wireless networks. The architecture takes into account both the user preferences and context in order to provide personalized contents to each user. In this way, third-party applications filter the most appropriate contents for each client in each situation. One of the key characteristics of the proposal is the scalability, which is provided, apart from the use of filtering techniques, through the transmission in multicast networks. In this sense, content delivery is carried out by means of the FLUTE (File Delivery over Unidirectional Transport) protocol, which provides reliability in unidirectional environments through different mechanisms such as AL-FEC (Application Layer - Forward Error Correction) codes, used in this paper. Another key characteristic is the context-awareness and personalization of content delivery, which is provided by means of context information, user profiles, and adaptation. The system proposed is validated through several empirical studies. Specifically, the paper presents evaluations of two types that collect objective and subjective measures. The first evaluate the efficiency of the transmission protocol, analyzing how the use of appropriate transmission parameters reduces the download time (and thus increasing the Quality of Experience), which can be minimized by using caching techniques. On the other hand, the subjective measures present a study about the user experience after testing the application and analyze the accuracy of the filtering process/strategy. Results show that using AL-FEC mechanisms produces download times until four times lower than when no protection is used. Also, results prove that there is a code rate that minimizes the download time depending on the losses and that, in general, code rates 0.7 and 0.9 provide good download times for a wide range of losses. On the other hand, subjective measures indicate a high user satisfaction (more than 80 %) and a relevant degree of accuracy of the content adaption.
C1 [de Fez, Ismael; Carlos Guerri, Juan] Univ Politecn Valencia, Inst Telecommun & Multimedia Applicat iTEAM, Valencia 46022, Spain.
   [Gil, Miriam; Fons, Joan; Pelechano, Vicente] Univ Politecn Valencia, Res Ctr Software Prod Methods PROS, Valencia 46022, Spain.
C3 Universitat Politecnica de Valencia; Universitat Politecnica de Valencia
RP de Fez, I (corresponding author), Univ Politecn Valencia, Inst Telecommun & Multimedia Applicat iTEAM, Camino Vera, Valencia 46022, Spain.
EM isdefez@iteam.upv.es; mgil@pros.upv.es; jjfons@pros.upv.es;
   jcguerri@dcom.upv.es; pele@pros.upv.es
RI de+Fez+Lava, Ismael/AAJ-1048-2020; Pelechano, Vicente/S-4344-2016; Gil,
   Miriam/AAB-1461-2020; Fons, Joan/ABG-9296-2020; Gil,
   Miriam/HGD-5342-2022; Guerri, Juan Carlos/K-9659-2014
OI Pelechano, Vicente/0000-0003-1090-230X; Gil, Miriam/0000-0002-2987-1825;
   de Fez, Ismael/0000-0002-1337-1973; Guerri, Juan
   Carlos/0000-0002-5807-1923; Fons, Joan/0000-0002-3718-3096
FU Ministerio de Economia y Competitividad of the Government of Spain under
   project COMINN [IPT-2012-0883-430000]; program of the Vicerrectorado de
   Investigacion of the Universitat Politecnica de Valencia [PAID/2012/313,
   PAID-05-12]
FX This work is supported in part by the Ministerio de Economia y
   Competitividad of the Government of Spain under project COMINN
   (IPT-2012-0883-430000) and by the project PAID/2012/313 from the
   PAID-05-12 program of the Vicerrectorado de Investigacion of the
   Universitat Politecnica de Valencia.
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P217, DOI 10.1007/978-0-387-85820-3_7
   [Anonymous], P 7 EUR INT TV C EUR
   [Anonymous], 2008, 5170 IETF RFC
   [Anonymous], 7 FRAM PROGR FP7
   [Anonymous], 2005, WORKSH SMART ENV THE
   [Anonymous], P SIGCOMM WORKSH NET
   [Anonymous], 126346 ETSI
   [Anonymous], 102034 ETSI
   [Anonymous], 102472 ETSI
   [Anonymous], P IEEE VEH TECHN C V
   [Anonymous], OWL 2WEB ONT LANG DO
   [Anonymous], P IEEE INT S BROADB
   [Anonymous], MAJ US MOB US AR NOW
   [Anonymous], INT J INFORM SCI TEC
   [Anonymous], 2000, SURVEY CONTEXT AWARE
   [Anonymous], P OZCHI COMP HUM INT
   [Anonymous], P MOMM LINZ AUSTR
   [Anonymous], P MOBIQUITOUS BEIJ C
   Assad M, 2007, LECT NOTES COMPUT SC, V4480, P55
   Bai Haowei, 2003, IEEE Communications Surveys & Tutorials, V5, P2, DOI 10.1109/COMST.2003.5341334
   Baldauf M, 2007, INT J AD HOC UBIQ CO, V2, P263, DOI 10.1504/IJAHUC.2007.014070
   Chen YFR, 2010, MULTIMEDIA SYST, V16, P199, DOI 10.1007/s00530-010-0184-y
   de Fez I, 2014, IEEE T MULTIMEDIA, V16, P1140, DOI 10.1109/TMM.2014.2307155
   de Fez I, 2013, COMPUT COMMUN, V36, P1298, DOI 10.1016/j.comcom.2013.04.008
   de Fez I, 2012, MULTIMED TOOLS APPL, V60, P669, DOI 10.1007/s11042-011-0841-y
   de Fez I, 2012, IEEE T MULTIMEDIA, V14, P641, DOI 10.1109/TMM.2012.2190392
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   Du RB, 2003, ICON 2003: 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORKS, P325
   Felfernig Alexander, 2013, Multimedia services in intelligent environments, P81
   Fraile F, 2014, IEEE T BROADCAST, V60, P1, DOI 10.1109/TBC.2013.2289639
   GALLAGER RG, 1962, IRE T INFORM THEOR, V8, P21, DOI 10.1109/tit.1962.1057683
   Gil M, 2012, PERS UBIQUIT COMPUT, V16, P543, DOI 10.1007/s00779-011-0414-0
   Guillén J, 2014, IEEE SOFTWARE, V31, P48, DOI 10.1109/MS.2013.140
   Hsieh CC, 2009, IEEE T CONSUM ELECTR, V55, P1779, DOI 10.1109/TCE.2009.5373731
   Jenkac H., 2006, Journal of Zhejiang University (Science), V7, P873, DOI 10.1631/jzus.2006.A0873
   Kellerer H., 2004, Knapsack Problems. Springer Nature Book Archives Millennium, P317
   Korpipää P, 2006, IEEE PERVAS COMPUT, V5, P82, DOI 10.1109/MPRV.2006.49
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Liang Li, 2010, 2010 Second IITA International Conference on Geoscience and Remote Sensing (IITA-GRS 2010), P1, DOI 10.1109/IITA-GRS.2010.5603083
   Neumann C, 2005, ACM SIGCOMM COMP COM, V35, P85, DOI 10.1145/1096536.1096550
   Paolini Enrico, 2008, 2008 4th Advanced Satellite Mobile Systems (ASMS), P274, DOI 10.1109/ASMS.2008.54
   Papastergiou G, 2009, COMPUT COMMUN, V32, P1757, DOI 10.1016/j.comcom.2009.02.012
   Peltotalo J, 2007, INT J COMMUN SYST, V20, P633, DOI 10.1002/dac.835
   Podlipnig S, 2003, ACM COMPUT SURV, V35, P374, DOI 10.1145/954339.954341
   Qianbing Zheng, 2010, Proceedings of the 2010 IEEE/ACM Int'l Conference on Green Computing and Communications (GreenCom) and Int'l Conference on Cyber, Physical and Social Computing (CPSCom), P578, DOI 10.1109/GreenCom-CPSCom.2010.64
   Runeson P, 2009, EMPIR SOFTW ENG, V14, P131, DOI 10.1007/s10664-008-9102-8
   Schiller J., 2004, Location-Based Services
   Serral E, 2014, MULTIMED TOOLS APPL, V71, P159, DOI 10.1007/s11042-013-1634-2
   Serral E, 2010, PERVASIVE MOB COMPUT, V6, P254, DOI 10.1016/j.pmcj.2009.07.006
   Streefkerk JW, 2006, COMPUT HUM BEHAV, V22, P749, DOI 10.1016/j.chb.2005.12.006
   Valtonen M, 2009, INT CONF PERVAS COMP, P31
   Walsh R., 2012, 6726 IETF RFC
   Weld Daniel S., 2003, P 18 INT JOINT C ART, P1613
   Xu JL, 2004, IEEE T KNOWL DATA EN, V16, P125, DOI 10.1109/TKDE.2004.1264827
   Yetgin Z, 2012, COMPUT NETW, V56, P533, DOI 10.1016/j.comnet.2011.09.017
NR 56
TC 1
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9595
EP 9621
DI 10.1007/s11042-014-2139-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200025
DA 2024-07-18
ER

PT J
AU Furini, M
   Tamanini, V
AF Furini, Marco
   Tamanini, Valentina
TI Location privacy and public metadata in social media platforms:
   attitudes, behaviors and opinions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geolocation; Public metadata; Location-enhanced computing; Location
   aware scenario; Location privacy; Location-aware social applications;
   Social media platform
AB The highavailability of geolocation technologies is changing the social media mobile scenario and is exposing users to privacy risks. Different studies have focused on location privacy in the mobile scenario, but the results are conflicting: some say that users are concerned about location privacy, others say they are not. In this paper, we initially investigate attitudes and behaviors of people toward a location-aware scenario; then, we show users the amount of personal and sensitive data that can be extracted from contents publicly available in social platforms, and finally we ask for their opinions about a location-aware scenario. Results show that people who were not initially concerned about privacy are the most worried about the location-aware scenario; conversely, people who were initially concerned are less worried about the location-aware scenario and find the scenario interesting. A deeper analysis of the obtained results allows us to draw guidelines that might be helpful to build an effective location-aware scenario.
C1 [Furini, Marco; Tamanini, Valentina] Univ Modena & Reggio Emilia, Dipartimento Comunicaz & Econ, Reggio Emilia, Italy.
C3 Universita di Modena e Reggio Emilia
RP Furini, M (corresponding author), Univ Modena & Reggio Emilia, Dipartimento Comunicaz & Econ, Reggio Emilia, Italy.
EM marco.furini@unimore.it
RI Furini, Marco/O-2867-2016
OI Furini, Marco/0000-0003-1094-6521
CR [Anonymous], 2010, P 19 ACM INT C INFOR, DOI DOI 10.1145/1871437.1871535
   [Anonymous], P 6 S US PRIV SEC
   [Anonymous], IEEE T SYST MAN CY B
   Backstrom L., 2010, WWW 2010 RAL NC, DOI [10.1145/1772690.1772698, DOI 10.1145/1772690.1772698]
   Bicocchi N, 2007, P 1 INT C MOBILE WIR, P6
   Chin E., 2012, Proceedings of the Eighth Symposium on Usable Privacy and Security, P1, DOI [DOI 10.1145/2335356.2335358, 10.1145/2335356.2335358.]
   Cho E., 2011, P 17 ACM SIGKDD INT, P1082, DOI DOI 10.1145/2020408.2020579
   Consolvo I. E., 2005, P SIGCHI C HUM FACT, P81, DOI [DOI 10.1145/1054972.1054985, 10.1145/1054972.1054985]
   De Silva GC, 2010, P ACM INT C IM VID R, P189
   Ferretti S, 2010, COMMUN ACM, V53, P139, DOI 10.1145/1721654.1721692
   Fisher D., 2012, Proc. spsm'12, P51, DOI 10.1145/2381934.2381945
   Friedland Gerald., 2010, P 18 ACM INT C MULTI, P1245, DOI DOI 10.1145/1873951.1874197
   ISACA, 2011, TECHNICAL REPORT
   Kelley PG, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2449
   Leighton T, 2009, COMMUN ACM, V52, P44, DOI 10.1145/1461928.1461944
   Li Rui., 2012, P 18 ACM SIGKDD INT, P1023
   Madden M., 2013, Teens, social media, and privacy, DOI DOI 14/2013/05/PIP_TEENSSOCIALMEDIAANDPRIVACY_PDF.PDF
   Roccetti M, 2008, CONSUM COMM NETWORK, P1123, DOI 10.1109/ccnc08.2007.253
   Zheng Y., 2009, WWW, P791, DOI [10.1145/1526709.1526816, DOI 10.1145/1526709.1526816]
NR 19
TC 46
Z9 50
U1 0
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9795
EP 9825
DI 10.1007/s11042-014-2151-7
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200034
DA 2024-07-18
ER

PT J
AU Liu, XY
   Zhu, YS
   Sun, ZQ
   Diao, MG
   Zhang, LM
AF Liu, Xiyao
   Zhu, Yuesheng
   Sun, Ziqiang
   Diao, Mengge
   Zhang, Liming
TI A novel robust video fingerprinting-watermarking hybrid scheme based on
   visual secret sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital rights management; Visual secret sharing; Fingerprinting;
   Zero-watermarking; 3D-DCT
ID EXTREME LEARNING-MACHINE; COPY DETECTION; ALGORITHM; TRANSFORM
AB In this paper, a novel robust Video Fingerprinting-Watermarking Hybrid Scheme (VFWHS) is proposed by applying fingerprinting technique to zero-watermarking algorithm for enhancing the performance of video Digital Rights Management (DRM). In the VFWHS, the content-based feature of the original video is extracted by an improved 3D-DCT fingerprinting algorithm and stored in a video fingerprint database for retrieval, while the watermark-based feature of the watermark image is extracted by a 2D-DCT fingerprinting algorithm for copyright identification. According to the visual secret sharing scheme, a master share is generated from the content-based feature while an ownership share is generated from the master share and the watermark-based feature. The ownership share is then stored in an ownership database. When a video is queried, its content-based features are generated, and a process of similarity measurement is executed to obtain the matched feature with the relevant ownership share. The copyright ownership can be identified by stacking the master share generated from the queried video with the relevant ownership share. Our experimental results demonstrate that the VFWHS can obtain the relevant ownership share precisely for reliable copyright identification in the mass content processing which cannot be achieved by the zero-watermarking algorithms, and provide explicit copyright identification to avoid possible copyright dissension which cannot be achieved by the fingerprinting algorithms.
C1 [Liu, Xiyao; Zhu, Yuesheng; Sun, Ziqiang; Diao, Mengge] Peking Univ, Shenzhen Grad Sch, Commun & Informat Secur Lab, Shenzhen 518055, Peoples R China.
   [Zhang, Liming] Univ Macau, Fac Sci & Technol, Macau 999078, Peoples R China.
C3 Peking University; University of Macau
RP Zhu, YS (corresponding author), Peking Univ, Shenzhen Grad Sch, Commun & Informat Secur Lab, Shenzhen 518055, Peoples R China.
EM lxyzoewx@163.com; zhuys@pkusz.edu.cn
RI Zhang, Liming/G-5518-2013; Zhang, Liming/ABG-5996-2020; liu,
   xiyao/GSE-0791-2022
OI Zhang, Liming/0000-0002-2664-8193; Zhang, Liming/0000-0002-2664-8193; 
FU 973 Program of China [2012CB315904]; Shenzhen Engineering Laboratory for
   Broadband Wireless Network Security
FX The authors would like to thanks Mr. Dennis D. Zhu for the kind support
   and valuable comments on this paper. This work is supported by the 973
   Program of China under Grant 2012CB315904; and Shenzhen Engineering
   Laboratory for Broadband Wireless Network Security.
CR Chan CS, 2012, J INF HIDING MULTIME, V3, P340
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   Gao GY, 2015, MULTIMED TOOLS APPL, V74, P841, DOI 10.1007/s11042-013-1701-8
   Gao GY, 2013, J SYST SOFTWARE, V86, P222, DOI 10.1016/j.jss.2012.07.070
   Guo C, 2013, JIH MSP, V4, P1
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Joly A, 2007, IEEE T MULTIMEDIA, V9, P293, DOI 10.1109/TMM.2006.886278
   Lee MC, 1997, J VIS COMMUN IMAGE R, V8, P405, DOI 10.1006/jvci.1997.0365
   Lee SJ, 2001, ISIE 2001: IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS PROCEEDINGS, VOLS I-III, P272, DOI 10.1109/ISIE.2001.931796
   Lee S, 2008, IEEE T CIRC SYST VID, V18, P983, DOI 10.1109/TCSVT.2008.920739
   Lian SG, 2010, STUD COMPUT INTELL, V282, P253
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Singh TR, 2013, AEU-INT J ELECTRON C, V67, P645, DOI 10.1016/j.aeue.2013.01.008
   Sun JD, 2012, IEEE SIGNAL PROC LET, V19, P328, DOI 10.1109/LSP.2012.2192271
   Sun ZQ, 2013, KSII T INTERNET INF, V7, P2754, DOI 10.3837/tiis.2013.11.012
   Tsai HH, 2010, J SYST SOFTWARE, V83, P1015, DOI 10.1016/j.jss.2009.12.026
   Wang MS, 2009, COMPUT STAND INTER, V31, P757, DOI 10.1016/j.csi.2008.09.003
   Wang ZH, 2014, JIH MSP, V5, P55
NR 23
TC 4
Z9 4
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9157
EP 9174
DI 10.1007/s11042-014-2073-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200004
DA 2024-07-18
ER

PT J
AU Wang, LJ
   Soong, FK
AF Wang, Lijuan
   Soong, Frank K.
TI HMM trajectory-guided sample selection for photo-realistic talking head
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual speech synthesis; Photo-realistic; Talking head;
   Trajectory-guided sample selection
ID SPEECH; SYSTEM
AB In this paper, we propose an HMM trajectory-guided, real image sample concatenation approach to photo-realistic talking head synthesis. An audio-visual database of a person is recorded first for training a statistical Hidden Markov Model (HMM) of Lips movement. The HMM is then used to generate the dynamic trajectory of lips movement for given speech signals in the maximum probability sense. The generated trajectory is then used as a guide to select, from the original training database, an optimal sequence of lips images which are then stitched back to a background head video. We also propose a minimum generation error (MGE) training method to refine the audio-visual HMM to improve visual speech trajectory synthesis. Compared with the traditional maximum likelihood (ML) estimation, the proposed MGE training explicitly optimizes the quality of generated visual speech trajectory, where the audio-visual HMM modeling is jointly refined by using a heuristic method to find the optimal state alignment and a probabilistic descent algorithm to optimize the model parameters under the MGE criterion. In objective evaluation, compared with the ML-based method, the proposed MGE-based method achieves consistent improvement in the mean square error reduction, correlation increase, and recovery of global variance. For as short as 20 min recording of audio/video footage, the proposed system can synthesize a highly photo-realistic talking head in sync with the given speech signals (natural or TTS synthesized). This system won the first place in the A/V consistency contest in LIPS Challenge, perceptually evaluated by recruited human subjects.
C1 [Wang, Lijuan; Soong, Frank K.] Microsoft Res Asia, Beijing 100080, Peoples R China.
C3 Microsoft; Microsoft Research Asia
RP Wang, LJ (corresponding author), Microsoft Res Asia, Beijing 100080, Peoples R China.
EM lijuanw@microsoft.com; frankkps@microsoft.com
RI Wang, Lijuan/GMX-3295-2022
CR Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bregler C., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P353, DOI 10.1145/258734.258880
   Cosatto E, 2000, IEEE T MULTIMEDIA, V2, P152, DOI 10.1109/6046.865480
   Donovan RE, 1998, P ICSLP, P1703
   Ezzat T, 2002, ACM T GRAPHIC, V21, P388, DOI 10.1145/566570.566594
   Ezzat T, 1998, COMP ANIM CONF PROC, P96, DOI 10.1109/CA.1998.681913
   Hirai T, 2004, P 5 ISCA SPEECH SYNT, P37
   Huang FJ, 2002, INT CONF ACOUST SPEE, P2037
   Huang X, 1997, INT CONF ACOUST SPEE, P959, DOI 10.1109/ICASSP.1997.596097
   Hunt AJ, 1996, INT CONF ACOUST SPEE, P373, DOI 10.1109/ICASSP.1996.541110
   King SA, 2005, IEEE T VIS COMPUT GR, V11, P341, DOI 10.1109/TVCG.2005.43
   Lewis J P., FAST NORMALIZED CROS
   Ling ZH, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2034
   Liu K, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2330
   Liu Kang., 2006, IEEE INT C ACOUSTICS, V5, P461
   Masuko T, 1996, INT CONF ACOUST SPEE, P389, DOI 10.1109/ICASSP.1996.541114
   Mattheyses W, 2008, LECT NOTES COMPUT SC, V5237, P125, DOI 10.1007/978-3-540-85853-9_12
   Nakamura S, 2002, IEEE T NEURAL NETWOR, V13, P854, DOI 10.1109/TNN.2002.1021886
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Pighin F., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P75, DOI 10.1145/280814.280825
   Sako S., 2000, ICSLP, P25
   Scott MR, 2011, P IEEE, V99, P1462, DOI 10.1109/JPROC.2011.2160107
   Theobald BJ, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2310
   Theobald BJ, 2004, SPEECH COMMUN, V44, P127, DOI 10.1016/j.specom.2004.07.002
   Toda T, 2005, INT CONF ACOUST SPEE, P9
   Tsuhan Chen, 2001, IEEE Signal Processing Magazine, V18, P9, DOI 10.1109/79.911195
   Wang JQ, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P653
   Wang LJ, 2012, COMPUTER, V45, P38, DOI 10.1109/MC.2012.152
   Wang LJ, 2011, INT CONF ACOUST SPEE, P4580
   Wang LJ, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P446
   Wang Q, 2006, IEEE T CIRC SYST VID, V16, P1533, DOI 10.1109/TCSVT.2006.885727
   Wu KK, 2011, INT CONF ACOUST SPEE, P1397
   Wu Y.-J., 2009, P 10 ANN C INT SPEEC, P1787
   Wu YJ, 2006, INT CONF ACOUST SPEE, P89
   Xie L, 2007, IEEE T MULTIMEDIA, V9, P500, DOI 10.1109/TMM.2006.888009
   Xie L, 2006, INT C PATT RECOG, P1128
   Yan ZJ, 2010, INT CONF ACOUST SPEE, P4798, DOI 10.1109/ICASSP.2010.5495150
   Zhang S, 2007, INT CONF ACOUST SPEE, P837
NR 38
TC 6
Z9 8
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 22
BP 9849
EP 9869
DI 10.1007/s11042-014-2118-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV1LQ
UT WOS:000364019400002
DA 2024-07-18
ER

PT J
AU Yang, MH
   Tao, JH
   Chao, LL
   Li, H
   Zhang, DW
   Che, H
   Gao, TL
   Liu, B
AF Yang, Minghao
   Tao, Jianhua
   Chao, Linlin
   Li, Hao
   Zhang, Dawei
   Che, Hao
   Gao, Tingli
   Liu, Bin
TI User behavior fusion in dialog management with multi-modal history cues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dialog management (DM); Multi-modal data fusion; Human computer
   interaction (HCI); Emotion detection
AB It enhances user experience by making the talking avatar be sensitive to user behaviors in human computer interaction (HCI). In this study, we combine user's multi-modal behaviors with behaviors' historical information in dialog management (DM) to improve the avatar's sensitivity not only to user explicit behavior (speech command) but also to user supporting expression (emotion and gesture, etc.). In the dialog management, according to the different contributions of facial expression, gesture and head motion to speech comprehension, we divide the user's multi-modal behaviors into three categories: complementation, conflict and independence. The behavior categories could be first automatically obtained from a short-term and time-dynamic (STTD) fusion model with audio-visual input. Different behavior category leads to different avatar's response in later dialog turns. Usually, the conflict behavior reflects user's ambiguous intention (for example: user says "no" while he (her) is smiling). In this case, the trial-and-error schema is adopted to eliminate the conversation ambiguity. For the later dialog process, we divide all the avatar dialog states into four types: "Ask", "Answer", "Chat" and "Forget". With the detection of complementation and independence behaviors, the user supporting expression as well as his (her) explicit behavior could be estimated as triggers for topic maintenance or transfer among four dialog states. At the first section of experiments, we discuss the reliability of STTD model for user behavior classification. Based on the proposed dialog management and STTD model, we continue to construct a drive route information query system by connecting the user behavior sensitive dialog management (BSDM) to a 3D talking avatar. The practical conversation records of avatar with different users show that the BSDM makes the avatar be able to understand and be sensitive to the users' facial expressions, emotional voice and gesture, which improves user experience on multi-modal human computer conversation.
C1 [Yang, Minghao; Tao, Jianhua; Chao, Linlin; Li, Hao; Zhang, Dawei; Che, Hao; Gao, Tingli; Liu, Bin] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Yang, MH (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing, Peoples R China.
EM mhyang@nlpr.ia.ac.cn; jhtao@nlpr.ia.ac.cn; llchao@nlpr.ia.ac.cn;
   hli@nlpr.ia.ac.cn; dwzhang@nlpr.ia.ac.cn; hche@nlpr.ia.ac.cn;
   tlgao@nlpr.ia.ac.cn; bliu@nlpr.ia.ac.cn
RI Zhang, Dawei/AHB-0326-2022
OI Zhang, Dawei/0000-0002-7593-1593
FU National Natural Science Foundation of China (NSFC) [61273288, 61233009,
   61203258, 61530503, 61332017, 61375027]; Major Program for the National
   Social Science Fund of China [13ZD189]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) (No. 61273288, No. 61233009, No. 61203258, No. 61530503,
   No. 61332017, No. 61375027), and the Major Program for the National
   Social Science Fund of China (13&ZD189).
CR [Anonymous], P 6 SIGDIAL WORKSH D
   Badler N, 1994, P SIGGRAPH, P73
   Bell L, 2000, INTERSPEECH, P589
   BOHUS D, 2005, P SIGDIAL LISB PORT
   Bousmalis K, 2013, EUR C MACH LEARN PRI
   Brustoloni J.C., 1991, Autonomous Agents: Characterization and Requirements. Carnegie Mellon Technical Report CMU-CS-91-204
   Cerekovic TPA, 2009, REALACTOR CHARACTER, P486
   Dobrisek S, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/54002
   Engwall Olov, 2007, Computer Assisted Language Learning, V20, P235, DOI 10.1080/09588220701489507
   Goddeau HMD, 1996, INT C SPOK LANG PROC, P701
   Heloir A, 2010, P 10 INT C INT VIRT
   Huang LX, 2007, LECT NOTES COMPUT SC, V4738, P729
   Lee C., 2010, J COMPUTING SCI ENG, V4, P1, DOI DOI 10.5626/JCSE.2010.4.1.001
   Levin E, 2000, IEEE T SPEECH AUDI P, V8, P11, DOI 10.1109/89.817450
   Litman DJ, 2006, C N AM CHAPT ASS COM
   McKeown G, 2010, IEEE INT CON MULTI, P1079, DOI 10.1109/ICME.2010.5583006
   Meng HY, 2011, LECT NOTES COMPUT SC, V6975, P378, DOI 10.1007/978-3-642-24571-8_49
   Niu ZH, 2009, IEEE SIGNAL PROC LET, V16, P897, DOI 10.1109/LSP.2009.2026457
   Pietquin O, 2006, IEEE T AUDIO SPEECH, V14, P589, DOI 10.1109/TSA.2005.855836
   Ramirez GA, 2011, LECT NOTES COMPUT SC, V6975, P396, DOI 10.1007/978-3-642-24571-8_51
   Rebillat M, 2010, 5 M FRENCH ASS VIRT
   Reidsma D Van, 2010, J MULTIMODAL USER IN, V3, P271
   Schatzmann J, 2006, KNOWL ENG REV, V21, P97, DOI 10.1017/S0269888906000944
   Schels M, 2013, MULTIMODAL CLASSIFIE
   Scherer KR, 1999, Handbook of Cognition and Emotion
   Schwarzlery SMS, 2009, C ANN C INT SPEECH C, P260
   Tao J, 2013, COMBINING EMOTIONAL
   Tao J, 2011, EURASIP J ADV SIG PR, V11, P1
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P449
   Tschechne S, 2011, AFFECTIVE COMPUTING, P378
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wik P, 2009, SPEECH COMMUN, V51, P1024, DOI 10.1016/j.specom.2009.05.006
   WILLIAMS JD, 2003, PROBABILISTIC MODEL
   Wöllmer M, 2013, IMAGE VISION COMPUT, V31, P153, DOI 10.1016/j.imavis.2012.03.001
   Yang MH, 2012, J MULTIMODAL USER IN, V5, P61, DOI 10.1007/s12193-011-0073-5
   Young S, 2006, C IEEE WORKSH SPOK L
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 37
TC 6
Z9 8
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 22
BP 10025
EP 10051
DI 10.1007/s11042-014-2161-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV1LQ
UT WOS:000364019400011
DA 2024-07-18
ER

PT J
AU Kim, MS
   Kim, CG
   Kim, SD
   Gaudiot, JL
AF Kim, Myoung-Seo
   Kim, Cheong Ghil
   Kim, Shin-Dug
   Gaudiot, Jean-Luc
TI Design of configurable I/O pin control block for improving reusability
   in multimedia SoC platforms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generic pin control block; Design automation; Multimedia
   system-on-a-chip
ID ARCHITECTURE
AB Multimedia system-on-a-chip (SoC) platform designs nowadays are facing some conflicting issues regarding product development. One is induced by increasing design complexity and another is induced by decreasing time-to-market. Hence, designers are seeking a more efficient and reliable methodology in order to design complex multi-million gate SoC under such harsh conditions. In particular, the complexity of a generic pin control block in multimedia SoC which implements input/output (I/O) paths for off-chip communication has increased exponentially in recent years. Accordingly, the possibility of introducing human errors in designing such block has grown. Operation of generic-pin control block needs to be validated with a top-level RTL from the early stages of design, which correctly checks full-chip interface. However, generic-pin control block has inherent several design issues since function registers and multi-I/O paths are usually fixed in the relatively late stages of design. Also, the role of a generic pin control block that shares limited pins causes frequent changes in pin assignment. Therefore, current design approaches of a generic pin control block are no longer adequate to meet the challenges of design productivity, design reusability, and shorter time-to-market for design. And, this results in many possible human errors when using a traditional RTL description. As a response to this problem, this paper presents a design automation based approach to reduce the possibility of human errors. In the case study presented, we succeeded in auto-generating a generic pin control block in multimedia SoC platforms which has more than 300 general purpose I/O interfaces including both input and output, as well as 900 PAD pins. Ultimately, we reduced the amount of manual description for generating a generic pin control block by a whopping 97 %.
C1 [Kim, Myoung-Seo; Gaudiot, Jean-Luc] Univ Calif Irvine, Henry Samueli Sch Engn, Dept EECS, Irvine, CA 92697 USA.
   [Kim, Cheong Ghil] Namseoul Univ, Dept Comp Sci, Cheonan, Choongnam, South Korea.
   [Kim, Shin-Dug] Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea.
C3 University of California System; University of California Irvine;
   Namseoul University; Yonsei University
RP Kim, MS (corresponding author), Univ Calif Irvine, Henry Samueli Sch Engn, Dept EECS, Irvine, CA 92697 USA.
EM myoungseo.kim@uci.edu; cgkim@nsu.ac.kr; sdkim@yonsei.ac.kr;
   gaudiot@uci.edu
OI Kim, Dr. Myoung-Seo/0000-0001-8556-4064
CR Adzic V, 2011, MULTIMED TOOLS APPL, V51, P379, DOI 10.1007/s11042-010-0669-x
   Berman V, 2006, IEEE DES TEST COMP
   Bruce A, 2006, P DES AUT C
   Cerqueira E, 2011, MULTIMED TOOLS APPL, V54, P635, DOI 10.1007/s11042-010-0578-z
   Cho K, 2008, P OF ISOCC
   Gajski D, 2000, P ASP DAC
   Grzegorzek M, 2013, MULTIMED TOOLS APPL, V62, P311, DOI 10.1007/s11042-012-1106-0
   Huang YS, 2011, MULTIMED TOOLS APPL, V54, P527, DOI 10.1007/s11042-010-0550-y
   Koukoulidis V, 2006, MULTIMED TOOLS APPL, V28, P203, DOI 10.1007/s11042-006-6143-0
   Kruijtzer W, P DES AUT TEST EUR
   Lennard C, 2006, P DES AUT TEST EUR
   Shengyu S, 2004, MICROELECTRON COMP
   Vijayaraghaven N, 2006, P IEEE INT TEST C
NR 13
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 9055
EP 9066
DI 10.1007/s11042-013-1598-2
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600026
DA 2024-07-18
ER

PT J
AU Kim, SH
   Chung, KY
AF Kim, Sung-Ho
   Chung, Kyung-Yong
TI Medical information service system based on human 3D anatomical model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical information service; Healthcare; Human 3D anatomy; Interactive
   diagnostic
AB Recently, due to rapid increases in the elderly population, the interest in u-healthcare for personal and social needs is increasing. In addition, extensive medical information through various media services is of interest. However, the general public often has no time to visit a medical authority for u-healthcare. The absence of a system that can be easily and quickly accessed anytime or anywhere to monitor health is a sad reality, especially in light of the rapid development of IT convergence technology. In this paper, we propose a medical information service system that monitors the human body for u-healthcare. First of all, this paper separates the human bodies of an adult male and female into a skeleton, muscle, internal organs, and skin. These four categories are then modeled using 3DS MAX. The human 3D body structures can be viewed with a 3D viewer. One of the key features of this system is the picking or selection technique. If user selects a specific part of the human body in the 3D viewer, the system provides detailed medical information about the diseases associated with the selected part. The 3D viewer has the advantage of being able to view the structure of the human body realistically and intuitively. Medical information about diseases is comprised of simple and clearly organized data concerning the causes, symptoms, treatment, prevention, recommended foods, and related medical institutions (such as hospitals) that can deal with the disease. Thus, our system can prevent diseases in advance and provide answers to many questions about disease-related symptoms.
C1 [Kim, Sung-Ho; Chung, Kyung-Yong] Sangji Univ, Sch Comp Informat Engn, Wonju 220702, Gangwon Do, South Korea.
C3 Sangji University
RP Chung, KY (corresponding author), Sangji Univ, Sch Comp Informat Engn, 83 Sangjidae Gil, Wonju 220702, Gangwon Do, South Korea.
EM kimsh1204@sangji.ac.kr; dragonhci@hanmail.net
RI Chung, Kyungyong/JAC-2276-2023
FU Basic Science Research Program through National Research Foundation of
   Korea - Ministry of Education, Science and Technology [2012-0004478]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea funded by the Ministry of
   Education, Science and Technology (No. 2012-0004478).
CR Baek SJ, 2013, WIRELESS PERS COMMUN, V73, P309, DOI 10.1007/s11277-013-1239-0
   Battulga B, 2012, INTERACT J MED RES, V1, P195, DOI 10.2196/ijmr.2172
   Chung KY, 2012, LNEE, V215, P967
   Chung KY, 2013, MULTIMED TOOLS APPL, DOI 10.1007/s00779-013-0682-y
   Chung KY, 2014, MULTIMED TOOLS APPL, V71, P843, DOI 10.1007/s11042-013-1355-6
   Jung YG, 2011, INFORMATION-TOKYO, V14, P3791
   Kang SK, 2014, PERS UBIQUIT COMPUT, V18, P515, DOI 10.1007/s00779-013-0668-9
   Kim GH, 2015, MULTIMED TOOLS APPL, V74, P8745, DOI 10.1007/s11042-013-1536-3
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P827, DOI 10.1007/s11042-012-1195-9
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P873, DOI 10.1007/s11042-011-0919-6
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P855, DOI 10.1007/s11042-011-0920-0
   Kim SH, 2014, MULTIMED TOOLS APPL, V68, P455, DOI 10.1007/s11042-013-1356-5
   Lee KD, 2013, MULTIMED TOOLS APPL, V63, P27, DOI 10.1007/s11042-012-1020-5
   Oh SY, 2014, CLUSTER COMPUT, V17, P893, DOI 10.1007/s10586-013-0284-5
   Silén C, 2008, MED TEACH, V30, pE115, DOI 10.1080/01421590801932228
   Song CW, 2014, MULTIMED TOOLS APPL, V71, P813, DOI 10.1007/s11042-013-1362-7
   Song C, 2011, INFORMATION-TOKYO, V14, P3591
   Sugand K, 2010, ANAT SCI EDUC, V3, P83, DOI 10.1002/ase.139
   Temkin B, 2006, CLIN ANAT, V19, P267, DOI 10.1002/ca.20230
   Temkin B, 2002, J AM MED INFORM ASSN, V9, P425, DOI 10.1197/jamia.M1106
NR 20
TC 37
Z9 40
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 8939
EP 8950
DI 10.1007/s11042-013-1584-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600017
DA 2024-07-18
ER

PT J
AU Omari, M
   El Hassouni, M
   Abdelouahad, AA
   Cherifi, H
AF Omari, Mounir
   El Hassouni, Mohammed
   Abdelouahad, Abdelkaher Ait
   Cherifi, Hocine
TI A statistical reduced-reference method for color image quality
   assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reduced reference image quality assessment; Steerable pyramid; Color
   spaces; Multivariate generalized Gaussian distribution; Kullback Leibler
   distance; Geodesic distance
AB Although color is a fundamental feature of human visual perception, it has been largely unexplored in the reduced-reference (RR) image quality assessment (IQA) schemes. In this paper, we propose a natural scene statistic (NSS) method, which efficiently uses this information. It is based on the statistical deviation between the steerable pyramid coefficients of the reference color image and the degraded one. We propose and analyze the multivariate generalized Gaussian distribution (MGGD) to model the underlying statistics. In order to quantify the degradation, we develop and evaluate two measures based respectively on the Geodesic distance between two MGGDs and on the closed-form of the Kullback Leibler divergence. We performed an extensive evaluation of both metrics in various color spaces (RGB, HSV, CIELAB and YCrCb) using the TID 2008 benchmark and the FRTV Phase I validation process. Experimental results demonstrate the effectiveness of the proposed framework to achieve a good consistency with human visual perception. Furthermore, the best configuration is obtained with CIELAB color space associated to KLD deviation measure.
C1 [Omari, Mounir; El Hassouni, Mohammed] Univ Mohammed 5, LRIT URAC 29, Rabat, Morocco.
   [Abdelouahad, Abdelkaher Ait] Univ Ibn Zohr, Agadir, Morocco.
   [Cherifi, Hocine] Univ Burgundy, Lab Elect Informat & Image Le2i, UMR 6306, CNRS, Dijon, France.
C3 Mohammed V University in Rabat; Ibn Zohr University of Agadir; Centre
   National de la Recherche Scientifique (CNRS); Universite de Bourgogne
RP El Hassouni, M (corresponding author), Univ Mohammed 5, LRIT URAC 29, Rabat, Morocco.
EM mouniro870@gmail.com; Mohamed.elhassouni@gmail.com;
   a.abdelkaher@gmail.com; hocine.cherifi@u-bourgogne.fr
RI El Hassouni, Mohammed/AAL-8452-2020; Cherifi, Hocine/X-9376-2019
OI El Hassouni, Mohammed/0000-0002-6741-4799; Cherifi,
   Hocine/0000-0001-9124-4921
FU  [CNRS-CNRST STIC 02/2014]
FX This work has been supported by the project CNRS-CNRST STIC 02/2014.
CR Abramowitz M., 1964, HDB MATH FUNCTIONS, Vfifth
   [Anonymous], 2004, CIE PUBLICATION
   [Anonymous], 1990, MONOGRAPHS STAT APPL
   Color Science, 1982, CONCEPTS METHODS QUA
   Decherchi S, 2013, NEUROCOMPUTING, V102, P78, DOI 10.1016/j.neucom.2011.12.050
   He LH, 2012, LECT NOTES COMPUT SC, V7664, P401, DOI 10.1007/978-3-642-34481-7_49
   Li Q, 2009, IEEE J-STSP, V3, P202, DOI 10.1109/JSTSP.2009.2014497
   Omari M, 2013, COLOR IMAGE QUALITY, P195
   Ponomarenko N., 2008, INT WORKSH MULT SIGN
   Redi JA, 2010, IEEE T CIRC SYST VID, V20, P1757, DOI 10.1109/TCSVT.2010.2087456
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725
   Soundararajan R, 2012, IEEE T IMAGE PROCESS, V21, P517, DOI 10.1109/TIP.2011.2166082
   Verdoolaege G, 2011, INT J COMPUT VISION, V95, P265, DOI 10.1007/s11263-011-0448-9
   Verdoolaege G, 2009, IEEE IMAGE PROC, P265, DOI 10.1109/ICIP.2009.5413405
   Wang Z, 2005, PROC SPIE, V5666, P149, DOI 10.1117/12.597306
   Wang Z, 2006, IEEE T IMAGE PROCESS, V15, P1680, DOI 10.1109/TIP.2005.864165
NR 17
TC 9
Z9 10
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8685
EP 8701
DI 10.1007/s11042-014-2353-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600028
DA 2024-07-18
ER

PT J
AU Park, DK
   Jung, EY
   Lee, SH
   Lim, JS
AF Park, Dong Kyun
   Jung, Eun-Young
   Lee, Sang-Hong
   Lim, Joon S.
TI A composite gene selection for DNA microarray data analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised gene selection; Supervised gene selection; TNoM score;
   Microarray; Neural network; Non-overlap area distribution measurement
ID NEURAL-NETWORK; MUTUAL INFORMATION; CLASSIFICATION; CANCER
AB An important aspect in microarray data analysis is the selection of an appropriate number of the most relevant genes among a large population of genes. In this study, we have proposed a composite gene selection using both unsupervised and supervised gene selections. In the unsupervised gene selection, we used the threshold number of misclassification (TNoM) score to select an appropriate number of the top-ranked genes for microarray data analysis. In the supervised gene selection, the minimum number of genes showing the highest accuracy is obtained using the non-overlap area distribution measurement (NADM) method provided by the neural network with weighted fuzzy membership functions (NEWFM) from the top-ranked genes. In this study, from a colon cancer dataset and a leukemia dataset, we selected the top-ranked 93 colon cancer and 143 leukemia genes with a parts per thousand currency sign14 (colon cancer) and a parts per thousand currency sign13 (leukemia) TNoM scores from a total of 2000 colon cancer and 7129 leukemia genes. By the NADM method, a minimum of 4 colon cancer and 13 leukemia genes were selected from the top-ranked 93 colon cancer and 143 leukemia genes. When the minimal 4 colon cancer and 13 leukemia genes were used as inputs for the NEWFM, the performance accuracies were 98.39 % and 100 % for colon cancer and leukemia, respectively.
C1 [Park, Dong Kyun; Jung, Eun-Young] Gachon Univ, Gil Med Ctr, Inchon, South Korea.
   [Lee, Sang-Hong] Anyang Univ, Dept Comp Sci & Engn, Anyang, South Korea.
   [Lim, Joon S.] Gachon Univ, IT Coll, Songnam, South Korea.
C3 Gachon University; Anyang University; Gachon University
RP Lim, JS (corresponding author), Gachon Univ, IT Coll, Songnam, South Korea.
EM pdk66@gilhospital.com; eyjung@gilhospital.com; shleedosa@anyang.ac.kr;
   jslim71@ymail.com
RI Lim, Joon Seok/R-7753-2019
FU Basic Science Research Program through National Research Foundation of
   Korea (NRF) - Ministry of Education, Science and Technology
   [2012R1A1A2044134]; Korean Health Technology R&D Project, Ministry of
   Health & Welfare, Republic of Korea [A112020]
FX "This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology. (2012R1A1A2044134)"; "This study
   was supported by a grant of the Korean Health Technology R&D Project,
   Ministry of Health & Welfare, Republic of Korea. (A112020)"
CR Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745
   Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943
   Cho JH, 2004, FEBS LETT, V571, P93, DOI 10.1016/j.febslet.2004.05.087
   Frank O, 2006, LEUKEMIA, V20, P1400, DOI 10.1038/sj.leu.2404270
   Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Hong Y, 2008, PATTERN RECOGN, V41, P2742, DOI 10.1016/j.patcog.2008.03.007
   Hopfgartner F, 2010, MULTIMED TOOLS APPL, V47, P631, DOI 10.1007/s11042-009-0340-6
   Huang HL, 2007, BIOSYSTEMS, V90, P516, DOI 10.1016/j.biosystems.2006.12.003
   Kabir MM, 2011, NEUROCOMPUTING, V74, P2914, DOI 10.1016/j.neucom.2011.03.034
   Krishnamoorthy P, 2011, MULTIMED TOOLS APPL, V54, P415, DOI 10.1007/s11042-010-0546-7
   Lee CP, 2011, APPL SOFT COMPUT, V11, P208, DOI 10.1016/j.asoc.2009.11.010
   Lee SH, 2013, MEASUREMENT, V46, P1995, DOI 10.1016/j.measurement.2013.02.014
   Lee SH, 2012, EXPERT SYST APPL, V39, P7338, DOI 10.1016/j.eswa.2012.01.084
   Lee SH, 2011, EXPERT SYST APPL, V38, P4259, DOI 10.1016/j.eswa.2010.09.093
   Li JX, 2007, IEEE T INF TECHNOL B, V11, P398, DOI 10.1109/TITB.2007.892693
   Li L, 2011, COMB CHEM HIGH T SCR, V4, P727
   Lim JS, 2009, IEEE T NEURAL NETWOR, V20, P522, DOI 10.1109/TNN.2008.2012031
   Liu X., 2005, BMC BIOINFORMATICS, V6, P1
   Maji P, 2011, INT J APPROX REASON, V52, P408, DOI 10.1016/j.ijar.2010.09.006
   Sotoca JM, 2010, PATTERN RECOGN, V43, P2068, DOI 10.1016/j.patcog.2009.12.013
   Mejdoub M, 2013, MULTIMED TOOLS APPL, V64, P197, DOI 10.1007/s11042-011-0900-4
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Tapia E, 2012, PATTERN RECOGN LETT, V33, P164, DOI 10.1016/j.patrec.2011.09.031
   Wang L, 2006, MULTIMED TOOLS APPL, V29, P55, DOI 10.1007/s11042-006-7813-7
   Wang SG, 2011, EXPERT SYST APPL, V38, P8696, DOI 10.1016/j.eswa.2011.01.077
   Wang YH, 2005, BIOINFORMATICS, V21, P1530, DOI 10.1093/bioinformatics/bti192
   Zhou X, 2007, BIOINFORMATICS, V23, P1106, DOI 10.1093/bioinformatics/btm036
NR 28
TC 8
Z9 8
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 9031
EP 9041
DI 10.1007/s11042-013-1583-9
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600024
DA 2024-07-18
ER

PT J
AU Shin, DK
   Jung, H
   Lee, KD
   Lee, JH
   Park, RC
AF Shin, Dong-Kun
   Jung, Hoill
   Lee, Kang-Dae
   Lee, Jung-Hyun
   Park, Roy C.
TI Performance improvement of intelligent u-Port system using metallic
   object applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE u-City; u-Port; UHF antenna; Metallic object; Impedance bandwidth;
   Multiple meander
AB The term u-City implies a next generation information city with innovative general functions that improve the convenience and quality of city life, guarantee safety and welfare through systematic city management, and create new businesses by combining advanced information communication infrastructures and ubiquitous information services with urban spaces. A u-City constitutes a pleasant city life for urban residents as well as effective city management for city managers. u-Port businesses, which represent an ubiquitous port in which all facilities related to port operations share information without any limitations through networks, have recently been highlighted. In particular, u-Port businesses use a specific ubiquitous technology to manage containers that has been recognized as a new scale for managing port logistics. However, as conventional technology is based on sensors, which represents a disadvantage in terms of initial and maintenance costs, studies on RFID-based technologies have largely been conducted. As conductive substances such as an aluminum can, metal box, or cigarette foil packet can improve both antenna directivity as well as have great effects upon antenna performance parameters such as resonant frequencies and radiant efficiency, it is difficult to build on RFID system. Under these circumstances, implementation of a tag antenna without deterioration has become an important task. In this paper, we assess the performance of a metallic object application in an intelligent u-Port system. In the proposed design, the antenna structure consists of square-shaped power feeder connected to the body for coordination with an attached common-use tag chip, whereas the patch device is manufactured in the form of multiple meanders to efficiently scale back the size of the antenna body. The characteristics of bandwidth, efficiency, and recognition distance were compared and analyzed based on the size of the proposed antenna and the number of folds. It was found that the efficiency and gain characteristics change according to the size of the antenna, and the number of folds in the form of meanders have a significant influence over recognition distance of the antenna.
C1 [Shin, Dong-Kun] Sahmyook Univ, Div Comp, Seoul 139742, South Korea.
   [Jung, Hoill] Sangji Univ, Sch Comp Informat Engn, Wonju 220702, Gangwon Do, South Korea.
   [Lee, Kang-Dae] Yonsei Univ, Dept Packaging, Wonju, Kangwon Do, South Korea.
   [Lee, Jung-Hyun] Inha Univ, Dept Comp & Informat Engn, Inchon 402751, South Korea.
   [Park, Roy C.] Samsun Technol Res Co Ltd, Samsun Co Affiliated Res, Bucheon Si 420772, Gyeonggi Do, South Korea.
C3 Sahmyook University; Sangji University; Yonsei University; Inha
   University
RP Park, RC (corresponding author), Samsun Technol Res Co Ltd, Samsun Co Affiliated Res, 564-6 Sang Dong, Bucheon Si 420772, Gyeonggi Do, South Korea.
EM dkshin@syu.ac.kr; hijung1982@gmail.com; pimeson@yonsei.ac.kr;
   jhlee@inha.ac.kr; roypark.asap@gmail.com
FU Sahmyook University
FX This paper was supported by the Sahmyook University Research Fund in
   2013.
CR Ahn J, 2007, SERA 2007: 5TH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT, AND APPLICATIONS, PROCEEDINGS, P264, DOI 10.1109/SERA.2007.1
   Ahn S.-J., 2009, POWER ENERGY SOC GEN, P1
   Anthopoulos Leonidas, 2010, 2010 6th International Conference on Intelligent Environments (IE), P301, DOI 10.1109/IE.2010.61
   Baek SJ, 2013, WIRELESS PERS COMMUN, V73, P309, DOI 10.1007/s11277-013-1239-0
   Chung KY, 2014, PERS UBIQUIT COMPUT, V18, P489, DOI 10.1007/s00779-013-0682-y
   Fillbrandt H, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P181
   Hyun Kyu Park, 2011, Proceedings of the 2011 13th International Conference on Advanced Communication Technology (ICACT). Smart Service Innovation through Mobile Interactivity, P855
   Jung YG, 2011, INFORMATION-TOKYO, V14, P3791
   Kang SK, 2014, PERS UBIQUIT COMPUT, V18, P515, DOI 10.1007/s00779-013-0668-9
   Kim GH, 2015, MULTIMED TOOLS APPL, V74, P8745, DOI 10.1007/s11042-013-1536-3
   Kim JY, 2014, MULTIMED TOOLS APPL, V68, P465, DOI 10.1007/s11042-013-1357-4
   Kim J, 2010, WISEC 10: PROCEEDINGS ON THE THIRD ACM CONFERENCE ON WIRELESS NETWORK SECURITY, P1
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P827, DOI 10.1007/s11042-012-1195-9
   Lai M, 2010, P IEEE ANT PROP SOC, V1, P1, DOI DOI 10.1111/J.1468-2273.2009.00432.X
   Oh SY, 2014, CLUSTER COMPUT, V17, P893, DOI 10.1007/s10586-013-0284-5
   Oh SY, 2015, MULTIMED TOOLS APPL, V74, P8781, DOI 10.1007/s11042-013-1514-9
   Park C, 2012, P INT C IT CONV SEC, P613
   Park CH, 2012, LNEE, V1, P325
   Park D., 2006, International Symposium on VLSI Technology, Systems, and Applications, P1
   Park H, 2011, PROC INT C TOOLS ART, P965, DOI 10.1109/ICTAI.2011.166
   Park RC, 2014, PERS UBIQUIT COMPUT, V18, P543, DOI 10.1007/s00779-013-0674-y
   Park W, 2007, PORTL INT CONF MANAG, P1141, DOI 10.1109/PICMET.2007.4349437
   Raumonen P., 2003, IEEE Antennas and Propagation Society International Symposium. Digest. Held in conjunction with: USNC/CNC/URSI North American Radio Sci. Meeting (Cat. No.03CH37450), P848
   Sangchul Jung, 2007, 2007 International Conference on Convergence Information Technology - ICCIT '07, P487
   Shin DK, 2015, MULTIMED TOOLS APPL, V74, P9043, DOI 10.1007/s11042-013-1539-0
   Shin S, 2013, INT CONF ADV COMMUN, P1020
   Ukkonen L, 2004, IEEE ANTENNAS AND PROPAGATION SOCIETY SYMPOSIUM, VOLS 1-4 2004, DIGEST, P101, DOI 10.1109/APS.2004.1329563
   Wu NC, 2009, P 4 INT C UB INF TEC, V1, P1
   Yoon WJ, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P106, DOI 10.1109/ICACT.2007.358315
NR 29
TC 2
Z9 2
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 8879
EP 8892
DI 10.1007/s11042-013-1599-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600012
DA 2024-07-18
ER

PT J
AU Choe, GM
   Wang, TJ
   Liu, F
   Choe, CH
   Jong, MH
AF Choe, Gwangmin
   Wang, Tianjiang
   Liu, Fang
   Choe, Chunhwa
   Jong, Manhung
TI An advanced association of particle filtering and kernel based object
   tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Similarity measure; Visual tracking; Particle filtering; Kernel based
   object tracking; Matrix condition number
AB The association approaches of particle filter (PF) and kernel based object tracking (KBOT) are widely used in visual tracking. Specially, a compact association approach is proposed, which is based on an incremental Bhattacharyya dissimilarity (IBD) and condition number. It is advanced approach, but this paper found that it cannot guarantee the stable tracking and the high accuracy of tracking in any cases. To solve these problems, we first introduces an asymmetric incremental Bhattacharyya similarity (AIBS) instead of IBD. AIBS is defined by incorporating an asymmetric incremental similarity matrix (AISM) and enables to ensure the stability of tracking. Then, we propose a boosting-refining approach, which is boosting the particles positioned at the ill-posed condition instead of eliminating the ill-posed particles to refine the particles. It enables the estimation of the object stare to obtatin high accuracy. Also, We propose also the resampling-refining algorithm to advance the performance of the framework based on the association of PF and KBOT. Finally, we test the stability and the accuracy of the association approaches that we proposed in this paper, on a synthesized image sequence and several real image sequences. Experimental results demonstrate that our approaches have the promising discriminative capability in comparison with other ones.
C1 [Choe, Gwangmin; Wang, Tianjiang; Liu, Fang] Huazhong Univ Sci & Technol, Intelligent & Distributed Comp Lab, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Choe, Chunhwa; Jong, Manhung] Kim Il Sung Univ, Visual Informat Proc Lab, Sch Comp Sci & Technol, Pyongyang, South Korea.
C3 Huazhong University of Science & Technology
RP Choe, GM (corresponding author), Huazhong Univ Sci & Technol, Intelligent & Distributed Comp Lab, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM cca2005@foxmail.com; tjwang@hust.edu.cn; Fang.Liu@hust.edu.cn
CR Bai KJ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P431, DOI 10.1109/ICAL.2007.4338601
   Birchfield ST, 2005, PROC CVPR IEEE, P1158
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Fan Z., 2006, IEEE C COMPUTER VISI, P658, DOI DOI 10.1109/CVPR.2006.109
   Gao CC, 2011, CHINESE J AERONAUT, V24, P622, DOI 10.1016/S1000-9361(11)60073-3
   Han B, 2004, PROC CVPR IEEE, P638
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jia JP, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3793
   KHAN ZH, 2009, IEEE INT C IM PROC I, P4077
   Khan ZH, 2011, IEEE T CIRC SYST VID, V21, P74, DOI 10.1109/TCSVT.2011.2106253
   Le P. N., 2009, P ICICS, P1
   Liu H, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P605
   MAGGIO E, 2005, P IEEE SIGN PROC SOC
   Shan CF, 2007, PATTERN RECOGN, V40, P1958, DOI 10.1016/j.patcog.2006.12.012
   Wang HZ, 2007, IEEE T PATTERN ANAL, V29, P1661, DOI [10.1109/TPAMI.2007.1112, 10.1109/TPAMl.2007.1112]
   Wang HL, 2009, PROCEEDINGS OF 2009 2ND IEEE INTERNATIONAL CONFERENCE ON BROADBAND NETWORK & MULTIMEDIA TECHNOLOGY, P550, DOI 10.1109/ICBNMT.2009.5347857
   Wang J, 2011, 4 INT C MACH VIS ICM
   Wang XS, 2006, OPT PHOTONICS NEWS, V17, P27, DOI 10.1364/OPN.17.12.000027
   Xu F, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P2252, DOI 10.1109/ICAL.2008.4636540
   Yang C, 2005, P IEEE COMP SOC C CO, V2, P1158
   Yang W, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING WORKSHOP PROCEEDINGS, VOLS 1 AND 2, P761, DOI 10.1109/KAMW.2008.4810602
   Yao AB, 2012, PATTERN RECOGN, V45, P2584, DOI 10.1016/j.patcog.2012.01.016
   Yao AB, 2010, PATTERN RECOGN, V43, P1244, DOI 10.1016/j.patcog.2009.09.024
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 24
TC 5
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7595
EP 7619
DI 10.1007/s11042-014-1993-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200009
DA 2024-07-18
ER

PT J
AU Erdem, CE
   Turan, C
   Aydin, Z
AF Erdem, Cigdem Eroglu
   Turan, Cigdem
   Aydin, Zafer
TI BAUM-2: a multilingual audio-visual affective face database
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Affective database; Audio-visual
   affective database
ID FACIAL EXPRESSIONS; TEXTURE CLASSIFICATION; EMOTION; RECOGNITION; MODEL
AB Access to audio-visual databases, which contain enough variety and are richly annotated is essential to assess the performance of algorithms in affective computing applications, which require emotion recognition from face and/or speech data. Most databases available today have been recorded under tightly controlled environments, are mostly acted and do not contain speech data. We first present a semi-automatic method that can extract audio-visual facial video clips from movies and TV programs in any language. The method is based on automatic detection and tracking of faces in a movie until the face is occluded or a scene cut occurs. We also created a video-based database, named as BAUM-2, which consists of annotated audio-visual facial clips in several languages. The collected clips simulate real-world conditions by containing various head poses, illumination conditions, accessories, temporary occlusions and subjects with a wide range of ages. The proposed semi-automatic affective clip extraction method can easily be used to extend the database to contain clips in other languages. We also created an image based facial expression database from the peak frames of the video clips, which is named as BAUM-2i. Baseline image and video-based facial expression recognition results using state-of-the art features and classifiers indicate that facial expression recognition under tough and close-to-natural conditions is quite challenging.
C1 [Erdem, Cigdem Eroglu; Turan, Cigdem; Aydin, Zafer] Bahcesehir Univ, Dept Elect & Elect Engn, TR-34349 Istanbul, Turkey.
C3 Bahcesehir University
RP Erdem, CE (corresponding author), Bahcesehir Univ, Dept Elect & Elect Engn, TR-34349 Istanbul, Turkey.
EM cigdem.eroglu@bahcesehir.edu.tr; cigdem.turan@connect.polyu.hk;
   zafer.aydin@agu.edu.tr
RI Turan, Cemal/Q-7638-2019; Eroglu Erdem, Cigdem/Z-4276-2019
OI Turan, Cemal/0000-0001-9584-0261; Eroglu Erdem,
   Cigdem/0000-0002-9264-5652; Turan-Schwiewager,
   Cigdem/0000-0002-4836-6023
FU Turkish Scientific and Technical Research Council (TUBITAK) [110E056]
FX This work was supported by the Turkish Scientific and Technical Research
   Council (TUBITAK) under project 110E056.
CR [Anonymous], 1 COST 2101 WORKSH B
   [Anonymous], 2011, FG 2011 FAC EXPR REC
   [Anonymous], 2010, INTRO GENEVA MULTIMO, DOI 10.1037/a0025827
   Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007
   BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Bozkurt E, 2011, SPEECH COMMUN, V53, P1186, DOI 10.1016/j.specom.2011.04.003
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cootes T., 1992, PROC BR MACHINE VISI, P266
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhall A., 2011, P WORKSH FAC EXPR RE
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Douglas-Cowie E., 2000, PROC ISCA ITRW SPEEC, P39
   Ekman P., 1976, PICTURES FACIAL EFFE
   Erdem CE, 2011, INT CONF ACOUST SPEE, P1497, DOI 10.1109/ICASSP.2011.5946777
   Fanelli G, 2010, IEEE T MULTIMEDIA, V12, P591, DOI 10.1109/TMM.2010.2052239
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Grimm M, 2008, P INT C MULT EXP ICM
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Gunes Hatice, 2010, International Journal of Strategic Synthetic Emotions, V1, P68, DOI 10.4018/jse.2010101605
   Hupont I, 2013, PATTERN ANAL APPL, V16, P41, DOI 10.1007/s10044-012-0286-6
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Li Z, 2009, P IEEE INT C SYST MA
   Littlewort G., 2011, IEEE C AUT FAC GEST
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Littlewort GC, 2009, IMAGE VISION COMPUT, V27, P1797, DOI 10.1016/j.imavis.2008.12.010
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Machine vision group, MATLAB COD LOC PHAS
   Martinez A, 2012, J MACH LEARN RES, V13, P1589
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   O'Toole AJ, 2005, IEEE T PATTERN ANAL, V27, P812, DOI 10.1109/TPAMI.2005.90
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pantic M, 2009, PHILOS T R SOC B, V364, P3505, DOI 10.1098/rstb.2009.0135
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Ryan Andrew, 2009, 2009 IEEE 43rd International Carnahan Conference on Security Technology. ICCST 2009, P172, DOI 10.1109/CCST.2009.5335546
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Savran A, 2012, PATTERN RECOGN, V45, P767, DOI 10.1016/j.patcog.2011.07.022
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Turan C, 2013, BAHCESEHIR U MULTIMO
   Ulukaya S, 2012, INT CONF ACOUST SPEE, P1385, DOI 10.1109/ICASSP.2012.6288149
   Valstar M.F., 2011, IEEE INT C FAC GEST
   Viera AJ, 2005, FAM MED, V37, P360
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wallhoff F., 2006, Facial Expressions and Emotion Database
   Watkins M.W., 2000, J BEHAV EDUC, V10, P205, DOI DOI 10.1023/A:1012295615144
   Whissell C, EMOTION THEORY RES E, V4
   Yang SF, 2012, IEEE T SYST MAN CY B, V42, P980, DOI 10.1109/TSMCB.2012.2192269
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang X., 2013, INT C AUT FAC GEST R
   Zhang Z, 2012, P INTERSPEECH PORTL
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 59
TC 27
Z9 30
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7429
EP 7459
DI 10.1007/s11042-014-1986-2
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200002
DA 2024-07-18
ER

PT J
AU Wu, XM
   Kashino, K
AF Wu, Xiaomeng
   Kashino, Kunio
TI Interest point selection by topology coherence for multi-query image
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interest point selection; Spatial topology; Delaunay triangulation;
   Multi-query image retrieval
ID SCALE
AB Although the bag-of-visual-words (BOVW) model in computer vision has been demonstrated successfully for the retrieval of particular objects, it suffers from limited accuracy when images of the same object are very different in terms of viewpoint or scale. Naively leveraging multiple views of the same object to query the database naturally alleviates this problem to some extent. However, the bottleneck appears to be the presence of background clutter, which causes significant confusion with images of different objects. To address this issue, we explore the structural organization of interest points within multiple query images and select those that derive from the tentative region of interest (ROI) to significantly reduce the negative contributions of confusing images. Specifically, we propose the use of a multi-layered undirected graph model built on sets of Hessian affine interest points to model the images' elastic spatial topology. We detect repeating patterns that preserve a coherent local topology, show how these redundancies are leveraged to estimate tentative ROIs, and demonstrate how this novel interest point selection approach improves the quality of visual matching. The approach is discriminative in distinguishing clutter from interest points, and at the same time, is highly robust as regards variation in viewpoint and scale as well as errors in interest point detection and description. Large-scale datasets are used for extensive experimentation and discussion.
C1 [Wu, Xiaomeng; Kashino, Kunio] NTT Commun Sci Labs, Atsugi, Kanagawa 2430198, Japan.
C3 Nippon Telegraph & Telephone Corporation
RP Wu, XM (corresponding author), NTT Commun Sci Labs, 3-1 Morinosato Wakamiya, Atsugi, Kanagawa 2430198, Japan.
EM wu.xiaomeng@lab.ntt.co.jp; kashino.kunio@lab.ntt.co.jp
CR [Anonymous], 2007, CVPR
   [Anonymous], 2007, CVPR
   [Anonymous], 2012, P 20 ACM INT C MULTI
   [Anonymous], 2012, P TRECVID 2012 NIST
   [Anonymous], 2008, CVPR
   Arandjelovic R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.92
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Berg M., 2008, COMPUTATIONAL GEOMET, V3rd, DOI DOI 10.1007/978-3-540-77974-2
   Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   Gammeter S, 2009, IEEE I CONF COMP VIS, P614, DOI 10.1109/ICCV.2009.5459180
   Heller K.A., 2006, IEEE Conference on Computer Vision and Pattern Recognition, V2, P2110
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Kalantidis Y, 2011, P 1 ACM INT C MULT R, P20
   Knopp J, 2010, LECT NOTES COMPUT SC, V6311, P748, DOI 10.1007/978-3-642-15549-9_54
   Li FY, 2006, IEEE INT CONF ROBOT, P3405, DOI 10.1109/ROBOT.2006.1642222
   Liu Z., 2012, P ACM INT C MULTIMED, P199
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Poullot S, 2010, MULTIMED TOOLS APPL, V47, P279, DOI 10.1007/s11042-009-0323-7
   Romberg S., 2011, P 1 ACM INT C MULT R, P1
   Romberg S, 2013, INT J MULTIMED INF R, V2, P243, DOI 10.1007/s13735-013-0040-x
   Shewchuk J. R., 1996, Applied Computational Geometry. Towards Geometric Engineering. FCRC'96 Workshop, WACG'96. Selected Papers, P203, DOI 10.1007/BFb0014497
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56
   Wang SY, 2012, NEUROCOMPUTING, V95, P117, DOI 10.1016/j.neucom.2011.05.043
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294
   WELZL E, 1997, COMP GEOM-THEOR APPL, V7, P361
   Wu Z, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPRW.2009.5206566
   Yang Y, 2011, IEEE I CONF COMP VIS, P1465, DOI 10.1109/ICCV.2011.6126403
   Zhang YM, 2011, PROC CVPR IEEE, P809, DOI 10.1109/CVPR.2011.5995528
   Zhu C., 2012, INT C MULT RETR ICMR, P52, DOI DOI 10.1145/2324796.2324856
NR 36
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 7147
EP 7180
DI 10.1007/s11042-014-1957-7
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800026
DA 2024-07-18
ER

PT J
AU Yang, F
   Yang, F
   Li, XL
   Tian, J
AF Yang, Fei
   Yang, Feng
   Li, Xiuli
   Tian, Jie
TI Ray feature analysis for volume rendering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Direct volume rendering; Classification; Ray feature analysis; Localized
   transfer function; Threshold based state transition
ID EXPLORATION
AB A major difficulty of volume rendering has been the recognition of different semantic regions which is crucial for the appropriate assignment of optical properties. Such difficulty arises from the fact that different semantic regions may share the same input value ranges. In this paper, we introduce the concept of ray-feature analysis and propose an on-the-fly state transition framework for the recognition of different semantic regions during volume rendering without the need of explicit segmentation information. In this framework, we consider the value along the path of a ray as a 1D-signal, and by making use of the feature analysis of these 1D-signals, semantic information of the current ray sample is extracted. To define the condition of state transition, we propose a method called "threshold based state transition". Since the parameters of the threshold based state transition method is not intuitive, an automatic learning method which enables an interactive user labeling routine is proposed. Experimental results show that our proposed framework is cost effective for on-the-fly semantic region recognition, and is especially suitable for closed, mostly convex, multi-layered objects.
C1 [Yang, Feng] Beijing JiaoTong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
   [Yang, Fei; Li, Xiuli; Tian, Jie] Chinese Acad Sci, Inst Automat, Key Lab Mol Imaging, Beijing 100190, Peoples R China.
C3 Beijing Jiaotong University; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Yang, F (corresponding author), Beijing JiaoTong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
EM fei.yang@ia.ac.cn; fengyang@bjtu.edu.cn; xiuli.li@ia.ac.cn
RI Yang, Feng/HLQ-2152-2023; Tian, Jie/H-1190-2011; yang, fei/HPF-9658-2023
OI Yang, Feng/0000-0002-8334-7450; Tian, Jie/0000-0003-0498-0432; RAMLI,
   ZARINA/0009-0007-1729-7057
FU National Basic Research Program of China (973 Program) [2011CB707700];
   National Natural Science Foundation of China [81227901, 61231004];
   Chinese Academy of Sciences Fellowship for Young International
   Scientists [2013Y1GB0005]; National High Technology Research and
   Development Program of China (863 Program) [2012AA021105]; Guangdong
   Province-Chinese Academy of Sciences comprehensive strategic cooperation
   program [2010A090100032, 2012B090400039]; NSFC-NIH Biomedical
   collaborative research program [81261120414]; Beijing Natural Science
   Foundation [4132080]; Fundamental Research Funds for the Central
   Universities [2013JBZ014]; National Basic Research Program [61301002,
   61302025]
FX This paper is supported by the National Basic Research Program of China
   (973 Program) under Grant 2011CB707700, the National Natural Science
   Foundation of China under Grant No. 81227901, 61231004, the Chinese
   Academy of Sciences Fellowship for Young International Scientists under
   Grant 2013Y1GB0005, the National High Technology Research and
   Development Program of China (863 Program) under 2012AA021105, the
   Guangdong Province-Chinese Academy of Sciences comprehensive strategic
   cooperation program under 2010A090100032 and 2012B090400039, the
   NSFC-NIH Biomedical collaborative research program under 81261120414,
   the Beijing Natural Science Foundation under Grant No. 4132080, the
   Fundamental Research Funds for the Central Universities under Grant No.
   2013JBZ014, the National Basic Research Program der Grant No. 61301002
   and No. 61302025.
CR Beyer J, 2007, IEEE T VIS COMPUT GR, V13, P1696, DOI 10.1109/TVCG.2007.70560
   Bruckner S, 2006, IEEE T VIS COMPUT GR, V12, P1559, DOI 10.1109/TVCG.2006.96
   Caban JJ, 2008, IEEE T VIS COMPUT GR, V14, P1364, DOI 10.1109/TVCG.2008.169
   Correa CD, 2008, IEEE T VIS COMPUT GR, V14, P1380, DOI 10.1109/TVCG.2008.162
   Correa CD, 2006, IEEE T VIS COMPUT GR, V12, P1069, DOI 10.1109/TVCG.2006.144
   Correa CarlosD., 2006, Fifth Eurographics / IEEE VGTC Workshop on Volume Graphics, P9, DOI DOI 10.2312/VG/VG06/009-016
   Hadwiger M, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P301, DOI 10.1109/VISUAL.2003.1250386
   Haidacher M, 2010, IEEE PAC VIS SYMP, P17, DOI 10.1109/PACIFICVIS.2010.5429615
   Hauser H, 2001, IEEE T VIS COMPUT GR, V7, P242, DOI 10.1109/2945.942692
   Kindlmann G, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P513, DOI 10.1109/VISUAL.2003.1250414
   Kindlmann G, 1998, IEEE SYMPOSIUM ON VOLUME VISUALIZATION, P79, DOI 10.1109/SVV.1998.729588
   Kniss J, 2002, IEEE T VIS COMPUT GR, V8, P270, DOI 10.1109/TVCG.2002.1021579
   Krüger J, 2006, IEEE T VIS COMPUT GR, V12, P941, DOI 10.1109/TVCG.2006.124
   Läthén G, 2012, IEEE T VIS COMPUT GR, V18, P2345, DOI 10.1109/TVCG.2012.203
   Nagy Z, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P429, DOI 10.1109/PCCGA.2003.1238289
   Patel D, 2009, IEEE PAC VIS SYMP, P201, DOI 10.1109/PACIFICVIS.2009.4906857
   Prassni JS, 2010, IEEE PAC VIS SYMP, P9, DOI 10.1109/PACIFICVIS.2010.5429624
   Rezk-Salama C, 2006, COMPUT GRAPH FORUM, V25, P597, DOI 10.1111/j.1467-8659.2006.00979.x
   Takahashi S, 2004, GRAPH MODELS, V66, P24, DOI 10.1016/j.gmod.2003.08.002
   Tappenbeck Andreas., 2006, SimVis, P259
   Viola I, 2005, IEEE T VIS COMPUT GR, V11, P408, DOI 10.1109/TVCG.2005.62
   Wang LJ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P367
   Wu YC, 2007, IEEE T VIS COMPUT GR, V13, P1027, DOI 10.1109/TVCG.2007.1051
   Xiang DH, 2011, IEEE T VIS COMPUT GR, V17, P1295, DOI 10.1109/TVCG.2010.239
   Yang F, 2012, IEEE T VIS COMPUT GR, V18, P925, DOI 10.1109/TVCG.2011.113
   Zhou JL, 2009, IEEE T VIS COMPUT GR, V15, P1481, DOI 10.1109/TVCG.2009.120
NR 26
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7621
EP 7641
DI 10.1007/s11042-014-1994-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200010
DA 2024-07-18
ER

PT J
AU Lee, D
   Chang, SW
   Lee, SS
AF Lee, Donggeun
   Chang, Sang-woo
   Lee, Sang-sun
TI Analysis and design on efficient message relay methods in VANET
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Broadcast protocol; Vehicle-to-vehicle communication; V2V; Vehicular ad
   hoc networks; VANET; message relay
ID SIMULATION
AB The aim of this paper is to analyze efficient message relay methods in vehicular ad hoc networks (VANETs). Safety applications installed in vehicles aim to send a warning message to all reachable network vehicles as soon as possible. There are several broadcast methods for disseminating messages. We implement each broadcast method and compare methods. We evaluate the reliability and performance of our distance based priority broadcast method for VANETs environment on a highway simulation. This analysis allows us to study the impact of vehicle density and of multi hop forwarding. The proposed method can stably spread the messages in high density vehicular networks. Furthermore, we can con-firm only 1.8 %, the percentage of forwarded packets by the simulation results.
C1 [Lee, Donggeun; Chang, Sang-woo; Lee, Sang-sun] Hanyang Univ, Dept Elect Engn, Seoul, South Korea.
C3 Hanyang University
RP Lee, SS (corresponding author), Hanyang Univ, Dept Elect Engn, 222 Wangsimni Ro, Seoul, South Korea.
EM leedg81@hanyang.ac.kr; inthewood78@naver.com; ssnlee@hanyang.ac.kr
FU Construction Technology Innovation Program (CTIP) - Minis-try of Land,
   Transportation and Maritime Affairs (MLTM) of Korean government (SMART
   Highway Project (07 Technology Innovation A01)); Brain Korea 21 Plus
   Project
FX This research was supported by a grant from Construction Technology
   Innovation Program (CTIP) funded by Minis-try of Land, Transportation
   and Maritime Affairs (MLTM) of Korean government (SMART Highway Project
   (07 Technology Innovation A01)). This work was supported by the Brain
   Korea 21 Plus Project in 2014.
CR Alam M, 2009, INT CONF EMERG TECHN, P452, DOI 10.1109/ICET.2009.5353127
   [Anonymous], 2000, P ACM IEEE INT C MOB
   [Anonymous], 2010, P80211P IEEE
   Briesemeister L, 2000, P IEEE INT VEH S DEA
   Chang SW, 2013, 3 INT C IT CONV SEC
   Chegin M, 2008, 5 INT C INF TECHN NE
   Chen Q, 2007, ACM S MODEL ANAL SIM, P159
   Ching-Yi Yang, 2010, Proceedings of the 2010 IEEE 24th International Conference on Advanced Information Networking and Applications Workshops (WAINA 2010), P323, DOI 10.1109/WAINA.2010.31
   Lee DG, 2013, 3 INT C IT CONV SEC
   Tonguz O.K., 2006, Broadband Communications, Networks and Systems, P1
   Williams B., 2002, MOBIHOC 2002. Proceedings of the Third ACM International Symposium on Mobile Ad Hoc Networking and Computing, P194, DOI 10.1145/513800.513825
NR 11
TC 4
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6331
EP 6340
DI 10.1007/s11042-014-2107-y
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700014
DA 2024-07-18
ER

PT J
AU Qin, C
   Chang, CC
   Hsu, TJ
AF Qin, Chuan
   Chang, Chin-Chen
   Hsu, Tai-Jung
TI Reversible data hiding scheme based on exploiting modification direction
   with two steganographic images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Exploiting modification direction; Hiding
   capacity; Image quality
ID DIFFERENCE EXPANSION; WATERMARKING
AB In this paper, we propose a novel data hiding scheme with reversibility based on exploiting modification direction (EMD). One cover image is first chosen and prepared to generate two visually similar steganographic images. During the secret embedding, the pixels in the first steganographic image are modified by no more than one gray level to embed secret data using the traditional EMD method, while the pixels in the second steganographic image are adaptively modified through referring to the first steganographic image without any confusions in image recovery process. On the receiver side, secret data can be extracted easily and the original cover image can also be recovered from the two steganographic images correctly. Experimental results demonstrate that our scheme can achieve high hiding capacity and satisfactory visual quality.
C1 [Qin, Chuan] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chang, Chin-Chen] Asia Univ, Dept Comp Sci & Informat Engn, Taichung 41354, Taiwan.
   [Hsu, Tai-Jung] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 62102, Taiwan.
C3 University of Shanghai for Science & Technology; Feng Chia University;
   Asia University Taiwan; National Chung Cheng University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM qin@usst.edu.cn; alan3c@gmail.com; andyblack77@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023; Qin, Chuan/C-1106-2017
OI Qin, Chuan/0000-0002-0370-4623
FU Natural Science Foundation of China [61303203]; Natural Science
   Foundation of Shanghai, China [13ZR1428400]; Innovation Program of
   Shanghai Municipal Education Commission [14YZ087]
FX This work was supported by the Natural Science Foundation of China
   (61303203), the Natural Science Foundation of Shanghai, China
   (13ZR1428400), and the Innovation Program of Shanghai Municipal
   Education Commission (14YZ087).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Highland HJ, 1997, COMPUT SECUR, V16, P369, DOI 10.1016/S0167-4048(97)82243-2
   Ker AD, 2004, LECT NOTES COMPUT SC, V3200, P97
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Zeng XT, 2012, AEU-INT J ELECTRON C, V66, P532, DOI 10.1016/j.aeue.2011.11.004
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
   Zhou JT, 2012, IEEE SIGNAL PROC LET, V19, P287, DOI 10.1109/LSP.2012.2190508
NR 17
TC 139
Z9 144
U1 1
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5861
EP 5872
DI 10.1007/s11042-014-1894-5
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100024
DA 2024-07-18
ER

PT J
AU Zhang, XP
   Xiao, YY
   Zhao, ZM
AF Zhang, Xuanping
   Xiao, Yangyang
   Zhao, Zhongmeng
TI Self-embedding fragile watermarking based on DCT and fast fractal coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile watermarking; Self-embedding; Discrete cosine transform; Fractal
   image compression
ID IMAGE TAMPER DETECTION; ADAPTIVE FUZZY CONTROL; AUTHENTICATION; RECOVERY
AB A self-embedding fragile watermarking scheme is proposed in this paper, which is based on Discrete Cosine Transform and fractal compression coding. To overcome the high computational complexity of fractal coding, a fast coding method is also presented that improves the efficiency of fractal block coding in the watermarking procedure. In our algorithm, three kinds of watermarks are generated for image authentication and recovery, which is based on an interleaved and overlapped 8 x8 image block structure. This makes our method obtain an authentication granularity of 4 x4 approximately. At the same time, we take advantage of two levels of mapping to select mapping block for every image block. Three versions of recovery watermarks for each block are embedded in different quadrants, which provides another two chances for block recovery in case one is destroyed. Experimental results demonstrate that the proposed scheme not only outperforms conventional self-embedding fragile watermarking algorithms in tamper recovery, but also improves the security against the various counterfeiting attacks.
C1 [Zhang, Xuanping; Xiao, Yangyang; Zhao, Zhongmeng] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Zhang, XP (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM zxp@mail.xjtu.edu.cn; xyr0528simple@126.com; zmzhao@mail.xjtu.edu.cn
FU National Natural Science Foundation of China [61100239, 60803088]; Ph.D.
   Programs Foundation of Ministry of Education of China [20100201110063]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No: 61100239 and 60803088), the Ph.D. Programs Foundation
   of Ministry of Education of China (Grant No: 20100201110063).
CR Hernandez-Avalos PA, 2012, DIGIT SIGNAL PROCESS, V22, P324, DOI 10.1016/j.dsp.2011.10.012
   Bhatnagar G, 2013, MULTIMED TOOLS APPL, V66, P179, DOI 10.1007/s11042-011-0788-z
   Bransley M., 1988, Fractals Everywhere
   Celik MU, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P502, DOI 10.1109/ICIP.2001.958538
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chen F, 2014, MULTIMED TOOLS APPL, V72, P41, DOI 10.1007/s11042-012-1332-5
   Chuanmu L, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 5, PROCEEDINGS, P669, DOI 10.1109/CISP.2008.374
   Coppersmith D, 1999, P SOC PHOTO-OPT INS, V3657, P79, DOI 10.1117/12.344705
   Fridrich J, 2002, J ELECTRON IMAGING, V11, P262, DOI 10.1117/1.1459449
   Hassani A., 2009, IDT WORKSH INT RES C, P1
   He HJ, 2009, SIGNAL PROCESS, V89, P1557, DOI 10.1016/j.sigpro.2009.02.009
   He HJ, 2011, MULTIMED TOOLS APPL, V52, P307, DOI 10.1007/s11042-010-0474-6
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Kiani S, 2011, J SYST SOFTWARE, V84, P1550, DOI 10.1016/j.jss.2011.03.019
   Korus P, 2013, IEEE T IMAGE PROCESS, V22, P1134, DOI 10.1109/TIP.2012.2227769
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Lin CY, 2001, IEEE T CIRC SYST VID, V11, P153, DOI 10.1109/76.905982
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Lin SD, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 3, PROCEEDINGS, P74
   Liu YJ, 2007, INFORM SCIENCES, V177, P3901, DOI 10.1016/j.ins.2007.03.005
   Liu YJ, 2013, IEEE T FUZZY SYST, V21, P275, DOI 10.1109/TFUZZ.2012.2212200
   Liu YJ, 2010, IEEE T SYST MAN CY A, V40, P170, DOI 10.1109/TSMCA.2009.2030164
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Qian ZX, 2010, IEEE SIGNAL PROC LET, V17, P929, DOI 10.1109/LSP.2010.2072991
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Wang XY, 2013, NONLINEAR DYNAM, V73, P1945, DOI 10.1007/s11071-013-0915-7
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Wong PW, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P455, DOI 10.1109/ICIP.1998.723526
   Yang L, 2012, 2012 INTERNATIONAL CONFERENCE ON INDUSTRIAL CONTROL AND ELECTRONICS ENGINEERING (ICICEE), P863, DOI 10.1109/ICICEE.2012.229
   Yoon JW, 2010, COMMUN NONLINEAR SCI, V15, P3998, DOI 10.1016/j.cnsns.2010.01.041
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2011, MULTIMED TOOLS APPL, V54, P385, DOI 10.1007/s11042-010-0541-z
   Zhao X, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P283
NR 35
TC 25
Z9 25
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5767
EP 5786
DI 10.1007/s11042-014-1882-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100019
DA 2024-07-18
ER

PT J
AU Liu, XQ
   Wang, WQ
AF Liu, Xiaoqian
   Wang, Weiqiang
TI An effective graph-cut scene text localization with embedded text
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene text; Text localization; Text segmentation; Graph-cut
AB This paper presents an effective and efficient approach to extracting scene text from images. The approach first extracts the edge information by the local maximum difference filter (LMDF), and at the same time a given image is decomposed into a group of image layers by color clustering. Then, through combining the characteristics of geometric structure and spatial distribution of scene text with the edge map, the candidate text image layers are identified. Further, in character level, the candidate text connected components are identified using a set of heuristic rules. Finally, the graph-cut computation is utilized to identify and localize text lines with arbitrary directions. In the proposed approach, the segmentation of text pixels is efficiently embedded into the computation of text localization as a part. The comprehensive evaluation experiments are performed on four challenging datasets (ICDAR 2003, ICDAR 2011, MSRA-TD500 and The Street View Text (SVT)) to verify the validation of our approach. In the comparison experiments with many state-of-the-art methods, the results demonstrate that our approach can effectively handle scene text with diverse fonts, sizes, colors, different languages, as well as arbitrary orientations, and it is robust to the influence of illumination change.
C1 [Liu, Xiaoqian; Wang, Weiqiang] Univ Chinese Acad Sci, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Liu, XQ (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.
EM xiaoqian1112@gmail.com; wqwang@ucas.ac.cn
FU National Natural Science Foundation of China [61232013, 61271434,
   61175115]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61232013, No. 61271434, No. 61175115.
CR Bhattacharya Ujjwal, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P171, DOI 10.1109/ICDAR.2009.178
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Fabrizio J, 2009, IEEE IMAGE PROC, P2373, DOI 10.1109/ICIP.2009.5413435
   Fei Lu, 2010, Proceedings of the 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P206, DOI 10.1109/ICCMS.2010.89
   Hanif S.M., 2008, Pattern Recognition, P1
   Jing Zhang, 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P308, DOI 10.1007/978-3-642-19309-5_24
   Jung C, 2008, SIGNAL PROCESS, V88, P1907, DOI 10.1016/j.sigpro.2008.02.002
   Kumar M., 2010, Proceedings of the 2010 IEEE 10th International Conference on Computer and Information Technology (CIT 2010), P1413, DOI 10.1109/CIT.2010.253
   Kumar M, 2010, INT CONF COMPUT AUTO, P594, DOI 10.1109/ICCAE.2010.5451808
   Lee JJ, 2011, PROC INT CONF DOC, P429, DOI 10.1109/ICDAR.2011.93
   Li XJ, 2008, IEEE IMAGE PROC, P969, DOI 10.1109/ICIP.2008.4711918
   Liu QF, 2006, IEEE IMAGE PROC, P1473, DOI 10.1109/ICIP.2006.312560
   Lucas SM, 2005, PROC INT CONF DOC, P80, DOI 10.1109/ICDAR.2005.231
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Mancas-Thillou C, 2006, IEEE IMAGE PROC, P985, DOI 10.1109/ICIP.2006.312653
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Neumann L, 2010, P ACCV NZ NOV 8 12, P30
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Neumann L, 2011, PROC INT CONF DOC, P687, DOI 10.1109/ICDAR.2011.144
   Park J, 2010, PATTERN RECOGN LETT, V31, P1728, DOI 10.1016/j.patrec.2010.05.024
   Pazio Marcin, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P272
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shivakumara P, 2011, IEEE T PATTERN ANAL, V33, P412, DOI 10.1109/TPAMI.2010.166
   Shivakumara P, 2010, PATTERN RECOGN, V43, P2165, DOI 10.1016/j.patcog.2010.01.009
   Tang X, 2002, IEEE T NEURAL NETWOR, V13, P961, DOI 10.1109/TNN.2002.1021896
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Yi CC, 2013, COMPUT VIS IMAGE UND, V117, P182, DOI 10.1016/j.cviu.2012.11.002
   Zeng C, 2011, CAM BAS DOC AN REC 4, P58
NR 31
TC 4
Z9 5
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4891
EP 4906
DI 10.1007/s11042-013-1848-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400021
DA 2024-07-18
ER

PT J
AU Ri, CY
   Yao, M
AF Ri, Chang-Yong
   Yao, Min
TI Bayesian network based semantic image classification with attributed
   relational graph
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic image classification; Attributed relational graph; Semantic
   distance; Bayesian network
ID SCENE CLASSIFICATION; NATURAL SCENES; MODELS
AB Semantic image classification is a hot issue of image mining. Information of spatial relations between objects in an image is one of the important semantic information of an image. However, the previous researches have not made full use of the spatial relations for image modeling and classification. In addition, to classify the images with Bayesian network, the accuracy of conditional probability estimation may be insufficient, because the learning methods of spatial contextual models have usually used a limited number of training samples. In this work, the semantic image modeling based on attributed relational graph has been proposed, in which the distance measure method between images was presented, therefore the object information and spatial relational information could be fully utilized. Then, the semantic distance between images based on attributed relational graph could be calculated for the support vector machine to obtain the joint conditional probability distribution of Bayesian network. Therefore the probabilistic estimation problem under the sparse training samples could be solved, and the accuracy of semantic image classification with Bayesian network was improved. Experimental results show the validity and reliability of this proposed method.
C1 [Ri, Chang-Yong; Yao, Min] Zhejiang Univ, Sch Comp Sci & Technol, Hangzhou 310027, Zhejiang, Peoples R China.
   [Ri, Chang-Yong] Kim Il Song Univ, Inst Informat Sci, Pyongyang 190016, North Korea.
C3 Zhejiang University
RP Ri, CY (corresponding author), Zhejiang Univ, Sch Comp Sci & Technol, Hangzhou 310027, Zhejiang, Peoples R China.
EM changyongri@gmail.com; myao@zju.edu.cn
FU 973 Program [2013CB329504]; NSF of China [61272261]; NSF of Zhejiang
   [Y1110152]; STD of Zhejiang [2012C21002]
FX This work was partly supported by the 973 Program (2013CB329504), NSF of
   China (No. 61272261), NSF of Zhejiang (Y1110152), and STD of Zhejiang
   (2012C21002).
CR Aksoy S, 2005, IEEE T GEOSCI REMOTE, V43, P581, DOI 10.1109/TGRS.2004.839547
   Aksoy S., 2003, FRONTIERS REMOTE SEN, P35
   [Anonymous], ELECT LETT COMP VISI
   [Anonymous], 2008, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2008.4587799, DOI 10.1109/CVPR.2008.4587799]
   Athanasiadis T, 2007, IEEE T CIRC SYST VID, V17, P298, DOI 10.1109/TCSVT.2007.890636
   Berretti S, 2001, IEEE T PATTERN ANAL, V23, P1089, DOI 10.1109/34.954600
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Boutell MR, 2007, IEEE T MULTIMEDIA, V9, P136, DOI 10.1109/TMM.2006.886372
   Bruzzone L, 2009, IEEE T GEOSCI REMOTE, V47, P2142, DOI 10.1109/TGRS.2008.2011983
   Carbonetto P, 2004, LECT NOTES COMPUT SC, V3021, P350
   Chang E, 2003, IEEE T CIRC SYST VID, V13, P26, DOI 10.1109/TCSVT.2002.808079
   Cheng HH, 2010, PATTERN RECOGN, V43, P4042, DOI 10.1016/j.patcog.2010.06.004
   Choi MJ, 2012, IEEE T PATTERN ANAL, V34, P240, DOI 10.1109/TPAMI.2011.119
   Duchenne O, 2011, IEEE I CONF COMP VIS, P1792, DOI 10.1109/ICCV.2011.6126445
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004
   Harchaoui Z., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383049
   Huang YZ, 2011, PROC CVPR IEEE, P1649, DOI 10.1109/CVPR.2011.5995655
   Jin B, 2012, IEEE SIGNAL PROC LET, V19, P151, DOI 10.1109/LSP.2012.2184091
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Liu SY, 2011, EXPERT SYST APPL, V38, P11591, DOI 10.1016/j.eswa.2011.03.037
   Luo JB, 2005, PATTERN RECOGN, V38, P919, DOI 10.1016/j.patcog.2004.11.001
   Papadopoulos GT, 2011, COMPUT VIS IMAGE UND, V115, P1288, DOI 10.1016/j.cviu.2011.05.005
   Park BG, 2003, COMPUT VIS IMAGE UND, V90, P217, DOI 10.1016/S1077-3142(03)00049-3
   Qi GJ, 2010, IEEE T MULTIMEDIA, V12, P278, DOI 10.1109/TMM.2010.2046270
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Serrano N, 2004, PATTERN RECOGN, V37, P1773, DOI 10.1016/j.patcog.2004.03.003
   Shen JL, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P340, DOI 10.1109/MMMC.2005.66
   Singhal A, 2003, PROC CVPR IEEE, P235
   Su Y, 2012, INT J COMPUT VISION, V100, P59, DOI 10.1007/s11263-012-0529-4
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang L, 2011, COMPUT VIS IMAGE UND, V115, P310, DOI 10.1016/j.cviu.2010.10.011
NR 34
TC 7
Z9 8
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4965
EP 4986
DI 10.1007/s11042-014-1858-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400025
DA 2024-07-18
ER

PT J
AU Dang, TK
   Worring, M
   Bui, TD
AF Trung Kien Dang
   Worring, Marcel
   The Duy Bui
TI Building 3D event logs for video investigation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene investigation; Video analysis; Story navigation; 3D model
AB In scene investigation, creating a video log captured using a handheld camera is more convenient and more complete than taking photos and notes. By introducing video analysis and computer vision techniques, it is possible to build a spatio-temporal representation of the investigation. Such a representation gives a better overview than a set of photos and makes an investigation more accessible. We develop such methods and present an interface for navigating the result. The processing includes (i) segmenting a log into events using novel structure and motion features making the log easier to access in the time dimension, and (ii) mapping video frames to a 3D model of the scene so the log can be navigated in space. Our results show that, using our proposed features, we can recognize more than 70 percent of all frames correctly, and more importantly find all the events. From there we provide a method to semi-interactively map those events to a 3D model of the scene. With this we can map more than 80 percent of the events. The result is a 3D event log that captures the investigation and supports applications such as revisiting the scene, examining the investigation itself, or hypothesis testing.
C1 [Trung Kien Dang; Worring, Marcel] Univ Amsterdam, Amsterdam, Netherlands.
   [Trung Kien Dang; The Duy Bui] Vietnam Natl Univ Hanoi, Univ Engn & Technol, Hanoi, Vietnam.
C3 University of Amsterdam; Vietnam National University Hanoi
RP Dang, TK (corresponding author), Univ Amsterdam, Amsterdam, Netherlands.
EM dtkien123@gmail.com
RI Worring, Marcel/JRW-7059-2023
OI Worring, Marcel/0000-0003-4097-4136
FU Research Grant from Vietnam's National Foundation for Science and
   Technology Development (NAFOSTED) [102.02-2011.13]
FX We thank Jurrien Bijhold and the Netherlands Forensic Institute for
   providing the data and bringing in domain knowledge, and the police
   investigators for participating in the experiment. This work is
   supported by the Research Grant from Vietnam's National Foundation for
   Science and Technology Development (NAFOSTED), No. 102.02-2011.13.
CR Abdollahian G, 2010, IEEE T MULTIMEDIA, V12, P28, DOI 10.1109/TMM.2009.2036286
   Aizawa K, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P10, DOI 10.1109/MMMC.2005.34
   Albiol A., 2003, IEEE INT C AC SPEECH
   [Anonymous], 15 INTERPOL FOR SCI
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Bush V., 1945, THE ATLANTIC
   Dang TK, 2011, COMPUT VIS IMAGE UND, V115, P1516, DOI 10.1016/j.cviu.2011.07.001
   Dickie C., 2004, P THE 1 ACM WORKSHOP, P105
   Doherty Aiden R., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P20, DOI 10.1109/WIAMIS.2008.32
   Doherty AR, 2007, P RIAO 2007 PITTSB
   Gemmell J., 2004, P THE 1 ACM WORKSHOP, P48
   Gibson S, 2003, COMPUT GRAPH-UK, V27, P293, DOI 10.1016/S0097-8493(02)00285-6
   Goldman DB, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P3, DOI 10.1145/1449715.1449719
   Howard TLJ, 2000, SPIE VISUAL DATA E 7, V3960, P1
   Kang H.W, 2002, P ACM S VIRT REAL SO, P73
   Kim Kihwan., 2006, ACM Multimedia, P655
   Lan DJ, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P469
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma Y.-F, 2003, P ACM MULT, P533
   Mei T, 2007, IEEE T MULTIMED, V9
   MEUR OL, 2005, P INT C IM PROC, V3, P1188
   Ngo CW, 2002, INT J COMPUT VISION, V50, P127, DOI 10.1023/A:1020341931699
   Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a
   Pollefeys M, 2002, LECT NOTES COMPUT SC, V2351, P837
   Robinson D, 2003, J MATH IMAGING VIS, V18, P35, DOI 10.1023/A:1021841127282
   Rui Y., 2000, Proceedings ACM Multimedia 2000, P105, DOI 10.1145/354384.354443
   Sinha SN, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409112
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Tancharoen Datchakorn., 2005, P 2 ACM WORKSHOP CON, P61
   Torr P, 1999, INT J COMPUT VIS, V32
   van den Hengel A, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239537, 10.1145/1276377.1276485]
NR 35
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4617
EP 4639
DI 10.1007/s11042-013-1826-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400008
DA 2024-07-18
ER

PT J
AU Hsiao, KF
   Rashvand, HF
AF Hsiao, Kuei-Fang
   Rashvand, Habib F.
TI Data modeling mobile augmented reality: integrated mind and body
   rehabilitation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile augmented reality; M-health; E-health; Elderly; Data modeling
ID TECHNOLOGY; SUPPORT
AB The rapid growth of elderly populations throughout the world necessitates inclusion of this sector in all active functions of communities. However, lack of physical and mental fitness threatens their effectiveness is making them to drain the community resources instead of positive and productive contributions. Our studies show the need for a massive large-scale boost in two main dimensions of physical and mental health enhancement. In order to solve this problem, in this paper we propose a new low-cost and innovative adoption of augmented reality (AR) functions through an agile deployment of mobile-based augmented reality (mAR) embedded in massively available intelligent smartphones. In our proposed method a set of downloadable AR-enabled embedded learning and exercising programs, designed upon users' historical and habitual improvement data would enable a collective sequence of required activities and individually optimized. At the system design level upon the individually recorded data in various databases select and configure the most suitable set of downloadable programs-a combination of mental and physical activities. From our experiment we provide some of our statistical results for two distinct application areas of mAR: 'exercising-rehab' and 'lifelong learning'. Three sets of results show the age related results for three user critical features of 'ease of use', 'usefulness' and 'user attitude'. Further analysis of data through modeling helps us to provide a systematic design procedure based on user's age in conjunction with other variables.
C1 [Hsiao, Kuei-Fang] Ming Chuan Univ, Dept Informat Management, Taoyuan, Taiwan.
   [Rashvand, Habib F.] Univ Warwick, Adv Commun Syst, Coventry CV4 7AL, W Midlands, England.
C3 Ming Chuan University; University of Warwick
RP Hsiao, KF (corresponding author), Ming Chuan Univ, Dept Informat Management, Taoyuan, Taiwan.
EM kfhsiao@mail.mcu.edu.tw; h.rashvand@ieee.org
FU National Science Council, Taiwan [NSC 100-2511-S-130-003-MY2]
FX This study was supported by the National Science Council, Taiwan, under
   contract no: NSC 100-2511-S-130-003-MY2.
CR Ahn J, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-18
   [Anonymous], 2012, NEILSON REPORT SURV
   [Anonymous], 2009, WORLDS OLD POP PROJ
   Baum Elizabeth E, 2003, J Am Med Dir Assoc, V4, P74, DOI 10.1016/S1525-8610(04)70279-0
   Brahami M, 2013, J INF PROCESS SYST, V9, P1, DOI 10.3745/JIPS.2013.9.1.001
   Burke J. W., 2010, 2010 2nd International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES 2010), P75, DOI 10.1109/VS-GAMES.2010.21
   Carmigniani J, 2011, HANDBOOK OF AUGMENTED REALITY, P3, DOI 10.1007/978-1-4614-0064-6_1
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Choi Y, 2005, J INF PROCESS SYST, V1, P107
   Colcombe SJ, 2004, P NATL ACAD SCI USA, V101, P3316, DOI 10.1073/pnas.0400266101
   Dementia, 2013, WIK FREE ENCY
   Fasola J, 2012, P IEEE, V100, P2512, DOI 10.1109/JPROC.2012.2200539
   Ferrigno G, 2011, IEEE PULSE, V2, P55, DOI 10.1109/MPUL.2011.941523
   Gorgu L, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON ADVANCES IN HUMAN-ORIENTED AND PERSONALIZED MECHANISM, TECHNOLOGIES, AND SERVICES, P61, DOI 10.1109/CENTRIC.2009.16
   Hsiao KF, 2011, HUM-CENTRIC COMPUT I, V1, DOI 10.1186/2192-1962-1-1
   Hsiao KF, 2013, MULTIMED TOOLS APPL, V64, P407, DOI 10.1007/s11042-011-0985-9
   Hsiao KF, 2012, INTERACT LEARN ENVIR, V20, P331, DOI 10.1080/10494820.2010.486682
   Kim B, 2012, J INF PROCESS SYST, V8, P555, DOI 10.3745/JIPS.2012.8.4.555
   Kowtko M., 2012 IEEE Long Island Systems, Applications and Technology Conference (LISAT), P1, DOI DOI 10.1109/LISAT.2012.6223205
   Malkawi M., 2013, J HUMAN CENTRIC COMP, V3, P1
   McDonnell R., 2010, 2010 IEEE 23rd International Symposium on Computer-Based Medical Systems (CBMS 2010), P122, DOI 10.1109/CBMS.2010.6042626
   Min Chen, 2011, Mobile Networks and Applications, V16, P171, DOI 10.1007/s11036-010-0260-8
   Mirzaei MR, 2012, 14 S COMB AUGM REAL, P174, DOI [10.1109/SVR.2012.10, DOI 10.1109/SVR.2012.10]
   Moak ZB, 2010, J PUBLIC HEALTH-UK, V32, P191, DOI 10.1093/pubmed/fdp093
   Mozgovoy M, 2010, J CONVERG JOC, V1, P29
   MURPHY E, 1982, BRIT J PSYCHIAT, V141, P135, DOI 10.1192/bjp.141.2.135
   Pan Yi, 2012, J. Converg., V3, P23
   Rashvand HF, 2012, WILEY SERIES COMMUNI
   Rashvand HF, 2012, 17 MOB COMP WORKSH T
   ROVNER BW, 1991, JAMA-J AM MED ASSOC, V265, P993, DOI 10.1001/jama.265.8.993
   Sakurai Y, 2008, SITIS 2008: 4TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY AND INTERNET BASED SYSTEMS, PROCEEDINGS, P480, DOI 10.1109/SITIS.2008.100
   Seelman KD, 2008, IEEE ENG MED BIOL, V27, P40, DOI 10.1109/EMB.2007.907393
   Sejin Oh, 2012, 2012 IEEE/ACIS 11th International Conference on Computer and Information Science (ICIS), P651, DOI 10.1109/ICIS.2012.106
   SPIRDUSO WW, 1978, J GERONTOL, V33, P26, DOI 10.1093/geronj/33.1.26
   The International Federation of Alzheimer's Disease and Related Disorders Societies Inc, 2008, TECHNICAL REPORT
   Wherton J, 2009, LECT NOTES COMPUT SC, V5889, P111
   Xhafa F, 2012, J CONVERGENCE, V3, P1
   Zapirain Begona Garcia, 2010, GAM INN C ICE GIC 20, P1
   Zhang Y, 2009, 2009 IEEE CONGRESS ON SERVICES (SERVICES-1 2009), VOLS 1 AND 2, P14, DOI 10.1109/SERVICES-I.2009.104
NR 39
TC 11
Z9 13
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3543
EP 3560
DI 10.1007/s11042-013-1649-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000020
DA 2024-07-18
ER

PT J
AU Yan, XH
   Wang, S
   Abd El-Latif, AA
   Niu, XM
AF Yan, Xuehu
   Wang, Shen
   Abd El-Latif, Ahmed A.
   Niu, Xiamu
TI Visual secret sharing based on random grids with abilities of AND and
   XOR lossless recovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual secret sharing; Random grids; Boolean operations; Lossless
   recovery; Threshold secret sharing
ID IMAGE ENCRYPTION; CRYPTOGRAPHY; SCHEMES
AB In this paper, a visual secret image sharing threshold scheme based on random grids and Boolean operations with the abilities of AND and XOR decryptions is proposed. When no light-weight computation device the secret could be revealed by human visual system with no cryptographic computation based on Boolean AND operation (stacking). On the other hand, if the light-weight computation device is available the secret could be revealed with better visual quality based on Boolean AND or XOR operation and could be losslessly revealed when sufficient shadow images are collected for a general k out of n scheme. Furthermore, the proposed scheme has several superior performances such as (k, n) threshold, no codebook design, avoiding the pixel expansion problem and the same color representation as digital images (digital color). Experiments are conducted to show the security and efficiency of the proposed scheme. Comparisons with previous approaches show the advantages of the proposed scheme.
C1 [Yan, Xuehu; Wang, Shen; Abd El-Latif, Ahmed A.; Niu, Xiamu] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
   [Abd El-Latif, Ahmed A.] Menoufia Univ, Dept Math, Fac Sci, Shibin Al Kawm 32511, Egypt.
C3 Harbin Institute of Technology; Egyptian Knowledge Bank (EKB); Menofia
   University
RP Wang, S (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
EM xuehu.yan@ict.hit.edu.cn; shen.wang@hit.edu.cn; ahmed_rahiem@yahoo.com;
   xiamu.niu@ict.hit.edu.cn
RI Abd El-Latif, Ahmed A. A./GRO-1613-2022; Yan, Xuehu/AAG-1718-2022; Yan,
   Xuehu/AFK-3139-2022
OI Abd El-Latif, Ahmed A. A./0000-0002-5068-2033; Yan,
   Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720
FU National Natural Science Foundation of China [61100187, 61301099,
   61361166006]; Fundamental Research Funds for the Central Universities
   [HIT. NSRIF. 2013061]
FX The authors wish to thank the anonymous reviewers for their suggestions
   to improve this paper. This work is supported by the National Natural
   Science Foundation of China (Grant Number: 61100187, 61301099,
   61361166006) and the Fundamental Research Funds for the Central
   Universities (Grant Number: HIT. NSRIF. 2013061).
CR [Anonymous], 2012, RES J APPL SCI ENG T
   Chen T., 2008, P 18 INF SEC C HUAL
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Feng YI, 2008, J TSINGHUA U SCI TEC, V48, P121
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Naor M., 1995, Advances in Cryptology - EUROCRYPT '94. Workshop on the Theory and Application of Cryptographic Techniques. Proceedings, P1, DOI 10.1007/BFb0053419
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Yan X., 2013, Journal of Information Hiding Multimedia and Signal Process (JIHMSP), V4, P118
   Yan X, THRESHOLD VISUAL SEC
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 20
TC 55
Z9 58
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 3231
EP 3252
DI 10.1007/s11042-013-1784-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800019
DA 2024-07-18
ER

PT J
AU Jia, Z
   Zhao, JW
   Wang, HC
   Xiong, ZY
   Finn, A
AF Jia, Zhen
   Zhao, Jianwei
   Wang, Hongcheng
   Xiong, Ziyou
   Finn, Alan
TI A two-step face hallucination approach for video surveillance
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Face tracking; Face recognition; Face hallucination;
   Super-resolution; Sparse representation; Visual surveillance
ID IMAGE SUPERRESOLUTION; SPARSE
AB In this paper we propose a novel face hallucination algorithm to synthesize a high-resolution face image from several low-resolution input face images. Face hallucination normally uses two models: a global parametric model which synthesizes the global face shapes from eigenfaces, and a local parametric model which enhances the local high frequency details. We follow a similar process to develop a robust face hallucination algorithm. First, we obtain eigenfaces from a number of low resolution face images segmented from a video sequence using a face tracking algorithm. Then we compute the difference between an interpolated low-resolution face and a mean face, and use this difference as the query to retrieve an approximate sparse eigenface representation. The eigenfaces are combined using the coefficients obtained from the sparse representation and added into the interpolated low-resolution face. In this way, the global shape of the interpolated low resolution face can be successfully enhanced. Second, we improve the example-based super-resolution method for local high frequency information enhancement. Our proposed algorithm uses the Approximate Nearest Neighbors (ANN) search method to find a number of nearest neighbors for a stack of queries, instead of finding the exact match for each low frequency patch. Median filtering is used to remove the noise from the nearest neighbors in order to enhance the signal. Our proposed algorithm uses a sparse representation and the ANN method to enhance both global face shape and local high frequency information while greatly improving the processing speed, as confirmed empirically.
C1 [Jia, Zhen; Zhao, Jianwei] United Technol Res Ctr China Ltd, Kerry Parkside Off, Shanghai 201204, Peoples R China.
   [Wang, Hongcheng; Xiong, Ziyou; Finn, Alan] United Technol Res Ctr, E Hartford, CT 06108 USA.
C3 Raytheon Technologies; Raytheon Technologies
RP Jia, Z (corresponding author), United Technol Res Ctr China Ltd, Kerry Parkside Off, Room 3502,35-F,1155 Fang Dian Rd, Shanghai 201204, Peoples R China.
EM jiaz@utrc.utc.com
CR [Anonymous], P IEEE INT C AUT FAC
   Blackman SS, 2004, IEEE AERO EL SYS MAG, V19, P5, DOI 10.1109/MAES.2004.1263228
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Hu Y, 2011, IEEE T IMAGE PROCESS, V20, P433, DOI 10.1109/TIP.2010.2063437
   Jian MW, 2013, PATTERN RECOGN, V46, P3091, DOI 10.1016/j.patcog.2013.03.020
   Jung CK, 2011, IEEE SIGNAL PROC LET, V18, P367, DOI 10.1109/LSP.2011.2140370
   Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5
   Liu T., 2004, INVESTIGATION PRACTI, P825
   Ma X, 2010, IEEE SIGNAL PROC LET, V17, P579, DOI 10.1109/LSP.2010.2047317
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 17
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 1845
EP 1862
DI 10.1007/s11042-013-1721-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500007
DA 2024-07-18
ER

PT J
AU Zinner, T
   Hossfeld, T
   Fiedler, M
   Liers, F
   Volkert, T
   Khondoker, R
   Schatz, R
AF Zinner, Thomas
   Hossfeld, Tobias
   Fiedler, Markus
   Liers, Florian
   Volkert, Thomas
   Khondoker, Rahamatullah
   Schatz, Raimund
TI Requirement driven prospects for realizing user-centric network
   orchestration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of experience; User-centric network orchestration; Application
   requirements; Network-application interface; Service composition
AB The Internet's infrastructure shows severe limitations when an optimal end user experience for multimedia applications should be achieved in a resource-efficiently way. In order to realize truly user-centric networking, an information exchange between applications and networks is required. To this end, network-application interfaces need to be deployed that enable a better mediation of application data through the Internet. For smart multimedia applications and services, the application and the network should directly communicate with each other and exchange information in order to ensure an optimal Quality of Experience (QoE). In this article, we follow a use-case driven approach towards user-centric network orchestration. We derive user, application, and network requirements for three complementary use cases: HD live TV streaming, video-on-demand streaming and user authentication with high security and privacy demands, as typically required for payed multimedia services. We provide practical guidelines for achieving an optimal QoE efficiently in the context of these use cases. Based on these results, we demonstrate how to overcome one of the main limitations of today's Internet by introducing the major steps required for user-centric network orchestration. Finally, we show conceptual prospects for realizing these steps by discussing a possible implementation with an inter-network architecture based on functional blocks.
C1 [Zinner, Thomas; Hossfeld, Tobias] Univ Wurzburg, Inst Comp Sci, D-97070 Wurzburg, Germany.
   [Fiedler, Markus] Blekinge Inst Technol, Dept Commun Syst, Karlskrona, Sweden.
   [Liers, Florian; Volkert, Thomas] Tech Univ Ilmenau, Ilmenau, Germany.
   [Khondoker, Rahamatullah] Univ Kaiserslautern, D-67663 Kaiserslautern, Germany.
   [Schatz, Raimund] Telecommun Res Ctr Vienna FTW, Vienna, Austria.
C3 University of Wurzburg; Blekinge Institute Technology; Technische
   Universitat Ilmenau; University of Kaiserslautern
RP Zinner, T (corresponding author), Univ Wurzburg, Inst Comp Sci, D-97070 Wurzburg, Germany.
EM zinner@informatik.uni-wuerzburg.de;
   hossfeld@informatik.uni-wuerzburg.de; markus.fiedler@bth.se;
   florian.liers@tu-ilmenau.de; thomas.volkert@tu-ilmenau.de;
   khondoker@informatik.uni-kl.de; schatz@ftw.at
RI Zinner, Thomas/AAA-6004-2019
OI Zinner, Thomas/0000-0002-4179-4105; Schatz, Raimund/0000-0002-8966-7439;
   Hossfeld, Tobias/0000-0003-0173-595X
FU Federal Ministry of Education and Research of the Federal Republic of
   Germany [01BK0917, 01BK0935]; European FP7 Network of Excellence
   "Euro-NF" through the Specific Joint Research Project "PRUNO"
FX This work was funded by the Federal Ministry of Education and Research
   of the Federal Republic of Germany (support code 01BK0917 and 01BK0935,
   G-Lab) and by the European FP7 Network of Excellence "Euro-NF" through
   the Specific Joint Research Project "PRUNO". The authors alone are
   responsible for the content of the paper.
CR Abboud O, 2010, 21 ITC SPEC SEM MULT
   Bouabene G, 2012, AUTONOMIC NETWORK AR, DOI [10.1109/JSAC.2010.100102, DOI 10.1109/JSAC.2010.100102]
   Braden R, 2003, TECHNICAL REPORT
   Brunet D, 2011, LECT NOTES COMPUT SC, V6753, P100, DOI 10.1007/978-3-642-21593-3_11
   Egger S., 2012, P IEEE INT C COMM IC
   Engelke U, 2009, SIGNAL PROCESS-IMAGE, V24, P525, DOI 10.1016/j.image.2009.06.005
   G-Lab Special Interest Group Functional Composition, 2011, P 11 WUERZB WORKSH I
   Ganichev I, 2009, P SIGCOMM 2009 BARC
   Hossfeld T., 2012, DATA TRAFFIC MONITOR
   Hossfeld T, QUALITY EXPERIENCE M
   Hossfeld T., 2011, P 7 C NEXT GEN INT N
   Hossfeld T, 2008, COMPUT NETW, V52, P650, DOI 10.1016/j.comnet.2007.10.008
   ITU-T Recommendation, 2010, H264 ITUT REC
   Khondoker R., 2011, Proceedings of the 2011 International Conference on the Network of the Future (NOF), P68, DOI 10.1109/NOF.2011.6126685
   Khondoker R., 2010, P KAL INT INN FUT NE, P1
   Krishnan R. K., 2012, P INT MEAS C, P211
   Kuschnig R, 2008, J VIS COMMUN IMAGE R, V19, P529, DOI 10.1016/j.jvcir.2008.07.004
   Lakshman T. V., SOFTROUTER OPEN EXTE
   Liers F, 2012, P INT C ADV FUT INT, P2012
   Lorentzen C., 2010, 2010 Australasian Telecommunication Networks and Applications Conference (ATNAC 2010), P84, DOI 10.1109/ATNAC.2010.5680262
   Lorentzen C, 2011, RECENT ADV TELETRAFF, V2, P79
   LUBY M, 2002, 43 ANN IEEE S FDN CO
   Martin D, 2011, COMPUT NETW, V55, P910, DOI 10.1016/j.comnet.2010.12.015
   Volkert T, 2013, P 27 IEEE INT C ADV
   Yamagishi K, 2008, IEEE ICC, P110, DOI 10.1109/ICC.2008.29
NR 25
TC 5
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 413
EP 437
DI 10.1007/s11042-014-2072-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300006
DA 2024-07-18
ER

PT J
AU Dutta, MK
   Gupta, P
   Pathak, VK
AF Dutta, Malay Kishore
   Gupta, Phalguni
   Pathak, Vinay K.
TI A perceptible watermarking algorithm for audio signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; Perceptual transparency; Digital rights management;
   Chaotic sequences
AB This paper proposes an unconventional method for removable audible watermarking system based on the requirements of a promising application. Given an audio file, the system makes some part of file available for preview and perceptual watermarking on the remaining portion. The watermark is embedded into selected DCT coefficients of host audio signal so that the signal to noise ratio is maintained at a level which is audibly annoying to human auditory system. An issue that arises here is generating huge number of copies of the audio file which are audibly similar and numerically different. Once the audio file is decoded using the secret key a new watermark is embedded in the audio that is perceptually transparent to the human auditory system. Hence this double watermarking i.e. imperceptible and perceptible watermarking provides a novel prototype for digital right management control. The subjective quality tests and robustness tests indicate that the audio quality is excellent and is robust to signal processing attacks.
C1 [Dutta, Malay Kishore] Galgotias Coll Engn & Technol, Dept Elect & Commun Engn, Greater Noida, India.
   [Gupta, Phalguni] IIT, Dept Comp Sci & Engn, Kanpur, Uttar Pradesh, India.
   [Pathak, Vinay K.] HBTI, Dept Comp Sci & Engn, Kanpur, Uttar Pradesh, India.
C3 Galgotias College of Engineering & Technology (GCET); Indian Institute
   of Technology System (IIT System); Indian Institute of Technology (IIT)
   - Kanpur; Harcourt Butler Technical University (HBTU)
RP Dutta, MK (corresponding author), Galgotias Coll Engn & Technol, Dept Elect & Commun Engn, Greater Noida, India.
EM malay_kishore@rediffmail.com; pg@cse.iitk.ac.in;
   vinaypathak.hbti@gmail.com
OI Dutta, Malay Kishore/0000-0003-2462-737X
CR Akhaee Mohammad A., 2009, IEEE T MULT IN PRESS
   Bassia P, 1998, IEEE T MULTIMED, V3, P35
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bhat KV, 2008, ADCOM: 2008 16TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P73, DOI 10.1109/ADCOM.2008.4760430
   Boney L, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P473, DOI 10.1109/MMCS.1996.535015
   Cui LL, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P1497
   Garcia R, 1999, AES 107 CONV, P123
   Hu YJ, 2006, IEEE T CIRC SYST VID, V16, P129, DOI 10.1109/TCSVT.2005.858742
   Kang XG, 2011, IEEE T MULTIMEDIA, V13, P181, DOI 10.1109/TMM.2010.2098850
   Kennedy MP, 2000, SIGNAL PROCESS, V80, P1307, DOI 10.1016/S0165-1684(00)00038-4
   Kirovski D, 2001, INT CONF ACOUST SPEE, P1345, DOI 10.1109/ICASSP.2001.941177
   Lee SK, 2000, IEEE T CONSUM ELECTR, V46, P744, DOI 10.1109/30.883441
   Lin Y., 2007, IEEE INT C SIGN PROC, P209
   Tsai HH, 2003, EURASIP J APPL SIG P, V2003, P252, DOI 10.1155/S1110865703208027
   Wang Y., 2010, J ADV SIGNAL PROCESS, V2010, P1, DOI DOI 10.1016/J.PEPTIDES.2010.12.001
   Xiang Y, 2011, IEEE T MULTIMEDIA, V13, P2, DOI 10.1109/TMM.2010.2080668
NR 16
TC 10
Z9 10
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 691
EP 713
DI 10.1007/s11042-011-0945-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700005
DA 2024-07-18
ER

PT J
AU Ding, K
   Wang, W
   Liu, YH
AF Ding, Ke
   Wang, Wei
   Liu, Yunhui
TI 3D model retrieval using Bag-of-View-Words
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; Bag-of-View Words; 3D model descriptor; Pyramid
   matching
ID SEARCH ENGINE; 3-D; RECOGNITION
AB The view-based 3D model descriptors, which represent a 3D model using its projected views, have limitations on viewpoints sampling and computational cost. This paper proposes a new 3D model descriptor, called the Bag-of-View-Words (BoVW) descriptor, which describes a 3D model by measuring the occurrences of its projected views. An adaptive clustering method is applied to reduce the redundancy of the projected views of each 3D model. A 3D model is represented by a multi-resolution histogram, which is combined by several BoVW descriptors at different levels. The codebook is obtained by unsupervised learning. We also propose a new pyramid matching method for 3D model comparison. Experimental results demonstrated that our method outperforms several existing 3D model descriptors in respect of retrieval precision and computational cost.
C1 [Ding, Ke; Wang, Wei; Liu, Yunhui] Chinese Univ Hong Kong, Dept Mech & Automat Engn, Shatin, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Ding, K (corresponding author), Chinese Univ Hong Kong, Dept Mech & Automat Engn, Room 106,MMW Engn Bldg, Shatin, Hong Kong, Peoples R China.
EM kding@mae.cuhk.edu.hk
CR Ankerst M, 1999, Proc Int Conf Intell Syst Mol Biol, P34
   [Anonymous], 2000, Icml, DOI DOI 10.1007/3-540-44491-2_3
   [Anonymous], P ACM INT C IM VID R
   [Anonymous], 2012, P 3DOR
   [Anonymous], P SAMT WORKSH SEM 3
   [Anonymous], MULTIMEDIA TOOLS APP
   ANSARY T.F., 2005, ICAPR
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Assfalg J, 2007, IEEE T MULTIMEDIA, V9, P589, DOI 10.1109/TMM.2006.886271
   Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Del Bimbo A, 2006, ACM T MULTIM COMPUT, V2, P20
   Dengsheng Zhang, 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P646
   Ding K, 2012, P 11 AS C COMP VIS A
   Ding K, 2012, INT C PATT REC TSUK
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185527
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gao Y, 2010, P ACM INT C MULT FIR, P955
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Giorgi D, 2010, P ACM WORKSH 3D OBJ, P9
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Hamerly G, 2004, ADV NEUR IN, V16, P281
   HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073
   Jarvelin K., 2000, SIGIR Forum, V34, P41
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kang S. B., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P580, DOI 10.1109/CVPR.1991.139757
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   LI B., 2012, EurographicsWorkshop on 3D Object Retrieval, P109
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Mademlis A, 2008, IEEE T MULTIMEDIA, V10, P819, DOI 10.1109/TMM.2008.922790
   Ohbuchi R, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P265, DOI 10.1109/PCCGA.2002.1167870
   Ohbuchi Ryutarou, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P63, DOI 10.1109/ICCVW.2009.5457716
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386
   Saupe D., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P392
   Shen Y-T, 2003, EUROGRAPHICS
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Tangelder JWH, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P145, DOI 10.1109/SMI.2004.1314502
   Vranic DV, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P757
   Vranic DV, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P293, DOI 10.1109/MMSP.2001.962749
   Wahl E, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P474, DOI 10.1109/IM.2003.1240284
   Wong HS, 2007, IEEE T MULTIMEDIA, V9, P1026, DOI 10.1109/TMM.2007.898915
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
NR 50
TC 4
Z9 6
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2701
EP 2722
DI 10.1007/s11042-013-1560-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300028
DA 2024-07-18
ER

PT J
AU Biernacki, A
   Tutschku, K
AF Biernacki, Arkadiusz
   Tutschku, Kurt
TI Performance of HTTP video streaming under different network conditions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia communication; Network measurements; Quality of service;
   Video streaming
ID QUALITY ASSESSMENT
AB The Internet video sharing services have been gaining importance and increasing their share in the multimedia market. In order to compete effectively and provide broadcast television with a comparable level of quality, the Internet video should fulfil stringent quality of service (QoS) constraints. However, as the Internet video is based on packet transmission, it is influenced by delays, transmission errors, data losses and bandwidth limitations which can have a devastating influence on the perceived quality of the multimedia content. There are many works which describe the impact of network impairments on the Internet video. Nevertheless, little is known about how network conditions influence the video streamed by the currently popular services such as YouTube, where video is transmitted over reliable TCP/HTTP protocols. Therefore using a network simulator, we conducted an experimental evaluation of the HTTP based video transmission analysing how the network impairments mentioned above influence the streamed video. The experiments were validated against a network emulator supplied with real network traces. As a result of this work, we can state that the buffering strategies implemented by a video player are in many cases able to mitigate unfavourable network conditions what allow to play the streamed video smoothly. The results may serve Internet Service Providers so that they could tune their network characteristics in order to match the demand from HTTP video.
C1 [Biernacki, Arkadiusz] Silesian Tech Univ, Inst Comp Sci, PL-44100 Gliwice, Poland.
   [Tutschku, Kurt] Blekinge Inst Technol BTH, Sch Comp COM, Telecommun Syst Commun & Comp Syst Res Lab CCS, S-37179 Karlskrona, Sweden.
C3 Silesian University of Technology; Blekinge Institute Technology
RP Biernacki, A (corresponding author), Silesian Tech Univ, Inst Comp Sci, Akad 16, PL-44100 Gliwice, Poland.
EM arkadiusz.biernacki@gmail.com; kurt.tutschku@bth.se
RI Tutschku, Kurt/B-4310-2013
OI Tutschku, Kurt/0000-0003-4814-4428
FU National Science Centre (Poland) [DEC-2011/01/D/ST6/06995]
FX The research was partially supported by the National Science Centre
   (Poland) under grant DEC-2011/01/D/ST6/06995.
CR Abhari A, 2010, MULTIMED TOOLS APPL, V46, P91, DOI 10.1007/s11042-009-0309-5
   Acharya S, 2000, P SOC PHOTO-OPT INS, V3969, P130
   Acharya S, 1997, P SOC PHOTO-OPT INS, V3310, P166, DOI 10.1117/12.298418
   Alcock S, 2011, ACM SIGCOMM COMP COM, V41, P25, DOI 10.1145/1971162.1971166
   [Anonymous], GLOB MOB DAT TRAFF F
   [Anonymous], 1999, TCP CONGESTION CONTR
   Apostolopoulos JG, 2002, HPL20025260
   Benno S, 2011, BELL LABS TECH J, V16, P101, DOI 10.1002/bltj.20505
   Cha M, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P1
   Cheng X, 2008, INT WORKSH QUAL SERV, P249
   De Cicco L, 2010, LECT NOTES COMPUT SC, V6389, P447
   De Pessemier T, 2013, IEEE T BROADCAST, V59, P47, DOI 10.1109/TBC.2012.2220231
   Finamore A., 2011, YouTube Everywhere: Impact of Device and Infrastructure Synergies on User Experience
   Floyd S, 2000, ACM SIGCOMM COMP COM, V30, P43, DOI 10.1145/347057.347397
   Gill P, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P15
   Hemminger Stephen., 2005, LINUX C, P18
   Hickson I., 2011, HTML5: A vocabulary and associated APIs for HTML and XHTML
   Hossfeld T, 2012, INT WORK QUAL MULTIM, P1, DOI 10.1109/QoMEX.2012.6263849
   Khlifi H, 2006, IEEE COMMUN MAG, V44, P93, DOI 10.1109/MCOM.2006.1668388
   Krishnappa DK, 2011, C LOCAL COMPUT NETW, P948, DOI 10.1109/LCN.2011.6115577
   Mathis M., 1997, Computer Communication Review, V27, P67, DOI 10.1145/263932.264023
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Plissonneau L, 2008, P 19 ITC SPEC SEM
   Rao Ashwin., 2011, CONEXT
   Rejaie R, 1999, COMP COMM R, V29, P189, DOI 10.1145/316194.316222
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Varga A., 2008, P 1 INT C SIMULATION, P60, DOI DOI 10.4108/ICST.SIMUTOOLS2008.3027
   Wang B, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1352012.1352020
   Watanabe K, 2007, PROC SPIE, V6494, DOI 10.1117/12.703870
   Wu DP, 2001, IEEE T CIRC SYST VID, V11, P282, DOI 10.1109/76.911156
   You JY, 2010, SIGNAL PROCESS-IMAGE, V25, P482, DOI 10.1016/j.image.2010.02.002
   Zink M, 2009, COMPUT NETW, V53, P501, DOI 10.1016/j.comnet.2008.09.022
NR 32
TC 20
Z9 24
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1143
EP 1166
DI 10.1007/s11042-013-1424-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300007
OA Green Submitted, Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Wang, SF
   Zhu, YC
   Wu, GB
   Ji, Q
AF Wang, Shangfei
   Zhu, Yachen
   Wu, Guobing
   Ji, Qiang
TI Hybrid video emotional tagging using users' EEG and video content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotional tagging; Videos; Independent feature-level fusion;
   Decision-level fusion; Dependent feature-level fusion
ID CONTENT REPRESENTATION; AFFECT RECOGNITION; EXPRESSIONS; RETRIEVAL;
   VALENCE; BODY; CLASSIFICATION; AROUSAL; SENSORS; STATES
AB In this paper, we propose novel hybrid approaches to annotate videos in valence and arousal spaces by using users' electroencephalogram (EEG) signals and video content. Firstly, several audio and visual features are extracted from video clips and five frequency features are extracted from each channel of the EEG signals. Secondly, statistical analyses are conducted to explore the relationships among emotional tags, EEG and video features. Thirdly, three Bayesian Networks are constructed to annotate videos by combining the video and EEG features at independent feature-level fusion, decision-level fusion and dependent feature-level fusion. In order to evaluate the effectiveness of our approaches, we designed and conducted the psychophysiological experiment to collect data, including emotion-induced video clips, users' EEG responses while watching the selected video clips, and emotional video tags collected through participants' self-report after watching each clip. The experimental results show that the proposed fusion methods outperform the conventional emotional tagging methods that use either video or EEG features alone in both valence and arousal spaces. Moreover, we can narrow down the semantic gap between the low-level video features and the users' high-level emotional tags with the help of EEG features.
C1 [Wang, Shangfei; Zhu, Yachen; Wu, Guobing] Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230026, Anhui, Peoples R China.
   [Ji, Qiang] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY USA.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Rensselaer Polytechnic Institute
RP Wang, SF (corresponding author), Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230026, Anhui, Peoples R China.
EM sfwang@ustc.edu.cn; zhuyc@mail.ustc.edu.cn; guobing@mail.ustc.edu.cn;
   qji@ecse.rpi.edu
FU NSFC [61175037, 61228304]; Special Innovation Project on Speech of Anhui
   Province [11010202192]; Anhui Science and Technology Agency ll
   [1106c0805008]; Youth Creative Project of USTC
FX This paper is supported by the NSFC (61175037, 61228304), Special
   Innovation Project on Speech of Anhui Province (11010202192), Project
   from Anhui Science and Technology Agency ll(1106c0805008) and Youth
   Creative Project of USTC.
CR AlZoubi O, 2009, LECT NOTES ARTIF INT, V5866, P52, DOI 10.1007/978-3-642-10439-8_6
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], J I IMAGE INF TELEV
   [Anonymous], 2001, P 9 ACM INT C MULT
   [Anonymous], 2006, SIG COM TEC
   [Anonymous], CONT BAS MULT IND CB
   [Anonymous], 2012, Doctoral dissertation
   [Anonymous], P SPIE
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], IMPLICIT AUTOMATED E
   Arapakis I., 2009, Proceedings of the 17th ACM International Conference on Multimedia, P461, DOI DOI 10.1145/1631272.1631336
   Arapakis I, 2009, IEEE INT CON MULTI, P1440, DOI 10.1109/ICME.2009.5202773
   Arifin S., 2007, Proceedings of the 15th International Conference on Multimedia, P68
   Arifin S, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P147, DOI 10.1109/ICSC.2007.22
   Arifin S, 2006, IEEE IMAGE PROC, P433, DOI 10.1109/ICIP.2006.312450
   Arroyo I, 2009, FRONT ARTIF INTEL AP, V200, P17, DOI 10.3233/978-1-60750-028-5-17
   Bänziger T, 2009, EMOTION, V9, P691, DOI 10.1037/a0017088
   Bailenson JN, 2008, INT J HUM-COMPUT ST, V66, P303, DOI 10.1016/j.ijhcs.2007.10.011
   Banich M.T., 2010, Cognitive neuroscience
   Bulut M., 2004, P 6 INT C MULT INT, P205
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Calvo RA, 2009, LECT NOTES ARTIF INT, V5866, P62, DOI 10.1007/978-3-642-10439-8_7
   Canini L, 2013, IEEE T CIRC SYST VID, V23, P636, DOI 10.1109/TCSVT.2012.2211935
   Cardani D., 2001, Adventures in HSV Space
   Caridakis G, 2008, NEUROCOMPUTING, V71, P2553, DOI 10.1016/j.neucom.2007.11.043
   Castellano G, 2008, LECT NOTES COMPUT SC, V4868, P92, DOI 10.1007/978-3-540-85099-1_8
   Ching Hau Chan, 2005, 13th Annual ACM International Conference on Multimedia, P427, DOI 10.1145/1101149.1101243
   Chuang Ze-Jing, 2004, International Journal of Computational Linguistics and Chinese Language Processing, V9, P45
   D'Mello SK, 2010, USER MODEL USER-ADAP, V20, P147, DOI 10.1007/s11257-010-9074-4
   el Kaliouby R, 2005, LECT NOTES COMPUT SC, V3784, P582
   Haag A, 2004, LECT NOTES COMPUT SC, V3068, P36
   Hanjalic A, 2006, IEEE SIGNAL PROC MAG, V23, P90, DOI 10.1109/MSP.2006.1621452
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Heraz A, 2007, PROC WRLD ACAD SCI E, V25, P323
   Hussain MS, 2011, LECT NOTES COMPUT SC, V6974, P568, DOI 10.1007/978-3-642-24600-5_60
   Izard C.E., 1988, Emotions, cognition, and behavior
   Joho H, 2011, MULTIMED TOOLS APPL, V51, P505, DOI 10.1007/s11042-010-0632-x
   Kang H.-B., 2003, Proceedings of the 11th ACM International Conference on Multimedia, P259
   Kang HB, 2003, LECT NOTES COMPUT SC, V2911, P243
   Kapoor A., P 13 ANN ACM INT C M, P677
   Kapoor A, 2007, INT J HUM-COMPUT ST, V65, P724, DOI 10.1016/j.ijhcs.2007.02.003
   Karpouzis K, 2007, LECT NOTES COMPUT SC, V4451, P91
   Kemp AH, 2002, NEUROIMAGE, V17, P1684, DOI 10.1006/nimg.2002.1298
   Kensinger EA, 2004, REV NEUROSCIENCE, V15, P241, DOI 10.1515/REVNEURO.2004.15.4.241
   Kim J, 2007, Robust Speech Recognition and Understanding, V265, P280, DOI DOI 10.5772/4754
   Kim J, 2006, LECT NOTES ARTIF INT, V4021, P53
   Kim KH, 2004, MED BIOL ENG COMPUT, V42, P419, DOI 10.1007/BF02344719
   Knautz K, 2011, J DOC, V67, P975, DOI 10.1108/00220411111183555
   Koelstra S., 2009, Proceedings of the 3rd International Conference on Affective Computing and Intelligent Interaction, IEEE, New York, NY, P1, DOI 10.1109/ACII.2009.5349482
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Koelstra S, 2010, LECT NOTES ARTIF INT, V6334, P89, DOI 10.1007/978-3-642-15314-3_9
   Kok-Meng Ong, 2009, Information and Media Technologies, V4, P903
   Krolak-Salmon P, 2004, NEURON, V42, P665, DOI 10.1016/S0896-6273(04)00264-8
   Kulic D, 2007, IEEE T ROBOT, V23, P991, DOI 10.1109/TRO.2007.904899
   Liu CC, 2008, INT J HUM-COMPUT ST, V66, P662, DOI 10.1016/j.ijhcs.2008.04.003
   Lu YJ, 2011, MULTIMED TOOLS APPL, V51, P247, DOI 10.1007/s11042-010-0621-0
   Mansoorizadeh M, 2010, MULTIMED TOOLS APPL, V49, P277, DOI 10.1007/s11042-009-0344-2
   MCLAREN K, 1976, J SOC DYERS COLOUR, V92, P338
   Molau S, 2001, INT CONF ACOUST SPEE, P73, DOI 10.1109/ICASSP.2001.940770
   Money AG, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823751
   Money AG, 2008, LECT NOTES COMPUT SC, V4868, P194, DOI 10.1007/978-3-540-85099-1_17
   Murphy K.P., 1998, INFERENCE LEARNING H
   Nasoz F., 2004, Cognition, Technology & Work, V6, P4, DOI 10.1007/s10111-003-0143-x
   Oliveira Eva, 2011, P 9 EUR C INT TV VID, P105
   Pantic M, 2009, IEEE SIGNAL PROC MAG, V26, P173, DOI 10.1109/MSP.2009.934186
   Peng WT, 2011, IEEE T MULTIMEDIA, V13, P539, DOI 10.1109/TMM.2011.2131638
   Rasheed Z, 2005, IEEE T CIRC SYST VID, V15, P52, DOI 10.1109/TCSVT.2004.839993
   Schaefer A, 2010, COGNITION EMOTION, V24, P1153, DOI 10.1080/02699930903274322
   Sebe N, 2005, PROC SPIE, V5670, P56, DOI 10.1117/12.600746
   Smeaton AF, 2009, INT WORK CONTENT MUL, P162, DOI 10.1109/CBMI.2009.21
   Soleymani M., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P803, DOI 10.1109/FG.2011.5771352
   Soleymani M., 2009, Affective Computing and Intelligent Interaction and Workshops, P1
   Soleymani M., 2008, P 2 ACM WORKSHOP MUL, P32, DOI DOI 10.1145/1460676.1460684
   Sun K, 2007, LECT NOTES COMPUT SC, V4738, P594
   Teixeira RMA, 2012, MULTIMED TOOLS APPL, V61, P21, DOI 10.1007/s11042-010-0702-0
   Vapnik V, 2009, NEURAL NETWORKS, V22, P544, DOI 10.1016/j.neunet.2009.06.042
   Wagner J, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P941
   Wang CW, 2007, LECT NOTES COMPUT SC, V4351, P606
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P689, DOI 10.1109/TCSVT.2006.873781
   Wang SF, 2011, KANSEI ENGINEERING AND SOFT COMPUTING: THEORY AND PRACTICE, P126, DOI 10.4018/978-1-61692-797-4.ch007
   Watanapa SC, 2008, IEICE T INF SYST, VE91D, P1562, DOI 10.1093/ietisy/e91-d.5.1562
   Wei CY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P831, DOI 10.1109/ICME.2004.1394329
   Winoto P, 2010, EXPERT SYST APPL, V37, P6086, DOI 10.1016/j.eswa.2010.02.117
   Wrase J, 2003, NEUROSCI LETT, V348, P41, DOI 10.1016/S0304-3940(03)00565-2
   Xu M., 2008, Proceeding of the 16th ACM International Conference on Multimedia, P677, DOI DOI 10.1145/1459359.1459457
   Xu M, 2014, MULTIMED TOOLS APPL, V70, P757, DOI 10.1007/s11042-012-1046-8
   Xu M, 2013, SIGNAL PROCESS, V93, P2140, DOI 10.1016/j.sigpro.2012.06.026
   Yazdani J.-S. Lee., 2009, Proc. SIGMM Workshop on Social media, P81
   Yoo HW, 2007, MULTIMED TOOLS APPL, V34, P317, DOI 10.1007/s11042-007-0109-8
   Zhang SL, 2010, IEEE T MULTIMEDIA, V12, P510, DOI 10.1109/TMM.2010.2059634
   Zhang SL, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1369, DOI 10.1109/ICME.2008.4607698
NR 91
TC 38
Z9 42
U1 6
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1257
EP 1283
DI 10.1007/s11042-013-1450-8
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300012
DA 2024-07-18
ER

PT J
AU Guldogan, E
   Olsson, T
   Lagerstam, E
   Gabbouj, M
AF Guldogan, Esin
   Olsson, Thomas
   Lagerstam, Else
   Gabbouj, Moncef
TI Instance based personalized multi-form image browsing and retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image indexing and retrieval; Image browsing; Implicit
   feedback; Personalized and adaptive image image browsing
ID RELEVANCE FEEDBACK; SYSTEM
AB It is important to adapt and personalize image browsing and retrieval systems based on users' preferences for improved user experience and satisfaction. In this paper, we present a novel instance based personalized multi-form image representation with implicit relevance feedback and adaptive weighting approach for image browsing and retrieval systems. In the proposed system, images are grouped into forms, which represent different information on images such as location, content etc. We conducted user interviews on image browsing, sharing and retrieval systems for understanding image browsing and searching behaviors of users. Based on the insights gained from the user interview study we propose an adaptive weighting method and implicit relevance feedback for multi-form structures that aim to improve the efficiency and accuracy of the system. Statistics of the past actions are considered for modeling the target of the users. Thus, on each iteration weights of the forms are updated adaptively. Moreover, retrieval results are modified according to the users' preferences on iterations in order to improve personalized user experience. The proposed method has been evaluated and results are illustrated in the paper. It is shown that, satisfactory improvements can be achieved with proposed approaches in the multi-form scheme.
C1 [Guldogan, Esin; Gabbouj, Moncef] Tampere Univ Technol, Dept Signal Proc, FIN-33101 Tampere, Finland.
   [Olsson, Thomas] Tampere Univ Technol, Unit Human Ctr Technol, FIN-33101 Tampere, Finland.
   [Lagerstam, Else] Tampere Univ Technol, Unit Human Ctr Technol, Dept Software Syst, FIN-33101 Tampere, Finland.
C3 Tampere University; Tampere University; Tampere University
RP Guldogan, E (corresponding author), Tampere Univ Technol, Dept Signal Proc, FIN-33101 Tampere, Finland.
EM esin.guldogan@tut.fi; moncef.gabbouj@tut.fi
RI Gabbouj, Moncef/G-4293-2014; Olsson, Thomas/N-9353-2015
OI Gabbouj, Moncef/0000-0002-9788-2323; Olsson, Thomas/0000-0002-1106-2544
FU Devices and Interoperability Ecosystem-DIEM-project; Finnish Funding
   Agency for Technology and Innovation
FX This work is supported by Devices and Interoperability
   Ecosystem-DIEM-project is part of the Finnish ICT SHOK program
   coordinated by TIVIT and funded by Finnish Funding Agency for Technology
   and Innovation.
CR [Anonymous], IEEE CVPR 2004 WORKS
   [Anonymous], 2008, PROC 3 INT C DIGIT I, DOI DOI 10.1145/1413634.1413687
   Benbunan-Fich R, 2007, J STRATEGIC INF SYST, V16, P393, DOI 10.1016/j.jsis.2007.08.002
   Bockting S, 2008, P DUTCH BELG INF RET, P15
   Covey DT, 2002, COUNCIL LIB INFORM R
   Djordjevic D, 2007, IEEE T CIRC SYST VID, V17, P313, DOI 10.1109/TCSVT.2007.890634
   Eakins JP, 2004, LECT NOTES COMPUT SC, V3115, P628
   Gray W.D., 2001, INT ENCY ERGONOMICS, V1, P387
   Guldogan E., 2010, Proceedings 2010 5th International Workshop on Semantic Media Adaptation and Personalization (SMAP 2010), P64, DOI 10.1109/SMAP.2010.5706855
   Guldogan E, 2010, INT WORKSH IM AN MUL, P1
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jaimes A, 2006, PROC SPIE, V6061, DOI 10.1117/12.660255
   Jing F, 2004, IEEE T CIRC SYST VID, V14, P672, DOI 10.1109/TCSVT.2004.826775
   Kelly Diane., 2001, Proceedings of SIGIR '01, P408, DOI [10.1145/383952.384045, DOI 10.1145/383952.384045]
   Kim YH, P IEEE REG 10 C TENC, V1, P439
   Kosch H, 2005, P INT ASS SCI TECHN
   Kuniavsky M., 2003, OBSERVING USER EXPER, P129
   Laaksonen J, 2000, PATTERN RECOGN LETT, V21, P1199, DOI 10.1016/S0167-8655(00)00082-9
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Manavoglu E, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P203
   Moghaddam B, 2004, INT J COMPUT VISION, V56, P109, DOI 10.1023/B:VISI.0000004834.62090.74
   Piras L, 2009, 2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES, P238, DOI 10.1109/WIAMIS.2009.5031477
   Rao Y, 2006, LECT NOTES COMPUT SC, V4071, P350
   Robertson S., 2001, Lectures on Information Retrieval. Third European Summer-School, ESSIR 2000. Revised Lectures (Lecture Notes in Computer Science Vol.1980), P81
   Sandhaus P, 2011, MULTIMED TOOLS APPL, V51, P5, DOI 10.1007/s11042-010-0673-1
   Shen X, P 28 ANN INT ACM SIG, V43, P43
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Torres JM, 2000, P WORKSH COMP SEM NE
   Zhou X.S., 2000, PROC SPIE IMAGE VIDE, P24
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 30
TC 4
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1087
EP 1104
DI 10.1007/s11042-012-1249-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000006
DA 2024-07-18
ER

PT J
AU Shirahama, K
   Matsuoka, Y
   Uehara, K
AF Shirahama, Kimiaki
   Matsuoka, Yuta
   Uehara, Kuniaki
TI Hybrid negative example selection using visual and conceptual features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Negative example selection; Partially supervised learning; Query by
   example; Visual feature; Conceptual feature
ID SUPPORT VECTOR MACHINES; CLASSIFICATION
AB An application of Query-By-Example (QBE) is presented where shots that are visually similar to provided example shots are retrieved. To implement QBE, counter-example shots are required to accurately distinguish shots that are relevant to the query from those that are not (Li and Snoek (2009), Yu et al. (2004)). However, there are usually a huge number of shots, not relevant to a particular query, which can serve as counter-example shots. It is difficult for a user to provide counter-example shots that would aid retrieval. Thus, we developed a QBE method based on partially supervised learning where a retrieval model is constructed by selecting counter-example shots from shots without user supervision. To ensure the speed and accuracy of the QBE method, we select a small number of counter-example shots that are visually similar to given example shots but irrelevant to the query. Such shots are useful for characterizing the boundary between relevant and irrelevant shots. For our method, we first filter shots that are visually dissimilar to example shots based on SVMs on a visual feature. Then we filter shots relevant to the query based on concept detection results from pre-constructed classifiers. Shots that pass the above two tests are considered as counter-example shots. Experimental results obtained using TRECVID 2009 video data validate the effectiveness of our method.
C1 [Shirahama, Kimiaki] Kobe Univ, Grad Sch Econ, Nada Ku, Kobe, Hyogo 6578501, Japan.
   [Matsuoka, Yuta] Kobe Univ, Grad Sch Engn, Nada Ku, Kobe, Hyogo 6578501, Japan.
   [Uehara, Kuniaki] Kobe Univ, Grad Sch Syst Informat, Nada Ku, Kobe, Hyogo 6578501, Japan.
C3 Kobe University; Kobe University; Kobe University
RP Shirahama, K (corresponding author), Kobe Univ, Grad Sch Econ, Nada Ku, 2-1 Rokkodai, Kobe, Hyogo 6578501, Japan.
EM shirahama@econ.kobe-u.ac.jp; matuoka@ai.cs.scitec.kobe-u.ac.jp;
   uehara@kobe-u.ac.jp
FU Ministry of Internal Affairs and Communications, Japan; Grants-in-Aid
   for Scientific Research [26280040, 23300038] Funding Source: KAKEN
FX This research is supported in part by Strategic Information and
   Communications R&D Promotion Programme (SCOPE) by the Ministry of
   Internal Affairs and Communications, Japan.
CR Akbani R, 2004, LECT NOTES COMPUT SC, V3201, P39, DOI 10.1007/978-3-540-30115-8_7
   [Anonymous], 2006, Advances in neural information processing systems
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], P ACM MULT
   [Anonymous], 2007, CIVR '07
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Elkan C., 2008, P ACM SIGKDD, P213, DOI 10.1145/1401890.1401920
   Fung GPC, 2006, IEEE T KNOWL DATA EN, V18, P6
   Komorowski J, 2002, HDB DATA MINING KNOW
   Le D, 2009, P TRECVID 2009, P281
   Liu B., 2002, ICML, P387
   Natsev A., 2005, 13th Annual ACM International Conference on Multimedia, P598, DOI 10.1145/1101149.1101288
   Ngo C.W., 2009, Proc. of TRECVID, P415
   Peng Y., 2010, P INT C MULT INF RET, P111
   Schohn G, 2000, P 17 INT C MACHINE L, P839
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shirahama K, 2011, LECT NOTES COMPUT SC, V6523, P96
   Snoek C., 2009, P TRECVID2009, P226
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Tax DMJ, 2002, J MACH LEARN RES, V2, P155, DOI 10.1162/15324430260185583
   Tesic J., 2007, CIVR '07: Proceedings of the 6th ACM international conference on Image and video retrieval, P595
   Tsang IW, 2005, J MACH LEARN RES, V6, P363
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Yan Rong., 2003, P 11 ACM INT C MULTI, P343
   Yom-Tov E., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P512, DOI 10.1145/1076034.1076121
   Yu HJ, 2004, IEEE T KNOWL DATA EN, V16, P70, DOI 10.1109/TKDE.2004.1264823
   Yuan Jinhui., 2006, P 14 ANN ACM INT C M, P441
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhao Z, 2009, P TRECVID 2009, P42
NR 31
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 967
EP 989
DI 10.1007/s11042-011-0886-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000001
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, N
   Li, Q
   Abd El-Latif, AA
   Zhang, TJ
   Niu, XM
AF Wang, Ning
   Li, Qiong
   Abd El-Latif, Ahmed A.
   Zhang, Tiejun
   Niu, Xiamu
TI Toward accurate localization and high recognition performance for noisy
   iris images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris recognition; Iris localization; Navier-Stokes(NS); Pb edge
   detection; Hough transforms; 1D Log-Gabor
AB Iris recognition plays an important role in biometrics. Until now, many scholars have made different efforts in this field. However, the recognition performances of most proposed methods degrade dramatically when the image contains some noise, which inevitably occurs during image acquisition such as reflection spots, inconsistent illumination, eyelid, eyelash, hair, etc. In this paper, an accurate iris localization and high recognition performance approach for noisy iris images is presented. After filling the reflection spots using the inpainting method which is based on Navier-Stokes (NS) equations, the Probable boundary (Pb) edge detection operator is used to detect pupil edge initially, which can eliminate the interference of inconsistent illumination, eyelid, eyelash and hair. Besides, the accurate circle parameters are obtained in delicately to reduce the input space of Hough transforms. The iris feature code is constructed based on 1D Log-Gabor filter. Our thorough experimental results on the challenging iris image database CASIA-Iris-Thousand achieve an EER of 1.8272 %, which outperforms the state-of-the-art methods.
C1 [Wang, Ning; Li, Qiong; Abd El-Latif, Ahmed A.; Zhang, Tiejun; Niu, Xiamu] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
   [Abd El-Latif, Ahmed A.] Menoufia Univ, Fac Sci, Dept Math, Shibin Al Kawm 32511, Egypt.
C3 Harbin Institute of Technology; Egyptian Knowledge Bank (EKB); Menofia
   University
RP Li, Q (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
EM ning.wang@ict.hit.edu.cn; qiong.li@hit.edu.cn; ahmed_rahiem@yahoo.com;
   tiejun.zhang@ict.hit.edu.cn; xiamu.niu@hit.edu.cn
RI Zhang, Tiejun/HDM-7091-2022; Abd El-Latif, Ahmed A. A./GRO-1613-2022
OI Abd El-Latif, Ahmed A. A./0000-0002-5068-2033
FU National Natural Science Foundation of China [60832010, 61100187];
   Fundamental Research Funds for the Central Universities [HIT. NSRIF.
   2010046, HIT. NSRIF. 2013061]
FX The authors would like to thank the reviewers for their valuable
   comments which are greatly helpful to improve the clarity and quality of
   this work. This work is supported by the National Natural Science
   Foundation of China (Grant Number: 60832010, 61100187) and the
   Fundamental Research Funds for the Central Universities (Grant Number:
   HIT. NSRIF. 2010046, HIT. NSRIF. 2013061).
CR [Anonymous], 2009, P 2009 1 IEEE INT C
   Bertalmío M, 2001, PROC CVPR IEEE, P355
   Cho DH, 2005, Sixth International Conference on Software Engineerng, Artificial Intelligence, Networking and Parallel/Distributed Computing and First AICS International Workshop on Self-Assembling Wireless Networks, Proceedings, P254
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2000, 482 CAMBR U COMP LAB
   Dong WB, 2011, IEEE T PATTERN ANAL, V33, P1744, DOI 10.1109/TPAMI.2010.227
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Feng JJ, 2011, IEEE T PATTERN ANAL, V33, P209, DOI 10.1109/TPAMI.2010.77
   Feng XH, 2006, INT C PATT RECOG, P553
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594
   He ZF, 2009, IEEE T PATTERN ANAL, V31, P1670, DOI 10.1109/TPAMI.2008.183
   He ZY, 2008, INT C PATT RECOG, P1401
   HEEGER D, 1995, P SIGGRAPH
   Hollingsworth KP, 2011, IEEE T PATTERN ANAL, V33, P2465, DOI 10.1109/TPAMI.2011.89
   Lee JE, 2008, 2008 BIOMETRICS SYMPOSIUM (BSYM), P1, DOI [10.1109/PLASMA.2008.4591032, 10.1109/BSYM.2008.4655515]
   Liu XM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P118
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Puzicha J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1165, DOI 10.1109/ICCV.1999.790412
   Puzicha J, 1997, PROC CVPR IEEE, P267, DOI 10.1109/CVPR.1997.609331
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Scott F, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS, P84, DOI 10.1109/CIMSA.2007.4362544
   Sheela SV., 2010, INT J COMPUTER APPL, V3, P19
   Shen WC, 1997, P IEEE, V85, P1464, DOI 10.1109/5.628719
   Tisse C., 2002, PROCVISION INTERFACE, P294
   Trucco E, 2005, PATTERN ANAL APPL, V8, P247, DOI 10.1007/sl0044-005-0004-8
   Uhl A, 2012, LECT NOTES COMPUT SC, V7325, P1, DOI 10.1007/978-3-642-31298-4_1
   Wang GS, 2009, IEEC 2009: FIRST INTERNATIONAL SYMPOSIUM ON INFORMATION ENGINEERING AND ELECTRONIC COMMERCE, PROCEEDINGS, P791, DOI 10.1109/IEEC.2009.172
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Yahya Abdulsamad Ebrahim., 2010, 2010 International Symposium in Information Technology, P1, DOI DOI 10.1109/ITSIM.2010.5561405
NR 31
TC 40
Z9 40
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1411
EP 1430
DI 10.1007/s11042-012-1278-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000020
DA 2024-07-18
ER

PT J
AU Bilandzic, M
   Foth, M
AF Bilandzic, Mark
   Foth, Marcus
TI Learning beyond books-strategies for ambient media to improve libraries
   and collaboration spaces as interfaces for social learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Commons 2.0; Library design; e-Library; Bookless library; Coworking;
   Collaboration; Social learning; Co-presence; Shared encounters;
   Serendipity; Urban informatics; Ambient media; Embodied interaction;
   Locative media
ID MOBILE; SERENDIPITY; INFORMATION; WEB
AB With the advent of digital media and online information resources, public libraries as physical destinations for information access are being increasingly challenged. As a response, many libraries follow the trend of removing bookshelves in order to provide more floorspace for social interaction and collaboration. Such spaces follow a Commons 2.0 model: they are designed to support collaborative work and social learning. The acquisition of skills and knowledge is facilitated as a result of being surrounded by and interacting with a community of likeminded others. Based on the results of a case study on a Commons 2.0 library space, this paper describes several issues of collaboration and social learning in public library settings. Acknowledging the significance of the architectural characteristics of the physical space, we discuss opportunities for ambient media to better reflect the social attributes of the library as a place; i.e. amplify the sense of other co-present library visitors and provide opportunities for shared encounters and conversations, which would remain invisible otherwise. We present the design of a user check-in system for improving the library as a physical destination for social learning, sharing, and inspiration for and by the community.
C1 [Bilandzic, Mark; Foth, Marcus] Queensland Univ Technol, Sch Design, Urban Informat Res Lab, Brisbane, Qld 4001, Australia.
C3 Queensland University of Technology (QUT)
RP Bilandzic, M (corresponding author), Queensland Univ Technol, Sch Design, Urban Informat Res Lab, Brisbane, Qld 4001, Australia.
EM mark.bilandzic@qut.edu.au; m.foth@qut.edu.au
RI Foth, Marcus/I-9914-2012
OI Foth, Marcus/0000-0001-9892-0208
CR Alexander C., 1977, PATTERN LANGUAGE TOW, V2
   Anderson C., 2006, LONG TAIL WHY FUTURE
   [Anonymous], 2008, BEHAV PUBLIC PLACES
   [Anonymous], 1997, VYGOTSKY FORMATION M
   [Anonymous], 2003, P SIGCHI C HUM FACT
   [Anonymous], TITLE ERROR
   Benedict Anderson., 2006, IMAGINED COMMUNITIES
   Bilandzic Mark, 2008, Proceedings of the 7th ACM Conference on Designing Interactive Systems. DIS 2008, P174, DOI 10.1145/1394445.1394464
   Bilandzic M., 2011, J COMMUNITY INFORM, V7
   Bilandzic M, 2012, INT J HUM-COMPUT ST, V70, P66, DOI 10.1016/j.ijhcs.2011.08.004
   Björneborn L, 2008, INFORM RES, V13
   Bjorneborn L., 2010, P 5 INT C PERS TECHN
   Brand S, 1994, BUILDING WHAT HAPPEN
   Burgess JeanE., 2006, EVERYDAY CREATIVITY
   Caldwell G., 2012, MED ARCH BIENN 2012
   Certeau M., 1984, The practise of everyday life
   Churchill E., 2003, PUBLIC SITUATED DISP
   de Botton Alain., 2006, ARCHITECTURE HAPPINE
   Dieberger A, 1997, INT J HUM-COMPUT ST, V46, P805, DOI 10.1006/ijhc.1996.0111
   Dieberger A, 1995, LECT NOTES COMPUT SC, V988, P93
   DOURISH P, 1994, HCI 94 GLASG UK
   Dourish P., 2001, ACTION IS FDN EMBODI
   Eagle N, 2005, IEEE PERVAS COMPUT, V4, P28, DOI 10.1109/MPRV.2005.37
   Eagle N, 2004, MIT SLOAN MANAGE REV, V46, P10
   Ebner M, 2005, IEEE MULTIMEDIA, V12, P70, DOI 10.1109/MMUL.2005.74
   Falk J, 1999, LECT NOTES COMPUT SC, V1707, P274
   Foth M, 2011, FROM SOCIAL BUTTERFLY TO ENGAGED CITIZEN: URBAN INFORMATICS, SOCIAL MEDIA, UBIQUITOUS COMPUTING, AND MOBILE TECHNOLOGY TO SUPPORT CITIZEN ENGAGEMENT, P1
   Foth M., 2008, MINDTREK 08 P 12 INT, P179, DOI [10.1145/1457199.1457239, DOI 10.1145/1457199.1457239]
   Foth M, 2007, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON INTELLECTUAL CAPITAL, KNOWLEDGE MANAGEMENT AND ORGANISATIONAL LEARNING, P127
   Gordon E, 2011, NET LOCALITY LOCATIO
   Greenberg S, 2001, P SIGCHI C HUM FACT
   Guzman ESD, 2004, CHI 04 HUM FACT COMP
   Hansen M, 2011, SPEED VEST
   Harrison Steve R, 1996, P 1996 ACM C COMP SU, V96, P67, DOI [DOI 10.1145/240080.240193, 10.1145/240080.240193]
   Hartwig S, 2006, NRCTR2007003
   Hazlewood WR, 2008, CHI 08 HUM FACT COMP
   Hook K., 2003, DESIGNING INFORM SPA
   Humphreys L, 2010, NEW MEDIA SOC, V12, P763, DOI 10.1177/1461444809349578
   Jaokar A, 2006, MOBILE WEB 2 0 INNOV
   Jenkins Henry., 2006, FANS BLOGGERS GAMERS
   KJELDSKOV J, 2005, P 7 INT C HUM COMP I, P23
   Kolbitsch J, 2006, J UNIVERS COMPUT SCI, V12, P187
   Lawson B., 2012, LANGUAGE SPACE
   Lefebvre H., 1991, PRODUCTION SPACE
   Lindahl C, 2003, COMPUTER, V36, P114, DOI 10.1109/MC.2003.1244542
   Lugmayr A, 2009, MULTIMED TOOLS APPL, V44, P337, DOI 10.1007/s11042-009-0282-z
   McCarthy JF, 2003, KIS CO SUP COOP WORK, V2, P283
   McDonald A., 2006, LIBER Quarterly, V16, P104
   Milgram S., 1992, INDIVIDUAL SOCIAL WO
   Motschnig-Pitrik R., 2002, Educational Technology & Society, V5
   NIEGAARD H, 2009, LIB SPACE INSPIRATIO
   Nischelwitzer A, 2007, UNIVERSAL ACCESS IN HUMAN-COMPUTER INTERACTION: APPLICATIONS AND SERVICES, PT 3, PROCEEDINGS, P728
   Norman D., 2010, Living with Complexity
   Norman D. A., 1999, Interactions, V6, P38, DOI 10.1145/301153.301168
   O'Reilly T., 2006, What Is Web 2.0: Design patterns and business models for the next generation of software
   Paulos E, 2004, FAMILIAR STRANGER AN, P223
   Rogers Y, 2010, P 12 ACM C UB COMP C
   Ruskin John., 1849, Seven Lamps of Architecture
   Scheible J, 2009, LEONARDO, V42, P332, DOI 10.1162/leon.2009.42.4.332
   Scherr R, 2006, PLACES-FORUM ENVIRON, V18, P6
   Schroeter R, 2011, PLANN I AUSTR NAT C
   Sinclair B, 2007, EDUCAUSE Q MAG, V30
   Sommer R., 1969, Personal Space: Behavioural Basis of Design
   Tuan Y.F., 1977, Space and Place: The Perspective of Experience
   Unconventionbrisbane, 2010, EDGE
   Veerasawmy R, 2010, OZCHI 2010 BRISB AUS
   Villareal L., 2004, SUPERCLUSTER
   Vygotsky L.S., 1979, MIND SOC
   Willis K, 2010, SHARED ENCOUNTERS CO
   Wired, 1998, LOV JAP STYL
   Wisneski C, 1998, LECT NOTES COMPUT SC, V1370, P22
NR 71
TC 12
Z9 14
U1 4
U2 71
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 77
EP 95
DI 10.1007/s11042-013-1432-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700005
DA 2024-07-18
ER

PT J
AU Choi, SP
   Lee, S
   Jung, H
   Song, SK
AF Choi, Sung-Pil
   Lee, Seungwoo
   Jung, Hanmin
   Song, Sa-kwang
TI An intensive case study on kernel-based relation extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Relation extraction; Kernel methods; Text mining; Information
   extraction; Machine learning
ID PERCEPTRON
AB Relation extraction refers to a method of efficiently detecting and identifying predefined semantic relationships within a set of entities in text documents. Numerous relation extractionfc techniques have been developed thus far, owing to their innate importance in the domain of information extraction and text mining. The majority of the relation extraction methods proposed to date is based on a supervised learning method requiring the use of learning collections; such learning methods can be classified into feature-based, semi-supervised, and kernel-based techniques. Among these methods, a case analysis on a kernel-based relation extraction method, considered the most successful of the three approaches, is carried out in this paper. Although some previous survey papers on this topic have been published, they failed to select the most essential of the currently available kernel-based relation extraction approaches or provide an in-depth comparative analysis of them. Unlike existing case studies, the study described in this paper is based on a close analysis of the operation principles and individual characteristics of five vital representative kernel-based relation extraction methods. In addition, we present deep comparative analysis results of these methods. In addition, for further research on kernel-based relation extraction with an even higher performance and for general high-level kernel studies for linguistic processing and text mining, some additional approaches including feature-based methods based on various criteria are introduced.
C1 [Choi, Sung-Pil; Lee, Seungwoo; Jung, Hanmin; Song, Sa-kwang] KISTI, Informat SW Res Ctr, Taejon, South Korea.
C3 Korea Institute of Science & Technology Information (KISTI)
RP Song, SK (corresponding author), KISTI, Informat SW Res Ctr, 335 Gwahangno, Taejon, South Korea.
EM spchoi@kisti.re.kr; swlee@kisti.re.kr; jhm@kisti.re.kr;
   esmallj@kisti.re.kr
CR Agichtein E., 2000, ACM 2000. Digital Libraries. Proceedings of the Fifth ACM Conference on Digital Libraries, P85, DOI 10.1145/336597.336644
   [Anonymous], 2009, P 2009 C EMPIRICAL M
   [Anonymous], 2004, P 42 ANN M ASS COMPU, DOI DOI 10.3115/1218955.1219009
   Aone C, 2000, 6 APPL NAT LANG PROC
   Bach N., 2007, LIT REV LANGUAGE STA
   Brin S, 1999, LECT NOTES COMPUT SC, V1590, P172
   Bunescu R, 2006, P 9 C NAT LANG LEARN
   Bunescu RC, 2005, P C HUM LANG TECHN E, P724, DOI DOI 10.3115/1220575.1220666
   Charniak E, 2001, P 39 ANN M ASS COMP
   Choi S-P, 2009, J KIISE SOFTW APPL, V36, P8
   Collins M., 2001, NIPS 2001
   Collins M., 1997, P 35 ANN M ACL JOINT
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Etzioni O, 2005, ARTIF INTELL, V165, P91, DOI 10.1016/j.artint.2005.03.001
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062
   Fundel K, 2007, BIOINFORMATICS, V23, P365, DOI 10.1093/bioinformatics/btl616
   Gärtner T, 2003, LECT NOTES ARTIF INT, V2777, P129, DOI 10.1007/978-3-540-45167-9_11
   HOCKENMAIER J, 2002, P 40 ANN M ASS COMP
   Jiang J., 2007, HUMAN LANGUAGE TECHN, P22
   JOACHIMS T, 1998, ECML 1998
   Kambhatla N., 2004, ACL 2004
   Li JX, 2008, J AM SOC INF SCI TEC, V59, P756, DOI 10.1002/asi.20791
   Li W., 2008, Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies: Short Papers, P89
   Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687
   Min Z, 2008, INFORM PROCESS MANAG, V44, P687, DOI 10.1016/j.ipm.2007.07.013
   Mintz M., 2009, P JOINT C 47 ANN M A, V2, P1003
   Moncecchi G., 2010, WORKSH NLP WEB BAS T
   MOSCHITTI A, 2004, ACL 2004
   Nguyen D.P., 2007, IJCAI WORKSH TEXT MI
   Ratnaparkhi Adwait., 1996, EMPIRICAL METHODS NA
   Reichartz F, 2009, LECT NOTES ARTIF INT, V5782, P270, DOI 10.1007/978-3-642-04174-7_18
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Yarowsky D., 1995, 33 ANN M ASS COMPUTA, P189, DOI DOI 10.3115/981658.981684
   Yates A., 2007, P HUMAN LANGUAGE TEC, P25
   Zelenko D, 2003, J MACH LEARN RES, V3, P1083, DOI 10.1162/153244303322533205
   Zhang M, 2006, 21 INT C COMP LING 4, P825
   Zhang Min, 2006, Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, P288, DOI DOI 10.3115/1220835.1220872
   Zhao S, 2005, ACL 2005
   Zhou G, 2007, 2007 JOINT C EMP MET
   ZHOU GD, 2005, ACL 2005
NR 42
TC 8
Z9 11
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 741
EP 767
DI 10.1007/s11042-013-1380-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400022
DA 2024-07-18
ER

PT J
AU Lugmayr, A
   Serral, E
   Scherp, A
   Pogorelc, B
   Mustaquim, M
AF Lugmayr, Artur
   Serral, Estefania
   Scherp, Ansgar
   Pogorelc, Bogdan
   Mustaquim, Moyen
TI Ambient media today and tomorrow What have ambient media in common? What
   are ambient media today? Where will ambient media be in 2020?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ambient media; Ubiquitous computation; Pervasive computation;
   Human-computer-interaction; Ambient assisted living; IPTV; Shape
   shifting media; User experience; Smart environments; Smart cities; Smart
   urban environments
ID SPECIAL-ISSUE; FUTURE; PHILOSOPHY
AB Ambient media are novel, and this new media form alters our daily-living experience in many ways. Ambient media refer to media environments that are embedded throughout the natural space where people are following their daily activities. These digital media environments become part of the living space and altering our daily-living experience in many ways. The goal of this article is to elaborate the status of ambient media today and to forecast how ambient media will develop in the next decade. It clearly identifies megatrends and develops scenarios (e. g., ambient-assisted living) for the future. These scenarios shall shed light on the potentials and give a glimpse on the potential future development of embedding digital objects into the daily living space. This paper is based on a future wheel approach and on an analysis of the results of an expert workshop. The article concludes with a discussion of the results and an evaluation of the impact of each scenario.
C1 [Serral, Estefania] Vienna Univ Technol, Christian Doppler Lab Software Engn Integrat Flex, A-1060 Vienna, Austria.
   [Pogorelc, Bogdan] Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana 1000, Slovenia.
   [Pogorelc, Bogdan] Spica Int Doo, Ljubljana 1231, Slovenia.
   [Pogorelc, Bogdan] Jozef Stefan Int Postgrad Sch, Ljubljana 1000, Slovenia.
   [Lugmayr, Artur] Tampere Univ Technol, EMMi Lab, FIN-33100 Tampere, Finland.
   [Scherp, Ansgar] Univ Mannheim, D-68131 Mannheim, Germany.
   [Mustaquim, Moyen] Uppsala Univ, Dept Informat & Media, S-75120 Uppsala, Sweden.
C3 Technische Universitat Wien; Slovenian Academy of Sciences & Arts
   (SASA); Jozef Stefan Institute; Slovenian Academy of Sciences & Arts
   (SASA); Jozef Stefan Institute; Tampere University; University of
   Mannheim; Uppsala University
RP Lugmayr, A (corresponding author), Tampere Univ Technol, EMMi Lab, POB 553, FIN-33100 Tampere, Finland.
EM lartur@acm.org; estefania.serral@tuwien.ac.at; scherp@uni-koblenz.de;
   bogdan.pogorelc@ijs.si; moyen.mustaquim@im.uu.se
RI Lugmayr, Artur/G-4357-2014; Serral, Estefanía/I-8123-2018; Scherp,
   Ansgar/Q-2315-2016; Lugmayr, Artur/AAY-7738-2020; Mustaquim, Moyen
   M/C-9322-2014
OI Lugmayr, Artur/0000-0001-6994-4470; Serral,
   Estefanía/0000-0001-7579-910X; 
FU European Union, the European Social Fund
FX This work was partially financed by the European Union, the European
   Social Fund. The operation was implemented in the framework of the
   Operational Programme for Human Resources Development for the Period
   2007-2013, Priority axis 1: Promoting entrepreneurship and adaptability,
   Main type of activity 1.1.: Experts and researchers for competitive
   enterprises.
CR Aladwani AM, 2002, INFORM MANAGE-AMSTER, V39, P467, DOI 10.1016/S0378-7206(01)00113-6
   Andler N, 2011, TOOLS PROJECT MANAGE
   [Anonymous], 2005, HDB HUMAN FACTORS ER
   [Anonymous], 2006, VLDB'06: Proceedings of the 32nd international conference on Very large data bases
   [Anonymous], 2010, SATISFACTION BEHAV P, DOI DOI 10.4324/9781315700892
   [Anonymous], 2000, HDB VALUE CHAIN RES, DOI DOI 10.1057/9781137373755.0007
   [Anonymous], 1995, CREATING CUSTOMER VA
   [Anonymous], 1998, Computational Intelligence: A Logical Approach
   [Anonymous], 2012, TELEGRAPH
   [Anonymous], 1994, The New Production of Knowledge: The Dynamics of Science and Research in Contemporary Societies
   [Anonymous], 2010, PRINC UN DES VERS 2
   Auinger A, 2011, LECT NOTES COMPUT SC, V6769, P3, DOI 10.1007/978-3-642-21675-6_1
   Baldauf M, 2012, P INT C PERV COMP NE
   Bilandzic M, 2011, 4 SEM AMB MED EXP SA
   Cheng E, 2011, 4 SEM AMB MED EXP SA
   Cheok AD, 2011, 2010 IEEE INT S MIX, P1
   Clarke I., 2001, J BUS STRATEG, V18, P133
   Dey AK, 2001, HUM-COMPUT INTERACT, V16, P97, DOI 10.1207/S15327051HCI16234_02
   Dietz PH, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P55
   Dutton W, 2004, UNESCO PUBLICATIONS
   Feldmann V, 2005, INFORM AGE ECON, P1
   Floridi L, 2003, MIND MACH, V13, P459, DOI 10.1023/A:1026241332041
   Floridi L, 2009, INFORM SOC, V25, P153, DOI 10.1080/01972240902848583
   Foster S, 2011, 4 SEM AMB MED EXP SA
   Gangadhar G, 2011, INT J COMPUT APPL, P65
   Gasson S., 2003, J INF TECHNOL THEORY, V5, P29
   Gershenfeld N, 2004, SCI AM, V291, P76, DOI 10.1038/scientificamerican1004-76
   Giffinger Rudolf., 2007, City-ranking of European medium-sized cities
   Golja M, 2011, 4 SEM AMB MED EXP SA
   Hassenzahl M, 2010, INTERACT COMPUT, V22, P353, DOI 10.1016/j.intcom.2010.04.002
   Holzinger A, 2011, UNIVERSAL ACCESS INF, V10, P245, DOI 10.1007/s10209-010-0212-x
   Holzinger A, 2011, J BIOMED INFORM, V44, P968, DOI 10.1016/j.jbi.2011.07.003
   Holzinger K, 2012, DCNET ICE B OPTICS, P115
   IBM, SMART CIT
   Jenkins Henry, 2006, CONVERGENCE CULTURE
   Jeung H, 2010, EFFECTIVE METADATA M, P107
   Kelly B, 2009, HEALTH PROMOT INT, V24, P120, DOI 10.1093/heapro/dap012
   Kjeldskov J, 2004, P AS PAC C HUM COMP
   Kleinberger T, 2007, LECT NOTES COMPUT SC, V4555, P103
   Kleinen A, 2011, 4 SEM AMB MED EXP SA
   Kuniavsky Mike, 2003, OBSERVING USER EXPER
   Lazar J., 2010, Research Methods in Human-Computer Interaction
   Lee JH, 2002, ADV ROBOTICS, V16, P265, DOI 10.1163/156855302760121936
   Luger GF., 2005, Artificial intelligence: structures and strategies for complex problem solving
   Lugmayr A, 2011, P 4 SEM AMB MED EXP
   Lugmayr A, 2010, P 3 SEM AMB MED EXP
   Lugmayr A, 2011, 4 SEM AMB MED EXP SA
   Lugmayr A, 2012, MULTIMED TOOLS APPL, V58, P289, DOI 10.1007/s11042-011-0899-6
   Lugmayr A, 2012, MULTIMED TOOLS APPL, V58, P385, DOI 10.1007/s11042-010-0671-3
   Lugmayr A, 2009, MULTIMED TOOLS APPL, V44, P337, DOI 10.1007/s11042-009-0282-z
   Lugmayr A, 2009, MULTIMED TOOLS APPL, V44, P331, DOI 10.1007/s11042-009-0283-y
   Mai JE, 2005, INFORM PROCESS MANAG, V41, P599, DOI 10.1016/j.ipm.2003.12.004
   McCarthy J, WHAT IS AI
   Mistry P, 2009, SIGGRAPH ASIA 09
   Morroni M., 2009, Production process and technical change
   Moscovici Serge., 1991, The Invention of Society: Psychological Explanations for Social Phenomena
   Mustaquim M, 2011, 4 SEM AMB MED EXP SA
   Mustaquim MM, 2012, LECT NOTES COMPUT SC, V7382, P428, DOI 10.1007/978-3-642-31522-0_65
   Napper V, 1991, ENGLISHEDUCATIONAL T, V42, P97
   Nilsson NJ., 1998, ARTIF INTELL
   Obal D, 2011, 4 SEM AMB MED EXP SA
   Oh J-S, 2011, 4 SEM AMB MED EXP SA
   Ollikainen V, 2012, NEW ELECT MEDIA NELM
   Olsson T, 2009, CREATING MANAGING SH
   Pacione M, 2003, LANDSCAPE URBAN PLAN, V65, P21, DOI 10.1016/S0169-2046(02)00234-7
   Peischl B, 2012, DCNET ICE B OPTICS, P217
   Pogorelc B., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining Workshops (ICDMW 2010), P976, DOI 10.1109/ICDMW.2010.205
   Pogorelc B, 2011, 4 SEM AMB MED EXP SA
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P333, DOI 10.1007/s11042-011-0786-1
   Pustisek M, 2011, 4 SEM AMB MED EXP SA
   Rahman ASMM, 2011, 4 SEM AMB MED EXP SA
   Russell J, 2012, A I ARTIFICIAL INTEL
   Saathoff C, 2010, P 19 INT C WORLD WID, P831, DOI [10.1145/1772690.1772775, DOI 10.1145/1772690.1772775]
   Schänzel H, 2012, ASPEC TOUR, P1
   Schenk S, 2009, J WEB SEMANT, V7, P298, DOI 10.1016/j.websem.2009.09.006
   Story MF, 1998, ASSIST TECHNOL, V10, P4, DOI 10.1080/10400435.1998.10131955
   Tom Heath C. B, 2011, LINKED DATA EVOLVING, V1
   Toyne S, 2002, BBC NEWS
   United Nations, 2009, WORLD POP AG REP 200
   Vasovic A, 2011, 4 SEM AMB MED EXP SA
   Vredenburg K., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P471, DOI 10.1145/503376.503460
   Wild K, 2012, AMB INTELL SMART ENV, V11, P94, DOI 10.3233/978-1-60750-837-3-94
   Xinshuang Zhang, 2011, Business Management and Electronic Information. Proceedings of the 2011 International Conference on Business Management and Electronic Information (BMEI 2011), P43, DOI 10.1109/ICBMEI.2011.5917838
NR 83
TC 3
Z9 3
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 7
EP 37
DI 10.1007/s11042-012-1346-z
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Asaari, MSM
   Rosdi, BA
   Suandi, SA
AF Asaari, Mohd. Shahrimie Mohd.
   Rosdi, Bakhtiar Affendi
   Suandi, Shahrel Azmin
TI Intelligent Biometric Group Hand Tracking (IBGHT) database for visual
   hand tracking research and development
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand gesture recognition; Hand detection; Hand tracking; Benchmark
   database; Annotated ground truth
ID RECOGNITION; GESTURES
AB With the increase of innovations in vision-based hand gesture interaction system, new techniques and algorithms are being developed by researchers. However, less attention has been paid on the scope of dismantling hand tracking problems. There is also limited publicly available database developed as benchmark data to standardize the research on hand tracking area. For this purpose, we develop a versatile hand gesture tracking database. This database consists of 60 video sequences containing a total of 15,554 RGB color images. The tracking sequences are captured in different situations ranging from an easy indoor scene to extremely high challenging outdoor scenes. Complete with annotated ground truth data, this database is made available on the web for the sake of assisting other researchers in the related fields to test and evaluate their algorithms based on standard benchmark data.
C1 [Asaari, Mohd. Shahrimie Mohd.; Rosdi, Bakhtiar Affendi; Suandi, Shahrel Azmin] USM, Sch Elect & Elect Engn, Intelligent Biometr Grp, Nibong Tebal 14300, Pulau Pinang, Malaysia.
C3 Universiti Sains Malaysia
RP Suandi, SA (corresponding author), USM, Sch Elect & Elect Engn, Intelligent Biometr Grp, Engn Campus, Nibong Tebal 14300, Pulau Pinang, Malaysia.
EM mohdshahrimie@yahoo.com; eebakhtiar@eng.usm.my; shahrel@eng.usm.my
RI Asaari, Mohd Shahrimie Mohd/U-5561-2019; Rosdi, Bakhtiar
   Affendi/O-9017-2019; Suandi, Shahrel Azmin/D-1776-2009
OI Asaari, Mohd Shahrimie Mohd/0000-0002-0225-4819; Rosdi, Bakhtiar
   Affendi/0000-0002-0917-3886; Suandi, Shahrel Azmin/0000-0001-9980-7426
CR [Anonymous], AUST J BASIC APPL SC
   [Anonymous], DOCUMENTATION POINTI
   [Anonymous], INT J ELECT COMPUT E
   [Anonymous], RECENT PROGR ROBOTIC
   [Anonymous], IEEE INT WORKSH MULT
   [Anonymous], IDIAP 2 HANDED DATAS
   [Anonymous], 2012, CANADIAN CTR COMPUT, DOI DOI 10.5539/CIS.V5N3P110
   [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], 2010, WORLD ENG C
   [Anonymous], 2007, PROC INTERSPEECH 200
   [Anonymous], 2011, Res Lett Inf Math Sci
   [Anonymous], SEBASTIEN MARCEL DYN
   [Anonymous], 2006, P IEEE INT C MULT IN
   Asaari Mohd Shahrimie Mohd, 2010, Proceedings 10th International Conference on Intelligent Systems Design and Applications (ISDA 2010), P166, DOI 10.1109/ISDA.2010.5687273
   Assaleh K, 2009, J FRANKLIN I, V346, P175, DOI 10.1016/j.jfranklin.2008.08.005
   Dadgostar F., 2005, Research letters in the information and mathematical sciences, V7, P127
   Doe-Hyung Lee, 2010, Proceedings of the 5th International Conference on Computer Sciences and Convergence Information Technology (ICCIT 2010), P1092, DOI 10.1109/ICCIT.2010.5711226
   Dreuw P, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P1115
   Elmezain M, 2009, IEEE IMAGE PROC, P3577, DOI 10.1109/ICIP.2009.5414322
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Gunes H, 2006, INT C PATT RECOG, P1148
   Hwang BW, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P243
   Imagawa K, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P462, DOI 10.1109/AFGR.1998.670991
   Ishida H, 2010, PATTERN RECOGN, V43, P2799, DOI 10.1016/j.patcog.2010.02.021
   Karami A, 2011, EXPERT SYST APPL, V38, P2661, DOI 10.1016/j.eswa.2010.08.056
   Kim TK, 2007, PROC CVPR IEEE, P1275
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Murthy G.R.S., 2009, International Journal of Information Technology and Knowledge Management, V2, P405
   Nickel K, 2007, IMAGE VISION COMPUT, V25, P1875, DOI 10.1016/j.imavis.2005.12.020
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Rogalla O, 2002, IEEE ROMAN 2002, PROCEEDINGS, P454, DOI 10.1109/ROMAN.2002.1045664
   Shan CF, 2007, PATTERN RECOGN, V40, P1958, DOI 10.1016/j.patcog.2006.12.012
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Starner T., 2000, IUI 2000. 2000 International Conference on Intelligent User Interfaces, P256, DOI 10.1145/325737.325864
   Starner T, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P87, DOI 10.1109/ISWC.2000.888469
   Tollmar K., 2003, CHI'03 Extended Abstracts, P620
   Wachs JP, 2008, J AM MED INFORM ASSN, V15, P321, DOI 10.1197/jamia.M241
   Wachs JP, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1897816.1897838
   Yang JC, 2010, COMPUT EDUC, V55, P1346, DOI 10.1016/j.compedu.2010.06.005
NR 39
TC 9
Z9 9
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1869
EP 1898
DI 10.1007/s11042-012-1212-z
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500023
DA 2024-07-18
ER

PT J
AU Huang, YH
   Chang, CC
   Wu, CY
AF Huang, Ying-Hsuan
   Chang, Chin-Chen
   Wu, Chun-Yu
TI A DNA-based data hiding technique with low modification rates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DNA; Reversible data hiding; DNA modification rate; Histogram
ID VIDEO; IMAGE
AB In 2010, Shiu et al. proposed three DNA-based reversible data hiding schemes with high embedding capacity. However, their schemes were not focused on DNA modification rate or the expansion problem. Therefore, we propose a novel reversible data hiding scheme based on histogram technique to solve the weaknesses of Shiu et al.'s schemes. The proposed scheme transforms the DNA sequence into a binary string and then combines several bits into a decimal integer. These decimal integers are used to generate a histogram. Afterwards, the proposed scheme uses a histogram technique to embed secret data. The experimental results show that the modification rate of our proposed scheme is 69 % lower than that of Shiu et al.'s schemes for the same embedding capacity. In addition, the length of the DNA sequence remains unchanged in the proposed scheme.
C1 [Huang, Ying-Hsuan] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung 40227, Taiwan.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chang, Chin-Chen] Asia Univ, Dept Comp Sci & Informat Engn, Taichung 41354, Taiwan.
   [Wu, Chun-Yu] Chung Cheng Univ, Dept Comp Sci & Imformat Engn, Chiayi 62102, Taiwan.
C3 National Chung Hsing University; Feng Chia University; Asia University
   Taiwan; National Chung Cheng University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
CR Chang CC, 2007, INT J INNOV COMPUT I, V3, P1145
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Farias MCQ, 2005, IEEE T CONSUM ELECTR, V51, P983, DOI 10.1109/TCE.2005.1510512
   Guo C, 2012, INT J INNOV COMPUT I, V8, P139
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Jin HL, 2007, IEICE T FUND ELECTR, VE90A, P771, DOI 10.1093/ietfec/e90-a.4.771
   Liao SR, 2010, THESIS CHAOVANG U TE
   Peterson I, 2001, MUSE, V22
   Shimanovsky B, 2003, LECT NOTES COMPUT SC, V2578, P373
   Shiu HJ, 2010, INFORM SCIENCES, V180, P2196, DOI 10.1016/j.ins.2010.01.030
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P685, DOI 10.1109/TIP.2003.810588
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P696, DOI 10.1109/TIP.2003.810589
   Wu Zhi-jun, 2009, Journal of China Universities of Posts and Telecommunications, V16, P103, DOI 10.1016/S1005-8885(08)60295-2
   Xu Shuzheng, 2009, Tsinghua Science and Technology, V14, P55, DOI 10.1016/S1007-0214(09)70007-0
NR 15
TC 15
Z9 16
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1439
EP 1451
DI 10.1007/s11042-012-1176-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500004
DA 2024-07-18
ER

PT J
AU Sun, SP
   Yuan, BC
   Su, HW
AF Sun, Shuh-Ping
   Yuan, Ben-Chih
   Su, Hui-Wen
TI Full-scale 3D multimedia preoperative planning system for total ankle
   joint replacement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Ankle joint; Computer-assisted engineering; Reverse
   engineering
ID FRACTURES
AB This study presents a "Full-Scale 3D Multimedia Preoperative Planning System for Total Ankle Joint Replacement" that evaluation and verifies the usability of artificial ankle joint replacement operation. The system uses a full-scale computer-assisted engineering technique for designing and developing preoperative planning modules. The multimedia user interface integrates the function of different software programs in order to plan and simulate the operation. These functions include 3D image model capturing, sectioning, translocation, rotating, and measuring relevant foot anatomy, all of which can be integrated and used for surgical planning, as well as for future study and discussion. Furthermore, because the system is computer based with a multimedia user interface, surgeons can use it to explore the optimal operative procedure. The system also has a databank that can update and expand, and can be used to provide clinical cases to different users for education and training.
C1 [Sun, Shuh-Ping] I Shou Univ, Dept Biomed Engn, Kaohsiung, Taiwan.
   [Sun, Shuh-Ping] I Shou Univ, Dept Digital Media Design, Kaohsiung, Taiwan.
   [Yuan, Ben-Chih] Fooyin Univ Hosp, Kaohsiung, Taiwan.
   [Su, Hui-Wen] I Shou Univ, Kaohsiung, Taiwan.
C3 I Shou University; I Shou University; I Shou University
RP Yuan, BC (corresponding author), Fooyin Univ Hosp, Kaohsiung, Taiwan.
EM fyent@fy.org.tw
CR Bråten M, 2000, INJURY, V31, P311, DOI 10.1016/S0020-1383(99)00299-5
   CAPONETTI L, 1993, IEEE COMPUT GRAPH, V13, P86, DOI 10.1109/38.252561
   JUPITER JB, 1992, J HAND SURG-AM, V17A, P406, DOI 10.1016/0363-5023(92)90340-U
   Messmer P, 2001, Comput Aided Surg, V6, P183, DOI 10.3109/10929080109146082
   Rammelt S, 2004, INJURY, V35, P443, DOI 10.1016/j.injury.2003.10.006
   Santler G, 1998, Comput Aided Surg, V3, P248, DOI 10.1002/(SICI)1097-0150(1998)3:5<248::AID-IGS4>3.3.CO;2-1
   Schepers T, 2009, J FOOT ANKLE SURG, V48, P156, DOI 10.1053/j.jfas.2008.11.006
   Schmerber S, 2001, Comput Aided Surg, V6, P1
   Shuh-Ping Sun, 2004, Biomedical Engineering, Applications Basis Communications, V16, P173
   Stapleton John J, 2009, Clin Podiatr Med Surg, V26, P79, DOI 10.1016/j.cpm.2008.10.003
   Stindel E, 2002, Comput Aided Surg, V7, P156, DOI 10.3109/10929080209146026
   Sun SP, 2008, COMPUT METH PROG BIO, V90, P95, DOI 10.1016/j.cmpb.2007.11.013
   Swanson Scott A, 2008, Foot Ankle Clin, V13, P659, DOI 10.1016/j.fcl.2008.09.006
NR 13
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1749
EP 1765
DI 10.1007/s11042-012-1187-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500018
DA 2024-07-18
ER

PT J
AU You, SD
   Chen, WK
AF You, Shingchern D.
   Chen, Woei-Kae
TI Optimally truncating head-related impulse response by dynamic
   programming with its applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HRTF; CAPZ; Multi-channel; Dynamic Programming; Headphones
ID POLE-ZERO APPROXIMATIONS; ALGORITHM; MODEL; IMPLEMENTATION
AB We propose a method to optimally truncate the head-related impulse responses (HRIRs) in this paper. The truncated HRIR consists of a portion of the original HRIR and a flat line. An algorithm based on dynamic programming is used to optimally select the portions of the original HRIRs and the constants of the flat lines to minimize the modeling errors. The truncated HRIRs can be used to reproduce multi-channel sound for headphones with a significantly lower computational cost. The proposed method is compared with another approximation method, the CAPZ (Common-Acoustical-Pole and Zero) approach. The experimental results show that the proposed method yields lower composition as well as modeling errors for the same amount of computation. Compared with the direct implementation, the proposed approach requires about 35 % of the computational cost while maintaining acceptable composition errors.
C1 [You, Shingchern D.; Chen, Woei-Kae] Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
C3 National Taipei University of Technology
RP You, SD (corresponding author), Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, 1,Sec 3,Chung Hsiao East Rd, Taipei, Taiwan.
EM you@csie.ntut.edu.tw; wkc@csie.ntut.edu.tw
RI You, Shingchern/AAG-6401-2020
CR Advanced Television Systems Committee, 1995, AC3 ADV TEL SYST COM
   [Anonymous], 144963 ISOIEC
   Blaurt J, 1997, SPATIAL HEARING PSYC
   Blommer MA, 1997, IEEE T SPEECH AUDI P, V5, P278, DOI 10.1109/89.568734
   Brown CP, 1998, IEEE T SPEECH AUDI P, V6, P476, DOI 10.1109/89.709673
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   Durant EA, 2002, IEEE T SPEECH AUDI P, V10, P18, DOI 10.1109/89.979382
   Gardner W.G., 1994, HRTF MEASUREMENTS KE
   GARDNER WG, 1995, J ACOUST SOC AM, V97, P3907, DOI 10.1121/1.412407
   Haneda Y, 1999, IEEE T SPEECH AUDI P, V7, P188, DOI 10.1109/89.748123
   Huang S, 2008, J ACOUST SOC AM, V123, P1
   Kulkarni A, 2004, J ACOUST SOC AM, V115, P1714, DOI 10.1121/1.1650332
   Mackenzie J, 1997, IEEE SIGNAL PROC LET, V4, P39, DOI 10.1109/97.554467
   Sakamoto N, 2003, J CIRCUIT SYST COMP, V12, P55, DOI 10.1142/S0218126603000830
   Shen Y.R., 2003, PRINCIPLES NONLINEAR, P1
   Yen CH, 2007, MULTIMED TOOLS APPL, V35, P335, DOI 10.1007/s11042-007-0110-2
   You SD, 2008, MULTIMED TOOLS APPL, V40, P341, DOI 10.1007/s11042-008-0210-7
NR 17
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2167
EP 2188
DI 10.1007/s11042-012-1234-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500035
DA 2024-07-18
ER

PT J
AU Yu, HF
AF Yu, Hsiang-Fu
TI Extension of practical channel transition broadcasting for near
   video-on-demand applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Periodic broadcasting; Near video-on-demand (VoD); Channel transition
ID RECEIVING SCHEME; WAITING TIME
AB Periodic broadcasting is a cost-effective solution for the large-scale distribution of popular videos. This strategy guarantees constant worst service latency to all clients, regardless of the number of video requests. The practical channel transition broadcasting (PCTB) scheme is an essential periodic broadcasting method that can dynamically add or release broadcasting channels (i.e., channel transition) according to video popularity. However, PCTB experiences bandwidth waste when performing channel transition. This study further finds that PCTB yields transition playback latency during channel addition. Therefore, an enhanced version referred to as PCTB+ is proposed to cause less bandwidth waste and lower transition playback latency. The applicability of this new scheme is verified, and an analytical evaluation is provided to demonstrate its performance advantage. The new scheme reduces bandwidth waste by 50 % to 100 % compared to the original PCTB scheme. Moreover, PCTB+ yields 50 % smaller transition playback latency than PCTB. The proposed scheme outperforms the seamless fast broadcasting (SFB) scheme for bandwidth waste under most conditions. No extra startup latency and client buffer demand are required when using PCTB+.
C1 Natl Taipei Univ Educ, Dept Comp Sci, Taipei, Taiwan.
C3 National Taipei University of Education
RP Yu, HF (corresponding author), Natl Taipei Univ Educ, Dept Comp Sci, Taipei, Taiwan.
EM yu@tea.ntue.edu.tw
FU National Science Council, Taiwan [NSC 101-2221-E-152-004]
FX This work was financially supported by National Science Council, Taiwan
   under a research grant numbered NSC 101-2221-E-152-004.
CR Chand S, 2010, COMPUT NETW, V54, P462, DOI 10.1016/j.comnet.2009.09.008
   Chen YW, 2012, IET COMMUN, V6, P2949, DOI 10.1049/iet-com.2011.0679
   Chen YW, 2011, IET COMMUN, V5, P951, DOI 10.1049/iet-com.2010.0410
   Chen YN, 2012, INT J DIGIT MULTIMED, V2012, DOI 10.1155/2012/717538
   Chien WD, 2005, IEEE T BROADCAST, V51, P360, DOI 10.1109/TBC.2005.852251
   Choi J, 2012, IEEE COMMUN SURV TUT, V14, P156, DOI 10.1109/SURV.2011.030811.00051
   De Vleeschauwer D, 2009, IEEE T BROADCAST, V55, P491, DOI 10.1109/TBC.2009.2015983
   Digital TV Research, 2012, SUST BOOM FOR GLOB O
   Febiansyah H, 2012, MULTIMEDIA TOOLS APP
   Guo Y, 2004, IEEE T MULTIMEDIA, V6, P387, DOI 10.1109/TMM.2003.822786
   Hongliang Yu, 2006, Operating Systems Review, V40, P333, DOI 10.1145/1218063.1217968
   Hua K. A., 1997, Computer Communication Review, V27, P89, DOI 10.1145/263109.263144
   Juhn LS, 1997, IEEE T CONSUM ELECTR, V43, P1110, DOI 10.1109/30.642378
   Juhn LS, 1998, IEEE T BROADCAST, V44, P100, DOI 10.1109/11.713059
   Kwon JB, 2011, MULTIMED TOOLS APPL, V51, P1105, DOI 10.1007/s11042-010-0461-y
   Natarajan A, 2009, MULTIMED TOOLS APPL, V43, P179, DOI 10.1007/s11042-009-0263-2
   Tang W, 2007, COMPUT NETW, V51, P336, DOI 10.1016/j.comnet.2006.05.003
   TechNavio, 2012, GLOB VID DEM MARK 20
   Tseng YC, 2004, IEEE ACM T NETWORK, V12, P559, DOI 10.1109/TNET.2004.828965
   Tseng YC, 2002, IEEE T COMMUN, V50, P1348, DOI 10.1109/TCOMM.2002.801466
   Tseng YC, 2001, IEEE T COMMUN, V49, P863, DOI 10.1109/26.923810
   Vilas M, 2005, EUROMICRO-SEAA 2005: 31st EUROMICRO Conference on Software Engineering and Advanced Applications, Proceedings, P330
   Wu BS, 2011, IEEE T BROADCAST, V57, P721, DOI 10.1109/TBC.2011.2128530
   Wu CJ, 2007, MULTIMEDIA SYST, V13, P223, DOI 10.1007/s00530-007-0085-x
   Wu CJ, 2011, INFORM PROCESS LETT, V111, P1014, DOI 10.1016/j.ipl.2011.07.013
   Yang ZY, 2012, INT J DIGIT MULTIMED, V2012, DOI 10.1155/2012/373459
   Yu H-F, 2012, MULTIMEDIA TOOLS APP
   Yu HF, 2008, COMPUT COMMUN, V31, P2270, DOI 10.1016/j.comcom.2008.02.014
   Yu HF, 2008, IEEE T BROADCAST, V54, P304, DOI 10.1109/TBC.2008.915761
   Yu HF, 2007, IEEE T BROADCAST, V53, P103, DOI 10.1109/TBC.2006.888917
   Yu HF, 2009, MULTIMED TOOLS APPL, V42, P295, DOI 10.1007/s11042-008-0245-9
   Yu HF, 2009, IEEE T MULTIMEDIA, V11, P152, DOI 10.1109/TMM.2008.2008931
NR 32
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2369
EP 2385
DI 10.1007/s11042-013-1436-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500045
DA 2024-07-18
ER

PT J
AU Kurz, T
   Güntner, G
   Damjanovic, V
   Schaffert, S
   Fernandez, M
AF Kurz, Thomas
   Guentner, Georg
   Damjanovic, Violeta
   Schaffert, Sebastian
   Fernandez, Manuel
TI Semantic enhancement for media asset management systems Integrating the
   Red Bull Content Pool in the Web of Data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Linked Data; Semantic media pool; Linked Media; Semantic enhancement;
   Media Annotation
ID ANNOTATION
AB The socio-economic development of the World Wide Web gathered a large momentum through Web 2.0 and currently, the Web of Data is adding a further technological driver to this. The tremendous growth of media data combined with structured (linked) data promises further opportunities for digital market places. Although the integration of media content with linked data is only beginning there are already working groups and projects addressing this issue. We show how media and existing data sets can be seamlessly integrated and thus give possibilities for an extended user experience while interacting with media content on the web. We focus on automatic semantic enhancement services that can link arbitrary and open accessible data and introduce opportunities for media annotation, fragmentation and presentation. Our use case scenario is based on the Red Bull Content Pool, a media management system for videos, images and articles about Red Bull related content covering a multitude of sports events.
C1 [Kurz, Thomas; Guentner, Georg; Damjanovic, Violeta; Schaffert, Sebastian] Salzburg Res Forsch Gesell MbH, A-5020 Salzburg, Austria.
   [Fernandez, Manuel] Red Bull Media House, A-5020 Salzburg, Austria.
RP Kurz, T (corresponding author), Salzburg Res Forsch Gesell MbH, Jakob Haringer Str 5-3, A-5020 Salzburg, Austria.
EM thomas.kurz@salzburgresearch.at; georg.guentner@salzburgresearch.at;
   violeta.damjanovic@salzburgresearch.at;
   sebastian.schaffert@salzburgresearch.at;
   manuel.fernandez@at.redbullmediahouse.com
RI Damjanovic-Behrendt, Violeta/T-2284-2019
OI Damjanovic-Behrendt, Violeta/0000-0002-9903-9081
FU Republic of Austria within the COMET project "Salzburg NewMediaLab - The
   Next Generation"; European Commission within the 7th Framework Programme
   project KiWi - Knowledge in a Wiki [211932]
FX This research has been funded by the Republic of Austria within the
   COMET project "Salzburg NewMediaLab - The Next Generation" and by the
   European Commission within the 7th Framework Programme project KiWi -
   Knowledge in a Wiki (No. 211932). The latest version of the Linked Media
   Framework source code is available with a permissive Open Source license
   at http://code.google.com/p/kiwi. We thank the members of the W3C Linked
   Data mailing list for their valuable comments on our idea.
CR [Anonymous], 1668412012 ISO
   [Anonymous], 2008, DCMI Metadata Terms Retrieved 2009-08-21, from
   [Anonymous], CP3451 JEITA TECHN S
   [Anonymous], P 20 INT IEEE ERK EL
   [Anonymous], 2000, Dissertation
   Arndt R, 2009, COMM CORE ONTOLOGY M, P403
   Aroyo L., 2011, Proceedings of the 1st IEEE First International Conference on Consumer Electronics - Berlin (IEEE ICCE-Berlin 2011), P269, DOI 10.1109/ICCE-Berlin.2011.6031805
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Berners-Lee T., 2006, Linked Data-Design Issues
   BIZER C, 2007, 4 EUR SEM WEB C ESWC, P802
   Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901
   Bottoni P., 2006, P WORK C ADV VIS INT, P314, DOI [https://doi.org/10.1145/1133265.1133331, DOI 10.1145/1133265.1133331]
   Brickley D., 2004, RDF VOCABULARY DESCR
   Bürger T, 2009, LECT NOTES COMPUT SC, V5887, P101, DOI 10.1007/978-3-642-10543-2_11
   Burger T, 2008, P 1 INT WORKSH INT M
   Burger T, 2010, P 2 WORKSH SEM MULT
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   de Sompel HV, 2009, CORR
   Enser P, 2008, J INF SCI, V34, P531, DOI 10.1177/0165551508091013
   Fialho A, 2010, P WORKSH REC TRACK E
   Forrester Research, 2009, VAL COMPR INT SOL
   Handschuh S, 2003, LECT NOTES ARTIF INT, V2821, P19
   Hardman L, 2008, CANONICAL PROCESSES
   Haslhofer B, 2011, WORKSH MULT WEB MMWE
   Haslhofer B, 2009, INT J DIGIT LIBRARIE, V10, P15, DOI 10.1007/s00799-009-0050-8
   Hausenblas M, 2009, WWW 2009 WORKSH LINK
   Herlocker JL, 2004, ACM T INF SYS TOIS, V22, P230
   Hollink L., 2003, KNOWLEDGE CAPTURE, V2
   Kahan J., 2001, P INT WORLD WIDE WEB, P623, DOI DOI 10.1145/371920.372166
   Klyne G, 2004, D91 SECURESCM
   Kurz T, 2011, WORKSH MULT WEB MMWE
   Lee W, 2010, ONTOLOGY MEDIA RESOU
   McGuinness D. L., 2004, OWL WEB ONTOLOGY LAN, DOI DOI 10.2004-03
   Mendes Pablo N, 2011, P 7 INT C SEM SYST, P1, DOI [DOI 10.1145/2063518.2063519, 10.1145/2063518.2063519]
   Miles A, 2009, SKOS Simple Knowledge Organization System Reference
   Nichols DM, 2000, LECT NOTES COMPUT SC, V1923, P239
   (NWG) NWG, 2005, RFC3986 UN RES ID UR
   Phelps TA, 1997, LECT NOTES COMPUT SC, V1324, P287, DOI 10.1007/BFb0026734
   Pipek V, 2009, REQUIREMENTS REPORT
   Saathoff C, 2010, P WORLD WID WEB C 20
   SANDERSON R, 2011, OPEN ANNOTATION BETA
   Schaffert S, 2012, P 8 INT C SEM SYST G
   Scharffe F, 2009, ALIGNMENTS DATA INTE
   Schebella M, 2011, LINKED MEDIA LAB REP, V2
   Schroeter R, 2006, P 2 IEEE INT C E SCI, P41
   Seaborne A., 2008, SPARQL Query Language for RDF
   SemanticWebCompany, 2011, POOLPARTY EXTR PPX
   Siorpaes K, 2008, IEEE INTELL SYST, V23, P50, DOI 10.1109/MIS.2008.45
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Spivak N, 2008, SEMANTIC WAVE 2008 I
   Stegmaier F, 2011, API MEDIA R IN PRESS
   Steiner T, 2010, P ISWC 2010 POST DEM
   Troncy R, 2011, D91 SECURESCM
   Uren V, 2006, J WEB SEMANT, V4, P14, DOI 10.1016/j.websem.2005.10.002
   W3C, 2007, LINK OP DAT
NR 55
TC 6
Z9 6
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 949
EP 975
DI 10.1007/s11042-012-1197-7
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900017
DA 2024-07-18
ER

PT J
AU Scherp, A
   Mezaris, V
AF Scherp, Ansgar
   Mezaris, Vasileios
TI Survey on modeling and indexing events in multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event models; Event aspects; Event-based indexing
ID VIDEO; KNOWLEDGE; ONTOLOGY; WEB; METADATA; RETRIEVAL; OBJECT
AB Events have gained increasing interest in the area of multimedia in recent years. There have been many approaches published and research conducted on how to extract events from multimedia, represent it using appropriate models, and how to use events in end user applications. In this paper, we conduct an extensive analysis of existing event models along commonly identified aspects of events. In addition, we analyze how the different aspects of events relate to each other and how they can be applied together. Subsequently, we look into different approaches for how to index multimedia data. Finally, we elaborate on how to link the multimedia data with events in order to provide the basis for future event-based multimedia applications.
C1 [Scherp, Ansgar] Univ Mannheim, Inst Comp Sci & Business Informat, D-68131 Mannheim, Germany.
   [Mezaris, Vasileios] Ctr Res & Technol Hellas CERTH, ITI, Thermi 57001, Greece.
C3 University of Mannheim; Centre for Research & Technology Hellas
RP Scherp, A (corresponding author), Univ Mannheim, Inst Comp Sci & Business Informat, B6,26, D-68131 Mannheim, Germany.
EM ansgar@informatik.uni-mannheim.de
RI Scherp, Ansgar/Q-2315-2016
OI Scherp, Ansgar/0000-0002-2653-9245
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   [Anonymous], P TRECVID 2010 WORKS
   [Anonymous], P 1 WORKSH MULT ANN
   [Anonymous], P TRECVID 2012 WORKS
   [Anonymous], 2006, ACM INT C MULTIMEDIA, DOI [10.1145/1180639.1180727, DOI 10.1145/1180639.1180727]
   [Anonymous], 2003, P WORKSH ONT AG SYST
   [Anonymous], 2002, CAUSE CORRELATION BI, DOI DOI 10.1017/CBO9780511605949
   [Anonymous], P TRECVID 2008 WORKS
   [Anonymous], SOUPA ONTOLOGY PERVA
   [Anonymous], SEMANTIC WEB ANNOTAT
   [Anonymous], 2009, HDB ONTOLOGIES
   [Anonymous], P ACM INT C MULT INF
   [Anonymous], EVENTS
   [Anonymous], SPIE
   [Anonymous], P TRECVID 2010 WORKS
   [Anonymous], 2010, COMM AL PROT VERS 1
   [Anonymous], P TRECVID 2012 WORKS
   [Anonymous], SYNTH LECT DAT MAN
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P 12 ANN ACM INT C M
   [Anonymous], P TRECVID 2012 WORKS
   [Anonymous], P TRECVID 2012 WORKS
   [Anonymous], D91 SECURESCM
   [Anonymous], TUT POST PAN IND CON
   Arndt R, 2007, LECT NOTES COMPUT SC, V4825, P30
   Atrey PK, 2011, MULTIMED TOOLS APPL, V51, P697, DOI 10.1007/s11042-010-0649-1
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Ballan L, 2010, IEEE MULTIMEDIA, V17, P80, DOI 10.1109/MMUL.2010.4
   Ballan L, 2010, MULTIMED TOOLS APPL, V48, P313, DOI 10.1007/s11042-009-0342-4
   Baumgartner N, 2006, PROCEEDINGS OF THE FOURTH IASTED INTERNATIONAL CONFERENCE ON KNOWLEDGE SHARING AND COLLABORATIVE ENGINEERING, P1
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bertini M, 2009, IEEE MULTIMEDIA, V16, P42, DOI 10.1109/MMUL.2009.25
   Carbonaro A, 2008, J E-LEARN KNOWL SOC, V4, P203
   Cervesato I, 2000, COMPUT INTELL-US, V16, P307, DOI 10.1111/0824-7935.00115
   Chandy K.Mani., 2007, Proceedings of the 2007 inaugural international conference on Distributed event-based systems, DEBS '07, P180
   Dasiopoulou S, 2005, IEEE T CIRC SYST VID, V15, P1210, DOI 10.1109/TCSVT.2005.854238
   Ekin A, 2004, IEEE T MULTIMEDIA, V6, P839, DOI 10.1109/TMM.2004.837238
   François ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87
   Gangemi A, 2002, LECT NOTES ARTIF INT, V2473, P166
   Gkalelis N., 2011, 2011 9th International Workshop on Content-Based Multimedia Indexing (CBMI), P85, DOI 10.1109/CBMI.2011.5972525
   Gkalelis N, 2013, IEEE T NEUR NET LEAR, V24, P8, DOI 10.1109/TNNLS.2012.2216545
   Gkalelis N, 2011, IEEE SIGNAL PROC LET, V18, P319, DOI 10.1109/LSP.2011.2127474
   Gkalelis N, 2010, IEEE INT C SEMANT CO, P79, DOI 10.1109/ICSC.2010.21
   Hakeem A, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P263
   Itkonen Esa., 1983, Causality in Linguistic Theorygt;: A critical Investigation into the philosophical and methodological Foundations of 'non-autonomous ' Linguistics
   Jain R, 2008, COMPUTER, V41, P42, DOI 10.1109/MC.2008.49
   Jiang YG, 2013, INT J MULTIMED INF R, V2, P73, DOI 10.1007/s13735-012-0024-2
   Kokar MM, 2009, INFORM FUSION, V10, P83, DOI 10.1016/j.inffus.2007.01.004
   KOWALSKI R, 1986, NEW GENERAT COMPUT, V4, P67, DOI 10.1007/BF03037383
   Lin FZ, 2008, FOUND ARTIF INTELL, P649, DOI 10.1016/S1574-6526(07)03016-7
   Lin FZ, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P670
   Lombard L.B., 1986, Events: A metaphysical study
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Matheus CJ, 2005, LECT NOTES COMPUT SC, V3791, P130, DOI 10.1007/11580072_11
   Matheus CJ, 2005, LECT NOTES COMPUT SC, V3729, P944, DOI 10.1007/11574620_67
   Matheus CJ, 2005, PROC SPIE, V5813, P75, DOI 10.1117/12.604120
   Merler M, 2012, IEEE T MULTIMEDIA, V14, P88, DOI 10.1109/TMM.2011.2168948
   Mezaris V, 2010, IEEE IMAGE PROC, P4697, DOI 10.1109/ICIP.2010.5653867
   Mezaris V, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/645052
   Mueller ET, 2008, FOUND ARTIF INTELL, P671, DOI 10.1016/S1574-6526(07)03017-9
   Nack F, 2005, IEEE MULTIMEDIA, V12, P54, DOI 10.1109/MMUL.2005.12
   Nevatia R., 2004, Computer Vision and Pattern Recognition Workshop, P119
   Papadopoulos GT, 2009, IEEE T CIRC SYST VID, V19, P1513, DOI 10.1109/TCSVT.2009.2026932
   QUINTON A, 1979, MIND, V88, P197
   Raimond Yves, 2007, The Event Ontology
   Saathoff C, 2010, P 19 INT C WORLD WID, P831, DOI [10.1145/1772690.1772775, DOI 10.1145/1772690.1772775]
   Scherp A, 2012, INT J SEMANT COMPUT, V6, P25, DOI 10.1142/S1793351X12400028
   Scherp A, 2011, APPL ONTOL, V6, P177, DOI 10.3233/AO-2011-0096
   Scherp A, 2012, MULTIMED TOOLS APPL, V58, P293, DOI 10.1007/s11042-010-0667-z
   Scherp A, 2009, K-CAP'09: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON KNOWLEDGE CAPTURE, P137
   Shadbolt N, 2006, IEEE INTELL SYST, V21, P96, DOI 10.1109/MIS.2006.62
   Shaw R, 2009, LECT NOTES COMPUT SC, V5926, P153, DOI 10.1007/978-3-642-10871-6_11
   Smeaton AF, 2009, SIGNALS COMMUN TECHN, P151, DOI 10.1007/978-0-387-76569-3_6
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Tesic J, 2005, IEEE MULTIMEDIA, V12, P86, DOI 10.1109/MMUL.2005.50
   Tjondronegoro DW, 2010, IEEE T SYST MAN CY A, V40, P1009, DOI 10.1109/TSMCA.2010.2046729
   van Hage WR, 2012, MULTIMED TOOLS APPL, V57, P175, DOI 10.1007/s11042-010-0680-2
   Wang F, 2008, ADVANCES IN MATRIX THEORY AND ITS APPLICATIONS, VOL 1, P238
   Wang XH, 2004, SECOND IEEE ANNUAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS, PROCEEDINGS, P18
   Wang XJ, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P95, DOI 10.1109/ICSC.2007.70
   Westermann U., 2006, DATA ENG WORKSHOPS, px106
   Westermann U, 2007, IEEE MULTIMEDIA, V14, P19, DOI 10.1109/MMUL.2007.23
   Xu D, 2008, IEEE T PATTERN ANAL, V30, P1985, DOI 10.1109/TPAMI.2008.129
   Yan WQ, 2011, MULTIMED TOOLS APPL, V55, P443, DOI 10.1007/s11042-010-0560-9
   Yau SS, 2006, FOURTH IEEE WORKSHOP ON SOFTWARE TECHNOLOGIES FOR FUTURE EMBEDDED AND UBIQUITOUS SYSTEMS AND THE SECOND INTERNATIONAL WORKSHOP ON COLLABORATIVE COMPUTING, INTEGRATION, AND ASSURANCE, PROCEEDINGS, P5, DOI 10.1109/SEUS-WCCIA.2006.25
NR 86
TC 20
Z9 21
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 7
EP 23
DI 10.1007/s11042-013-1427-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Hua, JY
   Kuang, WK
   Gao, Z
   Meng, LM
   Xu, ZJ
AF Hua, Jingyu
   Kuang, Wangkun
   Gao, Zheng
   Meng, Limin
   Xu, Zhijiang
TI Image denoising using 2-D FIR filters designed with DEPSO
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2-D FIR filters; Image denoising; DEPSO algorithm
AB Digital images are often corrupted by additive noises during transmission. Thus, how to alleviate noise as much as possible has received concerns for decades. In this paper, we present a simple denoising method based on two dimensional (2-D) finite impulse response (FIR) filtering, where by differential evolution particle swarm optimization (DEPSO) algorithm, five two dimensional finite impulse response filters are designed to filter different kinds of pixels. Comprised by differential evolution algorithm and particle swarm optimization algorithm, differential evolution particle swarm optimization algorithm is effective and robust, which helps to yield better denoise performance. And computer simulation demonstrates that the proposed method is superior to the conventional lowpass filtering method, as well as the modern bilateral filtering and stochastic denoising method.
C1 [Hua, Jingyu; Kuang, Wangkun; Gao, Zheng; Meng, Limin; Xu, Zhijiang] Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Zhejiang, Peoples R China.
   [Hua, Jingyu] Southeast Univ, Natl Mobile Commun Res Lab, Nanjing 210096, Jiangsu, Peoples R China.
C3 Zhejiang University of Technology; Southeast University - China
RP Hua, JY (corresponding author), Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Zhejiang, Peoples R China.
EM eehjy@163.com
RI meng, li/GVT-2063-2022; meng, li/HTQ-7341-2023
FU Chinese ministry of education [210087]; Zhejiang provincial science &
   technology project [2012R10011-6]; national mobile communications
   research laboratory, Southeast University [2010D06]
FX This work was supported by the key project of Chinese ministry of
   education under grant No. 210087, Zhejiang provincial science &
   technology project (No. 2012R10011-6) and in part by the open research
   fund of national mobile communications research laboratory, Southeast
   University (No. 2010D06).
CR [Anonymous], 2011, 2011 3 INT WORKSH IN
   Chen Y, 2006, P 25 CHIN CONTR C, P1110
   Estrada F, 2009, BRIT MACH VIS C
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Hao ZF, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1031
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Potnis A., 2010, ADV COMPUTATIONAL RE, V2, P06
   Storn R., 1995, INT COMPUT SCI I, DOI [10.1023/a, DOI 10.1023/A:1008202821328]
   TERRELL TJ, 1986, J I ELECTRON RAD ENG, V56, P103, DOI 10.1049/jiere.1986.0034
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yin L, 1996, IEEE T CIRCUITS-II, V43, P157, DOI 10.1109/82.486465
   Zhang WJ, 2003, IEEE SYS MAN CYBERN, P3816
NR 13
TC 14
Z9 14
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 1
BP 157
EP 169
DI 10.1007/s11042-012-1263-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AB3UH
UT WOS:000331715200008
DA 2024-07-18
ER

PT J
AU El Khoury, E
   Sénac, C
   Joly, P
AF El Khoury, Elie
   Senac, Christine
   Joly, Philippe
TI Audiovisual diarization of people in video content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE People diarization; Segmentation; Unsupervised clustering; Audiovisual
   fusion; Video indexing
ID TRACKING
AB Audio-Visual People Diarization (AVPD) is an original framework that simultaneously improves audio, video, and audiovisual diarization results. Following a literature review of people diarization for both audio and video content and their limitations, which includes our own contributions, we describe a proposed method for associating both audio and video information by using co-occurrence matrices and present experiments which were conducted on a corpus containing TV news, TV debates, and movies. Results show the effectiveness of the overall diarization system and confirm the gains audio information can bring to video indexing and vice versa.
C1 [El Khoury, Elie] Idiap Res Inst, Martigny, Switzerland.
   [El Khoury, Elie] Univ Maine, Lab Informat, F-72017 Le Mans, France.
   [Senac, Christine; Joly, Philippe] Univ Toulouse 3, Inst Rech Informat Toulouse, F-31062 Toulouse, France.
C3 Le Mans Universite; Universite de Toulouse; Universite Federale Toulouse
   Midi-Pyrenees (ComUE); Universite Toulouse III - Paul Sabatier; Institut
   National Polytechnique de Toulouse; Universite Toulouse 1 Capitole;
   Universite de Toulouse - Jean Jaures; Centre National de la Recherche
   Scientifique (CNRS)
RP El Khoury, E (corresponding author), Idiap Res Inst, Martigny, Switzerland.
EM khoury@lium.univ-lemans.fr
FU French Ministry of High Education and Research; SODA project; National
   French Research Agency (ANR)
FX This work was supported by a 3-year individual fellowship from the
   French Ministry of High Education and Research, and by the SODA project
   funded by the National French Research Agency (ANR).
CR Anguera X, 2006, INT C SPOK LANG PROC
   [Anonymous], ACM INT C MULT INF R
   [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], NIST RICH TRANSCR WO
   [Anonymous], 2009, ICCV
   [Anonymous], 2003, P GRAPH
   [Anonymous], DARPA SPEECH REC WOR
   Arandjelovic O, 2005, IEEE C COMP VIS PATT
   AZARBAYEJANI A, 1993, IEEE T PATTERN ANAL, V15, P602, DOI 10.1109/34.216730
   Bicego M, 2006, COMP VIS PATT REC WO
   Bigot B, 2010, INT WORKSH CONT BAS
   Bozonnet S, 2010, IEEE INT C AC SPEECH
   Cettolo M, 2003, IEEE INT C AC SPEECH
   Chang SF, 2008, TREC VID RETR WORKSH
   Chaudhari UV, 2003, IEEE INT C MULT EXP
   Chaudhari UV, 2003, IEEE INT C AC SPEECH
   Chen SS, 1998, IEEE INT C AC SPEECH
   Chu WT, 2009, ACM INT C MULT
   Cinbis G, 2011, IEEE INT C COMP VIS
   Czirjek C, 2003, ADV CONCEPTS INTELLI
   Dielmann A, 2010, IEEE INT WORKSH MULT
   Doretto G, 2011, J AMB INTEL HUM COMP, V2, P127, DOI 10.1007/s12652-010-0034-y
   El Khoury E, 2007, IEEE INT C AC SPEECH
   El-Khoury E, 2009, IEEE INT C AC SPEECH
   El-Khoury E, 2010, INT J DIGIT MULTIMED, V2010, DOI 10.1155/2010/539796
   Everingham M, 2006, BRIT MACH VIS C BMVC
   Everingham M, 2009, IMAGE VISION COMPUT, V27, P545, DOI 10.1016/j.imavis.2008.04.018
   Fitzgibbon AW, 2002, ECCV 02 EUR C COMP V
   Friedland G, 2009, IEEE INT C AC SPEECH
   Friedland G, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1865106.1865111
   Galliano S, 2005, EUR C SPEECH COMM TE
   Galliano Sylvain, 2009, INTERSPEECH
   Gish H, 1991, INT C AC SPEECH SIGN
   Hilsmann Anna, 2009, INT C COMP VIS COMP
   Hung H, 2008, WORKSH MULT MULT SEN
   Ioffe S, 2001, ICCV01
   Jaffre G, 2004, RIAO
   Leeuwen DAV, 2008, MULT TECHN PERC HUM
   Lerdsudwichai C, 2005, PATTERN RECOGN, V38, P1059, DOI 10.1016/j.patcog.2004.11.022
   Liu Z, 2001, IEEE INT C AC SPEECH
   Liu Z, 2007, IEEE INT C MULT EXP
   Liu Z, 2007, IEEE T MULTIMEDIA, V9, P89, DOI 10.1109/TMM.2006.886360
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Nguyen TH, 2009, NIST RICH TRANSCR WO
   Nockc HJ, 2003, CIVR ACM INT C IM VI
   Peng J, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P475
   Philippeau J, 2006, INT C SIGN PROC MULT
   Pinquier J, 2003, IEEE INT C AC SPEECH
   PLACKETT RL, 1983, INT STAT REV, V51, P59, DOI 10.2307/1402731
   Ramirez J., 2007, FUNDAMENTALS SPEECH, DOI 10.5772/4740
   Rosenhahn B., 2007, HUMAN MOTION UNDERST
   Scheirer E, 1997, IEEE INT C AC SPEECH
   Schmalenstroeer J, 2010, IEEE J-STSP, V4, P845, DOI 10.1109/JSTSP.2010.2050519
   Sivakumaran P, 2001, 7 EUR C SPEECH COMM
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Stiefelhagen R, 2008, LECT NOTES COMPUTER
   Sung J, 2008, INT J COMPUT VISION, V80, P260, DOI 10.1007/s11263-007-0125-1
   Tamura S, 2004, J VLSI SIG PROC SYST, V36, P117, DOI 10.1023/B:VLSI.0000015091.47302.07
   TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726
   Truong BT, 2000, ACM INT C MULT
   Tsai WH, 2005, IEEE INT C AC SPEECH
   Vajaria H, 2006, ICPR 06 INT C PATT R
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Viola P, 2003, ICCV 03 IEEE INT C C
   Yang MH, 2009, ENCY BIOMETRICS
   Zhou BW, 2005, IEEE T SPEECH AUDI P, V13, P467, DOI 10.1109/TSA.2005.845790
   Zhu X, 2008, MULTIMODAL TECHNOLOG
NR 68
TC 21
Z9 21
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 747
EP 775
DI 10.1007/s11042-012-1080-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000012
DA 2024-07-18
ER

PT J
AU Liang, ZJ
   Wang, MJ
   Zhou, XC
   Lin, L
   Li, WJ
AF Liang, Zhuojia
   Wang, Mingjia
   Zhou, Xiaocong
   Lin, Liang
   Li, Wenjun
TI Salient object detection based on regions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Saliency features; Center-surround;
   Color-distribution; Region growing and combination
ID VISUAL-ATTENTION; FEATURE CONTRAST; SEGMENTATION
AB Salient object detection aims to automatically localize the attractive objects with respect to surrounding background in an image. It can be applied to image browsing, image cropping, image compression, content-based image retrieval, and etc. In the literature, the low-level (pixel-based) features (e.g., color and gradient) were usually adopted for modeling and computing visual attention; these methods are straightforward and efficient but limited by performance, due to losing global organization and inference. Some recent works attempt to use the region-based features but often lead to incomplete object detection. In this paper, we propose an efficient approach of salient object detection using region-based representation, in which two novel region-based features are extracted for proposing salient map and the salient object are localized with a region growing algorithm. Its brief procedure includes: 1) image segmentation to get disjoint regions with characteristic consistency; 2) region clustering; 3) computation of the region-based center-surround feature and color-distribution feature; 4) combination of the two features to propose the saliency map; 5) region growing for detecting salient object. In the experiments, we evaluate our method with the public dataset provided by Microsoft Research Asia. The experimental results show that the new approach outperforms other four state-of-the-arts methods with regard to precision, recall and F-measure.
C1 [Liang, Zhuojia; Wang, Mingjia; Lin, Liang; Li, Wenjun] Sun Yat Sen Univ, Sch Software, Guangzhou 510275, Guangdong, Peoples R China.
   [Liang, Zhuojia; Wang, Mingjia; Zhou, Xiaocong] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510275, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University
RP Li, WJ (corresponding author), Sun Yat Sen Univ, Sch Software, Guangzhou 510275, Guangdong, Peoples R China.
EM lnslwj@mail.sysu.edu.cn
RI l, j/JVZ-8480-2024; L, J/JEF-9564-2023; Li, Wen-Jun/ACA-8525-2022; LU,
   LU/JEZ-4760-2023; l, j/HNC-5728-2023; Lin, L/HKO-8213-2023; zhou,
   you/KBC-3567-2024
OI Li, Wen-Jun/0000-0002-1233-736X; 
FU National Natural Science Foundation of China [60970156, 61173082];
   Fundamental Research Funds for the Central Universities
   [2010620003162041, 10LGZD05]; SYSU-Sugon high performance computing
   typical application projects [62000-1132001]
FX Supported by National Natural Science Foundation of China (under Grant
   nos. 60970156 and 61173082), Fundamental Research Funds for the Central
   Universities (Grant nos. 2010620003162041 and 10LGZD05), and SYSU-Sugon
   high performance computing typical application projects (Grant no.
   62000-1132001).
CR [Anonymous], WORKSH COMP ATT APPL
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Cheng HD, 2000, IEEE T IMAGE PROCESS, V9, P2071, DOI 10.1109/83.887975
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Frintrop S, 2005, LECT NOTES COMPUT SC, V3663, P117
   Geerinck Thomas, 2008, Attention in Cognitive Systems. 5th International Workshop on Attention in Cognitive Systems, WAPCV 2008. Revised Selected Papers, P166
   Geerinck T, 2007, LECT NOTES ARTIF INT, V4840, P481
   Gopalakrishnan V, 2009, IEEE T MULTIMEDIA, V11, P892, DOI 10.1109/TMM.2009.2021726
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Kanan C, 2009, VIS COGN, V17, P979, DOI 10.1080/13506280902771138
   Kim S., 2003, LECT NOTES COMPUTER, P523
   Ko B, 2003, INT J PATTERN RECOGN, V17, P1349, DOI 10.1142/S0218001403002939
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Lin L, 2007, P INT C COMP VIS, V1, P419
   Lin L, 2012, PATTERN RECOGN, V45, P231, DOI 10.1016/j.patcog.2011.06.011
   Lin LA, 2010, IEEE T PATTERN ANAL, V32, P1426, DOI 10.1109/TPAMI.2009.150
   Lin L, 2009, PATTERN RECOGN, V42, P1297, DOI 10.1016/j.patcog.2008.10.033
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Lucchese L., 2001, PINSA-A (Proceedings of the Indian National Science Academy) Part A (Physical Sciences), V67, P207
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Meur O L, 2006, IEEE T PATTERN ANAL, V28, P802
   Navalpakkam Vidhya, 2006, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, V2, P2049, DOI DOI 10.1109/CVPR.2006.54
   Nothdurft HC, 2000, VISION RES, V40, P1183, DOI 10.1016/S0042-6989(00)00031-6
   Nothdurft HC, 2000, VISION RES, V40, P3181, DOI 10.1016/S0042-6989(00)00168-1
   Ouerhani N, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P416, DOI 10.1109/ICIAP.2001.957045
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sun YR, 2003, ARTIF INTELL, V146, P77, DOI 10.1016/S0004-3702(02)00399-5
   Treue S, 2003, CURR OPIN NEUROBIOL, V13, P428, DOI 10.1016/S0959-4388(03)00105-3
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Zhang T, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON VEHICULAR ELECTRONICS AND SAFETY, P1, DOI 10.1109/ISEE.2008.4562845
   Zhuang LS, 2009, 2009 INTERNATIONAL CONFERENCE ON MEASURING TECHNOLOGY AND MECHATRONICS AUTOMATION, VOL I, P469, DOI 10.1109/ICMTMA.2009.320
NR 35
TC 10
Z9 12
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 517
EP 544
DI 10.1007/s11042-012-1040-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000002
DA 2024-07-18
ER

PT J
AU Lin, CP
   Chen, HL
   Leu, JS
AF Lin, Chih-Peng
   Chen, Hsing-Lung
   Leu, Jenq-Shiou
TI Modeling and evaluating IPTV applications in WiMAX networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WiMAX; IPTV; Streaming application; Wireless broadband network
AB Internet Protocol-based Television (IPTV) is a digital television service which delivers television content via an IP network. The rapid growth of wireless network technology in recent years has changed, the way people access the Internet. Adding mobility to IPTV can create a truly compelling ubiquitous service which spans different network domains and varied IP-enabled terminals and devices, such as set-top boxes, PCs and cell phones. However, extending IPTV service to wireless networks requires overcoming bandwidth bottlenecks and high packet loss rates. Following the IEEE 802.16 standard, worldwide interoperability for microwave access (WiMAX) features high data rates and large service coverage, offering a wireless broadband solution for IPTV services. While previous research has focused on creating a broadband IPTV service few studies have practically evaluated IPTV applications in a wireless broadband network environment. In this paper, we model and evaluate a common constant bit rate (CBR)(1) based IPTV application and an IPTV live streaming (PPStreaming)(2) application while retrieving IPTV content via a WiMAX network. We also use the NS2 simulation tool to evaluate the performance of these two IPTV applications. The evaluation metrics include latency, packet loss, data rate and throughput statistics when the two IPTV applications are run in the WiMAX network.
C1 [Lin, Chih-Peng; Chen, Hsing-Lung; Leu, Jenq-Shiou] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Lin, CP (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM chih.p37@msa.hinet.net; hlchen@mail.ntust.edu.tw;
   jsleu@mail.ntust.edu.tw
RI Lin, Chih-Peng/N-5343-2016
OI Lin, Chih-Peng/0000-0003-2928-3203
CR Aman M., 2009, Proc. IEEE Global Commun. Conf., Honolulu, P1
   [Anonymous], IEEE STAND LOC METR
   Bektasa T, 2007, THEORY PROB, P2436
   BREIMAN L, 1965, THEOR PROBAB APPL+, V10, P323, DOI 10.1137/1110037
   Chowdhury MZ, 2011, TECHNICAL REPORT, V36, P1
   Deshpande H, 2001, TECHNICAL REPORT, P105
   Etemad K, 2009, IEEE COMMUN MAG, V47, P84, DOI 10.1109/MCOM.2009.5273813
   Germishuizen J. J., 2010, 19 INT C EL MACH ICE, P1, DOI [10.1109/ICELMACH.2010.5608096, DOI 10.1109/ICELMACH.2010.5608096]
   Goldsmith A., 2005, WIRELESS COMMUNICATI
   Hrudey W, 2011, MATH COMPUT MODEL, V53, P2119, DOI 10.1016/j.mcm.2010.08.008
   Kuo WH, 2011, IEEE T MULTIMEDIA, V13, P116, DOI 10.1109/TMM.2010.2082350
   Liu P-C, 2011, 7 C TEL CONFT SANT M, P1
   Liu QW, 2006, IEEE T VEH TECHNOL, V55, P839, DOI 10.1109/TVT.2006.873832
   Matos R, 2009, 7 C TEL CONFT SANT M
   Park EC, 2008, IEEE INFOCOM SER, P1526
   Pizzi S., 2009, IEEE INT C COMM 2009, P1
   Retnasothie F., 2006, IEEE ANN WIR MICR TE, V2006, P1
   Sharma V., 2007, Proc. Mil. Commun. Conf, P1
   SILVERSTON T, 2007, P 17 ACM INT WORKSH, P83
   Sripanidkulchai K., 2004, Proceedings of the 4th ACM SIGCOMM conference on Internet measurement, P41
   Stutzbach R., 2006, ACM SIGCOMM C INT ME, P189, DOI [10.1145/1177080.1177105, DOI 10.1145/1177080.1177105]
   Ullah I, 2009, 10 JOURN DOCT INF RE, P43
   Verdu S., 2011, Multiuser Detection
   WiMAX Forum, 2011, ACM T MULTIMEDIA COM
   Wu C, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1386109.1386112
   YATES RD, 1995, IEEE J SEL AREA COMM, V13, P1341, DOI 10.1109/49.414651
   ZANDER J, 1992, IEEE T VEH TECHNOL, V41, P305, DOI 10.1109/25.155977
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
NR 28
TC 1
Z9 1
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2013
VL 67
IS 3
BP 641
EP 666
DI 10.1007/s11042-012-1041-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 209JD
UT WOS:000323750900007
DA 2024-07-18
ER

PT J
AU Wang, Z
   Liu, GZ
   Yang, Y
AF Wang, Zhe
   Liu, Guizhong
   Yang, Yang
TI A new ROI based image retrieval system using an auxiliary Gaussian
   weighting scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ROI; Image retrieval; AGW; Target region location; Re-ranking
ID SCALE
AB In state-of-the-art region of interest (ROI) based image retrieval systems, the user defined ROI query is considered more effectively reflecting the user's intention than an ROI query automatically selected by the system. Compared with existing image retrieval method, the user defined ROI based image retrieval has two obvious characteristics: One, the target region is located at the center of the ROI query, and two, the ROI query contains hardly any noisy descriptors which do not belong to the target region. Based on these two characteristics and general bag-of-words image retrieval method, an auxiliary Gaussian weighting (AGW) scheme is incorporated into our ROI based image retrieval system. Each of the descriptor is weighted according to its distance between the center of the ROI query, using a 2-d Gaussian window function. The AGW scheme is used to compute the score of each image in database. Meanwhile, an efficient re-ranking algorithm is proposed based on the distribution consistency of the Gaussian weight between the matched descriptors of the ROI query and the candidate image, which is simply written as the DCGW re-ranking. The experimental results demonstrate that our system can obtain satisfactory retrieval results.
C1 [Wang, Zhe; Liu, Guizhong; Yang, Yang] Xi An Jiao Tong Univ, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Liu, GZ (corresponding author), Xi An Jiao Tong Univ, Xianning West Rd 28, Xian 710049, Shaanxi, Peoples R China.
EM liugz@xjtu.edu.cn
FU National High Tech. Project [2009AA01Z409]; National Natural Science
   Foundation of China (NSFC) [60903 121]; National 973 Project
   [2007CB311002]
FX This work is supported in part by National High Tech. Project No.
   2009AA01Z409, National Natural Science Foundation of China (NSFC)
   Project No. 60903 121, and the National 973 Project No. 2007CB311002. We
   would like to thank Prof. Tian Qi for providing database.
CR Agrawal R, 2007, CIRA, P20
   [Anonymous], 2007, CIVR '07
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 2002, COMPUT LINGUIST
   Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785
   Baeza-Yates R., 1999, MODERN INFORM RETRIE, P38
   Chan YK, 2008, IMAGE VISION COMPUT, V26, P1540, DOI 10.1016/j.imavis.2008.04.019
   Chi PH, 2005, INT J SOFTW ENG KNOW, V15, P527, DOI 10.1142/S0218194005002439
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Coleman TF, 1996, SIAM J OPTIMIZ, V6, P418, DOI 10.1137/0806023
   Cui J., 2008, MM 08, P729
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Forsyth DA., 2002, COMPUTER VISION MODE, P720
   Goldberger J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P487
   Hua KA, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P225, DOI 10.1145/319463.319610
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jing F, 2005, IEEE T IMAGE PROCESS, V14, P979, DOI 10.1109/TIP.2005.847289
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   KATO T, 1992, P SOC PHOTO-OPT INS, V1662, P112, DOI 10.1117/12.58497
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   Nister David, 2006, CVPR
   Sadek S, 2009, COMM COM INF SC, V61, P56
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   THOMAS FC, 1994, MATH PROGRAM, V67, P189
   Tian Q, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P746, DOI 10.1109/ICIP.2000.899562
   Torr PHS, 1998, COMPUT VIS IMAGE UND, V71, P312, DOI 10.1006/cviu.1997.0559
   Vu K, 2003, IEEE T KNOWL DATA EN, V15, P1045, DOI 10.1109/TKDE.2003.1209021
   Wallach HM, 2006, 23 INT C MACH LEARN
   Wang ZZ, 2008, 2008 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND INFORMATION TECHNOLOGY, PROCEEDINGS, P338, DOI 10.1109/MMIT.2008.149
   Worring M, 2000, LECT NOTES COMPUT SC, V1929, P26
   Wu Z, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPRW.2009.5206566
   Yang J, 2007, INT WORKSH MULT INF
   Zhang J, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 4, PROCEEDINGS, P740, DOI 10.1109/FSKD.2007.493
   Zhao WL, 2006, LECT NOTES COMPUT SC, V4071, P72
   Zhou Q, 2005, MULTIMED TOOLS APPL, V27, P251, DOI 10.1007/s11042-005-2577-z
NR 40
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2013
VL 67
IS 3
BP 549
EP 569
DI 10.1007/s11042-012-1059-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 209JD
UT WOS:000323750900002
DA 2024-07-18
ER

PT J
AU Nam, Y
   Rho, S
   Park, JH
AF Nam, Yunyoung
   Rho, Seungmin
   Park, Jong Hyuk
TI Inference topology of distributed camera networks with multiple cameras
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Multi-camera; Intelligent system; People tracking;
   Camera network topology
ID MAXIMUM-LIKELIHOOD; TRACKING; OBJECTS; SYSTEM
AB This paper proposes an inference method to construct the topology of a camera network with overlapping and non-overlapping fields of view for a commercial surveillance system equipped with multiple cameras. It provides autonomous object detection, tracking and recognition in indoor or outdoor urban environments. The camera network topology is estimated from object tracking results among and within FOVs. The merge-split method is used for object occlusion in a single camera and an EM-based approach for extracting the accurate object feature to track moving people and establishing object correspondence across multiple cameras. The appearance of moving people and the transition time between entry and exit zones is measured to track moving people across blind regions of multiple cameras with non-overlapping FOVs. Our proposed method graphically represents the camera network topology, as an undirected weighted graph using the transition probabilities and 8-directional chain code. The training phase and the test were run with eight cameras to evaluate the performance of our method. The temporal probability distribution and the undirected weighted graph are shown in the experiments.
C1 [Nam, Yunyoung] SUNY Stony Brook, Mobile Syst Design Lab, Dept Elect & Comp Engn, Stony Brook, NY 11794 USA.
   [Rho, Seungmin] Baekseok Univ, Div Informat & Commun, Chungnam, South Korea.
   [Park, Jong Hyuk] Seoul Natl Univ Sci & Technol, Seoul, South Korea.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook; Baekseok University; Seoul National University of
   Science & Technology
RP Rho, S (corresponding author), Baekseok Univ, Div Informat & Commun, Chungnam, South Korea.
EM young022@gmail.com; seungminrho@aol.com; jhpark1@seoultech.ac.kr
RI Rho, Seungmin/HTP-6683-2023; Nam, Yunyoung/AAI-4536-2020
OI Nam, Yunyoung/0000-0002-3318-9394
FU Ubiquitous Computing and Network (UCN) Project; Knowledge and Economy
   Frontier R&D Program of the Ministry of Knowledge Economy (MKE); Korean
   government [11C3-T3-10M]; MKE (The Ministry of Knowledge Economy),
   Korea, under the ITRC (Information Technology Research Center)
   [NIPA-2011-C1090-1131-0004]
FX This research was supported by the Ubiquitous Computing and Network
   (UCN) Project, Knowledge and Economy Frontier R&D Program of the
   Ministry of Knowledge Economy (MKE), the Korean government, as a result
   of UCN's subproject 11C3-T3-10M and this research is also supported by
   the MKE (The Ministry of Knowledge Economy), Korea, under the ITRC
   (Information Technology Research Center) support program supervised by
   the NIPA (National IT Industry Promotion Agency)
   (NIPA-2011-C1090-1131-0004).
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   [Anonymous], 2003, JOINT IEEE INT WORKS
   Black J., 2004, Intelligent Distributed Surveillance Systems (IDSS-04), P21
   Cai Q., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P68, DOI 10.1109/ICPR.1996.546796
   Cai Q, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P356, DOI 10.1109/ICCV.1998.710743
   Chen M, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/36871
   Chen M, 2007, IEEE WIREL COMMUN, V14, P20, DOI 10.1109/MWC.2007.4407223
   Chen M, 2010, IEEE INTELL SYST, V25, P12, DOI 10.1109/MIS.2010.44
   Chen M, 2010, IEEE WIREL COMMUN, V17, P37, DOI 10.1109/MWC.2010.5416348
   Chen Min., 2013, The Journal of Supercomputing, V65, P287, DOI DOI 10.1007/S11227-010-0475-2
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dick AR, 2004, LECT NOTES ARTIF INT, V3339, P160
   Fisher RB, 2002, LECT NOTES COMPUT SC, V2353, P146
   Funiak S, 2006, IPSN 2006: THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, P34
   Gilbert A, 2008, COMPUT VIS IMAGE UND, V111, P43, DOI 10.1016/j.cviu.2007.06.005
   Haritaoglu I, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P222, DOI 10.1109/AFGR.1998.670952
   Haritaoglu I., 1998, EUR C COMPUTER VISIO, P877
   Huang T, 1997, INT JOINT CONF ARTIF, P1276
   Javed O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P952
   KaewTrakulPong P, 2003, IMAGE VISION COMPUT, V21, P913, DOI 10.1016/S0262-8856(03)00076-3
   Kelly P., 1995, PROC 3 ACE INT C MUL, P201
   Kettnaker V, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P267, DOI 10.1109/MMCS.1999.778358
   Makris D, 2005, IEEE T SYST MAN CY B, V35, P397, DOI 10.1109/TSMCB.2005.846652
   Makris D, 2004, PROC CVPR IEEE, P205
   Marinakis D, 2005, IEEE INT CONF ROBOT, P4581
   Min Chen, 2011, Mobile Networks and Applications, V16, P171, DOI 10.1007/s11036-010-0260-8
   Moorim Kim, 2009, Proceedings of the 2009 International Conference on Image Processing, Computer Vision, & Pattern Recognition. IPCV 2009, P492
   Niu CW, 2006, INT C PATT RECOG, P944
   Rahimi A, 2004, PROC CVPR IEEE, P187
   REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034
   Stauffer C., 2005, Proc. IEEE Comp. Soc. Wkshp. Motion and Video Computing, P96
   STURGES J, 1995, COLOR RES APPL, V20, P364, DOI 10.1002/col.5080200605
   Tieu K, 2005, IEEE I CONF COMP VIS, P1842
   Welch Greg., 2004, INTRO KALMAN FILTER
   Xiaotao Zou, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P133
NR 35
TC 9
Z9 12
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 1
BP 289
EP 309
DI 10.1007/s11042-012-0997-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 196PN
UT WOS:000322787800015
DA 2024-07-18
ER

PT J
AU Kim, SC
   Yeo, SS
   Kim, SK
AF Kim, Soo-Cheol
   Yeo, Sang-Soo
   Kim, Sung Kwon
TI A hybrid user authentication protocol for mobile IPTV service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPTV; RFID; Java Card; USIM; User authentication
ID SET-TOP BOX; SMART CARD
AB IPTV, a technological convergence that combines communication and broadcasting technologies, delivers customized, interactive TV content and other multimedia information over wired and wireless connections. Providing secure access to IPTV services calls for authentication, without proper and secure authentication mechanisms, an individual impersonating a subscriber could steal a service. This paper proposes a new authentication protocol to authenticate IPTV users. The authors based the proposed protocol, a hybrid authentication protocol providing lightweight, personalized user authentication, on RFID (radio-frequency identification) and USIM (Universal Subscriber Identity Module) technologies. In the proposed protocol, USIM performs highly personalized authentication, and the authenticated subscriber's RFID tags can have a temporary authority to execute authentication. These RFID tags become Agent Tags authorized to authenticate subscribers. Agent Tags identify and authenticate themselves to RFID readers in the set-top box, thus, simplifying the authentication process.
C1 [Kim, Soo-Cheol; Kim, Sung Kwon] Chung Ang Univ, Div Comp Sci & Engn, Seoul 156756, South Korea.
   [Yeo, Sang-Soo] Mokwon Univ, Div Comp Engn, Taejon, South Korea.
C3 Chung Ang University; Mokwon University
RP Kim, SK (corresponding author), Chung Ang Univ, Div Comp Sci & Engn, Seoul 156756, South Korea.
EM sckim@alg.cse.cau.ac.kr; sangsooyeo@gmail.com; skkim@cau.ac.kr
RI Yeo, Sang-Soo/D-3216-2016; Yeo, Sang-Soo/AAD-6176-2020
OI Yeo, Sang-Soo/0000-0002-0224-0150; 
FU National Research Foundation of Korea (NRF); Korea government (MEST)
   [2010-0013121]
FX This work was supported by Basic Science Research Programs through the
   National Research Foundation of Korea (NRF) grand funded by the Korea
   government (MEST) (No. 2010-0013121).
CR Huang YL, 2004, IEEE T MULTIMEDIA, V6, P760, DOI 10.1109/TMM.2004.834861
   Jabbar H, 2008, IEEE T CONSUM ELECTR, V54, P105, DOI 10.1109/TCE.2008.4470031
   Jiang TP, 2004, IEEE T CONSUM ELECTR, V50, P882, DOI 10.1109/TCE.2004.1341695
   Jiang TP, 2004, IEEE T CONSUM ELECTR, V50, P225, DOI 10.1109/TCE.2004.1277866
   Johnston D, 2004, IEEE SECUR PRIV, V2, P40, DOI 10.1109/MSP.2004.20
   Kanjanarim F, 2001, IEEE T CONSUM ELECTR, V47, P47
   Kornfeld M, 2007, IEEE T BROADCAST, V53, P161, DOI 10.1109/TBC.2006.889210
   Lyu J, 2007, INT C ADV COMMUNICAT, V1, P305
   Nicole R, 2001, IEEE T CONSUM ELECTR, V47, P47
   Park YK, 2008, ICHIT 2008: INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, PROCEEDINGS, P618, DOI 10.1109/ICHIT.2008.275
   Tu FK, 1999, IEEE T CONSUM ELECTR, V45, P151, DOI 10.1109/30.754430
   Xu S, 2006, ACM SE REG C, P113
   Yingjiu G, 2007, ISPACS, P554
   Yoon EJ, 2009, INFORMATICA-LITHUAN, V20, P139
   Zhang H, 2006, IMACS, P1680
NR 15
TC 6
Z9 6
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2013
VL 65
IS 2
BP 283
EP 296
DI 10.1007/s11042-011-0810-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 141EJ
UT WOS:000318708100007
DA 2024-07-18
ER

PT J
AU Datta, K
   Sen Gupta, I
AF Datta, Kamalika
   Sen Gupta, Indranil
TI Partial encryption and watermarking scheme for audio files with
   controlled degradation of quality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceptual encryption; Watermarking; Discrete wavelet transformation;
   Commutative watermarking and encryption (CWE)
AB With the rapid progress in communication and multimedia technology, protection of multimedia assets has become a major concern. Encryption and watermarking are two complementary techniques that are used for safeguarding multimedia data like audio, video and images. These methods serve two different purposes; encryption helps in making the media unintelligible, while watermarking helps in providing copyright information in it. In this paper a combination of both encryption and watermarking is incorporated on audio files with this aim in view. Discrete Wavelet Transformation (DWT) is performed on audio files up to third level which gives rise to a binary tree like structure. The areas for watermark embedding and encryption are selected among the wavelet coefficients in the leaf nodes of the tree. Detailed experimentation is carried out with analysis of SNR values, that leads to the determination of degree of degradation of the audio quality after encryption. Such controlled degradation can be used for safe distribution of audio contents over public networks, whereby only the authorized users can have access to the high quality contents, while other users can only access a lower quality version.
C1 [Datta, Kamalika] Bengal Engn & Sci Univ, Dept Informat Technol, Sibpur 711103, Howrah, India.
   [Sen Gupta, Indranil] Indian Inst Technol Kharagpur, Dept Comp Sci & Engn, Kharagpur 721301, W Bengal, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST);
   Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Datta, K (corresponding author), Bengal Engn & Sci Univ, Dept Informat Technol, Sibpur 711103, Howrah, India.
EM kdatta.iitkgp@gmail.com; isg@iitkgp.ac.in
CR [Anonymous], 2002, EUROPEAN NETWORK EXC
   Asokan N, 1998, LECT NOTES COMPUT SC, V1403, P591, DOI 10.1007/BFb0054156
   Cheung S, 2004, 37 HAW INT C SYST SC
   COX I, 2001, MORGAN KAUFMAN SERIE
   Daemen J., 2002, DESIGN RIJNDAEL INFO
   Datta K, 2009, P 13 WORLD MULT SYST, P423
   Dorr G, 2004, INT WORKSH MULT SEC, P133
   Fu Yu, 2004, Journal of Electronic Science and Technology of China, V2, P70
   Gang LT, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P13, DOI 10.1109/ISIMP.2001.925318
   Juan L, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1778
   Lemma A, 2006, LECT NOTES COMPUT SC, V4283, P433
   Li M, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P27
   Lian S, 2006, INT J OPT ENG, V45, P1062
   Lian S, 2006, IEEE CIRCUITS SYST V, V17, P774
   LIAN SG, 2009, MULTIMEDIA CONTENT E
   Lian SG, 2009, MULTIMED TOOLS APPL, V43, P91, DOI 10.1007/s11042-008-0258-4
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Servetti A, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P668
   Servetti A, 2002, IEEE T SPEECH AUDI P, V10, P637, DOI 10.1109/TSA.2002.804300
   SRIDHARAN S, 1991, IEE PROC-I, V138, P215, DOI 10.1049/ip-i-2.1991.0029
   TANG XH, 2005, INT J INFORM TECHNOL, V11, P24
   Wang LX, 2007, ICEMI 2007: PROCEEDINGS OF 2007 8TH INTERNATIONAL CONFERENCE ON ELECTRONIC MEASUREMENT & INSTRUMENTS, VOL II, P423
   WU T, 1997, INT C IM SCI SYST TE
   Yong S, 2005, LECT NOTES COMPUT SC, V3710, P54
NR 25
TC 9
Z9 10
U1 0
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2013
VL 64
IS 3
BP 649
EP 669
DI 10.1007/s11042-011-0969-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126IV
UT WOS:000317608600007
DA 2024-07-18
ER

PT J
AU Li, CL
   Wang, YH
   Ma, B
   Zhang, ZX
AF Li, Chunlei
   Wang, Yunhong
   Ma, Bin
   Zhang, Zhaoxiang
TI Multi-block dependency based fragile watermarking scheme for fingerprint
   images protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile watermarking; Fingerprint; Isolated-block; Tamper detection
ID AUTHENTICATION; LOCALIZATION
AB For traditional fragile watermarking schemes, isolated-block tamper which will destroy the minutiae of the fingerprint image can hardly be efficiently detected. In this paper, we propose a multi-block dependency based fragile watermarking scheme to overcome this shortcoming. The images are split into image blocks with size of 8 x 8; a 64-bit watermark is generated for each image block, and then equally partitioned into eight parts. Each part of the watermark is embedded into another image block which is selected by the corresponding secret key. Theoretic analysis and experimental results demonstrate that the proposed method not only can detect and localize the isolated-block tamper on fingerprint images with high detection probability and low false detection probability, but also enhances the systematic security obviously.
C1 [Li, Chunlei; Wang, Yunhong; Ma, Bin; Zhang, Zhaoxiang] Beihang Univ, Sch Comp Sci & Engn, Beijing, Peoples R China.
C3 Beihang University
RP Li, CL (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing, Peoples R China.
EM lichunlei1979@cse.buaa.edu.cn; yhwang@buaa.edu.cn;
   mabin@cse.buaa.edu.cn; zxzhang@buaa.edu.cn
RI L, Chun/HKW-1738-2023
FU National Natural Science Foundation of China [60873158]; National Basic
   Research Program of China [2010CB 327902]; Fundamental Research Funds
   for the Central Universities; Opening Funding of the State Key
   Laboratory of Virtual Reality Technology and Systems
FX This work was supported by the National Natural Science Foundation of
   China (No. 60873158), the National Basic Research Program of China (No.
   2010CB 327902), the Fundamental Research Funds for the Central
   Universities, and the Opening Funding of the State Key Laboratory of
   Virtual Reality Technology and Systems.
CR Ahmed AF, 2008, J ELECTRON IMAGING, V17, P1
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chang CC, 2006, PATTERN RECOGN LETT, V27, P439, DOI 10.1016/j.patrec.2005.09.006
   Chen WC, 2009, EXPERT SYST APPL, V36, P1300, DOI 10.1016/j.eswa.2007.11.018
   Deguillaume F, 2003, SIGNAL PROCESS, V83, P2133, DOI 10.1016/S0165-1684(03)00172-5
   Fridrich J, 2002, J ELECTRON IMAGING, V11, P262, DOI 10.1117/1.1459449
   He HJ, 2010, MULTIMED TOOLS APPL, V1, P1
   He HJ, 2009, LECT NOTES COMPUT SC, V5806, P132
   He HJ, 2009, SIGNAL PROCESS, V89, P1557, DOI 10.1016/j.sigpro.2009.02.009
   He HJ, 2008, LECT NOTES COMPUT SC, V5284, P147
   Ho ATS, 2008, IEEE T INF FOREN SEC, V3, P567, DOI 10.1109/TIFS.2008.926994
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Jea TY, 2005, PATTERN RECOGN, V38, P1672, DOI 10.1016/j.patcog.2005.03.016
   Li CT, 2006, OPT ENG, V45, DOI 10.1117/1.2402932
   Liu SH, 2007, APPL MATH COMPUT, V185, P869, DOI 10.1016/j.amc.2006.07.036
   Noore A, 2007, FORENSIC SCI INT, V169, P188, DOI 10.1016/j.forsciint.2006.08.019
   Ohkita K, 2009, LECT NOTES COMPUT SC, V5703, P279, DOI 10.1007/978-3-642-03688-0_25
   Pankanti S, 1999, P SOC PHOTO-OPT INS, V3657, P66, DOI 10.1117/12.344704
   Ratha NK, 2004, LECT NOTES COMPUT SC, V3087, P205
   Suthaharan S, 2004, PATTERN RECOGN LETT, V25, P1893, DOI 10.1016/j.patrec.2004.08.017
   Wong PW, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P455, DOI 10.1109/ICIP.1998.723526
   Wu JH, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P931, DOI 10.1109/ICME.2004.1394354
   Yu M, 2007, SCI CHINA SER F, V50, P491, DOI 10.1007/s11432-007-0024-7
   Zebbiche K, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/918601
   Zhang J, 2004, P IEEE ICME 04, V89, P157
   Zhang X, 2007, IEEE SIGNAL PROC LET, V14, P727, DOI 10.1109/LSP.2007.896436
NR 26
TC 11
Z9 11
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2013
VL 64
IS 3
BP 757
EP 776
DI 10.1007/s11042-011-0974-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126IV
UT WOS:000317608600012
DA 2024-07-18
ER

PT J
AU Seo, S
   Park, Y
   Ostromoukhov, V
AF Seo, SangHyun
   Park, YoungSub
   Ostromoukhov, Victor
TI Image recoloring using linear template mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recoloring; Templates; Color contrast; Color transfer
ID COLOR TRANSFER; ENHANCEMENT; ADJUSTMENT; GREYSCALE
AB We propose an artistic recoloring method that enhances the perception of complex scenes, while preserving the visual quality of the original image. Our algorithm employs the template which contains the information of color theme. The colors of template is selected based on the Munsell color and are designed on the a (auaEuro parts per thousand) b (auaEuro parts per thousand) chromatic plane of the CIE L (auaEuro parts per thousand) a (auaEuro parts per thousand) b (auaEuro parts per thousand) color space. Template can be used to recolor the original image with simpler and more focused color contrasts. The proposed algorithm consists of the three steps. First, we calculate the regression line for the colors on the original image and the template. Then we create a transformation refer to the relationship between the two regression lines. This transformation is used to change the color distribution in the source image. Finally, the transformed color distribution is mapped from the chromatic a (auaEuro parts per thousand) b (auaEuro parts per thousand) plane to become the template.
C1 [Seo, SangHyun; Ostromoukhov, Victor] Univ Lyon 1, LIRIS, F-69365 Lyon, France.
   [Park, YoungSub] AR Vis Corp, Taejon, South Korea.
C3 Institut National des Sciences Appliquees de Lyon - INSA Lyon;
   Universite Claude Bernard Lyon 1
RP Seo, S (corresponding author), Univ Lyon 1, LIRIS, F-69365 Lyon, France.
EM shseo75@gmail.com; aupres98@hanmail.net;
   victor.ostromoukhov@liris.cnrs.fr
RI Sanghyun, Seo/ADZ-4404-2022
OI Sanghyun, Seo/0000-0002-4824-3517
FU Korea Research Foundation; Korean Government [KRF-2011-357-D00202];
   French institutional grant [AMCQMCSGA ANR-10-CEXC-002]
FX This work was supported by the Korea Research Foundation Grant funded by
   the Korean Government (KRF-2011-357-D00202) and has been partly
   supported by French institutional grant AMCQMCSGA ANR-10-CEXC-002.
CR An XB, 2010, COMPUT GRAPH FORUM, V29, P263, DOI 10.1111/j.1467-8659.2009.01595.x
   [Anonymous], GRAMMER COLORS
   [Anonymous], 2007, PROC 3 EUR C COMPUTA
   [Anonymous], 1989, COLOR CHOICES MAKING
   [Anonymous], ACM T GRAPH
   [Anonymous], 2002, UNDERSTANDING COLOR
   [Anonymous], OIL PAINTING
   Bae SM, 2006, ACM T GRAPHIC, V25, P637, DOI 10.1145/1141911.1141935
   Bruckner S, 2007, IEEE T VIS COMPUT GR, V13, P1344, DOI 10.1109/TVCG.2007.70555
   Chang Y., 2005, ACM Trans. Appl. Perception, V2, P322
   Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933
   Gooch AA, 2005, ACM T GRAPHIC, V24, P634, DOI 10.1145/1073204.1073241
   Hou Xiaodi., 2007, Proceedings of the 15th ACM International Conference on Multimedia, MM'07, P265
   Ironi R., 2005, RENDERING TECHNIQUES, P201
   Krawczyk G, 2007, COMPUT GRAPH FORUM, V26, P581, DOI 10.1111/j.1467-8659.2007.01081.x
   Lischinski D, 2006, ACM T GRAPHIC, V25, P646, DOI 10.1145/1141911.1141936
   Liu XP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409105
   Luft T, 2006, ACM T GRAPHIC, V25, P1206, DOI 10.1145/1141911.1142016
   Pei SC, 2006, IEEE T IMAGE PROCESS, V15, P3230, DOI 10.1109/TIP.2006.877478
   Pouli T., 2010, Proceedings ofNPAR, P81
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Seo S, 2013, MULTIMED TOOLS APPL, V65, P221, DOI 10.1007/s11042-011-0796-z
   Seo S, 2010, VISUAL COMPUT, V26, P421, DOI 10.1007/s00371-010-0505-3
   Shapira L, 2009, COMPUT GRAPH FORUM, V28, P629, DOI 10.1111/j.1467-8659.2009.01403.x
   Smith K, 2008, COMPUT GRAPH FORUM, V27, P193, DOI 10.1111/j.1467-8659.2008.01116.x
   Tai YW, 2005, PROC CVPR IEEE, P747
   Wang BY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866172
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Xiao Xuezhong, 2006, PACM INT C VIRT REAL, P305, DOI DOI 10.1145/1128923.1128974
NR 30
TC 8
Z9 10
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 2
BP 293
EP 308
DI 10.1007/s11042-012-1024-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 116IM
UT WOS:000316876200005
DA 2024-07-18
ER

PT J
AU Zhao, HL
   Jin, XG
   Mao, XY
AF Zhao, Hanli
   Jin, Xiaogang
   Mao, Xiaoyang
TI Real-time directional stylization of images and videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-photorealistic rendering; Image abstraction; GPU
ID ABSTRACTION
AB This paper describes a real-time non-photorealistic rendering system that automatically produces stylistic effects from photos and videos. The algorithm includes the capture of salient shapes in the image using a smooth direction field and the abstraction of both colors and shapes along the direction field. In addition to the directional stylization, the proposed algorithm has many good properties. First, the temporal coherence is preserved without any extra processing. Second, the level of abstraction can be controlled within constant time complexity. Last but not least, the parallel GPU implementation allows the real-time stylization of online videos. A variety of experimental results demonstrate the effectiveness of the system in producing high-quality abstract illustrations.
C1 [Zhao, Hanli] Wenzhou Univ, Intelligent Informat Syst Inst, Wenzhou 325035, Peoples R China.
   [Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
   [Mao, Xiaoyang] Univ Yamanashi, Kofu, Yamanashi, Japan.
C3 Wenzhou University; Zhejiang University; University of Yamanashi
RP Zhao, HL (corresponding author), Wenzhou Univ, Intelligent Informat Syst Inst, Wenzhou 325035, Peoples R China.
EM hanlizhao@gmail.com; jin@cad.zju.edu.cn; mao@yamanashi.ac.jp
OI mao, xiaoyang/0000-0001-9531-3197
FU National Natural Science Foundation of China [61100146, 60933007,
   60833007]; Zhejiang Provincial Natural Science Foundation of China
   [Y1110004]; NSFC-MSRA [60970159]
FX The authors would like to thank the anonymous reviewers for their
   helpful and constructive comments and suggestions in improving the
   paper. Many thanks also to Kyprianidis for letting the test images
   available. This work was supported by the National Natural Science
   Foundation of China (Grant No. 61100146) and the Zhejiang Provincial
   Natural Science Foundation of China (Grant No. Y1110004). Xiaogang Jin
   was supported by the NSFC-MSRA Joint Funding (Grant No. 60970159) and
   the National Natural Science Foundation of China (Grants No. 60933007
   and No. 60833007).
CR [Anonymous], P IEEE INT C MULT EX
   [Anonymous], 2000, COLOR SCI CONCEPTS M
   Cabral B., 1993, Computer Graphics Proceedings, P263, DOI 10.1145/166117.166151
   Chen J, 2007, ACM T GRAPHIC, V26, DOI [10.1109/SARNOF.2007.4567317, 10.1145/1276377.1276506, 10.1145/1239451.1239554]
   Collomosse JP, 2005, IEEE T VIS COMPUT GR, V11, P540, DOI 10.1109/TVCG.2005.85
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DeCarlo D, 2002, ACM T GRAPHIC, V21, P769, DOI 10.1145/566570.566650
   Deriche R., 1992, ICIP 92. Proceedings of the 2nd Singapore International Conference on Image Processing, P263
   Hertzmann A., 2010, Proc. NPAR '10, P147
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Kang H, 2009, IEEE T VIS COMPUT GR, V15, P62, DOI 10.1109/TVCG.2008.81
   Kang H, 2008, COMPUT GRAPH FORUM, V27, P1773, DOI 10.1111/j.1467-8659.2008.01322.x
   Kuwahara M., 1976, Digital Processing of Biomedical Images, P187, DOI [DOI 10.1007/978-1-4684-0769-3_13, 10.1007/978-1-4684-0769-313, DOI 10.1007/978-1-4684-0769-313, 10.1007/978-1-4684-0769-3_13]
   Kyprianidis JE, 2011, COMPUT GRAPH FORUM, V30, P593, DOI 10.1111/j.1467-8659.2011.01882.x
   Kyprianidis JE, 2009, COMPUT GRAPH FORUM, V28, P1955, DOI 10.1111/j.1467-8659.2009.01574.x
   Lu SF, 2012, IEEE COMPUT GRAPH, V32, P26, DOI 10.1109/MCG.2011.51
   NVIDIA Corporation, 2010, CUD PROGR GUID CUD T
   Papari G, 2007, IEEE T IMAGE PROCESS, V16, P2449, DOI 10.1109/TIP.2007.903912
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang J, 2004, ACM T GRAPHIC, V23, P574, DOI 10.1145/1015706.1015763
   Weickert J., 1996, ANISOTROPIC DIFFUSIO
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Zeng K, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640445
   Zhao HL, 2008, VISUAL COMPUT, V24, P727, DOI 10.1007/s00371-008-0254-8
   Zhao HL, 2009, VISUAL COMPUT, V25, P973, DOI 10.1007/s00371-008-0308-y
   Zhao HL, 2009, LECT NOTES COMPUT SC, V5670, P390, DOI 10.1007/978-3-642-03364-3_47
NR 26
TC 4
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2013
VL 63
IS 3
BP 647
EP 661
DI 10.1007/s11042-011-0890-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 110YF
UT WOS:000316483000003
DA 2024-07-18
ER

PT J
AU Jiang, XM
   Liu, Q
   Wu, QY
AF Jiang Xuemei
   Liu Quan
   Wu Qiaoyan
TI A new video watermarking algorithm based on shot segmentation and block
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital video watermarking; Shot segmentation; Block classification;
   Real-time; H.264/AVC
ID DIGITAL WATERMARKING; SCHEME
AB In this paper, we propose a new video watermarking algorithm based on shot segmentation and block classification to enhance the robustness, imperceptibility and real-time performance based on the H.264/AVC codec. A method of selecting host frames is proposed based on shot segmentation to avoid embedding watermark frame by frame, so as to improve the robustness and the real-time performance. The watermark signal is cropped into small watermarks according to the number of shots in the host video, and small watermarks are respectively embedded into different shots. The watermarking capacity and the perceptual quality are greatly improved by this way. A method of selecting host coefficients is proposed based on block classification in the Discrete Cosine Transformation (DCT) compressed domain. The texture characteristics of host blocks are considered in the classification and the places of host coefficients can change adaptively according to the content of the video. The imperceptibility of the watermarked video is greatly improved by this way. The simplified quantization index modulation (QIM) is applied to embed watermark. It brings fewer artifacts to the host signal than the current main watermarking method, such as spread spectrum (SS), differential energy watermarking (DEW) and so on. The experiment results show that the proposed scheme has a good performance in maintaining real-time performance and resisting Gaussian noising, frame swapping, MPEG compression, etc.
C1 [Jiang Xuemei; Liu Quan; Wu Qiaoyan] Wuhan Univ Technol, Sch Informat Engn, Wuhan 430070, Hubei Province, Peoples R China.
C3 Wuhan University of Technology
RP Jiang, XM (corresponding author), Wuhan Univ Technol, Sch Informat Engn, 122 Luoshi Rd, Wuhan 430070, Hubei Province, Peoples R China.
EM jxm2001@whut.edu.cn
FU Theme Project of the National High Technology Research and Development
   Program (863 Program) of China;  [2010-IV-065]
FX This research is founded and supported by the Theme Project of the
   National High Technology Research and Development Program (863 Program)
   of China, and the Central Universities under Grant No. 2010-IV-065.
CR [Anonymous], P IEEE INT C IM PROC
   Bavipati Sampath K., 2010, Proceedings of the Seventh International Conference on Information Technology: New Generations (ITNG 2010), P387, DOI 10.1109/ITNG.2010.173
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Doërr G, 2003, SIGNAL PROCESS-IMAGE, V18, P263, DOI 10.1016/S0923-5965(02)00144-3
   El'Arbi M, 2011, MULTIMED TOOLS APPL, V55, P579, DOI 10.1007/s11042-010-0580-5
   Guil N, 2007, LECT NOTES COMPUT SC, V4477, P451
   Hu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1231
   Kyung-Su Kim, 2007, Digital Watermarking. Proceedings 6th International Workshop, IWDW 2007, P323
   Lin WH, 2009, LECT NOTES COMPUT SC, V5574, P165
   Shaohui Liu, 2010, Proceedings of the 2010 International Conference on Intelligent Computation Technology and Automation (ICICTA 2010), P587, DOI 10.1109/ICICTA.2010.721
   Shen HF, 2008, IEEE T CIRC SYST VID, V18, P746, DOI 10.1109/TCSVT.2008.918783
   Shen K, LNCS, V2314, P269
   Sun JD, 2006, LECT NOTES COMPUT SC, V3973, P312
   Sun JD, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P56, DOI 10.1109/WCICA.2010.5553953
   Sun TF, 2009, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, VOL I, P179, DOI 10.1109/ISECS.2009.223
   Sun ZW, 2009, NEURAL COMPUT APPL, V18, P507, DOI 10.1007/s00521-009-0253-3
   Tian LH, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P1295, DOI 10.1109/APSCC.2008.72
   Wang XY, 2010, MULTIDIM SYST SIGN P, V21, P179, DOI 10.1007/s11045-009-0096-1
   Wu CH, 2010, INT J ELECT COMMUN A
   Yen SH, 2009, JCPC: 2009 JOINT CONFERENCE ON PERVASIVE COMPUTING, P155, DOI 10.1109/JCPC.2009.5420198
   Zheng XS, 2008, 2008 ISECS INTERNATIONAL COLLOQUIUM ON COMPUTING, COMMUNICATION, CONTROL, AND MANAGEMENT, VOL 1, PROCEEDINGS, P276, DOI 10.1109/CCCM.2008.103
NR 21
TC 11
Z9 12
U1 0
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2013
VL 62
IS 3
BP 545
EP 560
DI 10.1007/s11042-011-0857-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 086VF
UT WOS:000314715500001
DA 2024-07-18
ER

PT J
AU Li, B
   Johan, H
AF Li, Bo
   Johan, Henry
TI 3D model retrieval using hybrid features and class information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; Hybrid shape descriptor; Class information;
   Integrated distance
ID SHAPE RETRIEVAL; CLASSIFICATION; BENCHMARK; SEARCH
AB To improve the retrieval performance on a classified 3D model database, we propose a 3D model retrieval algorithm based on a hybrid 3D shape descriptor ZFDR and a class-based retrieval approach CBR utilizing the existing class information of the database. The hybrid 3D shape descriptor ZFDR comprises four features, depicting a 3D model from different aspects and it itself is already comparable to or better than several related shape descriptors. To compute the distance between a query model and a target model within a class of a database, we define an integrated distance metric which takes into account the class information. It scales the distance between the query model and the target model according to the distance between the query model and the class. Our class-based retrieval approach CBR is general, it can be used with any shape descriptors to improve their retrieval performance. Extensive generic and partial 3D model retrieval experiments on seven standard databases demonstrate that after we employ CBR, the retrieval performance of our algorithm CBR-ZFDR is evidently improved and the result is better than that achieved by the state-of-the-art method on each database in terms of most of the commonly used performance metrics.
C1 [Li, Bo; Johan, Henry] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Li, B (corresponding author), Nanyang Technol Univ, Sch Comp Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
EM libo0002@ntu.edu.sg
CR AIM@SHAPE, 2010, SHREC CONT
   Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   [Anonymous], 2007, P INT C IMAGE PROCES
   [Anonymous], 2006, P EUR IT CHAPT C
   [Anonymous], EUR WORKSH 3D OBJ RE, DOI DOI 10.2312/3DOR/3DOR08/009-016
   Axenopoulos A, 2011, P 1 INT C MULT RETR
   Ben-Chen M., 2008, Proceedings of the 1st Eurographics Conference on 3D Object Retrieval, P1
   Biasotti S, 2007, LECT NOTES COMPUT SC, V4816, P140
   Bustos B, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1303, DOI 10.1109/ICME.2004.1394465
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Cohen S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1076, DOI 10.1109/ICCV.1999.790393
   Cornea ND, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P366, DOI 10.1109/SMI.2005.1
   Dengsheng Zhang, 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P652
   Fang R, 2008, LECT NOTES COMPUT SC, V5358, P381, DOI 10.1007/978-3-540-89639-5_37
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Godil A., 2009, 3DOR@ Eurographics, P61
   Han EH, 2000, LECT NOTES COMPUT<D>, V1910, P424
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073
   Iyer N, 2005, COMPUT AIDED DESIGN, V37, P509, DOI 10.1016/j.cad.2004.07.002
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Jayanti S, 2006, COMPUT AIDED DESIGN, V38, P939, DOI 10.1016/j.cad.2006.06.007
   Kazhdan M., 2003, P EUR ACM SIGGRAPH S, V6, P156
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Laga H, 2008, LECT NOTES ARTIF INT, V4938, P210, DOI 10.1007/978-3-540-78159-2_20
   Leng BA, 2011, MULTIMED TOOLS APPL, V51, P935, DOI 10.1007/s11042-009-0424-3
   Lian ZH, 2010, INT J COMPUT VISION, V89, P130, DOI 10.1007/s11263-009-0295-0
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   SHIH JL, 2009, MULTIMED TOOLS APPL, V43, P45, DOI DOI 10.1007/S11042-008-0256-6
   Shilane P., 2004, P INT C SHAPE MODELI, DOI DOI 10.1109/SMI.2004.1314504
   Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Suyu Hou, 2005, Computer-Aided Design and Applications, V2, P155
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Tatsuma A, 2009, VISUAL COMPUT, V25, P785, DOI 10.1007/s00371-008-0304-2
   Tierny J, 2009, COMPUT GRAPH FORUM, V28, P41, DOI 10.1111/j.1467-8659.2008.01190.x
   Toldo R., 2009, Proceedings of the 2nd Eurographics Conference on 3D Object Retrieval, P21
   Veltkamp RC, 2007, UUCS2007015 DEP INF
   Vranic DV, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P963
   VRANIC DV, 2004, THESIS U LEIPZIG
   Wessel Raoul., 2009, Eurographics 2009 Workshop on 3D Object Retrieval, P53
   Xiaoyong Liu, 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P186
   Xu D, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P774, DOI 10.1109/ICIG.2007.13
   Zhang D.S., 2001, Proceedings of International Conference on Intelligent Multimedia and Distance Education(ICIMADE01), P1
   Zhouhui Lian, 2010, Proceedings of the Shape Modeling International (SMI 2010), P25, DOI 10.1109/SMI.2010.20
NR 48
TC 54
Z9 64
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2013
VL 62
IS 3
BP 821
EP 846
DI 10.1007/s11042-011-0873-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 086VF
UT WOS:000314715500013
DA 2024-07-18
ER

PT J
AU Angelides, MC
   Sofokleous, AA
AF Angelides, Marios C.
   Sofokleous, Anastasis A.
TI A game approach to optimization of bandwidth allocation using MPEG-7 and
   MPEG-21
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG-7; MPEG-21; Game Theory
ID OPTIMAL RESOURCE-ALLOCATION; ADAPTATION; NETWORKS; SERVICE;
   TRANSMISSION; FRAMEWORK; QUALITY; ALGORITHMS; MANAGEMENT; FAIRNESS
AB Resource allocation aims at optimizing the usage of shared resources and maximizing the end-user experience by determining the optimum sharing of resources and choosing whom to serve, how and when. Approaches addressing this challenge are driven by the requirements of the environment and the characteristics of users. This paper addresses the challenge of optimising resource allocation through the combined application of game theory and normative tools such MPEG-21 and MPEG-7. The resulting game play leads to a forced Nash equilibrium where a change of strategy will not make any player better off.
C1 [Angelides, Marios C.; Sofokleous, Anastasis A.] Brunel Univ, Sch Engn & Design, Uxbridge UB8 3PH, Middx, England.
C3 Brunel University
RP Angelides, MC (corresponding author), Brunel Univ, Sch Engn & Design, Uxbridge UB8 3PH, Middx, England.
EM marios.angelides@brunel.ac.uk
CR Abrahams B, 2010, LECT NOTES ARTIF INT, V6070, P102, DOI 10.1007/978-3-642-13480-7_12
   Akkarajitsakul K, 2011, IEEE COMMUN MAG, V49, P120, DOI 10.1109/MCOM.2011.5978425
   Altman E, 2006, COMPUT OPER RES, V33, P286, DOI 10.1016/j.cor.2004.06.005
   Andrei D, 2008, IEEE ICC, P5354, DOI 10.1109/ICC.2008.1004
   Angelides M.C., 2011, The Handbook of MPEG Application: Standards in Practice
   Angelides M, 2006, LECT NOTES COMPUT SC, V4132, P55
   Angelides MC, 2006, LECT NOTES COMPUT SC, V3983, P118, DOI 10.1007/11751632_13
   [Anonymous], 2009, COMPLEXITY COMPUTING
   Bilasco IM, 2010, P 25 ACM S APPL COMP, P1366
   Boche H, 2008, IEEE T WIREL COMMUN, V7, P1163, DOI 10.1109/TWC.2008.060940
   CANIFF A, 2010, P 19 INT C WORLD WID, P1069
   Chakareski J, 2006, IEEE T MULTIMEDIA, V8, P207, DOI 10.1109/TMM.2005.864284
   Chao SL, 2008, MOBIHOC'08: PROCEEDINGS OF THE NINTH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING, P461
   Cheng X, 2010, NOSSDAV 2010: PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO, P15
   Cranley N, 2005, MULTIMEDIA SYST, V10, P392, DOI 10.1007/s00530-005-0168-5
   Creus-Mir A, 2008, COMPUT COMMUN, V31, P257, DOI 10.1016/j.comcom.2007.08.001
   Del Re E, 2008, IEEE VTS VEH TECHNOL, P2937, DOI 10.1109/VETECS.2008.307
   Elghirani AH, 2008, IEEE ACM INT SYMP, P433, DOI 10.1109/CCGRID.2008.22
   Elias J, 2007, COMPUT NETW, V51, P2833, DOI 10.1016/j.comnet.2006.12.003
   Fang ZY, 2004, IEEE INFOCOM SER, P1284
   Feng N, 2004, IEEE T COMMUN, V52, P1547, DOI 10.1109/TCOMM.2004.833191
   Fotakis D, 2008, THEOR COMPUT SCI
   Gruhne M, 2007, AXMEDIS 2007: THIRD INTERNATIONAL CONFERENCE ON AUTOMATED PRODUCTION OF CROSS MEDIA CONTENT FOR MULTI-CHANNEL DISTRIBUTION, PROCEEDINGS, P15, DOI 10.1109/AXMEDIS.2007.40
   Guturu P, 2008, STUD COMPUT INTELL, V96, P51
   Hsiao JL, 2008, IEEE T MULTIMEDIA, V10, P646, DOI 10.1109/TMM.2008.921852
   Huang JW, 2008, IEEE J SEL AREA COMM, V26, P1226, DOI 10.1109/JSAC.2008.080919
   Jannach D, 2006, APPL INTELL, V24, P109, DOI 10.1007/s10489-006-6933-0
   Ji Z, 2007, IEEE COMMUN MAG, V45, P88, DOI 10.1109/MCOM.2007.358854
   Jiang GY, 2010, INFORM SCIENCES, V180, P225, DOI 10.1016/j.ins.2009.09.014
   Kalasapur S, 2005, I S WORLD WIREL MOBI, P258, DOI 10.1109/WOWMOM.2005.77
   Keshav K, 2011, PROCEEDINGS OF THE TENTH INTERNATIONAL CONFERENCE ON NETWORKS (ICN 2011), P273
   Key P, 2010, PERFORM EVAL REV, V38
   Kim S, 2011, IET COMMUN, V5, P371, DOI 10.1049/iet-com.2010.0309
   Kung HY, 2006, IEEE T CONSUM ELECTR, V52, P240
   Li ZJ, 2009, COMPUT LANG SYST STR, V35, P406, DOI 10.1016/j.cl.2008.08.001
   Lin S, 2009, NOSSDAV 09: 18TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO, P7
   Londo NJ, 2009, BUCSTR2009002
   Lu Fan, 2010, International Journal of Advanced Media and Communication, V4, P108, DOI 10.1504/IJAMC.2010.032138
   LUCAS C., 2006, PRACTICAL MULTIOBJEC
   Ma R. T. B., 2004, Performance Evaluation Review, V32, P189, DOI 10.1145/1012888.1005711
   Ma RTB, 2006, IEEE ACM T NETWORK, V14, P978, DOI 10.1109/TNET.2006.882904
   Maheswaran RT, 1998, IEEE DECIS CONTR P, P1090, DOI 10.1109/CDC.1998.760843
   Martínez JM, 2007, J AM SOC INF SCI TEC, V58, P1374, DOI 10.1002/asi.20581
   Meshkati F, 2007, IEEE SIGNAL PROC MAG, V24, P58, DOI 10.1109/MSP.2007.361602
   Mukherjee D, 2005, IEEE T MULTIMEDIA, V7, P454, DOI 10.1109/TMM.2005.846798
   Nakhimovsky Y., 2009, CHI '09 Extended Abstracts on Human Factors in Computing Systems, New York, NY, USA, P4795
   Neely MJ, 2008, IEEE ACM T NETWORK, V16, P396, DOI 10.1109/TNET.2007.900405
   Ogryczak W, 2008, OMEGA-INT J MANAGE S, V36, P451, DOI 10.1016/j.omega.2005.12.005
   Prangl M, 2007, IEEE T CIRC SYST VID, V17, P719, DOI 10.1109/TCSVT.2007.896650
   Ranganathan P, 2006, COMPUTER, V39, P31, DOI 10.1109/MC.2006.89
   Roughgarden T, 2010, COMMUN ACM, V53, P78, DOI 10.1145/1785414.1785439
   Saad W, 2009, IEEE SIGNAL PROC MAG, V26, P77, DOI 10.1109/MSP.2009.000000
   Sahasrabudhe A, 2008, 2008 42ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1-3, P761, DOI 10.1109/CISS.2008.4558623
   Salonen H, 2010, INT J GAME THEORY, V39, P351, DOI 10.1007/s00182-009-0180-7
   Santana-Quintero LV, 2010, ADAPT LEARN OPTIM, V2, P29
   Schuster Alfons, 2010, Advances in Artificial Intelligence, DOI 10.1155/2010/521606
   Shoham Y, 2008, COMMUN ACM, V51, P74, DOI 10.1145/1378704.1378721
   Silvestre-Blanes J, 2011, IEEE T IND ELECTRON, V58, P1061, DOI 10.1109/TIE.2010.2049711
   Sofokleous AA, 2006, J MOBILE MULTIMEDIA, V2, P112
   Sofokleous AA, 2006, J MOBILE MULTIMEDIA, V2, P297
   Sofokleous AA, 2008, MULTIMED TOOLS APPL, V40, P151, DOI 10.1007/s11042-008-0198-z
   Sofokleous AA, 2009, COMPUT J, V52, P413, DOI 10.1093/comjnl/bxn035
   Tardos E, 2004, P 36 ANN ACM S THEOR, P341
   Teller P. J., 2006, Operating Systems Review, V40, P83, DOI 10.1145/1131322.1131339
   van der Kuijl A, 2010, CONCURR COMP-PRACT E, V22, P314, DOI 10.1002/cpe.1481
   Veeravalli B, 2006, MULTIMED TOOLS APPL, V28, P89, DOI 10.1007/s11042-006-5116-7
   Venkataraman H, 2011, IEEE T MOBILE COMPUT, V10, P532, DOI 10.1109/TMC.2010.170
   Vetro A, 2005, IEEE T MULTIMEDIA, V7, P418, DOI 10.1109/TMM.2005.846795
   Vetro A, 2006, MPEG 21, P282
   Yu F, 2003, IEEE T CIRC SYST VID, V13, P257, DOI 10.1109/TCSVT.2003.809829
   Zhang JZ, 2010, COMPUT OPTIM APPL, V45, P89, DOI 10.1007/s10589-008-9173-x
   Zibreira C, 2010, RES ADV TECH DIGITAL, P332
   Zitzler E, 1999, IEEE T EVOLUT COMPUT, V3, P257, DOI 10.1109/4235.797969
NR 73
TC 3
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 1
BP 287
EP 309
DI 10.1007/s11042-011-0981-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OL
UT WOS:000313965800013
DA 2024-07-18
ER

PT J
AU Singh, R
   Hsu, YW
   Moon, N
AF Singh, Rahul
   Hsu, Ya-Wen
   Moon, Naureen
TI Multiple perspective interactive search: a paradigm for exploratory
   search and information retrieval on the web
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Exploratory web search; Human-computer interaction; Information
   retrieval; Experiential interfaces; Direct manipulation; Multiple
   perspective search; Information visualization; Spatial search; Temporal
   search; Multimedia information systems; Information goal; User-media
   interaction
ID SEMANTICS
AB The World Wide Web (WWW) represents the largest and arguably the most complex repository of content at our current state of technological development. Information on the web is represented using a variety of media, with a (current) predominance of text- and images-based data and increasing presence of other media such as video and audio. The complexity and heterogeneity of the information implies that the associated semantics is often user-dependent and emergent. Thus, there is a need to develop novel paradigms for web-based user-data interactions that emphasize user context and interactivity with the goal of facilitating exploration, interpretation, retrieval, and assimilation of information. This article presents a novel presentation-interaction paradigm for exploratory web search which allows simultaneous and semantically correlated presentation of query results from different semantic perspectives. Users can explore the results either using a specific perspective or through a combination of perspectives via highly-intuitive yet powerful interaction operators. In the proposed paradigm, hits obtained from executing a query are first analyzed to determine latent content-based correlations between the pages. Next, the pages are analyzed to extract different types of perceptual and informational cues. This information is used to organize and present the results through an interactive and reflective user interface which supports both exploration and search. Experimental investigations, many of which are conducted in comparative settings, analyze the proposed approach in query-retrieval scenarios involving complex information goals. These results demonstrate the efficacy of the proposed approach and provide important insights for the development of the next-generation of interfaces for web-search.
C1 [Singh, Rahul; Hsu, Ya-Wen; Moon, Naureen] San Francisco State Univ, Dept Comp Sci, San Francisco, CA 94132 USA.
C3 California State University System; San Francisco State University
RP Singh, R (corresponding author), San Francisco State Univ, Dept Comp Sci, San Francisco, CA 94132 USA.
EM rahul@sfsu.edu
CR AHLBERG C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P313, DOI 10.1145/191666.191775
   Amitay E., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P273, DOI 10.1145/1008992.1009040
   [Anonymous], 2004, Proceedings of the 12th ACM International Conference on Multimedia, DOI DOI 10.1145/1027527.1027747
   Carpineto C, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541884
   Chau M., 2011, Acm transactions on management information systems (tmis), V2, P1
   Dumais S., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P277, DOI 10.1145/365024.365116
   Ferragina P., 2005, P 14 INT C WORLD WID, P801
   Gemmell J., 2002, P 10 ACM INT C MULTI, P235, DOI DOI 10.1145/641007.641053
   Grosky WI, 2006, INT J COMPUT SCI ENG, V2, P326, DOI 10.1504/IJCSE.2006.014779
   Havre S, 2002, IEEE T VIS COMPUT GR, V8, P9, DOI 10.1109/2945.981848
   Hearst M. A., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P59
   Hoeber O, 2008, INFORM PROCESS MANAG, V44, P485, DOI 10.1016/j.ipm.2007.07.003
   Hoeber O, 2006, INFORMATION VISUALIZATION-BOOK, P157
   Hsu YW, 2006, 2006 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, (WI 2006 MAIN CONFERENCE PROCEEDINGS), P815, DOI 10.1109/WI.2006.58
   Hua-Jun Zeng, 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P210
   Jain R, 2003, COMMUN ACM, V46, P48, DOI 10.1145/792704.792729
   Kammerer Yvonne, 2010, EYE TRACKING RES APP, P299, DOI [10.1145/1743666.1743736, DOI 10.1145/1743666.1743736]
   Kan M.Y., 2004, P 13 INT WORLD WID W, P262
   Kruse P.M., 2005, Clever search: A wordnet based wrapper for internet search engines
   Langer Lars, 2008, P 5 NORD C HUM COMP, V358, P249, DOI 10.1145/1463160.1463187
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Lin X., 1992, Proceedings. Visualization '92 (Cat. No.92CH3201-1), P274, DOI 10.1109/VISUAL.1992.235198
   Marchionini G, 2006, COMMUN ACM, V49, P41, DOI 10.1145/1121949.1121979
   Marcus A., 2000, Interactions, V7, P32, DOI 10.1145/345190.345238
   Mukherjea S, 1999, J VISUAL LANG COMPUT, V10, P585, DOI 10.1006/jvlc.1999.0147
   Nowell L. T., 1996, SIGIR Forum, P67
   Park H, 2008, P INT WORKSH HUM COM, P53
   Perer A, 2009, IEEE COMPUT GRAPH, V29, P39, DOI 10.1109/MCG.2009.44
   Pirolli P, 1999, PSYCHOL REV, V106, P643, DOI 10.1037/0033-295X.106.4.643
   Plaisant C., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P221, DOI 10.1145/238386.238493
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
   Radev DragomirR., 2000, P ACL 2000 WORKSHOP, P99, DOI DOI 10.3115/1117755.1117768
   Resnick M.L., 2001, P HUMAN FACTORS ERGO, V45, P1166, DOI [DOI 10.1177/154193120104501503, 10.1177/154193120, DOI 10.1177/154193120]
   Roberts J, 2002, SIXTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P549, DOI 10.1109/IV.2002.1028828
   Rose D.E., 2004, P 13 INT C WORLD WID, P13, DOI [DOI 10.1145/988672.988675, 10.1145/988672.988675]
   Salmerón L, 2010, COMPUT HUM BEHAV, V26, P419, DOI 10.1016/j.chb.2009.11.013
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Santini S, 2001, IEEE T KNOWL DATA EN, V13, P337, DOI 10.1109/69.929893
   Singh R., 2006, INTERACTIVE COMPUTAT, P323
   SINGH R., 2004, CVDB, P19
   Singh R, 2005, P IEEE INT C MULT EX, P1492
   Singh R, 2007, P 15 INT C MULT MULT, P569
   Singh R, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1031
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Strehl A., 2002, Relationship-Based Clustering and Cluster Ensembles for High-Dimensional Data Mining
   TEEVAN J., 2004, CHI
   Toyama Kentaro., 2003, P 11 ACM INT C MULTI, P156
   Vessey I, 1991, INFORM SYST RES, V2, P63, DOI 10.1287/isre.2.1.63
   Wang X.-J., 2004, MM, P436
   White R.W., 2007, Chi '07 extended abstracts, P2877, DOI DOI 10.1145/1240866.1241100
   White R.W., 2009, Exploratory search: Beyond the queryresponse paradigm
   Wilson M, 2010, J PETROL, V51, P1, DOI 10.1093/petrology/egp099
   Wise J., 1999, Readings in information visualization: using vision to think, P442
   Woodruff A., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P198, DOI 10.1145/365024.365098
   Yee Ka-Ping, 2003, P SIGCHI C HUM FACT, P401, DOI DOI 10.1145/642611.642681
   Zamir O, 1999, COMPUT NETW, V31, P1361, DOI 10.1016/S1389-1286(99)00054-7
   Zubizarreta Alvaro., 2008, CIKM'08: Proceeding of the 17th ACM conference on Information and knowledge management, P1485
NR 58
TC 11
Z9 11
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 2
BP 507
EP 543
DI 10.1007/s11042-011-0910-2
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 076OM
UT WOS:000313965900010
DA 2024-07-18
ER

PT J
AU Sakurai, Y
   Takada, K
   Knauf, R
   Tsuruta, S
AF Sakurai, Yoshitaka
   Takada, Kouhei
   Knauf, Rainer
   Tsuruta, Setsuo
TI A retrieval method adaptively reducing user's subjective impression gap
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information retrieval; Kansei engineering; User profile
AB As an approach to search/retrieve such objects as pictures, music, perfumes and apparels on the Internet, sensitivity-vectors or kansei-vectors are useful since textual keywords are not sufficient to find objects that users want. The sensitivity-vector is an array of values. Each value indicates a degree of feeling or impression represented by a sensitivity word or kansei word. However, due to the gap between user's subjective sensitivity (impression, image and feeling) degree and the corresponding value in the database. Also, such an approach is not enough to retrieve what users want. This paper proposes a retrieval method to automatically and dynamically reduce such gaps by estimating a subjective criterion deviation (we call "SCD") using the user's retrieval history and fuzzy modeling. Additionally, the proposed method can avoid users' burden caused by conventional methods such as completing required questionnaires. This method can also reflect the dynamic change of user's preference which cannot be accomplished by using questionnaires. For the evaluation, an experiment was performed by building and using a perfume retrieval system. Through observing the transition of the deviation reduction degree, it was clarified that the proposed method is effective. In the experiment, the machine could learn users' subjective criteria deviation as well as its dynamic change caused by factors such as user's preference, if the learning rate is well adjusted.
C1 [Sakurai, Yoshitaka; Takada, Kouhei; Tsuruta, Setsuo] Tokyo Denki Univ, Sch Informat Environm, Chiba, Japan.
   [Knauf, Rainer] Ilmenau Univ Technol, Fac Comp Sci & Automat, Ilmenau, Germany.
C3 Tokyo Denki University; Technische Universitat Ilmenau
RP Sakurai, Y (corresponding author), Tokyo Denki Univ, Sch Informat Environm, Chiba, Japan.
EM ysakurai@sie.dendai.ac.jp; tmorotaka@gmail.com;
   rainer.knauf@tu-ilmenau.de; tsuruta@sie.dendai.ac.jp
FU KAKENHI [21700244]; Research Center for Advanced Technologies of Tokyo
   Denki University; Grants-in-Aid for Scientific Research [24700214,
   21700244] Funding Source: KAKEN
FX This work was supported by KAKENHI(21700244) and Research Center for
   Advanced Technologies of Tokyo Denki University.
CR Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867
   Hachimura K, 1996, P 19 ANN INT ACM SIG
   Kato T, 2009, P 15 INT C ADV NER 1
   Kawai Y, 2006, LECT NOTES COMPUT SC, V4080, P549
   Khoshgoftaar T.M., 2009, ADV ARTIFICIAL INTEL, DOI [10.1155/2009/421425, DOI 10.1155/2009/421425]
   Liang Li, 2008, 2008 8th International Conference on Hybrid Intelligent Systems (HIS), P114, DOI 10.1109/HIS.2008.80
   Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583
   Liu A, 2009, P 17 ACM INT C MULT
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   Myint EEP, 2010, 2 INT C SIGN PROC SY, V1, P290
   Ng WF, 2007, ACM T INTERNET TECHN, V7, DOI 10.1145/1278366.1278368
   Orio Nicola, 2006, Foundations and Trends in Information Retrieval, V1, P1, DOI 10.1561/1500000002
   Sato N, 2007, P 2007 C HUM INT 1
   Segaran T., 2007, PROGRAMMING COLLECTI
   SHEN XH, 2005, P 14 ACM INT C INF K
   Shirahama N., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P269, DOI 10.1109/ICSMC.1999.816562
   Sugihara T, 2004, RO-MAN 2004: 13TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P141, DOI 10.1109/ROMAN.2004.1374745
   Sutton R., 1998, Reinforcement Learning: An Introduction
   WONG SKM, 1995, ACM T INFORM SYST, V13, P38, DOI 10.1145/195705.195713
   Yamakawa Y, 2007, BEHAVIORMETRIC SOC J, V35, P65
   Ying H., 2000, FUZZY CONTROL MODELI
   Yu Y, 2009, INT J SEMANT COMPUT, V3, P209, DOI 10.1142/S1793351X09000732
NR 23
TC 1
Z9 1
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 1
BP 25
EP 40
DI 10.1007/s11042-010-0690-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 940DI
UT WOS:000303869800003
DA 2024-07-18
ER

PT J
AU Kumar, P
   Pande, A
   Mittal, A
AF Kumar, Praveen
   Pande, Amit
   Mittal, Ankush
TI Efficient compression and network adaptive video coding for distributed
   video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wavelet transform; Segmentation; Video coding; Distributed video
   surveillance
AB The availability of cheap network based video cameras and the prevalence of wireless networks has lead to a major thrust towards deployment of large scale Distributed Video Surveillance (DVS) systems. This has opened up an important area of research to deal with the issues involved in DVS system for efficient collection and transmission of large scale video streams from the cameras at the guarded sites, to the end users in possibly constrained network conditions. In this paper, we propose a framework based on content-based video classification and scalable compression scheme to provide a robust bandwidth efficient video transmission for DVS. The scheme builds on a Discrete Wavelet Transform (DWT) based Color-Set Partitioning for Hierarchical Trees (CSPIHT) coding to obtain a scalable bitstream. Wavelet domain segmentation and compression assists in development of a DVS architecture. The architecture includes a novel module for dynamic allocation of Network bandwidth based on the current available resources and constraints. Different frame constituents are optimally coded based on their relative significance, perceptual quality, and available estimate of network bandwidth. Experimental result over different video sequences and simulations for Network conditions demonstrate the efficient performance of the approach.
C1 [Kumar, Praveen] Gokaraju Rangaraju Inst Engg & Tech, Dept Comp Sci & Engn, Hyderabad, Andhra Pradesh, India.
   [Pande, Amit] Iowa State Univ, Dept Elect & Comp Engn, Ames, IA 50011 USA.
   [Mittal, Ankush] Coll Engn Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
C3 Gokaraju Rangaraju Institute of Engineering & Technology; Iowa State
   University
RP Kumar, P (corresponding author), Gokaraju Rangaraju Inst Engg & Tech, Dept Comp Sci & Engn, Hyderabad, Andhra Pradesh, India.
EM praveen.kverma@gmail.com; amit@iastate.edu; dr.ankush.mittal@gmail.com
RI Kumar, Praveen/AAA-8584-2022
OI Kumar, Praveen/0000-0003-4820-3088
CR [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   Choi SJ, 1999, IEEE T IMAGE PROCESS, V8, P155, DOI 10.1109/83.743851
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Delp EJ, 1999, 42ND MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, PROCEEDINGS, VOLS 1 AND 2, P635
   Doulamis A, 2006, IEEE IJCNN, P4037
   Huang JC, 2003, ELECTRON LETT, V39, P1380, DOI 10.1049/el:20030909
   Javed O, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P649
   Kim C, 2002, IEEE T CIRC SYST VID, V12, P1128, DOI 10.1109/TCSVT.2002.806813
   Leo M, 2004, LECT NOTES COMPUT SC, V3332, P1019
   Liu Y, 2007, SIGNAL PROCESS-IMAGE, V22, P448, DOI 10.1016/j.image.2007.03.001
   Mahonen P, 1999, INTEGRATION WIRELESS
   Mitchell J.L., 1996, MPEG VIDEO COMPRESSI
   Niu W, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P1144
   Pande A, 2011, ACM T EMBED IN PRESS
   Pavlidis I., 2001, P IEEE, V89
   Qiu R, 2001, WUCS0137 WASH U ST L
   Sacchi C., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P1100, DOI 10.1109/ICIAP.1999.797747
   Said A, 1996, IEEE T IMAGE PROCESS, V5, P1303, DOI 10.1109/83.535842
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Töreyin BU, 2005, SIGNAL PROCESS-IMAGE, V20, P255, DOI 10.1016/j.image.2004.12.002
   Vetro A, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P417
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yang WX, 2006, IEEE T CIRC SYST VID, V16, P1385, DOI 10.1109/TCSVT.2006.884571
NR 26
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 2
SI SI
BP 365
EP 384
DI 10.1007/s11042-010-0672-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AR
UT WOS:000300189100009
DA 2024-07-18
ER

PT J
AU Liu, L
   Zhu, FD
   Jiang, M
   Han, JW
   Sun, LF
   Yang, SQ
AF Liu, Lu
   Zhu, Feida
   Jiang, Meng
   Han, Jiawei
   Sun, Lifeng
   Yang, Shiqiang
TI Mining diversity on social media networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social network; Mining; Diversity
AB The fast development of multimedia technology and increasing availability of network bandwidth has given rise to an abundance of network data as a result of all the ever-booming social media and social websites in recent years, e.g., Flickr, Youtube, MySpace, Facebook, etc. Social network analysis has therefore become a critical problem attracting enthusiasm from both academia and industry. However, an important measure that captures a participant's diversity in the network has been largely neglected in previous studies. Namely, diversity characterizes how diverse a given node connects with its peers. In this paper, we give a comprehensive study of this concept. We first lay out two criteria that capture the semantic meaning of diversity, and then propose a compliant definition which is simple enough to embed the idea. Based on the approach, we can measure not only a user's sociality and interest diversity but also a social media's user diversity. An efficient top-k diversity ranking algorithm is developed for computation on dynamic networks. Experiments on both synthetic and real social media datasets give interesting results, where individual nodes identified with high diversities are intuitive.
C1 [Liu, Lu; Jiang, Meng; Sun, Lifeng; Yang, Shiqiang] Capital Med Univ, Tsinghua Univ, Beijing, Peoples R China.
   [Zhu, Feida] Singapore Management Univ, Sch Informat Syst, Singapore, Singapore.
   [Han, Jiawei] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.
C3 Tsinghua University; Capital Medical University; Singapore Management
   University; University of Illinois System; University of Illinois
   Urbana-Champaign
RP Liu, L (corresponding author), Capital Med Univ, Tsinghua Univ, Beijing, Peoples R China.
EM lu-liu@mails.tsinghua.edu.cn
RI yang, shiqiang/AAH-5484-2019; Jiang, Meng/AAE-4976-2020; Zhu,
   Feida/E-8579-2012
OI Jiang, Meng/0000-0002-3009-519X; Zhu, Feida/0000-0001-6077-4356
FU U.S. National Science Foundation [IIS-08-42769, IIS-09-05215]; NASA
   [NNX08AC35A]; 973 Program of China [2006CB303103]; State Key Program of
   National Natural Science of China [60933013]; NASA [103334, NNX08AC35A]
   Funding Source: Federal RePORTER
FX The work was supported in part by the U.S. National Science Foundation
   grants IIS-08-42769 and IIS-09-05215, and the NASA grant NNX08AC35A, and
   973 Program of China grant 2006CB303103, and the State Key Program of
   National Natural Science of China grant 60933013. Any opinions,
   findings, and conclusions expressed here are those of the authors and do
   not necessarily reflect the views of the funding agencies.
CR [Anonymous], 2006, Elements of Information Theory
   [Anonymous], 2005, P 11 ACM SIGKDD INT, DOI DOI 10.1145/1081870.1081898
   [Anonymous], 2005, PVLDB
   [Anonymous], PAGERANK CITATION RA
   Barabási AL, 2004, NAT REV GENET, V5, P101, DOI 10.1038/nrg1272
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brandes U, 2001, J MATH SOCIOL, V25, P163, DOI 10.1080/0022250X.2001.9990249
   Faloutsos M, 1999, COMP COMM R, V29, P251, DOI 10.1145/316194.316229
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Hwang W., 2008, Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, P336
   Jeh G., 2002, PROC 8 ACM SIGKDD IN, P538
   Kempe D, 2003, P 9 ACM SIGKDD INT C, P137, DOI DOI 10.1145/956750.956769
   Kossinets G., 2008, P 14 ACM SIGKDD INT, P435, DOI DOI 10.1145/1401890.1401945
   Kuramochi M, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P313, DOI 10.1109/ICDM.2001.989534
   Leskovec J., 2005, P 11 ACM SIGKDD INT, P177
   Ng AY, 2002, ADV NEUR IN, V14, P849
   PUTNAM R, 1995, J DEMOCRACY, V0006
   Rosen-Zvi Michal., 2004, UAI
   Spirin V, 2003, P NATL ACAD SCI USA, V100, P12123, DOI 10.1073/pnas.2032324100
   StanleyWasserman Katherine, 1994, SOCIAL NETWORK ANAL, DOI 10.1017/CBO9780511815478
   STEPHENSON K, 1989, SOC NETWORKS, V11, P1, DOI 10.1016/0378-8733(89)90016-6
   Sun Y., 2009, ACM INT C P SERIES, P565, DOI DOI 10.1145/1516360.1516426
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Yan XF, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P721, DOI 10.1109/ICDM.2002.1184038
NR 24
TC 9
Z9 11
U1 0
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 1
SI SI
BP 179
EP 205
DI 10.1007/s11042-010-0568-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 876SH
UT WOS:000299127500009
DA 2024-07-18
ER

PT J
AU Molero, PC
   Reyes, NR
   Candeas, PV
   Bascon, SM
AF Cabanas Molero, Pablo
   Ruiz Reyes, Nicolas
   Vera Candeas, Pedro
   Maldonado Bascon, Saturnino
TI Low-complexity F0-based speech/nonspeech discrimination approach for
   digital hearing aids
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fundamental frequency estimation; Automatic sound classification;
   Digital hearing aids; Difference function; Multilayer perceptron; Hidden
   Markov model
ID SOUND CLASSIFICATION; SPEECH; DRIVEN
AB Digital hearing aids impose strong complexity and memory constraints on digital signal processing algorithms that implement different applications. This paper proposes a low complexity approach for automatic sound classification in digital hearing aids. The proposed scheme, which operates on a frame-by-frame basis, consists of two stages: analysis stage and classification stage. The analysis stage provides a set of low-complexity signal features derived from fundamental frequency (F0) estimation. Here, F0 estimation is performed by a decimated difference function, which results in a reduced-complexity analysis stage. The classification stage has been designed with the aim of reducing the complexity while maintaining high accuracy rates. Three low-complexity classifiers have been evaluated (tree-based C4.5, 1-Nearest Neighbor (1-NN) and a Multilayer Perceptron (MLP)), the MLP being chosen because it provides the best accuracy rates and fits to the computational and memory constraints of ultra low-power DSP-based hearing aids. The classification stage is composed of a MLP classifier followed by a Hidden Markov Model (HMM), providing a good trade-off solution between complexity and classification accuracy rate. The goal of the proposed approach is to perform a robust discrimination among speech/nonspeech parts of audio signals in commercial digital hearing aids, the computational cost being a critical issue. For the experiments, an audio database including speech, music and noise signals has been used.
C1 [Cabanas Molero, Pablo; Ruiz Reyes, Nicolas; Vera Candeas, Pedro] Univ Jaen, Dept Telecommun Engn, Polytech Sch, Jaen, Spain.
   [Maldonado Bascon, Saturnino] Univ Alcala, Dept Signal Theory & Commun, Polytech Sch, Madrid, Spain.
C3 Universidad de Jaen; Universidad de Alcala
RP Reyes, NR (corresponding author), Univ Jaen, Dept Telecommun Engn, Polytech Sch, Jaen, Spain.
EM nicolas@ujaen.es; pvera@ujaen.es; saturnino.maldonado@uah.es
RI Maldonado-Bascon, Saturnino/AAR-4127-2020; Vera-Candeas,
   Pedro/L-3428-2014; Ruiz Reyes, Nicolas/R-5878-2018; Cabanas-Molero,
   Pablo/I-1844-2015
OI Maldonado-Bascon, Saturnino/0000-0001-6472-5359; Vera-Candeas,
   Pedro/0000-0003-0866-703X; Ruiz Reyes, Nicolas/0000-0003-4631-5326;
   Cabanas-Molero, Pablo/0000-0002-2452-6037
FU FEDER; Spanish Ministry of Education and Science [TEC2006-13883-C04-03];
   Andalusian Council [P07-TIC-02713]
FX This work was supported by FEDER, the Spanish Ministry of Education and
   Science under Project TEC2006-13883-C04-03 and the Andalusian Council
   under project P07-TIC-02713. We would like to thank E. Alexandre for
   sharing with us the database designed for digital hearing aid
   applications.
CR Alexandre E., 2007, IEEE INT S INT SIGN
   ALEXANDRE E, 2007, P EUSIPCO 2007 POZN
   Alexandre E, 2007, IEEE T AUDIO SPEECH, V15, P2249, DOI 10.1109/TASL.2007.905139
   Alexandre E, 2008, STUD COMPUT INTELL, V83, P145, DOI 10.1007/978-3-540-75398-8_7
   ALEXANDRECORTIZ.E, 2006, P 120 AUD ENG SOC CO, V2, P1666
   [Anonymous], 2002, J ACOUST SOC AM, DOI DOI 10.1121/1.1458024
   [Anonymous], P 11 INT C DIG AUD E
   [Anonymous], 2005, Speech Enhancement
   Büchler M, 2005, EURASIP J APPL SIG P, V2005, P2991, DOI 10.1155/ASP.2005.2991
   Buchler M. C., 2002, THESIS SWISS FEDERAL
   Cuadra L, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/465189
   DONG R, 2007, P EUSIPCO 2007 POZN
   El-Maleh K, 2000, INT CONF ACOUST SPEE, P2445, DOI 10.1109/ICASSP.2000.859336
   Gil-Pita R, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/456945
   Harb H, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P125, DOI 10.1109/ISSPA.2003.1224831
   Keidser G, 1996, J Am Acad Audiol, V7, P92
   Keidser G, 1995, EAR HEARING, V16, P575, DOI 10.1097/00003446-199512000-00004
   Klapuri A, 2008, IEEE T AUDIO SPEECH, V16, P255, DOI 10.1109/TASL.2007.908129
   Klapuri AP, 2003, IEEE T SPEECH AUDI P, V11, P804, DOI 10.1109/TSA.2003.815516
   Le Roux J, 2007, IEEE T AUDIO SPEECH, V15, P1135, DOI 10.1109/TASL.2007.894510
   Luo FL, 2006, IEEE SIGNAL PROC MAG, V23, P103
   Moore B.C. J., 1989, INTRO PSYCHOL HEARIN
   Nordqvist P, 2004, J ACOUST SOC AM, V115, P3033, DOI 10.1121/1.1710877
   Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN
   Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77, DOI 10.1613/jair.279
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   ROHDENBURG T, 2007, IEEE WORKSH APPL SIG
   Ruiz-Reyes N, 2009, MULTIMED TOOLS APPL, V41, P253, DOI 10.1007/s11042-008-0228-x
   Scheirer E, 1997, INT CONF ACOUST SPEE, P1331, DOI 10.1109/ICASSP.1997.596192
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI 10.1002/0471250953.bia03as18
   VERACANDEAS P, 2008, 124 AUD ENG SOC CONV
   2004, TOCCATA PLUS FLEXIBL
NR 32
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 2
BP 291
EP 319
DI 10.1007/s11042-010-0523-1
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 781SK
UT WOS:000291953700005
DA 2024-07-18
ER

PT J
AU Cruz, RAS
   Nunes, MS
   Menezes, L
   Domingues, J
AF Cruz, Rui A. Santos
   Nunes, Mario Serafim
   Menezes, Leandro
   Domingues, Joao
TI IPTV architecture for an IMS environment with dynamic QoS adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPTV; IP Multimedia Subsystem; SIP; Hybrid SIP plus RTSP
AB This paper describes the development, implementation and evaluation of a SIP based IPTV architecture with a new dynamic QoS adaptation method and signaling structure. The implemented QoS adaptation method allows dynamic updates of session parameters, maximizing the QoE and turning the solution suitable for live multimedia streaming, independently of the cast mode (unicast or multicast). The new SIP signaling structure, for session and media control, was developed following an All-SIP approach and a hybrid SIP+RTSP approach, both suited for an IMS environment, in order to compare the system behavior and performance using either approach. The details of both the IPTV Application Server and the IPTV Client prototypical implementations are described, as well as the results of field tests carried out across different Fixed and Mobile access networks for each of the signaling structures. The proposed IPTV architecture revealed to be suitable for scalable converged networks, due to its flexible multimedia delivery of personalized streams over a variety of network infrastructures, namely, Mobile radio networks.
C1 [Cruz, Rui A. Santos; Nunes, Mario Serafim] Inst Super Tecn UTL, INESC ID, INOV, Lisbon, Portugal.
C3 Universidade de Lisboa; INOV INESC Inovacao; INESC-ID
RP Cruz, RAS (corresponding author), Inst Super Tecn UTL, INESC ID, INOV, Lisbon, Portugal.
EM rui.cruz@inesc-id.pt; mario.nunes@inesc-id.pt; leandro.menezes@ieee.org;
   joao.domingues@ieee.org
RI Nunes, Mario Serafim/AAC-7134-2019; Cruz, Rui António Santos/K-6884-2012
OI Nunes, Mario Serafim/0000-0002-2563-8241; Cruz, Rui António
   Santos/0000-0002-4683-417X
CR Al-Hezmi A, 2008, PROCEEDINGS OF THE FIRST ITU-T KALEIDOSCOPE ACADEMIC CONFERENCE INNOVATIONS IN NGN: FUTURE NETWORK AND SERVICES, P153
   [Anonymous], TR126 BROADB FOR
   [Anonymous], 2020, INT TELECOMMUNICATIO
   *ETSI, 2009, TISPAN TEL INT CONV
   Fabini J, 2006, IEEE VTS VEH TECHNOL, P881
   Floyd S., 2008, Rfc 5348: Tcp friendly rate control (tfrc): Protocol specification
   FOX A, 1997, SIGOPS OPER SYST REV, V31, P78
   HANDLEY M, 1998, RFC 237 SDP SESSION
   HESSELMAN CEW, 2005, THESIS U TWENTE ENSC
   *ISO IEC, 2007, ISOIEC1449622004
   *ISO IEC, 2005, ISOIEC14496102005
   Kerpez K, 2006, IEEE COMMUN MAG, V44, P166, DOI 10.1109/MCOM.2006.1705994
   LEE CS, 2007, BCN2007 IEEEIFIP, P1
   LINDQUIST J, 2009, DRAFT SIP SDP OVERLA
   MIKOCZY E, 2007, MOBIMEDIA 07, P1
   Park HJ, 2007, 9th International Conference on Advanced Communication Technology: Toward Network Innovation Beyond Evolution, Vols 1-3, P945, DOI 10.1109/ICACT.2007.358515
   Ponnappan A, 2002, THIRD INTERNATION WORKSHOP ON POLICIES FOR DISTRIBUTED SYSTEMS AND NETWORKS, PROCEEDINGS, P159, DOI 10.1109/POLICY.2002.1011303
   RIEDE C, 2008, MOBILWARE 08, P1
   ROSENBURG J, 2002, RFC 3311 SESSION INI
   ROSENBURG J, 2002, RFC 3261 SIP SESSION
   Salsano S, 2002, IEEE NETWORK, V16, P38, DOI 10.1109/MNET.2002.1081764
   Schulzrinne H., 1998, RFC 2326 - Real Time Streaming Protocol
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shirey R., 2007, INT C IP MULT SUBS A, P1
   SIVASOTHY S, 2009, DRAFT SIP EXTENSIONS
   Sivasothy S, 2009, 11TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, PROCEEDINGS,, P961
   Vanhastel S, 2008, IEEE COMMUN MAG, V46, P90, DOI 10.1109/MCOM.2008.4597110
   Volk M, 2008, IEEE COMMUN MAG, V46, P118, DOI 10.1109/MCOM.2008.4511660
   Zambelli A., 2009, IIS Smooth Streaming Technical Overview
   Zhang Q, 2005, P IEEE, V93, P123, DOI 10.1109/JPROC.2004.839603
   2009, COMPLETE RRDTOOL BAS
NR 31
TC 6
Z9 6
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2011
VL 53
IS 3
SI SI
BP 557
EP 589
DI 10.1007/s11042-010-0537-8
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 758OK
UT WOS:000290174100005
DA 2024-07-18
ER

PT J
AU Bhatnagar, G
   Raman, B
AF Bhatnagar, Gaurav
   Raman, Balasubramanian
TI A new robust reference logo watermarking scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Reference watermarking; Fractional Fourier
   transform; Singular value decomposition; Space filling curves; Human
   visual system
ID WAVELET-BASED WATERMARKING; ALGORITHM
AB In this paper, a new yet simple reference logo watermarking scheme based on fractional Fourier transform (FrFT) and singular value decomposition (SVD) is proposed. The core idea of the proposed scheme is to segment host image into non-overlapping blocks by the means of Hilbert space filling curve and a reference image is formed by considering Human visual system (HVS). First, reference image is transformed into FrFT domain and embedding is done by modifying singular values of the reference image using singular values of watermark. After embedding, modified reference image is segmented into blocks and these modified blocks are mapped into their original places for constructing watermarked image. For extraction, a reliable watermark extraction scheme is proposed. The experimental results demonstrate better visual imperceptibility and resiliency of the proposed scheme against intentional or un-intentional variety of attacks.
C1 [Bhatnagar, Gaurav; Raman, Balasubramanian] Indian Inst Technol Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Bhatnagar, G (corresponding author), Indian Inst Technol Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
EM goravdma@gmail.com; balaiitr@ieee.org
RI Raman, Balasubramanian/D-1282-2012; Bhatnagar, Gaurav/O-5817-2019
OI Bhatnagar, Gaurav/0000-0002-0282-3372
FU Council of Scientific and Industrial Research, New Delhi, India
   [09/143(0559)/2006-EMR-I]
FX One of the authors, Gaurav Bhatnagar, gratefully acknowledges the
   financial support of the Council of Scientific and Industrial Research,
   New Delhi, India through his Senior Research Fellowship (SRF) scheme
   (CSIR Award no.: 09/143(0559)/2006-EMR-I) for his research work.
CR [Anonymous], P INT WORKSH VID PRO
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Candan Ç, 2000, IEEE T SIGNAL PROCES, V48, P1329, DOI 10.1109/78.839980
   Chandra DVS, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P264
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Cox I., 2001, Digital Watermarking
   Djurovic I, 2001, J NETW COMPUT APPL, V24, P167, DOI 10.1006/jnca.2000.0128
   Ganic E, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2137650
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Hsia SC, 2002, IEICE T FUND ELECTR, VE85A, P463
   HUANG JW, 1999, J IMAGE GRAPHICS, V4, P400
   Hwang MS, 1999, IEEE T CONSUM ELECTR, V45, P286, DOI 10.1109/30.793411
   KATZENSEISSER S, 2000, INFORM HIDING TECHNI
   Kundur D, 2004, IEEE T MULTIMEDIA, V6, P185, DOI 10.1109/TMM.2003.819747
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Lewis N., 2003, P IASTED INT C COMM, V33, P85
   Li M, 2006, PATTERN RECOGN LETT, V27, P1948, DOI 10.1016/j.patrec.2006.05.004
   Li Q, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P1947, DOI 10.1109/ICACT.2007.358752
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Liu JL, 2006, COMPUT STAND INTER, V28, P356, DOI 10.1016/j.csi.2005.07.001
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Liu X, 2004, APPL MATH COMPUT, V149, P641, DOI 10.1016/S0096-3003(03)00168-1
   MCBRIDE AC, 1987, IMA J APPL MATH, V39, P159, DOI 10.1093/imamat/39.2.159
   Moon B, 2001, IEEE T KNOWL DATA EN, V13, P124, DOI 10.1109/69.908985
   Mooney A, 2008, CHAOS SOLITON FRACT, V35, P913, DOI 10.1016/j.chaos.2006.05.073
   NAMIAS V, 1980, J I MATH APPL, V25, P241
   Ozaktas H.M., 2001, FRACTIONAL FOURIER T
   Pei SC, 1998, SIGNAL PROCESS, V67, P99, DOI 10.1016/S0165-1684(98)00024-3
   Pereira S, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P671, DOI 10.1109/ICIP.2000.899543
   Pereira S, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P870, DOI 10.1109/MMCS.1999.779316
   RAMKUMAR M, 1999, P IEEE INT C IM PROC, V2, P211
   Rose NicholasJ., 2001, Hilbert-type space-filling curves
   Sagan H., 1994, SPACE FILLING CURVES
   Strang G., 1993, INTRO LINEAR ALGEBRA, V3
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Yu F., 2006, P 1 IEEE C IND EL AP, P1
   Zhang F, 2005, I S INTELL SIG PROC, P141
NR 42
TC 23
Z9 25
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 621
EP 640
DI 10.1007/s11042-009-0433-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000021
DA 2024-07-18
ER

PT J
AU Zeng, XA
   Chen, ZY
   Xiong, Z
AF Zeng, Xiao
   Chen, Zhenyong
   Xiong, Zhang
TI Issues and solution on distortion drift in reversible video data hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Compressed video; Distortion drift; Lossless
   drift compensation
ID WATERMARKING
AB Different from reversible image data hiding, most reversible video data hiding schemes have the particular problem that the distortion due to hidden data will spread and accumulate. In this paper, the problem of distortion drift caused by reversible data hiding in compressed video is analyzed, and a lossless drift compensation scheme is proposed to restrain the distortion for the first time. In order to ensure the reversibility, drift compensation signals are merged in the quantized DCT (Discrete Cosine Transform) coefficients of P-frames and the corresponding recovery mechanism is presented as well. Experimental results demonstrate that the proposed lossless drift compensation scheme significantly improves the video quality, and the original compressed video can be recovered exactly after the hidden data and compensation signals are removed. In addition, the proposed scheme does not depend on specific reversible data hiding method.
C1 [Zeng, Xiao; Chen, Zhenyong; Xiong, Zhang] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
C3 Beihang University
RP Zeng, XA (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
EM zengxiao29@gmail.com
CR Alattar AM, 2003, IEEE T CIRC SYST VID, V13, P787, DOI 10.1109/TCSVT.2003.815958
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Biswas S, 2005, IEEE T INSTRUM MEAS, V54, P1853, DOI 10.1109/TIM.2005.855084
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chen C, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 5, PROCEEDINGS, P605, DOI 10.1109/CISP.2008.194
   Chen CC, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P489
   Chen H, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL III, PROCEEDINGS, P37, DOI 10.1109/IITA.2008.451
   Du R, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P893
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Fridrich J, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P223, DOI 10.1109/ITCC.2001.918795
   Furht B., 1995, Real-Time Imaging, V1, P49, DOI 10.1006/rtim.1995.1005
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Lin SL, 2007, ROUTLEDGE STUD GROWT, V72, P1
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Winne DA, 2002, INT CONF ACOUST SPEE, P3457
   Xuan GR, 2007, LECT NOTES COMPUT SC, V4633, P715
   ZENG X, 2010, J COMPUT RE IN PRESS, V47
NR 19
TC 15
Z9 16
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 465
EP 484
DI 10.1007/s11042-010-0476-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000013
DA 2024-07-18
ER

PT J
AU Omerovic, S
   Babovic, Z
   Tafa, Z
   Milutinovic, V
   Tomazic, S
AF Omerovic, Sanida
   Babovic, Zoran
   Tafa, Zhilbert
   Milutinovic, Veljko
   Tomazic, Saso
TI Concept modeling: From origins to multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Concepts; Knowledge; Ontology; Semantics; Multimedia; Retrieval;
   Understanding; Data; Relations; Representation
AB The origins of concept modeling are in the field of artificial intelligence. This is where the initial algorithms were introduced first. With the emerging developments in the field of multimedia systems, a strong need is generated to examine and implement concepts-based retrieval of multimedia-contents, from large data bases or from the Internet. The early works were based on appropriate modifications of classical approaches. The latest developments utilize the algorithms that make sense only in the case of multimedia systems. This paper presents a number of classical approaches to concept modeling and their applicability to multimedia. Then it discusses a number of approaches introduced specifically for multimedia. Finally it presents an approach which was fully implemented and tested in an academic environment for industry needs.
C1 [Babovic, Zoran; Milutinovic, Veljko] Univ Belgrade, Sch Elect Engn, Belgrade, Serbia.
   [Omerovic, Sanida; Tomazic, Saso] Univ Ljubljana, Ljubljana, Slovenia.
   [Tafa, Zhilbert] Univ Podgor & Telekom Montenegro, Podgorica, Montenegro.
   [Milutinovic, Veljko] Singidunum Univ, Belgrade, Serbia.
C3 University of Belgrade; University of Ljubljana
RP Babovic, Z (corresponding author), Univ Belgrade, Sch Elect Engn, Belgrade, Serbia.
EM zbabovic@gmail.com
RI Tomazic, Saso/A-2018-2008; Tafa, Zhilbert/ABU-8059-2022
OI Babovic, Zoran/0000-0002-8651-2730; Tomazic, Saso/0000-0002-2968-8879
FU Purdue University, West Lafayette, Indiana, USA [2588-1314]
FX This research was conceptualized at Purdue University, West Lafayette,
   Indiana, USA, as a part of the grant # 2588-1314.
CR [Anonymous], 1998, The Symbolic Species: The Co-evolution of Language and the Brain
   [Anonymous], 2007, DATA INTENSIVE SUPER
   BABOVIC Z, 2010, P VIPSI 2010 AMALFI
   BALLAN L, 2010, IEEE MULTIM IN PRESS
   CHAN C, 2004, CAN C EL COMP ENG 2, V3, P1353
   Chein M., 1992, REV DINTELLIGENCE AR, V6, P365
   CHEN H, 2003, ONTOLOGY CONTEXT AWA, V18
   CHEN P, 2007, ACM T DATABASE SYST, V1, P9
   CHUA TS, 1994, P 27 ANN HAW INT C S, V3, P590
   COOK D, 2007, SUBDUE GRAPH BASED K
   Diligenti M, 2010, IPSI BDG TRANS INTER, V6, P18
   DJORDJEVIC N, 2010, IPSI T INTERNET RES, V6, P27
   DOU D, 2004, ONTOLOGY TRANSLATION
   FRAWLEY WJ, 1992, KNOWLEDGE DISCOVERY
   Fujihara H, 1997, IEEE T KNOWL DATA EN, V9, P209, DOI 10.1109/69.591447
   GAUCH S, 2002, ITTCFY2004TR864637 U
   GIUGNO R, 2007, GRAPHGREP
   Gómez-Pérez A, 2002, IEEE INTELL SYST, V17, P54, DOI 10.1109/5254.988453
   HALLADAY S, 2004, P 37 ANN HAW INT C S
   HALPIN T, 2007, OBJECT ROLE MODELING
   Han JW, 1996, IEEE T KNOWL DATA EN, V8, P373, DOI 10.1109/69.506706
   HAWKINS J, 2007, IEEE SPECTRUM ON APR
   HOLLINK L, 2005, P 13 ANN ACM INT C M, P479
   HOOGS A, 2003, P C COMP VIS PATT RE
   HUNTER J, 2001, INT SEM WEB WORK S
   JUNG MY, 2008, ITC CSCC 2008 JAP, P45
   MILUTINOVIC V, 2010, P VIPSI 2010 AMALFI
   NAKABASAMI C, 2002, INT SEM WEB C ISWC20
   Novak J., 2005, 200601 FLOR I HUM MA
   QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1007/BF00117105
   Rubin DL, 2009, IEEE INTELL SYST, V24, P57, DOI 10.1109/MIS.2009.3
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   SIEGEL, 1985, BASICS IMAGE UNDERST
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sowa J., 1999, LECT NOTES COMPUTER, P1
   Sowa JF, 2000, LECT NOTES ARTIF INT, V1867, P55
   *STANF U, 2006, CONC MOD SOFTW PACK
   Varga E, 2010, IPSI BDG TRANS INTER, V6, P5
   VIOLA P, 2001, 2000101 CRL
   VOSS A, 1999, INT WORKSH EN TECHN, P245
   Vrochidis Stefanos, 2008, International Journal of Metadata, Semantics and Ontologies, V3, P167, DOI 10.1504/IJMSO.2008.023566
   WAN X, 2009, BOOK ADV INFORM RETR, P749
   WOODS W, 1997, TR9761 SUN MICR
   Yan R., 2009, P 1 ACM WORKSHOP LAR, P35, DOI DOI 10.1145/1631058.1631067
   Zellweger P, 2003, INTERNATIONAL CONFERENCE ON INTEGRATION OF KNOWLEDGE INTENSIVE MULTI-AGENT SYSTEMS, P747, DOI 10.1109/KIMAS.2003.1245131
   2007, DAML ONTOLOGIES
NR 46
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2011
VL 51
IS 3
BP 1175
EP 1200
DI 10.1007/s11042-010-0642-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 717XL
UT WOS:000287081100015
DA 2024-07-18
ER

PT J
AU Wang, SC
   Chung, TC
   Yan, KQ
AF Wang, S. C.
   Chung, T. C.
   Yan, K. Q.
TI A new territory of multi-user variable remote control for interactive TV
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive TV; Variable remote controller; Human-computer interaction;
   Multi-user interaction
AB Unlike passive analog TV, interactive TV (iTV) is the next step toward interactivity that offers users a friendly interactive experience. As there are fewer studies focused on multi-user interaction in a local environment, we concentrate on multi-user interaction with families, especially within a home information system. Therefore, we propose a control service framework "MVC-iTV," based on distributed computing and Machine-to-Machine (M2M) communications, in which external displays (TVs or projectors) and handheld devices can be used for controlling iTV services by several members of the family at the same time, without any relocation. Further, the new remote control framework can free users from the restrictions of using one remote controller. The experiment results indicate that the MVC-iTV framework is applicable to the iTV service and that users can operate the service in any visible environment via wireless networking technologies. Besides, requirements of the hardware compatibility of the TV appliance and remote controller will be reduced in the MVC-iTV framework.
C1 [Wang, S. C.; Yan, K. Q.] Chaoyang Univ Technol, Dept Business Adm, Taichung, Taiwan.
   [Chung, T. C.] Hwa Hsia Inst Technol, Taipei, Taiwan.
C3 Chaoyang University of Technology
RP Yan, KQ (corresponding author), Chaoyang Univ Technol, Dept Business Adm, Taichung, Taiwan.
EM scwang@cyut.edu.tw; clock@cc.hwh.edu.tw; kqyan@cyut.edu.tw
FU Taiwan National Science Council [NSC95-2221-E-324-019-MY3,
   NSC96-2221-E-324-021]
FX This work was supported in part by the Taiwan National Science Council,
   under Grants NSC95-2221-E-324-019-MY3 and NSC96-2221-E-324-021.
CR [Anonymous], REMOTE CONTROL
   [Anonymous], TV Remote Controller Website
   Benford S., 2000, ACM Transactions on Computer-Human Interaction, V7, P510, DOI 10.1145/365058.365095
   BING J, 2001, P 7 INT C VIRT SYST, P147
   Cesar P, 2008, LECT NOTES COMPUT SC, V5066, P168, DOI 10.1007/978-3-540-69478-6_22
   Fallahkhair S, 2005, IEEE INTERNATIONAL WORKSHOP ON WIRELESS AND MOBILE TECHNOLOGIES IN EDUCATION, PROCEEDINGS, P85, DOI 10.1109/WMTE.2005.20
   Fallahkhair S, 2004, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P16, DOI 10.1109/ICALT.2004.1357366
   Ferscha A., 2002, Pervasive Computing. First International Conference, Pervasive 2002. Proceedings (Lecture Notes in Computer Science Vol.2414), P84
   FURHT B, 1995, COMPUTER, V28, P25, DOI 10.1109/2.384116
   Goularte Rudinei., 2004, Proceedings o f the 2004 ACM symposium on Document engineering, Milwaukee, Wisconsin, USA, P84, DOI DOI 10.1145/1030397.1030414
   *INT, AD TUN FLASH TV DEV
   Jensen J.F., 2005, Proc. the Second Australasian Conference on Interactive entertaINPent, P89
   LANKOSKI P, 2003, EUR C INT TEL BRIGHT, P2
   Myers BA, 2004, COMPUTER, V37, P36, DOI 10.1109/MC.2004.258
   *OP IPTV FOR, MEMB OP IPTV FOR
   Sanguinetti A, 2003, PERS UBIQUIT COMPUT, V7, P163, DOI 10.1007/s00779-003-0225-z
   Sohn M, 2004, IEEE T CONSUM ELECTR, V50, P413, DOI 10.1109/TCE.2004.1309402
   *SUNW TECHN CORP, PROD SUNW TECHN CORP
   *WIK, IPTV WIK
   Xiao Y, 2007, IEEE COMMUN MAG, V45, P126, DOI 10.1109/MCOM.2007.4378332
   ZALETELJ J, 2007, INT WORKSH IM AN MUL, P413
   TECH LAB VINT CERF
   SMARTPHONES 2007 ARP
   PALABRE XML SOCKET P
   Q STAT PDA SMARTPHON
NR 25
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2011
VL 51
IS 3
BP 1013
EP 1034
DI 10.1007/s11042-009-0435-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 717XL
UT WOS:000287081100009
DA 2024-07-18
ER

PT J
AU Gao, Y
   Chen, JZ
   Yu, SS
   Yang, J
   Zhou, JL
AF Gao, Yi
   Chen, Jiazhong
   Yu, Shengsheng
   Yang, Jie
   Zhou, Jingli
TI A hybrid <i>M</i>-channel filter bank and DCT framework for H.264/AVC
   intra coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE M-channel filter bank; Discrete cosine transform; Intra coding;
   H.264/AVC
ID INTEGER TRANSFORM; PREDICTION; DESIGN
AB In H. 264/AVC, discrete cosine transform (DCT) is performed on the residual blocks after prediction. However, the mismatch between variable block sizes and the fixed transform matrix not only degrades decorrelation performance but also causes severe blocky artifacts inside the blocks. In previous work, M-channel filter bank system (MCFBS) was proposed to overcome these defects. However, the increased percentage of encoding time by using MCFBS is very high, especially for intra coding. More seriously, the constructed M-channel filter bank with floating-point coefficients is an obstacle to hardware implementation. In this work, a hybrid M-channel Filter bank and DCT (HMD) framework is proposed for intra coding. Besides, the integer transform of a newly constructed M-channel filter bank is also implemented for HMD. Experimental results demonstrate that HMD can reduce 64-69% of the complexity of MCFBS with negligible quality degradation.
C1 [Gao, Yi; Chen, Jiazhong; Yu, Shengsheng; Yang, Jie; Zhou, Jingli] Huazhong Univ Sci & Technol, Dept Comp Sci, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Yu, SS (corresponding author), Huazhong Univ Sci & Technol, Dept Comp Sci, Wuhan 430074, Peoples R China.
EM gaoyi@smail.hust.edu.cn; ssyu@mail.hust.edu.cn
RI Yu, Sheng-Sheng/AAE-4862-2022
OI Yu, Sheng-Sheng/0000-0003-1304-5630
CR CHAM WK, 1989, IEE PROC-I, V136, P276, DOI 10.1049/ip-i-2.1989.0039
   Chan SC, 1998, IEEE T SIGNAL PROCES, V46, P1142, DOI 10.1109/78.668566
   Chen J, 2008, IET IMAGE PROCESS, V2, P263, DOI 10.1049/iet-ipr:20070140
   Chen JZ, 2006, MULTIMED TOOLS APPL, V29, P175, DOI 10.1007/s11042-006-0006-6
   Fan CP, 2006, IEEE T CIRCUITS-II, V53, P174, DOI 10.1109/TCSII.2005.858748
   GREGOIRE P, 2005, P INT C AC SPEECH SI
   Hao PW, 2001, IEEE T SIGNAL PROCES, V49, P2314, DOI 10.1109/78.950787
   He ZH, 2008, IEEE T CIRC SYST VID, V18, P851, DOI 10.1109/TCSVT.2008.919087
   *JVT, 2005, NVTN011
   Lee YL, 2006, ETRI J, V28, P668, DOI 10.4218/etrij.06.0206.0095
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   Lin CJ, 2000, IEEE T CIRC SYST VID, V10, P1496, DOI 10.1109/76.889059
   Oraintara S, 2002, IEEE T SIGNAL PROCES, V50, P607, DOI 10.1109/78.984749
   PEI SC, 2006, P INT S CIRC SYST IS
   Shui PL, 2004, IEEE T SIGNAL PROCES, V52, P2500, DOI 10.1109/TSP.2004.832013
   Shui PL, 2001, IEEE T SIGNAL PROCES, V49, P1704, DOI 10.1109/78.934140
   Steinbach E, 1997, IEEE T CIRC SYST VID, V7, P872, DOI 10.1109/76.644067
   Suh K, 2005, ETRI J, V27, P511, DOI 10.4218/etrij.05.0905.0032
   Sullivan GJ, 2004, P SOC PHOTO-OPT INS, V5558, P454, DOI 10.1117/12.564457
   SULLIVAN GJ, 2004, P SPIE C APPL DIGITA, V27
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   TRAC DT, 2000, IEEE T SIGNAL PROCES, V48, P133
   Tran TD, 2000, IEEE SIGNAL PROC LET, V7, P141, DOI 10.1109/97.844633
   TSAI AC, 2007, P 2007 INT C MULT EX
   Tsai AC, 2008, IEEE T CIRC SYST VID, V18, P694, DOI 10.1109/TCSVT.2008.919113
   VAIDYANATHAN PP, 1987, IEEE T ACOUST SPEECH, V35, P476, DOI 10.1109/TASSP.1987.1165155
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WOONG H, 2007, P INT S CIRC SYST IS
   Xu H, 2007, IEEE T CIRC SYST VID, V17, P1325, DOI 10.1109/TCSVT.2007.903552
   Zhang CX, 2008, IEEE T CIRC SYST VID, V18, P84, DOI 10.1109/TCSVT.2007.913749
NR 30
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2010
VL 47
IS 2
BP 225
EP 238
DI 10.1007/s11042-009-0320-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 576IY
UT WOS:000276139000001
DA 2024-07-18
ER

PT J
AU Fauqueur, J
   Boujemaa, N
AF Fauqueur, Julien
   Boujemaa, Nozha
TI Mental image search by Boolean composition of region categories
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE mental image search; content-based image retrieval; visual thesaurus;
   query by example paradigm; region categories; Boolean queries; inverted
   files; image google; clustering
ID RETRIEVAL
AB Existing content-based image retrieval paradigms almost never address the problem of starting the search, when the user has no starting example image but rather a mental image. We propose a new image retrieval system to allow the user to perform mental image search by formulating boolean composition of region categories. The query interface is a region photometric thesaurus which can be viewed as a visual summary of salient regions available in the database. It is generated from the unsupervised clustering of regions with similar visual content into categories. In this thesaurus, the user simply selects the types of regions which should and should not be present in the mental image (boolean composition). The natural use of inverted tables on the region category labels enables powerful boolean search and very fast retrieval in large image databases. The process of query and search of images relates to that of documents with Google. The indexing scheme is fully unsupervised and the query mode requires minimal user interaction (no example image to provide, no sketch to draw). We demonstrate the feasibility of such a framework to reach the user mental target image with two applications: a photo-agency scenario on Corel Photostock and a TV news scenario. Perspectives will be proposed for this simple and innovative framework, which should motivate further development in various research areas.
C1 Inst Natl Rech Informat & Automat, Projet IMEDIA, F-78153 Le Chesnay, France.
RP Fauqueur, J (corresponding author), Inst Natl Rech Informat & Automat, Projet IMEDIA, BP 105, F-78153 Le Chesnay, France.
EM jf330@cam.ac.uk; Nozha.Boujemaa@inria.fr
CR [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], IEEE COMPUT
   [Anonymous], 1999, MODERN INFORM RETRIE
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   BOUJEMAA N, 2001, INT WORKSH MULT CONT, P25
   Carson C., 1999, LECT NOTES COMPUTER, V1614, P509, DOI DOI 10.1007/3-540-48762-X_63
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790
   DELBIMBO A, 1998, IEEE WORKSH IM VID L
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DENG Y, 1999, P IEEE INT C AC SPEE
   Egenhofer MJ, 1997, J VISUAL LANG COMPUT, V8, P403, DOI 10.1006/jvlc.1997.0054
   Fauqueur J, 2004, J VISUAL LANG COMPUT, V15, P69, DOI 10.1016/j.jvlc.2003.08.002
   FAUQUEUR J, 2003, THESIS UVSQ INRIA
   FAUQUEUR J, 2003, INT WORKSH CONT BAS
   Frigui H, 1997, PATTERN RECOGN, V30, P1109, DOI 10.1016/S0031-3203(96)00140-9
   FUNG CY, 1999, ACM MULTIMEDIA
   GOUET V, 2001, IEEE WORKSH CONT BAS
   GUPTA A, 1996, SPIE STORAGE RETRIEV, V2670
   HARPER DJ, 1998, INT ACM SIGIR C, P232
   HIROIKE A, 1999, INT C VIS INF SYST V
   HUANG T, 1997, IEEE INT C IM P ICIP
   Huang T.S., 1996, P 33 ANN CLIN LIB AP
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Kohonen T., 1997, Self-Organizing Maps
   LAAKSONEN J, 2000, INT C NEUR INF PROC
   LACASCIA M, 1998, IEEE WORKSH CONT BAS
   LESAUX B, 2002, IAPR INT C PATT REC
   LIM JH, 1999, ACM C DIG LIB, P139
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Ma WY, 1998, J AM SOC INFORM SCI, V49, P633, DOI 10.1002/(SICI)1097-4571(19980515)49:7<633::AID-ASI5>3.0.CO;2-N
   Ma WY, 1999, MULTIMEDIA SYST, V7, P184, DOI 10.1007/s005300050121
   MACDONALD S, 2003, INT ACM SIGIR C
   MALKI J, 1999, P INT C VIS INF SYST, P115
   MEIERS T, 2002, IEEE INT C IM P ICIP
   MEIHAC C, 1999, IEEE INT C MULT COMP
   MOGHADDAM B, 1999, IEEE WORKSH CONT BAS
   NASTAR C, 1998, ACM MULT C P BRIST U
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   PENTLAND A, 1994, SPIE STOR RETR IM VI, V2
   PICARD RW, 1995, TR358 MIT
   RISSANAN J, 1978, AUTOMATICA
   RODDEN K, 2001, P SIGCHI C HUM FACT, P190, DOI DOI 10.1145/365024.365097
   Rubner Y, 1999, THESIS STANFORD U
   SCLAROFF S, 1997, IEEE WORKSH CONT BAS
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Smith JR, 1996, P SOC PHOTO-OPT INS, V2670, P426, DOI 10.1117/12.234781
   SQUIRE D, 1999, 11 SCAND C IM AN SCI
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TOWN C, 2001, CONTENT BASED IMAGE
   WANG JZ, 2001, IEEE INT C IM AN PRO
   Witten I.H., 1994, MANAGING GIGABYTES C
   ZHANG HJ, 2002, P ACM MULT, P456
NR 55
TC 10
Z9 11
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2006
VL 31
IS 1
BP 95
EP 117
DI 10.1007/s11042-006-0033-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 092QK
UT WOS:000241112200005
DA 2024-07-18
ER

PT J
AU Tsinaraki, C
   Polydoros, P
   Kazasis, F
   Christodoulakis, S
AF Tsinaraki, C
   Polydoros, P
   Kazasis, F
   Christodoulakis, S
TI Ontology-based semantic indexing for MPEG-7 and TV-anytime audiovisual
   content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE semantic indexing; MPEG-7; TV-anytime; ontologies; segmentation
AB In this paper, we describe a framework that we have developed for the support of ontology-based semantic indexing and retrieval of audiovisual content following the MPEG-7 and TV-Anytime standard specifications for metadata descriptions. Our work aims to provide a methodology to enhance the retrieval effectiveness of audiovisual content, while maintaining compatibility with the international multimedia standards.
   In our framework, domain-specific ontologies guide the definition of both the application-specific metadata and the instance-description metadata that describe the contents of audiovisual programs and/or their segments. The ontologies are also used in order to provide compatible descriptions in both audiovisual content standards (MPEG-7 and TV-Anytime) for the same content. This approach allows indexing compatibility and interoperability of TV-Anytime and digital library applications.
   We describe the design and implementation of a system supporting this framework. The components of the system include a segmentation tool for segmenting audiovisual information, which also provides ontology-based semantic indexing capabilities, and an appropriate API for semantic query support. An application testbed for the domain of soccer games has been developed on top of this system. An ontology for soccer games has been defined and used for indexing and retrieval of soccer games that have been stored in the system database.
   The methodology we developed opens up a wide opportunity for the creation of MPEG-7 and TV-Anytime services offering structured domain-specific ontologies that can be integrated to these standards for enhancing audiovisual content retrieval performance.
C1 TUC, MUSIC, Lab Distributed Multimedia Informat Syst & Applic, Kounoupidiana 73100, Chania, Greece.
RP TUC, MUSIC, Lab Distributed Multimedia Informat Syst & Applic, Tech Univ Crete Campus, Kounoupidiana 73100, Chania, Greece.
EM chrisa@ced.tuc.gr; panpolyd@ced.tuc.gr; fotis@ced.tuc.gr;
   stavros@ced.tuc.gr
OI Tsinaraki, Chrisa/0000-0002-6012-0835; Christodoulakis,
   Stavros/0000-0003-4786-0924
CR Al-Khatib W, 1999, IEEE T KNOWL DATA EN, V11, P64, DOI 10.1109/69.755616
   ANALYTI A, 1995, P ADV COURS MULT DAT, P213
   [Anonymous], P U MAR
   [Anonymous], TV-Anytime Forum
   BRANDT C, 1998, P EUR C MULT APPL SE, P85
   *CARN MELL U, INF PROJ
   CHRISTODOULAKIS S, 1997, P ECMAST MIL IT, P491
   DEJONG F, 2001, P CBMI WORKSH BRESC, P423
   *DELOS, DELOS NETW EXC DIG L
   EICKELER S, 2003, CHAN GREEC MDL WORKS
   FALLSIDE D, 2001, XML SCHEMA PART O PR
   *FIFA, 2003, FOOTB GAM RUL
   GEMMELL J, 1994, IEEE MULTIMEDIA, V1, P56
   Grosky WI, 1997, COMMUN ACM, V40, P72, DOI 10.1145/265563.265574
   Guarino N, 1998, FR ART INT, V46, P3
   HACID MS, 2000, IEEE T KNOWLEDGE DAT, V12
   *IBM JAP, VID ENR PROJ
   *ISO IEC JTC, 2001, 1SC29WG11N3966 ISOIE
   JAIMES A, 2002, P ICIP ROCH NY US
   Jiang HT, 1998, IEEE T KNOWL DATA EN, V10, P947, DOI 10.1109/69.738359
   KAZASIS F, 2002, TV AN FOR MET WG 2 I
   KYRIAKAKI G, 2000, THESIS TU CRETE
   MCGUINESS DL, 2003, OWL WEB ONTOLOGY LAN
   *MPEG GROUP, MPEG7 MULT CONT DESC
   PAPPAS N, 2003, MDL WORKSH P CHAN GR
   PAPPAS N, 2000, P VLDB CAIR EG, P578
   SINGH R, 2001, ICASSP SALT LAK CIT
   Tsinaraki C, 2003, LECT NOTES COMPUT SC, V2681, P340
   Tsinaraki C, 2001, 12TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P937, DOI 10.1109/DEXA.2001.953175
   TSINARAKI C, 2001, P MDDE WORKSH CONJ R, P104
   TSINARAKI C, UNPUB INTEGRATION OW
NR 31
TC 29
Z9 31
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2005
VL 26
IS 3
BP 299
EP 325
DI 10.1007/s11042-005-0894-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 942YO
UT WOS:000230319000004
DA 2024-07-18
ER

PT J
AU Hsieh, WW
   Chen, ALP
AF Hsieh, WW
   Chen, ALP
TI Constructing a bowling information system with video content analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st ACM International Workshop on Multimedia Databases
CY NOV   07, 2003
CL New Orleans, LA
SP ACM
DE video analysis; video content extraction; bowling events; MPEG-7; video
   summarization
ID RETRIEVAL
AB In this paper, we present a design and implementation of a bowling information system. This system contains three types of bowling game information including the bowling video content information, the game-related information and the player information. The MPEG-7 Description Schemes are used to describe these types of information and the relationships among them. This information is obtained through an annotator to which manual conceptual feature annotation (for the player and game-related information) and automatic perceptual feature extraction (for the video content information) are integrated. Several interesting events in the video such as strikes and the important frames are determined by automatically analyzing the video content. With an interactive user interface, users queries are transformed into XQuery path expression to retrieve needed information about the bowling games to learn the skills of bowling. In addition to the implementation of the system, we also perform experiments to show the effectiveness of the automatic video content information extraction.
C1 Dept Tsing Hua Univ, Hsinchu 300, Taiwan.
   Dept Chengchi Univ, Taipei 116, Taiwan.
C3 National Chengchi University
RP Hsieh, WW (corresponding author), Dept Tsing Hua Univ, Hsinchu 300, Taiwan.
EM wwhsieh@cs.nthu.edu.tw; alpchen@cs.nccu.edu.tw
CR Alatan AA, 2001, MULTIMED TOOLS APPL, V14, P137, DOI 10.1023/A:1011395131992
   DELBIMBO A, 1999, VISUAL INFORMATION R
   *ISO IEC, 2001, JTC1SC29WG11N4509 IS
   *ISO IEC, 2001, 1SC29WG11N3966 ISO 5
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   Nepal S., 2001, ACM Multimedia, P261
   PREIFFER S, 2001, MULTIMED TOOLS APPL, V15, P59
   SUDHIR G, 1998, P IEEE INT WORKSH CO
   TJONDRONEGORO D, 2001, WORLD WIDE WEB J, V5, P207
   Tovinkere V., 2001, P IEEE INT C MULT EX
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
NR 11
TC 5
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2005
VL 26
IS 2
BP 207
EP 220
DI 10.1007/s11042-005-0452-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 931TJ
UT WOS:000229508100005
DA 2024-07-18
ER

PT J
AU Pinto, M
   Amor, M
   Fuentes, L
   Troya, JM
AF Pinto, M
   Amor, M
   Fuentes, L
   Troya, JM
TI Analyzing architectural evolution issues of multimedia frameworks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Component-Based Software Engineering; Framework Technology; Web-based
   Multimedia Services; Distributed Web-based Systems; Java Media
   Framework; MultiTEL; Software Engineering for Multimedia Systems
AB The growing complexity in the development of Web-based services in general, and multimedia services in particular, makes necessary the application of sound development methods. New multimedia devices, coding algorithms, network protocols, etc., are continually appearing but, unfortunately, current solutions for developing multimedia applications do not accurately support architectural evolution issues for already deployed applications. Thus, the latest Software Engineering technologies should be applied to the development of open, reusable, and high-quality multimedia and Web-based software. In this paper, we apply component and framework technologies, two of the current trends in Software Engineering, to the development of multimedia services over the Web, presenting and comparing widespread solutions in use today.
C1 Univ Malaga, Dept Lenguajes & Ciencias Computac, E-29071 Malaga, Spain.
C3 Universidad de Malaga
RP Univ Malaga, Dept Lenguajes & Ciencias Computac, Campus Teatinos, E-29071 Malaga, Spain.
EM pinto@lcc.uma.es; pinilla@lcc.uma.es; lff@lcc.uma.es; troya@lcc.uma.es
RI Pinto, Monica/G-1891-2015; Pinilla, María Mercedes Amor/ABA-9149-2020;
   Fuentes, Lidia/M-5580-2014
OI Pinto, Monica/0000-0002-5376-742X; Pinilla, María Mercedes
   Amor/0000-0001-7190-0581; Fuentes, Lidia/0000-0002-5677-7156
CR BROWN WA, 1998, IEEE SOFTWARE    SEP
   DECARMO L, 1999, CORE JAVA MEDIA FRAM
   Fayad M. E., 1997, COMMUNICATIONS ACM, V40
   Fuentes L, 1999, IEEE INTERNET COMPUT, V3, P55, DOI 10.1109/4236.761654
   FUENTES L, 2001, ANN SOFTWARE ENG
   FUENTES L, 1997, LNCS, V1274
   Gamma E., 1994, Design patterns: Elements of reusable object-oriented software
   KRIEGER D, 1998, IEEE COMPUTER    MAR
   *MICR CORP, INTR WIND MED TECHN
   Pinto M, 2001, 21ST INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, PROCEEDINGS, P97, DOI 10.1109/CDCS.2001.918692
   PINTO M, 2001, WORKSH ASOC ADV SEP
   SCHULZRINNE H, 1996, 1889 RFC
   *SIL GRAPH, DIG MED PROGR GUID
   *SUN MICR INC, 2001, JAV MED FRAM
NR 14
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2004
VL 22
IS 1
BP 31
EP 51
DI 10.1023/B:MTAP.0000008658.36713.c2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 754MK
UT WOS:000187320800002
DA 2024-07-18
ER

PT J
AU Cho, J
   Sung, MY
   Shin, H
AF Cho, J
   Sung, MY
   Shin, H
TI A design framework for multi-resolution video servers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video server; multi-resolution video stream model; data placement and
   retrieval; admission control
ID STORAGE; SUPPORT
AB Video can be encoded into multiple-resolution format in nature. A multi-resolution or scalable video stream is a video sequence encoded such that subsets of the full resolution video bit stream can be decoded to recreate lower resolution video streams. Employing scalable video enables a video server to provide multiple resolution services for a variety of clients with different decoding capabilities and network bandwidths connected to the server. The inherent advantages of the multi-resolution video server include: heterogeneous client support, storage efficiency, adaptable service, and interactive operations support.
   For designing a video server, several issues should be dealt with under a unified framework including data placement/retrieval, buffer management, and admission control schemes for deterministic service guarantee. In this paper, we present a general framework for designing a large-scale multi-resolution video server. First, we propose a general multi-resolution video stream model which can be implemented by various scalable compression techniques. Second, given the proposed stream model, we devise a hybrid data placement scheme to store scalable video data across disks in the server. The scheme exploits both concurrency and parallelism offered by striping data across the disks and achieves the disk load balancing during any resolution video service. Next, the retrieval of multi-resolution video is described. The deterministic access property of the placement scheme permits the retrieval scheduling to be performed on each disk independently and to support interactive operations (e.g. pause, resume, slow playback, fastforward and rewind) simply by reconstructing the input parameters to the scheduler. We also present an efficient admission control algorithm which precisely estimates the actual disk workload for the given resolution services and hence permits the buffer requirement to be much smaller. The proposed schemes are verified through detailed simulation and implementation.
C1 Kyung Hee Univ, Sch Elect & Informat, Yongin 449701, South Korea.
C3 Kyung Hee University
RP Cho, J (corresponding author), Kyung Hee Univ, Sch Elect & Informat, Yongin 449701, South Korea.
EM chojs@khu.ac.kr; my.sung@samsung.com; shinhs@snu.ac.kr
RI Lee, Sungyoung/HDN-1116-2022; Cho, Jinsung/AAF-9842-2021
OI Cho, Jinsung/0000-0003-1661-4923; Sung, Minyoung/0000-0002-1670-6628
CR ANDERSON ER, 1992, ENVIRON CLAIM J, V4, P311
   Berson S., 1995, Multimedia Tools and Applications, V1, P127, DOI 10.1007/BF01215935
   BOGDAN A, 1994, P IEEE INT C IM PROC
   BOLOSKY WJ, 1996, P 6 INT WORKSH NETW, P97
   Chang E, 1997, IEEE T CIRC SYST VID, V7, P758, DOI 10.1109/76.633494
   CHANG E, 1994, P SOC PHOTO-OPT INS, V2185, P208, DOI 10.1117/12.171778
   Chen M., 1993, Proceedings of the first ACM international conference on Multimedia, P235
   Chen MS, 1996, IEEE MULTIMEDIA, V3, P51, DOI 10.1109/93.502294
   CHEN MS, 1995, P IS T SPIE S EL IM, P338
   CHEN MS, 1994, P ACM MULT, P391
   Chiueh T., 1993, Proceedings ACM Multimedia 93, P401, DOI 10.1145/166266.168438
   Cho JS, 1997, PARALLEL COMPUT, V23, P1743, DOI 10.1016/S0167-8191(97)00085-9
   Dan A, 1996, P SOC PHOTO-OPT INS, V2667, P344, DOI 10.1117/12.235887
   DAN A, 1995, P IEEE COMPCON SAN F, P217
   DelRosario JM, 1996, MULTIMED TOOLS APPL, V2, P215, DOI 10.1023/A:1018040906307
   DOGANATA YN, 1993, MULTIMED TOOLS APPL, V1, P127
   GEMMELL DJ, 1995, COMPUTER, V28, P40, DOI 10.1109/2.384117
   HEYBEY A, 1996, P USENIX 1996 ANN TE
   HUNTER J, REV VIDEO STREAMING
   KEETON K, 1993, P INT WORKSH NETW OP, P237
   Kwon TG, 1997, MULTIMEDIA SYST, V5, P271, DOI 10.1007/s005300050060
   Lau SW, 1997, MULTIMEDIA SYST, V5, P310, DOI 10.1007/s005300050063
   Lee JYB, 1998, IEEE MULTIMEDIA, V5, P20, DOI 10.1109/93.682522
   MacDougall M., 1987, Simulating Computer Systems: Techniques and Tools
   Makaroff D, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P143, DOI 10.1145/266180.266354
   Ng RT, 1996, MULTIMEDIA SYST, V4, P55, DOI 10.1007/s005300050012
   Paek S., 1995, Proceedings of the 5th International Workshop on Network and Operating System Support for Digital Audio and Video, P363
   *QNX SOFTW SYST LT, 1993, QNX OP SYST MAN
   Reddy A. L. N., 1993, P ACM MULT C, P225
   Shenoy PJ, 1999, MULTIMEDIA SYST, V7, P241, DOI 10.1007/s005300050126
   SHENOY PJ, 1995, P ACM MULT C NOV, P131
   TAUBMAN D, 1994, IEEE T IMAGE PROCESS, V3, P572, DOI 10.1109/83.334984
   Tong SR, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P86, DOI 10.1109/MMCS.1998.693628
   Vin H. M., 1995, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.95TH8066), P158, DOI 10.1109/MMCS.1995.484920
   Vin H. M., 1994, Proceedings ACM Multimedia '94, P33, DOI 10.1145/192593.192616
   VIN HM, 1993, IEEE J SEL AREA COMM, V11, P153, DOI 10.1109/49.210554
   Wu KL, 1998, MULTIMEDIA SYST, V6, P421, DOI 10.1007/s005300050104
   Wu MY, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P178, DOI 10.1109/MMCS.1997.609591
NR 38
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2003
VL 20
IS 3
BP 237
EP 262
DI 10.1023/A:1024072205156
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 686QF
UT WOS:000183331900003
DA 2024-07-18
ER

PT J
AU Hwang, E
   Prabhakaran, B
AF Hwang, E
   Prabhakaran, B
TI Unified read requests
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia storage server; request merging; optimality; cost function
AB Most work on multimedia storage systems has assumed that clients will be serviced using a round-robin strategy. The server services the clients in rounds and each client is allocated a time slice within that round. Furthermore, most such algorithms are evaluated on the basis of a tightly specified cost function. This is the basis for well known algorithms such as FCFS, SCAN, SCAN-EDF, etc.
   In this paper, we describe a Request Merging (RM) module that takes as input, a set of client requests, and a set of constraints on the desired performance such as client waiting time or maximum disk bandwidth, and a cost function. It produces as output, a Unified Read Request (URR), telling the storage server which data items to read, and when the clients would like these data items to be delivered to them. Given a cost function cf, a URR is optimal if there is no other URR satisfying the constraints with a lower cost. We present three algorithms in this paper, each of which accomplishes this kind of request merging. The first algorithm OptURR is guaranteed to produce minimal cost URRs with respect to arbitrary cost functions. In general, the problem of computing an optimal URR is NP-complete, even when only two data objects are considered. To alleviate this problem, we develop two other algorithms, called GreedyURR and FastURR that may produce sub-optimal URRs, but which have some nicer computational properties. We will report on the pros and cons of these algorithms through an experimental evaluation.
C1 Ajou Univ, Grad Sch Informat & Commun, Suwon 442749, South Korea.
   Univ Texas, Dept Comp Sci, Richardson, TX 75083 USA.
C3 Ajou University; University of Texas System; University of Texas Dallas
RP Hwang, E (corresponding author), Ajou Univ, Grad Sch Informat & Commun, Suwon 442749, South Korea.
CR [Anonymous], 1979, COMPUT INTRACTABILIT
   BALKIR NH, IN PRESS VLDB J
   BERSON S, 1994, P ACM SIGMOD, P79
   CHAUDHURI S, 1995, P VLDB C ZUR SWITZ
   Chen H. J., 1995, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.95TH8066), P65, DOI 10.1109/MMCS.1995.484909
   CHEN MS, 1994, P ACM MULT, P391
   DAN A, 1996, P MULT COMP NETW SAN
   DRAPEAU AL, 1994, P ACM SIGM C MEAS MO
   Golubchik L., 1995, P ACM SIGMETRICS JOI, P25
   Huang YM, 1999, MULTIMED TOOLS APPL, V9, P147, DOI 10.1023/A:1009628223063
   HWANG E, 2000, P INT WORKSH INT MUL
   HWANG E, IN PRESS T KNOWLEDGE
   LEUNG JYT, 1980, INFORM PROCESS LETT, V11, P115, DOI 10.1016/0020-0190(80)90123-4
   LIU CL, 1973, J ACM, V20, P46, DOI 10.1145/321738.321743
   NERJES G, 1998, P INT WORKSH RES ISS
   NG RT, 1994, P VLDB C CHIL
   NG RT, 1996, P INT WORKSH MULT IN
   RANGAN PV, 1991, P ACM S OP SYST PRIN, P69
   Rompogiannakis Y., 1998, Proceedings ACM Multimedia 98, P297, DOI 10.1145/290747.290785
   [No title captured]
   1992, VIDEO STORE MAGAZINE
NR 21
TC 0
Z9 0
U1 0
U2 0
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2003
VL 20
IS 3
BP 203
EP 224
DI 10.1023/A:1024058404247
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 686QF
UT WOS:000183331900001
DA 2024-07-18
ER

PT J
AU Cameron, H
   King, P
   Thompson, S
AF Cameron, H
   King, P
   Thompson, S
TI Modeling reactive multimedia: Events and behaviors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia; reactive; dynamic hyperlink; external behavior
ID SYNCHRONIZATION
AB This paper explores the idea of reactivity in multimedia, and proposes systems which can react to continuously-evolving behaviors as well as to more traditional discrete events. The idea is presented in a scenario as well as in a number of small programming examples.
   The illustrative examples are written in the Fran system. Fran provides a high-level programming model for animations, built in the Haskell functional programming language. Whilst we use Fran for illustration-and indeed we argue that the functional paradigm is a natural choice of host for such a system-we should stress that the notion of external behaviors within multimedia is independent of the programming environment chosen and could be incorporated into other systems such as SMIL.
C1 Univ Manitoba, Dept Comp Sci, Winnipeg, MB R3T 2N2, Canada.
   Univ Kent, Comp Lab, Canterbury, Kent, England.
C3 University of Manitoba; University of Kent
RP Cameron, H (corresponding author), Univ Manitoba, Dept Comp Sci, Winnipeg, MB R3T 2N2, Canada.
RI Thompson, Simon/B-8964-2012
OI Thompson, Simon/0000-0002-2350-301X
CR [Anonymous], 1999, Haskell: The Craft of Functional Programming
   ATES AF, 1996, IEEE J SELECTED AREA, V14
   BUCHANAN MC, 1993, P MULT 993
   ELLIOTT C, 1998, DOBBS J
   ELLIOTT C, 1997, P 1997 ACM SIGPLAN I
   ELLIOTT C, 1998, PLILP ALP98
   HARDMAN L, 1994, COMMUNICATIONS ACM, V37
   HIRZALLA N, 1995, IEEE MULTIMEDIA, V2, P24, DOI 10.1109/93.410508
   Huang CM, 1998, IEEE MULTIMEDIA, V5, P44, DOI 10.1109/93.735868
   HUGHES J, 1999, REPORT PROGRAMMING L
   JOURDAN M, 1998, HDB INTERNET MULTI 1
   JOURDAN M, 1997, MULTIMEDIA COMPUTING
   PETERSON J, 1997, FRAN USERS MANUAL
   PROBERTS S, 1998, LNCS, V1375, P550
   Schnepf J, 1996, IEEE J SEL AREA COMM, V14, P114, DOI 10.1109/49.481698
   Senac P, 1996, IEEE J SEL AREA COMM, V14, P84, DOI 10.1109/49.481696
   THOMPSON S, 1999, IN PRESS J FUNCTIONA
   Vazirgiannis M, 1998, MULTIMEDIA SYST, V6, P284, DOI 10.1007/s005300050094
   VAZIRGIANNIS M, 1997, IEEE INT C MULT COMP
NR 19
TC 2
Z9 2
U1 0
U2 0
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2003
VL 19
IS 1
BP 53
EP 77
DI 10.1023/A:1021168913400
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 617QH
UT WOS:000179372000003
DA 2024-07-18
ER

PT J
AU Hyok, RJ
   Hyok, OC
   Hyok, KC
AF Hyok, Ri Jong
   Hyok, O. Chung
   Hyok, Kim Chol
TI Probability cost function based weighted extreme learning machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Extreme learning machine; Imbalance learning; Single-hidden layer
   feedforward networks; Probability cost function
AB Standard extreme learning machine has good generalization performance and fast learning speed, but has the disadvantage of degrading performance for imbalance learning. Weighted extreme learning machine (WELM) is a kind of cost-sensitive learning method that significantly improves the classification performance for imbalanced data by adding extra weight to each training sample. In this paper, we present a novel WELM that defined by probability cost function concerned with the probability that given sample belong to each class. We propose learning network mapping input training data to a vector consisting of the probability value of given training sample belonging to each class. We define its cost functions to maximize the marginal distance between classes and the probability that each training sample will be accurately classified. We empirically show that our proposed algorithm obtains superior performance in general than some state-of-the-art imbalance learning approaches on 32 binary class and 14 multiclass imbalanced datasets. To further estimate the experimental results, we also provide statistical analysis.
C1 [Hyok, Ri Jong; Hyok, O. Chung; Hyok, Kim Chol] Kim Il Sung Univ, Inst Informat Technol, Hightech Res & Dev Ctr, Pyongyang, North Korea.
RP Hyok, RJ (corresponding author), Kim Il Sung Univ, Inst Informat Technol, Hightech Res & Dev Ctr, Pyongyang, North Korea.
EM jh.ri1220@ryongnamsan.edu.kp
CR Akbulut Y, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9080142
   Alcalá-Fdez J, 2011, J MULT-VALUED LOG S, V17, P255
   Balasundaram S, 2016, INT J MACH LEARN CYB, V7, P707, DOI 10.1007/s13042-014-0283-8
   Chawla NV, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P875, DOI 10.1007/978-0-387-09823-4_45
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Denis Serre., 2002, Matrices Theory and Applications
   Fletcher R., 1981, Practical methods of optimization, volume 2, Constrained Optimization, V2
   García S, 2009, SOFT COMPUT, V13, P959, DOI 10.1007/s00500-008-0392-y
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2015, IEEE COMPUT INTELL M, V10, P18, DOI 10.1109/MCI.2015.2405316
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y
   Jin ZC, 2020, NEURAL COMPUT APPL, V32, P6601, DOI 10.1007/s00521-018-3735-3
   Li K, 2014, NEUROCOMPUTING, V128, P15, DOI 10.1016/j.neucom.2013.05.051
   Lu CB, 2019, MEMET COMPUT, V11, P27, DOI 10.1007/s12293-017-0236-3
   Pal D, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106083
   Raghuwanshi BS, 2018, NEURAL NETWORKS, V105, P206, DOI 10.1016/j.neunet.2018.05.011
   Ri J, 2018, IEEE COMPUT INTELL M, V13, P32, DOI 10.1109/MCI.2018.2840707
   Schapire RE, 2003, LECT NOTES STAT, V171, P149, DOI 10.1007/978-0-387-21579-2_9
   Wang Y, 2019, APPL INTELL, V49, P1161, DOI 10.1007/s10489-018-1322-z
   Yu XM, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030508
   Zhang R, 2012, IEEE T NEUR NET LEAR, V23, P365, DOI 10.1109/TNNLS.2011.2178124
   Zong WW, 2013, NEUROCOMPUTING, V101, P229, DOI 10.1016/j.neucom.2012.08.010
NR 24
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 26
PY 2023
DI 10.1007/s11042-023-17800-w
EA DEC 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB6Q4
UT WOS:001129615800001
DA 2024-07-18
ER

PT J
AU Kavitha, D
   Geetha, S
   Geetha, R
   Kadry, S
AF Kavitha, D.
   Geetha, S.
   Geetha, R.
   Kadry, Seifedine
TI Dynamic neuro fuzzy diagnosis of fetal hypoplastic cardiac syndrome
   using ultrasound images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hypoplastic; Morphological operations; Neuro Fuzzy Classifier; Heart
   syndrome; Ultrasound imaging
ID SPECKLE REDUCTION; SEGMENTATION
AB Congenital heart anomalies (CHA) represent a substantial risk to neonates, with 28% to 48% of cases resulting in life-threatening conditions. Consequently, careful prenatal screening is crucial for effective management. Within the spectrum of 18 CHA types, identifying the irregularities in heart morphology, notably the underdeveloped left heart chamber, poses a significant challenge. Hypoplastic Left Heart Syndrome (HLHS), an infrequent yet critical CHA demands diagnosis between the 17th and 21st week of growth. Despite the efficacy of ultrasound imaging, the diagnosis remains intricate due to speckle noise and the complex nature of heart chamber appearances. Selecting an accurate pre-processing algorithm is crucial, and the Fuzzy-based Maximum Likelihood Estimation Technique (FMLET) stands as a pivotal choice. Among the vital parameters for manual diagnosis from ultrasound images, the Right Ventricular Left Ventricular Ratio (RVLVR) and the Cardiac Thoracic Ratio (CTR) play a prominent role. Employing morphological operations such as opening, closing, thinning, and thickening facilitates the extraction of diagnostically crucial features embedded within the images. The development of a Computer-Aided Decision Support (CADS) system, integrating an Adaptive Neuro Fuzzy Classifier (ANFC) proves to be instrumental. ANFC stands out as a better classifier and demonstrates self-learning capabilities similar to that of experts, resulting in a higher diagnostic accuracy rate. The presented Computer-Aided Diagnostic System (CADS) exhibited a notable diagnostic accuracy of 91%, supported by a standardized Area Under the Receiver Operating Characteristic (ROC) curve of 0.92. These results emphasize the system's robustness and effectiveness in diagnosing prenatal CHA, particularly HLHS.Graphical abstractArchitecture of the proposed CAD system
C1 [Kavitha, D.] CMR Inst Technol, Dept Elect & Commun Engn, Bangalore, India.
   [Geetha, S.] VIT Univ, Sch Comp Sci & Engn, Chennai Campus, Chennai, India.
   [Geetha, R.] Saveetha Univ, Saveetha Sch Engn, Dept Biomed Engn, Chennai, India.
   [Kadry, Seifedine] Noroff Univ Coll, Dept Appl Data Sci, Kristiansand, Norway.
   [Kadry, Seifedine] Ajman Univ, Artificial Intelligence Res Ctr AIRC, Ajman 346, U Arab Emirates.
   [Kadry, Seifedine] Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos, Lebanon.
C3 Vellore Institute of Technology (VIT); VIT Chennai; Saveetha Institute
   of Medical & Technical Science; Saveetha School of Engineering; Ajman
   University; Lebanese American University
RP Kadry, S (corresponding author), Noroff Univ Coll, Dept Appl Data Sci, Kristiansand, Norway.; Kadry, S (corresponding author), Ajman Univ, Artificial Intelligence Res Ctr AIRC, Ajman 346, U Arab Emirates.; Kadry, S (corresponding author), Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos, Lebanon.
EM kavithad0612@gmail.com; geethabaalan@gmail.com;
   rgeetha.mariappan@gmail.com; skadry@gmail.com
RI Kadry, Seifedine/C-7437-2011; R, Geetha/GXH-3505-2022
OI Kadry, Seifedine/0000-0002-1939-4842; R, Geetha/0000-0002-4451-1844
CR Abdulshahed AM, 2015, APPL SOFT COMPUT, V27, P158, DOI 10.1016/j.asoc.2014.11.012
   Aysal TC, 2007, IEEE T MED IMAGING, V26, P712, DOI 10.1109/TMI.2007.895484
   Bellsham-Revell H, 2021, FRONT CARDIOVASC MED, V8, DOI 10.3389/fcvm.2021.637838
   Carvalho JS, 2002, HEART, V88, P387, DOI 10.1136/heart.88.4.387
   Ciurte A, 2012, P CHALL US BIOM MEAS, P1315
   Coupé P, 2009, IEEE T IMAGE PROCESS, V18, P2221, DOI 10.1109/TIP.2009.2024064
   De Marsico M, 2015, LECT NOTES COMPUT SC, V9257, P195, DOI 10.1007/978-3-319-23117-4_17
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Fruitman DS, 2000, Paediatr Child Health, V5
   Gobergs Roberts, 2016, Acta Med Litu, V23, P86, DOI 10.6001/actamedica.v23i2.3325
   Hoffman JIE, 2002, J AM COLL CARDIOL, V39, P1890, DOI 10.1016/S0735-1097(02)01886-7
   LEE JS, 1986, OPT ENG, V25, P636, DOI 10.1117/12.7973877
   Loizou CP, 2006, MED BIOL ENG COMPUT, V44, P414, DOI 10.1007/s11517-006-0045-1
   Macedo AJ., 1993, Acta Medica Portuguesa, V6, P913
   Michielsen K., 2001, Physics Reports, V347, P461, DOI 10.1016/S0370-1573(00)00106-X
   Mohammed NB, 2011, J PAK MED ASSOC, V61, P904
   Nirmala S, 2016, PROCEDIA COMPUT SCI, V79, P344, DOI 10.1016/j.procs.2016.03.045
   Pouch AM, 2017, LECT NOTES COMPUT SC, V10263, P95, DOI 10.1007/978-3-319-59448-4_10
   Sadek S, 2015, Int J Comput Vis Signal Process, V5, P1
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Sridevi S, 2016, J INTELL FUZZY SYST, V31, P433, DOI 10.3233/IFS-162157
NR 21
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 21
PY 2023
DI 10.1007/s11042-023-17847-9
EA DEC 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5U7
UT WOS:001129334000006
DA 2024-07-18
ER

PT J
AU Gupta, A
   Purwar, A
AF Gupta, Aishwarya
   Purwar, Archana
TI Speech refinement using Bi-LSTM and improved spectral clustering in
   speaker diarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Speaker Diarization; Speech Refinement; Bi-directional Long Short-Term
   Memory (Bi-LSTM); Skip U-Net Connections; Singular Value Decomposition;
   Spectral clustering
ID MEAN SHIFT; ENHANCEMENT
AB In this digitally-driven culture, the need and demand for diarizing online meetings, classes, conferences, and medical diagnoses have increased a lot. Speaker Diarization, a sub-domain of Speaker Recognition has grown with the advent of neural networks in the last decade. Diarize generally refers to obtaining the duration of individual speakers in any event. Researchers have suggested various approaches for multiple-speaker diarization. However, it still suffers from a problem of various environmental noises, and non-speech sounds like laughter, murmuring, clapping, etc. in the datasets. Hence, this paper proposes an improved speaker diarization pipeline to deal with the noise present in a dataset having multiple speakers. This improved diarization pipeline uses Bi-directional Long Short-Term Memory (Bi-LSTM), based speech refinement pre-processing module, and Modified Spectral Clustering with Symmetrized Singular Value Decomposition (MSC-SSVD). MSC-SSVD is used to cater to the problem of spectral clustering in large datasets. The proposed diarization pipeline is evaluated using the publicly available VoxConverse dataset. The Diarization Error Rate (DER) obtained after experimentation are 37.2%, 37.1%, and 43.3% respectively for three batches of dataset under study. The results are also compared with the baseline system and significant change in DER by 6.1%, 4.7%, and 7% respectively for three batches is observed.
C1 [Gupta, Aishwarya; Purwar, Archana] Jaypee Inst Informat Technol, Comp Sci & Engn & Informat Technol, Noida, Uttar Pradesh, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Gupta, A (corresponding author), Jaypee Inst Informat Technol, Comp Sci & Engn & Informat Technol, Noida, Uttar Pradesh, India.
EM aishgupta.93@gmail.com; archana.purwar@jiit.ac.in
OI Gupta, Aishwarya/0000-0002-1416-3252
CR Abd El-Fattah MA, 2014, INT J SPEECH TECHNOL, V17, P53, DOI 10.1007/s10772-013-9205-5
   Ahmad R, 2020, IEEE ACCESS, V8, P126671, DOI 10.1109/ACCESS.2020.3007312
   Ahmad R, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235163
   Miro XA, 2012, IEEE T AUDIO SPEECH, V20, P356, DOI 10.1109/TASL.2011.2125954
   [Anonymous], 1998, P DARPA BROADC NEWS
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
   Bredin H, 2017, INTERSPEECH, P3587, DOI 10.21437/Interspeech.2017-411
   Chung JS, 2021, Arxiv, DOI arXiv:2007.01216
   Chung Joon Son, 2018, arXiv
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Das N, 2021, INT J SPEECH TECHNOL, V24, P883, DOI 10.1007/s10772-020-09674-2
   D‚fossez A, 2019, Arxiv, DOI arXiv:1909.01174
   Défossez A, 2021, Arxiv, DOI [arXiv:1911.13254, DOI 10.48550/ARXIV.1911.13254, 10.48550/arXiv.1911.13254]
   Défossez A, 2020, INTERSPEECH, P3291, DOI 10.21437/Interspeech.2020-2409
   Delacourt P, 2000, SPEECH COMMUN, V32, P111, DOI 10.1016/S0167-6393(00)00027-3
   Gupta A, 2022, 2022 1 INT C INF ICI, P19, DOI [10.1109/ICI53355.2022.9786928, DOI 10.1109/ICI53355.2022.9786928]
   Gupta A, 2022, Applications of artificial intelligence, big data and internet of things in sustainable development, P65
   Han K. J., 2007, INTERSPEECH, P1853
   Hu Y, 2004, IEEE T SPEECH AUDI P, V12, P59, DOI 10.1109/TSA.2003.819949
   Hu Y, 2004, IEEE SIGNAL PROC LET, V11, P270, DOI 10.1109/LSP.2003.821714
   Huang ZY, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2563
   Islam Md Rabiul, 2009, Proceedings of the 2009 12th International Conference on Computer and Information Technology (ICCIT 2009), P255, DOI 10.1109/ICCIT.2009.5407130
   kaggle, US
   Kaladharan N., 2014, Int J Comput Applic, V96, P45, DOI [10.5120/16858-6739, DOI 10.5120/16858-6739]
   Kang W, 2020, INT CONF ACOUST SPEE, P6509, DOI [10.1109/ICASSP40776.2020.9053122, 10.1109/icassp40776.2020.9053122]
   Kang Z, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12094161
   Karam M., 2014, Journal of Signal and Information Processing, V5, P32
   Kumariss VSR, 2023, Int J Eng Trends Technol (IJETT), VV5, P107
   Landini F, 2022, COMPUT SPEECH LANG, V71, DOI 10.1016/j.csl.2021.101254
   Landini F, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P5819, DOI 10.1109/ICASSP39728.2021.9414315
   Li JY, 2015, IEEE T KNOWL DATA EN, V27, P589, DOI 10.1109/TKDE.2014.2356471
   Li WF, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P149, DOI 10.1109/ICME.2008.4607393
   Luque J, 2012, OD 2012 THE SPEAK LA
   Macartney C, 2018, Arxiv, DOI [arXiv:1811.11307, DOI 10.48550/ARXIV.1811.11307]
   Meignier S, 2006, COMPUT SPEECH LANG, V20, P303, DOI 10.1016/j.csl.2005.08.002
   Mihov SG, 2009, Annual Journal Of Electronics, V6, P2
   Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950
   Nakanishi I., 2006, 2006 IEEE International Symposium on Circuits and Systems (IEEE Cat. No. 06CH37717C), DOI 10.1109/ISCAS.2006.1693141
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Ning HZ, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2178
   Novoselov S, 2019, INTERSPEECH, P1003, DOI 10.21437/Interspeech.2019-2757
   Pandey A, 2019, IEEE-ACM T AUDIO SPE, V27, P1179, DOI [10.1109/taslp.2019.2913512, 10.1109/TASLP.2019.2913512]
   Parchami M, 2016, IEEE CIRC SYST MAG, V16, P45, DOI 10.1109/MCAS.2016.2583681
   Park TJ, 2022, COMPUT SPEECH LANG, V72, DOI 10.1016/j.csl.2021.101317
   Park TJ, 2020, IEEE SIGNAL PROC LET, V27, P381, DOI 10.1109/LSP.2019.2961071
   Raj D, 2021, IEEE W SP LANG TECH, P582, DOI 10.1109/SLT48900.2021.9383602
   Rouvier M, 2015, EUR SIGNAL PR CONF, P2082, DOI 10.1109/EUSIPCO.2015.7362751
   Sainburg T, 2018, Noise reduction using spectral gating in python
   Sarikaya R., 1998, P INT C SPOK LANG PR, V4, P1455
   Sell G, 2014, IEEE W SP LANG TECH, P413, DOI 10.1109/SLT.2014.7078610
   Senoussaoui M, 2014, IEEE-ACM T AUDIO SPE, V22, P217, DOI 10.1109/TASLP.2013.2285474
   Shum SH, 2013, IEEE T AUDIO SPEECH, V21, P2015, DOI 10.1109/TASL.2013.2264673
   Sinclair M, 2013, INT CONF ACOUST SPEE, P7741, DOI 10.1109/ICASSP.2013.6639170
   Snyder D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5329
   Stafylakis T, 2010, ODYSSEY 2010: THE SPEAKER AND LANGUAGE RECOGNITION WORKSHOP, P186
   Stoller D, 2018, Arxiv, DOI [arXiv:1806.03185, DOI 10.48550/ARXIV.1806.03185]
   Sun G, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7168, DOI 10.1109/ICASSP39728.2021.9414390
   Sun L, 2018, INTERSPEECH, P2793, DOI 10.21437/Interspeech.2018-1742
   Toruk M, 2020, SIG PROCESS COMMUN, DOI 10.1109/siu49456.2020.9302162
   Upadhyay N, 2015, PROCEDIA COMPUT SCI, V54, P574, DOI 10.1016/j.procs.2015.06.066
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang Q, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5239, DOI 10.1109/ICASSP.2018.8462628
   Wang X, 2014, DATA MIN KNOWL DISC, V28, P1, DOI 10.1007/s10618-012-0291-9
   Xia W, 2022, INT CONF ACOUST SPEE, P8077, DOI 10.1109/ICASSP43922.2022.9746531
   Yu HJ, 2019, IEEE INT SYMP CIRC S, DOI 10.1109/bhi.2019.8834456
   Zelnik-Manor Lihi, 2004, Advances in neural information processing systems, V17
   Zhang AN, 2019, INT CONF ACOUST SPEE, P6301, DOI 10.1109/ICASSP.2019.8683892
NR 67
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 5
PY 2023
DI 10.1007/s11042-023-17017-x
EA DEC 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z6JY9
UT WOS:001113132600001
DA 2024-07-18
ER

PT J
AU Turkmen, HI
AF Turkmen, H. Irem
TI A novel two-staged deep learning based workflow for analyzable metaphase
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Analyzable metaphase detection; Karyotyping; Deep learning; Microscopic
   object detection; Faster R-CNN; VGG19
ID FASTER R-CNN
AB In the field of cytogenetics, chromosome image analysis plays a critical role in the diagnosis of various genetic disorders and cancers. As the gold standard, chromosome image analysis focuses on metaphase images, as all chromosomes become distinctly visible during this phase of cell mitosis. However, not all the detected metaphases are suitable for karyotyping due to chromosome stickiness. Therefore, cytogenetics selects the analyzable metaphase images by exploring all the samples. Since this task is very time-consuming, efforts have been made to automate the analyzable metaphase selection step of karyotyping. Nevertheless, these studies have drawbacks, such as utilizing hand-crafted features, requiring expert-provided candidate metaphase cell regions for classification, and demanding 100X magnified microscopic images. In this study, a novel two-staged deep-learning based workflow is presented for automatic detection of analyzable metaphase cells. The proposed model operates on 10X magnified images while omitting traditional image processing steps that are used in state-of-the-art methods for determining candidate metaphases. In the first stage, Faster R-CNN method with Inception V2 architecture is used to directly identify analyzable metaphases in specimen slide images. The second stage involves analyzable metaphase image verification based on VGG19 model. To assess the success of the proposed method, we also evaluate two state-of-the-art techniques: YOLOv8 and EfficientNet algorithms. The results obtained with different combination options achieved true positive rates up to 98.5% while reducing false positive rates to 0.0001. This study is the first to introduce an end-to-end deep learning-based approach for analyzable metaphase detection. Comparing it with existing literature, it becomes evident that the proposed approach achieves an optimal balance between true positive rates and false positive rates, maintains efficient processing speed, and eliminates the need for high-magnification image acquisition. All these factors play imperative roles in the clinical usage of the system.
C1 [Turkmen, H. Irem] Yildiz Tech Univ, Comp Engn Dept, Istanbul, Turkiye.
C3 Yildiz Technical University
RP Turkmen, HI (corresponding author), Yildiz Tech Univ, Comp Engn Dept, Istanbul, Turkiye.
EM irem@yildiz.edu.tr
OI Turkmen, H. Irem/0000-0002-8690-0725
CR Albayrak A, 2022, MED BIOL ENG COMPUT, V60, P239, DOI 10.1007/s11517-021-02474-z
   Andrade MFS, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01115-z
   Arora T, 2017, KNOWL INF SYST, V52, P773, DOI 10.1007/s10115-017-1024-6
   Arsa D.M.S., 2017, Jurnal Ilmu Komputer dan Informasi, V10, P50, DOI DOI 10.21609/JIKI.V10I1.445
   Avci D, 2023, BIOCYBERN BIOMED ENG, V43, P58, DOI 10.1016/j.bbe.2022.12.001
   Basha SHS, 2020, NEUROCOMPUTING, V378, P112, DOI 10.1016/j.neucom.2019.10.008
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dumitriu A, 2023, P IEEE CVF C COMP VI, P1261
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Henderson P, 2017, LECT NOTES COMPUT SC, V10115, P198, DOI 10.1007/978-3-319-54193-8_13
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jahnavi Kodi, 2023, 2023 7th International Conference on Computing Methodologies and Communication (ICCMC), P1538, DOI 10.1109/ICCMC56507.2023.10083564
   Jazayeriy H, 2022, 2022 8 IR C SIGN PRO, P1, DOI [10.1109/ICSPIS56952.2022.10043946, DOI 10.1109/ICSPIS56952.2022.10043946]
   Jocher G., 2023, YOLO by Ultralytics
   Karaci A, 2022, NEURAL COMPUT APPL, V34, P8253, DOI 10.1007/s00521-022-06918-x
   Keerthi V, 2020, 2020 ADV COMP COMM T, P1, DOI [10.1109/ACCTHPA49271.2020.9213212, DOI 10.1109/ACCTHPA49271.2020.9213212]
   Khan HU, 2023, BIOMED SIGNAL PROCES, V81, DOI 10.1016/j.bspc.2022.104414
   Kim J, 2020, IEEE COMPUT SOC CONF, P975, DOI 10.1109/CVPRW50498.2020.00129
   King RC., 2006, A Dictionary of Genetics, V7th
   Koushik J, 2016, Arxiv, DOI arXiv:1605.09081
   Li X., 2020, ADV NEURAL INF PROCE, V33, P21002, DOI DOI 10.48550/ARXIV.2006.04388
   Luo C, 2020, arXiv, DOI [10.48550/arXiv.2006.15528, DOI 10.48550/ARXIV.2006.15528]
   Ma PL, 2023, ARTIF INTELL REV, V56, P1627, DOI 10.1007/s10462-022-10209-1
   Madian N, 2020, INT CONF COMP COMMUN, P600, DOI 10.1109/iccci48352.2020.9104123
   Manzari ON, 2023, COMPUT BIOL MED, V157, DOI 10.1016/j.compbiomed.2023.106791
   da Nóbrega RVM, 2018, COMP MED SY, P244, DOI 10.1109/CBMS.2018.00050
   Moazzen Y, 2019, BIOMED SIGNAL PROCES, V52, P353, DOI 10.1016/j.bspc.2019.04.017
   Mukhopadhyay C, 2023, INT C ADV COMP DAT S, P466, DOI [10.1007/978-3-031-37940-6_38, DOI 10.1007/978-3-031-37940-6_38]
   Nanculef R., 2020, Intravascular Ultrasound Elsevier, P141, DOI [10.1016/B978-0-12-818833-0.00009-6, DOI 10.1016/B978-0-12-818833-0.00009-6]
   Ngugi LC, 2021, INFORM PROCESS AGR, V8, P27, DOI 10.1016/j.inpa.2020.04.004
   Pandey Anupam, 2023, 2023 IEEE 12th International Conference on Communication Systems and Network Technologies (CSNT), P398, DOI 10.1109/CSNT57126.2023.10134745
   Qiu YC, 2016, PROC SPIE, V9709, DOI 10.1117/12.2217418
   Remya RS, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1754-z
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sathyan RR, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12799
   Shewajo FA, 2023, BMC MED IMAGING, V23, DOI 10.1186/s12880-023-00993-9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soviany Petru, 2018, 2018 20th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC). Proceedings, P209, DOI 10.1109/SYNASC.2018.00041
   Su Y, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105866
   Subasinghe A., 2015, bioRxiv, V39, P032110, DOI [10.12688/f1000research.9075.1, DOI 10.12688/F1000RESEARCH.9075.1]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Talukdar K, 2022, TISSUE CELL, V76, DOI 10.1016/j.tice.2022.101761
   Tan MX, 2020, Arxiv, DOI arXiv:1905.11946
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tjio J., 1956, Hereditas, V42, P1, DOI [10.1111/j.1601-5223.1956.tb03010.x, DOI 10.1111/J.1601-5223.1956.TB03010.X]
   Tzeng E., 2020, arXiv, DOI DOI 10.48550/ARXIV.2012.09958
   Uttamatanin R, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-S16-S13
   Wang H, 2022, COMPUT ELECTR ENG, V102, DOI 10.1016/j.compeleceng.2022.108269
   Wang J, 2023, IEEE J BIOMED HEALTH, V27, P4579, DOI 10.1109/JBHI.2023.3286572
   Wang XW, 2008, J BIOMED INFORM, V41, P264, DOI 10.1016/j.jbi.2007.06.008
   Xiao L, 2020, IEEE T MED IMAGING, V39, P3920, DOI 10.1109/TMI.2020.3007642
   Xie N, 2019, IEEE ACCESS, V7, P179445, DOI 10.1109/ACCESS.2019.2951723
   Xu XK, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15143525
   Yanik H, 2020, TEH GLAS, V14, P273, DOI 10.31803/tg-20200524225359
   Yilmaz H, 2017, ENG TECHNOL APPL SCI, V7, P2160
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
NR 56
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 14
PY 2023
DI 10.1007/s11042-023-17509-w
EA NOV 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JF3O4
UT WOS:001171713900006
DA 2024-07-18
ER

PT J
AU Al-Habashna, A
   Murdoch, R
AF Al-Habashna, Ala'a
   Murdoch, Ryan
TI Building height estimation from street-view imagery using deep learning,
   image processing and automated geospatial analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CNNs; Building height estimation; Semantic segmentation; Image
   processing; Building footprint
ID OBJECT DETECTION; SEGMENTATION
AB Street-view imagery has been increasingly used for geospatial data collection due to its increased availability and the advancements in the field of computer vision. A great deal of research has been conducted in recent years to extract valuable data from such imagery on buildings and infrastructure, transportation and mobility, walkability, and health and well-being. Building height is important data that can have crucial applications in areas such as city modeling and planning, and urban and economic analysis. In this paper, two algorithms and their implementation are proposed for automatic estimation of building height from street-view images using Deep Learning (DL), and advanced algorithms for image and geospatial data processing. The data required by the systems, i.e., street-view images and building footprint, are becoming increasingly available through multiple platforms. In this paper, the developed algorithms are discussed in detail. Moreover, the algorithms are evaluated on a test set and the obtained results for building-height estimation are presented. Finally, scalability and challenging cases are discussed.
C1 [Al-Habashna, Ala'a; Murdoch, Ryan] Stat Canada, Ctr Special Business Projects, Data Explorat & Integrat Lab, Ottawa, ON, Canada.
C3 Statistics Canada
RP Al-Habashna, A (corresponding author), Stat Canada, Ctr Special Business Projects, Data Explorat & Integrat Lab, Ottawa, ON, Canada.
EM alaa.al-habashna@statcan.gc.ca; ryan.murdoch@statcan.gc.ca
FU The authors of this paper would like to thank Dr. Alessandro Alasia
   (Statistics Canada) for his valuable support and input. The authors
   would also like to thank the Ramp;D Board of Statistics Canada for
   funding this project.; Ramp;D Board of Statistics Canada
FX The authors of this paper would like to thank Dr. Alessandro Alasia
   (Statistics Canada) for his valuable support and input. The authors
   would also like to thank the R&D Board of Statistics Canada for funding
   this project.
CR Al-Habashna A, 2021, 2021 18TH CONFERENCE ON ROBOTS AND VISION (CRV 2021), P103, DOI 10.1109/CRV52889.2021.00022
   [Anonymous], 2000, Emporis
   [Anonymous], 2004, OpenStreetMap
   [Anonymous], 2005, GOOGL MAPS
   ArcGIS, 2016, Azimuthal Equidistant
   Biljecki F, 2021, LANDSCAPE URBAN PLAN, V215, DOI 10.1016/j.landurbplan.2021.104217
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P1487, DOI 10.1109/TGRS.2009.2031910
   Cao ZW, 2021, IEEE WINT CONF APPL, P1187, DOI 10.1109/WACV48630.2021.00123
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cui Y, 2021, PROC 2022 IEEECVF WI, DOI [10.48550/arxiv.2110.07790, DOI 10.48550/ARXIV.2110.07790]
   Cui Y., 2021, PROC IEEE INT C COMP, DOI DOI 10.48550/ARXIV.2108.05821
   Díaz E, 2016, PROC SPIE, V9868, DOI 10.1117/12.2224312
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Dubrofsky E., 2009, Ph.D. Thesis
   Goel R, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196521
   Gonzalez D, 2020, BUILD ENVIRON, V177, DOI 10.1016/j.buildenv.2020.106805
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Google, 2020, STREET VIEW STATIC A
   google, 2001, Google Earth
   Grab Holdings, 2009, OPEN STREET CAM
   Hao H., 2021, SPIE 11729 Automatic Target Recognition XXXI, V11729, P175, DOI DOI 10.1117/12.2585012
   Kang J, 2018, ISPRS J PHOTOGRAMM, V145, P44, DOI 10.1016/j.isprsjprs.2018.02.006
   Li S, 2020, IET INTELL TRANSP SY, V14, P1517, DOI 10.1049/iet-its.2019.0521
   Li Y., 2018, 10 INT C GEOGR INF S, DOI 10.4230/LIPIcs.GIScience.2018.40
   Liu D., 2021, P AAAI C ART INT, V35, DOI [10.48550/arXiv.2012.02366, DOI 10.48550/ARXIV.2012.02366]
   Liu DF, 2020, NEUROCOMPUTING, V409, P1, DOI 10.1016/j.neucom.2020.05.027
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Mapillary, 2014, MAPILLARY
   Marianingsih S, 2018, PROCEEDINGS OF 2018 3RD INTERNATIONAL CONFERENCE ON SUSTAINABLE INFORMATION ENGINEERING AND TECHNOLOGY (SIET 2018), P48, DOI 10.1109/SIET.2018.8693113
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Mou LC, 2018, Arxiv, DOI arXiv:1802.10249
   Qu Z, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/595246
   Sampath A, 2010, IEEE T GEOSCI REMOTE, V48, P1554, DOI 10.1109/TGRS.2009.2030180
   Smith V, 2013, 2013 INTERNATIONAL GREEN COMPUTING CONFERENCE (IGCC)
   Statistics Canada, 2019, The Open Database of Buildings
   Statistics Canada, 2019, The linkable open data environment
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wikipedia, 2004, OpenStreetMap
   Yuan JY, 2016, PROCEEDINGS OF THE 2ND ACM SIGSPATIAL WORKSHOP ON SMART CITIES AND URBAN ANALYTICS (URBANGIS'16, DOI 10.1145/3007540.3007548
   Zhao YX, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2436, DOI 10.1145/3308558.3313394
NR 43
TC 0
Z9 0
U1 10
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 11
PY 2023
DI 10.1007/s11042-023-17363-w
EA NOV 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y0ZQ9
UT WOS:001102641900005
DA 2024-07-18
ER

PT J
AU Chen, WX
   Li, Q
   Tang, XY
   Pan, QY
AF Chen, Weixia
   Li, Qin
   Tang, Xiaoyan
   Pan, Qiyong
TI A digital watermarking method for medical images resistant to print-scan
   based on QR code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Digital watermarking; Medical images; QR code; DWT-SVD; Hough transform;
   Print and scan attacks
ID ENCRYPTION; TRANSFORM; PRIVACY; ROBUST; LINES
AB Medical images are important records to improve people's health care, and their security has become an important issue when they are transmitted through various media especially print and scan equipments. This paper proposes a digital watermarking method for medical images based on live QR code, DWT-SVD, Hough transform and bilinear interpolation. A live QR code including private information was embedded into the SVD blocks of LL3sub-band wavelet of medical image. Adjusting the embedding strength, a trade-off between invisibility and robustness was achieved. We printed and scanned the watermarked medical image with common printers and scanners and get the watermarked images after print-scanning. In extraction method, the Hough transform was used to detect the edge of the watermarked medical image and calculate the rotation angle and scaling ratio, and bilinear interpolation was used to correct geometric distortion of watermarked image. Then we extracted live QR code from corrected image successfully. Experimental results indicated that the proposed method provides sufficient security for medical images against print and scan attacks.
C1 [Chen, Weixia; Tang, Xiaoyan; Pan, Qiyong] Changshu Inst Technol, Sch Elect & Informat Engn, Changshu 215500, Peoples R China.
   [Li, Qin] Soochow Univ, Sch Phys Sci & Technol, Suzhou 215000, Peoples R China.
   [Li, Qin] Changshu 2 Peoples Hosp, Med Image Ctr, Changshu 215500, Peoples R China.
C3 Changshu Institute of Technology; Soochow University - China
RP Pan, QY (corresponding author), Changshu Inst Technol, Sch Elect & Informat Engn, Changshu 215500, Peoples R China.
EM panqy@cslg.edu.cn
CR Ajili S, 2016, INT J SIGNAL IMAGING, V9, P242, DOI 10.1504/IJSISE.2016.078269
   Alghazo JM, 2019, CURR MED IMAGING REV, V15, P386, DOI 10.2174/1573405615666181228121535
   Araghi TK, 2018, EXPERT SYST APPL, V112, P208, DOI 10.1016/j.eswa.2018.06.024
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Cedillo-Hernandez M, 2015, SIGNAL IMAGE VIDEO P, V9, P1163, DOI 10.1007/s11760-013-0555-x
   Chen WX, 2019, APPL OPTICS, V58, P4185, DOI 10.1364/AO.58.004185
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Gunjal BL, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-0904-z
   Hamidi M, 2018, MULTIMED TOOLS APPL, V77, P27181, DOI 10.1007/s11042-018-5913-9
   Hough P. V. C., 1962, Method and Means for Recognizing Complex Patterns
   Garcia-Hernandez JJ, 2016, COMPUT BIOL MED, V68, P37, DOI 10.1016/j.compbiomed.2015.10.014
   Keskinarkaus A, 2010, J SYST SOFTWARE, V83, P1715, DOI 10.1016/j.jss.2010.04.073
   Lakshmi C, 2018, COMPUT METH PROG BIO, V159, P11, DOI 10.1016/j.cmpb.2018.02.021
   Matas J, 2000, COMPUT VIS IMAGE UND, V78, P119, DOI 10.1006/cviu.1999.0831
   Mehta S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI 2013), P287, DOI 10.1109/ICHI.2013.41
   Mizumoto T, 2003, ELECTRON COMM JPN 3, V86, P11, DOI 10.1002/ecjc.10059
   Prabakaran G., 2013, Proceedings of the 2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering (PRIME), P251, DOI 10.1109/ICPRIME.2013.6496482
   Seenivasagam V, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/516465
   Sharma A, 2017, WIRELESS PERS COMMUN, V92, P1611, DOI 10.1007/s11277-016-3625-x
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Sivaprakash A, 2019, CURR MED IMAGING, V15, P802, DOI 10.2174/1573405615666190408115158
   Thanki R, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0795-3
   Wang DY, 2016, J INF PROCESS SYST, V12, P765, DOI 10.3745/JIPS.03.0055
   Wang SZ, 2010, APPL OPTICS, V49, P1170, DOI 10.1364/AO.49.001170
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zermi N, 2021, FORENSIC SCI INT, V320, DOI 10.1016/j.forsciint.2021.110691
NR 26
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 10
PY 2023
DI 10.1007/s11042-023-17155-2
EA NOV 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9QP0
UT WOS:001101716100001
DA 2024-07-18
ER

PT J
AU Heruatmadja, CH
   Ramadhan, A
AF Heruatmadja, Chandra H.
   Ramadhan, Arief
TI Drivers and barriers of intention to work within metaverse environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Drivers; Barriers; Work; Metaverse; Technology paradox; Intention to
   work
ID PLS-SEM; TECHNOLOGY; PARADOXES; PERFORMANCE; EMOTIONS
AB Currently several industries are starting to try to apply metaverse in various possible implementations, such as manufacturing, health, business, education and training, architecture, and entertainment. For business in a smaller context, metaverse can be used to interact with other users in virtual meetings and predicted to be able to replace the current concept of online communication using video conferencing. The question is are the employees have intention to work within metaverse environment in the future, and what will be the barrier and the driver for employees to work within metaverse environment To answer this question, a Partial Least Squares Structural Equation Modelling (PLS-SEM) analysis methodology was carried out using a modified dual factor model approach. In this study it is also proposed to add environmental factors which are also a part in a decision-making process. The research result shows that the application of the metaverse in the company does not necessarily need to be driven by external factors. Instead, the company's independence determines its adaptation to the technology. From this study, it was obtained that the factors in the dual factor model had a significant or no significant effect on the intention to work within metaverse. By validity, reliability, and path coefficient tests on research model proposed, it is determined the readiness and interest of employees to switch to work within metaverse.
C1 [Heruatmadja, Chandra H.] Univ Bunda Mulia, Fac Technol & Design, Jakarta, Indonesia.
   [Ramadhan, Arief] Telkom Univ, Sch Comp, Bandung, Indonesia.
C3 Telkom University
RP Ramadhan, A (corresponding author), Telkom Univ, Sch Comp, Bandung, Indonesia.
EM arieframadhan@telkomuniversity.ac.id
RI Ramadhan, Arief/AAF-3969-2021
OI Ramadhan, Arief/0000-0001-5501-7457
CR Alvarez-Risco A., 2022, Journal of Open Innovation: Technology, Market, and Complexity, V8, P1, DOI DOI 10.3390/JOITMC8030142
   Amaizu G, 2022, KORENA I COMMUNICATI
   Aufegger L, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157393
   Bae S, 2022, INT C INTERFACES HUM, P239
   Bagozzi RP, 1998, Journal of the academy of marketing science, V16, P76
   Becker JM, 2023, INT J CONTEMP HOSP M, V35, P321, DOI 10.1108/IJCHM-04-2022-0474
   Bick A., 2020, WORK HOME COVID 19 O, DOI DOI 10.24149/WP2017
   Bruner GC, 2005, J BUS RES, V58, P553, DOI 10.1016/j.jbusres.2003.08.002
   Chae M, 2010, Int J Manag Sci; Seoul, V16, P140
   Chakrabartty S, 2014, J Knowl Manag Informat Technol, V1
   Charlton E, 2022, Will the metaverse be good for businesses? Here's what top executives say | World Economic Forum
   Cheng X., 2022, Journal of Electronic Business Digital Economics, V1, P206, DOI [10.1108/JEBDE-09-2022-0036, DOI 10.1108/JEBDE-09-2022-0036]
   Choi HY, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14063629
   Compeau D, 1999, MIS QUART, V23, P145, DOI 10.2307/249749
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Facebook Inc, 2023, Everything Facebook revealed about the Metaverse in 11 minutes
   Facebook Inc, 2021, The Facebook Company Is Now Meta
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Garson G.D., 2016, VALIDITY RELIABILITY
   Gokhan Nalbant K, 2022, Int J Comput, V7
   Golf-Papez M, 2022, BUS HORIZONS, V65, P739, DOI 10.1016/j.bushor.2022.07.007
   Hair JF, 2011, J MARKET THEORY PRAC, V19, P139, DOI 10.2753/MTP1069-6679190202
   Hair JF, 2014, EUR BUS REV, V26, P106, DOI 10.1108/EBR-10-2013-0128
   Heine H, 2007, A Short Tutorial of GPower, V3
   HOLAHAN CJ, 1987, J PERS SOC PSYCHOL, V52, P946, DOI 10.1037/0022-3514.52.5.946
   Jarvenpaa SL, 2005, INFORM SYST MANAGE, V22, P7, DOI 10.1201/1078.10580530/45520.22.4.20050901/90026.2
   Johnson DS, 2008, PSYCHOL MARKET, V25, P416, DOI 10.1002/mar.20218
   Johnson DS, 2005, J ACAD MARKET SCI, V33, P3, DOI 10.1177/0092070304266119
   Jones EE, 1989, Personal Soc Psychol Bull, V15
   Kock N, 2020, Data Anal Perspect J, V1
   Kwon H, 2023, MLSYS C
   Latumeten R., 2018, Sainmatika: Jurnal Ilmiah Matematika Dan Ilmu Pengetahuan Alam, V15, P76, DOI [10.31851/SAINMATIKA.V15I2.2301, DOI 10.31851/SAINMATIKA.V15I2.2301]
   Lee J., 2022, JAHR, V13, P177, DOI [10.21860/j.13.1.10, DOI 10.21860/J.13.1.10]
   Lee WJ., 2016, Int J Softw Eng Appl, V10, P441, DOI [10.14257/ijseia.2016.10.11.35, DOI 10.14257/IJSEIA.2016.10.11.35]
   Lin JCC, 2000, INT J INFORM MANAGE, V20, P197, DOI 10.1016/S0268-4012(00)00005-0
   Mick DG, 1998, J CONSUM RES, V25, P123, DOI 10.1086/209531
   Microsoft Developers, 2021, Microsoft Mesh App August 2021 updates
   Microsoft Mechanics, 2021, Microsoft Mesh hands-on demo
   Norman D, 2013, MIT Technol Rev, P101
   Obrien M, 2021, Tech Explorer
   Park SM, 2022, IEEE ACCESS, V10, P4209, DOI 10.1109/ACCESS.2021.3140175
   Patanjali S., 2022, VISION, DOI [10.1177/09722629221074137, DOI 10.1177/09722629221074137]
   Pozniak H., 2022, Eng Technol, V17, P1, DOI [10.1049/et.2022.0408, DOI 10.1049/ET.2022.0408]
   Ramadhan A, 2023, J INF ORGAN SCI, V47, P153, DOI 10.31341/jios.47.1.8
   Sarstedt M., 2017, HDB MARKET RES, P1, DOI [10.1007/978-3-319-05542-8_15-1, DOI 10.1007/978-3-319-05542-8_15-1]
   Stephenson N, 1992, Bantam books
   Sun HS, 2006, J ASSOC INF SYST, V7, P618, DOI 10.17705/1jais.00100
   Taber KS, 2018, RES SCI EDUC, V48, P1273, DOI 10.1007/s11165-016-9602-2
   Thompson R.L., 1995, Journal of Management Information Systems, V11, P167, DOI [10.1080/07421222.1994.11518035, DOI 10.1080/07421222.1994.11518035]
   Vartiainen M, 2006, Mobile virtual work, DOI [10.1007/3-540-28365-X_2, DOI 10.1007/3-540-28365-X_2]
   Williams P, 2002, J CONSUM RES, V28, P636, DOI 10.1086/338206
   Wong ES, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157581
   Xi NN, 2023, INFORM SYST FRONT, V25, P659, DOI 10.1007/s10796-022-10244-x
   Yang FF, 2022, HELIYON, V8, DOI 10.1016/j.heliyon.2022.e10562
NR 54
TC 0
Z9 0
U1 6
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 9
PY 2023
DI 10.1007/s11042-023-17567-0
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9MX6
UT WOS:001101620700013
DA 2024-07-18
ER

PT J
AU Mekouar, L
   Iraqi, Y
   Damaj, I
AF Mekouar, Loubna
   Iraqi, Youssef
   Damaj, Issam
TI A global user profile framework for effective recommender systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
AB Modern Recommender Systems (RSs) compete to maintain rich user profiles that can accurately reflect user behavior, interests, and service contexts. While benefiting from an online service supported by an RS, user preferences and interests may rapidly change over time. To keep up with the changes from the user perspective, an RS should maintain the making of effective personalization as supported by robust profile construction methods. Building an effective user profile database requires exhaustive data and behavior analysis over extended periods. In this paper, we delve into traditional RS architectures to identify limitations, gaps, and opportunities for improvements in existing user profile mechanisms. To that end, a Global User Profile Framework (GUPF) is proposed towards achieving increased effectiveness. Furthermore, the adoption of the developed framework is exemplified by presenting different potential scenarios. The presented work concludes with the identification of important venues and research directions that are enabled by the proposed GUPF.
C1 [Mekouar, Loubna; Iraqi, Youssef] Univ Mohammed VI Polytech, Coll Comp, Lot 660 Hay Moulay Rachid, Benguerir 43150, Morocco.
   [Damaj, Issam] Cardiff Metropolitan Univ, Cardiff Sch Technol, Western Ave, Cardiff CF5 2YB, Wales.
C3 Mohammed VI Polytechnic University; Cardiff Metropolitan University
RP Damaj, I (corresponding author), Cardiff Metropolitan Univ, Cardiff Sch Technol, Western Ave, Cardiff CF5 2YB, Wales.
EM Loubna.Mekouar@um6p.ma; Youssef.Iraqi@um6p.ma; IDamaj@cardiffmet.ac.uk
RI Iraqi, Youssef/A-4009-2015
OI Iraqi, Youssef/0000-0003-0112-2600
FU This research was partially funded by Zayed University, United Arab
   Emirates, under the R20055 Start-Up Grant Award and the Start-Up Grant
   Award provided by Mohammed VI Polytechnic University, Morocco. [R20055];
   Zayed University, United Arab Emirates; Mohammed VI Polytechnic
   University, Morocco
FX This research was partially funded by Zayed University, United Arab
   Emirates, under the R20055 Start-Up Grant Award and the Start-Up Grant
   Award provided by Mohammed VI Polytechnic University, Morocco.
CR Al-Ghuribi SM, 2019, IEEE ACCESS, V7, P169446, DOI 10.1109/ACCESS.2019.2954861
   Anjali, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P143, DOI 10.1109/ICCCIS51004.2021.9397099
   Bilal M, 2020, IEEE ACCESS, V8, P77227, DOI 10.1109/ACCESS.2020.2989463
   Campana Mattia G., 2017, Online Social Networks and Media, V3, P75, DOI 10.1016/j.osnem.2017.10.005
   Chen L, 2017, PROC INT C TOOLS ART, P301, DOI 10.1109/ICTAI.2017.00055
   Eke CI, 2019, IEEE ACCESS, V7, P144907, DOI 10.1109/ACCESS.2019.2944243
   Ekstrand M. D., 2015, Proceedings of the 9th ACM Conference on Recommender Systems RecSys'15, P11
   Fernandez-Tobias Ignacio, 2012, Cross-domain recommender systems: a survey of the state of the art
   Guo JP, 2018, MULTIMED TOOLS APPL, V77, P12901, DOI 10.1007/s11042-017-4922-4
   Harper F. Maxwell, 2015, Proceedings of the 9th ACM Conference on Recommender Systems, RecSys '15, P3
   He M, 2019, CHINA COMMUN, V16, P219, DOI 10.12676/j.cc.2019.04.017
   Heitmann B, 2010, P 1 INT WORKSHOP INF, P16, DOI [10.1145/1869446.1869449, DOI 10.1145/1869446.1869449]
   Hernandez-Bocanegra Diana C., 2020, i-com: Journal of Interactive Media, V19, P181, DOI 10.1515/icom-2020-0021
   Jalili M, 2018, IEEE ACCESS, V6, P74003, DOI 10.1109/ACCESS.2018.2883742
   Kapoor Komal, 2015, P 9 ACM C RECOMMENDE, P19, DOI [10.1145/2792838.2800172, DOI 10.1145/2792838.2800172]
   Karumur RP, 2018, INFORM SYST FRONT, V20, P1241, DOI 10.1007/s10796-017-9800-0
   Krishnan GS, 2017, INT CONF COMPUT
   Kulkarni T, 2019, ANNU IEEE IND CONF, DOI 10.1109/indicon47234.2019.9028982
   Lex E, 2021, FOUND TRENDS INF RET, V15, P134, DOI 10.1561/1500000090
   Li ZQ, 2018, INT CONF DAT MIN WOR, P1294, DOI 10.1109/ICDMW.2018.00184
   Liang HZ, 2022, IEEE T KNOWL DATA EN, V34, P1723, DOI 10.1109/TKDE.2020.2998695
   Liu JX, 2016, IEEE T SERV COMPUT, V9, P686, DOI 10.1109/TSC.2015.2433251
   MCCRAE RR, 1987, J PERS SOC PSYCHOL, V52, P81, DOI 10.1037/0022-3514.52.1.81
   Mekouar L, 2022, COMPUT COMMUN, V187, P1, DOI 10.1016/j.comcom.2022.01.020
   Mu RH, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2018.2880197
   Nguyen TT, 2018, INFORM SYST FRONT, V20, P1173, DOI 10.1007/s10796-017-9782-y
   nih, Developing universal electronic medical records
   ORCiD, ABOUT US
   Petersen F, 2008, Int J Interact Mobile Technol (IJIM), V2, DOI [10.3991/ijim.v2i4.666, DOI 10.3991/IJIM.V2I4.666]
   Sahu AK, 2019, APPL INTELL, V49, P2461, DOI 10.1007/s10489-018-01402-3
   showmethedata, How to measure data quality?
   Stakhiyevich Pavel, 2019, 2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS). Proceedings, P2559, DOI 10.1109/HPCC/SmartCity/DSS.2019.00358
   Stakhiyevich P, 2019, Building user profiles based on user interests and preferences for recommender systems, P450, DOI [10.1109/IUCC/DSCI/SmartCNS.2019.00101, DOI 10.1109/IUCC/DSCI/SMARTCNS.2019.00101]
   Uyangodage L, 2019, User profile feature-based approach to address the cold start problem in collaborative filtering for personalized movie recommendation
   w3, Composite capability/preference profiles (CC/PP)
   w3, User modeling
   Wischenbart M, 2021, MULTIMED TOOLS APPL, V80, P6785, DOI 10.1007/s11042-020-09803-8
   Yang Z, 2016, IEEE ACCESS, V4, P3273, DOI 10.1109/ACCESS.2016.2573314
   Zang T, 2018, Proc ACM Meas Anal Comput Syst, V37
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zhu F, 2021, Arxiv, DOI arXiv:2103.01696
   Zhu ZL, 2018, IEEE ACCESS, V6, P41068, DOI 10.1109/ACCESS.2018.2858564
NR 42
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-17436-w
EA NOV 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600016
OA hybrid
DA 2024-07-18
ER

PT J
AU Tüfekci, P
   Kösesoy, MB
AF Tufekci, Pinar
   Kosesoy, Melike Bektas
TI Biological gender identification in Turkish news text using deep
   learning models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Biological Gender Identification; Text Classification; Turkish News
   Text; Machine Learning; Deep Learning
ID AUTHOR; CATEGORIZATION; CLASSIFICATION; GENRE
AB Identifying the biological gender of authors based on the content of their written work is a crucial task in Natural Language Processing (NLP). Accurate biological gender identification finds numerous applications in fields such as linguistics, sociology, and marketing. However, achieving high accuracy in identifying the biological gender of the author is heavily dependent on the quality of the collected data and its proper splitting. Therefore, determining the best-performing model necessitates experimental evaluation. This study aimed to develop and evaluate four learning algorithms for biological gender identification in news texts. To this end, a comprehensive dataset, IAG-TNKU, was created from a Turkish newspaper, comprising 43,292 news articles. Four models utilizing popular machine learning algorithms, including Naive Bayes and Random Forest, and two deep learning algorithms, Long Short Term Memory and Convolutional Neural Networks, were developed and evaluated rigorously. The results indicated that the Long Short Term Memory (LSTM) algorithm outperformed the other three models, exhibiting an exceptional accuracy of 88.51%. This model's outstanding performance underpins the importance of utilizing innovative deep learning algorithms for biological gender identification tasks in NLP. The present study contributes to extant literature by developing a new dataset for biological gender identification in news texts and evaluating four machine learning algorithms. Our findings highlight the significance of utilizing innovative techniques for biological gender identification tasks. The dataset and deep learning algorithm can be applied in many areas such as sociolinguistics, marketing research, and journalism, where the identification of biological gender in written content plays a pivotal role.
C1 [Tufekci, Pinar] Tekirdag Namik Kemal Univ, Comp Engn Dept, Engn Fac, Univ 1 St,13, TR-59860 Tekirdag, Turkiye.
   [Kosesoy, Melike Bektas] Bursa Tech Univ, Informat Technol Dept, Bursa, Turkiye.
C3 Namik Kemal University; Bursa Technical University
RP Tüfekci, P (corresponding author), Tekirdag Namik Kemal Univ, Comp Engn Dept, Engn Fac, Univ 1 St,13, TR-59860 Tekirdag, Turkiye.
EM ptufekci@nku.edu.tr; melike.bektas@btu.edu.tr
RI Bektaş Kösesoy, Melike/AAW-5043-2021; Tufekçi, Pinar/ABA-5121-2020
OI Bektaş Kösesoy, Melike/0000-0002-1944-1928; TUFEKCI,
   PINAR/0000-0003-4842-2635
CR Abdallah EE, 2020, PROCEDIA COMPUT SCI, V170, P563, DOI 10.1016/j.procs.2020.03.126
   Akin A.A., 2007, Zemberek, an Open Source Nlp Framework for Turkic Languages"
   Al-Salemi B, 2019, INFORM PROCESS MANAG, V56, P212, DOI 10.1016/j.ipm.2018.09.008
   Alsmearat K, 2017, J INF SECUR APPL, V35, P85, DOI 10.1016/j.jisa.2017.06.003
   Amasyali MF, 2006, LECT NOTES COMPUT SC, V3999, P221
   Angeles A, 2021, TENCON 2021 2021 IEE
   Bhagvati Ritesh Chakravarthy, 2018, Procedia Computer Science, V132, P614, DOI 10.1016/j.procs.2018.05.015
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Canbek G, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P821, DOI 10.1109/UBMK.2017.8093539
   Cheng N, 2011, DIGIT INVEST, V8, P78, DOI 10.1016/j.diin.2011.04.002
   Chollet F., 2017, DEEP LEARNING PYTHON
   Dalyan T, 2022, INF TECHNOL CONTROL, V51, P429, DOI 10.5755/j01.itc.51.3.29907
   Dogan F., 2019, D MF M HENDISLIK DER, V10, P409, DOI [10.24012/dumf.411130, DOI 10.24012/DUMF.411130]
   Dogan S, 2010, Turkiye Bilisim Vakfi Bilgisayar Bilimleri ve Muhendisligi Dergisi, P11
   Gomes L, 2023, INFORM SOFTWARE TECH, V160, DOI 10.1016/j.infsof.2023.107217
   Gu J, 2006, arXiv:1512.07108, P1
   Guarino A, 2023, EXPERT SYST APPL, V219, DOI 10.1016/j.eswa.2023.119614
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI DOI 10.5121/IJDKP.2015.5201
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Husseina S, 2019, EGYPT INFORM J, V20, P109, DOI 10.1016/j.eij.2018.12.002
   Jin Z, 2020 IEEE INT S PROD, P1
   Kaban Z, 2008, 2008 IEEE 16 SIGNAL, P1
   Kucukyilmaz T, 2020, PATTERN RECOGN LETT, V140, P245, DOI 10.1016/j.patrec.2020.10.002
   Loper E., 2002, ARXIV
   Oliphant T.E., 2015, A Guide to NumPy, V2nd ed.
   Onikoyi B., 2023, Nat. Lang. Process. J., V4, DOI [10.1016/j.nlp.2023.100018, DOI 10.1016/J.NLP.2023.100018]
   PICARD RR, 1984, J AM STAT ASSOC, V79, P575, DOI 10.2307/2288403
   Reynaldo N, 2019, PROCEDIA COMPUT SCI, V157, P64, DOI 10.1016/j.procs.2019.08.142
   Sahin DO, 2018, arXiv
   Sboev A, 2016, PROCEDIA COMPUT SCI, V101, P135, DOI 10.1016/j.procs.2016.11.017
   Sboev A, 2018, PROCEDIA COMPUT SCI, V123, P417, DOI 10.1016/j.procs.2018.01.064
   Sboev A, 2018, PROCEDIA COMPUT SCI, V123, P424, DOI 10.1016/j.procs.2018.01.065
   Tai KS, 2015, Arxiv, DOI arXiv:1503.00075
   Stamatatos E, 2008, INFORM PROCESS MANAG, V44, P790, DOI 10.1016/j.ipm.2007.05.012
   Sun JW, 2022 11 INT C INF CO, P1
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Tufekci P, 2012, 20 SIGN PROC COMM AP, P1
   Tüfekci P, 2022, SADHANA-ACAD P ENG S, V47, DOI 10.1007/s12046-022-01975-3
   Tüfekci P, 2013, SIG PROCESS COMMUN
   Uzun E, 2020, IEEE ACCESS, V8, P61726, DOI 10.1109/ACCESS.2020.2984503
   VanderPlas J., 2016, Python Data Science Handbook: Essential Tools for Working with Data, V1st
   Varsamopoulos S, 2019, Arxiv, DOI arXiv:1811.12456
   Vijayakumar B, 2019, PROCEDIA COMPUT SCI, V159, P428, DOI 10.1016/j.procs.2019.09.197
   Wongso R, 2017, PROCEDIA COMPUT SCI, V116, P137, DOI 10.1016/j.procs.2017.10.039
   Yasdi M, 2012, 2012 20 SIGN PROC CO, P1
NR 45
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-17622-w
EA NOV 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600014
DA 2024-07-18
ER

PT J
AU Rajwal, S
AF Rajwal, Swati
TI LiHiSTO: a comprehensive list of Hindi stopwords
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Stopwords; Indian languages; Text analytics; Natural Language
   Processing; Python package
AB A preliminary preprocessing step in text analytics is the removal of words with no semantic meaning, otherwise known as stopwords. English stopwords are very easily accessible and created due to the broad usability of the English language. However, a standard list of Hindi stopwords is still missing. This paper proposes an exhaustive list of generic Hindi stopwords and a Python package for easy distribution and usage. The methodology uses a dual mechanism for creating a list of Hindi stopwords. First, the famous English stopwords are collected and translated into meaningful Hindi words (group 1). Second, unique Hindi stopwords from multiple sources are fetched (group 2). Finally, the respective Hindi stopwords from groups 1 and 2 are combined, which resulted in a significantly large set of 820 Hindi stopwords. Additionally, the list of Hindi stopwords is made openly available for use at the Python Package Index (PyPI) repository as a Python package, which is named LiHiSTO. With the help of illustrative implementations, it is shown that LiHiSTO provides abstract and easy access to the list of stopwords for users to perform Hindi text analytics.
C1 [Rajwal, Swati] Univ Cambridge, Cambridge, England.
C3 University of Cambridge
RP Rajwal, S (corresponding author), Univ Cambridge, Cambridge, England.
EM sr2050@cam.ac.uk
OI Rajwal, Swati/0000-0002-3826-5069
FU The author would like to thank the journal reviewers for their valuable
   suggestions contributing to the improvement of this paper.
FX The author would like to thank the journal reviewers for their valuable
   suggestions contributing to the improvement of this paper.
CR Akhtar M. S., 2016, P COLING 2016 26 INT, P482
   [Anonymous], Stopwords PPI
   [Anonymous], Find, install and publish python packages with the python package index
   Bird S., 2009, NATURAL LANGUAGE PRO
   Bozkurt F, 2019, TEH VJESN, V26, P1218, DOI 10.17559/TV-20180123005000
   BURCHFIELD R, 1985, J ENGL LINGUIST, V18, P64, DOI 10.1177/007542428501800107
   Coban O, 2022, ARAB J SCI ENG, V47, P9423, DOI 10.1007/s13369-021-06238-7
   Das K, 2020, Kaggle
   Dedhia H., 2020, Kaggle
   Dhanwal S, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P1191
   github, Stopwords-ISO/stopwords-hi: Hindi stopwords collection
   Jha V, 2016, 2016 INTERNATIONAL CONFERENCE ON MICROELECTRONICS, COMPUTING AND COMMUNICATIONS (MICROCOM)
   Joshi H, 2012, NIRMA UNIV INT CONF, DOI 10.1109/NUICONE.2012.6493219
   Kumar Y, 2019, arXiv, DOI [10.5281/zenodo.3457467, DOI 10.5281/ZENODO.3457467]
   Ladani DJ, 2020, INT CONF ADVAN COMPU, P466, DOI [10.1109/ICACCS48705.2020.9074166, 10.1109/icaccs48705.2020.9074166]
   LUHN HP, 1957, IBM J RES DEV, V1, P309, DOI 10.1147/rd.14.0309
   NirantK, Release dataset release: BBC Hindi v0.1  NIRANTK/hindi2vec
   Pandey AK, 2009, P 1 INT C INT HUM CO, P316
   Pip PPI, About us
   Ragnar, 2020, Kaggle
   Rani R, 2022, J KING SAUD UNIV-COM, V34, P2771, DOI 10.1016/j.jksuci.2020.03.003
   Rani R, 2018, LECT NOTES COMPUT SC, V11278, P123, DOI 10.1007/978-3-030-04021-5_12
   Raulji JK, 2017, IEEE INT ADV COMPUT, P799, DOI [10.1109/IACC.2017.0164, 10.1109/IACC.2017.155]
   Silva C, 2004, P INT JOINT C NEUR N
   Singh S, 2012, 2012 INT C INF RETR
   Szmigiera M, 2021, M 30. Mostspokenlanguagesintheworld
   Ul Haque R, 2020, ARAB J SCI ENG, V45, P3355, DOI 10.1007/s13369-020-04388-8
   Uppal S, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P706
NR 28
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17205-9
EA NOV 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200019
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Li, JT
   Wang, XD
   Song, YF
   Wang, P
AF Li, Jingtai
   Wang, Xiaodan
   Song, Yafei
   Wang, Peng
TI FPFnet: Image steganalysis model based on adaptive residual extraction
   and feature pyramid fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image steganalysis; Convolution neural networks; Feature fusion;
   Residual extraction; Up sampling
ID NETWORK; CNN
AB Image steganalysis is a technique for detecting images that contain hidden information. Convolutional neural networks have shown great potential in the steganalysis field. In this paper, we propose the feature pyramid fusion network (FPFnet), an image steganalysis model that combines adaptive residual extraction and feature pyramid fusion. In pre-processing, we present an adaptive residual extraction method instead of manually designed filters for extracting diverse residual features. The residual calculation function is reformed to improve the stability of optimal parameters. The residual is adaptively scaled to improve the truncation process. The residual extraction and truncation processes are incorporated into network training. To improve the utilization of residual features in different layers, we design feature pyramid fusion structure by introducing up sampling and feature fusion methods to fuse residual maps of different sizes in neural networks. Comparative experiments with different residual extraction methods, as well as up sampling and feature fusion methods, show that FPFnet has higher accuracy than other steganalysis models on the spatial universal wavelet relative distortion (S-UNIWARD) and wavelet obtained weights (WOW) datasets.
C1 [Li, Jingtai; Wang, Xiaodan; Song, Yafei; Wang, Peng] Air Force Engn Univ, Xian, Peoples R China.
C3 Air Force Engineering University
RP Wang, XD (corresponding author), Air Force Engn Univ, Xian, Peoples R China.
EM afeu_wang@163.com
RI Song, Yafei/M-7992-2014
OI Song, Yafei/0000-0003-0962-0671
FU This study was supported by the National Natural Science Foundation of
   China (61876189) [61876189]; National Natural Science Foundation of
   China
FX This study was supported by the National Natural Science Foundation of
   China (61876189)
CR Amrutha E, 2022, NEURAL PROCESS LETT, V54, P853, DOI 10.1007/s11063-021-10661-0
   [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bin Li, 2018, IEEE Signal Processing Letters, V25, P650, DOI 10.1109/LSP.2018.2816569
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen H, 2023, MULTIMED TOOLS APPL, V82, P22009, DOI 10.1007/s11042-021-11611-7
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Kodovsky J, 2011, SPIE, P204
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kodovsky J, 2012, PROC SPIE, V8303, DOI 10.1117/12.907495
   Lin M, 2014, Arxiv, DOI [arXiv:1312.4400, DOI 10.48550/ARXIV.1312.4400]
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Selvaraj A, 2021, IET IMAGE PROCESS, V15, P504, DOI 10.1049/ipr2.12043
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan SQ, 2021, IEEE T INF FOREN SEC, V16, P131, DOI 10.1109/TIFS.2020.3005304
   Tan SQ, 2014, ASIAPAC SIGN INFO PR
   Weng SW, 2022, IEEE SIGNAL PROC LET, V29, P1888, DOI 10.1109/LSP.2022.3201727
   Wu T, 2022, INT J INTELL SYST, V37, P7444, DOI 10.1002/int.22888
   Xie GL, 2023, DIGIT SIGNAL PROCESS, V139, DOI 10.1016/j.dsp.2023.104063
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Xu GY, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/3676720
   Xueyi Y., 2022, J Electron Inf Technol, V44, P1
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092, DOI 10.1109/ICASSP.2018.8461438
   You WK, 2021, IEEE T INF FOREN SEC, V16, P291, DOI 10.1109/TIFS.2020.3013204
   Zhang R, 2020, IEEE T INF FOREN SEC, V15, P1138, DOI 10.1109/TIFS.2019.2936913
NR 43
TC 1
Z9 1
U1 6
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17592-z
EA NOV 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500026
DA 2024-07-18
ER

PT J
AU Nayak, AA
   Venugopala, PS
   Sarojadevi, H
   Ashwini, B
   Chiplunkar, NN
AF Nayak, Ankitha A.
   Venugopala, P. S.
   Sarojadevi, H.
   Ashwini, B.
   Chiplunkar, Niranjan N.
TI A novel watermarking technique for video on android mobile devices based
   on JPG quantization value and discrete cosine transform approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE DCT; Mobile devices; Power consumption; Video watermarking
AB In today's communication era, social media and sharing data through the world wide web plays a substantial role. As per a recent survey, 80% of communication these days is carried out through the Internet. Moreover, the explosive growth of technology has transformed mobile devices into indispensable tools in the computing world. In short, the significant progress of technology has made accessing and modifying data quick and more straightforward. However, the ease of usage of multimedia over the net has opened a door for many attacks and piracy acts, where security and authentication play a vital role. This paper presents a novel video watermarking approach using hybrid discrete cosine transforms for copyright protection and authentication. The main objective of this method is to develop robust and efficient watermarking techniques for videos on mobile devices. Mobile devices function within the limitation of restricted storage and battery life. Therefore, there is heightened emphasis on the analysis of power consumption and execution time during the design of mobile applications. Our preliminary work draws a clear conclusion on the efficient video watermarking approach required for mobile devices concerning power consumption and execution time. In addition, we have illustrated a comparative analysis of existing works on multimedia security and authentication with the proposed watermarking technique on video.
C1 [Nayak, Ankitha A.; Chiplunkar, Niranjan N.] Nitte, NMAM Inst Technol NMAMIT, Dept Comp Sci & Engn, Udupi 574110, Karnataka, India.
   [Venugopala, P. S.] Nitte, NMAM Inst Technol NMAMIT, Dept Artificial Intelligence & Data Sci, Mangaluru 574110, Karnataka, India.
   [Sarojadevi, H.] Nitte Meenakshi Inst Technol, Dept Comp Sci & Engn, Bengaluru 560064, Karnataka, India.
   [Ashwini, B.] NITTE, NMAM Inst Technol NMAMIT, Dept Informat Sci & Engn, Mangaluru 574110, Karnataka, India.
C3 Nitte Meenakshi Institute of Technology
RP Nayak, AA (corresponding author), Nitte, NMAM Inst Technol NMAMIT, Dept Comp Sci & Engn, Udupi 574110, Karnataka, India.
EM ankitu.1234@gmail.com
RI B, Ashwini/AEN-0129-2022
OI H, Dr. SAROJA DEVI/0000-0002-2751-6088; Nayak, Ankitha
   A/0000-0002-4757-8542
CR Abdulla N.T.B., 2020, 2020 INT C POW EL RE, P1, DOI [10.1109/PEREA51218.2020.9339797, DOI 10.1109/PEREA51218.2020.9339797]
   Adul V, 2017, AFRICON, P309, DOI 10.1109/AFRCON.2017.8095500
   Agarwal P, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER AND COMPUTATIONAL SCIENCES (ICCCS), P151, DOI 10.1109/ICCACS.2015.7361341
   Ahmed Hasan M., 2019, 2019 2nd International Conference on Electrical, Communication, Computer, Power and Control Engineering (ICECCPCE), P74, DOI 10.1109/ICECCPCE46549.2019.203751
   Ahuja Rakesh, 2020, 2020 Sixth International Conference on Parallel, Distributed and Grid Computing (PDGC), P313, DOI 10.1109/PDGC50313.2020.9315778
   Ahuja Rakesh, 2019, International Journal of Information and Computer Security, V11, P585
   Arab F, 2019, 2019 IEEE 2ND INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT), P114, DOI [10.1109/INFOCT.2019.8711154, 10.1109/infoct.2019.8711154]
   Bai Jiayi, 2022, 2022 IEEE 22nd International Conference on Communication Technology (ICCT), P1667, DOI 10.1109/ICCT56141.2022.10072571
   Banoci V, 2014, P ELMAR 2014, P1, DOI [10.1109/ELMAR.2014.6923343, DOI 10.1109/ELMAR.2014.6923343]
   Basu A, 2016, 2016 SECOND IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P269, DOI 10.1109/ICRCICN.2016.7813669
   Busiri MG, 2017, INT C INSTR COMMUN, P207, DOI 10.1109/ICICI-BME.2017.8537779
   Cao ZL, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P103, DOI 10.1109/ICICIP.2018.8606680
   Vega-Hernandez PD, 2019, I W BIOMETRIC FORENS, DOI 10.1109/iwbf.2019.8739199
   Dhevanandhini G, 2021, MULTIMEDIA SYST, V27, P953, DOI 10.1007/s00530-021-00765-x
   Feng G, 2012, Anti-counterfeiting, Security, and Identification, P1, DOI [10.1109/ICASID.2012.6325285, DOI 10.1109/ICASID.2012.6325285]
   Gaj S, 2020, MULTIMED TOOLS APPL, V79, P18089, DOI 10.1007/s11042-019-08301-w
   Gao Z, 2021, 2021 INT C CULT OR S, P349, DOI [10.1109/ICCST53801.2021.00079, DOI 10.1109/ICCST53801.2021.00079]
   Hao KL, 2020, CHINA COMMUN, V17, P131, DOI 10.23919/JCC.2020.11.012
   Jadhav Anita, 2014, 2014 International Conference on Electronic Systems, Signal Processing and Computing Technologies (ICESC), P140, DOI 10.1109/ICESC.2014.29
   Jin Li, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1247, DOI 10.1109/ICOSP.2008.4697357
   Kadu S, 2016, 2016 IEEE STUDENTS' CONFERENCE ON ELECTRICAL, ELECTRONICS AND COMPUTER SCIENCE (SCEECS)
   Ke Z., 2022, 2022 IEEE INT C E BU, P80
   Kejariwal A, 2005, EMB SYST REAL TIME M, P33
   Kunhu Alavi, 2016, 2016 ONL INT C GREEN, P1
   Li C, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8848553
   Li JH, 2022, IEEE INT WORKSH MULT, DOI 10.1109/MMSP55362.2022.9948875
   Mishra A., 2018, 2018 INT JOINT C NEU, P1, DOI [10.1109/IJCNN.2018.8489305, DOI 10.1109/IJCNN.2018.8489305]
   Mohammed GN, 2012, INT CONF ADV COMPUT, P324, DOI 10.1109/ACSAT.2012.90
   Munir R, 2019, PROCEEDINGS OF THE 2019 4TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (INCIT), P32, DOI [10.1109/incit.2019.8912074, 10.1109/INCIT.2019.8912074]
   Nayak AA, 2014, Int Journal of Engineering Research and Applications., V4
   Panyavaraporn J, 2018, INT CONF KNOWL SMART, P154, DOI 10.1109/KST.2018.8426150
   Pinto VM, 2014, P 2 INT C ERCICA 14
   Sathya SP, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P45, DOI 10.1109/ICICCT.2017.7975156
   Sharma C, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5536170
   Shrivastava G, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3773
   Shuai Hao, 2012, 2012 First International Workshop on Green and Sustainable Software (GREENS), P1, DOI 10.1109/GREENS.2012.6224263
   Sun J, 2021, TSINGHUA SCI TECHNOL, V26, P154, DOI 10.26599/TST.2019.9010050
   Sun YF, 2021, OPTIK, V227, DOI 10.1016/j.ijleo.2020.165911
   Venugopala PS, 2017, SUSTAIN COMPUT-INFOR, V15, P82, DOI 10.1016/j.suscom.2017.06.003
   Venugopala P. S., 2016, 2016 International Conference on Signal Processing, Communication, Power and Embedded System (SCOPES), P578, DOI 10.1109/SCOPES.2016.7955505
   Venugopala PS, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P3554
   Venugopala PS, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P259, DOI 10.1109/ICSIP.2014.47
   Wang Yifei, 2022, 2022 International Conference on Culture-Oriented Science and Technology (CoST), P36, DOI 10.1109/CoST57098.2022.00017
   Yamada T, 2015, 2015 IIAI 4TH INTERNATIONAL CONGRESS ON ADVANCED APPLIED INFORMATICS (IIAI-AAI), P225, DOI 10.1109/IIAI-AAI.2015.164
   Yonggang Fu, 2009, Proceedings of the 2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2009), P437, DOI 10.1109/FSKD.2009.19
   Yu XY, 2019, IEEE ACCESS, V7, P115708, DOI 10.1109/ACCESS.2019.2936134
   Zhang Y, 2019, IEEE INT CONF ELECTR, P41, DOI [10.1109/ICEIEC.2019.8784574, 10.1109/iceiec.2019.8784574]
   Zhou ZL, 2019, IEEE ACCESS, V7, P100658, DOI 10.1109/ACCESS.2019.2930173
NR 48
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 31
PY 2023
DI 10.1007/s11042-023-17386-3
EA OCT 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XH9
UT WOS:001090305500002
DA 2024-07-18
ER

PT J
AU Arzehgar, A
   Davarinia, F
   Khalilzadeh, MM
AF Arzehgar, Afrooz
   Davarinia, Fatemeh
   Khalilzadeh, Mohammad Mahdi
TI Brain tissue magnetic resonance imaging segmentation using anisotropic
   textural features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE MRI segmentation; Curvelet transform; Feature selection; Support vector
   machine; Fuzzy C-means
ID DISCRETE CURVELET TRANSFORM; WAVELET TRANSFORM; MRI; CLASSIFICATION;
   IMAGES; ALGORITHMS; SEQUENCES
AB One of the most useful diagnostic tests for brain diseases is magnetic resonance imaging (MRI). It is a demanding task to segment brain tissue into cerebrospinal fluid (CSF), gray matter (GM), and white matter (WM) for early diagnosis of brain diseases and their causes based on MRI images. This study proposed a novel CSF, GM, and WM segmentation method employing just one modality (FLAIR image). The proposed segmentation is based on an anisotropic textural analysis of brain MRIs. For this purpose, the gray level co-occurrence matrix (GLCM) and curvelet transform were combined. The curvelet transform is an anisotropic multi-resolution method that was fully exploited for brain tissue segmentation. In addition to the information richness of GLCM features, the Relief method was utilized to achieve the best feature subset. Finally, support vector machine (SVM) and fuzzy C-means (FCM) were applied to recognize each pixel's label. FCM provided better segmentation results for CSF, GM, and WM with more selected features than SVM. Furthermore, FCM could track the area changes of scan sequences more accurately than SVM. Our segmentation framework involves analyzing an anisotropic curvelet of the statistical features, feature selection, clustering, and a classification-based method for segmentation. The proposed method outperforms well compared to other methods implemented on the MRBrainS18 challenge dataset. This study's outcomes can automatically detect the area of the brain tissue for all scans and capture the variations, reducing the specialist's burden of evaluating each scan and improving the performance.
C1 [Arzehgar, Afrooz] Mashhad Univ Med Sci, Sch Med, Med Informat Dept, Mashhad, Iran.
   [Davarinia, Fatemeh] Semnan Univ, Biomed Engn Dept, Semnan, Iran.
   [Khalilzadeh, Mohammad Mahdi] Islamic Azad Univ, Mashhad Branch, Biomed Engn Dept, Mashhad, Iran.
C3 Mashhad University Medical Science; Semnan University; Islamic Azad
   University
RP Davarinia, F (corresponding author), Semnan Univ, Biomed Engn Dept, Semnan, Iran.
EM arzegara4011@mums.ac.ir; f_davarinia@semnan.ac.ir;
   mmkhalilzadeh@mshdiau.ac.ir
OI Davarinia, Fatemeh/0000-0002-6864-4756; Arzehgar,
   Afrooz/0000-0003-0459-3395
CR Aghdasi N, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.3.034501
   [Anonymous], 2012, Int Sch Res Notices
   Avuçlu E, 2022, MEASUREMENT, V201, DOI 10.1016/j.measurement.2022.111702
   Azad R, 2017, KOREAN J RADIOL, V18, P973, DOI 10.3348/kjr.2017.18.6.973
   Bai XZ, 2019, IEEE J BIOMED HEALTH, V23, P2039, DOI 10.1109/JBHI.2018.2884208
   Bai XZ, 2019, IEEE T CYBERNETICS, V49, P2618, DOI 10.1109/TCYB.2018.2830977
   Bal A, 2019, MED BIOL ENG COMPUT, V57, P2567, DOI 10.1007/s11517-019-02014-w
   Baur C, 2021, MED IMAGE ANAL, V69, DOI 10.1016/j.media.2020.101952
   Beqiri A, 2018, MAGN RESON MED, V80, P1533, DOI 10.1002/mrm.27149
   Biratu ES, 2021, J IMAGING, V7, DOI 10.3390/jimaging7020022
   Biswas S, 2020, J KING SAUD UNIV-COM, V32, P718, DOI 10.1016/j.jksuci.2017.10.010
   Bommert A, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab354
   Borys D, 2021, FRONT NEUROINFORM, V15, DOI 10.3389/fninf.2021.684759
   Cabezas M, 2011, Comput Methods Prog Biomed, V104, P158
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chang HB, 2017, IEEE T MED IMAGING, V36, P721, DOI 10.1109/TMI.2016.2636026
   Chang-Chien SJ, 2021, SOFT COMPUT, V25, P1699, DOI 10.1007/s00500-020-04924-6
   Choi JY, 2023, CEREB CORTEX, V33, P3562, DOI 10.1093/cercor/bhac292
   Cole JH, 2018, BRAIN, V141, P822, DOI 10.1093/brain/awx354
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628
   Davis TS, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0234881
   Deng Y, 2019, IEEE ACCESS, V7, P107096, DOI 10.1109/ACCESS.2019.2917932
   Despotovic I, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/450341
   Dinsdale NK, 2021, NEUROIMAGE, V224, DOI 10.1016/j.neuroimage.2020.117401
   Dora Lingraj, 2017, IEEE Rev Biomed Eng, V10, P235, DOI 10.1109/RBME.2017.2715350
   Dorent R, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101862
   El-kenawy ESM, 2020, IEEE ACCESS, V8, P179317, DOI 10.1109/ACCESS.2020.3028012
   Esmaeili M, 2020, BIOMED OPT EXPRESS, V11, P586, DOI 10.1364/BOE.377021
   Fang F, 2021, IEEE J Biomed Health Inform, V26
   Faria AV, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00578
   Feng Y, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23111429
   Francis SV, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0023-3
   Gefen S, 2008, IEEE T BIO-MED ENG, V55, P147, DOI 10.1109/TBME.2007.899361
   Ghosal P, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105841
   Ghribi O, 2018, BIOMED SIGNAL PROCES, V40, P473, DOI 10.1016/j.bspc.2017.07.008
   Giedd JN, 1999, NAT NEUROSCI, V2, P861, DOI 10.1038/13158
   González-Villà S, 2019, NEUROIMAGE-CLIN, V22, DOI 10.1016/j.nicl.2019.101709
   Goodkind M, 2015, JAMA PSYCHIAT, V72, P305, DOI 10.1001/jamapsychiatry.2014.2206
   Gozzi N, 2022, KNOWL-BASED SYST, V240, DOI 10.1016/j.knosys.2021.108053
   Halder A, 2019, MAGN RESON IMAGING, V62, P129, DOI 10.1016/j.mri.2019.06.010
   Himanshi, 2016, ADV INTELL SYST, V379, P1, DOI 10.1007/978-81-322-2517-1_1
   HosseiniPanah S, 2019, J Biomed Phys Eng, V9, P699, DOI 10.31661/jbpe.v0i0.986
   Hu MD, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.714318
   Huang A, 2009, IEEE T BIO-MED ENG, V56, P1838, DOI 10.1109/TBME.2009.2017509
   Huang H, 2019, IEEE ACCESS, V7, P12386, DOI 10.1109/ACCESS.2019.2893063
   Hussein AF, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21072311
   Ji Y, 2013, PATTERN RECOGN, V46, P914, DOI 10.1016/j.patcog.2012.08.010
   Jia JH, 2013, MATH COMPUT MODEL, V58, P619, DOI 10.1016/j.mcm.2011.10.045
   Jin T, 2021, AM J NEURORADIOL, V42, P457, DOI 10.3174/ajnr.A6931
   John JP, 2015, J NEGAT RESULTS BIOM, V14, DOI 10.1186/s12952-015-0030-z
   Kanagaraj K, 2022, J KING SAUD UNIV-COM, V34, P375, DOI 10.1016/j.jksuci.2018.11.006
   Kaur S, 2016, COMPUT MED IMAG GRAP, V49, P46, DOI 10.1016/j.compmedimag.2016.01.002
   Kavitha MS, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1190-z
   Kaya IE, 2017, COMPUT METH PROG BIO, V140, P19, DOI 10.1016/j.cmpb.2016.11.011
   Khan MA, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11122208
   Kilsdonk ID, 2014, EUR RADIOL, V24, P841, DOI 10.1007/s00330-013-3080-y
   Krishnammal PM, 2020, MULTIMED TOOLS APPL, V79, P10099, DOI 10.1007/s11042-019-08089-9
   Le TT, 2019, BIOINFORMATICS, V35, P1358, DOI 10.1093/bioinformatics/bty788
   Li F, 2022, INT J PROD RES, V60, P6303, DOI 10.1080/00207543.2021.1991021
   Li H., 2020, Medical image computing and computer assisted intervention, P227
   Liu YM, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00198
   Liu ZP, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144834
   López NC, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph182010670
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Martins SB, 2020, COMPUT MED IMAG GRAP, V85, DOI [10.1016/j.compmedimag.2020.101770, 10.1016.j.compmedimag.2020.101770]
   Mendes SL, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/5550914
   Nayak DR, 2019, COMPUT MED IMAG GRAP, V77, DOI 10.1016/j.compmedimag.2019.101656
   Nayak DR, 2017, EXPERT SYST APPL, V88, P152, DOI 10.1016/j.eswa.2017.06.038
   Nayak DR, 2017, CNS NEUROL DISORD-DR, V16, P137, DOI 10.2174/1871527315666161024142036
   Oulhaj H, 2017, IEEE T MED IMAGING, V36, P2077, DOI 10.1109/TMI.2017.2708988
   Papadomanolakis TN, 2023, BRAIN SCI, V13, DOI 10.3390/brainsci13020348
   Pilli R, 2023, ENG APPL ARTIF INTEL, V125, DOI 10.1016/j.engappai.2023.106596
   Polak M, 2009, IMAGE VISION COMPUT, V27, P1223, DOI 10.1016/j.imavis.2008.09.008
   Qian WB, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106167
   Raichle ME, 2006, ANNU REV NEUROSCI, V29, P449, DOI 10.1146/annurev.neuro.29.051605.112819
   Ramamurthy K., 2019, Int J Innov Technol Explor Eng, V8, P201
   Ranjbarzadeh R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90428-8
   Rao AT, 2023, J NEURAL ENG, V20, DOI 10.1088/1741-2552/acbb2b
   Remeseiro B, 2019, COMPUT BIOL MED, V112, DOI 10.1016/j.compbiomed.2019.103375
   Riana D, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e07417
   Riddle K, 2017, BRAIN IMAGING BEHAV, V11, P541, DOI 10.1007/s11682-016-9534-5
   Roozpeykar S, 2022, AM J NUCL MED MOLEC, V12, P63
   Rostami M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00398-3
   Rostami M, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00352-3
   Rout R, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13112085
   Ségonne F, 2004, NEUROIMAGE, V22, P1060, DOI 10.1016/j.neuroimage.2004.03.032
   Shanmuganathan M, 2020, IET SIGNAL PROCESS, V14, P333, DOI 10.1049/iet-spr.2019.0543
   Shinde AA, 2017, INT J MULTIMED INF R, V6, P281, DOI 10.1007/s13735-017-0132-0
   Singh Mahender Kumar, 2021, Ann Neurosci, V28, P82, DOI 10.1177/0972753121990175
   Song JH, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23091196
   Srivastava D, 2020, NEURAL COMPUT APPL, V32, P10819, DOI 10.1007/s00521-018-3611-1
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Starck JL., 2010, SPARSE IMAGE SIGNAL
   Sun Liang, 2019, Chinese Medical Sciences Journal, V34, P110, DOI 10.24920/003576
   Sun QX, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/7467261
   Thakral S, 2019, COMM COM INF SC, V955, P499, DOI 10.1007/978-981-13-3140-4_45
   Turesky TK, 2021, DEV COGN NEUROS-NETH, V47, DOI 10.1016/j.dcn.2020.100893
   Upadhyay K, 2020, IET IMAGE PROCESS, V14, P2616, DOI 10.1049/iet-ipr.2019.0969
   Urbanowicz RJ, 2018, J BIOMED INFORM, V85, P168, DOI 10.1016/j.jbi.2018.07.015
   Urbanowicz RJ, 2018, J BIOMED INFORM, V85, P189, DOI 10.1016/j.jbi.2018.07.014
   Villanueva-Meyer JE, 2017, NEUROSURGERY, V81, P397, DOI 10.1093/neuros/nyx103
   Wang HL, 2019, MED BIOL ENG COMPUT, V57, P2145, DOI 10.1007/s11517-019-02017-7
   Ward PGD, 2018, NEUROIMAGE, V165, P294, DOI 10.1016/j.neuroimage.2017.10.049
   Weiss DA, 2021, NEUROIMAGE-CLIN, V31, DOI 10.1016/j.nicl.2021.102769
   Xu XY, 2022, J NEUROSCI, V42, P9435, DOI 10.1523/JNEUROSCI.1285-22.2022
   You Q, 2022, IEEE T MED IMAGING, V41, P2385, DOI 10.1109/TMI.2022.3162839
   Yousaf T, 2018, INT REV NEUROBIOL, V141, P31, DOI 10.1016/bs.irn.2018.08.008
   Zhang JN, 2020, BRAIN IMAGING BEHAV, V14, P2333, DOI 10.1007/s11682-019-00186-5
   Zhang YJ, 2001, ISSPA 2001: SIXTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOLS 1 AND 2, PROCEEDINGS, P148, DOI 10.1109/ISSPA.2001.949797
   Zhao JT, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00144
   Zhao Y, 2023, Complex Intell Syst, P1
   Zhu HC, 2020, NEUROINFORMATICS, V18, P319, DOI 10.1007/s12021-019-09448-5
   Zulfira FZ, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104951
NR 115
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 28
PY 2023
DI 10.1007/s11042-023-17259-9
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W7FP7
UT WOS:001093249700009
DA 2024-07-18
ER

PT J
AU Mandia, S
   Mitharwal, R
   Singh, K
AF Mandia, Sandeep
   Mitharwal, Rajendra
   Singh, Kuldeep
TI Automatic student engagement measurement using machine learning
   techniques: A literature study of data and methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Student engagement; Machine Learning; Deep Learning; E-learning;
   Classroom Learning
ID CLASSROOM; RECOGNITION; FACES
AB Student engagement is positively related to learning outcomes. The student engagement measurement is studied in varied settings, from the traditional classroom to online learning. Artificial intelligence and machine learning advancements have fueled automatic student engagement analysis. The automated student engagement measurement employed several sensor data such as audio, video, and physiological signals in different settings. This paper presents a literature review of automatic student engagement measurement in the classroom and online learning settings, including data collection and annotation techniques, methods, and evaluation metrics. First, a generalized methodology for automatic student engagement analysis is discussed. Then we describe various data collection techniques and annotation methods widely used in the literature and detail the limitations and advantages. The state-of-the-art machine learning methods and the evaluation metrics used to test those methods are reviewed. Additionally, we extend our literature review to the insight into the existing datasets for evaluating the automatic student engagement methods and recent developments in the machine learning methods on open-source datasets. Finally, we present a comprehensive comparison of the methods proposed on various public datasets based on evaluation metrics and engagement types.
C1 [Mandia, Sandeep; Mitharwal, Rajendra; Singh, Kuldeep] Malaviya Natl Inst Technol Jaipur, Dept Elect & Commun Engn, Jaipur, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Singh, K (corresponding author), Malaviya Natl Inst Technol Jaipur, Dept Elect & Commun Engn, Jaipur, Rajasthan, India.
EM kuldeep.ece@mnit.ac.in
RI Mandia, Sandeep/KVX-9906-2024
OI Mandia, Sandeep/0000-0001-6362-4185
CR Abtahi Shabnam, 2020, IEEE DataPort
   Aluja-Banet T, 2019, J COMPUT SCI-NETH, V36, DOI 10.1016/j.jocs.2017.03.007
   [Anonymous], 2014, P EMNLP 2014 WORKSH
   Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676
   Ashwin TS, 2020, FUTURE GENER COMP SY, V108, P334, DOI 10.1016/j.future.2020.02.075
   Ashwin TS, 2019, IEEE ACCESS, V7, P150693, DOI 10.1109/ACCESS.2019.2947519
   Ashwin TS, 2018, IEEE INT CONF ADV LE, P436, DOI 10.1109/ICALT.2018.00110
   Ashwin TS, 2015, IEEE CONF TECHNOL ED, P23, DOI 10.1109/T4E.2015.21
   Aslan S, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P545, DOI 10.1109/ICMLA.2014.111
   Balaam M, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1623
   Bian CL, 2019, IET COMPUT VIS, V13, P329, DOI 10.1049/iet-cvi.2018.5281
   Bin Zhu, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P841, DOI 10.1145/3382507.3417965
   Booth BM, 2017, INT CONF AFFECT, P470, DOI 10.1109/ACII.2017.8273641
   Bosch N, 2021, IEEE T AFFECT COMPUT, V12, P974, DOI 10.1109/TAFFC.2019.2908837
   Bosch N, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2946837
   Botelho AF, 2019, IEEE T LEARN TECHNOL, V12, P158, DOI 10.1109/TLT.2019.2912162
   Buono P, 2023, MULTIMED TOOLS APPL, V82, P12859, DOI 10.1007/s11042-022-14048-8
   Chen YP, 2022, PROC CVPR IEEE, P5260, DOI 10.1109/CVPR52688.2022.00520
   Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   D'Mello S, 2007, IEEE INTELL SYST, V22, P53, DOI 10.1109/MIS.2007.79
   Damiano R, 2021, MULTIMED TOOLS APPL, V80, P6711, DOI 10.1007/s11042-020-10007-3
   Deeva G, 2022, IEEE T LEARN TECHNOL, V15, P720, DOI 10.1109/TLT.2022.3215598
   Delgado K, 2021, IEEE INT CONF COMP V, P3621, DOI 10.1109/ICCVW54120.2021.00405
   Dewan MAA, 2019, SMART LEARN ENVIRON, V6, DOI 10.1186/s40561-018-0080-z
   Dewan MAA, 2018, 2018 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI), P1895, DOI 10.1109/SmartWorld.2018.00318
   Dhall Abhinav, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P784, DOI 10.1145/3382507.3417973
   DMello S, 2004, AFFECTIVE INTERACTIO, P7, DOI DOI 10.1158/0008-5472.CAN-06-1527
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Dridi N, 2019, IEEE SIGNAL PROC LET, V26, P302, DOI 10.1109/LSP.2018.2886933
   Dyment J, 2020, HIGH EDUC RES DEV, V39, P1440, DOI 10.1080/07294360.2020.1732879
   Farhan M, 2018, MULTIMED TOOLS APPL, V77, P4909, DOI 10.1007/s11042-016-4212-6
   Fox A, 2013, COMMUN ACM, V56, P38, DOI 10.1145/2535918
   Fredricks JA, 2004, REV EDUC RES, V74, P59, DOI 10.3102/00346543074001059
   Fujii K, 2018, ACM INT CONF PR SER, DOI 10.1145/3174910.3174927
   Fwa H.L., 2018, GSTF J COMPUTING JOC, V6, P1, DOI [10.5176/2251-3043_6.1.114, DOI 10.5176/2251-3043_6.1.114]
   Geng L, 2019, 2019 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2019), P442, DOI [10.1109/ssci44817.2019.9002713, 10.1109/SSCI44817.2019.9002713]
   Gupta A, 2022, Arxiv, DOI arXiv:1609.01885
   Gupta SK, 2019, MULTIMED TOOLS APPL, V78, P25321, DOI 10.1007/s11042-019-7651-z
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Halabi O, 2020, MULTIMED TOOLS APPL, V79, P2987, DOI 10.1007/s11042-019-08214-8
   Hamid SSA, 2018, ADV INTELL SYST, V700, P372, DOI 10.1007/978-3-319-72550-5_36
   Hew KF, 2018, INT REV RES OPEN DIS, V19, P69
   Hiver P., 2021, Student engagement in the language classroom
   Huang T, 2019, IEEE INT CONF ELECTR, P338, DOI [10.1109/ICEIEC.2019.8784559, 10.1109/iceiec.2019.8784559]
   Jianming Wu, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P777, DOI 10.1145/3382507.3417959
   Joshi A, 2019, IEEE INT CONF AUTOMA, P1, DOI [10.1109/FG.2019.8756624, DOI 10.1109/fg.2019.8756624]
   Kamath A, 2016, IEEE WINT CONF APPL
   Kaur A., 2018, 2018 DIGITAL IMAGE C, P1, DOI DOI 10.1109/DICTA.2018.8615851
   Khedher AB., 2019, J. Intell. Learn. Syst. Appl., V11, P1, DOI [10.4236/jilsa.2019.111001, DOI 10.4236/JILSA.2019.111001]
   Kim Y, 2018, IEEE ACCESS, V6, P5308, DOI 10.1109/ACCESS.2018.2791861
   Klein R, 2017, IEEE IMAGE PROC, P2856, DOI 10.1109/ICIP.2017.8296804
   Kumar V, 2022, MULTIMED TOOLS APPL, V81, P40775, DOI 10.1007/s11042-022-12898-w
   Lee H, 2021, MULTIMED TOOLS APPL, V80, P31239, DOI 10.1007/s11042-020-10267-z
   Liao JC, 2021, APPL INTELL, V51, P6609, DOI 10.1007/s10489-020-02139-8
   Liu M, 2015, IEEE T LEARN TECHNOL, V8, P215, DOI 10.1109/TLT.2014.2378786
   Liu YY, 2018, MULTIMED TOOLS APPL, V77, P28749, DOI 10.1007/s11042-018-6017-2
   Mehta NK, 2022, APPL INTELL, V52, P13803, DOI 10.1007/s10489-022-03200-4
   Monkaresi H, 2017, IEEE T AFFECT COMPUT, V8, P15, DOI 10.1109/TAFFC.2016.2515084
   Moubayed A, 2020, AM J DISTANCE EDUC, V34, P137, DOI 10.1080/08923647.2020.1696140
   Murshed M, 2019, IEEE 17TH INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP / IEEE 17TH INT CONF ON PERVAS INTELLIGENCE AND COMP / IEEE 5TH INT CONF ON CLOUD AND BIG DATA COMP / IEEE 4TH CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/CBDCOM/CYBERSCITECH), P80, DOI 10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00028
   Nezami OM, 2020, LECT NOTES ARTIF INT, V11908, P273, DOI 10.1007/978-3-030-46133-1_17
   Pabba C, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12839
   Hidalgo FJP, 2020, TECHNOL KNOWL LEARN, V25, P853, DOI 10.1007/s10758-019-09433-6
   Pattanasri N, 2012, IEEE T LEARN TECHNOL, V5, P52, DOI 10.1109/TLT.2011.22
   Ruiz Nataniel, 2023, IEEE Transactions on Biometrics, Behavior, and Identity Science, P411, DOI 10.1109/TBIOM.2022.3210479
   Ruiz-Palmero J, 2020, INT J EDUC TECHNOL H, V17, DOI 10.1186/s41239-020-00206-1
   Sathayanarayana S., 2014, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, P474
   Savchenko AV, 2022, IEEE T AFFECT COMPUT, V13, P2132, DOI 10.1109/TAFFC.2022.3188390
   Singh A, 2013, IEEE POTENTIALS, V32, P13, DOI 10.1109/MPOT.2012.2189443
   SKINNER EA, 1993, J EDUC PSYCHOL, V85, P571, DOI 10.1037/0022-0663.85.4.571
   Sumer O, 2023, IEEE T AFFECT COMPUT, V14, P1012, DOI 10.1109/TAFFC.2021.3127692
   Thomas C, 2017, P 1 ACM SIGCHI INT W, P33, DOI DOI 10.1145/3139513.3139514
   Tiam-Lee TJ, 2019, LECT NOTES COMPUT SC, V11528, P24, DOI 10.1007/978-3-030-22244-4_4
   Valdez MG., 2017, IJCCI, P297
   Wang YH, 2020, 2020 7TH IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (CSCLOUD 2020)/2020 6TH IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING AND SCALABLE CLOUD (EDGECOM 2020), P270, DOI 10.1109/CSCloud-EdgeCom49738.2020.00054
   Whitehill J, 2014, IEEE T AFFECT COMPUT, V5, P86, DOI 10.1109/TAFFC.2014.2316163
   Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085
   Yan S, 2022, PROC CVPR IEEE, P3323, DOI 10.1109/CVPR52688.2022.00333
   Yun WH, 2020, IEEE T AFFECT COMPUT, V11, P696, DOI 10.1109/TAFFC.2018.2834350
   Zaletelj J, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0228-8
   Zhalehpour S, 2017, IEEE T AFFECT COMPUT, V8, P300, DOI 10.1109/TAFFC.2016.2553038
   Zhang H, 2019, IEEE INT CONF ELECTR, P342, DOI [10.1109/iceiec.2019.8784507, 10.1109/ICEIEC.2019.8784507]
NR 82
TC 0
Z9 0
U1 10
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 28
PY 2023
DI 10.1007/s11042-023-17534-9
EA OCT 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W7FP7
UT WOS:001093249700008
DA 2024-07-18
ER

PT J
AU Agarwal, S
   Jung, KH
AF Agarwal, Saurabh
   Jung, Ki-Hyun
TI Image operator forensics and sequence estimation using robust deep
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image forgery detection; Image operator sequence; Convolutional neural
   network; Image filtering; Image forensics
AB Digital images can be manipulated with recent tools. Image forensics examines the image from several angles to spot any anomalies. Most techniques are applicable to detect a single operation on the image. In actual practice, fake photos are manipulated with multiple operations and compression algorithms. A convolutional neural network with a reasonable size is designed to detect operators and the respective sequences for two operators in particular. The bottleneck strategy is incorporated to optimize the network training cost and a high-depth network. The detection of a particular operator depends on inherent statistical information. A single global average pooling layer preserves the statistical information in a convolutional neural network. The strength of existing detection techniques is also reduced in low-resolution and high-compression environments. The proposed method performs better than existing techniques on compressed small-size images even though forensic is difficult in small-size and compressed images due to inadequate statistical traces. The proposed convolutional neural network also applies to detect operators with unknown specifications and compression not used in training.
C1 [Agarwal, Saurabh] Amity Univ Uttar Pradesh, Amity Sch Engn & Technol, Noida, India.
   [Agarwal, Saurabh; Jung, Ki-Hyun] Andong Natl Univ, Dept Software Convergence, Gyeongbuk 36729, South Korea.
C3 Amity University Noida; Andong National University
RP Jung, KH (corresponding author), Andong Natl Univ, Dept Software Convergence, Gyeongbuk 36729, South Korea.
EM saurabhnsit2510@gmail.com; khanny.jung@gmail.com
OI Jung, Ki-Hyun/0000-0002-0662-8355
FU This research was supported by Brain Pool program funded by the Ministry
   of Science and ICT through the National Research Foundation of Korea
   (2019H1D3A1A01101687) and Basic Science Research Program through the
   National Research Foundation of Korea (NRF) f [2019H1D3A1A01101687];
   Brain Pool program - Ministry of Science and ICT through the National
   Research Foundation of Korea [2021R1I1A3049788]; Basic Science Research
   Program through the National Research Foundation of Korea (NRF) -
   Ministry of Education
FX This research was supported by Brain Pool program funded by the Ministry
   of Science and ICT through the National Research Foundation of Korea
   (2019H1D3A1A01101687) and Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (2021R1I1A3049788).
CR Abdulrahman H., 2016, 4THACM WORKSHOP INF, P109
   Agarwal S, 2022, MULTIMED TOOLS APPL, V81, P7047, DOI 10.1007/s11042-022-11945-w
   Barni M, 2018, IEEE IMAGE PROC, P3803, DOI 10.1109/ICIP.2018.8451698
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bayar B, 2018, Electron Imaging, V2018, DOI 10.2352/
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Boroumand M, 2018, Electron. Imag., V30, DOI 10.2352/
   Chen JX, 2023, IEEE T CIRC SYST VID, V33, P935, DOI 10.1109/TCSVT.2022.3204753
   Chen JX, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116287
   Chen YF, 2019, J REAL-TIME IMAGE PR, V16, P725, DOI 10.1007/s11554-019-00866-x
   Cheng XC, 2022, J SUPERCOMPUT, V78, P17114, DOI 10.1007/s11227-022-04561-w
   Chu XY, 2016, IEEE T INF FOREN SEC, V11, P823, DOI 10.1109/TIFS.2015.2510958
   Comesaña P, 2012, IEEE INT WORKS INFOR, P211, DOI 10.1109/WIFS.2012.6412651
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Li HD, 2018, IEEE T CIRC SYST VID, V28, P31, DOI 10.1109/TCSVT.2016.2599849
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Liu QZ, 2015, ACM T INTEL SYST TEC, V5, DOI 10.1145/2560365
   Mazumdar A, 2018, Arxiv, DOI arXiv:1808.06323
   Mazumdar A, 2019, LECT NOTES COMPUT SC, V11941, P226, DOI 10.1007/978-3-030-34869-4_25
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Peng L, 2021, MULTIMEDIA SYST, V27, P363, DOI 10.1007/s00530-020-00697-y
   Qiu X., 2014, P 2 ACM WORKSH INF H, P165, DOI DOI 10.1145/2600918.2600941
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Sharma N, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.4.041210
   Shi Yun Q., 2013, Information Hiding. 14th International Conference, IH 2012 Revised Selected Papers, P63, DOI 10.1007/978-3-642-36373-3_5
   Singhal D, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3388634
   Stamm MC, 2013, IEEE INT WORKS INFOR, P162, DOI 10.1109/WIFS.2013.6707812
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Xu GS, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P67, DOI 10.1145/3082031.3083236
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Xue HW, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102910
   Yang PP, 2020, J IMAGING, V6, DOI 10.3390/jimaging6030009
   Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092, DOI 10.1109/ICASSP.2018.8461438
NR 36
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-17389-0
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300004
DA 2024-07-18
ER

PT J
AU Yadav, P
   Gera, J
   Kaur, H
AF Yadav, Pratibha
   Gera, Jaya
   Kaur, Harmeet
TI Enhancing the accuracy of collaborative filtering based recommender
   system with novel similarity measure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recommender system; Collaborative filtering; Similarity measure;
   Proximity-impact-popularity
AB One of the most effective and extensively used recommendation technique is collaborative filtering. Based on related users or items, collaborative filtering creates recommendations for the users. Similarity measures play a crucial role in Collaborative Filtering Recommender System. One useful similarity measure for a cold-start situation is the Proximity-Impact-Popularity (PIP) measure. The PIP measure is, nevertheless, subject to several limitations as it penalises users' multiple times throughout similarity computation in addition to ignoring their global rating behaviour. When a user rates the items, their overall rating behavior-whether they are lenient or strict-is referred to as global rating behaviour. In this study, we introduce an improved similarity metric to calculate similarity more accurately and generate high-quality recommendations. Our method takes into account both the user's rating behaviour and the percentage of co-rated items among users. Additionally, we have considered the computation complexity of the suggested work. In addition, to exhibit the performance of the proposed measure, empirical analysis has been done on real datasets. The results of the experiments performed on the dataset show that the suggested work takes precedence over the current similarity metrics. In comparison to state-of-the-art measurements, the suggested work exhibits improvements in MAE of 1.73%, RMSE of 4.01%, and F measure of 1.47% on an average.
C1 [Yadav, Pratibha; Gera, Jaya] Univ Delhi, Shyama Prasad Mukherji Coll Women, Delhi 110026, India.
   [Kaur, Harmeet] Univ Delhi, Hansraj Coll, Delhi 110007, India.
C3 University of Delhi; University of Delhi
RP Gera, J (corresponding author), Univ Delhi, Shyama Prasad Mukherji Coll Women, Delhi 110026, India.
EM pratibha.123@spm.du.ac.in; jayagera@spm.du.ac.in; hkaur@hrc.du.ac.in
RI Yadav, Pratibha/JRY-2907-2023
OI Yadav, Pratibha/0000-0003-0526-1624; Gera, Jaya/0000-0001-5422-4075
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Aggarwal C. C., 2016, Recommender Systems, P71
   Ahn HJ, 2008, INFORM SCIENCES, V178, P37, DOI 10.1016/j.ins.2007.07.024
   Ayub M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0220129
   Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124
   Bedi P, 2006, INFOCOMP J Comput Sci, V5, P19
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Bobadilla J, 2010, KNOWL-BASED SYST, V23, P520, DOI 10.1016/j.knosys.2010.03.009
   Çano E, 2017, INTELL DATA ANAL, V21, P1487, DOI 10.3233/IDA-163209
   Chang TM., 2014, J Inf Sci Eng, DOI [10.6688/JISE.2014.30.2.7, DOI 10.6688/JISE.2014.30.2.7]
   Chien YH, 1999, Direct
   Forouzandeh S, 2022, FUZZY INF ENG, V14, P26, DOI 10.1080/16168658.2021.2019430
   Forouzandeh S, 2020, COMPUT SCI ENG, V22, P62, DOI 10.1109/MCSE.2018.2875321
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Iftikhar A, 2020, IEEE ACCESS, V8, P123841, DOI 10.1109/ACCESS.2020.3005953
   Jain Gourav, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2018. Advances in Intelligent Systems and Computing (AISC 1053), P343, DOI 10.1007/978-981-15-0751-9_32
   Jamali M, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P397
   Javed U, 2021, INT J EMERG TECHNOL, V16, P274, DOI 10.3991/ijet.v16i03.18851
   Jeong B, 2010, INFORM SCIENCES, V180, P602, DOI 10.1016/j.ins.2009.10.016
   Liang SP, 2015, INT J INNOV COMPUT I, V11, P1629
   Lima GR, 2020, INFORM SCIENCES, V513, P412, DOI 10.1016/j.ins.2019.10.041
   Liu HF, 2014, KNOWL-BASED SYST, V56, P156, DOI 10.1016/j.knosys.2013.11.006
   Pennock DM, 2013, Arxiv, DOI arXiv:1301.3885
   Manochandar S, 2021, APPL INTELL, V51, P586, DOI 10.1007/s10489-020-01811-3
   Nasiri E, 2023, MULTIMED TOOLS APPL, V82, P3745, DOI 10.1007/s11042-022-12943-8
   Ni JJ, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11209554
   Paradarami TK, 2017, EXPERT SYST APPL, V83, P300, DOI 10.1016/j.eswa.2017.04.046
   Patra BK, 2015, KNOWL-BASED SYST, V82, P163, DOI 10.1016/j.knosys.2015.03.001
   Resnick P., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P175, DOI 10.1145/192844.192905
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Schafer J. B., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P291
   Shardanand U., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P210, DOI 10.1145/223904.223931
   Stephen SC, 2017, ACM INT C P F1296, DOI [10.1145/3092090.3092105, DOI 10.1145/3092090.3092105]
   Sun SB, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0183570
   Yadav P, 2017, INT J COMPUT SCI ENG, V15, P295, DOI 10.1504/IJCSE.2017.10008137
NR 36
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-17428-w
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300011
DA 2024-07-18
ER

PT J
AU Swaminathan, S
   Raajan, NR
AF Swaminathan, S.
   Raajan, N. R.
TI High-speed Optical OFDM transmission by reducing the nonlinearity of
   LEDs in Visible light Communication Systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Nonlinearity; Binary Data; Transmitter Side; Signal Detection;
   De-Mapping; I-Q Symbols
ID PAPR REDUCTION
AB The non-linearity of Light Emitting Diodes (LEDs) has limited the efficiency of visible Light Communication (VLC) in terms of Bit Error Rate (BER). In this report, we propose a model-driven Deep Learning (DL) strategy for Optical Orthogonal Frequency Division Multiplexing (O-OFDM)-based VLC processes, that is employed as the Auto Encoder (AE) network system to minimize the LED non-linearity. The suggested system successfully includes communication domain knowledge into the design of the training cost function and network architecture, as opposed to the conventional fully computer-controlled autoencoder. Deep Recurrent Neural Network (Deep RNN) and Inverse Fast Fourier Transform (IFFT) are used at the emitter end to convert the binary data first into challenging I-Q codes for each O- OFDM sub-band. Then, for nonlinearity compensation and signal detection at the receiver, the symbol de-mapping is done and the demodulation is performed through a Deep RNN. DeepRNN's hidden layers are fine-tuned using the MMRFA algorithm for enhanced performance and efficiency. The proposed methodology performance is compared with the existing methods using performance metrics like BER, MSE, ACF, Power consumption, and Energy efficiency. The proposed solution outperforms several current approaches in terms of BER performances and improves operating duration, demonstrating the practicality and promise of DL in the VLC platform.
C1 [Swaminathan, S.] SASTRA, Sch EEE, Dept ECE, SRC, Kumbakonam, Tamil Nadu, India.
   [Raajan, N. R.] SASTRA, Dept ECE, Thanjavur, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Swaminathan, S (corresponding author), SASTRA, Sch EEE, Dept ECE, SRC, Kumbakonam, Tamil Nadu, India.
EM swaminathans@src.sastra.edu
CR Ahmed F, 2021, OPT EXPRESS, V29, P33027, DOI 10.1364/OE.441650
   Al-Jawhar YA, 2021, ETRI J, V43, P209, DOI 10.4218/etrij.2019-0358
   Bakkas B, 2020, INFORMATION, V11, DOI 10.3390/info11040190
   Bian R, 2019, J LIGHTWAVE TECHNOL, V37, P2418, DOI 10.1109/JLT.2019.2906464
   Chagnon M, 2019, J LIGHTWAVE TECHNOL, V37, P1779, DOI 10.1109/JLT.2019.2901201
   Chaudhary NI, 2021, APPL MATH MODEL, V93, P412, DOI 10.1016/j.apm.2020.12.035
   Goel A, 2019, DIGIT SIGNAL PROCESS, V85, P113, DOI 10.1016/j.dsp.2018.11.002
   Hao LL, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9050852
   Hao LL, 2019, OPT COMMUN, V442, P110, DOI 10.1016/j.optcom.2019.03.013
   Hu QQ, 2018, J LIGHTWAVE TECHNOL, V36, P5488, DOI 10.1109/JLT.2018.2876042
   Ibrahim AA, 2019, NAT RADIO SCI CO, P92, DOI [10.1109/NRSC.2019.8734542, 10.1109/nrsc.2019.8734542]
   Khadr MH, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9050986
   Lain JK, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10080948
   Mardanikoram S, 2020, IEEE T COMMUN, V68, P1101, DOI 10.1109/TCOMM.2019.2953612
   Miao P, 2019, IEEE ACCESS, V7, P71436, DOI 10.1109/ACCESS.2019.2919983
   Miriyala G, 2021, OPTIK, V246, DOI 10.1016/j.ijleo.2021.167831
   Narsimha B, 2018, 2018 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P75, DOI 10.1109/RAICS.2018.8634904
   Wang C, 2018, 2018 AS COMM PHOT C, P1
   Wang HD, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183907
   Xing ZT, 2021, IEEE ACCESS, V9, P61565, DOI 10.1109/ACCESS.2021.3074009
   Zhang T, 2018, IEEE COMMUN LETT, V22, P1180, DOI 10.1109/LCOMM.2018.2827940
   Zhao TY, 2021, DIGIT SIGNAL PROCESS, V118, DOI 10.1016/j.dsp.2021.103230
   Zhou Z, 2019, IEEE ACCESS, V7, P131986, DOI 10.1109/ACCESS.2019.2941116
   Zhu ZY, 2021, OPT COMMUN, V488, DOI 10.1016/j.optcom.2021.126832
NR 24
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 26
PY 2023
DI 10.1007/s11042-023-17211-x
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2WU9
UT WOS:001090292500001
DA 2024-07-18
ER

PT J
AU Kapuriya, BR
   Pradhan, D
   Sharma, R
AF Kapuriya, B. R.
   Pradhan, Debasish
   Sharma, Reena
TI Detection of local motion blurred/non-blurred regions in an image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fourier transform (FT); Geodesic distance; Local blur angle estimator
   (LBAE); Point spread function (PSF); Laplacian of gaussian (LoG); Radon
   transform (RT)
ID BLIND; SEGMENTATION; RESTORATION
AB Motion blur of an image is a common phenomenon that occurs while taking a photograph due to the relative movement of the object and an image acquiring device. It is essential to detect this phenomenon of blurring of images in many applications such as information retrieval. This paper proposes a novel local blur detection technique, and it performs better than the existing works. This technique mainly uses Radon transform and Laplacian of Gaussian on the local neighborhood around each pixel to estimate blur information. Additionally, two new weight functions are introduced based on local geodesic distance and local variance. It is shown that these functions play a significant role in segregating blur and non-blurred parts. Simulation results validate the correctness and accuracy by testing the proposed algorithm on some challenging images with similar color information in the foreground and background. Various quantitative performance measures have determined the superiority of the proposed method.
C1 [Kapuriya, B. R.] Ctr Airborne Syst CABS, Bangalore 560037, India.
   [Pradhan, Debasish] Def Inst Adv Technol DIAT, Sch Comp Engn & Math Sci, Pune 411025, India.
   [Sharma, Reena] DRDO, Aeronaut Res & Dev Board ARDB, Delhi 110054, India.
C3 Defence Research & Development Organisation (DRDO); Centre for Air Borne
   Systems (CABS); Defence Research & Development Organisation (DRDO);
   Defence Institute of Advanced Technology (DIAT); Defence Research &
   Development Organisation (DRDO)
RP Pradhan, D (corresponding author), Def Inst Adv Technol DIAT, Sch Comp Engn & Math Sci, Pune 411025, India.
EM kapuriyabr@gmail.com; pradhandeb@gmail.com; reena@cabs.drdo.in
OI PRADHAN, DEBASISH/0000-0001-5343-4329
FU The authors would like to thank the Defence Institute of Advanced
   Technology, Pune, and Centre for Airborne Systems, Bangalore, for
   providing infrastructure for research work.; Defence Institute of
   Advanced Technology, Pune
FX The authors would like to thank the Defence Institute of Advanced
   Technology, Pune, and Centre for Airborne Systems, Bangalore, for
   providing infrastructure for research work.
CR Almeida MSC, 2013, IEEE T IMAGE PROCESS, V22, P2751, DOI 10.1109/TIP.2013.2257810
   Almeida MSC, 2010, IEEE T IMAGE PROCESS, V19, P36, DOI 10.1109/TIP.2009.2031231
   Bahrami K, 2013, IEEE INT CON MULTI
   Bini AA, 2014, VISUAL COMPUT, V30, P311, DOI 10.1007/s00371-013-0857-6
   Cai JF, 2012, IEEE T IMAGE PROCESS, V21, P562, DOI 10.1109/TIP.2011.2164413
   Cai JF, 2009, SIAM J IMAGING SCI, V2, P226, DOI 10.1137/080733371
   Chakrabarti A, 2010, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2010.5539954
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Cho TS, 2011, PROC CVPR IEEE, P241, DOI 10.1109/CVPR.2011.5995479
   Couzinié-Devy F, 2013, PROC CVPR IEEE, P1075, DOI 10.1109/CVPR.2013.143
   Favaro P, 2004, PROC CVPR IEEE, P631
   Golestaneh SA, 2017, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2017.71
   Harmeling S, 2010, P NEURAL INFORM PROC
   Huang R, 2018, NEUROCOMPUTING, V285, P154, DOI 10.1016/j.neucom.2018.01.041
   Javaran TA, 2017, VISUAL COMPUT, V33, P151, DOI 10.1007/s00371-015-1166-z
   Ji H, 2008, PROC CVPR IEEE, P1515
   Ji H, 2012, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2012.6247660
   Kalalembang E, 2009, INT C INSTR COMM INF, pv1
   Kapuriya BR, 2019, SIGNAL IMAGE VIDEO P, V13, P1001, DOI 10.1007/s11760-019-01438-z
   Kim B, 2018, COMPUT GRAPH FORUM, V37, P277, DOI 10.1111/cgf.13567
   Kim TH, 2014, PROC CVPR IEEE, P2766, DOI 10.1109/CVPR.2014.348
   Kim TH, 2016, Computer Vision
   Krahmer F, 2006, Inst Math Appl Univ Minnesota Minneapolis Minnesota Tech Rep 2133-5
   Levin A., 2006, P NEURAL INFORM PROC, V19, P841
   Liu RT, 2008, PROC CVPR IEEE, P954
   Liu SG, 2015, VISUAL COMPUT, V31, P733, DOI 10.1007/s00371-014-0998-2
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P5155, DOI 10.1109/TIP.2018.2847421
   Mignotte M, 2005, IEEE IMAGE PROC, P57
   Oliveira JP, 2014, IEEE T IMAGE PROCESS, V23, P466, DOI 10.1109/TIP.2013.2286328
   Oyamada Yuji, 2011, IPSJ Transactions on Computer Vision and Applications, V3, P32, DOI 10.2197/ipsjtcva.3.32
   Pan JS, 2016, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2016.56
   Paramanand C, 2013, IEEE IMAGE PROC, P4244, DOI 10.1109/ICIP.2013.6738874
   Sakano Morihiko, 2006, 2006 International Symposium on Intelligent Signal Processing and Communications, P522, DOI 10.1109/ISPACS.2006.364711
   Shi JP, 2014, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2014.379
   Su B, 2011, Proceedings of the 19th ACM International Conference on Multimedia. MM'11, DOI [DOI 10.1145/2072298.2072024, DOI 10.5555/1785794.1785825]
   Sun HW, 2009, IEEE IND ELEC, P1973, DOI 10.1109/IECON.2009.5415110
   Tai YW, 2011, IEEE T PATTERN ANAL, V33, P1603, DOI 10.1109/TPAMI.2010.222
   Tang C, 2016, IEEE SIGNAL PROC LET, V23, P1652, DOI 10.1109/LSP.2016.2611608
   Yan RM, 2016, IEEE T IMAGE PROCESS, V25, P1910, DOI 10.1109/TIP.2016.2535273
   Zhang XQ, 2010, SIAM J IMAGING SCI, V3, P253, DOI 10.1137/090746379
NR 40
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 23
PY 2023
DI 10.1007/s11042-023-17340-3
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9NV8
UT WOS:001088011000003
DA 2024-07-18
ER

PT J
AU Keikhosrokiani, P
   Fye, GM
AF Keikhosrokiani, Pantea
   Fye, Goh Man
TI A hybrid recommender system for health supplement e-commerce based on
   customer data implicit ratings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recommender System; Cold Start Problem; e-Commerce; Health Supplement;
   Collaborative Filtering; Content-based Filtering; Implicit rating;
   Information System
ID MATRIX-FACTORIZATION; INFORMATION; FEATURES
AB The personalized product preference and decision-making recommendation systems are highly demanded to handle big data and to increase service quality of the e-commerce platforms in the competitive industries. Previous recommender systems were hard coded and only extracted items from the same category. With this tactic, customers are limited to viewing only one category of products; items with several categories cannot be viewed. A concern for the e-commerce sector, particularly in the healthcare and pharmaceutical industries, is the growth of consumer preferences, the issue of cold starts, and the huge number of stocks holding units for new items. Therefore, this study aims to develop a product recommendation system for an e-commerce platform which deals with health supplements. For this reason, collaborative and content-based filtering are combined to propose a hybrid recommender system. In the proposed hybrid model, user's actions are converted into implicit rating weightage first. Then, to tackle the problem of increasing customer preferences, collaborative filtering is used to generate user's rating for warm-start items. Moreover, content-based filtering is used to solve cold start problem by recommending products to the users based on the similarity of the products regardless of user profile. Term frequency- inverse document frequency (TF-IDF) algorithm is adopted to weight the feature from the dataset first, then it creates step-by-step cosine similarity table. Finally, the proposed hybrid model is evaluated based on error metrices, ranking metrices, and business metrics and then compared based on the standard benchmarking algorithms. The best algorithm is selected to be used for the system development. Finally, the proposed hybrid model is developed and integrated into the real online e-commerce platform for healthcare company to handle the large number of stocks keeping units, cold start issues, and increasing customer preferences. This study can assist the healthcare companies to recommend relevant products to their customers and to help them stay competitive in healthcare e-commerce industry.
C1 [Keikhosrokiani, Pantea] Univ Oulu, Fac Informat Technol & Elect Engn, Oulu, Finland.
   [Keikhosrokiani, Pantea] Univ Oulu, Fac Med, Oulu, Finland.
   [Keikhosrokiani, Pantea; Fye, Goh Man] Univ Sains Malaysia, Sch Comp Sci, Minden 11800, Penang, Malaysia.
C3 University of Oulu; University of Oulu; Universiti Sains Malaysia
RP Keikhosrokiani, P (corresponding author), Univ Oulu, Fac Informat Technol & Elect Engn, Oulu, Finland.; Keikhosrokiani, P (corresponding author), Univ Oulu, Fac Med, Oulu, Finland.; Keikhosrokiani, P (corresponding author), Univ Sains Malaysia, Sch Comp Sci, Minden 11800, Penang, Malaysia.
EM pantea.keikhosrokiani@oulu.fi; manfye@student.usm.my
RI Keikhosrokiani, Pantea/Y-1281-2018
OI Keikhosrokiani, Pantea/0000-0003-4705-2732
FU The authors are thankful to the School of Computer Sciences, Universiti
   Sains Malaysia and Division of Research amp; Innovation, Universiti
   Sains Malaysia for the support from Short Term Grant
   (304/PKOMP/6315435). [304/PKOMP/6315435]; School of Computer Sciences,
   Universiti Sains Malaysia and Division of Research amp; Innovation,
   Universiti Sains Malaysia
FX The authors are thankful to the School of Computer Sciences, Universiti
   Sains Malaysia and Division of Research & Innovation, Universiti Sains
   Malaysia for the support from Short Term Grant (304/PKOMP/6315435).
CR Aditya PH, 2016, INT C ADV COMP SCI I, P303, DOI 10.1109/ICACSIS.2016.7872755
   Afoudi Y, 2021, SIMUL MODEL PRACT TH, V113, DOI 10.1016/j.simpat.2021.102375
   Aktukmak M, 2019, NEUROCOMPUTING, V367, P164, DOI 10.1016/j.neucom.2019.08.019
   Al-Hassan M, 2015, DECIS SUPPORT SYST, V72, P97, DOI 10.1016/j.dss.2015.02.001
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   Andreyev S., 2020, User-driven applications for research and science: Building programs for fields with open scenarios and unpredictable user actions, V1, DOI [10.1007/978-1-4842-6488-1, DOI 10.1007/978-1-4842-6488-1]
   [Anonymous], 2008, P 2008 ACM C REC SYS
   Ayvaz D, 2021, ELECTRON COMMER R A, V48, DOI 10.1016/j.elerap.2021.101058
   Azad HK, 2019, INFORM PROCESS MANAG, V56, P1698, DOI 10.1016/j.ipm.2019.05.009
   Azad HK, 2019, INFORM SCIENCES, V492, P147, DOI 10.1016/j.ins.2019.04.019
   Baltrunas L, 2008, LECT NOTES COMPUT SC, V5149, P22, DOI 10.1007/978-3-540-70987-9_5
   Bellogin A, 2018, Encyclopedia of social network analysis and mining, P2095
   Bloomberg, 2019, Alibaba beats estimates as personalised recommendations boost sales
   Böttcher A, 2008, LINEAR ALGEBRA APPL, V429, P1864, DOI 10.1016/j.laa.2008.05.020
   Bureau USC, 2020, Estimated annual U.S. retail trade sales-Total and e-commerce: 1998-2018
   Burke R., 2007, The adaptive web: methods and strategies of web personalization, P377, DOI [10.1007/978-3-540-72079-9_12, DOI 10.1007/978-3-540-72079-9_12]
   Cabitza F, 2015, COMPUT BIOL MED, V59, P202, DOI 10.1016/j.compbiomed.2014.03.009
   Çano E, 2017, INTELL DATA ANAL, V21, P1487, DOI 10.3233/IDA-163209
   Chatterjee S, 2021, J BUS RES, V131, P815, DOI 10.1016/j.jbusres.2020.10.043
   Chinchanachokchai S, 2021, J RETAIL CONSUM SERV, V61, DOI 10.1016/j.jretconser.2021.102528
   Colombo-Mendoza LO, 2020, INTEL SYST REF LIBR, V166, P383, DOI 10.1007/978-3-030-26488-8_17
   de Gemmis M., 2015, RECOMMENDER SYSTEMS, P119, DOI [DOI 10.1007/978-1-4899-7637-6_4, 10.1007/978-1-4899-7637-6_4]
   Dias MB, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P291
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Ezimmuo CM., 2022, Handbook of Research on Consumer Behavior Change and Data Analytics in the Socio-Digital Era, P210, DOI [10.4018/978-1-6684-4168-8.ch010, DOI 10.4018/978-1-6684-4168-8.CH010]
   Feng JM, 2021, KNOWL-BASED SYST, V214, DOI 10.1016/j.knosys.2020.106732
   Ford W, 2015, NUMERICAL LINEAR ALGEBRA WITH APPLICATIONS: USING MATLAB, P119, DOI 10.1016/B978-0-12-394435-1.00007-7
   Gao L, 2019, EXPERT SYST APPL, V136, P242, DOI 10.1016/j.eswa.2019.06.013
   George T, 2005, FIFTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P625, DOI 10.1109/icdm.2005.14
   Gong SJ, 2012, PHYSCS PROC, V24, P806, DOI 10.1016/j.phpro.2012.02.120
   Gunawardana A, 2009, J MACH LEARN RES, V10, P2935
   Guo GB, 2014, ELECTRON COMMER R A, V13, P440, DOI 10.1016/j.elerap.2014.10.003
   Gyrard Amelie, 2020, Smart Health, V15, P26, DOI 10.1016/j.smhl.2019.100083
   Hamed B, 2020, J Biostat Epidemiol, V5
   Herce-Zelaya J, 2020, INFORM SCIENCES, V536, P156, DOI 10.1016/j.ins.2020.05.071
   Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22
   Huang Z, 2015, TECHNOL FORECAST SOC, V95, P57, DOI 10.1016/j.techfore.2014.03.005
   Huang Z, 2013, ELECTRON COMMER R A, V12, P246, DOI 10.1016/j.elerap.2012.12.003
   Isinkaye FO, 2015, EGYPT INFORM J, V16, P261, DOI 10.1016/j.eij.2015.06.005
   Jiang T-X, 2022, Tensors for Data Processing, P31
   Jinjri WM, 2021, 2021 INT C INF TECHN
   Kalakota R., 1997, ELECT COMMERCE MANAG
   Kamili A, 2020, J INTELL FUZZY SYST, V39, P8389, DOI 10.3233/JIFS-189157
   Kawai M, 2022, EXPERT SYST APPL, V202, DOI 10.1016/j.eswa.2022.117129
   Keikhosrokiani P, 2022, Big Data Analytics for Healthcare: Datasets, Techniques, Life Cycles, Management, and Applications, P354
   Keikhosrokiani P, 2022, Handbook of research on opinion mining and text analytics on literary works and social media, DOI [10.4018/978-1-7998-9594-7, DOI 10.4018/978-1-7998-9594-7]
   Keikhosrokiani P, 2012, P 1 TAIB U INT C COM
   Keikhosrokiani P., 2013, The Int Technol Manag Rev, V3, P140, DOI [10.2991/itmr.2013.3.3.1, DOI 10.2991/ITMR.2013.3.3.1]
   Keikhosrokiani P, 2019, Cognition, Technology & Work, P1
   Keikhosrokiani P, 2021, The role of m-commerce literacy on the attitude towards using e-Torch in Penang, Malaysia, in e-business in the 21st century: Essential topics and studies, P309
   Keikhosrokiani P, 2018, Consumer-Driven Technologies in Healthcare, P128, DOI [10.4018/978-1-5225-6198-9.ch022, DOI 10.4018/978-1-5225-6198-9.CH022]
   Keikhosrokiani P, 2019, Perspectives in the development of mobile medical information systems: life cycle, management, methodological approach and application, V1st
   Keikhosrokiani P, 2021, INT J E-ADOPT, V13, P52, DOI 10.4018/IJEA.2021070104
   Keikhosrokiani P, 2018, TELEMAT INFORM, V35, P753, DOI 10.1016/j.tele.2017.11.006
   Kemp S., 2020, Digital 2020: Malaysia
   Koren Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1644873.1644874
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kotu V., 2019, Data Science, P343
   Kouris P., 2017, A Package Recommendation Framework Based on Collaborative Filtering and Preference Score Maximization, DOI [10.1007/978-3-319-65172-9_40, DOI 10.1007/978-3-319-65172-9_40]
   Kuanr M., 2021, Recent Challenges in Recommender Systems: A Survey. in Progress in Advanced Computing and Intelligent Engineerin
   Lemire D, 2005, SIAM PROC S, P471
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Liu J, 2010, IUI 2010, P31
   Liu X, 2021, EXPERT SYST APPL, V178, DOI 10.1016/j.eswa.2021.115015
   Losarwar V, 2012, INT C ART INT EMB SY
   Luo X, 2014, IEEE T IND INFORM, V10, P1273, DOI 10.1109/TII.2014.2308433
   MacKenzie I., 2013, How retailers can keep up with consumers, P18
   Malmir B, 2021, J HUMANIT LOGIST SUP, V11, P320, DOI 10.1108/JHLSCM-08-2020-0064
   Mangalindan JP., 2012, AMAZONS RECOMMENDATI
   Marconi A., 2006, Implicit vs. Explicit Data-Flow Requirements in Web Service Composition Goals in Service-Oriented Computing-ICSOC 2006
   Mican D., 2010, Berlin
   Moorthi K., 2021, Materials Today: Proceedings
   Nanda A, 2021, J URBAN MANAG, V10, P110, DOI 10.1016/j.jum.2021.04.001
   Norouzi R, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/6536908
   Papagelis M, 2005, ENG APPL ARTIF INTEL, V18, P781, DOI 10.1016/j.engappai.2005.06.010
   Pourhatami A, 2021, SCIENTOMETRICS, V126, P6625, DOI 10.1007/s11192-021-04038-2
   Prassas G, 2001, P 14 BLED EL COMM C
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Rodrigues F, 2016, PROCEDIA COMPUT SCI, V100, P136, DOI 10.1016/j.procs.2016.09.133
   Sahoo AK, 2019, COMPUTATION, V7, DOI 10.3390/computation7020025
   Sai Ambati L., 2020, Issues Inform Syst, V21, P103
   Sardianos C, 2020, FUTURE GENER COMP SY, V112, P394, DOI 10.1016/j.future.2020.05.041
   Senecal S, 2004, J RETAILING, V80, P159, DOI 10.1016/j.jretai.2004.04.001
   Sharma S., 2015, Int J Comput Appl, V975, P8887
   Talia D, 2019, J CLOUD COMPUT-ADV S, V8, DOI 10.1186/s13677-019-0127-x
   Thirumalai S, 2011, J OPER MANAG, V29, P477, DOI 10.1016/j.jom.2010.11.009
   Wei KN, 2007, I C SERV SYST SERV M, P734
   Xian Z., 2022, Handbook of Research on Consumer Behavior Change and Data Analytics in the Socio-Digital Era, P124, DOI [10.4018/978-1-6684-4168-8.ch006, DOI 10.4018/978-1-6684-4168-8.CH006]
   Zhao X, 2022, Comput Mater Continua, V70
   Zhe ITY, 2021, APPL INTELL, V51, P2406, DOI 10.1007/s10489-020-01928-5
NR 90
TC 0
Z9 0
U1 8
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 21
PY 2023
DI 10.1007/s11042-023-17321-6
EA OCT 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W1VN4
UT WOS:001089581100002
DA 2024-07-18
ER

PT J
AU Bhattacharyya, A
   Chatterjee, S
   Sen, S
   Obaidullah, SKM
   Roy, K
AF Bhattacharyya, Ankan
   Chatterjee, Somnath
   Sen, Shibaprasad
   Obaidullah, S. K. M. D.
   Roy, Kaushik
TI BWordDeepNet: a novel deep learning architecture for the recognition of
   online handwritten Bangla words
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Online handwriting; BLSTM; LSTM; GRU; BGRU; Constant error flow
AB Online handwritten word recognition (OHR) in low-resource languages such as Bangla is still an open problem. Although the need and importance of OHR are increasing nowadays, research works on word-level recognition are few (specifically for Bangla script), and there is a lot of room for improving recognition performance. In the current work, we employed different Recurrent Neural Network (RNN) architectures such as Long Short-Term Memory (LSTM), Bidirectional Long Short-Term Memory (BLSTM), Gated Recurrent Unit (GRU), and Bidirectional Gated Recurrent Unit (BGRU) for the recognition of online handwritten Bangla words written in an unconstrained domain. One of the challenges includes the variable number of strokes used to write words. This study aims to develop a segmentation-free recognition module where the features from constituent strokes of the word sample are fed to the developed RNN architectures. Sequential and dynamic information obtained from the strokes is considered as the features for the current experiment. The customized architecture of BLSTM known as BWordDeepNet (Bangla Word Deep-learning Network) provides the best performance with 98.35% correct recognition accuracy on the dataset having 7992 online handwritten Bangla word samples. Additionally, the model achieves a numerical gain of 8.08% compared to the Bangla word recognition work mentioned in [38] that was performed on the same word dataset containing 5550 word samples. We have also compared the performance of our proposed model with state-of-the-art techniques used for the same purpose.
C1 [Bhattacharyya, Ankan] Univ Kentucky, Lexington, KY 40506 USA.
   [Chatterjee, Somnath] Future Inst Engn & Management, Kolkata 700150, India.
   [Sen, Shibaprasad] Techno Main Salt Lake, Kolkata 700091, India.
   [Obaidullah, S. K. M. D.] Aliah Univ, Kolkata 700156, India.
   [Roy, Kaushik] West Bengal State Univ, Kolkata 700126, India.
C3 University of Kentucky; Aliah University; West Bengal State University
RP Roy, K (corresponding author), West Bengal State Univ, Kolkata 700126, India.
EM ankan.bhattacharyya@uky.edu; somnathchatterjee796@gmail.com;
   shibubiet@gmail.com; sk.obaidullah@aliah.ac.in; kaushik@wbsu.ac.in
RI Roy, Kaushik/O-7021-2019
OI Roy, Kaushik/0000-0002-3360-7576
FU One of the authors would like to thank SERB, DST for financial support
   in the form of a project; SERB, DST
FX One of the authors would like to thank SERB, DST for financial support
   in the form of a project
CR ALMUALLIM H, 1987, IEEE T PATTERN ANAL, V9, P715, DOI 10.1109/TPAMI.1987.4767970
   [Anonymous], 2011, P 2011 JOINT WORKSH
   Baghshah MSoleymani., 2006, 2 INT C INF COMM TEC, V1, P1878
   Bai ZL, 2005, PROC INT CONF DOC, P262
   Beigi HS, 1994, Arabic and other languages with similar writing styles an on-line digit recognizer
   Bharath A, 2007, PROC INT CONF DOC, P506
   Bharath A, 2012, IEEE T PATTERN ANAL, V34, P670, DOI 10.1109/TPAMI.2011.234
   Bhattacharya NA, 2017, PROC INT CONF DOC, P206, DOI 10.1109/ICDAR.2017.42
   Bhunia AK, 2015, PROC INT CONF DOC, P636, DOI 10.1109/ICDAR.2015.7333839
   Bouslama F, 1998, 1998 SECOND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED INTELLIGENT ELECTRONIC SYSTEMS, KES '98, PROCEEDINGS, VOL, 3, P76, DOI 10.1109/KES.1998.725956
   Budsayaplakorn R, 2003, 2003 IEEE XIII WORKSHOP ON NEURAL NETWORKS FOR SIGNAL PROCESSING - NNSP'03, P537, DOI 10.1109/NNSP.2003.1318053
   Chakraborty B, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010072
   Chowdhury K, 2015, 2015 18TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), P484, DOI 10.1109/ICCITechn.2015.7488119
   Chowdhury S, 2011, PROC INT CONF DOC, P599, DOI 10.1109/ICDAR.2011.126
   Das N, 2015, PATTERN RECOGN, V48, P2054, DOI 10.1016/j.patcog.2014.12.011
   Eberhard D. M., 2020, Ethnologue: Languages of the world, V23rd
   ELWAKIL MS, 1989, PATTERN RECOGN, V22, P97, DOI 10.1016/0031-3203(89)90058-7
   Fink Gernot A., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P393, DOI 10.1109/ICFHR.2010.68
   Frinken V, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P355, DOI 10.1109/DAS.2014.55
   Ghods V, 2013, PATTERN RECOGN LETT, V34, P486, DOI 10.1016/j.patrec.2012.12.005
   Ghosh R, 2019, PATTERN RECOGN, V92, P203, DOI 10.1016/j.patcog.2019.03.030
   Ghosh R, 2016, INT CONF FRONT HAND, P435, DOI [10.1109/ICFHR.2016.0087, 10.1109/ICFHR.2016.82]
   Halavati R, 2007, INT J PATTERN RECOGN, V21, P491, DOI 10.1142/S0218001407005533
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Izadi S, 2008, P 11 INT C FRONT HAN, P598
   Jaeger S., 2003, International Journal on Document Analysis and Recognition, V6, P75, DOI 10.1007/s10032-003-0107-y
   Karnchanapusakij C, 2009, I C COMP GRAPH IM VI, P323, DOI 10.1109/CGIV.2009.79
   Liu CL, 2013, PATTERN RECOGN, V46, P155, DOI 10.1016/j.patcog.2012.06.021
   Liu CL, 2004, IEEE T PATTERN ANAL, V26, P198, DOI 10.1109/TPAMI.2004.1262182
   Liu CL., 2006, Online Japanese character recognition using trajectory-based normalization and direction feature extraction
   Matsumoto K, 2001, PROC INT CONF DOC, P496, DOI 10.1109/ICDAR.2001.953839
   Mukherjee PS, 2017, PROC INT CONF DOC, P658, DOI 10.1109/ICDAR.2017.113
   Obaidullah SM, 2018, MULTIMED TOOLS APPL, V77, P1643, DOI 10.1007/s11042-017-4373-y
   Parui SK, 2008, INT C PATTERN RECOGN, P1
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Razavi S.M., 2004, 6th Iranian Conference on Intelligent Systems, (in Persian), P859
   Sanguansat P, 2004, IEEE INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES 2004 (ISCIT 2004), PROCEEDINGS, VOLS 1 AND 2, P492
   Sen S, 2020, NEURAL COMPUT APPL, V32, P9939, DOI 10.1007/s00521-019-04518-w
   Singh H, 2021, ARTIF INTELL REV, V54, P1525, DOI 10.1007/s10462-020-09886-7
   Srimany A, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P86, DOI 10.1109/DAS.2014.67
   Takahashi K, 1997, PROC INT CONF DOC, P369, DOI 10.1109/ICDAR.1997.619873
   TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669
   VELTMAN SR, 1994, IEEE T IMAGE PROCESS, V3, P314, DOI 10.1109/83.287027
   Zhou XD, 2007, PROC INT CONF DOC, P48
NR 44
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 20
PY 2023
DI 10.1007/s11042-023-16709-8
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9NY9
UT WOS:001088014100006
DA 2024-07-18
ER

PT J
AU Ouyang, JH
   Mao, D
   Meng, QY
AF Ouyang, Jihong
   Mao, Dong
   Meng, Qingyi
TI LaRW: boosting open-set semi-supervised learning with label-guided
   re-weighting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Image classification; Semi-supervised learning; Open-set
   semi-supervised learning; OOD detection
AB The superior performance of traditional Semi-Supervised Learning (SSL) methods are generally achieved in strictly data-constrained scenarios, e.g. the class distribution of labeled and unlabeled data is matched. However, in realistic scenarios, unlabeled data is gathered from a variety of sources and it is difficult to ensure a consistent class distribution with labeled data. Therefore, this paper considers a more realistic and widespread paradigm in which the labeled and unlabeled data come from the mismatched distribution, dubbed as Open-Set Semi-Supervised Learning (OS-SSL). Specifically, unlabeled data contains out of distribution (OOD) samples, which are samples that do not fall into the labeled categories. Existing research demonstrates that OOD samples can damage classification performance. Therefore, the OS-SSL methods usually filter out OOD samples during model training. In this work, we propose a simple but effective method, namely LaRW, which takes into account the overconfidence prediction of classifiers and the learning difficulty of each category, while attempting to utilize the OOD samples. First, we propose to apply the label propagation algorithm at the feature-level to assist in producing pseudo-labels, which improve the quality of pseudo-labels. Further, we design a novel OOD detection score to better filter OOD samples. Finally, we evaluate our method against the existing SSL and OS-SSL methods under several settings. Extensive empirical results demonstrate the effectiveness and expandability of our proposed method.
C1 [Ouyang, Jihong; Mao, Dong; Meng, Qingyi] Jilin Univ, Dept Comp Sci & Technol, Changchun, Jilin, Peoples R China.
C3 Jilin University
RP Meng, QY (corresponding author), Jilin Univ, Dept Comp Sci & Technol, Changchun, Jilin, Peoples R China.
EM ouyj@jlu.edu.cn; maodong21@mails.jlu.edu.cn; mengqy21@mails.jlu.edu.cn
FU This work was partially supported by the National Natural Science
   Foundation of China (NSFC) [No.62006094, No.61876071] and Scientific and
   Technological Developing Scheme of Jilin Province [No.20180201003SF,
   No.20190701031GH] and Energy Administration of J [62006094, 61876071];
   National Natural Science Foundation of China (NSFC) [20180201003SF,
   20190701031GH]; Scientific and Technological Developing Scheme of Jilin
   Province [3D516L921421]; Energy Administration of Jilin Province
FX This work was partially supported by the National Natural Science
   Foundation of China (NSFC) [No.62006094, No.61876071] and Scientific and
   Technological Developing Scheme of Jilin Province [No.20180201003SF,
   No.20190701031GH] and Energy Administration of Jilin Province
   [No.3D516L921421].
CR Albert P, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533616
   Arazo E, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207304
   Berthelot D., 2019, arXiv
   Berthelot D, Neural information processing systems, P5050
   Cascante-Bonilla P, 2021, AAAI CONF ARTIF INTE, V35, P6912
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Chen YB, 2020, AAAI CONF ARTIF INTE, V34, P3569
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Douze M, 2018, PROC CVPR IEEE, P3349, DOI 10.1109/CVPR.2018.00353
   Gidaris S., 2018, P 6 INT C LEARNING R
   Guo LZ, 2020, PR MACH LEARN RES, V119
   Huang JK, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8290, DOI 10.1109/ICCV48922.2021.00820
   Huang Z, 2022, IEEE Trans. Multimed., V1-1
   Iscen A, 2019, PROC CVPR IEEE, P5065, DOI 10.1109/CVPR.2019.00521
   Jeong J, 2019, Neural information processing systems, V10, P767
   Kingma D. P., 2014, arXiv
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Laine Samuli, 2017, 5 INT C LEARNING REP, DOI DOI 10.48550/ARXIV.1610.02242
   Lee D.-H., 2013, PSEUDOLABEL SIMPLE E, V3, P896
   Li C.-L., 2020, Advances in neural information processing systems, V33, P596
   Luo H., 2021, ARXIV
   Miyato T., 2017, ICLR
   Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Oh JH, 2016, AAAI CONF ARTIF INTE, P3022
   Oliver A., 2018, Advances in Neural Information Processing Systems, P3239
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qing Yu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P438, DOI 10.1007/978-3-030-58610-2_26
   Shi WW, 2018, LECT NOTES COMPUT SC, V11209, P311, DOI 10.1007/978-3-030-01228-1_19
   Shu Jun, 2019, ADV NEURAL INFORM PR, P1917
   Souly N, 2017, IEEE I CONF COMP VIS, P5689, DOI 10.1109/ICCV.2017.606
   Tarvainen A, 2017, ADV NEUR IN, V30
   Wang YZ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9282, DOI 10.1109/ICCV48922.2021.00917
   Xie Q., 2020, Unsupervised data augmentation for consistency training, P6256
   Yu F., 2015, ARXIV
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhai XH, 2019, IEEE I CONF COMP VIS, P1476, DOI 10.1109/ICCV.2019.00156
   Zhang B., 2021, Proc. Adv. Neural Inf. Process. Syst., P18408
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhou DY, 2004, ADV NEUR IN, V16, P321
NR 42
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 20
PY 2023
DI 10.1007/s11042-023-17357-8
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6NT6
UT WOS:001085957900001
DA 2024-07-18
ER

PT J
AU Khurana, P
   Sharma, K
AF Khurana, Parul
   Sharma, Kiran
TI Growth and impact of blockchain scientific collaboration network: a
   bibliometric analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blockchain; Bibliometrics analysis; Collaboration network; Country
   ranking; Thematic analysis
ID TECHNOLOGY; EVOLUTION; SECURITY; INTERNET
AB Numerous authors have presented the blockchain in their literature as a disruptive combustion engine with the potential to transform organizations and technology in the current digital economy, with features like validation of transactions, safeguarding of entries, preservation of records, immutability, decentralization, consensus, and faster settlement. However, literature on scientific production and collaboration through bibliometric and network analysis is still lacking. Based on the data extracted from the Web of Science from 2014-2020 with 6790 records, the emerging trends and collaboration patterns of blockchain technology are studied with the use of bibliometrics and network analysis. The study asserts (i) the impact of open-access publication on the growth and visibility of literature, (ii) the collaboration patterns and it's impact on team size, (iii) the ranking of countries based on their national and international collaboration, and (iv) thematic analysis of literature. The results show growth in the literature since 2017, and open-access publications have received more citations. Very few authors are actively working in the field, as only 73.7% of authors have published a single paper on the blockchain. China published the highest number of papers, followed by the United States of America and the United Kingdom. Singapore published a large number of papers with international collaboration and Russia with national collaboration, whereas the USA showed a balance between national and international publications. Finally, thematic analysis figured out the five key themes as supply chain management, smart contract, security, distributed ledger technology, and internet of things in contrast to the blockchain. Hence, this study investigates scientific productions by means of open-access publications, collaboration patterns, ranking, and key areas in blockchain literature.
C1 [Khurana, Parul] Lovely Profess Univ, Sch Comp Applicat, Jalandhar Delhi GT Rd, Phagwara 144411, Punjab, India.
   [Sharma, Kiran] BML Munjal Univ, Sch Engn & Technol, Gurugram 122413, Haryana, India.
C3 Lovely Professional University; BML Munjal University
RP Sharma, K (corresponding author), BML Munjal Univ, Sch Engn & Technol, Gurugram 122413, Haryana, India.
EM parul.khurana@lpu.co.in; kiran.sharma@bmu.edu.in
OI Sharma, Kiran/0000-0002-3797-7363
FU The authors express profound gratitude to all the reviewers for their
   invaluable suggestions. These suggestions have significantly enhanced
   the quality of the manuscript.
FX The authors express profound gratitude to all the reviewers for their
   invaluable suggestions. These suggestions have significantly enhanced
   the quality of the manuscript.
CR Aitzhan NZ, 2018, IEEE T DEPEND SECURE, V15, P840, DOI 10.1109/TDSC.2016.2616861
   Antelman K, 2004, COLL RES LIBR, V65, P372, DOI 10.5860/crl.65.5.372
   Aysan AF, 2021, J RISK FINANC MANAG, V14, DOI 10.3390/jrfm14090427
   Chen CM, 2008, DATA KNOWL ENG, V67, P234, DOI 10.1016/j.datak.2008.05.004
   Christidis K, 2016, IEEE ACCESS, V4, P2292, DOI 10.1109/ACCESS.2016.2566339
   Dabbagh M, 2019, IEEE ACCESS, V7, P19212, DOI 10.1109/ACCESS.2019.2895646
   Du MX, 2017, IEEE SYS MAN CYBERN, P2567, DOI 10.1109/SMC.2017.8123011
   Firdaus A, 2019, SCIENTOMETRICS, V120, P1289, DOI 10.1007/s11192-019-03170-4
   Frizzo-Barker J, 2020, INT J INFORM MANAGE, V51, DOI 10.1016/j.ijinfomgt.2019.10.014
   Nguyen GT, 2018, J INF PROCESS SYST, V14, P101, DOI 10.3745/JIPS.01.0024
   Gillpatrick T., 2022, Economics, V10, P105, DOI [DOI 10.2478/EOIK-2022-0009, 10.2478/eoik-2022-0009]
   Grover P, 2019, J ENTERP INF MANAG, V32, P735, DOI 10.1108/JEIM-06-2018-0132
   Guo YM, 2021, FUTURE GENER COMP SY, V116, P316, DOI 10.1016/j.future.2020.10.023
   Hoffman MR., 2019, Data Sci, V2, P291, DOI [10.3233/DS-190018, DOI 10.3233/DS-190018]
   Huynh-The T, 2023, FUTURE GENER COMP SY, V143, P401, DOI 10.1016/j.future.2023.02.008
   Joao BN, 2018, REV GES PROJ, V9, P33, DOI 10.5585/GeP.v9i3.11121
   Johng H, 2020, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING (SAC'20), P61, DOI 10.1145/3341105.3374022
   Kang JW, 2017, IEEE T IND INFORM, V13, P3154, DOI 10.1109/TII.2017.2709784
   Kewell B, 2017, STRATEG CHANG, V26, P429, DOI 10.1002/jsc.2143
   Khan AI, 2022, CMC-COMPUT MATER CON, V70, P2835, DOI 10.32604/cmc.2022.020342
   Khan C, 2017, COMPUTER, V50, P29, DOI 10.1109/MC.2017.3571057
   Khan MA, 2018, FUTURE GENER COMP SY, V82, P395, DOI 10.1016/j.future.2017.11.022
   Khurana P, 2023, Comput Intell Aided Syst Healthc Domain, V167
   Khurana P, 2023, MULTIMED TOOLS APPL, V82, P18501, DOI 10.1007/s11042-022-14161-8
   Kohli R, 2021, J MANAGE INFORM SYST, V38, P282, DOI 10.1080/07421222.2021.1912910
   Kube N, 2018, FINANC MARK PORTFOLI, V32, P329, DOI 10.1007/s11408-018-0315-6
   Kuzior A, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14138206
   Lee S, 2005, SOC STUD SCI, V35, P673, DOI 10.1177/0306312705052359
   Liang TP, 2021, J MANAGE INFORM SYST, V38, P314, DOI 10.1080/07421222.2021.1912915
   Liu MT, 2019, IEEE T IND INFORM, V15, P3559, DOI 10.1109/TII.2019.2897805
   Luo JL, 2021, IEEE ACCESS, V9, P120227, DOI 10.1109/ACCESS.2021.3092192
   Marijan D, 2022, COMPUT SCI REV, V45, DOI 10.1016/j.cosrev.2022.100492
   McCallig J, 2019, INT J ACCOUNT INF SY, V33, P47, DOI 10.1016/j.accinf.2019.03.004
   Meneghini R, 2007, EMBO REP, V8, P112, DOI 10.1038/sj.embor.7400906
   Mengelkamp E, 2018, APPL ENERG, V210, P870, DOI 10.1016/j.apenergy.2017.06.054
   Miau S, 2018, TECHNOL ANAL STRATEG, V30, P1029, DOI 10.1080/09537325.2018.1434138
   Mohanta BK, 2019, INTERNET THINGS-NETH, V8, DOI 10.1016/j.iot.2019.100107
   Moosavi J, 2021, ENVIRON SCI POLLUT R, DOI 10.1007/s11356-021-13094-3
   Mourtzis D, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13031353
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Nasir A, 2021, IEEE ACCESS, V9, P989, DOI 10.1109/ACCESS.2020.3046931
   Padmavathi U., 2023, RES ANTHOLOGY CONVER, P21
   Porter AL, 2007, SCIENTOMETRICS, V72, P117, DOI 10.1007/s11192-007-1700-5
   Puthal D, 2018, IEEE CONSUM ELECTR M, V7, P6, DOI 10.1109/MCE.2018.2816299
   Sadiku MN., 2023, Eur J Bus Startups Open Soc, V3, P12
   Saif ANM, 2022, Technol Innov Manag Rev, V12, P1
   Sajja Guna Sekhar, 2023, Materials Today: Proceedings, P3705, DOI 10.1016/j.matpr.2021.07.366
   Sankar LS, 2017, INT CONF ADVAN COMPU
   Schmidt K., 2017, SOLVING CHALLENGES D
   Sharma K, 2021, SCIENTOMETRICS, V126, P4417, DOI 10.1007/s11192-021-03884-4
   Shi XT, 2023, INT J PROD RES, V61, P3651, DOI 10.1080/00207543.2021.1953182
   Shrivastava Anurag, 2023, Materials Today: Proceedings, P3471, DOI 10.1016/j.matpr.2021.07.273
   Swarnkar M., 2021, Appl Blockchain Healthc, V2021, P69
   Tabrez Siddiqui Shams, 2020, Ambient Communications and Computer Systems. RACCCS 2019. Advances in Intelligent Systems and Computing (AISC 1097), P51, DOI 10.1007/978-981-15-1518-7_5
   Taherdoost H, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12061479
   Tandon A, 2021, TECHNOL FORECAST SOC, V166, DOI 10.1016/j.techfore.2021.120649
   Tasatanattakool P, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P473, DOI 10.1109/ICOIN.2018.8343163
   Tschorsch F, 2016, IEEE COMMUN SURV TUT, V18, P2084, DOI 10.1109/COMST.2016.2535718
   Vaigandla K.K., 2023, Mesopotamian J. Cyber Secur., V2023, P73, DOI 10.58496/MJCS/2023/012
   van Pelt R, 2021, INFORM SYST MANAGE, V38, P21, DOI 10.1080/10580530.2020.1720046
   Vivekanadam B., 2020, J. ISMAC, V2, P200, DOI [10.36548/jismac.2020.4.003, DOI 10.36548/JISMAC.2020.4.003]
   Wenhua Z, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12030546
   Wenjuan Zhao, 2019, Queueing Theory and Network Applications. 14th International Conference, QTNA 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11688), P379, DOI 10.1007/978-3-030-27181-7_23
   White GRT, 2017, STRATEG CHANG, V26, P439, DOI 10.1002/jsc.2144
   Xu LD, 2018, INT J PROD RES, V56, P2941, DOI 10.1080/00207543.2018.1444806
   Yalcin H, 2021, SCIENTOMETRICS, V126, P3775, DOI 10.1007/s11192-021-03876-4
   Yang Z, 2019, IEEE INTERNET THINGS, V6, P1495, DOI 10.1109/JIOT.2018.2836144
   Yli-Huumo J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163477
   Zeng S, 2018, IEEE INT VEH SYM, P102, DOI 10.1109/IVS.2018.8500606
   Zheng ZB, 2018, INT J WEB GRID SERV, V14, P352, DOI 10.1504/IJWGS.2018.095647
   Zheng ZB, 2017, IEEE INT CONGR BIG, P557, DOI 10.1109/BigDataCongress.2017.85
   Ziolkowski R, 2020, J MANAGE INFORM SYST, V37, P316, DOI 10.1080/07421222.2020.1759974
   Zyskind G, 2015, 2015 IEEE SECURITY AND PRIVACY WORKSHOPS (SPW), P180, DOI 10.1109/SPW.2015.27
NR 73
TC 2
Z9 2
U1 7
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17262-0
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000005
DA 2024-07-18
ER

PT J
AU Kaur, B
   Chaudhary, A
   Bano, S
   Yashmita
   Reddy, SRN
   Anand, R
AF Kaur, Binwant
   Chaudhary, Aastha
   Bano, Shahina
   Yashmita
   Reddy, S. R. N.
   Anand, Rishika
TI Fostering inclusivity through effective communication: Real-time sign
   language to speech conversion system for the deaf and hard-of-hearing
   community
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sign Language Translator; Sign Language to Speech; Jetson Nano;
   InceptionResNetV2; Deep Learning
AB In a world that values inclusivity, effective communication remains a cornerstone of empowerment for the deaf and hard-of-hearing community, with sign language serving as a pivotal means of expression. Yet, the limited proficiency in sign language among the general population underscores the need for innovative solutions like sign language translators. This study introduces a cutting-edge real-time sign language to speech conversion system, harnessing the power of a pre-trained InceptionResNetV2 deep learning model. To enhance accuracy, a bespoke American sign language dataset is employed, capturing 21 critical hand keypoints and sign images through Python libraries. The training dataset comprises 7200 images, categorized into 24 alphabet classes (excluding 'J' and 'Z'). Model refinement occurs over 20 epochs, each with a batch size of 16, culminating in remarkable training and validation accuracies of 98.23% and 97.07%, respectively. This impressive real-time sign language to speech conversion system, synergizing deep learning with Jetson Nano technology, paves the way for robust communication accessibility. Future advancements are envisaged, including expanding the system to support complete sentence translation and embracing diverse sign languages. By doing so, a comprehensive suite of sign language communication solutions will be offered, fostering universal understanding and inclusivity.
C1 [Kaur, Binwant; Chaudhary, Aastha; Bano, Shahina; Yashmita; Reddy, S. R. N.; Anand, Rishika] IGDTUW, Comp Sci & Engn, Delhi 110006, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW)
RP Anand, R (corresponding author), IGDTUW, Comp Sci & Engn, Delhi 110006, India.
EM binwant030btcse19@igdtuw.ac.in; aastha040btcse19@igdtuw.ac.in;
   shahina032btcse19@igdtuw.ac.in; yashmita027btcse19@igdtuw.ac.in;
   srnreddy@igdtuw.ac.in; rishika003phd19@igdtuw.ac.in
OI Kaur, Binwant/0009-0006-2368-6457; Chaudhary, Aastha/0009-0004-2929-1689
CR Adeyanju IA., 2021, INTELL SYST APPL, V12, DOI DOI 10.1016/J.ISWA.2021.200056
   Alarcon G., 2016, Convolutional Neural Netw Vis Recogn, V8, P225
   Aloysius N, 2020, INT J COMPUT SCI ENG, V22, P154, DOI 10.1504/IJCSE.2020.107268
   [Anonymous], 2023, NVIDIA Developer
   [Anonymous], 2020, Rock Pi, 10 designed for AI apps and solutions based on
   [Anonymous], 2023, Linaro HIKEY970
   [Anonymous], Inception-v4, Inception-resnet and the impact of residual connections on learning
   Banana Pi B-M, 2023, Banana Pi
   Bantupalli K, 2018, IEEE INT CONF BIG DA, P4896, DOI 10.1109/BigData.2018.8622141
   Battistoni Pietro, 2020, Learning and Collaboration Technologies. Human and Technology Ecosystems. 7th International Conference, LCT 2020. Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12206), P3, DOI 10.1007/978-3-030-50506-6_1
   Bheda V, 2017, Arxiv, DOI arXiv:1710.06836
   Breve B, 2022, MULTIMED TOOLS APPL, V81, P73, DOI 10.1007/s11042-021-11077-7
   Bukhari J., 2015, Int J u- e-Serv Sci Technol, V8, P131, DOI [10.14257/ijunesst.2015.8.1.12, DOI 10.14257/IJUNESST.2015.8.1.12]
   Coral, 2020, Dev Board
   de Souza Cesar Roberto, 2013, Machine Learning and Data Mining in Pattern Recognition. 9th International Conference, MLDM 2013. Proceedings: LNCS 7988, P84, DOI 10.1007/978-3-642-39712-7_7
   Dertat A, 2013, Applied deep learning-part 4: convolutional neural networks, Medium
   Elhamraoui Z., 2020, InceptionResNetV2-Simple introduction
   Gattupalli Srujana., 2016, ACM INT C P SERIES, P1, DOI DOI 10.1145/2910674.2910716
   Gavrilova Y, 2021, What are convolutional neural
   Kadhim RA, 2020, TEM J, V9, P937, DOI 10.18421/TEM93-14
   Katoch S, 2022, ARRAY-NY, V14, DOI 10.1016/j.array.2022.100141
   Kothadiya D, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11111780
   Lencse G, 2016, Int J Adv Telecommun Electrotech Signals Syst, V5, DOI [10.11601/ijates.v5i1.138, DOI 10.11601/IJATES.V5I1.138]
   Nano J, 2022, NVIDIA Developer
   Raj RD, 2018, 2018 IEEE INT STUD C, P1, DOI [10.1109/SCEECS.2018.8546967, DOI 10.1109/SCEECS.2018.8546967]
   Rosebrock A, 2020, physiol image search
   Sabeenian R., 2020, J. Adv. Res. Dyn. Control. Syst, V12, P964
   Saxena S, 2021, Beginner's guide to support vector machine (SVM)
   Shin DJ, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12083734
   Shirbhate RS, 2020, Int Res J Eng Technol
   Srivastava T, 2020, Simplified!, Analytics Vidya
   Süzen AA, 2020, 2ND INTERNATIONAL CONGRESS ON HUMAN-COMPUTER INTERACTION, OPTIMIZATION AND ROBOTIC APPLICATIONS (HORA 2020), P179, DOI 10.1109/hora49412.2020.9152915
   Talukder D, 2020, INT CONF COMPUT INFO, DOI 10.1109/ICCIT51783.2020.9392693
   Tayade A, 2021, Int J Res Publ Rev, V2, DOI [10.13140/RG.2.2.32364.03203, DOI 10.13140/RG.2.2.32364.03203]
   Thakur A., 2020, J. Innov. Image Proc, V2, P65, DOI [10.36548/jiip.2020.2.001, DOI 10.36548/JIIP.2020.2.001]
   TI.com, 2023, BEAGLE-3P-BBONE-AI BeagleBone® AI AM5729 development board for embedded Artificial Intelligence
   Triwijoyo BK, 2023, JITEKI: Jurnal Ilmiah Teknik Elektro Komputer dan Informatika, V9
   Yash J, 2017, Int J Innov Eng Res, V2, P37
   Zhou ZX, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI 10.1145/3373625.3418046
NR 39
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-17372-9
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600010
DA 2024-07-18
ER

PT J
AU Venunath, M
   Sujatha, P
   Koti, P
   Dharavath, S
AF Venunath, M.
   Sujatha, Pothula
   Koti, Prasad
   Dharavath, Srinu
TI Efficient community-based influence maximization in large-scale social
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Complex networks; Influence maximization problem; Community discovery;
   Social networks
ID COMPLEX NETWORKS; INFLUENCE SPREAD; ALGORITHM; IDENTIFICATION;
   INFORMATION; CENTRALITY; DIFFUSION; MODELS
AB The Influence Maximization problem (IMP) is a fundamental algorithmic challenge that involves selecting a set of k users, known as the seed set, from a social media network to maximize the expected number of influenced users or influence spread. In recent years, Influence maximization has been extensively studied due to its numerous applications in marketing and other domains. However, many existing algorithms neglect the impact of communities on influence maximization, and some other methods suffer from scalability issues and time-consuming computations. In this paper, we propose a fast, and scalable algorithm called Community based Influential maximization (CB-IM) to address these limitations. This method leverages the community structure of the network to select k users, thus maximizing the influence spread. The CB-IM algorithm comprises two main components for influence maximization: (1) seed selection and (2) local community spreading. In the seed selection phase, we extract seed nodes from communities identified through a community detection algorithm. To effectively reduce computational complexity and distribute seed nodes across communities, we carefully select meaningful communities. The second phase involves the propagation of influence within independent communities. In this step, the final seed nodes are strategically distributed to facilitate local spreading through simple paths within the communities. To evaluate the performance of proposed method, we conducted a series of experiments using real networks. The proposed CB-IM algorithm demonstrated superior performance over other algorithms in terms of influence spread and running time, highlighting its effectiveness.
C1 [Venunath, M.; Sujatha, Pothula] Pondicherry Univ, Sch Engn & Technol, Pondicherry, India.
   [Koti, Prasad] Sarada Gangadaran Coll, Dept Comp Applicat, Pondicherry, India.
   [Dharavath, Srinu] Annamalai Univ, Dept Comp Sci & Engn, Chidambaram 608002, India.
C3 Pondicherry University; Annamalai University
RP Venunath, M (corresponding author), Pondicherry Univ, Sch Engn & Technol, Pondicherry, India.
EM tovenunath@gmail.com; sujathaps.csc@pondiuni.ac.in;
   prasadkoti@sgcpd.com; srinudharavathphd@gmail.com
CR Aghaee Z, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00694-z
   Ahajjam S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30310-2
   Ahajjam S, 2018, SOC NETWORKS, V54, P41, DOI 10.1016/j.socnet.2017.11.004
   Ahn YY, 2010, NATURE, V466, P761, DOI 10.1038/nature09182
   Arora A, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P651, DOI 10.1145/3035918.3035924
   Bae J, 2014, PHYSICA A, V395, P549, DOI 10.1016/j.physa.2013.10.047
   Bauer F, 2012, EPL-EUROPHYS LETT, V99, DOI 10.1209/0295-5075/99/68007
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   BONACICH P, 1972, J MATH SOCIOL, V2, P113, DOI 10.1080/0022250X.1972.9989806
   Bonacich P, 2001, SOC NETWORKS, V23, P191, DOI 10.1016/S0378-8733(01)00038-7
   Borge-Holthoefer J, 2012, PHYS REV E, V85, DOI 10.1103/PhysRevE.85.026116
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Bu Z, 2020, IEEE T KNOWL DATA EN, V32, P1348, DOI 10.1109/TKDE.2019.2903712
   Budak C., 2011, P 20 INT C WORLD WID, P665, DOI DOI 10.1145/1963405.1963499
   Chen W, 2010, 16 ACM SIGKDD INT C, P1029
   Chen W., 2010, ACM SIGKDD INT C KNO, P1029, DOI DOI 10.1145/1835804.1835934
   Chen W, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P199, DOI 10.1145/1557019.1557047
   Cheng SQ, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P509, DOI 10.1145/2505515.2505541
   Cheng-Hsin Weng, 2010, Proceedings of the 2010 5th IEEE International Conference on Nano/Micro Engineered and Molecular Systems (NEMS 2010), P14, DOI 10.1109/NEMS.2010.5592127
   Clauset A, 2005, PHYS REV E, V72, DOI 10.1103/PhysRevE.72.026132
   Colizza V, 2007, NAT PHYS, V3, P276, DOI 10.1038/nphys560
   Cordasco G, 2019, THEOR COMPUT SCI, V764, P15, DOI 10.1016/j.tcs.2018.02.024
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Domingos P., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P57, DOI 10.1145/502512.502525
   Dorogovtsev SN, 2008, REV MOD PHYS, V80, P1275, DOI 10.1103/RevModPhys.80.1275
   Dorogovtsev SN, 2006, PHYS REV LETT, V96, DOI 10.1103/PhysRevLett.96.040601
   Feng ZD, 2007, LECT NOTES COMPUT SC, V4654, P385
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Freeman Linton C, 2016, A Set of Measures of Centrality Based on Betweenness, V40, P35
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Galhotra S, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P743, DOI 10.1145/2882903.2882929
   Garas A, 2010, NEW J PHYS, V12, DOI 10.1088/1367-2630/12/11/113043
   Goyal A., 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P211, DOI 10.1109/ICDM.2011.132
   Goyal A., 2011, P 20 INT C COMP WORL, P47, DOI [10.1145/1963192.1963217, DOI 10.1145/1963192.1963217]
   Guimerà R, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.065103
   Hu YM, 2016, INFORM SCIENCES, V355, P37, DOI 10.1016/j.ins.2016.03.028
   Iamnitchi A., 2002, Mapping the
   Jung K, 2012, IEEE DATA MINING, P918, DOI 10.1109/ICDM.2012.79
   Kempe David, 2003, P 9 ACM SIGKDD INT C, P137, DOI DOI 10.1145/956750.956769
   Kernighan B. W., 1970, Bell System Technical Journal, V49, P291
   Khomami MMD, 2016, INT J MOD PHYS B, V30, DOI 10.1142/S0217979216500429
   Kim J, 2013, PROC INT CONF DATA, P266, DOI 10.1109/ICDE.2013.6544831
   Kimura M, 2006, LECT NOTES ARTIF INT, V4213, P259
   Kitsak M, 2010, NAT PHYS, V6, P888, DOI [10.1038/NPHYS1746, 10.1038/nphys1746]
   Kleinberg J, 2007, Cascading behavior in networks: algorithmic and economic issues, DOI [10.1017/CBO9780511800481.015, DOI 10.1017/CBO9780511800481.015]
   Lawyer G, 2015, SCI REP-UK, V5, DOI 10.1038/srep08665
   Leskovec J., 2007, ACM T KNOWL DISCOV D, V1, P2, DOI [DOI 10.1145/1217299.1217301, 10.1145/1217299.1217301]
   Leskovec J, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P420
   Li DY, 2017, PHYSICA A, V471, P200, DOI 10.1016/j.physa.2016.12.038
   Li Y., 2013, P 6 ACM INT C WEB SE, P657
   Li Z, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44930-9
   Lin CC, 2015, INFORM SCIENCES, V299, P296, DOI 10.1016/j.ins.2014.12.009
   Liu ZY, 2019, INFORM SCIENCES, V482, P321, DOI 10.1016/j.ins.2019.01.028
   Lloyd-Smith JO, 2005, NATURE, V438, P355, DOI 10.1038/nature04153
   Lü LY, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021202
   Ma H, 2008, P 17 ACM C INF KNOWL, P233, DOI DOI 10.1145/1458082.1458115
   Ma TH, 2020, FUTURE GENER COMP SY, V105, P533, DOI 10.1016/j.future.2019.12.022
   Malliaros FD, 2016, SCI REP-UK, V6, DOI 10.1038/srep19307
   Malliaros FD, 2013, PHYS REP, V533, P95, DOI 10.1016/j.physrep.2013.08.002
   Moreno Y, 2002, EUR PHYS J B, V26, P521, DOI 10.1140/epjb/e20020122
   Morone F, 2016, SCI REP-UK, V6, DOI 10.1038/srep30062
   Morone F, 2015, NATURE, V524, P65, DOI 10.1038/nature14604
   Motter AE, 2004, PHYS REV LETT, V93, DOI 10.1103/PhysRevLett.93.098701
   Nguyen HT, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P695, DOI 10.1145/2882903.2915207
   Ochieng PJ, 2017, J PHYS CONF SER, V835, DOI 10.1088/1742-6596/835/1/012001
   Pan Y, 2010, PHYSICA A, V389, P2849, DOI 10.1016/j.physa.2010.03.006
   Parés F, 2018, STUD COMPUT INTELL, V689, P229, DOI 10.1007/978-3-319-72150-7_19
   Pastor-Satorras R, 2001, PHYS REV LETT, V86, P3200, DOI 10.1103/PhysRevLett.86.3200
   Pei S, 2018, COMPUT SOC SCI, P125, DOI 10.1007/978-3-319-77332-2_8
   Pinar Y, 2005, ISCIS
   Raghavan UN, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.036106
   Rameshkumar K, 2005, LECT NOTES COMPUT SC, V3612, P572
   Reppas AI, 2012, AIP CONF PROC, V1479, P1426, DOI 10.1063/1.4756427
   Rosenquist JN, 2010, ANN INTERN MED, V152, P426, DOI 10.7326/0003-4819-152-7-201004060-00007
   SABIDUSSI G, 1966, PSYCHOMETRIKA, V31, P581, DOI 10.1007/BF02289527
   Saito K, 2012, KNOWL INF SYST, V30, P613, DOI 10.1007/s10115-011-0396-2
   SEIDMAN SB, 1983, SOC NETWORKS, V5, P269, DOI 10.1016/0378-8733(83)90028-X
   Sheng JF, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121765
   Singh SS, 2020, SOFT COMPUT, V24, P10181, DOI 10.1007/s00500-019-04533-y
   Singh SS, 2019, APPL SOFT COMPUT, V82, DOI 10.1016/j.asoc.2019.105554
   Srinivas S, 2019, EXPERT SYST APPL, V135, P296, DOI 10.1016/j.eswa.2019.05.059
   Staudt CL, 2016, IEEE T PARALL DISTR, V27, P171, DOI 10.1109/TPDS.2015.2390633
   Tang JX, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.07.004
   Tang Y, 2014, In fl uence Maximization: Near-Optimal Time Complexity Meets Practical Ef fi ciency, P75
   Tang YZ, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1539, DOI 10.1145/2723372.2723734
   Taninmis K, 2019, EUR J OPER RES, V278, P105, DOI 10.1016/j.ejor.2019.04.010
   Teng Y. W., 2018, P 2018 SIAM INT C DA, P576, DOI DOI 10.1137/1.9781611975321.65
   Tong GM, 2017, IEEE ACM T NETWORK, V25, P112, DOI 10.1109/TNET.2016.2563397
   Venunath M, 2023, SOFT COMPUT, V27, P11041, DOI 10.1007/s00500-023-08391-7
   Venunath M, 2023, SOCIAL CAPITAL AGE O, P128, DOI [10.4018/978-1-6684-8953-6.ch010, DOI 10.4018/978-1-6684-8953-6.CH010]
   Venunath M., 2023, COMPUTATIONAL INTELL, P597, DOI [10.1007/978-981-19-3391-2_45, DOI 10.1007/978-981-19-3391-2_45]
   Wang F, 2018, FUTURE GENER COMP SY, V86, P1491, DOI 10.1016/j.future.2017.05.050
   Wang KXY, 2010, P 16 ACM SIGKDD INT, P1039
   Wang YT, 2009, LECT NOTES COMPUT SC, V5678, P350, DOI 10.1007/978-3-642-03348-3_34
   Wen S, 2015, IEEE T COMPUT, V64, P640, DOI 10.1109/TC.2013.2295802
   Williams David, 1991, CAMBRIDGE MATH TXB, DOI DOI 10.1017/CBO9780511813658
   Work R, 2016, Social Community Detection, V5, P1, DOI [10.1007/978-3-030-10767-3, DOI 10.1007/978-3-030-10767-3]
   Wu P, 2017, COMPUT NETW, V123, P38, DOI 10.1016/j.comnet.2017.05.004
   You XM, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.06.030
   Zalik KR, 2018, INFORM SCIENCES, V445, P38, DOI 10.1016/j.ins.2018.02.063
   Zhang HY, 2015, OPPORTUNISTIC MOBILE SOCIAL NETWORKS, P37
   Zhang JX, 2016, SCI REP-UK, V6, DOI 10.1038/srep27823
NR 102
TC 0
Z9 0
U1 12
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-17025-x
EA OCT 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600005
DA 2024-07-18
ER

PT J
AU Singh, S
   Singh, W
AF Singh, Simarpreet
   Singh, Williamjeet
TI AI-based personality prediction for human well-being from text data: a
   systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Personality measurement; Human well-being; Transfer learning; Systematic
   review; Deep learning; Text classification; Natural language processing
ID SOCIAL MEDIA; DIGITAL TWINS; RECOGNITION; EMBEDDINGS; SENTIMENT;
   NETWORKS; TRAITS; USER
AB In recent years, people have preferred interacting on social media instead of physical meetings. Researchers have explored social media text data to predict user personality using AI techniques automatically. To date, no comprehensive analysis offers a unified view of the literature in the area. To help researchers better understand the state-of-the-art, we summarise datasets, feature selection, text mapping, and AI techniques for personality prediction from text data. The standard systematic literature review protocol was followed, and the articles published between 2016 and 2022 were selected for the review. Measuring all the personality traits with a single AI model is quite difficult. The contribution of this systematic literature review shows that the increased efforts in personality prediction will surely help measure the Subjective Well-Being of an individual or a group. We conclude our work by providing an extensive discussion pointing requirement of labelled datasets, multiple personality dimensions, and advanced AI-based technologies to make an optimal system to predict personality.
C1 [Singh, Simarpreet; Singh, Williamjeet] Punjabi Univ, Dept Comp Sci & Engn, Rajpura Rd, Patiala 147002, Punjab, India.
C3 Punjabi University
RP Singh, S (corresponding author), Punjabi Univ, Dept Comp Sci & Engn, Rajpura Rd, Patiala 147002, Punjab, India.
EM simarpreetsinghbangar@gmail.com; williamjeet@gmail.com
OI Singh, Simarpreet/0000-0002-4168-8556
CR Adhikari A, 2019, Arxiv, DOI arXiv:1904.08398
   Agastya IMA, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON COMPUTING, ENGINEERING, AND DESIGN (ICCED), DOI 10.1109/icced46541.2019.9161107
   Ahmad H, 2020, OPEN COMPUT SCI, V10, P175, DOI 10.1515/comp-2020-0188
   Akhtar R, 2018, PERS INDIV DIFFER, V132, P90, DOI 10.1016/j.paid.2018.05.026
   Albawi S, 2017, I C ENG TECHNOL
   An GZ, 2018, INTERSPEECH, P1761, DOI 10.21437/Interspeech.2018-2263
   Anari MS, 2022, MULTIMED TOOLS APPL, V81, P10673, DOI 10.1007/s11042-022-12295-3
   [Anonymous], 2007, Spring research presentation: a theoretical foundation for inductive transfer
   [Anonymous], 2014, INT C MACHINE LEARNI
   [Anonymous], ALJAZEERA
   Arnoux P.-H., 2017, Proceedings of the International AAAI Conference on Web and Social Media, V11, P472
   Azucar D, 2018, PERS INDIV DIFFER, V124, P150, DOI 10.1016/j.paid.2017.12.018
   BARRICK MR, 1991, PERS PSYCHOL, V44, P1, DOI 10.1111/j.1744-6570.1991.tb00688.x
   Bharadwaj S, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1076, DOI 10.1109/ICACCI.2018.8554828
   Biel JI, 2013, IEEE T MULTIMEDIA, V15, P41, DOI 10.1109/TMM.2012.2225032
   Bin Siddique F, 2017, INTERSPEECH, P3271, DOI 10.21437/Interspeech.2017-1379
   Blackburn, 2015, DEV PSYCHOMETRIC PRO
   Briggs K., 1987, Myers-Briggs Type Indicator
   Cavnar WB, 1994, Using an N-Gram-based document representation with a vector processing retrieval model
   Celli F., 2013, P INT AAAI C WEB SOC, V7, P2
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen K-J., 1996, PROCEEDING 11 PACIFI, P167
   Chhabra GS, 2019, IOP conference series: materials science and engineering, V495
   Christian H, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00459-1
   CKIP Lab Publications, About Us
   CONNOR JT, 1994, IEEE T NEURAL NETWOR, V5, P240, DOI 10.1109/72.279188
   Darliansyah A, 2019, J UNIVERS COMPUT SCI, V25, P1323
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Diener E, 2006, AM PSYCHOL, V61, P305, DOI 10.1037/0003-066X.61.4.305
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Doosti B, 2020, PROC CVPR IEEE, P6607, DOI 10.1109/CVPR42600.2020.00664
   Doval Y., 2016, CEUR Workshop Proc, V1737, P33
   El Saddik A, 2018, IEEE MULTIMEDIA, V25, P87, DOI 10.1109/MMUL.2018.023121167
   El-Demerdash K, 2022, EGYPT INFORM J, V23, P47, DOI 10.1016/j.eij.2021.05.004
   Farnadi G, 2016, USER MODEL USER-ADAP, V26, P109, DOI 10.1007/s11257-016-9171-0
   Feizi-Derakhshi AR, Text-based automatic personality prediction: a bibliographic review, DOI [10.1007/s42001-022-00178-4, DOI 10.1007/S42001-022-00178-4]
   Finn C, 2017, PR MACH LEARN RES, V70
   Flask, about us
   github, Jieba Jieba Segmenter
   Gjurkovic M., 2018, REDDIT GOLD MINE PER, P87
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Halim Z, 2021, MULTIMED TOOLS APPL, V80, P33377, DOI 10.1007/s11042-021-11419-5
   Halim Z, 2020, INFORM FUSION, V53, P66, DOI 10.1016/j.inffus.2019.06.006
   Halim Z, 2019, IEEE T AFFECT COMPUT, V10, P568, DOI 10.1109/TAFFC.2017.2751602
   Harary F., 1994, Graph Theory
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hernández Y, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12062985
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Huang C. L., 2012, CHINESE J PSYCHOL, V54, P185, DOI DOI 10.6129/CJP.2012.5402.04
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Isabel Myers PM, 2010, Gifts differing: understanding personality type
   J M (MBTI, Myers-Briggs personality type dataset
   Jeremy NH, 2021, PROCEDIA COMPUT SCI, V179, P416, DOI 10.1016/j.procs.2021.01.024
   Jiang H, 2020, AAAI CONF ARTIF INTE, V34, P13821
   Josan G., 2017, Personality prediction from Facebook posts in Gurmukhi script, V3, P31
   Kahlon NK, 2023, UNIVERSAL ACCESS INF, V22, P1, DOI 10.1007/s10209-021-00823-1
   Kazameini A, 2020, Arxiv, DOI arXiv:2010.01309
   Kosinski M, 2015, AM PSYCHOL, V70, P543, DOI 10.1037/a0039210
   Kosinski M, 2013, P NATL ACAD SCI USA, V110, P5802, DOI 10.1073/pnas.1218772110
   Kulkarni A., 2019, NATURAL LANGUAGE PRO
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Levitan SI, 2016, P INT C SPEECH PROS
   Li Y, 2021, Arxiv, DOI arXiv:2101.02346
   Liu F, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P754
   Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692
   Low LSA, 2010, INT CONF ACOUST SPEE, P5154, DOI 10.1109/ICASSP.2010.5495018
   Lukito LC, 2016, PROCEEDINGS OF 2016 8TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND ELECTRICAL ENGINEERING (ICITEE)
   Luong T, 2015, Bilingual word representations with monolingual quality in mind
   Mairesse F, 2007, J ARTIF INTELL RES, V30, P457, DOI 10.1613/jair.2349
   Majumder N, 2017, IEEE INTELL SYST, V32, P74, DOI 10.1109/MIS.2017.23
   Marston WM, 2011, Emotions of normal people
   Mastorakis NE, 1999, Recent Adv Signal Process Commun, P7
   Mehta Y, 2020, ARTIF INTELL REV, V53, P2313, DOI 10.1007/s10462-019-09770-z
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P52
   Mishra NK, 2022, MULTIMED TOOLS APPL, V81, P21503, DOI 10.1007/s11042-022-12548-1
   Moffitt K, 2010, Spring, P1
   Moffitt KC, 2012, P RAP SCREEN TECHN D
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   O'Malley AJ, 2008, HEALTH SERV OUTCOME, V8, P222, DOI 10.1007/s10742-008-0041-z
   Ong V, 2017, FED CONF COMPUT SCI, P367, DOI 10.15439/2017F359
   Otter D.W., 2018, A Survey of the Usages of Deep Learning in Natural Language Processing
   Owoputi O, 2013, NAACL HLT 2013 2013
   Pennebaker J.W., 2001, Linguistic inquiry and word count: LIWC 2001, V71, P1
   Pennebaker JW, 1999, J PERS SOC PSYCHOL, V77, P1296, DOI 10.1037/0022-3514.77.6.1296
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pereira Junior RA, 2017, Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics)
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Personality cafe, About Us
   Popov V, 2015, Psychometrics Center of the University of Cambridge, P1
   Pradhan Tejas, 2020, Proceedings of Second International Conference on Inventive Research in Computing Applications (ICIRCA 2020), P457, DOI 10.1109/ICIRCA48905.2020.9183090
   Qaiser S., 2018, International Journal of Computer Applications, V181, P25, DOI [10.5120/ijca2018917395, DOI 10.5120/IJCA2018917395]
   Ragab M., 2019, Future Comput Informat J, V4, P79
   Rahaman MA, 2019, 1 INT C ADV SCI ENG
   Rahman AU, 2022, IEEE T COMPUT SOC SY, DOI 10.1109/TCSS.2022.3201153
   Rahman AU, 2022, MULTIMED TOOLS APPL, V81, P33671, DOI 10.1007/s11042-022-13114-5
   Ramezani M, arXiv
   Ramicic M, 2019, COGN SYST RES, V55, P124, DOI 10.1016/j.cogsys.2019.01.006
   Rammstedt B, 2007, J RES PERS, V41, P203, DOI 10.1016/j.jrp.2006.02.001
   Rayne H, Predicting Myers-Briggs type indicator with text classification
   Remaida A, 2020, 3RD INTERNATIONAL CONFERENCE ON NETWORKING, INFORMATION SYSTEM & SECURITY (NISS'20), DOI 10.1145/3386723.3387884
   Salminen Joni, 2020, Artificial Intelligence in HCI. First International Conference, AI-HCI 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12217), P101, DOI 10.1007/978-3-030-50334-5_7
   Sammut C., 2010, Encyclopedia of Machine Learning, P986, DOI [10.1007/978-0-387-30164-8_832, DOI 10.1007/978-0-387-30164-8_832]
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sharma E., 2021, Turkish J Comput Math Educ, V12, P5225
   Sinaga KP, 2020, IEEE ACCESS, V8, P80716, DOI 10.1109/ACCESS.2020.2988796
   Singh J, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100279
   Singh P., 2014, P ICCCCS, P741, DOI [10.1007/978-981-10-3770-2_70, DOI 10.1007/978-981-10-3770-2_70]
   Singh S, 2016, 2016 FOURTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P90, DOI 10.1109/PDGC.2016.7913121
   Speer R, 2018, Arxiv, DOI arXiv:1612.03975
   Stammatatos E, 2015, CLEF 2015 LABS WORKS
   Su MH, 2016, IEEE-ACM T AUDIO SPE, V24, P733, DOI 10.1109/TASLP.2016.2531286
   Sun JS, 2021, INT J COMPUT INTEG M, V34, P860, DOI 10.1080/0951192X.2020.1757155
   Sun X, 2018, IEEE INT C COMM MAY, V2018
   Sun XG, 2020, WORLD WIDE WEB, V23, P1887, DOI 10.1007/s11280-019-00729-2
   Tadesse MM, 2018, IEEE ACCESS, V6, P61959, DOI 10.1109/ACCESS.2018.2876502
   Tandera T, 2017, PROCEDIA COMPUT SCI, V116, P604, DOI 10.1016/j.procs.2017.10.016
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   Tian L, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1837
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Tseng SC., 2004, Traitement Automatique des Langes, V45, P89
   Vinciarelli A, 2014, IEEE T AFFECT COMPUT, V5, P273, DOI 10.1109/TAFFC.2014.2330816
   Wei HH, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P305, DOI 10.1145/3018661.3018717
   Whissell C. M., 1989, The Measurement of Emotions, P113, DOI 10.1016/B978-0-12-558704-4.50011-6
   Xue D, 2018, APPL INTELL, V48, P4232, DOI 10.1007/s10489-018-1212-4
   Xue X, 2021, APPL INTELL, V51, P7705, DOI 10.1007/s10489-021-02277-7
   Yang WZ, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12040075
   Yang ZL, 2019, ADV NEUR IN, V32
   Yu JG, 2017, INT CONF AWARE SCI, P383, DOI 10.1109/ICAwST.2017.8256484
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
   Zhang Y, 2017, ACM INT C P SERIES
   Zhu Y, 2020, INT J ELEC ENG EDUC, DOI 10.1177/0020720920936839
NR 134
TC 0
Z9 0
U1 8
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17282-w
EA OCT 2023
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000014
DA 2024-07-18
ER

PT J
AU Gayatri, E
   Aarthy, SL
AF Gayatri, Erapaneni
   Aarthy, S. L.
TI Classification of skin cancer using deep batch-normalized elu alexnet
   with fractional sparrow ladybug optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE DoubleU-Net; Deep Batch-normalized eLU AlexNet; Sparrow Search
   Algorithm; Ladybug Beetle Optimization; Fractional calculus
AB Skin cancer is the most commonly found kind of cancer with eight diagnostic classes, which makes its classification highly challenging. Recent years have witnessed the increased utilization of Computer-Aided Diagnosis (CAD) systems in several medical imaging processes, even in identifying skin cancer. Though multiple methods have been developed in the past to classify skin cancer, the high similarity of the skin cancer lesions with the surrounding skin makes classification a tedious process. A Deep Learning (DL) technique is introduced in this work for classifying skin cancer into eight classes based on skin images. This work presents two novel contributions to skin lesion segmentation and classification. Here, a technique for segmenting skin lesions is presented using DoubleU-Net, whose structure is optimized by the Sparrow Ladybug Beetle Optimization (SLBO). Further, a Fractional SLBO-Deep Batch-normalized eLU AlexNet (FSLBO-DbneAlexnet) is developed for classifying skin cancer. In addition to this, the competence of the FSLBO-DbneAlexnet in skin cancer classification is examined by considering accuracy, False Negative Rate (FNR), False Positive Rate (FPR), True Negative Rate (TNR), and True Positive Rate (TPR), and is found to produce superior values of 0.911, 0.080, 0.081, 0.919, and 0.920, respectively.
C1 [Gayatri, Erapaneni] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore 632014, Tamil Nadu, India.
   [Aarthy, S. L.] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Aarthy, SL (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
EM erapaneni.gayatri2019@vitstudent.ac.in; aarthy.sl@vit.ac.in
FU I would like to express my very great appreciation to the co-authors of
   this manuscript for their valuable and constructive suggestions during
   the planning and development of this research work.
FX I would like to express my very great appreciation to the co-authors of
   this manuscript for their valuable and constructive suggestions during
   the planning and development of this research work.
CR Abdar M, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104418
   Ahmad B, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11112147
   Alaeddine H, 2021, INT MULTICONF SYST, P17, DOI 10.1109/SSD52085.2021.9429404
   [Anonymous], The ISIC challenge Data Set
   Ashraf R, 2020, IEEE ACCESS, V8, P147858, DOI 10.1109/ACCESS.2020.3014701
   Atta A, 2022, PROCEEDING INT C CYB
   Bassel A, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102472
   Bhaladhare P.R., 2014, Adv. Comput. Eng., V2014
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Chilakala LR, 2021, INT J IMAG SYST TECH, V31, P1404, DOI 10.1002/ima.22515
   Dalal S, 2022, WORLD J GASTROENTERO, V28, P6551, DOI 10.3748/wjg.v28.i46.6551
   Dalal S, 2023, INT J MODEL SIMUL SC, V14, DOI 10.1142/S1793962323410234
   Dildar M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18105479
   El Khadiri I, 2018, COMPUT VIS IMAGE UND, V169, P14, DOI 10.1016/j.cviu.2018.01.004
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Fraiwan M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22134963
   Gayatri E, 2023, INT J IMAGE GRAPH, V23, DOI 10.1142/S0219467822400125
   Jain M, 2019, SWARM EVOL COMPUT, V44, P148, DOI 10.1016/j.swevo.2018.02.013
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Kaissis G, 2021, NAT MACH INTELL, V3, P473, DOI 10.1038/s42256-021-00337-8
   Kausar N, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112210593
   Lessa V, 2016, LECT NOTES COMPUT SC, V9972, P429, DOI 10.1007/978-3-319-46418-3_38
   Mukadam SB, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13021210
   Onyema EM., 2023, Meas Sens, V26, P100679, DOI [10.1016/j.measen.2023.100679, DOI 10.1016/J.MEASEN.2023.100679]
   Pacheco AGC, 2021, IEEE J BIOMED HEALTH, V25, P3554, DOI 10.1109/JBHI.2021.3062002
   Rehman MZU, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22186915
   Safiri S, 2023, J SUPERCOMPUT, V79, P3511, DOI 10.1007/s11227-022-04755-2
   Shamshad F., 2022, arXiv
   Su R, 2020, NEUROCOMPUTING, V385, P300, DOI 10.1016/j.neucom.2019.12.083
   Wu F, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101634
   Xin C, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.105939
   Xue JK, 2020, SYST SCI CONTROL ENG, V8, P22, DOI 10.1080/21642583.2019.1708830
   Zulpe N., 2012, Int. J. Comput. Sci. Issues (IJCSI), V9, P354
NR 33
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-16999-y
EA OCT 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400009
DA 2024-07-18
ER

PT J
AU Nair, DS
   Mol, MB
AF Nair, Deepthy S.
   Mol, M. Beena
TI Enhancing seismic performance prediction of RC frames using MFF-ANN
   model approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Seismic drift; Displacement prediction; RC building; Artificial neural
   network
ID AVERAGING FUSION STRATEGY; OPTIMIZATION; DESIGN
AB The seismic response of human-made structures to ground shaking caused by earthquakes can lead to catastrophic damage. Seismic investigation, a sub-discipline of primary examination, is utilized to evaluate the seismic reaction of designs. Artificial intelligence has emerged as a solution to address this problem. The seismic response of reinforced concrete (RC) is investigated in this research using an artificial neural network (ANN) structures to ground motions. The evaluation of a structure's seismic response is crucial for upgrading a building or its components. As a novelty of this study, Extended three-dimensional analysis of building systems (ETABS) is used to determine the seismic response of all structures, which serves as target data for designing the ANN. Symmetrical buildings are stimulated using various ground motions, and the resulting input and target data are used to construct an ANN in MATLAB. A novel multi feed-forward type of ANN (MFF-ANN) with the Levenberg Marquedt algorithm is employed. The input parameters that produce the lowest error and highest accuracy for forecasting the seismic response of RC multistory buildings are identified. The significance of each parameter used in the input layer contributing to the maximum accuracy is determined, along with the percentage of each parameter contributing to the optimal network.
C1 [Nair, Deepthy S.] Noorul Islam Univ Nagercoil, Dept Civil Engn, Nagercoil, India.
   [Mol, M. Beena] LBS Coll Engn, Dept Civil Engn, Kasargod, India.
C3 L.B.S College of Engineering
RP Nair, DS (corresponding author), Noorul Islam Univ Nagercoil, Dept Civil Engn, Nagercoil, India.
EM 91deepthy@gmail.com; beenamol@lbscek.ac.in
RI , BEENA MOL M/KHU-7143-2024
OI , DEEPTHY/0000-0002-2719-5245; M, BEENA MOL/0000-0002-3898-3060
CR Abbas Mohsin, 2021, Arabian Journal of Geosciences, V14, DOI 10.1007/s12517-021-07664-5
   Ahmed B, 2022, J BUILD ENG, V46, DOI 10.1016/j.jobe.2021.103737
   Ali U, 2020, SOIL DYN EARTHQ ENG, V132, DOI 10.1016/j.soildyn.2020.106046
   Bao XK, 2021, THEOR APPL FRACT MEC, V111, DOI 10.1016/j.tafmec.2020.102853
   Davies TRH, 2020, LANDSLIDES, V17, P3, DOI 10.1007/s10346-019-01224-5
   Deeks J. J., 2008, Cochrane Handbook for Systematic Reviews of Interventions, P243, DOI DOI 10.1002/9781119536604
   Divya R, 2021, MATER TODAY-PROC, V46, P8848, DOI 10.1016/j.matpr.2021.04.391
   Falcone R, 2022, STRUCTURES, V41, P1220, DOI 10.1016/j.istruc.2022.05.008
   Golafshani EM, 2020, CONSTR BUILD MATER, V232, DOI 10.1016/j.conbuildmat.2019.117266
   Gupta R, 2021, MOL DIVERS, V25, P1315, DOI 10.1007/s11030-021-10217-3
   Indian Standard (IS), IS 875 Part I 2003
   Indian Standard (IS), 1987, IS 875 Part II
   Inzunza-Aragon I, 2022, ADV CIV ENG, V2022, DOI 10.1155/2022/4219524
   Jomard H, 2021, J S AM EARTH SCI, V111, DOI 10.1016/j.jsames.2021.103406
   Kalinathan L, 2020, Nuclei detection in hepatocellular carcinoma and dysplastic liver nodules in histopathology images using bootstrap regression
   Kanmani M, 2019, INT J BIOMED ENG TEC, V31, P278
   Kanmani M, 2017, MULTIMED TOOLS APPL, V76, P20989, DOI 10.1007/s11042-016-4030-x
   Karimzadeh S, 2019, SOIL DYN EARTHQ ENG, V123, P525, DOI 10.1016/j.soildyn.2019.05.024
   Leng JZ, 2020, EARTHQ ENG STRUCT D, V49, P394, DOI 10.1002/eqe.3245
   Madheswari K, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2826, DOI 10.1109/TENCON.2016.7848558
   Madheswari K, 2017, QUANT INFR THERM J, V14, P24, DOI 10.1080/17686733.2016.1229328
   Amiruddin AAAM, 2020, NEURAL COMPUT APPL, V32, P447, DOI 10.1007/s00521-018-3911-5
   Morfidis K, 2019, ENG STRUCT, V197, DOI 10.1016/j.engstruct.2019.109436
   Nguyen HD, 2021, ENG STRUCT, V242, DOI 10.1016/j.engstruct.2021.112518
   Nie Y, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106809
   Oh BK, 2020, J SOUND VIB, V468, DOI 10.1016/j.jsv.2019.115109
   Pribadi KS, 2021, INT J DISAST RISK RE, V64, DOI 10.1016/j.ijdrr.2021.102424
   Rachedi M, 2021, ENG STRUCT, V232, DOI 10.1016/j.engstruct.2020.111800
   Ramirez E, 2019, Structural analysis of historical constructions, P1346
   Roy T, 2019, STRUCT INFRASTRUCT E, V15, P252, DOI 10.1080/15732479.2018.1547768
   Sahoo BB, 2019, ACTA GEOPHYS, V67, P1471, DOI 10.1007/s11600-019-00330-1
   Singh V., 2019, Int. J. Trend Scientific Res. Development, V3, P724, DOI [10.31142/ijtsrd22985, DOI 10.31142/IJTSRD22985]
   Stefanini L, 2022, INT J DISAST RISK RE, V67, DOI 10.1016/j.ijdrr.2021.102677
   Tang JS, 2019, ADV MATER, V31, DOI 10.1002/adma.201902761
   Theresa XB., 2018, INT J APPL ENG RES, V13, P8831
   Zhu M, 2021, NEUROCOMPUTING, V429, P110, DOI 10.1016/j.neucom.2020.11.068
NR 36
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-16931-4
EA OCT 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400001
DA 2024-07-18
ER

PT J
AU Ajmal, S
   Sarfraz, MS
   Memon, I
   Bilal, M
   Alam, KA
AF Ajmal, Sahar
   Sarfraz, Muhammad Shahzad
   Memon, Imran
   Bilal, Muhammad
   Alam, Khubaib Amjad
TI PUB-VEN: a personalized recommendation system for suggesting publication
   venues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recommendation System; Publication Venues; Journals; Content-Based
   Filtering; Collaborative Filtering; Hybrid Model; Multi-Criteria
   Decision Making
ID FRAMEWORK; JOURNALS
AB Researchers would like to publish their research articles in reputed journals along with quick review time. However, with the growing number of academic publications, it is becoming more difficult for scholars to find venues that are relevant to their domain. This study aims on the development of a technique that focuses on the priorities of the researchers that are linked to the recommendation of suitable suggestion of publication journal. The developed Recommendation System (RS) takes title, abstract, and keyword of the manuscript to be submitted. The proposed algorithm, named PUB-VEN which is hybridization of Content-Based Filtering (CBF), and Collaborative Filtering (CF), which is integrated with the Multi-Criteria Decision Making (MCDM) process to provide suitable journal recommendations by considering the researcher's point of view about different attributes gathered such as impact factor, eigen factor, average review time, etc. which affect the research process effectively. Our results demonstrate that the PUB-VEN provides better recommendations in comparison with state-of-the-art algorithms such as Term Frequency and Inverse Document Frequency (TF-IDF) and Latent Semantic Analysis (LSA). The study concluded that PUB-VEN is providing better precision, recall, F1 Score, Discounted Cumulative Gain (DCG), and Normalized DCG (NCDG). For precision, the gain ranges from 1% to 16%, the improvement in recall is between 33% and 3%, the betterment of result in F1 is by the ratio which ranges from 27% and 2%, the improvement in the result of DCG lies between 15% and 5% and the result of NDCG gain ranges from 6% to 1%. It is useful for the researchers in finding suitable venue for publication.
C1 [Ajmal, Sahar; Sarfraz, Muhammad Shahzad] Natl Univ Comp & Emerging Sci, FAST Sch Comp, Chiniot Faisalabad Campus, Islamabad 35400, Chiniot, Pakistan.
   [Memon, Imran; Bilal, Muhammad] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
   [Alam, Khubaib Amjad] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Islamabad Campus, Islamabad 44000, Pakistan.
C3 Zhejiang University
RP Memon, I (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
EM sahar.ajmal@nu.edu.pk; imranmemon52@zju.edu.cn
RI Bilal, PhD, Muhammad/F-3615-2018; memon, imran/K-1647-2017
OI Bilal, PhD, Muhammad/0000-0002-0915-6138; memon,
   imran/0000-0002-8202-6604
FU Thank for reviewer to improve our paper
FX Thank for reviewer to improve our paper
CR Agarwal D., 2010, P 3 ACM INT C WEB SE, P91, DOI [10.1145/1718487.1718499, DOI 10.1145/1718487.1718499]
   Ajmal S, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON COMPUTING, ENGINEERING, AND DESIGN (ICCED), DOI 10.1109/icced46541.2019.9161106
   Alghamdi R, 2015, INT J ADV COMPUT SC, V6, P147
   Alhoori H, 2017, J INFORMETR, V11, P553, DOI 10.1016/j.joi.2017.03.006
   Alshareef AM, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P55, DOI 10.1109/IRI.2018.00016
   Asabere NY, 2014, IEEE T HUM-MACH SYST, V44, P689, DOI 10.1109/THMS.2014.2325837
   Boukhris I, 2014, INT SYMP COMP INTELL, P465, DOI 10.1109/CINTI.2014.7028720
   Bozanta A, 2019, J INF SCI, V45, P212, DOI 10.1177/0165551518786678
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Çano E, 2017, INTELL DATA ANAL, V21, P1487, DOI 10.3233/IDA-163209
   Chang DY, 1996, EUR J OPER RES, V95, P649, DOI 10.1016/0377-2217(95)00300-2
   Chen L, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10020214
   Chen Z, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P579, DOI 10.1145/2740908.2741738
   Duan C, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10131581
   Dwivedi YK, 2022, INT J INFORM MANAGE, V62, DOI 10.1016/j.ijinfomgt.2021.102426
   Haruna K, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184516
   Hiep Luong, 2012, Proceedings of the 4th International Conference on Knowledge Discovery and Information Retrieval. KDIR 2012, P239
   Luong H, 2012, LECT NOTES ARTIF INT, V7198, P426, DOI 10.1007/978-3-642-28493-9_45
   Holzinger A, 2019, MACH LEARN KNOW EXTR, V1, P1, DOI 10.3390/make1010001
   Hornick MF, 2012, IEEE T KNOWL DATA EN, V24, P1478, DOI 10.1109/TKDE.2011.90
   Huh JH, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10040093
   Iana A, 2021, ACM-IEEE J CONF DIG, P90, DOI 10.1109/JCDL52503.2021.00021
   Jain S, 2019, ADV INTELL SYST, V740, P99, DOI 10.1007/978-981-13-1280-9_9
   Basgall MJ, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10151757
   Kang N, 2015, P 9 ACM C REC SYST A, P261, DOI [10.1145/2792838.2799663, DOI 10.1145/2792838.2799663]
   Kauffmann E, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11154235
   Ko H, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010141
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kreutz CK, 2022, INT J DIGIT LIBRARIE, V23, P335, DOI 10.1007/s00799-022-00339-w
   Küçüktunç O, 2013, ACM-IEEE J CONF DIG, P433
   Lewallen LP, 2010, J PROF NURS, V26, P250, DOI 10.1016/j.profnurs.2009.12.005
   Lops P, 2011, RECOMMENDER SYSTEMS HANDBOOK, P73, DOI 10.1007/978-0-387-85820-3_3
   LOVINS JB, 1968, MECH TRANSL, V11, P22
   Lu J, 2015, DECIS SUPPORT SYST, V74, P12, DOI 10.1016/j.dss.2015.03.008
   McKercher B, 2015, TOURISM MANAGE, V51, P306, DOI 10.1016/j.tourman.2015.05.012
   Medvet E, 2014, PROC INT C TOOLS ART, P1004, DOI 10.1109/ICTAI.2014.152
   Mhirsi Nour, 2017, INT C INT SYST DES A, P83
   Mohamed MH, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMPUTER ENGINEERING (ITCE 2019), P149, DOI [10.1109/ITCE.2019.8646645, 10.1109/itce.2019.8646645]
   Mukherjee P, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su131910579
   Muzammil MB, 2021, 2021 INT C ENG EM TE, P1
   Pham M, 2010, P I KNOW CIT
   Pham MC, 2011, J UNIVERS COMPUT SCI, V17, P583
   Pradhan T, 2021, INFORM SCIENCES, V559, P212, DOI 10.1016/j.ins.2020.12.024
   Pradhan T, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106181
   Pradhan T, 2020, FUTURE GENER COMP SY, V110, P1139, DOI 10.1016/j.future.2019.11.017
   Pradhan T, 2020, KNOWL-BASED SYST, V189, DOI 10.1016/j.knosys.2019.105092
   Rollins J., 2017, CEUR Workshop Proceedings, V1823, P18
   Safa R., 2017, Journal of Information Systems and Telecommunication, V1, P209
   Schafer J. B., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P291
   Schuemie MJ, 2008, BIOINFORMATICS, V24, P727, DOI 10.1093/bioinformatics/btn006
   Silva T, 2015, J ASSOC INF SCI TECH, V66, P180, DOI 10.1002/asi.23150
   Singh V., 2014, An effective tokenization algorithm for information retrieval systems, DOI [10.5121/csit.2014.4910, DOI 10.5121/CSIT.2014.4910]
   Stitini O, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11020242
   Taherdoost H., 2023, Encyclopedia, V3, P77, DOI DOI 10.3390/ENCYCLOPEDIA3010006
   Triantaphyllou E., 2000, MULTICRITERIA DECISI, P5, DOI [10.1007/978-1-4757-3157-6_2, DOI 10.1007/978-1-4757-3157-6_2, 10.1007/978-1-4757-3157-62, DOI 10.1007/978-1-4757-3157-62]
   Wang DH, 2018, KNOWL-BASED SYST, V157, P1, DOI 10.1016/j.knosys.2018.05.001
   Wang S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10151769
   Wongchokprasitti C, 2010, C NAV 2 0 COMM BAS R
   Xia F, 2013, 2013 IEEE 10TH INTERNATIONAL CONFERENCE ON AND 10TH INTERNATIONAL CONFERENCE ON AUTONOMIC AND TRUSTED COMPUTING (UIC/ATC) UBIQUITOUS INTELLIGENCE AND COMPUTING, P134, DOI 10.1109/UIC-ATC.2013.81
   Yang Q, 2019, WORLD WIDE WEB, V22, P2499, DOI 10.1007/s11280-019-00687-9
   YANG Z, 2012, P 12 ACM IEEE CS JOI, P371
   Yang ZH, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P681, DOI 10.1109/ICMLA.2012.127
   Yu S, 2018, J NETW COMPUT APPL, V104, P38, DOI 10.1016/j.jnca.2017.12.004
   Zhang AX, 2016, PROCEEDINGS OF THE 19TH ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING COMPANION, P118, DOI 10.1145/2818052.2874340
   Zhang HZ, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11040547
   Zhu C, 2018, Journal Impact Factor (JCR 2018), V2018
   Zhuang YY, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13148039
   Ziarani RJ, 2021, J COMPUT SCI TECH-CH, V36, P375, DOI 10.1007/s11390-020-0135-9
NR 68
TC 1
Z9 1
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 14
PY 2023
DI 10.1007/s11042-023-16798-5
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KR8
UT WOS:001082467000002
DA 2024-07-18
ER

PT J
AU Agarwal, S
   Jung, KH
AF Agarwal, Saurabh
   Jung, Ki-Hyun
TI Forensic analysis and detection using polycolor model binary pattern for
   colorized images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image forensics; Colorized image detection; Polycolor model binary
   pattern
AB Image recoloring is used to colorize historic grayscale images. Recoloring gives new life to grayscale images with realistic colors. Several techniques exist that can colorize grayscale images. Sometimes attackers create a realistic fake image using colorization techniques. Consequently, there is a need for some technique that can differentiate between natural color and colorized image to stop the misuse of the colorization techniques. In this paper, a Polycolor Model Binary Pattern (PMBP) is proposed to extract robust internal statistical features. Several color models such as RGB, YUV, YCbCr, and HSV are considered to fetch crucial statistical information from an image. A novel Polycolor Model Binary Pattern is formed using the effective channels of several color models. The proposed method gives promising results on non-compressed colorized images as well as on highly compressed colorized images. The efficacy of the proposed detection technique is verified on three fully automated deep learning-based colorization techniques. Three diverse image databases are used to assess the performance. Linear Discriminant Analysis classifier is utilized to classify natural color and colorized images from extracted features, whereas the inverse of the covariance matrix is calculated by using the Moore-Penrose Pseudo Inverse Matrix (MPPM).
C1 [Agarwal, Saurabh] Amity Univ Uttar Pradesh, Amity Sch Engn & Technol, Noida, India.
   [Agarwal, Saurabh; Jung, Ki-Hyun] Andong Natl Univ, Dept Software Convergence, Andong 36729, Gyeongbuk, South Korea.
C3 Amity University Noida; Andong National University
RP Jung, KH (corresponding author), Andong Natl Univ, Dept Software Convergence, Andong 36729, Gyeongbuk, South Korea.
EM saurabhnsit2510@gmail.com; khanny.jung@gmail.com
FU This research was supported by Brain Pool program funded by the Ministry
   of Science and ICT through the National Research Foundation of Korea
   (2019H1D3A1A01101687) and Basic Science Research Program through the
   National Research Foundation of Korea (NRF) f [2019H1D3A1A01101687];
   Brain Pool program - Ministry of Science and ICT through the National
   Research Foundation of Korea [2021R1I1A3049788]; Basic Science Research
   Program through the National Research Foundation of Korea (NRF) -
   Ministry of Education
FX This research was supported by Brain Pool program funded by the Ministry
   of Science and ICT through the National Research Foundation of Korea
   (2019H1D3A1A01101687) and Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (2021R1I1A3049788).
CR Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Agarwal S, 2017, P 2016 9 INT C CONT, DOI [10.1109/IC3.2016.7880221, DOI 10.1109/IC3.2016.7880221]
   Agarwal S, 2018, J APPL SEC RES, V13, P209, DOI 10.1080/19361610.2017.1422367
   Arbelot B, 2017, COMPUT GRAPH-UK, V62, P15, DOI 10.1016/j.cag.2016.12.005
   Bao B, 2019, COMPUT GRAPH-UK, V81, P73, DOI 10.1016/j.cag.2019.04.003
   Barni M, 2017, J VIS COMMUN IMAGE R, V49, P153, DOI 10.1016/j.jvcir.2017.09.003
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Fang FM, 2020, IEEE T VIS COMPUT GR, V26, P2931, DOI 10.1109/TVCG.2019.2908363
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Górecki T, 2013, INT J AP MAT COM-POL, V23, P463, DOI 10.2478/amcs-2013-0035
   Guo YF, 2018, IEEE T INF FOREN SEC, V13, P1932, DOI 10.1109/TIFS.2018.2806926
   Gupta S, 2020, PATTERN ANAL APPL, V23, P1569, DOI 10.1007/s10044-020-00879-4
   Iizuka S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925974
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Kumar R, 2019, J INF SECUR APPL, V47, P94, DOI 10.1016/j.jisa.2019.04.007
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Li YZ, 2019, IFIP ADV INF COMM TE, V569, P201, DOI 10.1007/978-3-030-28752-8_11
   Lim TS, 2000, MACH LEARN, V40, P203, DOI 10.1023/A:1007608224229
   Maenpaa T., 2005, Handbook of Pattern Recognition and Computer Vision, V3rd, P197
   Mouzon T, 2019, LECT NOTES COMPUT SC, V11603, P535, DOI 10.1007/978-3-030-22368-7_42
   Phutke Shruti S., 2022, Computer Vision and Image Processing: 6th International Conference, CVIP 2021, Revised Selected Papers. Communications in Computer and Information Science (1568), P73, DOI 10.1007/978-3-031-11349-9_7
   Pomari T, 2018, IEEE IMAGE PROC, P3788, DOI 10.1109/ICIP.2018.8451227
   Quan WZ, 2019, INT SYMP IMAGE SIG, P246, DOI 10.1109/ISPA.2019.8868802
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shan WY, 2019, SIGNAL PROCESS-IMAGE, V71, P138, DOI 10.1016/j.image.2018.11.011
   Swathi B, 2022, Advances in Intelligent Systems and Computing, V1415, DOI [10.1007/978-981-16, DOI 10.1007/978-981-16]
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Yan YY, 2019, IEEE T INF FOREN SEC, V14, P5, DOI 10.1109/TIFS.2018.2834155
   Yinyang Liu, 2018, 2018 IEEE 4th International Conference on Computer and Communications (ICCC). Proceedings, P1752, DOI 10.1109/CompComm.2018.8780936
   Yu YX, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103295
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhang Y, 2022, arXiv, DOI [10.48550/arXiv.2204.10973, DOI 10.48550/ARXIV.2204.10973]
   Zhang Z, 2019, IEEE I CONF COMP VIS, P5086, DOI 10.1109/ICCV.2019.00519
   Zhuo L, 2018, ASIAPAC SIGN INFO PR, P733, DOI 10.23919/APSIPA.2018.8659761
NR 36
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-16675-1
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7JA3
UT WOS:001086519900009
DA 2024-07-18
ER

PT J
AU Koshy, R
   Elango, S
AF Koshy, Rani
   Elango, Sivasankar
TI Utilizing social media for emergency response: a tweet classification
   system using attention-based BiLSTM and CNN for resource management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Disaster tweet classification; Resource tweets; RoBERTa; BiLSTM;
   Attention; CNN
AB During disasters and emergencies, microblogging platforms like Twitter are crucial sources of real-time information. With so much verbal content present during such situations, it is challenging to extract pertinent situational information. There have been various attempts to identify tweets that are relevant to disasters, but relatively few have concentrated on finding tweets with precise information. Techniques employing the underlying linguistic qualities had been applied in earlier studies which are not suitable for microblogs. We concentrate on one specific application that is crucial for the efficient administration of disaster-related recovery operations: recognizing tweets that provide information about the requirements and availability of vital resources. We focus on a supervised approach using deep learning techniques to differentiate resource tweets from others. The proposed system is a hybrid model employing CNN and BiLSTM to effectively learn fine-grained features from the tweet text. The attention mechanism is also incorporated into the model to get an importance-weighted feature vector. Once the resource tweets have been found, emergency responders can use them to schedule resource allocation so that recovery actions can be carried out efficiently. A supervised model is trained on tweets collected during earthquakes that struck Nepal and Italy in 2015 and 2016, respectively. To verify the appropriateness of the system for practical deployment, we performed in-domain and cross-domain experiments. Our system surpassed several state-of-the-art approaches. According to experimental findings, text categorization in a chaotic environment, such as a disaster event, will gain by considering local key information and global term dependency.
C1 [Koshy, Rani; Elango, Sivasankar] Natl Inst Technol, Dept Comp Sci & Engn, Trichy 620015, Tamilnadu, India.
   [Koshy, Rani] Coll Engn, Dept Comp Sci & Engn, Trivandrum 695016, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; College of Engineering, Trivandrum
RP Koshy, R (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Trichy 620015, Tamilnadu, India.; Koshy, R (corresponding author), Coll Engn, Dept Comp Sci & Engn, Trivandrum 695016, Kerala, India.
EM 406320002@nitt.edu; sivasankar@nitt.edu
NR 0
TC 1
Z9 1
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-16766-z
EA OCT 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ4S3
UT WOS:001142752200002
DA 2024-07-18
ER

PT J
AU Hafeez, MA
   Shakil, S
AF Hafeez, Muhammad Adeel
   Shakil, Sadia
TI EEG-based stress identification and classification using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brainwave images; Long short-term memory (LSTM); Convolutional neural
   networks (CNN); Electroencephalogram (EEG); Exam performance; Power
   spectral density (PSD); Stress
AB Mental stress has become one of the major reasons for the failure of students or their poor performance in the traditional limited-duration examination system. In this study, we aim to find the relationship between the student's level of stress and the deterioration of their subsequent examination results. Furthermore, we want to explore if different EEG frequency bands can be used as biomarkers of stress levels. We collected EEG data from the students while they performed the Montreal Imaging Stress Task-based Mental Arithmetic Tasks (MAT). They performed tests of the same level of difficulty twice; once without any limitation of time (and/or feedback) and next under limited time followed by feedback to induce more stress. We observed that the average score of 95% in the untimed test was dropped to 78% in the case of a timed test and a substantial difference in spectral powers of beta, alpha, and theta frequency bands of EEG. We took this limitation of time as a stressor and comprised three classes based on three stress levels (relaxed during rest, low during an untimed test, and high during a timed test). We used two different deep learning frameworks to classify this data and an accuracy of 70.67% was achieved using Long Short-Term Memory (LSTM) and 90.46% with convolutional neural networks (CNN). We found that time limitation increases the stress level of students and impairs performance, while EEG frequency bands converted to brainwave images, serve as potential biomarkers for stress detection.
C1 [Hafeez, Muhammad Adeel; Shakil, Sadia] Inst Space Technol, Islamabad, Pakistan.
   [Hafeez, Muhammad Adeel] Univ Galway, Galway, Ireland.
   [Shakil, Sadia] Chinese Univ Hong Kong, Hong Kong, Peoples R China.
C3 Ollscoil na Gaillimhe-University of Galway; Chinese University of Hong
   Kong
RP Hafeez, MA (corresponding author), Inst Space Technol, Islamabad, Pakistan.; Hafeez, MA (corresponding author), Univ Galway, Galway, Ireland.
EM adeelmhr@yahoo.com; sadia.shakil@ist.edu.pk
OI Hafeez, Muhammad Adeel/0000-0002-3593-7448
FU Higher Education Commission (HEC) of Pakistan [21-1433/SRGP/RD/HEC/2016]
FX This study was funded by the Start-up Research Grant Program of the
   Higher Education Commission (HEC) of Pakistan (Grant no.
   21-1433/SRGP/RD/HEC/2016).
CR Aboalayon KAI, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18090272
   Acharya UR, 2013, KNOWL-BASED SYST, V45, P147, DOI 10.1016/j.knosys.2013.02.014
   Al-Shargie FM, 2016, IFMBE PROC, V56, P15, DOI 10.1007/978-981-10-0266-3_4
   Alarcao SM, 2019, IEEE T AFFECT COMPUT, V10, P374, DOI 10.1109/TAFFC.2017.2714671
   Alhagry S, 2017, INT J ADV COMPUT SC, V8, P355, DOI 10.14569/IJACSA.2017.081046
   Alyasseri ZAA, 2022, IEEE ACCESS, V10, P10500, DOI 10.1109/ACCESS.2021.3135805
   Arsalan A, 2019, IEEE J BIOMED HEALTH, V23, P2257, DOI 10.1109/JBHI.2019.2926407
   Calibo TK, 2013, IEEE IMTC P, P1471
   Chatterjee D, 2023, BIOMED SIGNAL PROCES, V82, DOI 10.1016/j.bspc.2022.104526
   Cohen S., 1994, Meas Stress: a Guide Health Soc Sci, V10, P1, DOI DOI 10.1037/T02889-000
   Costin H, 2012, INT CONF EXPO ELECTR, P591, DOI 10.1109/ICEPE.2012.6463870
   Dedovic K, 2005, J PSYCHIATR NEUROSCI, V30, P319
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Feldt RC, 2008, PSYCHOL REP, V102, P855, DOI 10.2466/PR0.102.3.855-860
   Fenske MA, 2020, The effects of mental health resources on college student stress and coping
   Giannakakis G, 2022, IEEE T AFFECT COMPUT, V13, P440, DOI 10.1109/TAFFC.2019.2927337
   Hafeez MA, 2018, INT CONF EMERG TECHN
   Hamid NHA, 2010, 2010 6 INT C SIGN PR, P1
   Hao YF, 2018, NEUROIMAGE-CLIN, V17, P962, DOI 10.1016/j.nicl.2017.12.005
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI DOI 10.1177/154193120605000909
   HOMAN RW, 1987, ELECTROEN CLIN NEURO, V66, P376, DOI 10.1016/0013-4694(87)90206-9
   Khabiri H, 2023, Front Biomed Technol
   Kingma D. P., 2014, arXiv
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kumari A., 2014, Global Journal of Multidisciplinary Studies, V4, P31
   Kurniawan H, 2013, COMP MED SY, P209, DOI 10.1109/CBMS.2013.6627790
   Lee S, 2019, IEEE GLOB CONF SIG
   Liu L, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/4565968
   Lotte F, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aab2f2
   Love BC, 2002, PSYCHON B REV, V9, P829, DOI 10.3758/BF03196342
   Mitchell AM, 2008, RES NURS HEALTH, V31, P576, DOI 10.1002/nur.20284
   Panicker SS, 2019, BIOCYBERN BIOMED ENG, V39, P444, DOI 10.1016/j.bbe.2019.01.004
   Papathanasiou I.V., 2015, American Journal of Nursing Science, V4, P45, DOI [10.11648/j.ajns.s.2015040201.19, DOI 10.11648/J.AJNS.S.2015040201.19]
   Quick JCE., 2003, Handbook of occupational health psychology, DOI [10.1037/10474-000, DOI 10.1037/10474-000]
   Saadatnejad S, 2020, IEEE J BIOMED HEALTH, V24, P515, DOI 10.1109/JBHI.2019.2911367
   Saeed SMU, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071886
   Sciaraffa N, 2022, BRAIN SCI, V12, DOI 10.3390/brainsci12030304
   Sharma LD, 2022, EXPERT SYST APPL, V197, DOI 10.1016/j.eswa.2022.116634
   Shim M, 2020, 2020 8 INT WINT C BR, P1
   Tsai YH, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12168052
   Vanitha V, 2017, Int J Med Sci, P71
   Vohra R, 2015, 2015 IEEE INT C DAT, P1
   Wang Z, 2022, IEEE SENS J, V22, P4359, DOI 10.1109/JSEN.2022.3144317
   Wen ZY, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P672, DOI 10.1109/SPAC.2017.8304360
NR 44
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17111-0
EA OCT 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800013
DA 2024-07-18
ER

PT J
AU Keyvanpour, MR
   Mehrmolaei, S
   Shojaeddini, SV
   Esmaeili, F
AF Keyvanpour, Mohammad Reza
   Mehrmolaei, Soheila
   Shojaeddini, Seyed Vahab
   Esmaeili, Fatemeh
TI HAR-CO: A comparative analytical review for recognizing conventional
   human activity in stream data relying on challenges and approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Human Activity Recognition (HAR); Stream data; Wearable Sensor; Ambient
   Assisted Living (AAL); Vision-based HAR
ID HUMAN ACTIVITY RECOGNITION; CONVOLUTIONAL NEURAL-NETWORKS;
   PHYSICAL-ACTIVITY RECOGNITION; FALL DETECTION; SENSOR; FUSION; ENSEMBLE;
   CLASSIFICATION; INTERNET
AB The increase in the use of electronic devices and the high rate of data stream production such as video reveals the importance of analyzing the content of such data. Content analysis of video data for human activity recognizing (HAR) has a significant application in the science of machine vision. So far, vast studies have been conducted to HAR subject. Also, despite many challenges in the research field of video data content analysis, previous researchers have proposed many effective methods in field of human activity recognition. However, the literature reveals lacking of proper context for identification, analysis and evaluation of the HAR methods and challenges in a coherent and uniform form to achieve a macro vision of the HAR subject. Hence, it seems necessary to present a comprehensive and comparative analytical review regarding the HAR on video data relying on methods and challenges. The novelty of this research is to present a comparative analytical framework called HAR-CO, which provide a macro vision, coherent structure and deeper understanding concerning to the HAR. The HAR-CO consists of three main parts. Firstly, categorizing the HAR methods in a coherent and structured way based on data collection hardware. Secondly, categorizing HAR challenges in a systematic based on the sensor attachment. Thirdly, a comparative analytical evaluation of each class of HAR approaches according to challenges toward researchers. We think that the HAR-CO framework can serve as road map and guide to select a more appropriate of HAR methods and provide new research directions by researchers.
C1 [Keyvanpour, Mohammad Reza; Esmaeili, Fatemeh] Alzahra Univ, Fac Engn, Dept Comp Engn, Tehran, Iran.
   [Mehrmolaei, Soheila] Alzahra Univ, Fac Engn, Dept Comp Engn, Data Min Lab, Tehran, Iran.
   [Shojaeddini, Seyed Vahab] Iranian Res Org Sci & Technol, Tehran, Iran.
C3 Alzahra University; Alzahra University
RP Keyvanpour, MR (corresponding author), Alzahra Univ, Fac Engn, Dept Comp Engn, Tehran, Iran.
EM keyvanpour@alzahra.ac.ir
CR Abdel-Basset M, 2021, IEEE INTERNET THINGS, V8, P4969, DOI 10.1109/JIOT.2020.3033430
   Abedin A, 2019, Arxiv, DOI arXiv:1906.02399
   Abedin A, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3448083
   Acar Abbas, 2020, WiSec '20: Proceedings of the 13th ACM Conference on Security and Privacy in Wireless and Mobile Networks, P207, DOI 10.1145/3395351.3399421
   Ahmadi-Karvigh S, 2018, APPL ENERG, V211, P146, DOI 10.1016/j.apenergy.2017.11.055
   Ahmed N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010317
   Alam MS, 2019, INT C EL COMP COMM E, P1
   Alemdar H, 2013, INT CONF PER COMP, P232, DOI 10.4108/icst.pervasivehealth.2013.252120
   Altuve M, 2020, BIOCYBERN BIOMED ENG, V40, P901, DOI 10.1016/j.bbe.2020.04.007
   Amft O, 2007, IFMBE PROC, V13, P242
   Anagnostis A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11052188
   Arshad MH, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22176463
   Asim Y, 2020, IEEE SENS J, V20, P4361, DOI 10.1109/JSEN.2020.2964278
   Auvinet E, 2011, IEEE T INF TECHNOL B, V15, P290, DOI 10.1109/TITB.2010.2087385
   Ayvaz Ugur, 2020, Body Area Networks. Smart IoT and Big Data for Intelligent Health. 15th EAI International Conference, BODYNETS 2020. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 330), P168, DOI 10.1007/978-3-030-64991-3_12
   Baldominos A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041288
   Barlas T, 2023, INT J MED INFORM, V170, DOI 10.1016/j.ijmedinf.2022.104960
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   Beirami MJ., 2020, Health Manag Inf Sci, V7, P228
   Berrezueta-Guzman J, 2020, IEEE ACCESS, V8, P160251, DOI 10.1109/ACCESS.2020.3020734
   Bharti P, 2019, IEEE T MOBILE COMPUT, V18, P857, DOI 10.1109/TMC.2018.2841905
   Blumrosen G, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111965
   Bouchabou D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21186037
   Brito R, 2021, MULTIMED TOOLS APPL, V80, P12293, DOI 10.1007/s11042-020-10274-0
   Bulling A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2499621
   Buoncompagni L, 2022, IEEE T CYBERNETICS, V52, P5587, DOI 10.1109/TCYB.2021.3073539
   Chavarriaga R, 2013, PATTERN RECOGN LETT, V34, P2033, DOI 10.1016/j.patrec.2012.12.014
   Chen C, 2020, AUTOMAT CONSTR, V110, DOI 10.1016/j.autcon.2019.103045
   Chen JC, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030692
   Chen KX, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447744
   Chen LM, 2012, IEEE T KNOWL DATA EN, V24, P961, DOI 10.1109/TKDE.2011.51
   Chung S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071716
   Civitarese G, 2020, KNOWL-BASED SYST, V196, DOI 10.1016/j.knosys.2020.105816
   Commission I, 1990, J S Dev in Africa, V3, P39
   Cook DJ, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS (PERCOM 2003), P521, DOI 10.1109/PERCOM.2003.1192783
   Cruciani F, 2020, CCF T PERVAS COMPUT, V2, P18, DOI 10.1007/s42486-020-00026-2
   Dang LM, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107561
   Das Antar A, 2019, 2019 JOINT 8TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV) AND 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR) WITH INTERNATIONAL CONFERENCE ON ACTIVITY AND BEHAVIOR COMPUTING (ABC), P134, DOI [10.1109/ICIEV.2019.8858508, 10.1109/iciev.2019.8858508]
   De Vita A, 2020, 2020 2ND IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2020), P291, DOI 10.1109/AICAS48895.2020.9073913
   Demrozi F, 2020, IEEE ACCESS, V8, P210816, DOI [10.1109/ACCESS.2020.3037715, 10.1109/access.2020.3037715]
   Deng SZ, 2020, LECT NOTES COMPUT SC, V12113, P54, DOI 10.1007/978-3-030-59416-9_4
   Ding X, 2020, IEEE INT CONF COMM, DOI 10.1109/iccworkshops49005.2020.9145092
   Drumetz L, 2020, DATA HANDL SCI TECHN, V32, P167, DOI 10.1016/B978-0-444-63977-6.00009-2
   Dua N., 2023, Machine Learning, Image Processing, Network Security and Data Sciences, P52
   Dwivedi N, 2020, MULTIMED TOOLS APPL, V79, P21037, DOI 10.1007/s11042-020-08902-w
   Ezatzadeh S, 2017, 2017 9TH INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT 2017), P93, DOI 10.1109/IKT.2017.8258624
   Ferrari A, 2023, J CHEMOTHERAPY, V35, P163, DOI [10.1080/1120009X.2022.2067706, 10.1007/s40860-021-00167-w]
   Franco A, 2020, PATTERN RECOGN LETT, V131, P293, DOI 10.1016/j.patrec.2020.01.010
   Fu BY, 2020, IEEE ACCESS, V8, P83791, DOI 10.1109/ACCESS.2020.2991891
   Gaglio S, 2015, IEEE T HUM-MACH SYST, V45, P586, DOI 10.1109/THMS.2014.2377111
   Garcia-Gonzalez D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082200
   Geppert Marcel, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P333, DOI 10.1007/978-3-030-58452-8_20
   Gholamiangonabadi D, 2020, IEEE ACCESS, V8, P133982, DOI 10.1109/ACCESS.2020.3010715
   Gil-Martín M, 2020, COMPUT ELECTR ENG, V88, DOI 10.1016/j.compeleceng.2020.106822
   Gjoreski H, 2020, STUD SYST DECIS CONT, V273, P81, DOI 10.1007/978-3-030-38748-8_4
   Graña M, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S0129065720500537
   Gu T, 2010, DATA KNOWL ENG, V69, P533, DOI 10.1016/j.datak.2010.01.004
   Gu YZ, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1059, DOI 10.1145/3332165.3347947
   Gu Y, 2023, IEEE SENS J, V23, P4107, DOI 10.1109/JSEN.2022.3233653
   Guo JH, 2019, COMPLEXITY, DOI 10.1155/2019/5245373
   Guo YA, 2022, IEEE TETCI, V6, P728, DOI 10.1109/TETCI.2021.3079966
   Gupta N, 2022, ARTIF INTELL REV, V55, P4755, DOI [10.1080/19475683.2022.2040587, 10.1007/s10462-021-10116-x]
   Hamad RA., 2020, SN Comput. Sci., V1, P1, DOI DOI 10.1007/S42979-020-00211-1
   Hamad RA, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155293
   Han DY, 2020, INT J PRECIS ENG MAN, V21, P1035, DOI 10.1007/s12541-019-00291-x
   Hassan MM, 2021, J SUPERCOMPUT, V77, P2237, DOI 10.1007/s11227-020-03361-4
   Helmi AM, 2023, FUTURE GENER COMP SY, V142, P340, DOI 10.1016/j.future.2023.01.006
   Hendre M, 2020, Evolution in computational intelligence: frontiers in intelligent computing: theory and applications (FICTA 2020), V1, P223
   Hoang ML, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21072313
   Hu Y, 2020, IEEE ACCESS, V8, P135617, DOI 10.1109/ACCESS.2020.3003162
   Hussain Z, 2020, J NETW COMPUT APPL, V167, DOI 10.1016/j.jnca.2020.102738
   Irvine N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010216
   Ishwarya K, 2022, J SUPERCOMPUT, V78, P5241, DOI 10.1007/s11227-021-04065-z
   Jagannath S, 2018, INT CONF PER COMP, P88, DOI 10.1145/3240925.3240941
   Jalal A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226670
   Jansi R, 2020, MULTIDIM SYST SIGN P, V31, P1207, DOI 10.1007/s11045-020-00705-4
   Javed AR, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082216
   Jethanandani M, 2020, INTERNET THINGS-NETH, V12, DOI 10.1016/j.iot.2020.100324
   Jia R, 2013, IEEE INT C SIGNAL PR, P1
   Jung M, 2020, AUTOMAT CONSTR, V114, DOI 10.1016/j.autcon.2020.103177
   Kai KZ, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P20, DOI 10.1145/1409635.1409639
   Kantoch E, 2017, COMPUTING CARDIOLOGY, P1
   Kim E, 2020, IEEE T IND INFORM, V16, P7190, DOI 10.1109/TII.2020.2972628
   Kim K, 2019, J ELECTR ENG TECHNOL, V14, P2567, DOI 10.1007/s42835-019-00278-8
   Kim YJ, 2015, IEEE SYS MAN CYBERN, P3036, DOI 10.1109/SMC.2015.528
   Kolcz A., 2004, ACM SIGKDD EXPLORATI, V6, P1, DOI [10.2973/odp.proc.ir.207.2004, DOI 10.1145/1007730.1007733]
   Kong XB, 2018, INT C ADV MECH SYST, P31, DOI 10.1109/ICAMechS.2018.8506987
   Koutrintzes D, 2023, INT J NEURAL SYST, V33, DOI 10.1142/S0129065723500028
   Kowsar Y, 2016, PROCEEDINGS OF THE 28TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2016), DOI 10.1145/3010915.3010941
   Kwon H, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3411841
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Li QM, 2020, INFORM FUSION, V63, P121, DOI 10.1016/j.inffus.2020.06.004
   Li TY, 2020, INFORM FUSION, V60, P41, DOI 10.1016/j.inffus.2020.02.001
   Li XY, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090106
   Li Y, 2023, INFORM FUSION, V91, P47, DOI 10.1016/j.inffus.2022.10.015
   Liang H, 2021, J SENSORS, V2021, DOI 10.1155/2021/6613574
   Lima WS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143213
   Luo F, 2020, IEEE INTERNET THINGS, V7, P7432, DOI 10.1109/JIOT.2020.2984544
   Lv TQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071871
   Ma CC, 2020, INFORM FUSION, V53, P55, DOI 10.1016/j.inffus.2019.06.013
   Madokoro H, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112411807
   Malazi HT, 2018, APPL INTELL, V48, P315, DOI 10.1007/s10489-017-0976-2
   Manivannan A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236786
   Mao Z, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13050879
   Mario MO, 2019, IEEE SENS J, V19, P1487, DOI 10.1109/JSEN.2018.2882943
   Matsuyama H, 2020, UBICOMP/ISWC '20 ADJUNCT: PROCEEDINGS OF THE 2020 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2020 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P414, DOI 10.1145/3410530.3414333
   Mekruksavanich Sakorn, 2020, 2020 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering (ECTI DAMT & NCON), P75, DOI 10.1109/ECTIDAMTNCON48261.2020.9090711
   Mekruksavanich S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030308
   Meng L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030799
   Minusa S, 2020, IEEE ENG MED BIO, P4165, DOI 10.1109/EMBC44109.2020.9176710
   Morales J, 2017, BIOCYBERN BIOMED ENG, V37, P388, DOI 10.1016/j.bbe.2017.04.004
   Morshed MG, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23042182
   Muzammal M, 2020, INFORM FUSION, V53, P155, DOI 10.1016/j.inffus.2019.06.021
   Nadeem A, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111766
   Naik K, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030988
   Nandy A, 2020, MICROSYST TECHNOL, V26, P1889, DOI 10.1007/s00542-019-04738-z
   Nguyen B., 2021, Mach Lear Appl, V5
   Nizam Y, 2020, STUD SYST DECIS CONT, V273, P237, DOI 10.1007/978-3-030-38748-8_10
   Partridge K, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P144, DOI 10.1145/1409635.1409655
   Pawar Tanmay, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P3094
   Pérez-Torres R, 2016, PERVASIVE MOB COMPUT, V31, P1, DOI 10.1016/j.pmcj.2016.01.010
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Qi J, 2020, INFORM FUSION, V55, P269, DOI 10.1016/j.inffus.2019.09.002
   Qin Z, 2023, INFORM FUSION, V91, P694, DOI 10.1016/j.inffus.2022.10.032
   Qin Z, 2020, INFORM FUSION, V53, P80, DOI 10.1016/j.inffus.2019.06.014
   Qiu S, 2022, INFORM FUSION, V80, P241, DOI 10.1016/j.inffus.2021.11.006
   Qu YX, 2023, EXPERT SYST APPL, V219, DOI 10.1016/j.eswa.2023.119679
   Raeis H, 2021, IEEE INSTRU MEAS MAG, V24, P46, DOI 10.1109/MIM.2021.9513637
   Ramanujam E, 2021, IEEE SENS J, V21, P13029, DOI 10.1109/JSEN.2021.3069927
   Rashidi P, 2011, PERVASIVE MOB COMPUT, V7, P331, DOI 10.1016/j.pmcj.2011.02.007
   Ray A., 2023, Int J Inform Manag Data Insights, V3
   Rougier C, 2011, IEEE T CIRC SYST VID, V21, P611, DOI 10.1109/TCSVT.2011.2129370
   Salehzadeh A, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102094
   Sanabria AR, 2020, PERVASIVE MOB COMPUT, V64, DOI 10.1016/j.pmcj.2020.101147
   Seyfioglu MS, 2018, IEEE T AERO ELEC SYS, V54, P1709, DOI 10.1109/TAES.2018.2799758
   Shahi A, 2017, IEEE IJCNN, P3983, DOI 10.1109/IJCNN.2017.7966358
   Sheishaa O, 2020, Journal, P275
   Shojaedini SV, 2020, BIOMED ENG LETT, V10, P419, DOI 10.1007/s13534-020-00160-x
   Singh R, 2023, COGN SYST RES, V77, P30, DOI 10.1016/j.cogsys.2022.10.003
   Singha S, 2021, IEEE T GEOSCI REMOTE, V59, P9941, DOI 10.1109/TGRS.2020.3035029
   Slaton T, 2020, AUTOMAT CONSTR, V113, DOI 10.1016/j.autcon.2020.103138
   Sovacool BK, 2020, RENEW SUST ENERG REV, V120, DOI 10.1016/j.rser.2019.109663
   Su X, 2014, TSINGHUA SCI TECHNOL, V19, P235, DOI 10.1109/TST.2014.6838194
   Subasi A, 2020, Innovation in Health Informatics, P123, DOI DOI 10.1016/B978-0-12-819043-2.00005-8
   Suman S., 2021, Potential impacts of smart homes on human behavior: A reinforcement learning approach
   Tina, 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P1668, DOI 10.1109/ICCMC51019.2021.9418226
   Tong C, 2020, PROCEEDINGS OF THE 21ST INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS (HOTMOBILE'20), P39, DOI 10.1145/3376897.3377867
   Tong W, 2020, IEEE J-STARS, V13, P4121, DOI 10.1109/JSTARS.2020.3009352
   Twomey N, 2018, INFORMATICS-BASEL, V5, DOI 10.3390/informatics5020027
   Ustev Yunus Emre, 2013, P ACM C PERV UB COMP, P1427, DOI 10.1145/2494091
   Velloso Eduardo., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P1309
   Venkateswara Rao T, 2022, Lecture notes in mechanical engineering, DOI [10.1007/978-981-19-0296-3_59, DOI 10.1007/978-981-19-0296-3_59]
   Wan SH, 2020, MOBILE NETW APPL, V25, P743, DOI 10.1007/s11036-019-01445-x
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   Wang Y, 2019, EXPERT SYST APPL, V137, P167, DOI 10.1016/j.eswa.2019.04.057
   Wang Y, 2009, MOBISYS'09: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P179, DOI 10.1016/B978-044306732-7.50020-9
   Weng EJ, 2012, IEEE INT C INT ROBOT, P4112, DOI 10.1109/IROS.2012.6385863
   Weygers I, 2020, IEEE SENS J, V20, P7969, DOI 10.1109/JSEN.2020.2982459
   Win S., 2020, 2020 IEEE C COMP APP, P1, DOI DOI 10.1109/ICCA49400.2020.9022822
   Wu DG, 2016, NEUROCOMPUTING, V190, P35, DOI 10.1016/j.neucom.2015.11.095
   Xia K, 2020, IEEE ACCESS, V8, P56855, DOI 10.1109/ACCESS.2020.2982225
   Xing Y, 2019, IEEE T VEH TECHNOL, V68, P5379, DOI 10.1109/TVT.2019.2908425
   Xu ZY, 2017, INT C INDOOR POSIT
   Yang J., 2022, J Autom Intell, V1
   Yang R, 2016, INFORMATION, V7, DOI 10.3390/info7040072
   Yang XL, 2020, IEEE ACCESS, V8, P137758, DOI 10.1109/ACCESS.2020.3012021
   Yi ZK, 2020, EXPERT SYST APPL, V148, DOI 10.1016/j.eswa.2020.113238
   Yu M, 2012, IET COMPUT VIS, V6, P90, DOI 10.1049/iet-cvi.2011.0046
   Yuan D, 2023, IEEE T CIRCUITS-II, V70, P1224, DOI 10.1109/TCSII.2022.3223871
   Yuan D, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3266837
   Yuan D, 2023, NEURAL COMPUT APPL, V35, P3423, DOI 10.1007/s00521-022-07867-1
   Yuan D, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3486678
   Yuan D, 2021, IEEE T IMAGE PROCESS, V30, P976, DOI 10.1109/TIP.2020.3037518
   Yue Meng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P86, DOI 10.1007/978-3-030-58571-6_6
   Yurur O, 2014, IEEE COMMUN MAG, V52, P24, DOI 10.1109/MCOM.2014.6829941
   Zhang WT, 2019, IEEE ACCESS, V7, P80027, DOI 10.1109/ACCESS.2019.2922974
   Zhang Y, 2023, COMPUT COMMUN, V197, P87, DOI 10.1016/j.comcom.2022.10.027
   Zhang Y, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041106
   Zhang ZP, 2023, EVOL SYST-GER, V14, P939, DOI 10.1007/s12530-022-09480-y
   Zhao F, 2019, IEEE T AUTOM SCI ENG, V16, P1018, DOI 10.1109/TASE.2018.2861382
   Zhong CL, 2020, MEASUREMENT, V159, DOI 10.1016/j.measurement.2020.107774
   Zhou BD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030621
   Zhou XK, 2020, IEEE INTERNET THINGS, V7, P6429, DOI 10.1109/JIOT.2020.2985082
   Zhu Q, 2021, ISPRS J PHOTOGRAMM, V174, P105, DOI 10.1016/j.isprsjprs.2021.01.025
   Zolfaghari S, 2016, ACSIS-ANN COMPUT SCI, V8, P1435, DOI 10.15439/2016F132
NR 186
TC 0
Z9 0
U1 7
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 10
PY 2023
DI 10.1007/s11042-023-16795-8
EA OCT 2023
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2RB1
UT WOS:001083315100004
DA 2024-07-18
ER

PT J
AU Li, DY
   Cheng, YH
   Guo, YB
   Wang, LR
AF Li, Deyin
   Cheng, Yuhao
   Guo, Yunbo
   Wang, Lirong
TI Esophageal tissue segmentation on OCT images with hybrid attention
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Esophageal tissue segmentation; Attention network; Contextual
   information; OCT
ID OPTICAL COHERENCE TOMOGRAPHY; LAYER SEGMENTATION; RETINAL LAYER;
   IN-VIVO; EPITHELIUM
AB The accurate segmentation of the tissue layers of Optical Coherence Tomography (OCT) esophageal images has vital guiding significance for esophageal diseases research and computer-aided diagnosis. Existing automatic segmentation algorithms based on fully convolutional networks due to the lack of context information resulting in inaccurate segmentation performance. In this paper, we propose a hybrid attention network (HAN) to address this problem. The proposed framework includes an encoder attention module, a channel attention module and a tailored pyramid pooling module (TPPM). The encoder attention module can make up for the loss of image details due to down-sampling operation. The channel attention module is designed to selectively emphasize interdependent channel by integrating associated features among all channel maps. The tailored pyramid pooling module is designed to enhance the spatial contextual information. The combination of channel and spatial contextual information helps to boost feature discriminability, the framework has high segmentation accuracy. Through experiments, it can be verified that the network outperforms several advanced deep learning frameworks in segmentation. The clinical diagnostic potential of HAN for eosinophilic esophagitis (EOE), an esophageal disease, is also demonstrated in the experiment.
C1 [Li, Deyin; Cheng, Yuhao; Wang, Lirong] Soochow Univ, Sch Elect & Informat Engn, Donghuan Rd 50, Suzhou 215031, Jiangsu, Peoples R China.
   [Guo, Yunbo] Chinese Acad Sci, Suzhou Inst Biomed Engn & Technol, Keling Rd 88, Suzhou 10587, Jiangsu, Peoples R China.
C3 Soochow University - China; Chinese Academy of Sciences; Suzhou
   Institute of Biomedical Engineering & Technology, CAS
RP Wang, LR (corresponding author), Soochow Univ, Sch Elect & Informat Engn, Donghuan Rd 50, Suzhou 215031, Jiangsu, Peoples R China.
EM 20195228055@stu.suda.edu.cn; 20224028007@stu.suda.edu.cn;
   guoyb@sibet.ac.cn; wanglirong@suda.edu.cn
FU This work was funded by the Key Program for International S amp;T
   Cooperation Projects of China (2016YFE0107700). We would like to
   acknowledge Prof. Xingde Li and Dr. Wu Yuan from the Johns Hopkins
   University for their technical support in the SD-OCT syst
   [2016YFE0107700]; Key Program for International S amp;T Cooperation
   Projects of China
FX This work was funded by the Key Program for International S &T
   Cooperation Projects of China (2016YFE0107700). We would like to
   acknowledge Prof. Xingde Li and Dr. Wu Yuan from the Johns Hopkins
   University for their technical support in the SD-OCT systems.
CR Changqian Yu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12413, DOI 10.1109/CVPR42600.2020.01243
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dai YM, 2021, IEEE WINT CONF APPL, P3559, DOI 10.1109/WACV48630.2021.00360
   Devalla SK, 2018, BIOMED OPT EXPRESS, V9, P3244, DOI 10.1364/BOE.9.003244
   Fan XL, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105522
   Fang LY, 2019, IEEE T MED IMAGING, V38, P1959, DOI 10.1109/TMI.2019.2898414
   Fang LY, 2018, IEEE T GEOSCI REMOTE, V56, P1803, DOI 10.1109/TGRS.2017.2768479
   Fernández DC, 2005, OPT EXPRESS, V13, P10200, DOI 10.1364/OPEX.13.010200
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gan M, 2020, IEEE ACCESS, V8, P215020, DOI 10.1109/ACCESS.2020.3041767
   Gan M, 2018, BIOMED OPT EXPRESS, V9, P4481, DOI 10.1364/BOE.9.004481
   Ganjee R, 2020, MED PHYS, V47, P4872, DOI 10.1002/mp.14361
   Gao ZF, 2020, IEEE T MED IMAGING, V39, P1524, DOI 10.1109/TMI.2019.2952939
   Gora MJ, 2017, BIOMED OPT EXPRESS, V8, P2405, DOI 10.1364/BOE.8.002405
   Gora MJ, 2013, NAT MED, V19, P238, DOI 10.1038/nm.3052
   Hatta W, 2010, GASTROINTEST ENDOSC, V71, P899, DOI 10.1016/j.gie.2009.11.052
   HEE MR, 1995, ARCH OPHTHALMOL-CHIC, V113, P325, DOI 10.1001/archopht.1995.01100030081025
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu JF, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0247388
   HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169
   Huang JQ, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10030125
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Koozekanani D, 2001, IEEE T MED IMAGING, V20, P900, DOI 10.1109/42.952728
   Kugelman J, 2020, IEEE ACCESS, V8, P43537, DOI 10.1109/ACCESS.2020.2977355
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li DW, 2019, BIOMED OPT EXPRESS, V10, P1126, DOI 10.1364/BOE.10.001126
   Li XD, 2000, ENDOSCOPY, V32, P921, DOI 10.1055/s-2000-9626
   Liu W, 2020, ALGORITHMS, V13, DOI 10.3390/a13030060
   Liu ZY, 2014, GASTROENTEROLOGY, V146, pS92
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Meng FM, 2018, IEEE T MULTIMEDIA, V20, P310, DOI 10.1109/TMM.2017.2739919
   Ni JJ, 2021, BIOMED RES INT, V2021, DOI 10.1155/2021/6622253
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Poneros JM, 2001, GASTROENTEROLOGY, V120, P7, DOI 10.1053/gast.2001.20911
   Rasti R, 2020, BIOMED OPT EXPRESS, V11, P1139, DOI 10.1364/BOE.379150
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy AG, 2017, BIOMED OPT EXPRESS, V8, P3627, DOI 10.1364/BOE.8.003627
   Stegmann H, 2020, BIOMED OPT EXPRESS, V11, P1539, DOI 10.1364/BOE.386228
   Sun ZL, 2016, SCI REP-UK, V6, DOI 10.1038/srep21739
   Tearney GJ, 1997, SCIENCE, V276, P2037, DOI 10.1126/science.276.5321.2037
   Ughi GJ, 2016, BIOMED OPT EXPRESS, V7, P409, DOI 10.1364/BOE.7.000409
   Wang C, 2022, BIOMED OPT EXPRESS, V13, P6167, DOI 10.1364/BOE.475272
   Wang C, 2019, BIOMED OPT EXPRESS, V10, P978, DOI 10.1364/BOE.10.000978
   Xu R, 2022, BIOMED RES INT-UK, V2022, DOI 10.1155/2022/7966553
   Yuan X., 2017, Neuroinformatics, V16, P1, DOI [10.1007/s12021-018-9377-x, DOI 10.1007/S12021-018-9377-X]
   Zhang H, 2022, IEEE COMPUT SOC CONF, P2735, DOI 10.1109/CVPRW56347.2022.00309
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang JL, 2017, BIOMED OPT EXPRESS, V8, P2697, DOI 10.1364/BOE.8.002697
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng XW, 2020, ISPRS J PHOTOGRAMM, V170, P15, DOI 10.1016/j.isprsjprs.2020.09.019
NR 51
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 10
PY 2023
DI 10.1007/s11042-023-16550-z
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2RB1
UT WOS:001083315100001
DA 2024-07-18
ER

PT J
AU Alhabeeb, OH
   Fauzi, F
   Sulaiman, R
AF Alhabeeb, Omar Haitham
   Fauzi, Fariza
   Sulaiman, Rossilawati
TI Developing a novel DNA-based steganography algorithm using random table
   generation with segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Steganography; Bioinformatics; Cybersecurity; Hiding-patterns; Lookup
   encoding table; Randomness
ID HIGH-CAPACITY; SECURE; HYBRID
AB Genome steganography has emerged as a promising field for transmitting large amounts of data over an untrusted channel in the last two decades. DNA has many advantages over other multimedia cover mediums. Substitution is the most common approach to developing a DNA-based steganography algorithm. Components of the secret message are converted to DNA letters, which replace nucleotides in the cover sequence. The conversion is conducted through predetermined tables like binary coding rules and lookup/dictionary tables. These tables are static, limited to specific alphanumeric characters, and may compromise the hidden message if discovered by intruders. Most previously proposed algorithms adopt a simple sequential and ordered hiding pattern. This leads to poor utilization of the available hiding spots and creates a region of interest for attackers to apply steganalysis. In this paper, a novel DNA-based algorithm is proposed. Using two DNA sequences, primary and secondary, is the basis for this algorithm. Both sequences are segmented, where the primary sequence segments are for hiding the data, and the secondary sequence segments are for conveying the required information to find and extract the hidden data. Three enhanced tables are proposed: a modified ASCII table, a 4-bit binary coding rule table, and a two-tier lookup encoding table to convert the message to DNA form. The segmentation ensures that the hiding spots are randomly scattered across the primary cover DNA sequence, addressing the region of interest issue. The data is hidden in the cover using the least significant base substitutions. The result is an all-rounded algorithm that fulfills the desired performance measurements such as zero payloads, blindness, preserving functionality, high hiding capacity, low modification rate, and low cracking probability.
C1 [Alhabeeb, Omar Haitham] Univ Mosul, Coll Comp Sci & Math, Dept Software, Mosul, Iraq.
   [Alhabeeb, Omar Haitham; Fauzi, Fariza; Sulaiman, Rossilawati] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Bangi, Malaysia.
C3 University of Mosul; Universiti Kebangsaan Malaysia
RP Fauzi, F (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Bangi, Malaysia.
EM fariza.fauzi@ukm.edu.my
RI Fauzi, Fariza/S-8098-2017
OI Fauzi, Fariza/0000-0002-0491-4198
CR Abd El-Latif EI, 2019, J INFORM OPTIM SCI, V40, P1181, DOI 10.1080/02522667.2017.1413041
   Agrawal R, 2014, 2014 9TH INTERNATIONAL CONFERENCE ON INDUSTRIAL AND INFORMATION SYSTEMS (ICIIS), P35
   Al-Harbi OA, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1930-1
   Alhabeeb OH, 2021, INT J ADV COMPUT SC, V12, P184
   Ali AH, 2018, MULTIMED TOOLS APPL, V77, P31487, DOI 10.1007/s11042-018-6213-0
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Anusha R, 2020, P 4 INT C EL COMM AE, P765
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Atito A., 2011, J Commun Comput Eng, V2, P44, DOI [10.20454/jcce.2012.242, DOI 10.20454/JCCE.2012.242]
   Baawi Salwa Shakir, 2017, Journal of Theoretical and Applied Information Technology, V95, P6247
   Chakraborty S., 2015, International Journal of Advanced Information Science and Technology, V44, P1
   Chaudhury P, 2017, 2017 8TH ANNUAL INDUSTRIAL AUTOMATION AND ELECTROMECHANICAL ENGINEERING CONFERENCE (IEMECON), P332, DOI 10.1109/IEMECON.2017.8079618
   Clelland CT, 1999, NATURE, V399, P533, DOI 10.1038/21092
   Dalal M, 2021, MULTIMED TOOLS APPL, V80, P5723, DOI 10.1007/s11042-020-09929-9
   Das P, 2015, PROCEDIA COMPUT SCI, V46, P604, DOI 10.1016/j.procs.2015.02.103
   Elhadad A, 2022, INT J COMPUT SCI NET, V22, P697, DOI 10.22937/IJCSNS.2022.22.1.91
   Elshoush HT, 2022, MULTIMED TOOLS APPL, V81, P5191, DOI 10.1007/s11042-021-11741-y
   Folkersen L, 2019, World Scientific, P7
   French JD, 2020, TRENDS GENET, V36, P880, DOI 10.1016/j.tig.2020.07.004
   Hamed G, 2018, BIOSYSTEMS, V167, P47, DOI 10.1016/j.biosystems.2018.03.003
   Hamed G, 2015, INT CONF SOFT COMPUT, P95, DOI 10.1109/SOCPAR.2015.7492790
   Hamed G, 2016, INTEL SYST REF LIBR, V96, P47, DOI 10.1007/978-3-319-21212-8_3
   Hassan Shahriar, 2022, 2022 IEEE 13th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON), P0501, DOI 10.1109/IEMCON56893.2022.9946512
   Huang YH, 2014, MULTIMED TOOLS APPL, V70, P1439, DOI 10.1007/s11042-012-1176-z
   Kamil S, 2018, PROCEEDINGS OF THE 2018 CYBER RESILIENCE CONFERENCE (CRC)
   Kamil S, 2018, INT J ADV COMPUT SC, V9, P256
   Khalifa A., 2016, Appl Math Inf Sci, V10, P1483, DOI DOI 10.18576/AMIS/100427
   Khalifa A, 2012, 8 INT C INF SYST
   Khalifa A, 2020, INT CONF INFO SCI, P86, DOI [10.1109/ICIST49303.2020.9202036, 10.1109/icist49303.2020.9202036]
   Khalifa A, 2013, 2013 8TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P105, DOI 10.1109/ICCES.2013.6707182
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Liu HJ, 2013, COMPUT ELECTR ENG, V39, P1164, DOI 10.1016/j.compeleceng.2013.01.017
   Loehlin DW, 2019, P NATL ACAD SCI USA, V116, P12383, DOI 10.1073/pnas.1904071116
   Majeed Mohammed Abdul, 2015, Journal of Theoretical and Applied Information Technology, V80, P342
   Majeed MA, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9212829
   Malathi P, 2017, PROCEDIA COMPUT SCI, V115, P651, DOI 10.1016/j.procs.2017.09.151
   Manna S, 2014, 1 INT C AUT CONTR EN, P1
   Marwan Samiha, 2017, International Journal of Interactive Mobile Technologies, V11, P88, DOI 10.3991/ijim.v11i2.6565
   Meiser LC, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-021-27846-9
   Mohammed MH., 2019, Inf. Sci. Lett, V8, P15, DOI [10.18576/isl/080102, DOI 10.18576/ISL/080102]
   Momand J., 2017, Concepts in bioinformatics and genetics, DOI [10.1093/hesc/9780190610548.001.0001, DOI 10.1093/HESC/9780190610548.001.0001]
   Mousa H, 2011, INT ARAB J INF TECHN, V8, P147
   Na D, 2020, MICROB CELL FACT, V19, DOI 10.1186/s12934-020-01387-0
   Naskar PK, 2019, MULTIMED TOOLS APPL, V78, P25019, DOI 10.1007/s11042-019-7696-z
   NCBI, 2022, US
   Passarge E., 2019, Color Atlas of Genetics, V5, P54
   Sabry Mona, 2019, 2019 Ninth International Conference on Intelligent Computing and Information Systems (ICICIS), P317, DOI 10.1109/ICICIS46948.2019.9014843
   Saha P., 2019, Int J Recent Technol Eng, V8, P6551
   Sajisha KS, 2017, INT C EL COMM AER TE
   Santoso K, 2016, SECUR COMMUN NETW, V9, P4210, DOI 10.1002/sec.1599
   Sharma A, 2015, PROCEDIA COMPUT SCI, V70, P778, DOI 10.1016/j.procs.2015.10.117
   Shiu HJ, 2010, INFORM SCIENCES, V180, P2196, DOI 10.1016/j.ins.2010.01.030
   Sobti R., 2012, INT J COMPUTER SCI I, V9, P461
   Sreenivas K, 2018, INT J MACH LEARN CYB, V9, P1193, DOI 10.1007/s13042-017-0641-4
   Stallings W., 2017, Cryptography and network security principles and practice, V7, P295
   Tank Rashmi M., 2015, Oriental Journal of Computer Science and Technology, V8, P43
   Taur JS, 2012, INT J INNOV COMPUT I, V8, P6585
   Torkaman Mohammad Reza Najaf, 2012, International Journal of New Computer Architectures and their Applications, V2, P225
   Tuncer T, 2016, DISPLAYS, V41, P1, DOI 10.1016/j.displa.2015.10.005
   Vijayakumar P., 2018, International Journal of Advanced Intelligence Paradigms, V10, P74
   Xiao GZ, 2006, CHINESE SCI BULL, V51, P1413, DOI 10.1007/s11434-006-2012-5
NR 62
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 9
PY 2023
DI 10.1007/s11042-023-16699-7
EA OCT 2023
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2OJ4
UT WOS:001083245400012
DA 2024-07-18
ER

PT J
AU Wang, XS
   Nie, ZA
   Liang, W
   Pei, MT
AF Wang, Xusheng
   Nie, Zhengang
   Liang, Wei
   Pei, Mingtao
TI Self-trained multi-cues model for video anomaly detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Anomaly detection; Unsupervised task; Video understanding
AB Video anomaly detection is an extremely challenging task in the field of intelligent surveillance analysis. In this paper, we propose a video anomaly detection method without any manual annotation information, which is the key limitations of existing weakly-supervised methods. Compared to existing single-clue unsupervised methods, we explore the importance of multiple cues and design a self-trained multi-cues model for video anomaly detection. In addition to appearance features, we find motion features and reconstruction error features are essential for detecting abnormal behaviors. Our method achieves the extraction and fusion of these features from video based on self-trained framework. Specifically, we use auto-encoders to generate reconstruction error maps of frames and optic flow maps respectively. Then we extract multiple cues features from frames/flow maps and the reconstruction error maps to detect abnormal events. As our model is self-trained, we do not need manually labeled training data. We conduct validation experiments on two public datasets. The experimental results show our self-trained multi-cues model outperforms existing unsupervised video anomaly detection methods and leads to good results compared with weakly-supervised methods.
C1 [Wang, Xusheng; Liang, Wei; Pei, Mingtao] Beijing Inst Technol, Sch Comp Sci, Beijing 100081, Peoples R China.
   [Nie, Zhengang] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.
   [Liang, Wei] Yangtze Delta Reg Acad Beijing Inst Technol, Jiaxing 314000, Zhejiang, Peoples R China.
C3 Beijing Institute of Technology; Beijing Institute of Technology
RP Pei, MT (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing 100081, Peoples R China.
EM wangxusheng@bit.edu.cn; niezhengang@bit.edu.cn; liangwei@bit.edu.cn;
   peimt@bit.edu.cn
FU This work was supported by the Natural Science Foundation of China
   (NSFC) under Grant No.61972038. [61972038]; Natural Science Foundation
   of China (NSFC)
FX This work was supported by the Natural Science Foundation of China
   (NSFC) under Grant No.61972038.
CR Abati D, 2019, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2019.00057
   Del Giorno A, 2016, Arxiv, DOI arXiv:1609.08938
   Feng JC, 2021, PROC CVPR IEEE, P14004, DOI 10.1109/CVPR46437.2021.01379
   Georgescu MI, 2021, PROC CVPR IEEE, P12737, DOI 10.1109/CVPR46437.2021.01255
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Gong Y, 2022, 2022 IEEE INT C MULT, P1, DOI [10.1109/ICME52920.2022.9860012, DOI 10.1109/ICME52920.2022.9860012]
   Guansong Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12170, DOI 10.1109/CVPR42600.2020.01219
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ionescu RT, 2019, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2019.00803
   Ionescu RT, 2019, IEEE WINT CONF APPL, P1951, DOI 10.1109/WACV.2019.00212
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Lai YD, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102894
   Li S, 2022, AAAI CONF ARTIF INTE, P1395
   Liu FT, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2133360.2133363
   Liu W, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3023
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Liu Y., 2018, BMVC
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   MAHADEVAN V, 2010, PROC CVPR IEEE, P1975, DOI DOI 10.1109/CVPR.2010.5539872
   Park Hyunjong, 2020, IEEECVF C COMPUTER V, P2
   Paszke A, 2019, ADV NEUR IN, V32
   Ristea NC, 2022, PROC CVPR IEEE, P13566, DOI 10.1109/CVPR52688.2022.01321
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Sun QR, 2017, PATTERN RECOGN, V64, P187, DOI 10.1016/j.patcog.2016.09.016
   Nguyen TN, 2019, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2019.00136
   Wang XS, 2021, IEEE INT WORKS MACH, DOI 10.1109/MLSP52302.2021.9596140
   Yunpeng Chang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P329, DOI 10.1007/978-3-030-58555-6_20
   Zhang Y, 2016, PATTERN RECOGN, V59, P302, DOI 10.1016/j.patcog.2015.11.018
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133
NR 32
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 9
PY 2023
DI 10.1007/s11042-023-16904-7
EA OCT 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2OJ4
UT WOS:001083245400008
DA 2024-07-18
ER

PT J
AU Daniel, N
   Anitha, A
AF Daniel, Neenu
   Anitha, A.
TI Analysing texture, color and spatial features for face spoof detection
   with hybrid classification model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Face spoof detection; GLCM; Improved SLBT; HOG features and improved CNN
AB Facial biometrics are more natural, innate, and less invasive to humans. It is frequently used in the authentication of approved users and employees to safeguard data from unauthorized access. A face spoofing assault typically consists of a trespasser attempting to impersonate an individual with desirable authentication authorization to gain unlawful access to valuable undisclosed information. In order to detect such violations, several detectives have focused their efforts on visual recognition of structures produced when there are primary signs of spoofing violations. AI techniques like ML/DL play a major role in this aspect. This work intends to propose novel face spoof detection via a hybrid classification model (FSDHC). The input video is initially partitioned into a number of frames and is subjected to the pre processing step to remove the unwanted noise and blurriness from the image with the aid of the wiener filtering technique. Considering the preprocessed video frames, the colour features, improved shape local binary texture, GLCM and HOG-based features are extracted. Subsequently, the extracted features are given as the input to the proposed hybrid classification model to speed up the training process. The proposed hybrid classification model involves two models improved CNN and Bi-GRU models. The final classification process is determined by fusing the intermediate results obtained from both classifiers via an improved score-level fusion process. This work also validates the performance of the proposed model via cross-database validation, in which training and testing with two different datasets like the Replay Attack dataset and MSU MFSD. Additionally, the efficacy of the developed method is assessed using various performance metrics in comparison to state of- art methods.
C1 [Daniel, Neenu] Noorul Islam Ctr Higher Educ, Dept Comp Sci & Engn, Kanyakumari 629180, Tamilnadu, India.
   [Anitha, A.] Noorul Islam Ctr Higher Educ, Dept Comp Sci & Engn, Kumaracoil 629180, Tamilnadu, India.
RP Daniel, N (corresponding author), Noorul Islam Ctr Higher Educ, Dept Comp Sci & Engn, Kanyakumari 629180, Tamilnadu, India.
EM neenudaniel@gmail.com
RI Daniel, Neenu/JEZ-7697-2023; A, Anitha/AAS-9798-2020
OI A, Anitha/0000-0002-5714-2056
CR Abdullakutty F, 2022, COGN COMPUT, V14, P2223, DOI 10.1007/s12559-022-10037-z
   Aborisade D., 2014, Energy, V2, DOI DOI 10.14445/22312803/IJCTT-V11P151
   Abozaid A, 2019, MULTIMED TOOLS APPL, V78, P16345, DOI 10.1007/s11042-018-7012-3
   Aleem S, 2020, WORLD WIDE WEB, V23, P1299, DOI 10.1007/s11280-019-00698-6
   Arora S, 2022, VISUAL COMPUT, V38, P2461, DOI 10.1007/s00371-021-02123-4
   Bakshi A, 2022, MULTIMED TOOLS APPL, V81, P35047, DOI 10.1007/s11042-020-10045-x
   Banire B, 2021, J HEALTHC INFORM RES, V5, P420, DOI 10.1007/s41666-021-00101-y
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Bousnina N, 2021, MULTIMED TOOLS APPL, V80, P7229, DOI 10.1007/s11042-020-10041-1
   Cai P, 2021, J CENT SOUTH UNIV, V28, P194, DOI 10.1007/s11771-021-4596-y
   Daniel N, 2021, COMPUT ELECTR ENG, V94, DOI 10.1016/j.compeleceng.2021.107293
   Farmanbar M, 2017, SIGNAL IMAGE VIDEO P, V11, P1253, DOI 10.1007/s11760-017-1082-y
   Fourati E, 2020, MULTIMED TOOLS APPL, V79, P865, DOI 10.1007/s11042-019-08115-w
   Hamd M. H., 2020, IOP Conference Series: Materials Science and Engineering, V990, DOI 10.1088/1757-899X/990/1/012021
   Jadwa D. S., 2018, International Journal of Science and Engineering Applications, V7, P318
   Karmakar D, 2021, PATTERN RECOGN IMAGE, V31, P285, DOI 10.1134/S1054661821020097
   Katika BR, 2020, PATTERN ANAL APPL, V23, P1735, DOI 10.1007/s10044-020-00875-8
   Kavitha JC, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING TECHNOLOGIES AND INTELLIGENT DATA ENGINEERING (ICCTIDE'16)
   Kumar A, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03541-x
   Lakshmiprabha NS, 2012, INT CONF INTELL SYST, P258, DOI 10.1109/ISDA.2012.6416547
   Namatevs Ivars, 2017, Ind Technol Manag Sci, V20, P40, DOI DOI 10.1515/ITMS-2017-0007
   Neenu D, 2020, Int J Recent Technol Eng (IJRTE)
   Samrity S, 2019, Int J Sci Eng Res, V10
   Shu X, 2021, MULTIMEDIA SYST, V27, P161, DOI 10.1007/s00530-020-00719-9
   Singh M, 2020, WIRELESS PERS COMMUN, V111, P2465, DOI 10.1007/s11277-019-06996-6
   Sun YJ, 2021, VISUAL COMPUT, V37, P1015, DOI 10.1007/s00371-020-01849-x
   Tham Medari Janai, 2020, Medari Janai Tham / Indian Journal of Computer Science and Engineering (IJCSE), V11, DOI [10.21817/indjcse/2020/v11i5/201105167, DOI 10.21817/INDJCSE/2020/V11I5/201105167]
   Tyagi R, 2021, WIRELESS PERS COMMUN, V118, P901, DOI 10.1007/s11277-020-08050-2
   Vareto RH, 2021, PATTERN ANAL APPL, V24, P511, DOI 10.1007/s10044-020-00937-x
   Xiao YH, 2020, MULTIMED TOOLS APPL, V79, P16531, DOI 10.1007/s11042-019-7661-x
   Yilmaz AG, 2023, MULTIMED TOOLS APPL, V82, P40039, DOI 10.1007/s11042-023-14453-7
   Zhou W, 2020, IEEE T CIRCUITS-II, V67, P946, DOI 10.1109/TCSII.2020.2980557
NR 32
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-17020-2
EA OCT 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100007
DA 2024-07-18
ER

PT J
AU Akbulut, A
   Desouki, S
   AbdelKhaliq, S
   Khantomani, L
   Catal, C
AF Akbulut, Akhan
   Desouki, Sara
   AbdelKhaliq, Sara
   Khantomani, Layal
   Catal, Cagatay
TI Design and implementation of a deep learning-empowered m-Health
   application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Melanoma; Machine learning; Deep learning; m-Health; Skin lesion
   analysis
AB Many people are unaware of the severity of melanoma disease even though such a disease can be fatal if not treated early. This research aims to facilitate the diagnosis of melanoma disease in people using a mobile health application because some people do not prefer to visit a dermatologist due to several concerns such as feeling uncomfortable by exposing their bodies. As such, a skincare application was developed so that a user can easily analyze a mole at any part of the body and get the diagnosis results quickly. In the first phase, the corresponding image is extracted and sent to a web service. Later, the web service classifies using the pre-trained model built based on a deep learning algorithm. The final phase displays the confidence rates on the mobile application. The proposed model utilizes the Convolutional Neural Network and provides 84% accuracy and 72% precision. The results demonstrate that the proposed model and the corresponding mobile application provide remarkable results for addressing the specified health problem.
C1 [Akbulut, Akhan; Desouki, Sara; AbdelKhaliq, Sara; Khantomani, Layal] Istanbul Kultur Univ, Dept Comp Engn, TR-34536 Istanbul, Turkiye.
   [Catal, Cagatay] Qatar Univ, Dept Comp Sci & Engn, Doha 2713, Qatar.
C3 Istanbul Kultur University; Qatar University
RP Catal, C (corresponding author), Qatar Univ, Dept Comp Sci & Engn, Doha 2713, Qatar.
EM ccatal@qu.edu.qa
RI Catal, Cagatay/AAF-3929-2019
OI Catal, Cagatay/0000-0003-0959-2930
FU Qatar National Library
FX Open Access funding provided by the Qatar National Library.
CR Akay Metin, 2021, IEEE Open J Eng Med Biol, V2, P104, DOI 10.1109/OJEMB.2021.3066097
   Akbulut A, 2019, IEEE INTERNET COMPUT, V23, P19, DOI 10.1109/MIC.2019.2951094
   Ashraf R, 2020, IEEE ACCESS, V8, P147858, DOI 10.1109/ACCESS.2020.3014701
   Benbrahim H, 2020, SCALABLE COMPUT-PRAC, V21, P379, DOI 10.12694/scpe.v21i3.1725
   Bhatt H, 2022, Intell Med Elsevie
   Budhiman Arief, 2019, 2019 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI), P17, DOI 10.1109/ISRITI48646.2019.9034624
   Castro PBC, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207552
   Foster KR, 2017, IEEE PULSE, V8, P34, DOI 10.1109/MPUL.2017.2750783
   González-Díaz I, 2019, IEEE J BIOMED HEALTH, V23, P547, DOI 10.1109/JBHI.2018.2806962
   Guha Shetu Rani, 2019, 2019 International Conference on Sustainable Technologies for Industry 4.0 (STI), DOI 10.1109/STI47673.2019.9067979
   Gupta Aurobindo, 2020, 2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), P1345, DOI 10.1109/ICRITO48877.2020.9197820
   Li H, 2019, IEEE J BIOMED HEALTH, V23, P527, DOI 10.1109/JBHI.2018.2859898
   Mertz L, 2020, IEEE PULSE, V11, P10, DOI 10.1109/MPULS.2020.3036151
   Namozov A, 2018, I C INF COMM TECH CO, P417, DOI 10.1109/ICTC.2018.8539451
   Nawaz SA, 2022, FRONT PLANT SCI, V13, DOI 10.3389/fpls.2022.1041514
   Scarlat A, 2018, Melanoma: augmented dermoscopic pigmented skin lesions from HAM10k
   SensioAI, 2020, Melanoma224: dataset utilizado en los videos de sensioai
   Shoukat MU, 2022, 2022 INT C IT IND TE, P1
   Shoukat MU, 2022, INT CONF EMERG TECHN, P240, DOI 10.1109/ICET56601.2022.10004685
   Song L, 2020, IEEE J BIOMED HEALTH, V24, P2912, DOI 10.1109/JBHI.2020.2973614
   van Dinter R, 2022, INFORM SOFTWARE TECH, V151, DOI 10.1016/j.infsof.2022.107008
   Yan WD, 2019, IEEE PULSE, V10, P15, DOI 10.1109/MPULS.2019.2911822
   Yuan YD, 2019, IEEE J BIOMED HEALTH, V23, P519, DOI 10.1109/JBHI.2017.2787487
NR 23
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-17041-x
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Ohri, K
   Kumar, M
AF Ohri, Kriti
   Kumar, Mukesh
TI Domain and label efficient approach for diabetic retinopathy severity
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Self-supervised learning; Unsupervised learning; Diabetic retinopathy;
   Contrastive learning; Deep learning; Teacher-student network; Medical
   Imaging
ID DEEP; VALIDATION
AB Progress in medical imaging models using supervised learning has reached closer to clinical-level performance of doctors. However, labeling huge amounts of medical data comes with an additional challenge. There exists a difficulty in achieving label efficiency and generalization when models are trained on low data regimes. This paper proposes different variants of self-supervised models for diabetic retinopathy (DR) detection that exploit unlabeled fundus images to learn domain-specific representations using self-supervised learning frameworks such as SimCLR, SwAV, and DINO. The learned representations are then evaluated at the supervised task of DR severity detection using different fractions of labeled APTOS training dataset. The experimental results show that self-supervised pre-training on domain-specific images improves the kappa score of DR classifier (DINO-Un) at linear evaluation by an absolute value of 15.02% as compared to supervised counterpart at low data regime. Whereas during finetuning, the DR severity classifier (SwAV-Un) performs better by an absolute value of 16.86% in comparison to supervised counterpart at low data regime. The best model (DINO-Un) is also audited for model explainability using class activation maps to ensure it's looking for the right patterns in the input to make predictions.
C1 [Ohri, Kriti; Kumar, Mukesh] Natl Inst Technol Patna, Dept CSE, Patna 800005, India.
   [Ohri, Kriti] Vallurupalli Nageswara Rao Vignana Jyothi Inst Eng, Dept CSE, Hyderabad 500090, Telengana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna; Vallurupalli Nageswara Rao Vignana Jyothi Institute of
   Engineering &Technology (VNR VJIET)
RP Ohri, K (corresponding author), Natl Inst Technol Patna, Dept CSE, Patna 800005, India.; Ohri, K (corresponding author), Vallurupalli Nageswara Rao Vignana Jyothi Inst Eng, Dept CSE, Hyderabad 500090, Telengana, India.
EM kriti.ohri@gmail.com
OI Ohri, Kriti/0000-0002-6279-4147
CR Alzubaidi L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10134523
   Arlot S, 2010, STAT SURV, V4, P40, DOI 10.1214/09-SS054
   Assran M, 2022, LECT NOTES COMPUT SC, V13691, P456, DOI 10.1007/978-3-031-19821-2_26
   Atito S, 2022, arXiv
   Azizi S., 2022, arXiv preprint arXiv: 2205.09723
   Azizi S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3458, DOI 10.1109/ICCV48922.2021.00346
   Bachman P, 2019, Arxiv, DOI arXiv:1906.00910
   Bardes A, 2022, Arxiv, DOI arXiv:2105.04906
   Beede E, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376718
   Burlina P, 2020, JAMA OPHTHALMOL, V138, P1070, DOI 10.1001/jamaophthalmol.2020.3269
   Caron M, 2021, Arxiv, DOI arXiv:2006.09882
   Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Cavan D, 2017, DIABETES RES CLIN PR, V129, P16, DOI 10.1016/j.diabres.2017.03.023
   Chaves L, 2022, Arxiv, DOI arXiv:2106.09229
   Chen T, 2020, Arxiv, DOI [arXiv:2002.05709, DOI 10.48550/ARXIV.2002.05709]
   Chen T, 2019, PROC CVPR IEEE, P12146, DOI 10.1109/CVPR.2019.01243
   Chen XL, 2020, Arxiv, DOI arXiv:2003.04297
   Chen XL, 2021, PROC CVPR IEEE, P15745, DOI 10.1109/CVPR46437.2021.01549
   Chilukoti SV., 2022, IEEE J Biomed Heal Informatics, V20, P1, DOI [10.36227/techrxiv.18515357.v1, DOI 10.36227/TECHRXIV.18515357.V1]
   Dippel J, 2022, Arxiv, DOI arXiv:2104.04323
   Dosovitskiy A, 2016, IEEE T PATTERN ANAL, V38, P1734, DOI 10.1109/TPAMI.2015.2496141
   Dufumier B, 2021, LECT NOTES COMPUT SC, V12902, P58, DOI 10.1007/978-3-030-87196-3_6
   Fontanella A, 2020, Classification with a domain shift in medical imaging
   Gamper J, 2021, PROC CVPR IEEE, P16544, DOI 10.1109/CVPR46437.2021.01628
   Gatys LA, 2017, CURR OPIN NEUROBIOL, V46, P178, DOI 10.1016/j.conb.2017.08.019
   Geirhos R, 2019, Arxiv, DOI arXiv:1811.12231
   Gidaris S, 2021, PROC CVPR IEEE, P6826, DOI 10.1109/CVPR46437.2021.00676
   Gidaris S, 2020, PROC CVPR IEEE, P6926, DOI 10.1109/CVPR42600.2020.00696
   Graziani M., 2019, IRISH MACHINE VISION
   Grill J.B., 2020, arXiv, DOI DOI 10.48550/ARXIV.2006.07733
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Guo HX, 2017, EXPERT SYST APPL, V73, P220, DOI 10.1016/j.eswa.2016.12.035
   He KM, 2022, PROC CVPR IEEE, P15979, DOI 10.1109/CVPR52688.2022.01553
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   He X. etal, 2020, medRxiv
   Hong Jung Taeck, 2012, Korean J Ophthalmol, V26, P32, DOI 10.3341/kjo.2012.26.1.32
   Huang GB, 2021, Arxiv, DOI arXiv:2110.14711
   Huang SC, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00811-0
   Jenni S, 2020, PROC CVPR IEEE, P6407, DOI 10.1109/CVPR42600.2020.00644
   Jinfeng G, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8864698
   Jing Li, 2021, arXiv
   Kaku A, 2021, ADV NEUR IN, V34
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Lam Carson, 2018, AMIA Jt Summits Transl Sci Proc, V2017, P147
   LeCun Y, 2018, RES TECHNOL MANAGE, V61, P22, DOI 10.1080/08956308.2018.1516928
   Li XM, 2021, IEEE T MED IMAGING, V40, P2284, DOI 10.1109/TMI.2021.3075244
   Liu QD, 2020, IEEE T MED IMAGING, V39, P3429, DOI 10.1109/TMI.2020.2995518
   Liu Y, 2020, NAT MED, V26, P900, DOI 10.1038/s41591-020-0842-3
   McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6
   Mishra Supriya, 2020, 2020 International Conference on Smart Technologies in Computing, Electrical and Electronics (ICSTCEE), P515, DOI 10.1109/ICSTCEE49637.2020.9277506
   Misra I, 2020, PROC CVPR IEEE, P6706, DOI 10.1109/CVPR42600.2020.00674
   Islam SMS, 2018, Arxiv, DOI arXiv:1812.10595
   Mwanza JC, 2011, OPHTHAL SURG LAS IM, V42, P328, DOI 10.3928/15428877-20110603-05
   Newell A, 2020, PROC CVPR IEEE, P7343, DOI 10.1109/CVPR42600.2020.00737
   Nguyen QH, 2020, ICMLSC 2020: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING, P103, DOI 10.1145/3380688.3380709
   Ohri K, 2024, MULTIMED TOOLS APPL, V83, P14259, DOI 10.1007/s11042-023-16049-7
   Ohri K, 2021, KNOWL-BASED SYST, V224, DOI 10.1016/j.knosys.2021.107090
   Pan JJ, 2018, I C VIRTUAL REALITY, P46, DOI 10.1109/ICVRV.2018.00016
   Pardamean Bens, 2018, Procedia Computer Science, V135, P400, DOI 10.1016/j.procs.2018.08.190
   Paul A, 2021, IEEE T MED IMAGING, V40, P2642, DOI 10.1109/TMI.2021.3054817
   Porwal P, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101561
   Raghu M, 2019, ADV NEUR IN, V32
   Raschka S, 2020, Arxiv, DOI [arXiv:1811.12808, 10.48550/arXiv.1811.12808, DOI 10.48550/ARXIV.1811.12808]
   Rostami M, 2023, IEEE ACCESS, V11, P30247, DOI 10.1109/ACCESS.2023.3260652
   Roychowdhury S, 2021, IEEE ENG MED BIO, P2806, DOI 10.1109/EMBC46164.2021.9630682
   Sheikhpour R, 2023, KNOWL-BASED SYST, V269, DOI 10.1016/j.knosys.2023.110521
   Shurrab S, 2022, Arxiv, DOI arXiv:2109.08685
   Sowrirajan H, 2021, PR MACH LEARN RES, V143, P728
   Srinivasan V, 2021, Arxiv, DOI arXiv:2106.13497
   Stevens E., 2020, DEEP LEARNING PYTORC
   Taleb A, 2021, LECT NOTES COMPUT SC, V12729, P661, DOI 10.1007/978-3-030-78191-0_51
   Truong Tuan, 2021, Proc Machine Learning Research, P54
   Hagos MT, 2019, Arxiv, DOI arXiv:1905.07203
   Tymchenko B, 2020, Arxiv, DOI [arXiv:2003.02261, DOI 10.48550/ARXIV.2003.02261]
   van den Oord A, 2019, Arxiv, DOI arXiv:1807.03748
   Veličkovic P, 2018, Arxiv, DOI [arXiv:1809.10341, DOI 10.48550/ARXIV.1809.10341]
   Wang D, 2020, PROC CVPR IEEE, P3950, DOI 10.1109/CVPR42600.2020.00401
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   Yonglong Tian, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P776, DOI 10.1007/978-3-030-58621-8_45
   Yoo Y, 2014, LECT NOTES COMPUT SC, V8679, P117, DOI 10.1007/978-3-319-10581-9_15
   Zbontar J, 2021, PR MACH LEARN RES, V139
   Zhao QY, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102051
   Zheng YF, 2012, INDIAN J OPHTHALMOL, V60, P428, DOI 10.4103/0301-4738.100542
   Zhou Y, 2019, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2019.00218
   Zhu JW, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101746
   Zuckerberg M, 2022, Zuckerberg facebook live video called inside the lab: Building for the metaverse with AI
NR 87
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-16908-3
EA SEP 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000005
DA 2024-07-18
ER

PT J
AU Rawat, SS
   Verma, SK
   Kumar, Y
AF Rawat, Sur Singh
   Verma, Shashi Kant
   Kumar, Yatindra
TI Infrared small target detection based on Bi-Nuclear norm minimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Infrared search (IRST); Infrared patch image (IPI); Trace norm; Singular
   value decomposition; Background suppression factor (BSF); Receiver
   operating curve (ROC); Nuclear norm minimization (NNM); Signal clutter
   ratio (SCR)
ID PATCH-IMAGE MODEL; ALGORITHM
AB Infrared small target detection (ISTD) in complex backgrounds poses significant challenges in modern applications. Existing solutions based on infrared patch image (IPI) suffer from two key problems: nuclear norm (NN) and l1 norm defects. These defects allow false target points to persist in the target patch image (TPI) residuals, resulting in false alarms. Additionally, the IPI variants involving singular value decomposition (SVD) introduce high running complexity due to iterative operations. To address these issues, this paper introduces a novel IPI model based on Bi-Nuclear norm minimization (NNM) instead of NN to effectively control the background patch image (BPI) for small target detection in infrared images. Furthermore, to enhance accurate real target detection and minimize false targets, a weighted l1 norm is employed in place of the traditional l1 norm. The mathematical formulation of the proposed model employs the alternating direction method of the multiplier (ADMM). Experimental evaluation of the proposed solution against baseline methods demonstrates its superior capability in detecting real targets and reducing false targets in complex backgrounds. The comparative analysis verifies the effectiveness of the presented solution, showcasing improved results compared to existing baseline methods.
C1 [Rawat, Sur Singh] JSS Acad Tech Educ, Dept Comp Sci & Engn, Noida, India.
   [Verma, Shashi Kant] GBPIET, Dept Comp Sci & Engn, Pauri, India.
   [Kumar, Yatindra] GBPIET, Dept Elect Engn, Pauri, India.
RP Rawat, SS (corresponding author), JSS Acad Tech Educ, Dept Comp Sci & Engn, Noida, India.
EM sur.rawat@jssaten.ac.in
RI Rawat, Sur Singh/V-9496-2018; Verma, Shashi Kant/D-5447-2019
OI Rawat, Sur Singh/0000-0001-7394-6161; Verma, Shashi
   Kant/0000-0003-0660-3569
FU The authors would like to thanks all the reviewers.
FX The authors would like to thanks all the reviewers.
CR Bae TW, 2010, IEICE ELECTRON EXPR, V7, P112, DOI 10.1587/elex.7.112
   Bai XZ, 2010, PATTERN RECOGN, V43, P2145, DOI 10.1016/j.patcog.2009.12.023
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chen FJ, 2023, INFRARED PHYS TECHN, V133, DOI 10.1016/j.infrared.2023.104811
   Chen G, 2016, SIGNAL PROCESS, V119, P1, DOI 10.1016/j.sigpro.2015.06.027
   Dai YM, 2017, IEEE J-STARS, V10, P3752, DOI 10.1109/JSTARS.2017.2700023
   Dai YM, 2017, INFRARED PHYS TECHN, V81, P182, DOI 10.1016/j.infrared.2017.01.009
   Dai YM, 2016, INFRARED PHYS TECHN, V77, P421, DOI 10.1016/j.infrared.2016.06.021
   Deshpande SD, 1999, P SOC PHOTO-OPT INS, V3809, P74, DOI 10.1117/12.364049
   Dong X, 2023, IEEE Trans Comput Soc Syst
   Gao C, 2012, P 5 INT C IM SIGN PR
   Gao CQ, 2013, IEEE T IMAGE PROCESS, V22, P4996, DOI 10.1109/TIP.2013.2281420
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Gu YF, 2010, IEEE GEOSCI REMOTE S, V7, P469, DOI 10.1109/LGRS.2009.2039192
   Guo J, 2018, IET IMAGE PROCESS, V12, P70, DOI 10.1049/iet-ipr.2017.0353
   Hilliard CI, 2000, P SOC PHOTO-OPT INS, V4048, P74, DOI 10.1117/12.392022
   Hu T, 2010, J INFRARED MILLIM W, V29, P303
   Mohan K, 2012, J MACH LEARN RES, V13, P3441
   Ning X, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109216
   Rawat SS, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10040671
   Rawat SS, 2020, PROCEDIA COMPUT SCI, V167, P2496, DOI 10.1016/j.procs.2020.03.302
   Rawat SS, 2020, IET IMAGE PROCESS, V14, P1937, DOI 10.1049/iet-ipr.2019.1660
   REED I, 1988, IEEE T AERO ELEC SYS, V24, P327, DOI 10.1109/7.7174
   Shang FH, 2016, AAAI CONF ARTIF INTE, P2016
   Shang FH, 2016, JMLR WORKSH CONF PRO, V51, P620
   Srebro N, 2006, Advances in Neural Information Processing Systems, P1329
   Wang CL, 2022, INFRARED PHYS TECHN, V127, DOI 10.1016/j.infrared.2022.104375
   Wang CY, 2015, INFRARED PHYS TECHN, V69, P123, DOI 10.1016/j.infrared.2015.01.017
   Wang XY, 2017, IMAGE VISION COMPUT, V63, P1, DOI 10.1016/j.imavis.2017.04.002
   Wei XY, 2021, MULTIMED TOOLS APPL, V80, P33747, DOI 10.1007/s11042-021-11230-2
   Yan FJ, 2022, INFRARED PHYS TECHN, V125, DOI 10.1016/j.infrared.2022.104222
   Yu C, 2022, INFRARED PHYS TECHN, V123, DOI 10.1016/j.infrared.2022.104107
   Zhang LD, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11040382
   Zhang LD, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111821
   Zhong SS, 2023, MEASUREMENT, V211, DOI 10.1016/j.measurement.2023.112662
NR 36
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-16778-9
EA SEP 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000014
DA 2024-07-18
ER

PT J
AU Hoang-Xuan, N
   Trang-Trung, HP
   Tran, MK
   Le, TC
   Nguyen, ER
   Ninh, V
   Le, TK
   Tran, MT
AF Hoang-Xuan, Nhat
   Trang-Trung, Hoang-Phuc
   Tran, Mai-Khiem
   Le, Thanh-Cong
   Nguyen, E-Ro
   Ninh, Van-Tu
   Le, Tu-Khiem
   Tran, Minh-Triet
TI First-flexible interactive retrieval system for visual lifelog
   exploration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lifelog; Interactive retrieval; Information system; Joint embedding
   model; Component integration
AB Photos and videos are generated frequently in our daily activities. With a huge collection of visual data, it is essential to provide an efficient and easy-to-use system for users to retrieve moments of interest for a wide variation of query types. This motivates us to develop and upgrade our solution for visual lifelog exploration. Our solution includes a web-based retrieval system and a series of best practices to assist users in using our system. This paper details the enhanced version of FIRST, our Flexible Interactive Retrieval SysTem for visual lifelog retrieval. Our system supports multiple modalities for interaction and query processing, including visual query by meta-data, text query, and visual information matching based on a joint embedding model, scene clustering based on visual and location information, flexible temporal event navigation, and query expansion with visual examples. With a flexible system architecture, our system can easily integrate new modules to enhance its functionality. We conduct a user study to analyze the behaviors of novice and expert users of our system for different query scenarios. Finally, we propose best practice guidelines for users of our system to efficiently find events or moments of interest.
C1 [Hoang-Xuan, Nhat; Trang-Trung, Hoang-Phuc; Tran, Mai-Khiem; Le, Thanh-Cong; Nguyen, E-Ro; Tran, Minh-Triet] VNUHCM, Univ Sci, Ho Chi Minh City, Vietnam.
   [Trang-Trung, Hoang-Phuc; Tran, Mai-Khiem; Le, Thanh-Cong; Tran, Minh-Triet] VNUHCM, John Neumann Inst, Ho Chi Minh City, Vietnam.
   [Hoang-Xuan, Nhat; Trang-Trung, Hoang-Phuc; Tran, Mai-Khiem; Le, Thanh-Cong; Nguyen, E-Ro; Tran, Minh-Triet] Viet Nam Natl Univ, Ho Chi Minh City, Vietnam.
   [Ninh, Van-Tu; Le, Tu-Khiem] Dublin City Univ, Dublin, Ireland.
C3 Vietnam National University Hochiminh City; Vietnam National University
   Hochiminh City; Vietnam National University Hochiminh City; Dublin City
   University
RP Tran, MT (corresponding author), VNUHCM, Univ Sci, Ho Chi Minh City, Vietnam.; Tran, MT (corresponding author), VNUHCM, John Neumann Inst, Ho Chi Minh City, Vietnam.; Tran, MT (corresponding author), Viet Nam Natl Univ, Ho Chi Minh City, Vietnam.
EM hxnhat@selab.hcmus.edu.vn; tthphuc@selab.hcmus.edu.vn;
   tmkhiem@selab.hcmus.edu.vn; ltcong@selab.hcmus.edu.vn;
   nero@selab.hcmus.edu.vn; tu.ninhvan@adaptcentre.ie;
   tukhiem.le4@mail.dcu.ie; tmtriet@fit.hcmus.edu.vn
RI Tran, Minh-Triet/HTO-6586-2023
OI Tran, Minh-Triet/0000-0003-3046-3041
FU This research was funded by Vingroup and supported by Vingroup
   Innovation Foundation (VINIF) under project code VINIF.2019.DA19.
   [VINIF.2019]; Vingroup Innovation Foundation (VINIF)
FX This research was funded by Vingroup and supported by Vingroup
   Innovation Foundation (VINIF) under project code VINIF.2019.DA19.
CR Alam Naushad, 2022, LSC '22: Proceedings of the 5th Annual on Lifelog Search Challenge, P2, DOI 10.1145/3512729.3533006
   Alam N, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P53, DOI 10.1145/3463948.3469069
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Duane A, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P29, DOI 10.1145/3463948.3469067
   Faghri F, 2018, P BRIT MACH VIS C, P1
   Gurrin Cathal, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P584, DOI 10.1145/3372278.3388043
   Gurrin C, 2021, P INT C MULT RETR IC
   Gurrin C, 2021, PROCEEDINGS OF THE 2021 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR '21), P690, DOI 10.1145/3460426.3470945
   Gurrin C, 2019, ITE TRANS MEDIA TECH, V7, P46, DOI 10.3169/mta.7.46
   Heller S, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P35, DOI 10.1145/3463948.3469062
   Trang-Trung HP, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P81, DOI 10.1145/3463948.3469072
   Hoang-Xuan Nhat, 2022, P 2022 ACM WORKSH LI
   Krishna R, 2016, Arxiv, DOI arXiv:1602.07332
   Le N, 2019, WORKING NOTES CLEF 2, V2380
   Leibetseder A, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P23, DOI 10.1145/3463948.3469060
   Lin TY, 2015, Arxiv, DOI [arXiv:1405.0312, DOI 10.48550/ARXIV.1405.0312]
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Lokoc J, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P71, DOI 10.1145/3463948.3469074
   Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079
   Minh-Triet Tran, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P67, DOI 10.1145/3379172.3391726
   Nguyen Thao-Nhu, 2022, LSC '22: Proceedings of the 5th Annual on Lifelog Search Challenge, P14, DOI 10.1145/3512729.3533014
   Nguyen TN, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P41, DOI 10.1145/3463948.3469065
   Le NK, 2019, LSC '19 - PROCEEDINGS OF THE ACM WORKSHOP ON LIFELONG SEARCH CHALLENGE, P1, DOI 10.1145/3326460.3329155
   Radford A, 2021, PR MACH LEARN RES, V139
   Ren SQ, 2016, Arxiv, DOI [arXiv:1506.01497, DOI 10.1109/TPAMI.2016.2577031]
   Shin JH, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P59, DOI 10.1145/3463948.3469073
   Tran LD, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P11, DOI 10.1145/3463948.3469064
   Trang-Trung H, 2020, WORKING NOTES CLEF 2, V2696
   Vaswani A, 2017, ADV NEUR IN, V30
   Yaoyao Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12242, DOI 10.1109/CVPR42600.2020.01226
NR 30
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 21
PY 2023
DI 10.1007/s11042-023-16287-9
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S2KQ9
UT WOS:001069514100001
DA 2024-07-18
ER

PT J
AU Qi, JC
   Nguyen, M
   Yan, WQ
AF Qi, Jianchun
   Nguyen, Minh
   Yan, Wei Qi
TI CISO: Co-iteration semi-supervised learning for visual object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semi-supervised; Data augmentation; Transformer; CISO
AB Semi-supervised learning offers a solution to the high cost and limited availability of manually labeled samples in supervised learning. In semi-supervised visual object detection, the use of unlabeled data can significantly enhance the performance of deep learning models. In this paper, we introduce an end-to-end framework, named CISO (Co-Iteration Semi-Supervised Learning for Object Detection), which integrates a knowledge distillation approach and a collaborative, iterative semi-supervised learning strategy. To maximize the utilization of pseudo-label data and address the scarcity of pseudo-label data due to high threshold settings, we propose a mean iteration approach where all unlabeled data is applied to each training iteration. Pseudo-label data with high confidence is extracted based on an ever-changing threshold (average intersection over union of all pseudo-labeled data). This strategy not only ensures the accuracy of the pseudo-label but also optimizes the use of unlabeled data. Subsequently, we apply a weak-strong data augmentation strategy to update the model. Lastly, we evaluate CISO using Swin Transformer model and conduct comprehensive experiments on MS-COCO. Our framework showcases impressive results, outperforms the state-of-the-art methods by 2.16 mAP and 1.54 mAP with 10% and 5% labeled data, respectively.
C1 [Qi, Jianchun; Nguyen, Minh; Yan, Wei Qi] Auckland Univ Technol, Auckland 1010, New Zealand.
C3 Auckland University of Technology
RP Qi, JC (corresponding author), Auckland Univ Technol, Auckland 1010, New Zealand.
EM yhy5508@autuni.ac.nz; minh.nguyen@aut.ac.nz; weiqi.yan@aut.ac.nz
RI Nguyen, Minh/KLD-0648-2024
FU CAUL
FX & nbsp;Open Access funding enabled and organized by CAUL and its Member
   Institutions
CR Arazo E, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207304
   Bachman P, 2014, ADV NEUR IN, V27
   Bar A, 2022, PROC CVPR IEEE, P14585, DOI 10.1109/CVPR52688.2022.01420
   Berthelot D, 2019, ADV NEUR IN, V32
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chapelle O, 2010, MIT PRESS, V21, P2
   Chen BB, 2022, PROC CVPR IEEE, P14361, DOI 10.1109/CVPR52688.2022.01398
   Dean J., 2015, NIPS DEEP LEARNING R
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Heo B, 2019, IEEE I CONF COMP VIS, P1921, DOI 10.1109/ICCV.2019.00201
   Iscen A, 2019, PROC CVPR IEEE, P5065, DOI 10.1109/CVPR.2019.00521
   Janiesch C, 2021, ELECTRON MARK, V31, P685, DOI 10.1007/s12525-021-00475-2
   Jeong J, 2019, ADV NEUR IN, V32
   Joseph K. J., 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P5826, DOI 10.1109/CVPR46437.2021.00577
   Kim J., 2020, ADV NEUR IN, V33, P14567
   Komodakis N, 2017, P ICLR
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee D.-H., 2013, WORKSHOP CHALLENGES, V3, P896
   Li C.-L., 2020, Advances in neural information processing systems, V33, P596
   Li K, 2021, P IEEE CVF INT C COM, P8578, DOI DOI 10.1109/ICASSP39728.2021.9414376
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YC, 2022, INT C LEARN REPR, P1
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Park W, 2019, PROC CVPR IEEE, P3962, DOI 10.1109/CVPR.2019.00409
   Passalis Nikolaos, 2018, CoRR, V1, P5
   Qizhe Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10684, DOI 10.1109/CVPR42600.2020.01070
   Rasmus A, 2015, ADV NEUR IN, V28
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romero A., 2014, 3 INT C LEARN REPRES
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sajjadi M, 2016, ADV NEUR IN, V29
   Sajjadi M, 2016, IEEE IMAGE PROC, P1908, DOI 10.1109/ICIP.2016.7532690
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Simard PY, 2003, PROC INT CONF DOC, P958
   Sohn K., 2021, ARXIV
   Suzuki T, 2022, PROC CVPR IEEE, P10894, DOI 10.1109/CVPR52688.2022.01063
   Tang YH, 2021, PROC CVPR IEEE, P3131, DOI 10.1109/CVPR46437.2021.00315
   Tarvainen A, 2017, ADV NEUR IN, V30
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085
   Xie Q., 2020, ADV NEURAL INFORM PR, V33, P6256, DOI DOI 10.48550/ARXIV.1904.12848
   Xu MD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3040, DOI 10.1109/ICCV48922.2021.00305
   Yang F, 2022, PROC CVPR IEEE, P14401, DOI 10.1109/CVPR52688.2022.01402
   Yang QZ, 2021, PROC CVPR IEEE, P5937, DOI 10.1109/CVPR46437.2021.00588
   Yang XW, 2023, IEEE T NEUR NET LEAR, V34, P7339, DOI [10.1109/TNNLS.2022.3141463, 10.1109/IECON49645.2022.9968880]
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu J., 2016, P 24 ACM INT C MULT, P516, DOI DOI 10.1145/2964284.2967274
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhai XH, 2019, IEEE I CONF COMP VIS, P1476, DOI 10.1109/ICCV.2019.00156
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhou Q, 2021, PROC CVPR IEEE, P4079, DOI 10.1109/CVPR46437.2021.00407
NR 59
TC 1
Z9 1
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33941
EP 33957
DI 10.1007/s11042-023-16915-4
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900017
OA hybrid
DA 2024-07-18
ER

PT J
AU Roy, M
   Baruah, U
   Varma, V
AF Roy, Manojeet
   Baruah, Ujwala
   Varma, Vivek
TI TransDL: A transfer learning-based concatenated model for Covid-19
   identification and analysis of posteroanterior chest X-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Covid-19; Xception; Inception; ResNext-50; Chest-X-ray images; CNN
ID SEGMENTATION; INFECTION
AB In this work, a dataset of chest posteroanterior X-ray images has been used to categorise the images into three classes Covid-19, Normal and Pneumonic conditions. This paper addresses the Covid-19 classification problem by the application of Machine Learning (ML) and Deep Learning (DL) techniques. Active research work is ongoing in this area to aid and provide support to doctors treating patients. Several pre-trained models in a deep convolution network have been used. Introduction of a concatenation of pre-trained models based on its earlier work on the same dataset has been done. Transfer learning (TL) is a powerful computer vision technique that helps us to produce accurate models efficiently. Here, three customized pre-trained models, mainly Xception net, InceptionV3, and ResNext50, have been established and combined with model convolution neural networks with appropriate parameters. With the proposed model we have achieved improved results with this data set by applying feature extraction, selection, and concatenation the features generated by all three models. In the experimental results, the Xception model gave the best results as compared to the remaining two for Covid-19 detection. Application of all the three models collectively with our proposed approach has improved the classification accuracy score to around 98.44%. Which is an improvement of 4.44% on the previous work (Jain et al. Appl Intell 51(3):1690-1700, 2021).
C1 [Roy, Manojeet; Baruah, Ujwala; Varma, Vivek] Natl Inst Technol Silchar, Comp Sci & Engn, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Roy, M (corresponding author), Natl Inst Technol Silchar, Comp Sci & Engn, Silchar 788010, Assam, India.
EM manojeet_rs@cse.nits.ac.in; ujwala@cse.nits.ac.in;
   vivek_pg@cse.nits.ac.in
FU Not applicable
FX Not applicable
CR Afshar P, 2020, PATTERN RECOGN LETT, V138, P638, DOI 10.1016/j.patrec.2020.09.010
   Ajlan AM, 2014, AM J ROENTGENOL, V203, P782, DOI 10.2214/AJR.14.13021
   Alqudah A. M., 2020, Automated systems for detection of Covid-19 using chest X-ray images and lightweight convolutional neural networks, V4, DOI 10.1007/s13246-020-00865-4
   Alzubaidi L, 2021, ARXIV
   Ayan E, 2019, 2019 SCIENTIFIC MEETING ON ELECTRICAL-ELECTRONICS & BIOMEDICAL ENGINEERING AND COMPUTER SCIENCE (EBBT), DOI 10.1109/ebbt.2019.8741582
   Ayaz M, 2021, PHYS ENG SCI MED, V44, P183, DOI 10.1007/s13246-020-00966-0
   Bacellar GC, 2021, MEDRXIV
   Basile C, 2020, NEPHROL DIAL TRANSPL, V35, P737, DOI 10.1093/ndt/gfaa069
   Choi WJ, 2016, KOREAN J RADIOL, V17, P166, DOI 10.3348/kjr.2016.17.1.166
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chollet F., 2021, DEEP LEARNING PYTHON
   Chowdhury NK, 2020, HEALTH INF SCI SYST, V8, DOI 10.1007/s13755-020-00119-3
   Gómez O, 2021, NEUROCOMPUTING, V456, P575, DOI 10.1016/j.neucom.2020.10.116
   Haritha D, 2020, PROCEEDINGS OF THE 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND SECURITY (ICCCS-2020), DOI 10.1109/icccs49678.2020.9276795
   Huynh HT, 2019, IEEE RIVF INT CONF, P250, DOI 10.1109/rivf.2019.8713648
   Jain R, 2021, APPL INTELL, V51, P1690, DOI 10.1007/s10489-020-01902-1
   Jeyagopal J, 2021, INT C EM TECHN INT S, P205
   kaggle competitions, 2021, COVID 19 XRAY IM CLA
   Kanne JP, 2020, RADIOLOGY, V295, P16, DOI 10.1148/radiol.2020200241
   Ke Wang, 2020, IOP Conference Series: Earth and Environmental Science, V474, DOI 10.1088/1755-1315/474/3/032030
   Kermany Daniel, 2018, Mendeley Data, V3
   Levy D, 2016, ARXIV
   Li Y, 2020, NEUROCOMPUTING, V391, P25, DOI 10.1016/j.neucom.2020.01.054
   Majeed T, 2020, PHYS ENG SCI MED, V43, P1289, DOI 10.1007/s13246-020-00934-8
   Mooney P, 2020, Chest x-ray images (pneumonia)
   Nikolaou V, 2021, HEALTH INF SCI SYST, V9, DOI 10.1007/s13755-021-00166-4
   Nowlan Steven., 1990, Advances in Neural Information Processing Systems, V3
   Patel P, 2020, COVID CHEST XRAY DAT
   Perumal V, 2021, APPL INTELL, V51, P341, DOI 10.1007/s10489-020-01831-z
   Punia R., 2020, 2020 INT C EMERGING, P1
   Qiu GG, 2020, ACS NANO, V14, P5268, DOI 10.1021/acsnano.0c02439
   Raikote P, 2021, COVID 19 IMAGE DATAS
   Sekeroglu B, 2020, SLAS TECHNOL, V25, P553, DOI 10.1177/2472630320958376
   Low WCS, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/5528144
   Sharma Shivani, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P344, DOI 10.1109/ICAIS50930.2021.9395851
   Shuwan Pan, 2019, 2019 IEEE 4th International Conference on Image, Vision and Computing (ICIVC), P105, DOI 10.1109/ICIVC47709.2019.8981350
   Siddhu AK, 2020, REV PAPER DETECTION, P39
   Stirenko S, 2018, 2018 IEEE 38TH INTERNATIONAL CONFERENCE ON ELECTRONICS AND NANOTECHNOLOGY (ELNANO), P422, DOI 10.1109/ELNANO.2018.8477564
   Subramanian R.R., 2020, INT J CONTROL AUTOM, V13, P154
   Wang S, 2021, EUR RADIOL, V31, P6096, DOI [10.1080/1064119X.2021.1966557, 10.1079/9781789246070.0001, 10.1007/s00330-021-07715-1]
   Wang Y, 2020, ARXIV
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xie X., 2006, MINING XRAY IMAGES S
   Yao XQ, 2022, MATH EDUC RES J, V34, P241, DOI 10.1007/s13394-020-00343-w
   Yasin R, 2020, EGYPT J RADIOL NUC M, V51, DOI 10.1186/s43055-020-00296-x
NR 45
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33421
EP 33443
DI 10.1007/s11042-023-16825-5
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900009
DA 2024-07-18
ER

PT J
AU Veena, RC
   Brahmananda, SH
AF Veena, R. C.
   Brahmananda, S. H.
TI An efficient eavesdropping model for detection of advanced persistent
   threat (APT) in high volume network traffic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE APT; Network analysis; Hacking; Antivirus; Network security; Sniffing;
   R; Transmission control protocol (TCP); Network Interface cards (NICs);
   Cyclic redundancy check (CRC)
ID INTRUSION DETECTION; ATTACKS
AB Eavesdropping, commonly referred to as network analysis, is the process of gathering data traffic. To check if attackers are sneaking into a network, a thorough examination is essential. The risk of APT has considerably increased as a result of the rapid expansion of internet use and linked gadgets. The goal of this research is to develop an eavesdropping model. To train the developed system, the publicly available dataset having a range of simulated breaches in a military-grade network environment is used. The model can examine, decode, and display malicious data packets from commonly used protocols. The objective is to determine whether a threat might be present in the network. Before the firewall, a program keeps track of data transfer over a network. The detection model's use of historical learning of publicly accessible threat patterns is what makes this study novel. Among the features is a reliable model for APT detection, an intuitive user interface, and statistical capabilities to analyze. With an accuracy of 99.99% and a detection time of 0.2 seconds, Random Forest provided the greatest classification performance. The acquired accuracy is higher than the 98.85% accuracy that was previously published.
C1 [Veena, R. C.; Brahmananda, S. H.] GITAM Univ, Dept Comp Sci & Engn, Bengaluru, Karnataka, India.
C3 Gandhi Institute of Technology & Management (GITAM)
RP Veena, RC (corresponding author), GITAM Univ, Dept Comp Sci & Engn, Bengaluru, Karnataka, India.
EM vchalapa@gitam.edu; bsavadat@gitam.edu
CR Abdullahi M, 2013, INTELL SYST ENG, V4, DOI [10.5120/2222-2863, DOI 10.5120/2222-2863]
   Abdullayeva FJ, 2021, ARRAY-NY, V10, DOI 10.1016/j.array.2021.100067
   Ashoor AS, 2011, COMM COM INF SC, V196, P497
   Attack.mitre.org, 2022, US
   Auty Mike, 2015, Network Security, V2015, P13, DOI 10.1016/S1353-4858(15)30028-3
   Do Xuan C, 2021, J INTELL FUZZY SYST, V40, P11311, DOI 10.3233/JIFS-202465
   Xuan CD, 2021, NEURAL COMPUT APPL, V33, P13251, DOI 10.1007/s00521-021-05952-5
   Do Xuan C, 2020, J INTELL FUZZY SYST, V39, P4785, DOI 10.3233/JIFS-200694
   Choi J, 2015, 2015 10TH INTERNATIONAL CONFERENCE ON BROADBAND AND WIRELESS COMPUTING, COMMUNICATION AND APPLICATIONS (BWCCA 2015), P375, DOI 10.1109/BWCCA.2015.69
   Cordero CG, 2021, ACM T PRIV SECUR, V24, DOI 10.1145/3424155
   Coulter R, 2022, COMPUT SECUR, V112, DOI 10.1016/j.cose.2021.102496
   Cremer F, 2022, GENEVA PAP R I-ISS P, V47, P698, DOI 10.1057/s41288-022-00266-6
   Dijk A, 2021, IEEE INT CONF BIG DA, P2092, DOI 10.1109/BigData52589.2021.9671464
   Cho DX, 2019, PROCEDIA COMPUT SCI, V150, P316, DOI 10.1016/j.procs.2019.02.058
   Ferriyan A., 2021, HIKARI 2021 GENERATI
   FKIE F, 2022, TURLA GROUP THREAT A
   Gao XW, 2019, IEEE ACCESS, V7, P82512, DOI 10.1109/ACCESS.2019.2923640
   Ghafir I, 2018, FUTURE GENER COMP SY, V89, P349, DOI 10.1016/j.future.2018.06.055
   Goh VT, 2009, 2009 INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY (ARES), VOLS 1 AND 2, P540, DOI 10.1109/ARES.2009.76
   Haas S., 2020, THESIS STAATS UNIVER
   Harutyunyan AN, 2014, IEEE IFIP NETW OPER
   Hasan M M., 2023, SN Comput Sci, V4, DOI DOI 10.1007/S42979-023-01744-X
   Joloudari JH, 2020, IEEE ACCESS, V8, P186125, DOI 10.1109/ACCESS.2020.3029202
   Hesselman C, 2020, IEEE INTERNET COMPUT, V24, P23, DOI 10.1109/MIC.2020.3005388
   Nguyen HC, 2023, J INTELL FUZZY SYST, V44, P3459, DOI 10.3233/JIFS-221055
   Hofer-Schmitz K, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10060704
   Jang-Jaccard J, 2014, J COMPUT SYST SCI, V80, P973, DOI 10.1016/j.jcss.2014.02.005
   Kdd.ics.uci.edu, 2022, KDD CUP 1999 DAT
   Khammassi C, 2017, COMPUT SECUR, V70, P255, DOI 10.1016/j.cose.2017.06.005
   Khraisat A, 2019, CYBERSECURITY, V2, DOI 10.1186/s42400-019-0038-7
   Kshirsagar Deepak, 2021, ICT Express, V7, P371
   Kumar G, 2012, APPL COMPUT INTELL S, V2012, DOI 10.1155/2012/850160
   LANDWEHR CE, 1994, ACM COMPUT SURV, V26, P211, DOI 10.1145/185403.185412
   Lee S, 2019, J SUPERCOMPUT, V75, P4267, DOI 10.1007/s11227-018-2440-4
   Lu JZ, 2019, CLUSTER COMPUT, V22, pS7347, DOI 10.1007/s10586-017-1256-y
   Marchetti M, 2016, COMPUT NETW, V109, P127, DOI 10.1016/j.comnet.2016.05.018
   Milajerdi SM, 2019, P IEEE S SECUR PRIV, P1137, DOI 10.1109/SP.2019.00026
   Mohamed N, 2021, IEEE ACCESS, V9, P42919, DOI 10.1109/ACCESS.2021.3066289
   Neuschmied H, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136816
   Panahnejad M, 2022, J SUPERCOMPUT, V78, P8644, DOI 10.1007/s11227-021-04201-9
   Quintero-Bonilla S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113874
   Rajagopal S, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/4586875
   Moya JR, 2017, OPEN MATH, V15, P1108, DOI 10.1515/math-2017-0094
   Rath PS., 2017, IJCNCS, V5, P49
   Sadreazami H, 2018, IEEE T SIGNAL INF PR, V4, P137, DOI 10.1109/TSIPN.2017.2749976
   Seo J, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/9706706
   Shyu ML, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P353
   Siddique K, 2019, COMPUTER, V52, P41, DOI 10.1109/MC.2018.2888764
   Singh S, 2019, J SUPERCOMPUT, V75, P4543, DOI 10.1007/s11227-016-1850-4
   Su TT, 2020, IEEE ACCESS, V8, P29575, DOI 10.1109/ACCESS.2020.2972627
   Tatam M, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e05969
   Walkinshaw N, 2016, EMPIR SOFTW ENG, V21, P811, DOI 10.1007/s10664-015-9367-7
   Wang Y, 2020, J NETW COMPUT APPL, V154, DOI 10.1016/j.jnca.2020.102534
   Xiao L, 2018, IEEE SIGNAL PROC MAG, V35, P41, DOI 10.1109/MSP.2018.2825478
   Xuan C., 2020, INT J EMERGING TREND, V8, P1809, DOI [10.30534/ijeter/2020/53852020, DOI 10.30534/IJETER/2020/53852020]
   Yan JH, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/5036710
   Zhou YY, 2020, COMPUT NETW, V174, DOI 10.1016/j.comnet.2020.107247
NR 57
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32123
EP 32139
DI 10.1007/s11042-023-16684-0
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900015
DA 2024-07-18
ER

PT J
AU Ghoul, Y
   Naifar, O
AF Ghoul, Yamna
   Naifar, Omar
TI IoT based applications for healthcare and home automation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IoT; healthcare; home automation; sensors; Android; Bluetooth; ZigBee
AB The Internet of Things (IoT) is a paradigm that involves connecting the virtual world of the Internet to the real world through so-called smart objects. Indeed, Internet of Things (IoT) devices are extensively employed in a wide range of applications, including healthcare field and home automation. These objects are equipped with communication capabilities and can exchange data over the Internet. In recent times, the healthcare sector has witnessed a surge of growth and transformation. The integration of IoT-enabled devices has revolutionized remote monitoring in healthcare, empowering healthcare providers to keep their patients safe and healthy while delivering exceptional care. On the other hand, the home automation system is becoming increasingly popular due to its many benefits, which involve remotely monitoring and controlling household appliances. In fact, the main challenges faced by home automation systems are poor manageability, rigidity, difficulty in achieving security, and high ownership costs. As the internet and its applications continue to grow, there is enormous potential for remotely accessing, controlling and monitoring network-enabled devices. With this context in mind, the objective of this project is to develop two IoT-based models. These models are based on Arduino and Raspberry pi boards, cloud, Bluetooth and ZigBee protocols. The first model is an IoT healthcare system that employs various sensors to collect heart rate and motion data. The second model is a home automation system that utilizes a DHT11 sensor to measure temperature and humidity levels, a MQ2 sensor to detect gas leaks, and an ultrasonic sensor to control the garage door's opening and closing. Both systems are built around an Arduino or a Raspberry pi microcontrollers integrated with an Android mobile application to process and transmit data via Bluetooth or Zigbee ensuring that the mobile app receives real-time updates.
C1 [Ghoul, Yamna] Univ Tunis El Manar, Natl Engn Sch Tunis, LR11ES20 Anal Concept & Control Syst Lab, BP 37, Tunis 1002, Tunisia.
   [Naifar, Omar] Univ Sfax, Natl Engn Sch Sfax, Control & Energy Manamgment Lab, Sfax, Tunisia.
   [Naifar, Omar] Univ Kairouan, Higher Inst Appl Sci & Technol Kairouan, Kairouan, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Kairouan
RP Ghoul, Y (corresponding author), Univ Tunis El Manar, Natl Engn Sch Tunis, LR11ES20 Anal Concept & Control Syst Lab, BP 37, Tunis 1002, Tunisia.
EM yamnagea@hotmail.fr
CR Akan OB, 2019, IEEE COMMUN MAG, V57, P40, DOI 10.1109/mcom.2020.9071994
   Ali F, 2020, INFORM FUSION, V63, P208, DOI 10.1016/j.inffus.2020.06.008
   Ali Z, 2018, FUTURE GENER COMP SY, V85, P19, DOI 10.1016/j.future.2018.02.021
   Ashton K., 2009, RFID J, V22, P97
   Avatefipour O, 2018, INT CONF ELECTRO INF, P1041
   Ayaz M, 2019, IEEE ACCESS, V7, P129551, DOI 10.1109/ACCESS.2019.2932609
   Caputo S, 2021, Academia Lett, DOI [10.20935/al537, DOI 10.20935/AL537]
   Cele B, 2021, Quarter One Crime Statistics
   De Brouwer M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103514
   Eshratifar AE, 2021, IEEE T MOBILE COMPUT, V20, P565, DOI 10.1109/TMC.2019.2947893
   Evans D., 2011, Whitepaper, DOI DOI 10.1109/IEEESTD.2007.373646
   Feki MA, 2013, COMPUTER, V46, P24, DOI 10.1109/MC.2013.63
   Froiz-Miguez I, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082660
   Ghosh A, 2021, ENG CONSTR ARCHIT MA, V28, P457, DOI 10.1108/ECAM-04-2020-0271
   Gladence LM, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01968-2
   Govindraj V, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES FOR SMART NATION (SMARTTECHCON), P1059, DOI 10.1109/SmartTechCon.2017.8358532
   Holler, 2014, From Machine-to-Machine to the Internet of Things: Introduction to a New Age of Intelligence, V1, DOI [10.1016/c2012-0-03263-2, DOI 10.1016/C2012-0-03263-2]
   Ismail A, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12062403
   Khan M, 2018, WIRELESS PERS COMMUN, V99, P1683, DOI 10.1007/s11277-018-5336-y
   Majeed R, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/4579291
   Manogaran G, 2018, FUTURE GENER COMP SY, V82, P375, DOI 10.1016/j.future.2017.10.045
   Mathew PS, 2018, LECT NOTE DATA ENG, V14, P263, DOI 10.1007/978-3-319-70688-7_11
   Menon VG, 2022, INTERNET THINGS-NETH, V18, DOI 10.1016/j.iot.2020.100213
   Modu B, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7080836
   Nachankar PJ, 2018, Decision Making, V1, DOI [10.1201/9781003125433-8, DOI 10.1201/9781003125433-8]
   Patan R, 2020, SUSTAIN CITIES SOC, V59, DOI 10.1016/j.scs.2020.102141
   Pereira Sergio, 2018, Understanding and Interpreting Machine Learning in Medical Image Computing Applications. First International Workshops MLCN 2018, DLF 2018, and iMIMIC 2018. Held in Conjunction with MICCAI 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11038), P106, DOI 10.1007/978-3-030-02628-8_12
   Qin Erwa, 2013, Human Interface and the Management of Information. Information and Interaction for Health, Safety, Mobility and Complex Environments. 15th International Conference, HCI International 2013. Proceedings: LNCS 8017, P173, DOI 10.1007/978-3-642-39215-3_21
   Rani PJ., 2017, Voice controlled home automation system using natural language processing (NLP) and internet of things (IoT), in Proceedings of the Third International Conference on Science Technology Engineering and Management, DOI [10.1109/iconstem.2017.8261311, DOI 10.1109/ICONSTEM.2017.8261311]
   Subasi A, 2020, Innovation in Health Informatics, P123, DOI DOI 10.1016/B978-0-12-819043-2.00005-8
   Swati ZNK, 2019, COMPUT MED IMAG GRAP, V75, P34, DOI 10.1016/j.compmedimag.2019.05.001
   Verma P, 2020, MICROPROCESS MICROSY, V72, DOI 10.1016/j.micpro.2019.102929
   Villamil S., 2020, Telkomnika, V18, P2320, DOI [10.12928/telkomnika.v18i5.15911, DOI 10.12928/TELKOMNIKA.V18I5.15911]
   Weissberger A, 2014, IEEE Com Soc., DOI [10.1109/lcnw.2012.6424034, DOI 10.1109/LCNW.2012.6424034]
NR 34
TC 0
Z9 0
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29945
EP 29967
DI 10.1007/s11042-023-16774-z
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066065600008
DA 2024-07-18
ER

PT J
AU Aloraini, M
AF Aloraini, Mohammed
TI Two-stream convolutional networks for skin cancer classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin cancer classification; Convolutional neural networks; Medical
   images; Classification
AB Skin cancer has become a popular disease as it represents one-third of all diagnosed cancers around the world. This cancer kills many people every year, and it is therefore important to detect skin cancer at an early stage to increase the survival rate. Detecting the exact type of skin cancer is a challenging problem due to the similar appearance between types of skin cancer. In this paper, we propose a novel approach based on combining two streams of convolutional neural networks to detect and classify skin cancer. We use RGB images and gradient images as inputs to the two streams of convolutional neural networks. We combine gradient images that contain high frequency information with RGB images to enhance classification accuracy. The experimental results show that the proposed approach achieves state-of-the-art accuracy (96.67%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$96.67\%$$\end{document}) using Human Against Machine (HAM10000) data set.
C1 [Aloraini, Mohammed] Qassim Univ, Dept Elect Engn, Coll Engn, Unaizah 56452, Saudi Arabia.
C3 Qassim University
RP Aloraini, M (corresponding author), Qassim Univ, Dept Elect Engn, Coll Engn, Unaizah 56452, Saudi Arabia.
EM mo.aloraini@qu.edu.sa
RI Aloraini, Mohammed/JOJ-9695-2023
OI Aloraini, Mohammed/0000-0002-1655-8098
CR Adegun A, 2021, ARTIF INTELL REV, V54, P811, DOI 10.1007/s10462-020-09865-y
   Aladhadh S, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22114008
   Alquran H, 2017, IEEE JORDAN CONF APP
   Ansari U. B., 2017, Int. Res. J. Eng. Technol, V4, P2875
   Atta A, 2022, INT C CYB RES DUB UN, P01, DOI [10.1109/ICCR56254.2022.9995928, DOI 10.1109/ICCR56254.2022.9995928]
   Carcagnì P, 2019, LECT NOTES COMPUT SC, V11751, P335, DOI 10.1007/978-3-030-30642-7_30
   Chaturvedi SS, 2020, MULTIMED TOOLS APPL, V79, P28477, DOI 10.1007/s11042-020-09388-2
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dalila F, 2017, OPTIK, V140, P749, DOI 10.1016/j.ijleo.2017.04.084
   Danielsson P.-E., 1990, Machine Vision for Three-Dimensional Scenes, P347, DOI DOI 10.1016/B978-0-12-266722-0.50016-6
   Fitzmaurice C, 2020, JAMA ONCOL, V6, P444, DOI 10.1001/jamaoncol.2020.0224
   Fitzmaurice C, 2019, JAMA ONCOL, V5, P1749, DOI 10.1001/jamaoncol.2019.2996
   Foundation TSC, 2022, Skin cancer 101
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gouda W, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10071183
   Haggenmüller S, 2021, EUR J CANCER, V156, P202, DOI 10.1016/j.ejca.2021.06.049
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang HW, 2021, J DERMATOL, V48, P310, DOI 10.1111/1346-8138.15683
   Jaculin Femil J., 2023, Computer Systems Science and Engineering, V45, P2919, DOI [10.32604/csse.2023.032935, DOI 10.32604/CSSE.2023.032935]
   Jain S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21238142
   Khan MA, 2018, BMC CANCER, V18, DOI 10.1186/s12885-018-4465-8
   Kittler H, 2002, LANCET ONCOL, V3, P159, DOI 10.1016/S1470-2045(02)00679-4
   Mazhar T, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11030415
   Reis HC, 2022, MED BIOL ENG COMPUT, V60, P643, DOI 10.1007/s11517-021-02473-0
   Setiawan Agung W., 2020, 2020 International Seminar on Intelligent Technology and Its Applications (ISITIA). Proceedings, P148, DOI 10.1109/ISITIA49792.2020.9163734
   Shahin AH, 2018, CAIRO INT BIOM ENG, P150, DOI 10.1109/CIBEC.2018.8641815
   Shetty Aakash, 2022, Proceedings of the 2nd International Conference on Recent Trends in Machine Learning, IoT, Smart Cities and Applications: ICMISC 2021. Lecture Notes in Networks and Systems (237), P103, DOI 10.1007/978-981-16-6407-6_11
   Society AC, 2022, Cancer facts & figures 2022
   Taufiq MA, 2017, L N INST COMP SCI SO, V181, P468, DOI 10.1007/978-3-319-49655-9_57
   Tembhurne JV, 2023, MULTIMED TOOLS APPL, V82, P27501, DOI 10.1007/s11042-023-14697-3
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
NR 31
TC 0
Z9 0
U1 9
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30741
EP 30753
DI 10.1007/s11042-023-16758-z
EA SEP 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066976400007
DA 2024-07-18
ER

PT J
AU Hao, DS
   Zhu, M
   Zhang, C
   Yuan, G
   Yan, QY
   Zhuang, XB
AF Hao, Dashuai
   Zhu, Mu
   Zhang, Chen
   Yuan, Guan
   Yan, Qiuyan
   Zhuang, Xiaobao
TI A lightweight attention-based network for micro-expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-expression; Attention mechanism; Deep learning; Model optimization
AB Micro-expression has emerged to be a feasible strategy in affective estimation due to its great reliability in emotion detection. Recent years have witnessed that deep learning methods were successfully applied to the micro-expression recognition field. In visual data, micro-expression only exists in regions such as eyebrows and mouth, etc, which leads to its imbalanced distribution. Therefore, it's difficult for networks to distinguish the above micro-expression description with weak intensity when extracting feature maps. To tackle such issues, we propose a novel lightweight attention model, LAM, to improve the network recognition performance. LAM is enabled to calculate the correlation between the feature maps (channel dimension) and the correlation within the feature maps (spatial dimension), thus helping the network to focus on micro-expression information. Additionally, cooperated with residual block at various scales in Resnet, LAM can adaptively compute and update the feature maps in each network layer. Technically, coping with small datasets, we build LAM without adding obvious parameters, while a straightforward but efficient strategy that transfer facial expression knowledge is utilized together. Extensive experimental evaluations on two benchmarks (CASME II and SAMM) and post-hoc feature visualizations demonstrate the effectiveness of our proposed network with LAM.
C1 [Hao, Dashuai; Zhang, Chen; Yuan, Guan; Yan, Qiuyan; Zhuang, Xiaobao] China Univ Min & Technol, Sch Comp Sci & Technol, 1 Daxue Rd, Xuzhou 221116, Jiangsu, Peoples R China.
   [Zhu, Mu] State Key Lab NBC Protect Civilian, Beijing 100038, Peoples R China.
   [Yuan, Guan] Minist Educ, Engn Res Ctr, Digitizat Mine, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Yuan, G (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, 1 Daxue Rd, Xuzhou 221116, Jiangsu, Peoples R China.; Zhu, M (corresponding author), State Key Lab NBC Protect Civilian, Beijing 100038, Peoples R China.; Yuan, G (corresponding author), Minist Educ, Engn Res Ctr, Digitizat Mine, Xuzhou 221116, Jiangsu, Peoples R China.
EM zhumubest@163.com; yuanguan@cumt.edu.cn
RI Wang, Yibin/KEZ-9645-2024; WANG, SHIHAO/KHC-8263-2024; Wang,
   Yuhan/KGL-5855-2024; Wang, Fei/KEH-6292-2024
FU National Natural Science Foundation of China
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 71774159 and 61977061, the Fund of
   State Key Laboratory of NBC Protection for Civilian under Grants
   SKLNBC2020-23. Dr. Dashuai Hao and Dr. Chen Zhang contribute equally to
   this work.
CR Bhall RK, 2015, Int J Educ Sci Res Rev (IJESRR), V2
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Davison AK, 2018, IEEE T AFFECT COMPUT, V9, P116, DOI 10.1109/TAFFC.2016.2573832
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ekman P., 2007, Emotions revealed: Recognizing faces and feelings to improve communication and emotional life, V2nd ed.
   Huang XH, 2019, IEEE T AFFECT COMPUT, V10, P32, DOI 10.1109/TAFFC.2017.2713359
   Huang XH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1, DOI 10.1109/ICCVW.2015.10
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jakkula V., 2006, Sch. EECS Wash. State Univ, V37, P3
   Khor HQ, 2019, IEEE IMAGE PROC, P36, DOI [10.1109/icip.2019.8802965, 10.1109/ICIP.2019.8802965]
   Khor HQ, 2018, IEEE INT CONF AUTOMA, P667, DOI 10.1109/FG.2018.00105
   Lei L, 2021, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW53098.2021.00173
   [梁正友 Liang Zhengyou], 2020, [计算机科学, Computer Science], V47, P227
   Liu Y, 2019, 2019 14 IEEE INT C A, P23
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Merghani W, 2018, IEEE INT CONF AUTOMA, P662, DOI 10.1109/FG.2018.00104
   Oh TH, 2018, LECT NOTES COMPUT SC, V11208, P663, DOI 10.1007/978-3-030-01225-0_39
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   Porter S, 2008, PSYCHOL SCI, V19, P508, DOI 10.1111/j.1467-9280.2008.02116.x
   Russell TA, 2006, BRIT J CLIN PSYCHOL, V45, P579, DOI 10.1348/014466505X90866
   Sánchez J, 2013, IMAGE PROCESS ON LIN, V3, P137, DOI 10.5201/ipol.2013.26
   Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x
   Tang H., 2022, Image Video Process, V34, P2, DOI [10.1117/12.2611281, DOI 10.1117/12.2611281]
   Wang CY, 2020, NEUROCOMPUTING, V410, P354, DOI 10.1016/j.neucom.2020.06.005
   Wang SJ, 2014, NEURAL PROCESS LETT, V39, P25, DOI 10.1007/s11063-013-9288-7
   Wang YD, 2015, LECT NOTES COMPUT SC, V9003, P525, DOI 10.1007/978-3-319-16865-4_34
   Wei J., 2022, Multimed Tools Appl, V5, P1
   Wei JS, 2021, NEUROCOMPUTING, V449, P159, DOI 10.1016/j.neucom.2021.03.063
   Weinberger S, 2010, NATURE, V465, P412, DOI 10.1038/465412a
   Xia B, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2936, DOI 10.1145/3394171.3413774
   Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Zhang J., 2022, Complex Intell Syst, V2, P1
NR 37
TC 0
Z9 0
U1 11
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29239
EP 29260
DI 10.1007/s11042-023-16616-y
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066976400011
DA 2024-07-18
ER

PT J
AU Jyothi, P
   Pradeepini, G
AF Jyothi, P.
   Pradeepini, G.
TI Heart disease detection system based on ECG and PCG signals with the aid
   of GKVDLNN classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heart disease detection; Phonocardiography (PCG); Electrocardiography
   (ECG); Feature extraction; Chicken swarm optimization algorithm (CSOA);
   Empirical mode decomposition (EMD); Normalization
ID MODEL
AB One among the major causes of death in the country is Heart disease (HD). 17.3 million deaths per year are caused by cardiac diseases, which is the primary reason for death in the globe as per the World Health Organization (WHO). Hence, the early detection of heart disease increases the survival rate. For an efficient detection of HD, a wide variety of techniques are used. But, the techniques rely on limited data; this degrades the accuracy and the performance of the model. So, to deal with these shortcomings, this paper has proposed Gaussian Kaiming Variance-based Deep Learning Neural Network (GKVDLNN) classifier for HD. In this study, the problem of heart disease detection using ECG and PCG signals is investigated, which provides valuable information about heart function. Thereby, the possible abnormalities of the heart are identified. Moreover, large data are used in this work to ensure the model's accuracy. Firstly, from the publically accessible dataset, the input ECG along with PCG signals is gathered. Next, pre-processing is undergone by both signals. Utilizing Improved Empirical Mode Decomposition (IEMD), the signals are decomposed into bands after pre-processing. Then, for extracting the signal features, the decomposed bands are utilized. Then, for further process, the most suitable features are chosen as of the extracted features of both the ECG and PCG signals. After that, both the features are concatenated, and then classification is performed. In the classification process, the HD's type is identified and classified by GKVDLNN. Experimental results stated the proposed model's superiority and the proposed system withstands with 96.103% of accuracy with reduced costs. Overall, the method highlights the importance of early heart disease detection [32, 33] and provides a novel approach for achieving this goal through the integration of ECG and PCG signals with advanced signal processing and machine learning techniques [31].
C1 [Jyothi, P.; Pradeepini, G.] Koneru Lakshmaiah Educ Fdn, CSE Dept, Guntur, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Jyothi, P (corresponding author), Koneru Lakshmaiah Educ Fdn, CSE Dept, Guntur, Andhra Pradesh, India.
EM jyophani.reddy@gmail.com; pradeepini_cse@kluniversity.in
RI PRADEEPINI, GERA/M-7727-2019
OI PRADEEPINI, GERA/0000-0001-7757-6559
CR Abadi AM, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA SCIENCES (AIDAS2019), P64, DOI [10.1109/aidas47888.2019.8970975, 10.1109/AiDAS47888.2019.8970975]
   Abdulsalam G, 2023, INTELL AUTOM SOFT CO, V36, P761, DOI 10.32604/iasc.2023.032262
   Alloqmani A, ARAB J SCI ENG, P1, DOI [10.1007/2Fs13369-023-07945-z, DOI 10.1007/2FS13369-023-07945-Z]
   Alloqmani A, 2021, INT J ADV COMPUT SC, V12, P205
   Amiri AM, 2017, HEALTHCARE-BASEL, V5, DOI 10.3390/healthcare5010016
   Bao X, 2020, 13 INT C BIOINSP SYS
   Gharehbaghi A, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105615
   Ghosh SK, 2020, COMPUT BIOL MED, V118, DOI 10.1016/j.compbiomed.2020.103632
   Gjoreski M, 2017, INT CONF INTEL ENVIR, P14, DOI 10.1109/IE.2017.19
   Huang JS, 2019, IEEE ACCESS, V7, P92871, DOI 10.1109/ACCESS.2019.2928017
   Isin A, 2017, PROCEDIA COMPUT SCI, V120, P268, DOI 10.1016/j.procs.2017.11.238
   Javeed A, 2019, IEEE ACCESS, V7, P180235, DOI 10.1109/ACCESS.2019.2952107
   Kavila SD., 2021, J EMERG TECHNOL INNO, V8, P711, DOI [10.6017/ITAL.V41I2.14683, DOI 10.6017/ITAL.V41I2.14683]
   Khan AI, 2023, MEASUREMENT, V218, DOI 10.1016/j.measurement.2023.113230
   Khan MA, 2020, IEEE ACCESS, V8, P34717, DOI 10.1109/ACCESS.2020.2974687
   Khan RU, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMPUTING, MATHEMATICS AND ENGINEERING TECHNOLOGIES (ICOMET), DOI 10.1109/icomet.2019.8673506
   Latif S, 2019, IEEE T VIS COMPUT GR, V25, P152, DOI 10.1109/TVCG.2018.2865022
   Li H, 2019, IEEE ACCESS, V7, P146457, DOI 10.1109/ACCESS.2019.2943197
   Low JX, 2018, I C CONT AUTOMAT ROB, P119, DOI 10.1109/ICARCV.2018.8581315
   Low JX, 2018, INT J ELECTR COMPUT, DOI [10.5281/ZENODO.1315910, DOI 10.5281/ZENODO.1315910]
   Manju B. R., 2020, Procedia Computer Science, V171, P273, DOI 10.1016/j.procs.2020.04.029
   Nedoma J, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P420, DOI 10.1109/TSP.2017.8076019
   NIU XD, 2021, MATH PROBL ENG, P1
   Queyam AB., 2018, INT J INTELL SYST AP, V12, P69, DOI [10.5815/ijisa.2018.12.07, DOI 10.5815/IJISA.2018.12.07]
   Raza A, 2022, KNOWL-BASED SYST, V236, DOI 10.1016/j.knosys.2021.107763
   Sharma Vineet, 2020, Proceedings of Second International Conference on Inventive Research in Computing Applications (ICIRCA 2020), P554, DOI 10.1109/ICIRCA48905.2020.9182991
   Somwanshi D, 2018, 3 INT C WORKSH REC A, DOI [10.1109/ICRAIE.2018.8710343, DOI 10.1109/ICRAIE.2018.8710343]
   Taniguchi H, 2021, INT HEART J, V62, P534, DOI 10.1536/ihj.21-094
   Verma V., 2019, INT J APPL ENG RES, V14, P227
   Vijayavanan M., 2014, Int. J. of Comput. Sci. and Eng. Technology (IJCSET), V5, P449
   Yildirim Ö, 2018, COMPUT BIOL MED, V102, P411, DOI 10.1016/j.compbiomed.2018.09.009
   Zarrabi M, 2017, BIOMED ENG-APP BAS C, V29, DOI 10.4015/S1016237217500235
   Zhang DY, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8811962
   Zhang WB, 2018, 2018 INTERNATIONAL CONFERENCE ON BIG DATA AND ARTIFICIAL INTELLIGENCE (BDAI 2018), P47, DOI 10.1109/BDAI.2018.8546681
NR 34
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30587
EP 30612
DI 10.1007/s11042-023-16562-9
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001060763900003
DA 2024-07-18
ER

PT J
AU Zhao, XQ
   Feng, YF
   Shi, X
   Wang, Y
   Zhang, GG
AF Zhao, Xueqing
   Feng, Yifan
   Shi, Xin
   Wang, Yun
   Zhang, Guigang
TI A color constancy based flower classification method in the blockchain
   data lake
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color constancy; Blockchain data lake; Flower image classification;
   Convolutional neural network
AB The efficient classification of flower images will directly affect the accuracy of their automatic recognition. Due to the complexity of the background of flowers, not only the color, shape and texture of flowers are different, but also the illumination factors show significant effect on classification results of flower images during the process of acquiring flower images. Therefore, it is of great practical significance to identify flowers with the help of flower salient features and eliminate lighting factors. In order to reduce the influence of illumination factor on the classification accuracy of flower images and ensure the true transparency of flower images in the process of Internet data transmission, in this paper, we propose a color constancy based flower classification method in the Blockchain Data Lake, short for CCAN, firstly, we design a Blockchain Data Lake framework to ensure the accuracy and originality of the original image data; and then, color constancy mechanism is used to encode the color feature of images, in order to reduce the illumination effects. Thirdly, a convolutional neural network based classifier is proposed to achieve flower classification. Finally, we simulate the performance of CCAN on three different data set in the blockchain Data Lake environment, extensive results show that the proposed CCAN effectively improves the accuracy of flower image classification by minimizing the interference of illumination factors on flower targets.
C1 [Zhao, Xueqing; Feng, Yifan; Shi, Xin] Xian Polytech Univ, Sch Comp Sci, Shaanxi Key Lab Clothing Intelligence, 19 Jinhua South Rd, Xian 710048, Shaanxi, Peoples R China.
   [Wang, Yun; Zhang, Guigang] Chinese Acad Sci, Insititute Automat, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
C3 Xi'an Polytechnic University; Chinese Academy of Sciences
RP Zhao, XQ (corresponding author), Xian Polytech Univ, Sch Comp Sci, Shaanxi Key Lab Clothing Intelligence, 19 Jinhua South Rd, Xian 710048, Shaanxi, Peoples R China.
EM zhaoxueqing@xpu.edu.cn; fengyifan@stu.xpu.edu.cn; lrysx@163.com;
   y.wang@ia.ac.cn; guigang.zhang@ia.ac.cn
FU Key Research and Development Program of Shaanxi Province [2023-YBGY-404,
   2023-ZDLGY-48]; 2022 Research Project of Rural Public Cultural Service
   Research Institute, National Center for Public Culture Development,
   Ministry of Culture and Tourism [XCGGWH2022005]; 2022 Public Digital
   Cultural Service Project of National Center for Public Culture
   Development, Ministry of Culture and Tourism [GGSZWHFW2022-005]; Shaanxi
   Province University Young Outstanding Talents Support Program, and State
   Environmental Protection Key Laboratory of Coastal Ecosystem [202110]
FX This work was supported by the Key Research and Development Program of
   Shaanxi Province in 2023 (No.2023-YBGY-404, No. 2023-ZDLGY-48), the 2022
   Research Project of Rural Public Cultural Service Research Institute,
   National Center for Public Culture Development, Ministry of Culture and
   Tourism (No.XCGGWH2022005), the 2022 Public Digital Cultural Service
   Project of National Center for Public Culture Development, Ministry of
   Culture and Tourism (No. GGSZWHFW2022-005), Shaanxi Province University
   Young Outstanding Talents Support Program, and State Environmental
   Protection Key Laboratory of Coastal Ecosystem (202110)
CR [Акимов Михаил Юрьевич Akimov Mikhail Yur'yevich], 2020, [Химия растительного сырья, Khimija Rastitel’nogo Syr’ja, Khimiya rastitel'nogo syr'ya], P5
   Angelova A, 2013, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2013.110
   Ansari Prawej, 2017, Journal of Basic and Clinical Physiology and Pharmacology, V28, P171, DOI 10.1515/jbcpp-2016-0018
   Azadifar S, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105766
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Brohi M, 2021, TECHNIUM ROMANIAN J, V3, P32, DOI [10.47577/technium.v3i8.4692, DOI 10.47577/TECHNIUM.V3I8.4692]
   Cheng KY, 2014, NEUROCOMPUTING, V145, P416, DOI 10.1016/j.neucom.2014.05.011
   Davis J., 2014, SPRINGER P MATH STAT, V74, P251
   Elliot AJ, 2012, ADV EXP SOC PSYCHOL, V45, P61, DOI 10.1016/B978-0-12-394286-9.00002-0
   Gimenez-Aguilar M, 2021, FUTURE GENER COMP SY, V124, P91, DOI 10.1016/j.future.2021.05.007
   Hasan MT, 2021, BLOCKCHAIN RES REV, V07, P26, DOI [10.18488/journal.89.2021.71.26.35, DOI 10.18488/JOURNAL.89.2021.71.26.35]
   Laurent A, 2020, DATA LAKES, DOI [10.1002/9781119720430, DOI 10.1002/9781119720430]
   Meier BP, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040333
   Meregalli C, 2010, EUR J PAIN, V14, P343, DOI 10.1016/j.ejpain.2009.07.001
   Mhaisen N, 2020, FUTURE GENER COMP SY, V111, P39, DOI 10.1016/j.future.2020.04.035
   Nasiri E, 2023, MULTIMED TOOLS APPL, V82, P3745, DOI 10.1007/s11042-022-12943-8
   Nathan S, 2019, PROC VLDB ENDOW, V12, P1539, DOI 10.14778/3342263.3342632
   Nawaz A, 2021, THESIS, DOI [10.13140/RG.2.2.32733.54243/1, DOI 10.13140/RG.2.2.32733.54243/1]
   Nilsback M.E., 2006, IEEE C COMP VIS PATT, P1447, DOI DOI 10.1109/CVPR.2006.42
   Ouellette P, 2021, PROC VLDB ENDOW, V14, P2863, DOI 10.14778/3476311.3476364
   Panwar A, 2020, SCRUTINIZE IDEA HADO, P365, DOI [10.1007/978-981-15-3357-0_24, DOI 10.1007/978-981-15-3357-0_24]
   Puri V, 2021, CLUSTER COMPUT, V24, P1675, DOI 10.1007/s10586-020-03216-w
   Ren P, 2021, MHDP EFFICIENT DATA, P727, DOI [10.1007/978-3-030-87571-8_63, DOI 10.1007/978-3-030-87571-8_63]
   Rocca L, 2021, BLOCKCHAIN, P147, DOI [10.1007/978-3-030-80737-5_11, DOI 10.1007/978-3-030-80737-5_11]
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   SMITH JA, 1980, PHOTOGRAMM ENG REM S, V46, P1183
   Stawicki SP, 2018, INT J ACAD MED, V4, P1, DOI 10.4103/IJAM.IJAM_12_18
   Vangala A, 2021, IEEE SENS J, V21, P17591, DOI 10.1109/JSEN.2020.3012294
   Wang DQ, 2015, IEEE I CONF COMP VIS, P2399, DOI 10.1109/ICCV.2015.276
   Xiaohuan Wang, 2018, Web Information Systems and Applications. 15th International Conference, WISA 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11242), P300, DOI 10.1007/978-3-030-02934-0_28
   Yuan PeiSen Yuan PeiSen, 2018, Transactions of the Chinese Society of Agricultural Engineering, V34, P152
   Zhang C, 2021, IEEE T VEH TECHNOL, V70, P831, DOI 10.1109/TVT.2020.3046027
NR 32
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28657
EP 28673
DI 10.1007/s11042-023-16656-4
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001060763900016
DA 2024-07-18
ER

PT J
AU Kumari, P
   Saxena, P
AF Kumari, Pammi
   Saxena, Priyank
TI Disease localization and its prediction from retinal fundus images using
   explicitly designed deep learning architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy; Disease localization; Layer visualization;
   Convolutional neural network (CNN); Grad-CAM, APTOS dataset; Ablation
   study; Retinal fundus images
ID DIABETIC-RETINOPATHY
AB Visual disability is increasing due to the incidence of diabetic retinopathy (DR), but timely detection and diagnosis can provide more treatment options and a greater chance of patient survival. Retinal imaging is used for screening and timely detection of the disease. However, determining the exact stage of DR from color retinal fundus images is challenging because they consist of non-uniform lesions with indeterminate extremities. Hence, most of the pre-trained models used in earlier studies to classify retinal images couldn't deliver as expected because these models failed to understand the intricacies of the retinal images. Thus, this work addresses the classification of retinal images (S-0 to S-4) according to the extent of DR using a convolutional neural network (RINet) designed explicitly for retinal fundus images obtained from the APTOS dataset. To improve the classification performance of RINet, features from intermediate layers are extracted, which aid in improvising the model parameters as they indicate the actual state of the model. These extracted features are represented using layer visualization. For disease localization, Gradient-weighted Class Activation Mapping (Grad-CAM) is incorporated at the last convolutional layer, effectively highlighting the crucial regions for every stage in the image. In-depth ablation tests are conducted to realize the current form of the RINet and test its effectiveness. RINet achieves an accuracy of 85% for multi-stage and 95% for binary class on the test set. The simulation results show that the RINet outweighs the pre-trained models, particularly in moderate to severe DR stages.
C1 [Kumari, Pammi; Saxena, Priyank] Birla Inst Technol, Dept Elect & Commun Engn, Ranchi, India.
C3 Birla Institute of Technology Mesra
RP Kumari, P (corresponding author), Birla Inst Technol, Dept Elect & Commun Engn, Ranchi, India.
EM phdec10003.19@bitmesra.ac.in; priyanksaxena@bitmesra.ac.in
RI Saxena, Priyank/ADG-7631-2022
OI Saxena, Priyank/0000-0003-0227-0488
CR Aatila M., 2021, International Journal of Computer Engineering and Data Science (IJCEDS), V1
   Acharya UR, 2012, J MED SYST, V36, P2011, DOI 10.1007/s10916-011-9663-8
   Ali A, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22050567
   Burgess PI, 2013, DIABETIC MED, V30, P399, DOI 10.1111/j.1464-5491.2012.03756.x
   Choutele AA., 2023, JAIMLNN, V3, P27, DOI [10.55529/jaimlnn.33.27.34, DOI 10.55529/JAIMLNN.33.27.34]
   Damodara K., 2021, J INFOR ELECT ELECT, V2, P1, DOI [10.54060/JIEEE/002.02.016, DOI 10.54060/JIEEE/002.02.016]
   de la Torre J, 2020, NEUROCOMPUTING, V396, P465, DOI 10.1016/j.neucom.2018.07.102
   Dutta S, 2018, INT J GRID DISTRIB, V11, P89, DOI 10.14257/ijgdc.2018.11.1.09
   El Houby E. M., 2021, Appl Comput Inform, V1, P1, DOI [10.1108/ACI-07-2021-0191, DOI 10.1108/ACI-07-2021-0191]
   Feigin VL, 2005, STROKE, V36, P2773, DOI 10.1161/01.STR.0000190838.02954.e8
   Hassan R, 2020, EMERGING TECHNOLOGY, P1, DOI [10.1109/ETCCE51779.2020.9350905, DOI 10.1109/ETCCE51779.2020.9350905]
   Hinton G.E., 2018, INT C LEARN REPR
   Hsieh YT, 2021, J FORMOS MED ASSOC, V120, P165, DOI 10.1016/j.jfma.2020.03.024
   Huang F, 2016, J OPHTHALMOL, V2016, DOI 10.1155/2016/6259047
   Jalan S., 2015, Int J Adv Res Comput Sci Manag Stud, V3, P128
   Jiang HY, 2020, IEEE ENG MED BIO, P1560, DOI 10.1109/EMBC44109.2020.9175884
   Kori A, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1809.04228
   Lin XL, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-71908-9
   Masud M, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3470976
   Meng QE, 2020, IEEE J BIOMED HEALTH, V24, P3351, DOI 10.1109/JBHI.2020.3011805
   Michalska, 2019, COMPUTER VISION MACH, DOI [10.1101/763136, DOI 10.1101/763136]
   Mohanraj S, 2023, INT J DIABETES DEV C, V43, P936, DOI 10.1007/s13410-023-01202-7
   Panwar A, 2022, Edge Analytics, P653, DOI DOI 10.1007/978-981-19-0019-8_49
   Peto T, 2012, CURR DIABETES REP, V12, P338, DOI 10.1007/s11892-012-0285-4
   Pradhan A, 2020, 2020 INTERNATIONAL CONFERENCE ON COMPUTATIONAL PERFORMANCE EVALUATION (COMPE-2020), P813, DOI 10.1109/ComPE49325.2020.9200092
   Rajagopalan N, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0254180
   Raman R, 2019, EYE, V33, P97, DOI 10.1038/s41433-018-0269-y
   Roccetti M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00428-8
   Somasundaram A, 2016, 1 INT C RES ENG COMP
   Tandon N, 2018, LANCET GLOB HEALTH, V6, pE1352, DOI 10.1016/S2214-109X(18)30387-5
   Thota NB, 2020, MIDWEST SYMP CIRCUIT, P1003, DOI [10.1109/MWSCAS48704.2020.9184473, 10.1109/mwscas48704.2020.9184473]
   Tymchenko B, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2003.02261
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vijayan T., 2020, Microprocess. Microsyst, P103353, DOI [10.3390/s22145103, DOI 10.1016/J.MICPRO.2020.103353, 10.1016/j.micpro.2020.103353]
   Zago GT, 2020, COMPUT BIOL MED, V116, DOI 10.1016/j.compbiomed.2019.103537
NR 35
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28461
EP 28478
DI 10.1007/s11042-023-16585-2
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059022200001
DA 2024-07-18
ER

PT J
AU Rangwani, D
   Om, H
AF Rangwani, Diksha
   Om, Hari
TI Chaotic map based multi-factor authentication protocol for underwater
   environment monitoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-factor authentication; Underwater wireless sensor network;
   Chaotic-map; Environment-monitoring; Security
ID KEY AGREEMENT SCHEME; SECURITY; DESIGN
AB The underwater environment holds significant potential for advancing ecosystem understanding, industrial operations, and early natural disaster prediction. To monitor this environment effectively, technologies like Underwater Wireless Sensor Networks (UWSNs) are being extensively developed and deployed. However, due to the unreliable nature of the underwater environment, communications carried out using UWSNs are vulnerable to various security threats. For secure communication in UWSNs, it is essential that the communicating entities are mutually authenticated. Recently, Sureshkumar et al. discussed an authentication protocol using chaotic map operations. However, we have discovered that the protocol is not secure against privileged insider, user impersonation, and denial of service attacks. Additionally, the protocol lacks perfect forward secrecy. To address these issues, we propose a multi-factor authentication protocol based on the chaotic map for monitoring the underwater environment. The extensive formal security analysis employs the Burrows-Abadi-Needham (BAN) logic and Real-Or-Random (ROR) model to prove the robustness of our proposed protocol. Furthermore, a state-of-the-art informal security analysis demonstrates the effectiveness of our protocol against various threats. We also validate the security of our proposed protocol through simulations using the Automated Validation of Internet Security Protocols and Applications (AVISPA) tool. In terms of performance evaluation, our protocol outperforms existing ones ensuring proficient operation in the underwater environment.
C1 [Rangwani, Diksha; Om, Hari] Indian Inst Technol ISM Dhanbad, Dept Comp Sci & Engn, Police Line Rd, Dhanbad 826004, Jharkhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Rangwani, D (corresponding author), Indian Inst Technol ISM Dhanbad, Dept Comp Sci & Engn, Police Line Rd, Dhanbad 826004, Jharkhand, India.
EM diksharangwani@gmail.com; harionvlindia@gmail.com
RI Rangwani, Diksha/AAP-9318-2021
OI Rangwani, Diksha/0000-0003-0462-0680
CR Abdalla M., 2006, IEE Proceedings-Information Security, V153, P27, DOI 10.1049/ip-ifs:20055073
   Abdalla M, 2005, LECT NOTES COMPUT SC, V3788, P566
   Ahmed MR, 2015, 2015 INT C EL ENG IN, P1
   Al-Hussain A, 2010, P 8 INT C ADV MOBILE, P447
   Alsalhi IN, Authentication of crns by using ban logic
   Althobaiti O, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/407971
   [Anonymous], 2011, ADC-Converter-Basics
   Armando A, 2005, LECT NOTES COMPUT SC, V3576, P281
   Bae W, 2020, MULTIMED TOOLS APPL, V79, P15793, DOI 10.1007/s11042-017-5548-2
   Ben Salem M, 2008, ADV INFORM SECUR, V39, P69
   Boyd C., 1994, Advances in Cryptology - EUROCRYPT '93. Workshop on the Theory and Application of Cryptographic Techniques Proceedings, P240
   Canetti R, 2001, LECT NOTES COMPUT SC, V2045, P453
   Canetti R, 2002, LECT NOTES COMPUT SC, V2332, P337
   Capossele A., 2017, P INT C UND NETW SYS, P1
   Domingo MC, 2011, IEEE WIREL COMMUN, V18, P22, DOI 10.1109/MWC.2011.5714022
   Cohen M, 2005, Methods for modalities, V4
   Das AK, 2016, SECUR COMMUN NETW, V9, P2070, DOI 10.1002/sec.1464
   Dhillon PK, 2019, MULTIMED TOOLS APPL, V78, P22199, DOI 10.1007/s11042-019-7466-y
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   Dovom EM, 2019, J SYST ARCHITECT, V97, P1, DOI 10.1016/j.sysarc.2019.01.017
   Galindo D, 2008, LECT NOTES COMPUT SC, V5339, P120, DOI 10.1007/978-3-540-89641-8_9
   Gao GM, 2016, INT J DISTRIB SENS N, V12, DOI 10.1177/155014772174720
   Guo XY, 2020, IEEE ACCESS, V8, P111265, DOI 10.1109/ACCESS.2020.3002558
   Hao XH, 2013, J MED SYST, V37, DOI 10.1007/s10916-012-9919-y
   Islam SKH, 2015, INFORM SCIENCES, V312, P104, DOI 10.1016/j.ins.2015.03.050
   Jiang Q, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0012-6
   Ku WC, 2005, IEICE T COMMUN, VE88B, P2165, DOI 10.1093/ietcom/e88-b.5.2165
   Kumar Ashish, 2021, Proceedings of the Fourth International Conference on Microelectronics, Computing and Communication Systems. MCCS 2019. Lecture Notes in Electrical Engineering (LNEE 673), P921, DOI 10.1007/978-981-15-5546-6_76
   Kumari S, 2016, FUTURE GENER COMP SY, V63, P56, DOI 10.1016/j.future.2016.04.016
   Kumari S, 2016, COMPUT NETW, V104, P137, DOI 10.1016/j.comnet.2016.05.007
   Li X, 2018, FUTURE GENER COMP SY, V84, P149, DOI 10.1016/j.future.2017.08.029
   Li X, 2016, SECUR COMMUN NETW, V9, P2643, DOI 10.1002/sec.1214
   Liu H, 2010, PROCEEDINGS OF THE 2010 ACM WORKSHOP CLOUD COMPUTING SECURITY WORKSHOP (CCSW'10:), P65, DOI 10.1145/1866835.1866849
   Lloret J, 2013, SENSORS-BASEL, V13, P11782, DOI 10.3390/s130911782
   Madhusudhan R, 2020, MULTIMED TOOLS APPL, V79, P22007, DOI 10.1007/s11042-020-08983-7
   Madhusudhan R, 2019, MULTIMED TOOLS APPL, V78, P15255, DOI 10.1007/s11042-018-6884-6
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Qi MP, 2019, MULTIMED TOOLS APPL, V78, P27553, DOI 10.1007/s11042-019-07812-w
   Rehman HU, 2021, MULTIMED TOOLS APPL, V80, P16907, DOI 10.1007/s11042-020-09078-z
   Ryecroft SP, 2018, I C DEV ESYST ENG, P95, DOI 10.1109/DeSE.2018.00021
   Sasikaladevi N, 2019, MULTIMED TOOLS APPL, V78, P18037, DOI 10.1007/s11042-019-7149-8
   Shnayder Victor., 2004, P 2 INT C EMBEDDED N, P188
   Srinivas J, 2020, IEEE T DEPEND SECURE, V17, P1133, DOI 10.1109/TDSC.2018.2857811
   Sureshkumar V, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102539
   Vemishetty N, 2016, IEEE ACCESS, V4, P8407, DOI 10.1109/ACCESS.2016.2629486
   Wessels J., 2001, CMG FINANCE BV, V19, P1
   Yang G, 2019, PROCEDIA COMPUT SCI, V147, P210, DOI 10.1016/j.procs.2019.01.225
   Yanping Cong, 2010, Proceedings of the 2010 International Conference on Communications and Mobile Computing (CMC 2010), P162, DOI 10.1109/CMC.2010.18
   Zhao Y, 2018, LECT NOTES ELECTR EN, V450, P146, DOI 10.1007/978-981-10-6454-8_20
NR 49
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26871
EP 26900
DI 10.1007/s11042-023-16608-y
EA SEP 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001059026300006
DA 2024-07-18
ER

PT J
AU Singh, S
   Maurya, MK
   Singh, NP
AF Singh, Samridhi
   Maurya, Malti Kumari
   Singh, Nagendra Pratap
TI STRAMPN: Histopathological image dataset for ovarian cancer detection
   incorporating AI-based methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ovarian cancer; STRAMPN dataset; Dataset augmentation; Classification
   techniques; Machine Learning
AB Ovarian cancer, characterized by uncontrolled cell growth in the ovaries, poses a significant threat to women's reproductive health. Often referred to as the "silent killer," it is notorious for its elusive nature, as symptoms do not manifest until the disease has advanced to critical stages. Recognizing the urgent need for early detection, this research paper aimed to enhance the identification of ovarian cancer during its initial phases. To bolster the dataset and improve the chances of accurate classification, a comprehensive approach was undertaken. Leveraging available online images, an extensive pre-processing and data augmentation methodology was employed to enrich the dataset. By expanding the dataset size and ensuring its diversity, the research sought to capture a broader range of cancerous manifestations and mitigate potential biases. Utilizing MATLAB, a suite of six state-of-the-art classifiers were employed to categorize the augmented images. To assess the efficacy of the classifiers, a holdout method was adopted for cross-validation. Remarkably, the results showcased an exceptional accuracy rate of 99%, underscoring the effectiveness of the methodology in detecting ovarian cancer at its incipient stages. The implications of this research are far-reaching, as the early identification of ovarian cancer holds immense potential for improved prognosis and treatment outcomes. By shedding light on the significance of expanding and diversifying datasets and leveraging advanced classification techniques, this study contributes to the growing body of knowledge aimed at combating ovarian cancer and underscores the importance of early intervention in reducing mortality rates associated with this insidious disease.
C1 [Singh, Samridhi] Natl Inst Technol, Hamirpur 177005, India.
   [Maurya, Malti Kumari] King Georges Med Univ, Lucknow 226003, India.
   [Singh, Nagendra Pratap] Dr BR Ambedkar Natl Inst Technol Jalandhar, Jalandhar 144011, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur; King George's Medical University; National
   Institute of Technology (NIT System); Dr B R Ambedkar National Institute
   of Technology Jalandhar
RP Singh, S (corresponding author), Natl Inst Technol, Hamirpur 177005, India.
EM 22rcs005@nith.ac.in; mauryamalti@yahoo.co.in; singhnp@nitj.ac.in
RI Singh, Nagendra Pratap/JRY-4378-2023
CR Aditya MS, 2021, 2021 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER TECHNOLOGIES AND OPTIMIZATION TECHNIQUES (ICEECCOT), P279, DOI 10.1109/ICEECCOT52851.2021.9707954
   Agarwal S., 2017, BIOMED PHARMACOL J, V10, P831, DOI DOI 10.13005/bpj/1174
   Akazawa M, 2021, OBSTET GYNECOL SCI, V64, P266, DOI 10.5468/ogs.20248
   Akhand MAH, 2007, LECT NOTES COMPUT SC, V4668, P98
   Akter Sadia, 2020, AMIA Jt Summits Transl Sci Proc, V2020, P33
   Bushara AR, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-14893-1
   Caliskan A, 2018, ENG APPL ARTIF INTEL, V67, P14, DOI 10.1016/j.engappai.2017.09.002
   Islam Mohammed J., 2007, 2007 International Conference on Convergence Information Technology - ICCIT '07, P1541, DOI 10.1109/ICCIT.2007.148
   Jaiswal AK, 2020, MULTIMED TOOLS APPL, V79, P11837, DOI 10.1007/s11042-019-08480-6
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Karmakar P, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING - TECHNIQUES AND APPLICATIONS (DICTA), P461
   Kawakami E, 2019, CLIN CANCER RES, V25, P3006, DOI 10.1158/1078-0432.CCR-18-3378
   Klein O, 2019, PROTEOM CLIN APPL, V13, DOI 10.1002/prca.201700181
   Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P376
   Li YA, 2020, J MAGN RESON IMAGING, V52, P897, DOI 10.1002/jmri.27084
   Lu MY, 2020, INT J MED INFORM, V141, DOI 10.1016/j.ijmedinf.2020.104195
   Martínez-Más J, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219388
   Mohan V, 2015, LIVER DIS PREDICTION
   Mohanaiah P., 2013, INT J SCI RES PUB, V3, P1, DOI 10.5772/58692
   Oliva JT, 2016, EXPERT SYST APPL, V63, P267, DOI 10.1016/j.eswa.2016.07.008
   Pathak H, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P137, DOI 10.1109/ICRCICN.2015.7434224
   Pierson WE, 2020, GYNECOL ONCOL, V157, P55, DOI 10.1016/j.ygyno.2020.02.011
   Saida T, 2022, CANCERS, V14, DOI 10.3390/cancers14040987
   SHAKEEL PM, 2020, J NEURAL COMPUTING A, P1
   Shanthini A., 2020, Eur J Mol Clin Med, V7, P293
   Shaw R, 2022, CANCERS, V14, DOI 10.3390/cancers14051291
   Song F, 2010, INT C SYST SCI ENG D, P27, DOI [DOI 10.1109/ICSEM.2010.14, 10.1109/ICSEM.2010.14]
   Sundari M. Jeya, 2021, 2021 Sixth International Conference on Image Information Processing (ICIIP), P314, DOI 10.1109/ICIIP53038.2021.9702697
   Verma A, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105298
   Wang CW, 2022, COMPUT MED IMAG GRAP, V99, DOI 10.1016/j.compmedimag.2022.102093
   Wang S, 2019, RADIOTHER ONCOL, V132, P171, DOI 10.1016/j.radonc.2018.10.019
   Xu Y, 2010, PATTERN RECOGN, V43, P1106, DOI 10.1016/j.patcog.2009.09.013
   Yesilkaya B, 2022, J COMPUT SCI-NETH, V63, DOI 10.1016/j.jocs.2022.101775
   Yigit H, 2013, 2013 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMPUTER AND COMPUTATION (ICECCO), P228, DOI 10.1109/ICECCO.2013.6718270
   Zhang Z, 2020, IEEE ACCESS, V8, P44999, DOI 10.1109/ACCESS.2020.2977962
NR 35
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 28175
EP 28196
DI 10.1007/s11042-023-16576-3
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001057641700002
DA 2024-07-18
ER

PT J
AU Vikraman, BP
   Jabeena, A
AF Vikraman, Bindu Puthentharayil
   Jabeena, A.
TI Segmentation based medical image compression of brain magnetic resonance
   images using optimized convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Magnetic resonance images; Medical image compression; Region of
   Interest; Non- Region of Interest; Medical image; Fuzzy C-Means
ID ROI
AB Image compression plays a crucial role in the field of medical imaging, including Magnetic Resonance Imaging (MRI). The MRI images are typically large and high-resolution, which results in substantial data storage requirements. Compressing MRI images helps reduce the storage space needed to store the images, making it more efficient and cost-effective to store and transmit them. To overcome these drawbacks, this paper proposes an efficient medical image compression based on hybrid machine learning approaches. There are two main stages are considered in this proposed methodology, named a segmentation stage The Region of Interest (ROI) in the image is recognized by the segmentation stage; and it given to the next stage. Segmentation is carried out by hybrid Grey Wolf Optimization with Fuzzy C-Means (FCM) is proposed to better balance the exploitation and exploration phases of optimization. Then, the neural network i.e., optimized convolutional neural network (Op-CNN), compress the ROI region of the input image depending on the detected segments. Meanwhile, the second region (NROI) is compressed by the Recurrent Neural Networks (RNNs). The suggested method of image compression for medical imaging outcomes and datasets are assessed with highest PSNR value of 45.502, which is higher than the existing techniques.
C1 [Vikraman, Bindu Puthentharayil; Jabeena, A.] Vellore Inst Technol, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Vikraman, BP (corresponding author), Vellore Inst Technol, Vellore, Tamil Nadu, India.
EM bindup2005@gmail.com; ajabeena@vit.ac.in
OI Vikraman, Bindu/0000-0003-3134-6824
CR Ajagbe S, 2021, INT J ADV COMPUT RES, V11, P51, DOI [10.19101/IJACR.2021.1152001, DOI 10.19101/IJACR.2021.1152001, 10.3390/electronics12030676]
   Ajagbe SA, 2022, 2022 INT C ELECT COM, P1, DOI [10.1109/ICECET55527.2022.9872568, DOI 10.1109/ICECET55527.2022.9872568]
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   [Anonymous], DAT IS TAK
   Devadoss CP, 2019, CLUSTER COMPUT, V22, P12929, DOI 10.1007/s10586-018-1801-3
   Dhouib D, 2021, IRBM, V42, P146, DOI 10.1016/j.irbm.2020.05.001
   Dimililer K, 2022, SIGNAL IMAGE VIDEO P, V16, P55, DOI 10.1007/s11760-021-01951-0
   Ebrahimnejad J, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104831
   Geetha K, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12508
   Geetha V, 2020, MULTIMEDIA SYST, V26, P687, DOI 10.1007/s00530-020-00681-6
   Ibrahim Khaleel A, 2021, HYBRID COMPRESSION M
   Janghel RR, 2021, IRBM, V42, P258, DOI 10.1016/j.irbm.2020.06.006
   Lim ST, 2022, INT J ADV COMPUT SC, V13, P234
   Liu S, 2019, IEEE ACCESS, V7, P62412, DOI 10.1109/ACCESS.2019.2916934
   Magar SS, 2020, HEALTH TECHNOL-GER, V10, P313, DOI 10.1007/s12553-018-00282-4
   Manimekalai MAP, 2019, CLUSTER COMPUT, V22, P12805, DOI 10.1007/s10586-018-1761-7
   Prakash K, 2021, MATER TODAY-PROC
   Qasim AF, 2019, MULTIMED TOOLS APPL, V78, P16433, DOI 10.1007/s11042-018-7029-7
   Rao GS, 2019, ADV INTELL SYST COMP, V817, P107, DOI 10.1007/978-981-13-1595-4_9
   Sabbavarapu SR, 2021, J AMB INTEL HUM COMP, V12, P6333, DOI 10.1007/s12652-020-02212-7
   Singh, 2020, ADV COMPUTATIONAL TE, P185
   Singh V, 2021, INT J ELECT COMPUTER, V11
   Sran PK, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102089
   Sreenivasulu R, 2020, J INTELL SYST, V29, P1063, DOI 10.1515/jisys-2018-0180
   Sun L, 2020, IEEE T MED IMAGING, V39, P2000, DOI 10.1109/TMI.2019.2962792
   Sun LY, 2019, MAGN RESON IMAGING, V63, P185, DOI 10.1016/j.mri.2019.07.010
   Tackie Ammah Paul Nii, 2019, Informatics in Medicine Unlocked, V15, P188, DOI 10.1016/j.imu.2019.100183
   Ullah Z, 2022, INFORM SCIENCES, V608, P1541, DOI 10.1016/j.ins.2022.07.044
   Urvashi S, 2021, MULTIMED TOOLS APPL, V80, P12857, DOI 10.1007/s11042-020-10396-5
   Zuluaga JY., 2021, PARADIGMPLUS, V2, P1, DOI [10.55969/paradigmplus.v2n1a1, DOI 10.55969/PARADIGMPLUS.V2N1A1]
NR 33
TC 1
Z9 1
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26643
EP 26661
DI 10.1007/s11042-023-16559-4
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001057027000001
DA 2024-07-18
ER

PT J
AU Spolaôr, N
   Lee, HD
   Mendes, AI
   Nogueira, CV
   Parmezan, ARS
   Takaki, WSR
   Coy, CSR
   Wu, FC
   Fonseca-Pinto, R
AF Spolaor, Newton
   Lee, Huei Diana
   Mendes, Ana Isabel
   Nogueira, Conceicao Veloso
   Sabino Parmezan, Antonio Rafael
   Resende Takaki, Weber Shoity
   Rodrigues Coy, Claudio Saddy
   Wu, Feng Chung
   Fonseca-Pinto, Rui
TI Fine-tuning pre-trained neural networks for medical image classification
   in small clinical datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature learning; Few-shot learning; RMSprop; Shallow learning;
   Statistical test; VGG
ID MELANOMA; THICKNESS; FEATURES; TEXTURE
AB Convolutional neural networks have been effective in several applications, arising as a promising supporting tool in a relevant Dermatology problem: skin cancer diagnosis. However, generalizing well can be difficult when little training data is available. The fine-tuning transfer learning strategy has been employed to differentiate properly malignant from non-malignant lesions in dermoscopic images. Fine-tuning a pre-trained network allows one to classify data in the target domain, occasionally with few images, using knowledge acquired in another domain. This work proposes eight fine-tuning settings based on convolutional networks previously trained on ImageNet that can be employed mainly in limited data samples to reduce overfitting risk. They differ on the architecture, the learning rate and the number of unfrozen layer blocks. We evaluated the settings in two public datasets with 104 and 200 dermoscopic images. By finding competitive configurations in small datasets, this paper illustrates that deep learning can be effective if one has only a few dozen malignant and non-malignant lesion images to study and differentiate in Dermatology. The proposal is also flexible and potentially useful for other domains. In fact, it performed satisfactorily in an assessment conducted in a larger dataset with 746 computerized tomographic images associated with the coronavirus disease.
C1 [Spolaor, Newton; Lee, Huei Diana; Sabino Parmezan, Antonio Rafael; Resende Takaki, Weber Shoity; Wu, Feng Chung] Western Parana State Univ UNIOESTE, Lab Bioinformat, Presidente Tancredo Neves Ave 6731, BR-85867900 Foz Do Iguacu, Parana, Brazil.
   [Mendes, Ana Isabel; Nogueira, Conceicao Veloso; Fonseca-Pinto, Rui] Polytech Inst Leiria, Gen Norton Matos St 4133, P-2411901 Leiria, Portugal.
   [Nogueira, Conceicao Veloso] Univ Minho, Ctr Math, Braga, Portugal.
   [Sabino Parmezan, Antonio Rafael] Univ Sao Paulo, Inst Math & Comp Sci, Lab Computat Intelligence, Sao Carlos, SP, Brazil.
   [Rodrigues Coy, Claudio Saddy; Wu, Feng Chung] Univ Estadual Campinas, Fac Med Sci, Serv Coloproctol, Campinas, SP, Brazil.
   [Fonseca-Pinto, Rui] Polytech Inst Leiria, CiTechCare Ctr Innovat Care & Hlth Technol, Leiria, Portugal.
   [Fonseca-Pinto, Rui] IT Inst Telecomunicacoes Leiria, Leiria, Portugal.
C3 Universidade Estadual do Oeste do Parana; Universidade do Minho;
   Universidade de Sao Paulo; Universidade Estadual de Campinas
RP Spolaôr, N (corresponding author), Western Parana State Univ UNIOESTE, Lab Bioinformat, Presidente Tancredo Neves Ave 6731, BR-85867900 Foz Do Iguacu, Parana, Brazil.
EM newtonspolaor@gmail.com; huei.lee@unioeste.br
RI Spolaôr, Newton/J-2509-2012; Lee, Huei Diana/D-8219-2015; Fonseca-Pinto,
   Rui/K-9449-2014
OI Mendes, Ana/0000-0002-4161-6130; Parmezan, Antonio/0000-0002-1725-132X;
   Fonseca-Pinto, Rui/0000-0001-6774-5363; Nogueira,
   Conceicao/0000-0002-9269-2221
FU EurekaSD: Enhancing University Research and Education in Areas Useful
   for Sustainable Development [EK14AC0037, EK15AC0264]; Araucaria
   Foundation [028/2019]; Brazilian National Council for Scientific and
   Technological Development (CNPq) [142050/2019-9]; Fundacao para a
   Ciencia e a Tecnologia (FCT);  [UIDB/50008/2020];  [UIDP/50008/2020]; 
   [UIDB/05704/2020];  [UIDP/05704/2020];  [UIDB/00013/2020]; 
   [UIDP/00013/2020]
FX We would like to acknowledge eurekaSD: Enhancing University Research and
   Education in Areas Useful for Sustainable Development -grants EK14AC0037
   and EK15AC0264. We thankAraucaria Foundation for the Support of the
   Scientific and Technological Development of Parana through a Research
   and Technological Productivity Scholarship for H. D. Lee (grant
   028/2019). We also thank the Brazilian National Council for Scientific
   and Technological Development (CNPq) through the grant number
   142050/2019-9 for A. R. S. Parmezan. The Portuguese team was partially
   supported by Fundacao para a Ciencia e a Tecnologia (FCT). R.
   Fonseca-Pinto was financed by the projects UIDB/50008/2020,
   UIDP/50008/2020, UIDB/05704/2020 and UIDP/05704/2020 and C. V. Nogueira
   was financed by the projects UIDB/00013/2020 and UIDP/00013/2020. The
   funding agencies did not have any further involvement in this paper.
CR Abadi, 2015, TENSORFLOW LARGE SCA
   Abayomi-Alli OO, 2021, TURK J ELECTR ENG CO, V29, P2600, DOI 10.3906/elk-2101-133
   Abuzaghleh O, 2015, LONG ISLAND SYSTEMS, P1, DOI [10.1109/LISAT.2015.7160183, DOI 10.1109/LISAT.2015.7160183]
   Alazzam MB, 2021, Mathematical Problems in Engineering, V2021
   Ashraf R, 2020, IEEE ACCESS, V8, P147858, DOI 10.1109/ACCESS.2020.3014701
   Asiri N, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.009
   Bansal P, 2022, COMPUT IND ENG, V168, DOI 10.1016/j.cie.2022.108060
   Barata C, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107413
   Barata C, 2015, IEEE J BIOMED HEALTH, V19, P1146, DOI 10.1109/JBHI.2014.2336473
   Barata C, 2014, IEEE IMAGE PROC, P3527, DOI 10.1109/ICIP.2014.7025716
   Barata C, 2014, IEEE SYST J, V8, P965, DOI 10.1109/JSYST.2013.2271540
   Barata C, 2013, LECT NOTES COMPUT SC, V8033, P40, DOI 10.1007/978-3-642-41914-0_5
   Barata C, 2013, LECT NOTES COMPUT SC, V7887, P715
   Barata C, 2013, LECT NOTES COMPUT SC, V7950, P547, DOI 10.1007/978-3-642-39094-4_62
   Böer A, 2007, INDIAN J DERMATOL VE, V73, P138, DOI 10.4103/0378-6323.31909
   Celebi ME, 2019, IEEE J BIOMED HEALTH, V23, P474, DOI 10.1109/JBHI.2019.2895803
   Chen H., 2018, P IEEE 4 INT C MULT, P1, DOI DOI 10.1109/BIGMM.2018.8499067
   Chen ZT, 2019, AAAI CONF ARTIF INTE, P3379
   Cheng G, 2023, IEEE T PATTERN ANAL, V45, P4650, DOI 10.1109/TPAMI.2022.3193587
   Chollet F., 2018, Towards Data Science
   Chougrad H, 2018, COMPUT METH PROG BIO, V157, P19, DOI 10.1016/j.cmpb.2018.01.011
   Feng X, 2019, INTEGRATION, V69, P309, DOI 10.1016/j.vlsi.2019.07.005
   Fujita H, 2020, RADIOL PHYS TECHNOL, V13, P6, DOI 10.1007/s12194-019-00552-4
   Grochowski M, 2019, B POL ACAD SCI-TECH, V67, P363, DOI 10.24425/bpas.2019.128485
   Gulati S., 2019, INT C ADV COMP DAT S, P312, DOI DOI 10.1007/978-981-13-9939-8_28
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He X. etal, 2020, medRxiv
   Hinton G., 2020, Neural Networks for Machine Learning
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jaisakthi SM, 2023, MULTIMED TOOLS APPL, V82, P15763, DOI 10.1007/s11042-022-13847-3
   Kaur R, 2015, SKIN RES TECHNOL, V21, P466, DOI 10.1111/srt.12216
   Khan MA, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11050811
   Kokabi M, 2020, IEEE ACCESS, V8, P228831, DOI 10.1109/ACCESS.2020.3046190
   Kumar V., 2014, Robbins & Cotran Pathologic Basis of Disease
   Kwasigroch Arkadiusz, 2017, 2017 22nd International Conference on Methods and Models in Automation and Robotics (MMAR), P1069, DOI 10.1109/MMAR.2017.8046978
   Thao LT, 2017, 2017 21ST ASIA PACIFIC SYMPOSIUM ON INTELLIGENT AND EVOLUTIONARY SYSTEMS (IES), P106, DOI 10.1109/IESYS.2017.8233570
   Lee HD, 2018, KNOWL-BASED SYST, V158, P9, DOI 10.1016/j.knosys.2018.05.016
   Li WB, 2019, AAAI CONF ARTIF INTE, P8642
   Liu XJ, 2022, MULTIMED TOOLS APPL, V81, P4979, DOI 10.1007/s11042-021-11472-0
   Lorena AC, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3347711
   Machado M, 2015, J MED IMAGING, V2, DOI 10.1117/1.JMI.2.4.044503
   Mahajan K, 2020, IEEE COMPUT SOC CONF, P3142, DOI 10.1109/CVPRW50498.2020.00373
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071119
   Maia LB, 2018, INT CONF SYST SIGNAL, DOI 10.1109/IWSSIP.2018.8439373
   Mendonca T., 2015, Dermoscopy image analysis, DOI 10.1201/b19107-14
   Menegola A, 2017, I S BIOMED IMAGING, P297, DOI 10.1109/ISBI.2017.7950523
   Mitchell T. M., 1997, MACH LEARN
   Carvalho VAM, 2014, PROC LAT AM COMPUT C
   Nunnari F, 2021, LECT NOTES COMPUT SC, V12844, P241, DOI 10.1007/978-3-030-84060-0_16
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pereira J., 2015, ONLINE J SCI TECHNOL, V5, P56
   Pereira J, 2015, CIM SER MATH SCI, V1, P537, DOI 10.1007/978-3-319-16118-1_29
   Petersen D, 2017, SPECTROCHIM ACTA A, V181, P270, DOI 10.1016/j.saa.2017.03.054
   Porta CAML., 2011, Skin Cancers-Risk Factors, DOI [10.5772/1498, DOI 10.5772/1498]
   Prabhu V., 2019, P MACH LEARN HEALTHC, P532
   Rafay A, 2023, BIOMED SIGNAL PROCES, V85, DOI 10.1016/j.bspc.2023.104869
   Rastgoo M, 2015, COMPUT MED IMAG GRAP, V43, P44, DOI 10.1016/j.compmedimag.2015.02.011
   Sáez A, 2016, IEEE T MED IMAGING, V35, P1036, DOI 10.1109/TMI.2015.2506270
   Sánchez-Monedero J, 2016, LECT NOTES ARTIF INT, V9648, P427, DOI 10.1007/978-3-319-32034-2_36
   Seeja R.D., 2019, Int. J. Innov. Technol. Explor. Eng, V8, P2667, DOI [10.35940/ijitee.L2516.1081219, DOI 10.35940/IJITEE.L2516.1081219]
   Serte S, 2019, COMPUT BIOL MED, V113, DOI 10.1016/j.compbiomed.2019.103423
   Shuai WJ, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11091510
   Silva Pedro, 2020, Inform Med Unlocked, V20, P100427, DOI 10.1016/j.imu.2020.100427
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh R, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108111
   Sudowe P, 2016, BRIT MACH VIS C, DOI [10.5244/C.30.75, DOI 10.5244/C.30.75]
   Sugata TLI, 2017, IOP CONF SER-MAT SCI, V273, DOI [10.1088/1757-899X/273/1/012004, 10.1088/1757-899X/245/1/012004]
   Tahir M, 2023, CANCERS, V15, DOI 10.3390/cancers15072179
   Ul Ain Q, 2022, EXPERT SYST APPL, V197, DOI 10.1016/j.eswa.2022.116680
   Wang W, 2019, OPT ENG, V58, DOI 10.1117/1.OE.58.4.040901
   Wang Z, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2298
   Witten IH, 2011, MOR KAUF D, P1
   Wu P, 2022, Frontiers Comput Intell Syst, V2, P110, DOI [10.54097/fcis.v2i1.3177, DOI 10.54097/FCIS.V2I1.3177]
   Xin C, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.105939
   Yang S, 2017, BIOMED SIGNAL PROCES, V32, P90, DOI 10.1016/j.bspc.2016.09.019
   Yang XY, 2020, Arxiv, DOI arXiv:2003.13865
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
NR 78
TC 4
Z9 4
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27305
EP 27329
DI 10.1007/s11042-023-16529-w
EA AUG 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062556300007
DA 2024-07-18
ER

PT J
AU Zou, L
   Ding, ZS
   Ran, SY
   Wu, ZZ
   Wei, YS
   He, ZH
   Wang, XF
AF Zou, Le
   Ding, Ze-Sheng
   Ran, Shuo-Yi
   Wu, Zhi-Ze
   Wei, Yun-Sheng
   He, Zhi-Huang
   Wang, Xiao-Feng
TI A benchmark dataset in chemical apparatus: recognition and detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Chemical apparatus; Object detection; Image recognition;
   Benchmark dataset
ID CONVOLUTIONAL NEURAL-NETWORK; ARTIFICIAL-INTELLIGENCE; IMAGE RECOGNITION
AB Robots that perform chemical experiments autonomously have been implemented, using the same chemical apparatus as human chemists and capable of performing complex chemical experiments unmanaged. However, most robots in chemistry are still programmed and cannot adapt to diverse environments or to changes in displacement and angle of the object. To resolve this issue, we have conceived a computer vision method for identifying and detecting chemical apparatus automatically. Identifying and localizing such apparatus accurately from chemistry lab images is the most important task. We acquired 2246 images from real chemistry laboratories, with a total of 33,108 apparatus instances containing 21 classes. We demonstrate a Chemical Apparatus Benchmark Dataset (CABD) containing a chemical apparatus image recognition dataset and a chemical apparatus object detection dataset. We evaluated five excellent image recognition models: AlexNet, VGG16, GoogLeNet, ResNet50, MobileNetV2 and four state-of-the-art object detection methods: Faster R-CNN (3 backbones), Single Shot MultiBox Detector (SSD), YOLOv3-SPP and YOLOv5, respectively, on the CABD dataset. The results can serve as a baseline for future research. Experiments show that ResNet50 has the highest accuracy (99.9%) in the chemical apparatus image recognition dataset; Faster R-CNN (ResNet50-fpn) and YOLOv5 performed the best in terms of mAP (99.0%) and AR (94.5%) in the chemical apparatus object detection dataset.
C1 [Zou, Le; Ding, Ze-Sheng; He, Zhi-Huang; Wang, Xiao-Feng] Hefei Univ, Sch Artificial Intelligence & Big Data, Hefei 230601, Peoples R China.
   [Ran, Shuo-Yi; Wu, Zhi-Ze] Hefei Univ, Inst Appl Optimizat, Sch Artificial Intelligence & Big Data, Hefei 230601, Anhui, Peoples R China.
   [Wei, Yun-Sheng] Hefei Univ, Sch Energy Mat & Chem Engn, Hefei 230601, Anhui, Peoples R China.
C3 Hefei University; Hefei University; Hefei University
RP Wang, XF (corresponding author), Hefei Univ, Sch Artificial Intelligence & Big Data, Hefei 230601, Peoples R China.
EM xfwang@hfuu.edu.cn
FU Anhui Provincial Natural Science Foundation [1908085MF184,
   1908085QF285]; Scientific Research and Talent Development Foundation of
   the Hefei University [21-22RC15]; Key Research Plan of Anhui Province
   [202104d07020006, 2022 k07020011]; Hefei University Postgraduate
   Innovation and Entrepreneurship [21YCXL16, 21YCXL14]; Key Generic
   Technology Research and Development Project of Hefei [2021GJ030];
   Program for Scientific Research Innovation Team in Colleges and
   Universities of Anhui Province [2022AH010095]; AI General Computing
   Platform of Hefei University
FX This work was supported by the grant of Anhui Provincial Natural Science
   Foundation, Nos. 1908085MF184, 1908085QF285, the grant of Scientific
   Research and Talent Development Foundation of the Hefei University,
   No.21-22RC15, the Key Research Plan of Anhui Province, Nos.
   202104d07020006, 2022 k07020011, the grant of the Hefei University
   Postgraduate Innovation and Entrepreneurship Project, Nos.
   21YCXL16,21YCXL14, in part by the grant of Key Generic Technology
   Research and Development Project of Hefei, No. 2021GJ030, the grant of
   Program for Scientific Research Innovation Team in Colleges and
   Universities of Anhui Province 2022AH010095, as well as the AI General
   Computing Platform of Hefei University.
CR Althoff M, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aaw1924
   Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640
   Burger B, 2020, NATURE, V583, P237, DOI 10.1038/s41586-020-2442-2
   Cao WM, 2020, IEEE ACCESS, V8, P14531, DOI 10.1109/ACCESS.2020.2966881
   Chai JY, 2019, INT CONF MACH LEARN, P535, DOI 10.1109/icmlc48188.2019.8949185
   Christensen H., 2021, Foundations and Trends in Robotics, V8, P307
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding Ze-sheng, 2022, Artificial Intelligence in Data and Big Data Processing: Proceedings of ICABDE 2021. Lecture Notes on Data Engineering and Communications Technologies (124), P201, DOI 10.1007/978-3-030-97610-1_17
   Frizzi S, 2016, IEEE IND ELEC, P877, DOI 10.1109/IECON.2016.7793196
   Fujiyoshi H, 2019, IATSS RES, V43, P244, DOI 10.1016/j.iatssr.2019.11.008
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Henson AB, 2018, ACS CENTRAL SCI, V4, P793, DOI 10.1021/acscentsci.8b00176
   Hossain S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153371
   Huang ZC, 2020, INFORM SCIENCES, V522, P241, DOI 10.1016/j.ins.2020.02.067
   Jadon A., 2019, arXiv
   Kelley EW, 2021, J CHEM EDUC, V98, P1622, DOI 10.1021/acs.jchemed.0c01172
   Khan RU, 2019, J COMPUT VIROL HACKI, V15, P29, DOI 10.1007/s11416-018-0324-z
   Knickmeyer D, 2020, J CLEAN PROD, V245, DOI 10.1016/j.jclepro.2019.118605
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2020, ALEX ENG J, V59, P999, DOI 10.1016/j.aej.2020.03.034
   Li LF, 2020, IEEE ACCESS, V8, P208264, DOI 10.1109/ACCESS.2020.3037258
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lixuan Du, 2020, Journal of Physics: Conference Series, V1544, DOI 10.1088/1742-6596/1544/1/012033
   Lu ZM, 2006, INT J INNOV COMPUT I, V2, P831
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mukti IZ, 2019, INT CONF ELECTR ENG, DOI 10.1109/eict48899.2019.9068805
   Nayyar A, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON COMPUTING SCIENCES (ICCS), P151, DOI 10.1109/ICCS.2018.00033
   Pan XG, 2018, AAAI CONF ARTIF INTE, P7276
   Parmar DN, 2014, ARXIV
   Patrício DI, 2018, COMPUT ELECTRON AGR, V153, P69, DOI 10.1016/j.compag.2018.08.001
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rostianingsih Silvia, 2020, Procedia Computer Science, V171, P2445, DOI 10.1016/j.procs.2020.04.264
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Savadjiev P, 2019, EUR RADIOL, V29, P1616, DOI 10.1007/s00330-018-5674-x
   Shetty S, 2016, ARXIV
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan MX, 2021, PR MACH LEARN RES, V139, P7102
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Varga D, 2020, ALGORITHMS, V13, DOI 10.3390/a13120313
   Vrancken C, 2019, EXPERT SYST APPL, V125, P268, DOI 10.1016/j.eswa.2019.01.077
   Wan SH, 2020, COMPUT COMMUN, V149, P99, DOI 10.1016/j.comcom.2019.10.012
   Wang HT, 2015, CHEM SOC REV, V44, P2664, DOI 10.1039/c4cs00287c
   Willey RJ, 2020, J LOSS PREVENT PROC, V63, DOI 10.1016/j.jlp.2019.103961
   Zanchettin AM, 2016, IEEE T AUTOM SCI ENG, V13, P882, DOI 10.1109/TASE.2015.2412256
   Zhang Q, 2021, RESOUR CONSERV RECY, V171, DOI 10.1016/j.resconrec.2021.105636
   Zhavoronkov A, 2018, MOL PHARMACEUT, V15, P4311, DOI 10.1021/acs.molpharmaceut.8b00930
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 49
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26419
EP 26437
DI 10.1007/s11042-023-16563-8
EA AUG 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062556300002
DA 2024-07-18
ER

PT J
AU Liu, Y
   Fan, X
   Han, SY
   Zhou, J
   Yang, XH
   Li, ZT
AF Liu, Yu
   Fan, Xue
   Han, Shiyuan
   Zhou, Jin
   Yang, Xiaohui
   Li, Zhongtao
TI RVPNet: A real time unstructured road vanishing point detection
   algorithm using attention mechanism and global context information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vanishing point; Unstructured road; Encoder-decoder; Feature
   aggregation; Contextual information
ID SALIENT OBJECT DETECTION; LANE DETECTION; EXTRACTION; NETWORK
AB The detection of the vanishing point (VP) in unstructured road is crucial for the advancement of autonomous vehicle technology. However, due to the inadequate fusion of intra-level features and high computational requirements of existing CNN-based road VP detection methods, a model named RVPNet is proposed in this paper. To begin, the proposed algorithm adopts the architecture of encoder-decoder combined lightweight backbone to extract unstructured road features efficiently. Second, the Simple Residual Pyramid Pooling Module (SRPPM) is designed in this model to obtain cross-path global contextual information with low computational cost. And a Dual Attention-based Feature Aggregation Module (DAFAM) is proposed to obtain better inter-level feature representations. Finally, the offset loss is introduced to compensate for the inherent offset errors caused by the output stride of the heatmap. The experimental results show that the average detection error rate of our approach is only 0.03128 on the Kong dataset, and the average processing time reaches 238 FPS. The average detection error rate of our approach based is only 0.03600 on the Moghhadam dataset. Compared with the state-of-the-art methods, the proposed approach achieves the highest detection accuracy and speed.
C1 [Liu, Yu; Fan, Xue; Han, Shiyuan; Zhou, Jin; Yang, Xiaohui; Li, Zhongtao] Univ Jinan, Sch Informat Sci & Engn, Jinan 250022, Peoples R China.
C3 University of Jinan
RP Han, SY (corresponding author), Univ Jinan, Sch Informat Sci & Engn, Jinan 250022, Peoples R China.
EM qwepliuyu@163.com; ise_fanx@ujn.edu.cn; ise_hangsy@ujn.edu.cn;
   ise_zhouj@ujn.edu.cn; ise_xhyang@ujn.edu.cn; ise_lizt@ujn.edu.cn
RI Li, Zhongtao/GXF-7567-2022
OI Li, Zhongtao/0000-0002-0801-0698
FU Natural Science Foundation of Shandong Province for Key Project
   [ZR2020KF006]; National Natural Science Foundation of China [62273164];
   Development Program Project of Youth Innovation Team of Institutions of
   Higher Learning in Shandong Province; China Postdoctoral Science
   Foundation [2019M662407]
FX This research was funded by the Natural Science Foundation of Shandong
   Province for Key Project under Grant ZR2020KF006, the National Natural
   Science Foundation of China under Grant 62273164, the Development
   Program Project of Youth Innovation Team of Institutions of Higher
   Learning in Shandong Province, and the China Postdoctoral Science
   Foundation under Grant 2019M662407.
CR [Anonymous], 2006, 2006 IEEE COMPUTER S
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bang S, 2019, COMPUT-AIDED CIV INF, V34, P713, DOI 10.1111/mice.12440
   Cai Y., 2020, COMPUTER VISION ECCV, P455
   Chang CK, 2018, IEEE INT CONF ROBOT, P4496
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen X, 2013, ADV MATER RES-SWITZ, V781-784, P2383, DOI 10.4028/www.scientific.net/AMR.781-784.2383
   Ding WL, 2015, IET COMPUT VIS, V9, P549, DOI 10.1049/iet-cvi.2014.0187
   Ebrahimpour R, 2012, IET COMPUT VIS, V6, P40, DOI 10.1049/iet-cvi.2010.0046
   Fei JC, 2021, IEEE INT VEH SYM, P838, DOI 10.1109/IV48863.2021.9575694
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang SH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P844, DOI 10.1109/ICCV48922.2021.00090
   Huang ZL, 2022, IEEE T PATTERN ANAL, V44, P550, DOI 10.1109/TPAMI.2021.3062772
   Ji YZ, 2021, INFORM SCIENCES, V546, P835, DOI 10.1016/j.ins.2020.09.003
   Kingma DP, 2020, ARXIV
   Kocur V, 2021, LECT NOTES COMPUT SC, V12895, P628, DOI 10.1007/978-3-030-86383-8_50
   Kogan H, 2009, PROC CVPR IEEE, P755, DOI 10.1109/CVPRW.2009.5206713
   Kong H, 2013, IEEE T CYBERNETICS, V43, P1719, DOI 10.1109/TSMCB.2012.2228639
   Kong H, 2010, IEEE T IMAGE PROCESS, V19, P2211, DOI 10.1109/TIP.2010.2045715
   Kortli Y, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON ANTI-CYBER CRIMES (ICACC), P166, DOI 10.1109/Anti-Cybercrime.2017.7905284
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Lee J, 2019, PROC CVPR IEEE, P2273, DOI 10.1109/CVPR.2019.00238
   Lee S, 2017, IEEE I CONF COMP VIS, P1965, DOI 10.1109/ICCV.2017.215
   Li Y, 2018, ROBOT AUTON SYST, V109, P86, DOI 10.1016/j.robot.2018.08.011
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu YB, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3019863
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Moghadam P, 2012, IEEE T IMAGE PROCESS, V21, P425, DOI 10.1109/TIP.2011.2162422
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Peng J., 2022, ARXIV
   Peng KY, 2022, IEEE T INTELL TRANSP, V23, P15824, DOI 10.1109/TITS.2022.3145588
   Qin ZQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P763, DOI 10.1109/ICCV48922.2021.00082
   Rasmussen C, 2008, AUTON ROBOT, V25, P205, DOI 10.1007/s10514-008-9091-x
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen SY, 2022, VEHICLES-BASEL, V4, P314, DOI 10.3390/vehicles4020019
   Shruthiba A, 2021, 2021 IEEE INT C COMP, P1, DOI [10.1109/CSITSS54238.2021.9683182, DOI 10.1109/CSITSS54238.2021.9683182]
   Song Q, 2021, AAAI CONF ARTIF INTE, V35, P2567
   Varma G, 2019, IEEE WINT CONF APPL, P1743, DOI 10.1109/WACV.2019.00190
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang P, 2021, IEEE INT CONF ROBOT, P13120, DOI 10.1109/ICRA48506.2021.9561087
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang WG, 2018, PROC CVPR IEEE, P1711, DOI 10.1109/CVPR.2018.00184
   Wang Y, 2000, PATTERN RECOGN LETT, V21, P677, DOI 10.1016/S0167-8655(00)00021-0
   Wang Y, 2004, IMAGE VISION COMPUT, V22, P269, DOI 10.1016/j.imavis.2003.10.003
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu PC, 2014, PATTERN RECOGN, V47, P2756, DOI 10.1016/j.patcog.2014.02.004
   Wu ZS, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16070948
   Yan SA, 2017, 2017 32ND YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P634, DOI 10.1109/YAC.2017.7967487
   Yang GA, 2019, IEEE ACCESS, V7, P139358, DOI 10.1109/ACCESS.2019.2944244
   Yu CQ, 2021, PROC CVPR IEEE, P10435, DOI 10.1109/CVPR46437.2021.01030
   Zhang Y, 2019, 2019 13TH INTERNATIONAL SYMPOSIUM ON THEORETICAL ASPECTS OF SOFTWARE ENGINEERING (TASE 2019), P184, DOI [10.1109/TASE.2019.000-2, 10.1109/TASE.2019.00032]
   Zhou X., 2019, arXiv
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 54
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 28263
EP 28280
DI 10.1007/s11042-023-16447-x
EA AUG 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060692700009
DA 2024-07-18
ER

PT J
AU Sakshi
   Kukreja, V
AF Sakshi
   Kukreja, Vinay
TI Machine learning and non-machine learning methods in mathematical
   recognition systems: Two decades' systematic literature review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Mathematical expression recognition; Handwritten mathematical
   expressions; Classification; Machine learning; Math expressions; SVM;
   CNN
ID STRUCTURAL-ANALYSIS; FORMULA RECOGNITION; HANDWRITING RECOGNITION;
   IMPROVING RECOGNITION; SYMBOL RECOGNITION; SYNTACTIC APPROACH; ONLINE;
   EXPRESSIONS; GRAPH; CLASSIFICATION
AB Tools based on machine learning (ML) have seen widespread application in the prediction and categorization of mathematical symbols and phrases. The purpose of this work is to conduct a comprehensive analysis of the machine learning and non-machine learning strategies that are currently in use for the recognition of mathematical expressions. (MEs). The authors collected and analyzed research studies on the recognition of MEs (and closely related models and issues as well), which are published from January 2000 to December 2022 in the SLR. The review has nominated 98 primary studies out of the extracted 202 studies after heedful filtering using inclusion/exclusion criteria and quality assessment. The pertinent data is derived from IEEE explore, Science Direct, Wiley, Scopus, ACM Digital Library, etc. For assiduously reviewing and synthesizing the data, the authors used grounded theory and other qualitative and quantitative techniques. The analysis reveals that the support vector machine as an ML model with CROHME as the dataset and expression recognition rate as an accuracy metric is frequently used in the chosen studies. Recognition is typically fragmented down into three stages-segmenting symbols, recognizing symbols, and analyzing structures-in non-ML studies. In conclusion, this work aims to synthesize the results of existing research to provide a summary of the state-of-the-art in recognizing handwritten MEs.
C1 [Sakshi] Sharda Univ, Dept Comp Sci & Applicat, Greater Noida, Uttar Pradesh, India.
   [Kukreja, Vinay] Chitkara Univ, Inst Engn & Technol, Chandigarh, Punjab, India.
C3 Sharda University; Chitkara University, Punjab; Panjab University
RP Kukreja, V (corresponding author), Chitkara Univ, Inst Engn & Technol, Chandigarh, Punjab, India.
EM asakshi541@gmail.com; onlyvinaykukreja@gmail.com
RI Kukreja, Vinay/AAT-7893-2021
OI Kukreja, Vinay/0000-0002-9760-0824
CR Afshan N., 2017, Int J Adv Res Comput Sci, V8, P2021
   Aggarwal R, 2020, ADV INTELL SYST, V1024, P213, DOI 10.1007/978-981-32-9291-8_18
   Ahmed M, 2004, MATH COMPUT SIMULAT, V67, P149, DOI 10.1016/j.matcom.2004.05.015
   Ali A, 2019, J SOFTW-EVOL PROC, V31, DOI 10.1002/smr.2211
   Alvaro Francisco, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1953, DOI 10.1109/ICPR.2010.481
   Alvaro F, 2015, Departamento de Sistemas Inform'aticos y Computaci'on, Universitat Polit'ecnica de Val'encia], DOI 10.1.1.1031.2330
   Alvaro F, 2016, PATTERN RECOGN, V51, P135, DOI 10.1016/j.patcog.2015.09.013
   Alvaro F, 2014, INT C PATT RECOG, P2944, DOI 10.1109/ICPR.2014.507
   Alvaro F, 2013, LECT NOTES COMPUT SC, V7887, P666
   Alvaro F, 2014, PATTERN RECOGN LETT, V35, P58, DOI 10.1016/j.patrec.2012.09.023
   Alvaro F, 2012, INT CONF FRONT HAND, P181, DOI 10.1109/ICFHR.2012.287
   Alvaro F, 2011, PROC INT CONF DOC, P1225, DOI 10.1109/ICDAR.2011.247
   Aly Walaa, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1350, DOI 10.1109/ICDAR.2009.90
   Aly W, 2008, MATH COMPUT SCI, V2, P195, DOI 10.1007/s11786-008-0051-9
   Anderson R. H., 1967, S INT SYST EXP APPL, P436, DOI DOI 10.1145/2402536.2402585
   Le AD, 2019, PATTERN RECOGN LETT, V128, P255, DOI 10.1016/j.patrec.2019.09.002
   Le AD, 2019, INT J DOC ANAL RECOG, V22, P29, DOI 10.1007/s10032-019-00315-2
   Le AD, 2017, PROC INT CONF DOC, P1056, DOI 10.1109/ICDAR.2017.175
   Le AD, 2016, INT J DOC ANAL RECOG, V19, P305, DOI 10.1007/s10032-016-0272-4
   Le AD, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P51, DOI 10.1109/DAS.2014.52
   [Anonymous], 2013, P 2013 ACM S DOC ENG
   [Anonymous], 2017, Int. J. Adv. Soft Comp. Appl.
   [Anonymous], 2013, ACM Symposium on Document Engineering
   Arora S, 2008, IEEE REGION 10 COLLOQUIUM AND THIRD INTERNATIONAL CONFERENCE ON INDUSTRIAL AND INFORMATION SYSTEMS, VOLS 1 AND 2, P454
   Ashiquzzaman A, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR)
   Awal A., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P427, DOI 10.1109/ICFHR.2010.73
   Awal Ahmad-Montaser, 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P646, DOI 10.1109/ICFHR.2010.106
   Awal Ahmad-Montaser, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1046, DOI 10.1109/ICDAR.2009.71
   Awal AM, 2014, PATTERN RECOGN LETT, V35, P68, DOI 10.1016/j.patrec.2012.10.024
   Awal AM, 2010, PROC SPIE, V7534, DOI 10.1117/12.840023
   Bage D.D., 2010, International Journal of Innovative Research in Science, Engineering and Technology, V2, P2823
   Baker J.B., 2010, The Ninth IAPR International Workshop on Document Analysis Systems, DAS 2010, June 9-11, 2010, Boston, Massachusetts, USA, P485, DOI [DOI 10.1145/1815330.1815393, 10.1145/1815330.1815393]
   Basu S., 2005, P 2 IND INT C ART IN, P407
   BELAID A, 1984, IEEE T PATTERN ANAL, V6, P105, DOI 10.1109/TPAMI.1984.4767483
   Bharambe M., 2015, NAT C DIG IM SIGN P, P35
   Bott JN, 2011, P SBIM 2011 ACM SIGG, V1, P125, DOI [10.1145/2021164.2021187, DOI 10.1145/2021164.2021187]
   Brereton P, 2007, J SYST SOFTWARE, V80, P571, DOI 10.1016/j.jss.2006.07.009
   Büyükbayrak H, 2007, PROC SPIE, V6500, DOI 10.1117/12.704043
   Campanelli AS, 2015, J SYST SOFTWARE, V110, P85, DOI 10.1016/j.jss.2015.08.035
   Cao Y, 2019, INT C APPL TECHN CYB, V1, P1494
   Celar S, 2015, PROCEDIA ENGINEER, V100, P782, DOI 10.1016/j.proeng.2015.01.432
   Celik M, 2011, PROC INT CONF DOC, P161, DOI 10.1109/ICDAR.2011.41
   Chajri Y., 2016, International Journal of Signal Processing, Image Processing and Pattern Recognition, V9, P69, DOI [10.14257/ijsip.2016.9.5.07, DOI 10.14257/IJSIP.2016.9.5.07]
   Chan CK, 2020, IEEE ACCESS, V8, P61565, DOI 10.1109/ACCESS.2020.2984627
   Chan KF, 2000, PATTERN RECOGN, V33, P375, DOI 10.1016/S0031-3203(99)00067-9
   Chan KF, 2001, PATTERN RECOGN, V34, P1671, DOI 10.1016/S0031-3203(00)00102-3
   Chandrashekhar Iyer K., 2001, PICMET '01. Portland International Conference on Management of Engineering and Technology. Proceedings Vol.1: Book of Summaries (IEEE Cat. No.01CH37199), P274, DOI 10.1109/PICMET.2001.952162
   Chaudhuri BB, 2000, PATTERN ANAL APPL, V3, P120, DOI 10.1007/s100440070017
   Chen Y, 2001, INT J PATTERN RECOGN, V15, P967, DOI 10.1142/S021800140100126X
   Choudhary Amit, 2021, International Conference on Innovative Computing and Communications. Proceedings of ICICC 2020. Advances in Intelligent Systems and Computing (AISC 1166), P527, DOI 10.1007/978-981-15-5148-2_47
   Clark R, 2013, 2013 IEEE EUROCON, P2029, DOI 10.1109/EUROCON.2013.6625259
   CORBIN J, 1990, Z SOZIOL, V19, P418, DOI 10.1007/BF00988593
   Nguyen CT, 2020, PATTERN RECOGN LETT, V131, P113, DOI 10.1016/j.patrec.2019.12.015
   Dagenais B, 2009, 2009 ICSE WORKSHOP ON COOPERATIVE AND HUMAN ASPECTS OF SOFTWARE ENGINEERING, P32, DOI 10.1109/CHASE.2009.5071407
   Dai JY, 2019, 2019 10TH INTERNATIONAL CONFERENCE ON E-EDUCATION, E-BUSINESS, E-MANAGEMENT AND E-LEARNING (IC4E 2019), P198, DOI 10.1145/3306500.3306543
   Davila K, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1165, DOI 10.1145/3077136.3080748
   Drsouza L., 2018, INT C INF COMM ENG T, P1, DOI [10. 1109/ICICET.2018.8533789, DOI 10.1109/ICICET.2018.8533789]
   Eto Y, 2001, PROC INT CONF DOC, P762, DOI 10.1109/ICDAR.2001.953891
   Fahmy H., 1993, Machine Vision and Applications, V6, P83, DOI 10.1007/BF01211933
   Fang DB, 2020, IEEE ACCESS, V8, P48101, DOI 10.1109/ACCESS.2020.2979346
   Farulla GA, 2016, LECT NOTES COMPUT SC, V9758, P7, DOI 10.1007/978-3-319-41264-1_1
   Feng X, 2001, 85 TECHN RES M JSISE, P1
   Fitzgerald JA, 2007, PROC INT CONF DOC, P694
   Fitzgerald JA, 2006, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER SCIENCE AND TECHNOLOGY, P151
   Garain Utpal, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1340, DOI 10.1109/ICDAR.2009.203
   Garain U., 2002, On development and statistical analysis of a corpus for printed and handwritten mathematical expressions, V2002, P689
   Garain U., 2005, Automatic recognition of printed and handwritten mathematical expressions
   Garain U, 2007, ADV PATTERN RECOGNIT, P235, DOI 10.1007/978-1-84628-726-8_11
   Garst P., 2004, U.S. Patent Application, DOI 10.4324/9781315853178, Patent No. [2004/0054701A1, 20040054701]
   Genoe R, 2006, INT WORKSH FRONT HAN, P1
   Genoe R, 2006, IEEE INT CONF FUZZY, P244, DOI 10.1109/FUZZY.2006.1681721
   Gharde S.S, 2012, International Journal of Applied Information Systems, V1, P34, DOI DOI 10.5120/IJAIS12-450183
   Tran GS, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON CONTROL, ROBOTICS AND CYBERNETICS (CRC), P15, DOI 10.1109/CRC.2018.00012
   Gong Y., 2015, Computer Engineering and Applications Journal, V7, P43
   Nguyen HD, 2016, IEICE T INF SYST, VE99D, P3110, DOI 10.1587/transinf.2016EDP7102
   Han F, 2005, IEEE I CONF COMP VIS, P1778
   Hirata NST, 2015, PATTERN RECOGN, V48, P837, DOI 10.1016/j.patcog.2014.09.015
   Hirata NST, 2011, LECT NOTES COMPUT SC, V6658, P295, DOI 10.1007/978-3-642-20844-7_30
   Hossain MB, 2018, 2018 JOINT 7TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV) AND 2018 2ND INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR), P250, DOI 10.1109/ICIEV.2018.8640991
   Hu L, 2016, INT CONF FRONT HAND, P337, DOI [10.1109/ICFHR.2016.0070, 10.1109/ICFHR.2016.65]
   Hu L, 2016, INT CONF FRONT HAND, P180, DOI [10.1109/ICFHR.2016.0044, 10.1109/ICFHR.2016.41]
   Hu L, 2012, INT C PATT RECOG, P326
   Hu Y, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P171, DOI 10.1109/DAS.2014.47
   Huang BQ, 2007, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, P793, DOI 10.1109/ISDA.2007.31
   Huang BQ, 2007, INT J COMPUT SCI NET, V7, P47
   Jain C, 2017, Recognition of Online Handwritten Math Symbols using Density Features
   Jiaming Wang, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1181, DOI 10.1109/ICDAR.2019.00191
   Jianyu X., 2008, Computer Applications and Software, V5, P82
   Jin JM, 2003, PROC INT CONF DOC, P1138
   Julca-Aguilar F, 2015, P IBEROAMERICAN C PA, P144
   Kacem A., 2001, International Journal on Document Analysis and Recognition, V4, P97, DOI 10.1007/s100320100064
   Kam-Fai Chan, 2000, International Journal on Document Analysis and Recognition, V3, P3, DOI 10.1007/PL00013549
   Kanahori T, 2000, LECT NOTES COMPUT SC, V1948, P394
   Kang Kim, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1051, DOI 10.1109/ICDAR.2009.140
   Phan KM, 2018, INT J DOC ANAL RECOG, V21, P253, DOI 10.1007/s10032-018-0306-1
   Phan KM, 2015, Proceedings 3rd IAPR Asian Conference on Pattern Recognition ACPR 2015, P171, DOI 10.1109/ACPR.2015.7486488
   Kitchenham B, 2009, INFORM SOFTWARE TECH, V51, P7, DOI 10.1016/j.infsof.2008.09.009
   Kosmala A, 2000, INT C PATT RECOG, P590, DOI 10.1109/ICPR.2000.906143
   Kumar P., 2019, International Journal of Recent Technology and Engineering, V8, P1033, DOI [10.35940/ijrte.B1008.0882S819, DOI 10.35940/IJRTE.B1008.0882S819]
   Kumar PP, 2018, PATTERN ANAL APPL, V21, P1097, DOI 10.1007/s10044-017-0667-y
   Kundu S, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112916
   Lapointe Adrien, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1355, DOI 10.1109/ICDAR.2009.247
   LaViola JJ, 2008, P GRAPHICS INTERFACE, P131
   LaViola JJ, 2007, IEEE T PATTERN ANAL, V29, P1917, DOI 10.1109/TPAMI.2007.1109
   Le A, 2013, 16 INT GRAPH SOC C, DOI [10.9790/487X-171214553, DOI 10.9790/487X-171214553]
   Le AD, 2015, 18 M IMAGE RECOGNTIO, P1
   Li C, 2008, P INT C PATT REC, P1, DOI [10.1109/icpr.2008.4761825, DOI 10.1109/ICPR.2008.4761825]
   Lin XY, 2012, PROC SPIE, V8297, DOI 10.1117/12.912445
   Liu C, 2015, PR IEEE I C PROGR IN, P252, DOI 10.1109/PIC.2015.7489848
   Liu H, 2021, Smart Device Recognition, P229
   Lods Arnaud, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P641, DOI 10.1109/ICDAR.2019.00108
   MacLean S, 2010, Issue Tech.Rep.CS-2010-13
   MacLean S, 2015, PATTERN RECOGN, V48, P2433, DOI 10.1016/j.patcog.2015.02.017
   MacLean S, 2013, INT J DOC ANAL RECOG, V16, P139, DOI 10.1007/s10032-012-0184-x
   Mahdavi Mahshad, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1533, DOI 10.1109/ICDAR.2019.00247
   Malon C, 2008, PATTERN RECOGN LETT, V29, P1326, DOI 10.1016/j.patrec.2008.02.005
   Marques F. C. F.  Jr., 2019, 2019 8th Brazilian Conference on Intelligent Systems (BRACIS). Proceedings, P245, DOI 10.1109/BRACIS.2019.00051
   Medjkoune Sofiane, 2013, Human-Computer Interaction. Interaction Modalities and Techniques. 15th International Conference, HCI International 2013. Proceedings. LNCS 8007, P77, DOI 10.1007/978-3-642-39330-3_9
   Medjkoune S, 2017, IEEE T HUM-MACH SYST, V47, P259, DOI 10.1109/THMS.2017.2647850
   Medjkoune S, 2012, INT CONF FRONT HAND, P187, DOI 10.1109/ICFHR.2012.288
   Memon J, 2020, Arxiv, DOI arXiv:2001.00139
   Mohan K, 2013, Recognition of online handwritten mathematical expressions
   Mohan K, 2015, Recognition of online handwritten mathematical expressions using convolutional neural networks
   Mouchère H, 2016, INT CONF FRONT HAND, P607, DOI [10.1109/ICFHR.2016.0116, 10.1109/ICFHR.2016.108]
   Mouchère H, 2014, INT CONF FRONT HAND, P791, DOI 10.1109/ICFHR.2014.138
   Mouchère H, 2012, INT CONF FRONT HAND, P811, DOI 10.1109/ICFHR.2012.215
   Mouchère H, 2013, PROC INT CONF DOC, P1428, DOI 10.1109/ICDAR.2013.288
   Mouchére H, 2011, PROC INT CONF DOC, P1497, DOI 10.1109/ICDAR.2011.297
   Munoz F.A., 2010, Off-line Recognition of Printed Mathematical Expressions Using Stochastic Context-Free Grammars
   Okamoto M., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P121, DOI 10.1109/ICDAR.2001.953767
   Pacheco-Venegas ND, 2015, COMPUT EDUC, V88, P15, DOI 10.1016/j.compedu.2015.03.021
   Pattaniyil N., 2014, NTCIR WORKSH 11 M, P101
   Pfleeger SL, 2005, IEEE SOFTWARE, V22, P66, DOI 10.1109/MS.2005.19
   Phan KM, 2016, INT CONF FRONT HAND, P258, DOI [10.1109/ICFHR.2016.0057, 10.1109/ICFHR.2016.52]
   Phong BH., 2021, International Journal of Computational Vision and Robotics, V11, P66, DOI [10.1504/IJCVR.2021.111876, DOI 10.1504/IJCVR.2021.111876]
   Pillay A, 2014, Intelligent combination of structural analysis algorithms: Application to mathematical expression recognition
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Plötz T, 2009, INT J DOC ANAL RECOG, V12, P269, DOI 10.1007/s10032-009-0098-4
   Predovic G, 2011, U.S. Patent, Patent No. [8,009,915, 8009915]
   Prusa D, 2007, PROC INT CONF DOC, P849
   Qi Xiangwei, 2009, Journal of Software, V5, P44, DOI 10.4304/jsw.5.1.44-53
   Qi XW, 2009, 2009 INTERNATIONAL FORUM ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 2, PROCEEDINGS, P101, DOI 10.1109/IFITA.2009.169
   Quiniou S, 2011, PROC INT CONF DOC, P452, DOI 10.1109/ICDAR.2011.97
   Rahmi S., 2017, Infinity Journal, V6, P177, DOI DOI 10.22460/INFINITY.V6I2.P177-182
   Raman T.V., 1994, Inf Technol Disabil, V1, P1
   Ramteke RJ., 2006, IEEE Conference on Cybernetics and Intelligent Systems, V2006, P1, DOI [10.1109/ICCIS.2006.252262, DOI 10.1109/ICCIS.2006.252262]
   Ramteke S., 2012, International Journal of Engineering Research Technology (IJERT), V7, P2278
   Reichenbach MS, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P851, DOI 10.1145/2600428.2609457
   Ren HQ, 2019, PATTERN RECOGN, V93, P179, DOI 10.1016/j.patcog.2019.04.015
   Rhee TH, 2009, PATTERN RECOGN, V42, P3192, DOI 10.1016/j.patcog.2008.10.036
   Rohatgi S, 2019, Query auto completion for math formula search, P6
   Ruiz V, 2020, NEUROCOMPUTING, V374, P30, DOI 10.1016/j.neucom.2019.09.041
   Sain K, 2011, INT J DOC ANAL RECOG, V14, P75, DOI 10.1007/s10032-010-0121-9
   Sakshi, 2021, ENG APPL ARTIF INTEL, V103, DOI 10.1016/j.engappai.2021.104292
   Savchenkov P, 2018, United States Patent, Patent No. [15/187,723, 15187723]
   Shan GC, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-018-9824-9
   Shi Y, 2011, US Patent, Patent No. [7,885,456, 7885456]
   Shi Y, 2008, INT C PATT RECOG, P1937
   Shinde Sagar, 2017, 2017 International Conference on Trends in Electronics and Informatics (ICEI). Proceedings, P204, DOI 10.1109/ICOEI.2017.8300916
   Shinde S., 2016, Communications on Applied Electronics, V4, P1, DOI DOI 10.5120/CAE2016652125
   Shuvo Shifat Nayme, 2021, Soft Computing Techniques and Applications. Proceedings of the International Conference on Computing and Communication (IC3 2020). Advances in Intelligent Systems and Computing (AISC 1248), P515, DOI 10.1007/978-981-15-7394-1_47
   Silva W. P. da, 2014, Journal of the Saudi Society of Agricultural Sciences, V13, P67
   Simistira F, 2014, INT CONF FRONT HAND, P164, DOI 10.1109/ICFHR.2014.35
   Simistira F, 2015, PATTERN RECOGN LETT, V53, P85, DOI 10.1016/j.patrec.2014.11.015
   Simistira F, 2012, INT CONF FRONT HAND, P193, DOI 10.1109/ICFHR.2012.172
   So CMY, 2005, technical report
   Stria J, 2014, 19 COMP VIS WINT WOR, P103
   STRUTZEL E, 1968, NURS RES, V17, P364
   Suzuki M, 2005, PROC INT CONF DOC, P675, DOI 10.1109/ICDAR.2005.14
   Suzuki T, 2000, INT C PATT RECOG, P515, DOI 10.1109/ICPR.2000.902970
   Takiguchi Y, 2005, PROC INT CONF DOC, P745, DOI 10.1109/ICDAR.2005.10
   Tapia E, 2004, LECT NOTES COMPUT SC, V3088, P329
   Tapia E, 2003, PROC INT CONF DOC, P980
   Tapia E, 2007, Technical Report B-07-01 Freie Universitat Berlin, Institut fur Informatik Takustr., V9, P14195
   Tapia E, 2005, Understanding mathematics: A system for the recognition of on-line handwritten mathematical expressions
   Tapia E, 2007, MathFoR: The Mathematical Formula Recognition System
   Tapia E., 2007, Handwritten Mathematical notation a survey on recognition of on-line handwritten mathematical
   Thimbleby W, 2004, A better calculator: Processing handwritten mathematical expressions to solve problems
   Tian XD, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 3, PROCEEDINGS, P357
   Toyozumi K, 2004, INT C PATT RECOG, P630, DOI 10.1109/ICPR.2004.1334327
   Ung HQ, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE (ICPRAI 2018), P127
   Urquhart C., 2007, SAGE HDB GROUNDED TH, P339
   Utpal Garain, 2005, International Journal on Document Analysis and Recognition, V7, P241, DOI 10.1007/s10032-004-0140-5
   Veres O, 2019, CEUR WORKSHOP PROCEE, V2362, P378
   Vu Tran Minh Khuong, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P922, DOI 10.1109/ICDAR.2019.00152
   Khuong VTM, 2019, PROC INT CONF DOC, P26, DOI 10.1109/ICDARW.2019.10034
   Khuong VTM, 2021, IEICE T INF SYST, VE104D, P275, DOI 10.1587/transinf.2020EDP7087
   Vuong BQ, 2008, PATTERN RECOGN LETT, V29, P647, DOI 10.1016/j.patrec.2007.11.017
   Vuong BQ, 2010, EXPERT SYST APPL, V37, P886, DOI 10.1016/j.eswa.2009.05.091
   Wang H, 2020, COMPUTER VISION PATT
   Wang J., 2020, Pattern Recogn, V119, P1
   Wang ZR, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107102
   Wangperawong A, 2018, Attending to Mathematical Language with Transformers
   Wen JF, 2012, INFORM SOFTWARE TECH, V54, P41, DOI 10.1016/j.infsof.2011.09.002
   Wu JW, 2020, INT J COMPUT VISION, V128, P2386, DOI 10.1007/s11263-020-01291-5
   Wu JW, 2021, AAAI CONF ARTIF INTE, V35, P2925
   Wu W, 2006, LECT NOTES COMPUT SC, V4113, P274, DOI 10.1007/11816157_27
   Xianyi Chen, 2015, Cloud Computing and Security. First International Conference, ICCCS 2015. Revised Selected Papers: LNCS 9483, P133, DOI 10.1007/978-3-319-27051-7_12
   Yamamoto R, 2006, 10 INT WORKSH FRONT
   Yan L., 2019, International Journal of Engineering Applied Science and Technology, V4, P1
   Yogatama BW, 2018, INT SOC DESIGN CONF, P125
   Shi Y, 2007, PROC INT CONF DOC, P854
   Zanibbi R, 2001, PROC INT CONF DOC, P768, DOI 10.1109/ICDAR.2001.953892
   Zanibbi R, 2002, IEEE T PATTERN ANAL, V24, P1455, DOI 10.1109/TPAMI.2002.1046157
   Zanibbi R., 2001, GRIN 01 NO DESCRIPTI, P127
   Zanibbi R, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P145, DOI 10.1145/2911451.2911512
   Zanibbi R, 2011, PROC SPIE, V7874, DOI 10.1117/12.873312
   Zanibbi R, 2013, PROC SPIE, V8658, DOI 10.1117/12.2008409
   Zanibbi R, 2012, INT J DOC ANAL RECOG, V15, P331, DOI 10.1007/s10032-011-0174-4
   Zelin Hong, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P635, DOI 10.1109/ICDAR.2019.00107
   Zhang J, 2008, Journal of Huaibei Coal Industry Teachers College (Natural Science Edition), V29
   Zhang JS, 2017, PROC INT CONF DOC, P902, DOI 10.1109/ICDAR.2017.152
   Zhang J, 2019, IEEE T MULTIMEDIA, V21, P221, DOI 10.1109/TMM.2018.2844689
   Zhang L, 2005, PROC INT CONF DOC, P972
   Zhang T, 2017, New Architectures for Handwritten Mathematical Expressions Recognition. Image Processing
   Zhang T, 2020, NEURAL COMPUT APPL, V32, P4689, DOI 10.1007/s00521-018-3817-2
   Zhang T, 2016, INT CONF FRONT HAND, P187, DOI [10.1109/ICFHR.2016.0045, 10.1109/ICFHR.2016.42]
   Zhang W., 2019, P 2019 4 INT C MULT, P57, DOI DOI 10.1145/3330393.3330410
   Zhelezniakov D., 2020, IEEE Access, V24, P1
   Zhelezniakov D, 2021, Online handwritten mathematical expression recognition and applications: A survey 9
   Zhelezniakov D, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P212, DOI 10.1145/3377325.3377482
NR 221
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27831
EP 27900
DI 10.1007/s11042-023-16356-z
EA AUG 2023
PG 70
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060108100007
DA 2024-07-18
ER

PT J
AU Rahaman, MA
   Ali, MH
   Hasanuzzaman, M
AF Rahaman, Muhammad Aminur
   Ali, Md. Haider
   Hasanuzzaman, Md.
TI Real-time computer vision-based gestures recognition system for bangla
   sign language using multiple linguistic features analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computer vision; Bangla Sign Language (BdSL); Linguistic features;
   Hand-shape; Movement; Position
ID MODEL
AB Dynamic gestures recognition is a challenging task in the computer vision research area and still difficult to incorporate all linguistic features of a sign language in case of recognition. The proposed method has addressed only three linguistic features (hand-shape, position, and movement) among five more features for a real-time computer vision-based gestures recognition system for Bangla sign language (GRS-BdSL). The system uses Normalized Outer Boundary Vector (NOBV) and proposed Binary Window-Grid Vector (BWGV) of binary hand gestures to classify hand-shapes. Hand position is identified by using the proposed model of hand Position Mapping Filter (PMF). In parallel, the system tracks the movement path of hand-shape using the Adaptive Kalman Filter (AKF). After getting those three linguistic features, the system converts these into corresponding encoding patterns which are used to train and test the system. The proposed system recognizes each gesture by measuring the maximum Inter-Correlation Coefficient (ICC) between the encoding patterns of the test and pre-trained gestures. The system is trained and tested for 100 gestures of Bangla sign language (BdSL) achieving a mean recognition accuracy of 95.43% with the computational costs of 56.013 ms/f. We have also compared the performance of the proposed method with existing methods and have demonstrated that the proposed method has outperformed them under a similar experimental setup.
C1 [Rahaman, Muhammad Aminur] Green Univ Bangladesh, Dept Comp Sci & Engn, 220-D, Dhaka 1207, Bangladesh.
   [Ali, Md. Haider; Hasanuzzaman, Md.] Univ Dhaka, Dept Comp Sci & Engn, Dhaka 1000, Bangladesh.
C3 University of Dhaka
RP Rahaman, MA (corresponding author), Green Univ Bangladesh, Dept Comp Sci & Engn, 220-D, Dhaka 1207, Bangladesh.
EM aminur.wg@gmail.com
OI Rahaman, Muhammad Aminur/0000-0002-7399-5876
FU Center for Research, Innovation, and Transformation (CRIT) of Green
   University of Bangladesh (GUB) [GUBRG/7/2021]
FX & nbsp;This work was supported in part by the Center for Research,
   Innovation, and Transformation (CRIT) of Green University of Bangladesh
   (GUB) under grant No. GUBRG/7/2021.
CR Ahmed ST, 2016, 2016 INTERNATIONAL CONFERENCE ON MEDICAL ENGINEERING, HEALTH INFORMATICS AND TECHNOLOGY (MEDITEC)
   Al-Hammadi M, 2020, IEEE ACCESS, V8, P192527, DOI 10.1109/ACCESS.2020.3032140
   Al-Hammadi M, 2020, IEEE ACCESS, V8, P79491, DOI 10.1109/ACCESS.2020.2990434
   Anami BS, 2018, PATTERN ANAL APPL
   [Anonymous], 2018, WHO Deafness and hearing loss
   Asaari MSM, 2015, MULTIMED TOOLS APPL, V74, P9231, DOI 10.1007/s11042-014-2078-z
   Aziz KE, 2017, 2017 6TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION & 2017 7TH INTERNATIONAL SYMPOSIUM IN COMPUTATIONAL MEDICAL AND HEALTH TECHNOLOGY (ICIEV-ISCMHT)
   Battison R., 1978, Lexical borrowing in American sign language
   Begum Salma, 2009, Proceedings of the 2009 12th International Conference on Computer and Information Technology (ICCIT 2009), P414, DOI 10.1109/ICCIT.2009.5407274
   Bird JJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185151
   Boukir S, 2004, PATTERN ANAL APPL, V7, P308, DOI 10.1007/s10044-004-0228-z
   Boulares M, 2017, PATTERN ANAL APPL
   CD-1 Elementary, 2002, A186 CTR DIS DEV
   CD-2 Advanced, 2002, A186 CTR DIS DEV
   CDD, 2002, MAN SIGN SUPP BANGL
   Cuxac C., 1997, MOUVEMENT BOUCLES SE, P205
   Dong L, 2017, FRONT COMPUT SCI-CHI, V11, P649, DOI 10.1007/s11704-016-5558-7
   Faraway JJ, 2001, 383 U MICH
   Fendri E, 2017, PATTERN ANAL APPL, V20, P907, DOI 10.1007/s10044-017-0621-z
   Guo WL, 2019, MACH VISION APPL, V30, P763, DOI 10.1007/s00138-019-01027-7
   Hossain Sohrab, 2020, Proceedings of Second International Conference on Inventive Research in Computing Applications (ICIRCA 2020), P636, DOI 10.1109/ICIRCA48905.2020.9183357
   Hua GG, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8266-2
   Islalm MDS, 2019, 2019 INT C INN INT
   IVT, 1998, LA LANGUE DES SIGNES, V3
   Jasim M, 2014, INT J IMAGE GRAPH, V14, DOI 10.1142/S0219467814500065
   Kolivand H, 2021, NEURAL COMPUT APPL, V33
   Koller O, 2015, COMPUT VIS IMAGE UND, V141, P108, DOI 10.1016/j.cviu.2015.09.013
   Li GF, 2019, CLUSTER COMPUT, V22, pS2719, DOI 10.1007/s10586-017-1435-x
   Li YN, 2019, MACH VISION APPL, V30, P875, DOI 10.1007/s00138-018-0996-x
   Lu Z, 2019, MACH VISION APPL, V30, P1157, DOI 10.1007/s00138-019-01043-7
   Luo Y, 2008, INT CONF SYST SIGNAL, P89, DOI 10.1109/IWSSIP.2008.4604374
   Mangla FU, 2020, IMAGING SCI J, V68, P156, DOI 10.1080/13682199.2020.1771512
   Michelle J, 2018, SIGN LANGUAGE ASL EX
   Moody B, 1986, LANGUE SIGNES
   Mukushev M, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6073
   Nihal RA, 2021, PATTERN RECOGN LETT
   Rahaman MA, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-018-7253-3
   Rahaman MA, 2018, FRONT COMPUT SCI-CHI, V12, P1258, DOI 10.1007/s11704-018-7082-4
   Rahaman MA, 2015, 2015 18TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), P335, DOI 10.1109/ICCITechn.2015.7488092
   Rahaman MA, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1215, DOI 10.1109/ROBIO.2015.7418937
   Rahaman MA, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), P192, DOI 10.1109/ICCITechn.2014.7073150
   Rinalduzzi M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11125594
   Santa U, 2017, 2017 20TH INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATION TECHNOLOGY (ICCIT)
   Sidig AAI, 2018, INT J ADV COMPUT SC, V9, P283
   sourceforge.net, 2015, EMGUCV
   Starner T, 1995, TR375 MIT MED LAB PE
   Stoke WC, 1976, DICT AM SIGN LANGUAG
   Tabassum T., 2020, J THEOR APPL INF TEC, V98, P743
   Talukder D, 2021, 2020 23 INT C COMPUT, P04
   Talukder D, 2020, INT CONF COMPUT INFO, DOI 10.1109/ICCIT51783.2020.9392693
   Yang L, 2019, MACH VISION APPL, V30, P1071, DOI 10.1007/s00138-019-01038-4
   Yasir F, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING, INSTRUMENTATION AND CONTROL TECHNOLOGIES (ICICICT), P49, DOI 10.1109/ICICICT1.2017.8342533
   Yasir F, 2015, 2015 IEEE 8TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (IWCIA) PROCEEDINGS, P35, DOI 10.1109/IWCIA.2015.7449458
   Zadghorban M, 2018, PATTERN ANAL APPL, V21, P323, DOI 10.1007/s10044-016-0579-2
   Zbakh M, 2015, PATTERN RECOGN LETT, V67, P28, DOI 10.1016/j.patrec.2015.07.041
NR 55
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 19
PY 2023
DI 10.1007/s11042-023-15583-8
EA AUG 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P4YL0
UT WOS:001050733600001
DA 2024-07-18
ER

PT J
AU Jiang, B
   Zeng, WY
   Yang, C
   Wang, RJ
   Zhang, BL
AF Jiang, Bin
   Zeng, Weiyuan
   Yang, Chao
   Wang, Renjun
   Zhang, Bolin
TI DE-GAN: Text-to-image synthesis with dual and efficient fusion model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Text-to-image synthesis; Generative adversarial network; Cross-modal;
   Attention mechanism
ID ATTENTION
AB Generating diverse and plausible images conditioned on the given captions is an attractive but challenging task. While many existing studies have presented impressive results, text-to-image synthesis still suffers from two problems. (1) The fact that noise is only injected at the very beginning hurts the divesity of final results. (2) Most previous models exploit non-local-like spatial attention mechanisms to introduce fine-grained word-level information in the generation process, which makes these models too storage-consuming to apply to mobile and embedded applications. In this paper, we propose a novel Dual and Efficient Fusion Generative Adversarial Newtwork (DE-GAN) to cope with the issues above. To balance the diversity and fidelity of generated images, DE-GAN utilizes Dual Injection Blocks to simultaneously inject noise and text embeddings into the model multiple times during the generation process. In addition, an efficient condition channel attention module is designed in DE-GAN to capture the correlations between text and image modalities to guide the network in refining image features with as little storage overhead as possible, enabling the model to adapt to resource-constrained applications. Comprehensive experiments on two benchmark datasets demonstrate that DE-GAN efficiently generates more diverse and photo-realistic images compared to previous methods.
C1 [Jiang, Bin; Zeng, Weiyuan; Yang, Chao; Wang, Renjun; Zhang, Bolin] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Jiang, Bin; Zeng, Weiyuan] Hunan Univ, Key Lab Embedded & Network Comp Hunan Prov, Changsha 410082, Hunan, Peoples R China.
C3 Hunan University; Hunan University
RP Jiang, B (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.; Jiang, B (corresponding author), Hunan Univ, Key Lab Embedded & Network Comp Hunan Prov, Changsha 410082, Hunan, Peoples R China.
EM jiangbin@hnu.edu.cn; zwy0821@hnu.edu.cn; yangchaoedu@hnu.edu.cn;
   wrj@hnu.edu.cn; onlyou@hnu.edu.cn
OI Jiang, Bin/0000-0002-5840-9664
FU National Natural Science Foundation of China [62072169, 62172156]
FX This work was supported in part by the National Natural Science
   Foundation of China under grant 62072169 and 62172156.
CR Chen YP, 2018, ADV NEUR IN, V31
   Cheng J., 2020, IEEE C COMP VIS PATT, P10911
   Dash A, 2017, Arxiv, DOI arXiv:1703.06412
   Gao P, 2019, PROC CVPR IEEE, P6632, DOI 10.1109/CVPR.2019.00680
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hensel M, 2017, ADV NEUR IN, V30
   Hinz Tobias, 2020, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Islam MA, 2017, PROC CVPR IEEE, P4877, DOI 10.1109/CVPR.2017.518
   Jiadong Liang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P491, DOI 10.1007/978-3-030-58548-8_29
   Kingma D. P., 2014, arXiv
   Lee D, 2021, AAAI CONF ARTIF INTE, V35, P1845
   Li B., 2019, arXiv
   Li WH, 2019, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2019.00514
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ma C, 2020, PROC CVPR IEEE, P5568, DOI 10.1109/CVPR42600.2020.00561
   Mescheder L, 2018, PR MACH LEARN RES, V80
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Qiao TT, 2019, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR.2019.00160
   Reed S, 2016, PR MACH LEARN RES, V48
   Salimans T, 2016, ADV NEUR IN, V29
   Shrimal A, 2021, AAAI CONF ARTIF INTE, V35, P15887
   Tao M, 2022, Arxiv, DOI arXiv:2008.05865
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang ZX, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102904
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Yang C., 2021, P IEEE INT C MULT EX, P1
   Yang C, 2019, IEEE ACCESS, V7, P40771, DOI 10.1109/ACCESS.2019.2908035
   Yang J., 2020, IEEE GEOSCI REMOTE S
   Yang LC, 2021, AAAI CONF ARTIF INTE, V35, P3136
   Yang Y, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107798
   Yin GJ, 2019, PROC CVPR IEEE, P2322, DOI 10.1109/CVPR.2019.00243
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Zhang H, 2021, PROC CVPR IEEE, P833, DOI 10.1109/CVPR46437.2021.00089
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang ZQ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P4195, DOI 10.1109/ICASSP39728.2021.9414166
   Zhang ZZ, 2018, PROC CVPR IEEE, P6199, DOI 10.1109/CVPR.2018.00649
   Zhongjian Q, 2021, NEUROCOMPUTING, V449, P330, DOI 10.1016/j.neucom.2021.03.059
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu MF, 2019, PROC CVPR IEEE, P5795, DOI 10.1109/CVPR.2019.00595
NR 45
TC 1
Z9 1
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 18
PY 2023
DI 10.1007/s11042-023-16377-8
EA AUG 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YW0
UT WOS:001050046600002
DA 2024-07-18
ER

PT J
AU Kolivand, H
   Wee, TC
   Asadianfam, S
   Rahim, MS
   Sulong, G
AF Kolivand, Hoshang
   Wee, Tan Chi
   Asadianfam, Shiva
   Rahim, Mohd Shafry
   Sulong, Ghazali
TI High imperceptibility and robustness watermarking scheme for brain MRI
   using Slantlet transform coupled with enhanced knight tour algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Digital watermarking enhanced knight tour algorithm; Magnetic resonance
   imaging (MRI); Slantlet transform coupled; Medical image
ID REVERSIBLE WATERMARKING; MULTIPLE WATERMARKING; MEDICAL IMAGES;
   AUTHENTICATION; MANAGEMENT; SECURITY
AB This research introduces a novel and robust watermarking scheme for medical Brain MRI DICOM images, addressing the challenge of maintaining high imperceptibility and robustness simultaneously. The scheme ensures privacy control, content authentication, and protection against the detachment of vital Electronic Patient Record information. To enhance imperceptibility, a Dynamic Visibility Threshold parameter leveraging the Human Visual System is introduced. Embeddable Zones and Non-Embeddable Zones are defined to enhance robustness, and an enhanced Knight Tour algorithm based on Slantlet Transform shuffles the embedding sequence for added security. The scheme achieves remarkable results with a Peak Signal-to-Noise Ratio (PSNR) evaluation surpassing contemporary techniques. Extensive experimentation demonstrates resilience to various attacks, with low Bit Error Rate (BER) and high Normalized Cross-Correlation (NCC) values. The proposed technique outperforms existing methods, emphasizing its superior performance and effectiveness in medical image watermarking.
C1 [Kolivand, Hoshang] Liverpool John Moores Univ, Dept Comp Sci, Liverpool L3 3AF, England.
   [Kolivand, Hoshang] Staffordshire Univ, Sch Comp & Digital Technol, Stoke On Trent, England.
   [Wee, Tan Chi] Tunku Abdul Rahman Univ Management & Technol, Fac Comp & Informat Technol, Kuala Lumpur, Malaysia.
   [Kolivand, Hoshang; Wee, Tan Chi] Tunku Abdul Rahman Univ Management & Technol, Ctr Data Sci & Analyt CDSA, Kuala Lumpur, Malaysia.
   [Asadianfam, Shiva] Qom Univ Technol, Fac Elect & Comp Engn, Qom, Iran.
   [Rahim, Mohd Shafry; Sulong, Ghazali] Univ Teknol Malaysia, Fac Comp, Skudai 81310, Johor, Malaysia.
C3 University of Liverpool; Liverpool John Moores University; Staffordshire
   University; Universiti Teknologi Malaysia
RP Asadianfam, S (corresponding author), Qom Univ Technol, Fac Elect & Comp Engn, Qom, Iran.
EM h.kolivand@ljmu.ac.uk; sh_asadianfam@yahoo.com
RI Kolivand, Hoshang/F-4736-2011; Tan, Chi Wee/AGX-8655-2022; asadianfam,
   shiva/ABF-1231-2021; Kolivand, Hoshang/B-2501-2016
OI Tan, Chi Wee/0000-0001-6828-4896; asadianfam, shiva/0000-0002-0062-7079;
   Kolivand, Hoshang/0000-0001-5460-5679
CR Al-Qershi OM, 2011, J DIGIT IMAGING, V24, P114, DOI 10.1007/s10278-009-9253-1
   [Anonymous], 2005, APRS WORKSH DIG IM C
   Badran EF, 2009, NAT RADIO SCI CO, P713
   Badshah G, 2016, J DIGIT IMAGING, V29, P216, DOI 10.1007/s10278-015-9822-4
   Coatrieux G, 2007, 2007 29 ANN INT C IE
   Coatrieux G, 2006, 2005 IEEE ENG MED BI
   Coatrieux G, 2001, SECURITY WATERMARKIN
   Cox IJ., 2007, DIGITAL WATERMARKING
   Das S, 2013, COMPUT METH PROG BIO, V111, P662, DOI 10.1016/j.cmpb.2013.05.027
   Dhavale Sunita V., 2010, 2010 International Conference on Computer and Communication Technology (ICCCT 2010), P108, DOI 10.1109/ICCCT.2010.5640422
   Dong C, 2012, 2012 S PHOT OPT
   Fotopoulos V, 2008, IEEE INT C BIOINF BI, P910
   Garg K., 2015, INT J SCI ENG COMPUT, V5, P48
   Giakoumaki A, 2006, MED BIOL ENG COMPUT, V44, P619, DOI 10.1007/s11517-006-0081-x
   Giakoumaki A, 2004, P ANN INT IEEE EMBS, V26, P3241
   Guo XT, 2009, J DIGIT IMAGING, V22, P53, DOI 10.1007/s10278-007-9043-6
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   Hamidovic H., 2011, ISACA J, V5, P2
   Kundu M. K., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1457, DOI 10.1109/ICPR.2010.360
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   Li J, 2013, 2 INT C COMP SCI EL, P337
   Mehta MK., 2012, FAKE INSURANCE CLAIM
   Memon NA, 2008, INMIC: 2008 INTERNATIONAL MULTITOPIC CONFERENCE, P106, DOI 10.1109/INMIC.2008.4777717
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Nakhaie AA, 2011, CAN CON EL COMP EN, P121, DOI 10.1109/CCECE.2011.6030422
   NEMA, 2017, DICOM STAND, P3065
   Nyeem H, 2013, J DIGIT IMAGING, V26, P326, DOI 10.1007/s10278-012-9527-x
   Osborne D, 2004, P 3 INT C MOBILE UBI, P245, DOI [10.1145/1052380.1052414, DOI 10.1145/1052380.1052414]
   Parberry I, 1997, DISCRETE APPL MATH, V73, P251, DOI 10.1016/S0166-218X(96)00010-8
   Pradhan C, 2012, PROC TECH, V1, P897, DOI 10.1016/j.protcy.2012.10.109
   Raul RC., 2007, 17 INT C EL COMM COM, P32, DOI [10.1109/CONIELECOMP.2007.14, DOI 10.1109/CONIELECOMP.2007.14]
   SHANNON CE, 1949, P IRE, V37, P10, DOI 10.1109/JRPROC.1949.232969
   Solanki N, 2014, INT J COMPUT APPL, V96
   Tan CK, 2011, J DIGIT IMAGING, V24, P528, DOI 10.1007/s10278-010-9295-4
   Vasudeva K, 2016, METHODICAL REV ISSUE
   Wakatani A., 2002, Proceedings of the 35th Annual Hawaii International Conference on System Sciences, P2043, DOI 10.1109/HICSS.2002.994129
   Wee TC, 2020, 2020 6 INT C INT DIG
   Wong YL, 2021, INT C DIG TRANSF APP
   Zain JM, 2004, P ANN INT IEEE EMBS, V26, P3237
   Zhu SM, 2009, CHIN OPT LETT, V7, P580, DOI 10.3788/COL20090707.0580
NR 40
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 18
PY 2023
DI 10.1007/s11042-023-16459-7
EA AUG 2023
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P4RX5
UT WOS:001050545900003
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Dhanjal, AS
   Singh, W
AF Dhanjal, Amandeep Singh
   Singh, Williamjeet
TI A comprehensive survey on automatic speech recognition using neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Speech recognition; Dataset; Tools; Neural network; Deep learning
ID ARABIC SPEECH; SYSTEM; NOISE; HMM; ARCHITECTURES; SEGMENTATION; PRIMER
AB The continuous development in Automatic Speech Recognition has grown and demonstrated its enormous potential in Human Interaction Communication systems. It is quite a challenging task to achieve high accuracy due to several parameters such as different dialects, spontaneous speech, speaker's enrolment, computation power, dataset, and noisy environment that decrease the performance of the speech recognition system. It has motivated various researchers to make innovative contributions to the development of a robust speech recognition system. The study presents a systematic analysis of current state-of-the-art research work done in this field during 2015-2021. The prime focus of the study is to highlight the neural network-based speech recognition techniques, datasets, toolkits, and evaluation metrics utilized in the past seven years. It also synthesizes the evidence from past studies to provide empirical solutions for accuracy improvement. This study highlights the current status of speech recognition systems using neural networks and provides a brief knowledge to the new researchers.
C1 [Dhanjal, Amandeep Singh] Punjabi Univ, Dept Comp Sci, Rajpura Rd, Patiala 147001, Punjab, India.
   [Singh, Williamjeet] Punjabi Univ, Dept Comp Sci & Engn, Rajpura Rd, Patiala 147001, Punjab, India.
C3 Punjabi University; Punjabi University
RP Dhanjal, AS (corresponding author), Punjabi Univ, Dept Comp Sci, Rajpura Rd, Patiala 147001, Punjab, India.
EM aman.dhanjal13@live.com; williamjeet@gmail.com
OI Singh, Amandeep/0000-0002-7763-9174
FU Department of Science and Technology; Scheme for Young Scientists amp;
   Technologists (SYST); Government of India [SP/YO/382/2018(G)]
FX This is supported by the Department of Science and Technology, under the
   Scheme for Young Scientists & amp; Technologists (SYST), by the
   Government of India [SP/YO/382/2018(G)]
CR Abd El-Moneim S, 2020, MULTIMED TOOLS APPL, V79, P24013, DOI 10.1007/s11042-019-08293-7
   Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Abed S, 2019, IET CIRC DEVICE SYST, V13, P863, DOI 10.1049/iet-cds.2018.5225
   Addarrazi I, 2018, 2ND INTERNATIONAL CONFERENCE ON SMART DIGITAL ENVIRONMENT (ICSDE'18), P94, DOI 10.1145/3289100.3289116
   Alam M, 2020, NEUROCOMPUTING, V417, P302, DOI 10.1016/j.neucom.2020.07.053
   Ayo FE, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100311
   Azarang A, 2020, SPEECH COMMUN, V122, P1, DOI 10.1016/j.specom.2020.04.002
   Baevski A, 2020, INT CONF ACOUST SPEE, P7694, DOI [10.1109/ICASSP40776.2020.9054224, 10.1109/icassp40776.2020.9054224]
   Bang JU, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196936
   Becerra A, 2020, MULTIMED TOOLS APPL, V79, P19669, DOI 10.1007/s11042-020-08782-0
   Bhatt S, 2020, J INFORM OPTIM SCI, V41, P1333, DOI 10.1080/02522667.2020.1809091
   Bhatt S, 2020, J AMB INTEL HUM COMP, V11, P4213, DOI 10.1007/s12652-020-01703-x
   Bingol MC, 2020, ENG APPL ARTIF INTEL, V95, DOI 10.1016/j.engappai.2020.103903
   Bird JJ, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2020.113402
   Brunet RG, 2018, CIRC SYST SIGNAL PR, V37, P1177, DOI 10.1007/s00034-017-0598-2
   Cai M, 2016, SPEECH COMMUN, V77, P53, DOI 10.1016/j.specom.2015.12.003
   Caranica A, 2016, CONTROL ENG APPL INF, V18, P65
   Carlini N, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P1, DOI 10.1109/SPW.2018.00009
   Cheng GF, 2019, CHINESE J ELECTRON, V28, P107, DOI 10.1049/cje.2018.11.008
   Darabkh KA, 2018, COMPUT APPL ENG EDUC, V26, P285, DOI 10.1002/cae.21884
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   de Lima TA, 2020, COMPUT SPEECH LANG, V62, DOI 10.1016/j.csl.2019.101055
   Deepa P, 2022, MEASUREMENT SENSORS, V24, DOI [10.1016/j.measen.2022.100565, DOI 10.1016/J.MEASEN.2022.100565]
   Donkers T, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P152, DOI 10.1145/3109859.3109877
   El Hannani A, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00391-w
   Frihia H, 2017, INT J SPEECH TECHNOL, V20, P563, DOI 10.1007/s10772-017-9427-z
   Frihia H, 2016, LECT NOTES ARTIF INT, V9924, P383, DOI 10.1007/978-3-319-45510-5_44
   Garain A, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114416
   Goh YH, 2015, IET SIGNAL PROCESS, V9, P491, DOI 10.1049/iet-spr.2014.0109
   Guerid A, 2019, IET SIGNAL PROCESS, V13, P207, DOI 10.1049/iet-spr.2018.5131
   Han ZJ, 2019, 2019 IEEE 5TH INTL CONFERENCE ON BIG DATA SECURITY ON CLOUD (BIGDATASECURITY) / IEEE INTL CONFERENCE ON HIGH PERFORMANCE AND SMART COMPUTING (HPSC) / IEEE INTL CONFERENCE ON INTELLIGENT DATA AND SECURITY (IDS), P96, DOI 10.1109/BigDataSecurity-HPSC-IDS.2019.00027
   Hernandez F, 2018, LECT NOTES ARTIF INT, V11096, P198, DOI 10.1007/978-3-319-99579-3_21
   Hou JF, 2020, EURASIP J AUDIO SPEE, V2020, DOI 10.1186/s13636-020-0170-z
   Jahangir R, 2021, MULTIMED TOOLS APPL, V80, P23745, DOI 10.1007/s11042-020-09874-7
   Jermsittiparsert K, 2020, INT J SPEECH TECHNOL, V23, P799, DOI 10.1007/s10772-020-09690-2
   Jin YK, 2020, ADV MATER TECHNOL-US, V5, DOI 10.1002/admt.202000262
   Kadyan V, 2021, INT J SPEECH TECHNOL, V24, P517, DOI 10.1007/s10772-021-09814-2
   Kadyan V, 2018, IETE J RES, V64, P673, DOI 10.1080/03772063.2017.1369370
   Kalamani M, 2019, INT J SPEECH TECHNOL, V22, P47, DOI 10.1007/s10772-018-09580-8
   Kang J, 2018, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-018-0128-6
   Kang J, 2018, J SIGNAL PROCESS SYS, V90, P1013, DOI 10.1007/s11265-017-1292-0
   Kaur J, 2021, ARCH COMPUT METHOD E, V28, P1039, DOI 10.1007/s11831-020-09414-4
   Keshet J, 2018, INT J SPEECH-LANG PA, V20, P599, DOI 10.1080/17549507.2018.1510033
   Khan A., 2020, ARTIF INTELL REV, V53, P5455, DOI [10.1007/s10462-020-09825-6, DOI 10.1007/s10462-020-09825-6]
   Kim D, 2019, ETRI J, V41, P109, DOI 10.4218/etrij.2017-0087
   Kim S, 2021, SOFTW IMPACTS, V7, DOI 10.1016/j.simpa.2021.100054
   Kipyatkova IS, 2017, AUTOMAT REM CONTR+, V78, P858, DOI 10.1134/S0005117917050083
   Kitaoka N, 2021, EURASIP J AUDIO SPEE, V2021, DOI 10.1186/s13636-020-00193-1
   Kumar PS, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100288
   Kumar Y, 2021, SOFT COMPUT, V25, P1617, DOI 10.1007/s00500-020-05248-1
   Le Prell CG, 2017, HEARING RES, V349, P76, DOI 10.1016/j.heares.2016.10.004
   Lee S, 2017, MULTIMED TOOLS APPL, V76, P24917, DOI 10.1007/s11042-016-4122-7
   Lekshmi KR, 2021, INT J SPEECH TECHNOL, V24, P483, DOI 10.1007/s10772-021-09807-1
   Li RZ, 2020, IEEE-ACM T AUDIO SPE, V28, P646, DOI 10.1109/TASLP.2019.2959721
   Li ZR, 2021, NEUROCOMPUTING, V428, P259, DOI 10.1016/j.neucom.2020.11.025
   Liu D, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01933-z
   Magnuson JS, 2020, COGNITIVE SCI, V44, DOI 10.1111/cogs.12823
   Maheswari SU, 2021, ARTIF INTELL REV, V54, P2495, DOI 10.1007/s10462-020-09907-5
   Mamyrbayev O, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-12260-y
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Muhammad AN, 2021, NEURAL COMPUT APPL, V33, P2973, DOI 10.1007/s00521-020-05151-8
   Ogunfunmi T, 2019, CIRC SYST SIGNAL PR, V38, P3406, DOI 10.1007/s00034-019-01157-3
   Padmanabhan J, 2015, IETE TECH REV, V32, P240, DOI 10.1080/02564602.2015.1010611
   Palaz D, 2019, SPEECH COMMUN, V108, P15, DOI 10.1016/j.specom.2019.01.004
   Pan HY, 2020, NEUROCOMPUTING, V380, P201, DOI 10.1016/j.neucom.2019.11.021
   Passricha V, 2020, J AMB INTEL HUM COMP, V11, P675, DOI 10.1007/s12652-019-01325-y
   Passricha V, 2019, INT J SPEECH TECHNOL, V22, P601, DOI 10.1007/s10772-018-09584-4
   Patel H, 2018, J INFORM OPTIM SCI, V39, P31, DOI 10.1080/02522667.2017.1372908
   Pawar MD, 2021, MULTIMED TOOLS APPL, V80, P15563, DOI 10.1007/s11042-020-10329-2
   Pironkov G, 2020, COMPUT SPEECH LANG, V64, DOI 10.1016/j.csl.2020.101103
   Kumar PSP, 2020, CIRC SYST SIGNAL PR, V39, P391, DOI 10.1007/s00034-019-01189-9
   Qian YM, 2019, FRONT INFORM TECH EL, V20, P701, DOI 10.1631/FITEE.1800469
   Qian YM, 2019, SPEECH COMMUN, V114, P1, DOI 10.1016/j.specom.2019.08.006
   Qin CX, 2018, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-018-0141-9
   Radzikowski K, 2021, EURASIP J AUDIO SPEE, V2021, DOI 10.1186/s13636-021-00199-3
   Rahmani MH, 2018, DIGIT SIGNAL PROCESS, V82, P54, DOI 10.1016/j.dsp.2018.06.004
   Rajendran S, 2020, INT J SPEECH TECHNOL, V23, P265, DOI 10.1007/s10772-020-09687-x
   Ramteke PB, 2020, COMPUT SPEECH LANG, V62, DOI 10.1016/j.csl.2019.101057
   Ravanelli M, 2018, SPEECH COMMUN, V101, P34, DOI 10.1016/j.specom.2018.05.001
   Ravanelli M, 2018, IEEE T EM TOP COMP I, V2, P92, DOI 10.1109/TETCI.2017.2762739
   Sadhu S, 2021, ARXIV210308393, P1
   Saifan RR, 2018, COMPUT APPL ENG EDUC, V26, P1008, DOI 10.1002/cae.21952
   Sarma BD, 2018, IETE TECH REV, V35, P305, DOI 10.1080/02564602.2017.1293570
   Shahrebabaki AS, 2019, CIRC SYST SIGNAL PR, V38, P3501, DOI 10.1007/s00034-019-01130-0
   Sharma Mridusmita, 2017, CSI Transactions on ICT, V5, P209, DOI 10.1007/s40012-016-0145-5
   Sharma N., 2021, GLOBAL TRANSITIONS P, V2, P24, DOI [10.1016/j.gltp.2021.01.004, DOI 10.1016/J.GLTP.2021.01.004]
   Sharma VK, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100301
   Sharmin Riffat, 2020, Procedia Computer Science, V171, P1381, DOI 10.1016/j.procs.2020.04.148
   Shi YZ, 2013, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2013-22
   Shivakumar PG, 2020, COMPUT SPEECH LANG, V63, DOI 10.1016/j.csl.2020.101077
   Silber-Varod V, 2017, J COMPUT INFORM SYST, V57, P106, DOI 10.1080/08874417.2016.1183423
   Singh A, 2020, ARTIF INTELL REV, V53, P3673, DOI 10.1007/s10462-019-09775-8
   Soh KW, 2021, INT J AUDIOL, V60, P399, DOI 10.1080/14992027.2020.1826587
   Song ZJ, 2020, COMPUTING, V102, P663, DOI 10.1007/s00607-019-00753-0
   Syiem B, 2021, INT J SPEECH TECHNOL, V24, P419, DOI 10.1007/s10772-021-09811-5
   Tao Zhu, 2020, Journal of Shanghai Jiaotong University (Science), V25, P70, DOI 10.1007/s12204-019-2147-6
   Tong R, 2017, INT CONF ASIAN LANG, P36, DOI 10.1109/IALP.2017.8300540
   Tóth L, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0068-3
   Tripathi K, 2018, INT J SPEECH TECHNOL, V21, P489, DOI 10.1007/s10772-017-9483-4
   Tu YH, 2019, SPEECH COMMUN, V106, P31, DOI 10.1016/j.specom.2018.11.005
   Tu YH, 2018, J SIGNAL PROCESS SYS, V90, P963, DOI 10.1007/s11265-017-1295-x
   Ueda Y, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0278-y
   Veisi H, 2020, INT J SPEECH TECHNOL, V23, P893, DOI 10.1007/s10772-020-09768-x
   Wang DS, 2020, J EXP THEOR ARTIF IN, V32, P665, DOI 10.1080/0952813X.2019.1672795
   Wang J, 2020, PERS UBIQUIT COMPUT, V24, P237, DOI 10.1007/s00779-019-01293-2
   Wang QR, 2020, J CLOUD COMPUT-ADV S, V9, DOI 10.1186/s13677-020-00186-7
   Wang XH, 2021, J OTOL, V16, P109, DOI 10.1016/j.joto.2020.12.001
   Watanabe S, 2018, INTERSPEECH, P2207, DOI 10.21437/Interspeech.2018-1456
   Wellsandta S, 2020, PROCEDIA MANUF, V52, P4, DOI 10.1016/j.promfg.2020.11.002
   Ying WY, 2020, FRONT COMPUT SCI-CHI, V14, P378, DOI 10.1007/s11704-018-8030-z
   Yoon JW, 2022, IEEE W SP LANG TECH, P280, DOI 10.1109/SLT54892.2023.10022581
   Zhang XL, 2020, MULTIMED TOOLS APPL, V79, P24413, DOI 10.1007/s11042-020-09064-5
   Zhang YK, 2019, CHINESE J ELECTRON, V28, P604, DOI 10.1049/cje.2019.03.015
   Zhong J, 2019, MULTIMED TOOLS APPL, V78, P30749, DOI 10.1007/s11042-018-6590-4
   Zhong XM, 2018, INT J SPEECH TECHNOL, V21, P563, DOI 10.1007/s10772-018-9516-7
   Zhou P, 2015, IEEE-ACM T AUDIO SPE, V23, P631, DOI 10.1109/TASLP.2015.2392944
   Zia T, 2019, INT J SPEECH TECHNOL, V22, P21, DOI 10.1007/s10772-018-09573-7
   Zoughi T, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112840
   Zoughi T, 2019, IJST-T ELECTR ENG, V43, P635, DOI 10.1007/s40998-019-00177-8
NR 119
TC 1
Z9 1
U1 15
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 15
PY 2023
DI 10.1007/s11042-023-16438-y
EA AUG 2023
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P1DL3
UT WOS:001048111200001
DA 2024-07-18
ER

PT J
AU Uysal, G
   Ozturk, M
AF Uysal, Gokce
   Ozturk, Mahmut
TI Comparative analysis of different brain regions using machine learning
   for prediction of EMCI and LMCI stages of Alzheimer's disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's Disease; EMCI; LMCI; Machine Learning
ID MILD COGNITIVE IMPAIRMENT; PATTERN-CLASSIFICATION; PROBABLE AD;
   DIAGNOSIS; BIOMARKERS; ATROPHY; FMRI; MCI
AB For early diagnosis of dementia and slowing the progression of Alzheimer's disease (AD), detection of Mild Cognitive Impairment (MCI), which is the first stage of AD, in the early or late stages is crucial. The progression from Early Mild Cognitive Impairment (EMCI) stage to Late Mild Cognitive Impairment (LMCI) stage is not reversible and means that the cognitive condition of the patient gets worse significantly. Therefore, distinguishing the stages of MCI is very important for treatment possibilities. In this paper, it has been aimed to specify which brain regions are affected higher during the progression from EMCI to LMCI. Detection of EMCI stage gives an important opportunity to control the progression and results of the disease. Unfortunately, it is a very challenging classification problem because the changes in the values of biomarkers are generally low during the EMCI and LMCI stages. As a result of this study, we detect and present a combination of features which are the most effective ones for distinguishing the stages of MCI. Atrophy values obtained by magnetic resonance imaging (MRI) are considered as the powerful diagnostic biomarkers for the detection of AD. In this work, atrophy values of 90 EMCI, 38 LMCI and 14 MCI patients have been used. Volume information of 13 different brain regions for each patient were obtained from the ADNI dataset. By using the results of classification algorithms, the mostly affected brain regions on transition process from EMCI to LMCI are determined. Moreover, the classification results indicate the combination of the most effective features. This feature combination can be used as a pattern in the researches about the stages of MCI. Focusing on the brain regions which have more impact on the progression of AD can provide more sensitive analysis of the stages of AD and make possible to control and smooth the effects of it.
C1 [Uysal, Gokce] Istanbul Univ Cerrahpasa, Inst Grad Studies, Dept Biomed Engn, Istanbul, Turkiye.
   [Ozturk, Mahmut] Istanbul Univ Cerrahpasa, Engn Fac, Dept Elect & Elect Engn, Istanbul, Turkiye.
C3 Istanbul University - Cerrahpasa; Istanbul University - Cerrahpasa
RP Ozturk, M (corresponding author), Istanbul Univ Cerrahpasa, Engn Fac, Dept Elect & Elect Engn, Istanbul, Turkiye.
EM gokceuysal375@gmail.com; mahmutoz@iuc.edu.tr
RI Ozturk, Mahmut/D-2260-2019; Uysal, Gokce/AAW-1529-2020
OI Ozturk, Mahmut/0000-0003-2600-7051; Uysal, Gokce/0000-0003-1427-4320
CR Aidos H, 2014, IEEE IMAGE PROC, P21, DOI 10.1109/ICIP.2014.7025003
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Angelucci F, 2010, CURR ALZHEIMER RES, V7, P15, DOI 10.2174/156720510790274473
   [Anonymous], 2009, WORLD ALZHEIMER REPO
   Arimura H, 2008, ACAD RADIOL, V15, P274, DOI 10.1016/j.acra.2007.10.020
   Cabral C, 2013, IEEE ENG MED BIO, P2477, DOI 10.1109/EMBC.2013.6610042
   Davatzikos C, 2008, NEUROIMAGE, V41, P1220, DOI 10.1016/j.neuroimage.2008.03.050
   Davatzikos C, 2008, NEUROBIOL AGING, V29, P514, DOI 10.1016/j.neurobiolaging.2006.11.010
   Demirci O, 2008, NEUROIMAGE, V39, P1774, DOI 10.1016/j.neuroimage.2007.10.012
   Duchesne S, 2008, IEEE T MED IMAGING, V27, P509, DOI 10.1109/TMI.2007.908685
   Eskildsen SF, 2013, NEUROIMAGE, V65, P511, DOI 10.1016/j.neuroimage.2012.09.058
   Filippi M, 2011, J ALZHEIMERS DIS, V24, P455, DOI 10.3233/JAD-2011-101854
   Fox NC, 1996, LANCET, V348, P94, DOI 10.1016/S0140-6736(96)05228-2
   Gorji HT, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9090217
   Gray KR, 2012, NEUROIMAGE, V60, P221, DOI 10.1016/j.neuroimage.2011.12.071
   Hackeling G., 2014, MASTERING MACHINE LE
   Hardy J, 2006, J ALZHEIMERS DIS, V9, P151
   Hinrichs C, 2009, NEUROIMAGE, V48, P138, DOI 10.1016/j.neuroimage.2009.05.056
   Khan N, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/5360472
   Klöppel S, 2008, BRAIN, V131, P681, DOI 10.1093/brain/awm319
   Lantz B, 2013, PROBABILISTIC LEARNI, P99
   Liu AA, 2019, MULTIMED TOOLS APPL, V78, P677, DOI 10.1007/s11042-017-5532-x
   Liu XH, 2022, MAGN RESON MED, V88, P2694, DOI 10.1002/mrm.29400
   Liu Y, 2023, NEUROCOMPUTING, V517, P213, DOI 10.1016/j.neucom.2022.09.048
   López M, 2011, NEUROCOMPUTING, V74, P1260, DOI 10.1016/j.neucom.2010.06.025
   Mckee Ann C, 2015, Handb Clin Neurol, V127, P45, DOI 10.1016/B978-0-444-52892-6.00004-0
   Miller PE, 2019, J CARD FAIL, V25, P479, DOI 10.1016/j.cardfail.2019.01.018
   Nozadi SH, 2018, INT J BIOMED IMAGING, V2018, DOI 10.1155/2018/1247430
   Petrella JR, 2013, RADIOLOGY, V269, P671, DOI 10.1148/radiol.13122503
   Polat K, 2007, DIGIT SIGNAL PROCESS, V17, P694, DOI 10.1016/j.dsp.2006.10.008
   Qiu Y, 2014, ACTA PHARMACOL SIN, V35, P1111, DOI 10.1038/aps.2014.57
   Raschka S, 2016, PYTHON MACHINE LEARN, P3
   Raschka S, 2016, PYTHON MACHINE LEARN, P55
   Risacher SL, 2009, CURR ALZHEIMER RES, V6, P347, DOI 10.2174/156720509788929273
   Rodrigues F, 2014, IEEE ENG MED BIO, P1941, DOI 10.1109/EMBC.2014.6943992
   Román G, 2012, ARCH MED RES, V43, P671, DOI 10.1016/j.arcmed.2012.10.018
   Rowland DC, 2013, NEURON, V78, P953, DOI 10.1016/j.neuron.2013.05.039
   Shao Zhuang, 2022, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2022.3152990
   Shen L, 2003, P SOC PHOTO-OPT INS, V5032, P253, DOI 10.1117/12.480851
   Silverman D, 2009, PET HE EVALUAION ALZ, DOI [10.3174/ajnr.A1731, DOI 10.3174/AJNR.A1731]
   Smailagic N, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD010632.pub2
   Sontheimer H., 2015, Diseases ofthe Nervous System, P99, DOI DOI 10.1016/B978-0-12-800244-5.00004-5
   Soriano-Mas C, 2007, NEUROIMAGE, V35, P1028, DOI 10.1016/j.neuroimage.2007.01.011
   Stoeckel J, 2005, Fifth IEEE International Conference on Data Mining, Proceedings, P410, DOI 10.1109/ICDM.2005.141
   Uysal G, 2019, 2019 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO), P282, DOI 10.1109/tiptekno.2019.8895135
   Uysal G, 2020, J NEUROSCI METH, V337, DOI 10.1016/j.jneumeth.2020.108669
   Vemuri P, 2008, NEUROIMAGE, V39, P1186, DOI 10.1016/j.neuroimage.2007.09.073
   Weiner Michael W, 2015, Alzheimers Dement, V11, pe1, DOI 10.1016/j.jalz.2014.11.001
   Weiner Michael W, 2012, Alzheimers Dement, V8, pS1, DOI [10.1016/j.jalz.2013.05.1769, 10.1016/j.jalz.2011.09.172]
   Westman E, 2011, NEUROIMAGE, V58, P818, DOI 10.1016/j.neuroimage.2011.06.065
   Woo CW, 2017, NAT NEUROSCI, V20, P365, DOI 10.1038/nn.4478
   Wu LY, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047905
   Zhang DQ, 2011, NEUROIMAGE, V55, P856, DOI 10.1016/j.neuroimage.2011.01.008
   Zhang HY, 2009, BEHAV BRAIN RES, V197, P103, DOI 10.1016/j.bbr.2008.08.012
   Zhao A, 2019, PROC CVPR IEEE, P8535, DOI 10.1109/CVPR.2019.00874
   Zhou Z.-H., 2012, ENSEMBLE METHODS FDN, DOI DOI 10.1201/B12207
NR 56
TC 0
Z9 0
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21455
EP 21470
DI 10.1007/s11042-023-16413-7
EA AUG 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042601200014
DA 2024-07-18
ER

PT J
AU Balaha, HM
   Hassan, AE
   El-Gendy, EM
   ZainEldin, H
   Saafan, MM
AF Balaha, Hossam Magdy
   Hassan, Asmaa El-Sayed
   El-Gendy, Eman M. M.
   ZainEldin, Hanaa
   Saafan, Mahmoud M. M.
TI An aseptic approach towards skin lesion localization and grading using
   deep learning and harris hawks optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural network (CNN); Deep learning (DL); Harris hawks
   optimization (HHO); Skin lesion; Melanoma skin cancer; Meta-heuristic
   optimization; Transfer learning
ID ALGORITHM
AB Skin cancer is the most common form of cancer. It is predicted that the total number of cases of cancer will double in the next fifty years. It is an expensive procedure to discover skin cancer types in the early stages. Additionally, the survival rate reduces as cancer progresses. The current study proposes an aseptic approach toward skin lesion detection, classification, and segmentation using deep learning and Harris Hawks Optimization Algorithm (HHO). The current study utilizes the manual and automatic segmentation approaches. The manual segmentation is used when the dataset has no masks to use while the automatic segmentation approach is used, using U-Net models, to build an adaptive segmentation model. Additionally, the meta-heuristic HHO optimizer is utilized to achieve the optimization of the hyperparameters of 5 pre-trained CNN models, namely VGG16, VGG19, DenseNet169, DenseNet201, and MobileNet. Two datasets are used, namely "Melanoma Skin Cancer Dataset of 10000 Images" and "Skin Cancer ISIC" dataset from two publicly available sources for variety purpose. For the segmentation, the best-reported scores are 0.15908, 91.95%, 0.08864, 0.04313, 0.02072, 0.20767 in terms of loss, accuracy, Mean Absolute Error, Mean Squared Error, Mean Squared Logarithmic Error, and Root Mean Squared Error, respectively. For the "Melanoma Skin Cancer Dataset of 10000 Images" dataset, from the applied experiments, the best reported scores are 97.08%, 98.50%, 95.38%, 98.65%, 96.92% in terms of overall accuracy, precision, sensitivity, specificity, and F1-score, respectively by the DenseNet169 pre-trained model. For the "Skin Cancer ISIC" dataset, the best reported scores are 96.06%, 83.05%, 81.05%, 97.93%, 82.03% in terms of overall accuracy, precision, sensitivity, specificity, and F1-score, respectively by the MobileNet pre-trained model. After computing the results, the suggested approach is compared with 9 related studies. The results of comparison proves the efficiency of the proposed framework.
C1 [Balaha, Hossam Magdy; El-Gendy, Eman M. M.; ZainEldin, Hanaa; Saafan, Mahmoud M. M.] Mansoura Univ, Fac Engn, Comp & Control Syst Engn Dept, Mansoura 35511, Egypt.
   [Hassan, Asmaa El-Sayed] Mansoura Univ, Fac Engn, Math & Engn Phys Dept, Mansoura 35511, Egypt.
C3 Egyptian Knowledge Bank (EKB); Mansoura University; Egyptian Knowledge
   Bank (EKB); Mansoura University
RP Saafan, MM (corresponding author), Mansoura Univ, Fac Engn, Comp & Control Syst Engn Dept, Mansoura 35511, Egypt.
EM saafan2007@mans.edu.eg
RI Saafan, Mahmoud M./O-9976-2018; Balaha, Hossam Magdy/Z-1960-2018
OI Saafan, Mahmoud M./0000-0002-9279-1537; Balaha, Hossam
   Magdy/0000-0002-0686-4411
FU Science, Technology amp; Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX & nbsp;Open access funding provided by The Science, Technology &
   Innovation Funding Authority (STDF) in cooperation with The Egyptian
   Knowledge Bank (EKB).
CR Abdulazeem Y, 2021, IEEE ACCESS, V9, P82058, DOI 10.1109/ACCESS.2021.3086668
   Adegun A, 2021, ARTIF INTELL REV, V54, P811, DOI 10.1007/s10462-020-09865-y
   Adegun A, 2019, LECT NOTES ARTIF INT, V11683, P414, DOI 10.1007/978-3-030-28377-3_34
   Agrahari P, 2022, SKIN CANC DETECTION, P179
   Anand V, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030867
   [Anonymous], 2020, Skin cancer facts statistics: What you need to know
   [Anonymous], FWHO ULTRAVIOLET RAD
   [Anonymous], SKIN CANC FDN MELANO
   Badr AA, 2023, ARTIF INTELL REV, V56, P10679, DOI 10.1007/s10462-023-10431-5
   Baghdadi NA, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22114250
   Baghdadi NA, 2022, COMPUT BIOL MED, V144, DOI 10.1016/j.compbiomed.2022.105383
   Bahgat WM, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.555
   Balaha Hossam Magdy, 2023, Journal of Ambient Intelligence and Humanized Computing, P7897, DOI 10.1007/s12652-023-04600-1
   Balaha HM, 2022, NEURAL COMPUT APPL, V34, P8671, DOI 10.1007/s00521-021-06851-5
   Balaha HM, 2022, ARTIF INTELL REV, V55, P5063, DOI 10.1007/s10462-021-10127-8
   Balaha HM, 2021, ARTIF INTELL MED, V119, DOI 10.1016/j.artmed.2021.102156
   Balaha HM, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115805
   Balaha HM, 2021, MULTIMED TOOLS APPL, V80, P32473, DOI 10.1007/s11042-021-11185-4
   Balaha HM, 2021, IEEE ACCESS, V9, P32368, DOI 10.1109/ACCESS.2021.3060940
   Balaha HM, 2021, NEURAL COMPUT APPL, V33, P6325, DOI 10.1007/s00521-020-05397-2
   Balaha HM, 2021, NEURAL COMPUT APPL, V33, P3011, DOI 10.1007/s00521-020-05137-6
   Binaghi Elisabetta, 2014, Proceedings of the International Conference on Neural Computation Theory and Applications NCTA 2014, P152
   Board PATE, 2021, MEL TREATM PDQ PDQ C
   Cancer, NET MEL SYMPT SIGNS
   Cao XM, 2021, COMPUT METH PROG BIO, V207, DOI 10.1016/j.cmpb.2021.106174
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Segundo EHD, 2019, THERM SCI ENG PROG, V14, DOI 10.1016/j.tsep.2019.100431
   Elansary I, 2022, EFFICIENT CLASSIFICA, P15
   Faramarzi A, 2020, EXPERT SYST APPL, V152, DOI 10.1016/j.eswa.2020.113377
   Gaonkar R, 2020, CLIN EPIDEMIOL GLOB, V8, P501, DOI 10.1016/j.cegh.2019.11.003
   Garbe C, 2010, EUR J CANCER, V46, P270, DOI 10.1016/j.ejca.2009.10.032
   Gaziog lu BSA, 2021, BIOMED SIGNAL PROCES, V67
   He XZ, 2022, MED IMAGE ANAL, V77, DOI 10.1016/j.media.2022.102357
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Hosny KM, 2022, J AMB INTEL HUM COMP, V13, P973, DOI 10.1007/s12652-021-03675-y
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Husham S., 2020, J. Inf. Technol. Manag, V12, P48, DOI 10.22059/JITM.2020.78889
   Ilkin S, 2021, ENG SCI TECHNOL, V24, P1059, DOI 10.1016/j.jestch.2021.02.002
   Javid MH, 2022, MELANOMA SKIN CANC D
   Kassani SH, 2019, TISSUE CELL, V58, P76, DOI 10.1016/j.tice.2019.04.009
   Katanskiy A, 2019, SKIN CANC ISIC
   Kaur R, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22031134
   Klein C.E., 2018, ESANN 2018 P EUROPEA, P679
   Kumar NMS, 2021, MULTIMED TOOLS APPL, V80, P18677, DOI 10.1007/s11042-021-10572-1
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Nersisson R, 2021, ARAB J SCI ENG, V46, P9797, DOI 10.1007/s13369-021-05571-1
   Patil R, 2022, J KING SAUD UNIV-COM, V34, P3285, DOI 10.1016/j.jksuci.2020.09.002
   Pierezan J, 2021, COMPUT STRUCT, V242, DOI 10.1016/j.compstruc.2020.106353
   Popescu D, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020496
   Rajinikanth Venkatesan, 2022, 2022 Third International Conference on Intelligent Computing Instrumentation and Control Technologies (ICICICT), P982, DOI 10.1109/ICICICT54557.2022.9917848
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saafan MM, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114901
   Sayed GI, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104712
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shorfuzzaman M, 2022, MULTIMEDIA SYST, V28, P1309, DOI 10.1007/s00530-021-00787-5
   Sikka K, 2009, MAGN RESON IMAGING, V27, P994, DOI 10.1016/j.mri.2009.01.024
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soerjomataram I, 2021, NAT REV CLIN ONCOL, V18, P663, DOI 10.1038/s41571-021-00514-z
   Srividhya V., 2020, Procedia Computer Science, V171, P1726, DOI 10.1016/j.procs.2020.04.185
   Thomas L, 1998, DERMATOLOGY, V197, P11, DOI 10.1159/000017969
   Thomas SM, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101915
   Vani R, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03242-5
   Wu HS, 2022, MED IMAGE ANAL, V76, DOI 10.1016/j.media.2021.102327
NR 64
TC 5
Z9 5
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19787
EP 19815
DI 10.1007/s11042-023-16201-3
EA JUL 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037377100002
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Ji, HC
   Li, SQ
   Chen, J
   Zhou, SX
AF Ji, Hechao
   Li, Shiqi
   Chen, Jie
   Zhou, Shuxiang
TI On-site human-robot collaboration for lunar exploration based on shared
   mixed reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-robot collaboration; Lunar exploration; Mixed reality; Terrain
   perception; Spatial anchor; Navigation
AB On-site human-robot collaboration is one form of lunar exploration, where astronauts work side-by-side with rovers to accomplish tasks. Mixed reality (MR) is being tried in astronaut-rover teams. While research is primarily focused on MR technology to facilitate natural human-robot interaction, it often neglects the importance of incorporating transparency into decision-making processes. Our proposal is to utilize shared MR and optimized perception-localization techniques for human-robot collaboration in lunar exploration. The establishment of consensus between astronauts and rovers during decision-making processes can be facilitated through shared spatial context and interactive holographic content. This technology combines the strengths of astronauts and rovers for decision-making during rover navigation missions. It avoids blindly relying on rovers or only using manual manipulation by astronauts. In order to improve terrain perception and facilitate visualization for astronaut-rover teams during lunar navigation tasks, we develop a risk-aware lunar terrain parsing method that utilizes multiscale eigenvalue-based features and an optimized Random Forest classifier. Our method outperforms others with an impressive accuracy of 94.2%. Our co-location MR system incorporates a marker & instance-based spatial anchor method, customized specifically for the unique topography of the lunar terrain and optimized for resource conservation. Our experiments on lunar navigation with three terrain conditions and four configurations confirm that that shared MR could improve task performance and reduce workload. The proposed shared MR paradigm and related technologies can provide a reference in future lunar exploration missions.
C1 [Ji, Hechao; Li, Shiqi; Chen, Jie; Zhou, Shuxiang] Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, Luoyu Rd 1037, Wuhan 430070, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Li, SQ (corresponding author), Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, Luoyu Rd 1037, Wuhan 430070, Hubei, Peoples R China.
EM jihechao@hust.edu.cn; sqli@hust.edu.cn; chenjiecj1210@163.com;
   zsx70724@163.com
CR Abercrombie S.P., 2017, AGU FALL M ABSTRACTS, P11
   Abiodun OI, 2019, IEEE ACCESS, V7, P158820, DOI 10.1109/ACCESS.2019.2945545
   Ajoudani A, 2018, AUTON ROBOT, V42, P957, DOI 10.1007/s10514-017-9677-2
   Al-Sabbag ZA, 2022, ADV ENG INFORM, V53, DOI 10.1016/j.aei.2022.101709
   Allan M, 2019, AEROSP CONF PROC
   Anandapadmanaban E., 2018, 48 INT C ENV SYST
   Apple, 2022, ARKIT ARWORLDMAP
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Atik ME, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10030187
   Belobrajdic B, 2021, NPJ MICROGRAVITY, V7, DOI 10.1038/s41526-021-00144-w
   Biau G, 2016, TEST-SPAIN, V25, P197, DOI 10.1007/s11749-016-0481-7
   Boyd A., 2016, 14 INT C SPAC OP, P2306
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bulatov D, 2021, APPL OPTICS, V60, pF6, DOI 10.1364/AO.422973
   Burns JO, 2019, ACTA ASTRONAUT, V154, P195, DOI 10.1016/j.actaastro.2018.04.031
   Campos Carlos, 2021, IEEE Transactions on Robotics, V37, P1874, DOI 10.1109/TRO.2021.3075644
   Cao A, 2009, BEHAV RES METHODS, V41, P113, DOI 10.3758/BRM.41.1.113
   Cardenas IS, 2021, ACMIEEE INT CONF HUM, P463, DOI 10.1145/3434074.3447214
   Cervantes J, 2020, NEUROCOMPUTING, V408, P189, DOI 10.1016/j.neucom.2019.10.118
   Chghaf M, 2022, J INTELL ROBOT SYST, V105, DOI 10.1007/s10846-022-01582-8
   Christian JA, 2021, J ASTRONAUT SCI, V68, P1056, DOI 10.1007/s40295-021-00287-8
   Connors MM., 1994, COMMUNICATION
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Delmerico J, 2022, IEEE ROBOT AUTOM MAG, V29, P45, DOI 10.1109/MRA.2021.3138384
   Douillard B, 2011, IEEE INT CONF ROBOT
   Drury J.L., 2004, CHI 04 EXTENDED ABST, P1540, DOI DOI 10.1145/985921.986116
   Dubé R, 2020, INT J ROBOT RES, V39, P339, DOI 10.1177/0278364919863090
   EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552
   Feigl T, 2020, PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 1: GRAPP, P307, DOI 10.5220/0008989903070318
   Fong Terrence., 2013, Reviews of Human Factors and Ergonomics, V9, P6, DOI DOI 10.1177/1557234X13510679
   Frank JA, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00020
   Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Gelbart MA, 2014, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P250
   Google, 2022, ARCORE CLOUD ANCH
   Gou JP, 2019, EXPERT SYST APPL, V115, P356, DOI 10.1016/j.eswa.2018.08.021
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Hambuchen K., 2021, Curr. Robot. Rep., V2, P265, DOI [10.1007/$43154-021-00062-5, DOI 10.1007/$43154-021-00062-5]
   Holste B, 2021, ROUTL INT STUD MONEY, P83
   Hu L, 2020, MULTIMED TOOLS APPL, V79, P839, DOI 10.1007/s11042-019-08189-6
   Huang J, 2016, INT C PATT RECOG, P2670, DOI 10.1109/ICPR.2016.7900038
   Huang XL, 2009, ICICTA: 2009 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTATION TECHNOLOGY AND AUTOMATION, VOL II, PROCEEDINGS, P53, DOI 10.1109/ICICTA.2009.250
   Imhof B., 2017, 68 INT ASTR C IAC AD, P25
   Jeff D., 2022, AZURE SPATIAL ANCHOR
   Jianping Luo, 2020, Advances in Usability, User Experience, Wearable and Assistive Technology. Proceedings of the AHFE 2020 Virtual Conferences on Usability and User Experience, Human Factors and Assistive Technology, Human Factors and Wearable Technologies, and Virtual Environments and Game Design. Advances in Intelligent Systems and Computing (AISC 1217), P334, DOI 10.1007/978-3-030-51828-8_44
   Labbé M, 2019, J FIELD ROBOT, V36, P416, DOI 10.1002/rob.21831
   Lawin FJ, 2017, LECT NOTES COMPUT SC, V10424, P95, DOI 10.1007/978-3-319-64689-3_8
   Lee D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11177877
   Lee P., 2020, 2020 INT C ENV SYST
   Li SS, 2020, IEEE ACCESS, V8, P47468, DOI 10.1109/ACCESS.2020.2972034
   McGill M., 2020, 26 ACM S VIRT REAL S, DOI [10.1145/3385956.3418968, DOI 10.1145/3385956.3418968]
   McHenry N., 2022, 2022 IEEE AEROSPACE, P1
   McHenry N, 2020, AEROSP CONF PROC, DOI 10.1109/aero47225.2020.9172268
   Microsoft, 2022, AZ SPAT ANCH OV
   Microsoft, 2022, INTR HOLOLENS 2 DEV
   Miller L, 2021, IEEE INT CONF HIGH, DOI 10.1109/HPSR52026.2021.9481820
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Onime C, 2021, INT J INF LEARN TECH, V38, P161, DOI 10.1108/IJILT-06-2020-0108
   Ono M., 2020, 2020 IEEE AER C IEEE, P1
   Ono Masahiro., 2015, 2015 IEEE aerospace conference, P1, DOI [DOI 10.1109/AERO.2015.7119022, 10.1109/AERO.2015.7119022]
   Pelanis E, 2020, MINIM INVASIV THER, V29, P154, DOI 10.1080/13645706.2019.1616558
   Qi CR, 2017, ADV NEUR IN, V30
   Qiao DL, 2022, J INTELL ROBOT SYST, V104, DOI 10.1007/s10846-021-01543-7
   Rozenberszki D, 2021, PROCEEDINGS OF THE AUGMENTED HUMANS CONFERENCE 2021, AHS 2021, P274, DOI 10.1145/3458709.3458996
   Rydvanskiy R, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10020082
   Snoek J., 2012, Advances in Neural Information Processing Systems, V25, DOI DOI 10.48550/ARXIV.1206.2944
   Song Yan-Yan, 2015, Shanghai Arch Psychiatry, V27, P130, DOI 10.11919/j.issn.1002-0829.215044
   Suzuki R., 2022, CHI C HUM FACT COMP, P1, DOI 10.1145/1122445.1122456
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Uland W., 2017, POLAR OPTICAL LUNAR
   Wang BX, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14092110
   Wang J, 2017, J GEOGR SCI, V27, P1413, DOI 10.1007/s11442-017-1443-z
   Weinmann M., 2020, ISPRS ANN PHOTOGRAMM, V5
   Weinmann M, 2015, ISPRS J PHOTOGRAMM, V105, P286, DOI 10.1016/j.isprsjprs.2015.01.016
   Willis KS, 2009, COMPUT ENVIRON URBAN, V33, P100, DOI 10.1016/j.compenvurbsys.2009.01.004
   Winter M., 2017, 14 S ADV SPAC TECHN, P20
   Wong CB, 2017, NASA ESA CONF, P237, DOI 10.1109/AHS.2017.8046384
   Wonsick M, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.550644
   Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637
   Zhang HJ, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P2501, DOI 10.1109/ROBIO.2015.7419715
   Zhao J., 2018, SPIE, V10696, P143
NR 81
TC 1
Z9 1
U1 6
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18235
EP 18260
DI 10.1007/s11042-023-16178-z
EA JUL 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001033457500006
DA 2024-07-18
ER

PT J
AU Imani, M
AF Imani, Maryam
TI An iterative PolSAR image classification method with utilizing
   scattering and contextual information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iterative classifier; Scattering and contextual features; Polarimetric;
   SAR
ID CONVOLUTIONAL NEURAL-NETWORK; SAR; DECOMPOSITION; MATRIX
AB Polarimetric synthetic aperture radar (PolSAR) images with multiple polarimetric channels have high discrimination ability. So, they are appropriate data for classification applications. The suitable use of both scattering (polarimetric) and spatial features in a PolSAR image is important to provide an accurate classification map. Many basic classifiers such as support vector machine (SVM) only works based on feature vectors and ignore the spatial features. To convert a basic classifier such as SVM to a powerful classifier for PolSAR image classification, the polarimetric and spatial base iterative (PSI) classifier is proposed in this work. The PSI method tries to refine the labels of an initial classification map obtained by a simple classifier (SVM in this work). To this end, three terms of similarity based on spatial, polarimetric and class-specific features are computed in neighborhood regions. According to the computed similarity values, the new labels are generated and the scattering features of the PolSAR images are refined. This simple process is repeated several times to a pre-determined number of iterations. The result is a clean and accurate classification map. The experiments are done on two AIRSAR PolSAR images. Compared to the base classifier (SVM), the proposed method provides about 10% and 6% increase in classification accuracy of Flevoland and Sanfrancisco datasets with 19 and 50 iterations, respectively. Moreover, the proposed PSI method shows desirable performance compared to several complex and powerful classification methods.
C1 [Imani, Maryam] Tarbiat Modares Univ, Fac Elect & Comp Engn, Tehran, Iran.
C3 Tarbiat Modares University
RP Imani, M (corresponding author), Tarbiat Modares Univ, Fac Elect & Comp Engn, Tehran, Iran.
EM maryam.imani@modares.ac.ir
RI Imani, Maryam/AAA-8782-2022
OI Imani, Maryam/0000-0002-1924-9776
CR Chen B, 2015, IEEE GEOSCI REMOTE S, V12, P731, DOI 10.1109/LGRS.2014.2360421
   Chen J, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103128
   Chen YQ, 2021, IEEE ACCESS, V9, P70650, DOI 10.1109/ACCESS.2021.3078232
   Chen YQ, 2019, IEEE T GEOSCI REMOTE, V57, P2407, DOI 10.1109/TGRS.2018.2873302
   Garg R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-94422-y
   Ge SJ, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON FRONTIERS OF SIGNAL PROCESSING (ICFSP), P114, DOI 10.1109/ICFSP.2017.8097153
   Golpardaz M, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114370
   Guan HY, 2022, INT J APPL EARTH OBS, V107, DOI 10.1016/j.jag.2022.102677
   Guo J, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3045431
   Han KY, 2018, IEEE J-STARS, V11, P2847, DOI 10.1109/JSTARS.2018.2842125
   Ho BA, 2018, IEEE GEOSCI REMOTE S, V15, P1239, DOI 10.1109/LGRS.2018.2833492
   Hua WQ, 2020, IEEE J-STARS, V13, P4895, DOI 10.1109/JSTARS.2020.3018161
   Imani M, 2013, 2 INT C SENS MOD PHO, P209
   Imani M, 2022, EGYPT J REMOTE SENS, V25, P55, DOI 10.1016/j.ejrs.2021.12.007
   Imani M, 2021, INT J REMOTE SENS, V42, P4946, DOI 10.1080/01431161.2021.1906984
   Imani M, 2018, J APPL REMOTE SENS, V12, DOI 10.1117/1.JRS.12.016024
   Jamali A, 2023, IEEE GEOSCI REMOTE S, V20, DOI 10.1109/LGRS.2023.3239263
   Jamali A, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3185118
   Li Chen, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2137, DOI 10.1109/ICIP.2011.6116032
   Li LL, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107110
   Liu B, 2014, IEEE GEOSCI REMOTE S, V11, P2140, DOI 10.1109/LGRS.2014.2321629
   Luo Junjie, 2022, 2022 3rd China International SAR Symposium (CISS), P1, DOI 10.1109/CISS57580.2022.9971318
   Mahrooghy M, 2015, IEEE J-STARS, V8, P3791, DOI 10.1109/JSTARS.2015.2427337
   Mirzapour F, 2013, IRAN CONF ELECTR ENG
   Molaei S, 2020, APPL SOFT COMPUT, V88, DOI 10.1016/j.asoc.2019.105960
   Moustafa Housam, 2022, 2022 10th International Symposium on Digital Forensics and Security (ISDFS), P1, DOI 10.1109/ISDFS55398.2022.9800793
   Moya L, 2019, ISPRS J PHOTOGRAMM, V149, P14, DOI 10.1016/j.isprsjprs.2019.01.008
   Raj JA, 2022, MULTIMED TOOLS APPL, V81, P16921, DOI 10.1007/s11042-022-12243-1
   Ruggeri S, 2021, EGYPT J REMOTE SENS, V24, P1061, DOI 10.1016/j.ejrs.2021.10.009
   Samat A, 2021, IEEE J-STARS, V14, P9334, DOI 10.1109/JSTARS.2021.3110994
   Shang RH, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105542
   Song WY, 2021, IEEE GEOSCI REMOTE S, V18, P1406, DOI 10.1109/LGRS.2020.3001065
   Lê TT, 2015, ISPRS J PHOTOGRAMM, V107, P64, DOI 10.1016/j.isprsjprs.2015.02.008
   Wang JL, 2022, ISPRS J PHOTOGRAMM, V186, P246, DOI 10.1016/j.isprsjprs.2022.02.003
   Wang Y, 2019, DIGIT SIGNAL PROCESS, V95, DOI 10.1016/j.dsp.2019.102583
   Wang YM, 2022, IEEE GEOSCI REMOTE S, V19, DOI [10.1109/LGRS.2022.3214633, 10.1109/LGRS.2020.3047635]
   Xie W, 2022, INT GEOSCI REMOTE SE, P1205, DOI 10.1109/IGARSS46834.2022.9884179
   Xie W, 2018, IEEE ACCESS, V6, P40041, DOI 10.1109/ACCESS.2018.2852768
   Zhang L, 2016, IEEE GEOSCI REMOTE S, V13, P1359, DOI 10.1109/LGRS.2016.2586109
   Zhang ZJ, 2021, MULTIMED TOOLS APPL, V80, P5701, DOI 10.1007/s11042-020-09920-4
   Zhang ZM, 2017, IEEE T GEOSCI REMOTE, V55, P7177, DOI 10.1109/TGRS.2017.2743222
   Zhao FX, 2020, IEEE T VEH TECHNOL, V69, P101, DOI 10.1109/TVT.2019.2952605
   Zhu FY, 2016, INT GEOSCI REMOTE SE, P4730, DOI 10.1109/IGARSS.2016.7730234
   Zhu LK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093006
   Zou B, 2017, IEEE T GEOSCI REMOTE, V55, P3396, DOI 10.1109/TGRS.2017.2670261
NR 45
TC 1
Z9 1
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16605
EP 16621
DI 10.1007/s11042-023-16205-z
EA JUL 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001029126000015
DA 2024-07-18
ER

PT J
AU Tiwari, A
   Srivastava, VK
AF Tiwari, Anurag
   Srivastava, Vinay Kumar
TI Image watermarking techniques based on Schur decomposition and various
   image invariant moments: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Image watermarking; Schur decomposition; Image moments; Telemedicine;
   Affine invariant; Medical image watermarking
ID DWT-SVD; HADAMARD-TRANSFORM; ROBUST; SCHEME; DOMAIN; ALGORITHM; SCALE;
   AUTHENTICATION; RECOGNITION; ROTATION
AB Digital image watermarking provides security, copyright protection, and authenticity to multimedia content by embedding digital content like text, image, and video. In the modern digital age, watermarking of digital images is an essential aspect of providing authenticity to digital content. Digital image watermarking is also used for the authenticity of the medical image in telemedicine applications. In these applications, digital image watermarking provides security to various medical images like Computerized tomography (CT) scans, Magnetic resonance imaging (MRI) images, and X-radiation (X-ray) images. In the past decades, many intellectuals have been working in the field of image watermarking to provide various characteristics features to watermarking like sufficient embedding capacity, strong robustness, and better imperceptibility. This paper covers watermarking techniques based on Schur decomposition and various types of moments like Zernike moment, Fourier harmonic moments, polar harmonic moments, etc. A survey on watermarking techniques suitable for telemedicine applications which include various medical images like CT-scan, MRI image, and X-ray images, is also presented. Various performance measures proposed by different researchers are also discussed, and the suitability of these measures for watermarking schemes is analysed under various attacks. In this paper, novel classification of watermarking schemes, recent essential requirements for different categories of image watermarking applications are covered. A tabular comparison of various watermarking schemes based on different families of moments are presented and also a comparative analysis of outcomes of different categories of moment based watermarking schemes is included. Various challenges and opportunities are also included to make this review more comprehensive.
C1 [Tiwari, Anurag; Srivastava, Vinay Kumar] Motilal Nehru Natl Inst Technol, Elect & Commun Engn Dept, Prayagraj 211004, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Tiwari, A (corresponding author), Motilal Nehru Natl Inst Technol, Elect & Commun Engn Dept, Prayagraj 211004, Uttar Pradesh, India.
EM anuragt@mnnit.ac.in; vinay@mnnit.ac.in
RI Srivastava, Vinay Kumar/AAL-2501-2021; Tiwari, Anurag/IUM-5006-2023
OI Srivastava, Vinay Kumar/0000-0002-7993-0993; Tiwari,
   Anurag/0000-0001-6873-6450
CR Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   Aparna JR, 2015, PROCEDIA COMPUT SCI, V46, P1684, DOI 10.1016/j.procs.2015.02.109
   Awasthi D, 2023, J ELECTRON IMAGING, V32, DOI 10.1117/1.JEI.32.4.042107
   Awasthi D, 2023, CIRC SYST SIGNAL PR, V42, P4953, DOI 10.1007/s00034-023-02344-z
   Awasthi D, 2023, MULTIMED TOOLS APPL, V82, P35685, DOI 10.1007/s11042-023-14723-4
   Awasthi D, 2023, MULTIMED TOOLS APPL, V82, P16555, DOI 10.1007/s11042-022-14002-8
   Awasthi D, 2022, MULTIMED TOOLS APPL, V81, P25075, DOI 10.1007/s11042-022-12456-4
   BELKASIM SO, 1991, PATTERN RECOGN, V24, P1117, DOI 10.1016/0031-3203(91)90140-Z
   Cedillo-Hernández M, 2014, SIGNAL IMAGE VIDEO P, V8, P49, DOI 10.1007/s11760-013-0459-9
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Ernawan F, 2020, VISUAL COMPUT, V36, P19, DOI 10.1007/s00371-018-1567-x
   Favorskaya M, 2018, IOP CONF SER-MAT SCI, V450, DOI 10.1088/1757-899X/450/5/052003
   Gao GY, 2015, MULTIMED TOOLS APPL, V74, P841, DOI 10.1007/s11042-013-1701-8
   Golub G.H., 2013, Matrix Computations, DOI DOI 10.56021/9781421407944
   Hamidi M, 2018, MULTIMED TOOLS APPL, V77, P27181, DOI 10.1007/s11042-018-5913-9
   Heidari S, 2016, INT J THEOR PHYS, V55, P4205, DOI 10.1007/s10773-016-3046-3
   Hosny KM, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3325193
   Hosny KM, 2018, MULTIMED TOOLS APPL, V77, P24727, DOI 10.1007/s11042-018-5670-9
   Hsu CS, 2020, MULTIMED TOOLS APPL, V79, P11297, DOI 10.1007/s11042-019-08367-6
   Hsu LY, 2015, J VIS COMMUN IMAGE R, V32, P130, DOI 10.1016/j.jvcir.2015.07.017
   Ismail Ismail A., 2010, Journal of Computer Sciences, V6, P52, DOI 10.3844/jcssp.2010.52.59
   Khare P, 2021, MULTIDIM SYST SIGN P, V32, P131, DOI 10.1007/s11045-020-00732-1
   Khare P, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3918
   Kishore PVV, 2014, 2014 FIRST INTERNATIONAL CONFERENCE ON NETWORKS & SOFT COMPUTING (ICNSC), P258, DOI 10.1109/CNSC.2014.6906662
   Ko HJ, 2020, INFORM SCIENCES, V517, P128, DOI 10.1016/j.ins.2019.11.005
   Lakrissi Y, 2018, MULTIMED TOOLS APPL, V77, P13531, DOI 10.1007/s11042-017-4974-5
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu DC, 2020, MULTIMED TOOLS APPL, V79, P7491, DOI 10.1007/s11042-019-08423-1
   Liu P, 2010, INT C INF ENG COMP S, P1
   Liu XL, 2017, IEEE T SIGNAL PROCES, V65, P1894, DOI 10.1109/TSP.2017.2652383
   Maity SP, 2011, INFORM SCIENCES, V181, P450, DOI 10.1016/j.ins.2010.09.029
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Mohammad AA, 2012, MULTIMED TOOLS APPL, V59, P851, DOI 10.1007/s11042-011-0772-7
   Mohan B.Chandra., 2010, INT J COMPUTER ELECT, V2, P1793
   Mousavi SM, 2017, MULTIMED TOOLS APPL, V76, P10313, DOI 10.1007/s11042-016-3622-9
   Munib S, 2017, MULTIMED TOOLS APPL, V76, P8695, DOI 10.1007/s11042-016-3485-0
   Najafi E, 2019, J INF SECUR APPL, V44, P144, DOI 10.1016/j.jisa.2018.12.002
   Nasir I, 2008, SITIS 2007: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGIES & INTERNET BASED SYSTEMS, P942, DOI 10.1109/SITIS.2007.67
   Niu PP, 2016, MULTIMED TOOLS APPL, V75, P7655, DOI 10.1007/s11042-015-2687-1
   Papakostas GA, 2014, GATE COMPUTER SCI RE, V1
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Priyanka, 2017, MULTIMED TOOLS APPL, V76, P3617, DOI 10.1007/s11042-016-3913-1
   Ren HP, 2003, J OPT SOC AM A, V20, P631, DOI 10.1364/JOSAA.20.000631
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Ruanaidh JJKO, 1998, SIGNAL PROCESS, V66, P303, DOI 10.1016/S0165-1684(98)00012-7
   Sabbane F, 2019, MULTIMED TOOLS APPL, V78, P34129, DOI 10.1007/s11042-019-08134-7
   Santhi V, 2013, J INF SECUR APPL, V18, P167, DOI 10.1016/j.istr.2013.01.001
   Savelonas MA, 2010, SIGNAL PROCESS, V90, P2521, DOI 10.1016/j.sigpro.2010.02.021
   Shao ZH, 2016, SIGNAL PROCESS, V120, P522, DOI 10.1016/j.sigpro.2015.10.005
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P3557, DOI 10.1007/s11042-016-3885-1
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Soualmi A, 2021, MULTIMED TOOLS APPL, V80, P2279, DOI 10.1007/s11042-020-09614-x
   Soualmi A, 2018, ARAB J SCI ENG, V43, P7893, DOI 10.1007/s13369-018-3246-7
   Su QT, 2020, SOFT COMPUT, V24, P445, DOI 10.1007/s00500-019-03924-5
   Su QT, 2019, IEEE ACCESS, V7, P4358, DOI 10.1109/ACCESS.2018.2888857
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P24221, DOI 10.1007/s11042-016-4164-x
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P8781, DOI 10.1007/s11042-016-3522-z
   Su QT, 2012, OPT COMMUN, V285, P1792, DOI 10.1016/j.optcom.2011.12.065
   Swaraja K, 2018, MULTIMED TOOLS APPL, V77, P28249, DOI 10.1007/s11042-018-6020-7
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Thakkar FN, 2019, MULTIDIM SYST SIGN P, V30, P1769, DOI 10.1007/s11045-018-0627-8
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thakur S, 2020, MULTIMED TOOLS APPL, V79, P4263, DOI 10.1007/s11042-018-6691-0
   Thanki R, 2021, MULTIMED TOOLS APPL, V80, P4307, DOI 10.1007/s11042-020-09941-z
   Thanki R, 2019, MULTIMED TOOLS APPL, V78, P13905, DOI 10.1007/s11042-018-6746-2
   Tirkel AZ, 1996, IEEE ISSSTA '96 - IEEE FOURTH INTERNATIONAL SYMPOSIUM ON SPREAD SPECTRUM TECHNIQUES & APPLICATIONS, PROCEEDINGS, VOLS 1-3, P785, DOI 10.1109/ISSSTA.1996.563231
   Tiwari Anurag, 2022, Sustainable Technology and Advanced Computing in Electrical Engineering: Proceedings of ICSTACE 2021. Lecture Notes in Electrical Engineering (939), P119, DOI 10.1007/978-981-19-4364-5_10
   Tiwari Anurag, 2022, 2022 IEEE 9th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON), P1, DOI 10.1109/UPCON56432.2022.9986427
   Tiwari Anurag, 2022, 2022 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS), P581, DOI 10.1109/ICCCIS56430.2022.10037672
   Tiwari A, 2023, J SUPERCOMPUT, V79, P13142, DOI 10.1007/s11227-023-05167-6
   Tiwari N, 2013, IEEE INT ADV COMPUT, P1100
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Vaidya SP, 2017, MULTIMED TOOLS APPL, V76, P25623, DOI 10.1007/s11042-017-4355-0
   Vaishnavi D, 2015, PROCEDIA COMPUT SCI, V46, P1770, DOI 10.1016/j.procs.2015.02.130
   Van Loan CF, 1996, MATRIX COMPUTATIONS, V5
   Wang CP, 2017, MULTIMED TOOLS APPL, V76, P26355, DOI 10.1007/s11042-016-4130-7
   Wang CP, 2016, SIGNAL PROCESS-IMAGE, V45, P10, DOI 10.1016/j.image.2016.03.007
   Wang CP, 2018, INFORM SCIENCES, V450, P141, DOI 10.1016/j.ins.2018.03.040
   Wang XY, 2014, MULTIMED TOOLS APPL, V72, P1933, DOI 10.1007/s11042-013-1483-z
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Wang XY, 2010, MULTIDIM SYST SIGN P, V21, P179, DOI 10.1007/s11045-009-0096-1
   Wang XY, 2010, COMPUT ELECTR ENG, V36, P31, DOI 10.1016/j.compeleceng.2009.04.005
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Xia ZQ, 2019, IEEE ACCESS, V7, P122544, DOI 10.1109/ACCESS.2019.2935174
   Xia ZQ, 2019, SIGNAL PROCESS, V164, P368, DOI 10.1016/j.sigpro.2019.06.025
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Xin YQ, 2007, PATTERN RECOGN, V40, P3740, DOI 10.1016/j.patcog.2007.05.004
   Xu HC, 2019, OPTIK, V183, P401, DOI 10.1016/j.ijleo.2019.02.001
   Yamni M, 2021, J FRANKLIN I, V358, P2535, DOI 10.1016/j.jfranklin.2021.01.011
   Yamni M, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107509
   Yang HY, 2015, MULTIMED TOOLS APPL, V74, P10559, DOI 10.1007/s11042-014-2187-8
   Yang HY, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700299
   Yang Y, 2009, IEEE T CIRC SYST VID, V19, P656, DOI 10.1109/TCSVT.2009.2017401
   Yeo IK, 2003, MULTIMEDIA SYST, V9, P261, DOI 10.1007/s00530-003-0097-0
   Yuan XC, 2014, MULTIMED TOOLS APPL, V72, P777, DOI 10.1007/s11042-013-1405-0
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zernike F, 1934, PHYSICA, V1, P689
   Zhang H, 2011, IEEE T IMAGE PROCESS, V20, P2189, DOI 10.1109/TIP.2011.2118216
NR 103
TC 5
Z9 5
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16447
EP 16483
DI 10.1007/s11042-023-16109-y
EA JUL 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001029126000011
DA 2024-07-18
ER

PT J
AU Parvez, MT
   Alsuhibany, SA
AF Parvez, Mohammad T.
   Alsuhibany, Suliman A.
TI Challenges and opportunities for Arabic CAPTCHAs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arabic CAPTCHAs; User Authentication; Handwritten CAPTCHA
ID SECURITY
AB Arabic Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA) has only recently gained attention, with a few studies on handwritten text-based CAPTCHAs. Compared to Latin CAPTCHAs, Arabic CAPTCHAs provide several opportunities. They are suitable for around 444 million Arab speakers, provide several linguistic ways of solving CAPTCHAs due to the nature of the script, and can be easily extended to languages with similar scripts, including Urdu and Persian. Due to the difference in writing styles, Arabic CAPTCHAs provide new opportunities for research in CAPTCHA-based user authentication. The Image, video, or audio-based Arabic CAPTCHA schemes remain largely unexplored. In this paper, thus, we investigate state-of-the-art research in Arabic CAPTCHAs by exploring these opportunities and address the challenges that need to be overcome by researchers. The results show several challenges derived from previous studies that should be taken into consideration when developing an Arabic CAPTCHA system. In addition, numerous opportunities can be exploited in order to improve the existing Arabic CAPTCHA schemes.
C1 [Parvez, Mohammad T.] Qassim Univ, Coll Comp, Dept Comp Engn, Buraydah, Saudi Arabia.
   [Alsuhibany, Suliman A.] Qassim Univ, Coll Comp, Dept Comp Sci, Buraydah, Saudi Arabia.
C3 Qassim University; Qassim University
RP Parvez, MT (corresponding author), Qassim Univ, Coll Comp, Dept Comp Engn, Buraydah, Saudi Arabia.
EM m.parvez@qu.edu.sa; salsuhibany@qu.edu.sa
CR Abu Bakar Siddique Hafiz, 2015, 2015 17th European Conference on Power Electronics and Applications (EPE'15 ECCE-Europe), P1, DOI 10.1109/EPE.2015.7311719
   Abubaker H, 2016, IEEE INT CONF INNOV, P138
   Abubaker H, 2017, ARAB J SCI ENG, V42, P3391, DOI 10.1007/s13369-017-2494-2
   Akila G, 2015, LECT NOTES COMPUT SC, V9042, P655, DOI 10.1007/978-3-319-18117-2_49
   AL-Shatnawi A, 2009, 2009 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATICS, VOLS 1 AND 2, P73, DOI 10.1109/ICEEI.2009.5254814
   Aldosari MH, 2016, INT CONF INFORM COMM, P239, DOI 10.1109/IACS.2016.7476118
   Alqahtani FH, 2020, COMPUT SECUR, V88, DOI 10.1016/j.cose.2019.101635
   Alsuhibany S. A., 2011, 2011 Sixth International Conference on Availability, Reliability and Security, P740, DOI 10.1109/ARES.2011.114
   Alsuhibany SA, 2022, J INF SECUR APPL, V70, DOI 10.1016/j.jisa.2022.103318
   Alsuhibany SA, 2021, IEEE ACCESS, V9, P140991, DOI 10.1109/ACCESS.2021.3119571
   Alsuhibany SA, 2022, COMPUT SYST SCI ENG, V40, P421, DOI 10.32604/csse.2022.018929
   Alsuhibany SA, 2022, INTELL AUTOM SOFT CO, V31, P523, DOI 10.32604/iasc.2022.019913
   Alsuhibany SA, 2021, IET INFORM SECUR, V15, P191, DOI 10.1049/ise2.12018
   Alsuhibany SA, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON ANTI-CYBER CRIMES (ICACC), P81, DOI 10.1109/Anti-Cybercrime.2017.7905268
   Alsuhibany SA, 2016, INT CONF FRONT HAND, P126, DOI [10.1109/ICFHR.2016.0035, 10.1109/ICFHR.2016.32]
   [Anonymous], 2005, P SIGCHI C HUM FACT
   Ashraf K, 2012, SCRIPT FAMILIARITY I
   Bakry M, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P304, DOI 10.1109/DAS.2014.50
   Banday M. Tariq, 2015, International Journal of Web Portals, V7, P1, DOI 10.4018/IJWP.2015010101
   Bursztein E, 2011, PROCEEDINGS OF THE 18TH ACM CONFERENCE ON COMPUTER & COMMUNICATIONS SECURITY (CCS 11), P125
   Fanelle V, 2020, PROCEEDINGS OF THE SIXTEENTH SYMPOSIUM ON USABLE PRIVACY AND SECURITY (SOUPS 2020), P111
   Fawareh M, 2021, INT J COMMUN ANTENNA, V11, P288
   Khan B, 2013, INT ARAB J INF TECHN, V10, P76
   Khan B, 2010, COMM COM INF SC, V122, P8
   Mahmoud SA, 2014, PATTERN RECOGN, V47, P1096, DOI 10.1016/j.patcog.2013.08.009
   Moradi M, 2015, SECUR COMMUN NETW, V8, P2135, DOI 10.1002/sec.1157
   Motoyama M., 2010, USENIX Security Symposium, V10, page, P3
   Parvez MT, 2020, COMPUT SECUR, V95, DOI 10.1016/j.cose.2020.101829
   Sattar SA, 2008, COMM COM INF SC, V20, P279
   Shahreza MS, 2006, 2 IEEE INT C INF COM, V1, P78
   Shirali-Shahreza MH, 2007, ICCC 2007: 5TH IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL CYBERNETICS, PROCEEDINGS, P135, DOI 10.1109/ICCCYB.2007.4402026
   Shirali-shahreza MH, 2006, IADIS INT J COMPUTER, P63
   Shirali-Shahreza MH, 2006, J UNIVERS COMPUT SCI, V12, P1783
   Sulaiman MT, 2017, IRAQ J SCI, P2427
   Thobhani A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091522
   Thomas AO, 2009, PATTERN RECOGN, V42, P3365, DOI 10.1016/j.patcog.2008.12.018
   von Ahn L, 2004, COMMUN ACM, V47, P57, DOI 10.1145/966389.966390
   Wang P, 2020, IEEE T DEPEND SECURE
   Zheng LY, 2004, PATTERN RECOGN LETT, V25, P1723, DOI 10.1016/j.patrec.2004.06.015
   Zi Y, 2020, IEEE T INF FOREN SEC, V15, P753, DOI 10.1109/TIFS.2019.2928622
NR 40
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14047
EP 14062
DI 10.1007/s11042-023-16166-3
EA JUL 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001028770200002
DA 2024-07-18
ER

PT J
AU Xu, JL
   Guo, YY
   Shang, WQ
   You, SP
AF Xu, Jianlou
   Guo, Yuying
   Shang, Wanqing
   You, Shaopei
TI Image decomposition combining low-rank and deep image prior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Deep image prior; Low-rank; Sparsity
ID TOTAL VARIATION MINIMIZATION; TEXTURE; CARTOON; MODEL; RESTORATION
AB Most of the traditional variational decomposition models let the structure and texture belong to different functional spaces, which makes it difficult to distinguish structural edges from oscillatory components. Although existing learning-based methods can get better structural features, they require a large number of samples to train. However, image decomposition without ground truth is difficult to use supervised learning. Deep image prior is a typical unsupervised deep learning method, which avoids collecting a large number of training samples. Meanwhile, it is comparable to some of the most advanced methods in terms of image denoising, super-resolution, and inpainting. In this paper, we propose a new image decomposition model based on the deep image prior. Different from other existing methods, we use the deep image prior to characterize the cartoon and the low-rank norm to describe the texture. That is, our proposed model combines the superiority of the deep prior and sparsity. Moreover, we employ adaptive regularization parameters in order to make the structural component more edge-preserving. To the best of our knowledge, this is the first image decomposition model based on deep learning. To effectively solve the new model, the alternating direction method of multiplier is designed. In the numerical experiments, the structure images and texture images are displayed intuitively, and the structure images of the new model retain more edge features, and its texture images contain more complete texture details, thus verifying the validity of the new model.
C1 [Xu, Jianlou; Guo, Yuying; You, Shaopei] Henan Univ Sci & Technol, Sch Math & Stat, Luoyang 471023, Peoples R China.
   [Shang, Wanqing] Ningxia Univ, Sch Math & Stat, Ningxia 750021, Peoples R China.
C3 Henan University of Science & Technology; Ningxia University
RP Xu, JL (corresponding author), Henan Univ Sci & Technol, Sch Math & Stat, Luoyang 471023, Peoples R China.
EM xujianlou@126.com
FU National Natural Science Foundation of China; Key Science and Technology
   Research Project of Henan Province of China [232102210111]; Key
   Scientific Research Project of Colleges and Universities in Henan
   Province [21A510003, 22A120006]
FX AcknowledgementsThis work is supported by National Natural Science
   Foundation of China (No.U1504603), Key Science and Technology Research
   Project of Henan Province of China (No. 232102210111) and the Key
   Scientific Research Project of Colleges and Universities in Henan
   Province (Nos. 21A510003, 22A120006).
CR Atlas A, 2021, DISCRETE CONT DYN-B, V26, P4963, DOI 10.3934/dcdsb.2020321
   Aujol JF, 2006, INT J COMPUT VISION, V67, P111, DOI 10.1007/s11263-006-4331-z
   Aujol JF, 2005, J MATH IMAGING VIS, V22, P71, DOI 10.1007/s10851-005-4783-8
   Bortolotti V, 2017, INVERSE PROBL, V33, DOI 10.1088/1361-6420/33/1/015003
   Cascarano P, 2021, 2021 21ST INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ITS APPLICATIONS ICCSA 2021, P39, DOI 10.1109/ICCSA54496.2021.00016
   Chan TF, 2007, J VIS COMMUN IMAGE R, V18, P464, DOI 10.1016/j.jvcir.2006.12.004
   Chen Y., 2021, J COMPUTATIONAL VISI, V6, P1, DOI [10.15353/jcvis.v6i1.3537, DOI 10.15353/JCVIS.V6I1.3537]
   Ennouni A., 2021, J Computer Science, V17, P284, DOI [10.3844/JCSSP.2021.284.295, DOI 10.3844/JCSSP.2021.284.295]
   Gandelsman Y, 2019, PROC CVPR IEEE, P11018, DOI 10.1109/CVPR.2019.01128
   Giga Y, 2019, JPN J IND APPL MATH, V36, P261, DOI 10.1007/s13160-018-00340-4
   Gilles J, 2007, J MATH IMAGING VIS, V28, P285, DOI 10.1007/s10851-007-0020-y
   Guo ZC, 2011, MATH COMPUT MODEL, V53, P1336, DOI 10.1016/j.mcm.2010.12.031
   Kim T., 2020, J KOREAN ASS INFORM, V24, P573, DOI [10.14352/jkaie.2020.24.6.573, DOI 10.14352/JKAIE.2020.24.6.573]
   Kim Y, 2019, IEEE T IMAGE PROCESS, V28, P2692, DOI 10.1109/TIP.2018.2889531
   Kingma D, 2014, ICLR P, V2014, P1
   Li YF, 2020, CHINESE J ELECTRON, V29, P906, DOI 10.1049/cje.2020.08.006
   Lieu LH, 2008, APPL MATH OPT, V58, P167, DOI 10.1007/s00245-008-9047-8
   Lim J, 2017, J VIS COMMUN IMAGE R, V45, P107, DOI 10.1016/j.jvcir.2017.02.016
   Liu XW, 2018, IEEE SIGNAL PROC LET, V25, P1221, DOI 10.1109/LSP.2018.2850218
   Maclaurin D., 2015, ICML 2015 AUTOML WOR, V238, P5
   Meyer Y., 2001, AM MATH SOC, V22
   Ng MK, 2013, IEEE T IMAGE PROCESS, V22, P2233, DOI 10.1109/TIP.2013.2246520
   Oliveira H, 2020, INT J WAVELETS MUL I, V18
   Ono S, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2299067
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schaeffer H, 2013, SIAM J IMAGING SCI, V6, P226, DOI 10.1137/110854989
   Shang WQ, 2021, IEEE ACCESS, V9, P133531, DOI 10.1109/ACCESS.2021.3115779
   Starck JL, 2005, IEEE T IMAGE PROCESS, V14, P1570, DOI 10.1109/TIP.2005.852206
   Tadmor E, 2004, MULTISCALE MODEL SIM, V2, P554, DOI 10.1137/030600448
   Tadmor E, 2008, COMMUN MATH SCI, V6, P281
   Ulyanov D, 2020, INT J COMPUT VISION, V128, P1867, DOI 10.1007/s11263-020-01303-4
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   Wen YW, 2022, APPL MATH COMPUT, V414, DOI 10.1016/j.amc.2021.126654
   Wen YW, 2019, NUMER LINEAR ALGEBR, V26, DOI 10.1002/nla.2224
   Xu JL, 2022, SIGNAL IMAGE VIDEO P, V16, P1569, DOI 10.1007/s11760-021-02111-0
   Xu JL, 2019, SIGNAL IMAGE VIDEO P, V13, P967, DOI 10.1007/s11760-019-01434-3
   Xu JL, 2014, SIGNAL IMAGE VIDEO P, V8, P39, DOI 10.1007/s11760-012-0420-3
   Xu RT, 2021, IEEE T IMAGE PROCESS, V30, P1542, DOI 10.1109/TIP.2020.3043665
   Xu X, 2016, IEEE T GEOSCI REMOTE, V54, P3083, DOI 10.1109/TGRS.2015.2511197
   Yushi Li, 2018, International Journal of Software Science and Computational Intelligence, V10, P24, DOI 10.4018/IJSSCI.2018070102
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhang ZY, 2021, SIGNAL PROCESS-IMAGE, V96, DOI 10.1016/j.image.2021.116308
   Zhou F, 2020, IEEE T IMAGE PROCESS, V29, P3458, DOI 10.1109/TIP.2019.2961232
NR 44
TC 1
Z9 1
U1 12
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13887
EP 13903
DI 10.1007/s11042-023-16234-8
EA JUL 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001027813700003
DA 2024-07-18
ER

PT J
AU Ansari, F
   Samadi, S
   Mohseni, R
AF Ansari, Farzad
   Samadi, Sadegh
   Mohseni, Reza
TI Clean processing for direct signal cancellation using sparse
   representation in passive synthetic Aperture Radar based on DVB-T Signal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Direct signal cancellation; Effect of bright targets cancellation;
   Sparse representation; Passive synthetic Aperture Radar; DVB-T signal
AB This paper presents a new method of clean processing for cancelling direct signal from the reference channel signal using Sparse Representation (SR) in a Bistatic Passive Synthetic Aperture Radar (BPSAR) based on Digital Video Broadcasting - Terrestrial (DVB-T) signal, whose transmitter is stationary and receiver is moving. This paper develops the system model of BPSAR in presence of the direct signal interference and then proposes an SR based algorithm to cancel it. The sidelobe artifact of strong targets is another problem in passive radar imagery which degrades the quality of passive SAR images. The proposed method considers the cancellation of sidelobe effects of strong targets too. Experimental results indicate that the proposed algorithm is effective.
C1 [Ansari, Farzad; Samadi, Sadegh; Mohseni, Reza] Shiraz Univ Technol, Dept Elect Engn, Shiraz, Iran.
C3 Shiraz University of Technology
RP Samadi, S (corresponding author), Shiraz Univ Technol, Dept Elect Engn, Shiraz, Iran.
EM samadi@sutech.ac.ir
CR Anghel A, 2016, INT GEOSCI REMOTE SE, P2094, DOI 10.1109/IGARSS.2016.7729540
   Argenti F, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2277512
   Arron JR, 2013, ADV PHARMACOL, V66, P1, DOI 10.1016/B978-0-12-404717-4.00001-9
   Asadipooya A., 2021, REAL TIME IMAGE PROC, V18, P1
   Bahmani S, 2013, J MACH LEARN RES, V14, P807
   Blumensath T., 2007, IEEE INT C ACOUSTISR, P1520
   Carrara W. G., 1995, Spotlight synthetic aperture radar, signal processing algorithms
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Evers A, 2014, IEEE RAD CONF, P680, DOI 10.1109/RADAR.2014.6875677
   Fang Y, 2020, IEEE T GEOSCI REMOTE, V58, P5066, DOI 10.1109/TGRS.2020.2972156
   Final draft European Telecommunications Standards Institute (ETSI), 2004, 300744V151 ETSI
   Foucart S., 2012, Approximation Theory XIII: San Antonio 2010, V13, P65
   Gromek D, 2014, EUROP RADAR CONF, P137, DOI 10.1109/EuRAD.2014.6991226
   Gromek D, 2019, IET RADAR SONAR NAV, V13, P213, DOI 10.1049/iet-rsn.2018.5123
   Grossmann D, 2014, 2014 IEEE EMERGING TECHNOLOGY AND FACTORY AUTOMATION (ETFA)
   Iglesias R, 2013, IEEE GEOSCI REMOTE S, V10, P667, DOI 10.1109/LGRS.2012.2217935
   Krysik Piotr, 2013, 2013 International Conference on Radar, P39, DOI 10.1109/RADAR.2013.6651956
   Krysik P, 2012, EUROP RADAR CONF, P142
   Kulpa K., 2013, IEEE RAD C OTT, P1
   Ladebusch U, 2006, P IEEE, V94, P183, DOI 10.1109/JPROC.2005.861009
   Lee J. S., 1994, REMOTE SENSING REV, V8, P313, DOI [10.1080/02757259409532206, DOI 10.1080/02757259409532206]
   Rodriguez-Cassola M, 2012, IEEE GEOSCI REMOTE S, V9, P33, DOI 10.1109/LGRS.2011.2158984
   Samadi S, 2011, IET RADAR SONAR NAV, V5, P182, DOI 10.1049/iet-rsn.2009.0235
   Santoso FreddyK., 2015, 2015 International Symposium on Consumer Electronics (ISCE), P1, DOI DOI 10.1109/ISCE.2015.7177843
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
NR 25
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13315
EP 13336
DI 10.1007/s11042-023-15997-4
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023897700013
DA 2024-07-18
ER

PT J
AU Meetei, LS
   Singh, TD
   Bandyopadhyay, S
AF Meetei, Loitongbam Sanayai
   Singh, Thoudam Doren
   Bandyopadhyay, Sivaji
TI Exploiting multiple correlated modalities can enhance low-resource
   machine translation quality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal machine translation; Image-guided; Speech-guided;
   Low-resource; Manipuri; Hindi; Neural machine translation
AB In an effort to enhance the machine translation (MT) quality of low-resource languages, we report the first study on multimodal machine translation (MMT) for Manipuri?English, Manipuri?Hindi and Manipuri?German language pairs. Manipuri is a morphologically rich and resource-constrained language with limited resources that can be computationally utilized. No such MMT dataset has not been reported for these language pairs till date. To build the parallel datasets, we collected news articles containing images and associated text in English from a local daily newspaper and used English as a pivot language. The machine translated outputs of the existing translation systems of these languages go through manual post-editing to build the datasets. In addition to text, we build MT systems by exploiting features from images and audio recordings in the source language, i.e., Manipuri. We carried out an extensive analysis of the MT systems trained with text-only and multimodal inputs using automatic metrics and human evaluation techniques. Our findings attest that integrating multiple correlated modalities enhances the MT system performance in low-resource settings achieving a significant improvement of up to +3 BLEU score. The human assessment revealed that the fluency score of the MMT systems depends on the type of correlated auxiliary modality.
C1 [Meetei, Loitongbam Sanayai; Singh, Thoudam Doren] Natl Inst Technol Silchar, Ctr Nat Language Proc CNLP, Silchar, Assam, India.
   [Meetei, Loitongbam Sanayai; Singh, Thoudam Doren; Bandyopadhyay, Sivaji] Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar, Assam, India.
   [Bandyopadhyay, Sivaji] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, W Bengal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar; National Institute of Technology (NIT System);
   National Institute of Technology Silchar; Jadavpur University
RP Meetei, LS (corresponding author), Natl Inst Technol Silchar, Ctr Nat Language Proc CNLP, Silchar, Assam, India.; Meetei, LS (corresponding author), Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar, Assam, India.
EM loismeetei@gmail.com
OI Sanayai Meetei, Loitongbam/0000-0002-9816-9108
CR Anastasopoulos A, 2021, IWSLT 2021: THE 18TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE TRANSLATION, P1
   [Anonymous], 2009, P 4 WORKSH STAT MACH
   [Anonymous], 2007, P 45 ANN M ASS COMPU
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P33701, DOI 10.1007/s11042-021-11345-6
   Caglayan O, 2016, ARXIV
   Caglayan O, 2019, ARXIV
   Caglayan O, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1707.04481
   Calixto I., 2017, P 2017 C EMP METH NA, P992, DOI 10.18653/v1/D17-1105
   DHANJAL AS, 2022, MULTIMED TOOLS APPL, P1, DOI DOI 10.1007/S11042-021-11706-1
   Elliott D, 2016, ARXIV
   Gulcehre Caglar, 2015, arXiv preprint arXiv:1503.03535
   Hirasawa T, 2020, ARXIV
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang Po-Yao, 2016, P 1 C MACH TRANSL, DOI DOI 10.18653/V1/W16-2360
   Kakwani D, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4948
   Kingma D. P., 2014, arXiv
   Klein G, 2020, P 14 C ASS MACH TRAN, V1
   Kocabiyikoglu AC, 2018, ARXIV
   Koehn Philipp, 2003, HLT NAACL 2003 HUMAN, P48
   Lee JY, 2019, MULTIMED TOOLS APPL, V78, P31793, DOI 10.1007/s11042-019-08011-3
   Luong T., 2015, P 2015 C EMP METH NA, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Mao J, 2014, ARXIV
   Meetei Loitongbam Sanayai, 2023, Procedia Computer Science, P2102, DOI 10.1016/j.procs.2023.01.186
   Meetei LS, 2021, P 18 INT C NAT LANG, P54
   Meetei LS, 2019, P 6 WORKSH AS TRANSL, P181, DOI DOI 10.18653/V1/D19-5224
   Ney H, 1999, INT CONF ACOUST SPEE, P517, DOI 10.1109/ICASSP.1999.758176
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parida S, 2019, COMPUT SIST, V23, P1499, DOI [10.13053/CyS-23-4-3294, 10.13053/cys-23-4-3294]
   Pham NQ, 2019, P 16 INT C SPOKEN LA
   Popovic Maja, 2015, P 10 WORKSHOP STAT M, P392
   Post M., 2018, P 3 C MACHINE TRANSL, P186, DOI [10.18653/v1/W18-6319, DOI 10.18653/V1/W18-6319]
   Rahul Laishram, 2021, Advances in Computing and Network Communications. Proceedings of CoCoNet 2020. Lecture Notes in Electrical Engineering (LNEE 736), P249, DOI 10.1007/978-981-33-6987-0_21
   Sanabria R, 2018, ARXIV
   Sanayai Meetei L, 2020, P 17 INT C NATURAL L, P50
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sennrich Rico, 2015, arXiv
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A, 2022, MULTIMED TOOLS APPL, V81, P17989, DOI 10.1007/s11042-022-12343-y
   Singh Sakshi, 2022, Advanced Machine Intelligence and Signal Processing. Lecture Notes in Electrical Engineering (858), P625, DOI 10.1007/978-981-19-0840-8_48
   Singh SM, 2022, NEURAL COMPUT APPL, V34, P14823, DOI 10.1007/s00521-022-07337-8
   Singh SM, 2021, P 1 WORKSHOP MULTIMO, P2
   Singh TD, 2021, P 1 W MULT MACH TRA
   Singh TD, 2013, P 7 WORKSHOP SYNTAX, P11
   Singh TD, 2020, 2020 INTERNATIONAL CONFERENCE ON COMPUTATIONAL PERFORMANCE EVALUATION (COMPE-2020), P733, DOI 10.1109/ComPE49325.2020.9200059
   Snover Matthew., 2006, P 7 C ASS MACHINE TR, P223
   Sperber M, 2019, T ASSOC COMPUT LING, V7, P313, DOI 10.1162/tacl_a_00270/1923092
   Sutskever I., 2014, ADV NEURAL INFORM PR, V4, P3104, DOI DOI 10.5555/2969033.2969173
   Tillmann C, 2003, COMPUT LINGUIST, V29, P97, DOI 10.1162/089120103321337458
   Toral A., 2018, Frontiers in Digital Humanities, V5, P1, DOI [DOI 10.3389/FDIGH.2018.00009, https://doi.org/10.3389/fdigh.2018.00009]
   Wang DX, 2021, AAAI CONF ARTIF INTE, V35, P2720
   Wang X, 2019, IEEE I CONF COMP VIS, P4580, DOI 10.1109/ICCV.2019.00468
   Weiss RJ, 2017, INTERSPEECH, P2625, DOI 10.21437/Interspeech.2017-503
   Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
NR 55
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13137
EP 13157
DI 10.1007/s11042-023-15721-2
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023897700007
DA 2024-07-18
ER

PT J
AU Li, JY
   Osseyran, A
   Hekster, R
   Rudinac, S
   Codreanu, V
   Podareanu, D
AF Li, Jieyi
   Osseyran, Anwar
   Hekster, Ruben
   Rudinac, Stevan
   Codreanu, Valeriu
   Podareanu, Damian
TI Improving the speed and quality of cancer segmentation using lower
   resolution pathology images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic segmentation; Breast cancer; Whole-slide imaging; Gigapixel
   histopathology; Pixel-based convolutional neural networks
AB In this paper, we propose a pipeline to investigate the performance of semantic segmentation model that employs an encoder-decoder architecture with atrous separable convolution and spatial pyramid pooling, trained on multi-resolution whole slide breast pathological images with different patch sizes. Our segmentation model obtains the best performance on zoom level 2 (10xmagnification) with AUC score 0.974 in terms of slide-level classification. This outperforms both the performance of the pathologist and other semantic segmentation models on the Camelyon 16 dataset. By offering a larger field of view and reducing noise and detail, training a semantic segmentation model on the properly selected lower resolution pathology images can further improve the precision of pixel-wise cancer region segmentation. By contrast, the corresponding inference time is 14 times shorter than the inference time trained on the highest resolution patches, and it is also shorter than the time required by a pathologist with time constraints. Moreover, we prove that the model trained on lower resolution patches can still generate refined external polygons of cancer region on the highest resolution image. This study provides new insights into efficient gigapixel histopathology analysis that will make clinical adoption more likely.
C1 [Li, Jieyi; Osseyran, Anwar; Rudinac, Stevan] Univ Amsterdam, Amsterdam Business Sch, Plantage Muidergracht 12, NL-1018 TV Amsterdam, Netherlands.
   [Hekster, Ruben; Codreanu, Valeriu; Podareanu, Damian] SURF, High Performance Machine Learning Grp, Sci Pk 140, NL-1098 XG Amsterdam, Netherlands.
C3 University of Amsterdam
RP Li, JY (corresponding author), Univ Amsterdam, Amsterdam Business Sch, Plantage Muidergracht 12, NL-1018 TV Amsterdam, Netherlands.
EM j.li3@uva.nl
RI Li, Jieyi/AAN-4953-2021
OI Li, Jieyi/0000-0001-6786-1217
FU Atos through the HPC; AI; Quantum Life Sciences Centre of Excellence
   (CEPP); SURF
FX Financial support for this study was provided in part by Atos through
   the HPC, AI and QuantumLife Sciences Centre of Excellence (CEPP); as
   well as by SURF, the collaborative organization for IT in Dutch
   education and research. The funding agreement ensured the authors'
   independence in designing thestudy, interpreting the data, writing, and
   publishing the report. Jieyi Li, Anwar Osseyran, Ruben Hekster,Stevan
   Rudinac, Valeriu Codreanu, Damian Podareanu declare that they do not
   have any financial or personal & nbsp; relationships with other people
   or organizations that could have in appropriately influenced this study
CR [Anonymous], 2018, Medical Imaging with Deep Learning
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Cai K, 2017, NEUROCOMPUTING, V220, P138, DOI 10.1016/j.neucom.2016.03.106
   Chanchal AK, 2022, MULTIMED TOOLS APPL, V81, P9201, DOI 10.1007/s11042-021-11873-1
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Codreanu V, 2018, PROCEEDINGS OF 2018 IEEE/ACM MACHINE LEARNING IN HPC ENVIRONMENTS (MLHPC 2018), P67, DOI [10.1109/MLHPC.2018.000-2, 10.1109/MLHPC.2018.8638634]
   Deepa BG, 2022, MULTIMED TOOLS APPL, V81, P8575, DOI 10.1007/s11042-022-12114-9
   Dimitriou N, 2019, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00264
   EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552
   Goode Adam, 2013, J Pathol Inform, V4, P27, DOI 10.4103/2153-3539.119005
   Guo Z, 2019, SCI REP-UK, V9
   Gupta I, 2022, MULTIMED TOOLS APPL, V81, P36309, DOI 10.1007/s11042-021-11853-5
   Hou L, 2016, PROC CVPR IEEE, P2424, DOI 10.1109/CVPR.2016.266
   Jin YW, 2020, CANCERS, V12, DOI 10.3390/cancers12102934
   Khaliliboroujeni S, 2022, COMPUT MED IMAG GRAP, V102, DOI 10.1016/j.compmedimag.2022.102136
   Khan AI, 2020, PROCEDIA COMPUT SCI, V167, P1444, DOI 10.1016/j.procs.2020.03.355
   Khened M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90444-8
   Komura D, 2018, COMPUT STRUCT BIOTEC, V16, P34, DOI 10.1016/j.csbj.2018.01.001
   Liu S, 2020, MECH SYST SIGNAL PR, V138, DOI 10.1016/j.ymssp.2019.106537
   Liu SY, 2020, IEEE INT C BIOINFORM, P663, DOI 10.1109/BIBM49941.2020.9313511
   Liu XB, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3465220
   Liu XB, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13031224
   Magee D., 2009, P OPT TISS IM AN MIC, P100
   Murtaza G, 2020, MULTIMED TOOLS APPL, V79, P15481, DOI 10.1007/s11042-019-7525-4
   Nasor M, 2021, IET IMAGE PROCESS, V15, P1310, DOI 10.1049/ipr2.12106
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pantanowitz Liron, 2010, J Pathol Inform, V1, DOI [10.4103/2153-3539.68332, 10.4103/2153-3539.63821]
   Shen YQ, 2022, IEEE T MED IMAGING, V41, P3835, DOI 10.1109/TMI.2022.3198526
   Singh S, 2022, MULTIMED TOOLS APPL, V81, P5849, DOI 10.1007/s11042-021-11775-2
   Tourniaire P, 2023, MED IMAGE ANAL, V85, DOI 10.1016/j.media.2023.102763
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang D., 2016, arXiv
   Wang J, 2021, MULTIMED TOOLS APPL, V80, P17429, DOI 10.1007/s11042-020-09282-x
   Wang T, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-021-0173-7
   Wu YX, 2022, ORAL ONCOL, V131, DOI 10.1016/j.oraloncology.2022.105942
   Xu Lin, 2020, J Pathol Inform, V11, P28, DOI 10.4103/jpi.jpi_68_19
   Yu JG, 2023, IEEE T MED IMAGING, V42, P1809, DOI 10.1109/TMI.2023.3241204
   Zanjani FG, 2018, HISTOPATHOLOGY STAIN, P1
   Zhong JT, 2023, BIOMED SIGNAL PROCES, V82, DOI 10.1016/j.bspc.2022.104505
NR 41
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11999
EP 12015
DI 10.1007/s11042-023-15984-9
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001022136100010
OA hybrid
DA 2024-07-18
ER

PT J
AU Huang, H
   Lei, XY
   Xiang, T
AF Huang, Hong
   Lei, Xinyu
   Xiang, Tao
TI Mitigating cross-client GANs-based attack in federated learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Federated learning; Privacy preserving; GANs; Ensemble learning;
   Knowledge distillation
AB Machine learning makes multimedia data (e.g., images) more attractive, however, multimedia data is usually distributed and privacy sensitive. Multiple distributed multimedia clients can resort to federated learning (FL) to jointly learn a global shared model without requiring to share their private samples with any third-party entities. In this paper, we show that FL suffers from the cross-client generative adversarial networks (GANs)-based (C-GANs) attack, in which a malicious client (i.e., adversary) can reconstruct samples with the same distribution as the training samples from other clients (i.e., victims). Since a benign client's data can be leaked to the adversary, this attack brings the risk of local data leakage for clients in many security-critical FL applications. Thus, we propose Fed-EDKD (i.e., Federated Ensemble Data-free Knowledge Distillation) technique to improve the current popular FL schemes to resist C-GANs attack. In Fed-EDKD, each client submits a local model to the server for obtaining an ensemble global model. Then, to avoid model expansion, Fed-EDKD adopts data-free knowledge distillation techniques to transfer knowledge from the ensemble global model to a compressed model. By this way, Fed-EDKD reduces the adversary's control capability over the global model, so Fed-EDKD can effectively mitigate C-GANs attack. Finally, the experimental results demonstrate that Fed-EDKD significantly mitigates C-GANs attack while only incurring a slight accuracy degradation of FL.
C1 [Huang, Hong; Xiang, Tao] Chongqing Univ, Coll Comp Sci, Chongqing, Peoples R China.
   [Lei, Xinyu] Michigan Technol Univ, Dept Comp Sci, Houghton, MI USA.
C3 Chongqing University; Michigan Technological University
RP Xiang, T (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing, Peoples R China.
EM 20164478@cqu.edu.cn; xinyulei@mtu.edu; txiang@cqu.edu.cn
RI Xiang, Tao/N-3706-2016
OI Xiang, Tao/0000-0002-9439-4623
FU National Key R amp;D Program of China [2022YFB3103500]; National Natural
   Science Foundation of China [62072062, U20A20176]; Natural Science
   Foundation of Chongqing [cstc2022ycjh-bgzxm0031]; National Science
   Foundation [RF20220009]; CCF-AFSG Research Fund;  [CNS-2153393]
FX & nbsp;This work was supported by the National Key R &D Program of China
   under Grant 2022YFB3103500, the National Natural Science Foundation of
   China under Grants 62072062 and U20A20176, Natural Science Foundation of
   Chongqing under Grant cstc2022ycjh-bgzxm0031, CCF-AFSG Research Fund
   under Grant RF20220009, and National Science Foundation (Grant no.
   CNS-2153393).
CR Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318
   Bagdasaryan E, 2020, PR MACH LEARN RES, V108, P2938
   Blanchard P, 2017, ADV NEUR IN, V30
   Cao XY, 2021, AAAI CONF ARTIF INTE, V35, P6885
   Chen HT, 2019, IEEE I CONF COMP VIS, P3513, DOI 10.1109/ICCV.2019.00361
   Chen ZZ, 2021, IEEE INTERNET THINGS, V8, P5839, DOI 10.1109/JIOT.2020.3033171
   Dean J., 2015, NIPS DEEP LEARNING R
   Dwork C, 2006, LECT NOTES COMPUT SC, V4052, P1
   Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677
   Geyer RC, 2017, ARXIV
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu YH, 2022, J INF SECUR APPL, V67, DOI 10.1016/j.jisa.2022.103201
   Hitaj B, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P603, DOI 10.1145/3133956.3134012
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Karimireddy SP, 2020, PR MACH LEARN RES, V119
   Kilbertus N, 2018, 35 INT C MACHINE LEA, V80
   Kingma D. P., 2014, arXiv
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Li QB, 2021, PROC CVPR IEEE, P10708, DOI 10.1109/CVPR46437.2021.01057
   Li T., 2020, PROC MACH LEARN SYST, V2, P429, DOI DOI 10.48550/ARXIV.1812.06127
   Lin T., 2020, ADV NEURAL INFORM PR, V33
   Lin Y., 2017, ARXIV
   Liu L, 2023, MAR GEORESOUR GEOTEC, V41, P873, DOI 10.1080/1064119X.2022.2106913
   Luo X, 2020, ARXIV
   Ma J, 2022, INT J INTELL SYST, V37, P5880, DOI 10.1002/int.22818
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Melis L, 2019, P IEEE S SECUR PRIV, P691, DOI 10.1109/SP.2019.00029
   Nasr M, 2019, P IEEE S SECUR PRIV, P739, DOI 10.1109/SP.2019.00065
   Nguyen T. D., 2020, P WORKSH DEC IOT SYS, P1, DOI DOI 10.14722/DISS.2020.23003
   Opitz D., 1999, J ARTIF INTELL RES, V11, P169, DOI DOI 10.1613/JAIR.614
   Peyvandi A, 2022, MULTIMED TOOLS APPL, P1
   Radford A., 2015, ARXIV
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41
   Shokri R, 2015, ANN ALLERTON CONF, P909, DOI 10.1109/ALLERTON.2015.7447103
   Sun Yuwei, 2022, IEEE Transactions on Artificial Intelligence, V3, P963, DOI 10.1109/TAI.2021.3133819
   Tolpegin V., 2020, Computer Security-ESORICS 2020, P480
   Truex Stacey, 2019, P 12 ACM WORKSH ART, P1, DOI [DOI 10.1145/3338501.3357370, 10.1145/3338501.3357370]
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZB, 2019, IEEE INFOCOM SER, P2512, DOI [10.1109/infocom.2019.8737416, 10.1109/INFOCOM.2019.8737416]
   Yao A. C., 1986, 27th Annual Symposium on Foundations of Computer Science (Cat. No.86CH2354-9), P162, DOI 10.1109/SFCS.1986.25
   Zhang L., 2022, ARXIV
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang YL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P19, DOI [10.1145/3132747.3132768, 10.1109/SP.2017.12]
   Zhao B., 2020, ARXIV
   Zhu LG, 2019, ADV NEUR IN, V32
   Zhu ZD, 2021, PR MACH LEARN RES, V139
NR 49
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10925
EP 10949
DI 10.1007/s11042-023-15879-9
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000015
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ashiba, MI
   Youness, HA
   Ashiba, HI
AF Ashiba, Mohamed I.
   Youness, Hassan A.
   Ashiba, Huda I.
TI Proposed homomorphic DWT for cancelable palmprint recognition technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancelable biometrics; Palmprint; HFM; DWT; Template protection
ID DISCRIMINATION POWER ANALYSIS; FACE; FINGERPRINT; TRANSFORM
AB This paper suggests novel cancellable biometric realization approach recognition and template protection. In this paper, the Homomorphic Filtering Masking (HFM) encoding algorithm is utilized for cancelable palmprint recognition system. In the suggested technique, the Discreet Wavelet Transform (DWT) algorithm is applied on the palmprint. Then the DWT divides the image into four sub images. The resultant map is encrypted with the HFM algorithm, in order to the second HFM utilized in produced from the palmprint. This approach can be used to develop a frequency domain procedure for making this system for biometric template protection. The obtained results prove that the suggested technique is the best from the other algorithms.
C1 [Ashiba, Mohamed I.; Youness, Hassan A.] Minia Univ, Fac Engn, Dept Comp & Syst Engn, Al Minya, Egypt.
   [Ashiba, Huda I.] Bilbis Higher Inst Engn, Dept Elect & Elect Commun Engn, Bilbis, Sharqia, Egypt.
C3 Egyptian Knowledge Bank (EKB); Minia University
RP Ashiba, MI (corresponding author), Minia Univ, Fac Engn, Dept Comp & Syst Engn, Al Minya, Egypt.
EM engashiba@gmail.com
CR Akdogan D, 2018, COMPUT NETW, V142, P33, DOI 10.1016/j.comnet.2018.06.001
   [Anonymous], 2010, 25 INT C IMAGE VISIO, DOI DOI 10.1109/IVCNZ.2010.6148818
   Ashiba HI, 2020, MULTIMED TOOLS APPL, V79, P2543, DOI 10.1007/s11042-019-08154-3
   Ashiba HI, 2019, MULTIMED TOOLS APPL, V78, P11277, DOI 10.1007/s11042-018-6545-9
   Ashiba H. I., 2008, Progress In Electromagnetics Research C, V1, P123, DOI 10.2528/PIERC08012301
   Barra S, 2019, FUTURE GENER COMP SY, V101, P534, DOI 10.1016/j.future.2019.06.019
   Dabbaghchian S, 2010, PATTERN RECOGN, V43, P1431, DOI 10.1016/j.patcog.2009.11.001
   Didiot E, 2010, COMPUT SPEECH LANG, V24, P341, DOI 10.1016/j.csl.2009.05.003
   Düzenli T, 2011, ISTANB UNIV-J ELECTR, V11, P1355
   Dwivedi R, 2019, PATTERN RECOGN LETT, V126, P58, DOI 10.1016/j.patrec.2018.04.022
   Evelyn Brindha V., 2012, J. Biom. Biostat, V3, P100
   Feng YC, 2010, IEEE T INF FOREN SEC, V5, P103, DOI 10.1109/TIFS.2009.2038760
   Ghoneim A, 2018, IEEE COMMUN MAG, V56, P33, DOI 10.1109/MCOM.2018.1700817
   Kant Tyagi S., 2012, INT J ENG TECHNOLOGY, V4, P311, DOI [10.7763/IJET.2012.V4.372, DOI 10.7763/IJET.2012.V4.372]
   Kho JB, 2019, PATTERN RECOGN, V91, P245, DOI 10.1016/j.patcog.2019.01.039
   KONG WK, 2004, LNCS, V3072, P520
   Kumar A, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P583, DOI 10.1109/ICVGIP.2008.73
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P8373, DOI 10.1007/s11042-016-3458-3
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, MULTIMED TOOLS APPL, V74, P11683, DOI 10.1007/s11042-014-2255-0
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Li CS, 2011, J STAT COMPUT SIM, V81, P1081, DOI 10.1080/00949651003677410
   Li HJ, 2020, MULTIMED TOOLS APPL, V79, P11947, DOI 10.1007/s11042-019-08446-8
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Maiorana E, 2010, EXPERT SYST APPL, V37, P3454, DOI 10.1016/j.eswa.2009.10.043
   Matsuyama E, 2013, J DIGIT IMAGING, V26, P748, DOI 10.1007/s10278-012-9555-6
   Morchen F., 2003, TIME SERIES FEATURE
   Nixon M.S., 2002, FEATURE EXTRACTION I
   Prasad PS, 2020, LECT NOTES ELECTR EN, V570, P419, DOI 10.1007/978-981-13-8715-9_50
   Qayyum H, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/9854050
   Rachapalli DR., 2019, INT J RECENT TECHNOL, V7, P2277
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Rathgeb C, 2014, COMPUT SECUR, V42, P1, DOI 10.1016/j.cose.2013.12.005
   Scott II, 2003, THESIS LSU, P4059
   Trivedi AK, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2019.101690
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Umer S, 2017, INFORM SCIENCES, V406, P102, DOI 10.1016/j.ins.2017.04.026
   Wang S, 2016, PATTERN RECOGN, V54, P14, DOI 10.1016/j.patcog.2016.01.001
   Wu X, 2008, 19 INT C PATT REC IC, DOI [10.1109/ICPR.2008.4761117, DOI 10.1109/ICPR.2008.4761117]
   Yang WC, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020141
   Yang WC, 2018, PATTERN RECOGN, V78, P242, DOI 10.1016/j.patcog.2018.01.026
   Zhou K, 2018, IEEE T INF FOREN SEC, V13, P3050, DOI 10.1109/TIFS.2018.2838540
NR 45
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9479
EP 9502
DI 10.1007/s11042-023-15710-5
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001015589400010
DA 2024-07-18
ER

PT J
AU Mui-zzud-din
   Ahmed, KT
   Rustam, F
   Mehmood, A
   Ashraf, I
   Choi, GS
AF Mui-zzud-din, Khwaja Tahseen
   Ahmed, Khwaja Tahseen
   Rustam, Furqan
   Mehmood, Arif
   Ashraf, Imran
   Choi, Gyu Sang
TI Predicting skin cancer melanoma using stacked convolutional neural
   networks model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin cancer prediction; Skin melanoma; VGG16; ResNet50; Convolutional
   neural networks
ID CNN
AB Skin malignant growth has been regarded as the most widely recognized disease in the world and Malignant Melanoma is one of the deadliest diseases of skin cancer. Early prediction can be helpful to avoid the damage of this disease, however, many lab tests are required which are costly and time-consuming. Devising an automatic smart system for predicting the disease accurately and efficiently can be very helpful. Despite previous research efforts for such systems, accuracy and efficiency requirements still demand continual work to improve the performance of such systems. This study proposes a stacked convolutional neural network (CNN) model that can provide higher prediction accuracy compared to other pre-trained CNN variants. Stacked CNN uses the 2D CNN layers sequentially to process the data deeply to make accurate predictions. Data augmentation is performed for minority class data to make training data balanced and avoid the model's over-fitting. The model is trained on red, green, and blue (RGB) features extracted from the training data. For testing the performance of the proposed approach, two public datasets MINST-HAM10000 and ISIC-2020 are used for training and validation, respectively. The proposed model outperforms other models with 0.96 and 0.73 accuracy scores on the test dataset and validation dataset, respectively. In the end, a statistical T-test is used to show the significance of the proposed approach.
C1 [Mui-zzud-din, Khwaja Tahseen] Ghazi Univ, Dept Comp Sci & IT, Dera Ghazi khan, Pakistan.
   [Ahmed, Khwaja Tahseen] Bahauddin Zakariya Univ, Dept Comp Sci, Multan 60800, Pakistan.
   [Rustam, Furqan] Univ Coll Dublin, Sch Comp Sci, Dublin, Ireland.
   [Mehmood, Arif] Islamia Univ, Dept Informat Technol & Comp Sci, Bahawalpur, Pakistan.
   [Ashraf, Imran; Choi, Gyu Sang] Yeungnam Univ, Dept Informat, Commun Engieering, Daegu, South Korea.
C3 Bahauddin Zakariya University; University College Dublin; Yeungnam
   University
RP Ashraf, I (corresponding author), Yeungnam Univ, Dept Informat, Commun Engieering, Daegu, South Korea.
EM Mzdin@gudgk.edu.pk; khawajatehseenahmed@gmail.com;
   furqanrustam1@gmail.com; arifnhmp@gmail.com; imranashraf@ynu.ac.kr;
   castchoi@ynu.ac.kr
RI Ashraf, Imran/T-3635-2019; Rustam, Furqan/ABE-4772-2020
OI Ashraf, Imran/0000-0002-8271-6496; Rustam, Furqan/0000-0001-8403-1047
CR A Ameri, 2020, J Biomed Phys Eng, V10, P801, DOI 10.31661/jbpe.v0i0.2004-1107
   ALDWGERI A., 2019, International Visual Informatics Conference, P214, DOI DOI 10.1007/978-3-030-34032-2_20
   Allyn J, 2020, MEDICINE, V99, DOI 10.1097/MD.0000000000023568
   Almaraz-Damian JA, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22040484
   Bassi Pedro R. A. S., 2022, Research on Biomedical Engineering, V38, P139, DOI 10.1007/s42600-021-00132-9
   C. for Disease Control and Prevension, 2017, RAT NEW CANC MEL SKI
   cancer, MELANOMA SKIN CANCE
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Dataset ISIC, US
   Dildar M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18105479
   Duy Khang Nguyen, 2020, 2020 5th International Conference on Green Technology and Sustainable Development (GTSD), P366, DOI 10.1109/GTSD50082.2020.9303084
   El-Khatib H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061753
   Folego G, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.534592
   Gao F, 2018, COMPUT MED IMAG GRAP, V70, P53, DOI 10.1016/j.compmedimag.2018.09.004
   Gessert N, 2020, METHODSX, V7, DOI 10.1016/j.mex.2020.100864
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Janoria Honey, 2021, Intelligent Data Communication Technologies and Internet of Things. Proceedings of ICICI 2020. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 57), P643, DOI 10.1007/978-981-15-9509-7_52
   Jayapriya K, 2020, INT J IMAG SYST TECH, V30, P348, DOI 10.1002/ima.22377
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034
   Khan MA, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P63, DOI 10.1109/iccisci.2019.8716400
   Khan N H, 2021, J ADV RES
   Kwon D, 2018, INT CON DISTR COMP S, P1595, DOI 10.1109/ICDCS.2018.00178
   Labach A., 2019, ARXIV
   Lakshmanaprabu SK, 2019, FUTURE GENER COMP SY, V92, P374, DOI 10.1016/j.future.2018.10.009
   Maeda-Gutiérrez V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041245
   Mahbod A, 2019, INT CONF ACOUST SPEE, P1229, DOI [10.1109/ICASSP.2019.8683352, 10.1109/icassp.2019.8683352]
   Mehra A., 2021, Advances in Intelligent Systems and Computing, DOI [10.1007/978-981-33-4367-2_6, DOI 10.1007/978-981-33-4367-2_6]
   Nahata Hardik., 2020, Machine Learning with Health Care Perspective: Machine Learning and Healthcare, P159, DOI [DOI 10.1007/978-3-030-40850-3_8, 10.1007/978-3-030-40850-3_8]
   Nawaz M, 2022, MICROSC RES TECHNIQ, V85, P339, DOI 10.1002/jemt.23908
   Nunnari F, 2019, ARXIV
   Pomponiu V, 2016, IEEE IMAGE PROC, P2623, DOI 10.1109/ICIP.2016.7532834
   Reshi AA, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6621607
   Rocheteau E, 2020, ARXIV
   Rustam F, 2022, SAUDI J BIOL SCI, V29, P583, DOI 10.1016/j.sjbs.2021.09.021
   Rustam F, 2021, IEEE ACCESS, V9, P33675, DOI 10.1109/ACCESS.2021.3061592
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   skincancer, SKIN CANC INFORM
   Soudani A, 2019, EXPERT SYST APPL, V118, P400, DOI 10.1016/j.eswa.2018.10.029
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Thurnhofer-Hemsi K, 2021, NEURAL PROCESS LETT, V53, P3073, DOI 10.1007/s11063-020-10364-y
   Togaçar M, 2021, CHAOS SOLITON FRACT, V144, DOI 10.1016/j.chaos.2021.110714
   Trager MH, 2022, EXP DERMATOL, V31, P4, DOI 10.1111/exd.14114
   Wang ZJJ, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382899
   Yimeng Sun, 2020, 2020 IEEE 2nd Global Conference on Life Sciences and Technologies (LifeTech), P11, DOI 10.1109/LifeTech48969.2020.1570619224
   Zhang ZS, 2018, IEEE T VEH TECHNOL, V67, P10378, DOI [10.1109/TIE.2018.2835378, 10.1109/TVT.2018.2866828]
NR 51
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9503
EP 9522
DI 10.1007/s11042-023-15488-6
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001015589400013
DA 2024-07-18
ER

PT J
AU Wang, H
   Chi, JN
   Wu, CD
   Yu, XS
   Wu, H
AF Wang, Huan
   Chi, Jianning
   Wu, Chengdong
   Yu, Xiaosheng
   Wu, Hao
TI Progressive local-to-global vision transformer for occluded face
   hallucination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Super-resolution; Face inpainting; Vision transfomer
AB Hallucinating a photo-realistic high-resolution (HR) face image from an occluded low-resolution (LR) face image is beneficial for a series of face-related applications. However, previous efforts focused on either super-resolving HR face images from non-occluded LR counterparts or inpainting occluded HR faces. It is necessary to address all these challenges jointly for real-world face images in unconstrained environment. In this paper, we develop a novel Local-to-Global Face Hallucination Transformer (LGFH-Transformer), which simultaneously handles the occluded LR face image super-resolution (SR) and inpainting in a unified framework. Specifically, the LGFH-Transformer is built on self-attention modules which excel at modeling long-range information between image patch sequences. Meanwhile, we introduce a mask-guided convolution and gated mechanism into the building modules (i.e., multi-head attention and feed-forward network) of each Transformer block, which can bring in the complimentary strength of convolution operation to emphasize on the spatially local context. Moreover, equipped with the delicate designed local-to-global feature reasoning mechanism in the phase of encoder, we exploit facial geometry priors (i.e., facial parsing maps) as the semantic guidance during the hallucination process in the phase of decoder to reconstruct more realistic facial details. Extensive experiments demonstrate the effectiveness and advancement of LGFH-Transformer.
C1 [Wang, Huan; Chi, Jianning; Wu, Chengdong; Yu, Xiaosheng] Northeastern Univ, Shenyang 110167, Peoples R China.
   [Wu, Hao] Univ Sydney, Sydney, NSW 2006, Australia.
C3 Northeastern University - China; University of Sydney
RP Wu, CD (corresponding author), Northeastern Univ, Shenyang 110167, Peoples R China.
EM wanghuan@stu.neu.edu.cn; chijianning@mail.neu.edu.cn;
   wuchengdong@mail.neu.edu.cn; yuxiaosheng@mail.neu.edu.cn;
   hawu1598@uni.sydney.edu.au
CR Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chen CF, 2021, PROC CVPR IEEE, P11891, DOI 10.1109/CVPR46437.2021.01172
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Dai QY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1985, DOI 10.1145/3474085.3475356
   Dosovitskiy A., 2020, INT C LEARNING REPRE
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Fu CY, 2022, IEEE T PATTERN ANAL, V44, P2938, DOI 10.1109/TPAMI.2021.3052549
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Guo KH, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3495258
   Hendrycks D., 2016, ARXIV
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Huang HB, 2017, IEEE I CONF COMP VIS, P1698, DOI 10.1109/ICCV.2017.187
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiancheng Cai, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P109, DOI 10.1109/TBIOM.2019.2951063
   Kingma D. P., 2014, arXiv
   Kwatra V, 2005, ACM T GRAPHIC, V24, P795, DOI 10.1145/1073204.1073263
   Li HL, 2022, IEEE T CIRC SYST VID, V32, P4271, DOI 10.1109/TCSVT.2021.3130196
   Li YJ, 2017, PROC CVPR IEEE, P5892, DOI 10.1109/CVPR.2017.624
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu SF, 2015, PROC CVPR IEEE, P3451, DOI 10.1109/CVPR.2015.7298967
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu W, 2022, ARXIV
   Ma C, 2020, PROC CVPR IEEE, P5568, DOI 10.1109/CVPR42600.2020.00561
   Ma X, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108465
   Meng Q, 2021, PROC CVPR IEEE, P14220, DOI 10.1109/CVPR46437.2021.01400
   Qiu HB, 2022, IEEE T PATTERN ANAL, V44, P6939, DOI 10.1109/TPAMI.2021.3098962
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2021, KNOWL-BASED SYST, V222, DOI 10.1016/j.knosys.2021.106987
   Wang JK, 2023, IEEE T MULTIMEDIA, V25, P2382, DOI 10.1109/TMM.2022.3146774
   Wang LG, 2019, PROC CVPR IEEE, P12242, DOI 10.1109/CVPR.2019.01253
   Wang XT, 2021, PROC CVPR IEEE, P9164, DOI 10.1109/CVPR46437.2021.00905
   Wang Y, 2022, P AAAI C ART INT AAA
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang LB, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1551, DOI 10.1145/3394171.3413965
   Yang T, 2021, PROC CVPR IEEE, P672, DOI 10.1109/CVPR46437.2021.00073
   Yang Y, 2019, ARXIV, DOI DOI 10.1007/978-3-030-60633-6_2
   Yi Dong, 2014, ARXIV14117923
   Yu X, 2018, LECT NOTES COMPUT SC, V11213, P219, DOI 10.1007/978-3-030-01240-3_14
   Yu X, 2017, AAAI CONF ARTIF INTE, P4327
   Yu X, 2016, LECT NOTES COMPUT SC, V9909, P318, DOI 10.1007/978-3-319-46454-1_20
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zamir SW, 2022, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR52688.2022.00564
   Zhang S, 2018, IEEE T INF FOREN SEC, V13, P637, DOI 10.1109/TIFS.2017.2763119
   Zhang X, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108415
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhong YY, 2021, IEEE T IMAGE PROCESS, V30, P2587, DOI 10.1109/TIP.2020.3048632
   Zhu Z, 2021, PROC CVPR IEEE, P10487, DOI 10.1109/CVPR46437.2021.01035
NR 53
TC 0
Z9 0
U1 5
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8219
EP 8240
DI 10.1007/s11042-023-15028-2
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012974800001
DA 2024-07-18
ER

PT J
AU Ilhan, AE
   Togay, A
AF Ilhan, Ayse Ezgi
   Togay, Abdullah
TI Use of eye-tracking technology for appreciation-based information in
   design decisions related to product details: Furniture example
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye tracking technology; Product form; Design details; Appreciation;
   Visual analyses
ID VISUAL AESTHETICS
AB Although an ideal definition for a designed product is relative, it is primarily related to the appearance of the product. In this research, the focus is on visual perception, which has a great impact on the inner world of users. With the aim of accessing implicit aesthetic appreciation information through the user, eye tracking technology is used as a tool. The purpose of the conducted study is to determine the impact of varying details in the product on appreciation. For this purpose, samples of a furniture product, seats, were selected for an experimental study. 60 participants examined 480 different stylistic details designed for the 40 seats (10 different models * 4 variations) and rated the product while examining. During the examination, the eye metrics were recorded, which produced 230,400 data in total for the analysis. The results provided meaningful and instructive findings regarding the age and gender-focused data of the participants, the effect of product style and detail preferences on user appreciation. Accordingly, the study found that appreciation towards the product details can be read through eyes using certain gaze metrics such as time to first fixation, duration of first fixation, number and duration of fixations, number and duration of visits. In this context, a meaningful data series was obtained regarding which and how the metrics can be used in eye tracking technology, and it was demonstrated that the effect of decisions about the expected product form in early design processes on user appreciation can be addressed with this technology.
C1 [Ilhan, Ayse Ezgi; Togay, Abdullah] Gazi Univ, Fac Architecture, Dept Ind Design, TR-06570 Ankara, Turkiye.
C3 Gazi University
RP Ilhan, AE (corresponding author), Gazi Univ, Fac Architecture, Dept Ind Design, TR-06570 Ankara, Turkiye.
EM ezgikeser@gmail.com
RI Ilhan, Ezgi/KDO-1771-2024
OI Ilhan, Ezgi/0000-0002-5016-0948
FU Gazi University Ethics Committee [28.11.2019- E.40021]
FX Ethics approval was obtained for the study from the Gazi University
   Ethics Committee (28.11.2019- E.40021). We would like to thank all
   participants of the experiments and both Bilten Bilisim Teknolojileri
   and METU HCI laboratory and their team for providing the suitability of
   the experimental setting and eye trackers.
CR Bartholomew M, 2022, IOWA LAW REV, V108, DOI [10.2139/ssrn.4121728, DOI 10.2139/SSRN.4121728]
   Beardsley MC, 1981, AESTHETICS PROBLEMS, V165, P503
   Berni Aurora, 2023, Advances on Mechanics, Design Engineering and Manufacturing IV: Proceedings of the International Joint Conference on Mechanics, Design Engineering & Advanced Manufacturing, JCM 2022. Lecture Notes in Mechanical Engineering, P1471, DOI 10.1007/978-3-031-15928-2_128
   Bigné E, 2023, J BUS RES, V157, DOI 10.1016/j.jbusres.2022.113628
   Buswell GT., 1935, PEOPLE LOOK PICTURES, P169
   Carrara G., 1992, COMPUTER SUPPORTED D, P77
   Crilly N, 2004, DESIGN STUD, V25, P547, DOI 10.1016/j.destud.2004.03.001
   Ding M, 2022, DISPLAYS, V74, DOI 10.1016/j.displa.2022.102279
   Gong X, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su141710556
   Graf LKM, 2015, PERS SOC PSYCHOL REV, V19, P395, DOI 10.1177/1088868315574978
   Guo F, 2022, UNIVERSAL ACCESS INF, V21, P795, DOI 10.1007/s10209-021-00815-1
   Guo F, 2019, INT J IND ERGONOM, V71, P47, DOI 10.1016/j.ergon.2019.02.006
   Guo F, 2016, INT J IND ERGONOM, V53, P229, DOI 10.1016/j.ergon.2015.12.001
   H Alpay ER., 1997, Journal of Design History, V10, P293, DOI [10.1093/jdh/10.3.293, DOI 10.1093/JDH/10.3.293]
   Hou GH, 2019, INT J TECHNOL DES ED, V29, P543, DOI 10.1007/s10798-018-9450-7
   Hu H., 2022, Advances in Product Design Engineering, P199
   Hua YH, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-28331-7
   Hyerle D., 2000, A field guide to using visual tools, P89
   Ilhan AE, 2023, DISPLAYS, V76, DOI 10.1016/j.displa.2022.102335
   Ilhan E., 2020, GAZI U J SCI PART B, V8, P709
   Kahvecioglu NP, 2001, THESIS ISTANBUL TU
   Keinonen T, 1998, ONE DIMENSIONAL USAB, P156
   Kellaris J.J., 1993, Journal of Consumer Psychology, V2, P381, DOI [DOI 10.1207/S15327663JCP0204_03, 10.1016/S1057-7408(08)80068-X, DOI 10.1016/S1057-7408(08)80068-X, 10.1207/s15327663jcp0204_03]
   Khalighy S, 2015, INT J IND ERGONOM, V49, P31, DOI 10.1016/j.ergon.2015.05.011
   Krejtz K., 2014, P S EYE TRACK RES AP, P159, DOI DOI 10.1145/2578153.2578176
   Kuo LW, 2022, DISPLAYS, V71, DOI 10.1016/j.displa.2021.102108
   Li ML, 2022, J RETAIL CONSUM SERV, V67, DOI 10.1016/j.jretconser.2022.102990
   Li Wenshen., 2018, 2018 76th Device Research Conference (DRC), P1, DOI [DOI 10.1109/DRC.2018.8442245, DOI 10.1109/I2MTC.2018]
   Lidwell W, 2003, UNIVERSAL PRINCIPLES, P125
   Liu C, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062158
   Liu P, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/1791450
   Makin ADJ, 2016, I-PERCEPTION, V7, DOI 10.1177/2041669516637432
   Mandolesi S, 2022, J IMAGING, V8, DOI 10.3390/jimaging8010008
   Marshall B.H., 2014, Proceedings of the 3rd annual conference on Research in information technology, P3
   Naschitzki A, 2012, EYE TRACKING DESIGN
   Ngan HFB, 2022, J HOSP TOUR RES, V46, P100, DOI 10.1177/1096348020951226
   Norman D., 2004, EMOTIONAL DESIGN WHY, P23
   Palacios-Ibanez Almudena, 2024, IEEE Trans Vis Comput Graph, V30, P3636, DOI 10.1109/TVCG.2023.3238428
   Palmer SE, 2013, ANNU REV PSYCHOL, V64, P77, DOI 10.1146/annurev-psych-120710-100504
   Pascucci F, 2022, J NEUROSCI PSYCHOL E, V15, P89, DOI 10.1037/npe0000156
   Pei HN, 2022, DISPLAYS, V73, DOI 10.1016/j.displa.2022.102175
   Pradhan Annu, 2022, Advancements in Interdisciplinary Research: First International Conference, AIR 2022, Revised Selected Papers. Communications in Computer and Information Science (1738), P544, DOI 10.1007/978-3-031-23724-9_49
   Qu QX, 2019, INT J IND ERGONOM, V72, P281, DOI 10.1016/j.ergon.2019.06.006
   Rojas JC, 2020, IEEE GLOB ENG EDUC C, P127, DOI [10.1109/educon45650.2020.9125143, 10.1109/EDUCON45650.2020.9125143]
   Santella A, 2019, EYE TRACKING AESTHET
   Singh Jitender, 2022, Advances in Mechanical Engineering and Material Science: Select Proceedings of ICAMEMS-2022. Lecture Notes in Mechanical Engineering, P149, DOI 10.1007/978-981-19-0676-3_12
   Snyder E., 2015, J APPL PACKAGING RES, V7, P33
   Song SS, 2016, WOOD RES-SLOVAKIA, V61, P831
   Suhaimi SN, 2022, EMPIR STUD ARTS, DOI 10.1177/02762374221094137
   Sun HB, 2022, FOODS, V11, DOI 10.3390/foods11040505
   Takahashi R, 2018, J COMPUT DES ENG, V5, P449, DOI 10.1016/j.jcde.2017.12.007
   tobiipro, 2023, INTERNET SOURCE TOBI
   Uzun O, 2009, PROCD SOC BEHV, V1, P129, DOI 10.1016/j.sbspro.2009.01.024
   Wan Q, 2018, WOOD RES-SLOVAKIA, V63, P165
   Wan Q, 2018, WOOD RES-SLOVAKIA, V63, P727
   Wang FS, 2023, USER MODEL USER-ADAP, DOI 10.1007/s11257-022-09352-9
   Wang YH, 2020, ADV ENG INFORM, V45, DOI 10.1016/j.aei.2020.101095
   Xiao L, 2023, ASIA PAC J MARKET LO, V35, P472, DOI 10.1108/APJML-07-2021-0477
   Xu J., 2013, IEEE C ANTHOLOGY, P28
   Xu Y, 2022, DESIGN STUDIES INTEL, DOI [10.3233/FAIA220037, DOI 10.3233/FAIA220037]
   Xue L., 2018, J ENG TECHNOL-US, V6, P517
   Yapton MJ, 1998, YOUR LEARNING STYLE
   Zhu SY, 2022, ADV ENG INFORM, V52, DOI 10.1016/j.aei.2022.101601
   Zimmerer C, 2023, DESIGN COMPUTING AND COGNITION'22, P481, DOI 10.1007/978-3-031-20418-0_29
   Zuschke N, 2023, J BEHAV DECIS MAKING, V36, DOI 10.1002/bdm.2320
NR 65
TC 4
Z9 4
U1 18
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8013
EP 8042
DI 10.1007/s11042-023-15947-0
EA JUN 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001009907400001
DA 2024-07-18
ER

PT J
AU Annaby, M
   Fouda, Y
AF Annaby, Mahmoud
   Fouda, Yasser
TI Fast template matching and object detection techniques using
   <i>φ</i>-correlation and binary circuits
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Template matching; Bit-plane slices; Normalized correlation coefficient;
   phi-correlation coefficient; Boolean circuits
ID VENTRICULAR-TACHYCARDIA; ROTATION-INVARIANT; REENTRANT CIRCUITS; DEFECT
   DETECTION; NEURAL-NETWORKS; SINUS RHYTHM; ALGORITHM; SEGMENTATION;
   OPTIMIZATION; COEFFICIENT
AB In this paper, two new accelerated and robust template matching and object detection algorithms are established. The algorithms retain the accuracy measures compared to relevant well-known standard and recent schemes, and remarkably accelerate the execution time simultaneously. Instead of dealing with images in the grayscale or color representations, the proposed methods are established by measuring resemblance on extracted binary images. The two different techniques are based on the f-correlation coefficient and logical circuits. Both techniques enhance the accuracy, compared to two classical and two recent methods, while giving very efficient running time. The algorithms are carried out on two different datasets used in state-of-the-art methods with performance and comparison analysis. Robustness of the proposed algorithms against normal and artificial noises is examined and assured as well.
C1 [Annaby, Mahmoud] Cairo Univ, Fac Sci, Dept Math, Giza 12613, Egypt.
   [Fouda, Yasser] Mansoura Univ, Coll Sci, Math Dept, Comp Sci Div, Mansoura 35516, Egypt.
C3 Egyptian Knowledge Bank (EKB); Cairo University; Egyptian Knowledge Bank
   (EKB); Mansoura University
RP Annaby, M (corresponding author), Cairo Univ, Fac Sci, Dept Math, Giza 12613, Egypt.
EM mhannaby@sci.cu.edu.eg; ymafouda@mans.edu.eg
OI Fouda, Yasser/0000-0002-5236-0708
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Aggarwal A, 2021, MULTIMED TOOLS APPL, V80, P1289, DOI 10.1007/s11042-020-09520-2
   Ambrosini RD, 2010, J MAGN RESON IMAGING, V31, P85, DOI 10.1002/jmri.22009
   Annaby MH, 2019, IEEE T SEMICONDUCT M, V32, P199, DOI 10.1109/TSM.2019.2911062
   Annaby MH, 2021, OPT LASER ENG, V139, DOI 10.1016/j.optlaseng.2020.106474
   Atashpaz-Gargari E, 2007, IEEE C EVOL COMPUTAT, P4661, DOI 10.1109/CEC.2007.4425083
   Bator M, 2012, J DIGIT IMAGING, V25, P162, DOI 10.1007/s10278-011-9402-1
   Brunelli R., 2009, Template matching techniques in computer vision: theory and practice, DOI DOI 10.1002/9780470744055
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Choi MS, 2002, PATTERN RECOGN, V35, P119, DOI 10.1016/S0031-3203(01)00025-5
   Ciaccio EJ, 1999, J CARDIOVASC ELECTR, V10, P194, DOI 10.1111/j.1540-8167.1999.tb00661.x
   Ciaccio EJ, 2000, J CARDIOVASC ELECTR, V11, P446, DOI 10.1111/j.1540-8167.2000.tb00341.x
   Crispin AJ, 2007, INT J ADV MANUF TECH, V35, P293, DOI 10.1007/s00170-006-0730-0
   Dastanova N, 2018, IEEE ACCESS, V6, P18954, DOI 10.1109/ACCESS.2018.2819986
   Di Stefano L, 2005, PATTERN RECOGN LETT, V26, P2129, DOI 10.1016/j.patrec.2005.03.022
   Di Stefano L, 2003, MACH VISION APPL, V13, P213
   Duan HB, 2010, PATTERN RECOGN LETT, V31, P1868, DOI 10.1016/j.patrec.2009.12.005
   Ertas G, 2008, COMPUT BIOL MED, V38, P116, DOI 10.1016/j.compbiomed.2007.08.001
   Fredriksson K, 2005, THEOR COMPUT SCI, V347, P239, DOI 10.1016/j.tcs.2005.06.029
   Fu T, 2007, ENG APPL ARTIF INTEL, V20, P347, DOI 10.1016/j.engappai.2006.07.003
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   GREENHUT SE, 1992, PACE, V15, P2146, DOI 10.1111/j.1540-8159.1992.tb03038.x
   Hermann I, 2021, MAGN RESON MED, V86, P471, DOI 10.1002/mrm.28688
   Jung JH, 2010, IEEE SIGNAL PROC LET, V17, P107, DOI 10.1109/LSP.2009.2032452
   Kilic N, 2009, EXPERT SYST, V26, P378, DOI 10.1111/j.1468-0394.2009.00499.x
   Kilic N, 2009, J MED SYST, V33, P9, DOI 10.1007/s10916-008-9159-3
   Kurosaki K, 2009, PACE, V32, pS47, DOI 10.1111/j.1540-8159.2008.02226.x
   Lee WC, 2012, IEEE SIGNAL PROC LET, V19, P737, DOI 10.1109/LSP.2012.2212010
   Lei M, 2008, OPTOELECTRON LETT, V4, P379, DOI 10.1007/s11801-008-8043-1
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Lin YH, 2008, PATTERN RECOGN, V41, P2413, DOI 10.1016/j.patcog.2008.01.017
   LIU R, 1980, RES HIGH EDUC, V13, P3, DOI 10.1007/BF00975772
   Mahmood A, 2012, IEEE T IMAGE PROCESS, V21, P2099, DOI 10.1109/TIP.2011.2171696
   Mahmood A, 2010, IEEE T IMAGE PROCESS, V19, P2190, DOI 10.1109/TIP.2010.2046809
   Mattoccia S, 2008, IEEE T IMAGE PROCESS, V17, P528, DOI 10.1109/TIP.2008.919362
   Mattoccia S, 2011, PATTERN RECOGN LETT, V32, P694, DOI 10.1016/j.patrec.2010.12.004
   MCDONNELL MJ, 1981, COMPUT VISION GRAPH, V17, P65, DOI 10.1016/S0146-664X(81)80009-3
   Muramatsu S., 2003, Systems and Computers in Japan, V34, P81, DOI 10.1002/scj.1192
   Myers V, 2010, IEEE SIGNAL PROC LET, V17, P683, DOI 10.1109/LSP.2010.2051574
   Nguyen DT, 2018, IEEE SIGNAL PROC LET, V25, P1635, DOI 10.1109/LSP.2018.2862645
   Osman O, 2007, COMPUT BIOL MED, V37, P1167, DOI 10.1016/j.compbiomed.2006.10.007
   Padilla R, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030279
   Passos WL, 2018, P INT JOINT C NEUR N, P1
   Peng ZY, 2021, J REAL-TIME IMAGE PR, V18, P705, DOI 10.1007/s11554-020-01012-8
   Saitoh F, 2003, ELECTR ENG JPN, V145, P56, DOI 10.1002/eej.10235
   Tsai DM, 2003, PATTERN RECOGN LETT, V24, P2525, DOI 10.1016/S0167-8655(03)00098-9
   Uz T, 2009, COMPUT VIS IMAGE UND, V113, P979, DOI 10.1016/j.cviu.2009.04.002
   Vidal C, 2010, INT J COMPUT VISION, V88, P189, DOI 10.1007/s11263-009-0258-5
   Warrens MJ, 2008, PSYCHOMETRIKA, V73, P487, DOI 10.1007/s11336-008-9059-y
   Xia HY, 2019, MULTIMED TOOLS APPL, V78, P11905, DOI 10.1007/s11042-018-6722-x
   Yamaguchi T, 2019, IEEE SIGNAL PROC LET, V26, P1857, DOI 10.1109/LSP.2019.2951305
   Yang H, 2019, IEEE T IMAGE PROCESS, V28, P3061, DOI 10.1109/TIP.2019.2893743
   Yoo JC, 2010, DIGIT SIGNAL PROCESS, V20, P1482, DOI 10.1016/j.dsp.2010.01.002
   Yoon YG, 2008, COMPUT IND ENG, V55, P567, DOI 10.1016/j.cie.2008.01.015
NR 53
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6469
EP 6496
DI 10.1007/s11042-023-15564-x
EA JUN 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001005496300003
OA hybrid
DA 2024-07-18
ER

PT J
AU Song, Q
   Zhou, Y
   Hu, MJ
   Liu, C
AF Song, Qing
   Zhou, Yang
   Hu, Mengjie
   Liu, Chun
TI Faster learning of temporal action proposal via sparse multilevel
   boundary generator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Temporal action localization; Temporal action proposal generation;
   Temporal action detection; Boundary-sensitive method; Sparse Multilevel
   Boundary Generator (SMBG)
AB Temporal action localization in videos presents significant challenges in the field of computer vision. While the boundary-sensitive method has been widely adopted, its limitations include incomplete use of intermediate and global information, as well as an inefficient proposal feature generator. To address these challenges, we propose a novel framework, Sparse Multilevel Boundary Generator (SMBG), which enhances the boundary-sensitive method with boundary classification and action completeness regression. SMBG features a multi-level boundary module that enables faster processing by gathering boundary information at different lengths. Additionally, we introduce a sparse extraction confidence head that distinguishes information inside and outside the action, further optimizing the proposal feature generator. To improve the synergy between multiple branches and balance positive and negative samples, we propose a global guidance loss. Our method is evaluated on two popular benchmarks, ActivityNet-1.3 and THUMOS14, and is shown to achieve state-of-the-art performance, with a better inference speed (2.47xBSN++, 2.12xDBG). These results demonstrate that SMBG provides a more efficient and simple solution for generating temporal action proposals. Our proposed framework has the potential to advance the field of computer vision and enhance the accuracy and speed of temporal action localization in video analysis.The code and models are made available at .
C1 [Song, Qing; Zhou, Yang; Hu, Mengjie; Liu, Chun] Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligent Vis, Xi Tu Cheng Rd, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Liu, C (corresponding author), Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligent Vis, Xi Tu Cheng Rd, Beijing 100876, Peoples R China.
EM priv@bupt.edu.cn; zhouyang2020@bupt.edu.cn; mengjie.hu@bupt.edu.cn;
   chun.liu@bupt.edu.cn
RI Chen, John/GPW-8839-2022; Liu, Chun/I-1886-2016
OI Liu, Chun/0000-0002-2834-9461
FU National Key R&D Program of China [2022YFC3302200]
FX This work was supported by the National Key R&D Program of China
   (GrantNo.2022YFC3302200).
CR Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Gao JL, 2020, AAAI CONF ARTIF INTE, V34, P10810
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Lin C, 2020, P AAAI C ART INT, p11,499
   Lin TW, 2019, IEEE I CONF COMP VIS, P3888, DOI 10.1109/ICCV.2019.00399
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   Liu YF, 2019, PROC CVPR IEEE, P7099, DOI [10.1109/CVPR.2019.00726, 10.1109/CVPR.2019.00372]
   Nasiri E, 2023, MULTIMED TOOLS APPL, V82, P3745, DOI 10.1007/s11042-022-12943-8
   Qing ZW, 2021, PROC CVPR IEEE, P485, DOI 10.1109/CVPR46437.2021.00055
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami M, 2020, GENOMICS, V112, P4370, DOI 10.1016/j.ygeno.2020.07.027
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Simonyan K, 2014, ADV NEUR IN, V27
   Su HS, 2021, AAAI CONF ARTIF INTE, V35, P2602
   Tan J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13506, DOI 10.1109/ICCV48922.2021.01327
   Vaswani A, 2017, ADV NEUR IN, V30
   Vo K, 2021, IEEE ACCESS, V9, P126431, DOI 10.1109/ACCESS.2021.3110973
   Yang HS, 2022, AAAI CONF ARTIF INTE, P3054
   Yueran Bai, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P121, DOI 10.1007/978-3-030-58604-1_8
NR 20
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 9121
EP 9136
DI 10.1007/s11042-023-15308-x
EA JUN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001000907700005
DA 2024-07-18
ER

PT J
AU Liu, DL
   Yao, HX
AF Liu, Dilin
   Yao, Hongxun
TI Artistic image synthesis with tag-guided correlation matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artistic image synthesis; Conditional image translation;
   Nonphotorealistic rendering; Label guidance
AB Artistic image synthesis is receiving increasing engagement in the multimedia community because of the development and improvement of generative adversarial networks. Digital art synthesis methods perform uncontrolled manipulation in complicated landscape scenarios because of the domain diversity of the paintings. To solve this problem, this paper presents the tag-guided correlation matrix for matching the tag with the content code from the source image as better guidance on the style code. Correspondingly, the new generator module adapts the warped style code onto the semantic feature for controllable synthesis. Extensive experiments in several image synthesis tasks show the effectiveness of the proposed method in generating images with variations or multi-tag combinations. In addition, the proposed method shows better quantitative performance than recent conditional image synthesis approaches in artistic image manipulation tasks.
C1 [Liu, Dilin; Yao, Hongxun] Harbin Inst Technol, Dept Sch Comp Sci & Technol, Dazhi St West 92, Harbin 150006, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Liu, DL (corresponding author), Harbin Inst Technol, Dept Sch Comp Sci & Technol, Dazhi St West 92, Harbin 150006, Heilongjiang, Peoples R China.
EM liudilin@hit.edu.cn; h.yao@hit.edu.cn
OI Liu, Dilin/0000-0003-1462-3674
FU National Key R&D Program of China [2021ZD0110901]
FX AcknowledgmentsThis work is supported by the National Key R&D Program of
   China (No. 2021ZD0110901).
CR Abdal R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3447648
   Adeniyi JK., 2022, PARADIGMPLUS, V3, P1, DOI [10.55969/paradigmplus.v3n3a1, DOI 10.55969/PARADIGMPLUS.V3N3A1]
   Cohen N, 2022, COMPUT GRAPH FORUM, V41, P261, DOI 10.1111/cgf.14473
   Dobler K, 2022, Arxiv, DOI arXiv:2202.11777
   Garg M, 2023, MULTIMED TOOLS APPL, V82, P6271, DOI 10.1007/s11042-022-13596-3
   Ghodhbani H, 2023, MULTIMED TOOLS APPL, V82, P23151, DOI 10.1007/s11042-022-14127-w
   Hensel M, 2017, ADV NEUR IN, V30
   Hwang S, 2022, MULTIMED TOOLS APPL, V81, P40269, DOI 10.1007/s11042-022-12934-9
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim G, 2022, PROC CVPR IEEE, P2416, DOI 10.1109/CVPR52688.2022.00246
   Kingma D. P., 2014, arXiv
   Kumar SS, 2022, CMC-COMPUT MATER CON, V72, P281, DOI 10.32604/cmc.2022.023693
   Long J.L., 2014, Advances in neural information processing systems, V27, P1601
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Pirrone R, 2009, INT CONF INTELL SYST, P913, DOI 10.1109/ISDA.2009.219
   Qi YH, 2022, MULTIMED TOOLS APPL, V81, P35935, DOI 10.1007/s11042-022-13342-9
   Raja DRK, 2022, Int J Perform Eng, V18, P298
   Saharia C., 2022, ACM SIGGRAPH 2022 C, P1
   Samuth B, 2022, IEEE IMAGE PROC, P3490, DOI 10.1109/ICIP46576.2022.9897334
   Shi J., 2022, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P19730
   Thamizharasan V, 2023, MULTIMED TOOLS APPL, V82, P10471, DOI 10.1007/s11042-022-13224-0
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Tu C-T, 2022, MULTIMED TOOLS APPL, P1
   Tu H, 2023, MOD INTELLECT HIST, V20, P323, DOI 10.1017/S1479244322000063
   Woo Kim Min, 2023, 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), P744, DOI 10.1109/WACV56688.2023.00081
   Zhang P, 2020, PROC CVPR IEEE, P5142, DOI 10.1109/CVPR42600.2020.00519
   Zheng Z, 2022, IEEE T MULTIMED
NR 29
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 31
PY 2023
DI 10.1007/s11042-023-15182-7
EA MAY 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H9TW0
UT WOS:000999312400002
DA 2024-07-18
ER

PT J
AU Chen, PY
   Zhao, L
   Piao, YHR
   Ding, HW
   Cui, XH
AF Chen, Pengyuan
   Zhao, Lei
   Piao, Yangheran
   Ding, Hongwei
   Cui, Xiaohui
TI Multimodal visual-textual object graph attention network for propaganda
   detection in memes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Propaganda detection; Multimodal; Graph neural network; Attention
   mechanism
AB Propaganda as a purposeful form of communication deserves vigilance for its persuasiveness. With the emergence of social media, most propaganda is multimodal content such as online memes. This paper study the propaganda techniques detection in memes, which is a newly proposed multi-label multimodal task. Since understanding both modalities and their relationship is essential for detection, we introduce a novel classification composed of four modules: (1) the global-level feature encoder to obtain global image and text feature representation, (2) the region-level feature encoder to extract the most informative parts of multimodal content, namely textual and visual objects, (3) our proposed multimodal visual-textual object graph attention network (MViTO-GAT) model which aims to learn the semantic and positional relationships between visual and textual objects through attention-based sequential intra-modality and cross-modality graph reasoning, and (4) the multimodal fusion and classification module where global-level feature is exploited as complementary information of relationship-enhanced region-level feature representation and combined for final prediction. Experimental results show that our method outperforms the state-of-the-art unimodal and multimodal baselines. Moreover, an ablation experiment is designed to demonstrate the benefit of each component of the MViTO-GAT model.
C1 [Chen, Pengyuan; Zhao, Lei; Piao, Yangheran; Ding, Hongwei; Cui, Xiaohui] Wuhan Univ, Sch Cyber Sci & Engn, Wuhan 430072, Hubei, Peoples R China.
   [Chen, Pengyuan; Zhao, Lei; Piao, Yangheran; Ding, Hongwei; Cui, Xiaohui] Minist Educ, Key Lab Aerosp Informat Secur & Trusted Comp, Wuhan, Peoples R China.
C3 Wuhan University
RP Cui, XH (corresponding author), Wuhan Univ, Sch Cyber Sci & Engn, Wuhan 430072, Hubei, Peoples R China.; Cui, XH (corresponding author), Minist Educ, Key Lab Aerosp Informat Secur & Trusted Comp, Wuhan, Peoples R China.
EM pengyuanchen@whu.edu.cn; zhao_lei@whu.edu.cn; cdra_90n@whu.edu.cn;
   hwding@whu.edu.cn; xcui@whu.edu.cn
FU National Key R&D Program of China [2018YFC1604000]; RD Program
   [G20220126]
FX The numerical calculations in this paper have been done on the
   supercomputing system in the Supercomputing Center of Wuhan University.
   This research was supported by the National Key R&D Program of China
   (No.2018YFC1604000). This research was supported by the R&D Program
   (No.G20220126).
CR Barrón-Cedeño A, 2019, INFORM PROCESS MANAG, V56, P1849, DOI 10.1016/j.ipm.2019.03.005
   Casanova Arantxa, 2018, INT C LEARNING REPRE
   Chen PY, 2021, LECT NOTES COMPUT SC, V12893, P269, DOI 10.1007/978-3-030-86365-4_22
   Da San Martino G, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5636
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dimitrov D., 2021, arXiv preprint arXiv:2109.08013, V1, P6603
   Gori M, 2005, IEEE IJCNN, P729
   Habernal I, 2017, Arxiv, DOI arXiv:1707.06002
   Li LH, 2019, Arxiv, DOI [arXiv:1908.03557, DOI 10.48550/ARXIV.1908.03557]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Pengcheng, 2020, arXiv, DOI 10.48550/arXiv.2006.03654
   Kiela D, 2020, ADV NEURAL INF PROCE, V33
   Kiela D, 2020, Arxiv, DOI arXiv:1909.02950
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lee AM, 1945, AM J SOCIOL, V51, P126, DOI 10.1086/219744
   Lee RKW, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5138, DOI 10.1145/3474085.3475625
   Li KP, 2019, IEEE I CONF COMP VIS, P4653, DOI 10.1109/ICCV.2019.00475
   Liang W, 2021, P 3 WORKSHOP MULTIMO, P79
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu T., 2021, 2020 IEEE INFORM THE, P1
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Lu JS, 2019, ADV NEUR IN, V32
   Lu LH, 2020, IEEE T MULTIMEDIA, V22, P524, DOI 10.1109/TMM.2019.2930344
   Martino G.D.S., 2020, arXiv, DOI [10.48550/arXiv.2007.08024, DOI 10.48550/ARXIV.2007.08024]
   Mohammad SM, 2017, ACM T INTERNET TECHN, V17, DOI 10.1145/3003433
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Pramanick S, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4439
   Qi P, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P101
   Radford A, 2021, PR MACH LEARN RES, V139
   Rashkin Hannah, 2017, P C EMP METH NAT LAN, P2931
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sharma C., 2020, P 14 WORKSHOP SEMANT, P759, DOI DOI 10.18653/V1/2020.SEMEVAL-1.99
   Sharma H, 2021, IMAGE VISION COMPUT, V110, DOI 10.1016/j.imavis.2021.104165
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Wang R., 2020, RED HERRING, V24, P0
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Ze Hu, 2020, 2020 IEEE Fifth International Conference on Data Science in Cyberspace (DSC). Proceedings, P218, DOI 10.1109/DSC50466.2020.00040
   Zhou Y, 2021, 2021 IEEE INT C MULT, P1
   Zhu R, 2020, Arxiv, DOI arXiv:2012.08290
NR 40
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 30
PY 2023
DI 10.1007/s11042-023-15272-6
EA MAY 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0PB2
UT WOS:000999869700003
DA 2024-07-18
ER

PT J
AU Huang, K
   Xu, ZJ
AF Huang, Kan
   Xu, Zhijing
TI Lightweight video salient object detection via channel-shuffle enhanced
   multi-modal fusion network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video salient object detection; Lightweight model; Multi-modal fusion
ID OPTIMIZATION; MODEL
AB Video salient object detection (VSOD) has witnessed great development with the application of deep neural networks. However, the high computational cost of neural networks has hindered the deployment of VSOD models in real-world applications.In this work, we focus on developing lightweight VSOD model. The main issues involved in designing lightweight video saliency models include: how to combine multi-modal information (i.e., spatial and temporal information) and model multi-scale spatial context in an efficient setting. To tackle these issues, we propose a lightweight neural network architecture for VSOD. We start by adopting the ImageNet-pretrained ShuffleNet-V2 for deep feature extraction. Based on the backbone network, a Depth-wise Multi-scale Pooling Module (DMPM) is proposed to aggregate multi-scale spatial context information, which occupies only a small amount of parameters and computational overheads. Most importantly, a Shuffle enhanced Multi-modal Fusion Module (SMFM) is proposed to fuse spatial and temporal information progressively in an efficient manner, deriving the final saliency prediction. With these proposed modules, our method could achieve competitive detection accuracy with current outstanding methods while holding a much smaller model size. Specifically, the proposed model could run at a GPU speed of 49.2 FPS and hold only 1.9M parameters, making it suitable for real-time applications.
C1 [Huang, Kan; Xu, Zhijing] Shanghai Maritime Univ, Coll Informat Engn, Shanghai, Peoples R China.
C3 Shanghai Maritime University
RP Huang, K (corresponding author), Shanghai Maritime Univ, Coll Informat Engn, Shanghai, Peoples R China.
EM huangkan@shmtu.edu.cn; zjxu@shmtu.edu.cn
FU National Natural Science Foundation of China [62101316]
FX AcknowledgementsThis work was supported by the National Natural Science
   Foundation of China under Grant 62101316.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2016, ENET DEEP NEURAL NET
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P3995, DOI 10.1109/TIP.2021.3068644
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Chen YH, 2018, IEEE T IMAGE PROCESS, V27, P3345, DOI 10.1109/TIP.2018.2813165
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kim H, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425544
   Lee H, 2018, IEEE WINT CONF APPL, P1170, DOI 10.1109/WACV.2018.00133
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Li GB, 2018, PROC CVPR IEEE, P3243, DOI 10.1109/CVPR.2018.00342
   Li HF, 2019, IEEE I CONF COMP VIS, P7273, DOI 10.1109/ICCV.2019.00737
   Li J, 2018, IEEE T IMAGE PROCESS, V27, P349, DOI 10.1109/TIP.2017.2762594
   Li S, 2018, P EUR C COMP VIS ECC
   Li YS, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P458, DOI 10.1109/ICCV48922.2021.00052
   Liu Y, 2021, IEEE T CYBERNETICS, V51, P4439, DOI 10.1109/TCYB.2020.3035613
   Liu Z, 2017, IEEE T CIRC SYST VID, V27, P2527, DOI 10.1109/TCSVT.2016.2595324
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shafieyan F, 2014, IEEE IMAGE PROC, P1155, DOI 10.1109/ICIP.2014.7025230
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tang Y, 2019, IEEE T CIRC SYST VID, V29, P1973, DOI 10.1109/TCSVT.2018.2859773
   Le TN, 2018, IEEE T IMAGE PROCESS, V27, P5002, DOI 10.1109/TIP.2018.2849860
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2019, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2019.00318
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Yan PX, 2019, IEEE I CONF COMP VIS, P7283, DOI 10.1109/ICCV.2019.00738
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao WB, 2021, PROC CVPR IEEE, P16821, DOI 10.1109/CVPR46437.2021.01655
   Zhao X., 2020, P EUR C COMP VIS, P35, DOI 10.1007/ 978-3-030-58536-5_3
NR 47
TC 0
Z9 0
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 30
PY 2023
DI 10.1007/s11042-023-15251-x
EA MAY 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0PB2
UT WOS:000999869700002
DA 2024-07-18
ER

PT J
AU Agarwal, C
   Bhatnagar, C
AF Agarwal, Chandni
   Bhatnagar, Charul
TI Unmasking the potential: evaluating image inpainting techniques for
   masked face reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Generative Adversarial Network; Face reconstruction; Image Inpainting;
   Face inpainting; Deep learning; Masked Face Recognition; Face
   Recognition
AB The performance of most Face Recognizers tends to degrade when dealing with masked faces, making face recognition challenging. Image inpainting, a technique traditionally used for restoring old or damaged images, removing objects, or retouching photos, could potentially aid in reconstructing masked faces. In this paper, we compared three state-of-the-art image inpainting models-PatchMatch, a traditional algorithm, and two deep learning GAN-based models, Edge Connect and Free form image inpainting-to assess their performance in regenerating masked faces. The evaluation was conducted using own created synthetic datasets MaskedFace-CelebA and MaskedFace-CelebA-HQ, along with a synthetic masked dataset created for paired comparisons of masked images with ground truth for face verification. The computed results for Image Quality Assessment (IQA) between ground truth and reconstructed facial images indicated that the Gated Convolution model performed better than the other two models. To further validate the results, the reconstructed and ground truth images were also subject to VGG16 classifier, a widely used benchmark model for image recognition. The classifier outcomes supported the quantitative and qualitative assessment based on IQA.
C1 [Agarwal, Chandni; Bhatnagar, Charul] GLA Univ, Mathura, India.
C3 GLA University
RP Agarwal, C (corresponding author), GLA Univ, Mathura, India.
EM chandni.officialid@gmail.com; charul@gla.ac.in
RI Agarwal, Chandni/JCT-3987-2023
OI Agarwal, Chandni/0000-0001-8387-5969
CR All about Structural Similarity Index (SSIM), ALL STRUCT SIM IND S
   [Anonymous], 2012, ADV NEURAL INF PROCE
   Anwar A, 2020, Arxiv, DOI arXiv:2008.11104
   Arya K.V., 2019, The Biometric Computing: Recognition and Registration, DOI DOI 10.1201/9781351013437
   Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Barnes C., 2010, LECT NOTES COMPUT SC, V6313, P29
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Chen F, 2022, COMPUT ELECTR ENG, V103, DOI 10.1016/j.compeleceng.2022.108282
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Elharrouss O, 2020, NEURAL PROCESS LETT, V51, P2007, DOI 10.1007/s11063-019-10163-0
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Inamdar M, 2020, 3663305 SSRN
   Jain V., 2009, PROC ADV NEURAL INFO, P769
   Jiang M., 2020, RETINAMASK FACE MASK
   Jiang Y, 2020, IEEE ACCESS, V8, P22884, DOI 10.1109/ACCESS.2020.2970169
   Jignesh Chowdary G., 2020, Big Data Analytics. 8th International Conference, BDA 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12581), P81, DOI 10.1007/978-3-030-66665-1_6
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Li YJ, 2017, PROC CVPR IEEE, P5892, DOI 10.1109/CVPR.2017.624
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu HY, 2021, Arxiv, DOI arXiv:2105.02201
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Nazeri K., 2019, arXiv
   ni, SIGN TO NOIS RAT IM
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Qin Z, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102028
   Rother C, 2006, ACM T GRAPHIC, V25, P847, DOI 10.1145/1141911.1141965
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sengar Neha, 2022, Proceedings of the Seventh International Conference on Mathematics and Computing: ICMC 2021. Advances in Intelligent Systems and Computing (1412), P373, DOI 10.1007/978-981-16-6890-6_28
   Sethy Prabira Kumar, 2022, Intelligent and Cloud Computing: Proceedings of ICICC 2021. Smart Innovation, Systems and Technologies (286), P317, DOI 10.1007/978-981-16-9873-6_29
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   wandb.ai, EV GANS US FRECH INC
   Wang N, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107448
   Yang C, 2017, PROC CVPR IEEE, P4076, DOI 10.1109/CVPR.2017.434
   Yang XH, 2021, IEEE ACCESS, V9, P42100, DOI 10.1109/ACCESS.2021.3065661
   Yao F, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5904043
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zeng Y, 2020, PATTERN RECOGN LETT, V133, P158, DOI 10.1016/j.patrec.2020.02.033
   Zheng CX, 2019, PROC CVPR IEEE, P1438, DOI 10.1109/CVPR.2019.00153
NR 45
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 29
PY 2023
DI 10.1007/s11042-023-15807-x
EA MAY 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H4OO5
UT WOS:000995776100001
PM 37362642
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Liu, J
   Xian, XH
   Hou, ZJ
   Liang, JZ
   Liu, H
AF Liu, Jun
   Xian, Xuhua
   Hou, Zhenjie
   Liang, Jiuzhen
   Liu, Hao
TI Safety helmet wearing correctly detection based on capsule network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Construction safety; Deep learning; Capsule network; Safety helmet
   wearing detection
AB Construction workers protect themselves from accidental injury by wearing safety helmets correctly. The safety helmet wearing detection algorithms currently based on deep learning aim to solve the problem of whether the safety helmet is worn in the head region, rather than whether the safety helmet is worn properly. This paper presents a novel Spatial Position Relation Capsule Network, termed SPR-CapsNet, for addressing safety helmet wearing correctly detection. In the first step, the learned deep feature maps are divided into patches, and each patch is transformed into a vector as a primary capsule, which effectively reduces the computational cost. In the second step, the dynamic routing algorithm is used to learn the spatial relationship between local image features. In the final step, the decision-making is optimized based on the probability of different dimensions of the output vector. It will be recognized as wearing status when the safety helmet is in a more appropriate position relative to the face. SPR-CapsNet is compared with the original Capsule Network, Convolutional Neural Network (CNN), Vision Transformer (ViT), and other models on a large amount of data. Experiments demonstrate the superiority of the proposed network.
C1 [Liu, Jun; Xian, Xuhua; Hou, Zhenjie; Liang, Jiuzhen; Liu, Hao] Changzhou Univ, Sch Comp Sci & Artificial Intelligence, Changzhou 213164, Peoples R China.
C3 Changzhou University
RP Liu, J (corresponding author), Changzhou Univ, Sch Comp Sci & Artificial Intelligence, Changzhou 213164, Peoples R China.
EM liujun@cczu.edu.cn; s21150812041@smail.cczu.edu.cn; houzj@cczu.edu.cn;
   jzliang@cczu.edu.cn; helenliuhao@cczu.edu.cn
CR Al-Saffar Marwa Fadhil, 2019, Biochemical and Cellular Archives, V19, P203
   Baker N, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006613
   Bozkurt F, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6725
   Brendel Wieland, 2019, ARXIV190400760
   Chen S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155129
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Deng LX, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-15272-w
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Fan Y, 2020, ANAL DEPENDENCY CONV, V12544, P101
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Fekri-Ershad S, 2022, COMPUT BIOL MED, V144, DOI 10.1016/j.compbiomed.2022.105392
   Gu YW, 2021, IET IMAGE PROCESS, V15, P2441, DOI 10.1049/ipr2.12231
   Nguyen HH, 2019, Arxiv, DOI arXiv:1910.12467
   Hahn T., 2019, Advances in neural information processing systems, V32, P7658
   Han G, 2021, COMPUT ELECTR ENG, V95, DOI 10.1016/j.compeleceng.2021.107458
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G.E., 2018, INT C LEARN REPR
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Hosseini H, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P352, DOI 10.1109/ICMLA.2017.0-136
   Li J, 2017, 2017 NINTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P201, DOI 10.1109/ICACI.2017.7974509
   Li YG, 2020, ADV CIV ENG, V2020, DOI 10.1155/2020/9703560
   Liu Y, 2019, IEEE I CONF COMP VIS, P1232, DOI 10.1109/ICCV.2019.00132
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Rubaiyat AM, 2016, 2016 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE WORKSHOPS (WIW 2016), P135, DOI [10.1109/WIW.2016.10, 10.1109/WIW.2016.045]
   Sabour Sara, 2017, Advances in Neural Information Processing Systems, P3856
   Sadiq M, 2022, INT J FUZZY SYST, V24, P2600, DOI 10.1007/s40815-022-01267-2
   Shan Du, 2011, 2011 3rd International Conference on Computer Research and Development (ICCRD 2011), P25, DOI 10.1109/ICCRD.2011.5763846
   Shen J, 2021, COMPUT-AIDED CIV INF, V36, P180, DOI 10.1111/mice.12579
   Shrestha K., 2015, J CONSTRUCTION ENG, V2015, P1, DOI [10.1155/2015/721380, DOI 10.1155/2015/721380]
   Silva R, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P141, DOI 10.1109/SIBGRAPI.2014.28
   Singh M, 2018, IEEE COMPUT SOC CONF, P592, DOI 10.1109/CVPRW.2018.00089
   Tsai Y.-H. H., 2020, ARXIV200204764, P1
   Wang HK, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196732
   Wang ZJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21103478
   Waranusast R, 2013, INT CONF IMAG VIS, P35, DOI 10.1109/IVCNZ.2013.6726989
   Wójcik B, 2022, Arxiv, DOI arXiv:2106.10944
   Wu JX, 2019, AUTOMAT CONSTR, V106, DOI 10.1016/j.autcon.2019.102894
   Xi ED, 2017, Arxiv, DOI [arXiv:1712.03480, 10.48550/arXiv.1712.03480]
   Xiong RX, 2021, AUTOMAT CONSTR, V130, DOI 10.1016/j.autcon.2021.103828
   Yang ZL, 2019, Arxiv, DOI arXiv:1903.10588
   Yue SQ, 2022, MULTIMED TOOLS APPL, V81, P16783, DOI 10.1007/s11042-022-12014-y
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
NR 42
TC 0
Z9 0
U1 11
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 29
PY 2023
DI 10.1007/s11042-023-15309-w
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H8LP5
UT WOS:000998414300006
DA 2024-07-18
ER

PT J
AU Al Dujaili, MJ
   Dhaam, HZ
   Mezeel, MT
AF Al Dujaili, Mohammed Jawas
   Dhaam, Haidar Zaeer
   Mezeel, Mushtaq Talib
TI An intelligent fall detection algorithm for elderly monitoring in the
   internet of things platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Internet of Things (IoT); Data mining; Clustering; Health monitoring;
   Elderly monitoring; Deep learning; Fall detection; ECG signal
AB In recent years, the elderly population has increased, which requires more research on their health status. IoT has revolutionized device connectivity and remote access, making it an ideal solution for medical telemetry. Various plans have been presented to use the Internet of Things in the field of health. One of these plans is a fall detection system and notification to health centres and elderly families. One of the most critical requirements of fall detection algorithms is their accuracy. It is essential that the fall detection algorithm does not falsely send an alert to the elderly family, nurse or physician. Therefore, the accuracy of the fall detection algorithm should be increased by adding other techniques. In the proposed method of this research, this issue is solved by providing an intelligent framework based on clustering and ECG signal. The accuracy rate of the proposed detection algorithm is 97.1%.
C1 [Al Dujaili, Mohammed Jawas] Univ Kufa, Fac Engn, Dept Elect & Commun, Najaf, Iraq.
   [Dhaam, Haidar Zaeer] Al Furat Al Awsat Tech Univ ATU, Tech Engn Coll Najaf, Dept Laser & Optoelect Tech Engn, Najaf, Iraq.
   [Mezeel, Mushtaq Talib] Najaf Prov Council, Najaf, Iraq.
C3 University of Kufa; Al-Furat Al-Awsat Technical University
RP Al Dujaili, MJ (corresponding author), Univ Kufa, Fac Engn, Dept Elect & Commun, Najaf, Iraq.
EM Mohammed.challab@uokufa.edu.iq; haidar.dhaam@atu.edu.iq;
   mshtqtlb@gmail.com
RI Zaeer Dhaam, Haidar/GNP-1655-2022; Talib, Mushtaq/KUC-7850-2024
OI Zaeer Dhaam, Haidar/0000-0001-6628-3830; AL_Dujaili, Mohammed
   Jawad/0000-0002-3804-6667
CR Alatoun K, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145327
   Bhatia M, 2017, COMPUT IND, V92-93, P50, DOI 10.1016/j.compind.2017.06.009
   Chauhan K, 2019, INT J RECENT TECHNOL, V8, P811
   Chen T., 2018, IEEE T SYST MAN CY-S, V48, P1365
   Clark N, 2018, MIDWEST SYMP CIRCUIT, P787, DOI 10.1109/MWSCAS.2018.8624097
   Darshan KR, 2015, 2015 INTERNATIONAL CONFERENCE ON EMERGING RESEARCH IN ELECTRONICS, COMPUTER SCIENCE AND TECHNOLOGY (ICERECT), P132, DOI 10.1109/ERECT.2015.7499001
   Gjoreski M, 2017, SENSORS-BASEL, V17, P1747
   Hossain M, 2018, FUTURE GENER COMP SY, V82, P422, DOI 10.1016/j.future.2017.11.020
   Hu S., 2020, IEEE ACCESS, V8
   Iqbal SMH, 2020, SENSORS-BASEL, V20, P2071
   Kaur K, 2018, INT J ENG TECHNOLOGY, V7, P56
   Lakhan A, 2022, IEEE T NETW SCI ENG
   Lee I, 2015, BUS HORIZONS, V58, P431, DOI 10.1016/j.bushor.2015.03.008
   Liu CY, 2019, IEEE INTERNET THINGS, V6, P1363, DOI 10.1109/JIOT.2018.2844090
   Mishra Subhra Shriti, 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1052, DOI 10.1109/ICOEI.2019.8862763
   Neyja M, PROC IEEE GLOBAL COM, P1
   Ray P.P., 2014, CALCON, P32
   Rehman N, 2016, SENSORS-BASEL, V16, P1322
   Ren LM, 2019, IEEE ACCESS, V7, P77702, DOI 10.1109/ACCESS.2019.2922708
   Saleh M, 2019, IEEE SENS J, V19, P3156, DOI 10.1109/JSEN.2019.2891128
   Selvaraj S, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1925-y
   Shahzad A, 2019, IEEE T IND INFORM, V15, P35, DOI 10.1109/TII.2018.2839749
   Shin S., 2020, SENSORS-BASEL, V20, P684
   Stojanov G., 2020, SENSORS-BASEL, V20, P2256
   Sucerquia A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010198
   Vedaraj M, 2021, J AMB INTEL HUM COMP, V12, P7333, DOI 10.1007/s12652-020-02408-x
   Verma P, 2018, J PARALLEL DISTR COM, V116, P27, DOI 10.1016/j.jpdc.2017.11.018
   Vishwanatham A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ADVANCED NETWORKS AND TELECOMMUNICATIONS SYSTEMS (ANTS)
   Wannenburg J, 2018, IEEE SENS J, V18, P6023, DOI 10.1109/JSEN.2018.2844122
   Wu Y, 2019, IEEE ACCESS, V7, P51297
   Yacchirema D, 2019, PERS UBIQUIT COMPUT, V23, P801, DOI 10.1007/s00779-018-01196-8
   Zhang J, 2018, PROC 11 INT C IMAGE, P1
   Zhang J., 2020, SENSORS-BASEL, V20, P2849
   Zigel Y, 2009, C P ANN INT C IEEE E, V2009, P3566
NR 34
TC 1
Z9 1
U1 9
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 17
PY 2023
DI 10.1007/s11042-023-15820-0
EA MAY 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7EQ1
UT WOS:000990751100009
DA 2024-07-18
ER

PT J
AU Telem, ANK
   Fonzin, TF
   Sone, ME
   Tabekoueng, ZN
   Fotsin, HB
AF Telem, Adelaide Nicole Kengnou
   Fonzin, Theophile Fozin
   Sone, Michael Ekonde
   Tabekoueng, Zeric Njitacke
   Fotsin, Hilaire Bertrand
TI A chaos-based DS-CDMA transmission and synchronization for multi-leads
   medical ECG/EEG through AWGN and Rayleigh Channels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Biomedical multichannel ECG; EEG signals; Chaos; DS-CDMA; AWGN channel;
   Rayleigh flat fading channel; Synchronization
ID SEQUENCE SYNCHRONIZATION; ACQUISITION PERFORMANCE; SPREADING SEQUENCES;
   CODE ACQUISITION; ECG TRANSMISSION; ULTIMATE LIMITS; SYSTEM; UNIT;
   SIMULATION
AB For telemedicine purpose, simultaneous transmission of biomedical multichannel signals remains problematic. There is a need to transmit all the channels without creating distortions such as delay, inversion of the signal parts. Multiple access techniques are more indicated. In this paper, we proposed a multi-user direct sequence code division multiple access (DS-CDMA) based chaotic communication system to simulate the transmission of biomedical multichannel electrocardiogram (ECG) signals and electroencephalogram (EEG) signals in the same bandwidth. We used binary chaotic sequences to spread the ECG/EEG signals and the Walsh sequences as pilot signals. The performance of the proposed system is evaluated in the presence of Additive White Gaussian Noise (AWGN) channel and in the presence of the Rayleigh flat fading channel. We achieved the code acquisition that represents the first stage of the synchronization process in the presence of AWGN channel and in the presence of the Rayleigh flat fading channel. We evaluated the code acquisition stage in term of the probability of detection and probability of false alarm. We used the time delay estimated by the code acquisition to despread the received signal. The low bit error rate obtained confirms the effectiveness of the synchronization unit, the effectiveness and the robustness of the proposed system.
C1 [Telem, Adelaide Nicole Kengnou; Sone, Michael Ekonde; Tabekoueng, Zeric Njitacke] Univ Buea, Coll Technol COT, Dept Elect & Elect Engn, POB 63, Buea, Cameroon.
   [Telem, Adelaide Nicole Kengnou; Fotsin, Hilaire Bertrand] Univ Dschang, Fac Sci, Dept Phys, Lab Rech Matiere Condensee Elect & Traitement Sign, Dschang, Cameroon.
   [Fonzin, Theophile Fozin] Univ Buea, Fac Engn & Technol FET, Dept Elect & Elect Engn, POB 63, Buea, Cameroon.
C3 Universite de Dschang
RP Telem, ANK (corresponding author), Univ Buea, Coll Technol COT, Dept Elect & Elect Engn, POB 63, Buea, Cameroon.; Telem, ANK (corresponding author), Univ Dschang, Fac Sci, Dept Phys, Lab Rech Matiere Condensee Elect & Traitement Sign, Dschang, Cameroon.
EM adelkengnou@Gmail.com
OI adelaide Nicole, kengnou telem/0000-0001-5972-2444
CR Abib Greta A., 2015, IFAC - Papers Online, V48, P976, DOI 10.1016/j.ifacol.2015.09.319
   Al Bassam N, 2018, CHAOS THEORY, P61
   Al-Qaraawy SM., 2009, ENG TECHNOL J, V27, P1324
   Alesanco A, 2010, IEEE T INF TECHNOL B, V14, P1144, DOI 10.1109/TITB.2010.2047650
   Algarni AD, 2021, MULTIMED TOOLS APPL, V80, P10679, DOI 10.1007/s11042-020-09369-5
   Alshammari AS, 2020, ENG TECHNOL APPL SCI, V10, P5947
   [Anonymous], 1997, PROC ECCTD
   [Anonymous], 2010, 2010 6 INT C WIR COM
   Caini C, 2004, IEEE T COMMUN, V52, P1397, DOI 10.1109/TCOMM.2004.833024
   Corazza GE, 2004, IEEE T COMMUN, V52, P1160, DOI 10.1109/TCOMM.2004.831414
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Hanzo L., 2003, Single and Multi-Carrier DS-CDMA: Multi-User Detection, Space-Time Spreading, Synchronisation, Standards and Networking
   Heidari-Bateni G., 1992, 1992 IEEE International Conference on Selected Topics in Wireless Communications. Conference Proceedings (Cat. No.92TH0462-2), P437, DOI 10.1109/ICWC.1992.200803
   HEIDARIBATENI G, 1994, IEEE T COMMUN, V42, P1524, DOI 10.1109/TCOMM.1994.582834
   Hernández AI, 2001, IEEE T INF TECHNOL B, V5, P253, DOI 10.1109/4233.945297
   Jovic B, 2007, ELECTRON LETT, V43, P988, DOI 10.1049/el:20070989
   Jovic B, 2007, SIGNAL PROCESS, V87, P1692, DOI 10.1016/j.sigpro.2007.01.014
   Jovic B, 2011, SIGNALS COMMUN TECHN, P171
   Kaddoum G, 2007, P INT S NONL THEOR I
   Kaddoum G, 2008, THESIS TOULOUSE
   Kaddoum G, 2009, 2009 17 EUR SIGN PRO, P2141
   Kaddoum G, 2010, SIGNAL PROCESS, V90, P2923, DOI 10.1016/j.sigpro.2010.04.013
   Kaddoum G, 2009, IEEE INT SYMP CIRC S, P2637, DOI 10.1109/ISCAS.2009.5118343
   Kaddoum G, 2009, SIGNAL PROCESS, V89, P807, DOI 10.1016/j.sigpro.2008.10.023
   Kang K., 2011, International Symposium on Quality Electronic Design, P1
   KORSAKAS S., 2006, COMPUT CARDIOL, V2006, P833
   Lin CF, 2008, 10TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, P1903
   Mandi MV, 2006, 2006 INT C COMM TECH, P1
   Martoyo Ihan, 2010, 2010 Intl. Symposium on Information Theory & Its Applications (ISITA) & 2010 Intl. Symposium on Spread Spectrum Techniques & Applications (ISSSTA), P189, DOI 10.1109/ISSSTA.2010.5652316
   Mazzini G, 1997, IEEE T CIRCUITS-I, V44, P937, DOI 10.1109/81.633883
   Mazzini G., 1998, ISCAS '98. Proceedings of the 1998 IEEE International Symposium on Circuits and Systems (Cat. No.98CH36187), P485, DOI 10.1109/ISCAS.1998.698943
   Mazzini G, 2007, IEEE T CIRCUITS-I, V54, P2299, DOI 10.1109/TCSI.2007.904642
   Nasrabadi AM, 2011, 2011 IEEE INT S MED, P55
   Novosel L, 2017, EURASIP J WIREL COMM, DOI 10.1186/s13638-017-0866-7
   Prabhu GS, 2002, IEEE T EDUC, V45, P19, DOI 10.1109/13.983217
   Raeiatibanadkooki M, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0433-5
   Rahnama N, 2012, 2012 SIXTH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P404, DOI 10.1109/ISTEL.2012.6483021
   Rovatti R, 2004, IEEE T CIRCUITS-I, V51, P1348, DOI 10.1109/TCSI.2004.830698
   Rovatti R, 2004, IEEE T CIRCUITS-I, V51, P1336, DOI 10.1109/TCSI.2004.830700
   Setti G, 1999, IEICE T FUND ELECTR, VE82A, P1737
   SHANKS JL, 1969, IEEE T COMPUT, VC 18, P457, DOI 10.1109/T-C.1969.222685
   Silapaporn P, 2012, 2012 4 INT C COMP IN, P137
   Tchiotsop D., 2014, INT J ELECT COMMUN C, V6, P409
   Tchiotsop D, 2017, BIOMED ENG LETT, V7, P153, DOI 10.1007/s13534-017-0018-3
   Vali R, 2010, SIGNAL PROCESS, V90, P1924, DOI 10.1016/j.sigpro.2009.12.013
   Vali R, 2012, IEEE T WIREL COMMUN, V11, P722, DOI 10.1109/TWC.2011.120511.110306
   Wang IJ, 2010, TENCON IEEE REGION, P379, DOI 10.1109/TENCON.2010.5686658
   Xiuxia Yu, 2010, 2010 International Conference on Computer, Mechatronics, Control and Electronic Engineering (CMCE 2010), P211, DOI 10.1109/CMCE.2010.5610011
   Yang LL, 2002, IEEE T WIREL COMMUN, V1, P692, DOI 10.1109/TWC.2002.804161
NR 49
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 17
PY 2023
DI 10.1007/s11042-023-15711-4
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7EQ1
UT WOS:000990751100016
DA 2024-07-18
ER

PT J
AU Bhavani, SD
   Bharathi, RK
AF Bhavani, S. D.
   Bharathi, R. K.
TI A multi-dimensional review on handwritten signature verification:
   strengths and gaps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Handwritten signature verification; Few-shot learning; Synthetic
   signatures; Interoperability issues; Real-world documents;
   Hyperspectral; Deep learning
ID DYNAMIC SIGNATURE; ONLINE; FEATURES; RECOGNITION; ADAPTATION; NETWORKS;
   FUSION
AB A handwritten signature is the most widely accepted method to authenticate an individual in banking, financial, business transactions, cheque processing, access control, and e-business due to its simplicity and distinctiveness. Many automated systems have been created to predict the authenticity of a signature. However, barely a few review papers provide a summary of the existing research on deep learning-based signature verification systems. An attempt is made to bring out the strengths and find gaps in handwritten signature verification in various dimensions considering both online and offline signatures. The primary objective of this comprehensive study is to present the most recent deep learning-based models for signature verification systems by putting emphasis on five different aspects: datasets, preprocessing techniques, feature extraction methods, machine learning-based verification models, and performance evaluation metrics. This review includes publications on both offline and online signature verification systems published between 2017 and 2022. This systematic review has discovered that recently, the deep learning-based neural network accomplished the most encouraging results for signature verification systems on public datasets. This comprehensive review revealed that recently, the deep learning-based neural network attained the most promising results for signature verification systems on public datasets. This article distinguishes itself from other reviews by revealing the twelve most significant research areas for researchers. (1) Intra-personal and inter-personal variability. (2) Few-shot Learning. (3) Offline signature recovery from online signature and vice versa. (4) Device Interoperability issues in the multi-device scenario. (5) Extracting signatures from Real World Document images. (6) Signature segmentation using Hyper Spectral Imaging. (7) Signatures as a means of retrieval of documents. (8) Multiscript Signature Verification Systems. (9) Automatic health state assessment. (10) Ensemble of Classifiers. (11) Synthetic Signature Generation. (12) Transfer Learning.
C1 [Bhavani, S. D.; Bharathi, R. K.] JSS Sci & Technol Univ, Dept Comp Applicat, Mysore, Karnataka, India.
C3 JSS Science & Technology University
RP Bhavani, SD (corresponding author), JSS Sci & Technol Univ, Dept Comp Applicat, Mysore, Karnataka, India.
EM bhavani.sd@jssstuniv.in
CR Agam G., 2006, COMPLEX DOCUMENT IMA
   Agrawal P, 2021, MULTIMED TOOLS APPL, V80, P5319, DOI 10.1007/s11042-020-09818-1
   Ahrabian K, 2019, NEURAL COMPUT APPL, V31, P9321, DOI 10.1007/s00521-018-3844-z
   [Anonymous], 2014, IEEE INT JOINT C BIO, DOI DOI 10.1109/BTAS.2014.6996245
   [Anonymous], 2017, IMAGE PROCESSING THE, DOI 10.1109/IPTA.2017.8310112
   Antal M, 2018, MOB INF SYST, V2018, DOI 10.1155/2018/3127042
   Bharathi RK, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P179, DOI 10.1109/ICSIP.2014.34
   Bharathi RK, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2063, DOI 10.1109/ICACCI.2013.6637499
   Bhowal P, 2022, J AMB INTEL HUM COMP, V13, P21, DOI 10.1007/s12652-020-02872-5
   Bhunia AK, 2019, NEURAL COMPUT APPL, V31, P8737, DOI 10.1007/s00521-019-04220-x
   Blanco-Gonzalo R, 2014, IET BIOMETRICS, V3, P139, DOI 10.1049/iet-bmt.2013.0044
   Blankers Vivian L., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1403, DOI 10.1109/ICDAR.2009.216
   Bonde S. V., 2020, 2020 6th International Conference on Signal Processing and Communication (ICSC), P119, DOI 10.1109/ICSC48311.2020.9182727
   Bouamra W, 2018, EXPERT SYST APPL, V107, P182, DOI 10.1016/j.eswa.2018.04.035
   Butt UM, 2016, INT CONF FRONT HAND, P19, DOI [10.1109/ICFHR.2016.0017, 10.1109/ICFHR.2016.14]
   Çalik N, 2019, NEUROCOMPUTING, V359, P1, DOI 10.1016/j.neucom.2019.03.027
   Chandra S, 2017, MULTIMED TOOLS APPL, V76, P19139, DOI 10.1007/s11042-017-4531-2
   Chaturvedi Pooja, 2022, 2022 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COM-IT-CON), P710, DOI 10.1109/COM-IT-CON54601.2022.9850628
   Choudhury B, 2018, INT J IMAGE GRAPH, V18, DOI 10.1142/S0219467818500067
   Chuang Li, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P526, DOI 10.1109/ICDAR.2019.00090
   Das A, 2016, IET BIOMETRICS, V5, P305, DOI 10.1049/iet-bmt.2016.0010
   Deka A., 2020, STAT OPTIM INF COMPU, V8, P902, DOI [10.19139/soic-2310-5070-447, DOI 10.19139/SOIC-2310-5070-447]
   Dhiman S, 2019, BIOMETRIC AUTHENTICA
   Diaz M, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3274658
   Diaz M, 2017, PROC INT CONF DOC, P1204, DOI 10.1109/ICDAR.2017.199
   Diaz M, 2018, IEEE T CYBERNETICS, V48, P228, DOI 10.1109/TCYB.2016.2630419
   Diaz M, 2016, INT C PATT RECOG, P1147, DOI 10.1109/ICPR.2016.7899791
   Diaz-Cabrera M, 2014, INT CONF FRONT HAND, P482, DOI 10.1109/ICFHR.2014.87
   Engin Deniz, 2020, P IEEECVF C COMPUTER, P808
   Ferrer MA, 2005, IEEE T PATTERN ANAL, V27, P993, DOI 10.1109/TPAMI.2005.125
   Ferrer Marie-Helene, 2013, Instituto Diplomatico, P1, DOI [DOI 10.1109/ICB.2013.6612969, 10.1145/2501907.2501963, 10.1109/ICB.2013.6612969]
   Ferrer MA, 2018, IEEE T CYBERNETICS, V48, P2896, DOI 10.1109/TCYB.2017.2751740
   Ferrer MA, 2017, IEEE T PATTERN ANAL, V39, P1041, DOI 10.1109/TPAMI.2016.2582167
   Gadre A, 2021, 2021 INT C ADV EL EL, P1
   Galbally J, 2007, Pattern Analysis and Applications, P68, DOI [DOI 10.1007/S10044-009-0151-4, 10.1007/s10044-009-0151-4]
   Galbally J, 2015, PATTERN RECOGN, V48, P2921, DOI 10.1016/j.patcog.2015.03.019
   Ghosh R, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114249
   Guo JK, 2001, INT J PATTERN RECOGN, V15, P579, DOI 10.1142/S0218001401001088
   Hafemann LG, 2020, IEEE T INF FOREN SEC, V15, P1735, DOI 10.1109/TIFS.2019.2949425
   Hafemann LG, 2018, INT J DOC ANAL RECOG, V21, P219, DOI 10.1007/s10032-018-0301-6
   Hafemann LG, 2017, PATTERN RECOGN, V70, P163, DOI 10.1016/j.patcog.2017.05.012
   Hameed MM, 2021, SIGNAL PROCESS-IMAGE, V93, DOI 10.1016/j.image.2021.116139
   Impedovo Donato, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1320, DOI 10.1109/ICDAR.2019.00213
   Impedovo D, 2008, IEEE T SYST MAN CY C, V38, P609, DOI 10.1109/TSMCC.2008.923866
   Impedovo D, 2021, IEEE T EMERG TOP COM, V9, P554, DOI 10.1109/TETC.2018.2865345
   Impedovo D, 2019, IEEE SYS MAN CYBERN, P3048, DOI 10.1109/SMC.2019.8914523
   Iqbal K., 2017, PROC PAK ACAD SCI PH, V54, P269
   Jagtap AB, 2018, INT C RECENT TRENDS, P131
   Jagtap AB, 2020, MULTIMED TOOLS APPL, V79, P35109, DOI 10.1007/s11042-020-08857-y
   Jain A, 2021, IET BIOMETRICS, V10, P117, DOI 10.1049/bme2.12007
   Jain A, 2021, NEURAL COMPUT APPL, V33, P6999, DOI 10.1007/s00521-020-05473-7
   Jain A, 2020, MULTIMED TOOLS APPL, V79, P19993, DOI 10.1007/s11042-020-08728-6
   Jiang JJ, 2022, NEUROCOMPUTING, V507, P345, DOI 10.1016/j.neucom.2022.08.017
   Junior C.A., 2020, 2020 INT JOINT C NEU, P1
   Justino EJR, 2001, PROC INT CONF DOC, P1031, DOI 10.1109/ICDAR.2001.953942
   Kalera MK, 2004, INT J PATTERN RECOGN, V18, P1339, DOI 10.1142/S0218001404003630
   Kancharla K, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATION AND TELECOMMUNICATION (ICACAT)
   Kao HH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113716
   Kholmatov A, 2009, PATTERN ANAL APPL, V12, P227, DOI 10.1007/s10044-008-0118-x
   Kumar A, 2017, 2017 3 INT C ADV COM, P1
   Kumar G, 2014, INT C ADV COMPUT COM, P5, DOI 10.1109/ACCT.2014.74
   Kuriakose YV, 2022, P INT C COMP INT ICC, P45
   Lai S., 2021, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Lai SX, 2020, AAAI CONF ARTIF INTE, V34, P735
   Lai SX, 2019, IEEE T INF FOREN SEC, V14, P1624, DOI 10.1109/TIFS.2018.2883152
   Lai SX, 2018, INT CONF FRONT HAND, P175, DOI 10.1109/ICFHR-2018.2018.00039
   Lewis D., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P665, DOI 10.1145/1148170.1148307
   Li H, 2022, 2022 IEEE INT C MULT, P1
   Liang H, 2017, EURASIP J WIREL COMM, DOI 10.1186/s13638-017-0993-1
   Linden J, 2018, FORENSIC SCI INT, V291, P216, DOI 10.1016/j.forsciint.2018.08.021
   Liu L, 2021, PATTERN RECOGN, V118, DOI 10.1016/j.patcog.2021.108009
   Longjam T, 2023, EXPERT SYST APPL, V214, DOI 10.1016/j.eswa.2022.119111
   Longjam T, 2023, MULTIMED TOOLS APPL, V82, P5839, DOI 10.1007/s11042-022-13392-z
   Malik MI, 2015, 17 BIENN C INT GRAPH
   Malik MI, 2015, PROC INT CONF DOC, P1186, DOI 10.1109/ICDAR.2015.7333948
   Mandal R, 2013, INT CONF INTELL SYST, P80, DOI 10.1109/ISDA.2013.6920712
   Manikantha K., 2021, J U SHANGHAI SCI TEC, V23, P1129, DOI [10.51201/JUSST/21/07272, DOI 10.51201/JUSST/21/07272]
   Manjunatha KS, 2016, PATTERN RECOGN LETT, V80, P129, DOI 10.1016/j.patrec.2016.06.016
   Matsuda K, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P941, DOI 10.1109/ACPR.2017.156
   Matsuda K, 2016, INT CONF FRONT HAND, P489, DOI [10.1109/ICFHR.2016.0096, 10.1109/ICFHR.2016.89]
   Melo VKSL, 2019, IET BIOMETRICS, V8, P215, DOI 10.1049/iet-bmt.2018.5091
   Narwade P, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0200-0
   Nathwani C, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P1076, DOI [10.1109/iciccs48265.2020.9121023, 10.1109/ICICCS48265.2020.9121023]
   Obaidullah SM, 2021, 2 INT C PERS TECHN, P440
   Okawa M, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107699
   Okawa M, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107227
   Okawa M, 2018, PATTERN RECOGN LETT, V113, P75, DOI 10.1016/j.patrec.2018.05.019
   Okawa M, 2018, PATTERN RECOGN, V79, P480, DOI 10.1016/j.patcog.2018.02.027
   Oloyede A, 2018, FORENSICS INVESTIGAT, P57
   Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078
   Ortega-Garcia J, 2010, IEEE T PATTERN ANAL, V32, P1097, DOI 10.1109/TPAMI.2009.76
   Pal S, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P72, DOI 10.1109/DAS.2016.48
   Parcham E, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115649
   Pirlo G, 2015, LECT NOTES COMPUT SC, V9281, P242, DOI 10.1007/978-3-319-23222-5_30
   Pirlo G, 2015, LECT NOTES COMPUT SC, V9281, P290, DOI 10.1007/978-3-319-23222-5_36
   Qureshi R, 2019, PATTERN RECOGN, V90, P12, DOI 10.1016/j.patcog.2019.01.026
   Rateria A., 2018, IN 2018 5 IEEE UTTAR, P1
   Ruiz V, 2020, NEUROCOMPUTING, V374, P30, DOI 10.1016/j.neucom.2019.09.041
   Melo VKSL, 2018, INT CONF FRONT HAND, P540, DOI 10.1109/ICFHR-2018.2018.00100
   Santos YAC, 2022, PHYSICA A, V600, DOI 10.1016/j.physa.2022.127582
   Sekhar V Chandra, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1470, DOI 10.1109/ICDAR.2019.00236
   Shariatmadari S, 2019, INT J DOC ANAL RECOG, V22, P375, DOI 10.1007/s10032-019-00331-2
   Sharif M, 2020, PATTERN RECOGN LETT, V139, P50, DOI 10.1016/j.patrec.2018.01.021
   Sharma N, 2018, INT CONF FRONT HAND, P416, DOI 10.1109/ICFHR-2018.2018.00079
   Sheikh MR, 2021, 2021 INT C COMP COMM, P1
   Siepe BS, 2024, arXiv
   Singh A, 2020, 2020 C INF COMM TECH, P1
   Soleimani A, 2017, IET BIOMETRICS, V6, P1, DOI 10.1049/iet-bmt.2015.0058
   Souza VLF, 2020, EXPERT SYST APPL, V154, DOI 10.1016/j.eswa.2020.113397
   Souza VL, 2019, 2019 INT JOINT C NEU, P1
   Tahir NM., 2021, INT J INTELL SYST AP, V13, P45
   Tolosana Ruben, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P229, DOI 10.1109/TBIOM.2021.3054533
   Tolosana R, 2021, INT C DOC AN REC
   Tolosana R, 2018, IEEE ACCESS, V6, P5128, DOI 10.1109/ACCESS.2018.2793966
   Tolosana R, 2017, PROC INT CONF DOC, P652, DOI 10.1109/ICDAR.2017.112
   Tolosana R, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176792
   Tolosana R, 2015, IEEE ACCESS, V3, P478, DOI 10.1109/ACCESS.2015.2431493
   Vargas JF, 2007, PROC INT CONF DOC, P764
   Vorugunti Chandra Sekhar, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1125, DOI 10.1109/ICDAR.2019.00182
   Vorugunti CS, 2020, NEUROCOMPUTING, V409, P157, DOI 10.1016/j.neucom.2020.05.072
   Wang ZL, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21100956
   Wen J, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417560109
   Wu XM, 2019, INT CONF ACOUST SPEE, P2467, DOI [10.1109/icassp.2019.8683036, 10.1109/ICASSP.2019.8683036]
   Xiao W, 2019, 2018 INTERNATIONAL WORKSHOP ON ADVANCES IN SOCIAL SCIENCES (IWASS 2018), P1103, DOI [10.1109/ICDAR.2019.00179, 10.25236/iwass.2018.239]
   Xing ZJ, 2018, SPIE, V10615, P415
   Yapici MM, 2021, PATTERN ANAL APPL, V24, P165, DOI 10.1007/s10044-020-00912-6
   Yeung DY, 2004, LECT NOTES COMPUT SC, V3072, P16
   Yilmaz MB, 2018, IEEE COMPUT SOC CONF, P639, DOI 10.1109/CVPRW.2018.00094
   Zhang SJ, 2018, LECT NOTES COMPUT SC, V10996, P700, DOI 10.1007/978-3-319-97909-0_74
   Zhu YC, 2020, INT CONF FRONT HAND, P282, DOI 10.1109/ICFHR2020.2020.00059
   Zois EN, 2019, EXPERT SYST APPL, V125, P14, DOI 10.1016/j.eswa.2019.01.058
   Zois EN, 2018, IEEE COMPUT SOC CONF, P545, DOI 10.1109/CVPRW.2018.00084
NR 132
TC 1
Z9 1
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 13
PY 2023
DI 10.1007/s11042-023-15357-2
EA MAY 2023
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZM6
UT WOS:000988577200006
DA 2024-07-18
ER

PT J
AU Sangeethapriya, R
   Akilandeswari, J
AF Sangeethapriya, R.
   Akilandeswari, J.
TI Classification of cyberbullying messages using text, image and audio in
   social networks: a deep learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cyberbulying; GCN; CNN; Almetrics; Pre-trained Googlenet; MFCC; SNA
AB People's physical presence in smart cities is being shifted to the cyber world via social networks. Bullying that occurs through virtual devices such as phones, laptops, and tablet and PCS is known as cyberbullying. Online harassment can occur via text messaging, messages, and software, as well as online in social networking sites, discussion boards, or online games where individuals may view, participate in, or distribute content, including sending, posting, or sharing negative, harmful, false, or mean content. It can include revealing personal or private details, causing embarrassment or humiliation. This paper intends to sift through social media posts in order to identify bullying comments in text, image, and video form.We propose a graph convolutional neural network(GCN) and a pre-trained Googlenet for text and image recognition, as well as a Mel-scale filter bank speech spectrogram and CNN network model for audio post classification. This study's main results are that using graph convolution neural networks and Googlenet, as well as audio post-processing using MFCC's, produce superior results including one dimensional representation.We use in the present environment,GCN and Mel-frequency cepstrum to represent text, image, and video input, yielding an accuracy of 96%. The approach is unique in its use of these techniques and has not been previously proposed for cyberbullying detection. The study's main contribution is its ability to achieve superior accuracy in identifying bullying comments, which makes it a valuable addition to the existing literature on cyberbullying detection.
C1 [Sangeethapriya, R.; Akilandeswari, J.] Sona Coll Technol, Dept Informat Technol, Salem, Tamil Nadu, India.
C3 Sona College of Technology
RP Sangeethapriya, R (corresponding author), Sona Coll Technol, Dept Informat Technol, Salem, Tamil Nadu, India.
EM sangeethapriya.r@sonatech.ac.in; akilandeswari@sonatech.ac.in
CR Al-garadr MA, 2016, COMPUT HUM BEHAV, V63, P433, DOI 10.1016/j.chb.2016.05.051
   Alotaibi N, 2021, INT C SOC COMP SOC M, DOI [10.1007/978-3-030-79150-8_10, DOI 10.1007/978-3-030-79150-8_10]
   Choi YJ., 2020, TELEMATICS INFORM, V56, P202, DOI [10.1016/j.tele.101504, DOI 10.1016/J.TELE.101504]
   Hang OC, 2019, INT CONF RES INNOV, DOI 10.1109/icriis48246.2019.9073679
   Hani J, 2019, INT J ADV COMPUT SC, V10, P703
   Hassan M., 2021, INT J ADV COMP SCI A, V12, P189, DOI [10.14569/IJACSA.2021.0120323, DOI 10.14569/IJACSA.2021.0120323]
   Huang Q, 2014, CYBER BULLYING DETEC, DOI [10.1145/2661126.2661133, DOI 10.1145/2661126.2661133]
   Kumari K, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3907
   Kumari K, 2020, SOFT COMPUT, V24, P11059, DOI 10.1007/s00500-019-04550-x
   Li X, 2020, J IEEE ACCESS, V8, P72035, DOI [10.1109/ACCESS.2020.2998349, DOI 10.1109/ACCESS.2020.2998349]
   Lu NJ, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5627
   Ma CL, 2022, DEEP LEARNING APPROA, DOI [10.1016/j.eswa.2021.115371, DOI 10.1016/J.ESWA.2021.115371]
   Modha S, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113725
   Nurrahmi H, 2018, INT C INF COMMUN TEC, DOI [10.1109/ICOIACT.8350758, DOI 10.1109/ICOIACT.8350758]
   Sadiq S, 2021, FUTURE GENER COMP SY, V114, P120, DOI 10.1016/j.future.2020.07.050
   Sangwan S., 2020, Procedia Computer Science, V173, P305
   Shandilya S, 2022, MATH BIOSCI ENG, V19, P7232, DOI 10.3934/mbe.2022341
   Srivastava A., 2020, J AMBIENT INTELL HUM, V11, P3483, DOI [10.1007/s12652-020-02622-6, DOI 10.1007/S12652-020-02622-6]
   Van Hee C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203794
   Yadav Jaideep, 2020, 2020 International Conference on Electronics and Sustainable Communication Systems (ICESC). Proceedings, P1096, DOI 10.1109/ICESC48915.2020.9155700
   Zhao ZH, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207640
NR 21
TC 0
Z9 0
U1 7
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 12
PY 2023
DI 10.1007/s11042-023-15538-z
EA MAY 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G0SA7
UT WOS:000986346600009
DA 2024-07-18
ER

PT J
AU Li, ZT
   Zhang, ZR
   Gao, S
AF Li, Zhaotong
   Zhang, Zeru
   Gao, Song
TI Classical learning or deep learning: a study on food photo aesthetic
   assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Food photo aesthetic assessment; Supervised classification; Feature
   engineering; Deep learning
ID IMAGES; COLOR; SELECTION; FEATURES
AB Food photo aesthetic assessment has gained increasing attention in both commercial activity and social life. However, there has been little research dedicated to the quality classification of food photos. This paper presents a study on food photo aesthetic evaluation, covering dataset collection and evaluation methods. First, a dataset of food photos was collected by web crawler from food-sharing websites, and the appropriate images were selected and labeled using a WeChat applet for binary classification. Then, food photo aesthetic assessment was evaluated using classical machine learning and deep learning methods. Different hand-crafted features, including layout, texture, color, local, and deep features, were manually extracted. Two classifiers, support vector machine and random forest, were used to establish the classical learning models. Meanwhile, three convolutional neural networks (AlexNet, VGGNet, ResNet) were applied to compare with former methods by fine-tuning the model parameters. Four quantitative metrics (accuracy, recall, precision, and f1-score) were used to evaluate the performance of food photo aesthetic assessment, with the accuracy of classical and deep learning methods being 91.09% vs 94.70%, respectively. This demonstrates that classical learning with good enough hand-crafted features is capable of producing performance close to that of CNNs. The dataset for food photo aesthetic assessment can be used as a preliminary exploration of food image aesthetics assessment from both classical learning and deep learning.
C1 [Li, Zhaotong] Med Sch Nantong Univ, Dept Med Informat, Lab Digital Med, Nantong 226001, Peoples R China.
   [Zhang, Zeru] Peking Univ, Inst Med Humanities, Beijing 100191, Peoples R China.
   [Gao, Song] Peking Univ, Inst Med Technol, Hlth Sci Ctr, Beijing 100191, Peoples R China.
C3 Nantong University; Peking University; Peking University
RP Li, ZT (corresponding author), Med Sch Nantong Univ, Dept Med Informat, Lab Digital Med, Nantong 226001, Peoples R China.
EM zhaotong_li@bjmu.edu.cn
OI Li, Zhaotong/0000-0002-6947-0065
CR Al-Hamami A, 2010, INT ARAB J INF TECHN, V7, P324
   Asghar N, 2016, Arxiv, DOI arXiv:1605.05362
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Cervantes J, 2020, NEUROCOMPUTING, V408, P189, DOI 10.1016/j.neucom.2019.10.118
   Datta R, 2008, IEEE IMAGE PROC, P105, DOI 10.1109/ICIP.2008.4711702
   de Siqueira FR, 2013, NEUROCOMPUTING, V120, P336, DOI 10.1016/j.neucom.2012.09.042
   Debnath S, 2022, MULTIMED TOOLS APPL, V81, P22527, DOI 10.1007/s11042-021-11557-w
   Deng YB, 2017, IEEE SIGNAL PROC MAG, V34, P80, DOI 10.1109/MSP.2017.2696576
   Tran DT, 2023, J SUPERCOMPUT, V79, P4048, DOI 10.1007/s11227-022-04824-6
   Tran DT, 2022, J SUPERCOMPUT, V78, P11051, DOI 10.1007/s11227-021-04275-5
   Gaspar P, 2012, J INTEGR BIOINFORMAT, V9, DOI 10.2390/biecoll-jib-2012-201
   Han L, 2011, COMPUTATIONAL MODELI, P206
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jang H, 2021, IEEE ACCESS, V9, P29850, DOI 10.1109/ACCESS.2021.3060171
   Jiang GY, 2018, IEEE ACCESS, V6, P2231, DOI 10.1109/ACCESS.2017.2782320
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   Katz O, 2014, NAT PHOTONICS, V8, P784, DOI [10.1038/NPHOTON.2014.189, 10.1038/nphoton.2014.189]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li ZT, 2022, QUANT IMAG MED SURG, V12, P3151, DOI 10.21037/qims-21-846
   Li ZT, 2022, FRONT MICROBIOL, V13, DOI 10.3389/fmicb.2022.823324
   Liu WT, 2017, IEEE IMAGE PROC, P1317, DOI 10.1109/ICIP.2017.8296495
   Lou J, 2018, STANDFORD
   Lu X, 2015, IEEE T MULTIMEDIA, V17, P2021, DOI 10.1109/TMM.2015.2477040
   Ma S, 2017, PROC CVPR IEEE, P722, DOI 10.1109/CVPR.2017.84
   Mikhailava V, 2020, INT CONF ADV COMMUN, P285, DOI [10.23919/ICACT48636.2020.9061216, 10.23919/icact48636.2020.9061216]
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Nuari Reflan, 2019, 2019 4th International Conference on Information Technology, Information Systems and Electrical Engineering (ICITISEE), P107, DOI 10.1109/ICITISEE48480.2019.9003761
   Panetta K, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3328991
   Rahmad C, 2020, IOP C SERIES MAT SCI
   Ray P, 2021, ARTIF INTELL REV, V54, P3473, DOI 10.1007/s10462-020-09928-0
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sangwook Kim, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8226, P458, DOI 10.1007/978-3-642-42054-2_57
   Sheng KK, 2018, SA'18: SIGGRAPH ASIA 2018 TECHNICAL BRIEFS, DOI 10.1145/3283254.3283260
   Sheng KK, 2021, COMPUT VIS MEDIA, V7, P139, DOI 10.1007/s41095-020-0193-5
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Speiser JL, 2019, EXPERT SYST APPL, V134, P93, DOI 10.1016/j.eswa.2019.05.028
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Subhashree SN, 2017, FOOD QUAL SAF-OXFORD, V1, P221, DOI 10.1093/fqsafe/fyx021
   Sun WT, 2017, IEEE T MULTIMEDIA, V19, P1870, DOI 10.1109/TMM.2017.2688929
   Suran S, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE (ICIS), P77, DOI 10.1109/INFOSCI.2016.7845304
   Tang XO, 2013, IEEE T MULTIMEDIA, V15, P1930, DOI 10.1109/TMM.2013.2269899
   Tigistu T, 2021, MULTIMED TOOLS APPL, V80, P36143, DOI 10.1007/s11042-021-11397-8
   Vijayan T, 2023, IETE J RES, V69, P987, DOI 10.1080/03772063.2020.1844082
   Zhou J, 2021, COMPUT VIS MEDIA, V7, P241, DOI 10.1007/s41095-021-0207-y
NR 45
TC 1
Z9 1
U1 6
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 11
PY 2023
DI 10.1007/s11042-023-15791-2
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G1LI4
UT WOS:000986851800006
DA 2024-07-18
ER

PT J
AU Ming, H
   Heyong, W
AF Ming, Hong
   Heyong, Wang
TI Filter feature selection methods for text classification: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Text classification; Filter feature selection; Review
ID UNSUPERVISED FEATURE-SELECTION; AUTOMATIC CLASSIFICATION; RECOMMENDATION
   SYSTEM; DIMENSION REDUCTION; DOCUMENT FREQUENCY; ALGORITHM; SCHEME;
   CATEGORIZATION; EXTRACTION; FRAMEWORK
AB Filter feature selection methods are utilized to select discriminative terms from high-dimensional text data to improve text classification performance and reduce computational costs. This paper aims to provide a comprehensive systematic review of existing filter feature selection methods for text classification. Firstly, we briefly discuss text classification based on filter feature selection. Secondly, we present a detailed discussion on mathematical designs, effectiveness and complexity of existing filter feature selection methods of different methodologies (supervised methods, unsupervised methods and hybrid methods). In addition, a certain number of benchmark datasets for evaluating performance of filter feature selection methods in text classification are also discussion. Finally, we provide future directions in filter feature selection, along with conclusion.
C1 [Ming, Hong; Heyong, Wang] South China Univ Technol, Dept Elect Business, Guangzhou 510006, Peoples R China.
C3 South China University of Technology
RP Heyong, W (corresponding author), South China Univ Technol, Dept Elect Business, Guangzhou 510006, Peoples R China.
EM wanghey@scut.edu.cn
FU Project of National Nature Science Foundation of China [71731006];
   Fundamental Research Funds for Guangdong Natural Science Foundation
   [2022A1515011848]; Guangzhou Philosophy and Social Science [2020GZYB04];
   Guangdong Philosophy and Social Science [GD22YYJ15]
FX This research was supported by Project of National Nature Science
   Foundation of China, Grant No. 71731006; the Fundamental Research Funds
   for Guangdong Natural Science Foundation, Grant No. 2022A1515011848;
   Guangzhou Philosophy and Social Science, Grant No. 2020GZYB04; Guangdong
   Philosophy and Social Science, Grant No. GD22YYJ15.
CR Abiodun EO, 2021, NEURAL COMPUT APPL, V33, P15091, DOI 10.1007/s00521-021-06406-8
   Abualigah LM, 2017, EXPERT SYST APPL, V84, P24, DOI 10.1016/j.eswa.2017.05.002
   Agarwal S, 2007, IEEE DATA MINING, P3, DOI 10.1109/ICDM.2007.21
   Aggarwal CC, 2015, DATA MINING, P429
   Agnihotri D, 2019, APPL INTELL, V49, P1597, DOI 10.1007/s10489-018-1349-1
   Agnihotri D, 2017, EXPERT SYST APPL, V81, P268, DOI 10.1016/j.eswa.2017.03.057
   Ahmad SR, 2019, INTELL DATA ANAL, V23, P159, DOI 10.3233/IDA-173763
   Altinel B, 2015, ENG APPL ARTIF INTEL, V43, P54, DOI 10.1016/j.engappai.2015.03.015
   Amazal H., 2021, SCI PROGRAMMING-NETH, V2021, P1
   [Anonymous], 2004, P INT C INF KNOWL MA, DOI DOI 10.1145/1031171.1031241
   [Anonymous], 1995, P 4 ANN S DOCUMENT A
   [Anonymous], 1997, Hierarchically classifying documents using very few words, DOI DOI 10.5555/645526.657130
   Armi L., 2019, International Online Journal of Image Processing and Pattern Recognition, V2, P1, DOI DOI 10.48550/ARKXIV.1904.06554
   Armi L, 2019, MULTIMED TOOLS APPL, V78, P18995, DOI 10.1007/s11042-019-7207-2
   Ashokkumar P, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3425781
   Asim M, 2021, INT J MACH LEARN CYB, V12, P2461, DOI 10.1007/s13042-021-01324-6
   Azam N, 2012, EXPERT SYST APPL, V39, P4760, DOI 10.1016/j.eswa.2011.09.160
   Bahassine S, 2020, J KING SAUD UNIV-COM, V32, P225, DOI 10.1016/j.jksuci.2018.05.010
   Bakus J, 2006, KNOWL INF SYST, V9, P468, DOI 10.1007/s10115-005-0209-6
   Basu T, 2012, INT CONF DAT MIN WOR, P918, DOI 10.1109/ICDMW.2012.45
   Bharti KK, 2014, ADV INTELL SYST, V236, P1545, DOI 10.1007/978-81-322-1602-5_154
   Bharti KK, 2013, ADV INTELL SYST COMP, V202, P529, DOI 10.1007/978-81-322-1041-2_45
   Bhatti UA, 2021, CHEMOSPHERE, V288, P1
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, V29, P14780, DOI 10.1007/s11356-021-16627-y
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   CHAO S, 2016, PROCEEDINGS OF INTER, P122
   Chen JN, 2009, EXPERT SYST APPL, V36, P5432, DOI 10.1016/j.eswa.2008.06.054
   Chen K, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P221, DOI 10.1109/MMSP.2006.285301
   Ciarelli P. M., 2010, Proceedings of the 2010 Eleventh Brazilian Symposium on Neural Networks (SBRN 2010), P182, DOI 10.1109/SBRN.2010.39
   Ciarelli PM, 2009, INT CONF INTELL SYST, P547, DOI 10.1109/ISDA.2009.9
   de Campos LM, 2009, INT J APPROX REASON, V50, P932, DOI 10.1016/j.ijar.2008.10.006
   De Stefano C, 2017, LECT NOTES COMPUT SC, V10199, P506, DOI 10.1007/978-3-319-55849-3_33
   Dhillon I, 2004, SURVEY OF TEXT MINING, P73
   Dubey V. K., 2016, 2016 INT C CONTROL C, P1, DOI DOI 10.1109/ICCCCM.2016.7918222
   Fei G., 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, P2347
   Feinerer I, 2008, J STAT SOFTW, V25, P1
   Fekri-Ershad S, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113509
   Feng G, 2017, PLOS ONE, V12, P1
   Ferreira AJ, 2012, PATTERN RECOGN LETT, V33, P1794, DOI 10.1016/j.patrec.2012.05.019
   Francesconi E, 2007, ARTIF INTELL LAW, V15, P1, DOI 10.1007/s10506-007-9038-0
   Fu RJ, 2015, SOFT COMPUT, V19, P29, DOI 10.1007/s00500-014-1374-x
   Ganesan K, 2012, INFORM RETRIEVAL, V15, P116, DOI 10.1007/s10791-011-9174-8
   Gao Z., 2014, International Conference on Wireless Communications, Vehicular Technology, Information Theory and Aerospace Electronic Systems (VITAE), P1, DOI DOI 10.1109/VITAE.2014.6934421
   Garla V, 2013, J BIOMED INFORM, V46, P869, DOI 10.1016/j.jbi.2013.06.014
   Ghosh S, 2022, SOFT COMPUT, V26, P891, DOI 10.1007/s00500-021-06260-9
   Han EH, 2000, LECT NOTES COMPUT<D>, V1910, P424
   Han J, 2011, DATA MINING CONCEPTS, P310
   Heyong W, 2019, INFORM PROCESS MANAG, V56, P167, DOI 10.1016/j.ipm.2018.09.004
   Hurtado J, 2016, P 21 IB C PATT REC C, P142
   Javed K, 2015, NEUROCOMPUTING, V157, P91, DOI 10.1016/j.neucom.2015.01.031
   Jin J, 2013, P 2013 INT C INF SYS, P1
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   Kayhan N, 2021, MULTIMED TOOLS APPL, V80, P32763, DOI 10.1007/s11042-021-11217-z
   Khalil ME, 2016, 2016 13TH LEARNING AND TECHNOLOGY CONFERENCE (L&T), P13
   Kilinç D, 2017, J INF SCI, V43, P174, DOI 10.1177/0165551515620551
   Kumaran G., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P297, DOI 10.1145/1008992.1009044
   Labani M, 2018, ENG APPL ARTIF INTEL, V70, P25, DOI 10.1016/j.engappai.2017.12.014
   Laboreiro G., 2010, Proceedings of the fourth workshop on Analytics for noisy unstructured text data, AND '10, P81
   Lamirel JC, 2015, J INTELL INF SYST, V45, P379, DOI 10.1007/s10844-014-0317-4
   Lee LH, 2012, APPL INTELL, V37, P80, DOI 10.1007/s10489-011-0314-z
   LEHNERT W, 1995, J EXP THEOR ARTIF IN, V7, P49, DOI 10.1080/09528139508953800
   Lewis D. D., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P4, DOI 10.1007/BFb0026666
   Li S., 2009, ACL/AFNLP'09, P692
   Li Z, 2017, NEURAL COMPUT APPL, V28, pS513, DOI 10.1007/s00521-016-2351-3
   Lim H, 2020, ENTROPY-SWITZ, V22, P1
   Liu CL, 2016, IEEE T CYBERNETICS, V46, P462, DOI 10.1109/TCYB.2015.2403573
   Liu LY, 2005, PROCEEDINGS OF THE 2005 IEEE INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING (IEEE NLP-KE'05), P597
   Lu SH, 2010, KNOWL-BASED SYST, V23, P598, DOI 10.1016/j.knosys.2010.04.004
   Manne S, 2012, ADV INTEL SOFT COMPU, V132, P413
   Marini F, 2015, CHEMOMETR INTELL LAB, V149, P153, DOI 10.1016/j.chemolab.2015.08.020
   Martín-Valdivia MT, 2007, NEURAL NETWORKS, V20, P748, DOI 10.1016/j.neunet.2006.12.005
   Miltsakaki Eleni., 2008, Proc. Workshop on Innovative Use of NLP for Building Educational Applications, P89
   Mladenic D, 2003, DECIS SUPPORT SYST, V35, P45, DOI 10.1016/S0167-9236(02)00097-0
   Mladenic D, 2006, LECT NOTES COMPUT SC, V3940, P84
   Mustafa AM, 2018, J INF SCI, V44, P15, DOI 10.1177/0165551516683617
   Hai NT, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON KNOWLEDGE AND SYSTEMS ENGINEERING (KSE), P91, DOI 10.1109/KSE.2015.25
   Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085
   Noushahr H.G., 2016, P INT C INNOVATIVE T, P119
   Novovicová J, 2005, IEEE IJCNN, P3272
   Ogura H, 2009, EXPERT SYST APPL, V36, P6826, DOI 10.1016/j.eswa.2008.08.006
   Onan A, 2016, EXPERT SYST APPL, V57, P232, DOI 10.1016/j.eswa.2016.03.045
   Parlak B, 2023, J INF SCI, V49, P59, DOI 10.1177/0165551521991037
   Pinheiro RHW, 2015, EXPERT SYST APPL, V42, P1941, DOI 10.1016/j.eswa.2014.10.011
   Pintas JT, 2021, ARTIF INTELL REV, V54, P6149, DOI 10.1007/s10462-021-09970-6
   Rajpoot AK, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P971, DOI 10.1109/Confluence51648.2021.9377117
   Rashid Tarik A., 2017, Information Technology Journal, V16, P27, DOI 10.3923/itj.2017.27.34
   Rashid TA, 2018, LECT NOTE DATA ENG, V6, P187, DOI 10.1007/978-3-319-59463-7_19
   Rehman A, 2017, INFORM PROCESS MANAG, V53, P473, DOI 10.1016/j.ipm.2016.12.004
   Ritter A., 2011, P EMNLP, P1524
   Rose Carolyn P., 2003, Building Educational Applications Using Natural Language Processing, P68
   Sahin DÖ, 2019, AUTOMATIKA-UK, V60, P162, DOI 10.1080/00051144.2019.1602293
   Sanchez-Pi N, 2014, INT JOINT C SOCO 13, P211, DOI DOI 10.1007/978-3-319-01854-6_
   Sanchez-Pi N, 2016, J APPL LOGIC, V17, P48, DOI 10.1016/j.jal.2015.09.008
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Shah FP, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2264, DOI 10.1109/WiSPNET.2016.7566545
   Shang CX, 2013, KNOWL-BASED SYST, V54, P298, DOI 10.1016/j.knosys.2013.09.019
   Shang Lei, 2012, Proceedings of the 2012 International Conference on Computer Science and Electronics Engineering (ICCSEE 2012), P355, DOI 10.1109/ICCSEE.2012.97
   Shang WQ, 2007, EXPERT SYST APPL, V33, P1, DOI 10.1016/j.eswa.2006.04.001
   Shen CH, 2012, IEEE T PATTERN ANAL, V34, P825, DOI 10.1109/TPAMI.2011.240
   Sriram B, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P841, DOI 10.1145/1835449.1835643
   Szarvas Gyorgy., 2008, PROC46TH M ASS COMPU, P281
   Tan A.-H., 1999, P PAKDD 1999 WORKSH, V8, P65
   Tang B, 2016, IEEE T KNOWL DATA EN, V28, P2508, DOI 10.1109/TKDE.2016.2563436
   Tang XC, 2019, EXPERT SYST APPL, V120, P207, DOI 10.1016/j.eswa.2018.11.018
   Thirumoorthy K, 2021, PATTERN RECOGN LETT, V147, P63, DOI 10.1016/j.patrec.2021.03.034
   Tommasel A, 2018, INFORM FUSION, V40, P1, DOI [10.1016/j.inffus.2017.05:003, 10.1016/j.inffus.2017.05.003]
   Torii M, 2011, INT J MED INFORM, V80, P56, DOI 10.1016/j.ijmedinf.2010.10.015
   Tutkan M, 2016, INFORM PROCESS MANAG, V52, P885, DOI 10.1016/j.ipm.2016.03.007
   Uchida Y., 2008, J INEQUAL PURE APPL, V9, P1
   Uguz H, 2011, KNOWL-BASED SYST, V24, P1024, DOI 10.1016/j.knosys.2011.04.014
   Upasana, 2010, Proceedings of the 2nd International Conference on Machine Learning and Computing (ICMLC 2010), P32, DOI 10.1109/ICMLC.2010.61
   Uysal AK, 2018, IEEE ACCESS, V6, P43233, DOI 10.1109/ACCESS.2018.2863547
   Uysal AK, 2016, EXPERT SYST APPL, V43, P82, DOI 10.1016/j.eswa.2015.08.050
   Uysal AK, 2012, KNOWL-BASED SYST, V36, P226, DOI 10.1016/j.knosys.2012.06.005
   Verma Ishan, 2015, Pattern Recognition and Machine Intelligence. 6th International Conference, PReMI 2015. Proceedings: LNCS 9124, P575, DOI 10.1007/978-3-319-19941-2_55
   VILLATOROTELLO E, 2016, P 15 IBERO AM C ARTI, P115
   Wang DQ, 2014, PATTERN RECOGN LETT, V45, P1, DOI 10.1016/j.patrec.2014.02.013
   WANG F, 2016, P 2 INT C MOB SEC PR, P86
   Wang H., 2017, J RESIDUALS SCI TECH, V14, P218
   Wang HY, 2019, KNOWL INF SYST, V61, P197, DOI 10.1007/s10115-018-1281-z
   Wang HY, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/695720
   Wang SS, 2015, KNOWL INF SYST, V44, P77, DOI 10.1007/s10115-014-0746-y
   Wei G, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1345, DOI 10.1109/ICME.2000.871015
   Wiratunga N, 2006, LECT NOTES ARTIF INT, V4106, P340
   Witten IH, 2011, MOR KAUF D, P1
   Wu L, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), P280, DOI 10.1109/BigMM.2017.65
   Xu Y., 2007, Journal of Computational Information Systems, V3, P1007
   Yan Xu, 2010, Proceedings of the 2010 Fourth International Conference on Genetic and Evolutionary Computing (ICGEC 2010), P280, DOI 10.1109/ICGEC.2010.76
   Yang Y., 1997, ICML, V97, P412
   Yong Liu, 2020, Mathematical Problems in Engineering, V2020, DOI 10.1155/2020/6076272
   Zhang W, 2015, KNOWL-BASED SYST, V75, P152, DOI 10.1016/j.knosys.2014.11.028
   Zheng Z., 2004, ACM Sigkdd Explorations Newsletter, V6, P80, DOI DOI 10.1145/1007730.1007741
   Zhilong Zhen, 2011, Proceedings of the 2011 International Conference on Information Technology, Computer Engineering and Management Sciences (ICM 2011), P65, DOI 10.1109/ICM.2011.365
   Zhou HF, 2021, APPL INTELL, V51, P3255, DOI 10.1007/s10489-020-01937-4
   Zhu HD, 2009, LECT NOTES COMPUT SC, V5678, P796
   Zu C, 2017, NEUROCOMPUTING, V259, P146, DOI 10.1016/j.neucom.2016.08.124
NR 138
TC 0
Z9 0
U1 31
U2 102
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 11
PY 2023
DI 10.1007/s11042-023-15675-5
EA MAY 2023
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G1LI4
UT WOS:000986851800011
DA 2024-07-18
ER

PT J
AU Gutub, A
   Kheshaifaty, N
AF Gutub, Adnan
   Kheshaifaty, Nafisah
TI Practicality analysis of utilizing text-based CAPTCHA vs. graphic-based
   CAPTCHA authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Access Control; Text Based CAPTCHA; Graphic Based
   CAPTCHA; Security; Usability
AB CAPTCHA as "Completely Automated Public Turing test to tell Computers and Humans Apart" is becoming an essential tool to help reduce many automated security authentication attacks. This research focused on studying differences running text-based CAPTCHA vs. graphical-based CAPTCHA in a utilization applicable dominant practicality manner. The ordinary text-based CAPTCHA works simple to prevent automated submissions as thought of being relatively easy to exploit. On the other hand, graphic-based CAPTCHA can be more preferred from users side, but can be providing some complexities making clear tradeoff analysis need between its usability and security. Even though graphic-based CAPTCHA has been generally considered as improvement of text-based CAPTCHA with respect to security, its usage is still not common, raising a practicality gap needing some search for comparing the two methods side by side comprehensively involving usability applicability and cultural preference beside security. In this regard, this research contributes towards filling the gap in knowledge running thorough local experimentations for finding different CAPTCHA performance tradeoffs in terms of real statistical humanoid possibilities of practicality easiness, repetition secrecy, and configuration solving timing, that can be used as basis for conducting further techno improvement human-oriented research.
C1 [Gutub, Adnan; Kheshaifaty, Nafisah] Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
C3 Umm Al Qura University
RP Gutub, A (corresponding author), Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
EM aagutub@uqu.edu.sa; n_kheshaifaty@hotmail.com
RI Gutub, Adnan Abdul-Aziz/O-1240-2016
OI Gutub, Adnan Abdul-Aziz/0000-0003-0923-202X
CR Abu-Hashem M, 2022, CAAI T INTELL TECHNO, V7, P278, DOI 10.1049/cit2.12070
   Ali F, 2014, IEEE INT C COMP COMM, DOI [10.1109/I4CT.2014.6914219, DOI 10.1109/I4CT.2014.6914219]
   Almazrooie M, 2020, J KING SAUD UNIV-COM, V32, P24, DOI 10.1016/j.jksuci.2018.02.006
   Almutairi S., 2019, Review of Business and Technology Research (RBTR), V16, P43
   Almutairi SM, 2020, INT J TECHNOL ENHANC, V12, P200
   Alotaibi M., 2019, J. Inf. Secur. Cyber Res. (JISCR), V2, P9, DOI DOI 10.26735/16587790.2019.001
   Althamary Ibrahim A., 2017, 2017 8th International Conference on Information Technology (ICIT). Proceedings, P405, DOI 10.1109/ICITECH.2017.8080034
   [Anonymous], 2014, International Journal of Computer Science and Information Technologies
   [Anonymous], 2014, 8 USENIX WORKSHOP OF
   Baird, 2005, 2 INT WORKSH HIP 200, V3517
   Banne SS, 2016, INT J ADV RES COMPUT, V5, P14
   Bhat M. Poornananda, 2020, Advances in Communication, Signal Processing, VLSI, and Embedded Systems. Select Proceedings of VSPICE 2019. Lecture Notes in Electrical Engineering (LNEE 614), P471, DOI 10.1007/978-981-15-0626-0_37
   Bursztein E, 2011, PROCEEDINGS OF THE 18TH ACM CONFERENCE ON COMPUTER & COMMUNICATIONS SECURITY (CCS 11), P125
   Bursztein E, 2010, P IEEE S SECUR PRIV, P399, DOI 10.1109/SP.2010.31
   Chellapilla Kumar, 2005, CEAS, P1
   Chow Y. W., 2019, Advances in Cyber Security: Principles, Techniques, and Applications, P69
   Das R, 2015, 3 INT S DIG FOR SEC
   Ghorpade J, 2014, INT J SOFT COMPUTING, P2231
   Guo P, 2011, KEY ENG MATER, V474-476, P2203, DOI 10.4028/www.scientific.net/KEM.474-476.2203
   Gutub Adnan, 2022, International Journal of Speech Technology, P997, DOI 10.1007/s10772-022-09999-0
   Gutub A, 2023, J ENG RES-KUWAIT, V11, DOI 10.1016/j.jer.2023.100001
   Gutub A, 2023, ARAB J SCI ENG, V48, P9963, DOI 10.1007/s13369-022-07387-z
   Gutub A, 2022, INT J INF SECUR PRIV, V16, DOI 10.4018/IJISP.2022010118
   Gutub A, 2022, PAMUKKALE U J ENG SC, V28, P324, DOI 10.5505/pajes.2021.54837
   Gutub A, 2020, MULTIMED TOOLS APPL, V79, P17373, DOI 10.1007/s11042-020-08695-y
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   JingSong Cui, 2010, 2010 2nd International Workshop on Education Technology and Computer Science (ETCS), P23, DOI 10.1109/ETCS.2010.575
   Kaur R, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P862, DOI 10.1109/WiSPNET.2016.7566254
   Kheshaifaty N., 2021, J. Eng. Res., DOI [10.36909/jer.13761, DOI 10.36909/JER.13761]
   Kheshaifaty N, 2020, INT J COMPUT SCI NET, V20, P16, DOI 10.22937/IJCSNS.2020.20.09.3
   Kulkarni P, 2015, IEEE INT C EN SYST A, DOI [10.1109/ICESA.2015.7503319, DOI 10.1109/ICESA.2015.7503319]
   Kumar S, 2019, ARTIF INTELL, V7, P45
   Kushwaha P., 2021, BRIEF SURVEY CHALLEN, P573, DOI [10.1007/978-981-15-8354-4_57, DOI 10.1007/978-981-15-8354-4_57]
   Lv YP, 2016, IEEE C EVOL COMPUTAT, P4854, DOI 10.1109/CEC.2016.7744412
   Malutan R, 2015, IEEE C GRID CLOUD HI, DOI [10.1109/ROLCG.2015.7367431, DOI 10.1109/ROLCG.2015.7367431]
   Mori G, 2003, PROC CVPR IEEE, P134
   Roslan NA, 2022, EGYPT INFORM J, V23, P177, DOI 10.1016/j.eij.2022.10.003
   Roy PK, 2023, CAAI T INTELL TECHNO, V8, P95, DOI 10.1049/cit2.12081
   Serrao M, 2013, CRACKING CAPTCHAS CA, V2
   Shaikh RA, 2018, MULTIMED TOOLS APPL, DOI [10.1007/s11042-018-6796-5, DOI 10.1007/S11042-018-6796-5]
   Singh A, 2023, MULTIMED TOOLS APPL, V82, P21243, DOI 10.1007/s11042-022-14006-4
   Singh A, 2022, ARAB J SCI ENG, V47, P9801, DOI 10.1007/s13369-021-06348-2
   Sufi FK, 2023, ARAB J SCI ENG, V48, P2455, DOI 10.1007/s13369-022-07250-1
   Tang MY, 2018, IEEE T INF FOREN SEC, V13, P2522, DOI 10.1109/TIFS.2018.2821096
   Tirthani N, 2014, IACR CRYPTOL EPRINT, P49
   Vaithyasubramanian S, 2016, IEEE INT C INFORM CO, DOI [10.1109/ICICES.2016.7518939, DOI 10.1109/ICICES.2016.7518939]
   Varish N, 2020, IEEE ACCESS, V8, P117639, DOI 10.1109/ACCESS.2020.3003911
   Yan J, 2008, P 4 S USABLE PRIVACY, P44, DOI 10.1145/1408664.1408671
   Yan J, 2008, CCS'08: PROCEEDINGS OF THE 15TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P543
   Zhang L, 2017, IEEE INT C COMM SOFT, DOI [10.1109/ICCSN.2017.8230294, DOI 10.1109/ICCSN.2017.8230294]
NR 50
TC 5
Z9 5
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46577
EP 46609
DI 10.1007/s11042-023-15586-5
EA MAY 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000982739000009
PM 37362651
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Chakravarthy, SRS
   Bharanidharan, N
   Rajaguru, H
AF Chakravarthy, S. R. Sannasi
   Bharanidharan, N.
   Rajaguru, Harikumar
TI Processing of digital mammogram images using optimized ELM with deep
   transfer learning for breast cancer diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammograms; Breast cancer; Transfer-Learning; Extreme Learning Machine;
   Crow-Search; Median filtering
ID FEATURE-SELECTION; CLASSIFICATION; WAVELET
AB The mortality of breast cancer is more among women besides lung cancer. However, the survival rates of breast cancer can be increased when there is a promising computer-aided diagnosis tool available for earlier detection and timely diagnosis. To tackle this, several research works are emerging with different methodologies but still accuracy and robustness are the key issues. Hence, a robust framework that incorporates the concept of Extreme Learning Machine (ELM) and Deep Transfer Learning is proposed and the performance of ELM is improved using an Iterative Flight-Length-Based Crow-Search Algorithm (iFLCSA) in this research work. Performance of ELM heavily depends on its parameters and to provide enhanced performance, the optimum parameters of ELM are found through the iFLCSA. When compared to the existing Crow Search Algorithm(CSA), the flight length parameter will be updated iteratively using an appropriate equation in iFLCSA to provide better balance between exploration and exploitation. Digital & full-field digital mammograms from the Mammographic Image Analysis Society (MIAS) and INbreast datasets are used for evaluation. The results obtained are then compared with the existing Support Vector Machine, ELM, Particle Swarm Optimization and CSA optimized ELM algorithms. The proposed iFLCSA-ELM provides a maximum classification accuracy of 98.292% and 98.171% for MIAS & INbreast datasets respectively.
C1 [Chakravarthy, S. R. Sannasi; Rajaguru, Harikumar] Bannari Amman Inst Technol, Dept ECE, Sathyamangalam, India.
   [Bharanidharan, N.] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, India.
C3 Bannari Amman Institute of Technology; Vellore Institute of Technology
   (VIT); VIT Vellore
RP Chakravarthy, SRS (corresponding author), Bannari Amman Inst Technol, Dept ECE, Sathyamangalam, India.
EM elektroniqz@gmail.com; bharani2410@gmail.com;
   harikumarrajaguru@gmail.com
RI RAJAGURU, HARIKUMAR/ISU-9104-2023; Rajaguru, Harikumar/G-1320-2016
OI Rajaguru, Harikumar/0000-0002-2792-0945; N,
   BHARANIDHARAN/0000-0001-9064-8238; S R, Sannasi
   Chakravarthy/0000-0002-0162-7206
CR Abdel-Nasser M, 2015, EXPERT SYST APPL, V42, P9499, DOI 10.1016/j.eswa.2015.07.072
   Abirami C, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2327, DOI 10.1109/WiSPNET.2016.7566558
   Ahila R, 2015, APPL SOFT COMPUT, V32, P23, DOI 10.1016/j.asoc.2015.03.036
   [Anonymous], APPL TEXTURE ANAL ME, DOI [10.1088/1748-0221/12/07/P07009/meta, DOI 10.1088/1748-0221/12/07/P07009/META]
   Askarzadeh A, 2016, COMPUT STRUCT, V169, P1, DOI 10.1016/j.compstruc.2016.03.001
   Badawy SM, 2017, INT J ADV COMPUT SC, V8, P117, DOI 10.14569/IJACSA.2017.081016
   Buciu I, DIRECTIONAL FEATURES
   Chakraborty Shiropa, 2021, 2021 6th International Conference on Signal Processing, Computing and Control (ISPCC), P1, DOI 10.1109/ISPCC53510.2021.9609396
   Chakravarthy SRS, 2021, INT J IMAG SYST TECH, V31, P921, DOI 10.1002/ima.22493
   Chakravarthy SRS, 2020, INT J IMAG SYST TECH, V30, P126, DOI 10.1002/ima.22364
   Chakravarthy SRS, 2022, IRBM, V43, P49, DOI 10.1016/j.irbm.2020.12.004
   Chang Y, 2018, IEEE ACCESS, V6, P11782, DOI 10.1109/ACCESS.2018.2797872
   Clayton N, 2005, CURR BIOL, V15, pR80, DOI 10.1016/j.cub.2005.01.020
   Ezzat D, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106742
   Fu W, MULTISTEP SHORT TERM
   Ghiasi G, 2018, ADV NEUR IN, V31
   Gopi Arepalli Peda, 2023, International Journal of Information Technology, P965, DOI 10.1007/s41870-019-00409-4
   Görgel P, 2013, COMPUT BIOL MED, V43, P765, DOI 10.1016/j.compbiomed.2013.03.008
   Hariraj V., 2018, INT J MECH ENG TECHN, V9, P1281
   Hepsag PU, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P418, DOI 10.1109/UBMK.2017.8093429
   Hu K, MICROCALCIFICATION D
   Huang X, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0235236
   Iqbal B, 2020, CLUSTER COMPUT, V23, P397, DOI 10.1007/s10586-019-02929-x
   Liu D, 2017, ECOL INDIC, V81, P302, DOI 10.1016/j.ecolind.2017.06.009
   Luo M, 2016, ISA T, V65, P556, DOI 10.1016/j.isatra.2016.08.022
   Majhi B, MAMMOGRAM CLASSIFICA
   McKinney M, INT EVALUATION AI SY
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Muduli D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101912
   Prathibha G, 2018, MAMMOGRAMS CLASSIFIC
   Qassim H, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P169, DOI 10.1109/CCWC.2018.8301729
   Raghavendra U, 2016, APPL SOFT COMPUT, V46, P151, DOI 10.1016/j.asoc.2016.04.036
   Rajaguru Harikumar, 2019, Asian Pac J Cancer Prev, V20, P3777, DOI 10.31557/APJCP.2019.20.12.3777
   S R Sannasi Chakravarthy, 2019, Asian Pac J Cancer Prev, V20, P2159, DOI 10.31557/APJCP.2019.20.7.2159
   Safdarian N., 2019, Multidiscip. Cancer Invest., V3, P13
   Setiawan AS, 2015, PROCEDIA COMPUT SCI, V59, P92, DOI 10.1016/j.procs.2015.07.341
   Steiner DF, 2018, AM J SURG PATHOL, V42, P1636, DOI 10.1097/PAS.0000000000001151
   Suckling J., 2015, MAMMOGRAPHIC IMAGE A, DOI 10.250394
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wong PK, 2015, RENEW ENERG, V74, P640, DOI 10.1016/j.renene.2014.08.075
   Wong SY, 2016, NEUROCOMPUTING, V171, P1431, DOI 10.1016/j.neucom.2015.07.065
   Xie JY, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.00080
   Yala A, 2019, RADIOLOGY, V292, P60, DOI 10.1148/radiol.2019182716
   Zhang C, 2017, ENERG CONVERS MANAGE, V143, P360, DOI 10.1016/j.enconman.2017.04.007
   Zhang Y, 2017, 2017 IEEE 3RD INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC), P457, DOI 10.1109/ITOEC.2017.8122336
NR 45
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47585
EP 47609
DI 10.1007/s11042-023-15265-5
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000984294600001
DA 2024-07-18
ER

PT J
AU Kaithal, PK
   Sharma, V
AF Kaithal, Praveen Kumar
   Sharma, Varsha
TI A novel efficient optimized machine learning approach to detect malware
   activities in android applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Android malware; Machine learning; Android applications; African buffalo
   optimization; Decision Tree
AB The Android device convenience has increased the number of malware developers handling several unknown applications. Machine Learning (ML) approaches help to detect these malicious applications. In this research, a novel ML approach, namely the African Buffalo-based Decision Tree (ABDT) algorithm is developed for detecting malware activities in Android applications. Initially, the dataset is trained to the system that involves Android applications and malware functions. Subsequently, the developed ABDT mechanism is processed on the dataset, and the malware in each application is detected. Additionally, the applications are analyzed based on a static and dynamic manner to detect the malware. Moreover, the developed model is simulated in the network simulator 2, and the performance metrics are calculated. Here, the key novelty of this present research is enabling the monitoring mechanism in the decision with the help of buffalo fitness. Also, the present model was efficient in finding the malicious and unknown apps that have prevented the security threat and system damage. Finally, the attained outcomes are validated with the results of several existing works in terms of accuracy, precision, recall, detection rate, F-measure, and error rate. The presented model has earned 99.85% accuracy, 99.76% precision, 99.83% recall, and 99.79% F-measure.
C1 [Kaithal, Praveen Kumar; Sharma, Varsha] Rajiv Gandhi Proudyogiki Vishwavidyalaya, Sch Informat Technol, Bhopal, India.
C3 Rajiv Gandhi Technological University
RP Kaithal, PK (corresponding author), Rajiv Gandhi Proudyogiki Vishwavidyalaya, Sch Informat Technol, Bhopal, India.
EM praveenkaithal@yahoo.com; varshasharma@rgpv.ac.in
CR Agrawal P, 2021, ADV INTELLIGENT SYST, DOI [10.1007/978-981-15-5616-6_22, DOI 10.1007/978-981-15-5616-6_22]
   Agrawal R, 2020, 2020 INT C EM TRENDS
   Alazab M, 2020, FUTURE GENER COMP SY, V107, P509, DOI 10.1016/j.future.2020.02.002
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Alzaylaee MK, 2020, COMPUT SECUR, V89, DOI 10.1016/j.cose.2019.101663
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   Ananya A, 2020, CLUSTER COMPUT, V23, P2789, DOI 10.1007/s10586-019-03045-6
   Bakour K, 2021, NEURAL COMPUT APPL, V33, P3133, DOI 10.1007/s00521-020-05195-w
   Ding YX, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02196-4
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Faiz MFI, 2021, ADV INTELL SYST COMP, V1194, P244, DOI 10.1007/978-3-030-50454-0_23
   Fatima A, 2021, ADV COMPUTATIONAL IN, P195, DOI [10.1007/978-981-15-1275-9_17, DOI 10.1007/978-981-15-1275-9_17]
   Kamili A, 2020, J INTELL FUZZY SYST, V39, P8389, DOI 10.3233/JIFS-189157
   Liu KJ, 2020, IEEE ACCESS, V8, P124579, DOI 10.1109/ACCESS.2020.3006143
   Mahindru A, 2021, NEURAL COMPUT APPL, V33, P5183, DOI 10.1007/s00521-020-05309-4
   Mantoo BA, 2020, LECT NOTES ELECTR EN, V597, P31, DOI 10.1007/978-3-030-29407-6_4
   Martinelli F, 2020, SIMUL MODEL PRACT TH, V105, DOI 10.1016/j.simpat.2020.102169
   Mehtab A, 2020, MOBILE NETW APPL, V25, P180, DOI 10.1007/s11036-019-01248-0
   Raghuraman C, 2020, ADV INTELL SYST, V1045, P793, DOI 10.1007/978-981-15-0029-9_62
   Ren ZR, 2020, AD HOC NETW, V101, DOI 10.1016/j.adhoc.2020.102098
   Sai Ambati L., 2020, Issues Inform Syst, V21, P103
   Sangal Aviral, 2020, 2020 International Conference on Smart Electronics and Communication (ICOSEC), P48, DOI 10.1109/ICOSEC49089.2020.9215355
   Surendran R, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113581
   Vasan D, 2020, COMPUT NETW, V171, DOI 10.1016/j.comnet.2020.107138
   Wang J, 2020, IEEE WCNC, DOI 10.1109/wcnc45663.2020.9120537
   Zaabi A. A., 2020, INT C COMMUNICATIONS, P1, DOI DOI 10.1109/CCCI49893.2020.9256450
NR 29
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42833
EP 42850
DI 10.1007/s11042-023-15264-6
EA APR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:001066758900005
DA 2024-07-18
ER

PT J
AU Parlak, B
AF Parlak, Bekir
TI A novel feature and class-based globalization technique for text
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Text classification; Local feature selection; Globalization
ID FEATURE-SELECTION SCHEME
AB Text classification is a very important topic in the current era due to the high volume of textual data and handling. Feature selection is one of the most important steps in text classification studies, as well as significantly affecting classification performance. In the literature, filter-based global feature selection methods are widely proposed. While these methods are globalized, although they are generally performed by looking at the class information, feature information is ignored beside the class information. When calculating the score of each feature, the information of the feature should be taken into account along with the class information. To solve this problem, a new globalization technique called Feature and Class-based Weighted Sum (FCWS) which takes into account both feature and class information is proposed. FCWS method is compared with traditional globalization techniques on four datasets named as Reuters-21,578, 20Newsgroup, Enron1 and Polarity in addition to Support Vector Machines (SVM), Decision Tree (DT) and Multinomial Naive Bayes (MNB) classifiers. Also, it was employed 50, 100, 300, 500, 1000 and 3000 as dimension. Experimental studies on benchmark datasets show that the efficiency of the proposed method is higher performance than the other three methods named as maximum (MAX), sum (SUM), and weighted-sum (AVG), in most cases according to Micro-F1 and Macro-F1 scores.
C1 [Parlak, Bekir] Amasya Univ, Dept Comp Engn, Amasya, Turkiye.
C3 Amasya University
RP Parlak, B (corresponding author), Amasya Univ, Dept Comp Engn, Amasya, Turkiye.
EM bekir.parlak@amasya.edu.tr
RI PARLAK, Bekir/IXM-9534-2023
CR Agnihotri D, 2019, APPL INTELL, V49, P1597, DOI 10.1007/s10489-018-1349-1
   Agnihotri D, 2017, EXPERT SYST APPL, V81, P268, DOI 10.1016/j.eswa.2017.03.057
   Aslantas P, 2020, J Soft Comput Data Mining, P44, DOI [10.30880/jscdm.2020.01.02.005, DOI 10.30880/JSCDM.2020.01.02.005]
   Asuncion A., 2007, Uci machine learning repository
   Debole F, 2004, STUD FUZZ SOFT COMP, V138, P81
   Deng XL, 2019, MULTIMED TOOLS APPL, V78, P3797, DOI 10.1007/s11042-018-6083-5
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   Forman G., 2003, Journal of Machine Learning Research, V3, P1289, DOI 10.1162/153244303322753670
   Gupta STP, 2019, PROCEEDINGS OF 3RD INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND DATA MINING (ICISDM 2019), P133, DOI 10.1145/3325917.3325935
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   Khan J, 2021, IEEE ACCESS, V9, P140590, DOI 10.1109/ACCESS.2021.3118982
   Khurana A, 2020, MULTIMED TOOLS APPL, V79, P23821, DOI 10.1007/s11042-020-09013-2
   Kou G, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105836
   Kumar A, 2022, MULTIMED TOOLS APPL, V81, P34615, DOI 10.1007/s11042-021-11340-x
   Madasu A, 2020, MULTIMED TOOLS APPL, V79, P6313, DOI 10.1007/s11042-019-08409-z
   Onan A, 2018, J INF SCI, V44, P28, DOI 10.1177/0165551516677911
   Özgür A, 2005, LECT NOTES COMPUT SC, V3733, P606
   Parlak B, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.7140
   Parlak B, 2023, J INF SCI, V49, P59, DOI 10.1177/0165551521991037
   Parlak B, 2021, J INF SCI, V47, P727, DOI 10.1177/0165551520930897
   Parlak B, 2020, J INF SCI, V46, P648, DOI 10.1177/0165551519860982
   Porter M.F., 1997, Readings in information retrieval
   Rehman A, 2018, EXPERT SYST APPL, V114, P78, DOI 10.1016/j.eswa.2018.07.028
   Rehman A, 2017, INFORM PROCESS MANAG, V53, P473, DOI 10.1016/j.ipm.2016.12.004
   Rehman A, 2015, EXPERT SYST APPL, V42, P3670, DOI 10.1016/j.eswa.2014.12.013
   Shunmugapriya P, 2017, SWARM EVOL COMPUT, V36, P27, DOI 10.1016/j.swevo.2017.04.002
   Tasci S, 2013, EXPERT SYST APPL, V40, P4871, DOI 10.1016/j.eswa.2013.02.019
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   Uysal AK, 2018, IEEE ACCESS, V6, P43233, DOI 10.1109/ACCESS.2018.2863547
   Uysal AK, 2016, EXPERT SYST APPL, V43, P82, DOI 10.1016/j.eswa.2015.08.050
   Uysal AK, 2014, INFORM PROCESS MANAG, V50, P104, DOI 10.1016/j.ipm.2013.08.006
   Uysal AK, 2012, KNOWL-BASED SYST, V36, P226, DOI 10.1016/j.knosys.2012.06.005
   Xia T, 2021, NEUROCOMPUTING, V444, P48, DOI 10.1016/j.neucom.2021.02.075
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zong W, 2015, INT J PROD ECON, V165, P215, DOI 10.1016/j.ijpe.2014.12.035
NR 36
TC 3
Z9 3
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 APR 25
PY 2023
DI 10.1007/s11042-023-15459-x
EA APR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R8JH0
UT WOS:001066758900009
DA 2024-07-18
ER

PT J
AU Chen, H
   Xu, FY
AF Chen, Hui
   Xu, Fangyong
TI 3D symmetry detection by a single image and geometric transformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geometric transformation; Point cloud; Reflection symmetry; Symmetry
   detection
ID REFLECTION SYMMETRY
AB Three dimensional symmetry plane detection is a hot research topic in the field of computer vision. When detecting the symmetry plane, the integrity of the three-dimensional point cloud is often ignored, and it is often defaulted to be complete and absolutely symmetrical, which makes the mirror key points relatively easy to be found.This proposes a method for 3D symmetry plane detection based on 2D image and transformation. In detail, the proposed method firstly detects the mirror key points in a single 2D image of the target, then selects the corresponding points in the 2D image and the 3D point cloud to construct a transformation matrix, and finally obtains the mirror key points in the 3D point cloud based on the 2D mirror key points and the transformation matrix to detect the symmetry plane. Experimental evaluations are performed on both synthetic and real point cloud datasets. The results show that the proposed approach is effective for the complete point cloud as well as the incomplete point cloud. Compared with the other two methods, it is proved that the symmetry plane detected by the proposed method is more accurate. The experimental results show that the symmetry plane detected by the proposed method is more accurate than the other two comparison methods. Then the experimental results on incomplete point clouds show that the proposed method could detect symmetry plane effective.
C1 [Chen, Hui; Xu, Fangyong] Shanghai Univ Elect Power, Coll Automat Engn, Shanghai 200090, Peoples R China.
C3 Shanghai University of Electric Power
RP Chen, H (corresponding author), Shanghai Univ Elect Power, Coll Automat Engn, Shanghai 200090, Peoples R China.
EM chenhui@shiep.edu.cn
FU National Natural Science Foundation of China [51705304]; Natural Science
   Foundation of Shanghai General Program [20ZR1421300]; Shanghai Pujiang
   Program [21PJD025]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 51705304, in part by the Natural Science
   Foundation of Shanghai General Program under Grant 20ZR1421300, and in
   part by the Shanghai Pujiang Program under Grant 21PJD025.
CR Atadjanov IR, 2016, LECT NOTES COMPUT SC, V9907, P3, DOI 10.1007/978-3-319-46487-9_1
   Cheng L, 2018, IEEE J-STARS, V11, P285, DOI 10.1109/JSTARS.2017.2752765
   Cicconet M, 2017, IEEE INT CONF COMP V, P1759, DOI 10.1109/ICCVW.2017.207
   DANG QV, 2014, IEEE S COMP INT CONT, P1, DOI DOI 10.1109/CICA.2014.7013249
   Daras P, 2012, IEEE T MULTIMEDIA, V14, P374, DOI 10.1109/TMM.2011.2176111
   Elawady M, 2017, IEEE INT CONF COMP V, P1734, DOI 10.1109/ICCVW.2017.203
   Funk C, 2017, IEEE INT CONF COMP V, P1692, DOI 10.1109/ICCVW.2017.198
   Gao L, 2021, IEEE T VIS COMPUT GR, V27, P3007, DOI 10.1109/TVCG.2020.3003823
   Gao Z, 2019, MULTIMED TOOLS APPL, V78, P555, DOI 10.1007/s11042-017-5270-0
   Ge YY, 2020, BIOSYST ENG, V197, P188, DOI 10.1016/j.biosystemseng.2020.07.003
   Hosoki D, 2019, INT C CONTR AUTOMAT, P1037, DOI [10.23919/iccas47443.2019.8971537, 10.23919/ICCAS47443.2019.8971537]
   Ji PL, 2019, MULTIMED TOOLS APPL, V78, P35471, DOI 10.1007/s11042-019-08043-9
   Korman S, 2015, COMPUT GRAPH FORUM, V34, P2, DOI 10.1111/cgf.12454
   Li B, 2016, GRAPH MODELS, V83, P2, DOI 10.1016/j.gmod.2015.09.003
   Liu ZB, 2013, J COMPUT SCI TECH-CH, V28, P836, DOI 10.1007/s11390-013-1382-9
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Loy G, 2006, LECT NOTES COMPUT SC, V3952, P508
   Mitra NJ, 2013, COMPUT GRAPH FORUM, V32, P1, DOI 10.1111/cgf.12010
   Nagar R, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107483
   Nagar R, 2019, IEEE T SIGNAL PROCES, V67, P1582, DOI 10.1109/TSP.2019.2893835
   Noori SMR, 2020, PHYS ENG SCI MED, V43, P1087, DOI 10.1007/s13246-020-00909-9
   Sawada Tadamasa, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4562976
   Sawada T, 2010, J VISION, V10, DOI 10.1167/10.6.4
   Shi YF, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417775
   Tao DC, 2008, IEEE T CIRC SYST VID, V18, P1397, DOI 10.1109/TCSVT.2008.2002825
   Wu ZL, 2021, PROCEDIA COMPUT SCI, V183, P32, DOI 10.1016/j.procs.2021.02.027
   Yang AY, 2005, COMPUT VIS IMAGE UND, V99, P210, DOI 10.1016/j.cviu.2005.01.004
NR 27
TC 0
Z9 0
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41005
EP 41020
DI 10.1007/s11042-023-14955-4
EA APR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000967980300006
DA 2024-07-18
ER

PT J
AU Devi, HS
   Mohapatra, H
AF Devi, Hidangmayum Saxena
   Mohapatra, Hitesh
TI A novel robust blind medical image watermarking using GWO optimized
   DWT-DCT-SVD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete wavelet transform; Discrete cosine transform; Grey wolf
   optimization; Singular value decomposition
ID SECURITY
AB This paper aims at producing a new, robust, and efficient blind medical image watermarking system for CT scan, X-ray, MRI, and Ultrasound Dicom images. In this work, three binary watermark images are used to hide one at a time in the cover image by proposing a novel GWO-optimized hybrid DWT-DCT-SVD scheme. The reason for combining DWT and DCT is to select the position where to hide the message and SVD for conversion of the DCT matrix into the singular matrix and grey wolf optimization decides the gain value to be used to insert the message bits at selected positions. The performance criteria used for image watermarking are Peak Signal to Noise Ratio (PSNR), NCC(Normalized Cross-Correlation) values. It is noticed from the experimental results that the proposed method works more effectively than the existing systems in majority of the image processing attacks.
C1 [Devi, Hidangmayum Saxena] Natl Inst Technol, Dept Comp Sci & Engn, Langol, Manipur, India.
   [Mohapatra, Hitesh] KIIT Univ, Sch Comp Engn, Bhubaneswar 751024, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Manipur; Kalinga Institute of Industrial Technology (KIIT)
RP Mohapatra, H (corresponding author), KIIT Univ, Sch Comp Engn, Bhubaneswar 751024, Odisha, India.
EM sanahidangmayum@gmail.com; hiteshmahapatra@gmail.com
RI DEVI, HIDANGMAYUM Saxena/ABD-9327-2020; Mohapatra, Hitesh/N-9060-2017
OI DEVI, HIDANGMAYUM Saxena/0000-0003-4567-014X; Mohapatra,
   Hitesh/0000-0001-8100-4860
CR [Anonymous], 2018, International Journal of Engineering & Technology, DOI DOI 10.14419/IJET.V7I1.9.9729
   Aparna P., 2020, International Journal of Computational Vision and Robotics, V10, P1
   Aparna P, 2020, J INTELL SYST, V29, P1558, DOI 10.1515/jisys-2018-0370
   Aparna P, 2018, J INTELL SYST, V27, P115, DOI 10.1515/jisys-2017-0266
   Arunkumar S, 2019, MEASUREMENT, V139, P426, DOI 10.1016/j.measurement.2019.02.069
   Coatrieux G, 2006, 2006 28TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-15, P6118
   Giakoumaki A, 2003, P ANN INT IEEE EMBS, V25, P856, DOI 10.1109/IEMBS.2003.1279900
   Gunjal BL., 2012, INT J COMPUT INF ENG, V6, P997
   Jingjun Zhou, 2019, Cyberspace Safety and Security. 11th International Symposium, CSS 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11982), P501, DOI 10.1007/978-3-030-37337-5_41
   Kavitha V, 2018, J MED IMAG HEALTH IN, V8, P1857, DOI 10.1166/jmihi.2018.2513
   Kishore P. V. V., 2015, Journal of Theoretical and Applied Information Technology, V80, P528
   Kishore PVV, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION ENGINEERING SYSTEMS (SPACES), P270, DOI 10.1109/SPACES.2015.7058263
   Kishore PVV, 2014, 2014 FIRST INTERNATIONAL CONFERENCE ON NETWORKS & SOFT COMPUTING (ICNSC), P258, DOI 10.1109/CNSC.2014.6906662
   Kishore PVV, 2015, 2015 IEEE INT C EL C, P1
   MAMATHA P, 2016, INDIAN J SCI TECHNOL, V9, pNI305, DOI DOI 10.17485/ijst/2016/v9i17/93088
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Nagpal Sujata, 2016, International Journal of Modern Education and Computer Science, V8, P46, DOI 10.5815/ijmecs.2016.04.06
   Navas K., 2007, P INTERNATION C SCI, P25
   Planitz B, 2005, P AUSTR PATT REC SOC
   Prakash M. P., 2018, Int. J. Pure Appl. Math, V118, P265
   Rao NV, 2011, INF SECUR J, V20, P148, DOI 10.1080/19393555.2011.561154
   Salama AS, 2019, J MED IMAG HEALTH IN, V9, P610, DOI 10.1166/jmihi.2019.2571
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thanki R, 2017, IMAGING SCI J, V65, P457, DOI 10.1080/13682199.2017.1367129
   Velumani R, 2010, IEEE INT C COMP INT, P1, DOI DOI 10.1109/ICCIC.2010.5705832)
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zermi N, 2021, MULTIMED TOOLS APPL, V80, P24823, DOI 10.1007/s11042-021-10712-7
NR 28
TC 3
Z9 3
U1 6
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41267
EP 41286
DI 10.1007/s11042-023-15158-7
EA APR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000967652700004
DA 2024-07-18
ER

PT J
AU Kunhoth, J
   Subramanian, N
   Al-Maadeed, S
   Bouridane, A
AF Kunhoth, Jayakanth
   Subramanian, Nandhini
   Al-Maadeed, Somaya
   Bouridane, Ahmed
TI Video steganography: recent advances and challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video steganography; Raw and compressed videos; Data hiding; Motion
   vectors; Discrete Wavelet Transform (DWT); Discrete Cosine Transform
   (DCT)
ID DATA HIDING ALGORITHM; H.264/AVC VIDEO; DIGITAL IMAGES; SCHEME; ROBUST;
   STEGANALYSIS; STREAMS; SECURE
AB Video steganography approach enables hiding chunks of secret information inside video sequences. The features of video sequences including high capacity as well as complex structure make them more preferable for choosing as cover media over other media such as image, text, or audio. Video steganography is a prominent as well as the evolving field in the information security domain and significant number of video steganography methods are proposed in recent years. This article provides a comprehensive review of video steganography methods proposed in the literature. This article initially reviews various raw domain-based video steganography methods. In particular, the raw domain-based methods include spatial domain approaches such as least significant bits (LSB), transform domain-based methods such as discrete wavelet transform, discrete cosine transform, etc. Furthermore, the article looks into various compressed domain steganography methods. A critical comparative analysis is included in the article to analyze and contrast the steganography methods proposed in the literature. A brief description of various evaluation matrices for video steganography methods is provided in this article. Moreover, a brief introduction to steganalysis and video steganalysis is provided. The article concludes with a discussion focused on the limitations and challenges of the video steganography methods. Further, a brief insight into future directions in video steganography systems is provided.
C1 [Kunhoth, Jayakanth; Subramanian, Nandhini; Al-Maadeed, Somaya] Qatar Univ, Comp Sci & Engn, Al Jamia St, Doha, Qatar.
   [Bouridane, Ahmed] Univ Sharjah, Cybersecur & Data Analyt Res Ctr, Sharjah, U Arab Emirates.
C3 Qatar University; University of Sharjah
RP Kunhoth, J (corresponding author), Qatar Univ, Comp Sci & Engn, Al Jamia St, Doha, Qatar.
EM j.kunhoth@qu.edu.qa; nandhini.reborn@gmail.com; S_alali@qu.edu.qa;
   abouridane@sharjah.ac.ae
OI Kunhoth, Jayakanth/0000-0002-8972-0893
FU Qatar National Library; Qatar National Research Fund (a member of Qatar
   Foundation) [NPRP11S-0113-180276]
FX Open Access funding provided by the Qatar National Library. This work
   was made possible by NPRP11S-0113-180276 from the Qatar National
   Research Fund (a member of Qatar Foundation).
CR Abbas SA, 2015, 2015 IEEE SEVENTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INFORMATION SYSTEMS (ICICIS), P572, DOI 10.1109/IntelCIS.2015.7397279
   Ahmed EAE., 2014, INT J SCI RES, V3, P2431
   Al-Khater WA, 2020, IEEE ACCESS, V8, P137293, DOI 10.1109/ACCESS.2020.3011259
   Alavianmehr M. A., 2012, 2012 2nd International eConference on Computer and Knowledge Engineering (ICCKE 2012), P194, DOI 10.1109/ICCKE.2012.6395377
   Aly HA, 2011, IEEE T INF FOREN SEC, V6, P14, DOI 10.1109/TIFS.2010.2090520
   Balu S, 2019, CLUSTER COMPUT, V22, pS4057, DOI 10.1007/s10586-018-2639-4
   Banik BG, 2019, INTELL INNOV MULTIME, P88
   Battisti F., 2006, 3 INT C COMP DEV COM
   Bhawna, 2021, Computational Methods and Data Engineering. Proceedings of ICMDE 2020. Advances in Intelligent Systems and Computing (AISC 1257), P511, DOI 10.1007/978-981-15-7907-3_39
   Bohme R, 2010, PRINCIPLES MODERN ST, P11, DOI [10.1007/978-3-642-14313-7_2, DOI 10.1007/978-3-642-14313-7_2]
   Cao Y, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P23, DOI 10.1145/3206004.3206014
   Cao Y, 2015, IEEE COMMUN LETT, V19, P203, DOI 10.1109/LCOMM.2014.2387160
   Cetin O, 2012, IMAGING SCI J, V60, P75, DOI 10.1179/1743131X11Y.0000000004
   Chang PC, 2014, J VIS COMMUN IMAGE R, V25, P239, DOI 10.1016/j.jvcir.2013.10.007
   Dalal M, 2020, INF SECUR J, V29, P40, DOI 10.1080/19393555.2020.1714822
   Dalal M, 2019, MULTIMED TOOLS APPL, V78, P5769, DOI 10.1007/s11042-018-6093-3
   Dasgupta K., 2012, INT J SECURITY PRIVA, V1
   Nguyen DC, 2019, MULTIMED TOOLS APPL, V78, P16033, DOI 10.1007/s11042-018-6976-3
   Dua D., 2017, UCI MACHINE LEARNING
   Duan XT, 2019, IEEE ACCESS, V7, P9314, DOI 10.1109/ACCESS.2019.2891247
   Duan XT, 2018, CMC-COMPUT MATER CON, V55, P483, DOI 10.3970/cmc.2018.01798
   Elharrouss Omar, 2020, 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT), P131, DOI 10.1109/ICIoT48696.2020.9089566
   Eltahir ME, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P550, DOI 10.1109/ICIME.2009.13
   Fang DY, 2006, IEEE INT SYMP CIRC S, P1422
   Ferris J, 2009, PALG STUD THEAT PERF, P1
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Gadicha A.B., 2021, MULTIDISCIPLINARY AP, P99, DOI DOI 10.4018/978-1-7998-7160-6.CH005
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Gupta S., 2012, IJCEM International Journal of Computational Engineering & Management, V15, P40
   Hanafy A., 2008, IEEE MILITARY COMMUN, P1, DOI DOI 10.1109/MILCOM.2008.4753107
   Hao Bin, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P406, DOI 10.1109/ICCSN.2011.6013622
   Htet TT, 2013, 11 INT C COMP APPL I
   Htet TT, 2012, 10 INT C COMP APPL I
   Hu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1231
   Jaiswal A, 2020, 2020 IEEE 17 INDIA C, P1, DOI DOI 10.1109/INDICON49873.2020.9342200
   Jangid S, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P589, DOI 10.1109/ICCONS.2017.8250530
   Jha VK, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS AND ELECTRONICS (COMPTELIX), P315, DOI 10.1109/COMPTELIX.2017.8003986
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Roque JJ, 2009, SECURITY IN INFORMATION SYSTEMS, PROCEEDINGS, P57
   Kar N, 2018, ICT EXPRESS, V4, P6, DOI 10.1016/j.icte.2018.01.003
   Kaur K, 2018, INT ADV RES J SCI EN
   Kaur M, 2014, INT J ADV RES COMPUT, V2
   Kaur Ramandeep, 2016, International Journal of Image, Graphics and Signal Processing, V8, P31, DOI 10.5815/ijigsp.2016.09.05
   Kaur R, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P867, DOI 10.1109/WiSPNET.2016.7566255
   Kelash HM, 2014, INT J COMPUT NETW TE, V2
   Khan, 2015, INT J INNOV REAS SCI, V4
   Khupse S, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P811, DOI 10.1109/ICICICT.2014.6781384
   Kishor SN, 2016, 2016 INT C RES ADV I, P1, DOI [10.1109/RAINS.2016.7764373, DOI 10.1109/RAINS.2016.7764373]
   Kolakalur Anush, 2016, International Journal of Engineering and Technology, V8, P165, DOI 10.7763/IJET.2016.V8.878
   Koppanati K., 2019, INT C DEEP LEARN ART, P246
   Koppanati RK, 2021, IEEE CONSUM ELECTR M, V10, P41, DOI 10.1109/MCE.2020.3003127
   Kordov K, 2019, VIDEO STEGANOGRAPHY, V5, P15
   Korgaonkar VV, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P421, DOI 10.1109/RTEICT.2017.8256631
   Kumar K, 2019, IETE TECH REV, V36, P265, DOI 10.1080/02564602.2018.1454347
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar K, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN ELECTRONICS, SIGNAL PROCESSING AND COMMUNICATION (IESC), P106, DOI 10.1109/IESPC.2017.8071874
   Kumar P, 2018, MULTIMED TOOLS APPL, V77, P24247, DOI 10.1007/s11042-018-5709-y
   Kuppusamy PG, 2020, SCALABLE COMPUT-PRAC, V21, P63, DOI 10.12694/scpe.v21i1.1613
   Liao K, 2012, TELECOMMUN SYST, V49, P261, DOI 10.1007/s11235-010-9372-5
   Liao YC, 2009, JCPC: 2009 JOINT CONFERENCE ON PERVASIVE COMPUTING, P185, DOI 10.1109/JCPC.2009.5420191
   Lin TJ, 2013, J SYST SOFTWARE, V86, P604, DOI 10.1016/j.jss.2012.10.922
   Lin WB, 2021, STAT FEATURE BASED S
   Lin WB, 2021, ARAB J SCI ENG, V46, P8525, DOI 10.1007/s13369-021-05554-2
   Liu M. M., 2017, ARXIV
   Liu SH, 2007, LECT NOTES COMPUT SC, V4681, P667
   Liu SY, 2020, COGN SYST RES, V59, P207, DOI 10.1016/j.cogsys.2019.09.008
   Liu YX, 2019, NEUROCOMPUTING, V335, P238, DOI 10.1016/j.neucom.2018.09.091
   Liu YX, 2019, MULTIMED TOOLS APPL, V78, P6459, DOI 10.1007/s11042-018-6320-y
   Liu YX, 2016, NEUROCOMPUTING, V188, P113, DOI 10.1016/j.neucom.2015.02.102
   Liu YX, 2016, NEUROCOMPUTING, V188, P63, DOI 10.1016/j.neucom.2014.10.109
   Liu YX, 2014, MULTIMED TOOLS APPL, V72, P613, DOI 10.1007/s11042-013-1393-0
   Lu YQ, 2010, LECT NOTES COMPUT SC, V6059, P469
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Ma X, 2009, INT S COMP NETW MULT, P1, DOI DOI 10.1109/CNMT.2009.5374766
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Manisha S, 2019, MULTIDIM SYST SIGN P, V30, P529, DOI 10.1007/s11045-018-0568-2
   Mishra A., 2019, BMVC, P274
   Moon SK, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P660, DOI 10.1109/ICIIP.2013.6707677
   Mstafa R.J., 2016, Journal of Cyber Security and Mobility, V5, P167
   Mstafa RJ, 2020, IEEE ACCESS, V8, P161825, DOI 10.1109/ACCESS.2020.3021356
   Mstafa RJ, 2015, WIREL TELECOMM SYMP
   Mstafa RJ, 2017, MULTIMED TOOLS APPL, V76, P21749, DOI 10.1007/s11042-016-4055-1
   Mstafa RJ, 2017, IEEE ACCESS, V5, P5354, DOI 10.1109/ACCESS.2017.2691581
   Mstafa RJ, 2015, 2015 IEEE LONG ISLAND SYSTEMS, APPLICATIONS AND TECHNOLOGY CONFERENCE (LISAT)
   Mstafa RJ, 2014, 2014 IEEE LONG ISLAND SYSTEMS, APPLICATIONS AND TECHNOLOGY CONFERENCE (LISAT)
   Mstafa RJ, 2015, ASEE NE SECTION C 20
   Mumthas S, 2017, PROCEDIA COMPUT SCI, V115, P660, DOI 10.1016/j.procs.2017.09.152
   Narayanan K., 2012, J COMPUT APPL, V5, P358
   Nissar A, 2010, DIGIT SIGNAL PROCESS, V20, P1758, DOI 10.1016/j.dsp.2010.02.003
   Niu K, 2019, IEEE ACCESS, V7, P61523, DOI 10.1109/ACCESS.2019.2902464
   Niu Ke, 2013, 2013 IEEE 4th International Conference on Software Engineering and Service Science (ICSESS), P447, DOI 10.1109/ICSESS.2013.6615345
   Nyo HL, 2019, INT J COMPUT NETW IN, V11
   Patel K, 2013, INT CONF COMM SYST, P497, DOI 10.1109/CSNT.2013.109
   Raja Ratna S, 2019, INTELLIGENT COMMUNIC, P626
   Rajalakshmi K, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Rajesh G. R., 2013, IET Chennai Fourth International Conference on Sustainable Energy and Intelligent Systems (SEISCON 2013), P554
   RAMALINGAM M, 2015, INDIAN J SCI TECHNOL, V8, P79
   RAMALINGAM M, 2014, INDIAN J SCI TECHNOL, V7, P897
   Ramalingam M., 2011, Int J Informat Commun Eng, V5, P170, DOI [10.5281/zenodo.1070343, DOI 10.5281/ZENODO.1070343]
   Sadek MM, 2017, MULTIMED TOOLS APPL, V76, P3065, DOI 10.1007/s11042-015-3170-8
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Saini A, 2017, INT J ADV RES COMPUT, V8
   Sairam TD, 2019, AUTOMATIKA-UK, V60, P285, DOI 10.1080/00051144.2019.1579434
   Seeling P, 2012, IEEE COMMUN SURV TUT, V14, P1142, DOI 10.1109/SURV.2011.082911.00067
   Sharma Shikhar, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P51, DOI 10.1007/978-981-10-7895-8_5
   ShengDun Hu, 2011, Proceedings of the 2011 IEEE 14th International Conference on Computational Science and Engineering (CSE 2011). 11th International Symposium on Pervasive Systems, Algorithms, Networks (I-SPAN 2011). 10th IEEE International Conference on Ubiquitous Computing and Communications (IUCC 2011), P57, DOI 10.1109/CSE.2011.24
   Shukur WA, 2018, J PHYS CONF SER, V1003, DOI 10.1088/1742-6596/1003/1/012035
   Si Liu, 2020, Intelligent Computing Methodologies. 16th International Conference, ICIC 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science. (LNAI 12465), P624, DOI 10.1007/978-3-030-60796-8_54
   Subramanian Nandhini, 2021, Visions and Concepts for Education 4.0. Proceedings of the 9th International Conference on Interactive Collaborative and Blended Learning (ICBL2020). Advances in Intelligent Systems and Computing (AISC 1314), P520, DOI 10.1007/978-3-030-67209-6_56
   Subramanian N, 2021, IEEE ACCESS, V9, P23409, DOI 10.1109/ACCESS.2021.3053998
   Suresh M, 2020, MULTIMED TOOLS APPL, V79, P27023, DOI 10.1007/s11042-020-09330-6
   Suresh M, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P877, DOI 10.1109/ICCONS.2018.8662920
   Sushmitha MC, 2017, IEEE ICCE, P72, DOI 10.1109/ICCE-ASIA.2017.8307831
   Swanson MD, 1997, P SOC PHOTO-OPT INS, V3229, P32, DOI 10.1117/12.290362
   Swati S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105613
   Thakur A, 2015, INT J COMPUT APPL, V123
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Volkhonskiy D., 2016, Generative adversarial networks for image steganography
   Volkhonskiy D, 2020, PROC SPIE, V11433, DOI 10.1117/12.2559429
   Wahab OFA, 2015, INT J COMPUT NETW TE, V39
   Wang Y, 2021, IEEE T INF FOREN SEC, V16, P333, DOI 10.1109/TIFS.2020.3013523
   Weng XY, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P87, DOI 10.1145/3323873.3325011
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P685, DOI 10.1109/TIP.2003.810588
   Xu CY, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P297, DOI 10.1109/ICIG.2007.36
   Xu CY, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P269
   Xu DW, 2016, J VIS COMMUN IMAGE R, V36, P229, DOI 10.1016/j.jvcir.2016.02.002
   Xu DW, 2014, LECT NOTES COMPUT SC, V8389, P141, DOI 10.1007/978-3-662-43886-2_10
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Xuansen He, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P822, DOI 10.1109/CSSE.2008.359
   Xue YM, 2019, SIGNAL PROCESS-IMAGE, V76, P22, DOI 10.1016/j.image.2019.04.012
   Yadav P, 2013, 2013 IEEE INT C COMP, P1, DOI DOI 10.1109/ICCIC.2013.6724212
   Yang GB, 2011, AEU-INT J ELECTRON C, V65, P331, DOI 10.1016/j.aeue.2010.03.011
   Yao YZ, 2015, MULTIMED TOOLS APPL, V74, P11163, DOI 10.1007/s11042-014-2223-8
   Younus ZS, 2020, J INTELL SYST, V29, P1216, DOI 10.1515/jisys-2018-0225
   Yun C, 2011, VIDEO STEGANOGRAPHY
   Zhang H, 2016, MULTIMED TOOLS APPL, V75, P13503, DOI 10.1007/s11042-015-2743-x
   Zhang J, 2001, XIV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P179, DOI 10.1109/SIBGRAPI.2001.963053
   Zhang LY, 2017, LECT NOTES COMPUT SC, V10082, P518, DOI 10.1007/978-3-319-53465-7_39
   Zhang Y, 2015, INFORMATICA, V40
   Zhu H., 2010, Proc. 3rd Int.Congr. Image Signal Process., V1, P487
NR 140
TC 10
Z9 10
U1 9
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 41943
EP 41985
DI 10.1007/s11042-023-14844-w
EA APR 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000983404900013
OA hybrid
DA 2024-07-18
ER

PT J
AU Shah, TR
   Batool, A
AF Shah, Tariq
   Batool, Asma
TI Triple byte nonlinear component of block cipher and its application in
   frequency domain watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nonlinear component of block cipher; Galois ring; Watermarking; Discrete
   cosine transform
ID SUBSTITUTION BOX
AB In today's world, digital data such as images, videos, and texts are easily accessible to just about anyone, posing significant security and copyright concerns. An effective tool to address this concern is digital watermarking. We propose a new digital watermarking technique for color images based on discrete cosine transform (DCT) and a triple-byte nonlinear component of a block cipher. We have first constructed a triple byte nonlinear component of block cipher i.e. 24x24 substitution box (S-box) based on the Galois ring GR(2(3),8) and then we use it in watermarking procedure by dividing it into 3 bytes and each byte deals with Red (R), Green (G) and Blue (B) channels separately. We split the watermark and original image into R, G, and B channels. Then we embed the combined S-box substituted R, G, and B channel of the watermark image in the combined DCT applied R, G, and B channel of the original image. Experimental and comparative analysis shows that our proposed method is more secure,effective, and robust than previous schemes.
C1 [Shah, Tariq; Batool, Asma] Quaid i Azam Univ, Dept Math, Islamabad 45320, Pakistan.
C3 Quaid I Azam University
RP Batool, A (corresponding author), Quaid i Azam Univ, Dept Math, Islamabad 45320, Pakistan.
EM asmabatool@math.qau.edu.pk
CR Abdulla A. A., 2015, Ph.D. dissertation
   AGARWAL N, 2022, MULTIMED TOOLS APPL, P1
   Al-Maadeed TA, 2021, MULTIMED TOOLS APPL, V80, P24801, DOI 10.1007/s11042-021-10695-5
   Arya V, 2021, PROC INTEGR INTELL E, P311
   Attaullah, 2020, WIRELESS PERS COMMUN, V110, P1429, DOI 10.1007/s11277-019-06793-1
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P807, DOI 10.1007/s11071-021-06308-3
   Jamal SS, 2019, WIREL NETW, V25, P1491, DOI 10.1007/s11276-017-1606-y
   Lee CF, 2021, HIGH ROBUST BLIND IM
   Moosazadeh M, 2017, OPTIK, V140, P975, DOI 10.1016/j.ijleo.2017.05.011
   Rakhmawati L, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115906
   Shah T, 2022, MULTIMED TOOLS APPL, P1
   Shah T, 2020, WIRELESS PERS COMMUN, V113, P1201, DOI 10.1007/s11277-020-07274-6
   Shah T, 2017, COMPUT APPL MATH, V36, P1273, DOI 10.1007/s40314-015-0281-9
   Shah T, 2013, Z NATURFORSCH A, V68, P567, DOI 10.5560/ZNA.2013-0021
   Shih FY, 2005, J VIS COMMUN IMAGE R, V16, P115, DOI 10.1016/j.jvcir.2004.05.002
   Sinhal R, 2021, PATTERN RECOGN LETT, V145, P171, DOI 10.1016/j.patrec.2021.02.011
   Thanki RM, 2013, P NAT C EM TRENDS IN, P17
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Ullah A, 2017, NONLINEAR DYNAM, V88, P2757, DOI 10.1007/s11071-017-3409-1
   University of Southern California S, 2023, SIPI IMAGE DATABASE
   Yen JC, 2001, ELECTRON LETT, V37, P80, DOI 10.1049/el:20010065
   Yuan ZH, 2020, MULTIMED TOOLS APPL, V79, P30557, DOI 10.1007/s11042-020-09499-w
   Yuqi He, 2018, 2018 2nd IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC). Proceedings, P1214, DOI 10.1109/IMCEC.2018.8469626
   Zhao M, 2008, 4 INT C WIR COMM NET, P1, DOI DOI 10.1109/WICOM.2008.2913
NR 24
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40937
EP 40952
DI 10.1007/s11042-023-15125-2
EA APR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983404900010
DA 2024-07-18
ER

PT J
AU Falcon, A
   Serra, G
   Lanz, O
AF Falcon, Alex
   Serra, Giuseppe
   Lanz, Oswald
TI Video question answering supported by a multi-task learning objective
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video question answering; Word embedding techniques; Vision and
   language; Multi-task learning
AB Video Question Answering (VideoQA) concerns the realization of models able to analyze a video, and produce a meaningful answer to visual content-related questions. To encode the given question, word embedding techniques are used to compute a representation of the tokens suitable for neural networks. Yet almost all the works in the literature use the same technique, although recent advancements in NLP brought better solutions. This lack of analysis is a major shortcoming. To address it, in this paper we present a twofold contribution about this inquiry and its relation with question encoding. First of all, we integrate four of the most popular word embedding techniques in three recent VideoQA architectures, and investigate how they influence the performance on two public datasets: EgoVQA and PororoQA. Thanks to the learning process, we show that embeddings carry question type-dependent characteristics. Secondly, to leverage this result, we propose a simple yet effective multi-task learning protocol which uses an auxiliary task defined on the question types. By using the proposed learning strategy, significant improvements are observed in most of the combinations of network architecture and embedding under analysis.
C1 [Falcon, Alex] Fdn Bruno Kessler, Technol Vis, Via Sommar 18, I-38123 Trento, Italy.
   [Falcon, Alex; Serra, Giuseppe] Univ Udine, AILab, Via Sci 206, I-33100 Udine, Italy.
   [Lanz, Oswald] Free Univ Bozen Bolzano, Fac Comp Sci, Piazza Domenicani 3, I-39100 Bolzano, Italy.
C3 Fondazione Bruno Kessler; University of Udine; Free University of
   Bozen-Bolzano
RP Falcon, A (corresponding author), Fdn Bruno Kessler, Technol Vis, Via Sommar 18, I-38123 Trento, Italy.; Falcon, A (corresponding author), Univ Udine, AILab, Via Sci 206, I-33100 Udine, Italy.
EM afalcon@fbk.eu; giuseppe.serra@uniud.it; lanz@inf.unibz.it
RI Lanz, Oswald/AAW-7865-2021; Serra, Giuseppe/M-3572-2015
OI Falcon, Alex/0000-0002-6325-9066
FU Universita degli Studi di Udine within the CRUI-CARE
FX Open access funding provided by Universita degli Studi di Udine within
   the CRUI-CARE Agreement. No funding was received for conducting this
   study.
CR Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   del Barrio E, 2018, STUD SYST DECIS CONT, V142, P33, DOI 10.1007/978-3-319-73848-2_3
   Devlin J., 2018, BERT PRE TRAINING DE
   Dror R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2773
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan CY, 2019, PROC CVPR IEEE, P1999, DOI 10.1109/CVPR.2019.00210
   Fan CY, 2019, IEEE INT CONF COMP V, P4359, DOI 10.1109/ICCVW.2019.00536
   Fang ZW, 2019, PATTERN RECOGN, V90, P404, DOI 10.1016/j.patcog.2019.01.038
   Gao JY, 2018, PROC CVPR IEEE, P6576, DOI 10.1109/CVPR.2018.00688
   Garcia Noa, 2020, P AAAI C ART INT
   Gardner M.-A., 2017, ARXIV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hori C, 2017, IEEE I CONF COMP VIS, P4203, DOI 10.1109/ICCV.2017.450
   Huang D, 2020, AAAI CONF ARTIF INTE, V34, P11021
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jang Y, 2017, PROC CVPR IEEE, P1359, DOI 10.1109/CVPR.2017.149
   Jiang P, 2020, AAAI CONF ARTIF INTE, V34, P11109
   Jiasen Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10434, DOI 10.1109/CVPR42600.2020.01045
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kim J, 2019, IEEE IJCNN, DOI [10.1109/ijcnn.2019.8852087, 10.1007/s00779-019-01299-w]
   Kim KM, 2018, LECT NOTES COMPUT SC, V11219, P698, DOI 10.1007/978-3-030-01267-0_41
   Kim KM, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2016
   Kingma D. P., 2014, arXiv
   Kipf TN, 2017, INT C LEARN REPR
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5
   Lei J, 2021, PROC CVPR IEEE, P7327, DOI 10.1109/CVPR46437.2021.00725
   Lei J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1369
   Li LJ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2046
   Li XP, 2019, AAAI CONF ARTIF INTE, P8658
   Liu Yinhan, 2019, ARXIV190711692
   Luo Y, 2020, EMNLP
   Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272
   Park J, 2021, PROC CVPR IEEE, P15521, DOI 10.1109/CVPR46437.2021.01527
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7654
   Sanh V., 2019, NEURIPS WORKSHOP
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Seok M., 2016, INT J STW ENG APPL, V10, P93, DOI [DOI 10.14257/ijseia.2016.10.2.08, DOI 10.14257/IJSEIA.2016.10.2.08]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Standley T., 2020, INT C MACHINE LEARNI, P9120, DOI DOI 10.48550/ARXIV.1905.07553
   Sun G, 2021, MOBILE NETW APPL, P1
   Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501
   Ulmer D, 2022, ARXIV
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang J., 2021, IEEE Transactions on Multimedia
   Wang YR, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1022
   Winterbottom T., 2020, BMVC
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Wu Y, 2016, arXiv, P1
   Xiao JB, 2021, PROC CVPR IEEE, P9772, DOI 10.1109/CVPR46437.2021.00965
   Xu DJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1645, DOI 10.1145/3123266.3123427
   Xu H, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P4227
   Yang A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1666, DOI 10.1109/ICCV48922.2021.00171
   Yang ZK, 2020, IEEE WINT CONF APPL, P1545, DOI [10.1109/wacv45572.2020.9093596, 10.1109/WACV45572.2020.9093596]
   Zamir Amir R., 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11194, DOI 10.1109/CVPR42600.2020.01121
   Zhang Y, 2022, IEEE T KNOWL DATA EN, V34, P5586, DOI 10.1109/TKDE.2021.3070203
   Zhao Z, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3683
   Zhu L., 2020, P IEEE CVF C COMP VI, DOI 10.1109/CVPR42600.2020.00877
NR 62
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38799
EP 38826
DI 10.1007/s11042-023-14333-0
EA MAR 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000956328600003
OA hybrid
DA 2024-07-18
ER

PT J
AU Sekhar, CH
   Rao, KV
   Prasad, MHMK
AF Sekhar, C. H.
   Rao, K. Venkata
   Prasad, M. H. M. Krishna
TI Deep neural network empowered bi-directional cross GAN in context of
   classifying DDoS over flash crowd event on web server
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Flash crowd attack; Distributed denial of service attack; Generative
   adversarial network; Deep neural network; E-commerce
ID ATTACK DETECTION
AB DDoS (distributed denial of service) attack is a constant and serious danger to the Internet. New application-layer-based DDoS attacks that use valid requests to overload target resources are more undetected than low-layer DDoS attacks. When flash crowd assaults imitate or occur during a flash crowd event on webservers, the situation may become more dangerous. Flash Crowd Assaults (FCAs) are DDoS attacks that flood victim services, such as Web servers, with well-formed requests created by a large number of bots. Because both valid and attack requests appear identical, it's difficult to identify and filter such attacks.Hence, differentiating DDoS and FC is a critical task in protecting web servers against attacks, which can be fatal to cyber-systems.In this article, a novel Deep Neural Network empowered Bi-Directional Cross Generative Adversarial Network (GAN) is introduced for recognizing and separating distributed denial-of-service attacks from flash crowd attacks over web applications. The suggested research uses an ensemble feature selection approach to construct real samples of attack data in order to accomplish the goal. In the meanwhile, the generator network uses a bidirectionally cross GAN to generate bogus attack data by observing the random noise vector as input. The discriminator receives both manual and model input and using DNN to distinguish between DDoS assaults and flash crowd attacks. The proposed model is implemented in the working platform of python and is tested using the evaluation metrics like accuracy, precision, recall, and f1-measure.From the implementation result, is evident that the proposed model achieves an effective performance in whichthe obtained accuracy of the proposed approach is 96.58% which is comparatively higher than the existing techniques.
C1 [Sekhar, C. H.] JNTU Kakinada, Dept Comp Sci & Engn, Kakinada, Andhra Pradesh, India.
   [Rao, K. Venkata] Guru Nanak Inst Tech Campus, Dept Comp Sci & Engn, Ibrahimpatnam, Telangana, India.
   [Prasad, M. H. M. Krishna] Univ Coll Engn Kakinada Autonomous, JNTUK, Dept Comp Sci & Engn, Kakinada, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Kakinada; Guru Nanak
   Institutions Technical Campus; Jawaharlal Nehru Technological University
   - Kakinada
RP Sekhar, CH (corresponding author), JNTU Kakinada, Dept Comp Sci & Engn, Kakinada, Andhra Pradesh, India.
EM sekhar1203@gmail.com
RI Chipurupalli, SEKHAR/AAU-1651-2020
OI Chipurupalli, SEKHAR/0000-0001-5603-1453
CR Adi E, 2017, J NETW COMPUT APPL, V91, P1, DOI 10.1016/j.jnca.2017.04.015
   Ahmadi S, 2021, 2021 IEEE INTERNATIONAL FLEXIBLE ELECTRONICS TECHNOLOGY CONFERENCE (IFETC), DOI 10.1109/IFETC49530.2021.9580515
   Ahmed N, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/6503299
   Al-Rahmi WM, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12125052
   Aleesa AM, 2020, NEURAL COMPUT APPL, V32, P9827, DOI 10.1007/s00521-019-04557-3
   Anthi E, 2021, COMPUT SECUR, V108, DOI 10.1016/j.cose.2021.102352
   Behal S, 2018, J NETW COMPUT APPL, V111, P49, DOI 10.1016/j.jnca.2018.03.024
   Çakmakçi SD, 2020, J NETW COMPUT APPL, V168, DOI 10.1016/j.jnca.2020.102756
   Silva FSD, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113078
   de Lima FS, 2019, SECUR COMMUN NETW, V2019, DOI 10.1155/2019/1574749
   Dong S, 2020, IEEE ACCESS, V8, P5039, DOI 10.1109/ACCESS.2019.2963077
   Doshi R, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P29, DOI 10.1109/SPW.2018.00013
   Galeano-Brajones J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030816
   Gera J, 2018, EURASIP J INF SECUR, DOI 10.1186/s13635-018-0079-6
   Huh JH, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147718767630
   Idhammad M, 2018, APPL INTELL, V48, P3193, DOI 10.1007/s10489-018-1141-2
   Mayuranathan M, 2021, J AMB INTEL HUM COMP, V12, P3609, DOI 10.1007/s12652-019-01611-9
   Muraleedharan N, 2021, ICT EXPRESS, V7, P210, DOI 10.1016/j.icte.2020.08.005
   Panigrahi R., 2018, International Journal of Engineering & Technology, V7, P479, DOI DOI 10.14419/IJET.V7I3.24.22797
   Park SW, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10101216
   Park SW, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040688
   Grammatikis PR, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185305
   Ravi N, 2020, IEEE INTERNET THINGS, V7, P3559, DOI 10.1109/JIOT.2020.2973176
   Sahoo KS, 2019, J SUPERCOMPUT, V75, P4829, DOI 10.1007/s11227-019-02767-z
   Sambangi S., 2020, 14 INT C INT ENG INT, P51, DOI [10.3390/proceedings2020063051, DOI 10.3390/PROCEEDINGS2020063051]
   Sekhar C., 2021, TURK J COMPUT MATH E, V12, P2990
   Singh J, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100279
   Sreeram Indraneel., 2019, Applied computing and informatics, V15, P59, DOI DOI 10.1016/J.ACI.2017.10.003
   Tan L, 2020, IEEE ACCESS, V8, P161908, DOI 10.1109/ACCESS.2020.3021435
   Tuan TA, 2020, EVOL INTELL, V13, P283, DOI 10.1007/s12065-019-00310-w
   Tunio Muhammad Hanif, 2021, 2021 18th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP), P525, DOI 10.1109/ICCWAMTIP53232.2021.9674124
   Ujjan RMA, 2020, FUTURE GENER COMP SY, V111, P763, DOI 10.1016/j.future.2019.10.015
   Virupakshar KB, 2020, PROCEDIA COMPUT SCI, V167, P2297, DOI 10.1016/j.procs.2020.03.282
   Zhao MD, 2018, IEEE C EVOL COMPUTAT, P39, DOI 10.1109/CEC.2018.8477679
NR 34
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 21
PY 2023
DI 10.1007/s11042-023-15030-8
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F6PQ0
UT WOS:000983548500008
DA 2024-07-18
ER

PT J
AU Patel, S
   Vaish, A
AF Patel, Saumya
   Vaish, Ankita
TI Efficient image coding through compressive sensing and chaos theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic map; Compressive sensing; Discrete wavelet
   transform; Arnold scrambling
ID SEMI-TENSOR PRODUCT; ENCRYPTION ALGORITHM; MATRIX; SYSTEM
AB This paper introduces an image coding algorithm for gray scale images based on Block Compressive Sensing (BCS). The Original signal is sparse in Discrete Wavelet Transform (DWT) domain but the proposed work utilizes the virtue of encrypted DWT basis to employ sparsity. To generate encrypted DWT basis piecewise chaotic system is used which will provide more security to the signal. The Measurement Matrix (MM) is generated using hadamard matrix which is controlled by tent chaotic system. Further, the pixel values are mapped so that the values can be normalized in the desired range. Moreover, the seed values of chaotic map which is used to obtain MM and chaotic DWT basis, is used as encryption and decryption keys. To check the effectiveness of the proposed algorithm, it is tested on several test images and simulation results and detailed analysis has been done. It has been found that when the compression ratio is 0.5, the samples are half of the original signal, even then the reconstructed image is perceptually good. Further, the proposed algorithm is also examined against the statistical attacks and the results are fruitful as compared to the existing methods.
C1 [Patel, Saumya; Vaish, Ankita] Banaras Hindu Univ, Comp Sci, Varanasi 221005, UP, India.
C3 Banaras Hindu University (BHU)
RP Patel, S (corresponding author), Banaras Hindu Univ, Comp Sci, Varanasi 221005, UP, India.
EM saumyapatel5@gmail.com; av21lko@gmail.com
RI PATEL, SAUMYA/KQU-8641-2024
OI PATEL, SAUMYA/0000-0002-8692-7194
FU Banaras Hindu University under the seed grant IoE [R/Dev/D/IoE/Seed
   Grant/2020-21/6031]
FX AcknowledgementsThis work is supported by Banaras Hindu University under
   the seed grant IoE (no. R/Dev/D/IoE/Seed Grant/2020-21/6031).
CR [Anonymous], 2014, SCI WORLD J
   Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   Brahim AH, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106489
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107525
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   DYSON FJ, 1992, AM MATH MON, V99, P603, DOI 10.2307/2324989
   Fu JY, 2022, MULTIMED TOOLS APPL, V81, P17401, DOI 10.1007/s11042-022-12607-7
   Gong LH, 2019, OPT LASER ENG, V121, P169, DOI 10.1016/j.optlaseng.2019.03.006
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Gupta A, 2020, J AMB INTEL HUM COMP, V11, P1309, DOI 10.1007/s12652-019-01493-x
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Luo YL, 2019, SIGNAL PROCESS, V161, P227, DOI 10.1016/j.sigpro.2019.03.022
   Monika R, 2021, MULTIMED TOOLS APPL, V80, P4751, DOI 10.1007/s11042-020-09932-0
   Niu Y, 2020, MULTIMED TOOLS APPL, V79, P25613, DOI 10.1007/s11042-020-09237-2
   Pathak S, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON RELIABILTY, OPTIMIZATION, & INFORMATION TECHNOLOGY (ICROIT 2014), P413, DOI 10.1109/ICROIT.2014.6798366
   Ponuma R, 2019, MULTIDIM SYST SIGN P, V30, P1895, DOI 10.1007/s11045-019-00634-x
   Ponuma R, 2018, MULTIMED TOOLS APPL, V77, P19209, DOI 10.1007/s11042-017-5378-2
   Sharma MK., 2013, J ENG COMPUT APPL SC, V2, P1
   Talhaoui MZ, 2021, VISUAL COMPUT, V37, P541, DOI 10.1007/s00371-020-01822-8
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang X, 2021, IEEE T CIRCUITS-I, VI
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZP, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106246
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Yao SY, 2019, OPT LASER TECHNOL, V120, DOI 10.1016/j.optlastec.2019.105703
   Ye CH, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2978571
   YOSHIDA T, 1983, J STAT PHYS, V31, P279, DOI 10.1007/BF01011583
   Zhang Q, 2015, INT CONF INSTR MEAS, P1218, DOI 10.1109/IMCCC.2015.261
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
NR 34
TC 0
Z9 0
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33225
EP 33243
DI 10.1007/s11042-023-14946-5
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000949737500002
DA 2024-07-18
ER

PT J
AU Hongjin, Z
   Hui, W
   Gang, M
AF Hongjin, Zhang
   Hui, Wei
   Gang, Ma
TI A new stereo matching energy model based on image local features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Stereo image processing; Disparity reliable; Local
   feature; Cost function; Weight measurement
ID SUPERPIXEL
AB This paper constructs an energy model based on local features used in stereo matching. The local features include the similarity between different image areas, the matching cost function pattern, the connection between neighbor pixels, and the occlusion geometric relationship. Based on these features, we define the weight of each data term and smoothing term in the energy function and then design an algorithm to solve the energy model and get disparity results. The significant improvements of this paper include as following. 1) We modify the structure of the energy function. First, we define the weight of the data term based on the reliability of its corresponding disparity result, which is obtained by cost function features and the occlusion geometric relationship. Then we define the weight of the smoothing term by analyzing the characteristic relation between neighbor super-pixels. We can also reduce the computational complexity by detecting and reducing some low-strength connections. 2) We proposed an algorithm based on pairwise Markov random field (MRF) (Taniai et al., IEEE Trans Pattern Anal Machine Intell 40(11): 2725-2739, 2017) and local greedy iteratively, which can be used to solve the energy model. 3) In post-optimation, we select some areas with severe occlusion and fewer matching clues for post-interpolation fitting to optimize the results. The experiment shows that the proposed method reduced the average percentage of bad pixels (in bad 3) to 6.06 on the Middlebury dataset and 1.42 on the KITTI dataset. Finally, we compare our results with those of MC-Cnn (Zbontar and LeCun 2015), CF-Net (Shen et al., 2021), Guided-Stereo (Poggi et al., 2019), Gwc-Net (Guo et al., 2019) and Patchmatch-Net(PM-Net) (Wang et al., 2021) to verify the improved speed and accuracy of our algorithm, especially at recognizing the depth of changing edges and small objects. This paper's relevant research can contribute to practical engineering practices such as assisted vision, intelligent driving, and robot grasping control.
C1 [Hongjin, Zhang; Hui, Wei; Gang, Ma] Fudan Univ, Sch Comp Sci, Lab Algorithms Cognit Models, Shanghai 200433, Peoples R China.
C3 Fudan University
RP Hui, W (corresponding author), Fudan Univ, Sch Comp Sci, Lab Algorithms Cognit Models, Shanghai 200433, Peoples R China.
EM 18110240049@fudan.edu.cn; weihui@fudan.edu.cn; 20110240024@fudan.edu.cn
RI Zhang, Hongjin/KJL-6031-2024
OI Zhang, Hongjin/0000-0001-5863-2586; Ma, Gang/0000-0003-3365-5188
CR Bai C, 2018, INT J ADV ROBOT SYST, V15, DOI 10.1177/1729881417751544
   Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chang TA, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0462-3
   Chang Y-J., 2017, ELECT IMAGING, V2017, P124, DOI 10.2352/ISSN.2470-1173.2017.5.SDA-368
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen QY, 2017, IEEE INT CONF COMP V, P99, DOI 10.1109/ICCVW.2017.20
   Cheng FY, 2014, NEUROCOMPUTING, V131, P217, DOI 10.1016/j.neucom.2013.10.022
   Geiger A, 2011, LECT NOTES COMPUT SC, V6492, P25, DOI 10.1007/978-3-642-19315-6_3
   Gu XD, 2020, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR42600.2020.00257
   Guo XY, 2019, PROC CVPR IEEE, P3268, DOI 10.1109/CVPR.2019.00339
   Hamid M.S, 2020, Journal of King Saud University-Computer and Information Sciences
   Hamzah RA, 2018, SIGNAL PROCESS-IMAGE, V65, P165, DOI 10.1016/j.image.2018.04.001
   Hewei Wang, 2021, 2021 6th International Conference on Image, Vision and Computing (ICIVC), P312, DOI 10.1109/ICIVC52351.2021.9527014
   Hirschmüller H, 2002, INT J COMPUT VISION, V47, P229, DOI 10.1023/A:1014554110407
   Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478
   Huang CS, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00525-3
   Jellal Radouane Ait, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P146, DOI 10.1109/ICRA.2017.7989019
   Jiao JB, 2017, INT J COMPUT VISION, V124, P204, DOI 10.1007/s11263-017-1015-9
   Knyaz VA, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12193128
   Kong L., 2021, Mathematical Problems in Engineering, V2021
   Kong LB, 2020, CIRP ANN-MANUF TECHN, V69, P497, DOI 10.1016/j.cirp.2020.04.098
   Lai HY, 2019, PROC CVPR IEEE, P1890, DOI 10.1109/CVPR.2019.00199
   Lee I, 2017, J INF PROCESS SYST, V13, P256, DOI 10.3745/JIPS.02.0057
   Li HC, 2021, INT J ADV ROBOT SYST, V18, DOI 10.1177/17298814211002113
   Li LC, 2018, IEEE T CIRC SYST VID, V28, P679, DOI 10.1109/TCSVT.2016.2628782
   Lim J, 2019, IEEE T PATTERN ANAL, V41, P1203, DOI 10.1109/TPAMI.2018.2819662
   Lin C, 2017, SIGNAL PROCESS-IMAGE, V52, P64, DOI 10.1016/j.image.2017.01.001
   LUO WJ, 2016, PROC CVPR IEEE, P5695, DOI DOI 10.1109/CVPR.2016.614
   Mehltretter M, 2019, IEEE INT CONF COMP V, P2070, DOI 10.1109/ICCVW.2019.00262
   Mozerov MG, 2019, IEEE T IMAGE PROCESS, V28, P2936, DOI 10.1109/TIP.2019.2892668
   Odena A., 2016, DISTILL, V1, pe3, DOI 10.23915/distill.00003.-URL
   Pang JH, 2017, IEEE INT CONF COMP V, P878, DOI 10.1109/ICCVW.2017.108
   Poggi M, 2019, PROC CVPR IEEE, P979, DOI 10.1109/CVPR.2019.00107
   Shen ZL, 2021, PROC CVPR IEEE, P13901, DOI 10.1109/CVPR46437.2021.01369
   Shi, 2019, NEW BASIC CORRELATIO
   Sun J, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P336, DOI 10.1109/ICIVC.2018.8492802
   Taniai T, 2018, IEEE T PATTERN ANAL, V40, P2725, DOI 10.1109/TPAMI.2017.2766072
   Wang FJ, 2021, PROC CVPR IEEE, P14189, DOI 10.1109/CVPR46437.2021.01397
   Wang JL, 2019, PROC CVPR IEEE, P3813, DOI 10.1109/CVPR.2019.00394
   Wu WH, 2019, IEEE ACCESS, V7, P61960, DOI 10.1109/ACCESS.2019.2916035
   Xing Zhang, 2021, Journal of Physics: Conference Series, V1748, DOI 10.1088/1742-6596/1748/4/042011
   Xu HF, 2020, PROC CVPR IEEE, P1956, DOI 10.1109/CVPR42600.2020.00203
   Xue TF, 2019, IMAGE VISION COMPUT, V91, DOI 10.1016/j.imavis.2019.05.006
   Yang QX, 2014, IEEE T PATTERN ANAL, V36, P1026, DOI 10.1109/TPAMI.2013.186
   Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827
   Ye XQ, 2017, IEEE ACCESS, V5, P18745, DOI 10.1109/ACCESS.2017.2754318
   Zbontar J, 2016, J MACH LEARN RES, V17
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
   Zhang B, 2019, AUTOMATIC CONTROL, MECHATRONICS AND INDUSTRIAL ENGINEERING, P31
   Zhang C, 2015, IEEE I CONF COMP VIS, P2057, DOI 10.1109/ICCV.2015.238
   Zhang H, 2020, IET IMAGE PROCESS, V14, P2652, DOI 10.1049/iet-ipr.2019.1636
   Zhi TC, 2018, PROC CVPR IEEE, P1916, DOI 10.1109/CVPR.2018.00205
   Zhu HM, 2017, IET COMPUT VIS, V11, P733, DOI 10.1049/iet-cvi.2016.0446
   [邹进贵 Zou Jingui], 2018, [测绘通报, Bulletin of Surveying and Mapping], P11
NR 55
TC 0
Z9 0
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35651
EP 35684
DI 10.1007/s11042-023-14706-5
EA MAR 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000946493200001
DA 2024-07-18
ER

PT J
AU Yang, D
   Xie, ZQ
   Liu, Q
   Yu, X
AF Yang, Dan
   Xie, Zhiqiang
   Liu, Qi
   Yu, Xu
TI A signal-driven based flexible integrated scheduling algorithm with
   bidirectional coordination mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flexible integrated scheduling; Bidirectional coordination mechanism;
   Flexible integrated scheduling system; Grey relational analysis
ID SHOP; CONSTRAINT
AB Due to the excessive reliance on short-time strategy to weaken the flexibility of equipment, ignore the dual selection relationship between equipment and operations, and ignore the flexibility of the independent operations in the products of tree-like structure in the existing algorithms to solve the flexible integrated scheduling problem, the framework of the flexible integrated scheduling system with three management subsystems is designed. Moreover, the signal-driven based flexible integrated scheduling algorithm with bidirectional coordination mechanism is proposed by simulating the information interaction between the subsystems and the resources. In the proposed algorithm, the bidirectional coordination mechanism is established to coordinate the selection between equipment and operations. Thus, the impact of equipment and operations on each other is fully considered and avoids the problem of focusing too much on one side. The bidirectional scheduling strategy is adopted to eliminate the impact of the scheduling direction of the process tree on the product. Furthermore, the equipment-operation coordination strategy based on grey relational analysis is designed to integrate the impact of the processing time, the relative path, and other factors on the dispatching of machines and operations. Then the optimal combination is adopted to solve the conflict between machines and operations. Finally, the comparison results show that the proposed algorithm has better performance than the other comparison algorithms on the flexible integrated scheduling problem.
C1 [Yang, Dan; Xie, Zhiqiang; Liu, Qi] Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
   [Yu, Xu] Qingdao Univ Sci & Technol, Sch Informat Sci & Technol, Qingdao 266061, Peoples R China.
C3 Harbin University of Science & Technology; Qingdao University of Science
   & Technology
RP Xie, ZQ (corresponding author), Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
EM xiezhiqiang@hrbust.edu.cn
FU National Natural Science Foundation of China [61772160]; Postdoctoral
   Science-research developmental Foundation of Heilongjiang Province
   [LBHQ13092]
FX This work was supported by National Natural Science Foundation of China
   [grant numbers 61772160]; Postdoctoral Science-research developmental
   Foundation of Heilongjiang Province [grant number LBHQ13092].
CR Birgin EG, 2015, EUR J OPER RES, V247, P421, DOI 10.1016/j.ejor.2015.06.023
   Cheng TCE, 2003, COMPUTING, V70, P167, DOI 10.1007/s00607-002-1467-8
   Engin O, 2018, APPL SOFT COMPUT, V72, P166, DOI 10.1016/j.asoc.2018.08.002
   Fattahi P, 2020, ASSEMBLY AUTOM, DOI 10.1108/AA-11-2018-0178
   Gao YL, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12683
   Gao YL, 2020, MULTIMED TOOLS APPL, V79, P32285, DOI 10.1007/s11042-020-09477-2
   [郭伟飞 Guo Weifei], 2020, [计算机集成制造系统, Computer Integrated Manufacturing Systems], V26, P3313
   Guo Weifei, 2020, Journal of Mechanical Engineering, V56, P246, DOI 10.3901/JME.2020.04.246
   Hariri AMA, 1997, EUR J OPER RES, V103, P547, DOI 10.1016/S0377-2217(96)00312-8
   HOITOMT DJ, 1993, IEEE T ROBOTIC AUTOM, V9, P1, DOI 10.1109/70.210791
   IGNALL E, 1965, OPER RES, V13, P400, DOI 10.1287/opre.13.3.400
   [廖不凡 Liao Bufan], 2020, [中国机械工程, China Mechanical Engineering], V31, P1940
   Lin WH, 2022, INT T OPER RES, V29, P496, DOI 10.1111/itor.12767
   Liu M, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105954
   Park BJ, 2003, COMPUT IND ENG, V45, P597, DOI 10.1016/S0360-8352(03)00077-9
   Paul Midhun, 2018, International Journal of Advanced Operations Management, V10, P234
   Paul Midhun, 2016, International Journal of Management Concepts and Philosophy, V9, P362
   Pereira MT, 2011, INT J PROD RES, V49, P6089, DOI 10.1080/00207543.2010.527385
   Shao XY, 2010, INT J ADV MANUF TECH, V48, P1159, DOI 10.1007/s00170-009-2337-8
   Shi F, 2020, INT J PROD RES, V58, P2604, DOI 10.1080/00207543.2019.1622052
   Wang Fu-ji, 2010, Computer Integrated Manufacturing Systems, V16, P115
   Xia YC, 2021, J INTELL FUZZY SYST, V41, P4609, DOI 10.3233/JIFS-189721
   Xie Z., 2021, J MECH ENG SCI, V57, P240, DOI [10.3901/JME.2021.04.240, DOI 10.3901/JME.2021.04.240]
   Xie Z., 2021, J MECH ENG SCI, V57, P217, DOI [10.3901/JME.2021.17.217, DOI 10.3901/JME.2021.17.217]
   Xie Zhi-Qiang, 2017, Transactions of Beijing Institute of Technology, V37, P532, DOI 10.15918/j.tbit1001-0645.2017.05.018
   Xie Zhi-qiang, 2014, Transactions of Beijing Institute of Technology, V34, P1150
   [谢志强 XIE Zhi-qiang], 2010, [计算机科学, Computer Science], V37, P150
   Xie Zhigiang, 2014, Journal of Mechanical Engineering, V50, P203, DOI 10.3901/JME.2014.18.203
   Xie ZQ, 2020, INT J COOP INF SYST, V29, DOI 10.1142/S0218843020400031
   [谢志强 Xie Zhiqiang], 2013, [计算机学报, Chinese Journal of Computers], V36, P818
   [谢志强 Xie Zhiqiang], 2011, [机械工程学报, Chinese Journal of Mechanical Engineering], V47, P177
   Xie ZQ, 2009, COMPUT IND ENG, V57, P766, DOI 10.1016/j.cie.2009.02.004
   Zhang SC, 2020, EUR J OPER RES, V283, P441, DOI 10.1016/j.ejor.2019.11.016
   Zhang SC, 2018, IEEE T ENG MANAGE, V65, P487, DOI 10.1109/TEM.2017.2785774
   Zhang XH, 2019, MULTIMED TOOLS APPL, V78, P29989, DOI 10.1007/s11042-018-6805-8
   Zhang XH, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12305
   Zhang Xiaohuan, 2017, Computer Integrated Manufacturing Systems, V23, P1938, DOI 10.13196/j.cims.2017.09.013
NR 37
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34029
EP 34051
DI 10.1007/s11042-023-14544-5
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000946890000006
DA 2024-07-18
ER

PT J
AU Zhang, XR
   Pan, ZB
   Zhou, Q
   Gao, ER
   Gao, XY
   Fan, GJ
AF Zhang, Xiaoran
   Pan, Zhibin
   Zhou, Quan
   Gao, Erdun
   Gao, Xinyi
   Fan, Guojun
TI A novel two-level embedding pattern for grayscale-invariant reversible
   data hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Grayscale invariant; Novel embedding pattern;
   Two-level predictor
ID PREDICTION-ERROR EXPANSION; SCHEME; WATERMARKING; PARTITION; ALGORITHM;
   SCALE
AB Although traditional reversible data hiding (RDH) methods work well at protecting the secret data and guaranteeing the high visual quality of the cover image as well, the performance of down steaming visual tasks, such as feature extraction and point alignment, is degraded. To address this issue, Hou et al. [13] proposed to embed secret data into color images while keeping the corresponding grayscale invariant. However, we find that the embedding efficiency of this method is still unsatisfactory. And the embedding distortion should be further reduced. In this paper, unit embedding distortion is designed to help evaluate the embedding efficiency of per pixel unit. Then, an adaptive embedding pattern is introduced by adaptively embedding one or two bits of secret data into different positions according to the context information. While our approach provides a novel two-level predictor, benefiting from two normal predictors to reduce the embedding distortion. Experimental results demonstrate that, compared to the previous method, our scheme could significantly enhance the image fidelity while keeping the grayscale invariant.
C1 [Zhang, Xiaoran; Pan, Zhibin; Gao, Erdun; Gao, Xinyi; Fan, Guojun] Xi An Jiao Tong Univ, Fac Elect & Informat Engn, Xian 710049, Peoples R China.
   [Pan, Zhibin] Zhengzhou Xinda Inst Adv Technol, Zhengzhou 450002, Peoples R China.
   [Zhou, Quan] Xian Inst Space Radio Technol, Natl Key Lab Sci & Technol Space Microwave, Xian 710100, Peoples R China.
C3 Xi'an Jiaotong University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Fac Elect & Informat Engn, Xian 710049, Peoples R China.; Pan, ZB (corresponding author), Zhengzhou Xinda Inst Adv Technol, Zhengzhou 450002, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU National Key Laboratory Foundation of Satellite InformationHiding in
   Encryption Domain [6142411432107]; National Natural Science Foundation
   of China [U1903213]; Open Foundation of Henan Key Laboratory of
   Cyberspace Situation Awareness [HNTS2022015]; Key Science and Technology
   Program of Shaanxi Province [2020GY-005]
FX This work is supported in part by the National Key Laboratory Foundation
   of Satellite InformationHiding in Encryption Domain (Grant No.
   6142411432107), the National Natural Science Foundation of China(Grant
   No. U1903213), the Open Foundation of Henan Key Laboratory of Cyberspace
   Situation Awareness(Grant No. HNTS2022015) and the Key Science and
   Technology Program of Shaanxi Province (Grant No. 2020GY-005)
CR Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Fan GJ, 2021, INFORM SCIENCES, V581, P515, DOI 10.1016/j.ins.2021.09.019
   Fan GJ, 2021, SIGNAL PROCESS, V180, DOI 10.1016/j.sigpro.2020.107888
   Gao E, 2019, ARXIV
   Gao ED, 2019, INFORM SCIENCES, V505, P549, DOI 10.1016/j.ins.2019.07.101
   Gao XY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107579
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hou DD, 2019, IEEE T CIRC SYST VID, V29, P363, DOI 10.1109/TCSVT.2018.2803303
   Hou DD, 2018, IEEE T IMAGE PROCESS, V27, P5087, DOI 10.1109/TIP.2018.2851074
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ou B, 2020, IEEE T CIRC SYST VID, V30, P2329, DOI 10.1109/TCSVT.2019.2921812
   Ou B, 2019, IEEE T CIRC SYST VID, V29, P2176, DOI 10.1109/TCSVT.2018.2859792
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Ou B, 2015, SIGNAL PROCESS, V108, P642, DOI 10.1016/j.sigpro.2014.10.012
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Pan ZB, 2020, IEEE SIGNAL PROC LET, V27, P915, DOI 10.1109/LSP.2020.2996507
   Pan ZB, 2015, J VIS COMMUN IMAGE R, V31, P64, DOI 10.1016/j.jvcir.2015.05.005
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Weng SW, 2017, J VIS COMMUN IMAGE R, V48, P317, DOI 10.1016/j.jvcir.2017.05.005
   Weng SW, 2016, J VIS COMMUN IMAGE R, V41, P185, DOI 10.1016/j.jvcir.2016.09.016
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Xiao MY, 2019, SIGNAL PROCESS, V158, P210, DOI 10.1016/j.sigpro.2019.01.008
   Yang WJ, 2012, INFORM SCIENCES, V190, P208, DOI 10.1016/j.ins.2011.11.046
   Yao H, 2017, J VIS COMMUN IMAGE R, V43, P152, DOI 10.1016/j.jvcir.2017.01.004
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 48
TC 1
Z9 1
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33911
EP 33935
DI 10.1007/s11042-023-14789-0
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000946494700015
DA 2024-07-18
ER

PT J
AU Gauni, S
   Bhanupriya, P
   Kalimuthu, K
   Manimegalai, CT
AF Gauni, Sabitha
   Bhanupriya, P.
   Kalimuthu, K.
   Manimegalai, C. T.
TI Correlation and contrast of multi-user edge computation with single-user
   edge computation for data offload on terrain electric vehicular
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single user; Multi-user; Offloading; Smart Onboard Unit (SOBU); Vehicle
   Edge Computing (VEC)
AB Vehicles are getting equipped in technology, communication between vehicle and the user is getting better. The vehicular network is an emerging technology to provide mobile users with the flexibility to use various services such as entertainment and navigation on wheels. The users are served with data related to their travel in terms of road map, weather updates, traffic congestions, radio services, social network applications and place of interest. The data communication takes place with the help of Smart On-board Unit (SOBU) present on the vehicle. There is a requirement of compound data computations with firm latency. Vehicle Edge computing (VEC) is the emerging technology that has serves at the edge in the neighbourhood of vehicle that enables data offloading. There will be much of energy consumption and latency resulting from offloading and computations. In this paper smart offloading scheme is proposed that will efficiently harvest the energy and reduce the energy consumption problem. As a performance statistic, the execution cost is used, which accounts for both execution delay and task failure. And also, the offloading scheme is analyzed for single user and multiuser by simulations and the results are compared graphically for battery energy level, average execution cost and channel mode select parameters respectively. The factors affecting both Single-user and multi-user computation are identified from the results. Experimental results show that offloading schemes proposed for single user and multi user work better than the other state-of-the-art algorithms for vehicular networks. This single-user analysis will be a benchmark for developing auto pilot vehicle for people with special needs and multi-user analysis will help in developing to all kinds of Electric Vehicle communication.
C1 [Gauni, Sabitha; Bhanupriya, P.; Kalimuthu, K.; Manimegalai, C. T.] SRM Inst Sci & Technol, Chennai, India.
C3 SRM Institute of Science & Technology Chennai
RP Gauni, S (corresponding author), SRM Inst Sci & Technol, Chennai, India.
EM sabianup@gmail.com; bp1869@srmist.edu.in
CR Bayrak AE, 2020, IEEE T SYST MAN CY-S, V50, P2716, DOI 10.1109/TSMC.2018.2827387
   Cao YS, 2020, IEEE INTERNET THINGS, V7, P8590, DOI 10.1109/JIOT.2020.2992133
   Chaudhry SA, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5554318
   Deng SG, 2015, IEEE T PARALL DISTR, V26, P3317, DOI 10.1109/TPDS.2014.2381640
   Ge XH, 2016, IEEE WIREL COMMUN, V23, P72, DOI 10.1109/MWC.2016.7422408
   Hussain R, 2019, IEEE COMMUN SURV TUT, V21, P1275, DOI 10.1109/COMST.2018.2869360
   Jiang X, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5599334
   Lin SC, 2018, ACM SIGPLAN NOTICES, V53, P751, DOI [10.1145/3173162.3173191, 10.1145/3296957.3173191]
   Lin Y, 2021, SECUR COMMUN NETW, V2021
   Liu JH, 2018, IEEE ACCESS, V6, P12825, DOI 10.1109/ACCESS.2018.2800032
   Mao YY, 2016, IEEE J SEL AREA COMM, V34, P3590, DOI 10.1109/JSAC.2016.2611964
   Masoudi M., 2017, P IEEE WIR COMM NETW, P1
   Mustafa E, 2022, CLUSTER COMPUT, V25, P2429, DOI 10.1007/s10586-021-03376-3
   Ning ZL, 2019, IEEE T IND INFORM, V15, P3058, DOI 10.1109/TII.2019.2892767
   Sabitha G, 2017, WIRELESS PERS COMMUN, V97, P5089, DOI 10.1007/s11277-017-4768-0
   Shalev-Shwartz S., 2016, arXiv
   Sheikh MS, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/5129620
   Sheng JF, 2019, INFORMATION, V10, DOI 10.3390/info10060191
   Tassi A, 2019, IEEE VTS VEH TECHNOL, DOI 10.1109/vtcspring.2019.8746698
   Wu D, 2021, IEEE T MOBILE COMPUT, V20, P1110, DOI 10.1109/TMC.2019.2954872
   Xu X., 2018, COMPUT INTELL-US, V35, P1275
   Zhang JN, 2020, IEEE WORLD CONGR SER, P75, DOI 10.1109/SERVICES48979.2020.00029
NR 22
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26563
EP 26575
DI 10.1007/s11042-023-14848-6
EA MAR 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000945792800004
DA 2024-07-18
ER

PT J
AU Chen, Y
   Xu, SB
   Long, J
   Xie, YN
AF Chen, Yu
   Xu, Shibao
   Long, Jun
   Xie, Yining
TI DR-Net: Diabetic Retinopathy detection with fusion multi-lesion
   segmentation and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic Retinopathy; Segmentation; Classification; Detection
ID ARCHITECTURE; IMAGES
AB Diabetic Retinopathy (DR) is one of the most common microvascular complications of diabetes mellitus and is a major cause of blurred vision, vision loss, and blindness. Depending on the severity of the disease, DR is divided into non-proliferative diabetic retinopathy (NPDR) and proliferative diabetic retinopathy (PDR). Current research has focused on using Deep Learning (DL) models to classify fundus images based on DR severity. To make the lesions in DR images more visible and to make DR detection easier, this study proposes a two-phase classification model (DR-Net). SR-Net (SE-Block-ResNet) is the first phase of the network in this study, the second phase consists of MT-SNet (Multiple lesions-TransUnet-Segmentation-Net) and SRVGG (SE-Block-RepVGG). The first phase uses ST-Net to classify NPDR images with PDR images, while the second phase first implements segmentation of multiple lesions, followed by classification of the processed NPDR images. The accuracy on the DDR dataset is improved by 2.21% compared to the new study.
C1 [Chen, Yu; Xu, Shibao] Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin 150040, Peoples R China.
   [Long, Jun; Xie, Yining] Northeast Forestry Univ, Coll Mechean & Elect Engn, Harbin, Peoples R China.
C3 Harbin University of Science & Technology; Northeast Forestry University
   - China
RP Xie, YN (corresponding author), Northeast Forestry Univ, Coll Mechean & Elect Engn, Harbin, Peoples R China.
EM yiningxie@nefu.edu.cn
FU Fundamental Research Funds for the Central Universities [2572021BH01];
   National Natural Science Foundation of China [62172087]
FX AcknowledgmentsThis work was supported by the Fundamental Research Funds
   for the Central Universities (2572021BH01) and the National Natural
   Science Foundation of China (62172087).
CR Zapata MA, 2020, CLIN OPHTHALMOL, V14, P419, DOI 10.2147/OPTH.S235751
   Bodapati JD, 2021, J AMB INTEL HUM COMP, V12, P9825, DOI 10.1007/s12652-020-02727-z
   Cao Hu, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P205, DOI 10.1007/978-3-031-25066-8_9
   Chen J., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2102.04306, 10.48550/arXiv.2102.04306]
   Das S, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102600
   Developers S-L, 2021, USER GUIDE
   Ding XH, 2021, PROC CVPR IEEE, P13728, DOI 10.1109/CVPR46437.2021.01352
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Elwin JGR, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103712
   Foo A, 2020, AAAI CONF ARTIF INTE, V34, P13267
   Gangwar Akhilesh Kumar, 2021, Evolution in computational intelligence: frontiers in intelligent computing: theory and applications (FICTA 2020), P679, DOI DOI 10.1007/978-981-15-5788-064
   Garifullin A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104725
   Guo YS, 2022, ANN AM ASSOC GEOGR, V112, P1614, DOI 10.1080/24694452.2021.1989284
   Hemanth DJ, 2020, NEURAL COMPUT APPL, V32, P707, DOI 10.1007/s00521-018-03974-0
   Huang SQ, 2022, IEEE T MED IMAGING, V41, P1596, DOI 10.1109/TMI.2022.3143833
   Kalyani G, 2023, COMPLEX INTELL SYST, V9, P2651, DOI 10.1007/s40747-021-00318-9
   Karim AM, 2019, BIOCYBERN BIOMED ENG, V39, P148, DOI 10.1016/j.bbe.2018.11.004
   Kumar A., 2020, INT J SCI TECHNOL RE, V9, P1621
   Li T, 2019, INFORM SCIENCES, V501, P511, DOI 10.1016/j.ins.2019.06.011
   Math L, 2021, MULTIMED TOOLS APPL, V80, P5173, DOI 10.1007/s11042-020-09793-7
   Mo J, 2018, NEUROCOMPUTING, V290, P161, DOI 10.1016/j.neucom.2018.02.035
   Panwar A., 2022, EDGE ANALYTICS, P653, DOI 10.1007/978-981-19-0019-8_49
   Porwal P, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101561
   Porwal P, 2018, DATA, V3, DOI 10.3390/data3030025
   Qureshi I, 2021, MULTIMED TOOLS APPL, V80, P11691, DOI 10.1007/s11042-020-10238-4
   Rayavel P., 2022, J MED IMAG HEALTH IN, V12, P149, DOI [10.1166/jmihi.2022.3934, DOI 10.1166/JMIHI.2022.3934]
   Sambyal N, 2020, BIOCYBERN BIOMED ENG, V40, P1094, DOI 10.1016/j.bbe.2020.05.006
   Sivari E, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10030580
   Sungheetha Akey, 2021, J Trends Comp Sci Smart Technol, V3, P81, DOI [DOI 10.36548/JTCSST.2021.2.002, 10.36548/jtcsst.2021.2.002]
   Tan JH, 2017, INFORM SCIENCES, V420, P66, DOI 10.1016/j.ins.2017.08.050
   Thanh DNH, 2019, INT ARCH PHOTOGRAMM, V42-2, P211, DOI 10.5194/isprs-archives-XLII-2-W12-211-2019
   Thiagarajan AS., 2020, SCI REP-UK, V16, P305, DOI [10.3844/jcssp.2020.305.313, DOI 10.3844/JCSSP.2020.305.313]
   Tuyet VTH, 2022, ENG TECHNOL APPL SCI, V12, P8204
   Wang LY, 2021, I S BIOMED IMAGING, P1141, DOI 10.1109/ISBI48211.2021.9433917
   Xu YF, 2021, BIOMED RES INT, V2021, DOI 10.1155/2021/6644071
   YERUSHALMY J, 1947, PUBLIC HEALTH REP, V62, P1432, DOI 10.2307/4586294
   Zhou Y, 2021, IEEE T MED IMAGING, V40, P818, DOI 10.1109/TMI.2020.3037771
NR 37
TC 3
Z9 3
U1 15
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26919
EP 26935
DI 10.1007/s11042-023-14785-4
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000945313000011
DA 2024-07-18
ER

PT J
AU Ramesh, B
   Bhandari, BN
   Pothalaiah, S
AF Ramesh, B.
   Bhandari, B. N.
   Pothalaiah, S.
TI A hybrid technique to provide effective allocation based on mac with
   UWSN for energy efficiency and effective communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor network; EC- HGCS; UWSN; RSSI; GOA; CS
ID WIRELESS; PROTOCOL
AB In the Underwater Wireless Sensor Network (UWSN), the localization of sensor underwater plays a vital role. The underwater sensor gathers information from the earth and transmits the obtained data to the monitoring station. However, the UWSN is facing more serious issues than WSN like long propagation delay, shadow zones, narrow bandwidth, complex geographical environment, high bit error rates, etc. Therefore, the development of effective techniques in UWSN is highly demanded. The reason behind the proposed work is to develop an Energy Consumption-Hybrid Grass Hopper with Cuckoo Search (EC-HGCS) algorithm to mitigate the localization error based on analyzing the parameter of each sensor. The proposed algorithm is a combination of the Grasshopper Optimization Algorithm (GOA) and Cuckoo Search Algorithm (CS). Here, The GOA is improved with the help of the CS algorithm; therefore, highly effective communication can be achieved. The implementation is done in the NS2 platform with some simulation parameters and by comparing the performance metrics like overhead, Packet drops delivery ratio, delay, energy consumption, and throughput with the existing techniques. Eventually, for the proposed approach the throughput and delivery ratio are higher on the other hand energy consumption, overhead, packet drop and delay are lower than in the existing technique.
C1 [Ramesh, B.; Bhandari, B. N.] CVR Coll Engn, Dept Elect & Commun Engn, Hyderabad, India.
   [Pothalaiah, S.] Vignana Bharathi Inst Technol, Dept Elect & Commun Engn, Hyderabad, India.
RP Ramesh, B (corresponding author), CVR Coll Engn, Dept Elect & Commun Engn, Hyderabad, India.
EM rameshbommera@gmail.com
RI BOMMERABOINA, RAMESH/ACE-6324-2022; sake, pothalaiah/AAS-7590-2021
OI BOMMERABOINA, RAMESH/0000-0003-4116-2156; sake,
   pothalaiah/0000-0002-2545-993X
CR Abbasi M, 2020, IET INTELL TRANSP SY, V14, P1484, DOI 10.1049/iet-its.2019.0783
   Ahmed S, 2020, J SENSORS, V2020, DOI 10.1155/2020/8888957
   Alfouzan FA, 2019, IEEE ACCESS, V7, P39862, DOI 10.1109/ACCESS.2019.2906555
   Awan KM, 2019, WIREL COMMUN MOB COM, DOI 10.1155/2019/6470359
   el Alami H., 2017, Security Management in Mobile Cloud Computing, P1
   Feng P, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1533-y
   GUL H, 2021, J AMB INTEL HUM COMP, P1
   Hyder W., 2017, Journal of Basic and Application Sciences, V13, P63, DOI [10.6000/1927-5129.2017.13.12, DOI 10.6000/1927-5129.2017.13.12]
   Jouhari M, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.3971
   Karim S, 2021, IEEE ACCESS, V9, P36730, DOI 10.1109/ACCESS.2021.3063295
   Moon E, 2019, WIRELESS PERS COMMUN, V107, P1491, DOI 10.1007/s11277-018-5977-x
   Muzakkari B A., 2018, International Journal of Advanced Computer Research, V8, P212, DOI [10.19101/IJACR.2018.837016, DOI 10.19101/IJACR.2018.837016]
   Nain Mamta, 2021, 2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE), P747, DOI 10.1109/ICACITE51222.2021.9404652
   Nassiri M., 2020, INT WIREL COMMUN, V18, P145, DOI [10.37936/ecti-eec.2020182.222642, DOI 10.37936/ECTI-EEC.2020182.222642]
   Nguyen NT, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020627
   Novák M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11060734
   Poudel S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092635
   Qin Q, 2021, 3 DIMENSIONAL UWSN P
   Rahman P, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0819-3
   Roy A, 2021, DIGIT COMMUN NETW, V7, P385, DOI 10.1016/j.dcan.2020.09.002
   Sarang S, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8860371
   Su X, 2020, J SENSORS, V2020, DOI 10.1155/2020/6403161
   Sun N, 2021, COMPUT COMMUN, V173, P56, DOI 10.1016/j.comcom.2021.03.020
   Verma A, 2020, IEEE SENS J, V20, P5615, DOI 10.1109/JSEN.2020.2969697
   Wan ZP, 2019, CLUSTER COMPUT, V22, P14651, DOI 10.1007/s10586-018-2376-8
   Wang JJ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010183
   Zafar S, 2019, IEEE ACCESS, V7, P20394, DOI 10.1109/ACCESS.2019.2896938
   Zhang DG, 2018, MOBILE NETW APPL, V23, P828, DOI 10.1007/s11036-017-0878-x
   Zhang ZW, 2019, IEEE ACCESS, V7, P104542, DOI 10.1109/ACCESS.2019.2926158
NR 29
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 28977
EP 28996
DI 10.1007/s11042-023-14897-x
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000943966200003
DA 2024-07-18
ER

PT J
AU Kadirappa, R
   Deivalakshmi, S
   Pandeeswari, R
   Ko, SB
AF Kadirappa, Ravindranath
   Deivalakshmi, S.
   Pandeeswari, R.
   Ko, Seok-Bum
TI An automated multi-class skin lesion diagnosis by embedding local and
   global features of Dermoscopy images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin lesion analysis; Spatial attention blocks; Segmentation;
   Classification; Deep learning; Dermoscopy
ID SEGMENTATION
AB Skin cancer is an increasing cause of concern among cancers worldwide. There has been extensive research carried out all over the globe for the early detection of skin cancer to increase the life expectancy of patients. The decision support systems and Computer-aided diagnosis systems aid in detecting cancer at an early stage. The increasing ability of Convolutional Neural Networks (CNN) to extract delicate patterns has made it a popular choice in automated decision support systems. This work proposes a novel U-Net segmentation network with Spatial Attention Blocks (SPAB) called SASegNet to segment the skin lesion accurately. The spatial attention blocks emphasize the model to focus on a particular region. The proposed SASegNet model can provide an accuracy of 95% on the PH2 dataset. In this work, EfficientNet B1 is used for classification. The local features from segmentation results are then passed to EfficientNet B1 to extract features for classification. The pre-processed original images are passed to EfficientNet B1 to extract the global features. Finally, these two features are concatenated to extract the best patterns for classification. Experimentation is carried out on the International Skin Imaging Collaboration (ISIC) datasets. The proposed methodology can obtain the Area Under Curve Receiver Operating Characteristic Curve (AUC-ROC) as 0.974, 0.972, 0.962, and 0.937 for the ISIC-2017, 18, 19, and 2020 datasets. The results obtained are the benchmark results to the best of our knowledge. This automated methodology can aid practising dermatologists in a robust diagnosis.
C1 [Kadirappa, Ravindranath; Deivalakshmi, S.; Pandeeswari, R.] Natl Inst Technol Tiruchirappalli, Dept Elect & Commun Engn, Trichy, Tamil Nadu, India.
   [Ko, Seok-Bum] Univ Saskatchewan, Dept Elect & Comp Biomed Engn, Saskatoon, SK, Canada.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; University of Saskatchewan
RP Deivalakshmi, S (corresponding author), Natl Inst Technol Tiruchirappalli, Dept Elect & Commun Engn, Trichy, Tamil Nadu, India.
EM 408119010@nitt.edu; deiva@nitt.edu; rpands@nitt.edu; seokbum.ko@usask.ca
RI Kadirappa, Ravindranath/HPC-5488-2023; R, Pandeeswari/JCE-6689-2023
OI Kadirappa, Ravindranath/0000-0003-2562-2781; R,
   Pandeeswari/0000-0002-8147-4683; Deivalakshmi, S/0000-0002-7019-9807; ,
   Ravindranath K/0000-0001-6164-7180
FU Scheme for Promotion of Academic and Research Collaboration (SPARC),
   Ministry of Education (MoE) Government of India [SPARC-P641/2019]
FX This research work was partly funded by the Scheme for Promotion of
   Academic and Research Collaboration (SPARC), Ministry of Education (MoE)
   Government of India under grant id SPARC-P641/2019.
CR Almseidin Mohammed, 2019, International Journal of Interactive Mobile Technologies, V13, P171, DOI 10.3991/ijim.v13i12.11411
   [Anonymous], CANC FACTS FIGURES 2
   Ballerini L., 2013, Color medical image analysis, P63
   Bi L, 2019, PATTERN RECOGN, V85, P78, DOI 10.1016/j.patcog.2018.08.001
   Celebi ME, 2007, COMPUT MED IMAG GRAP, V31, P362, DOI 10.1016/j.compmedimag.2007.01.003
   Celebi ME, 2008, COMPUT MED IMAG GRAP, V32, P670, DOI 10.1016/j.compmedimag.2008.08.003
   Chaturvedi S.S., 2020, Advanced machine learning technologies and applications: proceedings of AMLTA 2020, P165, DOI [DOI 10.1007/978-981-15-3383-9_15, 10.1007/978-981-15-3383-9_15, DOI 10.1007/978-981-15-3383-915]
   Chaturvedi SS, 2020, MULTIMED TOOLS APPL, V79, P28477, DOI 10.1007/s11042-020-09388-2
   Chen B., 2021, arXiv
   Chen JP, 2021, NAT PHOTONICS, V15, P570, DOI 10.1038/s41566-021-00828-5
   Chen X, 2021, AUTOPHAGY, V17, P2054, DOI 10.1080/15548627.2020.1810918
   Codella NC, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1710.05006
   Combalia M., 2019, ARXIV, DOI DOI 10.48550/ARXIV.1908.02288
   Dabass M., 2021, Inf. Med. Unlocked, V27
   Gessert N, 2020, IEEE T BIO-MED ENG, V67, P495, DOI 10.1109/TBME.2019.2915839
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   Iqbal I, 2021, COMPUT MED IMAG GRAP, V88, DOI 10.1016/j.compmedimag.2020.101843
   Jain AK, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P2125
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jha D., 2020, arXiv
   Ji Y., 2021, ARXIV
   Jose JM, 2020, ARXIV
   Khan MA, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11050811
   Komodakis N, 2017, P INT C LEARN REPR, DOI [10.48550/arXiv.1612.03928, DOI 10.48550/ARXIV.1612.03928]
   Kostopoulos SA, 2017, INT J MED INFORM, V105, P1, DOI 10.1016/j.ijmedinf.2017.05.016
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lakhani P, 2018, J DIGIT IMAGING, V31, P283, DOI 10.1007/s10278-018-0079-6
   Li SD, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.297035
   Liu LN, 2020, COMPUT MED IMAG GRAP, V84, DOI 10.1016/j.compmedimag.2020.101765
   Liu XB, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3465220
   Maglogiannis I, 2009, IEEE T INF TECHNOL B, V13, P721, DOI 10.1109/TITB.2009.2017529
   Mahbod A, 2019, COMPUT MED IMAG GRAP, V71, P19, DOI 10.1016/j.compmedimag.2018.10.007
   Mishra A, 2021, IEEE ICCE, DOI 10.1109/ICCE50685.2021.9427772
   Mubashar M, 2022, NEURAL COMPUT APPL, V34, P17723, DOI 10.1007/s00521-022-07419-7
   Nida N, 2019, INT J MED INFORM, V124, P37, DOI 10.1016/j.ijmedinf.2019.01.005
   Nyíri T, 2018, LECT NOTES COMPUT SC, V11324, P438, DOI 10.1007/978-3-030-04070-3_34
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Punn NS, 2022, MACH VISION APPL, V33, DOI 10.1007/s00138-022-01280-3
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Rahman Z., 2021, Informatics in Medicine Unlocked, V25, DOI [10.1016/j.imu.2021.100659, DOI 10.1016/J.IMU.2021.100659]
   Ramella G., 2021, IMAGING VISUALIZATIO
   Ratul M.A.R., 2020, bioRxiv, DOI DOI 10.1101/860700
   Reboucas PP, 2018, COMPUT MED IMAG GRAP, V68, P40, DOI 10.1016/j.compmedimag.2018.05.004
   Rehman A, 2020, MICROSC RES TECHNIQ, V83, P410, DOI 10.1002/jemt.23429
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Shahin AH, 2018, CAIRO INT BIOM ENG, P150, DOI 10.1109/CIBEC.2018.8641815
   Song LP, 2022, APPL SOFT COMPUT, V122, DOI 10.1016/j.asoc.2022.108883
   Stergiou C., 2020, HDB COMPUTER NETWORK, P525, DOI [10.1007/978-3-030-22277-2_21, DOI 10.1007/978-3-030-22277-2_21]
   Tan M., 2020, INT C MACH LEARN, DOI DOI 10.48550/ARXIV.1905.11946
   Tomar NK, 2021, ARXIV
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie YT, 2020, IEEE T MED IMAGING, V39, P2482, DOI 10.1109/TMI.2020.2972964
   Yuan YD, 2019, IEEE J BIOMED HEALTH, V23, P519, DOI 10.1109/JBHI.2017.2787487
   Zhao P, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00670
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 56
TC 4
Z9 4
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34885
EP 34912
DI 10.1007/s11042-023-14892-2
EA MAR 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000943638900001
DA 2024-07-18
ER

PT J
AU Rafidison, MA
   Rakotomihamina, AH
   Rafanantenana, SHJ
   Toky, RFM
   Raoelina, MMN
   Ramafiarisona, HM
AF Rafidison, Maminiaina Alphonse
   Rakotomihamina, Andry Harivony
   Rafanantenana, Sabine Harisoa Jacques
   Toky, Rajaonarison Faniriharisoa Maxime
   Raoelina, Mirado Mike Noe
   Ramafiarisona, Hajasoa Malalatiana
TI Neural networks contribution in face mask detection to reduce the spread
   of COVID-19
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eyes detection; Face mask detection; Fully connected neural network;
   Orthogonal projection; Pulse couple neural network; Segmentation
AB In front of COVID-19 propagation, we can protect our self by taking precautionary measures such as wearing face masks. It may be mandatory in particular public place although some persons ignore this rule. Several research in face mask detection area have emerged and most of studies are based on deep learning. In this paper, we present a method to detect whether person wear a mask or not to prevent the propagation of virus. The approach is based on combination of Pulse Couple Neural Network and Fully Connected Neural Network and the processing is divided in three steps: geometrical, feature extraction and decision. The geometrical module selects the Region of Interest for given image and the feature extraction module composed by Pulse Couple Neural Network extracts all pertinent information which will be used by the last module for decision. This decision module makes directly a decision in case of non-complex classification without neural network training overwise the Fully Connected Neural Network continues the treatment. The input image may be captured from video surveillance sequence, the system triggers a signal alarm once a person doesn't wear face mask. Our proposed approach was tested with different datasets like Kaggle, AIZOO, Moxa3K, Real-World Masked Face Dataset, Medical Masks Dataset, Face Mask Dataset and the accuracy varies from 83.2% to 100% with minimum computation time.
C1 [Rafidison, Maminiaina Alphonse; Rakotomihamina, Andry Harivony; Rafanantenana, Sabine Harisoa Jacques; Toky, Rajaonarison Faniriharisoa Maxime; Raoelina, Mirado Mike Noe; Ramafiarisona, Hajasoa Malalatiana] Univ Antananarivo, Ecole Super Polytech Antananarivo, Doctoral Sch Sci & Technol Engn & Innovat, Telecommun Automat Signal Image Res Lab, Antananarivo 101, Madagascar.
C3 University Antananarivo
RP Rafidison, MA (corresponding author), Univ Antananarivo, Ecole Super Polytech Antananarivo, Doctoral Sch Sci & Technol Engn & Innovat, Telecommun Automat Signal Image Res Lab, Antananarivo 101, Madagascar.
EM mamynyaina@gmail.com; rakotomihaminaandry@gmail.com;
   rshjacques@gmail.com; tfaniriharisoa@gmail.com; raoelina89@gmail.com;
   mhramafiarisona@yahoo.fr
OI RAFIDISON, Maminiaina Alphonse/0000-0001-7734-4563; TOKY, Rajaonarison
   Faniriharisoa Maxime/0000-0001-7975-905X
CR Aldoski J, 2022, IMAGE CLASSIFICATION
   Asghar MZ, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.855254
   Asgher U, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00584
   Basu A., 2021, 2021 12 INT C COMPUT, P1
   Bhagyashree K, 2021, INT J ADV COMPUT SC, V11
   Bhawna R, 2021, FACE MASK DETECTION
   Chacon MMI., 2007, ADV NEURAL NETWORKS, DOI [10.1007/978-3-540-72395-0_109, DOI 10.1007/978-3-540-72395-0_109]
   Chavda A, 2021, 2021 6TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/I2CT51068.2021.9418207
   Chiang D., 2020, Detecting faces and determine whether people are wearing mask
   Deng HX, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167310
   Deng XY, 2014, CHINESE J ELECTRON, V23, P97
   Fan XQ, 2021, IEEE ACCESS, V9, P96964, DOI 10.1109/ACCESS.2021.3095191
   Ge S., 2017, IEEE C COMPUT VIS PA, P2682, DOI DOI 10.1109/CVPR.2017.53
   Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345
   Goyal H, 2022, MULTIMED TOOLS APPL, V81, P14999, DOI 10.1007/s11042-022-12166-x
   Hussain G. K. Jakir, 2021, Journal of Physics: Conference Series, V1916, DOI 10.1088/1742-6596/1916/1/012084
   JOHNSON JL, 1994, APPL OPTICS, V33, P6239, DOI 10.1364/AO.33.006239
   Johnson JL, 1999, IEEE T NEURAL NETWOR, V10, P480, DOI 10.1109/72.761706
   Kaur Gagandeep, 2022, Neurosci Inform, V2, P100035, DOI 10.1016/j.neuri.2021.100035
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Loey M, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108288
   Mahum R, 2021, GENERIC FRAMEWORK GE, P1, DOI [10.1109/MAJICC53071.2021.9526264, DOI 10.1109/MAJICC53071.2021.9526264]
   Militante SV, 2020, 2020 11TH IEEE CONTROL AND SYSTEM GRADUATE RESEARCH COLLOQUIUM (ICSGRC), P106, DOI [10.1109/icsgrc49013.2020.9232610, 10.1109/ICSGRC49013.2020.9232610]
   Rafidison MA., 2021, INT J INNOV ENG RES, V8, P62
   Rafidison MA., 2021, ARCH COMPUT METHOD E, V9, P1031
   Riya C, 2021, ARXIV
   Rosebrock A, 2020, COVID 19 FACE MASK D
   Roy Biparnak, 2020, Trans Indian Natl Acad Eng, V5, P509, DOI 10.1007/s41403-020-00157-z
   Son Changwon, 2020, J Med Internet Res, V22, pe21279, DOI 10.2196/21279
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
NR 30
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32559
EP 32581
DI 10.1007/s11042-023-14920-1
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943638900014
PM 37362662
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Kumar, KK
   Reddy, HV
AF Kumar, K. Kishore
   Reddy, H. Venkateswara
TI An optimized whale-based modular neural framework to predict crime
   events
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crime detection; Facial expression; Deep learning; Pre-processing;
   Surveillance system; Whale optimization
AB Nowadays, the surveillance system is an important asset for Crime detection. Hence, many methods were implemented to detect the crime in different ways, such as based on activities, handling tools, facial recognition, etc. In addition, to execute this method, several neural approaches were developed in a different environment; hence the noise content and video image complexity have made the crime detection task difficult. Therefore, to improve crime detection, the present work has aimed to design a novel Whale-based Modular Neural Framework (WbMNF) for attaining the best prediction results. In addition, the crime events were predicted by analyzing the face. Initially, the videos were collected and imported to the system. Hereafter, the training flaws were eliminated in the pre-processing layer. Moreover, the pre-processed data is entered into the classification layer of WbMNF to extract the face feature and to predict the criminals. Hence, the incorporation of whale fitness has provided the finest prediction outcome. Subsequently, the result of the developed technique is compared with state of the art schemes and has earned improved crime detection accuracy than the existing models.
C1 [Kumar, K. Kishore; Reddy, H. Venkateswara] Vardhaman Coll Engn, Dept Comp Sci & Engn, Hyderabad 501218, Telangana, India.
C3 Vardhaman College of Engineering
RP Kumar, KK (corresponding author), Vardhaman Coll Engn, Dept Comp Sci & Engn, Hyderabad 501218, Telangana, India.
EM kishorkadari@vardhaman.org; h.venkateswarareddy@vardhaman.org
CR Abed R, 2021, MULTIMED TOOLS APPL, V80, P23157, DOI 10.1007/s11042-020-09385-5
   Adero E, 2019, 2019 IST-AFRICA WEEK CONFERENCE (IST-AFRICA), DOI 10.23919/istafrica.2019.8764876
   Al-Obaydy WNI, 2020, MULTIMED TOOLS APPL, V79, P2897, DOI 10.1007/s11042-019-08414-2
   Ali W, 2021, MULTIMED TOOLS APPL, V80, P4825, DOI 10.1007/s11042-020-09850-1
   Bernasconi O., 2019, MAKING STATE VIOLENC, P117
   Ch Rupa, 2020, Sustainability, V12, DOI 10.3390/su12104087
   Dourado CMJM Jr, 2019, COMPUT NETW, V152, P25, DOI 10.1016/j.comnet.2019.01.019
   Enigo VSF, 2020, LECT NOTE DATA ENG, V46, P109, DOI 10.1007/978-3-030-38040-3_12
   Gonzalez-Lozoya SM, 2020, MULTIMED TOOLS APPL, V79, P13987, DOI 10.1007/s11042-020-08681-4
   Gottschalk P., 2021, The Case of Tjome Island, pXI, DOI DOI 10.1007/978-3-030-74184-6
   Hsu G.S.J., 2020, P IEEE CVF C COMP VI, P826
   HU Qidi, 2019, DESTECH T ENV ENERGY
   Hufnagel Saskia, 2019, PALGRAVE HDB ART CRI, P89
   Jain R, 2020, ADV INTELL SYST COMP, V1042, P503, DOI 10.1007/978-981-32-9949-8_35
   Kar NB, 2019, MULTIMED TOOLS APPL, V78, P4789, DOI 10.1007/s11042-017-5485-0
   Kumar Vikas, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12535), P756, DOI 10.1007/978-3-030-66415-2_53
   Kurshan E, 2020, INT J SEMANT COMPUT, V14, P565, DOI 10.1142/S1793351X20300022
   Mauricio FGM, 2019, MICROCHEM J, V150, DOI 10.1016/j.microc.2019.104037
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Nasir M, 2021, MULTIMED TOOLS APPL, V80, P31993, DOI 10.1007/s11042-021-11196-1
   Oloyede MO, 2020, MULTIMED TOOLS APPL, V79, P27891, DOI 10.1007/s11042-020-09261-2
   Oosterman N., 2019, PALGRAVE HDB ART CRI, P213
   Pavithra R., 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0797, DOI 10.1109/ICCSP.2019.8698014
   Peixoto SA, 2020, IMAGE VISION COMPUT, V96, DOI 10.1016/j.imavis.2020.103899
   Rahman RU, 2020, FORENS SCI INT-DIGIT, V33, DOI 10.1016/j.fsidi.2020.300943
   Rosenblum D, 2020, DRUG ALCOHOL DEPEN, V208, DOI 10.1016/j.drugalcdep.2019.107779
   Sangher KS., 2019, 2019 INT C AUTOMATIO
   Sreejith AG, 2020, LECT NOTE NETW SYST, V89, P699, DOI 10.1007/978-981-15-0146-3_65
   Sudha TS, 2019, 2019 INNOVATIONS IN POWER AND ADVANCED COMPUTING TECHNOLOGIES (I-PACT), DOI 10.1109/i-pact44901.2019.8960187
   Sung C-S, 2021, MULTIMED TOOLS APPL, P1
   Taha M, 2021, MULTIMED TOOLS APPL, V80, P26833, DOI 10.1007/s11042-021-10934-9
   Taha M, 2021, TELECOMMUN SYST, V77, P63, DOI 10.1007/s11235-020-00741-2
   Yan Y, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107370
   Zhu XY, 2022, IEEE T CIRC SYST VID, V32, P1273, DOI 10.1109/TCSVT.2021.3078436
   Zhu XY, 2022, IEEE T MULTIMEDIA, V24, P3074, DOI 10.1109/TMM.2021.3092571
   Zolfi Hamid, 2019, 2019 Third International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P180, DOI 10.1109/I-SMAC47947.2019.9032536
NR 36
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30855
EP 30873
DI 10.1007/s11042-023-14660-2
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000942756000003
DA 2024-07-18
ER

PT J
AU Tanwar, S
   Singh, J
AF Tanwar, Shashi
   Singh, Jaspreet
TI ResNext50 based convolution neural network-long short term memory model
   for plant disease classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AlexNet; Convolutional neural network; Long short term memory;
   ResNext50; VGG-16
AB Agricultural problems need to be dealt with advanced computing methods to increase food productivity. Automatic classification of plant disease using deep learning methods helps to analyze the food quality and productivity. The existing methods applied Convolutional Neural Network (CNN) based models such as VGG-19, VGG-16, AlexNet, and Resnet-50 for plant disease classification. The existing methods have limitations of vanishing gradient problem and overfitting problem in plant disease classification. The ResNext50-Long Short Term Memory (LSTM) is proposed to improve plant disease classification performance. The hybrid of ResNext50-LSTM model is proposed for effective feature extraction from input images and classification of plant diseases. The ResNext50 architectures helps to limit increases of features in input layer to eliminate bottleneck problem and store relevant features for long term in LSTM for classification. The ResNext 50 model increases the features from 4 to 128 for optimal path construction and existing techniques increases the features more than 128 that causes the overfitting problem. This process of feature limit helps to reduce the overfitting problem and vanishing gradient in LSTM model. The ResNext50 is applied to extract and select the relevant features from input images and LSTM model has advantage of store the relevant information on long term for classification. The ResNext50 model selects the features to differentiate the correlation between the relevant and irrelevant features in feature extraction. The ResNext50 extracted features were applied to the LSTM model to improve classification performance. The proposed Resnext50-LSTM model and existing CNN model performances are tested on plant village dataset to analysis the efficiency. The proposed ResNext50-LSTM model has validation accuracy of 95.44%, and existing ResNext50 model has 93.56% accuracy, and ResNet50 model 93.45% accuracy in plant disease classification.
C1 [Tanwar, Shashi; Singh, Jaspreet] GD Goenka Univ, Dept Comp Sci & Engn, Gurugram, India.
C3 GD Goenka University
RP Tanwar, S (corresponding author), GD Goenka Univ, Dept Comp Sci & Engn, Gurugram, India.
EM Shashitanwar26@gmail.com; jaspreet.singh@gdgu.org
CR Agarwal M, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100407
   Albattah W, 2022, COMPLEX INTELL SYST, V8, P507, DOI 10.1007/s40747-021-00536-1
   Barbedo JGA, 2018, COMPUT ELECTRON AGR, V153, P46, DOI 10.1016/j.compag.2018.08.013
   Chen JD, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100415
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Chimmula VKR, 2020, CHAOS SOLITON FRACT, V135, DOI 10.1016/j.chaos.2020.109864
   Chu Y, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8909458
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Hernández S, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106597
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   Kamal KC, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104948
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Khamparia A, 2020, CIRC SYST SIGNAL PR, V39, P818, DOI 10.1007/s00034-019-01041-0
   Khan K, 2022, COMPLEXITY, V2022, DOI 10.1155/2022/1168700
   Kundu N, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165386
   Liu J, 2020, PLANT METHODS, V16, DOI 10.1186/s13007-020-00624-2
   Maeda-Gutiérrez V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041245
   Nandhini S, 2021, MULTIMED TOOLS APPL, V80, P18583, DOI 10.1007/s11042-021-10599-4
   Saleem MH, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9111451
   Saleem MH, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9101319
   Saleem MH, 2019, PLANTS-BASEL, V8, DOI 10.3390/plants8110468
   Shabbir A, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/5843816
   Shah D, 2022, INFORM PROCESS AGR, V9, P212, DOI 10.1016/j.inpa.2021.06.001
   Shahid F, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110212
   Sharma Parul, 2020, Information Processing in Agriculture, V7, P566, DOI 10.1016/j.inpa.2019.11.001
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Sujatha R, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103615
   Tian K, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104962
   Tran TT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9081601
   Udutalapally V, 2021, IEEE SENS J, V21, P17525, DOI 10.1109/JSEN.2020.3032438
   Wang QM, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/9142753
   Zhang Y, 2020, IEEE ACCESS, V8, P56607, DOI 10.1109/ACCESS.2020.2982456
   Zhang Y, 2020, IEEE ACCESS, V8, P19033, DOI 10.1109/ACCESS.2020.2966827
NR 34
TC 2
Z9 2
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29527
EP 29545
DI 10.1007/s11042-023-14851-x
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000941926100007
DA 2024-07-18
ER

PT J
AU Liu, Y
   Nand, P
   Hossain, MA
   Nguyen, M
   Yan, WQ
AF Liu, Yu
   Nand, Parma
   Hossain, Md Akbar
   Nguyen, Minh
   Yan, Wei Qi
TI Sign language recognition from digital videos using feature pyramid
   network with detection transformer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign language recognition; ResNet152; Detection transformer; Feature
   pyramid network
AB Sign language recognition is one of the fundamental ways to assist deaf people to communicate with others. An accurate vision-based sign language recognition system using deep learning is a fundamental goal for many researchers. Deep convolutional neural networks have been extensively considered in the last few years, and a slew of architectures have been proposed. Recently, Vision Transformer and other Transformers have shown apparent advantages in object recognition compared to traditional computer vision models such as Faster R-CNN, YOLO, SSD, and other deep learning models. In this paper, we propose a Vision Transformer-based sign language recognition method called DETR (Detection Transformer), aiming to improve the current state-of-the-art sign language recognition accuracy. The DETR method proposed in this paper is able to recognize sign language from digital videos with a high accuracy using a new deep learning model ResNet152 + FPN (i.e., Feature Pyramid Network), which is based on Detection Transformer. Our experiments show that the method has excellent potential for improving sign language recognition accuracy. For instance, our newly proposed net ResNet152 + FPN is able to enhance the detection accuracy up to 1.70% on the test dataset of sign language compared to the standard Detection Transformer models. Besides, an overall accuracy 96.45% was attained by using the proposed method.
C1 [Liu, Yu; Nand, Parma; Hossain, Md Akbar; Nguyen, Minh; Yan, Wei Qi] Auckland Univ Technol, Auckland 1010, New Zealand.
C3 Auckland University of Technology
RP Yan, WQ (corresponding author), Auckland Univ Technol, Auckland 1010, New Zealand.
EM wyan@aut.ac.nz
RI Nguyen, Minh/KLD-0648-2024
FU CAUL and its Member Institutions
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Bastanfard A, 2010, LECT NOTES COMPUT SC, V6298, P705, DOI 10.1007/978-3-642-15696-0_65
   Bauer B, 2000, INT C PATT RECOG, P463, DOI 10.1109/ICPR.2000.906112
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Carion N, 2020, Arxiv, DOI [arXiv:2005.12872, DOI 10.48550/ARXIV.2005.12872]
   Camgoz NC, 2020, Arxiv, DOI arXiv:2003.13830
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Duarte A, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1650, DOI 10.1145/3343031.3352587
   Huang J, 2015, IEEE INT C MULTIMEDI
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   Ko SK, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132683
   Koller O, 2016, PROC CVPR IEEE, P3793, DOI 10.1109/CVPR.2016.412
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004
   Minoofam SAH, 2022, MULTIMED TOOLS APPL, V81, P6389, DOI 10.1007/s11042-021-11806-y
   Mishra A, 2018, IEEE WINT CONF APPL, P372, DOI 10.1109/WACV.2018.00047
   Molchanov P, 2016, PROC CVPR IEEE, P4207, DOI 10.1109/CVPR.2016.456
   Orbay A, 2020, Arxiv, DOI arXiv:2002.00479
   Ozdemir O, 2016, SIG PROC COMMUN APPL
   Qin J, 2017, PROC CVPR IEEE, P1042, DOI 10.1109/CVPR.2017.117
   Rastgoo R, 2021, Arxiv, DOI arXiv:2109.00796
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Starner T., 1997, MOTION BASED RECOGNI, P227, DOI 10.1007/978-94-015-8935-2_10
   Suzgun M, 2015, Journal of Naval Sciences and Engineering, V11, P75
   TAMURA S, 1988, PATTERN RECOGN, V21, P343, DOI 10.1016/0031-3203(88)90048-9
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762, 10.48550/arXiv.1706.03762]
   Wu J, 2016, IEEE COMPUT SOC CONF, P110, DOI 10.1109/CVPRW.2016.21
   Xiang N, 2021, ACM ICCCV, P57
   Xu X, 2016, LECT NOTES COMPUT SC, V9906, P343, DOI 10.1007/978-3-319-46475-6_22
   Yin K., 2020, COLING, P5975, DOI 10.18653/v1/2020.coling-main.525
   Yin KY, 2020, Arxiv, DOI arXiv:2004.00588
   Zhou DQ, 2021, Arxiv, DOI [arXiv:2103.11886, 10.48550/arXiv.2103.11886, DOI 10.48550/ARXIV.2103.11886]
   Zhu Y, 2018, PROC CVPR IEEE, P9436, DOI 10.1109/CVPR.2018.00983
NR 33
TC 5
Z9 5
U1 12
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21673
EP 21685
DI 10.1007/s11042-023-14646-0
EA FEB 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000940729500014
OA hybrid
DA 2024-07-18
ER

PT J
AU Theerthagiri, P
   Ruby, AU
AF Theerthagiri, Prasannavenkatesan
   Ruby, A. Usha
TI Seasonal learning based ARIMA algorithm for prediction of Brent oil
   Price trends
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ARIMA; Seasonal learning; Brent oil Price prediction; Prophet; XGBoost
ID CRUDE-OIL; MODEL
AB The global economy relies heavily on the worldwide crude oil market. This work presents a crude oil price prediction technique using a time-varying trend. It works by decomposing crude oil price trends over time to characterize changes using a variable time window and determine the price trend in terms of time series. Seasonal Auto Regressive Integrated Moving Average (SARIMA) methodology has been developed in order to predict crude oil price fluctuations over time. The proposed SARIMA model predicts the prices using the weighted average method and accuracy estimation methodology with the feedback error analysis method. Various SARIMA models are evaluated, and best fit relative quality orders have been selected based on the Akaike information criterion. The prediction results of the proposed SARIMA approach are analyzed with performance error metrics and Kurtosis values. Further, the results of the SARIMA model were compared with the existing algorithms. The proposed SARIMA produces higher prediction accuracy with a very much reduced mean absolute error of 30 to 59% compared to the existing approaches.
C1 [Theerthagiri, Prasannavenkatesan] GITAM Univ Bengaluru, GITAM Sch Technol, Dept Comp Sci & Engn, Bengaluru, India.
   [Ruby, A. Usha] VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal, India.
C3 Gandhi Institute of Technology & Management (GITAM); VIT Bhopal
   University
RP Theerthagiri, P (corresponding author), GITAM Univ Bengaluru, GITAM Sch Technol, Dept Comp Sci & Engn, Bengaluru, India.
EM vprasann@gitam.edu
RI Theerthagiri, Prasanna venkatesan/G-7019-2019
OI Theerthagiri, Prasanna venkatesan/0000-0003-3420-598X; , A USHA
   RUBY/0000-0003-4505-8727
CR Aamir M, 2018, MALAYS J FUNDAM APPL, V14, P471, DOI 10.11113/mjfas.v14n4.1013
   Aamir M, 2018, J TEKNOL, V80, P67
   Abdollahi H, 2020, ENERGY, V200, DOI 10.1016/j.energy.2020.117520
   Alvarez-Ramirez J, 2010, ENERG ECON, V32, P993, DOI 10.1016/j.eneco.2010.04.013
   Azevedo VG, 2016, INT J PROD RES, V54, P5219, DOI 10.1080/00207543.2016.1162340
   Bristone M, 2021, PETROLEUM-PRC, V7, P243, DOI 10.1016/j.petlm.2019.11.009
   Chai J, 2018, ENERG ECON, V71, P114, DOI 10.1016/j.eneco.2018.02.004
   Chen YH, 2017, PROCEDIA COMPUT SCI, V122, P300, DOI 10.1016/j.procs.2017.11.373
   Cheng FZ, 2019, ENERG ECON, V78, P656, DOI 10.1016/j.eneco.2017.12.035
   Dridi N, 2019, IEEE SIGNAL PROC LET, V26, P302, DOI 10.1109/LSP.2018.2886933
   Guleryuz D., 2020, European Journal of Science and Technology, V20, P1, DOI [10.31590/ejosat.759302, DOI 10.31590/EJOSAT.759302]
   Herrera GP, 2019, ENERGY, V179, P214, DOI 10.1016/j.energy.2019.04.077
   Lei TL, 2017, MOL PHARMACEUT, V14, P2407, DOI 10.1021/acs.molpharmaceut.7b00317
   Li P, 2018, ENERGIES, V11, DOI 10.3390/en11071687
   Li TY, 2020, IEEE ACCESS, V8, P26933, DOI 10.1109/ACCESS.2020.2971348
   Li XR, 2019, INT J FORECASTING, V35, P1548, DOI 10.1016/j.ijforecast.2018.07.006
   Luo C, 2019, INT J APPROX REASON, V108, P38, DOI 10.1016/j.ijar.2019.02.005
   Luo HP, 2016, GEOPHYS J INT, V204, P292, DOI 10.1093/gji/ggv453
   Mello CE, 2019, PATTERN RECOGN LETT, V125, P42, DOI 10.1016/j.patrec.2019.03.018
   Noureen S, 2019, MIDWEST SYMP CIRCUIT, P521, DOI [10.1109/MWSCAS.2019.8885349, 10.1109/mwscas.2019.8885349]
   Rahmayanti IA., 2020, ENERGIES, V13, P1403
   Safari A, 2018, ENERGY, V148, P49, DOI 10.1016/j.energy.2018.01.007
   Shen FR, 2015, NEUROCOMPUTING, V167, P243, DOI 10.1016/j.neucom.2015.04.071
   Sulasikin A., 2021, P INT C ICT SMART SO, P1, DOI 10.1109/ICISS53185.2021.9532507
   Tang L, 2015, INT J INF TECH DECIS, V14, P141, DOI 10.1142/S0219622015400015
   Theerthagiri P., 2021, EAI ENDORSED T PERVA, V7
   Theerthagiri P, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6625
   Theerthagiri P, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6248
   Theerthagiri P, 2020, WIREL NETW, V26, P4173, DOI 10.1007/s11276-020-02326-y
   Theerthagiri P, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.3951
   Torres-Barrán A, 2019, NEUROCOMPUTING, V326, P151, DOI 10.1016/j.neucom.2017.05.104
   Wang MG, 2018, APPL ENERG, V220, P480, DOI 10.1016/j.apenergy.2018.03.148
   Wu J, 2020, ENERGIES, V13, DOI 10.3390/en13071852
   Yahyaoui H, 2019, EXPERT SYST APPL, V130, P113, DOI 10.1016/j.eswa.2019.04.026
   Yang J, 2019, IEEE J BIOMED HEALTH, V23, P1251, DOI 10.1109/JBHI.2018.2840690
   Yuan CQ, 2016, ENERGY, V100, P384, DOI 10.1016/j.energy.2016.02.001
   Zhang DY, 2020, IEEE ACCESS, V8, P220990, DOI 10.1109/ACCESS.2020.3042848
   Zhang Q, 2011, WATER RESOUR MANAG, V25, P2683, DOI 10.1007/s11269-011-9833-y
   Zhao LT, 2021, EMERG MARK FINANC TR, V57, P1068, DOI 10.1080/1540496X.2019.1706045
   Zhao LT, 2018, APPL ENERG, V220, P154, DOI 10.1016/j.apenergy.2018.03.060
   Zou YC, 2020, PHYSICA A, V541, DOI 10.1016/j.physa.2019.123360
NR 41
TC 4
Z9 4
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24485
EP 24504
DI 10.1007/s11042-023-14819-x
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000940729500008
DA 2024-07-18
ER

PT J
AU Sreeja, SR
   Samanta, D
AF Sreeja, S. R.
   Samanta, Debasis
TI Dictionary reduction in sparse representation-based classification of
   motor imagery EEG signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain computer interface; Electroencephalogram signal analysis; Motor
   imagery brain signal; Sparsity-based classification; Dictionary
   reduction; Dictionary learning
ID SPATIAL-PATTERNS; CHANNEL SELECTION
AB Recently, sparse representation-based classification has turned into a successful technique for motor imagery electroencephalogram signal analysis. In this approach, the data is sparsely represented using a pre-defined or learned dictionary and classified based on the residual error. Recent works have proved that learned dictionary performs significantly better than the fixed dictionary. But in dictionary learning approach, when the number of training trials increases, the dictionary size increases and hence calculating sparse representation takes longer time and affects the performance accuracy. Thus, a compact dictionary should be considered to reduce the computation time without compromising the accuracy. However, building a compact dictionary is a non-trivial task, as it depends on the size of training data, the number of motor imageries and the discriminative power of features. In this work, two dictionary reduction strategies, namely redundancy identification and dictionary learning have been investigated to build a compact dictionary. Under the redundancy identification strategy, two methods based on distance measure and correlation analysis have been considered. For dictionary learning, discriminative K-SVD (D-KSVD) and label consistent K-SVD (LC-KSVD) have been explored. Extensive experiments show that the LC-KSVD dictionary learning approach produces a better compact dictionary, which takes lower computation time as well as improved accuracy. Further, the results of reduced dictionary with LC-KSVD is comparable to the existing works on sparsity-based motor imagery electroencephalogram signals classification.
C1 [Sreeja, S. R.] Indian Inst Informat Technol Sri City, Dept Comp Sci & Engn, Sricity 517646, Andhra Pradesh, India.
   [Samanta, Debasis] Indian Inst Technol Kharagpur, Dept Comp Sci & Engn, Kharagpur 721302, West Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Sreeja, SR (corresponding author), Indian Inst Informat Technol Sri City, Dept Comp Sci & Engn, Sricity 517646, Andhra Pradesh, India.
EM sreeja.sr@iiits.in; dsamanta@iitkgp.ac.in
RI SR, Sreeja/AAV-2512-2020
OI SR, Sreeja/0000-0002-9853-5964
CR Alomari Mohammad H, 2014, Computer and Information Science, V7, P17, DOI DOI 10.5539/CIS.V7N2P17
   Ameri R, 2016, NEUROCOMPUTING, V218, P382, DOI 10.1016/j.neucom.2016.08.082
   Arvaneh M, 2011, IEEE T BIO-MED ENG, V58, P1865, DOI 10.1109/TBME.2011.2131142
   Baali Hamza, 2015, IEEE J Transl Eng Health Med, V3, P2100108, DOI 10.1109/JTEHM.2015.2485261
   Banach K, 2021, BIO-ALGORITHMS MED-S, V17, P165, DOI 10.1515/bams-2021-0095
   Benesty J., 2009, NOISE REDUCTION SPEE, P1, DOI [10.1007/978-3-642-00296-0_5, DOI 10.1007/978-3-642-00296-05]
   Blankertz B, 2008, IEEE SIGNAL PROC MAG, V25, P41, DOI 10.1109/MSP.2008.4408441
   Blankertz B, 2006, IEEE T NEUR SYS REH, V14, P153, DOI 10.1109/TNSRE.2006.875642
   Cai TT, 2011, IEEE T INFORM THEORY, V57, P4680, DOI 10.1109/TIT.2011.2146090
   Chen ZJ, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.06.041
   Deng X, 2021, IEEE ACCESS, V9, P25118, DOI 10.1109/ACCESS.2021.3056088
   Ding Y, 2020, IEEE J-STARS, V13, P5609, DOI 10.1109/JSTARS.2020.3023483
   Gaur P, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3051996
   Golub GH, 1999, SIAM J MATRIX ANAL A, V21, P185, DOI 10.1137/S0895479897326432
   Grosse-Wentrup M, 2008, IEEE T BIO-MED ENG, V55, P1991, DOI 10.1109/TBME.2008.921154
   He LH, 2016, IEEE T SYST MAN CY-S, V46, P843, DOI 10.1109/TSMC.2015.2450680
   Hou YM, 2022, NEUROSCI RES, V176, P40, DOI 10.1016/j.neures.2021.09.002
   Huang DD, 2012, IEEE T NEUR SYS REH, V20, P379, DOI 10.1109/TNSRE.2012.2190299
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Jiao Y, 2018, IEEE J BIOMED HEALTH
   Jin J, 2020, IEEE T NEUR SYS REH, V28, P2153, DOI 10.1109/TNSRE.2020.3020975
   Kaszura S, 2021, ADV INTELL SYST COMP, V1362, P239, DOI 10.1007/978-3-030-72254-8_26
   Khare SK, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105722
   Koprinska I, 2015, KNOWL-BASED SYST, V82, P29, DOI 10.1016/j.knosys.2015.02.017
   Kumar Shiu, 2016, 2016 3rd Asia-Pacific World Congress on Computer Science and Engineering (APWC on CSE), P34, DOI 10.1109/APWC-on-CSE.2016.017
   Kumar S, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1964-6
   Lawhern V. J., 2018, Journal of neural engineering, V15, DOI DOI 10.1088/1741-2552/AACE8C
   Lin XY, 2020, IEEE ENG MED BIO, P502, DOI 10.1109/EMBC44109.2020.9176484
   Liu FQ, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5632
   Liu SG, 2020, IEEE ACCESS, V8, P8668, DOI 10.1109/ACCESS.2019.2960928
   Lu N, 2015, J NEUROSCI METH, V249, P41, DOI 10.1016/j.jneumeth.2015.03.031
   Mairal J., 2009, ADV NEURAL INFORM PR, P1033
   Malan N. S., 2021, IRBM
   McFarland DJ, 2008, J NEURAL ENG, V5, P101, DOI 10.1088/1741-2560/5/2/001
   Mei S, 2020, IEEE T MULTIMEDIA
   Miao MM, 2021, SIGNAL IMAGE VIDEO P, V15, P1797, DOI 10.1007/s11760-021-01924-3
   Miao YY, 2021, IEEE T NEUR SYS REH, V29, P699, DOI 10.1109/TNSRE.2021.3071140
   Mishuhina V, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107918
   Molina-Cantero AJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165481
   Moumgiakmas SS, 2022, COMPUTERS, V11, DOI 10.3390/computers11050061
   Ouzir N, 2018, IEEE T IMAGE PROCESS, V27, P64, DOI 10.1109/TIP.2017.2753406
   Palumbo A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21186285
   Qiu ZY, 2016, NEUROCOMPUTING, V207, P519, DOI 10.1016/j.neucom.2016.05.035
   Ramirez I., 2010, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2010.5539964, 10.1109/CVPR.2010.5539964]
   Devi KR, 2021, J MULTIMODAL USER IN, V15, P301, DOI 10.1007/s12193-020-00358-4
   Scherer R, 2004, IEEE T BIO-MED ENG, V51, P979, DOI 10.1109/TBME.2004.827062
   Shao ZF, 2019, IEEE J-STARS, V12, P2663, DOI 10.1109/JSTARS.2019.2925456
   Sharma P, 2017, IEEE-ACM T AUDIO SPE, V25, P2162, DOI 10.1109/TASLP.2017.2748240
   Shin Y, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/5/056002
   Sreeja SR, 2020, MULTIMED TOOLS APPL, V79, P13775, DOI 10.1007/s11042-019-08602-0
   Sreeja SR, 2019, NEUROCOMPUTING, V368, P133, DOI 10.1016/j.neucom.2019.08.037
   Sreeja SR, 2018, IEEE J BIOMED HEALTH, V22, P1362, DOI 10.1109/JBHI.2017.2771783
   Sreeja SR, 2017, LECT NOTES COMPUT SC, V10688, P47, DOI 10.1007/978-3-319-72038-8_5
   Sreeja SR, 2017, 2017 INTERNATIONAL CONFERENCE ON NEW TRENDS IN COMPUTING SCIENCES (ICTCS), P61, DOI 10.1109/ICTCS.2017.15
   Subasi A, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/1970769
   Tsuchimoto S, 2021, J NEUROSCI METH, V353, DOI 10.1016/j.jneumeth.2021.109089
   Wang QS, 2021, MEAS SCI TECHNOL, V32, DOI 10.1088/1361-6501/abc205
   Wang ZB, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103823
   Wolpaw J., 2012, BRAIN COMPUTER INTER, DOI [10.1093/acprof:oso/9780195388855.003.0001, DOI 10.1093/ACPROF:OSO/9780195388855.001.0001]
   Xu BG, 2019, IEEE ACCESS, V7, P6084, DOI 10.1109/ACCESS.2018.2889093
   Yang JC, 2010, PROC CVPR IEEE, P3517, DOI 10.1109/CVPR.2010.5539958
   Yuan H, 2014, IEEE T BIO-MED ENG, V61, P1425, DOI 10.1109/TBME.2014.2312397
   Zha ZY, 2020, IEEE T IMAGE PROCESS, V29, P7735, DOI 10.1109/TIP.2020.3005515
   Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]
   Zhang Y, 2019, IEEE T CYBERNETICS, V49, P3322, DOI 10.1109/TCYB.2018.2841847
   Zhang Y, 2015, J NEUROSCI METH, V255, P85, DOI 10.1016/j.jneumeth.2015.08.004
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zheng QQ, 2018, NEUROCOMPUTING, V275, P869, DOI 10.1016/j.neucom.2017.09.030
   Zhou N, 2012, PROC CVPR IEEE, P3490, DOI 10.1109/CVPR.2012.6248091
NR 69
TC 0
Z9 0
U1 6
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31157
EP 31180
DI 10.1007/s11042-023-14659-9
EA FEB 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000940065100006
DA 2024-07-18
ER

PT J
AU Yu, ZJ
   Wang, GD
   Zhang, XY
   Wang, ZY
AF Yu, Zhijun
   Wang, Guodong
   Zhang, Xinyue
   Wang, Ziying
TI Enhanced multi-scale feature progressive network for image Deblurring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Enhanced multi-scale feature extract; Cross-stage fusion; Cross-stage
   attention; Progressive architecture; Image Deblurring
ID SPARSE REPRESENTATION; REMOVAL
AB This paper tackles the problem of single image motion blur removal. Recently methods have achieved state-of-the-art results owe to multi-scale, scale-recurrent and coarse-to-fine architecture, however, the problem of image feature information extraction and information transfer between different stages has not been well solved. In this paper, first, an efficient Enhanced Multi-scale Feature Progressive Network (EMFPNet) was proposed, in order to solve the above problem, a multi-scale feature extraction module is applied in each stage to enrich the spatial features of the maps. Second, introducing a Cross-stage Feature Fusion module to solve the problem of information transmission in different stages. Third, a cross-stage attention mechanism is used to monitor and help the transmission of information. Compared to SOTA method, our method achieve 0.6% and 0.2% improvement in PSNR respectively on GoPro and HIDE datasets.
C1 [Yu, Zhijun; Wang, Guodong; Zhang, Xinyue; Wang, Ziying] Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Peoples R China.
C3 Qingdao University
RP Wang, GD (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Peoples R China.
EM doctorwgd@gmail.com
FU Natural Science Foundation of Shandong Province [ZR2019MF050]; Shandong
   Province [2020KJN011]
FX This work was supported by the Natural Science Foundation of Shandong
   Province (No.ZR2019MF050) and the Shandong Province colleges and
   universities youth innovation technology plan innovation team project
   under Grant (No. 2020KJN011).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Anwar S, 2019, IEEE I CONF COMP VIS, P3155, DOI 10.1109/ICCV.2019.00325
   Brooks T, 2019, PROC CVPR IEEE, P11028, DOI 10.1109/CVPR.2019.01129
   Chakrabarti A, 2016, LECT NOTES COMPUT SC, V9907, P221, DOI 10.1007/978-3-319-46487-9_14
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong JX, 2021, IEEE T IMAGE PROCESS, V30, P1799, DOI 10.1109/TIP.2020.3048679
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Hu Z, 2014, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR.2014.432
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jiang Z, 2020, PROC CVPR IEEE, P3317, DOI 10.1109/CVPR42600.2020.00338
   Koh J, 2021, COMPUT VIS IMAGE UND, V203, DOI 10.1016/j.cviu.2020.103134
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kupyn O, 2019, IEEE I CONF COMP VIS, P8877, DOI 10.1109/ICCV.2019.00897
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Lin CY, 2020, IEEE T IMAGE PROCESS, V29, P9250, DOI 10.1109/TIP.2020.3025402
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2386, DOI 10.1109/TPAMI.2020.3041332
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Qian R, 2018, PROC CVPR IEEE, P2482, DOI 10.1109/CVPR.2018.00263
   Ren DW, 2019, PROC CVPR IEEE, P3932, DOI 10.1109/CVPR.2019.00406
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rozumnyi D, 2021, PROC CVPR IEEE, P3455, DOI 10.1109/CVPR46437.2021.00346
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song HH, 2021, IEEE T IMAGE PROCESS, V30, P2923, DOI 10.1109/TIP.2021.3056868
   Suin M, 2020, PROC CVPR IEEE, P3603, DOI 10.1109/CVPR42600.2020.00366
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Wang P, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108082
   Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7
   Xiankai Lu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P661, DOI 10.1007/978-3-030-58580-8_39
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu Li, 2014, P ANN C NEUR INF PRO, P1790
   Yeh CH, 2020, IEEE T IMAGE PROCESS, V29, P3153, DOI 10.1109/TIP.2019.2957929
   Yuan Y, 2020, PROC CVPR IEEE, P3552, DOI 10.1109/CVPR42600.2020.00361
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zamir SW, 2020, PROC CVPR IEEE, P2693, DOI 10.1109/CVPR42600.2020.00277
   Zhang HG, 2019, PROC CVPR IEEE, P5971, DOI 10.1109/CVPR.2019.00613
   Zhang TL, 2021, IET IMAGE PROCESS, V15, P1583, DOI 10.1049/ipr2.12127
   Zhang YL, 2019, Arxiv, DOI arXiv:1903.10082
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 54
TC 0
Z9 0
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21147
EP 21159
DI 10.1007/s11042-023-14629-1
EA FEB 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000936302600003
DA 2024-07-18
ER

PT J
AU Zribi, CB
AF Zribi, Chiraz Ben Othmane
TI "Easy" meta-embedding for detecting and correcting semantic errors in
   Arabic documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Detection-correction; Real-word error; Semantic inconsistency;
   Meta-embedding; Collocation; SkipGram; FastText; BERT
ID TEXTS
AB Word-Embedding models have enabled massive advances in natural language understanding tasks and achieved state-of-the-art performances in multiple natural language processing tasks. In this paper, we present an original method based on an "easy" meta-embedding to automatically detect and correct Arabic real-words errors that are semantically inconsistent with the context of the sentence. Due to the lexical proximity of words in Arabic, the risk of having this type of errors in documents is relatively high compared to other languages. Our method uses three word embedding techniques and their combination, namely SkipGram, FastText and BERT for both detection and correction. It checks the semantic affinity of words with the immediate context in a collocation and the near context of the sentence. Experiments have shown that the proposed meta-embedding improves the overall performance of our system.
C1 [Zribi, Chiraz Ben Othmane] Manouba Univ, ENSI, La Manouba 2010, Tunisia.
C3 Universite de la Manouba
RP Zribi, CB (corresponding author), Manouba Univ, ENSI, La Manouba 2010, Tunisia.
EM chiraz.zribi@ensi-uma.tn
OI Ben Othmane, Chiraz/0000-0002-1846-6015
CR Al-Jefri MM, 2013, 2013 TAIBAH UNIVERSITY INTERNATIONAL CONFERENCE ON ADVANCES IN INFORMATION TECHNOLOGY FOR THE HOLY QURAN AND ITS SCIENCES, P258, DOI 10.1109/NOORIC.2013.59
   Alwehaibi A, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1471, DOI 10.1109/ICMLA.2018.00239
   Azmi AM, 2019, IEEE-ACM T AUDIO SPE, V27, P1308, DOI 10.1109/TASLP.2019.2918404
   Ben Othmane CZ, 2017, NAT LANG ENG, V23, P419, DOI 10.1017/S1351324915000480
   Bojanowski P., 2016, ARXIV
   Bravo-Candel D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21092893
   Coates J. N., 2018, P 2018 C N AM CHAPTE, V2, P194, DOI DOI 10.18653/V1/N18-2031
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Firth J. R, 1957, Studies in linguistic analysis, P1
   Golding A., 1996, P 34 ANN M ASS COMPU, P71
   Golding A.R., 1995, P 3 WORKSH VER LARG, P39
   Golding AR, 1999, MACH LEARN, V34, P107, DOI 10.1023/A:1007545901558
   Gutiererz F, 2014, LECT NOTES COMPUT SC, V8841, P562, DOI 10.1007/978-3-662-45563-0_34
   Hirst G., 2005, Natural Language Engineering, V11, P87, DOI 10.1017/S135I324904003560
   Islam A., 2009, P 18 C INFORM KNOWLE, P1689, DOI DOI 10.1145/1645953.1646205
   Kim M, 2015, PROC IEEE INT C COMP, P654
   Lee JH., 2018, PHYS REV D, V2018, P607
   Lee JH, 2020, IEEE ACCESS, V8, P152565, DOI 10.1109/ACCESS.2020.3014779
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Rokaya M., 2015, International Information Institute (Tokyo). Information, V18, P4749
   Samanta P, 2013, P 25 C COMP LING SPE
   Sharma S, 2015, PROCEDIA COMPUT SCI, V70, P99, DOI 10.1016/j.procs.2015.10.047
   Soliman A, 2017, PROCEDIA COMPUT SCI, V117, P256, DOI 10.1016/j.procs.2017.10.117
   Toshevska M., 2020, 6 INT C NATURAL LANG, DOI 10.5121/csit.2020.100402
   Turney PD, 2008, P 22 INT C COMP LING, P905, DOI DOI 10.3115/1599081.1599195
   Yin WP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1351
   Zribi Ben Othmane C., 2018, ACTES CORIA TALN RJC, V1, P293
   Zribi CB, 2020, KNOWL INF SYST, V62, P2439, DOI 10.1007/s10115-019-01428-0
   Zribi CB, 2013, ARTIF INTELL, V195, P249, DOI 10.1016/j.artint.2012.07.002
NR 29
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21161
EP 21175
DI 10.1007/s11042-023-14553-4
EA FEB 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000936302600006
DA 2024-07-18
ER

PT J
AU Sharma, P
   Arya, R
   Verma, R
   Verma, B
AF Sharma, Pulkit
   Arya, Rhythm
   Verma, Richa
   Verma, Bindu
TI Conv-CapsNet: capsule based network for COVID-19 detection through X-Ray
   scans
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19 detection; Capsule networks; Medical imaging; Chest X-ray
   classification
ID DIAGNOSIS
AB Coronavirus, a virus that spread worldwide rapidly and was eventually declared a pandemic. The rapid spread made it essential to detect Coronavirus infected people to control the further spread. Recent studies show that radiological images such as X-Rays and CT scans provide essential information in detecting infection using deep learning models. This paper proposes a shallow architecture based on Capsule Networks with convolutional layers to detect COVID-19 infected persons. The proposed method combines the ability of the capsule network to understand spatial information with convolutional layers for efficient feature extraction. Due to the model's shallow architecture, it has 23M parameters to train and requires fewer training samples. The proposed system is fast and robust and correctly classifies the X-Ray images into three classes, i.e. COVID-19, No Findings, and Viral Pneumonia. Experimental results on the X-Ray dataset show that our model performs well despite having fewer samples for the training and achieved an average accuracy of 96.47% for multi-class and 97.69% for binary classification on 5-fold cross-validation. The proposed model would be useful to researchers and medical professionals for assistance and prognosis for COVID-19 infected patients.
C1 [Sharma, Pulkit; Arya, Rhythm; Verma, Richa; Verma, Bindu] Delhi Technol Univ, Delhi, India.
C3 Delhi Technological University
RP Verma, B (corresponding author), Delhi Technol Univ, Delhi, India.
EM bindu.cvision@gmail.com
RI Verma, Richa/KIK-4518-2024
CR About worldometer, 2020, COVID 19 DAT WORLD
   Afshar P, 2020, PATTERN RECOGN LETT, V138, P638, DOI 10.1016/j.patrec.2020.09.010
   Afshar P, 2018, IEEE IMAGE PROC, P3129, DOI 10.1109/ICIP.2018.8451379
   Alqudah A. M., 2020, Automated systems for detection of Covid-19 using chest X-ray images and lightweight convolutional neural networks, V4, DOI 10.1007/s13246-020-00865-4
   [Anonymous], 2020, CASE STUDY, DOI [10.53347/rID-75264, DOI 10.53347/RID-75264]
   [Anonymous], 2018, ARXIV
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Asraf Amanullah, 2020, SN Comput Sci, V1, P363, DOI 10.1007/s42979-020-00383-w
   Avola D, 2022, COMPUT METH PROG BIO, V221, DOI 10.1016/j.cmpb.2022.106833
   Bassi Pedro R. A. S., 2022, Research on Biomedical Engineering, V38, P139, DOI 10.1007/s42600-021-00132-9
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Chakraborty Soarov, 2022, SN Comput Sci, V3, P17, DOI 10.1007/s42979-021-00881-5
   Chandra TB, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113909
   Chowdhury MEH, 2020, IEEE ACCESS, V8, P132665, DOI 10.1109/ACCESS.2020.3010287
   Cozzi D, 2020, RADIOL MED, V125, P730, DOI 10.1007/s11547-020-01232-9
   Dalvi J, 2021, ARXIV
   Dimeglio N, 2021, INT C MODEL DATA ENG, P166
   Gupta I., 2018, 2018 11 INT C CONT C, P1, DOI [DOI 10.1109/IC3.2018.8530651, 10.1109/ic3.2018.8530651, DOI 10.1109/RAIT.2018.8389069]
   Hussain E, 2021, CHAOS SOLITON FRACT, V142, DOI 10.1016/j.chaos.2020.110495
   Intisar Rizwan I. Haque, 2020, Informatics in Medicine Unlocked, V18, DOI 10.1016/j.imu.2020.100297
   Islam M., 2020, DIAGNOSIS COVID 19 X
   Islam MM, 2021, IEEE ACCESS, V9, P30551, DOI 10.1109/ACCESS.2021.3058537
   Islam Md Milon, 2020, SN Comput Sci, V1, P274, DOI 10.1007/s42979-020-00300-1
   Islam Md Milon, 2020, SN Comput Sci, V1, P320, DOI 10.1007/s42979-020-00335-4
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Ismael AM, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114054
   Karthik R, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106744
   Kim HW, 2020, EMERG RADIOL, V27, P617, DOI 10.1007/s10140-020-01808-y
   LaLonde R., 2018, arXiv, parXiv:1804.04241
   Law BK, 2021, IEEE INT C SIGNAL IM, P1, DOI DOI 10.1109/ICSIPA52582.2021.9576804
   Mousavi Z, 2022, SLAS TECHNOL, V27, P63, DOI 10.1016/j.slast.2021.10.011
   Muhammad L J, 2020, SN Comput Sci, V1, P206, DOI 10.1007/s42979-020-00216-w
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Ouchicha C, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110245
   Patrick MK, 2022, J KING SAUD UNIV-COM, V34, P1295, DOI 10.1016/j.jksuci.2019.09.014
   Rahimzadeh M, 2020, NEW MODIFIED DEEP CO, P2004
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Rahman Mohammad Marufur, 2021, SN Comput Sci, V2, P384, DOI 10.1007/s42979-021-00774-7
   Rahman MM, 2020, 2020 IEEE INTERNATIONAL IOT, ELECTRONICS AND MECHATRONICS CONFERENCE (IEMTRONICS 2020), P271
   Rahman T, 2020, ARXIV
   Rajasegaran J, 2019, PROC CVPR IEEE, P10717, DOI 10.1109/CVPR.2019.01098
   Sabour S, 2017, ARXIV
   Saha Prottoy, 2021, Inform Med Unlocked, V22, P100505, DOI 10.1016/j.imu.2020.100505
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Sharma A, 2022, BIOMED SIGNAL PROCES, V77, DOI 10.1016/j.bspc.2022.103778
   Sheykhivand S, 2021, ALEX ENG J, V60, P2885, DOI 10.1016/j.aej.2021.01.011
   Toraman S, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110122
   Ucar F, 2020, MED HYPOTHESES, V140, DOI 10.1016/j.mehy.2020.109761
   Uddin A., 2021, MATH PROBL ENG, V2021
   Ullah Shah Muhammad Azmat, 2021, SN Comput Sci, V2, P18, DOI 10.1007/s42979-020-00401-x
   Verma B, 2018, 2018 IEEE INT C VEHI, P1
   Verma B, 2018, IEEE INT C INTELL TR, P1421, DOI 10.1109/ITSC.2018.8569461
   Vesperini F, 2019, IEEE J-STSP, V13, P310, DOI 10.1109/JSTSP.2019.2902305
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Xi E., 2017, arXiv
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Zhao W., 2018, ARXIV
   Zoabi Y, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-020-00372-6
NR 61
TC 6
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28521
EP 28545
DI 10.1007/s11042-023-14353-w
EA FEB 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000936195100001
PM 36846527
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kang, HY
   Leng, L
   Chang, CC
AF Kang, Haoyang
   Leng, Lu
   Chang, Chin-Chen
TI Overlapped (7,4) hamming code for large-capacity and low-loss data
   hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Overlapped hamming code; Data hiding; Construction mode; Joint
   optimization
AB A novel data hiding method based on overlapped (7,4) Hamming code is proposed in this paper. 11-bit codewords are constructed from two overlapped (7,4) Hamming codes, and then a look-up table of 11-bit codeword is established, from which the suitable 11-bit codeword can be selected to minimize the stego image distortion. Because Hamming codes, rather than the bits of the pixels, are overlapped, the embedding capacity is improved remarkably. Two transferring stages are jointly optimized to minimize the stego image distortion and improve the visual quality. Several construction modes are designed and available to balance the embedding capacity and visual quality, so the modes can be selected flexibly. The systematical theoretical analysis consistent with the experimental results solidly confirms the advantages of the proposed method.
C1 [Kang, Haoyang; Leng, Lu] Nanchang Hangkong Univ, Key Lab Jiangxi Prov Image Proc & Pattern Recognit, Nanchang 330063, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
C3 Nanchang Hangkong University; Feng Chia University
RP Leng, L (corresponding author), Nanchang Hangkong Univ, Key Lab Jiangxi Prov Image Proc & Pattern Recognit, Nanchang 330063, Peoples R China.
EM leng@nchu.edu.cn
RI Chang, Ching-Chun/JAN-6210-2023
FU National Natural Science Foundation of China [61866028, 61866025,
   61763033, 62162045]; Technology Innovation Guidance Program Project
   (Special Project of Technology Cooperation, Science and Technology
   Department of Jiangxi Province) [20212BDH81003]; Open Foundation of Key
   Laboratory of Jiangxi Province for Image Processing and Pattern
   Recognition [ET201680245]
FX This research was funded by the National Natural Science Foundation of
   China (61866028, 61866025, 61763033, 62162045), Technology Innovation
   Guidance Program Project (Special Project of Technology Cooperation,
   Science and Technology Department of Jiangxi Province) (20212BDH81003),
   and Open Foundation of Key Laboratory of Jiangxi Province for Image
   Processing and Pattern Recognition (ET201680245).
CR Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang C.-C., 2021, SECUR COMMUN NETW, P1
   Chang CC, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5538720
   Chang CC, 2020, IEEE ACCESS, V8, P198425, DOI 10.1109/ACCESS.2020.3034936
   Chang CC, 2019, MATH BIOSCI ENG, V16, P3367, DOI 10.3934/mbe.2019168
   Chang CC, 2019, IEEE ACCESS, V7, P54117, DOI 10.1109/ACCESS.2019.2908924
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Di FQ, 2019, MULTIMED TOOLS APPL, V78, P7125, DOI 10.1007/s11042-018-6469-4
   Hong W, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P13, DOI 10.1109/CISP.2008.638
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hwang J, 2006, LECT NOTES COMPUT SC, V4283, P348
   Jana B, 2017, MULTIMED TOOLS APPL, V76, P21691, DOI 10.1007/s11042-016-3990-1
   Junlan Bai, 2016, International Journal of Network Security, V18, P1122
   Kim C, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155336
   Kim C, 2019, MULTIMED TOOLS APPL, V78, P17995, DOI 10.1007/s11042-018-7101-3
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, DIGIT SIGNAL PROCESS, V78, P284, DOI 10.1016/j.dsp.2018.03.016
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kim C, 2016, MULTIMED TOOLS APPL, V75, P15651, DOI 10.1007/s11042-014-2355-x
   Kim C, 2014, MULTIMED TOOLS APPL, V69, P569, DOI 10.1007/s11042-012-1114-0
   Kim HJ, 2010, COMPUT MATH APPL, V60, P319, DOI 10.1016/j.camwa.2010.01.006
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Kumar R, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P903, DOI [10.1109/SPIN.2019.8711635, 10.1109/spin.2019.8711635]
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Lin J, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101236
   Liu SQ, 2019, PHYSICA A, V521, P667, DOI 10.1016/j.physa.2019.01.036
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Su WG, 2019, MULTIMED TOOLS APPL, V78, P7927, DOI 10.1007/s11042-018-6410-x
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Wu HR, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107264
   Wu XT, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107657
   Xiao MY, 2019, SIGNAL PROCESS, V158, P210, DOI 10.1016/j.sigpro.2019.01.008
   Xu QZ, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123205
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Yang CN, 2019, MULTIMED TOOLS APPL, V78, P18595, DOI 10.1007/s11042-019-7220-5
   Yu Z, 2019, IEEE ACCESS, V7, P148439, DOI 10.1109/ACCESS.2019.2943505
   Zhang WM, 2007, IEEE COMMUN LETT, V11, P680, DOI 10.1109/LCOMM.2007.070438
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 45
TC 5
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30345
EP 30374
DI 10.1007/s11042-023-14502-1
EA FEB 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000934850300008
DA 2024-07-18
ER

PT J
AU Ji, ZT
   Wu, P
   Ling, C
   Zhu, P
AF Ji, Zhongtian
   Wu, Peng
   Ling, Chen
   Zhu, Peng
TI Exploring the impact of investor's sentiment tendency in varying input
   window length for stock price prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Sentiment analysis; Fine-tuned BERT; Stock price
   prediction; Attention-based LSTM
ID TIME-SERIES PREDICTION; TECHNICAL ANALYSIS; MARKET PREDICTION; SOCIAL
   MEDIA; TREND; INDEX; FRAMEWORK; MOVEMENT; CLASSIFICATION; VOLATILITY
AB Stock price prediction is one of the most important aspects of business investment plans, and has been an attractive research topic for both researchers and financial analysts. Many previous studies indicated the effectiveness of social media sentiment in stock price predictions through time series modelling. However, the time series information hidden in consecutive trading days has not been fully explored. In this paper, we build a stock price prediction model based on attention-based Long Short Term Memory (ALSTM) network using price data, technical indicators and sentiment information from social media. We employed a novel method to feed the deep network with long time series data to learn the deep sequential information of stock price movement. A fine-tuned BERT sentiment classification model and a sentiment lexicon are proposed to extract deep sentiment tendency of social media posts. We conducted experiments on 28 stocks within three years' transaction period, and the results show that: (1) evaluated by the indicators of the Mean Absolute Error (MAE), the Root Mean Square Error (RMSE) and the accuracy, our proposed method outperforms the baseline models in both validation and test data sets; (2) models incorporating stock prices, technical indicators and sentiment features perform better than models that only use partial data source; (3) the fine-tuned BERT model performs better in sentiment classification task, and the exploitation of the sentiment features computed with the use of BERT model also led to higher predicting accuracy compared with the features calculated using sentiment lexicon; and (4) setting the input window length to 5-day achieves the best performance in average prediction accuracy.
C1 [Ji, Zhongtian; Ling, Chen; Zhu, Peng] Nanjing Univ Sci &Technol, Sch Econ & Management, 200 Xiaolinwei Rd, Nanjing 210094, Jiangsu, Peoples R China.
   [Wu, Peng] Nanjing Univ Sci &Technol, Sch Intelligent Mfg, 200 Xiaolinwei Rd, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Science & Technology
RP Wu, P (corresponding author), Nanjing Univ Sci &Technol, Sch Intelligent Mfg, 200 Xiaolinwei Rd, Nanjing 210094, Jiangsu, Peoples R China.
EM jizhongtian@njust.edu.cn; wupeng@njust.edu.cn; lingchen@njust.edu.cn;
   pzhu@njust.edu.cn
RI Zhu, Peng/CAA-9954-2022
OI Zhu, Peng/0000-0003-3687-9187; wu, peng/0000-0001-7455-926X
FU National Natural Science Foundation of China [72274096, 72174087,
   71774084, 71874082]; National Social Science Fund of China [17ZDA291];
   program for Jiangsu Excellent Scientific and Technological Innovation
   Team [[2020]10]
FX This paper was supported by the National Natural Science Foundation of
   China (project numbers are 72274096, 72174087, 71774084 and 71874082),
   the National Social Science Fund of China (project number is 17ZDA291),
   program for Jiangsu Excellent Scientific and Technological Innovation
   Team (project number is [2020]10).
CR Anjaria M, 2014, SOC NETW ANAL MIN, V4, DOI 10.1007/s13278-014-0181-9
   [Anonymous], 2001, ADAPT LEARN SYST SIG, DOI 10.1002/047084535X
   [Anonymous], 1995, SPRINGERBRIEF MATH
   Antweiler W, 2004, J FINANC, V59, P1259, DOI 10.1111/j.1540-6261.2004.00662.x
   Baek Y, 2018, EXPERT SYST APPL, V113, P457, DOI 10.1016/j.eswa.2018.07.019
   Baker M, 2006, J FINANC, V61, P1645, DOI 10.1111/j.1540-6261.2006.00885.x
   Ballings M, 2015, EXPERT SYST APPL, V42, P7046, DOI 10.1016/j.eswa.2015.05.013
   Bollen J., 2011, Computer, V44, P91, DOI 10.1109/MC.2011.323
   Cambria E, 2015, AAAI CONF ARTIF INTE, P508
   Cavalcante RC, 2016, EXPERT SYST APPL, V55, P194, DOI 10.1016/j.eswa.2016.02.006
   Chandra R, 2016, APPL SOFT COMPUT, V49, P462, DOI 10.1016/j.asoc.2016.08.029
   Checkley MS, 2017, EXPERT SYST APPL, V77, P256, DOI 10.1016/j.eswa.2017.01.029
   Chen MY, 2019, COMPUT HUM BEHAV, V101, P402, DOI 10.1016/j.chb.2019.03.021
   Chen WL, 2018, DATA KNOWL ENG, V118, P14, DOI 10.1016/j.datak.2018.08.003
   Chollet F., KERAS
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   de Fortuny EJ, 2014, INFORM PROCESS MANAG, V50, P426, DOI 10.1016/j.ipm.2013.12.002
   de Oliveira FA, 2011, IEEE SYS MAN CYBERN, P2151, DOI 10.1109/ICSMC.2011.6083990
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Eapen J, 2019, 2019 IEEE 9TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P264, DOI [10.1109/ccwc.2019.8666592, 10.1109/CCWC.2019.8666592]
   FAMA EF, 1991, J FINANC, V46, P1575, DOI 10.2307/2328565
   Faraji-Rad A, 2016, J CONSUM RES, V44, DOI [10.2139/ssrn.2715333, DOI 10.2139/SSRN.2715333]
   Fischer T, 2018, EUR J OPER RES, V270, P654, DOI 10.1016/j.ejor.2017.11.054
   Gerlein EA, 2016, EXPERT SYST APPL, V54, P193, DOI 10.1016/j.eswa.2016.01.018
   Giles CL, 2001, MACH LEARN, V44, P161, DOI 10.1023/A:1010884214864
   GUNASEKARAGE Abeyratna., 2001, Emerging Markets Review, V2, P17, DOI DOI 10.1016/S1566-0141(00)00017-0
   Guresen E, 2011, EXPERT SYST APPL, V38, P10389, DOI 10.1016/j.eswa.2011.02.068
   Harb JGD, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102372
   Henrique B. M., 2018, The Journal of Finance and Data Science, V4, P183, DOI DOI 10.1016/J.JFDS.2018.04.003
   Hiransha M., 2018, Procedia Computer Science, V132, P1351, DOI 10.1016/j.procs.2018.05.050
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hung CL, 2017, INFORM PROCESS MANAG, V53, P751, DOI 10.1016/j.ipm.2017.02.007
   Kempe David, 2003, P 9 ACM SIGKDD INT C, P137, DOI DOI 10.1145/956750.956769
   Kim HY, 2018, EXPERT SYST APPL, V103, P25, DOI 10.1016/j.eswa.2018.03.002
   Kim SH, 2014, J ECON BEHAV ORGAN, V107, P708, DOI 10.1016/j.jebo.2014.04.015
   Kim T, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212320
   Kingma D. P., 2014, arXiv
   Klinker F., 2011, Mathematische Semesterberichte, V58, P97, DOI DOI 10.1007/S00591-010-0080-8
   Kumar Avanish, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P153, DOI 10.1007/978-3-030-67187-7_17
   Kumar Krishan, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2018. Advances in Intelligent Systems and Computing (AISC 1053), P671, DOI 10.1007/978-981-15-0751-9_62
   Kumar N, 2017, INT CONF ADV COMPU, P15, DOI 10.1109/ICoAC.2017.8441495
   Kumar S, 2018, 2018 C INFORM COMMUN, P1, DOI [10.1109/INFOCOMTECH.2018.8722387, DOI 10.1109/INFOCOMTECH.2018.8722387]
   Lee C, 1999, J FINANC, V55, DOI [10.2139/ssrn.92589, DOI 10.2139/SSRN.92589]
   Lee CY, 2017, CONF TECHNOL APPL, P160, DOI 10.1109/TAAI.2017.27
   Lee S, 2018, INFORM PROCESS MANAG, V54, P1115, DOI 10.1016/j.ipm.2018.08.002
   Lento C., 2007, Applied Financial Economics Letters, V3, P263
   Li B, 2017, INFORM SYST, V69, P81, DOI 10.1016/j.is.2016.10.001
   Li XD, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102212
   Li XD, 2014, KNOWL-BASED SYST, V69, P14, DOI 10.1016/j.knosys.2014.04.022
   Li YL, 2020, INT J FORECASTING, V36, P1541, DOI 10.1016/j.ijforecast.2020.05.001
   Long JW, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106205
   Loughran T, 2011, J FINANC, V66, P35, DOI 10.1111/j.1540-6261.2010.01625.x
   Maqsood H, 2020, INT J INFORM MANAGE, V50, P432, DOI 10.1016/j.ijinfomgt.2019.07.011
   Mourad M, 2018, 2018 1ST INTERNATIONAL CONFERENCE ON CANCER CARE INFORMATICS (CCI), P1, DOI 10.1109/CANCERCARE.2018.8618254
   Nelson DMQ, 2017, IEEE IJCNN, P1419, DOI 10.1109/IJCNN.2017.7966019
   Oh C., 2011, P INT C INFORM SYSTE
   Pang B., 2008, INFORM RETRIEVAL, V2, P1, DOI [10.1561/1500000011, DOI 10.1561/1500000011, https://doi.org/10.1561/1500000011]
   Pang XW, 2020, J SUPERCOMPUT, V76, P2098, DOI 10.1007/s11227-017-2228-y
   Patel J, 2015, EXPERT SYST APPL, V42, P259, DOI 10.1016/j.eswa.2014.07.040
   Peng Yangtuo., 2015, 'Leverage Financial News to Predict Stock Price Movements Using Word Embeddings and Deep Neural Networks'
   Picasso A, 2019, EXPERT SYST APPL, V135, P60, DOI 10.1016/j.eswa.2019.06.014
   Qian B, 2007, APPL INTELL, V26, P25, DOI 10.1007/s10489-006-0001-7
   Qian Y, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102209
   Qu H, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/4907654
   Ratto AP, 2018, 2018 IEEE S SERIES C
   Rezaei H, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114332
   Schumaker RP, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1462198.1462204
   Schumaker RP, 2009, INFORM PROCESS MANAG, V45, P571, DOI 10.1016/j.ipm.2009.05.001
   Sehgal Vivek, 2008, ICDM Workshops. 2007 7th IEEE International Conference on Data Mining Workshops, P21, DOI 10.1109/ICDMW.2007.100
   Sharma S, 2017, LECT NOTES COMPUT SC, V10597, P373, DOI 10.1007/978-3-319-69900-4_47
   Shynkevich Y, 2017, NEUROCOMPUTING, V264, P71, DOI 10.1016/j.neucom.2016.11.095
   Si J., 2013, Short Papers, V2, P24
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   TAYLOR MP, 1992, J INT MONEY FINANC, V11, P304, DOI 10.1016/0261-5606(92)90048-3
   Nguyen TH, 2015, EXPERT SYST APPL, V42, P9603, DOI 10.1016/j.eswa.2015.07.052
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
   Vaswani A, 2017, ADV NEUR IN, V30
   Verma I, 2017, 2017 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2017), P550, DOI 10.1145/3106426.3106482
   Vijayvergia A, 2021, MULTIMED TOOLS APPL, V80, P28349, DOI 10.1007/s11042-021-10997-8
   Vijayvergia A, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Vu T. T., 2012, P WORKSHOP INFORM EX, P23
   Walczak S, 2001, J MANAGE INFORM SYST, V17, P203
   Wang QL, 2018, NEUROCOMPUTING, V299, P51, DOI 10.1016/j.neucom.2018.02.095
   Xing FZ, 2018, IEEE COMPUT INTELL M, V13, P25, DOI 10.1109/MCI.2018.2866727
   Yeh CY, 2011, EXPERT SYST APPL, V38, P2177, DOI 10.1016/j.eswa.2010.08.004
   Yong B.X., 2017, MODELING DESIGN SIMU, P356, DOI DOI 10.1007/978-981-10-6463-031
   Yu JH, 2019, INFORM PROCESS MANAG, V56, P721, DOI 10.1016/j.ipm.2018.12.002
   Zhang LH, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2141, DOI 10.1145/3097983.3098117
   Zhang X., 2018, Lect Notes Comput Sci (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), DOI DOI 10.1007/978-3-319-93803-5_58
   Zhang X, 2018, KNOWL-BASED SYST, V143, P236, DOI 10.1016/j.knosys.2017.12.025
   Zhang YA, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113609
   Zhang YJ, 2021, FINANC RES LETT, V38, DOI 10.1016/j.frl.2020.101484
   Zuo Y., 2012, Eng. Manag. Res., V1, P46, DOI DOI 10.5539/EMR.V1N2P46
   Zuo Y, 2012, EXPERT SYST APPL, V39, P6729, DOI 10.1016/j.eswa.2011.12.035
NR 94
TC 3
Z9 3
U1 8
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27415
EP 27449
DI 10.1007/s11042-023-14587-8
EA FEB 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000931739200007
DA 2024-07-18
ER

PT J
AU Lati, A
   Belhocine, M
   Achour, N
AF Lati, Abdelhai
   Belhocine, Mahmoud
   Achour, Nouara
TI Fuzzy correlation based algorithm for UAV image mosaic construction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE UAV images; Image mosaic; Fuzzy correlation; Inliers
ID BRIEF-HISTORY; FEATURES
AB Aerial image mosaic construction is very important for obtaining a wide field of view with high-resolution image. After testing several image mosaicing methods, such as descriptors based algorithms and correlation based algorithms, it was observed that the common problem of those algorithms is the occurrence of numerous erroneous associations. To address this, many strategies for identifying the correct matches were suggested, such as the Random Sample Consensus (RANSAC) method; which cannot always provide efficient results. Therefore, in our work; we have proposed to detect corners as robust features in each image; then we have developed a fuzzy matching algorithm which combines known correlation measures to provide a sufficient and precise set of correct matched features required for determining the parameters of the projective transformation model. We tried the suggested technique on many scenes and found that the results maps for well-known benchmarks and are adequate in terms of recall, precision and execution speed. The results of the developed algorithm show that it efficiently overcomes problem of false matches associated with most image mosaicing techniques.
C1 [Lati, Abdelhai] Univ Kasdi Merbah Ouargla UKMO, Fac New Informat & Commun Technol, BP 511, Ouargla 30000, Algeria.
   [Belhocine, Mahmoud] Ctr Dev Technol Avancees CDTA, Cite 20 Aout 1956, Baba Hassen 16303, Alger, Algeria.
   [Achour, Nouara] Univ Sci & Technol Houari Boumedian USTHB, Lab Robot Parallelisme & Syst Embarques LRPSE, BP32, Bab Ezzouar 16111, Alger, Algeria.
C3 Centre for the Development of Advanced Technologies (CDTA)
RP Lati, A (corresponding author), Univ Kasdi Merbah Ouargla UKMO, Fac New Informat & Commun Technol, BP 511, Ouargla 30000, Algeria.
EM lati.abdelhai@univ-ouargla.dz; mbelhocine@cdta.dz; nachour@usthb.dz
CR Ait-Aoudia S., 2012, Proceedings of the 2012 16th International Conference on Information Visualisation (IV), P652, DOI 10.1109/IV.2012.113
   [Anonymous], AERIALROBOTICS DATAS
   [Anonymous], 2014, SIPIJ, DOI [10.5121/sipij.2014.5502, DOI 10.5121/SIPIJ.2014.5502]
   Arya Mary KJ, 2017, NATL C FUTURE TECHNO, P32
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Beckouche S., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P180, DOI 10.1109/ICCVW.2011.6130241
   Bede B, 2013, STUD FUZZ SOFT COMP, V295, P1, DOI 10.1007/978-3-642-35221-8
   Bhushan R., 2014, INT J COMPUT APPL, V98, P1, DOI [10.5120/17256-7602, DOI 10.5120/17256-7602]
   Bostanci E., 2017, arXiv
   Capel D, 1998, PROC CVPR IEEE, P885, DOI 10.1109/CVPR.1998.698709
   Chambon S., 2002, EVALUATION COMPARAIS
   Friendly M, 2002, J COMPUT GRAPH STAT, V11, P89, DOI 10.1198/106186002317375631
   Garcia Lina, 2020, Mendeley Data
   Ghannam S, 2013, INT J ADV COMPUT SC, V4, P94
   Ghosh D, 2016, J VIS COMMUN IMAGE R, V34, P1, DOI 10.1016/j.jvcir.2015.10.014
   Goshtasby AA, 2005, 2-D AND 3-D IMAGE REGISTRATION FOR MEDICAL, REMOTE SENSING, AND INDUSTRIAL APPLICATIONS, P1
   Harris C., 1988, ALVEY VISION C, P147151
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P11, DOI 10.1007/978-3-319-28854-3_2
   Hong Shen, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3415224
   Ientilucci E.J., 2003, Using the singular value decomposition
   Kamarainen JK, 2009, 111 LAPP U TECHN DEP
   Keane JF, 2013, J HOPKINS APL TECH D, V32, P558
   Lati A, 2018, ICINCO 2, P239, DOI [10.5220/0006826702290236, DOI 10.5220/0006826702290236]
   Li M, 2012, INT ARCH PHOTOGRAMM, V39-B6, P123
   Liu CY, 2019, OPTIK, V179, P610, DOI 10.1016/j.ijleo.2018.10.166
   Lotfi A-Z, 2004, FUZZY LOGIC SYSTEMS, P16
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   McCormack E.D., 2008, The use of small unmanned aircraft by the Washington State Department of Transportation
   Mtir Ines Hadj, 2012, Proceedings of the ICINCO 2012 9th International Conference on Informatics in Control, Automation and Robotics, P274
   Nemra A, 2010, ROBUST AIRBORNE 3D V
   Nieradka G, 2009, PROCEEDINGS OF THE JOINT 2009 INTERNATIONAL FUZZY SYSTEMS ASSOCIATION WORLD CONGRESS AND 2009 EUROPEAN SOCIETY OF FUZZY LOGIC AND TECHNOLOGY CONFERENCE, P1188
   Patidar M. D., 2011, INT J SCI ENG TECHNO, V1, P1
   Prathap KSV, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2413, DOI 10.1109/WiSPNET.2017.8300193
   Rankov V, 2005, PROC SPIE, V5701, P190, DOI 10.1117/12.590536
   Renuka D., 2016, International Journal of Engineering Research, V4
   Rey-Otero I, 2015, IEEE IMAGE PROC, P3024, DOI 10.1109/ICIP.2015.7351358
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rui T, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2021.107007
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shih-Ming Huang, 2012, 2012 12th International Conference on ITS Telecommunications (ITST 2012), P311, DOI 10.1109/ITST.2012.6425189
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Tang J., 2015, J INF HIDING MULTIME, V6, P728
   Tjahjadi ME., 2017, INT J ELECTR COMPUT, V7, P1188, DOI DOI 10.11591/ijece.v7i3.pp1188-1196
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Watson T.J., 1996, MANAGE RES NEWS, V19, P70, DOI [10.1108/eb028468, 10.35366/99275]
   Xiangyan Lan, 2020, 2020 IEEE 5th International Conference on Signal and Image Processing (ICSIP), P148, DOI 10.1109/ICSIP49896.2020.9339283
   Yan Peng, 2009, Infrared Laser Engineering, V38, P1104
   Yang Y, 2013, 2013 INT C WIR COMM, P1, DOI [10.1109/WCSP.2013.6677232, DOI 10.1109/WCSP.2013.6677232]
   Zadeh L. A., 1996, FUZZY SETS FUZZY LOG, P394, DOI [10.1142/9789814261302_0021, DOI 10.1142/9789814261302_0021]
NR 49
TC 1
Z9 1
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JAN 27
PY 2023
DI 10.1007/s11042-023-14391-4
EA JAN 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8H3YK
UT WOS:000920970600001
DA 2024-07-18
ER

PT J
AU Nagar, S
   Jain, A
   Singh, PK
   Kumar, A
AF Nagar, Surendra
   Jain, Ankush
   Singh, Pramod Kumar
   Kumar, Ajay
TI Structural similarity-based Bi-representation through true noise level
   for noise-robust face super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Face hallucination; Gaussian noise; True noise level;
   DnCNN; Residual image; Structural similarity
ID IMAGE SUPERRESOLUTION; HALLUCINATION; DICTIONARY; FRAMEWORK; SPARSITY;
   MODELS; CNN
AB In today's real-world scenarios' of computer vision applications, enhancing low-resolution (LR) facial images corrupted with unwanted noise effects is very challenging as the uneven noise distribution severely distorts these images' local structure. This paper proposes a novel noise-robust face super-resolution (SR) method, namely structural similarity-based Bi-representation SR (SS-BRSR), to tackle this problem. It firstly estimates the true noise level in the corrupted LR face through the novel noise-level estimation algorithm. Afterward, it employs a robust deep-convolutional neural network, namely DnCNN, to separate the pixel-wise noise from the noisy LR face image. This network produces two outputs: (i) a residual image and (ii) a smooth LR face image. We utilize the first output for pixel-wise updating the entire LR training images, making the structural similarity between the test and the training LR images. Further, for SR reconstruction, the SS-BRSR consists of two patch representation components that individually reconstruct the HR faces corresponding to the initial noisy LR and smooth LR face images. Besides, in both the components, the Gradient and Laplacian features-based learning scheme is incorporated to preserve the discriminative facial features in the SR reconstruction. Here, the first component substantially minimizes the reconstruction error due to noise, and the second component compensates for the lost detail in the LR face image. The target HR face image is restored by taking the appropriate proportions of obtained HR face images from each component. The experimental results on different face datasets justify the SS-BRSR method's superiority over the state-of-the-art face SR methods. For instance, the quantitative performance (in terms of PNSR and SSIM) of the proposed method over the state-of-the-art RLENR and DFDNet methods gained an improvement of [1%, 1.5%, 2.5%, 2.5%] under [10, 15, 20, 30] noise-level densities, and [1%, 1.5%, 2%, 1.5%] under [10, 15, 20, 30] noise-level densities, respectively, for the standard CelebA and FEI datasets.
C1 [Nagar, Surendra; Singh, Pramod Kumar] ABV Indian Inst Informat Technol & Management, Computat Intelligence & Data Min Lab, Gwalior, India.
   [Nagar, Surendra; Jain, Ankush] Netaji Subhas Univ Technol, Dept Comp Sci & Engn, Delhi, India.
   [Kumar, Ajay] ABV Indian Inst Informat Technol & Management, Modeling & Simulat Lab, Gwalior, India.
C3 ABV-Indian Institute of Information Technology & Management, Gwalior;
   Netaji Subhas University of Technology; ABV-Indian Institute of
   Information Technology & Management, Gwalior
RP Nagar, S (corresponding author), ABV Indian Inst Informat Technol & Management, Computat Intelligence & Data Min Lab, Gwalior, India.; Nagar, S (corresponding author), Netaji Subhas Univ Technol, Dept Comp Sci & Engn, Delhi, India.
EM nagar.surendra@outlook.com; ankush.jain@nsut.ac.in; pksingh@iiitm.ac.in;
   ajayfma@iiitm.ac.in
RI Kumar, Ajay/AAS-1455-2020; Jain, Ankush/AAW-2954-2020
OI Kumar, Ajay/0000-0002-0358-9936; Jain, Ankush/0000-0002-6042-7853
CR [Anonymous], 2009, P ADV NEUR INF PROC
   [Anonymous], 2005, WDIC 2005 APRS WORKS
   Anwar S, 2022, IEEE T PATTERN ANAL, V44, P1192, DOI 10.1109/TPAMI.2020.3021088
   Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616
   Banerjee J, 2008, PROCEEDINGS OF THE 8TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, P76, DOI 10.1109/DAS.2008.26
   Chakrabarti A, 2007, IEEE T MULTIMEDIA, V9, P888, DOI 10.1109/TMM.2007.893346
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong C, 2015, ARXIV
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Farrugia RA, 2017, IEEE T IMAGE PROCESS, V26, P4562, DOI 10.1109/TIP.2017.2717181
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Gao GW, 2014, NEUROCOMPUTING, V134, P92, DOI 10.1016/j.neucom.2012.12.059
   Greenspan H, 2009, COMPUT J, V52, P43, DOI 10.1093/comjnl/bxm075
   Guo S, 2019, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2019.00181
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Huang HB, 2017, IEEE I CONF COMP VIS, P1698, DOI 10.1109/ICCV.2017.187
   Jia Z, 2011, 2011 FIRST ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P179, DOI 10.1109/ACPR.2011.6166702
   Jiang J, 2018, LECT NOTES ARTIF INT, V10956, P1, DOI 10.1007/978-3-319-95957-3_1
   Jiang JJ, 2017, IEEE T CYBERNETICS, V47, P3991, DOI 10.1109/TCYB.2016.2594184
   Jiang JJ, 2016, INFORM SCIENCES, V367, P354, DOI 10.1016/j.ins.2016.05.032
   Jiang JJ, 2014, IEEE T IMAGE PROCESS, V23, P4220, DOI 10.1109/TIP.2014.2347201
   Jiang JJ, 2014, IEEE T MULTIMEDIA, V16, P1268, DOI 10.1109/TMM.2014.2311320
   Jiao QF, 2022, INFORM SCIENCES, V608, P1183, DOI 10.1016/j.ins.2022.07.011
   Jin DR, 2019, IEEE T CIRC SYST VID, V29, P1310, DOI 10.1109/TCSVT.2018.2839351
   Jung CK, 2011, IEEE SIGNAL PROC LET, V18, P367, DOI 10.1109/LSP.2011.2140370
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kouamé D, 2009, I S BIOMED IMAGING, P249, DOI 10.1109/ISBI.2009.5193030
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar M, 2022, NEURAL COMPUT APPL, V34, P4957, DOI 10.1007/s00521-021-06686-0
   Liu LC, 2022, INFORM SCIENCES, V609, P565, DOI 10.1016/j.ins.2022.07.057
   Liu LC, 2020, INFORM SCIENCES, V512, P416, DOI 10.1016/j.ins.2019.06.017
   Liu LC, 2018, IEEE T CYBERNETICS, V48, P1189, DOI 10.1109/TCYB.2017.2682853
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Liu Z, 2015, 20TH INTERNATIONAL CONFERENCE ON COMPOSITE MATERIALS
   Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019
   Makantasis K, 2018, IEEE T GEOSCI REMOTE, V56, P6884, DOI 10.1109/TGRS.2018.2845450
   Nagar S, 2022, EXPERT SYST APPL, V190, DOI 10.1016/j.eswa.2021.116141
   Nagar S, 2021, INFORM SCIENCES, V546, P121, DOI 10.1016/j.ins.2020.08.002
   Nagar S, 2020, DIGIT SIGNAL PROCESS, V99, DOI 10.1016/j.dsp.2020.102667
   Negi A., 2021, COMPUTATIONAL INTELL, P255
   Negi A., 2021, INT C BIG DATA ANALY, P296, DOI DOI 10.1007/978-3-030-93620-4_21
   Negi A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P595, DOI 10.1109/ICCCIS51004.2021.9397196
   Park JS, 2008, IEEE T IMAGE PROCESS, V17, P1806, DOI 10.1109/TIP.2008.2001394
   Pei XB, 2018, IEEE ACCESS, V6, P4577, DOI 10.1109/ACCESS.2018.2795038
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Shaoping Xu, 2017, IEEE Signal Processing Letters, V24, P1701, DOI 10.1109/LSP.2017.2755687
   Sharma S, 2017, 2017 IEEE 7TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE IEEE CCWC-2017
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Shi JG, 2015, IEEE SIGNAL PROC LET, V22, P554, DOI 10.1109/LSP.2014.2364262
   Shi JG, 2014, PATTERN RECOGN, V47, P3520, DOI 10.1016/j.patcog.2014.04.023
   Singh A, 2014, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2014.364
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang NN, 2017, IEEE T IMAGE PROCESS, V26, P1264, DOI 10.1109/TIP.2017.2651375
   Wang NN, 2014, INT J COMPUT VISION, V106, P9, DOI 10.1007/s11263-013-0645-9
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei SF, 2018, SUSTAIN CITIES SOC, V37, P358, DOI 10.1016/j.scs.2017.11.012
   Xiaoming Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P399, DOI 10.1007/978-3-030-58545-7_23
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang S, 2018, IEEE T CYBERNETICS, V48, P399, DOI 10.1109/TCYB.2016.2638856
   Yu X, 2020, IEEE T PATTERN ANAL, V42, P2148, DOI 10.1109/TPAMI.2019.2914039
   Zhang J, 2018, IEEE T IMAGE PROCESS, V27, P2420, DOI 10.1109/TIP.2018.2804218
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang Y, 2021, IEEE T IMAGE PROCESS, V30, P1728, DOI 10.1109/TIP.2020.3046918
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 72
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26255
EP 26288
DI 10.1007/s11042-022-14325-6
EA JAN 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000920621000003
DA 2024-07-18
ER

PT J
AU Zhao, H
   Liu, J
   Wang, WJ
AF Zhao, Hong
   Liu, Juan
   Wang, Weijie
TI Research on human behavior recognition in video based on 3DCCA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; 3DCNN; Spatiotemporal feature; Attention mechanism;
   Behavior recognition
ID SPATIAL-TEMPORAL ATTENTION; NETWORK; JOINT
AB Human behavior is an important part of video content. Therefore, the effective recognition of human behavior in the video has attracted extensive attention. In order to solve the problem that the key features are not prominent and the accuracy rate is not high in the existing methods of human behavior recognition in video. This paper proposes a three-dimensional convolutional neural network fusing channel attention (3DCCA) model feature extraction method. Mean normalization is presented for the preprocessing of RGB video frames. The three-dimensional convolution (3DCNN) is presented for the spatiotemporal features extraction of the inputs clips. The channel attention(CA) is used to select features that are more critical for current behavior recognition from all features. Softmax classifiers to achieve in the Classification and Identification of the human behavior in video. The training results on UCF101 and HMDB51 public datasets show that the algorithm can make better use of the original information in the video, extract more effective features, correctly detect human behaviors and actions and show stronger recognition ability to the algorithm compared with other commonly used human behavior feature extraction and recognition methods.
C1 [Zhao, Hong; Liu, Juan; Wang, Weijie] Lanzhou Univ Technol, Sch Comp & Commun Technol, Lanzhou 730050, Peoples R China.
C3 Lanzhou University of Technology
RP Liu, J (corresponding author), Lanzhou Univ Technol, Sch Comp & Commun Technol, Lanzhou 730050, Peoples R China.
EM 1507447025@qq.com
FU National Science Foundation of China [51668043, 61262016]; CERNET
   Innovation Project [NGII20160311, NGII20160112]; Gansu Science
   Foundation of China [18JR3RA156]
FX AcknowledgmentsThis research work was supported in part by the National
   Science Foundation of China under Grant 51668043, and Grant 61262016, in
   part by the CERNET Innovation Project under Grant NGII20160311, and
   Grant NGII20160112, and in part by the Gansu Science Foundation of China
   under Grant 18JR3RA156.
CR [Anonymous], ACTION RECOGNITION H
   [Anonymous], ACTION RECOGNITION U
   Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du WB, 2018, IEEE T IMAGE PROCESS, V27, P1347, DOI 10.1109/TIP.2017.2778563
   Hbn A., 2021, PATTERN RECOGN LETT
   Hsueh YL, 2020, INFORM SCIENCES, V517, P275, DOI 10.1016/j.ins.2020.01.002
   Hu HY, 2020, PATTERN RECOGN LETT, V130, P267, DOI 10.1016/j.patrec.2018.10.011
   Huang JH, 2020, IEEE J BIOMED HEALTH, V24, P292, DOI 10.1109/JBHI.2019.2909688
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kim JeeHyun, 2020, [Journal of The Korea Society of Computer and Information, 한국컴퓨터정보학회논문지], V25, P55, DOI 10.9708/jksci.2020.25.01.055
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   [李瑞峰 Li Ruifeng], 2014, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V27, P35
   Li ZY, 2018, COMPUT VIS IMAGE UND, V166, P41, DOI 10.1016/j.cviu.2017.10.011
   Liciotti D, 2020, NEUROCOMPUTING, V396, P501, DOI 10.1016/j.neucom.2018.10.104
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Tu NA, 2019, IEEE T CIRC SYST VID, V29, P800, DOI 10.1109/TCSVT.2018.2816960
   Peng YX, 2019, IEEE T CIRC SYST VID, V29, P773, DOI 10.1109/TCSVT.2018.2808685
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Salakhutdinov, 2015, ARXIV151104119
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Simonyan K, 2014, ADV NEUR IN, V27
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LK, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0365-8
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yao FG, 2021, BEHAV INFORM TECHNOL, V40, pLXXVI, DOI 10.1080/0144929X.2020.1716390
   Yao GL, 2019, PATTERN RECOGN LETT, V118, P14, DOI 10.1016/j.patrec.2018.05.018
   Ye Q, 2022, OPTIK, V251, DOI 10.1016/j.ijleo.2021.168402
   Yeung S, 2018, INT J COMPUT VISION, V126, P375, DOI 10.1007/s11263-017-1013-y
   Yu S, 2020, IEEE ACCESS, V8, P1840, DOI 10.1109/ACCESS.2019.2962284
   Yu TZ, 2018, PATTERN RECOGN LETT, V112, P226, DOI 10.1016/j.patrec.2018.07.034
   Zhang BW, 2018, IEEE T IMAGE PROCESS, V27, P2326, DOI 10.1109/TIP.2018.2791180
   Zhang JX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3321511
   Zhang JX, 2019, PATTERN RECOGN, V90, P196, DOI 10.1016/j.patcog.2019.01.027
   Zhang MX, 2018, SIGNAL PROCESS, V145, P137, DOI 10.1016/j.sigpro.2017.12.008
   Zhang ZF, 2020, NEUROCOMPUTING, V410, P304, DOI 10.1016/j.neucom.2020.06.032
   Zhao SC, 2018, IEEE T CIRC SYST VID, V28, P1839, DOI 10.1109/TCSVT.2017.2682196
   Zhu F, 2016, IMAGE VISION COMPUT, V55, P42, DOI 10.1016/j.imavis.2016.06.007
NR 41
TC 1
Z9 1
U1 5
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20251
EP 20268
DI 10.1007/s11042-023-14355-8
EA JAN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000949190900002
DA 2024-07-18
ER

PT J
AU Patil, NS
   Parveen, A
AF Patil, Nandini S.
   Parveen, Asma
TI Integrated CS-clustering mechanism for network lifetime improvisation in
   WSN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing; Data aggregation; Clustering; WSN
ID WIRELESS SENSOR NETWORKS; BIG DATA; PROTOCOL; ENERGY
AB Wireless Sensor network has become hub for the industry and academia people due to its vibrant application and various characteristics like low cost, distributable, low-power technology, data compression and especially wireless communication. Moreover, in terms of application, it provides huge diversified monitoring flexibility for several important field like battlefield, agricultural monitoring, medical monitoring and environmental monitoring. Despite of such large application, there has been constant concern regarding the network lifetime and energy consumption is directly responsible for such issue. Meanwhile compressive sensing has been one of the popular data aggregation mechanism to reduce the data redundancy; hence, this research work design and develop a mechanism named ICCM (Integrated CS-clustering mechanism) which incorporates the clustering and compressive sensing mechanism to design and efficient WSN architecture which aims at network lifetime enhancement through Compressive sensing along with clustering. In ICCM approach, Cluster Heads utilize the novel and optimal CS mechanism for data transmission to Base station; further an novel optimized clustering approach is used for efficient clustering, also we design standalone logical link for data transmission. Furthermore, ICCM is evaluated considering the different parameter like network lifetime, energy consumption, functioning node and non-functioning node; also, comparative analysis with the existing model suggest that ICCM simply outperforms the existing model.
C1 [Patil, Nandini S.; Parveen, Asma] Khaja Banda Nawaz Coll Engn, CSE Dept, Kalaburagi, India.
RP Patil, NS (corresponding author), Khaja Banda Nawaz Coll Engn, CSE Dept, Kalaburagi, India.
EM nandinipatil5@gmail.com
RI Parveen, Asma/IWD-5669-2023
OI Patil, Nandini/0000-0002-8606-5774
CR Al-Karaki Jamal N., 2007, 2007 International Conference on Sensor Technologies and Applications - SensorComm 2007, P424, DOI 10.1109/SENSORCOMM.2007.4394958
   Alaa S, 2015, INT J COMPUTER SCI I, V12, P23
   Bouyer A, 2015, INT J COMMUN NETW DI, V14, P400, DOI 10.1504/IJCNDS.2015.069675
   Dehghani S, 2018, WIRELESS PERS COMMUN, V98, P1605, DOI 10.1007/s11277-017-4937-1
   Gupta HP, 2015, IEEE SENS J, V15, P2984, DOI 10.1109/JSEN.2014.2385734
   Jain N, 2019, IEEE SENS J, V19, P1040, DOI 10.1109/JSEN.2018.2878788
   Lin DY, 2021, IEEE EMBED SYST LETT, V13, P126, DOI 10.1109/LES.2020.3022848
   Liu T, 2017, IEEE T MOBILE COMPUT, V16, P2213, DOI 10.1109/TMC.2016.2616309
   Liu XX, 2020, IEEE INTERNET THINGS, V7, P1205, DOI 10.1109/JIOT.2019.2953476
   Liu XX, 2020, IEEE T IND INFORM, V16, P350, DOI 10.1109/TII.2019.2916300
   Mukherjee A, 2020, NEURAL COMPUT APPL, V32, P16109, DOI 10.1007/s00521-020-04763-4
   Nie YL, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717717593
   Qiao JH, 2018, IEEE ACCESS, V6, P24391, DOI 10.1109/ACCESS.2018.2832626
   Reddy V., 2019, International Journal of Electrical and Computer Engineering, V9, P439
   Shen J, 2017, IEEE ACCESS, V5, P18469, DOI 10.1109/ACCESS.2017.2749606
   Su SC, 2018, SUSTAIN COMPUT-INFOR, V18, P127, DOI 10.1016/j.suscom.2017.08.001
   Sun ZY, 2019, INT J COMPUT SCI ENG, V19, P177
   Sun ZY, 2019, IEEE ACCESS, V7, P28238, DOI 10.1109/ACCESS.2019.2896250
   Sun ZY, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/5131949
   Sun ZY, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1023-7
   Tang JW, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030751
   Tinker MS, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATION ENGINEERING ICACCE 2015, P7, DOI 10.1109/ICACCE.2015.103
   Wang QY, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1067-8
   Wang T, 2020, IEEE T IND INFORM, V16, P1321, DOI 10.1109/TII.2019.2938861
   Wang T, 2020, IEEE T IND INFORM, V16, P4791, DOI 10.1109/TII.2019.2940745
   Wu YK, 2020, INFORM SCIENCES, V508, P79, DOI 10.1016/j.ins.2019.08.064
   Yalin N., 2014, J COMMUN, V9, P762, DOI [10.12720/jcm, DOI 10.12720/JCM]
   Yalin N., 2014, SENSOR LETT, V12, P287, DOI [10.1166/sl.2014.3281, DOI 10.1166/SL.2014.3281]
   Zhang P, 2019, IEEE T COMMUN, V67, P8450, DOI 10.1109/TCOMM.2019.2938950
NR 29
TC 2
Z9 2
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19487
EP 19502
DI 10.1007/s11042-022-14261-5
EA DEC 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000898637000001
DA 2024-07-18
ER

PT J
AU Bozkurt, F
AF Bozkurt, Ferhat
TI Skin lesion classification on dermatoscopic images using effective data
   augmentation and pre-trained deep learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin cancer; Dermatoscopic images; Classification; Deep learning; Data
   augmentation
ID NEURAL-NETWORKS; CANCER
AB Skin cancer is a severe disease that is common and causes death if left untreated. When skin cancer is detected early through dermatoscopic imaging, the possibility of definitive treatment is very high. Although melanoma is one of the fatal types of skin cancer, early detection dramatically increases the chances of survival. There is a low morbidity rate and limited actual data to study this deadly disease. This is a significant handicap in the application of machine learning techniques. Accurate diagnosis is essential because of the similarity of some types of lesions. The accuracy of the diagnosis is related to the professional experience of the specialist. The development of rapid and successful computerized diagnostic systems for the diagnosis and classification of skin cancer has become increasingly important. Deep learning-based applications are especially new trend in the detection of diseases from medical images. In this study, an effective data augmentation and a pre-trained deep learning approach are proposed for skin lesion classification. A hybrid network model called the Inception-Resnet-v2 is proposed to classify skin cancer images. The main aim of this study is to increase the number of images in the dataset by applying the affine transformation technique (data augmentation) and analyzing its effect on the skin cancer classification system. The highest reported accuracy in this study with an augmented dataset is 95.09% for the Inception-Resnet-v2 model while the same model achieved 83.59% with the original dataset.
C1 [Bozkurt, Ferhat] Ataturk Univ, Fac Engn, Dept Comp Engn, TR-25240 Erzurum, Turkey.
C3 Ataturk University
RP Bozkurt, F (corresponding author), Ataturk Univ, Fac Engn, Dept Comp Engn, TR-25240 Erzurum, Turkey.
EM fbozkurt@atauni.edu.tr
RI Bozkurt, Ferhat/GYR-3398-2022
OI Bozkurt, Ferhat/0000-0003-0088-5825
CR Abbas Q, 2013, PATTERN RECOGN, V46, P86, DOI 10.1016/j.patcog.2012.07.027
   Akram T, 2020, HUM-CENT COMPUT INFO, V10, DOI 10.1186/s13673-020-00216-y
   ALDWGERI A., 2019, International Visual Informatics Conference, P214, DOI DOI 10.1007/978-3-030-34032-2_20
   Ali MS, 2021, MACH LEARN APPL, V5, DOI 10.1016/j.mlwa.2021.100036
   Alqudaht AM, 2019, J BIOMIM BIOMATER BI, V42, P67, DOI 10.4028/www.scientific.net/JBBBE.42.67
   [Anonymous], 2021, CA Cancer J Clin, V71, P359, DOI 10.3322/caac.21669
   Brinker TJ, 2019, EUR J CANCER, V119, P11, DOI 10.1016/j.ejca.2019.05.023
   Capdehourat G, 2011, PATTERN RECOGN LETT, V32, P2187, DOI 10.1016/j.patrec.2011.06.015
   Celebi ME, 2008, COMPUT MED IMAG GRAP, V32, P670, DOI 10.1016/j.compmedimag.2008.08.003
   Cengil E., 2021, Avrupa Bilim Ve Teknoloji Dergisi, V28, P694
   Chaturvedi SS, 2020, MULTIMED TOOLS APPL, V79, P28477, DOI 10.1007/s11042-020-09388-2
   Demir F., 2021, F RAT NIVERSITESI M, V33, P617, DOI DOI 10.35234/FUMBD.900170
   Ergun E., 2021, BLACK SEA J ENG SCI, V4, P192, DOI [10.34248/bsengineering.938520, DOI 10.34248/BSENGINEERING.938520]
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fabbrocini G, 2011, INT J TELEMED APPL, V2011, DOI 10.1155/2011/125762
   Fabbrocini Gabriella, 2010, Cancers (Basel), V2, P1980, DOI 10.3390/cancers2041980
   Fattahi M, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00617-z
   Ferreira CA, 2018, LECT NOTES COMPUT SC, V10882, P763, DOI 10.1007/978-3-319-93000-8_86
   Garg R, 2021, INNOVATIONS COMPUTAT, P578, DOI [DOI 10.1007/978-981-15-6067-565, 10.1007/978-981-15-6067-5_65, DOI 10.1007/978-981-15-6067-5_65]
   Goceri Evgin, 2020, 2020 IEEE 4th International Conference on Image Processing, Applications and Systems (IPAS), P144, DOI 10.1109/IPAS50080.2020.9334937
   Haenssle H A, 2019, Ann Oncol, V30, p130e, DOI 10.1093/annonc/mdy520
   Hameed A, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03485-2
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoang L, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12052677
   Hosny KM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217293
   Kalaivani A., 2021, NEW ARCH, V8, P443
   Kassani SH, 2019, TISSUE CELL, V58, P76, DOI 10.1016/j.tice.2019.04.009
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li YX, 2020, EKSPLOAT NIEZAWODN, V22, P63, DOI 10.17531/ein.2020.1.8
   Mehra A., 2021, Advances in Intelligent Systems and Computing, DOI [10.1007/978-981-33-4367-2_6, DOI 10.1007/978-981-33-4367-2_6]
   Moataz L., 2021, P 6 INT C ADV TECHN
   Mohbey K. K., 2020, Journal of Digital Information Management, V2, P1, DOI [10.1007/s42488-019-00013-y, DOI 10.1007/S42488-019-00013-Y]
   Nami N., 2012, Expert Rev.Dermatol, V7, P1, DOI [10.1586/edm.11.79, DOI 10.1586/EDM.11.79]
   Narayanamurthy V, 2018, RSC ADV, V8, P28095, DOI 10.1039/c8ra04164d
   Nugroho AA, 2019, AIP CONF PROC, V2202, DOI 10.1063/1.5141652
   Pai K, 2019, TENCON IEEE REGION, P1794, DOI [10.1109/TENCON.2019.8929461, 10.1109/tencon.2019.8929461]
   Pouyanfar S, 2017, IEEE INT CON MULTI, P373, DOI 10.1109/ICME.2017.8019447
   Purnama I. K. E, 2019, 2019 INT C COMPUTER, P1
   Ramachandro M, 2021, 2021 INNOVATIONS POW, P1, DOI [10.1109/i-PACT52855.2021.9696874, DOI 10.1109/I-PACT52855.2021.9696874]
   Ratul M.A.R., 2020, bioRxiv, DOI DOI 10.1101/860700
   Rey-Barroso L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010252
   Roccetti M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00428-8
   Salamaa WM, 2021, MULTIMED TOOLS APPL, V80, P26795, DOI 10.1007/s11042-021-11000-0
   Salma W, 2022, MULTIMED TOOLS APPL, V81, P32643, DOI 10.1007/s11042-022-13081-x
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Thomas L, 2017, ACTA DERM-VENEREOL, V97, P14, DOI 10.2340/00015555-2719
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Ural A., 2021, International Journal of Computational and Experimental Science and Engineering, V7, P156, DOI [10.22399/ijcesen.973726, DOI 10.22399/IJCESEN.973726]
   Verma R, 2021, IEEE T MED IMAGING, V40, P3413, DOI 10.1109/TMI.2021.3085712
   Wang JK, 2021, IEEE ACCESS, V9, P93209, DOI 10.1109/ACCESS.2021.3093210
   Xie YT, 2020, IEEE T MED IMAGING, V39, P2482, DOI 10.1109/TMI.2020.2972964
   Zhang Y., 2019, arXiv
   Zunair H, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab86d3
NR 54
TC 8
Z9 8
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18985
EP 19003
DI 10.1007/s11042-022-14095-1
EA NOV 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000889032600004
DA 2024-07-18
ER

PT J
AU Sharaf, M
   Hemdan, EE
   El-Sayed, A
   El-Bahnasawy, NA
AF Sharaf, Marwa
   Hemdan, Ezz El-Din
   El-Sayed, Ayman
   El-Bahnasawy, Nirmeen A.
TI An efficient hybrid stock trend prediction system during COVID-19
   pandemic based on stacked-LSTM and news sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19 pandemic; Stock market; Sentimental analysis; Stacked-LSTM;
   Prediction; Machine learning
AB The coronavirus is an irresistible virus that generally influences the respiratory framework. It has an effective impact on the global economy specifically, on the financial movement of stock markets. Recently, an accurate stock market prediction has been of great interest to investors. A sudden change in the stock movement due to COVID -19 appearance causes some problems for investors. From this point, we propose an efficient system that applies sentiment analysis of COVID-19 news and articles to extract the final impact of COVID-19 on the financial stock market. In this paper, we propose a stock market prediction system that extracts the stock movement with the COVID spread. It is important to predict the effect of these diseases on the economy to be ready for any disease change and protect our economy. In this paper, we apply sentimental analysis to stock news headlines to predict the daily future trend of stock in the COVID-19 period. Also, we use machine learning classifiers to predict the final impact of COVID-19 on some stocks such as TSLA, AMZ, and GOOG stock. For improving the performance and quality of future trend predictions, feature selection and spam tweet reduction are performed on the data sets. Finally, our proposed system is a hybrid system that applies text mining on social media data mining on the historical stock dataset to improve the whole prediction performance. The proposed system predicts stock movement for TSLA, AMZ, and GOOG with average prediction accuracy of 90%, 91.6%, and 92.3% respectively.
C1 [Sharaf, Marwa; Hemdan, Ezz El-Din; El-Sayed, Ayman; El-Bahnasawy, Nirmeen A.] Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Sharaf, M (corresponding author), Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia, Egypt.
EM eng.marwa.sharaf@el-eng.menofia.edu.eg; ezzvip@yahoo.com;
   ayman.elsayed@el-eng.menofia.edu.eg;
   nirmeena.el-bahnasawy@el-eng.menofia.edu.eg
RI El-Bahnasawy, Nirmeen A./GNM-7138-2022; EL-SAYED, Ayman E./AFM-8547-2022
OI El-Bahnasawy, Nirmeen A./0000-0002-4542-323X; EL-SAYED, Ayman
   E./0000-0002-4437-259X
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Ananthi M, 2021, J AMB INTEL HUM COMP, V12, P4819, DOI 10.1007/s12652-020-01892-5
   Bach MP, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11051277
   Chandra R, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255615
   D'Andrea A., 2015, INT J COMPUT APPL, V125, DOI [DOI 10.5120/IJCA2015905866, 10.5120/ijca2015905866]
   Derakhshan A, 2019, ENG APPL ARTIF INTEL, V85, P569, DOI 10.1016/j.engappai.2019.07.002
   Farhadloo M, 2016, STUD COMPUT INTELL, V639, P1, DOI 10.1007/978-3-319-30319-2_1
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI DOI 10.5121/IJDKP.2015.5201
   Khan W, 2020, SOFT COMPUT, V24, P11019, DOI 10.1007/s00500-019-04347-y
   Khan W, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01839-w
   Lu X., 2020, ECCV, V12348, P661, DOI DOI 10.1007/978-3-030-58580-8_39
   Patel J, 2018, STOCK PRICE PREDICTI
   Picasso A, 2019, EXPERT SYST APPL, V135, P60, DOI 10.1016/j.eswa.2019.06.014
   Pramod B., 2021, Test Eng. Manag., V83, P5246
   Qiu JY, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0227222
   Rajput NK, 2020, arXiv
   Roccetti Marco, 2017, JMIR Public Health Surveill, V3, pe51, DOI 10.2196/publichealth.7004
   Ahmar AS, 2020, SCI TOTAL ENVIRON, V729, DOI 10.1016/j.scitotenv.2020.138883
   Sharaf M, 2022, MULTIMED TOOLS APPL, V81, P16761, DOI 10.1007/s11042-022-12564-1
   Sharaf M, 2021, MULTIMED TOOLS APPL, V80, P17923, DOI 10.1007/s11042-021-10579-8
   Stifanic D, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/1846926
   Sultana N., 2019, ICTACT J SOFT COMPUT, V09
   Tejwani R, 2014, ARXIV
   Thakkar A, 2020, PROCEDIA COMPUT SCI, V167, P616, DOI 10.1016/j.procs.2020.03.328
   Tiwari Dimple, 2020, 2020 7th International Conference on Computing for Sustainable Global Development (INDIACom), P150, DOI 10.23919/INDIACom49435.2020.9083693
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5
   Ye J., 2020, ARXIV
   Yulian Wen, 2020, IOP Conference Series: Materials Science and Engineering, V790, DOI 10.1088/1757-899X/790/1/012109
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhao JH, 2020, J AMB INTEL HUM COMP, V11, P3575, DOI 10.1007/s12652-019-01520-x
NR 30
TC 3
Z9 3
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 23945
EP 23977
DI 10.1007/s11042-022-14216-w
EA NOV 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000889417700007
PM 36467438
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Lanjewar, MG
   Shaikh, AY
   Parab, J
AF Lanjewar, Madhusudan G.
   Shaikh, Arman Yusuf
   Parab, Jivan
TI Cloud-based COVID-19 disease prediction system from X-Ray images using
   convolutional neural network on smartphone
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; CNN; Cloud computing; Chest X-Ray; DCNN
ID DROPOUT
AB COVID-19 has engulfed over 200 nations through human-to-human transmission, either directly or indirectly. Reverse Transcription-polymerase Chain Reaction (RT-PCR) has been endorsed as a standard COVID-19 diagnostic procedure but has caveats such as low sensitivity, the need for a skilled workforce, and is time-consuming. Coronaviruses show significant manifestation in Chest X-Ray (CX-Ray) images and, thus, can be a viable option for an alternate COVID-19 diagnostic strategy. An automatic COVID-19 detection system can be developed to detect the disease, thus reducing strain on the healthcare system. This paper discusses a real-time Convolutional Neural Network (CNN) based system for COVID-19 illness prediction from CX-Ray images on the cloud. The implemented CNN model displays exemplary results, with training accuracy being 99.94% and validation accuracy reaching 98.81%. The confusion matrix was utilized to assess the models' outcome and achieved 99% precision, 98% recall, 99% F1 score, 100% training area under the curve (AUC) and 98.3% validation AUC. The same CX-Ray dataset was also employed to predict the COVID-19 disease with deep Convolution Neural Networks (DCNN), such as ResNet50, VGG19, InceptonV3, and Xception. The prediction outcome demonstrated that the present CNN was more capable than the DCNN models. The efficient CNN model was deployed to the Platform as a Service (PaaS) cloud.
C1 [Lanjewar, Madhusudan G.; Shaikh, Arman Yusuf; Parab, Jivan] Goa Univ, Sch Phys & Appl Sci, Taleigao Plateau 403206, Goa, India.
C3 Goa University
RP Parab, J (corresponding author), Goa Univ, Sch Phys & Appl Sci, Taleigao Plateau 403206, Goa, India.
EM madhusudan@unigoa.ac.in; shaikhannanx@gmail.com; jsparab@unigoa.ac.in
OI Lanjewar, Madhusudan/0000-0002-9670-3020
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Alam T., SSRN Electronic Journal, 01, P2020, DOI DOI 10.2139/SSRN.3639063
   Alkhodari M, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0262448
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Ayalew AM, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103530
   Carretero J, 2014, CLUSTER COMPUT, V17, P1225, DOI 10.1007/s10586-014-0352-5
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chowdhury MEH, 2020, IEEE ACCESS, V8, P132665, DOI 10.1109/ACCESS.2020.3010287
   Dadario AMV, 2020, RADIOLOGY, V296, pE192, DOI 10.1148/radiol.2020201178
   Das AK, 2021, PATTERN ANAL APPL, V24, P1111, DOI 10.1007/s10044-021-00970-4
   Das AK, 2021, CHAOS SOLITON FRACT, V144, DOI 10.1016/j.chaos.2021.110713
   de Venâncio PVAB, 2022, NEURAL COMPUT APPL, V34, P15349, DOI 10.1007/s00521-022-07467-z
   Eftekhari A, 2021, MICROORGANISMS, V9, DOI 10.3390/microorganisms9020232
   Elgamal T, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), P1, DOI 10.1109/CLOUD.2018.00008
   Farooq M., 2020, arXiv preprint arXiv:2003.14395
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Garbin C, 2020, MULTIMED TOOLS APPL, V79, P12777, DOI 10.1007/s11042-019-08453-9
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Guefrechi S, 2021, MULTIMED TOOLS APPL, V80, P31803, DOI 10.1007/s11042-021-11192-5
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang CL, 2020, LANCET, V395, P497, DOI [10.1016/S0140-6736(20)30183-5, 10.1016/S0140-6736(20)30211-7]
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   Indumathi N., 2022, Intell Inter Multimedia Syst For e-Healthcare Appl, P171
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jordao A, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2004.11178
   Kaggle, COVID-19 Radiography Database
   keras, TEAM K KERAS DOCUMEN
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03306-6
   Kumar V, 2021, ADV COMPUT SYS SEC, V14, P17
   Lanjewar MG, 2022, MULTIMED TOOLS APPL, V81, P10313, DOI 10.1007/s11042-022-12200-y
   Lanjewar MG, 2023, CLUSTER COMPUT, V26, P3657, DOI 10.1007/s10586-022-03752-7
   Lanjewar MG, 2023, MULTIMED TOOLS APPL, V82, P12699, DOI 10.1007/s11042-022-13935-4
   Lanjewar MG, 2023, NEURAL COMPUT APPL, V35, P2755, DOI 10.1007/s00521-022-07743-y
   Lanjewar MG, 2022, MULTIMED TOOLS APPL, V81, P16537, DOI 10.1007/s11042-022-12392-3
   Li X, 2019, PROC CVPR IEEE, P2677, DOI 10.1109/CVPR.2019.00279
   Li XR, 2021, J AMB INTEL HUM COMP, V12, P923, DOI 10.1007/s12652-020-02108-6
   Lo WW, 2019, INT CONF NEW TECHNOL, DOI 10.1109/ntms.2019.8763852
   Maghdid HS, 2021, PROC SPIE, V11734, DOI 10.1117/12.2588672
   Makris Antonios, 2020, SETN 2020: Proceedings of the 11th Hellenic Conference on Artificial Intelligence, P60, DOI 10.1145/3411408.3411416
   Mansour NA, 2022, J AMB INTEL HUM COMP, V13, P41, DOI 10.1007/s12652-020-02883-2
   Mateen M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010001
   Meraihi Yassine, 2022, SN Comput Sci, V3, P286, DOI 10.1007/s42979-022-01184-z
   MK MV, 2022, FRONT ARTIF INTELL, V5
   Murugan R, 2021, J AMB INTEL HUM COMP, V12, P8887, DOI 10.1007/s12652-020-02688-3
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Natnael T, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0247954
   Ng MY, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200034
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Parab J, 2022, HDB INTELLIGENT COMP, P835
   Parab J, 2021, IEEE J TRANSL ENG HE, V9, DOI 10.1109/JTEHM.2021.3079714
   Qi X, 2021, INT J COMPUT ASS RAD, V16, P197, DOI 10.1007/s11548-020-02305-w
   Rahaman MM, 2020, J X-RAY SCI TECHNOL, V28, P821, DOI 10.3233/XST-200715
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Rehman Arshia., 2020, Improving coronavirus (COVID-19) diagnosis using deep transfer learning, DOI DOI 10.1101/2020.04.11.20054643
   Reshi AA, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6621607
   Rostad, 2018, WHAT IS HEROKU SIMPL
   Salakhutdinov R., 2007, P 24 INT C MACH LEAR, P791, DOI DOI 10.1145/1273496.1273596
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P158
   Salau AO, 2021, 2021 INTERNATIONAL CONFERENCE ON DECISION AID SCIENCES AND APPLICATION (DASA), DOI 10.1109/DASA53625.2021.9682267
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh D, 2020, EUR J CLIN MICROBIOL, V39, P1379, DOI 10.1007/s10096-020-03901-z
   Singhal T, 2020, INDIAN J PEDIATR, V87, P281, DOI 10.1007/s12098-020-03263-6
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tanaka F, 2020, FOOD CHEM, V303, DOI 10.1016/j.foodchem.2019.125381
   Targ S., 2016, ARXIV, p1603.08029, DOI [10.48550/arXiv.1603.08029, DOI 10.48550/ARXIV.1603.08029]
   Yadessa Asrat Gedefa, 2021, 2021 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT), P93, DOI 10.1109/3ICT53449.2021.9581821
   Yan Q, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2004.10987
   Yuen KS, 2020, CELL BIOSCI, V10, DOI 10.1186/s13578-020-00404-4
   Zhang JP, 2021, IEEE T MED IMAGING, V40, P879, DOI 10.1109/TMI.2020.3040950
   Zhao JJ, 2020, CLIN INFECT DIS, V71, P2027, DOI 10.1093/cid/ciaa344
NR 76
TC 6
Z9 6
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29883
EP 29912
DI 10.1007/s11042-022-14232-w
EA NOV 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000886864300001
PM 36467434
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Rani, N
   Mishra, V
   Singh, B
AF Rani, Narbda
   Mishra, Vinod
   Singh, Birmohan
TI Piecewise symmetric magic cube: application to text cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Magic cube; Magic constant; Arithmetic progression; Encryption;
   Decryption; Text message
AB This article propounds a Piecewise Symmetric Magic Cube (PSMC), the properties of which have reinvigorated its application to text encryption. A method has been introduced for the construction of magic cubes of order m x 2(l), for all l,m (m even) is an element of N boolean OR{0}, m >= 4 by using the concept of compounding. The behavior of elements in PSMC is controlled by the starting variables (S-start and L-start). The formula for evaluation of the magic sum of these magic cubes have been derived, which ensures magic nature of PSMC. Additionally, PSMC are applied to the field of text cryptography. The proposed text encryption model is applicable for the encryption and decryption of any language that may include numeric digits, and special characters along with their different combinations. Also, the validation of this model has been checked by focusing on the analysis of bilingual data (English-German, English-Hindi, German-Hindi, French-Arabic, and Italian-Spanish). The performance evaluation metrices (brute-force analysis, avalanche effect, CPU time analysis, Shannon entropy, and known plain text analysis) have been carried to analyze the resisting efficiency of the proposed model against different types of attacks. An analysis of encryption/ decryption time shows that decryption is more time-efficient which protects the data from getting being corrupted by the intruders. The distinct entries of PSMC remove the problem of repetition in cipher text which raises the level of security to a higher extent.
C1 [Rani, Narbda; Mishra, Vinod] St Longowal Inst Engn & Technol, Dept Math, Sangrur 148106, Punjab, India.
   [Singh, Birmohan] St Longowal Inst Engn & Technol, Dept Comp Sci & Engn, Sangrur 148106, Punjab, India.
C3 Sant Longowal Institute of Engineering & Technology (SLIET); Sant
   Longowal Institute of Engineering & Technology (SLIET)
RP Rani, N (corresponding author), St Longowal Inst Engn & Technol, Dept Math, Sangrur 148106, Punjab, India.
EM narmadasharma1990@gmail.com; vinodmishra.2011@rediffmail.com;
   birmohans@gmail.com
RI Mishra, Vinod/S-8941-2017; Singh, Birmohan/ABO-6887-2022; Rani,
   Narbda/HMD-7803-2023
OI Mishra, Vinod/0000-0002-9979-8627; Singh, Birmohan/0000-0001-6345-5537;
   Rani, Narbda/0000-0001-5676-071X
CR ALSPACH B, 1981, FIBONACCI QUART, V19, P97
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Andrew, 1960, MAGIC SQUARE CUBES
   Arroyo JCT., 2020, INT J ADV TRENDS COM, V9, P3798, DOI [10.30534/ijatcse/2020/198932020, DOI 10.30534/IJATCSE/2020/198932020]
   Bajaj, 2022, CAESAR CIPHER
   Bharathi B., 2017, INT J ADV RES SCI EN, V6, P62
   Bouffard, 2022, ROT13
   Chen XS, 2002, J CENT SOUTH UNIV T, V9, P70, DOI 10.1007/s11771-002-0014-2
   Chiron L, 2018, J COMPUT PHYS, V354, P552, DOI 10.1016/j.jcp.2017.10.041
   Dawood O, 2015, THESIS U TECHNOLOGY
   Galar D, 2017, EMAINTENANCE: ESSENTIAL ELECTRONIC TOOLS FOR EFFICIENCY, P129, DOI 10.1016/B978-0-12-811153-6.00003-8
   George D., 2014, INT J COMPUT APPL, V975, P38
   GUSTAFSON H, 1994, COMPUT SECUR, V13, P687, DOI 10.1016/0167-4048(94)90051-5
   Hankerson Darrel, 2006, Guide to Elliptic Curve Cryptography
   Hill, 2022, ADV ENCRYPTION STAND
   Jamel S, 2010, LECT NOTES COMPUT SC, V6019, P175, DOI 10.1007/978-3-642-12189-0_16
   Jiang YH, 2018, INT J INF SECUR, V17, P533, DOI 10.1007/s10207-017-0388-7
   Jiang YH, 2018, INT J INF SECUR, V17, P463, DOI 10.1007/s10207-017-0376-y
   Khanas Y, 2020, SECUR PRIVACY, V3, DOI 10.1002/spy2.108
   Krishna GJ, 2018, APPL SOFT COMPUT, V70, P301, DOI 10.1016/j.asoc.2018.05.025
   Kumar A., 2012, International Journal of Security, Privacy and Trust Management (IJSPTM), V1, P31
   Lee S, 2013, P KOREA INFORM PROCE, V20, P768
   LIN KY, 1986, DISCRETE MATH, V58, P159, DOI 10.1016/0012-365X(86)90158-5
   Mani, 2017, INT J COMPUT NETW IN, V9
   MICHEL R, 1995, DISCRETE MATH, V146, P313, DOI 10.1016/0012-365X(94)00073-7
   Mushtaq MF, 2019, INT J ADV COMPUT SC, V10, P427
   2018, DECR ENCR DEB FRAM D
   Nordgren RP, 2012, LINEAR ALGEBRA APPL, V437, P2009, DOI 10.1016/j.laa.2012.05.031
   Pavithran P, 2022, COMPUT COMMUN, V188, P1, DOI 10.1016/j.comcom.2022.02.008
   Rajavel D., 2012, Proceedings of the 2012 International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME), P183, DOI 10.1109/ICPRIME.2012.6208340
   Rani N, 2022, INT J MATH EDUC SCI, V53, P1044, DOI 10.1080/0020739X.2021.1890846
   Rasmi PS, 2014, INT J COMMUN SYST, V27, P2593, DOI 10.1002/dac.2491
   Richards D., 1980, MATH MAG, V53, P101, DOI DOI 10.1080/0025570X.1980.11976837
   Sef, 2022, FEISTEL TEXT ENCRYPT
   Shibiraj N., 2018, INT J COMPUT SCI ENG, V6, P315
   Trenkler Marian., 2000, The Mathematical Gazette, V84, P36, DOI DOI 10.2307/3621472
   Uko LU., 2018, RECREAT MATH MAG, V4, P39
   Xu J, 2021, INT J INF SECUR, V20, P141, DOI 10.1007/s10207-020-00487-7
   Yuan Y, 2020, SCI CHINA TECHNOL SC, V63, P1637, DOI 10.1007/s11431-020-1621-y
NR 39
TC 1
Z9 1
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19369
EP 19391
DI 10.1007/s11042-022-14153-8
EA NOV 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000886859100002
DA 2024-07-18
ER

PT J
AU Shan, YL
   Ma, Y
   Liao, Y
   Huang, H
   Wang, B
AF Shan, Yilin
   Ma, Yan
   Liao, Yuan
   Huang, Hui
   Wang, Bin
TI Interactive image segmentation based on multi-layer random forest
   classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Segmentation; Superpixel; Random forest; Region merging; Breadth-first
   search
ID CUTS
AB Since fully automatic image segmentation methods often fail for most complex images, researchers turn to the interactive segmentation paradigm to achieve better segmentation performance. However, many interactive image segmentation algorithms are highly dependent on user interactive information. This paper presents a novel interactive image segmentation algorithm based on multi-layer random forests. Given a small amount of user input markers, region merging is done according to the merging rule, in which both the color histogram and gradient orientation histogram of the region are included to avoid the merging error. To speed up the calculation of gradient orientation histogram, breadth-first search is used to determine the intersection of two adjacent regions. Then, we relabel the training samples with k-means algorithm and Silhouette index and further perform the first layer random forest classification. Next, we reconstruct the training samples with the adjacent superpixel pairs and use the second layer random forest classifiers to classify the superpixels whose prediction confidence is lower than the threshold after the first layer random forest classification. Experiments on real natural images are conducted to demonstrate the performance of the proposed algorithm.
C1 [Shan, Yilin; Ma, Yan; Liao, Yuan; Huang, Hui; Wang, Bin] Shanghai Normal Univ, Coll Informat Mech & Elect Engn, Shanghai, Peoples R China.
C3 Shanghai Normal University
RP Ma, Y (corresponding author), Shanghai Normal Univ, Coll Informat Mech & Elect Engn, Shanghai, Peoples R China.
EM syilin_310@163.com; ma-yan@shnu.edu.cn; 731705150@qq.com;
   huanghui@shnu.edu.cn; binwang@slum.edu.cn
RI Yang, Mei/JNS-2225-2023; Zhang, Wenkai/JWO-2030-2024; zhang,
   jiayue/JUF-0129-2023; Zhang, Zhipeng/KHY-2239-2024
FU National Natural Science Foundation of China [61373004]
FX This work is partially supported by the National Natural Science
   Foundation of China (Grant no. 61373004).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Acuna D, 2018, PROC CVPR IEEE, P859, DOI 10.1109/CVPR.2018.00096
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breve F, 2019, EXPERT SYST APPL, V123, P18, DOI 10.1016/j.eswa.2019.01.031
   Castrejón L, 2017, PROC CVPR IEEE, P4485, DOI 10.1109/CVPR.2017.477
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Csillik O, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030243
   Eramian M, 2020, INTERACT COMPUT, V32, P233, DOI 10.1093/iwcomp/iwaa017
   Gu Y, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13061213
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   Hu ZW, 2021, INT J APPL EARTH OBS, V105, DOI 10.1016/j.jag.2021.102605
   Jian M, 2016, IEEE T IMAGE PROCESS, V25, P1301, DOI 10.1109/TIP.2016.2518480
   Jiang QC, 2019, BIG DATA COGN COMPUT, V3, DOI 10.3390/bdcc3020031
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Li MC, 2021, SIGNAL IMAGE VIDEO P, V15, P571, DOI 10.1007/s11760-020-01778-1
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Li YC, 2019, COMPUT ELECTR ENG, V79, DOI 10.1016/j.compeleceng.2019.106463
   Li ZW, 2018, PROC CVPR IEEE, P577, DOI 10.1109/CVPR.2018.00067
   Lin T.Y., Proceedings of the European Conference on Computer Vision, P740
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P3060, DOI 10.1109/TIP.2015.2432711
   Liu YC, 2013, IEEE T CYBERNETICS, V43, P982, DOI 10.1109/TSMCB.2012.2220543
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Ning JF, 2010, PATTERN RECOGN, V43, P445, DOI 10.1016/j.patcog.2009.03.004
   Peng B, 2011, IEEE T IMAGE PROCESS, V20, P3592, DOI 10.1109/TIP.2011.2157512
   Peng ZL, 2019, SIGNAL PROCESS-IMAGE, V78, P159, DOI 10.1016/j.image.2019.06.012
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Pinto A, 2018, PATTERN RECOGN, V82, P105, DOI 10.1016/j.patcog.2018.05.006
   Prinke P, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93682-y
   Ramadan H, 2020, COMPUT VIS MEDIA, V6, P355, DOI 10.1007/s41095-020-0177-5
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tang M, 2013, IEEE I CONF COMP VIS, P1769, DOI 10.1109/ICCV.2013.222
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Wang XY, 2016, NEURAL NETWORKS, V74, P1, DOI 10.1016/j.neunet.2015.10.012
   Yu HK, 2017, IEEE IMAGE PROC, P3335, DOI 10.1109/ICIP.2017.8296900
   Zhao BW, 2017, ELECTRON LETT, V53, DOI 10.1049/el.2016.4438
   Zheng Q, 2018, J VIS COMMUN IMAGE R, V55, P157, DOI 10.1016/j.jvcir.2018.06.005
NR 40
TC 0
Z9 0
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 NOV 18
PY 2022
DI 10.1007/s11042-072-14199-8
EA NOV 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6H1TO
UT WOS:000885231500008
DA 2024-07-18
ER

PT J
AU Rocha, MMM
   Landini, G
   Florindo, JB
AF Rocha, Marina M. M.
   Landini, Gabriel
   Florindo, Joao B.
TI Medical image classification using a combination of features from
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classifiers ensemble; Texture recognition; Deep convolutional networks;
   Odontogenic cysts
ID ENSEMBLE; SCALE
AB Medical image classification is an important and challenging problem, since images are usually complex, variable and the amount of data is relatively constrained. Selecting optimal sets of features and classifiers is a crucial problem in this area. In this paper it is proposed an image classification method, named Hybrid CNN Ensemble (HCNNE), based on the combination of image features extracted by convolutional neural networks (CNN) and local binary patterns (LBP). The features are subsequently used to build an ensemble of multiple classifiers. More specifically, the Euclidean distance between LBP feature vectors of each training class and the confidence of CNN features classified by support vector machines are employed to compose the input of a multilayer perceptron classifier. Finally, these features are also used as input to other classifiers to compose the final voting ensemble. This approach achieved an accuracy similar to those of other state-of-the-art methods in texture classification and showed an improvement of 10% over the previously reported identification of a group of odontogenic oral cyst histological images, at a low computational cost. Three major contributions are presented here: 1) the combination of low and high level features assigning weights based on the confidence of the features for texture recognition; 2) the combination of automatically learned deep features with LBP by a multilayer perceptron based on the feature confidences; 3) state-of-the-art results are obtained in the odontogenic cyst categorization problem.
C1 [Rocha, Marina M. M.; Florindo, Joao B.] Univ Estadual Campinas, Inst Math Stat & Sci Comp, Rua Sergio Buarque Holanda 651,Cidade Univ Zeferi, BR-13083859 Campinas, SP, Brazil.
   [Landini, Gabriel] Univ Birmingham, Sch Dent, Oral Pathol Unit, Birmingham, W Midlands, England.
C3 Universidade Estadual de Campinas; University of Birmingham
RP Rocha, MMM (corresponding author), Univ Estadual Campinas, Inst Math Stat & Sci Comp, Rua Sergio Buarque Holanda 651,Cidade Univ Zeferi, BR-13083859 Campinas, SP, Brazil.
EM m183983@dac.unicamp.br; G.Landini@bham.ac.uk; florindo@unicamp.br
RI Rocha, Marina/JCP-5082-2023
OI Landini, Gabriel/0000-0002-9689-0989; Rocha M. Monteiro,
   Marina/0000-0002-7789-9208
FU National Council for Scientific and Technological Development, CNPq
   [121791/2019-0]; Sao Paulo Research Foundation (FAPESP) [2020/01984-8];
   National Council for Scientific and Technological Development, Brazil
   (CNPq) [306030/2019-5, 423292/2018-8]
FX Marina Rocha gratefully acknowledges the support of the National Council
   for Scientific and Technological Development, CNPq (Grant
   #121791/2019-0). Joao Florindo gratefully acknowledges the financial
   support of S~ao Paulo Research Foundation (FAPESP) (Grant #2020/01984-8)
   and from National Council for Scientific and Technological Development,
   Brazil (CNPq) (Grants #306030/2019-5 and #423292/2018-8).
CR Alipanahi B, 2015, NAT BIOTECHNOL, V33, P831, DOI 10.1038/nbt.3300
   [Anonymous], UIUC DATASET
   [Anonymous], UMD DATASET
   Anwar F., 2020, 2019 INT C ADV EMERG, P1, DOI 10.1109/AECT47998.2020.9194194
   Attallah O, 2022, COMPUT BIOL MED, V142, DOI 10.1016/j.compbiomed.2022.105210
   Attallah O, 2021, CONTRAST MEDIA MOL I, V2021, DOI 10.1155/2021/7192016
   Attallah O, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.493
   Attallah O, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.423
   Bacanin N, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09744-2
   Bousetouane F, 2015, LECT NOTES COMPUT SC, V9475, P379, DOI 10.1007/978-3-319-27863-6_35
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797
   Florindo JB, 2017, COMPUT BIOL MED, V81, P1, DOI 10.1016/j.compbiomed.2016.12.003
   Forcén J, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105698
   Fouad S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188717
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Ho YC, 2002, J OPTIMIZ THEORY APP, V115, P549, DOI 10.1023/A:1021251113462
   Kannala J, 2012, INT C PATT RECOG, P1363
   Kumar A, 2017, IEEE J BIOMED HEALTH, V21, P31, DOI 10.1109/JBHI.2016.2635663
   Landini G, 2004, CYTOM PART A, V61A, P45, DOI 10.1002/cyto.a.20082
   Landini Gabriel, 2006, Head Face Med, V2, P4, DOI 10.1186/1746-160X-2-4
   Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Malakar S, 2020, NEURAL COMPUT APPL, V32, P2533, DOI 10.1007/s00521-018-3937-8
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Quan YH, 2014, PROC CVPR IEEE, P160, DOI 10.1109/CVPR.2014.28
   Ragab DA, 2020, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.306
   Ragab DA, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9040165
   RAO CR, 1948, J ROY STAT SOC B, V10, P159
   Ren Y, 2016, IEEE COMPUT INTELL M, V11, P41, DOI 10.1109/MCI.2015.2471235
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Timofte R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.93
   Wei J, 2017, EXPERT SYST APPL, V69, P29, DOI 10.1016/j.eswa.2016.09.040
   Wolpert DH, 1996, NEURAL COMPUT, V8, P1341, DOI 10.1162/neco.1996.8.7.1341
   Xu Y, 2012, COMPUT VIS IMAGE UND, V116, P999, DOI 10.1016/j.cviu.2012.05.003
   Xu Y, 2010, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2010.5540217
NR 48
TC 5
Z9 5
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19299
EP 19322
DI 10.1007/s11042-022-14206-y
EA NOV 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000884893600008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shabbir, N
   Rout, RK
AF Shabbir, Nazir
   Rout, Ranjeet Kumar
TI Variation of deep features analysis for facial expression recognition
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolutional neural network; Facial expression;
   Recognition
ID GAUSSIAN-PROCESSES; MULTIVIEW
AB In this paper, a unique facial expression recognition system has been proposed. The objective of this paper is to identify the type of human facial expression and to improve the performance by incorporating different variant patterns present in facial images. In literature, the use of different patterns of the human face has not yet been employed in its full swing. In our proposed method, this gap has been overcome by fusing a data augmentation in the preprocessing step and an optimized weight in the deep CNN model at the feature extraction step. To make this proposed model noise-free, we focus on the feature extraction method rather than designing a complex model to decompose a set of feature vectors into expression-specific feature vectors. Here, to analyze the performance of FER system, we use cultural difference datasets in both laboratory controlled and wild environments. To develop a precise facial expression recognition system, we propose an invariant deep convolutional neural network (DCNN) model that learns from all image variants to improve performance. Our model also induces a new pipeline strategy to correlate a preprocessing and feature extraction step in an optimized way. Experiments on laboratory and wild-controlled datasets show that our FER system attains a more significant performance than other state-of-the-art models due to its ability to utilize all the different variant patterns present in the facial image.
C1 [Shabbir, Nazir; Rout, Ranjeet Kumar] Natl Inst Technol Srinagar, Dept Comp Sci & Engn, Hazratbal 190006, J&K, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Srinagar
RP Rout, RK (corresponding author), Natl Inst Technol Srinagar, Dept Comp Sci & Engn, Hazratbal 190006, J&K, India.
EM ranjeetkumarrout@nitsri.net; nazirshabbir89@gmail.com
RI Rout, Ranjeet Kumar/JCE-3978-2023
CR Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606
   [Anonymous], 2014, PROCEDIA IEEE COMPUT, DOI DOI 10.1109/CVPR.2014.233
   [Anonymous], 1976, Pictures of facial affect
   Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35
   Berthelot D., 2020, Remixmatch: Semi-supervised learning with distribution matching and augmentation anchoring
   Berthelot D, 2019, ADV NEUR IN, V32
   Chen C.-H., 2015, Handbook of pattern recognition and computer vision, DOI DOI 10.1142/9789814656535_0002
   Chu Wen-Sheng, 2013, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2013, P3515
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   Eleftheriadis S, 2015, IEEE T IMAGE PROCESS, V24, P189, DOI 10.1109/TIP.2014.2375634
   Fei Z, 2019, P 2019 IEEE GLOBAL C, P1
   Ghosh A, 2023, CLUSTER COMPUT, V26, P119, DOI 10.1007/s10586-022-03552-z
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hernández-García A, 2018, LECT NOTES COMPUT SC, V11139, P95, DOI 10.1007/978-3-030-01418-6_10
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Hossain S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11199174
   Ionescu R. T., 2013, WORKSH CHALL REPR LE
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Li S, 2018, INT C PATT RECOG, P3092, DOI 10.1109/ICPR.2018.8545284
   Liu MY, 2013, IEEE INT CONF AUTOMA
   Liu YP, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P368
   Ma L, 2004, IEEE T SYST MAN CY B, V34, P1588, DOI 10.1109/TSMCB.2004.825930
   Mehrabian A., 2017, Nonverbal Communication
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Rao QY, 2015, INT CONF AFFECT, P630, DOI 10.1109/ACII.2015.7344635
   Rudovic O, 2013, IEEE T PATTERN ANAL, V35, P1357, DOI 10.1109/TPAMI.2012.233
   Sardar A, 2020, IEEE ACCESS, V8, P105263, DOI 10.1109/ACCESS.2020.2999656
   Sikka K, 2012, LECT NOTES COMPUT SC, V7584, P250, DOI 10.1007/978-3-642-33868-7_25
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Umer S, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107917
   Umer S, 2022, J AMB INTEL HUM COMP, V13, P721, DOI 10.1007/s12652-020-02845-8
   Umer S, 2021, MULTIMED TOOLS APPL, V80, P34997, DOI 10.1007/s11042-020-09079-y
   Umer S, 2020, NEURAL NETWORKS, V122, P407, DOI 10.1016/j.neunet.2019.11.009
   Umer S, 2018, IETE TECH REV, V35, P145, DOI 10.1080/02564602.2016.1265904
   Umer S, 2017, INFORM SCIENCES, V406, P102, DOI 10.1016/j.ins.2017.04.026
   Wang YQ, 2014, IMAGE PROCESS ON LIN, V4, P128, DOI 10.5201/ipol.2014.104
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Xie Q., 2020, ADV NEURAL INFORM PR, V33, P6256, DOI DOI 10.48550/ARXIV.1904.12848
   Zavarez MV, 2017, SIBGRAPI, P405, DOI 10.1109/SIBGRAPI.2017.60
   Zhang FF, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3176646
   Zheng WM, 2014, IEEE T AFFECT COMPUT, V5, P71, DOI 10.1109/TAFFC.2014.2304712
   Zhong L, 2012, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR.2012.6247974
   Zhu YF, 2011, IEEE T AFFECT COMPUT, V2, P79, DOI 10.1109/T-AFFC.2011.10
NR 49
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11507
EP 11522
DI 10.1007/s11042-022-14054-w
EA NOV 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000884893600006
DA 2024-07-18
ER

PT J
AU Qi, YF
   Zhou, CY
   Chen, YX
AF Qi, Yongfeng
   Zhou, Chenyang
   Chen, Yixing
TI NA-Resnet: neighbor block and optimized attention module for
   global-local feature extraction in facial expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Facial expression recognition; Convolutional neural
   network (CNN); NA-Resnet; Neighbor block; Optimized attention module
ID REPRESENTATION
AB As deep networks constantly deepen to extract high-level abstract features, the significance of shallow features for the target task will inevitably diminish. To address this issue and provide novel technical support for current research in the field of facial expression recognition (FER), in this article, we propose a network that can increase the decision weight of the shallow and middle feature mappings through the neighbor block (Nei Block) and concentrate on the crucial areas for extracting necessary features through the optimized attention module (OAM), called NA-Resnet. Our work has several merits. First, to the best of our knowledge, NA-Resnet is the first network that directly utilizes surface features to assist image classification. Second, the suggested OAM is embedded into each layer of the network that can precisely extract critical information appropriate to the current stage. Third, our model achieves the best exhibition when using a single relatively lightweight network without a network ensemble on Fer2013. Extensive experiments have been conducted, and the results show that our model achieves much higher state-of-the-art performance than any single network on Fer2013. In particular, our NA-Resnet achieves 74.59% on Fer2013 and an average accuracy of 96.06% with a standard deviation of 2.9% through 10-fold-cross-validation on Ck+.
C1 [Qi, Yongfeng; Zhou, Chenyang] Northwest Normal Univ, Coll Comp Sci & Engn, Lanzhou 730070, Gansu, Peoples R China.
   [Chen, Yixing] Guangzhou Univ, Sch Comp Sci & Cyber Engn, Guangzhou 510006, Guangdong, Peoples R China.
C3 Northwest Normal University - China; Guangzhou University
RP Zhou, CY (corresponding author), Northwest Normal Univ, Coll Comp Sci & Engn, Lanzhou 730070, Gansu, Peoples R China.
EM yongfaig_qi@163.com; zhou.chenyang@foxmail.com;
   2112006074@e.gzhou.edu.cn
OI Zhou, Chenyang/0000-0002-7356-6203
FU National Natural Science Foundation of China [62267007]; Gansu
   Provincial Department of Education Higher Education Industry Support
   Plan Project [2022CYZC-16]
FX The research was supported by the National Natural Science Foundation of
   China under Grant 62267007,Gansu Provincial Department of Education
   Higher Education Industry Support Plan Project under Grant 2022CYZC-16.
CR Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   [Anonymous], 2014, PROCEDIA IEEE COMPUT, DOI DOI 10.1109/CVPR.2014.233
   Cai J, 2018, IEEE INT CONF AUTOMA, P302, DOI 10.1109/FG.2018.00051
   Connie Tee, 2017, Multi-disciplinary Trends in Artificial Intelligence. 11th International Workshop, MIWAI 2017. Proceedings: LNAI 10607, P139, DOI 10.1007/978-3-319-69456-6_12
   Fan YR, 2018, LECT NOTES COMPUT SC, V11139, P84, DOI 10.1007/978-3-030-01418-6_9
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Gunes H, 2013, IMAGE VISION COMPUT, V31, P120, DOI 10.1016/j.imavis.2012.06.016
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu GS, 2018, LECT NOTES COMPUT SC, V11216, P106, DOI 10.1007/978-3-030-01258-8_7
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jaderberg M, 2015, ADV NEUR IN, V28
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P356, DOI 10.1109/TIP.2018.2868382
   Liu K, 2016, 2016 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P163, DOI 10.1109/CW.2016.34
   Luan Pham, 2020, 2020 25th International Conference on Pattern Recognition (ICPR), P4513, DOI 10.1109/ICPR48806.2021.9411919
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Meng ZB, 2017, IEEE INT CONF AUTOMA, P558, DOI 10.1109/FG.2017.140
   Murthy ASD, 2020, MATER TODAY-PROC, V33, P4323, DOI 10.1016/j.matpr.2020.07.447
   Papers with Code, 2021, FACIAL EXPRESSION RE
   Pons G, 2018, IEEE T AFFECT COMPUT, V9, P343, DOI 10.1109/TAFFC.2017.2753235
   Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137
   Rouast PV, 2021, IEEE T AFFECT COMPUT, V12, P524, DOI 10.1109/TAFFC.2018.2890471
   Ruan DL, 2021, PROC CVPR IEEE, P7656, DOI 10.1109/CVPR46437.2021.00757
   Sanchez E, 2021, PROC CVPR IEEE, P9070, DOI 10.1109/CVPR46437.2021.00896
   Sikka K, 2016, PROC CVPR IEEE, P5580, DOI 10.1109/CVPR.2016.602
   Siqueira H, 2020, AAAI CONF ARTIF INTE, V34, P5800
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang K, 2020, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR42600.2020.00693
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu RL, 2020, PROC CVPR IEEE, P5020, DOI 10.1109/CVPR42600.2020.00507
   WuJie1010, 2021, FACIAL EXPRESSION RE
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yao L, 2021, MULTIMED TOOLS APPL, V80, P24287, DOI 10.1007/s11042-021-10836-w
   Ying ZL, 2008, INT CONF SIGN PROCES, P1462
   Zhang FF, 2020, IEEE T IMAGE PROCESS, V29, P6574, DOI 10.1109/TIP.2020.2991549
   Zhang HF, 2020, IEEE ACCESS, V8, P37976, DOI 10.1109/ACCESS.2020.2975913
   Zhang LG, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3158369
   Zhao SC, 2020, AAAI CONF ARTIF INTE, V34, P303
   Zhu KN, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300923
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 46
TC 2
Z9 3
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16375
EP 16393
DI 10.1007/s11042-022-14191-2
EA NOV 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000881891200002
DA 2024-07-18
ER

PT J
AU Vaissnave, V
   Deepalakshmi, P
AF Vaissnave, V.
   Deepalakshmi, P.
TI Modeling of automated glowworm swarm optimization based deep learning
   model for legal text summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text summarization; Legal text; Deep learning; Similarity measurement;
   Summary generation; Hyperparameter tuning
AB Automatic legal text summarization becomes a challenging process because of unusual structure and high complexity of the documents. Existing works related to legal text summarization are available, both for general text and a few targeted in summarizing legal documents, however, they relied on massive quantity of labelled dataset by the use of hand-engineered features, leveraging on domain knowledge and focused their attention on a narrow sub-domain for increased effectiveness. To resolve this issue, this paper presents an automated optimal DL based legal text summarization (ODL-LTS) approach. Initially, the proposed ODL-LTS technique performs similarity measurement using TF-IDF and Similarity based on Rouge-L scores (SROUGE). Besides, glowworm swarm optimization (GSO) with bidirectional gated recurrent neural network (BiGRNN) model is employed for summary generation, shows the novelty of the work. The major benefit of the ODL-LTS model is that it does not depend upon handcrafted features or domain specific knowledge, nor is their application limited to specific sub-domains thus making them suitable to be extended to other domains as well. The performance validation of the ODL-LTS technique takes place using our own dataset and the experimental results demonstrates the prosminig performance with the precision of 35.54%, recall of 51.60%, and F-score of 39.06%.
C1 [Vaissnave, V.; Deepalakshmi, P.] Kalasalingam Acad Res & Educ, Dept CSE, Srivilliputhur 626126, Tamil Nadu, India.
C3 Kalasalingam Academy of Research & Education
RP Vaissnave, V (corresponding author), Kalasalingam Acad Res & Educ, Dept CSE, Srivilliputhur 626126, Tamil Nadu, India.
EM vaissnave@gmail.com; deepa.kumar@klu.ac.in
CR Al-Radaideh QA, 2018, COGN COMPUT, V10, P651, DOI 10.1007/s12559-018-9547-z
   Al-Saleh AB, 2016, ARTIF INTELL REV, V45, P203, DOI 10.1007/s10462-015-9442-x
   Alami N, 2021, MULTIMED TOOLS APPL, V80, P19567, DOI 10.1007/s11042-021-10613-9
   Anand D, 2022, J KING SAUD UNIV-COM, V34, P2141, DOI 10.1016/j.jksuci.2019.11.015
   Bhattacharya Paheli, 2021, ICAIL '21: Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law, P22, DOI 10.1145/3462757.3466092
   Bhattacharya Paheli, 2019, Advances in Information Retrieval. 41st European Conference on IR Research, ECIR 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11437), P413, DOI 10.1007/978-3-030-15712-8_27
   Cho K, ARXIV
   Feijo DDV, 2021, ARTIF INTELL LAW, P1
   Hou WH, 2016, INT J PHOTOENERGY, V2016, DOI 10.1155/2016/4910862
   Huang YX, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-021-0561-z
   Li PP, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9110635
   Liu FG, 2020, NEUROCOMPUTING, V371, P39, DOI 10.1016/j.neucom.2019.09.012
   Merchant K, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1803, DOI 10.1109/ICACCI.2018.8554831
   Moradi M, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105117
   Muthu B, 2020, ACM T ASIAN LOW-RESO
   Rahman MM, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101290
   Rani R, 2021, MULTIMED TOOLS APPL, V80, P3275, DOI 10.1007/s11042-020-09549-3
   Roul RK, 2021, SOFT COMPUT, V25, P1113, DOI 10.1007/s00500-020-05207-w
   Rush Alexander M, 2015, P C EMP METH NAT LAN
   Sheik R, 2021, 2021 IEEE 8 UTTAR PR, P1
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Soni Vishal, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2019. Advances in Intelligent Systems and Computing (AISC 1154), P629, DOI 10.1007/978-981-15-4032-5_57
   Srivastava AK, 2021, MULTIMED TOOLS APPL, V80, P11273, DOI 10.1007/s11042-020-10176-1
   Suleiman D, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/9365340
   Sun Y, 2021, MATH PROB ENG
   Sunitha C, 2016, PROCEDIA COMPUT SCI, V87, P25, DOI 10.1016/j.procs.2016.05.121
   Thomas Jency, 2022, Sentimental Analysis and Deep Learning: Proceedings of ICSADL 2021. Advances in Intelligent Systems and Computing (1408), P769, DOI 10.1007/978-981-16-5157-1_60
   Tiwari Ashima, 2019, Ambient Communications and Computer Systems. RACCCS-2018. Advances in Intelligent Systems and Computing (AISC 904), P103, DOI 10.1007/978-981-13-5934-7_10
   Wagh Rupali Sunil, 2020, Intelligent Systems, Technologies and Applications. Proceedings of ISTA 2018. Advances in Intelligent Systems and Computing (AISC 910), P53, DOI 10.1007/978-981-13-6095-4_4
   Zhang Y, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9081665
NR 30
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17175
EP 17194
DI 10.1007/s11042-022-14171-6
EA NOV 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000881546700002
DA 2024-07-18
ER

PT J
AU Yuan, WX
   Yan, B
   Li, W
   Hao, LY
   Yang, HM
AF Yuan, Wen-Xin
   Yan, Bin
   Li, Wen
   Hao, Liu-Yao
   Yang, Hong-Mei
TI Blockchain-based medical health record access control scheme with
   efficient protection mechanism and patient control
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical health records; Blockchain; Proxy re-encryption
ID SECURITY; TECHNOLOGY
AB The patient's medical health record (PMHR) has always provided a large amount of research data to medical institutions and pharmaceutical companies, etc., and has contributed to the development in medical research. However, such PMHR data contains the patient's personal privacy and should be shared under the control of the patients, not the hospital where this data is acquired. In order to protect the privacy of PMHR data while realizing efficient data sharing, this paper proposes a blockchain-based sharing and protection scheme. In this solution, the PMHR data are encrypted and stored in a cloud server, which is equipped with an access control scheme implemented as a smart contract on a blockchain. Different from previous works, in order to ensure efficient access and reduce the workload of patients, the types of users who can apply for access are limited to hospitals and pharmaceutical companies. In order to resist the potential Man-in-the-middle (MITM) attack, we have introduced an improved proxy re-encryption scheme to ensure the secrecy of PMHR data while reducing the computational complexity. The whole system is implemented using Solidity and tested on 10 nodes for function verification. Experimental result shows that the proposed system is more efficient than previous systems. Security under the MITM attack is also ensured by security analysis.
C1 [Yuan, Wen-Xin; Yan, Bin] Shandong Univ Sci & Technol, Coll Elect & Informat Engn, Qingdao 266590, Peoples R China.
   [Li, Wen] Confidential Adm Bur Ji Ning, Ji Ning, Peoples R China.
   [Hao, Liu-Yao] China Mobile Commun Res Inst, Beijing, Peoples R China.
   [Yang, Hong-Mei] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; China Mobile; Shandong
   University of Science & Technology
RP Yan, B (corresponding author), Shandong Univ Sci & Technol, Coll Elect & Informat Engn, Qingdao 266590, Peoples R China.
EM yanbinhit@hotmail.com
FU Shandong Provincial Natural Science Foundation [ZR2021MF050]; MOE
   (Ministry of Education in China) Project of Humanities and Social
   Sciences [18YJAZH110]; National Statistics Science Project [2021LY082]
FX This work was funded by Shandong Provincial Natural Science Foundation
   (No. ZR2021MF050), the MOE (Ministry of Education in China) Project of
   Humanities and Social Sciences (No. 18YJAZH110), and the National
   Statistics Science Project (No. 2021LY082). The authors have no relevant
   financial or non-financial interests to disclose.
CR Al Omar Abdullah, 2017, Security, Privacy and Anonymity in Computation, Communication and Storage, SpaCCS 2017: International Workshops. Proceedings: LNCS 10658, P534, DOI 10.1007/978-3-319-72395-2_49
   Alok N, 2021, Mach. Learn. Healthc. Appl., P187, DOI DOI 10.1002/9781119792611.CH12
   Amofa S., 2018, 2018 IEEE 20 INT C E, P1, DOI [DOI 10.1109/HEALTHCOM.2018.8531160, 10.1109/HealthCom.2018.8531160]
   [Anonymous], REMIX IDE
   Ansari A, 2018, IEEE WRK SIG PRO SYS, P7, DOI 10.1109/SiPS.2018.8598348
   Chen HS, 2019, BIOMED J SCI TECHNOL, V20, P15017, DOI DOI 10.26717/BJSTR.2019.20.003448
   Chen Y, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1121-4
   Dabral I, 2019, INT C DEEP LEARN ART, P290, DOI DOI 10.1007/978-3-030-67187-7_30
   Darbari A, 2021, CARDIOTHORAC SURG, V29, DOI 10.1186/s43057-021-00053-4
   Durao F, 2014, J SUPERCOMPUT, V68, P1321, DOI 10.1007/s11227-014-1089-x
   Eltayieb N, 2019, COMM COM INF SC, V1105, P293, DOI 10.1007/978-981-15-0818-9_19
   Esposito C, 2018, IEEE CLOUD COMPUT, V5, P31
   Eyal I, 2017, COMPUTER, V50, P38, DOI 10.1109/MC.2017.3571042
   Gan C., 2020, MULTIMED TOOLS APPL, P1, DOI DOI 10.1007/S11042-020-09322-6
   Gordon WJ, 2018, COMPUT STRUCT BIOTEC, V16, P224, DOI 10.1016/j.csbj.2018.06.003
   Guo H, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN (BLOCKCHAIN 2019), P44, DOI 10.1109/Blockchain.2019.00015
   Jin H, 2019, IEEE ACCESS, V7, P61656, DOI 10.1109/ACCESS.2019.2916503
   Karame G, 2018, IEEE SECUR PRIV, V16, P11, DOI 10.1109/MSP.2018.3111241
   Khezr S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091736
   Kumar A., 2017, 2016 IEEE Annual India Conference, P1, DOI DOI 10.1109/ICISC.2017.8068696
   Kumari Shreya, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P339, DOI 10.1007/978-3-030-67187-7_35
   Li HW, 2020, IEEE T CLOUD COMPUT, V8, P484, DOI 10.1109/TCC.2017.2769645
   Liu XJ, 2018, NEUROCOMPUTING, V274, P99, DOI 10.1016/j.neucom.2016.06.100
   Mansfield-Devine Steve, 2017, Computer Fraud & Security, V2017, P14, DOI 10.1016/S1361-3723(17)30042-8
   Mikula T, 2018, 2018 21ST EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2018), P699, DOI 10.1109/DSD.2018.00008
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Negi A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P595, DOI 10.1109/ICCCIS51004.2021.9397196
   Noh S.W., 2017, Int. J. Control Autom., V10, P133, DOI DOI 10.14257/IJCA.2017.10.11.12
   Prasad RV, 2018, 2018 4TH IEEE INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2018), P90, DOI 10.1109/CIC.2018.00023
   Tanwar S, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102407
   Wang Y, 2019, IEEE ACCESS, V7, P136704, DOI 10.1109/ACCESS.2019.2943153
   Wang Z., 2018, INT C LOGISTICS INFO, P1
   Zhu T, 2021, PUBLIC HEALTH NURS, V38, P542, DOI 10.1111/phn.12874
NR 33
TC 3
Z9 3
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16279
EP 16300
DI 10.1007/s11042-022-14023-3
EA NOV 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000879728900001
PM 36404935
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Das, S
   Biswas, SK
   Purkayastha, B
AF Das, Soumen
   Biswas, Saroj Kr
   Purkayastha, Biswajit
TI Automated Indian sign language recognition system by fusing deep and
   handcrafted feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign language; Handcrafted feature; Feature fusion; Dynamic gesture
ID RECOMMENDATION SYSTEM; FRAMEWORK
AB The deaf community faces some major challenges due to the communication gap with the hearing community. The traditional approach of employing a Sign Language (SL) interpreter is not an efficient and cost-effective solution to this problem. Thus, an automated Sign Language Recognition System (SLRS) is needed to provide an efficient and reliable solution. Existing SLRS for dynamic SL recognition utilizes the CNN-LSTM architecture, which has accomplished satisfactory results. However, spatial features extracted through Convolutional Neural Network (CNN) are insufficient for recognizing SL word that consists of identical hand orientation and multiple viewing angles. Thus, this paper proposes an SLRS named Automated Indian Sign Language Recognition System for Emergency Words (AISLRSEW) for recognizing ISL words which are frequently used in an emergency situation. The proposed AISLRSEW uses a combination of CNN and local handcrafted features to resolve the issue of identifying SL words with identical hand orientation and multiple viewing angles, which improves the recognition accuracy. The performance of the proposed AISLRSEW is evaluated with two fold cross-validation method and compared with existing models. The proposed model has achieved an average accuracy of 94.42%, which is comparatively better than existing models.
C1 [Das, Soumen; Biswas, Saroj Kr; Purkayastha, Biswajit] NIT Silchar, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Das, S (corresponding author), NIT Silchar, Silchar 788010, Assam, India.
EM soumen_rs@cse.nits.ac.in; saroj@cse.nits.az.in; biswajit@nits.ac.in
OI Das, Soumen/0000-0002-3756-186X
CR Adithya V, 2020, DATA BRIEF, V31, DOI 10.1016/j.dib.2020.106016
   Aly S, 2020, IEEE ACCESS, V8, P83199, DOI 10.1109/ACCESS.2020.2990699
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Ansari MA, 2019, 2019 IEEE C INFORM C, P1, DOI [10.1109/CICT48419.2019.9066173, DOI 10.1109/CICT48419.2019.9066173]
   Aparna C., 2020, Revised Selected Papers, V1, P126
   Athira PK, 2022, J KING SAUD UNIV-COM, V34, P771, DOI 10.1016/j.jksuci.2019.05.002
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Breland DS, 2021, IEEE SENS J, V21, P10445, DOI 10.1109/JSEN.2021.3061608
   Cai YF, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3065438
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Das S, 2022, IEEE INT C INTELL SY, P177
   Das S., 2022, ICT Systems and Sustainability, P703
   Dhingra N, 2019, INT CONF 3D VISION, P491, DOI 10.1109/3DV.2019.00061
   Dutta KK, 2017, 2017 INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN COMPUTER, ELECTRICAL, ELECTRONICS AND COMMUNICATION (CTCEEC), P333, DOI 10.1109/CTCEEC.2017.8454988
   Fang YX, 2022, MULTIMED TOOLS APPL, V81, P16863, DOI 10.1007/s11042-022-12592-x
   Gupta B, 2016, INT CONF COMP COMMUN
   Hore S, 2017, ADV INTELL SYST, V455, P553, DOI 10.1007/978-3-319-38771-0_54
   Hussain R, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13234941
   Ismail M. H., 2022, Indonesian Journal of Electrical Engineering and Computer Science, V25, P952
   Janani T., 2017, International Journal of Machine Learning and Computing, V7, P123, DOI 10.18178/ijmlc.2017.7.5.633
   Jayadeep G, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P1228, DOI [10.1109/ICICCS48265.2020.9121144, 10.1109/iciccs48265.2020.9121144]
   Kaur P, 2022, CMC-COMPUT MATER CON, V71, P35, DOI 10.32604/cmc.2022.017681
   Kumar NKS, 2020, INT J SPEECH TECHNOL, V23, P373, DOI 10.1007/s10772-020-09716-9
   Kumar P, 2017, NEUROCOMPUTING, V259, P21, DOI 10.1016/j.neucom.2016.08.132
   Li TF, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-022-02106-6
   Li YC, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115543
   LIKHAR P, 2020, IEEE ICCE
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mittal A, 2019, IEEE SENS J, V19, P7056, DOI 10.1109/JSEN.2019.2909837
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Nawaz SA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256971
   Hoang NN, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND MACHINE INTELLIGENCE (MLMI 2018), P32, DOI 10.1145/3278312.3278314
   Rastgoo R, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113794
   Rastgoo R, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113336
   Saraee E, 2020, COMPUT VIS IMAGE UND, V195, DOI 10.1016/j.cviu.2020.102949
   Shaik KB, 2015, PROCEDIA COMPUT SCI, V57, P41, DOI 10.1016/j.procs.2015.07.362
   Singh DK, 2021, PROCEDIA COMPUT SCI, V189, P76, DOI 10.1016/j.procs.2021.05.071
   Sonare Babita, 2021, 2021 2 INT C EMERGIN, P1
   Sridhar A, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1366, DOI 10.1145/3394171.3413528
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Tareen Shaharyar Ahmed Khan, 2018, 2018 International Conference on Computing, Mathematics and Engineering Technologies (iCoMET). Proceedings, DOI 10.1109/ICOMET.2018.8346440
   Taskiran M, 2018, 2018 41ST INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P258, DOI 10.1109/TSP.2018.8441304
   Venugopalan A, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115601
   Wadhawan A, 2020, NEURAL COMPUT APPL, V32, P7957, DOI 10.1007/s00521-019-04691-y
   Zhang E, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121511
NR 48
TC 9
Z9 9
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16905
EP 16927
DI 10.1007/s11042-022-14084-4
EA OCT 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000875800000002
DA 2024-07-18
ER

PT J
AU Akraam, M
   Rashid, T
   Zafar, S
AF Akraam, Muhammad
   Rashid, Tabasam
   Zafar, Sohail
TI An image encryption scheme proposed by modifying chaotic tent map using
   fuzzy numbers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption scheme; Chaos theory; Fuzzy numbers
AB Digital images play a crucial role in data communication through the internet or any mode, but their security is a formidable task. Multiple image encryption approaches were conceived, employing chaotic maps to accomplish the security level of digital images. Chaotic maps are deemed suitable for encryption techniques because of their intrinsic properties of randomness, unpredictable behavior, and ergodicity. In this paper, we modify a chaotic map utilizing a fuzzy number and confer the enhancement in chaotic behavior through a bifurcation diagram. Further, we conceive a distinctive image encryption scheme that can uniform the pixel value of a plain image during the diffusion process with the help of a pseudo-random sequence generated from modifying the map. The sum of diffused pixels is used in the discretized tent map to annihilate the correlation among contiguous pixels of the diffused image. Finally, various security and statistical analysis exemplify that our proposed encryption scheme is fast, secure, and efficient against a plethora of threats.
C1 [Akraam, Muhammad; Rashid, Tabasam; Zafar, Sohail] Univ Management & Technol, Dept Math, Lahore 54770, State, Pakistan.
C3 University of Management & Technology (UMT)
RP Rashid, T (corresponding author), Univ Management & Technol, Dept Math, Lahore 54770, State, Pakistan.
EM makraamshaheen@gmail.com; tabasam.rashid@gmail.com;
   sohailahmad04@gmail.com
RI Rashid, Tabasam/C-4855-2015
OI Rashid, Tabasam/0000-0002-8691-1088
CR Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Bashir Zia, 2016, Pacific Science Review A: Natural Science and Engineering, V18, P254, DOI 10.1016/j.psra.2016.11.003
   Bashir Z, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9120312
   Chakraverty S., 2019, Concepts Soft Comput, DOI [10.1007/978-981-13-7430-2, DOI 10.1007/978-981-13-7430-2, 10.1007/978-981-13-7430-2_3]
   Elmanfaloty RA, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/7647421
   FRIDRICH J, 1994, INT J GEN SYST, V22, P369, DOI 10.1080/03081079408935222
   Gao W, 2020, IEEE ACCESS, V8, P136736, DOI 10.1109/ACCESS.2020.3010615
   Hanss M., 2005, Applied fuzzy arithmetic, DOI [DOI 10.1007/B138914, 10.1007/b138914]
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Idrees B, 2020, MULTIMED TOOLS APPL, V79, P6135, DOI 10.1007/s11042-019-08282-w
   Jian-Qiao Sun, 2006, Communications in Nonlinear Science and Numerical Simulation, V11, P1, DOI 10.1016/j.cnsns.2004.11.001
   Kanso A, 2011, COMMUN NONLINEAR SCI, V16, P822, DOI 10.1016/j.cnsns.2010.04.039
   Li SL, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20060463
   Malik DS, 2020, MATH COMPUT SIMULAT, V178, P646, DOI 10.1016/j.matcom.2020.07.007
   Malik MGA, 2020, IEEE ACCESS, V8, P88093, DOI 10.1109/ACCESS.2020.2990170
   Masuda N, 2002, IEEE T CIRCUITS-I, V49, P28, DOI 10.1109/81.974872
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Moysis L, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22040474
   Niu Y, 2020, MULTIMED TOOLS APPL, V79, P25613, DOI 10.1007/s11042-020-09237-2
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Rehman AU, 2020, IEEE ACCESS, V8, P172275, DOI 10.1109/ACCESS.2020.3024994
   Tromer E, 2010, J CRYPTOL, V23, P37, DOI 10.1007/s00145-009-9049-y
   Wang XY, 2018, IEEE ACCESS, V6, P23733, DOI 10.1109/ACCESS.2018.2805847
   Wei ZC, 2011, PHYS LETT A, V376, P102, DOI 10.1016/j.physleta.2011.10.040
   Zhang GD, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030355
   Zhang LY, 2018, IEEE T CYBERNETICS, V48, P1163, DOI 10.1109/TCYB.2017.2682561
   Zhu SQ, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22070772
NR 28
TC 9
Z9 9
U1 5
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16861
EP 16879
DI 10.1007/s11042-022-13941-6
EA OCT 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000871318500006
DA 2024-07-18
ER

PT J
AU He, B
   Xu, SX
   Dong, YC
   Wang, SB
   Yue, JG
   Ji, LL
AF He, Bin
   Xu, Sixiong
   Dong, Yanchao
   Wang, Senbo
   Yue, Jiguang
   Ji, Lingling
TI A robust visual SLAM system for low-texture and semi-static environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Visual SLAM; Low-texture and semi-static environments; Adaptive object
   rasterization; GPU acceleration; Factor graph optimization
ID OBJECT
AB Precisely estimating a vehicle's pose in a prior map is a fundamental capability for autonomous driving. This task, however, remains challenging in low-texture and semi-static environments where the number of available features is limited and their attached objects are faced with the risk of positional change over time. To cope with the adverse conditions, we propose an innovative visual SLAM method that can correct the position of biased objects in the prior map besides estimating the accurate camera pose. Our approach is based upon the structure of independent object management to complete localization and mapping. Each object in the current frame is represented by a group of organized raster points. Owing to the adaptive pixel-based object rasterization, these raster points are more dependable to use in the visual SLAM pipeline. Assisted by the factor graph optimization, each object can be separately supervised although with multi-constraints from surroundings, resulting in robust tracking and map correction. With the benefit of GPU acceleration in data association, the execution time is sharply reduced. The proposed algorithm is validated in computer graphic render datasets.
C1 [He, Bin; Xu, Sixiong; Dong, Yanchao; Wang, Senbo; Yue, Jiguang; Ji, Lingling] Tongji Univ, Dept Control Sci & Engn, Shanghai 201804, Peoples R China.
   [He, Bin; Xu, Sixiong; Dong, Yanchao; Yue, Jiguang] Shanghai Res Inst Intelligent Autonomous Syst, Shanghai 200120, Peoples R China.
C3 Tongji University
RP Dong, YC (corresponding author), Tongji Univ, Dept Control Sci & Engn, Shanghai 201804, Peoples R China.; Dong, YC (corresponding author), Shanghai Res Inst Intelligent Autonomous Syst, Shanghai 200120, Peoples R China.
EM hebin@tongji.edu.cn; xsx1910635@tongji.edu.cn;
   dongyanchao@tongji.edu.cn; 1410472@tongji.edu.cn;
   yuejiguang@tongji.edu.cn; 1830741@tongji.edu.cn
RI he, bin/AAV-6319-2021
OI Dong, Yanchao/0000-0001-6864-8354
FU National Key R&D Program of China [2020AAA0108905]; National Natural
   Science Foundation of China [61873189, 62088101]; Shanghai Municipal
   Science and Technology Major Project [2021SHZDZX0100]; Fundamental
   Research Funds for the Central Universities
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2020AAA0108905; in part by the National Natural Science
   Foundation of China under Grant 61873189 and 62088101; in part by the
   Shanghai Municipal Science and Technology Major Project under Grant
   2021SHZDZX0100 and the Fundamental Research Funds for the Central
   Universities. We are also grateful for the efforts from our colleagues
   in Sino-German Center of Intelligent Systems.
CR Anguelov D, 2012, Arxiv, DOI arXiv:1301.0551
   Bateman S, 2020, IEEE INT C INT ROBOT, P4878, DOI 10.1109/IROS45743.2020.9341789
   Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286
   Boniardi F, 2019, ROBOT AUTON SYST, V112, P84, DOI 10.1016/j.robot.2018.11.003
   Bozkurt F, 2019, TEH VJESN, V26, P1218, DOI 10.17559/TV-20180123005000
   Campos C, 2021, IEEE T ROBOT, V37, P1874, DOI 10.1109/TRO.2021.3075644
   Camposeco F, 2015, IEEE INT CONF ROBOT, P5219, DOI 10.1109/ICRA.2015.7139926
   Cao T.T., 2010, P 2010 ACM SIGGRAPH, P83, DOI 10.1145/1730804.1730818
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596
   Dong Y, 2019, TITS, DOI [10.1109/TITS.2019.2952159https://doi.org/10.1109/TITS.2019.2952159, DOI 10.1109/TITS.2019.2952159HTTPS://DOI.ORG/10.1109/TITS.2019.2952159]
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Forster C, 2017, IEEE T ROBOT, V33, P249, DOI 10.1109/TRO.2016.2623335
   Gomez-Ojeda R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4211, DOI 10.1109/IROS.2016.7759620
   Hosseinzadeh M, 2019, IEEE INT CONF ROBOT, P7123, DOI [10.1109/ICRA.2019.8793728, 10.1109/icra.2019.8793728]
   Hosseinzadeh M, 2019, LECT NOTES COMPUT SC, V11363, P410, DOI 10.1007/978-3-030-20893-6_26
   Jablonsky N, 2018, Arxiv, DOI arXiv:1809.06977
   Jurczuk K, 2021, APPL INTELL, V51, P5683, DOI 10.1007/s10489-020-01952-5
   Kaess Michael, 2011, 2011 IEEE International Conference on Robotics and Automation, P3281
   Konolige K, 2010, INT J ROBOT RES, V29, P941, DOI 10.1177/0278364910370376
   Krajnik T., 2015, P 2015 EUROPEAN C MO, P1
   Labbé M, 2022, Arxiv, DOI arXiv:2103.03827
   Liu MY, 2010, PROC CVPR IEEE, P1696, DOI 10.1109/CVPR.2010.5539837
   Loundagin J, 2015, THESIS FACULTY CALIF
   Lu Y, 2017, IEEE INT VEH SYM, P468, DOI 10.1109/IVS.2017.7995762
   McCormac J, 2018, INT CONF 3D VISION, P32, DOI 10.1109/3DV.2018.00015
   Morris T, 2014, IEEE INT CONF ROBOT, P2765, DOI 10.1109/ICRA.2014.6907255
   Müller M, 2018, ACM TRANS PARALLEL C, V5, DOI 10.1145/3291523
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Nicholson L, 2019, IEEE ROBOT AUTOM LET, V4, P1, DOI 10.1109/LRA.2018.2866205
   Rosen DM, 2016, IEEE INT CONF ROBOT, P1063, DOI 10.1109/ICRA.2016.7487237
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178
   Schöps T, 2020, IEEE T PATTERN ANAL, V42, P2494, DOI 10.1109/TPAMI.2019.2947048
   Schreiberhuber S, 2019, IEEE INT CONF ROBOT, P140, DOI [10.1109/ICRA.2019.8793654, 10.1109/icra.2019.8793654]
   Sunday D., 2021, PRACTICAL GEOMETRY A, P80
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   Wang KX, 2019, IEEE INT CONF ROBOT, P6919, DOI [10.1109/ICRA.2019.8794101, 10.1109/icra.2019.8794101]
   Wang X, 2016, BMVC, DOI [10.5244/C.30.35, DOI 10.5244/C.30.35]
   Wang XL, 2018, COMPUT GRAPH FORUM, V37, P227, DOI 10.1111/cgf.13356
   Xu BB, 2019, IEEE INT CONF ROBOT, P5231, DOI [10.1109/icra.2019.8794371, 10.1109/ICRA.2019.8794371]
   Xu ZW, 2021, VIS COMPUT IND BIOME, V4, DOI 10.1186/s42492-021-00086-w
   Yang SC, 2019, IEEE T ROBOT, V35, P925, DOI 10.1109/TRO.2019.2909168
   Yang SC, 2019, IEEE ROBOT AUTOM LET, V4, P3145, DOI 10.1109/LRA.2019.2924848
   Zhang XY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173795
   Zhou DX, 2020, LECT NOTES ARTIF INT, V12595, P415, DOI 10.1007/978-3-030-66645-3_35
   Zhou HZ, 2015, IEEE T VEH TECHNOL, V64, P1364, DOI 10.1109/TVT.2015.2388780
NR 45
TC 0
Z9 0
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 OCT 24
PY 2022
DI 10.1007/s11042-022-14013-5
EA OCT 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5M8AQ
UT WOS:000871318500004
DA 2024-07-18
ER

PT J
AU Halder, A
   Bhattacharya, P
   Sarkar, A
   Choudhuri, R
AF Halder, Amiya
   Bhattacharya, Pritam
   Sarkar, Apurba
   Choudhuri, Rudrajit
TI A novel statistical golden ratio based adaptive high density impulse
   noise removal algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Golden ratio; Left alpha trimmed average filter; Fine tuning; PSNR
ID PEPPER NOISE; MEDIAN FILTER; SALT
AB Enhancing the quality of images by removing impulse noise is an important preprocessing step while working with images. In this article, a novel and robust algorithm for removal of salt and pepper noise (SAPN) based on statistical golden ratio formula is presented. The proposed method uses a two stage filtering technique to enhance the image quality through removal of SAPN. After detecting the noisy pixels in the image, an adaptive golden ratio based interpolation filtering technique is applied as the Phase-I filter to regenerate the image using the structure and available details of the input image. The image thus obtained in Phase-I is fed to Phase-II where left alpha trimmed average filter is applied to further enhance the image using local features. For performance evaluation, the algorithm is tested on images with corruption levels as high as 99%, and the results obtained is very satisfactory that highlights better performance of the algorithm when compared to the state of the art methods for the entire range of noise density levels.
C1 [Halder, Amiya; Bhattacharya, Pritam; Choudhuri, Rudrajit] St Thomas Coll Engn & Technol, Dept CSE, 4-D H Rd, Kolkata, India.
   [Sarkar, Apurba] Indian Inst Engn Sci & Technol, Dept CST, Howrah 711103, W Bengal, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST)
RP Halder, A (corresponding author), St Thomas Coll Engn & Technol, Dept CSE, 4-D H Rd, Kolkata, India.
EM amiya.halder77@gmail.com; prb2794@gmail.com; as.besu@gmail.com;
   rudrajit1729@gmail.com
OI Bhattacharya, Pritam/0000-0002-5306-6092
CR Ahmed F, 2014, IEEE T FUZZY SYST, V22, P1352, DOI 10.1109/TFUZZ.2013.2286634
   Arora S, 2020, PATTERN RECOGN LETT, V139, P1, DOI 10.1016/j.patrec.2018.06.002
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chen T, 1999, IEEE T IMAGE PROCESS, V8, P1834, DOI 10.1109/83.806630
   Christo MS, 2020, MULTIMED TOOLS APPL, V79, P415, DOI 10.1007/s11042-019-08124-9
   Dharmarajan R, 2010, AEU-INT J ELECTRON C, V64, P1114, DOI 10.1016/j.aeue.2009.12.001
   Enginoglu S, 2019, MULTIMED TOOLS APPL, V78, P35401, DOI 10.1007/s11042-019-08110-1
   Garg B, 2020, INT J AD HOC UBIQ CO, V35, P84, DOI 10.1504/IJAHUC.2020.109795
   Goel N, 2020, MULTIMED TOOLS APPL, V79, P19739, DOI 10.1007/s11042-020-08687-y
   Gonzalez R.C., 2002, Digital Image Processing, V2nd
   González-Hidalgo M, 2018, APPL SOFT COMPUT, V63, P167, DOI 10.1016/j.asoc.2017.11.030
   Karthik B, 2021, J AMB INTEL HUM COMP, V12, P3901, DOI 10.1007/s12652-020-01737-1
   Liu XH, 2017, SIGNAL PROCESS, V135, P239, DOI 10.1016/j.sigpro.2017.01.003
   Luo WB, 2006, IEEE T CONSUM ELECTR, V52, P523, DOI 10.1109/TCE.2006.1649674
   Mayer, 2009, WATERLOO IMAGE REPOS
   Roy A, 2020, MULTIMED TOOLS APPL, V79, P34851, DOI 10.1007/s11042-020-09107-x
   Sharma N, 2021, MULTIMED TOOLS APPL, V80, P26531, DOI 10.1007/s11042-021-10958-1
   Sheela CJJ, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101657
   Singh V, 2018, IEEE T FUZZY SYST, V26, P3170, DOI 10.1109/TFUZZ.2018.2805289
   Smolka B, 2003, REAL-TIME IMAGING, V9, P261, DOI 10.1016/j.rti.2003.09.015
   Thanh DNH, 2020, MULTIMED TOOLS APPL, V79, P21013, DOI 10.1007/s11042-020-08887-6
   Toh KKV, 2010, IEEE SIGNAL PROC LET, V17, P281, DOI 10.1109/LSP.2009.2038769
   Varatharajan R, 2018, COMPUT ELECTR ENG, V70, P447, DOI 10.1016/j.compeleceng.2017.05.035
   Wang Y, 2017, J STAT COMPUT SIM, V87, P2538, DOI 10.1080/00949655.2017.1340474
   Wang Y, 2016, IEEE SIGNAL PROC LET, V23, P1582, DOI 10.1109/LSP.2016.2607785
   Weber Allan G, 2006, The USC-SIPI Image Database
   Yildirim M, 2021, ANALOG INTEGR CIRC S, V107, P195, DOI 10.1007/s10470-021-01820-3
   Zhang PX, 2014, IEEE SIGNAL PROC LET, V21, P1280, DOI 10.1109/LSP.2014.2333012
   Zhang XQ, 2015, AEU-INT J ELECTRON C, V69, P307, DOI 10.1016/j.aeue.2014.09.018
NR 29
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19155
EP 19188
DI 10.1007/s11042-022-14015-3
EA OCT 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000867602700004
DA 2024-07-18
ER

PT J
AU Jaisakthi, SM
   Mirunalini, P
   Aravindan, C
   Appavu, R
AF Jaisakthi, S. M.
   Mirunalini, P.
   Aravindan, Chandrabose
   Appavu, Rajagopal
TI Classification of skin cancer from dermoscopic images using deep neural
   network architectures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EfficientNet; Deep convolutional neural network (DCNN); Melanoma
   classification; Dermoscopic images
ID MALIGNANT-MELANOMA
AB A powerful medical decision support system for classifying skin lesions from dermoscopic images is an important tool to prognosis of skin cancer. In the recent years, Deep Convolutional Neural Network (DCNN) have made a significant advancement in detecting skin cancer types from dermoscopic images, in-spite of its fine grained variability in its appearance. The main objective of this research work is to develop a DCNN based model to automatically classify skin cancer types into melanoma and non-melanoma with high accuracy. The datasets used in this work were obtained from the popular challenges ISIC-2019 and ISIC-2020, which have different image resolutions and class imbalance problems. To address these two problems and to achieve high performance in classification we have used EfficientNet architecture based on transfer learning techniques, which learns more complex and fine grained patterns from lesion images by automatically scaling depth, width and resolution of the network. We have augmented our dataset to overcome the class imbalance problem and also used metadata information to improve the classification results. Further to improve the efficiency of the EfficientNet we have used ranger optimizer which considerably reduces the hyper parameter tuning, which is required to achieve state-of-the-art results. We have conducted several experiments using different transferring models and our results proved that EfficientNet variants outperformed in the skin lesion classification tasks when compared with other architectures. The performance of the proposed system was evaluated using Area under the ROC curve (AUC - ROC) and obtained the score of 0.9681 by optimal fine tuning of EfficientNet-B6 with ranger optimizer.
C1 [Jaisakthi, S. M.] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai Campus, Chennai, Tamil Nadu, India.
   [Mirunalini, P.; Aravindan, Chandrabose] Sri Sivasubramaniya Nadar Coll Engn, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Appavu, Rajagopal] Univ South Florida Hlth Tampa, Taneja Coll Pharm, Tampa, FL USA.
C3 Vellore Institute of Technology (VIT); VIT Chennai; SSN College of
   Engineering
RP Jaisakthi, SM (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Chennai Campus, Chennai, Tamil Nadu, India.
EM jaisakthi.murugaiyan@vit.ac.in; miruna@ssn.edu.in;
   aravindanc@ssn.edu.in; rajagopal@usf.edu
RI P, Mirunalini/CAA-6407-2022; S M, Jaisakthi/C-3796-2019
OI S M, Jaisakthi/0000-0001-9136-1300
FU Vellore Institute of Technology, Chennai, India; Sri Sivasubramaniya
   Nadar College of Engineering, Chennai, India
FX Supported by Vellore Institute of Technology, Chennai, India, and Sri
   Sivasubramaniya Nadar College of Engineering, Chennai, India
CR A Ameri, 2020, J Biomed Phys Eng, V10, P801, DOI 10.31661/jbpe.v0i0.2004-1107
   Alhichri H, 2021, IEEE ACCESS, V9, P14078, DOI 10.1109/ACCESS.2021.3051085
   Almaraz-Damian JA, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22040484
   Atila Ü, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101182
   Bakheet S, 2017, COMPUTATION, V5, DOI 10.3390/computation5010004
   Blanc-Talon J, 2020, ADV CONCEPTS INTELLI, P1294
   Chaturvedi SS, 2020, MULTIMED TOOLS APPL, V79, P28477, DOI 10.1007/s11042-020-09388-2
   Codella NCF, 2018, SKIN LES AN MEL DET
   Combalia Marc, 2019, ARXIV190802288
   Duong LT, 2020, COMPUT ELECTRON AGR, V171, DOI 10.1016/j.compag.2020.105326
   Ge Z, 2017, I S BIOMED IMAGING, P986, DOI 10.1109/ISBI.2017.7950681
   Gessert N, 2020, METHODSX, V7, DOI 10.1016/j.mex.2020.100864
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2016, arXiv
   Acosta MFJ, 2021, BMC MED IMAGING, V21, DOI 10.1186/s12880-020-00534-8
   Kasmi R, 2016, IET IMAGE PROCESS, V10, P448, DOI 10.1049/iet-ipr.2015.0385
   Ke GL, 2017, ADV NEUR IN, V30
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034
   Kingma D. P., 2014, arXiv
   Lee Y.-T., 2018, arXiv
   Li S, 2019, LEARNING RECONSTRUCT
   Liu L., 2019, arXiv
   Mahbod A, 2019, INT CONF ACOUST SPEE, P1229, DOI [10.1109/ICASSP.2019.8683352, 10.1109/icassp.2019.8683352]
   Mahbod A, 2019, COMPUT MED IMAG GRAP, V71, P19, DOI 10.1016/j.compmedimag.2018.10.007
   Marques G, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106691
   Moldovanu S, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11060936
   Moura N, 2019, MULTIMED TOOLS APPL, V78, P6869, DOI 10.1007/s11042-018-6404-8
   Munadi K, 2020, IEEE ACCESS, V8, P217897, DOI 10.1109/ACCESS.2020.3041867
   Naeem A, 2020, IEEE ACCESS, V8, P110575, DOI 10.1109/ACCESS.2020.3001507
   Rotemberg V, 2020, PATIENT CENTRIC DATA
   Salih O, 2020, IMAGE ANAL STEREOL, V39, P169, DOI 10.5566/ias.2397
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan M., 2019, arXiv
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Vestergaard ME, 2008, BRIT J DERMATOL, V159, P669, DOI 10.1111/j.1365-2133.2008.08713.x
   Wang JH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS AND COMPUTER ENGINEERING (ICCECE), P666, DOI 10.1109/ICCECE51280.2021.9342158
   Wang J, 2020, IEEE ACCESS, V8, P212499, DOI 10.1109/ACCESS.2020.3040275
   Yin XQ, 2020, COMPUT ELECTRON AGR, V177, DOI 10.1016/j.compag.2020.105707
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Zhang M., 2019, ARXIV
   Zhang P, 2020, COMPUT ELECTRON AGR, V176, DOI 10.1016/j.compag.2020.105652
NR 44
TC 23
Z9 23
U1 10
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15763
EP 15778
DI 10.1007/s11042-022-13847-3
EA OCT 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000866314400004
PM 36250184
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Pradhan, A
   Pradhan, MP
AF Pradhan, Ashis
   Pradhan, Mohan P.
TI A modified Bezier curve technique for automatic reconstruction of broken
   contour lines extracted from a poor-quality topographic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digitization; Topographic map; Broken contour lines; Euclidean distance;
   Contour reconnection; Bezier curve
ID COLOR; MODEL
AB The various essential morphological land features are represented in a scale-governed map called a topographic sheet. One of the crucial features presented in the topographic sheet often used in Geographical Information System (GIS) based applications is contour lines. Contour lines are non-intersecting lines formed after joining points which are at the same elevation from a given reference point. To elaborate on contour lines, these lines may be of different types, dictated by various geographical landforms such as enclosures (such as lakes, glaciers, etc.), linear features (such as drainage networks, geomorphological landscape. Etc.), islands, eyes and many more. A suitable purpose-specific digitization process is to be implemented for extracting the identified features for use in geographical applications. It can be achieved either through a traditional manual digitization approach or a computer-aided semi-automatic or fully-automatic digitization process may be conceived leveraging advancement in technological support. The manual approach demands considerable effort, execution time, digitization capabilities and attention making it relatively ineffective and inefficient. On the contrary, automatic digitization calls for greater reliance on color segmentation techniques which if implemented incorrectly or imprecisely, the quality of the result will be tremendously compromised. One of the pertinent problems often observed in the segmented image is the loss of continuity in contour lines. This may be circumstantially due to overlapping features, improper segmentation, incomplete information content, incomplete information extraction and the presence of additional details like elevation values. The solution to the identified problem should be motivated toward designing an integrity-preserving reconnection mechanism that is apt, computationally simple and effective. Therefore, this research initiative is motivated towards the conception and implementation of a technique for reconnection of broken contour lines to facilitate continuity of contour lines relying on concepts such as the Sign of Gradient (SG), Euclidean Distance (ED) and modified Bezier Curve (BC) drawing technique.
C1 [Pradhan, Ashis] SMU, Dept CSE, Sikkim Manipal Inst Technol, Gangtok, Sikkim, India.
   [Pradhan, Mohan P.] Sikkim Univ, Dept Comp Applicat, Gangtok, Sikkim, India.
C3 Sikkim Manipal Institute of Technology; Sikkim Manipal University;
   Sikkim University
RP Pradhan, A (corresponding author), SMU, Dept CSE, Sikkim Manipal Inst Technol, Gangtok, Sikkim, India.
EM ashis.p@smit.smu.edu.in; mppradhan@cus.ac.in
OI Pradhan, Ashis/0000-0002-9111-6257
CR Amenta N, 1998, GRAPH MODEL IM PROC, V60, P125, DOI 10.1006/gmip.1998.0465
   Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   [Anonymous], India and Pakistan AMS Topographic Maps - Perry-Castaneda Map Collection - UT Library Online
   Bhuiyan A.-A., 1997, Memoirs of the Faculty of Engineering, Osaka City University, V38, P175
   Chen LJ, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON SYSTEM RELIABILITY AND SAFETY (ICSRS), P1, DOI [10.1109/ICSRS.2018.8688869, 10.1109/ICSRS.2018.00009]
   Dmitriev N, 2019, AIP CONF PROC, V2172, DOI 10.1063/1.5133563
   Du JY, 2004, INT GEOSCI REMOTE SE, P2886
   Ganpatrao NG, 2014, SADHANA-ACAD P ENG S, V39, P1095, DOI 10.1007/s12046-014-0270-5
   Gul S., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P593, DOI 10.1109/DICTA.2010.105
   Hancer E, 2014, PROC IEEE INT SYMP, P930, DOI 10.1109/ISIE.2014.6864736
   Hu G, 2018, ADV ENG SOFTW, V125, P27, DOI 10.1016/j.advengsoft.2018.09.002
   Joy KennethI., 1999, Breshenham's Algorithm
   Khotanzad A, 2003, IEEE T PATTERN ANAL, V25, P18, DOI 10.1109/TPAMI.2003.1159943
   Li CM, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8010008
   Li HL, 2018, IEEE ACCESS, V6, P25363, DOI 10.1109/ACCESS.2018.2823501
   Mansourifar H., 2011, Proceedings of the 2011 Eighth International Conference on Computer Graphics, Imaging and Visualization (CGIV 2011), P65, DOI 10.1109/CGIV.2011.23
   Mansourifar H., 2011, Proceedings of the 2011 Eighth International Conference on Computer Graphics, Imaging and Visualization (CGIV 2011), P59, DOI 10.1109/CGIV.2011.33
   Mansourifar H, 2011, 2011 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P152, DOI 10.1109/CW.2011.26
   Oka S, 2012, AUTOMAT CONSTR, V22, P192, DOI 10.1016/j.autcon.2011.06.017
   Parker J.R., 1997, Algorithms for Image Processing and Computer Vision
   Pouderoux J, 2007, PROC INT CONF DOC, P779
   Pradhan MP., 2013, INT J COMPUT APPL, V65, P37
   Samet R, 2010, APPL COMPUT MATH-BAK, V9, P116
   San LM, 2004, I C COMP GRAPH IM VI, P187
   Sánchez-Reyes J, 2020, J TAIBAH UNIV SCI, V14, P849, DOI 10.1080/16583655.2020.1780057
   Soycan A, 2009, ARAB J SCI ENG, V34, P121
   Spinello S, 2004, J WSCG, V12, P1
   Wang F., 2018, PROC INT CARTOGR ASS, V1, P121, DOI [10.5194/ica-proc-1-121-2018, DOI 10.5194/ICA-PROC-1-121-2018]
   Xin D., 2006, J INFORM COMPUTING S, V1, P275
   Xu B, IDENTIFICATION CONTO
   Yadav S, 2016, INT GEOSCI REMOTE SE, P6036, DOI 10.1109/IGARSS.2016.7730577
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
NR 32
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18299
EP 18325
DI 10.1007/s11042-022-13912-x
EA OCT 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000863811300001
DA 2024-07-18
ER

PT J
AU Aravinth, J
   Veni, S
   Dheepika, R
   Polamuri, VG
   Poornima, AR
   Sandeep, KS
AF Aravinth, J.
   Veni, S.
   Dheepika, R.
   Polamuri, Venkat Gopinath
   Poornima, A. R.
   Sandeep, K. Sai
TI Optimal hyperspectral band selection using robust multi-verse
   optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral bands; K means; multi verse optimizer; metaheuristics;
   support vector machine
ID CLASSIFICATION; IMAGES
AB Hyperspectral Images (HSI) generally have high spectral resolution when compared with multispectral and panchromatic images. On the other hand, hyperspectral images are redundant in nature and to prevent this band selection technique is adopted which is efficient to decrease the hyperspectral data size. Multi-Verse Optimizer (MVO) is a novel nature-inspired metaheuristic algorithm, and it is based on the theory of multiverse in astrophysics. MVO is used to select optimal features and the effectiveness is proved through selective bands verification by classification algorithms such as: Random Forest (RF), and Support Vector Machine (SVM). It was observed from the literature that the existing works on hyperspectral band selection lacks in convergence rate and optimal fitness value. The proposed work aims to develop an efficient algorithm for optimal band selection for hyperspectral image data and it can be further used for agricultural applications. As a pilot study, the MVO algorithm is applied on two available hyperspectral image datasets such as: Pavia university and Indian Pines. To verify the results, MVO is compared with Particle Swarm Optimization (PSO) and Hybrid PSO-MVO (HPSO-MVO) and Sparrow Search Algorithm (SSA). Fusion of PSO-MVO algorithm was attempted in this work and the effectiveness of hyperspectral band selection was found to be improved in terms of its execution time and convergence analysis. From the experimental results it was observed that the proposed algorithm gives the average accuracy of 92.5% for MVO, 90% for PSO and 91% for HPSO -MVO respectively using SVM. In addition, RF classifier is also performed which gives the average accuracy of 89.5% for MVO, 87.5% for PSO, 89% for HPSO - MVO and 88% for SSA respectively.
C1 [Aravinth, J.; Veni, S.; Dheepika, R.; Polamuri, Venkat Gopinath; Poornima, A. R.; Sandeep, K. Sai] Amrita Vishwa Vidyapeetham, Dept Elect & Commun Engn, Amrita Sch Engn, Coimbatore, Tamil Nadu, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Coimbatore
RP Aravinth, J; Dheepika, R (corresponding author), Amrita Vishwa Vidyapeetham, Dept Elect & Commun Engn, Amrita Sch Engn, Coimbatore, Tamil Nadu, India.
EM cb.en.u4ece17009@cb.students.amrita.edu
CR Alturki A., 2017, COMPUTER SCI INFORM
   Anand R, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13071255
   Aravind Jukanti, 2017, Polyphenol Oxidases (PPOs) in Plants, P1, DOI 10.1007/978-981-10-5747-2_1
   Archibald R, 2007, IEEE GEOSCI REMOTE S, V4, P674, DOI 10.1109/LGRS.2007.905116
   Author John D, 2004, Q REV BIOL, V79, P405, DOI [10.1086/428147, DOI 10.1086/428147]
   Borzov SM, 2018, OPTOELECTRON INSTRUM, V54, P582, DOI [10.3103/S8756699018060079, 10.15372/AUT20180607]
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chang YL, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.084798
   Clerici N, 2012, REMOTE SENS-BASEL, V4, P1781, DOI 10.3390/rs4061781
   Cristianini N., 2000, An Introduction to Support Vector Machines and Other Kernel-Based Learning Methods, DOI [10.1017/CBO9780511801389, DOI 10.1017/CBO9780511801389]
   DAVIES PCW, 1978, REP PROG PHYS, V41, P1313, DOI 10.1088/0034-4885/41/8/004
   EARDLEY DM, 1974, PHYS REV LETT, V33, P442, DOI 10.1103/PhysRevLett.33.442
   Faris H, 2018, NEURAL COMPUT APPL, V30, P2355, DOI 10.1007/s00521-016-2818-2
   Feng L, 2016, SOFT COMPUT, V20, P4685, DOI 10.1007/s00500-014-1508-1
   George JE, 2018, 2018 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET)
   Guth AH, 2007, J PHYS A-MATH THEOR, V40, P6811, DOI 10.1088/1751-8113/40/25/S25
   Jangir P, 2017, ENG SCI TECHNOL, V20, P570, DOI 10.1016/j.jestch.2016.10.007
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khoury J, 2002, PHYS REV D, V65, DOI 10.1103/PhysRevD.65.086007
   Landgrebe D, 2002, IEEE SIGNAL PROC MAG, V19, P17, DOI 10.1109/79.974718
   Liu DS, 2007, IEEE T SYST MAN CY B, V37, P42, DOI 10.1109/TSMCB.2006.883270
   Ma AD, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020194
   Main-Knorn M, 2011, REMOTE SENS-BASEL, V3, P1427, DOI 10.3390/rs3071427
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   MORRIS MS, 1988, AM J PHYS, V56, P395, DOI 10.1119/1.15620
   Moughal TA, 2013, J PHYS CONF SER, V439, DOI 10.1088/1742-6596/439/1/012042
   Prabhakar TVN, 2016, ADV INTELL SYST, V384, P393, DOI 10.1007/978-3-319-23036-8_34
   Reshma S, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2272, DOI 10.1109/WiSPNET.2017.8300164
   Rodriguez-Galiano VF, 2012, ISPRS J PHOTOGRAMM, V67, P93, DOI 10.1016/j.isprsjprs.2011.11.002
   Sawant SS, 2019, WORK HYPERSP IMAG, DOI 10.1109/whispers.2019.8920950
   Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069
   Sheng Ding, 2012, International Innovative Computing and Applications, V4, P233
   Steinhardt PJ, 2005, NEW ASTRON REV, V49, P43, DOI 10.1016/j.newar.2005.01.003
   Su HJ, 2014, IEEE J-STARS, V7, P2659, DOI 10.1109/JSTARS.2014.2312539
   [汤可宗 Tang Kezong], 2013, [计算机应用, Journal of Computer Applications], V33, P3372
   Vapnik V, 2000, The Nature of Statistical Learning Theory, DOI [DOI 10.1007/978-1-4757-3264-1, DOI 10.1007/978-1-4757-2440-0]
   Xu MX, 2018, J SIGNAL PROCESS SYS, V90, P1269, DOI 10.1007/s11265-018-1348-9
   Zhang MY, 2017, IEEE GEOSCI REMOTE S, V14, P773, DOI 10.1109/LGRS.2017.2681118
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
   Zhong ZS, 2015, IEEE GEOSCI REMOTE S, V12, P1028, DOI 10.1109/LGRS.2014.2375188
NR 41
TC 1
Z9 1
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14663
EP 14687
DI 10.1007/s11042-022-13956-z
EA OCT 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000863553600007
DA 2024-07-18
ER

PT J
AU Biswas, P
   Samanta, T
   Sanyal, J
AF Biswas, Priyajit
   Samanta, Tuhina
   Sanyal, Judhajit
TI Intrusion detection using graph neural network and Lyapunov optimization
   in wireless sensor network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WSN; Intrusion detection; Graph neural network; Lyapunov optimization;
   Deep neural network
ID DETECTION SYSTEM
AB Sensor nodes deployed in a remote location are vulnerable to various attack. An intruder can easily capture and tamper with sensor nodes deployed in a remote location. As a result, intrusion detection is crucial task in the field of wireless sensor network. In this work, we propose an intrusion detection approach for WSN. In our method,we are using Graph Neural Network and Lyapunov optimization. In the training phase, we train graph data using GNN. We are using Lyapunov optimization to adjust weights of the synapses connecting two neurons to an optimum value. Here we used AWID datasets to train and test GNN. Lyapunov optimization is used to compute loss in GNN and adjust weight accordingly to minimize loss. We show test results of our method using performance matrices, namely, Accuracy, Sensitivity, Precision, F-1 Score. Comparison with existing work showed that our method gives better detection accuracy.
C1 [Biswas, Priyajit; Samanta, Tuhina; Sanyal, Judhajit] Indian Inst Engn Sci & Technol, Dept Informat Technol, Howrah 711103, W Bengal, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST)
RP Biswas, P (corresponding author), Indian Inst Engn Sci & Technol, Dept Informat Technol, Howrah 711103, W Bengal, India.
EM priyajit.biswas@yahoo.com; t_samanta@it.iiests.ac.in;
   sjudhajit@gmail.com
RI Sanyal, Judhajit/JMR-3714-2023
OI Biswas, Priyajit/0000-0002-6933-1858; Sanyal,
   Judhajit/0000-0002-2782-0047
CR Elsaid SA, 2020, SOFT COMPUT, V24, P12553, DOI 10.1007/s00500-020-04695-0
   Gavel S, 2021, ISA T, V111, P180, DOI 10.1016/j.isatra.2020.11.016
   Gu J, 2021, COMPUT SECUR, V103, DOI 10.1016/j.cose.2020.102158
   Kaja N, 2019, APPL INTELL, V49, P3235, DOI 10.1007/s10489-019-01436-1
   Kasongo SM, 2020, COMPUT SECUR, V92, DOI 10.1016/j.cose.2020.101752
   Kipf TN, 2016, ARXIV
   Kolias C, 2016, IEEE COMMUN SURV TUT, V18, P184, DOI 10.1109/COMST.2015.2402161
   Kumar NMS, 2016, WIRELESS PERS COMMUN, V87, P431, DOI 10.1007/s11277-015-3070-2
   Liu ZQ, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2077, DOI 10.1145/3269206.3272010
   Mao YY, 2015, IEEE J SEL AREA COMM, V33, P2463, DOI 10.1109/JSAC.2015.2481209
   Neely M. J., 2010, Synthesis Lectures on Communication Networks, V3, P1
   Rahman MA, 2021, MULTIMED TOOLS APPL, V80, P31381, DOI 10.1007/s11042-021-10567-y
   Safaldin M, 2021, J AMB INTEL HUM COMP, V12, P1559, DOI 10.1007/s12652-020-02228-z
   Shukla AK, 2021, NEURAL COMPUT APPL, V33, P7541, DOI 10.1007/s00521-020-05500-7
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wazid M, 2016, WIRELESS PERS COMMUN, V90, P1971, DOI 10.1007/s11277-016-3433-3
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890
   You JX, 2018, ADV NEUR IN, V31
   Yu H, 2018, IEEE ACM T NETWORK, V26, P1605, DOI 10.1109/TNET.2018.2844284
   Zheng L, 2014, IEEE T SMART GRID, V5, P2075, DOI 10.1109/TSG.2014.2313347
   Zhou YY, 2020, COMPUT NETW, V174, DOI 10.1016/j.comnet.2020.107247
   Zitnik M, 2017, BIOINFORMATICS, V33, pI190, DOI 10.1093/bioinformatics/btx252
NR 24
TC 4
Z9 4
U1 7
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 14123
EP 14134
DI 10.1007/s11042-022-13992-9
EA SEP 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000862219700005
DA 2024-07-18
ER

PT J
AU Yao, TT
   Liang, Y
   Zhang, LL
   Xia, N
   Hu, Q
AF Yao, Tingting
   Liang, Yue
   Zhang, Lelin
   Xia, Na
   Hu, Qing
TI Single image dehazing via cycle-consistent adversarial networks with a
   multi-scale hybrid encoder-decoder and global correlation loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image dehazing; Cycle-consistent adversarial networks; Hybrid
   encoder-decoder; Global correlation loss
ID MODEL
AB Deep learning technologies have been reshaping the research of image dehazing in recent years with superior performance. Due to the difficulty to obtain the real hazy and corresponding clear image pairs in the wild, most of the existed deep learning based methods utilize synthetic datasets for model training. As a result, the performance and robustness of those methods are compromised under the real-world complex scenarios. In this paper, we propose a novel image dehazing method for unpaired data via cycle-consistent adversarial networks with a multi-scale hybrid encoder-decoder and global correlation loss. The requirement of paired training data is eliminated by combining two generators and discriminators into a cycle-consistent adversarial network. Moreover, to further improve the feature representation capability of the network for degraded images, a multi-scale hybrid encoder-decoder structure is introduced into the generators and multiple residual and dense blocks are constructed. Furthermore, to preserve more details of color and structure in generated dehazed images, a global correlation loss function is proposed. The task-specific haze-line prior is reformulated in the form of color loss constraint and incorporates with adversarial loss, cycle consistency loss, identity mapping loss, and perceptual consistency loss into a unified framework. Comprehensive qualitative and quantitative experiments on both synthetic and real-world datasets demonstrate the favourable dehazing results of the proposed method compared with a number of state-of-the-art methods. The code will be made available on Github.
C1 [Yao, Tingting; Liang, Yue; Hu, Qing] Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian, Peoples R China.
   [Zhang, Lelin] Univ Technol Sydney, Data Sci Inst, Sydney, NSW, Australia.
   [Xia, Na] Hefei Univ Technol, Sch Comp & Informat, Hefei, Peoples R China.
C3 Dalian Maritime University; University of Technology Sydney; Hefei
   University of Technology
RP Yao, TT (corresponding author), Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian, Peoples R China.
EM ytt1030@dlmu.edu.cn
RI HU, Qing/GWQ-8711-2022
FU National Natural Science Foundation of China [62001078]; Fundamental
   Research Funds for the Central Universities [3132020208]
FX This work was partially supported by National Natural Science Foundation
   of China (No. 62001078) and Fundamental Research Funds for the Central
   Universities (No. 3132020208). We would also like to thank Yuan Gao for
   carrying out more comparative experiments in the process of revision.
CR Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen YP, 2017, ADV NEUR IN, V30
   Dudhane A, 2020, IEEE T IMAGE PROCESS, V29, P628, DOI 10.1109/TIP.2019.2934360
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Gao Y, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103868
   Guo F, 2020, NEUROCOMPUTING, V378, P9, DOI 10.1016/j.neucom.2019.09.094
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He LY, 2019, NEUROCOMPUTING, V341, P212, DOI 10.1016/j.neucom.2019.01.001
   Hu HM, 2019, IEEE T IMAGE PROCESS, V28, P2882, DOI 10.1109/TIP.2019.2891901
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Ju MY, 2020, IEEE T IMAGE PROCESS, V29, P3104, DOI 10.1109/TIP.2019.2957852
   Khan H, 2020, NEUROCOMPUTING, V381, P141, DOI 10.1016/j.neucom.2019.10.005
   Kumar A, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103122
   Kumar M, 2019, MULTIMED TOOLS APPL, V78, P9791, DOI 10.1007/s11042-018-6599-8
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Li YN, 2018, NEUROCOMPUTING, V283, P73, DOI 10.1016/j.neucom.2017.12.046
   Li ZW, 2015, PROC CVPR IEEE, P4988, DOI 10.1109/CVPR.2015.7299133
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mehta A, 2020, IEEE COMPUT SOC CONF, P846, DOI 10.1109/CVPRW50498.2020.00114
   Park J, 2020, IEEE T IMAGE PROCESS, V29, P4721, DOI 10.1109/TIP.2020.2975986
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Shen LH, 2019, IEEE T MULTIMEDIA, V21, P1093, DOI 10.1109/TMM.2018.2871955
   Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241
   Sim H, 2018, IEEE COMPUT SOC CONF, P1025, DOI 10.1109/CVPRW.2018.00136
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohn K, 2015, ADV NEUR IN, V28
   Wang JB, 2018, IEEE T CIRC SYST VID, V28, P2190, DOI 10.1109/TCSVT.2017.2728822
   Xiao JS, 2020, NEUROCOMPUTING, V389, P108, DOI 10.1016/j.neucom.2020.01.007
   Yang B, 2021, MULTIMED TOOLS APPL, V80, P16125, DOI 10.1007/s11042-019-07896-4
   Yang XT, 2018, AAAI CONF ARTIF INTE, P7485
   Yao LP, 2021, MULTIMED TOOLS APPL, V80, P3425, DOI 10.1007/s11042-020-09812-7
   Yin SB, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107255
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhao D, 2019, SIGNAL PROCESS-IMAGE, V74, P253, DOI 10.1016/j.image.2019.02.004
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 44
TC 1
Z9 1
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12279
EP 12301
DI 10.1007/s11042-022-13772-5
EA SEP 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000857685800004
DA 2024-07-18
ER

PT J
AU Hazra, S
   Mandal, S
   Saha, B
   Khatua, S
AF Hazra, Soma
   Mandal, Shaurjya
   Saha, Banani
   Khatua, Sunirmal
TI UMTSS: a unifocal motion tracking surveillance system for multi-object
   tracking in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surveillance system; Multiple object detection; FRI; Tracking; Unifocal
   features; UFOT-KLT
AB Multiple object detection and tracking play a very crucial role in solving several elementary problems in real-time surveillance video analysis and computer vision. However, it is a challenging problem because real-time surveillance videos are typically affected by a variety of adverse environmental effects. In this work, we propose a novel surveillance framework, called a unifocal motion tracking surveillance system (UMTSS), for multi-object tracking in real-time videos. The proposed UMTSS combines two significant steps. First, a Faster-RCNN with inception-v2 model is employed here to detect multi-objects efficiently in each video frame. Then, a unifocal feature-based KLT (Kanade-Lucas-Tomasi) method is proposed for tracking objects across the video frames based on region proposals generated by the object detector in the previous phase. Also, we have proposed a new tracking parameter, called dynamic tracking accuracy (DTA), to quantify the performance of the tracking algorithms. The performance of our UMTSS has been evaluated on five standard crowd video databases, namely CrowdHuman, PETS, UCSD, AGORASET and CRCV, and compared with state-of-the-art methods in terms of different qualitative and quantitative measures. It has been observed that our UMTSS outperforms the state-of-the-art methods.
C1 [Hazra, Soma; Mandal, Shaurjya; Saha, Banani; Khatua, Sunirmal] Univ Calcutta, Dept Comp Sci & Engn, Kolkata, India.
C3 University of Calcutta
RP Saha, B (corresponding author), Univ Calcutta, Dept Comp Sci & Engn, Kolkata, India.
EM soma.hazra.frnd@gmail.com; camionofspirit@gmail.com; bsaha_29@yahoo.com;
   enggnimu@gmail.com
RI Saha, Banani/HDL-8898-2022
FU DRDO [ERIP/ER/1404742/M/01/1661]
FX This project work is supported by DRDO under the title 'Object
   Identification through Syntactic as well as Semantic Interpretation from
   given Spatio-Temporal Scenarios'. The project was reviewed and
   sanctioned by the revew committee under the project grant number
   ERIP/ER/1404742/M/01/1661. We would like to express our sincere
   gratitude to DRDO members for this opportunity.
CR Abdulghafoor, 2022, INT J INTELL ENG SYS, V13, P533
   Abdulghafoor NH, 2022, ALEX ENG J, V61, P9637, DOI 10.1016/j.aej.2022.02.068
   Abdelali HA, 2016, MOD SIMUL ENG, V2016, DOI 10.1155/2016/2592368
   Allan P., 1983, P 1 AUSTR MACADAMIA, P1
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Buddubariki V, 2015, NAT CONF COMPUT VIS
   Cehovin L, 2016, IEEE T IMAGE PROCESS, V25, P1261, DOI 10.1109/TIP.2016.2520370
   Couturier R., 2021, ARXIV
   Dai JF, 2016, ADV NEUR IN, V29
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ellis A., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P135, DOI 10.1109/AVSS.2010.89
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Fu CH, 2019, INFORM SCIENCES, V481, P292, DOI 10.1016/j.ins.2018.12.080
   Gani MO, 2021, INT C COMPUTATIONAL, P105
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Jha S, 2021, MULTIMED TOOLS APPL, V80, P3981, DOI 10.1007/s11042-020-09749-x
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Jimenez-Bravo DM, 2022, NEUROCOMPUTING
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Karasawa T, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P35, DOI 10.1145/3126686.3126727
   Khan MA, 2021, MULTIMED TOOLS APPL, V80, P27867, DOI 10.1007/s11042-021-10811-5
   Kumar A, 2020, APPL INTELL, V50, P3201, DOI 10.1007/s10489-020-01649-9
   Lee B, 2016, LECT NOTES COMPUT SC, V9914, P68, DOI 10.1007/978-3-319-48881-3_6
   Li T, 2020, APPL INTELL, V50, P4631, DOI 10.1007/s10489-020-01783-4
   Li ZT, 2018, IEEE T IMAGE PROCESS, V27, P4478, DOI 10.1109/TIP.2018.2839916
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu J., 2016, ARXIV
   Lu Y, 2018, CHIN AUTOM CONGR, P1442, DOI 10.1109/CAC.2018.8623038
   Luna E, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124290
   MAHADEVAN V, 2010, PROC CVPR IEEE, P1975, DOI DOI 10.1109/CVPR.2010.5539872
   Mentzelopoulos M., 2004, P 6 ACM SIGMM INT WO, P39, DOI DOI 10.1145/1026711.1026719
   Mukilan P, 2022, SIGNAL IMAGE VIDEO P, V16, P1913, DOI 10.1007/s11760-022-02151-0
   Pal SK, 2021, APPL INTELL, V51, P6400, DOI 10.1007/s10489-021-02293-7
   Pal SK, 2020, NEURAL COMPUT APPL, V32, P16533, DOI 10.1007/s00521-019-04200-1
   Park Y, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10192406
   Pramanik A, 2022, IEEE TETCI, V6, P171, DOI 10.1109/TETCI.2020.3041019
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shao S., 2018, arXiv
   Sharma Prateek, 2019, Recent Trends in Communication, Computing, and Electronics. Select Proceedings of IC3E 2018. Lecture Notes in Electrical Engineering (LNEE 524), P323, DOI 10.1007/978-981-13-2685-1_31
   Sharma VK, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100301
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wang GA, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P482, DOI 10.1145/3343031.3350853
   Wang Z., 2020, COMPUTER VISION ECCV, P107, DOI [10.1007/978-3-030-58621-8_7, DOI 10.1007/978-3-030-58621-8_7]
   Xu Y, 2021, MEASUREMENT, V169, DOI 10.1016/j.measurement.2020.108502
   Xu YH, 2020, PROC CVPR IEEE, P6786, DOI 10.1109/CVPR42600.2020.00682
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4
NR 58
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12401
EP 12422
DI 10.1007/s11042-022-13780-5
EA SEP 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000854429500001
DA 2024-07-18
ER

PT J
AU Jena, B
   Jain, S
   Nayak, GK
   Saxena, S
AF Jena, Biswajit
   Jain, Sarthak
   Nayak, Gopal Krishna
   Saxena, Sanjay
TI Analysis of depth variation of U-NET architecture for brain tumor
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE U-NET architecture; Fully convolutional network (FCN); Brain tumor
   segmentation; Biomedical image segmentation; Deep learning;
   Convolutional neural network
AB U-NET is a fully convolutional network (FCN) architecture designed to research the segmentation of biomedical images. The depth of the U-NET is one of the major constraints of this model while computing the performances. The larger depth of the U-NET means that its computational complexity is high as well. In certain cases, this large depth, as in the original model, is not justified for biomedical imaging modalities. In this paper, we have done an efficient analysis of U-NET architecture's depth variation, i.e., after removing different layers. For the analysis, the datasets BraTS-2017 and BraTS-2019, which consist of High-Grade Glioma (HGG) and Low-Grade Glioma (LGG) MR Scans, have been used for tumor segmentation. We have achieved a dice coefficient of at least 0.8866 and as high as 0.8887 on the discovery cohort, and at least 0.8895 and as high as 0.8911 cross-validation replication cohort. The results show that there are the least significant changes occurring in the performance parameters while moving from the higher to the lower depth of the model. Hence, in this paper, we presented that the large depth of U-NET, which costs more in terms of computational complexity, is not always required. Moreover, the U-NET models with depth reduction, which decreases the computational complexity, can achieve nearly the same results as in the case of the original U-NET.
C1 [Jena, Biswajit; Jain, Sarthak; Nayak, Gopal Krishna; Saxena, Sanjay] Int Inst Informat Technol, Bhubaneswar, India.
C3 International Institute of Information Technology, Bhubaneswar
RP Jena, B (corresponding author), Int Inst Informat Technol, Bhubaneswar, India.
EM c118002@iiit-bh.ac.in
RI Jena, Biswajit/ABG-2236-2021
OI Jena, Biswajit/0000-0003-2221-6526; Saxena, Sanjay/0000-0002-8288-1010
CR Alqazzaz S, 2019, COMPUT VIS MEDIA, V5, P209, DOI 10.1007/s41095-019-0139-y
   Astaraki M, 2018, PHYS IMAG RADIAT ONC, V5, P52, DOI 10.1016/j.phro.2018.02.003
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Bakas Spyridon, 2018, ARXIV181102629, DOI DOI 10.17863/CAM.38755
   Baris K, 2017, ARXIV
   Beers A, 2017, ARXIV
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143903
   Christ Patrick Ferdinand, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P415, DOI 10.1007/978-3-319-46723-8_48
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Dvorak P, 2013, PIERS PROC
   Fu J, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2019.107152
   Gordillo N, 2013, MAGN RESON IMAGING, V31, P1426, DOI 10.1016/j.mri.2013.05.002
   Gupta D, 2017, BIOMED SIGNAL PROCES, V31, P116, DOI 10.1016/j.bspc.2016.06.012
   Hasan SMK, 2018, WEST NEW YORK IMAG, DOI 10.1109/WNYIPW.2018.8576421
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Jiang H, 2018, BIORXIV
   Kaus MR, 2001, RADIOLOGY, V218, P586, DOI 10.1148/radiology.218.2.r01fe44586
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li RR, 2018, IEEE J-STARS, V11, P3954, DOI 10.1109/JSTARS.2018.2833382
   Liu M, 2021, INT J OCCUP SAF ERGO, V27, DOI 10.1080/10803548.2018.1541648
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Menze BH, 2010, LECT NOTES COMPUT SC, V6362, P151
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Prastawa M, 2004, MED IMAGE ANAL, V8, P275, DOI 10.1016/j.media.2004.06.007
   Colmeiro RGR, 2018, LECT NOTES COMPUT SC, V10670, P226, DOI 10.1007/978-3-319-75238-9_20
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saxena S., 2019, EARLY DETECTION NEUR, ppp. 39
   Saxena S., 2020, Challenges and Applications for Implementing Machine Learning in Computer Vision ss, P43, DOI DOI 10.4018/978-1-7998-0182-5.CH002
   Saxena S, 2019, APPLICATION OF BIOMEDICAL ENGINEERING IN NEUROSCIENCE, P153, DOI 10.1007/978-981-13-7142-4_8
   Soltaninejad M, 2017, INT J COMPUT ASS RAD, V12, P183, DOI 10.1007/s11548-016-1483-3
   Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908
   Xu L, 2014, ADV NEUR IN, V27
   Yang CS, 2019, IEEE ENG MED BIO, P998, DOI [10.1109/EMBC.2019.8857303, 10.1109/embc.2019.8857303]
   Zhou XY, 2019, IEEE ROBOT AUTOM LET, V4, P1792, DOI 10.1109/LRA.2019.2896518
NR 39
TC 6
Z9 6
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10723
EP 10743
DI 10.1007/s11042-022-13730-1
EA SEP 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000852929600004
DA 2024-07-18
ER

PT J
AU Sahoo, GK
   Das, SK
   Singh, P
AF Sahoo, Goutam Kumar
   Das, Santos Kumar
   Singh, Poonam
TI A deep learning-based distracted driving detection solution implemented
   on embedded system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distracted driving; Convolutional neural networks (CNN); Deep neural
   network (DNN); SqueezeNet; Intelligent transport system (ITS)
ID DRIVER BEHAVIOR; RECOGNITION; TRANSFORM; POSTURES
AB Distracted driving is one of the leading causes of most road accidents. Rectification of distracted driving activity is a big challenge for an intelligent transport system (ITS). The use of an in-vehicle deep learning-based driver assistance system may reduce the risk of traffic accidents. However, computational resource requirement makes it challenging to deploy deep learning algorithms in resource-constrained devices, such as raspberry-Pi or mobile phones. This study aims to perform distracted driving detection (DDD) using lightweight deep-convolutional neural networks (DCNNs). This paper implements transfer learning SqueezeNet 1.1 with the last layer modification to classify ten distracted driving postures. It replaces a large number of parameters of DCNN with the help of series of fire modules that has two layers, the squeeze layer and the expand layer. The final output of these layers is concatenated, and a dropout of 0.5 is applied to reduce the over-fitting issue. During the last layer training, all other layer's weights are freezes. Finally, it unfreezes all weights and training of all layers carried out. The transfer learning SqueezeNet architecture's parameter size is about 4.79 MB, which can be feasible to deploy in embedded systems for ITS applications. The StateFarm's distracted driving detection dataset on the Kaggle platform is used, which consists of ten classes of distracted driving postures, including safe driving, texting, talking on the phone, operating the radio, drinking, reaching behind, fixing hair and makeup, and talking to the passenger. The training performance of the system achieves good driving posture estimation with a classification accuracy of 99.93%. Training is performed on the AWS cloud platform, and the best model is deployed in Raspberry Pi 4B to test only in a stationary vehicle. Pytorch and Python are used to build the deep learning model, and from comparative analysis, the SqueezeNet model provides superior performance to other models.
C1 [Sahoo, Goutam Kumar; Das, Santos Kumar; Singh, Poonam] Natl Inst Technol Rourkela, Dept Elect & Commun Engn, Rourkela, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Sahoo, GK (corresponding author), Natl Inst Technol Rourkela, Dept Elect & Commun Engn, Rourkela, Odisha, India.
EM goutamkrsahoo@gmail.com; dassk@nitrkl.ac.in; psingh@nitrkl.ac.in
RI Sahoo, Goutam Kumar/GON-7717-2022; Das, Santos Kumar/M-5844-2019
OI Sahoo, Goutam Kumar/0000-0001-8072-1454; Das, Santos
   Kumar/0000-0002-8788-6152
FU IMPacting Research, INnovation and Technology (IMPRINT) India
   [7794/2016]; Ministry of Human Resource Development; Ministry of Housing
   and Urban Affairs, Government of India
FX This research work was supported by the IMPacting Research, INnovation
   and Technology (IMPRINT) India (Grant No. 7794/2016), an initiative of
   Ministry of Human Resource Development and Ministry of Housing and Urban
   Affairs, Government of India.
CR Abouelnaga Y., 2017, ARXIV
   Administration NHTS., 2016, TRAFF SAF FACTS
   Alotaibi M, 2020, SIGNAL IMAGE VIDEO P, V14, P617, DOI 10.1007/s11760-019-01589-z
   [Anonymous], 2016, NEUROCOMPUTING, DOI [DOI 10.1016/J.NEUC0M.2015.09.116, DOI 10.1016/J.NEUCOM.2015.09.116, 10. 1016/j.neucom.2015.09.116]
   Artan Y, 2014, IEEE COMPUT SOC CONF, P225, DOI 10.1109/CVPRW.2014.42
   Baheti B, 2018, IEEE COMPUT SOC CONF, P1145, DOI 10.1109/CVPRW.2018.00150
   Berri RA, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P411
   Bertalmio M., 2001, PROC CVPR IEEE, V1, P1, DOI DOI 10.1109/CVPR.2001.990497
   Chandra R, 2022, IEEE T INTELL TRANSP, V23, P2572, DOI 10.1109/TITS.2021.3130218
   Chawan P.M., 2018, International Journal of Engineering Research and Applications, V4, P7
   Chihang Zhao, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P926, DOI 10.1109/ICIG.2011.184
   Chung J., 2016, ARXIV
   Craye C., 2015, ARXIV
   Tran C, 2012, COMPUT VIS IMAGE UND, V116, P435, DOI 10.1016/j.cviu.2011.09.008
   Tran D, 2018, IET INTELL TRANSP SY, V12, P1210, DOI 10.1049/iet-its.2018.5172
   Eraqi HM, 2019, J ADV TRANSPORT, DOI 10.1155/2019/4125865
   Eriksson A, 2017, HUM FACTORS, V59, P689, DOI 10.1177/0018720816685832
   Fernández A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111805
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang C, 2020, IEEE ACCESS, V8, P109335, DOI 10.1109/ACCESS.2020.3001159
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Jagannathan S, 2019, J INTELL FUZZY SYST, V36, P2005, DOI 10.3233/JIFS-169912
   Jamshidi S, 2021, MULTIMED TOOLS APPL, V80, P16045, DOI 10.1007/s11042-021-10542-7
   kaggle, STAT FARM CORP STAT
   Kamel M., 1989, Proceedings of the SPIE - The International Society for Optical Engineering, V1199, P712, DOI 10.1117/12.970082
   Koesdwiady A, 2017, LECT NOTES COMPUT SC, V10317, P11, DOI 10.1007/978-3-319-59876-5_2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le THN, 2016, IEEE COMPUT SOC CONF, P46, DOI 10.1109/CVPRW.2016.13
   Li YT, 2016, MULTIMED TOOLS APPL, V75, P16959, DOI 10.1007/s11042-015-2969-7
   Ma H, 2021, SIGNAL IMAGE VIDEO P, V15, P1507, DOI 10.1007/s11760-021-01883-9
   Min K, 2019, IEEE T INTELL VEHICL, V4, P416, DOI 10.1109/TIV.2019.2919467
   Moslemi Negar, 2019, 2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA), P145, DOI 10.1109/PRIA.2019.8786012
   Murphy-Chutorian E, 2010, IEEE T INTELL TRANSP, V11, P300, DOI 10.1109/TITS.2010.2044241
   Omerustaoglu F, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106657
   Ou CJ, 2018, LECT NOTES COMPUT SC, V10882, P443, DOI 10.1007/978-3-319-93000-8_50
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rastgoo MN, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.07.010
   Sahoo G. K., 2020, 2020 IEEE-HYDCON., P1
   Shahverdy M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113240
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soon FC, 2019, SIGNAL IMAGE VIDEO P, V13, P111, DOI 10.1007/s11760-018-1335-4
   Staubach M, 2009, ACCIDENT ANAL PREV, V41, P1025, DOI 10.1016/j.aap.2009.06.014
   Streiffer C, 2017, MIDDLEWARE'17: PROCEEDINGS OF THE 2017 INTERNATIONAL MIDDLEWARE CONFERENCE (INDUSTRIAL TRACK), P22, DOI 10.1145/3154448.3154452
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Teyeb I, 2014, 5TH INTERNATIONAL CONFERENCE ON INFORMATION, INTELLIGENCE, SYSTEMS AND APPLICATIONS, IISA 2014, P379, DOI 10.1109/IISA.2014.6878809
   WHO, 2020, Road traffic injuries
   Wu HY, 2020, MULTIMED TOOLS APPL, V79, P263, DOI 10.1007/s11042-019-08075-1
   Xuetao Zhang, 2011, 2011 IEEE International Conference on Vehicular Electronics and Safety (ICVES 2011), P248, DOI 10.1109/ICVES.2011.5983823
   Yan C, 2016, IET COMPUT VIS, V10, P103, DOI 10.1049/iet-cvi.2015.0175
   Ye MQ, 2017, ACCIDENT ANAL PREV, V106, P385, DOI 10.1016/j.aap.2017.07.010
   Zhao CH, 2012, IET INTELL TRANSP SY, V6, P161, DOI 10.1049/iet-its.2011.0116
   Zhao CH, 2012, ENG APPL ARTIF INTEL, V25, P1677, DOI 10.1016/j.engappai.2012.09.018
   Zhu B, 2018, IEEE T HUM-MACH SYST, V48, P572, DOI 10.1109/THMS.2018.2861225
NR 54
TC 5
Z9 5
U1 6
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11697
EP 11720
DI 10.1007/s11042-022-13450-6
EA AUG 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000847985800001
DA 2024-07-18
ER

PT J
AU Hafiz, AM
   Bhat, RA
   Hassaballah, M
AF Hafiz, A. M.
   Bhat, R. A.
   Hassaballah, M.
TI Image classification using convolutional neural network tree ensembles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Ensembles; Parallel processing; CNN; Deep
   learning; ImageNet
ID REPRESENTATION; SPARSE
AB Conventional machine learning techniques may have lesser performance when they deal with complex data. For addressing this issue, it is important to build data mining frameworks coupled with robust knowledge discovery mechanisms. One of such frameworks, which addresses these issues is ensemble learning. It fuses data, builds models and mines data into a single framework. In spite of the work done on ensemble learning, there remain issues like how to manage the complexity, how to optimize the model, and how to fine-tune the model. Natural data processing schemes use parallel processing and are robust and efficient, hence are successful. Taking a cue from natural data processing architectures, we propose a parallelized CNN tree ensemble approach. The proposed approach is compared against the baseline which is the deep network used in the ensemble. The ResNet50 architecture is utilized for initial experimentation. The datasets used for this task are the ImageNet and natural images datasets. The proposed approach outperforms the baseline on all experiments on the ImageNet dataset. Further, benchmarking of the proposed approach against different types of CNNs is done on various datasets including CIFAR-10, CIFAR-100, Fashion-MNIST, FEI face recognition, and MNIST digits. Since our approach is adaptable for CNNs, it outperforms the baseline CNNs as well as the state-of-the-art techniques on these datasets. The CNNs architectures used for benchmarking are ResNet-50, DenseNet, WRN-28-10 and NSGANetV1. The code for the paper is available in https://github.com/mueedhafiz1982/CNNTreeEnsemble.git.
C1 [Hafiz, A. M.; Bhat, R. A.] Univ Kashmir, Inst Technol, Dept ECE, Srinagar, J&k, India.
   [Hassaballah, M.] South Valley Univ, Fac Comp & Informat, Dept Comp Sci, Qena 83523, Egypt.
   [Hassaballah, M.] Prince Sattam Bin Abdulaziz Univ, Coll Comp Engn & Sci, Alkharj, Saudi Arabia.
C3 University of Kashmir; Egyptian Knowledge Bank (EKB); South Valley
   University Egypt; Prince Sattam Bin Abdulaziz University
RP Hafiz, AM (corresponding author), Univ Kashmir, Inst Technol, Dept ECE, Srinagar, J&k, India.
EM mueedhafiz@uok.edu.in
RI Hafiz, Abdul Mueed/AAF-3806-2020; Hassaballah, Mahmoud/A-5197-2018
OI Hafiz, Abdul Mueed/0000-0002-2266-3708; Hassaballah,
   Mahmoud/0000-0001-5655-8511
CR Akhtar N, 2017, PATTERN RECOGN, V65, P136, DOI 10.1016/j.patcog.2016.12.017
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.322
   Chen Y., 2015, UCR TIME SERIES CLAS
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dikici E, 2020, ARXIV
   Dong XB, 2020, FRONT COMPUT SCI-CHI, V14, P241, DOI 10.1007/s11704-019-8208-z
   Fawaz HI, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8852316
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Gashler M, 2008, 2008 7 INT C MACHINE, DOI 10.1109/ICMLA.2008.154
   Hafiz Abdul Mueed, 2021, Information and Communication Technology for Competitive Strategies (ICTCS 2020). Intelligent Strategies for ICT. Lecture Notes in Networks and Systems (LNNS 190), P445, DOI 10.1007/978-981-16-0882-7_38
   Hafiz Abdul Mueed, 2020, Information and Communication Technology for Sustainable Development. Proceedings of ICT4SD 2018. Advances in Intelligent Systems and Computing (AISC 933), P161, DOI 10.1007/978-981-13-7166-0_16
   Hafiz A.M., 2020, arXiv
   Hafiz A. M., 2021, ARXIV
   Hafiz AM, 2020, INT J MULTIMED INF R, V9, P171, DOI 10.1007/s13735-020-00195-x
   Hassaballah M., 2020, Deep Learning in Computer Vision: Principles and Applications, DOI DOI 10.1201/9781351003827
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jena B, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104803
   Kandaswamy C, 2015, LECT NOTES COMPUT SC, V9094, P335, DOI 10.1007/978-3-319-19258-1_29
   Khan S., 2021, Transformers in vision: A survey
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Lu ZC, 2021, IEEE T EVOLUT COMPUT, V25, P277, DOI 10.1109/TEVC.2020.3024708
   Ma Y, SPIE, V11911, P422, DOI 10.1117/12.2604526
   Machado GR, 2021, ADVERSARIAL MACHINE, V55, DOI 10.1145/3485133
   Mai ZD, 2022, NEUROCOMPUTING, V469, P28, DOI 10.1016/j.neucom.2021.10.021
   Nozza D, 2016, PROC INT C TOOLS ART, P184, DOI [10.1109/ICTAI.2016.0037, 10.1109/ICTAI.2016.34]
   Parimala M, 2021, SOFTWARE PRACT EXPER, V51, P550, DOI 10.1002/spe.2851
   Plested J, 2022, DEEP TRANSFER LEARNI
   Priya RMS, 2020, COMPUT COMMUN, V160, P139, DOI 10.1016/j.comcom.2020.05.048
   Reddy G.T., 2020, Int Conf Emerg Trends Inform Technol Eng Ic-ETITE, P1, DOI 10.1109/ic-etite47903.2020.235
   Reddy GT, 2020, COMPUT COMMUN, V157, P64, DOI 10.1016/j.comcom.2020.04.004
   Roy D, 2020, NEURAL NETWORKS, V121, P148, DOI 10.1016/j.neunet.2019.09.010
   Roy P, 2018, ARXIV
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schmarje L, 2021, IEEE ACCESS, V9, P82146, DOI 10.1109/ACCESS.2021.3084358
   Sollich P, 1996, ADV NEUR IN, V8, P190
   SOMAYAJI SRK, 2020, IEEE GLOBE WORK
   Tao S, 2019, LECT NOTES COMPUT SC, V11943, P1, DOI 10.1007/978-3-030-37599-7_1
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Xiao H., 2017, ARXIV170807747
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   You S, 2018, AAAI CONF ARTIF INTE, P4390
   Zeng SN, 2017, MULTIMED TOOLS APPL, V76, P20889, DOI 10.1007/s11042-016-4035-5
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou JH, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107529
   Zhou JH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112609
NR 55
TC 3
Z9 3
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6867
EP 6884
DI 10.1007/s11042-022-13604-6
EA AUG 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000840140700001
DA 2024-07-18
ER

PT J
AU Dasgupta, M
   Bandyopadhyay, O
   Chatterji, S
AF Dasgupta, Madhuchhanda
   Bandyopadhyay, Oishila
   Chatterji, Sanjay
TI Detection of helmetless motorcycle riders by video captioning using deep
   recurrent neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional Neural Network (CNN); Long Short Term Memory (LSTM); Soft
   attention; BiLingual Evaluation Understudy (BLEU); Metric for Evaluation
   of Translation with Explicit Ordering (METEOR); Optical flow
AB In a country like India with high density of population, motorcycle is one of the common and viable mode of transport. It is observed that many motorcyclists refrain from wearing helmets while driving. This results in fatal road accidents every year. In crowded roads and highways, it becomes difficult for the police to identify such cases and to take necessary actions. These traffic rule violators can be detected by analysing the traffic videos of surveillance camera. The main objective of this work is to detect the helmetless motorcyclists (and pillion riders) and generate appropriate video caption to help the traffic authority to take fast action against the rule violators. The system can also detect helmetless multiple riders and child rider cases from the video captions. A deep neural network based approach is proposed to generate the video captions for motorcycle riders from surveillance video analysis. In the proposed encoder-decoder based model, Convolutional Neural Network (CNN) along with optical flow guided approach are used for visual feature extraction in encoder part. In the decoder part, Recurrent Neural Network (RNN) based Long-Short-Term-Memory (LSTM) with Soft Attention (SA) technique is applied to achieve best result for video caption generation. The effectiveness of the proposed approach is evaluated by computing BiLingual Evaluation Understudy (BLEU) and Metric for Evaluation of Translation with Explicit Ordering (METEOR) metrices. The extensive experimental results show that the proposed method outperforms other state-of-the-art methods.
C1 [Dasgupta, Madhuchhanda; Bandyopadhyay, Oishila; Chatterji, Sanjay] Indian Inst Informat Technol Kalyani, Kalyani, W Bengal, India.
RP Bandyopadhyay, O (corresponding author), Indian Inst Informat Technol Kalyani, Kalyani, W Bengal, India.
EM madhuchhandaphd19@iiitkalyani.ac.in; oishila@iiitkalyani.ac.in;
   sanjayc@iiitkalyani.ac.in
OI Bandyopadhyay, Oishila/0000-0002-0348-371X
CR Ba J, 2015, ARXIV
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   Chen SX, 2019, AAAI CONF ARTIF INTE, P8191
   Chiverton J, 2012, IET INTELL TRANSP SY, V6, P259, DOI 10.1049/iet-its.2011.0138
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Dasgupta M., 2019, 2019 IEEE C INF COMM, P1
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Espinosa JE, 2018, ARXIV
   Fan Q., 2019, PROC CVPR IEEE
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu J, 2018, ADV NEURAL INFORM PR, P9401, DOI DOI 10.5555/3327546.3327612
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kunar A., 2020, OBJECT DETECTION SSD
   Li XL, 2021, IEEE T GEOSCI REMOTE, V59, P5246, DOI 10.1109/TGRS.2020.3010106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mallela NC, 2021, MULTIMED TOOLS APPL, V80, P8175, DOI 10.1007/s11042-020-10126-x
   Panesar S., 2019, PROF RK SHARMA, V13, P43, DOI DOI 10.3115/1073083.1073135
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ruder S, 2020, ARXIV
   Silva R, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P141, DOI 10.1109/SIBGRAPI.2014.28
   Simonyan K, 2014, ADV NEUR IN, V27
   Sun SY, 2018, PROC CVPR IEEE, P1390, DOI 10.1109/CVPR.2018.00151
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang Q, 2021, IEEE T GEOSCI REMOTE, V59, P10532, DOI 10.1109/TGRS.2020.3044054
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
NR 37
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5857
EP 5877
DI 10.1007/s11042-022-13473-z
EA AUG 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000834736500006
DA 2024-07-18
ER

PT J
AU Bindhu, JS
   Pramod, KV
AF Bindhu, J. S.
   Pramod, K., V
TI Texture and pixel-based satellite image classification using cellular
   automata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pixel-based classification; Texture-based classification; Cellular
   automata; Parallelepiped; Maximum likelihood; Softmax regression
   classifier
ID FEATURE-EXTRACTION; FUSION
AB Pixel and texture based classification using a well-defined and efficient architecture is considered as a major challenge. Nowadays, a large number of satellite images are received within a fraction of seconds, however processing such images to identify the land cover and land use is considered as a tedious process. To achieve this objective with high accuracy, an algorithm of cellular automata (ACA) is introduced in this proposed approach. The pixel-based classification is carried out with parallelepiped and maximum likelihood classifier, whereas the texture-based classification is accomplished using Softmax regression (SR) classifier. By incorporating ACA, the accuracy of these classification techniques is improved and the performance is then evaluated. This overall classification process is performed to understand the land cover and land use of Kerala. The classification accuracy attained using ACA-based parallelepiped, maximum likelihood and SR is found higher than classical parallelepiped, maximum likelihood, and SR algorithms. The final result reveals that the texture-based ACA classification provides a higher classification accuracy rate (96.8%) than the pixel-based ACA classification (90.98%).
C1 [Bindhu, J. S.; Pramod, K., V] CUSAT, Dept Comp Applicat, Kochi, Kerala, India.
C3 Cochin University Science & Technology
RP Bindhu, JS (corresponding author), CUSAT, Dept Comp Applicat, Kochi, Kerala, India.
EM bindhuscholar@gmail.com
CR Abburu S., 2015, Int. J. Comput. Appl, V119, P20, DOI [10.5120/21088-3779, DOI 10.5120/21088-3779]
   Aburas MM, 2016, INT J APPL EARTH OBS, V52, P380, DOI 10.1016/j.jag.2016.07.007
   Arya D, 2018, TEXTURE SHAPE COLOUR
   Devi M.S., 2019, Int. J. Comput. Intell. Res, V15, P1
   Devi MR., 2011, ENG TECHNOL, V2, P180
   Dixit A., 2017, INT J APPL ENG RES, V12, P3996
   Espínola M, 2010, LECT NOTES COMPUT SC, V6350, P312
   Hang RL, 2016, IEEE T GEOSCI REMOTE, V54, P783, DOI 10.1109/TGRS.2015.2465899
   Humeau-Heurtier A, 2019, IEEE ACCESS, V7, P8975, DOI 10.1109/ACCESS.2018.2890743
   Jog S, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P93
   Kamavisdar P., 2013, International Journal of Advanced Research in Computer and Communication Engineering, V2, P1005
   Li CF, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0436-5
   Liu QS, 2018, IEEE T GEOSCI REMOTE, V56, P117, DOI 10.1109/TGRS.2017.2743243
   Liu QS, 2017, IEEE J-STARS, V10, P4171, DOI 10.1109/JSTARS.2017.2700490
   Liu Q, 2020, REMOTE SENS LETT, V11, P156, DOI 10.1080/2150704X.2019.1693071
   Mahata K, 2018, QUANTUM INSPIRED INT, P178
   Mather P., 2016, Classification Methods for Remotely Sensed Data, DOI 10.1201/9781420090741
   NAIR M, 2016, INT J COMPUT APPL, V134, P1, DOI DOI 10.5120/IJCA2016908202
   Neware Rahul, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1860, DOI 10.1109/ICECA.2018.8474881
   Panda A, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P1403, DOI 10.1109/ICICCT.2018.8473241
   Shackelford AK, 2003, IEEE T GEOSCI REMOTE, V41, P2354, DOI 10.1109/TGRS.2003.815972
   Taher HB., 2019, J ED PURE SCI U THI, V9, P32
   Unar S, 2019, KNOWL-BASED SYST, V179, P8, DOI 10.1016/j.knosys.2019.05.001
   Unar S, 2018, INFORM FUSION, V44, P176, DOI 10.1016/j.inffus.2018.03.006
   Upadhyay A, 2018, SENSORS IMAGE PROCES, P245
   Venkateswaran CJ., 2013, INT J ENG TECHNOLOGY, V5, P3051
   Wang XY, 2012, COMPUT STAND INTER, V34, P31, DOI 10.1016/j.csi.2011.05.001
   Wang XY, 2009, FRACTALS, V17, P441, DOI 10.1142/S0218348X09004557
   Wang XY, 2014, PATTERN RECOGN, V47, P3293, DOI 10.1016/j.patcog.2014.04.020
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wolfe J, 2017, INT ARCH PHOTOGRAMM, V42-1, P455, DOI 10.5194/isprs-archives-XLII-1-W1-455-2017
   Wu QG, 2015, NEUROCOMPUTING, V151, P1133, DOI 10.1016/j.neucom.2014.04.085
   Yang W, 2015, IEEE T GEOSCI REMOTE, V53, P4472, DOI 10.1109/TGRS.2015.2400449
   Zhang X, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071474
NR 34
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9913
EP 9937
DI 10.1007/s11042-022-13457-z
EA JUL 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000832844000003
DA 2024-07-18
ER

PT J
AU El-Naby, AA
   Hemdan, EED
   El-Sayed, A
AF El-Naby, Aya Abd
   Hemdan, Ezz El-Din
   El-Sayed, Ayman
TI An efficient fraud detection framework with credit card imbalanced data
   in financial services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Credit card fraud; Imbalanced data; And machine learning
ID OVER-SAMPLING METHOD; CLASSIFICATION
AB Credit card fraud has adversely impacted market economic order and has broken stakeholders, financial entities, and consumers' trust and interest. Card fraud losses are increasing annually and billions of dollars are being lost. Therefore, this work provides a framework for fraud card detection to be tackled efficiently. Recently, the imbalanced dataset for fraud card transactions due to the number of ordinary transactions being far greater than the amount of fraud. Before solving the fraud problem, we first have to solve the imbalanced data problem which occurred when one class considerably outnumbers the examples of the other class. So, the classification of fraud come to be very tough as the result may get biased towards the majority group. Thus, this paper aims firstly to use hybrid sampling and oversampling preprocessing techniques to solve the imbalanced data problem, and secondly to resolve the fraud. The performance of the proposed framework is estimated based on different metrics accuracy, precision, and recall in comparing existing algorithms such as KNN, LR, LDA, NB, and CART. The obtained results revealing that when the data is highly imbalanced, the model strives to detect fraudulent transactions. Besides, it can predict positive classes improved significantly, reaching an accuracy of 99.9.
C1 [El-Naby, Aya Abd] Egypt Univ Informat EUI, Fac Engn, Dept Comp Engn, Cairo, Egypt.
   [Hemdan, Ezz El-Din; El-Sayed, Ayman] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP El-Naby, AA (corresponding author), Egypt Univ Informat EUI, Fac Engn, Dept Comp Engn, Cairo, Egypt.
EM aya.abdelnaby@eui.edu.eg; ezzvip@yahoo.com;
   ayman.elsayed@el-eng.menofia.edu.eg
RI EL-SAYED, Ayman E./AFM-8547-2022
OI EL-SAYED, Ayman E./0000-0002-4437-259X
CR Aditsania A, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON SCIENCE IN INFORMATION TECHNOLOGY (ICSITECH), P533, DOI 10.1109/ICSITech.2017.8257170
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Ali H, 2019, INDONES J ELECT ENG, V14, ppp1552, DOI 10.11591/ijeecs.v14.i3
   Batista G. E., 2004, ACM SIGKDD EXPL NEWS, V6, P20, DOI DOI 10.1145/1007730.1007735
   Bhattacharyya S, 2011, DECIS SUPPORT SYST, V50, P602, DOI 10.1016/j.dss.2010.08.008
   Ebenuwa SH, 2019, IEEE ACCESS, V7, P24649, DOI 10.1109/ACCESS.2019.2899578
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   Huang ZK, 2020, NEURAL COMPUT APPL, V32, P7183, DOI 10.1007/s00521-019-04208-7
   kaggle.com, RAFJAARESAMPLING STR
   Karim A, 2019, IEEE ACCESS, V7, P168261, DOI 10.1109/ACCESS.2019.2954791
   Keswani B, 2020, ADAPTING MACHINE LEA, DOI 10.1007/978-981-15-1286-5_38
   Moreno-Torres JG, 2012, PATTERN RECOGN, V45, P521, DOI 10.1016/j.patcog.2011.06.019
   Parkinson de Castro E, 2020, THESIS  TECH U DUBLI, DOI 10.21427/wj33-n221
   Parthasarathy G, 2019, SSRN ELECT J, DOI 10.2139/ssrn.3351584
   Pattanayak SS, 2018, ADV INTELL SYST, V564, P13, DOI 10.1007/978-981-10-6875-1_2
   Pedro Lopez Garcia, 2018, ENSEMBLE FUZZY TECHN, DOI 10.1007/978-3-319-91641-5_16
   Reddy GT, 2022, MULTIMED TOOLS APPL, V81, P41429, DOI 10.1007/s11042-020-09988-y
   Roberston D, NELSON REPORT
   Singh P, 2020, P ICRIC 2019, P209
   Soh W. W., 2019, Int. J. Data Sci. Adv. Anal., V1, P12
   Tang MJ, 2019, IEEE T BIG DATA, V5, P317, DOI 10.1109/TBDATA.2017.2723570
   Yun Hou, 2019, Journal of Physics: Conference Series, V1302, DOI 10.1088/1742-6596/1302/2/022064
NR 27
TC 9
Z9 9
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4139
EP 4160
DI 10.1007/s11042-022-13434-6
EA JUL 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000828446400001
DA 2024-07-18
ER

PT J
AU Tiwary, T
   Mahapatra, RP
AF Tiwary, Tejal
   Mahapatra, Rajendra Prasad
TI An accurate generation of image captions for blind people using extended
   convolutional atom neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image captioning; Blind people; Alternative text; Natural language
   processing; Deep learning; Extended convolutional atom neural network
   (ECANN)
AB Recently, the progress on image understanding and AIC (Automatic Image Captioning) has attracted lots of researchers to make use of AI (Artificial Intelligence) models to assist the blind people. AIC integrates the principle of both computer vision and NLP (Natural Language Processing) to generate automatic language descriptions in relation to the image observed. This work presents a new assistive technology based on deep learning which helps the blind people to distinguish the food items in online grocery shopping. The proposed AIC model involves the following steps such as Data Collection, Non-captioned image selection, Extraction of appearance, texture features and Generation of automatic image captions. Initially, the data is collected from two public sources and the selection of non-captioned images are done using the ARO (Adaptive Rain Optimization). Next, the appearance feature is extracted using SDM (Spatial Derivative and Multi-scale) approach and WPLBP (Weighted Patch Local Binary Pattern) is used in the extraction of texture features. Finally, the captions are automatically generated using ECANN (Extended Convolutional Atom Neural Network). ECANN model combines the CNN (Convolutional Neural Network) and LSTM (Long Short-Term Memory) architectures to perform the caption reusable system to select the most accurate caption. The loss in the ECANN architecture is minimized using AAS (Adaptive Atom Search) Optimization algorithm. The implementation tool used is PYTHON and the dataset used for the analysis are Grocery datasets (Freiburg Groceries and Grocery Store Dataset). The proposed ECANN model acquired accuracy (99.46%) on Grocery Store Dataset and (99.32%) accuracy on Freiburg Groceries dataset. Thus, the performance of the proposed ECANN model is compared with other existing models to verify the supremacy of the proposed work over the other existing works.
C1 [Tiwary, Tejal] SRMIST, Dept Comp Sci & Engn, NCR Campus, Ghaziabad, India.
   [Mahapatra, Rajendra Prasad] SRM Inst Sci & Technol, Dept CSE, NCR Campus, Ghaziabad, India.
C3 SRM Institute of Science & Technology Delhi NCR (Ghaziabad); SRM
   Institute of Science & Technology Delhi NCR (Ghaziabad)
RP Tiwary, T (corresponding author), SRMIST, Dept Comp Sci & Engn, NCR Campus, Ghaziabad, India.
CR Al-Muzaini HA, 2018, INT J ADV COMPUT SC, V9, P67
   Amritkar C, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Bai S, 2018, NEUROCOMPUTING, V311, P291, DOI 10.1016/j.neucom.2018.05.080
   Bigham JP, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P101, DOI 10.1145/3132525.3132533
   Geng WD, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1706, DOI 10.1145/3240508.3240522
   Giraud S, 2018, INT J HUM-COMPUT ST, V111, P23, DOI 10.1016/j.ijhcs.2017.10.011
   Guinness D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174092
   Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748
   Huang W., 2020, SIGNAL PROCESS-IMAGE, V85, P1
   Iwamura K, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041270
   Jund P, 2016, ARXIV PREPRINT ARXIV
   Khurram I, 2021, COGN COMPUT, V13, P595, DOI 10.1007/s12559-019-09697-1
   Kim Deokyun, 2019, PROC C EMPIRICAL MET, P2, DOI DOI 10.23919/ELINFOCOM.2019.8706453
   Klasson M, 2019, IEEE WINT CONF APPL, P491, DOI 10.1109/WACV.2019.00058
   Kuber R, 2020, ASSISTIVE MULTIMODAL
   Leo M, 2021, INT C PATT RECOG, P7234, DOI 10.1109/ICPR48806.2021.9413250
   Loganathan K, 2020, MATER TODAY-PROC, P1
   MacLeod H, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5988, DOI 10.1145/3025453.3025814
   Makav B, 2019, 2019 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ELECO 2019), P945, DOI [10.23919/eleco47770.2019.8990630, 10.23919/ELECO47770.2019.8990630]
   Melas-Kyriazi L, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P757
   Sadeghi Delaram, 2021, ARXIV210303081
   Sehgal Smriti, 2020, 2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), P165, DOI 10.1109/ICRITO48877.2020.9197977
   Sharma G, 2019, 2 INT C ADV SCI TECH
   Shoeibi A, 2020, AUTOMATED DETECTION
   Shoeibi A, 2021, FRONT NEUROINFORM, V15, DOI 10.3389/fninf.2021.777977
   Shoeibi A, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103417
   Shoeibi A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104697
   Singh AK, 2023, MATH METHOD APPL SCI, V46, P8208, DOI 10.1002/mma.7655
   Song H, 2020, COMPUT ELECTR ENG, V84, DOI 10.1016/j.compeleceng.2020.106630
   Wei YC, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8875910
   Wu SM, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P1180, DOI 10.1145/2998181.2998364
   Xiao F, 2019, NEUROCOMPUTING, V364, P322, DOI 10.1016/j.neucom.2019.06.085
   Yang MS, 2017, PATTERN RECOGN, V71, P45, DOI 10.1016/j.patcog.2017.05.017
   Yang M, 2020, IEEE T IMAGE PROCESS, V29, P9627, DOI 10.1109/TIP.2020.3028651
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu NG, 2019, IEEE T IMAGE PROCESS, V28, P2743, DOI 10.1109/TIP.2018.2889922
NR 36
TC 8
Z9 8
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3801
EP 3830
DI 10.1007/s11042-022-13443-5
EA JUL 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000825245900001
PM 35855372
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Sharma, KG
   Singh, Y
AF Sharma, Krishna Gopal
   Singh, Yashpal
TI KDV classifier: a novel approach for binary classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binary classification; k-distance; k-nearest neighbour; KNN; KDV;
   Variance
ID K-NEAREST-NEIGHBOR; PARTICLE SWARM OPTIMIZATION; CANCER; BAYES
AB The current era is an era of Artificial Intelligence. Artificial intelligence is an umbrella discipline that includes Machine Learning as a crucial component. In the Machine Learning space, Classification is an important research area that cannot be neglected. We can define classification as systematically arranging objects or elements in different groups based on given conditions or criteria. An important class of classifier is a Binary classifier that classifies observations or data into two classes. The binary classifier is useful when observation can only be grouped in two categories or where classification in two classes is required in a given situation. One example of a binary classifier is whether a patient is cancerous or not. In literature many binary classification algorithms are available. The proposed classifier in this research paper is also a binary classifier. The name of the proposed classifier is KDV Binary Classifier. Here KDV stands for K-Distance Variance. K-Distance is the distance of the kth nearest object of a given data point. This binary classifier is particularly useful if observations are not balanced. One particular class outnumbers another class. We compared KDV with KNN for binary classification based on the percentage of accuracy. KNN is a general classifier. We considered its binary aspect. The result shows that KDV is comparable with KNN. Many times KDV outperforms KNN. We compared results for accuracy using cross-validation methods like twofold, fivefold, tenfold and the Also Leave one out method. KDV can be a good research area in the field of Machine Learning.
C1 [Sharma, Krishna Gopal] Dr APJ Abdul Kalam Tech Univ, Lucknow, Uttar Pradesh, India.
   [Singh, Yashpal] Bundelkhand Inst Engn & Technol, Jhansi, Uttar Pradesh, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Bundelkhand
   Institute of Engineering & Technology
RP Sharma, KG (corresponding author), Dr APJ Abdul Kalam Tech Univ, Lucknow, Uttar Pradesh, India.
EM hollyhoc@gmail.com; yash_biet@yahoo.co.in
CR 37steps, US
   Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745
   [Anonymous], 2008, US
   Babaoglu Ismail, 2013, International Journal of Computer and Communication Engineering, V2, P56
   Babaoglu I, 2012, INT J INNOV COMPUT I, V8, P3467
   Bermejo S, 2000, PATTERN RECOGN, V33, P1999, DOI 10.1016/S0031-3203(99)00186-7
   Chen M., 2015, J COMPUT INF SYST, V11, P1407, DOI DOI 10.12733/JCIS13449
   cloudmoyo, WHAT IS BIG DAT IT C
   COVER T. M., 1968, P HAWAII INT C SYSTE, P413
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6, P325, DOI 10.1109/TSMC.1976.5408784
   El Houby EMF, 2017, INFORM-J COMPUT INFO, V41, P495
   FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797
   Flach P., 2012, MACHINE LEARNING ART, DOI [10.1017/CBO9780511973000, DOI 10.1017/CBO9780511973000]
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P285, DOI 10.1109/TIT.1975.1055373
   Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531
   Gopal M., 2019, Applied Machine Learning
   Halder A, 2014, 2014 FIRST INTERNATIONAL CONFERENCE ON AUTOMATION, CONTROL, ENERGY & SYSTEMS (ACES-14), P266
   Han EH., 2001, ADV KNOWLEDGE DISCOV, V2035, DOI 10.1007/3-540-45357-1_9
   Han JW, 2000, DATA MINING CONCEPTS
   ics, ABOUT US
   ics, UCI Machine Learning Repository
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI [10.1007/978-1-4614-7138-7, 10.1007/978-1-4614-7138-7_1]
   Jiang LX, 2005, LECT NOTES ARTIF INT, V3584, P175
   Józwik A, 1983, PATTERN RECOGN LETT, V1, P287, DOI 10.1016/0167-8655(83)90064-8
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Lambda A., 2016, International Journal of Advanced Research in Computer and Communication Engineering, V5, P430, DOI [10.17148/IJARCCE.2016.55101, DOI 10.17706/IJCCE.2016.5.6.430-440]
   Mitchell T. M., 1997, MACH LEARN
   Ougiaroglou S, 2007, LECT NOTES COMPUT SC, V4690, P66
   Russell S.J., 2000, Artificial Intelligence: A Modern Approach
   Sasirekha K, 2019, NEURAL COMPUT APPL, V31, P7935, DOI 10.1007/s00521-018-3624-9
   scholar, about us
   Sharma KG, 2011, COMM COM INF SC, V131, P542
   Sharma M., 2013, INT J ADV RES COMPUT, V3
   Sherman R., 2015, BUS INTELL GUIDEB, DOI 10.1016/b978-0-12-411461-6.00007-1
   Shrivastava SK., 2011, INT J COMPUT SCI ENG, V3, P1831
   Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2
   Song Y, 2007, LECT NOTES ARTIF INT, V4702, P248
   Suguna N., 2010, INT J COMPUTER SCI I, V7, P18
   Wettschereck D., 1994, Advances in Neural Information Processing Systems, V6, P184
   Wikipedia, CROSS VAL STAT
   WiraBuana P., 2012, INT J COMPUT APPL, V50, P37, DOI DOI 10.5120/7817-1105
   Zhang H., 2006, 2006 IEEE COMP SOC C, V2, P2126, DOI DOI 10.1109/CVPR.2006.301
NR 43
TC 0
Z9 0
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42241
EP 42259
DI 10.1007/s11042-021-11451-5
EA JUL 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000825246000009
DA 2024-07-18
ER

PT J
AU Balani, N
   Chavan, P
   Ghonghe, M
AF Balani, Nisha
   Chavan, Pallavi
   Ghonghe, Mangesh
TI Design of high-speed blockchain-based sidechaining peer to peer
   communication protocol over 5G networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Sidechain; Security; Decentralization; Machine learning
AB Blockchain technology has become the epitome of security due to its traceability, transparency, immutability, and decentralized nature. To deploy blockchain into any network, a wide variety of mathematical operations are needed to be performed. These operations include hashing, block verification, encryption, and mining. Implementation of these operations is highly complex and requires heavy computational operations to be performed in real-time. Thus, high-performance computing engines are needed to develop blockchain systems, which can be done via the design of parallel processing, pipelining, and VLSI process miniaturization. Apart from high-performance computing, blockchain systems require high-performance communication, which enables seamless node-to-node connectivity for a truly decentralized implementation. Current 4(th) Generation (4G) communication models do not have enough throughput which is needed for high-performance blockchain-based communications, due to rapid block transfers for verification, mining, and viewing operations. Thus, 5G networks are the best application for deploying truly decentralized blockchain systems due to their low communication overheads, and high throughput. As the length of the blockchain increases, 5G networks will also face scalability issues due to an exponential increase in packet sizes. This will reduce the QoS performance of large length blockchains, thereby making them less useful for real-time large-scale applications like Industrial IoT, medical data privacy, etc. Thus, in this work, a machine learning-based sidechaining model is proposed, that utilizes a modified Genetic Algorithm powered engine. This engine aims at splitting the underlying blockchain into sidechains, thereby reducing mining complexity and reducing the number of packets needed for communication while maintaining true decentralization. The model is compared with standard blockchain & sidechain implementations in terms of access time, reading delay, and writing delay. It is observed that the model when implemented under 5G network emulation, outperforms existing blockchain and sidechain models in terms of these parameters, thereby making it useful for highly scalable blockchain systems.
C1 [Balani, Nisha] Ramrao Adik Inst Technol, Dept Comp Engn, Navi Mumbai, MH, India.
   [Chavan, Pallavi] Ramrao Adik Inst Technol, Dept Informat Technol, Navi Mumbai, MH, India.
   [Ghonghe, Mangesh] Sandip Inst Technol & Res Ctr, Dept Comp Engn, Nasik, MH, India.
RP Chavan, P (corresponding author), Ramrao Adik Inst Technol, Dept Informat Technol, Navi Mumbai, MH, India.
RI chavan, pallavi Vijay/P-2640-2017
OI chavan, pallavi Vijay/0000-0002-1507-274X; Ghonge,
   Mangesh/0009-0008-3573-8458; Ghonge, Dr. Mangesh M./0000-0003-0140-4827
CR Abramova S., 2016, P 37 INT C INFORM SY
   Atzei N, 2017, LECT NOTES COMPUT SC, V10204, P164, DOI 10.1007/978-3-662-54455-6_8
   Bellini E, 2020, IEEE ACCESS, V8, P21127, DOI 10.1109/ACCESS.2020.2969820
   Abdo JB, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4148
   Carlos P, 2020, INT C FUNDAMENTAL AP
   Cho HH, 2014, IEEE ACCESS, V2, P1196, DOI 10.1109/ACCESS.2014.2357435
   Croman Kyle, 2016, SCALING DECENTRALIZE
   Crosby M, 2016, APPL INNOV REV, V2, P6, DOI DOI 10.21626/innova/2016.1/01
   Cui P., 2019, Journal of Hardware and Systems Security, V3, P338, DOI DOI 10.1007/S41635-019-00079-5
   Dev JA, 2014, CAN CON EL COMP EN
   Firoozjaei MD, 2020, SECUR PRIVACY, V3, DOI 10.1002/spy2.131
   Garriga M, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5992
   Gobierno de M├xico, 2020, TOD QUE DEB SAB COR
   Guo J, 2020, BIG DATA ANALYTICS C, V1117
   Holotiuk F, 2017, WIRTSCHAFTSINF
   Liu YM, 2020, IEEE COMMUN SURV TUT, V22, P1392, DOI 10.1109/COMST.2020.2975911
   Memon RA, 2020, FRONT INFORM TECH EL, V21, P563, DOI 10.1631/FITEE.1800343
   Perumal Sankan S, 2020, VISHWANATH N DEEPA E
   Rappaport TS, 2013, IEEE ACCESS, V1, P335, DOI 10.1109/ACCESS.2013.2260813
   Ren YJ, 2021, MULTIMED TOOLS APPL, V80, P30653, DOI 10.1007/s11042-020-09578-y
   Shi PC, 2021, SOFTWARE PRACT EXPER, V51, P2051, DOI 10.1002/spe.2739
   Singh A, 2020, J NETW COMPUT APPL, V149, DOI 10.1016/j.jnca.2019.102471
   Uriarte RB, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5800
   Walsh C, 2016, ICIS 2016 P
   Wang CX, 2014, IEEE COMMUN MAG, V52, P122, DOI 10.1109/MCOM.2014.6736752
   Xu XL, 2021, SOFTWARE PRACT EXPER, V51, P2015, DOI 10.1002/spe.2749
   Zohar A, 2015, COMMUN ACM, V58, P104, DOI 10.1145/2701411
NR 27
TC 10
Z9 10
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36699
EP 36713
DI 10.1007/s11042-021-11604-6
EA JUL 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000823376700017
DA 2024-07-18
ER

PT J
AU Tiwari, T
   Saraswat, M
AF Tiwari, Twinkle
   Saraswat, Mukesh
TI A new modified-unet deep learning model for semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; UNet; Vehicle segmentation; Batch normalization
AB Segmentation of vehicles into images of road traffic with congested and unstructured traffic patterns is a challenging task. For the same, this paper presents a modified-UNet which segments the input image by the sequential encoding and decoding steps. The modified-UNet uses a number of convolutions, inception modules, and batch normalization to encode the image into feature map. The extracted map is decoded into segmented image by performing the transposed convolutions in different layers. To validate the performance, two publicly available datasets have been considered, namely autorickshaw and IDD-Lite. Performance of the proposed model has been analyzed against state-of-the-art segmentation models in terms of seven parameters, namely intersection over union, accuracy, error, specificity, sensitivity, F1-score, and correlation-coefficient. Furthermore, ablation experiments have also been conducted. Experimental results depict that the proposed model outperforms the other models and reported the best IoU-Scores of 0.82 and 0.61 on autorickshaw and IDD-Lite datasets respectively.
C1 [Tiwari, Twinkle; Saraswat, Mukesh] Jaypee Inst Informat Technol, Noida, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Tiwari, T (corresponding author), Jaypee Inst Informat Technol, Noida, India.
EM twinkletiwari009@gmail.com; saraswatmukesh@gmail.com
CR [Anonymous], 2014, INT C LEARN REPR
   Aydogdu MF, 2017, IEEE INT C SEMANT CO, P372, DOI 10.1109/ICSC.2017.61
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Buric M, 2018, P INT C COMP SCI COM, P319
   BYEON W, 2015, PROC CVPR IEEE, P3547, DOI DOI 10.1109/CVPR.2015.7298977
   Chen C, 2021, IEEE T CIRCUITS SYST
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P3995, DOI 10.1109/TIP.2021.3068644
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P2350, DOI 10.1109/TIP.2021.3052069
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chu WQ, 2018, IEEE T IMAGE PROCESS, V27, P432, DOI 10.1109/TIP.2017.2762591
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Druzhkov P. N., 2016, Pattern Recognition and Image Analysis, V26, P9, DOI 10.1134/S1054661816010065
   Fan H, 2018, IEEE T INTELL TRANSP, V19, P3475, DOI 10.1109/TITS.2017.2775628
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Hayou S, 2018, ARXIV 180508266
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong S, 2015, ADV NEUR IN, V28
   Huang ZL, 2018, PROC CVPR IEEE, P7014, DOI 10.1109/CVPR.2018.00733
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lateef F, 2019, NEUROCOMPUTING, V338, P321, DOI 10.1016/j.neucom.2019.02.003
   Li HR, 2021, MEMET COMPUT, V13, P1, DOI 10.1007/s12293-021-00328-7
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   LIANG M, 2015, PROC CVPR IEEE, P3367, DOI [10.1109/CVPR.2015.7298958, DOI 10.1109/CVPR.2015.7298958]
   Maysam Shahedi JDDMBF, 2020, STUDY U NET LIMITATI
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Meyes R, 2019, ARXIV 190108644
   Nikolenko S., 2018, Deep Learning
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Paszke A., 2016, ARXIV160602147
   Pohlen T, 2017, PROC CVPR IEEE, P3309, DOI 10.1109/CVPR.2017.353
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Reddy DR, 1975, 1974 IEEE S
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sirignano J, 2019, ARXIV 190704108
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Valada Abhinav, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4644, DOI 10.1109/ICRA.2017.7989540
   Wang C, 2019, IEEE T INTELL TRANSP
   Wang GT, 2021, PROC CVPR IEEE, P15114, DOI 10.1109/CVPR46437.2021.01487
   Wu ZY, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108212
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xue HJ, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3203
   Zabihollahy F, 2019, MED PHYS, V46, P1740, DOI 10.1002/mp.13436
   Zhang M. R., 2019, Advances in Neural Information Processing Systems, P1, DOI DOI 10.48550/ARXIV.1907
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
NR 54
TC 8
Z9 8
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3605
EP 3625
DI 10.1007/s11042-022-13230-2
EA JUL 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000823376700003
DA 2024-07-18
ER

PT J
AU Mu, M
   Dohan, M
   Goodyear, A
   Hill, G
   Johns, C
   Mauthe, A
AF Mu, Mu
   Dohan, Murtada
   Goodyear, Alison
   Hill, Gary
   Johns, Cleyon
   Mauthe, Andreas
TI User attention and behaviour in virtual reality art encounter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Virtual reality; VR abstract painting; User attention; Eye-tracking;
   Machine learning
AB With the proliferation of consumer virtual reality (VR) headsets and creative tools, content creators are experimenting with new forms of interactive audience experience using immersive media. Understanding user attention and behaviours in virtual environment can greatly inform the creative processes in VR. We developed an abstract VR painting and an experimentation system to study audience art encounters through eye gaze and movement tracking. The data from a user experiment with 35 participants reveal a range of user activity patterns in art exploration. Deep learning models are used to study the connections between the behavioural data and the audience's background. The work also introduced new integrated methods to visualise user attention for content creators.
C1 [Mu, Mu; Dohan, Murtada; Johns, Cleyon] Univ Northampton, Univ Dr, Northampton NN1 5PH, England.
   [Goodyear, Alison] Alison Goodyear Artist, Bedford MK40 1QE, England.
   [Hill, Gary] Cranfield Univ, Coll Rd, Cranfield MK43 0AL, Beds, England.
   [Mauthe, Andreas] Univ Koblenz Landau, Univ Str 1, D-56070 Koblenz, Germany.
C3 University of Northampton; Cranfield University; University of Koblenz &
   Landau
RP Mu, M (corresponding author), Univ Northampton, Univ Dr, Northampton NN1 5PH, England.
EM mu.mu@northampton.ac.uk; murtada.dohan@northampton.ac.uk;
   alisongoodyear@me.com; gary.hill@cranfield.ac.uk;
   cleyon.johns@northampton.ac.uk; mauthe@uni-koblenz.de
RI Dohan, Murtada/AAB-8237-2019
OI Dohan, Murtada/0000-0003-4119-9055; Mu, Mu/0000-0003-1931-7959
FU UK Engineering and Physical Sciences Research Council (EPSRC)
   [EP/P033202/1]; EPSRC [EP/P033202/1] Funding Source: UKRI
FX Mu Mu received funding from UK Engineering and Physical Sciences
   Research Council (EPSRC) under Grant Agreement EP/P033202/1.
CR Akinyelu AA, 2020, IEEE ACCESS, V8, P142581, DOI 10.1109/ACCESS.2020.3013540
   alisongoodyear, GOODYEAR PHYGITAL WO
   [Anonymous], The Python Deep Learning library
   [Anonymous], theguardian
   Battisti F, 2018, EUR W VIS INF PROCES
   Caserman P, 2019, VIRTUAL REAL-LONDON, V23, P155, DOI 10.1007/s10055-018-0374-z
   Chambel T, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P2109, DOI 10.1145/3240508.3243718
   Chen SY, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P525, DOI 10.1109/VR.2018.8446494
   Dohan M, 2019, TVX 2019: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P167, DOI 10.1145/3317697.3325118
   Eads JR., GREAT 3D WAVE
   getfove, FOVE FOVE 0
   github, TILT BRUSH TOOLK
   Goodyear A, 2019, ADJUNCT P ACM INT C, DOI [10.6084/m9.figshare.c.4515005.v4, DOI 10.6084/M9.FIGSHARE.C.4515005.V4]
   Grant D., AM VIRTUAL MUSEUMS T
   Grau O, 2003, LEONARDO SER, P1
   Hammady R, 2020, MULTIMED TOOLS APPL, V79, P3465, DOI 10.1007/s11042-019-08026-w
   Hashemi SH, 2018, NEW REV HYPERMEDIA M, V24, P228, DOI 10.1080/13614568.2018.1525436
   Hayes J, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281620
   Heidenreich SM, 2011, EMPIR STUD ARTS, V29, P51, DOI 10.2190/EM.29.1.d
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Kevin S, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281587
   Kim DY, 2018, NEUROCOMPUTING, V280, P56, DOI 10.1016/j.neucom.2017.07.069
   Lécuyer A, 2017, IEEE COMPUT GRAPH, V37, P20, DOI 10.1109/MCG.2017.14
   Lin EL., GIRL PEARL EARRING 3
   Lopez S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300787
   Lugrin J.-L., 2018, P 10 INT C VIRTUAL W, P1
   Mack K., 2017, P ACM SIGGRAPH 2017, P1
   Marwecki S, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P777, DOI 10.1145/3332165.3347919
   mkgallery, GOODYEAR PAINT PARK
   Mu M., VIRTUAL REALITY USER
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Parker E, 2020, CONVERGENCE-US, V26, P1159, DOI 10.1177/1354856519897251
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Pfeil K, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225157
   Pfeuffer K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300340
   Rahman Y, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3358752
   Raz G, 2019, PALGRAVE HANDBOOK OF THE PHILOSOPHY OF FILM AND MOTION PICTURES, P995, DOI 10.1007/978-3-030-19601-1_42
   Sargezeh BA, 2019, PHYSIOL BEHAV, V206, P43, DOI 10.1016/j.physbeh.2019.03.023
   Smith LF, 2017, PSYCHOL AESTHET CREA, V11, P77, DOI 10.1037/aca0000049
   Sonar HA, 2020, SOFT ROBOT, V7, P22, DOI 10.1089/soro.2019.0013
   tensorflow, TENSORFLOW END TO EN
   thedali, MUSEUM SD DREAMS DAL
   Tobii, REAL VIRT VIS DYN FO
   vive, HTC VIVE PRO EYE
   Zhou H, 2019, SIGGRAPH ASIA 2019 DOCTORAL CONSORTIUM (SA '19), DOI 10.1145/3366344.3366441
   Zhu R, 2019, IEEE ACCESS, V7, P75490, DOI 10.1109/ACCESS.2019.2922104
NR 46
TC 5
Z9 5
U1 5
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 JUL 4
PY 2022
DI 10.1007/s11042-022-13365-2
EA JUL 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q6XQ
UT WOS:000820564000004
OA Green Published, hybrid, Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Cifuentes, J
   Olarte, F
AF Cifuentes, Jenny
   Olarte, Fredy
TI A macro perspective of the perceptions of the education system via topic
   modelling analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Textual content analysis; Stakeholder perception; Text mining; Topic
   modelling; Educational system
ID RESPONSES
AB Education quality has become an important issue and has received considerable attention around the world, especially due to its relevant repercussions on the socio-economical development of society. In recent years, many nations have realized the need for a highly skilled workforce to thrive in the emerging knowledge-based economy. They have consequently adopted strategies to identify the lines of action to improve the education quality. In response to the government's efforts to improve the education quality in Colombia, this study examines the current perceptions of the education system from the perspective of key local stakeholders. Therefore, we used a survey that contained open-ended questions to collect information about the limitations and difficulties of the education process for several groups of participants. The collected answers were categorized into a variety of topics using a Latent Dirichlet Allocation based model. Consequently, the students', teachers' and parents' answers were analyzed separately to obtain a general landscape of the perceptions of the education system. Evaluation metrics, such as topic coherence, were quantitatively analyzed to assess the modelling performance. In addition, a methodology for the hyper-parameters setting and the final topic labelling was presented. The results suggest that topic modelling strategies are a viable alternative to identify strategic lines of action and to obtain a macro-perspective of the perceptions of the education system.
C1 [Cifuentes, Jenny] Univ Pontificia Comillas, ICADE, Fac Econ & Business Adm, Calle Alberto Aguilera 23, Madrid 28015, Spain.
   [Cifuentes, Jenny] Univ Pontificia Comillas, Dept Quantitat Methods, Calle Alberto Aguilera 23, Madrid 28015, Spain.
   [Olarte, Fredy] Univ Nacl Colombia, Elect & Elect Engn Dept, Carrera 45 26-85, Bogota, Colombia.
C3 Comillas Pontifical University; Comillas Pontifical University;
   Universidad Nacional de Colombia
RP Cifuentes, J (corresponding author), Univ Pontificia Comillas, ICADE, Fac Econ & Business Adm, Calle Alberto Aguilera 23, Madrid 28015, Spain.; Cifuentes, J (corresponding author), Univ Pontificia Comillas, Dept Quantitat Methods, Calle Alberto Aguilera 23, Madrid 28015, Spain.
EM jacifuentesq@gmail.com; faolarted@unal.edu.co
OI Cifuentes Quintero, Jenny/0000-0001-7421-291X
CR Bankauskaite V, 2003, INT J QUAL HEALTH C, V15, P23, DOI 10.1093/intqhc/15.1.23
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Buenaño-Fernandez D, 2020, IEEE ACCESS, V8, P35318, DOI 10.1109/ACCESS.2020.2974983
   Cheng X, 2022, J INF SCI, V48, P304, DOI 10.1177/0165551520954674
   El Akrouchi M, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106650
   Erkens M, 2016, INT J COMP-SUPP COLL, V11, P387, DOI 10.1007/s11412-016-9243-5
   Faherty V.E., 2009, Wordcraft: applied qualitative data analysis (QDA): Tools for public and voluntary social services
   Jelodar H, 2019, MULTIMED TOOLS APPL, V78, P15169, DOI 10.1007/s11042-018-6894-4
   Kumari R, 2021, J INF SCI, V47, P658, DOI 10.1177/0165551519887878
   Kyriakopoulou A., 2013, PROC 17 PANHELLENIC, P180
   Liu L, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3252-8
   Lu Y, 2011, INFORM RETRIEVAL, V14, P178, DOI 10.1007/s10791-010-9141-9
   Mahmoud M, 2021, INT J INF LEARN TECH, V38, P33, DOI 10.1108/IJILT-05-2020-0081
   Mohammadi E, 2022, J INF SCI, V48, P44, DOI 10.1177/0165551520932855
   Nanda G, 2021, IEEE T LEARN TECHNOL, V14, P146, DOI 10.1109/TLT.2021.3064798
   Nguyen D. Q., 2015, Transactions of the Association for Computational Linguistics, V3, P299, DOI DOI 10.1162/TACL_A_00140
   Pope C, 2002, QUAL SAF HEALTH CARE, V11, P148, DOI 10.1136/qhc.11.2.148
   Roberts ME, 2014, AM J POLIT SCI, V58, P1064, DOI 10.1111/ajps.12103
   Romanowski M.H., 2013, INT J ED, V5, P108
   Runge CE, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114755
   ten Kleij F, 2003, FOOD QUAL PREFER, V14, P43, DOI 10.1016/S0950-3293(02)00011-3
   TINSLEY HEA, 1975, J COUNS PSYCHOL, V22, P358, DOI 10.1037/h0076640
   Tutubalina E, 2018, MULTIMED TOOLS APPL, V77, P4791, DOI 10.1007/s11042-017-5336-z
   Whittle S, 2007, EDUC HEALTH, V20, P7
   Yu WR, 2013, IEEE DATA MINING, P1271, DOI 10.1109/ICDM.2013.32
   Zuo Y, 2016, KNOWL INF SYST, V48, P379, DOI 10.1007/s10115-015-0882-z
NR 26
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 1783
EP 1820
DI 10.1007/s11042-022-13202-6
EA JUN 2022
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000809315600003
PM 35702681
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Rusia, MK
   Singh, DK
AF Rusia, Mayank Kumar
   Singh, Dushyant Kumar
TI A comprehensive survey on techniques to handle face identity threats:
   challenges and opportunities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Face recognition; Authentication; Computer vision; Machine
   learning; Deep learning; Image processing
ID FACIAL EXPRESSION RECOGNITION; PRESENTATION ATTACK DETECTION;
   SINGULAR-VALUE DECOMPOSITION; PLASTIC-SURGERY; OCCLUSION DETECTION;
   LANDMARK DETECTION; SPOOFING DETECTION; FUSION; 3D; FEATURES
AB The human face is considered the prime entity in recognizing a person's identity in our society. Henceforth, the importance of face recognition systems is growing higher for many applications. Facial recognition systems are in huge demand, next to fingerprint-based systems. Face-biometric has a highly dominant role in various applications such as border surveillance, forensic investigations, crime detection, access management systems, information security, and many more. Facial recognition systems deliver highly meticulous results in every of these application domains. However, the face identity threats are evenly growing at the same rate and posing severe concerns on the use of face-biometrics. This paper significantly explores all types of face recognition techniques, their accountable challenges, and threats to face-biometric-based identity recognition. This survey paper proposes a novel taxonomy to represent potential face identity threats. These threats are described, considering their impact on the facial recognition system. State-of-the-art approaches available in the literature are discussed here to mitigate the impact of the identified threats. This paper provides a comparative analysis of countermeasure techniques focusing on their performance on different face datasets for each identified threat. This paper also highlights the characteristics of the benchmark face datasets representing unconstrained scenarios. In addition, we also discuss research gaps and future opportunities to tackle the facial identity threats for the information of researchers and readers.
C1 [Rusia, Mayank Kumar; Singh, Dushyant Kumar] MNNIT Allahabad, CSED, Prayagraj, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Rusia, MK (corresponding author), MNNIT Allahabad, CSED, Prayagraj, Uttar Pradesh, India.
EM mayank.qip18@mnnit.ac.in; dushyant@mnnit.ac.in
RI Singh, Dushyant Kumar/AAD-8512-2021
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   Agarwal V, 2018, NEURAL COMPUT APPL, V30, P2643, DOI 10.1007/s00521-017-2874-2
   Al Jazaety M, 2020, IET BIOMETRICS, V9, P25, DOI 10.1049/iet-bmt.2019.0081
   Al-Dabagh M.Z. N., 2018, International Journal of Research and Engineering, V5, P335
   Albiol A, 2008, PATTERN RECOGN LETT, V29, P1537, DOI 10.1016/j.patrec.2008.03.017
   Ali ASO, 2016, IET COMPUT VIS, V10, P342, DOI 10.1049/iet-cvi.2014.0263
   Ansari MA, 2021, MULTIMED TOOLS APPL, V80, P8759, DOI 10.1007/s11042-020-10103-4
   Anzar S, 2020, AIP C P, V2222, P030017
   Arya K. V., 2019, Computational Intelligence: Theories, Applications and Future DirectionsVolume II. ICCI-2017. Advances in Intelligent Systems and Computing (AISC 799), P645, DOI 10.1007/978-981-13-1135-2_49
   Ashir AM, 2020, NEURAL COMPUT APPL, V32, P6295, DOI 10.1007/s00521-019-04138-4
   Astawa I., 2017, TELKOMNIKA, V15, P1894
   Bahreini K, 2019, MULTIMED TOOLS APPL, V78, P18943, DOI 10.1007/s11042-019-7250-z
   Ballihi L, 2012, IEEE T INF FOREN SEC, V7, P1766, DOI 10.1109/TIFS.2012.2209876
   Bargshady G, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106805
   Bhowmik MK, 2019, EXPERT SYST APPL, V116, P96, DOI 10.1016/j.eswa.2018.08.047
   Bodor R, 2007, J INTELL ROBOT SYST, V50, P257, DOI 10.1007/s10846-007-9164-7
   Bolle R. M., 2013, Guide to biometrics
   Borude PR, 2015, PROCEDIA COMPUT SCI, V49, P2, DOI 10.1016/j.procs.2015.04.220
   Bouguila J, 2020, J STOMATOL ORAL MAXI, V121, P696, DOI 10.1016/j.jormas.2020.06.007
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Bourlai T., 2012, Proceedings of the 2012 IEEE International Conference on Intelligence and Security Informatics. Cyberspace, Border, and Immigration Securities (ISI 2012), P196, DOI 10.1109/ISI.2012.6284307
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Buddharaju P, 2007, IEEE T PATTERN ANAL, V29, P613, DOI 10.1109/TPAMI.2007.1007
   Chang HW, 2018, PROC CVPR IEEE, P40, DOI 10.1109/CVPR.2018.00012
   Chen CJ, 2013, INT CONF BIOMETR
   Chen CJ, 2016, INFORM FUSION, V32, P80, DOI 10.1016/j.inffus.2015.09.005
   Chen FM, 2019, IET BIOMETRICS, V8, P369, DOI 10.1049/iet-bmt.2018.5235
   Chen Z, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107118
   Choi J, 2012, PROC SPIE, V8371, DOI 10.1117/12.920330
   Dadi H.S., 2016, IOSR J. Electron. Commun.Eng., V11, P34, DOI 10.9790/2834-1104013444
   Dagnes N, 2018, MACH VISION APPL, V29, P789, DOI 10.1007/s00138-018-0933-z
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dantcheva A, 2012, IEEE INT C BIOM THEO
   De Marsico M, 2015, PATTERN RECOGN, V48, P1261, DOI 10.1016/j.patcog.2014.10.004
   Deeb A, 2020, ADV INTELLIGENT SYST, P197, DOI DOI 10.1007/978-981-15-3383-9_18
   Deng WH, 2018, PATTERN RECOGN, V77, P426, DOI 10.1016/j.patcog.2017.10.020
   Dey S.K., 2021, P INT C TRENDS COMPU, V1309, P603, DOI DOI 10.1007/978-981-33-4673-449
   Dhekane M, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417560183
   Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089
   Nguyen DL, 2020, IEEE COMPUT SOC CONF, P3548, DOI 10.1109/CVPRW50498.2020.00415
   Du LS, 2019, NEUROCOMPUTING, V340, P133, DOI 10.1016/j.neucom.2019.02.053
   Duan QY, 2021, IEEE T NEUR NET LEAR, V32, P214, DOI 10.1109/TNNLS.2020.2978127
   Eckert ML, 2013, IEEE INT WORKSH MULT, P434, DOI 10.1109/MMSP.2013.6659328
   El-Said SA, 2014, INT J COMPUT APPL T, V49, P352, DOI 10.1504/IJCAT.2014.062371
   Faraji MR, 2015, IET COMPUT VIS, V9, P390, DOI 10.1049/iet-cvi.2014.0200
   Fassold H, 2015, PROC SPIE, V9400, DOI 10.1117/12.2083201
   Feng YC, 2008, PROC SPIE, V6944, DOI 10.1117/12.778652
   Fourati E, 2020, MULTIMED TOOLS APPL, V79, P865, DOI 10.1007/s11042-019-08115-w
   Gao F, 2021, NEURAL COMPUT APPL, V33, P3035, DOI 10.1007/s00521-020-05167-0
   Garcia DC, 2015, IEEE T INF FOREN SEC, V10, P778, DOI 10.1109/TIFS.2015.2411394
   George AM, 2021, INT J PAVEMENT ENG, V22, P181, DOI 10.1080/10298436.2019.1587437
   Gerig T, 2018, IEEE INT CONF AUTOMA, P75, DOI 10.1109/FG.2018.00021
   Goodfellow IJ, 2013, NEURAL NETWORKS
   Grattan KTV, 2013, 2013 IEEE 6TH INTERNATIONAL CONFERENCE ON ADVANCED INFOCOMM TECHNOLOGY (ICAIT), P1, DOI 10.1109/ICAIT.2013.6621468
   Guo GD, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102805
   Gupta K, 2020, APPL INTELL, V50, P1086, DOI 10.1007/s10489-019-01579-1
   Hancock KJ, 2008, BRIT J PSYCHOL, V99, P45, DOI 10.1348/000712607X199981
   He MJ, 2019, IEEE INT CONF AUTOMA, P383, DOI 10.1109/fg.2019.8756575
   Hermosilla G, 2017, INTELL AUTOM SOFT CO, V23, P1, DOI 10.1080/10798587.2015.1110288
   Hermosilla G, 2012, PATTERN RECOGN, V45, P2445, DOI 10.1016/j.patcog.2012.01.001
   Hernandez-Ortega J., 2019, Handbook of Biometric Anti-Spoofing, P187
   Hu CH, 2017, PATTERN RECOGN, V64, P60, DOI 10.1016/j.patcog.2016.10.029
   Huang MX, 2016, IEEE T AFFECT COMPUT, V7, P360, DOI 10.1109/TAFFC.2015.2495222
   Izenman AJ, 2013, MODERN MULTIVARIATE
   Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013
   Jang J, 2019, IEEE T CYBERNETICS, V49, P616, DOI 10.1109/TCYB.2017.2782661
   Jia S, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.11.004
   Jia S, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107032
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Jignesh Chowdary G., 2020, Big Data Analytics. 8th International Conference, BDA 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12581), P81, DOI 10.1007/978-3-030-66665-1_6
   Jillela R., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P402, DOI 10.1109/BTAS.2012.6374607
   Kak SF., 2018, EURASIAN J SCI ENG, V4, P157, DOI DOI 10.23918/EAJSE.V4I1SIP157
   Karve S, 2018, 2018 INT C COMMUNICA, P1
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Kepesiova Z, 2018, 2018 CYBERNETICS INF, P1
   Kolkur S, 2017, ADV INTEL SYS RES, V137, P324
   Kose N, 2014, IMAGE VISION COMPUT, V32, P779, DOI 10.1016/j.imavis.2014.06.003
   Krishnapriya K. S., 2020, IEEE Transactions on Technology and Society, V1, P8, DOI 10.1109/TTS.2020.2974996
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Labati Ruggero Donida, 2016, ACM Computing Surveys, V49, DOI 10.1145/2933241
   Lahasan B, 2019, ARTIF INTELL REV, V52, P949, DOI 10.1007/s10462-017-9578-y
   Le T. H. N., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P91, DOI 10.1109/BTAS.2012.6374562
   Li JS, 2018, IEEE T IMAGE PROCESS, V27, P4651, DOI 10.1109/TIP.2018.2839521
   Li L, 2018, J VIS COMMUN IMAGE R, V54, P182, DOI 10.1016/j.jvcir.2018.05.009
   Li L, 2018, IET BIOMETRICS, V7, P3, DOI 10.1049/iet-bmt.2017.0089
   Li TP, 2019, MULTIMED TOOLS APPL, V78, P21963, DOI 10.1007/s11042-019-7414-x
   Li YN, 2019, IEEE NETWORK, V33, P111, DOI [10.1109/MNET.2019.1800271, 10.1109/COASE.2019.8843280, 10.1109/coase.2019.8843280]
   Lian YY, 2020, INT WIREL COMMUN, P1394, DOI 10.1109/IWCMC48107.2020.9148064
   Lin L, 2020, HUMAN CENTRIC VISUAL, P2945
   Liu N, 2006, FACE RECOGNITION WEI
   Liu X., 2012, COMPUTER VISION ACCV, P565
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Lu D, 2019, NEUROCOMPUTING, V365, P113, DOI 10.1016/j.neucom.2019.07.008
   Luo Y, 2017, IET COMPUT VIS, V11, P550, DOI 10.1049/iet-cvi.2016.0295
   Mahalingam G, 2014, IEEE T INF FOREN SEC, V9, P2180, DOI 10.1109/TIFS.2014.2361479
   Mahmood Z, 2017, FRACTALS, V25, DOI 10.1142/S0218348X17500256
   Makhija Y, 2019, ADV INTELL SYST COMP, V741, P1189, DOI 10.1007/978-981-13-0761-4_110
   Mancini C, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10110794
   Marcel S., 2019, Handbook of Biometric Anti-Spoofing-Presentation Attack Detection
   Martin V, 2019, MULTIMED TOOLS APPL, V78, P6309, DOI 10.1007/s11042-018-6311-z
   Meytlis M, 2007, IEEE T PATTERN ANAL, V29, P1262, DOI 10.1109/TPAMI.2007.1033
   Miao Y, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3311747
   Minaee S., 2019, ARXIV191200271
   Mohammed Bayan Omar, 2019, IEIE Transactions on Smart Processing & Computing, V8, P71, DOI 10.5573/IEIESPC.2019.8.1.071
   Moore J, 2017, COMMUN MONOGR, V84, P258, DOI 10.1080/03637751.2017.1315891
   Mortezaie Z., 2019, JORDAN J COMPUT INFO, V5, P87, DOI DOI 10.5455/JJCIT.71-1554841475
   Mostafa E, 2013, COMPUT VIS IMAGE UND, V117, P1689, DOI 10.1016/j.cviu.2013.07.010
   Nappi M, 2016, IMAGE VISION COMPUT, V54, P71, DOI 10.1016/j.imavis.2016.08.012
   Neal TJ, 2016, J PATTERN RECOGNIT R, V11, P74, DOI 10.13176/11.764
   Nguyen TD, 2008, 2008 8 IEEE INT C AU, P17
   O'Toole AJ, 1999, VISION RES, V39, P3145, DOI 10.1016/S0042-6989(99)00034-6
   Paone JR, 2014, IEEE T INF FOREN SEC, V9, P285, DOI 10.1109/TIFS.2013.2296373
   Park U, 2010, IEEE T PATTERN ANAL, V32, P947, DOI 10.1109/TPAMI.2010.14
   Peng F, 2018, MULTIMED TOOLS APPL, V77, P8883, DOI 10.1007/s11042-017-4780-0
   Pereira TD, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-2
   Perveen N, 2018, IEEE T IMAGE PROCESS, V27, P5575, DOI 10.1109/TIP.2018.2856373
   Phillips P. J., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P185, DOI 10.1109/FG.2011.5771395
   Prasad PS, 2020, LECT NOTES ELECTR EN, V570, P419, DOI 10.1007/978-981-13-8715-9_50
   Raghavendra R, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P555, DOI 10.1109/BTAS.2017.8272742
   Ramachandra R, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3038924
   Reddy GV, 2020, COGN SYST RES, V62, P23, DOI 10.1016/j.cogsys.2020.03.002
   Rehman YAU, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103858
   Rehman YAU, 2020, EXPERT SYST APPL, V142, DOI 10.1016/j.eswa.2019.113002
   Revina IM, 2021, J KING SAUD UNIV-COM, V33, P619, DOI 10.1016/j.jksuci.2018.09.002
   Rodríguez-Gómez P, 2020, SOC COGN AFFECT NEUR, V15, P928, DOI 10.1093/scan/nsaa117
   Roy SD, 2020, IEEE T CIRCUITS SYST
   Rusia Mayank Kumar, 2021, International Journal of Information Technology, P2419, DOI 10.1007/s41870-021-00803-x
   Rusia MK, 2019, 2019 FIFTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP 2019), P612, DOI 10.1109/ICIIP47207.2019.8985867
   Sabharwal Tanupreet, 2021, International Journal of Information Technology, V13, P391, DOI 10.1007/s41870-020-00566-x
   Sabharwal T, 2019, ARTIF INTELL REV, V52, P1009, DOI 10.1007/s10462-018-9660-0
   Saha P, 2019, MULTIMED TOOLS APPL, V78, P23329, DOI 10.1007/s11042-019-7596-2
   Sánchez-Lozano E, 2018, IEEE T PATTERN ANAL, V40, P2037, DOI 10.1109/TPAMI.2017.2745568
   Sawant MM, 2019, ARTIF INTELL REV, V52, P981, DOI 10.1007/s10462-018-9661-z
   Scherhag U, 2019, IEEE ACCESS, V7, P23012, DOI 10.1109/ACCESS.2019.2899367
   Schuckers S, 2016, IMAGE VISION COMPUT, V55, P26, DOI 10.1016/j.imavis.2016.03.016
   Seibold C, 2017, LECT NOTES COMPUT SC, V10431, P107, DOI 10.1007/978-3-319-64185-0_9
   Sepas-Moghaddam A, 2018, IEEE T INF FOREN SEC, V13, P1696, DOI 10.1109/TIFS.2018.2799427
   Serengil S.I., 2020, 2020 INNOVATIONS INT, P1, DOI DOI 10.1109/ASYU50717.2020.9259802
   Sharma S, 2020, MULTIMED TOOLS APPL, V79, P26517, DOI 10.1007/s11042-020-09331-5
   Sharma V, 2016, ARXIV
   Shi Y, 2020, NEURAL COMPUT APPL, V32, P9267, DOI 10.1007/s00521-019-04437-w
   Shinwari AR., 2020, TECHNOLOGY, V2, P85
   Shirley CP, 2021, MULTIDIM SYST SIGN P, V32, P189, DOI 10.1007/s11045-020-00733-0
   Singh Dushyant Kumar, 2020, Procedia Computer Science, V171, P350, DOI 10.1016/j.procs.2020.04.036
   Singh D. K., 2016, Indian J Sci Technol, V9, DOI DOI 10.17485/ijst/2016/v9i33/87795
   Singh DK., 2016, International Journal of Control Theory and Applications, V9, P173
   Singh Maneet, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P97, DOI 10.1109/TBIOM.2019.2903860
   Singh R, 2010, IEEE T INF FOREN SEC, V5, P441, DOI 10.1109/TIFS.2010.2054083
   Soltanpour S, 2017, PATTERN RECOGN, V72, P391, DOI 10.1016/j.patcog.2017.08.003
   Song X, 2019, PATTERN RECOGN, V85, P220, DOI 10.1016/j.patcog.2018.08.019
   Spencer-Oatey H, 2007, J PRAGMATICS, V39, P639, DOI 10.1016/j.pragma.2006.12.004
   Srinivas N, 2012, IEEE T INF FOREN SEC, V7, P1536, DOI 10.1109/TIFS.2012.2206027
   Sun J, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3282833
   Surekha Samsani, 2020, Advances in Electrical and Computer Technologies. Select Proceedings of ICAECT 2019. Lecture Notes in Electrical Engineering (LNEE 672), P453, DOI 10.1007/978-981-15-5558-9_41
   Tamilselvi M., 2018, INT J PURE APPL MATH, V118, P831
   Tamrakar D, 2015, PROCEDIA COMPUT SCI, V54, P491, DOI 10.1016/j.procs.2015.06.056
   Tan HL, 2014, IET COMPUT VIS, V8, P224, DOI 10.1049/iet-cvi.2012.0302
   Tanaka JW, 2009, COGN AFFECT BEHAV NE, V9, P122, DOI 10.3758/CABN.9.1.122
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Ueda S, 2010, PERCEPTION, V39, P260, DOI 10.1068/p6634
   Vijayan V, 2011, 2011 INT JOINT C BIO, P17
   Wan J, 2020, NEURAL NETWORKS, V123, P261, DOI 10.1016/j.neunet.2019.12.009
   Wang DS, 2021, J INTELL SYST, V30, P18, DOI 10.1515/jisys-2019-0114
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   Wang QC, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102663
   Waseem Muhammad, 2020, 2020 International Conference on Computational Intelligence (ICCI), P51, DOI 10.1109/ICCI51257.2020.9247836
   Winant D, 2019, AIML, P70
   Wu Y, 2019, INT J COMPUT VISION, V127, P115, DOI 10.1007/s11263-018-1097-z
   Wu Y, 2017, PROC CVPR IEEE, P5719, DOI 10.1109/CVPR.2017.606
   Xiao QK, 2018, MULTIMED TOOLS APPL, V77, P6955, DOI 10.1007/s11042-017-4614-0
   Xie Z, 2020, INT C INT INT SYST A
   Xing-hua Lu, 2020, Multimedia Technology and Enhanced Learning. Second EAI International Conference, ICMTEL 2020. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 326), P159, DOI 10.1007/978-3-030-51100-5_14
   Xue ZW, 2020, IEEE INT CONF ELECTR, P362, DOI 10.1109/iceiec49280.2020.9152335
   Yang C, 2019, COMPUTING, V101, P605, DOI 10.1007/s00607-019-00706-7
   Yang C, 2020, IMAGE VISION COMPUT, V100, DOI 10.1016/j.imavis.2020.103945
   Yao YQ, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3131345
   Yu CY, 2019, IMAGE VISION COMPUT, V89, P88, DOI 10.1016/j.imavis.2019.06.009
   YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59
   Zafeiriou S, 2012, IEEE T NEUR NET LEAR, V23, P526, DOI 10.1109/TNNLS.2011.2182058
   Zangeneh E, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112854
   Zavan FHD, 2019, PATTERN RECOGN LETT, V123, P104, DOI 10.1016/j.patrec.2018.09.023
   Zeng JJ, 2018, IEEE T IMAGE PROCESS, V27, P2096, DOI 10.1109/TIP.2017.2784571
   Zhang GY, 2018, MULTIMED TOOLS APPL, V77, P7171, DOI 10.1007/s11042-017-4627-8
   Zhang LG, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3158369
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zhang TP, 2009, IEEE T IMAGE PROCESS, V18, P2599, DOI 10.1109/TIP.2009.2028255
   Zhang X, 2017, IEEE COMPUT SOC CONF, P2299, DOI 10.1109/CVPRW.2017.284
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhou S, 2018, HUM-CENT COMPUT INFO, V8, DOI 10.1186/s13673-018-0157-2
   Zuo KJ, 2019, PLAST RECONSTR SURG, V143, p1298E, DOI 10.1097/PRS.0000000000005673
NR 192
TC 17
Z9 17
U1 8
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 1669
EP 1748
DI 10.1007/s11042-022-13248-6
EA JUN 2022
PG 80
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000808527500004
PM 35702682
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Agarwal, S
   Mehta, S
AF Agarwal, Sakshi
   Mehta, Shikha
TI GNPA: a hybrid model for social influence maximization in dynamic
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Social network; Influence maximization; Genetic algorithm; Genetic
   network programming; Apriori algorithm; Graph theory
ID FEATURE-SELECTION; ALGORITHM; CLASSIFICATION; OPTIMIZATION; EFFICIENT
AB With the growing size of online social communities, influence propagation in social networks has become a hot topic of the research. Most of the studies in this area are based on the assumption that the structure of the social network is static and does not change during the information spread process. However, real-world social networks are dynamic. Modeling this continuous dynamic behavior of social networks is a challenge that must be tackled. This paper proposes a hybrid Genetic Network Programming with Apriori algorithm (GNPA) for Influence Maximization (IM) in social networks. Proposed GNPA is a meta-heuristic based optimization algorithm that handles the dynamicity, i.e. user attribute values or connection between users that changes with time. The working of GNPA is divided into 5 steps. It begins with the identification of the initial population of seeds using discounted degree method. Next, it predicts the future changes using the Apriori algorithm and updates the network accordingly. After updating the network dynamics, the influence score is estimated using the local consistent Factorization machines for each edge of the network. Finally, the diffusion score of each individual of the population is calculated using a linear cascade model. After the completion of all the above steps, the population is updated by replacing the weak individuals with new individuals using mutation and crossover, which is the last step of GNPA. The efficacy of GNPA is evaluated over two real and two synthetic datasets with low out-degree ratio and high out-degree ratio. Experimental results demonstrated that GNPA is able to predict the changing behavior of the users close to the actual-time network and improved the influence propagation 16% to 38% as compared to the contemporary counterparts.
C1 [Agarwal, Sakshi; Mehta, Shikha] Jaypee Inst Informat Technol, Comp Sci & Informat Technol, Noida 201309, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Agarwal, S (corresponding author), Jaypee Inst Informat Technol, Comp Sci & Informat Technol, Noida 201309, India.
EM sakshi.officialid@gmail.com; mehtshikha@gmail.com
RI mehta, shikha/AAE-3586-2021
OI mehta, shikha/0000-0002-2601-6284
CR Agarwal Sakshi, 2020, International Conference on Innovative Computing and Communications. Proceedings of ICICC 2019. Advances in Intelligent Systems and Computing (AISC 1087), P97, DOI 10.1007/978-981-15-1286-5_9
   Agarwal S., 2019, IJITEE, V8, P2560
   Agarwal S, 2017, ANN DATA SCI, V4, P547
   Agarwal S, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102321
   Agarwal S, 2018, INT CONF CONTEMP, P29
   Agrawal R., P 20 INT C VERY LARG
   [Anonymous], 1995, INKDD192197
   Bucur D, 2016, LECT NOTES COMPUT SC, V9597, P379, DOI 10.1007/978-3-319-31204-0_25
   Chen JN, 2009, EXPERT SYST APPL, V36, P5432, DOI 10.1016/j.eswa.2008.06.054
   Chen W, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P199, DOI 10.1145/1557019.1557047
   Chen ZQ, 2009, ACM SIGMOD/PODS 2009 CONFERENCE, P207
   Chung Y. H., 2018, P GENETIC EVOLUTIONA
   Cortez P, 2008, 15TH EUROPEAN CONCURRENT ENGINEERING CONFERENCE/5TH FUTURE BUSINESS TECHNOLOGY CONFERENCE, P5
   Freund Y, 1999, MACHINE LEARNING, PROCEEDINGS, P124
   Garg H, 2016, APPL MATH COMPUT, V274, P292, DOI 10.1016/j.amc.2015.11.001
   Goyal A., 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P211, DOI 10.1109/ICDM.2011.132
   Goyal A., 2010, P 3 ACM INT C WEB SE, P241, DOI DOI 10.1145/1718487.1718518
   GRANOVETTER M, 1978, AM J SOCIOL, V83, P1420, DOI 10.1086/226707
   Güney E, 2019, INFORM SCIENCES, V503, P589, DOI 10.1016/j.ins.2019.07.043
   Han M, 2017, T EMERG TELECOMMUN T, V28, DOI 10.1002/ett.3054
   Hirasawa K, 2001, IEEE C EVOL COMPUTAT, P1276, DOI 10.1109/CEC.2001.934337
   Inokuchi A, 2000, LECT NOTES COMPUT<D>, V1910, P13
   Jiang CR, 2010, INT ASIA CONF INFORM, P88, DOI 10.1109/CAR.2010.5456772
   Kempe David, 2003, P 9 ACM SIGKDD INT C, P137, DOI DOI 10.1145/956750.956769
   Kim D, 2017, INFORM SCIENCES, V394, P217, DOI 10.1016/j.ins.2017.02.023
   Kimura M, 2006, LECT NOTES ARTIF INT, V4213, P259
   Ko YY, 2018, INFORM SCIENCES, V465, P144, DOI 10.1016/j.ins.2018.07.003
   Langdon WB, 2010, INT SER OPER RES MAN, V146, P185, DOI 10.1007/978-1-4419-1665-5_7
   Lawrence T, 2019, INT J DATA SCI ANAL, V8, P1, DOI 10.1007/s41060-018-0155-5
   Li K, 2018, ENGINEERING-PRC, V4, P40, DOI 10.1016/j.eng.2018.02.004
   Li XY, 2010, TECNOL CIENC AGUA, V1, P89
   Li YC, 2018, IEEE T KNOWL DATA EN, V30, P1852, DOI 10.1109/TKDE.2018.2807843
   Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66
   Mabu S, 2007, EVOL COMPUT, V15, P369, DOI 10.1162/evco.2007.15.3.369
   Miller B. L., 1995, Complex Systems, V9, P193
   Perry-Smith JE, 2003, ACAD MANAGE REV, V28, P89
   Qiu LQ, 2020, IEEE ACCESS, V8, P12084, DOI 10.1109/ACCESS.2020.2966056
   Saxena B, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00654-7
   Setiono R, 1997, IEEE T NEURAL NETWOR, V8, P654, DOI 10.1109/72.572104
   Sheena K. K., 2016, INPROC INT C ADV EME, P1721
   Singh SS, 2020, SOFT COMPUT, V24, P10181, DOI 10.1007/s00500-019-04533-y
   Snijders TAB, 2001, SOCIOL METHODOL, V31, P361, DOI 10.1111/0081-1750.00099
   Steglich C., 2006, Methodology, V2, P48, DOI [DOI 10.1027/1614-2241.2.1.48, 10.1027/1614-2241.2.1.48, DOI 10.1027/1614-1881.2.1.48]
   Steglich C, 2010, SOCIOL METHODOL, V40, P329, DOI 10.1111/j.1467-9531.2010.01225.x
   Stehman SV, 1997, REMOTE SENS ENVIRON, V62, P77, DOI 10.1016/S0034-4257(97)00083-7
   Sun JM, 2011, SOCIAL NETWORK DATA ANALYTICS, P177
   Takac L., 2012, INT SCI C INT WORKSH, V1
   Tang JX, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.07.004
   Tang JX, 2019, PHYSICA A, V513, P477, DOI 10.1016/j.physa.2018.09.040
   Tang J, 2018, SOC NETW ANAL MIN, V8, DOI 10.1007/s13278-018-0489-y
   Tong GM, 2017, IEEE ACM T NETWORK, V25, P112, DOI 10.1109/TNET.2016.2563397
   Tso GKF, 2007, ENERGY, V32, P1761, DOI 10.1016/j.energy.2006.11.010
   Wang C, 2012, DATA MIN KNOWL DISC, V25, P545, DOI 10.1007/s10618-012-0262-1
   West D.B., 1996, Introduction to Graph Theory, V2
   Yun Y, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8010084
   Zhang ZZ, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P1087, DOI 10.1145/3308560.3316701
   Zhuang HL, 2013, IEEE DATA MINING, P1313, DOI 10.1109/ICDM.2013.145
NR 57
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 JUN 2
PY 2022
DI 10.1007/s11042-021-11606-4
EA JUN 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1T2JB
UT WOS:000804560500001
DA 2024-07-18
ER

PT J
AU Borwankar, S
   Verma, JP
   Jain, R
   Nayyar, A
AF Borwankar, Saumya
   Verma, Jai Prakash
   Jain, Rachna
   Nayyar, Anand
TI Improvise approach for respiratory pathologies classification with
   multilayer convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN (Convolutional neural network); MFCC (Mel-frequency cepstral
   coefficients); Melspectrogram; CENS (Chroma energy normalized
   statistics); Respiratory pathologies classification
ID LUNG SOUNDS
AB Every respiratory-related checkup includes audio samples collected from the individual, collected through different tools (sonograph, stethoscope). This audio is analyzed to identify pathology, which requires time and effort. The research work proposed in this paper aims at easing the task with deep learning by the diagnosis of lung-related pathologies using Convolutional Neural Network (CNN) with the help of transformed features from the audio samples. International Conference on Biomedical and Health Informatics (ICBHI) corpus dataset was used for lung sound. Here a novel approach is proposed to pre-process the data and pass it through a newly proposed CNN architecture. The combination of pre-processing steps MFCC, Melspectrogram, and Chroma CENS with CNN improvise the performance of the proposed system, which helps to make an accurate diagnosis of lung sounds. The comparative analysis shows how the proposed approach performs better with previous state-of-the-art research approaches. It also shows that there is no need for a wheeze or a crackle to be present in the lung sound to carry out the classification of respiratory pathologies.
C1 [Borwankar, Saumya; Verma, Jai Prakash] Nirma Univ, Inst Technol, Ahmadabad, Gujarat, India.
   [Jain, Rachna] Bhagwan Parshuram Inst Technol, IT Dept, New Delhi, India.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
C3 Nirma University; Bhagwan Parshuram Institute of Technology; Duy Tan
   University
RP Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
EM 17bec095@nirmauni.ac.in; jaiprakash.verma@nirmauni.ac.in;
   rachnajain@bpitindia.com; anandnayyar@duytan.edu.vn
RI Nayyar, Anand/F-3732-2015; Verma, Dr. Jai Prakash/AAE-6994-2022
OI Nayyar, Anand/0000-0002-9821-6146; Verma, Dr. Jai
   Prakash/0000-0001-6116-1383; Jain, Rachna/0000-0002-1819-550X
CR Alsmadi S, 2008, COMPUT BIOL MED, V38, P53, DOI 10.1016/j.compbiomed.2007.07.001
   Aly Mahmoud, 2022, Alexandria Engineering Journal, V61, P3487, DOI 10.1016/j.aej.2021.08.070
   Fiz JA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093595
   Aras S, 2015, SIG PROCESS COMMUN, P252, DOI 10.1109/SIU.2015.7129807
   Aykanat M, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0213-2
   Bardou D, 2018, ARTIF INTELL MED, V88, P58, DOI 10.1016/j.artmed.2018.04.008
   CELLI BR, 1995, AM J RESP CRIT CARE, V152, pS77
   Chambres G., 2018, 2018 INT C CONTENT B, P1, DOI DOI 10.1109/CBMI.2018.8516489
   Charleston-Villalobos S, 2011, COMPUT BIOL MED, V41, P473, DOI 10.1016/j.compbiomed.2011.04.009
   Chen CH, 2015, SENSORS-BASEL, V15, P13132, DOI 10.3390/s150613132
   Chen H, 2019, IEEE ACCESS, V7, P32845, DOI 10.1109/ACCESS.2019.2903859
   Dokur Z, 2009, PATTERN ANAL APPL, V12, P309, DOI 10.1007/s10044-008-0125-y
   Du XD, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P159, DOI 10.1109/YAC.2016.7804882
   Emmanuel Babatunde S., 2012, Journal of Medical Engineering & Technology, V36, P303, DOI 10.3109/03091902.2012.684831
   Flietstra B, 2011, PULM MED, V2011, DOI 10.1155/2011/590506
   FORGACS P, 1978, CHEST, V73, P399, DOI 10.1378/chest.73.3.399
   Gibson J, 2013, EUROPEAN LUNG WHITE BOOK: RESPIRATORY HEALTH AND DISEASE IN EUROPE, P1
   Goudarzi S, 2015, 2015 22ND IRANIAN CONFERENCE ON BIOMEDICAL ENGINEERING (ICBME), P70, DOI 10.1109/ICBME.2015.7404119
   Gross V, 2000, AM J RESP CRIT CARE, V162, P905, DOI 10.1164/ajrccm.162.3.9905104
   Guler Inan, 2005, J Med Syst, V29, P217, DOI 10.1007/s10916-005-5182-9
   Haider NS, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1388-0
   Hasan M. R., 2004, 3 INT C EL COMP ENG, P565
   Hashemi A., 2011, INT C BIOM ENG TECHN, V11, P127
   Islam MA, 2018, COMPUT METH PROG BIO, V159, P111, DOI 10.1016/j.cmpb.2018.03.002
   Jakovljevic N., 2017, PRECISION MED POWERE, P39, DOI [DOI 10.1007/978-981-10-7419-6_7, 10.1007/978-981-10-7419-6_7]
   Jin F, 2011, IEEE T BIO-MED ENG, V58, P3078, DOI 10.1109/TBME.2011.2160721
   Kahya Yasemin P, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P2856
   Kandaswamy A, 2004, COMPUT BIOL MED, V34, P523, DOI 10.1016/S0010-4825(03)00092-1
   KRAMAN SS, 1986, ARCH INTERN MED, V146, P1411, DOI 10.1001/archinte.146.7.1411
   Ku Y, 2022, CLIN EXP OTORHINOLAR, V15, P168, DOI 10.21053/ceo.2021.01536
   Lee ES, 2022, EMERG MED INT, V2022, DOI 10.1155/2022/4462018
   Lema GF, 2018, INT J SURG OPEN, V12, P17, DOI 10.1016/j.ijso.2018.05.002
   Li Q, 2014, I C CONT AUTOMAT ROB, P844, DOI 10.1109/ICARCV.2014.7064414
   Liao S, 2013, LECT NOTES COMPUT SC, V8150, P254, DOI 10.1007/978-3-642-40763-5_32
   Lin BS, 2015, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP), P49, DOI 10.1109/IIH-MSP.2015.51
   Lin BS, 2015, J HEALTHC ENG, V6, P649, DOI 10.1260/2040-2295.6.4.649
   LOUDON RG, 1987, CLIN CHEST MED, V8, P265
   Mahapoonyanont N, 2010, PROCD SOC BEHV, V9, DOI 10.1016/j.sbspro.2010.12.262
   Maruf SO, 2015, INT CONF IND INF SYS, P267, DOI 10.1109/ICIINFS.2015.7399022
   Matsunaga S, 2009, INT CONF ACOUST SPEE, P517, DOI 10.1109/ICASSP.2009.4959634
   Mhetre R, 2014, IOSR J ELECT ELECT E, V9, P42, DOI [10.9790/1676-09544246, DOI 10.9790/1676-09544246]
   Naves R, 2016, COMPUT METH PROG BIO, V129, P12, DOI 10.1016/j.cmpb.2016.02.013
   Palaniappan R, 2016, 2016 INTERNATIONAL CONFERENCE ON SYSTEM RELIABILITY AND SCIENCE (ICSRS 2016), P152, DOI 10.1109/ICSRS.2016.7815855
   Palaniappan R, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-223
   Palaniappan R, 2013, BIOCYBERN BIOMED ENG, V33, P129, DOI 10.1016/j.bbe.2013.07.001
   Palaniappan R, 2013, IETE TECH REV, V30, P248, DOI 10.4103/0256-4602.113524
   Park JS, 2009, IEEE T CONSUM ELECTR, V55, P1590, DOI 10.1109/TCE.2009.5278031
   Pasterkamp H, 1997, AM J RESP CRIT CARE, V156, P974, DOI 10.1164/ajrccm.156.3.9701115
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Perna D, 2019, COMP MED SY, P50, DOI 10.1109/CBMS.2019.00020
   Perna D, 2018, IEEE INT C BIOINFORM, P2109
   Price J, 2005, DESIGN AUTOMATIC SPE
   Reichert S, 2008, CIRCULATORY RESP PUL, V2
   Reichert S., 2007, ITBM RBM, V28, P169
   Riella RJ, 2009, BRAZ J MED BIOL RES, V42, P674, DOI 10.1590/S0100-879X2009000700013
   Rocha BM, 2018, InPrecision medicine powered by pHealth and connected health: ICBHI 2017, P33
   Sankar AB., 2011, EUR J SCI RES, V49, P468
   Schoeffmann K, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1957, DOI 10.1145/3123266.3130142
   Serbes G, 2011, IEEE ENG MED BIO, P3314, DOI 10.1109/IEMBS.2011.6090899
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   García-Ordás MT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041214
   Thun MJ, 2013, NEW ENGL J MED, V368, P351, DOI 10.1056/NEJMsa1211127
   Umeki S, 2015, ASIAPAC SIGN INFO PR, P213, DOI 10.1109/APSIPA.2015.7415506
   Uwaoma C, 2017, ICINCO: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS - VOL 1, P422, DOI 10.5220/0006404604220430
   Yadav A, 2020, 2020 43RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P545, DOI [10.1109/TSP49548.2020.9163565, 10.1109/tsp49548.2020.9163565]
   Yamashita M, 2011, INT CONF ACOUST SPEE, P693
   Zorc JJ, 2010, PEDIATRICS, V125, P342, DOI 10.1542/peds.2009-2092
NR 67
TC 8
Z9 8
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39185
EP 39205
DI 10.1007/s11042-022-12958-1
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788451400005
PM 35505670
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Iqbal, MJ
   Bajwa, UI
   Gilanie, G
   Iftikhar, MA
   Anwar, MW
AF Iqbal, Muhammad Javaid
   Bajwa, Usama Ijaz
   Gilanie, Ghulam
   Iftikhar, Muhammad Aksam
   Anwar, Muhammad Waqas
TI Automatic brain tumor segmentation from magnetic resonance images using
   superpixel-based approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor segmentation; Feature extraction; Low-Grade Glioma; FLAIR
   MRI; High-Grade Glioma; Superpixel Segmentation
ID TEXTURE ANALYSIS
AB Cancer is the second leading cause of deaths worldwide, reported by World Health Organization (WHO). The abnormal growth of cells, which should die at the time but they remained in body organ which makes tumor and brain tumor is one of them. During its treatment planning, brain tumor segmentation plays its vital role, Magnetic Resonance Imaging (MRI) is most widely used medical imaging modalities to scan brain tissues, and segmentation of brain tumor from MRI scans is still a challenging task, due to the variability in spatial, structure and appearance of the brain tumor. The existing brain tumor segmentation techniques are still suffering from an inadequate performance, dependent on initial assumptions, and required manual interference. The main challenge is to segment out the accurate tumor from MRI images, and to give the solution for its variability in size due to spatial change in image slices. The proposed model in an automated manners segment out abnormal tissues from MRI images. The proposed model has some aspects like we apply some pre-processing techniques, and apply superpixel-segmentation with their improved tuned parameter values. We have extracted different features for the superpixels in the images such that statistical features, fractal features, texton features, curvature feature and SIFT features. Due to unbalanced feature vector, we have proposed class balancing algorithm, and then apply SVM, KNN, Decision Tree and Ensemble classifiers, to classify the normal and abnormal superpixels. To evaluate the proposed model, we used MICCAI BRATS-2017 MRI training dataset. The Dice Coefficient (DSC), precision, sensitivity, and balanced error rate (BER) against the ground truths for FLAIR sequence in LGG volumes have been obtained as 0.8593, 87%, 93%, and 0.08 respectively. The DSC, precision, sensitivity, and BER against the ground truths for FLAIR sequence in HGG volumes have been obtained as 0.8528, 87%, 97%, and 0.08 respectively. It is evident from the quantitative and visual results that the proposed model provides a close match to the expert delineation for the FLAIR sequence.
C1 [Iqbal, Muhammad Javaid] Superior Univ, Dept Comp Sci & Informat Technol, Lahore, Pakistan.
   [Bajwa, Usama Ijaz; Iftikhar, Muhammad Aksam; Anwar, Muhammad Waqas] COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus 1-5 KM Def Rd Off Raiwind Rd, Lahore, Pakistan.
   [Gilanie, Ghulam] Islamia Univ Bahawalpur, Dept Artificial Intelligence, Bahawalpur, Pakistan.
C3 COMSATS University Islamabad (CUI); Islamia University of Bahawalpur
RP Bajwa, UI (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus 1-5 KM Def Rd Off Raiwind Rd, Lahore, Pakistan.
EM javaid.ciit@gmail.com; usamabajwa@cuilahore.edu.pk;
   ghulam.gilanie@iub.edu.pk; aksamiftikhar@cuilahore.edu.pk;
   waqasanwar@cuilahore.edu.pk
RI Iqbal, Javaid/GRY-4684-2022; Anwar, Muhammad Naseem/IAM-7949-2023;
   Gilanie, Ghulam/HDN-2595-2022
OI Anwar, Muhammad Naseem/0000-0002-4759-0656; Gilanie,
   Ghulam/0000-0001-6880-8506; Anwar, Muhammad Waqas/0000-0002-7822-8983;
   Iqbal, Muhammad Javaid/0000-0001-6183-1391; Bajwa,
   Usama/0000-0001-5755-1194
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alqazzaz S, 2019, COMPUT VIS MEDIA, V5, P209, DOI 10.1007/s41095-019-0139-y
   [Anonymous], 2015, P BRATS CHALLENGE 20
   Attique M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033616
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen H, 2020, NEUROCOMPUTING, V392, P305, DOI 10.1016/j.neucom.2019.01.111
   Costa A. F., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P39, DOI 10.1109/SIBGRAPI.2012.15
   Elangovan A, 2016, FIRST INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN ENGINEERING, TECHNOLOGY AND SCIENCE - ICETETS 2016
   Ferlay J, 2021, INT J CANCER, V149, P778, DOI 10.1002/ijc.33588
   Gilanie G, 2019, INT J IMAG SYST TECH, V29, P531, DOI 10.1002/ima.22333
   Gilanie G, 2019, INT J IMAG SYST TECH, V29, P260, DOI 10.1002/ima.22312
   Gilanie G, 2018, SIGNAL IMAGE VIDEO P, V12, P479, DOI 10.1007/s11760-017-1182-8
   Gilanie G, 2013, PATTERN RECOGN LETT, V34, P1356, DOI 10.1016/j.patrec.2013.04.010
   Henriksen JJ, 2007, 3D SURFACE TRACKING, P28
   Kadkhodaei M, 2016, IEEE ENG MED BIO, P5945, DOI 10.1109/EMBC.2016.7592082
   Li Weihao, 2018, ASIAN C COMPUT VIS, P638
   Li YH, 2016, ARTIF INTELL MED, V73, P1, DOI 10.1016/j.artmed.2016.08.004
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Nabizadeh N, 2017, EXPERT SYST APPL, V77, P1, DOI 10.1016/j.eswa.2017.01.036
   Nabizadeh N, 2015, COMPUT ELECTR ENG, V45, P286, DOI 10.1016/j.compeleceng.2015.02.007
   Pei LM, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101648
   Rehman ZU, 2019, EXPERT SYST APPL, V118, P598, DOI 10.1016/j.eswa.2018.10.040
   Schroeder M., 2009, Fractals, chaos, power laws: Minutes from an infinite paradise
   Sheela CJJ, 2022, J KING SAUD UNIV-COM, V34, P557, DOI 10.1016/j.jksuci.2019.04.006
   Soltaninejad M, 2017, INT J COMPUT ASS RAD, V12, P183, DOI 10.1007/s11548-016-1483-3
   Sompong C, 2017, EXPERT SYST APPL, V72, P231, DOI 10.1016/j.eswa.2016.10.064
   Tan L, 2021, IEEE ACCESS, V9, P14608, DOI 10.1109/ACCESS.2021.3052514
   Yang TJ, 2019, BIOCYBERN BIOMED ENG, V39, P613, DOI 10.1016/j.bbe.2019.06.003
   Zeineldin RA, 2020, INT J COMPUT ASS RAD, V15, P909, DOI 10.1007/s11548-020-02186-z
   Zhang JD, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0093-2
NR 30
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38409
EP 38427
DI 10.1007/s11042-022-13166-7
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000785933700004
DA 2024-07-18
ER

PT J
AU Jahanshahloo, A
   Ebrahimi, A
AF Jahanshahloo, Almas
   Ebrahimi, Alireza
TI Reconstruction of 3D shapes with B-spline surface using diagonal
   approximation BFGS methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE B-spline surface; Surface fitting; Aproximation BFGS technique;
   Nonlinear least squares problem
ID MATRIX ALGEBRAS; CURVE; ALGORITHM; COMPRESSION; OUTLINES; SYSTEM
AB The problem of surface reconstruction is a challenging problem in the fields of data visualization, virtual reality and engineering design. In this study, we investigate the topic of fitting B-spline surface to a set of 3D measured data points. Surface reconstruction in the proposed method consists of two main parts: (1) rewrite the problem as a nonlinear least squares optimization problem and compute the Jacobin matrix and (2) employ the diagonal approximation BFGS method to find the control points and the location parameters simultaneously. The space complexity and the time complexity of proposed method are O (n). We perform numerical experiments with five test problems, including complex shapes, self intersections, large number of data points and high genus to evaluate the performance of the suggested approach. The experimental results demonstrate that the introduced approach is easy to implement, fast convergence rate, extremely small fitting errors, flexibility, very general and applicable to real time simulations.
C1 [Jahanshahloo, Almas] Islamic Azad Univ, Dept Math, East Tehran Branch, Tehran, Iran.
   [Ebrahimi, Alireza] Yazd Univ, Fac Math Sci, Comp Geometry & Dynam Syst Lab, Yazd, Iran.
C3 Islamic Azad University; University of Yazd
RP Ebrahimi, A (corresponding author), Yazd Univ, Fac Math Sci, Comp Geometry & Dynam Syst Lab, Yazd, Iran.
EM Almasj63@yahoo.com; a.ebrahimi@stu.yazd.ac.ir
RI Ebrahimi, Alireza/R-6799-2019
OI Ebrahimi, Alireza/0000-0001-9023-5812
CR Abbas S, 2018, ALEX ENG J, V57, P931, DOI 10.1016/j.aej.2017.01.004
   Andreina A., 2013, STUDIES COMPUTATIONA, V441, P59
   [Anonymous], 2008, INTERACTIVE CURVE MO
   Bergström P, 2012, BIT, V52, P571, DOI 10.1007/s10543-012-0371-7
   Biswas S, 2004, PATTERN RECOGN, V37, P789, DOI 10.1016/j.patcog.2003.09.001
   Biswas S., 2007, BEZIER SPLINES IMAGE
   Cipolla S, 2015, LINEAR ALGEBRA APPL, V471, P544, DOI 10.1016/j.laa.2015.01.010
   Cox MG, 1990, NPL REPORT
   Di Fiore C, 2003, NUMER MATH, V94, P479, DOI 10.1007/s00211-002-0410-4
   Draper N. R., 1998, APPL REGRESSION ANAL, V326
   Ebrahimi A, 2019, IRAN J SCI TECHNOL A, V43, P947, DOI 10.1007/s40995-017-0347-1
   Ebrahimi A, 2018, MULTIMED TOOLS APPL, V77, P30331, DOI 10.1007/s11042-018-6109-z
   Ebrahimi A., 2020, J AI DATA MIN, V8, P105
   Ebrahimi A., 2019, IRANIAN J NUMERICAL, V9, P103
   Farin G.E., 2002, Curves and Surfaces for CAGD: A Practical Guide
   FRANKE R, 1987, TOPICS MULTIVARIATE, P275
   Gallier J., 2000, Curves and Surfaces in Geometric Modeling
   Gálvez A, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/528215
   Galvez A, 2015, APPL SOFT COMPUT, V26, P90, DOI 10.1016/j.asoc.2014.09.030
   Gálvez A, 2014, SCI WORLD J, DOI 10.1155/2014/138760
   Gálvez A, 2013, APPL SOFT COMPUT, V13, P1491, DOI 10.1016/j.asoc.2012.05.030
   Gálvez A, 2012, INFORM SCIENCES, V182, P56, DOI 10.1016/j.ins.2010.09.031
   Gálvez A, 2012, INFORM SCIENCES, V192, P174, DOI 10.1016/j.ins.2010.11.007
   Gulliksson M, 2008, 13 WSEAS INT C APPL
   Hasegawa A. Y., 2014, INT J COMPUT SCI APP, V11, P1
   Hussain MZ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179721
   Iglesias A, 2016, LECT NOTES COMPUT SC, V9590, P127, DOI 10.1007/978-3-662-53090-0_7
   Iglesias A, 2016, VISUAL COMPUT, V32, P393, DOI 10.1007/s00371-015-1181-0
   Javidrad F, 2012, INT J CAD CAM, V12, P9
   Kee CY, 2012, COMPUT AIDED DESIGN, V44, P275, DOI 10.1016/j.cad.2011.11.005
   Khan MA, 2007, IEICE T INF SYST, VE90D, P844, DOI 10.1093/ietisy/e90-d.5.844
   Khan MA, 2016, MULTIDIM SYST SIGN P, V27, P121, DOI 10.1007/s11045-014-0293-4
   Khan MA, 2012, SIGNAL IMAGE VIDEO P, V6, P19, DOI 10.1007/s11760-010-0165-9
   Leu MC, 2005, CIRP ANN-MANUF TECHN, V54, P131, DOI 10.1016/S0007-8506(07)60066-3
   Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849
   Li CJ, 2018, J COMPUT APPL MATH, V329, P179, DOI 10.1016/j.cam.2017.04.037
   Li X, 2019, COMPUT METHOD APPL M, V350, P664, DOI 10.1016/j.cma.2019.03.035
   Liu Y, 2008, LECT NOTES COMPUT SC, V4975, P384
   Lu LZ, 2009, J COMPUT APPL MATH, V226, P84, DOI 10.1016/j.cam.2008.05.056
   Majeed A, 2018, COMPUT APPL MATH, V37, P2877, DOI 10.1007/s40314-017-0487-0
   Mao Q, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010214
   Masood A, 2010, IMAGING SCI J, V58, P308, DOI 10.1179/136821910X12750339175709
   Masood A, 2009, IMAGE VISION COMPUT, V27, P704, DOI 10.1016/j.imavis.2008.07.012
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Patrikalakis NM, 2009, Shape interrogation for computer aided design and manufacturing
   Pérez-Arribas F, 2016, AEROSP SCI TECHNOL, V55, P449, DOI 10.1016/j.ast.2016.06.016
   Piegl L., 2012, The NURBS book
   Piegl LA, 2000, VISUAL COMPUT, V16, P386, DOI 10.1007/PL00013393
   Pottmann H, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P8, DOI 10.1109/PCCGA.2002.1167835
   Ravari AN, 2016, COMPUT AIDED DESIGN, V74, P32, DOI 10.1016/j.cad.2016.01.002
   Rossignac J., 1993, Geometric Modeling in Computer Graphics, P455
   Salomon D, 2007, CURVES SURFACES COMP
   Sarfraz M, 2003, INFORM SCIENCES, V150, P177, DOI 10.1016/S0020-0255(02)00376-6
   Sarfraz M, 2002, COMPUT GRAPH-UK, V26, P795, DOI 10.1016/S0097-8493(02)00134-6
   Sarfraz M, 2001, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P738, DOI 10.1109/IV.2001.942138
   Sarfraz M, 2018, ALEX ENG J, V57, P1041, DOI 10.1016/j.aej.2017.02.016
   Sun W, 2006, SPRINGER SER OPTIM A, V1, P1, DOI 10.1007/b106451
   Tang YY, 2001, IEEE T PATTERN ANAL, V23, P1443, DOI 10.1109/34.977567
   Ülker E, 2009, INFORM SCIENCES, V179, P1483, DOI 10.1016/j.ins.2008.11.037
   Uyar K, 2017, APPL MATH MODEL, V52, P320, DOI 10.1016/j.apm.2017.07.047
   Wang WP, 2006, ACM T GRAPHIC, V25, P214, DOI 10.1145/1138450.1138453
   Xie WC, 2012, COMPUT AIDED DESIGN, V44, P1127, DOI 10.1016/j.cad.2012.05.004
   Zhao XY, 2011, COMPUT AIDED DESIGN, V43, P598, DOI 10.1016/j.cad.2011.01.015
   Zheng WN, 2012, COMPUT AIDED GEOM D, V29, P448, DOI 10.1016/j.cagd.2012.03.004
   Zieniuk E, 2018, COMPUT APPL MATH, V37, P4835, DOI 10.1007/s40314-018-0598-2
NR 65
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 38091
EP 38111
DI 10.1007/s11042-022-13024-6
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000785933700013
DA 2024-07-18
ER

PT J
AU Anandhalli, M
   Tanuja, A
   Baligar, P
AF Anandhalli, Mallikarjun
   Tanuja, A.
   Baligar, Pavana
TI Geometric invariant features for the detection and analysis of vehicle
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle detection; Hu-Moments; Eigen values
AB The intelligent traffic management system (ITS) is one of the active research areas. Vehicle detection is a major role in traffic analysis. In the paper, analysis of detecting vehicles is proposed based on the features posed by the vehicle. The foreground pixels from image are extracted by histogram based foreground segmentation. After segmenting, Hu-Moments and Eigen values features are extracted and normalized. The classifiers are trained with the extracted Hu-Moments and Eigen values. The experiments are conducted on different benchmark datasets, and results are analysed considering the overall classification accuracy. Results of the algorithm are satisfactory and acceptable in real time.
C1 [Anandhalli, Mallikarjun; Tanuja, A.] KLSGIT, Dept Elect & Commun Engn, Belagavi, India.
   [Baligar, Pavana] SKSVM Agadi Coll Engn Technol, Dept Informat Sci & Engn, Lakshmeshwar, India.
RP Anandhalli, M (corresponding author), KLSGIT, Dept Elect & Commun Engn, Belagavi, India.
EM malliarjun71@gmail.com; a.tanuja3@gmail.com
RI Anandhalli, Mallikarjun/AAF-5880-2020
OI Anandhalli, Mallikarjun/0000-0002-0048-3925
FU Science Engineering Research Board under startup Research Grant Program
   in Engineering Science [SERB/SRG/2019/002277]
FX The Research is supported by Science Engineering Research Board under
   startup Research Grant Program in Engineering Science with File NO. :
   SERB/SRG/2019/002277 and is gratefully acknowledged.
CR Achyunda Putra F. A. I., 2020, IJCCS INDONESIAN J C, V14, P231, DOI DOI 10.22146/IJCCS.54050
   Ajay A, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1620, DOI 10.1109/ICCSP.2017.8286664
   Anandhalli M, 2018, ALEX ENG J, V57, P1597, DOI 10.1016/j.aej.2017.06.008
   Arróspide J, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-2
   Cao XB, 2011, IEEE T CIRC SYST VID, V21, P1522, DOI 10.1109/TCSVT.2011.2162274
   Dai SJ, 2009, 2009 WRI WORLD CONGRESS ON SOFTWARE ENGINEERING, VOL 3, PROCEEDINGS, P18, DOI 10.1109/WCSE.2009.263
   Gupte S, 2002, IEEE T INTELL TRANSP, V3, P37, DOI 10.1109/6979.994794
   Hassaballah M, 2020, PATTERN ANAL APPL, V23, P1505, DOI 10.1007/s10044-020-00874-9
   Hassaballah M, IEEE T INTELL TRANSP
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Lai A. H. S., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P86, DOI 10.1109/6979.880965
   Li LD, 2012, INFORM SCIENCES, V199, P1, DOI 10.1016/j.ins.2012.02.062
   Li LD, 2011, IEICE T FUND ELECTR, VE94A, P889, DOI 10.1587/transfun.E94.A.889
   Li LD, 2010, INFORM SCIENCES, V180, P2875, DOI 10.1016/j.ins.2010.04.009
   Sharma P., 2011, INT J SCI ENG RES, V2, pISSN 2229
   Tian Q, 2013, IEEE WORKSHOP SIG, P289, DOI 10.1109/SiPS.2013.6674521
   Tuermer S, 2013, IEEE J-STARS, V6, P2327, DOI 10.1109/JSTARS.2013.2242846
   Wei Y, 2019, MATH COMPUT SIMULAT, V155, P130, DOI 10.1016/j.matcom.2017.12.011
   Xianbin Cao, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2421, DOI 10.1109/ICIP.2011.6116132
NR 20
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33549
EP 33567
DI 10.1007/s11042-022-12919-8
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784951200008
PM 35463223
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Du, M
   Luo, T
   Xu, HY
   Song, Y
   Wang, CP
   Li, L
AF Du, Meng
   Luo, Ting
   Xu, Haiyong
   Song, Yang
   Wang, Chunpeng
   Li, Li
TI Robust HDR video watermarking method based on the HVS model and T-QR
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HDR video; The HVS model; T-QR; Robust watermarking
ID IMAGE WATERMARKING; ALGORITHM; SCHEME; SVD; DCT
AB In order to protect the copyright of the high dynamic range (HDR) video, a robust HDR video watermarking method based on the human visual system (HVS) model and Tensor-QR decomposition (T-QR) is proposed. In order to obtain the main information of the HDR video, the key frames are extracted by detecting the scene change, and each key frame is considered as the third-order tensor for preserving its main characteristics. Each key frame is divided into non-overlapping blocks, and each block is decomposed by using T-QR to obtain the orthogonal tensor, which includes three matrices and represents main energies of the frame. Since the second matrix has more correlations of the frame than other two matrices, it is used to embed watermark for robustness. Moreover, to obtain the trade-off between watermarking robustness and the visual quality, the HVS model of each key frame is computed by using the luminance perception, image contrast and contrast masking for determining the watermark embedding strength. Experiment results show that the proposed method can resist a variety of tone mapping and video attacks, and is more robust than existing watermarking methods.
C1 [Du, Meng; Luo, Ting; Song, Yang] Ningbo Univ, Coll Sci & Technol, Ningbo 315212, Peoples R China.
   [Du, Meng; Luo, Ting; Xu, Haiyong] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
   [Wang, Chunpeng] Qilu Univ Technol, Sch Informat, Sch Acad Sci, Jinan 250353, Peoples R China.
   [Li, Li] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
C3 Ningbo University; Ningbo University; Qilu University of Technology;
   Hangzhou Dianzi University
RP Luo, T (corresponding author), Ningbo Univ, Coll Sci & Technol, Ningbo 315212, Peoples R China.; Luo, T (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
EM luoting@nbu.edu.cn
OI Luo, Ting/0000-0003-1762-148X
FU Natural Science Foundation of China [61971247, 61501270]; Zhejiang
   Provincial Natural Science Foundation of China [LY22F020020,
   LQ20F010002]; Natural Science Foundation of Ningbo [2021J134]; K. C.
   Wong Magna Fund in Ningbo University
FX This work was supported by Natural Science Foundation of China under
   Grant No. 61971247 and 61501270, Zhejiang Provincial Natural Science
   Foundation of China under Grant No. LY22F020020 and LQ20F010002, Natural
   Science Foundation of Ningbo under Grant No. 2021J134. It was also
   sponsored by the K. C. Wong Magna Fund in Ningbo University.
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Bai YQ, 2018, SIGNAL PROCESS-IMAGE, V65, P187, DOI 10.1016/j.image.2018.04.005
   Bakhsh FY, 2018, J INF SECUR APPL, V41, P12, DOI 10.1016/j.jisa.2018.05.003
   Balasamy K, 2021, MULTIMED TOOLS APPL, V80, P7167, DOI 10.1007/s11042-020-09981-5
   Chen Y, 2021, SIGNAL PROCESS, V185, DOI 10.1016/j.sigpro.2021.108088
   Cheng YM, 2009, IEEE MULTIMEDIA, V16, P70, DOI 10.1109/MMUL.2009.43
   Chi BW, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102752
   Choudhury A, 2020, MULTIMED TOOLS APPL, V79, P22843, DOI 10.1007/s11042-020-08985-5
   Ernawan F, 2020, VISUAL COMPUT, V36, P19, DOI 10.1007/s00371-018-1567-x
   Guerrini F, 2011, IEEE T INF FOREN SEC, V6, P283, DOI 10.1109/TIFS.2011.2109383
   Hao N, 2013, SIAM J IMAGING SCI, V6, P437, DOI 10.1137/110842570
   Hu JY, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P799, DOI 10.1109/CISP.2015.7407986
   Hu RW, 2021, IEEE T IMAGE PROCESS, V30, P318, DOI 10.1109/TIP.2020.3036727
   Jie sang, 2020, Journal of Electronic Science and Technology, P1, DOI 10.1016/j.jnlest.2020.100052
   Joshi AM, 2017, ADV INTELL SYST, V468, P455, DOI 10.1007/978-981-10-1675-2_45
   Kang J, 2020, IEEE ACCESS, V8, P127477, DOI 10.1109/ACCESS.2020.3006980
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   Khan IR., 2009, 2009 7 INT C INFORM, P1, DOI [10.1109/ICICS.2009.5397652, DOI 10.1109/ICICS.2009.5397652]
   Khare P, 2020, ADV VLSI COMMUNICATI, V683, P359, DOI [10.1007/978-981-15-6840-4_28, DOI 10.1007/978-981-15-6840-4_28]
   Khwildi R, 2021, MULTIMED TOOLS APPL, V80, P15413, DOI 10.1007/s11042-020-10416-4
   Khwildi R, 2020, VISUAL COMPUT, V36, P1111, DOI 10.1007/s00371-019-01719-1
   Lai CC, 2011, OPT COMMUN, V284, P938, DOI 10.1016/j.optcom.2010.10.047
   Li JY, 2020, MULTIMED TOOLS APPL, V79, P1373, DOI 10.1007/s11042-019-08213-9
   Li MT, 2011, INT J INNOV COMPUT I, V7, P2021
   Lin YT, 2017, IEEE T MULTIMEDIA, V19, P196, DOI 10.1109/TMM.2016.2605499
   Luo YF, 2021, MULTIMED TOOLS APPL, V80, P14915, DOI 10.1007/s11042-020-10375-w
   Maiorana E, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0100-7
   Mantiuk R., 2006, ACM Transactions on Applied Perception, V3, P286, DOI DOI 10.1145/1166087.1166095
   Mantiuk R, 2011, LECT NOTES COMPUT SC, V6944, P1, DOI 10.1007/978-3-642-23834-5_1
   Martin CD, 2013, SIAM J SCI COMPUT, V35, pA474, DOI 10.1137/110841229
   Mousavi SMR, 2021, MULTIMED TOOLS APPL, V80, P14591, DOI 10.1007/s11042-021-10555-2
   Nasiopoulos P, 2018, ICMSP 2014 12 INT C
   Nouioua I, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/6712065
   Sathya SPA, 2018, WIRELESS PERS COMMUN, V102, P2011, DOI 10.1007/s11277-018-5252-1
   Solachidis V, 2013, PROC SPIE, V8655, DOI 10.1117/12.2005240
   Wu, 2012, WATERMARKING
   Yu CM, 2011, DISPLAYS, V32, P225, DOI 10.1016/j.displa.2011.02.004
   Yu M, 2019, IEEE ACCESS, V7, P113053, DOI 10.1109/ACCESS.2019.2935627
   Yuan ZH, 2020, MULTIMED TOOLS APPL, V79, P30557, DOI 10.1007/s11042-020-09499-w
   Zhang YF, 2019, OPTIK, V186, P379, DOI 10.1016/j.ijleo.2019.04.091
   Zhou RG, 2018, INT J QUANTUM INF, V16, DOI 10.1142/S0219749918500211
NR 41
TC 1
Z9 1
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33375
EP 33395
DI 10.1007/s11042-022-13145-y
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784122800011
DA 2024-07-18
ER

PT J
AU Li, XL
   Hua, Z
   Li, JJ
AF Li, Xiaoling
   Hua, Zhen
   Li, Jinjiang
TI Color layers -Based progressive network for Single image dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color layers; Progressive network; Single image dehazing
ID ENHANCEMENT; SEGMENTATION; WEATHER
AB While deep learning-based dehazing methods have achieved significant success in recent years, most emphasize more on dehazing and less on image color recovery. In this paper, we propose a progressive network incorporating color layers. It gradually recovers the image by repeatedly invoking an auxiliary progressive network. The RGBA image information captured by the soft color segmentation is used as the input for the auxiliary learning. Specifically, we first introduce the gated recurrent unit in the feature extraction module, which can effectively extract image features while preventing model overfitting. Next, local features are extracted in the residual learning module by combining the recurrent layer and residual blocks. Finally composite module integrates the features to produce a clean image with rich details. In addition, recursive computation is used in each stage to reduce network parameters while improving performance. Extensive experimental results demonstrate that the proposed method outperforms the state-of-the-arts quantitatively and qualitatively.
C1 [Li, Xiaoling; Hua, Zhen] Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.
   [Li, Jinjiang] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
C3 Shandong Technology & Business University; Shandong Technology &
   Business University
RP Hua, Z (corresponding author), Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.
EM 1828162238@qq.com; huazhen66@foxmail.com; lijinjiang@gmail.com
RI Hua, Zhen/AGN-6068-2022; wang, xiao/HZI-9156-2023
FU National Natural Science Foundation of China [61772319, 62002200,
   61976125, 61976124]; Shandong Natural Science Foundation of China
   [ZR2020QF012, ZR2021MF068]
FX The authors acknowledge the National Natural Science Foundation of China
   (61772319, 62002200, 61976125 and 61976124), and Shandong Natural
   Science Foundation of China (ZR2020QF012 and ZR2021MF068).
CR Akimoto Naofumi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8274, DOI 10.1109/CVPR42600.2020.00830
   Aksoy Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201275
   Aksoy Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3002176
   Anvari Z., 2020, ARXIV200806632
   Bin Xie, 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P848, DOI 10.1109/ISDEA.2010.141
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Dharejo FA, 2020, IEEE GEOSCI REMOTE S, V17, P1613, DOI 10.1109/LGRS.2019.2951626
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   FRIES RW, 1979, IEEE T ACOUST SPEECH, V27, P625, DOI 10.1109/TASSP.1979.1163324
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jing SW, 2021, IET IMAGE PROCESS, V15, P1053, DOI 10.1049/ipr2.12085
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Khatun A., 2020, J COMPUTER COMMUNICA, V8, P127, DOI DOI 10.4236/JCC.2020.84010
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Kinoshita Y, 2020, IEEE ACCESS, V8, P9540, DOI 10.1109/ACCESS.2020.2964823
   Koyama Y, 2018, COMPUT GRAPH FORUM, V37, P397, DOI 10.1111/cgf.13577
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li B., 2017, ARXIV PREPRINT ARXIV
   Li B, 2020, SIGNAL IMAGE VIDEO P, V14, P1245, DOI 10.1007/s11760-020-01665-9
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li JJ, 2021, IEEE T CIRC SYST VID, V31, P4227, DOI 10.1109/TCSVT.2021.3049940
   Li JJ, 2018, IEEE ACCESS, V6, P26831, DOI 10.1109/ACCESS.2018.2833888
   Li LD, 2016, IEICE T INF SYST, VE99D, P773, DOI 10.1587/transinf.2015EDL8204
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Liu Y, 2018, ARXIV180503146
   Lou WH, 2020, IEEE ACCESS, V8, P113318, DOI 10.1109/ACCESS.2020.3003444
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Paszke A., 2017, NAT COMMUN, P1, DOI DOI 10.1038/S41467-016-0009-6
   Peng YT, 2020, IEEE T CIRC SYST VID, V30, P1385, DOI 10.1109/TCSVT.2019.2902795
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Ren DW, 2019, PROC CVPR IEEE, P3932, DOI 10.1109/CVPR.2019.00406
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Tai YW, 2007, IEEE T PATTERN ANAL, V29, P1520, DOI 10.1109/TPAMI.2007.1168
   Tan JC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275054
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tangsakul S, 2020, IEEE ACCESS, V8, P103181, DOI 10.1109/ACCESS.2020.2999076
   Wang JB, 2015, P 7 INT C INT MULT C, P1
   Wang ZZ, 2018, APPL SOFT COMPUT, V70, P988, DOI 10.1016/j.asoc.2017.05.025
   Wu QB, 2020, IEEE T IMAGE PROCESS, V29, P2583, DOI 10.1109/TIP.2019.2949392
   Yamak P. T., 2019, P 2019 2 INT C ALG C, DOI [10.1145/3377713.3377722, DOI 10.1145/3377713.3377722]
   Zhang, 2020, INFORM SCIENCES
   Zhang WD, 2019, IEEE ACCESS, V7, P72492, DOI 10.1109/ACCESS.2019.2920403
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zhao, 2020, CRITERIA BASELINES
   Zhou JJ, 2013, 2013 2ND INTERNATIONAL SYMPOSIUM ON INSTRUMENTATION AND MEASUREMENT, SENSOR NETWORK AND AUTOMATION (IMSNA), P243, DOI 10.1109/IMSNA.2013.6743260
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 54
TC 0
Z9 0
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 32755
EP 32778
DI 10.1007/s11042-022-12731-4
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000782544600005
DA 2024-07-18
ER

PT J
AU Ma, ZP
   Zhou, J
   Ma, JL
   Li, TT
AF Ma, Ziping
   Zhou, Jie
   Ma, Jinlin
   Li, Tingting
TI A novel 3D shape recognition method based on double-channel attention
   residual network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D shape recognition; Residual; Multi-head self-attention; Weighted loss
   function
ID CONVOLUTIONAL NEURAL-NETWORK; POINT CLOUD; RETRIEVAL; CLASSIFICATION
AB Learning 3D features by deep networks has achieved a successful performance up to now. However, data imbalance and low-resolution voxels still remain and influence the performance of 3D shape recognition. To resolve these issues, we propose double-channel attention residual network (double-RVCNN) as a novel deep network model with residual structure based on multi-head self-attention mechanism. Double-channel structure adopts double channels to input data including voxels and 3D Radon feature matrices, aiming to fully utilize the local and global features. The multi-head self-attention mechanism can integrate the relatively important contents of the input data through multiple heads structure, which can enrich the information processing ability and stabilize the training process of our network. Residual structure with cross-entropy loss and center loss as weighted loss function can avoid information loss to a great extent. Experimental results show that the values of mean average precision (MAP) are 83.31% and 74.04%, the values of classification accuracy are 90.53% and 85.09% on ModelNet10 and ModelNet40 datasets respectively, which demonstrates that our method performs a better 3D shape recognition accuracy than compared methods on test datasets.
C1 [Ma, Ziping] North Minzu Univ, Coll Math & Informat Sci, Yinchuan 750021, Ningxia, Peoples R China.
   [Zhou, Jie; Ma, Jinlin; Li, Tingting] North Minzu Univ, Coll Comp Sci & Engn, Yinchuan 750021, Ningxia, Peoples R China.
C3 North Minzu University; North Minzu University
RP Ma, ZP (corresponding author), North Minzu Univ, Coll Math & Informat Sci, Yinchuan 750021, Ningxia, Peoples R China.
EM maziping@tom.com
RI Ting, Zhang/KGM-5479-2024; L, J/JEF-9564-2023; Li,
   Tingting/HKE-0812-2023; zhang, ting/IYT-0642-2023
OI ma, ziping/0000-0002-6764-6135
FU National Natural Science Foundation of China [61462002]; Major special
   projects of North Minzu University [ZDZX2001801]; First class discipline
   construction of Ningxia's University (mathematics discipline)
   [NXYLXK2017B09]; Special Project of North Minzu University [FWNX21]
FX This research is jointly supported by the National Natural Science
   Foundation of China (No.61462002), Major special projects of North Minzu
   University (No.ZDZX2001801), First class discipline construction of
   Ningxia's University (mathematics discipline)(No.NXYLXK2017B09) and the
   Special Project of North Minzu University (No.FWNX21).
CR Phan AV, 2018, NEURAL NETWORKS, V108, P533, DOI 10.1016/j.neunet.2018.09.001
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 2019, ARXIV PREPRINT ARXIV
   Ba J., 2014, ARXIV PREPRINT ARXIV
   Biasotti S, 2016, COMPUT GRAPH FORUM, V35, P87, DOI 10.1111/cgf.12734
   Bu SH, 2014, IEEE T MULTIMEDIA, V16, P2154, DOI 10.1109/TMM.2014.2351788
   Cai JH, 2020, VISUAL COMPUT, V36, P1261, DOI 10.1007/s00371-019-01733-3
   Chen D., 2021, COMPUT INTEL NEUROSC, V2021, P1
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Chen J, 2020, LEARNING ATTENTIVE H
   Chen SL, 2019, IEEE T VIS COMPUT GR, V25, P3244, DOI 10.1109/TVCG.2018.2866793
   Cordonnier J.B., 2019, INT C LEARNING REPRE
   Dubey Arun Kumar, 2019, Applications of Computing, Automation and Wireless Systems in Electrical Engineering. Proceedings of MARC 2018. Lecture Notes in Electrical Engineering (LNEE 553), P873, DOI 10.1007/978-981-13-6772-4_76
   Feng YT, 2019, AAAI CONF ARTIF INTE, P8279
   Han ZZ, 2019, IEEE T IMAGE PROCESS, V28, P3986, DOI 10.1109/TIP.2019.2904460
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322959
   Hara K, 2017, IEEE INT CONF COMP V, P3154, DOI 10.1109/ICCVW.2017.373
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He W., 2020, CURVANET GEOMETRIC D
   He XW, 2019, IEEE I CONF COMP VIS, P7514, DOI 10.1109/ICCV.2019.00761
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Katayama K, 2020, IEICE T INF SYST, VE103D, P992, DOI 10.1587/transinf.2019DAP0010
   Kazhdan M., 2003, P EUR ACM SIGGRAPH S, V6, P156
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuang Z, 2019, IEEE T MULTIMEDIA, P1
   Kumawat S, 2019, PROC CVPR IEEE, P4898, DOI 10.1109/CVPR.2019.00504
   Lahav A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417806
   Li HS, 2019, COMPUT ELECTR ENG, V78, P11, DOI 10.1016/j.compeleceng.2019.06.022
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Li YY, 2016, ADV NEUR IN, V29
   Li ZC, 2020, INT J COMPUT VISION, V128, P2265, DOI 10.1007/s11263-020-01331-0
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu M, 2019, COMPUT VIS MEDIA, V5, P91, DOI 10.1007/s41095-019-0135-2
   Lu W, 2019, MULTIMED TOOLS APPL, V78, P479, DOI 10.1007/s11042-017-5136-5
   Ma J, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (ICAIIC 2019), P467, DOI [10.1109/ICAIIC.2019.8669028, 10.1109/icaiic.2019.8669028]
   Mesbah A., 2019, P 2 INT C NETW INF S, P1, DOI DOI 10.1145/3320326.3320397
   Müller R, 2019, ADV NEUR IN, V32
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Peng B, 2020, IEEE I C VI COM I PR, P185, DOI 10.1109/vcip49819.2020.9301813
   Pickup D, 2016, INT J COMPUT VISION, V120, P169, DOI 10.1007/s11263-016-0903-8
   Qiu X., 2019, NEURAL NETWORKS DEEP
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schmitt W, 2015, SIBGRAPI, P226, DOI 10.1109/SIBGRAPI.2015.51
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Shi Y., 2019, 2019 INT C 3D VIS 3D
   Sinha A, 2016, LECT NOTES COMPUT SC, V9910, P223, DOI 10.1007/978-3-319-46466-4_14
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   SUN LC, 2020, IEEE C EVOL COMPUTAT, DOI DOI 10.1109/cec48606.2020.9185718
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Wang C, 2019, NEUROCOMPUTING, V323, P139, DOI 10.1016/j.neucom.2018.09.075
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang ZY, 2020, AAAI CONF ARTIF INTE, V34, P6315
   Wei X, 2020, PROC CVPR IEEE, P1847, DOI 10.1109/CVPR42600.2020.00192
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie J, 2017, IEEE T PATTERN ANAL, V39, P1335, DOI 10.1109/TPAMI.2016.2596722
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yizhak BS, 2018, IEEE ROBOT AUTOM LET
   You HX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1310, DOI 10.1145/3240508.3240702
   Zhang H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1541
   Zhang HY, 2019, PR MACH LEARN RES, V97
   Zhang Y, 2021, IEEE T MED IMAGING
   Zhang ZB, 2018, COMPUT AIDED DESIGN, V101, P12, DOI 10.1016/j.cad.2018.03.006
   Zhou Y, 2019, INFORM SCIENCES, V474, P205, DOI 10.1016/j.ins.2018.09.051
NR 67
TC 4
Z9 5
U1 3
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32519
EP 32548
DI 10.1007/s11042-022-12041-9
EA APR 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000783454600002
DA 2024-07-18
ER

PT J
AU Chang, TW
   Chen, CY
   Huang, HY
   Hsieh, TL
   Huang, WX
   Datta, S
AF Chang, Teng-Wen
   Chen, Chun-Yen
   Huang, Hsin-Yi
   Hsieh, Tsai-Ling
   Huang, Weixin
   Datta, Sambit
TI ViDA: developing a visualization system for a
   Design-Fabrication-Assembly (D-F-A) process
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic skin; Interactive design; Information visualization; Prototyping
   and Fabrication; Weaving structures
AB Most designs, especially architecture and product design, involve the collective efforts of multiple disciplinary teams. These kinds of designs encounter many problems because of the need to implement various experimental interactive installations as well as utilize innovative design methods and processes. According to the traditional process, these surfaces also require tailor-made construction processes in fabrication and assembly in order to test a proposed prototype. However, as component-based installation requires many people assisting with the assembly phase, team members require a dynamic process called Design-Fabrication-Assembly (DFA) to understand the method and process of the whole project. However allowing team members to participate in and understand the project is a problem for a novice design fabrication team. We propose a visualization system called Visualization System ofDFA (ViDA) and refine the DFA process according to the problem encountered, where a large experimental interactive installation needs to be implemented. We also describe in detail three experiments, two projects, and two design models of communication media for a component-based installation to help the design team fabricate and assemble the prototype. The ViDA is evaluated by reflecting on the initial three experiments and reifying the two projects (i.e., the prototyping process). Results of the ViDA redesign and user analysis show that the visualization system meets the short-term time cost feature of prototyping and provides an effective way to collaborate with team members, including allowing multiple disciplinary groups with different knowledge to work together.
C1 [Chang, Teng-Wen; Chen, Chun-Yen; Huang, Hsin-Yi; Hsieh, Tsai-Ling] Natl Yunlin Univ Sci & Technol, 123 Univ Rd,Sect 3, Touliu 64002, Yunlin, Taiwan.
   [Huang, Weixin] Tsinghua Univ, Sch Architecture, 30 Shuangqing Rd, Beijing, Peoples R China.
   [Datta, Sambit] Curtin Univ, Int Fac Sci & Engn, 6102 Kent St, Perth, WA, Australia.
C3 National Yunlin University Science & Technology; Tsinghua University;
   Curtin University
RP Chang, TW (corresponding author), Natl Yunlin Univ Sci & Technol, 123 Univ Rd,Sect 3, Touliu 64002, Yunlin, Taiwan.
EM tengwen@softlab.tw; chunyan056@gmail.com; sherry.hhy@gmail.com;
   mavishsieh8313@gmail.com; huangwx@tsinghua.edu.cn;
   Sambit.Datta@curtin.edu.au
RI Chang, Teng-Wen/AAH-3678-2020
OI Chang, Teng-Wen/0000-0001-9503-2766; Huang, Hsin-Yi/0000-0002-4765-1869;
   Datta, Sambit/0000-0002-5683-3832
CR Arduino, 2018, ARD MAN
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Billinghurst M, 1999, MIXED REALITY, P261
   Biswas A, 2017, MULTIMED TOOLS APPL, V76, P18619, DOI 10.1007/s11042-016-4270-9
   Borba EZ, 2020, MULTIMED TOOLS APPL, V79, P3425, DOI 10.1007/s11042-019-07924-3
   Chang TW, 2019, BUILDINGS-BASEL, V9, DOI 10.3390/buildings9040084
   Chang TW., 2016, INT J DIGIT MEDIA, V8, P1
   Chen C, 2019, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON VEHICLE TECHNOLOGY AND INTELLIGENT TRANSPORT SYSTEMS (VEHITS 2019), P312, DOI 10.5220/0007674203120318
   Cheng YB, 2019, DES J, V22, P169, DOI 10.1080/14606925.2019.1569809
   Davidova M, 2016, 1 1 TRANSDISCIPLINAR
   Fologram, 2018, FOL MAN
   Goldschmidt G, 2014, DES THINK DES THEOR, P1
   Guo X, 2016, MULTIMED TOOLS APPL, V75, P14351, DOI 10.1007/s11042-015-3176-2
   Hsieh TL, 2019, P 4 RSU NAT INT RES
   Hsieh TL, 2019, IEEE INT CONF INF VI, P68, DOI 10.1109/IV-2.2019.00022
   Hsieh TL, 2017, IEEE INT CON INF VIS, P14, DOI 10.1109/iV.2017.79
   Huang C., 2020, MULTIMED TOOLS APPL, P1
   Huang HY, 2017, IEEE INT CON INF VIS, P301, DOI 10.1109/iV.2017.76
   Huang W. X., 2018, 23 INT C COMP AID AR
   Huang WX, 2016, 8 INT C FRB COMP CIV
   Huangxin Wang, 2017, 2017 IEEE Conference on Communications and Network Security (CNS), P1, DOI 10.1109/CNS.2017.8228640
   Kim M, 2020, MULTIMED TOOLS APPL, V79, P5941, DOI 10.1007/s11042-019-08324-3
   Langacker RW, 1999, LACUS FORUM, V25, P41
   Lo CHN, 2013, INT C DES US EXP US, P402
   McNeel R., 2018, RHINO 3D MANUAL
   Microsoft, 2018, HOL DOC
   Nóbrega R, 2017, MULTIMED TOOLS APPL, V76, P163, DOI 10.1007/s11042-015-3031-5
   Park JS, 2011, MULTIMED TOOLS APPL, V55, P725, DOI 10.1007/s11042-010-0592-1
   Ryu SH, 2007, MULTIMED TOOLS APPL, V32, P209, DOI 10.1007/s11042-006-0066-7
   Takahashi M, 2020, MULTIMED TOOLS APPL, V79, P26411, DOI 10.1007/s11042-020-09249-y
   Weichel C, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3855, DOI 10.1145/2556288.2557090
   Yan D, 2016, GENERATION WEAVING S
   Yang MH, 2015, MULTIMED TOOLS APPL, V74, P10025, DOI 10.1007/s11042-014-2161-5
NR 33
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 14617
EP 14639
DI 10.1007/s11042-022-12179-6
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000781124000013
DA 2024-07-18
ER

PT J
AU Singh, S
   Chaurasiya, VK
AF Singh, Sunakshi
   Chaurasiya, Vijay Kumar
TI Mutual authentication framework using fog computing in healthcare
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Healthcare; Fog computing; IoT
ID LIGHTWEIGHT 3-FACTOR AUTHENTICATION; INTERNET; SCHEME; SYSTEMS
AB The development of the medical services framework is advanced by the development of the Internet of Things (IoT) innovation. There are many hindrances in the current healthcare framework, for example, security and privacy concerns, information irregularity, opportune admittance to the correct records across numerous medical services. Notwithstanding, there is an assortment of options available for the collection of medical data. Since the health data are exceptionally private, it requires proper vigilance and ingress for people dealing with them. So, one such solution; to secure data is the authentication of the communicating entities. Authentication is used to secure the information transferred over the public channels. There are many protocols proposed; however, the conventional authentication models cannot be applied straightforwardly to situations requiring low-latency in specific. Moreover, they are inefficient for two reasons: first, they are unable to adapt to the extending volume of generated data, and second, they are vulnerable to cyber-attacks. Hence, in this paper, we try to give a feasible solution as a "Mutual Authentication framework using Fog Computing in Healthcare" that is fully resilient and addresses the aforementioned concerns. The framework uses elliptic curve cryptography, aptly suitable for low constrained devices, to secure patients' data during communication with primacy. In addition to this, fog computing minimizes network latency, and cost, which efficiently manages the medical resources and altogether fulfills the high-security norms guaranteeing data confidentiality. Furthermore, a review of the most relevant techniques has been discussed. Finally, a comparison of these approaches, along with the security investigation, is made, and subsequently, the model's feasibility, stability, and security are evaluated.
C1 [Singh, Sunakshi; Chaurasiya, Vijay Kumar] IIITA Indian Inst Informat Technol Allahabad, Jhalwa 211015, Prayagraj, India.
C3 Indian Institute of Information Technology Allahabad
RP Singh, S (corresponding author), IIITA Indian Inst Informat Technol Allahabad, Jhalwa 211015, Prayagraj, India.
EM sonasunakshisunaks@gmail.com; vijayk@iiita.ac.in
FU Ministry of Education, Government of India
FX This work was supported and funded by the Ministry of Education,
   Government of India.
CR Aghili SF, 2019, FUTURE GENER COMP SY, V96, P410, DOI 10.1016/j.future.2019.02.020
   Akrivopoulos O, 2017, P INT COMP SOFTW APP, P288, DOI 10.1109/COMPSAC.2017.178
   Ali Z, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102502
   Alzahrani BA, 2021, WIRELESS PERS COMMUN, V117, P47, DOI 10.1007/s11277-020-07237-x
   Amin R, 2018, FUTURE GENER COMP SY, V80, P483, DOI 10.1016/j.future.2016.05.032
   Amin R, 2016, COMPUT NETW, V101, P42, DOI 10.1016/j.comnet.2016.01.006
   Armando A, 2005, LECT NOTES COMPUT SC, V3576, P281
   Armando A., 2006, ERCIM News, V64
   Bellavista P, 2019, PERVASIVE MOB COMPUT, V52, P71, DOI 10.1016/j.pmcj.2018.12.007
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   Das AK, 2017, WIRELESS PERS COMMUN, V94, P1899, DOI 10.1007/s11277-016-3718-6
   Dharminder D, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1471-6
   Dhillon Parwinder Kaur, 2018, Journal of Reliable Intelligent Environments, V4, P141, DOI 10.1007/s40860-018-0062-5
   Dwivedi AD, 2019, 2019 42ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P135, DOI [10.1109/tsp.2019.8769060, 10.1109/TSP.2019.8769060]
   Hamidi H, 2019, FUTURE GENER COMP SY, V91, P434, DOI 10.1016/j.future.2018.09.024
   Hu PF, 2017, J NETW COMPUT APPL, V98, P27, DOI 10.1016/j.jnca.2017.09.002
   Jiang Q, 2016, J SUPERCOMPUT, V72, P3826, DOI 10.1007/s11227-015-1610-x
   Jiang Q, 2017, IEEE ACCESS, V5, P3376, DOI 10.1109/ACCESS.2017.2673239
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Li CT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071482
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Mir O, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0265-8
   Mouradian C, 2018, IEEE COMMUN SURV TUT, V20, P416, DOI 10.1109/COMST.2017.2771153
   Mukherjee M, 2018, IEEE COMMUN SURV TUT, V20, P1826, DOI 10.1109/COMST.2018.2814571
   Radhakrishnan N., 2018, Informatics in Medicine Unlocked, V16, DOI 10.1016/j.imu.2018.02.003
   Renuka K, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1251-3
   Shaki KA, 2020, J KING SAUD UNIV-COM, V32, P57, DOI 10.1016/j.jksuci.2017.07.001
   Singh D, 2021, INT J HEALTHC INF SY, V16, P21, DOI 10.4018/IJHISI.20210401.oa2
   Singh S, 2021, CLUSTER COMPUT, V24, P1643, DOI 10.1007/s10586-020-03211-1
   Srinivas J, 2020, IEEE T DEPEND SECURE, V17, P1133, DOI 10.1109/TDSC.2018.2857811
   Usman M, 2019, IEEE J SEL AREA COMM, V37, P1222, DOI 10.1109/JSAC.2019.2904349
   Wazid M, 2019, FUTURE GENER COMP SY, V91, P475, DOI 10.1016/j.future.2018.09.017
   Wu F, 2018, FUTURE GENER COMP SY, V82, P727, DOI 10.1016/j.future.2017.08.042
   Xu ZS, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.5295
   Zhou L, 2019, FUTURE GENER COMP SY, V91, P244, DOI 10.1016/j.future.2018.08.038
NR 35
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31977
EP 32003
DI 10.1007/s11042-022-12131-8
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781124000018
DA 2024-07-18
ER

PT J
AU Wu, DK
   Tan, ZH
   Xia, ZC
   Ning, JY
AF Wu, Danke
   Tan, Zhenhua
   Xia, Zhenche
   Ning, Jingyu
TI TCSE: Trend and cascade based spatiotemporal evolution network to
   predict online content popularity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Popularity prediction; Information diffusion; Online social network;
   GCN; LSTM
AB During online social networks (OSNs), popularity prediction uncovers the final size of online content based on the observed cascade, which has been the critical technology for online recommendation, viral marketing, and rumor detection. Recently, representation learning could help to infer the mapping between the dynamic cascade and the final popularity efficiently, and has been a new research paradigm for popularity prediction. However, those methods are vulnerable to structure disturbance when lack of fine-grained supervision, as only the dynamic cascade is used. Therefore, we propose a novel trend and cascade based spatiotemporal evolution network (TCSE-Net), which preserves the distinguishable structure pattern while eliminating potential noise, via aligning and fusing the temporal popularity and cascade. To be specific, we first leveraged the Long-Short Term Memory (LSTM) and recurrent graph convolutional network (GCN) to learn the trend representation and the corresponding cascade representation respectively. Meanwhile, we represent node with it's layer, thereby the hierarchy is preserved in cascade representation through GCN. Then, both trend and cascade representations are aligned in time sequence and selectively assembled by a set of shared parameters for popularity prediction. The extensive experimental results show that our TCSE-Net outperforms state-of-the-art baselines on two real datasets. Related code will be publicly available on https://github.com/TAN-OpenLab/TCSE-Net.
C1 [Wu, Danke; Tan, Zhenhua; Xia, Zhenche; Ning, Jingyu] Northeastern Univ, Software Coll, Shenyang 110819, Liaoning, Peoples R China.
C3 Northeastern University - China
RP Tan, ZH (corresponding author), Northeastern Univ, Software Coll, Shenyang 110819, Liaoning, Peoples R China.
EM wudk2019@stumail.neu.edu.cn; tanzh@mail.neu.edu.cn;
   xiazhenche@stumail.neu.edu.cn; ningjy@stumail.neu.edu.cn
OI Ning, Jingyu/0000-0002-6949-6636; Tan, Zhenhua/0000-0002-9870-8925; Wu,
   Danke/0000-0002-4849-0470
FU National Natural Science Foundation of China [61772125]
FX This work is supported by the National Natural Science Foundation of
   China under Grants No. 61772125.
CR [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2012, P 5 ACM INT C WEB SE, DOI [10.1145/2124295.2124320, DOI 10.1145/2124295.2124320]
   [Anonymous], 2013, P 6 ACM INT C WEB SE, DOI DOI 10.1145/2433396.2433443
   [Anonymous], 2014, P INT AAAI C WEB SOC
   Bao P, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P177
   Cao Q, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P70, DOI 10.1145/3336191.3371834
   Cao Q, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1149, DOI 10.1145/3132847.3132973
   Chen XQ, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P885, DOI 10.1145/3331184.3331288
   Chen XQ, 2019, PROC INT CONF DATA, P770, DOI 10.1109/ICDE.2019.00074
   Cheng J, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P925, DOI 10.1145/2566486.2567997
   Corradini E, 2021, INT J INFORM MANAGE, V60, DOI 10.1016/j.ijinfomgt.2021.102377
   Crane R, 2008, P NATL ACAD SCI USA, V105, P15649, DOI 10.1073/pnas.0803685105
   Horawalavithana S, 2020, ARXIV200412373
   Jia AL, 2018, COMPUT NETW, V140, P112, DOI 10.1016/j.comnet.2018.05.004
   Li C, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P577, DOI 10.1145/3038912.3052643
   Li HT, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P169, DOI 10.1145/2505515.2505523
   Liao DL, 2019, AAAI CONF ARTIF INTE, P200
   Liu Y, 2020, HUM-CENT COMPUT INFO, V10, DOI 10.1186/s13673-020-00218-w
   Ma CS, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P467, DOI 10.1145/3132847.3132997
   Ma J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P708, DOI 10.18653/v1/P17-1066
   Martin T, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P683, DOI 10.1145/2872427.2883001
   Mishra S, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1069, DOI 10.1145/2983323.2983812
   Nasiri E, 2021, CHAOS SOLITON FRACT, V151, DOI 10.1016/j.chaos.2021.111230
   Rizoiu MA, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P735, DOI 10.1145/3038912.3052650
   Saha A, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1335, DOI 10.1145/3340531.3412025
   Seo Y, 2018, LECT NOTES COMPUT SC, V11301, P362, DOI 10.1007/978-3-030-04167-0_33
   Shen HW, 2014, AAAI CONF ARTIF INTE, P291
   Shulman Benjamin, 2016, ICWSM, P348
   Vadivu DK., 2017, INT J TREND SCI RES, V1, P796, DOI [10.31142/ijtsrd2366, DOI 10.31142/IJTSRD2366]
   Wu QT, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P517, DOI 10.1145/3269206.3271714
   Xu Z, 2020, CASGCN PREDICTING FU
   Yang C, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4033
   Yang J., 2011, P 4 ACM INT C WEB SE, P177, DOI DOI 10.1145/1935826.1935863
   Yu H, 2020, IEEE ACCESS, V8, P61453, DOI 10.1109/ACCESS.2020.2983583
   Zaman T, 2014, ANN APPL STAT, V8, P1583, DOI 10.1214/14-AOAS741
NR 35
TC 0
Z9 0
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1459
EP 1475
DI 10.1007/s11042-022-12989-8
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000781124000025
DA 2024-07-18
ER

PT J
AU Djaghbellou, S
   Attia, A
   Bouziane, A
   Akhtar, Z
AF Djaghbellou, Soumia
   Attia, Abdelouahab
   Bouziane, Abderraouf
   Akhtar, Zahid
TI Local features enhancement using deep auto-encoder scheme for the
   recognition of the proposed handwritten Arabic-Maghrebi characters
   database
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arabic database; Maghrebi style; Handwritten; Gabor filters; HOG; BSIF;
   Nearest neighbors classifier; Classification
ID TEXT
AB Over the years, automated handwritten Arabic character recognition systems have evolved. However, optical Arabic character recognition systems still suffer from low performances in the wild because of high human handwriting variations, styles, ambiguity and complexity. One of the main contributions of this paper is to create and present in detail a new database for Handwritten Arabic-Maghrebi Characters (HAMCDB), this handwriting style, which is represented and used for the first time in this field of character recognition and is much more difficult, poses additional challenges and complexities due to its characteristics. The database consists of all shapes of Arabic characters written in the Maghrebi style. The samples in the database were obtained from a variety of sources, the most important of which was the Algerian manuscripts portal (http://pam.univ-adrar.edu.dz/), which is a platform designed by the work team of the Algerian Manuscript's laboratory in Africa, to safeguard the humanitarian patrimony, where the reader can view and download digital copies and through this work by offering an OCR that is specific to the style of our region, we hope to make the search's operation more easier. HAMCDB understands a total of 1560 character images with 78 shapes and 20 images for each one. We propose a new and efficient Arabic handwritten character recognition scheme, tested on two datasets; the new proposed dataset HAMCDB compared to the public database AHCD of handwritten Arabic characters, where the local features using Gabor filter, Histogram of Oriented Gradients (HOG) and Binarized Statistical Image Features (BSIF) are enhanced with a deep auto-encoder architecture for better accuracy. These features are finally fed to a classification process based on nearest neighbor's classifier and cosine Mahalanobis distance to obtain final character labels. Experimental analyses on HAMCDB and AHCD databases, versus existing methods demonstrate the efficacy of the presented framework, and our framework's performance is promising, achieving accuracies of 98.63% and 98.95% using Gabor filters for HAMCDB and AHCD respectively, and 100% with HOG and BSIF.
C1 [Djaghbellou, Soumia; Attia, Abdelouahab] Mohamed El Bachir El Ibrahimi Univ Bordj Bou Arre, Dept Comp Sci, El Anasser, Algeria.
   [Bouziane, Abderraouf] Mohammed El Bachir El Ibrahimi Univ Bordj Bou Arr, MSE Lab, El Anceur, Algeria.
   [Akhtar, Zahid] State Univ New York Polytech Inst, Dept Network & Comp Secur, Utica, NY USA.
RP Djaghbellou, S (corresponding author), Mohamed El Bachir El Ibrahimi Univ Bordj Bou Arre, Dept Comp Sci, El Anasser, Algeria.
EM simo.djaghbellou@gmail.com; attia.abdelouahab@gmail.com;
   bouziane.abderraouf@gmail.com; akhtarz@sunypoly.edu
RI ATTIA, Abdelouahab/ADD-8906-2022; ATTIA, Abdelouahab/HJA-2990-2022
OI Akhtar, Zahid/0000-0002-5026-5416; ATTIA,
   Abdelouahab/0000-0003-1558-7273
CR Abandah G., 2010, Dirasat Engineering Sciences Journal, V37
   Ahmad R, 2020, INT ARAB J INF TECHN, V17, P299, DOI 10.34028/iajit/17/3/3
   Al-Ma'adeed S, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P485, DOI 10.1109/IWFHR.2002.1030957
   Al-Nassiri AMER, NEW ARABIC AHD AMSH
   Al-Ohali Y, 2003, PATTERN RECOGN, V36, P111, DOI 10.1016/S0031-3203(02)00064-X
   Alamri H, 2008, P 11 INT C FRONT HAN, P664
   Altwaijry N, 2021, NEURAL COMPUT APPL, V33, P2249, DOI 10.1007/s00521-020-05070-8
   [Anonymous], 2011, P 2011 14 EUROPEAN C
   [Anonymous], 2002, PRIK CIFED
   Assayony Mohammed O., 2018, International Journal of Computing and Digital Systems, V7, P35, DOI 10.12785/ijcds/0701004
   Attia A, 2018, EVOL SYST, P1
   Balaha HM, 2021, NEURAL COMPUT APPL, V33, P6325, DOI 10.1007/s00521-020-05397-2
   Chen J., 2010, 9th IAPR International Workshop on Document Analysis Systems (DAS), P53, DOI 10.1145/1815330.1815337
   Cheriet M, 2008, LECT NOTES COMPUT SC, V4768, P1, DOI 10.1007/978-3-540-78199-8_1
   Djaghbellou S., 2020, ICTACT J IMAGE VIDEO, V10, P2195
   El-Sherif Ezzat Ali, 2007, Proceedings of the 2007 International Conference on Artificial Intelligence and Pattern Recognition (AIPR-07), P237
   Elleuch M, 2017, INT ARAB J INF TECHN, V14, P639
   Elleuch M, 2016, IEEE IJCNN, P3241, DOI 10.1109/IJCNN.2016.7727613
   Elzobi M, 2012, INT CONF SIGN PROCES, P2154, DOI 10.1109/ICoSP.2012.6492007
   Farooq F, 2006, INT C PATT RECOG, P1142
   FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hafiz AM, 2016, KU DATABASE HANDWRIT
   Jebril Noor A., 2018, Pattern Recognition and Image Analysis, V28, P321, DOI 10.1134/S1054661818020141
   Kannala J, 2012, INT C PATT RECOG, P1363
   Kharma N., 1999, Engineering Solutions for the Next Millennium. 1999 IEEE Canadian Conference on Electrical and Computer Engineering (Cat. No.99TH8411), P766, DOI 10.1109/CCECE.1999.808042
   Khorashadizadeh, 2016, INT ARAB J INFORM TE, V13
   Lamghari N, 2021, J PHYS C SERIES, V1743
   Lawgali, 2015, SURVEY ARABIC CHARAC
   Lawgali A., 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P255
   Lawgali A, 2016, RECOGNITION HANDWRIT
   Märgner V, 2008, LECT NOTES COMPUT SC, V4768, P82, DOI 10.1007/978-3-540-78199-8_6
   Mahalanobis P. C., 1936, P NATL I SCI INDIA, V2, P49
   Mahmoud SA, 2014, PATTERN RECOGN, V47, P1096, DOI 10.1016/j.patcog.2013.08.009
   Maqqor A, 2014, 3 INT IEEE C INF SCI
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Mohammed D.A., 2019, INDONESIAN J ELECT E, V14, P1443
   Mozaffari S., 2006, COMPREHENSIVE ISOLAT
   Najadat HM, 2019, INT CONF INFORM COMM, P147, DOI 10.1109/iacs.2019.8809122
   Sahlol A, 2014, ARXIV PREPRINT ARXIV
   Slimane Fouad, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P946, DOI 10.1109/ICDAR.2009.155
   Torki M., 2014, ARXIV PREPRINT ARXIV
   Van den Boogert, 1989, SOME NOTES MAGHRIBI
NR 43
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31553
EP 31571
DI 10.1007/s11042-022-13032-6
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000779805700005
DA 2024-07-18
ER

PT J
AU Chammas, M
   Makhoul, A
   Demerjian, J
   Dannaoui, E
AF Chammas, Michel
   Makhoul, Abdallah
   Demerjian, Jacques
   Dannaoui, Elie
TI A deep learning based system for writer identification in handwritten
   Arabic historical manuscripts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Writer identification; Historical documents; Artificial intelligence;
   Document analysis; Arabic manuscripts
ID KHATT
AB Determining the writer or transcriber of historical Arabic manuscripts has always been a major challenge for researchers in the field of humanities. With the development of advanced techniques in pattern recognition and machine learning, these technologies have been applied to automate the extraction of paleographical features in order to solve this issue. This paper presents a baseline system for writer identification, tested on a Historical Arabic dataset of 11610 single and double folio images. These texts were extracted from a unique collection of 567 Historical Arabic Manuscripts available at the Balamand Digital Humanities Center. A survey has been conducted on the available Arabic datasets and previously proposed techniques and algorithms. The Balamand dataset presents an important challenge due to the geo-historical identity of manuscripts and their physical conditions. An advanced Deep Learning system was developed and tested on three different Latin and Arabic datasets: ICDAR19, ICFHR20 and KHATT, before testing it on the Balamand dataset. The system was compared with many other systems and it has yielded a state-of-the-art performance on the new challenging images with 95.2% mean Average Precision (mAP) and 98.1% accuracy.
C1 [Chammas, Michel; Dannaoui, Elie] Univ Balamand, Digital Humanities Ctr, El Koura, Lebanon.
   [Chammas, Michel; Makhoul, Abdallah] Univ Bourgogne Franche Comte, CNRS, UMR 6174, Femto ST Inst, Montb eliard, France.
   [Demerjian, Jacques] Lebanese Univ, LaRRIS, Fac Sci, Fanar, Lebanon.
C3 University Balamand; Universite de Technologie de Belfort-Montbeliard
   (UTBM); Centre National de la Recherche Scientifique (CNRS); CNRS -
   Institute for Engineering & Systems Sciences (INSIS); Universite de
   Franche-Comte; Lebanese University
RP Chammas, M (corresponding author), Univ Balamand, Digital Humanities Ctr, El Koura, Lebanon.; Chammas, M (corresponding author), Univ Bourgogne Franche Comte, CNRS, UMR 6174, Femto ST Inst, Montb eliard, France.
EM michel.chammas@balamand.edu.lb; abdallah.makhoul@univ-fcomte.fr;
   jacques.demerjian@ul.edu.lb; elie.dannaoui@balamand.edu.lb
RI Makhoul, Abdallah/K-7535-2018; Demerjian, Jacques/AAT-4694-2020;
   Chammas, Michel/I-7915-2018
OI Demerjian, Jacques/0000-0001-9798-8390; Chammas,
   Michel/0000-0003-3261-9417
FU EIPHI Graduate School [ANR-17-EURE0002]; NVIDIA Corporation
FX This research is funded by the EIPHI Graduate School (contract
   "ANR-17-EURE0002"). We gratefully acknowledge the support of NVIDIA
   Corporation with the donation of the Quadro RTX 6000 GPU used for this
   research.
CR Abdelhaleem A, 2017, 2017 1ST INTERNATIONAL WORKSHOP ON ARABIC SCRIPT ANALYSIS AND RECOGNITION (ASAR), P64, DOI 10.1109/ASAR.2017.8067761
   Abdleazeem S, 2008, INT J DOC ANAL RECOG, V11, P127, DOI 10.1007/s10032-008-0073-5
   [Anonymous], ARAB MAN ANT ORTH MO, V1-2
   Asi A, 2017, INT J DOC ANAL RECOG, V20, P173, DOI 10.1007/s10032-017-0289-3
   Awaida, 2011, 1 INT WORKSH FRONT A
   Awaida S.M., 2012, Educ. Res. Rev, V7, P445, DOI [10.5897/ERR11.303, DOI 10.5897/ERR11.303]
   Bausi A, 2015, COMST
   Chammas M, 2020, 19 INT C MACHINE LEA
   Chandra K, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P115, DOI 10.1109/ICICCS.2016.7542340
   Chaurasia P, 2014, BIOMETRICS MINUTIAE
   Chen SM, 2019, INFORM SCIENCES, V482, P156, DOI 10.1016/j.ins.2019.01.024
   Christlein V, 2019, ICDAR 2019 COMPETITI
   Christlein V, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P169, DOI 10.1109/DAS.2018.9
   Christlein V, 2017, PROC INT CONF DOC, P991, DOI 10.1109/ICDAR.2017.165
   Christlein V, 2017, PATTERN RECOGN, V63, P258, DOI 10.1016/j.patcog.2016.10.005
   Christlein V, 2014, IEEE WINT CONF APPL, P998, DOI 10.1109/WACV.2014.6835995
   De roche FCO, 2012, MANUSCRIPTS ARABIC C
   Deroche Francois., 2005, Islamic Codicology: An Introduction to the Study of Manuscripts in Arabic Script
   Djeddi C., 2011, 2011 Fourth International Symposium on Innovation in Information & Communication Technology (ISIICT), P159, DOI 10.1109/ISIICT.2011.6149612
   Fecker D, 2014, INT CONF FRONT HAND, P743, DOI 10.1109/ICFHR.2014.130
   Fecker D, 2014, INT C PATT RECOG, P3050, DOI 10.1109/ICPR.2014.526
   Fiel S, 2015, LECT NOTES COMPUT SC, V9257, P26, DOI 10.1007/978-3-319-23117-4_3
   Hannad Y, 2019, IET BIOMETRICS, V8, P221, DOI 10.1049/iet-bmt.2018.5009
   Nguyen HT, 2019, PATTERN RECOGN LETT, V121, P104, DOI 10.1016/j.patrec.2018.07.022
   Lai SX, 2020, IEEE T INF FOREN SEC, V15, P3553, DOI 10.1109/TIFS.2020.2991880
   Mahmoud SA, 2014, PATTERN RECOGN, V47, P1096, DOI 10.1016/j.patcog.2013.08.009
   Mahmoud SA, 2012, INT CONF FRONT HAND, P449, DOI 10.1109/ICFHR.2012.224
   Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229
   Pechwitz M., 2002, P CIFED, P127
   Rehman A, 2019, MULTIMED TOOLS APPL, V78, P10889, DOI 10.1007/s11042-018-6577-1
   Seuret M, 2020, INT CONF FRONT HAND, P216, DOI 10.1109/ICFHR2020.2020.00048
   Slimane F, 2014, INT CONF FRONT HAND, P797, DOI 10.1109/ICFHR.2014.139
NR 32
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30769
EP 30784
DI 10.1007/s11042-022-12673-x
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779233200003
DA 2024-07-18
ER

PT J
AU Chaudhary, S
   Bhardwaj, A
   Rana, P
AF Chaudhary, Suneeta
   Bhardwaj, Anuj
   Rana, Puneet
TI Image enhancement by linear regression algorithm and sub-histogram
   equalization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrast enhancement; Least squares method; Absolute mean brightness
   error; Histogram equalization; Structural similarity; Peak signal to
   noise ratio; Mean opinion score
ID ADAPTIVE GAMMA CORRECTION; CONTRAST ENHANCEMENT; BRIGHTNESS PRESERVATION
AB The present paper focuses on the contrast enhancement of an image using linear regression-based recursive sub-histogram equalization. The histogram of an image is partitioned into two non-overlapping sub-histograms using the mean intensity of the image. A set of points is constructed for each sub-histogram, considering gray level (intensity) as the abscissa and its corresponding count as the ordinate of the point. Then the method of least squares is used for fitting lines of regression for these sets of points in each sub-histogram. With the help of the regression line and histogram, intervals are created in each segmented partition. This process of creating intervals gives more intervals as compared to the Recursive Sub-Image Histogram Equalization (RSIHE) and the Mean and Variance-based Sub Image Histogram Equalization methods (MVSIHE). For qualitative and quantitative analysis of the proposed method, the experiments are performed on a set of test images, including medical and non-medical images. The evaluated results are presented in terms of various evaluation metrics. For medical images, the mean opinion score is also evaluated with the proposed method and other recent methods. The comparison with state-of-the-art methods shows the efficacy of the proposed method for enhancement.
C1 [Chaudhary, Suneeta] ITS Engn Coll, Knowledge Pk 3, Greater Noida 201308, India.
   [Bhardwaj, Anuj] Jaypee Inst Informat Technol, Dept Math, Noida 201309, India.
   [Rana, Puneet] Wenzhou Kean Univ, Coll Sci & Technol, Sch Math Sci, Wenzhou 325060, Peoples R China.
C3 Jaypee Institute of Information Technology (JIIT); Wenzhou-Kean
   University
RP Rana, P (corresponding author), Wenzhou Kean Univ, Coll Sci & Technol, Sch Math Sci, Wenzhou 325060, Peoples R China.
EM puneetranaiitr@gmail.com
RI Bhardwaj, Anuj/KIE-2095-2024; Rana, Puneet/AAW-1502-2020
OI Bhardwaj, Anuj/0000-0003-0866-2618; Rana, Puneet/0000-0002-9850-763X
CR Abdoli M, 2015, IET IMAGE PROCESS, V9, P569, DOI 10.1049/iet-ipr.2014.0583
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Casaca W, 2014, PATTERN RECOGN LETT, V36, P36, DOI 10.1016/j.patrec.2013.08.023
   Chandrasekharan R, 2018, IEEE SIGNAL PROC LET, V25, P813, DOI 10.1109/LSP.2018.2812861
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Du S, 2010, IEEE T CIRC SYST VID, V20, P1165, DOI 10.1109/TCSVT.2010.2045817
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Hanmandlu M, 2009, IEEE T INSTRUM MEAS, V58, P2867, DOI 10.1109/TIM.2009.2016371
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Huang TH, 2013, IEEE T IMAGE PROCESS, V22, P4587, DOI 10.1109/TIP.2013.2272517
   Iqbal MZ, 2013, IEEE GEOSCI REMOTE S, V10, P451, DOI 10.1109/LGRS.2012.2208616
   Khan MF, 2014, DIGIT SIGNAL PROCESS, V25, P198, DOI 10.1016/j.dsp.2013.10.015
   Kim D, 2017, IEEE SIGNAL PROC LET, V24, P804, DOI 10.1109/LSP.2017.2687945
   Kim M, 2008, IEEE T CONSUM ELECTR, V54, P1389, DOI 10.1109/TCE.2008.4637632
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Koppanati K., 2019, INT C DEEP LEARN ART, P246
   Kumain SC, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P243, DOI 10.1109/ICSCCC.2018.8703305
   Kumar A, 2018, P NATL A SCI INDIA A, V88, P95, DOI 10.1007/s40010-017-0369-2
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Li B, 2015, COMPUT ELECTR ENG, V45, P324, DOI 10.1016/j.compeleceng.2015.02.013
   Liang K, 2012, INFRARED PHYS TECHN, V55, P309, DOI 10.1016/j.infrared.2012.03.004
   Ooi CH, 2009, IEEE T CONSUM ELECTR, V55, P2072, DOI 10.1109/TCE.2009.5373771
   Pichai S, 2013, INT ARAB J INF TECHN, V10, P603
   Rao BS, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106114
   Santhi K, 2015, OPTIK, V126, P1809, DOI 10.1016/j.ijleo.2015.05.023
   Shanmugavadivu P, 2014, OPT LASER TECHNOL, V57, P243, DOI 10.1016/j.optlastec.2013.07.013
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Sun CC, 2005, IEEE T CONSUM ELECTR, V51, P1300
   Sun G, 2014, APPL OPTICS, V53, P6013, DOI 10.1364/AO.53.006013
   Tang JR, 2017, APPL SOFT COMPUT, V55, P31, DOI 10.1016/j.asoc.2017.01.053
   Tang JR, 2016, TURK J ELECTR ENG CO, V24, P3564, DOI 10.3906/elk-1403-44
   Tsai CM, 2008, IEEE T CONSUM ELECTR, V54, P213, DOI 10.1109/TCE.2008.4560077
   Veluchamy M, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106077
   Veluchamy M, 2019, OPTIK, V183, P329, DOI 10.1016/j.ijleo.2019.02.054
   Wadhwa A, 2021, MULTIMED TOOLS APPL, V80, P21595, DOI 10.1007/s11042-021-10743-0
   Wadhwa A, 2020, MULTIMED TOOLS APPL, V79, P25379, DOI 10.1007/s11042-020-09177-x
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Yoo JC, 2012, IET IMAGE PROCESS, V6, P483, DOI 10.1049/iet-ipr.2011.0025
   Zhuang LY, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/6029892
NR 43
TC 5
Z9 5
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 29919
EP 29938
DI 10.1007/s11042-022-12830-2
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500005
DA 2024-07-18
ER

PT J
AU Katada, S
   Okada, S
AF Katada, Shun
   Okada, Shogo
TI Biosignal-based user-independent recognition of emotion and personality
   with importance weighting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Importance weighting; Biosignal; Affective computing
ID COVARIATE SHIFT; DATABASE; AROUSAL; MODEL
AB For modeling human intelligence, understanding emotional intelligence as well as verbal and mathematical intelligence is an important and challenging issue. In affective and personality computing, it has been reported that not only visual and audio signals but also biosignals are useful for estimating emotions and personality. Biosignals are expected to provide additional and less biased information in implicit assessment, but estimation performance can degrade if there are physiological individual differences. In this paper, considering individual physiological differences as a covariate shift, we aimed to improve the performance results in biosignal-based emotion and personality estimations. For this purpose, we constructed importance-weighted logistic regression (IW-LR) and importance-weighted support vector machine (IW-SVM), which mitigate the accuracy degradation due to physiological individual differences in the training data, and compared them with conventional LR and linear SVM (L-SVM) for estimation performance. As a result, most of the IW models outperform conventional models based on electrocardiogram (ECG) and galvanic skin response (GSR) features in emotion estimation. In the personality estimation, the IW method improves the macroaveraged F1-score for all SVM models. The best performing model (GSR model) outperformed the model with the best previously reported macroaveraged F1-score by 1.9% in personality estimation. These results indicate that importance weighting in machine learning models can reduce the effects of individual physiological differences in peripheral physiological responses and contribute to the proposal of a new model for emotion and personality estimations based on biosignals.
C1 [Katada, Shun; Okada, Shogo] Japan Adv Inst Sci & Technol, Nomi, Ishikawa, Japan.
C3 Japan Advanced Institute of Science & Technology (JAIST)
RP Katada, S (corresponding author), Japan Adv Inst Sci & Technol, Nomi, Ishikawa, Japan.
EM s2040005@jaist.ac.jp; okada-s@jaist.ac.jp
OI Okada, Shogo/0000-0002-9260-0403; Katada, Shun/0000-0003-3241-4470
FU Japan Society for the Promotion of Science (JSPS) KAKENHI [19H01120,
   19H01719]; JST AIP Trilateral AI Research, Japan [JPMJCR20G6];
   Grants-in-Aid for Scientific Research [19H01719, 22H04860] Funding
   Source: KAKEN
FX The authors wish to thank the AMIGOS project members for sharing data.
   This work was partially supported by the Japan Society for the Promotion
   of Science (JSPS) KAKENHI Grant Numbers 19H01120, 19H01719, and JST AIP
   Trilateral AI Research, Grant Number JPMJCR20G6, Japan.
CR Abadi MK, 2015, IEEE T AFFECT COMPUT, V6, P209, DOI 10.1109/TAFFC.2015.2392932
   [Anonymous], 2012, Handbook of Computational Statistics
   Barral O, 2014, LECT NOTES COMPUT SC, V8820, P35, DOI 10.1007/978-3-319-13500-7_3
   Batrinca LM, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P39
   Chang EJ, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P137, DOI [10.1109/AICAS.2019.8771622, 10.1109/aicas.2019.8771622]
   Costa P.T., 1992, REVISED NEO PERSONAL
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Eyben F., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P322, DOI 10.1109/FG.2011.5771417
   Eysenck Hans J., 1950, Dimensions of personality, V5
   Gizycka B, 2018, 2018 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), P458, DOI 10.1109/GEM.2018.8516439
   Gjoreski M, 2018, INFORM-J COMPUT INFO, V42, P61
   Gjoreski M, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT), P754, DOI 10.1145/3123024.3125608
   Gross JJ, 2011, EMOT REV, V3, P8, DOI 10.1177/1754073910380974
   Gunes H, 2010, LECT NOTES ARTIF INT, V6356, P371, DOI 10.1007/978-3-642-15892-6_39
   Harper R, 2022, IEEE T AFFECT COMPUT, V13, P985, DOI 10.1109/TAFFC.2020.2981610
   Hassan A, 2013, IEEE T AUDIO SPEECH, V21, P1458, DOI 10.1109/TASL.2013.2255278
   Ivanov AV, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P1560
   Kanamori T, 2013, MACH LEARN, V90, P431, DOI 10.1007/s10994-012-5323-6
   Kanamori T, 2012, MACH LEARN, V86, P335, DOI 10.1007/s10994-011-5266-3
   Kanamori T, 2009, J MACH LEARN RES, V10, P1391
   Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kolodyazhniy V, 2011, PSYCHOPHYSIOLOGY, V48, P908, DOI 10.1111/j.1469-8986.2010.01170.x
   Komulainen E, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110907
   Kouw WM, 2019, IEEE INT WORKS MACH
   Landwehr N, 2005, MACH LEARN, V59, P161, DOI 10.1007/s10994-005-0466-3
   Lane RD, 2009, NEUROIMAGE, V44, P213, DOI 10.1016/j.neuroimage.2008.07.056
   Leiner D, 2012, COMMUN METHODS MEAS, V6, P237, DOI 10.1080/19312458.2012.732627
   Li Y, 2010, IEEE T BIO-MED ENG, V57, P1318, DOI 10.1109/TBME.2009.2039997
   Li YT, 2016, MULTIMED TOOLS APPL, V75, P7999, DOI 10.1007/s11042-015-2717-z
   Mairesse F, 2007, J ARTIF INTELL RES, V30, P457, DOI 10.1613/jair.2349
   Markova V, 2018, PROCEEDINGS OF THE 2018 SEVENTH BALKAN CONFERENCE ON LIGHTING (BALKANLIGHT), P115
   McDuff D, 2013, IEEE COMPUT SOC CONF, P881, DOI 10.1109/CVPRW.2013.130
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   Meagher M, 2007, IEEE INT CONF INF VI, P601
   Mehta Y, 2020, ARTIF INTELL REV, V53, P2313, DOI 10.1007/s10462-019-09770-z
   Miranda-Correa JA, 2021, IEEE T AFFECT COMPUT, V12, P479, DOI 10.1109/TAFFC.2018.2884461
   Miranda-Correa JA, 2018, IEEE INT CONF AUTOMA, P373, DOI 10.1109/FG.2018.00060
   Mou WX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3321509
   Perrin AF, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1007, DOI 10.1145/2733373.2806387
   Picard R.W., 2000, Affective Computing
   Picard RW, 2016, IEEE MULTIMEDIA, V23, P3, DOI 10.1109/MMUL.2016.38
   Ren Z, 2014, IEEE INTERNET THINGS, V1, P243, DOI 10.1109/JIOT.2014.2322331
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Santamaria-Granados L, 2019, IEEE ACCESS, V7, P57, DOI 10.1109/ACCESS.2018.2883213
   Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4
   Siddharth, 2018, IEEE ENG MED BIO, P291, DOI 10.1109/EMBC.2018.8512320
   Singh N, 2018, ARRHYTH ELECTROPHYSI, V7, P247, DOI 10.15420/aer.2018.30.2
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Stemmler G, 2010, BIOL PSYCHOL, V84, P541, DOI 10.1016/j.biopsycho.2009.09.012
   Subramanian R, 2018, IEEE T AFFECT COMPUT, V9, P147, DOI 10.1109/TAFFC.2016.2625250
   Sugiyama M, 2008, ANN I STAT MATH, V60, P699, DOI 10.1007/s10463-008-0197-x
   Terasawa Naoto, 2017, ICMI 16 P 18 ACM INT, P321
   Tobin RM, 2000, J PERS SOC PSYCHOL, V79, P656, DOI 10.1037//0022-3514.79.4.656
   Tsang IW, 2005, J MACH LEARN RES, V6, P363
   Tsuboi Y., 2009, Journal of Information Processing, V17, P138, DOI [10.2197/ipsjjip.17.138, DOI 10.1137/1.9781611972788.40.27]
   Tung K, 2018, IEEE EMBS CONF BIO, P22, DOI 10.1109/IECBES.2018.8626634
   van den Burg GJ, 2017, ARXIV171103512
   Vinciarelli A, 2014, IEEE T AFFECT COMPUT, V5, P273, DOI 10.1109/TAFFC.2014.2330816
   Wald A, 1947, ECONOMETRICA, V15, P279, DOI 10.2307/1905331
   Wang SH, 2018, IFIP ADV INF COMM TE, V519, P249, DOI 10.1007/978-3-319-92007-8_22
   Weisberg S., 2005, Applied linear regression, V528
   Wilson G, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3400066
   Yamada M, 2010, SIGNAL PROCESS, V90, P2353, DOI 10.1016/j.sigpro.2009.06.001
   Yang HC, 2019, INT CONF ACOUST SPEE, P1184, DOI 10.1109/ICASSP.2019.8683290
   Zbilut JP, 2002, MED ENG PHYS, V24, P53, DOI 10.1016/S1350-4533(01)00112-6
   Zhao SC, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1660
   Zohar A.H., 2013, Open Journal of Social Sciences, V01, P32
   Zuckerman M, 1995, PSYCHOL SCI, V6, P325, DOI 10.1111/j.1467-9280.1995.tb00521.x
NR 69
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30219
EP 30241
DI 10.1007/s11042-022-12711-8
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500007
DA 2024-07-18
ER

PT J
AU Hou, MZ
   Feng, ZL
   Wang, HB
   Shen, ZW
   Li, S
AF Hou, Mingzheng
   Feng, Ziliang
   Wang, Haobo
   Shen, Zhiwei
   Li, Sheng
TI An adaptive regression based single-image super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Dictionary learning; Global regression; Sparse
   representation; Image clustering
ID NETWORK
AB Image super-resolution (SR) is an important topic of low-level computer vision and is widely used in different fields. In this paper, a novel single-image SR method, which integrates image clustering, sparse representation and linear regression is proposed. Existing global regression based methods usually assume that the corresponding coefficients of HR and LR image patches are equal, which cannot be strictly guaranteed in practice and possibly leads to inaccurate coefficient estimation. In order to adapt the regression model to different types of patches, clustering operations are applied on the training patches to calculate the coefficients of the HR and LR training patches in each class under the same pair of dictionaries. Then the projection relationship between the coefficients of HR and LR training patches in each class is obtained by solving a ridge regression problem. From the experimental results, our algorithm demonstrates better results in both qualitative and quantitative aspects and the computational speed of our methods is noticeably less than other competitive methods.
C1 [Hou, Mingzheng; Feng, Ziliang] Sichuan Univ, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu 610065, Sichuan, Peoples R China.
   [Hou, Mingzheng; Feng, Ziliang; Wang, Haobo; Li, Sheng] Sichuan Univ, Coll Comp Sci, Coll Software Engn, Chengdu 610065, Sichuan, Peoples R China.
   [Shen, Zhiwei] Sichuan Univ, Coll Elect Informat, Chengdu 610065, Sichuan, Peoples R China.
C3 Sichuan University; Sichuan University; Sichuan University
RP Feng, ZL (corresponding author), Sichuan Univ, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu 610065, Sichuan, Peoples R China.; Feng, ZL (corresponding author), Sichuan Univ, Coll Comp Sci, Coll Software Engn, Chengdu 610065, Sichuan, Peoples R China.
EM fengziliang@scu.edu.cn
RI feng, ziliang/AAB-5612-2022
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Alzubi J. A., 2019, Indian J. Public Health Res. Dev, V10, P267, DOI [10.5958/0976-5506.2019.00298.5, DOI 10.5958/0976-5506.2019.00298.5]
   ALzubi JA, 2019, APPL SOFT COMPUT, V80, P579, DOI 10.1016/j.asoc.2019.04.031
   [Anonymous], 2015, ICTSD, DOI DOI 10.1109/ICTSD.2015.7095900
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Cai WW, 2021, MULTIMED TOOLS APPL, V80, P11291, DOI 10.1007/s11042-020-10188-x
   Cai WW, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3026587
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   DUCHON CE, 1979, J APPL METEOROL, V18, P1016, DOI 10.1175/1520-0450(1979)018<1016:LFIOAT>2.0.CO;2
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Huang SY, 2018, IEEE T IMAGE PROCESS, V27, P2650, DOI 10.1109/TIP.2018.2809472
   Jain DK, 2020, J REAL-TIME IMAGE PR, V17, P2113, DOI 10.1007/s11554-019-00889-4
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P15, DOI 10.1109/TMM.2016.2599145
   Lai W-S, 2017, PROC CVPR IEEE, P624, DOI DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lin F, 2007, LECT NOTES COMPUT SC, V4642, P1
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Meijering E, 2003, IEEE T IMAGE PROCESS, V12, P477, DOI 10.1109/TIP.2003.811493
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Rani SS, 2020, MULTIMED TOOLS APPL, V79, P35405, DOI 10.1007/s11042-019-07760-5
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wan BK, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS, P46, DOI 10.1109/CIMSA.2009.5069916
   Wang HJ, 2016, IEEE T IMAGE PROCESS, V25, P935, DOI 10.1109/TIP.2015.2512104
   Wang Hui-peng, 2010, Computer Engineering, V36, P216
   Wang YF, 2018, IEEE COMPUT SOC CONF, P977, DOI 10.1109/CVPRW.2018.00131
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang WM, 2020, NEUROCOMPUTING, V398, P291, DOI 10.1016/j.neucom.2019.09.091
   Yang ZL, 2021, IEEE T INF FOREN SEC, V16, P880, DOI 10.1109/TIFS.2020.3023279
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang XF, 2009, LECT NOTES COMPUT SC, V5879, P1197, DOI 10.1007/978-3-642-10467-1_121
   Zhang YN, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/5859727
   Zhao F, 2019, MULTIMED TOOLS APPL, V78, P28453, DOI 10.1007/s11042-017-5493-0
NR 40
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28231
EP 28248
DI 10.1007/s11042-022-12911-2
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000775769200008
DA 2024-07-18
ER

PT J
AU Lu, FL
   Fu, CC
   Shi, J
   Zhang, GY
AF Lu, Fengli
   Fu, Chengcai
   Shi, Jie
   Zhang, Guoying
TI Attention based deep neural network for micro-fracture extraction of
   sequential coal rock CT images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attention; Sequential images; ConvLSTM; Coal rock fractures; U-Net
ID SEGMENTATION; FRACTURES
AB The extraction and analysis of fractures from sequential coal rock Computed Tomography images play an important guiding role in development of coalbed methane and permeability calculation. However, the fracture extraction from sequential coal rock CT images is usually associated with tremendous complexities due to the low-contrast and high noise. Especially, the fractures cannot be accurately segmented in the case of the close grayscale values between micro-fractures and the surrounding coal matrix. In order to tackle these challenges, this paper proposes a deep neural network (A-DNNet) based on U-Net framework for extracting micro-fractures of sequential coal rock images. Specifically, in the proposed A-DNNet, (1) a number of continuous slices are fed into CNN encoder, and these smaller size continuous feature maps are obtained by recursive operations of convolution and down-sampling; (2) ConvLSTM (convolutional LSTM) is introduced to model the inter-slices fracture correlations for the smaller size feature maps outputted by CNN encoder; (3) RFA is proposed to refine fracture features gradually by capturing discriminative features. Compared with U-Net algorithms, the extensive experiments demonstrate that our method improve the average accuracy by 1.14%, the average precision by 2.60%, the average Dice by 3.20%, the average F1 by 2.45%, respectively. The robust fractures extraction performance of our methods will inform continuing future research into the development for fracture evolution and permeability calculation.
C1 [Lu, Fengli; Fu, Chengcai; Shi, Jie; Zhang, Guoying] China Univ Min & Technol, Sch Mech Elect & Informat Engn, Beijing, Peoples R China.
C3 China University of Mining & Technology
RP Zhang, GY (corresponding author), China Univ Min & Technol, Sch Mech Elect & Informat Engn, Beijing, Peoples R China.
EM zhangguoying1101@163.com
RI Zhang, Guoying/G-8945-2016
OI Zhang, Guoying/0000-0001-9568-3702
FU National Natural Science Foundation of China [U1704242]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. U1704242).
CR Appia V, 2011, IEEE I CONF COMP VIS, P1975, DOI 10.1109/ICCV.2011.6126468
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Choudhury A, 2021, MULTIMED TOOLS APPL, V80, P35649, DOI 10.1007/s11042-020-10470-y
   Deng H, 2016, COMPUTAT GEOSCI, V20, P231, DOI 10.1007/s10596-016-9560-9
   Fan TL, 2021, SIGNAL IMAGE VIDEO P, V15, P1089, DOI 10.1007/s11760-020-01835-9
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Karimpouli S, 2020, NAT RESOUR RES, V29, P1675, DOI 10.1007/s11053-019-09536-y
   Li CW, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185750
   Li H., 2018, ARXIV
   Li J, 2017, IEEE T NEUR NET LEAR, V28, P690, DOI 10.1109/TNNLS.2016.2522428
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Liu LM, 2020, IEEE ICC, DOI 10.1109/icc40277.2020.9148862
   Liu YY, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/7384085
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Mostaghimi P, 2017, J NAT GAS SCI ENG, V39, P143, DOI 10.1016/j.jngse.2017.01.025
   Nabavi S., 2018, BMVC, P1
   Nithila EE, 2016, ALEX ENG J, V55, P2583, DOI 10.1016/j.aej.2016.06.002
   Park J., 2018, BRIT MACH VIS C, P147
   Pfeuffer A, 2019, IEEE INT C INTELL TR, P1072, DOI [10.1109/ITSC.2019.8917487, 10.1109/itsc.2019.8917487]
   Pfeuffer A, 2019, IEEE INT VEH SYM, P1441, DOI [10.1109/ivs.2019.8813852, 10.1109/IVS.2019.8813852]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sarcheshmeh AN., 2017, COMMUNICATIONS ADV C, V2017, P70, DOI [10.5899/2017/cacsa-00077, DOI 10.5899/2017/CACSA-00077]
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Shi XH, 2018, FUEL, V212, P162, DOI 10.1016/j.fuel.2017.09.115
   Tareef A, 2018, IEEE T MED IMAGING, V37, P2044, DOI 10.1109/TMI.2018.2815013
   Voorn M, 2013, COMPUT GEOSCI-UK, V57, P44, DOI 10.1016/j.cageo.2013.03.006
   Wang Q, 2019, ARXIV COMPUTER VISI
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu HS, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2021.102025
   Yan ZP, 2020, MULTIMED TOOLS APPL, V79, P32415, DOI 10.1007/s11042-020-09664-1
   Yang J, 2022, MULTIMED TOOLS APPL, V81, P35983, DOI 10.1007/s11042-021-10841-z
   Ye LW, 2020, IEEE T MULTIMEDIA, V22, P3224, DOI 10.1109/TMM.2020.2971171
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Yuan M, 2019, REMOTE SENS LETT, V10, P506, DOI 10.1080/2150704X.2019.1574990
   Zhang A, 2019, COMPUT-AIDED CIV INF, V34, P213, DOI 10.1111/mice.12409
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou A, 2017, ENVIRON EARTH SCI, V76, DOI 10.1007/s12665-017-6564-2
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zou Q, 2020, IEEE T VEH TECHNOL, V69, P41, DOI 10.1109/TVT.2019.2949603
NR 42
TC 3
Z9 3
U1 8
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26463
EP 26482
DI 10.1007/s11042-022-12033-9
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000780464800008
DA 2024-07-18
ER

PT J
AU Du, NT
   Zhou, YQ
   Deng, W
   Luo, QF
AF Du, Nating
   Zhou, Yongquan
   Deng, Wu
   Luo, Qifang
TI Improved chimp optimization algorithm for three-dimensional path
   planning problem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Three-dimensional path planning; Chimp optimization algorithm;
   Somersault foraging strategy; Dynamic weighting factor; Metaheuristic
ID UNMANNED AERIAL VEHICLE; UAV
AB The three-dimensional (3D) path planning of unmanned aerial vehicle (UAV) focuses on avoiding collision with obstacles and finding the optimal path to reach the target position in the complex environment. An improved Chimp optimization algorithm (IChOA) based on somersault foraging strategy with adaptive weight was proposed to solve the three-dimensional path planning problem. Firstly, the position vector updating equation was dynamically adjusted by introducing the weighting factor derived from coefficient vector of the ChOA. Secondly, the somersault foraging strategy was introduced to prevent the group from falling into a local optimum in the later stage, and at the same time, the population diversity in the early stage was slightly improved. The algorithm was tested on CEC2019 functions and three-dimensional path planning. Compared with other methods, the results show that this algorithm can provide more competitive results.
C1 [Du, Nating; Zhou, Yongquan; Luo, Qifang] Guangxi Univ Nationalities, Coll Artificial Intelligence, Nanning 530006, Peoples R China.
   [Du, Nating; Zhou, Yongquan; Luo, Qifang] Guangxi Key Labs Hybrid Computat & IC Design Anal, Nanning 530006, Peoples R China.
   [Deng, Wu] Civil Aviat Univ China, Coll Elect Informat & Automat, Tianjin 300300, Peoples R China.
C3 Guangxi Minzu University; Civil Aviation University of China
RP Zhou, YQ (corresponding author), Guangxi Univ Nationalities, Coll Artificial Intelligence, Nanning 530006, Peoples R China.; Zhou, YQ (corresponding author), Guangxi Key Labs Hybrid Computat & IC Design Anal, Nanning 530006, Peoples R China.
EM yongquanzhou@126.com
RI Zhou, Yongquan/AAI-3982-2021; LUO, QI/GQH-7209-2022; Luo,
   Qiquan/JGD-7418-2023
OI Zhou, Yongquan/0000-0001-6945-4922; Luo, Qiquan/0000-0003-1450-2856;
   zhou, yongquan/0000-0003-4404-952X
FU National Science Foundation of China [62066005, U21A20464]; Project of
   the Guangxi Science and Technology [AD21196006]
FX This work is supported by National Science Foundation of China under
   Grants 62066005, U21A20464, and by the Project of the Guangxi Science
   and Technology under Grant No. AD21196006.
CR Andreev MA, 2012, J COMPUT SYS SC INT+, V51, P328, DOI 10.1134/S1064230712010030
   Bhattacharya P, 2008, IEEE ROBOT AUTOM MAG, V15, P58, DOI 10.1109/MRA.2008.921540
   Boesch C, 2002, HUM NATURE-INT BIOS, V13, P27, DOI 10.1007/s12110-002-1013-6
   Bogar E, 2020, APPL SOFT COMPUT, V95, DOI 10.1016/j.asoc.2020.106503
   Cekmez U, 2014, INT CONF UNMAN AIRCR, P347, DOI 10.1109/ICUAS.2014.6842273
   Duan HB, 2010, SIMUL MODEL PRACT TH, V18, P1104, DOI 10.1016/j.simpat.2009.10.006
   Girbacia Teodora, 2015, Applied Mechanics and Materials, V772, P471, DOI 10.4028/www.scientific.net/AMM.772.471
   [郭振洲 Guo Zhenzhou], 2017, [计算机应用研究, Application Research of Computers], V34, P3603
   Kaur M, 2022, ENG COMPUT-GERMANY, V38, P975, DOI 10.1007/s00366-020-01233-2
   Khishe M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113338
   Khishe M, 2020, APPL ACOUST, V157, DOI 10.1016/j.apacoust.2019.107005
   Kumar SV, 2020, OCEAN ENG, V217, DOI 10.1016/j.oceaneng.2020.107932
   Kumari Ch Leela, 2020, E3S Web of Conferences, V184, DOI 10.1051/e3sconf/202018401069
   Li MN, 2014, ADV MECH ENG, DOI 10.1155/2014/314797
   Liu W, 2013, KNOWL-BASED SYST, V44, P34, DOI 10.1016/j.knosys.2013.01.011
   Miller B, 2011, IEEE DECIS CONTR P, P6864, DOI 10.1109/CDC.2011.6160385
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mortazavi A, 2019, ADV ENG SOFTW, V127, P106, DOI 10.1016/j.advengsoft.2018.11.004
   Pehlivanoglu YV, 2007, AIRCR ENG AEROSP TEC, V79, P352, DOI 10.1108/00022660710758222
   Peng JH, 2015, IEEE INT C NETW SENS, P350, DOI 10.1109/ICNSC.2015.7116061
   Qu CZ, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106099
   Richards A, 2002, P AMER CONTR CONF, V1-6, P1936, DOI 10.1109/ACC.2002.1023918
   Rodríguez L, 2017, APPL SOFT COMPUT, V57, P315, DOI 10.1016/j.asoc.2017.03.048
   Song PC, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106443
   Stanford CB, 1996, AM ANTHROPOL, V98, P96, DOI 10.1525/aa.1996.98.1.02a00090
   Sujit PB, 2014, IEEE CONTR SYST MAG, V34, P42, DOI 10.1109/MCS.2013.2287568
   Wallace L, 2012, REMOTE SENS-BASEL, V4, P1519, DOI 10.3390/rs4061519
   Wang CB, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P2071, DOI 10.1109/ICInfA.2015.7279630
   Wang GG, 2016, AEROSP SCI TECHNOL, V49, P231, DOI 10.1016/j.ast.2015.11.040
   Wang Qiuping, 2019, Computer Engineering and Applications, V55, P60, DOI 10.3778/j.issn.1002-8331.1808-0117
   Webb B., 2002, CONNECT SCI, V14, P163, DOI [DOI 10.1080/09540090210144948, 10.1080/09540090210144948]
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Wittig Roman M., 2011, AM J PRIMATOL, V73, P498, DOI [10.1002/AJP.20923, DOI 10.1002/AJP.20923]
   Xiang HT, 2011, BIOSYST ENG, V108, P174, DOI 10.1016/j.biosystemseng.2010.11.010
   Xu C., 2016, J. Guangxi Univ. (Natural Science Edition), V41, P1869
   Yang CH, 2018, AUTOMAT CONSTR, V93, P214, DOI 10.1016/j.autcon.2018.05.024
   Yang L, 2016, J CONTROL SCI ENG, V2016, DOI 10.1155/2016/7426913
   Yang L, 2014, 2014 11TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P2376, DOI 10.1109/WCICA.2014.7053093
   Zafar MN, 2018, PROCEDIA COMPUT SCI, V133, P141, DOI 10.1016/j.procs.2018.07.018
   Zhang B, 2017, IEEE ACM T COMPUT BI, V14, P97, DOI 10.1109/TCBB.2015.2443789
   Zhang DF, 2018, NEUROCOMPUTING, V313, P229, DOI 10.1016/j.neucom.2018.06.032
   Zhao D., 2017, J JILIN I CHEM TECHN, V34, P93
   Zhao R., 2008, J UNCERTAIN SYSTEMS, V2, P165
NR 43
TC 24
Z9 26
U1 11
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27397
EP 27422
DI 10.1007/s11042-022-12882-4
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000780464900013
DA 2024-07-18
ER

PT J
AU Liu, SJ
   Wang, HJ
AF Liu, Shujun
   Wang, Huajun
TI Geometric weighting subspace clustering on nonlinear manifolds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nonlinear subspace clustering; Low-rank representation; Local tangent
   space; Weighted norm optimization
ID DIMENSIONALITY REDUCTION; MOTION SEGMENTATION; SPARSE; REPRESENTATION;
   ALGORITHM
AB Considering that the conventional subspace clustering methods of sparse subspace clustering (SSC) and low-rank representation (LRR) are only applicable to linear manifolds, we propose a novel subspace clustering framework that generalizes them for nonlinear manifolds. To do this, we integrate a weighting matrix and kernel matrix into the regularization of this framework. The weighting matrix is calculated using the similarities between tangent spaces on data manifolds and the Euclidean distances between data points, so that it can explicitly characterize the intrinsic geometry of data manifolds. Besides, we provide a geometrical interpretation for the effects of weighted l(*)-norm involved in the proposed framework, exploiting symmetric gauge function (SGF) of von Neumann theory that establishes a relationship exactly between singular and matrix norm. To solve the regularization with respect to the weighted norm, we design a fixed-point continuation algorithm to obtain an approximate closed solution. Experimental results on three computer vision tasks show the superiority of clustering accuracy over other similar approaches and demonstrate the effectiveness of the weighting matrix. That also proves the proposed method has better interpretability than other state-of-the-art methods.
C1 [Liu, Shujun; Wang, Huajun] Chengdu Univ Technol, Coll Geophys, Chengdu 610059, Sichuan, Peoples R China.
C3 Chengdu University of Technology
RP Liu, SJ (corresponding author), Chengdu Univ Technol, Coll Geophys, Chengdu 610059, Sichuan, Peoples R China.
EM suldier@outlook.com; wanghuajun@cdut.edu.cn
RI Liu, Shujun/HSF-4587-2023
OI Liu, Shujun/0000-0003-4657-1477
CR Bai L., 2020, P 37 INT C MACH LEAR, P561
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chen YX, 2018, IEEE SIGNAL PROC LET, V25, P164, DOI 10.1109/LSP.2017.2741509
   Chen Y, 2020, PROC CVPR IEEE, P4154, DOI 10.1109/CVPR42600.2020.00421
   Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Goh A, 2008, PROC CVPR IEEE, P626
   Goldfarb D, 2011, FOUND COMPUT MATH, V11, P183, DOI 10.1007/s10208-011-9084-6
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Hale ET, 2008, SIAM J OPTIMIZ, V19, P1107, DOI 10.1137/070698920
   Harandi MT, 2016, IEEE T NEUR NET LEAR, V27, P1294, DOI 10.1109/TNNLS.2014.2387383
   Nguyen H, 2015, NEUROCOMPUTING, V155, P32, DOI 10.1016/j.neucom.2014.12.051
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ji P, 2017, ADV NEUR IN, V30
   Kheirandishfard M, 2020, IEEE COMPUT SOC CONF, P3767, DOI 10.1109/CVPRW50498.2020.00440
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lewis AS, 2003, MATH PROGRAM, V97, P155, DOI 10.1007/s10107-003-0441-3
   Li CG, 2017, IEEE T IMAGE PROCESS, V26, P2988, DOI 10.1109/TIP.2017.2691557
   Lin Z.C., 2010, 100920105055 ARXIV, V1009, P5055, DOI [DOI 10.1016/J.JSB.2012.10.010, 10.1016/j.jsb.2012.10.010]
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu JL, 2014, CH CRC DATA MIN KNOW, P177
   Lu CY, 2019, IEEE T PATTERN ANAL, V41, P487, DOI 10.1109/TPAMI.2018.2794348
   Patel VM, 2014, IEEE IMAGE PROC, P2849, DOI 10.1109/ICIP.2014.7025576
   Patel VM, 2013, IEEE I CONF COMP VIS, P225, DOI 10.1109/ICCV.2013.35
   Peng X, 2020, IEEE T NEUR NET LEAR, V31, P5509, DOI 10.1109/TNNLS.2020.2968848
   Pham DS, 2012, PROC CVPR IEEE, P550, DOI 10.1109/CVPR.2012.6247720
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Soltanolkotabi M, 2012, ANN STAT, V40, P2195, DOI 10.1214/12-AOS1034
   Somandepalli K, 2019, INT CONF ACOUST SPEE, P4065, DOI 10.1109/ICASSP.2019.8682314
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974
   Vidal R, 2014, PATTERN RECOGN LETT, V43, P47, DOI 10.1016/j.patrec.2013.08.006
   Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739
   Von Neumann, 1937, SOME MATRIX INEQUALI
   Wang P, 2019, NEURAL PROCESS LETT, V49, P965, DOI 10.1007/s11063-018-9859-8
   Wang YN, 2019, IEEE T INFORM THEORY, V65, P685, DOI 10.1109/TIT.2018.2879912
   Wang Y, 2011, IEEE T NEURAL NETWOR, V22, P1149, DOI 10.1109/TNN.2011.2147798
   WATSON GA, 1992, LINEAR ALGEBRA APPL, V170, P33, DOI 10.1016/0024-3795(92)90407-2
   Wu JY, 2019, IEEE IMAGE PROC, P3387, DOI [10.1109/icip.2019.8803440, 10.1109/ICIP.2019.8803440]
   Xia GY, 2018, IEEE T IMAGE PROCESS, V27, P135, DOI 10.1109/TIP.2017.2738562
   Xiao SJ, 2016, IEEE T NEUR NET LEAR, V27, P2268, DOI 10.1109/TNNLS.2015.2472284
   Yang C, 2019, INFORM SCIENCES, V500, P48, DOI 10.1016/j.ins.2019.05.063
   Yin M, 2016, PROC CVPR IEEE, P5157, DOI 10.1109/CVPR.2016.557
   You C, 2016, PROC CVPR IEEE, P3918, DOI 10.1109/CVPR.2016.425
   You C, 2015, PR MACH LEARN RES, V37, P1585
   Zhai H, 2017, IEEE GEOSCI REMOTE S, V14, P43, DOI 10.1109/LGRS.2016.2625200
   Zhan JQY, 2020, IEEE IMAGE PROC, P211, DOI 10.1109/ICIP40778.2020.9191351
   Zhang JJ, 2019, PROC CVPR IEEE, P5468, DOI 10.1109/CVPR.2019.00562
   Zhang TH, 2007, NEUROCOMPUTING, V70, P1547, DOI 10.1016/j.neucom.2006.11.007
   Zhou L, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4440
   Zhou P, 2018, PROC CVPR IEEE, P1596, DOI 10.1109/CVPR.2018.00172
   Zhu WJ, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106199
NR 57
TC 4
Z9 4
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 42971
EP 42990
DI 10.1007/s11042-022-12797-0
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000773206100003
DA 2024-07-18
ER

PT J
AU Tsai, YY
   Liu, HL
   Ying, CY
AF Tsai, Yuan-Yu
   Liu, Hong-Lin
   Ying, Cheng-You
TI Applying homogeneity index modification to high-capacity
   high-dynamic-range image authentication with distortion tolerance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High-dynamic-range images; Image authentication; Homogeneity index
   modification; Multiple-base notational system
ID STEGANOGRAPHY; WATERMARKING; ALGORITHM; SCHEME
AB Distortion-free data hiding algorithms for high-dynamic-range (HDR) images use homogeneity index modification for data embedding. No distortion is encountered between a tone-mapped cover and stego images. However, only approximately one-eighth of pixels have two or more homogeneous representations for data embedding, affecting their performance and applications. This study investigates the feasibility of modifying the homogeneity index for a new application known as HDR image authentication. First, a revision threshold is introduced to ensure that each processing pixel has the maximum number of homogeneous representations possible. In the proposed algorithm, each pixel can perform data embedding. Following that, an authentication code is embedded using a multiple-base notational system. The experimental results indicate that the proposed algorithm significantly increases the embedding capacity and supports HDR image authentication. The data-embedded images with embedded messages are of good quality, and tampered pixels can be effectively detected.
C1 [Tsai, Yuan-Yu; Liu, Hong-Lin; Ying, Cheng-You] Asia Univ, Dept M Commerce & Multimedia Applicat, 500 Lioufeng Rd, Taichung 413305, Taiwan.
   [Tsai, Yuan-Yu] China Med Univ, China Med Univ Hosp, Dept Med Res, 2 Yude Rd, Taichung 404332, Taiwan.
C3 Asia University Taiwan; China Medical University Taiwan; China Medical
   University Hospital - Taiwan
RP Tsai, YY (corresponding author), Asia Univ, Dept M Commerce & Multimedia Applicat, 500 Lioufeng Rd, Taichung 413305, Taiwan.; Tsai, YY (corresponding author), China Med Univ, China Med Univ Hosp, Dept Med Res, 2 Yude Rd, Taichung 404332, Taiwan.
EM yytsai@asia.edu.tw
RI liu, honglin/HDN-0409-2022
OI liu, honglin/0000-0002-1254-3163; Tsai, Yuan-Yu/0000-0001-7904-8637
FU Ministry of Science and Technology of Taiwan [MOST
   109-2221-E-468-010-MY2, MOST 109-2321-B-468-001, MOST
   110-2321-B-468-001]
FX The authors would like to thank the anonymous reviewers for their
   constructive comments. This work was funded by the Ministry of Science
   and Technology of Taiwan under grant numbers MOST
   109-2221-E-468-010-MY2, MOST 109-2321-B-468-001, and MOST
   110-2321-B-468-001.
CR Aydin TO, 2008, PROC SPIE, V6806, DOI 10.1117/12.765095
   Bai YQ, 2018, SIGNAL PROCESS-IMAGE, V65, P187, DOI 10.1016/j.image.2018.04.005
   Bakhsh FY, 2018, J INF SECUR APPL, V41, P12, DOI 10.1016/j.jisa.2018.05.003
   Chang CC, 2016, MULTIMED TOOLS APPL, V75, P145, DOI 10.1007/s11042-014-2279-5
   Chen WS, 2016, INFORM SCIENCES, V358, P164, DOI 10.1016/j.ins.2016.03.045
   Cheng YM, 2009, IEEE MULTIMEDIA, V16, P70, DOI 10.1109/MMUL.2009.43
   Douglas M, 2018, MULTIMED TOOLS APPL, V77, P17333, DOI 10.1007/s11042-017-5308-3
   Fujiyoshi M, 2017, LECT NOTES COMPUT SC, V10431, P347, DOI 10.1007/978-3-319-64185-0_26
   Gao XY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107579
   Guerrini F, 2011, IEEE T INF FOREN SEC, V6, P283, DOI 10.1109/TIFS.2011.2109383
   He XY, 2019, MULTIMED TOOLS APPL, V78, P29137, DOI 10.1007/s11042-018-6589-x
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Li MT, 2011, INT J INNOV COMPUT I, V7, P2021
   Lin YT, 2017, IEEE T MULTIMEDIA, V19, P196, DOI 10.1109/TMM.2016.2605499
   Liu S, 2021, IEEE T MULTIMEDIA, V23, P2188, DOI 10.1109/TMM.2021.3065580
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Luo T, 2019, SIGNAL PROCESS, V155, P83, DOI 10.1016/j.sigpro.2018.09.024
   Maiorana E, 2016, SECUR COMMUN NETW, V9, P705, DOI 10.1002/sec.1345
   Maiorana E, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0100-7
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Mantiuk R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360667
   Narwaria M, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.010501
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Reinhard E., 2010, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting
   Ward, 1994, P 21 ANN C COMP GRAP, P475
   Yu CM, 2011, DISPLAYS, V32, P225, DOI 10.1016/j.displa.2011.02.004
   Yu XY, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101891
   Zhang XP, 2005, IEEE SIGNAL PROC LET, V12, P67, DOI 10.1109/LSP.2004.838214
   Zhi-Hui Wang, 2012, 2012 4th International Conference on Digital Home (ICDH 2012), P33, DOI 10.1109/ICDH.2012.49
   Zhou H, 2021, ACCEPT IEEE T VISUAL
   Zhu WW, 2020, IEEE T MULTIMEDIA, V22, P1823, DOI 10.1109/TMM.2020.2969791
NR 31
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24957
EP 24976
DI 10.1007/s11042-022-12837-9
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771882300010
DA 2024-07-18
ER

PT J
AU Ai, XS
   Sheng, VS
   Li, CH
AF Ai, Xusheng
   Sheng, Victor S.
   Li, Chunhua
TI A MBGD enhancement method for imbalance smoothing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; YOLO; Mini-batch stochastic gradient descent;
   Foreground-foreground imbalance
AB This paper addresses foreground-foreground imbalance in object detection. Firstly, we introduce Mini-batch Stochastic Gradient Descent (MBGD) with YOLO and the foreground-foreground imbalance problem. Then T-distribution is devised and proved to smoothen the imbalanced distribution and allocate at least a representative for each class. Furthermore, Mini-Batch Imbalance Smoothing method (MB-IS) is proposed to address the foreground-foreground imbalance by following T-distribution and proportionally assigning class weights in a mini-batch. Finally, Extensive experiments on our own transaction dataset and VOC2007 dataset demonstrate the superiority of MB-IS with certain mini-batch size.
C1 [Ai, Xusheng; Li, Chunhua] Suzhou Vocat Inst Ind Technol, Software & Serv Outsourcing Coll, Suzhou 215104, Peoples R China.
   [Sheng, Victor S.] Texas Tech Univ, Dept Comp Sci, Lubbock, TX 79409 USA.
C3 Texas Tech University System; Texas Tech University
RP Ai, XS (corresponding author), Suzhou Vocat Inst Ind Technol, Software & Serv Outsourcing Coll, Suzhou 215104, Peoples R China.
EM 00754@siit.edu.cn; victor.sheng@ttu.edu; 00804@siit.edu.cn
RI Chunhua, Li/V-1434-2019; Ai, Xusheng/ABD-8813-2020
OI Chunhua, Li/0000-0002-5703-774X; Ai, Xusheng/0000-0001-5629-9134
FU National Natural Science Foundation of China [61702351]; Natural Science
   Foundation of the Jiangsu Higher Education Institutions of China
   [17KJB520036]; Foundation of Key Laboratory in Science and Technology
   Development Project of Suzhou [SZS201609]; Suzhou Science and Technology
   Plan Project [SYG201903]; Computer Basic Education Teaching Research
   Project [2018-AFCEC-328]
FX This research was partially supported by the National Natural Science
   Foundation of China under grant No. 61702351, the Natural Science
   Foundation of the Jiangsu Higher Education Institutions of China under
   grant No. 17KJB520036, Foundation of Key Laboratory in Science and
   Technology Development Project of Suzhou under grant No. SZS201609,
   Suzhou Science and Technology Plan Project under Grant SYG201903, and
   Computer Basic Education Teaching Research Project under Grant
   2018-AFCEC-328.
CR Aydin I, 2017, 2017 INTERNATIONAL ARTIFICIAL INTELLIGENCE AND DATA PROCESSING SYMPOSIUM (IDAP)
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Cehovin L, 2016, IEEE WINT CONF APPL
   Chao Peng, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6181, DOI 10.1109/CVPR.2018.00647
   Chen YK, 2019, ADV NEUR IN, V32
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Dai JF, 2016, ADV NEUR IN, V29
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Franchini G, 2019, P NUMTA 19, P186
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Gulli A., 2017, Deep learning with Keras
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Idrees H, 2018, POLICING, V41, P292, DOI 10.1108/PIJPSM-11-2016-0158
   Jianyuan Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11402, DOI 10.1109/CVPR42600.2020.01142
   Khirirat S, 2017, IEEE DECIS CONTR P
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu S., 2019, CVPR
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Masko D., 2015, Degree Project
   Nickolls J, 2008, P HCS 08
   Oksuz K, 2020, IEEE WINT CONF APPL, P883, DOI [10.1109/WACV45572.2020.9093503, 10.1109/wacv45572.2020.9093503]
   Ouyang WL, 2016, PROC CVPR IEEE, P864, DOI 10.1109/CVPR.2016.100
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon Joseph, 2013, Darknet: Open Source Neural Networks in C, DOI DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roth, 2015, P DSAA 15
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Taheri SM, 2013, STAT PAP, V54, P457, DOI 10.1007/s00362-012-0443-4
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Triguero I, 2017, INT J COMPUT INT SYS, V10, P1238
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Xianzhi Du, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11589, DOI 10.1109/CVPR42600.2020.01161
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zhang HY, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3277958
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zhong Z, 2017, NEUROCOMPUTING, V242, P187, DOI 10.1016/j.neucom.2017.02.068
NR 45
TC 1
Z9 1
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24225
EP 24243
DI 10.1007/s11042-022-12697-3
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549500001
DA 2024-07-18
ER

PT J
AU Anwar, T
   Uma, V
   Hussain, MI
   Pantula, M
AF Anwar, Taushif
   Uma, V
   Hussain, Md Imran
   Pantula, Muralidhar
TI Collaborative filtering and kNN based recommendation to overcome cold
   start and sparsity issues: A comparative analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Collaborative filtering; K-Nearest neighbor; SVD;
   SVD plus plus; Co-Clustering; Cold start; Data sparsity
ID USER; SYSTEM
AB Collaborative Filtering (CF) has intrigued several researchers whose goal is to enhance Recommender System's performance by mitigating their drawbacks. CF's common idea is to recognize user's preferences by considering their ratings given to the items. The best-known limitations of recommender systems are the cpld start and data sparsity. In this paper, we analyse the CF-based recommendation approaches used to overcome the 2 issues, viz. cold start and data sparsity. This work attempts to implement the recommendation systems by 1) Generating a user-item similarity matrix and prediction matrix by performing collaborative filtering using memory-based CF approaches viz. KNNBasic, KNNBaseline, KNNWithMeans, SVD, and SVD++. 2) Generating a user-item similarity matrix and prediction matrix by performing collaborative filtering using model-based CF approach viz. Co-Clustering. The results reveal that the CF implemented using the K-NNBaseline approach decreased error rate when applied to MovieTrust datasets using cross-validation (CV = 5, 10, and 15). This approach is proved to address the cold start, sparsity issues and provide more relevant items as a recommendation.
C1 [Anwar, Taushif; Uma, V; Hussain, Md Imran] Pondicherry Univ, Dept Comp Sci, Pondicherry 605014, India.
   [Pantula, Muralidhar] CMR Grp Inst, Hyderabad, India.
C3 Pondicherry University
RP Anwar, T (corresponding author), Pondicherry Univ, Dept Comp Sci, Pondicherry 605014, India.
EM taushif21589@gmail.com
OI Anwar, Taushif/0000-0002-6937-7258
CR Al Sabaawi A., 2021, Two Models Based on Social Relations and SVD++ Method for Recommendation System
   Alhijawi B, 2021, INFORM SYST, V96, DOI 10.1016/j.is.2020.101670
   Anwar T, 2020, CONVERGENCE ICT SMAR, P137
   Anwar T, 2021, INT J INF TECH DECIS, P1
   Anwar T., 2020, 2020 INT C DATA ANAL, P1
   Anwar T., 2020, CHALLENGES APPL DATA, P175
   Anwar T., 2019, DATA ENG APPL, P3
   Anwar T, 2019 INT C
   Anwar T, 2022, J KING SAUD UNIV-COM, V34, P793, DOI 10.1016/j.jksuci.2019.01.012
   Anwar T, 2021, INT J SYST ASSUR ENG, V12, P426, DOI 10.1007/s13198-021-01087-x
   Bathla G, 2020, MULTIMED TOOLS APPL, V79, P20845, DOI 10.1007/s11042-020-08932-4
   Burke R., 2007, The adaptive web: methods and strategies of web personalization, P377, DOI [10.1007/978-3-540-72079-9_12, DOI 10.1007/978-3-540-72079-9_12]
   Chae DK, 2018, NEUROCOMPUTING, V278, P134, DOI 10.1016/j.neucom.2017.06.081
   Choi K, 2012, ELECTRON COMMER R A, V11, P309, DOI 10.1016/j.elerap.2012.02.004
   Feng L, 2020, EXPERT SYST APPL, V143, DOI 10.1016/j.eswa.2019.113078
   Forouzandeh S, 2021, MULTIMED TOOLS APPL, V80, P7805, DOI 10.1007/s11042-020-09949-5
   Hassan T, 2019, ARXIV190301780
   Huang L, 2019, IEEE ACCESS, V7, P19550, DOI 10.1109/ACCESS.2019.2897979
   Jazi SY, 2021, MULTIMED TOOLS APPL, V80, P13559, DOI 10.1007/s11042-020-10386-7
   Kant S, 2019, MULTIMED TOOLS APPL, V78, P4107, DOI 10.1007/s11042-017-5260-2
   Kant S, 2018, INT J SYST ASSUR ENG, V9, P173, DOI 10.1007/s13198-016-0500-9
   Karabadji NE, 2018, EXPERT SYST APPL, V98, P153, DOI 10.1016/j.eswa.2018.01.015
   Kim M, 2013, MULTIMED TOOLS APPL, V64, P505, DOI 10.1007/s11042-011-0897-8
   Kluver D, 2018, LECT NOTES COMPUT SC, V10100, P344, DOI 10.1007/978-3-319-90092-6_10
   Kumar Pushpendra, 2018, International Journal of Information Technology, V10, P495, DOI 10.1007/s41870-018-0138-8
   Kumar P, 2019, IETE TECH REV, V36, P463, DOI 10.1080/02564602.2018.1503568
   Kumar V., 2017, INT J INTELL ENG SYS, V10, P211
   Kumar V, 2020, NATL ACAD SCI LETT, V43, P409, DOI 10.1007/s40009-020-00895-2
   Li M, 2021, PHYSICA A, V561, DOI 10.1016/j.physa.2020.125140
   Li YK, 2020, IEEE ACCESS, V8, P98305, DOI 10.1109/ACCESS.2020.2997040
   Lin WQ, 2014, LECT NOTES COMPUT SC, V8709, P56, DOI 10.1007/978-3-319-11116-2_6
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Sharma M., 2019, RECENT PATENTS ENG, V13, P39
   Subramaniyaswamy V, 2017, WIRELESS PERS COMMUN, V97, P2229, DOI 10.1007/s11277-017-4605-5
   Tahmasebi F, 2021, MULTIMED TOOLS APPL, V80, P2339, DOI 10.1007/s11042-020-09768-8
   Walek B, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113452
   Zahir A, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8040427
   Zhang C., 2017, 17th SIAM International Conference on Data Mining, P381
   Zhou XZ, 2018, APPL SOFT COMPUT, V70, P1042, DOI 10.1016/j.asoc.2017.07.005
NR 39
TC 16
Z9 16
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35693
EP 35711
DI 10.1007/s11042-021-11883-z
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000770549800020
DA 2024-07-18
ER

PT J
AU Muñoz, JAV
   Dias, Z
   Torres, RD
AF Vargas Munoz, Javier A.
   Dias, Zanoni
   Torres, Ricardo da Silva
TI A genetic programming approach for searching on nearest neighbors graphs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distance learning; Genetic programming; Image retrieval; Graph-based
   indexes; Nearest neighbor searches; Network theory
ID PRODUCT QUANTIZATION; ALGORITHMS; TREES
AB Nearest neighbors graphs have gained a lot of attention from the information retrieval community since they were demonstrated to outperform classical approaches in the task of approximate nearest neighbor search. These approaches, firstly, index feature vectors by using a graph-based data structure. Then, for a given query, the search is performed by traversing the graph in a greedy-way, moving in each step towards the neighbor of the current vertex that is closer to the query (based on a distance function). However, local topological properties of vertices could be also considered at the moment of deciding the next vertex to be explored. In this work, we introduce a Genetic Programming framework that combines topological properties along with the distance to the query, aiming to improve the selection of the next vertex in each step of graph traversal and, therefore, reduce the number of vertices explored (scan rate) to find the true nearest neighbors. Experimental results, conducted over three large collections of feature vectors and four different graph-based techniques, show significant gains of the proposed approach over classic graph-based search algorithms.
C1 [Vargas Munoz, Javier A.; Dias, Zanoni] Univ Estadual Campinas, Campinas, Brazil.
   [Torres, Ricardo da Silva] Norwegian Univ Sci & Technol, Larsgardsvegen 2, N-6009 Alesund, Norway.
C3 Universidade Estadual de Campinas; Norwegian University of Science &
   Technology (NTNU)
RP Muñoz, JAV (corresponding author), Univ Estadual Campinas, Campinas, Brazil.
EM javier.munoz@ic.unicamp.br; zanoni@ic.unicamp.br; ricardo.torres@ntnu.no
RI Torres, Ricardo da S./C-4526-2012
OI Torres, Ricardo/0000-0001-9772-263X; Vargas Munoz, Javier
   Alvaro/0000-0002-5809-4228; Dias, Zanoni/0000-0003-3333-6822
FU CNPq [307560/2016-3, 400487/2016-0, 425340/ 2016-3, 304380/2018-0,
   422593/2018-4]; CAPES [88881.145912/2017-01]; FAPESP [2014/12236-1,
   2015/24494-8, 2016/50250-1, 2017/20945-0, 2015/11937-9, 2017/11618-6,
   2017/12646-3, 2017/16246-0]; FAPESP-Microsoft Virtual Institute
   [2013/50155-0, 2013/50169-1, 2014/50715-9]; Coordenacao de
   Aperfeicoamento de Pessoal de Nivel Superior - Brasil (CAPES) [001]
FX Authors are grateful to CNPq (grants #307560/2016-3, #400487/2016-0,
   #425340/ 2016-3, #304380/2018-0, and #422593/2018-4), CAPES (grant
   #88881.145912/2017-01), FAPESP (grants #2014/12236-1, #2015/24494-8,
   #2016/50250-1, #2017/20945-0, #2015/11937-9, #2017/11618-6,
   #2017/12646-3, and #2017/16246-0) and the FAPESP-Microsoft Virtual
   Institute (grants #2013/50155-0, #2013/50169-1, and #2014/50715-9). This
   study was financed in part by the CoordenacAo de Aperfeicoamento de
   Pessoal de Nivel Superior - Brasil (CAPES) - Finance Code 001. The
   authors are also grateful to the NFR SmartPlan and TwinFjord projects.
CR Albarracín JFH, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12142267
   Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   André F, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P164, DOI 10.1145/3078971.3078992
   [Anonymous], 2009, P 18 ACM C INFORM KN, DOI DOI 10.1145/1645953.1646063
   Aumuller M., 2017, ANN BENCHMARKS BENCH
   Babenko A, 2015, IEEE T PATTERN ANAL, V37, P1247, DOI 10.1109/TPAMI.2014.2361319
   Babenko A, 2014, PROC CVPR IEEE, P931, DOI 10.1109/CVPR.2014.124
   Bawa M, 2005, Proceedings of the 14th International Conference on World Wide Web-WWW'05, P651, DOI [DOI 10.1145/1060745.1060840, 10.1145/1060745.1060840]
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Chiu CY, 2019, MULTIMED TOOLS APPL, V78, P2877, DOI 10.1007/s11042-018-6059-5
   Costa LD, 2007, ADV PHYS, V56, P167, DOI 10.1080/00018730601170527
   Dasgupta S, 2008, ACM S THEORY COMPUT, P537
   de Carvalho MG, 2012, IEEE T KNOWL DATA EN, V24, P399, DOI 10.1109/TKDE.2010.234
   Dong W., 2011, P 20 INT C WORLD WID, P577
   Efstathiades C, 2016, ACM TRANS SPAT ALGOR, V2, DOI 10.1145/2934675
   Feng XK, 2019, MULTIMED TOOLS APPL, V78, P24407, DOI 10.1007/s11042-018-6987-0
   Ge TZ, 2013, PROC CVPR IEEE, P2946, DOI 10.1109/CVPR.2013.379
   Goldberg AV, 2005, PROCEEDINGS OF THE SIXTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P156
   Gonzalez-Lopez J, 2018, FUTURE GENER COMP SY, V87, P66, DOI 10.1016/j.future.2018.04.094
   Gubichev A., 2010, FAST ACCURATE ESTIMA
   Guttman Antonin., 1984, P 1984 ACM SIGMOD C, P47
   Harwood B, 2016, PROC CVPR IEEE, P5713, DOI 10.1109/CVPR.2016.616
   Albarracín JFH, 2017, INT GEOSCI REMOTE SE, P554, DOI 10.1109/IGARSS.2017.8127013
   Houle MichaelE., 2014, P INT C MULTIMEDIA R, P89
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Iwasaki M., 2016, PRUNED BIDIRECTED K
   Jebari K., 2013, International Journal of Emerging Sciences, V3, P333, DOI DOI 10.14355/ijes.2013.0305.05
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Ji TX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1005, DOI 10.1145/2647868.2655018
   Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298
   KOZA JR, 1994, STAT COMPUT, V4, P87, DOI 10.1007/BF00175355
   Lacerda A, 2006, P 29 ANN INT ACM SIG, P549, DOI 10.1145/1148170.1148265
   Li J, 2017, MULTIMED TOOLS APPL, V76, P23273, DOI 10.1007/s11042-016-4023-9
   Liu J, 2009, PATTERN RECOGN, V42, P218, DOI 10.1016/j.patcog.2008.04.012
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lv Q., 2007, P 33 INT C VER LARG, P950
   Malkov Y, 2014, INFORM SYST, V45, P61, DOI 10.1016/j.is.2013.10.006
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Muñoz JV, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106970
   Papadias D., 2000, SIGIR Forum, V34, P240
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Popescu A, 2015, MMCOMMONS'15: PROCEEDINGS OF THE 2015 WORKSHOP ON COMMUNITY-ORGANIZED MULTIMODAL MINING: OPPORTUNITIES FOR NOVEL SOLUTIONS, P7, DOI 10.1145/2814815.2814819
   Silpa-Anan C, 2008, PROC CVPR IEEE, P2308
   SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061
   Su F, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P403, DOI 10.1145/2671188.2749383
   Tang JH, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899418
   Torres RD, 2009, PATTERN RECOGN, V42, P283, DOI 10.1016/j.patcog.2008.04.010
   Tretyakov K., 2011, P 20 ACM INT C INFOR, P1785
   Vargas J.A., 2020, THESIS U CAMPINAS SA
   Muñoz JAV, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P43, DOI 10.1145/3323873.3325014
   Wang M, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1707, DOI 10.1145/3123266.3123415
   YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311
NR 53
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23449
EP 23472
DI 10.1007/s11042-022-12248-w
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000770549800024
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yadava, GT
   Nagaraja, BG
   Jayanna, HS
AF Yadava, Thimmaraja G.
   Nagaraja, B. G.
   Jayanna, H. S.
TI A spatial procedure to spectral subtraction for speech enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spectral subtraction (SS); Noisy speech data; Enhanced speech data;
   Musical noise suppression; Cross-terms; Spatial procedure (SP)
ID NOISE; RECOGNITION
AB The major drawback of the most widely used spectral subtraction (SS) algorithm is, it fails to reduce musical noise. In addition to this in SS, the subtraction rules are mainly based on false assumptions about cross-terms are being zero. A novel approach is proposed to overcome these shortcomings in the SS algorithm. A technique is implemented to calculate exactly the cross-terms which involve the differences in phase amidst degraded speech signal and noise model. The proposed technique gain function is having the same properties as traditional minimum mean square error (MMSE) algorithms. The experimental results on NOIZEUS speech corpora reveal that the proposed algorithm outperforms the traditional SS algorithms in terms of speech quality and intelligibility at lower SNR conditions. Further, the output of the proposed approach shows that there is no audibility of musical noise in processed or enhanced speech sound. The numerical complexity computation and pictorial representation of input-output waveforms and corresponding spectrograms of proposed and existing speech enhancement techniques are also presented in this work.
C1 [Yadava, Thimmaraja G.] Nitte Meenakshi Inst Technol, E & CE, Bengaluru 560064, Karnataka, India.
   [Nagaraja, B. G.] KLE Inst Technol, E & CE, Airport Rd, Hubballi 580027, Karnataka, India.
   [Jayanna, H. S.] Siddaganga Inst Technol, IS & E, BH Rd, Tumkur 572103, Karnataka, India.
C3 Nitte Meenakshi Institute of Technology; Siddaganga Institute of
   Technology
RP Yadava, GT (corresponding author), Nitte Meenakshi Inst Technol, E & CE, Bengaluru 560064, Karnataka, India.
EM thimrajyadav@gmail.com; nagarajbg@gmail.com; jayannahs@gmail.com
RI Yadava G, Thimmaraja/AEO-3181-2022
OI Yadava G, Thimmaraja/0000-0002-3266-9732
CR [Anonymous], 2000, ITU-T rec, P862
   [Anonymous], 1974, NSCFR4023
   Berouti M., 1979, ICASSP 79. 1979 IEEE International Conference on Acoustics, Speech and Signal Processing, P208
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
   Cappé O, 1994, IEEE T SPEECH AUDI P, V2, P345, DOI 10.1109/89.279283
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453
   Evans NWD, 2006, INT CONF ACOUST SPEE, P145
   Hirsch H.G, 2000, P ASR2000 AUT SPEECH
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   Hu Y, 2007, SPEECH COMMUN, V49, P588, DOI 10.1016/j.specom.2006.12.006
   Kamath S, 2002, INT CONF ACOUST SPEE, P4164
   Kitaoka N, 2002, 7 INT C SPOK LANG PR, P477
   LOCKWOOD P, 1992, SPEECH COMMUN, V11, P215, DOI 10.1016/0167-6393(92)90016-Z
   Loizou PC, 2005, IEEE T SPEECH AUDI P, V13, P857, DOI 10.1109/TSA.2005.851929
   Lu Y, 2008, SPEECH COMMUN, V50, P453, DOI 10.1016/j.specom.2008.01.003
   Martin R, 2001, IEEE T SPEECH AUDI P, V9, P504, DOI 10.1109/89.928915
   Papoulis A., 1965, PROBABILITY RANDOM V
   Philipos C, 2007, LOIZOU SPEECH ENHANC
   Virag N, 1999, IEEE T SPEECH AUDI P, V7, P126, DOI 10.1109/89.748118
   Yadava TG, 2019, INT J SPEECH TECHNOL, V22, P639, DOI 10.1007/s10772-018-9506-9
   Yoma NB, 1998, IEEE T SPEECH AUDI P, V6, P579, DOI 10.1109/89.725325
NR 21
TC 5
Z9 6
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23633
EP 23647
DI 10.1007/s11042-022-12152-3
EA MAR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549800016
DA 2024-07-18
ER

PT J
AU Zhu, QD
   Wang, F
   Cai, CT
   Meng, HY
   Qiao, RJ
AF Zhu, Qidan
   Wang, Feng
   Cai, Chengtao
   Meng, Haiyang
   Qiao, Renjie
TI Keypoint matching using salient regions and GMM in images with weak
   textures and repetitive patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Keypoints matching; Salient region; Weak texture; Repetitive patterns;
   Gaussian mixture model
ID POINT; DESCRIPTOR; STEREO
AB In the keypoint matching task, most standard methods cannot extract uniform and effective keypoints in images with weak textures and repetitive patterns, nor can they design unique feature descriptors for them. In order to bypass the difficulties encountered in matching ambiguous images, we make some efforts from keypoint extraction and keypoint matching respectively. First, a keypoint extractor based on local energy maxima is designed, which can extract stable features in weak texture regions. Second, to guide keypoints matching based on the Gaussian mixture model framework, an adaptive search method to locate salient regions in images without training is introduced. This is accomplished by quantifying the similarity between the center point and the remaining keypoints. Finally, the iterative equations considering the guiding information is derived. These algorithms alleviate the impacts of weak texture and repetitive patterns on keypoints matching. Experiments on test data show that our method can extract stable and reproducible keypoints, in matching, the precision is more than 60% and the recall is more than 80% when images containing description ambiguities.
C1 [Zhu, Qidan; Wang, Feng; Cai, Chengtao; Qiao, Renjie] Harbin Engn Univ, Coll Automat, Harbin 150001, Peoples R China.
   [Meng, Haiyang] Shanghai Aerosp Control Technol Inst, Shanghai, Peoples R China.
C3 Harbin Engineering University
RP Wang, F (corresponding author), Harbin Engn Univ, Coll Automat, Harbin 150001, Peoples R China.
EM wangfengrd8868@gmail.com
RI Qiao, Renjie/JCO-9357-2023; cai, chengtao/HGB-8304-2022
OI Qiao, Renjie/0000-0001-7580-0553; Wang, Feng/0000-0002-0040-9290
FU National Natural Science Foundation of China [61673129]; Development
   Project of Ship Situational Intelligent Awareness System [MC201920-X01]
FX This work was supported by [the National Natural Science Foundation of
   China] (Grant number [61673129]); [the Development Project of Ship
   Situational Intelligent Awareness System] (Grant number [MC201920-X01]).
CR Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Aldana-Iuit J, 2016, INT C PATT RECOG, P675, DOI 10.1109/ICPR.2016.7899712
   Awrangjeb M, 2012, IEEE T IMAGE PROCESS, V21, P4167, DOI 10.1109/TIP.2012.2200493
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Barroso-Laguna A, 2019, IEEE I CONF COMP VIS, P5835, DOI 10.1109/ICCV.2019.00593
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Beksi WJ, 2019, IMAGE VISION COMPUT, V88, P84, DOI 10.1016/j.imavis.2019.05.004
   Bian JW, 2017, PROC CVPR IEEE, P2828, DOI 10.1109/CVPR.2017.302
   Cho MS, 2014, PROC CVPR IEEE, P2091, DOI 10.1109/CVPR.2014.268
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Egozi A, 2013, IEEE T PATTERN ANAL, V35, P18, DOI 10.1109/TPAMI.2012.51
   Fan JW, 2018, IEEE T GEOSCI REMOTE, V56, P5368, DOI 10.1109/TGRS.2018.2815523
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Jiang S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12203390
   Kim H, 2010, IEEE INT CONF ROBOT, P1014, DOI 10.1109/ROBOT.2010.5509472
   Komorowski J., 2018, P EUR C COMP VIS ECC
   Kovesi P., 1999, Videre, V1
   Kovesi P, 2000, PSYCHOL RES-PSYCH FO, V64, P136, DOI 10.1007/s004260000024
   Lawin FJ, 2018, PROC CVPR IEEE, P3829, DOI 10.1109/CVPR.2018.00403
   Li Z, 2016, IEEE T MED IMAGING, V35, P63, DOI 10.1109/TMI.2015.2455416
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Livi L, 2013, PATTERN ANAL APPL, V16, P253, DOI 10.1007/s10044-012-0284-8
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma JY, 2016, IEEE T IMAGE PROCESS, V25, P53, DOI 10.1109/TIP.2015.2467217
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Morago B, 2015, IEEE T IMAGE PROCESS, V24, P4474, DOI 10.1109/TIP.2015.2456498
   Mustafa A, 2019, IEEE T IMAGE PROCESS, V28, P1118, DOI 10.1109/TIP.2018.2872906
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rocco I., 2020, P IEEE EUR C COMP VI, V16, P605
   Rocco M, 2018, ARXIV181010510
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Suárez I, 2020, PATTERN RECOGN LETT, V133, P366, DOI 10.1016/j.patrec.2020.04.005
   Sun Jiaming, 2021, ARXIV210400680
   Sun YB, 2015, ISPRS J PHOTOGRAMM, V104, P1, DOI 10.1016/j.isprsjprs.2014.12.003
   Trajkovic M, 1998, IMAGE VISION COMPUT, V16, P75, DOI 10.1016/S0262-8856(97)00056-5
   Wang LB, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.103984
   Wang ZH, 2009, PATTERN RECOGN, V42, P941, DOI 10.1016/j.patcog.2008.08.035
   Wu B, 2012, ISPRS J PHOTOGRAMM, V68, P40, DOI 10.1016/j.isprsjprs.2011.12.005
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28
   Yuan XX, 2017, ISPRS J PHOTOGRAMM, V129, P21, DOI 10.1016/j.isprsjprs.2017.04.015
   Zaafouri A, 2012, IEEE MEDITERR ELECT, P129, DOI 10.1109/MELCON.2012.6196396
   Zhang S, 2017, IEEE I CONF COMP VIS, P2688, DOI 10.1109/ICCV.2017.291
   Zhang XH, 2015, IEEE T PATTERN ANAL, V37, P2207, DOI 10.1109/TPAMI.2015.2396074
   Zhang YR, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104088
   Zickler S., 2007, Proceedings of the National Conference on Artificial Intelligence, P1127
   Zitnick CL, 2011, IEEE I CONF COMP VIS, P359, DOI 10.1109/ICCV.2011.6126263
NR 50
TC 1
Z9 1
U1 9
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23237
EP 23257
DI 10.1007/s11042-022-12503-0
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000770205600002
DA 2024-07-18
ER

PT J
AU Khan, S
AF Khan, Sahib
TI Canopy approach of image clustering based on camera fingerprints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Clustering; Camera fingerprints; Computational cost
ID IDENTIFICATION; ALGORITHM
AB The paper presents a canopy based image clustering algorithm using normalized cross-correlation among the camera fingerprints as a decision criterion. The proposed framework uses two levels of the threshold at two different stages to cluster images based on camera fingerprints. Initially, fingerprints are sorted in descending order of their goodness, and then raw clusters are constructed using a relaxed threshold followed by fine clustering with a hard threshold. The raw and fine clustering process results in non-overlapping clusters, which avoids assigning a fingerprint to multiple raw or fine clusters. The fine clusters are further processed in the attraction phase to improve the cluster's quality at the cost of some computation. The CIC algorithm results in high-quality clusters with a reduced computational cost. The results show that the computational complexity per fingerprint, with respect to the reference complexity of n(n - 1)/2, decreases as the size of the dataset increases. The proposed algorithm also does not suffer from the problem when the number of cameras is larger than the average number of images taken with a camera, i.e., NC >> SC. Hence, the algorithm is suitable for large scale clustering and solving different scenarios of NC >> SC.
C1 [Khan, Sahib] Univ Engn & Technol, Dept Telecommun Engn, Mardan, Pakistan.
RP Khan, S (corresponding author), Univ Engn & Technol, Dept Telecommun Engn, Mardan, Pakistan.
EM sahib@uetmardan.edu.pk
CR Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4
   Amelio A, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P1584, DOI 10.1145/2808797.2809344
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2011, ENCY MACHINE LEARNIN
   Bloy GJ, 2008, IEEE T PATTERN ANAL, V30, P532, DOI 10.1109/TPAMI.2007.1183
   Caldelli R, 2010, IEEE INT WORKS INFOR
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chen M, 2007, PROC SPIE, V6505, DOI 10.1117/12.703370
   de Souto M. C. P., 2012, 2012 Brazilian Symposium on Neural Networks (SBRN 2012), P49, DOI 10.1109/SBRN.2012.25
   Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547
   EQUITZ WH, 1989, IEEE T ACOUST SPEECH, V37, P1568, DOI 10.1109/29.35395
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fahmy OM, 2015, INT CONF SYST SIGNAL, P249, DOI 10.1109/IWSSIP.2015.7314223
   Filler T, 2008, IEEE IMAGE PROC, P1296
   Villalba LJG, 2015, EXPERT SYST APPL, V42, P1927, DOI 10.1016/j.eswa.2014.10.018
   Georgievska S, 2017, DIGIT INVEST, V23, P22, DOI 10.1016/j.diin.2017.08.005
   Gisolf F, 2014, FORENSIC SCI INT, V244, P222, DOI 10.1016/j.forsciint.2014.08.034
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Gloe T., 2012, Proceedings of the on Multimedia and security, P109
   Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3
   Guha S, 2001, INFORM SYST, V26, P35, DOI 10.1016/S0306-4379(01)00008-4
   Haralick R. M., 1992, COMPUTER ROBOT VISIO
   Hoffman M, 2015, SOC NETWORKS, V42, P72, DOI 10.1016/j.socnet.2015.03.002
   Holst G.C., 1998, CCD ARRAYS CAMERAS D
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Jain A K, 1988, ALGORITHMS CLUSTERIN
   Janesick J. R, 2001, Scientific Charge-Coupled Devices, DOI [DOI 10.1117/3.374903, 10.1117/3.374903]
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637
   Kennedy Donald, 2006, Science, V311, P335
   Khan S, 2019, IEEE INT CON MULTI, P766, DOI 10.1109/ICME.2019.00137
   Khan S, 2019, INT CONF ACOUST SPEE, P2682, DOI 10.1109/ICASSP.2019.8683754
   Li CT, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0217-y
   Li CT, 2010, IEEE INT SYMP CIRC S, P3429, DOI 10.1109/ISCAS.2010.5537850
   Li CT, 2010, IEEE INT SYMP CIRC S, P3052, DOI 10.1109/ISCAS.2010.5537994
   Li CT, 2010, IEEE T INF FOREN SEC, V5, P280, DOI 10.1109/TIFS.2010.2046268
   Li P., 2006, P 12 ACM SIGKDD INT, P287, DOI DOI 10.1145/1150402.1150436
   Lin XF, 2017, IEEE T INF FOREN SEC, V12, P793, DOI 10.1109/TIFS.2016.2636086
   Liu BB, 2010, IEEE INT WORKS INFOR
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Marra F, 2017, IEEE T INF FOREN SEC, V12, P2197, DOI 10.1109/TIFS.2017.2701335
   McCallum A., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P169, DOI 10.1145/347090.347123
   Murtagh F, 2012, WIRES DATA MIN KNOWL, V2, P86, DOI 10.1002/widm.53
   Ng RT, 2002, IEEE T KNOWL DATA EN, V14, P1003, DOI 10.1109/TKDE.2002.1033770
   Pearson H, 2005, NATURE, V434, P952, DOI 10.1038/434952a
   Phan Q., 2018, ARXIV181007945
   Phan Q.-T., 2017, PROC 2 INT WORKSHOP, P1
   RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239
   Tian Zhang, 1996, SIGMOD Record, V25, P103, DOI 10.1145/235968.233324
   Vinh Nguyen Xuan, 2009, P 26 ANN INT C MACH, P1073, DOI DOI 10.1145/1553374.1553511
   Yeung KY, 2001, BIOINFORMATICS, V17, P763, DOI 10.1093/bioinformatics/17.9.763
   Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361
NR 52
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21591
EP 21618
DI 10.1007/s11042-022-12463-5
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769836800006
DA 2024-07-18
ER

PT J
AU Dubey, P
   Kanumuri, T
   Vyas, R
AF Dubey, Pawan
   Kanumuri, Tirupathiraju
   Vyas, Ritesh
TI Optimal directional texture codes using multiscale bit crossover count
   planes for palmprint recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Palmprint textural code representation; Multiscale Gabor filters;
   Multiscale bit crossover count planes; ODTC
ID GABOR FILTER; VERIFICATION; EXTRACTION; IMAGES
AB The single variance Gabor filters have widely been employed for palmprint structural representation. These filters display inefficient representation due to loss in information detection and false localization of diverse width palmlines. Therefore, the proposed work employs a multiscale filtering based representation, "optimal directional texture codes (ODTC)". The proposed representation make use of the line structures that go unnoticed with single variance Gabor filters and the multiscale bit crossover count (MBCC) scheme integrates these structural attributes of multiple width. Firstly, the MBCC planes are obtained using bit transition count across the strings which are formed by concatenating the binarized responses of the Gabor filter coefficients at corresponding location binary responses in considered orientations. Thereafter, optimal directional texture plane, i.e., directional representation (DR), is derived by computing dominant directional indices associated with the maximum value of MBCC at each corresponding locations of MBCC planes in different directions. Finally, encoding of the obtained DR results in final ODTC representation. The experimental results on, standard PolyU 2D, multispectral and IITD touchless palmprint databases, demonstrate that the proposed work outperforms several state-of-the-art coding based approaches.
C1 [Dubey, Pawan] Madhav Inst Sci & Technol, Gwalior 474005, Madhya Pradesh, India.
   [Kanumuri, Tirupathiraju] Natl Inst Technol Delhi Narela, Delhi 110040, India.
   [Vyas, Ritesh] Univ Lancaster, Lancaster, England.
C3 Madhav Institute of Technology & Science; National Institute of
   Technology (NIT System); National Institute of Technology Delhi;
   Lancaster University
RP Dubey, P (corresponding author), Madhav Inst Sci & Technol, Gwalior 474005, Madhya Pradesh, India.
EM pawand@mitsgwalior.in; ktraju@nitdelhi.ac.in; r.vyas1@lancaster.ac.uk
RI Kanumuri, Tirupathiraju/V-5584-2019; dubey, pawan/HGU-6795-2022
OI Kanumuri, Tirupathiraju/0000-0002-0441-7642; dubey,
   pawan/0000-0002-5177-8715
CR Basu M, 2002, IEEE T SYST MAN CY C, V32, P252, DOI 10.1109/TSMCC.2002.804448
   Chen LP, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P273
   Connie T, 2005, IMAGE VISION COMPUT, V23, P501, DOI 10.1016/j.imavis.2005.01.002
   Dubey P, 2018, SIGNAL IMAGE VIDEO P, V12, P677, DOI 10.1007/s11760-017-1207-3
   Dubey P, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P1979
   Fei LK, 2018, IEEE T INSTRUM MEAS, V67, P2761, DOI 10.1109/TIM.2018.2830858
   Fei LK, 2016, IEEE T HUM-MACH SYST, V46, P787, DOI 10.1109/THMS.2016.2586474
   Fei LK, 2016, PATTERN RECOGN LETT, V69, P35, DOI 10.1016/j.patrec.2015.10.003
   Fei LK, 2016, PATTERN RECOGN, V49, P89, DOI 10.1016/j.patcog.2015.08.001
   Genovese A, 2019, IEEE T INF FOREN SEC, V14, P3160, DOI 10.1109/TIFS.2019.2911165
   Guo ZH, 2009, PATTERN RECOGN LETT, V30, P1219, DOI 10.1016/j.patrec.2009.05.010
   Han CC, 2003, PATTERN RECOGN, V36, P371, DOI 10.1016/S0031-3203(02)00037-7
   Han WY, 2012, EXPERT SYST APPL, V39, P13225, DOI 10.1016/j.eswa.2012.05.079
   Hanmandlu M., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P158, DOI 10.1109/ICSIP.2010.5697461
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Huang DS, 2008, PATTERN RECOGN, V41, P1316, DOI 10.1016/j.patcog.2007.08.016
   Huh JH, 2019, J SUPERCOMPUT, V75, P3123, DOI 10.1007/s11227-018-2496-1
   Jalali Amin, 2015, Proceedings of the 3rd International Conference on Human-Agent Interaction, P209
   Jia W, 2017, IEEE T IMAGE PROCESS, V26, P4483, DOI 10.1109/TIP.2017.2705424
   Jia W, 2014, IEEE T SYST MAN CY-S, V44, P385, DOI 10.1109/TSMC.2013.2258010
   Jia W, 2008, IEEE SYS MAN CYBERN, P1561
   Jing XY, 2004, IEEE T SYST MAN CY B, V34, P2405, DOI 10.1109/TSMCB.2004.837586
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kong A, 2009, PATTERN RECOGN, V42, P1408, DOI 10.1016/j.patcog.2009.01.018
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Kong AWK, 2004, LECT NOTES COMPUT SC, V3072, P761
   Kong WK, 2002, INT C PATT RECOG, P807
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A., 2004, Proceedings. Third International Conference on Image and Graphics, P258
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Li F, 2004, P INT WORKSH BIOM CI, pS33
   Li G, 2017, PATTERN RECOGN, V61, P29, DOI 10.1016/j.patcog.2016.06.025
   Lu GM, 2003, PATTERN RECOGN LETT, V24, P1463, DOI 10.1016/S0167-8655(02)00386-0
   Minaee S., 2019, Deep-emotion: Facial expression recognition using attentional convolutional network
   Pan X, 2008, IMAGE VISION COMPUT, V26, P1261, DOI 10.1016/j.imavis.2008.03.001
   Rotinwa-Akinbile M. O., 2011, Proceedings of the 2011 First International Conference on Informatics and Computational Intelligence (ICI 2011), P278, DOI 10.1109/ICI.2011.53
   Shu W, 1998, INT C PATT RECOG, P219, DOI 10.1109/ICPR.1998.711120
   Su R, 2018, INT C PATT RECOG, P3856, DOI 10.1109/ICPR.2018.8545292
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Sundararajan K, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3190618
   Tabejamaat M, 2017, MULTIMED TOOLS APPL, V76, P9387, DOI 10.1007/s11042-016-3544-6
   Tamrakar D, 2015, SIGNAL IMAGE VIDEO P, V9, P535, DOI 10.1007/s11760-013-0475-9
   Wai Kin Kong, 2003, Pattern Recognition, V36, P2339, DOI 10.1016/S0031-3203(03)00121-3
   Wang HG, 2008, PATTERN RECOGN, V41, P1514, DOI 10.1016/j.patcog.2007.10.021
   Wang S, 2008, CONF CYBERN INTELL S, P59
   Wu XQ, 2004, PATTERN RECOGN, V37, P1987, DOI 10.1016/j.patcog.2004.02.015
   Wu XQ, 2003, PATTERN RECOGN LETT, V24, P2829, DOI 10.1016/S0167-8655(03)00141-7
   Xu Yunhong, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538568
   Younesi A, 2017, PROCEDIA COMPUT SCI, V108, P2488, DOI 10.1016/j.procs.2017.05.157
   Young S R, 2015, MLHPC 15 P WORKSH MA
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang D, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071391
   Zhang D, 2010, IEEE T INSTRUM MEAS, V59, P480, DOI 10.1109/TIM.2009.2028772
   Zhang L, 2004, IEEE T SYST MAN CY B, V34, P1335, DOI 10.1109/TSMCB.2004.824521
   Zhang L, 2012, IMAGE VISION COMPUT, V30, P1043, DOI 10.1016/j.imavis.2012.09.003
   Zhang L, 2012, IEEE SIGNAL PROC LET, V19, P663, DOI 10.1109/LSP.2012.2211589
   Zhao Dandan, 2015, 6 INT C WIR MOB MULT, P214
   Zhong DX, 2019, NEUROCOMPUTING, V328, P16, DOI 10.1016/j.neucom.2018.03.081
NR 58
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 20291
EP 20310
DI 10.1007/s11042-022-12580-1
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000767748600002
DA 2024-07-18
ER

PT J
AU Hendaoui, R
   Nabiyev, V
AF Hendaoui, Rabeb
   Nabiyev, Vasif
TI An end-to-end neural network for detecting hidden people in images based
   on multiple attention network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hidden people; Visual attention; Neural network; Camouflage patterns
AB Camouflaged people like soldiers on the battlefield or even camouflaged objects in the natural environments are hard to be detected because of the strong resemblances between the hidden target and the background. That's why seeing these hidden objects is a challenging task. Due to the nature of hidden objects, identifying them require a significant level of visual perception. To overcome this problem, we present a new end-to-end framework via a multi-level attention network in this paper. We design a novel inception module to extract multi-scale receptive fields features aiming at enhancing feature representation. Furthermore, we use a dense feature pyramid taking advantage of multi-scale semantic features. At last, to locate and distinguish the camouflaged target better from the background, we develop a multi-attention module that generates more discriminative feature representation and combines semantic information with spatial information from different levels. Experiments on the camouflaged people dataset show that our approach outperformed all state-of-the-art methods.
C1 [Hendaoui, Rabeb; Nabiyev, Vasif] Karadeniz Tech Univ, Fac Engn, Dept Comp Engn, Trabzon, Turkey.
C3 Karadeniz Technical University
RP Hendaoui, R (corresponding author), Karadeniz Tech Univ, Fac Engn, Dept Comp Engn, Trabzon, Turkey.
EM rabeb@ktu.edu.tr; vasif@ktu.edu.tr
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Bhajantri NU, 2006, ICIT 2006: 9TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P145
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Galun M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P716
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P356, DOI 10.1109/TIP.2018.2868382
   Pan Y., 2011, Mod Appl Sci, V5, P152, DOI DOI 10.5539/MAS.V5N4P152
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Piergiovanni AJ, 2020, PROC CVPR IEEE, P130, DOI 10.1109/CVPR42600.2020.00021
   Rao CP, 2020, INT J SPEECH TECHNOL, V23, P327, DOI 10.1007/s10772-020-09699-7
   Sengottuvelan P., 2008, 2008 1st International Conference on Emerging Trends in Engineering and Technology (ICETET), P6, DOI 10.1109/ICETET.2008.232
   Shao R, 2019, IEEE T INF FOREN SEC, V14, P923, DOI 10.1109/TIFS.2018.2868230
   Song L., 2010, P INT C MULT TECHN, P1
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tankus A, 2001, COMPUT VIS IMAGE UND, V82, P208, DOI 10.1006/cviu.2001.0912
   Zeng Y, 2019, IEEE I CONF COMP VIS, P7233, DOI 10.1109/ICCV.2019.00733
   Zhang P., 2018, P 2 INT C ADV ARTIFI, P1
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
   Zhang PP, 2019, PATTERN RECOGN, V93, P521, DOI 10.1016/j.patcog.2019.05.012
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng YF, 2019, IEEE SIGNAL PROC LET, V26, P29, DOI 10.1109/LSP.2018.2825959
NR 26
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18531
EP 18542
DI 10.1007/s11042-022-12118-5
EA MAR 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766438300012
DA 2024-07-18
ER

EF