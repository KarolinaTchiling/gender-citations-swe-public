FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Shen, B
AF Shen, Bo
TI Perfect requantization for video transcoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE requantization; transcoding; H.264
AB Bit rate adaptation is one of the most important types of video transcoding. In this paper, we investigate certain critical points in the spectrum of rate shaping requests. We show that the selection of quantization step sizes may not have monotonic effects on rate-distortion characteristics in the transcoding sense. In other words, rate-distortion tradeoff for transcoding which operates on an already-compressed source can be different than that for regular encoding which operates on an original source. We show in a generic form that careful selections of the step size can lead to much improved performance for transcoding, especially when comparing to what would have been produced through a direct encoding. We demonstrate this unique rate-distortion characteristic through simulations as well as real transcoding scenario with H.264 sequences.
C1 Hewlett Packard Labs, Streaming Media Syst Grp, Palo Alto, CA 94304 USA.
C3 Hewlett-Packard
RP Shen, B (corresponding author), Hewlett Packard Labs, Streaming Media Syst Grp, 1501 Page Mill Rd 1181, Palo Alto, CA 94304 USA.
EM bo.shen@hp.com
CR Bauschke HH, 2003, IEEE T IMAGE PROCESS, V12, P843, DOI 10.1109/TIP.2003.812375
   CHEN S, 1996, ELECTRON LETT, V32, P1082
   *JOINT VID TEAM IS, 2002, ITUT REC H264 ISO IE
   Rosen Kenneth H, 2000, ELEMENTARY NUMBER TH
   SHEN B, 2005, P IEEE WORKSH MULT S
   TAUBMAN DS, 2002, JPED 2000 IMAGE COMP
   Werner O, 1999, IEEE T IMAGE PROCESS, V8, P179, DOI 10.1109/83.743853
NR 7
TC 5
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2007
VL 35
IS 2
BP 163
EP 173
DI 10.1007/s11042-007-0127-6
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 212XA
UT WOS:000249629100004
DA 2024-07-18
ER

PT J
AU Lam, KY
   Chiu, CKH
AF Lam, Kam-Yiu
   Chiu, Calvin K. H.
TI The design of a wireless real-time visual surveillance system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE real-time systems; adaptive scheduling; mobile systems; object modelling
ID TRACKING
AB In this paper, we study the important issues in the design of an efficient wireless real-time visual surveillance system (WISES). Two important considerations are to minimize: (1) the video workload on the wireless network; and (2) the processing workload at the front-end video capturing unit. To achieve the first objective, we propose a cooperative framework for semantic filtering of video frames instead of forwarding every video frame to the back-end server for analysis and monitoring query evaluation. To minimize the processing workload at the front-end unit, a hierarchical object model (HOM) is designed to model the status of the objects, and their temporal and spatial properties in the video scene. With the information provided from the back-end server, the front-end unit pre-analyses the current status of the objects in the HOM by comparing the selection conditions in the submitted monitoring queries following the adaptive object-based evaluation (APOBE) scheme which is proposed to reduce the processing workload at the front-end unit. In APOBE, a higher evaluation frequency is given to the object which is closer to satisfy the condition in the monitoring queries. The performance of WISES has been studied to demonstrate the efficiency of the proposed scheme.
C1 City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Lam, KY (corresponding author), City Univ Hong Kong, Dept Comp Sci, 83 Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.
EM cskylam@cityu.edu.hk; calvin@cs.cityu.edu.hk
RI Lam, Kam Yiu/W-3711-2018; Lam, Alfred/C-1652-2008
OI Lam, Alfred/0000-0003-2771-564X; Lam, Kam-Yiu/0000-0003-0673-3566
CR BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chiasserini CF, 2002, 13TH IEEE INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS, VOL 1-5, PROCEEDINGS, P2357, DOI 10.1109/PIMRC.2002.1046566
   CHRIS D, 1999, P SPIES 13 ANN INT C, V3713, P178
   Collins G, 2000, LECT NOTES ARTIF INT, V1831, P497
   Grimson WEL, 1998, PROC CVPR IEEE, P22, DOI 10.1109/CVPR.1998.698583
   Huwer S, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P37, DOI 10.1109/VS.2000.856856
   Intille SS, 1997, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.1997.609402
   PIATER JH, 2001, P 2 IEEE INT WORKSHP
   PIATER JH, 2002, P 3 IEEE INT WORKSH
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
NR 11
TC 6
Z9 6
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2007
VL 33
IS 2
BP 175
EP 199
DI 10.1007/s11042-006-0056-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 149GB
UT WOS:000245134000004
DA 2024-07-18
ER

PT J
AU Koukoulidis, V
   Shah, M
AF Koukoulidis, V
   Shah, M
TI The IP multimedia domain: service architecture for the delivery of
   voice, data, and next generation multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IMS; IP; SIP; multimedia; UMTS; GPRS; GSM; WLAN; WiFi
AB The IP Multimedia Subsystem (IMS) is defined by the 3(rd) Generation Partnership Project (3GPP) as a new core network domain. IMS provides a service control platform that allows creation of new Multimedia and multi-session applications utilizing wireless and wireline transport capabilities. In this paper we will cover the concepts and standards defining IMS and review the network architecture from a mobile perspective. We will see how IMS interacts with the Packet Switched Domain (e.g. Wireless LAN, GPRS, and UNITS networks), the Internet, and application services. Then we will examine the key IMS capabilities and show how they call be combined to create new mobile IP services. Finally, we present a software architecture, which is enabled by IMS and allows development of unique applications (with multimedia/multi-session functionality, single/multi-user, service to user). The software architecture is illustrated by ail example of a prototype application.
C1 Siemens Commun Inc, Boca Raton, FL USA.
   T Mobile USA Inc, Bellevue, WA USA.
C3 Siemens AG
RP Koukoulidis, V (corresponding author), Siemens Commun Inc, Boca Raton, FL USA.
EM Vassilios.Koukoulidis@siemens.com; Mehul.shah@t-mobile.com
CR ALAN B, 2004, SIP UNDERSTANDING SE
   [Anonymous], 2004, The 3G IP multimedia subsystem (IMS)
   [Anonymous], 2000, RFC2865
   CALHOUN P, 2003, RFC3588
   HANDLEY, 1998, RFC2327
   Mallick M., 2003, MOBILE WIRELESS DESI
   Poikselka M., 2004, IMS IP MULTIMEDIA CO
   ROSENBROCK K, 2001, RFC3113
   Schooler E., 2002, 3261 RFC
   Schulzrinne Henning, 2003, RFC3550
NR 10
TC 4
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2006
VL 28
IS 2
BP 203
EP 220
DI 10.1007/s11042-006-6143-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 042MH
UT WOS:000237531600007
DA 2024-07-18
ER

PT J
AU Bertini, M
   Del Bimbo, A
   Nunziati, W
AF Bertini, M
   Del Bimbo, A
   Nunziati, W
TI Common visual cues for sports highlights modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE semantic annotation; highlights detection; sport videos; visual cues
AB Automatic annotation of semantic events allows effective retrieval of video content. In this work, we present solutions for highlights detection in sports videos. The proposed approach exploits the typical structure of a wide class of sports videos, namely those related to sports which are played in delimited venues with playfields of well known geometry, like soccer, basketball, swimming, track and field disciplines, and so on. For these sports, a modeling scheme based on a limited set of visual cues and on finite state machines that encode the temporal evolution of highlights is presented, that is of general applicability to this class of sports. Visual cues encode position and speed information coming from the camera and from the object/athletes that are present in the scene, and are estimated automatically from the video stream. Algorithms for model checking and for visual cues estimation are discussed, as well as applications of the representation to different sport domains.
RI Bertini, Marco/X-1325-2019
OI Bertini, Marco/0000-0002-1364-218X; DEL BIMBO,
   ALBERTO/0000-0002-1052-8322
CR ANDRE E, 1988, P 8 EUR C ART INT EC, P449
   Assfalg J, 2002, P INT C MULT EXP ICM
   BALDI G, 1999, LNCS, P171
   Bengio Y., 1999, Neural Computing Surveys, V2
   Brand M, 1997, P IEEE C COMP VIS PA
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Intille SS, 2001, COMPUT VIS IMAGE UND, V81, P414, DOI 10.1006/cviu.2000.0896
   Jordan Michael Irwin, 1999, LEARNING GRAPHICAL M
   Leonardi R, 2002, IEEE MULTIMEDIA, V9, P44, DOI 10.1109/93.998057
   MOTTALEB M, 2003, P 9 INT C DISTR MULT, P154
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Russell S., 1995, Prentice Hall series in artificial intelligence, V25, P27
   Sudhir G, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P81, DOI 10.1109/CAIVD.1998.646036
   Tovinkere Vasanth., 2001, Proceedings of the 2001 IEEE International Conference on Multimedia and Expo (ICME'Ol), P1040
   Xie LX, 2002, INT CONF ACOUST SPEE, P4096
   Zhou W., 2000, ACM Workshops on Multimedia, P213
NR 17
TC 5
Z9 5
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2005
VL 27
IS 2
BP 215
EP 228
DI 10.1007/s11042-005-2575-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 961OP
UT WOS:000231672000003
DA 2024-07-18
ER

PT J
AU Avgeriou, P
   Retalis, S
AF Avgeriou, P
   Retalis, S
TI CRITON: A hypermedia design tool
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE hypermedia design; web site design; CASE tool; design tool; navigation;
   page metaphor
AB The WWW has turned into a development and run-time environment for large-scale and complex applications. Such sophisticated applications are being deployed in increasing numbers without having been developed according to appropriate methodologies, tools and quality standards. The reason is not only that the hypermedia industry resists to utilize formal methods, but also that these methods and corresponding tools are very few and of dubious standards. The consequence is that the hypermedia applications being developed are of poor functionality and lack qualities such as modifiability, usability and maintainability. Especially the design phase is one of the phases that lack sufficient support from methods and CASE tools. This paper presents CRITON, a cross platform tool, built to support a hypermedia design method within an integrated environment. CRITON manages all three aspects of hypermedia design: conceptual design, navigational design and graphical user interface design, utilizing well-established theories and practices from software as well as hypermedia engineering. It employs these designs to generate a preliminary, exemplary form of the hypermedia application for the purpose of assessing the designs before the implementation phase.
C1 Natl Tech Univ Athens, Dept Elect & Comp Engn, Software Engn Lab, Athens 15780, Greece.
   Univ Cyprus, Dept Comp Sci, CY-1678 Nicosia, Cyprus.
C3 National Technical University of Athens; University of Cyprus
RP Natl Tech Univ Athens, Dept Elect & Comp Engn, Software Engn Lab, Athens 15780, Greece.
EM pavger@softlab.ntua.gr; retal@softlab.ntua.gr
OI Retalis, Symeon/0000-0002-1703-6953; Avgeriou, Paris/0000-0002-7101-0754
CR CASANOVA MA, 1993, P HYP 91 SAN ANT
   CERI S, 2000, P WWW9 C AMST MAY
   CONKLIN J, 1988, ACM T INFORM SYST, V6, P303, DOI 10.1145/58566.59297
   DIAZ A, 1995, WORLD WIDE WEB J DEC
   *DUBL COR, 1999, DUBL COR MET EL SET
   Garzotto F., 1996, Journal of Organizational Computing and Electronic Commerce, V6, P211
   GARZOTTO F, 1993, ACM T INFORM SYST, V11, P1, DOI 10.1145/151480.151483
   Halasz F., 1990, Proceedings of the Hypertext Standardization Workshop (NIST SP 500-178), P95
   HALASZ FG, 1988, COMMUN ACM, V31, P836, DOI 10.1145/48511.48514
   HARDMAN L, HYPERMEDIA, V5, P47
   *IEEE LEARN TECHN, DRAFT STAND LEARN OB
   Isakowitz T., 1993, Proceeding of the Twenty-Sixth Hawaii International Conference on System Sciences (Cat. No.93TH0501-7), P361, DOI 10.1109/HICSS.1993.284333
   ISAKOWITZ T, 1995, COMMUN ACM, V38, P34, DOI 10.1145/208344.208346
   ISAKOWITZ T, 1998, IS9818 CTR RES INF S
   ISAKOWITZ T, 1997, P HICSS 30
   Lang M., 2002, P IS2002 INF SCI IT
   Lowe David., 1999, Hypermedia and the Web: an engineering approach
   MURUGESAN S, 1999, ACM SIGWEB NEWSLETTE, V3
   NANARD J, 1995, COMMUN ACM, V38, P49, DOI 10.1145/208344.208347
   OOCH G, 1999, UML USER GUIDE
   Pressman R.S., 2000, SOFTWARE ENG PRACTIT
   QUATRANI T, 1998, VISUAL MODELING RATI
   RETALIS S, 2000, WEB ENG NEW DISCIPLI, V20, P95
   RUMBAUGH J, 1999, UML REFERENCE MANUA
   SCHWABE D, 1998, THEORY PRACTICE OBJE, V4
   SCHWABE D, WORKSH HYP DEV PROC
   SCHWABE D, 1999, SIGWEB NEWSLETTER, V8
   SCHWABE D, 1998, 0898 MCC DEP INF
   SEWHABE D, 1995, COMMUNICATIONS ACM, V35
   SOMMERVILLE I, 1990, DESIGNERS NOTEPAD HY, P260
   THOMAS D, 1998, WEB TIME SOFTWARE DE, P78
   WALL D, 1999, GRAPHICS PROGRAMMING
NR 32
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2005
VL 27
IS 1
BP 5
EP 21
DI 10.1007/s11042-005-2712-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 955JI
UT WOS:000231221800001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Nack, F
   Putz, W
AF Nack, F
   Putz, W
TI Saying what it means: Semi-automated (news) media annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE media production; media annotation; news production; MPEG-7; XML-Schema;
   news production tools
ID BROADCAST NEWS; VIDEO; AUDIO
AB This paper considers the automated and semi-automated annotation of audiovisual media in a newtype of production framework, A4SM (Authoring System for Syntactic, Semantic and SemioticModelling). We present the architecture of the framework, describe a prototypical camera, a handheld device for basic semantic annotation, and an editing suite to demonstrate how video material can be annotated in real time and how this information can not only be used for retrieval but also can be used during the different phases of the production process itself. We then outline the underlying XML Schema based content description structures of A4SM and discuss the pros and cons of our approach of evolving semantic networks as the basis for audio-visual content description.
C1 CWI, Multimedia & Human Comp Interact Grp, NL-1009 AB Amsterdam, Netherlands.
   FHG, IPSI, Darmstadt, Germany.
C3 Fraunhofer Gesellschaft; Fraunhofer Institute Center Schloss
   Birlinghoven
RP Nack, F (corresponding author), CWI, Multimedia & Human Comp Interact Grp, NL-1009 AB Amsterdam, Netherlands.
EM Frank.Nack@cwi.nl; wolfgang.putz@ipsi.fraunhofer.de
CR AIGRAIN P, 1995, IJCAI WORKSH INT MUL, P5
   [Anonymous], 1984, Conceptual Structures: Information Processing in Mind and Machine
   [Anonymous], THEORY SEMIOTICS
   Arnheim R., 1956, ART VISUAL PERCEPTIO
   Bertini M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P483, DOI 10.1109/ICME.2000.869644
   BLOCH GR, 1986, ELEMENTS UNE MACHINE
   Bloom P. J., 1985, IEEE ASSP Magazine, V2, P2, DOI 10.1109/MASSP.1985.1163757
   Borchers J, 1998, IEEE MULTIMEDIA, V5, P36, DOI 10.1109/93.713303
   Bordwell David., MAKING MEANING INFER
   BRACHMAN RJ, 1983, READINGS KNOWLEDGE R
   Brooks K. M., 1999, THESIS MIT
   Colombo C, 1999, IEEE MULTIMEDIA, V6, P38, DOI 10.1109/93.790610
   DAVIS ME, 1995, MEDIA STREAMS REPRES
   DELBIMBO A, 1999, VISUAL INFORMATION R
   FEHLIS H, 1999, FERNSEH KINOTECHNIK, V53
   Gauvain JL, 2000, COMMUN ACM, V43, P64, DOI 10.1145/328236.328148
   Greimas J. A, 1983, STRUCTURAL SEMANTICS
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   HALASZ FG, 1988, COMMUNICATIONS ACM, V31
   HIRATA K, 1998, P ART INT MUS IJCAI, P77
   HUNTER J, 2001, 10 INT WORLD WID WEB, P457
   HUNTER J, 1999, P WWW 8 TOR
   IDE I, 2000, WORKSH P 9 ACM INT C, P195
   *ISO, 2000, MPEG BAUL M
   *ISO, 2001, 1SC29WG11N4242 ISOIE
   *ISO, 2001, 1SC29WG11N4288 ISOIE
   JOHNSON SE, 2000, RIAO 2000 C P, V43, P1163
   KUBALA F, 2000, COMMUN ACM, V43, P57
   LEMSTROM K, 2000, RIAO 2000 C P, V2, P1163
   LINDLEY C, 2000, BCS COMP GRAPH DISPL
   Melucci M, 2000, RIAO 2000 C P, V2, P1261
   MILLS TJ, 2000, RIAO 2000 C P, V2, P1135
   Nack F, 1997, MULTIMED TOOLS APPL, V4, P57, DOI 10.1023/A:1009682315690
   NACK F, 1999, EVERYTHING YOU WAN 1, P65
   Nack F., 1996, AUTEUR APPL VIDEO SE
   NACK F, 1999, EVERYTHING YOU WAN 2, P64
   NACK F, 1998, P ECAI 98 WORKSH AI
   NACK F, 2000, WORKSH DIG STOR DARM
   NAGASAKA A, 1992, IFIP TRANS A, V7, P113
   PACHET F, 2000, RIAO 2000 C P, V2, P1238
   PARKES AP, 1989, SIGIR 89, P229
   PARKES AP, 1989, THESIS LANCASTER U
   Pfeiffer S., 1996, Proceedings ACM Multimedia 96, P21, DOI 10.1145/244130.244139
   *RDF, 2001, RDF SCHEM
   Robertson J., 1998, P ECAI 98 WORKSH AI
   SACK W, 1993, INT JOINT C ART INT
   Santini S, 2000, IEEE MULTIMEDIA, V7, P26, DOI 10.1109/93.879766
   Smith TGA, 1992, ACM WORKSH NETW OP S
   *SMPTE, 1999, SMPTE DYN DAT DICT S
   Tonomura Y., 1994, IEEE Multimedia, V1, P34, DOI 10.1109/MMUL.1994.318984
   Wactlar HD, 2000, COMMUN ACM, V43, P42, DOI 10.1145/328236.328144
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
   YEUNG MM, 1995, P SOC PHOTO-OPT INS, V2417, P399, DOI 10.1117/12.206067
   ZHANG HJ, 1994, INT C MULT COMP SYST, P45
   2001, XLINK
NR 55
TC 7
Z9 7
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2004
VL 22
IS 3
BP 263
EP 302
DI 10.1023/B:MTAP.0000017031.26875.f7
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 776VC
UT WOS:000189139200003
DA 2024-07-18
ER

PT J
AU Zia, A
   Mahum, R
   Ahmad, N
   Awais, M
   Alshamrani, AM
AF Zia, Amna
   Mahum, Rabbia
   Ahmad, Nabeel
   Awais, Muhammad
   Alshamrani, Ahmad M.
TI Eye diseases detection using deep learning with BAM attention module
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Eye Disease Detection; Deep Learning; Cataract; Glaucoma; Diabetic
   Retinopathy; Improved SqueezeNet
ID CONVOLUTIONAL NEURAL-NETWORKS; AUTOMATIC DETECTION; IMAGES; RECOGNITION;
   DIAGNOSIS; ALGORITHM; GLAUCOMA; TEXTURE
AB With the changing lifestyle, a large population suffers from eye diseases such as glaucoma, cataract, and diabetic retinopathy. Therefore, timely detection and classification of the disease are necessary to minimize vision loss, however, it is time taking task and requires various tests and physicians' in-depth analysis. Thus, an accurate automated technique, timely detection, and classification are needed to cope with the aforementioned challenges. Therefore, this study proposes a technique based on an improved deep learning algorithm i.e., SqueezeNet that uses the eye image' features to detect various diseases such as cataract, glaucoma, and diabetic retinopathy simultaneously. In our proposed model, we employed Bottleneck Attention Module (BAM) with SqueezeNet having an additional layer. Our proposed attention module utilizes two different ways and effectively extracts the most representative features and drops the image's background features of eyes which don't take part in the detection of diseases. Moreover, the algorithm is a pre-trained network that doesn't require a huge training set, therefore, the existing dataset i.e., ODIR, cataract, ORIGA, and glaucoma datasets have been utilized for the training and testing. Additionally, cross-validation has been employed using the cataract dataset to assess the performance of the proposed model. The squeezed connections with regularization power help to minimize the overfitting during the training of eye samples training sets. The proposed algorithm is a novel and effective technique to report the successful implementation for the early detection and classification of eye disease images. The algorithm achieved 98.9% accuracy over the testing dataset and 98.1% accuracy over cross-validation. Various experiments have been performed to confirm that our proposed algorithm performs significantly to detect and classify eye diseases than existing state-of-the-art.
C1 [Zia, Amna; Ahmad, Nabeel] Sir Syed CASE Inst Informat Technol, Dept Comp Sci, Islamabad, Pakistan.
   [Mahum, Rabbia] Univ Engn & Technol, Dept Comp Sci, Taxila, Pakistan.
   [Awais, Muhammad] Henan Agr Univ, Dept Elect Engn, Zhengzhou 450002, Peoples R China.
   [Awais, Muhammad] Henan Int Joint Lab Laser Technol Agr Sci, Zhengzhou 450002, Peoples R China.
   [Alshamrani, Ahmad M.] King Saud Univ, Coll Sci, Stat & Operat Res Dept, Riyadh 11451, Saudi Arabia.
C3 University of Engineering & Technology Taxila; Henan Agricultural
   University; King Saud University
RP Mahum, R (corresponding author), Univ Engn & Technol, Dept Comp Sci, Taxila, Pakistan.
EM amnazia113@gmail.com; rabbia.mahum@uettaxila.edu.pk;
   nabeel.ahmed@cydea.tech; dr.muhammad.awais@henau.edu.cn;
   ahmadm@ksu.edu.sa
RI b, h/Q-9229-2019; Alshamrani, Ahmad Moied/GZA-3871-2022
OI b, h/0000-0002-6604-9785; Alshamrani, Ahmad Moied/0000-0001-7103-8872; ,
   rabbia/0000-0003-1983-8201
FU King Saud University [RSPD2023R533]; King Saud University, Riyadh, Saudi
   Arabia
FX The authors present their appreciation to King Saud University for
   funding this research through Researchers Supporting Program number
   (RSPD2023R533), King Saud University, Riyadh, Saudi Arabia.
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Acharya UR, 2011, IEEE T INF TECHNOL B, V15, P449, DOI 10.1109/TITB.2011.2119322
   Akram A, 2020, TURK J ELECTR ENG CO, V28, P917, DOI 10.3906/elk-1905-42
   Almazroa A, 2018, PROC SPIE, V10579, DOI 10.1117/12.2293584
   Amirkhani D, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019), DOI 10.1109/icspis48872.2019.9066140
   An GZ, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/6874765
   [Anonymous], 2019, Cataract Dataset
   [Anonymous], 2015, Int J Adv Networking Appl
   Asaoka R, 2016, OPHTHALMOLOGY, V123, P1974, DOI 10.1016/j.ophtha.2016.05.029
   Bajwa MN, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0842-8
   Bastanfard A, 2022, MULTIMED TOOLS APPL, V81, P23473, DOI 10.1007/s11042-022-12584-x
   Brown J D., 2015, Journal of Chemical Information and Modeling, V53, P160, DOI DOI 10.1017/CBO9781107415324.004
   Chaudhary PK, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3140437
   Chea N, 2021, Computers, Materials & Continua, V67
   Chen TQ, 2015, Arxiv, DOI arXiv:1512.01274
   Chen XY, 2015, IEEE ENG MED BIO, P715, DOI 10.1109/EMBC.2015.7318462
   Choi JY, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187336
   Chowdhury AR, 2019, MED BIOL ENG COMPUT, V57, P193, DOI 10.1007/s11517-018-1878-0
   Collobert R, 2011, BIGLEARN NIPS WORKSH, P1
   Darussalam U., 2020, J Teknik Informatika CIT Medicom, V12, P16
   de la Torre J, 2020, NEUROCOMPUTING, V396, P465, DOI 10.1016/j.neucom.2018.07.102
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   DT42, 2016, Squeezenet keras implementation
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Harifi S, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON COMPUTING TECHNOLOGY AND INFORMATION MANAGEMENT (ICCTIM), P115, DOI 10.1109/ICCTIM.2015.7224603
   Hemanth DJ, 2020, NEURAL COMPUT APPL, V32, P707, DOI 10.1007/s00521-018-03974-0
   Hossain MR, 2020, IEEE REGION 10 SYMP, P1333
   Ibrahim I., 2021, J Appl Sci Technol Trend, V2, P10, DOI [DOI 10.38094/JASTT20179, 10.38094/jastt20179]
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   kaggle, Dataset: Peking University International Competition on Ocular Disease Intelligent Recognition (ODIR-2019)
   Kim SJ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177726
   Kora P, 2022, BIOCYBERN BIOMED ENG, V42, P79, DOI 10.1016/j.bbe.2021.11.004
   Korpusik M, 2017, INT CONF ACOUST SPEE, P5685, DOI 10.1109/ICASSP.2017.7953245
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar KS, 2023, NEURAL COMPUT APPL, V35, P12495, DOI 10.1007/s00521-023-08402-6
   Li AN, 2016, IEEE ENG MED BIO, P1328, DOI 10.1109/EMBC.2016.7590952
   Li XM, 2020, IEEE T MED IMAGING, V39, P1483, DOI 10.1109/TMI.2019.2951844
   Li ZX, 2018, OPHTHALMOLOGY, V125, P1199, DOI 10.1016/j.ophtha.2018.01.023
   Lin M, 2014, Arxiv, DOI [arXiv:1312.4400, DOI 10.48550/ARXIV.1312.4400]
   Mahum R, 2023, IEEE ACCESS, V11, P134701, DOI 10.1109/ACCESS.2023.3332561
   Mahum R, 2023, HUM ECOL RISK ASSESS, V29, P303, DOI 10.1080/10807039.2022.2064814
   Mahum R, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010026
   Mahum R, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21186189
   Maninis Kevis-Kokitsi, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P140, DOI 10.1007/978-3-319-46723-8_17
   Minoofam SAH, 2023, IEEE T NEUR NET LEAR, V34, P2480, DOI 10.1109/TNNLS.2021.3106705
   Mishkin D, 2017, COMPUT VIS IMAGE UND, V161, P11, DOI 10.1016/j.cviu.2017.05.007
   Islam SMS, 2018, Arxiv, DOI arXiv:1812.10595
   Munir MH., 2022, International Journal of Innovations in Science and Technology, V3, P197, DOI [10.33411/IJIST/2021030516, DOI 10.33411/IJIST/2021030516]
   Iandola FN, 2016, Arxiv, DOI arXiv:1602.07360
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Nazir T, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165283
   Nazir T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186185
   Nguyen QH, 2020, ICMLSC 2020: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING, P103, DOI 10.1145/3380688.3380709
   Novotny A, 2010, BIOSIG BRNO, P308
   Pahuja Rahul, 2022, Proceedings of Data Analytics and Management: ICDAM 2021. Lecture Notes on Data Engineering and Communications Technologies (90), P719, DOI 10.1007/978-981-16-6289-8_59
   Panda R, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.4.044003
   Park J, 2018, Arxiv, DOI [arXiv:1807.06514, 10.48550/arXiv.1807.06514, DOI 10.48550/ARXIV.1807.06514]
   Prasad K, 2019, TENCON IEEE REGION, P2148, DOI [10.1109/TENCON.2019.8929666, 10.1109/tencon.2019.8929666]
   Pratap T, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2021.105927
   Pratt H, 2016, PROCEDIA COMPUT SCI, V90, P200, DOI 10.1016/j.procs.2016.07.014
   Priya R., 2013, ICTACT J. Soft Comput., V3, P563, DOI [10.21917/ijsc.2013.0083, DOI 10.21917/IJSC.2013.0083]
   Rahim Sarni Suhaila, 2016, Brain Inform, V3, P249, DOI 10.1007/s40708-016-0045-3
   Raju M, 2017, STUD HEALTH TECHNOL, V245, P559, DOI 10.3233/978-1-61499-830-3-559
   Rajyaguru Vipul, 2022, International Journal of Information Technology, V14, P713, DOI 10.1007/s41870-020-00442-8
   Rath Sovit Ranjan, 2019, Diabetic retinopathy 224 x 224 gaussian filtered
   Reed H., 2014, arXiv
   Sarki R, 2020, IEEE ACCESS, V8, P151133, DOI 10.1109/ACCESS.2020.3015258
   Selvathi D, 2019, PROCEEDINGS OF 2019 1ST INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION AND COMMUNICATION TECHNOLOGY (ICIICT 2019), DOI 10.1109/iciict1.2019.8741450
   Shankaranarayana SM, 2017, LECT NOTES COMPUT SC, V10554, P168, DOI 10.1007/978-3-319-67561-9_19
   Shibata N, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-33013-w
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Srivastava R, 2015, I S BIOMED IMAGING, P768, DOI 10.1109/ISBI.2015.7163985
   Syarifah MA, 2020, AIP CONF PROC, V2296, DOI 10.1063/5.0030744
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan JH, 2017, J COMPUT SCI-NETH, V20, P70, DOI 10.1016/j.jocs.2017.02.006
   Thanki R., 2023, Healthcare Analytics, V3, DOI [10.1016/j.health.2023.100140, DOI 10.1016/J.HEALTH.2023.100140]
   Tokui S., 2015, Chainer: a Next-Generation Open Source Framework for Deep Learning
   Tong Y, 2020, EYE VISION, V7, DOI 10.1186/s40662-020-00183-6
   Hagos MT, 2019, Arxiv, DOI arXiv:1905.07203
   Vyas M, 2015, Kaggle diabetic retinopathy detection competition report
   Waghmare SagarM., 2016, FireModule.lua
   Weni I., 2021, IJCCS (Indo. J. Comput. Cyber. Syst.), V15, P75, DOI [10.22146/ijccs.61882, DOI 10.22146/IJCCS.61882]
   Xu X, 2020, IEEE J BIOMED HEALTH, V24, P556, DOI 10.1109/JBHI.2019.2914690
   Yang HJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1209, DOI 10.1145/3123266.3129393
   Yu X, 2021, IEEE ACM T COMPUT BI, V18, P94, DOI 10.1109/TCBB.2020.2986544
   Zhang Edward, 2021, Sauman Das Glaucoma Detection
   Zhang LL, 2017, IEEE INT C NETW SENS, P60, DOI 10.1109/ICNSC.2017.8000068
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
   Zhang Z, 2009, 2009 2 INT C BIOMEDI, P1
   Zhao Y, 2018, IEEE T BIO-MED ENG, V65, P1975, DOI 10.1109/TBME.2017.2715281
   Zhe Wang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P267, DOI 10.1007/978-3-319-66179-7_31
   Zhou Y, 2020, IEEE T MED IMAGING, V39, P436, DOI 10.1109/TMI.2019.2928229
   Zilly J, 2017, COMPUT MED IMAG GRAP, V55, P28, DOI 10.1016/j.compmedimag.2016.07.012
NR 94
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 27
PY 2023
DI 10.1007/s11042-023-17839-9
EA DEC 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DE0M1
UT WOS:001130236200005
DA 2024-07-18
ER

PT J
AU Rajeyyagari, S
   Saravanan, M
   Pandey, PS
   Devi, A
   Shankar, SS
AF Rajeyyagari, Sivaram
   Saravanan, M.
   Pandey, Purnendu Shekhar
   Devi, Aruna
   Shankar, S. Siva
TI Convolutional Neural network-based African vulture optimization
   algorithm for the enhancement of cybersecurity in the blockchain-based
   Smart grid
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Attackers; AVOA; Blockchain CNN; Electricity; Detection of
   abnormalities; Security; And smart grid
ID ATTACK DETECTION; CYBER-SECURITY; MICROGRIDS
AB A smart grid is a network that utilizes a digital network to monitor the passage of electricity from one node to another within the network. Some of the applications of the smart grid are dynamic control of voltage, substation automation, outage management, and so on. The smart grid become an important topic since the inclusion of digital systems to monitor the electricity flow enhances usage and at the same time, it is affected by malicious attacks. Hence, it is necessary to protect the smart grid from attackers so that the authenticated user gets all the benefits without any scarcity. For this, many approaches have proposed by the researchers and have shortcomings of less accuracy in classifying the normal and abnormal flow, computational complexities, and less throughput. In context with these problems, we proposed a Convolutional Neural Network (CNN) based African Vulture Optimization Algorithm (AVOA) for the enhancement of cybersecurity in the blockchain-based Smart grid. To offer a novel way for improving smart grid security and defect detection in the industry by utilising block chain technology with deep learning architectures. The smart grid network's security performance can be improved by the use of a blockchain-based smart grid node based network module. In addition, the simulation results are carried out utilising a hybrid framework to monitor the attacks in the network. The data from the switches and PMU wascollected in the physical layer of the system. Then a blockchain controller controls the data. This also monitors the transaction details in the smart grids. The data are pre-processed with the aid of a Label encoder, and MIN-MAX scaling approaches. Then the features are extracted by using the CNN and the classification data is also performed by the CNN; however, the conventional CNN lacks scalability, and to enhance the scalability we utilize the AVO algorithm. The AVO algorithm effectively improves the scalability and thus our proposed classifies the normal and abnormal data from the smart grid. For the experimental purpose, we have taken the UNSW_NB15 dataset and compared it with the state of artworks in terms of different parameters. From the analysis, it is observed that the proposed method enhances the cybersecurity level by enhancing the throughput, accuracy (97.40%), F1-score (99.17%), precision (98.25%), recall (98.37%)computational time (1.34 ms) and detection rate (97.3%).
C1 [Rajeyyagari, Sivaram] Shaqra Univ, Coll Comp & Informat Technol, Dept Comp Sci & Engn, Shaqra, Saudi Arabia.
   [Saravanan, M.] Auroras Technol & Res Inst, Dept Comp Sci & Engn, Hyderabad, India.
   [Pandey, Purnendu Shekhar] Parul Univ, Dept Comp Sci & Engn, Vododara, Gujarat, India.
   [Devi, Aruna] Dr N G P Inst Technol, Dept ECE, Dr N G Nagar,Kalapatti Rd, Coimbatore, India.
   [Shankar, S. Siva] KG Reddy Coll Engn & Technol, Dept Comp Sci & Engn, Hyderabad, India.
C3 Shaqra University; Aurora's Technological & Research Institute; Parul
   University
RP Rajeyyagari, S (corresponding author), Shaqra Univ, Coll Comp & Informat Technol, Dept Comp Sci & Engn, Shaqra, Saudi Arabia.
EM sivaramraj.vital@gmail.com
RI Rajeyyagari, Sivaram/AAH-7389-2021; Matheswaran,
   Saravanan/KVA-8691-2024; Subramanian, SivaShankar/AGY-5958-2022
OI Rajeyyagari, Sivaram/0000-0002-3893-447X; Matheswaran,
   Saravanan/0000-0001-6310-4470; 
CR Ali ABMShawkat., 2013, Smart grids: opportunities, developments, and trends
   [Anonymous], 2021, The UNSW-NB15 Dataset
   Cui H, 2021, IEEE SENS J, V21, P15885, DOI 10.1109/JSEN.2020.3027778
   Dehghani M, 2021, IEEE ACCESS, V9, P16488, DOI 10.1109/ACCESS.2021.3051300
   Dehghani M, 2020, IEEE ACCESS, V8, P179002, DOI 10.1109/ACCESS.2020.3027782
   Ding PP, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8850550
   Dubey K, 2022, J GRID COMPUT, V20, DOI 10.1007/s10723-021-09591-x
   Gai KK, 2019, IEEE T IND INFORM, V15, P3548, DOI 10.1109/TII.2019.2893433
   Gautham SK., 2021, Int J Wirel Microw Technol, V11, P1
   Ghiasi M, 2021, IEEE ACCESS, V9, P29429, DOI 10.1109/ACCESS.2021.3059042
   Gupta Sourav Sen, 2017, Blockchain.IBM Onlone
   Miraz MH, 2018, Arxiv, DOI arXiv:1801.03528
   Justo JJ, 2013, RENEW SUST ENERG REV, V24, P387, DOI 10.1016/j.rser.2013.03.067
   Kang ES, 2018, PROCEEDINGS OF 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS), P472, DOI 10.1109/CCOMS.2018.8463317
   Kim SK, 2018, ENERGIES, V11, DOI 10.3390/en11081973
   Kroposki B, 2008, IEEE POW ENER SOC GE, P1319
   Kumar M, 2022, IEEE T SUST COMPUT, V7, P386, DOI 10.1109/TSUSC.2021.3110245
   Lasseter RH, 2004, IEEE POWER ELECTRON, P4285
   Le TD, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9081218
   Liu J, 2012, IEEE COMMUN SURV TUT, V14, P981, DOI 10.1109/SURV.2011.122111.00145
   Manickam M, 2022, INT J IMAG SYST TECH, V32, P843, DOI 10.1002/ima.22669
   Ometov A, 2020, IEEE ACCESS, V8, P103994, DOI 10.1109/ACCESS.2020.2998951
   Platt G, 2012, SMART GRID: INTEGRATING RENEWABLE, DISTRIBUTED & EFFICIENT ENERGY, P185, DOI 10.1016/B978-0-12-386452-9.00008-5
   Sharma Arvind, 2018, 2018 International Conference on Advances in Computing, Communication Control and Networking (ICACCCN). Proceedings, P1200, DOI 10.1109/ICACCCN.2018.8748491
   Shi JY, 2021, IEEE T CIRCUITS-II, V68, P993, DOI 10.1109/TCSII.2020.3020139
   Ustun TS, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13050826
   Wang BY, 2019, IEEE T IND APPL, V55, P7300, DOI 10.1109/TIA.2019.2919820
   Zhu XQ, 2022, SUSTAIN CITIES SOC, V76, DOI 10.1016/j.scs.2021.103418
NR 28
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 22
PY 2023
DI 10.1007/s11042-023-17805-5
EA DEC 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB8U4
UT WOS:001129672000003
DA 2024-07-18
ER

PT J
AU Douga, Y
   Hadjadj-Aoul, Y
   Bourenane, M
   Mellouk, A
AF Douga, Yassine
   Hadjadj-Aoul, Yassine
   Bourenane, Malika
   Mellouk, Abdelhamid
TI Adaptive video streaming solution based on multi-access edge computing
   advantages
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Dynamic adaptive video streaming; Multi-access Edge Computing (MEC);
   QoE; Optimization; Congestion; User terminal
AB In the last few years, video streaming traffic surpassed all the other Internet traffic. This is mainly due to the substantial and ever-increasing size of video files and the widespread popularity of streaming services. A significant portion of the traffic above originates from mobile devices, thereby increasing demands on operators' infrastructures and potentially degrading services. The content providers' response has been to adopt adaptive video streaming techniques that avoid playback interruptions, as these interruptions are the leading cause of the deterioration in the Quality Of Experience (QoE). To go beyond end-to-end approaches, the authors proposed a new strategy that utilizes the Multi-access Edge Computing (MEC) standard to optimize streaming services. Being located at the MEC level allows, indeed, to be aware of the network congestion's state, which facilitates optimizing network operations. The suggested seamless strategy considers the users' devices' parameters to prevent them from selecting video quality options that would not enhance their viewing experience. By avoiding choices that could diminish the quality or worsen the experience, our strategy optimizes network resources and reduces energy and bandwidth consumption on the mobile device side. The proposed approach was implemented and tested within an emulation environment. The findings demonstrate the suitability of this type of approach in comparison with existing strategies (YouTube service) in terms of users' satisfaction and network performance.
C1 [Douga, Yassine] Univ Saad Dahle, LRDSI Lab, Blida, Algeria.
   [Hadjadj-Aoul, Yassine] Univ Rennes1, IRISA Lab, Rennes, France.
   [Bourenane, Malika] Univ Ahmed Ben Bella Oran, LRIIR Lab, Es Senia, Algeria.
   [Mellouk, Abdelhamid] Univ Paris Est, LISSI Lab, Champs Sur Marne, France.
C3 Universite de Rennes; Universite Gustave-Eiffel; Universite
   Paris-Est-Creteil-Val-de-Marne (UPEC)
RP Douga, Y (corresponding author), Univ Saad Dahle, LRDSI Lab, Blida, Algeria.
EM yassine.douga@hotmail.com; yhadjadj@irisa.fr; mb_regina@yahoo.fr;
   mellouk@u-pec.fr
CR Adhikari VK, 2012, IEEE INFOCOM SER, P1620, DOI 10.1109/INFCOM.2012.6195531
   Barman N, 2019, IEEE ACCESS, V7, P30831, DOI 10.1109/ACCESS.2019.2901778
   Beck M. T., 2014, P 6 INT C ADV FUT IN, P48
   Douga Y, 2016, MULTIMED TOOLS APPL, V75, P11347, DOI 10.1007/s11042-015-2857-1
   Elgendy IA, 2021, WIREL NETW, V27, P2023, DOI 10.1007/s11276-021-02554-w
   Gao Y, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9322205
   Kim M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062171
   Kim M, 2021, IEEE ACCESS, V9, P2142, DOI 10.1109/ACCESS.2020.3047373
   Li B, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/6216372
   Li Y, 2016, 2016 IEEE CONFERENCE ON STANDARDS FOR COMMUNICATIONS AND NETWORKING (CSCN)
   Mehrabi A, 2019, IEEE T MOBILE COMPUT, V18, P787, DOI 10.1109/TMC.2018.2850026
   Jiménez LR, 2019, IEEE ACCESS, V7, P70237, DOI 10.1109/ACCESS.2019.2918433
   Schwarzmann S, 2019, INTERNET-QOE'19: PROCEEDINGS OF THE 4TH INTERNET-QOE WORKSHOP: QOE-BASED ANALYSIS AND MANAGEMENT OF DATA COMMUNICATION NETWORKS, P7, DOI 10.1145/3349611.3355547
   Shi WX, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4016, DOI 10.1145/3474085.3475325
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Vega MT, 2018, IEEE T BROADCAST, V64, P432, DOI 10.1109/TBC.2018.2822869
NR 16
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 19
PY 2023
DI 10.1007/s11042-023-17764-x
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7T2
UT WOS:001126521200010
DA 2024-07-18
ER

PT J
AU Bandhu, KC
   Litoriya, R
   Jain, A
   Shukla, AV
   Vaidya, S
AF Bandhu, Kailash Chandra
   Litoriya, Ratnesh
   Jain, Anshita
   Shukla, Anand Vardhan
   Vaidya, Swati
TI An improved technique for stock price prediction on real-time exploiting
   stream processing and deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Long short-term memory (LSTM); Deep learning (DL); Root mean squared
   error (RMSE); Mean squared error (MSE); Stock price
AB The proposed model is a Deep Learning (DL) based method employing Long Short-Term Memory (LSTM) networks for forecasting stocks. The aim of this approach is forecasting stock prices of Apple Inc. using statistics on previous stock prices obtained from Tiingo. The proposed model consists of several stages of processing and modelling, including data cleaning, feature selection, feature scaling, model building, model evaluation, model improvement, and prediction. Cleaning, organising, and transforming raw data into a format appropriate for analysis are all parts of data pre-processing. Feature engineering involves the data extraction and selection of relevant features for accuracy improvement of the model. The scaling of features involves normalising the data to prevent bias in the model. The LSTM models are built and evaluated using multiple metrics such as Mean Squared Error (MAE) and Root Mean Squared Error (RMSE). The model is iteratively improved using a combination of hyperparameter tuning and feature engineering. Finally, the model is then used to forecast stock prices for the following 30 days, and the accuracy of the forecasts is determined. The proposed methodology is designed to outperform traditional LSTM models for predicting the future price of stock by incorporating novel techniques, for feature engineering and model refinement. The suggested design is a comprehensive approach for forecasting future stock prices using DL based techniques. The model is designed to be flexible and adaptable, allowing for customization for different datasets and prediction horizons. It represents a significant improvement over existing LSTM models for stock price prediction to be valuable in a variety of financial industry applications. This paper collects data from Tiingo API and uses stacked LSTM to train the model. The experimental results give only 0.0813 RMSE, which proves that the model is more accurate and precise.
C1 [Bandhu, Kailash Chandra; Litoriya, Ratnesh; Jain, Anshita; Shukla, Anand Vardhan; Vaidya, Swati] Med Caps Univ, Dept Comp Sci & Engn, Indore, India.
RP Litoriya, R (corresponding author), Med Caps Univ, Dept Comp Sci & Engn, Indore, India.
EM kailashchandra.bandhu@gmail.com; litoriya.ratnesh@gmail.com;
   anshitajain12345@gmail.com; theanandam394@gmail.com;
   swati.dhage28@gmail.com
RI Bandhu, Kailash Chandra/ABF-4912-2020
OI Bandhu, Kailash Chandra/0000-0002-4337-4198; Litoriya,
   Ratnesh/0000-0002-7285-422X
CR Adlakha N, 2021, 2021 INT C SYST COMP, P1, DOI [10.1109/ICSCAN53069.2021.9526506, DOI 10.1109/ICSCAN53069.2021.9526506]
   Bandhu KC, 2022, Int J Electron Gov
   Bathla G, 2023, MULTIMED TOOLS APPL, V82, P9727, DOI 10.1007/s11042-022-12390-5
   Chugh A, 2023, Deep learning | Introduction to long short term memory
   Du JY, 2019, PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2019), P1083, DOI [10.1109/ITNEC.2019.8729026, 10.1109/itnec.2019.8729026]
   Gao SE, 2018, INT SYMP COMP CONS, P10, DOI 10.1109/IS3C.2018.00012
   Gao TW, 2017, INT CONF SOFTW ENG, P575, DOI 10.1109/ICSESS.2017.8342981
   Ghosh P, 2022, FINANC RES LETT, V46, DOI 10.1016/j.frl.2021.102280
   Hamed I. M., 2011, Proceedings of the 2011 International Conference on Computer Engineering & Systems (ICCES 2011), P105, DOI 10.1109/ICCES.2011.6141021
   Hirey M., 2022, 2022 INT C ADV TECHN, DOI [10.1109/iconat53423.2022.9725888, DOI 10.1109/ICONAT53423.2022.9725888]
   intellipaat, 2022, What is LSTM? Introduction to long short term memory
   Jagwani J, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P462, DOI 10.1109/ICCONS.2018.8663035
   Jeevan B, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON CIRCUITS, CONTROL, COMMUNICATION AND COMPUTING (I4C)
   Kavinnilaa J., 2021, 2021 International Conference on System, Computation, Automation and Networking (ICSCAN), IEEE, P1, DOI [10.1109/ICSCAN53069.2021.9526491, DOI 10.1109/ICSCAN53069.2021.9526491]
   Lakshmanarao A, 2022, 2022 INT C INN COMP, P1, DOI [10.1109/ICSES55317.2022.9914347, DOI 10.1109/ICSES55317.2022.9914347]
   Lei Y, 2018, 2018 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2018), P497
   Litoriya R, 2022, ADOPTION BLOCKCHAIN, P211, DOI [10.1007/978-3-030-89546-4_11, DOI 10.1007/978-3-030-89546-4_11]
   Ma C, 2022, MULTIMED TOOLS APPL, V81, P12599, DOI 10.1007/s11042-022-12381-6
   Malviya S, J Autom Mob Robot Intell Syst
   Manh H, 2006, Fintrop
   Marchai Fernando Liko, 2021, 2021 8th International Conference on Information Technology, Computer and Electrical Engineering (ICITACEE), P79, DOI 10.1109/ICITACEE53184.2021.9617222
   Mathanprasad LM, 2022, 2022 INT C ADV COMP, P1, DOI [10.1109/ACCAI53970.2022.9752616, DOI 10.1109/ACCAI53970.2022.9752616]
   Nivetha RY, 2017, 2017 INTERNATIONAL CONFERENCE ON TECHNICAL ADVANCEMENTS IN COMPUTERS AND COMMUNICATIONS (ICTACC), P1, DOI 10.1109/ICTACC.2017.11
   Nourbakhsh Z, 2023, MULTIMED TOOLS APPL, V82, P17769, DOI 10.1007/s11042-022-13963-0
   Othan D., 2021, Int Conference INnovations Intell SysTems App (INISTA), V2021, P1, DOI [10.1109/INISTA52262.2021.9548419, DOI 10.1109/INISTA52262.2021.9548419]
   Pandey M, 2020, INT J SOFTW ENG KNOW, V30, P23, DOI 10.1142/S0218194020500023
   Pandey M, 2019, WIRELESS PERS COMMUN, V107, P1687, DOI 10.1007/s11277-019-06351-9
   Pandey P, 2020, IBM J RES DEV, V64, DOI 10.1147/JRD.2019.2947018
   Pandey P., 2019, PREDICTIVE FUZZY EXP, P175, DOI DOI 10.4018/978-1-5225-9175-7.CH010
   Pandey P., 2018, J Eur des Systemes Autom, V51, P203, DOI [10.3166/jesa.51.203-223, DOI 10.3166/JESA.51.203-223]
   Pandey P, 2019, J INTELL FUZZY SYST, V36, P2481, DOI 10.3233/JIFS-181146
   Parmar I, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P574, DOI 10.1109/ICSCCC.2018.8703332
   Paul Taraknath, 2021, 2021 International Conference on Artificial Intelligence and Computer Science Technology (ICAICST), P42, DOI 10.1109/ICAICST53116.2021.9497817
   Selvamuthu D, 2019, FINANC INNOV, V5, DOI 10.1186/s40854-019-0131-7
   Shao Guanlan, 2022, 2022 IEEE Conference on Telecommunications, Optics and Computer Science (TOCS), P319, DOI 10.1109/TOCS56154.2022.10016086
   Sharaf M, 2021, MULTIMED TOOLS APPL, V80, P17923, DOI 10.1007/s11042-021-10579-8
   Singh T, 2023, EVOL SYST-GER, V14, P919, DOI 10.1007/s12530-022-09481-x
   Sisodia PS, 2022, 2022 2 INT C INN PRA, P156
   Soner S, 2022, WIRELESS PERS COMMUN, V125, P3001, DOI 10.1007/s11277-022-09695-x
   Soner S, 2021, WIRELESS PERS COMMUN, V121, P2495, DOI 10.1007/s11277-021-08833-1
   Tuarob S, 2021, FINANC INNOV, V7, DOI 10.1186/s40854-021-00269-7
   Vij A, 2021, 2021 9 INT C REL INF, P1, DOI [10.1109/ICRITO51393.2021.9596513, DOI 10.1109/ICRITO51393.2021.9596513]
   Xuefei Kan, 2020, 2020 2nd International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI), P182, DOI 10.1109/MLBDBI51377.2020.00040
   Yick C, 2017, Tiingo python
   Yulian Wen, 2020, IOP Conference Series: Materials Science and Engineering, V790, DOI 10.1088/1757-899X/790/1/012109
   Zang YZ, 2019, 5TH INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM 2019), P248, DOI [10.1109/infoman.2019.8714662, 10.1109/INFOMAN.2019.8714662]
NR 46
TC 0
Z9 0
U1 10
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 18
PY 2023
DI 10.1007/s11042-023-17130-x
EA DEC 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CO5S9
UT WOS:001126208400004
DA 2024-07-18
ER

PT J
AU Kumar, M
   Patel, AK
   Biswas, M
AF Kumar, Manoj
   Patel, Anoop Kumar
   Biswas, Mantosh
TI Real-time detection of abnormal human activity using deep learning and
   temporal attention mechanism in video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Abnormal human activity; Bidirectional long short-term memory; CNN;
   Attention mechanism
ID NEURAL-NETWORK; OPTICAL-FLOW; RECOGNITION; FUSION; LSTM
AB In the modern era of technology, monitoring and controlling abnormal human activity is essentially required as these activities may harm society through physical harm to a human being, or by spreading hate crimes on the World Wide Web. Although many authors have contributed to address this problem, a desired solution that may work in a real-time scenario has yet to be achieved. Recently, deep learning models have gained attraction as processing power for a large volume of data. However, there is little work based on deep learning models for detecting abnormal human activity classification that has been done till now. In the proposed framework, a deep-learning method has been used to detect abnormal human activity by combining a convolutional neural network (CNN), a Recurrent Neural Network (RNN), and an attention module for attending the specific spatiotemporal characteristics from unprocessed video streams. This proposed architecture can accurately classify an aberrant human activity with its special category after processing the video. The proposed architecture's analytical results show an accuracy of 96.94%, 98.95%, and 62.04% with UCF50, UCF110, and UCF crime datasets, which is compared with the results of state-of-the-art algorithms (SOTA).
C1 [Kumar, Manoj] JSS Acad Tech Educ, Noida, India.
   [Kumar, Manoj; Patel, Anoop Kumar; Biswas, Mantosh] Natl Inst Technol, Kurukshetra, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Kumar, M (corresponding author), JSS Acad Tech Educ, Noida, India.; Kumar, M (corresponding author), Natl Inst Technol, Kurukshetra, India.
EM manoj3534@gmail.com; akp@nitkkr.ac.in; mantoshbiswas@nitkkr.ac.in
RI KUMAR, MANOJ/ADH-0406-2022
OI KUMAR, MANOJ/0000-0001-5259-4208
CR Ali B, 2021, IEEE INTERNET THINGS, V8, P3822, DOI 10.1109/JIOT.2020.3024823
   Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4
   Baisware A, 2019, INT CONF EMERG TR, DOI 10.1109/icetet-sip-1946815.2019.9092193
   Dai C, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105820
   Dai C, 2019, IEEE NETWORK, V33, P206, DOI 10.1109/MNET.2019.1800310
   Geng C, 2016, ACSR ADV COMPUT, V42, P933
   Gharaee Z, 2017, APPL SOFT COMPUT, V59, P574, DOI 10.1016/j.asoc.2017.06.007
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   He CM, 2023, PROC CVPR IEEE, P22046, DOI 10.1109/CVPR52729.2023.02111
   He CM, 2023, Arxiv, DOI arXiv:2305.11003
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hussain T, 2022, IEEE COMPUT SOC CONF, P2877, DOI 10.1109/CVPRW56347.2022.00325
   Ibrahim MS, 2016, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2016.217
   Idrees H, 2017, COMPUT VIS IMAGE UND, V155, P1, DOI 10.1016/j.cviu.2016.10.018
   Jaouedi N, 2020, J KING SAUD UNIV-COM, V32, P447, DOI 10.1016/j.jksuci.2019.09.004
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Keshavarzian A, 2019, FUTURE GENER COMP SY, V101, P14, DOI 10.1016/j.future.2019.06.009
   Khemchandani R, 2016, APPL SOFT COMPUT, V47, P33, DOI 10.1016/j.asoc.2016.05.025
   Kumar M., 2023, Springer Proc. Math. Stat, V417, P305
   Kumar M., 2022, Jisuanji Jicheng Zhizao Xitong/Computer Integr Manuf Syst CIMS, V28, P105, DOI [10.24297/j.cims.2022.11.008, DOI 10.24297/J.CIMS.2022.11.008]
   Kumar M, 2021, Solid State Technology, V64, P6489
   Kumar M, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15904-x
   Latah M, 2017, Int J Adv Intell Informatics, V3, P47, DOI [10.26555/ijain.v3i1.89, DOI 10.26555/IJAIN.V3I1.89]
   Li YN, 2019, PATTERN RECOGN LETT, V119, P187, DOI 10.1016/j.patrec.2017.12.003
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu Y, 2022, IEEE T IMAGE PROCESS, V31, P6719, DOI 10.1109/TIP.2022.3215887
   Liu Y, 2020, IEEE T IMAGE PROCESS, V29, P360, DOI 10.1109/TIP.2019.2930906
   Meng B, 2018, MULTIMED TOOLS APPL, V77, P26901, DOI 10.1007/s11042-018-5893-9
   Muhammad K, 2021, FUTURE GENER COMP SY, V125, P820, DOI 10.1016/j.future.2021.06.045
   Nawaratne R, 2020, IEEE T IND INFORM, V16, P7756, DOI 10.1109/TII.2019.2957454
   Patel CI, 2018, COMPUT ELECTR ENG, V70, P284, DOI 10.1016/j.compeleceng.2016.06.004
   Rodrigues R, 2020, IEEE WINT CONF APPL, P2615, DOI [10.1109/WACV45572.2020.9093633, 10.1109/wacv45572.2020.9093633]
   Sak H, 2014, INTERSPEECH, P338
   Shi Y, 2015, P IEEE INT C MULT EX, DOI [10.1109/ICME.2015.7177461, DOI 10.1109/ICME.2015.7177461]
   Sikder N, 2021, 2021 JT 10 INT C INF, DOI [10.1109/ICIEVICIVPR52578.2021.9564234, DOI 10.1109/ICIEVICIVPR52578.2021.9564234]
   Singh D, 2017, PATTERN RECOGN, V65, P265, DOI 10.1016/j.patcog.2017.01.001
   Spolaôr N, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103557
   Sun L, 2020, IEEE IMAGE PROC, P2121, DOI 10.1109/ICIP40778.2020.9191072
   Ullah A, 2019, IEEE T IND ELECTRON, V66, P9692, DOI 10.1109/TIE.2018.2881943
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wu JZ, 2014, IEEE T MULTIMEDIA, V16, P147, DOI 10.1109/TMM.2013.2283846
   Zhang XF, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107394
   Zhang YG, 2018, J VIS COMMUN IMAGE R, V55, P215, DOI 10.1016/j.jvcir.2018.06.006
   Zhao SC, 2018, IEEE T CIRC SYST VID, V28, P1839, DOI 10.1109/TCSVT.2017.2682196
NR 44
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 5
PY 2023
DI 10.1007/s11042-023-17748-x
EA DEC 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8R0
UT WOS:001121582900007
DA 2024-07-18
ER

PT J
AU Ou, JC
   Li, WY
   Huang, JB
AF Ou, Jichu
   Li, Wanyi
   Huang, Jinbin
TI Frequency-domain enhanced bi-directional recurrent quantum network for
   stock price trend prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Stock price trend prediction; Frequency-domain; Quantum computation;
   Deep learning; Multistep prediction
ID MODEL; LSTM; ARIMA
AB Stock price trend prediction is the focus of academics and economists. Selecting appropriate forecasting techniques can help investors to avoid potential financial risks in some extent, and help to determine the future volatility of assets. However, financial time series signals are characterized by non-stationary, long memory and low signal-to-noise ratio, which make it difficult to be forecasted. In order to address the issue, a frequency-domain enhanced bi-directional recurrent quantum network (FDBRQ) is proposed in this paper, which takes into account the influence of external factors and is able to achieve multistep prediction. In the model, a frequency-domain embedding module (FDEM) is used to extract the frequency-domain features of the price series and convert the input stock price time series data into embedding vectors. And we introduce the external feature attention enhancement (EFAE), which utilizes external factor data to enhance the representation of the embedding vectors. To enhance the interpretation of stock price time series and improve the prediction accuracy, a quantum neural network with bi-directional recurrent structure is designed to capture the long-term dependence of the financial time series. The network is built by quantum circuit units (QCUs), and each QCU processes the embedding vector at each time step. Finally, the model outputs the predicted value for multiple future time steps through the fully connected layer, aiming to provide investors with a useful basis for decisions. Experimental results show that our proposed method outperforms other models on the four stock datasets from Chinese stock market.
C1 [Ou, Jichu; Huang, Jinbin] Guangdong Univ Educ, Sch Math, Guangzhou 510303, Peoples R China.
   [Li, Wanyi] Guangdong Univ Educ, Sch Comp Sci, Guangzhou 510303, Peoples R China.
   [Ou, Jichu] Shandong Univ Sci & Technol, Coll Econ & Management, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology
RP Li, WY (corresponding author), Guangdong Univ Educ, Sch Comp Sci, Guangzhou 510303, Peoples R China.
EM oujichu@163.com; luther1212@163.com; shuguang1012@163.com
OI Li, Wanyi/0000-0002-8048-7538
FU Educational Science Planning Project of Guangdong Province; Science and
   Technology Plan Project of Guangzhou [202002030232]; Collaborative
   Project for the Development of Philosophy and Social Science in
   Guangzhou in 14th Five-Year Plan [2023GZGJ171]; Special Support Program
   for Cultivating High-Level Talents of Guangdong University of Education
   [2022];  [2022GXJK073]
FX This work was supported in part by the Educational Science Planning
   Project of Guangdong Province (No. 2022GXJK073), in part by the Science
   and Technology Plan Project of Guangzhou (No. 202002030232), in part by
   the Collaborative Project for the Development of Philosophy and Social
   Science in Guangzhou in 14th Five-Year Plan (No. 2023GZGJ171), and in
   part by the Special Support Program for Cultivating High-Level Talents
   of Guangdong University of Education (2022 Outstanding Young Teacher
   Cultivation Object: Wanyi Li).
CR Adebiyi AA, 2014, UKSIM INT CONF COMP, P106, DOI 10.1109/UKSim.2014.67
   Alchieri L, 2021, QUANT MACH INTELL, V3, DOI 10.1007/s42484-021-00056-8
   Ba J. L., 2016, LAYER NORMALIZATION, DOI DOI 10.48550/ARXIV.1607.06450
   BALDAUF B, 1991, J FUTURES MARKETS, V11, P191, DOI 10.1002/fut.3990110206
   Banik S, 2022, KNOWL-BASED SYST, V239, DOI 10.1016/j.knosys.2021.107994
   BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   BOLLERSLEV T, 1986, J ECONOMETRICS, V31, P307, DOI 10.1016/0304-4076(86)90063-1
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Cao J, 2019, PHYSICA A, V519, P127, DOI 10.1016/j.physa.2018.11.061
   Chakraborty S., 2020, 2020 5 INT C COMM EL, P1395
   Chen JD, 2023, ENG APPL ARTIF INTEL, V121, DOI 10.1016/j.engappai.2023.106038
   Chen L, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD 2019), P113, DOI [10.1109/icaibd.2019.8837038, 10.1109/ICAIBD.2019.8837038]
   Cheng YX, 2022, SOFT COMPUT, V26, P8537, DOI 10.1007/s00500-022-07276-5
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   Dragomiretskiy K, 2014, IEEE T SIGNAL PROCES, V62, P531, DOI 10.1109/TSP.2013.2288675
   ENGLE RF, 1982, ECONOMETRICA, V50, P987, DOI 10.2307/1912773
   Gao ZB, 2023, N AM J ECON FINANC, V66, DOI 10.1016/j.najef.2023.101915
   Gilles J, 2013, IEEE T SIGNAL PROCES, V61, P3999, DOI 10.1109/TSP.2013.2265222
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gu QH, 2021, APPL SOFT COMPUT, V109, DOI 10.1016/j.asoc.2021.107472
   Gülmez B, 2023, EXPERT SYST APPL, V227, DOI 10.1016/j.eswa.2023.120346
   HAMAO Y, 1990, REV FINANC STUD, V3, P281, DOI 10.1093/rfs/3.2.281
   Hameroff S, 1996, MATH COMPUT SIMULAT, V40, P453, DOI 10.1016/0378-4754(96)80476-9
   Hansun S, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00495-x
   Hassan R, 2005, 5TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, PROCEEDINGS, P192
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Houssein EH, 2022, EXPERT SYST APPL, V194, DOI 10.1016/j.eswa.2022.116512
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Ismail MS, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106422
   Jenkins G M., 1976, Holden-Day, V37, P238
   Khashei M, 2019, COMMUN STAT-SIMUL C, V48, P2625, DOI 10.1080/03610918.2018.1458138
   Kingma D. P., 2014, arXiv
   Kumar K, 2021, NEW GENERAT COMPUT, V39, P231, DOI 10.1007/s00354-020-00104-0
   Li XT, 2020, NEURAL COMPUT APPL, V32, P1765, DOI 10.1007/s00521-019-04566-2
   Lu RC, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5694975
   Najeeb SF, 2015, EMERG MARK FINANC TR, V51, P188, DOI 10.1080/1540496X.2015.1011531
   Narendra Babu C., 2015, Applied Computing and Informatics, V11, P130, DOI 10.1016/j.aci.2014.09.002
   Ni LP, 2011, EXPERT SYST APPL, V38, P5569, DOI 10.1016/j.eswa.2010.10.079
   Nokeri T. C., 2021, APRESS, P21, DOI DOI 10.1007/978-1-4842-7110-0_2
   Pai PF, 2005, OMEGA-INT J MANAGE S, V33, P497, DOI 10.1016/j.omega.2004.07.024
   Paluch M, 2015, C HUM SYST INTERACT, P238, DOI 10.1109/HSI.2015.7170673
   Perus M, 1996, Informatica (Slovenia), P20
   Quadir MA, 2023, APPL SOFT COMPUT, V134, DOI 10.1016/j.asoc.2022.109830
   Ruslan S.M.M., 2021, J. Econ. Asymmetries, V24, pe00232, DOI [10.1016/j.jeca.2021.e00232, DOI 10.1016/J.JECA.2021.E00232]
   Sadorsky P, 2022, N AM J ECON FINANC, V61, DOI 10.1016/j.najef.2022.101705
   Saha S, 2021, P INT C PARADIGMS CO, P987
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shi Y, 2024, INT J MACH LEARN CYB, V15, P161, DOI 10.1007/s13042-023-01817-6
   Teng X, 2022, NEUROCOMPUTING, V505, P92, DOI 10.1016/j.neucom.2022.07.016
   Torres ME, 2011, INT CONF ACOUST SPEE, P4144
   Vantuch T., 2015, Sanayei A, E, P239
   Vaziri J, 2023, NEURAL COMPUT APPL, V35, P18445, DOI 10.1007/s00521-023-08669-9
   Wu JMT, 2023, MULTIMEDIA SYST, V29, P1751, DOI 10.1007/s00530-021-00758-w
   Wu MT, 2013, 2013 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM DESIGN AND ENGINEERING APPLICATIONS (ISDEA), P1526, DOI 10.1109/ISDEA.2012.366
   Xia DW, 2022, MULTIMED TOOLS APPL, V81, P23589, DOI 10.1007/s11042-022-12039-3
NR 60
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 27
PY 2023
DI 10.1007/s11042-023-17620-y
EA NOV 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8T3
UT WOS:001121585200001
DA 2024-07-18
ER

PT J
AU Abhadiomhen, SE
   Shen, XJ
   Song, HP
   Tian, SR
AF Abhadiomhen, Stanley Ebhohimhen
   Shen, Xiang-Jun
   Song, Heping
   Tian, Sirui
TI Image edge preservation via low-rank residuals for robust subspace
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Low-rank representation; Dimensionality reduction; Manifold learning;
   Edge preservation; Residual learning
ID DISCRIMINANT-ANALYSIS; RECOGNITION; EIGENFACES
AB In order to maintain low-rank characteristics, existing low-rank representation methods concentrate on capturing data's low-frequency signals, which are presumed to be the global data structure, and they delete the high ones, which are often a combination of corrupt elements and image edges. Such inefficient preservation of image edges could hamper discriminative details in images, especially in heavy corruptions. This paper proposes a new method, which preserves image edges by finding robust subspace projections from low-rank residuals. It is achieved through a least square minimization of the discrepancy between similar residuals in a manifold learning framework. Edge preserved subspace projections are learned from such residuals by reducing the influence of corrupt ones using a dynamic affinity graph regularization. Furthermore, through our adaptive learning approach, the proposed method can jointly find image intrinsic low-rank representation. Several experimental results in classification and clustering tasks demonstrate the proposed method's effectiveness over state-of-the-art (SOTA) methods.
C1 [Abhadiomhen, Stanley Ebhohimhen; Shen, Xiang-Jun; Song, Heping] JiangSu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Abhadiomhen, Stanley Ebhohimhen] Univ Nigeria, Dept Comp Sci, Nsukka, Nigeria.
   [Tian, Sirui] Nanjing Univ Sci & Technol, Sch Elect & Opt Engn, Dept Elect Engn, Nanjing, Peoples R China.
C3 Jiangsu University; University of Nigeria; Nanjing University of Science
   & Technology
RP Shen, XJ (corresponding author), JiangSu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
EM stanley.abhadiomhen@unn.edu.ng; xjshen@ujs.edu.cn
RI Abhadiomhen, Stanley Ebhohimhen/AAH-5788-2021
OI Abhadiomhen, Stanley Ebhohimhen/0000-0002-9509-1915
FU National Natural Science Foundation of China [41930110]; Key Program of
   National Natural Science Foundations of China
FX This research was funded in part by the Key Program of National Natural
   Science Foundations of China under Grant No. 41930110.
CR Abhadiomhen SE, 2022, APPL INTELL, V52, P530, DOI 10.1007/s10489-021-02409-z
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Benyong SXLBL, 2005, Comput Eng Appl, V27
   Böttcher A, 2008, LINEAR ALGEBRA APPL, V429, P1864, DOI 10.1016/j.laa.2008.05.020
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Ching WK, 2012, PATTERN RECOGN, V45, P2719, DOI 10.1016/j.patcog.2012.01.007
   Dai DQ, 2003, PATTERN RECOGN, V36, P845, DOI 10.1016/S0031-3203(02)00092-4
   Doorsamy W, 2023, NEURAL COMPUT APPL, V35, P1099, DOI 10.1007/s00521-020-05668-y
   Feng YY, 2021, Complexity 2021
   Fu ZQ, 2021, PROC CVPR IEEE, P5316, DOI 10.1109/CVPR46437.2021.00528
   Ge ZQ, 2009, CHEM ENG SCI, V64, P2245, DOI 10.1016/j.ces.2009.01.050
   Gholamy A., 2018, UTEPCS1809
   Gordon G., 2012, Optimization, V10, P725
   Guo YQ, 2007, BIOSTATISTICS, V8, P86, DOI 10.1093/biostatistics/kxj035
   Hajipour K, 2021, MULTIMED TOOLS APPL, V80, P5067, DOI 10.1007/s11042-020-09942-y
   He XF, 2004, ADV NEUR IN, V16, P153
   Hong MY, 2017, MATH PROGRAM, V162, P165, DOI 10.1007/s10107-016-1034-2
   Hosseini M, 2020, NEUROSCI BIOBEHAV R, V119, P456, DOI 10.1016/j.neubiorev.2020.09.036
   Hui KF, 2022, KNOWL-BASED SYST, V241, DOI 10.1016/j.knosys.2022.108230
   Indyk P, 2007, ACM T ALGORITHMS, V3, DOI 10.1145/1273340.1273347
   Jiang L, 2023, SIGNAL PROCESS, V204, DOI 10.1016/j.sigpro.2022.108817
   Li XP, 2023, IEEE Trans Neural Netw Learn Syst
   Lim DH, 2006, COMPUT STAT DATA AN, V50, P803, DOI 10.1016/j.csda.2004.10.005
   Lin Z., 2013, arXiv, DOI DOI 10.48550/ARXIV.1009.5055
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422
   Liu ZH, 2019, IEEE ACCESS, V7, P22941, DOI 10.1109/ACCESS.2019.2893915
   Lu GF, 2016, NEURAL PROCESS LETT, V43, P687, DOI 10.1007/s11063-015-9441-6
   Luo C, 2014, Open Automat Control Syst J, V6
   Nindrea Ricvan Dana, 2018, Asian Pac J Cancer Prev, V19, P1747, DOI 10.22034/APJCP.2018.19.7.1747
   Shen XJ, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107023
   Solgi A, 2017, J EARTH SYST SCI, V126, DOI 10.1007/s12040-017-0850-y
   Tang C, 2020, IEEE T KNOWL DATA EN, V32, P1747, DOI 10.1109/TKDE.2019.2911946
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wan MH, 2023, PATTERN RECOGN, V133, DOI 10.1016/j.patcog.2022.109034
   Wang HX, 2012, PATTERN RECOGN LETT, V33, P537, DOI 10.1016/j.patrec.2011.11.029
   Wang Z, 2021, IEEE T MULTIMEDIA, V23, P1855, DOI 10.1109/TMM.2020.3003747
   Wang ZY, 2021, IET IMAGE PROCESS, V15, P3573, DOI 10.1049/ipr2.12232
   Wen JJ, 2016, PATTERN RECOGN, V60, P515, DOI 10.1016/j.patcog.2016.06.006
   Wen J, 2020, IEEE T CYBERNETICS, V50, P1418, DOI 10.1109/TCYB.2018.2884715
   Wen J, 2019, IEEE T CYBERNETICS, V49, P1279, DOI 10.1109/TCYB.2018.2799862
   Wong WK, 2017, IEEE T IMAGE PROCESS, V26, P2905, DOI 10.1109/TIP.2017.2691543
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xie LF, 2018, IEEE T IMAGE PROCESS, V27, P5261, DOI 10.1109/TIP.2018.2855426
   Xu Y, 2010, PATTERN RECOGN, V43, P1106, DOI 10.1016/j.patcog.2009.09.013
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Zafeiriou S, 2012, IEEE T NEUR NET LEAR, V23, P526, DOI 10.1109/TNNLS.2011.2182058
   Zhang YMZ, 2013, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2013.93
   Zhang YP, 2017, PATTERN RECOGN, V70, P112, DOI 10.1016/j.patcog.2017.05.003
   Zhou J., 2022, IEEE Trans Knowl Data Eng, P1
   Zhou T, 2020, IEEE T CYBERNETICS, V50, P3517, DOI 10.1109/TCYB.2019.2918495
NR 51
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 23
PY 2023
DI 10.1007/s11042-023-17423-1
EA NOV 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AX8H4
UT WOS:001121833800004
DA 2024-07-18
ER

PT J
AU Singh, J
   Sharma, D
AF Singh, Jaiteg
   Sharma, Deepika
TI Automated detection of mental disorders using physiological signals and
   machine learning: A systematic review and scientometric analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Mental disorder; Machine learning; Physiological signals; Scientometric
   analysis; Modalities; Mental health
ID STRESS DETECTION; EEG; RECOGNITION; CLASSIFICATION; EXPRESSIONS;
   FRAMEWORK; NETWORK; HEALTH
AB Anomalies in mood, thinking, work, bodily functions, emotions, social interactions, and general behavior are frequently related to mental disorders. A strong correlation has been found between affective disorders, mental illnesses, and physiological reactions from the brain, muscles, heart, eyes, and skin. Understanding multidisciplinary open research challenges, including the combination of behavioral sciences, computer science, machine learning, psychology, and sociology, could potentially reveal new interdisciplinary research domains. In the purview of previously stated arguments, this study intends to investigate the physiological and behavioral signals could be used for machine learning-based detection of mental disorders. Subsequently, identification of machine learning algorithms to exploit these modalities for detecting mental disorders were studied. This study presents a systematic literature review to promulgate state-of-the-art computational methods and technologies facilitating the automated detection of affective disorders. The relevant literature between 2010 and 2022 has been studied for this survey. Recommendations of Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) model were adopted for the identification, screening, validating, and inclusion of research literature. The study concluded the fact that self-diagnosis tools for detecting mental disorders, like questionnaires and rating scales, produce inconsistent results. Further, there are no standard baselines for mental disorders. This situation mandates a multi-faceted approach that may utilize physiological signals, behavioral patterns, and even data obtained from various online portals like social media to efficiently and effectively detect mental disorders' prevalence, type, and severity.
C1 [Singh, Jaiteg; Sharma, Deepika] Chitkara Univ, Inst Engn & Technol, Patiala 140401, Punjab, India.
C3 Chitkara University, Punjab
RP Singh, J (corresponding author), Chitkara Univ, Inst Engn & Technol, Patiala 140401, Punjab, India.
EM jaitegkhaira@gmail.com
OI Singh, Jaiteg/0000-0002-2370-9384
FU None.
FX None.
CR Abdolzadegan D, 2020, BIOCYBERN BIOMED ENG, V40, P482, DOI 10.1016/j.bbe.2020.01.008
   Acharya UR, 2012, BIOMED SIGNAL PROCES, V7, P401, DOI 10.1016/j.bspc.2011.07.007
   Ahmed IA, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11040530
   Ahmedani Brian K, 2011, J Soc Work Values Ethics, V8, P41
   Ahn JW, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19091991
   Akbulut FP, 2020, ARTIF INTELL MED, V104, DOI 10.1016/j.artmed.2020.101824
   Almeida J, 2021, PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS (ICEIS 2021), VOL 1, P256, DOI 10.5220/0010474202560263
   Alotaiby TN, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-183
   [Anonymous], 2017, Cc By-Nc-Sa 3.0 Igo, P24
   [Anonymous], 2018, arXiv:1805.02397
   Aqajari S. A. H., 2020, arXiv preprint arXiv:2005.01834, DOI [DOI 10.48550/ARXIV.2005.01834, 10.48550/arxiv.2005.01834]
   Arango C, 2018, LANCET PSYCHIAT, V5, P591, DOI 10.1016/S2215-0366(18)30057-9
   Arya R, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100399
   Ay B, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1345-y
   Bae HB, 2019, NEUROCOMPUTING, V360, P198, DOI 10.1016/j.neucom.2019.06.031
   Bagirathan A, 2021, J AMB INTEL HUM COMP, V12, P405, DOI 10.1007/s12652-020-01985-1
   Balan O, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020496
   Bardram JE, 2020, IEEE PERVAS COMPUT, V19, P62, DOI 10.1109/MPRV.2019.2925338
   Baygin M, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.102936
   Berle Jan O, 2010, BMC Res Notes, V3, P149, DOI 10.1186/1756-0500-3-149
   Bota PJ, 2019, IEEE ACCESS, V7, P140990, DOI 10.1109/ACCESS.2019.2944001
   Cardone D, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10165673
   Castellano G, 2008, LECT NOTES COMPUT SC, V4868, P92, DOI 10.1007/978-3-540-85099-1_8
   Chandran A N., 2021, Advances in machine learning and computational intelligence, P229
   Chang HA, 2014, PSYCHIAT CLIN NEUROS, V68, P674, DOI 10.1111/pcn.12178
   Chao LL, 2015, INT CONF AFFECT, P526, DOI 10.1109/ACII.2015.7344620
   Chen H, 2019, NEUROCOMPUTING, V356, P83, DOI 10.1016/j.neucom.2019.04.058
   Chen J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041030
   Chen J, 2015, IEEE INT C BIOINFORM, P395, DOI 10.1109/BIBM.2015.7359713
   Chen XT, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P3320
   Corrigan PW, 2017, Oxford Handb. Stigma, Discrim. Heal, P413, DOI [10.1093/oxfordhb/9780190243470.001.0001, DOI 10.1093/OXFORDHB/9780190243470.001.0001]
   Critchley HD, 2018, CURR OPIN BEHAV SCI, V19, P13, DOI 10.1016/j.cobeha.2017.08.014
   Crocq Marc-Antoine, 2003, Dialogues Clin Neurosci, V5, P175
   Cuijpers P, 2014, AUST NZ J PSYCHIAT, V48, P481, DOI 10.1177/0004867414525846
   de Belen RAJ, 2020, TRANSL PSYCHIAT, V10, DOI 10.1038/s41398-020-01015-w
   de Melo WC, 2022, IEEE T AFFECT COMPUT, V13, P1581, DOI 10.1109/TAFFC.2020.3021755
   Delmastro F, 2020, IEEE ACCESS, V8, P65573, DOI 10.1109/ACCESS.2020.2985301
   Dev A, 2022, IEEE ACCESS, V10, P16756, DOI 10.1109/ACCESS.2022.3146711
   Ding XF, 2019, J AFFECT DISORDERS, V251, P156, DOI 10.1016/j.jad.2019.03.058
   Ding Y, 2020, ERGONOMICS, V63, P896, DOI 10.1080/00140139.2020.1759699
   Djemal R, 2017, BIOMED RES INT-UK, V2017, DOI 10.1155/2017/9816591
   Doernberg E, 2016, CNS SPECTRUMS, V21, P295, DOI 10.1017/S1092852916000262
   Elahi Md Toufick E., 2019, 3rd International Conference on Electrical, Computer & Telecommunication Engineering (ICECTE 2019), P33, DOI 10.1109/ICECTE48615.2019.9303564
   Erguzel TT, 2016, NEURAL COMPUT APPL, V27, P1607, DOI 10.1007/s00521-015-1959-z
   Faust O, 2018, COMPUT METH PROG BIO, V161, P1, DOI 10.1016/j.cmpb.2018.04.005
   Fei ZX, 2020, NEUROCOMPUTING, V388, P212, DOI 10.1016/j.neucom.2020.01.034
   Garcia-Ceja E, 2018, PERVASIVE MOB COMPUT, V51, P1, DOI 10.1016/j.pmcj.2018.09.003
   Giannakakis G, 2019, 2019 8TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION WORKSHOPS AND DEMOS (ACIIW), P269, DOI 10.1109/ACIIW.2019.8925142
   Girard JM, 2013, IEEE INT CONF AUTOMA
   Gorbova J, 2019, MULTIMED TOOLS APPL, V78, P23161, DOI 10.1007/s11042-019-7658-5
   Gowda SH., 2021, Int J Sci Res Eng Trends, V7, P3605
   Haque A., 2018, MEASURING DEPRESSION, DOI DOI 10.48550/ARXIV.1811.08592
   Houssein EH, 2022, NEURAL COMPUT APPL, V34, P12527, DOI 10.1007/s00521-022-07292-4
   Huang W, 2021, TRAIT SIGNAL, V38, P1123, DOI 10.18280/ts.380423
   Huang YR, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11050105
   Hussain I, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051896
   Jan Asim., 2014, Proceedings of the ACM 4th International Workshop on Audio/Visual Emotion Challenge, P73, DOI DOI 10.1145/2661806.2661812
   Jatupaiboon N, 2015, J MED IMAG HEALTH IN, V5, P1020, DOI 10.1166/jmihi.2015.1490
   Jayatilake SMDAC, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/6679512
   Kang JN, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103722
   Karthikeyan P, 2013, J MECH MED BIOL, V13, DOI 10.1142/S0219519413500383
   Kaur A, 2022, BRAIN SCI, V12, DOI 10.3390/brainsci12070831
   Ke PF, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-94007-9
   Keshan N, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2661, DOI 10.1109/BigData.2015.7364066
   Khare SK, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3070608
   Kim AY, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-35147-3
   Kollias KF, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10232982
   Kumar S, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15122907
   Kurniawan H, 2013, COMP MED SY, P209, DOI 10.1109/CBMS.2013.6627790
   Li BB, 2019, IEEE IMAGE PROC, P4549, DOI [10.1109/ICIP.2019.8803604, 10.1109/icip.2019.8803604]
   Li M, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/4174857
   Li XW, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.004
   Lin Q, 2021, J AMB INTEL HUM COMP, V12, P3329, DOI 10.1007/s12652-020-02650-3
   Liu XQ, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/8544750
   Liu Y, 2018, BEHAV BRAIN RES, V341, P50, DOI 10.1016/j.bbr.2017.12.021
   Mahato S, 2019, MICROSYST TECHNOL, V25, P1065, DOI 10.1007/s00542-018-4075-z
   Malhotra V, 2021, EAI ENDORSED TRANS S, V8, DOI 10.4108/eai.6-4-2021.169175
   McIntosh AM, 2016, LANCET PSYCHIAT, V3, P993, DOI 10.1016/S2215-0366(16)30089-X
   Moghaddari M, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105738
   Montag C, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/2983685
   Mporas I, 2015, EXPERT SYST APPL, V42, P3227, DOI 10.1016/j.eswa.2014.12.009
   Munsif M., Monitoring Neurological Disorder Patients via Deep Learning Based Facial Expressions Analysis, V2022, P412, DOI DOI 10.1007/978-3-031-08341-9_33
   Noor ST, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/1299870
   Onyema EM, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5196000
   Ooi JSK, 2016, IEEE EMBS CONF BIO, P365, DOI 10.1109/IECBES.2016.7843475
   Panicker SS, 2019, BIOCYBERN BIOMED ENG, V39, P444, DOI 10.1016/j.bbe.2019.01.004
   Panure T, 2019, Asian J Converg Technol, V05, P1, DOI [10.33130/ajct.2019v05i01.007, DOI 10.33130/AJCT.2019V05I01.007]
   Pinheiro M., 2017, Mental Health Economics, DOI DOI 10.1007/978-3-319-55266-8_28
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Pouromran F, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0254108
   Pustokhina IV, 2020, IEEE ACCESS, V8, P107112, DOI 10.1109/ACCESS.2020.3000322
   Rim B, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20040969
   Rivera MJ, 2022, ARTIF INTELL REV, V55, P1209, DOI 10.1007/s10462-021-09986-y
   Rosales MA, 2019, I C HUMANOID NANOTEC, DOI [10.1109/HNICEM48295.2019.9073355, 10.1109/hnicem48295.2019.9073355]
   Sadatnezhad K, 2011, EXPERT SYST APPL, V38, P1956, DOI 10.1016/j.eswa.2010.07.128
   Saeedi A, 2021, COGN NEURODYNAMICS, V15, P239, DOI 10.1007/s11571-020-09619-0
   Saffaryazdi N, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.864047
   Sandheep P, 2019, TENCON IEEE REGION, P1339, DOI [10.1109/TENCON.2019.8929254, 10.1109/tencon.2019.8929254]
   Sapiro G, 2018, Curr Opin Biomed Eng
   Sarchiapone M, 2018, BMC PSYCHIATRY, V18, DOI 10.1186/s12888-017-1551-4
   Schomerus G, 2015, EPIDEMIOL PSYCH SCI, V24, P166, DOI 10.1017/S2045796014000109
   Seal A, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3053999
   Shen XB, 2012, J ZHEJIANG UNIV-SC B, V13, P221, DOI 10.1631/jzus.B1100063
   Shoeibi A, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18115780
   Shukla P, 2017, IEEE WINT CONF APPL, P705, DOI 10.1109/WACV.2017.84
   Siddiqui Mohammad Khubeb, 2020, Brain Inform, V7, P5, DOI 10.1186/s40708-020-00105-1
   Singh J, 2022, COGN COMPUT, V14, P2169, DOI 10.1007/s12559-022-10042-2
   Singh J, 2021, MULTIMED TOOLS APPL, V80, P8189, DOI 10.1007/s11042-020-10128-9
   Singh J, 2020, ENTERP INF SYST-UK, V14, P243, DOI 10.1080/17517575.2019.1640392
   Singh J, 2019, MULTIMED TOOLS APPL, V78, P7207, DOI 10.1007/s11042-018-6412-8
   Siuly, 2011, COMPUT METH PROG BIO, V104, P358, DOI 10.1016/j.cmpb.2010.11.014
   Song TS, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P161, DOI 10.1145/3383972.3384003
   Sriamprakash S, 2017, PROCEDIA COMPUT SCI, V115, P359, DOI 10.1016/j.procs.2017.09.090
   Stein DJ, 2021, PSYCHOL MED, V51, P894, DOI 10.1017/S0033291721001185
   Suhaimi NS, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8875426
   Taghibeyglou B, 2020, IRAN CONF ELECTR ENG, DOI [10.1109/ICEE50131.2020.9260711, DOI 10.1109/icee50131.2020.9260711]
   Tandon Rajiv, 2014, Indian J Psychol Med, V36, P223, DOI 10.4103/0253-7176.135365
   Temko A, 2015, COMPUT BIOL MED, V63, P169, DOI 10.1016/j.compbiomed.2015.05.017
   Thoduparambil PP, 2020, PHYS ENG SCI MED, V43, P1349, DOI 10.1007/s13246-020-00938-4
   Trull TJ, 2018, BORDER PERS DIS EMOT, V5, DOI 10.1186/s40479-018-0093-9
   Vakadkar Kaushik, 2021, SN Comput Sci, V2, P386, DOI 10.1007/s42979-021-00776-5
   Valstar M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P3, DOI 10.1145/2988257.2988258
   Vandecasteele K, 2021, EPILEPSIA, V62, P2333, DOI 10.1111/epi.16990
   Wang ZX, 2020, MULTIMED TOOLS APPL, V79, P35553, DOI 10.1007/s11042-019-08328-z
   Wigham S, 2019, AUTISM, V23, P287, DOI 10.1177/1362361317748245
   Yolcu G, 2019, MULTIMED TOOLS APPL, V78, P31581, DOI 10.1007/s11042-019-07959-6
   Zhang PF, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11093838
   Zhang ZH, 2020, IEEE INT CONF AUTOMA, P344, DOI 10.1109/FG47880.2020.00033
   Zhao YX, 2023, IEEE T AFFECT COMPUT, V14, P1391, DOI 10.1109/TAFFC.2021.3093923
NR 129
TC 0
Z9 0
U1 7
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 10
PY 2023
DI 10.1007/s11042-023-17504-1
EA NOV 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9QP0
UT WOS:001101716100006
DA 2024-07-18
ER

PT J
AU Alam, MM
AF Alam, Md. Moddassir
TI An efficient random forest algorithm-based telemonitoring framework to
   predict mortality and length of stay of patients in ICU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Length of Stay; Mortality; Intensive Care Units; Machine Learning;
   Patient Monitoring System; Vulture Optimization; Random Forest
AB In all phases of care, patient monitoring is essential. In particular patient monitoring in Intensive Care Units (ICUs) can lower complications and morbidity while improving the standard of care by permitting hospitals to provide better-quality, more economical patient care. The creation and verification of ICU mortality and duration of stay prediction models. The Artificial Intelligent and Vulture based Remote Patient Monitoring (AIV-RPM) framework is proposed to track patients' health status and generates timely alerts, recommendations, or reports when dangerous medical conditions are anticipated. Additionally, pre-processing is employed to remove the noise and errors using Anisotropic Diffusion Filter Based Unsharp Masking and crispening (ADF-UMC). Extract the relevant features from the dataset using Grey-Level Co-Occurrence Matrix (GLCM). Moreover, update vulture fitness function in the RF classifier for accurate prediction of LOS and mortality in ICU. The experimental outcomes of the designed model were validated with other prevailing models. Finally, the designed model gained 98.04% accuracy, 99.8% precision, 99.9% sensitivity, 97.89% F1-Score, 99.63% specificity, and 99.89% AUC for 20 data file sizes. While comparing other models designed model gained 2% greater results while comparing others models.
C1 [Alam, Md. Moddassir] Univ Hafr Al Batin, Coll Appl Med Sci, Dept Hlth Informat Management & Technol, Hafar al Batin 39524, Saudi Arabia.
C3 Hafr Albatin University
RP Alam, MM (corresponding author), Univ Hafr Al Batin, Coll Appl Med Sci, Dept Hlth Informat Management & Technol, Hafar al Batin 39524, Saudi Arabia.
EM mmalam@uhb.edu.sa
RI Alam, Moddassir/AAW-2450-2020
FU The data that support the findings of this study are available on
   request.
FX The data that support the findings of this study are available on
   request.
CR Abd-Elrazek MA, 2021, AIN SHAMS ENG J, V12, P3691, DOI 10.1016/j.asej.2021.02.018
   Al Bassam Nizar, 2021, Inform Med Unlocked, V24, P100588, DOI 10.1016/j.imu.2021.100588
   Al-Dailami A, 2022, COMPUT BIOL MED, V151, DOI 10.1016/j.compbiomed.2022.106278
   Alabbad Dina A, 2022, Inform Med Unlocked, V30, P100937, DOI 10.1016/j.imu.2022.100937
   Alam MM, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111886
   Alam MdM, 2023, Comput Mater Continua, V75
   Alghatani K., 2019, P INT C HEALTH INF M
   Alghatani K, 2021, JMIR MED INF, V9, DOI 10.2196/21347
   Baskar D, 2021, 2021 6 INT C COMM EL
   Boussen S, 2022, COMPUT BIOL MED, V142, DOI 10.1016/j.compbiomed.2021.105192
   Chia AHT, 2021, Inform. Med. Unlock., V25, DOI [10.1016/j.imu.2021.100674, DOI 10.1016/J.IMU.2021.100674]
   Dhinakaran M, 2022, J FOOD QUALITY, V2022, DOI 10.1155/2022/6274092
   El-Rashidy N, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11040607
   Iwase S, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17091-5
   Kadri F, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-022-03717-z
   Kindle RD, 2019, CRIT CARE CLIN, V35, P483, DOI 10.1016/j.ccc.2019.02.005
   Kumar RR, 2020, 2020 INTERNATIONAL CONFERENCE ON EMERGING FRONTIERS IN ELECTRICAL AND ELECTRONIC TECHNOLOGIES (ICEFEET 2020)
   Kuo S, 2022, JAMIA OPEN, V5, DOI 10.1093/jamiaopen/ooac060
   Liu JL, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0246306
   Liu Y, 2022, INT J MED INFORM, V163, DOI 10.1016/j.ijmedinf.2022.104776
   Luo CD, 2022, J TRANSL MED, V20, DOI 10.1186/s12967-022-03340-8
   McAdams RM, 2022, J Perinatol, P1
   Motwani A, 2021, INF COMM TECHN INT S, V1
   Nie XM, 2021, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.610531
   Palimkar P, 2022, ADV COMP INT TECHN P
   Pourhomayoun Mohammad, 2021, Smart Health (Amst), V20, P100178, DOI 10.1016/j.smhl.2020.100178
   Raj R, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00652-3
   Rout S, 2022, INFORMATION, V13, DOI 10.3390/info13080386
   Salman OH, 2021, COMPUT METH PROG BIO, V209, DOI 10.1016/j.cmpb.2021.106357
   Shaik T, 2023, Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, P1485
   Sheikhalishahi S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0235424
   Un KC, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82771-7
   Wu WZ, 2023, COMPUT METH PROG BIO, V230, DOI 10.1016/j.cmpb.2022.107328
   Ye ZX, 2023, EUR J MED RES, V28, DOI 10.1186/s40001-023-00995-x
   Zou H, 2023, Heliyon
   Zubair AR, 2019, Int J Sci Eng Invest, V8, P64
NR 36
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 7
PY 2023
DI 10.1007/s11042-023-17239-z
EA NOV 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3TF7
UT WOS:001097705200012
DA 2024-07-18
ER

PT J
AU Iqbal, S
   Qureshi, AN
   Alhussein, M
   Aurangzeb, K
   Javeed, K
   Naqvi, RA
AF Iqbal, Saeed
   Qureshi, Adnan N.
   Alhussein, Musaed
   Aurangzeb, Khursheed
   Javeed, Khalid
   Ali Naqvi, Rizwan
TI Privacy-preserving collaborative AI for distributed deep learning with
   cross-sectional data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Federated Learning; Data Confidentiality; Data Privacy; Medical Image
   Analysis; Collaborative AI; Convolutional Neural Network
ID MELANOMA
AB Recent progress in Deep Learning (DL) has shown potential in intelligent healthcare applications, enhancing patients' quality of life. However, improving DL precision requires a larger and diverse dataset, leading to privacy and confidentiality challenges when consolidating data at a centralized server. To address this, we propose a skin cancer detection method prioritizing patient information and privacy. "Skin-net," a novel Convolutional Neural Network (CNN) model, integrates progressively private Federated Learning (FL) for accurate classification of complex skin lesion images. FL ensures data confidentiality during model training. Skin-net achieves promising results, with 98.3%+/- accuracy, 98.8%+/- sensitivity, and 97.9%+/- specificity, while preserving data privacy. It offers an effective pathway for skin cancer analysis and image augmentation, mitigating privacy concerns in medical image analysis.
C1 [Iqbal, Saeed; Qureshi, Adnan N.] Univ Cent Punjab, Fac Informat Technol & Comp Sci, Dept Comp Sci, Lahore 54000, Punjab, Pakistan.
   [Alhussein, Musaed; Aurangzeb, Khursheed] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Engn, POB 51178, Riyadh 11543, Saudi Arabia.
   [Javeed, Khalid] Univ Sharjah, Coll Comp & Informat, Dept Comp Engn, Sharjah 27272, U Arab Emirates.
   [Ali Naqvi, Rizwan] Sejong Univ, Intelligent Mechatron Engn, 209,Neungdong Ro,Gwangjin Gu, Seoul 05006, South Korea.
   [Qureshi, Adnan N.] Newman Univ, Fac Arts Soc & Profess Studies, Birmingham, England.
C3 University of Central Punjab; King Saud University; University of
   Sharjah; Sejong University; Birmingham Newman University
RP Iqbal, S (corresponding author), Univ Cent Punjab, Fac Informat Technol & Comp Sci, Dept Comp Sci, Lahore 54000, Punjab, Pakistan.
EM saeed.iqbal@ucp.edu.pk; a.qureshi@staff.newman.ac.uk; musaed@ksu.edu.sa;
   kaurangzeb@ksu.edu.sa; kjaveed@sharjah.ac.ae; rizwanali@sejong.ac.kr
RI Naqvi, Rizwan Ali/AAW-9242-2020; Aurangzeb, Khursheed/GWQ-3313-2022;
   Alhussein, Musaed/GYU-5641-2022
OI Alhussein, Musaed/0000-0002-5538-6778; Iqbal, Saeed/0000-0002-3176-4658
FU This Research is funded by Researchers Supporting Project Number
   (RSPD2023R947), King Saud University, Riyadh, Saudi Arabia.
   [RSPD2023R947]; King Saud University, Riyadh, Saudi Arabia
FX This Research is funded by Researchers Supporting Project Number
   (RSPD2023R947), King Saud University, Riyadh, Saudi Arabia.
CR Aggarwal R, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00438-z
   Ali ARA., 2012, Observer Performance, and Technology Assessment, V8318, P421
   [Anonymous], 2016, arXiv
   Bonawitz K., 2019, ARXIV190201046, V1, P374
   Castro PBC, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207552
   Habif TP, 2017, Skin Disease E-Book: Diagnosis and Treatment
   Heaton J, 2018, Genetic Programming and Evolvable Machines, V19, P305, DOI [10.1007/s10710-017-9314-z, DOI 10.1007/S10710-017-9314-Z]
   Howard A. G., 2017, arXiv
   Kaissis GA, 2020, NAT MACH INTELL, V2, P305, DOI 10.1038/s42256-020-0186-1
   Khan MQ, 2019, IEEE ACCESS, V7, P90132, DOI 10.1109/ACCESS.2019.2926837
   Kumar VB, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Li T, 2020, IEEE SIGNAL PROC MAG, V37, P50, DOI 10.1109/MSP.2020.2975749
   Lu SY, 2021, NEURAL COMPUT APPL, V33, P10799, DOI 10.1007/s00521-020-05082-4
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Mironov I, 2017, P IEEE CSFW, P263, DOI 10.1109/CSF.2017.11
   Mohan NJ, 2021, PHYS ENG SCI MED, V44, P1351, DOI 10.1007/s13246-021-01073-4
   Mooney SD, 2023, J APPL LAB MED, V8, P194, DOI 10.1093/jalm/jfac113
   Nishio T, 2019, IEEE ICC
   Oh W, 2023, ADV KIDNEY DIS HEAL, V30, P4, DOI 10.1053/j.akdh.2022.11.007
   Pennisi A, 2016, COMPUT MED IMAG GRAP, V52, P89, DOI 10.1016/j.compmedimag.2016.05.002
   Sattler F, 2020, IEEE T NEUR NET LEAR, V31, P3400, DOI 10.1109/TNNLS.2019.2944481
   Sheller MJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-69250-1
   Stern RS, 2010, ARCH DERMATOL, V146, P279, DOI 10.1001/archdermatol.2010.4
   Yan R, 2023, IEEE T MED IMAGING, V42, P1932, DOI 10.1109/TMI.2022.3233574
   Zafar M, 2023, LIFE-BASEL, V13, DOI 10.3390/life13010146
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 26
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 7
PY 2023
DI 10.1007/s11042-023-17202-y
EA NOV 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3TF7
UT WOS:001097705200004
DA 2024-07-18
ER

PT J
AU Mohammadi, Z
   Akhavanpour, A
   Rastgoo, R
   Sabokrou, M
AF Mohammadi, Zahra
   Akhavanpour, Alireza
   Rastgoo, Razieh
   Sabokrou, Mohammad
TI Diverse hand gesture recognition dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hand Gesture Recognition (HGR); Deep learning; Dataset; Hand Pose
   Estimation (HPE); Computer vision
ID SIGN-LANGUAGE RECOGNITION
AB Hand Gesture Recognition(HGR) is a challenging computer vision task. Recently, by taking advantages of deep learning-based models, HGR methods have achieved outstanding results and outperformed state-of-the-art alternatives by a high margin. However, the performance of deep learning-based models is highly dependent on the data. A large amount of data is required to train deep learning-based models. While there are some widely-used datasets in HGR, these datasets lack diverse gestures in real-world situations. To this end, we propose a hand gesture dataset (Dataset will be publicly available after paper publication.), including diverse gestures with more sample numbers per gesture class. Furthermore, we provide hand annotations, including a hand bounding box, 3D hand keypoints, and gesture label per sample. The proposed dataset aims to provide a benchmark for research works to tackle real-world situations. The dataset samples are recorded in a real-world background with high complexity and diversity. To be more realistic, the proposed dataset does not include any pre-processing step. All of the samples in this dataset are pure and real. This configuration makes room to underpin future research works in a real-world situation and develop gesture recognition models in an unrestricted environment. Overall, our dataset outperforms in terms of diversity, number of subjects, number of samples per gesture class, and use of real data. Finally, different analysis on the existing state-of-the-art models in HGR, HPE, hand recovery, and hand reconstruction were performed and reported. Our implementation is available at https://github.com/smohammadi96/Diverse_hand_gesture_dataset/blob/main/README.md.
C1 [Mohammadi, Zahra] Shahid Beheshti Univ, Comp Sci & Engn Dept, Tehran 1983969411, Iran.
   [Akhavanpour, Alireza] Shenasa, Artificial Intelligence Grp, Tehran 1456755131, Iran.
   [Rastgoo, Razieh] Semnan Univ, Elect & Comp Engn Dept, Semnan 3513119111, Iran.
   [Sabokrou, Mohammad] Inst Res Fundamental Sci IPM, Tehran 193955746, Iran.
C3 Shahid Beheshti University; Semnan University
RP Rastgoo, R (corresponding author), Semnan Univ, Elect & Comp Engn Dept, Semnan 3513119111, Iran.
EM s.mohammadi@shenasa.ai; akhavan@shenasa.ai; rrastgoo@semnan.ac.ir;
   sabokro@ipm.ir
RI Sabokrou, Mohammad/AAI-3766-2020; Rastgoo, Razieh/AFO-9957-2022
OI Rastgoo, Razieh/0000-0001-7963-9461
CR Adarsh P, 2020, INT CONF ADVAN COMPU, P687, DOI [10.1109/icaccs48705.2020.9074315, 10.1109/ICACCS48705.2020.9074315]
   Adthya V., 2020, Procedia Computer Science, V171, P2353, DOI 10.1016/j.procs.2020.04.255
   Alani AA, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM2018), P5, DOI 10.1109/INFOMAN.2018.8392660
   Ameen S, 2016, Wiley Expert Systems
   Baek S, 2018, PROC CVPR IEEE, P8330, DOI 10.1109/CVPR.2018.00869
   Benitez-Garcia G.., 2020, Ipn hand: A video dataset and benchmark for real-time continuous hand gesture recognition
   Blinded, 2021, Hand gesture recognition
   Bloom V, 2012, COMP SOC C COMP VIS
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen XH, 2020, NEUROCOMPUTING, V395, P138, DOI 10.1016/j.neucom.2018.06.097
   Chen Yi-Wen, 2019, ARXIV191004748
   Chen YF, 2020, IEEE WINT CONF APPL, P370, DOI [10.1109/WACV45572.2020.9093271, 10.1109/wacv45572.2020.9093271]
   Cooper H, 2012, J MACH LEARN RES, V13, P2205
   Cui RP, 2019, IEEE T MULTIMEDIA, V21, P1880, DOI 10.1109/TMM.2018.2889563
   Dadashzadeh A, 2018, arXiv
   Damaneh MM, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118559
   Dibia V., 2017, GitHub repository
   dos Santos CC, 2019, arXiv
   Duan J., 2016, arXiv
   Elboushaki A, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112829
   Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P365
   Cardenas EJE, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102772
   Feichtenhofer C., 2016, ADV NEURAL INFORM PR, P3468
   Haque A., 2016, Towards Viewpoint Invariant 3D Human Pose Estimation, DOI [10.1007/978-3-319-46448-0_10, DOI 10.1007/978-3-319-46448-0_10]
   Hasson Y, 2019, PROC CVPR IEEE, P11799, DOI 10.1109/CVPR.2019.01208
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   John J, 2023, IMAGING SCI J, V71, P221, DOI 10.1080/13682199.2023.2179965
   Kim S, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010166
   Köpüklü O, 2019, IEEE INT CONF AUTOMA, P407
   Koller O, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P477, DOI 10.1109/ICCVW.2015.69
   Koller O, 2015, COMPUT VIS IMAGE UND, V141, P108, DOI 10.1016/j.cviu.2015.09.013
   Kuniyoshi Y., 1990, Design and implementation of a system that generates assembly programs from visual recognition of human action sequences, DOI [10.1109/IROS.1990.262444, DOI 10.1109/IROS.1990.262444]
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   LabelImg, 2021, Labelimg: A graphical image annotation tool
   Lang S, 2012, P 11 INT C ART INT 1, VI
   Li J, 2020, AAAI CONF ARTIF INTE, V34, P11354
   Li Y., 2019, End-to-End 3D Hand Pose Estimation from Stereo Cameras
   Lim KM, 2019, MULTIMED TOOLS APPL, V78, P19917, DOI 10.1007/s11042-019-7263-7
   Lin K, 2021, PROC CVPR IEEE, P1954, DOI 10.1109/CVPR46437.2021.00199
   Lv J, 2021, BMVC
   Ma M., 2016, INT C BIOINSP COMP T, P399
   Majidi Nezam, 2020, Journal of AI and Data Mining, V8, P451
   Marín-Jiménez MJ, 2018, J VIS COMMUN IMAGE R, V55, P627, DOI 10.1016/j.jvcir.2018.07.010
   Marks R, 2011, US Patent, Patent No. [8,072,470, 8072470]
   Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079
   Mocialov B, 2017, P WORKSH CREAT MEAN
   Mohammadi M, 2022, NEUROMORPH COMPUT EN, V2, DOI 10.1088/2634-4386/ac94f3
   Mohanty A., 2016, P INT C COMP VIS IM, V2, P449
   Moon G, 2018, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2018.00533
   Mousavi HH, 2014, J Med Eng
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Noble F, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23073419
   Oberweger M, 2016, PROC CVPR IEEE, P4957, DOI 10.1109/CVPR.2016.536
   Ong EJ, 2012, PROC CVPR IEEE, P2200, DOI 10.1109/CVPR.2012.6247928
   Oszust M, 2013, C HUM SYST INTERACT, P219, DOI 10.1109/HSI.2013.6577826
   Park JoonKyu, 2022, CVPR
   Pugeault Nicolas, 2011, INT C COMP VIS WORKS
   Rastgoo R, 2022, arXiv
   Rastgoo R, 2022, arXiv
   Rastgoo R, 2022, arXiv
   Rastgoo R, 2023, MULTIMED TOOLS APPL, V82, P43781, DOI 10.1007/s11042-023-15112-7
   Rastgoo R, 2021, IEEE COMPUT SOC CONF, P3446, DOI 10.1109/CVPRW53098.2021.00384
   Rastgoo R, 2022, J AMB INTEL HUM COMP, V13, P591, DOI 10.1007/s12652-021-02920-8
   Rastgoo R, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113794
   Rastgoo R, 2021, MULTIMED TOOLS APPL, V80, P127, DOI 10.1007/s11042-020-09700-0
   Rastgoo R, 2020, MULTIMED TOOLS APPL, V79, P22965, DOI 10.1007/s11042-020-09048-5
   Rastgoo R, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113336
   Rastgoo R, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110809
   Rautaray SS, 2012, PROC TECH, V4, P595, DOI 10.1016/j.protcy.2012.05.095
   Roccetti M., 2010, Comput Entertain (CIE), V8, P1, DOI [10.1145/1921141.1921148, DOI 10.1145/1921141.1921148]
   Roccetti M, 2012, J VIS COMMUN IMAGE R, V23, P426, DOI 10.1016/j.jvcir.2011.12.006
   Romero Javier, 2022, ARXIV220102610
   Ronchetti F, 2016, C ARG CIENC COMP CAC
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharma S, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115657
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spurr A, 2018, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2018.00017
   Subhashini S, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15397-8
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Thangali A, 2011, PROC CVPR IEEE, P521, DOI 10.1109/CVPR.2011.5995718
   Hoang VT, 2020, DATA BRIEF, V30, DOI 10.1016/j.dib.2020.105676
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P978
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   with Depthwise SeparableConvolutions XDL, 2017, arXiv
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Yu JM, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-08133-z
   Zimmermann C, 2017, IEEE I CONF COMP VIS, P4913, DOI 10.1109/ICCV.2017.525
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 97
TC 1
Z9 1
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17268-8
EA NOV 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200005
DA 2024-07-18
ER

PT J
AU Tan, F
   Yu, XY
   Wang, RJ
   Ai, BQ
   Li, FG
AF Tan, Fei
   Yu, Xiaoyuan
   Wang, Renjie
   Ai, Baoquan
   Li, Fengguo
TI Feature aggregation and modulation network for single image dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Physical model; Single image dehazing; Feature aggregation and
   modulation; Attention mechanism
ID FRAMEWORK
AB Deep learning-based methods have recently achieved satisfying results in image dehazing. However, we observe that various researchers devote themselves to learning haze-free images directly, while often paying no attention to the physical features of the hazy image formation process. For single image dehazing, a suitable transmission map and global atmospheric light guidance proved effective. Meanwhile, for many dehazing networks, deep and non-adjacent feature information is not utilized which can likewise affect the effectiveness of image recovery. Therefore, we develop an effective feature aggregation and modulation network for image dehazing called FAM-Net. Specifically, the proposed FAM-Net first uses CNN to estimate the transmission map and global atmospheric light, and then embeds the output features into the overall network for joint dehazing. A feature aggregation and modulation module is proposed to fuse the extracted features of atmospheric light and transmission map into the network. Moreover, the attention guidance aggregation module is designed as a replacement for the skip connection. Furthermore, a novel edge-preserving loss function is proposed for training the network, preserving more details of the reconstructed images. Experimental results indicate that FAM-Net outperforms existing dehazing methods in quantitative and qualitative aspects.
C1 [Tan, Fei; Yu, Xiaoyuan; Wang, Renjie; Ai, Baoquan; Li, Fengguo] South China Normal Univ, Sch Phys & Telecommun Engn, Guangzhou 510006, Peoples R China.
C3 South China Normal University
RP Li, FG (corresponding author), South China Normal Univ, Sch Phys & Telecommun Engn, Guangzhou 510006, Peoples R China.
EM tanf@m.scnu.edu.cn; xiaoyuanyu@scnu.edu.cn; 2022022233@m.scnu.edu.cn;
   aibq@scnu.edu.cn; lifengguo@m.scnu.edu.cn
RI tan, fei/KOD-4737-2024
FU This work was supported by the National Natural Science Foundation of
   China (Grant No. 12075090), and by the Funding by Science and Technology
   Projects in Guangzhou (Grant No. 2023A04J1686), and by the GuangDong
   Basic and Applied Basic Research Foundation [12075090]; National Natural
   Science Foundation of China [2023A04J1686]; Science and Technology
   Projects in Guangzhou [2022A1515110119]; GuangDong Basic and Applied
   Basic Research Foundation
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 12075090), and by the Funding by Science and Technology
   Projects in Guangzhou (Grant No. 2023A04J1686), and by the GuangDong
   Basic and Applied Basic Research Foundation (Grant No. 2022A1515110119).
CR Bai HR, 2022, IEEE T IMAGE PROCESS, V31, P1217, DOI 10.1109/TIP.2022.3140609
   Berman D, 2017, IEEE INT CONF COMPUT, P115
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P2453, DOI 10.1109/ICCV.2019.00254
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Guo CL, 2022, PROC CVPR IEEE, P5802, DOI 10.1109/CVPR52688.2022.00572
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jiangxin Dong, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P188, DOI 10.1007/978-3-030-58577-8_12
   Kar A, 2022, Arxiv, DOI arXiv:2008.01701
   Kingma D. P., 2014, arXiv
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   McCartney E. J., 1976, Optics of the atmosphere. Scattering by molecules and particles
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Nishino K., 2012, Bayesian defogging. Int J Comput Vis, V98, P263, DOI [10.1007/s11263-011-0508-1, DOI 10.1007/S11263-011-0508-1]
   Pang YW, 2019, IEEE T CIRC SYST VID, V29, P3211, DOI 10.1109/TCSVT.2018.2880223
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Riaz I, 2016, J VIS COMMUN IMAGE R, V40, P85, DOI 10.1016/j.jvcir.2016.06.011
   Song YD, 2023, IEEE T IMAGE PROCESS, V32, P1927, DOI 10.1109/TIP.2023.3256763
   Wang C, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107279
   Wang T, 2021, NEUROCOMPUTING, V439, P75, DOI 10.1016/j.neucom.2021.01.042
   Wang ZD, 2022, PROC CVPR IEEE, P17662, DOI 10.1109/CVPR52688.2022.01716
   Xiao B, 2022, Single uhd image dehazing via interpretable pyramid network
   Ye Liu, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P50, DOI 10.1145/3474085.3475331
   Ye T, 2022, LECT NOTES COMPUT SC, V13679, P130, DOI 10.1007/978-3-031-19800-7_8
   Yu YK, 2021, IEEE COMPUT SOC CONF, P193, DOI 10.1109/CVPRW53098.2021.00028
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang J, 2020, IEEE T IMAGE PROCESS, V29, P72, DOI 10.1109/TIP.2019.2922837
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang XQ, 2020, COMPUT VIS IMAGE UND, V197, DOI 10.1016/j.cviu.2020.103003
   Zhao SY, 2021, IEEE T IMAGE PROCESS, V30, P3391, DOI 10.1109/TIP.2021.3060873
   Zhao SY, 2020, IEEE T IMAGE PROCESS, V29, P6947, DOI 10.1109/TIP.2020.2995264
   Zhu HY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1234
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 41
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17473-5
EA NOV 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200010
DA 2024-07-18
ER

PT J
AU Lin, Y
   Wang, SB
   Lan, YF
AF Lin, Yi
   Wang, Shunbo
   Lan, Yangfan
TI The research on the self-regulation strategies support for virtual
   interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Virtual environment; Self-regulatory behaviors; Self-regulation
   strategy; Self-directed learning
ID USABILITY
AB For students, self-regulated learning ability is a basic requirement when learning in a virtual environment. However, there is a lack of research on self-regulated learning for virtual interaction. To investigate the feasibility and effectiveness of supporting self-regulation strategies in virtual environment, four scaffoldings in the form of interactive tools were designed in this study based on self-regulation strategies that are applicable to virtual interaction. In doing so, the study can explore the impacts of these tools on students' self-directed learning performances and behaviors. Using a between-subjects experimental design, participants were assigned to the control group (common virtual environment) and experimental group (enhanced virtual environment with self-regulated learning interactive tools). Experimental results showed that students who used interactive tools in the enhanced virtual environment had better self-directed learning performances compared to those who experienced learning in the common virtual environment, and this result were of medium to high practical significance (Cohen's d = 0.79). Meanwhile, there was a correspondence between students' self-report of self-regulatory ability and self-regulatory behaviors presented in the virtual environment. Students who tended to use the tool of Learning Task Progress Tree that support goal-setting and planning strategy perform well in time management, while those who frequently use the tool of Panoramic Video Evaluation that support self-evaluation strategy had stronger self-assessment abilities. In addition, self-regulated learning interactive tools have a relative acceptable usability. Relevant suggestions were summarized through the analysis of the experimental findings meant to provide references for the design of interactive tools for self-regulated learning in a virtual environment.
C1 [Lin, Yi; Lan, Yangfan] Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou, Fujian, Peoples R China.
   [Wang, Shunbo] Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China.
C3 Fuzhou University; Tianjin University
RP Wang, SB (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China.
EM wang.shunbo@foxmail.com
OI Lin, Yi/0000-0003-3239-3446
FU Thanks to the funding of Program of Study Abroad for Young Scholar
   sponsored by CSC (China Scholarship Council) under Grant 201806655029,
   Educational Research Project for Young Teachers of the Education
   Department of Fujian Province of China (JAT200029). [201806655029]; CSC
   (China Scholarship Council) [JAT200029]; Educational Research Project
   for Young Teachers of the Education Department of Fujian Province of
   China
FX Thanks to the funding of Program of Study Abroad for Young Scholar
   sponsored by CSC (China Scholarship Council) under Grant 201806655029,
   Educational Research Project for Young Teachers of the Education
   Department of Fujian Province of China (JAT200029).
CR Abushamleh H, 2021, PROCEEDINGS OF THE 2021 INNOVATION AND NEW TRENDS IN ENGINEERING, SCIENCE AND TECHNOLOGY EDUCATION CONFERENCE (IETSEC 2021), P52, DOI 10.1109/IETSEC51476.2021.9440491
   Aguilar SJ, 2021, COMPUT EDUC, V162, DOI 10.1016/j.compedu.2020.104085
   Anderson A, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P687
   [Anonymous], 1995, Educational Psychology, DOI [DOI 10.1080/0144341950150207, 10.1080/0144341950150207]
   [Anonymous], IBM SPSS Statistics Version 22.0 for Windows
   Azevedo R, 2005, INSTR SCI, V33, P367, DOI 10.1007/s11251-005-1272-9
   Babu SK, 2018, IEEE INT CONF ADV LE, P385, DOI 10.1109/ICALT.2018.00094
   Bajpai S, 2016, IFAC PAPERSONLINE, V49, P813, DOI 10.1016/j.ifacol.2016.03.157
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Barnard L, 2009, INTERNET HIGH EDUC, V12, P1, DOI 10.1016/j.iheduc.2008.10.005
   Batista AF, 2020, INFORM EDUC, V19, P201, DOI 10.15388/infedu.2020.10
   Berkling Kay, 2013, 2013 International Conference on Interactive Collaborative Learning (ICL), P525, DOI 10.1109/ICL.2013.6644642
   Bielinis E, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17145109
   Broadbent J, 2015, INTERNET HIGH EDUC, V27, P1, DOI 10.1016/j.iheduc.2015.04.007
   Chen YL, 2020, COMPUT EDUC, V154, DOI 10.1016/j.compedu.2020.103910
   Cho YJ, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12020315
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Delen E, 2014, COMPUT EDUC, V78, P312, DOI 10.1016/j.compedu.2014.06.018
   Fitton IS, 2020, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.315
   Gao CM, 2019, PROCEEDINGS OF THE 20TH ANNUAL CONFERENCE ON INFORMATION TECHNOLOGY EDUCATION (SIGITE '19), P39, DOI 10.1145/3349266.3351351
   Garcia R, 2018, COMPUT EDUC, V123, P150, DOI 10.1016/j.compedu.2018.05.006
   Garner S., 2007, ICT: Providing Choices Learners Learn, V321, P324
   Grivokostopoulou F, 2017, PR IEEE INT CONF TEA, P486, DOI 10.1109/TALE.2017.8252385
   Harati H, 2021, EDUC SCI, V11, DOI 10.3390/educsci11100603
   Huang SF, 2021, UNIVERSAL ACCESS INF, V20, P429, DOI 10.1007/s10209-020-00750-7
   Huang HM, 2018, INT REV RES OPEN DIS, V19, P91
   Huang Q, 2022, EDUC INF TECHNOL, V27, P7973, DOI 10.1007/s10639-022-10963-3
   Isgin-Atici K, 2020, J NUTR EDUC BEHAV, V52, P1058, DOI 10.1016/j.jneb.2020.08.001
   Keuning H., 2016, Proceedings of the 2016 ACM Conference on Innovation and Technology in Computer Science Education, P41
   Khare S, 2014, 2014 INTERNATIONAL CONFERENCE ON POWER, CONTROL AND EMBEDDED SYSTEMS (ICPCES)
   Khiat H, 2022, J UNIV TEACH LEARN P, V19
   Kok M, 2020, PHYS EDUC SPORT PEDA, V25, P49, DOI 10.1080/17408989.2019.1688773
   Koriat A, 2018, MEM COGNITION, V46, P370, DOI 10.3758/s13421-017-0771-7
   Lamb R, 2020, J SCI EDUC TECHNOL, V29, P573, DOI 10.1007/s10956-020-09837-5
   Lee EAL., 2008, A Review of Using Virtual Reality for Learning, DOI [10.1007/978-3-540-69744-2_18, DOI 10.1007/978-3-540-69744-2_18]
   Lehmann T, 2014, COMPUT HUM BEHAV, V32, P313, DOI 10.1016/j.chb.2013.07.051
   Lewis JR, 2018, INT J HUM-COMPUT INT, V34, P577, DOI 10.1080/10447318.2018.1455307
   Li C, 2019, LECT NOTES COMPUT SC, V11546, P93, DOI 10.1007/978-3-030-21562-0_8
   Manso-Vázquez M, 2018, IEEE ACCESS, V6, P42467, DOI 10.1109/ACCESS.2018.2860519
   McNeish D, 2018, PSYCHOL METHODS, V23, P412, DOI 10.1037/met0000144
   ourworldindata, Our World in Data
   Pavlov V, 2021, J UNIV TEACH LEARN P, V18, DOI 10.53761/1.18.7.14
   Peters R, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P401, DOI 10.1145/3025171.3025188
   Probst D, 2018, J CHEM INF MODEL, V58, P1731, DOI 10.1021/acs.jcim.8b00402
   Quadir B, 2018, LECT N EDUC TECHNOL, P97, DOI 10.1007/978-981-10-8743-1_14
   Rahimi E, 2015, COMPUT EDUC, V81, P235, DOI 10.1016/j.compedu.2014.10.012
   Sattar MU, 2019, PAK J MED SCI, V35, P852, DOI 10.12669/pjms.35.3.44
   Scavarelli A, 2021, VIRTUAL REAL-LONDON, V25, P257, DOI 10.1007/s10055-020-00444-8
   Tsutsumi M, 2017, JPN J NURS SCI, V14, P3, DOI 10.1111/jjns.12131
   Vlachogianni P, 2022, J RES TECHNOL EDUC, V54, P392, DOI 10.1080/15391523.2020.1867938
   Vygotsky L. S., 1978, Mind in Society: The Development of Higher Psychological Processes, DOI 10.2307/j.ctvjf9vz4
   Weimin Wu, 2007, 2007 IEEE International Conference on Control and Automation, ICCA 2007, P742
   Wilkinson L, 1999, AM PSYCHOL, V54, P594, DOI 10.1037/0003-066X.54.8.594
   Wong J, 2019, INT J HUM-COMPUT INT, V35, P356, DOI 10.1080/10447318.2018.1543084
   WOOD D, 1976, J CHILD PSYCHOL PSYC, V17, P89, DOI 10.1111/j.1469-7610.1976.tb00381.x
   Zheng LQ, 2016, ASIA PAC EDUC REV, V17, P187, DOI 10.1007/s12564-016-9426-9
   ZIMMERMAN BJ, 1986, AM EDUC RES J, V23, P614, DOI 10.2307/1163093
   ZIMMERMAN BJ, 1989, J EDUC PSYCHOL, V81, P329, DOI 10.1037/0022-0663.81.3.329
NR 58
TC 0
Z9 0
U1 8
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17519-8
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500012
DA 2024-07-18
ER

PT J
AU Midhunraj, PK
   Thivya, KS
   Anand, M
AF Midhunraj, P. K.
   Thivya, K. S.
   Anand, M.
TI An Analysis of Plant Diseases on Detection and Classification: From
   Machine Learning to Deep Learning Techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Agriculture; Plant disease prediction; Deep learning; Machine learning;
   Cassava Disease; Crop diseases image processing; Classification
AB Plants are acknowledged as being crucial because they are the main source of human energy generation due to their nutritional, therapeutic, and other benefits. Therefore, it is necessary to increase crop productivity. One of these significant factors contributing to reduced agricultural yields is the prevalence of bacterial, fungal, and viral illnesses. Applying techniques for plant disease identification can stop and treat these diseases. So, numerous machine learning (ML) and deep learning (DL) methods were created and tested by researchers to identify plant diseases. Therefore, this study gives a detailed discussion of the various research studies conducted in plant disease detection utilizing ML and DL-based techniques. This review offers research advancements in plant disease recognition from ML to DL techniques. Additionally, many datasets about plant diseases are thoroughly examined. It also addresses the difficulties and issues with the current systems.
C1 [Midhunraj, P. K.] Dr MGR Educ & Res Inst, Dept Elect & Commun Engn, Chennai 600095, Tamil Nadu, India.
   [Thivya, K. S.; Anand, M.] Dr MGR Educ & Res Inst, Dept Elect & Commun Engn, Chennai 600095, Tamil Nadu, India.
RP Midhunraj, PK (corresponding author), Dr MGR Educ & Res Inst, Dept Elect & Commun Engn, Chennai 600095, Tamil Nadu, India.
EM midhunrajmeae@gmail.com; thivya.ece@drmgrdu.ac.in;
   anand.ece@drmgrdu.ac.in
CR Almadhor A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113830
   Amara J., 2017, A deep learning-based approach for banana leaf diseases classification
   Anari MS, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/6504616
   Andrew J, 2022, AGRONOMY-BASEL, V12, DOI 10.3390/agronomy12102395
   Anjanadevi B., 2020, An improved deep815learning model for plant disease detection
   Arshaghi A, 2023, MULTIMED TOOLS APPL, V82, P5725, DOI 10.1007/s11042-022-13390-1
   Ashwinkumar S, 2022, MATER TODAY-PROC, V51, P480, DOI 10.1016/j.matpr.2021.05.584
   Atila Ü, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101182
   Azim MA., 2021, Telecommun. Comput. Electronics Control TELKOMNIKA, V19, P463, DOI [10.12928/telkomnika.v19i2.16488, DOI 10.12928/TELKOMNIKA.V19I2.16488]
   Barbedo JGA, 2018, BIOSYST ENG, V172, P84, DOI 10.1016/j.biosystemseng.2018.05.013
   Belay Abebech Jenber, 2022, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2022.100970
   Bisht IS, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12093751
   Cap HQ, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P118, DOI 10.1109/CSPA.2018.8368697
   Chai JY, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100134
   Chowdhury MEH, 2021, AGRIENGINEERING, V3, P294, DOI 10.3390/agriengineering3020020
   Dhakal A, 2018, Int. J. Comput. Trends Technol., V61, P26, DOI [10.14445/22312803/IJCTT-V61P105, DOI 10.14445/22312803/IJCTT-V61P105, 10.14445/22312803/ijctt-v61p105]
   Divyanth LG, 2023, SMART AGR TECHNOL, V3, DOI 10.1016/j.atech.2022.100108
   Durmus H, 2017, INT CONF AGRO-GEOINF, P46
   Enkvetchakul Prem, 2022, ICIC Express Letters, P521, DOI 10.24507/icicel.16.05.521
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Gu YH, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12020300
   Haridasan A, 2023, ENVIRON MONIT ASSESS, V195, DOI 10.1007/s10661-022-10656-x
   Hassan SM, 2022, IEEE ACCESS, V10, P5390, DOI 10.1109/ACCESS.2022.3141371
   Islam MS, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22166079
   Jayaprakash K, 2022, 2022 4 INT C SMART S, P1473
   Joshi B. M., 2023, International Journal of Intelligent Systems and Applications in Engineering, V11, P215
   Kalwad Priyadarshini D., 2022, Information and Communication Technology for Competitive Strategies (ICTCS 2020): ICT: Applications and Social Interfaces. Lecture Notes in Networks and Systems (191), P803, DOI 10.1007/978-981-16-0739-4_76
   Karthick M., 2022, INT J ENG TRENDS TEC, V70, P392, DOI DOI 10.14445/22315381/IJETT-V70I12P237
   Kaur Prabhjot, 2023, Journal of Ambient Intelligence and Humanized Computing, P12407, DOI 10.1007/s12652-022-04331-9
   Kaur P, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020575
   Keh SS, 2020, arXiv, DOI [10.48550/arXiv.2012.00332, DOI 10.48550/ARXIV.2012.00332]
   Khan MA, 2021, INTELL AUTOM SOFT CO, V30, P771, DOI 10.32604/iasc.2021.018039
   Kumar R, 2021, Int J Adv Comput Sci Appl, V12
   Lee SH, 2021, INT C PATT RECOG, P3320, DOI 10.1109/ICPR48806.2021.9412643
   Liang WJ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38966-0
   Liu GS, 2023, ARAB J SCI ENG, V48, P1661, DOI 10.1007/s13369-022-06987-z
   Liu ZY, 2022, IEEE ACCESS, V10, P44934, DOI 10.1109/ACCESS.2022.3169147
   Lu YZ, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105760
   Mahum R, 2023, HUM ECOL RISK ASSESS, V29, P303, DOI 10.1080/10807039.2022.2064814
   Malik A, 2022, J FOOD QUALITY, V2022, DOI 10.1155/2022/9211700
   Methkal Y., 2023, Meas. Sensors, V25, DOI [10.1016/j.measen.2022.100643, DOI 10.1016/J.MEASEN.2022.100643]
   Miaomiao Ji, 2020, Information Processing in Agriculture, V7, P418, DOI 10.1016/j.inpa.2019.10.003
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Mohapatra M, 2022, COMPUTERS, V11, DOI 10.3390/computers11050082
   Musa A, 2022, J LOW POWER ELECT AP, V12, DOI 10.3390/jlpea12020024
   Nazarov PA, 2020, ACTA NATURAE, V12, P46
   Noyan MA, 2022, Arxiv, DOI [arXiv:2206.04374, 10.48550/arXiv.2206.04374]
   Oyewola DO, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.352
   Panchal Adesh V., 2023, Materials Today: Proceedings, P3500, DOI 10.1016/j.matpr.2021.07.281
   Pandey A, 2022, ECOL INFORM, V70, DOI 10.1016/j.ecoinf.2022.101725
   Pandian JA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12146982
   Panigrahi Kshyanaprava Panda, 2020, 2020 4th International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P678, DOI 10.1109/ICOEI48184.2020.9142871
   Patil Nilam Sachin, 2021, Turkish Journal of Computer and Mathematics Education, V12, P1672
   Patil P. S., 2020, Classification of various859plant diseases using deep siamese network
   Rahman CR, 2021, RICE GRAIN DIS IDENT, V2021, DOI 10.31220/agriRxiv.2021.00062
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Reddy SRG, 2021, INT J SPEECH TECHNOL, DOI 10.1007/s10772-021-09843-x
   Saleem MH, 2022, IEEE ACCESS, V10, P89798, DOI 10.1109/ACCESS.2022.3201104
   Saleem MH, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9111451
   Saleem MH, 2019, PLANTS-BASEL, V8, DOI 10.3390/plants8110468
   Sambasivam G, 2021, EGYPT INFORM J, V22, P27, DOI 10.1016/j.eij.2020.02.007
   Sembiring Arnes, 2021, Journal of Physics: Conference Series, V1845, DOI 10.1088/1742-6596/1845/1/012009
   Sethy PK., 2020, Crossref, DOI [10.1016/j.compag.2020.10552, DOI 10.1016/J.COMPAG.2020.10552]
   Shafiul HM, 2021, Corn leaf disease classification and detection using deep convolutional neural network, P1
   Shah D, 2022, INFORM PROCESS AGR, V9, P212, DOI 10.1016/j.inpa.2021.06.001
   Shrivastava Gaurav, 2022, ICTACT Journal on Soft Computing, P2619
   Singh Aditi, 2021, IOP Conference Series: Materials Science and Engineering, V1022, DOI 10.1088/1757-899X/1022/1/012121
   Singh D, 2020, ACM INT CONF PR SER, P249, DOI 10.1145/3371158.3371196
   Sun X., 2022, Cognit. Robot, V2, P155, DOI [10.1016/j.cogr.2022.07.001, DOI 10.1016/J.COGR.2022.07.001]
   Tamilvizhi T, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/3452413
   Tian Hong-kun, 2020, Information Processing in Agriculture, V7, P1, DOI 10.1016/j.inpa.2019.09.006
   Türkoglu M, 2019, TURK J ELECTR ENG CO, V27, P1636, DOI 10.3906/elk-1809-181
   Uguz S, 2021, NEURAL COMPUT APPL, V33, P4133, DOI 10.1007/s00521-020-05235-5
   Upadhyay Santosh Kumar, 2022, International Journal of Information Technology, V14, P185, DOI 10.1007/s41870-021-00817-5
   Vimal Adit V., 2020, Advances in cybernetics, cognition, and machine learning for communication technologies, P153, DOI [10.1007/978-981-15-3125-5_17, DOI 10.1007/978-981-15-3125-5_17]
   Wang HQ, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12070931
   Yousuf U., 2021, International Journal of Computer Science and Mobile Computing, V10, P14, DOI [10.47760/ijcsmc.2021.v10i01.003, DOI 10.47760/IJCSMC.2021.V10I01.003]
   Zhou GX, 2019, IEEE ACCESS, V7, P143190, DOI 10.1109/ACCESS.2019.2943454
NR 78
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17600-2
EA NOV 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500033
DA 2024-07-18
ER

PT J
AU Halder, A
   Talukdar, NA
AF Halder, Anindya
   Talukdar, Nur Alom
TI Kernel induced semi-supervised spatial clustering: a novel brain MRI
   segmentation technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Semi-supervised; Fuzzy sets; Kernel; Segmentation; MRI
ID MAGNETIC-RESONANCE IMAGES; OF-THE-ART; TISSUE SEGMENTATION; TUMOR;
   CLASSIFICATION; ALGORITHM; IDENTIFICATION; ROUGH; FCM
AB Segmentation of different brain tissues such as white matter (WM), cerebrospinal fluid (CSF), and gray matter (GM) form magnetic resonance image (MRI) is a challenging task as the various tissue regions are complex because of their overlapping, vague and indiscernible and nonlinearly separable nature. Additionally, MRI often suffers from noise and outliers. Clustering based segmentation performance can be improved significantly by providing some amount of label pixels in the clustering process by employing semi-supervision. To cope with the above mentioned challenges, for the segmentation of brain MRI a novel semi-supervised technique called Kernel Induced Semi-supervised Spatial clustering (KISS) is proposed. The method is a judicious integration of (i) kernel trick to enhance the chances of linear separability of different regions of brain boundaries, (ii) spatial contextual information to handle the noise and outliers, (iii) fuzzy set to deal with overlapping and uncertainty of different tissue boundaries, (iv) rough set to cope with the indiscernibility and vagueness of various tissue boundaries and (v) semi-supervision to direct the process of clustering in a better direction by supplying some labeled pixels with constraint seeded policy. Several benchmark true and synthetic MRI datasets with and without added noise are examined. The efficacy of the proposed technique is validated with three unsupervised and two semi-supervised techniques and evaluated using different validity indices. Improvements achieved by the proposed technique in accuracy against the closest competitive techniques are 1.125%, 0.864%, 0.729% and 1.130% for normal BrainWeb datasets and 3.53%, 2.57%, 2.90% and 4.62% for the same datasets considering 6% added "salt & pepper" noise whereas 0.475%, 0.553%, 0.585% and 0.496% for normal IBSR datasets. Improvements considering "rician" noise are 1.62% and 1.42% for IBSR datasets 144 and 150 respectively whereas, 3.73% and 0.61% for BrainWeb datasets 85 and 100 respectively. The paired t-test results statistically signify the better results in support of the proposed technique. The confidence interval test also confirms the superiority of the proposed method over other counter part techniques. The proposed technique turned out to be effective for brain MRI segmentation. Therefore, it may be utilized for other medical image segmentations in future.
C1 [Halder, Anindya] North Eastern Hill Univ, Sch Technol, Dept Comp Applicat, Tura Campus, Chasingre 794002, Meghalaya, India.
   [Talukdar, Nur Alom] Assam Town Univ, Fac Comp Technol, Gauhati 781026, India.
C3 North Eastern Hill University
RP Talukdar, NA (corresponding author), Assam Town Univ, Fac Comp Technol, Gauhati 781026, India.
EM anindya.halder@gmail.com; nuralom1988@gmail.com
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Akkus Z, 2017, J DIGIT IMAGING, V30, P449, DOI 10.1007/s10278-017-9983-4
   Alazraki NP, 2007, A clinicians guide to nuclear oncology, V1st
   [Anonymous], 2002, P 19 INT C MACHINE L
   Ashwani Kumar Aggarwal P.J., 2022, Int J Biol Biomed, V7, P40
   Bailey, 2005, POSITRON EMISSION TO
   Balafar MA, 2010, ARTIF INTELL REV, V33, P261, DOI 10.1007/s10462-010-9155-0
   Banerjee A, 2016, APPL SOFT COMPUT, V46, P558, DOI 10.1016/j.asoc.2016.03.010
   Banerjee S, 2016, INFORM SCIENCES, V330, P88, DOI 10.1016/j.ins.2015.10.018
   Basu S, 2004, SIAM PROC S, P333
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Bernal J, 2019, ARTIF INTELL MED, V95, P64, DOI 10.1016/j.artmed.2018.08.008
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Biga L.M., ANATOMY PHYSL
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Boncelet C, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P397, DOI 10.1016/B978-012119792-6/50087-5
   Cattin Philippe, 2013, IMAGE RESTORATION IN
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Ciritsis A, 2018, NMR BIOMED, V31, DOI 10.1002/nbm.3931
   Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135
   Cormack A., 1979, The nobel prize in physiology or medicine
   Das S, 2010, INFORM SCIENCES, V180, P1237, DOI 10.1016/j.ins.2009.11.041
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   English RJ, 2005, SPECT: A Primer, V3rd
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Golkov V, 2016, IEEE T MED IMAGING, V35, P1344, DOI 10.1109/TMI.2016.2551324
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Gordillo N, 2013, MAGN RESON IMAGING, V31, P1426, DOI 10.1016/j.mri.2013.05.002
   Grira N, 2005, Technical report B.P. 105
   GUDBJARTSSON H, 1995, MAGNET RESON MED, V34, P910, DOI 10.1002/mrm.1910340618
   Haidekker M.A., 2013, MED IMAGING TECHNOLO
   Halder A, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105758
   Halder A, 2019, MAGN RESON IMAGING, V62, P129, DOI 10.1016/j.mri.2019.06.010
   Halder A, 2015, 2015 International Symposium on Advanced Computing and Communication (ISACC), P41, DOI 10.1109/ISACC.2015.7377312
   HALL LO, 1992, IEEE T NEURAL NETWOR, V3, P672, DOI 10.1109/72.159057
   Han J, 2012, MOR KAUF D, P1
   Hastie T., 2009, The elements of statistical learning: data mining, inference, and prediction, V2
   HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126
   Hofmann T, 2008, ANN STAT, V36, P1171, DOI 10.1214/009053607000000677
   Hou ZJ, 2006, INT J BIOMED IMAGING, V2006, DOI 10.1155/IJBI/2006/49515
   Jeurissen B, 2015, P INT SOC MAGN RESON
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Son LH, 2017, ENG APPL ARTIF INTEL, V59, P186, DOI 10.1016/j.engappai.2017.01.003
   LI CL, 1993, IEEE T MED IMAGING, V12, P740, DOI 10.1109/42.251125
   Liew AWC, 2003, IEEE T MED IMAGING, V22, P1063, DOI 10.1109/TMI.2003.816956
   Liu J, 2014, TSINGHUA SCI TECHNOL, V19, P578, DOI 10.1109/TST.2014.6961028
   Liu W, 2013, IEEE T IMAGE PROCESS, V22, P872, DOI 10.1109/TIP.2012.2219544
   Maji P., 2012, ROUGH FUZZY PATTERN
   Maji P, 2007, FUND INFORM, V80, P475
   Maji P, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123677
   Manousakas IN, 1998, COMPUT BIOMED RES, V31, P393, DOI 10.1006/cbmr.1998.1489
   MEYER CR, 1995, IEEE T MED IMAGING, V14, P36, DOI 10.1109/42.370400
   Mitchel T, 2017, Machine learning, V1st
   Mitra S, 2011, INFORM SCIENCES, V181, P3601, DOI 10.1016/j.ins.2011.04.027
   National Research Council (US) and the Institute of Medicine (US) Committee, 1996, Mathematics and physics of emerging dynamic biomedical imaging
   Nie D, 2019, IEEE T CYBERNETICS, V49, P1123, DOI 10.1109/TCYB.2018.2797905
   Nowak RD, 1999, IEEE T IMAGE PROCESS, V8, P1408, DOI 10.1109/83.791966
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Pawlak Z., 1991, ROUGH SETS THEORETIC, DOI DOI 10.1007/978-94-011-3534-4
   Rajapakse JC, 1997, IEEE T MED IMAGING, V16, P176, DOI 10.1109/42.563663
   Ravishankar S, 2011, IEEE T MED IMAGING, V30, P1028, DOI 10.1109/TMI.2010.2090538
   Rice JA, 2006, Cengage Learning, Advanced series
   Rohlfing T, 2012, IEEE T MED IMAGING, V31, P153, DOI 10.1109/TMI.2011.2163944
   Saha S, 2016, EXPERT SYST APPL, V52, P50, DOI 10.1016/j.eswa.2016.01.005
   Saha S, 2007, IEEE C EVOL COMPUTAT, P4417, DOI 10.1109/CEC.2007.4425049
   Sarkar JP, 2016, APPL SOFT COMPUT, V46, P527, DOI 10.1016/j.asoc.2016.01.040
   Schnell S, 2009, NEUROIMAGE, V46, P642, DOI 10.1016/j.neuroimage.2009.03.003
   Scholkopf B., 2002, Learning with Kernels
   Singleton HR, 1997, MAGNET RESON MED, V37, P418, DOI 10.1002/mrm.1910370320
   Subudhi BN, 2016, MAGN RESON IMAGING, V34, P1292, DOI 10.1016/j.mri.2016.07.002
   Suetens Paul., 2002, FUNDAMENTALS MED IMA
   Sun P, 2019, MATH VIS, P69, DOI 10.1007/978-3-030-05831-9_6
   Taylor JS, 2004, Kernel method for pattern analysis
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   Thukral R, 2022, P INT C REC TRENDS C, P827, DOI DOI 10.1007/978-981-16-7118-0_70
   Tukey J.W., 1977, EXPLORATORY DATA ANA, V2
   Vanderah TW., 2015, Noltes the human brain: an introduction to its functional anatomy, V7th
   Vishnuvarthanan G, 2016, APPL SOFT COMPUT, V38, P190, DOI 10.1016/j.asoc.2015.09.016
   Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747
   Wittrock M.C., 1980, The Brain and Psychology
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang F, 2021, NEUROIMAGE, V233, DOI 10.1016/j.neuroimage.2021.117934
   Zhang WL, 2015, NEUROIMAGE, V108, P214, DOI 10.1016/j.neuroimage.2014.12.061
   Zhu Xiaojin Jerry, 2008, Semi-supervised learning literature survey
NR 84
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 28
PY 2023
DI 10.1007/s11042-023-16806-8
EA OCT 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W7FP7
UT WOS:001093249700003
DA 2024-07-18
ER

PT J
AU Agarwal, V
   Kumar, D
AF Agarwal, Varun
   Kumar, Dhirendra
TI Secure chaotic image encryption method using random graph traversal and
   three step diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; Lorenz map; Random graph traversal; Chaotic sequence
ID ALGORITHM; PERMUTATION; MAP
AB In this paper, we have presented an image encryption technique using random graph traversal, chaotic maps, and a secure hashing algorithm. Due to the innate features of images, such as a high correlation between pixels, high redundancy, and the bulk capacity of images, traditional cryptography methods cannot be used for image encryption. Several theories can be exploited for image cryptography, but we choose random graph traversal because of its immense potential in this field. Chaotic maps are highly sensitive to initial conditions, which makes them suitable for encryption tasks. It is difficult to predict the dynamic properties of high-dimensional maps since they are more complex in nature. We use a three-dimensional Lorenz map to make our algorithm more robust. The initial parameters of the Lorenz map are modified by using the SHA-3 algorithm in the plain image. All the pixels of the image are assumed to be nodes of a graph, and a novel method is used to find a random path of pixel nodes in this graph network using a Lorenz map sequence such that each pixel node is visited exactly once. Finally, the chaotic sequences are used to diffuse the image into three sub-parts to obtain the final cipher image. The experiment has been performed on several standard images to compare the proposed approach with related methods in terms of qualitative and quantitative measures. The proposed approach fails to decrypt the cipher image even with a key deviation as low as 10(-7) compared to related methods, which show excellent key sensitivity compared to the proposed method. Experimental results show that the proposed algorithm is highly secure and can resist several attacks.
C1 [Agarwal, Varun; Kumar, Dhirendra] Delhi Technol Univ, Dept Appl Math, Delhi, India.
C3 Delhi Technological University
RP Kumar, D (corresponding author), Delhi Technol Univ, Dept Appl Math, Delhi, India.
EM agarwalvarun2000@gmail.com; dhirendrakumar@dtu.ac.in
OI Kumar, Dhirendra/0000-0002-8902-5022
FU The authors would like to thanks Mr. Puneet Kumar Pal, Research Scholar,
   Department of Applied Mathematics, Delhi Technological University,
   Delhi, India for his constructive idea and help on addressing the
   reviewers' comments.
FX The authors would like to thanks Mr. Puneet Kumar Pal, Research Scholar,
   Department of Applied Mathematics, Delhi Technological University,
   Delhi, India for his constructive idea and help on addressing the
   reviewers' comments.
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Askar SS, 2015, Math Probl Eng, V2015
   Biswas HR, 2018, Chaos theory and its applications in our real life
   Cao LC, 2015, CHINESE PHYS B, V24, DOI 10.1088/1674-1056/24/10/100501
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen J, 2019, IEEE ACCESS, V7, P181083, DOI 10.1109/ACCESS.2019.2959031
   Daud NN, 2020, J NETW COMPUT APPL, V166, DOI 10.1016/j.jnca.2020.102716
   El-Shafai W, 2021, J AMB INTEL HUM COMP, V12, P9007, DOI 10.1007/s12652-020-02597-5
   Erkan U, 2022, INFORM SCIENCES, V589, P770, DOI 10.1016/j.ins.2021.12.126
   Faridnia S, 2010, LECT NOTES COMPUT SC, V6374, P352, DOI 10.1007/978-3-642-15910-7_40
   Gui XQ, 2022, MULTIMED TOOLS APPL, V81, P21975, DOI 10.1007/s11042-022-12239-x
   He XP, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P622, DOI 10.1109/CISP.2008.222
   Jafarzadeh N, 2013, MATCH-COMMUN MATH CO, V70, P401
   Li L, 2022, Multimed Tools Appl, P1
   Li X., 2018, EURASIP J Image Video Process, V1, P1
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Mao YB, 2005, HANDBOOK OF GEOMETRIC COMPUTING: APPLICATIONS IN PATTERN RECOGNITION, COMPUTER VISION, NEURALCOMPUTING, AND ROBOTICS, P231, DOI 10.1007/3-540-28247-5_8
   Mondal B, 2018, MULTIMED TOOLS APPL, V77, P31177, DOI 10.1007/s11042-018-6214-z
   Musanna F, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102560
   Rohith S, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRONICS, COMPUTERS AND COMMUNICATIONS (ICAECC)
   Roohi M, 2020, NONLINEAR DYNAM, V100, P3979, DOI 10.1007/s11071-020-05719-y
   Sharma K, 2020, Arxiv, DOI arXiv:1912.10413
   Teng L, 2022, INFORM SCIENCES, V605, P71, DOI 10.1016/j.ins.2022.05.032
   Tsai DY, 2008, J DIGIT IMAGING, V21, P338, DOI 10.1007/s10278-007-9044-5
   Vaish A, 2019, J KING SAUD UNIV-COM, V31, P208, DOI 10.1016/j.jksuci.2017.01.005
   Wang XY, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11030567
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P10301, DOI 10.1007/s11042-020-10101-6
   Weihua Zhu, 2010, 2010 International Conference on Anti-Counterfeiting, Security and Identification (2010 ASID), P20, DOI 10.1109/ICASID.2010.5551484
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xu C, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420500601
   Yang YG, 2021, INFORM SCIENCES, V562, P304, DOI 10.1016/j.ins.2021.01.041
   Ye GD, 2016, SECUR COMMUN NETW, V9, P2015, DOI 10.1002/sec.1458
   Zhang W, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22010073
   Zhang XC, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/9524080
   Zhang Y, 2021, INFORM SCIENCES, V550, P313, DOI 10.1016/j.ins.2020.10.026
   Zheng JM, 2020, MULTIMED TOOLS APPL, V79, P29901, DOI 10.1007/s11042-020-09454-9
NR 38
TC 2
Z9 2
U1 6
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 26
PY 2023
DI 10.1007/s11042-023-17418-y
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2WU9
UT WOS:001090292500009
DA 2024-07-18
ER

PT J
AU Zhao, HX
   Xie, SC
   Zhang, JZ
AF Zhao, Hongxiang
   Xie, Shucui
   Zhang, Jianzhong
TI Fast image encryption based on new cascade chaotic system and Rubik's
   cube strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chaotic system; Dynamical analysis; Fast image encryption; Short
   keystream; Rubik's permutation
ID ALGORITHM; MAP; COMBINATION; SCHEME
AB The strength and effectiveness of a chaotic image cryptosystem are closely related to the complexity of the used chaotic maps. This paper first introduces an enhanced chaotic model called Arc Cotangent and Cotangent Chaotic Model (ACCCM) to generate improved chaotic properties. Dynamical analysis indicates that the enhanced systems exhibit an extensive chaotic range, unpredictable orbit and uniform outputs. In order to improve the strengths and efficiency of encryption, this paper presents a novel image encryption scheme. The scheme consists of a new sequence generator, Rubik's permutation, and row-wise diffusion. Firstly, the sequence generator is utilized to generate a short keystream for encryption process, where the total keystream only requires 12/m of image size. This module can effectively reduce computational costs and counteract dynamical degradation. Secondly, the permutation phase can randomly break the high spatial correlation by rotating different sections of Rubik's cube. To further accelerate execution speed while ensuring sufficient security, a row-wise diffusion with random selection is performed to modify pixel values efficiently. Security analysis shows that the scheme has the advantages of high security level and fast running speed. Considering images with a size of 256 x 256, our scheme processes images in real-time at 83 frames per second. This indicates that it is well suited for real-time image encryption tasks.
C1 [Zhao, Hongxiang] Xian Univ Posts & Telecommun, Sch Cyberspace Secur, Xian, Peoples R China.
   [Xie, Shucui] Xian Univ Posts & Telecommun, Sch Sci, Xian, Peoples R China.
   [Zhang, Jianzhong] Shaanxi Normal Univ, Coll Math & Informat Sci, Xian, Peoples R China.
C3 Xi'an University of Posts & Telecommunications; Xi'an University of
   Posts & Telecommunications; Shaanxi Normal University
RP Zhao, HX (corresponding author), Xian Univ Posts & Telecommun, Sch Cyberspace Secur, Xian, Peoples R China.
EM Hungxiang_Zhao@163.com
OI Zhao, Hongxiang/0000-0002-7891-5193
FU The authors did not receive support from any organization for the
   submitted work.
FX The authors did not receive support from any organization for the
   submitted work.
CR Alawida M, 2019, IEEE ACCESS, V7, P150609, DOI 10.1109/ACCESS.2019.2947561
   Alawida M, 2019, NONLINEAR DYNAM, V96, P601, DOI 10.1007/s11071-019-04809-w
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Bassham L. E., 2010, SPECIAL PUBLICATION
   Chen LP, 2021, SIGNAL PROCESS-IMAGE, V97, DOI 10.1016/j.image.2021.116363
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Ding Y, 2021, IEEE INTERNET THINGS, V8, P1504, DOI 10.1109/JIOT.2020.3012452
   ElKamchouchi DH, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020180
   Fang PF, 2022, MULTIMED TOOLS APPL, V81, P21811, DOI 10.1007/s11042-022-12092-y
   Fridrich J, 1997, IEEE SYS MAN CYBERN, P1105, DOI 10.1109/ICSMC.1997.638097
   Guesmi R, 2021, MULTIMED TOOLS APPL, V80, P1925, DOI 10.1007/s11042-020-09672-1
   Hu GZ, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107790
   Hua ZY, 2020, IEEE T IND INFORM, V16, P887, DOI 10.1109/TII.2019.2923553
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2019, IEEE T IND ELECTRON, V66, P1273, DOI 10.1109/TIE.2018.2833049
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2018, IEEE T IND ELECTRON, V65, P2557, DOI 10.1109/TIE.2017.2736515
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Ismail R, 2023, MULTIMED TOOLS APPL, V82, P22213, DOI 10.1007/s11042-022-13343-8
   Jiang DH, 2021, SIGNAL PROCESS, V188, DOI 10.1016/j.sigpro.2021.108220
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Liu BC, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/4926937
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Lu Q, 2020, IEEE ACCESS, V8, P25664, DOI 10.1109/ACCESS.2020.2970806
   Mansouri A, 2021, INFORM SCIENCES, V563, P91, DOI 10.1016/j.ins.2021.02.022
   Mansouri A, 2020, INFORM SCIENCES, V520, P46, DOI 10.1016/j.ins.2020.02.008
   Naseer Y, 2020, MATH COMPUT SIMULAT, V178, P207, DOI 10.1016/j.matcom.2020.06.007
   National Institute of Standards and Technology, 2001, Advanced Encryption Standard (AES)
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Song W, 2022, SIGNAL PROCESS-IMAGE, V102, DOI 10.1016/j.image.2021.116628
   Vidhya R, 2022, J KING SAUD UNIV-COM, V34, P2000, DOI 10.1016/j.jksuci.2019.12.014
   Wang MX, 2018, OPT LASER TECHNOL, V108, P558, DOI 10.1016/j.optlastec.2018.07.052
   Wang XY, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105581
   Wang XY, 2019, NONLINEAR DYNAM, V95, P2797, DOI 10.1007/s11071-018-4723-y
   Wang XY, 2014, DIGIT SIGNAL PROCESS, V25, P244, DOI 10.1016/j.dsp.2013.10.020
   Wheeler D. D., 1991, Cryptologia, V15, P140, DOI 10.1080/0161-119191865821
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xian YJ, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106202
   Xiang HY, 2021, MULTIMED TOOLS APPL, V80, P19237, DOI 10.1007/s11042-021-10680-y
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Yang CX, 2022, NONLINEAR DYNAM, V109, P2103, DOI 10.1007/s11071-022-07534-z
   Yang S, 2023, MULTIMED TOOLS APPL, V82, P25559, DOI 10.1007/s11042-023-14394-1
   Yao SY, 2019, OPT LASER TECHNOL, V120, DOI 10.1016/j.optlastec.2019.105703
   Zhang MM, 2023, PROPULS POWER RES, V12, P138, DOI 10.1016/j.jppr.2022.02.004
   Zhang Y, 2020, IEEE ACCESS, V8, P94810, DOI 10.1109/ACCESS.2020.2995839
   Zhang Y, 2020, INFORM SCIENCES, V520, P177, DOI 10.1016/j.ins.2020.02.012
   Zhao HX, 2021, OPTIK, V230, DOI 10.1016/j.ijleo.2021.166307
   Zhao HX, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.2.023007
   Zhao JB, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-18079-x
   Zheng J, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109863
   Zheng J, 2018, NONLINEAR DYNAM, V94, P1535, DOI 10.1007/s11071-018-4440-6
   Zhou KL, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105769
   Zhou KL, 2019, DIGIT SIGNAL PROCESS, V93, P115, DOI 10.1016/j.dsp.2019.07.013
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu CX, 2018, IEEE ACCESS, V6, P18759, DOI 10.1109/ACCESS.2018.2817600
   Zhu HG, 2021, MATH COMPUT SIMULAT, V185, P754, DOI 10.1016/j.matcom.2021.02.009
NR 61
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 24
PY 2023
DI 10.1007/s11042-023-16936-z
EA OCT 2023
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0VW7
UT WOS:001088903700009
DA 2024-07-18
ER

PT J
AU Dittakan, K
   Prompitak, K
   Thungklang, P
   Wongwattanakit, C
AF Dittakan, Kwankamon
   Prompitak, Kamontorn
   Thungklang, Phutphisit
   Wongwattanakit, Chatchawan
TI Image caption generation using transformer learning methods: a case
   study on instagram image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image Captioning; Transformer Learning Model; Self-Attention Mechanism;
   Encoder-Decoder; Image feature extraction; Instagram image
AB Nowadays, images are being used more extensively for communication purposes. A single image can convey a variety of stories, depending on the perspective and thoughts of everyone who views it. To facilitate comprehension, inclusion image captions is highly beneficial, especially for individuals with visual impairments who can read Braille or rely on audio descriptions. The purpose of this research is to create an automatic captioning system that is easy to understand and quick to generate. This system can be applied to other related systems. In this research, the transformer learning process is applied to image captioning instead of the convolutional neural networks (CNN) and recurrent neural networks (RNN) process which has limitations in processing long-sequence data and managing data complexity. The transformer learning process can handle these limitations well and more efficiently. Additionally, the image captioning system was trained on a dataset of 5,000 images from Instagram that were tagged with the hashtag "Phuket" (#Phuket). The researchers also wrote the captions themselves to use as a dataset for testing the image captioning system. The experiments showed that the transformer learning process can generate natural captions that are close to human language. The generated captions will also be evaluated using the Bilingual Evaluation Understudy (BLEU) score and Metric for Evaluation of Translation with Explicit Ordering (METEOR) score, a metric for measuring the similarity between machine-translated text and human-written text. This will allow us to compare the resemblance between the researcher-written captions and the transformer-generated captions.
C1 [Dittakan, Kwankamon; Prompitak, Kamontorn; Thungklang, Phutphisit; Wongwattanakit, Chatchawan] Prince Songkla Univ, Coll Comp, Phuket Campus, Phuket, Thailand.
   [Dittakan, Kwankamon; Prompitak, Kamontorn; Thungklang, Phutphisit; Wongwattanakit, Chatchawan] Prince Songkla Univ, Fac Hospitality & Tourism, Phuket Campus, Phuket, Thailand.
C3 Prince of Songkla University; Prince of Songkla University
RP Prompitak, K (corresponding author), Prince Songkla Univ, Coll Comp, Phuket Campus, Phuket, Thailand.; Prompitak, K (corresponding author), Prince Songkla Univ, Fac Hospitality & Tourism, Phuket Campus, Phuket, Thailand.
EM Kamontorn.p@phuket.psu.ac.th
CR Aneja J, 2018, PROC CVPR IEEE, P5561, DOI 10.1109/CVPR.2018.00583
   Banerjee S., 2005, P ACL WORKSH INTR EX, P65
   Cao DY, 2019, MULTIMED TOOLS APPL, V78, P35329, DOI 10.1007/s11042-019-08116-9
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Das R, 2022, MULTIMED TOOLS APPL, V81, P10051, DOI 10.1007/s11042-022-12042-8
   Deorukhkar KP, 2022, SENS IMAGING, V23, DOI 10.1007/s11220-022-00400-7
   Dixon S, 2022, Instagram: active users 2018
   Dosovitskiy A, 2020, 9 INT C LEARN REPR C
   Ghandi T, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3617592
   Gupta N, 2020, NEURAL COMPUT APPL, V32, P17899, DOI 10.1007/s00521-019-04515-z
   Herdade S, 2019, ADV NEUR IN, V32
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Kim DJ, 2022, IEEE T PATTERN ANAL, V44, P7348, DOI 10.1109/TPAMI.2021.3119754
   Kim DJ, 2019, PROC CVPR IEEE, P6264, DOI 10.1109/CVPR.2019.00643
   Liu W., 2021, arXiv, DOI DOI 10.48550/ARXIV.2101.10804
   Longteng Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10324, DOI 10.1109/CVPR42600.2020.01034
   MongoDB, 2019, What Is MongoDB
   Mookdarsanit P., 2020, Int J Appl Comp Inform Syst, V10, P40
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Python, 2022, Urllib.Request-Extensible library for opening URLs
   Shah F. M., 2022, SN Computer Science, V3, P1
   Shao Z, 2023, IEEE T MULTIMEDIA, V25, P8753, DOI 10.1109/TMM.2023.3241517
   Shao Zhuang, 2022, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2022.3152990
   Singh A, 2021, MULTIMED TOOLS APPL, V80, P35721, DOI 10.1007/s11042-021-11106-5
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang YY, 2022, AAAI CONF ARTIF INTE, P2585
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zhang W, 2019, 2019 34RD YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P521, DOI [10.1109/yac.2019.8787715, 10.1109/YAC.2019.8787715]
   Zhu XX, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050739
NR 33
TC 1
Z9 1
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17275-9
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000014
DA 2024-07-18
ER

PT J
AU Li, HJ
   Sun, XH
   Chen, MY
AF Li, Hongjun
   Sun, Xiaohu
   Chen, Mingyi
TI Appearance-motion heterogeneous networks for video anomaly detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video anomaly detection; Heterogeneous network; U-Net; Key-value
   network; Mainfold distribution
ID EVENT DETECTION
AB Video anomaly detection, an important aspect of intelligent surveillance systems, is an important challenge to effectively distinguish the appearance and motion differences between normal and anomalous events. However, previous work either relies on single-scale appearance (spatial) features or motion (temporal) features or treats them indiscriminately, making the model unable to exploit information specific to both. Secondly, existing clustering methods are susceptible to high-dimensional spatial "chain" mainfold distribution, which affects the accuracy of anomaly detection. In this paper, we propose a novel unsupervised prediction network, the appearance-motion heterogeneous network (AMHN) for video anomaly detection. The AMHN consists of a spatial convolutional auto-encoder (CAE) for learning appearance normality, a temporal U-Net auto-encoder for learning motion normality, and a key-value network for alleviating the "chain" mainfold distribution of apparent-motion features in high-dimensional space. In the testing phase, normal and anomalous events are distinguished by generating a regular score for each sample. The proposed AMHN framework outperforms the state-of-the-art methods with AUCs 96.71%, 86.70% and 73.88% on UCSD Ped2, CHUK Avenue and ShanghaiTech datasets, respectively.
C1 [Li, Hongjun; Sun, Xiaohu; Chen, Mingyi] Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.
   [Li, Hongjun] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nantong University; Nanjing University
RP Li, HJ (corresponding author), Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.; Li, HJ (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
EM lihongjun103@126.com; 2010310052@stmail.ntu.edu.cn;
   2110310018@stmail.ntu.edu.cn
OI li, hongjun/0000-0001-7500-4979; sun, xiao hu/0000-0002-5501-5424
FU National Natural Science Foundation of China [61976120]; Nanjing
   University State Key Lab. for Novel Software Technology [KFKT2019B15];
   College Students' Innovation and Entrepreneurship Training Project
   [202310304160Y]
FX This work is supported in part by National Natural Science Foundation of
   China under Grant 61976120, in part by Nanjing University State Key Lab.
   for Novel Software Technology under Grant KFKT2019B15, and College
   Students' Innovation and Entrepreneurship Training Project Project No.
   202310304160Y.
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Chang YP, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108213
   Chen DY, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103915
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Chung J., 2014, NIPS 2014 WORKSH DEE
   Das R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P358, DOI 10.18653/v1/P17-2057
   Georgescu MI, 2021, PROC CVPR IEEE, P12737, DOI 10.1109/CVPR46437.2021.01255
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hyunjong Park, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14360, DOI 10.1109/CVPR42600.2020.01438
   Ionescu RT, 2019, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2019.00803
   Ionescu RT, 2019, IEEE WINT CONF APPL, P1951, DOI 10.1109/WACV.2019.00212
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Jia YY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P438
   Jin DL, 2018, INT C PATT RECOG, P1574, DOI 10.1109/ICPR.2018.8545794
   Kim J, 2009, PROC CVPR IEEE, P2913
   Kingma D. P., 2014, arXiv
   Kumar A., 2014, Seisan Kenkyu, V66, P101
   Kumar A, 2013, 2013 2ND INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT IN THE KNOWLEDGE ECONOMY (IMKE), P14
   Li BR, 2021, NEUROCOMPUTING, V463, P109, DOI 10.1016/j.neucom.2021.07.059
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2021, IEEE T PATTERN ANAL, V43, P1070, DOI 10.1109/TPAMI.2019.2944377
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Ma C, 2018, PROC CVPR IEEE, P6975, DOI 10.1109/CVPR.2018.00729
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Markovitz Amir, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10536, DOI 10.1109/CVPR42600.2020.01055
   Maruf S, 2017, P 55 ASS COMP LING A
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Paszke A., 2017, NIPS W
   Ravanbakhsh M, 2019, IEEE WINT CONF APPL, P1896, DOI 10.1109/WACV.2019.00206
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy PR, 2019, 2019 16TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2019), P65, DOI 10.1109/CRV.2019.00017
   Sabokrou M, 2018, PROC CVPR IEEE, P3379, DOI 10.1109/CVPR.2018.00356
   Sukhbaatar S, 2015, ADV NEUR IN, V28
   Sun QR, 2017, PATTERN RECOGN, V64, P187, DOI 10.1016/j.patcog.2016.09.016
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   Villegas Ruben, 2017, ICLR
   Weston Jason, 2015, P INT C LEARN REPR I
   Xiao CJ, 2018, AAAI CONF ARTIF INTE, P1455
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Yan SY, 2020, IEEE T COGN DEV SYST, V12, P30, DOI 10.1109/TCDS.2018.2883368
   Yang F, 2017, P C EMP METH NAT LAN, P1400
   Ye MC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1805, DOI 10.1145/3343031.3350899
   Zhang Y, 2016, PATTERN RECOGN, V51, P443, DOI 10.1016/j.patcog.2015.09.005
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zhou JT, 2020, IEEE T CIRC SYST VID, V30, P4639, DOI 10.1109/TCSVT.2019.2962229
NR 49
TC 0
Z9 0
U1 14
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17382-7
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000007
DA 2024-07-18
ER

PT J
AU Agarwal, A
   Gupta, S
   Vashishath, M
AF Agarwal, Archana
   Gupta, Shailender
   Vashishath, Munish
TI Contrast enhancement of underwater images using conditional generative
   adversarial network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CGAN; Contrast enhancement; Machine learning
ID ADAPTIVE HISTOGRAM EQUALIZATION
AB The scattering effect of light and the presence of water organism deteriorates image quality captured in underwater environment. Researchers have made several proposals to improve the quality of these images using traditional image processing methods. Some of them are specific to underwater images while others are used for generalized purpose. Both these categories can deal with noise, such as explicit modeling, which usually leads to problems of low contrast and color deviation, but are unable to extract image features due to lack of prior knowledge of experts. Recently, machine learning approaches have gained popularity due to its ability to automate image processing task. Also, its efficiency and scalability is good. Therefore, this paper employ Conditional Generative Adversarial Network (CGAN) to synthesize unlabeled images and generate congruent data to original data. The proposed model consists of generator and discriminator. The former maps the features of input image to corresponding high-contrast image while the generated image and real image are passed to the later for the classification purpose. Result analysis illustrates that the proposed framework not only depicts the best Absolute Mean Brightness Error (AMBE), contrast, and Contrast Improvement Index (CII) parameters compared to available mechanisms in the literature but also shows Average Information Content (AIC), Peak Signal to Noise Ratio (PSNR), Structural Similarity Index Measurement (SSIM) and Degree of Entropy Un-preservation (DEU) are 99.84%, 99.63%, 97.61% and 98.33% similar to expected outcome. Also, when the technique is compared to the state of art techniques given in literature, the performance is quite good.
C1 [Agarwal, Archana; Gupta, Shailender; Vashishath, Munish] JC Bose Univ Sci & Technol, YMCA, Faridabad, Haryana, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Gupta, S (corresponding author), JC Bose Univ Sci & Technol, YMCA, Faridabad, Haryana, India.
EM archana_aggrawal@yahoo.co.in; Shailender81@gmail.com;
   munish.vashishath@gmail.com
RI gupta, shailender/Y-8231-2019
OI gupta, shailender/0000-0003-1383-7152
CR Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   [Anonymous], 2017, Inter J Innovative Res Elect Electron Instrum Control Eng
   Cao G, 2018, COMPUT ELECTR ENG, V66, P569, DOI 10.1016/j.compeleceng.2017.09.012
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Fazli S, 2013, IRAN CONF MACH, P131, DOI 10.1109/IranianMVIP.2013.6779964
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Huang LD, 2015, IET IMAGE PROCESS, V9, P908, DOI 10.1049/iet-ipr.2015.0150
   Isola P, 2018, Arxiv, DOI arXiv:1611.07004
   Jabeen A, 2016, IEEE SENS J, V16, P7534, DOI 10.1109/JSEN.2016.2600483
   Jan LM, 2016, J DISP TECHNOL, V12, P368, DOI 10.1109/JDT.2015.2491998
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Li CL, 2020, IEEE ACCESS, V8, P169887, DOI 10.1109/ACCESS.2020.3023485
   Liu JH, 2017, IEEE GEOSCI REMOTE S, V14, P1715, DOI 10.1109/LGRS.2017.2730247
   Liu SL, 2017, J VIS COMMUN IMAGE R, V48, P169, DOI 10.1016/j.jvcir.2017.05.011
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Mohan S, 3 INT C COMP NETW CO
   Muniyappan S, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATIONS AND NETWORKING TECHNOLOGIES (ICCCNT)
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2543, DOI 10.1109/TCE.2010.5681139
   Ooi CH, 2009, IEEE T CONSUM ELECTR, V55, P2072, DOI 10.1109/TCE.2009.5373771
   Othman MK., 2022, UHD J SCI TECHNOL, V6, P135, DOI [10.21928/uhdjst.v6n2y2022.pp135-146, DOI 10.21928/UHDJST.V6N2Y2022.PP135-146]
   Padmavathi G, 2010, INT J COMPUT SCI NET, V10, P58
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Poddar S, 2013, IET IMAGE PROCESS, V7, P641, DOI 10.1049/iet-ipr.2012.0507
   Ronneberger O, 2015, Arxiv, DOI [arXiv:1505.04597, DOI 10.48550/ARXIV.1505.04597]
   Shi HY, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881417711683
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Suresh S., 2017, IEEE J Sel Top ApplEarth Obs Remote Sens, V10, P1
   Tylecek R, 2013, LECT NOTES COMPUT SC, V8142, P364, DOI 10.1007/978-3-642-40602-7_39
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wei C, 2018, Arxiv, DOI arXiv:1808.04560
   Wenhao Z, 2017, VISUAL COMMUN-US, P1
NR 35
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-17158-z
EA OCT 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU6C6
UT WOS:001155215300004
DA 2024-07-18
ER

PT J
AU Acharya, U
   Banerjea, S
   Rajitha, B
AF Acharya, Utsav
   Banerjea, Shashwati
   Rajitha, B.
TI SRC<sub>2</sub>: a novel deep learning based technique for identifying
   COVID-19 using images of chest x-ray
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE COVID-19; Deep learning; DenseNet; SVM; Decision tree; CNN; Adaboost
ID NETWORK
AB COVID-19 has affected more than 520 million population worldwide by April 2022. Few medical examinations such as rapid antigen and RT-PCR are recommended for timely diagnosis of COVID-19. However, RT-PCR and other similar type of tests can show the presence of virus only within eight to thirteen days. Furthermore, the chest related complications that arise as a result of COVID-19 (such as pneumonia and Acute Respiratory Distress Syndrome (ARDS)) cannot be diagnosed through these tests. In the present article, we have roposed a deep Convolutional Neural Network (CNN) based model, named SRC2 that can differentiate between a normal and COVID-19 affected Chest X-Ray image. The proposed model consists of two modules, SRC2F and SRC2C for feature extraction and classification respectively. We have done feature extraction using existing trained CNN models and our proposed model SRC2F. Then, we have implemented standard classifiers and our proposed classifier SRC2C over the extracted features. Finally, we have compared the performance of our proposed Feature extractor module and classification module. Experimental results show that our proposed model SRC(2 )has obtained an accuracy of 98.68 percent which is better than the existing methods.
C1 [Acharya, Utsav; Banerjea, Shashwati; Rajitha, B.] Motilal Nehru Natl Inst Technol Allahabad, Prayagraj, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Rajitha, B (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Prayagraj, India.
EM rajitha@mnnit.ac.in
CR Agnihotri A, 2023, 2023 INT C ADV COMP
   Alablani IAL, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13101675
   Alghamdi MMM, 2023, COGENT ENG, V10, DOI 10.1080/23311916.2023.2181917
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Bhattacharyya A, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103182
   Chaudhary PK, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104454
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chouhan V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020559
   Dong Y, 2017, 2017 IEEE ACM INT C
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   George GS, 2023, BIOCYBERN BIOMED ENG, V43, P1, DOI 10.1016/j.bbe.2022.11.003
   Ghoshal B, 2020, Arxiv, DOI [arXiv:2003.10769, 10.48550/arXiv.2003.10769]
   Gunraj H, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.608525
   Guo HQ, 2020, J DENT SCI, V15, P564, DOI 10.1016/j.jds.2020.02.002
   Gupta A, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106859
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hemdan E. E. D., 2020, arXiv, DOI [DOI 10.48550/ARXIV.2003.11055, 10.48550/arXiv.2003.11055]
   Hussein HI, 2023, EXPERT SYST APPL, V223, DOI 10.1016/j.eswa.2023.119900
   Jain R, 2021, APPL INTELL, V51, P1690, DOI 10.1007/s10489-020-01902-1
   Kaggle, 2020, Chest X-Ray images (Pneumonia) dataset
   Kesim E, 2019, 2019 SCIENTIFIC MEETING ON ELECTRICAL-ELECTRONICS & BIOMEDICAL ENGINEERING AND COMPUTER SCIENCE (EBBT), DOI 10.1109/ebbt.2019.8742050
   Kirar BS, 2023, MACHINE INTELLIGENCE, V1
   Liu C, 2017, IEEE IMAGE PROC, P2314, DOI 10.1109/ICIP.2017.8296695
   Maghdid HS, 2021, PROC SPIE, V11734, DOI 10.1117/12.2588672
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Cohen JP, 2020, Arxiv, DOI [arXiv:2003.11597, DOI 10.48550/ARXIV.2003.11597, 10.48550/arXiv.2003.11597]
   Rajpurkar P, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002686
   Rattanawin P, 2023, 2023 15 INT C KNOWL
   Rothan HA, 2020, J AUTOIMMUN, V109, DOI 10.1016/j.jaut.2020.102433
   Sahin ME, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103977
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Soundrapandiyan R, 2023, COMPUT ELECTR ENG, V108, DOI 10.1016/j.compeleceng.2023.108711
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Ukwandu Ogechukwu, 2022, Healthc Anal (N Y), V2, P100096, DOI 10.1016/j.health.2022.100096
   Wang LD, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76550-z
   Wang SH, 2021, INFORM FUSION, V67, P208, DOI 10.1016/j.inffus.2020.10.004
   Xu SJ, 2019, IEEE ACCESS, V7, P4466, DOI 10.1109/ACCESS.2018.2885997
   Zebin T, 2021, APPL INTELL, V51, P1010, DOI 10.1007/s10489-020-01867-1
   Zuo WX, 2019, IEEE ACCESS, V7, P32510, DOI 10.1109/ACCESS.2019.2903587
NR 39
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 10
PY 2023
DI 10.1007/s11042-023-16983-6
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2RB1
UT WOS:001083315100011
DA 2024-07-18
ER

PT J
AU Behera, NKS
   Sa, PK
   Bakshi, S
   Bilotti, U
AF Behera, Nayan Kumar Subhashis
   Sa, Pankaj Kumar
   Bakshi, Sambit
   Bilotti, Umberto
TI Explainable graph-attention based person re-identification in outdoor
   conditions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Visual surveillance; Person re-identification; Explainable person
   re-identification; Graph-attention network; Graph convolutional network
ID NEURAL-NETWORK; RE-RANKING; CONVOLUTION; BRIDGE; GAP
AB Person re-identification is the process of recognizing an individual across multiple camera views. It is essential for an extensive range of applications related to security and biometrics. We propose a shift in perspective for the ongoing re-identification studies. Present graph-based person re-identification methods need to explain the importance of graph attention and convolution techniques. However, our proposed method focuses on a less intrusive and explainable approach to attention selection and graph convolution methods. The proposed multi-channel framework utilizes visual features and attribute labels to represent each person uniquely. We applied large-scale benchmark datasets, such as MSMT17, DukeMTMC, CUHK03, and Market-1501.
C1 [Behera, Nayan Kumar Subhashis; Sa, Pankaj Kumar; Bakshi, Sambit] Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Rourkela 769008, Odisha, India.
   [Bilotti, Umberto] Univ Salerno, Dept Comp Sci, Salerno, Fisciano, Italy.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela; University of Salerno
RP Bakshi, S (corresponding author), Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Rourkela 769008, Odisha, India.
EM nksbehera@gmail.com; pankajksa@nitrkl.ac.in; sambitbaksi@gmail.com;
   ubilotti@unisa.it
RI Bakshi, Sambit/JDC-3355-2023; K, Pankaj/A-9362-2017
OI Bakshi, Sambit/0000-0002-6107-114X; 
FU This research is partially supported by a project titled "Deep learning
   applications for computer vision task" funded by NITROAA with support of
   Lenovo P920 workstation and NVIDIA Corporation with support of NVIDIA
   Titan V and Quadro RTX 8000 GPUs.; NVIDIA Corporation [RTX 8000 GPUs];
   NVIDIA Titan V
FX This research is partially supported by a project titled "Deep learning
   applications for computer vision task" funded by NITROAA with support of
   Lenovo P920 workstation and NVIDIA Corporation with support of NVIDIA
   Titan V and Quadro RTX 8000 GPUs.
CR Batool E, 2023, J SUPERCOMPUT, V79, P13090, DOI 10.1007/s11227-023-05169-4
   Bruna J, 2014, Arxiv, DOI [arXiv:1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Bukhari M, 2023, IMAGE VISION COMPUT, V132, DOI 10.1016/j.imavis.2023.104658
   Chen XQ, 2020, IEEE ACCESS, V8, P131352, DOI 10.1109/ACCESS.2020.3009653
   Guo JY, 2019, IEEE I CONF COMP VIS, P3641, DOI 10.1109/ICCV.2019.00374
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hosmer P, 2006, CAR C SECUR, P75
   Huang HJ, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102789
   Jiang B, 2021, IEEE T MULTIMEDIA, V24, P3218, DOI 10.1109/TMM.2021.3095789
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Karmakar A., 2021, arXiv, DOI DOI 10.48550/ARXIV.2105.00930
   Kim G, 2021, MULTIMED TOOLS APPL, V80, P29129, DOI 10.1007/s11042-021-11127-0
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Li H, 2019, IEEE INT CON MULTI, P694, DOI 10.1109/ICME.2019.00125
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2022, PROC CVPR IEEE, P7349, DOI 10.1109/CVPR52688.2022.00721
   Liu C, 2022, NEUROCOMPUTING, V483, P210, DOI 10.1016/j.neucom.2022.02.001
   Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39
   Liu HM, 2021, NEUROCOMPUTING, V423, P57, DOI 10.1016/j.neucom.2020.10.019
   Liu S, 2021, AAAI CONF ARTIF INTE, V35, P2172
   Maqsood M, 2023, FRONT COMPUT SCI-CHI, V17, DOI 10.1007/s11704-022-2050-4
   Matsukawa T, 2016, INT C PATT RECOG, P2428, DOI 10.1109/ICPR.2016.7900000
   Mazari A, 2019, P BMVC
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Nguyen BX, 2021, IEEE COMPUT SOC CONF, P3487, DOI 10.1109/CVPRW53098.2021.00388
   Pan HH, 2022, KNOWL-BASED SYST, V236, DOI 10.1016/j.knosys.2021.107300
   Quan RJ, 2019, IEEE I CONF COMP VIS, P3749, DOI 10.1109/ICCV.2019.00385
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Sun YF, 2021, IEEE T PATTERN ANAL, V43, P902, DOI 10.1109/TPAMI.2019.2938523
   Taherkhani F, 2021, Arxiv, DOI arXiv:2108.04352
   Veličkovic P, 2018, Arxiv, DOI arXiv:1710.10903
   Wang GC, 2019, AAAI CONF ARTIF INTE, P8933
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu JL, 2019, IEEE I CONF COMP VIS, P8320, DOI 10.1109/ICCV.2019.00841
   Nguyen BX, 2020, Arxiv, DOI arXiv:2009.04091
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xu YL, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P937, DOI 10.1145/2647868.2654965
   Yang F, 2019, PATTERN RECOGN, V86, P143, DOI 10.1016/j.patcog.2018.08.015
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2019, IEEE T IMAGE PROCESS, V28, P2976, DOI 10.1109/TIP.2019.2893066
   Yu YB, 2022, NEURAL PROCESS LETT, V54, P3201, DOI 10.1007/s11063-022-10757-1
   Zhang J, 2022, SIGNAL PROCESS-IMAGE, V107, DOI 10.1016/j.image.2022.116744
   Zhang YQ, 2022, INT CONF ACOUST SPEE, P2704, DOI 10.1109/ICASSP43922.2022.9747298
   Zhang Z, 2021, PROC CVPR IEEE, P12131, DOI 10.1109/CVPR46437.2021.01196
   Zhang Z, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108155
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
NR 50
TC 1
Z9 1
U1 6
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 10
PY 2023
DI 10.1007/s11042-023-16986-3
EA OCT 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2RB1
UT WOS:001083315100013
DA 2024-07-18
ER

PT J
AU Joshi, V
   Mitra, P
   Bose, S
AF Joshi, Vasudha
   Mitra, Pabitra
   Bose, Supratik
TI Multi-modal multi-head self-attention for medical VQA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical visual question answering; Multi-head self-attention;
   DistilBERT; VQA-Med 2019
ID QUESTION; MODEL
AB Medical Visual Question answering (MedVQA) systems provide answers to questions based on radiology images. Medical images are more complex than general images. They have low contrast and are very similar to one another. The difference between medical images can only be understood by medical practitioners. While general images have very high quality and their differences can easily be spotted by anyone. Therefore, methods used for general-domain Visual Question Answering (VQA) Systems can not be used directly. The performance of MedVQA systems depends mainly on the method used to combine the features of the two input modalities: medical image and question. In this work, we propose an architecturally simple fusion strategy that uses multi-head self-attention to combine medical images and questions of the VQA-Med dataset of the ImageCLEF 2019 challenge. The model captures long-range dependencies between input modalities using the attention mechanism of the Transformer. We have experimentally shown that the representational power of the model is improved by increasing the length of the embeddings, used in the transformer. We have achieved an overall accuracy of 60.0% which improves by 1.35% from the existing model. We have also performed the ablation study to elucidate the importance of each model component.
C1 [Joshi, Vasudha; Mitra, Pabitra] Indian Inst Technol, Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
   [Bose, Supratik] Varian Med Syst Inc, San Ramon, CA 94582 USA.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Joshi, V (corresponding author), Indian Inst Technol, Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
EM vasudhaj50@gmail.com; pabitra@gmail.com; supratik.bose@gmail.com
RI Joshi, Vasudha/KRO-7862-2024
OI Joshi, Vasudha/0009-0002-7425-4559
CR Abacha A. B., 2020, CLEF WORKING NOTES
   Abacha A. B., 2018, CLEF
   Abacha AB, 2019, CLEF (working notes), P2
   Al-Sadi A, 2021, PATTERN RECOGN LETT, V150, P57, DOI 10.1016/j.patrec.2021.07.002
   Allaouzi I, 2018, CLEF
   Alsentzer E., 2019, P 2 CLIN NAT LANG PR, V2019, P72, DOI [10.18653/v1/W19-1909, DOI 10.18653/V1/W19-1909]
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bansal M, 2019, CLEF
   Ben Abacha Asma, 2021, P CLEF 2021 C LABS E
   Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285
   Charikar M, 2004, THEOR COMPUT SCI, V312, P3, DOI 10.1016/S0304-3975(03)00400-6
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Gong HF, 2021, PROCEEDINGS OF THE 2021 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR '21), P456, DOI 10.1145/3460426.3463584
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Itri JN, 2018, RADIOGRAPHICS, V38, P1845, DOI 10.1148/rg.2018180021
   Kafle K, 2017, COMPUT VIS IMAGE UND, V163, P3, DOI 10.1016/j.cviu.2017.06.005
   Kazemi V, 2017, arXiv
   Khare Y, 2021, I S BIOMED IMAGING, P1033, DOI 10.1109/ISBI48211.2021.9434063
   Kim JH, 2018, ADV NEUR IN, V31
   Kingma D. P., 2014, arXiv
   Kornuta T, 2019, Arxiv, DOI arXiv:1905.12008
   Lau JJ, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.251
   Liu B, 2021, LECT NOTES COMPUT SC, V12902, P210, DOI 10.1007/978-3-030-87196-3_20
   Liu B, 2021, I S BIOMED IMAGING, P1650, DOI 10.1109/ISBI48211.2021.9434010
   Liu S, 2020, CLEF
   Lu JS, 2016, ADV NEUR IN, V29
   Manmadhan S, 2023, MULTIMED TOOLS APPL, V82, P34937, DOI 10.1007/s11042-023-14981-2
   McDonald RJ, 2015, ACAD RADIOL, V22, P1191, DOI 10.1016/j.acra.2015.05.007
   Pham N, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P239, DOI 10.1145/2487575.2487591
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Ren FJ, 2020, IEEE ACCESS, V8, P50626, DOI 10.1109/ACCESS.2020.2980024
   Rosen M.P, 2018, CLEF WORKING NOTES
   Sanh V, 2020, Arxiv, DOI arXiv:1910.01108
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Sharma D, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-98390-1
   Shi L., 2019, CLEF
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sitara NMS, 2021, CLEF WORKING NOTES, P1329
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Talafha B, 2018, CLEF
   Vaswani A, 2017, ADV NEUR IN, V30
   Verma H, 2020, CLEF WORKING NOTES
   Vu MH, 2020, IEEE T MED IMAGING, V39, P2856, DOI 10.1109/TMI.2020.2978284
   Xu J, 2020, IEEE SYMP COMP COMMU, P703, DOI 10.1109/iscc50000.2020.9219587
   Xu JJ, 2019, ADV NEUR IN, V32
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan X, 2019, Zhejiang university at imageclef 2019 visual question answering in the medical domain, P85
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Ye LW, 2019, PROC CVPR IEEE, P10494, DOI 10.1109/CVPR.2019.01075
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhou Y., 2018, CLEF
NR 57
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 10
PY 2023
DI 10.1007/s11042-023-17162-3
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2RB1
UT WOS:001083315100005
DA 2024-07-18
ER

PT J
AU Madhushree, B
   Kumar, HBB
   Chennamma, HR
AF Madhushree, B.
   Kumar, H. B. Basanth
   Chennamma, H. R.
TI An exhaustive review of authentication, tamper detection with
   localization and recovery techniques for medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical image; Localization; Signature; Tampering; Authentication;
   Watermarking
ID FRAGILE WATERMARKING SCHEME; DATA HIDING SCHEME; REVERSIBLE
   WATERMARKING; MULTIPLE WATERMARKING; LOSSLESS WATERMARKING; ROBUST
   WATERMARKING; ENHANCING SECURITY; INFORMATION; INTERPOLATION;
   COMPRESSION
AB In order to aim for diagnosis of disease and decision making, the medical imaging plays an important role in health science. Clinical pictures are portrayals of profoundly vulnerable computerized images, those can be tampered without leaving any visual clues. Hence it is challenging to keep up its credibility. However, as there are numerous ways to manipulate an image, correspondingly various strategies have also been proposed to safeguard the genuineness of medical images. This survey paper presents different techniques used for medical image authentication viz. watermarking, signature and hybrid techniques. The state-of-the-art techniques have attained promising results for authentication and tampering detection, but an efficient tampering localization and recovery have remained still as a challenge. This review article can be considered as a benchmark survey paper as it gives a complete comprehensive overview commencing from the evolution of medical image formats, types of medical imaging modalities and also provides an elaborative comparison over 40 research works in terms of prominent factors like type of medical image used, embedded region, embedded data, about the coverage of tampering localization and recovery along with the discussion on limitations and future works of each one.
C1 [Madhushree, B.; Chennamma, H. R.] JSS Sci & Technol Univ, Dept Comp Applicat, Mysuru 570006, India.
   [Kumar, H. B. Basanth] Pooja Bhagavat Mem Mahajana Post Grad Ctr, Dept Studies Comp Sci, Mysuru 570016, India.
C3 JSS Science & Technology University
RP Chennamma, HR (corresponding author), JSS Sci & Technol Univ, Dept Comp Applicat, Mysuru 570006, India.
EM madhushree0250@gmail.com; basanth.10@gmail.com; hrchennamma@jssstuniv.in
RI kumar b, harish/JGC-8338-2023
OI kumar b, harish/0000-0002-4145-5875
CR Acharya R, 2003, COMPUT BIOL MED, V33, P303, DOI 10.1016/S0010-4825(02)00083-5
   Al-Haj Ali, 2016, 2016 2nd International Conference on Information Management (ICIM), P40, DOI 10.1109/INFOMAN.2016.7477531
   Al-qdah M, 2018, Signal & Image Processing: An International Journal (SIPIJ), V9, DOI [10.2139/ssrn.3409803, DOI 10.2139/SSRN.3409803]
   Al-Qershi O. M., 2010, 2010 IEEE International Conference on Information Theory and Information Security, P151, DOI 10.1109/ICITIS.2010.5688743
   Al-Qershi OM, 2011, J DIGIT IMAGING, V24, P114, DOI 10.1007/s10278-009-9253-1
   Al-Shayea TK, 2019, MEASUREMENT, V148, DOI 10.1016/j.measurement.2019.07.041
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Ali TS, 2020, IEEE ACCESS, V8, P71974, DOI 10.1109/ACCESS.2020.2987615
   Ali Z, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11050710
   Amine K, 2023, MULTIMED TOOLS APPL, V82, P35401, DOI 10.1007/s11042-023-14792-5
   Amine K, 2023, MULTIMED TOOLS APPL, V82, P7901, DOI 10.1007/s11042-022-13649-7
   Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   Apostolidis KD, 2022, J IMAGING, V8, DOI 10.3390/jimaging8060155
   Arumugham S, 2019, ARAB J SCI ENG, V44, P9561, DOI 10.1007/s13369-019-03883-x
   Ayubi P, 2021, ARTIF INTELL REV, V54, P1237, DOI 10.1007/s10462-020-09877-8
   Babu S., 2019, Int J Intell Inf Syst, V7, P38
   Badshah G, 2016, J DIGIT IMAGING, V29, P216, DOI 10.1007/s10278-015-9822-4
   Balamurugan G, 2020, AIJR Abstracts, V24
   Balasamy K, 2023, IETE J RES, V69, P83, DOI 10.1080/03772063.2021.1893231
   Bamal R, 2019, MULTIMED TOOLS APPL, V78, P17899, DOI 10.1007/s11042-018-6820-9
   Bamal R, 2018, MULTIMED TOOLS APPL, V77, P12493, DOI 10.1007/s11042-017-4898-0
   Borra S, 2020, COMP M BIO BIO E-IV, V8, P345, DOI 10.1080/21681163.2019.1595730
   Cao F, 2003, COMPUT MED IMAG GRAP, V27, P185, DOI 10.1016/S0895-6111(02)00073-3
   Chen YC, 2008, COMPUT METH PROG BIO, V89, P282, DOI 10.1016/j.cmpb.2007.11.014
   Chen YP, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10080932
   Coatrieux G, 2013, IEEE J BIOMED HEALTH, V17, P1057, DOI 10.1109/JBHI.2013.2263533
   Das S, 2013, COMPUT METH PROG BIO, V111, P662, DOI 10.1016/j.cmpb.2013.05.027
   Dhole VS, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P752, DOI 10.1109/ICCUBEA.2015.150
   Eswaraiah R, 2014, INT J TELEMED APPL, V2014, DOI 10.1155/2014/984646
   Farri E, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-022-03771-7
   Fotopoulos V, 2008, IEEE INT C BIOINF BI, P910
   Ganic Emir., 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Giakoumaki A, 2006, MED BIOL ENG COMPUT, V44, P619, DOI 10.1007/s11517-006-0081-x
   Giakoumaki A, 2003, P ANN INT IEEE EMBS, V25, P856, DOI 10.1109/IEMBS.2003.1279900
   Giakoumaki A, 2006, IEEE T INF TECHNOL B, V10, P722, DOI 10.1109/TITB.2006.875655
   Gull S, 2020, J AMB INTEL HUM COMP, V11, P1799, DOI 10.1007/s12652-018-1158-8
   Guo XT, 2009, J DIGIT IMAGING, V22, P620, DOI 10.1007/s10278-008-9120-5
   Guo XT, 2009, J DIGIT IMAGING, V22, P53, DOI 10.1007/s10278-007-9043-6
   Guo XT, 2003, P SOC PHOTO-OPT INS, V5033, P350, DOI 10.1117/12.480450
   Hajjaji M.A., 2011, International Journal of Computer Science Issues
   Han BR, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5551520
   Iskandar MW, 2019, J PHYS CONF SER, V1192, DOI 10.1088/1742-6596/1192/1/012008
   Jabbar Amira K., 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/1963/1/012039
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kaissis GA, 2020, NAT MACH INTELL, V2, P305, DOI 10.1038/s42256-020-0186-1
   Kamil S, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12051222
   Kelkar Vishakha, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P131, DOI 10.1007/978-981-10-7895-8_11
   Khaldi Amine, 2023, Journal of Ambient Intelligence and Humanized Computing, P13901, DOI 10.1007/s12652-022-04101-7
   Khaldi A, 2023, MULTIMED TOOLS APPL, V82, P12211, DOI 10.1007/s11042-022-13724-z
   Khor HL, 2017, J DIGIT IMAGING, V30, P328, DOI 10.1007/s10278-016-9930-9
   Kumar B., 2011, J INF SECUR, V2, P91, DOI DOI 10.4236/JIS.2011.22009
   Kumar B., 2011, Eng Technol, V79, P2011
   Kumar V, 2023, INT J DIGIT CRIME FO, V15, DOI 10.4018/IJDCF.318666
   Kundu M. K., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1457, DOI 10.1109/ICPR.2010.360
   Lee HY, 2019, MULTIMED TOOLS APPL, V78, P19663, DOI 10.1007/s11042-019-7322-0
   Li-Qun Kuang, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1047, DOI 10.1109/ICISE.2009.60
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liew SC, 2011, Ph D Thesis
   Liew SC, 2013, J DIGIT IMAGING, V26, P316, DOI 10.1007/s10278-012-9484-4
   Liu J, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040700
   Liu YL, 2016, J VIS COMMUN IMAGE R, V39, P51, DOI 10.1016/j.jvcir.2016.05.008
   Madhu B., 2021, INDIAN J SCI TECHNOL, V14, P351, DOI DOI 10.17485/IJST/v14i4.1963
   Memon NA, 2011, INT J COMPUT MATH, V88, P265, DOI 10.1080/00207161003596690
   Moad MS, 2023, CYBERNET SYST, DOI 10.1080/01969722.2023.2166253
   Zain JM, 2011, Arxiv, DOI arXiv:1101.1603
   Naheed T, 2014, OPTIK, V125, P2515, DOI 10.1016/j.ijleo.2013.10.124
   Nayak J, 2004, Proceedings of the IEEE INDICON 2004, P147, DOI 10.1109/INDICO.2004.1497726
   Ou B, 2012, NEUROCOMPUTING, V93, P67, DOI 10.1016/j.neucom.2012.04.021
   Ouahi H, 2021, American Scientific Research Journal for Engineering Technology and Sciences, V76, P253
   Pan W, 2009, Data privacy management and autonomous spontaneous security, DOI [10.1007/978-3-642-11207-2_12, DOI 10.1007/978-3-642-11207-2_12]
   Parah SA, 2019, Security in smart cities: models, applications, and challenges, DOI [10.1007/978-3-030-01560-2, DOI 10.1007/978-3-030-01560-2]
   Parah SA, 2019, ADV UBIQUIT SENS APP, V2, P267, DOI 10.1016/B978-0-12-815368-0.00011-7
   Patra B., 2012, 2012 International Symposium on Intelligent Signal Processing and Communications Systems (ISPACS 2012), P430, DOI 10.1109/ISPACS.2012.6473528
   Piao CR, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P7, DOI 10.1109/CISP.2008.390
   Preda RO, 2014, 2014 10TH INTERNATIONAL CONFERENCE ON COMMUNICATIONS (COMM)
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Rai A, 2017, MULTIMED TOOLS APPL, V76, P18605, DOI 10.1007/s11042-016-4215-3
   Ranjani JJ, 2018, J INTELL SYST, V27, P19, DOI 10.1515/jisys-2017-0019
   Sahu A. K., 2023, SN Computer Science, V4, P222, DOI [10.1007/s42979-022-01657-1, DOI 10.1007/S42979-022-01657-1]
   Sayah Moad Med, 2023, Research on Biomedical Engineering, P167, DOI 10.1007/s42600-023-00261-3
   Seenivasagam V, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/516465
   Sharma A, 2017, WIRELESS PERS COMMUN, V92, P1611, DOI 10.1007/s11277-016-3625-x
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Shih FY, 2016, INFORM SCIENCES, V367, P648, DOI 10.1016/j.ins.2016.07.015
   Shih FY, 2005, INFORM SCIENCES, V175, P200, DOI 10.1016/j.ins.2005.01.013
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh A, 2016, 2016 39TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P511, DOI 10.1109/TSP.2016.7760932
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Soliman MM., 2012, Int J Smart Home, V6, P37
   Tan CK, 2011, J DIGIT IMAGING, V24, P528, DOI 10.1007/s10278-010-9295-4
   Thakur S, 2020, MULTIMED TOOLS APPL, V79, P4263, DOI 10.1007/s11042-018-6691-0
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Umamageswari A, 2014, J ENG RES-KUWAIT, V2, P87, DOI 10.7603/s40632-014-0015-y
   Umamageswari A, 2013, PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON CIRCUITS, POWER AND COMPUTING TECHNOLOGIES (ICCPCT 2013), P1116, DOI 10.1109/ICCPCT.2013.6528904
   Umamageswari A., 2014, INT J APPL ENG RES, V9, P12163
   Umamageswari A, 2013, ICTACT Journal on Image and Video Processing, V04
   Umamageswari A, 2014, Int J Comput Appl, V86
   Ustubioglu A, 2017, J DIGIT IMAGING, V30, P665, DOI 10.1007/s10278-017-9960-y
   Valandar MY, 2022, J INF SECUR APPL, V66, DOI 10.1016/j.jisa.2022.103160
   Wakatani A., 2002, Proceedings of the 35th Annual Hawaii International Conference on System Sciences, P2043, DOI 10.1109/HICSS.2002.994129
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   Wang ZH, 2013, J SYST SOFTWARE, V86, P315, DOI 10.1016/j.jss.2012.08.029
   Wong PW, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P455, DOI 10.1109/ICIP.1998.723526
   Wong YL, 2021, INT C DIG TRANSF APP, V25, P26
   Wu JHK, 2008, J DIGIT IMAGING, V21, P59, DOI 10.1007/s10278-007-9011-1
   Zain Jasni M, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P3270
   Zain JM, 2004, P ANN INT IEEE EMBS, V26, P3237
   Zear A, 2018, J INTELL SYST, V27, P5, DOI 10.1515/jisys-2016-0036
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 120
TC 2
Z9 2
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-16706-x
EA OCT 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX9N7
UT WOS:001142351700004
DA 2024-07-18
ER

PT J
AU Sivapriya, MS
   Fathimal, PM
AF Sivapriya, M. S.
   Fathimal, P. Mohamed
TI Iterative dual tree wavelet transform with posterior probability for sar
   despeckling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Synthetic aperture radar; Speckle noise; Wavelet transform; DWT; DTCWT;
   Posterior Probability
AB Speckle is a natural distortion produced by the interaction of backscattered waves from the target in active coherent imaging sensors like synthetic aperture radar (SAR). The presence of speckle in SAE images mainly restricts its usage in terms of ground target detection, information retrieval, and scene investigation. Numerous filtering techniques have been available in the literature to reduce speckles. Recently, wavelet transform approaches can be employed for the denoising purposes, which make use of a threshold value on the noisy image for sparse wavelet representation. However, the noisy image coefficients surpassing the threshold are the cause of spurious noise spikes over the discontinuities. Therefore, this study develops an iterative dual tree wavelet transform with posterior probability for SAR despeckling process. The proposed method works on the wavelet domain for efficient speckle noise reduction. The speckled image is fed to the Dual tree complex wavelet transform to produce six oriented wavelets which are then employed to the thresholding method. For fixing the threshold value, the posterior probability is used in each subband which in turn gives the threshold value concerning the distribution of coefficients. Furthermore, thresholding is applied on oriented wavelets for despeckling process. Entropy is calculated in each iteration for detecting the number of decomposition levels. The performance validation of the proposed model take place in terms of different measures. The experimental results stated that the proposed system is highly accurate than conventional 2D-DTCWT model.
C1 [Sivapriya, M. S.; Fathimal, P. Mohamed] SRM Inst Sci & Technol, Chennai, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Sivapriya, MS (corresponding author), SRM Inst Sci & Technol, Chennai, Tamil Nadu, India.
EM sivapriyaresearch@gmail.com; fathimap@srmist.edu.in
RI Fathimal, P.Mohamed/D-1409-2018
CR Ali SM, 2007, PROC WRLD ACAD SCI E, V25, P39
   Fracastoro G, 2021, IEEE GEOSC REM SEN M, V9, P29, DOI 10.1109/MGRS.2021.3070956
   Khosravi MR, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON POWER, CONTROL, SIGNALS AND INSTRUMENTATION ENGINEERING (ICPCSI), P212, DOI 10.1109/ICPCSI.2017.8392114
   Ma XS, 2020, IEEE T GEOSCI REMOTE, V58, P8807, DOI 10.1109/TGRS.2020.2990978
   Mohan RR, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2860, DOI 10.1109/TENCON.2016.7848566
   Mohanakrishnan P, 2024, APPL GEOMAT, V16, P313, DOI 10.1007/s12518-022-00420-8
   Singh P., 2016, Int J Eng Sci Res Technol, V5, P894
   Singh P, 2023, J ELECTRON IMAGING, V32, DOI 10.1117/1.JEI.32.2.021609
   Singh Pushkar., 2016, 2016 IEEE Region 10 Humanitarian Technology Conference (R10-HTC), P1
   Vijaykumar VR, 2012, 2012 4TH INTERNATIONAL CONFERENCE ON INTELLIGENT AND ADVANCED SYSTEMS (ICIAS), VOLS 1-2, P886, DOI 10.1109/ICIAS.2012.6306140
   Wang PY, 2017, IEEE SIGNAL PROC LET, V24, P1763, DOI 10.1109/LSP.2017.2758203
   Yommy AS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P158, DOI 10.1109/CISP.2015.7407868
   Zhang G, 2020, J APPL REMOTE SENS, V14, DOI 10.1117/1.JRS.14.026518
   Zhao Y, 2015, IEEE T GEOSCI REMOTE, V53, P2765, DOI 10.1109/TGRS.2014.2364525
   Zhou YY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212462
NR 15
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-16821-9
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX9N7
UT WOS:001142351700002
DA 2024-07-18
ER

PT J
AU Dixit, S
   Soni, N
AF Dixit, Shilpa
   Soni, Nitasha
TI Enhancing stock market prediction using three-phase classifier and
   EM-EPO optimization with news feeds and historical data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Stock Market; Stock Market Data; News Feeds; TF-IDF; CNN; Bi-LSTM; EMEPO
ID NETWORK
AB Stock price forecasting is a crucial area of research that demands a thorough comprehension of market dynamics and sophisticated analytical methods. Deep neural networks have recently demonstrated considerable potential for enabling academics to create extremely precise models for foretelling financial patterns. Another quickly developing technology is Natural language processing (NLP), which is increasingly used to evaluate financial data, notably news, and social media sentiment, and forecast the course of the market. An innovative deep learning-based stock market prediction model is created in this research paper. The historic stock market data and news feed as the information source. The acquired raw data (news data) are pre-processed using lowercase text conversion, punctuation removal, stop word removal, tokenization of sentences, normalization, and a bag of words technique. Then, from the pre-processed news data, the features such as Parts of Speech (PoS), Term Frequency-Inverse Document Frequency (TF-IDF), and N-gram-based features are extracted. In addition, the Moving Average Convergence/Divergence oscillator (MACD), and Relative Strength Index (RSI) based features are extracted from the historic stock market data. The extracted features from the historic stock market data and news feeds are fused. The optimal features are then chosen from the fused features using a new hybrid optimization model called Exchange Market Emperor Pigeon Optimization (EMEPO). The proposed EMEPO model is a combination of the standard Exchange Market Algorithm (EMA) and Emperor Pigeon Optimization (EPO). A new three-phase classifier is introduced in this research work, for accurate stock price forecasting. The proposed three-phase classifier includes Convolutional neural networks (CNN), Bidirectional long short-term memories (Bi-LSTM), and Autoencoder. The three-phase classifier is trained using the selected EMEPO-based features. The projected outcome from the three-phase classifier portrays the stock market prices. In all three feature selection events, the suggested method produces positive outcomes. In Case 1 (Open/Close), the Mean Absolute Error (MAE) value is 0.051582, suggesting a minimal average difference between the anticipated and actual values. The accuracy of the model in forecasting percentage errors is shown by the Mean Absolute Percentage Error (MAPE), which is 11.28154%. Similar results are obtained by the model in Case 2 (High/Low/Close), with an MAE of 0.056408 and a MAPE of 12.0081%. These results show how well the suggested strategy works for anticipating stock prices with accuracy.
C1 [Dixit, Shilpa; Soni, Nitasha] Manav Rachna Int Inst Res & Studies, CSE Fac Engn & Technol, Faridabad, India.
C3 Manav Rachna International Institute of Research & Studies
RP Dixit, S (corresponding author), Manav Rachna Int Inst Res & Studies, CSE Fac Engn & Technol, Faridabad, India.
EM shukla.shilpa24@gmail.com
CR Ahmad A, 2021, CHEMOMETR INTELL LAB, V208, DOI 10.1016/j.chemolab.2020.104214
   Akbar S, 2022, ARTIF INTELL MED, V131, DOI 10.1016/j.artmed.2022.102349
   Akbar S, 2020, CHEMOMETR INTELL LAB, V204, DOI 10.1016/j.chemolab.2020.104103
   Akhtar MM, 2022, J KING SAUD UNIV SCI, V34, DOI 10.1016/j.jksus.2022.101940
   Almalis I, 2022, KNOWL-BASED SYST, V258, DOI 10.1016/j.knosys.2022.109954
   [Anonymous], About Us
   Chaudhari K, 2023, EXPERT SYST APPL, V219, DOI 10.1016/j.eswa.2023.119527
   Chen JD, 2023, ENG APPL ARTIF INTEL, V121, DOI 10.1016/j.engappai.2023.106038
   Chen XT, 2022, NEUROCOMPUTING, V504, P1, DOI 10.1016/j.neucom.2022.06.106
   de Almeida RL, 2022, EXPERT SYST APPL, V204, DOI 10.1016/j.eswa.2022.117478
   Gao RZ, 2022, INFORM SCIENCES, V615, P529, DOI 10.1016/j.ins.2022.10.029
   Ingle V., 2021, Glob Trans Proc, V2, P47, DOI [10.1016/j.gltp.2021.01.008, DOI 10.1016/J.GLTP.2021.01.008]
   Jafari A, 2022, ENG APPL ARTIF INTEL, V116, DOI 10.1016/j.engappai.2022.105452
   kaggle, US
   Kanwal A, 2022, EXPERT SYST APPL, V202, DOI 10.1016/j.eswa.2022.117123
   Liu TT, 2022, KNOWL-BASED SYST, V252, DOI 10.1016/j.knosys.2022.109324
   Liu X, 2022, EXPERT SYST APPL, V204, DOI 10.1016/j.eswa.2022.117604
   Ma Y, 2023, INFORM FUSION, V91, P515, DOI 10.1016/j.inffus.2022.10.025
   Paramanik Rajendra N., 2020, Procedia Computer Science, V176, P330, DOI 10.1016/j.procs.2020.08.035
   Polamuri SR, 2022, J KING SAUD UNIV-COM, V34, P7433, DOI 10.1016/j.jksuci.2021.07.001
   Teng X, 2022, NEUROCOMPUTING, V505, P92, DOI 10.1016/j.neucom.2022.07.016
   Wang CH, 2022, COMPUT ELECTR ENG, V103, DOI 10.1016/j.compeleceng.2022.108285
   Wang CJ, 2022, EXPERT SYST APPL, V208, DOI 10.1016/j.eswa.2022.118128
   Wang WJ, 2021, EXPERT SYST APPL, V178, DOI 10.1016/j.eswa.2021.115022
   Xiong K, 2021, AI OPEN, V2, P168, DOI 10.1016/j.aiopen.2021.09.001
   Yan WL, 2023, N AM J ECON FINANC, V64, DOI 10.1016/j.najef.2022.101867
   Yang JH, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118800
   Yun KK, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115716
   Zhang DH, 2021, FUTURE GENER COMP SY, V115, P872, DOI 10.1016/j.future.2020.10.009
   Zhao YL, 2023, APPL SOFT COMPUT, V133, DOI 10.1016/j.asoc.2022.109921
NR 30
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-17184-x
EA OCT 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100006
DA 2024-07-18
ER

PT J
AU Mishra, S
   Bhatnagar, N
   Prakasam, P
   Sureshkumar, TR
AF Mishra, Swami
   Bhatnagar, Nehal
   Prakasam, P.
   Sureshkumar, T. R.
TI Speech emotion recognition and classification using hybrid deep CNN and
   BiLSTM model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Speech emotion recognition; Deep convolutional neural networks; LSTM;
   MFSC; Ensemble learning
ID SPECTROGRAM
AB Accurate emotion detection from speech utterances has been a challenging and active research affair recently. Speech emotion recognition (SER) systems play an essential role in Human-machine interaction, virtual reality, emergency services, and many other real-time systems. It is an open-ended problem as subjects from different regions and lingual backgrounds convey emotions altogether differently. The conventional approach used low-level periodic features from audio samples like energy, pitch, etc., for classification but was not efficient enough to detect emotions accurately and not generalized. With the recent advancements in computer vision and neural networks extracting high-level features and more accurate recognition can be achieved. This study proposes an ensemble deep CNN + Bi-LSTM-based framework for speech emotion recognition and classification of seven different emotions. The paralinguistic log Mel-frequency spectral coefficients (MFSC) is used as a feature to train the proposed architecture. The proposed Hybrid model is validated with TESS and SAVEE datasets. Experimental results have indicated a classification accuracy of 96.36%. The proposed model is compared with existing models, proving the superiority of the proposed hybrid deep CNN and Bi-LSTM model.
C1 [Mishra, Swami; Bhatnagar, Nehal; Prakasam, P.; Sureshkumar, T. R.] Vellore Inst Technol, Sch Elect Engn, Vellore, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Prakasam, P (corresponding author), Vellore Inst Technol, Sch Elect Engn, Vellore, India.
EM swami.mishra2017@vitsudent.ac.in; nehal.bhatnagar2017@vitsudent.ac.in;
   prakasam.p@vit.ac.in; trsureshkumar@vit.ac.in
RI P, Prakasam/B-3075-2016; T R, SureshKumar/M-8026-2014
OI P, Prakasam/0000-0002-2471-6375; T R, SureshKumar/0000-0002-5383-1882
CR Abbaschian BJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041249
   Abdelwahab M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5084, DOI 10.1109/ICASSP.2018.8461866
   Anvarjon T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185212
   Atmaja BT, 2022, SPEECH COMMUN, V140, P11, DOI 10.1016/j.specom.2022.03.002
   Chen J, 2021, NEURAL COMPUT APPL, V33, P8669, DOI 10.1007/s00521-020-05616-w
   Dangol R, 2020, MULTIMED TOOLS APPL, V79, P32917, DOI 10.1007/s11042-020-09693-w
   de Lope J, 2023, NEUROCOMPUTING, V528, P1, DOI 10.1016/j.neucom.2023.01.002
   Harár P, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P137, DOI 10.1109/SPIN.2017.8049931
   Jahangir R, 2021, MULTIMED TOOLS APPL, V80, P23745, DOI 10.1007/s11042-020-09874-7
   Jaiswal S, 2020, NEURAL COMPUT APPL, V32, P11253, DOI 10.1007/s00521-019-04564-4
   Kumbhar HS, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA), DOI 10.1109/iccubea47591.2019.9129067
   Lech M, 2020, FRONT COMP SCI-SWITZ, V2, DOI 10.3389/fcomp.2020.00014
   Likitha MS, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2257, DOI 10.1109/WiSPNET.2017.8300161
   Lotjidereshgi R, 2017, INT CONF ACOUST SPEE, P5135, DOI 10.1109/ICASSP.2017.7953135
   Luvembe AM, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103354
   Meng H, 2019, IEEE ACCESS, V7, P125868, DOI 10.1109/ACCESS.2019.2938007
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Mohan BJ, 2014, INT CONF ADV ELECTR
   Mohapatra A, 2022, MULTIMED TOOLS APPL, V81, P18503, DOI 10.1007/s11042-022-12764-9
   Monisha STA, 2022, ADV HUM-COMPUT INTER, V2022, DOI 10.1155/2022/9602429
   Mustaqeem, 2020, IEEE ACCESS, V8, P79861, DOI 10.1109/ACCESS.2020.2990405
   Neumann M, 2017, INTERSPEECH, P1263, DOI 10.21437/Interspeech.2017-917
   Schuller BW, 2018, COMMUN ACM, V61, P90, DOI 10.1145/3129340
   Shegokar P, 2016, 2016 10TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ICSPCS)
   Singh Jagjeet, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20065140
   Singh R, 2020, ARAB J SCI ENG, V45, P3111, DOI 10.1007/s13369-019-04293-9
   Sun CS, 2023, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.1075624
   Swain M, 2022, COMPLEX INTELL SYST, V8, P4237, DOI 10.1007/s40747-022-00713-w
   Tarantino L, 2019, INTERSPEECH, P2578, DOI 10.21437/Interspeech.2019-2822
   Tzinis E, 2017, INT CONF AFFECT, P190, DOI 10.1109/ACII.2017.8273599
   Tzirakis P, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5089, DOI 10.1109/ICASSP.2018.8462677
   Ullah S, 2022, P IEEE INT C IT IND, P01, DOI [10.1109/ICIT56493.2022.9989197, DOI 10.1109/ICIT56493.2022.9989197]
   Yadav A, 2020, 2020 11 INT C COMP C, P1, DOI [DOI 10.1109/ICCCNT49239.2020.9225614, 10.1109/ICCCNT49239.2020.9225614]
   Yadav A, 2020, CLUSTER COMPUT, V23, P2969, DOI 10.1007/s10586-020-03062-w
   Yenigalla P, 2018, INTERSPEECH, P3688, DOI 10.21437/Interspeech.2018-1811
   Yoon S, 2018, IEEE W SP LANG TECH, P112, DOI 10.1109/SLT.2018.8639583
   Zehra W, 2021, COMPLEX INTELL SYST, V7, P1845, DOI 10.1007/s40747-020-00250-4
   Zeng YN, 2019, MULTIMED TOOLS APPL, V78, P3705, DOI 10.1007/s11042-017-5539-3
   Zhang SQ, 2021, SPEECH COMMUN, V127, P73, DOI 10.1016/j.specom.2020.12.009
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   Zheng CJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010205
   Zong Y, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2537926
NR 42
TC 0
Z9 0
U1 6
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-16849-x
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100012
DA 2024-07-18
ER

PT J
AU Deepthi, BG
   Rani, KS
   Krishna, PV
   Saritha, V
AF Deepthi, B. Gnana
   Rani, K. Sandhya
   Krishna, P. Venkata
   Saritha, V.
TI An efficient architecture for processing real-time traffic data streams
   using apache flink
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Big Data; Big Data Processing; Stream Computing; Apache Flink
AB Big Data technologies emerging day by day and are making drastic changes in various real-world applications. Traditional data mining tools adequate to process volumes of data but from past decades the rapid growth in data becomes difficult for processing. Due to continuous flow of data, data streams require additional computational processing than the traditional one. Big data stream processing considers different features of the data streams heterogeneity, scalability, fault tolerance and query optimization. Efficient implementation of these features in real-world applications using big data analytics is a challenging job during data storage, processing, and analysis phases. Therefore, the proposed model FRTSPS is a generic architecture which is influenced by popular big data processing Lambda architecture, based on distributed computing platform. The architecture using open-source platform Apache Flink for doing data processing. Flink is a popular platform for processing historical and stream data flows at once parallelly. Its stateful streaming can obtain more scalability and flexibility along with high throughput and low latency than the remaining stream processing programming models.
C1 [Deepthi, B. Gnana; Rani, K. Sandhya; Krishna, P. Venkata; Saritha, V.] Sri Padmavati Mahila Visvavidyalayam, Dept Comp Sci & Engn, Tirupati, India.
C3 Sri Padmavati Mahila Vishwavidyalayam
RP Krishna, PV (corresponding author), Sri Padmavati Mahila Visvavidyalayam, Dept Comp Sci & Engn, Tirupati, India.
EM gdeepthi.bitra@gmail.com; sandhyaranikasireddy@yahoo.co.in;
   parimalavk@gmail.com; vsaritha@spmvv.ac.in
RI Krishna, Venkata/C-9554-2018
OI Krishna, Venkata/0000-0001-8138-5878
CR Akanbi A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113166
   Carbone P., 2015, IEEE DATA ENG B, V36, P28, DOI DOI 10.1109/IC2EW.2016.56
   Carbone P, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2651, DOI 10.1145/3318464.3383131
   Corral-Plaza D, 2020, COMPUT STAND INTER, V70, DOI 10.1016/j.csi.2020.103426
   De Mauro A, 2016, LIBR REV, V65, P122, DOI 10.1108/LR-06-2015-0061
   El Aboudi Naoual, 2018, Advances in Bioinformatics, V2018, P4059018, DOI 10.1155/2018/4059018
   Fragkoulis M, 2020, Arxiv, DOI arXiv:2008.00842
   Hasani Z., 2014, ICT INNOVATIONS, P133
   HoseinyFarahabady MR, 2020, 2020 20TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND INTERNET COMPUTING (CCGRID 2020), P629, DOI 10.1109/CCGrid49817.2020.00-30
   Isah H, 2019, IEEE ACCESS, V7, P154300, DOI 10.1109/ACCESS.2019.2946884
   Iwendi C, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8111331
   Jiang WW, 2022, APPL SYST INNOV, V5, DOI 10.3390/asi5010023
   Karri C, 2021, MULTIMED TOOLS APPL, V80, P18611, DOI 10.1007/s11042-020-10253-5
   Kiran M, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2785, DOI 10.1109/BigData.2015.7364082
   Li ZY, 2020, MOB INF SYST, V2020, DOI 10.1155/2020/5351824
   Limin Feng, 2020, 2020 International Conference on Intelligent Transportation, Big Data & Smart City (ICITBS). Proceedings, P473, DOI 10.1109/ICITBS49701.2020.00102
   Lopez MA, 2016, IEEE GLOB COMM CONF
   Mahapatra T, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00353-2
   Marques NC, 2016, IEEE INT CONF INF VI, P223, DOI 10.1109/IV.2016.72
   Nazari E., 2019, Frontiers in Health Informatics, V8, P14
   Probst L, 2018, IEEE INT CONF BIG DA, P548, DOI 10.1109/BigData.2018.8622592
   Puthal D, 2016, PROCEEDINGS OF 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS; IEEE 14TH INTERNATIONAL CONFERENCE ON SMART CITY; IEEE 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1218, DOI [10.1109/HPCC-SmartCity-DSS.2016.48, 10.1109/HPCC-SmartCity-DSS.2016.0170]
   Qadah E., 2018, In CEUR Workshop Proc, V2083, P109
   Rabl T, 2016, IT-INF TECHNOL, V58, P157, DOI 10.1515/itit-2016-0005
   Roriz M, 2019, J INTERNET SERV APPL, V10, DOI 10.1186/s13174-019-0107-x
   Shahverdi E, 2019, I C DATA ENGIN WORKS, P53, DOI 10.1109/ICDEW.2019.00-35
   Shen J, 2010, P 2010 ACM MULT WORK, P31, DOI DOI 10.1145/1877953.1877963
   Ta VD, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA 2016), P37, DOI 10.1109/ICCCBDA.2016.7529531
   Tantalaki N, 2020, INT J PARALLEL EMERG, V35, P571, DOI 10.1080/17445760.2019.1585848
   Van Dongen G, 2021, IEEE ACCESS, V9, P109413, DOI 10.1109/ACCESS.2021.3102645
   van Dongen G, 2021, IEEE ACCESS, V9, P93745, DOI 10.1109/ACCESS.2021.3093208
   van Dongen G, 2020, IEEE T PARALL DISTR, V31, P1845, DOI 10.1109/TPDS.2020.2978480
   Vanathi R, 2017, 2017 2ND WORLD CONGRESS ON COMPUTING AND COMMUNICATION TECHNOLOGIES (WCCCT), P97, DOI 10.1109/WCCCT.2016.32
   Venkataraman S, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P374, DOI 10.1145/3132747.3132750
NR 34
TC 0
Z9 0
U1 13
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 30
PY 2023
DI 10.1007/s11042-023-17151-6
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4DY8
UT WOS:001077522300004
DA 2024-07-18
ER

PT J
AU Al-Ghuraybi, HA
   Alzain, MA
   Soh, B
AF Al-Ghuraybi, Hind A.
   Alzain, Mohammed A.
   Soh, Ben
TI Exploring the integration of blockchain technology, physical unclonable
   function, and machine learning for authentication in cyber-physical
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cyber-Physical System (CPS); Authentication; Blockchain; PUF; Machine
   learning; Cloud computing
ID INDUSTRY 4.0; BIG DATA; SECURITY; FRAMEWORK; DRIVEN
AB In this rapidly advancing era, technology has been progressing extensively and swiftly. As a result, the emergence of numerous Cyber-Physical Systems (CPS) has become imperative to meet the technological demands of modern life. However, these systems generate a substantial amount of data, which poses challenges in terms of management, storage, and susceptibility to external attacks. This paper primarily focuses on the performance and security aspects of CPS, particularly in countering external threats, through the integration of blockchain technology and machine learning. It provides a comprehensive review of recent research findings that demonstrate the use of blockchain to enhance CPS performance while ensuring robust security. Furthermore, the paper explores the synergistic application of blockchain and machine learning techniques to reinforce CPS security. Moreover, it investigates how the combination of blockchain with physically unclonable functions (PUF) can significantly enhance the efficacy of physical device authentication.
C1 [Al-Ghuraybi, Hind A.; Alzain, Mohammed A.] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 11099, Taif 21944, Saudi Arabia.
   [Soh, Ben] La Trobe Univ, Dept Comp Sci & Comp Engn, Bundoora, Australia.
C3 Taif University; La Trobe University
RP Al-Ghuraybi, HA (corresponding author), Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 11099, Taif 21944, Saudi Arabia.
EM hendabed1@hotmail.com; m.alzain@tu.edu.sa; B.soh@latrobe.edu.au
RI Al-Ghuraybi, Hind A./ITU-0559-2023
OI Al-Ghuraybi, Hind A./0000-0001-5374-5960
CR Alkhodair AJ, 2023, Arxiv, DOI arXiv:2304.08713
   Alkhodair AJ., 2022, SN Computer Science, V3, P1, DOI [10.1007/s42979-022-01139-4, DOI 10.1007/S42979-022-01139-4]
   Almaiah MA, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041448
   Amjad S, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22051972
   Antonopoulos A. M., 2017, Mastering Bitcoin: Programming the Open Blockchain, V2nd
   Asif R, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010028
   Atat R, 2018, IEEE ACCESS, V6, P73603, DOI 10.1109/ACCESS.2018.2878681
   Bathalapalli Venkata K V V, 2022, SN Comput Sci, V3, P344, DOI 10.1007/s42979-022-01238-2
   Bathalapalli VK, 2022, IFIP INT INT THINGS
   Chen F, 2021, IEEE Transactions on Computational Social Systems
   Chen M, 2014, MOBILE NETW APPL, V19, P171, DOI 10.1007/s11036-013-0489-0
   Cheng X, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1468-1
   Cui P, 2019, IEEE COMP SOC ANN, P600, DOI 10.1109/ISVLSI.2019.00112
   Dedeoglu V, 2019, PROCEEDINGS OF THE 16TH EAI INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS SYSTEMS: COMPUTING, NETWORKING AND SERVICES (MOBIQUITOUS'19), P190, DOI 10.1145/3360774.3360822
   Dedeoglu V, 2020, INT CONF COMMUN SYST, DOI [10.1109/comsnets48256.2020.9027487, 10.1109/COMSNETS48256.2020.9027487]
   Dell J, 2014, IEEE INTL CONF IND I, P376, DOI 10.1109/INDIN.2014.6945542
   Dey N, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0921-x
   Duo WL, 2022, IEEE-CAA J AUTOMATIC, V9, P784, DOI 10.1109/JAS.2022.105548
   EL Azzaoui A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041371
   Gatouillat A, 2018, IEEE INTERNET THINGS, V5, P3810, DOI 10.1109/JIOT.2018.2849014
   Gawanmeh A, 2018, IEEE INT CONF COMM
   Guan Z, 2017, 2017 5 INT C APPL CO
   Guin U, 2018, IEEE 2018 INTERNATIONAL CONGRESS ON CYBERMATICS / 2018 IEEE CONFERENCES ON INTERNET OF THINGS, GREEN COMPUTING AND COMMUNICATIONS, CYBER, PHYSICAL AND SOCIAL COMPUTING, SMART DATA, BLOCKCHAIN, COMPUTER AND INFORMATION TECHNOLOGY, P1042, DOI 10.1109/Cybermatics_2018.2018.00193
   Hassan MU, 2020, IEEE COMMUN SURV TUT, V22, P746, DOI 10.1109/COMST.2019.2944748
   Hussain F, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093025
   Imran M, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10202501
   Ismail L, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101198
   Jahromi A. A., 2020, Cyber-Physical Systems in the Built Environment. Ed. by, P1, DOI DOI 10.1007/978-3-030-41560-0_1
   Jamal A A., 2021, Materials Today: Proceedings
   Jan MA, 2021, IEEE T IND INFORM, V17, P5829, DOI [10.1109/tii.2020.3043802, 10.1109/TII.2020.3043802]
   Jara AJ, 2014, I C INNOV MOBILE INT, P376, DOI 10.1109/IMIS.2014.139
   Jia B, 2022, IEEE T IND INFORM, V18, P4049, DOI 10.1109/TII.2021.3085960
   Khan MA, 2021, IEEE NETWORK, V35, P223, DOI [10.1109/MNET.011.2000530, 10.1109/MNET.011.2000514]
   Kim S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11125458
   Korenda AR, 2019, ANN IEEE INT CONF SE, DOI [10.1109/sahcn.2019.8824887, 10.23919/smagrimet.2019.8720389]
   Kumar P, 2021, IEEE T NETW SCI ENG, V8, P2326, DOI 10.1109/TNSE.2021.3089435
   Kumar R, 2019, IEEE ACCESS, V7, P64411, DOI 10.1109/ACCESS.2019.2916886
   Li DX, 2018, 2018 27TH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND NETWORKS (ICCCN)
   Li F, 2019, 2019 IEEE 8 INT C AD
   Mamta, 2021, IEEE-CAA J AUTOMATIC, V8, P1877, DOI 10.1109/JAS.2021.1004003
   Milne AJM, 2020, IEEE ACCESS, V8, P66423, DOI 10.1109/ACCESS.2020.2984675
   Mohanta BK, 2020, 2020 11 INT C COMP C
   Mohanty SP, 2020, IEEE CONSUM ELECTR M, V9, P8, DOI 10.1109/MCE.2019.2953758
   Nair MM, 2019, PROCEDIA COMPUT SCI, V165, P647, DOI 10.1016/j.procs.2020.01.059
   Namane S, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11142225
   Pereira A, 2020, MACH LEARN KNOW EXTR, V2, P579, DOI 10.3390/make2040031
   Priyadarshini I, 2021, SICS SOFTWARE, V35, P159, DOI 10.1007/s00450-021-00427-3
   Qiu H, 2020, IEEE J BIOMED HEALTH, V24, P2499, DOI 10.1109/JBHI.2020.2973467
   Rahman Syed, 2022, IECON 2022 - 48th Annual Conference of the IEEE Industrial Electronics Society, P1, DOI 10.1109/IECON49645.2022.9968581
   Rahman Z, 2023, IEEE INTERNET THINGS, V10, P6769, DOI 10.1109/JIOT.2022.3147186
   Rahman Z, 2021, IEEE COMMUN MAG, V59, P128, DOI 10.1109/MCOM.001.2000679
   Rathore H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010282
   Rathore S, 2021, IEEE T IND INFORM, V17, P5522, DOI 10.1109/TII.2020.3040968
   Sabrina F, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22197535
   Salah K, 2019, IEEE ACCESS, V7, P10127, DOI 10.1109/ACCESS.2018.2890507
   Sandborn M, 2021, 2021 6 INT C FOG MOB
   Shahbazi Z, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041467
   Shamshad S, 2022, IEEE INTERNET THINGS, V9, P5142, DOI 10.1109/JIOT.2021.3108668
   Shickel B, 2018, IEEE J BIOMED HEALTH, V22, P1589, DOI 10.1109/JBHI.2017.2767063
   Skowronski R, 2019, FUTURE GENER COMP SY, V94, P430, DOI 10.1016/j.future.2018.11.044
   Son S, 2023, IEEE Access
   Sultana T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020488
   Szsz C., 2020, Int Rev Appl Sci Eng, V11, P66, DOI [10.1556/1848.2020.00010, DOI 10.1556/1848.2020.00010]
   Tadaka SM, 2020, 2020 7TH INTERNATIONAL CONFERENCE ON INTERNET OF THINGS: SYSTEMS, MANAGEMENT AND SECURITY (IOTSMS), DOI 10.1109/IOTSMS52051.2020.9340215
   Tanwar S, 2020, IEEE ACCESS, V8, P474, DOI 10.1109/ACCESS.2019.2961372
   Tyagi AK., 2021, Internet of Things and Cyber-Physical Systems, V1, P22, DOI DOI 10.1016/J.IOTCPS.2021.12.002
   Tyagi AK, 2021, IJIN, V2, P175, DOI DOI 10.1016/J.IJIN.2021.09.007
   Verma R, 2022, WIRELESS PERS COMMUN, V122, P1413, DOI 10.1007/s11277-021-08955-6
   Wang WZ, 2022, IEEE INTERNET THINGS, V9, P8883, DOI 10.1109/JIOT.2021.3117762
   Wu J., 2020, Cyber-Physical Systems in the Built Environment, P255, DOI DOI 10.1007/978-3-030-41560-0_14
   Xi P, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157912
   Xu LD, 2019, ENTERP INF SYST-UK, V13, P148, DOI 10.1080/17517575.2018.1442934
   Yaacoub JPA, 2020, MICROPROCESS MICROSY, V77, DOI 10.1016/j.micpro.2020.103201
   Zhao WB, 2021, IEEE INTERNET THINGS, V8, P4023, DOI 10.1109/JIOT.2020.3014864
   Zheng X, 2020, IFIP INT C ADV PROD
NR 75
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-16979-2
EA SEP 2023
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600025
DA 2024-07-18
ER

PT J
AU Chawla, PK
   Nair, MS
   Malkhede, DG
   Patil, HY
   Jindal, SK
   Chandra, A
   Gawas, MA
AF Chawla, Prabhleen Kaur
   Nair, Meera S.
   Malkhede, Dattakumar Gajanan
   Patil, Hemprasad Yashwant
   Jindal, Sumit Kumar
   Chandra, Avinash
   Gawas, Mahadev Anant
TI Parkinson's disease classification using nature inspired feature
   selection and recursive feature elimination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Nature Inspired Feature Selection; Parkinson's disease; Vocal features;
   RFECV; SMOTE; Zebra Optimization Algorithm
ID DIAGNOSIS
AB New progress in machine learning (ML) have paved the way for solving various existing complex problems, including in the medical field. In the proposed paper, we have investigated methods to detect Parkinson's Disease (PD) with Nature Inspired Feature Selection (NIFS) using the Zebra Optimization Algorithm and Recursive Feature Elimination Cross Validation (RFECV). A vocal feature-based dataset has been used for PD Detection as it contains data relating to the vocal features of PD patients. It has been proven from research that vocal disorders are observed in the majority of individuals in the preliminary phases of this disease. The number of features has been reduced from 754, in the original dataset, to 40 using feature selection, and the classification results have been obtained for two cases, one being a 70:30 train test split and the other being tenfold cross-validation. We have implemented the proposed technique on 11 different classifiers. Out of these, the Gaussian Process classifier showed the best accuracy for both cases. The accuracy values obtained for cases one and two are 96% and 97.07%, respectively, one of the highest accuracy values obtained for similar research done by other researchers. Additionally, the generalization capability of the model obtained may be enhanced by including more data points in the dataset.
C1 [Chawla, Prabhleen Kaur; Nair, Meera S.; Malkhede, Dattakumar Gajanan; Patil, Hemprasad Yashwant; Jindal, Sumit Kumar; Chandra, Avinash] Vellore Inst Technol, Sch Elect Engn, Vellore 632014, Tamil Nadu, India.
   [Gawas, Mahadev Anant] Govt Goa, State Higher Educ Council, Directorate Higher Educ, Alto Porvorim, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Patil, HY (corresponding author), Vellore Inst Technol, Sch Elect Engn, Vellore 632014, Tamil Nadu, India.
EM prabhleenkaur.2606@gmail.com; meerans96@gmail.com;
   dattakumarmalkhede@gmail.com; hemprasadpatil@gmail.com;
   sumitjindal08@gmail.com; avinashchandra888@gmail.com;
   gawas-dhe.goa@gov.in
RI JINDAL, SUMIT/KVZ-1810-2024
CR Al-Mejibli IS, 2018, 2018 1ST ANNUAL INTERNATIONAL CONFERENCE ON INFORMATION AND SCIENCES (AICIS 2018), P96, DOI 10.1109/AiCIS.2018.00029
   Arkinson C, 2018, SCIENCE, V360, P267, DOI 10.1126/science.aar6606
   Braga D, 2019, ENG APPL ARTIF INTEL, V77, P148, DOI 10.1016/j.engappai.2018.09.018
   Caro T, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms4535
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   El Aboudi N, 2016, 2016 INTERNATIONAL CONFERENCE ON ENGINEERING & MIS (ICEMIS)
   Enireddy V, 2020, International Journal of Advanced Trends in Computer Science and Engineering, V9, P3977, DOI [10.30534/ijatcse/2020/222932020, DOI 10.30534/IJATCSE/2020/222932020]
   Estes R., 2012, The behavior guide to African mammals: including hoofed mammals, carnivores, primates, V20
   Gunduz H, 2019, IEEE ACCESS, V7, P115540, DOI 10.1109/ACCESS.2019.2936564
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Haas BR, 2012, TRANSL NEURODEGENER, V1, DOI 10.1186/2047-9158-1-11
   Hasan KA, 2020, IEEE REGION 10 SYMP, P758
   Heim B, 2017, J NEURAL TRANSM, V124, P915, DOI 10.1007/s00702-017-1717-8
   Hoq M, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11061076
   Huang QH, 2023, EXPERT SYST APPL, V229, DOI 10.1016/j.eswa.2023.120450
   Huang QH, 2022, IEEE T ULTRASON FERR, V69, P691, DOI 10.1109/TUFFC.2021.3132933
   Jahromi AH, 2017, 2017 19TH CSI INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P209, DOI 10.1109/AISP.2017.8324083
   Jaiswal JK, 2017, 2017 2ND WORLD CONGRESS ON COMPUTING AND COMMUNICATION TECHNOLOGIES (WCCCT), P65, DOI 10.1109/WCCCT.2016.25
   Johri A., 2019, 2019 Twelfth International Conference on Contemporary Computing (IC3), P1, DOI DOI 10.1109/IC3.2019.8844941
   Karan B, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102050
   Kaur Amandeep, 2021, 2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE), P789, DOI 10.1109/ICACITE51222.2021.9404623
   Lee KY, 2006, 2006 IEEE/PES POWER SYSTEMS CONFERENCE AND EXPOSITION. VOLS 1-5, P188, DOI 10.1109/PSCE.2006.296295
   Li GH, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11142014
   Liu YC, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102165
   Luo YZ, 2023, BIOMED SIGNAL PROCES, V84, DOI 10.1016/j.bspc.2023.104784
   Olivares R, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051827
   Pastor John, 2006, Conservation Biology Series (Cambridge), V11, P289
   Polat K, 2019, 2019 SCIENTIFIC MEETING ON ELECTRICAL-ELECTRONICS & BIOMEDICAL ENGINEERING AND COMPUTER SCIENCE (EBBT), DOI 10.1109/ebbt.2019.8741725
   Rasmussen CE, 2004, LECT NOTES ARTIF INT, V3176, P63, DOI 10.1007/978-3-540-28650-9_4
   Rehman A, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12132856
   Sakar CO, 2019, APPL SOFT COMPUT, V74, P255, DOI 10.1016/j.asoc.2018.10.022
   Schein AI, 2007, MACH LEARN, V68, P235, DOI 10.1007/s10994-007-5019-5
   Solana-Lavalle G, 2020, BIOCYBERN BIOMED ENG, V40, P505, DOI 10.1016/j.bbe.2020.01.003
   Taunk K, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P1255, DOI [10.1109/iccs45141.2019.9065747, 10.1109/ICCS45141.2019.9065747]
   Tharwat A, 2016, INT J APPL PATTERN R, V3, P145, DOI 10.1504/IJAPR.2016.079050
   Trojovska E, 2022, IEEE ACCESS, V10, P49445, DOI 10.1109/ACCESS.2022.3172789
   Tuncer T, 2020, BIOCYBERN BIOMED ENG, V40, P211, DOI 10.1016/j.bbe.2019.05.006
   Vakili M, 2020, Arxiv, DOI arXiv:2001.09636
   Varalakshmi P., 2021, 2021 INT C SYST COMP, P1
   Wilson AM, 2018, NATURE, V554, P183, DOI 10.1038/nature25479
   Wilson E., 1994, Neural Networks for Signal Processing IV. Proceedings of the 1994 IEEE Workshop (Cat. No.94TH0688-2), P61, DOI 10.1109/NNSP.1994.366063
   Wooten GF, 2004, J NEUROL NEUROSUR PS, V75, P637, DOI 10.1136/jnnp.2003.020982
   Wottschel V, 2019, NEUROIMAGE-CLIN, V24, DOI 10.1016/j.nicl.2019.102011
   Xi JN, 2023, COMPUT BIOL MED, V155, DOI 10.1016/j.compbiomed.2023.106672
   Xiao TQ, 2020, Arxiv, DOI arXiv:2010.13665
   Xu SJ, 2020, INT J MED INFORM, V144, DOI 10.1016/j.ijmedinf.2020.104283
   Yang X-S, 2020, Nature-inspired optimization algorithms, DOI [10.1016/B978-0-12-821986-7.00002-0, DOI 10.1016/B978-0-12-821986-7.00002-0]
   Zhou JK, 2022, IEEE T ULTRASON FERR, V69, P114, DOI 10.1109/TUFFC.2021.3110590
NR 49
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-16804-w
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T0BR3
UT WOS:001074732700001
DA 2024-07-18
ER

PT J
AU Gupta, A
   Rana, SS
   Eranhikkal, A
   Kumar, P
AF Gupta, Abhishek
   Rana, Shailendra Singh
   Eranhikkal, Arshad
   Kumar, Prashant
TI Repeatability and reproducibility of landmark localization on panoramic
   images for PA (Posteroanterior) cephalometric analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cephalometric analysis; Panoramic radiograph; Magnification correction;
   Non-linear magnification correction; Posteroanterior radiograph
ID IDENTIFICATION; ERRORS
AB The objective of this study was to examine the repeatability and reproducibility of landmark localization on panoramic images for PA (Posteroanterior) cephalometric analysis. Lateral, PA and panoramic images of 20 patients were acquired for landmark localization by 2 different observers 2 times each of them. 14 bilateral landmarks were plotted on 20 PA and 20 panoramic images which makes a total of 40 x 28x4 = 4480 landmarks which were plotted to compute the measurements. The calibration of all three images was performed and measurements of each landmark were recorded from its position to the mid-sagittal plane. The repeatability and reproducibility of the panoramic images and PA cephalometric images was found good and sufficient to use in further experiments. The study's findings on repeatability and reproducibility back up the premise of obtaining PA analysis using panoramic radiographs. As a result, it's safe to presume that the repeatability of landmark placement among appropriately educated observers is sufficient to provide reliable test findings from panoramic radiographs.
C1 [Gupta, Abhishek; Kumar, Prashant] CSIR Cent Sci Instruments Org, Chandigarh, India.
   [Gupta, Abhishek; Kumar, Prashant] Acad Sci & Innovat Res AcSIR, Ghaziabad 201002, India.
   [Rana, Shailendra Singh; Eranhikkal, Arshad] All India Inst Med Sci AIIMS, Dept Dent, Room 3015, Bathinda, Punjab, India.
C3 Council of Scientific & Industrial Research (CSIR) - India; CSIR -
   Central Scientific Instruments Organisation (CSIO); Academy of
   Scientific & Innovative Research (AcSIR)
RP Rana, SS (corresponding author), All India Inst Med Sci AIIMS, Dept Dent, Room 3015, Bathinda, Punjab, India.
EM abhishekgupta10@yahoo.co.in; rana.shailu0612@gmail.com;
   arshadtkl@gmail.com; prashantkumar@csio.res.in
RI Gupta, Abhishek/O-3016-2019; Kumar, Prashant/AAF-5376-2020
OI Gupta, Abhishek/0000-0002-8592-9964; Kumar,
   Prashant/0000-0001-9988-0236; Rana, Dr Shailendra
   Singh/0000-0002-9513-329X
CR Chadwick JW, 2009, ORAL SURG ORAL MED O, V107, P105, DOI 10.1016/j.tripleo.2008.09.025
   CHEBIB FS, 1981, ANGLE ORTHOD, V51, P214
   COHEN MM, 1995, INT J ORAL MAX SURG, V24, P127, DOI 10.1016/S0901-5027(06)80085-8
   de Oliveira AEF, 2009, ORAL SURG ORAL MED O, V107, P256, DOI 10.1016/j.tripleo.2008.05.039
   Friedland B, 1998, Semin Orthod, V4, P64, DOI 10.1016/S1073-8746(98)80004-2
   Grummons D., 2003, WORLD J ORTHOD, V4, P297
   Grummons D C, 1987, J Clin Orthod, V21, P448
   Grummons Duane, 2004, World J Orthod, V5, P99
   Gupta A, 2023, Multimed Tools Appl
   Gupta A., 2020, Int J Comput Vis Robot, V10, P360, DOI [10.1504/IJCVR.2020.108153, DOI 10.1504/IJCVR.2020.108153]
   Gupta A, 2022, MULTIMED TOOLS APPL, V81, P41869, DOI 10.1007/s11042-021-11609-1
   Gupta A, 2019, COMPUT SCI-AGH, V20, P389, DOI 10.7494/csci.2019.20.4.3163
   Gupta A, 2017, AM J ORTHOD DENTOFAC, V151, P118, DOI 10.1016/j.ajodo.2016.06.027
   Gupta A, 2016, INT J COMPUT ASS RAD, V11, P1297, DOI 10.1007/s11548-015-1334-7
   Gupta A, 2015, INT J COMPUT ASS RAD, V10, P1737, DOI 10.1007/s11548-015-1173-6
   Hirschfelder Ursula, 2004, J Orofac Orthop, V65, P204, DOI 10.1007/s00056-004-0331-1
   HOUSTON WJB, 1986, EUR J ORTHODONT, V8, P149, DOI 10.1093/ejo/8.3.149
   Hwang HS, 2006, AM J ORTHOD DENTOFAC, V130, P779, DOI 10.1016/j.ajodo.2005.02.021
   Kitai N, 2004, CLEFT PALATE-CRAN J, V41, P208, DOI 10.1597/02-112
   MCDAVID WD, 1981, ORAL SURG ORAL MED O, V52, P561, DOI 10.1016/0030-4220(81)90369-8
   Sayinsu K, 2007, EUR J ORTHODONT, V29, P105, DOI 10.1093/ejo/cjl065
   SCHMID W, 1991, AM J ORTHOD DENTOFAC, V100, P19, DOI 10.1016/0889-5406(91)70045-X
   Schulze RKW, 2002, AM J ORTHOD DENTOFAC, V122, P635, DOI 10.1067/mod.2002.129191
   Titiz I, 2012, EUR J ORTHODONT, V34, P276, DOI 10.1093/ejo/cjq190
   Vincent A M, 1987, Aust Orthod J, V10, P98
   Yeo D K L, 2002, Aust Orthod J, V18, P92
NR 26
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16961-y
EA SEP 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200015
DA 2024-07-18
ER

PT J
AU Kushwaha, S
AF Kushwaha, Sumit
TI An effective adaptive fuzzy filter for speckle noise reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Speckle noise; Fuzzy logic; SAR Image; Image processing; Noise reduction
ID ULTRASOUND IMAGES; CONTOURLET TRANSFORM; WAVELET DOMAIN; RADAR IMAGES;
   ENHANCEMENT; LOGIC; DIFFUSION; DESIGN
AB SAR is a self-illuminating imaging method that produces high-resolution images in all weather conditions, day and night. Many application scientists have accepted and used SAR pictures. The SAR images, however, are distorted by speckle noise. Random interference of electromagnetic signals scattered by the object surface within one resolution element causes speckle noise. The amount and distribution of noise that corrupts the image are unpredictably large. Traditional noise filters are quantitative in nature and are not well suited to problems involving uncertainty. Uncertainty can be handled through fuzzy logic. A despeckling approach based on non-subsampled contourlet transform is proposed in this study. Non-subsampled filter banks can influence the directionality, anisotropy, and translation invariance of this transform. The two most desirable qualities of noise filters are noise reduction and image detail preservation. PSNR and MSE are used to assess the suggested fuzzy filter's performance. The performance is measured using SAR images with varied degrees of speckle noise. The effective filter has shown to decrease noise while preserving image edges.
C1 [Kushwaha, Sumit] Chandigarh Univ, Univ Inst Comp, Dept Comp Applicat, Mohali, Punjab, India.
C3 Chandigarh University
RP Kushwaha, S (corresponding author), Chandigarh Univ, Univ Inst Comp, Dept Comp Applicat, Mohali, Punjab, India.
EM sumit.kushwaha1@gmail.com
OI Kushwaha, Dr. Sumit/0000-0002-3830-1736
CR Abd-Elmoniem KZ, 2002, IEEE T BIO-MED ENG, V49, P997, DOI 10.1109/TBME.2002.1028423
   Amitab K, 2018, J COMPUT METHODS SCI, V18, P859, DOI 10.3233/JCM-180843
   [Anonymous], SIPI Image Database
   Ashpreet, 2020, INT J SOFTW INNOV, V8, P38, DOI 10.4018/IJSI.2020040103
   Babu JJJ, 2014, IET COMPUT VIS, V8, P718, DOI 10.1049/iet-cvi.2014.0008
   Babu JJJ, 2016, BIOMED SIGNAL PROCES, V23, P93, DOI 10.1016/j.bspc.2015.08.001
   Baselice F, 2017, ULTRASOUND MED BIOL, V43, P2065, DOI 10.1016/j.ultrasmedbio.2017.05.006
   Bhuiyan MIH, 2009, IET IMAGE PROCESS, V3, P147, DOI 10.1049/iet-ipr.2007.0096
   Binaee K, 2014, BIOMED SIGNAL PROCES, V13, P89, DOI 10.1016/j.bspc.2014.03.013
   Chen SW, 2020, IEEE T IMAGE PROCESS, V29, P6641, DOI 10.1109/TIP.2020.2992883
   Cheng H, 2009, PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE, VOL I, P933, DOI 10.1109/ETCS.2009.212
   Coupé P, 2009, IEEE T IMAGE PROCESS, V18, P2221, DOI 10.1109/TIP.2009.2024064
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Damodaran N, 2012, ULTRASOUND MED BIOL, V38, P276, DOI 10.1016/j.ultrasmedbio.2011.10.021
   Dongdong Zeng AK, 2019, J Electron Imaging, P1
   Dutt V, 1996, IEEE T MED IMAGING, V15, P802, DOI 10.1109/42.544498
   Elyasi I, 2016, MEASUREMENT, V91, P55, DOI 10.1016/j.measurement.2016.05.025
   Fan LW, 2019, VIS COMPUT IND BIOME, V2, DOI 10.1186/s42492-019-0016-7
   Farzana E, 2010, TENCON IEEE REGION, P1728, DOI 10.1109/TENCON.2010.5686140
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Guo MQ, 2021, REMOTE SENS LETT, V12, P174, DOI 10.1080/2150704X.2020.1846820
   Guo Y, 2011, BIOMED SIGNAL PROCES, V6, P129, DOI 10.1016/j.bspc.2010.10.004
   Habib M, 2015, APPL SOFT COMPUT, V29, P471, DOI 10.1016/j.asoc.2015.01.010
   Jain L, 2020, J King Saud Univ-Comput Inform Sci
   Khwairakpam A, 2019, MICROSYST TECHNOL, V25, P1743, DOI 10.1007/s00542-017-3474-x
   Krissian K, 2007, IEEE T IMAGE PROCESS, V16, P1412, DOI 10.1109/TIP.2007.891803
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   Kushwaha S., 2017, BIOMED PHARMACOL J, V10, P1355, DOI DOI 10.13005/bpj/1240
   Kushwaha S., 2017, BIOMED PHARMACOL J, V10, P837, DOI DOI 10.13005/bpj/1175
   Kushwaha S., 2018, Biomed. Res., V29, P3444
   Kushwaha S., 2015, Int J Comput Sci Eng, V3, P15
   Kushwaha S., 2017, BIOMED PHARMACOL J, V10, P805, DOI DOI 10.13005/bpj/1171
   Kushwaha S., 2015, Int J Comput Sci Eng, V03, P13
   Kushwaha S, 2019, BIOMED ENG-BIOMED TE, V64, P601, DOI 10.1515/bmt-2018-0101
   Kwan HK, 2003, STUD FUZZ SOFT COMP, V122, P25
   Kwan HK, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P672
   Leal AS, 2019, MEASUREMENT, V140, P572, DOI 10.1016/j.measurement.2019.03.050
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Liang DX, 2022, IEEE J-STARS, V15, P6283, DOI 10.1109/JSTARS.2022.3195093
   Lim LA, 2020, PATTERN ANAL APPL, V23, P1369, DOI 10.1007/s10044-019-00845-9
   Pizurica A, 2003, IEEE T MED IMAGING, V22, P323, DOI 10.1109/TMI.2003.809588
   Singh A, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11101590
   Singh KK, 2014, IETE TECH REV, V31, P75, DOI 10.1080/02564602.2014.891375
   Tsakalakis M, 2014, IEEE INT C BIOINF BI, P62, DOI 10.1109/BIBE.2014.39
   Wang X, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112462
   Yang YZ, 2019, IEEE ACCESS, V7, P97949, DOI 10.1109/ACCESS.2019.2930319
   Yingtao Zhang HD., 2010, Pattern Recognit, V43, P2962
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Yue Y, 2006, IEEE T MED IMAGING, V25, P297, DOI 10.1109/TMI.2005.862737
   Zhu Z., 2022, IEEE GEOSCI REMOTE S, V19, P1
NR 50
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16792-x
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8ZG9
UT WOS:001073989600003
DA 2024-07-18
ER

PT J
AU Al-Ghuraybi, HA
   Alzain, MA
   Soh, B
AF Al-Ghuraybi, Hind A.
   Alzain, Mohammed A.
   Soh, Ben
TI Ensuring authentication in Medical Cyber-Physical Systems: A
   comprehensive literature review of blockchain technology integration
   with machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Medical Cyber-Physical System (MCPS); Authentication; Blockchain;
   Machine Learning; Cloud Computing
ID SECURE; FRAMEWORK
AB Medical Cyber-Physical Systems (MCPS) are increasingly prevalent in an era of rapid technological advancement. They hold significant importance for patients and healthcare professionals, as they leverage cyber-physical systems (CPS). These systems generate substantial amounts of big data, posing challenges for processing and storage. Furthermore, they face vulnerabilities to cyber-attacks. With multiple parties involved, concerns arise regarding authentication processes and safeguarding against unauthorized access. To address these issues, Blockchain technology is employed to enhance system authentication and protect medical data. The integration of Blockchain and machine learning further improves the efficiency of big data processing in MCPS. This paper provides a comprehensive review of recent studies focusing on the integration of Blockchain technology with Medical Cyber-Physical Systems (MCPS) and its application in the medical field. The reviewed studies shed light on various aspects of utilizing Blockchain to enhance the security and efficiency of MCPS and protect medical data. Through these studies, several unresolved weaknesses, concerns and proposed solutions have been identified in the integration of Blockchain with Medical Cyber-Physical Systems (MCPS).
C1 [Al-Ghuraybi, Hind A.; Alzain, Mohammed A.] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 11099, Taif 21944, Saudi Arabia.
   [Soh, Ben] La Trobe Univ, Dept Comp Sci & Comp Engn, Bundora, Australia.
C3 Taif University; La Trobe University
RP Al-Ghuraybi, HA (corresponding author), Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 11099, Taif 21944, Saudi Arabia.
EM hendabed1@hotmail.com
RI Al-Ghuraybi, Hind A./ITU-0559-2023
OI Al-Ghuraybi, Hind A./0000-0001-5374-5960
CR Akkaoui R, 2020, IEEE ACCESS, V8, P113467, DOI 10.1109/ACCESS.2020.3003575
   Azbeg K, 2022, Egyptian Informatics Journal
   Ch R, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11193070
   Chen F., 2021, Secur Commun Netw, V2021
   Chen F, 2021, IEEE Transactions on Computational Social Systems
   Chen F, 2021, Security and Communication Networks
   Cheng X, 2019, INT C PION COMP SCI
   Cheng X, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1468-1
   Dang LM, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8070768
   Dedeoglu V, 2020, INT CONF COMMUN SYST, DOI [10.1109/comsnets48256.2020.9027487, 10.1109/COMSNETS48256.2020.9027487]
   Dell JT, 2014, 2014 12 IEEE INT C I
   Gatouillat A, 2018, IEEE INTERNET THINGS, V5, P3810, DOI 10.1109/JIOT.2018.2849014
   Ghayvat H, 2022, IEEE J BIOMED HEALTH, V26, P1937, DOI 10.1109/JBHI.2021.3097237
   Hasib KTAM, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/2366632
   Hassan MU, 2020, IEEE COMMUN SURV TUT, V22, P746, DOI 10.1109/COMST.2019.2944748
   Imran M, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10202501
   Itoo S, 2022, IEEE ACCESS, V10, P67787, DOI 10.1109/ACCESS.2022.3185016
   Jain S., 2020, 2020 INT C MAINSTR B
   Kocabas O, 2016, IEEE ACM T COMPUT BI, V13, P401, DOI 10.1109/TCBB.2016.2520933
   Lakhan A, 2023, IEEE T NETW SCI ENG, V10, P2466, DOI 10.1109/TNSE.2022.3213651
   Lakhan A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-29170-2
   Lee I, 2020, DESIGN AUTOMATION C
   Mamta, 2021, IEEE-CAA J AUTOMATIC, V8, P1877, DOI 10.1109/JAS.2021.1004003
   Nair MM, 2019, PROCEDIA COMPUT SCI, V165, P647, DOI 10.1016/j.procs.2020.01.059
   Nguyen DC, 2019, IEEE ACCESS, V7, P66792, DOI 10.1109/ACCESS.2019.2917555
   Panwar A, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/3045107
   Pereira A, 2020, MACH LEARN KNOW EXTR, V2, P579, DOI 10.3390/make2040031
   Priyadarshini I, 2021, SICS SOFTWARE, V35, P159, DOI 10.1007/s00450-021-00427-3
   Qiu H, 2020, IEEE J BIOMED HEALTH, V24, P2499, DOI 10.1109/JBHI.2020.2973467
   Rahman MA, 2020, IEEE ACCESS, V8, P205071, DOI 10.1109/ACCESS.2020.3037474
   Rahman Syed, 2022, IECON 2022 - 48th Annual Conference of the IEEE Industrial Electronics Society, P1, DOI 10.1109/IECON49645.2022.9968581
   Rathore H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010282
   Salah K, 2019, IEEE ACCESS, V7, P10127, DOI 10.1109/ACCESS.2018.2890507
   Shafay M, 2023, CLUSTER COMPUT, V26, P197, DOI 10.1007/s10586-022-03582-7
   Shickel B, 2018, IEEE J BIOMED HEALTH, V22, P1589, DOI 10.1109/JBHI.2017.2767063
   Shishvan OR, 2018, IEEE ACCESS, V6, P46419, DOI 10.1109/ACCESS.2018.2866049
   Shu H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051521
   Sun J, 2020, IEEE ACCESS, V8, P59389, DOI 10.1109/ACCESS.2020.2982964
   Syed TA, 2019, IEEE ACCESS, V7, P176838, DOI 10.1109/ACCESS.2019.2957660
   Tadaka SM, 2020, 2020 7TH INTERNATIONAL CONFERENCE ON INTERNET OF THINGS: SYSTEMS, MANAGEMENT AND SECURITY (IOTSMS), DOI 10.1109/IOTSMS52051.2020.9340215
   Tanwar S, 2020, IEEE ACCESS, V8, P474, DOI 10.1109/ACCESS.2019.2961372
   Tyagi AK., 2021, Internet of Things and Cyber-Physical Systems, V1, P22, DOI DOI 10.1016/J.IOTCPS.2021.12.002
   Tyagi AK, 2021, IJIN, V2, P175, DOI DOI 10.1016/J.IJIN.2021.09.007
   Ul Haque R, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9122096
   Verma R, 2022, WIRELESS PERS COMMUN, V122, P1413, DOI 10.1007/s11277-021-08955-6
   Wang Y, 2019, IEEE ACCESS, V7, P136704, DOI 10.1109/ACCESS.2019.2943153
   Xi P, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157912
   Xu X., 2019, Architecture for Blockchain Applications, P93, DOI [10.1007/978-3-030-03035-3_6, DOI 10.1007/978-3-030-03035-3_6]
   Zhang Y, 2017, IEEE SYST J, V11, P88, DOI 10.1109/JSYST.2015.2460747
   Zhao WB, 2021, IEEE INTERNET THINGS, V8, P4023, DOI 10.1109/JIOT.2020.3014864
NR 50
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-17065-3
EA SEP 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8YJ1
UT WOS:001073965700009
DA 2024-07-18
ER

PT J
AU Barik, RC
   Hu, YC
   Samal, T
   Pati, R
AF Barik, Ram Chandra
   Hu, Yu-Chen
   Samal, Tusharkanta
   Pati, Rasmikanta
TI Dynamics of quantum mechanical schrodinger wave function and chaos for
   biomedical image encryption scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Schrodinger wave function; Chaotic logistic map; Medical image
   encryption; Initial condition; Block division
AB This paper proposes a new medical image encryption scheme employing cascaded Quantum Mechanics and Chaos systems. Firstly, a Quantum Mechanics based Schrodinger wave time signal generates a stream of initial conditions based on electron-free particles within a well. In the second phase, every initial condition is permuted by a series of Logistic map functions to perform chaotic confusion followed by XOR-based encryption with respective block or sub-image. Before that, the original image must have undergone a division of countable blocks. Chaotic map sequences are sensitive to initial conditions and control parameters. The proposed Cascaded Schrodinger Logistic Encryption (CSLE) algorithm can encrypt any grayscale and color image. The key space (2(359)) of the proposed algorithm is very high. It is validated against all statistical analysis and major security benchmark tests such as resistance to brute force attacks, differential attacks, key sensitivity tests, correlation analysis, resistance to noise, and plain text attack, along with speed analysis. The proposed CSLE algorithm meets all the NIST test suite standards. The security test result of the proposed algorithm outperforms many existing image encryption algorithms.
C1 [Barik, Ram Chandra] CV Raman Global Univ, Dept Comp Sci & Engn, Bhubaneswar 752054, Odisha, India.
   [Hu, Yu-Chen] Tunghai Univ, Dept Comp Sci, 1727,Sec 4,Taiwan Blvd, Taichung 407224, Taiwan.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung, Taiwan.
   [Samal, Tusharkanta] DRIEMS Autonomous Coll, Dept Comp Sci & Engn, Cuttack, Odisha, India.
   [Pati, Rasmikanta] Sambalpur Univ, SUIIT, Burla, India.
C3 Tunghai University; Providence University - Taiwan; Sambalpur University
RP Hu, YC (corresponding author), Tunghai Univ, Dept Comp Sci, 1727,Sec 4,Taiwan Blvd, Taichung 407224, Taiwan.; Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, Taichung, Taiwan.
EM ram.chandra@cgu-odisha.ac.in; ychu@thu.edu.tw; samaltushar1@gmail.com;
   rkpati@suiit.ac.in
RI Barik, Dr. Ram Chandra/ABG-1736-2021
OI Barik, Dr. Ram Chandra/0000-0002-2803-5868; Hu,
   Yu-Chen/0000-0002-5055-3645
CR Abanda Y, 2016, IET IMAGE PROCESS, V10, P742, DOI 10.1049/iet-ipr.2015.0244
   Adhikari S, 2022, MULTIMED TOOLS APPL, V81, P759, DOI 10.1007/s11042-021-11323-y
   Alrubaie AH, 2023, J Eng Appl Sci, V70, P60, DOI [10.1186/s44147-023-00228-2, DOI 10.1186/S44147-023-00228-2]
   Barik RC, 2021, MULTIMED TOOLS APPL, V80, P10723, DOI 10.1007/s11042-020-09930-2
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Chai XL, 2019, MULTIMED TOOLS APPL, V78, P35419, DOI 10.1007/s11042-019-08168-x
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen X, 2017, SAUDI J BIOL SCI, V24, P1821, DOI 10.1016/j.sjbs.2017.11.023
   El Hanouti I, 2021, MULTIMED TOOLS APPL, V80, P4975, DOI 10.1007/s11042-020-09815-4
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Fishman S, 2012, NONLINEARITY, V25, DOI 10.1088/0951-7715/25/4/R53
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Gao S, 2023, INFORM SCIENCES, V621, P766, DOI 10.1016/j.ins.2022.11.121
   Hasan MK, 2021, IEEE ACCESS, V9, P47731, DOI 10.1109/ACCESS.2021.3061710
   Hoang TM, 2024, MULTIMED TOOLS APPL, V83, P12985, DOI 10.1007/s11042-023-15880-2
   Karawia AA, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20100801
   Li RZ, 2019, IET IMAGE PROCESS, V13, P125, DOI 10.1049/iet-ipr.2018.5900
   Loizou CP, 2011, IEEE T INF TECHNOL B, V15, P119, DOI 10.1109/TITB.2010.2091279
   Lyle M, 2022, MULTIMED TOOLS APPL, V81, P8179, DOI 10.1007/s11042-022-11917-0
   Masood F, 2022, WIRELESS PERS COMMUN, V127, P1405, DOI 10.1007/s11277-021-08584-z
   Mathivanan P, 2023, IMAGING SCI J, V71, P343, DOI 10.1080/13682199.2023.2182547
   Mozaffari S, 2018, MULTIMED TOOLS APPL, V77, P25799, DOI 10.1007/s11042-018-5817-8
   Natiq H, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-11834-2
   Onyema EM, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5196000
   Priyanka, 2023, EVOL INTELL, V16, P801, DOI 10.1007/s12065-021-00683-x
   Wang C, 2023, INFORM SCIENCES, V642, DOI 10.1016/j.ins.2023.119166
   Wang XY, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118924
   Wang XY, 2018, IEEE ACCESS, V6, P23733, DOI 10.1109/ACCESS.2018.2805847
   Zhang LB, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/913476
   Zhang XT, 2019, INT J ANAL CHEM, V2019, DOI 10.1155/2019/2105839
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhou ZQ, 2023, CHAOS SOLITON FRACT, V173, DOI 10.1016/j.chaos.2023.113630
NR 32
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32813
EP 32834
AR s11042-023-16775-y
DI 10.1007/s11042-023-16775-y
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069966300003
DA 2024-07-18
ER

PT J
AU Dang, LX
   Wang, CY
   Tsou, MH
   Hou, YE
   Han, HY
AF Dang, Lanxue
   Wang, Chunyu
   Tsou, Ming-Hsiang
   Hou, Yan-e
   Han, Hongyu
TI Sentiment analysis of COVID-19 related social distancing using twitter
   data based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Deep learning; Sentiment analysis; Social distancing; Twitter
ID CLASSIFICATION; CORONAVIRUS
AB Social distancing is an important non-pharmaceutical intervention tool (NPIs) to prevent the spread of COVID-19. However, it also created negative impacts of economic activities. Understanding the emotions and public opinions about social distancing are important for the future policy making of COVID-19 mitigation and the assessment of public health impacts. This study collected 77,627 number of Twitter messages (tweets) between February 1, 2020 and April 30, 2020 from five English-speaking countries (United States, the United Kingdom, India, Canada, and Australia) using the social distancing keywords. We adopted a multi-module hybrid convolutional neural network model sentiment analysis on social distancing related tweets with 85.95% accuracy. This paper conducts a sentiment analysis of tweets from the public on social distancing measures in five countries. Our findings show similar sentiments in tweets from these five countries, which is more positives than negatives about social distancing measures in the public. Additionally, when the daily number of new cases changes, public sentiment fluctuates with it. We believe that social distancing is effective in preventing the spread of coronavirus.
C1 [Dang, Lanxue] Henan Univ, Henan Key Lab Big Data Anal & Proc, Kaifeng 475004, Peoples R China.
   [Dang, Lanxue; Wang, Chunyu; Hou, Yan-e; Han, Hongyu] Henan Univ, Sch Comp Sci & Informat Engn, Kaifeng 475004, Peoples R China.
   [Tsou, Ming-Hsiang] San Diego State Univ, Geog Dept, San Diego, CA USA.
C3 Henan University; Henan University; California State University System;
   San Diego State University
RP Han, HY (corresponding author), Henan Univ, Sch Comp Sci & Informat Engn, Kaifeng 475004, Peoples R China.
EM danglx@vip.henu.edu.cn; wangcy@henu.edu.cn; mtsou@sdsu.edu;
   houyane@henu.edu.cn; hanhongyu@henu.edu.cn
RI Dang, Lanxue/JRZ-1997-2023; Wang, Chunyu/HPC-0200-2023
FU We gratefully acknowledge that this work is financed by Technology
   Development Plan Project of Henan Province of China (grant number
   222102210178). [222102210178]; Technology Development Plan Project of
   Henan Province of China
FX We gratefully acknowledge that this work is financed by Technology
   Development Plan Project of Henan Province of China (grant number
   222102210178).
CR Aljameel SS, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18010218
   Barkur G, 2020, ASIAN J PSYCHIATR, V51, DOI 10.1016/j.ajp.2020.102089
   Basiri ME, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107242
   Basiri ME, 2021, FUTURE GENER COMP SY, V115, P279, DOI 10.1016/j.future.2020.08.005
   Block P, 2020, NAT HUM BEHAV, V4, P588, DOI 10.1038/s41562-020-0898-6
   Bowles DC, 2020, PEDAGOGY HEAL PROMOT, V6, P156, DOI 10.1177/2373379920938419
   Chintalapudi N, 2021, INFECT DIS REP, V13, P329, DOI 10.3390/idr13020032
   Chung Junyoung, 2014, ARXIV14123555
   Devlin J., 2018, BERT PRE TRAINING DE
   Goldberg Y., 2014, ARXIV
   Greenstone M., 2020, University of Chicago, Becker Friedman Institute for Economics Working Paper, V7, P1
   Guo B, 2019, NEUROCOMPUTING, V363, P366, DOI 10.1016/j.neucom.2019.07.052
   Harapan H, 2020, J INFECT PUBLIC HEAL, V13, P667, DOI 10.1016/j.jiph.2020.03.019
   Hasan A, 2018, MATH COMPUT APPL, V23, DOI 10.3390/mca23010011
   Hassan A, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P705, DOI 10.1109/ICCAR.2017.7942788
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heikal M, 2018, PROCEDIA COMPUT SCI, V142, P114, DOI 10.1016/j.procs.2018.10.466
   Huang FL, 2017, NEUROCOMPUTING, V253, P144, DOI 10.1016/j.neucom.2016.10.086
   Huq MR, 2017, INT J ADV COMPUT SC, V8, P19
   Imran AS, 2020, IEEE ACCESS, V8, P181074, DOI 10.1109/ACCESS.2020.3027350
   Jelodar H, 2020, IEEE J BIOMED HEALTH, V24, P2733, DOI 10.1109/JBHI.2020.3001216
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Maital S., 2020, Samuel Neaman Inst. Natl. Policy Res., V2020, P1
   Manek AS, 2017, WORLD WIDE WEB, V20, P135, DOI 10.1007/s11280-015-0381-x
   Mishra M, 2020, J HEALTH MANAG, V22, P224, DOI 10.1177/0972063420935547
   Mostafa L., 2020, Joint European-US Workshop on Applications of Invariance in Computer Vision, P405, DOI DOI 10.1007/978-3-030-44289-7_38
   Mullen T., 2004, P 2004 C EMP METH NA
   Nandal N, 2020, SPAT INF RES, V28, P601, DOI 10.1007/s41324-020-00320-2
   Neethu MS, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATIONS AND NETWORKING TECHNOLOGIES (ICCCNT)
   Omara E, 2018, 2018 PROCEEDINGS OF THE INTERNATIONAL JAPAN-AFRICA CONFERENCE ON ELECTRONICS, COMMUNICATIONS, AND COMPUTATIONS (JAC-ECC 2018), P155, DOI 10.1109/JEC-ECC.2018.8679558
   Qazi Umair, 2020, SIGSPATIAL Special, V12, P6, DOI 10.1145/3404820.3404823
   Qian MR, 2022, J PUBLIC HEALTH-HEID, V30, P259, DOI 10.1007/s10389-020-01321-z
   Rani S, 2019, ARAB J SCI ENG, V44, P3305, DOI 10.1007/s13369-018-3500-z
   Shofiya C, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18115993
   Singh J, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0116-3
   Sohrabi C, 2020, INT J SURG, V76, P71, DOI 10.1016/j.ijsu.2020.02.034
   Stojanovski D, 2015, LECT NOTES ARTIF INT, V9121, P726, DOI 10.1007/978-3-319-19644-2_60
   Sun CJ, 2020, SUSTAIN CITIES SOC, V62, DOI 10.1016/j.scs.2020.102390
   Tang D., 2015, ARXIV
   Vateekul P, 2016, INT JOINT CONF COMP, P70
   Venkatesh A, 2020, BMJ-BRIT MED J, V369, DOI 10.1136/bmj.m1379
   Vijayarani S., 2016, ADV COMPUTATIONAL IN, V3, P37, DOI DOI 10.1504/IJACII.2016.10000369
   Wang Xueting, 2020, medRxiv, DOI 10.1101/2020.07.12.20151936
   Wang Y., 2016, P 2016 C EMPIRICAL M, P606, DOI 10.18653/v1/D16-1058
   Wu DD, 2014, IEEE T SYST MAN CY-S, V44, P1077, DOI 10.1109/TSMC.2013.2295353
   Yuliana, 2020, Wellness and Healthy Magazine, V2, P187, DOI DOI 10.30604/WELL.95212020
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhao ZW, 2016, INTERSPEECH, P705, DOI 10.21437/Interspeech.2016-354
NR 50
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32587
EP 32612
DI 10.1007/s11042-023-17011-3
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069968300002
DA 2024-07-18
ER

PT J
AU Mao, KM
   Chen, C
   Zhang, JK
   Li, YY
AF Mao, Keming
   Chen, Chen
   Zhang, Jinkai
   Li, Yiyang
TI ORLEP: an efficient offline reinforcement learning evaluation platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Offline reinforcement learning; Model training and evaluation; Platform
   design and implementation
AB Developing offline reinforcement learning evaluation applications faces challenges such as heterogeneous data and algorithm integration, user-friendly interface, and flexible resource management. This paper designs and implements ORLEP, an efficient platform to provide high-level services for offline reinforcement learning evaluation. Besides integrating underlying infrastructure with highly concurrency and reliability, core components with distributed deployment and 3rd party libs and benchmarks incorporation, ORLEP supplies high-level abstractions for (1) data management, (2) model training and evaluation, (3) result visualization, and (4) resource configuration and supervision. Moreover, this paper verifies specific cases and the results demonstrate the performance and scalability of the proposed ORLEP.
C1 [Mao, Keming; Chen, Chen; Zhang, Jinkai; Li, Yiyang] Northeastern Univ, Software Coll, Shenyang, Peoples R China.
C3 Northeastern University - China
RP Chen, C (corresponding author), Northeastern Univ, Software Coll, Shenyang, Peoples R China.
EM maokm@mail.neu.edu.cn; 2271380@stu.neu.edu.cn; 1966465337@qq.com;
   20206861@stu.neu.edu.cn
FU All authors contributed to the study conception and design. Material
   preparation, analysis and writing original draft were performed by Chen
   Chen. Resources, supervision, funding acquisition were performed by Mao
   Keming. Material preparation, software, inv
FX All authors contributed to the study conception and design. Material
   preparation, analysis and writing original draft were performed by Chen
   Chen. Resources, supervision, funding acquisition were performed by Mao
   Keming. Material preparation, software, investigation were performed by
   Zhang Jinkai. Data collection and test were performed by Li Yiyang. And
   all authors commented on previous versions of the manuscript. All
   authors read and approved the final manuscript.
CR Alshuqayran N, 2016, IEEE INT CONF SERV, P44, DOI 10.1109/SOCA.2016.15
   Burch C., 2010, Journal of Computing Sciences in Colleges, V25, P154
   Cabi S, 2020, Arxiv, DOI arXiv:1909.12200
   D'Eramo C, 2021, J MACH LEARN RES, V22
   Denoyer L, 2021, Arxiv, DOI arXiv:2110.07910
   Fu J., 2020, arXiv
   Fujimoto S, 2019, P INT C MACH LEARN L, V97
   Gade AN, 2018, BUILD ENVIRON, V142, P107, DOI 10.1016/j.buildenv.2018.06.016
   Henderson J, 2008, COMPUT LINGUIST, V34, P487, DOI 10.1162/coli.2008.07-028-R2-05-82
   Ionescu VM, 2015, ROEDUNET IEEE, P132, DOI 10.1109/RoEduNet.2015.7311982
   Jaques N, 2019, Arxiv, DOI arXiv:1907.00456
   Kuhnle Alexander, 2017, Tensorforce: a tensorflow library for applied reinforcement learning
   Kumar A., 2020, ADV NEURAL INFORM PR, V33, P1179
   Levine S, 2020, Arxiv, DOI arXiv:2005.01643
   Li L., 2010, P 19 INT C WORLD WID, DOI [10.1145/1772690.1772758, DOI 10.1145/1772690.1772758]
   Linzecong, 2023, LPOJ usage and development Document
   Nandy A, 2018, Reinforcement learning: With open ai, tensorflow and keras using Python, P129
   Ouyang L., 2022, ADV NEURAL INFORM PR, V35, P27730, DOI 10.48550/ARXIV.2203.02155
   Pietquin O., 2011, ACM T SPEECH LANGUAG, V7, P1
   Qin R.-J., 2022, Advances in Neural Information Processing Systems, V35, P24753
   Raffin A, 2021, J MACH LEARN RES, V22, P1
   Seno T., 2022, J. Mach. Learn. Res., V23, P14205
   Sheldon R., 2005, Beginning MySQL
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Strehl A, 2010, Adv Neural Inf Process Syst, V23
   Thomas PS, 2017, AAAI CONF ARTIF INTE, P4740
   Vinyals O, 2019, NATURE, V575, P350, DOI 10.1038/s41586-019-1724-z
   Weng JY, 2022, J MACH LEARN RES, V23
   Wiering M, 2012, ADAPT LEARN OPTIM, V12, P1, DOI 10.1007/978-3-642-27645-3
   You Evan., 2022, Vue.js - The Progressive JavaScript Framework | Vue.js
NR 30
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 22
PY 2023
DI 10.1007/s11042-023-16906-5
EA SEP 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S3BY0
UT WOS:001069968300005
DA 2024-07-18
ER

PT J
AU Muntha, KC
   Ponnusamy, M
AF Muntha, Krishna Chaithanya
   Ponnusamy, Manimaran
TI Design approach of FPGA based efficient data compression technique (TS
   D<SUP>2</SUP> NIS) in FC technology for data transmission
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fiber channel; Data compression; Aircraft; Synchronization; Optical
   signals; Serial to parallel
ID BIG DATA
AB The avionic environment requires a high speed data connecting medium due to continuous advances in computer processor and peripheral performance. The mode of communication should be able to send accurate information over a long distance. The interconnecting technology must be serial and asynchronous in order to satisfy all of these requirements. High-speed and low-latency communication between the end systems is made possible via fibre channels. FC protocol is proposed in this study to speed up data communication compared to existing protocols significantly. Because of its tiny size, high integration, rapid speed, parallel processing, and programmable capabilities, FPGA is widely employed in a variety of sectors. Therefore, the FPGA-based FC with enhanced data compression methods is proposed and implemented in this research. The FC module is embraced with three major modules, namely serial to parallel (S/P) conversion module (S/P CM), link initialization module (LIM), and frame process module (FPM). The transformation of the optical signal to a digital signal, serial to parallel or parallel to serial, is employed in the first module. Also, this study investigates the Gigabit transceiver (GTH) with its functional modules. With a maximum data rate of 13.1 Gbps, the GTH is more potent than the Gigabit Transceiver with Low Power (GTP). The GTH module uses less power and includes configurable user-defined features and parameters. In addition, in the first module, the enhanced data compression technique is proposed for an efficient data transfer and is termed a time series delta difference neighbourhood indexing sequence ((TSDNIS)-N-2) model. The LIM module includes the receiver, transmitter, and port state machine. The initialization of each fibre channel port's link is controlled by a port state machine, which may also guarantee the recovery of link errors and regular transmission of data. The FPM module seeks to deal with frame protocols. The experimental results show the proposed architecture has flexible scalability and strong performance in high-speed data transmission using the FC protocols. The proposed work is simulated using Xilinx ISE tools, and the Virtex 7 FPGA family and comparative study were conducted. It attains a compression ratio of 40%, delay of 0.33 ns and frequency of 321.425 MHZ, respectively.
C1 [Muntha, Krishna Chaithanya] Vellore Inst Technol, Sch Elect Engn SENSE, Dept Commun Engn, Vellore 632014, Tamil Nadu, India.
   [Ponnusamy, Manimaran] Vellore Inst Technol, Sch Elect Engn SENSE, Dept Commun Engn, Chennai 600127, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Chennai
RP Ponnusamy, M (corresponding author), Vellore Inst Technol, Sch Elect Engn SENSE, Dept Commun Engn, Chennai 600127, Tamil Nadu, India.
EM manimaran.p@vit.ac.in
CR Abdulzahra SA, 2020, 2020 INTERNATIONAL CONFERENCE ON EMERGING SMART COMPUTING AND INFORMATICS (ESCI), P103, DOI [10.1109/esci48226.2020.9167636, 10.1109/ESCI48226.2020.9167636]
   [Anonymous], 2016, IEEE INT S PERS IND
   Azar J, 2020, NEUROCOMPUTING, V398, P222, DOI 10.1016/j.neucom.2020.02.097
   Bassinan O, 2023, NEXT GENERATION OPTI, V12429, P244
   Choi S, 2019, IEEE ACCESS, V7, P149583, DOI 10.1109/ACCESS.2019.2947273
   Chouakri SA, 2018, P 2018 IEEE INT INST, P1, DOI DOI 10.1109/I2MTC.2018.8409674
   Dinesh M, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1195, DOI 10.1109/RTEICT.2016.7808021
   Fei T, 2019, ROBOT CIM-INT MANUF, V57, P166, DOI 10.1016/j.rcim.2018.12.005
   Fu N, 2023, INT C IM SIGN PROC P, V12707, P31
   Hanumanthaiah A, 2019, PROCEEDINGS OF THE 2019 9TH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED 2019), P63, DOI 10.1109/ised48680.2019.9096229
   Helal EB, 2021, IEEE ACCESS, V9, P58161, DOI 10.1109/ACCESS.2021.3073090
   Huang YJ, 2024, IEEE T INTELL TRANSP, V25, P602, DOI 10.1109/TITS.2023.3307873
   Ivanova Diana L., 2020, 2020 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (EIConRus). Proceedings, P24, DOI 10.1109/EIConRus49466.2020.9038939
   Jancy S, 2021, J PHYS C SERIES IOP, V1770
   Kafle Ved P., 2016, IEEE Communications Magazine, V54, P43, DOI 10.1109/MCOM.2016.7565271
   Liu LS, 2013, IEEE IMTC P, P1817
   Murugan MS, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER TECHNOLOGIES AND OPTIMIZATION TECHNIQUES (ICEECCOT), P223, DOI [10.1109/iceeccot46775.2019.9114621, 10.1109/ICEECCOT46775.2019.9114621]
   Narapureddy P, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P926, DOI 10.1109/RTEICT.2016.7807964
   Naushad F, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN ELECTRONICS AND COMMUNICATION TECHNOLOGY (ICRAECT), P1, DOI 10.1109/ICRAECT.2017.26
   Patil SB, 2015, 2015 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES AND MANAGEMENT FOR COMPUTING, COMMUNICATION, CONTROLS, ENERGY AND MATERIALS (ICSTM), P307, DOI 10.1109/ICSTM.2015.7225432
   Prakash M, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P835, DOI 10.1109/RTEICT.2017.8256715
   Qi QL, 2018, IEEE ACCESS, V6, P3585, DOI 10.1109/ACCESS.2018.2793265
   Qiao J, 2020, 2020 IEEE INT INSTR, P1
   Saidani A, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8824954
   Tao F, 2019, IEEE T SYST MAN CY-S, V49, P81, DOI 10.1109/TSMC.2017.2723764
   Tao F, 2014, IEEE T IND INFORM, V10, P1547, DOI 10.1109/TII.2014.2306397
   Uthayakumar J, 2019, AD HOC NETW, V83, P149, DOI 10.1016/j.adhoc.2018.09.009
   Wang KuiSheng, 2022, 2022 7th International Conference on Intelligent Computing and Signal Processing (ICSP), P1374, DOI 10.1109/ICSP54964.2022.9778386
   Xu D, 2013, INT CONF ADV COMMUN, P110
   Yang SM, 2023, NEUROCOMPUTING, V542, DOI 10.1016/j.neucom.2023.126240
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Zhang F, 2020, HIGH SPEED SERIAL BU, P343
   Zhonglou Meng, 2010, 2010 International Conference on Computational Problem-Solving (ICCP 2010), P399
NR 34
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32321
EP 32341
DI 10.1007/s11042-023-16896-4
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001070386400006
DA 2024-07-18
ER

PT J
AU Porwal, P
   Devare, MH
AF Porwal, Priya
   Devare, Manoj H.
TI Citation count prediction using weighted latent semantic analysis (wlsa)
   and three-layer-deep-learning paradigm: a meta-heuristic approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Citation count prediction; Class distribution factor-based Term
   Frequency-Inverse Document Frequency (CDF-TFIDF); Weighted Latent
   Semantic Analysis (WLSA); Red fox optimization (RFO); Convolutional
   Neural Network (CNN)
ID IMPACT; PUBLICATION
AB Citation count prediction is a subfield of bibliometrics, which involves using mathematical and statistical models to predict the quantity of citations that a scholarly research paper will accept in the future. This study suggests a novel approach for forecasting the number of citations academic papers will receive in future. The proposed model includes four major phases: "(a) pre-processing, (b) feature extraction, (c) feature selection, (d) Three-Layer-Deep-Learning-based-citation-count-prediction". In this paper, the Raw data collected is pre-processed via stop word removal, stemming, lemmatization, tokenization. As a resultant, the tokens are acquired. The features are extracted from the tokens. The features like bag-of-words, Part-of-Speech (POS) Tagger, Pointwise Mutual Information (PMI), Class distribution factor-based Term Frequency-Inverse Document Frequency (CDF-TFIDF), Doc2vec (document to vector) and Weighted Latent Semantic Analysis (WLSA). Subsequently, from the extracted features, the optimal features are selected using the new hybrid optimization model. The proposed hybrid optimization model- Polar Red Fox Optimization (PRFO), is the agglomeration of concepts of the standard "Polar Bear Optimization (PBO)" and "Red the fox optimization (RFO)," respectively. The citation counts are predicted using the new three-layer-deep-learning paradigm that includes the "Long Short-Term Memory (LSTM), Recurrent Neural Net Language Model (RNNL), and Convolutional Neural Network (CNN)," respectively. The input to LSTM and RNNL is the selected optimal features. The outcome from LSTM and RNNL is fed as input to the CNN. The outcome is acquired from CNN. Finally, the proposed prototypical is validated over current models, to manifest its efficiency in accurate citation count prediction.
C1 [Porwal, Priya] Amity Univ, Comp Engn Dept, Mumbai, India.
   [Devare, Manoj H.] Amity Univ, Prof & Head Inst, Amity Inst Informat Technol, Mumbai, India.
RP Porwal, P (corresponding author), Amity Univ, Comp Engn Dept, Mumbai, India.
EM priya.porwal20@gmail.com; mhdevare@mum.amity.edu
RI Devare, Manoj/H-2442-2016
OI Devare, Manoj/0000-0002-9530-3914
CR Abramo G, 2019, J INFORMETR, V13, P32, DOI 10.1016/j.joi.2018.11.003
   Abrams DS., 2013, PATENT VALUE CITATIO, DOI [10.3386/w19647, DOI 10.3386/W19647]
   Abrishami A, 2019, J INFORMETR, V13, P485, DOI 10.1016/j.joi.2019.02.011
   Akella AP, 2021, J INFORMETR, V15, DOI 10.1016/j.joi.2020.101128
   Aljuaid H, 2021, TELEMAT INFORM, V56, DOI 10.1016/j.tele.2020.101492
   Bai XM, 2019, J INFORMETR, V13, P407, DOI 10.1016/j.joi.2019.01.010
   Berahmand K, 2021, COMPUTING, V103, P2227, DOI 10.1007/s00607-021-00982-2
   Bornmann L, 2007, J AM SOC INF SCI TEC, V58, P1100, DOI 10.1002/asi.20531
   Choudhury N, 2020, J INFORMETR, V14, DOI 10.1016/j.joi.2020.101057
   Dey AK, 2019, P NATL ACAD SCI USA, V116, P19368, DOI 10.1073/pnas.1819529116
   Dhanith PRJ, 2021, INT J INTERACT MULTI, V6, P122, DOI 10.9781/ijimai.2020.09.003
   Dion ML, 2018, POLIT ANAL, V26, P312, DOI 10.1017/pan.2018.12
   Färber M, 2020, INT J DIGIT LIBRARIE, V21, P375, DOI 10.1007/s00799-020-00288-2
   Gunti P., 2022, Data mining approaches for big data and sentiment analysis in social media, P116
   Gusenbauer M, 2020, RES SYNTH METHODS, V11, P181, DOI 10.1002/jrsm.1378
   Gusenbauer M, 2019, SCIENTOMETRICS, V118, P177, DOI 10.1007/s11192-018-2958-5
   Hassan SU, 2018, SCIENTOMETRICS, V117, P1645, DOI 10.1007/s11192-018-2944-y
   Kim M, 2018, APPL SOFT COMPUT, V66, P506, DOI 10.1016/j.asoc.2017.09.028
   Konda A, 2020, ACS NANO, V14, P6339, DOI 10.1021/acsnano.0c03252
   Kuhn J, 2020, RAND J ECON, V51, P109, DOI 10.1111/1756-2171.12307
   Kumar S, 2014, SCIENTOMETRICS, V98, P387, DOI 10.1007/s11192-013-1059-8
   Masrour F, 2020, AAAI CONF ARTIF INTE, V34, P841
   Newman MEJ, 2014, EPL-EUROPHYS LETT, V105, DOI 10.1209/0295-5075/105/28002
   Ozcan A, 2019, INT J INF TECH DECIS, V18, P241, DOI 10.1142/S0219622018500530
   Porwal P., 2021, CITATION CLASSIFICAT, P540
   Qurat-ul Ain, 2019, SCIENTOMETRICS, V119, P187, DOI 10.1007/s11192-019-03009-y
   Razzaq S, 2022, INT J INTERACT MULTI, V7, P103, DOI 10.9781/ijimai.2022.03.001
   Stegehuis C, 2015, J INFORMETR, V9, P642, DOI 10.1016/j.joi.2015.06.005
   Tope Megha, 2019, International Journal of Scientific Development and Research, V4, P1
   van Dongen T, 2020, ARXIV
   Yu T, 2014, SCIENTOMETRICS, V101, P1233, DOI 10.1007/s11192-014-1279-6
   Zhang Q, 2023, PATTERN RECOGN LETT, V168, P31, DOI 10.1016/j.patrec.2023.02.026
NR 32
TC 0
Z9 0
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32245
EP 32276
AR s11042-023-16957-8
DI 10.1007/s11042-023-16957-8
EA SEP 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001070386400005
DA 2024-07-18
ER

PT J
AU Bokde, ND
   Patil, PK
   Sengupta, S
   Sawant, M
   Feijóo-Lorenzo, AE
AF Bokde, Neeraj Dhanraj
   Patil, Prajwal Kailasnath
   Sengupta, Saradindu
   Sawant, Manisha
   Feijoo-Lorenzo, Andres E.
TI VedicDateTime: An R package to implement Vedic calendar system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vedic calendar; Gregorian calendar; Panchanga; Time series analysis; R
   package
AB Calendar systems adopted across the world are either solar, lunar or lunisolar, based on the movements of the sun, the moon, or both. The Gregorian (solar) calendars are considered as time references for modern computations. However, Vedic calendars, being lunisolar, can be more effective for the analysis of activities that depend on both celestial bodies. In this paper, we present VedicDateTime, an open-source framework that implements the Vedic calendar and provides conversions for Gregorian dates. Along with package details, we also provide two case studies that make use of the proposed package for time-series analysis. The objective of this paper is to motivate researchers to explore the potential of the Vedic calendar from the perspective of time series analysis.
C1 [Bokde, Neeraj Dhanraj] Aarhus Univ, Ctr Quantitat Genet & Genom, DK-8000 Aarhus, Denmark.
   [Patil, Prajwal Kailasnath] KLE Technol Univ, BV Bhoomaraddi Campus, Hubballi 580031, Karnataka, India.
   [Sengupta, Saradindu] Indian Inst Informat Technol & Management, Kazhakkoottam 695581, Kerala, India.
   [Sawant, Manisha] Natl Inst Technol, Dept Elect & Commun Engn, Calicut 673601, Kerala, India.
   [Feijoo-Lorenzo, Andres E.] Univ Vigo, Dept Enxeneria Elect, EEI, Campus Lagoas Marcosende, Vigo 36310, Spain.
C3 Aarhus University; KLE Technological University; Kerala University of
   Digital Sciences, Innovation & Technology (Digital University Kerala);
   National Institute of Technology (NIT System); National Institute of
   Technology Calicut; Universidade de Vigo
RP Bokde, ND (corresponding author), Aarhus Univ, Ctr Quantitat Genet & Genom, DK-8000 Aarhus, Denmark.
EM neerajdhanraj@qgg.au.dk
RI Bokde, Neeraj Dhanraj/I-2621-2016; Feijóo-Lorenzo, Andrés
   Elías/D-3866-2019; Sawant, Manisha/JRX-5340-2023
OI Bokde, Neeraj Dhanraj/0000-0002-3493-9302; Feijóo-Lorenzo, Andrés
   Elías/0000-0003-3172-7037; Sawant, Manisha/0009-0009-9399-1002
FU Royal Danish Library, Aarhus University Library
FX The authors would like to thank Google Inc. for its support and funds
   for the project through Google Summer of Code - 2022.
CR [Anonymous], 2018, Calendrical Calculations
   Basham AL, 1974, The wonder that was India
   Bhattacharya R, 2016, Tech rep
   Bokde Neeraj Dhanraj, 2023, CRAN
   Bokde ND, 2021, Arxiv, DOI arXiv:2111.03441
   Bureau UC, 2013, X-13ARIMA-SEATS Seasonal Adjustment Program
   Callan D, 2021, ethiopiandate: Convert between gregorian and ethiopian calendars
   Chakrabarti V., 1999, Indian Architectural Theory: Contemporary Uses of Vastu Vidya
   CLEVELAND WS, 1982, J AM STAT ASSOC, V77, P520, DOI 10.2307/2287705
   CRAN, 2023, CRAN Package Check Results for Package VedicDateTime
   De Livera AM, 2011, J AM STAT ASSOC, V106, P1513, DOI 10.1198/jasa.2011.tm09771
   Dorminey B, 2009, Sci Am, V21
   Gangooly P, 1989, The Surya siddhanta the Surya siddhanta: A text-book of Hindu-astronomy
   Griffith RTH, 2010, The hymns of the Atharva Veda
   Heris D, 2020, pyroj: Converting Gregorian and Solar dates to Kurdish date
   Hyndman RJ, 2023, CRAN Task View: Time Series Analysis
   indenkun, 2021, jcalendar: Interconversion between the japanese calendar system and the western calendar
   Jalilian Abdollah, 2021, CRAN
   Kumar A, 2020, J INDIAN I SCI, V100, P221, DOI 10.1007/s41745-019-00157-1
   Kumar H., 2017, MUDRA: Journal of Finance and Accounting, V4, P1, DOI [10.17492/mudra.v4i01.9780, DOI 10.17492/MUDRA.V4I01.9780]
   Lin J-L, 2023, Modeling Lunar Calendar Holiday Effects in Taiwan
   List MS, 2022, Pyluach: A Python package for manipulating Hebrew (Jewish) calendar dates and Hebrew-Gregorian conversion
   Maravall A, 2000, COMPSTAT P COMPUTATI, P121
   Maravall A, 2000, The Swiss CPI series, P121, DOI [10.1007/978-3-642-57678-2_11, DOI 10.1007/978-3-642-57678-2_11]
   Ramakumar KL, 2023, Panchangam calculations
   Ramana BV, 1992, Astrology in Predicting Weather and Earthquakes
   Ruiz E, 2021, maya: Converts between mayan and gregorian calendars
   Sanyal A, 2017, Statistics, V04
   Sax C, 2023, Seasonal adjustment by {x-13arima-seats} in {r} 87, DOI [10.18637/jss.v087.i11, DOI 10.18637/JSS.V087.I11]
   Sax C, 2018, J STAT SOFTW, V87, P1, DOI 10.18637/jss.v087.i11
   Shiskin J, 1965, Technical paper
   Tilak LB, 1955, The Orion or Researches into the Antiquity of the Vedas
   Tripathi A, 2020, sanatantime: Python module to convert christian system time to vedic sanatan time
   Van Wijk J. J., 1999, Proceedings 1999 IEEE Symposium on Information Visualization (InfoVis'99), P4, DOI 10.1109/INFVIS.1999.801851
   Yen LW, 2013, lunisolar: Converting Gregorian and Solar dates to Kurdish date
NR 35
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32141
EP 32157
DI 10.1007/s11042-023-16553-w
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900002
OA hybrid
DA 2024-07-18
ER

PT J
AU Zouache, D
   Abualigah, L
   Boumaza, F
AF Zouache, Djaafar
   Abualigah, Laith
   Boumaza, Farid
TI A guided epsilon-dominance arithmetic optimization algorithm for
   effective multi-objective optimization in engineering design problems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-objective optimization; Crowding distance; Epsilon-dominance;
   Arithmetic optimization algorithm; Engineering design application
AB The Arithmetic Optimization Algorithm (AOA) was recently proposed as a solution for single-objective real continuous problems and has demonstrated superior performance in various contexts. This paper presents a multi-objective version of the algorithm to solve multi-objective problems. The MOAOA employs an archive repository to keep and retrieve the non-dominated solutions produced during optimization. The leaders are then selected from the population archive to lead the solutions of the main population toward the potential search locations. The epsilon-dominance and crowding distance strategies balance the convergence and diversity of the obtained Pareto set. To assess the effectiveness and efficiency of the proposed algorithm, it was tested on various dimensions of multi-objective benchmarks, among them: five unconstrained test functions taken from ZDT-series and four multi-objective constrained tests functions (BNH, SRN, TNK, OSY). Also, it is evaluated on four multi-objective structural design problems, such as welded beam design, speed-reduced design, disk brake design, and four-bar truss design. The algorithm is compared with three algorithms widely used in multi-objectives optimization, such as MSSA, MOEA-D, and MOGWO. The comparison results demonstrate that MOAOA outperforms all other algorithms in terms of both convergence and diversity of solutions, achieving a score of (100%,100%) in the ZDT tests, (75%,50%) in the constrained test functions, and (75%,75%) for the structural design problems.
C1 [Zouache, Djaafar; Boumaza, Farid] Univ Mohamed El Bachir El Ibrahimi, Dept Comp Sci, Bordj Bou Arreridj, Algeria.
   [Zouache, Djaafar] Univ Sci & Technol Houari Boumediene, LRIA Lab, Algiers, Algeria.
   [Abualigah, Laith] Al al Bayt Univ, Prince Hussein Bin Abdullah Fac Informat Technol, Comp Sci Dept, Mafraq 25113, Jordan.
   [Abualigah, Laith] Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos 13505, Lebanon.
   [Abualigah, Laith] Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.
   [Abualigah, Laith] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
   [Abualigah, Laith] Appl Sci Private Univ, Appl Sci Res Ctr, Amman 11931, Jordan.
   [Abualigah, Laith] Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
   [Abualigah, Laith] Sunway Univ Malaysia, Sch Engn & Technol, Petaling Jaya 27500, Malaysia.
   [Boumaza, Farid] Univ Oran1, Dept Comp Sci, Oran, Algeria.
C3 University Science & Technology Houari Boumediene; Al al-Bayt
   University; Lebanese American University; Al-Ahliyya Amman University;
   Middle East University; Universiti Sains Malaysia; Sunway University
RP Zouache, D (corresponding author), Univ Mohamed El Bachir El Ibrahimi, Dept Comp Sci, Bordj Bou Arreridj, Algeria.; Zouache, D (corresponding author), Univ Sci & Technol Houari Boumediene, LRIA Lab, Algiers, Algeria.
EM djaafarzouache@yahoo.fr; aligah.20202@gmail.com; farid.pgia@gmail.com
RI Abualigah, Laith/ABC-9695-2020
OI Abualigah, Laith/0000-0002-2203-4549
CR Abualigah L, 2023, J Bionic Eng, P1
   Abualigah L, 2021, J Ambient Intell Humaniz Comput, P1
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Abualigah L, 2021, CLUSTER COMPUT, V24, P205, DOI 10.1007/s10586-020-03075-5
   Abualigah LM, 2018, ENG APPL ARTIF INTEL, V73, P111, DOI 10.1016/j.engappai.2018.05.003
   Allou L, 2022, NEURAL COMPUT APPL, V34, P17007, DOI 10.1007/s00521-022-07352-9
   Dabba A, 2020, INFOR, V58, P38, DOI 10.1080/03155986.2019.1629782
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Emmerich MTM, 2018, NAT COMPUT, V17, P585, DOI 10.1007/s11047-018-9685-y
   Ewees AA, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9182321
   Feng ZW, 2015, J GLOBAL OPTIM, V61, P677, DOI 10.1007/s10898-014-0210-2
   Got A, 2022, KNOWL-BASED SYST, V237, DOI 10.1016/j.knosys.2021.107880
   Hemici M, 2023, APPL SOFT COMPUT, V141, DOI 10.1016/j.asoc.2023.110282
   Jangir P, 2023, EVOL INTELL, V16, P169, DOI 10.1007/s12065-021-00649-z
   Kahloul S, 2022, ENG APPL ARTIF INTEL, V109, DOI 10.1016/j.engappai.2021.104588
   Khishe M, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118734
   Laumanns M, 2002, EVOL COMPUT, V10, P263, DOI 10.1162/106365602760234108
   Li K, 2015, INFORM SCIENCES, V309, P50, DOI 10.1016/j.ins.2015.03.002
   Liang J, 2023, IEEE T EVOLUT COMPUT, V27, P201, DOI 10.1109/TEVC.2022.3155533
   Mirjalili S., 2022, Handbook of moth-flame optimization algorithm: variants, hybrids, improvements, and applications, V1, DOI [10.1201/9781003205326, DOI 10.1201/9781003205326]
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2016, EXPERT SYST APPL, V47, P106, DOI 10.1016/j.eswa.2015.10.039
   Picheny V, 2015, STAT COMPUT, V25, P1265, DOI 10.1007/s11222-014-9477-x
   Premkumar M, 2021, IEEE ACCESS, V9, P84263, DOI 10.1109/ACCESS.2021.3085529
   Qiao KJ, 2022, IEEE T EVOLUT COMPUT, V26, P263, DOI 10.1109/TEVC.2022.3145582
   Rahimi I, 2023, ARCH COMPUT METHOD E, V30, P2181, DOI 10.1007/s11831-022-09859-9
   Sierra MR, 2004, Technical Report of CINVESTAV-IPN
   Tanabe R, 2018, LECT NOTES COMPUT SC, V11101, P249, DOI 10.1007/978-3-319-99253-2_20
   While L, 2006, IEEE T EVOLUT COMPUT, V10, P29, DOI 10.1109/TEVC.2005.851275
   Yang SM, 2023, MULTIMED TOOLS APPL, V82, P14107, DOI 10.1007/s11042-022-13846-4
   Zhang QF, 2007, IEEE T EVOLUT COMPUT, V11, P712, DOI 10.1109/TEVC.2007.892759
   Zheng R, 2021, PROCESSES, V9, DOI 10.3390/pr9101774
   Zitzler E, 1999, IEEE T EVOLUT COMPUT, V3, P257, DOI 10.1109/4235.797969
   Zitzler E, 2000, EVOL COMPUT, V8, P173, DOI 10.1162/106365600568202
   Zouache D, 2023, ARTIF INTELL REV, V56, P2607, DOI 10.1007/s10462-022-10235-z
   Zouache D, 2022, ANN OPER RES, DOI 10.1007/s10479-022-04641-3
   Zouache D, 2022, EXPERT SYST APPL, V189, DOI 10.1016/j.eswa.2021.116126
   Zouache D, 2021, ANN OPER RES, V296, P877, DOI 10.1007/s10479-019-03407-8
   Zouache D, 2019, COMPUT IND ENG, V129, P377, DOI 10.1016/j.cie.2019.01.055
   Zouache D, 2018, EUR J OPER RES, V264, P74, DOI 10.1016/j.ejor.2017.06.058
NR 41
TC 0
Z9 0
U1 6
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31673
EP 31700
DI 10.1007/s11042-023-16633-x
EA SEP 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001067934200011
DA 2024-07-18
ER

PT J
AU Oruganti, M
   Meenpal, T
   Majumder, S
AF Oruganti, Madhu
   Meenpal, Toshanlal
   Majumder, Saikat
TI Stationary wavelet transform features for kinship verification in
   childhood images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blood relationship estimation; Kinship verification; Facial images; Age
   variation; Illumination challenges; Feature extraction; Metric learning;
   Selective variance; Accuracy
AB Estimating blood relationships from facial images is a complex task in computer vision due to subtle differences. Existing models are facing difficulties in accurately assessing kin relationships, particularly when dealing with larger age variation datasets. This article proposes a novel approach that addresses these challenges and three key contributions. Firstly, childhood images are introduced as a new dimension for kinship verification, enabling the model to capture relevant facial features despite significant age discrepancies. Secondly, the extraction of facial features from low-illuminated images is a challenging problem. To overcome this, the proposed method employs stationary wavelet transformed (SWT) features and discrete cosine transformed (DCT) features. These features are enhanced through local patch-based SWT (LP-SWT) and LP-SWT-DCT methods. Basic statistical operations, such as mean and standard deviation, are applied to each patch for effective feature correlation. Finally, a selective variance-based method (SVBM) is proposed for metric learning. It selects distinguishable kin and non-kin pairs to design a global threshold, minimizing misclassifications. The proposed model achieves high accuracies: 85% for KinFaceW-I, 89% for KinFaceW-II, 88.90% for UBKINFACE, 85.11% for TSKINFACE, and 88.08% for KFVW. It surpasses state-of-the-art schemes in efficacy.
C1 [Oruganti, Madhu; Meenpal, Toshanlal; Majumder, Saikat] Natl Inst Technol, Dept ECE, GE Rd, Raipur 492010, CG, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Oruganti, M (corresponding author), Natl Inst Technol, Dept ECE, GE Rd, Raipur 492010, CG, India.
EM moruganti.phd2019.ece@nitrr.ac.in
RI Oruganti, Madhu/KIJ-9331-2024
OI Oruganti, Madhu/0000-0002-6274-3606
CR Aliradi R, 2018, Multimed Tools Appl, V28, P1
   Alirezazadeh P, 2015, IEEE SIGNAL PROC LET, V22, P2459, DOI 10.1109/LSP.2015.2490805
   Almuashi M, 2017, MULTIMED TOOLS APPL, V76, P265, DOI 10.1007/s11042-015-3007-5
   Cao J, 2018, ADV NEUR IN, V31
   Chen XP, 2021, IEEE T CIRC SYST VID, V31, P1939, DOI 10.1109/TCSVT.2020.3017683
   Cui LY, 2017, IEEE INT CON MULTI, P751, DOI 10.1109/ICME.2017.8019326
   Dong GN, 2021, IEEE T INF FOREN SEC, V16, P4197, DOI 10.1109/TIFS.2021.3098165
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Georgopoulos M, 2018, IMAGE VISION COMPUT, V80, P58, DOI 10.1016/j.imavis.2018.05.003
   Goyal A, 2021, IEEE T IMAGE PROCESS, V30, P191, DOI 10.1109/TIP.2020.3034027
   Goyal A, 2021, PATTERN ANAL APPL, V24, P119, DOI 10.1007/s10044-020-00906-4
   Gujunoori S, 2017, 2017 2 INT C EM COMP, P1, DOI [10.1109/ICECIT.2017.8456442, DOI 10.1109/ICECIT.2017.8456442]
   Guo GD, 2012, IEEE T INSTRUM MEAS, V61, P2322, DOI 10.1109/TIM.2012.2187468
   Kohli N., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P245, DOI 10.1109/BTAS.2012.6374584
   Kohli N, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2609811
   Li WH, 2021, PROC CVPR IEEE, P16130, DOI 10.1109/CVPR46437.2021.01587
   Li WH, 2021, IEEE T IMAGE PROCESS, V30, P4947, DOI 10.1109/TIP.2021.3077111
   Liang JQ, 2019, IEEE T IMAGE PROCESS, V28, P1149, DOI 10.1109/TIP.2018.2875346
   Liu HJ, 2017, IEEE INT CON MULTI, P319, DOI 10.1109/ICME.2017.8019375
   Liu J, 2023, RADIAT PHYS CHEM, V203, DOI 10.1016/j.radphyschem.2022.110592
   Liu Q, 2016, 2016 IEEE WINT C APP, P1
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Lopez MB, 2018, MACH VISION APPL, V29, P873, DOI 10.1007/s00138-018-0943-x
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Mahpod S, 2018, COMPUT VIS IMAGE UND, V167, P28, DOI 10.1016/j.cviu.2017.12.003
   Moujahid A, 2019, MULTIMED TOOLS APPL, V78, P9335, DOI 10.1007/s11042-018-6517-0
   Mukherjee M, 2022, J VIS COMMUN IMAGE R, V84, DOI 10.1016/j.jvcir.2022.103470
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oruganti M, 2023, 2023 INT C ADV TECHN, P1, DOI [10.1109/ICONAT57137.2023.10080273, DOI 10.1109/ICONAT57137.2023.10080273]
   Oruganti M, 2021, 2021 NAT C COMM NCC, P1
   Patel B, 2017, COMPUT VIS IMAGE UND, V160, P24, DOI 10.1016/j.cviu.2017.04.009
   Puthenputhussery A, 2016, IEEE IMAGE PROC, P2921, DOI 10.1109/ICIP.2016.7532894
   Qayyum H, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/9854050
   Qin XQ, 2020, NEUROCOMPUTING, V377, P213, DOI 10.1016/j.neucom.2019.09.089
   Qin XQ, 2015, IEEE T MULTIMEDIA, V17, P1855, DOI 10.1109/TMM.2015.2461462
   Ribeiro GT, 2019, ENG APPL ARTIF INTEL, V82, P272, DOI 10.1016/j.engappai.2019.03.012
   Robinson J. P., 2016, P 24 ACM INT C MULT, P242, DOI DOI 10.1145/2964284.2967219
   Robinson JP, 2018, IEEE T PATTERN ANAL, V40, P2624, DOI 10.1109/TPAMI.2018.2826549
   Stefenon SF, 2020, INT J ELEC POWER, V123, DOI 10.1016/j.ijepes.2020.106269
   Sun JQ, 2022, NEUROCOMPUTING, V514, P285, DOI 10.1016/j.neucom.2022.09.149
   team Y, 2023, Yellow class childhood contest
   Wang YQ, 2014, IMAGE PROCESS ON LIN, V4, P128, DOI 10.5201/ipol.2014.104
   Wei ZQ, 2019, IEEE ACCESS, V7, P100029, DOI 10.1109/ACCESS.2019.2929939
   Wu HS, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103265
   Xia SY, 2012, IEEE T MULTIMEDIA, V14, P1046, DOI 10.1109/TMM.2012.2187436
   Xu M, 2016, IEEE ACCESS, V4, P10280, DOI 10.1109/ACCESS.2016.2635147
   Yan HB, 2019, PATTERN RECOGN LETT, V117, P146, DOI 10.1016/j.patrec.2018.05.027
   Yan HB, 2018, PATTERN RECOGN, V75, P15, DOI 10.1016/j.patcog.2017.03.001
   Yan HB, 2015, IEEE T CYBERNETICS, V45, P2535, DOI 10.1109/TCYB.2014.2376934
   Yan HB, 2014, IEEE T INF FOREN SEC, V9, P1169, DOI 10.1109/TIFS.2014.2327757
   YANG Y., 2017, P INT C ART INT ENG, V10, P947
   Zhang HM, 2019, IEEE IMAGE PROC, P3856, DOI [10.1109/ICIP.2019.8803647, 10.1109/icip.2019.8803647]
   Zhang L, 2021, IEEE T CYBERNETICS, V51, P5883, DOI 10.1109/TCYB.2019.2959403
   Zhang YT, 2015, PROC CVPR IEEE, P249, DOI 10.1109/CVPR.2015.7298621
   Zhang ZG, 2022, APPL MATH COMPUT, V428, DOI 10.1016/j.amc.2022.127179
   Zhao YG, 2018, INFORM SCIENCES, V430, P247, DOI 10.1016/j.ins.2017.11.048
   Zhou XZ, 2019, INFORM FUSION, V48, P84, DOI 10.1016/j.inffus.2018.07.011
   Zhou XZ, 2016, INFORM FUSION, V32, P40, DOI 10.1016/j.inffus.2015.08.006
   Zhou Xiuzhuang, 2012, P 20 ACM INT C MULT, P725, DOI [DOI 10.1145/2393347, DOI 10.1145/2393347.2396297]
NR 60
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29689
EP 29714
DI 10.1007/s11042-023-16694-y
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001064737700005
DA 2024-07-18
ER

PT J
AU Parsons, L
   Deng, G
   Ross, R
AF Parsons, Lyle
   Deng, Guang
   Ross, Robert
TI Detecting image edges in IOT nodes without FPU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Edge computing; Internet of things; Integer arithmetic; Image processing
AB Internet of Things (IoT) applications continue to expand into new applications with a growing need for image processing on the edge. Many edge devices are resource limited microcontrollers, which significantly prohibits many of the mature image processing algorithms. This paper proposes an approach optimized, for resource constrained processors removing the need for computationally expensive floating point arithmetic by using a framework based on unsigned integer arithmetic for image processing. The proposed framework (OptInt) is demonstrated using edge detection algorithms evaluated on two typical low-power IoT-ready micro-controllers and for comparison a more powerful Raspberry Pi. Results indicate that the OptInt approach for basic image processing in resource constrained devices reduces the computation time as well as the memory requirements, thereby allowing for more edge computing capabilities in these devices. Furthermore, the images produced using OptInt produce results of similar quality to mature edge detection algorithms.
C1 [Parsons, Lyle; Deng, Guang; Ross, Robert] La Trobe Univ, Dept Engn, Sci Dr, Bundoora, Vic 3086, Australia.
C3 La Trobe University
RP Ross, R (corresponding author), La Trobe Univ, Dept Engn, Sci Dr, Bundoora, Vic 3086, Australia.
EM lylecp2002@gmail.com; D.Deng@latrobe.edu.au; R.Ross@latrobe.edu.au
OI Ross, Robert/0000-0002-2796-784X
CR Adelantado F, 2017, IEEE COMMUN MAG, V55, P34, DOI 10.1109/MCOM.2017.1600613
   Agarap A. F., 2018, ARXIV
   Al-Kofahi MM, 2019, COMPUT ELECTR ENG, V79, DOI 10.1016/j.compeleceng.2019.106457
   Alsaawy Y, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12042043
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bonomi Flavio, 2012, P 1 MCC WORKSH MOB C, P13, DOI 10.1145/2342509.2342513
   Cabello F, 2015, SPA 2015 SIGNAL PROCESSING ALGORITHMS, ARCHITECTURES, ARRANGEMENTS, AND APPLICATIONS, P28, DOI 10.1109/SPA.2015.7365108
   Dongarra JJ, 2003, CONCURR COMP-PRACT E, V15, P803, DOI 10.1002/cpe.728
   .espressif, 2020, ESP32 WI FI BLUETOOT
   espressif, 2020, ESP8266 WI FI MODULE
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hu XH, 2022, IEEE T CIRCUITS-II, V69, P2301, DOI 10.1109/TCSII.2022.3150980
   Hwang K, 2014, IEEE WRK SIG PRO SYS, P174
   Ivkovic J, 2017, P INT C INF SOC TECH, ppp12
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Kahan W., 1996, Lect. Not. Status IEEE 754 (94720-1776), V754, P94720
   Khan J.Y., 2019, Internet of Things (IoT): Systems and Applications
   Lakshmia PY, 2023, RECENT DEV ELECT COM, V32, P45
   Lampert CH, 2006, IEEE IMAGE PROC, P1565, DOI 10.1109/ICIP.2006.312606
   LIMARE N, 2014, INTEGER FLOATING POI
   Longbottom R, 2018, RASPBERRY PI 3B 32 B, DOI [10.13140/RG.2.2.31859.58403, DOI 10.13140/RG.2.2.31859.58403]
   Mrozek D, 2020, INFORM SCIENCES, V537, P132, DOI 10.1016/j.ins.2020.05.070
   Punyavathi G, 2022, MATER TODAY-PROC, V51, P909, DOI 10.1016/j.matpr.2021.06.283
   Ram B, 2001, ADV MICROPROCESSORS
   Ramakrishnan A, 2011, IEEE SOUTHEASTCON, P97, DOI 10.1109/SECON.2011.5752913
   raspberrypi, 2020, RASPBERRY PI 3 MODEL
   Ross R, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174670
   Safonov I, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010078
   Sharma A, 2020, SUSTAIN CITIES SOC, V61, DOI 10.1016/j.scs.2020.102332
   Shrivakshan G., 2012, INT J COMPUT SCI ISS, V9, P269
   Yates R., 2009, Digital Signal Labs, V81, P198
   York R, 2002, BENCHMARKING CONTEXT
   Yu W, 2018, IEEE ACCESS, V6, P6900, DOI 10.1109/ACCESS.2017.2778504
NR 34
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 31161
EP 31175
DI 10.1007/s11042-023-16672-4
EA SEP 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001081631900003
OA hybrid
DA 2024-07-18
ER

PT J
AU Anitha, R
   Dasari, DB
   Vivek, PSS
   Kakarla, NML
   Kumar, MS
AF Anitha, Raju
   Dasari, Durga Bhavani
   Vivek, P. Sandalya Sai
   Kakarla, Naga Madhavi Latha
   Kumar, M. Sirish
TI A novel adaptive dual swarm intelligence based image quality enhancement
   approach with the modified SegNet -RBM-based Alzheimer Segmentation and
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's disease; Restricted Boltzmann Machine; Adaptive salp swarm
   optimization algorithm; SegNet; Adaptive wind driven optimization
   algorithm
ID DISEASE; DIAGNOSIS; MODEL
AB In this research, a novel metaheuristic-based approach for enhancing the image quality of Magnetic resonance imaging (MRI) scans for Alzheimer's disease (AD) classification and segmentation is proposed. The proposed approach involves four phases: data collection, preprocessing, segmentation, and classification. The dataset used in this study is collected from an open-source internet platform and contains four classes of AD. To improve the quality of the collected images, various enhancement techniques are employed, such as local entropy-weighted histogram equalization using an adaptive wind-driven optimization algorithm and guided filter-based image denoising using an adaptive Salp Swarm Optimization algorithm. In addition to this, geometric transformations, image augmentation, noise reduction, and grayscale conversion are also utilized. The proposed segmentation model employs a drop-block in Segmentation Network (SegNet) for regularized feature learning, resulting in highly efficient pixel-wise segmentation. A modified loss function is also introduced for fine-tuning the performance of SegNet. The classification layer of SegNet utilizes a Restricted boltzmann machine (RBM) model for classifying AD. Performance evaluation of the proposed approach is done by considering performance metrics such as accuracy, precision, recall, F1-measure, Root means square error (RMSE), and mean absolute error (MAE). The proposed approach outperforms existing techniques such as Convolutional neural network (CNN), Recurrent neural network (RNN), Long short-term memory (LSTM), Understanding networks (UNET), and SegNet, demonstrating the effectiveness of the proposed metaheuristic-based image quality enhancement approach. The implementation of the proposed approach is carried out using Matlab.
C1 [Anitha, Raju] Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram, AP, India.
   [Dasari, Durga Bhavani] Inst Aeronaut Engn, Dept CSE, Hyderabad 500043, Telangana, India.
   [Vivek, P. Sandalya Sai] Indian Inst Informat Technol Design & Mfg IIITDM, Kurnool, India.
   [Kakarla, Naga Madhavi Latha] Sir CR Reddy Coll Engn, Dept CSE, Eluru, AP, India.
   [Kumar, M. Sirish] Mohan Babu Univ, Sch Comp, Tirupati, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Anitha, R (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram, AP, India.
EM rajuanitha46885@gmail.com
RI KAKARLA, NAGA MADHAVI LATHA/ABC-9511-2021; Raju, Anitha/U-6059-2018;
   Anitha, Raju/ABF-4410-2020; KUMAR, DR M SIRISH/IAO-4832-2023
OI KAKARLA, NAGA MADHAVI LATHA/0000-0001-5330-9181; Raju,
   Anitha/0000-0002-3786-7308; Anitha, Raju/0000-0002-3786-7308; KUMAR, DR
   M SIRISH/0009-0004-6381-8173; DurgaBhavani, Dasari/0000-0001-7001-5150
CR Ahmed S, 2019, IEEE ACCESS, V7, P73373, DOI 10.1109/ACCESS.2019.2920011
   Ashtari-Majlan M, 2022, IEEE J BIOMED HEALTH, V26, P3918, DOI 10.1109/JBHI.2022.3155705
   Basher A, 2021, IEEE ACCESS, V9, P29870, DOI 10.1109/ACCESS.2021.3059658
   Brand L, 2020, IEEE T MED IMAGING, V39, P1845, DOI 10.1109/TMI.2019.2958943
   Dao Q, 2023, IEEE ACCESS, V11, P2148, DOI 10.1109/ACCESS.2022.3232396
   Eke CS, 2021, IEEE J BIOMED HEALTH, V25, P218, DOI 10.1109/JBHI.2020.2984355
   Gao XY, 2022, IEEE J BIOMED HEALTH, V26, P36, DOI 10.1109/JBHI.2021.3097721
   Guo XJ, 2022, IEEE ACM T COMPUT BI, V19, P2613, DOI 10.1109/TCBB.2021.3106939
   Haider F, 2020, IEEE J-STSP, V14, P272, DOI 10.1109/JSTSP.2019.2955022
   Kaggle, 2023, About us
   Khan YF, 2022, IEEE ACCESS, V10, P126990, DOI 10.1109/ACCESS.2022.3223681
   Klepl D, 2022, IEEE T NEUR SYS REH, V30, P2651, DOI 10.1109/TNSRE.2022.3204913
   Klepl D, 2022, IEEE J BIOMED HEALTH, V26, P992, DOI 10.1109/JBHI.2021.3105397
   Li K, 2021, IEEE T NEUR SYS REH, V29, P1557, DOI 10.1109/TNSRE.2021.3101240
   Li W, 2019, IEEE J BIOMED HEALTH, V23, P1234, DOI 10.1109/JBHI.2018.2839771
   Li X, 2021, IEEE J BIOMED HEALTH, V25, P3677, DOI 10.1109/JBHI.2021.3093027
   Lian CF, 2020, IEEE T PATTERN ANAL, V42, P880, DOI 10.1109/TPAMI.2018.2889096
   Martinez-Murcia FJ, 2020, IEEE J BIOMED HEALTH, V24, P17, DOI 10.1109/JBHI.2019.2914970
   Mccombe N, 2022, IEEE J TRANSL ENG HE, V10, DOI 10.1109/JTEHM.2022.3164806
   Murugan S, 2021, IEEE ACCESS, V9, P90319, DOI 10.1109/ACCESS.2021.3090474
   Palacios-Navarro G, 2022, IEEE T NEUR SYS REH, V30, P2225, DOI 10.1109/TNSRE.2022.3196435
   Tanveer M, 2022, IEEE J BIOMED HEALTH, V26, P1453, DOI 10.1109/JBHI.2021.3083274
   Zaina HS, 2022, IEEE ACCESS, V10, P66511, DOI 10.1109/ACCESS.2022.3183185
   Zhang Y, 2023, IEEE J TRANSL ENG HE, V11, P1, DOI 10.1109/JTEHM.2022.3219775
   Zhao YF, 2020, IEEE T MED IMAGING, V39, P1571, DOI 10.1109/TMI.2019.2953584
   Zhou T, 2019, IEEE T MED IMAGING, V38, P2411, DOI 10.1109/TMI.2019.2913158
NR 26
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29261
EP 29288
DI 10.1007/s11042-023-16486-4
EA SEP 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066976400002
DA 2024-07-18
ER

PT J
AU Mewada, A
   Dewang, RK
AF Mewada, Arvind
   Dewang, Rupesh Kumar
TI Cipf: identifying fake profiles on social media using a cnn-based
   communal influence propagation framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Fake profile; Malicious activity; Spam account; Balance
   theory; Social media mining
AB Social media has a profound impact on the formation of end-users' social, economic, and political views. Unfortunately, some advertisement agencies and miscreants use fake and misleading reviews to influence people's opinions on their political and business interests. These fake reviews are often posted using fake profiles to conceal the identity of the perpetrator. Such fake reviews are spread on social media platforms through Sockpuppets and Crowdturfing based fake accounts. This paper proposes the Communal Influence Propagation Framework (CIPF), which identifies fake accounts by analysing the essential features set from individual user profile, linguistic, and group profiles (network) feature in userspace. Initially, CIPF scrutinises individual user profile features, group profiles (network) features, and linguistic features to generate the feature vector of the userspace. The CIPF framework then uses the Influence, Homophily and Balance theory of Social Media Mining (SMM) to enrich the malicious user space as an influential index. Additionally, the Jaccard coefficient evaluates the similarity index vector over the influential negative node, identifies Sockpuppet nodes, and generates a negative propagation belonging matrix. The CIPF framework amalgamates influence-based two-tier verification of malicious nodes, the first being the Sockpuppet Detection Phase (IB-SPD) and the second being the Convolutional Neural Network (CNN) based influence-based Crowdturfing Community (IB-CFC). The CIPF framework is evaluated based on the classification performance of Sockpuppet nodes, modularity, and normalised mutual information of the structured crowdturfing community. As a result, the CIPF achieves an approximate 98% accuracy for classifying Sockpuppet nodes and a structured 0.94 modular and 0.91 informative crowdturfing community.
C1 [Mewada, Arvind; Dewang, Rupesh Kumar] Motilal Nehru Natl Inst Technol Allahabad, Prayagraj 211004, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Mewada, A (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Prayagraj 211004, India.
EM arvindmewada@mnnit.ac.in; rupeshdewang@mnnit.ac.in
RI Mewada, Arvind/AAX-2915-2021
OI Mewada, Arvind/0000-0002-4680-611X
CR Ahmad A, 2020, PHYSICA A, V545, DOI 10.1016/j.physa.2019.123590
   [Anonymous], 2003, P 9 ACM SIGKDD INT C, DOI DOI 10.1145/956750.956769
   Balakrishna Varun, 2022, 2022 International Conference on Data Analytics for Business and Industry (ICDABI), P650, DOI 10.1109/ICDABI56818.2022.10041687
   Beni HA, 2023, INFORM SCIENCES, V640, DOI 10.1016/j.ins.2023.119105
   Bianchi T, 2023, Most popular websites worldwide as of november 2022
   Borkar Bharat S., 2022, 2022 International Conference on Fourth Industrial Revolution Based Technology and Practices (ICFIRTP), P80, DOI 10.1109/ICFIRTP56122.2022.10059430
   Boyd DM, 2007, J COMPUT-MEDIAT COMM, V13, P210, DOI 10.1111/j.1083-6101.2007.00393.x
   Cao BK, 2014, IEEE DATA MINING, P50, DOI 10.1109/ICDM.2014.25
   Chen W, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P199, DOI 10.1145/1557019.1557047
   Cheng-Hsin Weng, 2010, Proceedings of the 2010 5th IEEE International Conference on Nano/Micro Engineered and Molecular Systems (NEMS 2010), P14, DOI 10.1109/NEMS.2010.5592127
   Concone F, 2022, IEEE Trans Depend Secure Comp
   Corradini E, 2021, INT J INFORM MANAGE, V60, DOI 10.1016/j.ijinfomgt.2021.102377
   Cresci S, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P963, DOI 10.1145/3041021.3055135
   Dixon S., 2023, Number of Monthly Active Facebook Users Worldwide as of 3rd Quarter
   Dong C, 2023, EXPERT SYST APPL, V212, DOI 10.1016/j.eswa.2022.118702
   Du YP, 2019, EXPERT SYST APPL, V123, P227, DOI 10.1016/j.eswa.2019.01.044
   Fazil M, 2021, IEEE T INF FOREN SEC, V16, P4211, DOI 10.1109/TIFS.2021.3102498
   Goyal A., 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P211, DOI 10.1109/ICDM.2011.132
   Guesmi S, 2019, PROCEDIA COMPUT SCI, V159, P291, DOI 10.1016/j.procs.2019.09.184
   Han SQ, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105550
   Hanteer O, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P531, DOI 10.1109/ASONAM.2018.8508575
   Jebabli M, 2018, PHYSICA A, V492, P651, DOI 10.1016/j.physa.2017.10.018
   Jiang JC, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105522
   Jung K, 2012, IEEE DATA MINING, P918, DOI 10.1109/ICDM.2012.79
   Kavin BP, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/6356152
   Keikha MM, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112905
   Kim HJ, 2018, INFORM SCIENCES, V432, P185, DOI 10.1016/j.ins.2017.12.004
   Leskovec J, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P420
   Li C.-T., 2012, P 21 INT C WORLD WID, P559
   Li DY, 2021, KNOWL-BASED SYST, V221, DOI 10.1016/j.knosys.2021.106961
   Li J, 2023, Multimed Tools Appl, P1
   Li WM, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114207
   Liu DJ, 2021, IEEE ACCESS, V9, P132631, DOI 10.1109/ACCESS.2021.3115605
   Liu L, 2012, DATA MIN KNOWL DISC, V25, P511, DOI 10.1007/s10618-012-0252-3
   Liu ST, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-16576-7
   Liu YH, 2023, J SUPERCOMPUT, V79, P18667, DOI 10.1007/s11227-023-05376-z
   Maity SK, 2017, CSCW'17: COMPANION OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P243, DOI 10.1145/3022198.3026360
   Mei JP, 2019, DATA MIN KNOWL DISC, V33, P1059, DOI 10.1007/s10618-019-00626-2
   Mello JP Jr, 2023, A third of us social media users creating fake accounts
   Mewada A, 2022, J KING SAUD UNIV-COM, V34, P7530, DOI 10.1016/j.jksuci.2021.07.021
   Mewada A, 2023, J SUPERCOMPUT, V79, P5516, DOI 10.1007/s11227-022-04881-x
   Mewada A, 2023, MULTIMED TOOLS APPL, V82, P13199, DOI 10.1007/s11042-022-13702-5
   Molaei S, 2020, EXPERT SYST APPL, V160, DOI 10.1016/j.eswa.2020.113580
   Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103
   Nguyen NL, 2022, IEEE SYST J, V16, P1873, DOI 10.1109/JSYST.2021.3117815
   Pelaez JI, 2019, KNOWL-BASED SYST, V172, P33, DOI 10.1016/j.knosys.2019.02.009
   Rezaul H, 2023, Int J Cogn Comput Eng
   Rout JK, 2023, IEEE T COMPUT SOC SY, DOI 10.1109/TCSS.2023.3243139
   Sahoo SR, 2019, COMPUT ELECTR ENG, V76, P65, DOI 10.1016/j.compeleceng.2019.03.003
   Sakib Mostofa Najmus, 2022, 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P155, DOI 10.1109/ASONAM55673.2022.10068604
   Sansonetti G, 2020, IEEE ACCESS, V8, P213154, DOI 10.1109/ACCESS.2020.3040604
   Shen H, 2022, IEEE ACCESS, V10, P91192, DOI 10.1109/ACCESS.2022.3171846
   Singh A, 2019, FUTURE GENER COMP SY, V94, P173, DOI 10.1016/j.future.2018.11.026
   Song JH, 2018, KNOWL-BASED SYST, V159, P244, DOI 10.1016/j.knosys.2018.07.010
   Sowmya P., 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0067, DOI 10.1109/ICCSP48568.2020.9182353
   Tang ML, 2019, IEEE ACCESS, V7, P109646, DOI 10.1109/ACCESS.2019.2930474
   Tommasel A, 2018, NEUROCOMPUTING, V289, P195, DOI 10.1016/j.neucom.2018.02.023
   Van Der Walt E, 2018, IEEE ACCESS, V6, P6540, DOI 10.1109/ACCESS.2018.2796018
   Wang F, 2018, IEEE ACCESS, V6, P24660, DOI 10.1109/ACCESS.2018.2815904
   Wang TH, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116236
   Wang YS, 2015, LECT NOTES COMPUT SC, V9313, P141, DOI 10.1007/978-3-319-25255-1_12
   Wise J, 2023, How many people use twitter?
   Wu J, 2022, PEER PEER NETW APPL, V15, P1398, DOI 10.1007/s12083-022-01309-4
   Xie M, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103161
   Xiong Y, 2021, IEEE T KNOWL DATA EN, V33, P1960, DOI 10.1109/TKDE.2019.2947458
   Xu GX, 2021, INFORM SCIENCES, V576, P681, DOI 10.1016/j.ins.2021.07.072
   Yamak Z, 2018, KNOWL-BASED SYST, V149, P124, DOI 10.1016/j.knosys.2018.03.002
   Yang YD, 2019, IEEE INT CONF MOB DA, P557, DOI 10.1109/MDM.2019.00119
   Yu H, 2021, SMART INNOV SYST TEC, V218, P187, DOI 10.1007/978-981-33-6141-6_19
   Zareie A, 2018, EXPERT SYST APPL, V108, P96, DOI 10.1016/j.eswa.2018.05.001
   Zhang C, 2022, RELIAB ENG SYST SAFE, V222, DOI 10.1016/j.ress.2022.108445
   Zhang FZ, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103282
   Zhang YH, 2022, J INTELL INF SYST, V59, P1, DOI 10.1007/s10844-021-00681-6
   Zhang Z, 2023, EXPERT SYST APPL, V216, DOI 10.1016/j.eswa.2022.119454
   Zhou S, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2019.105458
   Zhu XY, 2022, IEEE T MULTIMEDIA, V24, P3074, DOI 10.1109/TMM.2021.3092571
NR 76
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29419
EP 29454
DI 10.1007/s11042-023-16685-z
EA SEP 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001063370800002
DA 2024-07-18
ER

PT J
AU Çakiroglu, F
   Kurban, R
   Durmus, A
   Karaköse, E
AF Cakiroglu, Fatma
   Kurban, Rifat
   Durmus, Ali
   Karakose, Ercan
TI Multi-focus image fusion by using swarm and physics based metaheuristic
   algorithms: a comparative study with archimedes, atomic orbital search,
   equilibrium, particle swarm, artificial bee colony and jellyfish search
   optimizers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-focus image fusion; Swarm-based optimization algorithm;
   Physics-based optimization algorithms
ID INFORMATION MEASURE; QUALITY ASSESSMENT; PERFORMANCE; TRANSFORM
AB The lenses focus only on the objects at a specific distance when an image is captured, the objects at other distances look blurred. This is referred to as the limited depth of field problem, and several attempts exist to solve this problem. Multi-focus image fusion is one of the most used methods when solving this problem. A clear image of the whole scene is obtained by fusing at least two different images obtained with different focuses. Block-based methods are one of the most used methods for multi-focus fusion at the pixel-level. The size of the block to be used is an important factor for determining the performance of the fusion. Thus, the block size must be optimized. In this study, the comparison between the swarm-based and physics-based algorithms is made to determine the optimal block size. The comparison has been made among the following optimization methods which are, namely, Archimedes Optimization Algorithm (AOA), Atomic Orbital Search (AOS) and Equilibrium Optimizer (EO) from the physics-based algorithms and Particle Swarm Optimization (PSO), Artificial Bee Colony (ABC) and Jellyfish Search Algorithm (JSA) from swarm-based algorithms. The swarm-based ABC and JSA algorithms have shown a better performance when compared to physics-based methods. Moreover, meta-heuristic algorithms, in general, are more adaptive compared to the traditional fusion methods.
C1 [Cakiroglu, Fatma] Kayseri Univ, Inst Grad Educ, Dept Elect & Elect Engn, Kayseri, Turkiye.
   [Kurban, Rifat] Abdullah Gul Univ, Engn Fac, Dept Comp Engn, Kayseri, Turkiye.
   [Durmus, Ali] Kayseri Univ, Engn & Architecture & Design Fac, Dept Elect & Elect Engn, Kayseri, Turkiye.
   [Karakose, Ercan] Kayseri Univ, Engn & Architecture & Design Fac, Dept Nat Sci, Kayseri, Turkiye.
C3 Kayseri University; Abdullah Gul University; Kayseri University; Kayseri
   University
RP Kurban, R (corresponding author), Abdullah Gul Univ, Engn Fac, Dept Comp Engn, Kayseri, Turkiye.
EM rifat.kurban@agu.edu.tr
RI Kurban, Rifat/B-1175-2012
OI Kurban, Rifat/0000-0002-0277-2210; Karakose, Ercan/0000-0001-5586-3258;
   Durmus, Ali/0000-0001-8283-8496
FU Kayseri University Scientific Research Projects Coordination Unit
   [FYL-2021-1051]
FX This work is supported by Kayseri University Scientific Research
   Projects Coordination Unit with the grant number FYL-2021-1051.
CR Aslantas V, 2015, AEU-INT J ELECTRON C, V69, P160, DOI 10.1016/j.aeue.2015.09.004
   Aslantas Veysel, 2014, Proceedings of the 11th International Conference on Informatics in Control, Automation and Robotics ICINCO 2014, P312
   Aslantas V, 2010, EXPERT SYST APPL, V37, P8861, DOI 10.1016/j.eswa.2010.06.011
   Aslantas V, 2009, OPT COMMUN, V282, P3231, DOI 10.1016/j.optcom.2009.05.021
   Azizi M, 2021, APPL MATH MODEL, V93, P657, DOI 10.1016/j.apm.2020.12.021
   Banharnsakun A, 2019, NEURAL COMPUT APPL, V31, P2025, DOI 10.1007/s00521-015-2061-2
   Baraiya S., 2014, INT J INNOVATIVE RES, V1, P86
   Bhat S, 2021, ARTIF INTELL REV, V54, P5735, DOI 10.1007/s10462-021-09961-7
   Bouzos O, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2922097
   Chen YB, 2018, IEEE T IMAGE PROCESS, V27, P1526, DOI 10.1109/TIP.2017.2779274
   Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002
   Chou JS, 2021, APPL MATH COMPUT, V389, DOI 10.1016/j.amc.2020.125535
   Citil F, 2022, EUR J SCI TECHNOL, P147, DOI [10.31590/ejosat.1136956, DOI 10.31590/EJOSAT.1136956]
   Desale RP, 2013, INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, IMAGE PROCESSING AND PATTERN RECOGNITION (ICSIPR 2013), P66, DOI 10.1109/ICSIPR.2013.6497960
   DS Maini and Ashwani Kumar Aggarwal, 2018, INT J INNOV ENG TECH, V10, P199, DOI DOI 10.21172/IJIET.102.29
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Estévez PA, 2009, IEEE T NEURAL NETWOR, V20, P189, DOI 10.1109/TNN.2008.2005601
   Faramarzi A, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105190
   Garg R, 2014, 2014 RECENT ADVANCES IN ENGINEERING AND COMPUTATIONAL SCIENCES (RAECS)
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   Ghassemian H, 2016, INFORM FUSION, V32, P75, DOI 10.1016/j.inffus.2016.03.003
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P789, DOI 10.1016/j.compeleceng.2011.04.016
   Hashim FA, 2021, APPL INTELL, V51, P1531, DOI 10.1007/s10489-020-01893-z
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   Helonde MRP, 2015, J COMPUT, VTech2, P76
   Hossny M, 2008, ELECTRON LETT, V44, P1066, DOI 10.1049/el:20081754
   Hu ZH, 2021, APPL INTELL, V51, P4453, DOI 10.1007/s10489-020-02066-8
   Huang W, 2007, PATTERN RECOGN LETT, V28, P1123, DOI 10.1016/j.patrec.2007.01.013
   Jiang Zhi-guo, 2004, Proceedings. Third International Conference on Image and Graphics, P176
   Kannan K., 2010, INT J COMPUTER APPL, V2, P88
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kaur G, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P1420, DOI 10.1109/ICEEOT.2016.7754918
   Kong J, 2008, INT J COMPUT SCI NET, V8, P220
   Kumar A., 2015, Int. J. Res. Electron. Commun. Technol., V3, P1
   Kuriakose Teneema, 2023, Curr Top Microbiol Immunol, V442, P65, DOI 10.1007/82_2019_189
   Li QL, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072143
   Li SS, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P167, DOI 10.1109/ICALIP.2008.4589989
   Li ZH, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P1050
   Liu Y, 2020, INFORM FUSION, V64, P71, DOI 10.1016/j.inffus.2020.06.013
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Meher B, 2019, INFORM FUSION, V48, P119, DOI 10.1016/j.inffus.2018.07.010
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Nejati M, 2017, INFORM FUSION, V36, P284, DOI 10.1016/j.inffus.2016.12.009
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Patel R, 2015, INT J COMPUT APPL, V109
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Phamila YAV, 2014, SIGNAL PROCESS, V95, P161, DOI 10.1016/j.sigpro.2013.09.001
   Pradnya PM, 2013, 2013 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND SIGNAL PROCESSING (ISSP), P77, DOI 10.1109/ISSP.2013.6526878
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Sahu D., 2012, Int. J. Mod. Eng. Res. (IJMER), V2, P4298
   Shreyamsha Kumar BK, 2013, SIGNAL IMAGE VIDEO P, V7, P1125, DOI 10.1007/s11760-012-0361-x
   Singh S., 2016, INT J SCI ENG RES, V7, P225
   Song Y, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-3, P401, DOI 10.1109/ROBIO.2006.340210
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Toprak AN, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P471, DOI 10.1109/UBMK.2018.8566416
   Vakaimalar E, 2019, MULTIMED TOOLS APPL, V78, P17573, DOI 10.1007/s11042-018-7124-9
   Wan T, 2013, PATTERN RECOGN LETT, V34, P1001, DOI 10.1016/j.patrec.2013.03.003
   Wang ZB, 2008, INFORM FUSION, V9, P176, DOI 10.1016/j.inffus.2007.04.003
   Wang ZJ, 2005, IEEE T GEOSCI REMOTE, V43, P1391, DOI 10.1109/TGRS.2005.846874
   Xia XH, 2018, SIGNAL PROCESS, V153, P71, DOI 10.1016/j.sigpro.2018.07.004
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang Y, 2011, PROCEDIA ENGINEER, V24, P177, DOI 10.1016/j.proeng.2011.11.2622
   Zafar I, 2006, IET C PUBLICATIONS, P606, DOI [10.1049/cp:20060600, DOI 10.1049/CP:20060600]
NR 67
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 44859
EP 44883
DI 10.1007/s11042-023-16651-9
EA SEP 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:001060763900004
DA 2024-07-18
ER

PT J
AU Sajjanar, R
   Dixit, UD
   Vagga, VK
AF Sajjanar, Ravikumar
   Dixit, Umesh D.
   Vagga, Vittalkumar K.
TI Advancements in hybrid approaches for brain tumor segmentation in MRI: a
   comprehensive review of machine learning and deep learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Deep learning; Brain tumor; Magnetic resonance imaging;
   Machine learning
ID CONVOLUTIONAL NEURAL-NETWORKS; MODEL; ARCHITECTURE; CNN
AB Magnetic resonance imaging (MRI) brain tumour segmentation is essential for the diagnosis, planning, and follow-up of patients with brain tumours. In an effort to increase efficiency and accuracy, a number of machine learning and deep learning algorithms have been developed over time to automate the segmentation process. Hybrid strategies, which include the advantages of both machine learning and deep learning, have become more and more popular as viable options. This in-depth analysis covers the developments in hybrid techniques for MRI segmentation of brain tumours. The essential ideas of machine learning and deep learning approaches are then covered, with an emphasis on their individual advantages and disadvantages. After that, the review explores the numerous hybrid strategies put out in the literature. In hybrid approaches, various phases of the segmentation pipeline are combined with machine learning and deep learning techniques. Pre-processing, feature extraction, and post-processing are examples of these phases. The paper examines at various combinations of methods utilised at these phases, such as segmentation using deep learning models and feature extraction utilising conventional machine learning algorithms. The implementation of ensemble approaches, which integrate forecasts from various models to improve segmentation accuracy, is also explored. The research study also examines the properties of freely accessible brain tumour datasets, which are essential for developing and testing hybrid models. To address the difficulties of generalisation and robustness in brain tumour segmentation, it emphasises the necessity of vast, varied, and annotated datasets. Additionally, by contrasting them with conventional machine learning and deep learning techniques, the review analyses the effectiveness of hybrid approaches reported in the literature. This comprehensive research provides information on recent advancements in hybrid techniques for MRI segmenting brain tumours. It emphasises the potential for merging deep learning and machine learning methods to enhance the precision and effectiveness of brain tumour segmentation, ultimately assisting in improving patient diagnosis and treatment planning.
C1 [Sajjanar, Ravikumar; Dixit, Umesh D.] BLDEAs V P Dr P G Halakatti Coll Engn & Technol, Dept Elect & Commun Engn, Vijayapura 586103, Karnataka, India.
   [Sajjanar, Ravikumar; Dixit, Umesh D.] Visvesvaraya Technol Univ, Belagavi 590018, India.
   [Vagga, Vittalkumar K.] Govt Polytech Koppal, Dept Elect & Commun Engn, Koppal 583231, Karnataka, India.
C3 Visvesvaraya Technological University
RP Sajjanar, R (corresponding author), BLDEAs V P Dr P G Halakatti Coll Engn & Technol, Dept Elect & Commun Engn, Vijayapura 586103, Karnataka, India.; Sajjanar, R (corresponding author), Visvesvaraya Technol Univ, Belagavi 590018, India.
EM ravikumar.sajjanar@gmail.com; uddixit@rediffmail.com; vkvagga@gmail.com
OI SAJJANAR, RAVIKUMAR/0009-0002-4484-9025
CR Abdel-Maksoud E, 2015, EGYPT INFORM J, V16, P71, DOI 10.1016/j.eij.2015.01.003
   Aboelenein NM, 2020, IEEE ACCESS, V8, P101406, DOI 10.1109/ACCESS.2020.2998601
   Ahmed ST, 2022, MALAYS J COMPUT SCI, P53, DOI 10.22452/mjcs.sp2022no2.5
   Amin J, 2018, FUTURE GENER COMP SY, V87, P290, DOI 10.1016/j.future.2018.04.065
   Anitha R, 2018, INT J IMAG SYST TECH, V28, P48, DOI 10.1002/ima.22255
   Badza MM, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11094317
   Baid U., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2107.02314, 10.48550/arXiv.2107.02314]
   Baid U, 2020, FRONT COMPUT NEUROSC, V14, DOI 10.3389/fncom.2020.00010
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Banerjee S, 2018, INFORM SCIENCES, V424, P337, DOI 10.1016/j.ins.2017.10.011
   Bonte S, 2018, COMPUT BIOL MED, V98, P39, DOI 10.1016/j.compbiomed.2018.05.005
   Cahall DE, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2108.06772
   Chaddad A, 2015, INT J BIOMED IMAGING, V2015, DOI 10.1155/2015/868031
   Chahal PK, 2020, MULTIMED TOOLS APPL, V79, P21771, DOI 10.1007/s11042-020-08898-3
   Chang J, 2019, J VIS COMMUN IMAGE R, V58, P316, DOI 10.1016/j.jvcir.2018.11.047
   Charron O, 2018, COMPUT BIOL MED, V95, P43, DOI 10.1016/j.compbiomed.2018.02.004
   Chattopadhyay A., 2022, Neurosci. Inform., V2, DOI DOI 10.1016/J.NEURI.2022.100060
   Chen BS, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105797
   Chen L, 2018, IEEE T MED IMAGING, V37, P2453, DOI 10.1109/TMI.2018.2835303
   Chen SC, 2019, PATTERN RECOGN, V88, P90, DOI 10.1016/j.patcog.2018.11.009
   Chen W, 2019, LECT NOTES COMPUTER, V11384
   Cole BL, 2018, PEDIATR DEVEL PATHOL, V21, P380, DOI 10.1177/1093526617743905
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Ellwaa A, 2016, LECT NOTES COMPUT SC, V10154, P129, DOI 10.1007/978-3-319-55524-9_13
   Fan Xu, 2019, 2019 IEEE 4th International Conference on Image, Vision and Computing (ICIVC), P236, DOI 10.1109/ICIVC47709.2019.8981027
   Farhi L, 2017, J VIS COMMUN IMAGE R, V46, P303, DOI 10.1016/j.jvcir.2017.04.013
   Gibson E, 2018, COMPUT METH PROG BIO, V158, P113, DOI 10.1016/j.cmpb.2018.01.025
   Guan X, 2022, BMC MED IMAGING, V22, DOI 10.1186/s12880-021-00728-8
   Havaei Mohammad, 2016, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. First International Workshop, Brainles 2015, held in conjunction with MICCAI 2015. Revised Selected Papers: LNCS 9556, P195, DOI 10.1007/978-3-319-30858-6_17
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Hu HX, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3450519
   Hu K, 2019, IEEE ACCESS, V7, P92615, DOI 10.1109/ACCESS.2019.2927433
   Hussain S, 2018, NEUROCOMPUTING, V282, P248, DOI 10.1016/j.neucom.2017.12.032
   Ibrahim RW, 2018, COMPUT METH PROG BIO, V163, P21, DOI 10.1016/j.cmpb.2018.05.031
   Ilhan U, 2017, PROCEDIA COMPUT SCI, V120, P580, DOI 10.1016/j.procs.2017.11.282
   Ilunga-Mbuyamba E, 2017, COMPUT BIOL MED, V91, P69, DOI 10.1016/j.compbiomed.2017.10.003
   Ilunga-Mbuyamba E, 2017, NEUROCOMPUTING, V220, P84, DOI 10.1016/j.neucom.2016.07.057
   Iorgulescu JB, 2022, NEURO-ONCOLOGY, V24, P1989, DOI 10.1093/neuonc/noac113
   Iqbal S, 2018, MICROSC RES TECHNIQ, V81, P419, DOI 10.1002/jemt.22994
   Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407
   Islam MK, 2021, MACH LEARN APPL, V5, DOI 10.1016/j.mlwa.2021.100044
   Izadyyazdanabadi M, 2018, J VIS COMMUN IMAGE R, V54, P10, DOI 10.1016/j.jvcir.2018.04.004
   Jyothi P, 2023, ARTIF INTELL REV, V56, P2923, DOI 10.1007/s10462-022-10245-x
   Kaldera H., 2019, 2019 ADV SCI ENG TEC, P1, DOI DOI 10.1109/ICASET.2019.8714263
   Karimi D, 2021, ARTIF INTELL MED, V116, DOI 10.1016/j.artmed.2021.102078
   Kaur G, 2020, ADV INTELL SYST, V1042, P451, DOI 10.1007/978-981-32-9949-8_31
   Kawahara J, 2017, NEUROIMAGE, V146, P1038, DOI 10.1016/j.neuroimage.2016.09.046
   Khan AR, 2021, MICROSC RES TECHNIQ, V84, P1389, DOI 10.1002/jemt.23694
   Khilkhal Rasha, 2022, 2022 Muthanna International Conference on Engineering Science and Technology (MICEST)., P43, DOI 10.1109/MICEST54286.2022.9790103
   Khosravanian A, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105809
   Kruchko C, 2018, NEURO-ONCOLOGY, V20, P295, DOI 10.1093/neuonc/noy006
   Kumar DM, 2021, MULTIMED TOOLS APPL, V80, P6939, DOI 10.1007/s11042-020-09635-6
   Kurnar M., 2018, 2018 4 INT C COMP CO, P1, DOI [10.1109/ICCUBEA.2018.8697713, DOI 10.1109/ICCUBEA.2018.8697713]
   Lefkovits L, 2016, LECT NOTES COMPUT SC, V10154, P88, DOI 10.1007/978-3-319-55524-9_9
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Lim KY, 2018, EXPERT SYST APPL, V112, P288, DOI 10.1016/j.eswa.2018.06.041
   Liu G, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5369516
   Magadza T, 2021, J IMAGING, V7, DOI 10.3390/jimaging7020019
   Meinel, 2019, LECT NOTES COMPUTER, V11384
   Miller KD, 2021, CA-CANCER J CLIN, V71, P381, DOI 10.3322/caac.21693
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Motagi AC., 2018, INT J SCI RES COMPUT, V6, P76, DOI [10.26438/ijsrcse/v6i3.7680, DOI 10.26438/IJSRCSE/V6I3.7680]
   Murali E, 2019, JETIR, V6
   Neelima G, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103537
   Nema S, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101641
   Özyurt F, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109433
   Padlia Minal, 2019, Nanoelectronics, Circuits and Communication Systems. Proceeding of NCCS 2017. Lecture Notes in Electrical Engineering (LNEE 511), P161, DOI 10.1007/978-981-13-0776-8_15
   Pak RW, 2017, J CEREBR BLOOD F MET, V37, P3475, DOI 10.1177/0271678X17707398
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Pravitasari AA, 2019, AIP CONF PROC, V2194, DOI 10.1063/1.5139817
   Raja PMS, 2020, BIOCYBERN BIOMED ENG, V40, P440, DOI 10.1016/j.bbe.2020.01.006
   Raju AR, 2018, BIOCYBERN BIOMED ENG, V38, P646, DOI 10.1016/j.bbe.2018.05.001
   Raju AR, 2019, SENSOR REV, V39, P473, DOI 10.1108/SR-01-2018-0008
   Ranjbarzadeh R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90428-8
   Rao CS, 2022, MULTIMED TOOLS APPL, V81, P7393, DOI 10.1007/s11042-021-11821-z
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Rehman A, 2021, MICROSC RES TECHNIQ, V84, P133, DOI 10.1002/jemt.23597
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Sarshar NT, 2023, SMART INNOV SYST TEC, V207, P386, DOI 10.1007/978-3-031-04435-9_39
   Sheela CJJ, 2021, SADHANA-ACAD P ENG S, V46, DOI 10.1007/s12046-021-01744-8
   Sheela CJJ, 2020, MULTIMED TOOLS APPL, V79, P17483, DOI 10.1007/s11042-020-08636-9
   Singh B, 2017, 2017 8TH IEEE ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P536, DOI 10.1109/IEMCON.2017.8117123
   Sisik F, 2020, MED HYPOTHESES, V136, DOI 10.1016/j.mehy.2019.109507
   SivaSai JG, 2020, STUDIES COMPUTATIONA, P163, DOI [DOI 10.1007/978-981-15-5495-7_9, 10.1007/978-981-15-5495-7_9/COVER/]
   Reddy AS, 2021, SOFT COMPUT, V25, P4135, DOI 10.1007/s00500-020-05493-4
   Sun JD, 2021, NEUROCOMPUTING, V423, P34, DOI 10.1016/j.neucom.2020.10.031
   Suzuki K, 2017, RADIOL PHYS TECHNOL, V10, P257, DOI 10.1007/s12194-017-0406-5
   Tahir A, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/2710285
   Takrouni W, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103232
   Thayumanavan M, 2021, CONCURRENT ENG-RES A, V29, P266, DOI 10.1177/1063293X211010542
   Thillaikkarasi R, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1223-7
   Pham TX, 2018, APPL SOFT COMPUT, V65, P230, DOI 10.1016/j.asoc.2018.01.003
   Van Houdt G, 2020, ARTIF INTELL REV, V53, P5929, DOI 10.1007/s10462-020-09838-1
   Vijh S, 2020, LECT NOTE DATA ENG, V32, P171, DOI 10.1007/978-3-030-25797-2_8
   Vishnuvarthanan A, 2018, EXPERT SYST APPL, V95, P280, DOI 10.1016/j.eswa.2017.11.040
   Wadhwa A, 2019, MAGN RESON IMAGING, V61, P247, DOI 10.1016/j.mri.2019.05.043
   Yang TJ, 2020, J X-RAY SCI TECHNOL, V28, P709, DOI 10.3233/XST-200650
   Yang TJ, 2019, BIOCYBERN BIOMED ENG, V39, P613, DOI 10.1016/j.bbe.2019.06.003
   Zeineldin RA, 2020, INT J COMPUT ASS RAD, V15, P909, DOI 10.1007/s11548-020-02186-z
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
   Zhou ZX, 2020, NEUROCOMPUTING, V402, P235, DOI 10.1016/j.neucom.2020.03.097
NR 102
TC 0
Z9 0
U1 6
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30505
EP 30539
DI 10.1007/s11042-023-16654-6
EA SEP 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001060763900012
DA 2024-07-18
ER

PT J
AU Verma, S
   Kumar, A
   Sharan, A
AF Verma, Sharad
   Kumar, Ashish
   Sharan, Aditi
TI MuCon: Multi-channel convolution for targeted sentiment classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Targeted sentiment analysis; Aspect specific sentiment polarity;
   Convolution neural network; Opinion mining; Natural language processing
AB Targeted Sentiment Analysis goes beyond general sentiment classification tasks by aiming to identify the sentiment of a specific target aspect within a given text. Previous studies have predominantly utilized recurrent neural networks (RNN) or their variants to predict target-specific sentiment polarity. However, the sequential processing nature of RNN restricts parallelization and fails to leverage the potential of modern multicore architectures. Additionally, these models often overlook the inherent linguistic perspective embedded in the text. This paper proposes a novel approach called MuCon (Multi-channel Convolution), which employs a simple yet effective convolutional neural network (CNN) model. MuCon incorporates multiple channels dedicated to linguistic and statistical features to determine aspect-specific sentiment polarity accurately. By incorporating linguistic knowledge into a statistical model, MuCon performs better and achieves comparable results to sophisticated state-of-the-art methods.
C1 [Verma, Sharad] Rajkiya Engn Coll, Ambedkar Nagar 224122, Uttar Pradesh, India.
   [Verma, Sharad; Kumar, Ashish; Sharan, Aditi] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
C3 Jawaharlal Nehru University, New Delhi
RP Kumar, A (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
EM sharad@recabn.ac.in; ashish29_scs@jnu.ac.in; aditisharan@mail.jnu.ac.in
RI Kumar, Ashish/AAC-1489-2021
OI Kumar, Ashish/0000-0002-2156-2104
FU TEQIP-III, REC Ambedkar Nagar, UP, India
FX This work was partially financially supported by TEQIP-III, REC Ambedkar
   Nagar, UP, India.
CR Akhtar MS, 2020, NEUROCOMPUTING, V398, P247, DOI 10.1016/j.neucom.2020.02.093
   [Anonymous], 2016, ARXIV160603391
   Basiri ME, 2021, FUTURE GENER COMP SY, V115, P279, DOI 10.1016/j.future.2020.08.005
   Benamara F., 2007, ICWSM, V7, P203
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Chaturvedi A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P272
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen Peng, 2017, P 2017 C EMP METH NA, P452, DOI [10.18653/v1/D17-1047, DOI 10.18653/V1/D17-1047]
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding X., 2008, P 2008 INT C WEB SEA, P231, DOI [DOI 10.1145/1341531.1341561, 10.1145/1341531.1341561]
   Dragut E., 2014, Frame Semantics in NLP: A Workshop in Honor of Chuck Fillmore, P38
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Gamon M., 2004, P 20 INT C COMPUTATI, P841
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1049/cp:19991218, 10.1162/089976600300015015]
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gu S., 2018, P 27 INT C COMP LING, P774
   Gu XD, 2017, NEURAL PROCESS LETT, V46, P581, DOI 10.1007/s11063-017-9605-7
   Hai Z, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P617, DOI 10.1145/2600428.2609570
   Hatzivassiloglou V, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P174, DOI 10.3115/976909.979640
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Joshi Mahesh., 2009, P 47 ACL 4 IJCNLP C, P313
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kim Y., 2014, P 2014 C EMP METH NA, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   Kingma D. P., 2014, arXiv
   Kolen JF, 2009, A Field Guide to Dynamical Recurrent Networks, DOI [DOI 10.1109/9780470544037.CH14, 10.1109/9780470544037]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LECUN Y, 1989, CONNECTIONISM IN PERSPECTIVE, P143
   Li FT, 2010, AAAI CONF ARTIF INTE, P1371
   Li ZC, 2022, IEEE T PATTERN ANAL, V44, P9904, DOI 10.1109/TPAMI.2021.3132068
   Liu B., 2012, SYNTHESIS LECT HUMAN, V5, P1, DOI [DOI 10.1007/978-3-031-02145-9, 10.2200/S00416ED1V01Y201204HLT016, DOI 10.2200/S00416ED1V01Y201204HLT016]
   Liu N, 2020, NEUROCOMPUTING, V395, P66, DOI 10.1016/j.neucom.2020.02.018
   Liu N, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.105010
   Ma DH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4068
   Matsumoto S, 2005, LECT NOTES ARTIF INT, V3518, P301
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mitchell Tom Michael, 2007, Machine Learning, V1
   Mullen T., 2004, P 2004 C EMP METH NA
   Peng ZM, 2019, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2019.00053
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Pontiki M., 2014, P 8 INT WORKSH SEM E, P27, DOI 10.3115/v1/S14-2004
   Poria S, 2016, KNOWL-BASED SYST, V108, P42, DOI 10.1016/j.knosys.2016.06.009
   Poria S, 2014, KNOWL-BASED SYST, V69, P45, DOI 10.1016/j.knosys.2014.05.005
   Qiang Y, 2020, ARXIV
   Rehurek R., 2010, P LREC 2010 WORKSH N, P45, DOI DOI 10.13140/2.1.2393.1847
   Shuang K, 2020, INFORM FUSION, V61, P13, DOI 10.1016/j.inffus.2020.03.003
   Subrahmanian VS, 2008, IEEE INTELL SYST, V23, P43, DOI 10.1109/MIS.2008.57
   Tang D., 2016, 26 INT C COMPUTATION, P3298, DOI DOI 10.48550/ARXIV.1512.01100
   Tang D., 2015, Computer Science
   Tang D, 2016, P C EMP METH NAT LAN, P214, DOI DOI 10.18653/V1/D16-1021
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Wang Y., 2016, P 2016 C EMPIRICAL M, P606, DOI 10.18653/v1/D16-1058
   Wilson T, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P761
   Xinyuan Liu, 2020, 2020 IEEE 5th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA), P17, DOI 10.1109/ICCCBDA49378.2020.9095571
   Xu H, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P592
   Xue W, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2514
   Yang C, 2019, INFORM PROCESS MANAG, V56, P463, DOI 10.1016/j.ipm.2018.12.004
   Yin W., 2016, Transactions of the Association for computational linguistics, V4, P259, DOI [DOI 10.1162/TACL_A_00097, DOI 10.1162/TACLA00244, 10.1162/tacla00097, DOI 10.1162/TACLA00097]
NR 58
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28615
EP 28633
DI 10.1007/s11042-023-16586-1
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059652000003
DA 2024-07-18
ER

PT J
AU Li, R
   Dai, J
   Yang, YH
   Ni, YL
   Sun, FY
AF Li, Ran
   Dai, Juan
   Yang, Yihao
   Ni, Yulong
   Sun, Fengyuan
TI Compressive-sensing recovery of images by context extraction from random
   samples
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive Sensing (CS); Image coding; Self-similarity descriptor;
   Context extraction; Predictive quantization; Linear recovery
ID RESTORATION; SPARSITY
AB Image Compressive Sensing (CS) provides a scheme of low-complex image coding, but coping with the recovery quality has been a challenge. Even the excessive investment of computations into recovery cannot prevent the quality degradation due to the lack of appropriate allocation for sampling resources. In light of this, this paper fuses a context-based allocation into image CS in order to improve the recovery quality with fewer computations. Independent of original pixels, the context features of blocks are extracted from random CS samples. According to the block-based distribution on context features, more CS samples are allocated to non-sparse regions and fewer to sparse regions. The proposed context-based allocation enables a linear recovery model to accurately recover images. The contributions of this paper include: (1) an adaptive allocation involving the context features extracted from CS samples, (2) a padding Differential Pulse Code Modulation (DPCM) to quantize the adaptive CS samples, and (3) a regrouping module to improve the quality of linear recovery. Experimental results show the proposed image CS system objectively and subjectively improves the recovery quality of an image while guaranteeing a low computational complexity, e.g., it achieves average 30.85 dB PSNR value on the five 512x512\documentclass[12pt]{minimal}\usepackage{amsmath}\usepackage{wasysym}\usepackage{amsfonts}\usepackage{amssymb}\usepackage{amsbsy}\usepackage{mathrsfs}\usepackage{upgreek}\setlength{\oddsidemargin}{-69pt}\begin{document}$$512 \times 512$$\end{document} test images, and costs about 10 seconds on a computer with 3.30 GHz CPU and 8 GB RAM. Besides, the proposed system presents a competitive performance to the recent deep-learned image CS systems.
C1 [Li, Ran; Dai, Juan; Yang, Yihao; Ni, Yulong] Xinyang Normal Univ, Sch Comp & Informat Technol, Nanhu Rd 237, Xinyang 464000, Henan, Peoples R China.
   [Sun, Fengyuan] Guilin Univ Elect Technol, Guangxi Key Lab Wireless Wideband Commun & Signal, Jinji Rd 1, Guilin 541004, Guangxi, Peoples R China.
C3 Xinyang Normal University; Guilin University of Electronic Technology
RP Li, R (corresponding author), Xinyang Normal Univ, Sch Comp & Informat Technol, Nanhu Rd 237, Xinyang 464000, Henan, Peoples R China.
EM liran@xynu.edu.cn; daijuan_xynu@163.com; yangyh_xynu@163.com;
   niyulong_xynu@126.com; fengyuansun@foxmail.com
RI Yang, Yihao/AAH-9713-2021; Li, Ran/N-3389-2013
OI Li, Ran/0000-0001-7475-759X
FU This work is supported in part by the Project of Science and Technology
   Department of Henan Province in China (212102210106,212102310993), in
   part by the National Natural Science Foundation of China (31872704), in
   part by the Natural Science Foundation of [31872704]; Project of Science
   and Technology Department of Henan Province in China [222300420274];
   National Natural Science Foundation of China; Natural Science Foundation
   of Henan Province in China; Guangxi Key Laboratory of Wireless Wideband
   Communication and Signal Processing of China; 
   [212102210106,212102310993]
FX This work is supported in part by the Project of Science and Technology
   Department of Henan Province in China (212102210106,212102310993), in
   part by the National Natural Science Foundation of China (31872704), in
   part by the Natural Science Foundation of Henan Province in China
   (222300420274), and in part by the Guangxi Key Laboratory of Wireless
   Wideband Communication and Signal Processing of China.
CR Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4
   Baraniuk RG, 2017, IEEE SIGNAL PROC MAG, V34, P52, DOI 10.1109/MSP.2016.2602099
   Castro RM, 2017, IEEE T INFORM THEORY, V63, P1535, DOI 10.1109/TIT.2017.2653802
   Chen C, 2011, CONF REC ASILOMAR C, P1193, DOI 10.1109/ACSSC.2011.6190204
   Chen Z, 2021, IEEE T IMAGE PROCESS, V30, P7112, DOI 10.1109/TIP.2021.3088611
   Chen Z, 2019, IEEE DATA COMPR CONF, P562, DOI 10.1109/DCC.2019.00074
   Deng C, 2021, IEEE T PATTERN ANAL, V43, P1380, DOI 10.1109/TPAMI.2019.2946567
   Do TT, 2012, IEEE T SIGNAL PROCES, V60, P139, DOI 10.1109/TSP.2011.2170977
   Dong WS, 2015, INT J COMPUT VISION, V114, P217, DOI 10.1007/s11263-015-0808-y
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Gao XW, 2015, IEEE DATA COMPR CONF, P133, DOI 10.1109/DCC.2015.47
   Hu XY, 2021, IEEE T GEOSCI REMOTE, V59, P8486, DOI 10.1109/TGRS.2020.3046381
   Khanh Quoc Dinh, 2013, 2013 20th IEEE International Conference on Image Processing (ICIP), P10, DOI 10.1109/ICIP.2013.6738003
   Lee H, 2021, IEEE T IND ELECTRON, V68, P8874, DOI 10.1109/TIE.2020.3018053
   Li R, 2018, MULTIMED TOOLS APPL, V77, P12139, DOI 10.1007/s11042-017-4862-z
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P2990, DOI 10.1109/TPAMI.2018.2873587
   Lu CS, 2015, INFORM SCIENCES, V325, P33, DOI 10.1016/j.ins.2015.07.017
   Mun S, 2012, EUR SIGNAL PR CONF, P1424
   Mun S, 2010, IEEE DATA COMPR CONF, P547, DOI 10.1109/DCC.2010.90
   Pham CDK, 2022, IEEE T IND INFORM, V18, P1271, DOI 10.1109/TII.2021.3082498
   Romano Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2576402
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P158
   Shechtman E, 2007, PROC CVPR IEEE, P1744
   Unde AS, 2020, IEEE T MOBILE COMPUT, V19, P2250, DOI 10.1109/TMC.2019.2926271
   Upadhyaya V, 2020, ALGO INTELL SY, P25, DOI 10.1007/978-981-15-0426-6_3
   Wang J, 2016, IEEE T SIGNAL PROCES, V64, P1076, DOI 10.1109/TSP.2015.2498132
   Wang JM, 2022, IEEE T IMAGE PROCESS, V31, P734, DOI 10.1109/TIP.2021.3135476
   Wu XL, 2012, IEEE T IMAGE PROCESS, V21, P451, DOI 10.1109/TIP.2011.2163520
   Xie ZH, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7171352
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850945
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang Y, 2020, IEEE T PATTERN ANAL, V42, P521, DOI 10.1109/TPAMI.2018.2883941
   Yu Y, 2010, IEEE SIGNAL PROC LET, V17, P973, DOI 10.1109/LSP.2010.2080673
   Yuan XF, 2021, IEEE T NEUR NET LEAR, V32, P3296, DOI 10.1109/TNNLS.2019.2951708
   Zha ZY, 2021, IEEE T IMAGE PROCESS, V30, P5819, DOI 10.1109/TIP.2021.3086049
   Zha ZY, 2021, IEEE T IMAGE PROCESS, V30, P5223, DOI 10.1109/TIP.2021.3078329
   Zhang J, 2013, IEEE IMAGE PROC, P1021, DOI 10.1109/ICIP.2013.6738211
   Zhang JG, 2017, MULTIMED TOOLS APPL, V76, P4227, DOI 10.1007/s11042-016-3496-x
   Zhou SW, 2023, IEEE T MULTIMEDIA, V25, P2022, DOI 10.1109/TMM.2022.3142952
   Zibetti MVW, 2017, IEEE T IMAGE PROCESS, V26, P3569, DOI 10.1109/TIP.2017.2699483
NR 42
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26711
EP 26732
DI 10.1007/s11042-023-16636-8
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001058323600003
DA 2024-07-18
ER

PT J
AU Bhattacharya, S
   Mishra, BK
   Borah, S
   Das, N
   Dey, N
AF Bhattacharya, Sudipta
   Mishra, Brojo Kishore
   Borah, Samarjeet
   Das, Nabanita
   Dey, Nilanjan
TI Cross-lingual deep learning model for gender-based emotion detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gender-based emotion recognition; RAVDESS; EmoDB; Urdu language;
   Cross-lingual database; Ensemble soft voting classifier; Deep learning
ID RECOGNITION; SPEECH
AB In real-world applications, speech recognition is becoming increasingly popular. Human emotion and automatic gender recognition, which aims to identify male and female voices from any available emotional speech database, is an exciting application. It is noticeable that the performance of the automatic speech emotion and gender recognition system diminishes when cross-corpus circumstances exist, such as when multiple languages are present or a previously unknown language is present, such as Urdu. This study focuses on automatic emotion detection and gender identification from publicly available emotional speech databases. For this work, two public western language databases, namely, RAVDESS (English) and EmoDB (German), are combined for training, and the Urdu database is used for test purposes. The research reported that the k-fold ensemble soft-voting model, deep learning model, and augmented deep learning model obtained 79%, 82%, and 97.6% accuracy, respectively. The results are considerably better than those of many existing systems. The performance evaluation results are also encouraging. Many previous studies on speech emotion recognition have focused on various languages. The proposed technique is sufficiently robust and can efficiently detect emotion and identify gender from the Urdu database. The approach can be used in a wide range of applications.
C1 [Bhattacharya, Sudipta; Mishra, Brojo Kishore] GIET Univ, Dept Comp Sci & Engn, Gunupur, Odisha, India.
   [Borah, Samarjeet] Sikkim Manipal Univ, Sikkim Manipal Inst Technol, Dept Comp Applicat, Sikkim, India.
   [Das, Nabanita] Bengal Inst Technol, Kolkata, India.
   [Dey, Nilanjan] Techno Int New Town, Dept Comp Sci & Engn, Kolkata, India.
C3 GIET University; Sikkim Manipal University; Sikkim Manipal Institute of
   Technology
RP Borah, S (corresponding author), Sikkim Manipal Univ, Sikkim Manipal Inst Technol, Dept Comp Applicat, Sikkim, India.
EM sudipta.bhattacharya@giet.edu; brojomishra@gmail.com;
   samarjeet.b@smit.smu.edu.in; nabanita.das@bitcollege.in;
   neelanjan.dey@gmail.com
RI Mishra, Brojo Kishore Kishore/M-2190-2015; Borah, Samarjeet/C-9801-2013
OI Mishra, Brojo Kishore Kishore/0000-0002-7836-052X; Borah,
   Samarjeet/0000-0001-9304-3525
CR Ali SA., 2013, INT J SCI ENG RES, V4, P1
   Ali SA, 2013, Int J Comput Appl, V76
   Alsharif MH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010088
   Badshah AM, 2017, 2017 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P125
   Bhattacharya S., 2021, Proceeding of First Doctoral Symposium on Natural Computing Research (DSNCR 2020). Lecture Notes in Networks and Systems (LNNS 169), P33, DOI 10.1007/978-981-33-4073-2_4
   Bhattacharya S, 2022, MULTIMED TOOLS APPL, V81, P41309, DOI 10.1007/s11042-022-12411-3
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Das N, 2021, INT J SPEECH TECHNOL, V24, P883, DOI 10.1007/s10772-020-09674-2
   Demircan S, 2018, NEURAL COMPUT APPL, V29, P59, DOI 10.1007/s00521-016-2712-y
   Dey N., 2018, Direction of arrival estimation and localization of multi-speech sources, Vxiv, P53, DOI [10.1007/978-3-319-73059-2, DOI 10.1007/978-3-319-73059-2]
   Dey N, 2018, Direction of arrival estimation and localization of multi-speech sources, P49
   Dey N, 2012, Arxiv, DOI arXiv:1209.1224
   Haider F, 2021, COMPUT SPEECH LANG, V65, DOI 10.1016/j.csl.2020.101119
   Huang ZW, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P801, DOI 10.1145/2647868.2654984
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   Jiang DN, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P113, DOI 10.1109/ICME.2002.1035731
   Kadiri SR, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1324
   Kalita Dhruba Jyoti, 2020, Social Networking and Computational Intelligence. Proceedings of SCI-2018. Lecture Notes in Networks and Systems (LNNS 100), P243, DOI 10.1007/978-981-15-2071-6_20
   Khan A, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P1017, DOI 10.1109/WiSPNET.2017.8299916
   Lampropoulos A. S., 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P98, DOI 10.1109/IIH-MSP.2012.29
   Latif S, 2019, INT CONF AFFECT, DOI [10.1109/acii.2019.8925513, 10.1109/ACII.2019.8925513]
   Latif S, 2018, INT CONF FRONT INFO, P88, DOI 10.1109/FIT.2018.00023
   Lim W, 2016, ASIAPAC SIGN INFO PR, DOI 10.1109/APSIPA.2016.7820699
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Luengo I, 2010, IEEE T MULTIMEDIA, V12, P490, DOI 10.1109/TMM.2010.2051872
   Maxim S, 2016, Maeaika i iika, V9, P518
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   Mignot R., 2019, Trans. Int. Soc. Music Inf. Retr, V2, P97, DOI DOI 10.5334/TISMIR.26
   Mirri S, 2020, COMPUTATION, V8, DOI 10.3390/computation8030074
   Pereira I, 2018, LECT NOTES COMPUT SC, V11139, P791, DOI 10.1007/978-3-030-01418-6_77
   Pohjalainen Jouni, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P980, DOI 10.1109/ICASSP.2014.6853743
   Popova AS, 2018, STUD COMPUT INTELL, V736, P117, DOI 10.1007/978-3-319-66604-4_18
   Robel A, 2005, INT C DIGITAL AUDIO, P30
   Robel A., 2003, PROC INT COMPUTER MU, P247
   Shegokar P, 2016, 2016 10TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ICSPCS)
   Sinith MS, 2015, PROCEEDINGS OF THE 2015 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P139, DOI 10.1109/RAICS.2015.7488403
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101
   Weisskirchen N, 2017, INT CONF AFFECT, P50, DOI 10.1109/ACIIW.2017.8272585
   Wu SQ, 2011, SPEECH COMMUN, V53, P768, DOI 10.1016/j.specom.2010.08.013
   Yang N, 2017, INT J SPEECH TECHNOL, V20, P27, DOI 10.1007/s10772-016-9364-2
   Yüncü E, 2014, INT C PATT RECOG, P773, DOI 10.1109/ICPR.2014.143
   Zaheer N, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445171
   Zeng YN, 2019, MULTIMED TOOLS APPL, V78, P3705, DOI 10.1007/s11042-017-5539-3
   Zhang BQ, 2016, INT CONF ACOUST SPEE, P5805, DOI 10.1109/ICASSP.2016.7472790
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
NR 45
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25969
EP 26007
DI 10.1007/s11042-023-16304-x
EA AUG 2023
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060200100001
DA 2024-07-18
ER

PT J
AU Nisi, V
   Prandi, C
   Ma, SH
   Ferreira, M
   Nicolau, H
   Esteves, A
   Nunes, N
AF Nisi, Valentina
   Prandi, Catia
   Ma, Shuhao
   Ferreira, Marta
   Nicolau, Hugo
   Esteves, Augusto
   Nunes, Nuno
TI The design of Tecnico GO!: catering for students' well-being during the
   COVID-19 pandemics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Student well-being; Human-centered computing; Design evaluation; Social
   distancing; Gamification; Crowdsensing
ID GAMIFICATION
AB Transitioning to and through University is a delicate period for students' well-being. Moreover, the recent COVID-19 pandemic added a further toll through the various challenges related to studying, socializing, community-building, and safety. These challenges inspired the design of a mobile application, called Tecnico GO!, to support university students' well-being and academic performance. This paper presents the design rationale and evaluation of the app conducted during the academic year 2021-2022. Findings cluster around three themes: i) students studying needs; ii) building a sense of community; iii) gamification strategies. The discussion elaborates on the student's perceptions of well-being during pandemics. Students' perception of the app is positive, appreciative of the crowdsensing features, supporting learning goals, community building, and safety. On the other hand, the gamification features, as currently deployed, do not achieve the expected goals.
C1 [Nisi, Valentina; Nicolau, Hugo; Esteves, Augusto; Nunes, Nuno] Univ Lisbon, Tecn, Lisbon, Portugal.
   [Nisi, Valentina; Prandi, Catia; Ma, Shuhao; Ferreira, Marta; Nicolau, Hugo; Esteves, Augusto; Nunes, Nuno] LARSyS, ITI, Lisbon, Portugal.
   [Prandi, Catia] Univ Bologna, Dept Comp Sci & Engn, Bologna, Italy.
C3 Universidade de Lisboa; University of Bologna
RP Prandi, C (corresponding author), LARSyS, ITI, Lisbon, Portugal.; Prandi, C (corresponding author), Univ Bologna, Dept Comp Sci & Engn, Bologna, Italy.
EM catia.prandi2@unibo.it
RI Prandi, Catia/KIB-1268-2024; Nisi, Valentina/G-8658-2018
OI Prandi, Catia/0000-0002-5566-2269; Nisi, Valentina/0000-0002-8051-3230
FU LARSyS [UIDB/50009/2020]; FCT [344]
FX The authors received support from LARSyS (Projeto UIDB/50009/2020) and
   FCT (RESEARCH 4 COVID-19 2nd Edition - 344).
CR Allas T., 2020, Well-being in Europe: Addressing the high cost of COVID-19 on life satisfaction
   Bartle R., 1996, J MUD Res, V1, P19, DOI DOI 10.1007/S00256-004-0875-6
   Beaunoyer E, 2020, COMPUT HUM BEHAV, V111, DOI 10.1016/j.chb.2020.106424
   Biernath A., VARIOLA MACACOS HEPA
   Bogost I, 2014, GAMEFUL WORLD: APPROACHES, ISSUES, APPLICATIONS, P65
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Brodeur A, 2021, J PUBLIC ECON, V193, DOI 10.1016/j.jpubeco.2020.104346
   Brooks Samantha K, 2020, Lancet, V395, P912, DOI [10.1016/S0140-6736(20)30460-8, 10.1016/S0140-6736(20)30460-8.]
   campusclear, FREE COVID 19 SELF S
   Center C, R NEW U APP LETS STU
   Cho H., 2020, Contact Tracing Mobile Apps for COVID-19: Privacy Considerations and Related Trade-offs
   Clemente-Suarez VJ, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13063221
   Cohen AM, 2011, FUTURIST, V45, P16
   Collado-Borrell R, 2020, J MED INTERNET RES, V22, DOI 10.2196/20334
   Deci EL, 1999, PSYCHOL BULL, V125, P627, DOI 10.1037/0033-2909.125.6.627
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI DOI 10.1145/2181037.2181040
   Deterding S., 2014, Rethinking Gamification, P305
   Deznabi Iman, 2021, ACM Digital Government: Research and Practice, V2, DOI 10.1145/3436731
   Doan A, 2011, COMMUN ACM, V54, P86, DOI 10.1145/1924421.1924442
   Farzan R, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P563
   Fogg B, 2003, CHI 2003 NEW HORIZON
   Fogg B.J., 2009, P 4 INT C PERS TECHN, P44, DOI DOI 10.1145/1541948.1542005
   Gaver B., 2012, INTERACTIONS, V19, P40
   Hamari J, 2015, INT J INFORM MANAGE, V35, P419, DOI 10.1016/j.ijinfomgt.2015.04.006
   Hamari J, 2014, P ANN HICSS, P3025, DOI 10.1109/HICSS.2014.377
   Hamari J, 2013, ELECTRON COMMER R A, V12, P236, DOI 10.1016/j.elerap.2013.01.004
   Hanus MD, 2015, COMPUT EDUC, V80, P152, DOI 10.1016/j.compedu.2014.08.019
   Hunicke R., 2004, Proc. AAAI Wksp. Challenges in Game AI, V4, P1722
   Hyrynsalmi S, 2017, DDGD MINDTREK, P4
   Ioannidis JPA, 2020, EUR J CLIN INVEST, V50, DOI 10.1111/eci.13423
   Ipeirotis PG, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P143, DOI 10.1145/2566486.2567988
   Johnson Daniel, 2016, Internet Interv, V6, P89, DOI 10.1016/j.invent.2016.10.002
   Kim TW, 2016, ETHICS INF TECHNOL, V18, P157, DOI 10.1007/s10676-016-9401-5
   Kupfer M Apps, MONITOR COVID 19 U S
   Liu D, 2017, MIS QUART, V41, P1011
   Loades ME, 2020, J AM ACAD CHILD PSY, V59, P1218, DOI 10.1016/j.jaac.2020.05.009
   Ma S, 2021, IASDR 2021 P
   Magson NR, 2021, J YOUTH ADOLESCENCE, V50, P44, DOI 10.1007/s10964-020-01332-9
   Marczewski A., 2017, XRDS: Crossroads, The ACM Magazine for Students, V24, P56, DOI DOI 10.1145/3123756
   Masten AS, 2021, INT J PSYCHOL, V56, P1, DOI 10.1002/ijop.12737
   Mastrotheodoros S., 2021, The effects of COVID-19 on young people's mental health and psychological well-being
   Ming LC, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/19796
   Montola Marcus., 2009, Pervasive Games: Theory and Design
   Mora A, 2015, 2015 IEEE 7TH INTERNATIONAL CONFERENCE ON GAMES AND VIRTUAL WORLDS FOR SERIOUS APPLICATIONS (VS-GAMES), P100
   Morschheuser B, 2017, INT J HUM-COMPUT ST, V106, P26, DOI 10.1016/j.ijhcs.2017.04.005
   Morschheuser B, 2016, P ANN HICSS, P4375, DOI 10.1109/HICSS.2016.543
   Onyeaka Helen, 2021, Sci Prog, V104, p368504211019854, DOI 10.1177/00368504211019854
   Organization, WH MULT MONK OUTBR N
   Ribeiro M, 2021, HUMAN COMPUTER INTER
   Ruiz MC, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.608216
   Seaborn K, 2015, INT J HUM-COMPUT ST, V74, P14, DOI 10.1016/j.ijhcs.2014.09.006
   Selinger E, 2014, GAMEFUL WORLD: APPROACHES, ISSUES, APPLICATIONS, P371
   Sharma T, 2021, PROC ACM SIG CAS C C, P215, DOI [10.1145/3460112.3471958, DOI 10.1145/3460112.3471958]
   Shuhao Ma, 2022, GoodIT 2022: Conference on Information Technology for Social Good, P146, DOI 10.1145/3524458.3547261
   Struzek D, 2021, 2021 CHI C HUM FACT
   Thom J., 2012, Incentives, P1067, DOI DOI 10.1145/2145204.2145362
   Trivedi A, 2020, ACM SIGCOMM COMP COM, V50, P75, DOI 10.1145/3431832.3431841
   Tumedei Gianni, 2021, GoodIT '21: Proceedings of the Conference on Information Technology for Social Good, P145, DOI 10.1145/3462203.3475911
   ucc, UCC CLIN STUDENTS CO
   un, REP SHOWS IMP COVID
   wehealth, WEHEALTH AR
   Werbach K., 2012, For the win: How game thinking can revolutionize your business
NR 62
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 46129
EP 46151
DI 10.1007/s11042-023-16320-x
EA AUG 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:001064537600006
OA hybrid
DA 2024-07-18
ER

PT J
AU Feng, YJ
   Li, MX
   Pei, YJ
   Huang, XL
   Wang, HL
   Li, PP
AF Feng, Yongjun
   Li, Mingxia
   Pei, Yongji
   Huang, Xinlei
   Wang, Hailong
   Li, Panpan
TI Research on Threat Assessment evaluation model based on improved CNN
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Improved CNN; Threat assessment; Multi-objective feature; Weight
AB In view of the traditional Threat Assessment (TA) evaluation model can only consider a single threat target, and the accuracy of threat evaluation is poor, the application effect of improved CNN algorithm in Ta evaluation model is studied. This paper proposes a TA evaluation model based on the improved Convolutional Neural Networks (CNN) algorithm. The model uses the powerful feature extraction ability of convolutional neural network, adopts the concept of dual channel neuron, improves the structure of convolutional neural network, and reduces the number of network parameters and obtains the target classification features with multiple markers on the basis of retaining the full connection layer. On this basis, fuzzy mathematics is used to quantitatively describe the classification features of multi marker targets, to define the weight value of each feature of targets, and to evaluate the threat degree of multiple targets by Technique for Order Preference by Similarity to Ideal Solution (TOPSIS). The simulation results show that the model has fast convergence speed and accurate threat prediction ability, and can accurately obtain the threat ranking of multiple targets.
C1 [Feng, Yongjun; Pei, Yongji] State Grid Xinjiang Elect Power Corp, Urumqi 830063, Xinjiang, Peoples R China.
   [Li, Mingxia] State Grid Xinjiang Elect Power Co Ltd, Res Inst, Urumqi 830011, Xinjiang, Peoples R China.
   [Huang, Xinlei; Wang, Hailong; Li, Panpan] Mkt Serv Centerer State Grid Xinjiang Elect Power, Ltd Co Capital Intens Ctr & Measurement Ctr, Urumqi 830013, Xinjiang, Peoples R China.
C3 State Grid Corporation of China
RP Feng, YJ (corresponding author), State Grid Xinjiang Elect Power Corp, Urumqi 830063, Xinjiang, Peoples R China.
EM zhijiao625104862@163.com
CR Bai C., 2019, COMPUT ENG APPL, V55, P111
   [陈德江 Chen Dejiang], 2019, [计算机科学, Computer Science], V46, P183
   Chen K, 2021, ARXIV
   Dong X., 2018, COMPUT ENG, V44, P46
   He S, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11111779
   Hocaoglu MF, 2022, J DEF MODEL SIMUL-AP, V19, P107, DOI 10.1177/15485129211040369
   [荆献勇 Jing Xianyong], 2017, [火力与指挥控制, Fire Control & Command Control], V42, P19
   Khaire UM, 2022, J KING SAUD UNIV-COM, V34, P1060, DOI 10.1016/j.jksuci.2019.06.012
   Liu G, 2021, P I MECH ENG I-J SYS, V235, P823, DOI 10.1177/0959651820965447
   [刘海龙 Liu Hailong], 2017, [计算机应用研究, Application Research of Computers], V34, P3816
   MAltinoz OT, 2021, 2021 INT C INNOVATIO, P1
   Meng T, 2019, LASER OPTOELECTRON P, V56, DOI 10.3788/LOP56.081001
   Shen ZY, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13148109
   Tian Chengping, 2022, 2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th Int Conf on Data Science & Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys), P2189, DOI 10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00324
   Xie ZJ, 2023, MEAS CONTROL-UK, V56, P518, DOI 10.1177/00202940221107620
   [许伟栋 Xu Weidong], 2018, [江苏农业学报, Jiangsu Journal of Agricultural Sciences], V34, P1378
   Xue YueJu Xue YueJu, 2018, Transactions of the Chinese Society of Agricultural Engineering, V34, P189
   Yang J., 2018, J. Yanshan Univ, V42, P427
   Yang Lu, 2019, Electronics Optics & Control, V26, P6, DOI 10.3969/j.issn.1671-637X.2019.08.002
   [余鹰 Yu Ying], 2019, [智能系统学报, CAAI Transactions on Intelligent Systems], V14, P566
   Zhang Hao-wei, 2017, Computer Engineering and Science, V39, P1908, DOI 10.3969/j.issn.1007-130X.2017.10.020
NR 21
TC 1
Z9 1
U1 7
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25351
EP 25364
DI 10.1007/s11042-023-16492-6
EA AUG 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001050733600006
DA 2024-07-18
ER

PT J
AU Al-Mouhamed, M
   Firdaus, L
   Khan, AH
   Mohammad, N
AF Al-Mouhamed, Mayez
   Firdaus, Lutfi
   Khan, Ayaz H.
   Mohammad, Nazeeruddin
TI SpMV and BiCG-Stab sparse solver on Multi-GPUs for reservoir simulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE BiCG-Stab solver; Multi-GPUs; Scalable SpMV; Numerical Simulation
ID ALGORITHM
AB This paper is on a multi-GPU simulation of a petroleum reservoir using a 3D structured grid, where each point is represented by its state. Using the Darcy model for porous media, each grid point is related to its six neighbors by a linear relation. The system equation is a sparse linear system AX = b, where A is a hepta-diagonal matrix, b is model parameters, and X is a state vector. The simulation repeatedly computes (1) A and b given X and (2) X given A and b, which is the focus of this paper. The BiCG-Stab is an iterative procedure for solving AX = b for X. This work focuses on developing a scalable multi-GPU approach for solving large sparse systems Ax = b using BiCG-Stab. We extend a previously developed storage scheme for blocked hepta-diagonal matrices to minimize storage and computing overheads of the sparse matrix-vector multiply (SpMV) used in BiCG-Stab. To honor data dependencies in BiCG-Stab tasks we propose a hierarchical multi-GPUs synchronization scheme that reduces the polling, combines barriers, termination BiCG-Stab iteration, and assembles the solution X. We present a multi-GPU implementation of BiCG-Stab by distribution operations overall units within a GPU and overall GPUs. Reduce-add operations are orchestrated by assembling partial results across all units and all GPUs. Since the cuSparse library works only on a single GPU, we present an SpMV for multi-GPU. In the evaluation, we present the testing of the pinned/paged memory to implement multi-GPU synchronization and communication. The scalability of the multi-GPU implementation of BiCG-Stab is presented showing a smooth increase in the computational load when the problem size grows to a billion, which is useful for developing scalable petroleum reservoir simulation on a clusterof GPUs.
C1 [Al-Mouhamed, Mayez; Firdaus, Lutfi; Khan, Ayaz H.] King Fahd Univ Petr & Minerals, Comp Engn Dept, Dhahran, Saudi Arabia.
   [Mohammad, Nazeeruddin] Prince Mohammad Bin Fahd Univ, Cybersecur Ctr, Dhahran, Saudi Arabia.
C3 King Fahd University of Petroleum & Minerals; Prince Mohammad Bin Fahd
   University
RP Khan, AH (corresponding author), King Fahd Univ Petr & Minerals, Comp Engn Dept, Dhahran, Saudi Arabia.
EM mayez.dandashy@gmail.com; g201402840@kfupm.edu.sa;
   ayaz.khan@kfupm.edu.sa; nmohammad@pmu.edu.sa
RI Khan, Ayaz ul Hassan/E-4025-2010
OI Khan, Ayaz ul Hassan/0000-0003-1167-7319
FU National Plan for Science, Technology, and Innovation (MAARIFAH) King
   Abdulaziz City for Science and Technology through the Science amp;
   Technology Unit at King Fahd University of Petroleum and Minerals
   (KFUPM) the Kingdom of Saudi Arabia [12-INF3008-04]; King Fahd
   University of Petroleum amp; Minerals (KFUPM)
FX AcknowledgementsThis research was funded through a research project by
   the National Plan for Science, Technology, and Innovation (MAARIFAH)
   King Abdulaziz City for Science and Technology through the Science &
   Technology Unit at King Fahd University of Petroleum and Minerals
   (KFUPM) the Kingdom of Saudi Arabia, award number (12-INF3008-04).
   Thanks to King Fahd University of Petroleum & Minerals (KFUPM) for
   computing support.
CR Abdelfattah A, 2015, LECT NOTES COMPUT SC, V9233, P601, DOI 10.1007/978-3-662-48096-0_46
   Abu-Sufah W, 2012, IEEE I C EMBED SOFTW, P453, DOI 10.1109/HPCC.2012.68
   Acosta A., 2012, 2012 IEEE 10th International Symposium on Parallel and Distributed Processing with Applications (ISPA), P646, DOI 10.1109/ISPA.2012.96
   Ahamed AKC, 2012, IEEE I C EMBED SOFTW, P836, DOI 10.1109/HPCC.2012.118
   Ahmad N, 2021, IEEE T PARALL DISTR, V32, P2809, DOI 10.1109/TPDS.2021.3074501
   Al-Mouhamed MA, 2017, J SUPERCOMPUT, V73, P3761, DOI 10.1007/s11227-017-1972-3
   Aliaga JI, 2019, PARALLEL COMPUT, V85, P79, DOI 10.1016/j.parco.2019.02.005
   Aliaga JI, 2013, PROC INT CONF PARAL, P320, DOI 10.1109/ICPP.2013.41
   Ament M, 2010, EUROMICRO WORKSHOP P, P583, DOI 10.1109/PDP.2010.51
   Anzt H., 2014, Technical Report UT-EECS-14-727
   Bastem B, 2020, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING IN ASIA-PACIFIC REGION (HPC ASIA 2020), P43, DOI 10.1145/3368474.3368485
   Ben-Nun T, 2020, ACM TRANS PARALLEL C, V7, DOI 10.1145/3399730
   Bocharov AN, 2020, J COMPUT PHYS, V406, DOI 10.1016/j.jcp.2019.109189
   Cevahir A, 2010, COMPUT SCI-RES DEV, V25, P83, DOI 10.1007/s00450-010-0112-6
   Chen Y, 2013, 2013 IEEE 15TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS & 2013 IEEE INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING (HPCC_EUC), P628, DOI 10.1109/HPCC.and.EUC.2013.94
   Choboter P, 2011, OCEANS 2011, P1, DOI 10.23919/OCEANS.2011.6107199
   developer.nvidia, NVIDIA GPUDIRECT
   developer.nvidia, COOP GROUPS
   docs.nvidia, DEV LIN KERN MOD US
   Gao JQ, 2017, PARALLEL COMPUT, V63, P1, DOI 10.1016/j.parco.2017.04.003
   Gao JQ, 2014, J PARALLEL DISTR COM, V74, P2088, DOI 10.1016/j.jpdc.2013.10.002
   Guan J, 2013, IEEE T ANTENN PROPAG, V61, P3607, DOI 10.1109/TAP.2013.2258882
   Guo P, 2016, 2016 28TH IEEE INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE AND HIGH PERFORMANCE COMPUTING WORKSHOPS (SBAC-PADW), P67, DOI 10.1109/SBAC-PADW.2016.20
   Hermann E, 2010, LECT NOTES COMPUT SC, V6272, P235, DOI 10.1007/978-3-642-15291-7_23
   Klie H., 2011, SPE RESERV SIMUL, DOI [10.2118/141265-MS, DOI 10.2118/141265-MS]
   Li A, 2020, IEEE T PARALL DISTR, V31, P94, DOI 10.1109/TPDS.2019.2928289
   Li A, 2015, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS'15), P109, DOI 10.1145/2751205.2751232
   Li RP, 2013, J SUPERCOMPUT, V63, P443, DOI 10.1007/s11227-012-0825-3
   Liu WF, 2015, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS'15), P339, DOI 10.1145/2751205.2751209
   Liu Y, 2014, FASTER GPU BASED SPA
   Liu YC, 2015, IEEE INT CONF ASAP, P82, DOI 10.1109/ASAP.2015.7245713
   Lopes Noel, 2011, International Journal of Computer Information Systems and Industrial Management Applications, V3, P355
   Mei XX, 2017, IEEE T PARALL DISTR, V28, P72, DOI 10.1109/TPDS.2016.2549523
   Micikevicius P, 2011, MULTIGPU PROGRAMMING
   Micikevicius Paulius., MULTIGPU PROGRAMMING
   Moler Cleve., 2004, Numerical Computing with MATLAB, P1, DOI DOI 10.1137/1.9780898717952
   Nickolls John, 2008, ACM Queue, V6, DOI 10.1145/1365490.1365500
   Owens JD, 2008, P IEEE, V96, P879, DOI 10.1109/JPROC.2008.917757
   Jradi WAR, 2018, 2018 SYMPOSIUM ON HIGH PERFORMANCE COMPUTING SYSTEMS (WSCAD 2018), P16, DOI 10.1109/WSCAD.2018.00013
   Saad Yousef, 2003, SIAM, P23, DOI DOI 10.1137/1.9780898718003
   Schaetz Sebastian, 2012, Algorithms and Architectures for Parallel Processing. Proceedings of the 12th International Conference, ICA3PP 2012, P114, DOI 10.1007/978-3-642-33078-0_9
   Sourouri M, 2014, INT C PAR DISTRIB SY, P981, DOI 10.1109/PADSW.2014.7097919
   Steinberger Markus, 2016, 2016 IEEE HIGH PERFO, P1, DOI [10.1109/HPEC.2016.7761634, DOI 10.1109/HPEC.2016.7761634]
   Technology P, PROD BRIEF PEX 8747
   Thibault JC, 2012, J SUPERCOMPUT, V59, P693, DOI 10.1007/s11227-010-0468-1
   Tiwari M, 2022, LECT NOTES COMPUT SC, V13387, P77, DOI 10.1007/978-3-031-23220-6_6
   Torres R, 2022, IEEE SYM PARA DISTR, P401, DOI 10.1109/IPDPSW55747.2022.00075
   Xie CH, 2021, PROC INT CONF PARAL, DOI 10.1145/3472456.3472478
   Yang C, 2018, LECT NOTES COMPUT SC, V11014, P672, DOI 10.1007/978-3-319-96983-1_48
   Zhang LQ, 2022, Arxiv, DOI arXiv:2204.02064
   Zhang XX, 2017, ACM SIGPLAN NOTICES, V52, P31, DOI [10.1145/3155284.3018755, 10.1145/3018743.3018755]
NR 51
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 17
PY 2023
DI 10.1007/s11042-023-16185-0
EA AUG 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YY0
UT WOS:001050048600007
DA 2024-07-18
ER

PT J
AU Lin, WG
   Yan, WC
   Chen, ZZ
   Xiao, RB
AF Lin, Wenguang
   Yan, Wenchao
   Chen, Zhizhen
   Xiao, Renbin
TI Research on product appearance patent spatial shape recognition for
   multi-image feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image segmentation; Support vector machines; Multi-image fusion; Patent
   image
ID IMAGE; RETRIEVAL
AB In the process of patent retrieval, the traditional content-based single image retrieval method mainly has the following two reasons: a) semantic deviation caused by text description, b) the similarity of a single pixel in the image is high but the whole is inconsistent. Low accuracy leads to unsatisfactory retrieval results, which makes it difficult to obtain product design information timely and effectively and reduces design efficiency. How to obtain data quickly and accurately has become a challenging problem. In this paper, by analyzing the problems existing in Locarno classification method, combined with the characteristics of the patent image, a new improved method is proposed. Firstly, the structural features of product parts are extracted through segmentation. Subsequently, combine it with multi-view image fusion to determine the spatial shape of product parts jointly. Finally, the spatial shape of key structures is confirmed to refine the specific search range as well as improve the search accuracy. The feasibility and effectiveness of the proposed method are verified by taking a shower appearance patent as an example.
C1 [Lin, Wenguang; Yan, Wenchao] Xiamen Univ Technol, Xiamen, Peoples R China.
   [Chen, Zhizhen; Xiao, Renbin] Huazhong Univ Sci & Technol, Wuhan, Peoples R China.
C3 Xiamen University of Technology; Huazhong University of Science &
   Technology
RP Xiao, RB (corresponding author), Huazhong Univ Sci & Technol, Wuhan, Peoples R China.
EM linwg@xmut.edu.cn; 18483641504@163.com; z.chen@gre.ac.uk;
   rbxiao@hust.edu.cn
RI Xiao, Renbin/N-5136-2018
OI lin, wenguang/0000-0003-2672-7542
FU National Science and Technology Innovation 2030 Major Project of the
   Ministry of Science and Technology of China [2018AAA0101200]; National
   Natural Science Foundation of China [52275249]; Social Science
   Foundation of Fujian Province [FJ2021B128]
FX This work is supported by the National Science and Technology Innovation
   2030 Major Project of the Ministry of Science and Technology of China
   (No. 2018AAA0101200), the National Natural Science Foundation of China
   (No. 52275249), and the Social Science Foundation of Fujian Province
   (No. FJ2021B128).
CR Arslan S, 2013, DATA KNOWL ENG, V86, P124, DOI 10.1016/j.datak.2013.01.007
   Cai N., 2011, J SHANDONG U ENG SCI, V4, P1
   Csurka Gabriela, 2011, CLEF NOT PAP LABS WO, V2
   Duan W, 2008, IMAGE VISION COMPUT, V26, P1196, DOI 10.1016/j.imavis.2008.01.009
   El-ghazal A, 2012, J VIS COMMUN IMAGE R, V23, P622, DOI 10.1016/j.jvcir.2012.01.011
   Gao JQ, 2016, NEURAL COMPUT APPL, V27, P431, DOI 10.1007/s00521-015-1862-7
   Huet B, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P737, DOI 10.1109/ICIP.2001.958599
   Ji F., 2004, COMPUT ENG APPL, V34, P209
   Jiang S, 2021, J MECH DESIGN, V143, DOI 10.1115/1.4049214
   Junyong Z, 2004, P 2004 INT C IND DES, P154
   [李兰 Li Lan], 2015, [计算机科学, Computer Science], V42, P306
   Li M, 2022, IEEE ACCESS, V10, P37829, DOI 10.1109/ACCESS.2021.3088757
   Li Y., 2014, CHINESE INVENTIONS P, V10, P66
   Lingyun S., 2008, COMPUT INTEGR MANUF, V2, P234
   Liu RC, 2011, J INFRARED MILLIM W, V30, P250
   Lu YW, 2017, INT J IMAG SYST TECH, V27, P383, DOI 10.1002/ima.22242
   Monge-Alvarez J, 2019, IEEE J BIOMED HEALTH, V23, P184, DOI 10.1109/JBHI.2018.2800741
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qiliang Z., 2020, SMALL MICROCOMPUT SY, V41, P837
   Qingqing L., 2016, COMPUT ENG DES, V37, P2469
   Qingyun D., 2002, COMPUT ENG APPL, V3, P27
   Senhong W., 2013, RES CLASSIFICATION M
   Shuangshuang H., 2013, MICROCOMPUT APPL, V32, P42
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Ting Z., 2012, RES IMAGE FEATURE EX
   [王梅 Wang Mei], 2014, [计算机应用与软件, Computer Applications and Software], V31, P1
   Yang AM, 2022, MOBILE NETW APPL, V27, P851, DOI 10.1007/s11036-021-01817-2
   [杨泽青 Yang Zeqing], 2021, [计算机集成制造系统, Computer Integrated Manufacturing Systems], V27, P1629
   Zhang BW, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196525
   Zheng Y, 2020, IEEE ACCESS, V8, P90141, DOI 10.1109/ACCESS.2020.2994234
   Zhiyuan Z, 2007, 2007 JAPAN-CHINA JOINT WORKSHOP ON FRONTIER OF COMPUTER SCIENCE AND TECHNOLOGY, PROCEEDINGS, P86, DOI 10.1109/FCST.2007.14
NR 31
TC 0
Z9 0
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 17
PY 2023
DI 10.1007/s11042-023-16477-5
EA AUG 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2QU0
UT WOS:001049144700001
DA 2024-07-18
ER

PT J
AU Padhy, S
   Dash, S
   Shankar, TN
   Rachapudi, V
   Kumar, S
   Nayyar, A
AF Padhy, Sasmita
   Dash, Sachikanta
   Shankar, T. N.
   Rachapudi, Venubabu
   Kumar, Sandeep
   Nayyar, Anand
TI A hybrid crypto-compression model for secure brain mri image
   transmission
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Generative adversarial networks; Cryptography; Chaotic map; DNA
   encoding; Security
ID GENERATIVE ADVERSARIAL NETWORK; SYSTEM
AB Medical image encryption is a major issue in healthcare applications where memory, energy, and computational resources are constrained. The modern technological architecture of digital healthcare systems is, in fact, insufficient to handle both the current and future requirements for data. Security has been raised to the highest priority. By meeting these conditions, the hybrid crypto-compression technique introduced in this study can be used for securing the transfer of healthcare images. The approach consists of two components. In order to construct a cutting-edge generative lossy compression system, we first combine generative adversarial networks (GANs) with oearned compression. As a result, the second phase might address this problem by using highly effective picture cryptography techniques. A randomly generated public key is subjected to the DNA technique. In this application, pseudo-random bits are produced by using a logistic chaotic map algorithm. During the substitution process, an additional layer of security is provided to boost the technique's fault resilience. Our proposed system and security investigations show that the method provides trustworthy and long-lasting encryption and several multidimensional aspects that have been discovered in various public health and healthcare issues. As a result, the recommended hybrid crypto-compression technique may significantly reduce a photo's size and remain safe enough to be used for medical image encryption.
C1 [Padhy, Sasmita] VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal Indore Highway, Kothrikalan 466114, Sehore Madhya P, India.
   [Dash, Sachikanta] GIET Univ, Dept Comp Sci & Engn, Gunupur, Odisha, India.
   [Shankar, T. N.] Dr Vishwanath Karad MIT World Peace Univ, Dept Comp Engn & Technol, Pune, Maharashtra, India.
   [Rachapudi, Venubabu] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Guntur, Andhra Pradesh, India.
   [Kumar, Sandeep] CHRIST Deemed Univ, Dept Comp Sci & Engn, Bengaluru 560074, Karnataka, India.
   [Nayyar, Anand] Duy Tan Univ, Grad Sch, Da Nang, Vietnam.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Da Nang, Vietnam.
C3 VIT Bhopal University; GIET University; Dr. Vishwanath Karad MIT World
   Peace University; Koneru Lakshmaiah Education Foundation (K L Deemed to
   be University); Christ University; Duy Tan University; Duy Tan
   University
RP Nayyar, A (corresponding author), Duy Tan Univ, Grad Sch, Da Nang, Vietnam.; Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Da Nang, Vietnam.
EM pinky.sasmita@gmail.com; sachikanta@giet.edu;
   tnshankar2004@rediffmail.com; venubabu.r@gmail.com;
   sandeepkumar@christuniversity.in; anandnayyar@duytan.edu.vn
RI SHANKAR, TARUN NARAYAN/ABD-9474-2020; Dash, Dr Sachikanta/AGU-6737-2022;
   RACHAPUDI, VENUBABU/U-5960-2018; RACHAPUDI, Dr VENU BABU/ABZ-7336-2022;
   Nayyar, Anand/F-3732-2015; Kumar, Sandeep/L-9952-2014
OI SHANKAR, TARUN NARAYAN/0000-0001-6566-8595; Dash, Dr
   Sachikanta/0000-0002-0807-4624; RACHAPUDI, VENUBABU/0000-0002-5969-7733;
   RACHAPUDI, Dr VENU BABU/0000-0002-5969-7733; Nayyar,
   Anand/0000-0002-9821-6146; Kumar, Sandeep/0000-0003-4125-4165; , Sasmita
   Padhy/0000-0001-8345-9834
CR Agustsson E, 2019, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2019.00031
   Ahmad I, 2021, SIGNAL PROCESS-IMAGE, V98, DOI 10.1016/j.image.2021.116418
   [Anonymous], IEEE T BIG DATA
   Arab A, 2019, J SUPERCOMPUT, V75, P6663, DOI 10.1007/s11227-019-02878-7
   Berghel H, 2017, COMPUTER, V50, P72, DOI 10.1109/MC.2017.4451227
   Boivin A, 2014, IMPLEMENT SCI, V9, DOI 10.1186/1748-5908-9-24
   Calderón AJ, 2006, SIGNAL PROCESS, V86, P2803, DOI 10.1016/j.sigpro.2006.02.022
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chenthara S, 2019, IEEE ACCESS, V7, P74361, DOI 10.1109/ACCESS.2019.2919982
   Dash S, 2022, INT J INF SECUR PRIV, V16, DOI 10.4018/IJISP.303669
   Dong H, 2020, IEEE ACCESS, V8, P163524, DOI 10.1109/ACCESS.2020.3022398
   Dong S, 2019, IEEE ACCESS, V7, P80813, DOI 10.1109/ACCESS.2019.2922196
   El-Khamy SE, 2021, MULTIMED TOOLS APPL, V80, P23319, DOI 10.1007/s11042-021-10527-6
   ElKamchouchi DH, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020180
   Gafsi M, 2020, J ELECTR COMPUT ENG, V2020, DOI 10.1155/2020/8937676
   Grass, 2020, ANGEW CHEM, V132, P8554, DOI DOI 10.1002/ANGE.202001162
   Iqbal T, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1072-9
   Jia CM, 2019, IEEE J EM SEL TOP C, V9, P177, DOI 10.1109/JETCAS.2018.2886642
   Kaur R., 2021, INT J GRID DISTRIB, V14, P1045
   Khashan OA, 2020, MULTIMED TOOLS APPL, V79, P26369, DOI 10.1007/s11042-020-09264-z
   Kim DW, 2019, ETRI J, V41, P415, DOI 10.4218/etrij.2018-0473
   Kruse Clemens Scott, 2017, JMIR Med Inform, V5, pe35, DOI 10.2196/medinform.7958
   Li CQ, 2014, NONLINEAR DYNAM, V78, P1545, DOI 10.1007/s11071-014-1533-8
   Li XJ, 2021, OPT LASER TECHNOL, V140, DOI 10.1016/j.optlastec.2021.107074
   Liu DY, 2021, INFORM SCIENCES, V545, P118, DOI 10.1016/j.ins.2020.07.073
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu JZ, 2018, MULTIMED TOOLS APPL, V77, P22787, DOI 10.1007/s11042-017-5534-8
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu Y, 2019, J VISUAL-JAPAN, V22, P95, DOI 10.1007/s12650-018-0519-x
   Mandal MK, 2012, IETE TECH REV, V29, P395, DOI 10.4103/0256-4602.103173
   Mentzer F, 2020, Arxiv, DOI arXiv:2006.09965
   Mousa Hardy M., 2016, International Journal of Computer Network and Information Security, V8, P1, DOI 10.5815/ijcnis.2016.07.01
   Niu Y, 2020, IEEE ACCESS, V8, P22082, DOI 10.1109/ACCESS.2020.2970103
   Padhy S, 2022, COMP FAST POINT MULT
   Padhy S, 2023, PROCESSES, V11, DOI 10.3390/pr11030757
   Ponuma R, 2018, MULTIMED TOOLS APPL, V77, P19209, DOI 10.1007/s11042-017-5378-2
   Pranitha G, 2022, 2022 2 INT C INTELLI, P1
   Roy Mousomi, 2020, Proceedings of International Ethical Hacking Conference 2019. eHaCON 2019. Advances in Intelligent Systems and Computing (AISC 1065), P239, DOI 10.1007/978-981-15-0361-0_19
   Samiullah M, 2020, IEEE ACCESS, V8, P25650, DOI 10.1109/ACCESS.2020.2970981
   Sang YP, 2022, PATTERN RECOGN LETT, V153, P59, DOI 10.1016/j.patrec.2021.11.025
   Shakir HR, 2019, ADV MULTIMED, V2019, DOI 10.1155/2019/7074264
   Shankar T, 2022, 2022 6 INT C TRENDS, P738
   Shankar TN, 2022, P IEEE GLOB C COMP P, P1, DOI DOI 10.1109/GLOBCONPT57482.2022.9938284
   Shu JG, 2021, IEEE T SERV COMPUT, V14, P235, DOI 10.1109/TSC.2018.2791601
   Singh KN, 2022, COMPUT COMMUN, V193, P410, DOI 10.1016/j.comcom.2022.07.049
   Song JK, 2020, INT J COMPUT VISION, V128, P2243, DOI 10.1007/s11263-020-01305-2
   Suri S, 2017, ADV INTELL SYST, V555, P37, DOI 10.1007/978-981-10-3779-5_6
   Vatandoost M., 2019, HOSP PRACTICES RES, V4, P1, DOI [DOI 10.15171/HPR.2019.01, 10.15171/hpr.2019.01]
   Wang SC, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2019.105995
   Wang T, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106355
   Wang WQ, 2021, SIGNAL PROCESS-IMAGE, V99, DOI 10.1016/j.image.2021.116521
   Wang XY, 2021, OPT LASER TECHNOL, V138, DOI 10.1016/j.optlastec.2020.106837
   Wang XY, 2018, OPT LASER ENG, V103, P1, DOI 10.1016/j.optlaseng.2017.11.009
   Yang CH, 2019, IEEE ACCESS, V7, P50513, DOI 10.1109/ACCESS.2019.2910859
   Yang FF, 2019, PHYS SCRIPTA, V94, DOI 10.1088/1402-4896/ab0033
   Ye GD, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107563
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang Y, 2021, INFORM SCIENCES, V547, P307, DOI 10.1016/j.ins.2020.07.058
   Zhu LY, 2022, INFORM SCIENCES, V607, P1001, DOI 10.1016/j.ins.2022.06.011
NR 61
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 14
PY 2023
DI 10.1007/s11042-023-16359-w
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2HF6
UT WOS:001048894900009
DA 2024-07-18
ER

PT J
AU Rani, S
   Jain, A
AF Rani, Somiya
   Jain, Amita
TI Aspect-based sentiment analysis of drug reviews using multi-task
   learning based dual BiLSTM model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Aspect-based Sentiment Analysis; Attention; BERT; Deep Learning; Drug
   Reviews; Dual BiLSTM; Multi-Head Self-Attention; Multi-task Learning
ID ATTENTION
AB User-generated content on healthcare web forums, particularly drug reviews, provides valuable information on drug benefits, effectiveness, side effects, dosage, condition, cost, and overall experiences. Applying Aspect-Based Sentiment Analysis (ABSA) can help researchers categorize sentiments toward specific aspects such as drug effectiveness, side effects, and treatment experiences. These insights are highly useful for healthcare professionals, pharmaceutical companies, and researchers to assess drug efficacy and safety, utilizing the vast amount of healthcare-related user-generated content available online. However, due to scarcity of annotated data for training ABSA models in the medical domain poses challenges in accurately extracting aspect terms. Also, the identification of implicit aspects poses a huge challenge as they frequently lack explicit names or keywords that directly indicate their presence. The domain-dependent nature of ABSA and the variability of term meanings across domains necessitate the incorporation of contextual information and semantic patterns. Therefore, we propose a novel model called Multi-task Learning based Dual Bidirectional LSTM Model (MLDBM) for ABSA of drug reviews. The MLDBM leverages BERT and incorporates a multi-head self-attention mechanism to produce aspect-specific representations which are further processed through the dual BiLSTM model. This enables the model to capture and analyze sentiments related to different aspects discussed in the reviews. We also introduce various modifications to the MLDBM to identify the constraints of the proposed model. The proposed model outperforms state-of-the-art models by achieving a performance gain of 8% to 12% on two benchmark datasets, demonstrating its effectiveness when compared to various baseline models. ABSA applied to drug reviews contributes to enhancing healthcare quality by considering different aspects of drugs as shared by consumers.
C1 [Rani, Somiya] Guru Gobind Singh Indraprastha Univ, Netaji Subhas Univ Technol East Campus erstwhile A, Dept Comp Sci & Engn, Delhi, India.
   [Jain, Amita] Netaji Subhas Univ Technol, Dept Comp Sci & Engn, Delhi, India.
C3 GGS Indraprastha University; Netaji Subhas University of Technology
RP Jain, A (corresponding author), Netaji Subhas Univ Technol, Dept Comp Sci & Engn, Delhi, India.
EM somiya1093@gmail.com; amitajain@aiactr.ac.in
OI Rani, Somiya/0000-0002-6345-4013
CR Abdelgwad MM, 2022, J KING SAUD UNIV-COM, V34, P6652, DOI 10.1016/j.jksuci.2021.08.030
   Alsayat A, 2022, ARAB J SCI ENG, V47, P2499, DOI 10.1007/s13369-021-06227-w
   Basiri ME, 2020, KNOWL-BASED SYST, V198, DOI 10.1016/j.knosys.2020.105949
   Bayraktar K, 2019, IEEE INT CONF BIG DA, P2154, DOI 10.1109/BigData47090.2019.9005473
   Bensoltane R, 2022, SOC NETW ANAL MIN, V12, DOI 10.1007/s13278-021-00794-4
   Bhatti UA, 2022, POL J ENVIRON STUD, V31, P4029, DOI 10.15244/pjoes/148065
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Bonifazi G, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103095
   Chen JA, 2023, T ASSOC COMPUT LING, V11, P191, DOI 10.1162/tacl_a_00542
   Colón-Ruiz C, 2020, J BIOMED INFORM, V110, DOI 10.1016/j.jbi.2020.103539
   Dubey G, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.7512
   Geetha M.P., 2021, Int. J. Intell. Netw, V2, P64, DOI [10.1016/j.ijin.2021.06.005, DOI 10.1016/J.IJIN.2021.06.005]
   Grasser F, 2018, DH '18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON DIGITAL HEALTH, P121, DOI 10.1145/3194658.3194677
   Han Y, 2020, IEEE ACCESS, V8, P21314, DOI 10.1109/ACCESS.2020.2969473
   He RD, 2018, Arxiv, DOI arXiv:1806.04346
   Huang BX, 2018, LECT NOTES COMPUT SC, V10899, P197, DOI 10.1007/978-3-319-93372-6_22
   Huang SQ, 2020, IET IMAGE PROCESS, V14, P3324, DOI 10.1049/iet-ipr.2019.0772
   Jayanto R., 2022, INT J ADV INTELL INF, V8, P391, DOI 10.26555/ijain.v8i3.691
   Karsi Redouane, 2021, Revue d'Intelligence Artificielle, V35, P307, DOI 10.18280/ria.350405
   Ke ZW, 2021, IEEE ACCESS, V9, P3570, DOI 10.1109/ACCESS.2020.3048088
   Li X, 2019, Arxiv, DOI arXiv:1910.00883
   Lin YM, 2021, IEEE ACCESS, V9, P8762, DOI 10.1109/ACCESS.2021.3049294
   Liu Q, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1023, DOI 10.1145/3178876.3186001
   Ma DH, 2017, Arxiv, DOI arXiv:1709.00893
   Ma YK, 2018, COGN COMPUT, V10, P639, DOI 10.1007/s12559-018-9549-x
   Ma YK, 2018, AAAI CONF ARTIF INTE, P5876
   Jiménez-Zafra SM, 2019, ARTIF INTELL MED, V93, P50, DOI 10.1016/j.artmed.2018.03.007
   Miao YL, 2021, J INTELL FUZZY SYST, V40, P8697, DOI 10.3233/JIFS-192078
   Patil RS, 2022, SOC NETW ANAL MIN, V12, DOI 10.1007/s13278-022-00877-w
   Ray P, 2022, APPL COMPUT INFORM, V18, P163, DOI 10.1016/j.aci.2019.02.002
   Setiawan EI., 2020, COMPUTING, V1, P2, DOI [10.22266/ijies2020.1031.35, DOI 10.22266/IJIES2020.1031.35]
   Sun C, 2019, Arxiv, DOI arXiv:1903.09588
   Sweidan AH, 2021, IEEE ACCESS, V9, P90828, DOI 10.1109/ACCESS.2021.3091394
   Tang D, 2016, P C EMP METH NAT LAN, P214, DOI DOI 10.18653/V1/D16-1021
   Wang Y., 2016, P 2016 C EMPIRICAL M, P606, DOI 10.18653/v1/D16-1058
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Xiao LW, 2022, NEUROCOMPUTING, V471, P48, DOI 10.1016/j.neucom.2021.10.091
   Xu H, 2019, Arxiv, DOI arXiv:1904.02232
   Xue W, 2018, Arxiv, DOI arXiv:1805.07043
   Yadav S, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P2790
   Yang C, 2019, INFORM PROCESS MANAG, V56, P463, DOI 10.1016/j.ipm.2018.12.004
   Zhao AP, 2021, KNOWL-BASED SYST, V227, DOI 10.1016/j.knosys.2021.107220
   Zhao HL, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102656
   Zunic A, 2022, MACH LEARN KNOW EXTR, V4, P474, DOI 10.3390/make4020021
NR 44
TC 0
Z9 0
U1 6
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-16360-3
EA AUG 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4RY6
UT WOS:001043714700006
DA 2024-07-18
ER

PT J
AU Wu, RW
   Bi, HB
   Zhang, C
   Zhang, JY
   Tong, YY
   Jin, W
   Liu, ZG
AF Wu, Ranwan
   Bi, Hongbo
   Zhang, Cong
   Zhang, Jiayuan
   Tong, Yuyu
   Jin, Wei
   Liu, Zhigang
TI Pyramid contract-based network for RGB-T salient object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RGB-T saliency detection; Salient object detection; Cross-modal
   interaction; Neighbor feature fusion
ID FUSION
AB RGB-Thermal (RGB-T) salient object detection (SOD) aims at utilizing RGB and thermal infrared data to segment the most visually attractive object(s) in an image. However, in RGB-T SOD community, how to effectively interact with different modalities (e.g. RGB information and thermal infrared data) has always been concerned by researchers. Besides, to obtain more accurate detection results, achieving the full fusion of adjacent features is another hot topic that arouses the discussion of many scholars. To achieve the effective interaction between different modalities and the entire integration of neighbor features, this paper proposes a Pyramid Contract-based Network (PCNet) for RGB-T salient object detection. Specifically, firstly, we design a cross-modal interaction module (CIM) to promote the feature interaction between RGB and thermal data by cross-referencing different modalities strategy. In addition, we propose a feature reinforcement block (FRB) for enhancing feature representation and construct a neighbor feature fusion module (NFFM) based on the FRB to accomplish the aggregation of neighbor features. Moreover, to make full use of multi-level features, this paper employs a pyramid shrinkage structure to boost the performance of salient object detection. Comprehensive experiments demonstrate that the proposed method is competitive compared with the other nine state-of-the-art methods on three benchmark data sets. The source code and results will be made publicly available at: .
C1 [Wu, Ranwan; Bi, Hongbo; Zhang, Cong; Zhang, Jiayuan; Tong, Yuyu] Northeast Petr Univ, Sch Eletr informat Engn, Daqing, Peoples R China.
   [Jin, Wei] Natl Univ Def Technol, Infrared & Low Temp Plasma Key Lab Anhui Prov, Hefei, Peoples R China.
   [Liu, Zhigang] Northeast Petr Univ, Sch Comp & informat Technol, Daqing, Peoples R China.
C3 Northeast Petroleum University; National University of Defense
   Technology - China; Northeast Petroleum University
RP Bi, HB (corresponding author), Northeast Petr Univ, Sch Eletr informat Engn, Daqing, Peoples R China.
EM bhbdq@126.com
RI Yang, Ning/KHD-1133-2024; zhang, ling/JXW-6931-2024; liu,
   xingyu/JXW-9444-2024; Zhang, Wenbin/JXX-8070-2024; Li,
   Lei/JPE-6543-2023; Wang, Guanhua/JXM-6373-2024
OI Bi, Hongbo/0000-0003-2442-330X
FU Infrared and Low Temperature Plasma Key Laboratory of Anhui Province
   [IRKL2022KF07]
FX This paper was supported by Infrared and Low Temperature Plasma Key
   Laboratory of Anhui Province under No.IRKL2022KF07
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Borji Ali, 2019, [Computational Visual Media, 计算可视媒体], V5, P117
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P742, DOI 10.1109/TIP.2014.2383320
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Cong RM, 2019, IEEE T MULTIMEDIA, V21, P1660, DOI 10.1109/TMM.2018.2884481
   Cong RM, 2019, IEEE T CIRC SYST VID, V29, P2941, DOI 10.1109/TCSVT.2018.2870832
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Fan D-P, 2018, ARXIV
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Fu KR, 2013, SIGNAL PROCESS-IMAGE, V28, P1448, DOI 10.1016/j.image.2013.07.005
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Gao W, 2022, IEEE T CIRC SYST VID, V32, P2091, DOI 10.1109/TCSVT.2021.3082939
   Gidaris S, 2016, PROC CVPR IEEE, P789, DOI 10.1109/CVPR.2016.92
   Gong AJ, 2022, APPL INTELL, V52, P1030, DOI 10.1007/s10489-021-02434-y
   Guo QL, 2021, IEEE SIGNAL PROC LET, V28, P1655, DOI 10.1109/LSP.2021.3102524
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Huang LM, 2022, IEEE T CIRC SYST VID, V32, P1366, DOI 10.1109/TCSVT.2021.3069812
   Kong YQ, 2021, PATTERN RECOGN, V114, DOI 10.1016/j.patcog.2021.107867
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li YW, 2021, PROC CVPR IEEE, P214, DOI 10.1109/CVPR46437.2021.00028
   Li ZC, 2022, IEEE T PATTERN ANAL, V44, P9904, DOI 10.1109/TPAMI.2021.3132068
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Liang YH, 2022, NEUROCOMPUTING, V490, P132, DOI 10.1016/j.neucom.2022.03.029
   Liu Z., 2022, ARXIV
   Ma YP, 2017, INT SYM COMPUT INTEL, P389, DOI 10.1109/ISCID.2017.92
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Pingping Zhang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P202, DOI 10.1109/ICCV.2017.31
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Tang J, 2020, IEEE T CIRC SYST VID, V30, P4421, DOI 10.1109/TCSVT.2019.2951621
   Tu Z, IEEE T MULTIMEDIA, V22, P16
   Tu ZZ, 2021, IEEE T IMAGE PROCESS, V30, P5678, DOI 10.1109/TIP.2021.3087412
   Tu ZZ, 2021, IEEE T CIRC SYST VID, V31, P582, DOI 10.1109/TCSVT.2020.2980853
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Wang JF, 2021, PROC CVPR IEEE, P15844, DOI 10.1109/CVPR46437.2021.01559
   Wang LZ, 2019, IEEE T PATTERN ANAL, V41, P1734, DOI 10.1109/TPAMI.2018.2846598
   Wang NN, 2019, IEEE ACCESS, V7, P55277, DOI 10.1109/ACCESS.2019.2913107
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Yongri Piao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9057, DOI 10.1109/CVPR42600.2020.00908
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang J, 2022, IEEE T PATTERN ANAL, V44, P4005, DOI 10.1109/TPAMI.2021.3064850
   Zhang M, 2020, PROC CVPR IEEE, P3469, DOI 10.1109/CVPR42600.2020.00353
   Zhang Q, 2021, IEEE T CIRC SYST VID, V31, P1804, DOI 10.1109/TCSVT.2020.3014663
   Zhang Q, 2020, IEEE T IMAGE PROCESS, V29, P3321, DOI 10.1109/TIP.2019.2959253
   Zhou HJ, 2017, IEEE INT CONF COMP V, P760, DOI 10.1109/ICCVW.2017.95
   Zhou T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4661, DOI 10.1109/ICCV48922.2021.00464
   Zhou T, 2021, COMPUT VIS MEDIA, V7, P37, DOI 10.1007/s41095-020-0199-z
   Zhou WJ, 2022, IEEE T CIRC SYST VID, V32, P1224, DOI 10.1109/TCSVT.2021.3077058
   Zhu L, 2014, IEEE T IMAGE PROCESS, V23, P5094, DOI 10.1109/TIP.2014.2361024
   Zongyan Han, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12862, DOI 10.1109/CVPR42600.2020.01288
NR 52
TC 1
Z9 1
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20805
EP 20825
DI 10.1007/s11042-023-15794-z
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001043063500003
DA 2024-07-18
ER

PT J
AU Singh, NM
   Sharma, SK
AF Singh, Neha Minder
   Sharma, Sanjay Kumar
TI An efficient automated multi-modal cyberbullying detection using
   decision fusion classifier on social media platforms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modal generation; Multi-modal decision fusion classifier; Score
   based fusion; Term frequency-average inverse document frequency; Deep
   learning classification
AB Cyberbullying poses a dangerous threat to teens, children, young people, and adults in today's digital world. Bullies use virtual social media platforms like Twitter, Facebook, YouTube, and Instagram to harm their victims. Therefore, this online bullying (cyberbullying) is now rising as an important societal issue that affects the person emotionally and psychologically. Among the number of studies conducted to deal with cyberbullying detection, most of them are limited to only text-based content. Since the network is continuously growing, the presence of visual and audio based provoking is also needed to be considered. Therefore, the proposed study aims to develop an automatic multi-modal cyberbullying detection on social media platforms through Multi-modal Decision Fusion Classifier. The proposed multi-modal cyberbullying detection steps are data collection, multi-modality generation, score-based fusion and classification. Multiple major modalities, such as audio, visual and textual, are initially gathered from appropriate datasets. The data collected is provided as input to a multi-modal generation, where the modality is generated separately for each input. The text modality is initially generated using the hybrid Bi-directional Long Short-Term Memory assisted Attention Hierarchical Capsule Network (BiLSTM-AHCNet) model. Next, the imaging modality is generated with the Tuned Aquila EfficientB0 (Tuned AEB0) model. Finally, the audio features are extracted through the Librosa library, and the extracted features are fed to the Attention Convolutional Neural Network (ACNN) model for acoustic modality generation. In the proposed work, the Multi-Modality Decision Fusion Classifier (MMDFC) is employed to fuse all modalities, and the classification is performed by adopting the softmax layer. In addition, a weighting scheme based on horse herd optimization is applied in the fusion phase to allow accurate characterization of the features. For the simulation analysis, the proposed study used Python, and the effectiveness of the proposed techniques is analyzed by measuring several performance metrics like accuracy (98.23%), F-measure (98.22%), specificity (98.47%) and AUC (0.982).
C1 [Singh, Neha Minder; Sharma, Sanjay Kumar] Oriental Univ, Comp Sci & Engn, Indore 453555, Maharashtra, India.
RP Singh, NM (corresponding author), Oriental Univ, Comp Sci & Engn, Indore 453555, Maharashtra, India.
EM neha.cse@orientaluniversity.in
RI Sharma, Sanjay Kumar/AAR-2495-2020
OI Sharma, Sanjay Kumar/0000-0003-1515-2069
CR Agrawal S, 2018, LECT NOTES COMPUT SC, V10772, P141, DOI 10.1007/978-3-319-76941-7_11
   Alam F, 2021, P 29 INT C COMPUTATI, P6625
   Alotaibi M, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10212664
   Bozyigit A, 2021, EXPERT SYST APPL, V179, DOI 10.1016/j.eswa.2021.115001
   Chatzakou D, 2017, PROCEEDINGS OF THE 2017 ACM WEB SCIENCE CONFERENCE (WEBSCI '17), P13, DOI 10.1145/3091478.3091487
   Cheng L, 2021, IEEE INTERNET COMPUT, V25, P66, DOI 10.1109/MIC.2020.3032930
   Cheng L, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P185, DOI 10.1145/3340531.3411934
   Fang Y, 2021, INFORMATION, V12, DOI 10.3390/info12040171
   Gomez R, 2020, IEEE WINT CONF APPL, P1459, DOI 10.1109/WACV45572.2020.9093414
   Haidar B, 2018, PROCEEDINGS OF THE 2018 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING (ICCCE), P284, DOI 10.1109/ICCCE.2018.8539303
   Islam MdManowarul., 2020, 2020 IEEE ASIA PACIF, P1
   Iwendi C, 2023, MULTIMEDIA SYST, V29, P1839, DOI 10.1007/s00530-020-00701-5
   Kumar A, 2022, MULTIMEDIA SYST, V28, P2043, DOI 10.1007/s00530-020-00747-5
   Kumar A, 2022, WORLD WIDE WEB, V25, P1537, DOI 10.1007/s11280-021-00920-4
   Kumar A, 2022, MULTIMEDIA SYST, V28, P2027, DOI 10.1007/s00530-020-00672-7
   Kumar S, 2019, MULTIMED TOOLS APPL, V78, P23809, DOI 10.1007/s11042-019-07936-z
   Kumari K, 2021, FUTURE GENER COMP SY, V118, P187, DOI 10.1016/j.future.2021.01.014
   Kumari K, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3907
   Kumari K, 2020, SOFT COMPUT, V24, P11059, DOI 10.1007/s00500-019-04550-x
   Maity K, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P1739, DOI 10.1145/3477495.3531925
   Menini S, 2020, CLIC IT, V2769, P290
   Nandhini BS, 2015, ICARCSET'15: PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON ADVANCED RESEARCH IN COMPUTER SCIENCE ENGINEERING & TECHNOLOGY (ICARCSET - 2015), DOI 10.1145/2743065.2743085
   Paul S, 2022, MULTIMEDIA SYST, V28, P1897, DOI 10.1007/s00530-020-00710-4
   Paul S, 2022, MULTIMED TOOLS APPL, V81, P26989, DOI 10.1007/s11042-020-09631-w
   Rezvani N., 2021, J DATA INTELL, V2, P418, DOI [10.26421/JDI2.4-2, DOI 10.26421/JDI2.4-2]
   Roy PK., 2022, COMPLEX INTELL SYST, V25, P1
   Sui J., 2015, Doctoral dissertation
   Vishwamitra N, 2021, 2020 19 IEEE INT C M
NR 28
TC 1
Z9 1
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20507
EP 20535
DI 10.1007/s11042-023-16402-w
EA AUG 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001041470800002
DA 2024-07-18
ER

PT J
AU Kaur, R
   Singh, B
AF Kaur, Rajwinder
   Singh, Butta
TI A robust and imperceptible n-Ary based image steganography in DCT domain
   for secure communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Chaotic maps; DCT
ID DATA HIDING SCHEME; CAPACITY; ALGEBRA
AB Generally, spatial domain and transform domain steganography techniques are used to achieve the covert communication. The main drawback of embedding in frequency domain is rounding error appeared in the embedded secret message. Information is lost when integer pixel values are restored from the frequency domain, causing the embedded message to be distorted. A minor distortion of the embedded message renders extraction impossible and results in loss of embedded secret message. In the present study, a novel imperceptible Discrete Cosine Transform (DCT) and chaotic map based steganographic algorithm for secure communication has been proposed. The proposed method performs an adaptive n-Ary secret data embedding in the higher frequency DCT coefficients and removes the distortion. Additionally, the security of secret data is enhanced using chaotic maps to select the random DCT coefficients for embedding. The experimental results confirm that the proposed technique has high embedding capacity (EC), excellent stego-image quality and capability to withstand against malicious users. To examine security of the proposed method, the key space and key sensitivity parameter were used. Maximum EC = 425,780 bits was achieved with Peak Signal to Noise Ratio (PSNR) = 32.2218, 29.8804, 32.2507, 33.3327, 32.3963 and 31.4936 dB in case of Lena, Baboon, Jetplane, Elaine, Pepper and Boat respectively. The evaluated results show that the proposed method outperforms the existing steganography techniques in terms of EC and PSNR. Additionally, quality of stego image is identified by universal image quality index (Q), Bit Error Rate (BER) and Structural Similarity Index (SSIM).
C1 [Kaur, Rajwinder; Singh, Butta] Guru Nanak Dev Univ Reg Campus, Dept Engn & Technol, Jalandhar, India.
C3 Guru Nanak Dev University
RP Singh, B (corresponding author), Guru Nanak Dev Univ Reg Campus, Dept Engn & Technol, Jalandhar, India.
EM bsl.khanna@gmail.com
OI Singh, Butta/0000-0002-0170-6270
CR Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Arunkumar S, 2019, MEASUREMENT, V139, P426, DOI 10.1016/j.measurement.2019.02.069
   Bhatti Uzair Aslam, 2022, Proceedings of International Conference on Information Technology and Applications: ICITA 2021. Lecture Notes in Networks and Systems (350), P75, DOI 10.1007/978-981-16-7618-5_7
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bhowal K, 2013, TELECOMMUN SYST, V52, P2197, DOI 10.1007/s11235-011-9542-0
   Chakraborty S, 2017, STUD COMPUT INTELL, V660, P133, DOI 10.1007/978-3-319-44790-2_7
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   El Rahman SA, 2018, COMPUT ELECTR ENG, V70, P380, DOI 10.1016/j.compeleceng.2016.09.001
   Martínez-González RF, 2016, COMPUT ELECTR ENG, V54, P435, DOI 10.1016/j.compeleceng.2015.12.005
   Ghosal SK, 2021, COMPUT ELECTR ENG, V89, DOI 10.1016/j.compeleceng.2020.106964
   Hussain M, 2017, SIGNAL PROCESS-IMAGE, V50, P44, DOI 10.1016/j.image.2016.10.005
   Jafari R, 2013, EXPERT SYST APPL, V40, P6918, DOI 10.1016/j.eswa.2013.06.008
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P3287, DOI 10.1016/j.cnsns.2011.12.012
   Khan A, 2019, SOFT COMPUT, V23, P8045, DOI 10.1007/s00500-018-3441-1
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kumar R, 2019, J INF SECUR APPL, V47, P94, DOI 10.1016/j.jisa.2019.04.007
   Lee CC, 2008, PATTERN RECOGN, V41, P2097, DOI 10.1016/j.patcog.2007.11.018
   Lee CF, 2012, DIGIT SIGNAL PROCESS, V22, P941, DOI 10.1016/j.dsp.2012.05.015
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Lin YK, 2014, COMPUT STAND INTER, V36, P855, DOI 10.1016/j.csi.2013.12.013
   Malik A, 2018, MULTIDIM SYST SIGN P, V29, P1801, DOI 10.1007/s11045-017-0530-8
   Mao Q, 2015, INFORM SCIENCES, V317, P170, DOI 10.1016/j.ins.2015.05.013
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Mukherjee S, 2019, MULTIMED TOOLS APPL, V78, P16363, DOI 10.1007/s11042-018-6975-4
   Mukherjee S, 2018, MULTIMED TOOLS APPL, V77, P27851, DOI 10.1007/s11042-018-5996-3
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P1983, DOI 10.1007/s11042-013-1733-0
   Rabie T, 2018, MULTIMED TOOLS APPL, V77, P8295, DOI 10.1007/s11042-017-4727-5
   Rajaraman V, 2016, RESONANCE, V21, P11, DOI 10.1007/s12045-016-0292-x
   Rostami MJ, 2017, COMPUT ELECTR ENG, V62, P384, DOI 10.1016/j.compeleceng.2017.04.004
   Rukhin Andrew L., 2001, A statistical test suite for random and pseudorandom number generators for cryptographic applications, V22
   Saidi M, 2017, MULTIMED TOOLS APPL, V76, P13493, DOI 10.1007/s11042-016-3722-6
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Srinivasu LN, 2022, OPTIK, V265, DOI 10.1016/j.ijleo.2022.169398
   Subhedar MS, 2016, COMPUT ELECTR ENG, V54, P406, DOI 10.1016/j.compeleceng.2016.04.017
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Valandar MY, 2019, MULTIMED TOOLS APPL, V78, P9971, DOI 10.1007/s11042-018-6584-2
   Valandar MY, 2017, J INF SECUR APPL, V34, P142, DOI 10.1016/j.jisa.2017.04.004
   Wang CC, 2014, J SYST SOFTWARE, V93, P152, DOI 10.1016/j.jss.2014.02.023
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Yang CH, 2010, J SYST SOFTWARE, V83, P1635, DOI 10.1016/j.jss.2010.03.081
   Yao YZ, 2015, MULTIMED TOOLS APPL, V74, P11163, DOI 10.1007/s11042-014-2223-8
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 51
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20357
EP 20386
DI 10.1007/s11042-023-16330-9
EA AUG 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040962400001
DA 2024-07-18
ER

PT J
AU Wan, D
   Gao, C
   Zhou, J
   Shen, XR
   Shen, LL
AF Wan, Da
   Gao, Can
   Zhou, Jie
   Shen, Xinrui
   Shen, Linlin
TI Unsupervised fabric defect detection with high-frequency feature mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fabric defect detection; Deep learning; High-frequency extraction;
   Attention mechanism; Feature mapping
ID INSPECTION
AB Fabric defect detection is an important and necessary step in textile mills, and many deep learning-based methods have been proposed to perform defect detection and segmentation for fabric images. However, they still suffer from the lack of labor-intensive and high- cost labeled fabric images and the difficulty in finding discriminative feature representations of fabric defects. To address the problem, a novel unsupervised High-Frequency Feature Mapping Model (HFFMM) is proposed for fabric defect detection. First, aiming to capture the rich high-frequency information in defective images, a multi-scale high-frequency information extraction module is designed for the generation of high-frequency fabric images. Subsequently, to notice the differences between the original and high-frequency features, a query-key attention module is proposed to obtain the fused mapping matrix to improve the mapping capability. Finally, the two features transformed by the mapping matrix are compared to detect defects. Extensive experiments conducted on four public fabric datasets show that our method outperforms other state-of-the-art methods, especially for fabric images with regular textures, and achieves an average AUC improvement of 5.3% in detection and 2.9% in segmentation.
C1 [Wan, Da; Gao, Can; Zhou, Jie; Shen, Linlin] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
   [Wan, Da; Gao, Can; Zhou, Jie; Shen, Linlin] Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518060, Peoples R China.
   [Wan, Da; Gao, Can; Zhou, Jie; Shen, Linlin] Shenzhen Inst Artificial Intelligence, Robot Soc, SZU Branch, Shenzhen 518060, Peoples R China.
   [Shen, Xinrui] Shenzhen Univ, Coll Math & Stat, Shenzhen 518060, Peoples R China.
C3 Shenzhen University; Shenzhen Institute of Artificial Intelligence &
   Robotics for Society; Shenzhen University
RP Gao, C (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.; Gao, C (corresponding author), Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518060, Peoples R China.; Gao, C (corresponding author), Shenzhen Inst Artificial Intelligence, Robot Soc, SZU Branch, Shenzhen 518060, Peoples R China.
EM 2005gaocan@163.com
FU Shenzhen Science and Technology Program [JCYJ20210324094601005];
   Guangdong Basic and Applied Basic Research Foundation [2021A1515011861];
   National Natural Science Foundation of China [62076164, 61806127]
FX AcknowledgementsThis work was partially supported by the Shenzhen
   Science and Technology Program (No. JCYJ20210324094601005), Guangdong
   Basic and Applied Basic Research Foundation (No. 2021A1515011861), and
   National Natural Science Foundation of China (No. 62076164, 61806127).
CR Afzal HMR, 2020, IEEE ACCESS, V8, P180681, DOI 10.1109/ACCESS.2020.3028106
   Bergmann P, 2019, PROC CVPR IEEE, P9584, DOI 10.1109/CVPR.2019.00982
   Cheng L, 2023, MULTIMED TOOLS APPL, V82, P3101, DOI 10.1007/s11042-022-13568-7
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P803, DOI 10.1109/34.85670
   Cohen N, 2020, ARXIV
   Fang B, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3165254
   Ghafoori Z, 2020, IEEE T KNOWL DATA EN, V32, P815, DOI 10.1109/TKDE.2019.2934450
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He LJ, 2022, APPL INTELL, V52, P2051, DOI 10.1007/s10489-021-02556-3
   Hu WM, 2020, IEEE T KNOWL DATA EN, V32, P218, DOI 10.1109/TKDE.2018.2882404
   Kumar Ankit, 2023, 2023 International Conference on Communication System, Computing and IT Applications (CSCITA), P50, DOI 10.1109/CSCITA55725.2023.10104785
   Kumar A, 2002, IEEE T IND APPL, V38, P425, DOI 10.1109/28.993164
   Kumar A, 2008, IEEE T IND ELECTRON, V55, P348, DOI 10.1109/TIE.1930.896476
   Kurt MN, 2021, IEEE T PATTERN ANAL, V43, P2463, DOI 10.1109/TPAMI.2020.2970410
   Li CL, 2021, PROC CVPR IEEE, P9659, DOI 10.1109/CVPR46437.2021.00954
   Liqing Li, 2016, Key Engineering Materials, V671, P369, DOI 10.4028/www.scientific.net/KEM.671.369
   Ngan HYT, 2011, IMAGE VISION COMPUT, V29, P442, DOI 10.1016/j.imavis.2011.02.002
   Ngan HYT, 2010, IEEE T AUTOM SCI ENG, V7, P58, DOI 10.1109/TASE.2008.2005418
   Raj R, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103957
   Rasheed A, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/8189403
   Ruff L, 2018, PR MACH LEARN RES, V80
   Shakoor MH, 2023, MULTIMED TOOLS APPL, V82, P7639, DOI 10.1007/s11042-022-13470-2
   Shi Y, 2021, NEUROCOMPUTING, V424, P9, DOI 10.1016/j.neucom.2020.11.018
   Silvestre-Blanes J, 2019, AUTEX RES J, V19, P363, DOI 10.2478/aut-2019-0035
   Tsang CSC, 2016, PATTERN RECOGN, V51, P378, DOI 10.1016/j.patcog.2015.09.022
   Wu J, 2021, APPL INTELL, V51, P4945, DOI 10.1007/s10489-020-02084-6
   Zavrtanik V, 2022, LECT NOTES COMPUT SC, V13691, P539, DOI 10.1007/978-3-031-19821-2_31
   Zavrtanik V, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8310, DOI 10.1109/ICCV48922.2021.00822
   Zavrtanik V, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107706
   Zhang HD, 2022, APPL INTELL, V52, P10116, DOI 10.1007/s10489-021-02981-4
   Zheng Y, 2023, APPL INTELL, V53, P4563, DOI 10.1007/s10489-022-03595-0
   Zhou C, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P665, DOI 10.1145/3097983.3098052
   Zhou FQ, 2020, NEURAL PROCESS LETT, V52, P961, DOI 10.1007/s11063-019-10113-w
   Zong B., 2018, P 6 INT C LEARN REPR
NR 35
TC 1
Z9 1
U1 6
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21615
EP 21632
DI 10.1007/s11042-023-16340-7
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040586800010
DA 2024-07-18
ER

PT J
AU Zhou, Y
   Chen, JY
   Wang, DL
   Zhu, XL
AF Zhou, Yan
   Chen, Junyu
   Wang, Dongli
   Zhu, Xiaolin
TI Multi-object tracking using context-sensitive enhancement via feature
   fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-object tracking; Inception convolution; Weighted bidirectional
   pyramid; Feature fusion; Context-sensitive prediction modules
ID MULTITARGET TRACKING
AB Multi-object tracking (MOT) is one of the most challenging tasks in the field of computer vision. Most MOT methods generally face the problem of not being able to handle pedestrian features such as size and appearance well, which can easily lead to the problem of missed detection and occlusion. Considering this, an end-to-end multi-target tracking network with feature fusion and feature enhancement is proposed. The network framework integrates feature extraction, object detection, and data association. Using two adjacent frames as input chain nodes, based on Inception convolution as the backbone network, which has special pre-training weights that increase the perceptual domain of the network for multiple targets. In addition, the three-times repetitive overlay weighted bidirectional pyramid structure in the feature fusion module, which can focus more on key features and enhance the adaptability to target deformation. In order to solve the phenomenon of crowding in complex scenes, a context-sensitive prediction modules are added, which contain deeper and wider convolution to enhance the key information between targets. After the above processing, three loss function branches are formed, where the classification branch and the identity branch together form the attention multiplied by the regression branch to ensure the accuracy of regression. In MOT16 and MOT17 dataset experiments, our model MOTA metrics reach 67.9 and 67.7, with frame rates up to 30 FPS on a single GPU, with improved visualization results beyond Chain-Tracker.
C1 [Zhou, Yan; Chen, Junyu; Wang, Dongli] Xiangtan Univ, Sch Automat & Elect Informat, Xiangtan 411105, Peoples R China.
   [Zhu, Xiaolin] Xiangtan Univ, Sch Math & Computat Sci, Xiangtan 411105, Peoples R China.
C3 Xiangtan University; Xiangtan University
RP Zhou, Y (corresponding author), Xiangtan Univ, Sch Automat & Elect Informat, Xiangtan 411105, Peoples R China.
EM yanzhou@xtu.edu.cn
RI Zhu, Xiaolin/T-2135-2017
OI Zhu, Xiaolin/0000-0001-6568-0308
CR Adame Berhan Oumer, 2020, 2020 IEEE International Women in Engineering (WIE) Conference on Electrical and Computer Engineering (WIECON-ECE), P131, DOI 10.1109/WIECON-ECE52138.2020.9397963
   Aharon N., 2022, arXiv
   Badal T, 2018, MULTIMED TOOLS APPL, V77, P25199, DOI 10.1007/s11042-018-5781-3
   Bergmann P, 2019, IEEE I CONF COMP VIS, P941, DOI 10.1109/ICCV.2019.00103
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bochinski Erik, 2017, 2017 14th IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS), DOI 10.1109/AVSS.2017.8078516
   Bouraffa T, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104468
   Brasó G, 2020, PROC CVPR IEEE, P6246, DOI 10.1109/CVPR42600.2020.00628
   Chen LT, 2020, MULTIMED TOOLS APPL, V79, P35333, DOI 10.1007/s11042-019-07747-2
   Chu P, 2023, IEEE WINT CONF APPL, P4859, DOI 10.1109/WACV56688.2023.00485
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Elayaperumal D, 2021, INFORM SCIENCES, V577, P467, DOI 10.1016/j.ins.2021.06.084
   Fang K, 2018, IEEE WINT CONF APPL, P466, DOI 10.1109/WACV.2018.00057
   Fu LH, 2020, MULTIMED TOOLS APPL, V79, P32623, DOI 10.1007/s11042-020-09546-6
   Gao XW, 2022, SIGNAL IMAGE VIDEO P, V16, P965, DOI 10.1007/s11760-021-02041-x
   Guo S, 2021, PROC CVPR IEEE, P8132, DOI 10.1109/CVPR46437.2021.00804
   Hornakova A, 2020, PR MACH LEARN RES, V119
   Jain Shruti, 2021, 2021 IEEE International Women in Engineering (WIE) Conference on Electrical and Computer Engineering (WIECON-ECE), P5, DOI 10.1109/WIECON-ECE54711.2021.9829686
   Jinlong Peng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P145, DOI 10.1007/978-3-030-58548-8_9
   Karunasekera H, 2019, IEEE ACCESS, V7, P104423, DOI 10.1109/ACCESS.2019.2932301
   Kim C, 2021, PROC CVPR IEEE, P9548, DOI 10.1109/CVPR46437.2021.00943
   Kim C, 2018, LECT NOTES COMPUT SC, V11212, P208, DOI 10.1007/978-3-030-01237-3_13
   Kim C, 2015, IEEE I CONF COMP VIS, P4696, DOI 10.1109/ICCV.2015.533
   Kim DY, 2019, PATTERN RECOGN, V90, P377, DOI 10.1016/j.patcog.2019.02.004
   Li JH, 2020, IEEE WINT CONF APPL, P708, DOI 10.1109/WACV45572.2020.9093347
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu J, 2021, PROC CVPR IEEE, P11481, DOI 10.1109/CVPR46437.2021.01132
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mahmoudi N, 2019, MULTIMED TOOLS APPL, V78, P7077, DOI 10.1007/s11042-018-6467-6
   Pang B, 2020, PROC CVPR IEEE, P6307, DOI 10.1109/CVPR42600.2020.00634
   Pang YH, 2020, MULTIMED TOOLS APPL, V79, P27229, DOI 10.1007/s11042-020-09267-w
   Qin W, 2021, J PHYS C SERIES
   Ren S., 2015, Advances in Neural Information Processing Systems, V9199
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salau A.O., 2021, Indonesian Journal of Electrical Engineering and Computer Science, V24, P1515, DOI [10.11591/ijeecs.v24.i3.pp1515-1522, DOI 10.11591/IJEECS.V24.I3.PP1515-1522]
   Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7
   Shuai B, 2021, PROC CVPR IEEE, P12367, DOI 10.1109/CVPR46437.2021.01219
   Song Y., 2016, 2016 IEEE INT C VEHI, P1, DOI DOI 10.1109/ICVES.2016.7548171
   Sun SJ, 2021, IEEE T PATTERN ANAL, V43, P104, DOI 10.1109/TPAMI.2019.2929520
   Takala V, 2007, PROC CVPR IEEE, P3790
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tang X, 2018, LECT NOTES COMPUT SC, V11213, P812, DOI 10.1007/978-3-030-01240-3_49
   Tokmakov P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10840, DOI 10.1109/ICCV48922.2021.01068
   Wan J, 2022, ARXIV
   Wang L, 2017, IEEE IMAGE PROC, P3630, DOI 10.1109/ICIP.2017.8296959
   Wang YX, 2021, IEEE INT CONF ROBOT, P13708, DOI 10.1109/ICRA48506.2021.9561110
   Wang Z., 2020, COMPUTER VISION ECCV, P107, DOI [10.1007/978-3-030-58621-8_7, DOI 10.1007/978-3-030-58621-8_7]
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xing D., 2022, P IEEE CVF WINT C AP, P2139
   Xingyi Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P474, DOI 10.1007/978-3-030-58548-8_28
   Xu JR, 2019, IEEE I CONF COMP VIS, P3987, DOI 10.1109/ICCV.2019.00409
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Yang M, 2016, COMPUT VIS IMAGE UND, V153, P16, DOI 10.1016/j.cviu.2016.05.003
   Yu FW, 2016, LECT NOTES COMPUT SC, V9914, P36, DOI 10.1007/978-3-319-48881-3_3
   Zeng F., 2021, arXiv
   Zhang TZ, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23073609
   Zhang YF, 2022, LECT NOTES COMPUT SC, V13682, P1, DOI 10.1007/978-3-031-20047-2_1
   Zhichao Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14656, DOI 10.1109/CVPR42600.2020.01468
   Zhou ZW, 2018, INT C PATT RECOG, P1809, DOI 10.1109/ICPR.2018.8545450
   Zou Z, 2022, P IEEECVF WINTER C A, P307, DOI DOI 10.1109/WACV51458.2022.00273
NR 61
TC 0
Z9 0
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19465
EP 19484
DI 10.1007/s11042-023-16027-z
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037378900012
DA 2024-07-18
ER

PT J
AU Dehkordi, MH
   Mashhadi, S
   Farahi, ST
   Noorallahzadeh, MH
   Vahedi, S
   Gholami, A
   Alimoradi, R
AF Dehkordi, Massoud Hadian
   Mashhadi, Samaneh
   Farahi, Seyed Taghi
   Noorallahzadeh, Mohammad Hossein
   Vahedi, Shahed
   Gholami, Ahmad
   Alimoradi, Reza
TI OPTP: A new steganography scheme with high capacity and security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Security; Lossy compression; High capacity
ID IMAGES; JPEG
AB Steganography is the art of hiding secret information (text, audio, video, image or file) in a cover medium. Our goal in this paper is to propose a new image steganography scheme that simultaneously increases capacity and security. Increasing these two characteristics at the same time while maintaining the quality of the extracted secret image is a big challenge for scheme designers, and requires a trade-off. In the present paper, a new steganography scheme called OPTP is introduced in the spatial domain, where for the first time, One secret Picture is sent using only Two cover Pictures; therefore the name OPTP. In this method, two stego images are generated for each secret image using a simple equation, which brings higher capacity, security and quality compared to other existing schemes. To increase the capacity, we introduced a new lossy compression algorithm that performs better compared to conventional compression methods. Regarding the security, we used a key without initial handshake, and bloom filter is employed for the verification. We will compare features and results of the proposed scheme with some existing and recent schemes in the literature.
C1 [Dehkordi, Massoud Hadian; Mashhadi, Samaneh; Farahi, Seyed Taghi] Iran Univ Sci & Technol, Sch Math, Cryptog & Data Secur Lab, Tehran 1684613114, Iran.
   [Noorallahzadeh, Mohammad Hossein; Vahedi, Shahed; Gholami, Ahmad; Alimoradi, Reza] Qom Univ, Qom, Iran.
C3 Iran University Science & Technology; University of Qom
RP Farahi, ST (corresponding author), Iran Univ Sci & Technol, Sch Math, Cryptog & Data Secur Lab, Tehran 1684613114, Iran.
EM mhadian@iust.ac.ir; smashhadi@iust.ac.ir; St_farahi@mathdep.iust.ac.ir;
   Mh.noorallahzadeh@stu.qom.ac.ir; a.gholami@qom.ac.ir;
   alimoradi@qom.ac.ir
RI mashhadi, samaneh/ISV-0962-2023
OI mashhadi, samaneh/0000-0001-9191-1376; Farahi, Seyed
   Taghi/0000-0001-8414-4439
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Azzahra N. F., 2018, Journal of Physics: Conference Series, V1108, DOI 10.1088/1742-6596/1108/1/012082
   Banan A, 2020, AQUACULT ENG, V89, DOI 10.1016/j.aquaeng.2020.102053
   Biswapati J, 2016, ADV INTELL SYST, V411, P239, DOI 10.1007/978-81-322-2731-1_22
   Blundo C, 1996, THEOR COMPUT SCI, V165, P407, DOI 10.1016/0304-3975(96)00003-5
   Bose P, 2008, INFORM PROCESS LETT, V108, P210, DOI 10.1016/j.ipl.2008.05.018
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Celik MU, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P157
   Celik MU, 2003, PROC SPIE, V5020, P689, DOI 10.1117/12.477312
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Christensen K, 2010, INFORM PROCESS LETT, V110, P944, DOI 10.1016/j.ipl.2010.07.024
   Cox IJ., 2007, DIGITAL WATERMARKING
   Das S, 2018, ADV INTELL SYST, V563, P3, DOI 10.1007/978-981-10-6872-0_1
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   FCMNet, 2021, NEUROCOMPUTING
   Grajeda-Marín IR, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418600108
   Hamza A, 2021, KSII T INTERNET INF, V15, P1051, DOI 10.3837/tiis.2021.03.013
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Jia W, 2008, APPL MATH COMPUT, V205, P927, DOI 10.1016/j.amc.2008.05.024
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Kalita M, 2016, P 25 INT C SYSTEMS S, DOI [10.1109/IWSSIP.2016.7502756, DOI 10.1109/IWSSIP.2016.7502756]
   Kim S, 2016, J DISP TECHNOL, V12, P376, DOI 10.1109/JDT.2015.2493163
   Lee CF, 2017, MULTIMED TOOLS APPL, V76, P9993, DOI 10.1007/s11042-016-3591-z
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lee K.-H., 2009, P 3 INT C UB INF MAN, P228, DOI [10.1145/1516241.1516281.11T.-C, DOI 10.1145/1516241.1516281.11T.-C]
   Li Liu, 2017, International Journal of Network Security, V19, P327, DOI 10.6633/IJNS.201703.19(3).01
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Lu TC, 2017, MULTIMED TOOLS APPL, V76, P1827, DOI 10.1007/s11042-015-3168-2
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Lu TC, 2015, SIGNAL PROCESS, V108, P77, DOI 10.1016/j.sigpro.2014.08.022
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P13025, DOI 10.1007/s11042-016-3707-5
   MoADNet, 2022, IEEE T CIRC SYST VID
   MULLIN JK, 1983, COMMUN ACM, V26, P570, DOI 10.1145/358161.358167
   Nezami ZI, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.1157
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   NYEEM H, 2017, 2017 20 INT C COMP I, P1
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Rabbani M., 2001, LOSSLESS RECOVERY OR, V6, P791
   Rajendran Sujarani, 2017, International Journal of Network Security, V19, P593, DOI 10.6633/IJNS.201707.19(4).12
   Shamshirband S, 2019, IEEE ACCESS, V7, P164650, DOI 10.1109/ACCESS.2019.2951750
   Shieh JM, 2006, COMPUT STAND INTER, V28, P428, DOI 10.1016/j.csi.2005.03.006
   Shih Frank Y, 2017, Digital watermarking and steganography: fundamentals and techniques
   Starosolski R, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168704
   Swain G, 2016, PROCEDIA COMPUT SCI, V85, P39, DOI 10.1016/j.procs.2016.05.174
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Ulutas G, 2013, PATTERN RECOGN LETT, V34, P283, DOI 10.1016/j.patrec.2012.10.017
   Visual Sentiment Classification via Low-rank Regularization and Label Relaxation, 2021, IEEE T COGN DEV SYST
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   Wu CL, 2013, ENG APPL ARTIF INTEL, V26, P997, DOI 10.1016/j.engappai.2012.05.023
   Wu XT, 2019, J VIS COMMUN IMAGE R, V59, P550, DOI 10.1016/j.jvcir.2019.02.008
   Wu Y, 2020, INT J INTERACT MULTI, V6, P51, DOI 10.9781/ijimai.2020.02.005
   Yan XH, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115721
   Yip SK, 2006, IEEE INT SYMP CIRC S, P1426
NR 59
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17579
EP 17599
DI 10.1007/s11042-023-16312-x
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035725700018
DA 2024-07-18
ER

PT J
AU Han, Q
   Huangfu, ZL
   Min, WD
   Ding, TQ
   Liao, YQ
AF Han, Qing
   Huangfu, Zhanlu
   Min, Weidong
   Ding, TianQi
   Liao, Yanqiu
TI Sign language recognition based on skeleton and SK3D-Residual network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign Language Recognition; Skeleton; SK3D-Residual Network;
   Convolution-LSTM
ID GESTURE RECOGNITION; 3D HAND
AB Most of the existing dynamic sign language recognition methods based on deep learning directly use the video sequence or the whole sequence based on RGB information, not just the video sequence representing the change of gesture. These make it difficult for sign language recognition to achieve good accuracy. In order to solve these problems, this paper proposes a method of sign language recognition based on skeleton and SK3D-Residual network. In SK3D-Residual network, a key frame optimization algorithm for skeleton sequence based on mutual information is designed. The 3D-LSTM module extracts spatiotemporal features from the skeleton key frame sequences, analyzes the features of each action in the sequence, and then recognizes sign language. The experimental accuracy is 88.6%. In addition, the accuracy of the combination of RGB and skeleton information is 93.2%. Our experiment has achieved a good recognition accuracy.
C1 [Han, Qing; Min, Weidong; Ding, TianQi; Liao, Yanqiu] Nanchang Univ, Sch Math & Comp Sci, Xuefu Ave, Nanchang 330031, Jiangxi, Peoples R China.
   [Han, Qing; Min, Weidong] Nanchang Univ, Jiangxi Key Lab Smart City, Xuefu Ave, Nanchang 330031, Jiangxi, Peoples R China.
   [Han, Qing; Min, Weidong] Nanchang Univ, Inst Metaverse, Xuefu Ave, Nanchang 330031, Jiangxi, Peoples R China.
   [Huangfu, Zhanlu] Nanchang Univ, Sch Software, Nanjing East Rd, Nanchang 330047, Jiangxi, Peoples R China.
C3 Nanchang University; Nanchang University; Nanchang University; Nanchang
   University
RP Min, WD (corresponding author), Nanchang Univ, Sch Math & Comp Sci, Xuefu Ave, Nanchang 330031, Jiangxi, Peoples R China.; Min, WD (corresponding author), Nanchang Univ, Jiangxi Key Lab Smart City, Xuefu Ave, Nanchang 330031, Jiangxi, Peoples R China.; Min, WD (corresponding author), Nanchang Univ, Inst Metaverse, Xuefu Ave, Nanchang 330031, Jiangxi, Peoples R China.
EM minweidong@ncu.edu.cn
RI han, qing/KCZ-0174-2024; han, qing/KPB-6559-2024; Min,
   Weidong/D-4585-2017
OI Min, Weidong/0000-0003-2526-2181
FU National Natural Science Foundation of China [62076117, 61762061,
   62166026]; Jiangxi Key Laboratory of Smart City [20192BCD40002]
FX AcknowledgementsThis work was supported by the National Natural Science
   Foundation of China (Grant No. 62076117, No. 61762061 and No.62166026)
   and Jiangxi Key Laboratory of Smart City (Grant No. 20192BCD40002).
CR Baribina Natalija, 2019, Key Engineering Materials, V800, P326, DOI 10.4028/www.scientific.net/KEM.800.326
   Boulahia SY, 2017, INT CONF IMAG PROC
   Brock H, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3377552
   Chai Xiujuan, 2014, Technical Report VIPL-TR-14-SLR-001
   Chen XH, 2020, NEUROCOMPUTING, V395, P138, DOI 10.1016/j.neucom.2018.06.097
   Chen XH, 2017, IEEE IMAGE PROC, P2881, DOI 10.1109/ICIP.2017.8296809
   De Smedt Q, 2016, IEEE COMPUT SOC CONF, P1206, DOI 10.1109/CVPRW.2016.153
   Du T, 2022, ARXIV
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hou JX, 2019, LECT NOTES COMPUT SC, V11134, P273, DOI 10.1007/978-3-030-11024-6_18
   Huang XA, 2019, IEEE SENS J, V19, P9504, DOI 10.1109/JSEN.2019.2924797
   Ionescu B, 2005, EURASIP J APPL SIG P, V2005, P2101, DOI 10.1155/ASP.2005.2101
   Jiang LJ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19214680
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kim T, 2017, COMPUT SPEECH LANG, V46, P209, DOI 10.1016/j.csl.2017.05.009
   Kishore PVV, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2165, DOI 10.1109/WiSPNET.2016.7566526
   Koller O, 2016, PROC CVPR IEEE, P3793, DOI 10.1109/CVPR.2016.412
   Köpüklü O, 2018, IEEE COMPUT SOC CONF, P2184, DOI 10.1109/CVPRW.2018.00284
   Liao YQ, 2019, IEEE ACCESS, V7, P38044, DOI 10.1109/ACCESS.2019.2904749
   Lin YS, 2015, LECT NOTES COMPUT SC, V9010, P233, DOI 10.1007/978-3-319-16634-6_18
   Moon G, 2018, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2018.00533
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Piergiovanni A, 2017, P AAAI C ART INT, V31, DOI [10.1609/aaai.v31i1.11240, DOI 10.1609/AAAI.V31I1.11240]
   Reddy KS, 2011, COMM COM INF SC, V198, P346
   Ryoo MS, 2015, PROC CVPR IEEE, P896, DOI 10.1109/CVPR.2015.7298691
   Shou Zheng, 2017, P IEEE C COMP VIS PA, P5734, DOI DOI 10.48550/ARXIV.1703.01515
   Singh B, 2016, PROC CVPR IEEE, P1961, DOI 10.1109/CVPR.2016.216
   Smedt Q. D., 2017, EUROGRAPHICS WORKSHO, P33, DOI [DOI 10.2312/3DOR.20171049, 10.2312/3DOR.20171049]
   Song W, 2019, IEEE T BIOMED CIRC S, V13, P1563, DOI 10.1109/TBCAS.2019.2953998
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   WANG C, 2014, P 4 INT WORKSH COGN, P1
   Wang GJ, 2018, J VIS COMMUN IMAGE R, V55, P404, DOI 10.1016/j.jvcir.2018.04.005
   Wang HJ, 2016, NEUROCOMPUTING, V175, P674, DOI 10.1016/j.neucom.2015.10.112
   Xiao QK, 2020, NEURAL NETWORKS, V125, P41, DOI 10.1016/j.neunet.2020.01.030
   Xiong X, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10050551
   Xiong X, 2020, APPL INTELL, V50, P3521, DOI 10.1007/s10489-020-01751-y
   Xu HJ, 2017, IEEE I CONF COMP VIS, P5794, DOI 10.1109/ICCV.2017.617
   Yang H, 2021, IEEE T MULTIMEDIA, V23, P572, DOI 10.1109/TMM.2020.2985536
NR 38
TC 0
Z9 0
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18059
EP 18072
DI 10.1007/s11042-023-16117-y
EA JUL 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001034665300010
DA 2024-07-18
ER

PT J
AU Zhang, H
   Luo, GF
   Yue, YY
   He, KJ
   Xu, D
AF Zhang, Hao
   Luo, Gaifang
   Yue, Yingying
   He, Kangjian
   Xu, Dan
TI Affective image recognition with multi-attribute knowledge in deep
   neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective image recognition; Multi-attribute; Visual details; Semantics;
   Deep metric learning
AB Incorporating visual attributes such as objects and scene features into deep models has been proved valuable for affective image recognition. In general, the existing works achieve it by either fine-tuning popular CNNs for emotion recognition, or connecting external attributes through additional well-designed modules. However, they do not realize the diversity of emotional representations for different styles of affective images, or utilize the inter-hierarchical correlations in deep models. In this paper, we propose a multi-attribute model which incorporates different visual concepts to solve this problem. The model consists of 2 branch modules from local to global view: one trains a gram encoder to capture local visual details, and the other trains a semantic tokenizer to extract global semantics simultaneously. Through a fusion layer, we represent image sentiments with aggregated attributes. Different from the existing methods, our model is composed of stacked CNNs without additional backbones, and it shows the great ability to learn hierarchical attributes from internal intermediate features. Furthermore, inspired by deep metric learning, we design an emotional contrast loss to consider dynamic polarity embedded in affective images, and optimize the model within cross-entropy loss as well. A comprehensive evaluation on 5 datasets supports that our model outperforms the others.
C1 [Zhang, Hao; He, Kangjian; Xu, Dan] Yunnan Univ, Sch Informat Sci & Engn, Kunming, Peoples R China.
   [Luo, Gaifang] Shanxi Agr Univ, Sch Software, Jinzhong, Peoples R China.
   [Yue, Yingying] Yuxi Normal Univ, Sch Math & Informat Technol, Yuxi, Peoples R China.
C3 Yunnan University; Shanxi Agricultural University; Yuxi Normal
   University
RP Xu, D (corresponding author), Yunnan Univ, Sch Informat Sci & Engn, Kunming, Peoples R China.
EM haoyevv@outlook.com; gfluo@outlook.com; yyy@yxnu.edu.cn;
   Hekj@ynu.edu.cn; danxu@ynu.edu.cn
RI He, Kangjian/CAG-0300-2022; Xu, Dan/KPA-7396-2024
OI Xu, Dan/0000-0003-4602-3550; Yingying, Yue/0000-0002-0099-4901; Zhang,
   Hao/0000-0002-0404-6941; He, Kangjian/0000-0001-6207-9728
FU National Natural Science Foundation of China [62162068]; Yunnan Province
   Ten Thousand Talents Program and Yunling Scholars Special Project
   [YNWR-YLXZ-2018-022]; Yunnan Provincial Science and Technology
   Department-Yunnan University "Double First Class" Construction Joint
   Fund [202301BF070001-025]; 13th Graduate Research amp; Innovation
   Project of Yunnan University [2021Y277]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant No. 62162068, the Yunnan Province Ten
   Thousand Talents Program and Yunling Scholars Special Project under
   Grant No. YNWR-YLXZ-2018-022, the Yunnan Provincial Science and
   Technology Department-Yunnan University "Double First Class"
   Construction Joint Fund Project under Grant No. 202301BF070001-025, and
   the 13th Graduate Research & Innovation Project of Yunnan University
   under Grant No. 2021Y277.
CR Ajagbe S, 2021, INT J ADV COMPUT RES, V11, P51, DOI [10.19101/IJACR.2021.1152001, DOI 10.19101/IJACR.2021.1152001, 10.3390/electronics12030676]
   Ajagbe SA, 2022, 2022 INT C ELECT COM, P1, DOI [10.1109/ICECET55527.2022.9872568, DOI 10.1109/ICECET55527.2022.9872568]
   ALAMEDAPINEDA X, 2016, PROC CVPR IEEE, P5240, DOI DOI 10.1109/CVPR.2016.566
   Ali AR, 2017, IEEE WINT CONF APPL, P679, DOI 10.1109/WACV.2017.81
   Ankita, 2022, EXPERT SYST APPL, V193, DOI 10.1016/j.eswa.2021.116256
   Bhandari A, 2021, NEUROCOMPUTING, V433, P162, DOI 10.1016/j.neucom.2020.12.092
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Borth D., 2013, P 21 ACM INT C MULT, P459
   Bradley MM., 2017, Encyclopedia of Personality and Individual Differences, DOI [10.1007/978-3-319-28099-8_42-1, DOI 10.1007/978-3-319-28099-8_42-1, 10.1007/978-3-319-28099-842-1, DOI 10.1007/978-3-319-28099-842-1]
   Chen T., 2014, arXiv
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XS, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON BIG DATA AND COMPUTATIONAL INTELLIGENCE (ICBDCI)
   He XY, 2018, NEUROCOMPUTING, V291, P187, DOI 10.1016/j.neucom.2018.02.073
   Hossain MS, 2019, INFORM SCIENCES, V504, P589, DOI 10.1016/j.ins.2019.07.040
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Khirirat S, 2017, IEEE DECIS CONTR P
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   Ou HC, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062136
   Panda R, 2018, LECT NOTES COMPUT SC, V11206, P594, DOI 10.1007/978-3-030-01216-8_36
   Patricia V, IN PRESS
   Peng KC, 2015, P IEEE C COMP VIS PA
   Rao TR, 2020, NEURAL PROCESS LETT, V51, P2043, DOI 10.1007/s11063-019-10033-9
   Rao TR, 2019, NEUROCOMPUTING, V333, P429, DOI 10.1016/j.neucom.2018.12.053
   Rao TR, 2016, IEEE IMAGE PROC, P634, DOI 10.1109/ICIP.2016.7532434
   She DY, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3326335
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srinivas A, 2021, PROC CVPR IEEE, P16514, DOI 10.1109/CVPR46437.2021.01625
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tolstikhin I, 2021, ADV NEUR IN, V34
   Xiong HT, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0433-8
   Yamamoto T, 2021, IEICE T INF SYST, VE104D, P1691, DOI 10.1587/transinf.2020EDP7218
   Yang HS, 2023, VISUAL COMPUT, V39, P2177, DOI 10.1007/s00371-022-02472-8
   Yang JF, 2018, IEEE T MULTIMEDIA, V20, P2513, DOI 10.1109/TMM.2018.2803520
   Yang J, 2018, IEEE CONF COMPUT
   Yanulevskaya V, 2008, IEEE IMAGE PROC, P101, DOI 10.1109/ICIP.2008.4711701
   Yao XX, 2021, IEEE T MULTIMEDIA, V23, P1640, DOI 10.1109/TMM.2020.3001527
   You QZ, 2016, AAAI CONF ARTIF INTE, P308
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Yuan J., 2013, P 2 INT WORKSH ISS S, P1
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang H, 2022, NEURAL COMPUT APPL, V34, P14107, DOI 10.1007/s00521-022-07139-y
   [张浩 Zhang Hao], 2019, [中国科学. 信息科学, Scientia Sinica Informationis], V49, P204
   Zhang J, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105245
   Zhang W, 2020, IEEE T MULTIMEDIA, V22, P515, DOI 10.1109/TMM.2019.2928998
   Zhao SC, 2022, IEEE T PATTERN ANAL, V44, P6729, DOI 10.1109/TPAMI.2021.3094362
   Zhao SC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P192, DOI 10.1145/3343031.3351062
   Zhao SC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P369, DOI 10.1145/3123266.3130858
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
NR 54
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18353
EP 18379
DI 10.1007/s11042-023-16081-7
EA JUL 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001031485100007
DA 2024-07-18
ER

PT J
AU Gu, MH
   Feng, J
   Chu, YL
AF Gu, Meihua
   Feng, Jing
   Chu, Yalu
TI A novel multi-scale facial expression recognition algorithm based on
   improved Res2Net for classroom scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classroom scenes; Expression recognition; Res2Net; Multi-scale;
   Fine-grained coordinate attention mechanism
AB Facial expression recognition under classroom scenes can help the teacher to understand students' classroom learning status and improve teaching effectiveness. Aiming at the problem of low expression recognition accuracy in classroom scenarios, a novel multi-scale facial expression recognition algorithm based on improved Res2Net is proposed. Firstly, a bi-directional residual BiRes2Net module is proposed to achieve bi-directional multi-scale expression feature extraction at the fine-grained level, while a short-directed connection path is introduced to make the network have the self-closing capability and avoid extracting redundant information of expressions; Then the Fine-Grained Coordinate Attention (FGCA) mechanism is embedded to extract expression spatial location features and channel features at a fine-grained level by making full use of the prior knowledge of facial expressions; Finally, a multi-classification Focalloss loss function is used to alleviate the imbalance of expression data, and different weights are assigned to expression samples with different recognition difficulty so that the network is biased towards difficult sample feature extraction. The experimental results show that the recognition accuracy of the proposed method is 79.47%, 94.06%, and 96.67% in RAF-DB, JAFFE, and CK+ datasets respectively, and up to 72.71% in real classroom scenes, which are better than other comparative algorithms significantly.
C1 [Gu, Meihua; Feng, Jing; Chu, Yalu] Xian Polytech Univ, Sch Elect Informat, Xian 710048, Peoples R China.
C3 Xi'an Polytechnic University
RP Gu, MH (corresponding author), Xian Polytech Univ, Sch Elect Informat, Xian 710048, Peoples R China.
EM gumh2001@163.com
FU Postgraduate Innovation Fund Project of Xi'an Polytechnic University
   [chx2022012]
FX AcknowledgementsThis work was supported in part by Postgraduate
   Innovation Fund Project of Xi'an Polytechnic University (chx2022012).
CR Alphonse AS, 2017, J VIS COMMUN IMAGE R, V49, P459, DOI 10.1016/j.jvcir.2017.10.008
   Dimitrios K, 2021, P IEEE C COMPUTER VI, DOI [10.48550/arXiv.2015.03790, DOI 10.48550/ARXIV.2015.03790]
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Gao T., 2021, J INTELL SYST, V17, P393, DOI [10.11992/tis.202107028, DOI 10.11992/TIS.202107028]
   Gupta SK, 2019, MULTIMED TOOLS APPL, V78, P25321, DOI 10.1007/s11042-019-7651-z
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ji YL, 2019, NEUROCOMPUTING, V333, P231, DOI 10.1016/j.neucom.2018.12.037
   Li D, 2021, RES FACIAL EXPRESSIO, DOI [10.27684/d.cnki.gxndx.2021.003154, DOI 10.27684/D.CNKI.GXNDX.2021.003154]
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P356, DOI 10.1109/TIP.2018.2868382
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Minaee S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093046
   Peng Li, 2020, RES END TO END STUDE, DOI [10.27005/d.cnki.gdzku.2020.003411, DOI 10.27005/D.CNKI.GDZKU.2020.003411]
   Radlak K, 2016, 2016 18 MED EL C MEL, P1, DOI [10.1109/melcon.2016.7495381, DOI 10.1109/MELCON.2016.7495381]
   Renneberg B, 2005, J BEHAV THER EXP PSY, V36, P183, DOI 10.1016/j.jbtep.2005.05.002
   Ruan DL, 2021, PROC CVPR IEEE, P7656, DOI 10.1109/CVPR46437.2021.00757
   Ruoyu Zhu, 2016, 2016 41st International Conference on Infrared, Millimeter and Terahertz Waves (IRMMW-THz), DOI 10.1109/IRMMW-THz.2016.7758827
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Song Y, 2021, J BEIJING U AERONAUT, DOI [10.13700/j.bh.1001-5965.2021.0114, DOI 10.13700/J.BH.1001-5965.2021.0114]
   Stewart A, 2017, LECT NOTES ARTIF INT, V10331, P359, DOI 10.1007/978-3-319-61425-0_30
   [苏志明 Su Zhiming], 2021, [计算机工程, Computer Engineering], V47, P299
   Sun WY, 2018, NEUROCOMPUTING, V296, P12, DOI 10.1016/j.neucom.2018.03.034
   Sun YX, 2017, NEUROCOMPUTING, V230, P397, DOI 10.1016/j.neucom.2016.12.043
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vemulapalli R, 2019, PROC CVPR IEEE, P5676, DOI 10.1109/CVPR.2019.00583
   Wang K, 2020, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR42600.2020.00693
   Whitehill J, 2014, IEEE T AFFECT COMPUT, V5, P86, DOI 10.1109/TAFFC.2014.2316163
   Yao L, 2021, MULTIMED TOOLS APPL, V80, P24287, DOI 10.1007/s11042-021-10836-w
   Yongqiang LV, 2021, RES FACE EXPRESSION, DOI [10.27159/d.cnki.ghzsu.2021.002034, DOI 10.27159/D.CNKI.GHZSU.2021.002034]
   Yu Z, 2018, EMOTION RECOGNITION, DOI [10.27307/d.cnki.gsjtu.2018.004755, DOI 10.27307/D.CNKI.GSJTU.2018.004755]
   Zhang Peng, 2022, Computer Engineering and Applications, V58, P182, DOI 10.3778/j.issn.1002-8331.2106-0174
NR 36
TC 0
Z9 0
U1 7
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16525
EP 16542
DI 10.1007/s11042-023-16115-0
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001028490600002
DA 2024-07-18
ER

PT J
AU Sabir, S
   Guleria, V
AF Sabir, Shazia
   Guleria, Vandana
TI Multi-layer permutation-substitution operations based novel lossless
   multiple color image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Random matrix affine cipher; Generalized 3D Arnold transform; 3D chaotic
   map; SHA-256; Permutation process and substitution process
ID HYPER-CHAOTIC SYSTEM; SCHEME; TRANSFORM; MAP; SECURITY; PLANE; 3D
AB This work develops a novel lossless multiple color image encryption based on multi-layer permutation-substitution operations. Initially, sixteen RGB images are converted into a single plain image using matrix theory. The single plain image is then segmented into red (R), green (G) and blue (B) color channels. Each channel is used as an input image for the further process. The first layer of permutation-substitution is obtained using random matrix affine cipher (RMAC). Both row and column permutation-substitution processes are simultaneously performed in this layer. The second layer of permutation-substitution is acquired using generalized three-dimensional (3D) Arnold transform. Lastly, the third layer of permutation-substitution is achieved using non-linear 3D chaotic map. In the proposed technique, SHA-256 hash function is utilized to generate the secret keys. This makes the system extremely sensitive to the plain image and improves its robustness against plaintext attacks. In addition, the multi-layer permutation-substitution operations make our system more secure and stronger with exorbitant huge key space, high sensitivity, randomness and uncertainty between the pixels. Also, the proposed system deals with multiple images at a time which supports high security, efficiency and capacity space in transmitting and storing the data. Simulation analysis validates the effectiveness of our proposed work. Moreover, the proposed technique is empirically assessed via security and statistical evaluation metrics. The experimental findings from the evaluation metrics and comparison analysis validate that our proposed technique is robust and secure enough for real-world applications.
C1 [Sabir, Shazia; Guleria, Vandana] Birla Inst Technol Mesra, Dept Math, Ranchi, India.
C3 Birla Institute of Technology Mesra
RP Guleria, V (corresponding author), Birla Inst Technol Mesra, Dept Math, Ranchi, India.
EM vandana@bitmesra.ac.in
CR ABUNDIZPEREZ F, 2016, MATH PROBL ENG, P1
   Abuturab MR, 2020, OPT LASER ENG, V129, DOI 10.1016/j.optlaseng.2020.106038
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   Alanezi A, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6615512
   Askar SS, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21010044
   Azoug SE, 2016, OPT COMMUN, V359, P85, DOI 10.1016/j.optcom.2015.09.054
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Boriga Radu Eugen, 2014, IAENG International Journal of Computer Science, V41, P249
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Dong CE, 2015, OPTIK, V126, P2571, DOI 10.1016/j.ijleo.2015.06.035
   Gao Z., 2021, DISCRETE DYN NAT SOC, V2021, P1
   Gomez-Barrero M, 2018, INFORM FUSION, V42, P37, DOI 10.1016/j.inffus.2017.10.003
   Gong LH, 2018, OPT LASER TECHNOL, V103, P48, DOI 10.1016/j.optlastec.2018.01.007
   Guleria V, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102524
   Hossain MB, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV)
   Hsue WL, 2019, IEEE T CIRCUITS-II, V66, P1602, DOI 10.1109/TCSII.2018.2889968
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Huang H, 2018, SIGNAL PROCESS, V150, P183, DOI 10.1016/j.sigpro.2018.04.014
   Huang ZJ, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105821
   Joshi AB, 2021, INT J IMAGE GRAPH, V21, DOI 10.1142/S0219467821500066
   Joshi AB, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106139
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kang XJ, 2019, IEEE T CIRC SYST VID, V29, P1595, DOI 10.1109/TCSVT.2018.2851983
   Khade P.N., 2012, Int. J. Comput. Sci. Issues, V9, P323
   Kumar D, 2020, RESULTS OPT, V1, DOI 10.1016/j.rio.2020.100031
   Kumar M, 2014, OPT LASER ENG, V52, P27, DOI 10.1016/j.optlaseng.2013.07.015
   Li CL, 2018, OPTIK, V171, P277, DOI 10.1016/j.ijleo.2018.06.029
   Liu HJ, 2021, SOFT COMPUT, V25, P11077, DOI 10.1007/s00500-021-05849-4
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu HJ, 2020, OPTIK, V216, DOI 10.1016/j.ijleo.2020.164925
   Liu HJ, 2020, APPL MATH COMPUT, V376, DOI 10.1016/j.amc.2020.125153
   Liu HJ, 2013, OPTIK, V124, P3527, DOI 10.1016/j.ijleo.2012.10.068
   Liu Q, 2018, OPT REV, V25, P46, DOI 10.1007/s10043-017-0390-3
   Mehdi SA, 2021, INT J INF SECUR PRIV, V15, P118, DOI 10.4018/IJISP.2021100107
   Mishra DC, 2017, J INF SECUR APPL, V37, P65, DOI 10.1016/j.jisa.2017.09.006
   Murillo-Escobar MA, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0698-3
   Oravec J, 2018, RADIOENGINEERING, V27, P281, DOI 10.13164/re.2018.0281
   Pan SM, 2017, MULTIMED TOOLS APPL, V76, P2933, DOI 10.1007/s11042-015-3209-x
   Patro KAK, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102470
   Rakheja P, 2020, OPT QUANT ELECTRON, V52, DOI 10.1007/s11082-020-2219-8
   Ran QW, 2015, OPT COMMUN, V348, P43, DOI 10.1016/j.optcom.2015.03.016
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Sabir S, 2021, MULTIMED TOOLS APPL, V80, P27829, DOI 10.1007/s11042-021-11003-x
   Sahari ML, 2018, NONLINEAR DYNAM, V94, P723, DOI 10.1007/s11071-018-4390-z
   Shah D, 2020, MULTIDIM SYST SIGN P, V31, P885, DOI 10.1007/s11045-019-00689-w
   Si YY, 2021, INT J BIFURCAT CHAOS, V31, DOI 10.1142/S0218127421501467
   Singh H, 2018, J MOD OPTIC, V65, P2065, DOI 10.1080/09500340.2018.1496286
   Singh P, 2017, OPT APPL, V47, P421, DOI 10.5277/oa170308
   Sivakumar T., 2014, IAENG International Journal of Computer Science, V41, P91
   Sui LS, 2019, OPT LASER ENG, V122, P113, DOI 10.1016/j.optlaseng.2019.06.005
   Tanveer M, 2021, IEEE ACCESS, V9, P73924, DOI 10.1109/ACCESS.2021.3081362
   Tong LJ, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6650515
   Wang MM, 2020, OPT LASER TECHNOL, V124, DOI 10.1016/j.optlastec.2019.106001
   Wang Q, 2012, OPT COMMUN, V285, P4317, DOI 10.1016/j.optcom.2012.07.033
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Ye GD, 2021, NONLINEAR DYNAM, V104, P2807, DOI 10.1007/s11071-021-06422-2
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Zhang QY, 2021, IET IMAGE PROCESS, V15, P885, DOI 10.1049/ipr2.12069
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang XQ, 2017, OPT LASER ENG, V92, P6, DOI 10.1016/j.optlaseng.2016.12.005
   Zheng J., 2018, ADV DIFFER EQU-NY, V1, P1, DOI DOI 10.1186/S13662-018-1622-Y
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1902-1
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2015, OPT COMMUN, V354, P112, DOI 10.1016/j.optcom.2015.05.043
NR 70
TC 1
Z9 1
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16563
EP 16604
DI 10.1007/s11042-023-15992-9
EA JUL 2023
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001029126000005
DA 2024-07-18
ER

PT J
AU Kumar, S
   Verma, S
   Singh, BK
   Kumar, V
   Chandra, S
   Barde, C
AF Kumar, Sanjay
   Verma, Sushma
   Singh, Binod Kumar
   Kumar, Vinay
   Chandra, Subhash
   Barde, Chetan
TI Entropy based adaptive color image watermarking technique in<i>
   YC<sub>b</sub>C<sub>r</sub></i> color space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; DWT; SVD; Arnold transform; Entropy
ID HADAMARD-TRANSFORM; DIGITAL WATERMARKING; BLIND WATERMARKING; ROBUST;
   DWT; SCHEME; HYBRID; SVD; DOMAIN; DCT
AB Digital watermarking can be used to ensure the authenticity and copyright protection of images. In watermarking balancing the trade-offs between its features is an important issue. To address this issue, in this work an adaptive hybrid domain color image watermarking based on Discrete Wavelet Transform (DWT), Walsh Hadamard Transform (WHT), and Singular Value Decomposition (SVD) is proposed. Here, watermarking is carried on YCbCr color space. In this work, the embedding factor is calculated adaptively using the visual entropy and edge entropy. For better robustness the watermark is inserted into the Y component of YCbCr color Space. Further, Arnold Transform (AT) is used to secure the watermark. The average PSNR and SSIM of the proposed hybrid domain adaptive watermarking scheme is 40.0876 dB and 0.9883 respectively. The experimental results compared to the recent hybrid domain color watermarking, illustrate the superiority of the suggested approach.
C1 [Kumar, Sanjay] SRM Univ AP, Dept Comp Sci & Engn, Visual Informat Proc Lab, Guntur 522503, Andhra Prasedh, India.
   [Verma, Sushma; Singh, Binod Kumar; Kumar, Vinay] NIT Jamshedpur, Dept Comp Sci & Engn, Jamshedpur 831014, Jharkhand, India.
   [Chandra, Subhash] NIT Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
   [Barde, Chetan] IIIT Bhagalpur, Dept Elect & Commun Engn, Bhagalpur 813210, Bihar, India.
C3 SRM University-AP; National Institute of Technology (NIT System);
   National Institute of Technology Jamshedpur; National Institute of
   Technology (NIT System); National Institute of Technology Patna
RP Kumar, S (corresponding author), SRM Univ AP, Dept Comp Sci & Engn, Visual Informat Proc Lab, Guntur 522503, Andhra Prasedh, India.
EM sanjaykumar.spj@gmail.com; 2020rscs003@nitjsr.ac.in;
   bksingh.cse@nitjsr.ac.in; vkumar.cse@nitjsr.ac.in;
   subhash.cs@nitp.ac.in; chetanbarde14@gmail.com
RI Chandra, Subhash/JAX-6130-2023; Kumar, Dr. Sanjay/V-3889-2019; Singh,
   Binod/AAB-8663-2019
OI Chandra, Subhash/0000-0001-7710-4375; Kumar, Dr.
   Sanjay/0000-0002-4564-1085; Singh, Binod/0000-0002-2697-8918
CR Abdulla A. A., 2015, Ph.D. dissertation
   Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Al-maweri NAAS, 2015, SECUR COMMUN NETW, V8, P4373, DOI 10.1002/sec.1371
   Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Begum M, 2021, J KING SAUD UNIV-COM
   Begum M, 2020, ADV MULTIMED, V2020, DOI 10.1155/2020/7912690
   Cheema AM, 2020, IEEE ACCESS, V8, P169525, DOI 10.1109/ACCESS.2020.3024181
   Chen SY, 2022, OPTIK, V249, DOI 10.1016/j.ijleo.2021.168231
   Chopra A, 2020, MULTIMED TOOLS APPL, V79, P501, DOI 10.1007/s11042-019-08087-x
   Ernawan F, 2023, MULTIMED TOOLS APPL, V82, P27123, DOI 10.1007/s11042-023-14447-5
   Ernawan F, 2020, VISUAL COMPUT, V36, P19, DOI 10.1007/s00371-018-1567-x
   Evsutin O, 2022, SIGNAL PROCESS-IMAGE, V100, DOI 10.1016/j.image.2021.116523
   Huang Y, 2019, IEEE T MULTIMEDIA, V21, P2447, DOI 10.1109/TMM.2019.2907475
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   Kumar Sanjay, 2021, Machine Vision and Augmented Intelligence-Theory and Applications: Select Proceedings of MAI 2021. Lecture Notes in Electrical Engineering (796), P91, DOI 10.1007/978-981-16-5078-9_8
   Kumar S, 2021, MULTIMED TOOLS APPL, V80, P15487, DOI 10.1007/s11042-020-10322-9
   Kumar S, 2021, MULTIMED TOOLS APPL, V80, P13975, DOI 10.1007/s11042-020-10397-4
   Kumar S, 2020, MULTIMED TOOLS APPL, V79, P20149
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Ma Z, 2021, IEEE T CIRC SYST VID
   Maity SP, 2010, AEU-INT J ELECTRON C, V64, P243, DOI 10.1016/j.aeue.2008.10.004
   Makbol NM, 2018, MULTIMED TOOLS APPL, V77, P26845, DOI 10.1007/s11042-018-5891-y
   Mohammed AO, 2023, MULTIMED TOOLS APPL, V82, P32855, DOI 10.1007/s11042-023-14797-0
   Ojha S, 2018, SOFT COMPUTING THEOR, V1, P217
   Pandey MK, 2019, MICROSYST TECHNOL, V25, P3071, DOI 10.1007/s00542-018-4162-1
   Prabha K, 2020, MULTIMED TOOLS APPL, V79, P6845, DOI 10.1007/s11042-019-08212-w
   Ramos AM, 2023, ENTROPY-SWITZ, V25, DOI 10.3390/e25030508
   Roy S, 2019, IJST-T ELECTR ENG, V43, P201, DOI 10.1007/s40998-018-0109-x
   Roy S, 2018, WIRELESS PERS COMMUN, V98, P2223, DOI 10.1007/s11277-017-4971-z
   Santhi V, 2013, J INF SECUR APPL, V18, P167, DOI 10.1016/j.istr.2013.01.001
   Shaheed K, 2022, INFORM FUSION, V79, P84, DOI 10.1016/j.inffus.2021.10.004
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P18753, DOI 10.1007/s11042-021-10610-y
   Sharma S, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105696
   Shen YX, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114414
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh R, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102734
   Sinhal R, 2021, PATTERN RECOGN LETT, V145, P171, DOI 10.1016/j.patrec.2021.02.011
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Vaidya SP, 2018, MULTIMED TOOLS APPL, V77, P5609, DOI 10.1007/s11042-017-4476-5
   Vaidya SP, 2017, MULTIMED TOOLS APPL, V76, P25623, DOI 10.1007/s11042-017-4355-0
   Vaidya SP, 2023, VISUAL COMPUT, V39, P2245, DOI 10.1007/s00371-022-02406-4
   Walia S, 2021, IEEE ACCESS, V9, P99742, DOI 10.1109/ACCESS.2021.3096240
   Wang KY, 2022, MAGN RESON IMAGING, V91, P1, DOI 10.1016/j.mri.2022.05.001
   Yasmeen Fauzia, 2021, SN Comput Sci, V2, P82, DOI 10.1007/s42979-021-00478-y
   Zhang FY, 2019, MULTIMED TOOLS APPL, V78, P20133, DOI 10.1007/s11042-019-7326-9
   Zhang H, 2022, J FRANKLIN I, V359, P1755, DOI 10.1016/j.jfranklin.2021.11.027
   Zheng PJ, 2018, IEEE T IMAGE PROCESS, V27, P2541, DOI 10.1109/TIP.2018.2802199
NR 47
TC 1
Z9 1
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13725
EP 13751
DI 10.1007/s11042-023-16059-5
EA JUL 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001025717900003
DA 2024-07-18
ER

PT J
AU Lee, KK
   Ha, JW
   Yoo, JS
   Kim, JO
AF Lee, Kang-Kyu
   Ha, Jeong-Won
   Yoo, Jun-Sang
   Kim, Jong-Ok
TI Deep intrinsic image decomposition under colored AC light sources
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AC light; Color constancy; Intrinsic image decomposition
ID RETINEX
AB Intrinsic image decomposition assumes that the observed color image can be decomposed into reflectance and illumination. It is beneficial for understanding the physical world, but a severely ill-posed problem. Several sequence-based deep learning methods only exploit spatial prior to illumination, while the proposed method introduced temporal prior of illumination. They also assume gray illumination which may cause color distortion in the reflectance image. This paper proposes a deep intrinsic image decomposition method using a high-speed camera under colored AC light sources. A high-speed camera can capture the sinusoidal variations in scene brightness, which was used to extract the temporal correlation among high-speed video frames. With these powerful cues, the proposed method jointly performs intrinsic image decomposition and color constancy. To the best of our knowledge, this is the first study that exploits AC light properties for intrinsic image decomposition. We evaluate the color constancy and intrinsic image decomposition quality to validate the model estimation accuracy. The experimental results show that the proposed deep network can accurately estimate both illumination color and intrinsic images, and the two factors are mutually supportive each other for learning.
C1 [Lee, Kang-Kyu; Ha, Jeong-Won; Kim, Jong-Ok] Korea Univ, Seoul 02841, South Korea.
   [Yoo, Jun-Sang] Samsung Adv Inst Technol, Comp Vis Lab, Suwon 16678, Gyeonggi Do, South Korea.
C3 Korea University; Samsung
RP Kim, JO (corresponding author), Korea Univ, Seoul 02841, South Korea.
EM lk2lngr@korea.ac.kr; jwon9339@korea.ac.kr; look2017@korea.ac.kr;
   jokim@korea.ac.kr
RI KIM, MINJI/IXD-7702-2023
FU Samsung Electronics; National Research Foundation of Korea (NRF) - Korea
   government (MSIT) [2020R1A4A4079705]
FX AcknowledgementsThis work was supported by Samsung Electronics, and the
   National Research Foundation of Korea (NRF) grant funded by the Korea
   government (MSIT) (No. 2020R1A4A4079705).
CR Afifi M, 2019, IEEE I CONF COMP VIS, P243, DOI 10.1109/ICCV.2019.00033
   Alperovich A, 2018, PROC CVPR IEEE, P9145, DOI 10.1109/CVPR.2018.00953
   Barron JT, 2017, PROC CVPR IEEE, P6950, DOI 10.1109/CVPR.2017.735
   Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712
   Barrow Harry, 1978, Comput. Vis. Syst, V2, P2
   Baslamisli AS, 2018, PROC CVPR IEEE, P6674, DOI 10.1109/CVPR.2018.00698
   Baslamisli AS, 2021, COMPUT VIS IMAGE UND, V205, DOI 10.1016/j.cviu.2021.103183
   Beigpour S, 2011, IEEE I CONF COMP VIS, P327, DOI 10.1109/ICCV.2011.6126259
   Bell Sean, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2601206
   Bi S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766946
   Bianco Simone, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P81, DOI 10.1109/CVPRW.2015.7301275
   Bjorck A., 2015, Numerical methods in matrix computations, V59, DOI [10.1007/978-3-319-05089-8, DOI 10.1007/978-3-319-05089-8]
   Bonato Jacopo, 2017, Physics Education, V52, DOI 10.1088/1361-6552/aa6f8c
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Cai BL, 2017, IEEE I CONF COMP VIS, P4020, DOI 10.1109/ICCV.2017.431
   Chang A. X., 2015, ARXIV
   Chen QF, 2013, IEEE I CONF COMP VIS, P241, DOI 10.1109/ICCV.2013.37
   Cheng Z, 2019, IEEE I CONF COMP VIS, P2521, DOI 10.1109/ICCV.2019.00261
   Das P, 2022, COMPUT VIS IMAGE UND, V223, DOI 10.1016/j.cviu.2022.103538
   Duchêne S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2756549
   Eilertsen G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130816
   Fan QN, 2018, PROC CVPR IEEE, P8944, DOI 10.1109/CVPR.2018.00932
   Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37
   FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770
   Gehler P., 2011, P ADV NEUR INF PROC, P765
   Gijsenij A, 2010, INT J COMPUT VISION, V86, P127, DOI 10.1007/s11263-008-0171-3
   Grosse R, 2009, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2009.5459428
   Hachama M, 2015, IEEE I CONF COMP VIS, P810, DOI 10.1109/ICCV.2015.99
   Hu YM, 2017, PROC CVPR IEEE, P330, DOI 10.1109/CVPR.2017.43
   Kim S, 2016, LECT NOTES COMPUT SC, V9912, P143, DOI 10.1007/978-3-319-46484-8_9
   Kovacs B, 2017, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2017.97
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lettry L, 2018, COMPUT GRAPH FORUM, V37, P409, DOI 10.1111/cgf.13578
   Lettry L, 2018, IEEE WINT CONF APPL, P1359, DOI 10.1109/WACV.2018.00153
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Li Y, 2014, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2014.346
   Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI [10.1007/978-3-030-01240-3_21, 10.1007/978-3-030-01219-9_23]
   Li ZQ, 2018, PROC CVPR IEEE, P9039, DOI 10.1109/CVPR.2018.00942
   Liu YF, 2020, PROC CVPR IEEE, P3245, DOI 10.1109/CVPR42600.2020.00331
   Ma T, 2021, IEEE ACCESS, V9, P56539, DOI 10.1109/ACCESS.2021.3072331
   Ma WC, 2018, LECT NOTES COMPUT SC, V11218, P211, DOI 10.1007/978-3-030-01264-9_13
   Narihira T, 2015, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2015.7298915
   Park S, 2018, IEEE ACCESS, V6, P22084, DOI 10.1109/ACCESS.2018.2812809
   Qiu JQ, 2020, IEEE T IMAGE PROCESS, V29, P5711, DOI 10.1109/TIP.2020.2985296
   Rudnev V, 2022, LECT NOTES COMPUT SC, V13676, P615, DOI 10.1007/978-3-031-19787-1_35
   Sheinin M, 2017, PROC CVPR IEEE, P2363, DOI 10.1109/CVPR.2017.254
   Shen L, 2008, PROC CVPR IEEE, P2479
   Shi J, 2017, PROC CVPR IEEE, P5844, DOI 10.1109/CVPR.2017.619
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan R.T., 2008, Digitally Archiving Cultural Objects, P323
   Tsuji T, 2010, IEEE INT CONF ROBOT, P1542, DOI 10.1109/ROBOT.2010.5509252
   Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Vollmer M, 2015, EUR J PHYS, V36, DOI 10.1088/0143-0807/36/3/035027
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wei C, 2018, ARXIV
   Woo SM, 2018, IEEE T IMAGE PROCESS, V27, P1862, DOI 10.1109/TIP.2017.2785290
   Xu J, 2020, IEEE T IMAGE PROCESS, V29, P5022, DOI 10.1109/TIP.2020.2974060
   Yang KF, 2015, PROC CVPR IEEE, P2254, DOI 10.1109/CVPR.2015.7298838
   Yoo J-S, 2021, IEEE T IMAGE PROCESS
   Yoo JS, 2022, IEEE ACCESS, V10, P15528, DOI 10.1109/ACCESS.2022.3147252
   Yoo JS, 2019, PROC CVPR IEEE, P12321, DOI 10.1109/CVPR.2019.01261
   Zhang Qing, 2021, IEEE T PATTERN ANAL, P2
   Zhang XT, 2023, APPL MATH MODEL, V113, P206, DOI 10.1016/j.apm.2022.08.025
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao Q, 2012, IEEE T PATTERN ANAL, V34, P1437, DOI 10.1109/TPAMI.2012.77
   Zhou TH, 2015, IEEE I CONF COMP VIS, P3469, DOI 10.1109/ICCV.2015.396
   Zoran D, 2015, IEEE I CONF COMP VIS, P388, DOI 10.1109/ICCV.2015.52
NR 69
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14775
EP 14795
DI 10.1007/s11042-023-15758-3
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023992100004
DA 2024-07-18
ER

PT J
AU Das, HV
   Mohan, K
   Paul, L
   Kumaresan, S
   Nair, CS
AF Das, Haritha V.
   Mohan, Kavya
   Paul, Linta
   Kumaresan, Sneha
   Nair, Chitra S.
TI Transforming consulting atmosphere with Indian sign language translation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign language translation; Gesture Recognition; Indian Sign Language;
   Long Short Term Memory; Convolutional Neural Network
AB One of the major challenges faced by medical practitioners is to facilitate hassle free communication with speech impaired people. It is difficult for speech impaired people to communicate their illness to a physician as most physicians do not understand sign language. Sign languages are languages that use the visual-manual modality to convey meaning. Sign languages are expressed through manual articulations in combination with non-manual elements. Indian Sign Language (ISL) is the most widely used sign language by the deaf and hearing-impaired community in India. Hearing impaired people face challenges during consultation with doctors in communicating the symptoms effectively due to the inability of doctors to understand sign language. The situation becomes even worse when the consultation is through an online platform. The existing models recognise hand gestures from videos, compare the recognised hand spatial orientation with the annotated dataset, and identify the letters or words. The drawbacks of the existing systems are, they neither include the entire vocabulary in the dataset nor are they contextual based. Hence these models are not very effective in a real-life communication situation. The datasets available are limited to recognition of alphabets, digits, some words like greeting terms, bank transaction terms etc. There has been little or no work done related to recognition of medical symptoms from Indian Sign Language. The proposed model will recognise patients' hand gestures in the video captured and translate it to corresponding words. Short sentences will be framed from the words recognised, in order to ensure clear communication.
C1 [Das, Haritha V.; Mohan, Kavya; Paul, Linta; Kumaresan, Sneha] NSS Coll Engn, Comp Sci, Palakkad, Kerala, India.
   [Nair, Chitra S.] NSS Coll Engn, Dept Comp Sci, Palakkad, Kerala, India.
C3 NSS College of Engineering Palakkad; NSS College of Engineering Palakkad
RP Das, HV (corresponding author), NSS Coll Engn, Comp Sci, Palakkad, Kerala, India.
EM 18bcs004@nssce.ac.in; 18b239@nssce.ac.in; 18b234@nssce.ac.in;
   18b225@nssce.ac.in; chitranairis@gmail.com
CR Al-Hammadi M, 2020, IEEE ACCESS, V8, P79491, DOI 10.1109/ACCESS.2020.2990434
   Amritkar C, 2018, P 2018 4 INT C COMP, P1
   Basnin Nanziba, 2021, Proceedings of International Conference on Trends in Computational and Cognitive Engineering. Proceedings of TCCE 2020. Advances in Intelligent Systems and Computing (AISC 1309), P695, DOI 10.1007/978-981-33-4673-4_57
   Chandra MM, 2019, TENCON IEEE REGION, P1803, DOI [10.1109/tencon.2019.8929356, 10.1109/TENCON.2019.8929356]
   Dignan C, 2022, MULTIMED TOOLS APPL, V81, P34525, DOI 10.1007/s11042-021-11830-y
   Gangadia D, 2020, 2020 IEEE PUNE SECTION INTERNATIONAL CONFERENCE (PUNECON), P71, DOI 10.1109/PuneCon50868.2020.9362383
   Gangrade J, 2020, IETE J RES, P1
   Hatibarnah Diksha., 2020, 2020 IEEE 17 IND COU
   Kapuscinski T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082190
   Qu YB, 2020, IEEE INT CONF ELECTR, P323, DOI 10.1109/iceiec49280.2020.9152352
   Sharma S, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115657
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Shrenika S, 2020, 2020 INT C COMP SCI
   Wadhawan A, 2020, NEURAL COMPUT APPL, V32, P7957, DOI 10.1007/s00521-019-04691-y
   Yirtici T, 2022, SIGNAL IMAGE VIDEO P, V16, P1305, DOI 10.1007/s11760-021-02082-2
NR 15
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13543
EP 13555
DI 10.1007/s11042-023-15214-2
EA JUL 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023991000002
DA 2024-07-18
ER

PT J
AU Ghaffari, M
   Khan, GF
   Singh, SP
   Ferwerda, B
AF Ghaffari, Mona
   Khan, Gohar F.
   Singh, Shivendu Pratap
   Ferwerda, Bruce
TI The impact of COVID-19 on online music listening behaviors in light of
   listeners' social interactions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19 pandemic; mental health; music listening; online platform;
   social dynamics
ID SOCIOECONOMIC-FACTORS; PREFERENCES; GENDER; PERSONALITY; CONSUMPTION;
   EXPERIENCE; ADOPTION; GENRE; YOUTH; AGE
AB This study investigated the global changes in online music listening behaviors in response to COVID-19 and its restrictions (such as quarantine, school and workplace closures, and travel restrictions). In addition, the research included an examination of how friendship networks and online communication motives have moderated the effect of COVID-19 on music listening behaviors. The causal inference methods: difference in differences (DiD) and two-way fixed effects (TWFE), were conducted to analyze the online music listening behaviors and social interactions of 37,328 Last.fm users in 45 countries before and after the first wave of confinement. It was found that in response to COVID-19, the quantity, variety, and novelty of music consumption decreased, shifting toward mainstream artists, whereas individuals with more online social connections and communications showed the reverse behavior. Our research shows that online social interactions and community development significantly impact listeners' behaviors and can be used as a guide to developing new design strategies for digital media, such as music, movies, and games.
C1 [Ghaffari, Mona; Khan, Gohar F.] Univ Waikato, Digital Business, Hamilton, New Zealand.
   [Singh, Shivendu Pratap] Southern Illinois Univ Edwardsville, Edwardsville, IL USA.
   [Ferwerda, Bruce] Jonkoping Univ, Comp Sci & Informat, Jonkoping, Sweden.
C3 University of Waikato; Southern Illinois University System; Southern
   Illinois University Edwardsville; Jonkoping University
RP Ghaffari, M (corresponding author), Univ Waikato, Digital Business, Hamilton, New Zealand.
EM mg141@students.waikato.ac.nz; shising@siue.edu
RI Ferwerda, Bruce/B-8168-2017
OI singh, shivendu/0000-0001-9789-0801
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions
CR Aguiar L, 2017, INF ECON POLICY, V41, P1, DOI 10.1016/j.infoecopol.2017.06.002
   Aguiar L, 2018, INT J IND ORGAN, V57, P278, DOI 10.1016/j.ijindorg.2017.06.004
   Aiken L.S., 1991, MULTIPLE REGRESSION
   Allison P.D., 2009, FIXED EFFECTS REGRES
   Anderson A, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2155, DOI 10.1145/3366423.3380281
   Andrews GJ, 2011, HEALTH PLACE, V17, P185, DOI 10.1016/j.healthplace.2010.09.008
   Angrist J D., 2008, Mostly harmless econometrics: An empiricist's companion, DOI DOI 10.2307/J.CTVCM4J72
   [Anonymous], 2007, Psychol Music, DOI [DOI 10.1177/0305735607068888, 10.1177/0305735607068888]
   Arditi D, 2018, POP MUSIC SOC, V41, P302, DOI 10.1080/03007766.2016.1264101
   Asghar MZ, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph182111012
   Bailey D, 2011, J STAT SOFTW, V42, P1
   Baker AC, 2022, J FINANC ECON, V144, P370, DOI 10.1016/j.jfineco.2022.01.004
   Bauer C, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217389
   BECK N, 1995, AM POLIT SCI REV, V89, P634, DOI 10.2307/2082979
   Berkers P., 2012, INTERACTIONS STUDIES, V2, P279, DOI [10.1386/iscc.2.3.279_1, DOI 10.1386/ISCC.2.3.279_1]
   Bhattacharya P, 2019, INFORM SYST RES, V30, P117, DOI 10.1287/isre.2018.0790
   Boldi A, 2022, HUM-COMPUT INTERACT, DOI 10.1080/07370024.2022.2050725
   Bu F., 2020, The British Journal of Psychiatry, DOI [10.1101/2020.08.18.20177345, DOI 10.1192/BJP.2021.44]
   Cabedo-Mas A, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.606180
   Callaway B, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2203.15646
   Callaway B, 2020, GETTING STARTED DID
   Callaway B, 2023, J ECONOMETRICS, V233, P184, DOI 10.1016/j.jeconom.2022.02.001
   Callaway B, 2021, J ECONOMETRICS, V225, P200, DOI 10.1016/j.jeconom.2020.12.001
   Martín JC, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e06274
   Chamorro-Premuzic T, 2012, PSYCHOL MUSIC, V40, P285, DOI 10.1177/0305735610381591
   Chan-Olmsted S, 2020, MOB MEDIA COMMUN, V8, P209, DOI 10.1177/2050157919856647
   Christenson P.G., 1998, Journal of Communication, V49, P212, DOI DOI 10.1111/J.1460-2466.1999.TB02829.X
   CHRISTENSON PG, 1988, COMMUN RES, V15, P282, DOI 10.1177/009365088015003004
   Colley A, 2008, J APPL SOC PSYCHOL, V38, P2039, DOI 10.1111/j.1559-1816.2008.00379.x
   Datta H, 2018, MARKET SCI, V37, P5, DOI 10.1287/mksc.2017.1051
   Dewan S, 2017, INFORM SYST RES, V28, P117, DOI 10.1287/isre.2016.0654
   Dimont J, 2018, HASTINGS LAW J, V69, P675
   Elliott D, 2011, J MUSIC THER, V48, P264, DOI 10.1093/jmt/48.3.264
   Erikson EH, 1950, CHILDHOOD SOC
   Ferwerda B., 2016, P 2016 C US MOD AD P
   Ferwerda B, 2019, MULTIMED TOOLS APPL, V78, P20157, DOI 10.1007/s11042-019-7336-7
   Fink LK, 2021, HUM SOC SCI COMMUN, V8, DOI 10.1057/s41599-021-00858-y
   Frei-Landau R, 2020, PSYCHOL TRAUMA-US, V12, pS258, DOI 10.1037/tra0000822
   Furht B, 2010, HANDBOOK OF SOCIAL NETWORK TECHNOLOGIES AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-7142-5
   Gibbons J.L., 1997, CROSS-CULT RES, V31, P55, DOI [10.1177/106939719703100104, DOI 10.1177/106939719703100104, 10.1177/2F106939719703100104]
   Corona FG, 2020, ANSIEDAD ESTRES, V26, P46, DOI 10.1016/j.anyes.2020.02.001
   Granot R, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.648013
   Greb F, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00390
   Grigoriadou EfthaliaThaleia., Cities Health, V5, P2020, DOI DOI 10.1080/23748834.2020.1795405
   Groarke JM, 2016, PSYCHOL MUSIC, V44, P769, DOI 10.1177/0305735615591844
   Guren C, 2021, PUBLISH RES Q, V37, P1, DOI 10.1007/s12109-021-09791-z
   Hagen AN, 2017, CONVERGENCE-US, V23, P643, DOI 10.1177/1354856516673298
   Hagen AN, 2015, POP MUSIC SOC, V38, P625, DOI 10.1080/03007766.2015.1021174
   Hale T, 2021, NAT HUM BEHAV, V5, P529, DOI 10.1038/s41562-021-01079-8
   Hansen NC, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.684083
   HARGREAVES DJ, 1995, J RES MUSIC EDUC, V43, P242, DOI 10.2307/3345639
   HECKMAN JJ, 1989, J AM STAT ASSOC, V84, P862, DOI 10.2307/2290059
   Henry N, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.647879
   Hilvert-Bruce Z, 2018, COMPUT HUM BEHAV, V84, P58, DOI 10.1016/j.chb.2018.02.013
   Hofstede G., 2010, CULTURES ORG SOFTWAR
   Howlin C, 2022, MUSIC MED
   Huang N, 2017, MIS QUART, V41, P1035
   Imai K, 2019, AM J POLIT SCI, V63, P467, DOI 10.1111/ajps.12417
   Imber-Black E, 2020, FAM PROCESS, V59, P912, DOI 10.1111/famp.12581
   Jazi SY, 2021, MULTIMED TOOLS APPL, V80, P13559, DOI 10.1007/s11042-020-10386-7
   Karatay S., 2022, YENI Y ZY LDA LETI I, V1, P77
   Katarya R, 2018, MULTIMED TOOLS APPL, V77, P2673, DOI 10.1007/s11042-017-4447-x
   Katsma C, 2010, AMCIS 2010 PROCEEDINGS
   Khlystova O, 2022, J BUS RES, V139, P1192, DOI 10.1016/j.jbusres.2021.09.062
   Kiernan F, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.696202
   Kirk DS, 2016, P 2016 ACM C DES INT
   Knees P, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2542205.2542206
   Lanzoni L, 2020, THESIS LUISS GUIDO C
   Levstek M, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.703892
   Liu M., 2020, 21 INT SOC MUS INF R
   Livesey L, 2012, J PUBLIC MENT HEALTH, V11, P10, DOI 10.1108/17465721211207275
   Lonsdale AJ, 2011, BRIT J PSYCHOL, V102, P108, DOI 10.1348/000712610X506831
   Madison G, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00147
   Martínez-Castilla P, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.647837
   Mas-Herrero E.M., 2020, PSYARXIV, DOI [DOI 10.31234/OSF.IO/X5UPN, 10.31234/osf.io/x5upn]
   Mechant Peter, 2011, International Journal of Web Based Communities, V7, P234, DOI 10.1504/IJWBC.2011.039513
   Melchiorre AB, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102666
   Mora R, 2019, ECONOMET REV, V38, P465, DOI 10.1080/07474938.2017.1348683
   North AC, 2000, BRIT J EDUC PSYCHOL, V70, P255, DOI 10.1348/000709900158083
   Oestreicher-Singer G, 2009, ICIS 2009 P
   Onderdijk KE, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.647929
   Park H.M., 2011, Practical guides to panel data modeling: A step by step analysis using Stata. Public Management and Policy Analysis Program, P1
   Parkinson B, 1999, COGNITION EMOTION, V13, P277, DOI 10.1080/026999399379285
   Pinto MP, 2021, THESIS I U LISBOA PO
   Poudel K, 2020, INT J SOC PSYCHIATR, V66, P748, DOI 10.1177/0020764020942247
   Price PC., 2015, RES METHODS PSYCHOL
   Putzke J, 2014, COMPUT NETW, V75, P519, DOI 10.1016/j.comnet.2014.08.027
   Rahman MM, 2022, GLOBALIZATION HEALTH, V18, DOI 10.1186/s12992-022-00855-z
   Ramesh B., 2020, SBV J BASIC CLIN APP, V3, P128, DOI DOI 10.5005/JP-JOURNALS-10082-02266
   Rentfrow PJ, 2003, J PERS SOC PSYCHOL, V84, P1236, DOI 10.1037/0022-3514.84.6.1236
   Ripp J, 2020, ACAD MED, V95, P1136, DOI 10.1097/ACM.0000000000003414
   ROE K, 1985, COMMUN RES, V12, P353, DOI 10.1177/009365085012003007
   Salminen J., 2018, COLLABORATIVE VALUE, P41
   Schäfer T, 2009, PSYCHOL MUSIC, V37, P279, DOI 10.1177/0305735608097247
   Schedl M, 2014, P 1 INT WORKSH INT S, DOI [DOI 10.1145/2661714.2661717, 10.1145/2661714.2661717]
   Schedl M, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P75, DOI 10.1145/3184558.3186936
   Schedl M, 2018, INT J MULTIMED INF R, V7, P95, DOI 10.1007/s13735-018-0154-2
   Schedl M, 2017, INT J MULTIMED INF R, V6, P71, DOI 10.1007/s13735-017-0118-y
   Schedl M, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P947, DOI 10.1145/2766462.2767763
   Seetharaman P, 2020, INT J INFORM MANAGE, V54, DOI 10.1016/j.ijinfomgt.2020.102173
   Shmargad Y, 2016, J INTERACT MARK, V36, P1, DOI 10.1016/j.intmar.2016.01.004
   Sim J, 2022, MARKET SCI, V41, P19, DOI 10.1287/mksc.2021.1321
   Skowron M, 2017, LECT NOTES COMPUT SC, V10193, P561, DOI 10.1007/978-3-319-56608-5_49
   Stewart M, 2018, INT C SOC COMP SOC M
   Stock J. H., 2003, INTRO ECONOMETRICS, V104
   Street J., 2004, BRIT J POLIT INT REL, V6, P435, DOI [DOI 10.1111/J.1467-856X.2004.00149.X, 10.1111/j.1467-856X.2004.00149.x]
   Ter Bogt TFM, 2017, PSYCHOL MUSIC, V45, P155, DOI 10.1177/0305735616650029
   Ter Bogt TFM, 2011, PSYCHOL MUSIC, V39, P147, DOI 10.1177/0305735610370223
   Tuck AB, 2021, JMIR FORM RES, V5, DOI 10.2196/26513
   Ulleri P, 2021, 12 INT C COMPUTING, P6
   van Wel F, 2008, YOUNG, V16, P325, DOI 10.1177/110330880801600305
   Varshney M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0233874
   Wang CY, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17051729
   Wang S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10151769
   Wooldridge JM, 2005, REV ECON STAT, V87, P385, DOI 10.1162/0034653053970320
   Wooldridge JM, 2021, Two-Way Fixed Effects, the Two-Way Mundlak Regression, and Differencein-Differences Estimators, DOI [DOI 10.2139/SSRN.3906345, 10.2139/ssrn.3906345]
   Yang J, 2016, LECT NOTES COMPUT SC, V9747, P110, DOI 10.1007/978-3-319-40355-7_11
   Yeung TY-C, 2020, COVID EC, DOI [10.2139/ssrn.3678606, DOI 10.2139/SSRN.3678606]
   Zhang WR, 2020, PSYCHOTHER PSYCHOSOM, V89, P242, DOI 10.1159/000507639
   Ziv N, 2022, PSYCHOL MUSIC, V50, P475, DOI 10.1177/03057356211003326
NR 120
TC 0
Z9 0
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13197
EP 13239
DI 10.1007/s11042-023-16079-1
EA JUL 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023897700003
OA hybrid
DA 2024-07-18
ER

PT J
AU Neelima, M
   Prabha, IS
AF Neelima, Medikonda
   Prabha, I. Santi
TI Optimized deep network based spoof detection in automatic speaker
   verification system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker-verification-system; Spoof identification; Mel-frequency and
   spectrum features; Recognition accuracy; Recurrent networks
AB Speaker-verification-system (SVS) is automated nowadays to improve the authenticity score of digital applications. However, spoofs in the audio signal have reduced the integrity score of the audio signal, which has tended to cause less authentication exactness score. Considering this, spoof recognition objectives emerged in this field to find the different types of spoofs with high exactness scores. Attracting the widest spoof forecasting score is impossible due to harmful and different spoof features. So, the present study built a novel Dove-based Recurrent Spoof Recognition System (DbRSRS) to identify the spoofing behaviour and its types from the trained audio data. The noise features were filtered in the primary stage to mitigate the complexity of spoof recognition. Moreover, the noise features filtered data is taken to the classification phase for feature selection and spoof recognition. Here, the spoof types were classified based on the different class features. Once the Spoof is identified, it is specified under different spoof classes. Here, the optimal dove features are utilized to tune the DbRSRS classification parameters. This process helped to earn the finest spoof recognition score than the recently published associated model. Henceforth, the recorded highest spoof forecasting accuracy was 99.2%, and the reported less error value was 0.05%. Thus, attaining the highest spoof prediction exactness score with less error value might improve the SVS performance.
C1 [Neelima, Medikonda] Gayatri Vidya Parishad Coll Engn A, Dept Elect & Commun Engn, Visakhapatnam 530048, Andhra Pradesh, India.
   [Prabha, I. Santi] Jawaharlal Nehru Technol Univ, Univ Coll Engn, Dept Elect & Commun Engn, Kakinada 533003, Andhra Pradesh, India.
C3 Gayatri Vidya Parishad College of Engineering; Jawaharlal Nehru
   Technological University - Kakinada
RP Neelima, M (corresponding author), Gayatri Vidya Parishad Coll Engn A, Dept Elect & Commun Engn, Visakhapatnam 530048, Andhra Pradesh, India.
EM neelu214@gmail.com; santiprabha@yahoo.com
OI Neelima, Medikonda/0000-0002-9793-4373
CR Alhumoud SO, 2022, ARTIF INTELL REV, V55, P707, DOI 10.1007/s10462-021-09989-9
   Bharath KP, 2022, MULTIMED TOOLS APPL, V81, P39343, DOI 10.1007/s11042-022-12380-7
   Chettri B, 2020, COMPUT SPEECH LANG, V63, DOI 10.1016/j.csl.2020.101092
   Chugh T, 2021, IEEE T INF FOREN SEC, V16, P42, DOI 10.1109/TIFS.2020.2990789
   Dang YC, 2022, IEEE INTERNET THINGS, V9, P25068, DOI 10.1109/JIOT.2022.3195320
   Daniel N, 2021, COMPUT ELECTR ENG, V94, DOI 10.1016/j.compeleceng.2021.107293
   Dua M, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103517
   Dua M, 2022, J AMB INTEL HUM COMP, V13, P1985, DOI 10.1007/s12652-021-02960-0
   Hanilçi C, 2018, MULTIMED TOOLS APPL, V77, P16099, DOI 10.1007/s11042-017-5181-0
   Huszár VD, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21217339
   Iliev Y, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010116
   Kinnunen T, 2020, IEEE-ACM T AUDIO SPE, V28, P2195, DOI 10.1109/TASLP.2020.3009494
   Kwon KC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20040954
   Mingote V, 2023, DIGIT SIGNAL PROCESS, V133, DOI 10.1016/j.dsp.2022.103859
   Nainan S, 2021, INT J SPEECH TECHNOL, V24, P809, DOI 10.1007/s10772-020-09771-2
   Nassif AB, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107141
   Neelima Medikonda, 2020, 2020 International Conference on Smart Electronics and Communication (ICOSEC), P314, DOI 10.1109/ICOSEC49089.2020.9215407
   Neelima M., 2020, INT J RECENT TECHNOL, V8, P3676, DOI [10.35940/ijrte.E6582.018520, DOI 10.35940/IJRTE.E6582.018520]
   Qin Z, 2023, INFORM FUSION, V91, P694, DOI 10.1016/j.inffus.2022.10.032
   Rahmeni R, 2022, MULTIMED TOOLS APPL, V81, P31443, DOI 10.1007/s11042-022-12606-8
   Ross A, 2020, PATTERN RECOGN LETT, V138, P346, DOI 10.1016/j.patrec.2020.07.009
   Rostami AM, 2023, CIRC SYST SIGNAL PR, V42, P4252, DOI 10.1007/s00034-023-02314-5
   Rostami M, 2023, IEEE ACCESS, V11, P30247, DOI 10.1109/ACCESS.2023.3260652
   Sankar MSA, 2023, CIRC SYST SIGNAL PR, V42, P3437, DOI 10.1007/s00034-022-02277-z
   Saritha B, 2023, ADV SPEECH MUSIC TEC, P3, DOI [10.1007/978-3-031-18444-4_1, DOI 10.1007/978-3-031-18444-4_1]
   Schmidt E, 2020, IEEE T AERO ELEC SYS, V56, P4224, DOI 10.1109/TAES.2020.2990149
   Semanjski S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041171
   Sheikhpour R, 2023, KNOWL-BASED SYST, V269, DOI 10.1016/j.knosys.2023.110521
   Su MC, 2022, IEEE ACCESS, V10, P46690, DOI 10.1109/ACCESS.2022.3170112
   Sun WY, 2020, IEEE T INF FOREN SEC, V15, P3181, DOI 10.1109/TIFS.2020.2985530
   Wei XM, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14194925
   Yang JC, 2021, IEEE-ACM T AUDIO SPE, V29, P1065, DOI 10.1109/TASLP.2021.3060810
   Zhang HY, 2023, IEEE-ACM T AUDIO SPE, V31, P1024, DOI 10.1109/TASLP.2023.3244518
   Zhang Y, 2021, IEEE SIGNAL PROC LET, V28, P937, DOI 10.1109/LSP.2021.3076358
   Zhu YK, 2023, IEEE-ACM T AUDIO SPE, V31, P1000, DOI 10.1109/TASLP.2023.3244502
NR 35
TC 3
Z9 3
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13073
EP 13091
DI 10.1007/s11042-023-16127-w
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023700800007
DA 2024-07-18
ER

PT J
AU Ni, TG
   He, CB
   Gu, XQ
AF Ni, Tongguang
   He, Chengbing
   Gu, Xiaoqing
TI Semi-supervised classifier with projection graph embedding for motor
   imagery electroencephalogram recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE brain computer interface; electroencephalogram; motor imagery;
   projection graph embedding; semi-supervised learning
ID MANIFOLD REGULARIZATION; FRAMEWORK; LABEL
AB Brain computer interface (BCI) based on motor imagery (MI) provides a communication channel between the brain and a computer or other communication devices. In BCI system, electroencephalogram (EEG) is the most widely used brain signals, which has the function of responding to the physiological and emotional information of the brain. The recognition of MI EEG signals is the core technology of MI-BCI system. In this study, semi-supervised learning strategy is adopted in model training, and semi-supervised classifier with projection graph embedding (SCPGE) is proposed for MI EEG recognition. SCPGE combines graph embedding projection and sparse constraint into semi-supervised least squares model to learn the discriminative structure of EEG data in projection space, and adaptively learns the similarity matrix and pseudo-label matrix based on manifold learning. Unlike the "two-step" strategy of constructing graph embedding and classifier, these two factors, together with subspace projection and pseudo-label estimation, are simultaneously considered in the objection function and optimized in the iteration process. In addition, SCPGE uses the class by class based l(2, 1)-norm inter class sparsity constraint to exploit the correlation between samples, so as to obtain the discriminative projection matrix and classifier. Experiments on the publicly available MI EEG datasets show that SCPGE classifier can significantly improve the recognition accuracy.
C1 [Ni, Tongguang; He, Chengbing; Gu, Xiaoqing] Changzhou Univ, Sch Comp Sci & Artificial Intelligence, Changzhou 213164, Peoples R China.
C3 Changzhou University
RP Gu, XQ (corresponding author), Changzhou Univ, Sch Comp Sci & Artificial Intelligence, Changzhou 213164, Peoples R China.
EM guxq@cczu.edu.cn
FU Natural Science Foundation of Jiangsu Province [BK 20211333]
FX AcknowledgementsThis work was supported in part by the Natural Science
   Foundation of Jiangsu Province under Grant BK 20211333.
CR Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Blankertz B, 2006, IEEE T NEUR SYS REH, V14, P153, DOI 10.1109/TNSRE.2006.875642
   Brunner C, 2007, PATTERN RECOGN LETT, V28, P957, DOI 10.1016/j.patrec.2007.01.002
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3701, DOI 10.1109/TVCG.2021.3084694
   Chen XJ, 2020, IEEE T KNOWL DATA EN, V32, P165, DOI 10.1109/TKDE.2018.2879797
   Dornaika F, 2021, INFORM SCIENCES, V546, P146, DOI 10.1016/j.ins.2020.07.065
   Gu XQ, 2021, IEEE ACM T COMPUT BI, V18, P1679, DOI 10.1109/TCBB.2020.3006699
   Guan G, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P379, DOI 10.1109/ICInfA.2013.6720327
   Hang WL, 2023, BIOMED SIGNAL PROCES, V82, DOI 10.1016/j.bspc.2023.104579
   Higashi H, 2013, IEEE T BIO-MED ENG, V60, P1100, DOI 10.1109/TBME.2012.2215960
   Lei YX, 2019, IEEE ACCESS, V7, P30102, DOI 10.1109/ACCESS.2019.2900267
   Liu GY, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105299
   Liu Z., 2022, COMPUT BIOL MED, V2022
   Lu XH, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108844
   Luo F., 2021, IEEE T GEOSCI ELECT, V60, P5517916
   Moradi MH., 2022, ARTIFIC INTEL BASED, V2022, P237, DOI DOI 10.1016/B978-0-323-91197-9
   Ni TG, 2015, INFORM SCIENCES, V294, P390, DOI 10.1016/j.ins.2014.09.050
   Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726
   Peng Y, 2022, IEEE T NEUR SYS REH, V30, P1288, DOI 10.1109/TNSRE.2022.3175464
   Sadiq MT, 2019, IEEE ACCESS, V7, P127678, DOI 10.1109/ACCESS.2019.2939623
   Sanodiya RK, 2022, KNOWL-BASED SYST, V257, DOI 10.1016/j.knosys.2022.109886
   She QS, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8111273
   Tangermann M, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00055
   Taran S, 2019, NEURAL COMPUT APPL, V31, P6925, DOI 10.1007/s00521-018-3531-0
   van Engelen JE, 2020, MACH LEARN, V109, P373, DOI 10.1007/s10994-019-05855-6
   Zhang Z, 2015, IEEE T KNOWL DATA EN, V27, P2362, DOI 10.1109/TKDE.2013.182
   Zou YJ, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103576
NR 27
TC 1
Z9 1
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14189
EP 14209
DI 10.1007/s11042-023-16010-8
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023700800004
DA 2024-07-18
ER

PT J
AU Rao, YB
   Mu, TZ
   Zeng, SN
   Xue, JM
   Liu, JH
AF Rao, Yunbo
   Mu, Tongze
   Zeng, Shaoning
   Xue, Junming
   Liu, Jinhua
TI Multi-session aware hypergraph neural network for session-based
   recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-session aware; Soft attention; Hypergraph neural network;
   Session-based recommendation
AB Session-based user behavior prediction is a difficulty in network behavior modeling due to the limitation of information. In recent years, the neural network has become a new research direction in recommendation system, however, the existing graph structure recommended method simple binary relation of concern within the session, but in real life tend to have the multiple complex relationships between items. In addition, hyperedges lack displayed position information in hypergraphs, and items in different orders may construct the same hyperedges, which necessarily limits the ability to obtain exact vector representations of sessions. Therefore, to solve the above limitations, a multi-session aware hypergraph neural network (MA-HGNN) for session-based recommendation is proposed, which takes advantage of hypergraphs to model complex multivariate relationships in sessions, and alleviates the hyperedge isomorphism problem by preserving sequence information. At the same time, the co-occurrence graph structure and the local session graph structure are established to realize the connection between the similar user intentions in different sessions and the potential behavior patterns in the same session. Finally, experiments are carried out on three real-world datasets Diginetica, Tmall and Nowplaying, and the models proposed in our work are significantly improved, which proves the effectiveness of the method.
C1 [Rao, Yunbo; Mu, Tongze; Xue, Junming] Univ Elect Sci & Technol China, Sch Informat & Software Engn, 4,Sect 2,North jianshe Rd, Chengdu 610054, Sichuan, Peoples R China.
   [Zeng, Shaoning] Univ Elect Sci & Technol China, Yangtze Delta Reg Inst Huzhou, 819 Xisaishan Rd, Chengdu 313000, Zhejiang, Peoples R China.
   [Liu, Jinhua] Shangrao Normal Univ, Sch Math & Comp Sci, 401 Zhimin Ave, Shangrao 334001, Jiangxi, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China; Shangrao Normal University
RP Rao, YB (corresponding author), Univ Elect Sci & Technol China, Sch Informat & Software Engn, 4,Sect 2,North jianshe Rd, Chengdu 610054, Sichuan, Peoples R China.
EM raoyb@uestc.edu.cn; ismutongze@foxmail.com; zeng@csj.uestc.edu.cn;
   15611021139@wo.cn; 314103@sru.edu.cn
OI Rao, Yunbo/0000-0001-5433-7379
FU Science and Technology Project of Sichuan [2021YFG0314, 2022ZHCG0033,
   2023ZHCG0005, 2023ZHCG0008]; National Natural Science Foundation of
   China [U19A2078]; Zhejiang Provincial Natural Science Foundation of
   China [LY23F020025]; Science and Technology Commissioner Program of
   Huzhou [ST22003]
FX This research was supported by the Science and Technology Project of
   Sichuan (Grant NOs.2021YFG0314, 2022ZHCG0033, 2023ZHCG0005,
   2023ZHCG0008), the National Natural Science Foundation of China (Grant
   No: U19A2078), the Zhejiang Provincial Natural Science Foundation of
   China (Grant No. LY23F020025), and the Science and Technology
   Commissioner Program of Huzhou (Grant No. ST22003).
CR Aggarwal C. C., 2016, RECOMMENDER SYSTEMS, P139, DOI DOI 10.1007/978-3-319-29659-3
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Cai DS, 2022, IEEE T MULTIMEDIA, V24, P805, DOI 10.1109/TMM.2021.3059508
   Cao LB, 2015, INFORM PROCESS MANAG, V51, P167, DOI 10.1016/j.ipm.2014.08.007
   Chen JY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P335, DOI 10.1145/3077136.3080797
   Chen TW, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1172, DOI 10.1145/3394486.3403170
   Ebesu T, 2018, ACM/SIGIR PROCEEDINGS 2018, P515, DOI 10.1145/3209978.3209991
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   He XN, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P549, DOI 10.1145/2911451.2911489
   Hidasi B, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P843, DOI 10.1145/3269206.3271761
   Kang WC, 2018, IEEE DATA MINING, P197, DOI 10.1109/ICDM.2018.00035
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Li J, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1419, DOI 10.1145/3132847.3132926
   Liu Q, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1831, DOI 10.1145/3219819.3219950
   Pan ZQ, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1195, DOI 10.1145/3340531.3412014
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   Qiu RH, 2020, ACM T INFORM SYST, V38, DOI 10.1145/3382764
   Qiu RH, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P579, DOI 10.1145/3357384.3358010
   Rendle S., 2010, P 19 INT C WORLD WID, P811, DOI DOI 10.1145/1772690.1772773
   Schafer B.J., 2006, RES J APPL SCI ENG T, V5, P4168, DOI 10.19026/rjaset.5.4644
   Schafer J. B., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P291
   Sun F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1441, DOI 10.1145/3357384.3357895
   Tan Y. K., 2016, Proceedings of the 1st workshop on deep learning for recommender systems, P17
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1235, DOI 10.1145/2783258.2783273
   Wang SJ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3771
   Wang SJ, 2020, IEEE INTELL SYST, V35, P3, DOI 10.1109/MIS.2020.3026430
   Wang X, 2018, EXPLAINABLE REASONIN
   Wang X, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P950, DOI 10.1145/3292500.3330989
   Wang X, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1543, DOI 10.1145/3178876.3186066
   Wang ZY, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P169, DOI 10.1145/3397271.3401142
   Wu M, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1457, DOI 10.1145/3366423.3380219
   Wu M, 2019, IEEE DATA MINING, P648, DOI 10.1109/ICDM.2019.00075
   Wu S, 2019, AAAI CONF ARTIF INTE, P346
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xia X, 2021, AAAI CONF ARTIF INTE, V35, P4503
   Xiang W, 2017, ACM SIGIR FORUM
   Xin X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P125, DOI 10.1145/3331184.3331188
   Xu CF, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3940
   Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890
   Yu F., 2020, arXiv
   Yu JL, 2022, IEEE T KNOWL DATA EN, V34, P3727, DOI 10.1109/TKDE.2020.3033673
NR 43
TC 0
Z9 0
U1 9
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12757
EP 12774
DI 10.1007/s11042-023-15894-w
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001022083300006
DA 2024-07-18
ER

PT J
AU Seo, HW
   Kim, SH
   Ryu, SG
   Jo, SK
   Cho, SP
   Sohn, JS
   Lim, CE
AF Seo, Hyun-Woo
   Kim, Soo-Hyeok
   Ryu, Sang-Gi
   Jo, Seung-Kyu
   Cho, Su-Phil
   Sohn, Jong-Soo
   Lim, Chi-Ehyeon
TI Development of an offline OOH advertising recommendation system using
   negative sampling and deep interest network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Out-of-home (OOH) advertising; Recommendation system; Deep interest
   network; Negative sampling
AB The out-of-home (OOH) advertising market has been operated exclusively following the know-how of salespeople. Thus, it is difficult to make scientific decisions and systematically provide various options to advertisers. In this regard, this study develops an OOH advertising recommendation system by analyzing past OOH history data. The OOH advertising allocation problem has the characteristics that the training data are implicit feedback, and only one advertisement can be posted per offline billboard. This study proposes a recommendation system suitable for OOH history data using negative sampling and Deep Interest Network. The proposed recommendation system showed a higher performance than excisting models used for comparison purposes, and the findings of this study present implications for solving similar recommendation problems.
C1 [Seo, Hyun-Woo; Kim, Soo-Hyeok; Lim, Chi-Ehyeon] UNIST, Dept Ind Engn, Ulsan, South Korea.
   [Ryu, Sang-Gi; Jo, Seung-Kyu; Cho, Su-Phil; Sohn, Jong-Soo] CJ Corp, CJ AI Ctr, Seoul, South Korea.
C3 Ulsan National Institute of Science & Technology (UNIST)
RP Sohn, JS (corresponding author), CJ Corp, CJ AI Ctr, Seoul, South Korea.
EM jongsoo.sohn@cj.net
CR Berahmand K, 2022, J KING SAUD UNIV-COM, V34, P5375, DOI 10.1016/j.jksuci.2021.05.006
   Ding JT, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2230
   Forouzandeh S, 2022, FUZZY INF ENG, V14, P26, DOI 10.1080/16168658.2021.2019430
   Forouzandeh S, 2021, INT J INF TECH DECIS, V20, P399, DOI 10.1142/S0219622020500522
   Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261
   Guo H., 2017, arXiv
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   He XN, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P549, DOI 10.1145/2911451.2911489
   Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22
   Kim Namki, 2016, Journal of Information Technology Applications & Management, V23, P55, DOI 10.21219/jitam.2016.23.4.055
   Kim NK, 2017, P 19 JOINT BUS ADM C, P600
   Liu Y, 2018, BIG DATA MIN ANAL, V1, P211, DOI 10.26599/BDMA.2018.9020019
   Ministry of Culture Sports and Tourism, 2020, 2019 AD IND SURV
   Pan R, 2008, IEEE DATA MINING, P502, DOI 10.1109/ICDM.2008.16
   Wang X, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P99, DOI 10.1145/3366423.3380098
   Xu ZH, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1921, DOI 10.1145/2983323.2983874
   Yih W.-T., 2009, Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2 - Volume 2, EMNLP '09, V2, P793
   최영환, 2006, [Journal of Korean Institute of Intelligent Systems, 한국지능시스템학회 논문지], V16, P185
   Zhang WN, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P785
   Zhou GR, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1059, DOI 10.1145/3219819.3219823
NR 20
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11943
EP 11955
DI 10.1007/s11042-023-16083-5
EA JUN 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016450400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Singh, VK
   Mishra, S
AF Singh, Vikash Kumar
   Mishra, Sanket
TI A truthful mechanism for time-bound tasks in IoT-based crowdsourcing
   with zero budget
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowdsourcing; Scheduling; Truthful; IoT devices; Zero budget
AB Crowdsourcing is a process of engaging a 'crowd' or a group of common people for accomplishing the tasks. In this work, the time-bound tasks allocation problem in IoT-based crowdsourcing is investigated in strategic setting. The proposed model consists of multiple task providers (or task requesters) and several IoT devices (or task executors), and each of the task providers carries a task that have start time and completion time. Each of the participating IoT devices provide a preference ordering (order of their interest for the tasks) over a subset of tasks. Given the time bound tasks and ranking (or preference ordering) of the task executors, the objectives are: (1) to assign the tasks to different slots so that they are non-conflicting in nature, and (2) to allocate at most one task to each of the task executors from their respective preference ordering. To achieve the above objectives, a truthful mechanism is proposed namely Truthful Mechanism for Time-bound Tasks in IoT-based Crowdsourcing (TMTTC). Through theoretical analysis, it is proved that TMTTC satisfies the properties such as computational efficiency, truthfulness, Pareto optimality, and The Core. Through simulation, it is shown that TMTTC performs better than benchmark mechanism on the ground of truthfulness.
C1 [Singh, Vikash Kumar; Mishra, Sanket] Vellore Inst Technol, Sch Comp Sci & Engn, Amaravati, Andhra Pradesh, India.
C3 VIT-AP University
RP Singh, VK (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Amaravati, Andhra Pradesh, India.
EM vikash.singh@vitap.ac.in; sanket.mishra@vitap.ac.in
OI Singh, Vikash Kumar/0000-0002-8747-1627
CR Ahmed ST, 2023, IEEE INTERNET THINGS, V10, P18461, DOI [10.1109/JIOT.2023.3243784, 10.1007/978-981-99-6706-3_1]
   Bhatti SS, 2020, J SYST SOFTWARE, V167, DOI 10.1016/j.jss.2020.110611
   Daniel F, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3148148
   Duan ZJ, 2017, IEEE ACCESS, V5, P20383, DOI 10.1109/ACCESS.2017.2751304
   Feng ZN, 2014, IEEE INFOCOM SER, P1231, DOI 10.1109/INFOCOM.2014.6848055
   GALE D, 1962, AM MATH MON, V69, P9, DOI 10.2307/2312726
   Gao L, 2015, IEEE INFOCOM SER
   Goel G., 2014, HCOMP
   Gong XW, 2018, PROCEEDINGS OF THE 2018 THE NINETEENTH INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING (MOBIHOC '18), P161, DOI 10.1145/3209582.3209599
   Hu Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103453
   Klaus B., 2016, HDB COMPUTATIONAL SO, P333, DOI DOI 10.1017/CBO9781107446984.015
   Kleinberg Jon, 2005, ALGORITHM DESIGN
   Kobayashi Masaki., 2018, P AAAI C HUMAN COMPU, P79
   Kong XJ, 2019, IEEE INTERNET THINGS, V6, P8095, DOI 10.1109/JIOT.2019.2921879
   Li JY, 2019, MULTIMED TOOLS APPL, V78, P33357, DOI 10.1007/s11042-019-08054-6
   Li Y, 2020, J COMPUT INFORM SYST, V60, P113, DOI [10.1080/08874417.2017.1405294, 10.1080/13632469.2017.1387202, 10.1007/s12652-017-0529-x]
   Luo T, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2837029
   Mazlan N, 2018, J AMB INTEL HUM COMP, V9, P743, DOI 10.1007/s12652-017-0490-8
   Mukhopadhyay J, 2022, J AMB INTEL HUM COMP, V13, P1107, DOI 10.1007/s12652-020-02844-9
   Munro R, 2013, INFORM RETRIEVAL, V16, P210, DOI 10.1007/s10791-012-9203-2
   Phuttharak J, 2019, IEEE ACCESS, V7, P304, DOI 10.1109/ACCESS.2018.2885353
   Qiu CX, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P1486
   Roughgarden T., 2016, CS269I: Incentives in computer science lecture# 15: The VCG mechanism
   Roughgarden T., 2016, LECT 3 STRATEGIC VOT
   Roughgarden T., 2013, CS364A ALGORITHMIC G, V9
   Roy S, 2021, J AMB INTEL HUM COMP, V12, P2103, DOI 10.1007/s12652-020-02309-z
   Schummer J, 2007, ALGORITHMIC GAME THEORY, P243
   Shapley L., 1974, J MATH ECON, V1, P23, DOI DOI 10.1016/0304-4068(74)90033-0
   Singer Y, 2010, ANN IEEE SYMP FOUND, P765, DOI 10.1109/FOCS.2010.78
   Singh V.K., 2020, ADV EDGE COMPUTING M, V35, P148
   Singh VK, 2020, J AMB INTEL HUM COMP, V11, P1531, DOI 10.1007/s12652-019-01219-z
   Slivkins A, 2013, ACM SIGECOM EXCH, V12, P4
   Venkatraman S, 2020, MULTIMED TOOLS APPL, V79, P3993, DOI 10.1007/s11042-019-7495-6
   Wang XM, 2020, IEEE T VEH TECHNOL, V69, P5570, DOI 10.1109/TVT.2020.2982243
   Wen YT, 2015, IEEE T VEH TECHNOL, V64, P4203, DOI 10.1109/TVT.2014.2363842
   Wikipedia, 2018, About us
   Xu P, 2017, AAMAS'17: PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P1763
   Xu XL, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.4961
   Yu RY, 2019, ACM T SENSOR NETWORK, V15, DOI 10.1145/3303703
   Zhang Lefeng, 2019, CONCURR COMP-PRACT E, V31, P5100
NR 40
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9873
EP 9892
DI 10.1007/s11042-023-16015-3
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900013
DA 2024-07-18
ER

PT J
AU Iqbal, N
   Khan, MA
   Lee, SW
AF Iqbal, Nadeem
   Khan, Muhammad Adnan
   Lee, Sang-Woong
TI Multi-image cipher based on the random walk of Knight in a virtual 3D
   chessboard
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Decryption; Encryption; Image processing; Knight; Multi-image cipher;
   Virtual 3D chessboard
ID IMAGE ENCRYPTION; PERMUTATION-DIFFUSION; CHAOTIC SYSTEMS; TOUR; MAP
AB This study proposes a novel, efficient and a secured multiple color images encryption scheme based on the random walk of knight in a virtual 3D chessboard, chaotic system and SHA256 hashing. First of all, a perfect square number of color images are input. These images are decomposed into their red, green and blue components. These components are stacked together to get a 3D image. Three intensity values from this 3D image are randomly chosen. These values serve as the starting address for the knight to start its scrambling project. This act increases both the key space and plaintext sensitivity. Next, this 3D image is converted into 1D image for the scrambling process. Knight - a chess piece, has been commissioned to walk randomly in the 3D chessboard in all the three coordinate planes for an arbitrary number of times. The movement of knight in the 3D chessboard has been linked with the transferring of pixels from the 1D image to the scrambled 3D image. In this way, the input images are abundantly scrambled. Lastly, an XOR operation has been carried out to throw the diffusion effects. The three chaotic vectors given by the intertwining logistic map have been used in the selection of planes, mode of movement of knight and the diffusion process. SHA-256 hash codes for the given input color images have been used for the plaintext sensitivity. Security analyses and the computer experiments suggest the desirable security effects and prospects for some real world application of the proposed cipher. Information entropy obtained by the proposed algorithm is 7.9999.
C1 [Iqbal, Nadeem; Khan, Muhammad Adnan] Univ Lahore, Dept Comp Sci & IT, Lahore 54590, Pakistan.
   [Khan, Muhammad Adnan; Lee, Sang-Woong] Gachon Univ, Dept Software, Pattern Recognit & Machine Learning Lab, Seongnam 13557, South Korea.
C3 University of Lahore; Gachon University
RP Iqbal, N (corresponding author), Univ Lahore, Dept Comp Sci & IT, Lahore 54590, Pakistan.
EM nadeem.iqbal537@gmail.com
RI Khan, Muhammad Adnan/GLU-1911-2022; Khan, Muhammad Adnan/ACJ-2841-2022
OI Khan, Muhammad Adnan/0000-0003-4854-9935; Khan, Muhammad
   Adnan/0000-0003-4854-9935; Iqbal, Nadeem/0000-0002-0954-5563
CR Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Murillo-Escobar MA, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080815
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Aqeel-ur-Rehman, 2016, MULTIMED TOOLS APPL, V75, P11241, DOI 10.1007/s11042-015-2851-7
   Bashir Z, 2021, MULTIMED TOOLS APPL, V80, P1029, DOI 10.1007/s11042-020-09695-8
   Berahmand Kamal, 2021, J KING SAUD UNIV-COM
   Boreale M, 2020, SCI COMPUT PROGRAM, V193, DOI 10.1016/j.scico.2020.102441
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Diaconu AV, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/932875
   Diaconu AV, 2013, MATH PROBL ENG
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Floating-Point Working Group IEEE computer society, 1985, 7541985 IEEE COMP SO
   Forouzandeh S, 2021, ENG APPL ARTIF INTEL, V104, DOI 10.1016/j.engappai.2021.104325
   Fu YG, 2014, SENSORS-BASEL, V14, P1988, DOI 10.3390/s140201988
   Gaurav A, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.285593
   Nguyen GN, 2021, J PARALLEL DISTR COM, V153, P150, DOI 10.1016/j.jpdc.2021.03.011
   Hammad M, 2022, MULTIMEDIA SYST, V28, P1373, DOI 10.1007/s00530-020-00728-8
   Hanif M, 2020, IEEE ACCESS, V8, P146408, DOI 10.1109/ACCESS.2020.3015085
   Hanif M, 2020, IEEE ACCESS, V8, P123536, DOI 10.1109/ACCESS.2020.3004536
   Hua ZY, 2019, IEEE ACCESS, V7, P8660, DOI 10.1109/ACCESS.2018.2890116
   Iqbal N., 2021, IEEE ACCESS DNA ENCO
   Iqbal N, 2021, MULTIMED TOOLS APPL, P1
   Iqbal N, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102809
   Iqbal N, 2020, IEEE ACCESS, V8, P178167, DOI 10.1109/ACCESS.2020.3025241
   Iqbal N, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.2.023025
   Iqbal N, 2019, IEEE ACCESS, V7, P174051, DOI 10.1109/ACCESS.2019.2956389
   Ji XY, 2017, MULTIMED TOOLS APPL, V76, P12965, DOI 10.1007/s11042-016-3684-8
   Kaur M, 2021, IEEE T GREEN COMMUN, V5, P1223, DOI 10.1109/TGCN.2021.3081616
   Khan FA, 2017, J INTELL FUZZY SYST, V33, P3753, DOI 10.3233/JIFS-17656
   Kong DZ, 2013, APPL OPTICS, V52, P2619, DOI 10.1364/AO.52.002619
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Kumar J, 2018, ADV INTELL SYST, V563, P233, DOI 10.1007/978-981-10-6872-0_22
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li YB, 2015, OPT LASER ENG, V72, P18, DOI 10.1016/j.optlaseng.2015.03.027
   Malik MGA, 2020, IEEE ACCESS, V8, P88093, DOI 10.1109/ACCESS.2020.2990170
   Mani N, 2021, INT J SOFTW SCI COMP, V13, P72, DOI 10.4018/IJSSCI.2021010105
   Mirsadeghi F, 2021, PEER PEER NETW APPL, V14, P2537, DOI 10.1007/s12083-020-01010-4
   Nasiri E, 2021, CHAOS SOLITON FRACT, V151, DOI 10.1016/j.chaos.2021.111230
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Singh M, 2015, PROCEDIA COMPUT SCI, V70, P245, DOI 10.1016/j.procs.2015.10.081
   Sivakumar T, 2016, J INF SCI ENG, V32, P133
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Wang HX, 2020, PATTERN RECOGN LETT, V130, P64, DOI 10.1016/j.patrec.2018.08.010
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xiong Z, 2019, MULTIMED TOOLS APPL, P1
   Xu M, 2019, INFORM SCIENCES, V478, P1, DOI 10.1016/j.ins.2018.11.010
   Zarebnia M, 2019, OPTIK, V179, P761, DOI 10.1016/j.ijleo.2018.10.025
   Zhang XQ, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10110660
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang XQ, 2017, OPT LASER ENG, V92, P6, DOI 10.1016/j.optlaseng.2016.12.005
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 55
TC 0
Z9 0
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8629
EP 8661
DI 10.1007/s11042-023-15701-6
EA JUN 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001014975000011
DA 2024-07-18
ER

PT J
AU Hariprasad, S
   Deepa, T
AF Hariprasad, S.
   Deepa, T.
TI An Ensemble Intrusion Detection System based on Acute Feature Selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IoT Security; Acute feature selection; Shallow learning; KNN; Flooding
   attacks
ID MQTT; INTERNET
AB As the Internet of Things (IoT), 5G, and Artificial intelligence (AI) continue to converge, the number of security incidents and occurrences on the networks has recently increased. Since more devices are connected to IoT networks, security is becoming a major concern. Conventional intrusion detection systems (IDS) are not well suited for use in the complex lightweight IoT environment. This research paper presented an IDS for the smart city environment based on IoT- Message queuing telemetry transport (MQTT) networks that could detect attacks using shallow learning algorithms. The proposed framework has four parts (i) a smart city network model with multiple MQTT clients (sensors and IoT devices) is created with the help of hardware. (ii) Injected a flooding attack on the MQTT broker to create the IDS dataset with normal and attack features, (iii) Based on the acute feature selection algorithm to select the optmized features from the raw dataset and validated with the Jaccard coefficient. (iv) The dataset is further trained and validated using shallow learning algorithms such as extreme gradient boosting (XGB), K-nearest Neighbors (KNN) and Random forest (RF). Experimental results outperform with better attack detection rate, attack prediction rate and improved accuracy over 97% with lower redundancy using selected features. Experimental results show that the proposed approach is more vulnerable to attacks in the IoT network.
C1 [Hariprasad, S.; Deepa, T.] SRM Inst Sci & Technol, Dept Elect & Commun Engn, Chennai 603203, Tamilnadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Deepa, T (corresponding author), SRM Inst Sci & Technol, Dept Elect & Commun Engn, Chennai 603203, Tamilnadu, India.
EM hs6512@srmist.edu.in; deepat@srmist.edu.in
RI Deepa, Thangavel/P-8977-2016
OI Deepa, Thangavel/0000-0003-4398-3679
CR Akhtar S, 2021, WIRELESS PERS COMMUN, V119, P1589, DOI 10.1007/s11277-021-08296-4
   Al-Hawawreh M, 2022, IEEE INTERNET THINGS, V9, P3962, DOI 10.1109/JIOT.2021.3102056
   Conti M, 2018, FUTURE GENER COMP SY, V78, P544, DOI 10.1016/j.future.2017.07.060
   Dinculeana D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9050848
   Gupta V, 2021, MULTIMED TOOLS APPL, V80, P2931, DOI 10.1007/s11042-020-09750-4
   Haripriya AP, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1402-8
   Herrero R, 2020, MULTIMEDIA SYST, V26, P643, DOI 10.1007/s00530-020-00674-5
   Hintaw AJ, 2023, IETE J RES, V69, P3368, DOI 10.1080/03772063.2021.1912651
   Hwang HC, 2016, WIRELESS PERS COMMUN, V91, P1765, DOI 10.1007/s11277-016-3398-2
   Jin J, 2014, IEEE INTERNET THINGS, V1, P112, DOI 10.1109/JIOT.2013.2296516
   Kawaguchi R, 2020, 2020 34TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2020), P232, DOI [10.1109/ICOIN48656.2020.9016528, 10.1109/icoin48656.2020.9016528]
   Khan R, 2012, 10TH INTERNATIONAL CONFERENCE ON FRONTIERS OF INFORMATION TECHNOLOGY (FIT 2012), P257, DOI 10.1109/FIT.2012.53
   Kim G, 2019, IEEE INTERNET THINGS, V6, P8519, DOI 10.1109/JIOT.2019.2919971
   Kondoro A, 2021, FUTURE GENER COMP SY, V116, P1, DOI 10.1016/j.future.2020.09.031
   Kotak J, 2019, COMP ANAL SECURITY M
   Larriva-Novo X, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103430
   Layeghy S, 2022, ARXIV
   Mishra B, 2020, IEEE ACCESS, V8, P201071, DOI 10.1109/ACCESS.2020.3035849
   MQTT, 2021, MQTT STAND IOT MESS
   Muthukrishnan R, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER APPLICATIONS (ICACA), P18, DOI 10.1109/ICACA.2016.7887916
   Nawandar NK, 2019, COMPUT ELECTRON AGR, V162, P979, DOI 10.1016/j.compag.2019.05.027
   Park CS, 2020, IEEE ACCESS, V8
   Ping Du, 2007, 2007 2nd Bio-Inspired Models of Network, Information and Computing Systems (BIONETICS), P93, DOI 10.1109/BIMNICS.2007.4610090
   Rathore MM, 2016, COMPUT NETW, V101, P63, DOI 10.1016/j.comnet.2015.12.023
   Sarker IH, 2021, INTERNET THINGS-NETH, V14, DOI 10.1016/j.iot.2021.100393
   Seoane V, 2021, COMPUT NETW, V197, DOI 10.1016/j.comnet.2021.108338
   Syed NF, 2020, J INFORM TELECOMMUN, V4, P482, DOI 10.1080/24751839.2020.1767484
   Vaccari I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226578
   Vaccari I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102932
   Veeramanikandan M, 2019, J PARALLEL DISTR COM, V127, P18, DOI 10.1016/j.jpdc.2019.01.004
   Wang Z, 2019, IEEE ACCESS, V7, P129678, DOI 10.1109/ACCESS.2019.2940061
   Whitmore A, 2015, INFORM SYST FRONT, V17, P261, DOI 10.1007/s10796-014-9489-2
   Xin Y, 2018, IEEE ACCESS, V6, P35365, DOI 10.1109/ACCESS.2018.2836950
   Zanella A, 2014, IEEE INTERNET THINGS, V1, P22, DOI 10.1109/JIOT.2014.2306328
   Zutshi V, 2022, D DOS ATTACK PREDICT
NR 35
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8267
EP 8280
DI 10.1007/s11042-023-15788-x
EA JUN 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012326000010
DA 2024-07-18
ER

PT J
AU Wang, Y
   Dong, MG
   Ye, W
   Liu, D
   Gan, GJ
AF Wang, Yan
   Dong, Minggang
   Ye, Wei
   Liu, Deao
   Gan, Guojun
TI A contrastive learning-based iterative network for remote sensing image
   super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super resolution; Remote sensing imagery; Contrastive learning;
   Iterative network
ID BACK-PROJECTION NETWORKS; QUALITY ASSESSMENT; INFORMATION; FUSION
AB Many deep convolutional neural network(CNN)-based methods have achieved significant success in noise-free image super-resolution(SR) tasks. However, these methods produce unsatisfactory results for noisy remote sensing imagery. Recently, some practical SR models have been proposed to eliminate the negative impact of noise during reconstruction process, but they still have the problem of insufficient or excessive denoising. To address this issue, this article proposes a contrastive learning-based iterative network(CLIN) for noisy remote sensing image SR. Specifically, CLIN adopts an iterative cooperation approach, which includes an evaluator and a reconstructor. First, the evaluator evaluates the noise levels of low resolution(LR) images. Then the reconstructor utilizes LR images and their noise levels to reconstruct the SR images, which are returned to the evaluator for noise evaluation again. Furthermore, in order to make the reconstructor retain more spatial details, we design a global feature fusion block in the reconstructor to fuse the local features and the global features. To further suppress the noise, we propose a novel contrastive penalty strategy to train our model away from the noise domain. Compared with state-of-the-art SR methods, the peak signal to noise ratio (PSNR) improvements of our approach are about 0.04-0.78 dB on RSSCN7 dataset with a scale factor of 2. Qualitative and quantitative experiments on several noisy satellite image datasets demonstrate that the proposed CLIN achieves promising performance under different noise levels.
C1 [Wang, Yan; Dong, Minggang; Ye, Wei; Liu, Deao; Gan, Guojun] Guilin Univ Technol, Sch informat Sci & Engn, Guilin 541004, Peoples R China.
   [Wang, Yan; Dong, Minggang; Ye, Wei; Liu, Deao; Gan, Guojun] Guangxi Key Lab Embedded Technol & Intelligent Sys, Guilin 541004, Peoples R China.
C3 Guilin University of Technology
RP Dong, MG (corresponding author), Guilin Univ Technol, Sch informat Sci & Engn, Guilin 541004, Peoples R China.; Dong, MG (corresponding author), Guangxi Key Lab Embedded Technol & Intelligent Sys, Guilin 541004, Peoples R China.
EM d2015mg@qq.com
OI dong, minggang/0000-0001-7078-3942
FU National Natural Science Foundation of China [61563012]; Guangxi Natural
   Science Foundation of China [2021GXNSFAA220074]; Guangxi Key Laboratory
   of Embedded Tech-nology and Intelligent System Foundation
FX AcknowledgementsThis work is supported by the National Natural Science
   Foundation of China (No. 61563012), the Guangxi Natural Science
   Foundation of China (No.2021GXNSFAA220074), and the Guangxi Key
   Laboratory of Embedded Tech-nology and Intelligent System Foundation
   (No.2020-1-3).
CR Ahmed U, 2022, IEEE T FUZZY SYST
   Ahmed U, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3506701
   Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Aly HA, 2005, IEEE T IMAGE PROCESS, V14, P1647, DOI 10.1109/TIP.2005.851684
   Chaitanya K., 2020, Advances in Neural Information Processing Systems, V33, P12546, DOI DOI 10.48550/ARXIV.2006.10511
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P2350, DOI 10.1109/TIP.2021.3052069
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P4296, DOI 10.1109/TIP.2020.2968250
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   DONG R, 2021, IEEE T GEOSCI ELECT, V60, P1, DOI DOI 10.1109/TGRS.2020.3046045
   Fu B, 2022, MULTIMED TOOLS APPL, V81, P34281, DOI 10.1007/s11042-021-11085-7
   Gu JJ, 2019, PROC CVPR IEEE, P1604, DOI 10.1109/CVPR.2019.00170
   Guo DG, 2021, NEUROCOMPUTING, V443, P117, DOI 10.1016/j.neucom.2021.02.026
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   Henaff O. J., 2020, P INT C MACH LEARN, V119, P4182
   Hu SY, 2020, MULTIMED TOOLS APPL, V79, P1427, DOI 10.1007/s11042-019-08241-5
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Ji XZ, 2020, IEEE COMPUT SOC CONF, P1914, DOI 10.1109/CVPRW50498.2020.00241
   Jiang K, 2019, IEEE T GEOSCI REMOTE, V57, P5799, DOI 10.1109/TGRS.2019.2902431
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Lai W-S, 2017, PROC CVPR IEEE, P624, DOI DOI 10.1109/CVPR.2017.618
   Lei S, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3069889
   Liu ZB, 2022, MULTIMED TOOLS APPL, V81, P6827, DOI 10.1007/s11042-021-11724-z
   Lugmayr A, 2019, IEEE INT CONF COMP V, P3408, DOI 10.1109/ICCVW.2019.00423
   Mei YQ, 2021, PROC CVPR IEEE, P3516, DOI 10.1109/CVPR46437.2021.00352
   Shao ZF, 2018, IEEE J-STARS, V11, P1656, DOI 10.1109/JSTARS.2018.2805923
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sun XF, 2022, MULTISENS RES, V35, P391, DOI 10.1163/22134808-bja10075
   Tian C., 2022, arXiv
   Wang LG, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4781, DOI 10.1109/ICCV48922.2021.00476
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang XT, 2021, IEEE INT CONF COMP V, P1905, DOI 10.1109/ICCVW54120.2021.00217
   Wang XH, 2021, IEEE T IMAGE PROCESS, V30, P458, DOI 10.1109/TIP.2020.3037470
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2020, NEUROCOMPUTING, V398, P328, DOI 10.1016/j.neucom.2019.03.106
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xia GS, 2010, INT ARCH PHOTOGRAMM, V38, P298
   Xiao AR, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041194
   Yu YL, 2020, IEEE T GEOSCI REMOTE, V58, P5503, DOI 10.1109/TGRS.2020.2966669
   Yuan Y, 2018, IEEE COMPUT SOC CONF, P814, DOI 10.1109/CVPRW.2018.00113
   Zhang K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4771, DOI 10.1109/ICCV48922.2021.00475
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang S, 2020, IEEE T GEOSCI REMOTE, V58, P4764, DOI 10.1109/TGRS.2020.2966805
   Zhang Y., 2019, arXiv
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zou Q, 2015, IEEE GEOSCI REMOTE S, V12, P2321, DOI 10.1109/LGRS.2015.2475299
NR 56
TC 1
Z9 1
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8331
EP 8357
DI 10.1007/s11042-023-15551-2
EA JUN 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012326000004
DA 2024-07-18
ER

PT J
AU Cotogni, M
   Cusano, C
AF Cotogni, Marco
   Cusano, Claudio
TI Explaining image enhancement black-box methods through a path planning
   based algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Explainable AI; Image enhancement; Heuristic search; Path planning
AB Nowadays, image-to-image translation methods, are the state of the art for the enhancement of natural images. Even if they usually show high performance in terms of accuracy, they often suffer from several limitations such as the generation of artifacts and the scalability to high resolutions. Moreover, their main drawback is the completely black-box approach that does not allow to provide the final user with any insight about the enhancement processes applied. In this paper we present a path planning algorithm which provides a step-by-step explanation of the output produced by state of the art enhancement methods. This algorithm, called eXIE, uses a variant of A(*) to emulate the enhancement process of another method through the application of an equivalent sequence of enhancing operators. We applied eXIE to explain the output of several state-of-the-art models trained on the Five-K dataset, obtaining sequences of enhancing operators able to produce very similar results in terms of performance and overcoming the huge limitation of poor interpretability of the best performing algorithms.
C1 [Cotogni, Marco; Cusano, Claudio] Univ Pavia, Dept Elect Comp & Biomed Engn, Via Ferrata 1, I-27100 Pavia, Italy.
C3 University of Pavia
RP Cotogni, M (corresponding author), Univ Pavia, Dept Elect Comp & Biomed Engn, Via Ferrata 1, I-27100 Pavia, Italy.
EM marco.cotogni01@universitadipavia.it; claudio.cusano@unipv.it
RI Cusano, Claudio/AAH-1115-2019; Cotogni, Marco/JXN-1103-2024
OI Cusano, Claudio/0000-0001-9365-8167; Cotogni, Marco/0000-0001-7950-7370
FU Universita degli Studi di Pavia
FX Open access funding provided by Universita degli Studi di Pavia within
   the CRUI-CARE Agreement.
CR Nguyen A, 2016, ADV NEUR IN, V29
   Bianco S, 2020, IEEE T IMAGE PROCESS, V29, P6223, DOI 10.1109/TIP.2020.2989584
   Bianco S, 2019, LECT NOTES COMPUT SC, V11418, P209, DOI 10.1007/978-3-030-13940-7_16
   Bychkovsky V, 2011, PROC CVPR IEEE, P97
   Cai Y, 2019, IEEE IMTC P, P1445, DOI 10.1109/i2mtc.2019.8827110
   Cotogni M, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109249
   Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592
   Goodman T, 2012, INT STAND COLOUR, P417
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Keles O, 2021, PICT COD SYMP, P286, DOI 10.1109/PCS50896.2021.9477470
   Kim Bomi, 2022, P IEEE CVF WINT C AP, P1455
   Kim H., 2021, P IEEE CVF INT C COM, P4459
   Li YL, 2020, IEEE T COMPUT IMAG, V6, P666, DOI 10.1109/TCI.2020.2964202
   Liu MY, 2017, ADV NEUR IN, V30
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   Lundberg SM, 2017, ADV NEUR IN, V30
   Park J, 2018, PROC CVPR IEEE, P5928, DOI 10.1109/CVPR.2018.00621
   Ribeiro MT, 2018, AAAI CONF ARTIF INTE, P1527
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shrikumar A, 2017, PR MACH LEARN RES, V70
   Song Y, 2021, P IEEE CVF INT C COM, P4126
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Yuanming Hu, 2018, ACM Transactions on Graphics, V37, DOI 10.1145/3181974
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang ZY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4086, DOI 10.1109/ICCV48922.2021.00407
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zintgraf L.M., 2017, 5 INT C LEARNING REP
NR 32
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8043
EP 8062
DI 10.1007/s11042-023-15648-8
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001009907400008
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Kaur, P
   Harnal, S
   Gautam, V
   Singh, MP
   Singh, SP
AF Kaur, Prabhjot
   Harnal, Shilpi
   Gautam, Vinay
   Singh, Mukund Pratap
   Singh, Santar Pal
TI Hybrid deep learning model for multi biotic lesions detection in solanum
   lycopersicum leaves
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN; Instance segmentation; Semantic segmentation; U-Net; Seg-Net; Leaf
   diseases; Classification
AB Farmers are concerned about the automatic detection of lesions and pests that threaten tomato plants. Traditional computer vision and pattern recognition technologies have limits when it comes to tackling such difficult problems. However, deep learning had gained popularity in recent years, particularly for the detection and recognition of biotic stress in diseased leaf photos of plants with varying lighting conditions, complicated backdrops, and background noise. In this paper, a system was provided that uses several "Convolutional Neural Networks (CNN)" for the automatic recognition and identification of multi-biotic tomato leaf lesions collected from PlantVillage. For instance segmentation, a "Mask R-CNN" network is used in the first phase; for semantic segmentation a Hybrid Deep Segmentation Convolutional Neural Network Model (Hybrid-DSCNN) model is compared with U-Net and Seg-Net in the second phase, and a CNN model is used for classification in the third stage. The two backbone feature extractors were employed in the Mask R-CNN network, and the ResNet50 displays average precision of 73.00% in the instance segmentation test, which is superior to other models. For the segmentation and classification tasks, the Hybrid-DSCNN 2Layer-Convo-USN has achieved an accuracy of 98.25% which is better than the pre-trained models. The precision of the proposed Hybrid-DSCNN 2Layer-Convo-USN is 95.7% and of U-Net is 94.9%. The results are positive, indicating that the entire system may be implemented in any platform that can be used in the real world.
C1 [Kaur, Prabhjot; Harnal, Shilpi; Gautam, Vinay] Chitkara Univ, Inst Engn & Technol, Punjab, India.
   [Singh, Mukund Pratap] Bennett Univ, Sch Comp Sci Engn & Technol, Greater Noida, India.
   [Singh, Santar Pal] Rashtrakavi Ramdhari Singh Dinkar Coll Engn, Dept Comp Sci & Engn, Begusarai, India.
C3 Chitkara University, Punjab
RP Singh, SP (corresponding author), Rashtrakavi Ramdhari Singh Dinkar Coll Engn, Dept Comp Sci & Engn, Begusarai, India.
EM spsingh78@gmail.com
RI Gautam, Vinay/ABF-6124-2020; Harnal, Shilpi/JVM-8172-2024; Kaur,
   Prabhjot/JXN-0073-2024; Singh, Mukund Pratap/GRX-7429-2022
OI Gautam, Vinay/0000-0002-0258-5132; Singh, Mukund
   Pratap/0000-0001-5877-9510; Kaur, Prabhjot/0000-0002-3539-0622
CR Barbedo JGA, 2018, COMPUT ELECTRON AGR, V153, P46, DOI 10.1016/j.compag.2018.08.013
   Barbedo JGA, 2016, BIOSYST ENG, V144, P52, DOI 10.1016/j.biosystemseng.2016.01.017
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bej Gopinath, 2021, Proceedings of International Conference on Computational Intelligence, Data Science and Cloud Computing. IEM-ICDC 2020. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 62), P471, DOI 10.1007/978-981-33-4968-1_37
   Bendjillali RI, 2019, P 9 INT C INFORM SYS, P1
   Boulent J, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00941
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Dutta A, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2276, DOI 10.1145/3343031.3350535
   Esgario JGM, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2019.105162
   Fernández CI, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12081292
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   He K., 2017, arXiv
   Hernández S, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106597
   Hughes D., 2015, ABS151108060 CORR
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Johannes A, 2017, COMPUT ELECTRON AGR, V138, P200, DOI 10.1016/j.compag.2017.04.013
   Kaur Prabhjot, 2021, Proceedings of 3rd International Conference on Computing Informatics and Networks. ICCIN 2020. Lecture Notes in Networks and Systems (LNNS 167), P597, DOI 10.1007/978-981-15-9712-1_51
   Kaur P, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020575
   Kaur P, 2021, MATER TODAY-PROC, V45, P4377, DOI 10.1016/j.matpr.2020.11.198
   Kiptoo GJ, 2019, MORPHOLOGICAL TRAITS
   Kukreja Vinay, 2022, 2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE), P1372, DOI 10.1109/ICACITE53722.2022.9823459
   Li KZ, 2020, INFORMATION, V11, DOI 10.3390/info11020095
   Li ZB, 2020, COMPUT ELECTRON AGR, V176, DOI 10.1016/j.compag.2020.105672
   Lu J, 2017, COMPUT ELECTRON AGR, V142, P369, DOI 10.1016/j.compag.2017.09.012
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Manso G.L., 2019, ARXIV
   MEYER F, 1994, SIGNAL PROCESS, V38, P113, DOI 10.1016/0165-1684(94)90060-4
   Minervini M, 2016, PATTERN RECOGN LETT, V81, P80, DOI 10.1016/j.patrec.2015.10.013
   Muni A, 2022, INTELL AUTOM SOFT CO, V31, P1157, DOI 10.32604/iasc.2022.020174
   Morris DD, 2018, ARXIV
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Santos TT, 2020, COMPUT ELECTRON AGR, V170, DOI 10.1016/j.compag.2020.105247
   Sharma Parul, 2020, Information Processing in Agriculture, V7, P566, DOI 10.1016/j.inpa.2019.11.001
   Tavakoli H, 2021, COMPUT ELECTRON AGR, V181, DOI 10.1016/j.compag.2020.105935
   Turkoglu M, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01591-w
   Uguz S, 2021, NEURAL COMPUT APPL, V33, P4133, DOI 10.1007/s00521-020-05235-5
   Wang CS, 2021, COMPUT ELECTRON AGR, V189, DOI 10.1016/j.compag.2021.106373
   Xu LL, 2018, JOINT INT CONF SOFT, P180, DOI 10.1109/SCIS-ISIS.2018.00038
   Zhang SW, 2023, COMPUT ELECTRON AGR, V204, DOI 10.1016/j.compag.2022.107511
NR 41
TC 2
Z9 2
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7847
EP 7871
DI 10.1007/s11042-023-15940-7
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001004891100002
DA 2024-07-18
ER

PT J
AU Wang, WL
   Tu, HY
   Chen, JC
   Wu, F
AF Wang, Wanliang
   Tu, Hangyao
   Chen, Jiacheng
   Wu, Fei
TI TCGAN: Three-Channel Generate Adversarial Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative Adversarial Network; Image Translation; Generative Model;
   Deep Learning
ID IMAGE; CYCLEGAN
AB Recently Image-to-image translation has achieve much progress in the literature. However, in exist method, border distortion, color distortion and others are the serious issues which continue to be resolved. Existing methods do not produce satisfactory results because the most exist methods are mainly used multi-channels which increase the difficulty of finding the gradient in optimizer. To address this problem, we proposed the Three-Channel Generative Adversarial Network. The algorithm decomposed color image into three color channels of RGB and utilized the single channel generators and dual discriminators in each color channel for adversarial training. The detailed discriminator adopted reversed PatchGAN which we proposed to be responsible for the image texture discrimination, and the structure discriminator adopted seven-layer convolutional structure to be responsible for the image structure discrimination. Then to improve the accuracy of translation, the loss function that associated to the network model has also been revised. In experiments, the ablation study were provided to prove the effectiveness of the algorithm on Cityscapes and Facades datasets. Our extensive experiments on a variety of datasets, including Style transfer, Image labeling transfer and End-to-end image dehazing, which consistently demonstrate clear improvement over the pix2pix method both qualitatively and quantitatively.
C1 [Wang, Wanliang; Tu, Hangyao; Chen, Jiacheng; Wu, Fei] ZheJiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310015, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology
RP Wang, WL (corresponding author), ZheJiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310015, Zhejiang, Peoples R China.
EM zjutwwl@zjut.edu.cn
FU National Natural Science Foundation of China [61873240]
FX AcknowledgementsThis work is supported by National Natural Science
   Foundation of China (No. 61873240). The data used to support the
   findings of this study are available from the corresponding author upon
   request.
CR Chai CL, 2018, MULTIMED TOOLS APPL, V77, P22339, DOI 10.1007/s11042-018-5968-7
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Dou H, 2020, NEUROCOMPUTING, V415, P114, DOI 10.1016/j.neucom.2020.07.044
   Feng SH, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3114101
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Goodfellow Ian, 2014, P ADV NEUR INF PROC, DOI 10.48550/arXiv.1406.2661
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   [贾颖霞 Jia Yingxia], 2020, [计算机研究与发展, Journal of Computer Research and Development], V57, P876
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kaiming H, 2015, ARXIV
   Kamal U, 2020, IEEE T INTELL TRANSP, V21, P1467, DOI 10.1109/TITS.2019.2911727
   Kim T, 2017, PR MACH LEARN RES, V70
   Kumar A, 2021, APPL INTELL, V51, P1152, DOI 10.1007/s10489-020-01894-y
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li GQ, 2021, INFORM SCIENCES, V577, P510, DOI 10.1016/j.ins.2021.07.011
   Liu RJ, 2020, MULTIMED TOOLS APPL, V79, P14375, DOI 10.1007/s11042-018-6761-3
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Mori M, 2020, JPN J RADIOL, V38, P1075, DOI 10.1007/s11604-020-01012-5
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosales R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P472
   Sheng Q, 2021, PAC RIM INT C ART IN, P127
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Taigman Y, 2016, ARXIV
   Tu hang-yao, 2022, Journal of Zhejiang University (Engineering Science), V56, P225, DOI 10.3785/j.issn.1008-973X.2022.02.002
   Wang CY, 2018, IEEE T IMAGE PROCESS, V27, P4066, DOI 10.1109/TIP.2018.2836316
   Wang GQ, 2021, INT J COMPUT VISION, V129, P1650, DOI 10.1007/s11263-020-01425-9
   Wang JX, 2021, MULTIMED TOOLS APPL, V80, P29299, DOI 10.1007/s11042-021-11081-x
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu WJ, 2019, PATTERN RECOGN, V93, P570, DOI 10.1016/j.patcog.2019.05.017
   Xuan X, 2019, 2019 IEEE C COMP VIS
   Yang XW, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P374, DOI 10.1145/3240508.3240716
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yuan YJ, 2020, MULTIMED TOOLS APPL, V79, P16573, DOI 10.1007/s11042-019-7729-7
   Zhao JM, 2019, ENG APPL ARTIF INTEL, V82, P263, DOI 10.1016/j.engappai.2019.04.003
   Zhao Y, 2020, MULTIMED TOOLS APPL, V79, P14981, DOI 10.1007/s11042-019-08346-x
   Zhu JY, 2017, ADV NEUR IN, V30
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 44
TC 0
Z9 0
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7873
EP 7894
DI 10.1007/s11042-023-15672-8
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001004891100001
DA 2024-07-18
ER

PT J
AU Lv, GR
   Dong, LL
   Zhang, WW
   Xu, WH
AF Lv, Guangrui
   Dong, Lili
   Zhang, Wenwen
   Xu, Wenhai
TI A global-local feature adaptive fusion network for image scene
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene classification; Multiple deep dependencies; Spatial contextual
   attention; Semantic aggregation; Feature adaptive fusion
ID CONVOLUTIONAL NEURAL-NETWORK; ATTENTION; GRADIENT
AB Convolutional neural networks (CNN) have been widely used in image scene classification and have achieved remarkable progress. However, because the extracted deep features can neither focus on the local semantics of the image, nor capture the spatial morphological variation of the image, it is not appropriate to directly use CNN to generate the distinguishable feature representations. To relieve this limitation, a global-local feature adaptive fusion (GLFAF) network is proposed. The GLFAF framework extracts multi-scale and multi-level features by using a designed CNN. Then, to leverage the complementary advantages of the multi-scale and multi-level features, we design a global feature aggregate module to discover global attention features and further learn the multiple deep dependencies of spatial scale variations among these global features. Meanwhile, a local feature aggregate module is designed to aggregate the multi-scale and multi-level features. Specially, multi-level features at the same scale are fused based on channel attention, and then spatial fused features at different scales are aggregated based on channel dependence. Moreover, spatial contextual attention is designed to refine spatial features across scales and different fisher vector layers are designed to learn semantic aggregation among spatial features. Subsequently, two different feature adaptive fusion modules are introduced to explore the complementary associations of global and local aggregate features, which can obtain comprehensive and differentiated image scene presentation. Finally, a large number of experiments on real scene datasets coming from three different fields show that the proposed GLFAF approach can more accurately realize scene classification than other state-of-the-art models.
C1 [Lv, Guangrui; Dong, Lili; Zhang, Wenwen; Xu, Wenhai] Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian 116026, Peoples R China.
C3 Dalian Maritime University
RP Dong, LL (corresponding author), Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian 116026, Peoples R China.
EM donglili@dlmu.edu.cn
RI Zhang, Wenwen/AAI-9384-2021
OI Zhang, Wenwen/0000-0002-3183-0344
FU Fundamental Research Funds for the Central Universities of China
   [3132019340, 3132019200]; high tech ship research project from ministry
   of industry and information technology of the people's republic of China
   [MC-201902-C01]
FX This paper was supported in part by the Fundamental Research Funds for
   the Central Universities of China under Grant 3132019340 and 3132019200.
   This paper was supported in part by high tech ship research project from
   ministry of industry and information technology of the people's republic
   of China under Grant MC-201902-C01.
CR Anwer RM, 2018, ISPRS J PHOTOGRAMM, V138, P74, DOI 10.1016/j.isprsjprs.2018.01.023
   Basiri ME, 2021, FUTURE GENER COMP SY, V115, P279, DOI 10.1016/j.future.2020.08.005
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bi Q, 2020, IEEE GEOSCI REMOTE S, V17, P1603, DOI 10.1109/LGRS.2019.2949930
   Bi Q, 2020, IEEE T IMAGE PROCESS, V29, P4911, DOI 10.1109/TIP.2020.2975718
   Bi Q, 2019, IEEE IMAGE PROC, P2501, DOI [10.1109/ICIP.2019.8803322, 10.1109/icip.2019.8803322]
   Bi Q, 2020, NEUROCOMPUTING, V377, P345, DOI 10.1016/j.neucom.2019.11.068
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chen Y., 2015, Convolutional neural network for sentence classificationD
   Cheng G, 2021, IEEE GEOSCI REMOTE S, V18, P431, DOI 10.1109/LGRS.2020.2975541
   Cheng G, 2016, INT GEOSCI REMOTE SE, P767, DOI 10.1109/IGARSS.2016.7729193
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Dong LL, 2020, J INFRARED MILLIM W, V39, P650, DOI 10.11972/j.issn.1001-9014.2020.05.016
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Huang H, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11141687
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   JIANG Y, 2012, RANDOMIZED SPATIAL P, P730
   Li LJ, 2007, IEEE I CONF COMP VIS, P345
   Li Q, 2018, COMPUT SCI ENG, V20, P52, DOI 10.1109/MCSE.2018.108164530
   Li QN, 2013, PROC CVPR IEEE, P851, DOI 10.1109/CVPR.2013.115
   Lin D, 2014, PROC CVPR IEEE, P3726, DOI 10.1109/CVPR.2014.476
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XQ, 2019, IEEE T GEOSCI REMOTE, V57, P7894, DOI 10.1109/TGRS.2019.2917161
   Lv YF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11243006
   Ma JJ, 2020, INT GEOSCI REMOTE SE, P537, DOI 10.1109/IGARSS39084.2020.9323281
   Ni K, 2021, IEEE J-STARS, V14, P7284, DOI 10.1109/JSTARS.2021.3096941
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Qi K, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13040569
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sadeghi F, 2012, LECT NOTES COMPUT SC, V7576, P228, DOI 10.1007/978-3-642-33715-4_17
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Shen JG, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030433
   Sheng GF, 2012, INT J REMOTE SENS, V33, P2395, DOI 10.1080/01431161.2011.608740
   Shi CP, 2020, IEEE J-STARS, V13, P5194, DOI 10.1109/JSTARS.2020.3018307
   Shrinivasa SR, 2022, MULTIMED TOOLS APPL, V81, P1237, DOI 10.1007/s11042-021-11354-5
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sitaula C, 2021, KNOWL-BASED SYST, V232, DOI 10.1016/j.knosys.2021.107470
   Sitaula C, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207106
   Sitaula C, 2019, LECT NOTES COMPUT SC, V11955, P90, DOI 10.1007/978-3-030-36718-3_8
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sun H, 2020, IEEE J BIOMED HEALTH, V24, P1664, DOI 10.1109/JBHI.2019.2944977
   Sun N, 2019, IEEE T CIRC SYST VID, V29, P1715, DOI 10.1109/TCSVT.2018.2848543
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang DZ, 2019, NEUROCOMPUTING, V329, P103, DOI 10.1016/j.neucom.2018.09.042
   Wang GL, 2017, IEEE J-STARS, V10, P4104, DOI 10.1109/JSTARS.2017.2705419
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wang X, 2021, IEEE T GEOSCI REMOTE, V59, P7918, DOI 10.1109/TGRS.2020.3044655
   Wang Y, 2016, ARXIV
   Wang Y, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3447530
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Wu F, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107632
   Wu F, 2020, IEEE T CYBERNETICS, V50, P1009, DOI 10.1109/TCYB.2018.2876591
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xia SF, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8101072
   Xiong ZT, 2020, NEUROCOMPUTING, V373, P81, DOI 10.1016/j.neucom.2019.09.066
   Xu K., 2021, IEEE GEOSCI REMOTE S
   Xu KJ, 2020, INFORM SCIENCES, V539, P250, DOI 10.1016/j.ins.2020.06.011
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI [10.1145/1869790.1869829, DOI 10.1145/1869790.1869829]
   Yujian F, 2021, IEEE SIGNAL PROC LET, V28, P1425, DOI 10.1109/LSP.2021.3093865
   Zeng D, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050734
   Zhang CY, 2022, ACM T INFORM SYST, V40, DOI 10.1145/3466641
   Zhang CJ, 2017, INFORM SCIENCES, V376, P125, DOI 10.1016/j.ins.2016.10.019
   Zhang F, 2016, IEEE T GEOSCI REMOTE, V54, P1793, DOI 10.1109/TGRS.2015.2488681
   Zhang JM, 2021, IEEE INT CONF COMP V, P1760, DOI 10.1109/ICCVW54120.2021.00202
   Zhang W, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11050494
   Zheng Y., 2012, LEARNING HYBRID PART, P172
   Zhou B, 2016, ARXIV
   Zhu QQ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10040568
NR 78
TC 0
Z9 0
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6521
EP 6554
DI 10.1007/s11042-023-15519-2
EA JUN 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001006598900005
DA 2024-07-18
ER

PT J
AU Maheswari, B
   Reeja, SR
AF Maheswari, B.
   Reeja, S. R.
TI Thermal infrared image semantic segmentation for night-time driving
   scenes based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thermal infrared images; Semantic segmentation; Top-down guided
   attention module; Attention loss; Organized gradient alignment loss;
   Semantic encoding ambiguity
ID ATTENTION NETWORK; FUSION; RGB
AB Semantic segmentation of thermal infrared (ThIR) images is challenging because the images considered in this task are highly complex. The discrimination of image regions is very difficult, and the traditional techniques fail to discover the crucial semantic information from the images completely. To overcome such issue, this paper introduces a novel network model for ThIR image semantic segmentation that facilitates effective image-to-image translation and reduces semantic encoding ambiguity. The proposed model is named top-down attention and gradient alignment-based graph neural network (AGAGNN). A top-down guided attention module (GAM) is utilized in the proposed model to deal with semantic encoding ambiguity. Apart from this, an elaborate attention loss is introduced to ensure a hierarchical coding of features. Also, the edge distortion problem due to the translation of images is reduced with an organized gradient alignment loss. The proposed model is evaluated under the Python platform based on pixel-level annotations over the KAIST dataset. The proposed model has shown 98.3% accuracy, and the comparative analysis has proved that the model is more effective than the existing models in preserving semantic information.
C1 [Maheswari, B.; Reeja, S. R.] VIT AP Univ, Sch Comp Sci & Engn, Amaravati 522237, Andhra Prades, India.
C3 VIT-AP University
RP Maheswari, B (corresponding author), VIT AP Univ, Sch Comp Sci & Engn, Amaravati 522237, Andhra Prades, India.
EM maheswari.21phd7152@vitap.ac.in
RI Bandi, Maheswari/JXM-7990-2024; Bandi, Maheswari/JJG-1785-2023; S R,
   Reeja/AFP-1349-2022
OI S R, Reeja/0000-0002-9198-3617
CR Abbadi NKE., 2020, INDONESIAN J ELECT E, V18, P1501, DOI [DOI 10.11591/IJEECS.V18.I3.PP1501-1509, 10.11591/ijeecs.v18.i3.pp1501-1509]
   Anoosheh A, 2019, IEEE INT CONF ROBOT, P5958, DOI [10.1109/ICRA.2019.8794387, 10.1109/icra.2019.8794387]
   Asano H, 2022, BMC MED IMAGING, V22, DOI 10.1186/s12880-021-00730-0
   Balit E., 2020, IN P 16 EUROPEAN C C, P1
   Cao YP, 2019, INFORM FUSION, V46, P206, DOI 10.1016/j.inffus.2018.06.005
   Choi KC, 2021, THERMAL IMAGE SEMANT
   Deng FQ, 2021, IEEE INT C INT ROBOT, P4467, DOI 10.1109/IROS51168.2021.9636084
   Feng D, 2021, IEEE T INTELL TRANSP, V22, P1341, DOI 10.1109/TITS.2020.2972974
   He DH, 2022, EXPERT SYST APPL, V193, DOI 10.1016/j.eswa.2021.116425
   He YZ, 2021, INFRARED PHYS TECHN, V116, DOI 10.1016/j.infrared.2021.103754
   Hou JL, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23030376
   Huang XW, 2018, PROCEEDINGS OF 2018 IEEE INTERNATIONAL CONFERENCE ON INTEGRATED CIRCUITS, TECHNOLOGIES AND APPLICATIONS (ICTA 2018), P172, DOI 10.1109/CICTA.2018.8706048
   John V., 2021, J AUTOVEHICLES SYST, V1, P1, DOI DOI 10.1115/1.4052529
   Kang, 2019, ARXIV
   Khalid Bushra, 2020, Image and Signal Processing. 9th International Conference, ICISP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12119), P138, DOI 10.1007/978-3-030-51935-3_15
   Kniaz VV, 2019, INT ARCH PHOTOGRAMME
   Kuang XD, 2020, INFRARED PHYS TECHN, V107, DOI 10.1016/j.infrared.2020.103338
   Lee HY, 2020, INT J COMPUT VISION, V128, P2402, DOI 10.1007/s11263-019-01284-z
   Li CL, 2021, IEEE T NEUR NET LEAR, V32, P3069, DOI 10.1109/TNNLS.2020.3009373
   Li GF, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106617
   Li YQ, 2021, VISAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 4: VISAPP, P321, DOI 10.5220/0010248503210328
   Liu MY, 2017, ADV NEURAL INFORM PR, P30
   Lu YW, 2021, IEEE WINT CONF APPL, P3832, DOI 10.1109/WACV48630.2021.00388
   Luo F, 2022, IEEE T INTELL TRANSP, P1
   Luo FY, 2021, LECT NOTES COMPUT SC, V12890, P388, DOI 10.1007/978-3-030-87361-5_32
   Lyu Y, 2020, ELECTRON LETT, V56, P920, DOI 10.1049/el.2020.1635
   Masouleh MK, 2019, ISPRS J PHOTOGRAMM, V155, P172, DOI 10.1016/j.isprsjprs.2019.07.009
   Mo YJ, 2022, NEUROCOMPUTING, V493, P626, DOI 10.1016/j.neucom.2022.01.005
   Müller D, 2021, J NONDESTRUCT EVAL, V40, DOI 10.1007/s10921-020-00740-y
   Munir F, 2022, LECT NOTES COMPUT SC, V13188, P366, DOI 10.1007/978-3-031-02375-0_27
   Panetta K, 2021, IEEE ACCESS, V9, P145212, DOI 10.1109/ACCESS.2021.3123066
   Pemasiri A, 2021, COMPUT VIS IMAGE UND, V202, DOI 10.1016/j.cviu.2020.103085
   Pozzer S, 2021, J PERFORM CONSTR FAC, V35, DOI 10.1061/(ASCE)CF.1943-5509.0001541
   Rahman AK., 2021, INT J IMAGE GRAPH, V13, P40, DOI [10.5815/ijigsp.2021.01.04, DOI 10.5815/IJIGSP.2021.01.04]
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P158
   Salau AO, 2021, J KING SAUD UNIV-COM, V33, P399, DOI 10.1016/j.jksuci.2019.01.011
   Shojaiee F, 2023, ENG APPL ARTIF INTEL, V117, DOI 10.1016/j.engappai.2022.105627
   Shopovska I, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173727
   Song S, 2022, P I MECH ENG D-J AUT, V236, P424, DOI 10.1177/09544070211016254
   Speth S, 2022, J FIELD ROBOT, V39, P840, DOI 10.1002/rob.22082
   Sun L., 2019, ARTIF INTELL MACH LE, V111
   Sun YX, 2021, IEEE T AUTOM SCI ENG, V18, P1000, DOI 10.1109/TASE.2020.2993143
   Sun YX, 2019, IEEE ROBOT AUTOM LET, V4, P2576, DOI 10.1109/LRA.2019.2904733
   Wang P, 2019, IEEE T IMAGE PROCESS, V28, P6007, DOI 10.1109/TIP.2019.2924171
   Xiong HT, 2021, INFRARED PHYS TECHN, V113, DOI 10.1016/j.infrared.2020.103628
   Xu JT, 2021, PATTERN RECOGN LETT, V146, P179, DOI 10.1016/j.patrec.2021.03.015
   Xuan P, 2022, KNOWL-BASED SYST, V236, DOI 10.1016/j.knosys.2021.107360
   Yadav R, 2020, IRISH MACHINE VISION
   Yi S, 2022, NEUROCOMPUTING, V482, P236, DOI 10.1016/j.neucom.2021.11.056
   Zhang L, 2019, INFORM FUSION, V50, P20, DOI 10.1016/j.inffus.2018.09.015
   Zhang Q, 2021, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR46437.2021.00266
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Ziqiang Zheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P155, DOI 10.1007/978-3-030-58580-8_10
NR 53
TC 2
Z9 2
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 44885
EP 44910
DI 10.1007/s11042-023-15882-0
EA JUN 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:001006598900002
DA 2024-07-18
ER

PT J
AU Chen, CL
   Li, Z
AF Chen, Cuiling
   Li, Zhi
TI Multiple kernel clustering with structure-preserving and block diagonal
   property
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple kernel clustering; Block diagonal representation; Structure
   preserving
ID LOW-RANK REPRESENTATION; ROBUST
AB It is well known that graph-based multiple kernel clustering (GMKC) methods improve the clustering performance by integrating multiple kernel learning and graph-based clustering. However, existing GMKC methods either do not consider the global and local structure of data in kernel space simultaneously, or ignore block diagonal property of the affinity matrix, thus impairing the final clustering performance greatly. To address this issue, in this paper we propose a novel method named multiple kernel clustering with structure-preserving and block diagonal property (SBDMKC) by combining GMKC and block diagonal regularizer. Typically, the local structure-preserving regularization term is an accurate measurement for the similarity between data in kernel space, rather than original space. Furthermore, the affinity matrix is encouraged to be block diagonal by a soft regularizer, which helps to achieve good data clustering. In addition, a simple kernel weight strategy is given, which can automatically weight each base kernel to find an optimal consensus kernel. Experimental results on the ten benchmark data sets show that our method outperforms the nine state-of-the-art clustering methods.
C1 [Chen, Cuiling; Li, Zhi] Guangxi Normal Univ, Sch Comp Sci & Engn, 15 Yucai Rd, Guilin 541004, Guangxi, Peoples R China.
C3 Guangxi Normal University
RP Li, Z (corresponding author), Guangxi Normal Univ, Sch Comp Sci & Engn, 15 Yucai Rd, Guilin 541004, Guangxi, Peoples R China.
EM zhili@gxnu.edu.cn
FU National Natural Science Foundation of China [61862009]; Natural Science
   Foundation of Guangxi [2018GXNSFAA281314]; Guangxi "Bagui Scholar" Teams
   for Innovation and Research; Project of Guangxi Key Lab of Multi-source
   Information Mining and Security [MIMS22-03,19-A-01-02]; Guangxi
   Collaborative Innovation Center of Multi-source Information Integration
   and Intelligent Processing
FX This work is partially supported by the National Natural Science
   Foundation of China (Grant No: 61862009), the Natural Science Foundation
   of Guangxi (Grant No: 2018GXNSFAA281314), Guangxi "Bagui Scholar" Teams
   for Innovation and Research, the Project of Guangxi Key Lab of
   Multi-source Information Mining and Security (Grant No:
   MIMS22-03,19-A-01-02), Guangxi Collaborative Innovation Center of
   Multi-source Information Integration and Intelligent Processing.
CR Dattorro J., 2010, CONVEX OPTIMIZATION
   Du L, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3476
   Han YN, 2018, IEEE T NEUR NET LEAR, V29, P2625, DOI 10.1109/TNNLS.2017.2688365
   Huang H, 2020, IEEE T CYBERNETICS, V50, P2604, DOI 10.1109/TCYB.2019.2905793
   Huang HC, 2012, PROC CVPR IEEE, P773, DOI 10.1109/CVPR.2012.6247748
   Huang HC, 2012, IEEE T FUZZY SYST, V20, P120, DOI 10.1109/TFUZZ.2011.2170175
   Iliadis M, 2017, IEEE T IMAGE PROCESS, V26, P2203, DOI 10.1109/TIP.2017.2675206
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Kang Z, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2312
   Kang Z, 2020, KNOWL-BASED SYST, V189, DOI 10.1016/j.knosys.2019.105102
   Kang Z, 2018, AAAI CONF ARTIF INTE, P3366
   Kang Z, 2019, KNOWL-BASED SYST, V163, P510, DOI 10.1016/j.knosys.2018.09.009
   Li BX, 2020, INT J PAVEMENT ENG, V21, P457, DOI 10.1080/10298436.2018.1485917
   Li M., 2016, P 25 INT JOINT C ART, P1704
   Liu BY, 2021, IEEE T CYBERNETICS, V51, P1571, DOI 10.1109/TCYB.2019.2955388
   Lu CY, 2019, IEEE T PATTERN ANAL, V41, P487, DOI 10.1109/TPAMI.2018.2794348
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Nie F., 2016, IJCAI, P1881
   Nie FP, 2018, IEEE T IMAGE PROCESS, V27, P1501, DOI 10.1109/TIP.2017.2754939
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726
   Ou QY, 2021, IEEE ACCESS, V9, P3291, DOI 10.1109/ACCESS.2020.3041764
   Pang YW, 2020, IEEE T CYBERNETICS, V50, P247, DOI 10.1109/TCYB.2018.2868742
   Ren ZW, 2021, IEEE T CYBERNETICS, V51, P3273, DOI 10.1109/TCYB.2020.3000947
   Ren ZW, 2021, IEEE T NEUR NET LEAR, V32, P1839, DOI 10.1109/TNNLS.2020.2991366
   Ren ZW, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.105040
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang CL, 2018, IEEE ACCESS, V6, P77911, DOI 10.1109/ACCESS.2018.2884441
   Wen J, 2018, NEURAL NETWORKS, V108, P83, DOI 10.1016/j.neunet.2018.08.007
   Xie XY, 2018, IEEE T IMAGE PROCESS, V27, P477, DOI 10.1109/TIP.2017.2764262
   Yang C, 2019, INFORM SCIENCES, V500, P48, DOI 10.1016/j.ins.2019.05.063
   Zhan K, 2019, IEEE T KNOWL DATA EN, V31, P1984, DOI 10.1109/TKDE.2018.2872061
   Zhan K, 2019, IEEE T IMAGE PROCESS, V28, P1261, DOI 10.1109/TIP.2018.2877335
   Zhou SH, 2020, IEEE T NEUR NET LEAR, V31, P1351, DOI 10.1109/TNNLS.2019.2919900
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P1532, DOI 10.1109/TKDE.2018.2858782
   Zhu XF, 2018, IEEE T KNOWL DATA EN, V30, P517, DOI 10.1109/TKDE.2017.2763618
NR 37
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6425
EP 6445
DI 10.1007/s11042-023-15610-8
EA JUN 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003484200002
DA 2024-07-18
ER

PT J
AU Juneja, A
   Kumar, V
   Singla, SK
AF Juneja, Akshay
   Kumar, Vijay
   Singla, Sunil Kumar
TI Desmogging of still images using residual regression network and
   morphological erosion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Airlight; Desmogging; Erosion; Residual network; Transmission map
ID QUALITY ASSESSMENT
AB Smog is one of the air pollutants that makes it difficult for drivers to see. Smog is a mixture of fog and smoke that produces black fumes and reduces the visibility of drivers within the range of one kilometre. The small size and high density of smog particles, in comparison to other air pollutants, impede drivers' vision on the road. To resolve these problems, researchers designed a number of visibility restoration models. However, the development of an adequate desmogging technique is a challenging issue. The aerial and sensing imaging of machine vision systems are modified by the desmogging model. In this paper, a residual regression network (RRNet) is proposed followed by morphological erosion to produce a transmission map. The atmospheric light is estimated by using a 2D order statistic filter. The smoggy image is further reconstructed to obtain the clear scene radiance. Thus, the proposed model has a susceptibility to remove smog from road images in an effective manner. The proposed model is evaluated on the four well-known benchmark datasets and compared with five well-known desmogging techniques. The performance of the proposed desmogging model is evaluated in terms of color deviation, structure similarity index, and peak signal to noise ratio. It is found superior as compared to the existing models in terms of various performance metrics namely, fog aware density evaluation, naturalness image quality evaluator, perception-based image-quality, blind/referenceless image spatial quality evaluator, and image entropy by 2.2%, 1.17%, 8.05%, 2.64%, and 0.69% respectively.
C1 [Juneja, Akshay; Singla, Sunil Kumar] Thapar Inst Engn & Technol, Dept Elect & Instrumentat Engn, Patiala, India.
   [Kumar, Vijay] Dr BR Ambedkar Natl Inst Technol, Dept Informat Technol, Jalandhar, India.
C3 Thapar Institute of Engineering & Technology; National Institute of
   Technology (NIT System); Dr B R Ambedkar National Institute of
   Technology Jalandhar
RP Kumar, V (corresponding author), Dr BR Ambedkar Natl Inst Technol, Dept Informat Technol, Jalandhar, India.
EM vijaykumarchahar@gmail.com
RI Juneja, Dr. Akshay/KCK-0186-2024; Chahar, Vijay Kumar/A-2782-2015
OI Juneja, Dr. Akshay/0000-0002-0616-6613; Chahar, Vijay
   Kumar/0000-0002-3460-6989
FU Council of Scientific and Industrial Research (CSIR), India
   [22(0801)/19/EMR-II]
FX AcknowledgementsThis research is supported by Council of Scientific and
   Industrial Research (CSIR), India. The sanction number of the scheme is
   22(0801)/19/EMR-II.
CR Agrawal SC, 2022, VISUAL COMPUT, V38, P781, DOI 10.1007/s00371-020-02049-3
   An S, 2021, VISUAL COMPUT, P1
   Babu GH, 2022, MULTIMED TOOLS APPL, V81, P43897, DOI 10.1007/s11042-022-13222-2
   Bala Jeevan, 2020, International Conference on Innovative Computing and Communications. Proceedings of ICICC 2019. Advances in Intelligent Systems and Computing (AISC 1059), P417, DOI 10.1007/978-981-15-0324-5_36
   Bala J, 2020, 2020 3 INT C EM TECH, P1, DOI [10.1109/ICETCE48199.2020.9091768, DOI 10.1109/ICETCE48199.2020.9091768]
   Bala J, 2020, MULTIDIM SYST SIGN P, V31, P1259, DOI 10.1007/s11045-020-00707-2
   Bala J, 2019, MOD PHYS LETT B, V33, DOI 10.1142/S0217984919500568
   Barner KE, 1998, HANDB STAT, V17, P555, DOI 10.1016/S0169-7161(98)17023-2
   Bindal A, 2021, NORMALIZATION TECHNI
   Brownlee J., 2019, A gentle introduction to the rectified linear unit
   Chen WT, 2018, IEEE IMAGE PROC, P2855, DOI 10.1109/ICIP.2018.8451581
   Chen ZH, 2020, VISUAL COMPUT, V36, P2189, DOI 10.1007/s00371-020-01929-y
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Choi LK, 2014, IEEE SW SYMP IMAG, P165, DOI 10.1109/SSIAI.2014.6806055
   Choi LK, 2014, PROC SPIE, V9014, P90
   Choi LK, 2021, FADE SOFTWARE RELEAS
   Fang Z, 2021, VISUAL COMPUT, P1
   Gadekallu TR, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.107836
   Ganguly B, 2022, IEEE T CIRC SYST VID, V32, P286, DOI 10.1109/TCSVT.2021.3059573
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu X, 2021, KNOWL INF SYST, V63, P2585, DOI 10.1007/s10115-021-01605-0
   Jain A, 2021, J AMB INTEL HUM COMP, V12, P1161, DOI 10.1007/s12652-020-02161-1
   Janocha K., 2017, arXiv
   Juneja A, 2022, ARCH COMPUT METHOD E, V29, P1727, DOI 10.1007/s11831-021-09637-z
   Kingma D. P., 2014, arXiv
   Kumar A, 2021, FRONT COMPUT SCI-CHI, V15, DOI 10.1007/s11704-020-9305-8
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li JY, 2019, IEEE GEOSCI REMOTE S, V16, P472, DOI 10.1109/LGRS.2018.2874084
   Liu XB, 2022, IET SYST BIOL, V16, P85, DOI 10.1049/syb2.12042
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mondal K, 2024, MULTIMED TOOLS APPL, V83, P15413, DOI 10.1007/s11042-021-11890-0
   Mondal R., 2020, Math. Morphol.-Theory Appl., V4, P87, DOI DOI 10.1515/MATHM-2020-0103
   Naeem A, 2021, IEEE T GREEN COMMUN, V5, P611, DOI 10.1109/TGCN.2021.3067885
   Ogueke NV., 2017, EUR J SUSTAIN DEV RE, V1, P1, DOI [10.20897/ejosdr.201709, DOI 10.20897/EJOSDR.201709]
   Rehman MU, 2022, IEEE T NETW SCI ENG, V9, P4322, DOI 10.1109/TNSE.2022.3199235
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Sharma N, 2021, ARCH COMPUT METHOD E, V28, P4449, DOI 10.1007/s11831-021-09541-6
   Si YZ, 2022, MULTIMED TOOLS APPL, V81, P43467, DOI 10.1007/s11042-022-13237-9
   Singh Dilbag, 2019, Archives of Computational Methods in Engineering, V26, P1395, DOI 10.1007/s11831-018-9294-z
   Singh D, 2018, MULTIMED TOOLS APPL, V77, P9595, DOI 10.1007/s11042-017-5321-6
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Sun XJ, 2022, MOBILE NETW APPL, V27, P784, DOI 10.1007/s11036-021-01907-1
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Tarel JP, 2010, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2010.5548128
   Tian C., 2022, arXiv
   Venkatanath N, 2015, NATL CONF COMMUN
   Wang CL, 2011, ENTROPY-SWITZ, V13, P254, DOI 10.3390/e13010254
   Wang R, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P621, DOI 10.1109/ICISCE.2016.138
   Wang YB, 2021, MULTIMED TOOLS APPL, V80, P32539, DOI 10.1007/s11042-021-11209-z
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang F, 2022, VISUAL COMPUT, V38, P1579, DOI 10.1007/s00371-021-02089-3
   Zhang JJ, 2022, MULTIMEDIA SYST, V28, P45, DOI 10.1007/s00530-021-00802-9
   Zhang L, 2015, 2015 FIRST INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE THEORY, SYSTEMS AND APPLICATIONS (CCITSA 2015), P177, DOI 10.1109/CCITSA.2015.55
NR 54
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7179
EP 7214
DI 10.1007/s11042-023-15893-x
EA JUN 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003562600003
DA 2024-07-18
ER

PT J
AU Deepa, D
   Sivasangari, A
AF Deepa, D.
   Sivasangari, A.
TI ESSR-GAN: Enhanced super and semi supervised remora resolution based
   generative adversarial learning framework model for smartphone based
   road damage detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Super-generative adversarial network; Adaptive Gaussian bilateral
   filter; Bionic remora meta-heuristic optimization; Semi-supervised
   learning; Road damage detection
AB Road surface condition detection is a significant application for many intelligent transportation systems (ITSs) to uphold favourable driving conditions and avoid accidents. However, the accurate detection and classification of road damages have become more challenging. Thus, this paper proposed an enhanced sensor based technology that determines road damage by employing a deep learning (DL) algorithm. Initially, the road damage image is acquired from mobilephone devices and pre-processed using the adaptive Gaussian bilateral filter (AGBF). Then, after data augmentation, the proposed method has applied the super and semi-supervised remora adversarial resolution learning generative (S3-RARLG) model for road damage detection and classification. Initially, a Super-Generative Adversarial Network (SGAN) is used in S3-RARLG to maximize road image clarity and improve road damage detection performance. Then semi-supervised learning is adapted to address the insufficiency of label images by maximizing the expandability of training data. Finally, adversarial learning is enhanced by integrating with SGAN to improve detection performance. Moreover, in S3-RARLG, the weight updation is executed using bionic remora meta-heuristic optimization (BRMO). The proposed ESSR-GAN is simulated on the Python platform, and the performance metrics are determined to demonstrate the effectiveness of the proposed model using the road damage dataset 2019. As a result, the proposed ESSR-GAN accomplishes a higher accuracy of 99.12%, and the acquired results outperform the existing architectures.
C1 [Deepa, D.] Sathyabama Inst Sci & Technol, Sch Comp, Dept Comp Sci & Engn, Chennai 600119, Tamil Nadu, India.
   [Sivasangari, A.] Sathyabama Inst Sci & Technol, Sch Comp, Dept Informat Technol, Chennai 600119, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology; Sathyabama Institute of
   Science & Technology
RP Deepa, D (corresponding author), Sathyabama Inst Sci & Technol, Sch Comp, Dept Comp Sci & Engn, Chennai 600119, Tamil Nadu, India.
EM deepa.cse@sathyabama.ac.in
CR Alfarraj O, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05401-9
   Alfarrarjeh A, 2018, IEEE INT CONF BIG DA, P5201, DOI 10.1109/BigData.2018.8621899
   Angulo A, 2019, LECT NOTES ARTIF INT, V11835, P3, DOI 10.1007/978-3-030-33749-0_1
   Arya D, 2020, Arxiv, DOI arXiv:2008.13101
   Arya D, 2021, AUTOMAT CONSTR, V132, DOI 10.1016/j.autcon.2021.103935
   Arya D, 2021, DATA BRIEF, V36, DOI 10.1016/j.dib.2021.107133
   Arya D, 2020, IEEE INT CONF BIG DA, P5533, DOI 10.1109/BigData50022.2020.9377790
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bansal K, 2020, INTERNET TECHNOL LET, V3, DOI 10.1002/itl2.156
   Chellaswamy C, 2018, 2018 INT C COMP POW
   Deepa D, 2023, MULTIMED TOOLS APPL, V82, P18151, DOI 10.1007/s11042-022-14001-9
   Doshi K, 2020, IEEE INT CONF BIG DA, P5540, DOI 10.1109/BigData50022.2020.9377774
   Dunphy K, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22166193
   Feng XR, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/8515213
   Guo GG, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-19674-8
   Heidari MJ, 2022, FOREST ROADS DAMAGE
   Japkowicz N., 2002, Intelligent Data Analysis, V6, P429
   Jia HM, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115665
   Jing Yang, 2020, IOP Conference Series: Materials Science and Engineering, V782, DOI 10.1088/1757-899X/782/4/042033
   Kapadia H, 2018, INT C ISMAC COMP VIS, P1611
   Maeda H, 2021, COMPUT-AIDED CIV INF, V36, P47, DOI 10.1111/mice.12561
   Maeda H, 2018, COMPUT-AIDED CIV INF, V33, P1127, DOI 10.1111/mice.12387
   Mehta S, 2019, PROC CVPR IEEE, P9182, DOI 10.1109/CVPR.2019.00941
   Munir MFMS., 2023, INT J PERCEPTIVE COG, V91, P122
   Naddaf-Sh S, 2020, IEEE INT CONF BIG DA, P5602, DOI 10.1109/BigData50022.2020.9377751
   Pham V, 2020, IEEE INT CONF BIG DA, P5592, DOI 10.1109/BigData50022.2020.9378027
   Ramesh A, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14148682
   Rasyid Alfandino, 2019, 2019 International Electronics Symposium (IES). Proceedings, P672, DOI 10.1109/ELECSYM.2019.8901626
   Shim S, 2021, AUTOMAT CONSTR, V130, DOI 10.1016/j.autcon.2021.103833
   Shim S, 2020, IEEE ACCESS, V8, P170939, DOI 10.1109/ACCESS.2020.3022786
   Singh J, 2018, Arxiv, DOI arXiv:1811.04535
   Ulil AMR, 2019, IOP C SER EARTH ENV, V239, DOI 10.1088/1755-1315/239/1/012034
   Wang WZ, 2018, IEEE INT CONF BIG DA, P5220, DOI 10.1109/BigData.2018.8622354
   Xing MD, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0264793
   Zhang HW, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157594
NR 35
TC 1
Z9 1
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 30
PY 2023
DI 10.1007/s11042-023-15850-8
EA MAY 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0PB2
UT WOS:000999869700008
DA 2024-07-18
ER

PT J
AU Hung, CC
   Gao, XY
   Liu, Z
   Chai, YM
   Liu, TT
   Liu, CJ
AF Hung, Chih-Chieh
   Gao, Xiaoyuan
   Liu, Zhen
   Chai, Yumei
   Liu, Tingting
   Liu, Cuijuan
TI CECM: A cognitive emotional contagion model in social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Emotional contagion; Emotional evolution; Social media; OCEAN
   personality factor; PAD model
ID INFORMATION DIFFUSION; PERSONALITY; MEDIA
AB Social networks have changed the way how people communicate with each other dramatically. The study on information dissemination in social networks has attracted considerable attention. Many evidences show that emotionsof netizens are likely to spread with information and the emotional contagion also affect information dissemination in social networks. In this paper, we propose a cognitive emotional contagion model (CECM) which combines the model of individual characteristics, the topology of a social network, and the changing process as well as evolution of emotion contagion. Distinguished from conventional epidemiology-based models, our CECM model not only considers the changes of individuals' emotional statuses but also the influence of individuals to others during the information dissemination in a social network. Specifically, CECM first models an individual's emotions as emotional attributes and emotional statuses. Using Emotional statuses, we define the process of an individual's emotional change, which could be affected by one's emotional attributes (e.g. personality). CECM also models the network-wise features of an individual, including one's authority and the connection strength to one's neighbors in a social network. Finally, given emotional models and network-wise features of all users in a social network, a series of transition probabilities among the user's emotional status are defined to model the emotional evolution. A series of simulations is conducted to observe the characteristics of the proposed model. The results demonstrate that the proposed model can reflect the real-world situation of emotional contagion for different distributions of personality factors.
C1 [Hung, Chih-Chieh] Natl Chung Hsing Univ, Taichung 40227, Taiwan.
   [Gao, Xiaoyuan; Liu, Zhen; Liu, Cuijuan] Ningbo Univ, Fac Informat Sci & Technol, Ningbo 315211, Peoples R China.
   [Chai, Yumei] Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450001, Peoples R China.
   [Liu, Tingting] Ningbo Univ, Coll Sci & Technol, Cixi 315300, Peoples R China.
C3 National Chung Hsing University; Ningbo University; Zhengzhou
   University; Ningbo University
RP Liu, Z (corresponding author), Ningbo Univ, Fac Informat Sci & Technol, Ningbo 315211, Peoples R China.
EM smalloshin@nchu.edu.tw; liuzhen@nbu.edu.cn
RI Hung, Chih-Chieh/AAA-1158-2019; Liu, Haibo/JWP-8549-2024; Li,
   Wen/JQI-4757-2023; xiang, wei/JXL-3308-2024; Yang, Shu/JUU-4592-2023;
   Yang, Fan/JVO-8611-2024; Wang, Jin/KAM-5595-2024; liu,
   yuhao/JWP-0475-2024; wang, jun/JPY-3635-2023
OI Liu, Haibo/0000-0002-4213-2883; Hung, Chih-Chieh/0000-0002-6972-6577
CR [Anonymous], 2012, LEARNING DISCOVER SO
   Bollen J, 2011, ARTIF LIFE, V17, P237, DOI 10.1162/artl_a_00034
   Bond RM, 2012, NATURE, V489, P295, DOI 10.1038/nature11421
   Bosse T, 2009, 23RD EUROPEAN CONFERENCE ON MODELLING AND SIMULATION (ECMS 2009), P212
   Bozorgi A, 2017, KNOWL-BASED SYST, V134, P149, DOI 10.1016/j.knosys.2017.07.029
   Budak C., 2011, P 20 INT C WORLD WID, P665, DOI DOI 10.1145/1963405.1963499
   Collins A, 1990, The cognitive structure of emotions
   Corradini E, 2021, INT J INFORM MANAGE, V60, DOI 10.1016/j.ijinfomgt.2021.102377
   Du ZW, 2018, FUTURE GENER COMP SY, V78, P933, DOI 10.1016/j.future.2017.04.015
   Fan R, 2018, PHYSICA A, V495, P245, DOI 10.1016/j.physa.2017.12.086
   Fu LB, 2014, PHYSICA A, V405, P380, DOI 10.1016/j.physa.2014.03.043
   GOLDBERG LR, 1990, J PERS SOC PSYCHOL, V59, P1216, DOI 10.1037/0022-3514.59.6.1216
   Gui H., 2014, CIKM, P649, DOI [DOI 10.1145/2661829.2662000, 10.1145/2661829.2662000]
   Guille A., 2012, WWW 12 Companion: Proceedings of the 21st International Conference on World Wide Web, V2012, P1145, DOI [DOI 10.1145/2187980.2188254, 10.1145/2187980.2188254]
   Gurbin T, 2015, PROCD SOC BEHV, V197, P2331, DOI 10.1016/j.sbspro.2015.07.263
   Hill AL, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000968
   Hill AL, 2010, P ROY SOC B-BIOL SCI, V277, P3827, DOI 10.1098/rspb.2010.1217
   Kim Dan, 2015, 21 AM C INF SYST AMC
   Lhommet Margaux, 2011, 2011 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies, P89, DOI 10.1109/WI-IAT.2011.149
   Lin SY, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P365
   [刘箴 Liu Zhen], 2013, [计算机研究与发展, Journal of Computer Research and Development], V50, P2578
   Marsella SC, 2009, COGN SYST RES, V10, P70, DOI 10.1016/j.cogsys.2008.03.005
   Mehrabian A, 1996, AUST J PSYCHOL, V48, P86, DOI 10.1080/00049539608259510
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Saito K, 2008, LECT NOTES ARTIF INT, V5179, P67, DOI 10.1007/978-3-540-85567-5_9
   Song ZJ, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/9682538
   Stieglitz S, 2013, J MANAGE INFORM SYST, V29, P217, DOI 10.2753/MIS0742-1222290408
   Vries DAD., 2017, MEDIA PSYCHOL, V21, P1
   Wang QY, 2015, KNOWL-BASED SYST, V81, P46, DOI 10.1016/j.knosys.2015.02.006
   Xiong X, 2018, PHYSICA A, V490, P185, DOI 10.1016/j.physa.2017.08.025
   Zhao LJ, 2014, PHYSICA A, V394, P17, DOI 10.1016/j.physa.2013.09.057
NR 31
TC 0
Z9 0
U1 13
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 30
PY 2023
DI 10.1007/s11042-023-15394-x
EA MAY 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0PB2
UT WOS:000999869700001
DA 2024-07-18
ER

PT J
AU Hu, ZP
   Liu, HY
   Xiong, Y
   Wang, LZ
   Wu, RZ
   Guan, K
   Hu, YJ
   Lyu, T
   Fan, CJ
AF Hu, Zhipeng
   Liu, Haoyu
   Xiong, Yu
   Wang, Lizi
   Wu, Runze
   Guan, Kai
   Hu, Yujing
   Lyu, Tangjie
   Fan, Changjie
TI Promoting human-AI interaction makes a better adoption of deep
   reinforcement learning: a real-world application in game industry
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Game AI; Deep reinforcement learning; Explainable reinforcement
   learning; Human-AI interaction
ID GO
AB Deep reinforcement learning (DRL) has been widely employed in game industry, mainly for building automatic game agents. While its performance and efficiency has significantly outperformed traditional approaches, the lack of model transparency constrains the interaction between the model and the human operators, thus degrading the practicality of DRL methods. In this paper, we propose to mitigate this human-AI interaction issue in a game industry scenario. Previously, existing methods need repetitive execution of DRL or are designed towards specific tasks, which are not applicable for our deployment scenario. Considering that different games could have different DRL AI agents, we hereby develop a post-hoc explanation framework which regards original DRL as a black-box model and can be applicable to any DRL based agents. Within the framework, a specially selected student model, which has been already well explored for model explanation, is employed to learn the decision policies of the trained DRL model. Then, by giving explanation information for the student model, indirect but practical explanation results can be obtained for original DRL model. Based on this information, the interaction between human and AI agents can be enhanced, benefiting deployment of DRL. Finally, based on the dataset from a real-world production game, we conduct experiments and user studies to illustrate the effectiveness of the proposed procedure from both objective and subjective perspectives.
C1 [Hu, Zhipeng] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
   [Hu, Zhipeng; Liu, Haoyu; Xiong, Yu; Wang, Lizi; Wu, Runze; Guan, Kai; Hu, Yujing; Lyu, Tangjie; Fan, Changjie] NetEase Inc, Fuxi AI Lab, Hangzhou, Peoples R China.
C3 Zhejiang University
RP Liu, HY (corresponding author), NetEase Inc, Fuxi AI Lab, Hangzhou, Peoples R China.
EM 11921156@zju.edu.cn; liuhaoyu03@corp.netease.com;
   xiongyu1@corp.netease.com; wanglizi@corp.netease.com;
   wurunze1@corp.netease.com; guankai1@corp.netease.com;
   huyujing@corp.netease.com; hzlvtangjie@corp.netease.com;
   fanchangjie@corp.netease.com
RI Wu, Runze/JNE-3491-2023
OI Liu, Haoyu/0000-0002-8998-1217
CR Agius H, 2021, MULTIMED TOOLS APPL, V80, P30939, DOI 10.1007/s11042-021-11306-z
   Amershi Saleema, 2012, P SIGCHI C HUM FACT
   Amir D, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P1168
   Anderson A, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1328
   Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Berner C., 2019, arXiv
   Bhatt U, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P648, DOI 10.1145/3351095.3375624
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Fails J. A., 2003, IUI 03. 2003 International Conference on Intelligent User Interfaces, P39, DOI 10.1145/604045.604056
   Frid E, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376514
   Ghorbani A., 2019, Adv. Neural Inf. Process. Syst, V32
   Gillies M, 2016, P 2016 CHI C EXT ABS, P3558, DOI [10.1145/2851581.2856492, DOI 10.1145/2851581.2856492]
   Greydanus S, 2018, PR MACH LEARN RES, V80
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heuillet A, 2021, KNOWL-BASED SYST, V214, DOI 10.1016/j.knosys.2020.106685
   Juozapaitis Z., 2019, IJCAI/ECAI workshop on explainable artificial intelligence
   Ke GL, 2017, ADV NEUR IN, V30
   Kuhn H. W., 1953, Contributions to the Theory of Games, V2, DOI DOI 10.1515/9781400881970-012
   Kulesza T, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3075, DOI 10.1145/2556288.2557238
   Lage I, 2018, ADV NEURAL INFORM PR, P31
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Lee L.-H., 2021, arXiv, DOI DOI 10.48550/ARXIV.2110.05352
   Lesort T, 2018, NEURAL NETWORKS, V108, P379, DOI 10.1016/j.neunet.2018.07.006
   Louie R, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376739
   Lundberg SM, 2017, ADV NEUR IN, V30
   Lundberg SM, 2020, NAT MACH INTELL, V2, P56, DOI 10.1038/s42256-019-0138-9
   Lundberg SM, 2019, Arxiv, DOI arXiv:1905.04610
   Lundberg SM, 2019, Arxiv, DOI arXiv:1802.03888
   Madumal P, 2020, AAAI CONF ARTIF INTE, V34, P2493
   Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007
   Oroojlooy A, 2023, APPL INTELL, V53, P13677, DOI 10.1007/s10489-022-04105-y
   Patel K, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P667
   Perez-Liebana D, 2019, IEEE T GAMES, V11, P195, DOI 10.1109/TG.2019.2901021
   Powers R., 2004, Advances in neural information processing systems, V17
   Raffin, 2019, ARXIV190108651
   Ramos G, 2020, HUM-COMPUT INTER-US, V35, P413, DOI 10.1080/07370024.2020.1734931
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249
   Schapire RE, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1401
   Sequeira P, 2020, ARTIF INTELL-AMST, V288, DOI 10.1016/j.artint.2020.103367
   Shi WZ, 2021, IEEE T GEOSCI REMOTE, V59, P4654, DOI 10.1109/TGRS.2020.3015826
   Shneiderman B, 2020, INT J HUM-COMPUT INT, V36, P495, DOI 10.1080/10447318.2020.1741118
   Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Sundararajan M., 2020, INT C MACHINE LEARNI, P9269
   Vinyals O, 2019, NATURE, V575, P350, DOI 10.1038/s41586-019-1724-z
   Vouros GA, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3527448
   Wiegreffe S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P11
   Yang G., 2022, NEURIPS
   Zha D, 2021, P 38 INT C MACH LEAR, P12333
   Zhang Marvin, 2019, INT C MACHINE LEARNI, P7444
NR 55
TC 1
Z9 1
U1 12
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 25
PY 2023
DI 10.1007/s11042-023-15361-6
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3NP9
UT WOS:000995070900001
DA 2024-07-18
ER

PT J
AU Chen, CL
   Deng, YY
   Zhu, SZ
   Tsaur, WJ
   Weng, W
AF Chen, Chin-Ling
   Deng, Yong-Yuan
   Zhu, Shunzhi
   Tsaur, Woei-Jiunn
   Weng, Wei
TI An IoT and blockchain based logistics application of UAV
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE IoT; blockchain; logistics; UAV; mutual authentication; non-repudiation
ID TRAVELING SALESMAN PROBLEM; VEHICLE-ROUTING PROBLEM; TRUCK-DRONE;
   OPTIMIZATION
AB With the increasing number of online consumers, the relationship between the Internet of things and the Internet is becoming closer. Logistics transportation plays an important role in the whole online shopping. Unmanned Aerial Vehicle (UAV) transportation in air transportation has led traditional logistics to the era of intelligent logistics. The application of UAV in the business logistics industry has become a formal issue. However, there are some security issues in today's UAV logistics, such as transaction disputes between sender and receiver about lost packages or wrong delivery. This paper focuses on the application of blockchain and smart contract mechanism to solve the shortcomings of the current UAV application in the e-commerce field and propose solutions. The proposed scheme achieves the following e-commerce requirements: mutual authentication of identity, non-repudiation of delivery and arrival, and other major blockchain-based security requirements. Once the dispute occurs, we also proposed an arbitrative mechanism to classify the responsibility.
C1 [Chen, Chin-Ling] Changchun Scitech Univ, Sch Informat Engn, Changchun 130600, Jilin, Peoples R China.
   [Chen, Chin-Ling; Deng, Yong-Yuan] Chaoyang Univ Technol, Dept Comp Sci & Informat Engn, Taichung 41349, Taiwan.
   [Zhu, Shunzhi; Weng, Wei] Xiamen Univ Technol, Sch Comp & Informat Engn, Xiamen 361024, Peoples R China.
   [Tsaur, Woei-Jiunn] Natl Taipei Univ, Comp Ctr, New Taipei 23741, Taiwan.
C3 Chaoyang University of Technology; Xiamen University of Technology;
   National Taipei University
RP Deng, YY (corresponding author), Chaoyang Univ Technol, Dept Comp Sci & Informat Engn, Taichung 41349, Taiwan.; Zhu, SZ (corresponding author), Xiamen Univ Technol, Sch Comp & Informat Engn, Xiamen 361024, Peoples R China.
EM allen.nubi@gmail.com; zhusz66@163.com
CR Agatz N, 2018, TRANSPORT SCI, V52, P965, DOI 10.1287/trsc.2017.0791
   Air AP, REV AIRSP MOD SAF IN
   Amukele T, 2017, TRANSFUSION, V57, P582, DOI 10.1111/trf.13900
   BURROWS M, 1989, P ROY SOC LOND A MAT, V426, P233, DOI 10.1098/rspa.1989.0125
   Chen C. L., 2021, J RES TECHNOL EDUC, V77, P7791, DOI [10.1007/s11227-020-03558-7, DOI 10.1080/15391523.2021.1983894]
   Chen CL, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010062
   Chen CL, 2019, ENERGIES, V12, DOI 10.3390/en12163061
   Chen CL, 2015, J INTERNET TECHNOL, V16, P1177, DOI 10.6138/JIT.2015.16.7.20120316
   Chen CL, 2015, IETE TECH REV, V32, P104, DOI 10.1080/02564602.2014.983565
   Chen CL, 2011, ELECTRON COMMER R A, V10, P279, DOI 10.1016/j.elerap.2010.09.001
   Chen CL, 2009, ELECTRON COMMER R A, V8, P327, DOI 10.1016/j.elerap.2009.04.012
   Das AK, 2020, COMPUT SECUR, V97, DOI 10.1016/j.cose.2020.101938
   Datta S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03591-1
   Dorling K, 2017, IEEE T SYST MAN CY-S, V47, P70, DOI 10.1109/TSMC.2016.2582745
   Euchi J, 2021, CHINESE J AERONAUT, V34, P182, DOI 10.1016/j.cja.2020.06.006
   Ferrandez SM, 2016, J IND ENG MANAG-JIEM, V9, P374, DOI 10.3926/jiem.1929
   Gonzalez-R PL, 2020, TRANSPORT RES C-EMER, V114, P657, DOI 10.1016/j.trc.2020.02.030
   Jithish J, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4042
   Johnson D., 2001, International Journal of Information Security, V1, P36, DOI 10.1007/s102070100002
   Kapitonov A, 2017, 2017 WORKSHOP ON RESEARCH, EDUCATION AND DEVELOPMENT OF UNMANNED AERIAL SYSTEMS (RED-UAS), P84, DOI 10.1109/RED-UAS.2017.8101648
   Kitjacharoenchai P, 2019, COMPUT IND ENG, V129, P14, DOI 10.1016/j.cie.2019.01.020
   Kornatowski PM, 2018, IEEE ROBOT AUTOM LET, V3, P3813, DOI 10.1109/LRA.2018.2856282
   Kunze O, 2016, TRANSP RES PROC, V19, P286, DOI 10.1016/j.trpro.2016.12.088
   Mckinnon A., 2016, EBE, V42, P617, DOI [10.2148/benv.42.4.617, DOI 10.2148/BENV.42.4.617]
   Mehta P, 2020, COMPUT COMMUN, V151, P518, DOI 10.1016/j.comcom.2020.01.023
   Moormann D., 2015, DHL PARCELCOPTER RES
   Murray CC, 2015, TRANSPORT RES C-EMER, V54, P86, DOI 10.1016/j.trc.2015.03.005
   Ponza A, 2016, OPTIMIZATION DRONE A, P2
   Ha QM, 2018, TRANSPORT RES C-EMER, V86, P597, DOI 10.1016/j.trc.2017.11.015
   Schermer D, 2019, COMPUT OPER RES, V109, P134, DOI 10.1016/j.cor.2019.04.021
   Sinha D, 2019, ADV INTELL SYST COMP, P133, DOI DOI 10.1007/978-3-030-39875-0_14
   Troudi A, 2017, LECT NOTES COMPUT SC, V10268, P86, DOI 10.1007/978-3-319-59513-9_9
   Wang Z, 2019, TRANSPORT RES B-METH, V122, P350, DOI 10.1016/j.trb.2019.03.005
NR 33
TC 1
Z9 1
U1 12
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 22
PY 2023
DI 10.1007/s11042-023-15517-4
EA MAY 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G9PW0
UT WOS:000992398700001
DA 2024-07-18
ER

PT J
AU de Brito, AR
   Levada, ALM
AF de Brito, Andre R.
   Levada, Alexandre L. M.
TI Dual Non-Local Means: a two-stage information-theoretic filter for image
   denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Filtering; Denoising; Non-local means; Information theory
ID NOISE; ALGORITHM
AB Image denoise has been explored with the development of various filters used to remove or reduce random disruptions on observed data, but at the same time it preserves most of the edges and the fine details of the scene. The issue caused by the combined deterioration of the Gaussian noise succeeds the scattering through all the signal frequencies. Thus, the most effective filters for this type of noise are implemented in spatial domain. In this article, we proposed a Non-Local Means filter that combines the average of each fragment of a browser window, by using four measures - of distinct similarities - among the Gaussian densities that are estimated from the following fragments: the Kullback-Leibler divergence, the Bhattacharyya distance, the Hellinger distance and the Cauchy-Schwarz divergence. Computational experiments were done in a set of 7 images that were deteriorated by a noise of Gaussian type, considering that the data obtained show that the proposed methods are capable of producing, on average, a Peak Signal-to-Noise Ratio significantly greater than the one the combination of Total Variation, Non-Local Means, BM3D, Anisotropic Diffusion, Wiener, Wavelet e Bilateral filters does when they are applied independently.
C1 [de Brito, Andre R.; Levada, Alexandre L. M.] Univ Fed Sao Carlos, Comp Dept, Sao Carlos, SP, Brazil.
C3 Universidade Federal de Sao Carlos
RP de Brito, AR (corresponding author), Univ Fed Sao Carlos, Comp Dept, Sao Carlos, SP, Brazil.
EM andrerb_1992@hotmail.com; alexandre.levada@ufscar.br
RI Levada, Alexandre M/A-8301-2010
OI Brito, Andre/0000-0002-8843-5388
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - Brasil
   (CAPES) [001]
FX This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior - Brasil (CAPES) - Finance Code 001.
CR Amer A, 2005, IEEE T CIRC SYST VID, V15, P113, DOI 10.1109/TCSVT.2004.837017
   Bindilatti AA, 2013, IEEE SIGNAL PROC LET, V20, P1010, DOI 10.1109/LSP.2013.2277111
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   DIACONIS P, 1982, J AM STAT ASSOC, V77, P822, DOI 10.2307/2287313
   Hasan M, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0264-z
   Hoang HG, 2014, 2014 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING (SSP), P240, DOI 10.1109/SSP.2014.6884620
   Jain P, 2016, INFORM SYST FRONT, V18, P159, DOI 10.1007/s10796-014-9527-0
   Jenssen R, 2005, LECT NOTES COMPUT SC, V3757, P34, DOI 10.1007/11585978_3
   Jenssen R, 2006, J FRANKLIN I, V343, P614, DOI 10.1016/j.jfranklin.2006.03.018
   Jin C, 2020, MULTIMED TOOLS APPL, V79, P20947, DOI 10.1007/s11042-020-08871-0
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Kundu R, 2022, NATL ACAD SCI LETT, V45, P61, DOI 10.1007/s40009-021-01052-z
   Levada ALM, 2021, SIBGRAPI, P152, DOI 10.1109/SIBGRAPI54419.2021.00029
   Mahler RPS, 1998, P SOC PHOTO-OPT INS, V3365, P252, DOI 10.1117/12.317518
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329
   Patidar P, 2010, Int J Comput Appl, V9, P45, DOI [DOI 10.5120/1370-1846, 10.5120/1370-1846]
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Petkova L, 2020, 2020 55TH INTERNATIONAL SCIENTIFIC CONFERENCE ON INFORMATION, COMMUNICATION AND ENERGY SYSTEMS AND TECHNOLOGIES (IEEE ICEST 2020), P177, DOI [10.1109/icest49890.2020.9232887, 10.1109/ICEST49890.2020.9232887]
   Riya, 2021, COMPUT MATH APPL, V93, P106, DOI 10.1016/j.camwa.2021.03.029
   Rohit V., 2013, Int. J. Adv. Res. Comput. Sci. Softw. Eng, V3, P2277
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Salehi H, 2021, INT J IMAGE GRAPH, V21, DOI 10.1142/S0219467821500364
   Shao L, 2014, IEEE T CYBERNETICS, V44, P1001, DOI 10.1109/TCYB.2013.2278548
   Spurek P, 2016, IEEE IJCNN, P3346, DOI 10.1109/IJCNN.2016.7727627
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Yahya AA, 2020, MULTIMED TOOLS APPL, V79, P20391, DOI 10.1007/s11042-020-08815-8
   Yue HJ, 2014, PROC CVPR IEEE, P2933, DOI 10.1109/CVPR.2014.375
   Zhang YY, 2020, MATH BIOSCI ENG, V17, P4970, DOI 10.3934/mbe.2020269
NR 32
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15339-4
EA MAY 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0OU4
UT WOS:000993050400019
DA 2024-07-18
ER

PT J
AU Roselinkiruba, R
   Kumar, AK
AF Roselinkiruba, R.
   Kumar, A. Krishna
TI Reversible key frame selection data hiding in videos using search tree
   labelling scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Data hiding; Quality metrics; Search tree
ID STEGANOGRAPHIC METHOD; IMAGES; WATERMARKING; LSB; PVD
AB Hiding a data inside video plays a vital role in data communication. The aim of data hiding is to protect the data with minimum distortion rate. In this paper, key frame selection data hiding in videos using Search Tree Labeling Scheme (STLS) is proposed. The cover video in the frames is trained for noise removal and compression using Denoising Convolution Neural Network (DnCNN) and the quality factor is checked for every frame using parameters. The compression is applied and key frames in the cover video are selected using Neural Image Assessment (NIMA) and Convolution Neural Network (CNN) model. This model is trained to predict the score of each frame based on quality metrics. The high score frame are selected as the key frame and it is separated into 2 x 3 blocks. Each block of pixels are represented in the tree structure using STLS to identify the differences and pixel is named in the tree according to its distortion range. Data is embedded using odd or even bit embedding on the pixel using Most Significant Bit (MSB) and Least Significant Bit (LSB). The experimental result reveals that the proposed schemes can attain better data extraction with more Embedding Capacity (EC), and security. The proposed method provides Peak Signal Noise Ratio (PSNR) value for ImageNet VID is 46.63 and CD-net 2014 is 45.47 and EC has achieved for ImageNet VID: 693,242 and CD-net 2014: 712,422 bits). Moreover the proposed scheme is significantly outperforms the state-of-the-art techniques in terms of quality assessment in the selection of frames and data embedding.
C1 [Roselinkiruba, R.] VelTech Rangarajan Dr Sagunthala R&D Inst Sci & Te, Dept CSE, Chennai, India.
   [Kumar, A. Krishna] Puducherry Technol Univ, Dept CSE, Pondicherry, India.
C3 Vel Tech Rangarajan Dr Sagunthala R&D Institute of Science & Technology;
   Pondicherry Engineering College
RP Roselinkiruba, R (corresponding author), VelTech Rangarajan Dr Sagunthala R&D Inst Sci & Te, Dept CSE, Chennai, India.
EM kirubaroselin@gmail.com; krish1095@ptuniv.edu.in
CR Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bhardwaj A, 2018, MULTIMED TOOLS APPL, V77, P19659, DOI 10.1007/s11042-017-5340-3
   Bin Wang, 2014, Advanced Materials Research, V1006-1007, P768, DOI 10.4028/www.scientific.net/AMR.1006-1007.768
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1431, DOI 10.1016/j.patrec.2004.05.006
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   Dalal M., 2019, INT J ENG ADV TECHNO, V8, P2460
   de Oliveira VA, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3145992
   Ding H, 2021, IEEE ACCESS, V9, P35324, DOI 10.1109/ACCESS.2021.3062468
   Ding WJ, 2022, PATTERN RECOGN LETT, V159, P116, DOI 10.1016/j.patrec.2022.05.014
   Diwakar Manoj, 2020, International Journal of Information and Computer Security, V12, P234
   Diwakar M, 2019, SOFT COMPUTING THEOR, V742
   Diwakar M, 2019, HDB MULTIMEDIA INFOR, P501, DOI [10.1007/978-3-030-15887-3_24, DOI 10.1007/978-3-030-15887-3_24]
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Diwakar M, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P297, DOI 10.1145/2791405.2791430
   Diwakar M, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P160, DOI 10.1109/ICIIP.2013.6707574
   Fu AY, 2006, IEEE T DEPEND SECURE, V3, P301, DOI 10.1109/TDSC.2006.50
   Girod Bernd, 1993, P207
   Himeur Y, 2018, MULTIMED TOOLS APPL, V77, P8603, DOI 10.1007/s11042-017-4754-2
   Hussain M, 2021, MULTIMED TOOLS APPL, V80, P20381, DOI 10.1007/s11042-021-10652-2
   Hussain M, 2018, IETE TECH REV, V35, P53, DOI 10.1080/02564602.2016.1244496
   Ichigaya A, 2006, IEEE T CIRC SYST VID, V16, P251, DOI 10.1109/TCSVT.2005.858745
   Katzenbeisser SC, 2000, ART H COMP SCI LIBR, P17
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Kittawi N, 2022, MULTIMED TOOLS APPL, V81, P12441, DOI 10.1007/s11042-022-12364-7
   Kumar P., 2011, Proceedings of the 2011 World Congress on Information and Communication Technologies (WICT), P816, DOI 10.1109/WICT.2011.6141352
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Paul R, 2013, CONFL 2013 NEXT GEN, P337
   Rai AK, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13061072
   Ranjithkumar R, 2021, MULTIMED TOOLS APPL, V80, P13865, DOI 10.1007/s11042-020-10324-7
   Kiruba RR, 2021, MULTIDIM SYST SIGN P, V32, P405, DOI 10.1007/s11045-019-00697-w
   Roselinkiruba R., 2021, International Journal of Information Technology, V13, P1797, DOI 10.1007/s41870-021-00774-z
   RoselinKiruba R, 2023, VISUAL COMPUT, V39, P59, DOI 10.1007/s00371-021-02312-1
   RoselinKiruba R, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATION, AND SIGNAL PROCESSING (ICCCSP): SPECIAL FOCUS ON TECHNOLOGY AND INNOVATION FOR SMART ENVIRONMENT, P156
   RoselinKiruba R., 2017, 2017 IEEE International Conference on Circuits and Systems (ICCS). Proceedings, P112, DOI 10.1109/ICCS1.2017.8325974
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sahu M, 2021, J KING SAUD U COMPUT
   Sharma P, 2013, C ADV COMMUN CONTROL
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Singh G, 2013, REV IMAGE ENHANCEMEN
   Sun J, 2022, HIGH CAPACITY DATA H
   Swain G, 2019, OPTIK, V180, P807, DOI 10.1016/j.ijleo.2018.11.015
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Wu YQ, 2020, IEEE T MULTIMEDIA, V22, P1929, DOI 10.1109/TMM.2019.2952979
   Yan B, 2019, IEEE T MULTIMEDIA, V21, P2603, DOI 10.1109/TMM.2019.2904879
   Yang CH, 2010, J SYST SOFTWARE, V83, P1635, DOI 10.1016/j.jss.2010.03.081
   Yao H, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2019.107447
   Yu CY, 2021, ACTA HORTIC, V1313, P1, DOI [10.17660/ActaHortic.2021.1313.1, 10.1109/TCSVT.2021.3062947]
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
NR 55
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15671-9
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0OU4
UT WOS:000993050400006
DA 2024-07-18
ER

PT J
AU Gilani, SMM
   Usman, M
   Daud, S
   Kabir, A
   Nawaz, Q
   Judit, O
AF Gilani, Syed Mushhad Mustuzhar
   Usman, Muhammad
   Daud, Saqib
   Kabir, Asif
   Nawaz, Qamar
   Judit, Olah
TI SDN-based multi-level framework for smart home services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE SDN; Smart home API; Smart services; Smart home framework
ID SOFTWARE-DEFINED NETWORKING; CHALLENGES; INTERNET
AB The smart home is a field that uses smart devices and gadgets to automate tasks and operations in the house, and it is expected that this study subject will become a focal point in future civilizations. The adoption of smart home services faces significant obstacles in terms of reliability and stability. The Software Defined Networking (SDN) paradigm offers up novel approaches and trends to embrace smart technologies to tackle the issues of smart homes. To avoid accidents, we developed a vertical SDN-based multi-level structure consisting of two controllers with a parent-child connection. It enables smart homes to make optimal use of current services while also providing new services to smart homes and buildings, opening the path for future smart services. In addition, we created an Application Programming Interface (API) for the smart home to make it easier to use current services and pave the path for future smart services. We designed numerous jobs depending on their categorization to give smart services, which is beneficial for smart homes. Local topologies, cloud topologies, and cloud-local topologies have all been compared in the evaluation section. The performance of POX, NOX, and Flood Light controllers is measured using three performance metrics: mean throughput, Round-Trip Time (RTT), and packet loss across all three topologies. Our findings revealed that the cloud-local topology had the lowest packet loss ratio of 1.4%, while the local and cloud topologies had 1.9% and 2.3%, respectively.
C1 [Gilani, Syed Mushhad Mustuzhar; Usman, Muhammad] Arid Agr Univ, UIIT, PMAS, Rawalpindi, Pakistan.
   [Daud, Saqib] Shaheed Zulfikar Ali Bhutto Inst Sci & Technol, Islamabad, Pakistan.
   [Kabir, Asif] Univ Kotli, Dept CS & IT, Kotli, Jammu & Kashmir, Pakistan.
   [Nawaz, Qamar] Agr Univ, Dept Comp Sci, Faisalabad, Pakistan.
   [Judit, Olah] Univ Debrecen, Fac Econ & Business, H-4032 Debrecen, Hungary.
   [Judit, Olah] Univ Johannesburg, Coll Business & Econ, ZA-2006 Johannesburg, South Africa.
C3 Arid Agriculture University; Shaheed Zulfikar Ali Bhutto Institute of
   Science & Technology; University of Debrecen; University of Johannesburg
RP Judit, O (corresponding author), Univ Debrecen, Fac Econ & Business, H-4032 Debrecen, Hungary.; Judit, O (corresponding author), Univ Johannesburg, Coll Business & Econ, ZA-2006 Johannesburg, South Africa.
EM mushhad@uaf.edu.pk; ranamusman92@gmail.com; saqibmirza.daud@gmail.com;
   asifkabirumsit@outlook.com; mqamarnawaz@hotmail.com;
   olah.judit@econ.unideb.hu
RI Muhammad, Usman/W-6993-2019
OI Muhammad, Usman/0000-0001-8363-0179; Mustuzhar Gilani, Syed
   Mushhad/0000-0003-1198-7632
FU University of Debrecen
FX Open access funding provided by University of Debrecen.
CR Abhishek R, 2017, IEEE INT WORKS LOCAL
   Almasi B., 2013, P C ADV WIR SENS NET, P7
   Alshnta AM, 2018, COGENT ENG, V5, P1, DOI 10.1080/23311916.2018.1469949
   [Anonymous], 2016, 2016 IEEE 7 ANN INFO, DOI DOI 10.1109/IEMCON.2016.7746320
   Atzori L, 2012, COMPUT NETW, V56, P3594, DOI 10.1016/j.comnet.2012.07.010
   Balta-Ozkan N, 2014, ENERGY RES SOC SCI, V3, P65, DOI 10.1016/j.erss.2014.07.007
   Banerjee A, 2018, CONFERENCE PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT), P78, DOI 10.1109/INFOCT.2018.8356844
   Ben Attia M, 2019, IEEE ACCESS, V7, P58990, DOI 10.1109/ACCESS.2019.2914658
   Boavida F, 2016, STUD COMPUT INTELL, V616, P463, DOI 10.1007/978-3-319-25017-5_44
   Chen W, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106503
   Darby SJ, 2018, BUILD RES INF, V46, P140, DOI 10.1080/09613218.2017.1301707
   Daud S, 2020, PAK J AGR SCI, V57, P871, DOI 10.21162/PAKJAS/20.9249
   Daud S, 2019, I C COMM SOFTW NET, P466, DOI [10.1109/ICCSN.2019.8905256, 10.1109/iccsn.2019.8905256]
   Demetriou S, 2017, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON SECURITY AND PRIVACY IN WIRELESS AND MOBILE NETWORKS (WISEC 2017), P122, DOI 10.1145/3098243.3098251
   Eghbali H, 2015, IEEE ICC, P5342, DOI 10.1109/ICC.2015.7249173
   Moyano RF, 2017, INT J NETW MANAG, V27, DOI 10.1002/nem.1984
   Moyano RF, 2017, COMPUT STAND INTER, V54, P279, DOI 10.1016/j.csi.2017.01.010
   Garcia Hernando Ana Belen, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P86, DOI 10.1109/ICCE.2017.7889240
   Gordon H, 2021, P INT COMP SOFTW APP, P1049, DOI 10.1109/COMPSAC51774.2021.00143
   Han B, 2015, IEEE COMMUN MAG, V53, P90, DOI 10.1109/MCOM.2015.7045396
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Illy P, 2022, IEEE T NETW SERV MAN, V19, P772, DOI 10.1109/TNSM.2022.3141942
   Jang HC, 2017, 2017 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTED, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI)
   Jimenez Y., 2014, 2014 IFIP NETWORKING, P1, DOI [10.1109/IFIPNetworking.2014.6857117, DOI 10.1109/IFIPNETWORKING.2014.6857117]
   Jo J, 2014, IEEE T CONSUM ELECTR, V60, P534, DOI 10.1109/TCE.2014.6937340
   Kim Y, 2015, 2015 IEEE 29TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS WAINA 2015, P662, DOI 10.1109/WAINA.2015.93
   Lee M, 2015, IEEE INT C NETW SENS, P444, DOI 10.1109/ICNSC.2015.7116078
   Luo SB, 2016, IEEE T CONSUM ELECTR, V62, P200, DOI 10.1109/TCE.2016.7514720
   Nobakht M, 2016, PROCEEDINGS OF 2016 11TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY, (ARES 2016), P147, DOI 10.1109/ARES.2016.64
   Oracle, 2014, INT THINGS MAN COMPL, P1
   Sharma PK, 2019, MOBILE NETW APPL, V24, P913, DOI 10.1007/s11036-018-1147-3
   Shiwei Wang, 2014, 2014 International Conference on Smart Computing (SMARTCOMP), P118, DOI 10.1109/SMARTCOMP.2014.7043848
   Sivaraman V, 2015, IEEE CONF WIREL MOB, P163, DOI 10.1109/WiMOB.2015.7347956
   Stojkoska BLR, 2017, J CLEAN PROD, V140, P1454, DOI 10.1016/j.jclepro.2016.10.006
   Stolojescu-Crisan C, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113784
   Tao M, 2017, FUTURE GENER COMP SY, V76, P528, DOI 10.1016/j.future.2016.11.012
   Wood T, 2015, IEEE NETWORK, V29, P36, DOI 10.1109/MNET.2015.7113223
   Xu K, 2016, IEEE COMMUN MAG, V54, P116, DOI 10.1109/MCOM.2016.7470945
   Yan Q, 2016, IEEE COMMUN SURV TUT, V18, P602, DOI 10.1109/COMST.2015.2487361
NR 39
TC 1
Z9 1
U1 11
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 16
PY 2023
DI 10.1007/s11042-023-15678-2
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G5FI8
UT WOS:000989408100007
OA hybrid
DA 2024-07-18
ER

PT J
AU Khishe, M
   Azar, OP
   Hashemzadeh, E
AF Khishe, Mohammad
   Azar, Omid Pakdel
   Hashemzadeh, Esmaeil
TI Variable-length CNNs evolved by digitized chimp optimization algorithm
   for deep learning applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chimp optimization algorithm; Image classification; Digitized-based
   coding; ChOA
ID OBJECTIVE DEPLOYMENT OPTIMIZATION
AB One of the most reliable deep learning approaches for image classification challenges is deep Conventional Conv neural networks (DCNNs); however, identifying the appropriate DCNN architecture for a given application can be quite challenging. This study focuses on finding the optimal DCNN architecture automatically using an improved version of the Chimp Optimization Algorithm (ChOA). Three changes based on the baseline ChOA are developed to accomplish the objectives. As a first step, a digitized-based coding strategy is created, making it easier for chimp vectors to encode DCNN layers. Then, to achieve variable-length DCNNs, a disabled layer is recommended to cover some chimp vector dimensions. As a third contribution, a mechanism is developed to assess the fitness function using only a part of the dataset instead of the whole dataset. In order to assess the developed model's performance, the comparison is made against 23 classifiers, including the top state-of-the-art approaches, using nine benchmark image datasets. The proposed model presents the best performance in the Fashion dataset with an error percentage of 5.08, while it is the second-best model with 750 k parameters. Also, for other datasets, the experimental findings indicate that the suggested method's classification accuracy outperforms other benchmarks in 87 out of 95 investigations. This variable-length approach is the first effort of its kind, employing ChOA to evolve the architectures of DCNNs autonomously.
C1 [Khishe, Mohammad; Hashemzadeh, Esmaeil] Imam Khomeini Marine Sci Univ, Dept Elect Engn, Nowshahr, Iran.
   [Azar, Omid Pakdel] Malek Ashtar Univ Technol, Fac Naval Aviat, Shiraz, Iran.
C3 Malek Ashtar University of Technology
RP Khishe, M (corresponding author), Imam Khomeini Marine Sci Univ, Dept Elect Engn, Nowshahr, Iran.
EM m_khishe@alumni.iust.ac.ir; omidpakdelazar@srbiau.ac.ir
RI Khishe, Mohammad/AAQ-9814-2021
OI Khishe, Mohammad/0000-0002-1024-8822
FU open research fund program of state key laboratory of hydroscience and
   engineering of Tsinghua university [sklhse-2020-A-01]
FX This work was supported by the open research fund program of state key
   laboratory of hydroscience and engineering of Tsinghua university (Grant
   No: sklhse-2020-A-01)
CR Ballester P, 2016, AAAI CONF ARTIF INTE, P1124
   Ban YX, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11132012
   BOURLARD H, 1988, BIOL CYBERN, V59, P291, DOI 10.1007/BF00332918
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Cao B, 2021, IEEE T NETW SCI ENG, V8, P2756, DOI 10.1109/TNSE.2021.3057915
   Cao B, 2021, IEEE T INTELL TRANSP, V22, P3841, DOI 10.1109/TITS.2021.3059455
   Cao B, 2021, IEEE INTERNET THINGS, V8, P3099, DOI 10.1109/JIOT.2020.3033473
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Cheng L, 2022, IEEE SIGNAL PROC MAG, V39, P18, DOI 10.1109/MSP.2022.3198201
   Dai BL, 2022, IEEE T MICROW THEORY, V70, P3838, DOI 10.1109/TMTT.2022.3186326
   Feng YN, 2022, IEEE T THZ SCI TECHN, V12, P678, DOI 10.1109/TTHZ.2022.3203308
   Fu LS, 2018, IFAC PAPERSONLINE, V51, P45, DOI 10.1016/j.ifacol.2018.08.059
   He K, 2016, RESNET P IEEE COMP S
   Hu TQ, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102764
   Huang NT, 2023, INT J ELEC POWER, V145, DOI 10.1016/j.ijepes.2022.108651
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Khishe M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113338
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larochelle H, 2007, EMPIRICAL EVALUATION, DOI DOI 10.1145/1273496.1273556
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 2015, Lenet-5, convolutional neural networks
   Li QH, 2022, MEASUREMENT, V188, DOI 10.1016/j.measurement.2021.110544
   Li RH, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3208465
   Liao X, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103244
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liu HR, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11203264
   Liu RJ, 2021, MOBILE NETW APPL, V26, P3, DOI 10.1007/s11036-020-01717-x
   Liu YQ, 2022, IEEE T MICROW THEORY, V70, P4399, DOI 10.1109/TMTT.2022.3197593
   Piri J, 2022, IEEE ACCESS, V10, P100376, DOI 10.1109/ACCESS.2022.3203400
   Piri J, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10152742
   Piri J, 2022, IEEE ACCESS, V10, P1756, DOI 10.1109/ACCESS.2021.3138403
   Popescu V, 2018, P S COMP ARITHM, P1, DOI 10.1109/ARITH.2018.8464801
   Postel J., 1980, ACM SIGCOMM Computer Communication Review, V10, P12, DOI [10.1145/1040132.1040133, DOI 10.1145/1040132.1040133]
   Qin XM, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11152321
   Rifai S., 2011, CONTRACTIVE AUTOENCO, DOI DOI 10.5555/3104482.3104587
   Shi YF, 2023, IEEE T PATTERN ANAL, V45, P4882, DOI 10.1109/TPAMI.2022.3186876
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohn K, 2013, LEARNING SELECTING F
   Sohn Kihyuk., 2012, Learning invariant representations with local transformations
   Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811
   Suganuma M, 2017, PROCEEDINGS OF THE 2017 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'17), P497, DOI 10.1145/3071178.3071229
   Sun B, 2022, ENERGY REP, V8, P4209, DOI 10.1016/j.egyr.2022.03.078
   Sun YA, 2020, IEEE T EVOLUT COMPUT, V24, P394, DOI 10.1109/TEVC.2019.2916183
   Szegedy C., 2014, P IEEE COMP SOC C CO
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Tomkins J., 2012, J CREAT, V26, P94
   Wang WC, 2022, SIGNAL PROCESS-IMAGE, V106, DOI 10.1016/j.image.2022.116742
   Webb G.I., 2011, ENCY MACHINE LEARNIN
   Wu C, 2023, SOFT COMPUT, V27, P3307, DOI 10.1007/s00500-021-05839-6
   Xiao H., 2017, ARXIV170807747
   Xiao S, 2023, IEEE T CIRCUITS-II, V70, P1194, DOI 10.1109/TCSII.2022.3223984
   Xu KD, 2021, IEEE ELECTR DEVICE L, V42, P1120, DOI 10.1109/LED.2021.3091277
   Xu S, 2022, IEEE T INSTRUM MEAS
   Yang M, 2022, IEEE J OCEANIC ENG, V47, P704, DOI 10.1109/JOE.2021.3126090
   Ye DH, 2013, ICLR17
   Zhang H, 2022, IEEE T INTELL TRANSP, V23, P12633, DOI 10.1109/TITS.2021.3115823
   Zhang ZY, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103261
   Zhou WY, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107819
   Zhou WJ, 2021, IEEE T SYST MAN CY-S, V51, P3641, DOI 10.1109/TSMC.2019.2957386
   Zhou WJ, 2018, IEEE T IMAGE PROCESS, V27, P2086, DOI 10.1109/TIP.2018.2794207
   Zhou XX, 2022, APPL INTELL, V52, P12556, DOI 10.1007/s10489-021-03121-8
NR 62
TC 7
Z9 7
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 16
PY 2023
DI 10.1007/s11042-023-15411-z
EA MAY 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G5FI8
UT WOS:000989408100003
DA 2024-07-18
ER

PT J
AU Shastri, S
   Thanikaiselvan, V
AF Shastri, Shounak
   Thanikaiselvan, V.
TI Interpolation based dual image reversible data hiding using trinary
   encoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Dual image reversible data hiding; Interpolation; Trinary encoding;
   Location map; High visual quality; Security
ID SCHEME; EXPANSION; ALGORITHM; CAPACITY; STRATEGY
AB This work proposes a Dual Image Reversible Data Hiding (DIRDH) scheme using interpolation and trinary encoding of secret data. Trinary encoding shows promise because it encodes 3-bit binary data to 2-bit trinary data from the set {-1, 0, 1}. This can be directly used as shifts in the cover pixel values to embed the data without any further processing. The main issue is that the encoding generates similar codes for some combinations of binary bits and makes it necessary to use auxiliary data. Thus, the auxiliary data becomes very difficult to handle with increasing payloads and needs to be sent as a separate file to the receiver. The proposed scheme avoids this problem by using interpolation to create space for the secret data while completely eliminating the need for auxiliary data. The original image is first interpolated to create the cover image and the trinary encoding is used to generate the shifts. The shifts are added to the interpolated pixels to generate the stego image. The modification to the processing of the cover image helps to eliminate the location map completely. Results show that the stego images have an average Peak Signal to Noise Ratio (PSNR) of 50.42 dB while improving the effective embedding capacity from 1.1 bits per pixel (bpp) to 1.2bpp. This is an improvement of about 9% over the previous trinary encoding schemes.
C1 [Shastri, Shounak; Thanikaiselvan, V.] VIT, Sch Elect Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Thanikaiselvan, V (corresponding author), VIT, Sch Elect Engn, Vellore, Tamil Nadu, India.
EM shounak.shastri@gmail.com; thanikaiselvan@vit.ac.in
OI Thanikaiselvan, V/0000-0003-2418-5217
CR Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Agrawal S, 2017, OPTIK, V130, P922, DOI 10.1016/j.ijleo.2016.11.059
   [Anonymous], 2007, TENCON 2007 2007 IEE
   [Anonymous], WATERLOO GREYSCALE I
   Arham A, 2017, SIGNAL PROCESS, V137, P52, DOI 10.1016/j.sigpro.2017.02.001
   Bhardwaj R, 2019, OPTIK, V181, P1099, DOI 10.1016/j.ijleo.2018.12.130
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P145, DOI 10.1109/MUE.2009.35
   Chen SS, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103064
   Franzen Rich, 1999, KODAK LOSSLESS TRUE, V4
   Govind PVS, 2015, PROCEDIA COMPUT SCI, V46, P491, DOI 10.1016/j.procs.2015.02.073
   Jafar IF, 2016, SIGNAL PROCESS, V128, P98, DOI 10.1016/j.sigpro.2016.03.023
   Jana B, 2016, OPTIK, V127, P3347, DOI 10.1016/j.ijleo.2015.12.055
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2009, IEEE SIGNAL PROC LET, V16, P69, DOI 10.1109/LSP.2008.2008947
   Lin JY, 2019, MULTIMED TOOLS APPL, V78, P25855, DOI 10.1007/s11042-019-07783-y
   Lu TC, 2020, IEEE ACCESS, V8, P90824, DOI 10.1109/ACCESS.2020.2994244
   Lu TC, 2019, MULTIMED TOOLS APPL, V78, P34397, DOI 10.1007/s11042-019-07904-7
   Lu TC, 2017, OPTIK, V130, P1377, DOI 10.1016/j.ijleo.2016.11.176
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Lu TC, 2015, SIGNAL PROCESS, V108, P77, DOI 10.1016/j.sigpro.2014.08.022
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Sellahewa H, 2013, MOBILE MULTIMEDIA IM, P63
   Shaji C, 2020, MULTIMED TOOLS APPL, V79, P26969, DOI 10.1007/s11042-020-09273-y
   Shastri S, 2019, J VIS COMMUN IMAGE R, V61, P130, DOI 10.1016/j.jvcir.2019.03.022
   Tang ZJ, 2018, OPTIK, V157, P750, DOI 10.1016/j.ijleo.2017.11.154
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tzu-Chen L., 2021, J COMPUT, V32, P1
   Wang JX, 2019, IEEE ACCESS, V7, P35564, DOI 10.1109/ACCESS.2019.2903079
   Wu HT, 2019, IEEE ACCESS, V7, P83332, DOI 10.1109/ACCESS.2019.2921407
   Yao H, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0281-y
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 38
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 16
PY 2023
DI 10.1007/s11042-023-15574-9
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G5FI8
UT WOS:000989408100002
DA 2024-07-18
ER

PT J
AU Thakur, N
   Bhattacharjee, E
   Jain, R
   Acharya, B
   Hu, YC
AF Thakur, Narina
   Bhattacharjee, Eshanika
   Jain, Rachna
   Acharya, Biswaranjan
   Hu, Yu-Chen
TI Deep learning-based parking occupancy detection framework using ResNet
   and VGG-16
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Convolutional neural network; Deep learning; Parking space detection;
   Parking space classification; Smart parking
AB The rise in traffic congestion today has necessitated growing research and development in parking management systems to provide real-time indications of the occupancy of indoor and outdoor parking spaces. The main challenge has been developing affordable detection methods based on images to substitute the more expensive sensor-based techniques deployed in indoor environments. With the advancement in computer vision and deep learning, we aim to harness the remarkable performance of convolutional neural networks for carrying out image category recognition tasks to develop a robust parking occupancy detection framework. The classifier was modeled and evaluated with the help of the features learned by the model from the PKLot dataset under varied illuminance and weather conditions. These two models used for parking space detection and classification include - Resnet50 (combined with support vector machine) and VGG16 (combined with OpenCV functionalities). An accuracy of 98.9% was reported with the ResNet and support vector machine model. The model using VGG16 reported an accuracy of 93.4%. Thereby, a low-cost and reliable solution to parking occupancy systems in outdoor systems was arrived at.
C1 [Thakur, Narina] Amity Univ, Dept Comp Sci & Engn, Dubai, U Arab Emirates.
   [Bhattacharjee, Eshanika] Bharati Vidyapeeths Coll Engn, Dept Comp Sci & Engn, New Delhi, India.
   [Jain, Rachna] Bhagwan Parshuram Inst Technol, Dept Informat Technol, New Delhi, India.
   [Acharya, Biswaranjan] Marwadi Univ, Dept Comp Engn AI & BDA, Rajkot, Gujarat, India.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung, Taiwan.
   [Hu, Yu-Chen] TungHai Univ, Dept Comp Sci, Taichung, Taiwan.
C3 Bhagwan Parshuram Institute of Technology; Marwadi University;
   Providence University - Taiwan; Tunghai University
RP Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, Taichung, Taiwan.; Hu, YC (corresponding author), TungHai Univ, Dept Comp Sci, Taichung, Taiwan.
EM narinat@gmail.com; esha342000@gmail.com; rachinajain@bpitindia.com;
   acharya.biswa85@gmail.com; ychu@pu.edu.tw
RI Acharya, Biswaranjan/AAL-1977-2020; Thakur, Dr. Narina/KFR-3104-2024
OI Acharya, Biswaranjan/0000-0002-6506-9207; Thakur, Dr.
   Narina/0000-0002-1625-1280; Hu, Yu-Chen/0000-0002-5055-3645; Jain,
   Rachna/0000-0002-1819-550X
CR Acharya D, 2018, RES LOCATE
   Amato G, 2017, EXPERT SYST APPL, V72, P327, DOI 10.1016/j.eswa.2016.10.055
   Amato G, 2016, 2016 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC), P1212, DOI 10.1109/ISCC.2016.7543901
   Atouf I., 2020, INT J POWER ELECT DR, V114, P2091
   Bura H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON COGNITIVE COMPUTING (ICCC), P17, DOI 10.1109/ICCC.2018.00010
   Cai BY, 2019, IEEE INTERNET THINGS, V6, P7693, DOI 10.1109/JIOT.2019.2902887
   Chen LC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10031079
   Choi J, 2015, MULTIMED TOOLS APPL, V74, P3277, DOI 10.1007/s11042-014-1862-0
   Dai Z, 2019, IEEE ACCESS, V7, P64460, DOI 10.1109/ACCESS.2019.2914254
   de Almeida PRL, 2015, EXPERT SYST APPL, V42, P4937, DOI 10.1016/j.eswa.2015.02.009
   Duan T, 2005, P INT C COMP SCI RIV, V1
   Farley A, 2021, PROCEDIA COMPUT SCI, V179, P606, DOI 10.1016/j.procs.2021.01.046
   Goumiri S, 2021, IEEE INT SM C CONF, DOI 10.1109/ISC253183.2021.9562946
   Hung BT, 2022, P 2 INT C ART INT AD, P501
   informer, CONV OPERATION PROGR
   Jiang SK, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10124295
   kaggle, VGG ARCHITECTURE
   Lee MR, 2019, MULTIMED TOOLS APPL, V78, P6827, DOI 10.1007/s11042-018-6394-6
   Liu HB, 2019, MULTIMED TOOLS APPL, V78, P29161, DOI 10.1007/s11042-018-6667-0
   Mármol E, 2016, MULTIMED TOOLS APPL, V75, P17711, DOI 10.1007/s11042-016-3773-8
   medium, TYPES LAYERS CNN MED
   Meshram SA, 2013, INT J ADV RES COMPUT, V1, P169
   Ng CK, 2020, LECT NOTES ELECTR EN, V603, P247, DOI 10.1007/978-981-15-0058-9_24
   Ninnemann J., 2022, ARXIV
   Nyambal J, 2017, 2017 PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA AND ROBOTICS AND MECHATRONICS (PRASA-ROBMECH), P1, DOI 10.1109/RoboMech.2017.8261114
   Ordonia S, 2019, THESIS SAN JOSE STAT
   Ozbay S, 2005, PROC WRLD ACAD SCI E, V9, P222
   Padmasiri H, 2020, 2020 MOR ENG RES C M
   Rahman S, 2020, 2020 INT C EL ENG IN
   ResNet architecture (machine learning knowledge), US
   Salvi G, 2012, P INT C IM PROC COMP
   Shapiro V, 2006, MACH VISION APPL, V17, P173, DOI 10.1007/s00138-006-0023-5
   Siddiqui S, 2020, J KING SAUD U COMPUT
   Thinh T, 2021, 2021 INT C ADV TECHN
   Thomas D, 2018, PROCEDIA COMPUT SCI, V125, P68, DOI 10.1016/j.procs.2017.12.011
   Tschentscher M, 2015, IEEE IJCNN
   Wang Y, 2020, 2020 IEEE RSJ INT C
   Wu Q, 2007, 2007 IEEE INT C MULT
   Zhang JD, 2021, MULTIMED TOOLS APPL, V80, P18181, DOI 10.1007/s11042-020-10370-1
   Zheng ZZ, 2013, IEEE J-STARS, V6, P2338, DOI 10.1109/JSTARS.2013.2266131
   Zhou TF, 2020, AAAI CONF ARTIF INTE, V34, P13066
NR 41
TC 3
Z9 3
U1 7
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 11
PY 2023
DI 10.1007/s11042-023-15654-w
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G1LI4
UT WOS:000986851800010
DA 2024-07-18
ER

PT J
AU Paul, B
   Phadikar, S
AF Paul, Bachchu
   Phadikar, Santanu
TI A hybrid feature-extracted deep CNN with reduced parameters substitutes
   an End-to-End CNN for the recognition of spoken Bengali digits
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hybrid feature; Mel frequency cepstral coefficients; Sub-band energy;
   Isolated word; One-dimensional convolution neural network;
   Hyper-parameter tuning; Max pooling
ID NEURAL-NETWORKS
AB Speech Recognition (SR) is an emerging field in the native language nowadays. Recognizing isolated words in the local language helps people use smartphones and electronic gadgets without technical or educational knowledge. This paper proposes a novel deep Convolutional Neural Network (CNN) architecture to classify ten spoken Bengali numerals. The proposed model generates almost similar prediction accuracy as compared to an end-to-end CNN with nine times fewer parameters has been trained. Here, the raw audio samples are pre-processed, and then a unique hybrid feature of Mel Frequency Cepstral Coefficients (MFCC), Spectral Sub-band Energy (SSE), and Log Spectral Sub-band Energy (LSSE) have been extracted frame-wise and engendered into a vector. Finally, these vectors are fed to the proposed architecture of a one-dimensional CNN and achieve the highest test accuracy of 98.52%. The model has been trained for our created speech corpus of 14000 spoken Bengali digits and 30000 spoken English digits from the audio-MNIST dataset. The proposed neural model generates high prediction accuracy with a few times fewer parameters to be trained, generating low computational costs. The outcome of the proposed model is compared with several pre trained deep learning models; the result shows the model's superiority. Source Code: https:// github.com/BachchuPaul/Bengali-Isolated-Spoken-Digit.
C1 [Paul, Bachchu] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, West Bengal, India.
   [Phadikar, Santanu] Maulana Abul Kalam Azad Univ Technol, Dept Comp Sci & Engn, BF 142,Sector 1, Kolkata 700064, West Bengal, India.
C3 Vidyasagar University; Maulana Abul Kalam Azad University of Technology
RP Paul, B (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, West Bengal, India.
EM ableb.paul@gmail.com; sphadikar@yahoo.com
OI Paul, Bachchu/0000-0002-4485-3393
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Ahammad K, 2016, INT J COMPUTER APPL, V149, P38
   Becker S, 2023, Arxiv, DOI [arXiv:1807.03418, 10.48550/arXiv.1807.03418, DOI 10.48550/ARXIV.1807.03418]
   Dikmese S, 2016, IEEE T SIGNAL PROCES, V64, P131, DOI 10.1109/TSP.2015.2480048
   Dimmita N., 2018, International Journal of Engineering Technology, V7, P133, DOI DOI 10.14419/IJET.V7I4.6.20449
   Du GM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P708, DOI 10.1109/SIPROCESS.2016.7888355
   Ferrer Luciana, 2016, IEEE/ACM Transactions on Audio, Speech and Language Processing, V24, P105, DOI 10.1109/TASLP.2015.2496226
   Gamit M., 2015, International Journal of Research in Engineering and Technology, V4, P146, DOI DOI 10.15623/IJRET.2015.0406024
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Grozdic DT, 2017, ENG APPL ARTIF INTEL, V59, P15, DOI 10.1016/j.engappai.2016.12.012
   Gupta A, 2018, INT ARAB J INF TECHN, V15, P263
   Kadyan V, 2019, INT J SPEECH TECHNOL, V22, P111, DOI 10.1007/s10772-018-09577-3
   Kaur G., 2017, INT J EMERG RES MANA, V6, P8
   Kondhalkar H, 2019, J ENG SCI TECHNOL, V14, P726
   Krishnamoorthy P, 2011, SPEECH COMMUN, V53, P154, DOI 10.1016/j.specom.2010.08.011
   Lisa NJ, 2010, INT J COMPUT SCI NET, V10, P96
   Mahalingam H., 2019, Int J Adv Comput Sci Cloud Comput, V7, P12
   Masmoudi S, 2011, INT J SPEECH TECHNOL, V14, P1, DOI 10.1007/s10772-010-9082-0
   Nicolson A., 2018, INT J SIGNAL PROCESS, V6, P12, DOI DOI 10.18178/IJSPS.6.1.12-16
   Palaz D, 2015, INT CONF ACOUST SPEE, P4295, DOI 10.1109/ICASSP.2015.7178781
   Paul Bachchu, 2022, Computational Intelligence in Pattern Recognition: Proceedings of CIPR 2021. Advances in Intelligent Systems and Computing (1349), P85, DOI 10.1007/978-981-16-2543-5_8
   Paul Bachchu, 2022, Computational Intelligence in Pattern Recognition: Proceedings of CIPR 2021. Advances in Intelligent Systems and Computing (1349), P231, DOI 10.1007/978-981-16-2543-5_20
   Paul Bachchu, 2021, Advances in Electronics, Communication and Computing. Select Proceedings of ETAEERE 2020. Lecture Notes in Electrical Engineering (LNEE 709), P85, DOI 10.1007/978-981-15-8752-8_9
   Paul Bachchu, 2021, Proceedings of the Sixth International Conference on Mathematics and Computing. ICMC 2020. Advances in Intelligent Systems and Computing (AISC 1262), P263, DOI 10.1007/978-981-15-8061-1_21
   Paul B, 2019, INT C INT COMP COMM, P511
   Pawar GS, 2014, INT J ADV RES COMPUT, V4
   Qadir JA, 2020, INT J FUZZY LOG INTE, V20, P272, DOI 10.5391/IJFIS.2020.20.4.272
   Sarma M., 2017, INT J INTELL SYST CO, V1, P71
   Sharmin Riffat, 2020, Procedia Computer Science, V171, P1381, DOI 10.1016/j.procs.2020.04.148
   Shukla S, 2021, INT J SPEECH TECHNOL, V24, P797, DOI 10.1007/s10772-021-09851-x
   Si SJ, 2021, Arxiv, DOI arXiv:2107.04803
   Siniscalchi SM, 2013, NEUROCOMPUTING, V106, P148, DOI 10.1016/j.neucom.2012.11.008
   Song ZJ, 2020, COMPUTING, V102, P663, DOI 10.1007/s00607-019-00753-0
   Sumon SA, 2018, 2018 INTERNATIONAL CONFERENCE ON BANGLA SPEECH AND LANGUAGE PROCESSING (ICBSLP)
   Tripathi AM, 2022, APPL ACOUST, V195, DOI 10.1016/j.apacoust.2022.108813
   VANI H, 2020, INT J COMPUTER APPL, V177, P39, DOI DOI 10.5120/IJCA2020919989
   Veisi H, 2020, INT J SPEECH TECHNOL, V23, P893, DOI 10.1007/s10772-020-09768-x
NR 37
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 9
PY 2023
DI 10.1007/s11042-023-15598-1
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F9KB5
UT WOS:000985452800011
DA 2024-07-18
ER

PT J
AU Bhargava, A
   Bansal, A
   Goyal, V
   Shukla, A
AF Bhargava, Anuja
   Bansal, Atul
   Goyal, Vishal
   Shukla, Aasheesh
TI Machine learning & computer vision-based optimum black tea fermentation
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tea; Computer vision; Machine learning; Statistical; Textural; DWT
AB The world's high-value crop is tea, its aspect plays a powerful role in its marketability. Tea is the utmost extensively absorbed aromatic beverage with the legion of health benefit and respond as a remedy for various disease like neurological disorder and cardiovascular. The identification of tea fermentation is onerous due to the heavy production of products. The manual investigation is expensive, laborious, and inconsistent. Thus, an automated machine learning-based algorithm is proposed for the grading of tea fermentation (fermented, over-fermented, under-fermented). Firstly, images are pre-processed by Gaussian filtering to enhance the quality of the image and removing of noise. Then various features namely, statistical, textural, color, geometrical, laws texture energy, the histogram of gradients, and discrete wavelet transform are extracted (150) and selected from feature vector by PCA. Lastly, k-NN, SRC, and SVM are used to make decisions for the detection of tea fermentation levels. The performance of the system has been validated by the k (10) fold cross-validation technique. The proposed algorithm achieves 87.39% (k-NN), 89.72% (SRC), and 98.75% (SVM) for tea fermentation level detection. The proper feature selection shows the enhanced performance of the system. Among three different classifiers, SVM shows more efficient results that are promising and comparable with the literature. This paper also includes the analytical comparison of distinct approaches proposed by the different researchers for tea fermentation level detection. This potential fermentation level detection may guide the detection of tea products which further promotes the development of the food industry.
C1 [Bhargava, Anuja; Bansal, Atul; Goyal, Vishal; Shukla, Aasheesh] GLA Univ, Mathura, India.
C3 GLA University
RP Bhargava, A (corresponding author), GLA Univ, Mathura, India.
EM anuja1012@gmail.com; atul.bansal@gla.ac.in; vishal.goyal@gla.ac.in;
   aasheesh.shukla@gla.ac.in
RI BHARGAVA, ANUJA/AAP-5094-2021; shukla, Aasheesh/W-7189-2018
OI BHARGAVA, ANUJA/0000-0002-2387-2552; 
CR [Anonymous], 2018, EC TIMES
   Bakhshipour A, 2020, J FOOD MEAS CHARACT, V14, P1402, DOI 10.1007/s11694-020-00390-8
   Bhargava A, 2021, J KING SAUD UNIV-COM, V33, P243, DOI 10.1016/j.jksuci.2018.06.002
   Bhargava A, 2021, FOOD ANAL METHOD, V14, P1359, DOI 10.1007/s12161-021-01970-0
   Bhargava A, 2020, MULTIMED TOOLS APPL, V79, P22989, DOI 10.1007/s11042-020-09036-9
   Bhargava A, 2020, FOOD ANAL METHOD, V13, P751, DOI 10.1007/s12161-019-01690-6
   Bhargava A, 2020, MULTIMED TOOLS APPL, V79, P7857, DOI 10.1007/s11042-019-08564-3
   Borah S, 2007, J FOOD ENG, V79, P629, DOI 10.1016/j.jfoodeng.2006.02.022
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cheng G, 2020, IEEE J-STARS, V13, P3735, DOI 10.1109/JSTARS.2020.3005403
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Dorj UO, 2017, COMPUT ELECTRON AGR, V140, P103, DOI 10.1016/j.compag.2017.05.019
   downtoearth.org, 2020, US
   Hall JG, 2013, COMPUTER, V46, P85, DOI 10.1109/MC.2013.42
   India at a glance, 2018, IND GLANC FAO IND
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Karak T, 2010, FOOD RES INT, V43, P2234, DOI 10.1016/j.foodres.2010.08.010
   Kimutai G, 2021, J SENS SENS SYST, V10, P153, DOI 10.5194/jsss-10-153-2021
   Mamta S, HORTICULTURAL STAT G
   Meng LW, 2020, MICROCHEM J, V153, DOI 10.1016/j.microc.2019.104512
   Moallem Payman, 2017, Information Processing in Agriculture, V4, P33, DOI 10.1016/j.inpa.2016.10.003
   Ou X, 2014, INT J PHARMACEUT, V460, P28, DOI 10.1016/j.ijpharm.2013.10.024
   Ren GX, 2021, MICROCHEM J, V160, DOI 10.1016/j.microc.2020.105600
   Wen XH, 2013, ENVIRON MONIT ASSESS, V185, P4361, DOI 10.1007/s10661-012-2874-8
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Zhou X, 2018, INT C INT AUT SYST I, DOI [10.1109/ICoIAS.2018.8494051, DOI 10.1109/ICOIAS.2018.8494051]
NR 26
TC 4
Z9 4
U1 11
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43335
EP 43347
DI 10.1007/s11042-023-15453-3
EA MAY 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000982739000004
DA 2024-07-18
ER

PT J
AU Khanna, K
   Gambhir, S
   Gambhir, M
AF Khanna, Ketna
   Gambhir, Sapna
   Gambhir, Mohit
TI A novel technique for classifying Parkinson's disease using structural
   MRI scans
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parkinson's disease; Machine learning; Magnetic resonance imaging;
   Wavelet transform; Fisher discriminant ratio; Local binary pattern; SVM;
   Random forest
ID DIFFERENTIAL-DIAGNOSIS; CLASSIFICATION; FEATURES
AB Parkinson's is a movement-related progressive disorder that causes irreversible damage and heavily derails the patient's life. PD is generally detected via inspection of symptoms and family history by neurologists which may be inefficient, time-consuming and costly to the patient. Although the motor-related signs act as the major contributor to Parkinson's detection, these occur in the later stage of the disease when the symptoms have already intensified. Henceforth, there is a necessity for a Computer Aided Diagnosis (CAD) for an early yet accurate classification of Parkinson's. This work proposes a fusion of 3D- Discrete Wavelet Transform (DWT) and a variant of 3D Local Binary Pattern (LBP) on 3D T1-weighted structural Magnetic Resonance Imaging (sMRI) scans acquired from two publically available databases namely: PPMI and SWADESH for Parkinson's diagnosis. The International dataset has been retrieved from the PPMI database and the Indian dataset has been acquired from SWADESH database. Features have been extracted from the gray matter. Fisher Discriminant Ratio (FDR) has been utilized for selecting relevant features. Support Vector Machine, Logistic Regression, Random forest and K-NN have been used for performing classification. The proposed technique achieved a performance accuracy of 92.45% and 90.57% for data acquired from the PPMI database and SWADESH database respectively. It outperformed the state-of-art techniques with respect to accuracy, sensitivity and specificity. From the results, it has been concluded that the suggested technique has the potential for an early yet effective identification of Parkinson's and can be utilized for clinical diagnosis by neurologists.
C1 [Khanna, Ketna; Gambhir, Sapna] J C Bose Univ Sci & Technol, YMCA, Faridabad 121002, Haryana, India.
   [Gambhir, Mohit] Minist Educ, Delhi 110001, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Khanna, K (corresponding author), J C Bose Univ Sci & Technol, YMCA, Faridabad 121002, Haryana, India.
EM ketnakhanna05@gmail.com
RI Khanna, Ketna/KUD-2096-2024
CR Akanksha J., 2017, INT J COMPUT VIS ROB, V7, P357, DOI [10.1504/IJCVR.2017.10005388, DOI 10.1504/IJCVR.2017.10005388]
   Ali L., 2019, 2019 INT C ELECT COM, DOI 10.1109/ICECCE47252.2019.8940696
   Alzubi JA, 2021, J INTELL FUZZY SYST, V40, P5761, DOI 10.3233/JIFS-189415
   Alzubi O, 2018, INT ARAB J INF TECHN, V15, P76
   Amoroso N, 2018, MED IMAGE ANAL, V48, P12, DOI 10.1016/j.media.2018.05.004
   ATHANASIOS T, 2017, ASSESSMENT PARKINSON, V744, P391
   Baggio HC, 2019, NEUROIMAGE-CLIN, V22, DOI 10.1016/j.nicl.2019.101720
   Celik E, 2019, 2019 SCIENTIFIC MEETING ON ELECTRICAL-ELECTRONICS & BIOMEDICAL ENGINEERING AND COMPUTER SCIENCE (EBBT), DOI 10.1109/ebbt.2019.8742057
   Chakraborty S, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10060402
   Chen Y, 2014, J NEUROSCI METH, V221, P22, DOI 10.1016/j.jneumeth.2013.09.001
   Chen YC, 2020, J NEUROL SCI, V411, DOI 10.1016/j.jns.2020.116721
   Dawn CM., 2018, FDG PET PARKINSONS D
   DeMaagd George, 2015, P T, V40, P504
   Focke NK, 2011, HUM BRAIN MAPP, V32, P1905, DOI 10.1002/hbm.21161
   Hammarlund CS, 2018, PARKINSONS DIS-US, V2018, DOI 10.1155/2018/4598651
   Huang ZW, 2022, IEEE T NEUR NET LEAR, V33, P3357, DOI 10.1109/TNNLS.2021.3052652
   Huertas-Fernández I, 2015, EUR J NUCL MED MOL I, V42, P112, DOI 10.1007/s00259-014-2882-8
   Huppertz HJ, 2016, MOVEMENT DISORD, V31, P1506, DOI 10.1002/mds.26715
   Kamagata K, 2018, NEUROIMAGE-CLIN, V17, P518, DOI 10.1016/j.nicl.2017.11.007
   Khanna K., 2020, J CRIT REV, V7, P1461, DOI [10.31838/jcr.07.18.188, DOI 10.31838/JCR.07.18.188]
   Khanna K, 2022, IEEE DELH SECT C DEL, P1, DOI [10.1109/DELCON54057.2022.9753324, DOI 10.1109/DELCON54057.2022.9753324]
   Khanna K, 2021, DES ENG, V2021, P10307
   Khanna K, 2022, MULTIMED TOOLS APPL, V81, P20705, DOI 10.1007/s11042-022-12671-z
   Laganas C, 2022, IEEE T BIO-MED ENG, V69, P1573, DOI 10.1109/TBME.2021.3116935
   Liaqat A, 2019, RELIABLE PARKINSONS
   Lindholm Terri L, 2009, BMC Med Imaging, V9, P15, DOI 10.1186/1471-2342-9-15
   Liu Luyan, 2016, Med Image Comput Comput Assist Interv, V9901, P1, DOI 10.1007/978-3-319-46723-8_1
   Long D, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047714
   Mabrouk R, 2019, IEEE T RADIAT PLASMA, V3, P170, DOI 10.1109/TRPMS.2018.2877754
   Mallat S., 1998, WAVELET TOUR SIGNAL
   Martinez-Eguiluz M, 2023, NEURAL COMPUT APPL, V35, P5603, DOI 10.1007/s00521-022-07256-8
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T., 2001, Advances in Pattern Recognition - ICAPR 2001. Second International Conference. Proceedings (Lecture Notes in Computer Science Vol.2013), P397
   Prince J, 2018, IEEE ENG MED BIO, P3144, DOI 10.1109/EMBC.2018.8512972
   Prochazka A, 2011, P IASTED INT C GRAPH, P263, DOI DOI 10.2316/P.2011.741-010
   Rana B, 2017, BIOMED SIGNAL PROCES, V34, P134, DOI 10.1016/j.bspc.2017.01.007
   Rubbert C, 2019, BRIT J RADIOL, V92, DOI 10.1259/bjr.20180886
   Sabrina Z, 2022, 10 INT C BIOINF COMP, P116, DOI [10.1109/ICBCB55259.2022.9802132, DOI 10.1109/ICBCB55259.2022.9802132]
   Salvatore C, 2014, J NEUROSCI METH, V222, P230, DOI 10.1016/j.jneumeth.2013.11.016
   Sarica A, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00329
   Segovia F, 2017, FRONT NEUROINFORM, V11, DOI 10.3389/fninf.2017.00023
   Shinde S, 2019, NEUROIMAGE-CLIN, V22, DOI 10.1016/j.nicl.2019.101748
   Singh G, 2018, J NEUROSCI METH, V305, P105, DOI 10.1016/j.jneumeth.2018.05.009
   Soltaninejad S, 2018, COMPUTER VISION PATT
   Song CG, 2021, FRONT COMPUT NEUROSC, V15, DOI 10.3389/fncom.2021.735991
   Stockner H, 2012, MOVEMENT DISORD, V27, P1180, DOI 10.1002/mds.25102
   Worker A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112638
   Zhang C, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.01052
NR 48
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 46011
EP 46036
DI 10.1007/s11042-023-15302-3
EA APR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000979936300006
DA 2024-07-18
ER

PT J
AU Khandelwal, J
   Sharma, VK
AF Khandelwal, Jyoti
   Sharma, Vijay Kumar
TI W-VDSR: wavelet-based secure image transmission using machine learning
   VDSR neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Deep learning; Steganography; Scrambling; VDSR
ID STEGANOGRAPHY; WATERMARKING; ROBUST; DWT; SCHEME
AB Digital communication often uses non-verbal ways to transmit important information. Such as; images, symbols, and different textures. At the time of the wavelet transform, a specific block of image (a small section) is used to hide the secret information. Due to this, the secret image size needs to be changed before the embedding process, and this process also affects the extracted image quality. This paper proposes a secure image steganography technique based on the discrete wavelet transform (DWT) and deep learning (DL) to improve the quality of the stego image and the extracted secret image. In the embedding process initially cover image is transformed into DWT coefficients, then embed the scrambled secret image following by singular value decomposition (SVD) and alpha blending operation. To get the stego image, the inverse discrete wavelet transform (IDWT) is applied. The secret image extraction process is the inverse of the embedding process, but due to the wavelet transform, a compressed secret image is extracted. This secret image resolution is increased using, DL-based very deep super-resolution (VDSR) neural network in post-processing. It converts the extracted image according to the size required by the receiver. The proposed VDSR method is evaluated on a publicly available dataset, the IAPR TC-12 Benchmark (dataset link is given before reference section). The proposed method has a 51.66 to 38.69 dB peak signal-to-noise ratio (PSNR) and a 0.99 structural similarity index (SSIM) for the various alpha values, which is shown in Section 3.3. According to obtained results, there is a 99.9% similarity between the SSIMs of the original and attacked stego images that makes the proposed technique robust. The observed range of SSIM is from 99.9% to 100%.
C1 [Khandelwal, Jyoti; Sharma, Vijay Kumar] Manipal Univ Jaipur, Dept Comp & Commun Engn, Jaipur, India.
C3 Manipal University Jaipur
RP Sharma, VK (corresponding author), Manipal Univ Jaipur, Dept Comp & Commun Engn, Jaipur, India.
EM jyoti.khandelwal19@gmail.com; vijaymayankmudgal2008@gmail.com
OI Khandelwal, Jyoti/0000-0002-3027-258X
CR Abdelwahab AA, 2008, P IEEE SWARM INT S, P1
   Abdullah HN, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND MANAGEMENT (ICICM 2016), P130, DOI 10.1109/INFOCOMAN.2016.7784229
   Acharya UK, 2021, OPTIK, V230, DOI 10.1016/j.ijleo.2021.166273
   Arai K, 2013, INT J WAVELETS MULTI, V11, DOI 10.1142/S0219691313600060
   Arora M, 2020, OPT QUANT ELECTRON, V52, DOI 10.1007/s11082-019-2130-3
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Coelho Luis Pedro, 2013, Journal of Open Research Software, V1, DOI [DOI 10.5334/JORS.AC, 10.5334/jors.ac]
   Dharwadkar NV, 2010, INT J IMAGE GRAPH, V10, P589, DOI 10.1142/S0219467810003901
   Durafe A, 2022, J KING SAUD UNIV-COM, V34, P4483, DOI 10.1016/j.jksuci.2020.10.008
   Garg M, 2023, MULTIMED TOOLS APPL, V82, P6271, DOI 10.1007/s11042-022-13596-3
   Grubinger M., 2006, Language Resources and Evaluation, P13
   Guo Y, 2017, IET IMAGE PROCESS, V11, P406, DOI 10.1049/iet-ipr.2016.0515
   Ho YA, 2008, IMAGING SCI J, V56, P351, DOI 10.1179/174313108X344489
   Hwang JJ, 2020, IMAGNG SCI DENT, V50, P331, DOI 10.5624/isd.2020.50.4.331
   Islam MA., 2021, ADV SCI TECHNOL ENG, V6, P36, DOI [10.25046/aj060205, DOI 10.25046/AJ060205]
   Jia SL, 2017, J APPL SCI ENG, V20, P193, DOI 10.6180/jase.2017.20.2.07
   Kang YH, 2019, CMC-COMPUT MATER CON, V59, P315, DOI 10.32604/cmc.2019.05242
   Kaur G, 2022, ARTIF INTELL REV, VRev56, P1
   Khalifa A, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14071325
   Khandelwal J, 2022, CMC-COMPUT MATER CON, V72, P3299, DOI 10.32604/cmc.2022.023116
   Kumar V, 2019, J INTELL SYST, V28, P749, DOI 10.1515/jisys-2017-0134
   Kwan C, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030308
   Lavanya B, 2017, 2017 INT C EL COMM A
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Modak Prarthana Madan, 2015, International Journal of Science and Research (IJSR), P813
   Mondal B., 2017, ICICCS, P261, DOI [10.15439/2017R47, DOI 10.15439/2017R47]
   Mondal B, 2018, Cryptograph Inf Secur, P37, DOI [10.1201/9780429435461-2, DOI 10.1201/9780429435461-2]
   Nazir H, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6617944
   Shaheed K, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116786
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Shaheed K, 2022, INFORM FUSION, V79, P84, DOI 10.1016/j.inffus.2021.10.004
   Shahi D., 2021, Webology, V18, P133
   Sharma VK, 2018, IET IMAGE PROCESS, V12, P1065, DOI 10.1049/iet-ipr.2017.0965
   Shejul AA, 2010, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON DATA STORAGE AND DATA ENGINEERING (DSDE 2010), P39, DOI 10.1109/DSDE.2010.10
   Thanki R, 2018, J INF SECUR APPL, V40, P92, DOI 10.1016/j.jisa.2018.03.004
   Ubhi JS, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103483
   Vaishnavi D, 2015, PROCEDIA COMPUT SCI, V46, P1770, DOI 10.1016/j.procs.2015.02.130
   Walia S, 2021, IEEE ACCESS, V9, P99742, DOI 10.1109/ACCESS.2021.3096240
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang MS, 2009, COMPUT STAND INTER, V31, P757, DOI 10.1016/j.csi.2008.09.003
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wu LY, 2021, NEUROCOMPUTING, V463, P17, DOI 10.1016/j.neucom.2021.08.048
   Xiong LZ, 2021, IEEE T INF FOREN SEC, V16, P2912, DOI 10.1109/TIFS.2021.3065794
   Yasin DA., 2021, INT J ADV COMPUT SC, V6, P49
NR 45
TC 2
Z9 2
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42147
EP 42172
DI 10.1007/s11042-023-15166-7
EA APR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000964979100001
DA 2024-07-18
ER

PT J
AU Salinas, JG
   Seguí, FB
   Piera, AS
   Castillo, FJP
AF Salinas, Juan Gonzalez
   Segui, Fernando Boronat
   Piera, Almanzor Sapena
   Castillo, Francisco Javier Pastor
TI Key Technologies for Networked Virtual Environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computing models; Data distribution; Data filtering; Networked virtual
   environment; Predictive modeling; Resource balancing; Synchronization
ID DISTRIBUTED INTERACTIVE APPLICATIONS; USER EXPERIENCE; LATENCY;
   ARCHITECTURE; CONSISTENCY; MECHANISM
AB Thanks to the improvements experienced in technology during the last few years, most especially in virtual reality systems, the number and potential of networked virtual environments or NVEs and their users have been increasing. NVEs aim to give distributed users a feeling of immersion in a virtual world and the possibility of interacting with other users or with virtual objects inside it, just like when they interact in the real world. Being able to provide that feeling and natural interactions when the users are geographically separated is one of the goals of these systems. Nevertheless, this goal is especially sensitive to different issues, such as different connections with heterogeneous throughput or particular network latencies, which can lead to consistency and synchronization problems and, thus, to a worsening of the users' quality of experience or QoE. With the purpose of solving these issues, researchers have proposed and evaluated numerous technical solutions, in fields like network architectures, data distribution and filtering, resource balancing, computing models, predictive modeling and synchronization in NVEs. This paper gathers and classifies them, summarizing their advantages and disadvantages, using a new way of classification. With the current increase in the number of NVEs and the multiple solutions proposed so far, this paper aims to become a useful tool and a starting point not only for future researchers in this field but also for those who are new to NVEs development, in which guaranteeing a good users' QoE is essential.
C1 [Salinas, Juan Gonzalez; Segui, Fernando Boronat; Piera, Almanzor Sapena; Castillo, Francisco Javier Pastor] Univ Politecn Valencia UPV, Immers Interact Media IIM R&D Grp, Campus Gandia, Valencia, Spain.
C3 Universitat Politecnica de Valencia
RP Salinas, JG (corresponding author), Univ Politecn Valencia UPV, Immers Interact Media IIM R&D Grp, Campus Gandia, Valencia, Spain.
EM juagons4@epsg.upv.es; fboronat@dcom.upv.es; alsapie@mat.upv.es;
   fjpastor@dib.upv.es
RI Boronat, Fernando/A-3234-2011; Sapena, Almanzor/H-5102-2015
OI Boronat, Fernando/0000-0001-5525-3441; Sapena,
   Almanzor/0000-0001-8473-6063; Gonzalez Salinas, Juan/0000-0002-1005-6038
FU CRUE-CSIC agreement; Springer Nature; ERDF A way of making Europe
   [PEJ2018-003875-A-A, MCIN/AEI/10.13039/501100011033]; Programa I+D+i de
   la Generalitat Valenciana [ACIF/2021/192]
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This work was supported, in part, by Grants
   PEJ2018-003875-A-A and PID2021-126645OB-I00, funded by
   MCIN/AEI/10.13039/501100011033 and by "ERDF A way of making Europe". It
   was also supported, in part, by ACIF/2021/192 from"Programa I+D+i de la
   Generalitat Valenciana".
CR Abdulazeez SA, 2017, I C DEV ESYST ENG, P50, DOI 10.1109/DeSE.2017.19
   acure, About us
   Ademoye OA, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2957753
   Ahmadi H, 2021, IEEE ACCESS, V9, P12332, DOI 10.1109/ACCESS.2021.3050489
   Alcañiz M, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01530
   Amar Yousef, 2019, IEEE CONF COMPU INTE, P1, DOI [10.1109/CIG.2019.8847958, DOI 10.1109/cig.2019.8847958]
   Amiri M, 2017, 15 ANN WORKSH NETW S, P1, DOI [10.1109/NetGames.2017.7991546, DOI 10.1109/NETGAMES.2017.7991546]
   [Anonymous], 2015, VIRT REAL M
   [Anonymous], FUT VIS
   [Anonymous], 2018, MOZ HUBS
   [Anonymous], 2004, UNR ENG
   [Anonymous], 2019, GOOGL STAD
   [Anonymous], 2019, CALL DUT MOD WARF
   [Anonymous], Steam Remote Play
   [Anonymous], WILD
   [Anonymous], 2018, DEEP LEARN SUP SAMPL
   [Anonymous], 2004, WORLD WARCR
   [Anonymous], 2004, City of Heroes
   [Anonymous], 2015, GEFORCE NOW
   [Anonymous], 2003, Second Life
   [Anonymous], 2017, Destiny 2
   [Anonymous], PLAY YOU DOWNLOAD
   Aung Su Thandar, 2020, 2020 IEEE Region 10 Conference (TENCON), P1266, DOI 10.1109/TENCON50793.2020.9293934
   Avni S., 2010, J FISH WILDL MANAG, P169, DOI [10.5555/1839214.1839244, DOI 10.5555/1839214.1839244]
   Bamutange Brian, 2020, 2020 3rd International Conference on Emerging Trends in Electrical, Electronic and Communications Engineering (ELECOM), P173, DOI 10.1109/ELECOM49001.2020.9296989
   Barman N, 2018, PROCEEDINGS OF THE 23TH ACM WORKSHOP ON PACKET VIDEO (PV'18), P7, DOI 10.1145/3210424.3210434
   Battle.net, 2013, US
   Bhojan A, 2020, MULTIMED TOOLS APPL, V79, P32503, DOI 10.1007/s11042-020-09612-z
   Bigscreen, 2019, US
   Bonomi Flavio, 2012, P 1 MCC WORKSH MOB C, P13, DOI 10.1145/2342509.2342513
   Boronat F, 2009, INFORM SYST, V34, P108, DOI 10.1016/j.is.2008.05.001
   Bouras CJ., 2011, GAMING SIMULATIONS, P7, DOI [10.4018/9781609601959.ch413, DOI 10.4018/9781609601959.CH413]
   Boutaba R, 2018, J INTERNET SERV APPL, V9, DOI 10.1186/s13174-018-0087-2
   Buyukkaya E, 2015, PEER PEER NETW APPL, V8, P276, DOI 10.1007/s12083-013-0231-5
   Calvin J., 1993, 1993 IEEE ANN VIRTUA, P450
   Capece Nicola, 2019, 2019 15th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS), P603, DOI 10.1109/SITIS.2019.00123
   Carlini E, 2019, J GRID COMPUT, V17, P45, DOI 10.1007/s10723-018-9470-2
   CARLSSON C, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P394, DOI 10.1109/VRAIS.1993.380753
   CAVRNUS, US
   Çevikbas SB, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1808
   Chan A., 2001, Proc. ACM Symposium on Virtual Reality Software and Technology, P135
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Chen JF, 2005, AINA 2005: 19TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 2, P377
   Chen YF, 2018, SIGSIM-PADS'18: PROCEEDINGS OF THE 2018 ACM SIGSIM CONFERENCE ON PRINCIPLES OF ADVANCED DISCRETE SIMULATION, P105, DOI 10.1145/3200921.3200939
   Cipresso P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02086
   Covaci A, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2378, DOI 10.1145/3343031.3350954
   Cristea DS, 2019, DUNAREA JOS U GALATI, P172, DOI [10.35219/eai1584040948, DOI 10.35219/EAI1584040948]
   Cronin E, 2004, MULTIMED TOOLS APPL, V23, P7, DOI 10.1023/B:MTAP.0000026839.31028.9f
   De Alwis Chamitha, 2021, IEEE Open Journal of the Communications Society, V2, P836, DOI 10.1109/OJCOMS.2021.3071496
   de Back TT, 2020, INT J EDUC TECHNOL H, V17, DOI 10.1186/s41239-020-00228-9
   De Grande RE, 2017, IEEE T PARALL DISTR, V28, P215, DOI 10.1109/TPDS.2016.2552174
   de Regt A., 2019, ACAD MARKETING SCI W, P945, DOI [10.1007/978-3-030-02568-7_269, DOI 10.1007/978-3-030-02568-7_269]
   Decentraland, 2020, US
   Delaney D, 2006, PRESENCE-TELEOP VIRT, V15, P465, DOI 10.1162/pres.15.4.465
   Dellaney D, 2006, PRESENCE-VIRTUAL AUG, V15, P218, DOI 10.1162/pres.2006.15.2.218
   Dias DRC, 2015, 30TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, VOLS I AND II, P480, DOI 10.1145/2695664.2695762
   Din SU, 2019, INT ARAB CONF INF TE, P222, DOI [10.1109/acit47987.2019.8991020, 10.1109/ACIT47987.2019.8991020]
   DROVA, US
   Dupont F, 2010, COLLABORATIVE SCI VI
   Engelbrecht HA, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3105577
   Eu, 2016, P 2016 ACM MULT C MM, P737, DOI [10.1145/2964284.2973827, DOI 10.1145/2964284.2973827]
   Farooq U, 2017, VIRTUAL REAL-LONDON, V21, P193, DOI 10.1007/s10055-017-0307-2
   FastStart, 2018, US
   Ferretti S., 2007, International Journal of Computers & Applications, V29, P33
   Ferretti S, 2008, MULTIMED TOOLS APPL, V37, P339, DOI 10.1007/s11042-007-0163-2
   Ferscha A, 2001, PARALLEL DISTRIBUTED, DOI [10.5555/193923, DOI 10.5555/193923]
   Fleury C., 2010, P JVRC, P29, DOI [10.2312/EGVE/JVRC10/029-036, DOI 10.2312/EGVE/JVRC10/029-036]
   Fleury C, 2010, ARCHITECTURES MECH M
   Freitas AC, 2020, LECT NOTES COMPUT SC, V12255, P771, DOI 10.1007/978-3-030-58820-5_55
   Gautier L, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P233, DOI 10.1109/MMCS.1998.693647
   Gilbert S., 2002, SIGACT News, V33, P51, DOI 10.1145/564585.564601
   Godot, 2007, US
   Gül S, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3632, DOI 10.1145/3394171.3413699
   He ZY, 2020, INT SYM MIX AUGMENT, P542, DOI 10.1109/ISMAR50242.2020.00082
   Herscher S, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1137, DOI 10.1145/3332165.3347929
   Hong HJ, 2015, IEEE T CIRC SYST VID, V25, P2078, DOI 10.1109/TCSVT.2015.2450173
   Hoshino S., 2011, P IEEE INT WORKSH TE, P1, DOI [10.1109/CQR.2011.5996082, DOI 10.1109/CQR.2011.5996082]
   Hou LQ, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON MECHANICAL, CONTROL AND COMPUTER ENGINEERING (ICMCCE 2020), P1948, DOI 10.1109/ICMCCE51767.2020.00427
   Huang P., 2018, MEDIASYNC HDB MULTIM, P149, DOI [10.1007/978-3-319-65,840-7_5, DOI 10.1007/978-3-319-65,840-7_5]
   Huang P., 2012, INT J COMMUN NETW SY, V5, P321, DOI [10.4236/ijcns.2012.56042, DOI 10.4236/IJCNS.2012.56042]
   Ida Y., 2010, Proceedings of the 9th Annual Workshop on Network and Systems Support for Games, NetGames 2010, P10, DOI [10.1109/NETGAMES.2010.5680283, DOI 10.1109/NETGAMES.2010.5680283]
   Illahi GK, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3369110
   IMVU, 2004, US
   Jiankun Zhang, 2021, 2021 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunication Engineering, P327, DOI 10.1109/ECTIDAMTNCON51128.2021.9425762
   Jiayi Meng, 2020, ASPLOS '20: Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, P923, DOI 10.1145/3373376.3378516
   Kaminski B, 2018, CENT EUR J OPER RES, V26, P135, DOI 10.1007/s10100-017-0479-6
   Kanellopoulos DN., 2019, ADV METHODOLOGIES TE, P229, DOI [10.4018/978-1-5225-7601-3.ch019, DOI 10.4018/978-1-5225-7601-3.CH019]
   Karuvally Aswin Babu, 2018, 2018 International CET Conference on Control, Communication, and Computing (IC4), P317, DOI 10.1109/CETIC4.2018.8531062
   Khan AM., 2008, 8 INT C NEW TECHNOLO, P42, DOI [10.1145/1416729.1416783, DOI 10.1145/1416729.1416783]
   Kharitonov VY, 2013, P INT COMP SOFTW APP, P696, DOI 10.1109/COMPSAC.2013.111
   Kim J., 2005, 7 WORKSH MULT SIGN P, P1, DOI [10.1109/MMSP.2005.248612, DOI 10.1109/MMSP.2005.248612]
   Kingspray, 2016, US
   Knutsson B, 2004, IEEE INFOCOM SER, P96
   Kshetri N, 2022, IT PROF, V24, P11, DOI 10.1109/MITP.2022.3157206
   Laakso M, 2003, SEM COMP GRAPH, P15
   Lee J, 2012, PRESENCE-TELEOP VIRT, V21, P452, DOI 10.1162/PRES_a_00127
   Lewis Christopher., 2020, ADV INTELLIGENT SYST, P309, DOI [DOI 10.1007/978-3-030-43020-7_41, 10.1007/978-3-030-43020-7_41]
   Li Y, 2019, IPSN '19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, P13, DOI 10.1145/3302506.3310385
   Lugrin J-L, 2019, EXPERIENCING WAITING, DOI [10.1145/3359996.3364807, DOI 10.1145/3359996.3364807]
   Macedonia MR, 1997, IEEE MULTIMEDIA, V4, P48, DOI 10.1109/93.580395
   Makbily V., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P39, DOI 10.1145/300523.300527
   Meiländer D, 2013, PROC INT CONF PARAL, P763, DOI 10.1109/ICPP.2013.90
   Melo M, 2022, MULTIMEDIA SYST, V28, P1027, DOI 10.1007/s00530-022-00898-7
   Messaoudi F, 2018, USER EQUIPMENT BASED, V1
   Mildner P, 2017, COMPUT ENTERTAIN, V15, DOI 10.1145/2818383
   Miller JL., 2011, DISTRIBUTED VIRTUAL, DOI [10.17863/CAM.16371, DOI 10.17863/CAM.16371]
   Montagud M, 2018, MEDIASYNC, P3, DOI [10.1007/978-3-319-65,840-7_1, DOI 10.1007/978-3-319-65,840-7_1]
   Montagud M, 2012, MULTIMEDIA SYST, V18, P459, DOI 10.1007/s00530-012-0278-9
   Muchallil S., 2021, 2021 INT C COMPUTER, P192, DOI [10.1109/COSITE52651.2021.9649619, DOI 10.1109/COSITE52651.2021.9649619]
   Muller Jens., 2006, Comput. Entertain, V4, P11
   Murray N, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2540994
   Nasrallah A, 2019, IEEE COMMUN SURV TUT, V21, P88, DOI 10.1109/COMST.2018.2869350
   Nguyen TV, 2014, CLIN CASE DERMATOL, P1, DOI [10.1007/978-1-4471-4312-3, 10.1109/3DCVE.2014.7160928]
   Paladina Luca, 2009, Journal of Networks, V4, P382, DOI 10.4304/jnw.4.6.382-391
   parsehub, ABOUT US
   Patni JC., 2020, P 3 INT C COMP MAN B, P151, DOI [10.1145/3383845.3383877, DOI 10.1145/3383845.3383877]
   Perez-Aldana Carlos A, 2021, JMIR Diabetes, V6, pe21611, DOI 10.2196/21611
   Petrykowski M, 2019, ADV INTELL SYST, V880, P962, DOI 10.1007/978-3-030-02686-8_72
   Pingguo Huang, 2013, 2013 IEEE 2nd Global Conference on Consumer Electronics (GCCE), P456, DOI 10.1109/GCCE.2013.6664889
   PlayKey, US
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Rhee E, 2014, I C INF COMM TECH CO, P478, DOI 10.1109/ICTC.2014.6983185
   Ricci L., 2012, 2012 International Conference on High Performance Computing & Simulation (HPCS 2012), P8, DOI 10.1109/HPCSim.2012.6266885
   Roth C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P215, DOI [10.1109/VRW50115.2020.00046, 10.1109/VRW50115.2020.0-230]
   Roth D., 2020, 2020 IEEE C VIRTUAL, DOI [10.25972/OPUS-18862, DOI 10.25972/OPUS-18862]
   Roth D, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P42, DOI 10.1109/ISMAR-Adjunct.2017.28
   Rothe S, 2021, VIRTUAL REAL-LONDON, V25, P613, DOI 10.1007/s10055-020-00472-4
   Rubio-Tamayo Jose Luis, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040021
   Ryan P, 2003, SIMTECT 2003 SIMUL I, V10, DOI 1.1.124.5042
   Sabet SS., 2020, PROC 12 ACM INT WORK, DOI [10.1145/3386293.3397116, DOI 10.1145/3386293.3397116]
   Saldana J., 2015, HDB DIGITAL GAMES EN, P1, DOI 10.1007/978-981-4560-52-8_23-1
   Salomoni P, 2017, J MULTIMODAL USER IN, V11, P173, DOI 10.1007/s12193-016-0236-5
   Satyanarayanan M, 2009, IEEE PERVAS COMPUT, V8, P14, DOI 10.1109/MPRV.2009.82
   Schmieg A, 2008, IEEE INT CONF PEER, P247, DOI 10.1109/P2P.2008.20
   Schuwerk C, 2017, IEEE T HAPTICS, V10, P240, DOI 10.1109/TOH.2016.2612635
   Shah Khalid SU., 2016, INT J COMPUTER APPL, V142, P35, DOI [10.5120/ijca2016909723, DOI 10.5120/IJCA2016909723]
   Sharkey PM, 1998, P IEEE VIRT REAL ANN, P242, DOI 10.1109/VRAIS.1998.658502
   Shea R, 2013, IEEE NETWORK, V27, P16, DOI 10.1109/MNET.2013.6574660
   Shen BQ, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12070112
   Shen S, 2017, I C VIRTUAL REALITY, P461, DOI 10.1109/ICVRV.2017.00123
   Shi S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2719921
   Shi XB, 2007, SNPD 2007: EIGHTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, VOL 1, PROCEEDINGS, P746, DOI 10.1109/SNPD.2007.43
   Pedro TMS, 2021, IEEE ACCESS, V9, P8455, DOI 10.1109/ACCESS.2020.3049060
   SINGHAL SK, 1995, PRESENCE-TELEOP VIRT, V4, P169, DOI 10.1162/pres.1995.4.2.169
   Smed J, 2002, ELECTRON LIBR, V20, P87, DOI 10.1108/02640470210424392
   Soares Pereira A, 2012, DISTANCE EDUC, P81, DOI [10.5772/50381, DOI 10.5772/50381]
   Song H, 2018, P I MECH ENG B-J ENG, V232, P2264, DOI 10.1177/0954405417711736
   Sora Stream, US
   Spatial, About us
   Spinview, US
   STEINMAN JS, 1993, 7TH WORKSHOP ON PARALLEL AND DISTRIBUTED SIMULATION (PADS '93), P109
   Sykownik P, 2022, SOMETHING PERSONAL M, DOI [10.1145/3491102.3502008, DOI 10.1145/3491102.3502008]
   Tao Chen, 2019, 2019 International Conference on Intelligent Computing, Automation and Systems (ICICAS), P324, DOI 10.1109/ICICAS48597.2019.00076
   Tasaka S, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3375922
   Tatematsu A., 2010, Communications Quality and Reliability (CQR), 2010 IEEE International Workshop Technical Committee on, P1, DOI [DOI 10.1109/CQR.2010.5619913, 10.1109/CQR.2010.5619913]
   Nguyen TC, 2019, IEEE ACCESS, V7, P3031, DOI 10.1109/ACCESS.2018.2888700
   Theia Interactive, US
   TOUEL S, 2017, 5 INT C ELECT ENG BO, P1, DOI DOI 10.1109/ICEEB.2017.8192219
   Trezi, US
   Tsiatsos T., 2012, 2012 IEEE 12th International Conference on Advanced Learning Technologies (ICALT), P621, DOI 10.1109/ICALT.2012.54
   Tumanov A, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P123
   Unity, 2005, US
   Utomik, 2014, US
   Valadares A, 2016, CONCURR COMP-PRACT E, V28, P3291, DOI 10.1002/cpe.3803
   Vasilevski N, 2020, RES LEARN TECHNOL, V28, DOI 10.25304/rlt.v28.2329
   Vectordash, 2018, US
   Virtway, 2006, US
   Vizamyl, US
   VRChat, 2014, US
   Wang L, 2017, ADAPTIVE BITRATE STR
   Wang MF, 2016, COMPUT ANIMAT VIRT W, V27, P519, DOI 10.1002/cav.1670
   Washington DB, 2001, IMPLEMENTATION MULTI
   Wei Zhang, 2009, Proceedings of the 2009 IEEE 15th International Conference on Parallel and Distributed Systems (ICPADS 2009), P594, DOI 10.1109/ICPADS.2009.52
   Weissker T, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P363, DOI 10.1109/VRW52623.2021.00073
   Win KZ., 2021, 2021 IEEE INT C CONS, P1, DOI [10.1109/ICCETW52618.2021.9602999, DOI 10.1109/ICCETW52618.2021.9602999]
   Wu J, 2021, PEER PEER NETW APPL, V14, P1006, DOI 10.1007/s12083-020-01060-8
   Xiong Y, 2018, J OPT COMMUN NETW, V10, P24, DOI 10.1364/JOCN.10.000024
   Yahyavi A, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2522968.2522977
   Yong Li, 2018, 2018 IEEE/ACM Symposium on Edge Computing (SEC), P1, DOI 10.1109/SEC.2018.00008
   Zhang L, 2018, ACM T ACCESS COMPUT, V11, DOI 10.1145/3209687
   Zhang Q, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020397
   Zhang W, 2017, ACSR ADV COMPUT, V62, P6
   Zhang W, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P187, DOI 10.1109/IAEAC.2017.8054003
   Zhang YC, 2012, W PRIN ADV DISTR SIM, P75, DOI 10.1109/PADS.2012.39
   Zook ZA, 2022, IEEE T HAPTICS, V15, P212, DOI 10.1109/TOH.2021.3112509
NR 185
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 41471
EP 41537
DI 10.1007/s11042-023-15160-z
EA APR 2023
PG 67
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000962689300004
OA hybrid
DA 2024-07-18
ER

PT J
AU Chaitanya, SMK
   Choppakatla, N
AF Chaitanya, S. M. K.
   Choppakatla, Nagadeepa
TI A novel embedded system for cyber-physical system using crypto mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Malicious Activity; Encryption; Ciphertext; Plain text; Memory-mapped
   Interface; I; O Interference
ID IOT
AB In recent years, the Cyber-Physical System (CPS) is ubiquitous and the core of modern critical infrastructure and industrial applications. Moreover, CPS is used for securing digital transactions and records with a high confidentiality rate. The main issues in CPS are harmful, malicious attacks it will break the application security. This paper proposed a novel Elapid Crypto (EC) mechanism for securing CPS from malicious activity. Furthermore, a mapped interface is created in the CPU to access the instruction set of the developed technique. Also, design an elapid core accelerator in the Instruction set for separating data and providing security using private keys. It will convert the plain text into Ciphertext during Encryption. Thus the developed technique is implemented in MATLAB, and the developed EC mechanism encrypts plain text into ciphertext. Additionally, the achieved performance metrics of the proposed EC mechanism are compared with other techniques in terms of execution time, energy, power, number of cycles, and latency.
C1 [Chaitanya, S. M. K.] Gayatri Vidya Parishad Coll Engn A, Dept Elect & Commun Engn, Visakhapatnam 530048, Andhra Pradesh, India.
   [Choppakatla, Nagadeepa] VNR Vignana Jyothi Inst Engn & Technol, Dept Elect & Commun Engn, Hyderabad 500090, Telangana, India.
C3 Gayatri Vidya Parishad College of Engineering; Vallurupalli Nageswara
   Rao Vignana Jyothi Institute of Engineering &Technology (VNR VJIET)
RP Chaitanya, SMK (corresponding author), Gayatri Vidya Parishad Coll Engn A, Dept Elect & Commun Engn, Visakhapatnam 530048, Andhra Pradesh, India.
EM chaitry1084@gmail.com; nagadeepach@gmail.com
CR Abbas H, 2020, IEEE ACCESS, V8, P208195, DOI 10.1109/ACCESS.2020.3036713
   Ashibani Y, 2017, COMPUT SECUR, V68, P81, DOI 10.1016/j.cose.2017.04.005
   Barkalov A, 2019, Foundations of Embedded Systems, V1st, DOI [10.1007/978-3-030-11961-4, DOI 10.1007/978-3-030-11961-4]
   Bodkhe U, 2020, IEEE ACCESS, V8, P54371, DOI 10.1109/ACCESS.2020.2981415
   Choi Y, 2020, IEEE T CIRCUITS-II, V67, P3337, DOI 10.1109/TCSII.2020.2971580
   Choudhary G, 2020, IEEE T NETW SERV MAN, V17, P2496, DOI 10.1109/TNSM.2020.3007535
   Feng W, 2018, COMPUT NETW, V134, P167, DOI 10.1016/j.comnet.2018.01.039
   Huang JQ, 2020, IEEE T IND INFORM, V16, P6553, DOI 10.1109/TII.2019.2963728
   Hussien HM, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1445-8
   Janakiraman S, 2018, MICROPROCESS MICROSY, V56, P1, DOI 10.1016/j.micpro.2017.10.013
   Jiang W, 2020, J SYST ARCHITECT, V107, DOI 10.1016/j.sysarc.2020.101739
   Jin X, 2022, IEEE T COGN DEV SYST, V14, P1678, DOI 10.1109/TCDS.2021.3135948
   Jin X, 2022, IEEE T CIRC SYST VID, V32, P7632, DOI 10.1109/TCSVT.2022.3180274
   Jin X, 2022, NEUROCOMPUTING, V491, P414, DOI 10.1016/j.neucom.2022.04.015
   Jin X, 2022, MULTIMED TOOLS APPL, V81, P40993, DOI 10.1007/s11042-022-13001-z
   Jin X, 2022, MULTIMED TOOLS APPL, V81, P35733, DOI 10.1007/s11042-021-11126-1
   Ko D, 2021, MULTIMED TOOLS APPL, V80, P34553, DOI 10.1007/s11042-020-09925-z
   Kumar AR, 2020, MULTIMED TOOLS APPL, V79, P14031, DOI 10.1007/s11042-020-08631-0
   Li X, 2019, ADV ENG INFORM, V42, DOI 10.1016/j.aei.2019.100938
   Liang W, 2019, FUTURE GENER COMP SY, V92, P383, DOI 10.1016/j.future.2018.09.002
   Mahdavifar S, 2020, NEURAL COMPUT APPL, V32, P14753, DOI 10.1007/s00521-020-04830-w
   Nambiar Vishnu P., 2009, International Journal of Information and Communication Technology, V2, P83, DOI 10.1504/IJICT.2009.026432
   Niu X, 2020, MICROPROCESS MICROSY, V75, DOI 10.1016/j.micpro.2020.103068
   Ordinez L, 2020, IEEE REV IBEROAM TEC, V15, P50, DOI 10.1109/RITA.2020.2978416
   Palumbo F, 2019, LECT NOTES COMPUT SC, V11733, P416, DOI 10.1007/978-3-030-27562-4_30
   Poudel B, 2021, IEEE T DEPEND SECURE, V18, P235, DOI 10.1109/TDSC.2018.2883057
   Qu LF, 2020, MULTIMED TOOLS APPL, V79, P29451, DOI 10.1007/s11042-020-09379-3
   Sharma D, 2022, MULTIMED TOOLS APPL, V81, P22129, DOI 10.1007/s11042-021-11254-8
   Ulas Dilber, 2019, Procedia Computer Science, V158, P662, DOI 10.1016/j.procs.2019.09.101
NR 29
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40085
EP 40103
DI 10.1007/s11042-023-15172-9
EA APR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000961747500003
DA 2024-07-18
ER

PT J
AU Khan, I
   Ahmad, K
   Gul, N
   Khan, T
   Ahmad, N
   Al-Fuqaha, A
AF Khan, Imran
   Ahmad, Kashif
   Gul, Namra
   Khan, Talhat
   Ahmad, Nasir
   Al-Fuqaha, Ala
TI Explainable event recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event recognition; Grad-CAM; Explainability; Interpretation;
   Convolutional neural networks; Natural disasters; Social events; Sports
   events; Multimedia indexing and retrieval
ID FRAMEWORK
AB The literature shows outstanding capabilities for Convolutional Neural Networks (CNNs) in event recognition in images. However, fewer attempts are made to analyze the potential causes behind the decisions of the models and explore whether the predictions are based on event-salient objects/regions? To explore this important aspect of event recognition, in this work, we propose an explainable event recognition framework relying on Grad-CAM and an Xception architecture-based CNN model. Experiments are conducted on four large-scale datasets covering a diversified set of natural disasters, social, and sports events. Overall, the model showed outstanding generalization capabilities obtaining overall F1 scores of 0.91, 0.94, and 0.97 on natural disasters, social, and sports events, respectively. Moreover, for subjective analysis of activation maps generated through Grad-CAM for the predicted samples of the model, a crowd-sourcing study is conducted to analyze whether the model's predictions are based on event-related objects/regions or not? The results of the study indicate that 78%, 84%, and 78% of the model decisions on natural disasters, sports, and social events datasets, respectively, are based on event-related objects/regions.
C1 [Khan, Imran; Khan, Talhat; Ahmad, Nasir] Univ Engn & Technol, Dept Comp Syst Engn, Peshawar, Pakistan.
   [Ahmad, Kashif] Munster Technol Univ, Dept Comp Sci, Cork, Ireland.
   [Gul, Namra] Natl Univ Sci & Technol, Sch Elect Engn & Comp Sci SEECS, Islamabad, Pakistan.
   [Al-Fuqaha, Ala] Hamad Bin Khalifa Univ, Doha, Qatar.
C3 University of Engineering & Technology Peshawar; Munster Technological
   University (MTU); National University of Sciences & Technology -
   Pakistan; Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar
RP Ahmad, K (corresponding author), Munster Technol Univ, Dept Comp Sci, Cork, Ireland.
EM imran.cse@uetpeshawar.edu.pk; kashif.ahmad@mtu.ie;
   nmgul.msee20seecs@seecs.edu.pk; talhatkhan95@gmail.com;
   n.ahmad@uetpeshawar.edu.pk; aalfuqaha@hbku.edu.qa
RI Ahmad, Kashif/JJE-8424-2023; Ahmad, Nasir/IXW-6930-2023; Al-Fuqaha,
   Ala/IQT-0689-2023
OI Al-Fuqaha, Ala/0000-0002-0903-1204; Ahmad, Kashif/0000-0002-0931-9275
CR Adadi A., 2020, Advances in Intelligent Systems and Computing, P327, DOI [DOI 10.1007/978-981-15-0947-631/FIGURES/1, 10.1007/978-981-15-0947-6_31, DOI 10.1007/978-981-15-0947-6_31]
   Afridi YS, 2022, INT J ENERG RES, V46, P21619, DOI 10.1002/er.7100
   Ahmad K, 2017, IEEE IMAGE PROC, P2886, DOI 10.1109/ICIP.2017.8296810
   Ahmad K, 2018, PROCEEDINGS 2018 IEEE 13TH IMAGE, VIDEO, AND MULTIDIMENSIONAL SIGNAL PROCESSING WORKSHOP (IVMSP)
   Ahmad K, 2022, COMPUT SCI REV, V43, DOI 10.1016/j.cosrev.2021.100452
   Ahmad K, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P380, DOI 10.1145/2910017.2910624
   Ahmad K, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3199668
   Ahmad K, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3306240
   Ahmad K, 2019, MULTIMED TOOLS APPL, V78, P2837, DOI 10.1007/s11042-018-5982-9
   Ahmad K, 2018, SIGNAL PROCESS-IMAGE, V60, P42, DOI 10.1016/j.image.2017.09.009
   Ahsan U, 2017, IEEE WINT CONF APPL, P669, DOI 10.1109/WACV.2017.80
   Baro Xavier, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301329
   Chandrakala S, 2021, SIVIP, P1
   Cheng D, 2015, IEEE INT C SEMANT CO, P32, DOI 10.1109/ICOSC.2015.7050775
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fiok K, 2022, J DEF MODEL SIMUL-AP, V19, P133, DOI 10.1177/15485129211028651
   François ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87
   Gade K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P3203, DOI 10.1145/3292500.3332281
   Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872
   Li LJ, 2007, IEEE I CONF COMP VIS, P345
   Limin Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P30, DOI 10.1109/CVPRW.2015.7301333
   Liu M, 2015, P IEEE INT C COMP VI, P32, DOI 10.1016/j.ijsolstr.2015.02.031
   Mattivi R., 2011, Proceedings of the 2011 joint ACM workshop on Modeling and representing events, P7, DOI DOI 10.1145/2072508.2072511
   Papadopoulos S, 2011, MEDIAEVAL
   Park S, 2015, IEEE C COMP VIS PATT, P45
   Rosani A, 2015, IEEE T MULTIMEDIA, V17, P1359, DOI 10.1109/TMM.2015.2441003
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Said N, 2019, MULTIMED TOOLS APPL, V78, P31267, DOI 10.1007/s11042-019-07942-1
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang LM, 2018, INT J COMPUT VISION, V126, P390, DOI 10.1007/s11263-017-1043-5
   Xiong Y, 2015, 2015 IEEE INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS 2015)
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Zhang ZJ, 2022, IEEE T NEUR NET LEAR, V33, P6856, DOI 10.1109/TNNLS.2021.3083710
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 38
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40531
EP 40557
DI 10.1007/s11042-023-14832-0
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983783100015
DA 2024-07-18
ER

PT J
AU Kimura, R
   Nakajima, T
AF Kimura, Risa
   Nakajima, Tatsuo
TI Designing innovative digital platforms from both human and nonhuman
   perspectives
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital platforms; Design methodology; Research through design;
   More-than-human; Annotated portfolio; Beyond usability
ID HUMAN-CENTERED DESIGN; TECHNOLOGY
AB Digital platforms are becoming critical infrastructures for supporting a variety of innovative services that enhance our everyday lives. These platforms need to offer not only rational services but also ludic or slow services that focus on human pleasure. One important aspect of creating innovative digital platforms is that their concrete requirements and potential opportunities are vague before they are designed. Thus, designing, prototyping and evaluating digital platforms iteratively is essential for refining or customizing them, as knowledge is gradually gained throughout these iterations. However, it is costly to develop prototype platforms and evaluate them with traditional methods. A better tool that can be used to reveal these platforms' potential opportunities by conceiving them in a simple and rapid way is needed. In this paper, we present our journey to develop nine digital platforms that share collective human sight and hearing with the Human-Material-Pleasure (HMP) annotation method, which is a tool that we use to describe the visually structured annotations of multiple digital platforms based on the annotated portfolio method. The most significant part of the paper presents annotated portfolios based on the HMP annotation method for the nine digital platforms that we develop and shows how these annotated portfolios play an essential role in revealing and exploring the potential opportunities of our platforms during the refinement process. We also discuss how the HMP annotation method is used in the context of exploring the potential opportunities of wearable shape-changing robotic devices; these devices have significantly different characteristics from our digital platforms, which allows for showing insights more objectively by extracting diverse insights from an alternative angle.
C1 [Kimura, Risa; Nakajima, Tatsuo] Waseda Univ, Dept Comp Sci & Engn, 3-4-1 Okubo Shinjuku Tokyo, Tokyo 1698555, Japan.
C3 Waseda University
RP Nakajima, T (corresponding author), Waseda Univ, Dept Comp Sci & Engn, 3-4-1 Okubo Shinjuku Tokyo, Tokyo 1698555, Japan.
EM risa.kimura@dcl.cs.waseda.ac.jp; tatsuo@dcl.cs.waseda.ac.jp
CR Al-Sada M, 2020, VIRTUAL REAL-LONDON, V24, P191, DOI 10.1007/s10055-019-00404-x
   Al-Sada M, 2019, PROCEEDINGS OF THE 10TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE 2019 (AH2019), DOI [10.1145/3311823.3311850, 10.1109/ictcs.2019.8923046]
   Anguelov D, 2010, COMPUTER, V43, P32, DOI 10.1109/MC.2010.170
   [Anonymous], 2013, The Encyclopedia of Human-Computer Interaction
   [Anonymous], CHINESE NUMBER HAND
   [Anonymous], AGORAPHOBIC TRAVELLE
   [Anonymous], GOOGLE GLASS
   Barad K, 2003, SIGNS, V28, P801, DOI 10.1086/345321
   Barad K., 2007, M UNIVERSE HALFWAY Q, P132, DOI DOI 10.2307/J.CTV12101ZQ
   Ben Shneiderman, 2020, ACM T INTERACT INTEL, V10, DOI 10.1145/3419764
   Benford S, 2013, COMMUN ACM, V56, P66, DOI [10.1145/2500889, 10.1145/2500468.2500889]
   Benford S, 2013, ACM T COMPUT-HUM INT, V20, DOI 10.1145/2491500.2491502
   Bogost Ian., 2008, ECOLOGY GAMES, P117
   Botsman R., 2010, WHATS MINE IS YOURS
   Bowers J., 2012, P 9 C DESIGNING INTE, P68, DOI 10.1145/2317956.2317968
   Chang WW, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P1001, DOI 10.1145/3064663.3064717
   Coulton P, 2019, DES J, V22, P463, DOI 10.1080/14606925.2019.1614320
   Cross N, 2001, DES ISSUES, V17, P49, DOI 10.1162/074793601750357196
   Cruickshank L, 2017, DES J, V20, P561, DOI 10.1080/14606925.2017.1349381
   Culén AL, 2020, PROCEEDINGS OF THE 2020 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2020), P1633, DOI 10.1145/3357236.3395490
   Culén AL, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P359, DOI 10.1145/3322276.3322319
   Dalsgaard P, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1635, DOI 10.1145/2556288.2557342
   Desmet P, 2002, THESIS TU DELFT
   Dunne Anthony, 2013, SPECULATIVE EVERYTHI, DOI DOI 10.1093/JDH/EPV001
   Edwards WK, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P423
   England D, 2016, SPR SER CULT COMPUT, P1, DOI 10.1007/978-3-319-28722-5_1
   Evans D. S., 2016, Matchmakers: The new economics of multisided platforms
   Fallman Daniel, 2007, Knowledge Technology & Policy, V20, P193, DOI 10.1007/s12130-007-9022-8
   Feyerabend P., 1975, Against Method
   Frauenberger C, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3364998
   Frauenberger C, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P130, DOI 10.1145/2858036.2858050
   Friedman B, 2019, VALUE SENSITIVE DESIGN: SHAPING TECHNOLOGY WITH MORAL IMAGINATION, P1, DOI 10.7551/mitpress/7585.001.0001
   Fuchsberger Verena., 2013, P SIGCHI C HUM FACT, P2853, DOI DOI 10.1145/2470654.2481395
   Gaver B., 1999, Interactions, V6, P21, DOI DOI 10.1145/291224.291235
   Gaver B., 2012, INTERACTIONS, V19, P40
   Gaver W, 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P937, DOI DOI 10.1145/2207676.2208538
   Gaver W. W., 2003, P SIGCHI C HUM FACT, P233, DOI [DOI 10.1145/642611.642653, 10.1145/642611.642653]
   Gaver William W., 2013, CHI'13 Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P3451, DOI DOI 10.1145/2470654.2466474
   Golub, 2015, DESIGN FICTION EUTRO
   Haidt L, 2014, NONPROFITS IMAGINE B
   Hall Cathryn., 2020, Journal of Textile Design Research and Practice, V8, P209, DOI [DOI 10.1080/20511787.2020.1751960, 10.1080/20511787.2 020.1751960]
   Hamari J, 2016, J ASSOC INF SCI TECH, V67, P2047, DOI 10.1002/asi.23552
   Hartelius G., 2007, HUMANIST PSYCHOL, V35, P135, DOI [10.1080/08873260701274017, DOI 10.1080/08873260701274017]
   Hauser S, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P459, DOI 10.1145/3196709.3196745
   Hauser S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173775
   Hobye M, 2013, NORDIC DESIGN RES, V5
   Höök K, 2012, ACM T COMPUT-HUM INT, V19, DOI 10.1145/2362364.2362371
   Hook Kristina., 2015, P 33 ANN ACM C EXTEN, P2429, DOI DOI 10.1145/2702613.2702653
   Ikeuchi K., 2014, AH '14,, P1
   Ishizawa F, 2018, MULTIMED TOOLS APPL, V77, P21329, DOI 10.1007/s11042-017-5595-8
   Jordan P. W., 2000, DESIGNING PLEASURABL, DOI [10.4324/9780203305683, DOI 10.4324/9780203305683]
   Kawsar F, 2018, IEEE PERVAS COMPUT, V17, P83, DOI 10.1109/MPRV.2018.03367740
   Kelliher A, 2015, FUTURES, V70, P36, DOI 10.1016/j.futures.2014.12.004
   Kimura Risa, 2021, Ambient Intelligence - Software and Applications. 11th International Symposium on Ambient Intelligence. Advances in Intelligent Systems and Computing (AISC 1239), P13, DOI 10.1007/978-3-030-58356-9_2
   Kimura Risa, 2020, Augmented Cognition. Human Cognition and Behavior. 14th International Conference, AC 2020. Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12197), P207, DOI 10.1007/978-3-030-50439-7_14
   Kimura R, 2021, P 9 INT C DISTR AMB
   Kimura R., 2020, SN Comput. Sci., V298, P1
   Kimura R, 2021, P 12 INT S AMB INT I
   Kimura R, 2021, P 23 INT C INF INT W
   Kimura R, 2021, P IEEE 10 GLOBAL C C
   Kimura R, 2022, P 10 INT C DISTR AMB
   Kolb David A, 2014, EXPERIENTIAL LEARNIN, DOI [10.1002/job.4030080408, DOI 10.1016/B978-0-7506-7223-8.50017-4]
   Koskinen I., 2012, Design Research Through Practice: From Lab, Field and Showroom
   Krippendorff K., 1984, INNOVATION J IND DES, V3, P4
   Larner J., 2019, ETHNOGRAPHIES COLLAB
   Latour B., 2005, Reassembling the Social: An Introduction to Actor Network Theory
   Leonardi P.M., 2010, First Monday, V15
   Leonardi PM, 2011, MIS QUART, V35, P147
   Light A, 2019, DES CULT, V11, P13, DOI 10.1080/17547075.2019.1567985
   Lindtner S, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P439, DOI 10.1145.2556288.2557132
   Lowgren Jonas, 2013, Interactions, V20, P30, DOI 10.1145/2405716.2405725
   Manzini E, 2015, DES THINK DES THEOR, P1
   Marita S, 2018, P DESIGN RES SOC 201, P1148
   Nakajima T, 2013, PERS UBIQUIT COMPUT, V17, P107, DOI 10.1007/s00779-011-0469-y
   Odom WT, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1961, DOI 10.1145/2556288.2557178
   Olson Judith S., 2014, Knowing in HCI, P167, DOI [DOI 10.1007/978-1-4939-0378-8_8, 10.1007/978-1-4939-0378-8_8]
   Orlikowski WJ, 2015, J MANAGE STUD, V52, P697, DOI 10.1111/joms.12114
   ORLIKOWSKI WJ, 1995, ORGAN SCI, V6, P423, DOI 10.1287/orsc.6.4.423
   Pal D, 2020, UNIVERSAL ACCESS INF, V19, P261, DOI 10.1007/s10209-018-0639-z
   Pedersen ERG, 2019, J FASH MARK MANAG, V23, P308, DOI 10.1108/JFMM-04-2018-0062
   Polanyi M., 1958, PERSONAL KNOWLEDGE
   Rauchs M., 2018, Distributed ledger technologysystems: A conceptual framework, DOI [10.2139/ssrn.3230013, DOI 10.2139/SSRN.3230013]
   Redstrom J, 2017, DES THINK DES THEOR
   Sakamoto M, 2017, MULTIMED TOOLS APPL, V76, P12539, DOI 10.1007/s11042-016-3665-y
   Sanders EBN, 2000, COLLABORATIVE DESIGN, P3
   Schifferstein H.N., 2011, Product experience
   Schon D. A., 1983, The reflective practitioner: How professionals think in action
   SCHWARTZ SH, 1987, J PERS SOC PSYCHOL, V53, P550, DOI 10.1037/0022-3514.53.3.550
   Shneiderman B, 2020, AIS T HUMAN COMPUTER, V12
   Smith A., 2017, Social Innovation, Democracy and Makerspaces Working paper Series
   Srivastava Swati, 2017, International Conference Interfaces and Human Computer Interaction 2017. Proceedings, P193
   Stappers Pieter Jan, 2017, The Encyclopedia of Human-Computer Interaction, V32, P1
   Stolterman E, 2010, HUM-COMPUT INTERACT, V25, P95, DOI 10.1080/07370020903586696
   Suchman L., 1998, COGNITIVE STUDIES, V5, P5, DOI [DOI 10.11225/JCSS.5.1_5, 10.11225/jcss.5.1_5]
   Tharp BM, 2018, DES THINK DES THEOR
   Tiger L., 1992, The Pursuit of Pleasure
   Urbani J, 2018, 2018 IEEE 24TH INTERNATIONAL CONFERENCE ON EMBEDDED AND REAL-TIME COMPUTING SYSTEMS AND APPLICATIONS (RTCSA), P209, DOI 10.1109/RTCSA.2018.00033
   van de Poel I, 2014, PHILOS ENG TECHNOL, V17, P103, DOI 10.1007/978-94-007-7914-3_7
   Vlachokyriakos V, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174055
   von Ahn L, 2008, COMMUN ACM, V51, P58, DOI 10.1145/1378704.1378719
   WindowSwap, US
NR 101
TC 1
Z9 1
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 39961
EP 40008
DI 10.1007/s11042-023-15124-3
EA MAR 2023
PG 48
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000955293100012
OA hybrid
DA 2024-07-18
ER

PT J
AU Ho, ST
   Huu, MKN
   Nguyen, TD
   Phan, N
   Nguyen, VT
   Ngo, TD
   Le, DD
   Nguyen, TV
AF Ho, Sy-Tuyen
   Huu, Manh-Khanh Ngo
   Nguyen, Thanh-Danh
   Phan, Nguyen
   Nguyen, Vinh-Tiep
   Ngo, Thanh Duc
   Le, Duy-Dinh
   Nguyen, Tam V.
TI Abstraction-perception preserving cartoon face synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cartoon face synthesis; Generative adversarial network; Neural style
   transfer
AB Portrait cartoonization aims at translating a portrait image to its cartoon version, which guarantees two conditions, namely, reducing textural details and synthesizing cartoon facial features (e.g., big eyes or line-drawing nose). To address this problem, we propose a two-stage training scheme based on GAN, which is powerful for stylization problems. The abstraction stage with a novel abstractive loss is used to reduce textural details. Meanwhile, the perception stage is adopted to synthesize cartoon facial features. To comprehensively evaluate the proposed method and other state-of-the-art methods for portrait cartoonization, we contribute a new challenging large-scale dataset named CartoonFace10K. In addition, we find that the popular metric FID focuses on the target style yet ignores the preservation of the input image content. We thus introduce a novel metric FISI, which compromises FID and SSIM to focus on both target features and retaining input content. Quantitative and qualitative results demonstrate that our proposed method outperforms other state-of-the-art methods.
C1 [Ho, Sy-Tuyen; Huu, Manh-Khanh Ngo; Nguyen, Thanh-Danh; Phan, Nguyen; Nguyen, Vinh-Tiep; Ngo, Thanh Duc; Le, Duy-Dinh] Univ Informat Technol, VNU HCM, Ho Chi Minh City, Vietnam.
   [Nguyen, Tam V.] Univ Dayton, Dayton, OH 45469 USA.
C3 Vietnam National University Hochiminh City; University System of Ohio;
   University of Dayton
RP Nguyen, TV (corresponding author), Univ Dayton, Dayton, OH 45469 USA.
EM tamnguyen@udayton.edu
RI Nguyen, Tam/AAU-6504-2020
OI Nguyen, Tam/0000-0003-0236-7992; Nguyen, Thanh-Danh/0000-0001-6577-2122;
   Ngo Huu, Manh Khanh/0009-0007-1187-1513
FU Vietnam National University Ho Chi Minh City (VNUHCM) [C2022-26-01];
   National Science Foundation (NSF) [2025234]; VingroupInnovation
   Foundation (VINIF) [VINIF.2022.ThS.104]; Direct For Computer & Info Scie
   & Enginr; Division Of Computer and Network Systems [2025234] Funding
   Source: National Science Foundation
FX This research is funded by Vietnam National University Ho Chi Minh City
   (VNUHCM) undergrant number C2022-26-01. This work is also supported by
   the National Science Foundation (NSF) underGrant 2025234. Thanh-Danh
   Nguyen is funded by the Master, PhD Scholarship Programme of
   VingroupInnovation Foundation (VINIF), code VINIF.2022.ThS.104.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2019, Danbooru2019 portraits: A large-scale anime head illustration dataset
   [Anonymous], LAOV DRAW YOURS AN C
   Benaim S, 2017, ADV NEUR IN
   Binkowski Mikolaj, 2018, INT C LEARNING REPRE
   Chen Y, 2018, PROC CVPR IEEE, P9465, DOI 10.1109/CVPR.2018.00986
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Dumoulin V., 2017, INT C LEARNING REPRE
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gooch A. A., 2001, NONPHOTOREALISTIC RE
   Gooch B., 2002, 2 INT S NONPHOTOREAL, P83
   Goodfellow I. J., 2014, ARXIV
   Goodfellow I.J., 2015, Nature, V521, P436, DOI DOI 10.1038/NATURE14539
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Huang X, 2018, EUP C COMP VIS
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim J., 2020, ICLR, P1
   Kim T, 2017, PR MACH LEARN RES, V70
   Kolliopoulos A., 2005, Image segmentation for stylized nonphotorealistic rendering and animation
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li HL, 2011, IEEE T MULTIMEDIA, V13, P1230, DOI 10.1109/TMM.2011.2168814
   Liu MY, 2017, ADV NEUR IN, V30
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Nguyen T.Q., 2017, ARXIV
   Park S, 2020, PROCEEDINGS OF THE FIFTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS'20), DOI 10.1145/3342195.3387527
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Planet A Anime planet website, AN PLAN
   Rosin PaulL., 2015, Proceedings of the Workshop on Computational Aesthetics, P159
   Salimans T, 2016, ADV NEUR IN, V29
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang T., 2018, ARXIV
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xinrui Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8087, DOI 10.1109/CVPR42600.2020.00811
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zhan F, 2022, ARXIV
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhu FD, 2019, IEEE T IMAGE PROCESS, V28, P3556, DOI 10.1109/TIP.2019.2908778
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu Jun-Yan, 2017, Advances in neural information processing systems (NeurIPS)
NR 47
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31607
EP 31624
DI 10.1007/s11042-023-14853-9
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000954481800005
DA 2024-07-18
ER

PT J
AU Sabir, S
   Guleria, V
AF Sabir, Shazia
   Guleria, Vandana
TI A novel multi-layer color image encryption based on RSA cryptosystem,
   RP2DFrHT and generalized 2D Arnold map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RSA cryptosystem; Reality-preserving two-dimensional discrete fractional
   Hartley transform; Generalized 2D Arnold map; Image encryption and image
   decryption
ID AVERAGING FUSION STRATEGY; FRACTIONAL HARTLEY; FRESNEL TRANSFORM;
   SCHEME; SECURITY; DOMAIN; EIGENVECTORS; DWT
AB The biggest threat to information security is the irrelevant presence of eavesdroppers, unauthorized access, illegal acquisition and modification over the open wireless network. In this scenario, the demand for an effective encryption technique has become a critically significant issue and has gained a great deal of attention among cryptographers. To address this challenge, a novel asymmetric encryption technique is presented for multi-layer security of color image data consolidating the concepts of RSA cryptosystem, reality-preserving two-dimensional discrete fractional Hartley transform (RP2DFrHT) and generalized two-dimensional Arnold map. Firstly, the three planes of an RGB image (red, green and blue) are subjected to the RSA cryptosystem. The RSA cryptosystem makes the image secure in the geometrical domain and provides security with highly sensitive parameters such as public keys, private keys and their arrangements. Secondly, RP2DFrHT is implemented on the partially encrypted images to transform the former encrypted pixel into the RP2DFrHT domain over the digital environment. The reality-preserving property gives the guarantee of the real domain output image corresponding to the real domain input image. This makes the system efficient in terms of storage, display, computation and transmission over the digital domain. Lastly, the generalized 2D Arnold map is utilized to dislocate the co-ordinate information of the intermediate encrypted images. This map adds an extra layer of security and makes our system more robust. Earlier developed techniques are single-layer secured either in the frequency domain, geometrical domain, or spatial domain. However, the presented technique is multi-layer secured in the geometrical domain, frequency domain and co-ordinate domain. The protection of the presented technique is strengthened not only by the parameters of RSA, fractional orders and Arnold keys but also by the order in which they are arranged. Simulation analysis demonstrates the feasibility and robustness of our presented work. Security analysis validates that the presented technique has higher sensitivity towards its keys and their correct arrangements. To confirm the immunity against statistical-based attacks, entropy-based attacks and various classical-based attacks, statistical analysis is examined. Further, results obtained in comparison analysis proved that the presented approach outperforms as compared to other related approaches.
C1 [Sabir, Shazia; Guleria, Vandana] Birla Inst Technol Mesra, Dept Math, Ranchi, India.
C3 Birla Institute of Technology Mesra
RP Guleria, V (corresponding author), Birla Inst Technol Mesra, Dept Math, Ranchi, India.
EM vandana@bitmesra.ac.in
CR Abuturab MR, 2015, OPT LASER ENG, V69, P49, DOI 10.1016/j.optlaseng.2015.01.001
   Abuturab MR, 2013, OPT LASER ENG, V51, P317, DOI 10.1016/j.optlaseng.2012.09.008
   Abuturab MR, 2012, OPT LASER ENG, V50, P1383, DOI 10.1016/j.optlaseng.2012.04.011
   Abuturab MR, 2012, APPL OPTICS, V51, P3006, DOI 10.1364/AO.51.003006
   Ahmadkelayeh S, 2023, CHEM ENG COMMUN, V210, P398, DOI 10.1080/00986445.2022.2050711
   Alfalou A, 2010, OPT LETT, V35, P2185, DOI 10.1364/OL.35.002185
   Banday S. A., 2020, Advances in Computational Techniques for Biomedical Image Analysis, P233, DOI [10.1016/B978-0-12-820024-7.00012-8, DOI 10.1016/B978-0-12-820024-7.00012-8]
   Candan Ç, 2000, IEEE T SIGNAL PROCES, V48, P1329, DOI 10.1109/78.839980
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen LF, 2013, OPT COMMUN, V291, P98, DOI 10.1016/j.optcom.2012.10.080
   Chen LF, 2009, OPT COMMUN, V282, P3433, DOI 10.1016/j.optcom.2009.05.044
   DICKINSON BW, 1982, IEEE T ACOUST SPEECH, V30, P25, DOI 10.1109/TASSP.1982.1163843
   Frauel Y, 2007, OPT EXPRESS, V15, P10253, DOI 10.1364/OE.15.010253
   Guleria V, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102524
   Hanna MT, 2008, DIGIT SIGNAL PROCESS, V18, P709, DOI 10.1016/j.dsp.2008.05.003
   Hwang HE, 2012, OPT COMMUN, V285, P567, DOI 10.1016/j.optcom.2011.11.007
   Jiao KX, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/9721675
   Jimenez C., 2011, Journal of Physics: Conference Series, V274, DOI 10.1088/1742-6596/274/1/012041
   Jin X, 2018, MULTIMED TOOLS APPL, V77, P15851, DOI 10.1007/s11042-017-5159-y
   Joshi AB, 2020, J MOD OPTIC, V67, P933, DOI 10.1080/09500340.2020.1789233
   Joshi AB, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106139
   Joshi M, 2007, OPT COMMUN, V279, P35, DOI 10.1016/j.optcom.2007.07.012
   Kang XJ, 2019, IEEE T CIRC SYST VID, V29, P1919, DOI 10.1109/TCSVT.2018.2859253
   Kang XJ, 2017, IEEE IMAGE PROC, P4362, DOI 10.1109/ICIP.2017.8297106
   Kanmani M, 2020, MULTIMED TOOLS APPL, V79, P17859, DOI 10.1007/s11042-020-08628-9
   Kanmani M, 2019, INT J BIOMED ENG TEC, V31, P278
   Kanmani M, 2019, MULTIDIM SYST SIGN P, V30, P1911, DOI 10.1007/s11045-019-00636-9
   Kaur G, 2022, VISUAL COMPUT, V38, P1027, DOI 10.1007/s00371-021-02066-w
   Kumar M, 2021, MULTIMED TOOLS APPL, V80, P18941, DOI 10.1007/s11042-020-10325-6
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Kumar M, 2014, OPT LASER ENG, V52, P27, DOI 10.1016/j.optlaseng.2013.07.015
   Kumar M, 2015, OPT LASER TECHNOL, V75, P138, DOI 10.1016/j.optlastec.2015.06.022
   Kumar S, 2019, MED BIOL ENG COMPUT, V57, P2517, DOI 10.1007/s11517-019-02037-3
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li XW, 2015, OPT LASER ENG, V66, P112, DOI 10.1016/j.optlaseng.2014.08.016
   Li XX, 2010, OPTIK, V121, P673, DOI 10.1016/j.ijleo.2008.10.008
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu Y, 2015, MULTIMED TOOLS APPL, V74, P3171, DOI 10.1007/s11042-013-1778-0
   Liu ZJ, 2007, OPT COMMUN, V275, P324, DOI 10.1016/j.optcom.2007.03.039
   Liu ZJ, 2013, OPT LASER ENG, V51, P967, DOI 10.1016/j.optlaseng.2013.02.015
   Liu ZJ, 2010, OPT EXPRESS, V18, P12033, DOI 10.1364/OE.18.012033
   Liu ZJ, 2010, OPT LASER ENG, V48, P800, DOI 10.1016/j.optlaseng.2010.02.005
   Liu ZJ, 2009, OPT COMMUN, V282, P518, DOI 10.1016/j.optcom.2008.10.068
   Mishra DC, 2017, J INF SECUR APPL, V37, P65, DOI 10.1016/j.jisa.2017.09.006
   Mishra DC, 2014, FRACTALS, V22, DOI 10.1142/S0218348X1450011X
   Munir R, 2014, TEL SYST SERV APPL T, P1
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Pei SC, 1998, IEEE T CIRCUITS-II, V45, P665, DOI 10.1109/82.686685
   Peng X, 2006, OPT LETT, V31, P1044, DOI 10.1364/OL.31.001044
   Prasad A, 2012, OPT COMMUN, V285, P1005, DOI 10.1016/j.optcom.2011.10.019
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Sabir S, 2021, MULTIMED TOOLS APPL, V80, P27829, DOI 10.1007/s11042-021-11003-x
   Samson C, 2012, INT J ADV COMPUT SC, V3, P36
   Singh LD, 2015, PROCEDIA COMPUT SCI, V54, P472, DOI 10.1016/j.procs.2015.06.054
   Singh M, 2009, OPT LASER ENG, V47, P1293, DOI 10.1016/j.optlaseng.2009.04.015
   Singh N, 2009, OPT COMMUN, V282, P1104, DOI 10.1016/j.optcom.2008.12.001
   Situ GH, 2004, OPT LETT, V29, P1584, DOI 10.1364/OL.29.001584
   Situ GH, 2005, OPT LETT, V30, P1306, DOI 10.1364/OL.30.001306
   Tao R, 2007, OPT EXPRESS, V15, P16067, DOI 10.1364/OE.15.016067
   Vaish A, 2018, OPT APPL, V48, P25, DOI 10.5277/oa180103
   Vaish A, 2017, OPTIK, V145, P273, DOI 10.1016/j.ijleo.2017.07.041
   Venturini I, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P205
   Wang M, 2020, OPT LASER TECHNOL, V50
   Wang MM, 2020, OPT LASER TECHNOL, V124, DOI 10.1016/j.optlastec.2019.106001
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang Y, 2015, OPT COMMUN, V344, P147, DOI 10.1016/j.optcom.2015.01.045
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   XIN Y, 2006, 1 INT C INN COMP INF, V3, P22
   Xin Y, 2006, P 1 INT C INN COMP I, P1
   Zhang YQ, 2016, OPT LASER ENG, V82, P95, DOI 10.1016/j.optlaseng.2016.02.002
   Zhao DM, 2008, OPT COMMUN, V281, P5326, DOI 10.1016/j.optcom.2008.07.049
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhou NR, 2012, OPT LASER TECHNOL, V44, P2270, DOI 10.1016/j.optlastec.2012.02.027
   Zhou NR, 2011, OPT COMMUN, V284, P5588, DOI 10.1016/j.optcom.2011.08.034
   Zhou NR, 2011, OPT COMMUN, V284, P2789, DOI 10.1016/j.optcom.2011.02.066
   Zhou NR, 2010, OPT COMMUN, V283, P3037, DOI 10.1016/j.optcom.2010.03.064
   Zhu Z, 2020, IEEE PHOTONICS J, V12, DOI 10.1109/JPHOT.2020.2981494
NR 82
TC 1
Z9 1
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38509
EP 38560
DI 10.1007/s11042-023-14829-9
EA MAR 2023
PG 52
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000952027100002
DA 2024-07-18
ER

PT J
AU Varangaonkar, P
   Rode, SV
AF Varangaonkar, Payal
   Rode, S. V.
TI Lightweight deep learning model for automatic landslide prediction and
   localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision methods; Convolutional neural network; Deep learning;
   LSTM; Landslide detection; Landslide localization; Segmentation
ID DECISION TREE; SUSCEPTIBILITY; RECOGNITION; MACHINE; SYSTEM
AB There has been a lot of interest in utilizing remote sensing images to anticipate landslides. We propose a novel framework for automatic landslide detection and landslide region localization from the input remote sensing image. The framework consists of pre-processing, dynamic segmentation, automatic feature extraction, classification, and localization. The pre-processing is the integrated step that performs atmospheric corrections, geometric corrections, and unnecessary region removal with denoising using 2D median filtering. The pre-processed image is then segmented using the dynamic segmentation approach to extract the Region of Interest (ROI). We propose lightweight Convolutional Neural Network (CNN) layers for automatic feature extraction and scaling using the ResNet50 model. The CNN layers are designed systematically for automatic feature extraction to improve accuracy and reduce computational requirements. The Long-Term Short Memory (LSTM), Artificial Neural Network (ANN), and Support Vector Machine (SVM) classifiers are designed to perform the landslide prediction. If landslides are forecast, the post-processing stages are intended to identify potential landslide locations. The experimental results show that the proposed CNN-LSTM model outperformed the existing solutions in terms of accuracy, F1 score, precision, and recall rates. The experimental outcomes reveal that the proposed model improves the overall prediction accuracy by 2% and reduces the computational complexity by 35% compared to state-of-the-art methods.
C1 [Varangaonkar, Payal] Sipna Coll Engn & Technol, Amravati, India.
   [Rode, S. V.] Sipna Coll Engn & Technol, Elect & Telecommun Dept, Amravati, India.
RP Varangaonkar, P (corresponding author), Sipna Coll Engn & Technol, Amravati, India.
EM payal.varangaonkar@gmail.com
RI Rode, Sandeep V/AAA-8069-2021; Akgun, Haluk/ABA-2218-2020
CR Aksoy B, 2012, COMPUT GEOSCI-UK, V38, P87, DOI 10.1016/j.cageo.2011.05.010
   [Anonymous], 2020, MULTIMED TOOLS APPL, V79, P9845, DOI [10.1007/s11042-020-08673-4, DOI 10.1007/S11042-020-08673-4]
   Azarafza M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-03585-1
   Bakkouri I, 2022, MULTIMED TOOLS APPL, V81, P10743, DOI 10.1007/s11042-022-12242-2
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bui TA, 2020, IEEE ACCESS, V8, P143665, DOI 10.1109/ACCESS.2020.3014305
   Chang HH, 2021, IEEE T GEOSCI REMOTE, V59, P7635, DOI 10.1109/TGRS.2021.3052926
   Das I, 2011, LANDSLIDES, V8, P293, DOI 10.1007/s10346-011-0257-9
   Ghorbanzadeh O, 2022, LANDSLIDES, V19, P929, DOI 10.1007/s10346-021-01843-x
   Hwang S, 2009, ENG GEOL, V104, P126, DOI 10.1016/j.enggeo.2008.09.004
   Khalifa NE, 2022, ARTIF INTELL REV, V55, P2351, DOI 10.1007/s10462-021-10066-4
   Khanlari GR, 2012, ENG GEOL, V131, P11, DOI 10.1016/j.enggeo.2011.12.006
   Lee S, 2013, CATENA, V100, P15, DOI 10.1016/j.catena.2012.07.014
   Lee S, 2001, ENVIRON GEOL, V40, P1095, DOI 10.1007/s002540100310
   Li LM, 2021, J MT SCI-ENGL, V18, P2130, DOI 10.1007/s11629-020-6396-5
   Lu W, 2023, SOFT COMPUT, V27, P423, DOI 10.1007/s00500-021-05650-3
   Marjanovic M, 2011, ENG GEOL, V123, P225, DOI 10.1016/j.enggeo.2011.09.006
   Meena SR, 2022, LANDSLIDES, V19, P1209, DOI 10.1007/s10346-022-01861-3
   Mohan A, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3998
   Nanare IKHS, 2021, INT CO SIG PROC COMM, P684, DOI 10.1109/ICSPC51351.2021.9451744
   Pain CD, 2022, EUR J NUCL MED MOL I, V49, P3098, DOI 10.1007/s00259-022-05746-4
   Parsa M, 2014, LANDSLIDE SUSCEPTIBI
   Pawluszek K, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8080321
   Perkins S, 2012, DEATH TOLL LANDSLIDE
   Ngo PTT, 2021, GEOSCI FRONT, V12, P505, DOI 10.1016/j.gsf.2020.06.013
   Pradhan B, 2013, COMPUT GEOSCI-UK, V51, P350, DOI 10.1016/j.cageo.2012.08.023
   Qin SW, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13173383
   Rasyid A.R., 2016, Geoenvironmental Disasters, V3, P19, DOI [DOI 10.1186/S40677-016-0053-X, 10.1186/s40677-016-0053-x]
   Roy J, 2019, GEOENVIRONMENTAL DIS, V6, DOI 10.1186/s40677-019-0126-8
   Sajadi P, 2022, GEOSCI LETT, V9, DOI 10.1186/s40562-022-00218-x
   San BT, 2014, INT J APPL EARTH OBS, V26, P399, DOI 10.1016/j.jag.2013.09.010
   Sarker Iqbal H, 2021, SN Comput Sci, V2, P420, DOI 10.1007/s42979-021-00815-1
   Sezer EA, 2011, EXPERT SYST APPL, V38, P8208, DOI 10.1016/j.eswa.2010.12.167
   Shahabi H, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13224698
   Shahabi H, 2015, SCI REP-UK, V5, DOI 10.1038/srep09899
   Srivastava P, 2021, MULTIMED TOOLS APPL, V80, P14887, DOI 10.1007/s11042-021-10544-5
   Tavakkoli Piralilou S, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212575
   Tien Bui D, 2012, THESIS NORWEGIAN U L
   Ullo SL, 2019, INT GEOSCI REMOTE SE, P9646, DOI [10.1109/IGARSS.2019.8898632, 10.1109/igarss.2019.8898632]
   Nhu VH, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17082749
   Wang HJ, 2021, GEOSCI FRONT, V12, P351, DOI 10.1016/j.gsf.2020.02.012
   Wang Y, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13132625
   Wang YW, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/2142050
   Yalcin A, 2011, CATENA, V85, P274, DOI 10.1016/j.catena.2011.01.014
   Yang G, 2021, P INT COMP SOFTW APP, P258, DOI 10.1109/COMPSAC51774.2021.00044
   Ye CM, 2022, J MT SCI-ENGL, V19, P461, DOI 10.1007/s11629-021-6848-6
NR 46
TC 1
Z9 1
U1 7
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33245
EP 33266
DI 10.1007/s11042-023-15049-x
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000950119600007
DA 2024-07-18
ER

PT J
AU Roselinkiruba, R
AF Roselinkiruba, R.
TI Reversible data hiding using optimization, interpolation and binary
   image encryption techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Image encryption; Interpolation
AB Data security is very essential since the communication takes place in the open network. In order to protect the data techniques such as image encryption and data hiding have become very popular. In this paper, a Reversible Data Hiding (RDH) based on combination of optimization algorithm, image interpolation and encryption techniques is proposed to achieve high quality of stego-images and security. Initially, the input cover image is taken and divided into 2 x 2 blocks and edges in the images are identified using edge detection techniques. Next, optimization algorithm is developed to find optimal pixels which improve the performance. Then, the interpolation process is applied to up-scale the image based on optimal pixel. Data is hidden in the interpolated pixels using dual capacity predictions method and finally image is encrypted based on edge, non-edge and interpolated pixels is sent to the receiver. Experimental results demonstrate that the proposed scheme outperforms the state-of-the-arts in terms of image quality performance, embedding capacity and Universal Image Quality Index (UIQI). Furthermore, the proposed solution is resistant to security analysis based on Structural Similarity Index Measure (SSIM) and Regular Singular (RS) analysis.
C1 [Roselinkiruba, R.] Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci & T, Dept CSE, Chennai, India.
C3 Vel Tech Rangarajan Dr Sagunthala R&D Institute of Science & Technology
RP Roselinkiruba, R (corresponding author), Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci & T, Dept CSE, Chennai, India.
EM kirubaroselin@gmail.com
RI R, RoselinKiruba/HOH-2068-2023
CR Abdel-Aziz MM, 2021, MULTIMED TOOLS APPL, V80, P12641, DOI 10.1007/s11042-020-10217-9
   Banharnsakun A, 2018, MULTIMED TOOLS APPL, V77, P27491, DOI 10.1007/s11042-018-5933-5
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chen YQ, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102584
   Chhikara S, 2021, MULTIMED TOOLS APPL, V80, P31865, DOI 10.1007/s11042-021-11118-1
   Ching-Sheng Hsu, 2010, Proceedings of the Second International Conference on Communication Software and Networks (ICCSN 2010), P293, DOI 10.1109/ICCSN.2010.61
   Gonzalez CI, 2016, SOFT COMPUT, V20, P773, DOI 10.1007/s00500-014-1541-0
   Hassan FS, 2021, ARAB J SCI ENG, V46, P8441, DOI 10.1007/s13369-021-05529-3
   Hassan FS, 2020, MULTIMED TOOLS APPL, V79, P30087, DOI 10.1007/s11042-020-09513-1
   Hosny KM, 2022, J AMB INTEL HUM COMP, V13, P973, DOI 10.1007/s12652-021-03675-y
   Hosny KM, 2021, IEEE ACCESS, V9, P47425, DOI 10.1109/ACCESS.2021.3068211
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Lee CF, 2019, SOFT COMPUT, V23, P9719, DOI 10.1007/s00500-018-3537-7
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Liang L.R., 2003, APPL SOFT COMPUT, V3, P123, DOI DOI 10.1016/S1568-4946(03)00008-5
   Lin IC, 2009, COMPUT STAND INTER, V31, P458, DOI 10.1016/j.csi.2008.05.010
   Malik A, 2020, MULTIMED TOOLS APPL, V79, P18005, DOI 10.1007/s11042-020-08691-2
   Mandal PC, 2021, MULTIMED TOOLS APPL, V80, P3623, DOI 10.1007/s11042-020-09341-3
   Mohammad AA, 2019, MULTIMED TOOLS APPL, V78, P7181, DOI 10.1007/s11042-018-6465-8
   Ponuma R, 2019, MULTIMED TOOLS APPL, V78, P25707, DOI 10.1007/s11042-019-07808-6
   Kiruba RR, 2021, MULTIDIM SYST SIGN P, V32, P405, DOI 10.1007/s11045-019-00697-w
   Roselinkiruba R., 2021, International Journal of Information Technology, V13, P1797, DOI 10.1007/s41870-021-00774-z
   RoselinKiruba R, 2023, VISUAL COMPUT, V39, P59, DOI 10.1007/s00371-021-02312-1
   RoselinKiruba R, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATION, AND SIGNAL PROCESSING (ICCCSP): SPECIAL FOCUS ON TECHNOLOGY AND INNOVATION FOR SMART ENVIRONMENT, P156
   RoselinKiruba R., 2017, 2017 IEEE International Conference on Circuits and Systems (ICCS). Proceedings, P112, DOI 10.1109/ICCS1.2017.8325974
   Shaik A, 2019, MULTIMED TOOLS APPL, V78, P9717, DOI 10.1007/s11042-018-6544-x
   Singh LD, 2018, ARAB J SCI ENG, V43, P7397, DOI 10.1007/s13369-018-3104-7
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Yuefen, 2010, P INT C COMPUTER COM
   Zhang XQ, 2017, MULTIMED TOOLS APPL, V76, P9195, DOI 10.1007/s11042-016-3521-0
NR 36
TC 1
Z9 1
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35757
EP 35780
DI 10.1007/s11042-023-14651-3
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000946885800003
DA 2024-07-18
ER

PT J
AU Wang, XY
   Chen, X
   Zhao, MC
AF Wang, Xingyuan
   Chen, Xuan
   Zhao, Maochang
TI A new two-dimensional sine-coupled-logistic map and its application in
   image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Two-dimensional chaotic map; Flag shape scrambling; Cross transform;
   Image encryption; Security
ID SEMI-TENSOR PRODUCT; ALGORITHM; MATRIX; CHAOS
AB Chaotic map has some important features such as unpredictability, ergodicity, and complexity. When chaotic map is widely used for information transmission and secure communication, its chaotic performance decides the security of encryption algorithm. For the purpose of improving the chaotic performance, we put forward a novel two-dimensional Sine-coupled-Logistic map (2D-SCLM) in this paper. By comparing with other 2D chaotic maps, 2D-SCLM has more excellent pseudo-random characteristics, unpredictability, and wider range of chaos. For the purpose of studying its application, we put forward an image encryption approach based on 2D-SCLM (SCLM-IEA). Firstly, a flag shape scrambling algorithm is designed to alter the pixel location of the image. Secondly, a cross transform algorithm is developed, the process of scrambling and diffusion is executed simultaneously. Finally, the entire image is processed by a supernumerary diffusion. Simulation experiments and performance analysis signify that SCLM-IEA has more excellent security standard than some algorithms.
C1 [Wang, Xingyuan; Chen, Xuan; Zhao, Maochang] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Wang, Xingyuan] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
C3 Dalian Maritime University; Guangxi Normal University
RP Wang, XY; Chen, X (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.; Wang, XY (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM xywang@dlmu.edu.cn; cx125829@163.com
OI Chen, Xuan/0000-0002-0628-3633
FU National Natural Science Foundation of China [61672124]; Password Theory
   Project of the 13th Five-Year Plan National Cryptography Development
   Fund [MMJJ20170203]; Liaoning Province Science and Technology Innovation
   Leading Talents Program Project [XLYC1802013]; Key R&D Projects of
   Liaoning Province [2019020105-JH2/103]; Jinan City '20 universities'
   Funding Projects Introducing Innovation Team Program [2019GXRC031];
   Research Fund of Guangxi Key Lab of Multi-source Information Mining
   Security [MIMS20-M-02]
FX This research is supported by the National Natural Science Foundation of
   China (No: 61672124), the Password Theory Project of the 13th Five-Year
   Plan National Cryptography Development Fund (No: MMJJ20170203), Liaoning
   Province Science and Technology Innovation Leading Talents Program
   Project (No: XLYC1802013), Key R&D Projects of Liaoning Province (No:
   2019020105-JH2/103), Jinan City '20 universities' Funding Projects
   Introducing Innovation Team Program (No: 2019GXRC031), Research Fund of
   Guangxi Key Lab of Multi-source Information Mining & Security (No:
   MIMS20-M-02).
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Basha SM, 2022, OPTIK, V259, DOI 10.1016/j.ijleo.2022.168956
   Basu S, 2022, MULTIMED TOOLS APPL, V81, P39995, DOI 10.1007/s11042-022-12557-0
   Bhattacharjee T, 2022, MULTIMED TOOLS APPL, V81, P18755, DOI 10.1007/s11042-022-12451-9
   Chen Y, 2022, PHYS SCRIPTA, V97, DOI 10.1088/1402-4896/ac6d85
   Chu R, 2022, FRONT PHYS-LAUSANNE, V10, DOI 10.3389/fphy.2022.844966
   Elkandoz MT, 2022, MULTIMED TOOLS APPL, V81, P25497, DOI 10.1007/s11042-022-12595-8
   Gao XH, 2021, OPT LASER TECHNOL, V142, DOI 10.1016/j.optlastec.2021.107252
   Ghorbani A, 2022, OPTIK, V259, DOI 10.1016/j.ijleo.2022.168961
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Li PY, 2018, IEEE T MULTIMEDIA, V20, P1960, DOI 10.1109/TMM.2017.2786860
   Li TY, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23050510
   Li XL, 2007, EPILEPSY RES, V77, P70, DOI 10.1016/j.eplepsyres.2007.08.002
   Mansouri A, 2021, MULTIMED TOOLS APPL, V80, P21955, DOI 10.1007/s11042-021-10757-8
   Nan SX, 2022, NONLINEAR DYNAM, V108, P2705, DOI 10.1007/s11071-022-07335-4
   Özkaynak F, 2014, NONLINEAR DYNAM, V78, P2015, DOI 10.1007/s11071-014-1591-y
   Richman JS, 2000, AM J PHYSIOL-HEART C, V278, pH2039
   Sachin, 2022, OPT QUANT ELECTRON, V54, DOI 10.1007/s11082-022-03646-3
   Schindler W., 2009, Cost Management, P5, DOI [10.1007/978-0-387-71817-0_2, DOI 10.1007/978-0-387-71817-0_2]
   Sheela SJ, 2022, MULTIDIM SYST SIGN P, V33, P579, DOI 10.1007/s11045-021-00814-8
   Skokos C, 2016, LECT NOTES PHYS, V915, P221, DOI 10.1007/978-3-662-48410-4_7
   Wang XY, 2022, CHAOS SOLITON FRACT, V155, DOI 10.1016/j.chaos.2021.111629
   Wang XY, 2022, IEEE T CIRCUITS-I, V69, P1291, DOI 10.1109/TCSI.2021.3133318
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang XY, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107316
   Wang XY, 2021, CHAOS SOLITON FRACT, V150, DOI 10.1016/j.chaos.2021.111117
   Wang XY, 2021, CHAOS SOLITON FRACT, V147, DOI 10.1016/j.chaos.2021.110962
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P591, DOI 10.1007/s11042-020-09688-7
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wen Y, 2022, IET IMAGE PROCESS, V16, P2467, DOI 10.1049/ipr2.12501
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xiao YT, 2022, PHYS SCRIPTA, V97, DOI 10.1088/1402-4896/ac6544
   Xiao YT, 2022, MULTIMEDIA SYST, V28, P727, DOI 10.1007/s00530-021-00868-5
   Yahi A, 2022, OPTIK, V249, DOI 10.1016/j.ijleo.2021.168290
   Yang C, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24020273
   Yousif SF, 2022, MULTIMED TOOLS APPL, V81, P27453, DOI 10.1007/s11042-022-12762-x
   Zhu HG, 2021, MATH COMPUT SIMULAT, V185, P754, DOI 10.1016/j.matcom.2021.02.009
   Zhu HG, 2019, IEEE ACCESS, V7, P14081, DOI 10.1109/ACCESS.2019.2893538
NR 44
TC 4
Z9 4
U1 8
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35719
EP 35755
DI 10.1007/s11042-023-14674-w
EA MAR 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000946890000007
DA 2024-07-18
ER

PT J
AU Amin, J
   Selwal, A
   Sabha, A
AF Amin, Junaid
   Selwal, Arvind
   Sabha, Ambreen
TI SaffNet: an ensemble-based approach for saffron adulteration prediction
   using statistical image features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saffron; Adulteration; Statistical image features; Machine learning;
   SVM; Decision tree; KNN; Ensemble learning
AB Saffron is one of the costlier spices that are cultivated in specific regions of the world. Due to its restricted accessibility and more popularity, eventually saffron adulteration is one of the concerning issues in the recent times. It becomes difficult for human vision to discriminate between real and adulterated saffron samples. With the emergence of visual computing and data-driven algorithms, the saffron adulteration prediction systems (SAPS) are designed to predict the original and adulterated saffron samples. However, the majority of the techniques exhibit promising performance but the problem of generalization capabilities (unseen - samples) and scarcity of the saffron databases are still open research challenges. In this work, to overcome these issues, we propose a novel ensemble-based saffron prediction model (SaffNet) using statistical image features for the detection of contamination in the Kashmiri saffron. As data-driven approaches mainly rely on the representative samples, but to the best of our knowledge the standard benchmark datasets for Kashmiri saffron is not available. Therefore, we have created our novel Saffron dataset (Saff-Kash) collected afresh from different parts of Kashmir valley that includes the samples of both the authentic and adulterated saffron classes. The primary aim of the work is to anticipate the adulteration in saffron samples. Thereafter, these images are pre-processed and the dataset is prepared for the proposed SaffNet model. The SaffNet architecture designed using gradient boosting ensemble evaluated on Saff-Kash outperforms the outcomes of individual classifiers i.e., Support vector machine (SVM), decision tree, and K-Nearest neighbor (KNN) with an overall accuracy of 98%. Moreover, the execution time taken by the SaffNet model for training the SVM classifier is 8.56 milliseconds whereas for gradient boosting classifier it is 7.7 milliseconds.
C1 [Amin, Junaid; Selwal, Arvind; Sabha, Ambreen] Cent Univ Jammu, Dept Comp Sci & Informat Technol, Jammu 181143, J&K, India.
C3 Central University of Jammu
RP Amin, J (corresponding author), Cent Univ Jammu, Dept Comp Sci & Informat Technol, Jammu 181143, J&K, India.
EM mohdjunaidkashmeer@gmail.com
RI Selwal, Arvind/HTR-1625-2023
OI Selwal, Arvind/0000-0002-1075-6966
CR Amin Junaid, 2021, 2021 Fourth International Conference on Computational Intelligence and Communication Technologies (CCICT), P64, DOI 10.1109/CCICT53244.2021.00024
   AzarabadI N., 2018, GIDA - Journal of Food, V43, P476, DOI [10.15237/gida.gd18018, 10.15237/gida.GD18018]
   Dowlatabadi R, 2017, METABOLOMICS, V13, DOI 10.1007/s11306-016-1155-x
   Er SV, 2017, FOOD ANAL METHOD, V10, P1547, DOI 10.1007/s12161-016-0710-4
   Ganai S. A., 2021, Journal of Horticulture and Postharvest Research, V4, P69
   Gohari Ahmad Reza, 2013, Pharmacogn Rev, V7, P61, DOI 10.4103/0973-7847.112850
   Heidarbeigi K, 2015, INT J FOOD PROP, V18, P1391, DOI 10.1080/10942912.2014.915850
   Huang WJ, 2015, IRAN J BIOTECHNOL, V13, P36, DOI 10.15171/ijb.1034
   Huang XL, 2017, APPL COMPUT HARMON A, V43, P162, DOI 10.1016/j.acha.2016.09.001
   Husaini A. M., 2009, Communications in Biometry and Crop Science, V4, P3
   Husaini A.M., 2020, J PHARMACOGN PHYTOCH, V9, P237, DOI [10.22271/phyto.2020.v9.i6d.12889, DOI 10.22271/PHYTO.2020.V9.I6D.12889]
   Husaini AM, 2022, MOL BIOL REP, V49, P5325, DOI 10.1007/s11033-021-07053-x
   Husaini AM, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e07068
   Jafari A., 2014, IRAN AGR RES, V33, P1, DOI [10.22099/iar.2014.2376, DOI 10.22099/IAR.2014.2376]
   Javanmardi N, 2015, IDENTIFICATION SAFFL, V3, P31
   Kaminski B, 2018, CENT EUR J OPER RES, V26, P135, DOI 10.1007/s10100-017-0479-6
   Kuhn M, 2013, Applied predictive modeling, P600, DOI [10.1007/978-1-4614-6849-3, 10.1007/978-1-4614-6849-3_3]
   Lu XH, 2020, SPECTROSC LETT, V53, P76, DOI 10.1080/00387010.2019.1693403
   Maggi L, 2009, J SCI FOOD AGR, V89, P1950, DOI 10.1002/jsfa.3679
   Minaei S, 2017, J APPL RES MED AROMA, V7, P124, DOI 10.1016/j.jarmap.2017.07.004
   Mohamad I, RES J FORENSIC SCI R, V3, P232
   Moghadam MM, 2020, FOOD SCI NUTR, V8, P1923, DOI 10.1002/fsn3.1478
   Parastar H, 2020, FOOD CONTROL, V112, DOI 10.1016/j.foodcont.2020.107149
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Shawky E, 2020, LWT-FOOD SCI TECHNOL, V122, DOI 10.1016/j.lwt.2020.109032
   Shukla SK, 2015, RAPID, V3
   Singh SP, 2016, INDIAN J ECON DEV, V12, P587, DOI 10.5958/2322-0430.2016.00180.3
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Zhou L, 2019, COMPR REV FOOD SCI F, V18, P1793, DOI 10.1111/1541-4337.12492
NR 29
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31445
EP 31465
DI 10.1007/s11042-023-14934-9
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000945313000008
PM 37362696
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Reddy, NDK
   Gupta, AK
   Sahu, AK
AF Reddy, Nerusupalli Dinesh Kumar
   Gupta, Ashok Kumar
   Sahu, Anil Kumar
TI Optimized ensemble-classification for prediction of soil liquefaction
   with improved features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soil liquefaction; Statistical features; Ensemble classifiers; Optimized
   RNN; OSA-SSO algorithm
ID NETWORK; SUSCEPTIBILITY; ALGORITHM
AB The occurrence of soil liquefaction is an interesting and complicated field in the geotechnical earthquake, which has attained the consideration of a lot of analysts in current years. Liquefaction is a process, where the stiffness and strength of soil are minimized by sudden cyclic loading or earthquakes. Liquefaction and associated phenomenon were accountable for the massive quantity of damages during earlier earthquakes around the globe. Here, pre-processing is done with data normalization. Subsequently, the features including "statistical and raw features, higher-order statistical features, and improved entropy and Mutual Information (MI) features" are derived. Further, ensemble classifiers like "Deep Belief Network (DBN), Long Short Term Memory (LSTM), and Recurrent Neural Network (RNN)" are deployed during prediction. Here, the outputs obtained from DBN and LSTM are fused and then given to optimized RNN, which provides the final predicted output. Particularly, the weights of RNN are fine-tuned by Opposition based Self Adaptive SSO (OSA-SSO) model. Eventually, the advantage of the adopted model is proven on diverse metrics. The accuracy of the developed approach was 9.09%, 8.08%, and 10.1% higher than the values obtained for traditional schemes such as EC + SSO, EC + SSA, EC + PRO, and EC + BOA at the 90th LP, respectively.
C1 [Reddy, Nerusupalli Dinesh Kumar; Gupta, Ashok Kumar; Sahu, Anil Kumar] Delhi Technol Univ, Dept Civil Engn, Delhi, India.
C3 Delhi Technological University
RP Reddy, NDK (corresponding author), Delhi Technol Univ, Dept Civil Engn, Delhi, India.
EM nerusupallidineshkumarreddy@gmail.com
RI Reddy, Nerusupalli Dinesh Kumar/JEF-6436-2023
OI Reddy, Nerusupalli Dinesh Kumar/0000-0001-6516-4813
CR Ahmad M, 2021, FRONT STRUCT CIV ENG, V15, P490, DOI 10.1007/s11709-020-0669-5
   Ahmad M, 2020, FRONT STRUCT CIV ENG, V14, P1476, DOI 10.1007/s11709-020-0670-z
   Alizadeh SH, 2020, KNOWL-BASED SYST, V213, P24
   AlKhatib AA, 2020, 2020 7 INT C SOFTWAR
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   Arora S, 2019, SOFT COMPUT, V23, P715, DOI 10.1007/s00500-018-3102-4
   Das SK, 2020, NAT HAZARDS, V103, P2371, DOI 10.1007/s11069-020-04089-3
   Ferreira C, 2020, B EARTHQ ENG, V18, P109, DOI 10.1007/s10518-019-00721-1
   Ghani Sufyan, 2021, Journal of the Institution of Engineers (India): Series A (Civil, Architectural, Environmental and Agricultural Engineering), V102, P783, DOI 10.1007/s40030-021-00555-8
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Haeri H, 2017, J MIN SCI+, V53, P457, DOI 10.1134/S1062739117032356
   Hu JL, 2021, COMPUT GEOTECH, V137, DOI 10.1016/j.compgeo.2021.104304
   Hu JL, 2019, ENG GEOL, V248, P34, DOI 10.1016/j.enggeo.2018.11.006
   Jadhav A. N., 2019, Multimedia Research, V2, P1, DOI DOI 10.46253/J.MR.V2I3.A1
   Javdanian H, 2019, B ENG GEOL ENVIRON, V78, P1697, DOI 10.1007/s10064-017-1201-6
   Javdanian H, 2017, IJST-T CIV ENG, V41, P283, DOI 10.1007/s40996-017-0061-4
   Juang CH, 2018, B ENG GEOL ENVIRON, V77, P1273, DOI 10.1007/s10064-017-1071-y
   Kao LJ, 2020, J MANUF SYST, V57, P109, DOI 10.1016/j.jmsy.2020.07.020
   Karafagka S, 2021, B EARTHQ ENG, V19, P6443, DOI 10.1007/s10518-021-01081-5
   Kumar D, 2021, GEOTECH GEOL ENG, V39, P1049, DOI 10.1007/s10706-020-01544-7
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P7383, DOI 10.1007/s11042-017-4642-9
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar K, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P119, DOI 10.1109/SITIS.2016.27
   Kurnaz TF, 2019, ENVIRON EARTH SCI, V78, DOI 10.1007/s12665-019-8344-7
   Lafi M, 2021, CMES-COMP MODEL ENG, V127, P99, DOI 10.32604/cmes.2021.013026
   Li Q, 2020, GRANULAR COMPUT, V5, P503, DOI 10.1007/s41066-019-00171-9
   Mahmood A, 2020, J CENT SOUTH UNIV, V27, P500, DOI 10.1007/s11771-020-4312-3
   Mansouri M, 2021, SN APPL SCI, V3, DOI 10.1007/s42452-021-04322-z
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mohammad-Azari S, 2018, STUD COMPUT INTELL, V720, P93, DOI 10.1007/978-981-10-5221-7_10
   Moosavi SHS, 2019, ENG APPL ARTIF INTEL, V86, P165, DOI 10.1016/j.engappai.2019.08.025
   Hoang ND, 2018, B ENG GEOL ENVIRON, V77, P191, DOI 10.1007/s10064-016-0924-0
   Rahbarzare A, 2019, B ENG GEOL ENVIRON, V78, P4977, DOI 10.1007/s10064-018-01445-3
   Rajakumar BR, 2013, AASRI PROC, V4, P288, DOI 10.1016/j.aasri.2013.10.043
   Rajakumar BR, 2013, INT J COMPUT SCI ENG, V8, P180, DOI 10.1504/IJCSE.2013.053087
   Rajakumar BR, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMPUTING RESEARCH (ICCIC), P606
   Rajakumar B.R., 2013, International Journal of Hybrid Intelligent Systems, V10, P11, DOI [10.3233/HIS-120161, DOI 10.3233/HIS-120161]
   Sabbar AS, 2019, INDIAN GEOTECH J, V49, P58, DOI 10.1007/s40098-017-0288-9
   Sadashiv Halbhavi B., 2019, J COMPUT MECH POWER, V2, P19, DOI [10.46253/jcmps.v2i3.a3, DOI 10.46253/JCMPS.V2I3.A3]
   Sarhrouni E., 2012, INT J ENG TECHNOL, V4, P268
   Swamy S. M., 2013, IET CHENN 4 INT C SU, DOI [DOI 10.1049/IC.2013.0361, 10.1049/ic.2013.0361]
   Wagh MB., 2019, J NETW COMMUN SYST, V2, P34, DOI DOI 10.46253/JNACS.V2I1.A4
   Wang HZ, 2016, APPL ENERG, V182, P80, DOI 10.1016/j.apenergy.2016.08.108
   Wang JX, 2018, ARAB J GEOSCI, V11, DOI 10.1007/s12517-018-3885-8
   Wang SR, 2020, COMPUTING, V102, P717, DOI 10.1007/s00607-019-00768-7
   Zhang JF, 2021, NEURAL COMPUT APPL, V33, P1533, DOI 10.1007/s00521-020-05084-2
   Zhang Y, 2021, ENVIRON EARTH SCI, V80, DOI 10.1007/s12665-021-09648-w
   Zhang YF, 2020, FRONT STRUCT CIV ENG, V14, P1066, DOI 10.1007/s11709-020-0651-2
   Zhang YG, 2021, NAT HAZARDS, V107, P539, DOI 10.1007/s11069-021-04594-z
   Zhang YG, 2021, B ENG GEOL ENVIRON, V80, P5053, DOI 10.1007/s10064-021-02250-1
   Zhou YG, 2020, B EARTHQ ENG, V18, P6181, DOI 10.1007/s10518-020-00939-4
   Zuzulock ML, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2878-x
NR 52
TC 0
Z9 0
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31467
EP 31486
DI 10.1007/s11042-023-14816-0
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000945313000006
DA 2024-07-18
ER

PT J
AU He, WT
   Zhang, N
   Song, BP
   Pan, RR
AF He, Wentao
   Zhang, Ning
   Song, Bingpeng
   Pan, Ruru
TI Garment reconstruction from a single-view image based on pixel-aligned
   implicit function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Garments; Reconstruction; Implicit function; Single-view
ID SHAPE
AB 3D garment reconstruction has a wide range of applications in apparel design, digital human body, and virtual try-on. Reconstructing 3D shapes from single-view images is a completely undefined and challenging problem. Recent single-view methods require only single-view images of static or dynamic objects and mine the potential multi-view information in single-view images by statistical, geometric, and physical prior knowledge, which is tedious to obtain. In this paper, we use an implicit function of pixel alignment represented by a neural network to correlate 2D image pixels with the corresponding 3D clothing information for end-to-end training without any relevant prior model. The qualitative and quantitative analysis of the experimental results showed that our results reduced the relative error by an average of 2.6% and the chamfer distance by 2.37% compared to the previous method. Experiments show that our model can reasonably reconstruct the 3D model of garments from their collections of single-view images. Our method can not only capture the overall geometry of the garment but also extract the tiny but important wrinkle details of the fabric. Even with low-resolution input images, our model still achieves available results. In addition, experiments show that the reconstructed 3D models of garments can be used for texture migration and virtual fitting.
C1 [He, Wentao; Zhang, Ning; Song, Bingpeng; Pan, Ruru] Jiangnan Univ, Key Lab Ecotext, Minist Educ, 1800 Lihu Ave, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University
RP Pan, RR (corresponding author), Jiangnan Univ, Key Lab Ecotext, Minist Educ, 1800 Lihu Ave, Wuxi 214122, Jiangsu, Peoples R China.
EM 13101978181@163.com; 15251635269@163.com; 15011403997@163.com;
   prrsw@163.com
CR [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   Balan AO, 2008, LECT NOTES COMPUT SC, V5303, P15, DOI 10.1007/978-3-540-88688-4_2
   BARAN I, 2007, ACM SIGGRAPH 2007 PA, DOI DOI 10.1145/1276377.1276467
   Bhatnagar BL, 2019, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2019.00552
   Bhatti Uzair Aslam, 2022, Proceedings of International Conference on Information Technology and Applications: ICITA 2021. Lecture Notes in Networks and Systems (350), P75, DOI 10.1007/978-981-16-7618-5_7
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Bradley D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360698
   Chang A. X., 2015, ARXIV
   Chen XW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818059
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Danerek R, 2017, COMPUT GRAPH FORUM, V36, P269, DOI 10.1111/cgf.13125
   de Aguiar E., 2010, ACM T GRAPHIC, V106, P1, DOI DOI 10.1145/1778765.1778843
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Guan P, 2010, LECT NOTES COMPUT SC, V6311, P285, DOI 10.1007/978-3-642-15549-9_21
   Habermann M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3311970
   Huang SY, 2018, LECT NOTES COMPUT SC, V11211, P194, DOI 10.1007/978-3-030-01234-2_12
   Huynh L, 2018, PROC CVPR IEEE, P8407, DOI 10.1109/CVPR.2018.00877
   Jackson AS, 2019, LECT NOTES COMPUT SC, V11132, P64, DOI 10.1007/978-3-030-11018-5_6
   Jiang BY, 2020, IEEE T VIS COMPUT GR, V26, P2560, DOI 10.1109/TVCG.2020.2988476
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kocabas M, 2020, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR42600.2020.00530
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Lähner Z, 2018, LECT NOTES COMPUT SC, V11208, P698, DOI 10.1007/978-3-030-01225-0_41
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Natsume R, 2019, PROC CVPR IEEE, P4475, DOI 10.1109/CVPR.2019.00461
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Niu CJ, 2018, PROC CVPR IEEE, P4521, DOI 10.1109/CVPR.2018.00475
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   PENNA MA, 1989, IEEE T PATTERN ANAL, V11, P545, DOI 10.1109/34.24790
   Pollefeys M, 1999, INT J COMPUT VISION, V32, P7, DOI 10.1023/A:1008109111715
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Scholz V, 2005, COMPUT GRAPH FORUM, V24, P439, DOI 10.1111/j.1467-8659.2005.00869.x
   SCLAROFF S, 1991, COMP GRAPH, V25, P247, DOI 10.1145/127719.122745
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Varol G, 2018, LECT NOTES COMPUT SC, V11211, P20, DOI 10.1007/978-3-030-01234-2_2
   Vlasic D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618520
   Wang CCL, 2003, COMPUT AIDED DESIGN, V35, P241, DOI 10.1016/S0010-4485(01)00209-3
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   White R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239485
   Yan XC, 2016, ADV NEUR IN, V29
   Yang S., 2016, ARXIV
   Yu Q, 2022, KNOWL-BASED SYST, V242, DOI 10.1016/j.knosys.2022.108395
   Zhao F, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12654, DOI 10.1109/ICCV48922.2021.01244
   Zhou B, 2013, COMPUT GRAPH FORUM, V32, P85, DOI 10.1111/cgf.12215
NR 48
TC 0
Z9 0
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 30247
EP 30265
DI 10.1007/s11042-023-14924-x
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000943970200004
DA 2024-07-18
ER

PT J
AU Sasikaladevi, N
   Revathi, A
AF Sasikaladevi, N.
   Revathi, A.
TI Intelligent prognostic system for pediatric pneumonia based on
   sustainable IoHT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of health things; Pneumonia; Pediatric pneumonia; Deep neural
   networks; Transfer learning; Adaptive movement estimation
ID CHEST X-RAYS; CHILDREN; RADIOGRAPHY; INFECTIONS; DIAGNOSIS
AB Despite the growing impacts of environmental changes due to smart city development, sustainable Internet of Health Things (IoHT) retains improved public health. Containment of contagious diseases is one of the prime factors as the population density in the smart city environment is growing exponentially. This work focuses on the prognosis of pediatric pneumonia through the IoHT framework. In the world population, nearly 15% of children under five years of mortality are caused by a lung infection called pediatric pneumonia. It kills approximately 800 thousand children every year, and 2200 children daily mortality rate due to pediatric pneumonia. The disease is caused by viral or bacterial infections in the lungs. Chest X-ray (CXR) is the predominant method for diagnosing and severity analysis of pneumonia by pediatricians. However, the CXR images are low-quality images, demanding the intelligence for accurate analysis and interpretation. Hence, researchers developed different machine learning and deep learning methods to diagnose pneumonia from CXR images in recent years. However, it lacks the accuracy of interpretations. This paper proposes a deep transfer learning-based neural network-based IoHT framework to diagnose pneumonia due to viral and bacterial infections. The proposed model is twofold: the first is the deep transfer learning network for discriminating normal CXR from pneumonia-affected lung CXR images. The second is that the deep transfer learning network is trained by an optimized training method called Adaptive Movement Estimation and deployed in IoHT. The performance of the proposed system is analyzed in terms of accuracy, sensitivity, specificity, and Area Under the Curve (AUC). It yields the highest sensitivity of 98.2% and a precision of 98.8%. The proposed system also yields a validation accuracy of 97.88, which is high compared to other state-of-the-art transfer learning methods for diagnosing pediatric pneumonia.
C1 [Sasikaladevi, N.; Revathi, A.] SASTRA Univ, Shanmugha Arts Sci Technol & Res Acad, Thanjavur, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Sasikaladevi, N (corresponding author), SASTRA Univ, Shanmugha Arts Sci Technol & Res Acad, Thanjavur, Tamil Nadu, India.
EM sasikalade@gmail.com
CR Ambita AAE, 2020, LECT NOTES ARTIF INT, V12034, P129, DOI 10.1007/978-3-030-42058-1_11
   [Anonymous], UNICEF Data: Monitoring the situation of children and women: Malnutrition
   Asnaoui Khalid El., 2021, ARTIF INTELL, P257, DOI [DOI 10.1007/978-3-030-74575-214, DOI 10.1007/978-3-030-74575-2_14]
   Ayan E, 2022, ARAB J SCI ENG, V47, P2123, DOI 10.1007/s13369-021-06127-z
   Ayan E, 2019, 2019 SCIENTIFIC MEETING ON ELECTRICAL-ELECTRONICS & BIOMEDICAL ENGINEERING AND COMPUTER SCIENCE (EBBT), DOI 10.1109/ebbt.2019.8741582
   Bada C, 2007, SAO PAULO MED J, V125, P150, DOI 10.1590/S1516-31802007000300005
   Bhatt R., 2020, Revised Selected Papers, V3, P254
   Bhuiyan MU, 2018, BMJ OPEN, V8, DOI 10.1136/bmjopen-2017-020646
   Chagas D, 2021, J REAL-TIME IMAGE PR, P1
   Cherian T, 2005, B WORLD HEALTH ORGAN, V83, P353
   Chhikara P, 2020, ADV INTELL SYST, V1064, P155, DOI 10.1007/978-981-15-0339-9_13
   Dey N, 2021, PATTERN RECOGN LETT, V143, P67, DOI 10.1016/j.patrec.2020.12.010
   Dong LY, 2020, DRUG DISCOV THER, V14, P58, DOI 10.5582/ddt.2020.01012
   Elshennawy NM, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10090649
   Enwere G, 2007, TROP MED INT HEALTH, V12, P1377, DOI 10.1111/j.1365-3156.2007.01922.x
   Fernandes V, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106259
   Habib Nahida, 2020, SN Comput Sci, V1, P359, DOI 10.1007/s42979-020-00373-y
   Hashmi MF, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10060417
   Hazir T, 2006, BMJ-BRIT MED J, V333, P629, DOI 10.1136/bmj.38915.673322.80
   Jain R, 2020, MEASUREMENT, V165, DOI 10.1016/j.measurement.2020.108046
   Jaiswal AK, 2019, MEASUREMENT, V145, P511, DOI 10.1016/j.measurement.2019.05.076
   Karar ME, 2021, COMPLEX INTELL SYST, V7, P235, DOI 10.1007/s40747-020-00199-4
   Kermany Daniel, 2018, Mendeley Data, V3
   Khan MA, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2020.106960
   Khan W, 2021, IEEE ACCESS
   Kingma D. P., 2014, arXiv
   Levinsky Y, 2013, ACTA PAEDIATR, V102, pe310, DOI 10.1111/apa.12249
   Liang GB, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.06.023
   Liz H, 2021, FUTURE GENER COMP SY, V122, P220, DOI 10.1016/j.future.2021.04.007
   Longjiang E, 2021, PEDIATR PULM, V56, P1036, DOI 10.1002/ppul.25229
   Masud M, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/8862089
   Narayanan BN, 2020, PROC SPIE, V11318, DOI 10.1117/12.2547635
   Neuman MI, 2011, PEDIATR EMERG CARE, V27, P606, DOI 10.1097/PEC.0b013e3182225578
   Nijman RG, 2013, BMJ-BRIT MED J, V346, DOI 10.1136/bmj.f1706
   O'Grady KAF, 2014, PNEUMONIA, V5, P38, DOI 10.15172/pneu.2014.5/482
   O'Grady KAF, 2012, PEDIATR PULM, V47, P386, DOI 10.1002/ppul.21551
   Omar H., 2019, P BOOK, V183
   Prina E, 2015, LANCET, V386, P1097, DOI 10.1016/S0140-6736(15)60733-4
   Rahman T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093233
   Rajaraman S, 2019, PROC SPIE, V10950, DOI 10.1117/12.2512752
   Rajpal S, 2021, CHAOS SOLITON FRACT, V145, DOI 10.1016/j.chaos.2021.110749
   Richardson M, 2007, BRIT MED J, V334, P1163, DOI 10.1136/bmj.39218.495255.AE
   Siddiqi R, 2020, SN COMPUT SCI, V1, P1, DOI DOI 10.1007/S42979-020-00361-2
   Sigaúque B, 2009, J TROP PEDIATRICS, V55, P379, DOI 10.1093/tropej/fmp030
   Stephen O, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/4180949
   Swingler George H, 2001, BMC Med Imaging, V1, P1, DOI 10.1186/1471-2342-1-1
   Test M, 2013, J HOSP MED, V8, P359, DOI 10.1002/jhm.1991
   Thakur S., 2021, P INT C ARTIFICIAL I, DOI [10.1007/978-981-15-4992-2_31, DOI 10.1007/978-981-15-4992-2_31]
   WHO, 2020, PNEUMONIA
   Williams GJ, 2013, PEDIATR PULM, V48, P1195, DOI 10.1002/ppul.22806
   Wingerter SL, 2012, PEDIATR INFECT DIS J, V31, P561, DOI 10.1097/INF.0b013e31824da716
   Wu H, 2020, PREPRINT
   Wu XJ, 2020, EUR J RADIOL, V128, DOI 10.1016/j.ejrad.2020.109041
   Xavier-Souza G, 2013, PEDIATR PULM, V48, P464, DOI 10.1002/ppul.22644
   Yee Sara Lee Kit, 2020, ICBET 2020: Proceedings of the 2020 10th International Conference on Biomedical Engineering and Technology, P101, DOI 10.1145/3397391.3397412
   Zech JR, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002683
NR 56
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26901
EP 26917
DI 10.1007/s11042-023-14930-z
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000943970200023
DA 2024-07-18
ER

PT J
AU Liu, CM
   Hu, GZ
   Li, YH
   Gao, YF
   Shi, L
AF Liu, Chengming
   Hu, Guanzhong
   Li, Yinghao
   Gao, Yufei
   Shi, Lei
TI GTL-ASENet: global to local adaptive spatial encoder network for crowd
   counting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Crowd counting; Density map; Spatial encoder; Global distribution;
   Contextual module
ID SCALE; PEOPLE
AB Crowd counting from a single image is a challenging task due to perspective distortion and large-scale variation in crowd scenes. Many Researches only focus on local features to create density maps which is not effective in handing the challenges. This paper proposes a novel network named global-to-local adaptive spatial encoder network, which focuses on global features to generate a total structure density map of the population distribution, and then utilizes local features to reconstruct the total structure density map in detail to generate high-quality density map. To capture global features, local information and correlate them, we design a contextual module using different kernels with convolution and transposed convolution. To create a density map from global structure to local detail, two branches are designed, the global distribution branch and the local detail branch. The former aims to capture the population distribution region of interest in terms of global structure, and the latter aims to focus on the local details of each unit. Furthermore, to overcome the problem of pixel-wise loss of MSE, this paper proposes an efficient loss function that focuses on perceiving the possible crowd distribution over the whole image. We also apply a new upsampling mechanism that learns to create high-quality density maps on its own is advisable. The proposed network can capture the characteristics of pedestrian distribution and predict accurate results. It is evaluated on four crowd counting datasets (ShanghaiTech, NWPU, UCF_QNRF, UCF_CC_50), it obtains MAE of 67.1 and MSE, and achieves 108.8 in ShanghaiTech and gets MAE of 139.2 and the best MSE of 217.7 in UCF_CC_50 dataset and so on, and our method shows state-of-the-art on all the datasets.
C1 [Liu, Chengming; Hu, Guanzhong; Li, Yinghao; Gao, Yufei; Shi, Lei] Zhengzhou Univ, Sch Cyber Sci & Engn, 97 Wenhua St, Zhengzhou 450002, Henan, Peoples R China.
C3 Zhengzhou University
RP Liu, CM (corresponding author), Zhengzhou Univ, Sch Cyber Sci & Engn, 97 Wenhua St, Zhengzhou 450002, Henan, Peoples R China.
EM cmliu@zzu.edu.cn; hug323081@gmail.com; yinghaoli@zzu.edu.cn;
   yfgao@zzu.edu.cn; shilei@zzu.edu.cn
OI Shi, Lei/0000-0002-1170-3911; Liu, Cheng-ming/0000-0002-8650-4271
FU National Key Research and Development Program of China [2020YFB1712401,
   2018******4402]
FX This work was supported by the National Key Research and Development
   Program of China under grant of 2018******4402 and 2020YFB1712401.
CR Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Fu M, 2015, ENG APPL ARTIF INTEL, V43, P81, DOI 10.1016/j.engappai.2015.04.006
   Gao JY, 2019, NEUROCOMPUTING, V363, P1, DOI 10.1016/j.neucom.2019.08.018
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hossain MA, 2019, IEEE WINT CONF APPL, P1280, DOI 10.1109/WACV.2019.00141
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Jiang XL, 2019, PROC CVPR IEEE, P6126, DOI 10.1109/CVPR.2019.00629
   Leibe B, 2005, PROC CVPR IEEE, P878
   Li M, 2008, INT C PATT RECOG, P1998
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liang DK, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-021-3445-y
   Liu N, 2019, PROC CVPR IEEE, P3220, DOI 10.1109/CVPR.2019.00334
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624
   Ng PC, 2003, NUCLEIC ACIDS RES, V31, P3812, DOI 10.1093/nar/gkg509
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Oh MH, 2020, AAAI CONF ARTIF INTE, V34, P11799
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550
   Shu Weibo, 2022, IEEECVF C COMPUT VIS, P19618
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song QY, 2021, AAAI CONF ARTIF INTE, V35, P2576
   Thanasutives P, 2021, INT C PATT RECOG, P2382, DOI 10.1109/ICPR48806.2021.9413286
   Topkaya IS, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P313, DOI 10.1109/AVSS.2014.6918687
   Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41
   Wang C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1299, DOI 10.1145/2733373.28063370-12345-67-8/90/01
   Wang JQ, 2019, IEEE I CONF COMP VIS, P3007, DOI 10.1109/ICCV.2019.00310
   Wang Q, 2021, IEEE T PATTERN ANAL, V43, P2141, DOI 10.1109/TPAMI.2020.3013269
   Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839
   Xie J, 2022, APPL SOFT COMPUT
   Xiong HP, 2019, IEEE I CONF COMP VIS, P8361, DOI 10.1109/ICCV.2019.00845
   Xu CF, 2019, IEEE I CONF COMP VIS, P8381, DOI 10.1109/ICCV.2019.00847
   Yu F, 2015, P INT C LEARN REPR
   Zhang AR, 2019, IEEE I CONF COMP VIS, P6787, DOI 10.1109/ICCV.2019.00689
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhou J. T., 2021, IEEE Trans. Pattern Anal. Mach. Intell., V44, P3602
NR 45
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 3
PY 2023
DI 10.1007/s11042-023-14330-3
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N8MG
UT WOS:000943163700005
DA 2024-07-18
ER

PT J
AU Pandey, P
   Singh, R
AF Pandey, Priyanka
   Singh, Raghuraj
TI QoS based modified route discovery in MANET for multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MANET; Quality of service; Step size; RWP; Signal power; Multimedia
   applications
AB In today's world, Mobile Ad hoc Network (MANET) is spread across different areas of applications due to its distinct characteristics. With the popularity of multimedia applications over MANET, it is vital to provide Quality of Service (QoS) during data transmission. In MANET, due to frequent topological changes and limited resources, routing of data packets between multimedia devices is a very challenging task. Inefficient routing may lead to higher delay, more packet loss and less throughput. Therefore, for providing quality of service (QoS) for multimedia applications over MANETs, this paper proposes a QoS enabled routing protocol (QoSRP) which is obtained using AODV with some changes during route discovery operation. Modifications have been done in route request phase, route reply phase and during exchange of hello messages. Simulation pattern shows significant improvement in performance. On varying simulation time, the packet delivery ratio (PDR) of QoSRP is found to be 10.58% more over AODV and 8.5% over Mo-AODV. Similarly, throughput is 9.8% higher with respect to AODV and 7.29% over Mo-AODV. Likewise, the scheme shows 50% improvement in delay perforamce over AODV and 35.71% over Mo-AODV. The simulation is also performed by varying number of nodes and results show that the PDR of QoSRP is 10.29% more as compared to AODV and 8.87% over Mo-AODV. Similarly, the scheme acheives 10.88% more throughput with respect to AODV and 9.62% against Mo-AODV. Likewise, the scheme shows 50% improvement in delay perforamce over AODV and 33.33% with respect to Mo-AODV.
C1 [Pandey, Priyanka; Singh, Raghuraj] Harcourt Butler Tech Univ, Dept Comp Sci & Engn, Kanpur, India.
C3 Harcourt Butler Technical University (HBTU)
RP Pandey, P (corresponding author), Harcourt Butler Tech Univ, Dept Comp Sci & Engn, Kanpur, India.
EM priyankapandey07@gmail.com; raghurajsingh@rediffmail.com
RI Singh, Raghuraj/AAC-5816-2022
OI Singh, Raghuraj/0000-0003-2360-8038; Pandey,
   Priyanka/0000-0001-5187-5796
CR Bettstetter C, 2003, IEEE T MOBILE COMPUT, V2, P257, DOI 10.1109/TMC.2003.1233531
   Geng R, 2006, LECT NOTES COMPUT SC, V4317, P159
   Hassan MH, 2019, J SW JIAOTONG U, V54
   HUNTER JS, 1986, J QUAL TECHNOL, V18, P203
   Iskander MF, 2002, IEEE T MICROW THEORY, V50, P662, DOI 10.1109/22.989951
   Issariyakul T, 2012, INTRODUCTION TO NETWORK SIMULATOR NS2, SECOND EDITION, P21, DOI 10.1007/978-1-4614-1406-3_2
   Kalaivanan S, 2021, J AMB INTEL HUM COMP, V12, P4019, DOI 10.1007/s12652-020-01769-7
   Kumar R., 2019, INT J ENG ADV TECHNO, V8, P2249
   Kumar S, 2019, INNOVATIONS COMPUTER, V32
   Lee ZK, 2008, LECT NOTES COMPUT SC, V5200, P751
   Loo J, 2011, MOBILE AD HOC NETWOR, P538
   Murugan K, 2018, WIRELESS PERS COMMUN, V102, P3323, DOI 10.1007/s11277-018-5370-9
   Palaniappan S, 2015, EURASIP J WIREL COMM, DOI 10.1186/s13638-014-0234-9
   Pandey P, 2021, INT C ADV NETWORK TE, P63
   Pandey P, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P245, DOI 10.1109/ICCCIS51004.2021.9397236
   Perkins C., 2003, AD HOC ON DEMAND DIS, DOI [DOI 10.17487/RFC3561, 10.17487/RFC3561]
   Ramani T., 2019, INT J RECENT TECHNOL, V7, P2277
   Santhi G., 2011, P INT C RECENT TREND, P1233
   Shrivastava M, 2018, INT J ADV COMPUT SC, V9
   Trivedi MC, 2016, ADV INTELL SYST, V439, P181, DOI 10.1007/978-981-10-0755-2_20
   Tyagi S, 2016, PROCEDIA COMPUT SCI, V79, P903, DOI 10.1016/j.procs.2016.03.112
   Walikar G., 2018, Int. J. Eng. Sci. Invent., V7, P58
   Yen YS, 2006, LECT NOTES COMPUT SC, V4138, P586
NR 23
TC 0
Z9 0
U1 6
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29671
EP 29688
DI 10.1007/s11042-023-14855-7
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000943163700008
DA 2024-07-18
ER

PT J
AU El Alami, A
   Mesbah, A
   Berrahou, N
   Lakhili, Z
   Berrahou, A
   Qjidaa, H
AF El Alami, Abdelmajid
   Mesbah, Abderrahim
   Berrahou, Nadia
   Lakhili, Zouhir
   Berrahou, Aissam
   Qjidaa, Hassan
TI Quaternion discrete orthogonal Hahn moments convolutional neural network
   for color image classification and face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quaternion representation; Quaternion Hahn moments; Quaternion
   convolutional neural network; Noise condition; Color image
   classification; Face recognition; Complexity
ID INVARIANTS; TRANSFORM; FOURIER
AB Color image recognition has recently attracted more researchers' attention. Many methods based on quaternions have been developed to improve the classification accuracies. Some approaches have currently used quaternions with convolutional neural network (CNN). Despite the obtained results, these approaches have some weakness such as the computational complexity. In fact, the large size of the input color images necessitates a high number of layers and parameters during the learning process which can generate errors calculation and hence influence the recognition rate. In this paper, a new architecture called quaternion discrete orthogonal Hahn moments convolutional neural network (QHMCNN) for color image classification and face recognition is proposed to reduce the computational complexity of CNN while improving the classification rate. The quaternion Hahn moments are used to extract pertinent and compact features from images and introduced them in quaternion convolutional neural network. Experimental simulations conducted on various databases are demonstrated the performance of the proposed architecture QHMCNN against other relevant methods in state-of-the-art and the robustness under different noise conditions.
C1 [El Alami, Abdelmajid; Berrahou, Nadia; Lakhili, Zouhir; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Univ, Fes, Morocco.
   [Mesbah, Abderrahim; Berrahou, Aissam] Mohammed V Univ, Rabat, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Mohammed V University in
   Rabat
RP El Alami, A (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fes, Morocco.
EM abdelmajid.elalami@usmba.ac.ma
RI El Alami, Abdelmajid/CAI-1690-2022
OI EL ALAMI, Abdelmajid/0000-0002-2489-661X
CR Bharati Puja, 2020, Computational Intelligence in Pattern Recognition. Proceedings of CIPR 2019. Advances in Intelligent Systems and Computing (AISC 999), P657, DOI 10.1007/978-981-13-9042-5_56
   Brandoni D, 2020, CALCOLO, V57, DOI 10.1007/s10092-020-0358-8
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Clevert D., 2016, ARXIV151107289
   Dad N, 2019, MULTIMED TOOLS APPL, V78, P20935, DOI 10.1007/s11042-019-7381-2
   Dad N, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.1.011007
   de Oliveira L. L., 2006, Undergraduate technical report
   El Alami A, 2022, MULTIMED TOOLS APPL, V81, P7685, DOI 10.1007/s11042-021-11669-3
   El Alami A, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS TECHNOLOGIES, EMBEDDED AND INTELLIGENT SYSTEMS (WITS), DOI 10.1109/wits.2019.8723788
   Elazary L, 2010, VISION RES, V50, P1338, DOI 10.1016/j.visres.2010.01.002
   Gaudet A. S., 2018, P INT JOINT C NEUR N, P1, DOI DOI 10.1109/IJCNN.2018.8489651
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Graham B., 2015, Arxiv, P1, DOI [10.48550/arxiv.1412.6071, DOI 10.48550/ARXIV.1412.6071]
   Guo GD, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102805
   Guo LQ, 2014, INFORM SCIENCES, V273, P132, DOI 10.1016/j.ins.2014.03.037
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Hayat M, 2015, IEEE T PATTERN ANAL, V37, P713, DOI 10.1109/TPAMI.2014.2353635
   Hosny KM, 2021, CLUSTER COMPUT, V24, P2385, DOI 10.1007/s10586-021-03271-x
   Hosny KM, 2021, NEURAL COMPUT APPL, V33, P5419, DOI 10.1007/s00521-020-05280-0
   Hosny KM, 2018, J MATH IMAGING VIS, V60, P717, DOI 10.1007/s10851-018-0786-0
   Khasanova R, 2017, IEEE INT CONF COMP V, P860, DOI 10.1109/ICCVW.2017.106
   Lakhili Z, 2020, INT C EL ENG REN EN, P151, DOI [10.1007/978-981-15-6259-4_14, DOI 10.1007/978-981-15-6259-4_14]
   Lakhili Z, 2020, MULTIMED TOOLS APPL, V79, P18883, DOI 10.1007/s11042-020-08654-7
   Lakhili Z, 2019, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON NETWORKING, INFORMATION SYSTEMS & SECURITY (NISS19), DOI 10.1145/3320326.3320398
   Lakhili Z, 2019, PROCEDIA COMPUT SCI, V148, P12, DOI 10.1016/j.procs.2019.01.002
   Leibe B, 2003, PROC CVPR IEEE, P409
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mesbah A., 2019, P 2 INT C NETW INF S, P1, DOI DOI 10.1145/3320326.3320397
   Mesbah A, 2019, IMAGE VISION COMPUT, V88, P76, DOI 10.1016/j.imavis.2019.04.010
   Mohan BC, 2019, INT CONF COMPUT, DOI 10.1109/icccnt45670.2019.8944775
   Muqeet Mohd Abdul, 2019, Applied Computing and Informatics, V15, P163, DOI 10.1016/j.aci.2017.11.002
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   Nitta T, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P2754
   Parcollet T., 2018, ARXIV
   Rassem TH., 2017, INT J ELECT COMPUTER, V7, P1594, DOI [10.11591/ijece.v7i3.pp1594-1601, DOI 10.11591/IJECE.V7I3.PP1594-1601]
   Sangwine SJ, 1996, ELECTRON LETT, V32, P1979, DOI 10.1049/el:19961331
   Shah SAA, 2017, IEEE COMPUT SOC CONF, P601, DOI 10.1109/CVPRW.2017.88
   Shao ZH, 2014, PATTERN RECOGN, V47, P603, DOI 10.1016/j.patcog.2013.08.016
   Singh C, 2018, OPT LASER TECHNOL, V106, P234, DOI 10.1016/j.optlastec.2018.03.033
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Soniya, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S021800142052014X
   Spacek L, 2008, DESCRIPTION COLLECTI
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang XY, 2015, APPL MATH COMPUT, V256, P951, DOI 10.1016/j.amc.2015.01.075
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Xu B., 2015, arXiv
   Xu D, 2017, NEURAL NETW WORLD, V27, P271, DOI 10.14311/NNW.2017.27.014
   Yang CZ, 2021, APPL MATH COMPUT, V403, DOI 10.1016/j.amc.2021.126096
   Yang HY, 2016, FUND INFORM, V145, P189, DOI 10.3233/FI-2016-1354
   Yap PT, 2007, IEEE T PATTERN ANAL, V29, P2057, DOI 10.1109/TPAMI.2007.70709
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang H, 2020, IEEE T NEUR NET LEAR, V31, P4538, DOI 10.1109/TNNLS.2019.2956015
   Zhu H., 2014, INT J SIGNAL PROCESS, V7, P149, DOI [10.14257/ijsip.2014.7.6.13, DOI 10.14257/IJSIP.2014.7.6.13]
   Zhu XY, 2018, LECT NOTES COMPUT SC, V11212, P645, DOI 10.1007/978-3-030-01237-3_39
NR 58
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32827
EP 32853
DI 10.1007/s11042-023-14866-4
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943009100010
DA 2024-07-18
ER

PT J
AU Patil, NP
   Ramteke, RJ
AF Patil, Nilima Prakash
   Ramteke, R. J.
TI A novel optimized deep learning framework to spot keywords and query
   matching process in Devanagari scripts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Devanagari script; Document indexing; Keyword spotting; Segmentation;
   Spider monkey optimization
AB Character recognition is the process of translating scanned images of handwritten, printed, or typewritten text into machine-encoded text. The character recognition of scanned handwritten historical Devanagari documents is the most significant research in recent years. However, the existing classifier's character recognition of historical Devanagari documents provided lower efficiency and less accuracy. Thus, to overcome these issues, the novel Spider Monkey-based Recurrent Framework (SMbRF) is developed in this research and used for Devanagari script character recognition and keyword spotting. In addition, the historical Devanagari script was collected from the library and scanned using an optical scanner. Moreover, the fitness of the spider monkey is utilized in the dense layer of the recurrent neural model that has tended to gain the finest performance. Here, the fitness function of the SMbRF is utilized to track and segment the lines and words. Also, keywords were tracked, indexed, and spotted by the SMbRF model. Additionally, the query-matching process was done by upgrading the fitness function of the spider monkey in the dense layer of the recurrent model. Finally, the developed approach was validated in the python environment and achieved the finest word spotting accuracy of 99.36%, F-measure of 98.26%, precision of 98.64, and recall of 97.865. Moreover, the recorded maximum error rate was only 2.5% compared to existing works; the proposed novel SMbRF has obtained outstanding results.
C1 [Patil, Nilima Prakash; Ramteke, R. J.] KBC North Maharashtra Univ, Sch Comp Sci, Jalgaon 425001, Maharashtra, India.
C3 Kavayitri Bahinabai Chaudhari North Maharashtra University, Jalgaon
RP Patil, NP (corresponding author), KBC North Maharashtra Univ, Sch Comp Sci, Jalgaon 425001, Maharashtra, India.
EM ramtekenilima25@gmail.com; rakeshjramteke@gmail.com
CR Awotunde JB, 2020, IEEE ACCESS, V8, P169568, DOI 10.1109/ACCESS.2020.3024077
   Benabdelaziz Ryma, 2020, 2020 1st International Conference on Communications, Control Systems and Signal Processing (CCSSP), P219, DOI 10.1109/CCSSP49278.2020.9151583
   Bhunia AK, 2020, MULTIMED TOOLS APPL, V79, P27365, DOI 10.1007/s11042-019-08442-y
   Bhunia AK, 2018, PATTERN RECOGN, V79, P12, DOI 10.1016/j.patcog.2018.01.034
   Cheikhrouhou A, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2021.107832
   Cheikhrouhou A, 2020, NEURAL COMPUT APPL, V32, P9201, DOI 10.1007/s00521-019-04429-w
   Cilia ND, 2020, PATTERN RECOGN LETT, V129, P137, DOI 10.1016/j.patrec.2019.11.025
   Dargan S, 2021, SOFT COMPUT, V25, P15281, DOI 10.1007/s00500-021-06118-0
   Das A, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P426, DOI 10.1109/ACPR.2015.7486539
   Dheemanth Urs R., 2021, DATA INTELLIGENCE CO, DOI [10.1007/978-981-15-8530-2_6, DOI 10.1007/978-981-15-8530-2_6]
   Elmansouri M, 2020, 2020 INT C INTELLIGE
   Farooqui FF, 2020, IEEE ACCESS, V8, P131119, DOI 10.1109/ACCESS.2020.3010166
   Gao J, 2020, LECT NOTES COMPUT SC, V12274, P368, DOI 10.1007/978-3-030-55130-8_32
   Gao YX, 2020, INT CONF ACOUST SPEE, P7479, DOI [10.1109/icassp40776.2020.9053313, 10.1109/ICASSP40776.2020.9053313]
   Kang B, 2021, ADV COMPUTER SCI UBI, V715, DOI [10.1007/978-981-15-9343-7_60, DOI 10.1007/978-981-15-9343-7_60]
   Kang S, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107577
   Kaur H, 2021, MULTIMED TOOLS APPL, V80, P11155, DOI 10.1007/s11042-020-10297-7
   Kaur H, 2021, SOFT COMPUT, V25, P4451, DOI 10.1007/s00500-020-05455-w
   Kaur RP, 2021, VISUAL COMPUT, V37, P1637, DOI 10.1007/s00371-020-01927-0
   Kumar M, 2021, SOFT COMPUT, V25, P11589, DOI 10.1007/s00500-021-06060-1
   Majumder S, 2021, MULTIMED TOOLS APPL, V80, P12411, DOI 10.1007/s11042-020-10363-0
   Mathew M, 2021, IEEE WINT CONF APPL, P2199, DOI 10.1109/WACV48630.2021.00225
   Mukherjee H, 2021, P 6 INT C MATH COMPU, V1262, DOI [10.1007/978-981-15-8061-1_16, DOI 10.1007/978-981-15-8061-1_16]
   Narang SR, 2021, MULTIMED TOOLS APPL, V80, P20671, DOI 10.1007/s11042-021-10775-6
   Roy PP, 2021, MULTIMED TOOLS APPL, V80, P11671, DOI 10.1007/s11042-020-10229-5
   Roy PP, 2017, EXPERT SYST APPL, V76, P113, DOI 10.1016/j.eswa.2017.01.027
   Roy PP, 2015, IMAGE VISION COMPUT, V44, P15, DOI 10.1016/j.imavis.2015.09.006
   Santoro A, 2020, PATTERN RECOGN LETT, V131, P329, DOI 10.1016/j.patrec.2020.01.007
   Sharada B, 2019, LECT NOTE NETW SYST, V43, P65, DOI 10.1007/978-981-13-2514-4_6
   Sharma H, 2019, STUD COMPUT INTELL, V779, P43, DOI 10.1007/978-3-319-91341-4_4
   Singh H, 2021, SOFT COMPUT, V25, P6329, DOI 10.1007/s00500-021-05620-9
   Sitender, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03479-0
   Pabón OS, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11020865
   Stauffer M, 2020, PATTERN RECOGN LETT, V134, P125, DOI 10.1016/j.patrec.2018.03.030
   Stauffer M, 2018, PATTERN RECOGN, V81, P240, DOI 10.1016/j.patcog.2018.04.001
   Ubeda I, 2020, PATTERN RECOGN LETT, V131, P398, DOI 10.1016/j.patrec.2020.02.002
   Westphal F., 2020, REPRESENTATIVE IMAGE
   Wolf F, 2020, 2020 17 INT C FRONTI
NR 38
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 30177
EP 30199
DI 10.1007/s11042-023-14912-1
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000941926100002
DA 2024-07-18
ER

PT J
AU Yassami, M
   Ashtari, P
AF Yassami, Mohammad
   Ashtari, Payam
TI A novel hybrid optimization algorithm: Dynamic hybrid optimization
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Meta-heuristic algorithms; Hybrid algorithm; Optimization; Dynamic
   hybrid algorithm
ID PARTICLE SWARM OPTIMIZATION; EVOLUTIONARY
AB Nowadays, many algorithms are invented with different strengths and weaknesses, none of which is the best for all cases. Herein, a hybrid optimization algorithm entitled the dynamic hybrid optimization algorithm (DHOA) is presented. We cover the weaknesses of one algorithm with the strengths of another algorithm using a new method of combination. There are two methods for combining algorithms: parallel and sequential. We adopted the parallel method and optimized the algorithm's performance. In this method, unlike other parallel methods, the population size of the better algorithm is enhanced. Three algorithms were selected due to their relatively different performance in the optimization, so that the results could be more accurately examined. We aimed to achieve better and more accurate results in a shorter time by using the exploitation ability of PSO, HHO, and the crossover of GA. Twenty-three well-known examples were provided to determine the fitness of the proposed method and to compare it with these three algorithms. A group of 10 modern benchmark test functions of Congress on Evolutionary Computation (CEC) was used as an extra evaluation for DHOA. Three well-known engineering examples (10-bar truss, welded beam, and pressure vessel designs) were also examined to evaluate the performance of the proposed method. The three algorithms were the Genetic Algorithm (GA), particle swarm optimization (PSO), and Harris Hawks algorithm (HHO). According to the findings, the proposed method has a faster convergence and better performance than the other algorithms. It also yields better results than its basic algorithms. The Friedman mean rank of the proposed dynamic hybrid optimization was one of the top three algorithms among 23 well-known functions and CEC2019 examples. As for the three famous engineering examples (10-bar truss, welded beam, and pressure vessel designs), it was one of the top three algorithms.
C1 [Yassami, Mohammad; Ashtari, Payam] Univ Zanjan, Dept Civil Engn, Zanjan, Iran.
C3 University Zanjan
RP Yassami, M (corresponding author), Univ Zanjan, Dept Civil Engn, Zanjan, Iran.
EM mohammad.yassami@znu.ac.ir
RI yassami, mohammad/JGE-2810-2023
OI yassami, mohammad/0000-0002-6554-6229; Ashtari,
   Payam/0000-0002-2687-0114
CR Abd Elaziz M, 2021, ADV ENG SOFTW, V154, DOI 10.1016/j.advengsoft.2021.102973
   Abdel-Basset M, 2021, ARTIF INTELL REV, V54, P593, DOI 10.1007/s10462-020-09860-3
   Al-Wajih R, 2021, IEEE ACCESS, V9, P31662, DOI 10.1109/ACCESS.2021.3060096
   Chegini SN, 2018, APPL SOFT COMPUT, V73, P697, DOI 10.1016/j.asoc.2018.09.019
   Chelouah R, 2003, EUR J OPER RES, V148, P335, DOI 10.1016/S0377-2217(02)00401-0
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Civicioglu P, 2020, NEURAL COMPUT APPL, V32, P3923, DOI 10.1007/s00521-018-3822-5
   Coelho LD, 2010, EXPERT SYST APPL, V37, P1676, DOI 10.1016/j.eswa.2009.06.044
   Coello CAC, 2000, COMPUT IND, V41, P113, DOI 10.1016/S0166-3615(99)00046-9
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Dhiman G, 2019, ADV INTELL SYST COMP, V816, P599, DOI 10.1007/978-981-13-1592-3_47
   Digalakis JG, 2001, INT J COMPUT MATH, V77, P481, DOI 10.1080/00207160108805080
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Fan SKS, 2007, EUR J OPER RES, V181, P527, DOI 10.1016/j.ejor.2006.06.034
   Faramarzi A, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105190
   Farnad B, 2018, APPL MATH MODEL, V55, P652, DOI 10.1016/j.apm.2017.10.001
   Fogel DB, 2006, EVOLUTIONARY COMPUTATION: TOWARD A NEW PHILOSOPHY OF MACHINE INTELLIGENCE, 3RD EDITION, P1, DOI 10.1002/0471749214
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Holland J. H., 1992, Scientific American (International Edition), V267, P44, DOI 10.1038/scientificamerican0792-66
   Holland JH., 1977, Pattern-DirectedInference Systems, V63, P49, DOI [DOI 10.1016/B978-0-12-737550-2.50020-8, DOI 10.1145/1045343.1045373]
   Jiang SH, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/1957812
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kaveh A, 2022, ENG COMPUT-GERMANY, V38, P1555, DOI 10.1007/s00366-020-01258-7
   Kaveh A, 2010, ACTA MECH, V213, P267, DOI 10.1007/s00707-009-0270-4
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kennedy J., 2001, Swarm Intelligence
   Khalilpourazari S, 2019, SOFT COMPUT, V23, P1699, DOI 10.1007/s00500-017-2894-y
   Khalilpourazari S, 2017, ENG OPTIMIZ, V49, P878, DOI 10.1080/0305215X.2016.1214437
   Kohler M, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105865
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Luo JK, 2022, INT J BIO-INSPIR COM, V20, P71, DOI 10.1504/IJBIC.2022.126764
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Moosavi SHS, 2019, ENG APPL ARTIF INTEL, V86, P165, DOI 10.1016/j.engappai.2019.08.025
   Nenavath H, 2019, NEURAL COMPUT APPL, V31, P5497, DOI 10.1007/s00521-018-3376-6
   Pakzad-Moghaddam SH, 2019, COMPUT IND ENG, V136, P591, DOI 10.1016/j.cie.2019.07.046
   Pan XQ, 2019, MULTIMED TOOLS APPL, V78, P29921, DOI 10.1007/s11042-018-6602-4
   Price KV, 2018, PROBLEM DEFINITIONS, DOI DOI 10.1155/2020/4854895
   Senel FA, 2019, ENG COMPUT-GERMANY, V35, P1359, DOI 10.1007/s00366-018-0668-5
   Trivedi I.N., 2018, ADV COMPUTER COMPUTA, P53, DOI [10.1007/978-981-10-3773-3_6, DOI 10.1007/978-981-10-3773-3_6]
   Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82, DOI 10.1109/4235.771163
   Yao X., 1999, Evolutionary computation: Theory and applications
   Yapici H, 2019, APPL SOFT COMPUT, V78, P545, DOI 10.1016/j.asoc.2019.03.012
   Yaseen ZM, 2019, NEURAL COMPUT APPL, V31, P8807, DOI 10.1007/s00521-018-3952-9
   Yokota T, 1998, COMPUT IND ENG, V35, P367, DOI 10.1016/S0360-8352(98)00096-5
   Yue SH, 2021, MULTIMED TOOLS APPL, V80, P3863, DOI 10.1007/s11042-020-09876-5
   Zhang DJ, 2016, INTEGR COMPUT-AID E, V23, P31, DOI 10.3233/ICA-150499
NR 48
TC 4
Z9 4
U1 15
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 31947
EP 31979
DI 10.1007/s11042-023-14444-8
EA MAR 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000940725400003
DA 2024-07-18
ER

PT J
AU Kumar, N
   Kumar, R
   Malik, A
   Singh, S
   Jung, KH
AF Kumar, Neeraj
   Kumar, Rajeev
   Malik, Aruna
   Singh, Samayveer
   Jung, Ki-Hyun
TI Reversible data hiding with high visual quality using pairwise PVO and
   PEE
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive RDH; Reversible data hiding; Pairwise PVO; Prediction error
   expansion; Pixel distribution; Standard deviation
ID PREDICTION; WATERMARKING; EXPANSION
AB Pixel-value ordering (PVO) and prediction-error expansion (PEE) are the two most popular strategies of reversible data hiding (RDH) as PVO provides high-fidelity stego-images with decent embedding capacity (EC) and PEE provides high EC with limited distortion. Further, pairwise embedding scheme introduced by Ou et al. again boosts the EC and reduces distortion of both the strategies. However, there has been a dearth of RDH schemes which can optimally utilize both the pairwise PVO and pairwise PEE strategies to provide a least trade-off between EC and visual quality. In this paper, we propound an adaptive RDH (ARDH) scheme which optimally selects the embedding strategy based on image block category. The proposed scheme reads the image in the block-wise manner using a sliding window of 4 x 4 size to get the image block of same size, then divides the block into inner and outer sub-block. The outer sub-block is considered as a reference block for the inner sub-block to determine statistical properties of the inner sub-block using standard deviation. An enhanced pairwise PEE is adopted for embedding when the standard deviation of outer sub-block's pixels is smaller than a first user-defined threshold. In case the standard deviation is greater than the first threshold but lower than a second user-defined threshold, then pairwise PVO is adopted. Otherwise, the sub-block is skipped without embedding the secret data. As a result, the ARDH scheme utilizes both the PEE and PVO strategies in optimum manner, which in turn provides higher EC and image quality than the most of the existing RDH schemes as validated by experimental results.
C1 [Kumar, Neeraj] Jamia Millia Islamia, Dept Elect & Commun, New Delhi, India.
   [Kumar, Rajeev] Delhi Technol Univ, Dept Comp Sci & Engn, New Delhi, India.
   [Malik, Aruna; Singh, Samayveer] NIT Jalandhar, Dept Comp Sci & Engn, Jalandhar, India.
   [Jung, Ki-Hyun] Andong Natl Univ, Dept Software Convergence, Andong Gyeongbuk, South Korea.
C3 Jamia Millia Islamia; Delhi Technological University; National Institute
   of Technology (NIT System); Dr B R Ambedkar National Institute of
   Technology Jalandhar; Andong National University
RP Kumar, R (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, New Delhi, India.
EM neeraj.mohiwal@gmail.com; rajeevkumar@dtu.ac.in; malika@nitj.ac.in;
   samays@nitj.ac.in; kingjung@anu.ac.kr
RI Singh, Samayveer/X-8119-2019
OI Singh, Samayveer/0000-0002-4199-721X
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2021R1I1A3049788]; Ministry of
   Science and ICT through the National Research Foundation of Korea
   [2019H1D3A1A01101687, 2021H1D3A2A01099390]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (2021R1I1A3049788) and Brain Pool program funded by the
   Ministry of Science and ICT through the National Research Foundation of
   Korea (2019H1D3A1A01101687, 2021H1D3A2A01099390).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Dragoi IC, 2017, INT S SIGN CIRC SYST, P1
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Dragoi IC, 2015, EUR SIGNAL PR CONF, P56, DOI 10.1109/EUSIPCO.2015.7362344
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Gadamsetty S, 2022, WATER-SUI, V14, DOI 10.3390/w14050707
   Gadekallu TR, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.107836
   He WG, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/2051058
   He WG, 2021, IEEE T IMAGE PROCESS, V30, P5045, DOI 10.1109/TIP.2021.3078088
   He WG, 2018, INFORM SCIENCES, V467, P784, DOI 10.1016/j.ins.2018.04.088
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hou JC, 2021, SIGNAL PROCESS-IMAGE, V92, DOI 10.1016/j.image.2020.116118
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kaur GJ, 2022, INT J SUST DEV WORLD, V29, P18, DOI 10.1080/13504509.2021.1896589
   Kaur G, 2021, ARCH COMPUT METHOD E, V28, P3517, DOI 10.1007/s11831-020-09512-3
   Kumar N, 2021, IEEE SIGNAL PROC LET, V28, P1335, DOI 10.1109/LSP.2021.3090673
   Kumar R, 2019, 2019 34TH INTERNATIONAL TECHNICAL CONFERENCE ON CIRCUITS/SYSTEMS, COMPUTERS AND COMMUNICATIONS (ITC-CSCC 2019), P306, DOI 10.1109/itc-cscc.2019.8793412
   Kumar R, 2020, MULTIMED TOOLS APPL, V79, P22635, DOI 10.1007/s11042-020-09069-0
   Kumar R, 2020, INFORM SCIENCES, V536, P101, DOI 10.1016/j.ins.2020.05.047
   Kumar R, 2020, MULTIDIM SYST SIGN P, V31, P1145, DOI 10.1007/s11045-020-00701-8
   Kumar R, 2018, INT ARAB J INF TECHN, V15, P763
   Kumar R, 2016, MULTIMED TOOLS APPL, V75, P241, DOI 10.1007/s11042-014-2289-3
   Lee CF, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12071164
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Malik A, 2018, MULTIMED TOOLS APPL, V77, P15803, DOI 10.1007/s11042-017-5156-1
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2019, IEEE T CIRC SYST VID, V29, P2176, DOI 10.1109/TCSVT.2018.2859792
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   sipi, USC-SIPI image database
   Su H, 2014, PROC SPIE, V9029, DOI 10.1117/12.2040890
   Tan TK, 2006, IEEE IMAGE PROC, P1693, DOI 10.1109/ICIP.2006.312685
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Weng SW, 2021, INFORM SCIENCES, V549, P13, DOI 10.1016/j.ins.2020.10.063
   Weng SW, 2016, J VIS COMMUN IMAGE R, V41, P185, DOI 10.1016/j.jvcir.2016.09.016
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Wu HR, 2019, J REAL-TIME IMAGE PR, V16, P685, DOI 10.1007/s11554-019-00867-w
   Zhang T, 2020, IEEE T INF FOREN SEC, V15, P2306, DOI 10.1109/TIFS.2019.2963766
   Zhao W., 2018, J INF HIDING MULTIME, V9, P918
NR 45
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30733
EP 30758
DI 10.1007/s11042-023-14867-3
EA FEB 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000940729500012
DA 2024-07-18
ER

PT J
AU Tan, X
   Li, S
   Yan, H
AF Tan, Xiao
   Li, Sheng
   Yan, Hua
TI Fast lane detection for extracting spatial location information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lane detection; Deep learning; Convolutional neural network; Row-wise
   classification; Lightweight networks
AB At present, even though great progress has been made in lane detection based on deep learning method in complex scenarios, there is still room for improvement in the real-time performance of most models. Row-wise classification method is the current mainstream method to improve the real-time performance of the model. It makes a trade-off between accuracy and speed. However, many models based on the row-wise classification method are not strong enough to extract spatial contextual information, This hinders the recognition of lanes. Inspired by Feature Pyramid Networks, we propose a simple and lightweight framework based on row-wise classification method: SIE-Net. The method can fully extract the spatial position information in the image. The framework can fuse the semantic information contained in the deep feature map and the spatial information contained in the shallow feature map. Then dilated convolution is used in the feature extraction process, which increases the receptive field of the model and extracts more global information in the image. Meanwhile, channel attention mechanism is used in the feature extraction process. It can give greater weight to the channel containing the structure information of the lanes. Finally, the experimental results demonstrate the effectiveness of the proposed method in terms of accuracy and speed on two popular Tusimple and CULane benchmark datasets.
C1 [Tan, Xiao; Li, Sheng; Yan, Hua] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Peoples R China.
C3 Sichuan University
RP Yan, H (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Peoples R China.
EM 2020222055212@stu.scu.edu.cn; 2019222050173@stu.scu.edu.cn;
   yanhua@scu.edu.cn
OI Yan, Hua/0000-0001-9231-3175
CR [Anonymous], Tusimple
   Chiu KY, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P706
   Ghafoorian M, 2019, LECT NOTES COMPUT SC, V11129, P256, DOI 10.1007/978-3-030-11009-3_15
   Ghazali K., 2012, 2012 Fourth International Conference on Computational Intelligence, Modelling and Simulation (CIMSiM 2012), P205, DOI 10.1109/CIMSim.2012.31
   Hang Xu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P689, DOI 10.1007/978-3-030-58555-6_41
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou YN, 2019, IEEE I CONF COMP VIS, P1013, DOI 10.1109/ICCV.2019.00110
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jayasinghe O, 2021, 20TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2021), P859, DOI 10.1109/ICMLA52953.2021.00142
   Kluge K., 1995, Proceedings of the Intelligent Vehicles '95. Symposium (Cat. No.95TH8132), P54, DOI 10.1109/IVS.1995.528257
   Ko Y, 2022, IEEE T INTELL TRANSP, V23, P8949, DOI 10.1109/TITS.2021.3088488
   Lee JW, 2009, ICCIT: 2009 FOURTH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND CONVERGENCE INFORMATION TECHNOLOGY, VOLS 1 AND 2, P1586, DOI 10.1109/ICCIT.2009.81
   Lee M, 2022, IEEE WINT CONF APPL, P1949, DOI 10.1109/WACV51458.2022.00201
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu T, 2020, IEEE INT VEH SYM, P1394, DOI 10.1109/IV47402.2020.9304613
   Liu Y.B., 2020, arXiv
   Neven D, 2018, IEEE INT VEH SYM, P286
   Pan XG, 2018, AAAI CONF ARTIF INTE, P7276
   Paszke A, 2019, ADV NEUR IN, V32
   Tabelini L, 2021, PROC CVPR IEEE, P294, DOI 10.1109/CVPR46437.2021.00036
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yoo S, 2020, IEEE COMPUT SOC CONF, P4335, DOI 10.1109/CVPRW50498.2020.00511
   Yu B, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P748, DOI 10.1109/ICIP.1997.638604
   Yu F., 2015, ARXIV
   Yuenan Hou, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12483, DOI 10.1109/CVPR42600.2020.01250
   Zequn Qin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P276, DOI 10.1007/978-3-030-58586-0_17
   Zheng T, 2021, Arxiv, DOI arXiv:2008.13719
NR 27
TC 0
Z9 0
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21743
EP 21756
DI 10.1007/s11042-023-14845-9
EA FEB 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000939106100001
DA 2024-07-18
ER

PT J
AU Samanta, A
   Hatai, I
   Mal, AK
AF Samanta, Anu
   Hatai, Indranil
   Mal, Ashis Kumar
TI An energy-efficient voice activity detector using reconfigurable
   Gaussian base normalization deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural networks; Voice activity detection; Gaussian base
   normalization deep neural network; Time-frequency non-negative matrix
   factorization
ID AUTOMATIC SPEECH RECOGNITION; DNN
AB This research paper proposed deep neural networks and approximation computation are used to create an energy-efficient voice activity detector (VDA). The proposed technique is split up into two parts: feature extraction and voice/noise classification using a deep neural network with Gaussian basis normalization (GNDNN). Pre-processing of input data initially: the digitalized speech signal's high-frequency components are pre-emphasized, trying to make it a little less susceptible to finite precision impacts later inside the signal processing. The feature extraction module uses Mel-frequency cepstral coefficients (MFCC), time-frequency non-negative matrix factorization (TFNMF), to extract the input speech signals feature value. The TFNMF, MFCC output from feature extraction is classified by the GNDNN speech prediction phase, which evaluates whether the signal is indeed a voice or noise. The proposed approach can be dynamically changed to meet various computing accuracy demands. Our proposed approach most exciting accuracy result of 98.75%. Comparable to the CNN and DNN, which achieves the accuracy of 97.25%, 95.25%, and EERA had the worst accuracy 88.75%. The results of the experiments show that our proposed strategy outperforms previous methods.
C1 [Samanta, Anu] Brainware Univ, Dept Elect & Commun Engn, Kolkata, West Bengal, India.
   [Hatai, Indranil] Mathworks India Pvt Ltd, Bangalore, India.
   [Mal, Ashis Kumar] NIT Durgapur, Dept Elect & Commun Engn, Durgapur, West Bengal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur
RP Samanta, A (corresponding author), Brainware Univ, Dept Elect & Commun Engn, Kolkata, West Bengal, India.
EM anusamanta4@gmail.com
CR Albinsaid H, 2020, IEEE COMMUN LETT, V24, P2775, DOI 10.1109/LCOMM.2020.3015810
   Anderson R, 2020, EURASIP J ADV SIG PR, V2020, DOI 10.1186/s13634-020-00681-8
   [Anonymous], 2010, FUNDAMENTALS SPEECH
   Braun S, 2021, EUR SIGNAL PR CONF, P421, DOI 10.23919/EUSIPCO54536.2021.9616082
   Chen Y. -H., 2018, ENERGY, V2, pL3
   Dellaferrera G, 2020, INT CONF ACOUST SPEE, P3207, DOI [10.1109/ICASSP40776.2020.9054761, 10.1109/icassp40776.2020.9054761]
   Fan ZC, 2019, INT CONF ACOUST SPEE, P6760, DOI 10.1109/ICASSP.2019.8682803
   FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P342, DOI 10.1109/TASSP.1981.1163605
   Jacob AJ., 2021, INT J RES ENGIN SCI, V4, P134
   Kim CH, 2020, NAT GENET, V6
   Korkmaz Y, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103520
   Koteswararao YV, 2021, MULTIMEDIA SYST, V27, P271, DOI 10.1007/s00530-020-00740-y
   Lee S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082911
   Lee T, 2019, 2019 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2019), P381, DOI [10.1109/APCCAS47518.2019.8953078, 10.1109/apccas47518.2019.8953078, 10.1145/3300061.3345447]
   Liu B, 2019, MICROELECTRON J, V87, P12, DOI 10.1016/j.mejo.2019.03.009
   Liu B, 2018, IEEE ACCESS, V6, P52227, DOI 10.1109/ACCESS.2018.2870273
   Liu WQ, 2019, IEEE T CIRCUITS-I, V66, P4727, DOI 10.1109/TCSI.2019.2933321
   Luckenbaugh J, 2021, INTERSPEECH, P4374, DOI 10.21437/Interspeech.2021-1234
   Martinelli F, 2020, INT CONF ACOUST SPEE, P8544, DOI [10.1109/ICASSP40776.2020.9053412, 10.1109/icassp40776.2020.9053412]
   Mason J. S., 1991, ICASSP 91: 1991 International Conference on Acoustics, Speech and Signal Processing (Cat. No.91CH2977-7), P3673, DOI 10.1109/ICASSP.1991.151073
   Mihalache S, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22031228
   Oh S, 2019, IEEE J SOLID-ST CIRC, V54, P3005, DOI 10.1109/JSSC.2019.2936756
   Oh YR, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10124091
   Ovaska M, 2021, ARXIV
   Price M, 2018, IEEE J SOLID-ST CIRC, V53, P66, DOI 10.1109/JSSC.2017.2752838
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Rios-Navarro A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10010094
   Savran A, 2018, IEEE INT CONF AUTOMA, P333, DOI 10.1109/FG.2018.00055
   Smit P, 2021, COMPUT SPEECH LANG, V66, DOI 10.1016/j.csl.2020.101158
   Sterneck R, 2021, ARXIV
   Teng P, 2013, IEEE SIGNAL PROC LET, V20, P475, DOI 10.1109/LSP.2013.2252615
   Wilkinson N, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6803, DOI 10.1109/ICASSP39728.2021.9415081
   Yin SY, 2018, SYMP VLSI CIRCUITS, P37, DOI 10.1109/VLSIC.2018.8502388
   Yin SY, 2019, IEEE T COMPUT AID D, V38, P678, DOI 10.1109/TCAD.2018.2821561
   Yoshimura T, 2020, INT CONF ACOUST SPEE, P6999, DOI [10.1109/icassp40776.2020.9054358, 10.1109/ICASSP40776.2020.9054358]
   Yu HJ, 2020, SPEECH COMMUN, V125, P142, DOI 10.1016/j.specom.2020.10.007
   Zhang J, 2018, DES AUT CON, DOI 10.1145/3195970.3196129
   Zheng Z., 2020, ARXIV
NR 38
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27861
EP 27882
DI 10.1007/s11042-023-14699-1
EA FEB 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000936292600006
DA 2024-07-18
ER

PT J
AU Yu, ZH
   Ma, YP
   Zhou, YQ
   Wang, CK
   Li, QW
AF Yu, Zhihong
   Ma, Yunpeng
   Zhou, Yaqin
   Wang, Chunkuan
   Li, Qingwu
TI A binocular stereo visual servo system for bird repellent in substations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bird repellent in substations; Binocular stereo visual servo system;
   Binocular vision; Visual servo; Bird detection and location
ID OBJECT; VISION
AB Bird damage has become one of the main threats to the safety of substations, and the accidents (short circuit, grounding failure and insulation flashover) caused by birds are increasing year by year. However, most existing devices and methods have little effect on intimidating birds in the substation, so they cannot meet the requirements for repelling birds in a high-efficiency and accurate way. In this paper, a binocular stereo visual servo system for bird repellent in substations is developed to detect, locate and repel birds in real-time. The system consists of a small processing computer, a rotatable Pan-tilt based on visual servo and the remote monitoring PC. In order to realize better real-time detection tasks, we improve the YOLOv3-tiny model by reducing the number of convolution kernels to reduce the parameters in the model and make the algorithm faster. And based on the bird detection results, we adopt binocular stereo vision and the coordinate conversion to obtain the distance and the angles of the bird relative to the laser. Experimental results in the actual working environment (the 220 kV substation) reveal that the proposed system could meet the real-time and accuracy requirements of detecting, locating and repelling the bird in practical substation application.
C1 [Yu, Zhihong; Ma, Yunpeng; Zhou, Yaqin; Wang, Chunkuan; Li, Qingwu] Hohai Univ, Coll Internet Things Engn, Changzhou 213022, Peoples R China.
   [Ma, Yunpeng; Zhou, Yaqin; Li, Qingwu] Hohai Univ, Jiangsu Key Lab Power Transmiss & Distribut Equipm, Changzhou 213022, Peoples R China.
C3 Hohai University; Hohai University
RP Li, QW (corresponding author), Hohai Univ, Coll Internet Things Engn, Changzhou 213022, Peoples R China.; Li, QW (corresponding author), Hohai Univ, Jiangsu Key Lab Power Transmiss & Distribut Equipm, Changzhou 213022, Peoples R China.
EM li_qingwu@163.com
OI li, qingwu/0000-0003-3224-9831
FU National Natural Science Foundation of China [62001156]; Key Research
   and Development Program of Jiangsu Province [BE2021042, BE2020092,
   BE2020649]; Jiangsu Key Laboratory of Power Transmission and
   Distribution Equipment Technology [2021JSSPD04]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This study
   is funded by National Natural Science Foundation of China under Grant
   (62001156), the Key Research and Development Program of Jiangsu Province
   under Grant (BE2021042, BE2020092 and BE2020649) and Project from
   Jiangsu Key Laboratory of Power Transmission and Distribution Equipment
   Technology (2021JSSPD04).
CR Chang TY, 2021, INT J ADV ROBOT SYST, V18, DOI 10.1177/17298814211016674
   Chattopadhyay A, 2018, IEEE T IND INFORM, V14, P2442, DOI 10.1109/TII.2017.2770096
   Deng F, 2020, IEEE T IMAGE PROCESS, V29, P5531, DOI 10.1109/TIP.2020.2984898
   Duan KW, 2020, IEEE T CIRC SYST VID, V30, P1639, DOI 10.1109/TCSVT.2019.2906246
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Feng D, 2018, IEEE T TRANSP ELECTR, V4, P389, DOI 10.1109/TTE.2017.2784959
   Göring C, 2014, PROC CVPR IEEE, P2489, DOI 10.1109/CVPR.2014.319
   Grujic A, 2011, INT J ELEC ENG EDUC, V48, P307, DOI 10.7227/IJEEE.48.3.8
   Hao Pan, 2021, 2021 IEEE Sustainable Power and Energy Conference (iSPEC), P2559, DOI 10.1109/iSPEC53008.2021.9735826
   He ZF, 2021, POLYM REV, V61, P689, DOI 10.1080/15583724.2021.1881792
   Hsu WY, 2021, IEEE T IMAGE PROCESS, V30, P934, DOI 10.1109/TIP.2020.3039574
   Juhuai Mo, 2020, 2020 7th International Conference on Information, Cybernetics, and Computational Social Systems (ICCSS), P808, DOI 10.1109/ICCSS52145.2020.9336861
   Kaur M, 2019, NEURAL COMPUT APPL, V31, P7975, DOI 10.1007/s00521-018-3642-7
   Kaur M, 2018, ARAB J SCI ENG, V43, P8127, DOI 10.1007/s13369-018-3355-3
   Kaur M, 2018, MOD PHYS LETT B, V32, DOI 10.1142/S0217984918501154
   Langåker HA, 2021, INT J ADV ROBOT SYST, V18, DOI 10.1177/17298814211002973
   Le FL, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1983, DOI 10.1109/ROBIO.2009.5420529
   Li G, 2018, PROCEEDINGS OF THE 16TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2018), DOI 10.1145/3284398.3284422
   Li XR, 2019, IEEE T MULTIMEDIA, V21, P2347, DOI 10.1109/TMM.2019.2896494
   Li YE, 2020, IEEE T NUCL SCI, V67, P2454, DOI 10.1109/TNS.2020.3022103
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Liu PC, 2018, NONLINEAR DYNAM, V94, P1803, DOI 10.1007/s11071-018-4458-9
   Lu XQ, 2020, IEEE T GEOSCI REMOTE, V58, P179, DOI 10.1109/TGRS.2019.2935177
   Ma JJ, 2019, IEEE T POWER ELECTR, V34, P9719, DOI 10.1109/TPEL.2019.2895043
   MUMINOV A, 2017, 2017 INT C INF SCI C, P1
   Norton GH, 2000, IEEE T INFORM THEORY, V46, P1060, DOI 10.1109/18.841186
   Permal N, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2019), P630, DOI [10.1109/CCOMS.2019.8821681, 10.1109/ccoms.2019.8821681]
   Qu Fang, 2011, 2011 IEEE Power Engineering and Automation Conference (PEAM 2011), P217, DOI 10.1109/PEAM.2011.6134839
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sadykova D, 2020, IEEE T POWER DELIVER, V35, P1599, DOI 10.1109/TPWRD.2019.2944741
   Sangineto E, 2019, IEEE T PATTERN ANAL, V41, P712, DOI 10.1109/TPAMI.2018.2804907
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Sundararajan R, 2004, IEEE T POWER DELIVER, V19, P1848, DOI 10.1109/TPWRD.2003.822522
   Tang J, 2018, C IND ELECT APPL, P270, DOI 10.1109/ICIEA.2018.8397727
   Wang HQ, 2018, INTL CONF POWER SYST, P2929, DOI 10.1109/POWERCON.2018.8602005
   Wang J, 2019, IEEE INT C NETW SENS, P218, DOI [10.1109/icnsc.2019.8743162, 10.1109/ICNSC.2019.8743162]
   Wen M, 2020, CSEE J POWER ENERGY, V6, P554, DOI 10.17775/CSEEJPES.2019.01970
   Xiao DP, 2020, IEEE T INSTRUM MEAS, V69, P9389, DOI 10.1109/TIM.2020.3001696
   Xin J, 2021, INT J ADV ROBOT SYST, V18, DOI 10.1177/1729881421990320
   Yao GB, 2018, IEEE T GEOSCI REMOTE, V56, P559, DOI 10.1109/TGRS.2017.2751567
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhao JB, 2021, IEEE T VIS COMPUT GR, V27, P3277, DOI 10.1109/TVCG.2020.2969181
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhen Yang, 2019, 2019 IEEE 19th International Conference on Communication Technology (ICCT), P1673, DOI 10.1109/ICCT46805.2019.8947158
   Zhou M, 2020, CSEE J POWER ENERGY, V6, P236, DOI 10.17775/CSEEJPES.2019.02840
NR 45
TC 0
Z9 0
U1 11
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29353
EP 29377
DI 10.1007/s11042-023-14667-9
EA FEB 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000936292600005
DA 2024-07-18
ER

PT J
AU Mansoor, S
   Parah, SA
AF Mansoor, Shaista
   Parah, Shabir A.
TI HAIE: a hybrid adaptive image encryption algorithm using Chaos and DNA
   computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive image encryption; Chaotic maps; DNA computing; Logistic map;
   Tent map
AB In this paper, a distinctive Hybrid Adaptive Image Encryption (HAIE) scheme is proposed that utilizes some statistical parameters of the plain image like mean and variance to modify the initial conditions and control parameters of the chaotic system. The proposed scheme involves two one-dimensional chaotic maps; logistic map and tent map to generate the pseudo-random sequences. The reason for the scheme being distinctive is that the outcome of the confusion phase, i.e. the permuted image is a hybrid one. Half of the plain image is permuted using the logistic map and the other half using the tent map. The two half-permuted images are concatenated after being encoded into DNA sequences using a DNA coding rule. Another random sequence generated using the logistic map is also encoded into a DNA sequence using the same rule. Finally, in the diffusion phase, the two DNA sequences are operated using the DNA addition operation and then decoded using the same DNA decoding rule followed by a XOR operation. The various experimental results like NPCR (Number of Pixel Changing Rate), UACI (Unified Average Changing Intensity), entropy, and correlation coefficients are calculated. For all the test images used, NPCR and UACI values are closer to their ideal values of 99.61% and 33.46%, respectively, entropy is also approximately equal to 8, and likewise, correlation coefficients are closer to zero in the encrypted images. Some other parameters like SSIM (Structural Similarity) and PSNR (Peak Signal to Noise Ratio) are also calculated and lie in their expected range. The scheme is also subjected to noise and cropping attacks. It is observed that the scheme is highly robust against these attacks. Additionally, being adaptive, the proposed algorithm is resilient to chosen and known plaintext attacks. All these experimental observations indicate that the proposed scheme has not only a good encryption effect but can resist various attacks as well.
C1 [Mansoor, Shaista; Parah, Shabir A.] Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar 190006, Jammu & Kashmir, India.
C3 University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar 190006, Jammu & Kashmir, India.
EM shabireltr@gmail.com
OI Parah, Shabir/0000-0001-5983-0912
FU JK Science Technology and Innovation Council [JKSTIC/SRE/874-77]
FX AcknowledgementsThe authors would like to acknowledge the support of JK
   Science Technology and Innovation Council for funding this work under
   fund number (JKST&IC/SRE/874-77).
CR ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Alghafis A, 2020, MATH COMPUT SIMULAT, V177, P441, DOI 10.1016/j.matcom.2020.05.016
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Arpaci B, 2020, J ELECTR ENG TECHNOL, V15, P1413, DOI 10.1007/s42835-020-00393-x
   Babaei A, 2020, OPTIK, V203, DOI 10.1016/j.ijleo.2019.164000
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, INT J MOD PHYS C, V28, DOI 10.1142/S0129183117500693
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   El-Samie F.E. A., 2013, Image encryption: A communication perspective, DOI 10.1201/b1630
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Huang HQ, 2019, IEEE ACCESS, V7, P177988, DOI 10.1109/ACCESS.2019.2958319
   Kang XJ, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115670
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Luo YL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105836
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Mondal B, 2017, J KING SAUD UNIV-COM, V29, P499, DOI 10.1016/j.jksuci.2016.02.003
   Niu Y, 2020, MULTIMED TOOLS APPL, V79, P25613, DOI 10.1007/s11042-020-09237-2
   Patro KAK, 2019, J INF SECUR APPL, V46, P23, DOI 10.1016/j.jisa.2019.02.006
   Ping P, 2018, IEEE ACCESS, V6, P67581, DOI 10.1109/ACCESS.2018.2879565
   Sravanthi D, 2019, ADV INTELL SYST, V758, P717, DOI 10.1007/978-981-13-0514-6_68
   Sun S, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2017.2766087
   Sun SL, 2019, IEEE ACCESS, V7, P28539, DOI 10.1109/ACCESS.2019.2901870
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   Wang XY, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106366
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yasser I, 2020, COMPLEXITY, P23
   Ye GD, 2016, SECUR COMMUN NETW, V9, P2015, DOI 10.1002/sec.1458
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zarebnia M, 2019, OPTIK, V179, P761, DOI 10.1016/j.ijleo.2018.10.025
   Zefreh EZ, 2020, MULTIMED TOOLS APPL, V79, P24993, DOI 10.1007/s11042-020-09111-1
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013021
   Zhang J, 2019, MULTIMED TOOLS APPL, V78, P15605, DOI 10.1007/s11042-018-6973-6
NR 37
TC 19
Z9 19
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 28769
EP 28796
DI 10.1007/s11042-023-14542-7
EA FEB 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000936302600005
DA 2024-07-18
ER

PT J
AU Singh, YB
   Goel, S
AF Singh, Youddha Beer
   Goel, Shivani
TI A lightweight 2D CNN based approach for speaker-independent emotion
   recognition from speech with new Indian Emotional Speech Corpora
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional Neural Network; Indian Emotional Speech Corpora;
   Spectrogram; Speech Emotion Recognition
ID FEATURES; CLASSIFICATION
AB Speech Emotion Recognition (SER) is the process of recognizing emotions by extracting few features of speech signals. It is becoming very popular in Human Computer Interaction (HCI) applications. The challenge is to extract relevant features of speech to recognize emotions with a low computational cost. In this paper, a lightweight Convolutional Neural Network (LCNN) based model has been proposed which extracts useful features automatically. The speech samples are converted into spectrograms of size 224 x 224 for LCNN input. 5 CNN layers and stride are used for down-sampling the feature maps in place of pooling layers which reduces the computational cost. It has been evaluated for accuracy on publicly available benchmark datasets EMOVO (81%), EMODB (87%), and SAVEE (80%). The accuracy of proposed model is also found to be better than SER CNN-assisted model, ResNet-18 and ResNet-34 models. Very few speech datasets are available in Indian ascent. So, authors have created a new Indian Emotional Speech Corpora (IESC) in English language with 600 speech samples recorded from 8 speakers using 2 sentences in 5 emotions. It will be made publicly available for researchers. The accuracy of the proposed LCNN model on IESC is found to be 95% which is better than existing datasets.
C1 [Singh, Youddha Beer; Goel, Shivani] Bennett Univ, Sch Comp Sci Engn & Technol, Greater Noida 201310, UP, India.
   [Singh, Youddha Beer] KIET Grp Inst, Dept Comp Sci & Informat Technol, Ghaziabad 201306, UP, India.
C3 KIET Group of Institutions
RP Singh, YB (corresponding author), Bennett Univ, Sch Comp Sci Engn & Technol, Greater Noida 201310, UP, India.; Singh, YB (corresponding author), KIET Grp Inst, Dept Comp Sci & Informat Technol, Ghaziabad 201306, UP, India.
EM youddhabeersingh@gmail.com
RI Singh, Youddha Beer Beer/CAJ-4542-2022
OI Singh, Youddha Beer Beer/0000-0002-3745-2823
CR [Anonymous], 2015, 2015 7 C INFORM KNOW, DOI DOI 10.1109/IKT.2015.7288756
   Bansal S, 2013, P INT C OR COCOSDA H, P1, DOI [10.1109/ICSDA.2013.6709867, DOI 10.1109/ICSDA.2013.6709867]
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Costantini G, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3501
   Dai Keshi, 2008, Proceedings of the Fourth IASTED International Conference on Telehealth and Assistive Technologies, P31
   Daneshfar F, 2020, MULTIMED TOOLS APPL, V79, P1261, DOI 10.1007/s11042-019-08222-8
   Deng J, 2017, IEEE SIGNAL PROC LET, V24, P500, DOI 10.1109/LSP.2017.2672753
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Firoz Shah A., 2009, Proceedings of the 2009 International Conference on Advances in Computing, Control, & Telecommunication Technologies (ACT 2009), P162, DOI 10.1109/ACT.2009.49
   Gu Chunhui, 2018, INT C COMP VIS PATT
   Han K, 2014, INTERSPEECH, P223
   Haq S., 2011, MACHINE AUDITION PRI, P398, DOI DOI 10.4018/978-1-61520-919-4.CH017
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   IESC, US
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   Jahangir R, 2021, MULTIMED TOOLS APPL, V80, P23745, DOI 10.1007/s11042-020-09874-7
   Kaya H, 2018, NEUROCOMPUTING, V275, P1028, DOI 10.1016/j.neucom.2017.09.049
   Khanchandani KB, 2009, J SCI IND RES INDIA, V68, P367
   Kim Y, 2013, INT CONF ACOUST SPEE, P3687, DOI 10.1109/ICASSP.2013.6638346
   Koolagudi SG, 2012, INT J SPEECH TECHNOL, V15, P495, DOI 10.1007/s10772-012-9150-8
   Koolagudi SG, 2018, INT J SPEECH TECHNOL, V21, P167, DOI 10.1007/s10772-018-9495-8
   Koolagudi SG, 2009, COMM COM INF SC, V40, P485, DOI 10.1007/978-3-642-03547-0_46
   Lakomkin E, 2018, IEEE INT C INT ROBOT, P854, DOI 10.1109/IROS.2018.8593571
   Lee MC, 2020, MULTIMED TOOLS APPL, V79, P19629, DOI 10.1007/s11042-020-08841-6
   Li SZ, 2021, NEUROCOMPUTING, V448, P238, DOI 10.1016/j.neucom.2021.02.094
   Liu ZT, 2018, NEUROCOMPUTING, V273, P271, DOI 10.1016/j.neucom.2017.07.050
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI [DOI 10.1109/ICDEW.2006.145, 10.1109/ICDEW.2006.145]
   Mo SS, 2018, NEUROCOMPUTING, V291, P11, DOI 10.1016/j.neucom.2018.02.052
   Mustaqeem, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010183
   Nakatsu R, 2000, KNOWL-BASED SYST, V13, P497, DOI 10.1016/S0950-7051(00)00070-8
   Niu JW, 2014, 2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), P128, DOI 10.1109/ISCSLP.2014.6936657
   Özseven T, 2019, APPL ACOUST, V146, P320, DOI 10.1016/j.apacoust.2018.11.028
   Özseven T, 2018, APPL ACOUST, V142, P70, DOI 10.1016/j.apacoust.2018.08.003
   Partila P., 2013, NOSTRADAMUS 2013 PRE, P221, DOI DOI 10.1007/978-3-319-00542-3_23
   Polzehl T, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P340
   Polzin T, 1998, P COOPERATIVE MULTIM
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Savargiv M., 2014, Journal of Computer & Robotics, V7, P19
   Savargiv M, 2016, 2016 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P72, DOI 10.1109/RIOS.2016.7529493
   Sharma R, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2020.101867
   Singh Youddha Beer, 2018, 2018 International Conference on Advances in Computing, Communication Control and Networking (ICACCCN). Proceedings, P298, DOI 10.1109/ICACCCN.2018.8748379
   Singh YB, 2021, MULTIMED TOOLS APPL, V80, P14001, DOI 10.1007/s11042-020-10399-2
   Stuhlsatz A, 2011, INT CONF ACOUST SPEE, P5688
   Tang DK, 2018, INTERSPEECH, P162
   Tang H, 2009, IEEE INT CON MULTI, P294, DOI 10.1109/ICME.2009.5202493
   ten Bosch L, 2003, SPEECH COMMUN, V40, P213, DOI 10.1016/S0167-6393(02)00083-3
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101
   Wang L., 2005, SUPPORT VECTOR MACHI, V177, DOI [10.1007/b95439, DOI 10.1007/B95439]
   Womack BD, 1999, IEEE T SPEECH AUDI P, V7, P668, DOI 10.1109/89.799692
   Wu L, 2020, IEEE T CIRC SYST VID, V30, P2081, DOI 10.1109/TCSVT.2019.2909549
   Yang W, 2018, ACM T MULTIM COMPUT, V37
   Zayene B, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP'2020), DOI 10.1109/atsip49331.2020.9231597
   Zhang WS, 2017, SOFTWARE PRACT EXPER, V47, P1127, DOI 10.1002/spe.2487
   Zhang Y, 2017, INT CONF ACOUST SPEE, P4990, DOI 10.1109/ICASSP.2017.7953106
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   Zheng WM, 2014, IEEE SIGNAL PROC LET, V21, P569, DOI 10.1109/LSP.2014.2308954
   Zhou J, 2006, PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, VOLS 1 AND 2, P53
   Zvarevashe K, 2020, ALGORITHMS, V13, DOI 10.3390/a13030070
NR 61
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23055
EP 23073
DI 10.1007/s11042-023-14577-w
EA FEB 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000936195100009
DA 2024-07-18
ER

PT J
AU Tous, R
AF Tous, Ruben
TI Pictonaut: movie cartoonization using 3D human pose estimation and GANs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital content creation; Deep learning; Computer vision; Computer
   graphics; Image cartoonization; Human pose estimation; Generative
   adversarial networks
AB This article describes Pictonaut, a novel method to automatically synthetise animated shots from motion picture footage. Its results are editable (backgrounds, characters, lighting, etc.) with conventional 3D software, and they have the finish of professional 2D animation. Rather than addressing the challenge solely as an image translation problem, a hybrid approach combining multi-person 3D human pose estimation and GANs is taken. Sub-sampled video frames are processed with OpenPose and SMPLify-X to obtain the 3D parameters of the pose (body, hands and face expression) of all depicted characters. The captured parameters are retargeted into manually selected 3D models, cel shaded to mimic the style of a 2D cartoon. The results of sub-sampled frames are interpolated to generate a complete and smooth motion for all the characters. The background is cartoonized with a GAN. Qualitative evaluation shows that the approach is feasible, and a small dataset of synthetised shots obtained from real movie scenes is provided.
C1 [Tous, Ruben] Univ Politecn Cataluna, Dept Comp Architecture, Jordi Girona 1-3, Barcelona 08034, Spain.
C3 Universitat Politecnica de Catalunya
RP Tous, R (corresponding author), Univ Politecn Cataluna, Dept Comp Architecture, Jordi Girona 1-3, Barcelona 08034, Spain.
EM rtous@ac.upc.edu
RI Tous, Ruben/N-5610-2014
OI Tous, Ruben/0000-0002-1409-5843
FU Spanish Ministry of Science and Innovation [PID2019-107255GB]; SGR
   programme of the Catalan Government [2017-SGR-1414]
FX This work is partially supported by the Spanish Ministry of Science and
   Innovation under contract PID2019-107255GB, and by the SGR programme
   2017-SGR-1414 of the Catalan Government.
CR Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Canini L, 2011, INT SYMP IMAGE SIG, P253
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chen J., 2020, INT S INT COMP APPL, P242, DOI DOI 10.1007/978-981-15-5577-0_18
   Chen Y, 2018, PROC CVPR IEEE, P9465, DOI 10.1109/CVPR.2018.00986
   Cheng BW, 2020, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR42600.2020.00543
   Dawei Liang, 2005, 13th Annual ACM International Conference on Multimedia, P217, DOI 10.1145/1101149.1101184
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Geng ZG, 2021, PROC CVPR IEEE, P14671, DOI 10.1109/CVPR46437.2021.01444
   Inc A, 2021, AN 3D CHAR MIX
   Inc R, 2021, CHAR CREAT 3 3D CHAR
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Ji X., 2020, Virtual Reality Intell. Hardw., V2, P471, DOI DOI 10.1016/J.VRIH.2020.04.005
   Joo H, 2015, IEEE I CONF COMP VIS, P3334, DOI 10.1109/ICCV.2015.381
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Li YJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11293, DOI 10.1109/ICCV48922.2021.01112
   Liu Z., 2022, ARXIV
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Ngo V, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P103, DOI 10.1109/ICARCV.2008.4795500
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Rogez G, 2020, IEEE T PATTERN ANAL, V42, P1146, DOI 10.1109/TPAMI.2019.2892985
   Sethian J.A., 2000, Robotica, VVolume 18, P89, DOI DOI 10.1017/S0263574799212404
   Sridhar S, 2013, IEEE I CONF COMP VIS, P2456, DOI 10.1109/ICCV.2013.305
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tianye Li, 2017, ACM Transactions on Graphics, V36, DOI 10.1145/3130800.3130813
   Tous R, 2021, PICTONAUT EDITABLE
   University CM, 2001, AN 3D CHAR MIX
   Weng CY, 2019, PROC CVPR IEEE, P5901, DOI 10.1109/CVPR.2019.00606
   Xinrui Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8087, DOI 10.1109/CVPR42600.2020.00811
   Yang S., 2021, 2021 IEEECVF INT C C
   Zhang J., 2022, IEEECVF C COMPUT VIS, P13232
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 33
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21101
EP 21115
DI 10.1007/s11042-023-14556-1
EA FEB 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000934216300002
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Ma, YP
   Yu, ZH
   Zhou, YQ
   Xu, C
   Yu, DB
AF Ma, Yunpeng
   Yu, Zhihong
   Zhou, Yaqin
   Xu, Chang
   Yu, Dabing
TI Visual saliency detection via invariant feature constrained stacked
   denoising autoencoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual saliency detection; Saliency prediction; Saliency object
   segmentation; Stacked denoising autoencoder; Reconstruction network;
   Scale invariant feature
ID IMAGE; MODEL; RETRIEVAL; SEARCH; SIFT
AB Visual saliency detection is usually regarded as an image pre-processing method to predict and locate the position and shape of saliency regions. However, many existing saliency detection methods can only obtain the local or even incorrect position and shape of saliency regions, resulting in incomplete detection and segmentation of the salient target region. In order to solve this problem, a visual saliency detection method based on scale invariant feature and stacked denoising autoencoder is proposed. Firstly, the deep belief network would be pretrained to initialize the parameters of stacked denoising autoencoder network. Secondly, different from traditional features, scale invariant feature is not limited to the size, resolution, and content of original images. At the same time, it can help the network to restore important features of original images more accurately in multi-scale space. So, scale invariant feature is adopted to design the loss function of the network to complete self-training and update the parameters. Finally, the difference between the final reconstructed image obtained by stacked denoising autoencoder and the original is regarded as the final saliency map. In the experiment, we test the performance of the proposed method in both saliency prediction and saliency object segmentation. The experimental results show that the proposed method has good ability in saliency prediction and has the best performance in saliency object segmentation than other comparison saliency prediction methods and saliency object detection methods.
C1 [Ma, Yunpeng; Yu, Zhihong; Zhou, Yaqin; Xu, Chang; Yu, Dabing] Hohai Univ, Key Lab Sensor Networks & Environm Sensing, Changzhou 213022, Peoples R China.
   [Ma, Yunpeng; Zhou, Yaqin] Hohai Univ, Jiangsu Key Lab Power Transmiss & Distribut Equipm, Changzhou 213022, Peoples R China.
   [Ma, Yunpeng; Yu, Zhihong; Zhou, Yaqin; Xu, Chang; Yu, Dabing] Hohai Univ, Coll Internet Things Engn, Changzhou 213022, Peoples R China.
C3 Hohai University; Hohai University; Hohai University
RP Ma, YP (corresponding author), Hohai Univ, Key Lab Sensor Networks & Environm Sensing, Changzhou 213022, Peoples R China.; Ma, YP (corresponding author), Hohai Univ, Jiangsu Key Lab Power Transmiss & Distribut Equipm, Changzhou 213022, Peoples R China.; Ma, YP (corresponding author), Hohai Univ, Coll Internet Things Engn, Changzhou 213022, Peoples R China.
EM yunpengma_hhu@163.com
RI 徐, 畅/HLW-9902-2023
FU National Natural Science Foundation of China [62001156, 62201197];
   Fundamental Research Funds for the Central Universities [B220201037];
   Key Research and Development Program of Jiangsu Province [BE2021042,
   BE2020649]; Jiangsu Excellent Postdoctoral Program
FX This work was supported in part by National Natural Science Foundation
   of China under Grant (62001156, 62201197), the Fundamental Research
   Funds for the Central Universities (B220201037), the Key Research and
   Development Program of Jiangsu Province under Grant (BE2021042,
   BE2020649) and Jiangsu Excellent Postdoctoral Program.
CR Afsharirad H, 2019, MULTIMED TOOLS APPL, V78, P19081, DOI 10.1007/s11042-019-7431-9
   Ahlgren P, 2003, J AM SOC INF SCI TEC, V54, P550, DOI 10.1002/asi.10242
   [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   [Anonymous], 2005, Advances in neural information processing systems, DOI DOI 10.5555/2976248.2976268
   Aytekin C, 2018, IEEE T MULTIMEDIA, V20, P82, DOI 10.1109/TMM.2017.2713982
   Borji A., 2012, 2012 IEEE COMPUTER S, P23, DOI 10.1109/CVPRW.2012.6239191
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Bruce N., 2010, Journal of Vision, V7, P950, DOI [10.1167/7.9.950, DOI 10.1167/7.9.950]
   Chang HH, 2019, MULTIMED TOOLS APPL, V78, P21731, DOI 10.1007/s11042-019-7462-2
   Cheng H, 2019, IEEE T MULTIMEDIA, V21, P678, DOI 10.1109/TMM.2018.2864613
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   DUNCAN J, 1989, PSYCHOL REV, V96, P433, DOI 10.1037/0033-295X.96.3.433
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Fang S, 2017, IEEE T NEUR NET LEAR, V28, P1095, DOI 10.1109/TNNLS.2016.2522440
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   Gao Y, 2015, IEEE T MULTIMEDIA, V17, P359, DOI 10.1109/TMM.2015.2389616
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI DOI 10.1109/CVPR.2010.5539929
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He JF, 2012, PROC CVPR IEEE, P3005, DOI 10.1109/CVPR.2012.6248030
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Huang F, 2017, IEEE T IMAGE PROCESS, V26, P1911, DOI 10.1109/TIP.2017.2669878
   Jerripothula KR, 2016, IEEE T MULTIMEDIA, V18, P1896, DOI 10.1109/TMM.2016.2576283
   Jia S, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103887
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kim KS, 2014, 2014 IEEE 3RD GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P317, DOI 10.1109/GCCE.2014.7031272
   Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399
   Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Liu F., 2017, ACTA OPT SINICA, V37, P272
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma C, 2017, IEEE T MULTIMEDIA, V19, P2415, DOI 10.1109/TMM.2017.2694219
   Mahadevan V, 2013, IEEE T PATTERN ANAL, V35, P541, DOI 10.1109/TPAMI.2012.98
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Pingping Zhang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P202, DOI 10.1109/ICCV.2017.31
   Qian XM, 2017, IEEE T MULTIMEDIA, V19, P813, DOI 10.1109/TMM.2016.2638207
   Rafiee G, 2013, PATTERN RECOGN, V46, P2685, DOI 10.1016/j.patcog.2013.03.006
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Riaz S, 2016, MULTIMED TOOLS APPL, V75, P16439, DOI 10.1007/s11042-015-3037-z
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Tavakoli HR, 2017, LECT NOTES COMPUT SC, V10116, P287, DOI 10.1007/978-3-319-54407-6_19
   Vikram TN, 2012, PATTERN RECOGN, V45, P3114, DOI 10.1016/j.patcog.2012.02.009
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Xia C, 2016, IEEE T NEUR NET LEAR, V27, P1227, DOI 10.1109/TNNLS.2015.2512898
   Xiao S, 2020, MULTIMED TOOLS APPL, V79, P17245, DOI 10.1007/s11042-019-7423-9
   Xiao XL, 2019, IEEE T IMAGE PROCESS, V28, P2126, DOI 10.1109/TIP.2018.2882156
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yang S, 2020, IEEE T MULTIMEDIA, V22, P2163, DOI 10.1109/TMM.2019.2947352
   Yang XY, 2015, IEEE T IMAGE PROCESS, V24, P1709, DOI 10.1109/TIP.2015.2411433
   Ye LW, 2017, IEEE T MULTIMEDIA, V19, P1742, DOI 10.1109/TMM.2017.2693022
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 64
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27451
EP 27472
DI 10.1007/s11042-023-14525-8
EA FEB 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000937944300004
DA 2024-07-18
ER

PT J
AU Priyadarshini, I
   Sahu, S
   Kumar, R
AF Priyadarshini, Ishaani
   Sahu, Sandipan
   Kumar, Raghvendra
TI A transfer learning approach for detecting offensive and hate speech on
   social media platforms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hate speech; Transfer learning; Word2vec model; GloVe model; LSTM
AB Over the last few decades, the expansion of technology and the internet has led to the number of users proliferating on social media, with a simultaneous increase in hate speech. A critical concern is, hate speech is not only responsible for igniting violence and spreading hatred, but its detection also requires a considerable amount of computing resources and content monitoring by human experts and algorithms. While the research is an active area, and several artificial intelligence techniques have been proposed in the past to address the concern, the rise in the number of petabytes of the content generated calls for methods that will exhibit improved performance and reduced model development time. We propose a transfer learning approach for detecting hate and offensive speech on social media that deploys a pre-trained model for data analysis thereby promoting model reusability. We propose two transfer learning models, i.e. Google's Word2vec model using LSTM and GloVe Model using LSTM for the same and compare the performance of our proposed model against unigram and bigram language models for Naive Bayes (NB), Decision Trees (DT), and Support Vector Machines (SVM), which are also the baseline algorithms considered for analysis. The performance of the proposed models for classifying hate speech, offensive speech, and neutral speech is validated using metrics such as precision, recall, F-1 score, and support. The overall performance of the models across multiple datasets has been evaluated with respect to accuracy. In-depth experimental analysis and results depict that the proposed model is significantly robust for detecting hateful and offensive speech and also performs better than the considered baseline algorithms.
C1 [Priyadarshini, Ishaani] Univ Calif Berkeley, Sch Informat, Berkeley, CA USA.
   [Sahu, Sandipan] Bengal Inst Technol, Dept Comp Sci & Engn, Kolkata, India.
   [Kumar, Raghvendra] GIET Univ, Dept Comp Sci & Engn, Gunupur, India.
C3 University of California System; University of California Berkeley; GIET
   University
RP Kumar, R (corresponding author), GIET Univ, Dept Comp Sci & Engn, Gunupur, India.
EM ishaani@berkeley.edu; sahusandipan@gmail.com; raghvendra@giet.edu
CR Al-Hassan A, 2022, MULTIMEDIA SYST, V28, P1963, DOI 10.1007/s00530-020-00742-w
   Al-Makhadmeh Z, 2020, COMPUTING, V102, P501, DOI 10.1007/s00607-019-00745-0
   García-Díaz JA, 2023, COMPLEX INTELL SYST, V9, P2893, DOI 10.1007/s40747-022-00693-x
   Aulia N, 2019, ICCAI '19 - PROCEEDINGS OF THE 2019 5TH INTERNATIONAL CONFERENCE ON COMPUTING AND ARTIFICIAL INTELLIGENCE, P164, DOI 10.1145/3330482.3330491
   Ayo FE, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100311
   Aziz NAA, 2021, 2021 3RD INTERNATIONAL CYBER RESILIENCE CONFERENCE (CRC), P78, DOI 10.1109/CRC50527.2021.9392486
   Briliani A, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS AND INTELLIGENCE SYSTEM (IOTAIS), P98, DOI [10.1109/iotais47347.2019.8980398, 10.1109/IoTaIS47347.2019.8980398]
   Gamback B., 2017, P 1 WORKSH AB LANG O, P85, DOI [DOI 10.18653/V1/W17-3013, 10.18653/v1/W17-3013]
   Gencoglu O, 2021, IEEE INTERNET COMPUT, V25, P20, DOI 10.1109/MIC.2020.3032461
   Hajung Sohn, 2019, 2019 International Conference on Data Mining Workshops (ICDMW). Proceedings, P551, DOI 10.1109/ICDMW.2019.00084
   Jha S, 2019, IEEE ACCESS, V7, P61840, DOI 10.1109/ACCESS.2019.2913349
   kaggle, DATASET 2 HATE OFFEN
   kaggle, DATASET 1 HATE SPEEC
   Khan H, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P688, DOI 10.1109/ICCCIS51004.2021.9397140
   Kumar D, 2021, INT CONF BIG DATA, P346, DOI 10.1109/BigComp51126.2021.00075
   Matamoros-Fernández A, 2021, TELEV NEW MEDIA, V22, P205, DOI 10.1177/1527476420982230
   Miok K, 2022, COGN COMPUT, V14, P353, DOI 10.1007/s12559-021-09826-9
   Mishra S., 2021, SN Comput. Sci., V2, P1, DOI [10.1007/s42979-021-00455-5, DOI 10.1007/S42979-021-00455-5]
   Muhammad IZ., 2020, 2020 1 INT C BIG DAT, P1
   Oriola O, 2020, IEEE ACCESS, V8, P21496, DOI 10.1109/ACCESS.2020.2968173
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pitsilis GK, 2018, APPL INTELL, V48, P4730, DOI 10.1007/s10489-018-1242-y
   Pritam N, 2019, IEEE ACCESS, V7, P37414, DOI 10.1109/ACCESS.2019.2905133
   Priyadarshini I, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107204
   Priyadarshini I, 2022, MULTIMED TOOLS APPL, V81, P27009, DOI 10.1007/s11042-021-11004-w
   Priyadarshini I, 2021, J SUPERCOMPUT, V77, P13911, DOI 10.1007/s11227-021-03838-w
   Priyadarshini I, 2021, EARTH SCI INFORM, V14, P735, DOI 10.1007/s12145-021-00579-5
   Priyadarshini I, 2020, ADV INTELL SYST COMP, V1070, P306, DOI 10.1007/978-3-030-32523-7_21
   Priyadarshini I, 2021, J EXP THEOR ARTIF IN, V33, P683, DOI 10.1080/0952813X.2020.1784296
   Priyadarshini I, 2020, ADV INTELL SYST, V1069, P204, DOI 10.1007/978-3-030-32520-6_16
   Pronoza E, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102674
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Roy PK, 2022, COMPUT SPEECH LANG, V75, DOI 10.1016/j.csl.2022.101386
   Saeed F., 2021, Advances on Smart and Softt Computing. Advances in Intelligent Systems and Computing, V1188, P71, DOI [10.1007/978-981, DOI 10.1007/978-981]
   Setyadi NA, 2018, 2018 INTERNATIONAL CONFERENCE ON CONTROL, ELECTRONICS, RENEWABLE ENERGY AND COMMUNICATIONS (ICCEREC), P159, DOI 10.1109/ICCEREC.2018.8712109
   Vo T, 2020, J INTELL FUZZY SYST, V38, P4287, DOI 10.3233/JIFS-190870
   Tuan TA, 2020, EVOL INTELL, V13, P283, DOI 10.1007/s12065-019-00310-w
   Vashistha N, 2021, INFORMATION, V12, DOI 10.3390/info12010005
   Waseem D., 2016, P NAACL STUD RES WOR, P88, DOI [DOI 10.18653/V1/N16-2013, DOI 10.18653/V1/N16]
   Wullach T, 2020, IEEE INTERNET COMPUT
NR 40
TC 7
Z9 7
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27473
EP 27499
DI 10.1007/s11042-023-14481-3
EA FEB 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000937944300005
DA 2024-07-18
ER

PT J
AU Zhu, SQ
   Zhu, CX
   Li, XJ
AF Zhu, Shuqin
   Zhu, Congxu
   Li, Xiujuan
TI An efficient chosen-plaintext attack and improvement on an image
   encryption algorithm based on cyclicshift and multiple chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Safety analysis; Chosen plaintext attack; Index matrix; Cyclic shift
ID SCHEME; CRYPTANALYSIS
AB This paper proposes a more efficient attack method on an image encryption algorithm with permutation-cyclic shift-pixel diffusion structure. After in-depth analysis, it was found that the security of the original algorithm completely depends on the equivalent key streams: index matrix indexB, cyclic shift sequence D and diffusion sequences Z and M. But the generation of these equivalent keys has nothing to do with the plaintext image or the corresponding ciphertext image, so the equivalent keys can be decoded by the chosen-plaintext attack, in which only 2 + ceil(log(256)m) special plaintext images and their corresponding cipher images are required. (m represent the height of the target ciphertext image). When cracking the chaotic sequences Z and M, only one plaintext image with all pixel values of 0 is used. When cracking the cyclic shift sequence D, only one plaintext image with all pixel values of 15 is used. Finally, ceil(log(256)m) plaintext image is used to crack the index matrix for scrambling. Theoretical analysis and simulation experiments verify the feasibility of chosen-plaintext attack strategy. At the same time, the original algorithm is improved on the basis of being loyal to the original algorithm as much as possible.In the improved algorithm, the key stream is related to the ciphertext image itself, so it can resist the chosen-plaintext attack and the encryption effect of the improved algorithm is better than that of the original encryption algorithm in the aspects of information entropy, ciphertext correlation and ciphertext sensitivity.
C1 [Zhu, Shuqin; Li, Xiujuan] Liaocheng Univ, Sch Comp Sci & Technol, Liaocheng 252059, Peoples R China.
   [Zhu, Congxu] Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.
C3 Liaocheng University; Central South University
RP Zhu, CX (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.
EM shuqinzhu2008@163.com; zhucx@csu.edu.cn
OI Zhu, Congxu/0000-0002-9662-0532
FU National Natural Science Foundation of China [62071496]; Shan Dong
   Province Nature Science Foundation [ZR2022MF283]
FX AcknowledgmentsThis work is supported by National Natural Science
   Foundation of China (62071496) and the Shan Dong Province Nature Science
   Foundation (ZR2022MF283).
CR Alanazi AS, 2021, IEEE ACCESS, V9, P93795, DOI 10.1109/ACCESS.2021.3092512
   Andreescu T, 2009, NUMBER THEORY STRUCT, DOI [10.1007/b11856, DOI 10.1007/B11856]
   Bao WJ, 2022, MULTIMED TOOLS APPL, V81, P15977, DOI 10.1007/s11042-022-12623-7
   Chen L, 2017, NONLINEAR DYNAM, V87, P1797, DOI 10.1007/s11071-016-3153-y
   Javan AAK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113925
   Javan AAK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010254
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Li GD, 2022, MULTIMED TOOLS APPL, V81, P32005, DOI 10.1007/s11042-022-12853-9
   Lidong L, 2020, IEEE ACCESS, V8, P210382, DOI 10.1109/ACCESS.2020.3039891
   Lin CY, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22050589
   Lu Q, 2020, IEEE ACCESS, V8, P25664, DOI 10.1109/ACCESS.2020.2970806
   Özkaynak F, 2014, NONLINEAR DYNAM, V78, P1311, DOI 10.1007/s11071-014-1517-8
   Sadeghi D, 2021, ARXIV
   Sha YW, 2021, IEEE ACCESS, V9, P96321, DOI 10.1109/ACCESS.2021.3094563
   Shoeibi A, 2021, DETECTION EPILEPTIC
   Shoeibi A., 2020, ARXIV
   Shoeibi A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104697
   [田军锋 Tian Junfeng], 2020, [计算机科学, Computer Science], V47, P327
   Wang XY, 2015, OPT LASER ENG, V68, P126, DOI 10.1016/j.optlaseng.2014.12.025
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Yap WS, 2015, NONLINEAR DYNAM, V80, P1483, DOI 10.1007/s11071-015-1956-x
   Zhang YS, 2014, NONLINEAR DYNAM, V78, P235, DOI 10.1007/s11071-014-1435-9
   Zhong HY, 2022, MULTIMED TOOLS APPL, V81, P24757, DOI 10.1007/s11042-022-12479-x
   Zhu CX, 2015, NONLINEAR DYNAM, V79, P1511, DOI 10.1007/s11071-014-1757-7
   Zhu SQ, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23070804
   Zhu SQ, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23050505
   Zhu SQ, 2020, MULTIMED TOOLS APPL, V79, P31957, DOI 10.1007/s11042-020-09699-4
   Zhu SQ, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22070772
   Zhu SQ, 2019, IEEE ACCESS, V7, P147106, DOI 10.1109/ACCESS.2019.2946208
   Zhu SQ, 2018, IEEE ACCESS, V6, P67095, DOI 10.1109/ACCESS.2018.2874336
   Zhu SQ, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20090716
   Zhu SQ, 2018, MULTIMED TOOLS APPL, V77, P29119, DOI 10.1007/s11042-018-6078-2
NR 33
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22835
EP 22852
DI 10.1007/s11042-023-14630-8
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000937944300003
DA 2024-07-18
ER

PT J
AU Sharma, S
   Kumar, V
AF Sharma, Sahil
   Kumar, Vijay
TI Distracted driver detection using learning representations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EfficientNet; Activity detection; Deep learning; Facial landmarks;
   Ensemble
ID NETWORK
AB With the current market's growing need for electric vehicles and technologies in high-end vehicles, distracted driver detection requires the artificial intelligence's attention. In this paper, new strategies for improving the performance of the driver detection methodology are proposed. The proposed approach consists of two sub-systems namely driver activity detection and driver fatigue detection systems. The former one detects the activities of driver. The latter one is based on the facial feature recognition and determines the driver's fatigue level. The proposed model is evaluated on the activity detection and attained the classification accuracy of 99.69%, compared to the 94.32% accuracy in the state-of-the-art comparison. The KNN classifier had the best accuracy for detecting driver fatigue, with a 76.33% success rate. Experimental results reveal the superiority of proposed model over the existing models. The proposed model can be applied in the real-life environment.
C1 [Sharma, Sahil] Punjab Engn Coll, Dept Comp Sci & Engn, Chandigarh, India.
   [Kumar, Vijay] Dr BR Ambedkar Natl Inst Technol, Dept Informat Technol, Jalandhar, Punjab, India.
C3 Punjab Engineering College (Deemed University); National Institute of
   Technology (NIT System); Dr B R Ambedkar National Institute of
   Technology Jalandhar
RP Sharma, S (corresponding author), Punjab Engn Coll, Dept Comp Sci & Engn, Chandigarh, India.
EM sahil301290@gmail.com; vijaykumarchahar@gmail.com
RI Sharma, Sahil/JXM-8658-2024; Kumar, Vijay/A-2782-2015; Sharma, Dr.
   Sahil/AAI-2846-2021
OI Sharma, Dr. Sahil/0000-0002-6694-3365; Sharma, Sahil/0000-0002-3187-4929
CR Abouelnaga Y., 2018, ARXIV170609498, P1
   Abtahi S., 2014, P 5 ACM MULT SYST C, P24, DOI DOI 10.1145/2557642.2563678
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Cañas P, 2021, VISAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 5: VISAPP, P458, DOI 10.5220/0010244504580465
   Chen M, 2021, IEEE T IMAGE PROCESS, P160, DOI [10.1109/iccis53528.2021.9646003, DOI 10.1109/ICCIS53528.2021.9646003]
   Cheng G, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3081421
   dmd.vicomtech, DMD DRIVER MONITORIN
   Dong BT, 2021, IEEE INT CONF INDUST, P850, DOI 10.1109/ICIT46573.2021.9453676
   Nguyen DL, 2021, IEEE IND ELEC, DOI 10.1109/IECON48115.2021.9589212
   google, UTA RLDD
   Hu YC, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115697
   Jabbar R, 2018, PROCEDIA COMPUT SCI, V130, P400, DOI 10.1016/j.procs.2018.04.060
   kaggle, State Farm Distracted Driver Detection
   Koay HV, 2021, IEEE REGION 10 SYMP, DOI 10.1109/TENSYMP52854.2021.9550995
   Kumar A, 2021, LECT NOTES COMPUT SC, V12855, P44, DOI 10.1007/978-3-030-87897-9_5
   Lu MQ, 2022, SIGNAL PROCESS-IMAGE, V100, DOI 10.1016/j.image.2021.116513
   National Highway Traffic Safety Administration,, 2020, Overview of Motor Vehicle Crashes in 2019
   Nel F, 2021, 2021 SOUTHERN AFRICAN UNIVERSITIES POWER ENGINEERING CONFERENCE/ROBOTICS AND MECHATRONICS/PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA (SAUPEC/ROBMECH/PRASA), DOI 10.1109/SAUPEC/RobMech/PRASA52254.2021.9377022
   Nguyen DL, 2021, INT C CONTR AUTOMAT, P371, DOI 10.23919/ICCAS52745.2021.9649760
   Ngxande M, 2020, 2020 INTERNATIONAL SAUPEC/ROBMECH/PRASA CONFERENCE, P62, DOI 10.1109/saupec/robmech/prasa48453.2020.9041105
   NN-SVG, US
   Olson RS., 2016, SPRING SER CHALLENGE, V64, P66
   Ou CJ, 2020, IEEE T INTELL VEHICL, V5, P385, DOI 10.1109/TIV.2019.2960930
   Pal A, 2021, OPT MEMORY NEURAL, V30, P257, DOI 10.3103/S1060992X21030103
   Qi Shen, 2020, RICAI 2020: Proceedings of the 2020 2nd International Conference on Robotics, Intelligent Control and Artificial Intelligence, P271, DOI 10.1145/3438872.3439093
   Qian XL, 2021, IEEE SIGNAL PROC LET, V28, P180, DOI 10.1109/LSP.2021.3049997
   Qin BB, 2022, IEEE T INTELL TRANSP, V23, P6922, DOI 10.1109/TITS.2021.3063521
   research.google, KINETICS HUMAN ACTIO
   Rohila VS., 2021, HDB RES MACHINE LEAR, P89, DOI [10.4018/978-1-7998-3299-7.ch006, DOI 10.4018/978-1-7998-3299-7.CH006]
   Roytburd B, 2022, ACM T INTEL SYST TEC, DOI [10.2139/ssrn.3996984, DOI 10.2139/SSRN.3996984]
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Sajid F, 2021, IEEE ACCESS, V9, P169270, DOI 10.1109/ACCESS.2021.3138137
   Santurkar S, 2018, ADV NEUR IN, V31
   Sharma S, 2020, MULTIMED TOOLS APPL, V79, P26517, DOI 10.1007/s11042-020-09331-5
   Wang J, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13010001
   Wang JY, 2022, IEEE T INTELL TRANSP, V23, P10186, DOI 10.1109/TITS.2021.3126231
   Wang Y, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3408317
   Wu L, 2020, IEEE T CIRC SYST VID, V30, P2081, DOI 10.1109/TCSVT.2019.2909549
   Wu L, 2020, IEEE T IMAGE PROCESS, V29, P1233, DOI 10.1109/TIP.2019.2940684
   Wu MY, 2021, INT C PATT RECOG, P1228, DOI 10.1109/ICPR48806.2021.9413337
NR 42
TC 0
Z9 0
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22777
EP 22794
DI 10.1007/s11042-023-14635-3
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000929853100004
DA 2024-07-18
ER

PT J
AU Karthika, J
   Senthilselvi, A
AF Karthika, J.
   Senthilselvi, A.
TI An integration of deep learning model with Navo Minority Over-Sampling
   Technique to detect the frauds in credit cards
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Credit card fraud detection; Deep learning; Convolutional neural
   network; Class Imbalance; Gated recurrent unit; Sampling technique
ID IMBALANCED CLASSIFICATION
AB In the real-world, the quality and quantity of various desirable products, services and facilities are effectively chosen by the people within a single step due to the rapid development of e-commerce technologies. Also, this technology offers scammers to do make credit card frauds (CCF), as credit card is considered as one of the most payment methods for any purchase. To prevent this fraudulent activities and payment losses, financial institution and researchers tries to develop an automated system for CCF Detection as CCFD. In this research work, an integration of is designed for detecting the CCF. Class inequality is presents in real-time dataset that leads poor performance of proposed classifier that needs to be addressed before final prediction. To address this issues, this research work develops a Navo Minority Over-Sampling Technique (NMOTe) to solve the class imbalance problem and increased the efficiency of CNN-GRU model. By using this developed model, huge financial losses are avoided by detecting the CCF. The experiments are carried out on three publicly available datasets in terms of important parameters to test the performance of proposed CNN-GRU model with existing deep learning (DL) classifiers. The results proved that the proposed model achieved 97.45% of accuracy and 99.80% of precision, where the existing CNN model achieved 93.22% of accuracy and 78.7% of precision on UCSD-FICO datasets.
C1 [Karthika, J.; Senthilselvi, A.] SRM Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, India.
C3 SRM Institute of Science & Technology Chennai
RP Karthika, J (corresponding author), SRM Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, India.
EM karthijegadeesan14@gmail.com; senthila3@srmist.edu.in
RI J, Karthika/ABM-8409-2022; Senthilselvi, A/AAY-1907-2020; J,
   Karthika/ABJ-3549-2022
OI Senthilselvi, A/0000-0002-0280-9773; J, Karthika/0000-0001-6895-5901
CR [Anonymous], 2014, INT J COMPUT APPL
   [Anonymous], 2009, UCSD U CALIFORNIA SA
   Asha R., 2021, Glob. Transit. Proc., V2, P35
   Benchaji Ibtissam, 2019, Smart Data and Computational Intelligence. Proceedings of the International Conference on Advanced Information Technology, Services and Systems (AIT2S-18). Lecture Notes in Networks and Systems (LNNS 66), P220, DOI 10.1007/978-3-030-11914-0_24
   Bhattacharyya S, 2011, DECIS SUPPORT SYST, V50, P602, DOI 10.1016/j.dss.2010.08.008
   Boracchi G, 2017, IEEE T NEUR NET LEAR, P2162
   Carcillo F, 2021, INFORM SCIENCES, V557, P317, DOI 10.1016/j.ins.2019.05.042
   Carcillo F, 2018, INFORM FUSION, V41, P182, DOI 10.1016/j.inffus.2017.09.005
   Chakrabarty N., 2020, Journal of Electronics and Informatics, V2, P96, DOI DOI 10.36548/JEI.2020.2.004
   Chen K, 2021, ARXIV
   Dal Pozzolo A, 2014, EXPERT SYST APPL, V41, P4915, DOI 10.1016/j.eswa.2014.02.026
   Darwish SM, 2020, J AMB INTEL HUM COMP, V11, P4873, DOI 10.1007/s12652-020-01759-9
   Fiore U, 2019, INFORM SCIENCES, V479, P448, DOI 10.1016/j.ins.2017.12.030
   Itoo F., 2021, Int J Inform Technol., V13, P1503
   Lucas Y, 2020, FUTURE GENER COMP SY, V102, P393, DOI 10.1016/j.future.2019.08.029
   Makki S, 2019, IEEE ACCESS, V7, P93010, DOI 10.1109/ACCESS.2019.2927266
   Mittal S., 2020, Handbook of Computer Networks and Cyber Security: Principles and Paradigms, P653
   Mittal S, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2019), P320, DOI [10.1109/CONFLUENCE.2019.8776925, 10.1109/confluence.2019.8776925]
   Najadat H, 2020, INT CONF INFORM COMM, P204, DOI 10.1109/ICICS49469.2020.239524
   Ngwenduna KS, 2021, RISKS, V9, DOI 10.3390/risks9030049
   Patil Suraj, 2018, Procedia Computer Science, V132, P385, DOI 10.1016/j.procs.2018.05.199
   Randhawa K, 2018, IEEE ACCESS, V6, P14277, DOI 10.1109/ACCESS.2018.2806420
   Shukur H.A., 2019, Int J Comput Sci Mobile Comput, V8, P257
   Tang Nguyen T., 2020, arXiv
   Thabtah F, 2020, INFORM SCIENCES, V513, P429, DOI 10.1016/j.ins.2019.11.004
   Thennakoon A, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2019), P488, DOI [10.1109/confluence.2019.8776942, 10.1109/CONFLUENCE.2019.8776942]
   Trivedi N K., 2020, International Journal of Advanced Science and Technology, V29, P3414
   Varma D. Suneel, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0001, DOI 10.1109/ICCSP.2019.8697932
   Wang S, 2012, IEEE T SYST MAN CY B, V42, P1119, DOI 10.1109/TSMCB.2012.2187280
   Xuan SY, 2018, IEEE INT C NETW SENS
   Zhang XW, 2021, INFORM SCIENCES, V557, P302, DOI 10.1016/j.ins.2019.05.023
   Zhu HH, 2020, NEUROCOMPUTING, V407, P50, DOI 10.1016/j.neucom.2020.04.078
NR 32
TC 2
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21757
EP 21774
DI 10.1007/s11042-023-14365-6
EA JAN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000920621000004
DA 2024-07-18
ER

PT J
AU Lei, SC
   Tian, X
   Ng, WWY
   Gong, YJ
AF Lei, Si-chao
   Tian, Xing
   Ng, Wing W. Y.
   Gong, Yue-Jiao
TI Length adaptive hashing for semi-supervised semantic image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image retrieval; Semi-supervised image hashing; Multiobjective
   optimization
ID SPARSE; GRAPH
AB Image Hashing methods have proven to be both effective and efficient for large-scale image retrieval problem. The advances in hashing methods concentrate on the learning of image features and hash tables. Existing hashing methods manually select fixed hash code length for all classes of images in a large database. However, we have observed that the length of the hash code is essential to the retrieval performance but it is rarely studied. Short hash codes cannot preserve similarity among images well while long hash codes may lead to high storage costs. Linear search for the optimal length of hash code length is time-consuming. In this paper, a semi-supervised length adaptive hashing method (LAH) is proposed to adaptively optimize hash code lengths for different semantic image classes using a multiobjective evolutionary algorithm based on decomposition. Two objectives regarding retrieval precision and storage cost are set for optimization. We conduct experiments on three real-world image databases and the experimental results show that the proposed LAH significantly improves the retrieval performance compared to the original traditional semi-supervised hashing methods.
C1 [Lei, Si-chao; Tian, Xing; Ng, Wing W. Y.; Gong, Yue-Jiao] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
C3 South China University of Technology
RP Lei, SC (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
EM cssclei@outlook.com; xingtian@scut.edu.cn; wingng@scut.edu.cn;
   gongyuejiao@gmail.com
OI Lei, Sichao/0000-0001-8684-4092; Ng, Wing W. Y./0000-0003-0783-3585
FU Guangdong Natural Science Funds for Distinguished Young Scholars
   [2022B1515020049]; Guangdong Regional Joint Fund for Basic and Applied
   Research [2021B1515120078]
FX AcknowledgementsThis work is supported in part by the Guangdong Natural
   Science Funds for Distinguished Young Scholars under Grant
   2022B1515020049, in part by the Guangdong Regional Joint Fund for Basic
   and Applied Research under Grant 2021B1515120078.
CR Chen ZX, 2017, IEEE T MULTIMEDIA, V19, P123, DOI 10.1109/TMM.2016.2620604
   Chong YW, 2020, NEUROCOMPUTING, V408, P216, DOI 10.1016/j.neucom.2019.12.130
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gilbert A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1027, DOI 10.1109/ICCVW.2015.135
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P1344, DOI 10.1109/TIP.2017.2652730
   Heo JP, 2015, IEEE T PATTERN ANAL, V37, P2304, DOI 10.1109/TPAMI.2015.2408363
   Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024
   Jiang K, 2015, PROC CVPR IEEE, P4933, DOI 10.1109/CVPR.2015.7299127
   Jiang YG, 2013, IEEE T MULTIMEDIA, V15, P442, DOI 10.1109/TMM.2012.2231061
   Kang WC, 2016, AAAI CONF ARTIF INTE, P1230
   Karamti H., 2022, INT J ELECT COMPUT E, V12, P2526
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Latif A, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9658350
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li P, 2013, NEUROCOMPUTING, V120, P83, DOI 10.1016/j.neucom.2012.07.053
   Li P, 2013, IEEE T MULTIMEDIA, V15, P141, DOI 10.1109/TMM.2012.2199970
   Liang X., 2021, IEEE T MULTIMED
   Liang XP, 2023, IEEE T KNOWL DATA EN, V35, P3765, DOI 10.1109/TKDE.2021.3131188
   Liu L, 2016, IEEE T CYBERNETICS, V46, P2548, DOI 10.1109/TCYB.2015.2480966
   Liu XL, 2016, IEEE T IMAGE PROCESS, V25, P4514, DOI 10.1109/TIP.2016.2593344
   Liu XL, 2013, PROC CVPR IEEE, P1570, DOI 10.1109/CVPR.2013.206
   Lv YM, 2015, IEEE T MULTIMEDIA, V17, P1225, DOI 10.1109/TMM.2015.2437712
   Ng WWY, 2022, MULTIMED TOOLS APPL, V81, P927, DOI 10.1007/s11042-021-11494-8
   Ng WWY, 2018, NEUROCOMPUTING, V275, P916, DOI 10.1016/j.neucom.2017.09.042
   Ng WWY, 2017, INT J MACH LEARN CYB, V8, P571, DOI 10.1007/s13042-015-0350-9
   Ong EJ, 2016, PROC CVPR IEEE, P2000, DOI 10.1109/CVPR.2016.220
   Raginsky M., 2009, NIPS, V22
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Shen FM, 2015, IEEE T IMAGE PROCESS, V24, P1839, DOI 10.1109/TIP.2015.2405340
   Shen X, 2022, INFORM SCIENCES, V604, P45, DOI 10.1016/j.ins.2022.05.006
   Song JK, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P827, DOI 10.1145/2733373.2806341
   Song Z., 2022, IEEE T NEUR NET LEAR, V408, P216
   Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103
   Tang J, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2564638
   Tian X, 2020, NEUROCOMPUTING, V379, P103, DOI 10.1016/j.neucom.2019.10.073
   Wang D, 2016, IEEE T IMAGE PROCESS, V25, P4540, DOI 10.1109/TIP.2016.2592800
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang YT, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107785
   Wang Z, 2014, IEEE IMAGE PROC, P2217, DOI 10.1109/ICIP.2014.7025449
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Wu CX, 2013, IEEE T KNOWL DATA EN, V25, P1380, DOI 10.1109/TKDE.2012.76
   Wu F, 2014, IEEE T MULTIMEDIA, V16, P427, DOI 10.1109/TMM.2013.2291214
   Xu H, 2011, IEEE I CONF COMP VIS, P1631, DOI 10.1109/ICCV.2011.6126424
   Yan XY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3238
   Ye RZ, 2016, IEEE T CYBERNETICS, V46, P718, DOI 10.1109/TCYB.2015.2414299
   Zeng ZQ, 2015, INT C WAVEL ANAL PAT, P185, DOI 10.1109/ICWAPR.2015.7295948
   Zhang J, 2019, IEEE T CIRC SYST VID, V29, P212, DOI 10.1109/TCSVT.2017.2771332
   Zhang QF, 2007, IEEE T EVOLUT COMPUT, V11, P712, DOI 10.1109/TEVC.2007.892759
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 51
TC 0
Z9 0
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JAN 24
PY 2023
DI 10.1007/s11042-023-14377-2
EA JAN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9W6LW
UT WOS:000949190900004
DA 2024-07-18
ER

PT J
AU Gong, JH
   Rezaeipanah, A
AF Gong, Jianhu
   Rezaeipanah, Amin
TI A fuzzy delay-bandwidth guaranteed routing algorithm for video
   conferencing services over SDN networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Routing algorithm; SDN; Delay; Bandwidth; Video conferencing service;
   Fuzzy system
ID QOS
AB Video conferencing is one of the advanced technologies for users that allows online communication despite long distances. High quality communication and ongoing support for the principles of video conferencing service that can be achieved through Software-Defined Networking (SDN). SDN is a new architecture for computer networks that separates the control plane from the data plane to improve network resources and reduce operating costs. All routing decisions and control mechanisms are made by a device called a controller. Traffic engineering can be well implemented in SDN because the entire network topology is known to the controller. Considering SDN features, user requests can be dynamically routed according to current network status and Quality of Service (QoS) requirements. In general, the purpose of SDN routing algorithms is to maximize the acceptance rate of user requests by considering QoS requirements. In this literature, most routing studies to provide satisfactory video conferencing services have focused solely on bandwidth. Nevertheless, some studies have considered both delay and bandwidth constraints. In this paper, a Fuzzy Delay-Bandwidth Guaranteed Routing (FDBGR) algorithm is proposed that considers both delay and bandwidth constraints in routing. The proposed fuzzy system is based on rules that can postpone requests with high resource demands. Also, the purpose of the FDBGR is to distribute the network workload evenly for all requests, where this is done by maintaining the capacity to accept future requests. The combination of conventional routing algorithms and SDN provides remarkable improvements in mobility, scalability and the overall performance of the networks. Simulations are performed on different scenarios to evaluate the performance of the FDBGR compared to state-of-the-art methods. Besides, FDBGR has been compared with a number of most related previous works such as H-MCOP, MH-MCOP, QoMRA, QROUTE and REDO based on criteria such as number of accepted requests, average path length, energy consumption, load balancing, and average delay. The simulation results clearly prove the superiority of the proposed algorithm with an average delay of 48 ms in different topologies for video conferencing applications.
C1 [Gong, Jianhu] Guangdong Peizheng Coll, Sch Data & Comp Sci, Guangzhou 510830, Peoples R China.
   [Rezaeipanah, Amin] Univ Rahjuyan Danesh Borazjan, Dept Comp Engn, Bushehr, Iran.
RP Gong, JH (corresponding author), Guangdong Peizheng Coll, Sch Data & Comp Sci, Guangzhou 510830, Peoples R China.
EM gjhlunwen2021@163.com; amin.rezaeipanah@gmail.com
CR Al-Jawad A, 2021, 2021 IEEE CONFERENCE ON NETWORK FUNCTION VIRTUALIZATION AND SOFTWARE DEFINED NETWORKS (IEEE NFV-SDN), P54, DOI [10.1109/NFV-SDN53031.2021.9665140, 10.4018/978-1-7998-5021-2.ch003]
   Barakabitze AA, 2018, IEEE ICC
   Bensalah F, 2019, INT J ADV COMPUT SC, V10, P280
   Binsahaq A, 2019, IEEE ACCESS, V7, P73384, DOI 10.1109/ACCESS.2019.2919957
   Blanchy F, 2003, TELECOMMUN SYST, V24, P187, DOI 10.1023/A:1026166813657
   Casas-Velasco D.M., 2021, IEEE TRANS NETW SERV
   Cheng FB, 2022, NEUROCOMPUTING, V500, P856, DOI 10.1016/j.neucom.2022.05.082
   Das T, 2021, IEEE T NETW SERV MAN, V18, P2929, DOI 10.1109/TNSM.2021.3066847
   Etemadi M, 2020, COMPUT COMMUN, V161, P109, DOI 10.1016/j.comcom.2020.07.028
   Feng G, 2002, IEICE T COMMUN, VE85B, P2838
   Heydarian M, 2012, J SUPERCOMPUT, V62, P315, DOI 10.1007/s11227-011-0723-0
   Huijuan Wang, 2011, 2011 Second International Conference on Mechanic Automation and Control Engineering, P1067
   Irawan A, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3565
   Kodialam M., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P884, DOI 10.1109/INFCOM.2000.832263
   Korkmaz T, 2004, GLOB TELECOMM CONF, P1515
   Korkmaz T, 2001, IEEE INFOCOM SER, P834, DOI 10.1109/INFCOM.2001.916274
   Kucminski A, 2017, IEEE INT SYM BROADB, P174
   Lammich P, 2016, LECT NOTES COMPUT SC, V9807, P219, DOI 10.1007/978-3-319-43144-4_14
   Li P, 2021, IEEE T SUSTAIN ENERG, V12, P58, DOI 10.1109/TSTE.2020.2978634
   Liu C, 2022, NEURAL PROCESS LETT, V54, P1823, DOI 10.1007/s11063-021-10708-2
   Mahmoudi M, 2022, CLUSTER COMPUT, V25, P1237, DOI 10.1007/s10586-021-03522-x
   Majdoub M, 2019, INT C INTELLIGENT SY, P497
   Mesbahi N, 2015, 2015 INT C PROTOCOL, P1
   Ogul M., 2014, BALKAN J ELECT COMP, V2, P46
   Pfaff Ben., 2012, Open Networking Foundation, P39
   Qayyum A., 2020, 2020 INT C IND ENG A, P1, DOI [10.1109/ICIEAM48468.2020.911195, DOI 10.1109/ICIEAM48468.2020.911195]
   Rezaeipanah A, 2021, WIRELESS PERS COMMUN, V120, P3293, DOI 10.1007/s11277-021-08614-w
   Rischke J, 2020, IEEE ACCESS, V8, P174773, DOI 10.1109/ACCESS.2020.3025432
   Shahidinejad A, 2020, CLUSTER COMPUT, V23, P1045, DOI 10.1007/s10586-019-02972-8
   Si ZY, 2021, APPL ENERG, V302, DOI 10.1016/j.apenergy.2021.117514
   Soorki MN, 2014, J NETW COMPUT APPL, V42, P21, DOI 10.1016/j.jnca.2014.03.008
   Stiliadis D, 1998, IEEE ACM T NETWORK, V6, P611, DOI 10.1109/90.731196
   Tejaswini V., 2021, Artificial Intelligence Techniques for Advanced Computing Applications. Proceedings of ICACT 2020. Lecture Notes in Networks and Systems (LNNS 130), P323, DOI 10.1007/978-981-15-5329-5_31
   Varyani N, 2020, IEEE ACCESS, V8, P104109, DOI 10.1109/ACCESS.2020.2995558
   Yang RQ, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6829
   Zhao YL, 2019, IEEE ACCESS, V7, P95397, DOI 10.1109/ACCESS.2019.2928564
   Zhou LF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020375
NR 37
TC 26
Z9 26
U1 7
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25585
EP 25614
DI 10.1007/s11042-023-14349-6
EA JAN 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000919698400003
PM 36712954
OA Green Published, Bronze
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Liu, HZ
   Yan, H
AF Liu, Hongzhe
   Yan, Hua
TI An end-to-end multi-scale network based on autoencoder for infrared and
   visible image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autoencoder; Image fusion; Infrared image; Visible image
ID QUALITY ASSESSMENT; ARCHITECTURE; NEST
AB Infrared and visible image fusion aims to obtain a more informative fusion image by merging the infrared and visible images. However, the existing methods have some shortcomings, such as detail information loss, unclear boundaries, and not being end-to-end. In this paper, we propose an end-to-end network architecture for infrared and visible image fusion task. Our network contains three essential parts: encoders, residual fusion module, and decoder. First, we input infrared and visible images to two encoders to extract shallow features, respectively. Subsequently, the two sets of features are concatenated and fed to the residual fusion module to extract multi-scale features and fuse them adequately. Finally, the fused image is obtained by the decoder. We conduct objective and subjective experiments on two public datasets. The comparison results with the state-of-art methods prove that the fusion results of the proposed method have better objective metrics and contain more detail information and more explicit boundary.
C1 [Liu, Hongzhe; Yan, Hua] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610065, Sichuan, Peoples R China.
C3 Sichuan University
RP Yan, H (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610065, Sichuan, Peoples R China.
EM yanhua@scu.edu.cn
OI Yan, Hua/0000-0001-9231-3175
CR Aslantas V, 2015, AEU-INT J ELECTRON C, V69, P160, DOI 10.1016/j.aeue.2015.09.004
   Bavirisetti DP, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P701
   Bavirisetti DP, 2016, INFRARED PHYS TECHN, V76, P52, DOI 10.1016/j.infrared.2016.01.009
   Darbari A, 2021, CARDIOTHORAC SURG, V29, DOI 10.1186/s43057-021-00053-4
   Fu Y, 2021, INT C PATT RECOG, P10675, DOI 10.1109/ICPR48806.2021.9412293
   Haghighat M, 2014, I C APPL INF COMM TE, P424
   Hanna BV, 2008, J AM COLL SURGEONS, V206, P1227, DOI 10.1016/j.jamcollsurg.2007.10.012
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Hwang S, 2015, PROC CVPR IEEE, P1037, DOI 10.1109/CVPR.2015.7298706
   Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019
   Kristan M., 2020, COMPUTER VISION ECCV, P547
   Li H, 2021, INFORM FUSION, V73, P72, DOI 10.1016/j.inffus.2021.02.023
   Li H, 2020, IEEE T INSTRUM MEAS, V69, P9645, DOI 10.1109/TIM.2020.3005230
   Li H, 2019, INFRARED PHYS TECHN, V102, DOI 10.1016/j.infrared.2019.103039
   Li H, 2018, INT C PATT RECOG, P2705, DOI 10.1109/ICPR.2018.8546006
   Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342
   Li JY, 2023, CURR PSYCHOL, V42, P12814, DOI 10.1007/s12144-021-02671-x
   Li QL, 2021, IEEE SENS J, V21, P7458, DOI 10.1109/JSEN.2019.2921803
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Liu Y, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500182
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Ma JY, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3038013
   Ma JY, 2020, IEEE T IMAGE PROCESS, V29, P4980, DOI 10.1109/TIP.2020.2977573
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Negi A., 2022, Cyber-Physical Systems, P1
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Negi A., 2021, Data Science and Its Applications, P63
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Simone G., 2002, Information Fusion, V3, P3, DOI 10.1016/S1566-2535(01)00056-2
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh R, 2008, PATTERN RECOGN, V41, P880, DOI 10.1016/j.patcog.2007.06.022
   Sun CQ, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9122162
   Sun K, 2021, INTEGR FERROELECTR, V217, P198, DOI 10.1080/10584587.2021.1911313
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Zhang XC, 2020, INFORM FUSION, V63, P166, DOI 10.1016/j.inffus.2020.05.002
NR 45
TC 2
Z9 2
U1 10
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20139
EP 20156
DI 10.1007/s11042-022-14314-9
EA DEC 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000904017400001
DA 2024-07-18
ER

PT J
AU Akyol, K
AF Akyol, Kemal
TI Handling hypercolumn deep features in machine learning for rice leaf
   disease classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rice leaf disease; Important keypoint detection; Hypercolumn deep
   features; Deep learning; Machine learning
ID ORB
AB Rice leaf disease, which is a plant disease, causes a decrease in rice production and more importantly, environmental pollution. 10-15% of the losses in rice production are due to rice plant diseases. Automatic recognition of rice leaf disease by computer-assisted expert systems is a promising solution to overcome this problem and to bear the shortage of field experts in this field. Many studies have been conducted using features extracted from deep learning architectures, so far. This study includes keypoint detection on the image, hypercolumn deep feature extraction from CNN layers, and classification stages. The hypercolumn is a vector that contains the activations of all CNN layers for a pixel. Keypoints are prominent points in the images that define what stands out in the image. The first step of the model proposed in this study includes the detection of keypoints on the image and then the extraction of hypercolumn features based on the interest points. In the second step, machine learning experiments are carried out by running classifier algorithms on the features extracted. The evaluation results show that the proposed approach in this paper can detect rice leaf diseases. Furthermore, the Random Forest classifier presented a very successful performance on hypercolumn deep features with 93.06% accuracy, 89.58% sensitivity, 94.79% specificity, and 89.58% precision. As a result, the proposed approach can be integrated into computer-aided rice leaf disease diagnosis systems and so support field experts.
C1 [Akyol, Kemal] Kastamonu Univ, Dept Comp Engn, Kastamonu, Turkey.
C3 Kastamonu University
RP Akyol, K (corresponding author), Kastamonu Univ, Dept Comp Engn, Kastamonu, Turkey.
EM kakyol@kastamonu.edu.tr
RI Akyol, Kemal/AES-1397-2022
OI Akyol, Kemal/0000-0002-2272-5243
CR Al-Hiary H, 2011, FAST ACCURATE DETECT
   Alshdaifat NFF, 2020, ECOL INFORM, V59, DOI 10.1016/j.ecoinf.2020.101121
   Anagnostis A, 2021, COMPUT ELECTRON AGR, V182, DOI 10.1016/j.compag.2021.105998
   Arivazhagan S, 2013, DETECTION UNHEALTHY
   Barbedo JGA, 2013, SPRINGERPLUS, V2, DOI 10.1186/2193-1801-2-660
   Bari BS, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.432
   Bhattacharya Shreyasi, 2020, Intelligence Enabled Research. DoSIER 2019. Advances in Intelligent Systems and Computing (AISC 1109), P61, DOI 10.1007/978-981-15-2021-1_8
   Capinha C, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2021.101252
   Chen JD, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114514
   Ghosal S, 2020, 2020 IEEE CALCUTTA CONFERENCE (CALCON), P230, DOI [10.1109/CALCON49167.2020.9106423, 10.1109/calcon49167.2020.9106423]
   Gutiérrez S, 2021, COMPUT ELECTRON AGR, V182, DOI 10.1016/j.compag.2021.105991
   Jalal A, 2020, ECOL INFORM, V57, DOI 10.1016/j.ecoinf.2020.101088
   Jiang F, 2020, COMPUT ELECTRON AGR, V179, DOI [10.1016/j.compeg.2020.105824, 10.1016/j.compag.2020.105824]
   Joshi RC, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101197
   Kahl S, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2021.101236
   Khirade SD, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P768, DOI 10.1109/ICCUBEA.2015.153
   Lee SH, 2020, COMPUT ELECTRON AGR, V170, DOI 10.1016/j.compag.2020.105220
   Liu XQ, 2020, NEUROCOMPUTING, V392, P253, DOI 10.1016/j.neucom.2018.10.100
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Lumini A, 2019, ECOL INFORM, V51, P33, DOI 10.1016/j.ecoinf.2019.02.007
   Majeed Y, 2020, COMPUT ELECTRON AGR, V170, DOI 10.1016/j.compag.2020.105277
   Patidar S., 2020, MACHINE LEARNING IMA, V1240, P278, DOI 10.1007/978- 981-15- 6315-7_23
   Peng SB, 2009, PLANT PROD SCI, V12, P3, DOI 10.1626/pps.12.3
   Phadikar S., 2012, International Journal of Information and Electronics Engineering, V2, DOI DOI 10.7763/IJIEE.2012.V2.137
   Prajapati HB, 2017, INTELL DECIS TECHNOL, V11, P357, DOI 10.3233/IDT-170301
   Ramcharan A, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01852
   Rosin PL, 1999, COMPUT VIS IMAGE UND, V73, P291, DOI 10.1006/cviu.1998.0719
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sethy PK, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105527
   Sharif H, 2017, PATTERN RECOGN LETT, V93, P154, DOI 10.1016/j.patrec.2016.11.007
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang H, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105739
   Tetila EC, 2020, COMPUT ELECTRON AGR, V179, DOI [10.1016/j.compeg.2020.105836, 10.1016/j.compag.2020.105836]
   Tian L, 2021, REMOTE SENS ENVIRON, V257, DOI 10.1016/j.rse.2021.112350
   Togaçar M, 2021, NEURAL COMPUT APPL, V33, P9877, DOI 10.1007/s00521-021-05758-5
   Togaçar M, 2020, PHYSICA A, V545, DOI 10.1016/j.physa.2019.123592
   Villon S, 2018, ECOL INFORM, V48, P238, DOI 10.1016/j.ecoinf.2018.09.007
   Wagle SA, 2021, TRAIT SIGNAL, V38, P699, DOI 10.18280/ts.380317
   Xie XY, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.00751
   Xiong YH, 2020, COMPUT ELECTRON AGR, V177, DOI 10.1016/j.compag.2020.105712
   Yan Q, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123535
NR 41
TC 5
Z9 5
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19503
EP 19520
DI 10.1007/s11042-022-14318-5
EA DEC 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000900034500001
DA 2024-07-18
ER

PT J
AU Jiang, B
   Huang, W
   Yang, C
   Huang, Y
AF Jiang, Bin
   Huang, Wei
   Yang, Chao
   Huang, Yun
TI Image inpainting based on cross-hierarchy global and local aware network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image inpainting; Cross-hierarchy module; Global-local attention
AB Recent image inpainting approaches based on deep convolutional neural networks have achieved promising results. However, existing methods fail to consider the global and local consistency of the pixels to be recovered. We designed a cross-hierarchy global and local aware network (CGLANet) to solve these problems. This model refines the high-level feature maps from deeper layers with global pixel attention (GPA), then fuses hierarchical feature maps with proposed local-consistent attention (LCA). The GPA is an image-level block that aims to improve the structural consistency between the restored images and those around the uncorrupted images. The LCA is a patch-level block that guarantees the consistency of local textural details by modeling the semantic relevance between the pixels within the local patches of images. Experiments on benchmark datasets demonstrated the superiority of our method over state-of-the-art image inpainting models.
C1 [Jiang, Bin; Huang, Wei; Yang, Chao; Huang, Yun] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Jiang, Bin] Key Lab Embedded & Network Comp Hunan Prov, Changsha 410082, Hunan, Peoples R China.
C3 Hunan University
RP Jiang, B (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.; Jiang, B (corresponding author), Key Lab Embedded & Network Comp Hunan Prov, Changsha 410082, Hunan, Peoples R China.
EM jiangbin@hnu.edu.cn; hwei@hnu.edu.cn; yangchaoedu@hnu.edu.cn;
   hy1112@hnu.edu.cn
OI Jiang, Bin/0000-0002-5840-9664
FU National Natural Science Foundation of China [62072169, 62172156];
   Natural Science Foundation of Hunan Province [2021JJ30138]
FX This work was supported in part by the National Natural Science
   Foundation of China under grant 62072169 and 62172156, and Natural
   Science Foundation of Hunan Province under grant 2021JJ30138.
CR Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Cao CJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14489, DOI 10.1109/ICCV48922.2021.01424
   Deng X, 2019, IEEE I CONF COMP VIS, P3076, DOI 10.1109/ICCV.2019.00317
   Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2465, DOI 10.1109/ICASSP39728.2021.9414065
   Jingyuan Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7757, DOI 10.1109/CVPR42600.2020.00778
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Komodakis N, 2007, IEEE T IMAGE PROCESS, V16, P2649, DOI 10.1109/TIP.2007.906269
   Li JY, 2019, IEEE I CONF COMP VIS, P5961, DOI 10.1109/ICCV.2019.00606
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu HY, 2019, IEEE I CONF COMP VIS, P4169, DOI 10.1109/ICCV.2019.00427
   Liu Hongyu, 2020, P EUR C COMP VIS, P725, DOI DOI 10.1007/978-3-030-58536-5_43
   Miyato T., 2018, ARXIV
   Nazeri K., 2019, ARXIV
   Park E, 2017, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2017.82
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Peng JL, 2021, PROC CVPR IEEE, P10770, DOI 10.1109/CVPR46437.2021.01063
   Ren YR, 2019, IEEE I CONF COMP VIS, P181, DOI 10.1109/ICCV.2019.00027
   Song Y., 2018, ARXIV
   Song YH, 2018, LECT NOTES COMPUT SC, V11206, P3, DOI [10.1007/978-3-030-01216-8_1, 10.1109/APCAP.2017.8420330]
   Wang CX, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3104907
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Xie CH, 2019, IEEE I CONF COMP VIS, P8857, DOI 10.1109/ICCV.2019.00895
   Yan ZY, 2018, LECT NOTES COMPUT SC, V11218, P3, DOI 10.1007/978-3-030-01264-9_1
   Yang J, 2020, AAAI CONF ARTIF INTE, V34, P12605
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zeng YH, 2019, PROC CVPR IEEE, P1486, DOI 10.1109/CVPR.2019.00158
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhou X, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2470, DOI 10.1109/ICASSP39728.2021.9413380
NR 35
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18747
EP 18760
DI 10.1007/s11042-022-14245-5
EA NOV 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000889417700002
DA 2024-07-18
ER

PT J
AU Jha, A
   Patil, HY
AF Jha, Abhinav
   Patil, Hemprasad Yashwant
TI A review of machine transliteration, translation, evaluation metrics and
   datasets in Indian Languages
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Machine translation; Machine transliteration; Datasets; Indian
   Languages; Natural language processing; Evaluation metrics
ID ENGLISH; WIKIPEDIA; SYSTEM; MTIL
AB In today's global scenario, frequent international and domestic interactions necessitate the application of Machine Transliteration and Translation systems to overcome the language barrier. This paper presents a review of Natural Language Processing (NLP) techniques like Machine Translation (MT) and Machine Transliteration (MTn), along with providing an analytical study of evaluation metrics such as BLEU (BiLingual Evaluation Understudy) score and discussing datasets available for MT and MTn systems in Indian languages. This paper is unique in providing a detailed review of all steps involved in the NLP system development pipeline, from the creation and collection of data to the development of the system, and furthermore, the evaluation and analysis of the system. It also comments on the validity and viability of various evaluation metrics for Indian languages. MT and MTn systems are an evolving field of computational linguistics and are considered to be incredibly challenging to develop. The lack of readily available grammatical rules, the distinction between proper and common nouns, and large datasets, along with additional linguistic complexity compared to many other languages, makes developing such systems for Indian languages even more complicated. It explores different approaches like statistics oriented, example oriented, and neural network-oriented MT techniques implied in MT tasks, along with providing insight into the work carried out so far for Indian languages. The review also discusses the scope for future research in this field. This article determines the current status of available datasets, MT and MTn systems, along with commenting on the validity of currently available evaluation metrics like BLEU for Indian languages. The article also provides a direction in which further research for Indian languages should ideally be headed.
C1 [Jha, Abhinav; Patil, Hemprasad Yashwant] Vellore Inst Technol, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Patil, HY (corresponding author), Vellore Inst Technol, Vellore, Tamil Nadu, India.
EM abhinavlatrobe@gmail.com; hemprasadpatil@gmail.com
RI Jha, Abhinav/HJI-7828-2023
OI Jha, Abhinav/0000-0002-0085-583X; Yashwant Patil,
   Hemprasad/0000-0002-8572-0765
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   Achanta SDM, 2021, INT J SPEECH TECHNOL, DOI 10.1007/s10772-021-09893-1
   Agarwal A., 2008, P 3 WORKSHOP STAT MA, P115
   Ambati V, 2007, P 5 INT C NAT LANG P, P4
   Andrabi SAB, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/7873012
   Annamalai E., 1979, Language Movements in India
   [Anonymous], TEAM AC FLASH FUTURE
   [Anonymous], 2013, EMNLP
   [Anonymous], IITK FIRE FORUM INFO
   [Anonymous], INC GOOGLE TRANSLATE
   [Anonymous], 2011, International Journal of Computer Applications
   [Anonymous], INFORM RETRIEVAL EVA
   [Anonymous], FDN WIKIPEDIA STAT T
   [Anonymous], ScienceDirect Search Results: "Data Centre"
   [Anonymous], ATTARDI G GITHUB ATT
   [Anonymous], GOOGLE SCHOLARADVANC
   [Anonymous], 2019, INDIA WHO SPEAKS ENG
   [Anonymous], LDC IL LDC IL TEXT C
   [Anonymous], BOMBAY IIT IIT BOMBA
   [Anonymous], LLC SM MACHINE TRANS
   [Anonymous], 2012, P 7 WORKSHOP STAT MA
   [Anonymous], APPS B2017 T ENGLISH
   [Anonymous], IEEE Xplore Search Results for TDDB in CMOS
   [Anonymous], 2006, AAAI
   [Anonymous], SEARCH RESULTS SPRIN
   [Anonymous], SAMUH SBM HOME SAKHI
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bandyopadhyay S, 2000, P 7 STAT SCI TECHN C, P1
   Bennett W. S., 1985, Computational Linguistics, V11, P111
   Bhatt R., 2009, Proceedings of the Third Linguistic Annotation Workshop (LAW III), P186, DOI DOI 10.3115/1698381.1698417
   Blatz John, 2004, COLING 2004, P315
   Bollacker Kurt D., 2007, Freebase: a shared database of structured general human knowledge. Proceedings of the 22nd National Conference on Artificial Intelligence-Volume 2, AAAI'07
   Cardona, 2017, INDO ARYAN LANGUAGES
   Chakravarthi BR, 2021, P 1 WORKSHOP SPEECH, P119
   Chopra D, 2018, ENG TECHNOL APPL SCI, V8, P3475
   Choudhary N, 2021, LANG RESOUR EVAL, V55, P855, DOI 10.1007/s10579-020-09523-3
   Chung Junyoung, 2014, ARXIV14123555
   Corporation, BING MICROSOFT TRANS
   Dan Stefanescu., 2013, P 14 INT C INT TEXT, P24
   Dave S., 2001, Machine Translation, V16, P251, DOI 10.1023/A:1021902704523
   Deng YG, 2008, IEEE T AUDIO SPEECH, V16, P494, DOI 10.1109/TASL.2008.916056
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Devi Sobha Lalitha, 2010, 2010 International Conference on Asian Language Processing (IALP 2010), P261, DOI 10.1109/IALP.2010.40
   Dey S.S., 2021, ARXIV
   Dhore ML., 2012, INT J COMPUTER APPL, V48, P31
   Diwakar, MAITHILI MAGAHI BIHA
   Dodge J, 2021, ARXIV
   dumps.wikimedia.org, FDN WIKIMEDIA DOWNLO
   Edunov S., 2018, ARXIV
   elra, ASS ELR ELRA ELDA PO
   Filippova K, 2013, GOOGLE RES
   Foundation, WIKIMEDIA STAT ENGLI
   Foundation WM, WIK SIZ COMP
   Garje G., 2013, INT J NAT LANGUAGE C, V2, P47, DOI [10.5121/ijnlc.2013.2504, DOI 10.5121/IJNLC.2013.2504]
   Gilbert AZ, CIIL SEO SPOKEN CORP
   GmbH DL, DEEPL TRANSLATE
   Goyal Vishal, 2008, 2008 1st International Conference on Emerging Trends in Engineering and Technology (ICETET), P1156, DOI 10.1109/ICETET.2008.11
   Goyal V, 2009, ARXIV
   Goyal V, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P191
   Gu J., 2018, ARXIV
   Gurevych I, 2007, P 45 ANN M ASS COMP, P1032
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Indian Languages CI of, 2021, CENTR I IND LANG LEG
   Indian Languages (CIIL), M CENTR I BHAR KNOWL
   indicnlp.ai4bharat.org, US AI4BHARAT INDICNL
   International SIL, 2021, INDIA
   internetworldstats, GROUP M INTERNET WOR
   Jehl L, 2015, P IWSLT
   Jha AK, 2019, 2019 INT C ELECT INF, P1
   Jha S, 2018, PREPRINTS
   Johnson M., 2017, T ASSOC COMPUT LING, V5, P339, DOI [10.1162/tacla00065, 10.1162/tacl_a_00065, DOI 10.1162/TACL_A_00065]
   Joshi N, 2012, ADV COMPUTER SCI ENG, P423
   Joshi N, 2013, ARXIV
   Junczys-Dowmunt M, 2018, ARXIV
   Karakanta A, 2019, P 2 WORKSHOP TECHNOL
   Kaur K., 2014, INT J COMPUTER APPL, V107
   Klein G., 2017, ARXIV
   Koehn P., 2007, CLSP SUMMER WORKSHOP
   Kumar MA, 2019, J INTELL SYST, V28, P455, DOI 10.1515/jisys-2018-0024
   Kunchukuttan A, 2017, ARXIV
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lample G, 2020, ARXIV
   Lavie A., 2010, AMTA Tutorial, P86
   ldc, PENNSYLVANIA UO HOME
   LDCIL, 2007, LDC
   Liu X., 2020, ARXIV
   LLC G, EVALUATING MODELS AU
   Luong M.-T., 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1166
   Madaan P, 2020, PROC WILDRE5 5 WORK, P29
   Mahata SK, 2022, NEURAL PROCESS LETT, V54, P3115, DOI 10.1007/s11063-022-10755-3
   Maity S, 2012, 2012 NAT C COMM NCC, P1, DOI DOI 10.1109/NCC.2012.6176831
   Matthews D, 2007, THESIS U EDINBURGH E
   Milne D, 2013, ARTIF INTELL, V194, P222, DOI 10.1016/j.artint.2012.06.007
   Mishra Kshitij, 2014, P WORKSH AUT TEXT SI, P21
   Mujadia Vandan, 2021, P 4 WORKSH TECHN MT, P151
   Mundotiya RK, 2020, ARXIV
   Murthy ASD, 2020, MATER TODAY-PROC, V33, P4323, DOI 10.1016/j.matpr.2020.07.447
   Murthy ASD, 2022, SOFT COMPUT, V26, P12933, DOI 10.1007/s00500-021-06125-1
   Nair LR., 2012, INT J COMP APPL, V39, P0975
   Naskar SK, 2006, P 3 ACL SIGSEM WORKS
   Nidhi R, 2018, INT CONF RELI INFO, P775, DOI 10.1109/ICRITO.2018.8748786
   Och FJ, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P440
   Oh JH, 2006, J ARTIF INTELL RES, V27, P119, DOI 10.1613/jair.1999
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pathak A, 2019, J INTELL SYST, V28, P465, DOI 10.1515/jisys-2018-0065
   Pingali P, 2008, P 2 WORKSHOP CROSS L
   Premjith B, 2019, J INTELL SYST, V28, P387, DOI 10.1515/jisys-2019-2510
   Rajpurkar P, 2018, ARXIV
   Ramanathan A, 2008, P 3 INT JOINT C NATU, VI
   Ramesh G, 2022, T ASSOC COMPUT LING, V10, P145, DOI 10.1162/tacl_a_00452
   Ramesh SH, 2018, ARXIV
   Rana M, 2016, PROCEDIA COMPUT SCI, V79, P199, DOI 10.1016/j.procs.2016.03.026
   Rathod P.H., 2013, International Journal on Natural Language Computing, V2, P55
   Reddy VR, 2013, INT J SPEECH TECHNOL, V16, P489, DOI 10.1007/s10772-013-9198-0
   Registrar General O of, 2021, LANG IND CENS IND 20
   Ruder Sebastian, 2021, Challenges and Opportunities in NLP Benchmarking
   Ruiz-Casado M, 2005, LECT NOTES COMPUT SC, V3528, P380
   Saha GK., 2005, J ZHEJIANG UNIV-SC A, V6, P1047, DOI [10.1631/jzus.2005.A1047, DOI 10.1631/JZUS.2005.A1047]
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Senti Subhadrika., THERES GROWING DEMAN
   Sharma A, 2017, INT J ADV RES COMPUT, V8
   Singh M, 2021, ARCH COMPUT METHOD E, V28, P2165, DOI 10.1007/s11831-020-09449-7
   Singh M, 2021, NEURAL COMPUT APPL, V33, P1103, DOI 10.1007/s00521-020-04990-9
   Singh TD, 2020, 2020 INTERNATIONAL CONFERENCE ON COMPUTATIONAL PERFORMANCE EVALUATION (COMPE-2020), P733, DOI 10.1109/ComPE49325.2020.9200059
   Singh UN, 2012, ENCY APPL LINGUISTIC
   Sinha RMK, 2004, P INT S MACHINE TRAN, P10
   Sitender, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03479-0
   Snover Matthew., 2006, P 7 C ASS MACHINE TR, P223
   Suchanek FM, 2008, J WEB SEMANT, V6, P203, DOI 10.1016/j.websem.2008.06.001
   Sutton C., 2006, INTRO STAT RELATIONA, V2, P93
   Takase S, 2021, ARXIV
   University, METEOR AUTOMATIC MT
   van Rijsbergen CJ, 1979, INFORM RETRIEVAL, P178
   Vogel S., 1996, COLING
   Voss, 2006, ARXIV
   Vuddagiri RK, 2018, 6 WORKSHOP SPOKEN LA, P56
   Wallach HM., 2004, TECHNICAL REPORTS CI, V24, P22
   Wang A., 2019, arXiv
   Wani SH., 2021, Indian J Multiling Res Dev, V2, P1, DOI [10.34256/ijmrd2111, DOI 10.34256/IJMRD2111]
   web.archive, 2021, INDIAN LANGUAGES 101
   Xia Fei, 2009, 7 INT C NAT LANG PRO, P14
   Xie, 2021, P 1 WORKSHOP SPEECH
   Xuegong Z, 2000, INT STAT LEARN THEOR
   YiningWang Long Zhou, 2017, Machine Translation, P30
   Zesch T., 2007, Proceedings of the TextGraphs-2 Workshop NAACL-HLT 2007, P1
   Zesch T, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P1646
   Zhao LW, 2000, LECT NOTES ARTIF INT, V1934, P54
NR 147
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23509
EP 23540
DI 10.1007/s11042-022-14273-1
EA NOV 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000888710500006
DA 2024-07-18
ER

PT J
AU Zhou, YT
   Dy, JB
   Hsu, SC
   Hsu, YL
   Yang, CL
   Hua, KL
AF Zhou, Yun-Ting
   Dy, Jilyan Bianca
   Hsu, Shang-Che
   Hsu, Yu-Ling
   Yang, Chao-Lung
   Hua, Kai-Lung
TI SSRFace: a face recognition framework against shallow data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial recognition; Shallow data; Deep learning; Computer vision
AB Most existing deep-learning-based approaches rely on high-resolution large-scale datasets to improve their performance. However, obtaining such datasets is challenging for tasks such as face recognition. The best way to address this is first to address the issue deep-learning-based approaches experience when trained on limited samples or shallow datasets (i.e., lack of diversity). We propose SSRFace, a framework for face recognition on shallow datasets. In detail, SSRFace leverages two novel components: Segregate-Representation (SR) and SimInstance. SR utilizes unlabeled data and angular-margin-based loss to increase inter-class distance, improving class discrimination. SimInstance, on the other hand, has a straightforward approach to improving intra-class diversity. Our proposed SimInstance starts by learning the unique class distribution from the few samples before randomly sampling a feature representation to serve as new intra-class samples. We train our model on TinyFace, a shallow dataset, to show its capabilities. We show SSRFace performed better than other existing approaches with Rank-1 accuracy and mean average precision (mAP) when trained on shallow datasets.
C1 [Zhou, Yun-Ting; Dy, Jilyan Bianca; Hsu, Shang-Che; Hsu, Yu-Ling; Yang, Chao-Lung; Hua, Kai-Lung] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Keelung Rd, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Hua, KL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Keelung Rd, Taipei 106, Taiwan.
EM ki11erbear5566@gmail.com; jilyandy@gmail.com;
   yulinghsu@mail.ntustedu.tw; clyang@mail.ntust.edu.tw
OI Hua, Kai-Lung/0000-0002-7735-243X
FU Ministry of Education, Taiwan; Ministry of Science and Technology,
   Taiwan [MOST109-2221-E-011-125-MY3, MOST110-2923-E-011-004]; Wang
   Jhan-Yang Charitable Trust Fund [WJY 2020-HR-01]
FX Ministry of Education, Taiwan and Ministry of Science and Technology,
   Taiwan (Grant number: MOST109-2221-E-011-125-MY3 and
   MOST110-2923-E-011-004); Wang Jhan-Yang Charitable Trust Fund (Contract
   No. WJY 2020-HR-01).
CR Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chandran P, 2020, PROC CVPR IEEE, P5860, DOI 10.1109/CVPR42600.2020.00590
   Chen T, 2020, PR MACH LEARN RES, V119
   Cheng Z., 2018, ARXIV
   Cheng Z., 2018, ASIAN C COMPUTER VIS, P605
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deng Y, 2019, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2019.00038
   Ding Z, 2019, ARXIV
   Du H., 2020, ECCV, P36
   Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33
   Guo Y, 2016, ARXIV
   Guo Y, 2017, ARXIV
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   Hsu C-H, 2013, P 21 ACM INT C MULTI, P407
   Hu MC, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P219, DOI 10.1109/BigMM.2016.62
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Khalid Syed Safwan, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P410, DOI 10.1109/TBIOM.2020.3007356
   Li WY, 2021, PROC CVPR IEEE, P14724, DOI 10.1109/CVPR46437.2021.01449
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu Y, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278091
   Liu ZW, 2019, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2019.00358
   Marzani G, 2021, 2021 INT C ICT SMART, P1
   Massoli FV, 2020, IMAGE VISION COMPUT, V99, DOI 10.1016/j.imavis.2020.103927
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sengupta S., 2016, 2016 IEEE WINT C APP, P1, DOI [DOI 10.1109/WACV.2016.7477558, 10.1109/WACV.2016.7477558]
   Shi YC, 2020, PROC CVPR IEEE, P6816, DOI 10.1109/CVPR42600.2020.00685
   Sohn K, 2016, ADV NEUR IN, V29
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Tan DS, 2022, IEEE T CYBERNETICS, V52, P4825, DOI 10.1109/TCYB.2021.3071172
   Wang F., 2018, ARXIV
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang LX, 2018, IEEE IMAGE PROC, P2386, DOI 10.1109/ICIP.2018.8451464
   Wu Y, 2017, IEEE INT CONF COMP V, P1933, DOI 10.1109/ICCVW.2017.228
   Yang L., 2020, P IEEECVF C COMPUTER
   Yang L, 2019, PROC CVPR IEEE, P2293, DOI 10.1109/CVPR.2019.00240
   Yao XW, 2016, IEEE T GEOSCI REMOTE, V54, P3660, DOI 10.1109/TGRS.2016.2523563
   Yeo YY, 2021, IEEE IMAGE PROC, P2523, DOI 10.1109/ICIP42928.2021.9506385
   Yi Dong, 2014, ARXIV14117923
   Yu HM, 2019, IEEE INT CONF COMP V, P2662, DOI 10.1109/ICCVW.2019.00325
   Zhan XH, 2018, LECT NOTES COMPUT SC, V11213, P576, DOI 10.1007/978-3-030-01240-3_35
   Zheng T., 2018, Tech. Rep., V5
   Zheng T., 2017, ARXIV
NR 43
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18617
EP 18633
DI 10.1007/s11042-022-14096-0
EA NOV 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000886859100009
DA 2024-07-18
ER

PT J
AU Ernawan, F
   Ariatmanto, D
AF Ernawan, Ferda
   Ariatmanto, Dhani
TI An efficient adaptive scaling factor for 4x4 DCT image watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Adaptive scaling factor; Embedding watermark;
   Extracting watermark; Discrete cosine transform; Robustness;
   Imperceptibility
ID SCHEME; ALGORITHM; SYSTEM
AB The imperceptibility and robustness properties of the watermarked image are the major requirements for maintaining the watermarked image similar to the original image and keeping the inserted watermark resistant under various attacks. In order to optimize the scaling factor for balancing between imperceptibility and robustness, this paper proposed a technique to generate scaling factors by considering the image content. The scaling factor is generated based on selected DCT coefficients of 4 x 4 DCT. The proposed watermarking can generate dynamic scaling factors for different DCT coefficients. The embedding regions are determined by using variance pixels, whereby the highest variance pixel was prioritised for the first embedding watermark. The watermark image pixels were scrambled by using an Arnold cat map before the watermark was embedded. This research uses 10 images from USC-SIPI image database to evaluate the effectiveness of the proposed watermarking. The experimental results showed that the proposed method improved the invisibility of the watermarked image with PSNR value of 45.38 dB rather than other watermarking schemes. The proposed watermarking showed superior performance against different types of attack.
C1 [Ernawan, Ferda] Univ Malaysia Pahang, Fac Comp, Pekan 26600, Pahang, Malaysia.
   [Ernawan, Ferda] Univ Nusa Mandiri, Fac Informat Technol, Jakarta, Indonesia.
   [Ariatmanto, Dhani] Univ AMIKOM, Fac Comp Sci, Dept Informat, Yogyakarta, Indonesia.
C3 Universiti Malaysia Pahang Al-Sultan Abdullah (UMPSA)
RP Ernawan, F (corresponding author), Univ Malaysia Pahang, Fac Comp, Pekan 26600, Pahang, Malaysia.; Ernawan, F (corresponding author), Univ Nusa Mandiri, Fac Informat Technol, Jakarta, Indonesia.
EM ferda@ump.edu.my
RI Ernawan, Ferda/B-4214-2012
OI Ernawan, Ferda/0000-0002-6779-1594
FU Universiti Malaysia Pahang through the Research Grant Scheme [PDU223208,
   PGRS1903186]
FX This research was supported by Universiti Malaysia Pahang through the
   Research Grant Scheme PDU223208 and PGRS1903186.
CR Abdelhakim AM, 2017, EXPERT SYST APPL, V72, P317, DOI 10.1016/j.eswa.2016.10.056
   Alotaibi Reem A., 2019, Applied Computing and Informatics, V15, P191, DOI 10.1016/j.aci.2018.06.003
   Ansari IA, 2016, OPTIK, V127, P5711, DOI 10.1016/j.ijleo.2016.03.070
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   El Rahman SA, 2018, COMPUT ELECTR ENG, V70, P380, DOI 10.1016/j.compeleceng.2016.09.001
   Ernawan F, 2017, Journal of Telecommunication, Electronic and Computer Engineering (JTEC), V9, P111
   Ernawan F., 2019, Int J. Electr. Computer Eng., V9, P1850, DOI [10.11591/ijece.v9i3.pp1850-1860, DOI 10.11591/IJECE.V9I3.PP1850-1860]
   Ernawan F, 2019, IEEE ACCESS, V7, P151985, DOI 10.1109/ACCESS.2019.2948086
   Ernawan F, 2016, J ICT RES APPL, V10, P228, DOI 10.5614/itbj.ict.res.appl.2016.10.3.3
   Gangadhar Y, 2018, BIOMED SIGNAL PROCES, V43, P31, DOI 10.1016/j.bspc.2018.02.007
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Hannoun K, 2018, IFAC PAPERSONLINE, V51, P50, DOI 10.1016/j.ifacol.2018.12.089
   Hsu LY, 2017, J VIS COMMUN IMAGE R, V46, P33, DOI 10.1016/j.jvcir.2017.03.009
   Jiao SM, 2019, OPT LASER TECHNOL, V109, P370, DOI 10.1016/j.optlastec.2018.08.011
   Khalili M, 2015, OPTIK, V126, P4367, DOI 10.1016/j.ijleo.2015.08.042
   Koley S, 2022, J KING SAUD UNIV-COM, V34, P636, DOI 10.1016/j.jksuci.2019.03.002
   Lai CC, 2011, OPT COMMUN, V284, P938, DOI 10.1016/j.optcom.2010.10.047
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Manikandan VM, 2018, COMPUT ELECTR ENG, V72, P614, DOI 10.1016/j.compeleceng.2018.03.007
   Mehta R, 2016, J SIGNAL PROCESS SYS, V84, P265, DOI 10.1007/s11265-015-1055-8
   Mehto A, 2016, PROCEDIA COMPUT SCI, V78, P88, DOI 10.1016/j.procs.2016.02.015
   Moosazadeh M, 2019, J INF SECUR APPL, V47, P28, DOI 10.1016/j.jisa.2019.04.001
   Poonam, 2018, Procedia Computer Science, V132, P1441, DOI 10.1016/j.procs.2018.05.076
   Roy R, 2018, VIS INFORM, V2, P125, DOI 10.1016/j.visinf.2018.03.001
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Sheltami T, 2016, FUTURE GENER COMP SY, V64, P151, DOI 10.1016/j.future.2016.01.015
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Sk A, 2018, COMPUT ELECTR ENG, V72, P589, DOI 10.1016/j.compeleceng.2018.02.045
   Su QT, 2012, OPT COMMUN, V285, P1717, DOI 10.1016/j.optcom.2011.11.117
   Thanki R, 2019, J INF SECUR APPL, V46, P231, DOI 10.1016/j.jisa.2019.03.017
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   USC-SIPI, 2022, USC SIPI IMAGE DATAB
   Vishwakarma Virendra P., 2018, Procedia Computer Science, V132, P1012, DOI 10.1016/j.procs.2018.05.017
   Wang SQ, 2019, OPT LASER ENG, V114, P76, DOI 10.1016/j.optlaseng.2018.10.014
   Wang XJ, 2012, PHYSCS PROC, V25, P1264, DOI 10.1016/j.phpro.2012.03.231
   Yadav Jyotsna, 2018, Procedia Computer Science, V132, P863, DOI 10.1016/j.procs.2018.05.098
   Yadav N, 2015, SIGNAL IMAGE VIDEO P, V9, P1531, DOI 10.1007/s11760-013-0607-2
NR 38
TC 0
Z9 0
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8603
EP 8621
DI 10.1007/s11042-022-14220-0
EA NOV 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000884893600005
DA 2024-07-18
ER

PT J
AU Wang, H
   Sun, MH
AF Wang, Hao
   Sun, Minghui
TI HQLC-Overlap: an adaptive low-cost binocular 3D human pose estimation
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single-view 3D human pose estimation; Blind spots; Multi-view fusion;
   Dynamic binocular 3D pose overlap; View filtering
AB In single-view 3D human pose modeling and analysis, there are always many hard problems of occlusion and blind spots that cannot be completely solved by single-view. Additionally, the multi-view training and complex view fusion greatly increase the training and application cost of the multi-view model. Therefore, we implemented a novel model based on dynamic binocular 3D pose overlap. It filters the views by a view filtering method to get the two best pose observation views. Then, it uses these two views to simulate the process of high-precision 3D collaborative imaging of an object by the human eye. Compared with most current single-view or multi-view models, HQLC-Overlap not only combines the advantages of the single-view model based on the high-quality view attention mechanism, but also solves the inherent problems of the single-view model through the binocular estimation mode. In this article, based on these filtered views in the data, we also counted and visualized the model's estimation error of a large number of pose images and corrected them. The principle of HQLC-Overlap model shows that it has the advantages of fast, low computational cost and dynamic flexibility for multiple views. In the experiment, we used two large-scale human pose datasets and completed the ablation experiment of this model and the comparison experiment with other models. The experimental results show that it greatly improves the 3D pose estimation accuracy of the model.
C1 [Wang, Hao; Sun, Minghui] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
   [Wang, Hao; Sun, Minghui] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Jilin, Peoples R China.
C3 Jilin University; Jilin University
RP Sun, MH (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.; Sun, MH (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Jilin, Peoples R China.
EM whao21@mails.jlu.edu.cn; smh@jlu.edu.cn
FU National Natural Science Foundation of China [61872164]; Program of
   Science and Technology Development Plan of Jilin Province of China
   [20220201147GX]; Fundamental Research Funds for the Central Universities
   [2022-JCXK-02]
FX This study has been partially supported by National Natural Science
   Foundation of China (61872164), Program of Science and Technology
   Development Plan of Jilin Province of China (20220201147GX) and
   Fundamental Research Funds for the Central Universities (2022-JCXK-02).
CR Amin S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.45
   Burenius M, 2013, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2013.464
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P336, DOI 10.1109/TCSS.2021.3102591
   Gholami M, 2022, NEUROCOMPUTING, V488, P97, DOI 10.1016/j.neucom.2022.02.076
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Güler RA, 2019, PROC CVPR IEEE, P10876, DOI 10.1109/CVPR.2019.01114
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Ionescu C, 2011, IEEE I CONF COMP VIS, P2220, DOI 10.1109/ICCV.2011.6126500
   Kanazawa A, 2019, PROC CVPR IEEE, P5597, DOI 10.1109/CVPR.2019.00576
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kocabas M, 2020, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR42600.2020.00530
   Kocabas M, 2019, PROC CVPR IEEE, P1077, DOI 10.1109/CVPR.2019.00117
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Li Z, 2021, 2021 IEEE WINTER C A, P1888, DOI DOI 10.1109/WACV48630.2021.00193
   Li Z, 2021, PROC CVPR IEEE, P14157, DOI 10.1109/CVPR46437.2021.01394
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Ma XX, 2021, PROC CVPR IEEE, P6234, DOI 10.1109/CVPR46437.2021.00617
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062
   Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Qiu HB, 2019, IEEE I CONF COMP VIS, P4341, DOI 10.1109/ICCV.2019.00444
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Y, 2019, IEEE I CONF COMP VIS, P5348, DOI 10.1109/ICCV.2019.00545
   Wang CY, 2019, IEEE T PATTERN ANAL, V41, P1227, DOI 10.1109/TPAMI.2018.2828427
   Wang H, 2022, KNOWL-BASED SYST, V239, DOI 10.1016/j.knosys.2021.107992
   Wang H, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0264302
   Xiao JS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419842
   Zhang F, 2019, PROC CVPR IEEE, P3512, DOI 10.1109/CVPR.2019.00363
NR 35
TC 0
Z9 0
U1 5
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17159
EP 17173
DI 10.1007/s11042-022-14156-5
EA NOV 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000881546700001
DA 2024-07-18
ER

PT J
AU Ghiasi, R
   Amirkhani, H
   Bosaghzadeh, A
AF Ghiasi, Razieh
   Amirkhani, Hossein
   Bosaghzadeh, Alireza
TI Multi-view graph structure learning using subspace merging on Grassmann
   manifold
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph convolutional network; Graph structure learning; Multi-view
   learning; Subspace merging; Grassmann manifold
ID NETWORK
AB Many successful learning algorithms have been recently developed to represent graph-structured data. For example, Graph Neural Networks (GNNs) have achieved considerable successes in various tasks such as node classification, graph classification, and link prediction. However, these methods are highly dependent on the quality of the input graph structure. One used approach to alleviate this problem is to learn the graph structure instead of relying on a manually designed graph. In this paper, we introduce a new graph structure learning approach using multi-view learning, named MV-GSL (Multi-View Graph Structure Learning), in which we aggregate different graph structure learning methods using subspace merging on Grassmann manifold to improve the quality of the learned graph structures. Extensive experiments are performed to evaluate the effectiveness of the proposed method on two benchmark datasets, Cora and Citeseer. Our experiments show that the proposed method has promising performance compared to single and other combined graph structure learning methods.
C1 [Ghiasi, Razieh; Amirkhani, Hossein] Univ Qom, Comp & Informat Technol Dept, Qom, Iran.
   [Bosaghzadeh, Alireza] Shahid Rajaee Teacher Training Univ, Artificial Intelligence Dept, Tehran, Iran.
C3 University of Qom; Shahid Rajaee Teacher Training University (SRTTU)
RP Amirkhani, H (corresponding author), Univ Qom, Comp & Informat Technol Dept, Qom, Iran.
EM raziehghiasi@gmail.com; amirkhani@qom.ac.ir; a.bosaghzadeh@sru.ac.ir
CR Adaloglou Nikolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12371), P398, DOI 10.1007/978-3-030-58574-7_24
   Bendokat T, 2020, ARXIV
   Bruna J., 2014, ABS13126203 CORR, P1, DOI [10.48550/arXiv.1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Chen Y, 2020, ADV NEURAL INF PROCE, V33
   Dai HJ, 2018, PR MACH LEARN RES, V80
   Defferrard M, 2016, ADV NEUR IN, V29
   Dong XW, 2019, IEEE SIGNAL PROC MAG, V36, P44, DOI 10.1109/MSP.2018.2887284
   Dong XW, 2016, IEEE T SIGNAL PROCES, V64, P6160, DOI 10.1109/TSP.2016.2602809
   Dong XW, 2014, IEEE T SIGNAL PROCES, V62, P905, DOI 10.1109/TSP.2013.2295553
   Dua D., 2017, UCI MACHINE LEARNING
   Duvenaudt D, 2015, ADV NEUR IN, V28
   Egilmez HE, 2017, IEEE J-STSP, V11, P825, DOI 10.1109/JSTSP.2017.2726975
   Fox JS, 2020, ROBUST ARE GRAPH NEU
   Franceschi L, 2019, PR MACH LEARN RES, V97
   Gao X, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102726
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hssayni E, 2022, NEURAL COMPUT APPL, V34, P2443, DOI 10.1007/s00521-021-06540-3
   Huang ZC, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1258
   Jiang B, 2019, PROC CVPR IEEE, P11305, DOI 10.1109/CVPR.2019.01157
   Jin W, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P66, DOI 10.1145/3394486.3403049
   Kalofolias V, 2016, JMLR WORKSH CONF PRO, V51, P920
   Keramatfar A, 2022, ARXIV
   Keramatfar A, 2022, COGN COMPUT, V14, P2234, DOI 10.1007/s12559-021-09986-8
   Khan MR, 2019, AAAI CONF ARTIF INTE, P606
   Kipf T.N., 2016, NIPS WORKSHOP BAYESI, P1
   Kipf TN, 2017, INT C LEARN REPR
   Li RY, 2018, AAAI CONF ARTIF INTE, P3546
   Lin GF, 2021, PATTERN RECOGN, V118, DOI 10.1016/j.patcog.2021.108039
   Lin GF, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030432
   Liu Z., 2020, SYNTH LECT ARTIF INT, V14, P1, DOI DOI 10.2200/S00980ED1V01Y202001AIM045
   Ma Y., 2019, P 2019 SIAM INT C DA, P657, DOI DOI 10.1137/1.9781611975673.74
   Niepert M, 2016, PR MACH LEARN RES, V48
   Pass R, 2017, LECT NOTES COMPUT SC, V10211, P643, DOI 10.1007/978-3-319-56614-6_22
   Peng L, 2021, COMPUT J, V64, P1093, DOI 10.1093/comjnl/bxab064
   Pilco DS, 2019, ARXIV
   Pitner G, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9371899
   Pourhatami A, 2021, SCIENTOMETRICS, V126, P6625, DOI 10.1007/s11192-021-04038-2
   Pu XY, 2021, IEEE T SIGNAL INF PR, V7, P192, DOI 10.1109/TSIPN.2021.3059995
   Rong WT, 2021, INFORM SCIENCES, V547, P68, DOI 10.1016/j.ins.2020.07.059
   Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Sen P, 2008, AI MAG, V29, P93, DOI 10.1609/aimag.v29i3.2157
   Shanthamallu US, 2020, INT CONF ACOUST SPEE, P3372, DOI [10.1109/ICASSP40776.2020.9054363, 10.1109/icassp40776.2020.9054363]
   Shi M, 2022, IEEE T NEUR NET LEAR, V33, P7899, DOI 10.1109/TNNLS.2021.3084125
   Shirazi S., 2019, J. Biostat. Epidemiol, V5, P183
   Subba B, 2019, IEEE I C ADV NETW TE, DOI 10.1109/ants47819.2019.9117966
   Tang JX, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2940, DOI 10.1109/ICASSP39728.2021.9414792
   Velickovic Petar, 2018, INT C LEARN REPR
   Wan L, 2022, MULTIMED TOOLS APPL, P1
   Wang X, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1243, DOI 10.1145/3394486.3403177
   Wei Jin, 2020, ACM SIGKDD Explorations Newsletter, V22, P19, DOI 10.1145/3447556.3447566
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xu C., 2013, arXiv
   Yan XQ, 2021, NEUROCOMPUTING, V448, P106, DOI 10.1016/j.neucom.2021.03.090
   Yang L, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4054
   Yu DH, 2021, LECT NOTES ARTIF INT, V12459, P378, DOI 10.1007/978-3-030-67664-3_23
   Zhan MM, 2022, MULTIMED TOOLS APPL, V81, P34183, DOI 10.1007/s11042-020-09984-2
   Zhang JN, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P339
   Zhang Si, 2019, Comput Soc Netw, V6, P11, DOI 10.1186/s40649-019-0069-y
   Zhou J, 2020, AI OPEN, V1, P57, DOI 10.1016/j.aiopen.2021.01.001
   Zhu DY, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1399, DOI 10.1145/3292500.3330851
   Zhu Y.J., 2021, ARXIV
   Zhuang CY, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P499, DOI 10.1145/3178876.3186116
   Zügner D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6246, DOI 10.1145/3219819.3220078
NR 64
TC 0
Z9 0
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17135
EP 17157
DI 10.1007/s11042-022-13904-x
EA NOV 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000880356200001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Oztel, I
   Oztel, GY
   Akgun, D
AF Oztel, Ismail
   Oztel, Gozde Yolcu
   Akgun, Devrim
TI A hybrid LBP-DCNN based feature extraction method in YOLO: An
   application for masked face and social distance detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Covid-19; Deep learning; Face mask detection; Human detection
AB COVID-19 is an ongoing pandemic and the WHO recommends at least one-meter social distance, and the use of medical face masks to slow the disease's transmission. This paper proposes an automated approach for detecting social distance and face masks. Thus, it aims to help the reduction of diseases transferred by respiratory droplets such as COVID-19. For this system, a two-cascaded YOLO is used. The first cascade detects humans in the environment and computes the social distance between them. Then, the second cascade detects human faces with or without a mask. Finally, red bounding boxes encircle the people's images that did not follow the rules. Also, in this paper, we propose a two-part feature extraction approach used with YOLO. The first part of the proposed feature extraction method extracts general features using the transfer learning approach. The second part extracts better features specific to the current task using the LBP layer and classification layers. The best average precision for the human detection task was obtained as 66% using Resnet50 in YOLO. The best average precision for the mask detection was obtained as 95% using Darknet19+LBP with YOLO. Also, another popular object detection network, Faster R-CNN, have been used for comparison purpose. The proposed system performed better than the literature in human and mask detection tasks.
C1 [Oztel, Ismail] Sakarya Univ, Comp Engn Dept, TR-54050 Sakarya, Turkey.
   [Oztel, Gozde Yolcu; Akgun, Devrim] Sakarya Univ, Software Engn Dept, TR-54050 Sakarya, Turkey.
C3 Sakarya University; Sakarya University
RP Oztel, I (corresponding author), Sakarya Univ, Comp Engn Dept, TR-54050 Sakarya, Turkey.
EM ioztel@sakarya.edu.tr; gyolcu@sakarya.edu.tr; dakgun@sakarya.edu.tr
RI Akgün, Devrim/GYU-5271-2022; Yolcu Öztel, Gözde/HSH-8239-2023; Oztel,
   Ismail/ABI-4346-2020
OI Akgün, Devrim/0000-0002-0770-599X; Oztel, Ismail/0000-0001-5157-7035
CR [Anonymous], CVPR 2011 WORKSHOPS, DOI DOI 10.1109/CVPRW.2011.5981811
   Bellotto N, 2009, IEEE T SYST MAN CY B, V39, P167, DOI 10.1109/TSMCB.2008.2004050
   Bhambani K., 2020, 2020 IEEE BANG HUM T, P1, DOI [10.1109/B-HTC50970.2020.9297902, DOI 10.1109/B-HTC50970.2020.9297902]
   Boccaletti S, 2020, CHAOS SOLITON FRACT, V135, DOI 10.1016/j.chaos.2020.109794
   Castillo O, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9020196
   Castillo O, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110242
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Corinna C., 1995, MACH LEARN, V20, P273, DOI [DOI 10.1007/BF00994018, 10.1007/BF00994018. S2CID 206787478]
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Nguyen DT, 2016, PATTERN RECOGN, V51, P148, DOI 10.1016/j.patcog.2015.08.027
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Falkena W, 2020, XML2STRUCT
   Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645
   Gad A., 2020, INT C INN INT INF CO, P1, DOI [10.1109/3ict51146.2020.9311969, DOI 10.1109/3ICT51146.2020.9311969]
   Ge S., 2017, IEEE C COMPUT VIS PA, P2682, DOI DOI 10.1109/CVPR.2017.53
   Guo YQ, 2021, PREV MED, V143, DOI 10.1016/j.ypmed.2020.106385
   Han F., 2006, Performance Metrics for Intelligent Systems 2006 Workshop, P133
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hong Q, 2020, PROC INT C TOOLS ART, P731, DOI 10.1109/ICTAI50040.2020.00116
   Htet Lin H., 2020, REV COMPUT ENG RES, V7, P38, DOI [10.18488/journal.76.2020.71.38.46, DOI 10.18488/JOURNAL.76.2020.71.38.46]
   Ieamsaard Jirarat, 2021, Proceedings of 2021 9th International Electrical Engineering Congress (iEECON), P428, DOI 10.1109/iEECON51072.2021.9440346
   Jason, 2021, PROCEDIA COMPUT SCI, V179, P662, DOI 10.1016/j.procs.2021.01.053
   Jiang YS, 2015, PROC CVPR IEEE, P240, DOI 10.1109/CVPR.2015.7298620
   Kaggle, 2020, FAC MASK DET
   Lalitha SD, 2019, INT J COMPUT INT SYS, V12, P903, DOI 10.2991/ijcis.d.190801.001
   Li YD, 2021, APPL INTELL, V51, P3012, DOI 10.1007/s10489-020-02100-9
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Loey M, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108288
   Maghari AYA, 2021, INVERSE PROBL SCI EN, V29, P1158, DOI 10.1080/17415977.2020.1845329
   Meivel S, 2021, Mater Today Proc, DOI 10.1016/j.matpr.2020.12.1042
   Melin P, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8020181
   Mi C, 2015, POL MARIT RES, V22, P163, DOI 10.1515/pomr-2015-0049
   Mohan P, 2020, ARXIV
   Nie Q, 2021, MOBILE NETW APPL, V26, P404, DOI 10.1007/s11036-020-01675-4
   Oulefki A, 2021, PATTERN RECOGN, V114, DOI 10.1016/j.patcog.2020.107747
   Oztel I, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P290, DOI [10.1109/UBMK.2019.8907203, 10.1109/ubmk.2019.8907203]
   OZTEL Ismail, 2020, 2020 4 INT S MULT ST, P1
   Padilla R, 2020, INT CONF SYST SIGNAL, P237, DOI [10.1109/IWSSIP48289.2020.9145130, 10.1109/iwssip48289.2020.9145130]
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Qiao L, 2022, MOBILE NETW APPL, V27, P2391, DOI 10.1007/s11036-021-01883-6
   Qin BS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185236
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Redmon Joseph, 2013, Darknet: Open Source Neural Networks in C, DOI DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusli M. E., 2020, 2020 8 INT C INF TEC, P399
   Sathyabama B., 2020, Proceedings of the 3rd International Conference on Intelligent Sustainable Systems (ICISS 2020), P1036, DOI 10.1109/ICISS49785.2020.9315934
   Sharma S, 2022, ARCH COMPUT METHOD E, V29, P3475, DOI 10.1007/s11831-021-09705-4
   Sharma S, 2020, INT J INTELL ENG INF, V8, P305, DOI 10.1504/IJIEI.2020.112038
   Sharma S, 2020, MULTIMED TOOLS APPL, V79, P26517, DOI 10.1007/s11042-020-09331-5
   Shi Y, 2015, 2 SEMINAR SOFT COMPU, V1, P1
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Somaldo P, 2020, 2020 IEEE 8 R10 HUMA, P1, DOI [10.1109/R10-HTC49770.2020.9357040, DOI 10.1109/R10-HTC49770.2020.9357040]
   Sumit SS, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12189331
   Sun TZ, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109949
   Thornton SM, 2008, P 1 IEEE WORKSH HUM, P1
   Varela-Santos S, 2021, INFORM SCIENCES, V545, P403, DOI 10.1016/j.ins.2020.09.041
   Vinay GK, 2016, SIGNAL IMAGE VIDEO P, V10, P585, DOI 10.1007/s11760-015-0781-5
   Vu HN, 2022, APPL INTELL, V52, P5497, DOI 10.1007/s10489-021-02728-1
   World Health Organization, 2020, Coronavirus disease 2019 (COVID-19) situation report -72
   Yadav Shashi., 2020, INT J RES APPL SCI E, V8, P1368, DOI [DOI 10.22214/IJRASET.2020.30560, 10.22214/IJRASET.2020.30560]
   Yew Cheong Hou, 2020, 2020 8th International Conference on Information Technology and Multimedia (ICIMU), P334, DOI 10.1109/ICIMU49871.2020.9243478
   Zhang X, 2017, ARXIV
   Zheng WK, 2022, MOBILE NETW APPL, DOI 10.1007/s11036-022-02024-3
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
   Zhu XD, 2017, IEEE ACCESS, V5, P25682, DOI 10.1109/ACCESS.2017.2771237
NR 66
TC 2
Z9 2
U1 4
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1565
EP 1583
DI 10.1007/s11042-022-14073-7
EA OCT 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000870644300002
PM 36313483
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Chen, YL
   Chen, JH
AF Chen, Yulei
   Chen, Jianhua
TI A biometrics-based mutual authentication and key agreement protocol for
   TMIS using elliptic curve cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Key agreement; Biometrics; TMIS; ROM
ID SMART CARDS; SCHEME; SECURE; EFFICIENT
AB Telecare Medicine Information System (TMIS) refers to a medical model that uses communication and information technology to realize multiple medical functions such as remote disease diagnosis, treatment, and health care. Because TMIS is carried out on an insecure public Internet, a large number of mutual authentication and key agreement protocols for TMIS have been proposed to protect the privacy of patients. Recently, Ostad-Sharif et al. proposed a novel anonymous authentication and key agreement scheme for TMIS. In this work, we will demonstrate that Ostad-Sharif et al.'s scheme exists the problems of strong authentication and inefficient password change, and it cannot resist the off-line password guessing attack. To overcome the weaknesses found in Ostad-Sharif et al.'s scheme, we propose a biometrics-based mutual authentication and key agreement protocol for TMIS, making full use of the advantages of one-way hash function and elliptic curve cryptosystem (ECC). The security of the proposed scheme is formally proved under the widely used random oracle model (ROM), and various known malicious attack resistances also are presented by the heuristic discussion. Compared with the existing related schemes, the computation cost and communication overhead of our scheme are reduced by 74.5% and 27.3% respectively.
C1 [Chen, Yulei] Zhoukou Normal Univ, Sch Math & Stat, Zhoukou 466001, Peoples R China.
   [Chen, Jianhua] Wuhan Univ, Sch Math & Stat, Wuhan 430072, Peoples R China.
C3 Zhoukou Normal University; Wuhan University
RP Chen, YL (corresponding author), Zhoukou Normal Univ, Sch Math & Stat, Zhoukou 466001, Peoples R China.
EM ylchen.math@whu.edu.cn; chenjh_ecc@163.com
CR Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Amin R, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0318-z
   Awasthi AK, 2003, IEEE T CONSUM ELECTR, V49, P1246, DOI 10.1109/TCE.2003.1261225
   Awasthi AK, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9964-1
   Bellare M, 2000, LECT NOTES COMPUT SC, V1807, P139
   Boyen X., 2009, ASIACCS 09, P228
   Chang YF, 2013, J MED SYST, V37, DOI 10.1007/s10916-012-9902-7
   Chaudhry SA, 2016, MULTIMED TOOLS APPL, V75, P12705, DOI 10.1007/s11042-015-3194-0
   Chaudhry SA, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0335-y
   Das AK, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0027-z
   Das AK, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9948-1
   Dodis Y, 2004, LECT NOTES COMPUT SC, V3027, P523
   Esposito C, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102468
   Gupta BB, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4946
   He DB, 2015, MULTIMEDIA SYST, V21, P49, DOI 10.1007/s00530-013-0346-9
   He DB, 2015, IEEE SYST J, V9, P816, DOI 10.1109/JSYST.2014.2301517
   He DB, 2013, IEEE T CONSUM ELECTR, V59, P811, DOI 10.1109/TCE.2013.6689693
   He DB, 2013, WIRELESS PERS COMMUN, V70, P323, DOI 10.1007/s11277-012-0696-1
   Hwang MS, 2000, IEEE T CONSUM ELECTR, V46, P28, DOI 10.1109/30.826377
   Islam SKH, 2018, IEEE INTERNET THINGS, V5, P3408, DOI 10.1109/JIOT.2017.2739921
   Kumari S, 2014, INT J COMMUN SYST, V27, P3939, DOI 10.1002/dac.2590
   Leu JS, 2014, IET INFORM SECUR, V8, P104, DOI 10.1049/iet-ifs.2012.0206
   Li CS, 2011, J STAT COMPUT SIM, V81, P1081, DOI 10.1080/00949651003677410
   Li X, 2018, FUTURE GENER COMP SY, V84, P149, DOI 10.1016/j.future.2017.08.029
   Lwamo NMR, 2019, INFORM SCIENCES, V477, P369, DOI 10.1016/j.ins.2018.10.037
   Malasri K, 2009, SENSORS-BASEL, V9, P6273, DOI 10.3390/s90806273
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Ostad-Sharif A, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.3913
   Ravanbakhsh N, 2018, MULTIMED TOOLS APPL, V77, P55, DOI 10.1007/s11042-016-4208-2
   Salem FM, 2020, INFORM SCIENCES, V527, P382, DOI 10.1016/j.ins.2019.07.029
   Shunmuganathan S, 2015, CAN J ELECT COMPUT E, V38, P20, DOI 10.1109/CJECE.2014.2344447
   Singh AK, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10228291
   Stergiou CL, 2021, IEEE INTERNET THINGS, V8, P5164, DOI 10.1109/JIOT.2020.3033131
   Sun HM, 2000, IEEE T CONSUM ELECTR, V46, P958, DOI 10.1109/30.920446
   Sureshkumar V, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102539
   Tewari A, 2017, J SUPERCOMPUT, V73, P1085, DOI 10.1007/s11227-016-1849-x
   Tsai JL, 2013, IEEE T IND INFORM, V9, P2004, DOI 10.1109/TII.2012.2230639
   Wang D, 2018, IEEE T DEPEND SECURE, V15, P708, DOI 10.1109/TDSC.2016.2605087
   Wang HX, 2020, PATTERN RECOGN LETT, V130, P64, DOI 10.1016/j.patrec.2018.08.010
   Yang GM, 2008, J COMPUT SYST SCI, V74, P1160, DOI 10.1016/j.jcss.2008.04.002
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
NR 41
TC 1
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16009
EP 16032
DI 10.1007/s11042-022-14007-3
EA OCT 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000865911600001
PM 36250183
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kumar, A
   Dua, M
AF Kumar, Atul
   Dua, Mohit
TI A GRU and chaos-based novel image encryption approach for transport
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; GRU; Sine-cosine map; Chaos
ID ALGORITHM; CRYPTANALYSIS; SYSTEM; MAP; PERMUTATION
AB An Intelligent Transport System (ITS) uses smart devices to capture the traffic data in the form of images. However, the adversary can steal and misuse this traffic information. Hence, it becomes essential to have an efficient encryption strategy to save data from various types of attacks. This paper proposes a novel encryption algorithm that uses the Gated Recurrent Unit (GRU) and Sine-Cosine chaotic map to encrypt transport images. The encryption scheme is divided into three phases. In the first phase, two intermediate keys and the seed value required for creating chaotic sequence are generated using unique combinations of 128-bit share key and 128-bit initial vector. In the second phase, permutation is performed using one of the intermediate keys and the chaotic sequence generated by the novel Sine-Cosine chaotic map. The final phase performs the diffusion process using the other intermediate key and GRU approach that uses the chaotic sequence generated by the Sine-Cosine map. The performance of the proposed encryption approach is analyzed using various standard encryption metrics, attacks and decryption parameters. The obtained results and comparative results with existing approaches reveal that the proposed method is suitable for implementing secure and efficient transport image cryptosystems.
C1 [Kumar, Atul; Dua, Mohit] Natl Inst Technol, Dept Comp Engn, Kurukshetra, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Kumar, A (corresponding author), Natl Inst Technol, Dept Comp Engn, Kurukshetra, Haryana, India.
EM atul.kumar1995@gmail.com; er.mohitdua@nitkkr.ac.in
RI ; DUA, MOHIT/A-1409-2016
OI Kumar, Atul/0000-0002-6895-0104; DUA, MOHIT/0000-0001-7071-8323
CR ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Bentoutou Y, 2020, ADV SPACE RES, V66, P176, DOI 10.1016/j.asr.2019.09.027
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2013, OPT EXPRESS, V21, P27873, DOI 10.1364/OE.21.027873
   Chen L, 2017, NONLINEAR DYNAM, V87, P1797, DOI 10.1007/s11071-016-3153-y
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Dhall S, 2022, J KING SAUD UNIV-COM, V34, P1533, DOI 10.1016/j.jksuci.2018.09.015
   Dou YQ, 2021, MULTIMED TOOLS APPL, V80, P24437, DOI 10.1007/s11042-021-10850-y
   Dua M, 2021, COMPLEX INTELL SYST, V7, P327, DOI 10.1007/s40747-020-00201-z
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   flickr, MONTAUK STUDENT TRAN
   flickr, ONE 2 3 HERE WE GOND
   flickr, TOTAL TRANSPORTATION
   flickr, VALLO TRANSPORTATION
   Ghazvini M, 2020, MULTIMED TOOLS APPL, V79, P26927, DOI 10.1007/s11042-020-09058-3
   Guesmi R, 2021, MULTIMED TOOLS APPL, V80, P1925, DOI 10.1007/s11042-020-09672-1
   He Y, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-85377-1
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Hui YY, 2023, MULTIMED TOOLS APPL, V82, P21983, DOI 10.1007/s11042-021-10526-7
   Ismail SM, 2018, J ADV RES, V10, P85, DOI 10.1016/j.jare.2018.01.009
   Kaur M, 2020, FUTURE GENER COMP SY, V107, P333, DOI 10.1016/j.future.2020.02.029
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Kumar A., 2021, MULTIMED TOOLS APPL, V80, P1, DOI [10.1007/s11042-020-08904-8, DOI 10.1007/S11042-020-08904-8]
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar M, 2021, MULTIMED TOOLS APPL, V80, P31277, DOI 10.1007/s11042-020-10471-x
   Kumar M, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103052
   Lalitha RVSS, 2017, LECT NOTE NETW SYST, V5, P261, DOI 10.1007/978-981-10-3226-4_26
   Li Z, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/8824915
   Lin CH, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11031329
   Liu DD, 2018, SIGNAL PROCESS, V151, P130, DOI 10.1016/j.sigpro.2018.05.008
   Liu JZ, 2019, MULTIDIM SYST SIGN P, V30, P1637, DOI 10.1007/s11045-018-0622-0
   Liu LF, 2017, MULTIMED TOOLS APPL, V76, P16511, DOI 10.1007/s11042-016-3925-x
   Liu YS, 2016, NONLINEAR DYNAM, V84, P2241, DOI 10.1007/s11071-016-2642-3
   Ma KY, 2021, MULTIMED TOOLS APPL, V80, P24737, DOI 10.1007/s11042-021-10847-7
   Monika, 2021, Computational Methods and Data Engineering. Proceedings of ICMDE 2020. Advances in Intelligent Systems and Computing (AISC 1227), P207, DOI 10.1007/978-981-15-6876-3_16
   Mousavi M, 2021, MULTIMED TOOLS APPL, V80, P13157, DOI 10.1007/s11042-020-10440-4
   Pak C, 2021, MULTIMED TOOLS APPL, V80, P25367, DOI 10.1007/s11042-021-10660-2
   Pankaj S, 2021, NETW MODEL ANAL HLTH, V10, DOI 10.1007/s13721-021-00324-4
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Srinivasu PN, 2022, GAZI U J SCI, V35, P1372, DOI 10.35378/gujs.884880
   Srinivasu PN, 2015, INT J COMPUT APPL, V120
   Thoms GRW, 2019, IEEE ACCESS, V7, P158697, DOI 10.1109/ACCESS.2019.2950007
   Walia S, 2021, IEEE ACCESS, V9, P99742, DOI 10.1109/ACCESS.2021.3096240
   Wang J, 2021, MULTIMED TOOLS APPL, V80, P16087, DOI 10.1007/s11042-020-10413-7
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106501
   Wang XY, 2014, NONLINEAR DYNAM, V78, P2975, DOI 10.1007/s11071-014-1639-z
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Xiang HY, 2021, MULTIMED TOOLS APPL, V80, P22135, DOI 10.1007/s11042-021-10807-1
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Zareai D, 2021, MULTIMED TOOLS APPL, V80, P18317, DOI 10.1007/s11042-021-10576-x
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang X, 2021, MULTIMED TOOLS APPL, V80, P8809, DOI 10.1007/s11042-020-09465-6
   Zhang YQ, 2021, MULTIMED TOOLS APPL, V80, P19291, DOI 10.1007/s11042-021-10724-3
   Zhao JF, 2015, NONLINEAR DYNAM, V80, P1721, DOI 10.1007/s11071-015-1911-x
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu CX, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110843
NR 65
TC 12
Z9 12
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18381
EP 18408
DI 10.1007/s11042-022-13902-z
EA OCT 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000865911600004
OA hybrid
DA 2024-07-18
ER

PT J
AU Nourbakhsh, Z
   Habibi, N
AF Nourbakhsh, Zahra
   Habibi, Narges
TI Combining LSTM and CNN methods and fundamental analysis for stock price
   trend prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Long short term memory; Convolutional neural network; Stock trend Price;
   Stock exchange; Deep learning; Fundamental analysis
ID MARKET PREDICTION; TIME-SERIES; NETWORKS
AB Stock market trend prediction has always been a major challenge for investors. In this paper, the combination of Convolutional Neural Network and long short-term memory methods, as well as fundamental analysis components such as P/E ratio, profitability and the number of company transactions have been used to increase the performance and reduce the model error in stock price trend prediction. To evaluate the model, the parameters of evaluating mean absolute error and mean absolute percentage error in four groups of financial, petroleum, basic metals and non-metallic minerals were employed, the results of which indicated an increase in the performance and a reduction in error. According to the results, in the financial group, we obtained 0.49 for the mean absolute percentage error and 4.30 the for mean absolute error. In petroleum group, mean absolute percentage error is 0.33 and mean absolute error equals 3.64. In basic metals group, mean absolute percentage error is 0.29 and mean absolute error equals 2.39. Finally, in non-metallic minerals group, we achieved 0.73 for mean absolute percentage error and 6.16 for mean absolute error. The values obtained in the proposed method show the effect of the model on the performance and prediction of error.
C1 [Nourbakhsh, Zahra; Habibi, Narges] Islamic Azad Univ, Isfahan Khorasgan Branch, Dept Comp Engn, Esfahan, Iran.
C3 Islamic Azad University
RP Habibi, N (corresponding author), Islamic Azad Univ, Isfahan Khorasgan Branch, Dept Comp Engn, Esfahan, Iran.
EM za.nourbakhsh@gmail.com; n.habibi@khuisf.ac.ir
RI Nourbakhsh, Zahra/JSK-1365-2023
OI Nourbakhsh, Zahra/0000-0002-1406-0798
CR Adebiyi AA, 2014, UKSIM INT CONF COMP, P106, DOI 10.1109/UKSim.2014.67
   Agarap A. F., 2018, ARXIV
   Baek Y, 2018, EXPERT SYST APPL, V113, P457, DOI 10.1016/j.eswa.2018.07.019
   Bahi M, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON PATTERN ANALYSIS AND INTELLIGENT SYSTEMS (PAIS), P268
   Baldo Alessandro, 2021, Hybrid Artificial Intelligent Systems: 16th International Conference, HAIS 2021, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (12886), P550, DOI 10.1007/978-3-030-86271-8_46
   Behera RK, 2020, J UNIVERS COMPUT SCI, V26, P1128
   Bhuvaneshwari M., 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P996, DOI 10.1109/ICCMC51019.2021.9418022
   Budiharto W, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00430-0
   Cai QS, 2013, PROCEDIA COMPUT SCI, V18, P1155, DOI 10.1016/j.procs.2013.05.281
   Chen K, 2021, ARXIV
   Chen YJ, 2017, SOFT COMPUT, V21, P3735, DOI 10.1007/s00500-016-2028-y
   Chen YQ, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/9976209
   Chung H, 2020, NEURAL COMPUT APPL, V32, P7897, DOI 10.1007/s00521-019-04236-3
   Chung H, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10103765
   COYLE EJ, 1988, IEEE T ACOUST SPEECH, V36, P1244, DOI 10.1109/29.1653
   Das SP, 2018, INT J MACH LEARN CYB, V9, P97, DOI 10.1007/s13042-015-0359-0
   DeMark, 1994, NEW SCI TECHNICAL AN, P1
   Fischer T, 2018, EUR J OPER RES, V270, P654, DOI 10.1016/j.ejor.2017.11.054
   Ganster H, 2001, IEEE T MED IMAGING, V20, P233, DOI 10.1109/42.918473
   Hiransha M., 2018, Procedia Computer Science, V132, P1351, DOI 10.1016/j.procs.2018.05.050
   Hoseinzade E, 2019, EXPERT SYST APPL, V129, P273, DOI 10.1016/j.eswa.2019.03.029
   Kim KJ, 2000, EXPERT SYST APPL, V19, P125, DOI 10.1016/S0957-4174(00)00027-0
   Li WJ, 2011, PROCEDIA ENVIRON SCI, V11, P256, DOI 10.1016/j.proenv.2011.12.040
   Lin Z, 2018, FUTURE GENER COMP SY, V79, P960, DOI 10.1016/j.future.2017.08.033
   Livieris IE, 2020, INTELL DECIS TECHNOL, V14, P313, DOI 10.3233/IDT-190035
   Long JW, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106205
   Merh N., 2010, Business Intelligence Journal, V3, P23
   Moghar A, 2020, PROCEDIA COMPUT SCI, V170, P1168, DOI 10.1016/j.procs.2020.03.049
   Nabipour M, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22080840
   Olah C., 2015, Understanding LSTM Networks, DOI DOI 10.1007/S13398-014-0173-7.2
   Patel J, 2015, EXPERT SYST APPL, V42, P259, DOI 10.1016/j.eswa.2014.07.040
   Pawar K, 2019, ADV INTELL SYST, V841, P493, DOI 10.1007/978-981-13-2285-3_58
   Qian B, 2007, APPL INTELL, V26, P25, DOI 10.1007/s10489-006-0001-7
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00398-3
   Rostami M, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00352-3
   Rostami M, 2020, GENOMICS, V112, P4370, DOI 10.1016/j.ygeno.2020.07.027
   Saud AS, 2020, PROCEDIA COMPUT SCI, V167, P788, DOI 10.1016/j.procs.2020.03.419
   Selvin S, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1643, DOI 10.1109/ICACCI.2017.8126078
   Sharma S, 2017, Towards Data Sci, V6, P310, DOI [DOI 10.33564/IJEAST.2020.V04I12.054, 10.33564/IJEAST.2020.v04i12.054]
   Sim HS, 2019, COMPLEXITY, DOI 10.1155/2019/4324878
   Thakkar A, 2020, PROCEDIA COMPUT SCI, V167, P616, DOI 10.1016/j.procs.2020.03.328
   Tsantekidis A, 2017, CONF BUS INFORM, V1, P7, DOI 10.1109/CBI.2017.23
   Valueva MV, 2020, MATH COMPUT SIMULAT, V177, P232, DOI 10.1016/j.matcom.2020.04.031
   Wang W, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER AIDED EDUCATION (ICISCAE 2018), P64, DOI 10.1109/ICISCAE.2018.8666928
   WONG W. K., 2003, Applied Financial Economics, V13, P543, DOI [DOI 10.1080/0960310022000020906, 10.1080/0960310022000020906]
   Wu JMT, 2021, MOB INF SYST, V2021, DOI 10.1155/2021/6706345
   Yadav A, 2020, PROCEDIA COMPUT SCI, V167, P2091, DOI 10.1016/j.procs.2020.03.257
   Zhang YD, 2009, EXPERT SYST APPL, V36, P8849, DOI 10.1016/j.eswa.2008.11.028
   Zhou X., 2018, Mathematical Problems in Engineering, V2018
NR 50
TC 5
Z9 5
U1 11
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17769
EP 17799
DI 10.1007/s11042-022-13963-0
EA OCT 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000865911600006
DA 2024-07-18
ER

PT J
AU Zhou, XY
   Yang, GS
   Hong, W
   Chen, KS
   Chen, TS
AF Zhou, Xiaoyu
   Yang, Guangsong
   Hong, Wien
   Chen, Kia Sheng
   Chen, Tung-Shou
TI An adaptive data hiding for AMBTC compressed images with recoverability
   using bound shifting technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AMBTC; Recoverability; Data hiding; Bound shifting
AB This paper proposes an efficient data hiding method for absolute moment block truncation coding (AMBTC) images with the recoverability of compressed code. The existing methods sacrifice some embedding capacity and image quality for recovering the AMBTC compressed code. To remedy these problems, this paper divides the quantized differences into four intervals to embed data bits with different lengths. Therefore, the embedding capacity is improved. Moreover, our method uses the bound shifting technique (BST) to provide a significant improvement in image quality. The experimental results show that the payload of our method increases by 19.14% and the image quality is also enhanced by 8.02% compared with prior works for the test Lena image.
C1 [Zhou, Xiaoyu; Yang, Guangsong] Jimei Univ, Sch Ocean Informat Engn, Xiamen 361021, Peoples R China.
   [Hong, Wien; Chen, Tung-Shou] Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung 404, Taiwan.
   [Chen, Kia Sheng] Nanfang Coll Guangzhou, Sch Elect & Comp Engn, Guangzhou 510970, Peoples R China.
C3 Jimei University; National Taichung University of Science & Technology;
   Nanfang College, Guangzhou
RP Yang, GS (corresponding author), Jimei Univ, Sch Ocean Informat Engn, Xiamen 361021, Peoples R China.; Hong, W (corresponding author), Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung 404, Taiwan.
EM xiaoyuzhou68@outlook.com; gsyang@jmu.edu.cn; wienhong@nutc.edu.tw;
   chenksh@nfu.edu.cn; tschen.prof@gmail.com
RI Zhou, Xiao-Yu/B-2593-2018; Chen, Kai-Sheng/N-1013-2016
FU Science Foundation of Fujian Province [2021 J01865, 2021 J01866]; Open
   Project Fund of Fujian Shipping Research Institute
FX The paper is supported by the Science Foundation of Fujian Province (No.
   2021 J01865) (No.2021 J01866), Open Project Fund of Fujian Shipping
   Research Institute.
CR Abdallah Emad E., 2007, Proceedings Graphics Interface 2007, P327, DOI 10.1145/1268517.1268570
   Abdallah EE, 2010, SIGNAL IMAGE VIDEO P, V4, P233, DOI 10.1007/s11760-009-0114-7
   Abdallah EE, 2009, SIGNAL IMAGE VIDEO P, V3, P375, DOI 10.1007/s11760-008-0079-y
   Abdallah EE, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2764466
   Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   BOWS-2, IM DAT
   Chen YH, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11020635
   Chen YY, 2019, MULTIMEDIA SYST, V25, P551, DOI 10.1007/s00530-017-0560-y
   Choi KS, 2013, DIGIT SIGNAL PROCESS, V23, P1171, DOI 10.1016/j.dsp.2013.03.008
   Hong W, 2018, INFORM SCIENCES, V463, P245, DOI 10.1016/j.ins.2018.05.055
   Hong WE, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10070254
   Hong W, 2017, MULTIMED TOOLS APPL, V76, P5441, DOI 10.1007/s11042-016-4032-8
   Horng JH, 2020, IEEE ACCESS, V8, P129347, DOI 10.1109/ACCESS.2020.3009232
   Hu YC, 2017, MULTIMED TOOLS APPL, V76, P15435, DOI 10.1007/s11042-016-3847-7
   Hu YC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013012
   Jiang N, 2018, INT J THEOR PHYS, V57, P611, DOI 10.1007/s10773-017-3593-2
   Kim C, 2020, MATH BIOSCI ENG, V17, P160, DOI 10.3934/mbe.2020009
   Kim S, 2016, IEEE T CONSUM ELECTR, V62, P412, DOI 10.1109/TCE.2016.7838094
   Lema M., 1984, IEEE T INF FOREN SEC, V10, P507
   Li S, 2020, IEEE ACCESS, V8, P214732, DOI 10.1109/ACCESS.2020.3040048
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Lin YH, 2021, MULTIMED TOOLS APPL, V80, P24949, DOI 10.1007/s11042-021-10914-z
   Malik A, 2018, MULTIDIM SYST SIGN P, V29, P1801, DOI 10.1007/s11045-017-0530-8
   Rahmani P, 2018, IET IMAGE PROCESS, V12, P1195, DOI 10.1049/iet-ipr.2016.0618
   Su W., 2019, J INF SECUR APPL, V45, P1
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Tang MW, 2016, OPTIK, V127, P471, DOI 10.1016/j.ijleo.2015.09.216
   The University of Southern California (USC) Signal and Image Processing Institute (SIPI), IM DAT
   Wu XT, 2019, DIGIT SIGNAL PROCESS, V93, P22, DOI 10.1016/j.dsp.2019.06.016
   Yao H, 2021, INFORM SCIENCES, V563, P130, DOI 10.1016/j.ins.2021.02.015
   Zhang Y, 2013, IEICE T COMMUN, VE96B, P624, DOI 10.1587/transcom.E96.B.624
NR 33
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15593
EP 15612
DI 10.1007/s11042-022-13961-2
EA OCT 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000865713700001
DA 2024-07-18
ER

PT J
AU Du, RY
   Zhu, SJ
   Ni, HJ
   Mao, TY
   Li, JJ
   Wei, R
AF Du, Ruoyu
   Zhu, Shujin
   Ni, Huangjing
   Mao, Tianyi
   Li, Jiajia
   Wei, Ran
TI Valence-arousal classification of emotion evoked by Chinese
   ancient-style music using 1D-CNN-BiLSTM model on EEG signals for college
   students
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EEG; Chinese music; Emotion classification; BiLSTM
ID RECOGNITION
AB During the COVID-19 pandemic, young people are using multimedia content more frequently to communicate with each other on Internet platforms. Among them, music, as psychological support for a lonely life in this special period, is a powerful tool for emotional self-regulation and getting rid of loneliness. More and more attention has been paid to the music recommender system based on emotion. In recent years, Chinese music has tended to be considered an independent genre. Chinese ancient-style music is one of the new folk music styles in Chinese music and is becoming more and more popular among young people. The complexity of Chinese-style music brings significant challenges to the quantitative calculation of music. To effectively solve the problem of emotion classification in music information search, emotion is often characterized by valence and arousal. This paper focuses on the valence and arousal classification of Chinese ancient-style music-evoked emotion. It proposes a hybrid one-dimensional convolutional neural network and bidirectional and unidirectional long short-term memory model (1D-CNN-BiLSTM). And a self-acquisition EEG dataset for Chinese college students was designed to classify music-induced emotion by valence-arousal based on EEG. In addition to that, the proposed 1D-CNN-BILSTM model verified the performance of public datasets DEAP and DREAMER, as well as the self-acquisition dataset DESC. The experimental results show that, compared with traditional LSTM and 1D-CNN-LSTM models, the proposed method has the highest accuracy in the valence classification task of music-induced emotion, reaching 94.85%, 98.41%, and 99.27%, respectively. The accuracy of the arousal classification task also gained 93.40%, 98.23%, and 99.20%, respectively. In addition, compared with the positive valence classification results of emotion, this method has obvious advantages in negative valence classification. This study provides a computational classification model for a music recommender system with emotion. It also provides some theoretical support for the brain-computer interactive (BCI) application products of Chinese ancient-style music which is popular among young people.
C1 [Du, Ruoyu; Zhu, Shujin; Ni, Huangjing; Mao, Tianyi; Li, Jiajia] Nanjing Univ Posts & Telecommun, Sch Geog & Biol Informat, Nanjing, Peoples R China.
   [Du, Ruoyu; Zhu, Shujin; Ni, Huangjing; Mao, Tianyi] Smart Hlth Big Data Anal & Locat Serv Engn Lab Ji, Nanjing, Peoples R China.
   [Wei, Ran] Tianjin Polytech Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Tiangong University
RP Du, RY; Zhu, SJ (corresponding author), Nanjing Univ Posts & Telecommun, Sch Geog & Biol Informat, Nanjing, Peoples R China.; Du, RY; Zhu, SJ (corresponding author), Smart Hlth Big Data Anal & Locat Serv Engn Lab Ji, Nanjing, Peoples R China.
EM dury@njupt.edu.cn; shujinzhu@njupt.edu.cn
FU National Natural Science Foundation of China [61977039]; Natural Science
   Foundation of Jiangsu Province [BK20190736, BK20200745]; Natural Science
   Foundation for Colleges and Universities of Jiangsu Province
   [20KJB510022]; NUPTSF [NY218138]
FX We thank American Journal Experts (AJE) for English language editing.;
   This work was supported by a grant from the National Natural Science
   Foundation of China (Grant No. 61977039), and the Natural Science
   Foundation of Jiangsu Province (Grant No. BK20190736, BK20200745), This
   work was also sponsored by the Natural Science Foundation for Colleges
   and Universities of Jiangsu Province, 20KJB510022, NUPTSF (Grant No.
   NY218138).
CR Algarni M, 2021, REV EMOTION RECOGNIT, DOI [10.1007/978-3-030-70713-2_42, DOI 10.1007/978-3-030-70713-2_42]
   Alhagry S, 2017, INT J ADV COMPUT SC, V8, P355, DOI 10.14569/IJACSA.2017.081046
   [Anonymous], 2011, Handbook of music and emotion: Theory, research, applications
   Anubhav, 2020, 2020 16TH IEEE INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2020), P88, DOI [10.1109/CSPA48992.2020.9068691, 10.1109/cspa48992.2020.9068691]
   Bai ZY, 2019, ENERGIES, V12, DOI 10.3390/en12173258
   Martín JC, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e06274
   Chen, 2019, P 3 INT C CULTURE ED, DOI [10.2991/iccese-19.2019.71, DOI 10.2991/ICCESE-19.2019.71]
   Galvao F, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21103414
   Gao ZK, 2021, IEEE T COGN DEV SYST, V13, P945, DOI 10.1109/TCDS.2020.2976112
   Graves A, 2005, LECT NOTES COMPUT SC, V3697, P799
   Hennessy S, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0258027
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Juslin PN, 2008, EMOTION, V8, P668, DOI 10.1037/a0013505
   Katsigiannis S, 2018, IEEE J BIOMED HEALTH, V22, P98, DOI 10.1109/JBHI.2017.2688239
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Lampropoulos AS, 2012, MULTIMED TOOLS APPL, V59, P241, DOI 10.1007/s11042-011-0742-0
   Li X, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2203.11279
   Liu YJ, 2018, IEEE T AFFECT COMPUT, V9, P550, DOI 10.1109/TAFFC.2017.2660485
   Liu Y, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103927
   Pandey P., 2022, International Conference on Innovative Computing and Communications: Proceedings of ICICC 2021, Volume 2, P509, DOI [10.1007/978-981-16-2597-8_43, DOI 10.1007/978-981-16-2597-8_43]
   Sharma R, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2020.101867
   Song TF, 2020, IEEE T AFFECT COMPUT, V11, P532, DOI 10.1109/TAFFC.2018.2817622
   Strasser MA, 2022, J AFFECT DISORDERS, V300, P481, DOI 10.1016/j.jad.2022.01.007
   Yehuda N, 2011, J ADULT DEV, V18, P85, DOI 10.1007/s10804-010-9117-4
   Zhan Y, 2019, IEEE INT CONF COMP, P198, DOI 10.1109/civemsa45640.2019.9071594
   Zhang Y, 2022, COGN COMPUT SYST, V4, P147, DOI 10.1049/ccs2.12036
   Zhou W, 2021, EFFICIENT REGULATION, P81, DOI [10.1145/3459212.3459225, DOI 10.1145/3459212.3459225]
   Ziv N, 2022, PSYCHOL MUSIC, V50, P475, DOI 10.1177/03057356211003326
NR 28
TC 12
Z9 12
U1 12
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15439
EP 15456
DI 10.1007/s11042-022-14011-7
EA OCT 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000863811400005
PM 36213341
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Sharma, P
   Kumar, M
   Sharma, H
AF Sharma, Preeti
   Kumar, Manoj
   Sharma, Hitesh
TI Comprehensive analyses of image forgery detection methods from
   traditional to deep learning approaches: an evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; GAN; Copy-move forgery detection; Data-driven
   methods; Image splicing; Deep learning-based detection techniques
ID COMPUTER-GENERATED IMAGES; LOCALIZATION; NETWORKS; MODEL
AB The digital image proves critical evidence in the fields like forensic investigation, criminal investigation, intelligence systems, medical imaging, insurance claims, and journalism to name a few. Images are an authentic source of information on the internet and social media. But, using easily available software or editing tools such as Photoshop, Corel Paint Shop, PhotoScape, PhotoPlus, GIMP, Pixelmator, etc. images can be altered or utilized maliciously for personal benefits. Various active, passive and other new deep learning technology like GAN approaches have made photo-realistic images difficult to distinguish from real images. Digital image tamper detection now focuses on determining the authenticity and consistency of digital photos. The major research problems use generic solutions and strategies, such as standardized data sets, benchmarks, evaluation criteria and generalized approaches.This paper overviews the evaluation of various image tamper detection methods. A brief discussion of image datasets and a comparative study of image criminological (forensic) methods are included in this paper. Furthermore, recently developed deep learning techniques along with their limitations have also been addressed. This study aims to comprehensively analyze image forgery detection methods using conventional and advanced deep learning approaches.
C1 [Sharma, Preeti; Sharma, Hitesh] Univ Petr & Energy Studies UPES, Sch Comp Sci, Dehra Dun 248007, Uttarakhand, India.
   [Kumar, Manoj] Univ Wollongong Dubai, Fac Engn & Informat Sci, Dubai Knowledge Pk, Dubai, U Arab Emirates.
C3 University of Petroleum & Energy Studies (UPES); University of
   Wollongong
RP Kumar, M (corresponding author), Univ Wollongong Dubai, Fac Engn & Informat Sci, Dubai Knowledge Pk, Dubai, U Arab Emirates.
EM preetiii.kashyup@gmail.com; wss.manojkumar@gmail.com;
   hksharma@ddn.upes.ac.in
RI Kumar, Manoj/AFS-0700-2022
OI Kumar, Manoj/0000-0001-9598-0280; Kumar, Dr. Manoj/0000-0001-5113-0639
CR Amandeep K., 2016, International Journal of Technical Research & Science, V1, P18
   Amerini I, 2017, IEEE COMPUT SOC CONF, P1865, DOI 10.1109/CVPRW.2017.233
   [Anonymous], 2001, P VLBV
   Ansari MD, 2014, IETE Journal of Education, V55, P40, DOI DOI 10.1080/09747338.2014.921415
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Barni M, 2018, IEEE IMAGE PROC, P3803, DOI 10.1109/ICIP.2018.8451698
   Barni M, 2017, J VIS COMMUN IMAGE R, V49, P153, DOI 10.1016/j.jvcir.2017.09.003
   Bondi L, 2017, IEEE SIGNAL PROC LET, V24, P259, DOI 10.1109/LSP.2016.2641006
   Bourouis S, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111811
   Bunk J, 2017, IEEE COMPUT SOC CONF, P1881, DOI 10.1109/CVPRW.2017.235
   Camacho IC, 2021, J IMAGING, V7, DOI 10.3390/jimaging7040069
   Castillo Camacho Ivan, 2021, Digital Forensics and Watermarking 19th International Workshop, IWDW 2020. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12617), P208, DOI 10.1007/978-3-030-69449-4_16
   Chaitra B., 2019, 2019 International Conference on contemporary Computing and Informatics (IC3I). Proceedings, P127, DOI 10.1109/IC3I46837.2019.9055573
   Choi KS, 2006, PROC SPIE, V6069, DOI 10.1117/12.649775
   Cozzolino D, 2020, IEEE T INF FOREN SEC, V15, P144, DOI 10.1109/TIFS.2019.2916364
   Cozzolino D, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P159, DOI 10.1145/3082031.3083247
   de Rezende ERS, 2018, SIGNAL PROCESS-IMAGE, V66, P113, DOI 10.1016/j.image.2018.04.006
   Deng H, 2019, NIPS
   Diallo B, 2019, LECT NOTES COMPUT SC, V11295, P387, DOI 10.1007/978-3-030-05710-7_32
   Ding XH, 2019, IEEE ACCESS, V7, P25878, DOI 10.1109/ACCESS.2019.2897360
   Ding XY, 2020, EURASIP J INF SECUR, V2020, DOI 10.1186/s13635-020-00109-8
   Doke KK., 2012, INT J COMPUT APPL, V49, P1
   Eversberg L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21237901
   Fan W, 2012, EUR SIGNAL PR CONF, P1777
   Fan Y, 2015, IEEE IMAGE PROC, P2940, DOI 10.1109/ICIP.2015.7351341
   Fernandes FE Jr, 2019, SWARM EVOL COMPUT, V49, P62, DOI 10.1016/j.swevo.2019.05.010
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Freire-Obregón D, 2019, PATTERN RECOGN LETT, V126, P86, DOI 10.1016/j.patrec.2018.01.005
   Fridrich J., 2013, Digital Image Forensics, P179
   Gardella M, 2021, J IMAGING, V7, DOI 10.3390/jimaging7070119
   Geradts ZJ, 2000, PROC SPIE, V4232, P505, DOI 10.1117/12.417569
   Gill NK, 2017, INT CONF COMPUT
   Ginesu G, 2006, EURASIP J WIREL COMM, DOI 10.1155/WCN/2006/73685
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Gupta A., 2013, INT J SCI RES PUBL, V3, P5
   Hashmi MF, 2014, AASRI PROC, V9, P84, DOI 10.1016/j.aasri.2014.09.015
   He PS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174743
   Heng Yao, 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P591, DOI 10.1109/MINES.2011.104
   Hssayni E, 2022, NEURAL COMPUT APPL, V34, P2443, DOI 10.1007/s00521-021-06540-3
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Hussain M, 2015, INT J ARTIF INTELL T, V24, DOI 10.1142/S0218213015400163
   Johnson Micah K, 2006, ACM WORKSHOP MULTIME, P48
   Johnson MK, 2006, COMPUTER SCI TECHNIC
   Kashyap A, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1703.09968
   Kaur C., 2019, Stat. Optim. Inf. Comput, V7, P486, DOI DOI 10.19139/SOIC.V7I2.542
   KEE E, 2010, 2010 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2010.5711437
   Khalid H, 2020, IEEE COMPUT SOC CONF, P2794, DOI 10.1109/CVPRW50498.2020.00336
   Koppanati R.K., 2021, LECT NOTES NETWORKS, V175, DOI [10.1007/978-3-030-67187-7_26, DOI 10.1007/978-3-030-67187-7_26]
   Koppanati RK, 2021, IEEE CONSUM ELECTR M, V10, P41, DOI 10.1109/MCE.2020.3003127
   Koppanati RK, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P1820, DOI 10.1109/ICCONS.2018.8662840
   Kumar B.S., 2018, Journal of computational and theoretical Nanoscience, V15, P2560, DOI [10.1166/jctn.2018.7498, DOI 10.1166/JCTN.2018.7498]
   Kumar M, 2019, INT J IMAGE GRAPH, V19, DOI 10.1142/S0219467819500141
   Kumar M, 2019, AUST J FORENSIC SCI, V51, P243, DOI 10.1080/00450618.2017.1356871
   Kumar M, 2019, MULTIMED TOOLS APPL, V78, P12451, DOI 10.1007/s11042-018-6775-x
   Kumar M, 2018, L N COMPUT VIS BIOME, V28, P1129, DOI 10.1007/978-3-319-71767-8_97
   Kumar M, 2019, AUST J FORENSIC SCI, V51, P119, DOI 10.1080/00450618.2017.1356868
   Lee S, 2021, APPL SOFT COMPUT, V105, DOI 10.1016/j.asoc.2021.107256
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Liu Q, 2009, P 1 ACM WORKSH MULT, P43, DOI [10.1145/1631081.1631092, DOI 10.1145/1631081.1631092]
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P18269, DOI 10.1007/s11042-017-5374-6
   Lu M, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050858
   Lu SL, 2022, MULTIMED TOOLS APPL, V81, P37847, DOI 10.1007/s11042-022-12755-w
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahalakshmi SD, 2012, DIGIT INVEST, V8, P215, DOI 10.1016/j.diin.2011.06.004
   Mantri A, 2023, IETE J RES, V69, P8058, DOI 10.1080/03772063.2022.2048706
   MANUPRIYA P, 2017, 2017 C INF COMM TECH, P1, DOI DOI 10.1109/INFOCOMTECH.2017.8340639
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Meena K.B., 2019, DATA ENG APPL, P163, DOI [DOI 10.1007/978-981-13-6351-1_14, 10.1007/978-981-13-6351-1_14]
   Meiners W, 1998, United States Patent, Patent No. 19
   Mohite VD, 2019, INT J RES ENG APPL M, V02, P885
   Morgand A, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2108.09378
   Morgand A, 2018, IEEE T VIS COMPUT GR, V24, P1691, DOI 10.1109/TVCG.2017.2677445
   Mushtaq S., 2014, International Journal of Advanced Science and Technology, V73, P15, DOI DOI 10.14257/IJAST.2014.73.02
   Nath VV., 2015, INT J SCI TECHNOL MA, V4, P146
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Nirmalkar N, 2015, 2015 INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION, EMBEDDED AND COMMUNICATION SYSTEMS (ICIIECS)
   O'Brien JF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077345
   Pan XY, 2011, MM&SEC 11: PROCEEDINGS OF THE 2011 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P15
   Park J, 2018, LECT NOTES COMPUT SC, V11209, P656, DOI 10.1007/978-3-030-01228-1_39
   PAWLAK Z, 1984, J CHEM SOC FARAD T 1, V80, P1757, DOI 10.1039/f19848001757
   Peng B, 2017, IEEE T INF FOREN SEC, V12, P479, DOI 10.1109/TIFS.2016.2623589
   Pine J, 2001, INT WORK VERY LOW BI, P197
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Qureshi MA, 2014, 2014 11TH INTERNATIONAL MULTI-CONFERENCE ON SYSTEMS, SIGNALS & DEVICES (SSD), DOI 10.1109/SSD.2014.6808907
   Raja, 2021, IJERTPROC, V9, P418
   Rani A, 2021, MULTIMED TOOLS APPL, V80, P23877, DOI 10.1007/s11042-021-10810-6
   Rani A, 2017, COMM COM INF SC, V721, P140, DOI 10.1007/978-981-10-5427-3_15
   Rao Y, 2016, IEEE INT WORKS INFOR
   Reddy V., 2021, EUROPEAN J MOL CLIN, V8, P1485
   Rohde LE, 2005, INT J CARDIOL, V102, P71, DOI 10.1016/j.ijcard.2004.04.006
   Roy A, 2017, IEEE COMPUT SOC CONF, P1848, DOI 10.1109/CVPRW.2017.231
   Saber A.H., 2020, Advances in Science, Technology and Engineering Systems Journal, V5, P361
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Sharma Shikhar, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P51, DOI 10.1007/978-981-10-7895-8_5
   Sharma S, 2017, 2017 IEEE 7TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE IEEE CCWC-2017
   Singh MsN, 2016, P 31 NATL CONVENTION
   Sri C.G., 2021, 2021 INT C INT TECHN, P1, DOI [10.1109/CONIT51480.2021.9498357, DOI 10.1109/CONIT51480.2021.9498357]
   Stojkovic A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143215
   Sun JY, 2018, SIGNAL PROCESS-IMAGE, V63, P149, DOI 10.1016/j.image.2018.02.001
   Swapna P, 2010, EL COMP ENG CCECE 20, P1, DOI 10.1109/CCECE.2010.5575238
   Tang HS, 2018, J VIS COMMUN IMAGE R, V51, P162, DOI 10.1016/j.jvcir.2018.01.011
   Thakur A, 2018, MULTIMED TOOLS APPL, V77, P26033, DOI 10.1007/s11042-018-5836-5
   Tian-Tsong Ng, 2005, 13th Annual ACM International Conference on Multimedia, P239
   Tuama A, 2016, IEEE INT WORKS INFOR
   Verma V, 2018, SIGNAL PROCESS-IMAGE, V67, P22, DOI 10.1016/j.image.2018.04.014
   Wang XY, 2021, IETE TECH REV, V38, P149, DOI 10.1080/02564602.2020.1782274
   Wu L., 2011, COMPUTER VISION MULT, V1, P197, DOI DOI 10.4018/978-1-60960-024-2.CH012
   Wu L, 2012, MACH VISION APPL, V23, P363, DOI 10.1007/s00138-010-0296-6
   Wu Y, 2018, LECT NOTES COMPUT SC, V11210, P170, DOI 10.1007/978-3-030-01231-1_11
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Xu BC, 2016, NEUROCOMPUTING, V207, P131, DOI 10.1016/j.neucom.2016.05.012
   Xu J, 2009, 2009 WRI INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND MOBILE COMPUTING: CMC 2009, VOL 3, P626, DOI 10.1109/CMC.2009.369
   Yang PP, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23101318
   Yarlagadda Sri Kalyan, 2018, P ELECT IMAGING EI, DOI DOI 10.2352/ISSN.2470-1173.2018.07.MWSF-214
   Zhang RS, 2020, J COMPUT SCI TECH-CH, V35, P592, DOI 10.1007/s11390-020-0216-9
   Zhang XQ, 2018, IEEE ACCESS, V6, P70025, DOI 10.1109/ACCESS.2018.2879844
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhuo L, 2018, ASIAPAC SIGN INFO PR, P733, DOI 10.23919/APSIPA.2018.8659761
NR 120
TC 4
Z9 4
U1 5
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18117
EP 18150
DI 10.1007/s11042-022-13808-w
EA OCT 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000862543700001
PM 36213342
OA Green Published
DA 2024-07-18
ER

PT J
AU Pibre, L
   Madrigal, F
   Equoy, C
   Lerasle, F
   Pellegrini, T
   Pinquier, J
   Ferrané, I
AF Pibre, Lionel
   Madrigal, Francisco
   Equoy, Cyrille
   Lerasle, Frederic
   Pellegrini, Thomas
   Pinquier, Julien
   Ferrane, Isabelle
TI Audio-video fusion strategies for active speaker detection in meetings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active speaker detection; Multimodal fusion; Deep learning; Audio
   processing; Video processing; Speech analysis
ID SPEECH; DIARIZATION; AREA
AB Meetings are a common activity in professional contexts, and it remains challenging to endow vocal assistants with advanced functionalities to facilitate meeting management. In this context, a task like active speaker detection can provide useful insights to model interaction between meeting participants. Detection of the active speaker can be performed using only video based on the movements of the participants of a meeting. Depending on the assistant design and each participant position regarding the device, active speaker detection can benefit from information coming from visual and audio modalities. Motivated by our application context related to advanced meeting assistant, we want to combine audio and visual information to achieve the best possible performance. In this paper, we propose two different types of fusion (naive fusion and attention-based fusion) for the detection of the active speaker, combining two visual modalities and an audio modality through neural networks. In addition, the audio modality is mainly processed using neural networks. For comparison purpose, classical unsupervised approaches for audio feature extraction are also used. We expect visual data centered on the face of each participant to be very appropriate for detecting voice activity, based on the detection of lip and facial gestures. Thus, our baseline system uses visual data (video) and we chose a 3D Convolutional Neural Network (CNN) architecture, which is effective for simultaneously encoding appearance and movement. To improve this system, we supplemented the visual information by processing the audio stream with a CNN or an unsupervised speaker diarization system. We have further improved this system by adding visual modality information using motion through optical flow. We evaluated our proposal with a public and state-of-the-art benchmark: the AMI corpus. We analysed the contribution of each system to the merger carried out in order to determine if a given participant is currently speaking. We also discussed the results we obtained. Besides, we have shown that, for our application context, adding motion information greatly improves performance. Finally, we have shown that attention-based fusion improves performance while reducing the standard deviation.
C1 [Pibre, Lionel; Pellegrini, Thomas; Pinquier, Julien; Ferrane, Isabelle] Univ Toulouse, IRIT, CNRS, INP Toulouse,UT3, Toulouse, France.
   [Madrigal, Francisco; Equoy, Cyrille; Lerasle, Frederic] UT3, LAAS CNRS, Toulouse, France.
C3 Universite de Toulouse; Universite Toulouse III - Paul Sabatier;
   Universite Federale Toulouse Midi-Pyrenees (ComUE); Institut National
   Polytechnique de Toulouse; Centre National de la Recherche Scientifique
   (CNRS); Centre National de la Recherche Scientifique (CNRS); Universite
   de Toulouse; Universite Toulouse III - Paul Sabatier
RP Pibre, L (corresponding author), Univ Toulouse, IRIT, CNRS, INP Toulouse,UT3, Toulouse, France.
EM lionel.pibre@gmail.com
FU LinTO project (2018-2021) - Bpi France, as part of the French project
   "PIA3: Programme d'Investissements d'Avenir 3"
   [P169201-2658717//DOS0069247]
FX This work was supported by the LinTO project (2018-2021)
   P169201-2658717//DOS0069247, funded by Bpi France, as part of the French
   project "PIA3: Programme d'Investissements d'Avenir 3".
CR Afouras T, 2022, IEEE T PATTERN ANAL, V44, P8717, DOI 10.1109/TPAMI.2018.2889052
   Miro XA, 2012, IEEE T AUDIO SPEECH, V20, P356, DOI 10.1109/TASL.2011.2125954
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bonastre JF, 2011, P INTERSPEECH, P13
   Borghi G, 2017, PROC CVPR IEEE, P5494, DOI 10.1109/CVPR.2017.583
   Bost X, 2015, INT CONF ACOUST SPEE, P4799, DOI 10.1109/ICASSP.2015.7178882
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Carletta J, 2007, LANG RESOUR EVAL, V41, P181, DOI 10.1007/s10579-007-9040-x
   Chakravarty P, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P312, DOI 10.1145/2993148.2993172
   Cho K., 2014, ARXIV14061078
   Chung JS, 2019, INTERSPEECH, P371, DOI 10.21437/Interspeech.2019-3116
   Das A, 2017, INT J SCI RES COMPUT, V2
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Dubey H, 2019, INT CONF ACOUST SPEE, P6296, DOI 10.1109/ICASSP.2019.8683023
   El Khoury E, 2014, MULTIMED TOOLS APPL, V68, P747, DOI 10.1007/s11042-012-1080-6
   Everingham M., 2006, P BRIT MACH VIS C, P899, DOI [DOI 10.5244/C.20.92, 10.5244/C.20.92]
   Haider F, 2016, IEEE GLOB CONF SIG, P1207, DOI 10.1109/GlobalSIP.2016.7906033
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He WP, 2018, IEEE INT CONF ROBOT, P74
   Hong XP, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P321
   Hrúz M, 2017, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2017.7953097
   Kingma D. P., 2014, arXiv
   Korshunov P., 2019, P INT C MACH LEARN I
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le N, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P202, DOI 10.1145/2964284.2967211
   Li S., 2020, AAAI
   Madrigal F, 2021, INT C PATT RECOG, P2536, DOI 10.1109/ICPR48806.2021.9412681
   Nagrani A, 2020, COMPUT SPEECH LANG, V60, DOI 10.1016/j.csl.2019.101027
   Patino J, 2018, INTERSPEECH, P2813, DOI 10.21437/Interspeech.2018-2172
   Petridis S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6219, DOI 10.1109/ICASSP.2018.8461596
   Ren J, 2016, AAAI CONF ARTIF INTE, P3581
   Roth J, 2019, IEEE INT CONF COMP V, P3718, DOI 10.1109/ICCVW.2019.00460
   Sarkar A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5229, DOI 10.1109/ICASSP.2018.8462375
   Stefanov K, 2017, INT WORKSHOP GROUNDI, DOI [10.21437/GLU.2017-10, DOI 10.21437/GLU.2017-10]
   Tao F, 2019, SPEECH COMMUN, V113, P25, DOI 10.1016/j.specom.2019.07.003
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Vestman V, 2018, SPEECH COMMUN, V99, P62, DOI 10.1016/j.specom.2018.02.009
   Wang Q, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5239, DOI 10.1109/ICASSP.2018.8462628
   Wu JD, 2011, EXPERT SYST APPL, V38, P6112, DOI 10.1016/j.eswa.2010.11.013
   Xie WD, 2019, INT CONF ACOUST SPEE, P5791, DOI 10.1109/ICASSP.2019.8683120
   Yasir Muhammad, 2019, Journal of Physics: Conference Series, V1230, DOI 10.1088/1742-6596/1230/1/012081
   Zhong YJ, 2019, LECT NOTES COMPUT SC, V11362, P35, DOI 10.1007/978-3-030-20890-5_3
   Zhou ZH, 2014, IMAGE VISION COMPUT, V32, P590, DOI 10.1016/j.imavis.2014.06.004
NR 44
TC 1
Z9 1
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13667
EP 13688
DI 10.1007/s11042-022-13746-7
EA SEP 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000861190800003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mughaid, A
   AlZu'bi, S
   Alnajjar, A
   AbuElsoud, E
   El Salhi, S
   Igried, B
   Abualigah, L
AF Mughaid, Ala
   AlZu'bi, Shadi
   Alnajjar, Asma
   AbuElsoud, Esraa
   El Salhi, Subhieh
   Igried, Bashar
   Abualigah, Laith
TI Improved dropping attacks detecting system in 5g networks using machine
   learning and deep learning approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cyber security; 5G networks; Dropping attack; Simulation; Machine
   learning; Attack detection
AB Non Orthogonal Multiple Access (NOMA) successfully drew attention to the deployment of 5th Generation (5G) wireless communication systems, and it is now considered a significant technology in 5G communications. The primary enhancement in 5G is the speed, which may be 100 times faster than 4G. Due to the rising number of internal or external attacks on the Network, wireless intrusion detection systems are a vital aspect of any system connected to the Internet, and 5G will demand considerable improvements in data rate and security. In this paper, we have built a simulator for NOMA and applied a dropping attack to extract a dataset from the simulation model. The accuracy for detecting dropping attacks using the extracted data after applying ML algorithms was 95.7% for LR. Furthermore, this work suggests a methodology for wireless cyberattack detection in 5G networks based on applying several ML and DL techniques such as Decision Trees, KNN, Multi-class Decision Jungle, Multi-class Decision Forest, and Multi-class Neural Network. The proposed work is implemented and tested using a comprehensive Wi-Fi network benchmark dataset. The conducted experiments resulted in an outstanding performance with an accuracy of 99% for the KNN algorithm and 93% for DF and Neural Network.
C1 [Mughaid, Ala; Alnajjar, Asma; AbuElsoud, Esraa; El Salhi, Subhieh; Igried, Bashar] Hashemite Univ, Fac Prince Al Hussien Bin Abdullah IT, Dept Informat Technol, POB 330127, Zarqa 13133, Jordan.
   [AlZu'bi, Shadi] Al Zaytoonah Univ Jordan, Fac Sci & IT, Amman, Jordan.
   [Abualigah, Laith] Amman Arab Univ, Fac Comp Sci & Informat, Amman 11953, Jordan.
   [Abualigah, Laith] Middle East Univ, Fac Informat Technol, Amman 11831, Jordan.
   [Abualigah, Laith] Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
   [Abualigah, Laith] Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.
C3 Hashemite University; Al-Zaytoonah University of Jordan; Middle East
   University; Universiti Sains Malaysia; Al-Ahliyya Amman University
RP Abualigah, L (corresponding author), Amman Arab Univ, Fac Comp Sci & Informat, Amman 11953, Jordan.; Abualigah, L (corresponding author), Middle East Univ, Fac Informat Technol, Amman 11831, Jordan.; Abualigah, L (corresponding author), Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.; Abualigah, L (corresponding author), Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.
EM ala.mughaid@hu.edu.jo; smalzubi@zuj.edu.jo; 2070595@std.hu.edu.jo;
   2070606@std.hu.edu.jo; subhieh@hu.edu.jo; bashar.igried@hu.edu.jo;
   Aligah.2020@gmail.com
RI Abualigah, Laith/ABC-9695-2020; El-Salhi, Subhieh/KHT-3948-2024
OI Abualigah, Laith/0000-0002-2203-4549; El-Salhi,
   Subhieh/0000-0002-9700-4862; Mughaid, Ala/0000-0002-1298-6933; Igried,
   Bashar/0000-0001-6255-236X; Abu Elsoud, Esraa/0009-0000-0796-8522
CR Abusukhon A, 2020, 2020 SEVENTH INTERNATIONAL CONFERENCE ON SOFTWARE DEFINED SYSTEMS (SDS), P235, DOI 10.1109/SDS49854.2020.9143891
   Ahmad Ijaz, 2018, IEEE Communications Standards Magazine, V2, P36, DOI 10.1109/MCOMSTD.2018.1700063
   Ahmad R, 2021, INTERNET THINGS-NETH, V14, DOI 10.1016/j.iot.2021.100365
   Akbar A, 2021, COMPUT NETW, V190, DOI 10.1016/j.comnet.2021.107950
   Al Ridhawi I, 2021, IEEE T INTELL TRANSP, V22, P5190, DOI 10.1109/TITS.2021.3053095
   Al Shinwan M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22010349
   Al-Falahy N, 2017, IT PROF, V19, P12, DOI 10.1109/MITP.2017.9
   Al-Mnayyis A., 2020, INT J EL COMP ENG SY, V10-4, P4101, DOI DOI 10.11591/IJECE.V10I4.PP4101-4108
   Al-Obiedollah H, 2022, SIMUL MODEL PRACT TH, V116, DOI 10.1016/j.simpat.2021.102452
   Al-Zu'bi S, 2021, MULTIMED TOOLS APPL, V80, P16887, DOI 10.1007/s11042-020-09160-6
   Alkhatib AAA, 2022, IET SMART CITIES, V4, P143, DOI 10.1049/smc2.12032
   AlZu'bi S, 2019, MULTIMED TOOLS APPL, V78, P24223, DOI 10.1007/s11042-018-7003-4
   Alzubi S, 2020, INT CONF INFORM COMM, P191, DOI 10.1109/ICICS49469.2020.239519
   Aminanto ME, 2017, 2017 INTERNATIONAL WORKSHOP ON BIG DATA AND INFORMATION SECURITY (IWBIS 2017), P99, DOI 10.1109/IWBIS.2017.8275109
   Aminanto ME, 2018, IEEE T INF FOREN SEC, V13, P621, DOI 10.1109/TIFS.2017.2762828
   [Anonymous], 2006, P INT C INTELLIGENT
   Aqel D, 2022, CLUSTER COMPUT, V25, P2007, DOI 10.1007/s10586-021-03397-y
   Arachchillage USSS, 2018, VEH TECHNOL CONFE, DOI 10.1109/VTCSpring.2018.8417843
   Arfaoul G, 2018, IEEE ACCESS, V6, P22466, DOI 10.1109/ACCESS.2018.2827419
   Bengag A, 2019, 2019 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING IN DATA SCIENCES (ICDS 2019), DOI 10.1109/icds47004.2019.8942268
   Bounouni M, 2022, WIRELESS PERS COMMUN, V123, P3291, DOI 10.1007/s11277-021-09289-z
   Dawoud A, 2018, 2018 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND DATA ENGINEERING (ICMLDE 2018), P149, DOI 10.1109/iCMLDE.2018.00035
   Fang H, 2019, IEEE WIREL COMMUN, V26, P55, DOI 10.1109/MWC.001.1900054
   Maimó LF, 2018, IEEE ACCESS, V6, P7700, DOI 10.1109/ACCESS.2018.2803446
   Forland MK, 2019, IEEE GLOBE WORK, DOI 10.1109/gcwkshps45667.2019.9024497
   Hnaif A, 2021, INT ARAB J INF TECHN, V18, P77, DOI 10.34028/iajit/18/1/9
   Intelligence NM., 2021, EVOL COMPUT, V3, P9
   Khan R, 2020, IEEE COMMUN SURV TUT, V22, P196, DOI 10.1109/COMST.2019.2933899
   Koh PW, 2022, MACH LEARN, V111, P1, DOI 10.1007/s10994-021-06119-y
   Kumar A, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103352
   Lafi M, 2021, CMES-COMP MODEL ENG, V127, P99, DOI 10.32604/cmes.2021.013026
   Lam J., 2020, arXiv
   Malekzadeh M., 2011, International Journal of Network Security, V3, P13
   Malik A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22051897
   Marashdeh Zain, 2021, 2021 International Conference on Information Technology (ICIT), P957, DOI 10.1109/ICIT52682.2021.9491117
   Mughaid Ala, 2021, 2021 International Conference on Information Technology (ICIT), P691, DOI 10.1109/ICIT52682.2021.9491709
   Mughaid A, 2022, SOFT COMPUT, V26, P5577, DOI 10.1007/s00500-022-07080-1
   Mughaid Ala., 2022, Cluster Computing, P1
   Muro Barbe M, 2020, THESIS U POLITECNICA
   Obeidat Ibrahim, 2019, SECURE ENCRYPTED PRO
   Otair M, 2022, WIREL NETW, V28, P721, DOI 10.1007/s11276-021-02866-x
   Oyelade ON, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09905-3
   Pathan F., 2019, INT RES J ENG TECHNO, V6, P2973
   Ran J, 2019, IEEE VTS VEH TECHNOL, DOI 10.1109/vtcspring.2019.8746576
   Safaldin M, 2021, J AMB INTEL HUM COMP, V12, P1559, DOI 10.1007/s12652-020-02228-z
   Samarati P, 2021, VLDB J, P1
   Thanthrige USKPM, 2016, CAN CON EL COMP EN
   Vaca F.D., 2018, NCA 2018 2018 IEEE 1, DOI DOI 10.1109/NCA.2018.8548315
   Wang S., 2018, INT WIR INT C SPRING, P95
   Zhang SL, 2019, COMPUT NETW, V162, DOI 10.1016/j.comnet.2019.106871
NR 50
TC 16
Z9 16
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13973
EP 13995
DI 10.1007/s11042-022-13914-9
EA SEP 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000860416900009
DA 2024-07-18
ER

PT J
AU Adem, K
   Ozguven, MM
   Altas, Z
AF Adem, Kemal
   Ozguven, Mehmet Metin
   Altas, Ziya
TI A sugar beet leaf disease classification method based on image
   processing and deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Leaf spot disease; Sugar Beet; Faster RCNN; SSD; VGG16; Yolov4
ID IDENTIFICATION; SPOT
AB Leaf spot disease, which causes 10 - 50% loss in sugar beet yield, causes great damage on the leaves. This disease physiologically appears as individual circular spots on the sugar beet leaves and over time spreads to the entire leaf, resulting in complete death of the leaf. Therefore, in our study, Faster R-CNN, SSD, VGG16, Yolov4 deep learning models were used directly, and Yolov4 deep learning model with image processing was used in a hybrid way for automatic determination of leaf spot disease on sugar beet and classification of severity. The proposed hybrid method for the diagnosis of diseases and identifying the severity were trained and tested using 1040 images, and the classification accuracy rate of the most successful method was found to be 96.47%. The proposed hybrid approach showed that the combined use of image processing and deep learning models yield more successful results than the analysis made using only deep learning models. In this way, both the time spent for the diagnosis of leaf spot disease on sugar beet will be reduced and human error will be eliminated, and the relevant pesticides will be sprayed to the plant at the right time.
C1 [Adem, Kemal] Sivas Univ Sci & Technol, Dept Comp Engn, Sivas, Turkey.
   [Ozguven, Mehmet Metin; Altas, Ziya] Tokat Gaziosmanpasa Univ, Dept Biosyst Engn, Tokat, Turkey.
C3 Sivas University of Science & Technology; Gaziosmanpasa University
RP Adem, K (corresponding author), Sivas Univ Sci & Technol, Dept Comp Engn, Sivas, Turkey.
EM kemaladem@sivas.edu.tr; metin.ozguven@gop.edu.tr;
   kayseri_ziya@hotmail.com
RI Ozguven, Mehmet Metin/Q-1353-2016
OI Ozguven, Mehmet Metin/0000-0002-6421-4804; ALTAS,
   Ziya/0000-0001-9900-0606; Adem, Kemal/0000-0002-3752-7354
CR Abade A, 2021, COMPUT ELECTRON AGR, V185, DOI 10.1016/j.compag.2021.106125
   Abbas A, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106279
   Adem K, 2019, TURK J ELECTR ENG CO, V27, P4220, DOI 10.3906/elk-1903-112
   Agarwal M, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100407
   Altas Z., 2018, Curr. Investig. Agric. Curr. Res, V5, P621, DOI [DOI 10.32474/CIACR.2018.05.000214, 10.32474/CIACR.2018.05.000214]
   Ampatzidis Y, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9061010
   Barbedo JGA, 2016, BIOSYST ENG, V144, P52, DOI 10.1016/j.biosystemseng.2016.01.017
   Asraf Amanullah, 2020, SN Comput Sci, V1, P363, DOI 10.1007/s42979-020-00383-w
   Avelino J, 2015, FOOD SECUR, V7, P303, DOI 10.1007/s12571-015-0446-9
   Bai XB, 2017, COMPUT ELECTRON AGR, V136, P157, DOI 10.1016/j.compag.2017.03.004
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Bock CH, 2010, CRIT REV PLANT SCI, V29, P59, DOI 10.1080/07352681003617285
   Camargo A, 2009, BIOSYST ENG, V102, P9, DOI 10.1016/j.biosystemseng.2008.09.030
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Cruz A, 2019, COMPUT ELECTRON AGR, V157, P63, DOI 10.1016/j.compag.2018.12.028
   Cruz AC, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01741
   Darwish A, 2020, SWARM EVOL COMPUT, V52, DOI 10.1016/j.swevo.2019.100616
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gavhale KR, 2014, IOSR J COMPUT ENG IO, V16, P10, DOI DOI 10.9790/0661-16151016
   Gayathri S., 2020, 2020 International Conference on Electronics and Sustainable Communication Systems (ICESC). Proceedings, P398, DOI 10.1109/ICESC48915.2020.9155850
   Ghoury Shekofa, 2019, INT C ADV TECHN COMP
   Gopalakrishnan K, 2017, CONSTR BUILD MATER, V157, P322, DOI 10.1016/j.conbuildmat.2017.09.110
   Hillnhütter C, 2008, GESUNDE PFLANZ, V60, P143, DOI 10.1007/s10343-008-0196-0
   Hu GS, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2021.107023
   Huang HJ, 2019, IEEE T VEH TECHNOL, V68, P3027, DOI 10.1109/TVT.2019.2893928
   Hyun Ah Song, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8226, P466, DOI 10.1007/978-3-642-42054-2_58
   Islam Ayon S., 2019, Int J Inf Eng Electronic Business, V11, P21, DOI DOI 10.5815/IJIEEB.2019.02.03
   Islam MM, 2021, IEEE ACCESS, V9, P30551, DOI 10.1109/ACCESS.2021.3058537
   Islam Md Milon, 2020, SN Comput Sci, V1, P274, DOI 10.1007/s42979-020-00300-1
   Jiang HZ, 2017, IEEE INT CONF AUTOMA, P650, DOI [10.1109/FG.2017.82, 10.1109/MWSYM.2017.8058653]
   Khan MFR, 2005, CROP PROT, V24, P79, DOI 10.1016/j.cropro.2004.06.010
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Krishnamoorthy N, 2021, ENVIRON RES, V198, DOI 10.1016/j.envres.2021.111275
   Kundu N, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165386
   Li Z., 2017, Meta-sgd: Learning to learn quickly for few-shot learning
   Liu C, 2021, COMPUT ELECTRON AGR, V189, DOI 10.1016/j.compag.2021.106378
   Liu F, 2019, IEEE ACCESS, V7, P119209, DOI 10.1109/ACCESS.2019.2935222
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Marcal ARS, 2019, COMPUT ELECTRON AGR, V162, P380, DOI 10.1016/j.compag.2019.04.031
   Mutka AM, 2015, FRONT PLANT SCI, V5, DOI 10.3389/fpls.2014.00734
   Nazki H, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105117
   Ning CC, 2017, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2017.8026312
   Ozguven, 2019, INT ERCIYES AGR ANIM
   Ozguven, 2018, HASSAS TARIM
   Ozguven M., 2018, CURR INVESTIG AGR CU, V5, P573, DOI [DOI 10.32474/CIACR.2018.05.000201, 10.32474/CIACR.2018.05.000201]
   Ozguven MM, 2022, J PLANT PATHOL, V104, P1397, DOI 10.1007/s42161-022-01178-z
   Ozguven MM, 2020, FRESEN ENVIRON BULL, V29, P7081
   Ozguven MM, 2019, PHYSICA A, V535, DOI 10.1016/j.physa.2019.122537
   Ozguven MM, 2020, BILDIRILER KITABI 1, P301
   Pal S., 2016, TRANSFER LEARNING FI
   Qimei Wang, 2019, 2019 10th International Conference on Information Technology in Medicine and Education (ITME). Proceedings, P772, DOI 10.1109/ITME.2019.00176
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rossi V., 1995, Phytopathologia Mediterranea, V34, P149
   Rumpf T, 2010, COMPUT ELECTRON AGR, V74, P91, DOI 10.1016/j.compag.2010.06.009
   Savary S., 2014, Plant Health Instr, DOI 10.1094/PHI-A-2014-0314-01
   Sharma Parul, 2020, Information Processing in Agriculture, V7, P566, DOI 10.1016/j.inpa.2019.11.001
   Shin J, 2021, COMPUT ELECTRON AGR, V183, DOI 10.1016/j.compag.2021.106042
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soylu S, 2012, BITKISEL URETIM CIFT
   Sujatha R, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103615
   Temniranrat P, 2021, COMPUT ELECTRON AGR, V185, DOI 10.1016/j.compag.2021.106156
   Tetila EC, 2020, COMPUT ELECTRON AGR, V179, DOI [10.1016/j.compeg.2020.105836, 10.1016/j.compag.2020.105836]
   Vaidya B., 2019, Smart Techniques for a Smarter Planet: Towards Smarter Algorithms, Studies in Fuzziness and Soft Computing, P53, DOI [DOI 10.1007/978-3-030-03131-2_4, DOI 10.1007/978-3-030]
   Wang CS, 2021, COMPUT ELECTRON AGR, V189, DOI 10.1016/j.compag.2021.106373
   Whitney ED, 1991, COMPENDIUM BEET DIS, P8
   Wu DH, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105742
   Yadav S, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2021.101247
   Yu S, 2017, IEEE ENG MED BIO, P1744, DOI 10.1109/EMBC.2017.8037180
   Zhang KK, 2021, COMPUT ELECTRON AGR, V183, DOI 10.1016/j.compag.2021.106064
   Zhang SW, 2019, COMPUT ELECTRON AGR, V162, P422, DOI 10.1016/j.compag.2019.03.012
   Zhao C, 2015, PATTERN RECOGN, V48, P3203, DOI 10.1016/j.patcog.2015.04.004
NR 73
TC 12
Z9 12
U1 6
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12577
EP 12594
DI 10.1007/s11042-022-13925-6
EA SEP 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000857685800007
DA 2024-07-18
ER

PT J
AU Ma, GY
   Yue, XF
   Gao, XL
   Liu, FQX
AF Ma, Guoyuan
   Yue, Xiaofeng
   Gao, Xueliang
   Liu, Fuqiuxuan
TI Application of an improved sparrow search algorithm in BP network
   classification of strip steel surface defect images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; BP neural network; Sparrow search algorithm;
   Adaptive weight; Levy flight; T distribution
ID BAT ALGORITHM; INTELLIGENCE
AB In this paper, the BP neural network optimized by an improved sparrow search algorithm is proposed (WLT-SSA-BP), which performs excellently in the classification task of strip steel defect images. In the current work, an adaptive weight is introduced into the WLT-SSA algorithm, and the weight is affected by the number of population iterations and the size of the fitness value, which enhances the global search ability of the algorithm; A Levy flight strategy is introduced into WLT-SSA, which helps the algorithm jump out of the local optimal solution through a short-distance local search and occasional longer-distance walking; At the same time, the population t distribution strategy is introduced into the population initialization, which effectively prevents the aggregation of the population. Finally, the proposed WLT-SSA and BP neural network are modeled. The experimental results show that the accuracy rate of WLT-SSA-BP in classifying defect images can reach 96.62%, which is comparable to some other typical heuristic algorithm-optimized BP networks. Its accuracy, precision, recall, specificity, and F1 score were increased by 0.5%-4.66%, 2.62%-8.1%, 1.71%-7.77%, 0.72%-1.33%, 1.59%-8.73%, respectively.
C1 [Ma, Guoyuan; Yue, Xiaofeng; Gao, Xueliang; Liu, Fuqiuxuan] Changchun Univ Technol, Changchun, Jilin, Peoples R China.
C3 Changchun University of Technology
RP Ma, GY (corresponding author), Changchun Univ Technol, Changchun, Jilin, Peoples R China.
EM magy_ccut@126.com
RI ma, guoyuan/CAH-3286-2022; Zhao, Hang/KCL-7278-2024; Wang,
   Jinyang/JXN-8650-2024; li, liu/JXN-7328-2024
OI ma, guoyuan/0000-0001-8949-9757; 
FU Jilin Province Development and Reform Commession [2020C018-3]; Education
   Department of Jilin Province [JJKH20200654KJ]
FX This work is supported by the Jilin Province Development and Reform
   Commession (2020C018-3), The Education Department of Jilin
   Province(JJKH20200654KJ).
CR Barukcic I, 2021, MATEC WEB CONF, V336, DOI 10.1051/matecconf/202133609032
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Chanuri C., 2021, APPL SCI, V11, DOI 10.3390/app11030992
   Cheng PP, 2020, SOFT COMPUT, V24, P13219, DOI 10.1007/s00500-020-04735-9
   Deng B, 2019, NANOSCALE RES LETT, V14, DOI 10.1186/s11671-019-3118-4
   Dhal KG, 2019, EVOL SYST-GER, V10, P129, DOI 10.1007/s12530-018-9216-1
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Gao L, 2021, NETWORK SECURITY SIT
   Han JW, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105733
   Health and Medicine-Orthopedics, 2020, ENERGY WEEKLY NEWS
   Hjouji A, 2021, J SUPERCOMPUT, V77, P5637, DOI 10.1007/s11227-020-03450-4
   Hui B, 2021, TSINGHUA SCI TECHNOL, V26, P199, DOI 10.26599/TST.2019.9010058
   Jiang Y., 2020, J PHYS C SER, V1621, P012054, DOI 10.1088/1742-6596/1621/1/012054
   Kato T, 2019, WEAR, V438, DOI 10.1016/j.wear.2019.203038
   Kesav OH, 2021, INT J SPEECH TECHNOL, V24, P251, DOI 10.1007/s10772-020-09774-z
   Li N, 2020, MEASUREMENT, V150, DOI 10.1016/j.measurement.2019.107075
   Li Q, 2020, J SENSORS, V2020, DOI 10.1155/2020/8824091
   Lionel IWE, 2020, IEEE T NEURAL NETW L
   Malik K, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030492
   Mao HD, 2020, CMC-COMPUT MATER CON, V65, P511, DOI 10.32604/cmc.2020.09841
   Mathematics, 2020, J MATH-UK
   Molga Marcin., 2005, Test Functions for Optimization Needs
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Parsa A, 2012, INT J ORAL MAX IMPL, V27, P1438
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Saha SK, 2020, CONSTR BUILD MATER, V249, DOI 10.1016/j.conbuildmat.2020.118744
   SCHAFFER JD, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P51
   Sharma Meenakshi, 2020, International Journal of Mathematics in Operational Research, V17, P253, DOI 10.1504/IJMOR.2020.109699
   Simon L., 2021, CANCER IMAGING, V21, P21
   Song KC, 2013, APPL SURF SCI, V285, P858, DOI 10.1016/j.apsusc.2013.09.002
   Uaba B, 2021, ASSESSING CHANGE AMB
   Wei DS, 2020, REMOTE SENS LETT, V11, P127, DOI 10.1080/2150704X.2019.1692389
   Xue JK, 2020, SYST SCI CONTROL ENG, V8, P22, DOI 10.1080/21642583.2019.1708830
   Xue XY, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0413-z
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   YANG XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI [DOI 10.1504/IJBIC.2010.032124, 10.1504/IJBIC.2010.032124]
   Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82, DOI 10.1109/4235.771163
   Yin XZ, 2022, NEURAL COMPUT APPL, V34, P3365, DOI 10.1007/s00521-021-05712-5
   Yue XF, 2021, J INTELL FUZZY SYST, V41, P1509, DOI 10.3233/JIFS-210374
   Yue XF, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106157
   Zhang Y, 2019, MATER RES EXPRESS, V6, DOI 10.1088/2053-1591/ab4aed
   Zhang YG, 2021, STOCH ENV RES RISK A, V35, P1273, DOI 10.1007/s00477-020-01920-y
   Zhou GB, 2020, J MECH SCI TECHNOL, V34, P3445, DOI 10.1007/s12206-020-0737-8
   Zhu YL, 2021, INT J HYDROGEN ENERG, V46, P9541, DOI 10.1016/j.ijhydene.2020.12.107
NR 46
TC 2
Z9 2
U1 6
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14403
EP 14439
DI 10.1007/s11042-022-13757-4
EA SEP 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000857685800001
DA 2024-07-18
ER

PT J
AU Zhang, ZW
   Li, FF
   Zuo, XY
   Meng, Q
   Jin, SH
AF Zhang, Zhengwei
   Li, Fenfen
   Zuo, Xingyuan
   Meng, Qian
   Jin, Shenghua
TI Reversible image watermarking algorithm based on reverse histogram
   translation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Histogram translation; Embedding capacity; Image visual quality;
   Reversible image watermarking
AB Medical, military and other fields need high degrees of security and privacy for images. Aiming at the problems of low embedding rate and low visual quality of the traditional reversible image watermarking based on histogram translation, a new reversible watermarking algorithm based on reverse histogram translation is proposed to further improve the embedding capacity and visual quality. A reversible image watermarking algorithm based on reverse histogram translation is proposed. Firstly, the embedded watermark information is scrambled. Then, after embedding the watermark through histogram translation, the inverse histogram transform is used to embed the watermark information for the second time. In order to further improve the reversible watermark embedding capacity, the peak value and secondary peak value in the histogram can be used to embed the watermark by reverse histogram translation. The experimental result shows that compared with different carrier images and similar algorithms, this method has better visual effects and less distortion at the same embedding rate, and the extracted image does not have any pixel difference from the original image. In addition, using this method to embed watermark, the watermark embedding capacity is improved on the premise of ensuring a certain visual quality.
C1 [Zhang, Zhengwei; Li, Fenfen; Zuo, Xingyuan; Meng, Qian; Jin, Shenghua] Huaiyin Inst Technol, Fac Comp & Software Engn, Huaian 223003, Jiangsu, Peoples R China.
C3 Huaiyin Institute of Technology
RP Zhang, ZW (corresponding author), Huaiyin Inst Technol, Fac Comp & Software Engn, Huaian 223003, Jiangsu, Peoples R China.
EM zzw49010650@sina.com
FU National Statistical Science Research Project [2018LY12]
FX This work is supported by National Statistical Science Research Project
   (2018LY12).
CR Agoyi M, 2015, SIGNAL IMAGE VIDEO P, V9, P735, DOI 10.1007/s11760-014-0624-9
   Anil NK., 2014, INT J COMPUT APPL, V106, P12
   Du W, 2019, INT C IMAGE VIDEO PR, V1321, P1
   Fan GJ, 2021, INFORM SCIENCES, V581, P515, DOI 10.1016/j.ins.2021.09.019
   Fan HY, 2020, MULTIMED TOOLS APPL, V79, P5693, DOI 10.1007/s11042-019-08289-3
   He JH, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107647
   Hua G, 2020, IEEE SIGNAL PROC LET, V27, P236, DOI 10.1109/LSP.2020.2965331
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Iyer R, 2014, SADHANA-ACAD P ENG S, V39, P1357, DOI 10.1007/s12046-014-0288-8
   Jung KH, 2018, MULTIMED TOOLS APPL, V77, P7795, DOI 10.1007/s11042-017-5066-2
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kim S, 2019, IEEE T CIRC SYST VID, V29, P3236, DOI 10.1109/TCSVT.2018.2878932
   Kittawi N, 2022, MULTIMED TOOLS APPL, V81, P12441, DOI 10.1007/s11042-022-12364-7
   Lee CF, 2019, SOFT COMPUT, V23, P9719, DOI 10.1007/s00500-018-3537-7
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Lin SL., 2013, J INF HIDING MULTIME, V4, P19
   Liu L, 2016, MULTIMED TOOLS APPL, V75, P11311, DOI 10.1007/s11042-015-2855-3
   Liu ZL, 2019, MULTIMED TOOLS APPL, V78, P16311, DOI 10.1007/s11042-018-6958-5
   Malik Sunesh, 2019, International Journal of Information Technology, V11, P373, DOI 10.1007/s41870-018-0259-0
   Mandal PC, 2021, MULTIMED TOOLS APPL, V80, P3623, DOI 10.1007/s11042-020-09341-3
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Rajkumar R, 2019, CLUSTER COMPUT, V22, P12313, DOI 10.1007/s10586-017-1614-9
   Weng SW, 2015, MULTIMED TOOLS APPL, V74, P10657, DOI 10.1007/s11042-014-2197-6
   Xuan GR, 2019, J INF SECUR APPL, V45, P1, DOI 10.1016/j.jisa.2018.12.007
   Yang P., 2020, IEEE ACCESS, V8, P3210
   Yu X, 2018, MULTIMED TOOLS APPL, V77, P18085, DOI 10.1007/s11042-018-5794-y
   Zhang ZW, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199143
   Zhang ZW, 2018, ARAB J SCI ENG, V43, P979, DOI 10.1007/s13369-017-2898-z
   Zhang ZW, 2017, KSII T INTERNET INF, V11, P1761, DOI 10.3837/tiis.2017.03.028
   Zhang ZQ, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/3507203
   Zhang ZW., 2016, J INFORM HIDING MULT, V7, P530
   Zhou K, 2021, MULTIMED TOOLS APPL, V80, P1123, DOI 10.1007/s11042-020-09374-8
   Zhuang YJ, 2022, APPL INTELL, V52, P14406, DOI 10.1007/s10489-022-03211-1
   Zong TR, 2015, IEEE T CIRC SYST VID, V25, P717, DOI 10.1109/TCSVT.2014.2363743
NR 35
TC 2
Z9 2
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 11005
EP 11019
DI 10.1007/s11042-022-13770-7
EA SEP 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000854848100001
DA 2024-07-18
ER

PT J
AU Sahoo, RC
   Pradhan, SK
   Sahoo, BM
   Balabantaray, BK
AF Sahoo, Ramesh Chandra
   Pradhan, Sateesh Kumar
   Sahoo, Biswa Mohan
   Balabantaray, Bunil Kumar
TI Pattern recalling analysis of an auto-associative memory network using
   FFT and DWT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hopfield neural network; Hebbian; Pseudo-inverse; Storkey; FFT; DWT; FVC
   database; Fingerprint
ID FACE RECOGNITION; NEURAL-NETWORKS; FINGERPRINT; ARCHITECTURE
AB This study focused on recalling efficiency analysis of three different learning rules in Hopfield content addressable recurrent network for fingerprint image patterns. DWT and FFT feature extraction methods have been applied individually and combining one after another to gather the final feature vectors which are then normalized to trained into Hopfiled network by dividing the pattern into four non-overlapping equal sub-regions. To get the relevant features from each sub-region and to reduce the dimensionality of the pattern, DWT is applied first and then followed by FFT feature extraction methods. These feature vectors are normalized to pass into Hopfield network for training with three rules such as Hebbian, Pseudo-inverse and Storkey learning rules. Hamming distance method is used for recalling test pattern with the previously stored patterns. FVC2002 and FVC2004 fingerprint databases are used in simulation process. Performance of the network in terms of recalling efficiency is measured for originally stored patterns and several new patterns by introducing different noise percentages. Results achieved from various observations of this study demonstrated that recalling efficiency in case of DWT plus FFT is outperformed as compared to individual feature extraction techniques as well as work done in the literature. It has been observed that Storkey rule with combined features surpasses other two rules in terms of recalling efficiency. Recalling accuracy is almost 100% for 80, 160 and 240 patterns packing density network for both fingerprint databases used in this study with up to 30% of noise.
C1 [Sahoo, Ramesh Chandra] MRIIRS, Dept Comp Sci & Engn, FET, Faridabad, India.
   [Pradhan, Sateesh Kumar] Utkal Univ, Dept Comp Sci, Bhubaneswar, India.
   [Sahoo, Biswa Mohan] Manipal Univ Jaipur, Sch Comp & IT, Jaipur, Rajasthan, India.
   [Balabantaray, Bunil Kumar] Natl Inst Technol, Dept CSE, Shillong, Meghalaya, India.
C3 Manav Rachna International Institute of Research & Studies; Utkal
   University; Manipal University Jaipur; National Institute of Technology
   (NIT System); National Institute of Technology Meghalaya
RP Sahoo, RC (corresponding author), MRIIRS, Dept Comp Sci & Engn, FET, Faridabad, India.
EM biswamohans@gmail.com; rcsahoo.fet@mriu.edu.in; sateesh19601@gmail.com;
   bunil@nitm.ac.in
RI Balabantaray, Bunil/M-9711-2013; sahoo, ramesh/AAO-3518-2020
OI sahoo, ramesh/0000-0003-0296-8106; Sahoo, Biswa/0000-0002-8368-107X
CR Alam M., 2012, INT J SCI ENG RES, V3, P1360
   Algarni AD, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22121361
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Almajmaie L, 2019, COGN SYST RES, V58, P107, DOI 10.1016/j.cogsys.2019.05.004
   [Anonymous], 2014, 2014 INT C ADV COMM
   Awan N, 2021, IEEE ACCESS, V9, P26502, DOI 10.1109/ACCESS.2021.3056926
   Bashir A, 2018, SCI INFORM C, P581
   Belyaev M. A., 2020, IOP Conference Series: Materials Science and Engineering, V862, DOI 10.1088/1757-899X/862/5/052048
   Bhairannawar SS, 2018, CIRC SYST SIGNAL PR, V37, P342, DOI 10.1007/s00034-017-0555-0
   Bhowmik UK, 2009, 2009 INTERNATIONAL CONFERENCE ON ELECTRICAL COMMUNICATIONS AND COMPUTERS, P90, DOI 10.1109/CONIELECOMP.2009.57
   Dadgostar M, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P217, DOI 10.1109/ICAPR.2009.64
   Davey N, 2004, NEUROCOMPUTING, V62, P459, DOI 10.1016/j.neucom.2004.02.007
   Hemanth DJ, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1111-6
   HOPFIELD JJ, 1986, SCIENCE, V233, P625, DOI 10.1126/science.3755256
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Huang ZH, 2015, IMAGE VISION COMPUT, V37, P12, DOI 10.1016/j.imavis.2014.12.005
   Jain Anil K., 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563117
   Jiang XD, 2000, INT C PATT RECOG, P1038, DOI 10.1109/ICPR.2000.906252
   Kobayashi M, 2020, IEEE T NEUR NET LEAR, V31, P352, DOI 10.1109/TNNLS.2019.2899914
   KOHONEN T, 1973, IEEE T COMPUT, VC 22, P701, DOI 10.1109/TC.1973.5009138
   Morris RGM, 1999, BRAIN RES BULL, V50, P437, DOI 10.1016/S0361-9230(99)00182-3
   Neethu S, 2015, PROCEDIA COMPUT SCI, V46, P1561, DOI 10.1016/j.procs.2015.02.083
   Pandya B, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM2018), P86, DOI 10.1109/INFOMAN.2018.8392815
   PERSONNAZ L, 1986, PHYS REV A, V34, P4217, DOI 10.1103/PhysRevA.34.4217
   Pokhriyal Avinash, 2010, Journal of Theoretical and Applied Information Technology, V13, P131
   Rangaswamy Y, 2015, PROCEDIA COMPUT SCI, V54, P809, DOI 10.1016/j.procs.2015.06.095
   Rezaei Zahra, 2017, 2017 24th National and 2nd International Iranian Conference on Biomedical Engineering (ICBME), P330, DOI 10.1109/ICBME.2017.8430256
   Singh MP, 2013, ENG APPL ARTIF INTEL, V26, P2383, DOI 10.1016/j.engappai.2013.07.003
   Storkey A., 1997, Artificial Neural Networks - ICANN '97. 7th International Conference Proceedings, P451, DOI 10.1007/BFb0020196
   Sujatha BM., 2015, INT J IMAGE PROCESSI, V9, P283
   Varshney Sudeep, 2022, Materials Today: Proceedings, P3482, DOI 10.1016/j.matpr.2021.05.470
   Wei HL, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS ( ICAL 2009), VOLS 1-3, P197, DOI 10.1109/ICAL.2009.5262937
   Wen CM, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON FUTURE INFORMATION TECHNOLOGY AND MANAGEMENT ENGINEERING, FITME 2009, P226, DOI 10.1109/FITME.2009.62
   Xu C, 2009, THIRD INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTING, P827, DOI 10.1109/WGEC.2009.74
   Yuan CS, 2019, IEEE ACCESS, V7, P26953, DOI 10.1109/ACCESS.2019.2901235
   Zhang Qinghui, 2010, Proceedings of the 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P282, DOI 10.1109/ICCMS.2010.330
   Zhou Weina, 2009, Proceedings of the 2009 9th International Conference on Electronic Measurement & Instruments (ICEMI 2009), P3, DOI 10.1109/ICEMI.2009.5274401
NR 39
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9113
EP 9135
DI 10.1007/s11042-022-13778-z
EA SEP 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000854694900001
DA 2024-07-18
ER

PT J
AU Gupta, S
   Kumar, P
   Tekchandani, RK
AF Gupta, Swadha
   Kumar, Parteek
   Tekchandani, Raj Kumar
TI Facial emotion recognition based real-time learner engagement detection
   system in online learning context using deep learning models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expressions; Engagement detection; Emotion detection; Deep
   learning; Real-time engagement detection; Online learning; Online
   learner
ID EXPRESSION RECOGNITION
AB The dramatic impact of the COVID-19 pandemic has resulted in the closure of physical classrooms and teaching methods being shifted to the online medium.To make the online learning environment more interactive, just like traditional offline classrooms, it is essential to ensure the proper engagement of students during online learning sessions.This paper proposes a deep learning-based approach using facial emotions to detect the real-time engagement of online learners. This is done by analysing the students' facial expressions to classify their emotions throughout the online learning session. The facial emotion recognition information is used to calculate the engagement index (EI) to predict two engagement states "Engaged" and "Disengaged". Different deep learning models such as Inception-V3, VGG19 and ResNet-50 are evaluated and compared to get the best predictive classification model for real-time engagement detection. Varied benchmarked datasets such as FER-2013, CK+ and RAF-DB are used to gauge the overall performance and accuracy of the proposed system. Experimental results showed that the proposed system achieves an accuracy of 89.11%, 90.14% and 92.32% for Inception-V3, VGG19 and ResNet-50, respectively, on benchmarked datasets and our own created dataset. ResNet-50 outperforms all others with an accuracy of 92.3% for facial emotions classification in real-time learning scenarios.
C1 [Gupta, Swadha; Kumar, Parteek; Tekchandani, Raj Kumar] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Gupta, S (corresponding author), Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
EM sgupta_phd18@thapar.edu; parteek.bhatia@thapar.edu;
   rtekchandani@thapar.edu
OI Gupta, Swadha/0000-0001-6097-0533
CR Abbassi Nessrine, 2020, 20th International Conference on Sciences and Techniques of Automatic Control and Computer Engineering (STA 2020), P271, DOI 10.1109/STA50679.2020.9329355
   Abedi A, 2021, IMPROVING STATE OF T
   Adedoyin O. B., 2020, INTERACT LEARN ENVIR, P1, DOI [DOI 10.1080/10494820.2020.1813180, 10.1080/10494820.2020.1813180]
   Altuwairqi K, 2021, SIGNAL IMAGE VIDEO P, V15, P1387, DOI 10.1007/s11760-021-01869-7
   Aneja D, 2017, LECT NOTES COMPUT SC, V10112, P136, DOI 10.1007/978-3-319-54184-6_9
   [Anonymous], 2014, PROCEDIA IEEE COMPUT, DOI DOI 10.1109/CVPR.2014.233
   Bawa P, 2016, SAGE OPEN, V6, DOI 10.1177/2158244015621777
   Benitez-Quiroz CF, 2016, PROC CVPR IEEE, P5562, DOI 10.1109/CVPR.2016.600
   Botelho AF, 2017, LECT NOTES ARTIF INT, V10331, P40, DOI 10.1007/978-3-319-61425-0_4
   Chowdary MK, 2023, NEURAL COMPUT APPL, V35, P23311, DOI 10.1007/s00521-021-06012-8
   Dewan MAA, 2018, 2018 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI), P1895, DOI 10.1109/SmartWorld.2018.00318
   Diego-Mas JA, 2020, I-PERCEPTION, V11, DOI 10.1177/2041669520961123
   EKMAN P, 1979, ANNU REV PSYCHOL, V30, P527, DOI 10.1146/annurev.ps.30.020179.002523
   Eom SB, 2016, DECIS SCI-J INNOV ED, V14, P185, DOI 10.1111/dsji.12097
   Fish J, 2016, MINDFULNESS, V7, P1011, DOI 10.1007/s12671-016-0548-2
   Ghosh S, 2018, IEEE IMAGE PROC, P1967, DOI 10.1109/ICIP.2018.8451242
   Giannopoulos P., 2018, ADV HYBRIDIZATION IN, P1, DOI DOI 10.1007/978-3-319-66790-4_1
   Gupta Swadha, 2021, Emerging Technologies for Smart Cities. Select Proceedings of EGTET 2020. Lecture Notes in Electrical Engineering (LNEE 765), P139, DOI 10.1007/978-981-16-1550-4_15
   Gupta Shivam, 2018, 2018 2nd International Conference on Inventive Systems and Control (ICISC), P553, DOI 10.1109/ICISC.2018.8398861
   Hew KF, 2016, BRIT J EDUC TECHNOL, V47, P320, DOI 10.1111/bjet.12235
   Huang Q., 2016, ORTESOL Journal, V33, P14
   Hung JC, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105724
   Jmour N, 2021, INNOVATIVE AND INTELLIGENT TECHNOLOGY-BASED SERVICES FOR SMART ENVIRONMENTS-SMART SENSING AND ARTIFICIAL INTELLIGENCE, P134, DOI 10.1201/9781003181545-20
   Kim HR, 2018, IEEE T MULTIMEDIA, V20, P2980, DOI 10.1109/TMM.2018.2827782
   Kiuru N, 2020, LEARN INDIVID DIFFER, V80, DOI 10.1016/j.lindif.2020.101873
   KUNDU A, 2021, CORP GOV-OXFORD
   Lee J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1513, DOI 10.1109/ICASSP.2018.8461920
   Li B., 2021, International Journal of Cognitive Computing in Engineering, V2, P57
   Li Hai, 2020, ICCCV'20: 2020 the 3rd International Conference on Control and Computer Vision, P22, DOI 10.1145/3425577.3425582
   Li ML, 2022, J OPER RES SOC, V73, P261, DOI [10.1080/01605682.2020.1843974, 10.1080/01932691.2021.1915158]
   Li Q, 2021, J PHYS C SERIES, V1827
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Liao J, 2021, APPL INTELL, V51, P7933, DOI 10.1007/s10489-021-02309-2
   Long F, 2016, NEUROCOMPUTING, V173, P2049, DOI 10.1016/j.neucom.2015.09.049
   Manseras R, 2017, CLASS ENGAGEMENT ANA, P1052
   Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35
   Minaee S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093046
   Mishra Lokanath, 2020, Int J Educ Res Open, V1, P100012, DOI 10.1016/j.ijedro.2020.100012
   Mittal M, 2021, ENERGIES, V14, DOI 10.3390/en14113125
   Mittal M, 2019, IEEE INT CONF BIG DA, P4113, DOI 10.1109/BigData47090.2019.9006477
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Mukhopadhyay Moutan, 2020, ICIIT 2020: Proceedings of the 2020 5th International Conference on Intelligent Information Technology, P107, DOI 10.1145/3385209.3385231
   Murshed M, 2019, IEEE 17TH INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP / IEEE 17TH INT CONF ON PERVAS INTELLIGENCE AND COMP / IEEE 5TH INT CONF ON CLOUD AND BIG DATA COMP / IEEE 4TH CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/CBDCOM/CYBERSCITECH), P80, DOI 10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00028
   Nezami OM, 2020, LECT NOTES ARTIF INT, V11908, P273, DOI 10.1007/978-3-030-46133-1_17
   Patricia Aguilera-Hermida A, 2020, Int J Educ Res Open, V1, P100011, DOI 10.1016/j.ijedro.2020.100011
   Priya RV, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5610
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Riaz MN, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041087
   Rudovic O, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aao6760
   Sharma A, 2019, INT C ADV COMPUTING, P465, DOI DOI 10.1007/978-981
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Sugianto N., 2018, Deep residual learning for analyzing customer satisfaction using video surveillance
   Torres II, 2020, THESIS CHICAGO SCH P
   Turabzadeh S, 2018, TECHNOLOGIES, V6, DOI 10.3390/technologies6010017
   Vanneste P, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9030287
   Wu YH, 2021, INT C PATT RECOG, P3336, DOI 10.1109/ICPR48806.2021.9411983
   Xianwen Zheng, 2021, Artificial Intelligence in HCI. Second International Conference, AI-HCI 2021 Held as Part of the 23rd HCI International Conference, HCII 2021. Proceedings. Lecture Notes in Artificial Intelligence, Subseries of Lecture Notes in Computer Science (LNAI 12797), P541, DOI 10.1007/978-3-030-77772-2_36
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 60
TC 23
Z9 24
U1 5
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11365
EP 11394
DI 10.1007/s11042-022-13558-9
EA SEP 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000852127600002
PM 36105662
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Chen, LF
   Shi, Y
   Du, YX
AF Chen, LiFang
   Shi, Yu
   Du, YuanXin
TI Real-time monitoring system of cyanobacteria blooms using deep learning
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cyanobacteria bloom; EGAN; Real-time monitoring system; Video
   surveillance
ID LAKE
AB In recent years, a large number of cyanobacteria formed harmful blooms. The traditional method of preventing and controlling cyanobacteria blooms is to manually observe the video image to find the outbreak site of cyanobacteria, and manually prompt the salvage or chemical treatment according to the degree of cyanobacteria outbreak. Due to the traditional methods are difficult to early warning timely and accurately, we designed a real-time monitoring system of cyanobacteria blooms. The system can automatically identify cyanobacteria in the video image and calculate the coverage rate of cyanobacteria to realize the automatic warning of cyanobacteria bloom outbreak. First, we propose EGAN (Enhanced Generative Adversarial Networks) algorithm to improve the accuracy of cyanobacteria identification, the precision is 94.03%, the recall is93.65%. Second, we use the coverage rate of cyanobacteria to determine if (and when) early warning of cyanobacteria salvage. The proposed cyanobacterial video monitoring system not only helps Environmental Monitoring Center of Wuxi to provide early warning of the outbreak of cyanobacteria in real time, but also provides effective strategies for subsequent prevention and control by analyzing the cyanobacterial video data.
C1 [Chen, LiFang; Shi, Yu] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.
   [Chen, LiFang] Jiangsu Key Lab Media Design & Software Technol, Wuxi 214122, Jiangsu, Peoples R China.
   [Du, YuanXin] Environm Monitoring Ctr Wuxi, Wuxi 214121, Jiangsu, Peoples R China.
C3 Jiangnan University
RP Chen, LF (corresponding author), Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.; Chen, LF (corresponding author), Jiangsu Key Lab Media Design & Software Technol, Wuxi 214122, Jiangsu, Peoples R China.
EM chenlifang@jiangnan.cdu.cn; 804223389@qq.com; 18921280026@189.CN
FU Jiangsu Key Laboratory of Media Design and Software Technology
FX This work is supported Jiangsu Key Laboratory of Media Design and
   Software Technology. We also thank Environmental Monitoring Center of
   Wuxi for providing us with video data of cyanobacteria.
CR Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen LQ., 2016, J CENTRAL CHINA NORM, V50, P606
   Fang S.Z., 2019, INF TECHNOL NETW SEC, V38, P97
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   [贾军梅 Jia Junmei], 2015, [生态学报, Acta Ecologica Sinica], V35, P2255
   Kingma D. P., 2014, arXiv
   Klinger R, 2007, CLASSICAL PROBABILIS
   Li X., 2017, GEO SPAT INF TECHNOL, V40, P153
   Li Yachun, 2016, Hupo Kexue, V28, P1256, DOI 10.18307/2016.0611
   Lin Yi, 2011, Journal of Tongji University (Natural Science), V39, P1247, DOI 10.3969/j.issn.0253-374x.2011.08.028
   Liu F, 2019, MULTIMED TOOLS APPL, V78, P4527, DOI 10.1007/s11042-018-6058-6
   [刘俊萍 Liu Junping], 2015, [中国给水排水, China Water & Wastewater], V31, P66
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo AN., 2018, COMPUT APPL SOFTW, V35, P254
   Perdigao P, 2020, MULTIMED TOOLS APPL, V79, P22131, DOI 10.1007/s11042-020-08949-9
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Wu WQ., 2018, INT J ECOL, V7, P53, DOI [10.12677/IJE.2018.72008, DOI 10.12677/IJE.2018.72008]
   Yu Jiabin, 2018, Journal of Computer Applications, V38, P2119, DOI 10.11772/j.issn.1001-9081.2017122959
   Zhu YD, 2014, WATER RESOUR INFORMA, P33
NR 20
TC 0
Z9 0
U1 13
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42413
EP 42431
DI 10.1007/s11042-022-13490-y
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000843996100006
DA 2024-07-18
ER

PT J
AU Du, LN
   Li, JF
   Zhuo, L
   Yang, S
AF Du, Lina
   Li, Jiafeng
   Zhuo, Li
   Yang, Shuo
TI VCFNet: video clarity-fluency network for quality of experience
   evaluation model of HTTP adaptive video streaming services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of experience; Video clarity; Video fluency;
   Harmonic-ResNeXt101; GRU
AB In HTTP adaptive video streaming service, video clarity and fluency are the two most important Influencing Factors (IFs) affecting user's Quality of Experience (QoE). In this paper, a Video Clarity-Fluency Network (VCFNet) is proposed to establish a QoE evaluation model, which focuses on characterizing the clarity-fluency characteristics of video. Firstly, the Harmonic-ResNeXt101 network is constructed by introducing the Harmonic Network into ResNeXt101 to capture the clarity information of video frames. The output of the Fully Connected (FC) layer of the Harmonic-ResNeXt101 network is fed into the Gated Recurrent Unit (GRU), which is used to perform short-term temporal modeling to capture the fluency information of video chunk. Then, the final output of GRU is extracted as the clarity-fluency features, which are concatenated with the statistical features of other IFs (including video quality level, re-buffering duration, re-buffering frequency, etc.) to form the feature parameter vector of IFs. Finally, a neural network composed of One-Dimensional Convolutional Neural Network (1D CNN) layer and two FC layers is designed to establish the mapping relationship model between the feature parameter vector of IFs and Mean Opinion Score (MOS) to predict user's QoE. Experimental results on SQoE-III and SQoE-IV datasets demonstrate that the proposed VCFNet can effectively capture the clarity-fluency information of video, and the resulted QoE model can achieve the state-of-the-art performance compared with the existing QoE evaluation models.
C1 [Du, Lina; Li, Jiafeng; Zhuo, Li; Yang, Shuo] Beijing Univ Technol, Beijing Key Lab Computat Intelligence & Intellige, Beijing 100124, Peoples R China.
   [Du, Lina; Li, Jiafeng; Zhuo, Li; Yang, Shuo] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
C3 Beijing University of Technology; Beijing University of Technology
RP Zhuo, L (corresponding author), Beijing Univ Technol, Beijing Key Lab Computat Intelligence & Intellige, Beijing 100124, Peoples R China.; Zhuo, L (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
EM Dulina@emails.bjut.edu.cn; lijiafeng@bjut.edu.cn; zhuoli@bjut.edu.cn;
   yangshuo045@emails.bjut.edu.cn
RI Du, Lina/HJA-5282-2022; li, jiafeng/KVY-4468-2024
FU National Natural Science Foundation of China [61531006, 61971016];
   Beijing Municipal Education Commission Cooperation Beijing Natural
   Science Foundation
FX This work was supported by the National Natural Science Foundation of
   China (No. 61531006, 61971016), Beijing Municipal Education Commission
   Cooperation Beijing Natural Science Foundation (No.KZ201910005007).
CR Agarla M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080074
   Bampis CG, 2017, ARXIV
   Bentaleb A, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1296, DOI 10.1145/2964284.2964332
   Chen PF, 2021, IEEE T IMAGE PROCESS, V30, P3279, DOI 10.1109/TIP.2021.3060255
   Chen PF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P834, DOI 10.1145/3394171.3413717
   Du LN, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051793
   Duanmu Z, 2020, ARXIV
   Duanmu Z, 2019, ARXIV
   Duanmu ZF, 2018, IEEE T BROADCAST, V64, P474, DOI 10.1109/TBC.2018.2822870
   Duanmu ZF, 2017, IEEE J-STSP, V11, P154, DOI 10.1109/JSTSP.2016.2608329
   Hossfeld Tobias, 2013, Data Traffic Monitoring and Analysis. From Measurement, Classification, and Anomaly Detection to Quality of Experience, P264, DOI 10.1007/978-3-642-36784-7_11
   Jiang J., 2020, ARXIV
   Li Z., 2016, NETFLIX TECH BLOG, V6
   Liu X, 2012, ACM SIGCOMM COMP COM, V42, P359, DOI 10.1145/2377677.2377752
   Luan SZ, 2018, IEEE T IMAGE PROCESS, V27, P4357, DOI 10.1109/TIP.2018.2835143
   Li M, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP), P206, DOI 10.1109/ICMIP.2017.26
   Mok R. K. P., 2011, 2011 IFIP/IEEE International Symposium on Integrated Network Management (IM 2011), P485, DOI 10.1109/INM.2011.5990550
   Rassool R, 2017, IEEE INT SYM BROADB, P351
   Recommendation I, 2017, PAR BITSTR BAS QUAL
   Sector TS,, 2016, SERIES P TERMINALS S
   Tran HTT, 2019, IEEE CONF COMPUT, P702, DOI [10.1109/infcomw.2019.8845041, 10.1109/INFCOMW.2019.8845041]
   Ulicny M, 2018, ARXIV
   Ulicny M., 2019, P BRIT MACH VIS C BM
   Ulicny M, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8902831
   Wang YA, 2019, IEEE INT CON MULTI, P1846, DOI 10.1109/ICME.2019.00317
   Wang ZD, 2017, SENS IMAGING, V18, P1, DOI 10.1007/s11220-017-0161-z
   Watanabe K, 2007, PROC SPIE, V6494, DOI 10.1117/12.703870
   Xue JT, 2014, IEEE INT CON MULTI
   Yan SY, 2019, L N INST COMP SCI SO, V258, P292, DOI 10.1007/978-3-030-05888-3_27
   Yin XQ, 2015, ACM SIGCOMM COMP COM, V45, P325, DOI 10.1145/2785956.2787486
   Yue Qin, 2019, 2019 2nd World Symposium on Communication Engineering (WSCE). Proceedings, P189, DOI 10.1109/WSCE49000.2019.9040920
NR 31
TC 1
Z9 1
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42907
EP 42923
DI 10.1007/s11042-022-13483-x
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000842724400003
DA 2024-07-18
ER

PT J
AU Yadav, S
   Gulia, P
   Gill, NS
AF Yadav, Sangeeta
   Gulia, Preeti
   Gill, Nasib Singh
TI Flow-MotionNet: A neural network based video compression architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video; Compression; Deep learning; CNN; ConvGRU; SSIM; PSNR
ID ALGORITHM
AB The growth of superfluous video content over the internet led to the emergence of highly proficient video compression techniques. These novel techniques make optimal use of the available varying bandwidths to deliver quality video content. The traditional techniques of video compression are mainly based on block designs and remove the redundancies using Discrete Cosine Transforms. Although these techniques perform well but these are not adaptive to the varying bandwidth. A number of learning based video compression schemes have been developed during previous years. Though some are performing efficiently but these are not adaptable for mobile usage because of their flexibility lack for varying reconstruction quality with varying bandwidth. In this paper, a lightweight learning-based video compression architecture has been proposed that attempts to allow variation in quality of the reconstructed video with the amount of data sent, without requiring separate low-resolution versions of the same video. The proposed model is a amalgamation of three tiny networks namely frame autoencoder, flow autoencoder and motion extension network. The performance analysis reveals a significant improvement in visual quality of the video frames but in tradeoff with frame reconstruction time. The results have also been compared to some state-of-the-art techniques including H.264 in terms of SSIM and PSNR.
C1 [Yadav, Sangeeta; Gulia, Preeti; Gill, Nasib Singh] Maharshi Dayanand Univ, Dept Comp Sci & Applicat, Rohtak, Haryana, India.
C3 Maharshi Dayanand University
RP Yadav, S (corresponding author), Maharshi Dayanand Univ, Dept Comp Sci & Applicat, Rohtak, Haryana, India.
EM sangirao5228@gmail.com; preetigulia81@gmail.com; nasibsgill@gmail.com
RI GILL, Nasib Singh/H-3914-2015; A, P/JUU-6693-2023; A,
   preeti/GYI-9428-2022
OI GILL, Nasib Singh/0000-0002-8594-4320; A, preeti/0000-0001-8535-4016;
   yadav, sangeeta/0000-0003-2625-8096
CR Agustsson E, 2017, ADV NEUR IN, V30
   Baig MH, 2017, ADV NEUR IN, V30
   Balle J, 2017, 5 INT C LEARN REPR I
   Cavigelli L, 2017, IEEE IJCNN, P752, DOI 10.1109/IJCNN.2017.7965927
   Chen T, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   De Brabandere B, 2016, ADV NEUR IN, V29
   Fan Q., 2019, PROC CVPR IEEE
   Goswami K, 2018, IEEE T IND ELECTRON, V65, P8861, DOI 10.1109/TIE.2018.2815941
   Goswami K, 2016, INFORM SCIENCES, V364, P72, DOI 10.1016/j.ins.2016.05.018
   Huo S, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351609
   Jiang HZ, 2018, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR.2018.00938
   Johnston N, 2017, ARXIV
   Kim S.Y., 2018, ARXIV
   Le Gall D., 1991, Communications of the ACM, V34, P46, DOI 10.1145/103085.103090
   Lee JH, 2013, IEEE IMAGE PROC, P1982, DOI 10.1109/ICIP.2013.6738408
   Li C, CNN BASED POSTPROCES
   Li YQ, 2017, ADV SOC SCI EDUC HUM, V185, P1, DOI 10.1145/3130941
   Liu D, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3368405
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Mathieu M., 2015, ARXIV
   Mathieu Michael, 2016, ICLR, DOI DOI 10.48550/ARXIV.1511.05440
   Niklaus S, 2017, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2017.37
   Rippel O, 2017, PR MACH LEARN RES, V70
   Song R, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Song X, 2018, ARXIV
   Theis L., 2017, ICLR
   Todeschini G, 2017, INVENTIONS-BASEL, V2, DOI 10.3390/inventions2030014
   van den Oord A, 2016, PR MACH LEARN RES, V48
   Vondrick C, 2016, 30 C NEURAL INFORM P, V29
   Wang TT, 2017, IEEE DATA COMPR CONF, P410, DOI 10.1109/DCC.2017.42
   WebP, SPEED WEBP
   Xue Tianfan, 2016, Advances in Neural Information Processing Systems, P91
   Yan N, 2017, IEEE INT SYMP CIRC S, P822
   Yang R, MULTIFRAME QUALITY E
   Yang R, 2017, ARXIV
   Yang R, 2017, IEEE INT CON MULTI, P817, DOI 10.1109/ICME.2017.8019299
   Zhao ZH, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351189
NR 37
TC 3
Z9 3
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42783
EP 42804
DI 10.1007/s11042-022-13480-0
EA AUG 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000838552300002
DA 2024-07-18
ER

PT J
AU Yang, TD
   Wang, WM
   Cheng, G
   Wei, MQ
   Xie, HR
   Wang, FL
AF Yang, Tongda
   Wang, Weiming
   Cheng, Gary
   Wei, Mingqiang
   Xie, Haoran
   Wang, Fu Lee
TI FDDL-Net: frequency domain decomposition learning for speckle reduction
   in ultrasound images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE FDDL-Net; Speckle noise removal; Ultrasound images; Dual-branch
   interaction
ID NOISE
AB Image decomposition is a useful operation that benefits a number of low-level vision tasks. However, this conventional wisdom is not well studied in deep learning, and almost no existing deep learning-based methods consider the fact that the extracted feature map from a convolution layer consists of different frequency information. We propose an end-to-end frequency domain decomposition learning network (FDDL-Net) to remove speckle noise from ultrasound images. FDDL-Net leverages frequency domain decomposition at the feature level to learn structure and detail information from ultrasound images via an interactive dual-branch framework. According to the properties of speckle noise, the median filter is utilized in the high-frequency branch of the network to remove the noise effectively. In addition, information from the two branches is exchanged interactively, so that valuable features from different frequencies are fully exploited for speckle reduction. Compared with state-of-the-art methods, FDDL-net demonstrates superior noise reduction and feature preservation (0.89 and 30.92 for SSIM and PSNR metrics respectively), attributing to the dual-branch interaction of the network.
C1 [Yang, Tongda; Wei, Mingqiang] Nanjing Univ Aeronaut & Astronaut, Nanjing, Peoples R China.
   [Wang, Weiming; Wang, Fu Lee] Hong Kong Metropolitan Univ, Ho Man Tin, Hong Kong, Peoples R China.
   [Cheng, Gary] Educ Univ Hong Kong, Tai Po, Hong Kong, Peoples R China.
   [Xie, Haoran] Lingnan Univ, Tuen Mun, Hong Kong, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Hong Kong Metropolitan
   University; Education University of Hong Kong (EdUHK); Lingnan
   University
RP Cheng, G (corresponding author), Educ Univ Hong Kong, Tai Po, Hong Kong, Peoples R China.
EM tdy.chinese@gmail.com; wmwang@hkmu.edu.hk; chengks@eduhk.hk;
   mqwei@nuaa.edu.cn; hrxie2@gmail.com; pwang@hkmu.edu.hk
RI Wang, Fu Lee/AAD-9782-2021; Xie, Haoran/AFS-3515-2022
OI Wang, Fu Lee/0000-0002-3976-0053; Xie, Haoran/0000-0003-0965-3617;
   Cheng, Gary/0000-0002-5614-3348
FU National Natural Science Foundation of China [61802072];
   Interdisciplinary Research Scheme of the Dean's Research Fund 2019-20
   [FLASS/DRF/IDS-2]; Research Cluster Fund of The Education University of
   Hong Kong [RG 78/2019-2020R]; Lam Woo Research Fund of Lingnan
   University, Hong Kong [LWI20011]; One-off Special Fund from Central and
   Faculty Fund [MIT02/19-20]
FX The research described in this article has been supported by the
   National Natural Science Foundation of China (No. 61802072), the One-off
   Special Fund from Central and Faculty Fund in Support of Research from
   2019/20 to 2021/22 (MIT02/19-20), the Interdisciplinary Research Scheme
   of the Dean's Research Fund 2019-20 (FLASS/DRF/IDS-2) and the Research
   Cluster Fund (RG 78/2019-2020R) of The Education University of Hong
   Kong, and the Lam Woo Research Fund (LWI20011) of Lingnan University,
   Hong Kong.
CR Al-Dhabyani W, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.104863
   Burger H., 2012, CVPR
   Chen YP, 2019, IEEE I CONF COMP VIS, P3434, DOI 10.1109/ICCV.2019.00353
   Coupé P, 2009, IEEE T IMAGE PROCESS, V18, P2221, DOI 10.1109/TIP.2009.2024064
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Feng D, 2019, INT WORKSHOP MULTISC, P85
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Jain V., 2009, ADV NEURAL INFORM PR, P769, DOI DOI 10.5555/2981780.2981876
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Liang L, 2019, ARXIV
   Lindeberg T., 1994, SCALE SPACE THEORY C
   LOPES A, 1990, IEEE T GEOSCI REMOTE, V28, P992, DOI 10.1109/36.62623
   Paszke A, 2019, ADV NEUR IN, V32
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sen Deng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14548, DOI 10.1109/CVPR42600.2020.01457
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   WAGNER RF, 1983, IEEE T SON ULTRASON, V30, P156, DOI 10.1109/T-SU.1983.31404
   Wang GQ, 2019, IEEE I CONF COMP VIS, P5643, DOI 10.1109/ICCV.2019.00574
   Yu JH, 2010, PATTERN RECOGN, V43, P3083, DOI 10.1016/j.patcog.2010.04.006
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Zhan Y, 2014, SIGNAL PROCESS, V103, P201, DOI 10.1016/j.sigpro.2013.12.019
   Zhang F, 2007, IEEE T MED IMAGING, V26, P200, DOI 10.1109/TMI.2006.889735
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
NR 26
TC 1
Z9 1
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42769
EP 42781
DI 10.1007/s11042-022-13481-z
EA AUG 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000838552300003
DA 2024-07-18
ER

PT J
AU Zhou, Y
   Xiao, XT
   Zhang, QD
   Wang, X
   Jiang, JM
AF Zhou, Yu
   Xiao, Xiaotong
   Zhang, Qiudan
   Wang, Xu
   Jiang, Jianmin
TI Deep stereoscopic image saliency inspired stereoscopic image thumbnail
   generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereoscopic saliency detection; Stereoscopic thumbnail generation;
   Energy minimization; Uncertain weighted fusion
ID MODEL
AB In this paper, we propose a stereoscopic image thumbnail generation method guided by the stereoscopic image saliency. Specifically, we utilize an uncertain-weighted fusion mechanism to combine the spatial saliency information with the saliency driven by depth cues, generating the dense stereoscopic saliency fixation map. Subsequently, the obtained dense fixation map is converted into a salient object map through a saliency optimization module, which provides the object-level saliency cues for the thumbnail generation task. Under the guidance of the obtained salient object map, a cropping window is employed to cut out the most salient region and generate the stereoscopic thumbnails, such that the disparity distribution of the original image can be well preserved, and avoid sharply deforming certain structured objects in the subsequent warping operation. Finally, the warping operation is utilized to adjust the aspect ratio of the stereoscopic thumbnail to the target size. Qualitative and quantitative results demonstrate that our proposed method achieves superior performance than the state-of-the-art benchmarks on the public datasets.
C1 [Zhou, Yu; Xiao, Xiaotong; Wang, Xu; Jiang, Jianmin] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
   [Zhang, Qiudan] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 Shenzhen University; City University of Hong Kong
RP Wang, X (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
EM wangxu@szu.edu.cn
OI ZHOU, Yu/0000-0002-3224-0063
FU National Natural Science Foundation of China [61871270, 62032015];
   Shenzhen Natural Science Foundation [JCYJ20200109110410133,
   20200812110350001]; National Engineering Laboratory for Big Data System
   Computing Technology of China
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant 61871270 and 62032015), in part by the
   Shenzhen Natural Science Foundation under Grants JCYJ20200109110410133
   and 20200812110350001, in part by the National Engineering Laboratory
   for Big Data System Computing Technology of China.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Nguyen AD, 2019, IEEE T IMAGE PROCESS, V28, P1939, DOI 10.1109/TIP.2018.2879408
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Banitalebi-Dehkordi A, 2017, MULTIMED TOOLS APPL, V76, P23859, DOI 10.1007/s11042-016-4155-y
   Chai XL, 2020, IEEE T MULTIMEDIA, V22, P1208, DOI 10.1109/TMM.2019.2939707
   Chang CH, 2011, IEEE T MULTIMEDIA, V13, P589, DOI 10.1109/TMM.2011.2116775
   Che ZH, 2020, IEEE T IMAGE PROCESS, V29, P2287, DOI 10.1109/TIP.2019.2945857
   Chen JS, 2016, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.2016.61
   Cho D, 2017, IEEE I CONF COMP VIS, P4568, DOI 10.1109/ICCV.2017.488
   Cong RM, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2557347
   Dong WM, 2012, J COMPUT SCI TECH-CH, V27, P121, DOI 10.1007/s11390-012-1211-6
   Fan SJ, 2018, PROC CVPR IEEE, P7521, DOI 10.1109/CVPR.2018.00785
   Fan XT, 2021, NEUROCOMPUTING, V447, P161, DOI 10.1016/j.neucom.2021.02.079
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Fu Z, 2020, IEEE T MULTIMEDIA
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang QP, 2015, SIGNAL PROCESS-IMAGE, V38, P57, DOI 10.1016/j.image.2015.04.007
   Jung YJ, 2016, IEEE T CIRC SYST VID, V26, P1201, DOI 10.1109/TCSVT.2015.2430632
   Kiess J, 2012, PROC SPIE, V8304, DOI 10.1117/12.906386
   Kroner A, 2020, NEURAL NETWORKS, V129, P261, DOI 10.1016/j.neunet.2020.05.004
   Lifang Wu, 2014, Journal of Multimedia, V9, P483, DOI 10.4304/jmm.9.4.483-492
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mao YD, 2022, IEEE T MULTIMEDIA, V24, P2435, DOI 10.1109/TMM.2021.3081260
   Niu YZ, 2020, IEEE T CIRC SYST VID, V30, P3624, DOI 10.1109/TCSVT.2019.2949587
   Qiudan Zhang, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9917, P580, DOI 10.1007/978-3-319-48896-7_57
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Shao F, 2017, IEEE T IMAGE PROCESS, V26, P4790, DOI 10.1109/TIP.2017.2721546
   Suh Bongwon, 2003, P ACM S US INT SOFTW, P95, DOI DOI 10.1145/964696.964707
   Sun J, 2013, INT J COMPUT VISION, V104, P135, DOI 10.1007/s11263-013-0618-z
   Tan WM, 2020, IEEE T MULTIMEDIA, V22, P1730, DOI 10.1109/TMM.2019.2959925
   Wang WG, 2020, IEEE T PATTERN ANAL, V42, P1913, DOI 10.1109/TPAMI.2019.2905607
   Wang WG, 2017, IEEE T VIS COMPUT GR, V23, P2014, DOI 10.1109/TVCG.2016.2600594
   Wang XJ, 2022, IEEE T MULTIMEDIA, V24, P2422, DOI 10.1109/TMM.2021.3081259
   Wang YS, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409071
   Zhang LX, 2017, SOFT COMPUT, V21, P447, DOI 10.1007/s00500-015-1795-1
   Zhang QD, 2020, IEEE T IMAGE PROCESS, V29, P5722, DOI 10.1109/TIP.2020.2985531
   Zhang YB, 2016, IEEE T IMAGE PROCESS, V25, P4286, DOI 10.1109/TIP.2016.2585884
   Zhou Y, 2021, IEEE T CIRC SYST VID, V31, P126, DOI 10.1109/TCSVT.2020.2977943
NR 41
TC 1
Z9 1
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42749
EP 42767
DI 10.1007/s11042-022-13487-7
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000840140800005
DA 2024-07-18
ER

PT J
AU Kaur, G
   Goyal, RK
   Mehta, R
AF Kaur, Gaganpreet
   Goyal, Raman Kumar
   Mehta, Rajesh
TI An efficient handover mechanism for 5G networks using hybridization of
   LSTM and SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LSTM; SVM; Handover; Deep learning; Mobility management; Network
   selection
ID VERTICAL HANDOVER; WIRELESS; ALGORITHM
AB Mobile devices can access the internet through different wireless interfaces such as wireless fidelity (WiFi), worldwide interoperability for microwave access (WiMAX), and cellular networks like long-term evolution (LTE), fifth-generation networks (5G), etc. The main objective of the handover technique is to select the best network with minimum handover latency to provide seamless connectivity to the user. This paper proposes a hybrid handover technique for predictive handover based on long-short term memory (LSTM) and support vector machine (SVM). LSTM is used to predict the parameters of mobile devices such as location coordinates, speed, reference signal received power (RSRP), and reference signal received quality (RSRQ) at the next time step based on their values at previous time steps. The output of LSTM is supplied as input to the SVM for the selection of the most appropriate network. The mechanism proposed in this work significantly reduces the handover latency for predictive handover along with high prediction accuracy. The experimental results revealed that proposed approach can achieve accuracy up to 99.99% as compared to 85.76% (by using Stacked-LSTM) on dataset1 and improvement in validation and testing accuracy on whole dataset2 upto 76 and 75.92% relative to the accuracy 49.11 and 47.09% achieved by existing method as discussed in experimental and results analysis section.
C1 [Kaur, Gaganpreet; Goyal, Raman Kumar; Mehta, Rajesh] Thapar Inst Engn & Technol, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Kaur, G (corresponding author), Thapar Inst Engn & Technol, Patiala, Punjab, India.
EM gaganpreet.k@thapar.edu; ramankumar.goyal@thapar.edu;
   rajesh.mehta@thapar.edu
OI , Gaganpreet Kaur/0000-0003-4680-3485
CR Ali Z, 2020, UEEE INT SYM PERS IN
   Aljeri N, 2019, Q2SWINET'19: PROCEEDINGS OF THE 15TH ACM INTERNATIONAL SYMPOSIUM ON QOS AND SECURITY FOR WIRELESS AND MOBILE NETWORKS, P85, DOI 10.1145/3345837.3355963
   Aljeri N, 2019, AD HOC NETW, V94, DOI 10.1016/j.adhoc.2019.101930
   Almutairi AF, 2018, TELECOMMUN SYST, V68, P151, DOI 10.1007/s11235-017-0364-6
   [Anonymous], HUMAN DYNAMICS LAB R
   [Anonymous], 2009, 36133 3GPP TS
   Bahlke F, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P3564, DOI 10.1109/ICASSP.2018.8461780
   Brownlee&nbsp, 2017, DEEP LEARNING TIME S
   Choi R, 2009, 2009 IEEE YOUTH CONFERENCE ON INFORMATION, COMPUTING AND TELECOMMUNICATION, PROCEEDINGS, P279, DOI 10.1109/YCICT.2009.5382368
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Goudarzi S, 2017, NEUROCOMPUTING, V256, P63, DOI 10.1016/j.neucom.2016.08.136
   Goutam S, 2019, 2019 INT C ADV COMP, P1
   Goyal Riya, 2019, Proceedings of 2nd International Conference on Communication, Computing and Networking. ICCCN 2018. Lecture Notes in Networks and Systems (LNNS 46), P293, DOI 10.1007/978-981-13-1217-5_29
   Goyal T, 2019, COMPUT COMMUN, V133, P67, DOI 10.1016/j.comcom.2018.10.011
   Gupta Mani Shekhar, 2019, Proceedings of the 2nd International Conference on Data Engineering and Communication Technology (ICDECT 2017). Advances in Intelligent Systems and Computing (AISC 828), P145, DOI 10.1007/978-981-13-1610-4_15
   Haldorai A, 2019, EAI SPRINGER INNOVAT, P135, DOI 10.1007/978-3-030-15416-5_7
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI [10.1007/978-1-4614-7138-7, 10.1007/978-1-4614-7138-7_1]
   Jaraíz-Simon MD, 2013, LECT NOTES COMPUT SC, V7902, P198, DOI 10.1007/978-3-642-38679-4_19
   Khan M, 2017, MULTIMED TOOLS APPL, V76, P24649, DOI 10.1007/s11042-016-4330-1
   Lahby M., 2018, 2018 9 IFIP INT C NE, P1
   Lahby M, 2019, DIGIT COMMUN NETW, V5, P297, DOI 10.1016/j.dcan.2019.10.001
   Li MX, 2020, TRANSPORTMETRICA A, V16, P119, DOI 10.1080/23249935.2018.1552334
   Michaelis S, 2006, IEEE VTS VEH TECHNOL, P952
   Mohamed A, 2015, IEEE ICC, P3939, DOI 10.1109/ICC.2015.7248939
   Nimmalapudi, 2020, ARXIV PREPRINT ARXIV
   Ozturk M, 2019, NEUROCOMPUTING, V358, P479, DOI 10.1016/j.neucom.2019.01.031
   Parambanchary D, 2020, WIREL NETW, V26, P165, DOI 10.1007/s11276-018-1787-z
   Peters J, 2017, ADAPT COMPUT MACH LE
   Qin W., 2013, JOINT INT C PERVASIV, P476
   Raca D, 2020, MMSYS'20: PROCEEDINGS OF THE 2020 MULTIMEDIA SYSTEMS CONFERENCE, P303, DOI 10.1145/3339825.3394938
   Salih YK, 2016, T EMERG TELECOMMUN T, V27, P1641, DOI 10.1002/ett.3102
   Shi R, 2019, INT CONF WIREL OPT, P337, DOI 10.1109/wocc.2019.8770632
   Trestian R., 2011, Phys. Commun., V4, P156
   Wang XW, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 3, P423, DOI 10.1109/ICICISYS.2009.5358142
   Wang Z, 2018, IEEE INTERNET THINGS, V5, P4296, DOI 10.1109/JIOT.2018.2848295
   Wickramasuriya DS, 2017, 2017 IEEE 18TH WIRELESS AND MICROWAVE TECHNOLOGY CONFERENCE (WAMICON)
   Yang BT, 2018, IEEE COMMUN LETT, V22, P2116, DOI 10.1109/LCOMM.2018.2861731
   Yang HZ, 2020, IEEE POW ENER SOC GE, DOI 10.1109/pesgm41954.2020.9281738
   Yang JX, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA ANALYSIS (ICBDA), P837, DOI 10.1109/ICBDA.2017.8078755
   Yi Z, 2019, 2019 INT C WIR COMM, P143
   Yu HW, 2019, J NETW SYST MANAG, V27, P756, DOI 10.1007/s10922-018-9483-y
   Zekri M, 2012, COMPUT COMMUN, V35, P2055, DOI 10.1016/j.comcom.2012.07.011
   Zeljkovic E, 2019, IEEE T NETW SERV MAN, V16, P1522, DOI 10.1109/TNSM.2019.2948883
NR 43
TC 5
Z9 5
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37057
EP 37085
DI 10.1007/s11042-021-11510-x
EA JUL 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000825246000007
DA 2024-07-18
ER

PT J
AU Hamila, O
   Ramanna, S
   Henry, CJ
   Kiranyaz, S
   Hamila, R
   Mazhar, R
   Hamid, T
AF Hamila, Oumaima
   Ramanna, Sheela
   Henry, Christopher J.
   Kiranyaz, Serkan
   Hamila, Ridha
   Mazhar, Rashid
   Hamid, Tahir
TI Fully automated 2D and 3D convolutional neural networks pipeline for
   video segmentation and myocardial infarction detection in
   echocardiography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D convolutional neural network; Video segmentation; Myocardial
   infarction; Detection; Echocardiography
ID VENTRICULAR CONTRACTION ABNORMALITIES; QUANTITATIVE DETECTION;
   DIAGNOSIS; MOTION; QUALITY; IMPACT
AB Myocardial infarction (MI) is a life-threatening disorder that occurs due to a prolonged limitation of blood supply to the heart muscles, and which requires an immediate diagnosis to prevent death. To detect MI, cardiologists utilize in particular echocardiography, which is a non-invasive cardiac imaging that generates real-time visualization of the heart chambers and the motion of the heart walls. These videos enable cardiologists to identify almost immediately regional wall motion abnormalities (RWMA) of the left ventricle (LV) chamber, which are highly correlated with MI. However, data acquisition is usually performed during emergency which results in poor-quality and noisy data that can affect the accuracy of the diagnosis. To address the identified problems, we propose in this paper an innovative, real-time and fully automated model based on convolutional neural networks (CNN) to early detect MI in a patient's echocardiography. Our model is a pipeline consisting of a 2D CNN that performs data preprocessing by segmenting the LV chamber from the apical four-chamber (A4C) view, followed by a 3D CNN that performs a binary classification to detect MI. The pipeline was trained and tested on the HMC-QU dataset consisting of 162 echocardiography. The 2D CNN achieved 97.18% accuracy on data segmentation, and the 3D CNN achieved 90.9% accuracy, 100% precision, 95% recall, and 97.2% F1 score. Our detection results outperformed existing state-of-the-art models that were tested on the HMC-QU dataset for MI detection. This work demonstrates that developing a fully automated system for LV segmentation and MI detection is efficient and propitious.
C1 [Hamila, Oumaima; Ramanna, Sheela; Henry, Christopher J.] Univ Winnipeg, Dept Appl Comp Sci, 515 Portage Ave, Winnipeg, MB R3B 2E9, Canada.
   [Kiranyaz, Serkan; Hamila, Ridha] Qatar Univ, Dept Elect Engn, Doha, Qatar.
   [Mazhar, Rashid] Hamad Med Corp, Hamad Hosp, Thorac Surg, Doha, Qatar.
   [Hamid, Tahir] Hamad Med Corp, Heart Hosp, Cardiol, Doha, Qatar.
C3 University of Winnipeg; Qatar University; Hamad Medical Corporation;
   Hamad General Hospital; Hamad Medical Corporation
RP Hamila, O (corresponding author), Univ Winnipeg, Dept Appl Comp Sci, 515 Portage Ave, Winnipeg, MB R3B 2E9, Canada.
EM hamila-o@webmail.uwinnipeg.ca; s.ramanna@uwinnipeg.ca;
   ch.henry@uwinnipeg.ca; mkiranyaz@qu.edu.qa; hamila@qu.edu.qa
RI Hamila, Ridha/ABI-2129-2020; Kiranyaz, Serkan/AAK-1416-2021; Mazhar,
   Rashid/AAY-9565-2020
OI Hamila, Ridha/0000-0002-6920-7371; Mazhar, Rashid/0000-0003-4255-8996;
   Hamila, Oumaima/0000-0003-4223-1598
FU NSERC Discovery Grants Program [194376, 418413]
FX The work of Sheela Ramanna and Christopher J. Henry was funded by the
   NSERC Discovery Grants Program (nos. 194376, 418413).
CR Alhassan V, 2020, NEURAL COMPUT APPL, V32, P8529, DOI 10.1007/s00521-019-04349-9
   [Anonymous], 2018, NPJ DIGIT MED
   [Anonymous], TENSORRT CARDIOVASCU
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bax JJ, 2017, NAT REV CARDIOL, V14, P209, DOI 10.1038/nrcardio.2017.1
   Cao CS, 2018, GENOM PROTEOM BIOINF, V16, P17, DOI 10.1016/j.gpb.2017.07.003
   Chen M, 2021, IEEE T SYST MAN CY-S, V51, P1414, DOI 10.1109/TSMC.2019.2896891
   Chollet F., 2015, Keras
   Davenport Thomas, 2019, Future Healthc J, V6, P94, DOI 10.7861/futurehosp.6-2-94
   Degerli A, HMC QU DATASET
   Degerli A, 2021, IEEE ACCESS, V9, P34442, DOI 10.1109/ACCESS.2021.3059595
   Douglas PS, 2016, JACC-CARDIOVASC IMAG, V9, P1211, DOI 10.1016/j.jcmg.2016.02.027
   Dumoulin V, 2016, GUIDE CONVOLUTION AR, P18
   Dwivedi G, 2013, CAN J CARDIOL, V29, P257, DOI 10.1016/j.cjca.2013.01.011
   Gahungu N, 2020, CURR CARDIOVASC IMAG, V13, DOI 10.1007/s12410-020-9529-x
   Gottdiener JS, 2004, J AM SOC ECHOCARDIOG, V17, P1086, DOI 10.1016/j.echo.2004.07.013
   Hamad Medical Corporation, About us
   Hernandez AF, 2005, ARCH INTERN MED, V165, P2162, DOI 10.1001/archinte.165.18.2162
   HOROWITZ RS, 1982, CIRCULATION, V65, P323, DOI 10.1161/01.CIR.65.2.323
   Hubbard Julia, 2003, Nurs Times, V99, P28
   Kiranyaz S, 2020, IEEE ACCESS, V8, P210301, DOI 10.1109/ACCESS.2020.3038743
   Kiranyaz S, 2020, NEUROCOMPUTING, V411, P291, DOI 10.1016/j.neucom.2020.05.063
   KLEIN HO, 1983, CIRCULATION, V67, P558, DOI 10.1161/01.CIR.67.3.558
   Kosmidou I, 2017, EUR HEART J, V38, P1656, DOI 10.1093/eurheartj/ehx159
   Kurt M, 2009, J AM COLL CARDIOL, V53, P802, DOI 10.1016/j.jacc.2009.01.005
   Kusunose K, 2020, JACC-CARDIOVASC IMAG, V13, P374, DOI 10.1016/j.jcmg.2019.02.024
   Laslett LJ, 2012, J AM COLL CARDIOL, V60, pS1, DOI 10.1016/j.jacc.2012.11.002
   Lüscher TF, 2015, EUR HEART J, V36, P947, DOI 10.1093/eurheartj/ehv071
   Mannor S., 2005, P 22 INT C MACH LEAR, P561
   McBee MP, 2018, ACAD RADIOL, V25, P1472, DOI 10.1016/j.acra.2018.02.018
   Mishra A, 2003, IMAGE VISION COMPUT, V21, P967, DOI 10.1016/S0262-8856(03)00121-5
   MOYNIHAN PF, 1981, CIRCULATION, V63, P752, DOI 10.1161/01.CIR.63.4.752
   Nagata Y, 2018, ECHO RES PRACT, V5, P27, DOI 10.1530/ERP-17-0047
   Narula S, 2016, J AM COLL CARDIOL, V68, P2287, DOI 10.1016/j.jacc.2016.08.062
   Neskovic AN, 2013, EUR HEART J-CARD IMG, V14, P1, DOI 10.1093/ehjci/jes193
   OBOYLE JE, 1983, AM J CARDIOL, V51, P1732, DOI 10.1016/0002-9149(83)90220-5
   OHMAN EM, 1990, BRIT HEART J, V63, P335
   Palmieri V, 2003, HYPERTENSION, V41, P75, DOI 10.1161/01.HYP.0000045081.54784.36
   Qazi M, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P519
   Refaeilzadeh P., 2009, ENCYCL DATABASE SYST, V5, P532, DOI DOI 10.1007/978-0-387-39940-9565
   ROBERTS R, 1994, CIRCULATION, V89, P872, DOI 10.1161/01.CIR.89.2.872
   Sevakula RK, 2020, J AM HEART ASSOC, V9, DOI 10.1161/JAHA.119.013924
   Thygesen K, 2007, J AM COLL CARDIOL, V50, P2173, DOI [10.1161/CIRCULATIONAHA.107.187397, 10.1016/j.jacc.2007.09.011]
   Ulloa A, 2018, ARXIV181110553
   Upendra K.E.T., 2018, 2018 NATL INFORM TEC, P1
   Van de Werf F, 2003, EUR HEART J, V24, P28, DOI 10.1016/S0195-668X(02)00618-8
   Wael M., 2015, J CARDIOVASC MAGN R, V17, P47, DOI [10.1186/1532-429X-17-S1-P47, DOI 10.1186/1532-429X-17-S1-P47]
   Wharton G, 2015, ECHO RES PRACT, V2, pG9, DOI 10.1530/ERP-14-0079
   Wu CC, 2019, COMPUT METH PROG BIO, V173, P109, DOI 10.1016/j.cmpb.2019.01.013
   Xing YF, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8861886
   Zhu YD, 1996, MAGNET RESON MED, V35, P471, DOI 10.1002/mrm.1910350405
NR 51
TC 7
Z9 8
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37417
EP 37439
DI 10.1007/s11042-021-11579-4
EA JUL 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000823376700005
DA 2024-07-18
ER

PT J
AU Prabhaker, MLC
   Ponnan, S
AF Prabhaker, M. Lordwin Cecil
   Ponnan, Suresh
TI AI based realtime task schedulers for multicore processor based low
   power biomedical devices for health care application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bioinformatics; Low power biomedical devices; Multicore architecture;
   Multi-objective evolutionary algorithms; AI realtime task schedulers
AB The bioinformatics data processing plays a vital role in low power biomedical devices. The functional domain of processing biological data is collection, execution, conversion, storing and distribution. So, there is an effective multiple objective real time task scheduling technique are required to provide better solution in this domain. This paper describes novel AI based multi-objective evolutionary algorithmic techniques such as multi-objective genetic algorithm (MOGA), non-dominated sorting genetic algorithm (NSGA) and multi-objective messy genetic algorithm (MOMGA) for scheduling real time tasks to a multicore processor-based low power biomedical device used for health care application. These techniques improve the performance upon earlier reported system by considering multiple objectives such as, low power consumption (P), maximizing core utilization (U) and minimizing deadline miss-rate (delta). The novelty of this work is to achieve the schedulability of realtime tasks by computing the converging value of a series of task parameters such as execution time, release time, workload and arrival time. Finally, we investigated the performance parameters such as power consumption (P), deadline miss-rate (delta), and core utilization for the given architecture. The evaluation results show that the power consumption is reduced to about 5-8%, utilization of the core is increased about 10% to 40% and deadline miss-rate is comparatively minimized with conventional realtime scheduling approaches.
C1 [Prabhaker, M. Lordwin Cecil; Ponnan, Suresh] Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci &, Dept ECE, Chennai, Tamil Nadu, India.
C3 Vel Tech Rangarajan Dr Sagunthala R&D Institute of Science & Technology
RP Ponnan, S (corresponding author), Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci &, Dept ECE, Chennai, Tamil Nadu, India.
EM suresh3982@yahoo.co.in
RI K P, Suresh/AAK-4725-2021; Micheal, Lordwin Cecil
   Prabhaker/AAT-7483-2020; P, SURESH/D-2981-2014
OI K P, Suresh/0000-0002-4672-8334; Micheal, Lordwin Cecil
   Prabhaker/0000-0001-9867-6276; P, SURESH/0000-0002-0488-972X
CR Balakrishnan A, 2011, IEEE T ELECTRON DEV, V58, P2831, DOI 10.1109/TED.2011.2158104
   Barros CA, 2015, MICROPROCESS MICROSY, V39, P418, DOI 10.1016/j.micpro.2015.05.009
   Buttazzo GC, 2011, HARD REAL-TIME COMPUTING SYSTEMS: PREDICTABLE SCHEDULING ALGORITHMS AND APPLICATIONS, THIRD EDITION, P1, DOI 10.1007/978-1-14614-0676-1
   Deb K., 2011, Multi-objective optimisation using evolutionary algorithms: an introduction, P3, DOI DOI 10.1007/978-0-85729-652-8_1
   FONSECA CM, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P416
   Gálvez S, 2010, BIOINFORMATICS, V26, P683, DOI 10.1093/bioinformatics/btq017
   He D, 2013, MICROPROCESS MICROSY, V37, P858, DOI 10.1016/j.micpro.2013.04.007
   Kalidass J, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03409-0
   Obukhova K, 2020, 15TH INTERNATIONAL CONFERENCE ON ADVANCED TRENDS IN RADIOELECTRONICS, TELECOMMUNICATIONS AND COMPUTER ENGINEERING (TCSET - 2020), P368, DOI 10.1109/TCSET49122.2020.235456
   Langmead B, 2009, GENOME BIOL, V10, DOI 10.1186/gb-2009-10-3-r25
   Merelli I., 2019, UND INF MISINF FLIGH, V1, P209, DOI [10.1016/B978-0-12-809633-8.20369-5, DOI 10.1016/B978-0-12-809633-8.20369-5]
   Nebro AJ, 2009, INT J INTELL SYST, V24, P726, DOI 10.1002/int.20358
   Ocaña KACS, 2020, FUTURE GENER COMP SY, V107, P192, DOI 10.1016/j.future.2020.01.030
   Ponnan S., 2020, COMPUT ELECTR ENG, V90, P6996
   Ponnan S, 2021, IEEE SENS J, V21, P17373, DOI 10.1109/JSEN.2021.3080217
   Prabhaker MLC, 2020, AUTOM CONTROL COMPUT, V54, P291, DOI 10.3103/S0146411620040094
   Ram RS, 2020, MICROPROCESS MICROSY, V76, DOI 10.1016/j.micpro.2020.103088
   Revathi M., 2021, IMPROVED PERFORMANCE
   SAHU S. N., 2020, INTERNET THINGS SMAR, P151, DOI [10.1007/978-3-030-39047-1_7, DOI 10.1007/978-3-030-39047-1_7]
   Seo E, 2008, IEEE T PARALL DISTR, V19, P1540, DOI 10.1109/TPDS.2008.104
   Weise T, 2009, Global Optimization Algorithms-Theory and Application, DOI DOI 10.1017/CBO9780511691881.010
NR 21
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42079
EP 42095
DI 10.1007/s11042-021-11651-z
EA JUL 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000823376700006
DA 2024-07-18
ER

PT J
AU El Biach, FZ
   Iala, I
   Laanaya, H
   Minaoui, K
AF El Biach, Fatima Zahra
   Iala, Imad
   Laanaya, Hicham
   Minaoui, Khalid
TI Encoder-decoder based convolutional neural networks for image forgery
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Deep learning; Image forgery
ID EXPOSING DIGITAL FORGERIES; COPY-MOVE FORGERY; DETECTION ALGORITHM;
   PASSIVE DETECTION; ROBUST-DETECTION; LOCALIZATION; TRANSFORM; REMOVAL;
   REGION
AB Today, images editing software has greatly evolved, thanks to them that the semantic manipulation of images has become easier. On the other hand, the identification of these modifications becomes a very difficult task because the modified regions are not visually apparent. In this article, a new convolutional neural network method based on an encoder/decoder called Fals-Unet is proposed to locate the manipulated regions. The encoder of our method uses an architecture topologically identical to that of the Resnet50 method; its main goal is the exploitation of spatial maps to analyze the discriminating characteristics between the manipulated and non-manipulated regions. The decoding network learns the mapping from low-resolution feature maps to pixel-wise predictions for localizing the falsified regions. Finally, the predicted binary mask (0: falsify, 1: not falsify) is generated by the final layer (softmax). Experimental results on many public datasets CASIA, NIST'16, COVERAGE, and COMOD show that the proposed CNN-based model outperforms some methods.
C1 [El Biach, Fatima Zahra; Iala, Imad; Laanaya, Hicham; Minaoui, Khalid] Mohammed V Univ Rabat, Fac Sci, Rabat IT Ctr, LRIT Associated Unit CNRST URAC N29, BP 1014 RP, Rabat, Morocco.
C3 Mohammed V University in Rabat
RP El Biach, FZ (corresponding author), Mohammed V Univ Rabat, Fac Sci, Rabat IT Ctr, LRIT Associated Unit CNRST URAC N29, BP 1014 RP, Rabat, Morocco.
EM fatizz.elbiach@gmail.com; imad.iala01@gmail.com;
   hicham.laanaya@gmail.com; khalid.minaoui@um5.ac.ma
RI Laanaya, Hicham/JMQ-1702-2023
OI khalid, Minaoui/0000-0002-3918-8552
CR Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2017, Electronic Imaging
   Ansari MD, 2014, IETE Journal of Education, V55, P40, DOI DOI 10.1080/09747338.2014.921415
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Bappy JH, 2017, IEEE I CONF COMP VIS, P4980, DOI 10.1109/ICCV.2017.532
   Bayar B, 2017, INT CONF ACOUST SPEE, P2152, DOI 10.1109/ICASSP.2017.7952537
   Bharati A, 2016, IEEE T INF FOREN SEC, V11, P1903, DOI 10.1109/TIFS.2016.2561898
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bianchi T, 2011, INT CONF ACOUST SPEE, P2444
   Boughorbel S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177678
   Buccoli M, 2014, IEEE INT WORKS INFOR, P131, DOI 10.1109/WIFS.2014.7084316
   Bunk J, 2017, IEEE COMPUT SOC CONF, P1881, DOI 10.1109/CVPRW.2017.235
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Chang IC, 2013, IMAGE VISION COMPUT, V31, P57, DOI 10.1016/j.imavis.2012.09.002
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chollet F., 2015, KERAS
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Dirik AE, 2009, IEEE IMAGE PROC, P1497, DOI 10.1109/ICIP.2009.5414611
   Dong Jing., 2011, CASIA TAMPERED IMAGE
   Farid H., 1999, DETECTING DIGITAL FO
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Feng X., 2011, 2011 IEEE International Conference on Multimedia and Expo, P1
   Feng XY, 2012, IEEE T MULTIMEDIA, V14, P536, DOI 10.1109/TMM.2012.2191946
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Fillion C, 2010, PROC SPIE, V7541, DOI 10.1117/12.838647
   Fu DD, 2006, LECT NOTES COMPUT SC, V4283, P177
   Gao SD, 2019, J REAL-TIME IMAGE PR, V16, P741, DOI 10.1007/s11554-019-00860-3
   Golestaneh SA, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013018
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Jaberi M, 2014, MACH VISION APPL, V25, P451, DOI 10.1007/s00138-013-0522-0
   Johnson MK, 2007, LECT NOTES COMPUT SC, V4567, P311, DOI 10.1007/978-3-540-77370-2_21
   Kakar P, 2012, IEEE T INF FOREN SEC, V7, P1018, DOI 10.1109/TIFS.2012.2188390
   Kendall A, 2016, Arxiv, DOI arXiv:1511.02680
   Kolcz A., 2004, ACM SIGKDD EXPLORATI, V6, P1, DOI [10.2973/odp.proc.ir.207.2004, DOI 10.1145/1007730.1007733]
   Kwon Y, 2015, IEEE T PATTERN ANAL, V37, P1792, DOI 10.1109/TPAMI.2015.2389797
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Liang ZS, 2015, J VIS COMMUN IMAGE R, V30, P75, DOI 10.1016/j.jvcir.2015.03.004
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu QZ, 2015, ACM T INTEL SYST TEC, V5, DOI 10.1145/2560365
   Luo WQ, 2006, INT C PATT RECOG, P746
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   Manu VT, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, VISION AND INFORMATION SECURITY (CGVIS), P145, DOI 10.1109/CGVIS.2015.7449911
   Mohammed T.M., 2018, Electronic Imaging, V2018, P1
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nataraj L, 2010, PROC SPIE, V7541, DOI 10.1117/12.839086
   Nguyen HH, 2019, 13TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY (ARES 2018), DOI 10.1145/3230833.3230863
   Nist, 2016, NIMBL
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Rahmouni N, 2017, IEEE INT WORKS INFOR
   Rao Y, 2016, IEEE INT WORKS INFOR
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Ryu SJ, 2014, PATTERN RECOGN LETT, V36, P89, DOI 10.1016/j.patrec.2013.09.028
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Sarkar A, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P107
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Verdoliva L, 2014, IEEE INT WORKS INFOR, P149, DOI 10.1109/WIFS.2014.7084319
   Wang ZS, 2020, IEEE ACCESS, V8, P71353, DOI 10.1109/ACCESS.2020.2986267
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   Wu Q, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1222, DOI 10.1109/ICMLC.2008.4620591
   Xiao B, 2020, INFORM SCIENCES, V511, P172, DOI 10.1016/j.ins.2019.09.038
   Ye SM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P12
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Zhang RY, 2020, INT CONF ACOUST SPEE, P2982, DOI [10.1109/icassp40776.2020.9054068, 10.1109/ICASSP40776.2020.9054068]
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou BL, 2014, ADV NEUR IN, V27
NR 82
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22611
EP 22628
DI 10.1007/s11042-020-10158-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8O9DW
UT WOS:000926132100001
DA 2024-07-18
ER

PT J
AU Alamgir, FM
   Alam, MS
AF Alamgir, Fakir Mashuque
   Alam, Md Shafiul
TI An artificial intelligence driven facial emotion recognition system
   using hybrid deep belief rain optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Pre-processing; Feature extraction;
   Feature selection; Classification; Optimization
ID FEATURE-EXTRACTION; NETWORK
AB Facial expression recognition is a process of identifying the different facial expressions of the individuals to categorize the mental health of the individual. This system is used in most of the fields but is vastly used in the medical field to identify the mental health issues. In this paper, a novel approach has been proposed to identify the facial expressions of the individuals and categorizing it into seven different emotions. Initially, the images collected from the dataset are subjected to pre-processing for de-noising. Then, the major geometric and appearance-based features are extracted from the images. The most relevant features are selected from the extracted feature set. Finally, based on the selected features, the classification is performed where the input images get labelled into seven different emotions. The classification is carried out with the use of the hybrid strategy called the Deep Belief Rain Optimization (DBRO) technique. The efficiency of the proposed model is proved through the simulations and it is identified to outperform the other existing approaches.
C1 [Alamgir, Fakir Mashuque; Alam, Md Shafiul] Univ Dhaka, Dept Elect & Elect Engn, Dhaka, Bangladesh.
C3 University of Dhaka
RP Alamgir, FM (corresponding author), Univ Dhaka, Dept Elect & Elect Engn, Dhaka, Bangladesh.
EM fma@ewubd.edu
CR ALRESHIDI A, 2020, INFORMATICS MULTIDIS, P1
   Anguraju K, 2020, J CRITIC REV
   Arora M, 2021, MULTIMED TOOLS APPL, V80, P3039, DOI 10.1007/s11042-020-09726-4
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Choudhary D, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), P125, DOI 10.1109/BigMM50055.2020.00027
   Dhiman G, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114150
   Garg D., 2018, IEEE Punecon, P1, DOI 10.1109/PUNECON.2018.8745376
   Graumann L, 2021, J PSYCHIATR RES, V132, P131, DOI 10.1016/j.jpsychires.2020.10.007
   Hassan AK, 2020, DEF TECHNOL, V16, P1062, DOI 10.1016/j.dt.2019.12.006
   Hosny KM, 2020, J DIGIT IMAGING, V33, P1325, DOI 10.1007/s10278-020-00371-9
   Hou N, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8184-3
   Jahanjoo A, 2020, J AMB INTEL HUM COMP, V11, P4145, DOI 10.1007/s12652-020-01690-z
   Jain DK, 2019, PATTERN RECOGN LETT, V120, P69, DOI 10.1016/j.patrec.2019.01.008
   Li B., 2021, International Journal of Cognitive Computing in Engineering, V2, P57
   Li HR, 2020, SWARM EVOL COMPUT, V58, DOI 10.1016/j.swevo.2020.100743
   Liang YH, 2020, INT CONF ASIAN LANG, P1, DOI [10.1109/ialp51396.2020.9310512, 10.1109/IALP51396.2020.9310512]
   Luo JK, 2020, INTELL DATA ANAL, V24, P581, DOI 10.3233/IDA-194641
   Mehendale N, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2234-1
   Mistry K, 2020, 2020 INT JOINT C NEU, P1
   Moazzeni AR, 2020, J PETROL SCI ENG, V195, DOI 10.1016/j.petrol.2020.107512
   Nawaz R, 2020, BIOCYBERN BIOMED ENG, V40, P910, DOI 10.1016/j.bbe.2020.04.005
   Nguyen TD, THESIS QUEENSLAND U, P1
   Patwari, 2020, ARXIV PREPRINT ARXIV, P1
   Rahul Mayur, 2021, Advances in Computational Intelligence and Communication Technology. Proceedings of CICT 2019. Advances in Intelligent Systems and Computing (AISC 1086), P511, DOI 10.1007/978-981-15-1275-9_42
   Saha S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082816
   Sepas-Moghaddam A, 2020, INT CONF ACOUST SPEE, P3367, DOI [10.1109/icassp40776.2020.9053919, 10.1109/ICASSP40776.2020.9053919]
   Siddiqui MFH, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4030046
   Simcock G, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17010330
   Slimani, 2020, INT J ELECTR COMPUT, V10, P4080, DOI DOI 10.11591/IJECE.V10I4.PP4080-4092
   Staff AI, 2022, EUR CHILD ADOLES PSY, V31, P715, DOI 10.1007/s00787-020-01709-y
   Tian Ma, 2020, Mobile Networks and Management. 10th EAI International Conference, MONAMI 2020. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 338), P30, DOI 10.1007/978-3-030-64002-6_3
   Ulusoy SI, 2020, GEN HOSP PSYCHIAT, V65, P9, DOI 10.1016/j.genhosppsych.2020.04.008
   Wang KX, 2020, NEUROCOMPUTING, V398, P257, DOI 10.1016/j.neucom.2020.02.085
   Wang SH, 2018, NEUROCOMPUTING, V272, P668, DOI 10.1016/j.neucom.2017.08.015
   Wieckowski AT, 2020, J AUTISM DEV DISORD, V50, P30, DOI 10.1007/s10803-019-04223-6
   Yang MJ, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/7025403
   Yarasca, 2020, 2020 IEEE ENG INT RE, P1
   Yildirim S, 2021, APPL ACOUST, V173, DOI 10.1016/j.apacoust.2020.107721
   Yin Z, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113768
   Zhou W, 2020, IEEE T CIRCUITS-II, V67, P946, DOI 10.1109/TCSII.2020.2980557
NR 40
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2437
EP 2464
DI 10.1007/s11042-022-13378-x
EA JUN 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000817041800001
DA 2024-07-18
ER

PT J
AU Gupta, A
   Muthiah, SB
AF Gupta, Arpan
   Muthiah, Sakthi Balan
TI Learning cricket strokes from spatial and motion visual word sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cricket stroke; GRU; KMeans; Optical flow; Sports activity recognition;
   Transformer; Visual words
ID ACTION RECOGNITION; PLAYERS
AB There are a number of challenges involved in recognizing actions from Cricket telecast videos, mainly, due to the rapid camera motion, camera switching, and variations in background/foreground, scale, position and viewpoint. Our work deals with the task of trimmed Cricket stroke classification. We used the Cricket Highlights dataset of Gupta and Balan (2020) and manually labeled the 562 trimmed strokes into 5 categories based on the direction of stroke play. These categories are independent of the batsman pose orientations (or handedness) and are useful in determining the outcome of a Cricket stroke. Models trained on our proposed categories can have applications in building player profiles, automated extraction of direction dependent strokes and highlights generation. The Gated Recurrent Unit (GRU) based models were trained on sequences of spatial and motion visual words, obtained by hard(HA) and soft assignment(SA). Extensive set of experiments were carried out on the frame-level dense optical flow grid(OF Grid) features, histogram of oriented optical flow(HOOF), pretrained 2D ResNet and pretrained 3D ResNet extracted features. The training on visual word sequences gives better results as compared to the training on raw feature sequences. Moreover, the soft assignment based word sequences perform better than the hard assignment based sequences of OF Grid features. We present strong baseline results for this new dataset, with the best accuracy of 81.13% on the test set, using soft assignment on optical flow based grid features. We compare our results with Transformer and 2-stream GRU models trained on HA/SA visual words, and 3D convolutional models (C3D/I3D) trained on raw frame sequences.
C1 [Gupta, Arpan; Muthiah, Sakthi Balan] LNM Inst Informat Technol, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
C3 LNM Institute of Information Technology
RP Gupta, A (corresponding author), LNM Inst Informat Technol, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
EM arpan@lnmiit.ac.in; sakthi.balan@lnmiit.ac.in
RI Gupta, Arpan/AGS-4594-2022
OI Gupta, Arpan/0000-0002-9417-3169; Muthiah, Sakthi/0000-0003-1817-7173
CR [Anonymous], 2011, 2011 NAT C COMM NCC
   [Anonymous], 2019, RECENT TRENDS IMAGE
   Bradski G, 2000, DR DOBBS J, V25, P120
   Cai Z, 2018, ARXIV 181209533
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Chung Junyoung, 2014, ARXIV14123555
   Cioppa Anthony, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13123, DOI 10.1109/CVPR42600.2020.01314
   D'Orazio T, 2010, PATTERN RECOGN, V43, P2911, DOI 10.1016/j.patcog.2010.03.009
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deliege A, 2021, IEEE COMPUT SOC CONF, P4503, DOI 10.1109/CVPRW53098.2021.00508
   DGT, About us
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   event veo, VEO SPORTS CAMERA
   Fan Q., 2019, PROC CVPR IEEE
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Faulkner H, 2017 INT C DIGITAL I, P1
   Gourgari S, 2013, IEEE COMPUT SOC CONF, P676, DOI 10.1109/CVPRW.2013.102
   Gupta A, 2020, COMPUTER VISION IMAG, P509, DOI DOI 10.1007/978-981-15-4018-9_45
   Gupta A, 2021, COMPUTER VISION IMAG, P231, DOI DOI 10.1007/2F978-981-16-1092-2021
   Gupta A, 2018, ELEVENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2018), DOI 10.1145/3293353.3293415
   Gupta A, 2020, IMAGE VISION COMPUT, V100, DOI 10.1016/j.imavis.2020.103944
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   HEILBRON FC, 2015, PROC CVPR IEEE, P961, DOI DOI 10.1109/CVPR.2015.7298698
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang X., 2018, IEEE COMPUT SOC CONF
   Hui TW, 2018, PROC CVPR IEEE, P8981, DOI 10.1109/CVPR.2018.00936
   Ibrahim MS, 2016, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2016.217
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W., 2017, ARXIV170506950
   King DB, 2015, ACS SYM SER, V1214, P1
   Kolekar MH, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P382, DOI 10.1109/ICVGIP.2008.102
   Kolekar MH, 2011, MULTIMED TOOLS APPL, V54, P27, DOI 10.1007/s11042-010-0544-9
   Kolekar MH, 2010, MULTIMED TOOLS APPL, V47, P545, DOI 10.1007/s11042-009-0337-1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kulkarni K M, 2021, ARXIV 210409907
   Kumar A, 2014, INT IM PROC APPL SYS, P1, DOI [10.1109/IPAS.2014.7043264, DOI 10.1109/IPAS.2014.7043264, 10.1080/11263504.2013.845268]
   Lazarescu M, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P809, DOI 10.1109/ICME.2002.1035905
   Liu H, 2016, CAAI T INTELL TECHNO, V1, P125, DOI 10.1016/j.trit.2016.10.001
   Liu JC, 2013, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2013.239
   Lu WL, 2013, IEEE T PATTERN ANAL, V35, P1704, DOI 10.1109/TPAMI.2012.242
   Lucas B.D., 1981, IMAGING, V130, P674679
   Moodley Tevin, 2020, Digital Human Modeling and Applications in Health, Safety, Ergonomics and Risk Management. Posture, Motion and Health. 11th International Conference, DHM 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12198), P67, DOI 10.1007/978-3-030-49904-4_5
   Moodley T, 2020, LECT NOTES ELECTR EN, V621, P171, DOI 10.1007/978-981-15-1465-4_18
   Najafzadeh N, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P310, DOI 10.1109/AISP.2015.7123503
   Peng X, 2014, ARXIV 14054506
   Piergiovanni AJ, 2018, IEEE COMPUT SOC CONF, P1821, DOI 10.1109/CVPRW.2018.00226
   pytorch, GRU MODULE TORCH
   pytorch, LANGUAGE MODELING NN
   Quiroga J, 2020, IEEE COMPUT SOC CONF, P3911, DOI 10.1109/CVPRW50498.2020.00455
   Ramanathan V, 2015, ARXIV 151102917
   Ravinder M, 2016, ADV INTELL SYST, V394, P599, DOI 10.1007/978-81-322-2656-7_55
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sankar P, 2006, LECT NOTES COMPUT SC, V4338, P433
   Semwal A, 2018, INT CONF COMPUT
   Sharma R A, 2015, ARXIV 151107607
   Shih HC, 2018, IEEE T CIRC SYST VID, V28, P1212, DOI 10.1109/TCSVT.2017.2655624
   Simonyan K, 2014, ADV NEUR IN, V27
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Soomro K., 2012, ARXIV12120402CS
   Sutskever I, 2014, ADV NEUR IN, V27
   Teachabarikiti K, 2010, I C CONT AUTOMAT ROB, P2491, DOI 10.1109/ICARCV.2010.5707906
   Thomas G, 2017, COMPUT VIS IMAGE UND, V159, P3, DOI 10.1016/j.cviu.2017.04.011
   traceup, TRACE BOT
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Vaswani A, 2017, ADV NEUR IN, V30
   Yan XQ, 2020, ACM T KNOWL DISCOV D, V14, DOI 10.1145/3375394
   Yao A, 2010, LECT NOTES COMPUT SC, V6376, P151
   Zhu GY, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1629, DOI 10.1109/ICME.2006.262859
NR 73
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1237
EP 1259
DI 10.1007/s11042-022-13307-y
EA JUN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000810821800009
DA 2024-07-18
ER

PT J
AU Ming, Y
   Liu, XY
   Shen, G
   Gao, D
   Wang, Y
AF Ming, Yue
   Liu, Xiyuan
   Shen, Gang
   Gao, Di
   Wang, Yu
TI A conditional random field framework for language process in product
   review mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Conditional Random Fields (CRFs); Natural language processing; POS
   tagging; Text mining; HMM; L-BFGS algorithm
AB The Part-Of-Speech tagging is widely used in the natural language process. There are many statistical approaches in this area. The most popular one is Hidden Markov Model. In this paper, an alternative approach, linear-chain Conditional Random Fields, is introduced. The Conditional Random Fields is a factor graph approach that can naturally incorporate arbitrary, non-independent features of the input without conditional independence among the features or distributional assumptions of inputs. This paper applied the Conditional Random Fields for the car review word Part-Of-Speech tagging and then the feature extraction, which can be used as an input to an opinion mining system. To reduce the computational time, we also proposed applying the Limited-memory BFGS algorithm to train the Conditional Random Fields. Furthermore, this paper evaluated the Conditional Random Fields and the classical graph approach using the car review dataset to demonstrate that the Conditional Random Fields have a more robust result with a smaller training dataset.
C1 [Ming, Yue] Syngenta Seeds LLC, Basel, Switzerland.
   [Liu, Xiyuan] Louisiana Tech Univ, Dept Math & Stat, Ruston, LA 71270 USA.
   [Shen, Gang] North Dakota State Univ, Dept Stat, Fargo, ND USA.
   [Gao, Di] Sam Houston State Univ, Dept Math & Stat, Huntsville, TX 77340 USA.
   [Wang, Yu] Texas A&M Univ, Dept Stat, College Stn, TX 77843 USA.
C3 University of Louisiana System; Louisiana Technical University; North
   Dakota State University Fargo; Texas State University System; Sam
   Houston State University; Texas A&M University System; Texas A&M
   University College Station
RP Liu, XY (corresponding author), Louisiana Tech Univ, Dept Math & Stat, Ruston, LA 71270 USA.
EM ming.stat@hotmail.com; liuxyuan@latech.edu
OI liu, xiyuan/0000-0002-0456-7931
CR Azzalini A, 2005, SCAND J STAT, V32, P159, DOI 10.1111/j.1467-9469.2005.00426.x
   Bird S., 2009, NATURAL LANGUAGE PRO
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Jin W, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1195
   Lafferty John, 2001, INT C MACH LEARN ICM
   NOCEDAL J, 1980, MATH COMPUT, V35, P773, DOI 10.1090/S0025-5718-1980-0572855-7
   Qu L, 2008, P NTCIR 7 WORKSH M
   Sutton C, 2012, FOUND TRENDS MACH LE, V4, P267, DOI 10.1561/2200000013
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
NR 9
TC 0
Z9 0
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 803
EP 817
DI 10.1007/s11042-022-13303-2
EA JUN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000808527500002
OA hybrid
DA 2024-07-18
ER

PT J
AU Golalipour, K
AF Golalipour, Keyvan
TI A novel permutation-diffusion technique for image encryption based on
   the Imperialist Competitive Algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Permutation; Coupled map lattice; Imperialist
   Competitive Algorithm
ID HYBRID GENETIC ALGORITHM; MODEL; OPTIMIZATION; SCHEME; MAP
AB Recently, there has been explosive growth in the sharing of images on social media networks. This has occurred primarily because people are using smart phones with high quality imaging facilities and a mobile Internet connection. Accordingly, digital image security has formed a particular focus of recent research. Image encryption is the most common method used to keep images safe during their transmission over the Internet. There are two main phases in image encryption: permutation and diffusion. In this paper, a hybrid model is proposed, which is a combination of a novel permutation technique in conjunction with a new diffusion method. In the permutation phase of the suggested model, pixels are relocated based on their indices. The resulting permuted image has a high difference (more than 99.3%) in the gray level of pixels compared to the corresponding pixels in a plain image. The proposed diffusion method is based on a combination of an Imperialist Competitive Algorithm (ICA) and adjacent lattices as a chaotic function. To date, the ICA, as an evolutionary algorithm, in combination with adjacent lattices, has never been exploited for image encryption. The result analysis demonstrates that the proposed method has excellent resistance against brute force and statistical attacks, in addition to obtaining a 7.9993 entropy score for the encrypted image.
C1 [Golalipour, Keyvan] Islamic Azad Univ, Sari Branch, Dept Comp Engn, Sari, Iran.
C3 Islamic Azad University
RP Golalipour, K (corresponding author), Islamic Azad Univ, Sari Branch, Dept Comp Engn, Sari, Iran.
EM Kgolalipour@gmail.com
OI Golalipour, Keyvan/0000-0001-5405-7465
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Annaby MH, 2016, SIGNAL PROCESS-IMAGE, V49, P25, DOI 10.1016/j.image.2016.09.006
   Atashpaz-Gargari E, 2007, IEEE C EVOL COMPUTAT, P4661, DOI 10.1109/CEC.2007.4425083
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   de Oliveira FB, 2016, EXPERT SYST APPL, V43, P117, DOI 10.1016/j.eswa.2015.08.030
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Enayatifar R, 2013, OPT LASER ENG, V51, P1066, DOI 10.1016/j.optlaseng.2013.03.010
   Fakhrzad MB, 2019, RAIRO-OPER RES, V53, P963, DOI 10.1051/ro/2019018
   Hosseini S, 2014, APPL SOFT COMPUT, V24, P1078, DOI 10.1016/j.asoc.2014.08.024
   Kanso A, 2015, COMMUN NONLINEAR SCI, V24, P98, DOI 10.1016/j.cnsns.2014.12.005
   Laiphrakpam DS, 2017, OPTIK, V147, P88, DOI 10.1016/j.ijleo.2017.08.028
   Lima JB, 2015, SIGNAL PROCESS-IMAGE, V35, P1, DOI 10.1016/j.image.2015.03.005
   Mahmud M, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105818
   Qin C, 2018, INFORM SCIENCES, V465, P285, DOI 10.1016/j.ins.2018.07.021
   Sadaei HJ, 2016, APPL SOFT COMPUT, V40, P132, DOI 10.1016/j.asoc.2015.11.026
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Stallings William, 2012, COMPUTER SECURITY PR
   Talarposhti FM, 2016, INT J APPROX REASON, V70, P79, DOI 10.1016/j.ijar.2015.12.011
   Talarposhti KM, 2016, OPT LASER ENG, V81, P21, DOI 10.1016/j.optlaseng.2016.01.006
   Tao R, 2010, IEEE T INF FOREN SEC, V5, P734, DOI 10.1109/TIFS.2010.2068289
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Vaish A, 2017, OPTIK, V145, P273, DOI 10.1016/j.ijleo.2017.07.041
   Wang HJ, 2017, OPT LASER TECHNOL, V95, P63, DOI 10.1016/j.optlastec.2017.04.019
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yao LL, 2017, OPT LASER ENG, V89, P72, DOI 10.1016/j.optlaseng.2016.06.006
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   Yousefi M, 2012, INT COMMUN HEAT MASS, V39, P1605, DOI 10.1016/j.icheatmasstransfer.2012.10.002
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 34
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 725
EP 746
DI 10.1007/s11042-022-12883-3
EA JUN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000808527600004
DA 2024-07-18
ER

PT J
AU Sneha
   Kaul, A
AF Sneha
   Kaul, Ajay
TI Hyperspectral imaging and target detection algorithms: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral; Spatial; Spectral; Atmospheric correction; Dimensionality
   reduction; Target detection
ID BAND SELECTION METHOD; FEATURE-EXTRACTION; ANOMALY DETECTION; SPARSE
   REPRESENTATION; MATCHED-FILTER; CLASSIFICATION; PROJECTION;
   INTERFERENCE; SPECTROSCOPY; MOUNTAINS
AB Target detection is the field of hyperspectral imaging where the materials or objects of interest are detected from images captured by hyperspectral sensors. This methodology has gained much significance in the area of military and defense, exploration of minerals, monitoring the food quality, and medical science. Various challenges such as errors occurring in the data at the time of image acquisition, data redundancy, and separation of background from desired targets however still exist. So in this study, we have given a brief introduction to hyperspectral imaging and have reviewed various atmospheric corrections, dimensionality reduction, and target detection techniques that help in overcoming these challenges related to hyperspectral data and target detection. Many of the researchers have worked significantly in this area and have acquired desired results by overcoming these challenges. Our review analysis has been approached from the perspectives of the synthetic dataset, public repositories, and developments made in pre-defined algorithms. Further, to percept the scope of the designed algorithms, the achieved results are also presented and compared for further improvements. The review study is presented in Filtering based and Optimization-based detection algorithms. The comparative analysis of various papers states that focus on optimization-based detection algorithms needs to be explored as these have gained much-desired results.
C1 [Sneha; Kaul, Ajay] Shri Mata Vaishno Devi Univ, Comp Sci & Engn Dept, Katra, J&K, India.
C3 Shri Mata Vaishno Devi University
RP Sneha (corresponding author), Shri Mata Vaishno Devi Univ, Comp Sci & Engn Dept, Katra, J&K, India.
EM Sneharaina007@gmail.com; Ajay.kaul@smvdu.ac.in
OI raina, sneha/0000-0002-1085-0119
CR Acito N, 2016, IEEE J-STARS, V9, P2365, DOI 10.1109/JSTARS.2016.2531747
   Adler-Golden S., 1998, FLAASH, a MODTRAN4 atmospheric correction package for hyperspectral data retrievals and simulations, P9
   agc.army.mil, COPPERAS COVE HYDICE
   AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   Akhter MA, 2015, IEEE GEOSCI REMOTE S, V12, P661, DOI 10.1109/LGRS.2014.2355915
   [Anonymous], 2005, ADV NEURAL INF PROCE
   Aspinall R.J., 2002, Journal of Geographical Systems, V4, P15, DOI [10.1007/s101090100071, DOI 10.1007/S101090100071]
   Baldridge AM, 2009, REMOTE SENS ENVIRON, V113, P711, DOI 10.1016/j.rse.2008.11.007
   Belghini N., 2011, INT C INT SYST DAT P, P78
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Ben-Dor E, 2004, REMOTE SENS ENVIRON, V90, P389, DOI 10.1016/j.rse.2004.01.014
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bernstein L.S., 2012, IEEE 4th Workshop on Hyperspectral Image and Signal Processing WHISPERS, P1, DOI DOI 10.1109/WHISPERS.2012.6874311
   Bernstein LS, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.11.111719
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brumbley C, 1999, PATTERN RECOGN, V32, P1161, DOI 10.1016/S0031-3203(98)00150-2
   Bruzzone L, 2000, INT J REMOTE SENS, V21, P549, DOI 10.1080/014311600210740
   Cao XH, 2017, IEEE GEOSCI REMOTE S, V14, P2147, DOI 10.1109/LGRS.2017.2755541
   Carlotto MJ, 2005, IEEE T GEOSCI REMOTE, V43, P374, DOI 10.1109/TGRS.2004.841481
   Chandra B, 2015, IEEE IJCNN
   Chang C. I., 2003, HYPERSPECTRAL IMAGIN
   Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P1575, DOI 10.1109/TGRS.2006.864389
   Chang CI, 1999, IEEE T GEOSCI REMOTE, V37, P2387, DOI 10.1109/36.789637
   Chang CI, 1998, OPT ENG, V37, P735, DOI 10.1117/1.601905
   Chang CI, 2006, IEEE GEOSCI REMOTE S, V3, P63, DOI 10.1109/LGRS.2005.856701
   Chang CI, 1999, IEEE T GEOSCI REMOTE, V37, P2631, DOI 10.1109/36.803411
   Chen Y, 2011, IEEE J-STSP, V5, P629, DOI 10.1109/JSTSP.2011.2113170
   Clark RN., 1988, 3 AIRBORNE IMAGING S, P49
   Conel J.E., 1987, P 3 AIRBORNE IMAGING, P18
   Çukur H, 2015, SIG PROCESS COMMUN, P1769, DOI 10.1109/SIU.2015.7130196
   Devijver P. A., 1982, PATTERN RECOGNITION, V265
   Dick SJ, 2009, NASA HIST
   Ding S., 2009, 2009 International Conference on Computational Intelligence and Software Engineering, P1, DOI [DOI 10.1109/CISE.2009.5366095, DOI 10.1109/ICIECS.2009.5363456, 10.1109/CISE.2009.5366095]
   Dong YN, 2015, IEEE J-STARS, V8, P1830, DOI 10.1109/JSTARS.2015.2416255
   Du JM, 2018, IEEE ACCESS, V6, P45562, DOI 10.1109/ACCESS.2018.2865963
   Du Q, 2008, IEEE GEOSCI REMOTE S, V5, P564, DOI 10.1109/LGRS.2008.2000619
   Du X, 2017, MUUFL GULFPORT HYPER
   Du XP, 2018, OPTIK, V158, P985, DOI 10.1016/j.ijleo.2018.01.001
   Fausett L., 1994, FUNDAMENTALS NEURAL
   Feng J, 2016, IEEE T GEOSCI REMOTE, V54, P6516, DOI 10.1109/TGRS.2016.2585961
   Foster DH, 2019, J OPT SOC AM A, V36, P606, DOI 10.1364/JOSAA.36.000606
   Freitas S, 2019, INT J ADV ROBOT SYST, V16, DOI 10.1177/1729881419842991
   FROST OL, 1972, PR INST ELECTR ELECT, V60, P926, DOI 10.1109/PROC.1972.8817
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Gao BC, 2009, REMOTE SENS ENVIRON, V113, pS17, DOI 10.1016/j.rse.2007.12.015
   Gao JW, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1JRS.8.085094
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P37, DOI 10.1109/MGRS.2017.2762087
   Giannandrea A, 2013, PROC SPIE, V8743, DOI 10.1117/12.2015935
   GOETZ AFH, 1985, SCIENCE, V228, P1147, DOI 10.1126/science.228.4704.1147
   Goldberg H, 2007, PROC SPIE, V6565, DOI 10.1117/12.719932
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P544, DOI 10.1109/TGRS.2015.2461653
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   GREEN AA, 1988, IEEE T GEOSCI REMOTE, V26, P65, DOI 10.1109/36.3001
   Green RO, 1998, REMOTE SENS ENVIRON, V65, P227, DOI 10.1016/S0034-4257(98)00064-9
   Harsanyi J. C., 1993, THESIS U MARYLAND
   HARSANYI JC, 1994, IEEE T GEOSCI REMOTE, V32, P779, DOI 10.1109/36.298007
   Hashjin SS, 2019, IET IMAGE PROCESS, V13, P323, DOI 10.1049/iet-ipr.2018.5324
   He XF, 2004, ADV NEUR IN, V16, P153
   Hu LS, 2018, IEEE ACCESS, V6, P22754, DOI 10.1109/ACCESS.2018.2827403
   Hu P, 2019, IEEE GEOSCI REMOTE S, V16, P452, DOI 10.1109/LGRS.2018.2872540
   HUNT GR, 1977, GEOPHYSICS, V42, P501, DOI 10.1190/1.1440721
   Jensen J.R., 2015, INTRO DIGITAL IMAGE
   Jensen Richard., 2008, COMPUTATIONAL INTELL, DOI 10.1002/9780470377888
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kerekes J, TARGET DETECTION BLI
   Khayam S. A., 2003, Michigan State Univ., V114, P1
   Koshy T., 2004, DISCRETE MATH APPL
   KRUSE FA, 1988, REMOTE SENS ENVIRON, V24, P31, DOI 10.1016/0034-4257(88)90004-1
   Kruse FA, 1993, NASACR192086
   Kumar MV, 2017, INDIAN J GEO-MAR SCI, V46, P1008
   Kuo BC, 2004, IEEE T GEOSCI REMOTE, V42, P1096, DOI 10.1109/TGRS.2004.825578
   Kwon H, 2005, IEEE T GEOSCI REMOTE, V43, P388, DOI 10.1109/TGRS.2004.841487
   Kwon HS, 2003, OPT ENG, V42, P3342, DOI 10.1117/1.1614265
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Landgrebe D. A., 1999, INFORM EXTRACTION PR
   Le JH, 2015, LECT NOTES COMPUT SC, V9474, P682, DOI 10.1007/978-3-319-27857-5_61
   LEE CH, 1993, IEEE T PATTERN ANAL, V15, P388, DOI 10.1109/34.206958
   Leng L., 2012, P INT C WAV AN PATT, P164, DOI DOI 10.1109/ICWAPR.2012.6294772
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2012, 2012 25TH IEEE CANADIAN CONFERENCE ON ELECTRICAL & COMPUTER ENGINEERING (CCECE)
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li F, 2018, IEEE ACCESS, V6, P71632, DOI 10.1109/ACCESS.2018.2879963
   Li J, 2013, IEEE T GEOSCI REMOTE, V51, P4816, DOI 10.1109/TGRS.2012.2230268
   Li J, 2010, IEEE T GEOSCI REMOTE, V48, P4085, DOI 10.1109/TGRS.2010.2060550
   Li YS, 2022, IEEE T IMAGE PROCESS, V31, P1418, DOI 10.1109/TIP.2022.3141843
   Liu YJ, 2017, IEEE T GEOSCI REMOTE, V55, P1967, DOI 10.1109/TGRS.2016.2632863
   Loughlin C, 2020, IEEE J-STARS, V13, P6019, DOI 10.1109/JSTARS.2020.3027155
   Lu RY, 2020, SIGNAL PROCESS, V177, DOI 10.1016/j.sigpro.2020.107737
   Ma JP, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2810, DOI 10.1109/ICMLC.2003.1260030
   Martínez-Usó A, 2006, INT C PATT RECOG, P760
   Mather P.M., 1999, COMPUTER PROCESSING, VSecond
   Matteoli S, 2018, IEEE J-STARS, V11, P1056, DOI 10.1109/JSTARS.2018.2810336
   Matteoli S, 2010, IEEE AERO EL SYS MAG, V25, P5, DOI 10.1109/MAES.2010.5546306
   MAUSEL PW, 1990, PHOTOGRAMM ENG REM S, V56, P55
   McWhorter L., 1996, C RECORD 30 ASILOMAR, V1, P536
   Meerdink SK, 2019, REMOTE SENS ENVIRON, V230, DOI 10.1016/j.rse.2019.05.015
   Miller CJ, 2002, P SOC PHOTO-OPT INS, V4725, P438, DOI 10.1117/12.478777
   Mishra N, 2016, REMOTE SENS ENVIRON, V185, P7, DOI 10.1016/j.rse.2016.07.032
   Mojaradia B, 2008, INT ARCH PHOTOGRAMME, P37
   Nasrabadi NM, 2014, IEEE SIGNAL PROC MAG, V31, P34, DOI 10.1109/MSP.2013.2278992
   Niu YB, 2015, IEEE GEOSCI REMOTE S, V12, P1531, DOI 10.1109/LGRS.2015.2412142
   Pandey S., 2015, Int. J. Current Engin. Technol., V5, P1178
   Pervez W, 2015, INT ARCH PHOTOGRAMM, V40-3, P169, DOI 10.5194/isprsarchives-XL-3-W2-169-2015
   Phillips RD., 2008, P 17 WT PEC MEM REM, P16
   Press W.H., 1990, COMPUT PHYS, V4, P669, DOI [10.1063/1.4822961, DOI 10.1063/1.4822961]
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Qu Z., 2000, P 9 AV EARTH SCI APP, P18
   Ramakrishna B, 2005, P SOC PHOTO-OPT INS, V5806, P772, DOI 10.1117/12.604128
   REED IS, 1990, IEEE T ACOUST SPEECH, V38, P1760, DOI 10.1109/29.60107
   Rezvanian AR, 2020, IRAN CONF ELECTR ENG, P839
   Roberts DA, 1998, REMOTE SENS ENVIRON, V65, P267, DOI 10.1016/S0034-4257(98)00037-6
   ROBEY FC, 1992, IEEE T AERO ELEC SYS, V28, P208, DOI 10.1109/7.135446
   Rodarmel C., 2002, Surveying and Land Information Science, V62, P115, DOI DOI 10.1109/IGARSS.2001.976068
   Rodriguez P, 1999, CONNECT SCI, V11, P5, DOI 10.1080/095400999116340
   Romero A, 2016, IEEE T GEOSCI REMOTE, V54, P1349, DOI 10.1109/TGRS.2015.2478379
   Rubinstein D, 1998, THESIS STANFORD U
   SALISBURY JW, 1992, REMOTE SENS ENVIRON, V42, P157, DOI 10.1016/0034-4257(92)90099-6
   Scholkopf B., 2002, Learning with Kernels
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Shangguan XC, 2022, IEEE T CONTR SYST T, V30, P860, DOI 10.1109/TCST.2021.3070861
   Sharma M, 2021, IEEE J-STARS, V14, P1497, DOI 10.1109/JSTARS.2020.3041316
   Shi YZ, 2021, IEEE T GEOSCI REMOTE, V59, P6894, DOI 10.1109/TGRS.2020.3032528
   Shibi S, 2020, IET IMAGE PROCESS, V14, P3781, DOI 10.1049/iet-ipr.2020.0344
   Smith R., 2008, Smith, R. (2008). Open dynamics engine. http://www.ode.org. 37, 56 Software, R. (2008). Pascal script 3.0. http://www.remobjects.com/ps. 67
   Smith R.B., 2001, Introduction to remote sensing of the environment
   STAMNES K, 1988, APPL OPTICS, V27, P2502, DOI 10.1364/AO.27.002502
   Stein DWJ, 2002, IEEE SIGNAL PROC MAG, V19, P58, DOI 10.1109/79.974730
   Sun K, 2015, IEEE GEOSCI REMOTE S, V12, P998, DOI 10.1109/LGRS.2014.2372071
   Sun K, 2015, IEEE GEOSCI REMOTE S, V12, P329, DOI 10.1109/LGRS.2014.2337957
   Sun WW, 2015, IEEE J-STARS, V8, P2784, DOI 10.1109/JSTARS.2015.2417156
   Sun XT, 2021, IEEE T GEOSCI REMOTE, V59, P4233, DOI 10.1109/TGRS.2020.3024852
   Tan K, 2014, IEEE J-STARS, V7, P40, DOI 10.1109/JSTARS.2013.2265697
   Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49
   Tharwat A, 2017, AI COMMUN, V30, P169, DOI 10.3233/AIC-170729
   Toksöz MA, 2018, IEEE GEOSCI REMOTE S, V15, P1264, DOI 10.1109/LGRS.2018.2835759
   Van Veen B. D., 1988, IEEE ASSP Magazine, V5, P4, DOI 10.1109/53.665
   Wang J., 2005, INT GEOSCIENCE REMOT
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Xie WY, 2020, IEEE T GEOSCI REMOTE, V58, P2015, DOI 10.1109/TGRS.2019.2952091
   Xie WY, 2020, IEEE T GEOSCI REMOTE, V58, P1463, DOI 10.1109/TGRS.2019.2947033
   Xu Y, 2017, IEEE GEOSCI REMOTE S, V14, P554, DOI 10.1109/LGRS.2017.2658666
   Yan YH, 2013, OPTIK, V124, P6341, DOI 10.1016/j.ijleo.2013.06.006
   Yang S, 2016, IEEE T IMAGE PROCESS, V25, P2249, DOI 10.1109/TIP.2016.2545248
   Yang S, 2014, IEEE GEOSCI REMOTE S, V11, P2135, DOI 10.1109/LGRS.2014.2321556
   Yuan ZZ, 2014, IEEE GEOSCI REMOTE S, V11, P1697, DOI 10.1109/LGRS.2014.2306209
   Zeng M, 2019, IEEE GEOSCI REMOTE S, V16, P1889, DOI 10.1109/LGRS.2019.2912170
   Zhai H, 2019, IEEE T GEOSCI REMOTE, V57, P1723, DOI 10.1109/TGRS.2018.2868796
   Zhang C, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20270-y
   Zhang GG, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091489
   Zhang LF, 2014, IEEE T GEOSCI REMOTE, V52, P4955, DOI 10.1109/TGRS.2013.2286195
   Zhang LL, 2019, INFRARED PHYS TECHN, V96, P52, DOI 10.1016/j.infrared.2018.11.015
   Zhang XR, 2018, IEEE J-STARS, V11, P4141, DOI 10.1109/JSTARS.2018.2844873
   Zhang XR, 2019, IET IMAGE PROCESS, V13, P316, DOI 10.1049/iet-ipr.2017.1173
   Zhang Y, 2020, IEEE J-STARS, V13, P2663, DOI 10.1109/JSTARS.2020.2994340
   Zhang YM, 2017, IEEE GEOSCI REMOTE S, V14, P1923, DOI 10.1109/LGRS.2017.2732454
   Zhang YX, 2016, IEEE T GEOSCI REMOTE, V54, P1376, DOI 10.1109/TGRS.2015.2479299
   Zhang YX, 2015, IEEE T GEOSCI REMOTE, V53, P1346, DOI 10.1109/TGRS.2014.2337883
   Zhang YX, 2014, IEEE GEOSCI REMOTE S, V11, P313, DOI 10.1109/LGRS.2013.2257666
   Zhong YF, 2018, APPL SOFT COMPUT, V64, P75, DOI 10.1016/j.asoc.2017.11.045
   Zhu LX, 2019, IEEE GEOSCI REMOTE S, V16, P95, DOI 10.1109/LGRS.2018.2869337
   Zou ZX, 2016, IEEE T GEOSCI REMOTE, V54, P330, DOI 10.1109/TGRS.2015.2456957
NR 161
TC 12
Z9 12
U1 7
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44141
EP 44206
DI 10.1007/s11042-022-13235-x
EA JUN 2022
PG 66
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000804560400002
DA 2024-07-18
ER

PT J
AU Waqar, S
   Khan, UG
   Waseem, MH
   Qayyum, S
AF Waqar, Sahar
   Khan, Usman Ghani
   Waseem, M. Hamza
   Qayyum, Samyan
TI The utility of datasets in crowd modelling and analysis: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd datasets; Crowd analysis; Computer vision; Machine learning
ID REAL-TIME; MOTION; DEPTH
AB Computer Vision-based smart surveillance systems are needed in the present era that can analyse crowd events for behaviour assessment, activity and event recognition, anomaly detection and recognition, crowd density estimation, and counting etc. Even with the human resource available for surveillance of an event, any turn of events can convert a peaceful crowd to a violent one which can cause causalities in no time. Therefore, smart systems need to be introduced which recognizes the behaviour of the crowd and inform the officials beforehand. However, datasets related to the above-mentioned problems are diversely classified. Thus, a need was felt to organize crowd datasets available on the web on their crowd definition, applications, methodologies, and metadata. This paper attempts to do this and gives a comprehensive survey of online publicly available datasets for studying crowd dynamics. It was also observed that available datasets do not cover several important natural events like gate entry and exit surveillance, exit events after religious rituals, and violent activities etc. Some of such events play a crucial role in defining abnormal behaviour. Furthermore, the number of crowd events in some of the available datasets are quite a few and are simulated. To overcome the limitations of the existing datasets, a crowd dataset, named CRUETPAK (CRowd UET PAKistan) is presented. The dataset includes video clips of group and crowd activities related to surveillance, sports, dining, education, and various human interactions (surpassing counts and realism of existing datasets).
C1 [Waqar, Sahar] Univ Engn & Technol, Comp Engn, Lahore, Pakistan.
   [Khan, Usman Ghani; Qayyum, Samyan] Univ Engn & Technol, Comp Sci, Lahore, Pakistan.
   [Waseem, M. Hamza] Univ Engn & Technol, Elect Engn, Lahore, Pakistan.
C3 University of Engineering & Technology Lahore; University of Engineering
   & Technology Lahore; University of Engineering & Technology Lahore
RP Waqar, S (corresponding author), Univ Engn & Technol, Comp Engn, Lahore, Pakistan.
EM sahar.waqar@uet.edu.pk; usman.ghani@uet.edu.pk; hamzawaseem2@yahoo.com;
   samyan.qayyum@uet.edu.pk
FU National ICT RD Fund
FX The project `Automatic Security and Surveillance System for Video
   Sequences' and this research are fully supported by the National ICT R&D
   Fund.
CR Ali S, 2008, LECT NOTES COMPUT SC, V5303, P1, DOI 10.1007/978-3-540-88688-4_1
   Ali S, 2007, PROC CVPR IEEE, P65
   Andrade E.L., 2005, First International Workshop on Crowd Simulation, V3, P71
   Andrade EL, 2006, INT C PATT RECOG, P460
   Andrade EL, 2006, INT C PATT RECOG, P175
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   [Anonymous], 2007, IEEE WORKSH PERF EV
   [Anonymous], 2013, Modeling, Simulation and Visual Analysis of Crowds: A Multidisciplinary Perspective
   Bandini S, 2006, INNOVATIONS DESIGN D
   Bird N, 2006, IEEE INT CONF ROBOT, P3775, DOI 10.1109/ROBOT.2006.1642279
   Blunsden S., 2010, ANN BMVA, V4, P4, DOI DOI 10.5465/19416521003654160
   Brostow GJ, 2006, COMPUTER VISION PATT, V1
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   CHEN K, 2013, PROC CVPR IEEE, P2467, DOI [DOI 10.1109/CVPR.2013.319, 10.1109/CVPR.2013.319]
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Cheriyadat AM, 2008, IEEE J-STSP, V2, P568, DOI 10.1109/JSTSP.2008.2001306
   Courty N, 2007, COMPUT ANIMAT VIRT W, V18, P361, DOI 10.1002/cav.199
   Courty N, 2014, PATTERN RECOGN LETT, V44, P161, DOI 10.1016/j.patrec.2014.01.004
   DAVIES AC, 1995, ELECTRON COMMUN ENG, V7, P37, DOI 10.1049/ecej:19950106
   Ess A, 2009, IEEE INT CONF ROBOT, P4451
   Ess A, 2008, PROC CVPR IEEE, P1857
   Ess A, 2007, IEEE I CONF COMP VIS, P2065
   Ferraro F., 2015, P EMPIRICAL METHODS
   Ferryman J, 2009, PERFORM EVALUATION, P16
   Fisher Robert., 2005, Caviar: Context aware vision using image-based active recognition
   Fruin J. J., 1971, PEDESTRIAN PLANNING
   Hassner T, 2012, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2012.6247842
   Helbing D, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.046109
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Ihaddadene N, 2008, INT C PATT RECOG, P217
   Infodemic, About us
   kics, DATASET CVML CROWD
   Leal-Taix L., 2015, ARXIV PREPRINT ARXIV
   Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Lim MK, 2014, INT C PATT RECOG, P3957, DOI 10.1109/ICPR.2014.678
   Loy CC, 2013, IEEE I CONF COMP VIS, P2256, DOI 10.1109/ICCV.2013.270
   Ma RH, 2004, 2004 IEEE CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS, VOLS 1 AND 2, P170
   MAHADEVAN V, 2010, PROC CVPR IEEE, P1975, DOI DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Possegger H, 2013, PROC CVPR IEEE, P2395, DOI 10.1109/CVPR.2013.310
   Prati A., 2013, INTELLIGENT MULTIMED, DOI [10.1007/978-3-642-41512-8_1, DOI 10.1007/978-3-642-41512-8_1]
   Rodriguez M, 2011, IEEE I CONF COMP VIS, P1235, DOI 10.1109/ICCV.2011.6126374
   Shao J, 2015, PROC CVPR IEEE, P4657, DOI 10.1109/CVPR.2015.7299097
   Shao J, 2014, PROC CVPR IEEE, P2227, DOI 10.1109/CVPR.2014.285
   Jacques JCS, 2007, PATTERN ANAL APPL, V10, P321, DOI 10.1007/s10044-007-0070-1
   Jacques JCS, 2010, IEEE SIGNAL PROC MAG, V27, P66, DOI 10.1109/MSP.2010.937394
   Taylor GR, 2007, PROC CVPR IEEE, P3883
   Thida M., 2013, Intelligent multimedia surveillance, P17, DOI DOI 10.1007/978-3-642-41512-8_2
   Thomas A, 2007, IEEE I CONF COMP VIS, P23
   ViPER, VID PERF EV RES
   Vreugdenhil BJ, 2015, P ISCRAM 2015 C, P24
   Wu XY, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-3, P214, DOI 10.1109/ROBIO.2006.340379
   Zawbaa H, 2012, PREPRINTS
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zhou BL, 2012, PROC CVPR IEEE, P2871, DOI 10.1109/CVPR.2012.6248013
NR 58
TC 3
Z9 3
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43947
EP 43978
DI 10.1007/s11042-022-13227-x
EA MAY 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000802134900004
DA 2024-07-18
ER

PT J
AU Minhas, AA
   Jabbar, S
   Farhan, M
   ul Islam, MN
AF Minhas, Abid Ali
   Jabbar, Sohail
   Farhan, Muhammad
   ul Islam, Muhammad Najam
TI A smart analysis of driver fatigue and drowsiness detection using
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drowsiness detection; Convolutional Neural Networks (CNN); InceptionV3;
   VGG16; ResNet50; Active and sleepy face
ID ACTIVATION FUNCTION; DETECTION SYSTEM
AB Automotive industry experiences multiple injuries in our everyday life. The increasing road accident rate is due to driver drowsiness, such as fatigue and insomnia. This research is intended primarily to diagnose exhaustion and drowsiness, utilizing the deep learning models like convolution neural network. A research project has been initiated in the Kingdom of Saudi Arabia to address the problem of identifying the driver's drowsiness state. In this article, we present a real-time driver disturbance monitoring method using Convolutional Neural Network (CNN). Detection is done using state-of-the-art CNN models such as InceptionV3, VGG16, and ResNet50. We have analyzed that InceptionV3 has 90.70% with 0.6931 loss, the VGG16 has 39.87% with 0.6931 loss, and the ResNet50 has 93.69% accuracy with 0.6931 loss. So, the ResNet50 model has the best accuracy as compared to all other deep learning models. Using sleepy and active human face image collection, we present the output review of the CNN models. We expanded device deployment and performance review of the best-performing CNN model among the evaluated models, utilizing our custom dataset to enhance real-time efficiency. This unique data collection is similar to the driver end scenarios because it includes not just the side view, but also the driver's front view, greatly enhancing the performance. Extending this work into a commodity and its large-scale production will also render a significant contribution to the Kingdom's economy.
C1 [Minhas, Abid Ali] Al Yamamah Univ, Dept Comp Engn, Coll Engn & Architecture, Riyadh, Saudi Arabia.
   [Jabbar, Sohail] Univ Faisalabad, Dept Comp Sci, Faisalabad, Pakistan.
   [Farhan, Muhammad] COMSATS Univ Islamabad, Dept Comp Sci, Sahiwal Campus, Sahiwal, Pakistan.
   [ul Islam, Muhammad Najam] Bahria Univ, Dept Elect Engn, Islamabad, Pakistan.
C3 Al-Yamamah University; COMSATS University Islamabad (CUI)
RP Farhan, M (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Sahiwal Campus, Sahiwal, Pakistan.
EM a_minhas@yu.edu.sa; sjabbar.research@gmail.com; farhansajid@gmail.com;
   najam@bahria.edu.pk
RI Jabbar, Sohail/E-3052-2012; Farhan, Muhammad/F-8071-2011
OI Jabbar, Sohail/0000-0002-2127-1235; Farhan, Muhammad/0000-0002-3649-5717
FU Al Yamamah University, Riyadh, Kingdom of Saudi Arabia
FX This research, including all funds and support for equipment, was fully
   supported by Al Yamamah University, Riyadh, Kingdom of Saudi Arabia.
CR Chang WJ, 2018, IEEE T CONSUM ELECTR, V64, P461, DOI 10.1109/TCE.2018.2872162
   Fu SP, 2020, CIRC SYST SIGNAL PR, V39, P805, DOI 10.1007/s00034-019-01283-y
   Giusti A, 2013, IEEE IMAGE PROC, P4034, DOI 10.1109/ICIP.2013.6738831
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jabbar R., 2020, ARXIV PREPRINT ARXIV
   Jabbar R, 2018, PROCEDIA COMPUT SCI, V130, P400, DOI 10.1016/j.procs.2018.04.060
   Kapoor K, 2020, LECT NOTES ELECTR EN, V605, P280, DOI 10.1007/978-3-030-30577-2_24
   Khan MT, 2019, WIREL COMMUN MOB COM, DOI 10.1155/2019/2036818
   Kundinger T, 2020, INT J PERVASIVE COMP, V16, P1, DOI 10.1108/IJPCC-03-2019-0017
   Kyong Hee Lee, 2019, 2019 21st International Conference on Advanced Communication Technology (ICACT), P710, DOI 10.23919/ICACT.2019.8701928
   Lee KW, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18040957
   LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5
   Li J, 2020, AUTOMAT CONSTR, V109, DOI 10.1016/j.autcon.2019.103000
   Li ZJ, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719872452
   Li ZJ, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061212
   Liu WH, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11050115
   MANN JD, 1970, PLANTA, V92, P285, DOI 10.1007/BF00385095
   Mehta S, 2019, REAL TIME DRIVER DRO
   Minhas AA, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01554-1
   Monteiro ANA, 1996, P NATL ACAD SCI USA, V93, P13595, DOI 10.1073/pnas.93.24.13595
   Ngxande M, 2019, ARXIV PREPRINT ARXIV
   Nissimagoudar P., 2020, COMPUTATIONAL NETWOR, P247, DOI DOI 10.1007/978-981-32-9585-8_21
   Nosseir A, 2020, ADV INTELL SYST COMP, V1027, P141, DOI 10.1007/978-981-32-9343-4_13
   Park S, 2017, LECT NOTES COMPUT SC, V10118, P154, DOI 10.1007/978-3-319-54526-4_12
   Riaz F, 2018, COMPUT NETW, V143, P62, DOI 10.1016/j.comnet.2018.06.007
   Riaz F, 2018, COMPUT ELECTR ENG, V69, P690, DOI 10.1016/j.compeleceng.2018.02.011
   Ross PJ., 1989, Taguchi Techniques for Quality Engineering: Loss Function, Orthogonal Experiments, Parameter and Tolerance Design
   Schmidtmann G, 2012, VISION RES, V62, P44, DOI 10.1016/j.visres.2012.03.001
   Shahverdy M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113240
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Vijayan V, 2019, J INTELL FUZZY SYST, V36, P1977, DOI 10.3233/JIFS-169909
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhou F, 2020, EXPERT SYST APPL, V147, DOI 10.1016/j.eswa.2020.113204
NR 34
TC 3
Z9 3
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26969
EP 26986
DI 10.1007/s11042-022-13193-4
EA MAY 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000805509400005
DA 2024-07-18
ER

PT J
AU Hamdi, Y
   Akouaydi, H
   Boubaker, H
   Alimi, AM
AF Hamdi, Yahia
   Akouaydi, Hanen
   Boubaker, Houcine
   Alimi, Adel M.
TI Handwriting quality analysis using online-offline models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-lingual Handwriting quality analysis; Beta-Elliptic Model; Fourier
   Descriptor model; CNN; SVM
AB This work is part of an innovative e-learning project allowing the development of an advanced digital educational tool that provides feedback during the process of learning handwriting for young school children (three to eight years old). In this paper, we describe a new method for children handwriting quality analysis. It automatically detects mistakes, gives real-time on-line feedback for children's writing, and helps teachers comprehend and evaluate children's writing skills. The proposed method adjudges five main criteria: shape, direction, stroke order, position respect to the reference lines, and kinematics of the trace. It analyzes the handwriting quality and automatically gives feedback based on the combination of three extracted models: Beta-Elliptic Model (BEM) using similarity detection (SD) and dissimilarity distance (DD) measure, Fourier Descriptor Model (FDM), and perceptive Convolutional Neural Network (CNN) with Support Vector Machine (SVM) comparison engine. The originality of our work lies partly in the system architecture which apprehends complementary dynamic, geometric, and visual representation of the examined handwritten scripts and in the efficient selected features adapted to various handwriting styles and multiple script languages such as Arabic, Latin, digits, and symbol drawing. The application offers two interactive interfaces respectively dedicated to learners, educators, experts or teachers and allows them to adapt it easily to the specificity of their disciples. The evaluation of our framework is enhanced by a database collected in Tunisia primary school with 400 children. Experimental results show the efficiency and robustness of our suggested framework that helps teachers and children by offering positive feedback throughout the handwriting learning process using tactile digital devices.
C1 [Hamdi, Yahia; Akouaydi, Hanen; Boubaker, Houcine; Alimi, Adel M.] Univ Sfax, ENIS, REGIM Lab REs Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
   [Alimi, Adel M.] Univ Johannesburg, Fac Engn & Built Environm, Dept Elect & Elect Engn Sci, Johannesburg, South Africa.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   University of Johannesburg
RP Hamdi, Y (corresponding author), Univ Sfax, ENIS, REGIM Lab REs Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
EM yahia.hamdi@regim.usf.tn; hanen.akouaydi@regim.usf.tn;
   houcine.boubaker@regim.usf.tn; adel.alimi@regim.usf.tn
RI Hamdi, Yahia/HKE-8065-2023
OI Hamdi, Yahia/0000-0003-2999-139X
FU Ministry of Higher Education and Scientific Research of Tunisia
   [LR11ES4]
FX This study was funded by the Ministry of Higher Education and Scientific
   Research of Tunisia (grant number LR11ES4).
CR Accardo AP, 2013, HUM MOVEMENT SCI, V32, P136, DOI 10.1016/j.humov.2012.10.004
   Alimi AM, 1997, PROC INT CONF DOC, P382, DOI 10.1109/ICDAR.1997.619875
   [Anonymous], 2013, KINDERGARTENS TEACHI
   Bezine H, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P515, DOI 10.1109/IWFHR.2004.45
   Bonneton-Botté N, 2020, COMPUT EDUC, V151, DOI 10.1016/j.compedu.2020.103831
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Boubaker H., 2013, INT J COMPUTER SCI I, V10, P57
   Dhieb T., 2019, Computer Methods in Biomechanics and Biomedical Engineering, V22, P188, DOI 10.1080/10255842.2020.1714235
   Dhieb T, 2016, J INF ASSUR SECUR, V11, P263
   Dinehart LH, 2015, J EARLY CHILD LIT, V15, P97, DOI 10.1177/1468798414522825
   Falk TH, 2011, COMPUT METH PROG BIO, V104, pE102, DOI 10.1016/j.cmpb.2010.12.010
   Fan Y, 2019, P ACM MULTIMEDIA ASI
   Guinet E, 2010, BEHAV RES METHODS, V42, P326, DOI 10.3758/BRM.42.1.326
   Hamdi Yahia, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P545, DOI 10.1109/ICDAR.2019.00093
   Hamdi Y., 2021, P EN MACH LEARN APPL, P281, DOI [10.1007/978-981-33-6129-4_20, DOI 10.1007/978-981-33-6129-4_20]
   Hamdi Y, 2021, LECT NOTES COMPUT SC, V12916, P379, DOI 10.1007/978-3-030-86198-8_27
   Hamdi Y, 2021, INT J DOC ANAL RECOG, V24, P283, DOI 10.1007/s10032-021-00376-2
   Hu Z-H., 2009, J SOFTW, V101, P107
   Krichen O, 2021, LECT NOTES COMPUT SC, V12916, P125, DOI 10.1007/978-3-030-86198-8_10
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu Jun, 2019, IEEE T PATTERN ANAL IEEE T PATTERN ANAL, P02
   McAuley JH, 2000, BRAIN, V123, P1545, DOI 10.1093/brain/123.8.1545
   PERSOON E, 1986, IEEE T PATTERN ANAL, V8, P388, DOI 10.1109/TPAMI.1986.4767799
   Plamondon R, 2014, PATTERN RECOGN LETT, V35, P225, DOI 10.1016/j.patrec.2012.06.004
   Platt JC, 2000, ADV NEUR IN, P61
   Rabhi B, 2021, MEMET COMPUT, V13, P459, DOI 10.1007/s12293-021-00345-6
   Rosenblum S, 2003, EDUC PSYCHOL REV, V15, P41, DOI 10.1023/A:1021371425220
   Sen Shibaprasad, 2018, Intelligent Engineering Informatics. Proceedings of the 6th International Conference on FICTA. Advances in Intelligent Systems and Computing (AISC 695), P413, DOI 10.1007/978-981-10-7566-7_40
   Simonnet D, 2019, PATTERN RECOGN LETT, V121, P133, DOI 10.1016/j.patrec.2018.07.021
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wu YC, 2017, PATTERN RECOGN, V65, P251, DOI 10.1016/j.patcog.2016.12.026
   Xie Z, 2017, IEEE T PAMI
   Zhang XY, 2017, PATTERN RECOGN, V61, P348, DOI 10.1016/j.patcog.2016.08.005
NR 34
TC 2
Z9 2
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43411
EP 43439
DI 10.1007/s11042-022-13228-w
EA MAY 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800967900001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Si, YZ
   Yang, F
   Chong, NN
AF Si, Yazhong
   Yang, Fan
   Chong, Nannan
TI A novel method for single nighttime image haze removal based on gray
   space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nighttime image dehazing; Gray space; Convolutional neural network;
   Feature fusion; Color consistency
AB Nighttime haze images always suffer from non-uniform illumination from artificial light sources, and most of the current dehazing algorithms are more suitable for daytime image haze removal than nighttime. In this paper, we propose a novel method for nighttime image dehazing via gray space. Firstly, we mapped the haze image from RGB color space to gray space and adopted convolutional neural network to obtain the feature distribution map of the haze. We then fused the haze feature distribution map with original image to obtain the initial haze-free image. Finally, the value and chroma of the initial haze-free image were enhanced in HSV space by improved gamma function. Extensive experiments demonstrate that the proposed method outperforms the state-of-the-art algorithms for nighttime image haze removal, especially in terms of color consistency and artifacts reduction.
C1 [Si, Yazhong; Yang, Fan] Hebei Univ Technol, Sch Elect & Informat Engn, Tianjin 300401, Peoples R China.
   [Chong, Nannan] Tianjin Univ, Sch Informat & Commun Engn, Renai Coll, Tianjin 301600, Peoples R China.
C3 Hebei University of Technology; Tianjin University
RP Si, YZ (corresponding author), Hebei Univ Technol, Sch Elect & Informat Engn, Tianjin 300401, Peoples R China.
EM siyazhong123@163.com; yangfan@hebut.cdu.cn; chongnannan@163.com
RI si, yazhong/JDW-4576-2023; Yang, Fan/GRJ-6470-2022
OI Si, Yazhong/0000-0002-4454-1605
FU National Key Research and Development Project of China [2019YFB1312102];
   Natural Science Foundation of Hebei Province [F2019202364]; Scientific
   Research Project of Tianjin Municipal Commission of Education
   [2018KJ268]
FX This work is supported by the National Key Research and Development
   Project of China(2019YFB1312102), the Natural Science Foundation of
   Hebei Province(F2019202364) and the Scientific Research Project of
   Tianjin Municipal Commission of Education (No. 2018KJ268).
CR Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cai Z, 2021, EUROGRAPHICS 2021 SH
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong J, 2020, EUR C COMP VIS
   Dong Y, 2020, AAAI CONF ARTIF INTE, V34, P10729
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Golts A, 2020, IEEE T IMAGE PROCESS, V29, P2692, DOI 10.1109/TIP.2019.2952032
   Haoran Xu, 2012, 2012 IEEE International Conference on Information Science and Technology, P663, DOI 10.1109/ICIST.2012.6221729
   He J, 2019, ARXIV PREPRINT ARXIV
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hou GJ, 2018, IET IMAGE PROCESS, V12, P292, DOI 10.1049/iet-ipr.2017.0359
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Khan H, 2020, NEUROCOMPUTING, V381, P141, DOI 10.1016/j.neucom.2019.10.005
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li H, 2017, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2017.560
   Li XJ, 2020, IEEE ACCESS, V8, P197448, DOI 10.1109/ACCESS.2020.3034275
   Li Y, 2015, IEEE I CONF COMP VIS, P226, DOI 10.1109/ICCV.2015.34
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu XJ, 2019, IEEE I CONF COMP VIS, P2611, DOI 10.1109/ICCV.2019.00270
   Liu Y, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107986
   Liu Zhi-cheng, 2016, Transactions of Beijing Institute of Technology, V36, P191, DOI 10.15918/j.tbit1001-0645.2016.02.016
   McCartney E. J., 1976, Optics of the atmosphere. Scattering by molecules and particles
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Ning X, 2017, IEICE T INF SYST, VE100D, P211, DOI 10.1587/transinf.2016EDL8180
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Tang QF, 2021, COMPUT VIS IMAGE UND, V202, DOI 10.1016/j.cviu.2020.103086
   Wei XY, 2021, MULTIMED TOOLS APPL, V80, P33747, DOI 10.1007/s11042-021-11230-2
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang J, 2017, PROC CVPR IEEE, P5226, DOI 10.1109/CVPR.2017.555
   Zhang J, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2355, DOI 10.1145/3394171.3413763
   Zhang J, 2014, IEEE IMAGE PROC, P4557, DOI 10.1109/ICIP.2014.7025924
   Zhang W, 2021, IEEE J OCEANIC ENG, P118
   Zhang Y, 2021, COMPUT GRAPH FORUM, V40, P179, DOI 10.1111/cgf.142624
   Zhou JJ, 2013, 2013 2ND INTERNATIONAL SYMPOSIUM ON INSTRUMENTATION AND MEASUREMENT, SENSOR NETWORK AND AUTOMATION (IMSNA), P243, DOI 10.1109/IMSNA.2013.6743260
NR 41
TC 3
Z9 3
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43467
EP 43484
DI 10.1007/s11042-022-13237-9
EA MAY 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800967900003
DA 2024-07-18
ER

PT J
AU Liu, SM
   Yang, HM
   Pan, JS
   Liu, T
   Yan, B
AF Liu, Shu-Mei
   Yang, Hong-Mei
   Pan, Jeng-Shyang
   Liu, Tao
   Yan, Bin
TI A novel perfect contrast XOR-based visual cryptography scheme for
   multiple secrets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography scheme; Multiple secret images; XOR; Basic matrix
AB Visual cryptography scheme (VCS) is a kind of secret sharing scheme that only relies on human visual system (HVS) without complicated calculation. In this paper, a novel visual cryptography scheme for multiple secrets is proposed which hides n - 1 (n is odd) secret images by n shares and can fully recover secret images by XOR. In this scheme, each share is divided into n regions and then basic matrices are designed for different regions. The basic matrix of each region is determined by one or two specific secret images. When any m (m is even) shares are acquired, m secret images can be obtained by XOR. In this way, when interceptors do not obtain n - 1 shares, they will mistakenly think that they have obtained all the secret images and reduce the suspicion to give up further interception. Only when the receiver obtains any n - 1 shares for XOR operation, it can get n - 1 complete recovered secret images. The final regions of the secret images will be different with different selected sharing group. The experiment proves that when n takes an odd value, no secret image can be obtained from any odd shares and this scheme has good security. In addition, this paper also analyzes the case that n is even, and gives the suitable solution. The new solution proves the flexibility and scalability of the scheme.
C1 [Liu, Shu-Mei; Yang, Hong-Mei; Pan, Jeng-Shyang; Liu, Tao] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
   [Yan, Bin] Shandong Univ Sci & Technol, Coll Elect & Informat Engn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Yang, HM (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
EM liusm@sdust.edu.cn; yanghongmei@sdust.edu.cn; jspan@cc.kuas.edu.tw;
   taoliu0201@sdust.edu.cn; yanbinhit@sdust.edu.cn
RI Pan, Jeng-Shyang/AEO-3450-2022
OI Pan, Jeng-Shyang/0000-0002-3128-9025
FU MOE (Ministry of Education in China) Project of Humanities and Social
   Sciences [18YJAZH110]; Shandong Provincial Natural Science Foundations
   [ZR2014JL044, ZR202102220198]
FX This work is supported by MOE (Ministry of Education in China) Project
   of Humanities and Social Sciences (Project No. 18YJAZH110) and Shandong
   Provincial Natural Science Foundations (No. ZR2014JL044, NO.
   ZR202102220198), China.
CR [Anonymous], 1994, WORKSH THEOR APPL CR
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Fu ZX, 2019, MULTIMED TOOLS APPL, V78, P2367, DOI 10.1007/s11042-018-6364-z
   Hou YC, 2014, IEEE T CIRC SYST VID, V24, P733, DOI 10.1109/TCSVT.2013.2280097
   Krishnamoorthy S., 2011, Proceedings 2011 12th International Symposium on Quality Electronic Design (ISQED 2011), DOI 10.1109/ISQED.2011.5770770
   Li P, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102911
   Li P, 2020, IEEE ACCESS, V8, P32840, DOI 10.1109/ACCESS.2020.2973659
   Lin CC, 2003, PATTERN RECOGN LETT, V24, P349, DOI 10.1016/S0167-8655(02)00259-3
   Liu LT, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102971
   Shamir A., 1979, Communications of the ACM, V22, P612, DOI 10.1145/359168.359176
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   Shivani S, 2018, PATTERN ANAL APPL, V21, P139, DOI 10.1007/s10044-016-0571-x
   Socek D, 2005, FIRST INTERNATIONAL CONFERENCE ON SECURITY AND PRIVACY FOR EMERGING AREAS IN COMMUNICATIONS NETWORKS, PROCEEDINGS, P406, DOI 10.1109/SECURECOMM.2005.39
   Wang L, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13010065
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Weir, 2009, SHARING MULTIPLE SEC
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Xiong LZ, 2021, SIGNAL PROCESS, V185, DOI 10.1016/j.sigpro.2021.108064
   Yan B, 2019, IEEE T IMAGE PROCESS, V28, P896, DOI 10.1109/TIP.2018.2874378
   Yan XH, 2016, MULTIMED TOOLS APPL, V75, P8657, DOI 10.1007/s11042-015-2779-y
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P3231, DOI 10.1007/s11042-013-1784-2
   Yang CN, 2014, INFORM SCIENCES, V278, P141, DOI 10.1016/j.ins.2014.03.033
   Yang CN, 2014, INFORM SCIENCES, V271, P246, DOI 10.1016/j.ins.2014.02.099
   Yang CN, 2014, IEEE T CIRC SYST VID, V24, P189, DOI 10.1109/TCSVT.2013.2276708
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 26
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43125
EP 43143
DI 10.1007/s11042-022-13187-2
EA MAY 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800825900003
DA 2024-07-18
ER

PT J
AU Liang, SD
   Yan, WQ
AF Liang, Sendong
   Yan, Wei Qi
TI A hybrid CTC plus Attention model based on end-to-end framework for
   multilingual speech recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech recognition; End-to-end framework; Attention model; CTC model;
   Code-Switch
AB Speech recognition is an important field in natural language processing. In this paper, the end-to-end framework for speech recognition with multilingual datasets is proposed. The end-to-end methods do not require complicated alignment and construction of the pronunciation dictionary, which show a promising prospect. In this paper, we implement a hybrid model of CTC and attention (CTC+Attention) model based on PyTorch. In order to compare speech recognition methods for multiple languages, we design and create three datasets: Chinese, English, and Code-Switch. We evaluate the proposed hybrid CTC+Attention model in multilingual environment. Throughout our experiments, we find that the proposed hybrid CTC+Attention model based on end-to-end framework achieves better performance compared with the HMM-DNN model in a single language and Code-Switch speaking environment. Moreover, the results of speech recognition with regard to different languages are compared in this paper. The CER(i.e., Character Error Rate) of the proposed hybrid CTC+Attention model based on the Chinese dataset defeated the traditional model and reached 10.22%.
C1 [Liang, Sendong; Yan, Wei Qi] Auckland Univ Technol, Sch Engn Comp & Math, 31 Symonds St, Auckland 1010, New Zealand.
C3 Auckland University of Technology
RP Yan, WQ (corresponding author), Auckland Univ Technol, Sch Engn Comp & Math, 31 Symonds St, Auckland 1010, New Zealand.
EM ghg0412@autuni.ac.nz; weiqi.yan@aut.ac.nz
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Abdel-Hamid O, 2012, INT CONF ACOUST SPEE, P4277, DOI 10.1109/ICASSP.2012.6288864
   [Anonymous], 2009, NIPS WORKSH DEEP LEA
   [Anonymous], 2015, Listen, attend and spell
   Boden Mikael, 2002, the Dallas project
   Chan JYC, 2004, 2004 International Symposium on Chinese Spoken Language Processing, Proceedings, P293
   Chiu C.-C., 2017, MONOTONIC CHUNKWISE
   Eyben F, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P376, DOI 10.1109/ASRU.2009.5373257
   Georgescu AL, 2019, INT C SPEECH TECHN H, P16
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   iFLYTEK Co. Ltd., 2020, ONL TTS WEBAPI
   Jason CA., 2020, LANGUAGE, V67, P68
   Kim S, 2017, INT CONF ACOUST SPEE, P4835, DOI 10.1109/ICASSP.2017.7953075
   Li B, 2020, INT CONF ACOUST SPEE, P6069, DOI [10.1109/icassp40776.2020.9054715, 10.1109/ICASSP40776.2020.9054715]
   Li JY, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P114, DOI [10.1109/ASRU46091.2019.9003906, 10.1109/asru46091.2019.9003906]
   Liang S., 2021, THESIS AUCKLAND U TE
   Lin C.-H., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P227, DOI 10.1109/ICASSP.1993.319276
   Liu ZY, 2019, LECT NOTES COMPUT SC, V11955, P522, DOI 10.1007/978-3-030-36718-3_44
   Long LK, 2022, FOOD ANAL METHOD, V15, P294, DOI 10.1007/s12161-021-02104-2
   Maas AL, 2017, COMPUT SPEECH LANG, V41, P195, DOI 10.1016/j.csl.2016.06.007
   Manaswi N. K., 2018, DEEP LEARNING APPL U, DOI [DOI 10.1007/978-1-4842-3516-4_2, 10.1007/978-1-4842-3516-42]
   Mansikkaniemi A, 2010, THESIS AALTO U
   Miao YJ, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P167, DOI 10.1109/ASRU.2015.7404790
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Moritz N, 2019, INT CONF ACOUST SPEE, P5666, DOI 10.1109/ICASSP.2019.8683510
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Passricha V, 2020, J INTELL SYST, V29, P1261, DOI 10.1515/jisys-2018-0372
   Petridis S, 2018, IEEE W SP LANG TECH, P513, DOI 10.1109/SLT.2018.8639643
   Povey D., 2011, IEEE 2011 WORKSH AUT
   Qu Z, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P173, DOI 10.1109/ASRU.2017.8268932
   Senior A, 2015, INT CONF ACOUST SPEE, P4585, DOI 10.1109/ICASSP.2015.7178839
   Shi FF, 2012, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION APPLICATIONS (ICCIA 2012), P627
   Smit P, 2021, COMPUT SPEECH LANG, V66, DOI 10.1016/j.csl.2020.101158
   Sundermeyer M, 2013, INT CONF ACOUST SPEE, P8430, DOI 10.1109/ICASSP.2013.6639310
   TAL Education Group, 2019, TAL CS AUT SPEECH RE
   Ueno S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5804, DOI 10.1109/ICASSP.2018.8462576
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang D, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11081018
   Wang W., 2020, ARXIV
   Watanabe S, 2018, INTERSPEECH, P2207, DOI 10.21437/Interspeech.2018-1456
   WOODLAND PC, 1994, INT CONF ACOUST SPEE, P125
   Wu CH, 2014, IEEE-ACM T AUDIO SPE, V22, P858, DOI 10.1109/TASLP.2014.2310353
   Zenkel T., 2017, ARXIV
   Zheng Y., 2020, ARXIV
NR 43
TC 3
Z9 3
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 41295
EP 41308
DI 10.1007/s11042-022-12136-3
EA MAY 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000801074900001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Li, L
   Gao, JQ
   Ge, HW
   Zhang, YX
   Zhang, HF
AF Li, Li
   Gao, Jianqiang
   Ge, Hongwei
   Zhang, Yixin
   Zhang, Haifei
TI An effective feature extraction method via spectral-spatial filter
   discrimination analysis for hyperspectral image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image; Feature extraction; Harmonic mean; Feature space
   discriminant analysis; Classification
ID SUPPORT VECTOR REGRESSION; EMPIRICAL MODE DECOMPOSITION; DIMENSIONALITY
   REDUCTION; CLASSIFICATION; ALGORITHM; NOISE
AB Multi band, high spatial resolution and information redundancy are the most significant characteristics of hyperspectral image. These remarkable characteristics are mainly caused by the high-dimensional image data. In view of these characteristics, feature extraction of hyperspectral image has naturally become one of the research hotspots in this field. However, it is impossible to fully describe the intrinsic geometric structure of hyperspectral image only by using spectral information. To improve the subsequent forecasting accuracy, spatial information should be mined to further describe the geometric structure of hyper-spectral image. Therefore, an effective feature extraction method (SSF_HM) was proposed via using harmonic mean and spectral-spatial filter. This investigation divides the SSF_HM into three steps. First, the p(i) principal components were extracted by using principal components analysis (PCA) skill and subsequent the p(i) spatial filtering features were obtained via using area median filter (AMF) method. Then, the original spectral features and extracted spatial filtering features combine to form the fusion feature matrix, and then the scatter matrix S-b(HM) (based on harmonic mean (HM) spectral-spatial filter inter-class) and scatter matrix S-w(HM) (based on harmonic mean (HM) spectral-spatial filter intra-class) can be established in the fusion feature space, respectively. Finally, combining the Fisher discriminant analysis model and regularization technique, a new feature extraction method SSF_HM is developed. The proposed SSF_HM method combines spectral information and spatial information. At the same time, the range of feature extraction is expanded from spectral space to spectral-spatial fusion space. The experimental results on three real-world hyperspectral image data sets show the better performance of SSF_HM in comparison with other feature extraction methods in small sample size situation by using maximum likelihood classifier (MLC).
C1 [Li, Li; Gao, Jianqiang] Jining Med Univ, Sch Med Informat Engn, Rizhao 276826, Shandong, Peoples R China.
   [Li, Li; Ge, Hongwei; Zhang, Yixin; Zhang, Haifei] Jiangnan Univ, Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jining Medical University; Jiangnan University
RP Gao, JQ (corresponding author), Jining Med Univ, Sch Med Informat Engn, Rizhao 276826, Shandong, Peoples R China.
EM liliiot@163.com; gaojianqiang@mail.jnmc.edu.cn; ghw8601@163.com;
   zyx@jiangnan.edu.cn
OI Gao, Jianqiang/0000-0002-1989-4943
FU Doctoral Research Foundation of Jining Medical University [2018JYQD03];
   Doctoral Research Foundation of Jining Medical University; Project of
   Shandong Province Higher Educational Science and Technology Program,
   China [J18KA217]
FX This work is partly supported by the Doctoral Research Foundation of
   Jining Medical University under Grant No.2018JYQD03, and the Doctoral
   Research Foundation of Jining Medical University for Dr. Li Li, and a
   Project of Shandong Province Higher Educational Science and Technology
   Program under Grant No.J18KA217, China.
CR Aït-Sahalia Y, 2019, J AM STAT ASSOC, V114, P287, DOI 10.1080/01621459.2017.1401542
   Bi ZQ, 2021, INT J MACH LEARN CYB, V12, P3069, DOI 10.1007/s13042-020-01185-5
   Cai D, 2007, IEEE C COMP VIS ICCV, P1, DOI DOI 10.1109/CVPR.2007.383054
   Chang CI, 2011, PATTERN RECOGN, V44, P2760, DOI 10.1016/j.patcog.2011.03.030
   Chang CI, 2000, IEEE T GEOSCI REMOTE, V38, P1044, DOI 10.1109/36.841984
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Chen SG, 2011, IEEE GEOSCI REMOTE S, V8, P369, DOI 10.1109/LGRS.2010.2076407
   Chen TT, 2019, IEEE ACCESS, V7, P150960, DOI 10.1109/ACCESS.2019.2946980
   ELTON E.J., 2011, Modern portfolio theory and investment analysis-international student version
   Fabija n ska A., 2011, IET IMAGE PROCESS, V5, P480, DOI [10.1049/iet-ipr.2009.0178, DOI 10.1049/IET-IPR.2009.0178]
   Fan GF, 2016, NEUROCOMPUTING, V173, P958, DOI 10.1016/j.neucom.2015.08.051
   Fauvel M, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/783194
   Gao JQ, 2016, NEURAL PROCESS LETT, V43, P805, DOI 10.1007/s11063-015-9447-0
   Gao JQ, 2016, NEURAL COMPUT APPL, V27, P431, DOI 10.1007/s00521-015-1862-7
   Gao JQ, 2015, EURASIP J ADV SIG PR, P1, DOI 10.1186/s13634-015-0223-0
   Gao JQ, 2015, AEU-INT J ELECTRON C, V69, P198, DOI 10.1016/j.aeue.2014.09.001
   Gao JQ, 2014, APPL MATH COMPUT, V228, P531, DOI 10.1016/j.amc.2013.12.001
   Gao WJ, 2019, COMPUT INTELL-US, V35, P496, DOI 10.1111/coin.12202
   Ghamisi P, 2014, IEEE T GEOSCI REMOTE, V52, P5771, DOI 10.1109/TGRS.2013.2292544
   Guo AJX, 2019, IEEE T GEOSCI REMOTE, V57, P1755, DOI 10.1109/TGRS.2018.2869004
   He X, 2005, 10 IEEE INT C COMPUT, V2
   He XF, 2004, ADV NEUR IN, V16, P153
   Hong WC, 2011, ENERGY, V36, P5568, DOI 10.1016/j.energy.2011.07.015
   Hosseini SA, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416500014
   Hosseini SA, 2016, REMOTE SENS LETT, V7, P101, DOI 10.1080/2150704X.2015.1101180
   Ibrahim H, 2008, IEEE T CONSUM ELECTR, V54, P1920, DOI 10.1109/TCE.2008.4711254
   Imani M, 2015, ISPRS J PHOTOGRAMM, V102, P1, DOI 10.1016/j.isprsjprs.2014.12.024
   Jiang J, 2018, IEEE T GEOSCI REMOTE, P113
   Journaux L, 2006, 2006 7TH NORDIC SIGNAL PROCESSING SYMPOSIUM, P242
   Kuo BC, 2004, IEEE T GEOSCI REMOTE, V42, P1096, DOI 10.1109/TGRS.2004.825578
   Landgrebe D, 2002, IEEE SIGNAL PROC MAG, V19, P17, DOI 10.1109/79.974718
   Landgrebe D.A., 2005, SIGNAL THEORY METHOD
   Li L, 2020, NEURAL PROCESS LETT, V51, P515, DOI 10.1007/s11063-019-10101-0
   Li L, 2019, NEURAL PROCESS LETT, V49, P357, DOI 10.1007/s11063-018-9825-5
   Li L, 2017, ADV SPACE RES, V59, P954, DOI 10.1016/j.asr.2016.11.006
   Li MW, 2019, NONLINEAR DYNAM, V97, P2579, DOI 10.1007/s11071-019-05149-5
   Liao WZ, 2013, IEEE T GEOSCI REMOTE, V51, P184, DOI 10.1109/TGRS.2012.2200106
   Ou DP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060654
   Park CH, 2008, PATTERN RECOGN, V41, P1083, DOI 10.1016/j.patcog.2007.07.022
   Plaza A, 2005, IEEE T GEOSCI REMOTE, V43, P466, DOI 10.1109/TGRS.2004.841417
   Ren JC, 2014, IEEE SIGNAL PROC MAG, V31, P149, DOI 10.1109/MSP.2014.2312071
   Sugiyama M, 2010, MACH LEARN, V78, P35, DOI 10.1007/s10994-009-5125-7
   Tarabalka Y, 2009, IEEE T GEOSCI REMOTE, V47, P2973, DOI 10.1109/TGRS.2009.2016214
   Wang M, 2017, 2017 IEEE INT C ACOU
   Wei-Chiang H., 2013, ELECT POWER ENERGY S, V44, P614, DOI [10.1016/j.ijepes.2012.08.010, DOI 10.1016/J.IJEPES.2012.08.010]
   Xia JS, 2014, IEEE GEOSCI REMOTE S, V11, P239, DOI 10.1109/LGRS.2013.2254108
   Xiao JS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419842
   Zabalza J, 2014, ISPRS J PHOTOGRAMM, V93, P112, DOI 10.1016/j.isprsjprs.2014.04.006
   Zhang LF, 2019, INFORM SCIENCES, V485, P154, DOI 10.1016/j.ins.2019.02.008
   Zhang TH, 2007, NEUROCOMPUTING, V70, P1547, DOI 10.1016/j.neucom.2006.11.007
   Zhang ZC, 2020, NEUROCOMPUTING, V410, P185, DOI 10.1016/j.neucom.2020.05.075
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   Zhang ZC, 2019, ENG APPL ARTIF INTEL, V85, P254, DOI 10.1016/j.engappai.2019.06.017
   Zhou YC, 2015, IEEE T GEOSCI REMOTE, V53, P1082, DOI 10.1109/TGRS.2014.2333539
NR 54
TC 3
Z9 3
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40871
EP 40904
DI 10.1007/s11042-022-13121-6
EA MAY 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000795177800003
DA 2024-07-18
ER

PT J
AU Nozaripour, A
   Soltanizadeh, H
AF Nozaripour, Ali
   Soltanizadeh, Hadi
TI Discriminative convolution sparse coding for robust image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional sparse coding; Sparse representation; Classification;
   Dictionary learning
ID DICTIONARY; REPRESENTATION
AB Convolutional Sparse Coding (CSC) is a popular model in the signal and image processing communities, resolving some limitations of the traditional patch-based sparse representations. However, most existing CSC algorithms are suited for image restoration. Also, in some CSC-based classification methods, the CSC model is only used as a feature extractor and so other classifiers are needed for classification. In this paper, we present a novel discriminative model based on CSC for image classification. The proposed method, discriminative local block coordinate descent (D-LoBCoD), is based on extending the LoBCoD algorithm by incorporating the classification error into the objective function that considers the performance of a linear classifier and the representational power of the filters, simultaneously. Thus, in the training phase, in each iteration, after updating the sparse coefficients and convolutional filters, we minimize the classification error by updating the parameters of the classifier according to the class label information of the training samples. Also, in the test phase, the label of the query image is determined by the trained classifier. To demonstrate the performance of the proposed method, we conduct extensive experiments on image data sets in comparison with state-of-the-art classification methods. The experimental results show that our method outperforms other competing methods in most cases. Further, we demonstrate that our proposed method is less dependent on the number of training samples because of capturing more representative information from the corresponding images. Thus our proposed method can work better than other methods on all small databases that have fewer samples.
C1 [Nozaripour, Ali] Semnan Univ, Dept Elect Comp Engn, Semnan 3513119111, Iran.
   [Soltanizadeh, Hadi] Semnan Univ, Fac Elect Comp Engn, Semnan 3513119111, Iran.
C3 Semnan University; Semnan University
RP Soltanizadeh, H (corresponding author), Semnan Univ, Fac Elect Comp Engn, Semnan 3513119111, Iran.
EM a_nozari@semnan.ac.ir.com; h_soltanizadeh@semnan.ac.ir
RI Soltanizadeh, Hadi/AAH-1840-2019
OI Soltanizadeh, Hadi/0000-0002-2210-675X
CR An FP, 2020, SOFT COMPUT, V24, P16967, DOI 10.1007/s00500-020-04989-3
   Annunziata R, 2016, IEEE T MED IMAGING, V35, P2381, DOI 10.1109/TMI.2016.2570123
   Benavente R, 1998, 24 COMP VIS CTR
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Chen BH, 2016, IEEE IMAGE PROC, P1918, DOI 10.1109/ICIP.2016.7532692
   CHEN S, 1989, INT J CONTROL, V50, P1873, DOI 10.1080/00207178908953472
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Cogliati A, 2016, IEEE-ACM T AUDIO SPE, V24, P2218, DOI 10.1109/TASLP.2016.2598305
   Degraux K, 2017, IEEE IMAGE PROC, P1617, DOI 10.1109/ICIP.2017.8296555
   Deng C, 2018, IEEE T IMAGE PROCESS, V27, P3893, DOI 10.1109/TIP.2018.2821921
   Ding Z, 2016, EUROPEAN C COMPUTER
   Foroughi H, 2018, IEEE T IMAGE PROCESS, V27, P806, DOI 10.1109/TIP.2017.2766446
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Goel N, 2005, PROC SPIE, V5779, P426, DOI 10.1117/12.605553
   Gou JP, 2020, NEURAL NETWORKS, V125, P104, DOI 10.1016/j.neunet.2020.01.020
   Gu S, 2015, P IEEE INT C COMPUTE
   Guo YD, 2017, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2017.72
   He J, 2021, SIVIP, V19
   Heide F, 2015, P IEEE C COMPUTER VI
   Hu CE, 2023, IEEE T CYBERNETICS, V53, P2440, DOI 10.1109/TCYB.2021.3120188
   Hu JL, 2018, PATTERN RECOGN, V75, P282, DOI 10.1016/j.patcog.2017.02.009
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Jin JW, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION, CYBERNETICS AND COMPUTATIONAL SOCIAL SYSTEMS (ICCSS), P137, DOI 10.1109/ICCSS.2017.8091400
   Kavukcuoglu K., 2010, Advances in neural information processing systems, P1
   Li ZM, 2020, IEEE T NEUR NET LEAR, V31, P786, DOI 10.1109/TNNLS.2019.2910146
   Liao HW, 2018, IEEE SIGNAL PROC LET, V25, P1156, DOI 10.1109/LSP.2018.2847236
   Liu J, 2017, 2017 IEEE INT C IMAG
   Liu Z, 2019, PATTERN ANAL APPL, V22, P1527, DOI 10.1007/s10044-019-00792-5
   Nozaripour A, 2021, J AI DATA MINING
   Pan H, 2018, IEEE T CYBERNETICS, V48, P2875, DOI 10.1109/TCYB.2017.2751585
   Papyan V, 2017, P IEEE INT C COMPUTE
   Parvasideh P, 2021, ADV DATA ANAL CLASSI, V15, P575, DOI 10.1007/s11634-020-00417-4
   Pham DS, 2008, PROC CVPR IEEE, P517
   Pour AN, 2015, INT J APPL PATTERN R, V2, P111, DOI 10.1504/IJAPR.2015.069540
   Rodriguez P, 2018, 2018 IEEE 25 INT C E, P14
   Romano Y, 2015, 2015 IEEE INT C ACOU
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shazeeda S, 2019, IET BIOMETRICS, V8, P49, DOI 10.1049/iet-bmt.2018.5130
   Sorel M, 2016, DIGIT SIGNAL PROCESS, V55, P44, DOI 10.1016/j.dsp.2016.04.012
   Sun J, 2016, INT J COMPUT VISION, V120, P111, DOI 10.1007/s11263-016-0899-0
   Uddin M, 2017, I C NETWORK PROTOCOL, DOI 10.1109/TPAMI.2017.2656884
   Vu TH, 2017, IEEE T IMAGE PROCESS, V26, P5160, DOI 10.1109/TIP.2017.2729885
   Wang J., 2013, P 21 ACM INT C MULTI, P769
   Wang K, 2016, P IEEE C COMPUTER VI
   Wang L, 2021, MULTIMED TOOLS APPL, P121
   Wang YQ, 2018, IEEE T IMAGE PROCESS, V27, P4850, DOI 10.1109/TIP.2018.2842152
   Wohlberg B, 2016, IEEE T IMAGE PROCESS, V25, P301, DOI 10.1109/TIP.2015.2495260
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2017, IEEE ACCESS, V5, P8502, DOI 10.1109/ACCESS.2017.2695239
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yuksel A, 2011, IET COMPUT VIS, V5, P398, DOI 10.1049/iet-cvi.2010.0175
   Zeiler M D, 2010, 2010 IEEE COMPUTER S
   Zeng SN, 2017, MULTIMED TOOLS APPL, V76, P20889, DOI 10.1007/s11042-016-4035-5
   Zhang L, 2011, 2011 INT C COMPUTER
   Zhang Q, 2010, 2010 IEEE COMPUTER S
   Zhao L, 2016, VISUAL COMPUT, V32, P1165, DOI 10.1007/s00371-015-1169-9
   Zhao Z, 2021, SOFT COMPUT, V25, P7627, DOI 10.1007/s00500-021-05723-3
   Zheng H, 2015, NEUROCOMPUTING, V162, P9, DOI 10.1016/j.neucom.2015.03.071
   Zhou Y, 2014, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2014.394
   Zhu Y, 2019, IEEE T MULTIMEDIA, V21, P1825, DOI 10.1109/TMM.2019.2891999
   Zisselman E, 2019, P IEEECVF C COMPUTER
NR 61
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40849
EP 40870
DI 10.1007/s11042-022-12395-0
EA MAY 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000795177900003
DA 2024-07-18
ER

PT J
AU Li, YK
AF Li Yong-Kui
TI A new chaotic map and analysis of properties of "Reciprocal difference
   twice modular maps" on <i>Z</i>(<i>p</i><SUP><i>n</i></SUP>)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic map; Generating sequence; Period; Residue class ring; Reciprocal
   difference twice modular map
ID ARNOLD CAT MAP; PERIOD DISTRIBUTION; LOGISTIC MAPS
AB The chaotic maps on the real number fields certainly cause the degenerate of the chaotic characters because of the finite precision when realized on computers. And its complexity is very high. In this paper a new class of 1-D nonlinear chaotic map on the real number fields is proposed. This map is chaotic in the whole range of parameters. The Lyapunov exponents of this map tend to ln 2. It has complex dynamical properties and high sensitivity to initial values; the iterative sequences obey a uniform distribution. Then we propose the concept of "reciprocal difference twice modular maps" based on this map which is realized on Z(p(n)) and avoids the defects above. The properties of the generating sequences by the new maps are analyzed, including periods and long chains and so on. The analysis and numeral experiments show that reciprocal difference twice modular maps can be widely applied in the pseudo-random number generators, cryptography, spread spectrum communication and so on.
C1 [Li Yong-Kui] Hubei Univ Sci & Technol, Sch Comp Sci & Technol, Xianning 437100, Peoples R China.
C3 Hubei University of Science & Technology
RP Li, YK (corresponding author), Hubei Univ Sci & Technol, Sch Comp Sci & Technol, Xianning 437100, Peoples R China.
EM lyk0@163.com
FU Scientific Research Program of Department of Education of Hubei Province
   [D20202801]; Scientific Research Foundation for PhD of Hubei University
   of Science and Technology [BK202030]
FX This work was supported by the Scientific Research Program of Department
   of Education of Hubei Province (Grant No. D20202801) and the Scientific
   Research Foundation for PhD of Hubei University of Science and
   Technology(Grant No. BK202030).
CR Chen F, 2013, IEEE T INFORM THEORY, V59, P3249, DOI 10.1109/TIT.2012.2235907
   Chen F, 2012, COMMUN NONLINEAR SCI, V17, P3848, DOI 10.1016/j.cnsns.2012.02.021
   Chen F, 2012, IEEE T INFORM THEORY, V58, P445, DOI 10.1109/TIT.2011.2171534
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Daemen, 1997, P 4 FAST SOFTW ENCR, P149165
   GROSSMANN S, 1977, Z NATURFORSCH A, V32, P1353
   Khan M, 2012, NONLINEAR DYNAM, V70, P2303, DOI 10.1007/s11071-012-0621-x
   Li YK, 2019, CHINA COMMUN, V16, P189, DOI 10.12676/j.cc.2019.05.015
   Li YK, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419590109
   Liao XF, 2010, IEEE T COMPUT, V59, P1392, DOI 10.1109/TC.2010.148
   LORENZ EN, 1963, J ATMOS SCI, V20, P448, DOI 10.1175/1520-0469(1963)020<0448:TMOV>2.0.CO;2
   Machicao J, 2017, CHAOS, V27, DOI 10.1063/1.4983836
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Mira C., 1987, Chaotic dynamics. From the one-dimensional endomorphism to the two-dimensional diffeomorphism, DOI [10.1142/0413, DOI 10.1142/0413]
   Miyazaki, 2011, INT WORKSH SIGN DES, P2124
   Miyazaki T, 2014, 2014 INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY AND ITS APPLICATIONS (ISITA), P714
   Miyazaki T, 2010, IEICE T FUND ELECTR, VE93A, P2258, DOI 10.1587/transfun.E93.A.2258
   Sui LS, 2014, OPT LASER ENG, V62, P139, DOI 10.1016/j.optlaseng.2014.06.003
   Tsuchiya K, 2015, P INT WORKSHOP SIGNA
   Yang B, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0756-1
   Yoshida, 2014, P INT S INF THEOR IT, P665668
   Zhou S, 2020, CHAOS SOLITON FRACT, V141, DOI 10.1016/j.chaos.2020.110225
NR 22
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40371
EP 40383
DI 10.1007/s11042-022-13074-w
EA MAY 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791638000001
DA 2024-07-18
ER

PT J
AU Pornpongtechavanicha, P
   Wuttidittachotti, P
   Daengsi, T
AF Pornpongtechavanicha, Phisit
   Wuttidittachotti, Pongpisit
   Daengsi, Therdpong
TI QoE modeling for audiovisual associated with MOBA game using subjective
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QoE; MOS; Online game; Video game; MOBA; ROV
ID QUALITY; EXPERIENCE
AB With the advancement of multimedia communications and information technologies, online video games have become very popular recreational activities worldwide, while Multiplayer Online Battle Arena (MOBA) games have gained immense popularity from game players in recent times. Therefore, based on quality of experience, audiovisual quality evaluation models for MOBA games have been proposed in this study. The subjective data from 210 game players (both males and females) about audio quality during conversation, the video quality, the overall quality, and the weighted percentage of video and voice have been collected from small competition events of the Garena ROV (Arena of Valor) in Hua Hin, Thailand. The data from 160 game players have been used to create the models, while the data from 50 game players have been applied for model performance evaluation. After developing the models, Mean Absolute Percentage Error (MAPE) technique has been utilized for model evaluation. On completion of this study, it was found that two thirds of the proposed models provide better performance than the other previous works. All of them, called MOSAudiovisual-MOBA1 model, MOSAudiovisual-MOBA2 model and MOSAudiovisual-MOBA3 model, show excellent performances with MAPE values of 4.95%, 5.92% and 4.75% respectively. Therefore, excellent performance of these proposed models becomes one of the contributions of this study. Also, this evidence of excellent model performance makes the proposed models ideal for utilization for assessment of audiovisual quality of the MOBA games. All audiovisual quality evaluation models provide excellent efficiencies.
C1 [Pornpongtechavanicha, Phisit] Rajamangala Univ Technol Rattanakosin, Dept Informat Technol, Fac Ind & Technol, Wang Klai Kangwon Campus, Prachuap Khiri Khan, Thailand.
   [Wuttidittachotti, Pongpisit] King Mongkuts Univ Technol North Bangkok, Fac Informat Technol & Digital Innovat, Dept Data Commun & Networking, Bangkok, Thailand.
   [Daengsi, Therdpong] Rajamangala Univ Technol Phra Nakhon, Fac Engn, Dept Sustainable Ind Management Engn, Bangkok, Thailand.
C3 Rajamangala University of Technology Rattanakosin; King Mongkuts
   University of Technology North Bangkok; Rajamangala University of
   Technology Phra Nakhon
RP Daengsi, T (corresponding author), Rajamangala Univ Technol Phra Nakhon, Fac Engn, Dept Sustainable Ind Management Engn, Bangkok, Thailand.
EM phisit.kha@rmutp.ac.th; pongpisitw@kmutnb.ac.th; therdpong.d@rmutp.ac.th
RI Daengsi, Therdpong/AAH-9231-2019
OI Daengsi, Therdpong/0000-0002-7569-8197
FU Faculty of Industry and Technology, Rajamangala University of Technology
   Rattanakosin (Wang Klai Kangwon Campus); Faculty of Information
   Technology and Digital Innovation, King Mongkut's University of
   Technology North Bangkok; Faculty of Engineering, Rajamangala University
   of Technology Phra Nakhon
FX Thanks to the Faculty of Industry and Technology, Rajamangala University
   of Technology Rattanakosin (Wang Klai Kangwon Campus), Faculty of
   Information Technology and Digital Innovation, King Mongkut's University
   of Technology North Bangkok, and Faculty of Engineering, Rajamangala
   University of Technology Phra Nakhon for supporting. Especially, thanks
   to all students, staff and lecturers who were participants or involved.
   Lastly, thanks to Mr. Bhaskar Laha (Bobby) for English editing.
CR 5G Americas, 2017, 5G Services & Use Cases
   Afonso AP, 2019, MULTIMED TOOLS APPL, V78, P33069, DOI 10.1007/s11042-019-07952-z
   [Anonymous], 2018, ITU T RECOMMENDATION
   [Anonymous], 2019, S CHINA MORNING POST
   Anunpattana P., 2018, ASIA PACIFIC J INFOR, V7, P1
   Aovpro, 2021, AR VAL WORLD CUP 202
   Bangkokpost, 2019, GAR TOUTS THAI E SPO
   Bányai F, 2019, COMPR PSYCHIAT, V94, DOI 10.1016/j.comppsych.2019.152117
   Batteram H, 2010, BELL LABS TECH J, V15, P175, DOI 10.1002/bltj.20431
   Belmudez B, 2013, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2013-24
   Calyam P., 2005, P ISCIS 05 IST TURK, P91
   Chung T, 2019, J BEHAV ADDICT, V8, P384, DOI 10.1556/2006.8.2019.46
   Daengsi T, 2020, INT CONF ADV COMMUN, P367, DOI [10.23919/ICACT48636.2020.9061343, 10.23919/icact48636.2020.9061343]
   Daengsi T, 2019, J NETW SYST MANAG, V27, P837, DOI 10.1007/s10922-018-09487-4
   de Moura MP, 2019, BRAZIL SYMP GAME DIG, P72, DOI 10.1109/SBGames.2019.00020
   Denton, 2020, GAMER MOTIVATION F 2
   Depa, 2021, INV Q GAM IND
   Dwyer DT., 2013, PREDICTING PERCEIVED
   Esports inquirer, 2020, ESPORTS INQUIRER
   Gough, 2020, GENRE BREAKDOWN VIDE
   Hamari J, 2017, INTERNET RES, V27, P211, DOI 10.1108/IntR-04-2016-0085
   Hands DS, 2004, IEEE T MULTIMEDIA, V6, P806, DOI 10.1109/TMM.2004.837233
   Hemphill D., 2012, CYBERSPORT J PHILOS, V32, P207, DOI [10.1080/00948705.2005.9714682, DOI 10.1080/00948705.2005.9714682]
   International Olympic Committee, 2021, IOC MAK LANDM MOV VI
   *ITU T, 2017, ITU T RECOMMENDATION
   Jia B, 2019, MOBILE NETW APPL, V24, P25, DOI 10.1007/s11036-018-1135-7
   Jonasson K, 2010, SPORT SOC, V13, P287, DOI 10.1080/17430430903522996
   Karhulahti VM, 2017, PHYS CULT SPORT STUD, V74, P43, DOI 10.1515/pcssr-2017-0010
   Khan A, 2010, IET COMMUN, V4, P1337, DOI 10.1049/iet-com.2009.0422
   Maaloul S, 2012, ACM INT SYM MOB MAN, P149
   Mo C, 2018, PROCEEDINGS OF THE 28TH ACM WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO (NOSSDAV'18), P25, DOI 10.1145/3210445.3210450
   Moller S., 2018, P QOMEX 2018 CAGL, DOI 10.1109/QoMEX.2018.8463404
   Mora-Cantallops M, 2018, ENTERTAIN COMPUT, V26, P128, DOI 10.1016/j.entcom.2018.02.005
   Orestis, 2018, FEATURE BASED MULTIM
   Pornpongtechavanich P., 2020, J IND TECHNOL, V16, P31, DOI [10.14416/j.ind.tech.2020.03.00, DOI 10.14416/J.IND.TECH.2020.03.00]
   Pornpongtechavanich P, 2019, MULTIMED TOOLS APPL, V78, P31987, DOI 10.1007/s11042-019-07928-z
   Ries M, 2008, INT CONF SYST SIGNAL, P181, DOI 10.1109/IWSSIP.2008.4604397
   Sarakatsanos, 2020, FEATURE BASED MULTIM
   Slivar I, 2014, ANN WORK NETW
   Statista, 2021, ESPORTS AUDIENCE SIZ
   Suznjevic M, 2019, MULTIMEDIA SYST, V25, P395, DOI 10.1007/s00530-019-00615-x
   The Nationthailand, 2018, GAM MAD THAIS READ P
   Video Games Stats (VGS), 2020, HON KINGS AR VAL
   Wagner, 2006, P ICOMP 2006 LAS VEG
   Wattimena A., 2006, Proceedings of 5th ACM SIGCOMM Workshop on Network and System Support for Games, NetGames '06, P1
   Weiss T, 2011, 24TH BLED ECONFERENCE: EFUTURE: CREATING SOLUTIONS FOR THE INDIVIDUAL, ORGANISATIONS AND SOCIETY, P572
   Winkler S, 2006, IEEE T MULTIMEDIA, V8, P973, DOI 10.1109/TMM.2006.879871
   Wuttidittachotti P, 2018, MULTIMEDIA SYST, V24, P285, DOI 10.1007/s00530-017-0549-6
   YEE N, 2015, GAMER MOTIVATION MOD
NR 49
TC 4
Z9 4
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37763
EP 37779
DI 10.1007/s11042-022-12807-1
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000786824500005
PM 35493419
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Bartani, A
   Abdollahpouri, A
   Ramezani, M
   Tab, FA
AF Bartani, Ako
   Abdollahpouri, Alireza
   Ramezani, Mohsen
   Tab, Fardin Akhlaghian
TI An adaptive optic-physic based dust removal method using optimized
   air-light and transfer function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Dust removal; Physical-optic model; Transmission
   function; Air light estimation
ID HAZE REMOVAL; IMAGE; ENHANCEMENT; RESTORATION; FRAMEWORK; ALGORITHM;
   DOMAIN; MODEL
AB In recent years, computer vision is used in different applications. In these applications, images may be contaminated by different factors such as clouds, shadow, haze, fog, and dust phenomena. The dust phenomenon caused environmental problems in certain regions of the world. This phenomenon, which reduced visibility, acts as a barrier against the object's light reflection to the eyes or camera lens. There are few studies relating to removing dust from images, while haze removal has received more attention. The haze removal methods have been examined for removing dust that haven't proper performance. Thus, we propose a new physic-optic based method to remove dust from images properly. Here, the air-light estimation on the dark channel histogram is modified and a new method is used to estimate the weight of the dust-based transmission function per pixel in the R, G, and B channels, separately. Experimental results indicate that the proposed method appropriately removes dust from the images which contain different density of dust. It should be noted that output images have high contrast, good brightness level, and natural colors. Moreover, the proposed method can be used for removing haze from hazy images as a suitable method that achieves better or acceptable results than popular and recent haze removal methods. Experiments indicate that the PCQI value of the proposed method for two dusty datasets is about 1.24 on average, while this value for the best state-of-the-art method is about 1.15 on average. These values for hazy images are 1.33, and 1.15, respectively.
C1 [Bartani, Ako; Abdollahpouri, Alireza; Tab, Fardin Akhlaghian] Univ Kurdistan, Fac Engn, Dept Comp Engn, Sanandaj, Iran.
   [Ramezani, Mohsen] Univ Kurdistan, Dept Comp Sci, Sanandaj, Iran.
C3 University of Kurdistan; University of Kurdistan
RP Tab, FA (corresponding author), Univ Kurdistan, Fac Engn, Dept Comp Engn, Sanandaj, Iran.
EM a.bartani@eng.uok.ac.ir; abdollahpouri@uok.ac.ir; m.rameznai@uok.ac.ir;
   f.akhlaghian@uok.ac.ir
OI Akhlaghian Tab, Fardin/0000-0002-0300-9233; Bartani,
   Ako/0009-0002-9320-8398
CR Al-Ameen Zohair, 2016, International Journal of Intelligent Systems and Applications, V8, P10, DOI 10.5815/ijisa.2016.08.02
   Alajarmeh A, 2018, INFORM SCIENCES, V436, P108, DOI 10.1016/j.ins.2018.01.009
   Alruwaili M, 2015, INT CONF ELECTRO INF, P286, DOI 10.1109/EIT.2015.7293354
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Ansia S, 2015, PROCEDIA COMPUT SCI, V46, P12, DOI 10.1016/j.procs.2015.01.042
   Anwar MI, 2017, ENG SCI TECHNOL, V20, P1075, DOI 10.1016/j.jestch.2016.11.015
   Anwar S, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115978
   Berman D, 2017, IEEE INT CONF COMPUT, P115
   Biswas B, 2014, IEEE INT SYMP SIGNAL, P25, DOI 10.1109/ISSPIT.2014.7300558
   Cheng YQ, 2020, IEEE ACCESS, V8, P196690, DOI 10.1109/ACCESS.2020.3034151
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Galdran A, 2018, SIGNAL PROCESS, V149, P135, DOI 10.1016/j.sigpro.2018.03.008
   Gibson KB, 2012, IEEE T IMAGE PROCESS, V21, P662, DOI 10.1109/TIP.2011.2166968
   Gopalan S, 2015, PROCEDIA COMPUT SCI, V46, P1786, DOI 10.1016/j.procs.2015.02.134
   Haoran Xu, 2012, 2012 IEEE International Conference on Information Science and Technology, P663, DOI 10.1109/ICIST.2012.6221729
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang CQ, 2018, COMPUT ELECTR ENG, V70, P659, DOI 10.1016/j.compeleceng.2017.09.018
   Huang SC, 2014, IEEE T CIRC SYST VID, V24, P1814, DOI 10.1109/TCSVT.2014.2317854
   Jarraud M, 2018, 8 WMO
   Jaya VL, 2015, PROCEDIA COMPUT SCI, V46, P1747, DOI 10.1016/j.procs.2015.02.125
   Katiyar K., 2016, INT J COMPUT APPL, V141, P37, DOI [10.5120/ijca2016909827, DOI 10.5120/IJCA2016909827]
   Kou F, 2015, IEEE T IMAGE PROCESS, V24, P4528, DOI 10.1109/TIP.2015.2468183
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li HB, 2016, ADV SPACE RES, V57, P340, DOI 10.1016/j.asr.2015.09.023
   Li Y, 2017, COMPUT VIS IMAGE UND, V165, P1, DOI 10.1016/j.cviu.2017.09.003
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Liu Q, 2017, SIGNAL PROCESS, V137, P33, DOI 10.1016/j.sigpro.2017.01.036
   Loza A, 2013, DIGIT SIGNAL PROCESS, V23, P1856, DOI 10.1016/j.dsp.2013.06.002
   Middleton W.E.K., 1957, Geophysik II/Geophysics II, P254, DOI DOI 10.1007/978-3-642-45881-13
   Park TH, 2021, IEEE ACCESS, V9, P19749, DOI 10.1109/ACCESS.2021.3054899
   Pei SC, 2012, IEEE IMAGE PROC, P957, DOI 10.1109/ICIP.2012.6467020
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Saravanan G, 2016, PROCEDIA COMPUT SCI, V87, P105, DOI 10.1016/j.procs.2016.05.134
   Shi ZH, 2019, IEEE ACCESS, V7, P116722, DOI 10.1109/ACCESS.2019.2936444
   Shi ZW, 2014, OPTIK, V125, P3868, DOI 10.1016/j.ijleo.2014.01.170
   Shiau YH, 2014, J VIS COMMUN IMAGE R, V25, P445, DOI 10.1016/j.jvcir.2013.12.011
   Sun W, 2015, COMPUT ELECTR ENG, V46, P371, DOI 10.1016/j.compeleceng.2015.02.009
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tang QF, 2021, COMPUT VIS IMAGE UND, V202, DOI 10.1016/j.cviu.2020.103086
   Wang JB, 2015, NEUROCOMPUTING, V149, P718, DOI 10.1016/j.neucom.2014.08.005
   Wang SQ, 2015, IEEE SIGNAL PROC LET, V22, P2387, DOI 10.1109/LSP.2015.2487369
   Wang WC, 2020, MULTIMED TOOLS APPL, V79, P27185, DOI 10.1007/s11042-020-09380-w
   Wu JJ, 2020, IEEE T IMAGE PROCESS, V29, P7414, DOI 10.1109/TIP.2020.3002478
   Yeh CH, 2013, OPT EXPRESS, V21, P27127, DOI 10.1364/OE.21.027127
   Zhang WD, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116030
   Zhu MZ, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.11.113105
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu YY, 2018, NEUROCOMPUTING, V275, P499, DOI 10.1016/j.neucom.2017.08.055
NR 50
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33823
EP 33849
DI 10.1007/s11042-022-13109-2
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300012
DA 2024-07-18
ER

PT J
AU Gupta, I
   Nayak, SR
   Gupta, S
   Singh, S
   Verma, KD
   Gupta, A
   Prakash, D
AF Gupta, Isha
   Nayak, Soumya Ranjan
   Gupta, Sheifali
   Singh, Swati
   Verma, K. D.
   Gupta, Abhishek
   Prakash, Deo
TI A deep learning based approach to detect IDC in histopathology images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; CNN; Invasive ductal carcinoma; SVM; ConvNet; KNN
ID COMPUTER-AIDED DIAGNOSIS; BREAST-CANCER; CLASSIFICATION
AB Breast cancer is one of the widespread reasons of morbidity worldwide that begins in the cells of the tissues of morbidity worldwide in the woman community. Breast cancer can be confirmed by investigating the interior tissue regions in terms of Invasive- Ductal-Breast Carcinoma (IDC) and Invasive-lobular-Breast Carcinoma (ILC). Therefore, early diagnosis of breast tissue abnormalities is crucial to diminish the risk by enabling quick and efficient treatment. This research study aims to propose a comprehensive CAD system invasive ductal carcinoma (IDC) by employing the proposed deep learning-based algorithm using the histopathology images. The proposed scheme developed three different CNN models from scratch like ConvNet-A, ConvNet-B, and ConvNet-C by considering different layers that are 8, 9, and 19 layer, respectively. Furthermore, the performance has been validated against four popular machine learning models such as support vector machine (SVM), K-nearest neighbor (KNN), random forest (RF) and logistic regression (LR). Experiments have been performed in two-steps; first, proposed CNN model is evaluated in different sample size, and achieved best accuracy of 88.7% and sensitivity of 92.6% with ConvNet-C with 100,000 sample images. Second, the best classification accuracy achieved by SVM if the number of images taken are more than 5000, because it has a regularization parameter which avoids over-fitting. It is clearly perceived that the proposed CNN algorithms lead to better classification accuracy for detection of IDC compared to state-of-art techniques and hence, this computational framework will act as a helping aid for the pathologist.
C1 [Gupta, Isha; Gupta, Sheifali] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
   [Nayak, Soumya Ranjan] Amity Univ Uttar Pradesh, Amity Sch Engn & Technol, Noida, India.
   [Singh, Swati] Himachal Pradesh Univ, Univ Inst Technol, Shimla 171005, India.
   [Verma, K. D.] Shri Varshney PG Coll, Dept Phys, Aligarh 202001, Uttar Pradesh, India.
   [Gupta, Abhishek; Prakash, Deo] Shri Mata Vaishno Devi Univ, Fac Engn, Sch Comp Sci & Engn, Katra 182320, J&k, India.
C3 Chitkara University, Punjab; Amity University Noida; Himachal Pradesh
   University; Shri Mata Vaishno Devi University
RP Prakash, D (corresponding author), Shri Mata Vaishno Devi Univ, Fac Engn, Sch Comp Sci & Engn, Katra 182320, J&k, India.
EM deoprakash.a@gmail.com
RI Gupta, Sheifali/IQU-0129-2023; Prakash, Deo/O-9722-2015; Gupta,
   Abhishek/O-3016-2019; Nayak, Soumya Ranjan/S-5908-2018; Gupta,
   Isha/GWM-8002-2022; Verma, K.D./K-5758-2018; Gupta, Isha/HNJ-4016-2023
OI Gupta, Abhishek/0000-0002-8592-9964; Nayak, Soumya
   Ranjan/0000-0002-4155-884X; Gupta, Isha/0000-0003-0833-7786; Verma,
   K.D./0000-0002-5492-2997; gupta, sheifali/0000-0001-5692-418X
CR Albarqouni S, 2016, IEEE T MED IMAGING, V35, P1313, DOI 10.1109/TMI.2016.2528120
   Aloyayri, 2020, BREAST CANC CLASSIFI
   Bayramoglu N, 2016, LECT NOTES COMPUT SC, V9915, P532, DOI 10.1007/978-3-319-49409-8_46
   Bayramoglu N, 2016, INT C PATT RECOG, P2440, DOI 10.1109/ICPR.2016.7900002
   Beevi KS, 2017, IEEE J TRANSL ENG HE, V5, DOI 10.1109/JTEHM.2017.2694004
   Bejnordi BE, 2018, MODERN PATHOL, V31, P1502, DOI 10.1038/s41379-018-0073-z
   Nguyen CP, 2019, ISCIT 2019: PROCEEDINGS OF 2019 19TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P366, DOI [10.1109/iscit.2019.8905196, 10.1109/ISCIT.2019.8905196]
   Conte L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10176109
   Couture HD, 2018, NPJ BREAST CANCER, V4, DOI 10.1038/s41523-018-0079-1
   Doyle S, 2008, I S BIOMED IMAGING, P496, DOI 10.1109/ISBI.2008.4541041
   Dundar MM, 2011, IEEE T BIO-MED ENG, V58, P1977, DOI 10.1109/TBME.2011.2110648
   Gecer B, 2018, PATTERN RECOGN, V84, P345, DOI 10.1016/j.patcog.2018.07.022
   Han ZY, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04075-z
   Kowal M, 2013, COMPUT BIOL MED, V43, P1563, DOI 10.1016/j.compbiomed.2013.08.003
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Litjens G, 2016, SCI REP-UK, V6, DOI 10.1038/srep26286
   Loukas C, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/829461
   Mobolaji O, 2020, INT J APPL INF SYST, V12, P29
   Mohamed ST, 2019, OPTIMIZED FEED FORWA
   Niwas S. Issac, 2010, 2010 IEEE Symposium on Industrial Electronics and Applications (ISIEA 2010), P686, DOI 10.1109/ISIEA.2010.5679377
   Osareh A., 2010, 2010 5 INT S HLTH IN, P114
   Pöllänen I, 2015, PROCEEDINGS INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS - ARCHITECTURES, MODELING AND SIMULATION (SAMOS XV), P319, DOI 10.1109/SAMOS.2015.7363692
   Puerto M, 2016, 2016 IEEE LATIN AMERICAN CONFERENCE ON COMPUTATIONAL INTELLIGENCE (LA-CCI)
   Rachapudi V, 2021, EVOL INTELL, V14, P1337, DOI 10.1007/s12065-020-00367-y
   Sharma S, 2020, J DIGIT IMAGING, V33, P632, DOI 10.1007/s10278-019-00307-y
   Singh S., 2018, INT J PURE APPL MATH, V118, P1151
   Sommer C, 2012, INT C PATT RECOG, P2306
   Spanhol FA, 2017, IEEE SYS MAN CYBERN, P1868, DOI 10.1109/SMC.2017.8122889
   Torrents-Barrena J, 2016, J EXP THEOR ARTIF IN, V28, P295, DOI 10.1080/0952813X.2015.1024491
   Van Bockstal MR, 2020, AM J CLIN PATHOL, V154, P596, DOI 10.1093/ajcp/aqaa077
   Xu J, 2016, IEEE T MED IMAGING, V35, P119, DOI 10.1109/TMI.2015.2458702
NR 31
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36309
EP 36330
DI 10.1007/s11042-021-11853-5
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000784679300001
DA 2024-07-18
ER

PT J
AU Dansena, P
   Bag, S
   Pal, R
AF Dansena, Prabhat
   Bag, Soumen
   Pal, Rajarshi
TI Pen ink discrimination in handwritten documents using statistical and
   motif texture analysis : A classification based approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document alteration; Document forgery; Handwritten document forensics;
   Ink analysis; Classification
ID SYSTEM; COLOR; IDENTIFICATION; BLUE
AB Pen ink analysis is an essential step for establishing the integrity of a handwritten document. Traditional approaches for analyzing the ink are based on destructive techniques like thin layer chromatography, high performance liquid chromatography, etc. There are several non-destructive techniques too which focus on multi-spectral imaging on various wavelengths in ultraviolet, visible, and infra-red range. On the contrary, there have been very limited techniques that focus on analyzing scanned handwritten documents using normal scanners in the visible light spectrum. In this regard, a novel method has been proposed to discriminate pen inks on a handwritten document. The proposed technique considers a set of statistical (global) and motif (local) textural features of ink colors for differentiating pen inks in a pair of words. This is the first use of motif textural features along with statistical textural features for this task. In this work, absolute differences between feature values from a pair of words are considered as feature vector. This feature vector is fed to a binary classifier to determine whether those two words are written using same pen or different pens. Five different classifiers (decision tree, k-nearest neighbor, random forest, radial-basis-function kernel support vector machine, and multi-layer perceptron) have been experimentally tested for this task. Experimental results reveal that the proposed method with random forest classifier outperforms other classifiers for this task. Furthermore, the comparative analysis confirms the efficacy of the proposed method w.r.t. state-of-the-art methods for pen ink discrimination in visible light spectrum.
C1 [Dansena, Prabhat; Bag, Soumen] Indian Inst Technol ISM Dhanbad, Dept Comp Sci & Engn, Dhanbad, Bihar, India.
   [Pal, Rajarshi] Inst Dev & Res Banking Technol, Hyderabad, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Dansena, P (corresponding author), Indian Inst Technol ISM Dhanbad, Dept Comp Sci & Engn, Dhanbad, Bihar, India.
EM p.dansena23@gmail.com
RI Dansena, Prabhat/AAS-2023-2020
OI Dansena, Prabhat/0000-0001-5982-1215
CR AGINSKY VN, 1993, J FORENSIC SCI, V38, P1131
   Ali A, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P504
   Andrasko J, 2001, J FORENSIC SCI, V46, P21
   [Anonymous], 2016, IDRBT CHEQUE IMAGE D
   [Anonymous], 2013, NATL FORENSIC SCI TE
   Avola D, 2020, MULTIMED TOOLS APPL, V79, P4463, DOI 10.1007/s11042-019-7196-1
   Barboza RD, 2014, INT CONF FRONT HAND, P517, DOI 10.1109/ICFHR.2014.93
   Berenguel A, 2017, PROC INT CONF DOC, P15, DOI 10.1109/ICDAR.2017.390
   Berenguel A, 2017, PROC INT CONF DOC, P1237, DOI 10.1109/ICDAR.2017.204
   Berenguel A, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P66, DOI 10.1109/DAS.2016.34
   Brauns EB, 2006, APPL SPECTROSC, V60, P833, DOI 10.1366/000370206778062093
   Chhabra S, 2017, IFIP ADV INF COMM TE, V511, P245, DOI 10.1007/978-3-319-67208-3_14
   Chlebda DK, 2016, APPL PHYS A-MATER, V122, DOI 10.1007/s00339-016-0494-9
   Cruz F, 2017, PROC INT CONF DOC, P1223, DOI 10.1109/ICDAR.2017.202
   Dansena P, 2021, IEEE ACCESS, V9, P38979, DOI 10.1109/ACCESS.2021.3059342
   Dansena P, 2020, IET IMAGE PROCESS, V14, P1594, DOI 10.1049/iet-ipr.2018.6616
   Dansena P, 2017, LECT NOTES COMPUT SC, V10597, P655, DOI 10.1007/978-3-319-69900-4_83
   Dasari H, 2007, PROC INT CONF DOC, P486
   Deviterne-Lapeyre, 2020, INTERPOL REV QUESTIO
   Gorai A, 2016, IEEE IJCNN, P4512, DOI 10.1109/IJCNN.2016.7727790
   Gupta G, 2006, DIGIT INVEST, V3, P43, DOI 10.1016/j.diin.2006.01.009
   Gupta S, 2020, SOFT COMPUT, V24, P5409, DOI 10.1007/s00500-019-04297-5
   HARRIS J, 1992, J FORENSIC SCI, V37, P612
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   Khan Muhammad Jaleed, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1097, DOI 10.1109/ICDAR.2019.00178
   Khan MJ, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P393, DOI 10.1109/DAS.2018.26
   Khan Z, 2015, PATTERN RECOGN, V48, P3615, DOI 10.1016/j.patcog.2015.04.008
   Kher A, 2006, VIB SPECTROSC, V40, P270, DOI 10.1016/j.vibspec.2005.11.002
   Koppenhaver K. M., 2007, Forensic document examination: Principles and practice
   Kota S, 2014, IEEE INT ADV COMPUT, P1041, DOI 10.1109/IAdCC.2014.6779469
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M, 2020, SOFT COMPUT, V24, P13197, DOI 10.1007/s00500-020-04733-x
   Kumar M, 2019, ARTIF INTELL REV, V52, P2235, DOI 10.1007/s10462-017-9607-x
   Kumar R, 2009, ANNU IEEE IND CONF, P143
   Kumar R, 2012, IEEE T INF FOREN SEC, V7, P809, DOI 10.1109/TIFS.2011.2176119
   Kumar R, 2009, LECT NOTES COMPUT SC, V5909, P400, DOI 10.1007/978-3-642-11164-8_65
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   MERRILL RA, 1992, J FORENSIC SCI, V37, P528
   Okawa M, 2015, IEEE T HUM-MACH SYST, V45, P339, DOI 10.1109/THMS.2014.2380828
   Padoan R, 2008, Art Proceedings, P25
   Pal R, 2019, INT C COMP VIS IM PR, P223
   Rahiche A., 2020, P IEEE CVF C COMP VI, P662
   Roux C, 1999, FORENSIC SCI INT, V101, P167, DOI 10.1016/S0379-0738(99)00021-3
   Roy P, 2019, IEEE INT C ID SEC BE, P1
   Roy P, 2020, ADV INTELL SYST, V1024, P183, DOI 10.1007/978-981-32-9291-8_16
   Roy P, 2019, LECT NOTES COMPUT SC, V11941, P596, DOI 10.1007/978-3-030-34869-4_65
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stuner B, 2020, MULTIMED TOOLS APPL, V79, P34407, DOI 10.1007/s11042-020-09198-6
   Subrahmanyam M, 2013, COMPUT ELECTR ENG, V39, P762, DOI 10.1016/j.compeleceng.2012.11.023
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Teixeira CA, 2019, MICROCHEM J, V144, P411, DOI 10.1016/j.microc.2018.10.002
   Tejawat M, 2015, INT C ADV COMP NETW, P631
   Vipparthi SK, 2014, EXPERT SYST APPL, V41, P8016, DOI 10.1016/j.eswa.2014.07.001
   Wadhwa A., 2018, PROC 15 IEEE INDIA C, P1, DOI [10.1109/INDICON45594.2018.8987116, DOI 10.1109/INDICON45594.2018.8987116]
   Wang WL, 2017, 2017 9TH INTERNATIONAL CONFERENCE ON ADVANCED INFOCOMM TECHNOLOGY (ICAIT 2017), P345, DOI 10.1109/ICAIT.2017.8388943
   Wang XF, 2008, FORENSIC SCI INT, V180, P43, DOI 10.1016/j.forsciint.2008.06.008
NR 56
TC 2
Z9 2
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30881
EP 30909
DI 10.1007/s11042-022-12843-x
EA APR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779229700002
DA 2024-07-18
ER

PT J
AU Raju, KU
   Prabha, NA
AF Raju, K. Upendra
   Prabha, N. Amutha
TI Error-free and mean value based reversible data hiding using
   gravitational search algorithm in encrypted images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Data security; Encrypted images; Alpha channel;
   Content owner; Gravitational search algorithm
ID HIGH-CAPACITY
AB In recent years the data hiding on encrypted image is significant topic for data security. Due to its capability for preserving confidentiality, Reversible Data Hiding (RDH) on encrypted domain will helpful on cloud computing as an emerging technology. In this paper, an error free and mean value based RDH process with high capacity on encrypted images is proposed. Here, the image provider (content owner), data hider and data receiver are three parties. Initially, the image provider keeps the averages to obtain the modified image. Encrypt the modified image further through the aid of the encryption key and pass it to data hider. In data hider, Gravitational Search Algorithm (GSA) is utilized to find the best pixel locations in encrypted image for information hiding. Moreover, the similar encrypted image size, an alpha channel is created and then combines the encrypted image and the alpha channel for embedding secret data to make an encrypted image with embedded data. On receiver side, through the aid of encryption key, the receiver recovers the image by decrypting the encrypted image and also the secret bits are removed through the aid of data hiding keys by data extraction. The experimental result demonstrates that proposed system has better performance compared to other state-of- art strategies. The peak signal-to-noise ratio (PSNR) achieved by the proposed system is better than 8.36% and 18.3% compared to other existing works.
C1 [Raju, K. Upendra] VIT, SENSE, Vellore, Tamil Nadu, India.
   [Prabha, N. Amutha] VIT Univ, Sch Elect Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Prabha, NA (corresponding author), VIT Univ, Sch Elect Engn, Vellore, Tamil Nadu, India.
EM amuthaprabha@vit.ac.in
RI Konduru, Dr. K. Upendra Raju/ACD-7711-2022
OI Konduru, Dr. K. Upendra Raju/0000-0001-7834-3503
CR Anajemba JH, 2020, INT CONF COMM SYST, P201, DOI [10.1109/CSNT.2020.38, 10.1109/CSNT48778.2020.9115741]
   Aryal A, 2017, ASIAPAC SIGN INFO PR, P203, DOI 10.1109/APSIPA.2017.8282028
   Bhardwaj R, 2020, PATTERN RECOGN LETT, V139, P60, DOI 10.1016/j.patrec.2018.01.014
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Jana B, 2016, OPTIK, V127, P3347, DOI 10.1016/j.ijleo.2015.12.055
   Khosravi Mohammad R., 2020, Current Signal Transduction Therapy, V15, P215, DOI 10.2174/1574362413666181005101315
   Li Q, 2018, MULTIMED TOOLS APPL, V77, P30749, DOI 10.1007/s11042-018-6187-y
   Lizhi Xiong, 2018, Multidimensional Systems and Signal Processing, V29, P1191, DOI 10.1007/s11045-017-0497-5
   Mehmood Y, 2017, IEEE COMMUN MAG, V55, P16, DOI 10.1109/MCOM.2017.1600514
   Mythili S., 2020, HKIE T, V27, P25, DOI DOI 10.33430/V27N1THIE-2018-0024
   O Akbarzadeh, 2020, J Biomed Phys Eng, V10, P357, DOI 10.31661/jbpe.v0i0.797
   Prakash G., 2013, Journal of Theoretical and Applied Information Technology, V58, P623
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qian ZX, 2019, IEEE T CIRC SYST VID, V29, P351, DOI 10.1109/TCSVT.2018.2797897
   Rajesh P., 2020, Eur J Electr Eng, V22, P224, DOI [10.18280/ejee.224-509, DOI 10.18280/EJEE.224-509]
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Sakthivel S., 2014, INT J APPL ENG RES, V9, P17601
   Shajin FH, 2022, INT J PERVASIVE COMP, V18, P603, DOI 10.1108/IJPCC-09-2020-0136
   Shen WT, 2019, IEEE T INF FOREN SEC, V14, P331, DOI 10.1109/TIFS.2018.2850312
   Smieee CI, 2018, IEEE INT CONF INDUST, P1935, DOI 10.1109/ICIT.2018.8352482
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tang ZJ, 2018, OPTIK, V157, P750, DOI 10.1016/j.ijleo.2017.11.154
   Tavallali P, 2019, MULTIMED TOOLS APPL, V78, P2599, DOI 10.1007/s11042-018-6385-7
   Thota M. K., 2020, Int. J. ApplSci Eng., V17, P331, DOI [DOI 10.6703/IJASE.20201217(4).331, DOI 10.6703/IJASE.202012_17(4).331]
   Upendra Raju K., 2018, P ARPN J ENG APPL SC, V13, P1105
   Upendra Raju K., 2019, P J ADV RES DYNAMICA, V11, P163
   Vaferi E, 2015, OPTIK, V126, P2474, DOI 10.1016/j.ijleo.2015.06.012
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wu HZ, 2017, IEEE T CIRC SYST VID, V27, P1620, DOI 10.1109/TCSVT.2016.2556585
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Yi S, 2018, SIGNAL PROCESS, V150, P171, DOI 10.1016/j.sigpro.2018.04.016
   Zhang XQ, 2017, MULTIMED TOOLS APPL, V76, P9195, DOI 10.1007/s11042-016-3521-0
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhenjun Tang, 2011, Journal of Multimedia, V6, P202, DOI 10.4304/jmm.6.2.202-206
NR 35
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30749
EP 30768
DI 10.1007/s11042-022-12419-9
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779233200009
DA 2024-07-18
ER

PT J
AU Selvaganesh, B
   Ganesan, R
AF Selvaganesh, B.
   Ganesan, R.
TI A hybrid segmentation and classification techniques for detecting the
   neurodegenerative disorder from brain Magnetic Resonance Images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neurodegenerative disorder; Alzheimer's Disease (AD); Parkinson's
   Disease (PD); Normal control (NC); Particle swarm optimization (PSO);
   Self-Organizing Map (SOM); Neighbor intensity pattern (NIP); Neural
   network (NN); K-Nearest Neighbor (KNN) classification
ID ALZHEIMERS-DISEASE; TEXTURE ANALYSIS
AB The mechanism of detecting the neurodegenerative disorder from Magnetic Resonance Images (MRIs) is one of the demanding and critical process in recent days. For this purpose, the existing works introduced some of the segmentation and classification techniques, which were used to detect the abnormal region from the brain images. However, it limits the problems of over segmentation, inefficient classification, and more complexity. The early predictions and the diagnosis process of neurodegenerative-disorders were accomplished by the use of segmentation and classification approaches of various methods. The proposed methodology focused on developing an integrated segmentation and classification techniques for an accurate brain disease classification. Here, the most extensively used segmentation techniques such Particle Swarm Optimization (PSO) and Self-Organizing Map (SOM) techniques are integrated for enabling an efficient image segmentation. In addition, it segments the Grey Matter (GM), White Matter (WM) and Cerebrospinal Fluid (CSF) regions. Consequently, the most suitable features are extracted from the segmented image by using the Neighbor Intensity Pattern (NIP) extraction technique. Based on these features, the normal and abnormal regions are classified by the use of an integrated Neural Network and K-Nearest Neighbor (KNN) classification techniques. The hybridization of the work is, that it integrates the benefits of various segmentation and classification techniques, which leads to increased detection efficiency and classification accuracy. The performance of these techniques are evaluated by using two different datasets such as ADNI and PPMI, which contains more number of brain MRIs. Also, various performance parameters have been utilized to test the results of the proposed system. Moreover, the traditional classification techniques are considered to compare the results of the proposed classification technique. During experimental evaluation, the performance of the techniques are validated by using different measures, and the results are compared with other existing techniques for analyzing the efficiency of proposed mechanism. At last, the results stated that the NN-KNN outperforms the other techniques by exactly locating the affected regions. The proposed framework exhibits the higher performance of accuracy level with 98.6%, sensitivity rate of 95%, exposed 96% of specificity rate and acquires the efficient precision rate of 99.21%. In future, this work can be expanded by using some advanced techniques for classifying other brain diseases.
C1 [Selvaganesh, B.; Ganesan, R.] EGS Pillay Engn Coll, Dept Elect & Elect Engn, Nagapattinam 611002, Tamil Nadu, India.
RP Selvaganesh, B (corresponding author), EGS Pillay Engn Coll, Dept Elect & Elect Engn, Nagapattinam 611002, Tamil Nadu, India.
EM bselvaganesh@gmail.com; ganesanhod@gmail.com
RI Dr. R, Ganesan/AGP-3121-2022; R, Ganesan/E-3175-2017
OI Dr. R, Ganesan/0000-0003-0559-0591; 
CR Abdullah A., 2020, LIFE SCI J, V17, P59
   Bento M, 2018, LECT NOTES COMPUT SC, V10882, P538, DOI 10.1007/978-3-319-93000-8_61
   Betrouni N, 2020, TRANSL STROKE RES, V11, P643, DOI 10.1007/s12975-019-00746-3
   Chan, 2019, MAXIMUM PSEUDOLIKELI, V2019, P1
   Holilah D., 2021, Journal of Physics: Conference Series, V1725, DOI 10.1088/1742-6596/1725/1/012009
   Kalam A, 2018, ADV ELECT COMMUNICAT
   Khatri U, 2020, COMPUTATIONAL INTELL, P1
   Kumar PR, 2018, COMPUT ELECTR ENG, V72, P283, DOI 10.1016/j.compeleceng.2018.09.019
   Liu MX, 2016, IEEE T MED IMAGING, V35, P1463, DOI 10.1109/TMI.2016.2515021
   Ma D, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00853
   Maikusa, 2020, HARMONIZED Z SCORES
   Oppedal K, 2017, BIOMED SIGNAL PROCES, V33, P19, DOI 10.1016/j.bspc.2016.10.007
   Ortiz-Ramón R, 2019, COMPUT MED IMAG GRAP, V74, P12, DOI 10.1016/j.compmedimag.2019.02.006
   Osadebey ME, 2018, BMC MED IMAGING, V18, DOI 10.1186/s12880-018-0266-4
   Prashanth R, 2017, IEEE J BIOMED HEALTH, V21, P794, DOI 10.1109/JBHI.2016.2547901
   Priyadarshini, 2020, IJATCSE INT J, V9, P2278
   Qiu SR, 2020, BRAIN, V143, P1920, DOI 10.1093/brain/awaa137
   Rallabandi V. P. Subramanyam, 2020, Informatics in Medicine Unlocked, V18, P295, DOI 10.1016/j.imu.2020.100305
   Sivaranjini S, 2020, MULTIMED TOOLS APPL, V79, P15467, DOI 10.1007/s11042-019-7469-8
   Solana-Lavalle G, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105793
   Uysal G, 2019, 2019 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO), P282, DOI 10.1109/tiptekno.2019.8895135
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P10393, DOI 10.1007/s11042-016-4222-4
   Wilson B, 2020, LMCST J ENG TECHNOL, V5, P2278
NR 23
TC 3
Z9 3
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28801
EP 28822
DI 10.1007/s11042-022-12967-0
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900014
DA 2024-07-18
ER

PT J
AU Qiao, CC
   Wu, CM
   Li, CX
   Wang, JY
AF Qiao, CaiCai
   Wu, ChengMao
   Li, ChangXing
   Wang, JiaYe
TI Guided filter-driven kernel fuzzy clustering with local information for
   noise image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Fuzzy local information clustering; Kernel function;
   Guided filtering; Optimization model
ID C-MEANS ALGORITHM; SPATIAL INFORMATION; FCM
AB Fuzzy local information clustering is the most widely robust segmentation methods, but it is only suitable for image corrupted by certain intensity noise. Later, although fuzzy local information clustering integrated guided filter is improved the ability of suppressing noise, it still cannot meet the needs of image with high noise. This paper proposed a novel robust fuzzy local information clustering combined kernel metric with guided filter. Firstly, guided filter is introduced into fuzzy local information clustering with kernel metric (KWFLICM), and a novel multiple objective optimization model for fuzzy clustering is constructed. Secondly, the optimization model is solved by Lagrange multiplier method, and the iterative algorithm for image segmentation is presented. Experimental results show that the proposed algorithm has better segmentation performance and robustness than existing state of the art guided filter-driven fuzzy clustering with local information.
C1 [Qiao, CaiCai; Wang, JiaYe] Xian Univ Post & Telecommun, Sch Commun & Informat Engineer, Xian 710100, Peoples R China.
   [Wu, ChengMao] Xian Univ Post & Telecommun, Sch Elect & Engn, Xian 710100, Peoples R China.
   [Li, ChangXing] Xian Univ Post & Telecommun, Sch Sci, Xian 710100, Peoples R China.
C3 Xi'an University of Posts & Telecommunications; Xi'an University of
   Posts & Telecommunications; Xi'an University of Posts &
   Telecommunications
RP Qiao, CC (corresponding author), Xian Univ Post & Telecommun, Sch Commun & Informat Engineer, Xian 710100, Peoples R China.
EM qiaocaicai2021@163.com; Wuchengmao123@sohu.com; shuxueshiyanshi@163.com;
   galawjy@163.com
RI Cai, Qiao/GRJ-4433-2022; wang, jiaye/KMY-4046-2024
OI Qiao, Caicai/0000-0003-1811-7218
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Alonso F, 2004, P ANN INT IEEE EMBS, V26, P1794
   Bai XZ, 2019, IEEE J BIOMED HEALTH, V23, P2039, DOI 10.1109/JBHI.2018.2884208
   BEZDEK JC, 1976, IEEE T SYST MAN CYB, V6, P387
   Boskovitz V., 2010, FUZZY SYST, V10, P262, DOI 10.1109/91.995125
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Cao HB, 2012, IEEE T FUZZY SYST, V20, P1, DOI 10.1109/TFUZZ.2011.2160025
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Choy SK, 2017, PATTERN RECOGN, V68, P141, DOI 10.1016/j.patcog.2017.03.009
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   Dagher I., 2015, IEEE INT C FUZZY SYS, P1, DOI DOI 10.1109/FUZZ-IEEE.2015.7337804
   Fan F, 2017, INFORM SCIENCES, V397, P48, DOI 10.1016/j.ins.2017.02.044
   Feng F, 2018, CHIN AUTOM CONGR, P4124, DOI 10.1109/CAC.2018.8623471
   Gharieb RR, 2017, APPL SOFT COMPUT, V59, P143, DOI 10.1016/j.asoc.2017.05.055
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Guangmei Xu, 2018, 2018 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC), P255, DOI 10.1109/SPAC46244.2018.8965448
   Guo L, 2018, DIGIT SIGNAL PROCESS, V83, P235, DOI 10.1016/j.dsp.2018.08.022
   Guo L, 2017, INT J FUZZY SYST, V19, P1660, DOI 10.1007/s40815-017-0322-1
   Guo L, 2016, IEEE SYS MAN CYBERN, P4271, DOI 10.1109/SMC.2016.7844902
   Guo YH, 2013, CIRC SYST SIGNAL PR, V32, P1699, DOI 10.1007/s00034-012-9531-x
   Ham B, 2015, PROC CVPR IEEE, P4823, DOI 10.1109/CVPR.2015.7299115
   Happ PN, 2015, INT GEOSCI REMOTE SE, P4352, DOI 10.1109/IGARSS.2015.7326790
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang CW, 2015, SOFT COMPUT, V19, P459, DOI 10.1007/s00500-014-1264-2
   Huang HC, 2012, IEEE T FUZZY SYST, V20, P120, DOI 10.1109/TFUZZ.2011.2170175
   Ji J, 2014, IEEE J-STARS, V7, P4929, DOI 10.1109/JSTARS.2014.2308531
   Jiang H, 2011, KEY ENG MATER, V474-476, P15, DOI 10.4028/www.scientific.net/KEM.474-476.15
   Kanaani S, 2017, PROCEEDINGS OF THE 2017 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P445, DOI 10.1109/ICCKE.2017.8167919
   Kou F, 2015, IEEE T IMAGE PROCESS, V24, P4528, DOI 10.1109/TIP.2015.2468183
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Memon KH, 2018, FUZZY SET SYST, V340, P91, DOI 10.1016/j.fss.2018.01.019
   Oda H, 2018, LECT NOTES COMPUT SC, V11071, P228, DOI 10.1007/978-3-030-00934-2_26
   Panagiotakis C, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.09.001
   Panigrahi L, 2018, IET COMPUT VIS, V12, P1067, DOI 10.1049/iet-cvi.2018.5332
   Patil A. B., 2016, INT J COMPUT ENG RES, V6, P1
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Qin GF, 2019, MULTIMED TOOLS APPL, V78, P5181, DOI 10.1007/s11042-017-4683-0
   Rajaby E, 2016, DIGIT SIGNAL PROCESS, V51, P170, DOI 10.1016/j.dsp.2016.01.010
   Sing JK, 2015, J CHEMOMETR, V29, P492, DOI 10.1002/cem.2728
   Song J, 2017, J Inf Hiding Multim Signal Process, V8, P578
   Sui X, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062195
   Szilágyi L, 2003, P ANN INT IEEE EMBS, V25, P724, DOI 10.1109/IEMBS.2003.1279866
   Wang AN, 2010, PROCEEDINGS OF 2010 INTERNATIONAL CONFERENCE ON LOGISTICS SYSTEMS AND INTELLIGENT MANAGEMENT, VOLS 1-3, P1462, DOI 10.1109/ICLSIM.2010.5461210
   Wang WN, 2007, FUZZY SET SYST, V158, P2095, DOI 10.1016/j.fss.2007.03.004
   [吴其平 Wu Qiping], 2018, [中国图象图形学报, Journal of Image and Graphics], V23, P1838
   Wu X., 2010, 18 INT C GEOINF, P1, DOI DOI 10.1109/GEOINFORMATICS.2010.5567589
   Xie Y, 2010, INT C GEOINF, P18, DOI [10.1109/GEOINFORMATICS.2010.5567552, DOI 10.1109/GEOINFORMATICS.2010.5567552, 10. 1109/GEOINFORMATICS. 2010. 5567552]
   Xu GM, 2020, INT J MACH LEARN CYB, V11, P2793, DOI 10.1007/s13042-020-01151-1
   Yan Q, 2013, IEEE I CONF COMP VIS, P1537, DOI 10.1109/ICCV.2013.194
   Yang B, 2009, 2009 IITA INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS ENGINEERING, PROCEEDINGS, P636, DOI 10.1109/CASE.2009.106
   Zengwei Ju, 2013, 2013 IEEE 4th International Conference on Software Engineering and Service Science (ICSESS), P385, DOI 10.1109/ICSESS.2013.6615330
   Zhang XL, 2019, 2019 2 INT C INT SYS, P253, DOI [10.25236/isrme.2019.045, DOI 10.25236/ISRME.2019.045]
   Zhao F, 2013, NEUROCOMPUTING, V106, P115, DOI 10.1016/j.neucom.2012.10.022
   Zhu HM, 2016, INT GEOSCI REMOTE SE, P3354, DOI 10.1109/IGARSS.2016.7729867
   Zhu HM, 2016, INT GEOSCI REMOTE SE, P2340, DOI 10.1109/IGARSS.2016.7729604
NR 60
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28431
EP 28477
DI 10.1007/s11042-022-12840-0
EA MAR 2022
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000775769200005
DA 2024-07-18
ER

PT J
AU Bhuiyan, MR
   Abdullah, J
   Hashim, N
   Al Farid, F
AF Bhuiyan, Md Roman
   Abdullah, Junaidi
   Hashim, Noramiza
   Al Farid, Fahmid
TI Video analytics using deep learning for crowd analysis: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Deep learning; Crowd analysis; Abnormal behavior; Video surveillances
ID ANOMALY DETECTION; NEURAL-NETWORK; TRACKING
AB Gathering a large number of people in a shared physical area is very common in urban culture. Although there are limitless examples of mega crowds, the Islamic religious ritual, the Hajj, is considered as one of the greatest crowd scenarios in the world. The Hajj is carried out once in a year with a congregation of millions of people when the Muslims visit the holy city of Makkah at a given time and date. Such a big crowd is always prone to public safety issues, and therefore requires proper measures to ensure safe and comfortable arrangement. Through the advances in computer vision based scene understanding, automatic analysis of crowd scenes is gaining popularity. However, existing crowd analysis algorithms might not be able to correctly interpret the video content in the context of the Hajj. This is because the Hajj is a unique congregation of millions of people crowded in a small area, which can overwhelm the use of existing video and computer vision based sophisticated algorithms. Through our studies on crowd analysis, crowd counting, density estimation, and the Hajj crowd behavior, we faced the need of a review work to get a research direction for abnormal behavior analysis of Hajj pilgrims. Therefore, this review aims to summarize the research works relevant to the broader field of video analytics using deep learning with a special focus on the visual surveillance in the Hajj. The review identifies the challenges and leading-edge techniques of visual surveillance in general, which may gracefully be adaptable to the applications of Hajj and Umrah. The paper presents detailed reviews on existing techniques and approaches employed for crowd analysis from crowd videos, specifically the techniques that use deep learning in detecting abnormal behavior. These observations give us the impetus to undertake a painstaking yet exhilarating journey on crowd analysis, classification and detection of any abnormal movement of the Hajj pilgrims. Furthermore, because the Hajj pilgrimage is the most crowded domain for video-related extensive research activities, this study motivates us to critically analyze the crowd on a large scale.
C1 [Bhuiyan, Md Roman; Abdullah, Junaidi; Hashim, Noramiza; Al Farid, Fahmid] Multimedia Univ, Fac Comp & Informat, Cyberjaya 63100, Selangor, Malaysia.
C3 Multimedia University
RP Bhuiyan, MR (corresponding author), Multimedia Univ, Fac Comp & Informat, Cyberjaya 63100, Selangor, Malaysia.
EM romanbhuiyanpv@gmail.com; junaidi.abdullah@mmu.edu.my;
   noramiza.hashim@mmu.edu.my; fahmid.farid@gmail.com
RI BHUIYAN, MD ROMAN/JAD-1640-2023; Farid, Fahmid Al/AAZ-8271-2021; Hashim,
   Noramiza/B-3699-2010
OI BHUIYAN, MD ROMAN/0000-0002-8919-4459; Farid, Fahmid
   Al/0000-0003-2625-2348; Hashim, Noramiza/0000-0001-9838-2892
FU Multimedia University, Cyberjaya, Malaysia
FX Multimedia University, Cyberjaya, Malaysia fully supported this
   research.
CR Albattah W, 2021, CMC-COMPUT MATER CON, V66, P2183, DOI 10.32604/cmc.2020.014227
   Amirgholipour S, 2018, IEEE IMAGE PROC, P948, DOI 10.1109/ICIP.2018.8451399
   Anjum N, 2008, IEEE T CIRC SYST VID, V18, P1555, DOI 10.1109/TCSVT.2008.2005603
   [Anonymous], COMPUT VIS PATTERN R
   Arteta C, 2016, LECT NOTES COMPUT SC, V9911, P483, DOI 10.1007/978-3-319-46478-7_30
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Basharat A, 2008, PROC CVPR IEEE, P1301
   Bendali-Braham M, 2020, RECENT TRENDS CROWD, V4
   Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300
   Brostow G.J., 2006, CVPR, P594, DOI DOI 10.1109/CVPR.2006.320
   Candamo J, 2010, IEEE T INTELL TRANSP, V11, P206, DOI 10.1109/TITS.2009.2030963
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chattopadhyay P, 2017, PROC CVPR IEEE, P4428, DOI 10.1109/CVPR.2017.471
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Cheng HY, 2011, J VIS COMMUN IMAGE R, V22, P673, DOI 10.1016/j.jvcir.2011.07.001
   Cohen JP, 2017, IEEE INT CONF COMP V, P18, DOI 10.1109/ICCVW.2017.9
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Deb D, 2018, IEEE COMPUT SOC CONF, P308, DOI 10.1109/CVPRW.2018.00057
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Du DW, 2013, IEEE INT CON MULTI
   Elbishlawi S, 2020, J IMAGING, V6, DOI 10.3390/jimaging6090095
   Feng YC, 2017, NEUROCOMPUTING, V219, P548, DOI 10.1016/j.neucom.2016.09.063
   Fiaschi T, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034782
   Forsyth D, 2014, COMPUTER, V47, P6, DOI 10.1109/MC.2014.42
   Fu M, 2015, ENG APPL ARTIF INTEL, V43, P81, DOI 10.1016/j.engappai.2015.04.006
   Gao G., 2020, CNN BASED DENSITY ES, P1
   Gao JY, 2020, IEEE T CIRC SYST VID, V30, P3486, DOI 10.1109/TCSVT.2019.2919139
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   Han K, 2017, J ADV COMPUT INTELL, V21, P632, DOI 10.20965/jaciii.2017.p0632
   Hossain MA, 2019, IEEE WINT CONF APPL, P1280, DOI 10.1109/WACV.2019.00141
   Hu YC, 2016, J VIS COMMUN IMAGE R, V38, P530, DOI 10.1016/j.jvcir.2016.03.021
   Huang SY, 2018, IEEE T IMAGE PROCESS, V27, P1049, DOI 10.1109/TIP.2017.2740160
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Ilyas N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010043
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kang D., 2019, BRIT MACHINE VISION, P1
   Kumar Ajay, 2021, Turkish Journal of Computer and Mathematics Education (TURCOMAT), V12, P2322
   Lempitsky V, 2010, LEARNING COUNT OBJEC, P1
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li YC, 2020, J MED VIROL, V92, P552, DOI 10.1002/jmv.25728
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545
   Liu LB, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P849
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Lu T, 2014, INT C PATT RECOG, P2203, DOI 10.1109/ICPR.2014.383
   Marsden M, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Marsden M, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P27, DOI 10.5220/0006097300270033
   Mundhenk TN, 2016, LECT NOTES COMPUT SC, V9907, P785, DOI 10.1007/978-3-319-46487-9_48
   Onoro-Rubio D, 2018, P BRIT MACH VIS C BM, P1
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Rodriguez M, 2011, IEEE I CONF COMP VIS, P1235, DOI 10.1109/ICCV.2011.6126374
   Ryan D, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P81, DOI 10.1109/DICTA.2009.22
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Shami MB, 2019, IEEE T CIRC SYST VID, V29, P2627, DOI 10.1109/TCSVT.2018.2803115
   Sindagi VA, 2017, CRPATTERN RECOGNITIO, DOI 10.1016/j.patrec.2017.07.007
   Sindagi VA, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Singh K, 2020, NEUROCOMPUTING, V371, P188, DOI 10.1016/j.neucom.2019.08.059
   Tian YK, 2020, IEEE T IMAGE PROCESS, V29, P2714, DOI 10.1109/TIP.2019.2952083
   Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Vanden Oord A., 2014, ADV NEURAL INFORM PR, P3518
   Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372
   Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41
   Wang C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1299, DOI 10.1145/2733373.28063370-12345-67-8/90/01
   Wang Q, 2021, IEEE T PATTERN ANAL, V43, P2141, DOI 10.1109/TPAMI.2020.3013269
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Xinyi Cui, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3161, DOI 10.1109/CVPR.2011.5995558
   Xu ML, 2019, PATTERN RECOGN LETT, V125, P563, DOI 10.1016/j.patrec.2019.02.026
   Yang B, 2018, SIGNAL PROCESS-IMAGE, V64, P118, DOI 10.1016/j.image.2018.03.004
   Zeng X, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112977
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhang YM, 2018, NEUROCOMPUTING, V273, P190, DOI 10.1016/j.neucom.2017.08.018
   Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007
   Zhu J, 2018, PROCEEDINGS 2018 33RD YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P993, DOI 10.1109/YAC.2018.8406516
NR 82
TC 12
Z9 12
U1 5
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27895
EP 27922
DI 10.1007/s11042-022-12833-z
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000774644100005
OA hybrid
DA 2024-07-18
ER

PT J
AU Marques, G
   Ferreras, A
   de la Torre-Diez, I
AF Marques, Goncalo
   Ferreras, Antonio
   de la Torre-Diez, Isabel
TI An ensemble-based approach for automated medical diagnosis of malaria
   using EfficientNet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; EfficientNet; Health informatics; Machine
   learning; Malaria
ID IMAGE-ANALYSIS; RECOGNITION; ERYTHROCYTES
AB Each year, more than 400,000 people die of malaria. Malaria is a mosquito-borne transmissible infection that affects humans and other animals. According to World Health Organization (WHO), 1.5 billion malaria cases and 7.6 million related deaths have been prevented from 2000 to 2019. Malaria is a disease that can be treated if early detected. We propose a support decision system for detecting malaria from microscopic peripheral blood cells images through convolutional neural networks (CNN). The proposed model is based on EfficientNetB0 architecture. The results are validated with 10-fold stratified cross-validation. This paper presents the classification findings using images from malaria patients and normal patients. The proposed approach is compared and outperforms the related work. Furthermore, the proposed ensemble method shows a recall value of 98.82%, a precision value of 97.74%, an F1-score of 98.28% and a ROC value of 99.76%. This work suggests that EfficientNet is a reliable architecture for automatic medical diagnostics of malaria.
C1 [Marques, Goncalo; Ferreras, Antonio; de la Torre-Diez, Isabel] Univ Valladolid, Dept Signal Theory & Commun & Telemat Engn, Paseo de Belen 15, Valladolid 47011, Spain.
C3 Universidad de Valladolid
RP Marques, G (corresponding author), Univ Valladolid, Dept Signal Theory & Commun & Telemat Engn, Paseo de Belen 15, Valladolid 47011, Spain.
EM goncalosantosmanques@gmail.com; antonio.ferrerasextremo@gmail.com;
   isator@tel.uva.es
RI de la Torre, Isabel Prof./B-7064-2008; Marques, Goncalo/N-1805-2018
OI de la Torre, Isabel Prof./0000-0003-3134-7720; Marques,
   Goncalo/0000-0001-5834-6571
CR Al-Qizwini M, 2017, IEEE INT VEH SYM, P89, DOI 10.1109/IVS.2017.7995703
   [Anonymous], 2017, Dual path networks
   Brown G., 2011, Encyclopedia of Machine Learning
   Buslaev A, 2020, INFORMATION, V11, DOI 10.3390/info11020125
   Caraballo Hector, 2014, Emerg Med Pract, V16, P1
   Rangel JC, 2018, APPL SOFT COMPUT, V65, P603, DOI 10.1016/j.asoc.2018.02.005
   Das D, 2019, COMPUTER AIDED TOOL, V8
   Das DK, 2013, J MICROSC-OXFORD, V249, P136, DOI 10.1111/jmi.12002
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Duong LT, 2020, COMPUT ELECTRON AGR, V171, DOI 10.1016/j.compag.2020.105326
   Ersoy I, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P748, DOI 10.1109/ISBI.2012.6235656
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jais IKM., 2019, KNOWL ENG DATA SCI, V2, P41, DOI [DOI 10.17977/UM018V2I12019P41-46, 10.17977/um018v2i12019p41-46]
   Jan Z, 2019, IEEE S SER COMP INT
   Ji X, 2019, INTELLIGENT COMPUTIN, P663, DOI DOI 10.1007/978-3-030-26763-6_63
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Kaur H, 2020, NEURAL COMPUT APPL, V32, P12697, DOI 10.1007/s00521-020-04720-1
   KIMURA F, 1991, PATTERN RECOGN, V24, P969, DOI 10.1016/0031-3203(91)90094-L
   Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Liang ZH, 2016, IEEE INT C BIOINFORM, P493, DOI 10.1109/BIBM.2016.7822567
   Makhija KS, 2015, PATHOLOGY, V47, P68, DOI 10.1097/PAT.0000000000000190
   Malihi L, 2013, IRAN CONF MACH, P360, DOI 10.1109/IranianMVIP.2013.6780011
   Marques G, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106691
   Mirri S, 2020, COMPUTATION, V8, DOI 10.3390/computation8030074
   Mitiku K., 2003, ETHIOP J HEALTH DEV, V17, P149
   Parinov, ALBUMENTATIONS
   Perrone MP, 1995, We Learn We Remember an Understanding of Brain Neural Systems, P342, DOI 10.1142/9789812795885_0025
   Poostchi M, 2018, TRANSL RES, V194, P36, DOI 10.1016/j.trsl.2017.12.004
   Purwar Y, 2011, MALARIA J, V10, DOI 10.1186/1475-2875-10-364
   Quan Q, 2020, INTERDISCIP SCI, V12, P217, DOI 10.1007/s12539-020-00367-7
   Rahman A., 2019, Improving Malaria Parasite Detection from Red Blood Cell using Deep Convolutional Neural Networks
   Rajaraman S, 2018, PEERJ, V6, DOI 10.7717/peerj.4568
   Re M, 2012, CH CRC DATA MIN KNOW, P563
   Roccetti M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00428-8
   Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249
   Sarwar Abid, 2020, International Journal of Information Technology, V12, P419, DOI 10.1007/s41870-018-0270-5
   Savkare SS, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATION, INFORMATION & COMPUTING TECHNOLOGY (ICCICT)
   Shah D, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P984, DOI 10.1109/ICICCS48265.2020.9121073
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sio SWS, 2007, J MICROBIOL METH, V68, P11, DOI 10.1016/j.mimet.2006.05.017
   Somasundaram A, 2016, PROC 1 INT C RES ENG, P1
   Sun YM, 2009, INT J PATTERN RECOGN, V23, P687, DOI 10.1142/S0218001409007326
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tan M., 2019, EfficientNet: Improving Accuracy and Efficiency through AutoML and Model Scaling
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tavanaei A, 2019, NEURAL NETWORKS, V111, P47, DOI 10.1016/j.neunet.2018.12.002
   Tokumasu F, 2005, J CELL SCI, V118, P1091, DOI 10.1242/jcs.01662
   Tukiainen M, IMAGEDATAAUGMENTOR
   Verbraeken J, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3377454
   Vink JP, 2013, J MICROSC-OXFORD, V250, P166, DOI 10.1111/jmi.12032
   Wang C, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106253
   Wang Y, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106302
   WHO, 2011, WORLD MALARIA REPORT 2011, P1
   World Health Organization, 2015, GUID TREATM MAL
   Xiao YW, 2018, COMPUT METH PROG BIO, V153, P1, DOI 10.1016/j.cmpb.2017.09.005
   Yadav Dhyan Chandra, 2019, Asian Pac J Cancer Prev, V20, P1275
   Yakubovskiy P, KERAS TENSORFLOW KER
   Yang F, 2021, INT J HUM RESOUR MAN, V32, P2493, DOI 10.1080/09585192.2019.1588347
NR 59
TC 14
Z9 14
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 28061
EP 28078
DI 10.1007/s11042-022-12624-6
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000774644100012
PM 35368860
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Gupta, J
   Pathak, S
   Kumar, G
AF Gupta, Jaya
   Pathak, Sunil
   Kumar, Gireesh
TI A hybrid optimization-tuned deep convolutional neural network for bare
   skinned image classification in websites
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pornography; Porn image; Websites; Deep convolutional neural network;
   Optimization
ID ALGORITHM
AB With the advent of the Internet, social media, and mobile technologies, pornographic images have been broadly disseminated and caused great destruction to the social stability and the psychology of adolescents. Furthermore, pornographic content acts as one of the major causes of crimes and abuses, and hence it is crucial to identify such images in the websites. This paper proposes an optimization tuned Deep Convolutional neural network (Deep-CNN) model for classifying pornographic images in websites. The significance in the classification of such images relies on the utilization of the proposed spotted hyena Aquila (SHyAq) optimization algorithm that inherits the characteristics of the hyena hunters and the Aquila hunters in tuning the tunable weights of the Deep-CNN model optimally. In addition, the performance of the proposed SHyAq-based Deep-CNN model is enhanced using the significant features of the image extracted using the feature extraction strategy. Finally, the proposed porn image classification model analysis is carried out based on the performance metrics, such as accuracy, sensitivity, and specificity. The results thus obtained are compared with the existing methods to validate the effectiveness of the proposed model in porn image classification. The proposed SHyAq-based Deep-CNN technique outperformed other states of the art techniques like AIRNet, Multiple feature fusion transfer learning, MLP, FSVM, DOCAPorn, CNN, Multi-level CNN, Deep CNN, Aquila-based Deep CNN, Coyote-based Deep CNN, and AqCO-based Deep CNN in terms of accuracy, sensitivity, and the specificity with the values of 96.46% each, respectively.
C1 [Gupta, Jaya; Pathak, Sunil] Amit Univ, Amity Sch Engn & Technol, Jaipur, Rajasthan, India.
   [Kumar, Gireesh] JK Lakshmipat Univ, Jaipur, Rajasthan, India.
RP Pathak, S (corresponding author), Amit Univ, Amity Sch Engn & Technol, Jaipur, Rajasthan, India.
EM jayagupta286@gmail.com; sunilpath@gmail.com; gireesh8@gmail.com
OI Pathak, Dr. Sunil/0000-0001-7409-9814
CR Abualigah L, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107250
   AGASTYA IMA, 2018, 2018 4 INT C ADV COM, P1, DOI DOI 10.1109/ICACCAF.2018.8776843
   Agrawal D, 2021, COMPUT BIOL MED
   Agrawal D, 2021, IEEE 15TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS (SACI 2021), P199, DOI 10.1109/SACI51354.2021.9465609
   Ahmadi R, 2020, J MANAG ACCOUNT STUD, V8
   Alguliyev RM, 2020, CAAI T INTELL TECHNO, V5, P9, DOI 10.1049/trit.2019.0048
   Appati JK, 2021, INT J SOFTW INNOV, V9, P102, DOI 10.4018/IJSI.2021040106
   AsadUllah M, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/6759526
   Binu D, 2021, IEEE T IND ELECTRON, V68, P10097, DOI 10.1109/TIE.2020.3028796
   Burlina PM, 2020, COMPUT BIOL MED, V125, DOI 10.1016/j.compbiomed.2020.103977
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Chen JR, 2020, IEEE ACCESS, V8, P122709, DOI 10.1109/ACCESS.2020.2988736
   Cheng F, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106983
   Dhar P., 2021, INT J ENG MANUF, V11, P11, DOI [10.5815/ijem.2021.01.02, DOI 10.5815/IJEM.2021.01.02]
   Doreswamy, 2020, CAAI T INTELL TECHNO, V5, P283, DOI 10.1049/trit.2020.0073
   El Khadiri I, 2018, COMPUT VIS IMAGE UND, V169, P14, DOI 10.1016/j.cviu.2018.01.004
   Farooq MS, 2019, INT CONF INF COMMUN, P106, DOI [10.1109/ICICT47744.2019.9001915, 10.1109/icict47744.2019.9001915]
   Gupta J., 2022, INT J EMERG TECHNOL, V12, P130
   Hidayati SC, 2021 13 INT C INF CO, P155
   Hussain S, 2019, J INTELL FUZZY SYST, V37, P2769, DOI 10.3233/JIFS-18760
   Jiang QS, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010087
   Kumar A, 2021, INT J WEB GRID SERV, V17, P321, DOI 10.1504/IJWGS.2021.118398
   Kumar V, 2020, J AMB INTEL HUM COMP, V11, P2625, DOI 10.1007/s12652-019-01324-z
   Laier Christian, 2017, Addict Behav Rep, V5, P9, DOI 10.1016/j.abrep.2016.11.003
   Li L., 2017, PAC RIM C MULT, P488
   Lin XN, 2021, INT J MACH LEARN CYB, V12, P73, DOI 10.1007/s13042-020-01157-9
   Moreira D.C., 2020, 2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring), P1, DOI DOI 10.1109/VTC2020-SPRING48590.2020.9129490
   Namasudra S., 2022, IEEE CONSUM ELECTR M
   Namasudra S, 2023, NEURAL PROCESS LETT, V55, P171, DOI 10.1007/s11063-021-10495-w
   Namasudra S, 2022, IEEE T SERV COMPUT, V15, P2289, DOI 10.1109/TSC.2020.3046471
   Namasudra S, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3392665
   Ndichu S, 2020, CAAI T INTELL TECHNO, V5, P184, DOI 10.1049/trit.2020.0026
   Khoa NH, 2020, IEEE RIVF INT CONF, P342, DOI 10.1109/rivf48685.2020.9140739
   Nurhadiyatna A, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P106, DOI 10.1109/IC3INA.2017.8251749
   Patel KD, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P533, DOI [10.1109/ICICCS48265.2020.9120926, 10.1109/iciccs48265.2020.9120926]
   Pierezan J, 2018, IEEE C EVOL COMPUTAT, P2633, DOI 10.1109/CEC.2018.8477769
   Rothman EF, 2021, ARCH SEX BEHAV, V50, P629, DOI 10.1007/s10508-020-01877-7
   Ying ZF, 2018, PROCEEDINGS OF 2018 IEEE 4TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2018), P212, DOI 10.1109/ITOEC.2018.8740365
   Yuangyai C, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01889-0
   Zeebaree DQ, 2021, CMC-COMPUT MATER CON, V66, P3363, DOI 10.32604/cmc.2021.013314
NR 40
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26283
EP 26305
DI 10.1007/s11042-022-12891-3
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000780464900008
DA 2024-07-18
ER

PT J
AU Imoto, D
   Hirabayashi, M
   Honma, M
   Kurosawa, K
AF Imoto, Daisuke
   Hirabayashi, Manato
   Honma, Masakatsu
   Kurosawa, Kenji
TI Enhancing the robustness of forensic gait analysis against near-distance
   viewing direction differences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D camera parameter calibration; Forensics; Gait energy image;
   Silhouette-based gait analysis; Practicality
ID RECOGNITION
AB Gait analysis is a promising biometric technology to visually and quantitatively analyze an individual's walking style. In Japan, silhouette-based quantitative gait analyses have been implemented as a forensic tool; however, several challenges remain owing the narrow range of application. One of the yet-unsolved issues pertains to the existence of a 'slight' but critical viewing direction difference, which leads to the incorrect judgment in the analyses of a person even when using deep learning-based feature extraction. To alleviate the critical viewing direction difference problem, we developed a novel gait analysis technique involving three components: 3D calibration, gait energy image space registration, and regression of the distance vector. Results of the GUI development and mock appraisal tests indicated that the proposed method can help achieve practical improvements in the forensic science domain.
C1 [Imoto, Daisuke; Hirabayashi, Manato; Honma, Masakatsu] Natl Res Inst Police Sci, Dept Forens Sci 2, Artificial Intelligence Sect, Kashiwa, Chiba, Japan.
   [Kurosawa, Kenji] Natl Res Inst Police Sci, Dept Forens Sci 2, Kashiwa, Chiba, Japan.
RP Imoto, D (corresponding author), Natl Res Inst Police Sci, Dept Forens Sci 2, Artificial Intelligence Sect, Kashiwa, Chiba, Japan.
EM imoto@nrips.go.jp
OI Imoto, Daisuke/0000-0002-7419-5491
FU JSPS KAKENHI [JP17K18379, JP20K19835]; Grants-in-Aid for Scientific
   Research [20K19835] Funding Source: KAKEN
FX The authors would like to thank Prof. Yasushi Makihara at Osaka
   University for the valuable discussions. A part of this study was
   supported by JSPS KAKENHI grants (JP17K18379 and JP20K19835).
CR Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Baker R, 2006, J NEUROENG REHABIL, V3, DOI 10.1186/1743-0003-3-4
   Birch I, 2013, SCI JUSTICE, V53, P339, DOI 10.1016/j.scijus.2013.04.005
   Bouchrika I, 2011, J FORENSIC SCI, V56, P882, DOI 10.1111/j.1556-4029.2011.01793.x
   Cignoni P., 2008, P EUR IT CHAPT C, P129, DOI [DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136, 10.2312/LocalChapterEvents/ItalChap/ItalianChapConf2008/129-136]
   Edmond G, 2016, J CRIM LAW CRIM, V106, P219
   El-Alfy H, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P929, DOI 10.1109/ACPR.2017.153
   Falk T, 2019, NAT METHODS, V16, P67, DOI 10.1038/s41592-018-0261-2
   Farsight Security Services Ltd, POS CCTV CAM YOUR BU
   Guo Bingchen H., 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P292, DOI 10.1109/TBIOM.2019.2943934
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Imoto D, 2018, EUR W VIS INF PROCES
   Iwama H, 2013, Information and Media Technologies, V5, P163
   Iwashita Yumi, 2010, Proceedings of the 2010 International Conference on Emerging Security Technologies (EST 2010), P30, DOI 10.1109/EST.2010.19
   Larsen PK, 2008, J FORENSIC SCI, V53, P1149, DOI 10.1111/j.1556-4029.2008.00807.x
   Larsen PK, 2010, EUR SIGNAL PR CONF, P1660
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Makihara Y., 2012, IPSJ T COMPUT VISION, V4, P53, DOI DOI 10.2197/IPSJTCVA.4.53
   Makihara Y, 2015, ENCY ELECT ELECT ENG
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Muramatsu D, 2015, IEEE T IMAGE PROCESS, V24, P140, DOI 10.1109/TIP.2014.2371335
   Nixon MS, 2006, P IEEE, V94, P2013, DOI 10.1109/JPROC.2006.886018
   Shiraga K, 2016, INT CONF BIOMETR
   Takemura Noriko, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0039-6
   Yu S., 2020, P ASIAN C COMPUTER V, P1
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zheng S, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6115889
NR 27
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26199
EP 26221
DI 10.1007/s11042-022-12751-0
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000780464900002
OA hybrid
DA 2024-07-18
ER

PT J
AU Khan, SS
   Khan, M
   Haider, S
   Damasevicius, R
AF Khan, Sarwar Shah
   Khan, Muzammil
   Haider, Shahab
   Damasevicius, Robertas
TI Hyperspectral image classification using NRS with different distance
   measurement techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral data; Tikhonov Metrix; Distances measures; Classification;
   Euclidean and Manhattan; Nearest regularized subspace
ID NEAREST-REGULARIZED SUBSPACE
AB For the HSI classification, the recently introduced nearest regularized subspace (NRS) classifier outperform the sparse representation-based classification (SRC) and collaborative representation-based classification (CRC). The NRS method has two major distance measurements parts to classify approximation of the testing simple properly. One is the residual between the approximation and the corresponding pixel, and the other is the elements in the Tikhonov matrix. The main contribution of this paper is to find the optimum distance measures for NRS to increase the performance results and minimize the running time compared to their previous versions and other existing methods. The experiments were conducted with four distance measures such as Manhattan distance (MD), Euclidean distance(ED), Chi-square (X-2) and Cosine distance (CS). The different distance measures are implemented in residual and Tikhonov Matrix calculations. To sum up, sixteen (16) distance measurement combinations are tested on Four Datasets, such as Indian Pines, Pavia University, KSC and Center of Pavia. The experiments show higher accuracy and reduced time as compared to other methods, with NRS_X-2-MD and NRS_MD-MD as the top two combinations.
C1 [Khan, Sarwar Shah; Khan, Muzammil] Univ Swat, Dept Comp & Software Technol, Swat 19130, KP, Pakistan.
   [Khan, Sarwar Shah; Khan, Muzammil] Univ Sialkot, Dept Software Engn, Sialkot 51310, Pakistan.
   [Haider, Shahab] City Univ Sci & Informat Technol, Peshawar 25000, Pakistan.
   [Damasevicius, Robertas] Kaunas Univ Technol, LT-51386 Kaunas, Lithuania.
C3 Kaunas University of Technology
RP Khan, M (corresponding author), Univ Swat, Dept Comp & Software Technol, Swat 19130, KP, Pakistan.; Khan, M (corresponding author), Univ Sialkot, Dept Software Engn, Sialkot 51310, Pakistan.
EM muzammilkhan86@gmail.com
RI Damaševičius, Robertas/E-1387-2017; Haider, Shahab/ABG-4128-2020
OI Damaševičius, Robertas/0000-0001-9990-1084; Haider,
   Shahab/0000-0001-6802-6133
CR Agresti A., 2007, INTRO CATEGORICAL DA, DOI DOI 10.1002/0470114754
   Ahmad MJ., 2012, INT J HUMANITIES SOC, V2, P256
   Arias FX., 2017, SUPERVISED SPARSE RE, DOI [10.1049/cp.2017.0141, DOI 10.1049/CP.2017.0141]
   Benediktsson JA, 2015, ARTECH HSE REMOTE SE, P1
   Challa A., 2022, IEEE T GEOSCI REMOTE, V60, P1, DOI [10.1109/TGRS.2021.3113721, DOI 10.1109/TGRS.2021.3113721]
   Chen C, 2019, INT GEOSCI REMOTE SE, P2475, DOI [10.1109/igarss.2019.8898443, 10.1109/IGARSS.2019.8898443]
   Chowdhary C.L., 2019, RECENT PAT COMPUT SC, V12, P18, DOI [10.2174/2213275911666180821092033, DOI 10.2174/2213275911666180821092033]
   De Leeuw J, 2006, INT J REMOTE SENS, V27, P223, DOI 10.1080/01431160500275762
   Goswami M., 2018, APPL SCI MANAG, V8, P786
   Khan SS, 2019, J APPL REMOTE SENS, V14, DOI 10.1117/1.JRS.14.032604
   Li J, 2013, IEEE T GEOSCI REMOTE, V51, P844, DOI 10.1109/TGRS.2012.2205263
   Li W, 2015, IEEE GEOSCI REMOTE S, V12, P389, DOI 10.1109/LGRS.2014.2343956
   Li W, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083665
   Li W, 2014, IEEE T GEOSCI REMOTE, V52, P477, DOI 10.1109/TGRS.2013.2241773
   Li XY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020109
   Li ZX, 2020, IEEE J-STARS, V13, P3534, DOI 10.1109/JSTARS.2020.3004064
   Liu S, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050456
   Ma LY, 2020, EUR J REMOTE SENS, V53, P1, DOI 10.1080/22797254.2019.1707124
   Mahdavi S, 2018, GISCI REMOTE SENS, V55, P623, DOI 10.1080/15481603.2017.1419602
   McHugh ML, 2013, BIOCHEM MEDICA, V23, P143, DOI 10.11613/BM.2013.018
   Moughal TA, 2013, J PHYS CONF SER, V439, DOI 10.1088/1742-6596/439/1/012042
   Pele O, 2010, LECT NOTES COMPUT SC, V6312, P749, DOI 10.1007/978-3-642-15552-9_54
   Pu HY, 2014, IEEE T GEOSCI REMOTE, V52, P7008, DOI 10.1109/TGRS.2014.2306687
   Sharma D., 2015, PRACTICAL ASSESSMENT, P1, DOI [10.7275/tbfa-x148, DOI 10.7275/TBFA-X148]
   Sharma M, 2018, PROCEDIA COMPUT SCI, V143, P458, DOI 10.1016/j.procs.2018.10.418
   Su HJ, 2019, IEEE T GEOSCI REMOTE, V57, P1230, DOI 10.1109/TGRS.2018.2866190
   van der Linden S, 2007, J APPL REMOTE SENS, V1, DOI 10.1117/1.2813466
   Wei YT, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030203
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xie FD, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7090338
   Yang Wei., 2015, Mathematical Problems in Engineering, V2015
   Zhan TM, 2015, PR IEEE I C PROGR IN, P30, DOI 10.1109/PIC.2015.7489804
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhao M., 2018, HYPERSPECTRAL IMAGIN, P101
NR 34
TC 2
Z9 2
U1 9
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24869
EP 24885
DI 10.1007/s11042-022-12263-x
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771882300002
DA 2024-07-18
ER

PT J
AU Hu, Q
   Zhang, Y
   Liu, TJ
   Liu, JB
   Luo, H
AF Hu, Qing
   Zhang, Yu
   Liu, Tiejun
   Liu, Jiabing
   Luo, Han
TI Maritime video defogging based on spatial-temporal information fusion
   and an improved dark channel prior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Maritime video defogging; Spatial-temporal information fusion;
   Atmospheric light; Transmittance map
AB Marine fog causes degradation and blurring of video images acquired by the vision systems of unmanned ships, which can seriously affects the safety of ship navigation. Therefore, this paper proposes a maritime video defogging algorithm based on spatial-temporal information fusion and an improved dark channel prior to realize the clarity of the original foggy dynamic videos. First, the atmospheric light in each frame is estimated using the quadtree algorithm and the spatial-temporal information fusion that considering interframe correlations. Second, through the introduction of edge smoothing, color-guided filtering and correction factors, the initial transmittance map obtained using the dark channel prior is refined and corrected. Then, spatial-temporal information fusion considering interframe color consistency is introduced to obtain the transmittance map of each frame image. Finally, an improved dark channel prior model is utilized to restore each frame image, thereby achieving video defogging. The results of a video defogging experiment show that the interframe transitions are natural and that the restored frame images exhibit detailed textures and accurate color reproduction. In contrast to other algorithms, the proposed algorithm maintains the saturated pixel ratio at approximately zero, suggesting preferable saturation of the defogged images. Also, compared with other algorithms that are not affected by artifact noise, the proposed algorithm obtains the optimal values in terms of the average gradient and the gradient ratio of visible edges. Meanwhile, the single-frame processing times corresponding to different image resolutions are 0.2676 s, 0.6935 s and 0.7976 s. Compared with other advanced defogging algorithms, the proposed algorithm is fast and efficient.
C1 [Hu, Qing; Zhang, Yu; Liu, Jiabing; Luo, Han] Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian, Peoples R China.
   [Liu, Tiejun] Maritime Safety Adm, Northern Nav Serv Ctr, Tianjin, Peoples R China.
C3 Dalian Maritime University
RP Zhang, Y (corresponding author), Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian, Peoples R China.
EM hq0518@dlmu.edu.cn; 240961678@qq.com; hbchj@sina.com; 312828105@qq.com;
   luohandmu@163.com
RI HU, Qing/GWQ-8711-2022; Hu, Qing/K-1400-2014
OI Zhang, Yu/0000-0002-1631-0551; Hu, Qing/0000-0001-8569-044X
FU Key research and development project of Liaoning Province
   [2019020090-JH2/101]; Key Technologies of Ship Perception and Network
   Support in a complex environment [017210332]; Natural Science Foundation
   of Liaoning Province of China [2020-HYLH-42]
FX This work was supported in part by the Key research and development
   project of Liaoning Province (No. 2019020090-JH2/101) and the Key
   Technologies of Ship Perception and Network Support in a complex
   environment (No. 017210332) and Joint Fund of the Natural Science
   Foundation of Liaoning Province of China (No. 2020-HYLH-42).
CR Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bolun Cai, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9917, P315, DOI 10.1007/978-3-319-48896-7_31
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cheng J, 2018, IEEE T MED IMAGING, V37, P2536, DOI 10.1109/TMI.2018.2838550
   Ngo D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194011
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Guo Fan, 2011, Acta Electronica Sinica, V39, P2019
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hu HM, 2019, IEEE T IMAGE PROCESS, V28, P2882, DOI 10.1109/TIP.2019.2891901
   Hu XC, 2014, INT CONF DIGIT SIG, P1, DOI 10.1109/ICDSP.2014.6900715
   [蒋建国 Jiang Jianguo], 2011, [电路与系统学报, Journal of Circuits and Systems], V16, P7
   Jin JC, 2018, ACTA OCEANOL SIN, V37, P99, DOI 10.1007/s13131-018-1269-2
   Johnson J, 2008, AEROSP CONF PROC, P2322
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li RT, 2020, PROC CVPR IEEE, P3172, DOI 10.1109/CVPR42600.2020.00324
   Li Y., 2015, J COMPUT INFORM SYST, V16, P5799, DOI [10.12733/jcis14861, DOI 10.12733/JCIS14861]
   Liu W, 2019, COMPUTER VISION PATT
   Liu W, 2020, IEEE T IMAGE PROCESS, V29, P7819, DOI 10.1109/TIP.2020.3007844
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Nguyen TV, 2021, IEEE ACCESS, V9, P34590, DOI 10.1109/ACCESS.2021.3060439
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Qing CM, 2016, MULTIDIM SYST SIGN P, V27, P909, DOI 10.1007/s11045-016-0407-2
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Salazar-Colores S, 2020, IEEE ACCESS, V8, P149176, DOI 10.1109/ACCESS.2020.3015724
   Sharma N, 2021, ARCH COMPUT METHOD E, V28, P4449, DOI 10.1007/s11831-021-09541-6
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang C, 2021, IEEE SIGNAL PROC LET, V28, P419, DOI 10.1109/LSP.2021.3056961
   Yu Jing, 2011, Acta Automatica Sinica, V37, P923, DOI 10.3724/SP.J.1004.2011.00923
   Zhao D, 2019, SIGNAL PROCESS-IMAGE, V74, P253, DOI 10.1016/j.image.2019.02.004
   Zhongli Ma, 2013, Advances in Swarm Intelligence. 4th International Conference, ICSI 2013. Proceedings, P436, DOI 10.1007/978-3-642-38715-9_52
   Zhou FQ, 2019, IEEE ACCESS, V7, P50780, DOI 10.1109/ACCESS.2019.2909591
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu XS, 2021, IEEE T IMAGE PROCESS, V30, P7620, DOI 10.1109/TIP.2021.3108022
NR 37
TC 3
Z9 3
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24777
EP 24798
DI 10.1007/s11042-022-11921-4
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771380200006
DA 2024-07-18
ER

PT J
AU Nahar, P
   Chaudhari, NS
   Tanwani, SK
AF Nahar, Prateek
   Chaudhari, N. S.
   Tanwani, S. K.
TI Fingerprint classification system using CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Minutiae; Fingerprint recognition; Fingerprint classification; Batch
   normalization; CNN; VGGNet; LeNet5; FVC; Multilayer perceptron (MLP);
   Feed forward neural networks (FNN); Channels; filters and feature maps
   (FM)
AB Most solitary finger impression check and acknowledgment frameworks / methods are based on the minutiae feature points. Feature Extraction is a fundamental advance in solitary finger impression based acknowledgment frameworks. In this paper, a CNN based finger impression affirmation strategy is proposed without preprocessing an image. The framework fuses two phases include extraction and coordinating. Feature elicitation is realized by different filters with different parameter set; matching juncture relates extracted features and creates a corresponding score. Recognition attainment of the preferred system has been tested by utilizingFVC2004 database. The inference is very favoring for implementing a CNN based self-regulating fingerprint recognition system. Our method achieves an overall rate of 99.1% of accurately classified samples.
C1 [Nahar, Prateek; Chaudhari, N. S.; Tanwani, S. K.] DAVV, SCSIT, Takshashila Campus, Indore 452017, Madhya Pradesh, India.
C3 Devi Ahilya University
RP Nahar, P (corresponding author), DAVV, SCSIT, Takshashila Campus, Indore 452017, Madhya Pradesh, India.
EM Prateek07file@yahoo.co.in; nsc0183@yahoo.com; sanjay_tanwani@hotmail.com
OI Nahar, Prateek/0000-0002-7839-7728
CR Darlow LN, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P22, DOI 10.1109/BTAS.2017.8272678
   Devore J., 1997, Statistics: The exploration and analysis of data, V3rd
   Gunasekaran K., 2014, INT C INFORM COMMUNI, P1, DOI [10.1109/ICICES.2014.7033922, DOI 10.1109/ICICES.2014.7033922]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jeon WS, 2017, INT J FUZZY LOG INTE, V17, P170, DOI 10.5391/IJFIS.2017.17.3.170
   Kulkarni S., 2016, INT C ELECT ELECT OP
   Kussul EM, 2006, IEEE T NEURAL NETWOR, V17, P1566, DOI 10.1109/TNN.2006.880676
   Li-qiang Y., 2012, 2012 INT C COMPUTER, DOI 10.1109/CSSS.2012.434
   Marak Pavol, 2016, Tatra Mountains Mathematical Publications, V67, P117, DOI 10.1515/tmmp-2016-0035
   Nachar R, 2017, 2017 8 INT C INFORM, V2017, P1, DOI [10.1109/IISA.2017.8316356, DOI 10.1109/IISA.2017.8316356]
   Petraltal D, 2017, COMPUTER SCI COMPUTE
   RATCLIFF JW, 1988, DR DOBBS J, V13, P46
   Waibel A., 2005, IEEE T ACOUST SPEECH, V37, p551 556
   Wang R, 2014, ARXIV COMPUTER SCI C
NR 14
TC 7
Z9 7
U1 4
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24515
EP 24527
DI 10.1007/s11042-022-12294-4
EA MAR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770960100003
DA 2024-07-18
ER

PT J
AU Banerjee, N
   Borah, S
   Sethi, N
AF Banerjee, Nilanjan
   Borah, Samarjeet
   Sethi, Nilambar
TI Intelligent stuttering speech recognition: A succinct review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Stuttering; Speech recognition; Feature extraction; Machine learning;
   Deep learning; Classification
ID ARTIFICIAL NEURAL-NETWORKS; CLASSIFICATION; MODELS; REPETITION; BLIND
AB Stuttering speech recognition is a well-studied concept in speech signal processing. Classification of speech disorder is the main focus of this study. Classification of stuttered speech is becoming more important with the enhancement of machine learning and deep learning. In this study, some of the recent and most influencing stuttering speech recognition methods are reviewed with a discussion on different categories of stuttering. The stuttering speech recognition process is divided mainly into four segments-input speech pre-emphasis, segmentation, feature extraction, and stutter classification. All these segments are briefly elaborated and related researches are discussed. It is observed that different traditional machine learning and deep learning classification approaches are employed to recognize stuttered speech in last few decades. A comprehensive analysis is presented on different feature extraction and classification method with their efficiency.
C1 [Banerjee, Nilanjan; Sethi, Nilambar] GIET Univ, Dept Comp Sci & Engn, Gunupur, Odisha, India.
   [Borah, Samarjeet] Sikkim Manipal Univ, Sikkim Manipal Inst Technol, Dept Comp Applicat, Gangtok, Sikkim, India.
C3 GIET University; Sikkim Manipal Institute of Technology; Sikkim Manipal
   University
RP Borah, S (corresponding author), Sikkim Manipal Univ, Sikkim Manipal Inst Technol, Dept Comp Applicat, Gangtok, Sikkim, India.
EM nilanjan.banerjee@giet.edu; samarjeet.b@smit.smu.edu.in;
   nilambar@giet.edu
RI ; Borah, Samarjeet/C-9801-2013
OI Sethi, Nilambar/0000-0003-3649-3233; Borah,
   Samarjeet/0000-0001-9304-3525
CR Alam MJ, 2013, SPEECH COMMUN, V55, P237, DOI 10.1016/j.specom.2012.08.007
   Alanazi F., 2019, INT J ELECT COMPUT E, V9, P4258, DOI DOI 10.11591/IJECE.V9I5.PP4258-4265
   Berndt DJ, 1994, P 3 INT C KNOWL DISC, P359, DOI DOI 10.5555/3000850.3000887
   Bhattacharya S, 2020, 1 DOCT S NAT COMP RE
   Boulmaiz A, 2017, INT J AMBIENT COMPUT, V8, P98, DOI 10.4018/IJACI.2017010105
   Buza O, 2006, 2006 IEEE-TTTC INTERNATIONAL CONFERENCE ON AUTOMATION, QUALITY AND TESTING, ROBOTICS, VOL 2, PROCEEDINGS, P360
   Chee LS, 2009, 2009 INTERNATIONAL CONFERENCE FOR TECHNICAL POSTGRADUATES (TECHPOS 2009), P15
   Das N, 2021, INT J SPEECH TECHNOL, V24, P883, DOI 10.1007/s10772-020-09674-2
   Dave N., 2013, INT J ADV RES ENG TE, V1, P1
   Dey N, 2019, INTELLIGENT SPEECH S
   Elhadad A, 2021, ALEX ENG J, V60, P2471, DOI 10.1016/j.aej.2020.12.050
   Elhadad A, 2017, NEURAL COMPUT APPL, V28, pS91, DOI 10.1007/s00521-016-2323-7
   Fook CY, 2013, TURK J ELECTR ENG CO, V21, P1983, DOI 10.3906/elk-1112-84
   Geetha YV, 2000, J FLUENCY DISORD, V25, P99, DOI 10.1016/S0094-730X(99)00029-7
   Girish M, 2017, NAT C COMM IM PROC T
   Gupta H, 2016, 2016 6th International Conference - Cloud System and Big Data Engineering (Confluence), P498, DOI 10.1109/CONFLUENCE.2016.7508171
   Gupta S., 2013, SIGNAL IMAGE PROCESS, V4, P101, DOI [DOI 10.5121/SIPIJ.2013.4408, 10.5121/sipij.2013.4408]
   Hariharan M., 2012, 2012 IEEE 8th International Colloquium on Signal Processing & its Applications, P240, DOI 10.1109/CSPA.2012.6194726
   Hariharan M, 2012, J MED SYST, V36, P1821, DOI 10.1007/s10916-010-9641-6
   Healey E. Charles, 2010, Seminars in Speech and Language, V31, P227, DOI 10.1055/s-0030-1265756
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Hidayat R, 2018, PROCEEDINGS OF 2018 THE 10TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND ELECTRICAL ENGINEERING (ICITEE), P280, DOI 10.1109/ICITEED.2018.8534807
   Hossan MA, 2010, 2010 4TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ICSPCS)
   Hosseini R, 2018, IEEE T NEUR SYS REH, V26, P1254, DOI 10.1109/TNSRE.2018.2829083
   Howell P, 1997, J SPEECH LANG HEAR R, V40, P1085, DOI 10.1044/jslhr.4005.1085
   Howell P., 1995, Proceedings of the First World Congress on Fluency Disorders, P372
   Howell Peter, 2004, Stammering Res, V1, P309
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Khalil OH, 2020, IMAGING SCI J, V68, P90, DOI 10.1080/13682199.2020.1740431
   Khan, 2015, INT J STUD ENGLISH L, V3, P89
   KN VN., 2016, INT J ADV RES ELECT, V5, P2278
   Kourkounakis T, 2020, ARXIV PREPRINT ARXIV
   Kumar K. M. Ravi, 2011, International Journal of Advanced Networking and Applications, V2, P854
   Kumar P., 2010, ARXIV10035623
   Li Q, 2011, IEEE T AUDIO SPEECH, V19, P1791, DOI 10.1109/TASL.2010.2101594
   Likitha MS, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2257, DOI 10.1109/WiSPNET.2017.8300161
   Lim S., 2009, ICIS 2009 P, V91, P1
   Maas AL, 2017, COMPUT SPEECH LANG, V41, P195, DOI 10.1016/j.csl.2016.06.007
   Mahesha P., 2013, INT C HETEROGENEOUS, P298
   Mahesha P., 2015, P INT C INT COMP COM, V308, P623
   Manjula G, 2019, PROCEEDINGS OF 2019 THE 3RD INTERNATIONAL CONFERENCE ON CRYPTOGRAPHY, SECURITY AND PRIVACY (ICCSP 2019) WITH WORKSHOP 2019 THE 4TH INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP 2019), P93, DOI 10.1145/3309074.3309113
   Manjula G, 2016, 11 IRF INT C
   Manjula G., 2017, International Journal of Applied Engineering Research, V12, P11976
   Meenakshi M, 2020, SSRN
   Mirri S, 2020, COMPUTATION, V8, DOI 10.3390/computation8030074
   Mohan BJ, 2014, INT CONF ADV ELECTR
   Noth Elmar, 2000, INTERSPEECH, P65
   Oue S., 2015, PROC SLPAT 2015 6 WO, P60
   Pálfy J, 2011, SPA 2011: SIGNAL PROCESSING ALGORITHMS, ARCHITECTURES, ARRANGEMENTS, AND APPLICATIONS CONFERENCE PROCEEDINGS, P79
   PINELLI P, 1992, CURR OPIN NEUROL NEU, V5, P744
   Prakash CO, 2018, DESIGN IMPLEMENTATIO
   Qi FY, 2004, 2004 International Symposium on Chinese Spoken Language Processing, Proceedings, P77
   Raghavendra M., 2016, COMPUT SPEECH LANG I, V4, P2321
   Ramteke PB, 2016, SMART INNOV SYST TEC, V43, P611, DOI 10.1007/978-81-322-2538-6_63
   Ravikumar K., 2008, Proceedings of world academy science, engineering and technology, P270
   Ravikumar K M., 2009, The international congress for global science and technology, page, P19
   Revada LKV., 2011, IJCSI INT J COMPUT S, V8, P484
   Savin PS, 2016, SMART INNOV SYST TEC, V43, P65, DOI 10.1007/978-81-322-2538-6_8
   Sen S, 2019, AUDIO PROCESSING SPE
   Sharma Usha, 2015, 2015 International Conference on Futuristic Trends on Computational Analysis and Knowledge Management (ABLAZE). Proceedings, P654, DOI 10.1109/ABLAZE.2015.7154944
   Shirvan R. A., 2011, 2011 18th Iranian Conference of Biomedical Engineering (ICBME), P278, DOI 10.1109/ICBME.2011.6168572
   Subasi A, 2010, EXPERT SYST APPL, V37, P8659, DOI 10.1016/j.eswa.2010.06.065
   Suguna N., 2010, INT J COMPUTER SCI I, V7, P18
   Suryaa A. A., 2016, INT J CONTROL THEORY, V9, P16
   Swietlicka I, 2009, ADV INTEL SOFT COMPU, V57, P347
   Szczurowska I., 2014, Archives of Acoustics, V31, P205
   Tan TS, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P330
   UCLASS, DATABASE
   Wahyuni ES, 2017, 2017 2ND INTERNATIONAL CONFERENCES ON INFORMATION TECHNOLOGY, INFORMATION SYSTEMS AND ELECTRICAL ENGINEERING (ICITISEE), P22, DOI 10.1109/ICITISEE.2017.8285499
   Wisniewski M, 2007, J MED INFORM TECHNOL, V11
   Wisniewski M, 2007, ADV INTEL SOFT COMPU, V45, P445
   Xie L, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P4359
   Yairi E, 2007, J FLUENCY DISORD, V32, P165, DOI 10.1016/j.jfludis.2007.04.001
   YUHAS BP, 1990, P IEEE, V78, P1658, DOI 10.1109/5.58349
   Zhang JM, 2022, IEEE T SOFTWARE ENG, V48, P1, DOI 10.1109/TSE.2019.2962027
NR 75
TC 1
Z9 1
U1 8
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24145
EP 24166
DI 10.1007/s11042-022-12817-z
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000010
DA 2024-07-18
ER

PT J
AU Liu, Y
   Jia, PF
   Zhou, H
   Wang, AZ
AF Liu, Yun
   Jia, Pengfei
   Zhou, Hao
   Wang, Anzhi
TI Joint dehazing and denoising for single nighttime image via multi-scale
   decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nighttime image dehazing; Multi-scale decomposition; Total variation;
   Structure dehazing; Texture denoising and enhancement
ID COLOR TRANSFER; ALGORITHM; SUPERRESOLUTION; VISIBILITY; CONSTRAINT
AB Outdoor images taken in the foggy or haze weather conditions are usually contaminated due to the presence of turbid medium in the atmosphere. Moreover, images captured under nighttime haze scenarios will be degraded even further owing to some unexpected factors. However, most existing dehazing methods mainly focus on daytime haze scenes, which cannot effectively remove the haze and suppress the noise for nighttime hazy images. To overcome these intractable problems, a joint dehazing and denoising framework for nighttime haze scenes is proposed based on multi-scale decomposition. First, the glow is removed by using its characteristic of the relative smoothness and the gamma correction operation is employed on the glow-free image for improving the overall brightness. Then, we adopt the multi-scale strategy to decompose the nighttime hazy image into a structure layer and multiple texture layers based on the total variation. Subsequently, the structure layer is dehazed based on the dark channel prior (DCP) and the texture layers are denoised based on color block-matching 3D filtering (CBM3D) prior to enhancement. Finally, the dehazed structure layer and the enhanced texture layers are fused into a dehazing result. Experiments on real-world and synthetic nighttime hazy images reveal that the proposed nighttime dehazing framework outperforms other state-of-the-art daytime and nighttime dehazing techniques.
C1 [Liu, Yun; Jia, Pengfei] Southwest Univ, Coll Artificial Intelligence, Chongqing 400715, Peoples R China.
   [Zhou, Hao] Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.
   [Wang, Anzhi] Guizhou Normal Univ, Coll Big Data & Comp Sci, Guiyang 550001, Peoples R China.
C3 Southwest University - China; Southwest University - China; Guizhou
   Normal University
RP Liu, Y (corresponding author), Southwest Univ, Coll Artificial Intelligence, Chongqing 400715, Peoples R China.
EM yunliu@swu.edu.cn
RI Jia, Pengfei/AFD-8649-2022
FU Chongqing Natural Science Foundation [cstc2020jcyj-msxmX0324];
   Fundamental Research Funds for the Central Universities [SWU119044];
   Construction of Chengdu-Chongqing Economic Circle Science and Technology
   Innovation Project [KJCX2020007]; Fundamental Science and Advanced
   Technology Research Foundation of Chongqing [cstc2018jcyjA0867];
   Fundamental Science on Nuclear Wastes and Environmental safety
   Laboratory [19kfhk03]; Open Research Fund Program of Data Recovery Key
   Laboratory of Sichuan Province [DRN19015]
FX This work was supported by Chongqing Natural Science Foundation (Grant
   no. cstc2020jcyj-msxmX0324), the Fundamental Research Funds for the
   Central Universities under Project SWU119044, the Construction of
   Chengdu-Chongqing Economic Circle Science and Technology Innovation
   Project (Grant no. KJCX2020007), the Fundamental Science and Advanced
   Technology Research Foundation of Chongqing (cstc2018jcyjA0867), the
   Fundamental Science on Nuclear Wastes and Environmental safety
   Laboratory (Grant No. 19kfhk03) and Open Research Fund Program of Data
   Recovery Key Laboratory of Sichuan Province (Grant No. DRN19015).
CR Ancuti CO, 2019, IEEE SIGNAL PROC LET, V26, P1413, DOI 10.1109/LSP.2019.2932189
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Ancuti C, 2020, IEEE T IMAGE PROCESS, V29, P6264, DOI 10.1109/TIP.2020.2988203
   Ancuti C, 2016, IEEE IMAGE PROC, P2256, DOI 10.1109/ICIP.2016.7532760
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Dabov K, 2007, IEEE IMAGE PROC, P313, DOI 10.1109/icip.2007.4378954
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Jiang B, 2018, MULTIMED TOOLS APPL, V77, P3125, DOI 10.1007/s11042-017-4954-9
   Ju MY, 2020, IEEE T IMAGE PROCESS, V29, P3104, DOI 10.1109/TIP.2019.2957852
   Ju MY, 2017, NEUROCOMPUTING, V260, P180, DOI 10.1016/j.neucom.2017.04.034
   Koschmieder H., 1925, Theorie der horizontalen Sichtweite: Kontrast und Sichtweite
   Li Y, 2015, IEEE I CONF COMP VIS, P226, DOI 10.1109/ICCV.2015.34
   Li Y, 2014, LECT NOTES COMPUT SC, V8690, P174, DOI 10.1007/978-3-319-10605-2_12
   Liu Y, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107986
   Liu Y, 2019, IEEE ACCESS, V7, P15722, DOI 10.1109/ACCESS.2019.2894525
   Liu Y, 2017, IEEE ACCESS, V5, P8890, DOI 10.1109/ACCESS.2017.2710305
   Lou WH, 2020, IEEE ACCESS, V8, P113318, DOI 10.1109/ACCESS.2020.3003444
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Mi ZT, 2016, IET IMAGE PROCESS, V10, P206, DOI 10.1049/iet-ipr.2015.0112
   Pan JS, 2021, IEEE T PATTERN ANAL, V43, P2449, DOI 10.1109/TPAMI.2020.2969348
   Pei SC, 2012, IEEE IMAGE PROC, P957, DOI 10.1109/ICIP.2012.6467020
   Rajput Shyam Singh, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P252, DOI 10.1109/TBIOM.2019.2939808
   Rajput SS, 2020, MULTIMED TOOLS APPL, V79, P23909, DOI 10.1007/s11042-020-09072-5
   Rajput SS, 2019, MULTIMED TOOLS APPL, V78, P25407, DOI 10.1007/s11042-019-07791-y
   Rajput SS, 2019, APPL INTELL, V49, P1324, DOI 10.1007/s10489-018-1340-x
   Rajput SS, 2018, INFORM SCIENCES, V463, P227, DOI 10.1016/j.ins.2018.06.050
   Rajput SS, 2018, SIGNAL PROCESS, V147, P233, DOI 10.1016/j.sigpro.2018.01.030
   Rajput SS, 2019, FACE IMAGE SUPER RES, V2
   Rajput SS, 2018, P 2018 C INF COMM TE, P21
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu Z., 2009, 2009 INT C COMP INT, P1
   Yang D, 2018, LECT NOTES COMPUT SC, V11211, P729, DOI 10.1007/978-3-030-01234-2_43
   Yang MM, 2018, IEEE T MULTIMEDIA, V20, P3008, DOI 10.1109/TMM.2018.2820327
   Yu T, 2019, IEEE ACCESS, V7, P114619, DOI 10.1109/ACCESS.2019.2936049
   Zhang J, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2355, DOI 10.1145/3394171.3413763
   Zhang J, 2017, PROC CVPR IEEE, P7016, DOI 10.1109/CVPR.2017.742
   Zhang J, 2014, IEEE IMAGE PROC, P4557, DOI 10.1109/ICIP.2014.7025924
   Zhou JJ, 2013, 2013 2ND INTERNATIONAL SYMPOSIUM ON INSTRUMENTATION AND MEASUREMENT, SENSOR NETWORK AND AUTOMATION (IMSNA), P243, DOI 10.1109/IMSNA.2013.6743260
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu ZQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3024335
NR 49
TC 3
Z9 3
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23941
EP 23962
DI 10.1007/s11042-022-12681-x
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000003
DA 2024-07-18
ER

PT J
AU Zhao, C
   Shuai, RJ
   Ma, L
   Liu, WJ
   Wu, ML
AF Zhao, Chen
   Shuai, Renjun
   Ma, Li
   Liu, Wenjia
   Wu, Menglin
TI Improving cervical cancer classification with imbalanced datasets
   combining taming transformers with T2T-ViT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cervical cancer; Cervical cytology; Cervical cell classification;
   Convolutional neural networks; Generative adversarial networks; Vision
   transformer
ID IMAGE; SMEARS
AB Cervical cell classification has important clinical significance in cervical cancer screening at early stages. However, there are fewer public cervical cancer smear cell datasets, the weights of each classes' samples are unbalanced, the image quality is uneven, and the classification research results based on CNN tend to overfit. To solve the above problems, we propose a cervical cell image generation model based on taming transformers (CCG-taming transformers) to provide high-quality cervical cancer datasets with sufficient samples and balanced weights, we improve the encoder structure by introducing SE-block and MultiRes-block to improve the ability to extract information from cervical cancer cells images; we introduce Layer Normlization to standardize the data, which is convenient for the subsequent non-linear processing of the data by the ReLU activation function in feed forward; we also introduce SMOTE-Tomek Links to balance the source data set and the number of samples and weights of the images we use Tokens-to-Token Vision Transformers (T2T-ViT) combing transfer learning to classify the cervical cancer smear cell image dataset to improve the classification performance. Classification experiments using the model proposed in this paper are performed on three public cervical cancer datasets, the classification accuracy in the liquid-based cytology Pap smear dataset (4-class), SIPAKMeD (5-class), and Herlev (7-class) are 98.79%, 99.58%, and 99.88%, respectively. The quality of the images we generated on these three data sets is very close to the source data set, the final averaged inception score (IS), Frechet inception distance (FID), Recall and Precision are 3.75, 0.71, 0.32 and 0.65 respectively. Our method improves the accuracy of cervical cancer smear cell classification, provides more cervical cell sample images for cervical cancer-related research, and assists gynecologists to judge and diagnose different types of cervical cancer cells and analyze cervical cancer cells at different stages, which are difficult to distinguish. This paper applies the transformer to the generation and recognition of cervical cancer cell images for the first time.
C1 [Zhao, Chen; Shuai, Renjun; Wu, Menglin] Nanjing Tech Univ, Coll Comp Sci & Technol, Nanjing 211816, Peoples R China.
   [Ma, Li] Nanjing Hlth Informat Ctr, Nanjing 210003, Peoples R China.
   [Liu, Wenjia] Nanjing Med Univ, Changzhou 2 Peoples Hosp, Changzhou 213003, Peoples R China.
C3 Nanjing Tech University; Nanjing Medical University
RP Shuai, RJ (corresponding author), Nanjing Tech Univ, Coll Comp Sci & Technol, Nanjing 211816, Peoples R China.
EM srjwhy@njtech.edu.cn
FU National Natural Science Foundation of China [61701222]
FX This work was supported in part by The National Natural Science
   Foundation of China NO.61701222.
CR Bissoto A, 2019, ARXIV PREPRINT ARXIV
   Bora K, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010068
   Bora K, 2017, COMPUT METH PROG BIO, V138, P31, DOI 10.1016/j.cmpb.2016.10.001
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chankong T, 2014, COMPUT METH PROG BIO, V113, P539, DOI 10.1016/j.cmpb.2013.12.012
   Chen H., 2020, Causalml: Python package for causal machine learning, P12299
   Chouhan N, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104318
   Conceiçao T, 2019, INT J MOL SCI, V20, DOI 10.3390/ijms20205114
   Dai J., 2021, ICLR
   Denton E, 2015, ADV NEUR IN, V28
   Dong N, 2021, J AMB INTEL HUM COMP, V12, P1837, DOI 10.1007/s12652-020-02256-9
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Dounias G, 2006, ONCOL REP, V15, P1001
   Esser Patrick, 2020, Taming transformers for high-resolution image synthesis
   Gautam S., 2018, arXiv preprint arXiv:1806.09025
   Ghoneim A, 2020, FUTURE GENER COMP SY, V102, P643, DOI 10.1016/j.future.2019.09.015
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guissous AE, 2019, ARXIV PREPRINT ARXIV
   Gv KK., 2019, AUTOMATIC CLASSIFICA, P1074
   Han C, 2019, INT CONF 3D VISION, P729, DOI 10.1109/3DV.2019.00085
   Han YX, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105754
   Haryanto Toto, 2020, 2020 International Conference on Computer Engineering, Network, and Intelligent Multimedia (CENIM), P34, DOI 10.1109/CENIM51130.2020.9297895
   He X, 2019, IEEE GEOSCI REMOTE S, V16, P1884, DOI 10.1109/LGRS.2019.2911322
   Hensel M, 2017, ADV NEUR IN, V30
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hussain E, 2020, DATA BRIEF, V30, DOI 10.1016/j.dib.2020.105589
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jaiswal A, 2021, J BIOMOL STRUCT DYN, V39, P5682, DOI 10.1080/07391102.2020.1788642
   Jantzen J., 2005, Nature inspired Smart Information Systems (NiSIS 2005), P1
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Khamparia A, 2020, J SUPERCOMPUT, V76, P8590, DOI 10.1007/s11227-020-03159-4
   Khan S., 2021, ARXIV210101169
   Kim Kitai., 2012, Practical guide to surgical pathology with cytologic correlation: a text and color atlas
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Loshchilov I., 2017, INT C LEARN REPR
   Loshchilov Ilya, 2017, ARXIV171105101
   Mamunur Rahaman M, 2021, ARXIV210212191
   Marinakis Y, 2009, COMPUT BIOL MED, V39, P69, DOI 10.1016/j.compbiomed.2008.11.006
   McGuire S, 2014, ADV NUTR, V5, P456, DOI [10.3945/an.114.006171, 10.3945/an.116.012211]
   Papanicolaou GN, 1941, AM J OBSTET GYNECOL, V42, P193
   Park Sangjoon, 2021, ARXIV210307055
   Peng GY, 2021, COMPUT BIOL MED, V130, DOI 10.1016/j.compbiomed.2021.104209
   Plissiti ME, 2018, IEEE IMAGE PROC, P3144, DOI 10.1109/ICIP.2018.8451588
   Pollastri F, 2020, MULTIMED TOOLS APPL, V79, P15575, DOI 10.1007/s11042-019-7717-y
   Radford A., 2015, ARXIV
   Ramesh S, 2021, MULTIMED TOOLS APPL, V80, P11789, DOI 10.1007/s11042-020-10351-4
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salimans T, 2016, ADV NEUR IN, V29
   Shah V., 2020, INT C DATA SCI ENG I, V2020, P1
   Shi J, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105807
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI [DOI 10.3322/caac.21660, 10.3322/caac.21660]
   Talo M., 2019, ACAD PERSPECTIVE PRO, V2, P1043, DOI DOI 10.33793/ACPERPRO.02.03.116
   Thuy M.B.H., 2019, International Conference on Computer Science, Applied Mathematics and Applications, P255, DOI 10.1007/978-3-030-38364-0_23
   Torrey Lisa, 2010, Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques, P242
   Valanarasu Jeya Maria Jose, 2021, Medical Image Computing and Computer Assisted Intervention - MICCAI 2021: 24th International Conference, Proceedings. Lecture Notes in Computer Science, Image Processing, Computer Vision, Pattern Recognition, and Graphics (12901), P36, DOI 10.1007/978-3-030-87193-2_4
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang L, 2020, CHEM COMMUN, V56, P9368, DOI 10.1039/d0cc02657c
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Wang Q, 2020, I C NETWORK PROTOCOL, DOI 10.1109/icnp49622.2020.9259369
   Wang S.-Y., 2020, CVPR, P8695
   Wang WX, 2021, LECT NOTES COMPUT SC, V12901, P109, DOI 10.1007/978-3-030-87193-2_11
   Wieslander H, 2017, IEEE INT CONF COMP V, P82, DOI 10.1109/ICCVW.2017.18
   William Wasswa, 2019, Informatics in Medicine Unlocked, V14, P23, DOI 10.1016/j.imu.2019.02.001
   William W, 2018, COMPUT METH PROG BIO, V164, P15, DOI 10.1016/j.cmpb.2018.05.034
   Win KP, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051800
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu M, 2018, BIOSCIENCE REP, V38, DOI 10.1042/BSR20181769
   Xie Y., 2021, ARXIV PREPRINT ARXIV
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhao C, 2021, IEEE ACCESS, V9, P8659, DOI 10.1109/ACCESS.2021.3049600
   Zhao LL, 2016, COMPUT BIOL MED, V71, P46, DOI 10.1016/j.compbiomed.2016.01.025
NR 74
TC 16
Z9 16
U1 6
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24265
EP 24300
DI 10.1007/s11042-022-12670-0
EA MAR 2022
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000016
PM 35342326
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Ramakrishnan, B
   Kamdeu, PYN
   Natiq, H
   Pone, JRM
   Karthikeyan, A
   Kingni, ST
   Tiedeu, A
AF Ramakrishnan, Balamurali
   Kamdeu, Pascal Yannick Nkandeu
   Natiq, Hayder
   Pone, Justin Roger Mboupda
   Karthikeyan, Anitha
   Kingni, Sifeu Takougang
   Tiedeu, Alain
TI Image encryption with a Josephson junction model embedded in FPGA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Josephson junction; Hidden chaos and antimonotonicity; Bistable periodic
   attractors; Image encryption; Bit-level permutation; FPGA implementation
ID SCHEME; CHAOS; DYNAMICS; ANTIMONOTONICITY; IMPLEMENTATION; EFFICIENT
AB The dynamical analysis, field programmable gate array (FPGA) implementation and image encryption of a linear piecewiseresistive-capacitive-inductive shunted Josephson junction (LPRCISJJ) model are reported in this paper. The numerical simulations of LPRCISJJ model reveal the existence of periodic attractors, bistable periodic attractors, antimonotonicity phenomenon and hidden chaotic attractors with different shapes by varying its parameters. Numerical simulations and FPGA results produce alike timing evolutions and phase planes. Chaotic LPRCISJJ model is used as a pseudo-random number generator (PRNG) in the design of cryptography algorithm based on bit-level permutation. The designed algorithm performs bit masking and relocation depending on the amount of information the bit contains in the pixel. The standard image security analysis on color Lena image of size 512 x 512 are performed and compared with good standing papers in the literature. Prominent outcomes in term of mean entropy of 7.9994, mean NPCR of 99.62%, key sensitivity percentage of 99.68%, average correlation of 0.002 are obtained just to name a few. These security tests carried out certify its resistance to common attacks and its high sensitivity to one-bit changes in the key or image to be encrypted.
C1 [Ramakrishnan, Balamurali; Karthikeyan, Anitha] Chennai Inst Technol, Ctr Nonlinear Syst, Chennai 600069, Tamil Nadu, India.
   [Kamdeu, Pascal Yannick Nkandeu; Tiedeu, Alain] Univ Yaounde I, HTTTC Higher Tech Teachers Training Coll, Dept Med & Biomed Engn, Image & Syst Lab, POB 886, Ebolowa, Cameroon.
   [Natiq, Hayder] Imam Jaafar Al Sadiq Univ, Informat Technol Coll, Baghdad 10001, Iraq.
   [Pone, Justin Roger Mboupda] Univ Dschang, Elect Engn Dept IUT FV, Res Unit Automat & Appl Comp RU AIA, POB 134, Bandjoun, Cameroon.
   [Kingni, Sifeu Takougang] Univ Maroua, Natl Adv Sch Mines & Petr Ind, Dept Mech Petr & Gas Engn, POB 46, Maroua, Cameroon.
   [Tiedeu, Alain] HTTTC Ebolowa, Ctr Res Expt & Prod CREP, POB 886, Ebolowa, Cameroon.
C3 Chennai Institute of Technology; University of Yaounde I; Imam Jaa'far
   al-Sadiq University; Universite de Dschang
RP Pone, JRM (corresponding author), Univ Dschang, Elect Engn Dept IUT FV, Res Unit Automat & Appl Comp RU AIA, POB 134, Bandjoun, Cameroon.
EM mboupdapone00@gmail.com
RI Natiq, Hayder/AAO-7283-2020; Tiedeu, Alain/IWM-7083-2023
OI Natiq, Hayder/0000-0003-1303-9089; 
FU Center for Nonlinear Systems, Chennai Institute of Technology, India
   [CIT/CNS/2021/RD/064]
FX This work is partially funded by the Center for Nonlinear Systems,
   Chennai Institute of Technology, India via funding number
   CIT/CNS/2021/RD/064
CR Abanda Y, 2016, IET IMAGE PROCESS, V10, P742, DOI 10.1049/iet-ipr.2015.0244
   [Anonymous], 2010, NIST handbook of mathematical functions
   Bahi JM, 2013, APPL MATH INFORM SCI, V7, P2175, DOI 10.12785/amis/070607
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   BIER M, 1984, PHYS LETT A, V104, P239, DOI 10.1016/0375-9601(84)90059-8
   Cawthorne AB, 1998, J APPL PHYS, V84, P1126, DOI 10.1063/1.368113
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chakraborty S, 2016, INT J SECUR APPL, V10, P205, DOI 10.14257/ijsia.2016.10.2.19
   Chen X., 2017, Biomed Res, V28, P9001
   Chen X, 2017, SAUDI J BIOL SCI, V24, P1821, DOI 10.1016/j.sjbs.2017.11.023
   Danger JL, 2009, MICROELECTRON J, V40, P1650, DOI 10.1016/j.mejo.2009.02.004
   DAWSON SP, 1993, PHYS REV E, V48, P1676, DOI 10.1103/PhysRevE.48.1676
   Ding Q, 2007, INT J INNOV COMPUT I, V3, P449
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Ismail SM, 2017, AEU-INT J ELECTRON C, V80, P114, DOI 10.1016/j.aeue.2017.05.047
   Kanso A, 2015, COMMUN NONLINEAR SCI, V24, P98, DOI 10.1016/j.cnsns.2014.12.005
   Kengne LK, 2021, INT J CIRC THEOR APP, V49, P1470, DOI 10.1002/cta.2968
   Koyuncu I, 2014, NONLINEAR DYNAM, V77, P49, DOI 10.1007/s11071-014-1272-x
   Kyprianidis IM, 2000, INT J BIFURCAT CHAOS, V10, P1903, DOI 10.1142/S0218127400001171
   Li Z, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12091497
   Liu Y, 2019, IEEE ACCESS, V7, P74070, DOI 10.1109/ACCESS.2019.2916600
   Machida M, 2004, PHYS REV B, V70, DOI 10.1103/PhysRevB.70.024523
   Machida M, 2000, PHYSICA C, V330, P85, DOI 10.1016/S0921-4534(99)00613-9
   Michael K., 2000, CHAOTIC ELECT TELECO
   Nkandeu YPK, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00318-y
   Nkandeu YPK, 2019, MULTIMED TOOLS APPL, V78, P10013, DOI 10.1007/s11042-018-6612-2
   Pozzo EN, 2007, PHYS REV LETT, V98, DOI 10.1103/PhysRevLett.98.057006
   Rajagopal K, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501438
   Rajagopal K, 2017, COMPLEXITY, DOI 10.1155/2017/1892618
   Rajagopal K, 2017, COMPLEXITY, DOI 10.1155/2017/8979408
   Rajagopal K, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/7307452
   Rajagopal K, 2017, NONLINEAR DYNAM, V87, P2281, DOI 10.1007/s11071-016-3189-z
   Sadoudi Said., 2009, International Journal of Nonlinear Science, V7, P467
   Shukrinov YM, 2006, PHYSICA C, V449, P62, DOI 10.1016/j.physc.2006.06.054
   Sugiura T, 2011, IEEE T APPL SUPERCON, V21, P843, DOI 10.1109/TASC.2010.2092401
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Tlelo-Cuautle E, 2015, NONLINEAR DYNAM, V82, P1879, DOI 10.1007/s11071-015-2284-x
   Uchida A, 2003, APPL PHYS LETT, V83, P3213, DOI 10.1063/1.1619215
   Wang MX, 2021, INFORM SCIENCES, V544, P1, DOI 10.1016/j.ins.2020.07.051
   Wang XY, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116246
   Wen HP, 2019, EUR PHYS J PLUS, V134, DOI 10.1140/epjp/i2019-12797-4
   Woods R., 2017, FPGA BASED IMPLEMENT, V2nd
   Yepdia LMH, 2021, SENS IMAGING, V22, DOI 10.1007/s11220-021-00340-8
   Yepdia LMH., 2021, SECUR COMMUN NETW, V2021, P1
   Zhang S, 2014, MATH PROBL ENG, V1, P1
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 50
TC 14
Z9 14
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23819
EP 23843
DI 10.1007/s11042-022-12400-6
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549800031
DA 2024-07-18
ER

PT J
AU Polat, Ö
   Salk, I
   Dogan, OT
AF Polat, Ozlem
   Salk, Ismail
   Dogan, Omer Tamer
TI Determination of COPD severity from chest CT images using deep transfer
   learning network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COPD severity classification; Convolutional neural networks; Transfer
   learning; Inception-V3
ID STATEMENT; DISEASE
AB The purpose of this study is to present a solution to the problem of detecting the severity of Chronic Obstructive Pulmonary Disease (COPD) from chest CT images using deep transfer learning network. The study has a novelty in terms of classifying the severity of COPD with machine learning methods for the first time in the literature. Transfer learning has been preferred because of its proven performance in image analysis and classification. In this study, a dataset containing a total of 1815 CT images from 121 patients with moderate, severe and very severe COPD was used. Lung parenchyma was first segmented from CT images using HSV color space thresholding. Then Inception-V3 model was trained and tested on the segmented image dataset for COPD severity classification. The tests were repeated 10 times. The proposed model was able to detect the severity level of COPD with an average accuracy of 96.79% and a maximum of 97.98%. The classification result proved that the severity of COPD can be classified with very high performance. Thus, the applied transfer learning is promising in medical sciences and can assist to radiologists in making quick and accurate decisions.
C1 [Polat, Ozlem] Sivas Cumhuriyet Univ, Fac Technol, Dept Mechatron Engn, Sivas, Turkey.
   [Salk, Ismail] Sivas Cumhuriyet Univ, Fac Med, Dept Radiol, Sivas, Turkey.
   [Dogan, Omer Tamer] Sivas Cumhuriyet Univ, Fac Med, Dept Chest Dis, Sivas, Turkey.
C3 Cumhuriyet University; Cumhuriyet University; Cumhuriyet University
RP Polat, Ö (corresponding author), Sivas Cumhuriyet Univ, Fac Technol, Dept Mechatron Engn, Sivas, Turkey.
EM ozlem.polat@cumhuriyet.edu.tr
RI Polat, Ozlem/AAC-3022-2021; Salk, Ismail/M-8295-2015
OI Polat, Ozlem/0000-0002-9395-4465; Salk, Ismail/0000-0002-5156-6923
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Ahmed J, 2020, BILDVERARBEITUNG MED, DOI [10.1007/978-3-658-29267-6_8arXiv:2001.01100, DOI 10.1007/978-3-658-29267-6_8ARXIV:2001.01100]
   Amalakuhan B, 2012, J COMMUNITY HOSP INT, V2, DOI 10.3402/jchimp.v2i1.9915
   Celli BR, 2015, EUR RESPIR REV, V24, P159, DOI 10.1183/16000617.00000315
   Chollet F, 2015, KERAS
   Christodoulou E, 2019, J CLIN EPIDEMIOL, V110, P12, DOI 10.1016/j.jclinepi.2019.02.004
   Delen D, 2010, ARTIF INTELL MED, V49, P33, DOI 10.1016/j.artmed.2010.01.002
   Du R, 2020, IEEE ACCESS, V8, P38907, DOI 10.1109/ACCESS.2020.2974617
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ganesan P, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P101, DOI 10.1109/ICCICCT.2014.6992938
   Gietema HA, 2011, ACAD RADIOL, V18, P661, DOI 10.1016/j.acra.2011.01.011
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Leidy NK, 2016, CHRON OBSTR PULM DIS, V3, P406, DOI 10.15326/jcopdf.3.1.2015.0144
   Leng L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092644
   Lynch DA, 2015, RADIOLOGY, V277, P192, DOI 10.1148/radiol.2015141579
   Moll M, 2020, CHEST, V158, P952, DOI 10.1016/j.chest.2020.02.079
   Naylor CD, 2018, JAMA-J AM MED ASSOC, V320, P1099, DOI 10.1001/jama.2018.11103
   Nichols James A, 2019, Biophys Rev, V11, P111, DOI 10.1007/s12551-018-0449-9
   Rabe KF, 2007, AM J RESP CRIT CARE, V176, P532, DOI 10.1164/rccm.200703-456SO
   Saravanan G, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P462, DOI 10.1109/ICCSP.2016.7754179
   Saria S, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002721
   Shah, 2019, INT RES J ENG TECHNO, V6, P608
   Smith A.R., 1978, P 5 ANN C COMP GRAPH, V12, P12, DOI [10.1145/965139.807361, DOI 10.1145/965139.807361]
   Sorensen L, 2020, AM J ROENTGENOL, V214, P1269, DOI 10.2214/AJR.19.22300
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Vogelmeier CF, 2017, EUR RESPIR J, V49, DOI [10.1183/13993003.00214-2017, 10.1164/rccm.201701-0218PP, 10.1111/resp.13012, 10.1016/j.arbres.2017.02.001]
   Yang ZY, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121464
   Zhang Y, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19183914
NR 32
TC 1
Z9 1
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21903
EP 21917
DI 10.1007/s11042-022-12801-7
EA MAR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770205800009
DA 2024-07-18
ER

PT J
AU Shao, DG
   Li, CY
   Huang, CS
   Xiang, Y
   Yu, ZT
AF Shao, Dangguo
   Li, Chengyao
   Huang, Chusheng
   Xiang, Yan
   Yu, Zhengtao
TI A news classification applied with new text representation based on the
   improved LDA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE News classification; Latent Dirichlet allocation (LDA); Gibbs sampling;
   Adaptive iteration; Long short-term memory (LSTM) networks
ID CHINESE WORD SEGMENTATION; LSTM
AB Recently, news classification became an essential part of the Natural Language Processing (NLP). The traditional Latent Dirichlet Allocation (LDA) model used the generated "topic-document" matrix theta as a text representation feature to train a classifier and has achieved improved results. However, some text information will be missed using only the "topic-document" matrix theta as the text feature. In addition, the Gibbs sampling iteration number of the traditional LDA model must be set in advance, which affects the algorithm's speed. In this paper, the traditional LDA model is improved in two phases. In the first phase, a method to determine the convergence of the parameter search process is proposed. An adaptive iterative method is used with the proposed method. In the second phase, a new text representation (C-new) obtained by multiplying the "topic-document" matrix theta and the "word-topic" matrix phi is provided. In the evaluation results, the proposed method is tested using the news corpus in the field of metallurgy, and the THU Chinese News (THUCNews) corpus provided by the Natural Language Processing Laboratory of Tsinghua University. The proposed method proved its efficiency in improving the classification accuracy and reducing the number of iterations for the Gibbs sampling compared with the traditional LDA.
C1 [Shao, Dangguo; Li, Chengyao; Huang, Chusheng; Xiang, Yan; Yu, Zhengtao] Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Yunnan, Peoples R China.
   [Shao, Dangguo; Xiang, Yan; Yu, Zhengtao] Kunming Univ Sci & Technol, Yunnan Key Lab Artificial Intelligence, Kunming 650500, Yunnan, Peoples R China.
C3 Kunming University of Science & Technology; Kunming University of
   Science & Technology
RP Shao, DG (corresponding author), Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Yunnan, Peoples R China.; Shao, DG (corresponding author), Kunming Univ Sci & Technol, Yunnan Key Lab Artificial Intelligence, Kunming 650500, Yunnan, Peoples R China.
EM 23014260@qq.com; 644599667@qq.com; 646561123@qq.com; 50691012@qq.com;
   2187933459@qq.com
RI yu, zhang/JWO-7724-2024; Lin, Fan/JZT-1441-2024
OI Lin, Fan/0000-0002-7330-3833
FU Postdoctoral Science Foundation of China [2016M592894XB]; Nature and
   Science Foundation of China [61741112]; Nature and Science Foundation of
   Yunnan Province [2017FB098]
FX This work was supported by the Postdoctoral Science Foundation of China
   (2016M592894XB), the Nature and Science Foundation of China (61741112)
   and the Nature and Science Foundation of Yunnan Province (2017FB098). We
   also appreciated the valuable comments from the other members in our
   department.
CR Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Burkhardt S, 2018, MACH LEARN, V107, P859, DOI 10.1007/s10994-017-5689-6
   Cecchini D, 2018, INT CONF BIG DATA, P681, DOI 10.1109/BigComp.2018.00125
   Chair-Chickering P, 2004, P 20 C UNC ART INT
   Chen JZ, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P551, DOI [10.1109/CIS.2016.133, 10.1109/CIS.2016.0134]
   Chen KW, 2016, EXPERT SYST APPL, V66, P245, DOI 10.1016/j.eswa.2016.09.009
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Feng GZ, 2015, PATTERN RECOGN LETT, V65, P109, DOI 10.1016/j.patrec.2015.07.028
   Gao JF, 2005, COMPUT LINGUIST, V31, P531, DOI 10.1162/089120105775299177
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang R, 2018, INT GEOSCI REMOTE SE, P6408, DOI 10.1109/IGARSS.2018.8519240
   Jia-Ni HU, 2005, STUDY FEATURE SELECT
   Jiang LX, 2016, ENG APPL ARTIF INTEL, V52, P26, DOI 10.1016/j.engappai.2016.02.002
   Xu JY, 2020, NEUROCOMPUTING, V386, P42, DOI 10.1016/j.neucom.2019.08.080
   Jun L., 2012, J COMPUT APPL, V29, P4224
   Kaur RP, 2020, MULTIMED TOOLS APPL, V79, P7435, DOI 10.1007/s11042-019-08365-8
   Li GM, 2020, NEURAL PROCESS LETT, V51, P749, DOI 10.1007/s11063-019-10108-7
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Liu JX, 2019, NEUROCOMPUTING, V338, P46, DOI 10.1016/j.neucom.2019.01.085
   Liu Y., 2019, COMPUT INFORM ENCE, V12, P87
   Luo LX, 2019, PERS UBIQUIT COMPUT, V23, P405, DOI 10.1007/s00779-018-1183-9
   Nan F, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6345
   Park ST, 2022, PERS UBIQUIT COMPUT, V26, P429, DOI 10.1007/s00779-020-01476-2
   Rajeswari S, 2019, COMPUT ELECTRON AGR, V156, P530, DOI 10.1016/j.compag.2018.12.013
   Rani R, 2021, MULTIMED TOOLS APPL, V80, P3275, DOI 10.1007/s11042-020-09549-3
   Shen X., 2014, P 23 ACM INT C C INF, P101, DOI DOI 10.1145/2661829.2661935
   Shoukun X., 2018, COMPUT ENG DES, V39, P2764
   Srivastava A., 2017, ARXIV170301488, P1, DOI [DOI 10.1109/ICACCAF.2017.8344732, 10.1109/ICISC.2017.8068607, DOI 10.1109/ICISC.2017.8068607]
   Sun M, 2016, EFFICIENT CHINESE TE
   van Ravenzwaaij Don, 2018, Psychon Bull Rev, V25, P143, DOI 10.3758/s13423-016-1015-8
   Varatharajan R, 2018, MULTIMED TOOLS APPL, V77, P17573, DOI [10.1007/s11042-017-4768-9, 10.1007/s11042-017-5318-1]
   Wang Q, 2019, CHIN AUTOM CONGR, P1974, DOI 10.1109/CAC48633.2019.8996952
   Wermter S, 2000, INFORM RETRIEVAL, V3, P87, DOI 10.1023/A:1009942513170
   Xiangdong L., 2015, LIB INF TECHNOL, V31, P42
   Xu GX, 2019, IEEE ACCESS, V7, P21527, DOI 10.1109/ACCESS.2019.2897475
   Yang Z, 2014, CHINESE J ELECTRON, V23, P315
   Yu S, 2020, J INTELL FUZZY SYST, P1
   Zhang XY, 2014, INTELL DATA ANAL, V18, P449, DOI 10.3233/IDA-140650
   Zhang YS, 2019, CHINESE J ELECTRON, V28, P120, DOI 10.1049/cje.2018.11.004
   Zhao W, 2018, IEEE T KNOWL DATA EN, V30, P185, DOI 10.1109/TKDE.2017.2756658
   Zhiyong Q, 2014, RES AUTOMATIC WORD S
   Zhou C., 2015, COMPUT ENCE, V1, P44
   Zhou Y, 2017, ACM IEEE WIC ACM INT
NR 43
TC 10
Z9 10
U1 3
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21521
EP 21545
DI 10.1007/s11042-022-12713-6
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770061400001
DA 2024-07-18
ER

PT J
AU Srikanth, R
   Bikshalu, K
AF Srikanth, Rangu
   Bikshalu, Kalagadda
TI Chaotic multi verse improved Harris hawks optimization (CMV-IHHO)
   facilitated multiple level set model with an ideal energy active contour
   for an effective medical image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contour; Chan and Vese; Level set; Meta-heuristic optimization; Multi
   verse; Harris hawks optimization
AB Nowadays, the contour models (CMs) are widely used in image segmentation. Among these CMs, the Chan and Vese model depending on level set is the current regional based model, considering the regularity of intensity in every region. If the contour is not initialized correctly, the conventional level set (LS) model frequently sticks in local minima. This is becoming more important in the medical images context. In this manuscript, a multi-level set model with an ideal energy active contour is proposed, which is anticipated to realize the performance of acceptable segmentation, regardless of the contour's initial choice. The active contour models are utilized to identify an object outline from the image. The active CMs with energy based segmentation methods minimizes the energy related with active contour. This work makes the appropriate energy minimized difficult to solve by using meta-heuristic optimization algorithm and makes a proficient execution of the approach by Chaotic Multi Verse Improved Harris Hawks Optimization (CMV-IHHO) technique. Here, the proposed approach is compared with six existing approaches. The existing methods such as DA, Symmetry Analysis, Fuzzy C-Means, Rough Fuzzy C-Means, K-Means Level Set, Random Forest, and Support vector machine method. The accuracy of the proposed method is 0.91%, 5.84%, 15.63%, 8.30%, 10.97%, 15.77%, and 5.14% better than the existing approaches. The sensitivity of the proposed method is 3.37%, 5.74%, 22.66%, 4.54%, 17.94%, 4.54% and 15% better than the existing methods.
C1 [Srikanth, Rangu] Kakatiya Inst Technol & Sci, Dept Elect & Commun Engn, Warangal, Andhra Pradesh, India.
   [Bikshalu, Kalagadda] Kakatiya Univ, Univ Coll Engn, Dept Elect & Commun Engn, Warangal, Andhra Pradesh, India.
C3 Kakatiya University; Kakatiya University
RP Srikanth, R (corresponding author), Kakatiya Inst Technol & Sci, Dept Elect & Commun Engn, Warangal, Andhra Pradesh, India.
EM rangusphd@gmail.com
OI kalagadda, Bikshalu/0000-0001-8716-4582
CR Ahn E, 2017, IEEE J BIOMED HEALTH, V21, P1685, DOI 10.1109/JBHI.2017.2653179
   Chartrand G, 2017, IEEE T BIO-MED ENG, V64, P2110, DOI 10.1109/TBME.2016.2631139
   Chen H, 2020, FUTURE GENER COMP SY, V111, P175, DOI 10.1016/j.future.2020.04.008
   Choy SK, 2017, PATTERN RECOGN, V68, P141, DOI 10.1016/j.patcog.2017.03.009
   Desheng Li, 2019, Vibroengineering PROCEDIA. 42nd International Conference on Vibroengineering, P93, DOI 10.21595/vp.2019.21054
   Ewees AA, 2020, ENG APPL ARTIF INTEL, V88, DOI 10.1016/j.engappai.2019.103370
   Gupta S, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113510
   Jae Hoon Jung, 2017, IEEE Life Science Letters, V3, P5, DOI 10.1109/LLS.2017.2756886
   Jia HM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11121421
   Jiang HY, 2019, ELECTRON LETT, V55, P386, DOI 10.1049/el.2019.0183
   Kaur R, 2018, MULTIMED TOOLS APPL, P1
   Li XP, 2018, J SIGNAL PROCESS SYS, V90, P449, DOI 10.1007/s11265-017-1257-3
   Mandal D, 2017, STUD COMPUT INTELL, V704, P49, DOI 10.1007/978-3-662-54428-0_4
   Mythili S., 2020, HKIE T, V27, P25, DOI DOI 10.33430/V27N1THIE-2018-0024
   Obaidullah SM, 2018, MULTIMED TOOLS APPL, V77, P1643, DOI 10.1007/s11042-017-4373-y
   Rajesh P., 2020, Eur J Electr Eng, V22, P224, DOI [10.18280/ejee.224-509, DOI 10.18280/EJEE.224-509]
   Sayed GI, 2019, NEURAL COMPUT APPL, V31, P2763, DOI 10.1007/s00521-017-3228-9
   Shajin FH, 2022, INT J PERVASIVE COMP, V18, P603, DOI 10.1108/IJPCC-09-2020-0136
   Singh T, 2020, NEURAL COMPUT APPL, V32, P17789, DOI 10.1007/s00521-020-04951-2
   Tan TY, 2019, IEEE ACCESS, V7, P34004, DOI 10.1109/ACCESS.2019.2903015
   Thota M. K., 2020, Int. J. ApplSci Eng., V17, P331, DOI [DOI 10.6703/IJASE.20201217(4).331, DOI 10.6703/IJASE.202012_17(4).331]
   Virupakshappa, 2020, MULTIMED TOOLS APPL, V79, P3571, DOI 10.1007/s11042-018-6176-1
   Wang GT, 2018, IEEE T MED IMAGING, V37, P1562, DOI 10.1109/TMI.2018.2791721
   Wang XH, 2019, MULTIMED TOOLS APPL, V78, P33921, DOI 10.1007/s11042-019-08073-3
   Yang P, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3339474
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Zhang Z, 2020, ENG APPL ARTIF INTEL, V96, DOI 10.1016/j.engappai.2020.103998
   Zhou SP, 2017, NEUROCOMPUTING, V234, P216, DOI 10.1016/j.neucom.2017.01.013
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 29
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20963
EP 20992
DI 10.1007/s11042-022-12344-x
EA MAR 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000768099900001
DA 2024-07-18
ER

PT J
AU Dayana, AM
   Emmanuel, WRS
AF Dayana, A. Mary
   Emmanuel, W. R. Sam
TI An enhanced swarm optimization-based deep neural network for diabetic
   retinopathy classification in fundus images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy; Deep neural network; Classification; Chronological
   tunicate swarm algorithm; Stacked autoencoder
ID RETINAL LESIONS; DIAGNOSIS; SEVERITY; SYSTEM
AB Diabetic Retinopathy (DR) is one of the long-lasting Diabetic retinal disorders that leads to vision impairment eventually blindness in most of the working-age population. The process of classifying the severity level of DR has been a great challenging task as the lesion features are hard to analyze. The screening process requires an effective detection method to classify the subtle pathologies of the retina. Deep neural architectures play a vital role in diagnosing eye disease and helps ophthalmologists to provide timely treatment. This paper proposes an efficient, optimized deep neural network with Chronological Tunicate Swarm Algorithm (CTSA) for classifying the severity of DR. Initially, the retinal images captured through the low-quality fundus photography are preprocessed and then subjected to the segmentation process. First, the optic disc and the blood vasculatures are segmented using a U-Net and sparse Fuzzy C-means-based hybrid entropy model. The lesion area is then detected using the Gabor filter banks, and then the features are extracted. The final classification process takes place using a deep Stacked Autoencoder (SAE) jointly optimized with a bio-inspired Tunicate Swarm Algorithm based on the chronological concept. The presented model achieved an average accuracy, sensitivity, specificity and F1-Score values of 95.9%, 88.07%, 96.80% and 85.26% for the DIARETDB0 database and 95.48%, 93.29%, 91.89% and 90.53% for the DIARETDB1 database. The experimental outcome demonstrates the effectiveness and the robustness of the proposed method in the DR classification task.
C1 [Dayana, A. Mary] Nesamony Mem Christian Coll, Dept Comp Sci, Marthandam, India.
   [Dayana, A. Mary; Emmanuel, W. R. Sam] Manonmaniam Sundaranar Univ, Tirunelveli 627012, Tamil Nadu, India.
   [Emmanuel, W. R. Sam] Nesamony Mem Christian Coll, Dept PG Comp Sci, Marthandam, India.
C3 Manonmaniam Sundaranar University
RP Dayana, AM (corresponding author), Nesamony Mem Christian Coll, Dept Comp Sci, Marthandam, India.; Dayana, AM (corresponding author), Manonmaniam Sundaranar Univ, Tirunelveli 627012, Tamil Nadu, India.
EM amarydayana@gmail.com; sam_emmanuel@nmcc.ac.in
RI Dayana, Mary/DUL-9149-2022; EMMANUEL, W R SAM/E-5526-2018
OI Dayana A, Mary/0000-0003-1561-6804
CR Abbas Q, 2017, MED BIOL ENG COMPUT, V55, P1959, DOI 10.1007/s11517-017-1638-6
   Abdelmaksoud E, 2021, IEEE ACCESS, V9, P15939, DOI 10.1109/ACCESS.2021.3052870
   Adem K, 2019, EXPERT SYST APPL, V115, P557, DOI 10.1016/j.eswa.2018.08.050
   Akram MU, 2014, COMPUT BIOL MED, V45, P161, DOI 10.1016/j.compbiomed.2013.11.014
   Aljarah I, 2018, SOFT COMPUT, V22, P1, DOI 10.1007/s00500-016-2442-1
   [Anonymous], DIARETDB0 STANDARD D
   [Anonymous], DIARETDB1 STANDARD D
   Bazi Y, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030516
   Bhardwaj C, 2021, J AMB INTEL HUM COMP, V12, P2649, DOI 10.1007/s12652-020-02426-9
   Casini L, 2021, PHILOS ADV MED IMAGI
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Chang XY, 2017, IEEE T CYBERNETICS, V47, P2616, DOI 10.1109/TCYB.2016.2627686
   Das S, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102600
   Gadekallu TR, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020274
   Gayathri S, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102115
   Hemanth DJ, 2020, NEURAL COMPUT APPL, V32, P707, DOI 10.1007/s00521-018-03974-0
   Hemeida AM, 2020, AIN SHAMS ENG J, V11, P659, DOI 10.1016/j.asej.2020.01.007
   Islam M., 2017, J Biomed Sci Eng, V10, P86, DOI DOI 10.4236/JBISE.2017.105B010
   Jadhav AS, 2021, EVOL INTELL, V14, P1431, DOI 10.1007/s12065-020-00400-0
   Jia XH, 2020, IEEE ACCESS, V8, P146182, DOI 10.1109/ACCESS.2020.3015270
   Kadan AB, 2021, INT J IMAG SYST TECH, V31, P1009, DOI 10.1002/ima.22482
   Kar SS, 2018, IEEE T BIO-MED ENG, V65, P608, DOI 10.1109/TBME.2017.2707578
   Karthikeyan R, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1055-x
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Keerthiveena B, 2021, IET IMAGE PROCESS, V15, P542, DOI 10.1049/ipr2.12047
   Khamparia A, 2020, MULTIMED TOOLS APPL, V79, P35425, DOI 10.1007/s11042-019-07839-z
   Li YH, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6142839
   Liu GF, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/5105709
   Luo YG, 2020, IEEE ACCESS, V8, P92352, DOI 10.1109/ACCESS.2020.2994047
   Mahesh KM, 2020, IET IMAGE PROCESS, V14, P2541, DOI 10.1049/iet-ipr.2018.6682
   Mane VM, 2017, BIOMED ENG-BIOMED TE, V62, P321, DOI 10.1515/bmt-2016-0112
   Nguyen PT, 2021, CMC-COMPUT MATER CON, V66, P2815, DOI 10.32604/cmc.2021.012315
   Playout C, 2019, IEEE T MED IMAGING, V38, P2434, DOI 10.1109/TMI.2019.2906319
   Qiao LF, 2020, IEEE ACCESS, V8, P104292, DOI 10.1109/ACCESS.2020.2993937
   Rani N., 2020, J XIAN U ARCHIT TECH, VXII, P1444
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roshini TV, 2020, INT J IMAG SYST TECH, V30, P1173, DOI 10.1002/ima.22419
   Saeedi P, 2019, DIABETES RES CLIN PR, V157, DOI 10.1016/j.diabres.2019.107843
   Shankar K, 2020, IEEE ACCESS, V8, P118164, DOI 10.1109/ACCESS.2020.3005152
   Shankar K, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2568-8
   Shankar K, 2020, PATTERN RECOGN LETT, V133, P210, DOI 10.1016/j.patrec.2020.02.026
   Vaishnavi J, 2020, MULTIMED TOOLS APPL, V79, P30439, DOI 10.1007/s11042-020-09288-5
   Wang J, 2020, IEEE J BIOMED HEALTH, V24, P3397, DOI 10.1109/JBHI.2020.3012547
   Wei SS, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11010068
   Witten DM, 2010, J AM STAT ASSOC, V105, P713, DOI 10.1198/jasa.2010.tm09415
   Xu B, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/832093
   Yang YH, 2022, IEEE T CYBERNETICS, V52, P11407, DOI 10.1109/TCYB.2021.3062638
   Zeng XL, 2019, IEEE ACCESS, V7, P30744, DOI 10.1109/ACCESS.2019.2903171
   Zhou W, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/1942582
   Zhou Y, 2021, IEEE T MED IMAGING, V40, P818, DOI 10.1109/TMI.2020.3037771
NR 50
TC 16
Z9 16
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20611
EP 20642
DI 10.1007/s11042-022-12492-0
EA MAR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767748600014
DA 2024-07-18
ER

PT J
AU Husain, SS
   Mir, J
   Anwar, SM
   Rafique, W
   Ullah, MO
AF Husain, Syed Sameed
   Mir, Junaid
   Anwar, Syed Muhammad
   Rafique, Waqas
   Ullah, Muhammad Obaid
TI Development and validation of a deep learning-based algorithm for
   drowsiness detection in facial photographs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drowsiness detection; Fatigue detection; Deep convolutional neural
   network; Parametric aggregation; CNN
ID FATIGUE; NETWORK; EEG
AB Drowsiness is a feeling of sleepiness before the sleep onset and has severe implications from a safety perspective for the individuals involved in industrial activities, mining, and driving. The state-of-the-art computer vision (CV) based drowsiness detection methods generally utilize multiple deep convolutional neural networks (DCNN) without investigating deep feature aggregation techniques for the drowsiness detection task. More importantly, the reported results are mostly based on acted drowsy data, making the utilization of models trained on such data highly arguable for detecting drowsiness in real-life situations. Towards ameliorating this, we first present a comprehensive real drowsy data curated from 50 subjects, where subjects are labeled as fresh or drowsy. Further, four DCNN models: Xception, ResNet101, InceptionV4, and ResNext101, are trained on our dataset using transfer learning to select a baseline model for our drowsiness detection method. Moreover, an experimental study is performed using five different pooling methods: global max, global average, generalized mean, region of interest, and Weibull activation, to compute a robust and discriminative global descriptor. Our results reveal that the parametric Weibull activation pooling is the best suited for aggregating deep convolutional features. Additionally, a low complexity model based on the MobileNetV2 is proposed for a deployable drowsiness detection solution in mobile devices. The detection accuracy of 93.80% and 90.50% is achieved using our proposed Weibull-based ResNext101 and MobileNetV2 models, respectively. Moreover, our results show that the proposed non-invasive method outperforms the polysomnography signals-based invasive drowsiness detection approach.
C1 [Husain, Syed Sameed] Univ Surrey, Ctr Vis, Speech, Signal Proc, Guildford, Surrey, England.
   [Mir, Junaid; Ullah, Muhammad Obaid] Univ Engn & Technol Taxila, Dept Elect Engn, Taxila 47050, Pakistan.
   [Anwar, Syed Muhammad] Univ Engn & Technol Taxila, Dept Comp Engn, Taxila 47050, Pakistan.
   [Rafique, Waqas] Univ Oxford, Dept Engn Sci, Oxford, England.
C3 University of Surrey; University of Engineering & Technology Taxila;
   University of Engineering & Technology Taxila; University of Oxford
RP Mir, J (corresponding author), Univ Engn & Technol Taxila, Dept Elect Engn, Taxila 47050, Pakistan.
EM junaid.mir@uettaxila.edu.pk
RI anwar, syed/AGY-3965-2022
OI anwar, syed/0000-0002-8179-3959
CR Abtahi S., 2014, P 5 ACM MULT SYST C, P24, DOI DOI 10.1145/2557642.2563678
   Akin M, 2008, NEURAL COMPUT APPL, V17, P227, DOI [10.1007/s00521-007-0117-7, 10.1007/S00521-007-0117-7]
   Akrout B, 2013, MULTIMEDIA UBIQUITOU, P43, DOI 10.1007/978-94-007-6738-6_6
   Arefnezhad S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040943
   Arora M, 2021, MULTIMED TOOLS APPL, V80, P3039, DOI 10.1007/s11042-020-09726-4
   Azizpour Hossein, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P36, DOI 10.1109/CVPRW.2015.7301270
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Byrnes A, 2018, IEEE INT C INTELL TR, P2092, DOI 10.1109/ITSC.2018.8569293
   Celona L, 2018, IEEE I C CONS ELECT
   Chen S, 2021, INFORMATION, V12, DOI 10.3390/info12010003
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chowdhury A, 2018, IEEE SENS J, V18, P3055, DOI 10.1109/JSEN.2018.2807245
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dua M, 2021, NEURAL COMPUT APPL, V33, P3155, DOI 10.1007/s00521-020-05209-7
   Gao ZH, 2017, INT CONF MEAS, P99, DOI [10.1109/ICMTMA.2017.30, 10.1109/ICMTMA.2017.0031]
   Gershon P, 2011, ACCIDENT ANAL PREV, V43, P797, DOI 10.1016/j.aap.2010.10.027
   Ghoddoosian R, 2019, IEEE COMPUT SOC CONF, P178, DOI 10.1109/CVPRW.2019.00027
   Guo JM, 2019, MULTIMED TOOLS APPL, V78, P29059, DOI 10.1007/s11042-018-6378-6
   Hachisuka S, 2013, 2013 INTERNATIONAL CONFERENCE ON BIOMETRICS AND KANSEI ENGINEERING (ICBAKE), P320, DOI 10.1109/ICBAKE.2013.89
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Husain SS, 2019, ACTNET END TO END LE
   Ibrahim LF, 2014, MULTIMED TOOLS APPL, V71, P1857, DOI 10.1007/s11042-012-1308-5
   Jamshidi S, 2021, MULTIMED TOOLS APPL, V80, P16045, DOI 10.1007/s11042-021-10542-7
   Kaida K, 2006, CLIN NEUROPHYSIOL, V117, P1574, DOI 10.1016/j.clinph.2006.03.011
   Katyal Y, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P1008, DOI 10.1109/ICACCCT.2014.7019248
   Khessiba S, 2021, NEURAL COMPUT APPL, V33, P6921, DOI 10.1007/s00521-020-05467-5
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   MacLean AW, 2019, HBK BEHAV NEUROSCI, V30, P611, DOI 10.1016/B978-0-12-813743-7.00040-2
   Malcangi M, 2016, NEURAL COMPUT APPL, V27, P1165, DOI 10.1007/s00521-015-1928-6
   Massoz Q., 2016, Applications of Computer Vision (WACV), P1
   Mehreen A, 2019, IEEE SENS J, V19, P5119, DOI 10.1109/JSEN.2019.2904222
   Monika, 2021, Computational Methods and Data Engineering. Proceedings of ICMDE 2020. Advances in Intelligent Systems and Computing (AISC 1227), P207, DOI 10.1007/978-981-15-6876-3_16
   Ngxande M, 2017, 2017 PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA AND ROBOTICS AND MECHATRONICS (PRASA-ROBMECH), P156, DOI 10.1109/RoboMech.2017.8261140
   Park S, 2017, LECT NOTES COMPUT SC, V10118, P154, DOI 10.1007/978-3-319-54526-4_12
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Ramzan M, 2019, IEEE ACCESS, V7, P61904, DOI 10.1109/ACCESS.2019.2914373
   Reddy B, 2017, IEEE COMPUT SOC CONF, P438, DOI 10.1109/CVPRW.2017.59
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharaff Aakanksha, 2020, International Journal of Web-Based Learning and Teaching Technologies, V15, P19, DOI 10.4018/IJWLTT.2020040102
   Sharaff Aakanksha., 2016, Emerging Research in Computing, Information. Communication and Applications, P237, DOI DOI 10.1007/978-81-322-2553-9_23
   Shih TH, 2017, LECT NOTES COMPUT SC, V10118, P146, DOI 10.1007/978-3-319-54526-4_11
   SIMONYAN K, 2013, DEEP FACE RECOGNITIO
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tolias G., 2015, ARXIV151105879
   Wang Y, 2019, PATTERN RECOGN LETT, V123, P61, DOI 10.1016/j.patrec.2019.03.013
   Weng CH, 2017, LECT NOTES COMPUT SC, V10118, P117, DOI 10.1007/978-3-319-54526-4_9
   Wijnands JS, 2020, NEURAL COMPUT APPL, V32, P9731, DOI 10.1007/s00521-019-04506-0
   World Health Organization, 2018, Global status report on alcohol and health 2018
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yu J, 2019, IEEE T INTELL TRANSP, V20, P4206, DOI 10.1109/TITS.2018.2883823
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao L, 2020, MULTIMED TOOLS APPL, V79, P26683, DOI 10.1007/s11042-020-09259-w
NR 61
TC 5
Z9 5
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20425
EP 20441
DI 10.1007/s11042-022-12433-x
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767748600011
DA 2024-07-18
ER

PT J
AU Debarba, HG
   Montagud, M
   Chagué, S
   Herrero, JGL
   Lacosta, I
   Langa, SF
   Charbonnier, C
AF Galvan Debarba, Henrique
   Montagud, Mario
   Chague, Sylvain
   Garcia-Lajara Herrero, Javier
   Lacosta, Ignacio
   Fernandez Langa, Sergi
   Charbonnier, Caecilia
TI Content format and quality of experience in virtual reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Content formats; Quality of experience; Virtual reality
AB In this paper, we investigate three forms of virtual reality (VR) content production and consumption. Namely, pre-rendered 360 stereoscopic video, full real-time rendered 3D scenes, and the combination of a real-time rendered 3D environment with a pre-rendered video billboard used to present the central elements of the scene. We discuss the advantages and disadvantages of these content formats and describe the production of a piece of VR cinematic content for the three formats. The cinematic segment presented the interaction between two actors, which the VR user could watch from the virtual room next-door, separated from the action by a one-way mirror. To compare the three content formats, we carried out an experiment with 24 participants. In the experiment, we evaluated the quality of experience, including presence, simulation sickness and the participants' assessment of content quality, for each of the three versions of the cinematic segment. We found that, in the context of our cinematic segment, combining video and 3D content produced the best experience. We discuss our results, including their limitations and the potential applications.
C1 [Galvan Debarba, Henrique; Chague, Sylvain; Charbonnier, Caecilia] Artanim Fdn, Chemin Grand Puits 40, CH-1217 Meyrin, Switzerland.
   [Galvan Debarba, Henrique] Aalborg Univ, AC Meyers Vaenge 15, DK-2450 Copenhagen, Denmark.
   [Montagud, Mario] Univ Valencia, Av Blasco Ibanez 13, Valencia 46010, Spain.
   [Montagud, Mario; Fernandez Langa, Sergi] Fundacio i2CAT, Caner Gran Capita 2, Barcelona 08034, Spain.
   [Garcia-Lajara Herrero, Javier] Overlat, Calle Merce Rodoreda 2, Madrid 28702, Spain.
   [Garcia-Lajara Herrero, Javier; Lacosta, Ignacio] Mo Modern Cultural Prod, Espoz & Mina N4, Zaragoza 50003, Spain.
C3 Aalborg University; University of Valencia; Internet I Innovacio Digital
   A Catalunya (I2CAT)
RP Debarba, HG (corresponding author), Artanim Fdn, Chemin Grand Puits 40, CH-1217 Meyrin, Switzerland.; Debarba, HG (corresponding author), Aalborg Univ, AC Meyers Vaenge 15, DK-2450 Copenhagen, Denmark.
EM hgd@create.aau.dk
RI Charbonnier, Caecilia/HLV-7680-2023; Galvan Debarba,
   Henrique/D-8081-2015
OI Charbonnier, Caecilia/0000-0002-7018-885X; Galvan Debarba,
   Henrique/0000-0003-2090-9409
CR Alexiadis DS, 2017, IEEE T CIRC SYST VID, V27, P798, DOI 10.1109/TCSVT.2016.2576922
   Anwar MS, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2734-y
   Boukhris M., 2017, P 27 INT C ART REAL, P71, DOI DOI 10.2312/EGVE.20171341
   Cai S., 2018, 2018 3 DIG HER INT C, P1
   De Simone F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P890, DOI [10.1109/VR.2019.8798264, 10.1109/vr.2019.8798264]
   Fourquet E, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P49
   Germann M, 2010, COMPUT GRAPH FORUM, V29, P585, DOI 10.1111/j.1467-8659.2009.01628.x
   Gunkel Simon NB, 2017, ACM international conference on interactive experiences for TV and online video (ACM), P83, DOI [DOI 10.1145/3084289.3089914, 10.1145/3084289.3089914]
   Hamill J, 2005, COMPUT GRAPH FORUM, V24, P623, DOI 10.1111/j.1467-8659.2005.00887.x
   Hayashi K., 2006, INT C COMPUTER GRAPH, P220
   Kalckert A, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00040
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Levoy M, 1985, USE POINTS DISPLAY P
   Mangiante S, 2017, VR/AR NETWORK '17: PROCEEDINGS OF THE 2017 WORKSHOP ON VIRTUAL REALITY AND AUGMENTED REALITY NETWORK, P30, DOI 10.1145/3097895.3097901
   Pece F., 2013, Proceedings of the Conference on Human Factors in Computing Systems (CHI'13), P1319
   Revilla A, 2019, DELIVERABLE D4 1 1 E, DOI [10.5281/zenodo.3530496, DOI 10.5281/ZENODO.3530496]
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Teo T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300431
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Wu TLY, 2019, INT J HUM-COMPUT INT, V35, P1569, DOI 10.1080/10447318.2018.1555736
NR 22
TC 4
Z9 4
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 MAR 9
PY 2022
DI 10.1007/s11042-022-12176-9
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZP5BQ
UT WOS:000766438300006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Farooq, U
   Rabbi, I
   Akbar, S
   Zia, K
   Rehman, WU
AF Farooq, Umar
   Rabbi, Ihsan
   Akbar, Sajida
   Zia, Kashif
   Rehman, Waheed Ur
TI The impact of design on improved learning in virtual worlds: an
   experimental study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual words; Cultural heritage; Virtual reconstruction; OpenSimulator;
   Tele-porting; Learning
AB Virtual worlds are the most advanced form of virtual environments, which offer one of the best platforms for serving various domains. They are, especially, well suited for education, to cope with the physical restrictions imposed due to COVID-19 outbreak, as they offer classroom experience to their users through immersion. They are online interactive spaces which are collaborative, persistent, coherent, and social in nature. Users immersed in these spaces are represented in the form of digital characters called, avatars. Virtual worlds offer advanced navigation methods such as flying and teleporting to facilitate quick learning. This paper analyses the use of a partial but carefully reconstructed cultural heritage site, developed in OpenSimulator framework, for learning both in terms of discourse and quantitative analysis. Discourse analysis compares the developed virtual world presence with traditional content provisioning methods in terms of a large set of well-known characteristics. Quantitative analysis, on the other hand, is based on data collected from users after conducting simple learning experiments. It revealed that the properties such as realism, friendliness, advanced navigation, and being detailed and social in nature greatly attracted user attention in learning. The learning was fast compared with traditional methods, however, it was a little hard for naive users to start exploring the content. Pre and post learning responses of users revealed that their knowledge level was significantly increased. Based on valuable suggestions, it is planned in future, to add intelligence to traditional agents, so they may help in an increased learning experience of users, based on the knowledge gained in earlier sessions.
C1 [Farooq, Umar; Rabbi, Ihsan; Akbar, Sajida] Univ Sci & Technol, Bannu, Pakistan.
   [Zia, Kashif] Sohar Univ, Sohar, Oman.
   [Rehman, Waheed Ur] Univ Peshawar, Peshawar, Pakistan.
C3 University of Science & Technology Bannu; Sohar University; University
   of Peshawar
RP Rabbi, I (corresponding author), Univ Sci & Technol, Bannu, Pakistan.
EM umar214@gmail.com; ihsanrabbi@gmail.com; sajidamustafa2019@gmail.com;
   kzia@su.edu.om; wahrehman@gmail.com
RI Rabbi, Ihsan/F-3121-2013
OI Rabbi, Ihsan/0000-0003-1699-6300
CR Ahamd S, 2016, DAWN NEWS
   Beck J, 2019, TOUR REV, V74, P586, DOI 10.1108/TR-03-2017-0049
   Behnke L, 2020, THESIS U W SCOTLAND
   Berger Helmut, 2007, Virtual Reality, V11, P75, DOI 10.1007/s10055-006-0057-z
   Coy D, 2020, TELEPHONE MUSEUM
   Dai Z., 2021, Designing, deploying, and evaluating virtual and augmented reality in education, P143, DOI DOI 10.4018/978-1-7998-5043-4.CH007
   Davies CJ, 2014, P 20 ACM S VIRT REAL, P213
   Fibis-Wiki, 2020, FIB WIK N W RAILW
   Gearz S, 2020, CLIENT VIEWER SINGUL
   GoP, 2020, PAKISTAN EC SURVEY 2
   Griol D, 2019, VIRTUAL REALITY ED B, P314
   Harris A.L., 2009, Journal of information systems education, V20, P3
   Heeter C, 2020, INTERACT COMPUT, V32, P1, DOI 10.1093/iwc/iwaa001
   Javaid M, 2020, CLIN EPIDEMIOL GLOB, V8, P600, DOI 10.1016/j.cegh.2019.12.010
   Khan KF, 2020, KOT FATEH KHAN OFFIC
   Khan OM, 2016, NEWS SUNDAY JAN
   Krishna BA, 2023, CLIN INFECT DIS, V76, P738, DOI 10.1093/cid/ciac630
   Lallemand T, 1998, US Patent App, Patent No. [29/074,220, 29074220]
   Lercari N, 2016, PROGR IS, P337, DOI 10.1007/978-3-319-22041-3_13
   Luxford JM, 2012, P 2 EUR IMM ED SUMM
   Melo Jorge Orlando, 2021, Colombia: las razones de la guerra
   Nemtinov V., 2019, INT MULTIDISCIP SCI, V19, P225
   OSGrid Inc, 2021, OPENSIMULATOR OSIM G
   Pentecost D, 2021, MAYA PYRAMID ARCHIVE
   Petrovic VM, 2018, IEEE ACCESS, V6, P39976, DOI 10.1109/ACCESS.2018.2855970
   Pietroni E, 2008, INT J ARCHIT COMPUT
   Rashid S, 2016, CHOOSING LIFE REMITT
   Second Life, 2020, 18 CENT FRANC TIM PO
   Sequeira L., 2013, Journal of Virtual Words Research, V6, P1
   Yilmaz L, 2014, WINT SIMUL C PROC, P2797, DOI 10.1109/WSC.2014.7020122
   Yunjo An, 2019, Foundations and Trends in Smart Learning. Proceedings of 2019 International Conference on Smart Learning Environments. Lecture Notes in Educational Technology (LNET), P89, DOI 10.1007/978-981-13-6908-7_12
   Zapatero C, 2021, MUSEUM ISLAND
   Zia K, 2020, 2019 INT C ADV EM CO, P1
NR 33
TC 0
Z9 0
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18033
EP 18051
DI 10.1007/s11042-022-12593-w
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766064000002
PM 35282406
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Makem, M
   Tiedeu, A
   Kom, G
   Nkandeu, YPK
AF Makem, Mimosette
   Tiedeu, Alain
   Kom, Guillaume
   Nkandeu, Yannick Pascal Kamdeu
TI A robust algorithm for white blood cell nuclei segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE White blood cell; Nuclei; Color spaces; Fourier transform; Segmentation
ID LEUKOCYTES; DIAGNOSIS; IMAGES
AB Segmentation of white blood cell nucleus is a crucial step in white blood cell counting and classification system based on peripheral blood smear images. It is also used in the automated diagnosis of blood cancer diseases. However, this step is a challenging task due to the variation of contrast and shape of the nucleus in peripheral blood smear images. This paper proposes an improved method for white blood cell nucleus extraction. The proposed method makes use of arithmetical operation guided by a control parameter, Fourier Transform algorithm for texture enhancement, mean shift technique for smoothing and boundary preservation, and k-means clustering algorithm with an adaptive K for nucleus extraction. The proposed segmentation algorithm was tested on 5 completely different image databases, and the results compared favorably with recent methods from good standing papers. An Average dice similarity coefficient of 97.35% was obtained for CellaVision database, 96.63% for normal leukocytes of ALL-IDB2 database, 93.48% for BloodSeg database, 93.14% for JTSC database, 88.63% for the healthy leukocytes of the ALL-IDB2 database and 86.02% for the LSCI database.
C1 [Makem, Mimosette; Tiedeu, Alain; Nkandeu, Yannick Pascal Kamdeu] HTTTC EBOLOWA, Dept Med & Biomed Engn, Signal Image & Syst Lab, POB 886, Ebolowa, Cameroon.
   [Tiedeu, Alain] Univ Yaounde I, HTTTC EBOLOWA, Ctr Res Expt & Prod, Ebolowa, Cameroon.
   [Tiedeu, Alain] Univ Yaounde I, Natl Adv Sch Engn, Ingn Math & Syst Informat, POB 8390, Yaounde, Cameroon.
   [Kom, Guillaume] Univ Dschang, IUT FV Bandjoun, Dept Elect Engn, Automat & Signal Proc Lab, Dschang, Cameroon.
C3 University of Yaounde I; University of Yaounde I; Universite de Dschang
RP Tiedeu, A (corresponding author), HTTTC EBOLOWA, Dept Med & Biomed Engn, Signal Image & Syst Lab, POB 886, Ebolowa, Cameroon.; Tiedeu, A (corresponding author), Univ Yaounde I, HTTTC EBOLOWA, Ctr Res Expt & Prod, Ebolowa, Cameroon.; Tiedeu, A (corresponding author), Univ Yaounde I, Natl Adv Sch Engn, Ingn Math & Syst Informat, POB 8390, Yaounde, Cameroon.
EM alain_tiedeu@yahoo.ir
RI Tiedeu, Alain/IWM-7083-2023
OI Tiedeu, Alain/0000-0002-0067-4254
FU SIDA (the Swedish International Development Cooperation Agency) through
   ISP (the International Science Programme, Uppsala University)
FX The authors wish to thank Ms Shemmira Yunus from the University of Cape
   Coast, Ghana for proof-reading this paper. SIDA (the Swedish
   International Development Cooperation Agency) through ISP (the
   International Science Programme, Uppsala University) is acknowledged by
   Ms Makem, for the financial support.
CR Abdul Nasir A. S., 2011, 2011 Proceedings of IEEE International Conference on Imaging Systems and Techniques (IST 2011), P142, DOI 10.1109/IST.2011.5962188
   AL-Dulaimi K, 2020, COMPUT BIOL MED, V116, DOI 10.1016/j.compbiomed.2019.103568
   Alireza, 2020, K MEANS MEAN SHIFT N
   Alizadehsani R, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104095
   Amin Morteza Moradi, 2015, J Med Signals Sens, V5, P49
   Andrade AR, 2019, COMPUT METH PROG BIO, V173, P1, DOI 10.1016/j.cmpb.2019.03.001
   Anita, 2021, COMPUT METH PROG BIO, V199, DOI 10.1016/j.cmpb.2020.105893
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Banik PP, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113211
   Baydilli YY, 2020, COMPUT MED IMAG GRAP, V80, DOI 10.1016/j.compmedimag.2020.101699
   Chen Y., 2020, PERIPHERAL BLOOD LEU, DOI [10.1007/978-3-030-62463-7_43, DOI 10.1007/978-3-030-62463-7_43]
   Demirovic D, 2019, IMAGE PROCESS ON LIN, V9, P251, DOI 10.5201/ipol.2019.255
   Feng YC, 2017, DIGIT SIGNAL PROCESS, V60, P186, DOI 10.1016/j.dsp.2016.08.003
   Ghassemi N, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101678
   Gonzalez W., 2004, DIGITAL IMAGE PROCES, P845
   Hegde RB, 2019, MULTIMED TOOLS APPL, V78, P17879, DOI 10.1007/s11042-018-7107-x
   Hegde RB, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1219-3
   Jha KK, 2019, COMPUT METH PROG BIO, V179, DOI 10.1016/j.cmpb.2019.104987
   Jyotismita C., 2020, IMAGE COLOR FEATURE
   Khodatars M, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104949
   Khouani A, 2020, BIOMED ENG LETT, V10, P359, DOI 10.1007/s13534-020-00168-3
   Ko BC, 2011, MICRON, V42, P695, DOI 10.1016/j.micron.2011.03.009
   Kumar P., 2017, J Biomed Imaging Bioeng, V1, P20
   Kutlu H, 2020, MED HYPOTHESES, V135, DOI 10.1016/j.mehy.2019.109472
   Labati RD, 2011, IEEE IMAGE PROC
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lu Y, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107006
   Madhloom H. T., 2010, Journal of Applied Sciences, V10, P959, DOI 10.3923/jas.2010.959.966
   Madhukar M, 2012, PROC SPIE, V8295, DOI 10.1117/12.905969
   Makem M., 2020, Inform Med Unlocked, V20, DOI [10.1016/j.imu.2020.100416, DOI 10.1016/J.IMU.2020.100416]
   Mohamed M, 2012, IEEE SYS MAN CYBERN, P220, DOI 10.1109/ICSMC.2012.6377703
   Moshavash Z, 2018, J DIGIT IMAGING, V31, P702, DOI 10.1007/s10278-018-0074-y
   Pakhira MK, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS, P1047, DOI 10.1109/CICN.2014.220
   Rezatofighi SH, 2011, COMPUT MED IMAG GRAP, V35, P333, DOI 10.1016/j.compmedimag.2011.01.003
   Roy RM, 2021, BIOMED SIGNAL PROCES, V65, DOI 10.1016/j.bspc.2020.102385
   Sadeghi D., 2021, OVERVIEW ARTIFICIAL, P1
   Sapna S., 2020, International Journal of Computers and Applications, V42, P622, DOI 10.1080/1206212X.2020.1726013
   Saraswat M, 2014, MICRON, V65, P20, DOI 10.1016/j.micron.2014.04.001
   Sarrafzadeh O, 2015, 2015 IEEE INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS 2015)
   Shahin AI, 2017, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-017-0038-5
   Shoeibi A, 2020, AUTOMATED DETECTION
   Shoeibi A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104697
   Shoeibi A, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18115780
   Singh KK, 2021, BIG DATA MIN ANAL, V4, P84, DOI 10.26599/BDMA.2020.9020012
   Singh KK, 2020, ROM J INF SCI TECH, V23, pS91
   Sompayrac L. M., 2019, IMMUNE SYSTEM WORKS
   Sthitpattanapongsa P., 2012, INT C PATTERN RECOGN, P894
   Tareef A, 2017, I S BIOMED IMAGING, P565, DOI 10.1109/ISBI.2017.7950584
   Tareef A, 2016, I S BIOMED IMAGING, P935, DOI 10.1109/ISBI.2016.7493418
   Tran T, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION ENGINEERING (ICECE 2018), P13, DOI 10.1109/ICECOME.2018.8644754
   The Fast Fourier Transform (FFT), VER SHORT COURS TIM
   Tiedeu A, 2012, DIGIT SIGNAL PROCESS, V22, P124, DOI 10.1016/j.dsp.2011.09.004
   Umamaheswari D, 2020, INDIAN J SCI TECHNOL, V13, P4541, DOI [10.17485/ijst/v13i45.328, DOI 10.17485/IJST/v13i45.328]
   Vincent I., 2015, 2015 21st Korea-Japan Joint Workshop on Frontiers of Computer Vision (FCV), P1, DOI [DOI 10.1109/FCV.2015.7103739, 10.1109/fcv.2015.7103739]
   Vogado LHS, 2018, ENG APPL ARTIF INTEL, V72, P415, DOI 10.1016/j.engappai.2018.04.024
   Vogado LHS, 2016, IEEE INT SYM MULTIM, P451, DOI [10.1109/ISM.2016.30, 10.1109/ISM.2016.0103]
   Wang X, 2020, MACHINE LEARNING BAS, DOI [10.1007/978-981-13-9217-7, DOI 10.1007/978-981-13-9217-7]
   Yepdia LMH, 2021, SENS IMAGING, V22, DOI 10.1007/s11220-021-00340-8
   Yin SB, 2017, PATTERN RECOGN, V68, P245, DOI 10.1016/j.patcog.2017.03.012
   Zhang CC, 2014, SENSORS-BASEL, V14, P16128, DOI 10.3390/s140916128
   Zheng X, 2018, MICRON, V107, P55, DOI 10.1016/j.micron.2018.01.010
NR 61
TC 8
Z9 8
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17849
EP 17874
DI 10.1007/s11042-022-12285-5
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701900003
DA 2024-07-18
ER

PT J
AU Sharma, VK
   Sharma, PC
   Goud, H
   Singh, A
AF Sharma, Vijay Kumar
   Sharma, Prakash Chandra
   Goud, Harsh
   Singh, Arjun
TI Hilbert quantum image scrambling and graph signal processing-based image
   steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quantum image scrambling; Alpha blending; Graph signal processing;
   Steganography; Graph wavelet
ID TRANSFORM
AB Steganography plays a big role in secret communication by concealing secret information in the carrier. This paper presents a graph signal processing-based robust image steganography technique for posting images over social networks. In the embedding, we first obtained a scrambled version of the secret image using quantum scrambling. Next, we applied graph wavelet transformation on both the cover image and scrambled secret image followed by alpha (alpha) blending on both image signals (cover image signal and scrambled image signal). Finally, inverse graph wavelet transformation of the resulting image was undertaken to obtain the stego image. In this paper, the use of graph wavelet transformation improved interpixel correlation, which resulted in the excellent visual quality of both the stego image and the extracted secret image. Our experiments show that the picture quality of both the cover image and the stego image is exactly the same.
C1 [Sharma, Vijay Kumar; Singh, Arjun] Manipal Univ Jaipur, Sch Comp & Informat Technol, Ajmer Rd, Jaipur, Rajasthan, India.
   [Sharma, Prakash Chandra] Manipal Univ Jaipur, Informat Technol Dept, Ajmer Rd, Jaipur, Rajasthan, India.
   [Goud, Harsh] Indian Inst Informat Technol, Elect & Commun Engg Dept, Nagpur, Maharashtra, India.
C3 Manipal University Jaipur; Manipal University Jaipur
RP Sharma, VK (corresponding author), Manipal Univ Jaipur, Sch Comp & Informat Technol, Ajmer Rd, Jaipur, Rajasthan, India.
EM vijaymayankmudgal2008@gmail.com
RI SINGH, ARJUN/AAA-8518-2022
OI SINGH, ARJUN/0000-0003-4631-6601
CR Ahani S, 2015, IET IMAGE PROCESS, V9, P496, DOI 10.1049/iet-ipr.2014.0351
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Das P, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, ENERGY & COMMUNICATION (CIEC), P211, DOI 10.1109/CIEC.2016.7513754
   Debnath B, 2017, IET CIRC DEVICE SYST, V11, P58, DOI 10.1049/iet-cds.2015.0245
   Elshazly E, 2018, J SYST ENG ELECTRON, V29, P639, DOI 10.21629/JSEE.2018.03.21
   Girdhar A, 2018, IET IMAGE PROCESS, V12, P619, DOI 10.1049/iet-ipr.2018.0088
   Hamidi H, 2015, IET IMAGE PROCESS, V9, P716, DOI 10.1049/iet-ipr.2013.0663
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Jiang N, 2014, INT J THEOR PHYS, V53, P2463, DOI 10.1007/s10773-014-2046-4
   Kim CR, 2018, ELECTRON LETT, V54, P626, DOI 10.1049/el.2017.4276
   Laskar SA., 2014, INT J ENG RES TECHNO, V3, P3400
   Mostafa R, 2015, 2015 IEEE SEVENTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INFORMATION SYSTEMS (ICICIS), P300, DOI 10.1109/IntelCIS.2015.7397238
   Mukhopadhyay S, 2021, MULTIMED TOOLS APPL, V80, P14495, DOI 10.1007/s11042-020-10424-4
   Narang SK, 2012, IEEE T SIGNAL PROCES, V60, P2786, DOI 10.1109/TSP.2012.2188718
   Nazari M, 2020, MULTIMED TOOLS APPL, V79, P13693, DOI 10.1007/s11042-019-08415-1
   Rathore M, 2019, INT J FUTURE EVOL CO, V5
   Reddy HSM, 2012, 4 INT C ADV REC TECH, P169
   Sajasi S, 2015, APPL SOFT COMPUT, V30, P375, DOI 10.1016/j.asoc.2015.01.032
   Setiadi DIM, 2021, MULTIMED TOOLS APPL, V80, P8423, DOI 10.1007/s11042-020-10035-z
   Sharma VK, 2020, INT ARAB J INF TECHN, V17, P154, DOI 10.34028/iajit/17/2/2
   Shrestha A, 2015, 9 INT C SOFTW KNOWL, P9
   Shuman DI, 2013, IEEE SIGNAL PROC MAG, V30, P83, DOI 10.1109/MSP.2012.2235192
   Sukumar A, 2020, MULTIMED TOOLS APPL, V79, P10825, DOI 10.1007/s11042-019-08476-2
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Zhang X, 2016, IEEE IND ELEC, P889, DOI 10.1109/IECON.2016.7793133
NR 25
TC 8
Z9 8
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17817
EP 17830
DI 10.1007/s11042-022-12426-w
EA MAR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701900018
DA 2024-07-18
ER

PT J
AU Sridevi, A
   Sivaraman, R
   Balasubramaniam, V
   Sreenithi
   Siva, J
   Thanikaiselvan, V
   Rengarajan, A
AF Sridevi, A.
   Sivaraman, R.
   Balasubramaniam, Varun
   Sreenithi
   Siva, J.
   Thanikaiselvan, V
   Rengarajan, Amirtharajan
TI On Chaos based duo confusion duo diffusion for colour images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Confusion; Diffusion; Logistic map; Tent map; Lorenz attractor; Lu
   attractor
ID ENCRYPTION; CRYPTANALYSIS; COMBINATION; SYSTEM
AB In recent years, owing to the frequent flow of digital images worldwide over the transmission media, it has become essential to secure them from leakages. Moreover, many applications like military image databases, confidential video conferencing, medical imaging systems, cable TV, online personal photograph albums, etc., require reliable, fast and robust security systems to transmit digital images. Among the available encryption schemes, chaos-based (Chaos means randomness) encryption techniques are considered acceptable, which provides randomness and high security. In this work, chaos assisted Color image encryption has been proposed. Initially, the Colour image is split into its RGB planes. To accomplish the encryption on RGB planes, duo confusion and duo diffusion through chaotic maps and attractors have been performed. Confusion and diffusion have been carried out in each plane in two stages, namely - block and plane, for which Logistic Map, Lorenz Attractor, Tent map and Lu attractor with different initial conditions and seeds are used. Finally, the separated RGB planes have been merged to produce an encrypted image. Standard encryption analyses such as - statistical attack analyses, encryption quality analyses, keyspace analyses, and chi-square tests have been performed to evaluate the proposed work. To evidence, the proposed method's attack resistance capability, chosen plain text, noise and cropping attacks have been conducted
C1 [Sridevi, A.; Sivaraman, R.; Siva, J.; Rengarajan, Amirtharajan] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
   [Balasubramaniam, Varun] Perfios Software Solut, Bengaluru 560030, Karnataka, India.
   [Sreenithi] Tech Univ Chemnitz, Chemnitz, Germany.
   [Thanikaiselvan, V] Vellore Inst Technol, Vellore, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Technische Universitat Chemnitz; Vellore Institute of Technology (VIT);
   VIT Vellore
RP Rengarajan, A (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM amir@ece.sastra.edu
RI R, Sivaraman/ABB-1397-2020; Amirtharajan, Rengarajan/C-6471-2011
OI R, Sivaraman/0000-0001-5989-4422; Amirtharajan,
   Rengarajan/0000-0003-1574-3045; Rethinam, Sivaraman/0000-0001-9292-8524;
   Thanikaiselvan, V/0000-0003-2418-5217
FU Department of Science & Technology, New Delhi
   [<bold>SR/FST/ET-I/2018/221(C)</bold>]
FX Authors thank the Department of Science & Technology, New Delhi, for the
   FIST funding (<BOLD>SR/FST/ET-I/2018/221(C)</BOLD>). Also, the authors
   wish to thank the Intrusion Detection Lab at School of Electrical &
   Electronics Engineering, SASTRA Deemed University, for providing
   infrastructural support to carry out this research work.
CR Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Belazi A, 2014, NONLINEAR DYNAM, V76, P1989, DOI 10.1007/s11071-014-1263-y
   Dhall S, 2018, SIGNAL PROCESS, V146, P22, DOI 10.1016/j.sigpro.2017.12.021
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   El Ogri O, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106346
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Gagunashvili ND, 2012, COMPUT PHYS COMMUN, V183, P418, DOI 10.1016/j.cpc.2011.10.009
   Girdhar A, 2018, MULTIMED TOOLS APPL, V77, P27017, DOI 10.1007/s11042-018-5902-z
   Hu GZ, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107790
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Iqbal N, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102809
   Kaur G, 2022, J KING SAUD UNIV-COM, V34, P5883, DOI 10.1016/j.jksuci.2021.03.007
   Khaitan S., 2021, Materials Today: Proceedings, DOI [10.1016/j.matpr.2021.05.251, DOI 10.1016/J.MATPR.2021.05.251]
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Kumar V, 2021, MULTIMED TOOLS APPL, V80, P3749, DOI 10.1007/s11042-020-09854-x
   Kunwar RS, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATION AND AUTOMATION (ICACCA 2016), P228
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Muñoz-Guillermo M, 2021, INFORM SCIENCES, V552, P352, DOI 10.1016/j.ins.2020.11.045
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Naseer Y, 2021, J INF SECUR APPL, V59, DOI 10.1016/j.jisa.2021.102829
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Shah T, 2020, WIRELESS PERS COMMUN, V113, P1201, DOI 10.1007/s11277-020-07274-6
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang XY, 2016, BIOSYSTEMS, V144, P18, DOI 10.1016/j.biosystems.2016.03.011
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Xian YJ, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106202
   Xu M, 2018, OPTIK, V171, P891, DOI 10.1016/j.ijleo.2018.06.112
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Yildirim M, 2020, MICROELECTRON J, V104, DOI 10.1016/j.mejo.2020.104878
   Zhang XQ, 2021, OPT LASER TECHNOL, V141, DOI 10.1016/j.optlastec.2021.107073
   Zhang Y, 2021, INFORM SCIENCES, V547, P307, DOI 10.1016/j.ins.2020.07.058
NR 35
TC 11
Z9 11
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16987
EP 17014
DI 10.1007/s11042-022-12471-5
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764599600003
DA 2024-07-18
ER

PT J
AU Abbaspoor, N
   Hassanpour, H
AF Abbaspoor, Navid
   Hassanpour, Hamid
TI Face recognition in a large dataset using a hierarchical classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Large datasets; FERET dataset; Non-negative matrix
   factorization; Shi-Tomasi; FREAK
ID SINGLE TRAINING SAMPLE; IMAGE; TRACKING; FLDA
AB Face recognition is one of the most common authentication methods. Although much research has been conducted in this area, there are still many challenging issues to be addressed on face recognition, such as a large number of images in a dataset, with only one sample per person. The goal of this paper is to provide a robust face recognition method for a database having a large number of images with only one sample per person. The proposed method first uses a simple clustering approach to divide the images hierarchically into balanced clusters. Balanced clustering helps us to continue clustering in several hierarchies and finally reach very small clusters of equal size. Then, the face recognition task is performed within each cluster. A combination of the Non-negative Matrix Factorization (NMF) and the Fast Retina Key-point (FREAK) descriptors has been used to match the faces. The proposed method was evaluated on the FERET dataset that achieved an accuracy of 98.36%. Also, some other experiments have been done to validate the efficiency of the proposed method. The results of the experiments show that the proposed method can be applied to even larger datasets, while its complexity increases linearly.
C1 [Abbaspoor, Navid; Hassanpour, Hamid] Shahrood Univ Technol, Shahrood, Semnan, Iran.
C3 Shahrood University of Technology
RP Hassanpour, H (corresponding author), Shahrood Univ Technol, Shahrood, Semnan, Iran.
EM navid.abbaspoor@gmail.com; h.hassanpour@shahroodut.ac.ir
RI Hassanpour, Hamid/AAL-7271-2020
OI Hassanpour, Hamid/0000-0002-5513-9822
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Al-Obaydy Wasseem N. Ibrahem, 2020, InECCE2019. Proceedings of the 5th International Conference on Electrical, Control & Computer Engineering. Lecture Notes in Electrical Engineering (LNEE 632), P425, DOI 10.1007/978-981-15-2317-5_36
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Annalakshmi M, 2019, CLUSTER COMPUT, V22, P11, DOI 10.1007/s10586-017-1585-x
   Awad AI, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3
   Bai G, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P610, DOI 10.1109/CISP.2008.520
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Biglari M, 2014, ROBUST FEATURE EXTRA
   Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010
   Chen YH, 2006, LECT NOTES COMPUT SC, V4224, P355
   Cheng ZY, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107422
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Du G, 2009, FACE RECOGNITION USI
   Duong VH, 2019, VISUAL OBJECT TRACKI
   Gao QX, 2008, APPL MATH COMPUT, V205, P726, DOI 10.1016/j.amc.2008.05.019
   Gutta S, 1996, IEEE IJCNN, P1017, DOI 10.1109/ICNN.1996.549037
   Hao L, 2019, PROGR HUM COMPUT INT, V2
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hassaballah M, 2015, IET COMPUT VIS, V9, P614, DOI 10.1049/iet-cvi.2014.0084
   Hassaballah M., 2020, Deep Learning in Computer Vision: Principles and Applications, DOI DOI 10.1201/9781351003827
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu C.-M, 2015, 2015 40th International Conference on Infrared, Millimeter and Terahertz Waves (IRMMW-THz), P1, DOI 10.1109/IRMMW-THz.2015.7327529
   Jain A. K., 2011, HDB FACE RECOGNITION
   Ji HK, 2017, PATTERN RECOGN, V62, P125, DOI 10.1016/j.patcog.2016.08.007
   Kan MN, 2013, PATTERN RECOGN, V46, P2497, DOI 10.1016/j.patcog.2013.01.037
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kim J, 2011, SIAM J SCI COMPUT, V33, P3261, DOI 10.1137/110821172
   Kortli Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020342
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607
   Li YT, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3397179
   Liu HH, 2014, ASIAPAC SIGN INFO PR
   Lu J, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P109
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Milborrow S., 2010, Pattern Recognition Association of South Africa, V201, P1
   Min R, 2019, IEEE ACCESS, V7, P45219, DOI 10.1109/ACCESS.2019.2909039
   Moussa M, 2018, STUD INFORM CONTROL, V27, P127, DOI 10.24846/v27i1y201813
   Nikan F, 2020, MULTIMED TOOLS APPL, V79, P28265, DOI 10.1007/s11042-020-09394-4
   Nikolaus, 2007, LEARNING PARTS OBJEC
   Otto C, 2016, ARXIV160400989CS
   Pan J, 2016, IEEE ACCESS, V4, P2873, DOI 10.1109/ACCESS.2016.2574366
   Perronnin F, 2005, PROC SPIE, V5779, P256, DOI 10.1117/12.603276
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Sireesha V., 2019, J INFO TECH SOFTW EN, V09, P254
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Taskiran M, 2020, DIGIT SIGNAL PROCESS, V106, DOI 10.1016/j.dsp.2020.102809
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Tuncer T, 2020, MULTIMED TOOLS APPL, V79, P29573, DOI 10.1007/s11042-020-09439-8
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wild S, 2004, PATTERN RECOGN, V37, P2217, DOI 10.1016/j.patcog.2004.02.013
   Wu BZ, 2017, LECT NOTES COMPUT SC, V10614, P49, DOI 10.1007/978-3-319-68612-7_6
   Xi M, 2016, IEEE IMAGE PROC, P3224, DOI 10.1109/ICIP.2016.7532955
   Xin M., 2015, APPL MATH INFORM SCI, V9, P353, DOI [10.12785/amis/090141, DOI 10.12785/AMIS/090141]
   Yang HC, 2016, J ALGORITHMS COMPUT, V10, P187, DOI 10.1177/1748301816649073
   Yang M, 2020, IEEE T INF FOREN SEC, V15, P2469, DOI 10.1109/TIFS.2020.2965301
   Yang M, 2013, IEEE I CONF COMP VIS, P689, DOI 10.1109/ICCV.2013.91
   Zeng JY, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/3803627
   Zhang DQ, 2005, APPL MATH COMPUT, V163, P895, DOI 10.1016/j.amc.2004.04.016
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhong S, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P459
   Zhou E., 2015, arXiv preprint arXiv:1501.04690
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
NR 76
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16477
EP 16495
DI 10.1007/s11042-022-12382-5
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256300001
DA 2024-07-18
ER

PT J
AU Zhang, XW
   Sun, XJ
   Lu, LP
AF Zhang, Xuewei
   Sun, Xiaojuan
   Lu, Liping
TI Research on multi-image and multi-parameter fusion algorithm based on
   detail restoration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrast enhancement; Detail restoration; Multi-image fusion; Low
   illumination
ID IMAGE-ENHANCEMENT
AB In order to improve the contrast, clarity and color fidelity of low illumination image, reduce the negative impact of image degradation, in this paper, we propose an image clarity scheme based on multi-image multi-parameter and multi-scale fusion. The scheme is based on the original image, according to our algorithm to generate the optimal exposure image, overexposure image and variational Retinex image. Secondly, the four images are taken as input seperately, and each input is decomposed into contrast component, texture structure component and brightness component. Finally, the extracted contrast component, texture structure component and brightness component are fused respectively according to the weight to build the image enhancement model, then get the enhanced image. Comparing different low illumination images, the experimental results show that the color cast of the proposed method is reduced by 47.8%, the contrast value are increased by 53%, the standard deviation is increased by more than 1.18 times, and the average gradient is increased by more than 4 times compared with the original image. The comprehensive performance is better than other comparison algorithms. The method in this paper has been well improved in image enhancement and detail preservation. It effectively improves the color fidelity, contrast and detail clarity of the image under low illumination. The enhanced visual effect and visibility of the image are obviously improved and more real and natural.
C1 [Zhang, Xuewei; Sun, Xiaojuan; Lu, Liping] Xian Technol Univ, Xian 710021, Peoples R China.
C3 Xi'an Technological University
RP Zhang, XW (corresponding author), Xian Technol Univ, Xian 710021, Peoples R China.
EM xueweizhang163@163.com
RI SUN, Xiaojuan/J-8982-2016
OI Zhang, Xuewei/0000-0002-5165-4886
FU Key Programs of Shaanxi science and Technology Department [2021GY-319]
FX This work has been supported by Key Programs of Shaanxi science and
   Technology Department (No.2021GY-319).
CR Abiko R, 2019, IEEE ACCESS, V7, P148790, DOI 10.1109/ACCESS.2019.2947266
   Celik T, 2014, IEEE T IMAGE PROCESS, V23, P5298, DOI 10.1109/TIP.2014.2364537
   Chuanmin Z., 2018, J ELECTRON IMAGING, V27
   Florea L, 2019, DIGIT SIGNAL PROCESS, V93, P1, DOI 10.1016/j.dsp.2019.06.014
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Ke L., 2020, ACTA OPTICA SIN, V40, P73
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lecca M, 2018, IEEE T IMAGE PROCESS, V27, P5802, DOI 10.1109/TIP.2018.2858541
   Lin CY, 2019, MULTIMED TOOLS APPL, V78, P1547, DOI 10.1007/s11042-018-6139-6
   Liu XL, 2019, ACTA PHOTONICA SINIC, V48, DOI 10.3788/gzxb20194808.0810002
   Mulyantini Agustien, 2016, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V19, P233, DOI 10.9717/kmms.2016.19.2.233
   Qin YC, 2020, J MED IMAG HEALTH IN, V10, P152, DOI 10.1166/jmihi.2020.2859
   Qu JH, 2020, IEEE ACCESS, V8, P30522, DOI 10.1109/ACCESS.2020.2972939
   Rao YB, 2013, ETRI J, V35, P923, DOI 10.4218/etrij.13.0212.0550
   Simi VR, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106364
   Singh K, 2014, OPTIK, V125, P4646, DOI 10.1016/j.ijleo.2014.04.093
   Srinivas K, 2020, J FRANKLIN I, V357, P13941, DOI 10.1016/j.jfranklin.2020.10.013
   Wu XM, 2021, IEEE T CIRC SYST VID, V31, P863, DOI 10.1109/TCSVT.2020.2991437
   Xiqin, 2017, J MINJIANG U, V5, P47
   Yao L, 2018, J MED IMAG HEALTH IN, V8, P122, DOI 10.1166/jmihi.2018.2244
   Yingjie M., 2019, ACTA PHOTONICA SINIC, V48, DOI 10.3788/gzxb20194807.0710005
   Yoon J, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.11.113103
   Yulu G., 2019, INFRARED TECHNOL, V41, P617
   Zhang CM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063026
   Zhang R, 2017, SIGNAL PROCESS-IMAGE, V58, P270, DOI 10.1016/j.image.2017.08.008
   [张淑芳 Zhang Shufang], 2018, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V30, P1015
   Zhang X, 2021, IEEE ACCESS, V9, P50939, DOI 10.1109/ACCESS.2021.3068534
NR 27
TC 2
Z9 2
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16589
EP 16600
DI 10.1007/s11042-022-12682-w
EA MAR 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256300003
DA 2024-07-18
ER

PT J
AU Wang, L
   Zhang, SH
   He, H
   Zhang, XX
   Sang, Y
AF Wang, Lei
   Zhang, Shihui
   He, Huan
   Zhang, Xiaoxiao
   Sang, Yu
TI A hierarchical residual network with compact triplet-center loss for
   sketch recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch recognition; Residual learning; Multi-scale fusion; Compact
   triplet-center loss
AB With the widespread use of touch-screen devices, it is more and more convenient for people to draw sketches on screen. This results in the demand for automatically understanding the sketches. Thus, the sketch recognition task becomes more significant than before. To accomplish this task, it is necessary to solve the critical issue of improving the distinction of the sketch features. To this end, we have made efforts in three aspects. First, a novel multi-scale residual block is designed. Compared with the conventional basic residual block, it can better perceive multi-scale information and reduce the number of parameters during training. Second, a hierarchical residual structure is built by stacking multi-scale residual blocks in a specific way. In contrast with the single-level residual structure, the learned features from this structure are more sufficient. Last but not least, the compact triplet-center loss is proposed specifically for the sketch recognition task. It can solve the problem that the triplet-center loss does not fully consider too large intra-class space and too small inter-class space in sketch field. By studying the above modules, a hierarchical residual network as a whole is proposed for sketch recognition and evaluated on Tu-Berlin benchmark thoroughly. The experimental results show that the proposed network outperforms most of baseline methods and it is excellent among non-sequential models at present.
C1 [Wang, Lei; Zhang, Shihui; Zhang, Xiaoxiao; Sang, Yu] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
   [Wang, Lei; Zhang, Shihui; Zhang, Xiaoxiao; Sang, Yu] Key Lab Comp Virtual Technol & Syst Integrat Hebe, Qinhuangdao 066004, Hebei, Peoples R China.
   [He, Huan] Hebei Normal Univ Sci & Technol, Sch Math & Informat Sci & Technol, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Yanshan University; Hebei Normal University of Science & Technology
RP Zhang, SH (corresponding author), Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.; Zhang, SH (corresponding author), Key Lab Comp Virtual Technol & Syst Integrat Hebe, Qinhuangdao 066004, Hebei, Peoples R China.
EM sshhzz@ysu.edu.cn
RI Zhang, Shihui/HHS-1779-2022; Zhang, Shihui/KFB-3255-2024
FU National Natural Science Foundation of China [61379065]; Natural Science
   Foundation of Hebei province in China [F2019203285]
FX This work was supported partly by the National Natural Science
   Foundation of China (No. 61379065) and the Natural Science Foundation of
   Hebei province in China (No. F2019203285).
CR Chang J, 2020, PROC CVPR IEEE, P5709, DOI 10.1109/CVPR42600.2020.00575
   Chen JX, 2019, PROC CVPR IEEE, P791, DOI 10.1109/CVPR.2019.00088
   Dai J, 2019, IEEE T IMAGE PROCESS, V28, P1366, DOI 10.1109/TIP.2018.2878505
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   He JY, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P448, DOI 10.1145/3123266.3123321
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XW, 2018, PROC CVPR IEEE, P1945, DOI 10.1109/CVPR.2018.00208
   Huang G, 2018, INT C LEARN REPR VAN, P4700
   Huang GL, 2017, IEEE ICC
   Kaiyue Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10344, DOI 10.1109/CVPR42600.2020.01036
   Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Y, 2015, COMPUT VIS IMAGE UND, V137, P1, DOI 10.1016/j.cviu.2015.02.003
   Lin HY, 2020, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR42600.2020.00679
   Ouyang S, 2020, IEEE C COMPUTER VISI, P5571
   Pang KY, 2019, PROC CVPR IEEE, P677, DOI 10.1109/CVPR.2019.00077
   Qiu HQ, 2020, IEEE C COMP VIS PATT, P13185
   Schneider RG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661231
   Sert M, 2019, MULTIMED TOOLS APPL, V78, P17095, DOI 10.1007/s11042-018-7067-1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srinivas A, 2021, PROC CVPR IEEE, P16514, DOI 10.1109/CVPR46437.2021.01625
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang M, 2020, C COMPUTER VISION PA, P9319
   Xu P, 2018, PROC CVPR IEEE, P8090, DOI 10.1109/CVPR.2018.00844
   Yang L, 2020, P IEEE INT C MULT EX, P1, DOI DOI 10.1142/S021800142059003X
   Yeh CH, 2020, IEEE T IMAGE PROCESS, V29, P3153, DOI 10.1109/TIP.2019.2957929
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Yu Q, 2016, PROC CVPR IEEE, P799, DOI 10.1109/CVPR.2016.93
   Yu Q, 2017, INT J COMPUT VISION, V122, P411, DOI 10.1007/s11263-016-0932-3
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang H, 2016, PROC CVPR IEEE, P1105, DOI 10.1109/CVPR.2016.125
   Zhang L, 2019, NEUROCOMPUTING, V351, P167, DOI 10.1016/j.neucom.2019.03.024
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zheng Y, 2021, NEUROCOMPUTING, V456, P528, DOI 10.1016/j.neucom.2020.05.124
NR 39
TC 1
Z9 1
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15879
EP 15899
DI 10.1007/s11042-022-12431-z
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762902200003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Dewangan, KK
   Dewangan, DK
   Sahu, SP
   Janghel, R
AF Dewangan, Kranti Kumar
   Dewangan, Deepak Kumar
   Sahu, Satya Prakash
   Janghel, Rekhram
TI Breast cancer diagnosis in an early stage using novel deep learning with
   hybrid optimization technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Deep learning; Magnetic resonance imaging; Krill herd
   optimization; Back propagation; African Buffalo optimization
AB Breast cancer is one of the primary causes of death that is occurred in females around the world. So, the recognition and categorization of initial phase breast cancer are necessary to help the patients to have suitable action. However, mammography images provide very low sensitivity and efficiency while detecting breast cancer. Moreover, Magnetic Resonance Imaging (MRI) provides high sensitivity than mammography for predicting breast cancer. In this research, a novel Back Propagation Boosting Recurrent Wienmed model (BPBRW) with Hybrid Krill Herd African Buffalo Optimization (HKH-ABO) mechanism is developed for detecting breast cancer in an earlier stage using breast MRI images. Initially, the MRI breast images are trained to the system, and an innovative Wienmed filter is established for preprocessing the MRI noisy image content. Moreover, the projected BPBRW with HKH-ABO mechanism categorizes the breast cancer tumor as benign and malignant. Additionally, this model is simulated using Python, and the performance of the current research work is evaluated with prevailing works. Hence, the comparative graph shows that the current research model produces improved accuracy of 99.6% with a 0.12% lower error rate.
C1 [Dewangan, Kranti Kumar; Dewangan, Deepak Kumar; Sahu, Satya Prakash; Janghel, Rekhram] Natl Inst Technol, Dept Informat Technol, Raipur 492010, Chhatisgarh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Dewangan, KK (corresponding author), Natl Inst Technol, Dept Informat Technol, Raipur 492010, Chhatisgarh, India.
EM kranti.d123@gmail.com; dkdcwangan.phd2018.it@nitrr.ac.in;
   spsahu.it@nitrr.ac.in; rrjanghel.it@nitrr.ac.in
RI Sahu, Satya Prakash/AAY-7426-2020
OI Sahu, Satya Prakash/0000-0002-9886-9518; Dewangan, Deepak
   Kumar/0000-0002-0160-4215
CR Bacolod MD, 2020, BMC CANCER, V20, DOI 10.1186/s12885-020-6574-4
   Benhammou Y, 2020, NEUROCOMPUTING, V375, P9, DOI 10.1016/j.neucom.2019.09.044
   Braz G, 2019, MULTIMED TOOLS APPL, V78, P13005, DOI 10.1007/s11042-018-6259-z
   Chaudhary PK, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104454
   Chaudhary PK, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102237
   Dembrower K, 2020, RADIOLOGY, V294, P265, DOI 10.1148/radiol.2019190872
   Dong YP, 2021, EUR RADIOL, V31, P345, DOI 10.1007/s00330-020-07085-0
   dos Santos JCM, 2020, RES BIOMED ENG, P1, DOI DOI 10.1007/S42600-020-00046-Y
   Du J, 2021, IEEE T CYBERNETICS, V51, P1586, DOI 10.1109/TCYB.2020.2969705
   Ghasemzadeh A, 2019, INT J MACH LEARN CYB, V10, P1603, DOI 10.1007/s13042-018-0837-2
   Gupta V, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102265
   Hu QY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-67441-4
   Kesavan D, 2022, INT J COMMUN SYST, V35, DOI 10.1002/dac.5003
   Khaled R, 2022, COMPUT BIOL MED, V140, DOI 10.1016/j.compbiomed.2021.105093
   Khalil R, 2020, EGYPT J RADIOL NUC M, V51, DOI 10.1186/s43055-019-0103-y
   Khan S, 2019, PATTERN RECOGN LETT, V125, P1, DOI 10.1016/j.patrec.2019.03.022
   Kim J, 2022, EUR RADIOL, V32, P4056, DOI 10.1007/s00330-021-08461-0
   Kumar M, 2020, ALGO INTELL SY, P113, DOI 10.1007/978-981-15-0994-0_7
   Lee JY, 2022, EUR RADIOL, V32, P650, DOI 10.1007/s00330-021-08146-8
   Li LQ, 2020, MULTIMED TOOLS APPL, V79, P14509, DOI 10.1007/s11042-018-6970-9
   Ma MM, 2022, EUR J RADIOL, V146, DOI 10.1016/j.ejrad.2021.110095
   Madhavan S, 2020, IEEE SENS J, V20, P3078, DOI 10.1109/JSEN.2019.2956072
   Melekoodappattu JG, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02359-3
   Meng ZH, 2021, J COLLOID INTERF SCI, V581, P31, DOI 10.1016/j.jcis.2020.07.072
   Mohsenpourian M, 2021, KNOWL-BASED SYST, V214, DOI 10.1016/j.knosys.2020.106625
   Nayak SR, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102365
   Patil RS, 2021, EVOL INTELL, V14, P1459, DOI 10.1007/s12065-020-00403-x
   Peng CT, 2022, COMPUT MED IMAG GRAP, V95, DOI 10.1016/j.compmedimag.2021.102021
   Piantadosi G, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2019.101781
   Qiao MY, 2022, IEEE J BIOMED HEALTH, V26, P3059, DOI 10.1109/JBHI.2022.3140236
   Qiao MY, 2021, COMPUT MED IMAG GRAP, V90, DOI 10.1016/j.compmedimag.2021.101909
   Ravi V., 2021, IEEE T ENG MANAGE, DOI [DOI 10.1109/TEM.2021.3059664, 10.1109/tem.2021.3059664]
   Sadhukhan S., 2020, EMERGING TECHNOLOGY, P113, DOI [10.1007/978-981-13-7403-6_12, DOI 10.1007/978-981-13-7403-6_12]
   Saranyaraj D, 2020, MULTIMED TOOLS APPL, V79, P11013, DOI 10.1007/s11042-018-6560-x
   Sheela CJJ, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101657
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Sriram S, 2020, IEEE CONF COMPUT, P189, DOI 10.1109/INFOCOMWKSHPS50562.2020.9162668
   Supriya M, 2020, HEALTH CARE MANAG SC, V23, P414, DOI 10.1007/s10729-019-09498-w
   Togaçar M, 2020, MED HYPOTHESES, V135, DOI 10.1016/j.mehy.2019.109503
   Vaka AR, 2020, ICT EXPRESS, V6, P320, DOI 10.1016/j.icte.2020.04.009
   Vinayakumar R, 2020, IEEE T IND APPL, V56, P4436, DOI 10.1109/TIA.2020.2971952
   Xianwei Jiang, 2020, Frontiers in Intelligent Computing: Theory and Applications. Proceedings of the 7th International Conference on FICTA (2018). Advances in Intelligent Systems and Computing (AISC 1014), P182, DOI 10.1007/978-981-13-9920-6_19
   Yadav SS, 2022, MULTIMED TOOLS APPL, V81, P13139, DOI 10.1007/s11042-020-09600-3
   Yala A, 2019, RADIOLOGY, V292, P60, DOI 10.1148/radiol.2019182716
   Yavuz E, 2020, MED BIOL ENG COMPUT, V58, P1583, DOI 10.1007/s11517-020-02187-9
   Yu XC, 2022, MULTIMED TOOLS APPL, V81, P11949, DOI 10.1007/s11042-020-09977-1
   Zhang Y, 2021, EUR RADIOL, V31, P2559, DOI 10.1007/s00330-020-07274-x
   Zheng J, 2020, IEEE ACCESS, V8, P96946, DOI 10.1109/ACCESS.2020.2993536
NR 48
TC 16
Z9 17
U1 6
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13935
EP 13960
DI 10.1007/s11042-022-12385-2
EA FEB 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761886300003
PM 35233181
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Hariss, K
   Noura, H
AF Hariss, Khalil
   Noura, Hassan
TI Towards a fully homomorphic symmetric cipher scheme resistant to
   plain-text/cipher-text attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Symmetric homomorphic cipher scheme; Known plain-text/cipher-text
   attack; Domingo ferrer; MORE approach; PORE approach; RSA ring; Cloud
   computing
ID ENCRYPTION ALGORITHM
AB Users' privacy becomes nowadays an important need and a big challenge for a lot of enterprises and service providers especially after adopting the cloud migration strategy. Thus, Homomorphic Encryption (HE) came as a novel cryptographic approach that enables users' privacy at the cloud side by allowing computation over encrypted data. Existing HE schemes are based on either symmetric or asymmetric encryption algorithms. While asymmetric HE schemes provide the high and the required level of security, they suffer from high computational complexity and high storage overhead making a big majority of them not practical for real world applications. On the other hand, symmetric schemes assure the required efficiency, but they are vulnerable to attacks and especially the known plain-text/cipher-text attacks making their usage limited in practical implementation. The main objective of this paper is to design a new symmetric HE variant that provides the desired level of efficiency in implementation and the immunity against data breaches especially the known plain-text/cipher-text attacks. The proposed scheme, named Homomorphic Hybrid Symmetric Encryption Scheme (HHSES), which is based on combining the homomorphic behavior of two well-known symmetric encryption schemes that are the MORE (Matrix Operation for Randomization and Encryption) approach and the Domingo Ferrer (DF) scheme. The performance analysis of HHSES confirms its efficiency for real-world applications in comparison with a big variety of existing and well known symmetric and asymmetric schemes. A main drawback of HHSES is the cipher-text dimension expansion after the homomorphic multiplication since homomorphic operations are restricted to polynomial operations over the matrices. Therefore, to fix this issue, we propose a specific Key Switching (KS) technique after the homomorphic multiplication that reduces the cipher-texts' dimension without altering its homomorphic behavior and the primitive classified data. Security analysis of the new scheme also verifies its immunity against different types of attacks and especially the known plain-text/cipher-text attacks. Another important contribution in this work is the optimization of the HHSES encryption and decryption procedures by making them parallelized using the Chinese Remainder Theorem (CRT). The implementation results have shown that the proposed optimization technique reduces the execution time of the HHSE encryption and decryption algorithms with a ratio close to 1/2. To the best of our knowledge, HHSES is the first symmetric HE scheme immune against the known/chosen plain-text/cipher-text attacks.
C1 [Hariss, Khalil] Lebanese Univ, Fac Engn CRSI, Hadath, Lebanon.
   [Hariss, Khalil] St Joseph Univ, ESIB CIMTI, Mar Roukoz, Lebanon.
   [Noura, Hassan] Univ Bourgogne Franche Comte UBFC, FEMTO ST Inst, CNRS, Belfort, France.
C3 Lebanese University; Centre National de la Recherche Scientifique
   (CNRS); Universite de Technologie de Belfort-Montbeliard (UTBM);
   Universite de Franche-Comte
RP Noura, H (corresponding author), Univ Bourgogne Franche Comte UBFC, FEMTO ST Inst, CNRS, Belfort, France.
EM hassan.noura@univ-fcomte.fr
RI Noura, Hassan/U-8729-2018
OI Noura, Hassan/0000-0002-2589-5053
FU EIPHI Graduate School [ANR-17-EURE-0002]
FX This work has been funded by the EIPHI Graduate School (contract
   "ANR-17-EURE-0002").
CR Aguilar-Melchor C, 2013, IEEE SIGNAL PROC MAG, V30, P108, DOI 10.1109/MSP.2012.2230219
   Brakerski Zvika, 2014, ACM Transactions on Computation Theory, V6, DOI 10.1145/2633600
   Brakerski Z, 2013, LECT NOTES COMPUT SC, V7778, P1, DOI 10.1007/978-3-642-36362-7_1
   Brakerski Z, 2011, LECT NOTES COMPUT SC, V6841, P505, DOI 10.1007/978-3-642-22792-9_29
   Catalano D, 2005, ADV COURSES MATH
   Coron JS, 2011, LECT NOTES COMPUT SC, V6841, P487, DOI 10.1007/978-3-642-22792-9_28
   Domingo-Ferrer J, 2002, LECT NOTES COMPUT SC, V2433, P471
   Gentry C, 2013, LECT NOTES COMPUT SC, V8042, P75, DOI 10.1007/978-3-642-40041-4_5
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   Gentry Craig, 2009, A fully homomorphic encryption scheme
   Hariss K, 2017, 2017 1ST CYBER SECURITY IN NETWORKING CONFERENCE (CSNET)
   Hariss K, 2019, PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON E-BUSINESS AND TELECOMMUNICATIONS, VOL 2: SECRYPT, P341, DOI 10.5220/0007788803410349
   Hariss K, 2018, LECT NOTES COMPUT SC, V10694, P127, DOI 10.1007/978-3-319-76687-4_9
   Hariss K, 2017, J INF SECUR APPL, V34, P233, DOI 10.1016/j.jisa.2017.02.001
   Im JH, 2016, 2016 IEEE 14TH INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, 14TH INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, 2ND INTL CONF ON BIG DATA INTELLIGENCE AND COMPUTING AND CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/DATACOM/CYBERSC, P878, DOI 10.1109/DASC-PICom-DataCom-CyberSciTec.2016.150
   Katz J., 2014, INTRO MODERN CRYPTOG
   Kim M, 2015, BMC MED INFORM DECIS, V15, DOI 10.1186/1472-6947-15-S5-S3
   Kim T, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/4195852
   Kipnis A., 2012, IACR Cryptol. ePrint Arch, V2012, P637
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Micciancio D, 2013, LECT NOTES COMPUT SC, V8042, P21, DOI 10.1007/978-3-642-40041-4_2
   Noura H, 2018, MULTIMED TOOLS APPL, V77, P18383, DOI 10.1007/s11042-018-5660-y
   Ozturk E., 2015, IACR Cryptology, V2015, P294
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Regev O, 2009, J ACM, V56, DOI 10.1145/1568318.1568324
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Schwarzweller C., 2009, STUDIELOGIC GRAMMA, V18
   Smart NP, 2014, DESIGN CODE CRYPTOGR, V71, P57, DOI 10.1007/s10623-012-9720-4
   Torres WAA, 2015, INT J PERVASIVE COMP, V11, P151, DOI 10.1108/IJPCC-02-2015-0012
   van Dijk M, 2010, LECT NOTES COMPUT SC, V6110, P24
   Vizar Damian, 2019, Tatra Mountains Mathematical Publications, V73, P163, DOI 10.2478/tmmp-2019-0012
   Wagner D, 2003, LECT NOTES COMPUT SC, V2851, P234
   Xiao Liangliang., 2012, IACR CRYPTOLOGY EPRI, V2012, P193
   Yi X, 2014, HOMOMORPHIC ENCRYPTI
NR 39
TC 4
Z9 4
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14403
EP 14449
DI 10.1007/s11042-022-12043-7
EA FEB 2022
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300002
DA 2024-07-18
ER

PT J
AU Kumar, A
   Tewari, N
   Kumar, R
AF Kumar, Amit
   Tewari, Naveen
   Kumar, Rajeev
TI A comparative study of various techniques of image segmentation for the
   identification of hand gesture used to guide the slide show navigation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human computer interaction; Region of interest; Hand gesture
   recognition; Machine learning; Image segmentation
AB Interaction between human and computer is becoming powerful day by day with the development of ubiquitous computing. Hand gesture recognition plays an efficient role to establish interaction between human and computer. Gesture is way of communication to understand body language. We can interact with computer using various devices like keyboard, mouse etc. This paper focus on comparing the different segmentation technique used to enhance the controling of slide show navigation without using these devices like mouse, keyboard, touch screen or laser device etc. Hand gesture recognition used to perform interaction by capturing the image, the image segmentation techniques detect the region of interst(ROI) which show the hand region. The gesture can be detected by analysing segmented hand region. All segemented regions are compared on the basis of their features. This paper show comparison of thresholding, laplacian kernel, k-means and canny edge detection segmentation technique use for recognition system to makes interaction easy, convenient and does not require any other system.
C1 [Kumar, Amit] Uttarakhand Tech Univ, Dehra Dun, Uttarakhand, India.
   [Tewari, Naveen] Graph Era Hill Univ, Bhimtal Campus, Naini Tal, Uttarakhand, India.
   [Kumar, Rajeev] Teerthanker Mahaveer Univ, CCSIT, Moradabad, UP, India.
C3 Uttarakhand Technical University; Teerthanker Mahaveer University
RP Kumar, A (corresponding author), Uttarakhand Tech Univ, Dehra Dun, Uttarakhand, India.
EM amit.vishnoi08@gmail.com; navtewari@gmail.com; rajeev2009mca@gmail.com
RI Kumar, Amit/ABC-2774-2022; Kumar, Rajeev/AAJ-4134-2021; Kumar,
   Rajeev/N-8237-2016; Tewari, Naveen/AAY-7668-2021
OI Kumar, Amit/0000-0001-6548-6820; Kumar, Rajeev/0000-0002-4141-1282;
   Kumar, Rajeev/0000-0002-4141-1282; Tewari, Naveen/0000-0002-6104-5005
CR Acharjya PP, 2012, GLOBAL J COMP SCI TE, V12
   Alfian G, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072183
   Ameur M, 2019, MULTIMED TOOLS APPL, V78, P34353, DOI 10.1007/s11042-019-08133-8
   Bhargavi K., 2014, INT J INNOV RES DEV, V3, P234
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Gao Z, 2020, NEURAL NETWORKS, V125, P290, DOI 10.1016/j.neunet.2020.02.017
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   Jaliya UK., 2016, INT RES J ENG TECHNO, V3, P2179
   Ji G.-R, 2018, 2018 IEEE 29 ANN INT, P1
   Kazdorf SY, 2019, PROCEDIA COMPUT SCI, V150, P450, DOI 10.1016/j.procs.2019.02.076
   Khan R.Z., 2012, Int. J. Artif, V3, P161, DOI 10.1007/s10489-010-0251-2
   Kumar A., 2019, INT J ANAL EXP MODAL, V11, P1456
   Kumar DM, 2021, MULTIMED TOOLS APPL, V80, P6939, DOI 10.1007/s11042-020-09635-6
   Li J, 2011, COMM COM INF SC, V228, P102
   Maharani DA, 2018, 2018 IEEE SYMPOSIUM ON COMPUTER APPLICATIONS & INDUSTRIAL ELECTRONICS (ISCAIE 2018), P1, DOI 10.1109/ISCAIE.2018.8405435
   Malik M, 2015, 4 INT C SYST MOD ADV
   Oudah M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080073
   Patel NA., 2018, INT J SCI RES SCI EN, V4, P1061
   Peng B, 2020, MULTIMED TOOLS APPL, V79, P32833, DOI 10.1007/s11042-020-09346-y
   Pradeep Kumar Reddy R, 2015, INT J ENG TRENDS TEC, DOI [10.14445/22315381/IJETT-ICGTETM-N3/ICGTETM-P121, DOI 10.14445/22315381/IJETT-ICGTETM-N3/ICGTETM-P121]
   Roy P, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P1182, DOI 10.1109/ICCICCT.2014.6993140
   Shanthakumar VA, 2020, MULTIMED TOOLS APPL, V79, P17707, DOI 10.1007/s11042-019-08520-1
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Tsai TH, 2020, MULTIMED TOOLS APPL, V79, P5989, DOI 10.1007/s11042-019-08274-w
   Wang H, 2020, MULTIMED TOOLS APPL, V79, P21177, DOI 10.1007/s11042-020-08950-2
   Wang LB, 2019, FUTURE GENER COMP SY, V100, P316, DOI 10.1016/j.future.2019.05.035
   Zhao Y, 2019, IEEE J BIOMED HEALTH, V23, P1363, DOI 10.1109/JBHI.2019.2891526
NR 29
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14503
EP 14515
DI 10.1007/s11042-022-12203-9
EA FEB 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300020
DA 2024-07-18
ER

PT J
AU Attia, A
   Mazaa, S
   Akhtar, Z
   Chahir, Y
AF Attia, Abdelouahab
   Mazaa, Sofiane
   Akhtar, Zahid
   Chahir, Youssef
TI Deep learning-driven palmprint and finger knuckle pattern-based
   multimodal Person recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Finger knuckle print; Palmprint; Score level fusion; PCANet deep
   learning; SVM multiclass
ID PRINT; FEATURES; PCANET
AB Biometric recognition systems are widely being used in several applications due to its distinctiveness and reliability. In recent years, hand-based person recognition has received much momentum due to its stability, feature richness, reliability and higher user acceptability. In this paper, we propose a multimodal hand biometric system based on Finger Knuckle Print (FKP) and Palmprint. In particular, the PCANet deep learning method is employed to extract distinctive features from each modality. Then, multiclass SVM is utilized to compute a matching score for each individual modality. Finally, score level fusion is performed to combine the matching scores via different rules such as, min, sum, max and multiplication. The performance of the proposed system is evaluated on the publicly available database known as PolyU. First, we conducted several experiments on single FKP and Palmprint traits. Next, score level fusion based multimodal experiments were performed. The proposed framework was able to achieve 0.00% of EER (equal error rates) and 100% of rank-1 performance. In addition, the proposed system based on PCANet with score level fusion of FKP and Palmprint outperformed existing multimodal methods.
C1 [Attia, Abdelouahab; Mazaa, Sofiane] Mohamed El Bachir El Ibrahimi Univ, MSE Lab, Bordj Bou Arreridj, Algeria.
   [Attia, Abdelouahab; Mazaa, Sofiane] Mohamed El Bachir El Ibrahimi Univ, Comp Sci Dept, Bordj Bou Arreridj, Algeria.
   [Akhtar, Zahid] State Univ New York Polytech Inst, Utica, NY USA.
   [Chahir, Youssef] Univ Caen, Image Team GREYC CNRS UMR, Caen, France.
C3 Universite de Caen Normandie
RP Attia, A (corresponding author), Mohamed El Bachir El Ibrahimi Univ, MSE Lab, Bordj Bou Arreridj, Algeria.; Attia, A (corresponding author), Mohamed El Bachir El Ibrahimi Univ, Comp Sci Dept, Bordj Bou Arreridj, Algeria.
EM attia.abdelouahab@gmail.com
RI ATTIA, Abdelouahab/HJA-2990-2022; Maza, Sofiane/ABF-1700-2021; ATTIA,
   Abdelouahab/ADD-8906-2022
OI Maza, Sofiane/0000-0002-5113-6907; ATTIA,
   Abdelouahab/0000-0003-1558-7273; Akhtar, Zahid/0000-0002-5026-5416
CR Akhtar Z, 2011, 2011 CARN C SEC TECH, P1, DOI DOI 10.1109/CCST.2011.6095935
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Attallah B., 2019, 2019 6th International Conference on Image and Signal Processing and their Applications (ISPA), P1
   Attia A, 2021, SIGNAL IMAGE VIDEO P, V15, P851, DOI 10.1007/s11760-020-01806-0
   Attia A, 2021, EVOL SYST-GER, V12, P1015, DOI 10.1007/s12530-020-09359-w
   Attia A, 2020, EVOL SYST-GER, V11, P625, DOI 10.1007/s12530-018-9260-x
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Bastanfard A, 2002, ITE TECHNICAL REPORT, P1
   Benmalek M., 2022, EVOL SYST, P1
   Bhattacharya S, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102589
   Chaa M, 2019, IET IMAGE PROCESS, V13, P736, DOI 10.1049/iet-ipr.2018.5642
   Chaa M, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013018
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chlaoua R, 2019, EVOL SYST-GER, V10, P261, DOI 10.1007/s12530-018-9227-y
   Connie T, 2003, P IM VIS COMP NEW ZE
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Database PolyUP Database, 2011, POLYUP
   Dehshibi MM, 2010, SIGNAL PROCESS, V90, P2431, DOI 10.1016/j.sigpro.2010.02.015
   Esther Rani P, 2014, INT J ADV RES COMPUT, V5
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jaswal G, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12523
   Jaswal G, 2017, LECT NOTES COMPUT SC, V10597, P233, DOI 10.1007/978-3-319-69900-4_30
   Jaswal G, 2017, MULTIMED TOOLS APPL, V76, P18955, DOI 10.1007/s11042-017-4475-6
   Jaswal G, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2938727
   Kant Chander, 2021, Innovations in Computational Intelligence and Computer Vision. Proceedings of ICICV 2020. Advances in Intelligent Systems and Computing (AISC 1189), P182, DOI 10.1007/978-981-15-6067-5_21
   Lakshmanan S, 2022, PATTERN ANAL APPL, V25, P395, DOI 10.1007/s10044-021-01047-y
   Meraoumia A, 2011, ANALOG INTEGR CIRC S, V69, P17, DOI 10.1007/s10470-011-9632-7
   Nigam A, 2015, NEUROCOMPUTING, V151, P1120, DOI 10.1016/j.neucom.2014.03.083
   OVEISI IS, 2015, INT C WORKSH COMP CO, P1
   PolyU, 2010, HONG KONG POL U POLY
   Usha K, 2016, J KING SAUD UNIV-COM, V28, P416, DOI 10.1016/j.jksuci.2015.02.004
   Usha K, 2016, ALEX ENG J, V55, P683, DOI 10.1016/j.aej.2015.10.003
   Vasan D, 2020, COMPUT NETW, V171, DOI 10.1016/j.comnet.2020.107138
   Veluchamy S, 2020, SENSOR REV, V40, P203, DOI 10.1108/SR-09-2017-0203
   Wang Xinshao, 2015, 2015 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA). Proceedings, P408, DOI 10.1109/APSIPA.2015.7415304
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang L, 2010, PATTERN RECOGN, V43, P2560, DOI 10.1016/j.patcog.2010.01.020
   Zhu LQ, 2010, PATTERN RECOGN LETT, V31, P1641, DOI 10.1016/j.patrec.2010.05.010
NR 42
TC 9
Z9 9
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10961
EP 10980
DI 10.1007/s11042-022-12384-3
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757168400008
DA 2024-07-18
ER

PT J
AU Li, CX
   Cohen, F
AF Li, Chenxi
   Cohen, Fernand
TI Virtual reconstruction of 3D articulated human shapes applied to garment
   try-on in a virtual fitting room
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Articulation; Anthropometric points; Moving parts; Affine transformation
AB We introduce an efficient and practical integrated system for human body model personalization with articulation. Starting with a 3D personalized model of the individual in a standard pose, the model is updated to accommodate for changes in articulations captured in a video clip with N frames. The personalized model is segmented into different parts using anthropometric control points on the silhouette boundary of the frontal projection of the 3D model. These are endpoints of segments in 2D corresponding to projections of regions of independently moving parts in 3D. These points can either be manually selected or predicted using a pre-trained convolutional neural network (NN) point model. Model evolution consists of finding a set of 3D transformations that are independently applied to parts on 3D model so that the projections of the 3D model 'match' those observed in the video sequence at corresponding frames. This is done by minimizing the error between the frontally projected body region points and the target region points in the image for each independent moving part. The average vertex error of our articulation recovery method yields sub-resolution recovery errors ((about 4.77 mm compared to 17.82 mm-the resolution cell of the body model). This is quite an improvement over the SMPL NN approach using the same error metric that yields 10 times the resolution cell. The virtually reconstructed articulated 3D model is fitted with a 3D garment model for the creation of virtual fitting room that allows an individual to virtually access how well the garment fits.
C1 [Li, Chenxi; Cohen, Fernand] Drexel Univ, Elect & Comp Engn, Philadelphia, PA 19104 USA.
C3 Drexel University
RP Li, CX (corresponding author), Drexel Univ, Elect & Comp Engn, Philadelphia, PA 19104 USA.
EM cl982@dragons.drexel.edu; fsc22@drexel.edu
OI Li, Chenxi/0000-0002-0963-4363
CR Alldieck T, 2018, PROC CVPR IEEE, P8387, DOI 10.1109/CVPR.2018.00875
   Amenta N., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P415, DOI 10.1145/280814.280947
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Anguelov D, 2012, RECOVERING ARTICULAT, DOI [10.5555/1036843.1036846, DOI 10.5555/1036843.1036846]
   Anguelov Dragomir., 2004, NIPS, P33
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Baumberg A., 1994, P EUR C COMP VIS STO, P297
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Cheung GKM, 2003, PROC CVPR IEEE, P77
   Choi H., 2020, COMPUTER VISION ECCV, P769
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Delamarre Q., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P716, DOI 10.1109/ICCV.1999.790292
   Freifeld O, 2010, PROC CVPR IEEE, P639, DOI 10.1109/CVPR.2010.5540154
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Hauswiesner S, 2013, IEEE T VIS COMPUT GR, V19, P1552, DOI 10.1109/TVCG.2013.67
   Hauswiesner Stefan, 2011, P 10 INT C VIRTUAL R, P23
   He ZL, 2017, IEEE INT CONF AUTOMA, P200, DOI 10.1109/FG.2017.33
   Jang C, 2008, P WORLD ACAD SCI ENG, P46
   Ju SX, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P38, DOI 10.1109/AFGR.1996.557241
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463
   Li C, 2020, IEEE Trans. Ind. Electron., V99, P1, DOI [10.1109/ACCESS.2020.2987078, DOI 10.1109/ACCESS.2020.2987078]
   Li JT, 2013, TEXT RES J, V83, P519, DOI 10.1177/0040517512450758
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Loop C, 1987, THESIS U UTAH
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Magnenat-Thalmann N, 2004, J COMPUT SCI TECH-CH, V19, P575, DOI 10.1007/BF02945583
   Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055
   Pishchulin L, 2017, PATTERN RECOGN, V67, P276, DOI 10.1016/j.patcog.2017.02.018
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Westoby MJ, 2012, GEOMORPHOLOGY, V179, P300, DOI 10.1016/j.geomorph.2012.08.021
   Xu Z, 2019, INT CONF 3D VISION, P298, DOI 10.1109/3DV.2019.00041
   Zhong YQ, 2009, TEXT RES J, V79, P792, DOI 10.1177/0040517508090779
NR 35
TC 5
Z9 5
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11071
EP 11085
DI 10.1007/s11042-021-11398-7
EA FEB 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757200200009
DA 2024-07-18
ER

PT J
AU Fatima, M
   Abbas, H
   Iqbal, W
   Shafqat, N
AF Fatima, Maheen
   Abbas, Haider
   Iqbal, Waseem
   Shafqat, Narmeen
TI Forensic analysis of image deletion applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secure deletion; Artifacts; NIST 800-88; Images; Android
AB With the increased use of smartphones over the years, an immense evolution in camera technology and image enhancement applications has been observed. However, this associates significantly greater security concerns with smartphones. Cyber crime offenders often retrieve personal images from second hand smart phones and try to blackmail or harass their former users. Similar situations are often faced by users in undesirable situations like hacking or theft of smartphones. Despite deletion of images by popular image deletion tools, sensitive images can still be recovered by using widely available forensic methods and tools. This paper checks the efficacy of top five image deletion applications namely Shreddit, Android Eraser, Permanent Delete, Sdelete, and Safe Delete in perspective of permanent deletion of images for Android, against National Institute of Standards and Technology's (NIST), Standard for Media Sanitization known as NIST 800-88. The efficiency of the aforementioned deletion applications has been analyzed by using famous image recovery forensic tools; XRY, Autopsy, and DiskDigger. The results of our forensic analysis recovered the deleted images which were ostensibly deleted by the chosen applications. Moreover, all the image locations have been identified in this research which were found to contain images' artifacts. In addition to that, the capability of forensic tools in recovering deleted images has been discussed too. So, this research highlights weaknesses of existing deletion mechanisms. Moreover, based on the conducted forensic analysis and NIST 800-88 standard, the research proposes a model for secure deletion by setting grounds for the development of a secure image deletion application to make permanent deletion of images possible.
C1 [Fatima, Maheen; Abbas, Haider; Iqbal, Waseem; Shafqat, Narmeen] Natl Univ Sci & Technol, Dept Informat Secur, Islamabad 46000, Pakistan.
C3 National University of Sciences & Technology - Pakistan
RP Iqbal, W (corresponding author), Natl Univ Sci & Technol, Dept Informat Secur, Islamabad 46000, Pakistan.
EM maheen.ncsael@mcs.edu.pk; haider@mcs.edu.pk; waseem.iqbal@mcs.edu.pk;
   narmeen_shafqat@mcs.edu.pk
RI Iqbal, Waseem/KCK-0502-2024; Iqbal, Waseem/X-1481-2019
OI Iqbal, Waseem/0000-0002-3616-2621
FU Higher Education Commission (HEC), Pakistan through its initiative of
   National Center for Cyber Security [2(1078)/HEC/ME/2018/707]
FX This research is supported by theT Higher Education Commission (HEC),
   Pakistan through its initiative of National Center for Cyber Security
   for the affiliated lab National Cyber Security Auditing and Evaluation
   Lab (NCSAEL), Grant No: 2(1078)/HEC/M&E/2018/707.
CR Albano P., 2011, 2011 International Conference on Broadband, Wireless Computing, Communication and Applications, P380, DOI 10.1109/BWCCA.2011.62
   [Anonymous], 2018, SMARTPHONE THEFT STA
   [Anonymous], 2013, SEC 12 P 21 USENIX C
   Azadegan S., 2012, 2012 45th Hawaii International Conference on System Sciences (HICSS), P5424, DOI 10.1109/HICSS.2012.452
   Glisson WB, 2013, DIGIT INVEST, V10, P44, DOI 10.1016/j.diin.2013.03.004
   Gutmann P, 1996, PROCEEDINGS OF THE SIXTH ANNUAL USENIX SECURITY SYMPOSIUM: FOCUSING ON APPLICATIONS OF CRYPTOGRAPHY, P77
   Joel R, 2012, P 7 S INF COMP COMM, DOI 10.1145/2414456.2414493
   JUNLIANG S, 2017, ACM T EMBED COMPUT S
   Kang SH, 2014, MULTIMED TOOLS APPL, V71, P643, DOI 10.1007/s11042-013-1603-9
   Lee J, 2010, J INF SCI ENG, V26, P27
   Nikolai J, 2006, STORAGESS 06 P 2 ACM, DOI 10.1145/1179559.1179571
   Richard K, 2014, THESIS NIST
   Roy NR, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P605, DOI 10.1109/CCAA.2016.7813792
   Steven S., 2010, SAFE FAST VERIFIABLE
   Subha S, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 4, P260, DOI 10.1109/ICCSIT.2009.5234575
   Yang L, 2018, COMPUT SECUR, V77, P612, DOI 10.1016/j.cose.2018.05.013
NR 16
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19559
EP 19586
DI 10.1007/s11042-021-11619-z
EA FEB 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000756332700001
DA 2024-07-18
ER

PT J
AU Gonegandla, P
   Kolekar, MH
AF Gonegandla, Pranesh
   Kolekar, Maheshkumar H.
TI Automatic song indexing by predicting listener's emotion using EEG
   correlates and multi-neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-neural network; Learning accuracy based weighting; Song indexing;
   Valence-arousal model; Emotion classification
AB Song indexing using emotions is an interesting area of research as it enables authentic analysis based on listener's emotions. In this work, we propose a multi-neural network architecture with learning accuracy based weights algorithm in order to classify the emotions of listener's based on self-rated valence, arousal and dominance values into three emotion categories. This classification data is then used in order to identify the major emotion induced by the song, which is then compared with the tags present on that particular song on the last.fm website. The training and testing data for the multi-neural network model is taken from the DEAP dataset and we obtained 85% accuracy in indexing the songs.
C1 [Gonegandla, Pranesh; Kolekar, Maheshkumar H.] Indian Inst Technol, Dept Elect Engn, Patna, Bihar, India.
C3 Indian Institute of Technology (IIT) - Patna; Indian Institute of
   Technology System (IIT System)
RP Kolekar, MH (corresponding author), Indian Inst Technol, Dept Elect Engn, Patna, Bihar, India.
EM pranesh.iitp@gmail.com; mahesh@iitp.ac.in
OI Kolekar, Maheshkumar/0000-0002-4272-3528
CR Aneja D, 2016, P 13 AS C COMP VIS
   Bhandari P, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P509, DOI 10.1109/SPIN.2018.8474199
   Choi K., 2017, ARXIV170309179, P141
   Gautam G, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P62
   Ghosal D, 2018, INTERSPEECH, P2087
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang HP, 2020, IEEE ACCESS, V8, P3265, DOI 10.1109/ACCESS.2019.2962085
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kolekar MH, 2015, IEEE T BROADCAST, V61, P195, DOI 10.1109/TBC.2015.2424011
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar JS, 2012, PROCEDIA ENGINEER, V38, P2525, DOI 10.1016/j.proeng.2012.06.298
   Liu W, 2016, LECT NOTES COMPUT SC, V9948, P521, DOI 10.1007/978-3-319-46672-9_58
   Liu YS, 2013, 2013 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P302, DOI 10.1109/CW.2013.52
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Tripathi S, 2017, AAAI CONF ARTIF INTE, P4746
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Varganova AV, 2015, 2015 INTERNATIONAL CONFERENCE ON MECHANICAL ENGINEERING, AUTOMATION AND CONTROL SYSTEMS (MEACS), DOI 10.1109/meacs.2015.7414907
   Xie Q, 2018, CHIN CONTR CONF, P5544, DOI 10.23919/ChiCC.2018.8483496
   Xu CS, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P429
NR 20
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27137
EP 27147
DI 10.1007/s11042-021-11879-9
EA FEB 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000756332700003
DA 2024-07-18
ER

PT J
AU Gupta, M
   Singh, VP
   Gupta, KK
   Shukla, PK
AF Gupta, Manish
   Singh, Vibhav Prakash
   Gupta, Kamlesh Kumar
   Shukla, Piyush Kumar
TI An efficient image encryption technique based on two-level security for
   internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Session key; Logistic map; Crossover; Image watermarking; DWT; Image
   encryption
ID SCHEME; CLOUD
AB This paper proposes an efficient image encryption method based on a hybrid of watermarking and cryptographic techniques. It is based on two-level security for the secure and error-free transmission of images between the IoT enabled devices. A discrete wavelet transform (DWT) based watermarking scheme is used at the first level, while at another level, an efficient image encryption technique based on a hybrid of logistic chaotic map and crossover is applied. In the DWT scheme, an encrypted secret image is used as a watermark image, where the secret image is encrypted via the lightweight cryptographic scheme. Here the hybrid of logistic chaotic map and crossover is used to produce random session keys for encryption of digital images. The use of DWT and 1-D logistic map along with crossover operation enhances the encryption effect compared to ordinary, chaotic encryption algorithms. The significance of this scheme is to improve security by using the hybrid concept. The strength of the proposed image encryption method is estimated by checking the proposed technique on various types of cryptographic attacks such as differential attack (NPCR), statistical attack (information entropy, histogram analysis, and correlation coefficient), noise attack, and prone to the secret user key. The higher value of NPCR (99.63) and information entropy (7.9973) are achieved, reflecting the effectiveness of this work.
C1 [Gupta, Manish; Shukla, Piyush Kumar] UIT RGPV, Dept Comp Sci & Engn, Bhopal, MP, India.
   [Singh, Vibhav Prakash] Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj 211004, India.
   [Gupta, Kamlesh Kumar] RJIT, Dept Informat Technol, Tekanpur, MP, India.
C3 Rajiv Gandhi Technological University; National Institute of Technology
   (NIT System); Motilal Nehru National Institute of Technology
RP Singh, VP (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj 211004, India.
EM manishgupta.2007@gmail.com; vibhav@mnnit.ac.in;
   kamlesh_rjitbsf@yahoo.co.in; pphdwss@gmail.com
RI user, user/GLQ-6797-2022; Shukla, Dr. Piyush Kumar/GVT-3949-2022; gupta,
   manish/HIK-2539-2022
OI Shukla, Dr. Piyush Kumar/0000-0002-3715-3882; Gupta, Dr.
   Manish/0000-0003-0848-6132; Singh, Dr. Vibhav
   Prakash/0000-0002-6823-2524
CR Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   Arpaci B, 2020, J ELECTR ENG TECHNOL, V15, P1413, DOI 10.1007/s42835-020-00393-x
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Cai ZQ, 2017, CLUSTER COMPUT, V20, P2415, DOI 10.1007/s10586-017-0796-5
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   Demir FB, 2020, NEURAL COMPUT APPL, V32, P14227, DOI 10.1007/s00521-020-04815-9
   Ding LN, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9081280
   Eisenbarth Thomas, 2012, Progress in Cryptology - AFRICACRYPT 2012. Proceedings 5th International Conference on Cryptology in Africa, P172, DOI 10.1007/978-3-642-31410-0_11
   Eisenbarth T, 2007, IEEE DES TEST COMPUT, V24, P522, DOI 10.1109/MDT.2007.178
   Gupta M, 2021, MULTIMED TOOLS APPL, V80, P10391, DOI 10.1007/s11042-020-10116-z
   Hameed S, 2019, J COMPUT NETW COMMUN, V2019, DOI 10.1155/2019/9629381
   Koo WK, 2008, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON INFORMATION SECURITY AND ASSURANCE, P73, DOI 10.1109/ISA.2008.53
   Kricha Z, 2018, ROBUST WATERMARKING
   Liu BL, 2016, FRONT COMPUT SCI-CHI, V10, P543, DOI 10.1007/s11704-015-4559-2
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P17669, DOI 10.1007/s11042-020-08645-8
   Mehta R, 2020, MULTIMED TOOLS APPL, V79, P18657, DOI 10.1007/s11042-020-08634-x
   Mohanarathinam A, 2020, J AMB INTEL HUM COMP, V11, P3221, DOI 10.1007/s12652-019-01500-1
   Mondal B, 2020, MULTIMED TOOLS APPL, V79, P17497, DOI 10.1007/s11042-019-08352-z
   Niu Y, 2020, MULTIMED TOOLS APPL, V79, P25613, DOI 10.1007/s11042-020-09237-2
   Peng SC, 2017, INFORM SCIENCES, V379, P146, DOI 10.1016/j.ins.2016.08.023
   Poettering B, 2013, RIJNDAELFURIOUS AES
   Rayachoti E, 2020, CLUSTER COMPUT, V23, P3175, DOI 10.1007/s10586-020-03078-2
   Salimi L, 2020, MULTIMED TOOLS APPL, V79, P11357, DOI 10.1007/s11042-019-08455-7
   Shen J, 2018, INFORM SCIENCES, V453, P186, DOI 10.1016/j.ins.2018.04.048
   Singh A, 2021, MOD RHEUMATOL, V31, P197, DOI [10.1080/14397595.2020.1724671, 10.1007/978-981-15-1781-5_1]
   Talhaoui MZ, 2021, J REAL-TIME IMAGE PR, V18, P85, DOI 10.1007/s11554-020-00948-1
   Tankard C, 2015, COMPUT FRAUD SECUR, P11
   Usman, 2017, ARXIV PREPRINT ARXIV
   Vidhya R, 2020, MULTIMED TOOLS APPL, V79, P30281, DOI 10.1007/s11042-020-09462-9
   Wang H, 2017, CLUSTER COMPUT, V20, P2385, DOI 10.1007/s10586-016-0701-7
   Wu DP, 2018, IEEE INTERNET THINGS, V5, P2958, DOI 10.1109/JIOT.2017.2768073
   Xiong JB, 2019, IEEE INTERNET THINGS, V6, P1530, DOI 10.1109/JIOT.2018.2842773
   You L, 2020, SOFT COMPUT, V24, P12413, DOI 10.1007/s00500-020-04683-4
   Zhang W, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21050504
   Zheng P., 2020, MULTIMED TOOLS APPL, V79, P1, DOI [10.1007/s11042-019-7523-6, DOI 10.1007/S11042-019-7523-6]
NR 35
TC 31
Z9 31
U1 3
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5091
EP 5111
DI 10.1007/s11042-022-12169-8
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000756332700033
DA 2024-07-18
ER

PT J
AU Li, ZY
   Shen, ZR
AF Li, Zhiyi
   Shen, Zhirui
TI Deep semantic mining of big multimedia data advertisements based on
   needs ontology construction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep semantic mining; Big multimedia data; Advertisements; Needs
   ontology; Construction
ID ARCHITECTURE
AB Constructing an ontology of human needs is to enable computers to perform deep semantic mining so that valuable information can be extracted from social media. Traditional intent recognition classification mainly uses regularization methods based on rules and template matching or machine learning based methods, which have the problems of high computational cost and poor generalization ability. In this paper, in order to improve user query intent recognition and analysis in e-commerce platform, we propose an intent recognition method based on ontology and matter mapping. We try to introduce the needs ontology combined with BERT-CRF model into semantic mining to solve the problem of inefficient accurate recommendation due to the lack of needs ontology support. From the intention classification of the given commodity type and the index of each model test, the results are good. We conducted extensive experiments using the GoodsKG corpus and obtained an accuracy improvement of 3.3% compared to the base model BERT. It also proved that the method has substantial application value and will also provide a good reference for large data analysis. Through ontology construction, the cutting-edge deep learning technology is combined with multimedia computing, and large-scale multimedia advertising data is deeply semantically mined, which enriches the knowledge discovery calculation methods of multimedia data and enhances the perception of multimedia data.
C1 [Li, Zhiyi] South China Normal Univ, Sch Econ & Management, Guangzhou 510006, Peoples R China.
   [Li, Zhiyi] Macau Univ Sci & Technol, Fac Informat Technol, Macau, Peoples R China.
   [Shen, Zhirui] Guangzhou Qizhi Informat Technol Co Ltd, Guangzhou 510006, Peoples R China.
C3 South China Normal University; Macau University of Science & Technology
RP Li, ZY (corresponding author), South China Normal Univ, Sch Econ & Management, Guangzhou 510006, Peoples R China.; Li, ZY (corresponding author), Macau Univ Sci & Technol, Fac Informat Technol, Macau, Peoples R China.
EM leeds@scnu.edu.cn
FU National Office for Philosophy and Social Sciences Project [17BTQ062]
FX This paper is supported by the National Office for Philosophy and Social
   Sciences Project (No. 17BTQ062) and it is a further extension of the
   patent --"A method and system for publishing text advertisements based
   on deep semantic mining" (patent No. ZL 201410075127X). Special thanks
   to Jinxiang Zeng, Xiaolin Li and Jiaying Luo for the successful
   completion of this paper. Thank you for your hard work and contribution
   to the publication of this paper.
CR Acar E, 2017, MULTIMED TOOLS APPL, V76, P11809, DOI 10.1007/s11042-016-3618-5
   [Anonymous], 2021, MODERN INTELL, DOI DOI 10.3969/J.ISSN.1008-0821.2021.01.003
   Balahur A, 2014, COMPUT SPEECH LANG, V28, P1, DOI 10.1016/j.csl.2013.09.003
   Briggs BD, 2018, U.S. patent, Patent No. [US20180247443A1, 20180247443]
   Chen DY, 2001, P SOC PHOTO-OPT INS, V4523, P338, DOI 10.1117/12.434329
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Chen xingyu, 2017, Journal of Shenzhen University Science and Engineering, V34, P173, DOI 10.3724/SP.J.1249.2017.02173
   Duran-Limon HA, 2015, IEEE T SOFTWARE ENG, V41, P1153, DOI 10.1109/TSE.2015.2449854
   Fu Bo, 2016, Journal of Software, V27, P2843, DOI 10.13328/j.cnki.jos.004870
   [顾小东 Gu Xiaodong], 2012, [计算机科学, Computer Science], V39, P8
   Hawalah A, 2019, BIG DATA COGN COMPUT, V3, DOI 10.3390/bdcc3040053
   Hong XB, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050852
   Huang Y., 2019, SCI TECH INNOV APPL, V5
   Jiang, 2017, THESIS NANJING U AER
   Kim Y., 2014, P 2014 C EMPIRICAL M
   Li, 2015, THESIS QIQIHAR U
   Li CX, 2012, THESIS U SCI TECHNOL
   [李峰 LI Feng], 2007, [中文信息学报, Journal of Chinese Information Processing], V21, P99
   Li XH, 2017, APPL MATH COMPUT, V310, P182, DOI 10.1016/j.amc.2017.03.031
   [刘丹丹 Liu Dandan], 2014, [中文信息学报, Journal of Chinese Information Processing], V28, P91
   Lopez-Lorca AA, 2016, INT J HUM-COMPUT ST, V87, P20, DOI 10.1016/j.ijhcs.2015.10.007
   Mao, 2015, THESIS SHANGHAI JIAO
   Mi G.W., 2021, MODERN INTELLIGENCE, V41, P108
   Miao H., 2020, J INF, V39, P134
   Mihalcea, 2004, P EMNLP, P401, DOI DOI 10.3115/1219044.1219064
   Peng, 2012, THESIS CHONGQING U
   Punyakanok V, 2008, COMPUT LINGUIST, V34, P257, DOI 10.1162/coli.2008.34.2.257
   Qi Chenxi, 2014, Telecommunications Science, V30, P15, DOI 10.3969/j.issn.1000-0801.2014.10.003
   Tang DY, 2016, IEEE T KNOWL DATA EN, V28, P496, DOI 10.1109/TKDE.2015.2489653
   [滕艳平 TENG Yan-ping], 2009, [情报科学, Information Science], V27, P1695
   Wang S., 2018, J. Huaqiao Univ. Nat. Sci, V39, P467
   [王思宇 Wang Siyu], 2020, [中文信息学报, Journal of Chinese Information Processing], V34, P104
   [王莹 Wang Ying], 2020, [计算机科学, Computer Science], V47, P56
   Wang YJ., 2015, ARCH SCI B, V6, P19
   Wang Z. Z., 2017, THESIS JILIN U
   [杨沁 Yang Qin], 2013, [工程设计学报, Constriction Engineering Design], V20, P97
   [尹绍宏 Yin Shaohong], 2013, [计算机科学, Computer Science], V40, P241
   Zadeh PDH, 2013, INFORM SCIENCES, V250, P21, DOI 10.1016/j.ins.2013.06.056
   Zhai Li-li, 2013, Computer Integrated Manufacturing Systems, V19, P173
   Zhang, 2015, COMP PROGR SKIL MAIN, V3, P54
   Zhang G.R., 2021, Information Science, V39, P53
   Zhang X., 2015, Character-level convolutional networks for text classification, P649
   Zhao MY, 2006, LECT NOTES COMPUT SC, V4043, P16
   Zhao ZD, 2013, SCI REP-UK, V3, DOI 10.1038/srep03472
   Zheng HT, 2012, INFORM SCIENCES, V216, P138, DOI 10.1016/j.ins.2012.06.012
   Zhou SS, 2013, NEUROCOMPUTING, V120, P536, DOI 10.1016/j.neucom.2013.04.017
NR 46
TC 0
Z9 0
U1 5
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28079
EP 28102
DI 10.1007/s11042-021-11892-y
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000755422300003
DA 2024-07-18
ER

PT J
AU Bhusal, A
   Alsadoon, A
   Prasad, PWC
   Alsalami, N
   Rashid, TA
AF Bhusal, Akriti
   Alsadoon, Abeer
   Prasad, P. W. C.
   Alsalami, Nada
   Rashid, Tarik A.
TI Deep learning for sleep stages classification: modified rectified linear
   unit activation function and modified orthogonal weight initialisation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Orthogonal CNN; Leaky rectified linear
   unit; Adam optimisation; Sleep stage classification
ID NEURAL-NETWORK
AB Each stage of sleep can affect human health, and not getting enough sleep at any stage may lead to sleep disorder like parasomnia, apnea, insomnia, etc. Sleep-related diseases could be diagnosed using Convolutional Neural Network Classifier. However, this classifier has not been successfully implemented into sleep stage classification systems due to high complexity and low accuracy of classification. The aim of this research is to increase the accuracy and reduce the learning time of Convolutional Neural Network Classifier. The proposed system used a modified Orthogonal Convolutional Neural Network and a modified Adam optimisation technique to improve the sleep stage classification accuracy and reduce the gradient saturation problem that occurs due to sigmoid activation function. The proposed system uses Leaky Rectified Linear Unit (ReLU) instead of sigmoid activation function as an activation function. The proposed system called Enhanced Sleep Stage Classification system (ESSC) used six different databases for training and testing the proposed model on the different sleep stages. These databases are University College Dublin database (UCD), Beth Israel Deaconess Medical Center MIT database (MIT-BIH), Sleep European Data Format (EDF), Sleep EDF Extended, Montreal Archive of Sleep Studies (MASS), and Sleep Heart Health Study (SHHS). Our results show that the gradient saturation problem does not exist anymore. The modified Adam optimiser helps to reduce the noise which in turn result in faster convergence time. The convergence speed of ESSC is increased along with better classification accuracy compared to the state of art solution.
C1 [Bhusal, Akriti; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Alsalami, Nada] Worcester State Univ, Comp Sci Dept, Worcester, MA USA.
   [Rashid, Tarik A.] Univ Kurdistan Hewler, Comp Sci & Engn, Erbil, Krg, Iraq.
C3 Charles Sturt University; Western Sydney University; Massachusetts
   System of Public Higher Education; Worcester State University;
   University of Kurdistan Hewler
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Rashid, Tarik A./HLX-0184-2023; Rashid, Tarik A./P-3473-2019; Alsadoon,
   A/Prof. Abeer/AAU-1532-2021
OI Rashid, Tarik A./0000-0002-8661-258X; Rashid, Tarik
   A./0000-0002-8661-258X; Alsadoon, A/Prof. Abeer/0000-0002-2309-3540;
   withana, chandana/0000-0002-3007-687X
CR [Anonymous], 2002, SLEEP EDF DATABASE
   Erdenebayar U, 2019, COMPUT METH PROG BIO, V180, DOI 10.1016/j.cmpb.2019.105001
   Fernandez-Blanco E, 2020, SOFT COMPUT, V24, P4067, DOI 10.1007/s00500-019-04174-1
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Phan H, 2019, IEEE T BIO-MED ENG, V66, P1285, DOI 10.1109/TBME.2018.2872652
   Kang CH, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1485-0
   Kemp B, 2000, IEEE T BIO-MED ENG, V47, P1185, DOI 10.1109/10.867928
   Liu D., 2017, PRACTICAL GUIDE RELU
   Mousavi Z, 2019, J NEUROSCI METH, V324, DOI 10.1016/j.jneumeth.2019.108312
   O'Reilly C, 2014, J SLEEP RES, V23, P628, DOI 10.1111/jsr.12169
   Serengil S.I., 2018, INSIDERS GUIDE ADAM
   Sors A, 2018, BIOMED SIGNAL PROCES, V42, P107, DOI 10.1016/j.bspc.2017.12.001
   Sun CL, 2019, IEEE ACCESS, V7, P109386, DOI 10.1109/ACCESS.2019.2933814
   Werth J, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101663
   Xu ZL, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00014
   Zhang JM, 2020, COMPUT METH PROG BIO, V183, DOI 10.1016/j.cmpb.2019.105089
   Zhang LD, 2019, SLEEP, V42, DOI 10.1093/sleep/zsz159
   Zhang XQ, 2020, SLEEP BREATH, V24, P581, DOI 10.1007/s11325-019-02008-w
NR 18
TC 3
Z9 3
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9855
EP 9874
DI 10.1007/s11042-022-12372-7
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gutub, AAA
AF Gutub, Adnan Abdul-Aziz
TI Adopting counting-based secret-sharing for e-Video Watermarking allowing
   Fractional Invalidation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Counting-based secret sharing; Digital-watermarking; Information
   security; Multimedia steganography; Video watermarking
ID DECOMPOSITION; CRYPTOGRAPHY
AB Watermarking is the process of embedding secret data to prove ownership copyright authentication validation. It is becoming urgently required within e-videos to provide proper permission confirmation. The problem raised in this research video watermarking to be addressed is to help providing ownership proof whenever slight tampering occurs on the video multimedia intentionally or unintentionally. Normally, any breach to e-video makes the watermarking hidden data injured, causing difficulty in accepting its copyright evidence. Therefore, this paper proposes utilizing counting-based secret sharing strategy to allow watermarking validation of ownership even if some fragments of the multimedia video-file is interfered. The study modeled the system and implemented it to be tested to explore the relation between security and authenticity in relation to data dependency, as in order to provide fractional authentication. It is giving the user full authority in accepting the incomplete video watermarking proof in a percentage-based analysis. The proposed work validity has been tested via many experimentations covered embedding watermarking data within 15 different size e-videos using different embedding LSB models showing interesting variational remarks. The analysis also involved standard media images for demonstrating the watermarking methods validity research providing enhancement effects to capacity (authentication) vs. security (ambiguity), as enforced unavoidable interesting tradeoff. The work uniqueness is presented in showing different multi-measures allowing the application decision maker to have full power to choose from. The research proved applicability to be adopting specific LSB approach as to give acceptable watermarking security enjoying the highest authentication with acceptable security. This watermarking adoption of counting-based secret sharing displayed interesting features, although the work is still in its early stage, providing promising investigations opportunities for innovative attractive progress coming.
C1 [Gutub, Adnan Abdul-Aziz] Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
C3 Umm Al Qura University
RP Gutub, AAA (corresponding author), Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
EM aagutub@uqu.edu.sa
RI Gutub, Adnan Abdul-Aziz/O-1240-2016
OI Gutub, Adnan Abdul-Aziz/0000-0003-0923-202X
CR Abu-Hashem M, 2022, CAAI T INTELL TECHNO, V7, P278, DOI 10.1049/cit2.12070
   Agilandeeswari L, 2016, MULTIMED TOOLS APPL, V75, P8745, DOI 10.1007/s11042-015-2789-9
   Al-Ghamdi M, 2019, MULTIMED TOOLS APPL, V78, P16283, DOI 10.1007/s11042-018-6977-2
   Al-Nofaie S, 2021, J KING SAUD UNIV-COM, V33, P963, DOI 10.1016/j.jksuci.2019.06.010
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Al-Roithy BO, 2021, MULTIMED TOOLS APPL, V80, P28521, DOI 10.1007/s11042-021-11051-3
   Al-Shaarani F, 2022, ARAB J SCI ENG, V47, P2455, DOI 10.1007/s13369-021-06165-7
   Alanazi N, 2021, ARAB J SCI ENG, V46, P8869, DOI 10.1007/s13369-021-05605-8
   AlKhodaidi T, 2021, MULTIMED TOOLS APPL, V80, P1143, DOI 10.1007/s11042-020-09720-w
   AlKhodaidi T, 2020, ARAB J SCI ENG, V45, P3403, DOI 10.1007/s13369-020-04422-9
   Almazrooie M, 2020, J KING SAUD UNIV-COM, V32, P24, DOI 10.1016/j.jksuci.2018.02.006
   Almehmadi E, 2022, ARAB J SCI ENG, V47, P2585, DOI 10.1007/s13369-021-06200-7
   Bin Hureib ES, 2020, INT J COMPUT SCI NET, V20, P1
   Deshmukh PR, 2014, INT J ENG RES APPL, V4, P44
   Faragallah OS, 2013, AEU-INT J ELECTRON C, V67, P189, DOI 10.1016/j.aeue.2012.07.010
   Gupta Hemant, 2013, INT J ENG RES DEV, V6, P32
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P48, DOI 10.4304/jetwi.2.1.48-55
   Gutub A, 2022, INT J INF SECUR PRIV, V16, DOI 10.4018/IJISP.2022010118
   Gutub A, 2022, PAMUKKALE U J ENG SC, V28, P324, DOI 10.5505/pajes.2021.54837
   Gutub A, 2020, J ENG RES-KUWAIT, V8, P91
   Gutub A, 2020, MULTIMED TOOLS APPL, V79, P17373, DOI 10.1007/s11042-020-08695-y
   Gutub A, 2020, ARAB J SCI ENG, V45, P2433, DOI 10.1007/s13369-019-04010-6
   Gutub A, 2020, MULTIMED TOOLS APPL, V79, P7951, DOI 10.1007/s11042-019-08427-x
   Gutub A, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0216-0
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub AAA, 2007, PROC WRLD ACAD SCI E, V21, P28
   Gutub AAA, 2007, SECRYPT 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON SECURITY AND CRYPTOGRAPHY, P329, DOI 10.5220/0002116903290332
   Gutub AAA, 2021, J KING SAUD UNIV-COM, V33, P1108, DOI 10.1016/j.jksuci.2019.06.014
   Hassan FS, 2022, CAAI T INTELL TECHNO, V7, P56, DOI 10.1049/cit2.12053
   Hassan FS, 2021, ARAB J SCI ENG, V46, P8441, DOI 10.1007/s13369-021-05529-3
   Jiang XM, 2013, MULTIMED TOOLS APPL, V62, P545, DOI 10.1007/s11042-011-0857-3
   Karmakar A, 2016, J KING SAUD UNIV-COM, V28, P199, DOI 10.1016/j.jksuci.2014.06.019
   Kheshaifaty N., 2021, J. Eng. Res., DOI [10.36909/jer.13761, DOI 10.36909/JER.13761]
   Kong WH, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P265
   Li S, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/3847092
   Popa Richard, THESIS POLITECHNICA
   Rasti P, 2016, J VIS COMMUN IMAGE R, V38, P838, DOI 10.1016/j.jvcir.2016.05.001
   Shambour MK, 2023, J ENG RES-KUWAIT, V11, P1, DOI 10.36909/jer.13199
   Shambour MK, 2022, ARAB J SCI ENG, V47, P1253, DOI 10.1007/s13369-021-05838-7
   Singh A, 2022, ARAB J SCI ENG, V47, P9801, DOI 10.1007/s13369-021-06348-2
   Singh K., 2014, INT J ENG RES APPL, V4, P105
   Singh TR, 2013, AEU-INT J ELECTRON C, V67, P645, DOI 10.1016/j.aeue.2013.01.008
   Swathi A., 2012, International Journal Of Computational Engineering Research (ijceronline.com), V2, P1620
   Tabassum T, 2012, INT CONF COMPUT INFO, P101, DOI 10.1109/ICCITechn.2012.6509780
   Venugopala P. S., 2020, International Journal of Computer Aided Engineering and Technology, V12, P55
   Youssef SM, 2014, MULTIMED TOOLS APPL, V73, P1545, DOI 10.1007/s11042-013-1515-8
NR 47
TC 18
Z9 18
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 FEB 9
PY 2022
DI 10.1007/s11042-022-12062-4
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YW2IG
UT WOS:000753241100006
DA 2024-07-18
ER

PT J
AU Jia, DY
   He, ZH
   Zhang, CAW
   Yin, WT
   Wu, NK
   Li, ZQ
AF Jia, Dongyao
   He, Zihao
   Zhang, Chuanwang
   Yin, Wanting
   Wu, Nengkai
   Li, Ziqi
TI Detection of cervical cancer cells in complex situation based on
   improved YOLOv3 network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE YOLOv3; Target detection; Complex situation
ID ACCURATE SEGMENTATION; CLASSIFICATION; CYTOLOGY; FEATURES
AB Cervical cancer is one of the major diseases that seriously threaten women's health. Cervical cancer automatic screening technology is of great significance to reduce the incidence of cervical cancer. However, the current method has shortcomings: low efficiency, low accuracy, and weak generalization ability, especially in complex situation. This paper innovatively applies the YOLO algorithm to the detection of abnormal cervical cells to ensure the rapidity and accuracy of the detection. For cellular classification of small targets, complex background and irregular shapes, we add the dense block and S3Pool algorithm on the basis of the feature extraction network Darknet-53 to improve the generalization ability of the model to cell features. The improved algorithm k-means++ is used to replace the clustering algorithm k-means in the original yolov3 to cluster the target frame of the cell data set, set reasonable anchors size, reconstruct the prediction scale creatively. Moreover, the Focal Loss and balanced cross entropy function are employed to improve the detection effect of the model against complex backgrounds, tight cell clusters, and uneven number of cell types. The NMS algorithm with linear attenuation is used to post-processing the model to improve the detection accuracy of cells in the occlusion situation. Experimental verification shows that the network achieved MAP of 78.87%, which is 8.02%, 8.22% and 4.83% higher than SSD (Single Shot Multi-Box Detector), YOLOv3(You Only Look Once) and ResNet50. The optimization method proposed in this paper improves the network sensitivity and the overall accuracy, especially in complex background. The research in this paper will have significance for the future design of an automatic cervical cancer diagnosis system.
C1 [Jia, Dongyao; He, Zihao; Zhang, Chuanwang; Yin, Wanting; Wu, Nengkai; Li, Ziqi] Beijing Jiao Tong Univ, Sch Elect & Informat Engn, 3 Shangyuan, Beijing 100044, Peoples R China.
RP Zhang, CAW (corresponding author), Beijing Jiao Tong Univ, Sch Elect & Informat Engn, 3 Shangyuan, Beijing 100044, Peoples R China.
EM cwzhang1995@qq.com
RI He, Zihao/HDN-7652-2022; li, ziqi/JDC-9141-2023
FU Beijing Jiaotong University [W19L00130]
FX This research is supported by the Beijing Jiaotong University
   (W19L00130).
CR Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Arya M, 2018, IET COMPUT VIS, V12, P1049, DOI 10.1049/iet-cvi.2018.5349
   Basheer S, 2019, J COMPUT THEOR NANOS, V16, P2523, DOI DOI 10.1166/JCTN.2019.7925
   Chankong T, 2014, COMPUT METH PROG BIO, V113, P539, DOI 10.1016/j.cmpb.2013.12.012
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Huang P, 2020, IEEE ACCESS, V8, P24219, DOI 10.1109/ACCESS.2020.2970121
   Iandola F., 2014, DenseNet: Implementing efficient convnet descriptor pyramids
   Iliyasu AM, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122935
   Jantzen J., 2005, Nature inspired Smart Information Systems (NiSIS 2005), P1
   Jia ADY, 2020, NEUROCOMPUTING, V411, P112, DOI 10.1016/j.neucom.2020.06.006
   Jia D, 2021, MULTIMED TOOLS APPL, P1
   Jia DY, 2020, IEEE ACCESS, V8, P64891, DOI 10.1109/ACCESS.2020.2984657
   Kido S, 2018, PROC INT WORKSH ADV
   Kuang L., 2016, Facial expression recognition method based on convolutional network integration
   Li KX, 2018, EUR J RADIOL, V106, P160, DOI 10.1016/j.ejrad.2018.07.024
   Li Y, 2021, RES PRODUCT QUALITY
   Lin HM, 2019, IEEE ACCESS, V7, P71541, DOI 10.1109/ACCESS.2019.2919390
   Lu JY, 2020, FUTURE GENER COMP SY, V106, P199, DOI 10.1016/j.future.2019.12.033
   Lu Z, 2017, IEEE J BIOMED HEALTH, V21, P441, DOI 10.1109/JBHI.2016.2519686
   Martin E, 2003, THESIS DTU
   Molnar C, 2016, SCI REP-UK, V6, DOI 10.1038/srep32412
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   NIE Y, 2019, 2019 IEEE MIL POWERT, P1, DOI DOI 10.1109/PTC.2019.8810948
   Nosrati MS, 2015, I S BIOMED IMAGING, P186, DOI 10.1109/ISBI.2015.7163846
   Plissiti ME, 2011, PATTERN RECOGN LETT, V32, P838, DOI 10.1016/j.patrec.2011.01.008
   Priyankaa J., 2021, Turkish J. Comp. Math. Edu., V12, P3050
   Prum S., 2018, 2018 4 INT C ADV COM, P1, DOI 10.1109/ICACCAF.2018.8776766
   Ragothaman S, 2016, IEEE COMPUT SOC CONF, P1374, DOI 10.1109/CVPRW.2016.173
   Ramesh N, 2019, IEEE J BIOMED HEALTH, V23, P1457, DOI 10.1109/JBHI.2018.2885544
   Rayavarapu K., 2018 International Conference on Current Trends towards Converging Technologies (ICCTCT), Coimbatore, P1, DOI DOI 10.1109/ICCTCT.2018.8551176
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Sompawong N, 2019, IEEE ENG MED BIO, P7044, DOI [10.1109/embc.2019.8856369, 10.1109/EMBC.2019.8856369]
   Song J, 2018, IEEE T IMAGE PROCESS, V27, P5759, DOI 10.1109/TIP.2018.2857001
   Song YY, 2017, IEEE T MED IMAGING, V36, P288, DOI 10.1109/TMI.2016.2606380
   Song YY, 2016, I S BIOMED IMAGING, P1159, DOI 10.1109/ISBI.2016.7493472
   Song YY, 2015, IEEE T BIO-MED ENG, V62, P2421, DOI 10.1109/TBME.2015.2430895
   Sun G., 2017, INT J PERFORMABILITY, V13, P446, DOI [10.23940/ijpe.17.04.p12.446457, DOI 10.23940/IJPE.17.04.P12.446457]
   Tareef A, 2017, NEUROCOMPUTING, V248, P28, DOI 10.1016/j.neucom.2017.01.093
   Tareef A, 2017, NEUROCOMPUTING, V221, P94, DOI 10.1016/j.neucom.2016.09.070
   Thohir Muhammad, 2020, 2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), P373, DOI 10.1109/ICAIIC48513.2020.9065027
   Wan T, 2019, NEUROCOMPUTING, V365, P157, DOI 10.1016/j.neucom.2019.06.086
   Wang P, 2019, BIOMED SIGNAL PROCES, V48, P93, DOI 10.1016/j.bspc.2018.09.008
   Wang X, 2018, IEEE ACCESS, V6, P51566, DOI 10.1109/ACCESS.2018.2865541
   William W, 2018, COMPUT METH PROG BIO, V164, P15, DOI 10.1016/j.cmpb.2018.05.034
   Xia MY, 2020, CHIN CONTR CONF, P6527, DOI [10.23919/CCC50068.2020.9188454, 10.23919/ccc50068.2020.9188454]
   Yang H, 2020, J CLIN MED, V9, DOI 10.3390/jcm9061839
   Zhang JW, 2016, PATTERN RECOGN, V60, P286, DOI 10.1016/j.patcog.2016.04.021
   Zhang L, 2017, IEEE J BIOMED HEALTH, V21, P1633, DOI 10.1109/JBHI.2017.2705583
   Zhang L, 2017, I S BIOMED IMAGING, P406, DOI 10.1109/ISBI.2017.7950548
   Zhang L, 2014, CYTOM PART A, V85, P214, DOI 10.1002/cyto.a.22407
   Zheng X, 2018, CHIN J LIQ CRYST DIS, V33, P965, DOI 10.3788/YJYXS20183311.0965
   Zhiqiang Z., 2019, ELECTROOPTICS CONTRO, V26, P32
NR 55
TC 22
Z9 24
U1 1
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8939
EP 8961
DI 10.1007/s11042-022-11954-9
EA FEB 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000753241100003
DA 2024-07-18
ER

PT J
AU Bedi, AK
   Sunkaria, RK
AF Bedi, Anterpreet Kaur
   Sunkaria, Ramesh Kumar
TI Statistical recursive minimum cross entropy for ultrasound image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ultrasound; Segmentation; Cross entropy; Histogram
ID LIVER; TEXTURE
AB Ultrasound imaging is one of the most widely used biomedical imaging modality for diagnostic purposes. Ultrasound image segmentation is an important step in order to achieve efficient qualitative measures, such as location of relevant structures, and quantitative measures, such as area of the structures for further analysis. However, segmentation of ultrasound images is considered a challenging task owing to its poor quality. Moreover, segmentation using global image statistics results in unsatisfactory results, making it difficult to use for further processing. In this study, we formulate a scheme to achieve successful segmentation of real time ultrasound images. The proposed method makes use of local statistics of the image in order to perform efficient segmentation. It considers histogram-based thresholding by making use of recursive minimum cross entropy on statistical properties (image integral and image gradient) derived from the instantaneous coefficient of variation images. To validate its excellence, results of the proposed method have been analysed by an expert and compared with some state-of-the-art methods. Results reveal that the proposed technique outperforms other techniques visually as well as quantitatively by an average of 13.67%. Thus, the technique is effective in segmenting ultrasound images efficiently by removing redundant information and leaving relevant information intact.
C1 [Bedi, Anterpreet Kaur; Sunkaria, Ramesh Kumar] Dr BR Ambedkar Natl Inst Technol, Dept Elect & Commun Engn, Jalandhar, Punjab, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Bedi, AK (corresponding author), Dr BR Ambedkar Natl Inst Technol, Dept Elect & Commun Engn, Jalandhar, Punjab, India.
EM anterpreetbedi27@gmail.com; sunkariark@gmail.com
OI Bedi, Anterpreet Kaur/0000-0001-6064-5925
CR Bedi AK, 2021, MULTIMED TOOLS APPL, V80, P20773, DOI 10.1007/s11042-021-10758-7
   Boukerroui D, 2016, LOCAL STAT MODELS UL
   Brink AD, 1996, PATTERN RECOGN, V29, P179, DOI 10.1016/0031-3203(95)00066-6
   BURCKHARDT CB, 1978, IEEE T SON ULTRASON, V25, P1, DOI 10.1109/T-SU.1978.30978
   Cerrolaza JJ, 2016, IEEE T MED IMAGING, V35, P2393, DOI 10.1109/TMI.2016.2572641
   Chen CM, 2002, ULTRASOUND MED BIOL, V28, P1061, DOI 10.1016/S0301-5629(02)00531-8
   Chen MF, 2013, IMAGING SCI J, V61, P579, DOI 10.1179/1743131X12Y.0000000028
   Hammouche K, 2008, COMPUT VIS IMAGE UND, V109, P163, DOI 10.1016/j.cviu.2007.09.001
   Hermawati FA, 2021, J KING SAUD UNIV-COM
   Horng MH, 2011, EXPERT SYST APPL, V38, P14805, DOI 10.1016/j.eswa.2011.05.069
   JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Kullback S., 1968, INFORM THEORY STAT
   Kumar S, 2013, MEMET COMPUT, V5, P323, DOI 10.1007/s12293-013-0123-5
   Kurban T, 2014, APPL SOFT COMPUT, V23, P128, DOI 10.1016/j.asoc.2014.05.037
   Lee WL, 2005, INFORM SCIENCES, V175, P177, DOI 10.1016/j.ins.2005.01.007
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Li G, 2020, TSINGHUA SCI TECHNOL, V25, P149, DOI 10.26599/TST.2019.9010026
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Martín-Fernández M, 2005, MED IMAGE ANAL, V9, P1, DOI 10.1016/j.media.2004.05.001
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Slabaugh G, 2009, ULTRASOUND MED BIOL, V35, P781, DOI 10.1016/j.ultrasmedbio.2008.10.014
   Smeets D, 2010, MED IMAGE ANAL, V14, P13, DOI 10.1016/j.media.2009.09.002
   Sree S. Jayanthi, 2021, Journal of Physics: Conference Series, V1916, DOI 10.1088/1742-6596/1916/1/012014
   Tan KS, 2011, PATTERN RECOGN, V44, P1, DOI 10.1016/j.patcog.2010.07.013
   Tang KZ, 2011, KNOWL-BASED SYST, V24, P1131, DOI 10.1016/j.knosys.2011.02.013
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Virmani J, 2013, J DIGIT IMAGING, V26, P530, DOI 10.1007/s10278-012-9537-8
   Xiao GF, 2002, IEEE T MED IMAGING, V21, P48, DOI 10.1109/42.981233
   Xie J, 2005, IEEE T MED IMAGING, V24, P45, DOI 10.1109/TMI.2004.837792
   Yang W, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229651
   Yin PY, 2007, APPL MATH COMPUT, V184, P503, DOI 10.1016/j.amc.2006.06.057
   Yoshida H, 1998, ULTRASON, P1713, DOI 10.1109/ULTSYM.1998.765279
   Yu YJ, 2004, IEEE T IMAGE PROCESS, V13, P1640, DOI 10.1109/TIP.2004.836166
   Yüksel ME, 2009, IEEE T FUZZY SYST, V17, P976, DOI 10.1109/TFUZZ.2009.2018300
   Zheng XL, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19050191
   Zhou SP, 2017, NEUROCOMPUTING, V234, P216, DOI 10.1016/j.neucom.2017.01.013
   Zimmer Y, 1996, ULTRASOUND MED BIOL, V22, P1183, DOI 10.1016/S0301-5629(96)00167-6
   Zong JJ, 2019, COMPUT MATH APPL, V78, P929, DOI 10.1016/j.camwa.2019.03.022
NR 42
TC 1
Z9 1
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7873
EP 7893
DI 10.1007/s11042-022-12050-8
EA JAN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749232600004
DA 2024-07-18
ER

PT J
AU Luna, E
   SanMiguel, JC
   Martínez, JM
   Escudero-Viñolo, M
AF Luna, Elena
   SanMiguel, Juan C.
   Martinez, Jose M.
   Escudero-Vinolo, Marcos
TI Online clustering-based multi-camera vehicle tracking in scenarios with
   overlapping FOVs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-camera tracking; Multi-target tracking; Online tracking
ID MULTITARGET
AB Multi-Target Multi-Camera (MTMC) vehicle tracking is an essential task of visual traffic monitoring, one of the main research fields of Intelligent Transportation Systems. Several offline approaches have been proposed to address this task; however, they are not compatible with real-world applications due to their high latency and post-processing requirements. This lack of suitable approaches motivates our proposal: A new low-latency online approach for MTMC tracking in scenarios with partially overlapping fields of view (FOVs), such as road intersections. Firstly, the proposed approach detects vehicles at each camera. Then, the detections are merged between cameras by applying cross-camera clustering based on appearance and location. Lastly, the clusters containing different detections of the same vehicle are temporally associated to compute the tracks on a frame-by-frame basis. The experiments show promising low-latency results while addressing real-world challenges such as the a priori unknown and time-varying number of targets and the continuous state estimation of them without performing any post-processing of the trajectories.
C1 [Luna, Elena; SanMiguel, Juan C.; Martinez, Jose M.; Escudero-Vinolo, Marcos] Univ Autonoma Madrid, Escuela Politecn Super Madrid, Madrid, Spain.
C3 Autonomous University of Madrid
RP Luna, E (corresponding author), Univ Autonoma Madrid, Escuela Politecn Super Madrid, Madrid, Spain.
EM elena.luna@uam.es; juancarlos.sanmiguel@uam.es; josem.martinez@uam.es;
   marcos.escudero@uam.es
RI Martinez, Jose M./A-1185-2008; Sanmiguel, Juan/GQH-1613-2022; San
   Miguel, Juan Carlos/E-8644-2010; Escudero-Vinolo, Marcos/C-3601-2014
OI San Miguel, Juan Carlos/0000-0002-4999-2851; Escudero-Vinolo,
   Marcos/0000-0002-9156-3428; Luna, Elena/0000-0002-7961-2848
FU CRUE-CSIC agreement; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Chang Ming-Fang, 2019, CVPR
   Chen L, 2020, PROC CVPR IEEE, P3276, DOI 10.1109/CVPR42600.2020.00334
   Chen LT, 2020, MULTIMED TOOLS APPL, V79, P35333, DOI 10.1007/s11042-019-07747-2
   Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530
   Ciaparrone G, 2020, NEUROCOMPUTING, V381, P61, DOI 10.1016/j.neucom.2019.11.023
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guerrero-Ibáñez J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041212
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2019, PROC CVPR IEEE, P4335, DOI 10.1109/CVPR.2019.00447
   He YH, 2020, IEEE T IMAGE PROCESS, V29, P5191, DOI 10.1109/TIP.2020.2980070
   He ZZ, 2019, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2019.00068
   Hou Yunzhong, 2019, P IEEE CVF C COMP VI, P167
   Hsu H.M., 2019, P CVPR WORKSH LONG B, P416
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kaufman L., 2009, FINDING GROUPS DATA
   Kriegel H.-P., 1996, KNOWLEDGE DISCOVERY, P226, DOI DOI 10.5555/3001460
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Leal-Taixe L., 2017, Tracking the trackers: an analysis of the state of the art in multiple object tracking
   Li Peiliang, 2019, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
   Liem MC, 2014, COMPUT VIS IMAGE UND, V128, P36, DOI 10.1016/j.cviu.2014.06.003
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luna E, 2019, P IEEE CVF C COMP VI
   Menouar H, 2017, IEEE COMMUN MAG, V55, P22, DOI 10.1109/MCOM.2017.1600238CM
   Oksuz K, 2021, IEEE T PATTERN ANAL, V43, P3388, DOI 10.1109/TPAMI.2020.2981890
   Peng JJ, 2019, IEEE INT CONF MULTI, P453, DOI 10.1109/ICMEW.2019.00084
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shen YT, 2017, IEEE I CONF COMP VIS, P1918, DOI 10.1109/ICCV.2017.210
   Shirazi MS, 2017, IEEE T INTELL TRANSP, V18, P4, DOI 10.1109/TITS.2016.2568920
   Sio C. H., 2019, P ACM MULT AS, P1
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tan X., 2019, P IEEE C COMP VIS PA, P275
   Tang Z, 2019, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2019.00900
   Tang Z, 2018, IEEE COMPUT SOC CONF, P108, DOI 10.1109/CVPRW.2018.00022
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Veres M, 2020, IEEE T INTELL TRANSP, V21, P3152, DOI 10.1109/TITS.2019.2929020
   Yang Z, 2018, IMAGE VISION COMPUT, V69, P143, DOI 10.1016/j.imavis.2017.09.008
   Zhang Y, 2019, IEEE SYS MAN CYBERN, P1, DOI [10.1109/SMC.2019.8914524, 10.1109/ipcon.2019.8908272]
   Zhang Z, 2017, ARXIV171209531
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zhipeng, 2020, J SHANGHAI JIAOTONG, P2
NR 49
TC 5
Z9 5
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7063
EP 7083
DI 10.1007/s11042-022-11923-2
EA JAN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000746354000004
OA hybrid
DA 2024-07-18
ER

PT J
AU Mijwil, MM
   Aggarwal, K
AF Mijwil, Maad M.
   Aggarwal, Karan
TI A diagnostic testing for people with appendicitis using machine learning
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acute appendicitis; Data mining; Machine learning; Appendicitis surgery;
   Specimens
ID MORTALITY
AB Appendicitis is a common disease that occurs particularly often in childhood and adolescence. The accurate diagnosis of acute appendicitis is the most significant precaution to avoid severe unnecessary surgery. In this paper, the author presents a machine learning (ML) technique to predict appendix illness whether it is acute or subacute, especially between 10 and 30 years and whether it requires an operation or just taking medication for treatment. The dataset has been collected from public hospital-based citizens between 2016 and 2019. The predictive results of the models achieved by different ML techniques (Logistic Regression, Naive Bayes, Generalized Linear, Decision Tree, Support Vector Machine, Gradient Boosted Tree, Random Forest) are compared. The covered dataset are 625 specimens and the total of the medical records that are applied in this paper include 371 males (60.22%) and 254 females (40.12%). According to the dataset, the records consist of 318 (50.88%) operated and 307 (49.12%) unoperated patients. It is observed that the random forest algorithm obtains the optimal result with an accurately predicted result of 83.75%, precision of 84.11%, sensitivity of 81.08%, and the specificity of 81.01%. Moreover, an estimation method based on ML techniques is improved and enhanced to detect individuals with acute appendicitis.
C1 [Mijwil, Maad M.] Baghdad Coll Econ Sci Univ, Comp Tech Engn Dept, Baghdad, Iraq.
   [Aggarwal, Karan] Maharishi Markandeshwar Univ, Elect & Commun Engn Dept, Ambala, India.
C3 Baghdad College of Economic Science University; Maharishi Markandeshwar
   University
RP Mijwil, MM (corresponding author), Baghdad Coll Econ Sci Univ, Comp Tech Engn Dept, Baghdad, Iraq.
EM mr.maad.alnaimiy@baghdadcollege.edu.iq; karan.170987@gmail.com
RI Mijwil, Maad M./M-8031-2019; Aggarwal, Karan Kumar/AAR-5617-2020
OI Mijwil, Maad M./0000-0002-2884-2504; Aggarwal, Karan
   Kumar/0000-0002-9038-0099
CR Aggarwal K, 2019, EURASIP J IMAGE VIDE, V2019, DOI 10.1186/s13640-019-0482-z
   Ahuja AS, 2019, PEERJ, V7, DOI 10.7717/peerj.7702
   Akmese OF, 2020, EMERG MED INT, V2020, DOI 10.1155/2020/7306435
   Al-Najafy, 2018, ANN COLL MED MOSUL, V40, P56, DOI [10.33899/mmed.2018.159189, DOI 10.33899/MMED.2018.159189]
   Ali J., 2012, International Journal of Computer Science Issues (IJCSI), V9, P272
   Almaramhy HH, 2017, ITAL J PEDIATR, V43, DOI 10.1186/s13052-017-0335-2
   ALVARADO A, 1986, ANN EMERG MED, V15, P557, DOI 10.1016/S0196-0644(86)80993-3
   Amisha, 2019, J FAM MED PRIM CARE, V8, P2328, DOI 10.4103/jfmpc.jfmpc_440_19
   [Anonymous], 2018, Microscopy science: last approaches on educational programs and applied research (Microscopy Book Series, 8)
   Biau G, 2012, J MACH LEARN RES, V13, P1063
   Chandrashekara S., 2014, IJRCI, V2, pSR3, DOI [DOI 10.15305/IJRCI/V2IS1/117, 10.15305/ijrci/v2iS1/117]
   CHAPMAN P, CRISP DM 1 0 STEP BY
   Chen W, 2015, CANCER EPIDEM BIOMAR, V24, P386, DOI 10.1158/1055-9965.EPI-14-1038
   Ciepiela O, 2015, ANN HEMATOL, V94, P1277, DOI 10.1007/s00277-015-2377-0
   Cioffi R, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12020492
   Conley C.L, BLOOD BIOCH ARTICLE
   Das K., 2017, Int. J. Innov. Res. Comput. Commun. Eng., V5, P1301, DOI [10.15680/IJIRCCE.2017.0502001, DOI 10.15680/IJIRCCE.2017.0502001]
   Davenport Thomas, 2019, Future Healthc J, V6, P94, DOI 10.7861/futurehosp.6-2-94
   Dogan Onur., 2015, European Journal of Business Economics, V10, P16, DOI DOI 10.12955/EJBE.V10I2.682
   Doig K, 2017, CLIN LAB SCI, V30, P186
   Golwala ZM, 2016, AFR HEALTH SCI, V16, P356, DOI 10.4314/ahs.v16i2.3
   Guada C, 2016, INT J COMPUT INT SYS, V9, P43, DOI 10.1080/18756891.2016.1180819
   Hirsch L., KIDS HLTH WEBSITE
   Huang N, 2016, J HEMATOL ONCOL, V9, DOI 10.1186/s13045-016-0358-y
   Ishikawa, 2001, J JAPAN MED ASS, V127, P747
   Jaffe T, 2015, RADIOLOGY, V275, P650, DOI 10.1148/radiol.2015140916
   Kesieme E, 2011, J BLOOD MED, V2, P59, DOI 10.2147/JBM.S19009
   Kishimoto S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-68319-1
   Koenhemsi L, 2019, Medical Science and Discovery, V6, P24, DOI [10.17546/msd.522081, DOI 10.17546/MSD.522081]
   Leventhal B., 2010, Journal of Direct, Data and Digital Marketing Practice, V12, P137, DOI DOI 10.1057/DDDMP.2010.35
   Levin MD., 2019, GASTROENTEROLOGY HEP, V10, P279, DOI DOI 10.15406/GHOA.2019.10.00396
   Lurii B., 2018, MOLDOVAN MED J, V61, P29
   Marcinkevics R, 2021, FRONT PEDIATR, V9, DOI 10.3389/fped.2021.662183
   Marengo-Rowe Alain J, 2006, Proc (Bayl Univ Med Cent), V19, P239
   Marzuillo Pierluigi, 2015, World J Clin Pediatr, V4, P19, DOI 10.5409/wjcp.v4.i2.19
   Mendelson A, 2014, NAT MED, V20, P833, DOI 10.1038/nm.3647
   Mijwil M.M., 2021, Asian J. Appl. Sci, V9, P87, DOI [10.24203/ajas.v9i2.6589, DOI 10.24203/AJAS.V9I2.6589]
   Mijwil MM, 2021, MULTIMED TOOLS APPL, V80, P26255, DOI 10.1007/s11042-021-10952-7
   Mijwil MM, 2021, Iraqi J. Sci., P2099, DOI 10.24996/ijs.2021.62.6.35
   Mohmmed AGM., 2016, AM J ENG RES AJER, V5, P9
   Monsalve-Torra A, 2016, J BIOMED INFORM, V62, P195, DOI 10.1016/j.jbi.2016.07.007
   Mostbeck G, 2016, INSIGHTS IMAGING, V7, P255, DOI 10.1007/s13244-016-0469-6
   Necas Martin, 2018, Australas J Ultrasound Med, V21, P9, DOI 10.1002/ajum.12075
   Orakpoghenor O., 2019, Sci. J. Immunol. Immunotherapy, V3, P4
   Park SY, 2013, Future Information Technology: FutureTech, P85, DOI [10.1007/978-3-642-40861-8_13, DOI 10.1007/978-3-642-40861-8_13]
   Rashid MI, 2016, MICROBIOL RES, V183, P26, DOI 10.1016/j.micres.2015.11.007
   Reismann J, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222030
   Rosales C, 2017, J IMMUNOL RES, V2017, DOI 10.1155/2017/9748345
   Sathiyakumarir K., 2017, INT J COMP APPLICAT, V163, P8, DOI [10.5120/ijca2017913480, DOI 10.5120/IJCA2017913480]
   Schwartz KL, 2011, J PEDIATR SURG, V46, P2060, DOI 10.1016/j.jpedsurg.2011.07.018
   Sidey-Gibbons JAM, 2019, BMC MED RES METHODOL, V19, DOI 10.1186/s12874-019-0681-4
   Souza Sandro Cilindro de, 2015, J. Coloproctol. (Rio J.), V35, P212, DOI 10.1016/j.jcol.2015.08.003
   Stewart-Parker Emma Patricia, 2016, BMJ Case Rep, V2016, DOI 10.1136/bcr-2016-216150
   Stoppler MCC, APPENDICITIS SYMPTOM
NR 54
TC 14
Z9 14
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7011
EP 7023
DI 10.1007/s11042-022-11939-8
EA JAN 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000746354000006
PM 35095329
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Arroyo, R
   Alvarez, S
   Aller, A
   Bergasa, LM
   Ortiz, ME
AF Arroyo, Roberto
   Alvarez, Sergio
   Aller, Aitor
   Bergasa, Luis M.
   Ortiz, Miguel E.
TI Fine-tuning your answers: a bag of tricks for improving VQA models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Natural language processing; Knowledge representation &
   reasoning; Visual question answering; Artificial intelligence
AB In this paper, one of the most novel topics in Deep Learning (DL) is explored: Visual Question Answering (VQA). This research area uses three of the most important fields in Artificial Intelligence (AI) to automatically provide natural language answers for questions that a user can ask about an image. These fields are: 1) Computer Vision (CV), 2) Natural Language Processing (NLP) and 3) Knowledge Representation & Reasoning (KR&R). Initially, a review of the state of art in VQA and our contributions to it are discussed. Then, we build upon the ideas provided by Pythia, which is one of the most outstanding approaches. Therefore, a study of the Pythia's architecture is carried out with the aim of presenting varied enhancements with respect to the original proposal in order to fine-tune models using a bag of tricks. Several training strategies are compared to increase the global accuracy and understand the limitations associated with VQA models. Extended results check the impact of the different tricks over our enhanced architecture, jointly with additional qualitative results.
C1 [Arroyo, Roberto; Alvarez, Sergio; Aller, Aitor] NielsenIQ, Madrid, Spain.
   [Bergasa, Luis M.; Ortiz, Miguel E.] Univ Alcala UAH, Elect Dept, Madrid, Spain.
C3 Universidad de Alcala
RP Arroyo, R (corresponding author), NielsenIQ, Madrid, Spain.
EM roberto.arroyo@nielseniq.com; sergio.alvarezpardo@nielseniq.com;
   aitor.allerbeascoechea@nielseniq.com; luism.bergasa@uah.es;
   eduardo.ortiz@edu.uah.es
RI Bergasa, Luis M./H-9810-2013
OI Bergasa, Luis M./0000-0002-0087-3077; Arroyo,
   Roberto/0000-0003-2649-0477; Ortiz Huamani, Miguel
   Eduardo/0000-0002-5814-2058
FU Spanish MICINN/FEDER [RTI2018-099263-B-C21]; RoboCity2030-DIH-CM project
   - Programas de actividades I+D (CAM) [P2018/NMT-4331]; EU Structural
   Funds; NielsenIQ
FX Authors want to thank to NielsenIQ for its funding in the development of
   this project. This work has been also funded in part from the Spanish
   MICINN/FEDER through the Techs4AgeCar project (RTI2018-099263-B-C21) and
   from the RoboCity2030-DIH-CM project (P2018/NMT-4331), funded by
   Programas de actividades I+D (CAM) and cofunded by EU Structural Funds.
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiang Y., 2018, arXiv
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
   Kervadec C, 2021, PROC CVPR IEEE, P4205, DOI 10.1109/CVPR46437.2021.00419
   Kervadec C, 2021, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR46437.2021.00280
   Kingma D. P., 2014, arXiv
   Liang JW, 2018, PROC CVPR IEEE, P6135, DOI 10.1109/CVPR.2018.00642
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Malinowski M, 2014, ADV NEUR IN, V27
   Ortiz ME, 2020, WORKSH PHYS AG WAF, P256
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Singh A, 2019, PROC CVPR IEEE, P8309, DOI 10.1109/CVPR.2019.00851
   Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444
   Wu CF, 2019, AAAI CONF ARTIF INTE, P8997
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yi KX, 2018, ADV NEUR IN, V31
   Yuan YY, 2021, PROC CVPR IEEE, P16903, DOI 10.1109/CVPR46437.2021.01663
   Zhang MD, 2021, PROC CVPR IEEE, P7042, DOI 10.1109/CVPR46437.2021.00697
NR 21
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26889
EP 26913
DI 10.1007/s11042-021-11546-z
EA JAN 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000740429700027
DA 2024-07-18
ER

PT J
AU Lin, ZR
   Li, JD
   Yao, QP
   Shen, HC
   Wan, LH
AF Lin, Zhenrong
   Li, Jidong
   Yao, Qipeng
   Shen, Haocheng
   Wan, Lihang
TI Adversarial learning with data selection for cross-domain
   histopathological breast Cancer segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer segmentation; Domain adaptation; Pseudo label
ID IMAGE SEGMENTATION; CLASSIFICATION; SYSTEM; MODEL
AB Histopathology plays an important role in the clinical diagnosis of breast diseases. Early diagnosis and adjuvant therapy are of great help to patients. With the development of deep learning, fully convolutional networks (FCNs) have achieved remarkable results in the field of segmentation. However, this approach suffers from obtaining sufficient labelled data and underperforms when it comes to a new domain. Recently, adversarial learning becomes prevalent in domain adaptation, which is able to transfer learned knowledge between domains and greatly reduces the workload of labeling. In this paper, we propose a new domain adaptation method, which consists of three steps: adversarial learning, data selection and pseudo-label model refinement. Our method combines the advantages of adversarial learning and pseudo-labelling for domain adaptation. We also introduce a new data selection method to select target domain data with their pseudo-label for model refinement, considering prediction confidence and representativeness, which further strengths the model capability in target domain. We evaluate our method on private HE- and IHC-stained datasets. In order to strength the robustness, the color augmentation is utilized in this paper, the cross-domain prediction performance has been improved from 0.213 Dice to 0.703 Dice. The experimental results show that with only using unlabeled data, the proposed method can achieve 0.846 Dice on target domain, which outperforms the state-of-the-art method by 1.8%.
C1 [Lin, Zhenrong; Li, Jidong; Yao, Qipeng; Wan, Lihang] Nanchang Univ, Sch Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Shen, Haocheng] Tencent, AI Lab, Shenzhen 518000, Peoples R China.
C3 Nanchang University; Tencent
RP Yao, QP (corresponding author), Nanchang Univ, Sch Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM qpyao@ncu.edu.cn
FU National Natural Science Foundation of China [62066027]
FX This research was funded by National Natural Science Foundation of
   China, grant number 62066027.
CR Achanta SDM, 2019, INT J INTELL UNMANNE, V8, P43, DOI 10.1108/IJIUS-01-2019-0005
   Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   Bayramoglu N, 2016, INT C PATT RECOG, P2440, DOI 10.1109/ICPR.2016.7900002
   Beeravolu AR, 2021, IEEE ACCESS, V9, P33438, DOI 10.1109/ACCESS.2021.3058773
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Buslaev A, 2020, INFORMATION, V11, DOI 10.3390/info11020125
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Chen H, ARXIV180410916
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Courty N, 2017, IEEE T PATTERN ANAL, V39, P1853, DOI 10.1109/TPAMI.2016.2615921
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Feige U, 1998, J ACM, V45, P634, DOI 10.1145/285055.285059
   Foran DJ, 2009, I S BIOMED IMAGING, P1306, DOI 10.1109/ISBI.2009.5193304
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Haocheng Shen, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12265), P509, DOI 10.1007/978-3-030-59722-1_49
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kamnitsas K, 2017, LECT NOTES COMPUT SC, V10265, P597, DOI 10.1007/978-3-319-59050-9_47
   Khaki S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092721
   Kien Nguyen, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1497, DOI 10.1109/ICPR.2010.370
   Kong H, 2011, IEEE T MED IMAGING, V30, P1661, DOI 10.1109/TMI.2011.2141674
   Kong J, 2007, I S BIOMED IMAGING, P61, DOI 10.1109/ISBI.2007.356788
   Lahoura V, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11020241
   Lee D.-H., 2013, WORKSHOP CHALLENGES, V3, P896
   Leng L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092644
   Lin Yang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P399, DOI 10.1007/978-3-319-66179-7_46
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Long M., 2016, Advances in neural information processing systems, V29
   Malebary SJ, 2021, IEEE ACCESS, V9, P55312, DOI 10.1109/ACCESS.2021.3071297
   Nagao T, 2012, ACTA HISTOCHEM CYTOC, V45, P269, DOI 10.1267/ahc.12019
   Qu AP, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-014-5277-3
   Roccetti M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00428-8
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruiz A, 2008, I S BIOMED IMAGING, P296, DOI 10.1109/ISBI.2008.4540991
   Saber A, 2021, IEEE ACCESS, V9, P71194, DOI 10.1109/ACCESS.2021.3079204
   Shen RB, 2019, FUTURE GENER COMP SY, V101, P668, DOI 10.1016/j.future.2019.07.013
   Somasundaram A, 2016, PROC 1 INT C RES ENG, P1
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Sun YM, 2009, INT J PATTERN RECOGN, V23, P687, DOI 10.1142/S0218001409007326
   Taher F, 2015, ALGORITHMS, V8, P1088, DOI 10.3390/a8041088
   Taher F, 2013, ALGORITHMS, V6, DOI 10.3390/a6030512
   Tahmoush D, 2009, ALGORITHMS, V2, P1503, DOI 10.3390/a2041503
   Theriot CM, 2019, J CLIN INVEST, V129, P3539, DOI 10.1172/JCI130008
   Tsai YH, 2018, PROC CVPR IEEE, P7472, DOI 10.1109/CVPR.2018.00780
   Vu TH, 2019, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2019.00262
   Tzeng E., 2014, ARXIV14123474
   van Opbroek A, 2019, IEEE T MED IMAGING, V38, P213, DOI 10.1109/TMI.2018.2859478
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Vununu C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092717
   Wilkowski A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092689
   Yang ZY, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121464
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng YF, 2010, ALGORITHMS, V3, P44, DOI 10.3390/a3010044
NR 54
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5989
EP 6008
DI 10.1007/s11042-021-11814-y
EA JAN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000738438500002
DA 2024-07-18
ER

PT J
AU Ji, CF
   Liu, GZ
   Zhao, D
AF Ji, Chaofeng
   Liu, Guizhong
   Zhao, Dan
TI Monocular 3D object detection via estimation of paired keypoints for
   autonomous driving
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D Object Detection; Deep Learning; Keypoint Detection; Instance Point
   Cloud
AB 3D objection detection is a key task in autonomous driving. Because 3D structure information is lost during perspective projection, 3D localization of an object from monocular images is challenging. We herein present a monocular 3D object detection method that formulates the 3D object localization as a paired keypoints regression problem. Our method exploits 2D bounding box priors to predict the projection of paired 3D keypoints on the image plane for each object, and the object localization is recovered via an inverse projection. A fast keypoint regression network is proposed to predict the projection of keypoints and to generate the initial 3D bounding box. Furthermore, to obtain more accurate 3D detection results, we leverage a light-weight cascaded refinement module to rectify the initial 3D box, which takes the instance point cloud converted from the monocular depth prediction as input. Experiments on the KITTI dataset demonstrate that our method exhibits state-of-the-art performance solely via monocular images. Our method achieves 15.97, 10.42, and 7.91 3D AP on the three difficulty levels on the KITTI test set, respectively.
C1 [Ji, Chaofeng; Liu, Guizhong; Zhao, Dan] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian, Peoples R China.
C3 Xi'an Jiaotong University
RP Liu, GZ (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian, Peoples R China.
EM jichaofeng@stu.xjtu.edu.cn; liugz@xjtu.edu.cn;
   zhaodan1014@stu.xjtu.edu.cn
CR Brazil G, 2019, IEEE I CONF COMP VIS, P9286, DOI 10.1109/ICCV.2019.00938
   Cai YJ, 2020, AAAI CONF ARTIF INTE, V34, P10478
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Chabot F, 2017, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2017.198
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chen XZ, 2018, IEEE T PATTERN ANAL, V40, P1259, DOI 10.1109/TPAMI.2017.2706685
   Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236
   Chen Y., 2020, CVPR, P10337
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Geiger A., 2012, CVPR
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Gupta I, 2018, EUR C COMP VIS, P626
   Jiaming Sun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10545, DOI 10.1109/CVPR42600.2020.01056
   Ku J, 2019, PROC CVPR IEEE, P11859, DOI 10.1109/CVPR.2019.01214
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li BY, 2019, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2019.00111
   Li P, 2019, ARXIV191009777
   Li PL, 2019, PROC CVPR IEEE, P7636, DOI 10.1109/CVPR.2019.00783
   Li Peixuan, 2020, EUROPEAN C COMPUTER, P644
   Liu LJ, 2019, PROC CVPR IEEE, P1057, DOI 10.1109/CVPR.2019.00115
   Liu ZC, 2020, IEEE COMPUT SOC CONF, P4289, DOI 10.1109/CVPRW50498.2020.00506
   Ma XZ, 2019, IEEE I CONF COMP VIS, P6850, DOI 10.1109/ICCV.2019.00695
   Manhardt F, 2019, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2019.00217
   Mousavian A, 2017, PROC CVPR IEEE, P7074, DOI DOI 10.1109/CVPR.2017.597
   Naiden A, 2019, IEEE IMAGE PROC, P61, DOI [10.1109/ICIP.2019.8803397, 10.1109/icip.2019.8803397]
   Ng MY, 2020, IEEE COMPUT SOC CONF, P4306, DOI 10.1109/CVPRW50498.2020.00508
   Pon AD, 2020, IEEE INT CONF ROBOT, P8383, DOI [10.1109/ICRA40945.2020.9196660, 10.1109/icra40945.2020.9196660]
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Qin ZY, 2019, PROC CVPR IEEE, P7607, DOI 10.1109/CVPR.2019.00780
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Simonelli A, 2019, IEEE I CONF COMP VIS, P1991, DOI 10.1109/ICCV.2019.00208
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vora S, 2020, PROC CVPR IEEE, P4603, DOI 10.1109/CVPR42600.2020.00466
   Wang Y, 2019, PROC CVPR IEEE, P8063, DOI 10.1109/CVPR.2019.00826
   Xiang Y, 2017, IEEE WINT CONF APPL, P924, DOI 10.1109/WACV.2017.108
   Xie L, 2020, AAAI CONF ARTIF INTE, V34, P12460
   Xu B, 2018, PROC CVPR IEEE, P2345, DOI 10.1109/CVPR.2018.00249
   Xuepeng Shi, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12374), P91, DOI 10.1007/978-3-030-58526-6_6
   Yang B, 2018, PROC CVPR IEEE, P7652, DOI 10.1109/CVPR.2018.00798
   Yang L., 2021, ABS210500268 ARXIV
   You Y., 2020, ICLR, P1
   Zhou X, 2019, ARXIV190407850
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 48
TC 5
Z9 5
U1 4
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5973
EP 5988
DI 10.1007/s11042-021-11801-3
EA JAN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000737741900003
DA 2024-07-18
ER

PT J
AU Kiruthika, S
   Masilamani, 
AF Kiruthika, S.
   Masilamani, V
TI Image quality assessment based fake face detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forgery; Image quality assessment; Random forest; Deepfake; Face
   forensics; Face detection
ID STATISTICS
AB The tremendous growth of data in social media and other platforms has raised an interesting question of authenticity. It has led to an active research area named Digital Forensics. Especially, the face manipulation has become a major issue in character assassination. The image forgery tools are improving everyday thereby posing a challenge in detection systems. The current detection systems provide deep learning based solutions which do not bring the reliability and also have chance to fail when different forgery tool is developed to synthesise or edit the face image. Therefore, an efficient system is required which gives explainability along with efficacy. In this paper, we propose a novel method to detect the forged faces using Image Quality Assessment(IQA) based features. As far as we know IQA has not been used for detecting AI generated images. Despite the visual appearance being same for original and fake images, most of the discriminative information will be available in the frequency domain of those images. With that intuition we have extracted image quality based features from frequency domain and also spatial domain. The proposed method has achieved the highest accuracy of 99% when different types of experiments were performed on standard datasets. The generalisation and explainability of the proposed model have also been discussed.
C1 [Kiruthika, S.; Masilamani, V] Indian Inst Informat Technol Design & Mfg, Kancheepuram, India.
C3 Indian Institute of Information Technology, Design & Manufacturing,
   Kancheepuram
RP Kiruthika, S (corresponding author), Indian Inst Informat Technol Design & Mfg, Kancheepuram, India.
EM coe18d003@iiitdm.ac.in; masila@iiitdm.ac.in
RI Bueno, Regis Cortez/AAG-3852-2020
OI Bueno, Regis Cortez/0000-0002-2923-4930; S,
   Kiruthika/0000-0003-1615-391X
CR Akhtar Z., 2019, PROC IEEE INT S TECH, P1, DOI DOI 10.1109/HST47167.2019.9033005
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   Bakshi A, 2022, MULTIMED TOOLS APPL, V81, P35047, DOI 10.1007/s11042-020-10045-x
   Bappy JH, 2017, IEEE I CONF COMP VIS, P4980, DOI 10.1109/ICCV.2017.532
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Cristin R, 2018, IET IMAGE PROCESS, V12, P1439, DOI 10.1049/iet-ipr.2017.1120
   Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582
   De K, 2017, MULTIMED TOOLS APPL, V76, P18641, DOI 10.1007/s11042-016-4335-9
   De K, 2013, PROCEDIA ENGINEER, V64, P149, DOI 10.1016/j.proeng.2013.09.086
   Fei JW, 2021, MULTIMED TOOLS APPL, V80, P30789, DOI 10.1007/s11042-020-09147-3
   Fernando T., 2019, ARXIV191107844
   Fourati E, 2020, MULTIMED TOOLS APPL, V79, P865, DOI 10.1007/s11042-019-08115-w
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Galbally J, 2012, FUTURE GENER COMP SY, V28, P311, DOI 10.1016/j.future.2010.11.024
   Guan HY, 2019, IEEE WINT CONF APPL, P63, DOI 10.1109/WACVW.2019.00018
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsu CC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010370
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Khalid H, 2020, IEEE COMPUT SOC CONF, P2794, DOI 10.1109/CVPRW50498.2020.00336
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Li J., 2019, ARXIV191205790
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li XR, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P88, DOI 10.1145/3366424.3382711
   [李艳歌 Li Yange], 2018, [高分子通报, Polymer Bulletin], P46
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Lundberg SM, 2017, ADV NEUR IN, V30
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   McCloskey Scott, 2018, arXiv
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Nataraj L., 2019, Electron. Imaging, V5, P1, DOI 10.2352/
   Neves Joao C, 2019, ARXIV191105351
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Nhu T, 2018, P 2018 INT S INF TEC
   Rana MS, 2020, 2020 7TH IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (CSCLOUD 2020)/2020 6TH IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING AND SCALABLE CLOUD (EDGECOM 2020), P70, DOI 10.1109/CSCloud-EdgeCom49738.2020.00021
   Kiruthika S, 2022, IET IMAGE PROCESS, V16, P1054, DOI 10.1049/ipr2.12209
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tariq S, 2018, MPS'18: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA PRIVACY AND SECURITY, P81, DOI 10.1145/3267357.3267367
   Theobalt Chris- tian, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.262
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Wang R., 2019, ARXIV190906122
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yeh CH, 2018, IEEE WINT CONF APPL, P49, DOI 10.1109/WACV.2018.00012
   Yi Dong, 2014, ARXIV14117923
   Zhang Y, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P15, DOI 10.1109/SIPROCESS.2017.8124497
NR 50
TC 6
Z9 6
U1 7
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8691
EP 8708
DI 10.1007/s11042-021-11493-9
EA JAN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000737741900014
DA 2024-07-18
ER

PT J
AU Mohapatra, AG
   Talukdar, J
   Mishra, TC
   Anand, S
   Jaiswal, A
   Khanna, A
   Gupta, D
AF Mohapatra, Ambarish G.
   Talukdar, Jaideep
   Mishra, Tarini Ch.
   Anand, Sameer
   Jaiswal, Ajay
   Khanna, Ashish
   Gupta, Deepak
TI Fiber Bragg grating sensors driven structural health monitoring by using
   multimedia-enabled iot and big data technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE FBG; Sensor Sensor calibration; Sensor signal processing; Strain;
   distribution analysis; Structural health monitoring; Critical sensing;
   Big data; IoT; Kafka; Smart distributed sensing
ID SYSTEM; TEMPERATURE
AB Structural Health Monitoring (SHM) of large structures is a critical aspect due to various environmental conditions, high speed & long-distance communication, dynamic analysis of the structure, and cost of operation. These issues can be addressed using Fiber Bragg Grating (FBG) sensor technology which has evolved to a new height and is widely used in various distributed critical sensing applications. These are mostly preferred due to long-distance monitoring, low cost of operation, and immunity to Electromagnetic (EM) radiations. Similarly, the monitoring of a large structure from a long distance is also one of the crucial aspects of SHM technologies. These technological challenges can be addressed using an integrated distributed sensing solution consisting of FBG sensors, Big Data, Kafka, and the Internet of Things (IoT). In this article, the fabrication of the FBG sensor and the bonding of the sensing element to the base plate of the suspension bridge structure are discussed along with experimental details. A scalable architecture of the proposed Smart Distributed Sensing (SDS) model using FBG sensors is also discussed in this article. The experimental validation is performed using an IoT based FBG sensing mechanism to estimate the strain distribution profile at the bonding region of the base plate from a central location.
C1 [Mohapatra, Ambarish G.] Silicon Inst Technol, Dept Elect & Instrumentat Engn, Bhubaneswar, Odisha, India.
   [Talukdar, Jaideep] Silicon Inst Technol, Dept Basic Sci & Humanities, Bhubaneswar, Odisha, India.
   [Mishra, Tarini Ch.] Silicon Inst Technol, Dept Informat Technol, Bhubaneswar, Odisha, India.
   [Anand, Sameer; Jaiswal, Ajay] Univ Delhi, SS Coll Business Studies, Dept Comp Sci, Delhi, India.
   [Khanna, Ashish; Gupta, Deepak] Maharaja Agrasen Inst Technol, Delhi, India.
C3 Silicon Institute of Technology; Silicon Institute of Technology;
   Silicon Institute of Technology; University of Delhi; Maharaja Agrasen
   Institute of Technology
RP Mohapatra, AG (corresponding author), Silicon Inst Technol, Dept Elect & Instrumentat Engn, Bhubaneswar, Odisha, India.
EM ambarish.mohapatra@gmail.com
RI Gupta, Deepak/AAV-2728-2020; Mohapatra, Ambarish/AAC-5585-2022;
   Talukdar, Jaideep/HHZ-3522-2022
OI Gupta, Deepak/0000-0002-3019-7161; Mohapatra, Dr. Ambarish
   G./0000-0001-5139-8889
FU Silicon Research Promotion Scheme (SRPS), Silicon Institute of
   Technology India
FX The authors thank the personnel of Central Glass and Ceramic Research
   Institute (CSIR-CGCRI), Kolkata who have provided continuous support in
   fabricating and calibrating the FBG sensor during this research work.
   The authors also thank Silicon Institute of Technology, Bhubaneswar for
   providing licensed software like LabVIEW and state-of-the art equipment
   like the FBG interrogator, for successful conduction of the experiments
   related to this study. This article is an extension of the research work
   sponsored by Silicon Research Promotion Scheme (SRPS), Silicon Institute
   of Technology India.
CR Ahmed O, 2021, COMPOS PART B-ENG, V223, DOI 10.1016/j.compositesb.2021.109136
   Alavi AH, 2019, FUTURE GENER COMP SY, V93, P651, DOI 10.1016/j.future.2018.10.059
   [Anonymous], 2019, FACEBOOKS SCRIBE
   [Anonymous], 2020, APACHE HADOOP
   [Anonymous], 2019, ENABLING HADOOP BATC
   Dobbelaere P., 2017, P 11 ACM INT C DISTR, P227, DOI [10.1145/3093742.3093908, DOI 10.1145/3093742.3093908]
   Ezzedine T, 2017, OPTIK, V135, P454, DOI 10.1016/j.ijleo.2017.01.061
   Isah BW, 2021, AIN SHAMS ENG J, V12, P1677, DOI 10.1016/j.asej.2020.09.007
   Jin X, 2019, SENSOR ACTUAT A-PHYS, V285, P491, DOI 10.1016/j.sna.2018.11.052
   Keswani B, 2019, NEURAL COMPUT APPL, V31, P277, DOI 10.1007/s00521-018-3737-1
   Kreps J., 2011, Kafka: a Distributed Messaging System for Log Processing
   Lenka SK, 2015, 2015 IEEE International Symposium on Nanoelectronic and Information Systems, P63, DOI 10.1109/iNIS.2015.56
   Li RY, 2019, OPT FIBER TECHNOL, V48, P199, DOI 10.1016/j.yofte.2019.01.009
   Li XX, 2015, SENSOR ACTUAT A-PHYS, V223, P105, DOI 10.1016/j.sna.2015.01.003
   Li Y, 2019, OPT FIBER TECHNOL, V48, P207, DOI 10.1016/j.yofte.2019.01.006
   Lima HF, 2008, IEEE SENS J, V8, P1236, DOI 10.1109/JSEN.2008.926177
   Markowski K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030770
   Mieloszyk M, 2021, MAR STRUCT, V76, DOI 10.1016/j.marstruc.2020.102903
   Mieloszyk M, 2017, MAR STRUCT, V51, P65, DOI 10.1016/j.marstruc.2016.10.006
   Mita A, 2001, P SOC PHOTO-OPT INS, V4330, P479, DOI 10.1117/12.434148
   Mohamed A. A. S., 2016, P IEEE IND APPL SOC, P1
   Mohapatra Ambarish G., 2016, International Journal of Intelligent Systems Technologies and Applications, V15, P4
   Mohapatra A.G., 2016, INT J CONVERG COMPUT, V2, P3
   Mohapatra AG, 2019, P NATL A SCI INDIA A, V89, P67, DOI 10.1007/s40010-017-0401-6
   Rao YJ, 1997, MEAS SCI TECHNOL, V8, P355, DOI 10.1088/0957-0233/8/4/002
   Rekha KS, 2018, MATER TODAY-PROC, V5, P1169, DOI 10.1016/j.matpr.2017.11.198
   Salter C., 2020, REV FIBER OPTIC ACCE
   Savastru D, 2020, U POLITEH BUCH SER A, V82, P253
   Williamson C., 2006, STATE ART REV STRUCT
   XU MG, 1993, ELECTRON LETT, V29, P398, DOI 10.1049/el:19930267
   Yasuda S, 2017, PROC CIRP, V61, P785, DOI 10.1016/j.procir.2016.11.260
   Yu JS, 2018, OPTIK, V167, P25, DOI 10.1016/j.ijleo.2018.03.021
   Zhang XL, 2015, OPT COMMUN, V343, P38, DOI 10.1016/j.optcom.2014.12.079
   Zhao Y, 2018, SENSOR ACTUAT A-PHYS, V279, P101, DOI 10.1016/j.sna.2018.06.004
NR 34
TC 15
Z9 15
U1 6
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34573
EP 34593
DI 10.1007/s11042-021-11565-w
EA JAN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000737741900011
DA 2024-07-18
ER

PT J
AU Mnasri, Z
   Rovetta, S
   Masulli, F
AF Mnasri, Zied
   Rovetta, Stefano
   Masulli, Francesco
TI Anomalous sound event detection: A survey of machine learning based
   methods and applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomalous sound event detection; Feature extraction; Supervised
   learning; Unsupervised learning; Evaluation metrics
ID ACOUSTIC SCENES; NEURAL-NETWORK; SELECTION; REPRESENTATIONS;
   CLASSIFICATION; AUTOENCODERS; SEGMENTATION; EXTRACTION; MODELS; SYSTEM
AB With the development of multi-modal man-machine interaction, audio signal analysis is gaining importance in a field traditionally dominated by video. In particular, anomalous sound event detection offers novel options to improve audio-based man-machine interaction, in many useful applications such as surveillance systems, industrial fault detection and especially safety monitoring, either indoor or outdoor. Event detection from audio can fruitfully integrate visual information and can outperform it in some respects, thus representing a complementary perceptual modality. However, it also presents specific issues and challenges. In this paper, a comprehensive survey of anomalous sound event detection is presented, covering various aspects of the topic, i.e.feature extraction methods, datasets, evaluation metrics, methods, applications, and some open challenges and improvement ideas that have been recently raised in the literature.
C1 [Mnasri, Zied] Univ Tunis El Manar, Elect Eng Dept, ENIT, Tunis El Manar, Tunisia.
   [Mnasri, Zied; Rovetta, Stefano; Masulli, Francesco] Univ Genoa, Genoa, Italy.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); University of Genoa
RP Mnasri, Z (corresponding author), Univ Tunis El Manar, Elect Eng Dept, ENIT, Tunis El Manar, Tunisia.; Mnasri, Z (corresponding author), Univ Genoa, Genoa, Italy.
EM zied.mnasri@enit.utm.tn; stefano.rovetta@unige.it;
   stefano.rovetta@unige.it
FU University of Genoa
FX This work has been funded by the University of Genoa in the framework of
   the project Xpert.
CR Abdullatif A, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1258
   Adavanne S, 2020, P DET CLASS AC SCEN
   Adavanne S, 2017, INT CONF ACOUST SPEE, P771, DOI 10.1109/ICASSP.2017.7952260
   Adavanne Sharath, 2016, WORKSHOP DETECTION C, P6
   Ahn JW, 2019, PROCEEDINGS OF THE 17TH CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS (SENSYS '19), P378, DOI 10.1145/3356250.3361963
   [Anonymous], 2016, P DET CLASS AC SCEN
   [Anonymous], 2015, 3 INT C LEARN REPR
   [Anonymous], 2017, P DCASE MUN GERM 16
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2018, PR MACH LEARN RES
   [Anonymous], 2017, P 18 ISMIR C SUZH CH, DOI DOI 10.5281/ZENODO.1417159
   Arora V, 2019, INT CONF ACOUST SPEE, P3297, DOI 10.1109/ICASSP.2019.8682395
   ATREY P.K., 2006, 2006 IEEE INT C AC S, DOI DOI 10.1109/ICASSP.2006.1661400
   Aurino F, 2014, 2014 INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKING AND COLLABORATIVE SYSTEMS (INCOS), P145, DOI 10.1109/INCoS.2014.59
   Babaee E, 2017, APPL ARTIF INTELL, V31, P661, DOI 10.1080/08839514.2018.1430469
   Baumann J, 2020, INT CONF ACOUST SPEE, P611, DOI [10.1109/icassp40776.2020.9052950, 10.1109/ICASSP40776.2020.9052950]
   Bayram B, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12564
   Becker P, 2020, 2020 IEEE 7TH INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND APPLICATIONS (ICIEA 2020), P921, DOI [10.1109/iciea49774.2020.9102002, 10.1109/ICIEA49774.2020.9102002]
   Benetos E, 2013, J ACOUST SOC AM, V133, P1727, DOI 10.1121/1.4790351
   Borges N, 2008, 2008 42ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1-3, P950, DOI 10.1109/CISS.2008.4558655
   Butko T, 2011, FEATURE SELECTION MU
   Çakir E, 2017, IEEE-ACM T AUDIO SPE, V25, P1291, DOI 10.1109/TASLP.2017.2690575
   Chakrabarty D, 2016, INT CONF ACOUST SPEE, P216, DOI 10.1109/ICASSP.2016.7471668
   Chan TK, 2020, IEEE ACCESS, V8, P103339, DOI 10.1109/ACCESS.2020.2999388
   Chandrakala S, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3322240
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chen C, 2020, P DET CLASS AC SCEN
   Chen YP, 2019, INTERSPEECH, P619, DOI 10.21437/Interspeech.2019-1985
   Chen ZJ, 2021, COMPUT COMMUN, V168, P65, DOI 10.1016/j.comcom.2021.01.005
   Colangelo F, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Cooper C, 2020, PROCEDIA MANUF, V48, P372, DOI 10.1016/j.promfg.2020.05.059
   Cotton CV, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P69, DOI 10.1109/ASPAA.2011.6082331
   Criminisi A, 2013, DECISION FORESTCOM, P95
   Dang A, 2017, WORKSH DCASE2017 CHA
   Dee HM, 2005, AVSS 2005: Advanced Video and Signal Based Surveillance, Proceedings, P34
   Dekkers G., 2017, 2017 IEEE AASP CHALL, P32
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dissanayake T, 2021, IEEE T BIO-MED ENG, V68, P1978, DOI 10.1109/TBME.2020.3045720
   Duman T.B., 2020, INT WORKSH SOFT COMP, P432
   Erfani SM, 2016, PATTERN RECOGN, V58, P121, DOI 10.1016/j.patcog.2016.03.028
   Foggia P, 2016, IEEE T INTELL TRANSP, V17, P279, DOI 10.1109/TITS.2015.2470216
   Forman George, 2010, ACM SIGKDD Explorations Newsletter, DOI DOI 10.1145/1882471.1882479
   Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261
   Giri R., 2020, P DCASE WORKSH, P51
   Hayashi T, 2018, EUR SIGNAL PR CONF, P2494, DOI 10.23919/EUSIPCO.2018.8553423
   Hayashi T, 2017, IEEE-ACM T AUDIO SPE, V25, P2059, DOI 10.1109/TASLP.2017.2740002
   Hayashi T, 2017, INT CONF ACOUST SPEE, P766, DOI 10.1109/ICASSP.2017.7952259
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   He KX, 2019, ASIAPAC SIGN INFO PR, P1491, DOI [10.1109/APSIPAASC47483.2019.9023308, 10.1109/apsipaasc47483.2019.9023308]
   Heittola T, 2013, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2013-1
   Holmes A., 2012, HADOOP IN PRACTICE
   Phan H, 2019, INT CONF ACOUST SPEE, P51, DOI 10.1109/ICASSP.2019.8683064
   Phan H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P336, DOI 10.1109/ICASSP.2018.8461353
   Iandola Forrest, 2017, 2017 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS), DOI 10.1145/3125502.3125606
   Imoto K, 2020, INT CONF ACOUST SPEE, P621, DOI [10.1109/ICASSP40776.2020.9053912, 10.1109/icassp40776.2020.9053912]
   Janjua ZH, 2019, ENG APPL ARTIF INTEL, V84, P41, DOI 10.1016/j.engappai.2019.05.011
   Kao CC, 2020, INT CONF ACOUST SPEE, P316
   Kao CC, 2018, INTERSPEECH, P1358, DOI 10.21437/Interspeech.2018-2323
   Kawachi Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2366, DOI 10.1109/ICASSP.2018.8462181
   Kawaguchi Y, 2018, EUR SIGNAL PR CONF, P2524, DOI 10.23919/EUSIPCO.2018.8553480
   Kim H.G., 2006, MPEG 7 AUDIO AUDIO C
   Ko BJ, 2016, P ACM BUILDSYS
   Koizumi Y, 2020, INT CONF ACOUST SPEE, P281, DOI [10.1109/icassp40776.2020.9053620, 10.1109/ICASSP40776.2020.9053620]
   Koizumi Y, 2019, IEEE WORK APPL SIG, P313, DOI [10.1109/WASPAA.2019.8937164, 10.1109/waspaa.2019.8937164]
   Koizumi Y, 2019, INT CONF ACOUST SPEE, P915, DOI 10.1109/ICASSP.2019.8683667
   Koizumi Y, 2017, EUR SIGNAL PR CONF, P698, DOI 10.23919/EUSIPCO.2017.8081297
   Koizumi Yuma, 2020, ARXIV200605822
   Kriegel HP, 2011, WIRES DATA MIN KNOWL, V1, P231, DOI 10.1002/widm.30
   Pham L, 2021, IEEE J BIOMED HEALTH, V25, P2938, DOI 10.1109/JBHI.2021.3064237
   Latif S, 2018, INTERSPEECH, P3107, DOI 10.21437/Interspeech.2018-1568
   Lee J, 2011, IEEE T INTELL TRANSP, V12, P1640, DOI 10.1109/TITS.2011.2163154
   Lim H., 2017, P DETECTION CLASSIFI, P80
   Lin LW, 2020, INT CONF ACOUST SPEE, P626, DOI [10.1109/ICASSP40776.2020.9053584, 10.1109/icassp40776.2020.9053584]
   Liu CY, 2016, PHYSIOL MEAS, V37, P2181, DOI 10.1088/0967-3334/37/12/2181
   Liu YM, 2018, ASIAPAC SIGN INFO PR, P1853, DOI 10.23919/APSIPA.2018.8659533
   Lu YC, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P749, DOI 10.1145/2911451.2914700
   Alsina-Pagès RM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112480
   Mandel M., 2019, P DET CLASS AC SCEN
   Marchi E, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/4694860
   Mesaros A, 2019, IEEE-ACM T AUDIO SPE, V27, P992, DOI 10.1109/TASLP.2019.2907016
   Mesaros A, 2018, IEEE-ACM T AUDIO SPE, V26, P379, DOI 10.1109/TASLP.2017.2778423
   Mesaros A, 2016, EUR SIGNAL PR CONF, P1128, DOI 10.1109/EUSIPCO.2016.7760424
   Mesaros A, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6060162
   Mesaros A, 2011, EUR SIGNAL PR CONF, P1307
   Morise M, 2016, IEICE T INF SYST, VE99D, P1877, DOI 10.1587/transinf.2015EDP7457
   Mulimani M, 2019, DIGIT SIGNAL PROCESS, V87, P1, DOI 10.1016/j.dsp.2019.01.001
   Muller R., 2020, ARXIV200603429
   Nachman B, 2020, PHYS REV D, V101, DOI 10.1103/PhysRevD.101.075042
   Ng A, 2011, ELGAR LAW TECH SOC, P1
   Ntalampiras S, 2014, DIGIT SIGNAL PROCESS, V31, P69, DOI 10.1016/j.dsp.2014.05.003
   Ntalampiras S, 2011, IEEE T MULTIMEDIA, V13, P713, DOI 10.1109/TMM.2011.2122247
   Nunes E.C., ARXIV PREPRINT ARXIV
   Oh DY, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051308
   Omar MK, 2005, INT CONF ACOUST SPEE, P501
   Ono Y, 2013, INT CONF ACOUST SPEE, P2800, DOI 10.1109/ICASSP.2013.6638167
   Papadaniil CD, 2014, IEEE J BIOMED HEALTH, V18, P1138, DOI 10.1109/JBHI.2013.2294399
   Parascandolo G, 2016, INT CONF ACOUST SPEE, P6440, DOI 10.1109/ICASSP.2016.7472917
   Park D, 2019, AUTON ROBOT, V43, P611, DOI 10.1007/s10514-018-9733-6
   Perez-Castanos S, 2020, P DET CLASS AC SCEN
   Petitjean F, 2014, IEEE DATA MINING, P470, DOI 10.1109/ICDM.2014.27
   Phan H., 2017, P DCASE 2017 WORKSH
   Plinge Axel, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3704, DOI 10.1109/ICASSP.2014.6854293
   Plumbley M. D., 2018, P DET CLASS AC SCEN
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Prego TD, 2016, IEEE LAT AMER SYMP, P207, DOI 10.1109/LASCAS.2016.7451046
   Purohit H, 2020, P DET CLASS AC SCEN
   Purohit H., 2019, MIMII Dataset: Sound Dataset for MalfunctioningIndustrial Machine Investigation and Inspection, P209, DOI [10.33682/m76f-d618, DOI 10.33682/M76F-D618]
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rachburee N, 2015, 2015 7TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND ELECTRICAL ENGINEERING (ICITEE), P420, DOI 10.1109/ICITEED.2015.7408983
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Riccardi G, 2005, IEEE T SPEECH AUDI P, V13, P504, DOI 10.1109/TSA.2005.848882
   Rocha BM, 2018, InPrecision medicine powered by pHealth and connected health: ICBHI 2017, P33
   Rossi A, 2017, IOP CONF SER-MAT SCI, V261, DOI 10.1088/1757-899X/261/1/012009
   Rovetta S, 2021, 12 C EUR SOC FUZZ LO
   Rovetta S, 2020, IEEE CONF EVOL ADAPT, DOI 10.1109/eais48028.2020.9122704
   Rushe E, 2019, INT CONF ACOUST SPEE, P3597, DOI 10.1109/ICASSP.2019.8683414
   Salamon J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1041, DOI 10.1145/2647868.2655045
   Sammarco M., 2018, Vehits, P27
   Schmidt SE, 2010, PHYSIOL MEAS, V31, P513, DOI 10.1088/0967-3334/31/4/004
   Schölkopf B, 2000, ADV NEUR IN, V12, P582
   Shawe-Taylor J., 2004, Kernel Methods for Pattern Analysis, DOI [DOI 10.1017/CBO9780511809682, 10.1017/cbo9780511809682]
   Shimada K, 2020, INT CONF ACOUST SPEE, P616, DOI [10.1109/icassp40776.2020.9054712, 10.1109/ICASSP40776.2020.9054712]
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Stevens SS, 1937, J ACOUST SOC AM, V8, P185, DOI 10.1121/1.1915893
   Stowell D, 2015, IEEE T MULTIMEDIA, V17, P1733, DOI 10.1109/TMM.2015.2428998
   Stowell D, 2013, J MACH LEARN RES, V14, P2213
   Su TW, 2017, INT CONF ACOUST SPEE, P791, DOI 10.1109/ICASSP.2017.7952264
   Syed Z, 2007, IEEE T BIO-MED ENG, V54, P651, DOI 10.1109/TBME.2006.889189
   Tranter SE, 2006, IEEE T AUDIO SPEECH, V14, P1557, DOI 10.1109/TASL.2006.878256
   Turpault N., 2019, WORKSH DET CLASS AC, DOI DOI 10.33682/006B-JX26
   Uematsu H, 2017, NTT TECHNICAL REV, V15
   Valenzise G, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P21, DOI 10.1109/AVSS.2007.4425280
   Vallim RMM, 2015, PROG ARTIF INTELL, V4, P1, DOI 10.1007/s13748-015-0063-z
   van den Oord Aaron, 2016, PROC 9 ISCA SPEEC, P125
   Vesperini F, 2017, P DCASE 2017 WORKSH
   Vincent E, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P162, DOI 10.1109/ASRU.2013.6707723
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Virtanen T., 2017, P DET CLASS AC SCEN
   WEI Q., 2020, AUTOENCODER METRIC L
   Xia XJ, 2020, IEEE T MULTIMEDIA, V22, P569, DOI 10.1109/TMM.2019.2933330
   Xia XJ, 2019, CIRC SYST SIGNAL PR, V38, P3433, DOI 10.1007/s00034-019-01094-1
   Xiang T, 2008, COMPUT VIS IMAGE UND, V111, P59, DOI 10.1016/j.cviu.2007.06.004
   Yamaguchi M, 2019, INT CONF ACOUST SPEE, P3647, DOI [10.1109/ICASSP.2019.8683072, 10.1109/icassp.2019.8683072]
   Yamato Y., 2017, J. Inf. Process., V25, P317
   Yan J, 2019, INT CONF ACOUST SPEE, P755, DOI [10.1109/icassp.2019.8682376, 10.1109/ICASSP.2019.8682376]
   Ye JX, 2012, 2012 IEEE SENSORS APPLICATIONS SYMPOSIUM (SAS 2012), P171
   Zabihi M, 2016, COMPUT CARDIOL CONF, V43, P613, DOI 10.22489/cinc.2016.180-213
   Zhang YS, 2021, EUR J OPER RES, V290, P235, DOI 10.1016/j.ejor.2020.09.028
   Zhang ZX, 2012, INT CONF ACOUST SPEE, P333, DOI 10.1109/ICASSP.2012.6287884
   Zhuang XD, 2008, INT CONF ACOUST SPEE, P17
   Zhuang XD, 2010, PATTERN RECOGN LETT, V31, P1543, DOI 10.1016/j.patrec.2010.02.005
NR 151
TC 19
Z9 20
U1 7
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5537
EP 5586
DI 10.1007/s11042-021-11817-9
EA DEC 2021
PG 50
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000734718100003
DA 2024-07-18
ER

PT J
AU Trivedi, M
   Gupta, A
AF Trivedi, Megha
   Gupta, Abhishek
TI A lightweight deep learning architecture for the automatic detection of
   pneumonia using chest X-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pneumonia; Chest X-ray; Deep learning; MobileNet; Automatic detection of
   pneumonia
AB Pneumonia is a life-threatening respiratory lung disease. Children are more prone to be affected by the disease and accurate manual detection is not easy. Generally, chest radiographs are used for the manual detection of pneumonia and expert radiologists are required for the assessment of the X-ray images. An automatic system would be beneficial for the diagnosis of pneumonia based on chest radiographs as manual detection is time-consuming and tedious. Therefore, a method is proposed in this paper for the fast and automatic detection of pneumonia. A deep learning-based architecture 'MobileNet' is proposed for the automatic detection of pneumonia based on the chest X-ray images. A benchmark dataset of 5856 chest X-ray images was taken for the training, testing, and evaluation of the proposed deep learning network. The proposed model was trained within 3 Hrs. and achieved a training accuracy of 97.34%, a validation accuracy of 87.5%, and a testing accuracy of 94.23% for automatic detection of pneumonia. However, the combined accuracy was achieved as 97.09% with 0.96 specificity, 0.97 precision, 0.98 recall, and 0.97 F-Score. The proposed method was found faster and computationally lesser expensive as compared to other methods in the literature and achieved a promising accuracy.
C1 [Trivedi, Megha] Shri Mata Vaishno Devi Univ, Sch Elect & Commun Engn, Katra 182320, Jammu & Kashmir, India.
   [Gupta, Abhishek] Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182320, Jammu & Kashmir, India.
C3 Shri Mata Vaishno Devi University; Shri Mata Vaishno Devi University
RP Gupta, A (corresponding author), Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182320, Jammu & Kashmir, India.
EM meghat525@gmail.com; abhishekgupta10@yahoo.co.in
RI Gupta, Abhishek/O-3016-2019
OI Gupta, Abhishek/0000-0002-8592-9964
CR [Anonymous], 2020, BIOMED PHARMACOL J, V13
   Ashok M, 2021, 2021 INT C ARTIFICIA, P198, DOI [10.1109/ICAIS50930.2021.9396016, DOI 10.1109/ICAIS50930.2021.9396016]
   Ashok M, 2021, ARCH COMPUT METHOD E, V28, P3245, DOI 10.1007/s11831-020-09497-z
   Batch normalization in Neural Networks, DATA SCI
   Budak Ü, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109426
   Cömert Z, 2019, ADV INTELL SYST COMP, V763, P239, DOI 10.1007/978-3-319-91186-1_25
   Del Fiol G, 2018, J MED INTERNET RES, V20, DOI 10.2196/10281
   El Asnaoui K, 2021, INT J MULTIMED INF R, V10, P55, DOI 10.1007/s13735-021-00204-7
   Gupta A., 2020, Int J Comput Vis Robot, V10, P360, DOI [10.1504/IJCVR.2020.108153, DOI 10.1504/IJCVR.2020.108153]
   Gupta A, 2021, INT J UNCERTAIN FUZZ
   Gupta A, 2019, COMPUT SCI-AGH, V20, P389, DOI 10.7494/csci.2019.20.4.3163
   Gupta A, 2016, INT J COMPUT ASS RAD, V11, P1297, DOI 10.1007/s11548-015-1334-7
   Gupta A, 2015, INT J COMPUT ASS RAD, V10, P1737, DOI 10.1007/s11548-015-1173-6
   Hammoudi K, 2021, J MED SYST, V45, DOI 10.1007/s10916-021-01745-4
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jakhar K., 2018, P 2018 4 INT C COMP, P1
   Javid T, 2022, J KING SAUD UNIV-COM, V34, P3602, DOI 10.1016/j.jksuci.2020.06.010
   Kermany Daniel, 2018, Mendeley Data, V2
   Kolditz M, 2017, DTSCH ARZTEBL INT, V114, P838, DOI 10.3238/arztebl.2017.0838
   Lavine M, 2012, J HIST MED ALL SCI, V67, P587, DOI 10.1093/jhmas/jrr047
   Livieris IE, 2019, ALGORITHMS, V12, DOI 10.3390/a12030064
   Melendez J, 2015, IEEE T MED IMAGING, V34, P179, DOI 10.1109/TMI.2014.2350539
   Namasudra S, 2022, IEEE T SERV COMPUT, V15, P2289, DOI 10.1109/TSC.2020.3046471
   Namasudra S, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3392665
   Namasudra S, 2017, IET COMMUN, V11, P1558, DOI 10.1049/iet-com.2016.0777
   Neelapu BC, 2018, DENTOMAXILLOFAC RAD, V47, DOI 10.1259/dmfr.20170054
   Nwankpa C., 2018, ARXIV181103378
   Pletz Mathias W, 2016, F1000Res, V5, DOI 10.12688/f1000research.7657.1
   Pneumonia Detection, 2020, KAGGLE
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Santurkar S, 2018, ADV NEUR IN, V31
   Saraiva AA, 2019, BIOIMAGING: PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES, VOL 2, P112, DOI 10.5220/0007404301120119
   Shen YC, 2016, SCI REP-UK, V6, DOI 10.1038/s41598-016-0023-2
   Sriram A., 2019, 2019 INT JOINT C NEU, DOI DOI 10.1109/IJCNN.2019.8851758
   Stephen O, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/4180949
   Togaçar M, 2020, IRBM, V41, P212, DOI 10.1016/j.irbm.2019.10.006
   Trivedi M, INT J APPL SCI ENG, V18, P1
   Varshni D., 2019 IEEE INT C EL C, DOI DOI 10.1109/ICECCT.2019.8869364
   Wang YB, 2017, PROC CVPR IEEE, P2097, DOI 10.1109/CVPR.2017.226
NR 40
TC 18
Z9 19
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5515
EP 5536
DI 10.1007/s11042-021-11807-x
EA DEC 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000734718100001
PM 34975283
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Su, XP
   Gao, M
   Ren, J
   Li, YH
   Dong, M
   Liu, X
AF Su, Xueping
   Gao, Meng
   Ren, Jie
   Li, Yunhong
   Dong, Mian
   Liu, Xi
TI Face mask detection and classification via deep transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Masked face detection; Masked face dataset; Mask
   classification
AB Wearing a mask is an important way of preventing COVID-19 transmission and infection. German researchers found that wearing masks can effectively reduce the infection rate of COVID-19 by 40%. However, the detection of face mask-wearing in the real world is affected by factors such as light, occlusion, and multi-object. The detection effect is poor, and the wearing of cotton masks, sponge masks, scarves and other items greatly reduces the personal protection effect. Therefore, this paper proposes a new algorithm for mask detection and classification that fuses transfer learning and deep learning. Firstly, this paper proposes a new algorithm for face mask detection that integrates transfer learning and Efficient-Yolov3, using EfficientNet as the backbone feature extraction network, and choosing CIoU as the loss function to reduce the number of network parameters and improve the accuracy of mask detection. Secondly, this paper divides the mask into two categories of qualified masks (N95 masks, disposable medical masks) and unqualified masks (cotton masks, sponge masks, scarves, etc.), creates a mask classification data set, and proposes a new mask classification algorithm that the combines transfer learning and MobileNet, enhances the generalization of the model and solves the problem of small data size and easy overfitting. Experiments on the public face mask detection data set show that the proposed algorithm has a better performance than existing algorithms. In addition, experiments are performed on the created mask classification data set. The mask classification accuracy of the proposed algorithm is 97.84%, which is better than other algorithms.
C1 [Su, Xueping; Gao, Meng; Ren, Jie; Li, Yunhong; Dong, Mian] Xian Polytech Univ, Sch Elect & Informat, Xian 710048, Peoples R China.
   [Liu, Xi] GuangDong Pharmaceut Univ, Guangzhou 510000, Peoples R China.
C3 Xi'an Polytechnic University; Guangdong Pharmaceutical University
RP Liu, X (corresponding author), GuangDong Pharmaceut Univ, Guangzhou 510000, Peoples R China.
EM liuxigdpu@163.com
FU National Natural Science Foundation of China [61902301]; Shaanxi natural
   science basic research project [2021JQ692]; Shaanxi Provincial Education
   Department [19JK0364, 20JK0647]; Science and Technology Project of Xi'an
   Science and Technology Bureau [21XJZZ0020]
FX This work is supported by National Natural Science Foundation of China
   under Grant 61902301, Shaanxi natural science basic research project
   under Grant 2021JQ692, the Scientific Research Program funded by Shaanxi
   Provincial Education Department, under Grant 19JK0364 and 20JK0647,
   Science and Technology Project of Xi'an Science and Technology
   Bureau(grant no. 21XJZZ0020).
CR Betsch C, 2020, P NATL ACAD SCI USA, V117, P21851, DOI 10.1073/pnas.2011674117
   Chiang D., 2020, Detect faces and determine whether people are wearing mask
   Ejaz M.S., 2019, 2019 1 INT C ADV SCI, P1
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Ge S., 2017, IEEE C COMPUT VIS PA, P2682, DOI DOI 10.1109/CVPR.2017.53
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   GitHub, 2021, YOLOV5 MAST
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jiang M., 2020, ARXIV200503950
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li, 2020, FACE DETECTION BASED, DOI 10.1007/978-981-13-9406-5_34
   Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905
   Li YZ, 2020, PEDIATR PULM, V55, pE1, DOI 10.1002/ppul.24734
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu CS, 2020, RESPIROLOGY, V25, P895, DOI 10.1111/resp.13892
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loey M, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108288
   Ma SY, 2016, INT CONF SOFTW ENG, P651, DOI 10.1109/ICSESS.2016.7883152
   MacIntyre CR, 2020, J TRAVEL MED, V27, DOI 10.1093/jtm/taaa056
   MacIntyre CR, 2015, BMJ OPEN, V5, DOI 10.1136/bmjopen-2014-006577
   Ning C, 2021, COMPLEX INTELL SYST, V7, P577, DOI 10.1007/s40747-020-00206-8
   Novak B, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P165, DOI [10.1109/zinc50678.2020.9161446, 10.1109/ZINC50678.2020.9161446]
   Qaseem A, 2020, ANN INTERN MED, V173, P642, DOI 10.7326/M20-3234
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shan F., 2020, ARXIV200304655
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vaswani A, 2017, ADV NEUR IN, V30
   Viola, 2001, PROCIEEE CONFON COMP
   Wang G., 2020, arXiv
   Wang Y, 2020, ARCH DERMATOL RES, V312, P581, DOI 10.1007/s00403-020-02044-7
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zou Z, 2019, ARXIV
NR 44
TC 24
Z9 24
U1 13
U2 155
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4475
EP 4494
DI 10.1007/s11042-021-11772-5
EA DEC 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000728448300002
PM 34903950
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Bashir, Z
   Malik, MGA
   Hussain, M
   Iqbal, N
AF Bashir, Zia
   Malik, M. G. Abbas
   Hussain, Muhammad
   Iqbal, Nadeem
TI Multiple RGB images encryption algorithm based on elliptic curve,
   improved Diffie Hellman protocol
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple RGB images; Diffie Hellman protocol; Public key; Hyper Chaotic
   dynamical system; Hash-256
ID DNA-SEQUENCE OPERATION; CHAOTIC SYSTEM; HYPER-CHAOS; SCHEME; TRANSFORM;
   MAP
AB For the asymmetric key, the Diffie Hellman Key (DHK) protocol is very efficient, but sometimes it is vulnerable against brute force attacks if the parameters are not chosen carefully. Our study aims to improve the asymmetric key scheme based on the elliptic curve cryptosystem (ECC). The sender and receiver agree on an elliptic curve based on the DHK sharing technique, but generator G is kept secret, and we generate its hash value, which is shared publicly. The authorized members can recover G using the hash value. By keeping G secret, the key protocol becomes much more robust than existing ones. Further, the proposed scheme will be applied to multiple RGB images. In this novel public key algorithm, 4D chaotic sequences are used for the diffusion of image pixels. The pixels' values are used for permutations of images rather than the chaotic sequences, strengthening the scheme against chosen/known plain text attacks. The simulation and the security analysis of the proposed algorithm show efficiency, potential to endure the varied attacks, and prospects for real-world application.
C1 [Bashir, Zia; Hussain, Muhammad] Quaid I Azam Univ, Dept Math, Islamabad 45320, Pakistan.
   [Malik, M. G. Abbas] Universal Coll Learning, Sch Business & ICT, Palmerston North 4442, New Zealand.
   [Iqbal, Nadeem] Univ Lahore, Dept Comp Sci & IT, Lahore, Pakistan.
C3 Quaid I Azam University; Universal College of Learning - New Zealand;
   University of Lahore
RP Iqbal, N (corresponding author), Univ Lahore, Dept Comp Sci & IT, Lahore, Pakistan.
RI Hussain, Muhammad/AAD-2380-2022; Hussain, Muhammad/KGL-0395-2024; Iqbal,
   Nadeem/GWB-9856-2022; Malik, M G Abbas/AAC-8288-2019
OI Malik, M G Abbas/0000-0002-0679-8346; Iqbal, Nadeem/0000-0002-0954-5563;
   Bashir, Zia/0000-0002-6051-8413
CR Abd-El-Hafiz SK, 2014, IET IMAGE PROCESS, V8, P742, DOI 10.1049/iet-ipr.2013.0570
   [Anonymous], 2015, ADVINTELLSYSTCOMPUT, DOI DOI 10.1007/978-81-322-2268-2_16
   [Anonymous], 2010, 2010 6 IR C MACH VIS
   Bashir Z, 2021, MULTIMED TOOLS APPL, V80, P1029, DOI 10.1007/s11042-020-09695-8
   Bashir Z, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9120312
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Bissell C, 2009, IEEE COMMUN MAG, V47, P24, DOI 10.1109/MCOM.2009.5273804
   Cassels JWS., 1987, Bull. (New Ser.) Am. Math. Soc, V17, P148, DOI [10.1090/S0273-0979-1987-15544-3, DOI 10.1090/S0273-0979-1987-15544-3]
   Çokal C, 2009, PHYS LETT A, V373, P1357, DOI 10.1016/j.physleta.2009.02.030
   Dey D, 2018, SECUR PRIVACY, V1, DOI 10.1002/spy2.52
   Di H, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.7.073103
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hankerson D., 2006, Guide to Elliptic Curve Cryptography, DOI DOI 10.1007/0-387-21846-73
   Huang XL, 2014, COMMUN NONLINEAR SCI, V19, P4094, DOI 10.1016/j.cnsns.2014.04.012
   Iqbal N, 2019, IEEE ACCESS, V7, P174051, DOI 10.1109/ACCESS.2019.2956389
   Karawia AA, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20100801
   Kaushik A, 2013, INT J ADV ENG SCI AP, V3
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Lai Q, 2018, CHAOS SOLITON FRACT, V107, P92, DOI 10.1016/j.chaos.2017.12.023
   Laiphrakpam DS, 2018, MULTIMED TOOLS APPL, V77, P8629, DOI 10.1007/s11042-017-4755-1
   Li CQ, 2011, COMMUN NONLINEAR SCI, V16, P837, DOI 10.1016/j.cnsns.2010.05.008
   Li CL, 2018, OPTIK, V171, P277, DOI 10.1016/j.ijleo.2018.06.029
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu HJ, 2013, OPTIK, V124, P3527, DOI 10.1016/j.ijleo.2012.10.068
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu W, 2015, OPT COMMUN, V335, P205, DOI 10.1016/j.optcom.2014.09.046
   Luo YL, 2019, IEEE ACCESS, V7, P38507, DOI 10.1109/ACCESS.2019.2906052
   Malik MGA, 2020, IEEE ACCESS, V8, P88093, DOI 10.1109/ACCESS.2020.2990170
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Noura H, 2019, MULTIMED TOOLS APPL, V78, P16527, DOI 10.1007/s11042-018-7000-7
   Paar C., 2009, UNDERSTANDING CRYPTO
   Sampangi RV, 2015, SENSORS-BASEL, V15, P23145, DOI 10.3390/s150923145
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Singh LD, 2018, ARAB J SCI ENG, V43, P7397, DOI 10.1007/s13369-018-3104-7
   Singh LD, 2015, PROCEDIA COMPUT SCI, V54, P472, DOI 10.1016/j.procs.2015.06.054
   Stallings, 2021, Cryptography and network security: principles and practice, Patent No. 0133354695
   Su YG, 2017, OPT LASER ENG, V98, P46, DOI 10.1016/j.optlaseng.2017.05.019
   Suri S, 2017, ADV INTELL SYST, V555, P37, DOI 10.1007/978-981-10-3779-5_6
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   Vanstone, 2001, HDB APPL CRYPTOLOGY
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Xiong ZG, 2019, MULTIMED TOOLS APPL, V78, P31035, DOI 10.1007/s11042-018-7081-3
   Xu M, 2019, INFORM SCIENCES, V478, P1, DOI 10.1016/j.ins.2018.11.010
   Yuan S, 2016, J MOD OPTIC, V63, P1457, DOI 10.1080/09500340.2016.1154196
   Zhang LZ, 2018, OPT LASER TECHNOL, V105, P162, DOI 10.1016/j.optlastec.2018.03.004
   Zhang XQ, 2018, IEEE ACCESS, V6, P70025, DOI 10.1109/ACCESS.2018.2879844
   Zhang XQ, 2019, MULTIMED TOOLS APPL, V78, P7841, DOI 10.1007/s11042-018-6496-1
   Zhang XQ, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10110660
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang XQ, 2017, OPT LASER ENG, V92, P6, DOI 10.1016/j.optlaseng.2016.12.005
   Zhao ZJ, 2013, ADV INTELL SYST, V181, P859
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 59
TC 11
Z9 11
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3867
EP 3897
DI 10.1007/s11042-021-11687-1
EA NOV 2021
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000722157500001
DA 2024-07-18
ER

PT J
AU Liu, P
   Wu, H
   Luo, L
   Wang, DS
AF Liu, Pei
   Wu, Hao
   Luo, Lan
   Wang, Dao-Shun
TI DT CWT and Schur decomposition based robust watermarking algorithm to
   geometric attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust watermarking; Geometric attack; Schur decomposition; Scale
   invariant feature transform (SIFT); Maximum election statistics
ID IMAGE WATERMARKING; HYBRID; DCT; SVD
AB To improve the robustness of image watermarking algorithms against geometric attacks such as cropping, rotation, scaling, shearing, projective mapping, a robust image watermarking algorithm based on DT CWT and Schur decomposition is proposed. Firstly, we use Dual Tree Complex Wavelet Transform (DT CWT) to decompose the U component of the original image (cover image), the decomposed low frequency component is divided into non-overlapping N x N blocks, and Schur decomposition is applied in each block. Secondly, we modify maximum primary diagonal value of the upper triangular matrix of each block to embed the watermark. Finally, the Scale Invariant Feature Transform (SIFT) features of the watermarked image (stego-image) is saved as the SIFT key for watermark extraction. When extracting the watermark, we first use the SIFT features of stego-image and changed stego-image to obtain the geometric torsion, thereby a spatial synchronization can be guaranteed. And we then use the maximum election statistics to improve the quality of the extracted watermark. Experiment results show that the proposed algorithm can resist geometric attacks, and is more robust than the existing watermarking methods.
C1 [Liu, Pei] Army Med Univ, Daping Hosp, Informat Dept, Chongqing, Peoples R China.
   [Wu, Hao] Army Med Univ, Xinqiao Hosp, Dept Clin Lab, Chongqing, Peoples R China.
   [Luo, Lan] Army Med Univ, Southwest Hosp, Dept Blood Transfus, Chongqing, Peoples R China.
   [Wang, Dao-Shun] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
C3 Army Medical University; Army Medical University; Army Medical
   University; Tsinghua University
RP Wang, DS (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
EM daoshun@mail.tsinghua.edu.cn
RI luo, lan/JTT-0853-2023
FU National Natural Science Foundation of China [61972225, 61902164]; China
   Mobile Research Fund Project [MCM20170407]; Key Laboratory of Digital
   Content Anti-Counterfeiting and Security; Forensics of State
   Administration of Press, Publication, Radio, Film and Television
   (SAPPRFT)
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant No. 61972225, 61902164, China Mobile
   Research Fund Project No. MCM20170407,the Key Laboratory of Digital
   Content Anti-Counterfeiting and Security, Forensics of State
   Administration of Press, Publication, Radio, Film and Television
   (SAPPRFT).
CR Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Alsultan Mohammed, 2017, Journal of Theoretical and Applied Information Technology, V95, P1818
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Asikuzzaman M, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P277, DOI 10.1109/PCS.2015.7170090
   Bi HB, 2010, INT CONF SIGN PROCES, P881, DOI 10.1109/ICOSP.2010.5656038
   Chen ZG, 2018, IEEE T MULTIMEDIA, V20, P1973, DOI 10.1109/TMM.2018.2794985
   Han SC, 2018, OPTOELECTRON LETT, V14, P61, DOI 10.1007/s11801-018-7212-0
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   Keskinarkaus A, 2010, J SYST SOFTWARE, V83, P1715, DOI 10.1016/j.jss.2010.04.073
   Kingsbury N, 1999, INT CONF ACOUST SPEE, P1221, DOI 10.1109/ICASSP.1999.756198
   Leng L, 2015, MULTIMED TOOLS APPL, V74, P11683, DOI 10.1007/s11042-014-2255-0
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   [刘凡 Liu Fan], 2017, [计算机应用研究, Application Research of Computers], V34, P3085
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Liu Q, 2008, INT CONF SIGN PROCES, P953, DOI 10.1109/ICOSP.2008.4697285
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   OpenCV, 2015, INTR SIFT SCAL INV F
   OpenCV, 2015, INTR SURF SPEED UP R
   Rassem TH, 2016, AIP CONF PROC, V1774, DOI 10.1063/1.4965108
   Singh SP, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P140, DOI 10.1109/CSPA.2018.8368701
   Song W, 2009, ACTA PHYS SIN-CH ED, V58, P4449, DOI 10.7498/aps.58.4449
   Su QT, 2013, THESIS E CHINA U SCI
   Tian C, 2020, MULTIMED TOOLS APPL, V79, P7515, DOI 10.1007/s11042-019-08530-z
   Wang DS, 2013, TELECOMMUN SYST, V54, P359, DOI 10.1007/s11235-013-9739-5
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao Zhen-jiu, 2018, Computer Engineering and Science, V40, P1772, DOI 10.3969/j.issn.1007-130X.2018.10.008
   [张宪海 ZHANG Xianhai], 2006, [计算机工程, Computer Engineering], V32, P120
   Zou JC, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, PROCEEDINGS, P965
NR 28
TC 6
Z9 7
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2637
EP 2679
DI 10.1007/s11042-021-11532-5
EA NOV 2021
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000714321500001
DA 2024-07-18
ER

PT J
AU Zhang, SZ
   Wang, XW
   Lv, J
   Huang, M
AF Zhang, Songzhu
   Wang, Xingwei
   Lv, Jianhui
   Huang, Min
TI Routing and content delivery for in-network caching enabled IP network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE In-network caching; IP routing; Content delivery; Throughput; Quality of
   experience
ID INTERNET; THINGS; MODEL; SDN
AB Information-Centric Networking (ICN) has been recently recognized as a promising future Internet paradigm by providing content-oriented functionality and in-network caching characteristic rather than relying on overlay or end-to-end communication mode. However, the deployment of ICN on the real network is very difficult or even almost impossible at the current stage. In other words, the end-to-end IP network always has the overwhelming development strengths. In spite of this, the end-to-end IP network has no the adequate in-network caching resources to offload the traffic. At the right time, as the essential and significant characteristic of ICN, in-network caching has great potential to be applied into IP network in order to dramatically reduce load pressure of Origin Server (OS). Therefore, we in this paper enable IP network to have the capacity of in-network caching, and on this base, we investigate the comprehensive routing and content delivery. Firstly, the network topology is divided into a number of Autonomous Systems (ASs), and each AS has an Information Management Center (IMC) which has rich functionalities by maintaining Content Index Table (CIT), Physical Topology Index Table (PTIT) and Response Request Table (RRT). Then, CIT is used to conduct both intra-AS routing and explicitly collaborative caching, and PTIT is used to conduct both inter-AS routing and adaptive content delivery including on-path and off-path. In particular, RRT is only sent to OS so that the end-to-end communication connection is switched off. Finally, the experimental results reveal that the proposed scheme can reduce load pressure of OS around 45.7% over Deltacom and 54.8% over GTS. In addition, compared to the previous work, the proposed scheme has better performance.
C1 [Zhang, Songzhu; Wang, Xingwei] Northeastern Univ, Coll Comp Sci & Engn, Shenyang 110819, Peoples R China.
   [Wang, Xingwei] State Key Lab Synthet Automat Proc Ind, Shenyang 110819, Peoples R China.
   [Lv, Jianhui] Tsinghua Univ, Grad Sch Shenzhen, Shenzhen 518057, Peoples R China.
   [Huang, Min] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.
C3 Northeastern University - China; Tsinghua University; Tsinghua Shenzhen
   International Graduate School; Northeastern University - China
RP Wang, XW (corresponding author), Northeastern Univ, Coll Comp Sci & Engn, Shenyang 110819, Peoples R China.; Wang, XW (corresponding author), State Key Lab Synthet Automat Proc Ind, Shenyang 110819, Peoples R China.
EM zhangsongzhu@neuq.edu.cn; wangxw@mail.neu.edu.cn;
   lvjianhui2012@sz.tsinghua.edu.cn; mhuang@mail.neu.edu.cn
RI Zhang, Songzhu/IQU-8070-2023; Min, Huang/KLZ-0497-2024
OI Zhang, Songzhu/0000-0002-6152-5738; 
FU LiaoNing Revitalization Talents Program [XLYC1902010]; Major
   International(Regional) Joint Research Project of NSFC [71620107003];
   National Natural Science Foundation of China [61872073]
FX This work is supported by the LiaoNing Revitalization Talents Program
   under Grant No. XLYC1902010, the Major International(Regional) Joint
   Research Project of NSFC under Grant No. 71620107003, and the National
   Natural Science Foundation of China under Grant No. 61872073.
CR Ascigil O, 2012, P ACM CONEXT, P11
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Bannour F, 2020, FUTURE GENER COMP SY, V113, P78, DOI 10.1016/j.future.2020.05.032
   Bidkar S, 2015, J OPT COMMUN NETW, V7, P445, DOI 10.1364/JOCN.7.000445
   Chen JD, 2020, WIREL NETW, V26, P3159, DOI 10.1007/s11276-019-02007-5
   Chiesa M, 2013, P IEEE ICCCN, P1
   Din IU, 2020, FUTURE GENER COMP SY, V111, P634, DOI 10.1016/j.future.2019.11.022
   Djama A, 2020, COMPUT COMMUN, V159, P37, DOI 10.1016/j.comcom.2020.05.003
   Fernando N, 2013, FUTURE GENER COMP SY, V29, P84, DOI 10.1016/j.future.2012.05.023
   Ghosh A, 2021, WIRELESS PERS COMMUN, V116, P2873, DOI 10.1007/s11277-020-07825-x
   Hongliang Yu, 2006, Operating Systems Review, V40, P333, DOI 10.1145/1218063.1217968
   Jiang XK, 2014, IEEE CONF COMPUT, P440, DOI 10.1109/INFCOMW.2014.6849272
   Julian Benadit P., 2020, Procedia Computer Science, V171, P2435, DOI 10.1016/j.procs.2020.04.263
   Khandaker F, 2019, COMPUT NETW, V165, DOI 10.1016/j.comnet.2019.106937
   Kobayashi N, 2017, INFORM COMPUT, V252, P48, DOI 10.1016/j.ic.2016.03.004
   Kumar S, 2020, COMPUT NETW, V179, DOI 10.1016/j.comnet.2020.107434
   Lv JH, 2017, COMPUT NETW, V123, P88, DOI 10.1016/j.comnet.2017.05.010
   Noh H, 2019, C LOCAL COMPUT NETW, P210, DOI [10.1109/LCN44214.2019.8990762, 10.1109/lcn44214.2019.8990762]
   Thomdapu ST, 2021, COMPUT NETW, V187, DOI 10.1016/j.comnet.2021.107822
   Wu F, 2019, PEER PEER NETW APPL, V12, P789, DOI 10.1007/s12083-018-0679-4
   Wu H, 2019, PROC IEEE S COMPUTER, P1
   Zhang PY, 2018, IEEE T INF FOREN SEC, V13, P2167, DOI 10.1109/TIFS.2018.2812166
   Zhang Z, 2020, IEEE T MULTIMEDIA, V22, P1069, DOI 10.1109/TMM.2019.2935683
   Zhao Jiaming., 2019, International Symposium on Parallel Architectures, Algorithms and Programming, P98
NR 24
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 715
EP 735
DI 10.1007/s11042-021-11359-0
EA SEP 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000696465800003
DA 2024-07-18
ER

PT J
AU Gupta, MK
   Chandra, P
AF Gupta, Manoj Kumar
   Chandra, Pravin
TI Effects of similarity/distance metrics on k-means algorithm with respect
   to its applications in IoT and multimedia: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Internet of things; Data analytics and multimedia; Similarity metrics;
   Distance metrics; K-means algorithm; Clustering; Machine learning
AB Recently, Internet of Things (IoT) and multimedia are gaining popularity because of their usages in various applications. Numerous sensors and automated devices are generating huge volumes of data. Therefore, it is required to efficiently and effectively analyze this voluminous data. It can be achieved by using appropriate machine leaning techniques such as clustering. Among the clustering techniques, the k-means method/algorithm is one of the simplest, effective and commonly used methods. For making the cluster, it uses a measure of similarity/distance among the data observations. Nearby/similar data observations are placed within the same cluster whereas distant/dis-similar data observations are placed in other clusters. Hence, the similarity/distance metric plays a major role on the performance and accuracy of the k-means. Therefore, using an appropriate similarity/distance metric, the performance and accuracy of the k-means can be improved. K-means algorithm is majorly implemented using Euclidean distance metric. With the objective to explore the better and/or alternate similarity/distance metric(s) for k-means, a case study, based on empirical evaluation, of thirteen different similarity/distance metrics on six well-known datasets is performed and presented in this paper. By using the efficient and effective similarity / distance metrics, the performance and accuracy of the k-means algorithm can be improved which leads to formation of good clusters of various data observations or things or images etc. The results of the empirical study are analyzed and compared on the basis of widely used statistical clustering evaluation/validation measures. Based on the comparative results, these metrics are assigned with the ranks. Overall, the results demonstrate that Manhattan and Minkowski distance metrics gives better results for k-means algorithm.
C1 [Gupta, Manoj Kumar; Chandra, Pravin] Guru Gobind Singh Indraprastha Univ, Univ Sch Informat & Commun Technol, Sect 16C, Delhi 110078, India.
   [Gupta, Manoj Kumar] Trinity Inst Innovat Profess Studies, Greater Noida 201310, Uttar Pradesh, India.
C3 GGS Indraprastha University
RP Gupta, MK (corresponding author), Guru Gobind Singh Indraprastha Univ, Univ Sch Informat & Commun Technol, Sect 16C, Delhi 110078, India.; Gupta, MK (corresponding author), Trinity Inst Innovat Profess Studies, Greater Noida 201310, Uttar Pradesh, India.
EM manojkgupta5@gmail.com
RI Chandra, Pravin/ABE-8711-2020
OI Chandra, Pravin/0000-0002-6555-3832
CR Aggarwal CC, 2014, CH CRC DATA MIN KNOW, P1
   An FW, 2013, J SYST ARCHITECT, V59, P155, DOI 10.1016/j.sysarc.2012.11.004
   Arora R. K., 2017, INT J COMPUT APPL, V169, P28, DOI DOI 10.5120/IJCA2017914785
   Bangui H., 2018, IOTBDS, P269, DOI DOI 10.5220/0006773402690276
   Boriah S., 2008, P 8 SIAM INT C DAT M, P243, DOI DOI 10.1137/1.9781611972788.22
   Cha S.-H., 2007, Int. J. Math. Models Methods Appl. Sci., V1, P300
   Choi S.-S., 2010, Systemics, Cybernetics and Informatic, V8, P43
   Deepana R, 2017, INT J STATIST SYST, V12, P421
   Everitt B., 2011, Cluster Analysis, V5
   Gan G, 2007, ASA SIAM SER STAT AP, V20, P1, DOI 10.1137/1.9780898718348
   Gheware, 2014, INT J ADV RES COMPUT, DOI 10.17148/IJARCCE.2014.31003
   Gupta, 2019, P ICACM 2019, P567
   Gupta, 2019, SPRINGER CCIS SERIES, DOI 10.1007/978-981-15-5827_1
   Gupta, 2019, INT J INNOV TECHNOL, DOI 10.35940/ijitee.J9774.0881019
   Gupta, 2019, INT J RECENT TECHNOL, V8, P1140, DOI [10.35940/ijre.D6837.118419, DOI 10.35940/IJRE.D6837.118419]
   GUPTA MK, LNEE, V605, P884
   Gupta MK, 2020, INT J INF TECHNOL, P1
   Gupta P, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA), DOI 10.1109/iccubea47591.2019.9128925
   Halkidi M, 2002, SIGMOD REC, V31, P19, DOI 10.1145/601858.601862
   Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483
   Han J, 2012, MOR KAUF D, P1
   Hinneburg A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining, P58
   Irani J., 2016, International Journal of Computer Applications, V134, P9, DOI DOI 10.5120/IJCA2016907841
   Jain A K, 1988, ALGORITHMS CLUSTERIN
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Kumar JS, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/8739203
   Lee D, 2018, J SUPERCOMPUT, V74, P6859, DOI 10.1007/s11227-018-2288-7
   Liao SH, 2012, EXPERT SYST APPL, V39, P11303, DOI 10.1016/j.eswa.2012.02.063
   More S., 2012, INT J SCI SPIRIT BUS, V1, P49
   Padmini, 2013, INT J ENG RES TECHNO, V2, P2965
   PAVITHRA A., 2018, International Journal for Research Development, V10, No, P271
   Prasath, 2019, DISTANCE SIMILARITY
   Ram MK., 2017, INT J COMPUT SCI TRE, V5, P108
   Rendon E., 2011, INT J COMPUT COMMUN, V5, P27
   Shah, 2020, IMPORTANCE CLUSTER 2
   Shirkhorshidi AS, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144059
   Sholla, 2017, J SCI TECHNOL, V3, P21, DOI DOI 10.31130/JST.2017.61
   Steinmetz R., 2004, Multimedia Applications
   Sung Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18040961
   Torres G., 2008, Proc. World Acad. Sci. Eng. Technol, V31, P490
   Xu D., 2015, Annals of Data Science, V2, P165, DOI [DOI 10.1007/S40745-015-0040-1, 10.1007/s40745-015-0040-1]
   Xu ZS, 2008, INT J UNCERTAIN FUZZ, V16, P529, DOI 10.1142/S0218488508005406
   Xu ZS, 2011, INFORM SCIENCES, V181, P2128, DOI 10.1016/j.ins.2011.01.028
NR 44
TC 10
Z9 11
U1 3
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37007
EP 37032
DI 10.1007/s11042-021-11255-7
EA SEP 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000692967600004
DA 2024-07-18
ER

PT J
AU Lei, BY
   Zeng, XL
   Huang, S
   Zhang, RG
   Chen, GZ
   Zhao, JF
   Wang, TF
   Wang, JT
   Zhang, GM
AF Lei, Baiying
   Zeng, Xianlu
   Huang, Shan
   Zhang, Rugang
   Chen, Guozhen
   Zhao, Jinfeng
   Wang, Tianfu
   Wang, Jiantao
   Zhang, Guoming
TI Automated detection of retinopathy of prematurity by deep attention
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinopathy of prematurity; Deep learning; Attention mechanism;
   Automatic detection
ID INTERNATIONAL CLASSIFICATION; AGREEMENT; DIAGNOSIS
AB Retinopathy of prematurity (ROP) is a retinal vascular proliferative disease principally observed in infants born prematurely with low birth weight. ROP is the leading cause of childhood blindness. Early screening and timely treatment are crucial in preventing ROP blindness. Previous ROP diagnosis lacks clear understanding of the underlying factors and properties that supports the final decision. For this reason, a deep convolutional neural network (DCNN) is developed for automated ROP detection using wide-angle retinal images. Specifically, we first choose ResNet50 as our base architecture and improve the ResNet by adding a channel and a spatial attention module. Then, we utilize a class-discriminative localization technique (i.e., gradient-weighted class activation mapping (Grad-CAM)) to visualize the trained models and realize pathological structure localization. The efficacy of the proposed network is evaluated on two test datasets. Our method obtains a sensitivity of 94.84 % and a specificity of 99.49 % on test set 1 while a sensitivity of 98.03 % and a specificity of 94.55 % on test set 2. Also, the model successfully detects the pathological structures of ROP (e.g., demarcation lines or ridges) in the retina images.
C1 [Lei, Baiying; Huang, Shan; Zhang, Rugang; Chen, Guozhen; Wang, Tianfu] Shenzhen Univ, Natl Reg Key Technol Engn Lab Med Ultrasound, Guangdong Key Lab Biomed Measurements & Ultrasoun, Sch Biomed Engn,Hlth Sci Ctr, Nanhai Ave 3688, Shenzhen 518060, Guangdong, Peoples R China.
   [Zeng, Xianlu; Zhao, Jinfeng; Wang, Jiantao; Zhang, Guoming] Jinan Univ, Shenzhen Univ, Shenzhen Key Ophthalm Lab, Hlth Sci Ctr,Shenzhen Eye Hosp,Affiliated Hosp 2, Shenzhen, Peoples R China.
C3 Shenzhen University; Jinan University; Shenzhen University; Shenzhen Eye
   Hospital
RP Wang, JT; Zhang, GM (corresponding author), Jinan Univ, Shenzhen Univ, Shenzhen Key Ophthalm Lab, Hlth Sci Ctr,Shenzhen Eye Hosp,Affiliated Hosp 2, Shenzhen, Peoples R China.
EM 1021235537@qq.com; 13823509060@163.com
RI Lei, Baiying/GQO-8422-2022; Lei, Baiying/AAY-5515-2020; Xi,
   Yang/KEH-5204-2024; ying, liu/KEI-0478-2024; Lei, Baiying/GRE-9741-2022
OI Lei, Baiying/0000-0002-3087-2550; Lei, Baiying/0000-0002-3087-2550; Lei,
   Baiying/0000-0002-3087-2550
FU Shenzhen Key Medical Discipline Construction Fund [SZXK038]; Shenzhen
   Fund for Guangdong Provincial High-level Clinical Key Specialties
   [SZGSP014]; Shenzhen-Hong Kong Co-financing Project
   [SGDX20190920110403741]; Guangdong Basic and Applied Basic Research
   Foundation [2019A1515111205]
FX This work was supported partly by Shenzhen Key Medical Discipline
   Construction Fund (No. SZXK038), Shenzhen Fund for Guangdong Provincial
   High-level Clinical Key Specialties (No.SZGSP014), Shenzhen-Hong Kong
   Co-financing Project (No.SGDX20190920110403741), and Guangdong Basic and
   Applied Basic Research Foundation (No. 2019A1515111205).
CR [Anonymous], 1987, Arch Ophthalmol, V105, P906
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Brown JM, 2018, JAMA OPHTHALMOL, V136, P803, DOI 10.1001/jamaophthalmol.2018.1934
   Burlina PM, 2017, JAMA OPHTHALMOL, V135, P1170, DOI 10.1001/jamaophthalmol.2017.3782
   Chen LL, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P349, DOI 10.1145/3126686.3126723
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen Y, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116669
   Chiang MF, 2007, ARCH OPHTHALMOL-CHIC, V125, P875, DOI 10.1001/archopht.125.7.875
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Diaz M, 2019, PATTERN RECOGN LETT, V128, P204, DOI 10.1016/j.patrec.2019.08.018
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   GARNER A, 1984, ARCH OPHTHALMOL-CHIC, V102, P1130
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gole GA, 2005, ARCH OPHTHALMOL-CHIC, V123, P991, DOI 10.1001/archopht.123.7.991
   Good WV, 2010, ARCH OPHTHALMOL-CHIC, V128, P663, DOI 10.1001/archophthalmol.2010.72
   Good WV, 2003, ARCH OPHTHALMOL-CHIC, V121, P1684
   Gschliesser A, 2015, AM J OPHTHALMOL, V160, P553, DOI 10.1016/j.ajo.2015.05.016
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hellström A, 2013, LANCET, V382, P1445, DOI 10.1016/S0140-6736(13)60178-6
   Hu JJ, 2019, IEEE T MED IMAGING, V38, P269, DOI 10.1109/TMI.2018.2863562
   Hutchinson AK, 2016, OPHTHALMOLOGY, V123, P804, DOI 10.1016/j.ophtha.2015.11.003
   Jia X, 2016, INT C PATT RECOG, P77, DOI 10.1109/ICPR.2016.7899611
   Khan MA., 2021, SIGNAL IMAGE PROCESS, P1
   Khan MA, 2020, IEEE ACCESS, V8, P132850, DOI 10.1109/ACCESS.2020.3010448
   Kim SJ, 2018, SURV OPHTHALMOL, V63, P618, DOI 10.1016/j.survophthal.2018.04.002
   Kimyon S, 2018, OPHTHALMOLOGICA, V240, P99, DOI 10.1159/000489023
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liaqat A, 2020, CURR MED IMAGING, V16, P1229, DOI 10.2174/1573405616666200425220513
   Liu MH, 2018, FRONT NEUROINFORM, V12, DOI 10.3389/fninf.2018.00035
   Long EP, 2017, NAT BIOMED ENG, V1, DOI 10.1038/s41551-016-0024
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Majid A, 2020, MICROSC RES TECHNIQ, V83, P562, DOI 10.1002/jemt.23447
   Masumoto H, 2018, J GLAUCOMA, V27, P647, DOI 10.1097/IJG.0000000000000988
   Quinn GE, 2010, CHINESE MED J-PEKING, V123, P2929, DOI 10.3760/cma.j.issn.0366-6999.2010.20.033
   Rao JM, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21771-6
   Roy AG, 2019, IEEE T MED IMAGING, V38, P540, DOI 10.1109/TMI.2018.2867261
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Ting DSW, 2019, BRIT J OPHTHALMOL, V103, P577, DOI 10.1136/bjophthalmol-2018-313290
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang JY, 2018, EBIOMEDICINE, V35, P361, DOI 10.1016/j.ebiom.2018.08.033
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu C, 2006, J AAPOS, V10, P107, DOI 10.1016/j.jaapos.2005.11.019
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zahoor S, 2020, CURR MED IMAGING, V16, P1187, DOI 10.2174/1573405616666200406110547
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang YS, 2019, IEEE ACCESS, V7, P10232, DOI 10.1109/ACCESS.2018.2881042
   Zheng X, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2019.107147
NR 55
TC 10
Z9 11
U1 3
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36341
EP 36360
DI 10.1007/s11042-021-11208-0
EA SEP 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000692489400001
DA 2024-07-18
ER

PT J
AU Pramanik, J
   Samal, AK
   Pani, SK
   Chakraborty, C
AF Pramanik, Jitendra
   Samal, Abhaya Kumar
   Pani, Subhendu Kumar
   Chakraborty, Chinmay
TI Elementary framework for an IoT based diverse ambient air quality
   monitoring system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things (IoT); Wireless sensor network (WSN); MEMS
   (micro-electromechanical system) technology; Early warning system;
   Mining safety; Ambient air quality; Mine sensor network (MSN)
ID DESIGN; MEMS
AB The underground mine environment presents a highly confined workspace. The ambiance in this confined space plays a crucial role in maintaining and ensuring good occupational health. In any working environment, deterioration in the ambient air quality presents a global challenge to improve. The traditional approach of air quality monitoring involves large and expensive scientific equipment permanently installed and professionally maintained as an arrangement in specialized laboratories in selected locations. These labs monitor and measure air quality based on the samples collected from fields. Advances in micro-electro-mechanical system technology, internet of things (IoT) platform, Wireless sensor network and energy-efficient telecommunication infrastructure have led to the emergence of low-cost, miniature, and efficient sensors based embedded systems, capable of measuring and monitoring ambient air quality in real-time. IoT-enabled sensors can provide vital ambiance data on a real-time basis in a simple form yet accurate enough to help perceive the environment and take necessary corrective measures to improve quality or predict possible ensuing hazards to plan safety measures. This study presents a precursor work leading towards the design of IoT enabled ambient air quality monitoring system to track the presence of toxic gaseous elements in the atmosphere of underground coal mine and monitor the degree of adherence of ambiance quality parameters to the set standards on a real-time basis so that the presence of any specific environment pollutant susceptible to cause hazardous health conditions and risk human life due to presence of poisonous gaseous elements.
C1 [Pramanik, Jitendra] Centurion Univ Technol & Management, Bhubaneswar, Odisha, India.
   [Samal, Abhaya Kumar] Trident Acad Technol, Bhubaneswar, India.
   [Pani, Subhendu Kumar] BPUT, Krupajal Comp Acad, Bhubaneswar, Odisha, India.
   [Chakraborty, Chinmay] Birla Inst Technol, Mesra, Jharkhand, India.
C3 Centurion University of Technology & Management; Trident Academy of
   Technology; Birla Institute of Technology Mesra
RP Chakraborty, C (corresponding author), Birla Inst Technol, Mesra, Jharkhand, India.
EM jitendra.pramanik@cutm.ac.in; abhaya@tat.ac.in; skpani.india@gmail.com;
   cchakrabarty@bitmesra.ac.in
RI Pani, Subhendu kumar/AAX-9596-2021; Chakraborty, Chinmay/N-3608-2017;
   Pramanik, Jitendra/ABH-1036-2020
OI Pani, Subhendu kumar/0000-0001-9595-0567; Chakraborty,
   Chinmay/0000-0002-4385-0975; Pramanik, Jitendra/0000-0001-7862-3599;
   Samal, Dr. Abhaya Kumar/0000-0002-5007-760X
CR [Anonymous], EVOLUTION GAS SENSOR
   [Anonymous], THERE MUST BE SOMETH
   [Anonymous], 2018, Air Quality Monitoring Using IoT and Big Data A Value Generation Guide for Mobile Operators February 2018
   [Anonymous], MINE GASES
   [Anonymous], GASES SUBSURFACE OPE
   Ciuti G, 2015, SENSORS-BASEL, V15, P6441, DOI 10.3390/s150306441
   Doni A., 2018, Indian J. Sci. Res., V17, P147
   Guo C., 2020, ADV CIV ENG, V2020, P16
   Henriques V, 2016, IEEE ACCESS, V4, P3511, DOI 10.1109/ACCESS.2016.2581844
   Huff M A., 2017, Internet of Things and Data Analytics Handbook, P147, DOI [10.1002/9781119173601.ch9, DOI 10.1002/9781119173601.CH9]
   Judy JW, 2001, SMART MATER STRUCT, V10, P1115, DOI 10.1088/0964-1726/10/6/301
   Khanna A, 2020, WIRELESS PERS COMMUN, V114, P1687, DOI 10.1007/s11277-020-07446-4
   Malinowski A, 2011, IEEE T IND INFORM, V7, P244, DOI 10.1109/TII.2011.2124466
   Moridi, 2015, 11 IR 2 REG TUNN C, P19
   Moridi MA, 2018, TUNN UNDERGR SP TECH, V73, P127, DOI 10.1016/j.tust.2017.12.015
   Osunmakinde IO, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/159273
   Ranjan A., 2016, International Journal of Applied Evolutionary Computation (IJAEC), V7, P1, DOI DOI 10.4018/IJAEC.2016100101
   Ranjan A, 2020, MEASUREMENT, V149, DOI 10.1016/j.measurement.2019.106980
   Shi W, 2009, 2009 INTERNATIONAL CONFERENCE ON INDUSTRIAL MECHATRONICS AND AUTOMATION, P225, DOI 10.1109/ICIMA.2009.5156601
   Singh J, 2013, INT J INNOV RES ELEC, V1, P425
   Spachos P, 2016, IEEE SENS J, V16, P506, DOI 10.1109/JSEN.2015.2479647
   Syafrudin M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092946
   Tan AP, 2020, IEEE ACCESS, V8, P775, DOI 10.1109/ACCESS.2019.2959659
   Tan W, 2007, 2007 INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, P148, DOI 10.1109/ICIA.2007.4295715
   Weber Rolf H., 2010, Computer Law and Security Report, V26, P23, DOI 10.1016/j.clsr.2009.11.008
   Zhang XD, 2014, CHIN CONT DECIS CONF, P4112, DOI 10.1109/CCDC.2014.6852901
NR 26
TC 11
Z9 11
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 36983
EP 37005
DI 10.1007/s11042-021-11285-1
EA SEP 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000692075600001
DA 2024-07-18
ER

PT J
AU Kundu, R
   Singh, PK
   Ferrara, M
   Ahmadian, A
   Sarkar, R
AF Kundu, Rohit
   Singh, Pawan Kumar
   Ferrara, Massimiliano
   Ahmadian, Ali
   Sarkar, Ram
TI ET-NET: an ensemble of transfer learning models for prediction of
   COVID-19 infection through chest CT-scan images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19 screening; Computer-aided detection; Deep learning;
   Coronavirus; Transfer learning; Bagging ensemble classifier; CT-scan
   image
ID CLASSIFICATION
AB The COVID-19 virus has caused a worldwide pandemic, affecting numerous individuals and accounting for more than a million deaths. The countries of the world had to declare complete lockdown when the coronavirus led to community spread. Although the real-time Polymerase Chain Reaction (RT-PCR) test is the gold-standard test for COVID-19 screening, it is not satisfactorily accurate and sensitive. On the other hand, Computer Tomography (CT) scan images are much more sensitive and can be suitable for COVID-19 detection. To this end, in this paper, we develop a fully automated method for fast COVID-19 screening by using chest CT-scan images employing Deep Learning techniques. For this supervised image classification problem, a bootstrap aggregating or Bagging ensemble of three transfer learning models, namely, Inception v3, ResNet34 and DenseNet201, has been used to boost the performance of the individual models. The proposed framework, called ET-NET, has been evaluated on a publicly available dataset, achieving 97.81 +/- 0.53% accuracy, 97.77 +/- 0.58% precision, 97.81 +/- 0.52% sensitivity and 97.77 +/- 0.57% specificity on 5-fold cross-validation outperforming the state-of-the-art method on the same dataset by 1.56%. The relevant codes for the proposed approach are accessible in: https://github.com/Rohit-Kundu/ET-NET_Covid-Detection
C1 [Kundu, Rohit] Jadavpur Univ, Dept Elect Engn, Kolkata 700032, India.
   [Singh, Pawan Kumar] Jadavpur Univ, Dept Informat Technol, Kolkata 700106, India.
   [Ferrara, Massimiliano] Mediterranea Univ Reggio Calabria, Dept Law, Econ & Human Sci & Decis Lab, I-89125 Reggio Di Calabria, Italy.
   [Ferrara, Massimiliano] Bocconi Univ, Invernizzi Ctr Res Innovat Org Strategy & Entrepr, Dept Management & Technol, ICRIOS, Via Sarfatti 25, I-20136 Milan, MI, Italy.
   [Ahmadian, Ali] Natl Univ Malaysia, Inst IR 40, Ukm 43600, Selangor, Malaysia.
   [Ahmadian, Ali] Near East Univ, Dept Math, Nicosia TRNC, Mersin 10, Turkey.
   [Ahmadian, Ali] Univ Putra Malaysia, Inst Math Res, Seri Kembangan 43400, Selangor, Malaysia.
   [Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
C3 Jadavpur University; Jadavpur University; Universita Mediterranea di
   Reggio Calabria; Bocconi University; Near East University; Universiti
   Putra Malaysia; Jadavpur University
RP Ahmadian, A (corresponding author), Natl Univ Malaysia, Inst IR 40, Ukm 43600, Selangor, Malaysia.; Ahmadian, A (corresponding author), Near East Univ, Dept Math, Nicosia TRNC, Mersin 10, Turkey.; Ahmadian, A (corresponding author), Univ Putra Malaysia, Inst Math Res, Seri Kembangan 43400, Selangor, Malaysia.
EM ali.ahmadian@ukm.edu.my
RI Ahmadian, Ali/N-3697-2015; Kundu, Rohit/AAV-5810-2021; SINGH, PAWAN
   KUMAR/E-3408-2013; Ferrara, Massimiliano/P-8797-2014; Sarkar,
   Ram/AAX-3822-2020; Senu, Norazak/G-2776-2014
OI Ahmadian, Ali/0000-0002-0106-7050; Kundu, Rohit/0000-0001-8665-8898;
   SINGH, PAWAN KUMAR/0000-0002-9598-7981; Ferrara,
   Massimiliano/0000-0002-3663-836X; Sarkar, Ram/0000-0001-8813-4086; Senu,
   Norazak/0000-0001-8614-8281
FU Ministry of Higher Education, Malaysia [FRGS/1/2018/STG06/UPM/02/6]
FX This research did not receive any specific grant from funding agencies
   in the public, commercial, or not-for-profit sectors. This research was
   financially supported for Ali Ahmadian by the Ministry of Higher
   Education, Malaysia with Fundamental Research Grant Scheme (FRGS) with
   the reference no FRGS/1/2018/STG06/UPM/02/6.
CR Abdel-Basset M, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106647
   Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   Agarap A. F., 2018, ARXIV
   AlHasan M, 2006, SDM06, P798
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Angelov P, 2020, EXPLAINABLE BY DESIG, DOI DOI 10.1101/2020.04.24.20078584
   [Anonymous], 1995, Backpropagation: theory, architectures, and applications
   Banerjee A, 2021, IEEE T CIRC SYST VID, V31, P2206, DOI 10.1109/TCSVT.2020.3019293
   Breiman L, 1996, MACH LEARN, V24, P49
   Bühlmann P, 2007, STAT SCI, V22, P477, DOI 10.1214/07-STS242
   Bühlmann P, 2003, RECENT ADVANCES AND TRENDS IN NONPARAMETRIC STATISTICS, P19, DOI 10.1016/B978-044451378-6/50002-8
   Chattopadhyay S, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11020315
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Das S, 2021, BIG DATA RES, V25, DOI 10.1016/j.bdr.2021.100233
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Fang YC, 2020, RADIOLOGY, V296, pE115, DOI 10.1148/radiol.2020200432
   FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7
   Fukushima S., 1982, inCompetition and Cooperation in Neural Nets, P267, DOI 10.1007/978-3-642-46466-9_18
   Garain A, 2021, NEURAL COMPUT APPL, V33, P12591, DOI 10.1007/s00521-021-05910-1
   Ghahramani Z., 1994, ADV NEURAL INFORM PR, P120
   Gozes O., 2020, RAPID AI DEV CYCLE C
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Pham H, 2019, COMPUT INTELL-US, V35, P184, DOI 10.1111/coin.12198
   Hoeting JA, 1999, STAT SCI, V14, P382, DOI 10.1214/ss/1009212519
   Huang G, 2022, IEEE T PATTERN ANAL, V44, P8704, DOI 10.1109/TPAMI.2019.2918284
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jaiswal A, 2021, J BIOMOL STRUCT DYN, V39, P5682, DOI 10.1080/07391102.2020.1788642
   Karbhari Y, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11050895
   Li L., 2020, Radiology, V296, DOI 10.1148/radiol.2020200905
   Li ZT, 2020, J MED VIROL, V92, P1518, DOI [10.1002/jmv.25727, 10.12052/gdutxb.200076]
   Mannor S., 2005, P 22 INT C MACH LEAR, P561
   Masood A, 2018, J BIOMED INFORM, V79, P117, DOI 10.1016/j.jbi.2018.01.005
   Mathieu E, 2021, NAT HUM BEHAV, V5, P947, DOI 10.1038/s41562-021-01122-8
   Opitz D., 1999, J ARTIF INTELL RES, V11, P169, DOI DOI 10.1613/JAIR.614
   Panwar H, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110190
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760
   Sen S, 2021, APPL INTELL, V51, P8985, DOI 10.1007/s10489-021-02292-8
   Silva Pedro, 2020, Inform Med Unlocked, V20, P100427, DOI 10.1016/j.imu.2020.100427
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soares E., 2020, medRxiv, V10, P1
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tahamtan A, 2020, EXPERT REV MOL DIAGN, V20, P453, DOI 10.1080/14737159.2020.1757437
   WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Wang Z, 2020, IEEE J BIOMED HEALTH, V24, P2806, DOI 10.1109/JBHI.2020.3023246
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Yamaguchi K., 1990, 1 INT C SPOK LANG PR
   Yang Y, 2020, INNOVATION-AMSTERDAM, V1, DOI 10.1016/j.xinn.2020.100061
   YAP JCH, 2020, NUS LIB
   Zhang JQ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2831, DOI 10.1145/3394486.3403334
   Zhang JY, 2020, ETHIOP J HEALTH DEV, V34
   ZHANG W, 1990, APPL OPTICS, V29, P4790, DOI 10.1364/AO.29.004790
NR 58
TC 49
Z9 50
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 31
EP 50
DI 10.1007/s11042-021-11319-8
EA AUG 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000691163200002
PM 34483709
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Ray, B
   Mukhopadhyay, S
   Hossain, S
   Ghosal, SK
   Sarkar, R
AF Ray, Biswarup
   Mukhopadhyay, Souradeep
   Hossain, Sabbir
   Ghosal, Sudipta Kr
   Sarkar, Ram
TI Image steganography using deep learning based edge detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Edge detection; LSB; CNN; Deep learning
ID LAPLACIAN
AB This paper introduces a deep learning-based Steganography method for hiding secret information within the cover image. For this, we use a convolutional neural network (CNN) with Deep Supervision based edge detector, which can retain more edge pixels over conventional edge detection algorithms. Initially, the cover image is pre-processed by masking the last 5-bits of each pixel. The said edge detector model is then applied to obtain a gray-scale edge map. To get the prominent edge information, the gray-scale edge map is converted into a binary version using both global and adaptive binarization schemes. The purpose of using different binarization techniques is to prove the less sensitive nature of the edge detection method to the thresholding approaches. Our rule for embedding secret bits within the cover image is as follows: more bits into the edge pixels while fewer bits into the non-edge pixels. Experimental outcomes on various standard images confirm that compared to state-of-the-art methods, the proposed method achieves a higher payload.
C1 [Ray, Biswarup; Mukhopadhyay, Souradeep; Hossain, Sabbir; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
   [Ghosal, Sudipta Kr] Nalhati Govt Polytech, Dept Comp Sci & Technol, Birbhum 731243, India.
C3 Jadavpur University
RP Ghosal, SK (corresponding author), Nalhati Govt Polytech, Dept Comp Sci & Technol, Birbhum 731243, India.
EM sudipta.ghosal@gmail.com
RI Sarkar, Ram/AAX-3822-2020
OI Sarkar, Ram/0000-0001-8813-4086; Ray, Biswarup/0000-0002-7378-0920
CR Abdulla AA, 2015, THESIS BUCKINGHAM U
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Abdulla AA, 2013, PROC SPIE, V8755, DOI 10.1117/12.2018994
   Akhtar N, 2017, COMPRESSED LSB STEGA
   Bhattacharyya D, 2011, COMM COM INF SC, V151, P315
   Boehm Benedikt, 2014, ARXIV14106656
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chandwadkar R, 2013, 6 ANN C IRAJ
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Dhargupta S, 2019, MULTIMED TOOLS APPL, V78, P17589, DOI 10.1007/s11042-018-7123-x
   Dube RR., 2016, INT J SCI RES, V5, P1976, DOI DOI 10.21275/V5I6.NOV164686
   Dumitrescu S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P641, DOI 10.1109/ICIP.2002.1039052
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   El-Sayed MA, 2013, INT J ADV COMPUT SC, V4, P11
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Ghosal SK, 2018, MULTIMED TOOLS APPL, V77, P30403, DOI 10.1007/s11042-018-6126-y
   Ghosal SK, 2021, COMPUT ELECTR ENG, V89, DOI 10.1016/j.compeleceng.2020.106964
   Ghosal SK, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3984
   Ghosal SK, 2021, MULTIMEDIA SYST, V27, P73, DOI 10.1007/s00530-020-00703-3
   Gujjunoori S, 2019, MULTIMED TOOLS APPL, V78, P25889, DOI 10.1007/s11042-019-07767-y
   Hosam O, 2016, SECUR COMMUN NETW, V9, P5036, DOI 10.1002/sec.1676
   Islam S, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-8
   Ismail, 2018, INT C EL CONTR OPT C
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2179, DOI 10.1007/s11042-014-2081-4
   Lee, 2010, 2010 4 INT C GEN EV
   Ma X., 2012, Artificial Intelligence and Computational Intelligence, P50
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mathur N, 2016, PROCEDIA COMPUT SCI, V93, P431, DOI 10.1016/j.procs.2016.07.230
   Mukherjee N, 2018, MULTIMED TOOLS APPL, V77, P18451, DOI 10.1007/s11042-018-5720-3
   Mukhopadhyay S, 2021, MULTIMED TOOLS APPL, V80, P14495, DOI 10.1007/s11042-020-10424-4
   Pak C, 2020, MULTIMED TOOLS APPL, V79, P1409, DOI 10.1007/s11042-019-08103-0
   Setiadi DIM, 2018, CYBERN INF TECHNOL, V18, P74, DOI 10.2478/cait-2018-0029
   Shanthakumari R, 2020, MULTIMED TOOLS APPL, V79, P3975, DOI 10.1007/s11042-019-7584-6
   Shin N, 2000, LECT NOTES COMPUTER, V1768, DOI 10.1007/10719724_2
   Shrivakshan G., 2012, INT J COMPUT SCI ISS, V9, P269
   Simonyan K., 2014, CORR
   Soria X, 2020, IEEE WINT CONF APPL, P1912, DOI 10.1109/WACV45572.2020.9093290
   Stanley, 2005, PAIRS VALUES CHI SQU, P1
   Suneetha D., 2017, INT J APPL ENG RES, V12, P5565
   Tseng HW, 2014, IET IMAGE PROCESS, V8, P647, DOI 10.1049/iet-ipr.2013.0584
   Wang X, 2007, IEEE T PATTERN ANAL, V29, P886, DOI 10.1109/TPAMI.2007.1027
   Wang Y, 2017, IETE TECH REV, V34, P3, DOI 10.1080/02564602.2016.1139475
   Weber A., 1997, The usc-sipi image database
   Wibisono JK, 2020, IEEE IMAGE PROC, P678, DOI 10.1109/ICIP40778.2020.9190982
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xue C, 2019, IEEE 8 JOINT INT INF
   Yang L, 2011, 2011 4 INT C IM SIGN
   Younus ZS, 2022, J KING SAUD UNIV-COM, V34, P2951, DOI 10.1016/j.jksuci.2019.04.008
   Zhang Z, 2009, COMPUT MATH APPL, V57, P1265, DOI 10.1016/j.camwa.2008.11.013
   Zou Y, 2019, J VIS COMMUN IMAGE R, V60, P266, DOI 10.1016/j.jvcir.2019.02.034
NR 50
TC 24
Z9 24
U1 3
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33475
EP 33503
DI 10.1007/s11042-021-11177-4
EA AUG 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000686512900004
DA 2024-07-18
ER

PT J
AU An, FP
   Liu, JE
AF An, Fengping
   Liu, Jun-e
TI Remote sensing image classification algorithm based on ridge wave sparse
   collaborative representation convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Ridge wave self-encoder; Sparse collaborative
   representation; Ridge wave convolutional neural network; Remote sensing
   image classification
ID SEGMENTATION; MODEL
AB Remote sensing image classification is a crucial link when processing remote sensing images. Through classification, remote sensing images are converted into classified features that can be understood and processed by computers running deep applications. However, the traditional remote sensing image classification methods do not meet the actual application requirements. In recent years, the rapid development of deep learning theory has provided a technical approach for solving remote sensing image classification. However, deep learning has the following problems when applied to remote sensing image classification: First, it is impossible to construct an activation function suitable for deep learning models that matches the characteristics of remote sensing images; second, the deep learning classification models have poor effects. In view of this, this paper first studies the activation function and constructs ridge waves with scale, displacement, and direction information. Because a ridge wave has good compact support characteristics, it can more closely approximate the high-dimensional nonlinear decision function and obtain a more effective activation function, thus solving the activation function problem in deep learning modeling. At the same time, to optimize the classifiers included in deep learning models, this paper proposes a sparse collaborative representation classifier that more fully combines the advantages of sparse representation classifiers and collaborative representation classifiers. It can yield the relationship between the competition and the collaboration of the remote sensing image to be classified and better use the characteristics of the remote sensing image, achieving better classification effect. Based on the above ideas, this paper proposes a remote sensing image classification algorithm based on a ridge wave sparse collaborative representation convolutional neural network. Finally, the method in this paper is verified by experiments on "UC Merced Land Use Dataset" and "RSSCN7 Dataset". The results show that the average accuracy of the method proposed in this paper is significantly higher than that of machine learning and other deep learning methods, and the method in this paper has better stability and robustness.
C1 [An, Fengping] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.
   [An, Fengping] Huaiyin Normal Univ, Sch Phys Elect Elect Engn, Huaian 223300, Peoples R China.
   [Liu, Jun-e] Beijing Wuzi Univ, Sch Informat, Beijing 100061, Peoples R China.
C3 Beijing Institute of Technology; Huaiyin Normal University; Beijing Wuzi
   University
RP An, FP (corresponding author), Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.; An, FP (corresponding author), Huaiyin Normal Univ, Sch Phys Elect Elect Engn, Huaian 223300, Peoples R China.
EM anfengping@bit.edu.cn
OI AN, FENGPING/0000-0002-2220-2987
FU Natural Science Foundation of Jiangsu Province [BK20201479]; National
   Natural Science Foundation of China [61701188]; China Postdoctoral
   Science Foundation [2019M650512]; Natural Science Foundation of Shanxi
   [201801D221171]
FX This work was supported in part by Natural Science Foundation of Jiangsu
   Province (No. BK20201479), National Natural Science Foundation of China
   (No. 61701188), China Postdoctoral Science Foundation (No. 2019M650512),
   and Natural Science Foundation of Shanxi (No. 201801D221171).
CR Ben Hamida A, 2018, IEEE T GEOSCI REMOTE, V56, P4420, DOI 10.1109/TGRS.2018.2818945
   Chen TCT, 2020, NEURAL COMPUT APPL, V32, P7057, DOI 10.1007/s00521-019-04211-y
   Chen WS, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010110
   Chen YQ, 2017, IEEE T GEOSCI REMOTE, V55, P6683, DOI 10.1109/TGRS.2017.2727067
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Fang LY, 2017, IEEE T INSTRUM MEAS, V66, P1646, DOI 10.1109/TIM.2017.2664480
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Hou B, 2016, IEEE GEOSCI REMOTE S, V13, P33, DOI 10.1109/LGRS.2015.2493242
   Jiang JJ, 2017, IEEE GEOSCI REMOTE S, V14, P404, DOI 10.1109/LGRS.2016.2645708
   Li W, 2015, IEEE GEOSCI REMOTE S, V12, P48, DOI 10.1109/LGRS.2014.2325978
   Li W, 2014, IEEE J-STARS, V7, P2200, DOI 10.1109/JSTARS.2014.2306956
   Li YS, 2016, IEEE GEOSCI REMOTE S, V13, P157, DOI 10.1109/LGRS.2015.2503142
   Lillesand T. M., 2004, REMOTE SENSING IMAGE
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Haut JM, 2018, IEEE T GEOSCI REMOTE, V56, P6440, DOI 10.1109/TGRS.2018.2838665
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Qi KL, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060934
   Ratha D, 2018, IEEE GEOSCI REMOTE S, V15, P151, DOI 10.1109/LGRS.2017.2778749
   Rezaee M, 2018, IEEE J-STARS, V11, P3030, DOI 10.1109/JSTARS.2018.2846178
   Romero A, 2016, IEEE T GEOSCI REMOTE, V54, P1349, DOI 10.1109/TGRS.2015.2478379
   Song WY, 2017, IEEE J-STARS, V10, P3556, DOI 10.1109/JSTARS.2017.2684301
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Weng Q, 2017, IEEE GEOSCI REMOTE S, V14, P704, DOI 10.1109/LGRS.2017.2672643
   Wu H, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8050436
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xie W, 2017, IEEE J-STARS, V10, P3604, DOI 10.1109/JSTARS.2017.2698076
   Yusuf A, 2018, CAN J REMOTE SENS, V44, P532, DOI 10.1080/07038992.2018.1559725
   Zhang C, 2018, ISPRS J PHOTOGRAMM, V140, P133, DOI 10.1016/j.isprsjprs.2017.07.014
   Zhang LM, 2015, IEEE J-STARS, V8, P3923, DOI 10.1109/JSTARS.2014.2359459
   Zhao LJ, 2019, MULTIMED TOOLS APPL, V78, P9667, DOI 10.1007/s11042-018-6548-6
   Zhong N, 2017, IEEE T GEOSCI REMOTE, V55, P5381, DOI 10.1109/TGRS.2017.2707243
   Zou Q, 2015, IEEE GEOSCI REMOTE S, V12, P2321, DOI 10.1109/LGRS.2015.2475299
NR 35
TC 1
Z9 1
U1 3
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 33099
EP 33114
DI 10.1007/s11042-021-11406-w
EA AUG 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000684785000006
DA 2024-07-18
ER

PT J
AU Han, Y
   Chang, QY
   Ding, SM
   Gao, MJ
   Zhang, BZ
   Li, SY
AF Han, Ying
   Chang, Qiuyue
   Ding, Shuaimin
   Gao, Meijing
   Zhang, Bozhi
   Li, Shiyu
TI Research on multiple jellyfish classification and detection based on
   deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Jellyfish detection; Image preprocessing; Deep learning; Convolutional
   neural network
ID COLOR; AGGREGATIONS
AB In recent years, there have been frequent jellyfish outbreaks in many offshore areas worldwide, which have severely affected marine fishery production, coastal tourism, coastal industrial cooling water systems, and marine ecology. Achieving the monitoring of jellyfish plays a vital role in solving the problems mentioned above. However, the research on jellyfish is still in the primary stage. Jellyfish detection technology based on deep learning is gradually being applied to jellyfish detection due to its high efficiency and accuracy, but it is not systematic enough and can identify few jellyfish species. So this paper studies a jellyfish detection algorithm based on deep learning. Based on convolution neural network theory and digital image processing technology, 10 species of jellyfish and fish are detected. Because the quality of underwater images affects the detection accuracy, to further improve the accuracy of the detection algorithm, this paper studies the underwater image processing algorithm. Experimental results show that the image quality is better after applying the three algorithms of dark channel prior algorithm, quadratic combining gray world and perfect reflection algorithm, and contrast-limited adaptive histogram equalization algorithm, which is more conducive to detection. Then, deep learning theory is applied to classify jellyfish. By comparing the AlexNet and GoogLeNet backbone networks' classification results, the accuracy of the jellyfish classification task based on the GoogLeNet backbone network is 96.21%, which is better than AlexNet. Finally, the Faster R-CNN algorithm is used to detect jellyfish, and its detection performance is analyzed based on the two backbone networks mentioned above. The results show that the Faster R-CNN algorithm based on GoogLeNet has a higher detection accuracy in the jellyfish detection task, with an average detection accuracy of 74.96%. In addition, we set up a new jellyfish data set, which includes 25,344 images. The images were divided into 11 species, including 10 species of jellyfish and one fish species. The paper's research lays a theoretical and technical foundation for the subsequent construction of a real-time monitoring system for underwater jellyfish optical imaging, plays an important role in the development of jellyfish monitoring technology, and provides valuable information for marine biologists.
C1 [Han, Ying; Chang, Qiuyue; Ding, Shuaimin; Gao, Meijing; Zhang, Bozhi; Li, Shiyu] Yanshan Univ, Sch Informat Sci & Engn, Key Lab Special Fiber & Fiber Sensor Hebei Prov, Qinhuangdao, Hebei, Peoples R China.
C3 Yanshan University
RP Gao, MJ (corresponding author), Yanshan Univ, Sch Informat Sci & Engn, Key Lab Special Fiber & Fiber Sensor Hebei Prov, Qinhuangdao, Hebei, Peoples R China.
EM gaomeijing@126.com
FU National Key Research and Development Plan [2019YFC1407904]; National
   Nature Science Foundation of China [61971373]; Natural Science
   Foundation of Hebei Province - China [F2019203440, C2020203010]; Science
   and Technology Support Projects of Key research and Development Plans of
   Qinhuangdao City - China [201801B010]; China Scholarship Council
FX Thank to Professor Paul L. Rosin and Xianfang Sun (Cardiff University)
   for participating in writing and technical editing of the manuscript.
   This work was supported by National Key Research and Development Plan
   (2019YFC1407904) and National Nature Science Foundation of China
   (61971373) and Natural Science Foundation of Hebei Province - China
   (F2019203440, C2020203010) and Science and Technology Support Projects
   of Key research and Development Plans of Qinhuangdao City - China
   (201801B010). The authors gratefully acknowledge funding support from
   the China Scholarship Council.
CR BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Colombo GA, 2003, ICES J MAR SCI, V60, P650, DOI 10.1016/S1054-3139(03)00051-1
   Dong Jing, 2005, Fisheries Science (Liaoning), V24, P22
   French G, 2018, INT CONF SIGN PROCES, P406, DOI 10.1109/ICSP.2018.8652268
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gould RW, 1999, APPL OPTICS, V38, P2377, DOI 10.1364/AO.38.002377
   Han Q., 2009, Inf Technol, V33, P55
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Houghton JDR, 2006, MAR ECOL PROG SER, V314, P159, DOI 10.3354/meps314159
   Hu B, 2015, Underwater image color correction based on image-fusion method
   Kim D, 2016, INT J CONTROL AUTOM, V14, P312, DOI 10.1007/s12555-014-0305-z
   Kim H, 2015, INT CONF UBIQ ROBOT, P495, DOI 10.1109/URAI.2015.7358813
   Kim S, 2016, OCEAN SCI J, V51, P59, DOI 10.1007/s12601-016-0006-z
   Koo J, 2017, IEEE OES INT S UND T
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Martin-Abadal M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061708
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rong S., 2012, Inf Technol, V36, P85
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vodopivec M, 2018, J SEA RES, V142, P147, DOI 10.1016/j.seares.2018.09.014
   Wang Jian-yan, 2013, Yingyong Shengtai Xuebao, V24, P847
   Xu Y, 2018, Laser Optoelectron Prog, V55, P221
   Yan L., 2004, Mar. Fisheries, V1, P10
   Zhang X., 2009, Nat Sci Prog, V26, P121
   Zhao XW, 2015, OCEAN ENG, V94, P163, DOI 10.1016/j.oceaneng.2014.11.036
   Zhou Z, 2009, Study of marine plankton image capture system in real time
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 29
TC 10
Z9 10
U1 7
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19429
EP 19444
DI 10.1007/s11042-021-11307-y
EA AUG 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000684067100001
DA 2024-07-18
ER

PT J
AU Pei, Z
   Gou, YS
   Ma, M
   Guo, M
   Leng, CC
   Chen, YL
   Li, J
AF Pei, Zhao
   Gou, Yuanshuai
   Ma, Miao
   Guo, Min
   Leng, Chengcai
   Chen, Yuli
   Li, Jun
TI Alzheimer's disease diagnosis based on long-range dependency mechanism
   using convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's disease diagnosis; Long-range dependency mechanism;
   Convolutional neural network; Classification
ID CLASSIFICATION; REGRESSION; CONVERSION; ADNI; MCI
AB Being able to collect rich morphological information of brain, structural magnetic resonance imaging (MRI) is popularly applied to computer-aided diagnosis of Alzheimer's disease (AD). Conventional methods for AD diagnosis are labor-intensive and typically depend on a substantial amount of hand-crafted features. In this paper, we propose a novel framework of convolutional neural network that aims at identifying AD or normal control, and mild cognitive impairment or normal control. The centerpiece of our method are pseudo-3D block and expanded global context block which are integrated into residual block of backbone in a cascaded manner. To be specific, we transfer pseudo-3D block in the video feature representation to extract structural MRI features. Besides, we extend the 2D global context block to the 3D model which can effectively combine the features and capture the latent associations, while simulate the global context in each dimension of structural MRI results. With the preprocessed structural MRI used as the input of the overall network, our method is capable of constructing a latent representation with multiple residual blocks to promote the classification accuracy. Intrinsically, our method reduces the complexity of conventional 3D convolutional network model applied to AD diagnosis and improves the classification accuracy over the baseline. Furthermore, our network can fully take advantage of the deep 3D convolutional neural network for automatic feature extraction and representation, and thus avoids the limitation of low processing efficiency caused by the preprocessing procedure in which a specific area needs to be annotated in advance. Experimental results on Alzheimer's Disease Neuroimaging Initiative database indicate that our proposed method reports accuracy of 89.29% on the AD/NC and 87.57% on the mild cognitive impairment/NC, whilst our approach achieves the 0.5% improvement of accuracy compared with the backbone.
C1 [Pei, Zhao] Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Peoples R China.
   [Pei, Zhao; Gou, Yuanshuai; Ma, Miao; Guo, Min; Chen, Yuli] Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Peoples R China.
   [Leng, Chengcai] Northwest Univ, Sch Math, Xian 710127, Peoples R China.
   [Li, Jun] Nanjing Normal Univ, Sch Comp Sci, Nanjing 210046, Peoples R China.
C3 Shaanxi Normal University; Northwest University Xi'an; Nanjing Normal
   University
RP Pei, Z (corresponding author), Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Peoples R China.; Pei, Z (corresponding author), Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Peoples R China.
EM zpei@snnu.edu.cn; gys@snnu.edu.cn; mmthp@snnu.edu.cn;
   guomin@snnu.edu.cn; ccleng@nwu.edu.cn; chenyuli@snnu.edu.cn;
   lijuncst@njnu.edu.cn
RI Lin, Lin/JTU-1595-2023
FU National Natural Science Foundation of China [61971273, 61877038,
   61702251, 61703096]; Key Research and Development Program in Shaanxi
   Province of China [2021GY-032]; Fundamental Research Funds for the
   Central Universities [GK202003077, GK202105006]; NVIDIA Corporation
FX This work is supported by the National Natural Science Foundation of
   China under Grant 61971273, Grant 61877038, Grant 61702251, Grant
   61703096, the Key Research and Development Program in Shaanxi Province
   of China under Grant 2021GY-032 and the Fundamental Research Funds for
   the Central Universities under Grant GK202003077, Grant GK202105006. The
   authors would like to gratefully thank NVIDIA Corporationfor for the
   support of the Titan XP GPU used in our work.
CR Akkus Z, 2017, J DIGIT IMAGING, V30, P449, DOI 10.1007/s10278-017-9983-4
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Cheng D, 2017, SOC PHOTOOPTICAL INS, P07
   Escudero J, 2011, IEEE ENG MED BIO, P7957, DOI 10.1109/IEMBS.2011.6091962
   Falahati F, 2014, J ALZHEIMERS DIS, V41, P685, DOI 10.3233/JAD-131928
   Gao XHW, 2017, COMPUT METH PROG BIO, V138, P49, DOI 10.1016/j.cmpb.2016.10.007
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hosseini-Asl E, 2016, IEEE IMAGE PROC, P126, DOI 10.1109/ICIP.2016.7532332
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jack CR, 2008, J MAGN RESON IMAGING, V27, P685, DOI 10.1002/jmri.21049
   Jin D, 2019, I S BIOMED IMAGING, P1047, DOI 10.1109/ISBI.2019.8759455
   Khvostikov A, 2018, ARXIV COMPUTER VISIO, V01
   Klöppel S, 2008, BRAIN, V131, P681, DOI 10.1093/brain/awm319
   Lian CF, 2020, IEEE T PATTERN ANAL, V42, P880, DOI 10.1109/TPAMI.2018.2889096
   Liu MH, 2018, FRONT NEUROINFORM, V12, DOI 10.3389/fninf.2018.00035
   Liu MH, 2014, HUM BRAIN MAPP, V35, P1305, DOI 10.1002/hbm.22254
   Liu MX, 2019, IEEE T BIO-MED ENG, V66, P1195, DOI 10.1109/TBME.2018.2869989
   Liu SD, 2013, LECT NOTES COMPUT SC, V8150, P303, DOI 10.1007/978-3-642-40763-5_38
   Liu SQ, 2014, I S BIOMED IMAGING, P1015, DOI 10.1109/ISBI.2014.6868045
   Moradi E, 2015, NEUROIMAGE, V104, P398, DOI 10.1016/j.neuroimage.2014.10.002
   Ortiz A, 2016, INT J NEURAL SYST, V26, DOI 10.1142/S0129065716500258
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Risacher SL, 2009, CURR ALZHEIMER RES, V6, P347, DOI 10.2174/156720509788929273
   Sarraf S., 2016, ARXIV160706583
   Suk HI, 2017, MED IMAGE ANAL, V37, P101, DOI 10.1016/j.media.2017.01.008
   Varol E, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P146, DOI 10.1109/ISBI.2012.6235505
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang SQ, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P517, DOI 10.1109/ICMLA.2018.00083
   Ye Dong Hye, 2011, Int Workshop Pattern Recognit Neuroimaging, V2011, P1, DOI 10.1109/PRNI.2011.12
   Zhang CQ, 2018, AAAI CONF ARTIF INTE, P4406
   Zhang DQ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033182
   Zhang DQ, 2011, NEUROIMAGE, V55, P856, DOI 10.1016/j.neuroimage.2011.01.008
   Zhang J, 2018, IEEE T IMAGE PROCESS, V27, P2420, DOI 10.1109/TIP.2018.2804218
   Zhou T, 2019, IEEE T MED IMAGING, V38, P2411, DOI 10.1109/TMI.2019.2913158
   Zhu XF, 2017, MED IMAGE ANAL, V38, P205, DOI 10.1016/j.media.2015.10.008
NR 35
TC 6
Z9 6
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36053
EP 36068
DI 10.1007/s11042-021-11279-z
EA JUL 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000679633100001
DA 2024-07-18
ER

PT J
AU Li, RH
   Wang, LF
   Jiang, ZJ
   Liu, D
   Zhao, M
   Lu, XY
AF Li, Ronghan
   Wang, Lifang
   Jiang, Zejun
   Liu, Dong
   Zhao, Meng
   Lu, Xinyu
TI Incremental BERT with commonsense representations for multi-choice
   reading comprehension
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine reading comprehension; BERT; External knowledge; Common sense;
   Deep learning
AB Compared to extractive machine reading comprehension (MRC) limited to text spans, multi-choice MRC is more flexible in evaluating the model's ability to utilize external commonsense knowledge. On the one hand, existing methods leverage transfer learning and complicated matching networks to solve the multi-choice MRC, which lacks interpretability for commonsense questions. On the other hand, although Transformer based pre-trained language models such as BERT have shown powerful performance in MRC, external knowledge such as unspoken commonsense and world knowledge still can not be used explicitly for downstream tasks. In this work, we present three simple yet effective injection methods plugged in BERT's structure to fine-tune the multi-choice MRC tasks with off-the-shelf commonsense representations directly. Moreover, we introduce a mask mechanism for the token-level multi-hop relationship searching to filter external knowledge. Experimental results indicate that the incremental BERT outperforms the baseline by a considerable margin on DREAM and CosmosQA, two knowledge-driven multi-choice datasets. Further analysis shows the robustness of the incremental model in the case of an incomplete training set.
C1 [Li, Ronghan; Wang, Lifang; Jiang, Zejun; Liu, Dong; Zhao, Meng; Lu, Xinyu] Northwestern Polytech Univ, Sch Comp Sci & Engn, Xian 710072, Peoples R China.
C3 Northwestern Polytechnical University
RP Jiang, ZJ (corresponding author), Northwestern Polytech Univ, Sch Comp Sci & Engn, Xian 710072, Peoples R China.
EM lrh000@mail.nwpu.edu.cn; wanglf@nwpu.edu.cn; claud@mail.nwpu.edu.cn;
   liudong2018@mail.nwpu.edu.cn; zmsmartboy@mail.nwpu.edu.cn;
   luxy@mail.nwpu.edu.cn
RI Lu, Xinyu/KIB-5798-2024
FU Henan key Laboratory for Big Data Processing & Analytics of Electronic
   Commerce [2020-KF-10]
FX We thank the funding 2020-KF-10 supported by Henan key Laboratory for
   Big Data Processing & Analytics of Electronic Commerce.
CR [Anonymous], 2019, P 2 WORKSH MACH READ, DOI [DOI 10.1109/ISORC.2019.00015, 10.18653/v1/D19-5804]
   [Anonymous], 2017, Quasar: Datasets for question answering by search and reading
   Bauer L, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4220
   Chen Q, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2406
   Choi E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2174
   Clark P, 2018, ARXIVABS1803057
   Devlin J, 2019, P 2019 C N AM CHAPT, P4171
   Ding M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2694
   Hermann Karl Moritz, 2015, Advances in Neural Information Processing Systems, P1693
   Hill F., 2016, 4 INT C LEARN REPR I
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Huang LF, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2391
   Jin D, 2020, AAAI CONF ARTIF INTE, V34, P8010
   Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147
   Koisky T., 2018, T ASSOC COMPUT LING, V6, P317, DOI [DOI 10.1162/TACL_A_00023, 10.1162/tacla00023]
   Lai Guokun, 2017, P 2017 C EMPIRICAL M, DOI [10.18653/v1/D17-1082, DOI 10.18653/V1/D17-1082]
   Li ZK, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P12
   Mihaylov T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2381
   Mihaylov T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P821
   Miller G.A., 1990, Int. J. Lexicogr, V3, P235, DOI [DOI 10.1093/IJL/3.4.235, 10.1093/ijl/3.4.235]
   Peters ME, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P43
   Rajpurkar P., 2016, P 2016 C EMP METH NA, V2016, P2383
   Reddy S, 2019, T ASSOC COMPUT LING, V7, P249, DOI 10.1162/tacl_a_00266
   Seo M. J., 2017, INT C LEARN REPR ICL
   Speer R, 2017, AAAI CONF ARTIF INTE, P4444
   Sun K, 2019, T ASSOC COMPUT LING, V7, P217, DOI 10.1162/tacl_a_00264
   Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149
   Nguyen TH, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7510925
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Wang C, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2263
   Wang L., 2018, Proceedings of the 12th International Workshop on Semantic Evaluation, P758
   Wang R, 2020, ARXIVABS200201808
   Wang SH, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P746
   Wang WH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P189, DOI 10.18653/v1/P17-1018
   Wang X, 2019, ARXIVABS191106136
   Welbl J., 2018, T ASS COMPUTATIONAL, V6, P287, DOI [10.1162/tacl_a_00021, DOI 10.1162/TACL_A_00021]
   Xiong WH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4258
   Xiong Wenhan, 2020, P ICLR
   Yang A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2346
   Yang BS, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1436, DOI 10.18653/v1/P17-1132
   Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2369
   Yu J., 2019, IEEE T NEUR NET LEAR
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zhang Sheng, 2018, ARXIV181012885
   Zhang SL, 2020, AAAI CONF ARTIF INTE, V34, P9563
   Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1441
   Zhong WJ, 2019, LECT NOTES ARTIF INT, V11838, P16, DOI 10.1007/978-3-030-32233-5_2
   Zhu P, 2020, ARXIVABS200109515
NR 50
TC 3
Z9 3
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32311
EP 32333
DI 10.1007/s11042-021-11197-0
EA JUL 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000678480300003
DA 2024-07-18
ER

PT J
AU Sun, L
   Li, Y
   Liu, BZ
   Xu, LY
   Zhang, Z
   Zhu, J
AF Sun, Lin
   Li, Yi
   Liu, Bingzheng
   Xu, Liying
   Zhang, Zhe
   Zhu, Jie
TI Transferring knowledge from monocular completion for self-supervised
   monocular depth estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Monocular depth estimation; Self-supervised learning; Knowledge
   transfer; Monocular depth completion
AB Monocular depth estimation is a very challenging task in computer vision, with the goal to predict per-pixel depth from a single RGB image. Supervised learning methods require large amounts of depth measurement data, which are time-consuming and expensive to obtain. Self-supervised methods are showing great promise, exploiting geometry to provide supervision signals through image warping. Moreover, several works leverage on other visual tasks (e.g. stereo matching and semantic segmentation) to further advance self-supervised monocular depth estimation. In this paper, we propose a novel framework utilizing monocular depth completion as an auxiliary task to assist monocular depth estimation. In particular, a knowledge transfer strategy is employed to enable monocular depth estimation to benefit from the effective feature representations learned by monocular depth completion task. The correlation between monocular depth completion and monocular depth estimation could be fully and effectively utilized in this framework. Only unlabeled stereo images are used in the proposed framework, which achieves a self-supervised learning paradigm. Experimental results on publicly available dataset prove that the proposed approach achieves superior performance to state-of-the-art self-supervised methods and comparable performance with supervised methods.
C1 [Sun, Lin; Li, Yi; Liu, Bingzheng; Xu, Liying; Zhang, Zhe; Zhu, Jie] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Li, Y (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM annie@tju.edu.cn
OI Zhang, Zhe/0000-0002-8772-2107
FU Natural Science Foundation of Tianjin [18ZXZNGX00110]
FX This work was supported in part by the Natural Science Foundation of
   Tianjin (No.18ZXZNGX00110).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   ATAPOURABARGHOU.A, 2018, PROC CVPR IEEE, P2800, DOI DOI 10.1109/CVPR.2018.00296
   Cao YZH, 2018, IEEE T CIRC SYST VID, V28, P3174, DOI 10.1109/TCSVT.2017.2740321
   Chen PY, 2019, PROC CVPR IEEE, P2619, DOI 10.1109/CVPR.2019.00273
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Eigen D, 2014, ADV NEUR IN, V27
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A., 2012, CVPR
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Guizilini V, 2020, INT C LEARN REPR
   Guizilini V, 2020, PROC CVPR IEEE, P2482, DOI 10.1109/CVPR42600.2020.00256
   Guo XY, 2018, LECT NOTES COMPUT SC, V11215, P506, DOI 10.1007/978-3-030-01252-6_30
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jiang HZ, 2018, LECT NOTES COMPUT SC, V11215, P20, DOI 10.1007/978-3-030-01252-6_2
   Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lei JJ, 2021, IEEE T CIRC SYST VID, V31, P2686, DOI 10.1109/TCSVT.2020.3027616
   Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594
   Mehta I, 2018, INT CONF 3D VISION, P314, DOI 10.1109/3DV.2018.00044
   Owen AB, 2007, CONTEMP MATH, V443, P59
   Pan ZQ, 2022, IEEE T CIRC SYST VID, V32, P345, DOI 10.1109/TCSVT.2021.3057518
   Peng B, 2021, NEUROCOMPUTING, V456, P519, DOI 10.1016/j.neucom.2020.05.123
   Pilzer A, 2019, PROC CVPR IEEE, P9760, DOI 10.1109/CVPR.2019.01000
   Poggi M, 2018, INT CONF 3D VISION, P324, DOI 10.1109/3DV.2018.00045
   Ramirez PZ, 2019, LECT NOTES COMPUT SC, V11363, P298, DOI 10.1007/978-3-030-20893-6_19
   Ranjan A, 2019, PROC CVPR IEEE, P12232, DOI 10.1109/CVPR.2019.01252
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Tonioni A, 2020, IEEE T PATTERN ANAL, V42, P2396, DOI 10.1109/TPAMI.2019.2940948
   Tosi F, 2017, 28 BRIT MACH VIS C
   Tosi F, 2019, PROC CVPR IEEE, P9791, DOI 10.1109/CVPR.2019.01003
   Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong A, 2019, PROC CVPR IEEE, P5627, DOI 10.1109/CVPR.2019.00579
   Xing M., 2011, Proc. IEEE ICCV, P467
   Xu D, 2019, IEEE T PATTERN ANAL, V41, P1426, DOI 10.1109/TPAMI.2018.2839602
   Yang ZH, 2018, AAAI CONF ARTIF INTE, P7493
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
   Zhu JJ, 2011, IEEE T PATTERN ANAL, V33, P1400, DOI 10.1109/TPAMI.2010.172
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI [10.1007/978-3-030-01219-9_, 10.1007/978-3-030-01219-9_18]
NR 49
TC 3
Z9 3
U1 9
U2 65
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42485
EP 42495
DI 10.1007/s11042-021-11212-4
EA JUL 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000677229000005
DA 2024-07-18
ER

PT J
AU Mishra, SK
   Singh, KK
   Dixit, R
   Bajpai, MK
AF Mishra, Santosh Kumar
   Singh, Koushlendra Kumar
   Dixit, Richa
   Bajpai, Manish Kumar
TI Design of Fractional Calculus based differentiator for edge detection in
   color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Grunwald Letnikov definition; Laplacian Operator; Thresholding; Edge
   linking
ID RGB
AB Edge detection has many applications in engineering and medical field. Edge detection in color images is getting the attention of the researchers due to the reason that color images have more information as compared to gray scale images. Different differential methods have been proposed in the literature for edge detection. Some of them required smoothing due to high sensitivity of differential methods towards noise. In the present manuscript, fractional order differentiation operator is defined to find out the gradient of the image which is further used for edge detection. Considering the input image as a reconstructed image, optimal threshold selection method is defined which is based on an error in image reconstruction assuming thatthe input image isa reconstructed image. Fractional edge detection improves the thin edge detection. It has more details of edges as compared to integer order based fractional differentiation. Fractional differentiation based edge detector does not require additional smoothing. Optimal threshold selection based on an error in a reconstructed image enhances the texture information as compared to normal threshold selection.
C1 [Mishra, Santosh Kumar; Bajpai, Manish Kumar] Indian Inst Informat Technol Design & Mfg Jabalpu, Jabalpur, India.
   [Singh, Koushlendra Kumar] Natl Inst Technol Jamshedpur, Jamshedpur, Bihar, India.
   [Dixit, Richa] Rani Durgavati Univ, Jabalpur, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; National Institute of Technology (NIT System); National
   Institute of Technology Jamshedpur
RP Singh, KK (corresponding author), Natl Inst Technol Jamshedpur, Jamshedpur, Bihar, India.
EM koushlendra.cse@nitjsr.ac.in
RI Bajpai, Manish Kumar/K-7915-2015
OI Bajpai, Manish Kumar/0000-0003-2258-2390; Singh, Dr. Koushlendra
   kumar/0000-0002-5614-6098
CR Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   [Anonymous], 1998, FRACTIONAL DIFFERENT
   [Anonymous], 2004, P 15 ANN C IND NUCL
   Athe P, 2013, FLOW MEAS INSTRUM, V33, P122, DOI 10.1016/j.flowmeasinst.2013.05.005
   BI C, 2017, DYNAMIC MODE DECOMPO
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chung KL, 2008, IEEE T IMAGE PROCESS, V17, P2356, DOI 10.1109/TIP.2008.2005561
   Demirci R, 2007, AEU-INT J ELECTRON C, V61, P469, DOI 10.1016/j.aeue.2006.08.004
   Denis P, 2007, COMPUT VIS IMAGE UND, V107, P74, DOI 10.1016/j.cviu.2006.11.019
   Evans AN, 2006, IEEE T IMAGE PROCESS, V15, P1454, DOI 10.1109/TIP.2005.864164
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   Heath M, 1998, COMPUT VIS IMAGE UND, V69, P38, DOI 10.1006/cviu.1997.0587
   Hueckel MH., 1969, AIM105 STANF U COMP
   Itier V, 2021, MULTIMED TOOLS APPL, V80, P13215, DOI 10.1007/s11042-020-10326-5
   Jain Anil K, 2007, FUNDAMENTAL DIGITAL
   Jang DW, 2017, IEEE T IMAGE PROCESS, V26, P2561, DOI 10.1109/TIP.2017.2687125
   Khan PW, 2019, IEEE ACCESS, V7, P38442, DOI 10.1109/ACCESS.2019.2906033
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Luo JB, 2006, IEEE T IMAGE PROCESS, V15, P1443, DOI 10.1109/TIP.2006.871081
   Mafi M, 2018, IEEE T IMAGE PROCESS, V27, P5475, DOI 10.1109/TIP.2018.2857448
   Manish B., 2013, RES NONDESTRUCT EVAL, V24, P211, DOI [10.1080/09349847.2013.795635, DOI 10.1080/09349847.2013.795635]
   NEVATIA R, 1977, IEEE T SYST MAN CYB, V7, P820
   Pietikainen M., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P594
   ROSENFELD A, 1971, IEEE T COMPUT, VC 20, P562, DOI 10.1109/T-C.1971.223290
   Roy M, 2020, MULTIMED TOOLS APPL, V79, P24089, DOI 10.1007/s11042-020-09116-w
   Scharcanski J, 1997, IEEE T CIRC SYST VID, V7, P397, DOI 10.1109/76.564116
   Shi MH, 2019, MULTIMED TOOLS APPL, V78, P10701, DOI 10.1007/s11042-018-6617-x
   Singh KK, 2015, INT ARCH PHOTOGRAMM, V40-3, P211, DOI 10.5194/isprsarchives-XL-3-W2-211-2015
   Singh KK, 2018, IEEE-CAA J AUTOMATIC, V5, P628, DOI 10.1109/JAS.2017.7510670
   Singh KK, 2017, RES NONDESTRUCT EVAL, V28, P150, DOI 10.1080/09349847.2016.1148214
   Singh KK, 2015, IEEE INT SYMP SIGNAL, P274, DOI 10.1109/ISSPIT.2015.7394342
   Solinsky J.C., 1985, P VIS 85, P434
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Trahanias PE, 1993, IEEE T IMAGE PROCESS, V2, P528, DOI 10.1109/83.242362
   Trahanias PE, 1993, IEEE T IMAGE PROCESS, V2, P259, DOI 10.1109/83.217230
   Trahanias PE, 1996, IEEE T SYST MAN CY B, V26, P135, DOI 10.1109/3477.484445
   Tufail Z, 2018, IEEE ACCESS, V6, P32576, DOI 10.1109/ACCESS.2018.2843261
   Verma OP, 2017, IEEE T FUZZY SYST, V25, P114, DOI 10.1109/TFUZZ.2016.2551289
   Yang CK, 1996, PATTERN RECOGN LETT, V17, P481, DOI 10.1016/0167-8655(95)00112-3
   Yasmin S, 2018, IET IMAGE PROCESS, V12, P1111, DOI 10.1049/iet-ipr.2017.0921
   Zhang Z, 2020, MULTIMED TOOLS APPL, V79, P14777, DOI 10.1007/s11042-018-7062-6
NR 43
TC 4
Z9 5
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29965
EP 29983
DI 10.1007/s11042-021-11187-2
EA JUL 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000673928000005
DA 2024-07-18
ER

PT J
AU Carretero, MD
   García, S
   Moreno, A
   Alcain, N
   Elorza, I
AF del Puy Carretero, Maria
   Garcia, Sara
   Moreno, Aitor
   Alcain, Nieves
   Elorza, Idurre
TI Methodology to create virtual reality assisted training courses within
   the Industry 4.0 vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE eLearning; Virtual reality; Training; Industry 4; 0; 3D reconstruction
AB Industry 4.0 paradigm has introduced a set of technological advances into the productive means. However, the training of the operators is somehow neglected. An operator without the necessary skills will take risks or will provoke problems that might appear at any point of the productive process. Therefore, training the operators is required to acquire the necessary skills to interact with the machines in the most productive and safest way possible. Virtual Reality (VR) is a good option to train people. However, the development of a VR system is usually expensive and slow due to the 3D design process and the creation and edition of VR training sessions. This paper presents a methodology to develop VR tutorials and training courses for professional preparation in industrial jobs, providing usable virtual tools to solve the following problems: i) how to create of the virtual model of workstations by its 3D reconstruction, ii) how to apply the expected behavior to the 3D models, and iii) how to prepare online tutorials and train workers in the virtual environment.
C1 [del Puy Carretero, Maria; Garcia, Sara; Moreno, Aitor] Basque Res & Technol Alliance BRTA, Vicomtech Fdn, Mikeletegi 57, Donostia San Sebastian 20009, Spain.
   [Alcain, Nieves; Elorza, Idurre] ALECOP, SCOOP, Loramendi 11, Arrasate Mondragon, Gipuzkoa, Spain.
RP Carretero, MD (corresponding author), Basque Res & Technol Alliance BRTA, Vicomtech Fdn, Mikeletegi 57, Donostia San Sebastian 20009, Spain.
EM mcarretero@vicomtech.org
OI Carretero, Maria del Puy/0000-0003-2197-0260
FU Spanish Government through the Center for the Development of Industrial
   Technology (CDTI): PRIOR [IDI-20180276]; SPRI agency of the Basque
   Autonomous Government [ZL-2016/00577, ZL-2017/00228, ZL-2018/00205]
FX This work has been carried out with the support of the Spanish
   Government through the Center for the Development of Industrial
   Technology (CDTI): PRIOR (IDI-20180276) and the SPRI agency of the
   Basque Autonomous Government for support within the financing scheme
   HAZITEK: ViWork (ZL-2016/00577; ZL-2017/00228; ZL-2018/00205).
CR Abulrub A. G., 2011, 2011 IEEE Global Engineering Education Conference (EDUCON), P751, DOI 10.1109/EDUCON.2011.5773223
   Ameddah H., 2011, Computer-Aided Design and Applications, V8, P37, DOI DOI 10.3722/CADAPS.2011.37-42
   [Anonymous], 2017, P 13 INT TAG WIRTSCH
   ASGARI S, 2018, INDIAN J SCI TECHNOL, V11, pNIL74, DOI DOI 10.17485/ijst/2018/v11i24/123052
   BECKER WE, 1979, AM ECON REV, V69, P1010
   Besnea FL, 2019, 2019 20 INT CARP CON, P1
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Garcia CA, 2019, LECT NOTES COMPUT SC, V11614, P379, DOI 10.1007/978-3-030-25999-0_32
   Hamza-Lup FG, 2007, 2 INT C VIRT LEARN I
   Hussein M, 2015, THESIS CHLAMERS U TE
   Jee HK, 2014, MULTIMED TOOLS APPL, V68, P225, DOI 10.1007/s11042-011-0880-4
   Johnson T., 2019, J DIGIT LANDSC ARCHI, V4, P266
   Kasim NNM, 2016, INT J EMERG TECHNOL, V11, P55, DOI 10.3991/ijet.v11i06.5644
   Kim BC, 2018, J MAR SCI TECH-JAPAN, V23, P647, DOI 10.1007/s00773-017-0501-7
   Lacko J, 2020, PROCEEDINGS OF THE 2020 30TH INTERNATIONAL CONFERENCE CYBERNETICS & INFORMATICS (K&I '20), DOI 10.1109/ki48306.2020.9039854
   Landers RichardN., 2011, Serious Games and Edutainment Applications, P399, DOI [DOI 10.1007/978-1-4471-2161-9_20, DOI 10.1007/978-1-4471-2161-920]
   Liagkou V, 2019, PROC CIRP, V79, P712, DOI 10.1016/j.procir.2019.02.025
   Liu DF, 2015, PROCEDIA COMPUT SCI, V75, P95, DOI 10.1016/j.procs.2015.12.224
   Lou Y, 2001, COMPUT ENG, V6
   Markopoulos A.P., 2015, International Journal of Mechanical Engineering Education, V43, P118, DOI DOI 10.1177/0306419015591324
   Matsas E, 2018, ROBOT CIM-INT MANUF, V50, P168, DOI 10.1016/j.rcim.2017.09.005
   Posada J, 2015, IEEE COMPUT GRAPH, V35, P26, DOI 10.1109/MCG.2015.45
   Roldán-Alvarez D, 2016, INT J HUM-COMPUT ST, V94, P18, DOI 10.1016/j.ijhcs.2016.04.011
   Segura A, 2020, COMPUT IND ENG, V139, DOI 10.1016/j.cie.2018.11.060
   Severance C., 2010, Technology, Instruction, Cognition and Learning, V7, P245
   Sharma Anirudh., 2011, Proceedings of the 13th international conference on multimodal interfaces, P307
   Ssemugabi S., 2007, P 2007 ANN RES C S A, P132
   Sumak B, 2011, COMPUT HUM BEHAV, V27, P2067, DOI 10.1016/j.chb.2011.08.005
   Tang JKT, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON TEACHING, ASSESSMENT, AND LEARNING FOR ENGINEERING (TALE), P236, DOI 10.1109/TALE.2015.7386050
   Vert Silviu, 2019, ITM Web of Conferences, V29, DOI 10.1051/itmconf/20192903008
   Xie WY, 2017, IEEE I CONF COMP VIS, P2344, DOI 10.1109/ICCV.2017.255
   Yang JW, 2015, 2015 4 NAT C EL EL C
   Zaino J, 2016, SAMSUNG BUSINES 0627
NR 33
TC 8
Z9 8
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29699
EP 29717
DI 10.1007/s11042-021-11195-2
EA JUL 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000671519600002
DA 2024-07-18
ER

PT J
AU Kalamaras, I
   Glykos, K
   Megalooikonomou, V
   Votis, K
   Tzovaras, D
AF Kalamaras, Ilias
   Glykos, Konstantinos
   Megalooikonomou, Vasilis
   Votis, Konstantinos
   Tzovaras, Dimitrios
TI Graph-based visualization of sensitive medical data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph-based visualization; Glyphs; Incremental graph construction
AB With the increasing amounts of electronic health data being constantly generated in medical examinations and by sensors and mobile applications, data visualization methods can assist medical professionals and researchers in exploring and making sense of the data. Two important challenges faced by data visualization are large data volume and protection of sensitive data. In this paper, we propose a graph-based method that allows the exploration of a patient dataset, while also naturally allowing the summarization of large amounts of data, making it applicable to large datasets and sensitive data. A graph is constructed from the raw data, encoding local similarities among patients, and is visualized on the screen, producing a visual map of the patient distribution. Multidimensional glyphs are put in place of the nodes, revealing the properties that characterize each graph area. The graph construction method is extended to an incremental scheme, allowing federated graph formation. The proposed method is demonstrated in three use cases, regarding frailty in older adults, Sjogren's Syndrome patients, and a large-size diabetes dataset.
C1 [Kalamaras, Ilias; Glykos, Konstantinos; Votis, Konstantinos; Tzovaras, Dimitrios] Ctr Res & Technol Hellas, Inst Informat Technol, 6th Km Harilaou Thermi, Thermi 57001, Greece.
   [Megalooikonomou, Vasilis] Univ Patras, Comp Engn & Informat Dept, Patras 26504, Greece.
C3 Centre for Research & Technology Hellas; University of Patras
RP Kalamaras, I (corresponding author), Ctr Res & Technol Hellas, Inst Informat Technol, 6th Km Harilaou Thermi, Thermi 57001, Greece.
EM kalamar@iti.gr; glykos@iti.gr; vasilis@ceid.upatras.gr; kvotis@iti.gr;
   dimitrios.tzovaras@iti.gr
RI Tzovaras, Dimitrios/ABB-9576-2021
OI Tzovaras, Dimitrios/0000-0001-6915-6722
FU EU [731944, 690140]
FX This work has been supported by the EU H2020 projects FrailSafe
   (H2020-PHC-21-2015, grant agreement no. 690140) and HarmonicSS
   (H2020-SC1-2016-RTD, grant agreement no. 731944).
CR [Anonymous], 2020, EU H2020, CREATE project Documents, EeB-06-2015
   [Anonymous], 1998, P WORKING C ADV VISU, DOI DOI 10.1145/948496.948514
   [Anonymous], 2018, H2020 EU
   Asprou M., 2019, 2019 IEEE MIL POW, V2019, P1, DOI [10.1109/PTC.2019.8810827, DOI 10.1109/ptc.2019.8810827]
   Beck F, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.12791
   Bhavnani SK, 2014, ROLE VISUAL ANAL AST
   Borgo R., 2013, EUROGRAPHICS STARS, P39, DOI DOI 10.2312/CONF/EG2013/STARS/039-063
   Cao N, 2018, INFORM VISUAL, V17, P22, DOI 10.1177/1473871616686635
   Drosou Anastasios, 2016, Journal of Innovation in Digital Ecosystems, V3, P83, DOI 10.1016/j.jides.2016.10.005
   Fried LP, 2001, J GERONTOL A-BIOL, V56, pM146, DOI 10.1093/gerona/56.3.M146
   Fuchs J, 2017, IEEE T VIS COMPUT GR, V23, P1863, DOI 10.1109/TVCG.2016.2549018
   Hachul S., 2005, LARGE GRAPH LAYOUT F, VV, P1
   Heer J, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P33
   JIAWEI L, 2020, J SUPERCOMPUT, V76, P9654
   Kalamaras I, 2014, IEEE T MULTIMEDIA, V16, P1460, DOI 10.1109/TMM.2014.2316473
   Kwon OH, 2016, IEEE T VIS COMPUT GR, V22, P1802, DOI 10.1109/TVCG.2016.2520921
   Li L, 2015, SCI TRANSL MED, V7, DOI 10.1126/scitranslmed.aaa9364
   Linhares C. D. G., 2017, P S APPL COMP SAC 17, P187, DOI [DOI 10.1145/3019612.3019686, 10.1145/3019612.3019686]
   Liu J, 2016, AI MAG, V37, P33, DOI 10.1609/aimag.v37i2.2630
   Opach T, 2018, CARTOGR GEOGR INF SC, V45, P400, DOI 10.1080/15230406.2017.1364169
   Pai S, 2018, J MOL BIOL, V430, P2924, DOI 10.1016/j.jmb.2018.05.037
   Polyakov EV., 2018, 2018 MOSCOW WORKSHOP, P1, DOI [DOI 10.1109/MWENT.2018.8337236, 10.1109/MWENT.2018.8337236]
   Polychronidou E, 2017, ADV EXP MED BIOL, V988, P127, DOI 10.1007/978-3-319-56246-9_10
   Ribassin-Majed L, 2017, J CLIN ONCOL, V35, P498, DOI 10.1200/JCO.2016.67.4119
   Ropinski T, 2011, COMPUT GRAPH-UK, V35, P392, DOI 10.1016/j.cag.2011.01.011
   Strack B, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/781670
   Valdivia P, 2021, IEEE T VIS COMPUT GR, V27, P1, DOI 10.1109/TVCG.2019.2933196
   Ward MO, 2008, Handbook of Data Visualization, P179, DOI [DOI 10.1007/978-3-540-33037-0_8, DOI 10.1007/978-3-540-33037-08, 10.1007/978-3-540-33037-08]
   Widanagamaachchi Wathsala, 2017, AMIA Annu Symp Proc, V2017, P1773
   WILLIAM J, 2012, BMC BIOINFORMATICS, V13, P1
   Zacharaki EI, 2020, IEEE J BIOMED HEALTH, V24, P1557, DOI 10.1109/JBHI.2020.2986918
   Zhou Y, 2007, SIAM J MATRIX ANAL A, V29, P954, DOI 10.1137/050630404
NR 32
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 209
EP 236
DI 10.1007/s11042-021-10990-1
EA JUN 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000667012400004
DA 2024-07-18
ER

PT J
AU Diniz, JOB
   Quintanilha, DBP
   Neto, ASC
   da Silva, GLF
   Ferreira, JL
   Netto, SMB
   Araújo, JDL
   Da Cruz, LB
   Silva, TFB
   Martins, CMD
   Ferreira, MM
   Rego, VG
   Boaro, JMC
   Cipriano, CLS
   Silva, AC
   de Paiva, AC
   Braz, G Jr
   de Almeida, JDS
   Nunes, RA
   Mogami, R
   Gattass, M
AF Diniz, Joao O. B.
   Quintanilha, Darlan B. P.
   Santos Neto, Antonino C.
   da Silva, Giovanni L. F.
   Ferreira, Jonnison L.
   Netto, Stelmo M. B.
   Araujo, Jose D. L.
   Da Cruz, Luana B.
   Silva, Thamila F. B.
   da S. Martins, Caio M.
   Ferreira, Marcos M.
   Rego, Venicius G.
   Boaro, Jose M. C.
   Cipriano, Carolina L. S.
   Silva, Aristofanes C.
   de Paiva, Anselmo C.
   Braz Junior, Geraldo
   de Almeida, Joao D. S.
   Nunes, Rodolfo A.
   Mogami, Roberto
   Gattass, M.
TI Segmentation and quantification of COVID-19 infections in CT using
   pulmonary vessels extraction and deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; CT findings; Infection quantification; Infection segmentation;
   Lung segmentation; Medical imaging
ID LUNG SEGMENTATION; THORACIC CT; RECONSTRUCTION; COHORT; SCANS
AB At the end of 2019, the World Health Organization (WHO) reported pneumonia that started in Wuhan, China, as a global emergency problem. Researchers quickly advanced in research to try to understand this COVID-19 and sough solutions for the front-line professionals fighting this fatal disease. One of the tools to aid in the detection, diagnosis, treatment, and prevention of this disease is computed tomography (CT). CT images provide valuable information on how this new disease affects the lungs of patients. However, the analysis of these images is not trivial, especially when researchers are searching for quick solutions. Detecting and evaluating this disease can be tiring, time-consuming, and susceptible to errors. Thus, in this study, we aim to automatically segment infections caused by COVID19 and provide quantitative measures of these infections to specialists, thus serving as a support tool. We use a database of real clinical cases from Pedro Ernesto University Hospital of the State of Rio de Janeiro, Brazil. The method involves five steps: lung segmentation, segmentation and extraction of pulmonary vessels, infection segmentation, infection classification, and infection quantification. For the lung segmentation and infection segmentation tasks, we propose modifications to the traditional U-Net, including batch normalization, leaky ReLU, dropout, and residual block techniques, and name it as Residual U-Net. The proposed method yields an average Dice value of 77.1% and an average specificity of 99.76%. For quantification of infectious findings, the proposed method achieves results like that of specialists, and no measure presented a value of rho < 0.05 in the paired t-test. The results demonstrate the potential of the proposed method as a tool to help medical professionals combat COVID-19. fight the COVID-19.
C1 [Diniz, Joao O. B.] Fed Inst Maranhao, BR-226 SN,Campus Grajau, BR-6594000 Grajau, MA, Brazil.
   [Diniz, Joao O. B.; Quintanilha, Darlan B. P.; Santos Neto, Antonino C.; da Silva, Giovanni L. F.; Ferreira, Jonnison L.; Netto, Stelmo M. B.; Araujo, Jose D. L.; Da Cruz, Luana B.; Silva, Thamila F. B.; da S. Martins, Caio M.; Ferreira, Marcos M.; Rego, Venicius G.; Boaro, Jose M. C.; Cipriano, Carolina L. S.; Silva, Aristofanes C.; de Paiva, Anselmo C.; Braz Junior, Geraldo; de Almeida, Joao D. S.] Univ Fed Maranhao, Av Portugueses SN,Campus Bacanga, BR-65085580 Sao Luis, MA, Brazil.
   [da Silva, Giovanni L. F.] Dom Bosco Higher Educ Unit UNDB, Av Colares Moreira 443, BR-65075441 Sao Luis, MA, Brazil.
   [Ferreira, Jonnison L.] Fed Inst Amazonas IFAM, BR-226 SN,Campus Grajau, BR-6594000 Grajau, MA, Brazil.
   [Nunes, Rodolfo A.; Mogami, Roberto] Univ Estado Rio De Janeiro, Blvd 28 Setembro,77, BR-20551030 Rio De Janeiro, RJ, Brazil.
   [Gattass, M.] Pontifical Catholic Univ Rio De Janeiro, R Sao Vicente 225, BR-22453900 Rio De Janeiro, RJ, Brazil.
C3 Instituto Federal do Maranhao; Universidade Federal do Maranhao;
   Instituto Federal do Amazonas (IFAM); Universidade do Estado do Rio de
   Janeiro; Pontificia Universidade Catolica do Rio de Janeiro
RP Diniz, JOB (corresponding author), Fed Inst Maranhao, BR-226 SN,Campus Grajau, BR-6594000 Grajau, MA, Brazil.; Diniz, JOB (corresponding author), Univ Fed Maranhao, Av Portugueses SN,Campus Bacanga, BR-65085580 Sao Luis, MA, Brazil.
EM joao.bandeira@ifma.edu.br; antoninocalisto@nca.ufma.br;
   giovannilucca@nca.ufma.br; jonnison@nca.ufma.br; stelmo@nca.ufma.br;
   luana.b.cruz@nca.ufma.br; thamila.fontenele@nca.ufma.br;
   caiomanfredini@nca.ufma.br; marcos.melo@nca.ufma.br;
   venicius.gr@nca.ufma.br; boaro@nca.ufma.br; carol@nca.ufma.br;
   ari@nca.ufma.br; paiva@nca.ufma.br; jdallyson@nca.ufma.br;
   rodolfoacatauassu@yahoo.com.br; pq242001@hotmail.com;
   mgattass@inf.puc-rio.br
RI Paiva, Anselmo/L-2358-2013; Bandeira, João/E-6498-2019; Cruz,
   Luana/AAB-9138-2021; Braz, Geraldo/AAW-1827-2021
OI Paiva, Anselmo/0000-0003-4921-0626; Bandeira, João/0000-0003-3303-3346;
   Braz, Geraldo/0000-0003-3731-6431; Almeida, Joao Dallyson Sousa de
   Almeida/0000-0001-7013-9700; Mogami, Roberto/0000-0002-7610-2404; Pontes
   Quintanilha, Darlan Bruno/0000-0001-8134-4873
FU Federal University of Maranhao (UFMA); Federal Institutes of Maranhao
   (IFMA); Amazonas (IFAM); Pedro Ernesto University Hospital (HUPE) from
   State University of Rio de Janeiro (UERJ); Fundacao de Amparo a Pesquisa
   e ao Desenvolvimento Cientifico e Tecnologico do Maranhao (FAPEMA);
   Tecgraf Institute for Technical and Scientific Software Development
   (Tecgraf/PUC-Rio)
FX This research was carried out with the support of the institutions
   Applied Computing Group (NCA) from Federal University of Maranhao
   (UFMA), Federal Institutes of Maranhao (IFMA) and Amazonas (IFAM), Pedro
   Ernesto University Hospital (HUPE) from State University of Rio de
   Janeiro (UERJ), Fundacao de Amparo a Pesquisa e ao Desenvolvimento
   Cientifico e Tecnologico do Maranhao (FAPEMA), and Tecgraf Institute for
   Technical and Scientific Software Development (Tecgraf/PUC-Rio).
CR Agam G, 2005, IEEE T MED IMAGING, V24, P486, DOI 10.1109/TMI.2005.844167
   [Anonymous], 2020, COVID-19 CT Segmentation Dataset
   Armato SG, 2004, ACAD RADIOL, V11, P1011, DOI 10.1016/j.acra.2004.06.005
   Baldi Pierre, 2013, Advances in Neural Information Processing Systems, P2814
   Diniz JOB, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105685
   Diniz JOB, 2019, COMPUT METH PROG BIO, V170, P53, DOI 10.1016/j.cmpb.2019.01.005
   Diniz JOB, 2018, COMPUT METH PROG BIO, V156, P191, DOI 10.1016/j.cmpb.2018.01.007
   Diniz PHB, 2018, COMPUT METH PROG BIO, V167, P49, DOI 10.1016/j.cmpb.2018.04.011
   Boccia S, 2020, JAMA INTERN MED, V180, P927, DOI 10.1001/jamainternmed.2020.1447
   Chan JFW, 2020, LANCET, V395, P514, DOI 10.1016/S0140-6736(20)30154-9
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chollet Francois, 2018, Keras: the Python Deep Learning Library
   Coudray N, 2018, NAT MED, V24, P1559, DOI 10.1038/s41591-018-0177-5
   da Cruz LB, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103906
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Diniz JOB, 2020, REV SISTEMAS COMPUTA, V10
   Fan DP, 2020, ARXIV PREPRINT ARXIV
   Firmino M, 2014, BIOMED ENG ONLINE, V13, DOI 10.1186/1475-925X-13-41
   Gao T, 2020, CHEST XRAY IMAGE ANA
   Godoy Daniel., 2019, Understanding binary cross-entropy / log loss: a visual explanation
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He WJ, 2020, LEUKEMIA, V34, P1637, DOI 10.1038/s41375-020-0836-7
   Hofmanninger J, 2020, EUR RADIOL EXP, V4, DOI 10.1186/s41747-020-00173-2
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jaccard P., 1912, New Phytologist, V11, P37, DOI [10.1111/j.1469-8137.1912.tb05611.x, DOI 10.1111/J.1469-8137.1912.TB05611.X]
   Johnson H, 2009, INSIGHT SEGMENTATION
   Johnson H.J., 2015, ITK SOFTWARE GUIDE B, V2
   Kolarík M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030404
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lau MM, 2018, IEEE EMBS CONF BIO, P686, DOI 10.1109/IECBES.2018.8626714
   Lehmann G., 2007, INSIGHT J, V8, P1
   Liu FJ, 2020, THERANOSTICS, V10, P5613, DOI 10.7150/thno.45985
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Machado DJD, 2020, TRANSPL INFECT DIS, V22, DOI 10.1111/tid.13306
   Mangal A, 2020, ARXIV PREPRINT ARXIV
   Mansoor A, 2014, IEEE T MED IMAGING, V33, P2293, DOI 10.1109/TMI.2014.2337057
   Mittal A, 2017, IET IMAGE PROCESS, V11, P937, DOI 10.1049/iet-ipr.2016.0526
   Ng MY, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200034
   Organization WH, 2020, COR DIS COV 19 SIT R
   Organization WH, 2020, COR DIS COV19 TECHN
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Petrosillo N, 2020, CLIN MICROBIOL INFEC, V26, P729, DOI 10.1016/j.cmi.2020.03.026
   Provost F, 2003, MACH LEARN, V52, P199, DOI 10.1023/A:1024099825458
   Pu J, 2008, COMPUT MED IMAG GRAP, V32, P452, DOI 10.1016/j.compmedimag.2008.04.005
   Qiu Y., 2020, ARXIV PREPRINT ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rothan HA, 2020, J AUTOIMMUN, V109, DOI 10.1016/j.jaut.2020.102433
   Salem S, 2020, GLOB MID EAST, P1, DOI [10.2214/AJR.20.23034, 10.2214/AJR.20.23034S., 10.1017/9781108868969]
   Samet R, 2016, PROCEEDINGS NICOGRAPH INTERNATIONAL 2016, P1, DOI 10.1109/NicoInt.2016.1
   Sato Y, 1998, Med Image Anal, V2, P143, DOI 10.1016/S1361-8415(98)80009-1
   Shen C, 2020, J PHARM ANAL, V10, P123, DOI 10.1016/j.jpha.2020.03.004
   Shen K., 2020, WORLD J PEDIATR
   Sousa JA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0251591
   Souza JC, 2019, COMPUT METH PROG BIO, V177, P285, DOI 10.1016/j.cmpb.2019.06.005
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x
   Tan WJ, 2020, CHINA CDC WEEKLY, V2, P61
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Wang LD, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76550-z
   Wu YH, 2021, IEEE T IMAGE PROCESS, V30, P3113, DOI 10.1109/TIP.2021.3058783
   Wu ZY, 2020, JAMA-J AM MED ASSOC, V323, P1239, DOI 10.1001/jama.2020.2648
   You Z, 2020, ARXIV PREPRINT ARXIV
   Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75
   Yu Q, 2020, THERANOSTICS, V10, P5641, DOI 10.7150/thno.46465
   Zeng CY, 1998, AM HEART J, V136, P852, DOI 10.1016/S0002-8703(98)70131-0
   Zheng CM, 2021, IEEE T MULTIMEDIA, V23, P2520, DOI 10.1109/TMM.2020.3013398
   Zhou SC, 2020, AM J ROENTGENOL, V214, P1287, DOI 10.2214/AJR.20.22975
   Zhu N, 2020, NEW ENGL J MED, V382, P727, DOI [10.1056/NEJMoa2001017, 10.1172/JCI89857]
   Zou LR, 2020, NEW ENGL J MED, V382, P1177, DOI [10.1056/NEJMc2001737, 10.1148/radiol.2020200463]
NR 70
TC 29
Z9 29
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29367
EP 29399
DI 10.1007/s11042-021-11153-y
EA JUN 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000665677500002
PM 34188605
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Wang, JX
   Li, CF
   Xu, SK
AF Wang, Jixiao
   Li, Chaofeng
   Xu, Shoukun
TI An ensemble multi-scale residual attention network (EMRA-net) for image
   Dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image dehazing; Convolutional neural network; Residual learning; Channel
   attention
AB Image dehazing aims to recover a clean image from a hazy image, which is a challengingly longstanding problem. In this paper, we propose an Ensemble Multi-scale Residual Attention Network (EMRA-Net) to directly generate a clean image, which include two parts: a three-scale residual attention CNN (TRA-CNN), and an ensemble attention CNN (EA-CNN). In TRA-CNN, we employ wavelet transform to obtain the downsampled images, instead of using common spatial downsampling methods, such as nearest downsampling and strided-convolution. With the help of wavelet transform, we can avoid the loss of image texture details. Moreover, in each scale-branch, Res2Net modules are connected in series to make full use of the hierarchical features from the original hazy images, and channel attention mechanism is introduced to focus channel-dimension information. Finally, an EA-CNN is proposed to fuse coarse images generated from TRA-CNN into a refined clean image. Extensive experiments on the benchmark synthetic hazy datasets and the real-world hazy dataset prove that proposed EMRA-Net is superior to previous state-of-the-art methods both in subjective visual perception and objective image quality assessment metrics.
C1 [Wang, Jixiao; Li, Chaofeng] Shanghai Maritime Univ, Inst Logist Sci & Engn, Shanghai 201306, Peoples R China.
   [Xu, Shoukun] Changzhou Univ, Sch Informat Sci & Engn, Changzhou 213164, Jiangsu, Peoples R China.
C3 Shanghai Maritime University; Changzhou University
RP Li, CF (corresponding author), Shanghai Maritime Univ, Inst Logist Sci & Engn, Shanghai 201306, Peoples R China.
EM wxlichaofeng@126.com
OI Li, Chaofeng/0000-0002-3236-3143
FU National Natural Science Foundation of China [61771223]
FX This study was funded by National Natural Science Foundation of China
   (No. 61771223).
CR Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   [Anonymous], 2017, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2017.683
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Blau Yochai, 2018, ECCV WORKSH
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Dong Y, 2020, AAAI CONF ARTIF INTE, V34, P10729
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Guo TT, 2017, IEEE COMPUT SOC CONF, P1100, DOI 10.1109/CVPRW.2017.148
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   King DB, 2015, ACS SYM SER, V1214, P1
   Kumar A, 2019, INT J CLOUD APPL COM, V9, P22, DOI 10.4018/IJCAC.2019070102
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li R., 2018, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2018.00856
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Ma C, 2017, COMPUT VIS IMAGE UND, V158, P1, DOI 10.1016/j.cviu.2016.12.009
   Mei K., 2018, P AS C COMP VIS
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Wang HX, 2020, PATTERN RECOGN LETT, V130, P64, DOI 10.1016/j.patrec.2018.08.010
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wu QB, 2020, IEEE T IMAGE PROCESS, V29, P1788, DOI 10.1109/TIP.2019.2942504
   Yang D, 2018, LECT NOTES COMPUT SC, V11211, P729, DOI 10.1007/978-3-030-01234-2_43
   Yang HH, 2020, INT CONF ACOUST SPEE, P2628, DOI [10.1109/ICASSP40776.2020.9053920, 10.1109/icassp40776.2020.9053920]
   Yang HH, 2019, IEEE IMAGE PROC, P2736, DOI [10.1109/icip.2019.8803391, 10.1109/ICIP.2019.8803391]
   Yang XT, 2018, AAAI CONF ARTIF INTE, P7485
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 45
TC 8
Z9 11
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29299
EP 29319
DI 10.1007/s11042-021-11081-x
EA JUN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000664856100001
DA 2024-07-18
ER

PT J
AU Kumar, R
   Singh, A
   Bala, M
AF Kumar, Rajesh
   Singh, Anurag
   Bala, Manju
TI A secure and robust multilayer network with optimum inter layer links
   under budget constraints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multilayer networks; Robustness; Mutually connected giant component;
   Inter-layer links; Edge betweenness centrality
ID INTERDEPENDENT NETWORKS; PERCOLATION
AB Most of the complex systems consist of multiple subsystems and can be modeled as multilayer networks. These networks are prone to random or strategical attacks and end up disintegrating the entire multilayer network. These attacks can't be avoided, but a model can be proposed to restore the network to make it secure and robust. In multilayer networks, each inter-layer link has its own cost (in terms of money) associated with it. The total cost of the inter-layer links is considered as the available budget. In the present work, a method is proposed to introduce the optimal number of inter-layer links (under budget constraints) to maintain the robustness of the multilayer network. For the simulation purpose, three variants of the artificial multilayer networks and data set EU-Air Transport Networks are considered. Simulation results reveal that for the multilayer network constructed with random network layers, approx. 65% of the available budget is utilized. Nearly 70% of the total nodes are connected to a mutually connected giant component (MCGC) via inter-layer links. However, for the Configuration model, using the almost total available budget, nearly all the nodes from the considered network layers are present in MCGC. Finally, in the case of the empirical dataset, by using approx. 75% of the available budget, almost 80% of the total nodes from the considered network layers are connected to MCGC via inter-layer links.
C1 [Kumar, Rajesh; Singh, Anurag] Natl Inst Tehnol, Delhi, India.
   [Bala, Manju] Khalsa Coll Engn & Technol, Amritsar, Punjab, India.
RP Kumar, R (corresponding author), Natl Inst Tehnol, Delhi, India.
EM rajeshkumar@nitdelhi.ac.in; anuragsg@nitdelhi.ac.in;
   drmanju571@gmail.com
RI Singh, Anurag/AAC-6485-2022
OI Singh, Anurag/0000-0001-5354-4691; k, Dr. rajesh/0000-0002-9827-643X
FU Science and Engineering Research Board (SERB), DST, Government of India
   under MATRICS project [MTR/2019/000631]
FX This work was supported by Science and Engineering Research Board
   (SERB), DST, Government of India under MATRICS project F. No.
   MTR/2019/000631.
CR Baxter GJ, 2012, PHYS REV LETT, V109, DOI 10.1103/PhysRevLett.109.248701
   Bianconi Ginestra., 2014, PHYS REV E, V89
   Boccaletti S, 2014, PHYS REP, V544, P1, DOI 10.1016/j.physrep.2014.07.001
   BONACICH P, 1972, J MATH SOCIOL, V2, P113, DOI 10.1080/0022250X.1972.9989806
   Brandes U, 2001, J MATH SOCIOL, V25, P163, DOI 10.1080/0022250X.2001.9990249
   Buldyrev SV, 2010, NATURE, V464, P1025, DOI 10.1038/nature08932
   Cardillo A, 2013, SCI REP-UK, V3, DOI 10.1038/srep01344
   Chattopadhyay S, 2020, IEEE T NETW SCI ENG, V7, P1441, DOI 10.1109/TNSE.2019.2935068
   Chattopadhyay S, 2017, IEEE T COMMUN, V65, P3847, DOI 10.1109/TCOMM.2017.2709302
   Cover T. M., 2006, Elements of Information Theory, DOI DOI 10.1002/047174882X
   Feng FL, 2013, DISCRETE DYN NAT SOC, V2013, DOI 10.1155/2013/391709
   Gao JX, 2012, NAT PHYS, V8, P40, DOI 10.1038/nphys2180
   Gao J, 2011, PHYS REV LETT, V107, DOI 10.1103/PhysRevLett.107.092002
   Gu CG, 2011, PHYS REV E, V84, DOI 10.1103/PhysRevE.84.026101
   Jiang Y, 2014, EVALUATION COMPLEX N
   Kivela M, 2014, J COMPLEX NETW, V2, P203, DOI 10.1093/comnet/cnu016
   Koç Y, 2013, SAFETY SCI, V59, P126, DOI 10.1016/j.ssci.2013.05.006
   LIU Y, 2019, CHAOS INTERDISCIPL J, V29
   Min B, 2016, SCI REP-UK, V6, DOI 10.1038/srep21392
   Parandehgheibi M, 2013, IEEE GLOB COMM CONF, P2164, DOI 10.1109/GLOCOM.2013.6831395
   Parshani R, 2010, EPL-EUROPHYS LETT, V92, DOI 10.1209/0295-5075/92/68002
   Parshani R, 2010, PHYS REV LETT, V105, DOI 10.1103/PhysRevLett.105.048701
   Pastor-Satorras R, 2016, SCI REP-UK, V6, DOI 10.1038/srep18847
   Pradhan P, 2017, PHYS REV E, V96, DOI 10.1103/PhysRevE.96.022312
   Rachdi M, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030260
   Radicchi F, 2015, NAT PHYS, V11, P597, DOI 10.1038/NPHYS3374
   Schneider CM, 2011, P NATL ACAD SCI USA, V108, P3838, DOI 10.1073/pnas.1009440108
   Shorten D, 2018, 2018 CONFERENCE ON ARTIFICIAL LIFE (ALIFE 2018), P374
   Son SW, 2012, EPL-EUROPHYS LETT, V97, DOI 10.1209/0295-5075/97/16006
   Suweis S, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms10179
   van Nimwegen E, 1999, P NATL ACAD SCI USA, V96, P9716, DOI 10.1073/pnas.96.17.9716
   van Nimwegen E, 2006, SCIENCE, V314, P1884, DOI 10.1126/science.1137300
   Watanabe S, 2014, PHYS REV E, V89, DOI 10.1103/PhysRevE.89.012808
   ZHANG Y, 2018, PHYS REV E, V97
NR 34
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19609
EP 19635
DI 10.1007/s11042-021-11110-9
EA JUN 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000663271700001
DA 2024-07-18
ER

PT J
AU Huang, RX
   Ning, JY
   Mei, ZH
   Fang, XD
   Yi, XM
   Gao, YY
   Hui, GH
AF Huang, Ruixiao
   Ning, Jingyuan
   Mei, Zhenghao
   Fang, Xudong
   Yi, Xiaomei
   Gao, Yuanyuan
   Hui, Guohua
TI Study of delivery path optimization solution based on improved ant
   colony model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ant colony algorithm; TSP; Bionic
ID VEHICLE-ROUTING PROBLEM
AB As a bionic optimization algorithm, ant colony algorithm has the advantages of robustness, parallel computation and easy combination and so on, which can solve complicated combinatorial optimization problems. However, the selection strategy of traditional algorithm is more random, which leads to the slow evolution speed. Therefore, an improved ant colony algorithm is proposed, which uses density peak clustering algorithm to classify sites and local optimization strategy. The simulating results of multiple TSP problems demonstrate that the improved algorithm has good optimization ability, greatly improves the quality of the solution and the speed of optimization, and overcomes the slowness and tendency of the algorithm.
C1 [Huang, Ruixiao; Ning, Jingyuan; Mei, Zhenghao; Fang, Xudong; Yi, Xiaomei; Gao, Yuanyuan; Hui, Guohua] Zhejiang A&F Univ, Key Lab Forestry Intelligent Monitoring & Informa, Key Lab Forestry Sensing Technol & Intelligent Eq, Sch Math & Comp Sci,Dept Forestry, Hangzhou 311300, Peoples R China.
C3 Zhejiang A&F University
RP Hui, GH (corresponding author), Zhejiang A&F Univ, Key Lab Forestry Intelligent Monitoring & Informa, Key Lab Forestry Sensing Technol & Intelligent Eq, Sch Math & Comp Sci,Dept Forestry, Hangzhou 311300, Peoples R China.
EM deliver1982@163.com
RI Fang, Xudong/Q-5105-2019
OI Fang, Xudong/0000-0002-0956-3833
FU Scientific Research Project of National Natural Science Foundation of
   China [U1709212]; Scientific Research Project of Zhejiang Province
   [2019C02075, LGG18F030012, LGG19F010012]; Natural Science Foundation of
   Zhejiang Province [LY19F030023, LY19F020048]; College Student Research
   Programme of Zhejiang AF University
FX Scientific Research Project of National Natural Science Foundation of
   China (No. U1709212), Scientific Research Project of Zhejiang Province
   (Grant No. 2019C02075, LGG18F030012, LGG19F010012), Natural Science
   Foundation of Zhejiang Province (Grant No. LY19F030023, LY19F020048).
   and College Student Research Programme of Zhejiang A&F University.
CR Baldacci R, 2006, MULTIPLE DISPOSAL FA
   Belhaiza S, 2018, IEEE SYST J, V12, P1251, DOI 10.1109/JSYST.2016.2601058
   Ben Ticha H, 2017, COMPUT OPER RES, V88, P103, DOI 10.1016/j.cor.2017.06.024
   de Oliveira HCB, 2010, ANN OPER RES, V180, P125, DOI 10.1007/s10479-008-0487-y
   Jiang CB, 2020, INT J BIO-INSPIR COM, V16, P229, DOI 10.1504/IJBIC.2020.112328
   Lai DSW, 2016, TRANSPORT RES E-LOG, V86, P32, DOI 10.1016/j.tre.2015.12.001
   Li HY, 2018, MEMET COMPUT, V10, P103, DOI 10.1007/s12293-016-0222-1
   Meng Xiang-ping, 2013, Control and Decision, V28, P782
   Pradhananga R, 2014, SOCIO-ECON PLAN SCI, V48, P135, DOI 10.1016/j.seps.2014.02.003
   Sánchez-Oro J, 2020, J HEURISTICS, V26, P423, DOI 10.1007/s10732-017-9363-8
   Tarantilis CD, 2012, EXPERT SYST APPL, V39, P4233, DOI 10.1016/j.eswa.2011.09.111
   Wang JH, 2016, IEEE T CYBERNETICS, V46, P582, DOI 10.1109/TCYB.2015.2409837
   Wang J, 2018, IEEE T VEH TECHNOL, V67, P8205, DOI 10.1109/TVT.2018.2840052
   YING Z, 2017, IEEE SYST J, V9, P1100
   Yu B, 2009, EUR J OPER RES, V196, P171, DOI 10.1016/j.ejor.2008.02.028
   Yucenur GN, 2011, EXPERT SYST APPL, V38, P11859, DOI 10.1016/j.eswa.2011.03.077
   Zhang ZZ, 2019, APPL INTELL, V49, P63, DOI 10.1007/s10489-018-1210-6
NR 17
TC 6
Z9 7
U1 8
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28975
EP 28987
DI 10.1007/s11042-021-11142-1
EA JUN 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000661795800001
DA 2024-07-18
ER

PT J
AU Wen, JQ
   Wang, XH
AF Wen, Junqin
   Wang, Xiuhui
TI Cross-view gait recognition based on residual long short-term memory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait classification; Deep learning; Long short-term memory; Residual
   network
ID PERFORMANCE; MODEL
AB As a promising biometric recognition technology, gait recognition has many advantages, such as non-invasive, easy to implement in a long distance, but it is very sensitive to the change of video acquisition angles. In this paper, we propose a novel cross-view gait recognition framework based on residual long short-term memory, namely, CVGR-RLSTM, to extract intrinsic gait features and carry out gait recognition. The proposed framework captures dependencies of human postures in time dimension during walking by inputting randomly sampling frame-by-frame gait energy images. The frame-by-frame gait energy images are generated by merging adjacent gait silhouette images sequentially, which integrates gait features of temporal and spatial dimensions to a certain extent. In the CVGR-RLSTM framework, the embedded residual module is used to further refine the spatial gait features, and the LSTM module is utilized to optimize the temporal gait features. To evaluate the proposed framework, we carried out a series of comparative experiments on the CASIA Dataset B and OU-ISIR LP Dataset. Experimental results show that the proposed method reaches the state-of-the-art level.
C1 [Wen, Junqin] Zhejiang Tech Inst Econ, Hangzhou 310058, Peoples R China.
   [Wang, Xiuhui] China Jiliang Univ, Coll Informat Engn, Key Lab Electromagnet Wave Informat Technol & Met, Hangzhou 310018, Peoples R China.
C3 China Jiliang University
RP Wang, XH (corresponding author), China Jiliang Univ, Coll Informat Engn, Key Lab Electromagnet Wave Informat Technol & Met, Hangzhou 310018, Peoples R China.
EM wenjq@zjtie.edu.cn; wangxiuhui@cjlu.edu.cn
OI Wang, Xiuhui/0000-0003-1773-9760
FU National Natural Science Foundation of China [61602431]; Natural Science
   Foundation of Zhejiang Province [Y20F020113]
FX This research was funded by the National Natural Science Foundation of
   China, grant number No. 61602431 and the Natural Science Foundation of
   Zhejiang Province, grant number No.Y20F020113.
CR Abdulsattar F, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY AND BEHAVIOR ANALYSIS (ISBA), DOI 10.1109/ISBA.2016.7477229
   Battistone F, 2019, PATTERN RECOGN LETT, V126, P132, DOI 10.1016/j.patrec.2018.05.004
   Boulgouris NV, 2013, IEEE T IMAGE PROCESS, V22, P3636, DOI 10.1109/TIP.2013.2266578
   Chen K, 2016, IEEE-ACM T AUDIO SPE, V24, P1185, DOI 10.1109/TASLP.2016.2539499
   Deng MQ, 2017, PATTERN RECOGN, V67, P186, DOI 10.1016/j.patcog.2017.02.014
   Ercolano G, 2021, INTEL SERV ROBOT, V14, P175, DOI 10.1007/s11370-021-00358-7
   Feng Y, 2016, INT C PATT RECOG, P325, DOI 10.1109/ICPR.2016.7899654
   Gao Z, 2019, IEEE INTERNET THINGS, V6, P9280, DOI 10.1109/JIOT.2019.2911669
   Gao Z, 2016, NEUROCOMPUTING, V173, P110, DOI 10.1016/j.neucom.2015.07.105
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Han JG, 2012, IEEE T CONSUM ELECTR, V58, P255, DOI 10.1109/TCE.2012.6227420
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253
   Li YH, 2018, PATTERN RECOGN, V80, P109, DOI 10.1016/j.patcog.2018.03.005
   Muramatsu D, 2016, IEEE T CYBERNETICS, V46, P1602, DOI 10.1109/TCYB.2015.2452577
   Muramatsu D, 2015, IEEE T IMAGE PROCESS, V24, P140, DOI 10.1109/TIP.2014.2371335
   Perrett T, 2019, PROC CVPR IEEE, P7844, DOI 10.1109/CVPR.2019.00804
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Shiraga K, 2016, INT CONF BIOMETR
   Takemura N, 2019, IEEE T CIRC SYST VID, V29, P2708, DOI 10.1109/TCSVT.2017.2760835
   Tang J, 2017, IEEE T IMAGE PROCESS, V26, P7, DOI 10.1109/TIP.2016.2612823
   Thapar D, 2018, 2018 IEEE 4TH INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY, AND BEHAVIOR ANALYSIS (ISBA)
   Wang XL, 2019, INT CONF MEASURE, P1, DOI [10.1109/TCYB.2019.2935141, 10.1109/ICMIC48233.2019.9068567]
   Wang XH, 2020, NEURAL COMPUT APPL, V32, P7275, DOI 10.1007/s00521-019-04256-z
   Wang XH, 2018, MULTIMED TOOLS APPL, V77, P12545, DOI 10.1007/s11042-017-4903-7
   Wang XH, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S0129065719500278
   Wang XH, 2020, NEURAL COMPUT APPL, V32, P14275, DOI 10.1007/s00521-019-04524-y
   Watanabe Yuji, 2020, Procedia Computer Science, V176, P3873, DOI 10.1016/j.procs.2020.09.001
   Wolf T, 2016, IEEE IMAGE PROC, P4165, DOI 10.1109/ICIP.2016.7533144
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Yu JC, 2019, IEEE T MAGN, V55, DOI 10.1109/TMAG.2019.2896177
   Yu SQ, 2006, INT C PATT RECOG, P441
   Yu SQ, 2017, IEEE COMPUT SOC CONF, P532, DOI 10.1109/CVPRW.2017.80
   Yu SQ, 2017, NEUROCOMPUTING, V239, P81, DOI 10.1016/j.neucom.2017.02.006
NR 37
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28777
EP 28788
DI 10.1007/s11042-021-11107-4
EA JUN 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000660815700003
DA 2024-07-18
ER

PT J
AU Martins, NC
   Marques, B
   Alves, J
   Araújo, T
   Dias, P
   Santos, BS
AF Martins, Nuno Cid
   Marques, Bernardo
   Alves, Joao
   Araujo, Tiago
   Dias, Paulo
   Santos, Beatriz Sousa
TI Augmented reality situated visualization in decision-making
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Decision-making; Augmented reality; Situated visualization
ID SUPPORT-SYSTEMS; MODEL
AB Decision-making processes and decision support systems (DSS) have been improved by a variety of methods originated from several scientific fields, such as information science and artificial intelligence (AI). Situated visualization (SV) allows presenting visual data representations in context and may support better DSS. Its main characteristic is to display data representations near the data referent. As augmented reality (AR) is becoming more mature, affordable, and widespread, using it as a tool for SV becomes viable in several situations. Moreover, it may provide a positive contribution to more effective and efficient decision-making, as the users have contextual, relevant, and appropriate information that fosters more informed choices. As new challenges and opportunities arise, it is important to understand the relevance of intertwining these fields. Based on literature analysis, this paper introduces the main concepts involved, and, through practical examples, addresses and discusses current areas of application, benefits, challenges, and opportunities of using SV through AR to visualize data in context to support better decision-making processes. In the end, a set of guidelines for the design and implementation of DSS based on situated augmented reality are proposed.
C1 [Martins, Nuno Cid] Univ Aveiro, Coimbra Inst Engn, Polytech Inst Coimbra, IEETA, Coimbra, Portugal.
   [Marques, Bernardo; Alves, Joao; Dias, Paulo; Santos, Beatriz Sousa] Univ Aveiro, IEETA, DETI, Aveiro, Portugal.
   [Araujo, Tiago] Univ Fed Para, PPGCC, Univ Aveiro, IEETA, Belem, Para, Brazil.
C3 Universidade de Coimbra; Universidade de Aveiro; Universidade de Aveiro;
   Universidade Federal do Para
RP Martins, NC (corresponding author), Univ Aveiro, Coimbra Inst Engn, Polytech Inst Coimbra, IEETA, Coimbra, Portugal.
EM nuno.cid.martins@ua.pt; bernardo.marques@ua.pt; jbga@ua.pt;
   tiagoaraujo@ufpa.br; paulo.dias@ua.pt; bss@ua.pt
RI Dias, Paulo PMD/G-3681-2013; Cid Martins, Nuno/AGT-5533-2022; Marques,
   Bernardo/AGY-4340-2022
OI Dias, Paulo PMD/0000-0002-3754-2749; Cid Martins,
   Nuno/0000-0002-3397-6793; Marques, Bernardo/0000-0002-4454-710X;
   Oliveira de Araujo, Tiago Davi/0000-0002-4971-9951
FU IEETA - Institute of Electronics and Informatics Engineering of Aveiro -
   FCT - Foundation for Science and Technology [UID/CEC/00127/2019]
FX We would like to thank the reviewers for their thoughtful comments and
   efforts towards improving this manuscript. This study was supported by
   IEETA - Institute of Electronics and Informatics Engineering of Aveiro,
   funded by National Funds through the FCT - Foundation for Science and
   Technology, in the context of the project UID/CEC/00127/2019.
CR Alter S., 1980, Decision Support Systems: Current Practise and Continuing Challenges
   [Anonymous], 2003, DSS NEWS
   [Anonymous], 2010, DECISION SUPPORT SYS
   Arth Clemens, 2015, ARXIV150501319
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma R., 2017, Applied Industrial Optics: Spectroscopy, Imaging and Metrology
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Benito JL., 2013, 5 JOINT VIRT REAL C, P113
   Berryman Donna R., 2012, Medical Reference Services Quarterly, V31, P212, DOI 10.1080/02763869.2012.670604
   Bohanec M, 2003, SPRING INT SER ENG C, V745, P23
   Bridges SA, 2020, J SPEC EDUC TECHNOL, V35, P3, DOI 10.1177/0162643419836411
   Brito PQ, 2018, MULTIMED TOOLS APPL, V77, P7487, DOI 10.1007/s11042-017-4658-1
   Buchanan L, 2006, HARVARD BUS REV, V84, P32
   Burstein F., 2008, Handbook on Decision Support Systems, P2, DOI DOI 10.1007/978-3-540-48716-6
   Card S K., 1999, READINGS INFORM VISU
   Caricato P., 2014, IFAC PROC VOL 19 IFA, V47, P754, DOI [10.3182/20140824-6-ZA-1003.01947, DOI 10.3182/20140824-6-ZA-1003.01947]
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Caudell T. P., 1992, P HAW INT C SYST SCI, V2, P659, DOI [10.1109/HICSS.1992.183317, DOI 10.1109/HICSS.1992.183317]
   Chai Zhengmeng, 2011, Proceedings of the 2011 International Symposium on Information Technology in Medicine and Education (ITME 2011), P401, DOI 10.1109/ITiME.2011.6132134
   Chen CT, 2006, Innovations in Design & Decision Support Systems in Architecture and Urban Planning, P487, DOI 10.1007/978-1-4020-5060-2_31
   Choi JH, 2020, MULTIMED TOOLS APPL, V79, P16349, DOI 10.1007/s11042-020-08939-x
   Druzdzel Marek., 2002, ENCY LIB INFORM SCI
   Dwyer T., 2016, DAGST SEM
   Dwyer T, 2018, LECT NOTES COMPUT SC, V11190, P1, DOI 10.1007/978-3-030-01388-2_1
   Eissele M., 2008, GRAPH INTERFACE, P89
   ElSayed NAM, 2016, J VISUAL LANG COMPUT, V36, P13, DOI 10.1016/j.jvlc.2016.07.006
   ElSayed NAM, 2015, P IEEE VIRT REAL ANN, P175, DOI 10.1109/VR.2015.7223352
   Filip FG, 2017, AUTO COLLAB E-SERV, P1, DOI 10.1007/978-3-319-47221-8
   Finlay P.N., 1994, INTRO DECISION SUPPO, V2nd
   Fraga-Lamas P, 2018, IEEE ACCESS, V6, P13358, DOI 10.1109/ACCESS.2018.2808326
   Fuhrmann A, 1997, VISUALIZATION '97 - PROCEEDINGS, P459, DOI 10.1109/VISUAL.1997.663921
   Grasset R, 2012, INT SYM MIX AUGMENT, P177, DOI 10.1109/ISMAR.2012.6402555
   Grubert J, 2017, IEEE T VIS COMPUT GR, V23, P1706, DOI 10.1109/TVCG.2016.2543720
   Holsapple C.W., 2008, Handbook on Decision Support Systems, V1, P21
   Jansen Y, 2013, IEEE T VIS COMPUT GR, V19, P2396, DOI 10.1109/TVCG.2013.134
   Jerald Jason, 2015, The VR Book: Human-Centered Design for Virtual Reality, DOI [DOI 10.1145/2792790, 10.1145/2792790]
   Juan MC., 2019, MULTIMED TOOLS APPL, P1
   Kaklauskas A., 2016, INIMPACT J INNOV IMP, V6, P131
   Kalkofen D, 2011, HANDBOOK OF AUGMENTED REALITY, P65, DOI 10.1007/978-1-4614-0064-6_3
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Kosara R, 2007, IEEE INT CONF INF VI, P631
   Krakhoferand S, 2015, PROCEEDINGS OF THE 20TH INTERNATIONAL CONFERENCE ON COMPUTER-AIDED ARCHITECTURAL DESIGN RESEARCH IN ASIA (CAADRIA 2015), P231
   Lorenz M, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P151, DOI 10.1109/ISMAR-Adjunct.2018.00055
   Maciel A., 2020, COMPUT GRAPH-UK
   Marques B, 2019, EUROGRAPHICS SHORT P, ppp45
   Marques B, 2019, IEEE INT CON INF VIS, P13, DOI 10.1109/IV.2019.00012
   Marriott K, 2018, LECT NOTES COMPUTER, V11190
   Meiguins BS, 2006, INFORMATION VISUALIZATION-BOOK, P529
   Mekni M., 2014, APPL COMPUTATIONAL S, P205
   Mendez E, 2008, IEEE COMPUT GRAPH, V28, P48, DOI 10.1109/MCG.2008.53
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Milovanovic J., 2017, P 17 INT C CAAD FUT
   Munzner T, 2014, VISUALIZATION ANAL D, DOI DOI 10.1201/B17511
   Nee AYC, 2012, CIRP ANN-MANUF TECHN, V61, P657, DOI 10.1016/j.cirp.2012.05.010
   Nizam SS Muhammad., 2018, Int. J. Adv. Sci. Eng. Inf. Technol, V8, P1460, DOI [10.18517/ijaseit.8.4-2.6824, DOI 10.18517/IJASEIT.8.4-2.6824]
   Park S. J., 2020, 2020 45th International Conference on Infrared, Millimeter, and Terahertz Waves (IRMMW-THz), DOI 10.1109/IRMMW-THz46771.2020.9370679
   Power D., 2003, A Brief History of Decision Support Systems
   Power DJ, 2007, DECIS SUPPORT SYST, V43, P1044, DOI 10.1016/j.dss.2005.05.030
   Power DJ, 2011, ANN INFORM SYST, V14, P25, DOI 10.1007/978-1-4419-6181-5_2
   Quigley A, 2017, WORKSH IMM AN
   Robinett W., 1992, PRESENCE, V1, P229, DOI [10.1162/pres.1992.1.2.229, DOI 10.1162/PRES.1992.1.2.229]
   Schall G, 2009, PERS UBIQUIT COMPUT, V13, P281, DOI 10.1007/s00779-008-0204-5
   Schmalstieg D., 2016, AUGMENTED REALITY PR
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Sutherland IE., 1968, Assoc. Comput. Machinery, V68, P757, DOI [DOI 10.1145/1476589.1476686, 10.1145/1476589.1476686, 10.1145/1476589.1476686.2.2.1]
   Syberfeldt A, 2016, PROC CIRP, V44, P108, DOI 10.1016/j.procir.2016.02.017
   Tatzgern M., 2015, PhD Thesis
   Turban E., 2005, Decision Support Systems and Intelligent Systems, V7th ed
   Ware C., 2020, INFORM VISUALIZATION
   Weiskopf D, 2020, ARXIV200205963
   Whinstone AB, 1983, EVOLVING ROLES DECIS, P343
   White S., 2008, P ACM CHI 2008 WORKS
   White S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1117
   White Sean Michael, 2009, Interaction and presentation techniques for situated visualization. phd
   Willett W, 2017, IEEE T VIS COMPUT GR, V23, P461, DOI 10.1109/TVCG.2016.2598608
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
   Zhu B., 2008, Handbook on Decision Support Systems, V2, P699, DOI [10.1007/978-3-540-48716-632, DOI 10.1007/978-3-540-48716-632]
NR 77
TC 33
Z9 34
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 14749
EP 14772
DI 10.1007/s11042-021-10971-4
EA JUN 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000658112700001
DA 2024-07-18
ER

PT J
AU Sood, S
   Singh, H
AF Sood, Shivani
   Singh, Harjeet
TI Computer Vision and Machine Learning based approaches for Food Security:
   A Review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Food Ssecurity; Deep learning; Convolutional neural network; Smart
   farming
ID CLASSIFICATION; AGRICULTURE; RECOGNITION; DISEASES; SEGMENTATION;
   FEATURES; SYSTEM
AB With the rapidly increase of population every day, it has become a major issue to fulfill everyone's need for food products (i.e., vegetables, fruits, milk, wheat, etc.) due to limited production of food products. Moreover, healthy food utilization among people is the foremost requirement. The major factors that affect the food system includes increasing food shortage, decreasing quality, wastage, and loss of food products, limited natural resources, etc. This article addresses the various computer vision and machine learning based techniques, used to minimize the aforementioned issues. Image processing has become an effective technique for the analysis of many research applications. This study intends to focus on analysis of image processing based applications in food products and agriculture field. Such applications help in decision making , disease prediction, classification, fruit sorting, soil quality measurement, etc. Moreover, a comprehensive review has been accomplished for various computer vision and statistical approaches used in food production and agricultural field and concludes that Deep Learning (DL) based approaches produce better results, specifically for image processing applications. Additionally, an effort has been made to provide a list of publicly available datasets for the related study.
C1 [Sood, Shivani; Singh, Harjeet] Chitkara Univ, Inst Engn & Technol, Chandigarh, Punjab, India.
C3 Chitkara University, Punjab; Panjab University
RP Singh, H (corresponding author), Chitkara Univ, Inst Engn & Technol, Chandigarh, Punjab, India.
EM shivani.sood@chitkara.edu.in; harjeet.singh@chitkara.edu.in
RI University, Chitkara/AAZ-3040-2021; An, Hongda/GNH-4090-2022; Singh,
   Harjeet/AAE-4215-2020
OI University, Chitkara/0000-0003-3776-7136; Singh,
   Harjeet/0000-0002-9760-5166; Sood, Shivani/0000-0002-2642-6187
CR Adeel A, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12569
   Adeel A, 2019, SUSTAIN COMPUT-INFOR, V24, DOI 10.1016/j.suscom.2019.08.002
   Akmal Farah, 2020, 2020 6th Conference on Data Science and Machine Learning Applications (CDMA), P146, DOI 10.1109/CDMA47397.2020.00031
   Amara J., 2017, Lecture Notes in Informatics (LNI), Gesellschaft fur Informatik, P79
   [Anonymous], 2008, CLIM CHANG FOOD SEC
   [Anonymous], 2014, P AFITA
   [Anonymous], 2012, Computer vision: models, learning, and inference
   Bargoti Suchet, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3626, DOI 10.1109/ICRA.2017.7989417
   Chandini AA, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P150, DOI 10.1109/ICACCI.2018.8554876
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen SW, 2017, IEEE ROBOT AUTOM LET, V2, P781, DOI 10.1109/LRA.2017.2651944
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Choi HS, 2018, IEEE INT CONF INDUST, P2081, DOI 10.1109/ICIT.2018.8352510
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   dos Santos JFC, 2016, REV BRAS ENG AGR AMB, V20, P1051, DOI 10.1590/1807-1929/agriambi.v20n12p1051-1056
   Dyrmann M., 2016, P INT C AGR ENG AARH, P26
   Dyrmann M, 2016, BIOSYST ENG, V151, P72, DOI 10.1016/j.biosystemseng.2016.08.024
   FAO, 2014, Family Farmers: Feeding the World, Caring for the Earth
   García-Esteban JA, 2018, IEEE INTL CONF IND I, P221, DOI 10.1109/INDIN.2018.8471994
   Gebbers R, 2010, SCIENCE, V327, P828, DOI 10.1126/science.1183899
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003
   Gunders D.J. Bloom., 2017, WASTED AM IS LOSING
   Gustavsson J., 2011, Global food losses and food waste: extent, causes and prevention
   Hall D, 2015, IEEE WINT CONF APPL, P797, DOI 10.1109/WACV.2015.111
   Hnoohom N, 2018, 2018 1ST INTERNATIONAL ECTI NORTHERN SECTION CONFERENCE ON ELECTRICAL, ELECTRONICS, COMPUTER AND TELECOMMUNICATIONS ENGINEERING (ECTI-NCON, P116, DOI 10.1109/ECTI-NCON.2018.8378293
   Hornberg A., 2017, Handbook of Machine and Computer Vision: The Guide for Developers and Users, DOI [DOI 10.1002/9783527413409, 10.1002/9783527413409]
   Iqbal Z, 2018, COMPUT ELECTRON AGR, V153, P12, DOI 10.1016/j.compag.2018.07.032
   Kamilaris A, 2016, 2016 IEEE 3RD WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P442, DOI 10.1109/WF-IoT.2016.7845467
   Kaya A, 2019, COMPUT ELECTRON AGR, V158, P20, DOI 10.1016/j.compag.2019.01.041
   Khan MA, 2020, MULTIMED TOOLS APPL, V79, P25763, DOI 10.1007/s11042-020-09244-3
   Khan MA, 2020, MULTIMED TOOLS APPL, V79, P18627, DOI 10.1007/s11042-020-08726-8
   Khan MA, 2019, IEEE ACCESS, V7, P46261, DOI 10.1109/ACCESS.2019.2908040
   Khan MA, 2018, COMPUT ELECTRON AGR, V155, P220, DOI 10.1016/j.compag.2018.10.013
   Kuwata K, 2015, INT GEOSCI REMOTE SE, P858, DOI 10.1109/IGARSS.2015.7325900
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Li X, 2018, PROCEEDINGS 2018 33RD YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P1072, DOI 10.1109/YAC.2018.8406530
   Liakos KG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082674
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Malambo L, 2018, INT J APPL EARTH OBS, V64, P31, DOI 10.1016/j.jag.2017.08.014
   Marsland S., 2011, Machine learning: an algorithmic perspective, DOI DOI 10.1201/9781420067194
   Martinel N, 2018, IEEE WINT CONF APPL, P567, DOI 10.1109/WACV.2018.00068
   Mc Carthy U, 2018, TRENDS FOOD SCI TECH, V77, P11, DOI 10.1016/j.tifs.2018.05.002
   McGuire S, 2015, ADV NUTR, V6, P623, DOI 10.3945/an.115.009936
   Milioto A, 2017, ISPRS ANN PHOTO REM, V4-2, P41, DOI 10.5194/isprs-annals-IV-2-W3-41-2017
   Minh DHT, 2018, IEEE GEOSCI REMOTE S, V15, P464, DOI 10.1109/LGRS.2018.2794581
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Nnachi, 2019, THESIS NUI GALWA
   Pantazi XE, 2019, COMPUT ELECTRON AGR, V156, P96, DOI 10.1016/j.compag.2018.11.005
   PASCAL VOC Project, 2012, PASCAL VISUAL OBJECT
   Pound MP, 2017, GIGASCIENCE, V6, DOI 10.1093/gigascience/gix083
   Rahnemoonfar M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040905
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Rauf HT, 2019, DATA BRIEF, V26, DOI 10.1016/j.dib.2019.104340
   Reyes A, 2015, FINE TUNING DEEP CON
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Sakti MBG, 2018, IOP C SER EARTH ENV, V200, DOI 10.1088/1755-1315/200/1/012004
   Sehgal G, 2017, 2017 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P47, DOI 10.1109/VDS.2017.8573443
   SEN A, 1981, Q J ECON, V96, P433, DOI 10.2307/1882681
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Shrivakshan G., 2012, INT J COMPUT SCI ISS, V9, P269
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Song XD, 2016, J ARID LAND, V8, P734, DOI 10.1007/s40333-016-0049-0
   Thakur R., 2019, Step by step VGG16 implementation in Keras for beginners
   Trujillano F, 2018, PROC IEEE 1 COLOMBIA, P1
   Tyagi AC, 2016, IRRIG DRAIN, V65, P388, DOI 10.1002/ird.2076
   UN Food and Agriculture Organization, 2012, STATE FOOD INSECURIT
   United Nations, 1975, WORLD FOOD C ROM 5 1
   Wise T.A., 2013, CAN WE FEED WORLD 20
   Zhang SW, 2017, COMPUT ELECTRON AGR, V134, P135, DOI 10.1016/j.compag.2017.01.014
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
NR 73
TC 21
Z9 21
U1 2
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27973
EP 27999
DI 10.1007/s11042-021-11036-2
EA MAY 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000655574500003
DA 2024-07-18
ER

PT J
AU Tan, H
   He, L
   Huang, ZC
   Zhan, H
AF Tan, Hua
   He, Lang
   Huang, Zhang-Can
   Zhan, Hang
TI Online signature verification based on dynamic features from gene
   expression programming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online signature verification; GEP; Curve fitting; Curvature and
   torsion; Hausdorff distance; Neural network classifier
ID SYSTEM
AB Gene Expression Programming (GEP) is a powerful evolutionary algorithm with simple, linear and compact chromosomes, which has been applied in many fields to solve a large variety of complex problems such as logistic regression, function finding and time series prediction. Since online signature data are composed of discrete points, it is difficult to represent by functional forms, resulting in a limited amount of information used in calculating feature values. Hausdorff distance is utilized as a similarity measure to compute the maximum distance between two point sets, which reduces computational complexity compared with other distance measures. The main contributions of this work are: (1) In preprocessing stage, GEP is used to make signature curve continuous and control each parameter to obtain a fitting curve. Curve fitting is to find a suitable function that is the best fitting for a given set of data; (2) In feature extraction stage, curvature and torsion are utilized to construct eight feature sets for characterizing each user's signatures, and then Hausdorff distance is proposed to calculate the distances between feature sets of two signatures to form an eight-dimensional feature vector; (3) In verification stage, combined with Feed-Forward BP Neural Network classifier, distance matrices consisting of feature vectors are trained and tested many times. The best performances can be provided with false rejection rate, false acceptance rate, average error rate and standard deviation. The experimental results implemented on three available online signature databases MCYT-100, SVC2004 and SUSIG indicate the effectiveness and robustness of our proposed method.
C1 [Tan, Hua; He, Lang; Huang, Zhang-Can; Zhan, Hang] Wuhan Univ Technol, Sch Sci, Wuhan 430070, Peoples R China.
C3 Wuhan University of Technology
RP Tan, H (corresponding author), Wuhan Univ Technol, Sch Sci, Wuhan 430070, Peoples R China.
EM tanhua123@whut.edu.cn
RI Tan, tanhua/ISA-0905-2023
CR Alhaddad M.J., 2012, World of Computer Science and Information Technology Journal (WCSIT), V2, P46
   Aqili N, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL AND INFORMATION TECHNOLOGIES (ICEIT), P410, DOI 10.1109/EITech.2016.7519631
   Che C, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0456-1
   CPAKA K, 2016, APPL SOFT COMPUT, V43, P47, DOI DOI 10.1016/J.ASOC.2016.02.017
   Cpalka K, 2014, PATTERN RECOGN, V47, P2652, DOI 10.1016/j.patcog.2014.02.012
   Cpalka K, 2014, EXPERT SYST APPL, V41, P4170, DOI 10.1016/j.eswa.2013.12.047
   Doroz R, 2016, NEUROCOMPUTING, V171, P921, DOI 10.1016/j.neucom.2015.07.026
   Durrani MY, 2019, CLUSTER COMPUT, V22, pS7229, DOI 10.1007/s10586-017-1129-4
   [方丽菁 Fang Lijing], 2012, [图学学报, Journal of Graphics], V33, P9
   Fang X, 2017, 7 INT C COMP ENG NET, P1
   Ferreira C., 2001, Complex Systems, V13, P87
   Garcia-Capulin CH, 2015, GENET PROGRAM EVOL M, V16, P151, DOI 10.1007/s10710-014-9231-3
   He L, 2019, MULTIMED TOOLS APPL, V78, P19253, DOI 10.1007/s11042-019-7264-6
   Kholmatov A, 2009, PATTERN ANAL APPL, V12, P227, DOI 10.1007/s10044-008-0118-x
   Manjunatha KS, 2016, PATTERN RECOGN LETT, V80, P129, DOI 10.1016/j.patrec.2016.06.016
   Ooi SY, 2016, APPL SOFT COMPUT, V40, P274, DOI 10.1016/j.asoc.2015.11.039
   Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078
   Patel OP, 2019, SOFT COMPUT, V23, P3067, DOI 10.1007/s00500-017-2954-3
   Peng YZ, 2014, NEUROCOMPUTING, V137, P293, DOI 10.1016/j.neucom.2013.05.062
   Pirlo G, 2015, IEEE T HUM-MACH SYST, V45, P805, DOI 10.1109/THMS.2015.2443050
   Qiang HQ., 2014, APPL MECH MAT, V635, P1039, DOI [10.4028/www.scientific.net/AMM.635-637.1039, DOI 10.4028/WWW.SCIENTIFIC.NET/AMM.635-637.1039]
   Sharma A, 2017, IEEE T INF FOREN SEC, V12, P705, DOI 10.1109/TIFS.2016.2632063
   Sharma A, 2016, PATTERN RECOGN LETT, V84, P22, DOI 10.1016/j.patrec.2016.07.015
   Tang L, 2018, IEEE T INF FOREN SEC, V13, P861, DOI 10.1109/TIFS.2017.2769023
   Xia XH, 2018, PATTERN RECOGN, V74, P422, DOI 10.1016/j.patcog.2017.09.033
   Yang L, 2019, CLUSTER COMPUT, V22, P1691, DOI 10.1007/s10586-018-1749-3
   Yang L, 2018, SOFT COMPUT, V22, P7811, DOI 10.1007/s00500-018-3477-2
   Yeung DY, 2004, LECT NOTES COMPUT SC, V3072, P16
   Yuen CT., 2011, RES J APPL SCI ENG T, V3, P1318
   Zalasinski M, 2016, LECT NOTES ARTIF INT, V9693, P232, DOI [10.1007/978-3-319-39384-1_21, 10.1007/978-3-319-39384-12_1]
   Zhong JH, 2016, IEEE T EVOLUT COMPUT, V20, P65, DOI 10.1109/TEVC.2015.2424410
   [朱延娟 ZHU Yanjuan], 2007, [中国图象图形学报, Journal of Image and Graphics], V12, P164
NR 32
TC 11
Z9 12
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15195
EP 15221
DI 10.1007/s11042-021-11063-z
EA MAY 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000650615800002
DA 2024-07-18
ER

PT J
AU Tuncer, T
   Dogan, S
   Naik, GR
   Plawiak, P
AF Tuncer, Turker
   Dogan, Sengul
   Naik, Ganesh R.
   Plawiak, Pawel
TI Epilepsy attacks recognition based on 1D octal pattern, wavelet
   transform and EEG signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete wavelet transform; 1D octal pattern; Electroencephalogram
   signals; Classification; Epilepsy
ID EMPIRICAL MODE DECOMPOSITION; VECTOR REGRESSION-MODEL;
   SURFACE-ELECTROMYOGRAPHY; SEIZURE DETECTION; CLASSIFICATION; MACHINE;
   ENTROPY; CANCER; CNN
AB Electroencephalogram (EEG) signals have been generally utilized for diagnostic systems. Nowadays artificial intelligence-based systems have been proposed to classify EEG signals to ease diagnosis process. However, machine learning models have generally been used deep learning based classification model to reach high classification accuracies. This work focuses classification epilepsy attacks using EEG signals with a lightweight and simple classification model. Hence, an automated EEG classification model is presented. The used phases of the presented automated EEG classification model are (i) multileveled feature generation using one-dimensional (1D) octal-pattern (OP) and discrete wavelet transform (DWT). Here, main feature generation function is the presented octal-pattern. DWT is employed for level creation. By employing DWT frequency coefficients of the EEG signal is obtained and octal-pattern generates texture features from raw EEG signal and wavelet coefficients. This DWT and octal-pattern based feature generator extracts 128 x 8 = 1024 (Octal-pattern generates 128 features from a signal, 8 signal are used in the feature generation 1 raw EEG and 7 wavelet low-pass filter coefficients). (ii) To select the most useful features, neighborhood component analysis (NCA) is deployed and 128 features are selected. (iii) The selected features are feed to k nearest neighborhood classifier. To test this model, an epilepsy seizure dataset is used and 96.0% accuracy is attained for five categories. The results clearly denoted the success of the presented octal-pattern based epilepsy classification model.
C1 [Tuncer, Turker; Dogan, Sengul] Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkey.
   [Naik, Ganesh R.] Western Sydney Univ, Biomed Engn & Neuromorph Syst BENS, MARCS Inst, Penrith, NSW 2145, Australia.
   [Plawiak, Pawel] Cracow Univ Technol, Fac Comp Sci & Telecommun, Dept Comp Sci, Warszawska 24 St, PL-31155 Krakow, Poland.
   [Plawiak, Pawel] Polish Acad Sci, Inst Theoret & Appl Informat, Baltycka 5, PL-44100 Gliwice, Poland.
C3 Firat University; Western Sydney University; Cracow University of
   Technology; Polish Academy of Sciences; Institute of Theoretical &
   Applied Informatics of the Polish Academy of Sciences
RP Plawiak, P (corresponding author), Cracow Univ Technol, Fac Comp Sci & Telecommun, Dept Comp Sci, Warszawska 24 St, PL-31155 Krakow, Poland.; Plawiak, P (corresponding author), Polish Acad Sci, Inst Theoret & Appl Informat, Baltycka 5, PL-44100 Gliwice, Poland.
EM turkertuncer@firat.edu.tr; sdogan@firat.edu.tr;
   ganesh.naik@westernsydney.edu.au; plawiak@pk.edu.pl
RI TUNCER, Turker/W-4846-2018; Pławiak, Paweł/K-8151-2013; DOGAN,
   Sengul/W-4854-2018; Naik, Ganesh/G-5538-2011
OI Pławiak, Paweł/0000-0002-4317-2801; DOGAN, Sengul/0000-0001-9677-5684;
   Naik, Ganesh/0000-0003-1790-9838
CR Abdar M, 2020, PATTERN RECOGN LETT, V132, P123, DOI 10.1016/j.patrec.2018.11.004
   Abdar M, 2017, LIBR HI TECH, V35, P521, DOI 10.1108/LHT-01-2017-0030
   Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Acharya UR, 2018, COMPUT BIOL MED, V100, P270, DOI 10.1016/j.compbiomed.2017.09.017
   Al-Salman W, 2019, BIOMED SIGNAL PROCES, V48, P80, DOI 10.1016/j.bspc.2018.10.004
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   Augustyniak P, 2006, PHYSIOL MEAS, V27, P597, DOI 10.1088/0967-3334/27/7/004
   Ayyad SM, 2019, BIOSYSTEMS, V176, P41, DOI 10.1016/j.biosystems.2018.12.009
   Balasundaram S, 2016, NEURAL COMPUT APPL, V27, P1629, DOI 10.1007/s00521-015-1961-5
   Becerra-García RA, 2017, NEUROCOMPUTING, V250, P28, DOI 10.1016/j.neucom.2016.10.077
   Borah P, 2019, NEURAL COMPUT APPL, P1
   Borah P, 2020, APPL INTELL, V50, P1327, DOI 10.1007/s10489-019-01596-0
   Das Adhikary D, 2021, MULTIMED TOOLS APPL, V80, P35123, DOI 10.1007/s11042-020-09658-z
   Das A, 2019, COGN SYST RES, V54, P165, DOI 10.1016/j.cogsys.2018.12.009
   Dose H, 2018, EXPERT SYST APPL, V114, P532, DOI 10.1016/j.eswa.2018.08.031
   Duan N, 2019, J IND INF INTEGR, V15, P201, DOI 10.1016/j.jii.2018.09.001
   Fan GF, 2020, SUSTAIN CITIES SOC, V61, DOI 10.1016/j.scs.2020.102320
   Fan GF, 2020, J FORECASTING, V39, P737, DOI 10.1002/for.2655
   Fan GF, 2016, NEUROCOMPUTING, V173, P958, DOI 10.1016/j.neucom.2015.08.051
   Fan GF, 2013, ENERGIES, V6, P1887, DOI 10.3390/en6041887
   Fathima T., 2011, MES Journal of Technology and Management, V2, P108
   Faust O, 2018, COMPUT METH PROG BIO, V161, P1, DOI 10.1016/j.cmpb.2018.04.005
   Ghayab Hadi Ratham Al, 2016, Brain Inform, V3, P85, DOI 10.1007/s40708-016-0039-1
   Giannakeas N, 2018, HEAL TECHNOL, P1
   Gruszczynska I, 2019, ADV MED SCI-POLAND, V64, P58, DOI 10.1016/j.advms.2018.08.003
   Gupta D, 2019, IEEE SYS MAN CYBERN, P2298, DOI 10.1109/SMC.2019.8913897
   Gupta D, 2017, 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P1
   Hammad M, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12547
   Hassoon M, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER AND APPLICATIONS (ICCA), P299, DOI 10.1109/COMAPP.2017.8079783
   Hazarika BB, 2021, INT J ENVIRON SCI TE, V18, P2675, DOI 10.1007/s13762-020-02967-8
   Hazarika BB, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106626
   Hong WC, 2019, ENERGIES, V12, DOI 10.3390/en12061093
   Hussain S, 2014, INT J ADV COMPUT SC, V5, P22
   Ibrahim S, 2018, BIOCYBERN BIOMED ENG, V38, P16, DOI 10.1016/j.bbe.2017.08.006
   Iwendi C, 2020, IEEE ACCESS, V8, P72650, DOI 10.1109/ACCESS.2020.2988160
   Izonin I, 2019, LECT NOTES COMPUT SC, V11506, P467, DOI 10.1007/978-3-030-20521-8_39
   Jiang XT, 2017, MED ENG PHYS, V41, P63, DOI 10.1016/j.medengphy.2017.01.015
   Kandala RNVPS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235079
   Kaya Y, 2018, AUSTRALAS PHYS ENG S, V41, P721, DOI 10.1007/s13246-018-0669-0
   Kaya Y, 2015, AUSTRALAS PHYS ENG S, V38, P435, DOI 10.1007/s13246-015-0362-5
   Kaya Y, 2014, APPL MATH COMPUT, V243, P209, DOI 10.1016/j.amc.2014.05.128
   Kocadagli O, 2017, EXPERT SYST APPL, V88, P419, DOI 10.1016/j.eswa.2017.07.020
   Kumar Y, 2014, NEUROCOMPUTING, V133, P271, DOI 10.1016/j.neucom.2013.11.009
   Li MW, 2019, NONLINEAR DYNAM, V97, P2579, DOI 10.1007/s11071-019-05149-5
   Li YZ, 2018, NEUROCOMPUTING, V314, P336, DOI 10.1016/j.neucom.2018.06.068
   Masterton RAJ, 2007, NEUROIMAGE, V37, P202, DOI 10.1016/j.neuroimage.2007.02.060
   Motamedi-Fakhr S, 2014, BIOMED SIGNAL PROCES, V10, P21, DOI 10.1016/j.bspc.2013.12.003
   Mutlu AY, 2018, BIOMED SIGNAL PROCES, V40, P33, DOI 10.1016/j.bspc.2017.08.023
   Nazmi N, 2019, BIOMED SIGNAL PROCES, V47, P334, DOI 10.1016/j.bspc.2018.08.030
   Nicolaou N, 2012, EXPERT SYST APPL, V39, P202, DOI 10.1016/j.eswa.2011.07.008
   Orhan U, 2011, EXPERT SYST APPL, V38, P13475, DOI 10.1016/j.eswa.2011.04.149
   Plawiak P, 2020, INFORM SCIENCES, V516, P401, DOI 10.1016/j.ins.2019.12.045
   Plawiak P, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105740
   Richhariya B, 2018, EXPERT SYST APPL, V106, P169, DOI 10.1016/j.eswa.2018.03.053
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Schiurunack M, 2016, IFAC PAPERSONLINE, V49, P99, DOI 10.1016/j.ifacol.2016.07.160
   Sharma M, 2018, COMPUT BIOL MED, V102, P341, DOI 10.1016/j.compbiomed.2018.07.005
   Sisodia, 2018, BIOMED SIGNAL PROCES
   Siuly S, 2019, IET SCI MEAS TECHNOL, V13, P35, DOI 10.1049/iet-smt.2018.5358
   Supriya, 2016, LECT NOTES COMPUT SC, V9877, P56, DOI 10.1007/978-3-319-46922-5_5
   Szaleniec J, 2013, COMPUT BIOL MED, V43, P16, DOI 10.1016/j.compbiomed.2012.10.003
   Szaleniec M, 2008, NEUROCOMPUTING, V72, P241, DOI 10.1016/j.neucom.2008.01.003
   Tkachenko Roman, 2019, Advances in Computer Science for Engineering and Education. Advances in Intelligent Systems and Computing (AISC 754), P112, DOI 10.1007/978-3-319-91008-6_12
   Tkachenko Roman, 2019, Advances in Computer Science for Engineering and Education. Advances in Intelligent Systems and Computing (AISC 754), P578, DOI 10.1007/978-3-319-91008-6_58
   Tkachenko R, 2018, STUD COMPUT INTELL, V730, P537, DOI 10.1007/978-3-319-63754-9_25
   Tripathy RK, 2018, BIOCYBERN BIOMED ENG, V38, P890, DOI 10.1016/j.bbe.2018.05.005
   Tuncer SA, 2018, MEASUREMENT, V123, P298, DOI 10.1016/j.measurement.2018.04.002
   Tuncer T, 2020, J SUPERCOMPUT, V76, P2119, DOI 10.1007/s11227-020-03205-1
   Yilmaz CM, 2018, COMPUT METH PROG BIO, V162, P187, DOI 10.1016/j.cmpb.2018.05.026
   Zhang P, 2021, COMPUTING, V103, P473, DOI 10.1007/s00607-020-00860-3
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   Zhu GH, 2014, COMPUT METH PROG BIO, V115, P64, DOI 10.1016/j.cmpb.2014.04.001
   Zilberman Y, 2015, BIOSENS BIOELECTRON, V67, P465, DOI 10.1016/j.bios.2014.09.006
NR 73
TC 17
Z9 17
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 25197
EP 25218
DI 10.1007/s11042-021-10882-4
EA APR 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000640172500004
OA hybrid
DA 2024-07-18
ER

PT J
AU Lu, H
AF Lu, Hu
TI Click-cut: a framework for interactive object selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive object selection; Image automatic segmentation; Community
   partitioning
ID IMAGE; NETWORK
AB In order to simplify interactive image segmentation, We propose a new interactive segmentation framework for cutting an object from its background by which user interaction is reduced to only one click. Our proposed interactive segmentation framework consists of two steps: the image is first segmented automatically and then the object is extracted via user interaction, achieving image interactive segmentation. Combining the color and texture features of an image, We propose automatic partitioning for the image on the basis of modularity optimization. We construct the image region similarity network and partition the network into communities. We propose several region selection strategies. The user only needs to provide an interaction click. The region where the user click is merged with its adjacent regions recursively in accordance with the region selection strategy, resulting in user-desired regions. The image is finally divided into the foreground and the background. Compared with existing interactive segmentation approaches, the proposed method uses the simplest user interaction: it does not simultaneously require foreground or background markers for input. We evaluate our framework on different public image datasets. The experimental results indicate that the proposed method is superior to all existing interactive segmentation approaches. Results show that our framework achieves 67.5% accuracy on Grabcut, 80.8% accuracy on BSD_SSDS and 78.6% accuracy on MSRC_HighQuality.
C1 [Lu, Hu] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
C3 Jiangsu University
RP Lu, H (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
EM luhu@ujs.edu.cn
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bampis CG, 2017, IEEE T IMAGE PROCESS, V26, P35, DOI 10.1109/TIP.2016.2621663
   Benuwa BB, 2019, MULTIMED TOOLS APPL, V78, P6721, DOI 10.1007/s11042-018-6417-3
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Cheng KY, 2021, MULTIMED TOOLS APPL, V80, P5997, DOI 10.1007/s11042-020-09859-6
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Criminisi A, 2008, LECT NOTES COMPUT SC, V5302, P99, DOI 10.1007/978-3-540-88682-2_9
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Geng X, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12060944
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Hoi SCH, 2020, 2020 IEEE CVF C COMP
   Li H, 2013, IEEE INT CON MULTI
   Li SJ, 2015, IEEE T CIRC SYST VID, V25, P570, DOI 10.1109/TCSVT.2014.2360028
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu H, 2021, NEURAL NETWORKS, V135, P148, DOI 10.1016/j.neunet.2020.12.005
   Lu H, 2020, SOFT COMPUT, V24, P14157, DOI 10.1007/s00500-020-04785-z
   Lu H, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113513
   Lu H, 2012, PHYSICA A, V391, P6156, DOI 10.1016/j.physa.2012.06.062
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Ning JF, 2010, PATTERN RECOGN, V43, P445, DOI 10.1016/j.patcog.2009.03.004
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Taha A, 2015, IEEE IMAGE PROC, P11, DOI 10.1109/ICIP.2015.7350749
   Torki M, 2015, BMVC, P72
   Vezhnevets V., 2005, Proc. Graphicon, V1, P150
   Wang X, 2019, MULTIMED TOOLS APPL, V78, P27001, DOI 10.1007/s11042-017-4666-1
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   Xu N, 2016, PROC CVPR IEEE, P373, DOI 10.1109/CVPR.2016.47
NR 35
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24759
EP 24776
DI 10.1007/s11042-021-10880-6
EA APR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000638867400003
DA 2024-07-18
ER

PT J
AU Rebollo, C
   Remolar, I
   Rossano, V
   Lanzilotti, R
AF Rebollo, Cristina
   Remolar, Inmaculada
   Rossano, Veronica
   Lanzilotti, Rosa
TI Multimedia augmented reality game for learning math
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serious games; Engagement; Education; Augmented reality
AB The traditional method for learning the multiplication tables is a repetitive and boring task. Teachers try to find new methods to motivate children in this tedious duty, and one of the lines to consider is to integrate en- tertainment into educational processes. This work presents a new multimedia interaction approach in order to allow children to practice these math opera- tions and have fun. The learning process has been gamified by means of two mini-games designed for mobile platforms, based on meromictic or repetitive learning. The genre of these mini-games have been selected according to chil- dren preferences: one turn-based fighting and other throwing-objects game. A series of proposed multiplications have to be solved during the play to per- form the player actions. Moreover, in order to support learning engagement, both have been visualized through Augmented Reality, combining real and virtual reality. This paper discusses the good results of mixing entertainment with some learning tasks, due to the engagement of the children to the mobile based games. A pilot study has been performed in order to evaluate the learn- ing effectiveness and usability of the proposal. Results support that playing the video games makes this tedious multiplication practice more enjoyable and attractive for children so they improve their math skills.
C1 [Rebollo, Cristina; Remolar, Inmaculada] Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana 12006, Spain.
   [Rossano, Veronica; Lanzilotti, Rosa] Univ Bari A Moro, Dept Comp Sci, I-70125 Bari, Italy.
C3 Universitat Jaume I; Universita degli Studi di Bari Aldo Moro
RP Remolar, I (corresponding author), Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana 12006, Spain.
EM rebollo@uji.es; remolar@uji.es; veronica.rossano@uniba.it;
   rosa.lanzilotti@uniba.it
RI Rebollo Santamaría, Cristina/T-1272-2017; Remolar Quintana,
   Inmaculada/T-1268-2017
OI Rebollo Santamaría, Cristina/0000-0002-1328-2110; Remolar Quintana,
   Inmaculada/0000-0002-7743-2579
FU Spanish Ministry of Science and Technology [PID2019-106426RB-C32];
   Universitat Jaume I research project [UJI-B2018-56]; UJI Educational
   Innovation Project [3805 GAMELAB]; Universitat Jaume I; Carasso
   Foundation; Living Lab Planeta Debug
FX This work was supported by the Spanish Ministry of Science and
   Technology (Project PID2019-106426RB-C32), the Universitat Jaume I
   research project (UJI-B2018-56), the UJI Educational Innovation Project
   3805 GAMELAB and the Living Lab Planeta Debug supported by the
   Universitat Jaume I and the Carasso Foundation.
CR [Anonymous], 2019, 92412102019 ISO
   [Anonymous], 2004, COMF ZON P 21 ASCILI
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Ibáñez MB, 2020, COMPUT EDUC, V145, DOI 10.1016/j.compedu.2019.103734
   Cabero-Almenara J, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11184990
   Cabiria J., 2012, Increasing student engagement and retention using immer- sive interfaces: Virtual worlds, gaming, and simulation, P225
   Cahyono Bambang, 2018, 2018 2nd East Indonesia Conference on Computer and Information Technology (EIConCIT). Proceedings, P299, DOI 10.1109/EIConCIT.2018.8878553
   Juan MC, 2011, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY (ACE 2011)
   Cerqueira, 2020, P 1 INT COMP PROGR E
   Cerqueira Jose, 2019, Interactivity, Game Creation, Design, Learning, and Innovation. 7th EAI International Conference, ArtsIT 2018, and 3rd EAI International Conference, DLI 2018, ICTCC 2018. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 265), P508, DOI 10.1007/978-3-030-06134-0_53
   Fombona J., 2012, PIXEL-BIT, V41, P197
   Furió D, 2015, J COMPUT ASSIST LEAR, V31, P189, DOI 10.1111/jcal.12071
   Kang S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376252
   Keller J.M., 2016, Participatory Educational Research (PER), V3, P1, DOI [DOI 10.17275/PER.16.06.3.2, 10.17275/per.16.06.3.2]
   Keller JM, 2008, DISTANCE EDUC, V29, P175, DOI 10.1080/01587910802154970
   Liu TY, 2007, 6TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, PROCEEDINGS, P5, DOI 10.1109/ICIS.2007.1
   Rossano V., 2017, INT C SMART ED SMART, P48
   Rossano V, 2020, IEEE ACCESS, V8, P107772, DOI 10.1109/ACCESS.2020.3000990
   Schell J., 2008, The Art of Game Design: A Book of Lenses
   Sharples M, 2002, PERS UBIQUIT COMPUT, V6, P220, DOI 10.1007/s007790200021
   Tan K.-T., 2008, ACM SIGGRAPH ASIA 20
   Tomaschko M, 2020, AUGMENTED REALITY IN EDUCATIONAL SETTINGS, P325, DOI 10.1163/9789004408845_014
   Virvou M, 2005, COMPUT EDUC, V44, P53, DOI 10.1016/j.compedu.2003.12.020
   Yusoff Z, 2013, INT CONF RES INNOV, P251, DOI 10.1109/ICRIIS.2013.6716718
NR 24
TC 23
Z9 25
U1 9
U2 84
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 14851
EP 14868
DI 10.1007/s11042-021-10821-3
EA MAR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000635488800002
PM 33814967
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Miao, J
   Xu, SW
   Zou, BX
   Qiao, YH
AF Miao, Jun
   Xu, Shaowu
   Zou, Baixian
   Qiao, Yuanhua
TI ResNet based on feature-inspired gating strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ResNet; Gating network; Gating residual network; Feature-inspired gating
AB CNN(Convolutional Neural Networks) is a hot topic in the field of pattern recognition., especially in the field of image recognition. And ResNet(Residual Networks) is a special kind of CNN. Compared with the general CNN structure, ResNet introduces the residual unit with an identity mapping. Identity mapping allows the deep layers to directly learn the data received by the shallow layers, which reduces the difficulty of network convergence to a certain extent. As a result, ResNet has a better learning ability, has achieved good performance in various types of image recognition work. The essence of the residual network is to fuse two types of features from different receptive fields, using the fused features instead of the output features of the previous layer as the learning object. But the implementation of feature fusion in original ResNet is adding the two features with equal weights. And this method ignores the fact that the contribution of features from different levels to the learning of the network may not be the same. In this paper, we introduce a feature-inspired gating strategy in the residual unit of ResNet, which allows the network giving different weights to different features, so that the implementation of the feature fusion can be transformed from adding features with equal weights into weighted summation with different weights. And through experiments, we proved that ResNet with gating strategy proposed in this paper can obtain higher recognition accuracy than original ResNet.
C1 [Miao, Jun; Xu, Shaowu] Beijing Informat Sci & Technol Univ, Beijing Key Lab Internet Culture & Digital Dissem, Beijing 100101, Peoples R China.
   [Zou, Baixian] Beijing Union Univ, Coll Appl Arts & Sci, Beijing 100191, Peoples R China.
   [Qiao, Yuanhua] Beijing Univ Technol, Coll Appl Sci, Beijing 100124, Peoples R China.
C3 Beijing Information Science & Technology University; Beijing Union
   University; Beijing University of Technology
RP Miao, J (corresponding author), Beijing Informat Sci & Technol Univ, Beijing Key Lab Internet Culture & Digital Dissem, Beijing 100101, Peoples R China.
EM jmiao@bistu.edu.cn; swxu@mail.bistu.edu.cn
FU Beijing Natural Science Foundation [4202025]; Beijing Municipal
   Education Commission Projects [KM201911232003, KZ201910005008]; Beijing
   Innovation Center for Future Chips [KYJJ2018004]
FX This research is partially sponsored by Beijing Natural Science
   Foundation (No. 4202025), Beijing Municipal Education Commission
   Projects (Nos. KM201911232003 and KZ201910005008), and the Research Fund
   from Beijing Innovation Center for Future Chips (No. KYJJ2018004).
CR [Anonymous], COMPUT VIS PATTERN R
   Brunner G, 2019, PROC INT C TOOLS ART, P1124, DOI 10.1109/ICTAI.2019.00157
   Ciresan D., 2012, NIPS, P2843
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Guo Ya., 2020, INFORM PROCESSING AG
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He K., 2015, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2015.7299173, DOI 10.1109/CVPR.2015.7299173]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lao YD, 2019, 3RD INTERNATIONAL CONFERENCE ON INNOVATION IN ARTIFICIAL INTELLIGENCE (ICIAI 2019), P45, DOI 10.1145/3319921.3319928
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   McClelland J. L., 2013, EXACT SOLUTIONS NONL, DOI DOI 10.2514/6.2013-4659
   McNeely-White D, 2020, COGN SYST RES, V59, P312, DOI 10.1016/j.cogsys.2019.10.004
   Mishra P, 2019, WORK HYPERSP IMAG, DOI 10.1109/whispers.2019.8921019
   Myronenko A, 2020, LECT NOTES COMPUT SC, V12009, P72, DOI 10.1007/978-3-030-39074-7_8
   Passricha V, 2020, J INTELL SYST, V29, P1261, DOI 10.1515/jisys-2018-0372
   RANA R, 2016, ARXIV PREPRINT ARXIV
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava R. K., 2015, ADV NEURAL INFORM PR, P2377, DOI DOI 10.48550/ARXIV.1505.00387
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang D, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11050644
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Xianghui Liu, 2018, 2018 14th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD), P1187, DOI 10.1109/FSKD.2018.8686963
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yan DF, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/8320316
   Yu Q, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR 2019), P116, DOI 10.1145/3357254.3357262
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 32
TC 7
Z9 8
U1 18
U2 96
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19283
EP 19300
DI 10.1007/s11042-021-10802-6
EA MAR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000632798100001
DA 2024-07-18
ER

PT J
AU Chen, L
   Liu, YG
   Man, YC
AF Chen, Lin
   Liu, Yungang
   Man, Yongchao
TI Spatial-temporal channel-wise attention network for action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Channel-wise attention; Spatial-temporal
   information; Two-stream network
ID REPRESENTATION
AB Video-based action recognition has become a challenging task in computer vision and attracted extensive attention from the academic community. Most existing methods for action recognition treat all spatial or temporal input features equally, thus ignoring the difference of contribution provided by different features. To address this problem, we propose a spatial-temporal channel-wise attention network (STCAN) that is able to effectively learn discriminative features of human actions by adaptively recalibrating channel-wise feature responses. Specifically, the STCAN is constructed on a two-stream structure and we design a channel-wise attention unit (CAU) module. Two-stream network can effectively extract spatial and temporal information. Using the CAU module, the interdependencies between channels can be modelled to further generate a weight distribution for selectively enhancing informative features. The network performance of STCAN has been evaluated on two typical action recognition datasets, namely UCF101 and HMDB51, and comparable experiments have been performed to demonstrate the effectiveness of the proposed STCAN.
C1 [Chen, Lin; Liu, Yungang; Man, Yongchao] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
C3 Shandong University
RP Liu, YG (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
EM lygfr@sdu.edu.cn
FU National Natural Science Foundations of China [62033007, 61873146,
   61973186, 61821004, 62073192]; Key and Development Plan of Shandong
   Province [2019JZZY010433]; Taishan Scholars Climbing Program of Shandong
   Province
FX The research is supported by the National Natural Science Foundations of
   China (62033007, 61873146, 61973186, 61821004 and 62073192), the Key and
   Development Plan of Shandong Province (Grant No. 2019JZZY010433) and the
   Taishan Scholars Climbing Program of Shandong Province.
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   Bianco S, 2016, COMPUT VIS IMAGE UND, V145, P15, DOI 10.1016/j.cviu.2016.01.003
   Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Crasto N, 2019, PROC CVPR IEEE, P7874, DOI 10.1109/CVPR.2019.00807
   Diba A., 2017, Temporal 3D ConvNets: New architecture and transfer learning for video classification
   Dong XP, 2019, IEEE T IMAGE PROCESS, V28, P3516, DOI 10.1109/TIP.2019.2898567
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Guo S, 2020, MULTIMED TOOLS APPL, V79, P4713, DOI 10.1007/s11042-019-7675-4
   Hao WL, 2019, PATTERN RECOGN, V92, P13, DOI 10.1016/j.patcog.2019.03.005
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He DL, 2019, AAAI CONF ARTIF INTE, P8401
   He PS, 2018, IEEE SIGNAL PROC LET, V25, P1369, DOI 10.1109/LSP.2018.2855566
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hinton G. E., 2012, 12070580 ARXIV
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kwon H, 2018, PATTERN RECOGN LETT, V112, P161, DOI 10.1016/j.patrec.2018.07.011
   Lai QX, 2020, IEEE T IMAGE PROCESS, V29, P1113, DOI 10.1109/TIP.2019.2936112
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li J, 2020, IEEE T MULTIMEDIA, V22, P2990, DOI 10.1109/TMM.2020.2965434
   Liang ZY, 2020, IEEE T IMAGE PROCESS, V29, P3351, DOI 10.1109/TIP.2019.2959256
   Liao ZK, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102821
   Lu Z., 2013, Proceedings of the 21st ACM international conference on Multimedia, P621, DOI DOI 10.1145/2502081.2502163
   Lv ZH, 2016, NEUROCOMPUTING, V208, P290, DOI 10.1016/j.neucom.2015.12.128
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Ma ZC, 2018, MULTIMED TOOLS APPL, V77, P32275, DOI 10.1007/s11042-018-6260-6
   McNeely-White D, 2020, COGN SYST RES, V59, P312, DOI 10.1016/j.cogsys.2019.10.004
   Murphy P., 2012, Machine learning: a probabilistic perspective, Adaptive computation and machine learning series
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Plizzari Chiara, 2020, ARXIV200807404
   Shen JB, 2020, IEEE T CYBERNETICS, V50, P3068, DOI 10.1109/TCYB.2019.2936503
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan Z, 2017, ARXIV171201586
   Tao Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9260, DOI 10.1109/CVPR42600.2020.00928
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wang LM, 2016, INT J COMPUT VISION, V119, P254, DOI 10.1007/s11263-015-0859-0
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2019, IEEE I CONF COMP VIS, P5702, DOI 10.1109/ICCV.2019.00580
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724
   Wenguan Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8926, DOI 10.1109/CVPR42600.2020.00895
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang BW, 2018, IEEE T IMAGE PROCESS, V27, P2326, DOI 10.1109/TIP.2018.2791180
   Zhang JX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3321511
   Zhang KT, 2018, MULTIMED TOOLS APPL, V77, P16053, DOI 10.1007/s11042-017-5179-7
   Zheng WQ, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2019), DOI 10.1145/3331453.3361651
   Zhu JG, 2019, IEEE SIGNAL PROC LET, V26, P1633, DOI 10.1109/LSP.2019.2942739
NR 59
TC 5
Z9 5
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21789
EP 21808
DI 10.1007/s11042-021-10752-z
EA MAR 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000630848100001
DA 2024-07-18
ER

PT J
AU Shao, ZH
   Tang, YD
   Liang, MX
   Shang, YY
   Wang, F
   Wang, YF
AF Shao, Zhuhong
   Tang, Yadong
   Liang, Mingxian
   Shang, Yuanyuan
   Wang, Feng
   Wang, Yunfei
TI Double image encryption based on symmetry of 2D-DFT and equal modulus
   decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Double image encryption; Conjugate symmetry; Equal modulus
   decomposition; Gyrator transform; Sharing
AB This paper introduces a double image encryption scheme mainly based on symmetry of two-dimensional discrete Fourier transform (2D-DFT) and equal modulus decomposition (EMD). Firstly, the plural form is adopted to encode double image as a whole and the 2D-DFT is performed. To obtain matrices satisfying property of conjugate symmetry, the spectra are implemented addition and subtraction. Followed by truncation-superposition operations, another complex value matrix is attained and equal modulus decomposition is carried out to get two phase templates, which are further gyrator transformed to enhance security. With an orthogonal matrix, the real and imaginary parts are shared and spliced together to produce a real-valued cipherimage, which aims to make storage and transmission convenient. The initial states of 2D logistic map are closely related to the plaintext images and is employed to generate phase mask, rotation angles as well as the input of Gaussian matrix, which ensures the high level of security. Experimental results have demonstrated the feasibility and validity of the proposal in restituting plaintext images, security and resisting Gaussian noise attack.
C1 [Shao, Zhuhong; Tang, Yadong; Shang, Yuanyuan; Wang, Feng] Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China.
   [Shao, Zhuhong] Beijing Engn Res Ctr Highly Reliable Embedded Sys, Beijing 100048, Peoples R China.
   [Liang, Mingxian] Hosp Wuzhou Tradit Chinese Med, Wuzhou 432002, Peoples R China.
   [Shang, Yuanyuan] Beijing Adv Innovat Ctr Imaging Technol, Beijing 100048, Peoples R China.
   [Wang, Yunfei] Capital Normal Univ, Dept Phys, Beijing 100048, Peoples R China.
C3 Capital Normal University; Capital Normal University
RP Shao, ZH (corresponding author), Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China.; Shao, ZH (corresponding author), Beijing Engn Res Ctr Highly Reliable Embedded Sys, Beijing 100048, Peoples R China.
EM zhshao@cnu.edu.cn
RI Shao, Zhuhong/AAD-4129-2022
OI Wang, Yunfei/0009-0004-2991-3935
FU National Natural Science Foundation of China [61876112, 61601311];
   Support Project of High-level Teachers in Beijing Municipal Universities
   in the Period of 13th Five-year Plan [CITTCD20170322]; Project of
   Beijing Excellent Talents [2016000020124G088]; Beijing Municipal
   Education Research Plan Project [SQKM201810028018]
FX This work was supported by the National Natural Science Foundation of
   China (61876112, 61601311), Support Project of High-level Teachers in
   Beijing Municipal Universities in the Period of 13th Five-year Plan
   (CIT&TCD20170322), Project of Beijing Excellent Talents
   (2016000020124G088), Beijing Municipal Education Research Plan Project
   (SQKM201810028018).
CR Arul M.C., 2018, Mob. Netw. Appl., DOI [10.1007/s11036-018-1058-3, DOI 10.1007/S11036-018-1058-3]
   Bekkouche T, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023033
   Ghoneim A, 2018, IEEE COMMUN MAG, V56, P33, DOI 10.1109/MCOM.2018.1700817
   Golea Nour El-Houda, 2019, International Journal of High Performance Computing and Networking, V13, P199
   Guo C, 2017, OPT LASER ENG, V89, P2, DOI 10.1016/j.optlaseng.2016.03.021
   He CT, 2020, IET OPTOELECTRON, V14, P169, DOI 10.1049/iet-opt.2019.0159
   Huang ZJ, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105821
   Jiang H, 2019, OPT APPL, V49, P445, DOI 10.5277/oa190307
   Kang XJ, 2016, IEEE T SIGNAL PROCES, V64, P3402, DOI 10.1109/TSP.2016.2544740
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kumar A, 2019, INT J CLOUD APPL COM, V9, P22, DOI 10.4018/IJCAC.2019070102
   Kumar R, 2018, OPT LASER TECHNOL, V107, P353, DOI 10.1016/j.optlastec.2018.06.014
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Liu YJ, 2020, OPT LASER TECHNOL, V127, DOI 10.1016/j.optlastec.2020.106171
   Liu ZJ, 2011, OPTIK, V122, P864, DOI 10.1016/j.ijleo.2010.06.010
   Luan GY, 2020, IEEE PHOTONICS J, V12, DOI 10.1109/JPHOT.2020.2963921
   Luo YL, 2018, IEEE ACCESS, V6, P77740, DOI 10.1109/ACCESS.2018.2884013
   Rodrigo JA, 2007, OPT EXPRESS, V15, P2190, DOI 10.1364/OE.15.002190
   Sang J, 2015, SENSORS-BASEL, V15, P19199, DOI 10.3390/s150819199
   Shao ZH, 2018, MULTIMED TOOLS APPL, V77, P1285, DOI 10.1007/s11042-016-4279-0
   Sui LS, 2019, OPT LASER ENG, V122, P113, DOI 10.1016/j.optlaseng.2019.06.005
   Sui LS, 2019, OPT LASER ENG, V113, P29, DOI 10.1016/j.optlaseng.2018.10.002
   Sui LS, 2015, OPT COMMUN, V354, P184, DOI 10.1016/j.optcom.2015.05.071
   Sun WQ, 2019, OPT REV, V26, P332, DOI 10.1007/s10043-019-00506-6
   Tao S, 2020, APPL OPTICS, V59, P2422, DOI 10.1364/AO.385652
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zhang LN, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107421
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhao SM, 2020, OPT COMMUN, V474, DOI 10.1016/j.optcom.2020.126086
NR 35
TC 7
Z9 7
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8973
EP 8998
DI 10.1007/s11042-020-09961-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QZ7ZL
UT WOS:000630940800002
DA 2024-07-18
ER

PT J
AU Sur, C
AF Sur, Chiranjib
TI CRUR: coupled-recurrent unit for unification, conceptualization and
   context capture for language representation - a generalization of bi
   directional LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Language modeling; Dual context initialization; Representation learning;
   Tensor representation; Memory networks
AB In this work we have analyzed a novel concept of sequential binding based learning capable network based on the coupling of recurrent units with Bayesian Prior definition. The coupling structure encodes to generate efficient tensor representations that can be decoded to generate efficient sentences and can describe certain events. These descriptions are derived from structural representations of visual features of images and media. An elaborated study of the different types of coupling recurrent structures are studied and some insights of their performance are provided. Supervised learning performance for natural language processing is judged based on statistical evaluations, however, the truth is perspective, and in this case the qualitative evaluations reveal the real capability of the different architectural strengths and variations. Bayesian Prior definition of different embedding helps in better characterization of the sentences based on the natural language structure related to parts of speech and other semantic level categorization in a form which is machine interpret-able and inherits the characteristics of the Tensor Representation binding and unbinding based on the mutually orthogonality. Our approach has surpassed some of the existing basic works related to image captioning.
C1 [Sur, Chiranjib] Univ Florida, Comp & Informat Sci & Engn Dept, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Sur, C (corresponding author), Univ Florida, Comp & Informat Sci & Engn Dept, Gainesville, FL 32611 USA.
EM chiranjibsur@gmail.com
RI Sur, Chiranjib/Z-4268-2019
OI Sur, Chiranjib/0000-0002-1563-9304
FU NVIDIA Tesla K80 GPU
FX The author has used University of Florida HiperGator, equipped with
   NVIDIA Tesla K80 GPU, extensively for the experiments. The author
   acknowledges University of Florida Research Computing for providing
   computational resources and support that have contributed to the
   research results reported in this publication. URL:
   http://researchcomputing.ufl.edu
CR Anderson Peter, 2018, CVPR, DOI DOI 10.1109/CVPR.2018.00636
   [Anonymous], 2015, FINITE ELEMENT METHO
   Chang SF, 2018, ARXIV 180407889
   Chen FH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P46, DOI 10.1145/3123266.3123275
   Chen FH, 2018, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2018.00146
   Chen H, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P606
   Chen HM, 2017, IEEE POW ENER SOC GE
   Chen MH, 2017, AAAI CONF ARTIF INTE, P3981
   Chen T., 2018, ARXIV ABS180607366
   Chen WZ, 2017, IEEE IJCNN, P1403, DOI 10.1109/IJCNN.2017.7966017
   Chen X, 2015, Microsoft coco captions: Data collection and evaluation server
   Cole C., 2017, J COMPUT NONLIN DYN
   Cornia M, 2018, ACM T MULTIM COMPUT, V14, P48
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Fu K, 2018, IEEE T NEUR NET LEAR, V29, P5910, DOI 10.1109/TNNLS.2018.2813306
   Fu K, 2017, IEEE T PATTERN ANAL, V39, P2321, DOI 10.1109/TPAMI.2016.2642953
   Gan C, 2017, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2017.108
   Gan Z, 2016, ARXIV 161108002
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Jiang WH, 2018, AAAI CONF ARTIF INTE, P6959
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kilickaya M, 2017, IET COMPUT VIS, V11, P398, DOI 10.1049/iet-cvi.2016.0286
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li X, 2018, ARXIV 180508661
   Liu CX, 2017, AAAI CONF ARTIF INTE, P4176
   Liu MF, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102178
   Liu SQ, 2017, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2017.100
   Liu X., 2018, ARXIV PREPRINT ARXIV
   Lu JS, 2018, PROC CVPR IEEE, P7219, DOI 10.1109/CVPR.2018.00754
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Luo J, 2018, PLANT ANIMAL GENOME
   Mao J.X., 2014, J POSTDR RES, V2
   Mooney RJ, 2018, EUR C COMP VIS ECCV
   Mroueh Y, 2018, ARXIV 180500063
   Park CC, 2018, AIAA ASCE AHS ASC ST
   Park CC, 2017, PROC CVPR IEEE, P6432, DOI 10.1109/CVPR.2017.681
   Peng YQ, 2019, IMAGE VISION COMPUT, V86, P38, DOI 10.1016/j.imavis.2019.03.003
   Potts C, 2018, ARXIV 180405417
   Redmond WA, 2017, ARXIV 170508432
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Schallner R, 2018, ARXIV 180201958
   Sharma G, 2019, VISUAL IMAGE CAPTION
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Sur, 2020, SN COMPUT SCI, V1, P228, DOI [DOI 10.1007/S42979-020-00234-8, 10.1007/s42979-020-00234-8115, DOI 10.1007/S42979-020-00234-8115]
   Sur C, ARXIV PREPRINT ARXIV
   Sur C., 2020, SN COMPUT SCI, V1, P229, DOI [10.1007/s42979-020-00238-4, DOI 10.1007/S42979-020-00238-4]
   Sur C, 2018, ARXIV 181206624
   Sur C, 2020, ARXIV 200109545
   Sur C, 2019, ARXIV 191110115
   Sur C, 2019, 5TH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING AND COMMUNICATIONS (BIGCOM 2019), P33, DOI 10.1109/BIGCOM.2019.00013
   Sur C, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1765-9
   Sur C, 2019, MULTIMED TOOLS APPL, V78, P32187, DOI 10.1007/s11042-019-08021-1
   Sur C, 2019, EVOL INTELL, V12, P689, DOI 10.1007/s12065-019-00278-7
   Tan YH, 2019, NEUROCOMPUTING, V333, P86, DOI 10.1016/j.neucom.2018.12.026
   Tavakoli HR, 2017, IEEE I CONF COMP VIS, P2506, DOI 10.1109/ICCV.2017.272
   Vinyals O., 2016, IEEE TPMAI, V39, P652, DOI DOI 10.1109/TPAMI.2016.2587640
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang C, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3115432
   Wang L., 2018, SIGNAL PROCESS IMAGE
   Wang Y., 2017, P 36 CHIN CONTR C B
   Wu C.Z., 2018, ECOC
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   Yao T, 2017, PROC CVPR IEEE, P5263, DOI 10.1109/CVPR.2017.559
   Ye Senmao., 2018, IEEE Transactions on Image Processing
   You Q, 2016, PROC CVPR IEEE
   Zhang H., 2020, 2 TARGET RECOGNITION, V11427
   Zhang Lei, 2017, ARXIV PREPRINT ARXIV
   Zhang M., 2018, ARXIV180209691
   Zhang N., 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.128
   Zhao W, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1205
   Zheng J, 2019, ARXIV PREPRINT ARXIV
   Zitnick CL, 2015, ARXIV 150501809
NR 73
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 9917
EP 9959
DI 10.1007/s11042-020-09865-8
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO7LK
UT WOS:000641223300001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yuan, JF
   Abdul-Rashid, H
   Li, B
AF Yuan, Juefei
   Abdul-Rashid, Hameed
   Li, Bo
TI A survey of recent 3D scene analysis and processing methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D Scenes; Survey; Scene analysis; Scene processing; Semantics-driven
   approaches; Data-driven approaches
AB With ubiquitous cameras and popular 3D scanning and capturing devices to help us capture 2D/3D scene data, there are many scene understanding related applications, as well as quite a few important and interesting research problems in processing, analyzing, and understanding the available scene data. During the recent several years, there is a significant advancement in different research directions in this field and quite a few novel 3D scene analysis and processing methods have been proposed correspondingly in each direction. This paper provides a review and critical evaluation on the most recent (i.e., within five recent years) and novel data-driven or semantics-driven 3D scene analysis and processing methods, as well as several involved 3D scene datasets. For each method, its advantage(s) and disadvantage(s) are discussed, after an overview and/or analysis of the approach. Finally, based on the review, we propose several promising future research directions in this field.
C1 [Yuan, Juefei; Abdul-Rashid, Hameed; Li, Bo] Univ Southern Mississippi, Sch Comp Sci & Comp Engn, Long Beach, MS 39560 USA.
C3 University of Southern Mississippi
RP Li, B (corresponding author), Univ Southern Mississippi, Sch Comp Sci & Comp Engn, Long Beach, MS 39560 USA.
EM juefei.yuan@usm.edu; hameedabdulrashid@gmail.com; bo.li@usm.edu
RI wang, qiang/IZW-1751-2023; Li, Ye/JBS-2949-2023; Li, bo/IWL-9318-2023;
   Yuan, Juefei/HJI-9440-2023; Li, Kun/JLL-6505-2023
OI Li, Kun/0000-0002-3638-2974; LI, BO/0000-0002-3330-8103
CR Abdul-Rashid, 2019, SHREC 19 EXTENDED 2D
   Abdul-Rashid H., 2018, SHREC 18 2D SCENE IM
   Adler J, 2018, IEEE T MED IMAGING, V37, P1322, DOI 10.1109/TMI.2018.2799231
   Akase R., 2014, P 7 INT S VIS INF CO, P178
   Akase R, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT, AND SOFTWARE INTENSIVE SYSTEMS (CISIS), P726, DOI 10.1109/CISIS.2013.130
   [Anonymous], 2017, ARXIV171210215
   [Anonymous], 2016, ARXIV160605908
   [Anonymous], 2012, LECT NOTES COMPUT SC, DOI [10.1007/978-3-642-33715-4_54, DOI 10.1007/978-3-642-33715-4_54]
   [Anonymous], 2017, ARXIV171209216
   Behl A, 2017, IEEE I CONF COMP VIS, P2593, DOI 10.1109/ICCV.2017.281
   Blaha M, 2016, PROC CVPR IEEE, P3176, DOI 10.1109/CVPR.2016.346
   Bobenrieth C, 2017, CGI'17: PROCEEDINGS OF THE COMPUTER GRAPHICS INTERNATIONAL CONFERENCE, DOI 10.1145/3095140.3095167
   Cao, 2017, P 23 ACM S VIRT REAL
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081
   Chen BX, 2018, ARXIV190806422
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Derczynski L, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P261
   Dong SY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322942
   Ebrahimnezhad H., 2011, INT J INFORM COMMUN, V4, P9
   Ebrahimnezhad H, 2008, IMAGE VISION COMPUT, V26, P1397, DOI 10.1016/j.imavis.2008.01.002
   Fellbaum C, 1998, LANG SPEECH & COMMUN, P1
   Fisher M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818057
   Flynn J, 2019, PROC CVPR IEEE, P2362, DOI 10.1109/CVPR.2019.00247
   Guo H., 2018, P 2 INT C INN ART IN, P92
   Gupta A, 2019, PROC CVPR IEEE, P5351, DOI 10.1109/CVPR.2019.00550
   Handa A, 2016, PROC CVPR IEEE, P4077, DOI 10.1109/CVPR.2016.442
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He XW, 2018, PROC CVPR IEEE, P1945, DOI 10.1109/CVPR.2018.00208
   Hua BS, 2016, INT CONF 3D VISION, P92, DOI 10.1109/3DV.2016.18
   Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248
   Li, 2020, 3 IEEE C MULT INF PR
   Li M., 2019, ACM T GRAPHIC, V38
   Lin DH, 2013, IEEE I CONF COMP VIS, P1417, DOI 10.1109/ICCV.2013.179
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Y, 2008, PROC CVPR IEEE, P2008
   Loop C, 1987, THESIS U UTAH
   Ma R, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275035
   Mikolov Tomas, 2013, EFFICIENT ESTIMATION
   Miksik O, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3317, DOI 10.1145/2702123.2702222
   Müller-Budack E, 2018, LECT NOTES COMPUT SC, V11216, P575, DOI 10.1007/978-3-030-01258-8_35
   Vo N, 2017, IEEE I CONF COMP VIS, P2640, DOI 10.1109/ICCV.2017.286
   Penner E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130855
   Rangel JC, 2016, ADV ROBOTICS, V30, P758, DOI 10.1080/01691864.2016.1164621
   Rematas K, 2018, PROC CVPR IEEE, P4738, DOI 10.1109/CVPR.2018.00498
   Ritchie D., 2018, ARXIV181112463
   Savinov N, 2016, ARXIV160402885
   Savva Manolis, 2017, ARXIV170300061
   Schmitt Industries Inc, 2020, ACUITY LASER
   Shi Y, 2019, ARXIV190303757
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Sood G, 2015, CLARIFAI R CLIENT CL
   Steinhauser D, 2008, IEEE INT VEH SYM, P940
   Straub Julian, 2019, ARXIV190605797
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Vasiljevic I., 2019, ARXIV190800463
   Vineet V, 2015, IEEE INT CONF ROBOT, P75, DOI 10.1109/ICRA.2015.7138983
   Vineet V, 2014, INT J COMPUT VISION, V110, P290, DOI 10.1007/s11263-014-0708-6
   Walczak K, 2015, WEB3D 2015, P123, DOI 10.1145/2775292.2775311
   Wang L., 2016, ARXIV161001119
   Weyand T, 2016, LECT NOTES COMPUT SC, V9912, P37, DOI 10.1007/978-3-319-46484-8_3
   Wikipedia, 2019, AV FLIGHT PASS
   Wikipedia contributors, 2020, JACC WIK FREE ENC
   Wikipedia contributors, 2020, LEAP MOT WIK FREE EN
   Wikipedia contributors, 2020, LID WIK FREE ENC
   Wikipedia contributors, 2020, SEM GAP WIK FREE ENC
   Xiang Y, 2016, LECT NOTES COMPUT SC, V9912, P160, DOI 10.1007/978-3-319-46484-8_10
   Xiao JX, 2016, INT J COMPUT VISION, V119, P3, DOI 10.1007/s11263-014-0748-y
   XU K, 2017, ACM T GRAPHIC, V36
   Yuan, 2019, SHREC 19 EXTENDED 2D
   Yuan J., 2018, SHREC 18 2D SCENE SK
   Yuan JF, 2020, COMPUT VIS IMAGE UND, V201, DOI 10.1016/j.cviu.2020.103070
   Yuan JF, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P264, DOI 10.1109/MIPR.2019.00054
   Zhang SY, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P353, DOI 10.1145/3013971.3014002
   Zhao H, 2017, IEEE I CONF COMP VIS, P2021, DOI 10.1109/ICCV.2017.221
   Zheng Jia, 2019, ARXIV PREPRINT ARXIV, V2, P5
   Zhong WC, 2018, PROCEEDINGS OF 2018 THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ARTIFICIAL INTELLIGENCE (CSAI 2018) / 2018 THE 10TH INTERNATIONAL CONFERENCE ON INFORMATION AND MULTIMEDIA TECHNOLOGY (ICIMT 2018), P277, DOI 10.1145/3297156.3297214
   Zhou BL, 2019, INT J COMPUT VISION, V127, P302, DOI 10.1007/s11263-018-1140-0
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 82
TC 3
Z9 3
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19491
EP 19511
DI 10.1007/s11042-021-10615-7
EA FEB 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000622668700003
DA 2024-07-18
ER

PT J
AU de Oliveira, DN
   Merschmann, LHD
AF de Oliveira, Douglas Nunes
   Merschmann, Luiz Henrique de Campos
TI Joint evaluation of preprocessing tasks with classifiers for sentiment
   analysis in Brazilian Portuguese language
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Natural language processing; Data mining; Portuguese
   language
ID IMPACT
AB Sentiment analysis is a task that deals with the automatic extraction of sentimental contents expressed in written text. Several approaches in sentiment analysis are based on machine learning techniques, more specifically classifiers that are trained on labeled datasets. In this context, many Natural Language Processing (NLP) tasks are usually employed as a preprocessing step to help improve the quality of the data and to convert them into forms appropriate for the subsequent classification process. Several studies on sentiment analysis in the literature have already performed some evaluation of NLP tasks and/or classification. However, the vast majority of them did not work with texts in the Brazilian Portuguese language and the analyzes did not consider the combination of sets of preprocessing tasks with classifiers. Therefore, in this work, we evaluate the combination of five NLP tasks and three classifiers in the domain of sentiment analysis using texts written in Portuguese. The experimental results showed that different combinations of preprocessing tasks can significantly affect the predictive performance of a classifier for a given dataset. Thus, it is clear the importance of performing the joint evaluation of preprocessing tasks with classifiers when choosing which preprocessing tasks and classifiers should be used for a dataset.
C1 [de Oliveira, Douglas Nunes] Univ Fed Lavras, Dept Comp Sci, BR-37200000 Lavras, MG, Brazil.
   [Merschmann, Luiz Henrique de Campos] Univ Fed Lavras, Dept Appl Comp, BR-37200000 Lavras, MG, Brazil.
C3 Universidade Federal de Lavras; Universidade Federal de Lavras
RP de Oliveira, DN (corresponding author), Univ Fed Lavras, Dept Comp Sci, BR-37200000 Lavras, MG, Brazil.
EM douglas.oliveira@estudante.ufla.br; luiz.hcm@ufla.br
RI Merschmann, Luiz Henrique C/B-7178-2016
OI Merschmann, Luiz Henrique C/0000-0002-9948-2673; Nunes de Oliveira,
   Douglas/0000-0002-0698-1845
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - Brazil
   (CAPES) [001]; Fundacao de Amparo a Pesquisa do Estado de Minas Gerais -
   Brazil (FAPEMIG) [APQ-02266-16]; Stilingue Inteligencia Artificial Ltda
   - Brazil [006/2020]
FX This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior - Brazil (CAPES) - Finance Code 001, by
   Fundacao de Amparo a Pesquisa do Estado de Minas Gerais - Brazil
   (FAPEMIG) - Finance Code APQ-02266-16 and by Stilingue Inteligencia
   Artificial Ltda - Brazil - Partnership Agreement 006/2020 - UFLA.
CR Alam S, 2019, COMPUT MATH ORGAN TH, V25, P319, DOI 10.1007/s10588-018-9266-8
   Almeida TG, 2016, P BRAZ S MULT WEB, P355
   Araujo M., 2016, P 31 ANN ACM S APPL, P1140, DOI [10.1145/2851613.2851817, DOI 10.1145/2851613.2851817]
   Bird Steven, 2009, NATURAL LANGUAGE PRO, DOI DOI 10.1007/S10579-010-9124-X
   Camacho-Collados JP, 2017, P 2018 EMNLP WORKSH
   Cirqueira D AFLJ, 2016, REVISED PAPERS LECT, V263, P245
   Dashtipour K, 2016, COGN COMPUT, V8, P772, DOI 10.1007/s12559-016-9421-9
   dos Santos FL, 2014, 2014 BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS), P50, DOI 10.1109/BRACIS.2014.20
   Feldman R, 2013, COMMUN ACM, V56, P82, DOI 10.1145/2436256.2436274
   Ferreira Rodrigo Santana, 2017, Analise de Sentimentos-Aprenda de uma vez por todas como funciona utilizando dados do Twitter
   Fonseca Erick Rocha, 2013, 9 BRAZILIAN S INFORM, P98
   Ghosh M, 2017, ADV INTELL SYST, V515, P721, DOI 10.1007/978-981-10-3153-3_72
   Grandin P, 2016, IEEE LAT AM T, V14, P3467, DOI 10.1109/TLA.2016.7587656
   Haddi E, 2013, PROCEDIA COMPUT SCI, V17, P26, DOI 10.1016/j.procs.2013.05.005
   Martins R., 2015, WebMedia 2015 - Proceedings of the 21st Brazilian Symposium on Multimedia and the Web, P105
   McNair C, 2017, TECH REP EMARKETER
   Menezes AA, P BRAZ WORKSH SOC NE, P555
   Narr S., 2012, Knowledge discovery and machine learning (KDML), P12
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pereira DA, 2021, ARTIF INTELL REV, V54, P1087, DOI 10.1007/s10462-020-09870-1
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Ribeiro FN, 2016, EPJ DATA SCI, V5, DOI 10.1140/epjds/s13688-016-0085-1
   Rosa RL, 2017, THESIS UFLA
   Silva IS, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P475
   Simons G. F., 2017, Ethnologue: Languages of the World, V20th
   Souza E, 2018, IET SOFTW, V12, P49, DOI 10.1049/iet-sen.2016.0226
   Souza E, 2016, LECT NOTES ARTIF INT, V9727, P122, DOI 10.1007/978-3-319-41552-9_12
   Stiilpen Junior M., 2016, Proceedings of the 22nd Brazilian Symposium on Multimedia and the Web, P239, DOI 10.1145/2976796.2976845
   Uysal AK, 2014, INFORM PROCESS MANAG, V50, P104, DOI 10.1016/j.ipm.2013.08.006
   Viera R, 2015, THESIS PUC RS
NR 30
TC 9
Z9 10
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15391
EP 15412
DI 10.1007/s11042-020-10323-8
EA FEB 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000614341400001
DA 2024-07-18
ER

PT J
AU Zhu, JM
   Zhang, GP
   Zhou, SB
   Li, K
AF Zhu, Jiaming
   Zhang, Guopeng
   Zhou, Shibin
   Li, Kun
TI Relation-aware Siamese region proposal network for visual object
   tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Siamese network; Graph convolutional network; Deep
   learning
AB The backbone networks used in Siamese trackers are relatively shallow, such as AlexNet and VGGNet, resulting in insufficient features for tracking task. Therefore, this paper focuses on extracting more discriminative features to improve the performance of Siamese trackers. By comprehensive experimental validations, this goal is achieved through a simple yet effective framework referred as relation-aware Siamese region proposal network (Ra-SiamRPN). Firstly, the deep backbone network ResNet-50 is adopted to extract both low-level detail features and high-level semantic features of an image. Then we propose the feature fusion module (FFM), which can combine low-level detail features with high-level semantic features effectively. Furthermore, we propose the relation reasoning module (RRM) to perform the global relation reasoning in multiple disjoint regions. RRM can generate discriminative information to enhance the features generated by ResNet-50. Extensive experiments are conducted on the dataset OTB2015, VOT2016, VOT2018, UAV123 and LaSOT. The experiment results indicate that Ra-SiamRPN achieves competitive performance with the current advanced algorithms and shows good real-time performance. To be highlighted, in the experiments conducted on the large-scale dataset LaSOT, the success score and the normalized precision score of Ra-SiamRPN are 0.495 and 0.576, respectively. These performance indexes are better than the second best tracker MDNet 24.7% and 25.2%.
C1 [Zhu, Jiaming; Zhang, Guopeng; Zhou, Shibin; Li, Kun] China Univ Min & Technol, Engn Res Ctr Mine Digitalizat, Minist Educ, Xuzhou, Jiangsu, Peoples R China.
   [Zhu, Jiaming; Zhang, Guopeng; Zhou, Shibin; Li, Kun] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou, Jiangsu, Peoples R China.
C3 China University of Mining & Technology; China University of Mining &
   Technology
RP Zhou, SB (corresponding author), China Univ Min & Technol, Engn Res Ctr Mine Digitalizat, Minist Educ, Xuzhou, Jiangsu, Peoples R China.; Zhou, SB (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou, Jiangsu, Peoples R China.
EM jmzhu@cumt.edu.cn; gpzhang@cumt.edu.cn; zhoushibin@cumt.edu.cn;
   likun@163.com
RI Zhu, Jiaming/O-5774-2016
FU National Natural Science Foundation of China [61971421, 62071470]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant nos. 61971421 and 62071470).
CR Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bertasius G, 2017, PROC CVPR IEEE, P6137, DOI 10.1109/CVPR.2017.650
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chandra S, 2017, IEEE I CONF COMP VIS, P5113, DOI 10.1109/ICCV.2017.546
   Che MQ, 2019, LECT NOTES COMPUT SC, V11129, P70, DOI 10.1007/978-3-030-11009-3_3
   Choi J, 2018, PROC CVPR IEEE, P479, DOI 10.1109/CVPR.2018.00057
   Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Deng J., 2009, IEEE C COMP VIS PATT
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Gao JY, 2019, PROC CVPR IEEE, P4644, DOI 10.1109/CVPR.2019.00478
   Grabner H, 2006, CVPR
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Kipf TN, 2016, ARXIV
   Kong T, 2018, LECT NOTES COMPUT SC, V11209, P172, DOI 10.1007/978-3-030-01228-1_11
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li PX, 2019, IEEE I CONF COMP VIS, P6161, DOI 10.1109/ICCV.2019.00626
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Lin T.-Y., 2014, CoRR, P740
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang Y, 2020, ARXIV200108878
   Yunhua Zhang, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11213), P355, DOI 10.1007/978-3-030-01240-3_22
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
NR 62
TC 6
Z9 6
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15469
EP 15485
DI 10.1007/s11042-021-10574-z
EA FEB 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000614341400007
DA 2024-07-18
ER

PT J
AU Chen, YL
   Chen, JH
AF Chen, Yulei
   Chen, Jianhua
TI Anonymous and provably secure authentication protocol using
   self-certified cryptography for wireless sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mutual authentication; Key agreement; WSN; Password; BAN logic; Privacy
ID KEY AGREEMENT SCHEME; USER AUTHENTICATION; MUTUAL AUTHENTICATION;
   INTERNET; ROBUST
AB The rapid development of wireless sensor networks (WSNs) has brought great convenience to people's lives, as well as huge security challenges. Recently, Kaur et al. proposed an improved user authentication protocol for WSNs. However, we find that their protocol cannot provide user untraceability and perfect forward security, and it fails to resist the privileged insider attack because it only uses lightweight cryptographic primitive to ensure the security of the scheme. To overcome the weaknesses in Kaur et al.'s protocol, we propose a secure anonymous authentication with key agreement protocol for WSNs. It uses self-certified public key cryptography to guarantee confidentiality, security and availability in public channels. Additionally, through formal and informal security proofs, we demonstrate that the proposed scheme can achieve the expected security properties. By comparing with other related protocols on execution time and communication cost, we find that our protocol is more secure and efficient.
C1 [Chen, Yulei; Chen, Jianhua] Wuhan Univ, Sch Math & Stat, Wuhan 430072, Peoples R China.
C3 Wuhan University
RP Chen, YL (corresponding author), Wuhan Univ, Sch Math & Stat, Wuhan 430072, Peoples R China.
EM ylchen.math@whu.edu.cn
CR Amin R, 2016, COMPUT NETW, V101, P42, DOI 10.1016/j.comnet.2016.01.006
   [Anonymous], 2004, Proc. 2nd ACM workshop on Security of Ad hoc and Sensor Networks, DOI DOI 10.1145/1029102.1029113
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   Chin-Chen Chang, 2004, Operating Systems Review, V38, P91, DOI 10.1145/1031154.1031165
   Das AK, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.2933
   Das ML, 2009, IEEE T WIREL COMMUN, V8, P1086, DOI 10.1109/TWC.2008.080128
   Dodis Y, 2004, LECT NOTES COMPUT SC, V3027, P523
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   Fan CI, 2009, IEEE T INF FOREN SEC, V4, P933, DOI 10.1109/TIFS.2009.2031942
   Fan CI, 2005, COMPUT SECUR, V24, P619, DOI 10.1016/j.cose.2005.03.006
   Farash MS, 2016, AD HOC NETW, V36, P152, DOI 10.1016/j.adhoc.2015.05.014
   Gong P, 2012, NONLINEAR DYNAM, V70, P2401, DOI 10.1007/s11071-012-0628-3
   He DB, 2015, INFORM SCIENCES, V321, P263, DOI 10.1016/j.ins.2015.02.010
   He DB, 2015, IEEE SYST J, V9, P816, DOI 10.1109/JSYST.2014.2301517
   He DB, 2013, IEEE T CONSUM ELECTR, V59, P811, DOI 10.1109/TCE.2013.6689693
   Huang XY, 2011, IEEE T PARALL DISTR, V22, P1390, DOI 10.1109/TPDS.2010.206
   Jabbari A, 2019, NONLINEAR DYNAM, V95, P3177, DOI 10.1007/s11071-018-04748-y
   Jan R, 2009, IEEE INT C COMM ICC, P1
   Juang WS, 2008, IEEE T IND ELECTRON, V55, P2551, DOI 10.1109/TIE.2008.921677
   Kai Chain, 2015, International Journal of Computers and Applications, V37, P67, DOI 10.1080/1206212X.2015.1088211
   Kaur D, 2019, T EMERG TELECOMMUN T, V30, DOI 10.1002/ett.3745
   Khan MK, 2008, CHAOS SOLITON FRACT, V35, P519, DOI 10.1016/j.chaos.2006.05.061
   Kocher Paul, 1999, LECT NOTES COMPUTER, P388, DOI [DOI 10.1007/3-540-48405-1_25, 10.1007/3-540-48405-1_25]
   Ku WC, 2005, ELECTRON LETT, V41, P240, DOI 10.1049/el:20047658
   Kumar P., 2018, RECENT PATENTS ENG, V12, P23, DOI DOI 10.2174/1872212111666170808104744
   Kumar P, 2012, SENSORS-BASEL, V12, P1625, DOI 10.3390/s120201625
   Kumari R, 2018, HDB RES NETWORK FORE, P38
   Kumari S, 2016, FUTURE GENER COMP SY, V63, P56, DOI 10.1016/j.future.2016.04.016
   LAMPORT L, 1981, COMMUN ACM, V24, P770, DOI 10.1145/358790.358797
   Lee CC, 2015, NONLINEAR DYNAM, V79, P2485, DOI 10.1007/s11071-014-1827-x
   Li CT, 2010, J NETW COMPUT APPL, V33, P1, DOI 10.1016/j.jnca.2009.08.001
   Li JL, 2018, T EMERG TELECOMMUN T, V29, DOI 10.1002/ett.3295
   Li X, 2016, SECUR COMMUN NETW, V9, P1916, DOI 10.1002/sec.961
   Li X, 2014, SECUR COMMUN NETW, V7, P1488, DOI 10.1002/sec.767
   Lin CH, 2004, COMPUT STAND INTER, V27, P19, DOI 10.1016/j.csi.2004.03.003
   Lwamo NMR, 2019, INFORM SCIENCES, V477, P369, DOI 10.1016/j.ins.2018.10.037
   Mishra D, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.2946
   Nayyar A., 2015, J WIRELESS NETWORKIN, V5, P19
   Niu YJ, 2011, COMMUN NONLINEAR SCI, V16, P1986, DOI 10.1016/j.cnsns.2010.08.015
   Odelu V, 2015, IEEE T INF FOREN SEC, V10, P1953, DOI 10.1109/TIFS.2015.2439964
   Ojha Rudra Pratap, 2019, International Journal of Advanced Intelligence Paradigms, V13, P113
   Qi MP, 2018, COMPUT METH PROG BIO, V164, P101, DOI 10.1016/j.cmpb.2018.07.008
   Roy S, 2018, IEEE INTERNET THINGS, V5, P2884, DOI 10.1109/JIOT.2017.2714179
   Sharma K, 2017, SCALABLE COMPUT-PRAC, V18, pIII, DOI 10.12694/scpe.v18i3.1299
   Srinivas J, 2020, IEEE T DEPEND SECURE, V17, P1133, DOI 10.1109/TDSC.2018.2857811
   Srivastava PK., 2018, International Journal of Sensors Wireless Communications and Control, V8, P26, DOI [10.2174/2210327908666180413154130, DOI 10.2174/2210327908666180413154130]
   Sun DZ, 2009, IEEE T IND ELECTRON, V56, P2284, DOI 10.1109/TIE.2009.2016508
   Tseng HR, 2007, GLOB TELECOMM CONF, P986
   Turkanovic M, 2014, AD HOC NETW, V20, P96, DOI 10.1016/j.adhoc.2014.03.009
   Wang XY, 2013, CHINESE PHYS B, V22, DOI 10.1088/1674-1056/22/11/110503
   Wang XY, 2010, COMMUN NONLINEAR SCI, V15, P99, DOI 10.1016/j.cnsns.2008.05.002
   Wang XY, 2016, SECUR COMMUN NETW, V9, P5028, DOI 10.1002/sec.1675
   Wang XY, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033012
   Wang XY, 2010, COMMUN NONLINEAR SCI, V15, P4052, DOI 10.1016/j.cnsns.2010.02.014
   Wang YG, 2012, IFIP ADV INF COMM TE, V376, P489
   Xue KP, 2013, J NETW COMPUT APPL, V36, P316, DOI 10.1016/j.jnca.2012.05.010
   Zheng Y, 2006, IEEE INT C SENS NETW, P1
NR 57
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15291
EP 15313
DI 10.1007/s11042-020-10259-z
EA FEB 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613993900007
DA 2024-07-18
ER

PT J
AU Luo, YF
   Peng, DZ
AF Luo, Yifan
   Peng, Dezhong
TI A robust digital watermarking method for depth-image-based rendering 3D
   video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D video; DIBR; SIFT; Watermarking
AB Depth-image-based rendering (DIBR) has become an accessible rendering technology for 3D video. A variety of digital watermarking methods have been proposed to protect the copyright of DIBR 3D video works. However, the robustness and imperceptibility of the existing methods need to be improved. Therefore, we apply the DIBR rendering features to propose a watermarking method to enhance the watermarking effect. First, to improve the robustness, we combine the DIBR rendering rules to construct steady feature data as the selection criterion of watermark embedding position. We detect the scale invariable feature transformation (SIFT) feature points from centre views and match them in every two adjacent views. Each two matched feature points construct one matching vector. The gradient-probability distributions of the vectors are used as the feature data to determine the watermark embedding position. Thus, the embedding positions are robust to the affine transformation and geometric attacks, and the watermark robustness improved. Second, to improve the imperceptibility, we design a joint watermark extraction strategy based on the similarity of the rendered left and right images. The watermark data are embedded into the centre view with low embedding strength and jointly extracted from the left and right images. This strategy guarantees the extraction accuracy while reducing the impact of watermark embedding on the original centre view. Experimental data show that the proposed method has good robustness and imperceptibility.
C1 [Luo, Yifan; Peng, Dezhong] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
   [Luo, Yifan] Sichuan Deqiang Technol Co Ltd, Chengdu 610000, Peoples R China.
   [Luo, Yifan] Sichuan Post & Telecommun Coll, Chengdu 610067, Peoples R China.
   [Peng, Dezhong] Shenzhen Peng Cheng Lab, Shenzhen 518052, Peoples R China.
   [Peng, Dezhong] Chengdu Ruibei Yingte Informat Technol Co Ltd, Chengdu 610054, Peoples R China.
C3 Sichuan University; Peng Cheng Laboratory
RP Luo, YF (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.; Luo, YF (corresponding author), Sichuan Deqiang Technol Co Ltd, Chengdu 610000, Peoples R China.; Luo, YF (corresponding author), Sichuan Post & Telecommun Coll, Chengdu 610067, Peoples R China.
EM tgyifanl@qq.com; pengdz@scu.edu.cn
FU National Natural Science Foundation of China [61971296, U19A2078];
   Sichuan Science and Technology Planning Project [2020YFG0319,
   2020YFH0186]
FX This work is supported by the National Natural Science Foundation of
   China (Grants No. 61971296, U19A2078), Sichuan Science and Technology
   Planning Project (Grants No. 2020YFG0319, 2020YFH0186).
CR Al-Haj A, 2017, MEASUREMENT, V95, P405, DOI 10.1016/j.measurement.2016.10.016
   Alrehily Ashwag, 2018, International Journal of Computer Network and Information Security, V10, P28, DOI 10.5815/ijcnis.2018.05.04
   [Anonymous], 2013, INT C COMP COMM NETW
   Asikuzzaman M, 2016, IEEE T MULTIMEDIA, V18, P1733, DOI 10.1109/TMM.2016.2589208
   Asikuzzaman M, 2014, IEEE IMAGE PROC, P5497, DOI 10.1109/ICIP.2014.7026112
   Bashir T, 2020, AUTOMATIKA, V61, P58, DOI 10.1080/00051144.2019.1670992
   Bashir T, 2016, MULTIMED TOOLS APPL, V75, P7697, DOI 10.1007/s11042-015-2689-z
   Bors AG, 2006, IEEE T IMAGE PROCESS, V15, P687, DOI 10.1109/TIP.2005.863116
   Burini Cesar, 2014, P SPIE, V9028
   Cedillo-Hernandez A, 2014, SIGNAL PROCESS, V97, P40, DOI 10.1016/j.sigpro.2013.08.019
   Chammem A, 2011, PROC SPIE, V7863, DOI 10.1117/12.876267
   Cui C, 2017, MULTIMED TOOLS APPL, V76, P649, DOI 10.1007/s11042-015-3028-0
   Dugelay, 2006, IEEE INT C ACOUST SP, V2, P221
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Franco-Contreras J., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2761, DOI 10.1109/ICIP.2011.6116242
   Garcia E, 2003, IEEE T CIRC SYST VID, V13, P853, DOI 10.1109/TCSVT.2003.815963
   Halici E, 2009, IEEE IMAGE PROC, P4217, DOI 10.1109/ICIP.2009.5413525
   Hefeeda M, 2015, IEEE T MULTIMEDIA, V17, P420, DOI 10.1109/TMM.2015.2389628
   Huawei Tian, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P156, DOI 10.1007/978-3-642-32205-1_14
   Kim H., 2013, IASTED INT C SIGN PR, V2, P222
   Kim HD, 2012, IEEE T BROADCAST, V58, P533, DOI 10.1109/TBC.2012.2206851
   Konstantinides JM, 2009, IEEE T MULTIMEDIA, V11, P23, DOI 10.1109/TMM.2008.2008913
   Koz A, 2010, IEEE T IMAGE PROCESS, V19, P1785, DOI 10.1109/TIP.2010.2045024
   Lin YH, 2011, IEEE T BROADCAST, V57, P602, DOI 10.1109/TBC.2011.2131470
   Liu XY, 2017, NEUROCOMPUTING, V222, P155, DOI 10.1016/j.neucom.2016.10.015
   Liu Y, 2012, IEEE T INF FOREN SEC, V7, P1459, DOI 10.1109/TIFS.2012.2204251
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   Min-Jeong Lee, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P81, DOI 10.1109/IIHMSP.2011.83
   Nam SH, 2018, MULTIMED TOOLS APPL, V77, P7811, DOI 10.1007/s11042-017-4678-x
   Ohbuchi R, 1998, IEEE J SEL AREA COMM, V16, P551, DOI 10.1109/49.668977
   Ou ZH, 2016, MULTIMED TOOLS APPL, V75, P3259, DOI 10.1007/s11042-014-2433-0
   Pei SC, 2015, IEEE T MULTIMEDIA, V17, P128, DOI 10.1109/TMM.2014.2368255
   Pizzolante R, 2018, COMPUT SECUR, V74, P384, DOI 10.1016/j.cose.2017.06.003
   Rana S, 2019, MULTIMED TOOLS APPL, V78, P16665, DOI 10.1007/s11042-018-7024-z
   Sakr N, 2010, IEEE T INSTRUM MEAS, V59, P1047, DOI 10.1109/TIM.2010.2040970
   Singh KM, 2018, MULTIMED TOOLS APPL, V77, P16419, DOI 10.1007/s11042-017-5213-9
   Smolic A, 2007, IEEE T CIRC SYST VID, V17, P1606, DOI 10.1109/TCSVT.2007.909972
   Wang S, 2014, MEASUREMENT, V48, P54, DOI 10.1016/j.measurement.2013.10.028
   Wang YL, 2018, IEEE ACCESS, V6, P8882, DOI 10.1109/ACCESS.2018.2810058
   Yu ZQ, 2003, PATTERN RECOGN, V36, P2603, DOI 10.1016/S0031-3203(03)00086-4
   Zadokar SR, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P483, DOI 10.1109/ICACCI.2013.6637219
   Zafeiriou S, 2005, IEEE T VIS COMPUT GR, V11, P596, DOI 10.1109/TVCG.2005.71
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
NR 44
TC 8
Z9 9
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14915
EP 14939
DI 10.1007/s11042-020-10375-w
EA JAN 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613057400004
DA 2024-07-18
ER

PT J
AU Chou, HM
   Hung, CL
AF Chou, Hsien-Ming
   Hung, Chihli
TI Multiple strategies for trading short-term stock index futures based on
   visual trend bands
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Short-term investment; Day traders; Stock index
   futures; Visual trend bands
AB Many day traders focus on forecasts of stock index futures. These securities are suitable for frequent and time-sensitive trading as well as for short-term investments. However, most day traders' strategies are based on their experiences or news headlines. Combined with a pool trading policy, this may lead to unsatisfactory average monthly profit, particularly when compared to the opportunity cost of the traders' full-time employment in other non-trading jobs. This paper represents multiple investment strategies for day traders based on visual trend bands on short-term stock index futures. This study uses sequential minimal optimization and other machine learning algorithms to evaluate the performance of visual trend bands and derive strategies for better predictions. This study also applies empirical methods on short-term stock index futures datasets to explore the impact of visual trend bands on short-term stock index trading. The accuracy of our proposed visual trend bands reaches 82%, which is not only an objectively high forecasting accuracy rate but also substantially higher than other visual trend bands. The proposed visual trend bands can support day traders in realizing higher profits in their day trades and short-term investments.
C1 [Chou, Hsien-Ming; Hung, Chihli] Chung Yuan Christian Univ, Dept Informat Management, Taoyuan, Taiwan.
C3 Chung Yuan Christian University
RP Chou, HM (corresponding author), Chung Yuan Christian Univ, Dept Informat Management, Taoyuan, Taiwan.
EM chou0109@cycu.edu.tw; chihli@cycu.edu.tw
RI Chou, Hsien-Ming/AAM-2445-2020
OI Chou, Hsien-Ming/0000-0002-4622-5032
CR Bai Y, 2019, J INTELL MANUF, V30, P2245, DOI 10.1007/s10845-017-1388-1
   Bebchuk LA, 2015, COLUMBIA LAW REV, V115, P1085
   Cao JS, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.3987
   Chen S., 2018, Applied Economics and Finance, V5, P49, DOI DOI 10.11114/AEF.V5I3.3079
   Chou H.-M., 2019, ADV MANAG APPL EC, V9, P43
   Chou H.-M., 2020, ADV MANAG APPL EC, V10, P101
   Chou HM, 2020, IEEE ACCESS, V8, P43657, DOI 10.1109/ACCESS.2020.2977043
   Chou HM, 2017, 2017 IEEE 3RD INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC), P399, DOI 10.1109/CIC.2017.00057
   Chung H, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10103765
   Das SP., 2012, INT J COMPUT APPL, DOI [10.5120/5522-7555, DOI 10.5120/5522-7555]
   Desai Ruchi, 2014, INT J ENG DEV RES, P2780
   Huang W, 2005, COMPUT OPER RES, V32, P2513, DOI 10.1016/j.cor.2004.03.016
   Ince H, 2008, INT J GEN SYST, V37, P677, DOI 10.1080/03081070601068595
   Iqbal Z., 2013, Journal of Engineering Research and Applications, V3, P855
   Jahangiri A, 2015, IEEE T INTELL TRANSP, V16, P2406, DOI 10.1109/TITS.2015.2405759
   Kremic E, 2016, INT ARAB J INF TECHN, V13, P287
   Lai HC, 2016, APPL ECON, V48, P3550, DOI 10.1080/00036846.2016.1142653
   Leung JMJ, 2003, APPL ECON LETT, V10, P339, DOI 10.1080/1350485022000041032
   Lin WY, 2012, IEEE T SYST MAN CY C, V42, P421, DOI 10.1109/TSMCC.2011.2170420
   Moghaddam Amin Hedayati, 2016, Journal of Economics, Finance and Administrative Science, V21, P89
   Safi S, 2017, ELECTRON J APPL STAT, V10, P14, DOI 10.1285/i20705948v10n1p14
   Yan X.X., 2017, Int J Econ Finance, V9, P78, DOI [DOI 10.5539/IJEF.V9N1P78, 10.5539/ijef.v9n1p78]
   Zhou JZ, 2018, ENERGIES, V11, DOI 10.3390/en11092292
NR 24
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35481
EP 35494
DI 10.1007/s11042-020-10496-2
EA JAN 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000611465900001
DA 2024-07-18
ER

PT J
AU Tang, ZJ
   Luo, ZH
   Jiang, LZ
   Ma, GQ
AF Tang, Zhijie
   Luo, Zhihang
   Jiang, Lizhou
   Ma, Gaoqian
TI A novel high precision mosaic method for sonar video sequence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater sonar video; Few feature points; High precision; Image mosaic
AB The mosaic of sonar images is more difficult than the mosaic of traditional optical images due to their poor quality and the difficulty in extracting feature points. The existing mosaic methods of sonar images have a series of problems, such as low correct matching rate, large cumulative errors and high requirements for the quality of collected sonar images. In this paper, we proposed a high precision method to implement the mosaic of the underwater sonar video image sequence. Firstly, Accelerated Unsharp Masking (AUSM) algorithm is proposed to preprocess the original image. Then we extract KAZE feature points from preprocessed sonar images. A matching method combining multiple matching strategies with Progressive Sample Consensus (PROSAC) algorithm is followed to complete the image registration. Weighted fusion method and a region of interest (ROI) acquisition method based on the slope of right border is used to optimize the mosaicked image. Finally, we can obtain a high-quality panoramic image of underwater sonar video by a global mosaic strategy. Mosaic experiments on the sonar video image sequence collected by multi-beam sonar demonstrate that the proposed method in this paper can increase the number of feature points by about 70% and make the correct matching rate higher than 70%. The proposed method also has good robustness and the cumulative error during multi-image mosaic is less.
C1 [Tang, Zhijie; Luo, Zhihang; Jiang, Lizhou; Ma, Gaoqian] Shanghai Univ, Sch Mechatron Engn & Automat, 99 Shangda Rd, Shanghai, Peoples R China.
C3 Shanghai University
RP Luo, ZH (corresponding author), Shanghai Univ, Sch Mechatron Engn & Automat, 99 Shangda Rd, Shanghai, Peoples R China.
EM luozhihang@shu.edu.cn
FU National Natural Science Foundation of China [51005142]; Innovation
   Program of Shanghai Municipal Education Commission [14YZ010]; Natural
   Science Foundation of Shanghai [14ZR1414900, 19ZR1419300]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by the National Natural Science Foundation of China (No.
   51005142), the Innovation Program of Shanghai Municipal Education
   Commission (No.14YZ010), and the Natural Science Foundation of Shanghai
   (No. 14ZR1414900, No.19ZR1419300) for providing financial support for
   this work.
CR Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Chen DS, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON TRANSPORTATION INFORMATION AND SAFETY (ICTIS), P1177, DOI 10.1109/ICTIS.2017.8047920
   Deng G, 2011, IEEE T IMAGE PROCESS, V20, P1249, DOI 10.1109/TIP.2010.2092441
   Ferreira F, 2015, ANNU REV CONTROL, V40, P212, DOI 10.1016/j.arcontrol.2015.09.014
   Franchi M, 2018, 2018 IEEE/OES AUTONOMOUS UNDERWATER VEHICLE WORKSHOP (AUV)
   Fu QT, 2018, IEEE ACCESS, V6, P61277, DOI 10.1109/ACCESS.2018.2870638
   HURTOS N, 2013, OCEANS BERGEN 2013 M, P1
   Issartel M, 2017, OCEANS-IEEE
   Lee DH, 2017, IEEE T AERO ELEC SYS, V53, P2399, DOI 10.1109/TAES.2017.2696318
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P2330, DOI 10.1109/LRA.2018.2809510
   Qu Z, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/428076
   Reggiannini M, 2017, J CULT HERIT, V24, P147, DOI 10.1016/j.culher.2016.10.012
   Rehman A, 2010, IEEE IMAGE PROC, P289, DOI 10.1109/ICIP.2010.5653508
   Sha Q., 2017, OCEANS-IEEE
   Song SM, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881417746270
   Tang CR, 2014, INT C INTEL HUM MACH, P249, DOI 10.1109/IHMSC.2014.162
   Tao WL, 2018, IET IMAGE PROCESS, V12, P194, DOI 10.1049/iet-ipr.2017.0172
   Tao WL, 2017, POL MARIT RES, V24, P81, DOI 10.1515/pomr-2017-0068
   [王鸿南 Wang Hongnan], 2004, [中国图象图形学报. A, Journal of image and graphics], V9, P828
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   West G, 2017, OCEANS-IEEE
   Ya-Qiong C., 2016, OCEANS 2016 SHANGHAI, P1
   Ye XF, 2016, J MAR SCI TECH-JAPAN, V21, P38, DOI 10.1007/s00773-015-0330-5
   YOUNG IT, 1995, SIGNAL PROCESS, V44, P139, DOI 10.1016/0165-1684(95)00020-E
   Zhang J, 2017, IET RADAR SONAR NAV, V11, P1512, DOI 10.1049/iet-rsn.2017.0053
   Zhao J, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER NETWORK, ELECTRONIC AND AUTOMATION (ICCNEA), P383, DOI 10.1109/ICCNEA.2017.73
   Zhao JH, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060953
   Zhao JH, 2013, IET IMAGE PROCESS, V7, P616, DOI 10.1049/iet-ipr.2012.0468
NR 28
TC 4
Z9 4
U1 5
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14429
EP 14458
DI 10.1007/s11042-020-10433-3
EA JAN 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000611041300001
DA 2024-07-18
ER

PT J
AU Climent-Pérez, P
   Florez-Revuelta, F
AF Climent-Perez, Pau
   Florez-Revuelta, Francisco
TI Protection of visual privacy in videos acquired with RGB cameras for
   active and assisted living applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Visual privacy; Data protection; Video surveillance;
   Active and assisted living
ID VISION
AB Active and assisted living technologies are much needed, but some aspects of them cause user rejection due to concerns on privacy. This is even more concerning to users when visual information is used, processed, and transmitted. To respond to these concerns, and maximise user acceptance, visual privacy protection measures have to be put in place. In the past, human detection and object segmentation in video were constrained by technological limitations, and could only run with specific hardware and sensors. This paper introduces a proposal for an RGB-only based visual privacy preservation filter, which capitalises on 'deep learning'-based segmentation and pose detectors. A background update scheme is presented, which limits leakage of sensitive information when detection fails. Dilation of the mask can further prevent information leakage, but a trade-off is necessary to correctly update background information. This is achieved via a specific study which is also presented. A comparative study is performed to determine the best configuration for privacy preservation. Results show that union of dilated masks from different deep networks achieves the best overall result.
C1 [Climent-Perez, Pau; Florez-Revuelta, Francisco] Univ Alicante, Dept Comp Technol, POB 99, E-03080 Alicante, Spain.
C3 Universitat d'Alacant
RP Climent-Pérez, P (corresponding author), Univ Alicante, Dept Comp Technol, POB 99, E-03080 Alicante, Spain.
EM pcliment@dtic.ua.es
RI Flórez-Revuelta, Francisco/J-3370-2013
OI Flórez-Revuelta, Francisco/0000-0002-3391-711X; Climent-Perez,
   Pau/0000-0003-1723-5757
FU PAAL -"Privacy-Aware and Acceptable Lifelogging services for older and
   frail people" project: The support of the Joint Programme Initiative
   "More Years, Better Lives" (JPI MYBL) [PAAL JTC2017]; Spanish Agencia
   Estatal de Investigacion [PCIN-2017-114]
FX This work is part of the PAAL -"Privacy-Aware and Acceptable Lifelogging
   services for older and frail people" project: The support of the Joint
   Programme Initiative "More Years, Better Lives" (JPI MYBL, award number:
   PAAL JTC2017) and the Spanish Agencia Estatal de Investigacion (grant
   no: PCIN-2017-114) is gratefully acknowledged.
CR Chaaraoui AA, 2014, SENSORS-BASEL, V14, P8895, DOI 10.3390/s140508895
   [Anonymous], 2013, 9 WORKSH VIS COMP WV, DOI DOI 10.13140/2.1.1740.7044
   Arning K, 2015, LECT NOTES COMPUT SC, V9102, P152, DOI 10.1007/978-3-319-19312-0_13
   Babiceanu Radu F., 2015, 2015 Integrated Communication, Navigation and Surveillance Conference (ICNS), pJ1:1, DOI 10.1109/ICNSURV.2015.7121232
   Bouwmans T, 2019, NEURAL NETWORKS, V117, P8, DOI 10.1016/j.neunet.2019.04.024
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Calvaresi D, 2017, J AMB INTEL HUM COMP, V8, P239, DOI 10.1007/s12652-016-0374-3
   Chen JW, 2018, IEEE COMPUT SOC CONF, P1651, DOI 10.1109/CVPRW.2018.00207
   Çiftçi S, 2018, IEEE T MULTIMEDIA, V20, P68, DOI 10.1109/TMM.2017.2728479
   Climent-Pérez P, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112847
   Dabrowski A, 2015, LECT NOTES BUS INF P, V228, P235, DOI 10.1007/978-3-319-26762-3_21
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Hassan ET, 2017, IEEE COMPUT SOC CONF, P1333, DOI 10.1109/CVPRW.2017.175
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Krombholz Katharina, 2017, USEC 17
   Offermann-van, 2019, SMART CITIES GREEN T
   Offermann-van Heek J., 2018, JMIR REHABIL ASSIST, V5, pE10424, DOI 10.2196/10424
   Orekondy T, 2017, IEEE I CONF COMP VIS, P3706, DOI 10.1109/ICCV.2017.398
   Patil V, 2019, INT CONF COMPUT
   Planinc R, 2016, IET HEALTH TECH SER, V6, P57, DOI 10.1049/PBHE006E_ch4
   Padilla-López JR, 2015, SENSORS-BASEL, V15, P12959, DOI 10.3390/s150612959
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ribaric S, 2016, SIGNAL PROCESS-IMAGE, V47, P131, DOI 10.1016/j.image.2016.05.020
   Sathyanarayana S, 2018, J AMB INTEL HUM COMP, V9, P225, DOI 10.1007/s12652-015-0328-1
   Schif Jeremy, 2009, Privacy in Video Surveillance, P65, DOI DOI 10.1007/978-1-84882-301-3_5
   Shu JY, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P304, DOI 10.1145/3204949.3204973
   Singh Sanchit, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P48, DOI 10.1109/AVSS.2010.63
   Steil J, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319913
   Nguyen THC, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010072
   Varol G, 2017, PROC CVPR IEEE, P4627, DOI 10.1109/CVPR.2017.492
   Waleed A, 2017, GITHUB REPOSITORY
   Wang SQ, 2018, IEEE CONSUM ELECTR M, V7, P95, DOI 10.1109/MCE.2017.2712797
   Wu Y., 2019, DETECTRON2
   Wu ZY, 2018, LECT NOTES COMPUT SC, V11220, P627, DOI 10.1007/978-3-030-01270-0_37
NR 34
TC 13
Z9 14
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23649
EP 23664
DI 10.1007/s11042-020-10249-1
EA JAN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000610019400002
DA 2024-07-18
ER

PT J
AU Sivabalan, KR
   Ramaraj, E
AF Sivabalan, K. R.
   Ramaraj, E.
TI Phenology based classification index method for land cover mapping from
   hyperspectral imagery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Phenology; Remote sensing; Hyperspectral image classification;
   Supervised classification
ID VEGETATION
AB Remote sensing imagery classification contributes assistance to real-time applications for comfort and secures the society. The imagery of satellites entirely depends on the sensor type in satellites. Phenology reflection varies based on the land cover type, which absorbs external energy. Multispectral high-resolution imagery has the maximum details about the earth's surface. This research work defines phenology based classification approach, which can produce precise high precision land cover classification. The need to develop a phenology based methodology reflects on the vegetation development classification and produces a much more suitable land cover map based on reflection values. The RGB channel values of the image do not influence this technique of reflection phenology classification. Phenology Based Classification Index (PBCI) supervised method is used to classify the high-resolution multispectral imagery with improved phenology classification methods. PBCI works on the passive sensor satellite images, without clouds and shadow in classification. The proposed method has compared with existing phenology classification methods using more than seven quality metrics.
C1 [Sivabalan, K. R.; Ramaraj, E.] Alagappa Univ, Dept Comp Sci, Karaikkudi 630003, Tamil Nadu, India.
C3 Alagappa University
RP Sivabalan, KR (corresponding author), Alagappa Univ, Dept Comp Sci, Karaikkudi 630003, Tamil Nadu, India.
EM sivabalanalu@gmail.com
RI E, RAMARAJ/AAQ-1847-2021; KR, SIVABALAN/AAQ-1689-2021
OI KR, SIVABALAN/0000-0003-3821-9043
FU RUSA - phase 2.0 grant, Policy (TNMulti-Gen), Dept. of Edn. Govt. of
   India [F.24-51/2014-U]
FX This article has been written with the financial support of RUSA - phase
   2.0 grant sanctioned via Letter No F.24-51/2014-U, Policy (TNMulti-Gen),
   Dept. of Edn. Govt. of India, Dt. 09.10.2018.
CR Agarwal S, 2016, ISPRS INT J GEO-INF, V5, DOI 10.3390/ijgi5070117
   [Anonymous], 2006, Remote Sensing: Models and Methods for Image Processing
   Atzberger C, 2011, REMOTE SENSING AGR E, V8174, p81740E
   Azzari G, 2017, REMOTE SENS ENVIRON, V202, P64, DOI 10.1016/j.rse.2017.05.025
   Belgiu M, 2018, REMOTE SENS ENVIRON, V204, P509, DOI 10.1016/j.rse.2017.10.005
   Bhosle, 2010, RADIOMETRIC CORRECTI
   Cai ZZ, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121271
   Caiping, 2003, CRUSTAL DEFORMATION, V3, P013
   CARNEIRO F, 2019, PRECIS AGRIC, V21, P1
   Chumbley JR, 2009, NEUROIMAGE, V44, P62, DOI 10.1016/j.neuroimage.2008.05.021
   Devika G, 2018, EUR J REMOTE SENS, V51, P754, DOI 10.1080/22797254.2018.1482731
   Dinh DN, 2016, INT ARCH PHOTOGRAMM, V41, P987, DOI 10.5194/isprsarchives-XLI-B8-987-2016
   Gara TW, 2019, ISPRS J PHOTOGRAMM, V157, P108, DOI 10.1016/j.isprsjprs.2019.09.005
   Goetz SJ, 2004, SER REMOTE SENS, V3, P223, DOI 10.1142/9789812702630_0025
   Gong ZQ, 2018, IEEE T GEOSCI REMOTE, V56, P371, DOI 10.1109/TGRS.2017.2748120
   He L, 2019, IEEE T GEOSCI REMOTE, V57, P1637, DOI 10.1109/TGRS.2018.2868138
   Hermosilla T, 2018, CAN J REMOTE SENS, V44, P67, DOI 10.1080/07038992.2018.1437719
   Hill MJ, 2003, REMOTE SENS ENVIRON, V84, P367, DOI 10.1016/S0034-4257(02)00128-1
   Hua AK, 2018, EUR J REMOTE SENS, V51, P1049, DOI 10.1080/22797254.2018.1542976
   Inglada J, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010095
   Li N, 2018, INT J REMOTE SENS, V39, P8963, DOI 10.1080/01431161.2018.1500731
   Liao CH, 2018, CAN J REMOTE SENS, V44, P215, DOI 10.1080/07038992.2018.1481737
   LOVELAND TR, 1995, ANN ASSOC AM GEOGR, V85, P339, DOI 10.1111/j.1467-8306.1995.tb01798.x
   Moreno J, 2016, REMOTE SENSING GEOME, DOI 10.1002/047134608X.W3605.pub2
   Parikh R, 2008, INDIAN J OPHTHALMOL, V56, P45, DOI 10.4103/0301-4738.37595
   Ren HR, 2018, REMOTE SENS ENVIRON, V209, P439, DOI 10.1016/j.rse.2018.02.068
   Rocchini D, 2019, REMOTE SENS ENVIRON, V231, DOI 10.1016/j.rse.2019.05.011
   Rujoiu-Mare MR, 2017, EUR J REMOTE SENS, V50, P496, DOI 10.1080/22797254.2017.1365570
   Simonetti D, 2015, IEEE GEOSCI REMOTE S, V12, P1496, DOI 10.1109/LGRS.2015.2409982
   Simonetti E., 2014, TECHNICAL REPORTPHEN
   Sivabalan KR, 2020, IET IMAGE PROCESS, V14, P1813, DOI 10.1049/iet-ipr.2018.6526
   Sivabalan KR., 2017, INT J ENG TECHNOL, V9, P3630, DOI [10.21817/ijet/2017/v9i5/170905323, DOI 10.21817/IJET/2017/V9I5/170905323]
   Villamuelas M, 2016, ECOL INDIC, V61, P658, DOI 10.1016/j.ecolind.2015.10.017
   Yu Y, 2017, INT GEOSCI REMOTE SE, P668, DOI 10.1109/IGARSS.2017.8127041
   Zewdie W, 2015, EUR J REMOTE SENS, V48, P121, DOI 10.5721/EuJRS20154808
   Zhen Zhijun, 2019, Acta Geologica Sinica (English Edition), V93, P173, DOI 10.1111/1755-6724.14281
NR 36
TC 1
Z9 1
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14321
EP 14342
DI 10.1007/s11042-020-10484-6
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000610019400016
DA 2024-07-18
ER

PT J
AU Sun, XC
   Lu, ZM
   Wang, Z
   Liu, YL
AF Sun, Xue-Cheng
   Lu, Zhe-Ming
   Wang, Zhe
   Liu, Yong-Liang
TI A geometrically robust multi-bit video watermarking algorithm based on
   2-D DFT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video watermarking; Robust watermarking; 2-D DFT; Geometric attacks
ID DIGITAL WATERMARKING; IMAGE
AB The development of the Internet, together with the progress of multimedia processing techniques, has led to the problems of data piracy, data tampering and illegal dissemination. Digital watermarking is an effective approach to data authentication and copyright protection. This paper proposes a geometrically robust multi-bit video watermarking algorithm based on 2-D DFT (two-dimensional discrete Fourier transform). While most of the existing video watermarking schemes require synchronization to extract the watermark from rotated or scaled videos, which is time-consuming and affects the accuracy, the proposed method can do direct extraction without performing synchronization for videos attacked by rotation, scaling or cropping. For embedding the watermark, circular templates in DFT domain are transformed into spatial masks and added to the video frames in spatial domain. A perceptual model based on local contrast is applied to keep the fidelity of the watermarked video. We also propose an accurate and efficient extraction method which is based on the cross-correlation between the Wiener-filtered DFT magnitude and the stretched template sequence in polar coordinates. Experimental results show that the proposed algorithm is robust against various kinds of attacks, such as compression, filtering, rotation, scaling, cropping, frame averaging and frame rate changing.
C1 [Sun, Xue-Cheng; Lu, Zhe-Ming; Wang, Zhe] Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou 310027, Peoples R China.
   [Lu, Zhe-Ming; Liu, Yong-Liang] Alibaba Grp, Hangzhou 311121, Peoples R China.
   [Lu, Zhe-Ming] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 Zhejiang University; Alibaba Group; Chinese Academy of Sciences;
   Institute of Information Engineering, CAS
RP Lu, ZM (corresponding author), Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou 310027, Peoples R China.; Lu, ZM (corresponding author), Alibaba Grp, Hangzhou 311121, Peoples R China.; Lu, ZM (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
EM zheminglu@zju.edu.cn
FU Alibaba-Zhejiang University Joint Institute of Frontier Technologies
FX This work is supported by the Alibaba-Zhejiang University Joint
   Institute of Frontier Technologies.
CR Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Chen L, 2018, MULTIMED TOOLS APPL, V77, P7187, DOI 10.1007/s11042-017-4628-7
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Cox IJ, 2009, DIGITAL WATERMARKING
   Deng C, 2010, SIGNAL PROCESS, V90, P3256, DOI 10.1016/j.sigpro.2010.05.032
   Dutta T, 2016, J VIS COMMUN IMAGE R, V38, P29, DOI 10.1016/j.jvcir.2015.12.007
   Faragallah OS, 2013, AEU-INT J ELECTRON C, V67, P189, DOI 10.1016/j.aeue.2012.07.010
   Kaehler A., 2016, Learning OpenCV 3
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Liu Y, 2010, SIGNAL PROCESS, V90, P626, DOI 10.1016/j.sigpro.2009.08.001
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Mukherjee DP, 2004, IEEE T MULTIMEDIA, V6, P1, DOI 10.1109/TMM.2003.819759
   Noorkami M, 2005, IEEE IMAGE PROC, P1229
   Pereira S, 2000, IEEE T IMAGE PROCESS, V9, P1123, DOI 10.1109/83.846253
   Pramila Anu, 2007, Digital Watermarking. Proceedings 6th International Workshop, IWDW 2007, P279
   Preda RO, 2015, ELECTRON LETT, V51, P1873, DOI 10.1049/el.2015.2522
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Suhail MA, 2003, IEEE T INSTRUM MEAS, V52, P1640, DOI 10.1109/TIM.2003.817155
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiph.Org Foundation, 2020, XIPH ORG VIDEO TEST
NR 26
TC 19
Z9 19
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13491
EP 13511
DI 10.1007/s11042-020-10392-9
EA JAN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607776200004
DA 2024-07-18
ER

PT J
AU Hmimz, Y
   Chanyour, T
   El Ghmary, M
   Malki, MOC
AF Hmimz, Youssef
   Chanyour, Tarik
   El Ghmary, Mohamed
   Cherkaoui Malki, Mohammed Oucamah
TI Bi-objective optimization for multi-task offloading in latency and radio
   resources constrained mobile edge computing networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile edge computing; Bi-objective optimization; Resource allocation;
   Energy efficiency; Hybrid local search
ID COMPUTATIONAL RESOURCES; JOINT OPTIMIZATION; ENERGY-EFFICIENT; DELAY;
   ALLOCATION; POLICY
AB The Mobile Edge Computing (MEC) environment provides leading-edge services to smart mobile devices (SMDs). Besides, computation offloading is a promising service in 5G: it reduces battery drain and applications' execution time. In this context, we consider a general system consisting of a multi-cell communication network where each base station (BS) is equipped with a MEC server to provide computation offloading services to nearby mobile users. In addition, each SMD handles multiple independent offloadable heavy tasks that are latency-sensitive. The purpose of this article is to jointly optimize tasks' offloading decisions as well as the allocation of critical radio resources while minimizing the overall energy consumption. Therefore, we have formulated a bi-objective optimization problem that is NP-hard. Because of the short decision time constraint, the optimal solution implementation is infeasible. Accordingly, with the use of the weighted aggregation approach, we propose Intelligent Truncation based Hybrid Local Search (ITHLS) solution. In critical radio resources situations, our solution jointly minimizes the number of penalized SMDs and the overall consumed energy. Finally, simulation experiments were realized to study the ITHLS solution performance compared to some effective state of the art solutions, and the simulation results in terms of decision-making time, energy and number of truncated SMDs are very promising.
C1 [Hmimz, Youssef; Chanyour, Tarik; El Ghmary, Mohamed; Cherkaoui Malki, Mohammed Oucamah] Sidi Mohamed Ben Abdellah Univ, FSDM, LIIAN Lab, Dept Math & Comp Sci, POB 1796, Fes 30003, Atlas, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Hmimz, Y (corresponding author), Sidi Mohamed Ben Abdellah Univ, FSDM, LIIAN Lab, Dept Math & Comp Sci, POB 1796, Fes 30003, Atlas, Morocco.
EM youssef.hmimz@usmba.ac.ma
OI Hmimz, Youssef/0000-0001-7625-2106; el ghmary,
   mohamed/0000-0001-5970-481X
CR Abraham S, 2020, TELECOMMUN SYST, V73, P131, DOI 10.1007/s11235-019-00585-5
   Ahmed E, 2015, J NETW COMPUT APPL, V52, P52, DOI 10.1016/j.jnca.2015.02.003
   Ai Y, 2018, DIGIT COMMUN NETW, V4, P77, DOI 10.1016/j.dcan.2017.07.001
   [Anonymous], 2012, P INT C INF COMP NET
   Barbera MV, 2013, IEEE INFOCOM SER, P1285
   Chaufournier L, 2017, SEC 2017: 2017 THE SECOND ACM/IEEE SYMPOSIUM ON EDGE COMPUTING (SEC'17), DOI 10.1145/3132211.3134445
   Chen X, 2016, IEEE ACM T NETWORK, V24, P2827, DOI 10.1109/TNET.2015.2487344
   Chen X, 2015, IEEE T PARALL DISTR, V26, P974, DOI 10.1109/TPDS.2014.2316834
   Chun BG, 2011, EUROSYS 11: PROCEEDINGS OF THE EUROSYS 2011 CONFERENCE, P301
   Hoang DT, 2012, IEEE WCNC, P3145, DOI 10.1109/WCNC.2012.6214347
   El Ghmary Mohamed, 2020, Embedded Systems and Artificial Intelligence. Proceedings of ESAI 2019. Advances in Intelligent Systems and Computing (AISC 1076), P99, DOI 10.1007/978-981-15-0947-6_10
   El Ghmary M., 2019, INT J ELECT COMPUTER, V9, P2088
   Ericsson L., 2011, White Pap, V14, P124
   Fan B, 2016, IEEE NETWORK, V30, P6, DOI 10.1109/MNET.2016.7389824
   Fang Guo, 2018, Shock and Vibration, V2018, DOI 10.1155/2018/6014570
   Fu ZJ, 2016, IEEE T PARALL DISTR, V27, P2546, DOI 10.1109/TPDS.2015.2506573
   Gautam S, 2019, IEEE T WIREL COMMUN, V18, P2493, DOI 10.1109/TWC.2019.2904273
   Ge XH, 2016, IEEE WIREL COMMUN, V23, P72, DOI 10.1109/MWC.2016.7422408
   Gu B, 2017, IEEE T NEUR NET LEAR, V28, P1241, DOI 10.1109/TNNLS.2016.2527796
   Guo FX, 2018, IEEE ACM T NETWORK, V26, P2651, DOI 10.1109/TNET.2018.2873002
   Guo HZ, 2020, IEEE T IND INFORM, V16, P2737, DOI 10.1109/TII.2019.2954944
   Hegyi A, 2016, 2016 IEEE 1ST INTERNATIONAL WORKSHOPS ON FOUNDATIONS AND APPLICATIONS OF SELF* SYSTEMS (FAS*W), P230, DOI 10.1109/FAS-W.2016.56
   Jafari AH, 2015, EURASIP J WIREL COMM, P1, DOI 10.1186/s13638-015-0426-y
   Kumar K, 2010, COMPUTER, V43, P51, DOI 10.1109/MC.2010.98
   Li YZ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING (IEEE EDGE), P66, DOI 10.1109/EDGE.2018.00016
   Lin YD, 2015, IEEE SYST J, V9, P393, DOI 10.1109/JSYST.2013.2289556
   Liu JH, 2019, IEEE ACCESS, V7, P11222, DOI 10.1109/ACCESS.2019.2891113
   Liu J, 2015, J NETW COMPUT APPL, V48, P99, DOI 10.1016/j.jnca.2014.09.009
   Liu LQ, 2019, WIREL NETW, V25, P2027, DOI 10.1007/s11276-018-1794-0
   Lyu XC, 2017, IEEE T VEH TECHNOL, V66, P3435, DOI 10.1109/TVT.2016.2593486
   Mach P, 2017, IEEE COMMUN SURV TUT, V19, P1628, DOI 10.1109/COMST.2017.2682318
   Milan P., 2014, White paper, P854
   Niu XD, 2019, IEEE ACCESS, V7, P83771, DOI 10.1109/ACCESS.2019.2920325
   Peng MG, 2015, IEEE T VEH TECHNOL, V64, P5275, DOI 10.1109/TVT.2014.2379922
   Sardellitti S, 2015, IEEE T SIGNAL INF PR, V1, P89, DOI 10.1109/TSIPN.2015.2448520
   Secci S, 2016, IEEE T NETW SERV MAN, V13, P927, DOI 10.1109/TNSM.2016.2592241
   Sun HJ, 2019, IEEE T VEH TECHNOL, V68, P3052, DOI 10.1109/TVT.2019.2893094
   Wu YH, 2020, IEEE COMMUN LETT, V24, P159, DOI 10.1109/LCOMM.2019.2950013
   Yan J, 2020, IEEE T WIREL COMMUN, V19, P235, DOI 10.1109/TWC.2019.2943563
   Yang L., 2013, ACM SIGMETRICS Perform. Eval. Rev., V40, P23
   YU YP, 2016, IEEE ICC
   Zhang HL, 2017, IEEE CONF COMPUT, P115, DOI 10.1109/INFCOMW.2017.8116362
   Zhang K, 2016, IEEE ACCESS, V4, P5896, DOI 10.1109/ACCESS.2016.2597169
   Zhang WW, 2014, IEEE NETWORK, V28, P67, DOI 10.1109/MNET.2014.6963807
   Zhang WW, 2013, IEEE T WIREL COMMUN, V12, P4569, DOI 10.1109/TWC.2013.072513.121842
   Zhao PT, 2017, IEEE ACCESS, V5, P11255, DOI 10.1109/ACCESS.2017.2710056
   Zhao ZC, 2020, IEEE T IND INFORM, V16, P5424, DOI 10.1109/TII.2019.2949348
NR 47
TC 10
Z9 11
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17129
EP 17166
DI 10.1007/s11042-020-09365-9
EA JAN 2021
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000606296800003
DA 2024-07-18
ER

PT J
AU Dubey, SR
   Chakraborty, S
AF Dubey, Shiv Ram
   Chakraborty, Soumendu
TI Average biased ReLU based CNN descriptor for improved face retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ReLU; AB-ReLU; VGGFace; Image retrieval; CNN
ID RECOGNITION; PATTERN
AB The convolutional neural networks (CNN), including AlexNet, GoogleNet, VGGNet, etc. extract features for many computer vision problems which are very discriminative. The trained CNN model over one dataset performs reasonably well whereas on another dataset of similar type the hand-designed feature descriptor outperforms the same trained CNN model. The Rectified Linear Unit (ReLU) layer discards some values in order to introduce the non-linearity. In this paper, it is proposed that the discriminative ability of deep image representation using trained model can be improved by Average Biased ReLU (AB-ReLU) at the last few layers. Basically, AB-ReLU improves the discriminative ability in two ways: 1) it exploits some of the discriminative and discarded negative information of ReLU and 2) it also neglects the irrelevant and positive information used in ReLU. The VGGFace model trained in MatConvNet over the VGG-Face dataset is used as the feature descriptor for face retrieval over other face datasets. The proposed approach is tested over six challenging, unconstrained and robust face datasets (PubFig, LFW, PaSC, AR, FERET and ExtYale) and also on a large scale face dataset (PolyUNIR) in retrieval framework. It is observed that the AB-ReLU outperforms the ReLU when used with a pre-trained VGGFace model over the face datasets. The validation error by training the network after replacing all ReLUs with AB-ReLUs is also observed to be favorable over each dataset. The AB-ReLU even outperforms the state-of-the-art activation functions, such as Sigmoid, ReLU, Leaky ReLU and Flexible ReLU over all seven face datasets.
C1 [Dubey, Shiv Ram] Indian Inst Informat Technol, Comp Vis Grp, Sri City, Andhra Pradesh, India.
   [Chakraborty, Soumendu] Indian Inst Informat Technol, Lucknow, Uttar Pradesh, India.
RP Dubey, SR (corresponding author), Indian Inst Informat Technol, Comp Vis Grp, Sri City, Andhra Pradesh, India.
EM shivram1987@gmail.com; soum.uit@gmail.com
RI Chakraborty, Soumendu/ABA-2031-2020; Dubey, Shiv Ram/T-7541-2019
OI Chakraborty, Soumendu/0000-0002-8778-8229; Dubey, Shiv
   Ram/0000-0002-4532-8996
FU IIIT Sri City, India through the Faculty Seed Research Grant; NVIDIA
   Corporation
FX This research is funded by IIIT Sri City, India through the Faculty Seed
   Research Grant. We gratefully acknowledge the support of NVIDIA
   Corporation with the donation of the GeForce Titan X Pascal used for
   this research.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2018, ARXIV180307441
   [Anonymous], 2015, Advances in neural information processing systems
   Bansal A, 2017, IEEE INT CONF COMP V, P2545, DOI 10.1109/ICCVW.2017.299
   Benavente R, 1998, 24 COMP VIS CTR
   Beveridge J. R., 2013, 2013 IEEE Sixth International Conference on Biometrics: Theory, Applications and Systems (BTAS), P1
   Chakraborty S, 2018, IEEE T CIRC SYST VID, V28, P171, DOI 10.1109/TCSVT.2016.2603535
   Chakraborty S, 2017, COMPUT ELECTR ENG, V62, P92, DOI 10.1016/j.compeleceng.2017.06.013
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P1201, DOI 10.1007/s11042-015-3111-6
   Clevert D., 2016, ARXIV151107289
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dubey SR, 2019, MULTIMED TOOLS APPL, V78, P28063, DOI 10.1007/s11042-019-07908-3
   Dubey SR, 2019, MULTIMED TOOLS APPL, V78, P16411, DOI 10.1007/s11042-018-7028-8
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Dubey SR, 2014, IEEE T IMAGE PROCESS, V23, P5323, DOI 10.1109/TIP.2014.2358879
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang G. B., 2007, Technical Report, DOI 10.1.1. 122.8268
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li YH, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6142839
   Liu PZ, 2017, IEEE T IMAGE PROCESS, V26, P5706, DOI 10.1109/TIP.2017.2736343
   Ma X, 2019, MULTIMED TOOLS APPL, P1
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Qiu S, 2018, INT C PATT RECOG, P1223, DOI 10.1109/ICPR.2018.8546022
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shamsolmoali P, 2019, MULTIMED TOOLS APPL, V78, P23867, DOI 10.1007/s11042-018-6146-7
   Sharma S, 2015, EXPERT SYST APPL, V42, P821, DOI 10.1016/j.eswa.2014.08.052
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang YJ, 2019, MULTIMED TOOLS APPL, V78, P19945, DOI 10.1007/s11042-019-7377-y
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xu B, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/832093
   Ye F, 2018, MULTIMED TOOLS APPL, P1
   Zhang BC, 2010, PATTERN RECOGN LETT, V31, P2337, DOI 10.1016/j.patrec.2010.07.006
   Zhou HJ, 2019, MULTIMED TOOLS APPL, V78, P197, DOI 10.1007/s11042-018-5702-5
NR 52
TC 19
Z9 19
U1 5
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23181
EP 23206
DI 10.1007/s11042-020-10269-x
EA JAN 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000604478900001
DA 2024-07-18
ER

PT J
AU Kaur, H
   Kumar, M
AF Kaur, Harmandeep
   Kumar, Munish
TI On the recognition of offline handwritten word using holistic approach
   and AdaBoost methodology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Handwritten word recognition; Feature extraction; Classification;
   AdaBoost; Holistic approach
ID NAME RECOGNITION
AB Offline handwritten word recognition assumes an imperative part in the domain of document analysis and recognition. This article describes a technique for the recognition of offline handwritten Gurumukhi words. The proposed system uses a holistic approach to recognize a word, where a word itself is considered as an individual item. Thus, the word is recognized without considering any explicit segmentation. A set of features, i.e. zoning features, diagonal features, intersection & open-end point features is considered to extract the desirable characteristics from the word images. The classification techniques like k-Nearest Neighbor (k-NN), Support Vector Machine (SVM) and Random forest classifiers are employed for the recognition purpose. To boost the system performance, majority voting scheme of all the considered classifiers and an ensemble algorithm i.e. AdaBoost (Adaptive Boosting) algorithm are used. This system is evaluated on the database comprising 1,00,000 samples of 100 different city names handwritten in Gurumukhi script. Maximum recognition accuracy of 88.78% has been achieved using AdaBoost methodology and the attained results are comparable with state-of-the-art results.
C1 [Kaur, Harmandeep; Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM harmandeepk08@gmail.com; munishcse@gmail.com
RI Kumar, Munish/P-7756-2018; Kaur, Harmandeep/AAL-6727-2021
OI Kumar, Munish/0000-0003-0115-1620; Kaur, Harmandeep/0000-0003-1230-1225
CR Adak C, 2016, INT CONF FRONT HAND, P429, DOI [10.1109/ICFHR.2016.0086, 10.1109/ICFHR.2016.81]
   [Anonymous], 2016, J AI DATA MIN
   Arani SAAA, 2019, INT J IMAGE GRAPH, V19, DOI 10.1142/S0219467819500013
   Assayony MO, 2018, IEEE GCC CONF EXHIB, P1
   Bhowmik S, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS, P257, DOI 10.1109/CICN.2014.66
   Bhunia AK, 2019, PROC CVPR IEEE, P4762, DOI 10.1109/CVPR.2019.00490
   Bhunia AK, 2020, INFORM FUSION, V57, P1, DOI 10.1016/j.inffus.2019.10.010
   Bhunia AK, 2018, PATTERN RECOGN, V79, P12, DOI 10.1016/j.patcog.2018.01.034
   Dasgupta J, 2016, PATTERN RECOGN LETT, V79, P73, DOI 10.1016/j.patrec.2016.05.017
   Dehghan M, 2001, PATTERN RECOGN, V34, P1057, DOI 10.1016/S0031-3203(00)00051-0
   Dutta K, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P25, DOI 10.1109/DAS.2018.69
   Ghosh M, 2019, STUD COMPUT INTELL, V687, P103, DOI 10.1007/978-981-10-8974-9_6
   Gowda PK, 2017, Int J Innov Res Comput Commun Eng, V5, P9955, DOI [10.15680/IJIRSET.2015.0407007, DOI 10.15680/IJIRSET.2015.0407007]
   Hu HL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Jayech K, 2016, INT ARAB J INF TECHN, V13, P1024
   Kadhm MS, 2015, INT J ADV COMPUT SC, V6, P64
   Kaur H., 2019, DOCUMENT ANAL RECOGN, V1020, P152
   Kaur H, 2018, PATTERN ANAL APPL, V21, P897, DOI 10.1007/s10044-018-0731-2
   Kessentini Y, 2010, PATTERN RECOGN LETT, V31, P60, DOI 10.1016/j.patrec.2009.08.009
   Khémiri A, 2016, INT CONF FRONT HAND, P560, DOI [10.1109/ICFHR.2016.101, 10.1109/ICFHR.2016.0108]
   KUMAR M, 2016, MACHINE GRAPHICS VIS, V25, P45
   Kumar Manoj, 2015, INT J ENG RES TECHNO, V4, P90
   Kumar M, 2019, ARTIF INTELL REV, V52, P2235, DOI 10.1007/s10462-017-9607-x
   Kumar M, 2014, NATL ACAD SCI LETT, V37, P567, DOI 10.1007/s40009-014-0280-1
   Kumar M, 2014, NATL ACAD SCI LETT, V37, P381, DOI 10.1007/s40009-014-0253-4
   Kumar N., 2018, Int J Pure Appl Math, V119, P14749
   Kumar S, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1009, DOI 10.1109/ICCSP.2016.7754301
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Li YT, 2019, IEEE INTERNET THINGS, V6, P628, DOI 10.1109/JIOT.2018.2851185
   Li YG, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3378026
   Mhiri M, 2018, PATTERN RECOGN LETT, V111, P87, DOI 10.1016/j.patrec.2018.04.025
   Pal U, 2012, INT CONF FRONT HAND, P169, DOI 10.1109/ICFHR.2012.238
   Pal U, 2011, PROC INT CONF DOC, P483, DOI 10.1109/ICDAR.2011.103
   Pal U, 2009, IEICE T INF SYST, VE92D, P1146, DOI 10.1587/transinf.E92.D.1146
   Patel C., 2011, Proceedings of the Second International Conference on Emerging Applications of Information Technology (EAIT 2011), P194, DOI 10.1109/EAIT.2011.47
   Patel MS, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P630, DOI 10.1109/IC3I.2014.7019825
   Patel MS, 2015, Int J Innov Res Sci Eng Technol, V04, P5078, DOI [10.15680/IJIRSET.2015.0407007, DOI 10.15680/IJIRSET.2015.0407007]
   Roy PP, 2014, INT CONF FRONT HAND, P506, DOI 10.1109/ICFHR.2014.91
   Roy PP, 2016, PATTERN RECOGN, V60, P1057, DOI 10.1016/j.patcog.2016.04.012
   Shaw B, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P720, DOI 10.1109/ACPR.2015.7486597
   Tamen Z, 2017, PATTERN RECOGN LETT, V93, P123, DOI 10.1016/j.patrec.2017.01.020
   Tavoli R, 2018, IET IMAGE PROCESS, V12, P1606, DOI 10.1049/iet-ipr.2017.0839
   Thadchanamoorthy S, 2013, PROC INT CONF DOC, P793, DOI 10.1109/ICDAR.2013.162
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
NR 45
TC 17
Z9 17
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 11155
EP 11175
DI 10.1007/s11042-020-10297-7
EA JAN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604816700004
DA 2024-07-18
ER

PT J
AU Yan, XP
   Wang, XY
   Xian, YJ
AF Yan, Xiaopeng
   Wang, Xingyuan
   Xian, Yongjin
TI Chaotic image encryption algorithm based on arithmetic sequence
   scrambling model and DNA encoding operation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Arithmetic sequence scrambling; DNA operation;
   Logistic map; Hash function; Diffusion operation
ID SEMI-TENSOR PRODUCT; PERMUTATION-DIFFUSION; SCHEME; MAP; SYSTEMS; SECURE
AB In this paper, in order to solve the problem of un-rigorous scrambling method and single diffusion method in image encryption, a new method based on arithmetic sequence scrambling model, DNA coding sequence and one-dimensional Logistic mapping is proposed. First, the Hash array is obtained by combining the information of the original plaintext image with the Hash algorithm SHA-512. The Hash array generates the initial value and control parameters of the chaotic system, and then generates the chaotic key flow. Second, the arithmetic progression of partitioned matrix after scrambling, change the position of the original image pixels, replacement and operation, and then for DNA combines images and the chaotic sequence of chaotic system to produce DNA, DNA encoding, decoding rules for operation, change the original data bits of pixel values, thus further destruction of the original information. Finally, a chaotic diffusion operation is performed to further change the pixel information of the original image and output the cipher-text image. The experimental results and various security analyses show that the algorithm has good encryption effect and can resist the common plaintext attack, clipping attack and noise attack. The algorithm can be used for image encryption.
C1 [Yan, Xiaopeng; Wang, Xingyuan; Xian, Yongjin] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
C3 Dalian Maritime University
RP Wang, XY (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
EM karasyxp@126.com; xywang@dlmu.edu.cn; marsxyj@163.com
RI Wang, Xing-yuan/I-6353-2015; Yan, Xiaopeng/GWV-6620-2022; yan,
   xiao/JVP-0766-2024; Xian, Yongjin/AAQ-6737-2021
OI Xian, Yongjin/0000-0003-1921-049X
FU National Natural Science Foundation of China [61672124]; Password Theory
   Project of the 13th Five-Year Plan National Cryptography Development
   Fund [MMJJ20170203]; Liaoning Province Science and Technology Innovation
   Leading Talents Program Project [XLYC1802013]; Key R&D Projects of
   Liaoning Province [2019020105-JH2/103]; Jinan City '20 universities'
   Funding Projects Introducing Innovation Team Program [2019GXRC031]
FX This research is supported by the National Natural Science Foundation of
   China (No: 61672124), the Password Theory Project of the 13th Five-Year
   Plan National Cryptography Development Fund (No: MMJJ20170203), Liaoning
   Province Science and Technology Innovation Leading Talents Program
   Project (No: XLYC1802013), Key R&D Projects of Liaoning Province (No:
   2019020105-JH2/103), Jinan City '20 universities' Funding Projects
   Introducing Innovation Team Program (No: 2019GXRC031).
CR Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Azimi Z, 2020, MULTIMED TOOLS APPL, V79, P1727, DOI 10.1007/s11042-019-08375-6
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Cao WJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107457
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Chen Y., 2019, IEEE PHOTONICS J, V11, P1
   Chen YB, 2020, J CONTEMP CHINA, V29, P1, DOI [10.1080/10670564.2019.1621526, 10.1080/01932691.2020.1791172, 10.1007/s12652-020-02066-z]
   Chen Y, 2021, VIROL SIN, V36, P365, DOI 10.1007/s12250-020-00250-1
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Dagadu JC, 2019, MULTIMED TOOLS APPL, V78, P24979, DOI 10.1007/s11042-019-7693-2
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Gu K, 2020, IEEE T NETW SERV MAN, V17, P332, DOI 10.1109/TNSM.2019.2941869
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Kocarev L., 2001, IEEE CIRC SYST MAG, V1, P6, DOI DOI 10.1109/7384.963463
   Liao ZF, 2019, IEEE ACCESS, V7, P26411, DOI 10.1109/ACCESS.2019.2901742
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P21579, DOI 10.1007/s11042-020-08880-z
   Lu WP, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102794
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Mollaeefar M, 2017, MULTIMED TOOLS APPL, V76, P607, DOI 10.1007/s11042-015-3064-9
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Praveenkumar P, 2017, TELECOMMUN SYST, V65, P65, DOI 10.1007/s11235-016-0212-0
   Ramasamy P, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21070656
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Sun L, 2020, IEEE J-STARS, V13, P1174, DOI 10.1109/JSTARS.2020.2980576
   Sun LH, 2020, INT GEOL REV, V62, P1094, DOI 10.1080/00206814.2019.1669079
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   Wang J, 2019, MATH BIOSCI ENG, V16, P5851, DOI 10.3934/mbe.2019292
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2015, OPT LASER ENG, V68, P126, DOI 10.1016/j.optlaseng.2014.12.025
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P26111, DOI 10.1007/s11042-019-07794-9
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2018, IEEE ACCESS, V6, P62272, DOI 10.1109/ACCESS.2018.2875676
   Wang XY, 2018, IEEE ACCESS, V6, P39705, DOI 10.1109/ACCESS.2018.2855726
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Wu XJ, 2018, MULTIMED TOOLS APPL, V77, P12349, DOI 10.1007/s11042-017-4885-5
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Yu F, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/5859273
   Yuan HM, 2017, MULTIMED TOOLS APPL, V76, P8087, DOI 10.1007/s11042-016-3454-7
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013021
   Zhang JM, 2019, IEEE ACCESS, V7, P83873, DOI 10.1109/ACCESS.2019.2924944
   Zhang JY, 2020, J INTERNET TECHNOL, V21, P1, DOI 10.3966/160792642020012101001
   Zhang LL, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/6/064209
   Zhang YT, 2020, MULTIMED TOOLS APPL, V79, P14751, DOI 10.1007/s11042-019-7240-1
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
NR 68
TC 43
Z9 44
U1 7
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10949
EP 10983
DI 10.1007/s11042-020-10218-8
EA JAN 2021
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604479100007
DA 2024-07-18
ER

PT J
AU Liu, TP
   Xue, F
   Sun, J
   Sun, X
AF Liu, Tianpeng
   Xue, Feng
   Sun, Jian
   Sun, Xiao
TI A survey of event analysis and mining from social multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social event; Multimedia; Topic model; Multi-modality
ID MODEL
AB In recent years, with the popularity of mobile devices and mobile Internet, more and more social media sites are growing in an explosive way. Therefore, the social hot event will be rapidly fermented by the interaction of a large number of network users, and a large amount of multimedia data (such as texts, images and videos) will be generated. Therefore, it is important and necessary to conduct the research of multimedia social event analysis to know the evolutionary trend of social event over time automatically. This paper provides a survey and summarizes major progresses in multimedia social event analysis. We focus on four areas: (1) multimedia social event representation; (2) multimedia social event detection and tracking; (3) multimedia social event evolutionary analysis; and (4) multimedia social event topic mining.
C1 [Liu, Tianpeng; Xue, Feng; Sun, Jian] Hefei Univ Technol, Dept Comp Sci, 485 Danxia Rd, Hefei, Peoples R China.
   [Sun, Xiao] Hefei Univ Technol, AnHui Prov Key Lab Affect Comp & Adv Intelligent, 485 Danxia Rd, Hefei, Peoples R China.
C3 Hefei University of Technology; Hefei University of Technology
RP Xue, F (corresponding author), Hefei Univ Technol, Dept Comp Sci, 485 Danxia Rd, Hefei, Peoples R China.
EM liutianpeng_cs@mail.hfut.edu.cn; feng.xue@hfut.edu.cn;
   jsun2016@mail.hfut.edu.cn; sunx@hfut.edu.cn
RI Sun, Xiao/JTV-1301-2023
OI Sun, Xiao/0000-0001-9750-7032
CR Ahmed A., 2008, SDM, P219, DOI DOI 10.1137/1.9781611972788.20
   Allan J, 2002, INFORM RETRIEVAL, V5, P139, DOI 10.1023/A:1015793827697
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], 2010, ARXIV PREPRINT ARXIV
   [Anonymous], 2012, Mining Text Data, DOI [10.1007/978-1-4614-3223-4_13, DOI 10.1007/978-1-4614-3223-4_13, DOI 10.1007/978-1-4614-3223-413]
   [Anonymous], 2012, P 20 ACM INT C MULTI
   Behmo R, 2010, LECT NOTES COMPUT SC, V6314, P171, DOI 10.1007/978-3-642-15561-1_13
   Blei D.M., 2003, Modeling annotated data, P127, DOI [DOI 10.1145/860435.860460, 10.1145/860435.860460]
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Caron F, 2008, GEN POLYA URN TIME V
   Chen J, 2013, IEEE WIC ACM INT C W, P153
   Chen NY, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P868, DOI 10.1109/IIH-MSP.2014.219
   Chi Y, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P153
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Das R, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P795
   Debole F, 2004, SUPERVISED TERM WEIG, DOI [10.1007/978-3-540-45219-5_7, DOI 10.1007/978-3-540-45219-5_7]
   Deerwester S, 1990, J AM SOC OFR INFORM, V41
   Diakopoulos N., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P115, DOI 10.1109/VAST.2010.5652922
   Fang Q, 2015, IEEE T MULTIMEDIA, V17, P2281, DOI 10.1109/TMM.2015.2491019
   Fang Y, 2012, MINING CONTRASTIVE O, P63
   Firan C.S., 2010, Proceedings of the 19th ACM international conference on Information and knowledge management, P189
   Gao ZJ, 2012, IEEE INT C DAT MIN, P1056
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Guillaumin M, 2010, PROC CVPR IEEE, P902, DOI 10.1109/CVPR.2010.5540120
   Haghighi Aria, 2009, P HUMAN LANGUAGE TEC, P362, DOI DOI 10.3115/1620754.1620807
   Hardoon DR, 2004, Canonical correlation analysis: An overview with application to learning methods
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P5814, DOI 10.1109/TIP.2016.2614132
   Hong RC, 2016, IEEE T MULTIMEDIA, V18, P1555, DOI 10.1109/TMM.2016.2567071
   Iwata T, 2010, P 16 ACM SIGKDD INT, P663
   Iwata T, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1427
   Jelodar H., 2017, Latent Dirichlet Allocation (LDA) and Topic modeling: models, applications, a survey
   Jin W, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P807, DOI 10.1145/1244002.1244182
   Joachims T, 1999, P EUR C MACH LEARN
   Kalamaras I, 2014, IEEE T MULTIMEDIA, V16, P1460, DOI 10.1109/TMM.2014.2316473
   Kasiviswanathan SP, 2011, EMERGING TOPIC DETEC, P745
   KELLER KL, 1993, J MARKETING, V57, P1, DOI 10.2307/1252054
   Kumaran G., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P297, DOI 10.1145/1008992.1009044
   Lewis D. D., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P4, DOI 10.1007/BFb0026666
   Li PJ, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA 2016), P324, DOI 10.1109/ICCCBDA.2016.7529578
   Liu Jiawei, 2016, P 24 ACM INT C MULT, P192
   Makkonen J, 2004, INFORM RETRIEVAL, V7, P347, DOI 10.1023/B:INRT.0000011210.12953.86
   MARON ME, 1961, J ACM, V8, P404, DOI 10.1145/321075.321084
   McCallum A., 1998, AAAI 98 WORKSH LEARN, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426
   Merler M, 2012, IEEE T MULTIMEDIA, V14, P88, DOI 10.1109/TMM.2011.2168948
   Moghaddam S, 2012, DESIGN LDA MODELS AS, P803
   Moghaddam S, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P665
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Pan C.Mitra., 2011, Proceedings of the 11th annual international ACM/IEEE joint conference on Digital libraries, JCDL '11, P349
   Putthividhya D, 2010, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2010.5540000
   Qian S., 2015, ACM T MULTIM COMPUT, V11, P1
   Qian SS, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P99, DOI 10.1145/2733373.2806234
   Qian SS, 2016, IEEE T MULTIMEDIA, V18, P233, DOI 10.1109/TMM.2015.2510329
   Qian Shengsheng, 2016, P 24 ACM INT C MULTI
   QIU M, 2013, P NAACL HLT, P1031
   Ramage D., 2009, Clustering the Tagged Web, P54
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Ren L., 2008, P 25 INT C MACH LEAR, P824, DOI [10.1145/1390156.1390260, DOI 10.1145/1390156.1390260]
   Richang Hong, 2015, IEEE Transactions on Big Data, V1, P152, DOI 10.1109/TBDATA.2016.2515640
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Sang JT, 2016, IEEE INT SYM MULTIM, P481, DOI 10.1109/ISM.2016.130
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   THEIL H, 1988, STAT PROBABIL LETT, V6, P137, DOI 10.1016/0167-7152(88)90107-1
   Wan L, 2012, HYBRID NEURAL NETWOR, P1287
   Wang C, 2012, P 24 C UNC ART INT, P579
   Wang H, 2016, P ANN HICSS, P1134, DOI 10.1109/HICSS.2016.144
   Wang M, 2017, IEEE T KNOWL DATA EN, V29, P1101, DOI 10.1109/TKDE.2017.2654445
   Wang M, 2016, IEEE T KNOWL DATA EN, V28, P1864, DOI 10.1109/TKDE.2016.2535367
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wang X, 2005, P 3 INT WORKSHOP LIN, P28
   Wu X, 2008, IEEE T MULTIMEDIA, V10, P188, DOI 10.1109/TMM.2007.911778
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P64, DOI 10.1109/TMM.2014.2375793
   Yang Y., 2002, P 8 ACM SIGKDD INT C, P688, DOI DOI 10.1145/775047.775150
   Yu J, 2012, INT C PATT RECOG, P246
   Zha ZJ, 2008, PROC CVPR IEEE, P333
   Zhang H, 2007, CROSS MODAL CORRELAT, V40, P273
   Zhang J, 2010, Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, P1079
   Zhu J, 2014, J MACH LEARN RES, V15, P1073
NR 80
TC 8
Z9 9
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33431
EP 33448
DI 10.1007/s11042-019-7567-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000594855000007
DA 2024-07-18
ER

PT J
AU Pan, ZG
   Li, XW
   Cui, L
   Zhang, ZW
AF Pan, Zhenggao
   Li, Xianwei
   Cui, Lin
   Zhang, Zhiwei
TI Video clip recommendation model by sentiment analysis of time-sync
   comments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video clip recommendation; Time-sync comment sentiment; Topic modeling;
   Sentiment analysis; Emotion vector
AB With the advent of video time-sync comments, users can not only comment the videos on the Internet, but also share their feelings with others. However, the number of the videos on the Internet is so huge that users do not have enough time and energy to watch all the videos. How to recommend the videos suitable for users has become an important problem. The traditional video sentiment analysis methods can not work effectively and the results are not easy to explain. In this paper, an emotion recognition algorithm based on sync-time comments is proposed, as a basis for the recommendation of video clips. First, we propose a formal description of video clips recommendation based on sentiment analysis. Secondly, by constructing the classification of time-sync comments based on Latent Dirichlet Allocation (LDA) topic model, we evaluate the emotion vector of the words in time-sync comments. Meanwhile, the video clips are recommended according to the emotion relationships among the video clips. The experimental results show that the proposed model is effective in analyzing the complex sentiment of different kinds of text information.
C1 [Pan, Zhenggao; Li, Xianwei; Cui, Lin; Zhang, Zhiwei] Suzhou Univ, Sch Informat Engn, Suzhou, Peoples R China.
   [Li, Xianwei] Waseda Univ, Global Informat & Telecommun Inst, Tokyo, Japan.
   [Cui, Lin] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing, Peoples R China.
C3 Waseda University; Nanjing University of Aeronautics & Astronautics
RP Pan, ZG (corresponding author), Suzhou Univ, Sch Informat Engn, Suzhou, Peoples R China.
EM szxypzg@163.com
RI Zhang, Zhiwei/AAU-1222-2020
OI Zhang, Zhiwei/0000-0002-4766-6198
CR [Anonymous], 2009, P 3 INT C WEBLOGS SO
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bobicev V, 2010, LECT NOTES COMPUT SC, V6008, P375, DOI 10.1007/978-3-642-12116-6_31
   Foundation PS, 2017, 039EBOL FDN PS
   Heinrich G, 2016, PARAMETER ESTIMATION
   [李寿山 Li Shoushan], 2010, [中文信息学报, Journal of Chinese Information Processing], V24, P56
   Liu Zhiming, 2012, Computer Engineering and Applications, V48, P1, DOI 10.3778/j.issn.1002-8331.2012.01.001
   Luo CZ, 2016, IEEE T MULTIMEDIA, V18, P40, DOI 10.1109/TMM.2015.2495248
   Lv GY, 2016, AAAI CONF ARTIF INTE, P3000
   Quan C, 2010, INT J ADV INTELLIGEN, V2, P105
   Ren FJ, 2012, INFORM TECHNOL MANAG, V13, P321, DOI 10.1007/s10799-012-0138-5
   Ren J, 2016, 10EBOL CECPS
   Wang M, 2017, IEEE T KNOWL DATA EN, V29, P1101, DOI 10.1109/TKDE.2017.2654445
   Wang M, 2016, IEEE T IMAGE PROCESS, V26, P5678, DOI 10.1109/TIP.2016.2612829
   Wang M, 2013, IEEE T IMAGE PROCESS, V22, P1395, DOI 10.1109/TIP.2012.2231088
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wu B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P721, DOI 10.1145/2623330.2623625
   Wu B, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P117, DOI 10.1145/2647868.2654904
   Wu ZC, 2014, 2014 IIAI 3RD INTERNATIONAL CONFERENCE ON ADVANCED APPLIED INFORMATICS (IIAI-AAI 2014), P280, DOI 10.1109/IIAI-AAI.2014.65
   Xian Yikun., 2015, Proceedings of the 7th International Workshop on Hot Topics in Planet-scale mObile computing and online Social neTworking, P31
   Yoshii K, 2016, MUSIC COMMENTATOR GE
   Yu H, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P129
   Zhao JM, 2008, PROCEEDINGS OF THE CHINA ASSOCIATION FOR SCIENCE AND TECHNOLOGY, VOL 4, NO 3, P117, DOI 10.3115/1613715.1613733
   Zheng Y.Y., 2015, New Technology of Library and Information Service, V31, P82
   Zhou L, 2016, WIA OPINMINE SYSTEM
NR 25
TC 6
Z9 6
U1 3
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33449
EP 33466
DI 10.1007/s11042-019-7578-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000594855000008
DA 2024-07-18
ER

PT J
AU Gupta, M
   Gupta, KK
   Shukla, PK
AF Gupta, Manish
   Gupta, Kamlesh Kumar
   Shukla, Piyush Kumar
TI Session key based fast, secure and lightweight image encryption
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption algorithm; Decryption algorithm; Session key; Crossover
   operator; Mutation operator; Block cipher
AB Nowadays, most of the communications in IoT enabled devices are done in the form of images. To protect the images from intruders, there is a need for a secure encryption algorithm. Many encryption algorithms have been proposed, some of the algorithms are based on symmetric-key cryptography and others are based on asymmetric key cryptography. This work proposed a fast, secure, and lightweight symmetric image cryptographic algorithm based on the session key. In this work, for every image encryption, a new session key is generated. Here session keys are generated with the help of crossover and mutation operators of genetic algorithm. This proposed algorithm uses a 64-bit plain text and requires an 80-bit key, where 64-bits of a key is generated via symmetric hexadecimal key and the remaining 16-bits of a key are randomly added, to encrypt the image. Here crossover and mutation operators are used to generate random 64-bits of a key. The proposed algorithm will work for both color and grayscale images. The proposed algorithm is simulated on MATLAB 2017 platform and compared with similar types of the existing algorithm on various parameters.
C1 [Gupta, Manish; Shukla, Piyush Kumar] UIT RGPV, Dept Comp Sci & Engn, Bhopal, India.
   [Gupta, Kamlesh Kumar] RJIT, Dept Informat Technol, Tekanpur, India.
C3 Rajiv Gandhi Technological University
RP Gupta, M (corresponding author), UIT RGPV, Dept Comp Sci & Engn, Bhopal, India.
EM manishgupta.2007@gmail.com; kamlesh_rjitbsf@yahoo.com; pphdwss@gmail.com
RI SHukla, Piyush Kumar/AAB-3521-2021; Shukla, Dr. Piyush
   Kumar/GVT-3949-2022; user, user/GLQ-6797-2022; gupta,
   manish/HIK-2539-2022
OI SHukla, Piyush Kumar/0000-0002-3715-3882; Shukla, Dr. Piyush
   Kumar/0000-0002-3715-3882; Gupta, Dr. Manish/0000-0003-0848-6132
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   [Anonymous], 1998, P 1 ADV ENCR STAND A
   Barker E, 2011, NIST SPECIAL PUBLICA
   Bhoi, 2017, INT C SMART COMP COM
   Bhowmik S, 2011, COMM COM INF SC, V157, P342
   Burwick Carolynn, 1998, MARS-a candidate cipher for AES
   Chakrabarti P, 2008, INT J COMPUT SCI NET, V8
   Chattopadhyay C, 2015, ARXIV150501795
   Coppersmith D, 1996, IBM J RES DEV, V40, P253, DOI 10.1147/rd.402.0253
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   de Dormale GM, 2007, ANN IEEE SYM FIELD P, P281, DOI [10.1109/FCCM.2007.47, 10.1109/FCCM.2007.13]
   Ebrahim M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2013), P557, DOI 10.1109/ICCSCE.2013.6720027
   Elamrawy F., 2018, INT J SIGNAL PROCESS, V3, P27
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P27919, DOI 10.1007/s11042-018-5974-9
   Goswami RS, 2013, PROCEEDINGS OF THE 2013 10TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, P489, DOI 10.1109/ITNG.2013.82
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Gupta K, 2012, ADV ENG SOFTW, V49, P29, DOI 10.1016/j.advengsoft.2012.03.001
   Huang X, 2015, ENTROPY-SWITZ, V17, P28, DOI 10.3390/e17010028
   Jin X, 2018, MULTIMED TOOLS APPL, V77, P15851, DOI 10.1007/s11042-017-5159-y
   Khan S, 2015, ARXIV150900981
   Li RP, 2021, MULTIMED TOOLS APPL, V80, P30583, DOI 10.1007/s11042-020-08802-z
   Liu H, 2019, MULTIMED TOOLS APPL, V78, P20465, DOI 10.1007/s11042-019-7186-3
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P17669, DOI 10.1007/s11042-020-08645-8
   Milad Ali Ahmad, 2012, Journal of Computer Science, V8, P1191, DOI 10.3844/jcssp.2012.1191.1197
   Premkumar R, 2019, MULTIMED TOOLS APPL, V78, P9577, DOI 10.1007/s11042-018-6534-z
   Qatawneh M., 2018, INT J COMPUTER NETWO, V10, P43, DOI DOI 10.5121/IJCNC.2018.10205
   SCHNEIER B, 1993, DR DOBBS J, V18, P50
   Sreelaja NK, 2012, APPL SOFT COMPUT, V12, P2879, DOI 10.1016/j.asoc.2012.04.002
   Stalin S, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1389-z
   Sun S, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.3.034113
   Talhaoui MZ, 2021, J REAL-TIME IMAGE PR, V18, P85, DOI 10.1007/s11554-020-00948-1
   Tang JY, 2019, MULTIMED TOOLS APPL, V78, P24765, DOI 10.1007/s11042-019-7602-8
   Tong XJ, 2015, ENTROPY-SWITZ, V17, P181, DOI 10.3390/e17010181
   Usman M, 2017, INT J ADV COMPUT SC, V8, P402
   Wang X, 2019, NEUROSCI LETT, V699, P1, DOI 10.1016/j.neulet.2019.01.028
   Wuling Ren, 2010, Proceedings of the 2010 Second International Conference on Modeling, Simulation and Visualization Methods (WMSVM 2010), P221, DOI 10.1109/WMSVM.2010.48
   Yao W, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0165937
   Ye GD, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/8402578
   Zhang X, 2018, COMMUNICATIONS COMPU, V952
NR 39
TC 24
Z9 24
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10391
EP 10416
DI 10.1007/s11042-020-10116-z
EA NOV 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000591261300001
DA 2024-07-18
ER

PT J
AU Sun, LM
   Liang, SL
   Chen, PP
   Chen, YX
AF Sun, Limin
   Liang, Shili
   Chen, Peipei
   Chen, Yixin
TI Encrypted digital watermarking algorithm for quick response code using
   discrete cosine transform and singular value decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QR code; Digital watermark; Cellular automaton; Josephus ring; Singular
   value decomposition
ID QR CODE; IMAGE; SVD
AB There is a trade-off relationship between the imperceptibility of a watermark and the robustness of a digital watermarking algorithm; to overcome this, we propose a robust digital watermarking encryption algorithm for quick response (QR) code images based on discrete cosine transform (DCT) and singular value decomposition (SVD) through dual scrambling using Josephus ring and cellular automata. Experimental results show that watermark can still be identified from a seriously distorted QR code. The proposed scheme maintains satisfactory image quality, with great robustness to noise, filters, JPEG compression, rotation, cropping, contrast variation attacks, print/scan attacks, and so on. This algorithm can achieve further reform for QR code, which can be widely used to protect the copyright of digital works.
C1 [Sun, Limin; Chen, Peipei; Chen, Yixin] Northeast Normal Univ, Sch Phys Circuits & Syst, 5268 Renmin St, Changchun 130024, Peoples R China.
   [Liang, Shili] Northeast Normal Univ, Sch Phys, 5268 Renmin St, Changchun 130024, Peoples R China.
C3 Northeast Normal University - China; Northeast Normal University - China
RP Liang, SL (corresponding author), Northeast Normal Univ, Sch Phys, 5268 Renmin St, Changchun 130024, Peoples R China.
EM lsl@nenu.edu.cn
FU Jilin Provincial Science and Technology Department Social Development
   Project [20190303016SF]; Changchun City Science and Technology Bureau
   Local Academy (School, Institute) Cooperation Project [18DY010]
FX This work is supported by the Jilin Provincial Science and Technology
   Department Social Development Project (Key) (20190303016SF) and the
   Changchun City Science and Technology Bureau Local Academy (School,
   Institute) Cooperation Project (18DY010).
CR Akter A., 2014, 3 INT C INF EL VIS M, P1
   Chai ZQ, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1167-5
   Chouhan R., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2745, DOI 10.1109/ICIP.2011.6116238
   Hua ZY, 2019, IEEE ACCESS, V7, P8660, DOI 10.1109/ACCESS.2018.2890116
   Huang HC, 2011, IEEE T CONSUM ELECTR, V57, P779, DOI 10.1109/TCE.2011.5955222
   Jin J, 2012, OPT LASER ENG, V50, P1836, DOI 10.1016/j.optlaseng.2012.06.002
   Jindal H, 2014, 2014 INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P251, DOI 10.1109/PDGC.2014.7030751
   Kabra RG, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1968, DOI 10.1109/ICCSP.2016.7754516
   Kang QB, 2014, INT C INTELL COMP CO, P331, DOI 10.1109/ICCP.2014.6937017
   Kaur Sandeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P23, DOI 10.5815/ijigsp.2017.07.03
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li Li, 2011, J HANGZHOU DIANZI U, V31, P46
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   LIU L, 2013, INFRARED LASER ENG, V42, P304
   Liu Zi-ming, 2018, Journal of East China University of Science and Technology (Natural Science Edition), V44, P97, DOI 10.14135/j.cnki.1006-3080.20170220002
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Mittal Archie, 2017, International Journal of Image, Graphics and Signal Processing, V9, P28, DOI 10.5815/ijigsp.2017.05.04
   Pandya KH, 2008, INT J EMERG TECHNOL, V4, P258
   Thompson N, 2013, J DIGIT FORENSICS SE, V8, P43
   Tralic D, 2016, RADIOENGINEERING, V25, P548, DOI 10.13164/re.2016.0548
   Vongpradhip S., 2011, 2011 Proceedings of 9th International Conference on ICT and Knowledge Engineering (ICT & Knowledge Engineering 2011) - Conference postponed to 2012, P47, DOI 10.1109/ICTKE.2012.6152412
   Wang XY, 2013, COMMUN NONLINEAR SCI, V18, P3075, DOI 10.1016/j.cnsns.2013.04.008
   Xie Rong-sheng, 2013, Journal of Shanghai Jiaotong University (Science), V18, P443, DOI 10.1007/s12204-013-1415-0
   Xie RS, 2015, NEUROCOMPUTING, V167, P625, DOI 10.1016/j.neucom.2015.04.026
   Xu J, 2015, NETINFO SECUR, V6, P13
   [薛青晨 Xue Qingchen], 2016, [包装工程, Packaging Engineering], V37, P158
   Ye XY, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P479, DOI 10.1109/CIS.2014.28
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
   Zhou Peng-ying, 2010, Application Research of Computers, V27, P1896, DOI 10.3969/j.issn.1001-3695.2010.05.083
NR 32
TC 4
Z9 5
U1 2
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10285
EP 10300
DI 10.1007/s11042-020-10075-5
EA NOV 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000590997400001
DA 2024-07-18
ER

PT J
AU An, H
   Moon, N
AF An, Hyeonwoo
   Moon, Nammee
TI Image-based positioning system using LED Beacon based on IoT central
   management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Positioning; IoT; Object detection; Deep learning
AB The benefits of technologies related to the Internet of Things (IoT), virtual and augmented reality (VR/AR), digital twins, and so on, can be fully realized when associated devices are positioned intuitively. However, AR systems hosted within smartphones pose challenges where auxiliary hardware and computational configurations associated with precise positioning are concerned. To this effect, we propose a deep learning-based indoor measurement system that can determine positions using images collected via beacons designed as IoT terminals. The proposed system is broadly divided into a detection unit, an extraction unit, a positioning unit, and a management server. The beacons were detected using deep learning algorithms, from which the postures were extracted using a homography matrix, and position of the imaging device was determined in reference to the beacon's position. With the unique design of our system, in that it simultaneously performs posture and positioning estimations, high immersive AR can be achieved. Moreover, scalability of the positioning space is also guaranteed as multiple beacons can be monitored at once. For the experiment, we simulated a virtual indoor space comprising pyramid beacons and the results were promising.
C1 [An, Hyeonwoo; Moon, Nammee] Hoseo Univ, Dept Comp Engn, Asan, South Korea.
C3 Hoseo University
RP Moon, N (corresponding author), Hoseo Univ, Dept Comp Engn, Asan, South Korea.
EM nammee.moon@gmail.com
FU National Research Foundation of Korea (NRF) - Korean Government (MSIT)
   [NRF-2017R1A2B4008886]
FX This work is supported by the National Research Foundation of Korea
   (NRF) and the grant was funded by the Korean Government (MSIT, No.
   NRF-2017R1A2B4008886).
CR Beauregard S., 2006, Proceedings of the 3rd Workshop on Positioning, Navigation and Communication, P27
   Chum O, 2005, COMPUT VIS IMAGE UND, V97, P86, DOI 10.1016/j.cviu.2004.03.004
   Dai JF, 2016, ADV NEUR IN, V29
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Ha H, 2016, LECT NOTES COMPUT SC, V9431, P447, DOI 10.1007/978-3-319-29451-3_36
   Jo D, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-018-0162-5
   Khongkraphan K, 2019, J INF PROCESS SYST, V15, P22, DOI 10.3745/JIPS.04.0098
   Komine T, 2004, IEEE T CONSUM ELECTR, V50, P100, DOI 10.1109/TCE.2004.1277847
   Lee S, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-019-0168-7
   Lee SW, 2015, J KOREAN I COMMUNICA, V32, P81, DOI [10.13067/JKIECS.2015.10.1.81, DOI 10.13067/JKIECS.2015.10.1.81]
   Li YW, 2018, IEEE PHOTONIC TECH L, V30, P1171, DOI 10.1109/LPT.2018.2834930
   Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199
   Luo PF, 2013, INK WORKS OPTIC WIRE, P25, DOI 10.1109/IWOW.2013.6777770
   Mautz R, 2011, INT C INDOOR POSITIO
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Slabaugh G.G., 1999, COMPUTING EULER ANGL
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang X-X, 2019, J INFORM PROCESSING, V15
   Werner M., 2011, 2011 International Conference on Indoor Positioning and Indoor Navigation, P1
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang XZ, 2012, SENSORS-BASEL, V12, P429, DOI 10.3390/s120100429
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 23
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26655
EP 26667
DI 10.1007/s11042-020-10166-3
EA NOV 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000590503300001
DA 2024-07-18
ER

PT J
AU Shanthi, P
   Nickolas, S
AF Shanthi, P.
   Nickolas, S.
TI An efficient automatic facial expression recognition using local
   neighborhood feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion; Facial expression; Local binary pattern; Local neighborhood
   encoded pattern; Feature fusion; Feature selection; Multiclass support
   vector machine
ID EMOTION RECOGNITION; TEXTURE CLASSIFICATION; BINARY PATTERNS; NETWORK
AB In computer vision, several feature extraction methods have been developed to differentiate the variations of facial expressions. But the effect of the relationship among the neighboring pixel is not considered in the existing texture encoding based method. This paper exploits the method to analyze the association among the adjacent pixels using feature fusion technique. For efficient texture representation, the proposed approach combines the Local Binary Pattern (LBP) with the Local Neighborhood Encoded Pattern (LNEP). The LBP feature encodes the relationship of adjacent pixels with respect to the central pixel whereas LNEP represents the relationship among the two closest local neighboring pixels of the current pixel. After concatenating LBP with LNEP, the most relevant features are selected using chi-square statistical analysis and classified using multiclass Support Vector Machine (SVM). Experimental findings show that the proposed hybrid feature performed better than an individual feature and it achieves an average recognition accuracy of 97.86% and 97.11% on CK+ and MMI dataset, respectively. The effectiveness of the reduced hybrid feature is also evaluated under a noisy environment and the results show better performance in such conditions.
C1 [Shanthi, P.; Nickolas, S.] Natl Inst Technol, Dept Comp Applicat, Tiruchirappalli, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Shanthi, P (corresponding author), Natl Inst Technol, Dept Comp Applicat, Tiruchirappalli, Tamil Nadu, India.
EM shanthianu81@gmail.com; nickolas@nitt.edu
RI Nickolas, Savarimuthu/ADQ-6349-2022; Shanthi, P/IUN-0318-2023
OI Nickolas, Savarimuthu/0000-0002-0703-3839; 
CR Ahmed F, 2014, INT ARAB J INF TECHN, V11, P195
   Akputu OK, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3131287
   Arshid S, 2018, CLUSTER COMPUT, V21, P323, DOI 10.1007/s10586-017-0832-5
   Banerjee P, 2018, EXPERT SYST APPL, V113, P100, DOI 10.1016/j.eswa.2018.06.044
   Barman A, 2017, PATTERN RECOGNIT LET
   Barman A, 2019, APPL SOFT COMPUT, V77, P88, DOI 10.1016/j.asoc.2019.01.011
   Chang C, 2022, EVOL INTELL, V15, P2321, DOI 10.1007/s12065-019-00296-5
   Chen JK, 2018, IEEE T AFFECT COMPUT, V9, P38, DOI 10.1109/TAFFC.2016.2593719
   Chen LF, 2018, INFORM SCIENCES, V428, P49, DOI 10.1016/j.ins.2017.10.044
   Friesen E., 1978, Environmental Psychology & Nonverbal Behavior, V3, P5, DOI 10.1037/t27734-000
   Guo M, 2017, MULTIMED TOOLS APPL, V76, P2995, DOI 10.1007/s11042-016-3282-9
   Nguyen HD, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419400159
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Holder RP, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0190-5
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   Kumar S, 2016, IET COMPUT VIS, V10, P567, DOI 10.1049/iet-cvi.2015.0273
   Lai CC, 2014, OPTIK, V125, P6678, DOI 10.1016/j.ijleo.2014.08.052
   Li R, 2015, INT CONF COMPUT INTE, P347, DOI 10.1109/CICN.2015.75
   Liang DD, 2020, VISUAL COMPUT, V36, P499, DOI 10.1007/s00371-019-01636-3
   Liu ZT, 2017, IEEE-CAA J AUTOMATIC, V4, P668, DOI 10.1109/JAS.2017.7510622
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Luo RC, 2011, IEEE IND ELEC, P4244
   Luo Y, 2016, OPTIK, V127, P718, DOI 10.1016/j.ijleo.2015.10.147
   Luo Y, 2013, OPTIK, V124, P2767, DOI 10.1016/j.ijleo.2012.08.040
   Majumder A, 2018, IEEE T CYBERNETICS, V48, P103, DOI 10.1109/TCYB.2016.2625419
   Majumder A, 2014, PATTERN RECOGN, V47, P1282, DOI 10.1016/j.patcog.2013.10.010
   Makhmudkhujaev F, 2019, TURK J ELECTR ENG CO, V27, P516, DOI 10.3906/elk-1804-58
   da Silva FAM, 2016, INT J IMAGE GRAPH, V16, DOI 10.1142/S0219467816500194
   Meena HK, 2021, IETE J RES, V67, P667, DOI 10.1080/03772063.2019.1565952
   Mistry K, 2017, IEEE T CYBERNETICS, V47, P1496, DOI 10.1109/TCYB.2016.2549639
   Munir A, 2018, OPTIK, V158, P1016, DOI 10.1016/j.ijleo.2018.01.003
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Punitha A., 2013, INT J COMPUTER APPL, V80, P1
   Rathee N, 2017, IETE J RES, V63, P845, DOI 10.1080/03772063.2017.1329639
   Rivera AR, 2015, PATTERN RECOGN LETT, V51, P94, DOI 10.1016/j.patrec.2014.08.012
   Shbib R., 2015, Int J Signal Process Image Process Pattern Recognit, V8, P9
   Siddiqi MH, 2015, IEEE T IMAGE PROCESS, V24, P1386, DOI 10.1109/TIP.2015.2405346
   Cruz EAS, 2018, PATTERN RECOGN LETT, V114, P13, DOI 10.1016/j.patrec.2017.08.008
   Sun WY, 2018, NEUROCOMPUTING, V296, P12, DOI 10.1016/j.neucom.2018.03.034
   Tong Y, 2014, OPTIK, V125, P4186, DOI 10.1016/j.ijleo.2014.04.062
   Topi M, 2000, INT C PATT RECOG, P935, DOI 10.1109/ICPR.2000.903698
   Turan C, 2018, J VIS COMMUN IMAGE R, V55, P331, DOI 10.1016/j.jvcir.2018.05.024
   Upputuri AV, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P349, DOI 10.1109/ICCSP.2015.7322904
   Valstar M., 2010, Proceedings of 3rd intern. workshop on EMOTION (satellite of LREC): Corpora for research on emotion and affect, P65
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang HJ, 2018, IEEE ACCESS, V6, P6001, DOI 10.1109/ACCESS.2017.2784842
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Zavaschi THH, 2013, EXPERT SYST APPL, V40, P646, DOI 10.1016/j.eswa.2012.07.074
   Zhang ZY, 1999, INT J PATTERN RECOGN, V13, P893, DOI 10.1142/S0218001499000495
NR 52
TC 9
Z9 9
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10187
EP 10212
DI 10.1007/s11042-020-10105-2
EA NOV 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000590061100001
DA 2024-07-18
ER

PT J
AU Elshamy, EM
   Hussein, AI
   Hamed, HFA
   Abdelghany, MA
   Kelash, HM
AF Elshamy, Elsayed M.
   Hussein, Aziza I.
   Hamed, Hesham F. A.
   Abdelghany, M. A.
   Kelash, Hamdy M.
TI Voice over internet protocol voicemail security system using two factor
   authentication and biometric prints with new efficient hybrid
   cryptosystem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VoIP; Cryptosystem; Authentication; Baker map; RC6; Encryption; Security
   systems
AB New hybrid cryptosystems represent a highly effective method for increasing security levels of Voice over Internet Protocol (VoIP) systems. In this paper, a dual-security cryptosystem for VoIP voicemail is proposed based on two-factor authentication, followed by Baker Map and RC6 encryption. Two security system models are proposed: the first involves biometric voiceprint encryption with pin code, and the second involves dual-biometric encryption via voiceprint with fingerprint. Parameters were selected to assess the proposed security systems for both quality of function and real-life practicality. An experiment was conducted with a true VoIP call manager, VoIP terminals and fingerprint reader. In addition, Visual Basic and MATLAB were utilized for development and testing of the new cryptosystems. Behind this orthogonal frequency division multiplexing (OFDM) simulation system was developed to ensure efficiency with different signal-to-noise ratio (SNR). Comparative analysis among both encryption methods determined that the first scenario is more cost-effective than the second owing to the lack of fingerprint-reading device, but the second is more secure due to combined biometric print requirements. A comparison with techniques used by other, recently developed voice cryptosystems demonstrated lower correlation coefficient (25% improvement) and encryption processing time by the presented hybrid cryptosystem. Collectively, this paper presents a VoIP system with high security and immunity vis-a-vis image encryption noise.
C1 [Elshamy, Elsayed M.; Kelash, Hamdy M.] Menoufia Univ, Dept Comp Sci & Engn, Fac Elect Engn, Menoufia 32952, Egypt.
   [Hussein, Aziza I.; Hamed, Hesham F. A.; Abdelghany, M. A.] Menia Univ, Dept Comp & Syst Engn, Fac Engn, Al Minya, Egypt.
   [Hussein, Aziza I.] Effat Univ, Elect & Comp Engn Dept, Jeddah, Saudi Arabia.
   [Hamed, Hesham F. A.] Egyptian Russian Univ, Dept Telecommun Engn, Cairo, Egypt.
   [Abdelghany, M. A.] Prince Sattam Bin Abdulaziz Univ, Elect Engn Dept, Coll Engn, Wadi Addwasir 11991, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Minia University; Effat University; Egyptian Russian
   University; Prince Sattam Bin Abdulaziz University
RP Elshamy, EM (corresponding author), Menoufia Univ, Dept Comp Sci & Engn, Fac Elect Engn, Menoufia 32952, Egypt.
EM engsm2008@hotmail.com; azibrahim@effatuniversity.edu.sa;
   hfah66@yahoo.com; abdelghany@mu.edu.eg; dr.hamdykelash@yahoo.com
RI Hussein, Aziza/GRO-5962-2022; Abdelghany, Mahmoud/DXV-9501-2022
OI Abdelghany, Mahmoud/0000-0002-9772-0324
CR Aissa B, 2015, BRIT J APPL SCI TECH, V8, P107, DOI [10.9734/BJAST/2015/14744, DOI 10.9734/BJAST/2015/14744]
   Al-Azawi MKM, 2018, IET SIGNAL PROCESS, V12, P214, DOI 10.1049/iet-spr.2016.0708
   Albin C, 2018, INT C EL COMM AER TE, P29
   Augustine N., 2015, INT J TRUST MANAG CO, V3, P74, DOI [10.1504/IJTMCC.2015.072467, DOI 10.1504/IJTMCC.2015.072467]
   Dharavath K, 2013, REV INT C COMP INT C
   Du RS, 2014, INT J COMPUT SCI NET, V14, P44
   Eldin SMS, 2015, INT J SPEECH TECHNOL, V18, P131, DOI 10.1007/s10772-014-9253-5
   Elsayed M, 2015, INT J SPEECH TECHNOL, V18, P13
   Elshamy A. M., 2016, OPTICAL QUANTUM ELEC, V48, P1
   Elshamy AM, 2013, J LIGHTWAVE TECHNOL, V31, P2533, DOI 10.1109/JLT.2013.2267891
   Fayyaz Y., 2016, INT J NAT ENG SCI, P33
   Fishawy NFE., 2007, INT J NETWORK SECUR, V5, P241
   Fujii H, 2013, 8 INT C INT TECHN SE
   Ghasemzadeh A, 2017, INT J SPEECH TECHNOL, V20, P829, DOI 10.1007/s10772-017-9452-y
   Kakaei KH, 2018, NOVEL FAST SECURE AP
   Kataria AN, 2013, NIRMA UNIV INT CONF
   Khanapur NH, 2015, INT J ADV COMPUTER R, V5, P225
   Lima JB, 2016, MULTIMED TOOLS APPL, V75, P8403, DOI 10.1007/s11042-015-2755-6
   Liu HJ, 2016, OPTIK, V127, P7431, DOI 10.1016/j.ijleo.2016.05.073
   Ometov A, 2018, CRYPTOGRAPHY-BASEL, V2, DOI 10.3390/cryptography2010001
   Padmanabhan M, 2002, IEEE T SPEECH AUDI P, V10, P433, DOI 10.1109/TSA.2002.804303
   Rohloff K, 2017, IEEE T INF FOREN SEC, V12, P1031, DOI 10.1109/TIFS.2016.2639340
   Sathiyamurthi P, 2017, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-017-0118-0
   Shelke R, 2018, 2018 3 INT C CONVERG, P1, DOI [10.1109/I2CT.2018.8529329, DOI 10.1109/I2CT.2018.8529329]
   Sinha K, 2017, IMPERIAL J INTERDISC, V3, P1981
   Tamimi AA, 2014, WORLD C ENG COMP SCI
   Wang XY, 2020, IEEE ACCESS, V8, P9260, DOI 10.1109/ACCESS.2019.2963329
   Wickramanayake DK, 2011, IEEE COMP SOC JAM SE
   Yu HL, 2009, ICICTA: 2009 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTATION TECHNOLOGY AND AUTOMATION, VOL I, PROCEEDINGS, P536, DOI 10.1109/ICICTA.2009.136
   Zhang YJ, 2019, PR ELECTROMAGN RES S, P300, DOI 10.1109/PIERS-Fall48861.2019.9021400
NR 30
TC 1
Z9 1
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 9877
EP 9893
DI 10.1007/s11042-020-09986-0
EA NOV 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000589565200001
DA 2024-07-18
ER

PT J
AU Badshah, S
   Khan, AA
   Hussain, S
   Khan, B
AF Badshah, Sher
   Khan, Arif Ali
   Hussain, Shahid
   Khan, Bilal
TI What users really think about the usability of smartphone applications:
   diversity based empirical investigation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Usability; Accessibility; Accessible-design; Universal design;
   Guidelines; Smartphone apps
ID MOBILE APPLICATIONS; DESIGN GUIDELINES; ACCESSIBILITY; INTERFACE;
   CHECKLIST; QUALITY; APPS; PAIN
AB In recent years, smartphone devices are becoming progressively popular across a diverse range of users. However, user diversity creates challenges in smartphone application (app) development. The diversity of users is often ignored by designers and developers due to the absence of requirements. Owing to this, many smartphone users face usability issues. Despite that, no dedicated platform found that guide smartphone app designers and developers regarding human universality. The aim of this research is to explore the requirements of diverse users in smartphone apps and provide usability guidelines. The objectives of this research are achieved by following two scientific approaches. The human diversity requirements are located by conducting usability tests that investigated the requirements in the form of usability issues. The systematic literature review (SLR) process is followed in order to resolve the discovered usability issues. Both approaches resulted in a list of usability issues and guidelines. The usability tests returned 27 problems while the SLR came with a comprehensive set of universal usability guidelines that were grouped into eleven categories. The study concluded with some major outcomes. The results show evidence of critical usability problems that must be addressed during the design and development of smartphone apps. Moreover, the study also revealed that people with disabilities were three times severely affected by usability problems in such apps than people of different ages and their needs must be considered a top priority in the development of smartphone apps.
C1 [Badshah, Sher; Khan, Arif Ali] Nanjing Univ Aeronut & Astronaut, Coll Comp Sci & Technol, Nanjing, Peoples R China.
   [Badshah, Sher; Hussain, Shahid; Khan, Bilal] COMSATS Univ Islamabad, Dept Comp Sci, Islamabad 44000, Pakistan.
C3 COMSATS University Islamabad (CUI)
RP Khan, AA (corresponding author), Nanjing Univ Aeronut & Astronaut, Coll Comp Sci & Technol, Nanjing, Peoples R China.
EM sherbadshah46@gmail.com; arif.khan@nuaa.edu.cn
RI Hussain, Shahid/AAP-5065-2021; khan, Arif/HMV-3165-2023; Khan, Arif
   Ali/ABG-2862-2020
OI Hussain, Shahid/0000-0003-4826-3339; Khan, Arif Ali/0000-0002-8479-1481
CR Afzal W, 2009, INFORM SOFTWARE TECH, V51, P957, DOI 10.1016/j.infsof.2008.12.005
   Ahmad N, 2018, INFORM SOFTWARE TECH, V94, P130, DOI 10.1016/j.infsof.2017.10.005
   [Anonymous], 9241202008EN ISO
   [Anonymous], 2003, CONSTRUCTING ACCESSI
   [Anonymous], 2013, J INFORM SYSTEMS RES
   Ayob NZB, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P427, DOI 10.1109/ICIME.2009.99
   Baharuddin R., 2013, RES J APPL SCI ENG T, V5, P2225
   Ballantyne M, 2018, 17TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2018), P305, DOI 10.1145/3282894.3282921
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bangs D, 2014, BR WILDL, V25, P228
   Bhuiyan M., 2017, ARXIV170804653
   Billi M, 2010, UNIVERSAL ACCESS INF, V9, P337, DOI 10.1007/s10209-009-0180-1
   Brooke John., 1996, Usability evaluation in industry, V189, P4, DOI DOI 10.1201/9781498710411
   Carmien S, ELDERS USING SMARTPH
   Carmien S, 2014, ELDERS USING SMARTPH, P26
   Chen L, 2010, EASE 10 P 14 INT C E, P135
   Zapata BC, 2015, J MED SYST, V39, DOI 10.1007/s10916-014-0182-2
   Zapata BC, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0081-6
   Da Costa RP, 2019, IEEE ACCESS, V7, P116145, DOI 10.1109/ACCESS.2019.2910778
   Darejeh Ali, 2013, Journal of Computer Science, V9, P1443, DOI 10.3844/jcssp.2013.1443.1450
   Díaz-Bossini JM, 2014, PROCEDIA COMPUT SCI, V27, P57, DOI 10.1016/j.procs.2014.02.008
   Dybå T, 2008, ESEM'08: PROCEEDINGS OF THE 2008 ACM-IEEE INTERNATIONAL SYMPOSIUM ON EMPIRICAL SOFTWARE ENGINEERING AND MEASUREMENT, P178
   Franklin A, 2018, PHARMAKON CONCEPT FI, P1
   Gorlenko L, 2003, IBM SYST J, V42, P639, DOI 10.1147/sj.424.0639
   Hanna L., 1997, interactions, V4, P9, DOI [DOI 10.1145/264044.264045, 10.1145/264044.264045]
   Harrison R., 2013, J INTERACTION SCI, V1, P1, DOI [10.1186/2194-0827-1-1, DOI 10.1186/2194-0827-1-1]
   Hoehle H, 2016, INT J HUM-COMPUT ST, V89, P35, DOI 10.1016/j.ijhcs.2016.02.001
   Huang H, 2018, UNIVERSAL ACCESS INF, V17, P291, DOI 10.1007/s10209-017-0550-z
   Hussain A., 2012, International Journal of Computer Science Issues, V9, P11
   Idri A, 2013, ASIA PAC SOFWR ENG, P1, DOI 10.1109/APSEC.2013.12
   Imtinan U, 2013, QSCIENCE P, V2013, P19, DOI [10.5339/qproc.2013.mlearn.19, DOI 10.5339/QPROC.2013.MLEARN.19]
   Inostroza R., 2014, MAPPING USABILITY HE, P1
   Inostroza R, 2012, USABILITY HEURISTICS
   Inostroza R, 2016, COMPUT STAND INTER, V43, P40, DOI 10.1016/j.csi.2015.08.007
   Iqbal MW, 2017, PROCEDIA COMPUT SCI, V112, P2185, DOI 10.1016/j.procs.2017.08.258
   Ismailova R, 2017, UNIVERSAL ACCESS INF, V16, P1017, DOI 10.1007/s10209-016-0481-0
   ISO, 9241112018EN ISO
   Kascak LR, 1999, INTEGRATING UNIVERSA
   Khan AA, 2017, INFORM SOFTWARE TECH, V87, P180, DOI 10.1016/j.infsof.2017.03.006
   Khan S, 2013, 2013 INTERNATIONAL CONFERENCE ON OPEN SOURCE SYSTEMS AND TECHNOLOGIES (ICOSST), P107, DOI 10.1109/ICOSST.2013.6720615
   Kitchenham B, 2009, INFORM SOFTWARE TECH, V51, P7, DOI 10.1016/j.infsof.2008.09.009
   Kumar BA, 2018, J COMPUT EDUC, V5, P1, DOI 10.1007/s40692-017-0093-6
   Kurniawan S, 2005, Research-derived web design guidelines for older people, P129, DOI [10.1145/1090785.1090810, DOI 10.1145/1090785.1090810]
   Lee Y, 2017, UNIVERSAL ACCESS INF
   Lee Y, 2019, UNIVERSAL ACCESS INF, V18, P343, DOI 10.1007/s10209-017-0585-1
   Leporini B, 2012, INTERACTING MOBILE D
   Leuthold S, 2008, INT J HUM-COMPUT ST, V66, P257, DOI 10.1016/j.ijhcs.2007.10.006
   Lienhard K. R., 2017, 13 INT C WIRTSCH ST, P1066
   Lobo D, 2013, INT J INF ELECT ENG, V1, P33
   Looije R, 2008, USABILITY ENG MOBILE, V07, P532
   Masood M, 2015, PROCD SOC BEHV, V197, P1818, DOI 10.1016/j.sbspro.2015.07.241
   Mi N, 2014, UNIVERSAL ACCESS INF, V13, pCP4, DOI 10.1007/s10209-013-0321-4
   Milne Lauren R, 2014, INT TECHN PERS DIS C, P166
   Mkpojiogu EOC, 2016, PROCEEDINGS OF KNOWLEDGE MANAGEMENT INTERNATIONAL CONFERENCE (KMICE) 2016, P263
   Morey SA, 2019, ERGON DES, V27, P4, DOI 10.1177/1064804619840731
   Moumane K, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2171-z
   Nayebi F, 2012, 2012 25TH IEEE CANADIAN CONFERENCE ON ELECTRICAL & COMPUTER ENGINEERING (CCECE)
   Carvalho MCN, 2018, 33RD ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P2022, DOI 10.1145/3167132.3167349
   Nielsen J., 1995, SEVERITY RATINGS USA
   Nilsson EG, 2009, COMPUTER-AIDED DESIGN OF USER INTERFACES VI, P307, DOI 10.1007/978-1-84882-206-1_28
   Nunes F, 2016, UNIVERSAL ACCESS INF, V15, P659, DOI 10.1007/s10209-015-0440-1
   Park K, 2015, ACCESSIBLE MOBILE AP, P31
   Park W, 2011, INT J IND ERGONOM, V41, P536, DOI 10.1016/j.ergon.2011.04.002
   Paz F, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY - NEW GENERATIONS, P549, DOI 10.1109/ITNG.2015.92
   Persson H, 2015, UNIVERSAL ACCESS INF, V14, P505, DOI 10.1007/s10209-014-0358-z
   Petrie H, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P397
   Petrovcic A, 2018, INT J HUM-COMPUT INT, V34, P251, DOI 10.1080/10447318.2017.1345142
   Pribeanu C, 2014, UNIVERSAL ACCESS INF, V13, P339, DOI 10.1007/s10209-013-0315-2
   Punchoojit L, 2017, ADV HUM-COMPUT INTER, V2017, DOI 10.1155/2017/6787504
   Rahmati A, 2012, MOBILEHCI, P179
   Rauch M, 2011, 2011 IEEE INTERNATIONAL PROFESSIONAL COMMUNICATION CONFERENCE (IPCC)
   Reynoldson C, 2014, PAIN MED, V15, P898, DOI 10.1111/pme.12327
   Rusu C, 2011, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER-HUMAN INTERACTIONS (ACHI 2011), P59
   Salman HM, 2018, IEEE ACCESS, V6, P22578, DOI 10.1109/ACCESS.2018.2827358
   Schefer RP, 2019, SUPPORTING DEV SOCIA, P278
   Shitkova M, 2015, WIRTSCH P, P366
   Shneiderman B, 2014, UNIVERSAL USABILITY
   Shneiderman B., 2010, DESIGNING USER INTER
   Siebra C, 2017, P 11 INT C UB INF MA, p6:1
   Silva PA, 2015, P ANN HICSS, P3237, DOI 10.1109/HICSS.2015.390
   Sonderegger A, 2016, APPL ERGON, V52, P291, DOI 10.1016/j.apergo.2015.06.012
   SUGAWARA E, 1983, BUNSEKI KAGAKU, V32, P11
   Sun T, 2018, PEDIATR ANESTH, V28, P897, DOI 10.1111/pan.13471
   Thitichaimongkhol K, 2016, P WORLD C ENG COMP S, VI
   Trewin S., 2006, Proceedings of the 2006 international cross-disciplinary workshop on Web accessibility (W4A): Building the mobile web: rediscovering accessibility?, P109
   Vatavu RD, 2017, INT J HUM-COMPUT INT, V33, P486, DOI 10.1080/10447318.2017.1279827
   Von Eye A., 2014, ANAL RATER AGREEMENT
   Wang YY, 2009, J MECH ROBOT, V1, DOI 10.1115/1.3046131
   WHO, 2001, INT CLASS FUNCT DIS
   Wirtz S, 2009, PROC 9 INT C WORK CO, P2
   Xu XY, 2015, P IEEE, V103, P236, DOI 10.1109/JPROC.2014.2378776
   Zhang D, 2009, CHALLENGES METHODOLO, V7318
NR 92
TC 2
Z9 2
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9177
EP 9207
DI 10.1007/s11042-020-10099-x
EA NOV 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587972400002
DA 2024-07-18
ER

PT J
AU Soni, N
   Saini, I
   Singh, B
AF Soni, Neetika
   Saini, Indu
   Singh, Butta
TI An integer wavelet transform and pixel value differencing based feature
   specific hybrid technique for 2D ECG steganography with high payload
   capacity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ECG steganography; Chaotic map; Integer wavelet transform; Pixel
   inverted pixel value differencing; Key space; Key sensitivity
ID IMAGE STEGANOGRAPHY; INFORMATION; SCHEME; TIME; ALGORITHM; STANDARD; MAP
AB Electrocardiogram (ECG) is essentially a significant physiological signal required in the diagnosis of cardiac disorders. For remote healthcare assistance, ECG signal along with patient's meta-data is communicated over the public network. During communication, security and privacy of patient's sensitive information is a major issue. Presently, a common steganography technique is being applied on the entire ECG signal. Since ECG signal consists of clinically more significant QRS regions as well as less significant non-QRS regions and employing same steganography approach on both the regions is not admissible. In this work, a hybrid approach is proposed for concealing the sensitive information in 2-dimensional (2D) ECG. A fusion of integer wavelet transform and modified least significant bit (IWT-mLSB) approach is applied in the pivotal QRS complex region; while pixel inverted pixel value differencing (PI-PVD) technique is implemented in the non-QRS region to hide the confidential data. The performance of the proposed algorithm is evaluated on standard as well as self-recorded database in terms of statistical parameters, clinically critical metrics, heart rate variability (HRV) analysis, embedding capacity (EC) and bit error rate (BER). The security of the proposed algorithm is further evaluated in terms of key space and key sensitivity. A comparative analysis with other state-of-the-art techniques exhibits the competency of the proposed technique.
C1 [Soni, Neetika; Saini, Indu] Dr BR Ambedkar Natl Inst Technol, Dept Elect & Commun Engn, Jalandhar 144011, Punjab, India.
   [Soni, Neetika; Singh, Butta] Guru Nanak Dev Univ, Dept Elect & Commun Engn, Reg Campus, Jalandhar 144007, Punjab, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar; Guru Nanak Dev University
RP Singh, B (corresponding author), Guru Nanak Dev Univ, Dept Elect & Commun Engn, Reg Campus, Jalandhar 144007, Punjab, India.
EM bsl.khanna@gmail.com
RI Saini, Indu/GNP-7112-2022
OI Singh, Butta/0000-0002-0170-6270
CR Al-Dmour H, 2016, COMPUT METH PROG BIO, V127, P24, DOI 10.1016/j.cmpb.2016.01.011
   Al-Fahoum AS, 2006, IEEE T INF TECHNOL B, V10, P182, DOI 10.1109/TITB.2005.855554
   Algeria-Barrero E, 2008, PERFORM PRE OPERATIV, V7, P13
   Berkaya SK, 2018, BIOMED SIGNAL PROCES, V43, P216, DOI 10.1016/j.bspc.2018.03.003
   Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Chou HH, 2006, IEEE T BIO-MED ENG, V53, P1198, DOI 10.1109/TBME.2005.863961
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   English A, 2015, CONFIDENTIALITY THIR
   Martínez-González RF, 2016, COMPUT ELECTR ENG, V54, P435, DOI 10.1016/j.compeleceng.2015.12.005
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Ibaida A, 2013, IEEE T BIO-MED ENG, V60, P3322, DOI 10.1109/TBME.2013.2264539
   Jero SE, 2016, EXPERT SYST APPL, V49, P123, DOI 10.1016/j.eswa.2015.12.010
   Jero SE, 2015, BIOMED SIGNAL PROCES, V22, P161, DOI 10.1016/j.bspc.2015.07.004
   Jero SE, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0132-z
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Kim KK, 2007, PHYSIOL MEAS, V28, P1485, DOI 10.1088/0967-3334/28/12/003
   Kozat SS, 2009, J MED SYST, V33, P241, DOI 10.1007/s10916-008-9185-1
   Liji CA, 2016, PROC TECH, V24, P1039, DOI 10.1016/j.protcy.2016.05.230
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   Manikandan AS, 2007, BIOMED SIGNAL PROCES, V2, P80, DOI 10.1016/j.bspc.2007.05.001
   Nambakhsh MS, 2011, COMPUT METH PROG BIO, V104, P418, DOI 10.1016/j.cmpb.2010.08.016
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Pandey A, 2019, BIOCYBERN BIOMED ENG, V39, P282, DOI 10.1016/j.bbe.2018.11.012
   Pandey A, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0830-4
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Rajaraman V, 2016, RESONANCE, V21, P11, DOI 10.1007/s12045-016-0292-x
   Reichel J, 2001, IEEE T IMAGE PROCESS, V10, P383, DOI 10.1109/83.908504
   Rubio OJ, 2013, J BIOMED INFORM, V46, P653, DOI 10.1016/j.jbi.2013.05.002
   Saini I, 2013, J ADV RES, V4, P331, DOI 10.1016/j.jare.2012.05.007
   Schamroth Leo, INTRO ELECTROCARDIOL
   Shaffer F, 2017, FRONT PUBLIC HEALTH, V5, DOI 10.3389/fpubh.2017.00258
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Shiu HJ, 2017, COMPUT METH PROG BIO, V151, P159, DOI 10.1016/j.cmpb.2017.08.015
   Singh B, 2012, INT J SYST SCI, V43, P884, DOI 10.1080/00207721.2010.543478
   Slimane ZEH, 2010, DIGIT SIGNAL PROCESS, V20, P1221, DOI 10.1016/j.dsp.2009.10.017
   Soni N, 2019, AUSTRALAS PHYS ENG S, V42, P111, DOI 10.1007/s13246-018-00718-1
   Kieu TD, 2011, EXPERT SYST APPL, V38, P10648, DOI 10.1016/j.eswa.2011.02.122
   Trinder J, 2001, J SLEEP RES, V10, P253, DOI 10.1046/j.1365-2869.2001.00263.x
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Yang CY, 2016, J MED SYST, V40, DOI 10.1007/s10916-015-0426-9
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 44
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8505
EP 8540
DI 10.1007/s11042-020-09856-9
EA NOV 2020
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587038500004
DA 2024-07-18
ER

PT J
AU Kalhor, E
   Bakhtiari, B
AF Kalhor, Elham
   Bakhtiari, Behzad
TI Speaker independent feature selection for speech emotion recognition: A
   multi-task approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; Multi-task feature selection; Speaker
   independent features
ID STRESS RECOGNITION; SPECTRAL FEATURES; POSITIVE EMOTIONS; ALGORITHM; PSO
AB Nowadays, automatic speech emotion recognition has numerous applications. One of the important steps of these systems is the feature selection step. Because it is not known which acoustic features of person's speech are related to speech emotion, much effort has been made to introduce several acoustic features. However, since employing all of these features will lower the learning efficiency of classifiers, it is necessary to select some features. Moreover, when there are several speakers, choosing speaker-independent features is required. For this reason, the present paper attempts to select features which are not only related to the emotion of speech, but are also speaker-independent. For this purpose, the current study proposes a multi-task approach which selects the proper speaker-independent features for each pair of classes. The selected features are then given to the classifier. Finally, the outputs of the classifiers are appropriately combined to achieve an output of a multi-class problem. Simulation results reveal that the proposed approach outperforms other methods and offers higher efficiency in terms of detection accuracy and runtime.
C1 [Kalhor, Elham; Bakhtiari, Behzad] Sadjad Univ Technol, Dept Comp Engn, 64 Jalal Al Ahmad St, Mashhad 9188148848, Razavi Khorasan, Iran.
RP Bakhtiari, B (corresponding author), Sadjad Univ Technol, Dept Comp Engn, 64 Jalal Al Ahmad St, Mashhad 9188148848, Razavi Khorasan, Iran.
EM e.kalhor333@sadjad.ac.ir; bakhtiari@sadjad.ac.ir
CR [Anonymous], 2013, INT J ADV ROBOT SYST, DOI DOI 10.5772/55403
   Argyriou A., 2007, NIPS, P41
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Burkhardt F, 2005, P 9 EUR C SPEECH COM, P1516
   Charoendee M, 2017, COMP SCI SOFTW ENG J, P1
   Chen L., 2017, IEEE T INTELL TRANSP, V99, P1
   Dang T, 2016, INTERSPEECH, P913, DOI 10.21437/Interspeech.2016-880
   Demircan S, 2018, NEURAL COMPUT APPL, V29, P59, DOI 10.1007/s00521-016-2712-y
   Dibeklioglu H, 2018, IEEE J BIOMED HEALTH, V22, P525, DOI 10.1109/JBHI.2017.2676878
   Escalera S, 2010, IEEE T PATTERN ANAL, V32, P120, DOI 10.1109/TPAMI.2008.266
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Farrús M, 2007, LECT NOTES COMPUT SC, V4642, P819
   Fredrickson BL, 2001, AM PSYCHOL, V56, P218, DOI 10.1037/0003-066X.56.3.218
   Fu JM, 2019, MULTIMEDIA SYST, V25, P451, DOI 10.1007/s00530-017-0547-8
   Fürnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605
   Gajsek Rok, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4133, DOI 10.1109/ICPR.2010.1005
   Gao L., 2014, P 3 RENEWABLE POWER, P1
   Kaya Heysem, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3729, DOI 10.1109/ICASSP.2014.6854298
   Kaya H, 2018, NEUROCOMPUTING, V275, P1028, DOI 10.1016/j.neucom.2017.09.049
   Kok BE, 2016, PSYCHOL SCI, V27, P931, DOI 10.1177/0956797616647346
   Kotti Margarita, 2010, 2010 2nd International Workshop on Cognitive Information Processing (CIP 2010), P417, DOI 10.1109/CIP.2010.5604091
   Kotti M, 2012, INT J SPEECH TECHNOL, V15, P131, DOI 10.1007/s10772-012-9127-7
   Liu JT, 2012, PROCEEDINGS OF 2012 INTERNATIONAL CONFERENCE ON CONSTRUCTION & REAL ESTATE MANAGEMENT, VOLS 1 AND 2, P339
   Liu ZT, 2018, NEUROCOMPUTING, V309, P145, DOI 10.1016/j.neucom.2018.05.005
   Liu ZT, 2018, NEUROCOMPUTING, V273, P271, DOI 10.1016/j.neucom.2017.07.050
   Lugger M, 2007, INT CONF ACOUST SPEE, P17
   Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI [DOI 10.1109/ICDEW.2006.145, 10.1109/ICDEW.2006.145]
   Muthusamy H, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120344
   Nesterov Y., 1994, SIAM REV, V36, P682
   Nicolaou MA, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6853852
   Obozinski G, 2006, Technical Report, V2, P2
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Rottenberg J, 2017, ANNU REV CLIN PSYCHO, V13, P241, DOI 10.1146/annurev-clinpsy-032816-045252
   Sarvestani RR, 2017, APPL INTELL, V46, P438, DOI 10.1007/s10489-016-0823-x
   Schuller B, 2010, IEEE T AFFECT COMPUT, V1, P119, DOI 10.1109/T-AFFC.2010.8
   Shi CJA, 2015, IEEE T MULTIMEDIA, V17, P16, DOI 10.1109/TMM.2014.2375792
   Shirani Amirreza, 2016, International Journal of Image, Graphics and Signal Processing, V8, P40, DOI 10.5815/ijigsp.2016.04.05
   Song XN, 2016, MULTIMEDIA SYST, V22, P41, DOI 10.1007/s00530-014-0390-0
   Tang J., 2012, P 18 ACM SIGKDD INT, P904, DOI DOI 10.1145/2339530.2339673
   Xie ZB, 2013, INT J SEMANT COMPUT, V7, P25, DOI 10.1142/S1793351X13400023
   Xu XZ, 2016, AUTOMATIKA, V57, P37, DOI 10.7305/automatika.2016.07.853
   Yang B, 2010, SIGNAL PROCESS, V90, P1415, DOI 10.1016/j.sigpro.2009.09.009
   Yang N, 2017, INT J SPEECH TECHNOL, V20, P27, DOI 10.1007/s10772-016-9364-2
   Yang X, 2018, SOC COGN AFFECT NEUR, V13, P256, DOI 10.1093/scan/nsy012
   Yeh YC, 2015, COMPUT EDUC, V81, P143, DOI 10.1016/j.compedu.2014.09.011
   Yogesh CK, 2017, COMPUT ELECTR ENG, V62, P676, DOI 10.1016/j.compeleceng.2017.01.024
   Yogesh CK, 2017, APPL SOFT COMPUT, V56, P217, DOI 10.1016/j.asoc.2017.03.013
   Yogesh CK, 2017, EXPERT SYST APPL, V69, P149, DOI 10.1016/j.eswa.2016.10.035
   Yun Jin, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4808, DOI 10.1109/ICASSP.2014.6854515
   Zhang BQ, 2019, IEEE T AFFECT COMPUT, V10, P85, DOI 10.1109/TAFFC.2017.2684799
   Zhang BQ, 2016, INT CONF ACOUST SPEE, P5805, DOI 10.1109/ICASSP.2016.7472790
   Zhao YH, 2011, J MICROMECH MICROENG, V21, DOI 10.1088/0960-1317/21/5/054017
   Zou DY, 2015, ACSR ADV COMPUT, V13, P1508
NR 53
TC 9
Z9 9
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8127
EP 8146
DI 10.1007/s11042-020-10119-w
EA OCT 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000583128600011
DA 2024-07-18
ER

PT J
AU Panwar, P
   Dhall, S
   Gupta, S
AF Panwar, Priya
   Dhall, Sangeeta
   Gupta, Shailender
TI A multilevel secure information communication model for healthcare
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptography; Encryption; Geometric attacks; Improved BPCS; Performance
   metrics; Quantum chaos; RSA; Steganography
ID IMAGE ENCRYPTION SCHEME; STEGANOGRAPHY; VISIBILITY; INTERNET; PATIENT
AB The emerging demand for sharing medical digital images amid specialists and hospitals for enhanced and precise analysis necessitates protecting patients' privacy. The communication of such information over available channels is very much susceptible to numerous security threats. The contemporary defence level is not strong enough for maintaining the protection and integrity of information in a required field like the human healthcare sector. There is a stern need for a robust safety mechanism. In this paper, a model is created by harmonizing various cryptography and steganography techniques to secure secret diagnostic information. This proposal provides multi-level security by utilizing a blend of Rivest, Shamir, and Adleman (RSA) and Quantum Chaos (QC) for Encryption mechanism as the first level and the Improved BPCS (IBPCS) steganography as the next step to conceal the resultant cipher in a cover image. Both image formats, Grayscale, and colored are employed as the cover images to hide various volumes of the confidential data. The proposed framework is implemented in MATLAB and assessed using different performance metrics like mean square error (MSE), Peak Signal to noise ratio (PSNR), bit error rate (BER), structural component (SC), structural similarity (SSIM), and so forth that are referenced in writing. Appraisal and comparison with state-of-art methods are also made after applying the different attacks (geometric, Gaussian, salt and pepper, flipping, etc.) on the stego image. Result analysis illustrates that the proposed model reveals its capacity to conceal the confidential patient's information into a transmitted cover image with high imperceptibility and robustness in the presence and absence of attacks.
C1 [Panwar, Priya; Dhall, Sangeeta; Gupta, Shailender] JC Bose Univ Sci & Technol, YMCA, Faridabad, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Dhall, S (corresponding author), JC Bose Univ Sci & Technol, YMCA, Faridabad, India.
EM sangeeta_dhall@yahoo.co.in
RI gupta, shailender/Y-8231-2019
OI gupta, shailender/0000-0003-1383-7152
CR Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Abdel-Nabi H, 2017, INT CONF INFORM COMM, P147, DOI 10.1109/IACS.2017.7921962
   Abdelaziz A, 2018, MEASUREMENT, V119, P117, DOI 10.1016/j.measurement.2018.01.022
   Alkhraisat Habes, 2006, [Информационные процессы, Informatsionnye protsessy], V6, P1
   [Anonymous], 2010, 2010 2 INT C COMPUTI
   [Anonymous], 2012, INT J COMPUTER APPL
   [Anonymous], 2017, 2017 INT C CIRC POW
   [Anonymous], 2014, INT J COMPUTER ELECT
   [Anonymous], 2011, MULTIDISCIPLINARY IN
   [Anonymous], 2012, INT J COMPUTERS APPL
   [Anonymous], 2012, INT J COMPUTER SCI I
   [Anonymous], 2013, GLOBAL J COMP SCI TE
   [Anonymous], 2012, INT J ENG TRENDS TEC
   [Anonymous], 2013, INT J EMERG TECHNOL
   [Anonymous], 2014, 2014 INT C INFORMATI
   Anwar A.S., 2015, INT J BIOMED INFORM, V3, P7
   Bairagi AK, 2016, INF SECUR J, V25, P197, DOI 10.1080/19393555.2016.1206640
   Bansal R, 2018, MULTIMED TOOLS APPL, V77, P6799, DOI 10.1007/s11042-017-4600-6
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Bansal R, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P933
   Chatterjee A, 2020, MULTIMED TOOLS APPL, V79, P11747, DOI 10.1007/s11042-019-08472-6
   Chaudhary Divya, 2016, International Journal of Information Privacy, Security and Integrity, V2, P216
   Darwish A, 2019, J AMB INTEL HUM COMP, V10, P4151, DOI 10.1007/s12652-017-0659-1
   Dhall S, 2020, MULTIMED TOOLS APPL, V79, P1987, DOI 10.1007/s11042-019-08223-7
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Gupta S., 2012, Int. J. Mod. Educ. Comput. Sci., V4, P27
   Hanchinamani G, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0062-7
   Jain M, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P291, DOI 10.1109/IC3I.2016.7917977
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Joseph A, 2015, INT J COMPUT APPL, V2, P626
   Kawaguchi E, 1999, P SOC PHOTO-OPT INS, V3528, P464, DOI 10.1117/12.337436
   Khalil M. I., 2017, International Journal of Computer Network and Information Security, V9, P22, DOI 10.5815/ijcnis.2017.02.03
   Kumar P, 2012, SENSORS-BASEL, V12, P55, DOI 10.3390/s120100055
   Laskar S. A., 2012, International Journal of Database Management Systems (IJDMS), V4, P57
   Li LG, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/3295769
   Liu AD, 2012, IEEE DECIS CONTR P, P763, DOI 10.1109/CDC.2012.6426635
   Mandal A. K., 2012, 2012 IEEE Students' Conference on Electrical, Electronics and Computer Science (SCEECS 2012), DOI 10.1109/SCEECS.2012.6184991
   Mare S. F., 2011, Proceedings 2011 IEEE 17th International Symposium for Design and Technology in Electronic Packaging (SIITME 2011), P339, DOI 10.1109/SIITME.2011.6102748
   Masud Karim S. M., 2011, 2011 14th International Conference on Computer and Information Technology (ICCIT), P286, DOI 10.1109/ICCITechn.2011.6164800
   McEvoy FJ, 2009, J DIGIT IMAGING, V22, P65, DOI 10.1007/s10278-007-9068-x
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Parah SA, 2018, STUD BIG DATA, V30, P409, DOI 10.1007/978-3-319-60435-0_17
   Paschou M, 2013, SIMUL MODEL PRACT TH, V34, P186, DOI 10.1016/j.simpat.2012.08.002
   PRIYA S, 2019, MOB NETW APPL
   Rabbani H, 2015, INVEST OPHTH VIS SCI, V56, P1482, DOI 10.1167/iovs.14-15457
   Razzaq MA, 2017, INT J ADV COMPUT SC, V8, P224
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Sajasi S, 2015, APPL SOFT COMPUT, V30, P375, DOI 10.1016/j.asoc.2015.01.032
   Sajjad M, 2017, MULTIMED TOOLS APPL, V76, P3519, DOI 10.1007/s11042-016-3811-6
   Seyyedi Seyyed Amin, 2016, International Journal of Network Security, V18, P124
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Silva EA, 2007, PROC SPIE, V6579, DOI 10.1117/12.720087
   Tayal N., 2016, INT J COMPUTER NETWO, V3, P13
   varnan C.Sasi., 2011, IJCST, V2
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Y, 2011, NPCR and UACI randomness tests for image encryption
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yehia L., 2015, ADV INTERNET THINGS, V5, P21, DOI [10.4236/ait.2015.53004, DOI 10.4236/AIT.2015.53004]
   Yin JHJ, 2015, I C ARTIF INTELL, P310, DOI 10.1109/AIMS.2015.56
   Zaw Z.M., 2015, INT J COMPUTER IJC, V19, P26
NR 61
TC 5
Z9 5
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 8039
EP 8062
DI 10.1007/s11042-020-10083-5
EA OCT 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000583128600009
DA 2024-07-18
ER

PT J
AU Bera, SK
   Ghosh, S
   Bhowmik, S
   Sarkar, R
   Nasipuri, M
AF Bera, Suman Kumar
   Ghosh, Soulib
   Bhowmik, Showmik
   Sarkar, Ram
   Nasipuri, Mita
TI A non-parametric binarization method based on ensemble of clustering
   algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binarization; Document image; Clustering; Ensemble; DB index; DIBCO
ID OPTICAL CHARACTER-RECOGNITION; DOCUMENT; ENHANCEMENT
AB Binarization of document images still attracts the researchers especially when degraded document images are considered. This is evident from the recent Document Image Binarization Competition (DIBCO 2019) where we can see researchers from all over the world participated in this competition. In this paper, we present a novel binarization technique which is found to be capable of handling almost all types of degradations without any parameter tuning. Present method is based on an ensemble of three classical clustering algorithms (Fuzzy C-means, K-medoids and K-means++) to group the pixels as foreground or background, after application of a coherent image normalization method. It has been tested on four publicly available datasets, used in DIBCO series, 2016, 2017, 2018 and 2019. Present method gives promising results for the aforementioned datasets. In addition, this method is the winner of DIBCO 2019 competition.
C1 [Bera, Suman Kumar; Ghosh, Soulib; Sarkar, Ram; Nasipuri, Mita] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Bhowmik, Showmik] Ghani Khan Choudhury Inst Engn & Technol GKCIET, Dept Comp Sci & Engn, Malda, India.
C3 Jadavpur University
RP Bera, SK (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
EM berasuman007@gmail.com; ghoshsoulib@gmail.com; showmik@gkciet.ac.in;
   ramjucse@gmail.com; mitanasipuri@gmail.com
RI Bhowmik, Showmik/M-4248-2017; Sarkar, Ram/AAX-3822-2020
OI Sarkar, Ram/0000-0001-8813-4086; Bera, Suman Kumar/0000-0001-6968-2079
CR Ahmadi E, 2015, PATTERN RECOGN LETT, V63, P36, DOI 10.1016/j.patrec.2015.06.008
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Ayyalasomayajula KR, 2019, PATTERN RECOGN LETT, V121, P52, DOI 10.1016/j.patrec.2018.05.011
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Bataineh B, 2011, PATTERN RECOGN LETT, V32, P1805, DOI 10.1016/j.patrec.2011.08.001
   Ben Messaoud I, 2011, PROC INT CONF DOC, P1205, DOI 10.1109/ICDAR.2011.243
   Bera SK, 2019, PATTERN RECOGN LETT, V128, P488, DOI 10.1016/j.patrec.2019.10.025
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bhowmik S, 2019, IEEE T IMAGE PROCESS, V28, P1443, DOI 10.1109/TIP.2018.2878959
   Bhowmik S, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS, P257, DOI 10.1109/CICN.2014.66
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Gatos B, 2006, PATTERN RECOGN, V39, P317, DOI 10.1016/j.patcog.2005.09.010
   Guo JB, 2019, APPL MATH COMPUT, V351, P8, DOI 10.1016/j.amc.2019.01.021
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   He S, 2019, PATTERN RECOGN, V91, P379, DOI 10.1016/j.patcog.2019.01.025
   Jana P, 2017, 2017 NINTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P332
   Jana P, 2017, 2017 IEEE CALCUTTA CONFERENCE (CALCON), P226, DOI 10.1109/CALCON.2017.8280729
   Kavallieratou E, 2001, PATTERN RECOGN, V34, P2515, DOI 10.1016/S0031-3203(00)00153-9
   Khurshid Khurram, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7247, DOI 10.1117/12.805827
   KITTLER J, 1985, IEEE T SYST MAN CYB, V15, P652, DOI 10.1109/TSMC.1985.6313443
   Kundu S, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112916
   Lazzara G, 2014, INT J DOC ANAL RECOG, V17, P105, DOI 10.1007/s10032-013-0209-0
   Lelore T, 2013, IEEE T PATTERN ANAL, V35, P2039, DOI 10.1109/TPAMI.2013.63
   Lu D, 2018, INT J DOC ANAL RECOG, V21, P123, DOI 10.1007/s10032-018-0299-9
   Lu HP, 2004, IEEE SIGNAL PROC LET, V11, P228, DOI 10.1109/LSP.2003.821748
   Lu SJ, 2010, INT J DOC ANAL RECOG, V13, P303, DOI 10.1007/s10032-010-0130-8
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Malakar, 2019, COMMUN COMPUT INF SC, V1020, P27, DOI DOI 10.1007/978-981-13-9361-7_3
   Moghaddam RF, 2012, PATTERN RECOGN, V45, P2419, DOI 10.1016/j.patcog.2011.12.013
   Ng R.T., 1994, Proceedings of the 20th International Conference on Very Large Data Bases, VLDB '94, P144
   Niblack W., 1986, INTRO DIGITAL IMAGE, P115
   Ntirogiannis K, 2014, PATTERN RECOGN LETT, V35, P3, DOI 10.1016/j.patrec.2012.09.026
   Olszewska JI, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART), VOL 2, P850, DOI 10.5220/0007585208500856
   Olszewska JI, 2015, NEUROCOMPUTING, V161, P65, DOI 10.1016/j.neucom.2014.12.089
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pai YT, 2010, PATTERN RECOGN, V43, P3177, DOI 10.1016/j.patcog.2010.03.014
   Pratikakis I, 2019, 2019 15 IAPR INT C D
   Pratikakis I, 2018, INT CONF FRONT HAND, P489, DOI 10.1109/ICFHR-2018.2018.00091
   Pratikakis I, 2017, PROC INT CONF DOC, P1395, DOI 10.1109/ICDAR.2017.228
   Pratikakis I, 2016, INT CONF FRONT HAND, P619, DOI [10.1109/ICFHR.2016.110, 10.1109/ICFHR.2016.0118]
   Ramírez-Ortegón MA, 2010, PATTERN RECOGN, V43, P1233, DOI 10.1016/j.patcog.2009.11.006
   Rani U., 2020, COGNITIVE COMPUTING, P83
   Sahlol AT, 2020, IEEE ACCESS, V8, P23011, DOI 10.1109/ACCESS.2020.2970438
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Su Bolan, 2010, P INT WORKSH DOC AN, P159
   Tensmeyer C, 2017, PROC INT CONF DOC, P99, DOI 10.1109/ICDAR.2017.25
   TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511
   Xiankai Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8957, DOI 10.1109/CVPR42600.2020.00898
   Zahoor S, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.2.023002
   Zhang L, 2009, PATTERN RECOGN, V42, P2961, DOI 10.1016/j.patcog.2009.03.025
   Zhao JY, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106968
NR 53
TC 18
Z9 18
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7653
EP 7673
DI 10.1007/s11042-020-09836-z
EA OCT 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000009
DA 2024-07-18
ER

PT J
AU Zhang, M
   Li, CY
   Zhou, ZP
AF Zhang, Min
   Li, Chunye
   Zhou, Zhiping
TI Text to image synthesis using multi-generator text conditioned
   generative adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text to image; Generative adversarial networks; Mode collapse; Text
   description; Multiple generators
AB Recently, Generative Adversarial Network(GAN) has been the most mainstream technology in the task of Text to Image. However, the vanilla deep neural networks tend to approximate continuous mappings in real generation tasks rather than discontinuous mappings with discrete points. When training on datasets with multiple types, GAN fails to synthesize diverse images, which we call as mode collapse. To deal with it, we propose the Multi-generator Text Conditioned Generative Adversarial Network (MTC-GAN) in this paper. Textual description of real images is embedded on the noise vector as a constraint. Based on Deep Convolutional Generative Adversarial Networks(DCGAN), multiple generators are incorporated to capture high probability among the target distribution. To identify the generated fake sample from a particular generator, the discriminator must enforce multiple generators to have different identifiable modes. The method based on global constraints can make the generated images more diverse. Multiple generators can improve the particular functional shape of the discriminators indirectly, which should make the GAN more stable when trained in high dimensional spaces. The experimental results on the standard dataset demonstrate the good performance of the proposed method. The problem of mode collapse can be improved, and the generated samples can be more diverse.
C1 [Zhang, Min; Li, Chunye; Zhou, Zhiping] Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Jiangsu, Peoples R China.
   [Zhou, Zhiping] Jiangnan Univ, Minist Educ, Engn Res Ctr Internet Things Technol Applicat, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University; Jiangnan University
RP Zhou, ZP (corresponding author), Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Jiangsu, Peoples R China.; Zhou, ZP (corresponding author), Jiangnan Univ, Minist Educ, Engn Res Ctr Internet Things Technol Applicat, Wuxi 214122, Jiangsu, Peoples R China.
EM zzp@jiangnan.edu.cn
RI zhang, min/IYI-9869-2023
CR [Anonymous], 2017, arXiv preprint arXiv:1703.06412
   [Anonymous], 2018, ABS180500676
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bang D., 2018, ARXIV PREPRINT ARXIV
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Che Tong, 2016, CoRR
   Chidambaram M., 2017, ARXIV170206762
   Ghosh A, 2018, PROC CVPR IEEE, P8513, DOI 10.1109/CVPR.2018.00888
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo HF, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S021800141859005X
   Hensel M, 2017, ADV NEUR IN, V30
   Li Jiwei, 2017, P 2017 C EMP METH NA, P2157, DOI DOI 10.18653/V1/D17-1230
   Lin ZA, 2018, ADV NEUR IN, V31
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Mansimov Elman, 2015, ARXIV151102793
   Metz Luke, 2016, ARXIV161102163
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Moradshahi M, 2018, LANGUAGE MODELING GE
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Odena A, 2017, PR MACH LEARN RES, V70
   Reed S. E., 2016, ADV NEURAL INFORM PR, V29, P217
   Reed S, 2016, PR MACH LEARN RES, V48
   Salimans T, 2016, ADV NEUR IN, V29
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Srivastava A, 2017, ADV NEUR IN, V30
   Thanh-Tung H., 2018, ARXIV180704015
   van den Oord A, 2016, ADV NEUR IN, V29
   Welinder P, CALTECH UCSD BIRDS 2, p2,5
   Xiang S., 2017, EFFECTS BATCH WEIGHT
   Xu C, 2019, MULTIMEDIA SYSTEMS
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
NR 32
TC 9
Z9 9
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7789
EP 7803
DI 10.1007/s11042-020-09965-5
EA OCT 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000002
DA 2024-07-18
ER

PT J
AU Mittal, H
   Tripathi, A
   Pandey, AC
   Pal, R
AF Mittal, Himanshu
   Tripathi, Ashish
   Pandey, Avinash Chandra
   Pal, Raju
TI Gravitational search algorithm: a comprehensive analysis of recent
   variants
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optimization algorithm; Nature-inspired algorithm; Gravitational search
   algorithm
ID DIFFERENTIAL EVOLUTION; OPTIMIZATION
AB Gravitational search algorithm is a nature-inspired algorithm based on the mathematical modelling of the Newton's law of gravity and motion. In a decade, researchers have presented many variants of gravitational search algorithm by modifying its parameters to efficiently solve complex optimization problems. This paper conducts a comparative analysis among ten variants of gravitational search algorithm which modify three parameters, namely Kbest, velocity, and position. Experiments are conducted on two sets of benchmark categories, namely standard functions and CEC2015 functions, including problems belonging to different categories such as unimodal, multimodal, and unconstrained optimization functions. The performance comparison is evaluated and statistically validated in terms of mean fitness value and convergence graph. In experiments, IGSA has achieved better precision with balanced trade-off between exploration and exploitation. Moreover, triple negative breast cancer dataset has been considered to analysis the performance of GSA variants for the nuclei segmentation. The variants performance has been analysed in terms of both qualitative and quantitive with aggregated Jaccard index as performance measure. Experiments affirm that IGSA-based method has outperformed other methods.
C1 [Mittal, Himanshu; Pandey, Avinash Chandra; Pal, Raju] Jaypee Inst Informat Technol, Noida, India.
   [Tripathi, Ashish] Malaviya Natl Inst Technol, Jaipur, Rajasthan, India.
C3 Jaypee Institute of Information Technology (JIIT); National Institute of
   Technology (NIT System); Malaviya National Institute of Technology
   Jaipur
RP Tripathi, A (corresponding author), Malaviya Natl Inst Technol, Jaipur, Rajasthan, India.
EM mail2ashish07@gmail.com
RI Tripathi, Ashish Kumar/CAG-2021-2022; Pal, Raju/AAC-2589-2020
OI Pal, Raju/0000-0001-5715-5204; Kumar Tripathi,
   Ashish/0000-0003-1218-0515; Mittal, Himanshu/0000-0003-4127-7092
CR Bansal JC, 2018, APPL INTELL, V48, P3446, DOI 10.1007/s10489-018-1148-8
   Brest J, 2013, 2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P377
   Chatterjee A, 2012, INT J BIO-INSPIR COM, V4, P33, DOI 10.1504/IJBIC.2012.044934
   Davarynejad Mohsen, 2012, Simulated Evolution and Learning. 9th International Conference, SEAL 2012. Proceedings, P62, DOI 10.1007/978-3-642-34859-4_7
   Dhal KG, 2019, ARCH COMPUT METHOD E, V26, P1607, DOI 10.1007/s11831-018-9289-9
   Dixit M., 2015, INT J SOFTWARE ENG I, V9, P91
   Dorigo M, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.329691
   Feng Y, 2007, P IEEE INT C INN COM, P475
   Gagrani M, 2018, IEEE DECIS CONTR P, P1053, DOI 10.1109/CDC.2018.8619423
   Giladi C, 2020, INFORM SCIENCES, V517, P18, DOI 10.1016/j.ins.2019.12.047
   Guha R, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106341
   Gupta V, 2018, SMART COMPUTING INFO, P245, DOI DOI 10.1007/978-981-10-5547-826
   Han XH, 2012, INFORM SCIENCES, V208, P14, DOI 10.1016/j.ins.2012.04.039
   Ibrahim RA, 2019, J AMB INTEL HUM COMP, V10, P3155, DOI 10.1007/s12652-018-1031-9
   Jadon SS, 2018, INT J SYST ASSUR ENG, V9, P589, DOI 10.1007/s13198-014-0286-6
   Jiang JH, 2020, EXPERT SYST APPL, V144, DOI 10.1016/j.eswa.2019.113118
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khajehzadeh M, 2012, ENG APPL ARTIF INTEL, V25, P1589, DOI 10.1016/j.engappai.2012.01.011
   Lei ZY, 2020, EXPERT SYST APPL, V152, DOI 10.1016/j.eswa.2020.113396
   Li CS, 2014, NEUROCOMPUTING, V124, P139, DOI 10.1016/j.neucom.2013.07.018
   Li P, 2012, SCI CHINA TECHNOL SC, V55, P2712, DOI 10.1007/s11431-012-4890-x
   Liu HW, 2018, NEURAL COMPUT APPL, V29, P1, DOI 10.1007/s00521-017-3243-x
   Luo J, 2018, APPL MATH MODEL, V64, P654, DOI 10.1016/j.apm.2018.07.044
   Mirjalili S., 2010, Proceedings of the 2010 International Conference on Computer and Information Application (ICCIA 2010), P374, DOI 10.1109/ICCIA.2010.6141614
   Mirjalili S, 2014, NEURAL COMPUT APPL, V25, P1569, DOI 10.1007/s00521-014-1640-y
   Mittal H, 2021, EVOL INTELL, V14, P1293, DOI 10.1007/s12065-018-0192-y
   Mittal H, 2018, INT CONF CONTEMP, P190
   Mittal H, 2020, LECT NOTES COMPUT SC, V11969, P429, DOI 10.1007/978-3-030-36987-3_29
   Mittal H, 2019, ADV INTELL SYST, V817, P231, DOI 10.1007/978-981-13-1595-4_18
   Mittal H, 2019, SWARM EVOL COMPUT, V45, P15, DOI 10.1016/j.swevo.2018.12.005
   Mittal H, 2018, ENG APPL ARTIF INTEL, V71, P226, DOI 10.1016/j.engappai.2018.03.001
   Mukherjee M, 2019, LEADERSH SCH CHANGE, P173
   Nagaraju S, 2019, ADV INTELL SYST, V758, P525, DOI 10.1007/978-981-13-0514-6_51
   Nanda SJ, 2014, SWARM EVOL COMPUT, V16, P1, DOI 10.1016/j.swevo.2013.11.003
   Nayyar A., 2018, Advances in swarm intelligence for optimizing problems in computer science, P1, DOI DOI 10.1201/9780429445927
   Nayyar Anand., 2018, Advances in swarm intelligence for optimizing problems in computer science, P53
   Niknam T, 2012, ENERGY, V43, P427, DOI 10.1016/j.energy.2012.03.064
   Olivas F, 2019, INFORM SCIENCES, V476, P159, DOI 10.1016/j.ins.2018.10.025
   Pal R, 2019, APPL INTELL, V49, P3406, DOI 10.1007/s10489-019-01460-1
   Pal R, 2016, INT CONF CONTEMP, P61, DOI 10.1109/IC3.2016.7880201
   Pelusi D, 2020, KNOWL-BASED SYST, V193, DOI 10.1016/j.knosys.2019.105404
   Rashedi E, 2018, SWARM EVOL COMPUT, V41, P141, DOI 10.1016/j.swevo.2018.02.018
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Rawal P, 2020, ALGO INTELL SY, P1, DOI 10.1007/978-981-15-0426-6_1
   Sabri N.M., 2013, International Journal of Advances in Soft Computing and Its Applications, V5, P1
   Sarafrazi S, 2011, SCI IRAN, V18, P539, DOI 10.1016/j.scient.2011.04.003
   Sharma A, 2016, SWARM EVOL COMPUT, V28, P58, DOI 10.1016/j.swevo.2016.01.002
   Shaw B, 2012, INT J ELEC POWER, V35, P21, DOI 10.1016/j.ijepes.2011.08.012
   Simon D, 2008, IEEE T EVOLUT COMPUT, V12, P702, DOI 10.1109/TEVC.2008.919004
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Tan ZP, 2020, J AMB INTEL HUM COMP, V11, P4983, DOI 10.1007/s12652-020-01777-7
   Thakur AS, 2021, J SUPERCOMPUT, V77, P796, DOI 10.1007/s11227-020-03292-0
   Tsai HC, 2013, APPL MATH COMPUT, V219, P9106, DOI 10.1016/j.amc.2013.03.098
   Wang MW, 2018, NEUROCOMPUTING, V273, P57, DOI 10.1016/j.neucom.2017.07.059
   Wang YR, 2019, SWARM EVOL COMPUT, V46, P118, DOI 10.1016/j.swevo.2019.02.004
   WHITLEY D, 1994, STAT COMPUT, V4, P65, DOI 10.1007/BF00175354
   Wu ZQ, 2018, APPL SOFT COMPUT, V62, P101, DOI 10.1016/j.asoc.2017.10.039
   Yin BY, 2018, COMPUT ELECTR ENG, V66, P505, DOI 10.1016/j.compeleceng.2017.06.001
NR 58
TC 55
Z9 56
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7581
EP 7608
DI 10.1007/s11042-020-09831-4
EA OCT 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584947400004
DA 2024-07-18
ER

PT J
AU Liu, L
   Wang, LF
   Chang, CC
AF Liu, Li
   Wang, Lifang
   Chang, Chin-Chen
TI Separable reversible data hiding in encrypted images based on flexible
   preservation of the differences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Separable; Encryption; Difference
ID PRIVACY
AB To better protect the security of users' private data in the cloud environment, the technology for separable reversible data hiding in encrypted images has been attracting increasing attention from researchers. In this paper, we propose a separable reversible data hiding scheme in encrypted images based on the flexible preservation of differences. This scheme has three parts: 1) For the content owner, the original image is divided into non-overlapping blocks, for which block-mean is computed. Then the differences between the values of every pixel and the block-mean are obtained and an initial label map is generated. Because most of the differences tend to concentrate around 0, we use two bits to dynamically record the range of the differences to vacate space for hiding. Further, introducing the block-mean differences also serves to vacate more space, for which the label map is amended accordingly. Finally, the image with free space is encrypted into the encrypted image using an encryption key. 2) For the data hider, the secret bits are embedded into the encrypted image by directly replacing the spare bits without obtaining any information of the original image. 3) For the receiver, he/she can achieve the desired information according to the key in his/her possession. Experimental results show that our proposed scheme is able to achieve an average embedding capacity as large as 1.785 bpp and 1.709 bpp when block size is set to 2 x 2 and 2 x 4, respectively. Comparison with those of previous schemes, the proposed scheme has excellent embedding capacity, especially for smoother images.
C1 [Liu, Li] Taiyuan Univ Sci & Technol, Coll Elect Informat & Engn, Taiyuan 030024, Peoples R China.
   [Liu, Li; Wang, Lifang] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
   [Chang, Chin-Chen] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Taiyuan University of Science & Technology; Northwestern Polytechnical
   University; Feng Chia University; Hangzhou Dianzi University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.; Chang, CC (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Zhejiang, Peoples R China.
EM alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
FU National Natural Science Foundation of China [61540009]; Shanxi Province
   Natural Science Foundation [201801D121129]; Shanxi Scholarship Council
   of China
FX This work was supported in part by The National Natural Science
   Foundation of China (No. 61540009), Shanxi Province Natural Science
   Foundation (No. 201801D121129). Research Project Supported by Shanxi
   Scholarship Council of China.
CR Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen D, 2012, PROCEEDINGS OF INTER
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Khelifi F, 2018, SIGNAL PROCESS, V148, P91, DOI 10.1016/j.sigpro.2018.02.016
   Li HY, 2018, PROCEEDINGS OF THE 2018 2ND INTERNATIONAL CONFERENCE ON BIG DATA RESEARCH (ICBDR 2018), P1, DOI 10.1145/3291801.3291805
   Li Q, 2018, MULTIMED TOOLS APPL, V77, P30749, DOI 10.1007/s11042-018-6187-y
   Liu L, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010082
   Liu L, 2016, MULTIMED TOOLS APPL, V75, P11311, DOI 10.1007/s11042-015-2855-3
   Liu ZL, 2018, INFORM SCIENCES, V433, P188, DOI 10.1016/j.ins.2017.12.044
   Lizhi Xiong, 2018, Multidimensional Systems and Signal Processing, V29, P1191, DOI 10.1007/s11045-017-0497-5
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Malik A, 2020, MULTIMED TOOLS APPL, V79, P11591, DOI 10.1007/s11042-019-08460-w
   Nasrullah N, 2019, MULTIMED TOOLS APPL, V78, P17535, DOI 10.1007/s11042-018-7130-y
   Puyang Y, 2018, IEEE INT WORKS INFOR
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Qin C, 2018, INFORM SCIENCES, V465, P285, DOI 10.1016/j.ins.2018.07.021
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HB, 2019, MULTIMED TOOLS APPL, V78, P25349, DOI 10.1007/s11042-019-07769-w
   Wu XT, 2018, SIGNAL PROCESS, V143, P269, DOI 10.1016/j.sigpro.2017.09.017
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yi S, 2018, SIGNAL PROCESS-IMAGE, V64, P78, DOI 10.1016/j.image.2018.03.001
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Zhang W, 2019, J REAL-TIME IMAGE PR, V16, P697, DOI 10.1007/s11554-018-0811-y
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 30
TC 1
Z9 1
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6639
EP 6659
DI 10.1007/s11042-020-09790-w
EA OCT 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000582172700001
DA 2024-07-18
ER

PT J
AU Sengupta, P
   Mollah, AF
AF Sengupta, Payel
   Mollah, Ayatullah Faruk
TI Journey of scene text components recognition: Progress and open issues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene text components; Scene character segmentation; Scene character
   recognition; Datasets of scene components
ID SEGMENTATION; LOCALIZATION; IMAGES
AB In computer vision, scene text component recognition is an important problem in end-to-end scene text reading systems. It involves two major sub-problems - segmentation of such components into scene characters and classification of segmented characters into known character classes. Significant attention and increasingly focused research efforts are being put forth and reasonable progress in this field has already been made, though a diversity of challenges like background complexity, variety of text appearances, noise, blur, distortion and various other degradation and deformation issues are still left to address. In this paper, we present (i) a detail survey of scene component segmentation and/or recognition methods reported so far in literature, (ii) related datasets available for quantitative evaluation and benchmarking segmentation and/or recognition performance, (iii) comparative results and analysis over the reported methods, and (iv) discussion on open areas to be looked into in order to achieve the desired goal of end-to-end scene text recognition. Moreover, this paper provides an acceptable reference for researcher in the area of scene text components segmentation and recognition.
C1 [Sengupta, Payel; Mollah, Ayatullah Faruk] Aliah Univ, Dept Comp Sci & Engn, 2A-27 New Town, Kolkata 700160, India.
C3 Aliah University
RP Mollah, AF (corresponding author), Aliah Univ, Dept Comp Sci & Engn, 2A-27 New Town, Kolkata 700160, India.
EM afmollah@aliah.ac.in
OI Mollah, Ayatullah Faruk/0000-0002-3445-7469; SENGUPTA,
   PAYEL/0000-0003-3981-5971
FU Dept. of MA & ME, Govt. of West Bengal
FX The authors are thankful to the Department of Computer Science and
   Engineering of Aliah University, Kolkata, India for providing every kind
   of support for carrying out this research work. P. Sengupta is grateful
   to Dept. of MA & ME, Govt. of West Bengal for providing Swami
   Vivekananda Merit cum Means Fellowship.
CR Abdali AR, 2019, IEEE ST CONF RES DEV, P152, DOI [10.1109/SCORED.2019.8896354, 10.1109/scored.2019.8896354]
   [Anonymous], 2019, KAIST SCENE TEXT DAT
   [Anonymous], 2019, PROGNOST SYST HEALT
   [Anonymous], 2017, ARXIV17070883
   Bae JH, 1998, PATTERN RECOGN LETT, V19, P701, DOI 10.1016/S0167-8655(98)00048-8
   Bai F, 2018, PROC CVPR IEEE, P1508, DOI 10.1109/CVPR.2018.00163
   Bai X, 2016, IEEE T IMAGE PROCESS, V25, P2789, DOI 10.1109/TIP.2016.2555080
   Bartz C, 2018, AAAI CONF ARTIF INTE, P6674
   Bissacco A, 2013, IEEE I CONF COMP VIS, P785, DOI 10.1109/ICCV.2013.102
   Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792
   Chekol B, 2019, TURK J ELECTR ENG CO, V27, P3804, DOI 10.3906/elk-1806-195
   Chen DT, 2004, PATTERN RECOGN, V37, P595, DOI 10.1016/j.patcog.2003.06.001
   Chen XX, 2020, NEUROCOMPUTING, V381, P261, DOI 10.1016/j.neucom.2019.11.049
   de Campos T. E., 2009, P INT C COMP VIS THE
   Du XC, 2020, INT CONF ACOUST SPEE, P2383, DOI [10.1109/ICASSP40776.2020.9054269, 10.1109/icassp40776.2020.9054269]
   Esmaile MF, 2018, J ENG, V24, P146
   Fabrizio J, 2009, IEEE IMAGE PROC, P2373, DOI 10.1109/ICIP.2009.5413435
   Francis LM, 2019, J SAUD U COMPUT INF, DOI 10.1016/j.jksuci.2019.01.013
   Ghosh SK, 2017, PROC INT CONF DOC, P943, DOI 10.1109/ICDAR.2017.158
   Gómez L, 2017, PATTERN RECOGN, V70, P60, DOI 10.1016/j.patcog.2017.04.027
   Guo Q, 2016, NEUROCOMPUTING, V184, P78, DOI 10.1016/j.neucom.2015.07.135
   Hazim N., 2018, International Journal of Engineering Technology, V7, P3148, DOI DOI 10.14419/IJET.V7I4.18952
   He P, 2016, PHYS COMMUN-AMST, V20, P1, DOI 10.1016/j.phycom.2016.04.003
   Ho CH, 2018, ELECT IMAGING, V2018, P1
   Hong S, 2020, IEEE WINT CONF APPL, P183, DOI [10.1109/WACVW50321.2020.9096928, 10.1109/wacvw50321.2020.9096928]
   Iwamura M., 2018, ARXIV181205219
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg Max, 2014, WORKSH DEEP LEARN NI
   Kang C, 2017, AAAI CONF ARTIF INTE, P4103
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Katper SH, 2020, INT J ADV COMPUT SC, V11, P178
   Lee CY, 2016, PROC CVPR IEEE, P2231, DOI 10.1109/CVPR.2016.245
   Liao MH, 2019, AAAI CONF ARTIF INTE, P8714
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Lin H, 2020, ARCH COMPUT METHOD E, V27, P433, DOI 10.1007/s11831-019-09315-1
   Litman Ron, 2020, CVPR, P11959, DOI 10.1109/CVPR42600.2020.01198
   Liu HY, 2019, IEEE COMPUT SOC CONF, P2457, DOI 10.1109/CVPRW.2019.00301
   Liu W, 2018, P AS C COMP VIS, P196
   Liu XY, 2019, INT J DOC ANAL RECOG, V22, P143, DOI 10.1007/s10032-019-00320-5
   Liu ZC, 2018, AAAI CONF ARTIF INTE, P7194
   Long SB, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01369-0
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Lue HT, 2010, ETRI J, V32, P729, DOI 10.4218/etrij.10.1510.0086
   Luo CJ, 2019, PATTERN RECOGN, V90, P109, DOI 10.1016/j.patcog.2019.01.020
   Mancas-Thillou C, 2006, INT C PATT RECOG, P901
   Mishra A., 2012, CVPR
   Mishra A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.127
   Mollah AF, 2011, INT J COMPUT SCI APP, V1, P33
   Moysset B, 2017, PROC INT CONF DOC, P871, DOI 10.1109/ICDAR.2017.147
   Nayef Nibal, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1582, DOI 10.1109/ICDAR.2019.00254
   Negishi K, 2005, P 1 INT WORKSH CAM B, P140
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Neumann L, 2016, IEEE T PATTERN ANAL, V38, P1872, DOI 10.1109/TPAMI.2015.2496234
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Noola DA, 2015, INT J EMERG TECHNOL, V14, P916
   Patel Chirag., 2013, Em: International Journal of Current Engineering and Technology, V3, P2075
   Pruthi D, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5582
   Rong XJ, 2017, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2017.349
   Roy Prasun, 2020, P IEEECVF C COMPUTER, P13228
   Roy S, 2012, INT C PATT RECOG, P3300
   Saidane Z, 2007, PROC INT CONF DOC, P874
   Sambyal N, 2016, INT J SCI TECH ADVAN, V2, P303
   Saric M, 2017, NEUROCOMPUTING, V266, P56, DOI 10.1016/j.neucom.2017.05.021
   Sarshogh MR, 2019, ARXIV190609266
   Seeri Shivananda V., 2016, International Journal of Image, Graphics and Signal Processing, V8, P36, DOI 10.5815/ijigsp.2016.05.02
   Sengupta P, 2019, INT J COMPUTATIONAL, V2, P336
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shi BG, 2016, PROC CVPR IEEE, P4168, DOI 10.1109/CVPR.2016.452
   Shi BG, 2015, PROC INT CONF DOC, P531, DOI 10.1109/ICDAR.2015.7333818
   Shi Baoguang, 2018, IEEE T PATTERN ANAL
   Shi CZ, 2013, PROC CVPR IEEE, P2961, DOI 10.1109/CVPR.2013.381
   Shruthi V, 2015, INT J ENG COMPUT SCI, V4, P12123
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su BL, 2017, PATTERN RECOGN, V63, P397, DOI 10.1016/j.patcog.2016.10.016
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang T, 2012, INT C PATT RECOG, P3304
   Xu X., 2020, P IEEECVF C COMPUTER, P12304
   Yang C, 2017, ARXIV PREPRINT ARXIV
   Yao C, 2014, IEEE T IMAGE PROCESS, V23, P4737, DOI 10.1109/TIP.2014.2353813
   Yi CC, 2014, IEEE T IMAGE PROCESS, V23, P2972, DOI 10.1109/TIP.2014.2317980
   Yousef M, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107482
   Zhan FN, 2019, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2019.00216
   Zhang H., 2020, AUTOSTR EFFICIENT BA
   Zhang YP, 2019, PROC CVPR IEEE, P2735, DOI 10.1109/CVPR.2019.00285
   Zhang YG, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P106, DOI 10.1109/IVS.2003.1212892
   Zhi Qiao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13525, DOI 10.1109/CVPR42600.2020.01354
   Zhiwei Zhou, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P133, DOI 10.1109/ICPR.2010.41
   Zhu Hongyuan, 2019, ARXIV PREPRINT ARXIV
   Zuo LQ, 2019, IEEE ACCESS, V7, P62616, DOI 10.1109/ACCESS.2019.2916616
NR 90
TC 3
Z9 3
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6079
EP 6104
DI 10.1007/s11042-020-09862-x
EA OCT 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577066700004
DA 2024-07-18
ER

PT J
AU Rajathilagam, G
   Kavitha, K
AF Rajathilagam, G.
   Kavitha, K.
TI Task unit bid- spatial coverage and post input density (TUBSC_PID) based
   crowd sourcing network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Task selection; Spatial; Temporal; Profit; Offer; Input density
AB A huge number of items are associated with the Internet of Things (IoT) which is fixed with software, electronics and sensors. It has a wide variety of applications, namely smart homes, smart grids and smart cities. The sensor devices combine with Internet of Things (IoT) operates as robot system to execute data collection task. The IoT control objects, sense devices and gathers data. In crowd sourcing network there are two main issues, namely to guarantee the Quality of Service (QoS) of tasks and to reduce the data collection cost. There is also some problems arise between the task circulator and the data reporter in terms of profit. Since, IoT sensing devices have increased a lot, the relationship for finishing the task is very much important. In this paper, a novel framework called Task Unit Bit-based Spatial Coverage and Post Input density (TUBSC_PID) has been proposed. The input density is applied to estimate the contribution of a single data collector to a particular sensing task. A Task Unit Bid-based task selection strategy is proposed to choose the task which provides more contribution density and higher profit to the system. A novel spatial coverage technique is also applied to cover all the information obtained from the data collector. The present and post input density is applied to estimate the contribution of a single data collector to a particular sensing task as well as future sensing tasks. This method reduces the cost of data selection and maximizes the system profit. Experimental results predict that compared to the traditional techniques, namely Random Task selection with Input Density Reporter selection (RTCDR) and Collaborative Multi-Tasks Data Collection Scheme (CMDCS), the profit of the system is improved by 96.1%.
C1 [Rajathilagam, G.; Kavitha, K.] Mother Teresa Womens Univ, Dept Comp Sci, Kodaikanal 624101, Tamil Nadu, India.
C3 Mother Teresa Women's University
RP Rajathilagam, G (corresponding author), Mother Teresa Womens Univ, Dept Comp Sci, Kodaikanal 624101, Tamil Nadu, India.
EM rajathilagam.phd2021@gmail.com; kavitha.urc@gmail.com
RI K, Kavitha/JBS-2736-2023; K, Kavitha/AAD-8422-2021
CR [Anonymous], 2015, FUTUR GENER COMPUT S
   Ashouri M, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11110235
   Estelles-Arolas Enrique, 2015, ADV CROWDSOURCING
   Funk C, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1606
   Karger DR, 2014, OPER RES, V62, P1, DOI 10.1287/opre.2013.1235
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Longo A, 2017, ACM T INTERNET TECHN, V18, DOI 10.1145/3093895
   Müller MM, 2019, FRONT PUBLIC HEALTH, V7, DOI 10.3389/fpubh.2019.00081
   Peng ZL, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/7413460
   Phuttharak J, 2018, IEEE ACCESS, V7, P2169
   Pournajaf L, 2014, IEEE INT CONF MOB DA, P73, DOI 10.1109/MDM.2014.15
   Ren YY, 2019, IEEE ACCESS, V7, P19238, DOI 10.1109/ACCESS.2019.2897062
   Roy SB, 2015, TASK ASSIGNMENT OPTI
   Roy SB, 2015, VLDB J, V24, P467, DOI 10.1007/s00778-015-0385-2
   Sarkar S, 2018, IEEE T CLOUD COMPUT, V6, P46, DOI 10.1109/TCC.2015.2485206
   Wazny K, 2018, J GLOB HEALTH, V8, DOI 10.7189/jogh.08.010502
   Xiao MJ, 2020, IEEE T KNOWL DATA EN, V32, P782, DOI 10.1109/TKDE.2019.2893240
   Zhao D, 2016, IEEE ACM T NETWORK, V24, P647, DOI 10.1109/TNET.2014.2379281
   Zheng FF, 2018, REV GEOPHYS, V56, P698, DOI 10.1029/2018RG000616
   Zheng YD, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1031, DOI 10.1145/2723372.2749430
   Zhengy Y, 2015, SIGMOD 15
NR 22
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5273
EP 5286
DI 10.1007/s11042-020-09895-2
EA OCT 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000575795600011
DA 2024-07-18
ER

PT J
AU Sun, ZJ
   Wang, Y
   Gong, C
   Laganiére, R
AF Sun, Zhuojin
   Wang, Yong
   Gong, Chen
   Laganiere, Robert
TI Study of UAV tracking based on CNN in noisy environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Noisy videos; UAV tracking; CNN feature based tracker
ID OBJECT TRACKING
AB Recently, there are lots of tracking methods proposed to improve the performance of visual tracking in videos with challenging situations, such as background clutter, severe occlusion, rotation, and so on. In real unmanned aerial vehicle (UAV) based tracking systems, there are various noises occurring during video capturing, transmission, and processing. However, most existing studies pay attention to improve the robustness and accuracy of visual tracking while ignoring the performance of tracking methods on videos with noise. In this paper, we investigate the performance evaluation of existing tracking methods on videos with noise. A group of noisy UAV based tracking video datasets are constructed and used to the benchmark datasets for analysis of tracking methods. Furthermore, we propose an algorithm for robustness tracking in noisy videos. The performance of 9 tracking methods is evaluated on the proposed dataset. We provide the detailed analysis and discussion on the robustness analysis of different tracking methods on videos with different variance of noises. Our investigation shows that it is still challenging for effective tracking for existing methods on videos with noise. And our proposed method shows promising results in noisy videos.
C1 [Sun, Zhuojin] Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, Shanghai, Peoples R China.
   [Wang, Yong] Sun Yat Sen Univ, Sch Aeronaut & Astronaut, Guangzhou, Peoples R China.
   [Gong, Chen] Nanjing Univ Sci & Technol, Key Lab Intelligent Percept & Syst High Dimens In, Sch Comp Sci & Engn, PCA Lab,Minist Educ, Nanjing 210094, Peoples R China.
   [Laganiere, Robert] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON, Canada.
C3 Shanghai Jiao Tong University; Sun Yat Sen University; Nanjing
   University of Science & Technology; University of Ottawa
RP Wang, Y (corresponding author), Sun Yat Sen Univ, Sch Aeronaut & Astronaut, Guangzhou, Peoples R China.
EM wangyong5@mail.sysu.edu.cn
RI Laganiere, Robert/H-9138-2013; GONG, CHEN/JDW-5727-2023
OI , yong/0000-0001-6559-9550
FU NSF of China [61602246]; NSF of Jiangsu Province [BK20171430];
   Fundamental Research Funds for the Central Universities [30918011319];
   "Summit of the Six Top Talents" Program [DZXX-027]
FX This research is partially supported by NSF of China (No: 61602246), NSF
   of Jiangsu Province (No: BK20171430), the Fundamental Research Funds for
   the Central Universities (No: 30918011319), and the "Summit of the Six
   Top Talents" Program (No: DZXX-027).
CR [Anonymous], 2012, 2012 IEEE COMPUTER S, DOI DOI 10.1109/CVPRW.2012.6239201
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen Z., 2015, Comput. Sci., V53, P68
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Du DW, 2018, LECT NOTES COMPUT SC, V11214, P375, DOI 10.1007/978-3-030-01249-6_23
   Fan H, 2018, CORR
   Fang YM, 2017, IEEE ACCESS, V5, P2430, DOI 10.1109/ACCESS.2017.2666218
   Fiaz M., 2018, ARXIV180203098
   Fu CH, 2014, IEEE INT CONF ROBOT, P5441, DOI 10.1109/ICRA.2014.6907659
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Gaszczak A, 2011, PROC SPIE, V7878, DOI 10.1117/12.876663
   Hendrycks Dan, 2019, ARXIV190312261
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Kendall AG, 2014, INT CONF UNMAN AIRCR, P404, DOI 10.1109/ICUAS.2014.6842280
   Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li AN, 2016, IEEE T PATTERN ANAL, V38, P335, DOI 10.1109/TPAMI.2015.2417577
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li SY, 2017, AAAI CONF ARTIF INTE, P4140
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Lim H, 2015, IEEE INT CONF ROBOT, P2182, DOI 10.1109/ICRA.2015.7139487
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Madry A., 2018, ARXIV
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Mueller M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1562, DOI 10.1109/IROS.2016.7759253
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Naseer T, 2013, IEEE INT C INT ROBOT, P624, DOI 10.1109/IROS.2013.6696416
   Nussberger A, 2014, INT CONF UNMAN AIRCR, P1284, DOI 10.1109/ICUAS.2014.6842386
   Pestana J, 2013, IEEE INT SYMP SAFE
   Portmann J, 2014, IEEE INT CONF ROBOT, P1794, DOI 10.1109/ICRA.2014.6907094
   Prokaj J, 2014, PROC CVPR IEEE, P1186, DOI 10.1109/CVPR.2014.155
   Qadir A, 2011, INF AER C AM I AER A
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Solis B, 2015, X: THE EXPERIENCE WHEN BUSINESS MEETS DESIGN, P24
   Sun Z, 2018, 15 C COMP ROB VIS CR
   Tramonti F, 2019, PSYCHOL HEALTH MED, V24, P27, DOI 10.1080/13548506.2018.1510131
   Valmadre J, 2018, LECT NOTES COMPUT SC, V11207, P692, DOI 10.1007/978-3-030-01219-9_41
   Wang F, 2018, LECT NOTES COMPUT SC, V11213, P780, DOI 10.1007/978-3-030-01240-3_47
   Wang N, 2018, IEEE T CIRCUITS SYST
   Wang NY, 2015, IEEE I CONF COMP VIS, P3101, DOI 10.1109/ICCV.2015.355
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wang X., 2020, PROGRESSIVE LOCAL FI
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhou YQ, 2018, IEEE INT CONF AUTOMA, P769, DOI 10.1109/FG.2018.00121
NR 58
TC 2
Z9 2
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5351
EP 5372
DI 10.1007/s11042-020-09713-9
EA OCT 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000575795600004
DA 2024-07-18
ER

PT J
AU Mukherjee, A
   Das, SD
   Ghosh, J
   Chowdhury, AS
   Saha, SK
AF Mukherjee, Aritra
   Das, Sourya Dipta
   Ghosh, Jasorsi
   Chowdhury, Ananda S.
   Saha, Sanjoy Kumar
TI Semantic segmentation of surface from lidar point cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic surface segmentation; 3D point cloud processing; Lidar Data;
   Meshing
ID EXTRACTION
AB Mapping the environment for robot navigation is an important and challenging task in SLAM (Simultaneous Localization And Mapping). Lidar sensor can produce near accurate 3D map of the environment in real time in form of point clouds. Though the point cloud data is adequate for building the map of the environment, processing millions of points in a point cloud is found to be computationally expensive. In this paper, we propose a fast algorithm that can be used to extract semantically labelled surface segments from the cloud in real time for direct navigational use or for higher level contextual scene reconstruction. First, a single scan from a spinning Lidar is used to generate a mesh of sampled cloud points. The generated mesh is further used for surface normal computation of a set of points on the basis of which surface segments are estimated. A novel descriptor is proposed to represent the surface segments. This descriptor is used to determine the surface class (semantic label) of the segments with the help of a classifier. These semantic surface segments can be further utilized for geometric reconstruction of objects in the scene or for optimized trajectory planning of a robot. The proposed method is compared with a number of point cloud segmentation methods and state of the art semantic segmentation methods to demonstrate its efficacy in terms of speed and accuracy.
C1 [Mukherjee, Aritra; Saha, Sanjoy Kumar] Jadavpur Univ, Dept Comp Sci, Engn, Kolkata, India.
   [Das, Sourya Dipta; Ghosh, Jasorsi; Chowdhury, Ananda S.] Jadavpur Univ, Telecommun Engn, Dept Elect, Kolkata, India.
C3 Jadavpur University; Jadavpur University
RP Saha, SK (corresponding author), Jadavpur Univ, Dept Comp Sci, Engn, Kolkata, India.
EM sks_ju@yahoo.co.in
OI Saha, Sanjoy Kumar/0000-0003-2241-5373
CR ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Nguyen A, 2013, PROCEEDINGS OF THE 2013 6TH IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P225, DOI 10.1109/RAM.2013.6758588
   Vo AV, 2015, ISPRS J PHOTOGRAMM, V104, P88, DOI 10.1016/j.isprsjprs.2015.01.011
   [Anonymous], 2017, P INT ARCH PHOT REM, DOI DOI 10.5194/isprs-archives-XLII-2-W8-25-2017
   Ben-Shabat Y, 2018, COMPUT VIS IMAGE UND, V174, P12, DOI 10.1016/j.cviu.2018.06.004
   Bhanu B., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P236
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Feng C, 2014, IEEE INT CONF ROBOT, P6218, DOI 10.1109/ICRA.2014.6907776
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Golovinskiy Aleksey, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P39, DOI 10.1109/ICCVW.2009.5457721
   Gschwandtner Michael, 2011, PROC 7 INT S VISUAL, P199, DOI DOI 10.1007/978-3-642-24031-7_20
   Hackel T, 2016, ISPRS ANN PHOTO REM, V3, P177, DOI 10.5194/isprsannals-III-3-177-2016
   Himmelsbach M, 2010, IEEE INT VEH SYM, P560, DOI 10.1109/IVS.2010.5548059
   Ioannou Y, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P501, DOI 10.1109/3DIMPVT.2012.12
   Jiang M., 2018, ARXIV180700652
   Jiang XY, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P83, DOI 10.1109/ACV.1996.572006
   Landrieu L, 2018, PROC CVPR IEEE, P4558, DOI 10.1109/CVPR.2018.00479
   Lee YK, 2004, J AM STAT ASSOC, V99, P67, DOI 10.1198/016214504000000098
   Li GH, 2019, IEEE I CONF COMP VIS, P9266, DOI 10.1109/ICCV.2019.00936
   Li MJ, 2017, CHIN CONT DECIS CONF, P3561, DOI 10.1109/CCDC.2017.7979123
   Li YY, 2018, ADV NEUR IN, V31
   Liu ZJ, 2019, ADV NEUR IN, V32
   Moosmann F, 2009, IEEE INT VEH SYM, P215, DOI 10.1109/IVS.2009.5164280
   Mukherjee A, 2019, LECT NOTES COMPUT SC, V11941, P415, DOI 10.1007/978-3-030-34869-4_45
   Qi CR, 2017, ADV NEUR IN, V30
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Rosa S., 2020, 2020 P IEEECVF C COM, P11108, DOI [DOI 10.1109/CVPR42600.2020.01112, 10.1109/CVPR42600.2020.01112]
   Rusu RB, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P7, DOI 10.1109/IROS.2009.5354763
   Srivastava S, 2019, PATTERN RECOGN LETT, V127, P27, DOI 10.1016/j.patrec.2019.02.027
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Tarsha-Kurdi F., 2007, INT ARCH PHOTOGRAMME, V36, P407
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wicaksono SB, 2019, 2019 4TH INTERNATIONAL WORKSHOP ON BIG DATA AND INFORMATION SECURITY (IWBIS 2019), P63, DOI [10.1109/iwbis.2019.8935882, 10.1109/IWBIS.2019.8935882]
   Yang Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9598, DOI 10.1109/CVPR42600.2020.00962
   Zermas D., 2017, 2017 IEEE INT C ROB, P5067, DOI DOI 10.1109/ICRA.2017.7989591
   Zhan Q., 2009, Laser scanning, V38, P155
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhao N., 2020, ARXIV200612052
NR 40
TC 1
Z9 1
U1 1
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35171
EP 35191
DI 10.1007/s11042-020-09841-2
EA OCT 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000574800200006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Reska, D
   Kretowski, M
AF Reska, Daniel
   Kretowski, Marek
TI GPU-accelerated image segmentation based on level sets and multiple
   texture features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Active contour model; Level set method; Texture
   analysis; GPU acceleration
ID ACTIVE CONTOUR MODEL
AB In this paper, we present a fast multi-stage image segmentation method that incorporates texture analysis into a level set-based active contour framework. This approach allows integrating multiple feature extraction methods and is not tied to any specific texture descriptors. Prior knowledge of the image patterns is also not required. The method starts with an initial feature extraction and selection, then performs a fast level set-based evolution process and ends with a final refinement stage that integrates a region-based model. The presented implementation employs a set of features based on Grey Level Co-occurrence Matrices, Gabor filters and structure tensors. The high performance of feature extraction and contour evolution stages is achieved with GPU acceleration. The method is validated on synthetic and natural images and confronted with results of the most similar among the accessible algorithms.
C1 [Reska, Daniel; Kretowski, Marek] Bialystok Tech Univ, Fac Comp Sci, Wiejska 45A, PL-15351 Bialystok, Poland.
C3 Bialystok University of Technology
RP Reska, D (corresponding author), Bialystok Tech Univ, Fac Comp Sci, Wiejska 45A, PL-15351 Bialystok, Poland.
EM d.reska@pb.edu.pl; m.kretowski@pb.edu.pl
RI Reska, Daniel/R-9358-2018; Kretowski, Marek/P-8079-2018
OI Reska, Daniel/0000-0002-2367-7546; Kretowski, Marek/0000-0001-9175-2678
FU Polish National Science Centre [2017/25/N/ST6/01849]
FX This work was supported by the Polish National Science Centre under
   Grant No. 2017/25/N/ST6/01849. The authors are grateful to Dr. Cezary
   Boldak for his contribution to the work
CR Ahmad A, 2020, SOFT COMPUT, V24, P15491, DOI 10.1007/s00500-020-04878-9
   [Anonymous], 2017, ARXIV170305230
   [Anonymous], 2011, KYLBERG TEXTURE DATA
   Awate SP, 2006, LECT NOTES COMPUT SC, V3952, P494
   BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668
   Bigun J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P433
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   Dahl Anders Bjorholm, 2015, Image Analysis. 19th Scandinavian Conference, SCIA 2015. Proceedings: LNCS 9127, P26, DOI 10.1007/978-3-319-19665-7_3
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   de Siqueira FR, 2013, NEUROCOMPUTING, V120, P336, DOI 10.1016/j.neucom.2012.09.042
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Dong YS, 2019, IEEE ACCESS, V7, P93887, DOI 10.1109/ACCESS.2019.2928415
   ESEDOGLU S, 2005, P IEEE ICIP, V2, P502
   Gao MQ, 2019, SIGNAL PROCESS, V159, P104, DOI 10.1016/j.sigpro.2019.01.021
   Gao MQ, 2016, IEEE IMAGE PROC, P4309, DOI 10.1109/ICIP.2016.7533173
   Grushnikov A, 2018, MACH VISION APPL, V29, P125, DOI 10.1007/s00138-017-0880-0
   Han B, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107520
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Heimann T, 2009, IEEE T MED IMAGING, V28, P1251, DOI 10.1109/TMI.2009.2013851
   Houhou N., 2008, 2008 IEEE C COMPUTER, P1, DOI DOI 10.1109/CVPR.2008.4587449
   Huang XL, 2005, LECT NOTES COMPUT SC, V3757, P119, DOI 10.1007/11585978_9
   JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI [10.1109/ICSMC.1990.142050, 10.1016/0031-3203(91)90143-S]
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Lefohn AE, 2003, LECT NOTES COMPUT SC, V2878, P564
   Liu XW, 2006, IEEE T IMAGE PROCESS, V15, P3066, DOI 10.1109/TIP.2006.877511
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   McInerney T., 1999, Medical Image Analysis, P840
   Mewada H, 2015, COMPUT J, V58, P2044, DOI 10.1093/comjnl/bxu143
   Min H, 2015, PATTERN RECOGN, V48, P1547, DOI 10.1016/j.patcog.2014.10.018
   Moallem P, 2016, SIGNAL IMAGE VIDEO P, V10, P351, DOI 10.1007/s11760-015-0748-6
   Moore P, 2007, IMVIP 2007: INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, PROCEEDINGS, P55, DOI 10.1109/IMVIP.2007.31
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Ni K, 2009, INT J COMPUT VISION, V84, P97, DOI 10.1007/s11263-009-0234-0
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   Pujol O., 2004, INT J IMAGE GRAPHICS, V4, P433
   REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024
   Reska D, 2017, SIGNAL IMAGE VIDEO P, V11, P809, DOI 10.1007/s11760-016-1026-y
   Reska D, 2016, ADV INTELL SYST, V389, P205, DOI 10.1007/978-3-319-23814-2_24
   Reska D, 2014, BIOCYBERN BIOMED ENG, V34, P146, DOI 10.1016/j.bbe.2014.02.003
   RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153
   Rousson M, 2003, PROC CVPR IEEE, P699
   Sagiv C, 2006, IEEE T IMAGE PROCESS, V15, P1633, DOI 10.1109/TIP.2006.871133
   Sethian J., 1999, LEVEL SET METHODS FA
   Shen T, 2011, MULTI MODALITY STATE-OF-THE-ART MEDICAL IMAGE SEGMENTATION AND REGISTRATION METHODOLOGIES, VOL 1, P1, DOI 10.1007/978-1-4419-8195-0_1
   Sochen N, 1998, IEEE T IMAGE PROCESS, V7, P310, DOI 10.1109/83.661181
   Subudhi P, 2018, SIGNAL IMAGE VIDEO P, V12, P669, DOI 10.1007/s11760-017-1206-4
   Tatu A, 2015, LECT NOTES COMPUT SC, V8932, P223, DOI 10.1007/978-3-319-14612-6_17
   Wang L, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107297
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wang YQ, 2013, COMPUT ELECTR ENG, V39, P1506, DOI 10.1016/j.compeleceng.2013.03.017
   Wu QG, 2015, NEUROCOMPUTING, V151, P1133, DOI 10.1016/j.neucom.2014.04.085
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P28525, DOI 10.1007/s11042-020-09311-9
   Zhao G, 2018, MULTIMED TOOLS APPL, V77, P24537, DOI 10.1007/s11042-018-5777-z
NR 59
TC 6
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5087
EP 5109
DI 10.1007/s11042-020-09911-5
EA OCT 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000574800200002
OA hybrid
DA 2024-07-18
ER

PT J
AU Aljawarneh, S
   Lara, JA
   Yassein, MB
AF Aljawarneh, Shadi
   Lara, Juan A.
   Yassein, Muneer Bani
TI A visual big data system for the prediction of weather-related
   variables: Jordan-Spain case study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; Weather forecasting; Data mining; Information fusion; MongoDB
AB The Meteorology is a field where huge amounts of data are generated, mainly collected by sensors at weather stations, where different variables can be measured. Those data have some particularities such as high volume and dimensionality, the frequent existence of missing values in some stations, and the high correlation between collected variables. In this regard, it is crucial to make use of Big Data and Data Mining techniques to deal with those data and extract useful knowledge from them that can be used, for instance, to predict weather phenomena. In this paper, we propose a visual big data system that is designed to deal with high amounts of weather-related data and lets the user analyze those data to perform predictive tasks over the considered variables (temperature and rainfall). The proposed system collects open data and loads them onto a local NoSQL database fusing them at different levels of temporal and spatial aggregation in order to perform a predictive analysis using univariate and multivariate approaches as well as forecasting based on training data from neighbor stations in cases with high rates of missing values. The system has been assessed in terms of usability and predictive performance, obtaining an overall normalized mean squared error value of 0.00013, and an overall directional symmetry value of nearly 0.84. Our system has been rated positively by a group of experts in the area (all aspects of the system except graphic desing were rated 3 or above in a 1-5 scale). The promising preliminary results obtained demonstrate the validity of our system and invite us to keep working on this area.
C1 [Aljawarneh, Shadi; Yassein, Muneer Bani] Jordan Univ Sci & Technol, Fac Comp & Informat Technol, JUST, POB 3030, Irbid 22110, Jordan.
   [Lara, Juan A.] Madrid Open Univ, UDIMA, Sch Comp Sci, KM 38,500,Via Serv 15, Madrid 28400, Spain.
C3 Jordan University of Science & Technology; Madrid Open University, UDIMA
RP Lara, JA (corresponding author), Madrid Open Univ, UDIMA, Sch Comp Sci, KM 38,500,Via Serv 15, Madrid 28400, Spain.
EM juanalfonso.lara@udima.es
RI Lara Torralbo, Juan Alfonso/I-9196-2014; Aljawarneh, Shadi/ABD-6329-2021
OI Lara Torralbo, Juan Alfonso/0000-0001-5131-8447; Aljawarneh,
   Shadi/0000-0001-5748-4921; Bani Yassein, Muneer/0000-0001-5030-6196
FU Jordan University of Science and Technology, JUST (Jordan)
FX This paper was drafted as part of Juan A. Lara's research stay during
   2019-2020 at Jordan University of Science and Technology, JUST (Jordan),
   which partially sponsored this research. The authors would like to thank
   UDIMA's and JUST's students who took part in the design and
   implementation of the system, particularly Francisco Javier Moreno
   Hermosilla, Paulina Pyzel and Amnah Al-Abdi; and JUST's experts for
   providing their feedback in order to assess this system.
CR Adam K, 2017, ADV SCI LETT, V23, P11138, DOI 10.1166/asl.2017.10237
   Aggarwal C, 2014, DATA CLASSIFICATIONA
   Alodah A, 2019, STOCH ENV RES RISK A, V33, P253, DOI 10.1007/s00477-018-1613-2
   Ambigavathi M, 2020, INTELLIGENT COMMUNIC, V989
   [Anonymous], 2015, Information Granularity, Big Data, and Computational Intelligence, DOI DOI 10.1007/978-3-319-08254-719
   Gutiérrez PA, 2016, IEEE T KNOWL DATA EN, V28, P127, DOI 10.1109/TKDE.2015.2457911
   Baerg A, 2017, J SPORT SOC ISSUES, V41, P3, DOI 10.1177/0193723516673409
   Bajaber F, 2020, COMPUT COMMUN, V149, P241, DOI 10.1016/j.comcom.2019.10.002
   Booz J, 2019, INT CONF COMPUT NETW, P697, DOI [10.1109/ICCNC.2019.8685584, 10.1109/iccnc.2019.8685584]
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chodorow Kristina., 2010, MONGODB DEFINITIVE G, V1st
   Chouksey P, 2017, INT J ADV RES COMPUT, V6, P365, DOI [10.17148/IJARCCE.2017.6172, DOI 10.17148/IJARCCE.2017.6172]
   Corbellini A, 2017, INFORM SYST, V63, P1, DOI 10.1016/j.is.2016.07.009
   Dagade V, 2015, INT J EMERG TECHNOL, V14, P847
   Fayyad U, 1996, AI MAG, V17, P37
   Firican G, 2020, 10 VS BIG DATA
   Hassani H., 2015, ANN DATA SCI, V2, P5, DOI DOI 10.1007/S40745-015-0029-9
   Haupt SE, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P496, DOI 10.1109/SSCI.2015.79
   Haykin S, 1998, Neural Networks: A Comprehensive Foundation
   Hussein E, 2020, LECT NOTES I COMPUTE
   Ismail KA, 2016, IEEE CONF OPEN SYST, P13, DOI 10.1109/ICOS.2016.7881981
   Jose B, 2017, 2017 INTERNATIONAL CONFERENCE ON NETWORKS & ADVANCES IN COMPUTATIONAL TECHNOLOGIES (NETACT), P266, DOI 10.1109/NETACT.2017.8076778
   Kristjanpoller RW, 2018, APPL SOFT COMPUT, V67, P106, DOI 10.1016/j.asoc.2018.02.055
   Kucukkececi C, 2019, IEEE ACCESS, V7, P67818, DOI 10.1109/ACCESS.2019.2918765
   Kulkarni P, 2020, SMART TECHNOLOGIES
   Lakshman Avinash, 2010, Operating Systems Review, V44, P35, DOI 10.1145/1773912.1773922
   Lin SY, 2018, FUTURE GENER COMP SY, V89, P446, DOI 10.1016/j.future.2018.06.052
   Liu HT, 2020, IEEE T NEUR NET LEAR, V31, P4405, DOI 10.1109/TNNLS.2019.2957109
   Lynch C, 2008, NATURE, V455, P28, DOI 10.1038/455028a
   Marchioni F., 2012, INFINISPAN DATA GRID
   Membrey Peter., 2010, The Definitive Guide to MongoDB: the noSQL Database for Cloud and Desktop Computing
   Miyoshi T, 2015, COMPUTER, V48, P15, DOI 10.1109/MC.2015.332
   Moreno FJ, 2019, THESIS
   Narendra K, 2020, SECURITY PRIVACY FOR, P247, DOI DOI 10.4018/978-1-5225-9742-1.CH010
   Objectivity Inc, 2013, INF
   Pandey P, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P3625
   Pyzel P, 2019, THESIS
   Seber G. A. F., 2003, Wiley Series in Probability and Statistics
   Shastri A, 2020, STUDIES BIG DATA
   Shevade SK, 2000, IEEE T NEURAL NETWOR, V11, P1188, DOI 10.1109/72.870050
   Torres JF, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12394
   Udeh K, 2019, 2019 IEEE 10TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P499, DOI 10.1109/UEMCON47517.2019.8992951
   Venkatesham N, 2019, MATER RES EXPRESS, V6, DOI 10.1088/2053-1591/aae4eb
   Waladi A, 2019, INT C ADV COMP SCI I, P193, DOI [10.1109/ICACSIS47736.2019.8979691, 10.1109/icacsis47736.2019.8979691]
   Witten H., 1999, P ICONIPANZIISANNES, P192
   Wu YK, 2020, INFORM SCIENCES, V508, P79, DOI 10.1016/j.ins.2019.08.064
   Yang RJ, 2020, INT J INFORM MANAGE, V50, P452, DOI 10.1016/j.ijinfomgt.2019.05.027
NR 47
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13103
EP 13139
DI 10.1007/s11042-020-09848-9
EA OCT 2020
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000574376900002
DA 2024-07-18
ER

PT J
AU Ke, LF
   Yin, ZX
AF Ke, Longfei
   Yin, Zhaoxia
TI On the security and robustness of "Keyless dynamic optimal multi-bit
   image steganography using energetic pixels"
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive steganography; Robustness; Security; Multi-bit steganography
AB The multi-bit image steganography (Paul et al. Multimedia Tools and Applications 76(5):7445-7471,2017) proposed by Paul et al. provides high embedding capacity, and adapts the embedding position of messages to image content. This paper investigates the security and robustness of multi-bit steganography. In detection resistant experiment, we embed secret messages into cover images with multi-bit image steganography to get corresponding stego images, and adopt a more popular steganalyzer (SRM) to extract features of cover images and stego images. The ensemble classifier is trained with default settings. The experimental results show detection resistance performance of multi-bit image steganography is poor. In robustness test, we embed secret messages into cover images with multi-bit image steganography to get stego images, and attack the stego images with Stirmark. Then, we extract the secret messages from the attacked stego images. The experimental results demonstrate that we can not recover the secret messages from the attacked stego images. Therefore, there are flaws in detection resistant test and robustness test of multi-bit image steganography.
C1 [Ke, Longfei; Yin, Zhaoxia] Anhui Univ, Sch Comp Sci & Technol, Minist Educ, Key Lab Intelligent Comp & Signal Proc, Hefei 230601, Peoples R China.
C3 Anhui University
RP Yin, ZX (corresponding author), Anhui Univ, Sch Comp Sci & Technol, Minist Educ, Key Lab Intelligent Comp & Signal Proc, Hefei 230601, Peoples R China.
EM yinzhaoxia@ahu.edu.cn
RI Yin, Zhaoxia/HRD-7425-2023
OI Yin, Zhaoxia/0000-0003-0387-4806
FU National Natural Science Foundation of China [61872003,
   U1636206,61860206004]
FX This research work is partly supported by National Natural Science
   Foundation of China (61872003, U1636206,61860206004).
CR Amirtharajan R, 2012, INFORM SCIENCES, V193, P115, DOI 10.1016/j.ins.2012.01.010
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gupta P, 2019, LECT NOTE NETW SYST, V55, P369, DOI 10.1007/978-981-13-2324-9_37
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Huang H-C, 2016, J INFORM HIDING MULT, V7, P11
   Huang HC., 2017, J INFORM HIDING MULT, V8, P435
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2143, DOI 10.1007/s11042-013-1832-y
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Paul G., 2012, INT C INF SYST SEC, P134, DOI 10.1007/978-3-642-35130-3_10
   Paul G, 2017, MULTIMED TOOLS APPL, V76, P7445, DOI 10.1007/s11042-016-3319-0
   Peng F, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115715
   Peng F, 2019, MULTIMED TOOLS APPL, V78, P26885, DOI 10.1007/s11042-017-4362-1
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Sarreshtedari S, 2014, IET IMAGE PROCESS, V8, P78, DOI 10.1049/iet-ipr.2013.0109
   Setiadi DIM, 2018, CYBERN INF TECHNOL, V18, P74, DOI 10.2478/cait-2018-0029
   Swain G, 2019, ARAB J SCI ENG, V44, P2995, DOI 10.1007/s13369-018-3372-2
   Tavares R, 2016, IEEE LAT AM T, V14, P1058, DOI 10.1109/TLA.2016.7437258
   Wang ZH, 2012, INFORM SCIENCES, V192, P98, DOI 10.1016/j.ins.2010.07.011
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Yang HF, 2009, RADIOENGINEERING, V18, P509
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Zhang D, 2017, IMMUNOPHARM IMMUNOT, V39, P2, DOI 10.1080/08923973.2016.1255225
NR 26
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3997
EP 4005
DI 10.1007/s11042-020-09807-4
EA SEP 2020
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000573572100001
DA 2024-07-18
ER

PT J
AU Liang, RY
   Xie, Y
   Cheng, JM
   Tang, GC
   Sun, SN
AF Liang, Ruiyu
   Xie, Yue
   Cheng, Jiaming
   Tang, Guichen
   Sun, Shinuo
TI Real-time speech enhancement algorithm for transient noise suppression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech enhancement; Transient noise suppression; The quantile noise
   estimation; Harmonic analysis
ID NEURAL-NETWORK; ENVIRONMENTS; RECOGNITION
AB To effectively restrain stationary noise and transient noise, a real-time single-channel speech enhancement algorithm is proposed. First, to evaluate stationary noise, the quantile noise estimation method is used to obtain the spectrum of stationary noise. Then, based on the normalized variance and gravity center of the signal, the transient noise detection method is proposed to modify the spectrum of stationary noise. Next, the speech presence probability is estimated based on the speech features and harmonic analysis. Finally, the optimized-modified log-spectral amplitude (OM-LSA) estimator is adopted for speech enhancement. The experimental noise contains 115 environmental sounds with the SNR of -10 to 10 dB. The experimental results show that the performance of the proposed algorithm is comparable to the OM-LSA algorithm which has good denoising performance, but the real-time performance of the former is much better. Compared with the Webrtc real-time algorithm, under the overall performance of stationary noise and transient noise, the overall speech quality indicators of the improved algorithm increased by 7.5%, 7.8% and 5.0%, respectively. And the short-time objective intelligibility increased by 2.4%, 2.4% and 2.0%, respectively. Even compared with the recurrent neural network(RNN) algorithm, the suppression performance of the transient noise is better. Besides, the real-time experiment base on the hardware platform shows that the runtime of processing a 10 ms frame is 4.3 ms.
C1 [Liang, Ruiyu; Xie, Yue; Tang, Guichen] Nanjing Inst Technol, Sch Informat & Commun Engn, Nanjing 211167, Peoples R China.
   [Cheng, Jiaming; Sun, Shinuo] Southeast Univ, Sch Informat Sci & Engn, Nanjing 210096, Peoples R China.
C3 Nanjing Institute of Technology; Southeast University - China
RP Liang, RY (corresponding author), Nanjing Inst Technol, Sch Informat & Commun Engn, Nanjing 211167, Peoples R China.
EM liangry@njit.edu.cn
FU National Key Research and Development Program of China [2020YFC2004003,
   2020YFC2004002]; National Natural Science Foundation of China [62001215]
FX The authors would like to thank the reviewers for their valuable
   suggestions and comments. And they also thank Mr. ChaoHe for his
   excellent work in algorithm design and programming. The work was
   supported in part by the National Key Research and Development Program
   of China under Grant 2020YFC2004003 and Grant 2020YFC2004002, the
   National Natural Science Foundation of China under Grant No. 62001215.
CR [Anonymous], 2012, INT WORKSHOP ACOUSTI
   [Anonymous], 2014, P 2 IEEE GLOB C SIGN
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
   Brockwell PJ, 2004, J ECONOMETRICS, V118, P129, DOI 10.1016/S0304-4076(03)00138-6
   Cappé O, 1994, IEEE T SPEECH AUDI P, V2, P345, DOI 10.1109/89.279283
   Chen JT, 2017, J ACOUST SOC AM, V141, P4705, DOI 10.1121/1.4986931
   Cohen I, 2003, IEEE T SPEECH AUDI P, V11, P466, DOI 10.1109/TSA.2003.811544
   Cohen I, 2001, SIGNAL PROCESS, V81, P2403, DOI 10.1016/S0165-1684(01)00128-1
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   EPHRAIM Y, 1985, IEEE T ACOUST SPEECH, V33, P443, DOI 10.1109/TASSP.1985.1164550
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453
   Fu SW, 2017, ASIAPAC SIGN INFO PR, P6, DOI 10.1109/APSIPA.2017.8281993
   Gao T, 2016, INTERSPEECH, P3713, DOI 10.21437/Interspeech.2016-224
   GRIFFIN DW, 1988, IEEE T ACOUST SPEECH, V36, P1223, DOI 10.1109/29.1651
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu GN, 2010, IEEE T AUDIO SPEECH, V18, P2067, DOI 10.1109/TASL.2010.2041110
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   KENNEDY DA, 1961, J FLUID MECH, V10, P366, DOI 10.1017/S0022112061000974
   Kim M, 2015, LECT NOTES COMPUT SC, V9237, P100, DOI 10.1007/978-3-319-22482-4_12
   Kumar B, 2018, INT J SPEECH TECHNOL, V21, P1033, DOI 10.1007/s10772-018-09567-5
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li JF, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS (SOLI), P1, DOI [10.1109/SOLI.2014.6960683, 10.1109/USNC-URSI-NRSM.2014.6928037]
   Lu XG, 2013, INTERSPEECH, P436
   Manohar K, 2006, SPEECH COMMUN, V48, P96, DOI 10.1016/j.specom.2005.08.002
   Michelsanti D, 2017, INTERSPEECH, P2008, DOI 10.21437/Interspeech.2017-1620
   Nongpiur RC, 2008, INT CONF ACOUST SPEE, P1593, DOI 10.1109/ICASSP.2008.4517929
   Pandey A, 2020, INT CONF ACOUST SPEE, P6629, DOI [10.1109/icassp40776.2020.9054536, 10.1109/ICASSP40776.2020.9054536]
   Pandey A, 2019, INT CONF ACOUST SPEE, P6875, DOI [10.1109/ICASSP.2019.8683634, 10.1109/icassp.2019.8683634]
   Pascual S, 2017, INTERSPEECH, P3642, DOI 10.21437/Interspeech.2017-1428
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Stahl V, 2000, INT CONF ACOUST SPEE, P1875, DOI 10.1109/ICASSP.2000.862122
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881
   Takeuchi D, 2020, INT CONF ACOUST SPEE, P851, DOI [10.1109/ICASSP40776.2020.9054597, 10.1109/icassp40776.2020.9054597]
   Tan K, 2019, INT CONF ACOUST SPEE, P5751, DOI 10.1109/ICASSP.2019.8683385
   Tan K, 2018, INTERSPEECH, P3229
   Valin JM, 2018, IEEE INT WORKSH MULT
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   Wang DeLiang, 2017, IEEE Spectr, V54, P32, DOI 10.1109/MSPEC.2017.7864754
   Weninger F, 2015, LECT NOTES COMPUT SC, V9237, P91, DOI 10.1007/978-3-319-22482-4_11
   Xishuang Y., 2004, IMPLEMENTATION SUMMA
   Xu Y, 2015, RES DEEP NEURAL NETW
   Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240
   Zheng C, 2013, AUDIO ENG SOC CONVEN
   Zheng CS, 2014, IEEE SIGNAL PROC LET, V21, P559, DOI 10.1109/LSP.2014.2310772
NR 46
TC 1
Z9 1
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3681
EP 3702
DI 10.1007/s11042-020-09849-8
EA SEP 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572335600002
DA 2024-07-18
ER

PT J
AU Amakdouf, H
   Zouhri, A
   El Mallahi, M
   Tahiri, A
   Chenouni, D
   Qjidaa, H
AF Amakdouf, Hicham
   Zouhri, Amal
   El Mallahi, Mostafa
   Tahiri, Ahmed
   Chenouni, Driss
   Qjidaa, Hassan
TI Artificial intelligent classification of biomedical color image using
   quaternion discrete radial Tchebichef moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image representation; Color image reconstruction; Image
   classification; Quaternion
ID ZERNIKE MOMENTS; INVARIANTS
AB In this work, we propose a new set of an intelligent classifier of biomedical color images using Quaternion Discrete Radial Tchebichef Moments (QRTM). This moment has shown very high robustness in terms of color image representation. Thus, we propose a new approach for the fast and accurate reconstruction of multi-level and color images. This approach based on the reconstruction of color images by applying matrix computation. In the second step, we propose a new method for the extraction of Quaternion Discrete Radial Tchebichef Moments invariant (QRTMI). This method based on the representation of the extraction of these invariants. The performance of the invariance of these moments under the three types of geometrical transformations (Rotation, translation, scale) are very important. Finally, we present a new model based on a Multilayer perceptron (MLP) for the classification of biomedical color images. The experimental results show that the QRTMI very powerful compared with radial Legendre - Fourier and Quaternion discrete radial Krawtchouk moments invariant for the biomedical colors images using the BreaKHis Database (Breast Tumor).
C1 [Amakdouf, Hicham; Zouhri, Amal; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar el Mahraz, Lab Informat Signaux Automat & Cognitivisme, Fes, Morocco.
   [El Mallahi, Mostafa; Tahiri, Ahmed; Chenouni, Driss] Sidi Mohamed Ben Abdellah Univ, Height Normal Sch, Lab Comp Sci & Interdisciplinary Phys, Math & Comp Sci Dept, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP El Mallahi, M (corresponding author), Sidi Mohamed Ben Abdellah Univ, Height Normal Sch, Lab Comp Sci & Interdisciplinary Phys, Math & Comp Sci Dept, Fes, Morocco.
EM hicham.amakdouf@usmba.ac.ma; amal.zouhri@usmba.ac.ma;
   mostafa.elmallahi@hotmail.com; tahiri_ahmed@hotmail.com;
   d_chenouni@yahoo.fr; hassan.ajidaa@usmba.ac.ma
RI ZOUHRI, Amal/AAA-4511-2022; TAHIRI, Ahmed/AAK-5602-2021
OI TAHIRI, Ahmed/0000-0003-3483-0726; El Mallahi,
   Mostafa/0000-0001-9735-6799; Hassan, qjidaa/0000-0003-4505-5243
CR Amakdouf H, 2020, MULTIMED TOOLS APPL, V79, P26571, DOI 10.1007/s11042-020-09120-0
   Amakdouf H, 2018, PROCEDIA COMPUT SCI, V127, P226, DOI 10.1016/j.procs.2018.01.118
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Chen BJ, 2017, J VIS COMMUN IMAGE R, V49, P283, DOI 10.1016/j.jvcir.2017.08.011
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Chen BB, 2010, IEEE INFOCOM SER
   Chen SZ, 2019, IEEE T MULTIMEDIA, V21, P2407, DOI 10.1109/TMM.2019.2896515
   El Mallahi, 2017, INT C MULT COMP SYST
   El Mallahi M., 2018, Pattern Recognition and Image Analysis, V28, P207, DOI 10.1134/S1054661818020128
   El Mallahi M., 2017, Pattern Recognition and Image Analysis, V27, P810
   El Mallahi M, 2018, NEURAL COMPUT APPL, V30, P2283, DOI 10.1007/s00521-016-2782-x
   El Mallahi M, 2018, INT J AUTOM COMPUT, V15, P169, DOI 10.1007/s11633-017-1105-8
   El Mallahi M, 2018, MULTIMED TOOLS APPL, V77, P6583, DOI 10.1007/s11042-017-4573-5
   El Mallahi M, 2017, 2017 INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV)
   El Mallahi M, 2015, I C COMP SYST APPLIC
   Hosny KM, 2019, PATTERN ANAL APPL, V22, P1105, DOI 10.1007/s10044-018-0740-1
   Machhour A, 2020, ADV INTELLIGENT SYST
   Machhour A, 2020, LECT NOTES ELECT ENG
   Machhour A, 2019, P ESAI 2019 FEZ MOR, P2019
   Mukundan R, 2012, COMP ANAL RADIAL TCH, DOI [10.5244/c.23.16, DOI 10.5244/C.23.16]
   Pandey VK, 2016, 3 INT C SIGN PROC IN
   Shen JL, 2008, IEEE T CIRC SYST VID, V18, P1587, DOI 10.1109/TCSVT.2008.2005607
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wang XY, 2015, APPL MATH COMPUT, V256, P951, DOI 10.1016/j.amc.2015.01.075
   XIANGYANG W, 2015, OPT LASER TECHNOL, V66, P78, DOI DOI 10.1016/j.optlastec.2014.07.020
   Xiao B, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023002
   Xiao B, 2012, J VIS COMMUN IMAGE R, V23, P381, DOI 10.1016/j.jvcir.2011.11.008
   Zouhri A, 2020, PATTERN RECOGN IMAGE, V30, P87, DOI 10.1134/S1054661820010186
NR 29
TC 18
Z9 18
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 3173
EP 3192
DI 10.1007/s11042-020-09781-x
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000571253200009
DA 2024-07-18
ER

PT J
AU Alanazi, N
   Khan, E
   Gutub, A
AF Alanazi, Norah
   Khan, Esam
   Gutub, Adnan
TI Efficient security and capacity techniques for Arabic text steganography
   via engaging Unicode standard encoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arabic steganography; Letters Unicode; Capacity; Information security;
   Whitespace utilization; Kishida; Zero-width non-joiner; Zero-width
   joiner
AB Steganography is the science of hiding information messages in groups of irrelevant data possibly of another form. Despite of several Arabic text steganography techniques that have been proposed in the literature, there are only limited number of researches that showed high steganography quality in terms of capacity and security. In this paper, we present a novel approach for hiding the secret bits within Arabic text by engaging Unicode standard. Our methods rely on the use of contextual form of Arabic characters to hide certain secret bits showing interesting feedback. Moreover, extra characters such as Zero-width-Joiner or Zero-width-without-joiner, Kashida, and MMSP, are all also used to further enhance the capacity, while preserving acceptable security. Our testing results show that these proposed techniques outperform most reviewed existing methods to be practical, i.e. in order of both efficiency measures of capacity and security. Moreover, our techniques can be widely adopted due to the use of Unicode, in Arabic as well as Urdu Languages, which is opening the research field for the encoding standards to be utilized differently benefitting the ongoing evolving World's text writing systems.
C1 [Alanazi, Norah; Gutub, Adnan] Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
   [Khan, Esam] Umm Al Qura Univ, Custodian Two Holy Mosques Inst Hajj & Omrah Res, Mecca, Saudi Arabia.
C3 Umm Al Qura University; Umm Al Qura University
RP Gutub, A (corresponding author), Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
EM Noorah_1410@hotmail.com; eakhan@uqu.edu.sa; aagutub@uqu.edu.sa
RI Gutub, Adnan Abdul-Aziz/O-1240-2016
OI Gutub, Adnan Abdul-Aziz/0000-0003-0923-202X
FU Umm Al-Qura University (UQU)
FX The authors would like to thank Umm Al-Qura University (UQU) for all
   motivation and support toward this research. Thanks also for Al-Jouf
   University for this wonderful graduate studies cooperation giving Miss
   Norah Alanazi the chance to continue her MS research in the field of
   information security at UQU.
CR Aabed MA, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P756
   Abbasi A.T., 2015, AUSTR INF SEC MAN C
   Adnan G., 2010, Bahria University Journal of Information Communication Technology, V3, P68
   Ahmadoh Esraa Mohammad, 2015, Lecture Notes on Information Theory, V3, P42, DOI 10.18178/lnit.3.1.42-47
   Al-Haidari F, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P396, DOI 10.1109/AICCSA.2009.5069355
   Al-Nazer A, 2009, NSS: 2009 3RD INTERNATIONAL CONFERENCE ON NETWORK AND SYSTEM SECURITY, P447, DOI 10.1109/NSS.2009.21
   Al-Nofaie S., 2016, J COMPUTER SCI COMPU, V6, P59, DOI [10.20967/jcscm.2016.03.004, DOI 10.20967/jcscm.2016.03.004]
   Al-Nofaie S, 2021, J KING SAUD UNIV-COM, V33, P963, DOI 10.1016/j.jksuci.2019.06.010
   Alanazi N, 2020, J KING SAUD UNIV-COM, V34, P1343, DOI 10.1016/j.jksuci.2020.04.011
   Alhusban AM, 2017, INT J COMPUTER SCI I, V9
   Almutairi SM, 2020, INT J TECHNOL ENHANC, V12, P200
   Bensaad ML, 2013, ARAB J SCI ENG, V38, P2035, DOI 10.1007/s13369-013-0576-3
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P48, DOI 10.4304/jetwi.2.1.48-55
   Gutub A. A. A., 2007, INT J COMPUT ELECT A, V1, P502, DOI DOI 10.5281/ZENODO.1061621
   Gutub A, 2020, ARAB J SCI ENG, V45, P2631, DOI 10.1007/s13369-020-04413-w
   Gutub A, 2020, ARAB J SCI ENG, V45, P2433, DOI 10.1007/s13369-019-04010-6
   Gutub AA, 2010, KUWAIT J SCI ENG, V37, P89
   Gutub AAA, 2021, J KING SAUD UNIV-COM, V33, P1108, DOI 10.1016/j.jksuci.2019.06.014
   Gutub AAA, 2010, ISECURE-ISC INT J IN, V2, P107
   Hassan FS, 2022, J KING SAUD UNIV-COM, V34, P2017, DOI 10.1016/j.jksuci.2020.07.008
   Khan E., 2014, ASIAN J COMPUTER SCI, V4, DOI 10.15520/ajcsit.v4i6.2
   Mersal Samira, 2014, International Journal of Computer and Information Technology, V3, P441
   Obeidat A., 2017, J COMPUT SCI-NETH, V13, P184, DOI [10.3844/jcssp.2017.184.191, DOI 10.3844/JCSSP.2017.184.191]
   Odeh A., 2012, Systems, Applications and Technology Conference (LISAT), 2012 IEEE Long Island, Farmingdale State College - State University of New York, P1, DOI DOI 10.1109/LISAT.2012.6223209
   Odeh A., 2013, Systems, Applications and Technology Conference (LISAT), 2013 IEEE Long Island, P1
   Rabevohitra Feno Heriniaina, 2019, 2019 IEEE 19th International Conference on Communication Technology (ICCT), P1704, DOI 10.1109/ICCT46805.2019.8947188
   Roslan Nuur Alifah, 2011, Journal of Theoretical and Applied Information Technology, V33, P32
   Shaker A, 2017, INT J ADV COMPUTER S, V8
   Shirali-Shahreza Mohammad, 2008, 2008 IEEE Joint 6th National Conference on Telecommunication Technologies & 2nd Malaysia Conference on Photonics, P372, DOI 10.1109/NCTT.2008.4814305
   Shirali-Shahreza Mohammad, 2007, 2007 International Conference on Convergence Information Technology - ICCIT '07, P2260, DOI 10.1109/ICCIT.2007.100
   Shirali-Shahreza M, 2008, ADV COMPUTER INFORM
   Shirali-Shahreza MH, 2008, J THEORETICAL APPL I
   Shirali-Shahreza MH, 2010, ARABIC PERSIAN TEXT
   Shirali-Shahreza M, 2006, 2006 INNOVATIONS IN INFORMATION TECHNOLOGY, P310
NR 34
TC 22
Z9 22
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1403
EP 1431
DI 10.1007/s11042-020-09667-y
EA SEP 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566871600001
DA 2024-07-18
ER

PT J
AU Sharma, PK
   Basavaraju, S
   Sur, A
AF Sharma, Prasen Kumar
   Basavaraju, Sathisha
   Sur, Arijit
TI High-resolution image de-raining using conditional GAN with sub-pixel
   upscaling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image restoration; Deep learning; Conditional GAN
ID STREAKS REMOVAL; DECOMPOSITION; SYSTEMS
AB High-quality image de-raining is a challenging task that has been given considerable importance in recent times. To begin with, this problem is modeled as an image decomposition task where a rainy image is decomposed into the rain-free background and the associated rain streak map. Most of the existing methods have been successful in removing the rain-streaks but fails to restore the image quality, which is degraded due to noise removal. This paper proposes a novel architecture called High-Resolution Image De-Raining using Conditional Generative Adversarial Networks (HRID-GAN) to generate a de-rained image with minimal artifacts and better visual quality. Extensive experiments on publicly available synthetic as well as real-world datasets show a substantial improvement over the state-of-the-art methods SPANet (Wang et al.2019) by similar to 2.43%in PSNR and, DID-MDN (Zhang and Patel2018) by similar to 2.43%,similar to 10.12%and ID-CGAN (Zhang et al.2017) by similar to 11.80%,similar to 34.70%in SSIM and PSNR respectively.
C1 [Sharma, Prasen Kumar; Basavaraju, Sathisha; Sur, Arijit] Indian Inst Technol Guwahati, Gauhati, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Sharma, PK (corresponding author), Indian Inst Technol Guwahati, Gauhati, India.
EM kumar176101005@iitg.ac.in
RI Sharma, Prasen Kumar/ABG-8211-2020; Sur, Arijit/AAB-4216-2020
OI Sharma, Prasen Kumar/0000-0003-4847-8866; 
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Chang Y, 2017, IEEE I CONF COMP VIS, P1735, DOI 10.1109/ICCV.2017.191
   Chen DY, 2014, IEEE T CIRC SYST VID, V24, P1430, DOI 10.1109/TCSVT.2014.2308627
   Chen Q, 2017, IEEE T ELECTRON DEV, V64, P463, DOI 10.1109/TED.2016.2636322
   Chung H, 2018, IEEE W SP LANG TECH, P1, DOI [10.1109/SLT.2018.8639524, 10.1109/CACS.2018.8606774]
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Fu XY, 2017, IEEE T IMAGE PROCESS, V26, P2944, DOI 10.1109/TIP.2017.2691802
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Gu SH, 2017, IEEE I CONF COMP VIS, P1717, DOI 10.1109/ICCV.2017.189
   Haar A, 1910, MATH ANN, V69, P331, DOI 10.1007/BF01456326
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang DA, 2014, IEEE T MULTIMEDIA, V16, P83, DOI 10.1109/TMM.2013.2284759
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Kingma D. P., 2014, arXiv
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Li Y, 2017, IEEE T IMAGE PROCESS, V26, P3874, DOI 10.1109/TIP.2017.2708841
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lu XK, 2018, MULTIMED TOOLS APPL, V77, P15521, DOI 10.1007/s11042-017-5131-x
   Mao XJ, 2016, ADV NEUR IN, V29
   NASH JF, 1950, P NATL ACAD SCI USA, V36, P48, DOI 10.1073/pnas.36.1.48
   Odena A., 2016, DISTILL, V1, pe3, DOI 10.23915/distill.00003.-URL
   Qian R, 2018, PROC CVPR IEEE, P2482, DOI 10.1109/CVPR.2018.00263
   Ren WH, 2017, PROC CVPR IEEE, P2838, DOI 10.1109/CVPR.2017.303
   Sharma PK, 2020, IEEE WINT CONF APPL, P2344, DOI [10.1109/wacv45572.2020.9093528, 10.1109/WACV45572.2020.9093528]
   Sharma PK, 2019, IEEE IMAGE PROC, P2796, DOI [10.1109/icip.2019.8803353, 10.1109/ICIP.2019.8803353]
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shen L, 2018, ARXIVABS180106769
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sutskever I, 2014, ADV NEUR IN, V27
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang Jingya, 2018, CVPR
   Wang TY, 2019, PROC CVPR IEEE, P12262, DOI 10.1109/CVPR.2019.01255
   Wang YL, 2016, IEEE IMAGE PROC, P4087, DOI 10.1109/ICIP.2016.7533128
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Yang W., 2017, PROC CVPR IEEE, P1685, DOI DOI 10.1109/CVPR.2017.183
   Yeh CH, 2015, IEEE ICCE, P462, DOI 10.1109/ICCE-TW.2015.7216999
   Yu SJ, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P215, DOI 10.1109/ChinaSIP.2015.7230394
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
   Zhang H, 2017, IEEE WINT CONF APPL, P1259, DOI 10.1109/WACV.2017.145
   Zhang HG, 2020, IEEE T SYST MAN CY-S, V50, P3169, DOI 10.1109/TSMC.2018.2889377
   Zhu L, 2017, IEEE I CONF COMP VIS, P2545, DOI 10.1109/ICCV.2017.276
NR 54
TC 4
Z9 6
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1075
EP 1094
DI 10.1007/s11042-020-09642-7
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566665500006
DA 2024-07-18
ER

PT J
AU Sarkar, A
   Singh, BK
AF Sarkar, Arpita
   Singh, Binod K.
TI A multi-instance cancelable fingerprint biometric based secure session
   key agreement protocol employing elliptic curve cryptography and a
   double hash function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Cancelable template; Key agreement protocol; Elliptic curve
   cryptography; Network Security; Hash value
ID AUTHENTICATION SCHEME
AB The generation of cryptographic keys using the biometric features of both communicating parties throughout the sessions of communication avoids the process of key sharing through some insecure channel, difficulty in remembering the large key(256 or 1024 bits key), and storing the key in some safe place. At the same time preserving the safety of cryptographic keys. Nonetheless, the biometric-based cryptographic key formation contains few matters so as the secrecy of biometrics, distributing biometric data among both communicating users, and creating the revocable key of irrevocable biometric. The present work discusses the above-mentioned concerns. Here a structure for a reliable session key agreement protocol has been suggested. For this, communication a 256-bit session key is created by both communicating parties at their end. For the generation of the 256-bit key, each of the left and right thumb was captured in each session. The right thumb impressions of the communicating parties are used to generate the cancelable fingerprint biometric s and the left thumb impressions of each communicating parties are used to generate a 64-bit hash value by applying the proposed double hash function. After that both communicating parties generate secret value using elliptic curve cryptography from their cancelable biometrics data and share along with the generated hash value. At the end of the process generated secret value and the hash value are concatenated to generate the revocable key for session key agreement protocol. For better performance and security purposes, all the actions of this protocol are based on elliptic curve cryptography. Proposed protocol precludes undesired third-parties from requiring a key selection on this agreeing parties. Based on the experimental evaluation across four datasets of FVC2002, the proposed structure is privacy-preserving and is excellently fitting for various real-time biometric-based applicability.
C1 [Sarkar, Arpita; Singh, Binod K.] Natl Inst Technol, Dept Comp Sci & Engn, Jamshedpur, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Sarkar, A (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Jamshedpur, Jharkhand, India.
EM 24arpitasarkar@gmail.com; bksingh.cse@nitjsr.ac.in
RI Sarkar, Arpita/JFL-1710-2023; Singh, Binod/AAB-8663-2019
OI Singh, Binod/0000-0002-2697-8918
CR Al-Maytami BA, 2020, AD HOC NETW, V98, DOI 10.1016/j.adhoc.2019.102028
   Alloghani M, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102362
   [Anonymous], 2016, PROC 8 IFIP INT C NE
   Baker T, 2020, SOFTWARE PRACT EXPER, V50, P503, DOI 10.1002/spe.2688
   Barman S, 2015, COMPUTERS ELECT ENG
   Barman S, 2015, EURASIP J INF SECUR, DOI 10.1186/s13635-015-0020-1
   Barman S, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1629, DOI 10.1109/ICACCI.2014.6968299
   Chaudhry SA, 2016, MULTIMED TOOLS APPL, V75, P12705, DOI 10.1007/s11042-015-3194-0
   Feng Q, 2018, FUTURE GENER COMP SY, V84, P239, DOI 10.1016/j.future.2017.07.040
   Guo FC, 2016, IEEE T INF FOREN SEC, V11, P247, DOI 10.1109/TIFS.2015.2489179
   He DB, 2013, ARAB J SCI ENG, V38, P2055, DOI 10.1007/s13369-013-0575-4
   Islam SKH, 2017, J KING SAUD UNIV-COM, V29, P311, DOI 10.1016/j.jksuci.2015.08.002
   Jiang Q, 2016, NONLINEAR DYNAM, V83, P2085, DOI 10.1007/s11071-015-2467-5
   Jin Z, 2016, PATTERN RECOGN, V56, P50, DOI 10.1016/j.patcog.2016.02.024
   Kaur H, 2020, FUTURE GENER COMP SY, V102, P30, DOI 10.1016/j.future.2019.07.023
   Khan MK, 2011, COMPUT COMMUN, V34, P305, DOI 10.1016/j.comcom.2010.02.011
   Khan MK, 2010, SENSORS-BASEL, V10, P2450, DOI 10.3390/s100302450
   Kumari S, 2017, FUTURE GENER COMP SY, V68, P320, DOI 10.1016/j.future.2016.10.004
   Li C, 2016, IEEE T INF FOREN SEC, V11, P543, DOI 10.1109/TIFS.2015.2505630
   Li X, 2018, J NETW COMPUT APPL, V103, P194, DOI 10.1016/j.jnca.2017.07.001
   Lin Y, 2017, CHINESE J ELECTRON, V26, P236
   Panchal G, 2017, ADV INTELLIGENT SYST, V507
   Panchal G, 2019, MULTIMED TOOLS APPL, V78, P26979, DOI 10.1007/s11042-017-4528-x
   Panchal G, 2018, COMPUT ELECTR ENG, V69, P461, DOI 10.1016/j.compeleceng.2018.01.028
   Pu Q, 2009, 2009 INTERNATIONAL CONFERENCE ON RESEARCH CHALLENGES IN COMPUTER SCIENCE, ICRCCS 2009, P7, DOI 10.1109/ICRCCS.2009.11
   Rukhin A., 2010, NATL I STANDARDTEC, V800
   Sarkar A., 2018, 2018 4 INT C REC ADV, P1
   Sarkar A, 2019, P NUTR SOC, V78, P329, DOI 10.1017/S0029665118002768
   Sarkar A, 2019, MULTIMED TOOLS APPL, V78, P21645, DOI 10.1007/s11042-019-7426-6
   Sarkar A, 2018, ADV INTELL SYST, V710, P265, DOI 10.1007/978-981-10-7871-2_26
   Stallings W., 2010, CRYPTOGRAPHY NETWORK, V5e
   Tan, 2010, J CONVERGENCE INF TE, V5, P120, DOI [10.4156/jcit.vol5.issue4.13, DOI 10.4156/JCIT.VOL5.ISSUE4.13]
   Usha S, 2018, CYBERN INF TECHNOL, V18, P61, DOI 10.2478/cait-2018-0048
   Vivekanandan M, 2019, 2019 5TH IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY, AND BEHAVIOR ANALYSIS (ISBA 2019), DOI 10.1109/isba.2019.8778529
   Yang JH, 2009, J SYST SOFTWARE, V82, P1497, DOI 10.1016/j.jss.2009.03.075
   Zuowen Tan, 2010, Journal of Communications, V5, P436, DOI 10.4304/jcm.5.5.436-443
NR 36
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 799
EP 829
DI 10.1007/s11042-020-09375-7
EA SEP 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566318900005
DA 2024-07-18
ER

PT J
AU Kollem, S
   Reddy, KR
   Rao, DS
AF Kollem, Sreedhar
   Reddy, Katta Ramalinga
   Rao, Duggirala Srinivasa
TI An optimized SVM based possibilistic fuzzy c-means clustering algorithm
   for tumor segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nonsubsampled contourlet transform; Partial differential equations;
   Possibilistic fuzzy C-means clustering; Support vector machine; Grey
   wolf optimization
ID CONTOURLET TRANSFORM; BRAIN; DESIGN; FILTER
AB To design an efficient partial differential equation-based total variation method for denoising and possibilistic fuzzy c-means clustering algorithm for segmentation and these methods presented the more detailed information of the MRI medical images compared to traditional methods. In this article, the pipeline of the proposed method described by two modules like pre-processing and segmentation. In pre-processing, noisy image is decomposed using nonsubsampled contourlet transform and it contains highpass contourlet coefficient (i.e., noisy coefficient) is removed by the threshold method as well. After reconstruction, the primary denoised image is enhanced by an improved partial differential equation-based total variation method in terms of image details like edges, boundaries, etc. In segmentation, the enhanced primary denoised image is segmented by an improved possibilistic fuzzy c-means clustering algorithm that avoids limitations in possibilistic c-means, fuzzy c-means, and K-means clustering. Next, a support vector machine classifier is utilized to identify brain tissues into gray matter, white matter, cerebrospinal fluid, and tumor part. The parameters were optimally selected by a grey wolf optimization algorithm for the classification of brain tissues. The performance of the proposed method is computed with reference to peak signal-to-noise ratio, mean square error, structural similarity index, sensitivity, specificity, and accuracy. The experimental results claimed that the proposed method is better than the traditional methods.
C1 [Kollem, Sreedhar] SR Univ, Sch Engn, Dept ECE, Warangal 506371, Telangana, India.
   [Reddy, Katta Ramalinga] G Narayanamma Inst Technol & Sci, Dept ETM, Hyderabad 500104, Telangana, India.
   [Rao, Duggirala Srinivasa] JNTUH Coll Engn, Dept ECE, Hyderabad 500085, Telangana, India.
   [Kollem, Sreedhar] JNTUH Univ, Dept ECE, Res Scholar, Hyderabad 500085, Telangana, India.
C3 Jawaharlal Nehru Technological University - Hyderabad; Jawaharlal Nehru
   Technological University - Hyderabad
RP Kollem, S (corresponding author), SR Univ, Sch Engn, Dept ECE, Warangal 506371, Telangana, India.; Kollem, S (corresponding author), JNTUH Univ, Dept ECE, Res Scholar, Hyderabad 500085, Telangana, India.
EM ksreedhar446@gmail.com
RI Katta, Ramalinga Reddy/AAD-8597-2021; Kollem, S/GPT-4725-2022; Kollem,
   S/GQQ-3144-2022; Kollem, Sreedhar/AAT-3764-2020
OI Katta, Ramalinga Reddy/0000-0002-4649-4187; Kollem,
   S/0000-0002-9203-0404; Kollem, S/0000-0002-9203-0404; 
CR Ananthi VP, 2016, SOFT COMPUT, V20, P4859, DOI 10.1007/s00500-015-1775-5
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Dubey YK, 2016, BIOCYBERN BIOMED ENG, V36, P413, DOI 10.1016/j.bbe.2016.01.001
   Eswaramoorthy S, 2016, COMPEL, V35, P1513, DOI 10.1108/COMPEL-09-2015-0337
   Hajiaboli MR, 2011, INT J COMPUT VISION, V92, P177, DOI 10.1007/s11263-010-0330-1
   Irum I, 2015, J Eng Sci Technol Rev, V8, P41
   Ji ZX, 2011, COMPUT MED IMAG GRAP, V35, P383, DOI 10.1016/j.compmedimag.2010.12.001
   Kalaiselvi T, 2018, INT J IMAG SYST TECH, V28, P163, DOI 10.1002/ima.22267
   Kollem S, 2021, MULTIMED TOOLS APPL, V80, P2663, DOI 10.1007/s11042-020-09745-1
   Kollem S, 2020, INT J IMAG SYST TECH, V30, P1271, DOI 10.1002/ima.22429
   Kollem S, 2019, INT J IMAG SYST TECH, V29, P195, DOI 10.1002/ima.22302
   Korti A, 2018, INT J IMAG SYST TECH, V28, P92, DOI 10.1002/ima.22260
   Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P98, DOI 10.1109/91.227387
   Liu X, 2020, IEEE T IND INFORM, V16, P5379, DOI 10.1109/TII.2019.2947435
   Liu X, 2019, IEEE INTERNET THINGS, V6, P5962, DOI 10.1109/JIOT.2018.2847731
   Magnin B, 2009, NEURORADIOLOGY, V51, P73, DOI 10.1007/s00234-008-0463-x
   Meng XY, 2017, MULTIMED TOOLS APPL, V76, P17651, DOI 10.1007/s11042-015-2881-1
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Nambura A, 2017, APPL SOFT COMPUT, V54, P456, DOI 10.1016/j.asoc.2016.08.020
   Nnolim UA, 2017, INT J IMAGE GRAPH, V17, DOI 10.1142/S0219467817500048
   Phophalia A, 2015, APPL SOFT COMPUT, V33, P1, DOI 10.1016/j.asoc.2015.04.005
   Rajaguru H, 2016, INT J IMAG SYST TECH, V26, P196, DOI 10.1002/ima.22177
   Roy Provas Kumar, 2014, International Journal of Power and Energy Conversion, V5, P47, DOI 10.1504/IJPEC.2014.059983
   Rufus NHA, 2018, INT J IMAG SYST TECH, V28, P77, DOI 10.1002/ima.22258
   Sam BB, 2018, MULTIMED TOOLS APPL, V77, P30205, DOI 10.1007/s11042-018-6088-0
   Tian C, 2020, IEEE SENS J, V20, P11935, DOI 10.1109/JSEN.2019.2959704
   Wang DH, 2016, INT J COMPUT MATH, V93, P942, DOI 10.1080/00207160.2015.1011144
   Zhang CJ, 2016, ENG APPL ARTIF INTEL, V48, P204, DOI 10.1016/j.engappai.2015.10.008
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
NR 33
TC 11
Z9 11
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 409
EP 437
DI 10.1007/s11042-020-09675-y
EA SEP 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565837600007
DA 2024-07-18
ER

PT J
AU Kim, S
   Kim, D
   Ahn, H
   Ahn, B
AF Kim, Shinyoung
   Kim, Dohyeon
   Ahn, HyungGeun
   Ahn, Byeongtae
TI Implementation of user playstyle coaching using video processing and
   statistical methods in league of legends
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LoL game; Video processing; Coaching education; Deep learning; Playstyle
ID SOCIAL MEDIA; ENGAGEMENT
AB Recently, the game market is growing rapidly with the growth of e-sports. In particular, the market for League of Legends games continues to grow. Massively Online Battle Arena (MOBA) games have grown to become a massive industry, projected to reach over 140 billion USD worth of market value. Many users learn the League of Legends game, but their skills do not improve. Current analysis of the player's manual playback through visual media such as video is the most common method. Therefore, this paper extracts data from gameplay videos and analyzes intuitive gameplay "styles" in the popular MMO game League of Legends to provide coaching-specific information. we were able to classify whether the player is cooperative and aggressive, but if additional information which we did not extract nor process like map vision were taken into account, Big Data and Machine Learning could come into play.
C1 [Kim, Shinyoung] Boin High Sch, 18 Ogeum Ro 49 Gil, Seoul, South Korea.
   [Kim, Dohyeon] PlayAuto Inc, 18 Ogeum Ro 49 Gil, Seoul, South Korea.
   [Ahn, HyungGeun] Sungkyunkwan Univ, 25-2 Sungkyunkwan Ro,Myeongnyun 3 Sam Ga Dong, Seoul, South Korea.
   [Ahn, Byeongtae] Anyang Univ, Liberal & Arts Coll, Anyang, South Korea.
C3 Sungkyunkwan University (SKKU); Anyang University
RP Ahn, B (corresponding author), Anyang Univ, Liberal & Arts Coll, Anyang, South Korea.
EM tttllshin@gmail.com; nonamep@setsuna.kr; ahg2230@gmail.com;
   ahnbt@anyang.ac.kr
OI Ahn, Byeong-Tae/0000-0003-3431-9493
CR [Anonymous], 2016, IEEE GAM ENT MED C, DOI DOI 10.1109/GEM.2015.7377227
   Aran O, 2014, IEEE T MULTIMEDIA, V16, P201, DOI 10.1109/TMM.2013.2284893
   Bermejo F, 2009, NEW MEDIA SOC, V11, P133, DOI 10.1177/1461444808099579
   Bucher T, 2017, AFFORDANCES SOCIAL M, P233
   Cha H, 2007, MOONI TUBE YOU TUBE, DOI [10.1145/1298306.1298309, DOI 10.1145/1298306.1298309]
   Chau Clement, 2010, New Dir Youth Dev, V2010, P65, DOI 10.1002/yd.376
   Chen YS, 2017, Int J Soc Humanist Comput, V2, P261, DOI [10.1504/IJSHC.2017.084760, DOI 10.1504/IJSHC.2017.084760]
   Churchill BCB, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCES ON BIG DATA AND CLOUD COMPUTING (BDCLOUD 2016) SOCIAL COMPUTING AND NETWORKING (SOCIALCOM 2016) SUSTAINABLE COMPUTING AND COMMUNICATIONS (SUSTAINCOM 2016) (BDCLOUD-SOCIALCOM-SUSTAINCOM 2016), P223, DOI 10.1109/BDCloud-SocialCom-SustainCom.2016.43
   Costa LM, 2019, BRAZIL SYMP GAME DIG, P52, DOI 10.1109/SBGames.2019.00018
   Deuze M., 2006, JOURNALISM, V7, P262, DOI DOI 10.1177/1464884906065512
   Evren T, 2019, J INT SOCIAL RES, V12, P1423, DOI [10.17719/jisr.2019.3682, DOI 10.17719/JISR.2019.3682]
   Festinger L, 1954, HUM RELAT, V7, P117, DOI 10.1177/001872675400700202
   Fuchs C, 2014, TIME SOC, V23, P97, DOI 10.1177/0961463X13502117
   Gandolfi E, 2016, J GAMING VIRTUAL WOR, V8, P63, DOI 10.1386/jgvw.8.1.63_1
   Gaver W. W., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P79, DOI 10.1145/108844.108856
   Gaver WW, 1996, ECOL PSYCHOL, V8, P111, DOI 10.1207/s15326969eco0802_2
   Grave Jan-Frederik., 2017, P 8 INT C SOCIAL MED, V36, P1, DOI [DOI 10.1145/3097286.3097322, 10.1145/3097286.3097322]
   Haimson OL, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P48, DOI 10.1145/3025453.3025642
   Hamari J, 2017, COMPUT HUM BEHAV, V71, P469, DOI 10.1016/j.chb.2015.03.036
   Hamari J, 2014, P ANN HICSS, P3025, DOI 10.1109/HICSS.2014.377
   Hamari J, 2013, ELECTRON COMMER R A, V12, P236, DOI 10.1016/j.elerap.2013.01.004
   Hamilton WA, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1315, DOI 10.1145/2556288.2557048
   Hilvert-Bruce Z, 2018, COMPUT HUM BEHAV, V84, P58, DOI 10.1016/j.chb.2018.02.013
   Holland Margaret., 2016, ELON J UNDERGRADUATE, V7
   Hou J, 2020, INT J SPORT COMMUN, V13, P1, DOI 10.1123/ijsc.2019-0060
   Joinson AN, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1027
   Kaytoue M., 2012, Proceedings of the 21st International Conference Companion on World Wide Web-WWW'12 Companion, P1181, DOI [DOI 10.1145/2187980.2188259, 10.1145/2187980.2188259]
   Khamis S, 2017, CELEBR STUD, V8, P191, DOI 10.1080/19392397.2016.1218292
   Khan ML, 2017, COMPUT HUM BEHAV, V66, P236, DOI 10.1016/j.chb.2016.09.024
   Kim J, 2012, MEDIA CULT SOC, V34, P53, DOI 10.1177/0163443711427199
   Sharahina LV, 2018, SAINT PETERSBURG ELE, P85
   Sharma MK, 2018, ASIAN J PSYCHIATR, V34, P16, DOI 10.1016/j.ajp.2018.03.019
   Zheng X, 2017, INT J SOC HUMANIST C, V2, P141, DOI [10.1504/IJSHC.2017.084732, DOI 10.1504/IJSHC.2017.084732]
NR 33
TC 6
Z9 6
U1 2
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34189
EP 34201
DI 10.1007/s11042-020-09413-4
EA AUG 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000562360200006
DA 2024-07-18
ER

PT J
AU Singh, AK
   Gupta, I
AF Singh, Ashutosh Kumar
   Gupta, Ishu
TI Online information leaker identification scheme for secure data sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Average success rate; Business's data; Cloud computing; Data leakage;
   Detection rate; Distribution strategy; Information security; Malicious
   user; Time instance
ID RELATIONAL DATABASES; ALGORITHM
AB This paper proposes a novel scheme for the leaker identification that deals with the dynamic scenario by handling the requests of the users in an online custom. A distribution strategy is introduced having less risk associated with exposing the data and furthermore improves the likelihood of identifying the leaker when the information is revealed by the malicious user. The observed results signify an improvement of up to 41%, 368%, and 318% for average probability, average success rate, and detection rate respectively compared to the prior work. Also, the proposed framework significantly minimizes the possibility of data leakage up to 88% and synchronously achieves a 100% efficacy rate.
C1 [Singh, Ashutosh Kumar; Gupta, Ishu] Natl Inst Technol Kurukshetra, Kurukshetra, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Gupta, I (corresponding author), Natl Inst Technol Kurukshetra, Kurukshetra, Haryana, India.
EM ashutosh@nitkkr.ac.in; ishugupta23@gmail.com
RI Singh, Ashwani/GQP-2566-2022; Singh, Ashok K/HGF-2506-2022; Singh,
   Anil/JUU-2219-2023
FU University Grants Commission (UGC), Government of India
FX The authors would like to thank all the anonymous reviewers for their
   valuable comments. This work was financially supported by the University
   Grants Commission (UGC), Government of India.
CR Al-Fedaghi SS, 2018, INT J ADV COMPUT SC, V9, P101
   Ali M, 2017, IEEE SYST J, V11, P395, DOI 10.1109/JSYST.2014.2379646
   Assale M, 2019, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00066
   Backes M, 2016, IEEE T DEPEND SECURE, V13, P178, DOI 10.1109/TDSC.2015.2399296
   Bertino E, 2013, WORKSH SEC DAT MAN, P9
   Blesswin AJ, 2020, MULTIMED TOOLS APPL, V79, P17057, DOI 10.1007/s11042-019-7535-2
   Cheng L, 2017, WIRES DATA MIN KNOWL, V7, DOI 10.1002/widm.1211
   Fang Y, 2019, IEEE ACCESS, V7, P48770, DOI 10.1109/ACCESS.2019.2910229
   Guevara C, 2017, KNOWL-BASED SYST, V120, P236, DOI 10.1016/j.knosys.2017.01.009
   Gupta I, 2019, J COMMUN SOFTW SYST, V15
   Gupta I, 2020, J INFORM SCI ENG
   Gupta I., 2020, INT J ADV SCI TECHNO, V135, P49, DOI DOI 10.33832/IJAST.2020.135.05
   Gupta I, 2019, INFORM PROCESS LETT, V147, P69, DOI 10.1016/j.ipl.2019.03.005
   Gupta I, 2018, PROCEDIA COMPUT SCI, V125, P662, DOI 10.1016/j.procs.2017.12.085
   Harel A, 2012, IEEE T DEPEND SECURE, V9, P414, DOI 10.1109/TDSC.2012.17
   IBM, 2018, PON COST DAT BREACH
   Jero SE, 2016, ELECTRON LETT, V52, P283, DOI 10.1049/el.2015.3218
   Kieseberg Peter, 2016, Brain Inform, V3, P269, DOI 10.1007/s40708-016-0046-2
   Kieseberg P, 2015, LECT NOTES ARTIF INT, V9250, P369, DOI 10.1007/978-3-319-23344-4_36
   Kieseberg P, 2014, ELECTRON MARK, V24, P113, DOI 10.1007/s12525-014-0154-x
   Kumar N, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS, P803, DOI 10.1109/CICN.2014.172
   Li YJ, 2005, IEEE T DEPEND SECURE, V2, P34, DOI 10.1109/TDSC.2005.12
   Nag A, 2020, MULTIMED TOOLS APPL, V79, P16219, DOI 10.1007/s11042-019-07807-7
   Papadimitriou P, 2011, IEEE T KNOWL DATA EN, V23, P51, DOI 10.1109/TKDE.2010.100
   Popper N., 2017, SNE Simulation Notes Europe, V27, P203, DOI [10.11128/sne.27.tn.10396, DOI 10.11128/SNE.27.TN.10396]
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Shabtai A, 2012, SPRINGERBRIEF COMPUT, P1, DOI 10.1007/978-1-4614-2053-8
   Shehab M, 2008, IEEE T KNOWL DATA EN, V20, P116, DOI 10.1109/TKDE.2007.190668
   Shen WT, 2019, IEEE T INF FOREN SEC, V14, P331, DOI 10.1109/TIFS.2018.2850312
   Shu XK, 2016, IEEE T INF FOREN SEC, V11, P528, DOI 10.1109/TIFS.2015.2503271
   Shu XK, 2015, IEEE T INF FOREN SEC, V10, P1092, DOI 10.1109/TIFS.2015.2398363
   Wei JH, 2018, IEEE T CLOUD COMPUT, V6, P1136, DOI 10.1109/TCC.2016.2545668
   Xu SM, 2018, IEEE T INF FOREN SEC, V13, P2101, DOI 10.1109/TIFS.2018.2810065
   Yoon-Su J, 2020, MULTIMED TOOLS APPL, V79, P16593, DOI 10.1007/s11042-019-07833-5
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zaghloul E., 2019, IEEE TRANS BIG DATA, P1
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
NR 38
TC 9
Z9 9
U1 6
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31165
EP 31182
DI 10.1007/s11042-020-09470-9
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560998800002
DA 2024-07-18
ER

PT J
AU Beddiar, DR
   Nini, B
   Sabokrou, M
   Hadid, A
AF Beddiar, Djamila Romaissa
   Nini, Brahim
   Sabokrou, Mohammad
   Hadid, Abdenour
TI Vision-based human activity recognition: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; Behavior understanding; Action
   representation; Action detection; Computer Vision; Survey
ID HUMAN MOTION ANALYSIS; GESTURE RECOGNITION; RECOGNIZING ACTIONS;
   ACTIONLET ENSEMBLE; VIDEO SURVEILLANCE; ABNORMAL-BEHAVIOR; KINECT
   SENSOR; HAND POSTURE; MULTIVIEW; NETWORKS
AB Human activity recognition (HAR) systems attempt to automatically identify and analyze human activities using acquired information from various types of sensors. Although several extensive review papers have already been published in the general HAR topics, the growing technologies in the field as well as the multi-disciplinary nature of HAR prompt the need for constant updates in the field. In this respect, this paper attempts to review and summarize the progress of HAR systems from the computer vision perspective. Indeed, most computer vision applications such as human computer interaction, virtual reality, security, video surveillance and home monitoring are highly correlated to HAR tasks. This establishes new trend and milestone in the development cycle of HAR systems. Therefore, the current survey aims to provide the reader with an up to date analysis of vision-based HAR related literature and recent progress in the field. At the same time, it will highlight the main challenges and future directions.
C1 [Beddiar, Djamila Romaissa; Nini, Brahim] Larbi Ben Mhidi Univ, Res Lab Comp Sci Complex Syst, Oum El Bouaghi, Algeria.
   [Sabokrou, Mohammad] Inst Res Fundamental Sci IPM, Sch Comp Sci, Tehran, Iran.
   [Beddiar, Djamila Romaissa; Hadid, Abdenour] Univ Oulu, Ctr Machine Vis Res Comp Sci & Engn, Oulu, Finland.
C3 Universite d'Oum El Bouaghi; University of Oulu
RP Beddiar, DR (corresponding author), Larbi Ben Mhidi Univ, Res Lab Comp Sci Complex Syst, Oum El Bouaghi, Algeria.; Beddiar, DR (corresponding author), Univ Oulu, Ctr Machine Vis Res Comp Sci & Engn, Oulu, Finland.
EM ad_beddiar@esi.dz
RI Sabokrou, Mohammad/AGO-5234-2022; Sabokrou, Mohammad/AAI-3766-2020;
   Beddiar, Romaissa/E-1591-2017
OI Sabokrou, Mohammad/0000-0002-9409-2799; Beddiar,
   Romaissa/0000-0002-1371-3881
FU University of Oulu including Oulu University Hospital
FX Open access funding provided by University of Oulu including Oulu
   University Hospital.
CR Afiq AA, 2019, J VIS COMMUN IMAGE R, V58, P285, DOI 10.1016/j.jvcir.2018.11.035
   Aggarwal, 2010, IEEE International Conference on Pattern Recognition Workshops, P4
   Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   Ahmad M, 2008, PATTERN RECOGN, V41, P2237, DOI 10.1016/j.patcog.2007.12.008
   Ahsan U., 2018, ARXIV180107230
   Akansha UA, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P3839
   Alevizos E, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3117809
   Ali A, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P28, DOI 10.1109/EVENT.2001.938863
   Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284
   Almubarak H, 2019, INT J HEALTHC INF SY, V14, P66, DOI 10.4018/IJHISI.2019040105
   Amirbandi EJ, 2016, 2016 1ST CONFERENCE ON SWARM INTELLIGENCE AND EVOLUTIONARY COMPUTATION (CSIEC 2016), P160, DOI 10.1109/CSIEC.2016.7482122
   Angelini F, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4219, DOI 10.1109/ICASSP.2018.8461472
   [Anonymous], 2018, ARXIV180200761
   [Anonymous], ARXIV150105964
   [Anonymous], 2018, PATTERN RECOGNITION
   [Anonymous], 2009, IEEE C COMP VIS PATT
   [Anonymous], 2013, ARXIV13102053
   Antoshchuk Svitlana., 2018, Digitisation of Culture: Namibian and International Perspectives, P269
   Argyros AA, 2006, INT C PATT RECOG, P207
   Asadi-Aghbolaghi M, 2017, IEEE INT CONF AUTOMA, P476, DOI 10.1109/FG.2017.150
   Ballan Lamberto, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P506, DOI 10.1109/ICCVW.2009.5457658
   Beddiar Djamila Romaissa, 2017, 2017 8th International Conference on Information Technology (ICIT). Proceedings, P548, DOI 10.1109/ICITECH.2017.8080057
   Ben Youssef M, 2016, INT J HUMAN MACHINE
   Bhardwaj R, 2016, 2016 6TH INTERNATIONAL CONFERENCE - CLOUD SYSTEM AND BIG DATA ENGINEERING (CONFLUENCE), P531, DOI 10.1109/CONFLUENCE.2016.7508177
   Borges PVK, 2013, IEEE T CIRC SYST VID, V23, P1993, DOI 10.1109/TCSVT.2013.2270402
   Bour P, 2019, COMPUT VIS PATT REC, P289, DOI 10.1016/B978-0-12-814601-9.00023-7
   Bux A, 2017, THESIS
   Bux A, 2017, ADV INTELL SYST COMP, V513, P341, DOI 10.1007/978-3-319-46562-3_23
   Cao YP, 2019, INFORM FUSION, V46, P206, DOI 10.1016/j.inffus.2018.06.005
   Chahuara P, 2012, RFIA 2012 RECONNAISS
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Chaudhry R, 2013, IEEE COMPUT SOC CONF, P471, DOI 10.1109/CVPRW.2013.153
   Chen C.C., 2010, UT TOWER DATASET AER
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Cheng H, 2016, IEEE T CIRC SYST VID, V26, P1659, DOI 10.1109/TCSVT.2015.2469551
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Chu WT, 2019, LECT NOTES COMPUT SC, V11295, P640, DOI 10.1007/978-3-030-05710-7_53
   Chu WQ, 2019, IEEE T MULTIMEDIA, V21, P246, DOI 10.1109/TMM.2018.2846411
   Cornacchia M, 2017, IEEE SENS J, V17, P386, DOI 10.1109/JSEN.2016.2628346
   Denina G, 2011, DISTRIBUTED VIDEO SENSOR NETWORKS, P335, DOI 10.1007/978-0-85729-127-1_23
   Dhiman C, 2019, ENG APPL ARTIF INTEL, V77, P21, DOI 10.1016/j.engappai.2018.08.014
   Díaz-Rodríguez N, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2523819
   Dixon S, 2018, HUMAN ACTIVITY WORKF
   Doersch Carl, 2016, ARXIV160605908
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Nguyen DT, 2016, PATTERN RECOGN, V51, P148, DOI 10.1016/j.patcog.2015.08.027
   Edwards M, 2016, COMPUT VIS IMAGE UND, V144, P73, DOI 10.1016/j.cviu.2015.10.010
   Escalera S, 2017, SPRING SER CHALLENGE, P1, DOI 10.1007/978-3-319-57021-1_1
   Firman M, 2016, IEEE COMPUT SOC CONF, P661, DOI 10.1109/CVPRW.2016.88
   Forsyth DA, 2005, FOUND TRENDS COMPUT, V1, P77, DOI 10.1561/0600000005
   Fothergill S., 2012, P SIGCHI C HUM FACT, P1737, DOI DOI 10.1145/2207676.2208303
   Fu JT, 2017, IEEE/SICE I S SYS IN, P547, DOI 10.1109/SII.2017.8279278
   Fu YW, 2014, IEEE T PATTERN ANAL, V36, P303, DOI 10.1109/TPAMI.2013.128
   Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872
   GAO ZY, 2011, VISUAL ANAL HUMANS, P411
   Garcia-Ceja E, 2018, INFORM FUSION, V40, P45, DOI 10.1016/j.inffus.2017.06.004
   Gavrilova ML, 2018, IEEE CONSUM ELECTR M, V7, P88, DOI 10.1109/MCE.2017.2755498
   Ghorbel E, 2018, IMAGE VISION COMPUT, V77, P60, DOI 10.1016/j.imavis.2018.06.004
   Gleick J, 1992, PHYS TODAY, P45
   Gonzalez L, 2018, SILHOUETTE BASED HUM
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Goyani M., 2017, Indian J. Sci. Technol, V10, P9, DOI DOI 10.17485/ijst/2017/v10i9/108944
   Grant JM, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3052930
   Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018
   Guo YL, 2014, C IND ELECT APPL, P1846, DOI 10.1109/ICIEA.2014.6931468
   Hammouche M., 2016, INT JOINT C COMP VIS
   Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Haria A, 2017, PROCEDIA COMPUT SCI, V115, P367, DOI 10.1016/j.procs.2017.09.092
   Hassner T, 2013, IEEE COMPUT SOC CONF, P245, DOI 10.1109/CVPRW.2013.43
   Heilbron Fabian Caba, 2015, C COMP VIS PATT REC
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Ijjina EP, 2017, PATTERN RECOGN, V72, P504, DOI 10.1016/j.patcog.2017.07.013
   Inkawhich N., 2018, ARXIV181111875
   Islam S, 2018, SIGNAL IMAGE VIDEO P, V12, P853, DOI 10.1007/s11760-017-1228-y
   Jadooki S, 2017, NEURAL COMPUT APPL, V28, P3285, DOI 10.1007/s00521-016-2244-5
   Kang S., 2016, CoRR
   Kang WX, 2007, 6TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, PROCEEDINGS, P824, DOI 10.1109/ICIS.2007.157
   Kay W., 2017, ARXIV170506950
   Ke SR, 2013, COMPUTERS, V2, P88, DOI 10.3390/computers2020088
   Kliper-Gross O, 2012, IEEE T PATTERN ANAL, V34, P615, DOI 10.1109/TPAMI.2011.209
   Kong Y, 2014, IEEE T PATTERN ANAL, V36, P1775, DOI 10.1109/TPAMI.2014.2303090
   Krüger V, 2007, ADV ROBOTICS, V21, P1473
   Kuehne H., 2011, P INT C COMP VIS
   Kuehne H, 2016, IEEE WINT CONF APPL
   Kuehne H, 2014, PROC CVPR IEEE, P780, DOI 10.1109/CVPR.2014.105
   Kumar V, 2018, P 3 INT C INT THINGS, P26
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li CY, 2019, PATTERN RECOGN, V85, P161, DOI 10.1016/j.patcog.2018.08.005
   Li JX, 2019, INFORM FUSION, V45, P215, DOI 10.1016/j.inffus.2018.02.005
   Li W., 2016, ARXIV161002455
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li YQ, 2015, PATTERN RECOGN, V48, P3417, DOI 10.1016/j.patcog.2015.04.022
   Li ZY, 2018, COMPUT VIS IMAGE UND, V166, P41, DOI 10.1016/j.cviu.2017.10.011
   Liang YJ, 2014, MOBILE NETW APPL, V19, P303, DOI 10.1007/s11036-013-0448-9
   Lin WY, 2016, IEEE T IMAGE PROCESS, V25, P1674, DOI 10.1109/TIP.2016.2531281
   Lin Z, 2009, IEEE I CONF COMP VIS, P444
   Liu AA, 2019, IEEE T IMAGE PROCESS, V28, P853, DOI 10.1109/TIP.2018.2872879
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Liu L, 2018, PATTERN RECOGN, V81, P545, DOI 10.1016/j.patcog.2018.04.022
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Liu SL, 2016, PROC SPIE, V9897, DOI 10.1117/12.2230495
   Liu TT, 2018, ICAIP 2018: 2018 THE 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN IMAGE PROCESSING, P198, DOI 10.1145/3239576.3239619
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Lopes HCT, 2017, CONTEXTUAL GAME DESI
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Lun R, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415550083
   Ma SG, 2018, INT J COMPUT VISION, V126, P314, DOI 10.1007/s11263-016-0980-8
   Machado IP, 2015, INFORM PROCESS MANAG, V51, P204, DOI 10.1016/j.ipm.2014.07.008
   Mademlis I, 2019, LECT NOTES COMPUT SC, V11295, P578, DOI 10.1007/978-3-030-05710-7_48
   Mao Ye, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P149, DOI 10.1007/978-3-642-44964-2_8
   Mathieu M., 2015, PROC INT C LEARN REP
   Mavroudi E, 2018, ARXIV180109571
   Minnen D., 2006, Perform. Metr. Intell. Syst, P141
   Mirchev A, 2018, ARXIV180108712
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Mollet N, 2005, 2005 3 INT C SETIT
   Murthy G.R.S., 2009, International Journal of Information Technology and Knowledge Management, V2, P405
   Negin F, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P37, DOI 10.1109/AVSS.2016.7738021
   Nghiem AT, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P476, DOI 10.1109/AVSS.2007.4425357
   Nhan Nguyen-Duc-Thanh, 2011, Convergence and Hybrid Information Technology. Proceedings 5th International Conference, ICHIT 2011, P762, DOI 10.1007/978-3-642-24082-9_92
   Nicolaou MA, 2014, IEEE T PATTERN ANAL, V36, P1299, DOI 10.1109/TPAMI.2014.16
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Nweke HF, 2019, INFORM FUSION, V46, P147, DOI 10.1016/j.inffus.2018.06.002
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Onofri L, 2016, EXPERT SYST APPL, V63, P97, DOI 10.1016/j.eswa.2016.06.011
   Park HS, 2015, PROC CVPR IEEE, P4777, DOI 10.1109/CVPR.2015.7299110
   Paulson B, 2011, INT J HUM-COMPUT ST, V69, P19, DOI 10.1016/j.ijhcs.2010.09.003
   Pham HH, 2015, VIDEO BASED HUMAN AC
   Pires IM, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16020184
   Pirsiavash H, 2014, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2014.85
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Portet F, 2013, PERS UBIQUIT COMPUT, V17, P127, DOI 10.1007/s00779-011-0470-5
   Poulos A, 2017, US Patent, Patent No. [9,791,921, 9791921]
   Prati A, 2019, J AMB INTEL SMART EN, V11, P5, DOI 10.3233/AIS-180510
   Rahmani H, 2018, IEEE T PATTERN ANAL, V40, P667, DOI 10.1109/TPAMI.2017.2691768
   Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48
   Ramanathan M, 2014, IEEE T HUM-MACH SYST, V44, P650, DOI 10.1109/THMS.2014.2325871
   Ramanathan V, 2015, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.2015.7298713
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P56, DOI 10.1109/JBHI.2016.2633287
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Richard A, 2017, ARXIV170600699
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Ruffieux S, 2014, LECT NOTES COMPUT SC, V8511, P337, DOI 10.1007/978-3-319-07230-2_33
   Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361
   Sabokrou M, 2016, ELECTRON LETT, V52, P1122, DOI 10.1049/el.2016.0440
   Sabokrou Mohammad, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P56, DOI 10.1109/CVPRW.2015.7301284
   Sabokrou M., 2018, AS COMP VIS C
   Sabokrou M, 2019, INT C COMP VIS
   Sabokrou M, 2018, PROC CVPR IEEE, P3379, DOI 10.1109/CVPR.2018.00356
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Sabokrou M, 2017, MACH VISION APPL, V28, P965, DOI 10.1007/s00138-017-0869-8
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Sagayam KM, 2017, VIRTUAL REAL-LONDON, V21, P91, DOI 10.1007/s10055-016-0301-0
   Saha Suman, 2016, ARXIV160801529
   Samanta S, 2014, IEEE T MULTIMEDIA, V16, P1525, DOI 10.1109/TMM.2014.2326734
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sebestyen G, 2016, INT C INTELL COMP CO, P341, DOI 10.1109/ICCP.2016.7737171
   Seidenari L, 2013, IEEE COMPUT SOC CONF, P479, DOI 10.1109/CVPRW.2013.77
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shao J, 2015, PROC CVPR IEEE, P4657, DOI 10.1109/CVPR.2015.7299097
   Shao L, 2012, PATTERN RECOGN LETT, V33, P438, DOI 10.1016/j.patrec.2011.05.015
   Sharaf A, 2015, IEEE WINT CONF APPL, P998, DOI 10.1109/WACV.2015.138
   Sharma A, 2016, 2016 6TH INTERNATIONAL CONFERENCE - CLOUD SYSTEM AND BIG DATA ENGINEERING (CONFLUENCE), P524, DOI 10.1109/CONFLUENCE.2016.7508176
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Shu TM, 2015, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR.2015.7299088
   Sigurdsson GA, 2017, PROC CVPR IEEE, P5650, DOI 10.1109/CVPR.2017.599
   Singh Tej, 2019, Advances in Signal Processing and Communication. Select Proceedings of ICSC 2018. Lecture Notes in Electrical Engineering (LNEE 526), P247, DOI 10.1007/978-981-13-2553-3_24
   Singh T, 2019, ARTIF INTELL REV, V52, P1107, DOI 10.1007/s10462-018-9651-1
   Song SJ, 2018, IEEE T IMAGE PROCESS, V27, P3459, DOI 10.1109/TIP.2018.2818328
   Soomro K., 2014, COMPUTER VISION SPOR, V71, P181, DOI [DOI 10.1007/978-3-319-09396-3_9, DOI 10.1007/978-3-319-09396-39]
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Stein S, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P729, DOI 10.1145/2493432.2493482
   Subetha T, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Sun S, 2018, IEEE C COMP VIS PATT, V8
   Tabia H, 2012, RECONNAISSANCE ACTIV
   Tang KV, 2013, IEEE I CONF COMP VIS, P2696, DOI 10.1109/ICCV.2013.335
   Tapus A, 2019, PATTERN RECOGN LETT, V118, P3, DOI 10.1016/j.patrec.2018.03.006
   Nguyen THC, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010072
   Tripathi RK, 2017, ARTIF INTELL, V50, P1
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Ullah A, 2019, FUTURE GENER COMP SY, V96, P386, DOI 10.1016/j.future.2019.01.029
   van den Oord A, 2016, PR MACH LEARN RES, V48
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Vital JPM, 2017, PATTERN ANAL APPL, V20, P1179, DOI 10.1007/s10044-016-0558-7
   Vrigkas M, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00028
   Vrigkas M, 2014, LECT NOTES ARTIF INT, V8445, P95, DOI 10.1007/978-3-319-07064-3_8
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wang LL, 2017, PATTERN RECOGN LETT, V92, P33, DOI 10.1016/j.patrec.2017.04.004
   Wang P., 2018, COMPUTER VISION IMAG
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P289, DOI 10.1109/TMM.2013.2293060
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wenkai X, 2012, APPL MATH INFORM SCI, V6, p339S
   Wu C, 2017, IEEE T PATTERN ANAL, V40, P2
   Wu QX, 2013, IEEE T SYST MAN CY-S, V43, P875, DOI 10.1109/TSMCA.2012.2226575
   Wu Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P426, DOI 10.1109/ICCV.2001.937656
   Wu Y., 2000, CVPR, P2088
   Wu YW, 2013, COMPUT VIS IMAGE UND, V117, P1421, DOI 10.1016/j.cviu.2013.05.003
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   XING L, 2018, SOFTWARE GUIDE, P41
   Xu K, 2016, IEEE INT C MULT EXP, P976, DOI [10.1109/ICME.2016.7552941, DOI 10.1109/ICME.2016.7552941]
   XU W, 2015, KSII T INTERNET INF, V7
   Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386
   Yao GL, 2019, PATTERN RECOGN LETT, V118, P14, DOI 10.1016/j.patrec.2018.05.018
   Yao TT, 2017, PATTERN RECOGN, V64, P236, DOI 10.1016/j.patcog.2016.11.012
   Yi Li, 2012, Proceedings of the 2012 IEEE 3rd International Conference on Software Engineering and Service Science (ICSESS), P196, DOI 10.1109/ICSESS.2012.6269439
   Yu G, 2015, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2015.7298735
   Yudistira N, 2018, J SIGNAL PROCESSING, V42, P1
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
   Zhang ZQ, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P736, DOI 10.1109/CISP.2014.7003875
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhu F, 2016, IMAGE VISION COMPUT, V55, P42, DOI 10.1016/j.imavis.2016.06.007
   Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y
   Ziaeefard M, 2015, PATTERN RECOGN, V48, P2329, DOI 10.1016/j.patcog.2015.03.006
NR 237
TC 186
Z9 201
U1 11
U2 77
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30509
EP 30555
DI 10.1007/s11042-020-09004-3
EA AUG 2020
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559953900015
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Bharath, KP
   Kumar, MR
AF Bharath, K. P.
   Kumar, Rajesh M.
TI ELM speaker identification for limited dataset using multitaper based
   MFCC and PNCC features with fusion score
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multitaper; MFCC; PNCC; Frequency warping; CMVN
ID EXTREME LEARNING-MACHINE; I-VECTOR; CONTINUOUS AUTHENTICATION;
   RECOGNITION; SPEECH; COMPENSATION
AB In current scenario, speaker recognition under noisy condition is the major challenging task in the area of speech processing. Due to noise environment there is a significant degradation in the system performance. The major aim of the proposed work is to identify the speaker's under clean and noise background using limited dataset. In this paper, we proposed a multitaper based Mel frequency cepstral coefficients (MFCC) and power normalization cepstral coefficients (PNCC) techniques with fusion strategies. Here, we used MFCC and PNCC techniques with different multitapers to extract the desired features from the obtained speech samples. Then, cepstral mean and variance normalization (CMVN) and Feature warping (FW) are the two techniques applied to normalize the obtained features from both the techniques. Furthermore, as a system model low dimension i-vector model is used and also different fusion score strategies like mean, maximum, weighted sum, cumulative and concatenated fusion techniques are utilized. Finally extreme learning machine (ELM) is used for classification in order to increase the system identification accuracy (SIA) intern which is having a single layer feedforward neural network with less complexity and time consuming compared to other neural networks. TIMIT and SITW 2016 are the two different databases are used to evaluate the proposed system under limited data of these databases. Both clean and noisy backgrounds conditions are used to check the SIA.
C1 [Bharath, K. P.; Kumar, Rajesh M.] Vellore Inst Technol, Sch Elect Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Kumar, MR (corresponding author), Vellore Inst Technol, Sch Elect Engn, Vellore, Tamil Nadu, India.
EM bharathkp25@gmail.com; mrajeshkumar@vit.ac.in
RI M, Dr.M Ranjith Kumar/U-4667-2019
OI M, Dr.M Ranjith Kumar/0000-0001-8411-7609; M, Dr. Rajesh
   Kumar/0000-0003-0350-4397; K P, BHARATH/0000-0003-3402-4337
FU Council of Scientific AMP; Industrial Research (CSIR) Human Resource
   Development Group (HRDG), Govt of India [143672/2 k18/1,
   09/844(0084)/2019 EMR-I]
FX First author Bharath K P, (CSIR-Senior Research Fellow) would like to
   thank Council of Scientific & Industrial Research (CSIR) Human Resource
   Development Group (HRDG), Govt of India, for financial assistance during
   his Ph.D. (CSIR-SRF, Ack. No.: 143672/2 k18/1, File No.:
   09/844(0084)/2019 EMR-I.)
CR Alku P, 2017, IEEE-ACM T AUDIO SPE, V25, P1606, DOI 10.1109/TASLP.2017.2703165
   Angkititrakul P, 2007, IEEE T AUDIO SPEECH, V15, P498, DOI 10.1109/TASL.2006.881689
   [Anonymous], TIMIT ACOUSTIC PHONE
   Campbell JP, 1997, P IEEE, V85, P1437, DOI 10.1109/5.628714
   Chakroun R, 2018, IET SIGNAL PROCESS, V12, P873, DOI 10.1049/iet-spr.2016.0572
   Chen L, 2013, INT CONF ACOUST SPEE, P7760, DOI 10.1109/ICASSP.2013.6639174
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   El-Moneim A, 2020, MULTIMED TOOLS APPL, P1
   Frankle MN, 2016, MIDWEST SYMP CIRCUIT, P133
   Ghahabi Omid, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1700, DOI 10.1109/ICASSP.2014.6853888
   Hansson M, 1997, SPECTRA, V45, P1995
   Hansson-Sandsten M, 2009, INT CONF ACOUST SPEE, P3077, DOI 10.1109/ICASSP.2009.4960274
   Hu HL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Huang GB, 2008, NEUROCOMPUTING, V71, P576, DOI 10.1016/j.neucom.2007.07.025
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Jahangir R, 2020, IEEE ACCESS, V8, P32187, DOI 10.1109/ACCESS.2020.2973541
   Jayanna HS, 2009, SADHANA-ACAD P ENG S, V34, P717, DOI 10.1007/s12046-009-0042-9
   Kanagasundaram A, 2014, SPEECH COMMUN, V59, P69, DOI 10.1016/j.specom.2014.01.004
   Kenny P, 2005, IEEE T SPEECH AUDI P, V13, P345, DOI 10.1109/TSA.2004.840940
   Kenny Patrick., 2012, Odyssey, P1
   Kim C, 2016, IEEE-ACM T AUDIO SPE, V24, P1315, DOI 10.1109/TASLP.2016.2545928
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Kinnunen Tomi, 2009, 11 ANN C INT SPEECH
   Kua JMK, 2013, SPEECH COMMUN, V55, P707, DOI 10.1016/j.specom.2013.01.005
   Kumari RSS, 2012, PROCEDIA ENGINEER, V30, P319, DOI 10.1016/j.proeng.2012.01.867
   Lawson A, 2013, INTERSPEECH, P1506
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Li YT, 2019, IEEE INTERNET THINGS, V6, P628, DOI 10.1109/JIOT.2018.2851185
   Li YT, 2018, IEEE ACCESS, V6, P32554, DOI 10.1109/ACCESS.2018.2841347
   Liu F.H., 1993, P 6 ARPA WORKSHOP HU, P69
   Liu TT, 2014, 2014 11TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P5420, DOI 10.1109/WCICA.2014.7053640
   Ma ZY, 2016, IEEE ACCESS, V4, P9733, DOI 10.1109/ACCESS.2016.2646458
   Macková L, 2016, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA 2016), P372
   McLaren M, 2016, INTERSPEECH, P818, DOI 10.21437/Interspeech.2016-1129
   Murty KR, 2006, IEEE SIGNAL PROC LET, V13, P52, DOI 10.1109/LSP.2005.860538
   Park DS, 2019, INTERSPEECH, P2613, DOI 10.21437/Interspeech.2019-2680
   Prasad NV, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P156, DOI 10.1109/ASRU.2013.6707722
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   Reynolds Douglas A., 2009, DIGIT SIGNAL PROCESS, V10
   RIEDEL KS, 1995, IEEE T SIGNAL PROCES, V43, P188, DOI 10.1109/78.365298
   Saeidi R, 2016, IEEE-ACM T AUDIO SPE, V24, P42, DOI 10.1109/TASLP.2015.2493366
   Saha A, 2020, J BIOMOL STRUCT DYN, V38, P2440, DOI 10.1080/07391102.2019.1635912
   Sandberg J, 2010, IEEE SIGNAL PROC LET, V17, P343, DOI 10.1109/LSP.2010.2040228
   Toruk MM, 2019, INT MULTICONF SYST, P383, DOI [10.1109/SSD.2019.8893188, 10.1109/ssd.2019.8893188]
   Verma P, 2015, INT J SPEECH TECHNOL, V18, P529, DOI 10.1007/s10772-015-9295-3
   Viikki O, 1998, SPEECH COMMUN, V25, P133, DOI 10.1016/S0167-6393(98)00033-8
   Wang LB, 2007, SPEECH COMMUN, V49, P501, DOI 10.1016/j.specom.2007.04.004
   Zaw Win, 2019, 2019 16 ECTI CON
   Zhang C, 2019, PROCEEDINGS OF 2019 IEEE 8TH JOINT INTERNATIONAL INFORMATION TECHNOLOGY AND ARTIFICIAL INTELLIGENCE CONFERENCE (ITAIC 2019), P962, DOI [10.1109/itaic.2019.8785780, 10.1109/ITAIC.2019.8785780]
NR 50
TC 9
Z9 9
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28859
EP 28883
DI 10.1007/s11042-020-09353-z
EA AUG 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556646300010
DA 2024-07-18
ER

PT J
AU Li, M
   Ao, YH
   Peng, WZ
   He, JH
AF Li, Meng
   Ao, Yinhui
   Peng, Wenzheng
   He, Jinghui
TI Research of status recognition of Fiber transfer box based on machine
   vision and deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Support Vector Machine (SVM); You Look Only Once (YOLO); Adaptive
   Checkerboard Segmentation; Convolution Neural Network (CNN)
ID IMAGE CLASSIFICATION; SVM
AB Fiber transfer box is a box containing fiber ports which transfer optical signals for telecommunication networks. It's hard to check and record the status of hundreds of ports using man power. This paper proposes an intelligent recognition and localization system for fiber transfer box. Pictures of ports are treated and classified with Support Vector Machine (SVM) and Deep learning algorithm. It can identify the status of all ports in the fiber transfer box and recognize the writing letter for each layer. First, the image is converted to binary one by threshold of the Cr channel. A SVM classifier is used to identify the Red-Hat ports by HOG features. Second, an adaptive chessboard segmentation algorithm is designed for segmentation of all ports and character area. In order to improve the identification accuracy, an eleven-layer Convolution Neural Network (CNN) is trained and used to further identify the ports which have not been classified correctly by SVM. Letters are extracted and positioned by using YOLOv3-tiny network. Experiments show that the method achieves great accuracy and efficiency for a variety of scenes on mobile devices.
C1 [Li, Meng; Ao, Yinhui; Peng, Wenzheng; He, Jinghui] Guangdong Univ Technol, Sch Mech & Elect Engn, Guangzhou 510006, Peoples R China.
C3 Guangdong University of Technology
RP Li, M (corresponding author), Guangdong Univ Technol, Sch Mech & Elect Engn, Guangzhou 510006, Peoples R China.
EM 286222982@qq.com
RI He, Jinghui/A-6813-2017
OI He, Jinghui/0000-0002-0093-8897
CR Bai X, 2017, PATTERN RECOGN, V66, P437, DOI 10.1016/j.patcog.2016.12.005
   Driss S.B, 2017, SPIE C SERIES
   Fu XJ, 2003, IEEE T SYST MAN CY B, V33, P399, DOI 10.1109/TSMCB.2003.810911
   Giacinto G, 2001, IMAGE VISION COMPUT, V19, P699, DOI 10.1016/S0262-8856(01)00045-2
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Giust F, 2017, 2017 IEEE 28TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), DOI 10.1109/PIMRC.2017.8292609
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lipo W., 2006, NEURAL NETWORKS IEEE, V17, P826, DOI DOI 10.1109/TNN.2006.875965
   Liu Y, 2018, PATTERN RECOGN
   Mitra V, 2006, IEEE T NEURAL NETWOR, V17, P717, DOI 10.1109/TNN.2006.873279
   Peyrard Clement, 2015, VISAPP
   Radman A, 2017, DIGIT SIGNAL PROCESS, V64, P60, DOI 10.1016/j.dsp.2017.02.003
   Ratle F, 2010, IEEE T GEOSCI REMOTE, V48, P2271, DOI 10.1109/TGRS.2009.2037898
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Taha Z, 2018, 2018 IDENTIFICATION
   Vlacic Ljubo, 2002, NEUROCOMPUTING, V47, P578
   Zhang X, 2006, WORLD C INT CONTR AU
NR 22
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28695
EP 28709
DI 10.1007/s11042-020-09327-1
EA AUG 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556646300002
DA 2024-07-18
ER

PT J
AU Vidyarthi, A
AF Vidyarthi, Ankit
TI Multi-scale dyadic filter modulation based enhancement and
   classification of medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Filter bank; Image enhancement; Amplitude; Frequency modulation; Medical
   imaging; Classification
ID RECOGNITION; ALGORITHM; FACE
AB For the last many decades, the research is towards the classification of medical images in the early phase of its detection. But, the task becomes challenging due to the absence of the color information, like in natural scene images, and low illumination. In this paper, a multi-scale spectral approach is proposed for the classification of medical images. The proposed approach uses a dyadic filter bank extended to six scales for simultaneous modulation of the frequency and amplitude signal of the medical image. The modulated signal strength is used for enhancing the contrast of the image as a preprocessing step. The 32 bin spectral histogram is used to fetch the features using different modulation components at each scale of the dyadic filter bank. The proposed method has experimented with two medical imaging databases - one is malignant Brain tumor MRI scans collected from SMS medical college Jaipur. The second database is from the TCIA data repository having three datasets of Lung-CT and Brain MRI. These datasets have experimented with SVM using a quadratic kernel function. The experimental results show that the proposed approach fetches better textural information as compared with traditional texture analysis methods. Based on the analysis of the experimentation results, it is recommended that the use of the spectral features gives better early detection of the abnormalities for medical imaging datasets.
C1 [Vidyarthi, Ankit] Jaypee Inst Informat Technol, Dept Comp Sci Engn & Informat Technol, Noida 201309, Uttar Pradesh, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Vidyarthi, A (corresponding author), Jaypee Inst Informat Technol, Dept Comp Sci Engn & Informat Technol, Noida 201309, Uttar Pradesh, India.
EM dr.ankit.vidyarthi@gmail.com
RI Vidyarthi, Ankit/AAD-4939-2020
OI Vidyarthi, Ankit/0000-0002-8026-4246
CR Amira S, 2015, SIG INFO P, V6, P244
   [Anonymous], 2015, COMPUT INTEL NEUROSC
   Chi JN, 2017, J DIGIT IMAGING, V30, P477, DOI 10.1007/s10278-017-9997-y
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Fesharaki N. J., 2012, 2012 4th International Conference on Computational Intelligence and Communication Networks (CICN 2012), P369, DOI 10.1109/CICN.2012.145
   Fesharaki Nooshin Jafari, 2013, J Med Signals Sens, V3, P150
   Gao XHW, 2017, COMPUT METH PROG BIO, V138, P49, DOI 10.1016/j.cmpb.2016.10.007
   Guo WY, 2014, EXPERT SYST APPL, V41, P6446, DOI 10.1016/j.eswa.2014.03.033
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Hsu WY, 2015, J MED BIOL ENG, V35, P580, DOI 10.1007/s40846-015-0078-8
   Ji TT, 2015, J OCEAN U CHINA, V14, P255, DOI 10.1007/s11802-015-2426-2
   Jiang G, 2015, J MOD OPTIC, V62, P536, DOI 10.1080/09500340.2014.991358
   Jindal K, 2014, INT C ADV ENG TECHN, P1
   Khatkar K, 2015, PROCEDIA COMPUT SCI, V48, P513, DOI 10.1016/j.procs.2015.04.128
   Kwok NM, 2013, ENG APPL ARTIF INTEL, V26, P2356, DOI 10.1016/j.engappai.2013.07.023
   Kwok N, 2015, J MOD OPTIC, V62, P1037, DOI 10.1080/09500340.2015.1051601
   Leng L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092644
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Loizou CP, 2011, IEEE T INF TECHNOL B, V15, P119, DOI 10.1109/TITB.2010.2091279
   Miranda E, 2017, INT C INF MGMT TECH, P56, DOI DOI 10.1109/ICIMTECH.2016.7930302
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Murray V, 2010, IEEE T IMAGE PROCESS, V19, P1138, DOI 10.1109/TIP.2010.2040446
   Pei SC, 2006, IEEE T IMAGE PROCESS, V15, P3230, DOI 10.1109/TIP.2006.877478
   Purushothaman J, 2016, INT SYMP INT SIG PRO, P1, DOI [10.1109/ispacs.2016.7824720., DOI 10.1109/ISPACS.2016.7824720]
   Silva SDD, 2015, IEEE ENG MED BIO, P6321, DOI 10.1109/EMBC.2015.7319838
   Sodanil M., 2015, P 5 INT C IT CONV SE, P1
   STRICKLAND RN, 1987, OPT ENG, V26, P609, DOI 10.1117/12.7974125
   Thomas BA, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P30, DOI 10.1109/ICIP.1997.631967
   THOMAS RL, 2015, THESIS
   Vidyarthi A., 2014, P 3 INT C SOFT COMPU, P889, DOI DOI 10.1007/978-81-322-1771-8-77
   Wang JJ, 2015, INT J IMAG SYST TECH, V25, P7, DOI 10.1002/ima.22115
   Wang LM, 2017, SCI REP-UK, V7, DOI 10.1038/srep41545
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang ZY, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121464
   Yu YH, 2011, AUTOMAT CONSTR, V20, P669, DOI 10.1016/j.autcon.2011.04.013
   Zebin S, 2015, J ELECTRON IMAGING, V24, P24
   Zhang J., 2017, Advanced Colonoscopy and Endoluminal Surgery [Internet], P1, DOI [DOI 10.1007/s42114-017-0007-0, 10.1007/978-3-319-48370-2_1, DOI 10.1007/978-3-319-48370-2_1]
   Zhang JP, 2019, IEEE ACM T COMPUT BI, V16, P396, DOI 10.1109/TCBB.2017.2701379
   Zhang QL, 2017, AUTOM CONTROL COMPUT, V51, P263, DOI 10.3103/S0146411617040113
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
NR 43
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28105
EP 28129
DI 10.1007/s11042-020-09357-9
EA JUL 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554334600002
DA 2024-07-18
ER

PT J
AU Xie, YR
   He, XH
   Zhang, J
   Luo, XD
AF Xie, Yurui
   He, Xiaohai
   Zhang, Jing
   Luo, Xiaodong
TI Zero-shot recognition with latent visual attributes learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zero-shot learning; Human-designed attributes; Dictionary learning;
   Visual attributes; Semantic representation
ID CONVOLUTIONAL NEURAL-NETWORKS
AB Zero-shot learning (ZSL) aims to recognize novel object categories by means of transferring knowledge extracted from the seen categories (source domain) to the unseen categories (target domain). Recently, most ZSL methods concentrate on learning a visual-semantic alignment to bridge image features and their semantic representations by relying solely on the human-designed attributes. However, few works study whether the human-designed attributes are discriminative enough for recognition task. To address this problem, we propose a couple semantic dictionaries (CSD) learning approach to exploit the latent visual attributes and align the visual-semantic spaces at the same time. Specifically, the learned visual attributes are elegantly incorporated into the semantic representation of image feature and then consolidate the discriminative visual cues for object recognition. In addition, existing ZSL methods suffer from the domain shift issue due to the source domain and target domain have completely separated label spaces. We further employ the visual-semantic alignment and latent visual attributes jointly from source domain to regularise the learning of target domain, which ensures the expansibility of information transfer across domains. We formulate this as an optimization problem on a unified objective and propose an iterative solver. Extensive experiments on two challenging benchmark datasets demonstrate that our proposed approach outperforms several state-of-the-art ZSL methods.
C1 [Xie, Yurui; He, Xiaohai; Zhang, Jing; Luo, Xiaodong] Sichuan Univ, Coll Elect & Informat Engn, Chengdu, Peoples R China.
   [Xie, Yurui] Chengdu Univ Informat Technol, Chengdu, Peoples R China.
C3 Sichuan University; Chengdu University of Information Technology
RP He, XH (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Chengdu, Peoples R China.
EM gloriousxyr@163.com; nic5602@scu.edu.cn; 2018222050153@stu.scu.edu.cn;
   2017322055027@stu.scu.edu.cn
RI Luo, Xiaodong/G-5953-2011; Zhang, Yuchen/GYI-8858-2022
FU National Natural Science Foundation of China [61806028]; Program for
   Educational Foundation of Sichuan Province, China [18ZB0125]; Industrial
   Cluster Collaborative Innovation Project of Chengdu
   [2016-XT00-00015-GX]; Sichuan Science and Technology Program
   [2018HH0143]
FX This work was supported by The National Natural Science Foundation of
   China (No. 61806028), The Program for Educational Foundation of Sichuan
   Province, China (No. 18ZB0125), and in part by the Industrial Cluster
   Collaborative Innovation Project of Chengdu (No. 2016-XT00-00015-GX),
   the Sichuan Science and Technology Program (No. 2018HH0143).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986
   Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Annadani Y, 2018, PROC CVPR IEEE, P7603, DOI 10.1109/CVPR.2018.00793
   Chakraborty J, 2018, IEEE INT C SEMANT CO, P397, DOI 10.1109/ICSC.2018.00079
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Ding ZM, 2019, IEEE T PATTERN ANAL, V41, P2861, DOI 10.1109/TPAMI.2018.2867870
   Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hung KW, 2019, MULTIMED TOOLS APPL, V78, P22813, DOI 10.1007/s11042-019-7633-1
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Lee H., 2007, ADV NEURAL INFORM PR, P801, DOI DOI 10.7551/MITPRESS/7503.003.0105
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu WF, 2018, INFORM FUSION, V41, P119, DOI 10.1016/j.inffus.2017.09.001
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Mettes P, 2017, IEEE I CONF COMP VIS, P4453, DOI 10.1109/ICCV.2017.476
   Norouzi M., 2014, P INT C LEARN REPR
   Purushwalkam S, 2019, IEEE I CONF COMP VIS, P3592, DOI 10.1109/ICCV.2019.00369
   Qin J, 2017, PROC CVPR IEEE, P1042, DOI 10.1109/CVPR.2017.117
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen YM, 2018, PROC CVPR IEEE, P3598, DOI 10.1109/CVPR.2018.00379
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Sun YH, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1107-4
   Szczuko P, 2019, MULTIMED TOOLS APPL, V78, P29357, DOI 10.1007/s11042-019-7433-7
   Tong B, 2019, PROC CVPR IEEE, P11459, DOI 10.1109/CVPR.2019.01173
   Verma VK, 2017, LECT NOTES ARTIF INT, V10535, P792, DOI 10.1007/978-3-319-71246-8_48
   Wang YD, 2020, MULTIMED TOOLS APPL, V79, P33689, DOI 10.1007/s11042-019-7689-y
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Xie GS, 2019, PROC CVPR IEEE, P9376, DOI 10.1109/CVPR.2019.00961
   Xu CY, 2019, MULTIMED TOOLS APPL, V78, P573, DOI 10.1007/s11042-017-5262-0
   Xu X, 2018, MULTIMED TOOLS APPL, V77, P22185, DOI 10.1007/s11042-018-5796-9
   Yang X, 2019, ICDLT 2019: 2019 3RD INTERNATIONAL CONFERENCE ON DEEP LEARNING TECHNOLOGIES, P1, DOI [10.1145/3342999.3343000, 10.1109/TSMC.2019.2894171]
   Yang YZ, 2015, AAAI CONF ARTIF INTE, P3686
   Yelamarthi SK, 2018, LECT NOTES COMPUT SC, V11208, P316, DOI 10.1007/978-3-030-01225-0_19
   Yu J, 2014, INFORM SCIENCES, V281, P674, DOI 10.1016/j.ins.2014.01.025
   Yu S, 2017, MULTIMED TOOLS APPL, V76, P13367, DOI 10.1007/s11042-016-3768-5
   Zhang HF, 2019, MULTIMED TOOLS APPL, V78, P24147, DOI 10.1007/s11042-018-6842-3
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
NR 48
TC 2
Z9 2
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27321
EP 27335
DI 10.1007/s11042-020-09316-4
EA JUL 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000552190000001
DA 2024-07-18
ER

PT J
AU Aydogdu, O
   Ekinci, M
AF Aydogdu, Ozge
   Ekinci, Murat
TI A new approach for data stream classification: unsupervised feature
   representational online sequential extreme learning machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data stream; Data stream classification; Online sequential extreme
   learning machine; Concept drift; Extreme learning machine based
   autoencoder; Representational learning
ID CONCEPT DRIFT; CLASS IMBALANCE; INPUT WEIGHTS; ENSEMBLE; ALGORITHM;
   ROBUST; ELM
AB The characteristics of the data stream have brought enormous challenges to classification algorithms. Concept drift is the most concerning characteristics, and developed classification algorithms must tackle the concept drift problem. Therefore, Extreme Learning Machines (ELM) based algorithms have been developed to respond to the characteristics of the data stream. However, due to randomly assigned input layer weights, ELM based algorithms have encountered problems such as producing inconsistent outputs, generating ill-conditioned matrix, and mapping the inputs to the worst representative space. To overcome these problems, this paper aims to build a stable and well-constructed classifier that responds to the requirements of the data stream by considering all characteristics. A novel data stream classification approach based online sequential ELM (OS-ELM) with unsupervised feature representation learning (UFROS-ELM) and ensemble UFROS-ELM approach based on majority learning is presented in this paper. UFROS-ELM is a modification of the OS-ELM with ELM-AE and concept drift mechanism. ELM-AE is utilized for computing the best discriminative input weights of the classifier. The classifier is then initialized by using the determined weights, first chunk, and OS-ELM algorithm. When a new data chunk arrives, the classifier firstly searches any concept drift occurrence. If it is detected, ELM-AE is utilized to reconstruct the classifier to adapt to the changes. Otherwise, the classifier is sequentially updated updates by processing the current chunk. The results are achieved on the well-known real and artificial data sets and compared with state-of-the-art data stream classification algorithms. The experimental studies demonstrate the achievements of the proposed approaches.
C1 [Aydogdu, Ozge; Ekinci, Murat] Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
C3 Karadeniz Technical University
RP Aydogdu, O (corresponding author), Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
EM omakul@ktu.edu.tr; ekinci@ktu.edu.tr
RI Aydoğdu, Özge/AAW-3974-2020; Ekinci, Murat/A-9653-2012
OI Aydoğdu, Özge/0000-0001-9386-4390; 
CR Aggarwal CC, 2014, CH CRC DATA MIN KNOW, P457
   Amini A, 2014, SCI WORLD J, DOI 10.1155/2014/926020
   Arabmakki E, 2017, NEUROCOMPUTING, V262, P120, DOI 10.1016/j.neucom.2016.11.088
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   BANERJEE KS, 1973, TECHNOMETRICS, V15, P197, DOI 10.1080/00401706.1973.10489026
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bifet A, 2010, J MACH LEARN RES, V11, P1601
   Castaño A, 2013, NEURAL PROCESS LETT, V37, P377, DOI 10.1007/s11063-012-9253-x
   Deng WY, 2016, NEUROCOMPUTING, V174, P72, DOI 10.1016/j.neucom.2015.06.087
   Ding SF, 2017, INT J MACH LEARN CYB, V8, P587, DOI 10.1007/s13042-015-0351-8
   Ding SY, 2018, NEUROCOMPUTING, V277, P139, DOI 10.1016/j.neucom.2017.02.102
   Dua D., 2017, UCI MACHINE LEARNING
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Han F, 2013, NEUROCOMPUTING, V116, P87, DOI 10.1016/j.neucom.2011.12.062
   Han Min, 2014, Control and Decision, V29, P1576, DOI 10.13195/j.kzyjc.2013.0098
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Kasun LLC, 2013, IEEE INTELL SYST, V28, P31
   Krawczyk B, 2018, APPL SOFT COMPUT, V68, P677, DOI 10.1016/j.asoc.2017.12.008
   Lall A., 2006, ACM SIGMETRICS PERFO, P145
   Lan Y, 2009, NEUROCOMPUTING, V72, P3391, DOI 10.1016/j.neucom.2009.02.013
   Laohakiat S, 2017, INFORM SCIENCES, V381, P104, DOI 10.1016/j.ins.2016.11.018
   Leal B, 2010, INTERNET OF THINGS-BOOK, P3, DOI 10.1007/978-1-4419-1674-7_1
   Li L, 2019, MULTIMED TOOLS APPL, V78, P33375, DOI 10.1007/s11042-019-7543-2
   Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583
   Liu ZY, 2019, APPL SOFT COMPUT, V75, P494, DOI 10.1016/j.asoc.2018.11.006
   Miche Y, 2010, IEEE T NEURAL NETWOR, V21, P158, DOI 10.1109/TNN.2009.2036259
   Mirza B, 2016, NEURAL NETWORKS, V80, P79, DOI 10.1016/j.neunet.2016.04.008
   Mirza B, 2015, NEUROCOMPUTING, V149, P316, DOI 10.1016/j.neucom.2014.03.075
   Mirza B, 2013, NEURAL PROCESS LETT, V38, P465, DOI 10.1007/s11063-013-9286-9
   Pacheco AGC, 2018, EXPERT SYST APPL, V96, P77, DOI 10.1016/j.eswa.2017.11.054
   Rutkowski L, 2013, IEEE T KNOWL DATA EN, V25, P1272, DOI 10.1109/TKDE.2012.66
   Sethi TS, 2017, EXPERT SYST APPL, V82, P77, DOI 10.1016/j.eswa.2017.04.008
   Shao ZF, 2016, NEUROCOMPUTING, V173, P778, DOI 10.1016/j.neucom.2015.08.029
   Singh R, 2015, EXPERT SYST APPL, V42, P8609, DOI 10.1016/j.eswa.2015.07.015
   Tso FP, 2013, IEEE T MOBILE COMPUT, V12, P2206, DOI 10.1109/TMC.2012.191
   Venkatesan R, 2017, EVOL SYST-GER, V8, P303, DOI 10.1007/s12530-016-9162-8
   Venkatesan R, 2016, IEEE IJCNN, P1833, DOI 10.1109/IJCNN.2016.7727422
   Wang D, 2015, NEUROCOMPUTING, V151, P883, DOI 10.1016/j.neucom.2014.10.006
   Wang WH, 2017, NEUROCOMPUTING, V261, P28, DOI 10.1016/j.neucom.2016.06.079
   Wang YG, 2011, NEUROCOMPUTING, V74, P2483, DOI 10.1016/j.neucom.2010.11.030
   Webb GI, 2016, DATA MIN KNOWL DISC, V30, P964, DOI 10.1007/s10618-015-0448-4
   Xiao D, 2018, CHEMOMETR INTELL LAB, V176, P126, DOI 10.1016/j.chemolab.2018.01.014
   Xu SL, 2017, NEUROCOMPUTING, V238, P433, DOI 10.1016/j.neucom.2016.12.078
   Xu SL, 2016, EXPERT SYST APPL, V65, P332, DOI 10.1016/j.eswa.2016.08.052
   Yang R, 2018, ALGORITHMS, V11, DOI 10.3390/a11070107
   Yu HL, 2019, NEUROCOMPUTING, V343, P141, DOI 10.1016/j.neucom.2018.11.098
   Zeng XQ, 2014, PATTERN RECOGN, V47, P3726, DOI 10.1016/j.patcog.2014.05.022
   Zeng YJ, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10100474
   Zhang P, 2011, DECIS SUPPORT SYST, V50, P469, DOI 10.1016/j.dss.2010.11.004
   Zhang Y, 2017, J INTELL FUZZY SYST, V33, P1143, DOI 10.3233/JIFS-16724
   Zhao G., 2011, INT J INF TECHNOL, V17, P1
   Zhao JW, 2012, NEUROCOMPUTING, V87, P79, DOI 10.1016/j.neucom.2012.02.003
NR 53
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27205
EP 27227
DI 10.1007/s11042-020-09300-y
EA JUL 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000551736600003
DA 2024-07-18
ER

PT J
AU Shaji, C
   Sam, IS
AF Shaji, C.
   Sam, I. Shatheesh
TI Two level data encoding approach for reversible data hiding in dual
   Stego images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Histogram; Dual stego images; PSNR and embedding
   rate
ID SCHEME
AB Due to high embedding capacity and security, dual stego-image based data hiding has become so popular. This paper proposes a two-level data encoding approach for reversible data hiding in dual stego-images. In the first level of encoding, the encoded intensities are estimated from the message intensities by assigning lower intensities to higher histogram data and higher intensities to lower histogram data. In the second level of encoding, the encoded intensities are folded by identifying the negative values to obtain the folded intensities. The folded intensities are embedded in the cover image to obtain the dual stego-images. The two-level data encoding process reduces the intensity of secret data which increases the quality of the two stego-images. During the extraction process, the folded intensities are extracted from the dual stego images. The folded intensities are decoded to encoded intensities and then to message intensities to obtain the secret data. This two-level data encoding approach increases the peak signal to noise ratio (PSNR) around 2 dB, and embedding rate (bpp) by 1%when compared to the traditional data hiding approach in dual stego images.
C1 [Shaji, C.] ManonmaniamSundaranar Univ, Dept Comp Sci, Nesamony Mem Christian Coll, Tirunelveli 627012, Tamil Nadu, India.
   [Sam, I. Shatheesh] ManonmaniamSundaranar Univ, Dept PG Comp Sci, Nesamony Mem Christian Coll, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University; Manonmaniam Sundaranar University
RP Shaji, C (corresponding author), ManonmaniamSundaranar Univ, Dept Comp Sci, Nesamony Mem Christian Coll, Tirunelveli 627012, Tamil Nadu, India.
EM shaji2012@gmail.com; shatheeshsam@yahoo.com
CR Cao X., 2015, HIGH CAPACITY REVERS, P1
   Chang CJ, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/526806
   Chen GL, 2007, PROCEEDINGS OF THE 35TH INTERNATIONAL MATADOR CONFERENCE, P17, DOI 10.1007/978-1-84628-988-0_4
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Hong WE, 2017, SIGNAL PROCESS-IMAGE, V58, P111, DOI 10.1016/j.image.2017.07.001
   Huang F., 2015, REVERSIBLE DATA HIDI, V8215, P1, DOI DOI 10.1109/TCSVT.2015.2473235
   Jung KH, 2018, MULTIMED TOOLS APPL, V77, P6225, DOI 10.1007/s11042-017-4533-0
   Li M, 2017, SIGNAL PROCESS, V130, P190, DOI 10.1016/j.sigpro.2016.07.002
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Lo CC, 2014, SIGNAL PROCESS, V98, P174, DOI 10.1016/j.sigpro.2013.11.028
   Luo Z., 2010, IEEE T INF FOREN SEC, V5, P187, DOI DOI 10.1109/TIFS.2009.2035975
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Nikolaidis A, 2015, IET IMAGE PROCESS, V9, P560, DOI 10.1049/iet-ipr.2014.0689
   Ou B, 2015, SIGNAL PROCESS, V108, P642, DOI 10.1016/j.sigpro.2014.10.012
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Shaji C, 2019, IMAGING SCI J, V67, P202, DOI 10.1080/13682199.2019.1592892
   Shi YQ, 2005, REVERSIBLE DATA HIDI, P1, DOI [10.1109/ICIP.2002.1039911, DOI 10.1109/ICIP.2002.1039911]
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang Y., 2018, INT J NETW SECURITY, V20, P801, DOI DOI 10.6633/IJNS.201807
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Yao H, 2017, J VIS COMMUN IMAGE R, V43, P152, DOI 10.1016/j.jvcir.2017.01.004
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 27
TC 3
Z9 3
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 26969
EP 26993
DI 10.1007/s11042-020-09273-y
EA JUL 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000550587600001
DA 2024-07-18
ER

PT J
AU Singh, S
AF Singh, Samayveer
TI Adaptive PVD and LSB based high capacity data hiding scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Secret data; Embedding capacity; LSB; PVD
ID IMAGES; DIFFERENCE
AB In this paper, a new data hiding scheme using a mixture of adaptive pixel value differencing (PVD) and least significant bit substitution (LSB) is proposed for increasing the data hiding capacity. The scheme is a generalization of Jung (J Real-Time Image Proc. 14:127-36, 2018) which is the first work to use PVD and LSB methods simultaneously on a single image. However, the PVD used by Jung (J Real-Time Image Proc. 14:127-36, 2018) is not an adaptive method means it does not consider the vertical and diagonal edges of the image for hiding the secret data. In the proposed scheme, the vertical and diagonal edges in addition to horizontal edges are used for hiding the secret data so that a large amount of secret data is hidden without any perceived change. Experimental results show that the performance of the proposed scheme is superior to the existing schemes in terms of both data hiding capacity and image quality. Moreover, it is very simple as it does not require much computation for embedding the secret data.
C1 [Singh, Samayveer] Natl Inst Technol Jalandhar, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Singh, S (corresponding author), Natl Inst Technol Jalandhar, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
EM samayveersingh@gmail.com
RI Singh, Samayveer/X-8119-2019
OI Singh, Samayveer/0000-0002-4199-721X
CR Alrehily Ashwag, 2018, International Journal of Computer Network and Information Security, V10, P28, DOI 10.5815/ijcnis.2018.05.04
   [Anonymous], 2014, AUST J BASIC APPL SC
   Baluja S, 2017, ADV NEUR IN, V30
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Das SK, 2018, MULTIMED TOOLS APPL, V77, P15321, DOI 10.1007/s11042-017-5117-8
   Jung KH, 2018, J REAL-TIME IMAGE PR, V14, P127, DOI 10.1007/s11554-017-0719-y
   Kumar R, 2018, INT ARAB J INF TECHN, V15, P763
   Kumar R, 2018, MULTIMED TOOLS APPL, V77, P13445, DOI 10.1007/s11042-017-4960-y
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Lin CC, 2011, COMPUT STAND INTER, V33, P477, DOI 10.1016/j.csi.2011.02.003
   Malik Aruna, 2015, International Journal of Image, Graphics and Signal Processing, V7, P68, DOI 10.5815/ijigsp.2015.04.08
   Malik A, 2018, MULTIMED TOOLS APPL, V77, P15803, DOI 10.1007/s11042-017-5156-1
   Meng RH, 2018, CMC-COMPUT MATER CON, V55, P1, DOI 10.3970/cmc.2018.055.001
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pizzolante R, 2017, COMPUT SECUR, V74
   Pradhan A, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/1924618
   Rabah K., 2004, Information Technology Journal, V3, P245
   Shen SY, 2015, MULTIMED TOOLS APPL, V74, P707, DOI 10.1007/s11042-014-2016-0
   Swain G, 2016, MULTIMED TOOLS APPL, V75, P13541, DOI 10.1007/s11042-015-2937-2
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang YL, 2018, IEEE ACCESS, V6, P8882, DOI 10.1109/ACCESS.2018.2810058
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu NI, 2017, IMAGING SCI J, V65, P371, DOI 10.1080/13682199.2017.1355089
   Xu WL, 2016, DISPLAYS, V42, P36, DOI 10.1016/j.displa.2016.03.002
NR 25
TC 26
Z9 26
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18815
EP 18837
DI 10.1007/s11042-020-08745-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800069
DA 2024-07-18
ER

PT J
AU Wang, XZ
   Liu, X
   Peng, SJ
   Zhong, BN
   Chen, YW
   Du, JX
AF Wang, Xingzhi
   Liu, Xin
   Peng, Shu-Juan
   Zhong, Bineng
   Chen, Yewang
   Du, Ji-Xiang
TI Semi-supervised discrete hashing for efficient cross-modal retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semi-supervised discrete hashing; Cross-modal retrieval; Relaxed hash
   representation; Semantic consistency
AB Cross-modal hashing has recently gained significant popularity to facilitate multimedia retrieval across different modalities. Since the acquisition of large-scale labeled training data are very labor intensive, most supervised cross-modal hashing methods are uncompetitive for real applications. With limited label available, this paper presents a novelSemi-SupervisedDiscreteHashing (SSDH) for efficient cross-modal retrieval. In contrast to most semi-supervised cross-modal hashing works that need to predict the label of unlabeled data, our proposed approach groups the labeled and unlabeled data together, and exploits the informative unlabeled data to promote hashing code learning directly. Specifically, the proposed SSDH approach utilizes the relaxed hash representations to characterize each modality, and learns the semi-supervised semantic-preserving regularization to correlate the semantic consistency between the heterogeneous modalities. Accordingly, an efficient objective function is proposed to learn the hash representation, while designing an efficient optimization algorithm to optimize the hash codes for both labeled and unlabeled data. Without sacrificing the retrieval performance, the proposed SSDH method is adaptive to benefit various kinds of retrieval tasks, i.e., unsupervised, semi-supervised and supervised. Experimental results compared with several competitive algorithms show the effectiveness of the proposed method and its superiority over state-of-the-arts.
C1 [Wang, Xingzhi; Liu, Xin; Zhong, Bineng] Huaqiao Univ, Dept Comp Sci & Technol, Jimei Rd 668, Xiamen, Fujian, Peoples R China.
   [Peng, Shu-Juan; Chen, Yewang; Du, Ji-Xiang] Fujian Key Lab Big Data Intelligence & Secur, Jimei Rd 668, Xiamen, Fujian, Peoples R China.
C3 Huaqiao University
RP Liu, X (corresponding author), Huaqiao Univ, Dept Comp Sci & Technol, Jimei Rd 668, Xiamen, Fujian, Peoples R China.
EM xliu@hqu.edu.cn
RI Liu, Xin/JVN-3263-2024; Chen, Yewang/AAN-6803-2020
OI Liu, Xin/0000-0002-0011-6260; Chen, Yewang/0000-0001-9691-0807; wang,
   xingzhi/0009-0007-5901-8888
FU National Science Foundation of China [61673185, 61672444, 61972167];
   Quanzhou City Science&Technology Program of China [2018C107R]; State Key
   Laboratory of Integrated Services Networks of Xidian University
   [ISN20-11]; Promotion Program for graduate student in Scientific
   research and innovation ability of Huaqiao University [17013083010]
FX The work was supported by National Science Foundation of China (Nos.
   61673185, 61672444 and 61972167), Quanzhou City Science&Technology
   Program of China (No. 2018C107R), State Key Laboratory of Integrated
   Services Networks of Xidian University (No. ISN20-11), Promotion Program
   for graduate student in Scientific research and innovation ability of
   Huaqiao University (No. 17013083010).
CR [Anonymous], 2014, INF SOFTW TECHNOL
   [Anonymous], 2018, SELF SUPERVISED ADVE
   [Anonymous], 2018, IEEE T CYBERNETICS
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Cao Y, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1445, DOI 10.1145/2939672.2939812
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Dong X, 2018, MULTIMED TOOLS APPL, V77, P3579, DOI 10.1007/s11042-017-5164-1
   Guo FZ, 2019, ACM T INTERACT INTEL, V9, DOI 10.1145/3182187
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jiang QY, 2019, IEEE T IMAGE PROCESS, V28, P3490, DOI 10.1109/TIP.2019.2897944
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Li AN, 2011, PATTERN RECOGN LETT, V32, P1948, DOI 10.1016/j.patrec.2011.07.020
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Liu H, 2017, PROC CVPR IEEE, P6345, DOI 10.1109/CVPR.2017.672
   Liu X, 2019, IEEE T PATTERN ANAL, V9, P1
   Long MS, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P579, DOI 10.1145/2911451.2911493
   Mandal D, 2017, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR.2017.282
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Tang J, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2564638
   Toh KC, 2010, PAC J OPTIM, V6, P615
   Wang D, 2019, MULTIMED TOOLS APPL, V78, P24167, DOI 10.1007/s11042-018-6858-8
   Wang JL, 2017, MULTIMED TOOLS APPL, V76, P20197, DOI 10.1007/s11042-017-4567-3
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang L, 2018, IEEE T MULTIMEDIA, V20, P128, DOI 10.1109/TMM.2017.2723841
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
   Zou FH, 2019, WORLD WIDE WEB, V22, P825, DOI 10.1007/s11280-018-0581-2
NR 34
TC 3
Z9 4
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25335
EP 25356
DI 10.1007/s11042-020-09195-9
EA JUL 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000544580800001
DA 2024-07-18
ER

PT J
AU Hayat, N
   Imran, M
AF Hayat, Naila
   Imran, Muhammad
TI Detailed and enhanced multi-exposure image fusion using recursive filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-exposure; Low dynamic range; High dynamic range; Histogram;
   Recursive filter
ID QUALITY ASSESSMENT
AB A single photo is usually inadequate to represent a high-quality scene due to the dynamic range limitation. A high-quality image can be obtained by fusing multi-exposure images of the same scene. However, ghosting artifact can be produced in the fused image due to moving objects. To overcome this problem, we propose a detailed and enhanced multi-exposure image fusion technique using an edge-preserving recursive filter. The proposed technique reduces the artifacts near edges and produces an HDR-like image without any ghosting artifact. The idea behind the proposed method is to first decompose the LDR multiple-exposed input images into the detail layer and the base layer to extract the sharp and fine details, respectively. To do so, first, the recursive filter is applied to input images. Then, these recursive-based output images are used for extracting the detail and base layer. Finally, the detail layer and the base layer are combined together to produce a detailed and enhanced image without artifacts. Additionally, the proposed method is suitable for multi-focus image fusion. Experimental results prove the effectiveness of the proposed method over the existing methods both qualitatively and quantitatively.
C1 [Hayat, Naila] Sardar Bandur Khan Women Univ, Quetta, Pakistan.
   [Imran, Muhammad] Balochistan Univ IT, Engn & Management Sci, Quetta, Pakistan.
RP Imran, M (corresponding author), Balochistan Univ IT, Engn & Management Sci, Quetta, Pakistan.
EM nailahayat_sbk@ymail.com; engr.imran@buitms.edu.pk
RI Imran, Muhammad/HTT-4220-2023
OI Imran, Muhammad/0000-0002-1147-3159
CR [Anonymous], 2017, Advanced high dynamic range imaging
   [Anonymous], MVA
   Artusi A, 2017, IEEE SIGNAL PROC MAG, V34, P165, DOI 10.1109/MSP.2017.2716957
   Biradar N, 2014, EDGE PRESERVED SPECK
   Demirel H, 2011, IEEE T IMAGE PROCESS, V20, P1458, DOI 10.1109/TIP.2010.2087767
   Eilertsen G, 2017, COMPUT GRAPH FORUM, V36, P565, DOI 10.1111/cgf.13148
   Fu X., 2019, arXiv
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Gonzalea RC, 2004, WAVELETS MULTIRESOLU
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Heidrich Wolfgang, ERIK REINHARD
   Huang F, 2018, IEEE ACCESS, V6, P42877, DOI 10.1109/ACCESS.2018.2859355
   Huo Y., 2016, 2016 INT C COMMUNICA, P1
   Huo YQ, 2017, IET IMAGE PROCESS, V11, P1317, DOI 10.1049/iet-ipr.2016.1075
   Jain P, 2015, EM ICT BRIDG FUT P 4, V1, P393
   Jain P, 2016, INFORM SYST FRONT, V18, P159, DOI 10.1007/s10796-014-9527-0
   Kalantari N. K., 2017, ACM Trans. Graph., V36, DOI DOI 10.1145/3072959.3073609
   Khan IR, 2018, IEEE T IND ELECTRON, V65, P3469, DOI 10.1109/TIE.2017.2760247
   Lee SH, 2018, IEEE IMAGE PROC, P1737, DOI 10.1109/ICIP.2018.8451153
   Li RJ, 2007, IEEE T CONSUM ELECTR, V53, P1161, DOI 10.1109/TCE.2007.4341600
   Li ST, 2012, IEEE T CONSUM ELECTR, V58, P626, DOI 10.1109/TCE.2012.6227469
   Li ZG, 2017, IEEE T IMAGE PROCESS, V26, P1243, DOI 10.1109/TIP.2017.2651366
   Liu Y, 2015, J VIS COMMUN IMAGE R, V31, P208, DOI 10.1016/j.jvcir.2015.06.021
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P2519, DOI 10.1109/TIP.2017.2671921
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Mertens T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P382, DOI 10.1109/PG.2007.17
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Núñez J, 1999, IEEE T GEOSCI REMOTE, V37, P1204, DOI 10.1109/36.763274
   Paris S, 2006, LECT NOTES COMPUT SC, V3954, P568
   Paris S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964963
   Richard S., 2016, OPT ENG, V52, P913
   Serrano A, 2016, COMPUT GRAPH FORUM, V35, P153, DOI 10.1111/cgf.12819
   Shen JB, 2014, IEEE T CYBERNETICS, V44, P1579, DOI 10.1109/TCYB.2013.2290435
   Vanmali A. V., 2015, P 2015 21 NATL C COM, P1
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
NR 36
TC 8
Z9 8
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 25067
EP 25088
DI 10.1007/s11042-020-09190-0
EA JUN 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000544580400004
DA 2024-07-18
ER

PT J
AU Yin, D
   Zhao, YQ
   Wang, Y
   Zhao, WP
   Hu, XM
AF Yin, Dai
   Zhao, Yiqi
   Wang, Yang
   Zhao, Wenpu
   Hu, Xiaoming
TI Auxiliary diagnosis of heterogeneous data of Parkinson's disease based
   on improved convolution neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parkinson's disease; Heterogeneous data; Improved convolution neural
   network; Gabor filter
AB Parkinson's disease (PD) is a kind of nervous system degenerative disease frequently occurring in the elderly over sixty years old. With the development of imaging technology, medical imaging has played a certain role in the diagnosis of Parkinson's disease. The aim of the paper is to the diagnosis of Parkinson's disease through deep learning. This paper selects the T2-MRI(T2-Magnetic Resonance Imaging) image and clinical data to diagnose Parkinson's disease and integrates the heterogeneous data into the improved convolution neural network. In this paper, convolution neural network is added to the Gabor filter to make the whole convolution neural network have better effect; the activation function is improved and adjusted, which means the traditional sigmoid function and the tanh function are discarded, and the Relu activation function is used to improve the neural network. It is proved by experiments that the heterogeneous data diagnosis of T2-MRI image and clinical data (the accuracy is 77.9%) is better than the simple image data diagnosis (the accuracy is71.2%). For the same data, the improved convolution neural network is superior to the traditional network (the accuracy is 64.5%).
C1 [Yin, Dai; Zhao, Wenpu; Hu, Xiaoming] Northeastern Univ, Coll Med & Bioinformat Engn, Shenyang 110169, Peoples R China.
   [Yin, Dai] Northeastern Univ, Minist Educ, China & Engn Ctr Med Imaging & Intelligent Anal, Shenyang 110169, Peoples R China.
   [Zhao, Yiqi] Univ Sydney, Fac Engn & Informat Technol, Sydney, NSW, Australia.
   [Wang, Yang] Neusoft Corp, Shenyang, Peoples R China.
   [Wang, Yang] Northeastern Univ, Comp Sci Sch, Shenyang, Peoples R China.
C3 Northeastern University - China; Northeastern University - China;
   University of Sydney; Northeastern University - China
RP Yin, D (corresponding author), Northeastern Univ, Coll Med & Bioinformat Engn, Shenyang 110169, Peoples R China.; Yin, D (corresponding author), Northeastern Univ, Minist Educ, China & Engn Ctr Med Imaging & Intelligent Anal, Shenyang 110169, Peoples R China.
EM daiyin@bmie.neu.edu.cn; 496698471@qq.com; wy@neusoft.com;
   962961353@qq.com; 1344584494@qq.com
RI zhao, yiqi/HDL-8861-2022; Cao, Yang/HGD-6463-2022
FU National Natural Science Foundation of China [61902058]; Fundamental
   Research Funds for the Central Universities. "Research on Key
   Technologies of Early Diagnosis of Encephalitis based on Heterogeneous
   Data Fusion" [N2019002]; Fundamental Research Funds for the Central
   Universities [N2024005-2]
FX The authors acknowledge the Foundation Research Funds for: 1.Youth
   Program of National Natural Science Foundation of China. "Key
   Technologies of Early Diagnosis of Alzheimer's Disease based on
   Heterogeneous Data Fusion and Brain Network Construction." (61902058).
   2.The Fundamental Research Funds for the Central Universities. "Research
   on Key Technologies of Early Diagnosis of Encephalitis based on
   Heterogeneous Data Fusion." (N2019002). 3.The Fundamental Research Funds
   for the Central Universities under Grant. (N2024005-2)
CR Alzubi J, 2018, J PHYS CONF SER, V1142, DOI 10.1088/1742-6596/1142/1/012012
   [陈永平 Chen Yongping], 2017, [中国实用内科杂志, Chinese Journal of Practical Internal Medicine], V37, P124
   Dan Li, 2016, COMPUTER ERA, P4
   Dan Zhao, 2010, CHIN J CLIN NEUROSCI, V18, P130
   Dongfeng Xu, 2018, HAINAN MED, V29, P381
   Fang Y, 2014, CLIN NEUROL, V27, P111
   Haidong Huang, 2004, CLIN NEUROL, V17, P11
   Jieying Feng, 2013, RADIO PRACTICE, V28, P1105
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lakshmi C, 2019, CURR SIGNAL TRANSD T, V14, P1, DOI [10.2174/157436241401190221110719, DOI 10.2174/157436241401190221110719]
   LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5
   [李俭川 Li Jianchun], 2002, [振动、测试与诊断, Journal of Vibration, Measurement and Diagnosis], V22, P260
   MEHROTRA R, 1992, PATTERN RECOGN, V25, P1479, DOI 10.1016/0031-3203(92)90121-X
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Suh MH, 2016, OPHTHALMOLOGY, V123, P2509, DOI 10.1016/j.ophtha.2016.09.002
   Vinoj PG, 2019, IEEE ACCESS, V7, P132628, DOI 10.1109/ACCESS.2019.2921375
   Wenxi Zhang, 2017, PROGR MODERN BIOMEDI, V17, P738
   Yueqi Z, 2016, DIAGN CONCEPTS PRACT, V15, P122
   Zhang LH, 2016, EVID-BASED COMPL ALT, V2016, DOI 10.1155/2016/5365291
   [赵泉华 Zhao Quanhua], 2015, [仪器仪表学报, Chinese Journal of Scientific Instrument], V36, P2519
NR 20
TC 7
Z9 8
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24199
EP 24224
DI 10.1007/s11042-020-08984-6
EA JUN 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000541201200006
DA 2024-07-18
ER

PT J
AU Umer, S
   Mohanta, PP
   Rout, RK
   Pandey, HM
AF Umer, Saiyed
   Mohanta, Partha Pratim
   Rout, Ranjeet Kumar
   Pandey, Hari Mohan
TI Machine learning method for cosmetic product recognition: a visual
   searching approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cosmetic products; E-commerce application; Feature extraction; Machine
   learning; Visual search
ID IMAGE; CLASSIFICATION; FEATURES; SCALE
AB A cosmetic product recognition system is proposed in this paper. For this recognition system, we have proposed a cosmetic product database that contains image samples of forty different cosmetic items. The purpose of this recognition system is to recognize Cosmetic products with there types, brands and retailers such that to analyze a customer experience what kind of products and brands they need. This system has various applications in such as brand recognition, product recognition and also the availability of the products to the vendors. The implementation of the proposed system is divided into three components: preprocessing, feature extraction and classification. During preprocessing we have scaled and transformed the color images into gray-scaled images to speed up the process. During feature extraction, several different feature representation schemes: transformed, structural and statistical texture analysis approaches have been employed and investigated by employing the global and local feature representation schemes. Various machine learning supervised classification methods such as Logistic Regression, Linear Support Vector Machine, Adaptive k-Nearest Neighbor, Artificial Neural Network and Decision Tree classifiers have been employed to perform the classification tasks. Apart from this, we have also performed some data analytic tasks for Brand Recognition as well as Retailer Recognition and for these experimentation, we have employed some datasets from the 'Kaggle' website and have obtained the performance due to the above-mentioned classifiers. Finally, the performance of the cosmetic product recognition system, Brand Recognition and Retailer Recognition have been aggregated for the customer decision process in the form of the state-of-the-art for the proposed system.
C1 [Umer, Saiyed] Engn Aliah Univ, Dept Comp Sci, Kolkata, India.
   [Mohanta, Partha Pratim] Indian Stat Inst, Elect & Commun Sci Unit, Kolkata, India.
   [Rout, Ranjeet Kumar] Natl Inst Technol Srinagar, Dept Comp Sci, Srinagar, Jammu & Kashmir, India.
   [Pandey, Hari Mohan] Edge Hill Univ, Dept Comp Sci, Ormskirk, Lancs, England.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata;
   National Institute of Technology (NIT System); National Institute of
   Technology Srinagar; Edge Hill University
RP Pandey, HM (corresponding author), Edge Hill Univ, Dept Comp Sci, Ormskirk, Lancs, England.
EM saiyedumer@gmail.com; ppmohanta@isical.ac.in;
   ranjeetkumarrout@nitsri.net; Pandeyh@edgehill.ac.uk
RI Pandey, Hari Mohan/M-9658-2015; umer, saiyed/ABD-1070-2021; Rout,
   Ranjeet kumar/AAT-3763-2020; Rout, Ranjeet Kumar/JCE-3978-2023
OI Pandey, Hari Mohan/0000-0002-9128-068X; umer,
   saiyed/0000-0002-1476-041X; Rout, Ranjeet Kumar/0000-0002-1546-1702
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Andrearczyk V, 2016, PATTERN RECOGN LETT, V84, P63, DOI 10.1016/j.patrec.2016.08.016
   [Anonymous], 2012, RETAIL DATA ANAL
   [Anonymous], 2008, PAIN PHYS S, V11, pS5
   [Anonymous], 2019, Ecommerce events history in cosmetics shop
   Bhabatosh C, 2011, DIGITAL IMAGE PROCES
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Chan J, 2017, PROC CVPR IEEE, P3020, DOI 10.1109/CVPR.2017.322
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Costa A. F., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P39, DOI 10.1109/SIBGRAPI.2012.15
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhar V, 2013, COMMUN ACM, V56, P64, DOI 10.1145/2500499
   Ethem A, 2010, INTRO MACHINE LEARNI
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x
   Forsyth D. A., 2002, Computer vision: a modern approach, DOI DOI 10.5555/580035
   Freeman W. T., 1995, P INT WORKSH AUT FAC, V12, P296
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Gonzalez R.C., 2002, Digital image processing second edition, P455
   Gunasekaran A, 2002, INT J PROD ECON, V75, P185, DOI 10.1016/S0925-5273(01)00191-8
   Guyon I, 2006, STUD FUZZ SOFT COMP, V207, P1
   HE DC, 1990, IEEE T GEOSCI REMOTE, V28, P509
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Kephart JO, 2003, COMPUTER, V36, P41, DOI 10.1109/MC.2003.1160055
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lance M, 1999, IEEE T IMAGE PROCESS, V8, P1572, DOI [10.1109/83.799885, DOI 10.1109/83.799885]
   LeCun Y., 2015, Lenet-5, convolutional neural networks
   LIANG M, 2015, PROC CVPR IEEE, P3367, DOI [10.1109/CVPR.2015.7298958, DOI 10.1109/CVPR.2015.7298958]
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG., 2004, U.S. Patent, Patent No. [6,711,293, 6711293]
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   McConnell RK, 1986, US Patent, Patent No. [4,567,610, 4567610]
   Michalski R.S., 2013, Machine Learning: An Artificial Intelligence Approach
   Mullick SS, 2018, IEEE T NEUR NET LEAR, V29, P5713, DOI 10.1109/TNNLS.2018.2812279
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Obdrzálek S, 2006, LECT NOTES COMPUT SC, V4170, P83
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Oluleye HB, 2014, ZERNIKE MOMENTS GENE
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Piccinini P, 2012, IMAGE VISION COMPUT, V30, P573, DOI 10.1016/j.imavis.2012.06.004
   Ponce J., 2007, Toward category-level object recognition, V4170
   Porter S., 1997, Journal of Product Brand Management, V6, P373
   Ramsay JO., 2004, ENCY STAT SCI, V4, P147
   Raschka S., 2015, Python Machine Learning: Unlock Deeper Insights Into Machine Learning with this Vital Guide to Cutting-edge Predictive Analytics
   Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1
   Sachs A.L., 2015, LECT NOTES EC MATH S
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Saravanan C, 2010, INT C COMPUT ENG APP, P196, DOI 10.1109/ICCEA.2010.192
   Shen WY, 2011, MODELLING SIMULATION, P277, DOI 10.1109/CIT.2011.51
   Shih YF, 2017, PROC CVPR IEEE, P7302, DOI 10.1109/CVPR.2017.772
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2008, PROC CVPR IEEE, P2182
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Tang XO, 1998, IEEE T IMAGE PROCESS, V7, P1602, DOI 10.1109/83.725367
   Tokarczyk P, 2015, IEEE T GEOSCI REMOTE, V53, P280, DOI 10.1109/TGRS.2014.2321423
   Umer S, 2018, IETE TECH REV, V35, P145, DOI 10.1080/02564602.2016.1265904
   Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747
   Wu CC, 2015, IEEE ICCE, P25, DOI 10.1109/ICCE-TW.2015.7216881
   Xu ZW, 2017, PROC CVPR IEEE, P5358, DOI 10.1109/CVPR.2017.569
NR 62
TC 14
Z9 15
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 34997
EP 35023
DI 10.1007/s11042-020-09079-y
EA JUN 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000539857100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Chhabra, GS
   Singh, VP
   Singh, M
AF Chhabra, Gurpal Singh
   Singh, Varinder Pal
   Singh, Maninder
TI Cyber forensics framework for big data analytics in IoT environment
   using machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hadoop; Hive; HQL; Mahout; R; Sqoop; Cyber forensic framework
ID SECURITY; INTERNET
AB Forensic analyst skills are at stake for processing of growing data from IoT based environment platforms. Tangible sources often have the size limits, but that's not the case for communication traffic source. Hence, increasing the thirst for an efficient benchmarking for big data analysis. Available solutions to date have used an anomaly-based approach or have proposed approaches based on the deviation from a regular pattern. To tackle the seized bytes, authors have proposed an approach for big data forensics, with efficient sensitivity and precision. In the presented work, a generalized forensic framework has been proposed that use Google's programming model, MapReduce as the backbone for traffic translation, extraction, and analysis of dynamic traffic features. For the proposed technique, authors have used open source tools like Hadoop, Hive, and Mahout and R. Apart from being open source, these tools support scalability and parallel processing. Also, comparative analysis of globally accepted machine learning models of P2P malware analysis in mocked real-time is presented. Dataset from CAIDA was taken and executed in parallel to validate the proposed model. Finally, the forensic performance metrics of the model shows the results with the sensitivity of 99%.
C1 [Chhabra, Gurpal Singh; Singh, Varinder Pal; Singh, Maninder] Thapar Univ, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Chhabra, GS (corresponding author), Thapar Univ, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
EM gurpal.singh@thapar.edu; vpsingh@thapar.edu; msingh@thapar.edu
RI Singh, Maninder/B-7553-2009; singh, maninder/IQS-3568-2023
OI Singh, Maninder/0000-0001-8489-8759; Chhabra, Dr. Gurpal
   Singh/0000-0001-5306-4348; Singh, V. P./0000-0001-7648-9170
CR Al Fahdi M., 2013, 2013 Information Security for South Africa, P1, DOI [10.1109/ISSA.2013.6641058, DOI 10.1109/ISSA.2013.6641058]
   Almulla S, 2013, INT CONF CLOUD COMP, P699, DOI 10.1109/CloudCom.2013.114
   [Anonymous], AP HIV DOC
   [Anonymous], 2000, R LANG DEF
   [Anonymous], DAT EXP SYST APPL DE
   [Anonymous], SQOOP DOC
   [Anonymous], COMP SCI ENG UBMK 20
   [Anonymous], 2017, BLOG HARVARD
   [Anonymous], 2014, P 2 ASE INT C BIG DA
   [Anonymous], AP MAH DOC
   [Anonymous], INN MOB INT SERV UB
   [Anonymous], APPL SYST INN ICASI
   Babar S, 2010, COMM COM INF SC, V89, P420
   Benvenuti C., 2006, Understanding Linux Network Internals
   Bradford A, 2002, HDB BRAIN THEORY NEU
   Carroll O.L., 2008, United States Attorneys Bulletin, V56, P1
   Chun-Feng Liao, 2017, 2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P351, DOI 10.1109/ICCE-China.2017.7991140
   Conti M, 2018, FUTURE GENER COMP SY, V78, P544, DOI 10.1016/j.future.2017.07.060
   Cook K, 2012, IEEE CONF VIS ANAL, P251
   Europol, 2016, INT ORG CRIM THREAT
   Grabosky P, 2016, 2 EVOLUTION CYBERCRI, P15
   Guarino A., 2013, ISSE 2013 SECURING E, P197, DOI DOI 10.1007/978-3-658-03371-2_17
   Help Net Security, 2015, TOP IOT CONC DAT VOL
   Ingersoll G., 2009, INTRO APACHE MAHOUT
   Khanbhai M, 2014, ISRN Hematol, V2014, P547914, DOI 10.1155/2014/547914
   Koroniotis N, 2018, L N INST COMP SCI SO, V235, P30, DOI 10.1007/978-3-319-90775-8_3
   Lavion D, 2018, PWCS 2018 GLOBAL EC
   MacDonald A, 2019, NUTR RES REV, V32, P70, DOI [10.1017/S0954422418000173, 10.1017/s0954422418000173]
   Mayhew M, 2015, IEEE MILIT COMMUN C, P915, DOI 10.1109/MILCOM.2015.7357562
   Meidan Y., 2017, P S APPL COMP, P506, DOI [10.1145/3019612.3019878, DOI 10.1145/3019612.3019878]
   Merino Borja., 2013, Instant Traffic Analysis with Tshark How-to
   Mylavarapu G, 2015, HIGH PERFORMANCE COM
   Neshatpour K, 2015, ANN IEEE SYM FIELD P, P164, DOI 10.1109/FCCM.2015.59
   Ngu AH, 2017, IEEE INTERNET THINGS, V4, P1, DOI 10.1109/JIOT.2016.2615180
   Owen Seaon., 2012, Mahout in Action
   Pajouh NH, 2019, IEEE T EMERG TOP COM, V7, P314, DOI 10.1109/TETC.2016.2633228
   Pakalra EG, 2017, CHOOSE ALGORITHMS MI
   Pan X, 2009, INT S SOFTW REL ENG
   Perumal S, 2015, 2015 FIFTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION PROCESSING AND COMMUNICATIONS (ICDIPC), P19, DOI 10.1109/ICDIPC.2015.7323000
   Puthal D, 2018, L N INST COMP SCI SO, V189, P243, DOI 10.1007/978-3-319-67636-4_25
   Ramanathan R, 2019, CLUSTER COMPUT, V22, P14061, DOI 10.1007/s10586-018-2234-8
   Rathore MM, 2016, J SUPERCOMPUT, V72, P3489, DOI 10.1007/s11227-015-1615-5
   Razzaq A, 2014, INFORM SCIENCES, V254, P19, DOI 10.1016/j.ins.2013.08.007
   Ripley BD, R WINDOWS FAQ
   Salcedo-Campos F, 2012, INFORM SCIENCES, V195, P45, DOI 10.1016/j.ins.2012.01.022
   Sánchez-Artigas M, 2013, INFORM SCIENCES, V236, P33, DOI 10.1016/j.ins.2013.02.034
   Schoof R., 2007, Detecting peer-to-peer botnets'
   Shvachko K., 2010, SYMPOSIUM, P1, DOI DOI 10.1109/MSST.2010.5496972
   Singh K, 2014, INFORM SCIENCES, V278, P488, DOI 10.1016/j.ins.2014.03.066
   Skopko T, 2012, CARPATHIAN J ELECT C, V5, P107
   Srinivasan MK, 2018, ISEC'18: PROCEEDINGS OF THE 11TH INNOVATIONS IN SOFTWARE ENGINEERING CONFERENCE, DOI 10.1145/3172871.3172886
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Thusoo A, 2009, PROC VLDB ENDOW, V2, P1626, DOI 10.14778/1687553.1687609
   Uzun M, 2016, NETW COMP COMM ISNCC, P1, DOI [10.1109/ISNCC.2016.7746114, DOI 10.1109/ISNCC.2016.7746114]
   Verma S, 2017, IEEE COMMUN SURV TUT, V19, P1457, DOI 10.1109/COMST.2017.2694469
   Wang C, 2015, AAAI CONF ARTIF INTE, P1861
   Wang XF, 2018, IEEE WIREL COMMUN, V25, P32, DOI 10.1109/MWC.2018.1700215
   Yen TF, 2010, INT CON DISTR COMP S, DOI 10.1109/ICDCS.2010.76
   Zheng XH, 2015, NEUROCOMPUTING, V159, P27, DOI 10.1016/j.neucom.2015.02.047
   Zuech R., 2015, J. Big Data, V1, P1, DOI [10.1186/s40537-015-0013-4, DOI 10.1186/S40537-015-0013-4]
NR 60
TC 24
Z9 26
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 15881
EP 15900
DI 10.1007/s11042-018-6338-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600006
DA 2024-07-18
ER

PT J
AU Cui, Y
   Zhang, R
   Gao, HC
   Lu, YY
   Liu, YQ
   Gao, GW
AF Cui, Yan
   Zhang, Rui
   Gao, Huacheng
   Lu, Yuanyuan
   Liu, Yinqiu
   Gao, Guangwei
TI A novel biclustering of gene expression data based on hybrid BAFS-BSA
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Microarray; Gene expression data; Biclustering; Binary artificial fish
   swarm algorithm; Binary simulated annealing algorithm
AB As one of usual concepts, co-expressed genes can represent co-regulated genes in gene expression data. This strategy can be refined further because co-expression of the genome may be the result of independent activation under same experimental samples, rather than the same regulatory regime. Therefore, traditional clustering techniques are proposed to find significant clusters, especially, the biclustering technology. By combining Binary Artificial Fish Swarm (BAFS) with Binary Simulated Annealing (BSA) algorithms, the hybrid algorithm named BAFS-BSA-BIC was proposed in this paper. When this method of biclustering was applied to several datasets, lots of biological significant bifclusters were searched, and the results demonstrate the promising clustering performance of our method. The proposed technology was also compared to classical biclustering technologies-CC, QUBIC, FLOC and original BAFS algorithm, and its robustness and quality are better than these algorithms in searching optimal biclusters of co-expressed genes.
C1 [Cui, Yan; Zhang, Rui; Gao, Huacheng; Lu, Yuanyuan; Liu, Yinqiu] Nanjing Univ Posts & Telecommun, Natl Engn Reaearch Ctr Commun & Network Technol, Nanjing 210003, Peoples R China.
   [Gao, Guangwei] Nanjing Univ Posts & Telecommun, Inst Adv Technol, Nanjing 210003, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Posts & Telecommunications
RP Cui, Y (corresponding author), Nanjing Univ Posts & Telecommun, Natl Engn Reaearch Ctr Commun & Network Technol, Nanjing 210003, Peoples R China.
EM cuiyan@njupt.edu.cn
RI Zhang, Yonghui/AGY-9072-2022; Liu, Yinqiu/AAE-6869-2020
CR Aarts E., 1989, HDB BRAIN THEORY NEU
   [Anonymous], 2015, International Journal for Computational Biology (IJCB), DOI DOI 10.34040/IJCB.4.1.2014.36
   Banka Haider., 2006, UBIQUITY, V7, P1, DOI DOI 10.1145/1183081.1183082
   Ben-Dor A, 2003, J COMPUT BIOL, V10, P373, DOI 10.1089/10665270360688075
   Bergmann S, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.031902
   Bouleimen K, 2003, EUR J OPER RES, V149, P268, DOI 10.1016/S0377-2217(02)00761-0
   Bryan K, 2005, COMP MED SY, P383, DOI 10.1109/CBMS.2005.37
   Busygin S, 2008, COMPUT OPER RES, V35, P2964, DOI 10.1016/j.cor.2007.01.005
   Cheng Y, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P93
   Hochreiter S, 2010, BIOINFORMATICS, V26, P1520, DOI 10.1093/bioinformatics/btq227
   Jaskowiak PA, 2013, IEEE ACM T COMPUT BI, V10, P845, DOI 10.1109/TCBB.2013.9
   Jung TW, 2019, ZOOKEYS, P1, DOI 10.3897/zookeys.886.38511
   Katayama K, 2001, EUR J OPER RES, V134, P103, DOI 10.1016/S0377-2217(00)00242-3
   Lan RS, 2019, APPL SOFT COMPUT, V74, P693, DOI 10.1016/j.asoc.2018.08.049
   Li GJ, 2009, NUCLEIC ACIDS RES, V37, DOI 10.1093/nar/gkp491
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Ma PCH, 2009, IEEE T BIO-MED ENG, V56, P1803, DOI 10.1109/TBME.2009.2015055
   Madeira SC, 2004, IEEE ACM T COMPUT BI, V1, P24, DOI 10.1109/TCBB.2004.2
   Markowetz F, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-S6-S5
   Nepomuceno JA, 2015, COMPUT METH PROG BIO, V119, P163, DOI 10.1016/j.cmpb.2015.02.010
   Nepomuceno JA, 2011, BIODATA MIN, V4, DOI 10.1186/1756-0381-4-3
   Panteli A., 2019, OPER RES-GER, P1
   Pontes B, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0115497
   Rathipriya R, ARXIV11080748
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Shuai Bing, 2018, PROC BRIT MACH VIS C, P1
   Tanay A, HDB BIOINFORMATICS B
   Yang J, 2005, INT J ARTIF INTELL T, V14, P771, DOI 10.1142/S0218213005002387
   Yongming Cheng, 2009, Proceedings of the 2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2009), P141, DOI 10.1109/FSKD.2009.534
   Zhang Y, 2018, J NETW COMPUT APPL, V117, P10, DOI 10.1016/j.jnca.2018.05.007
   Zhong YR, 2018, INT C DIGITAL HOME, P1, DOI 10.1109/ICDH.2018.00008
NR 33
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14811
EP 14824
DI 10.1007/s11042-019-7656-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900028
DA 2024-07-18
ER

PT J
AU Jang, SW
   Ahn, B
AF Jang, Seok-Woo
   Ahn, Byeongtae
TI Effective detection of exposed target regions based on deep learning
   from multimedia data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia data; Deep learning; Target object area; Skin color;
   Convolution layer; Feature extraction
ID FACE DETECTION; NEURAL-NETWORK; IMAGE
AB With the development of high-performance visual sensors, it has been very easy to obtain a variety of image data. Of these image data, human face regions contain personal information to distinguish one from the others. Therefore, it is important to accurately detect unhidden face regions from an input image. This paper proposes a method of robustly detecting human face regions from an input color image with the use of a deep learning algorithm, one of the machine learning algorithms. The proposed method first transforms the RGB color model of an input image to the YC(b)C(r)color model, and then removes other regions than face regions to segment skin regions with the use of the pre-learned elliptical skin color distribution model. Subsequently, a CNN model-based deep learning algorithm was applied to robustly detect human face regions from the detected skin regions in the previous step. As a result, the proposed method segments face regions more efficiently than an existing method. The face region detection method proposed in this paper is expected to be usefully applied to practical areas related to multimedia data processing, such as video surveillance, target blocking, image security, visual data analysis, and object recognition and tracking.
C1 [Jang, Seok-Woo] Anyang Univ, Dept Software, 22,37 Beongil, Anyang 14028, South Korea.
   [Ahn, Byeongtae] Anyang Univ, Liberal & Arts Coll, 22,37 Beongil, Anyang 14028, South Korea.
C3 Anyang University; Anyang University
RP Ahn, B (corresponding author), Anyang Univ, Liberal & Arts Coll, 22,37 Beongil, Anyang 14028, South Korea.
EM swjang7285@gmail.com; ahnbt@anyang.ac.kr
OI Jang, Seok-Woo/0000-0001-5580-4098; Ahn, Byeong-Tae/0000-0003-3431-9493
CR Akresh Michael E., 2015, Caribbean Naturalist, P1
   Al-Mohair HK, 2015, APPL SOFT COMPUT, V33, P337, DOI 10.1016/j.asoc.2015.04.046
   Amina S, 2018, COMMUN NONLINEAR SCI, V60, P12, DOI 10.1016/j.cnsns.2017.12.017
   Andrews JL, 2017, COMPUT STAT DATA AN, V127, P60
   Chakraborty BK, 2017, PATTERN RECOGN LETT, V88, P33, DOI 10.1016/j.patrec.2017.01.005
   Chifor BC, 2018, FUTURE GENER COMP SY, V86, P740, DOI 10.1016/j.future.2017.05.048
   Frank JA, 2017, IEEE ROBOT AUTOM LET, V2, P1901, DOI 10.1109/LRA.2017.2714128
   Hamuda E, 2017, COMPUT ELECTRON AGR, V133, P97, DOI 10.1016/j.compag.2016.11.021
   Le THN, 2018, IEEE T IMAGE PROCESS, V27, P2393, DOI 10.1109/TIP.2018.2794205
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Huang QY, 2017, IEEE T IND INFORM, V13, P2956, DOI 10.1109/TII.2017.2753319
   Kumari A, 2018, J NETW COMPUT APPL, V124, P169, DOI 10.1016/j.jnca.2018.09.014
   Larsson M, 2018, APPL SOFT COMPUT, V70, P465, DOI 10.1016/j.asoc.2018.05.038
   Lee KM, 2008, PATTERN RECOGN LETT, V29, P200, DOI 10.1016/j.patrec.2007.09.013
   Li J, 2017, IEEE T NEUR NET LEAR, V28, P1425, DOI 10.1109/TNNLS.2016.2541681
   Li M, 2017, IEEE T HUM-MACH SYST, V47, P822, DOI 10.1109/THMS.2017.2700630
   Lou S, 2012, PRECIS ENG, V36, P414, DOI 10.1016/j.precisioneng.2012.01.003
   Niu G, 2018, J VIS COMMUN IMAGE R, V55, P457, DOI 10.1016/j.jvcir.2018.07.001
   Paolillo A, 2018, IEEE ROBOT AUTOM LET, V3, P2746, DOI 10.1109/LRA.2018.2835515
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Ren LL, 2017, PATTERN RECOGN, V72, P446, DOI 10.1016/j.patcog.2017.06.037
   Sáez JA, 2016, NEUROCOMPUTING, V176, P26, DOI 10.1016/j.neucom.2014.11.086
   Shi C, 2018, NEUROCOMPUTING, V294, P82, DOI 10.1016/j.neucom.2018.03.012
   Silva HO, 2018, ENG APPL ARTIF INTEL, V70, P184, DOI 10.1016/j.engappai.2018.02.002
   Su R, 2014, PATTERN RECOGN, V47, P3193, DOI 10.1016/j.patcog.2014.04.024
   Tsai TH, 2014, IEEE T IMAGE PROCESS, V23, P1047, DOI 10.1109/TIP.2014.2298982
   Tusar T, 2017, APPL SOFT COMPUT, V59, P77, DOI 10.1016/j.asoc.2017.05.027
   Yang XT, 2018, IEEE SENS J, V18, P6461, DOI 10.1109/JSEN.2018.2847332
   Yao L, 2018, IEEE T IND ELECTRON, V65, P1490, DOI 10.1109/TIE.2017.2733448
   Yeong Nam Chae, 2009, Journal of KISS: Software and Applications, V36, P548
   Yu W, 2018, COMPUT VIS IMAGE UND, V169, P40, DOI 10.1016/j.cviu.2018.01.001
   Zhang C, 2014, IEEE WINT CONF APPL, P1036, DOI 10.1109/WACV.2014.6835990
   Zhang SM, 2017, IEEE T HUM-MACH SYST, V47, P814, DOI 10.1109/THMS.2017.2693238
   Zhang Y, 2018, IEEE T IMAGE PROCESS, V27, P5113, DOI 10.1109/TIP.2018.2851390
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
   Zhou W, 2016, INFORM SCIENCES, V358, P191, DOI 10.1016/j.ins.2016.04.003
NR 37
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16609
EP 16625
DI 10.1007/s11042-019-07832-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600045
DA 2024-07-18
ER

PT J
AU Liu, RJ
   Yang, R
   Li, SX
   Shi, YQ
   Jin, X
AF Liu, Ruijun
   Yang, Rui
   Li, Shanxi
   Shi, Yuqian
   Jin, Xin
TI Painting completion with generative translation models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image completion; Semantic inpainting; Computer vision; Generative model
AB Image completion has always been an important research area of image processing. With the continuous development of the deep learning model in recent years, further progress has been made in the repair of images. In this paper, we focused on realistic and painting portrait data, studied on semantic inpainting techniques based on regional completions, and proposed an improved generative translation model. Through the context generation network and the image discriminator network, a patch image is generated which should keep consistency between the hole and the surrounding area. Then the completed part will be processed according to the scene structure of the image through the style translation network to ensure the consistency between the generated area and the whole image, which means the repair part can better adapt to the style, texture, and structure of the artistic work. Experiments have shown that our method could achieve good results in the completion of realistic and painting portraits, and it also provided some reference for restoration and identification of art works.
C1 [Liu, Ruijun; Yang, Rui; Li, Shanxi; Shi, Yuqian] Beijing Technol & Business Univ, Sch Comp Informat & Engn, Beijing, Peoples R China.
   [Liu, Ruijun; Yang, Rui; Li, Shanxi; Shi, Yuqian] Beijing Key Lab Big Data Technol Food Safety, Beijing, Peoples R China.
   [Jin, Xin] Beijing Elect Sci & Technol Inst, Dept Comp Sci & Technol, Beijing, Peoples R China.
C3 Beijing Technology & Business University; Beijing Electronic Science &
   Technology Institute
RP Liu, RJ (corresponding author), Beijing Technol & Business Univ, Sch Comp Informat & Engn, Beijing, Peoples R China.; Liu, RJ (corresponding author), Beijing Key Lab Big Data Technol Food Safety, Beijing, Peoples R China.
EM liuruijun@btbu.edu.cn; ruiyang@st.btbu.edu.cn; shanxi@st.btbu.edu.cn;
   yuqianshi@st.btbu.edu.cn; jinxinbesti@foxmail.com
RI jin, xin/GQZ-5811-2022; Shi, Yuqian/D-7230-2017
OI Liu, Ruijun/0000-0003-4871-8989
CR Afonso MV, 2011, IEEE T IMAGE PROCESS, V20, P681, DOI 10.1109/TIP.2010.2076294
   [Anonymous], 2016, P IEEE C COMPUTER VI
   [Anonymous], 2016, NIPS
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271
   Huang JB, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601205
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kingma DP, 2013, ARXIV
   Liu SF, 2016, LECT NOTES COMPUT SC, V9908, P560, DOI 10.1007/978-3-319-46493-0_34
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Quan Z, 2018, WORLD WIDE WEB, V22, P1
   Radford A., 2015, ARXIV151106434
   Ren JS., 2015, ADV NEURAL INFORM PR, V1, P901
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Wang D, 2016, IEEE T CIRC SYST VID, V26, P1709, DOI 10.1109/TCSVT.2015.2462012
   Wang D, 2015, IEEE T IMAGE PROCESS, V24, P2646, DOI 10.1109/TIP.2015.2427518
   Xie J., 2012, ADV NEURAL INFORM PR, P341
   Yang WB, 2017, COMM COM INF SC, V771, P696, DOI 10.1007/978-981-10-7299-4_58
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Zhou Q, 2016, PATTERN RECOGN, V59, P312, DOI 10.1016/j.patcog.2016.03.023
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 28
TC 16
Z9 16
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14375
EP 14388
DI 10.1007/s11042-018-6761-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900004
DA 2024-07-18
ER

PT J
AU Park, JS
   Kim, SH
AF Park, Jeong-Sik
   Kim, Seok-Hoon
TI Sound learning-based event detection for acoustic surveillance sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic surveillance sensor; Surveillance system; Sound learning;
   Acoustic event detection
ID RECOGNITION
AB This study proposes an event detection technique for acoustic surveillance that detects emergency situations by using acoustic sensors. Most surveillance systems have widely depended on visual data recorded by closed-circuit television (CCTV) cameras, but more intelligent systems are now beginning to use audio information for more reliable detection of emergency situations. Most of the conventional studies on acoustic event detection adopt limited types of acoustic data and are based on simple algorithms, such as energy-based determination. Thus, these approaches are easily realized, but may induce serious detection errors in real-world applications. In this study, we propose an event detection technique based on a sound-learning algorithm to be adopted by real-time acoustic surveillance systems. One main process of this technique is to construct acoustic models via learning algorithms from sound data collected according to types of acoustic events. The models are used to determine whether audio streams entering an acoustic sensor refer to the events or not. In event detection experiments performed in an outdoor environment, the proposed approach outperformed conventional approaches in the real-time detection of acoustic events.
C1 [Park, Jeong-Sik] Hankuk Univ Foreign Studies, Dept English Linguist & Language Technol, Seoul, South Korea.
   [Kim, Seok-Hoon] Paichai Univ, Dept Elect Commerce, Daejeon, South Korea.
C3 Hankuk University Foreign Studies; Pai Chai University
RP Kim, SH (corresponding author), Paichai Univ, Dept Elect Commerce, Daejeon, South Korea.
EM parkjs@hufs.ac.kr; kimshn@pcu.ac.kr
OI Park, Jeong-Sik/0000-0002-4213-8775
CR BILMES J, 1997, ICSITR97021 U BERK
   Campbell JP, 1997, P IEEE, V85, P1437, DOI 10.1109/5.628714
   Clavel C., 2005, IEEE INT C MULT EXP
   Cornacchia M, 2017, IEEE SENS J, V17, P386, DOI 10.1109/JSEN.2016.2628346
   Didrikas T, 2011, NORLT0047 KLAIP U
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Huang PS, 2011, IEEE INT C AC SPEECH
   Kang K, 2016, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2016.95
   Lurton X., 2002, An introduction to underwater acoustics: principles and applications
   Lyon D., 2007, SURVEILLANCE STUDIES
   Mesaros A, 2010, EUR SIGN PROC C
   Ntalampiras S, 2009, IEEE INT C AC SPEECH
   Park JS, 2012, IEEE T CONSUM ELECTR, V58, P1000, DOI 10.1109/TCE.2012.6311348
   Park JS, 2009, IEEE T CONSUM ELECTR, V55, P1590, DOI 10.1109/TCE.2009.5278031
   Park K, 2010, IEEE T CONSUM ELECTR, V56, P1123, DOI 10.1109/TCE.2010.5506048
   Phillips PJ, 2000, COMPUTER, V33, P56, DOI 10.1109/2.820040
   Qureshi FZ, 2006, MULTIMEDIA SYST, V12, P269, DOI 10.1007/s00530-006-0059-4
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Turaga P, 2011, IEEE SENS J, V11, P593, DOI 10.1109/JSEN.2010.2050309
   Zhu Z, 2009, MULTIMODAL SURVEILLA
   Zhuang XD, 2010, PATTERN RECOGN LETT, V31, P1543, DOI 10.1016/j.patrec.2010.02.005
NR 21
TC 5
Z9 5
U1 5
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16127
EP 16139
DI 10.1007/s11042-019-7547-y
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600018
DA 2024-07-18
ER

PT J
AU Xiao, YH
   Cao, DL
   Gao, LP
AF Xiao, Yihan
   Cao, Dalu
   Gao, Lipeng
TI Face detection based on occlusion area detection and recovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Face occlusion; Saliency detection; Robust PCA; Adaboost
ID SUBSPACE
AB Face detection is an important part of face image processing. In many cases, face images have occlusion problems. In this paper, the POOA (positioning the optimal occlusion area) algorithm is proposed for the problem of occlusion face detection. After obtaining the data of the saliency detection processing, firstly, the algorithm computes an average gray value according to the face image, and multiplies the appropriate coefficient as a threshold to obtain a binary image. Then, using the idea of the Haar feature, the two features of "large rectangle" and "large T shape" are used for retrieval, and the occlusion region of the face is obtained by combining the binary images. Finally, a robust principal component analysis (PCA) method is used to obtain the best projection of the occlusion face, and the face occlusion area is filled. The algorithm proposed in this paper is fast. The Adaboost method has achieved good results in terms of occlusion area, size and shape, and the detection precision has also been improved to varying degrees.
C1 [Xiao, Yihan; Cao, Dalu; Gao, Lipeng] Harbin Engn Univ, Coll Informat & Commun Engn, Harbin, Peoples R China.
C3 Harbin Engineering University
RP Gao, LP (corresponding author), Harbin Engn Univ, Coll Informat & Commun Engn, Harbin, Peoples R China.
EM xiaoyihan@hrbeu.edu.cn; 1910545964@qq.com; gaolipeng@hrbeu.edu.cn
CR Ao L, 2018, IEEE ACCESS, P1
   Chan PPK, 2018, IEEE T INF FOREN SEC, V13, P521, DOI 10.1109/TIFS.2017.2758748
   Ding G, 2018, IEEE COMMUNICATIONS, P1
   Ding GR, 2018, IEEE COMMUN MAG, V56, P29, DOI 10.1109/MCOM.2017.1700452
   Ding GR, 2017, IEEE T VEH TECHNOL, V66, P8022, DOI 10.1109/TVT.2017.2693384
   Ding GR, 2015, IEEE COMMUN MAG, V53, P178, DOI 10.1109/MCOM.2015.7158283
   Ding GR, 2013, IEEE SIGNAL PROC MAG, V30, P126, DOI 10.1109/MSP.2013.2251071
   Duan J., 2016, ASIAN C COMPUTER VIS, P319
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Huang QY, 2017, IEEE T IND INFORM, V13, P2956, DOI 10.1109/TII.2017.2753319
   Ji PF, 2016, ACSIS-ANN COMPUT SCI, V8, P253, DOI 10.15439/2016F508
   Jin SY, 2017, IEEE I CONF COMP VIS, P5286, DOI 10.1109/ICCV.2017.564
   Jinghui LI, 2017, ADABOOST FACE DETECT, V16, P22
   Khan MH, 2017, IEEE I CONF COMP VIS, P3811, DOI 10.1109/ICCV.2017.409
   Li A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199141
   [李根 Li Gen], 2015, [电子学报, Acta Electronica Sinica], V43, P198
   Lin YQ, 2019, INT J HYPERTHER, V35, P450, DOI 10.1080/02656736.2018.1507047
   Lin Y, 2019, J SUPERCOMPUT, V75, P3010, DOI 10.1007/s11227-017-2216-2
   Lin Y, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16101675
   Lin Z, 2010, APPL PHYS LETT, V97, DOI 10.1063/1.3533259
   Liu GC, 2012, NEURAL COMPUT, V24, P3371, DOI 10.1162/NECO_a_00369
   Liu S, 2017, FRACTALS, V25, DOI 10.1142/S0218348X17400047
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Liu X, 2013, SIAM J SCI COMPUT, V35, pA1641, DOI 10.1137/120871328
   Lv JJ, 2017, PROC CVPR IEEE, P3691, DOI 10.1109/CVPR.2017.393
   Mao X, 2009, 2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES, P113, DOI 10.1109/WIAMIS.2009.5031445
   Min R, 2014, SCI WORLD J, V35, P519
   Murphy TM, 2017, IET BIOMETRICS, V6, P200, DOI 10.1049/iet-bmt.2016.0037
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Qian JJ, 2014, IEEE COMPUT SOC CONF, P21, DOI 10.1109/CVPRW.2014.9
   Tu Y, 2018, CMC-COMPUT MATER CON, V55, P243, DOI 10.3970/cmc.2018.01755
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang J, 2016, PROC CVPR IEEE, P2295, DOI 10.1109/CVPR.2016.252
   [王弯弯 Wang Wanwan], 2018, [电子学报, Acta Electronica Sinica], V46, P646
   Wu QD, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/586014
   Wu QD, 2017, MULTIMED TOOLS APPL, V76, P17179, DOI 10.1007/s11042-016-3760-0
   Wu Y, 2017, PROC CVPR IEEE, P5719, DOI 10.1109/CVPR.2017.606
   Wu Y, 2015, IEEE I CONF COMP VIS, P3658, DOI 10.1109/ICCV.2015.417
   Wu Y, 2014, PROC CVPR IEEE, P1781, DOI 10.1109/CVPR.2014.230
   Yin SY, 2017, IEEE SYST J, V11, P260, DOI 10.1109/JSYST.2015.2418680
   Zhang Shu, 2013, Journal of Software, V24, P2747, DOI 10.3724/SP.J.1001.2013.04484
NR 41
TC 6
Z9 7
U1 5
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16531
EP 16546
DI 10.1007/s11042-019-7661-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600041
DA 2024-07-18
ER

PT J
AU Abdelwahed, MF
AF Abdelwahed, Mohamed F.
TI A hybrid method for data compression and encryption based on bit
   packing, 128-based numerals, and bitmap manipulations: application to
   seismic data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bitmap data; base128 numerical system; 128-bit encryption; Data
   compression; Steim method
ID ALGORITHM
AB Numerous seismic datasets are routinely acquired, stored and transferred via different systems and networks. Significant reduction of data sizes with encryption would significantly reduce storage media and transmission costs and security. This study presents a novel approach for compressing and encrypting numerical data in descriptive bitmap images. The method depends on the Steim method for bit-packing and the 128-bit numerical system for encryption and bitmap manipulations for compression. The method produced encrypted data capsules in a WebP image file. For seismic data, it is found that the size of the WebP image comprises similar to 20% of the corresponding binary size with a bit-rate of similar to 5.6 b/s which is smaller than that of the Steim form, 27% and 8.9 b/s, respectively. The size of the redundant data is reduced to similar to 0.1% with a bit rate similar to 0.04 b/s. Regarding the compression speed, it is found that the code compresses data with a rate of similar to 11,118 samples/s or similar to 44 Kbytes/s in average. For the first time, this study provides an unconventional use of an image file to hold a big amount of 128-bit encrypted data in a compressible form. It is proven that the data in the WebP format, regardless of being encrypted, occupies the least amount of storage space among other image formats, that can be easily handled, stored, and shared through clouds and devices safely with a lower cost.
C1 [Abdelwahed, Mohamed F.] King Abdulaziz Univ, Geohazards Res Ctr, Jeddah, Saudi Arabia.
   [Abdelwahed, Mohamed F.] NRIAG, Natl Res Inst Astron & Geophys, Cairo, Egypt.
C3 King Abdulaziz University; Egyptian Knowledge Bank (EKB); National
   Research Institute of Astronomy & Geophysics - NRIAG
RP Abdelwahed, MF (corresponding author), King Abdulaziz Univ, Geohazards Res Ctr, Jeddah, Saudi Arabia.; Abdelwahed, MF (corresponding author), NRIAG, Natl Res Inst Astron & Geophys, Cairo, Egypt.
EM mfarouk40@yahoo.com
RI Abdelwahed, Mohamed Farouk/D-5902-2013
OI Abdelwahed, Mohamed Farouk/0000-0003-1612-6997
CR Abdelwahed MF, 2012, COMPUT GEOSCI-UK, V40, P153, DOI 10.1016/j.cageo.2011.06.019
   Adobe, 1986, TAGG IM FIL FORM TIF
   [Anonymous], 2011, QR COD ESS
   Blackstock S, 1987, LZW GIF EXPLAINED
   Boussif M, 2019, MULTIMED TOOLS APPL, V78, P35493, DOI 10.1007/s11042-019-08108-9
   Bradski G, 2000, LEARNING OPENCV COMP
   Burrows M., 1994, SRC RES REPORT 124
   Chai XL, 2019, MULTIMED TOOLS APPL, V78, P35419, DOI 10.1007/s11042-019-08168-x
   Cooper AB, 1984, US patent, Patent No. [CA2260883 A1, 2260883]
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   David Salomon., 2002, GUIDE DATA COMPRESSI
   Federal Telephone and Radio Corporation, 1946, REF DAT RAD ENG, P52
   Google Inc, 2009, WEBP FORM LOSSL LOSS
   GSE, 1997, PROV GSE2 1 MESS FOR
   Held C, 1984, DATA COMPRESSION TEC
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Islam MT, 2019, INT C COMP COMM CHEM, DOI [10.1109/IC4ME247184.2019.9036662, DOI 10.1109/IC4ME247184.2019.9036662]
   Kumar V, 2019, MINI-REV ORG CHEM, V16, P12, DOI 10.2174/1570193X15666180406142116
   Li HL, 2017, COMPUT GEOSCI-UK, V100, P41, DOI 10.1016/j.cageo.2016.11.017
   Li X, 2015, J AMB INTEL HUM COMP, V6, P563, DOI 10.1007/s12652-013-0217-4
   Luo HB, 2019, MULTIMED TOOLS APPL, V78, P34323, DOI 10.1007/s11042-019-08072-4
   Nanometrics Inc, 2017, TAUR ISNTR
   Ratha P, 2015, PROCEDIA COMPUT SCI, V57, P1235, DOI 10.1016/j.procs.2015.07.422
   ROBINSON AH, 1967, PR INST ELECTR ELECT, V55, P356, DOI 10.1109/PROC.1967.5493
   Salomon D, 2010, HDB DATA COMPRESSION, DOI [10.1007/10.1007/978-1-84882-903-9, DOI 10.1007/10.1007/978-1-84882-903-9]
   SEED, 2012, STAND EXCH EARTHQ DA
   SEG, 2002, SEG REV1 DAT EXCH FO
   Sivanantham S, 2014, INTEGRATION, V47, P499, DOI 10.1016/j.vlsi.2013.12.001
   Stallings W, 2002, CRYPTOLOGIA, V26, P165, DOI 10.1080/0161-110291890876
   Steim J. M., 1994, STEIM COMPRESSION
   Tapley WC, 1990, SEISMIC ANAL CODE SA
   Trimble, 2017, GEOPH MON SOL
   Warnock J, 1982, POSTSCRIPT LANGUAGE
   Wessel P, 2003, COMPUT GEOSCI-UK, V29, P665, DOI 10.1016/S0098-3004(03)00038-4
   Wiggins RH, 2001, RADIOGRAPHICS, V21, P789, DOI 10.1148/radiographics.21.3.g01ma25789
   Wu WB, 2006, INT GEOSCI REMOTE SE, P787, DOI 10.1109/IGARSS.2006.202
   Zebari DA, 2019, I C SOFTWARE KNOWL I, DOI 10.1109/skima47702.2019.8982392
   ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714
   ZIV J, 1978, IEEE T INFORM THEORY, V24, P530, DOI 10.1109/TIT.1978.1055934
NR 39
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22705
EP 22726
DI 10.1007/s11042-020-09082-3
EA MAY 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000554789500001
DA 2024-07-18
ER

PT J
AU del Molino, J
   Bibiloni, T
   Oliver, A
AF del Molino, Javier
   Bibiloni, Toni
   Oliver, Antoni
TI Keys for successful 360° hypervideo design: A user study based on an
   xAPI analytics dashboard
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 360 degrees video; Dashboard; Hypervideo; User behavior; Video
   analytics; xAPI
AB One of the most recent trends in the evaluation of immersive virtual environments is the incorporation of user metrics. In this article, we conduct a user study on a 360 degrees hypervideo, using a dashboard based on detailed metrics obtained from users' interactions with 360 degrees hypervideos. It is essential to evaluate the quality of experience to monitor service quality from the perspectives of consumers. We demonstrate a framework to examine the user experiences of 360 degrees environments and evaluate them using the xAPI specification, facilitating the development of analytics solutions centered in the user experience; and how the graphs and related data composing the dashboard provide valuable information about ways of navigating and interacting with 360 degrees video experiences, as well as the time invested in them. In the user study, we include the visual perception, attention, tracking and interaction of users watching Proemaid (a 360 degrees multimedia production), collected from an interactive 360 degrees video player in the form of xAPI statements. The Proemaid production has been played in a vast variety of contexts by stakeholders from government, technology and education, among others. Therefore, the quantitative results and the qualitative analysis of the user study are intended to outline a sketch of the users' ways of navigating, interacting and investing time in 360 degrees hypervideo productions. We consider that these metrics will be very interesting in the specification of new omnidirectional storyboards for film producers of content in 360 degrees. Finally, we propose potential directions for empirical investigation that highlight its great potential in many fields.
C1 [del Molino, Javier; Bibiloni, Toni; Oliver, Antoni] Univ Balearic Isl UIB, Dept Math & Comp Sci DMI, Multimedia Informat Technol Lab LTIM, Carretera Valldemossa,Km 7-5, Palma De Mallorca 07122, Illes Balears, Spain.
C3 Universitat de les Illes Balears
RP del Molino, J (corresponding author), Univ Balearic Isl UIB, Dept Math & Comp Sci DMI, Multimedia Informat Technol Lab LTIM, Carretera Valldemossa,Km 7-5, Palma De Mallorca 07122, Illes Balears, Spain.
EM j.delmolino1@estudiant.uib.es
RI Bibiloni, Toni/G-3426-2015; Oliver Tomas, Antoni/L-4256-2018
OI Bibiloni, Toni/0000-0002-7359-8280; Oliver Tomas,
   Antoni/0000-0002-2495-5245
CR Acharya S, 1999, P MULT COMP NETW MMC, V3969, DOI [10.1117/12.373516, DOI 10.1117/12.373516]
   Agarwala M., 2012, 2012 IEEE 12th International Conference on Advanced Learning Technologies, P629, DOI [DOI 10.1109/ICALT.2012.127, 10.1109/ICALT.2012.127]
   Antoni Oliver, 2019, WORLD C INF SYST COM, P275
   Aubert Olivier, 2014, 6th International Conference on Computer-Supported Education (CSEDU 2014). Proceedings, P479
   Bakharia A, 2016, LAK '16 CONFERENCE PROCEEDINGS: THE SIXTH INTERNATIONAL LEARNING ANALYTICS & KNOWLEDGE CONFERENCE,, P378, DOI 10.1145/2883851.2883882
   Berg A, 2016, IEEE INT CONF ADV LE, P234, DOI 10.1109/ICALT.2016.48
   Bibiloni T, 2018, MULTIMED TOOLS APPL, V77, P20597, DOI 10.1007/s11042-017-5510-3
   Brar J, 2017, COMPUT HUM BEHAV, V70, P475, DOI 10.1016/j.chb.2017.01.014
   Brinton CG, 2016, IEEE T SIGNAL PROCES, V64, P3677, DOI 10.1109/TSP.2016.2546228
   Brooks AL, 2013, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INTERNET TECHNOLOGIES AND APPLICATIONS (ITA 13), P9
   Calmettes G, 2012, J PHYSIOL-LONDON, V590, P3403, DOI 10.1113/jphysiol.2012.239376
   Cattaneo AAP, 2019, INTERACT LEARN ENVIR, V27, P508, DOI 10.1080/10494820.2018.1486860
   Corbillon X, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P199, DOI 10.1145/3083187.3083215
   David EJ, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P432, DOI 10.1145/3204949.3208139
   De Abreu A., 2017, PROC IEEE 9 INT C QU, P1, DOI 10.1109/QoMEX.2017.7965634
   de Boer J, 2011, COMPUT EDUC, V56, P727, DOI 10.1016/j.compedu.2010.10.015
   Debevc M, 2011, MULTIMED TOOLS APPL, V54, P181, DOI 10.1007/s11042-010-0529-8
   Fahmy Yousef Ahmed Mohamed., 2015, Proceedings of the Third European MOOCs Stakeholders Summit EMOOCs, P131
   Gaudenzi S., 2013, Doctorado disertacion
   Giannakos Michail N., 2016, Smart Learning Environments, V3, DOI 10.1186/s40561-016-0034-2
   Giannakos MN, 2015, INT REV RES OPEN DIS, V16, P260
   Gorissen P, 2012, INT J LEARN TECHNOL, V7, P23, DOI 10.1504/IJLT.2012.046864
   Kevan JM, 2016, TECHNOL KNOWL LEARN, V21, P143, DOI 10.1007/s10758-015-9260-x
   Kim Juho, 2014, P 1 ACM C LEARN SCAL, P31, DOI [DOI 10.1145/2556325.2566237, DOI 10.1145/2556325.2566239]
   Kleftodimos Alexandros, 2016, Smart Learning Environments, V3, DOI 10.1186/s40561-016-0032-4
   Kleftodimos A, 2014, I C COMP SYST APPLIC, P280, DOI 10.1109/AICCSA.2014.7073210
   Konstantinos Chorianopoulos, 2012, SOCIALMEDIA RETRIEVA, P3
   Kuzyakov Evgeny, 2017, ENHANCING HIGHRESOLU
   Kwiatek K, 2009, 2009 15TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA PROCEEDINGS (VSMM 2009), P197, DOI 10.1109/VSMM.2009.36
   Lo WC, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P211, DOI 10.1145/3083187.3083219
   Meixner B., 2016, ACM SIGMultimedia Records, V8, P10, DOI [https://doi.org/10.1145/2898367.2898371, DOI 10.1145/2898367.2898371]
   Meixner B, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3038925
   Meixner B, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P713, DOI 10.1145/2733373.2807413
   Meixner B, 2014, MULTIMED TOOLS APPL, V70, P1251, DOI 10.1007/s11042-012-1218-6
   Mirriahi N., 2017, Handbook of learning analytics, V1st, P251, DOI [10.18608/hla17.022, DOI 10.18608/HLA17.022]
   Morikawa H, 2017, JAPANESE J ERGONOMIC, V53, P758, DOI [10.5100/jje.53.S758, DOI 10.5100/JJE.53.S758]
   Nan Li, 2015, Design for Teaching and Learning in a Networked World. 10th European Conference on Technology-Enhanced Learning, EC-TEL 2015. Proceedings: LNCS 9307, P197, DOI 10.1007/978-3-319-24258-3_15
   Neng LAR, 2012, INT J AMBIENT COMPUT, V4, P40, DOI 10.4018/jaci.2012100103
   Neng Luisa. R., 2010, Proceedings of the 14th International Academic MindTrek Conference on Envisioning Future Media Environments-MindTrek '10, P119, DOI DOI 10.1145/1930488.1930512
   Oliver A, 2018, COMM COM INF SC, V813, P117, DOI 10.1007/978-3-319-90170-1_9
   Oliver Antoni, 2017, P 6 IB C APPL US INT, P162
   Paterno F, 2016, P INT WORK C ADV VIS, P88, DOI DOI 10.1145/2909132.2909272
   Pavel A, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P289, DOI 10.1145/3126594.3126636
   Preston M., 2005, Proceedings of world conference on educational multimedia, hypermedia and telecommunications, P4357
   Rabelo T, 2017, IEEE FRONT ED C FIE, P1, DOI [10.1109/FIE.2017.8190729, DOI 10.1109/FIE.2017.8190729]
   Rai Y, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P205, DOI 10.1145/3083187.3083218
   Risko EF, 2013, IEEE T LEARN TECHNOL, V6, P4, DOI 10.1109/TLT.2012.15
   Rovelo G, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P4077, DOI 10.1145/2556288.2557113
   Sauli F, 2018, TECHNOL PEDAGOG EDUC, V27, P115, DOI 10.1080/1475939X.2017.1407357
   Sawhney N., 1996, Seventh ACM Conference on Hypertext. Hypertext '96, P1, DOI 10.1145/234828.234829
   Schwan S, 2004, LEARN INSTR, V14, P293, DOI 10.1016/j.learninstruc.2004.06.005
   Scott J, 2014, S VIS LANG HUM CEN C, P45, DOI 10.1109/VLHCC.2014.6883020
   Seidel N, 2017, P DELFI GMW WORKSH
   Sottilare RA, 2017, PROCEEDINGS OF THE FOURTH (2017) ACM CONFERENCE ON LEARNING @ SCALE (L@S'17), P265, DOI 10.1145/3051457.3054001
   Wijnants M, 2016, LECT NOTES BUS INF P, V246, P47, DOI 10.1007/978-3-319-30996-5_3
   Zenonas Theodosiou, 2009, LECT NOTES COMPUT SC, P913
NR 56
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22771
EP 22796
DI 10.1007/s11042-020-09059-2
EA MAY 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000554789500005
DA 2024-07-18
ER

PT J
AU Qaddoura, R
   Al Manaseer, W
   Abushariah, MAM
   Alshraideh, MA
AF Qaddoura, Raneem
   Al Manaseer, Waref
   Abushariah, Mohammad A. M.
   Alshraideh, Mohammad Aref
TI Dental radiography segmentation using expectation-maximization
   clustering and grasshopper optimizer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Expectation-Maximization algorithm; Grasshopper
   optimization algorithm; Dental radiography; Anatomical segmentation and
   classification
ID ALGORITHM; LIKELIHOOD
AB Image segmentation is a popular technique that is used for extracting information from images, which has also gained a lot of interest lately due to its importance in different scientific fields such as the medical field. This paper proposes a novel image segmentation technique using Expectation-Maximization (EM) clustering algorithm and Grasshopper Optimizer Algorithm (GOA). The proposed technique and the concept of image segmentation are effectively applied on dental radiography datasets that are collected from 120 patients with an age between 6 to 60 years old. To validate the proposed technique, a comparison in terms of purity and entropy measures is conducted against K-means, X-means, EM, and Farthest First algorithms. Based on our experimental results, the proposed technique using EM and GOA achieved the best results compared to other algorithms for all three datasets in terms of entropy and purity. The best results were obtained using the second dataset, which achieved purity value of 0.7126 and entropy value of 0.3083. Further, the proposed technique also outperforms U-net and Random Forest algorithms for the selected datasets.
C1 [Qaddoura, Raneem] Philadelphia Univ, Informat Technol, Amman, Jordan.
   [Al Manaseer, Waref; Alshraideh, Mohammad Aref] Univ Jordan, King Abdullah II Sch Informat Technol, Dept Comp Sci, Amman, Jordan.
   [Abushariah, Mohammad A. M.] Univ Jordan, King Abdullah II Sch Informat Technol, Dept Comp Informat Syst, Amman, Jordan.
C3 Philadelphia University Jordan; University of Jordan; University of
   Jordan
RP Qaddoura, R (corresponding author), Philadelphia Univ, Informat Technol, Amman, Jordan.
EM rqaddoura@philadelphia.edu.jo; warefalmanaseer@gmail.com;
   m.abushariah@ju.edu.jo; mshridah@ju.edu.jo
RI Qaddoura, Raneem/V-4601-2019; Alshraideh, Mohammad A/C-8113-2015;
   Abushariah, Mohammad/C-2501-2015
OI Qaddoura, Raneem/0000-0003-4093-9349; Alshraideh, Mohammad
   A/0000-0002-2724-9290; Abushariah, Mohammad/0000-0002-1676-8765
CR Abdel-Khalek S, 2017, OPTIK, V131, P414, DOI 10.1016/j.ijleo.2016.11.039
   Aljarah I, 2018, COGN COMPUT, V10, P478, DOI 10.1007/s12559-017-9542-9
   Aljarah I, 2013, 2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P2642
   Amer YY, 2015, PROCEDIA COMPUT SCI, V65, P718, DOI 10.1016/j.procs.2015.09.016
   [Anonymous], 2013, LNCS
   [Anonymous], 2014, INT J ENG RES APPL
   [Anonymous], 2012, FACILITIES
   BORA DJ, 2015, ARXIV150601710
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   de Geus Daan, 2020, IEEE ROBOTICS AUTOMA, V1, P6
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dhal KG, 2020, ARCH COMPUT METHOD E, V27, P855, DOI 10.1007/s11831-019-09334-y
   Dhamangaonkar AC, 2013, MALAYS ORTHOP J, V7, P36, DOI 10.5704/MOJ.1303.014
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   DONGRI S, 2010, 2010 INT C BIOINF BI, P74
   FARMER ME, 2006, 2006 CEC 2006 IEEE C, P1300
   Forsyth D. A., 2002, Computer vision: a modern approach, DOI DOI 10.5555/580035
   Gao H, 2010, PATTERN RECOGN, V43, P2406, DOI 10.1016/j.patcog.2010.01.010
   Gopi Raju N., 2013, INT J ENG RES APPL, V3, P1572
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   *I AS, 2018, XRAYS
   ISHIOKA T, 2005, P INT C COMP INT, V2, P91
   Kaur Dilpreet, 2014, International Journal of Computer Science and Mobile Computing, V3, P809, DOI DOI 10.13140/RG.2.2.28324.07046
   Kirillov A, 2019, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR.2019.00963
   Kumar R., 2011, Int. J. Multimed. Image Process, V1, P72, DOI [10.20533/ijmip.2042.4647.2012.0009, DOI 10.20533/IJMIP.2042.4647.2012.0009]
   Lai YH, 2008, LECT NOTES COMPUT SC, V5259, P936, DOI 10.1007/978-3-540-88458-3_85
   LALAOUI L, 2013, IJACSA, V4, P211
   LAPORTE J, 2017, ORAL HLTH DENT CARE
   Li YY, 2017, APPL SOFT COMPUT, V56, P345, DOI 10.1016/j.asoc.2017.03.018
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lira PHM, 2014, IEEE LAT AM T, V12, P694, DOI 10.1109/TLA.2014.6868871
   Liu J, 2012, J VIS COMMUN IMAGE R, V23, P1234, DOI 10.1016/j.jvcir.2012.09.002
   Lukasik S, 2017, FED CONF COMPUT SCI, P71, DOI 10.15439/2017F340
   Mesejo P, 2016, APPL SOFT COMPUT, V44, P1, DOI 10.1016/j.asoc.2016.03.004
   Minaee S., 2020, ARXIV200105566
   Mirjalili SZ, 2018, APPL INTELL, V48, P805, DOI 10.1007/s10489-017-1019-8
   MOHSEN FM, 2011, INT J ADV COMPUTER S
   Mortaheb P, 2013, IRAN CONF MACH, P121, DOI 10.1109/IranianMVIP.2013.6779962
   NAIK D, 2014, INT J COMPUTER SCI I, V5, P3289
   Nomir O, 2008, IEEE T INF FOREN SEC, V3, P223, DOI 10.1109/TIFS.2008.919343
   Panda R, 2017, APPL SOFT COMPUT, V50, P94, DOI 10.1016/j.asoc.2016.11.011
   Parra L, 1998, IEEE T MED IMAGING, V17, P228, DOI 10.1109/42.700734
   PATANACHAI N, 2010, 2010 8 INT C ICT KNO, P103
   Qaddoura R, 2020, LECT NOTES COMPUT SC, V12104, P20, DOI 10.1007/978-3-030-43722-0_2
   Qaddoura R, 2020, INT J MACH LEARN CYB, V11, P675, DOI 10.1007/s13042-019-01027-z
   Rad AE, 2013, IETE TECH REV, V30, P210, DOI 10.4103/0256-4602.113498
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   SAHU M, 2016, INT J COMPUTER APPL, V140
   Sanderson M, 2010, NAT LANG ENG, V16, P100, DOI 10.1017/S1351324909005129
   Sandhya G, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/6783209
   Senthilkumaran N., 2016, COMPUT SCI ENG INT J, V6, P1, DOI [DOI 10.5121/CSEIJ.2016.6101, 10.5121/cseij.2016, DOI 10.5121/CSEIJ.2016]
   Shah S, 2006, 2006 BIOMETRICS SYMPOSIUM: SPECIAL SESSION ON RESEARCH AT THE BIOMETRIC CONSORTIUM CONFERENCE, P137
   Silva G, 2018, EXPERT SYST APPL, V107, P15, DOI 10.1016/j.eswa.2018.04.001
   Wang CW, 2016, MED IMAGE ANAL, V31, P63, DOI 10.1016/j.media.2016.02.004
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Zheng X, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0309-3
   ZUO W, 2006, COMP APPL SOFTW, V23, P97
NR 59
TC 7
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 22027
EP 22045
DI 10.1007/s11042-020-09014-1
EA MAY 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000533180600002
DA 2024-07-18
ER

PT J
AU Wang, H
   Du, YQ
   Han, J
AF Wang, Hui
   Du, Yingqiong
   Han, Jing
TI An integrated two-stage approach for image segmentation via active
   contours
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Image segmentation; Active contour model; Level set
   method
ID LEVEL SET EVOLUTION; DRIVEN; MODEL; ALGORITHMS; EFFICIENT; SNAKES
AB A novel integrated two-stage approach is proposed for image segmentation, where the edge, global and local region information of images are in turn incorporated to define the intensity fitting energy. In the first stage, the Chan-Vese model flexibly assimilates the edge indicator function in the beginning, and then the Laplace operator is introduced to regularize the level set function when minimizing the energy functional. As an edge-based and global region-based active contour, it can be inclined to rapidly produce a coarse segmentation result. In the second stage, we further segment the image by absorbing the local region fitting energy, where its initialization is acquired by the final active contour of the first stage. In addition, we present a generalized level set regularization term, which efficiently eliminates the periodically re-initialization procedure of traditional level set methods and maintains the corresponding signed distance property. Compared with the first stage, the local object details are accurately segmented in the second stage, which can acquire an accurate segmentation result. Qualitative and quantitative experimental results demonstrate the accuracy, robustness and efficiency of our approach with applications to some synthetical and real-world images.
C1 [Wang, Hui; Han, Jing] Anshun Univ, Sch Math & Phys, Anshun 561000, Guizhou, Peoples R China.
   [Du, Yingqiong] Anshun Univ, Sch Resources & Environm Engn, Anshun 561000, Guizhou, Peoples R China.
C3 Anshun University; Anshun University
RP Wang, H (corresponding author), Anshun Univ, Sch Math & Phys, Anshun 561000, Guizhou, Peoples R China.
EM wanghui561403@163.com
RI Wang, Hui/ABB-2327-2020
FU Union Program of Science Technology of Guizhou Province; Anshun
   Government; Anshun University [LH20157699]; Natural Science Research
   Foundation of Guizhou Education Department [KY2018034, KY2018070];
   Natural Science Foundation of China [11601010]
FX This research is supported by the Union Program of Science Technology of
   Guizhou Province, Anshun Government and Anshun University (LH20157699),
   the Natural Science Research Foundation of Guizhou Education Department
   (KY2018070), the Natural Science Foundation of China (11601010), and the
   Natural Science Research Foundation of Guizhou Education Department
   (KY2018034).
CR [Anonymous], P IEEE C COMP VIS PA
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416
   Darolti C, 2008, IEEE T IMAGE PROCESS, V17, P2275, DOI 10.1109/TIP.2008.2006443
   Faisal A, 2015, IEEE T MED IMAGING, V34, P2162, DOI 10.1109/TMI.2015.2425144
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Kim JM, 2005, IEEE T IMAGE PROCESS, V14, P1486, DOI 10.1109/TIP.2005.854442
   Kong S, 2018, PROC CVPR IEEE, P9018, DOI 10.1109/CVPR.2018.00940
   Lang FK, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101592
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Li B, 2007, IEEE T IMAGE PROCESS, V16, P2096, DOI 10.1109/TIP.2007.899601
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li DY, 2013, J VIS COMMUN IMAGE R, V24, P522, DOI 10.1016/j.jvcir.2013.03.007
   Li L, 2010, IEEE T IMAGE PROCESS, V19, P1, DOI 10.1109/TIP.2009.2032341
   Li WS, 2019, SIGNAL IMAGE VIDEO P, V13, P103, DOI 10.1007/s11760-018-1334-5
   Liu JW, 2020, MASS COMMUN SOC, V23, P537, DOI 10.1080/15205436.2020.1728776
   Min H, 2018, IEEE T IMAGE PROCESS, V27, P5016, DOI 10.1109/TIP.2018.2848471
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Niu SJ, 2017, PATTERN RECOGN, V61, P104, DOI 10.1016/j.patcog.2016.07.022
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Shen LQ, 2012, IEEE T IMAGE PROCESS, V21, P2582, DOI 10.1109/TIP.2011.2177849
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sussman M, 1999, SIAM J SCI COMPUT, V20, P1165, DOI 10.1137/S1064827596298245
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang H, 2016, NEUROCOMPUTING, V205, P130, DOI 10.1016/j.neucom.2016.03.050
   Wang H, 2014, INFORM SCIENCES, V263, P43, DOI 10.1016/j.ins.2013.10.033
   Wang L, 2009, COMPUT MED IMAG GRAP, V33, P520, DOI 10.1016/j.compmedimag.2009.04.010
   Wang L, 2009, SIGNAL PROCESS, V89, P2435, DOI 10.1016/j.sigpro.2009.03.014
   Xie XH, 2008, IEEE T PATTERN ANAL, V30, P632, DOI 10.1109/TPAMI.2007.70737
   Xie XH, 2010, IEEE T IMAGE PROCESS, V19, P154, DOI 10.1109/TIP.2009.2032891
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhang WH, 2020, IEEE T IMAGE PROCESS, V29, P57, DOI 10.1109/TIP.2019.2928134
   Zhao XL, 2014, SIAM J IMAGING SCI, V7, P456, DOI 10.1137/13092472X
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 37
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21177
EP 21195
DI 10.1007/s11042-020-08950-2
EA MAY 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000529768200002
DA 2024-07-18
ER

PT J
AU Avramelos, V
   De Praeter, J
   Van Wallendael, G
   Lambert, P
AF Avramelos, Vasileios
   De Praeter, Johan
   Van Wallendael, Glenn
   Lambert, Peter
TI Random access prediction structures for light field video coding with
   MV-HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Light field video coding; Multi-view video coding; MV-HEVC; Prediction
   structures; Random access; Virtual reality; Free navigation
ID MULTIVIEW VIDEO; IMAGE
AB Computational imaging and light field technology promise to deliver the required six-degrees-of-freedom for natural scenes in virtual reality. Already existing extensions of standardized video coding formats, such as multi-view coding and multi-view plus depth, are the most conventional light field video coding solutions at the moment. The latest multi-view coding format, which is a direct extension of the high efficiency video coding (HEVC) standard, is called multi-view HEVC (or MV-HEVC). MV-HEVC treats each light field view as a separate video sequence, and uses syntax elements similar to standard HEVC for exploiting redundancies between neighboring views. To achieve this, inter-view and temporal prediction schemes are deployed with the aim to find the most optimal trade-off between coding performance and reconstruction quality. The number of possible prediction structures is unlimited and many of them are proposed in the literature. Although some of them are efficient in terms of compression ratio, they complicate random access due to the dependencies on previously decoded pixels or frames. Random access is an important feature in video delivery, and a crucial requirement in multi-view video coding. In this work, we propose and compare different prediction structures for coding light field video using MV-HEVC with a focus on both compression efficiency and random accessibility. Experiments on three different short-baseline light field video sequences show the trade-off between bit-rate and distortion, as well as the average number of decoded views/frames, necessary for displaying any random frame at any time instance. The findings of this work indicate the most appropriate prediction structure depending on the available bandwidth and the required degree of random access.
C1 [Avramelos, Vasileios; De Praeter, Johan; Van Wallendael, Glenn; Lambert, Peter] Univ Ghent, Dept Elect & Informat Syst, IMEC, IDLab Technol Pk Zwijnaarde 122, B-9052 Ghent, Belgium.
C3 IMEC; Ghent University
RP Avramelos, V (corresponding author), Univ Ghent, Dept Elect & Informat Syst, IMEC, IDLab Technol Pk Zwijnaarde 122, B-9052 Ghent, Belgium.
EM vasileios.avramelos@ugent.be
RI Van Wallendael, Glenn/H-8315-2015; Avramelos, Vasileios/AAQ-9280-2021;
   Lambert, Peter/D-7776-2016
OI Van Wallendael, Glenn/0000-0001-9530-3466; Lambert,
   Peter/0000-0001-5313-4158; Avramelos, Vasileios/0000-0001-6601-0920
CR Ahmad W, 2018, PROC SPIE, V10679, DOI 10.1117/12.2315597
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2013, IEEE J SELECTED TOPI
   [Anonymous], MPEG 122 M SAN DIEG
   [Anonymous], 2015, JTC1SC29WG11 ISOIEC
   [Anonymous], 3DTV C TRUE VIS CAPT
   [Anonymous], MULTIVIEW HIGH EFFIC
   [Anonymous], NEW VISUAL CODING EX
   [Anonymous], J REAL TIME IMAGE PR
   [Anonymous], IEEE T IMAGE PROCESS
   Avramelos V, 2019, PROC SPIE, V11137, DOI 10.1117/12.2529137
   Avramelos V, 2018, PROC SPIE, V10752, DOI 10.1117/12.2320563
   Bjontegaard G., 2001, Document VCEG-M33
   de la Fuente YS, 2017, MULTIMED TOOLS APPL, V76, P5631, DOI 10.1007/s11042-016-4097-4
   Domanski M, 2017, INT CONF SYST SIGNAL, DOI 10.1109/IWSSIP.2017.7965623
   Dricot A, 2014, IEEE IMAGE PROC, P135, DOI 10.1109/ICIP.2014.7025026
   Gao P, 2014, IEEE T MULTIMEDIA, V16, P1797, DOI 10.1109/TMM.2014.2331013
   Hansen BC, 2004, J VISION, V4, P1044, DOI 10.1167/4.12.5
   Huszák A, 2017, MULTIMED TOOLS APPL, V76, P373, DOI 10.1007/s11042-015-3048-9
   Liu DY, 2018, MULTIMED TOOLS APPL, V77, P31929, DOI 10.1007/s11042-018-6255-3
   Liu DY, 2018, MULTIMED TOOLS APPL, V77, P1261, DOI 10.1007/s11042-016-4293-2
   Liu D, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574674
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Ozcinar C, 2016, MULTIMED TOOLS APPL, V75, P12431, DOI 10.1007/s11042-016-3475-2
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sze V., 2014, INTEGRATED CIRCUITS
   Verhack R, 2017, IEEE INT CON MULTI, P1183, DOI 10.1109/ICME.2017.8019442
   Wang Ting-Chun, 2017, ACM Trans. Graph., V36, P4, DOI DOI 10.1145/3072959.3073614
   Zilly F, 2014, J VIS COMMUN IMAGE R, V25, P632, DOI 10.1016/j.jvcir.2013.07.002
NR 29
TC 9
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 12847
EP 12867
DI 10.1007/s11042-019-08605-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000534818700005
OA Green Published
DA 2024-07-18
ER

PT J
AU Gao, H
   Gao, TG
AF Gao, Hang
   Gao, Tiegang
TI Detection of median filtering based on ARMA model and pixel-pair
   histogram feature of difference image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Median filtering; Image forensic; Autoregressive moving average model;
   Difference image
ID JPEG COMPRESSION; BLIND DETECTION; FORENSICS
AB Median filtering is a widely used method for removing noise and smoothing regions of an image, and the detection of median filtering has drawn much attention from researchers of image forensic. A new robust detection scheme of median filtering based on pixel-pair histogram (PPH) and coefficients of autoregressive moving average model (ARMA) of difference image is proposed in this paper. In the proposed scheme, the PPH and ARMA are extracted from the difference image in four directions; the generated PPH-ARMA feature of 396 dimensions can effectively be used to detect the median filtering. In order to verify the effectiveness of the proposed scheme, a series of experiments on single database and compound databases are conducted, and the experimental results show that, the proposed scheme outperforms many existing algorithms. Moreover, the suggested approach achieves best performance in single dataset and multiple compound datasets compared with state-of-the-art methods, especially for strong JPEG compression and low resolution images.
C1 [Gao, Hang] Nankai Univ, Coll Comp, Tianjin 300381, Peoples R China.
   [Gao, Tiegang] Nankai Univ, Coll Software, Tianjin 300381, Peoples R China.
C3 Nankai University; Nankai University
RP Gao, TG (corresponding author), Nankai Univ, Coll Software, Tianjin 300381, Peoples R China.
EM gaotiegang@nankai.edu.cn
RI Gao, Tiegang/AAT-9599-2021
CR [Anonymous], NAT RES CON SERV PHO
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2011, P 13 INF HID C PRAG
   [Anonymous], P 2010 INT C SIGNAL
   Bas P., 2007, Break our Watermarking System, V2nd
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Ding F, 2018, J VIS COMMUN IMAGE R, V50, P93, DOI 10.1016/j.jvcir.2017.11.009
   Ding F, 2015, IEEE SIGNAL PROC LET, V22, P327, DOI 10.1109/LSP.2014.2359033
   Gao H, 2018, LECT NOTES COMPUT SC, V11165, P396, DOI 10.1007/978-3-030-00767-6_37
   Gao H, 2019, SIGNAL PROCESS-IMAGE, V72, P126, DOI 10.1016/j.image.2018.12.014
   Gloe T., 2010, Proceedings of the ACM Symposium on Applied Computing, P1584, DOI DOI 10.1145/1774088.1774427
   He PS, 2017, NEUROCOMPUTING, V228, P84, DOI 10.1016/j.neucom.2016.09.084
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kirchner M, 2010, PROC SPIE, V7541, DOI 10.1117/12.839100
   Li B, 2015, IEEE T INF FOREN SEC, V10, P558, DOI 10.1109/TIFS.2015.2389148
   Liu AN, 2017, MULTIMED TOOLS APPL, V76, P22119, DOI 10.1007/s11042-017-4845-0
   Mahmood T, 2017, FORENSIC SCI INT, V279, P8, DOI 10.1016/j.forsciint.2017.07.037
   Nirenberg L., 1971, Lecture Notes in Mathematics, V192, P97
   Niu YK, 2017, SIGNAL PROCESS-IMAGE, V53, P65, DOI 10.1016/j.image.2017.01.008
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shabanifard M, 2013, IET IMAGE PROCESS, V7, P817, DOI 10.1049/iet-ipr.2012.0717
   Shen ZY, 2016, MULTIMED TOOLS APPL, V75, P2327, DOI 10.1007/s11042-014-2407-2
   Tang HS, 2018, J VIS COMMUN IMAGE R, V51, P162, DOI 10.1016/j.jvcir.2018.01.011
   Vaishali D, 2017, CURR MED IMAGING, V13, P355, DOI 10.2174/1573405613666170427153750
   Yang JQ, 2018, MULTIMED TOOLS APPL, V77, P7931, DOI 10.1007/s11042-017-4691-0
   Yang JQ, 2014, IEEE T INF FOREN SEC, V9, P1933, DOI 10.1109/TIFS.2014.2359368
   Yang L, 2016, INT J DIGIT CRIME FO, V8, P27, DOI 10.4018/IJDCF.2016040103
   Yao H, 2018, MULTIMED TOOLS APPL, V77, P18139, DOI 10.1007/s11042-017-5206-8
   Yao H, 2017, MULTIMED TOOLS APPL, V76, P12457, DOI 10.1007/s11042-016-3660-3
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Yun-Ni Lai, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P421, DOI 10.1007/978-3-319-22180-9_41
   Zhang YJ, 2014, IEEE SIGNAL PROC LET, V21, P275, DOI 10.1109/LSP.2013.2295858
   Zhao XD, 2015, IEEE T CIRC SYST VID, V25, P185, DOI 10.1109/TCSVT.2014.2347513
NR 37
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12551
EP 12567
DI 10.1007/s11042-019-08340-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400057
DA 2024-07-18
ER

PT J
AU Liu, J
   Wei, X
   Li, LL
AF Liu, Jin
   Wei, Xue
   Li, Langlang
TI MR image segmentation based on level set method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MR image segmentation; Intensity inhomogeneity; Probability statistics;
   Level set
ID CLASSIFICATION; OPTIMIZATION
AB In this paper, a level set model combining probabilistic statistics for image segmentation is proposed. Through adding a single-point pixel distribution into the energy function, the step size of each iteration is increased and the efficiency of the algorithm is improved. By adding the membership function of fuzzy clustering and bias field function, this method can effectively segment the image with intensity inhomogeneities. In addition, a new rule item is added to improve the edge segmentation effect of the image. Experiments on MR images of the brain show that the proposed model can provide ideal segmentation results compared with several level set segmentation models.
C1 [Liu, Jin; Wei, Xue; Li, Langlang] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
C3 Xidian University
RP Liu, J (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM Jinliu@xidian.edu.cn; wxyyxz@163.com; langzgy@163.com
CR Abdel-Maksoud E, 2015, EGYPT INFORM J, V16, P71, DOI 10.1016/j.eij.2015.01.003
   Anitha V, 2016, IET COMPUT VIS, V10, P9, DOI 10.1049/iet-cvi.2014.0193
   [Anonymous], 2019, OBJ TRACK VAR LIGHT
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], MULTIMED TOOLS APPL
   Balla-Arabé S, 2013, IEEE T CYBERNETICS, V43, P910, DOI 10.1109/TSMCB.2012.2218233
   Banerjee S, 2016, INFORM SCIENCES, V330, P88, DOI 10.1016/j.ins.2015.10.018
   Bansal S, 2018, INT CONF SPEECH DATA, P1, DOI 10.1109/ICSDA.2018.8693013
   Caldairou B, 2011, PATTERN RECOGN, V44, P1916, DOI 10.1016/j.patcog.2010.06.006
   Chabrier S, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/96306
   Despotovic I, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/450341
   Gong MG, 2015, INFORM SCIENCES, V293, P351, DOI 10.1016/j.ins.2014.09.023
   Kamaruddin N, 2017, SURF SCI, V363, P321
   Khadidos A, 2014, IEEE IMAGE PROC, P902, DOI 10.1109/ICIP.2014.7025181
   Li CM, 2014, MAGN RESON IMAGING, V32, P913, DOI 10.1016/j.mri.2014.03.010
   Li CM, 2009, LECT NOTES COMPUT SC, V5636, P288
   Li CM, 2005, PROC CVPR IEEE, P430
   Lu S, 2017, INT C IM SIGN PROC, P1381
   Mary NAB, 2018, WIRELESS PERS COMMUN, V98, P2427, DOI 10.1007/s11277-017-4981-x
   Mary NAB, 2017, J VIS COMMUN IMAGE R, V49, P225, DOI 10.1016/j.jvcir.2017.09.008
   Rajapakse JC, 1997, IEEE T MED IMAGING, V16, P176, DOI 10.1109/42.563663
   Rajapakse JC, 1998, IMAGE VISION COMPUT, V16, P165, DOI 10.1016/S0262-8856(97)00067-X
   Shen LQ, 2012, IEEE T IMAGE PROCESS, V21, P2582, DOI 10.1109/TIP.2011.2177849
   Visual attention feature (VAF), 2019, J PARALLEL DISTRIBUT
   Xie XH, 2010, IEEE T IMAGE PROCESS, V19, P154, DOI 10.1109/TIP.2009.2032891
   Yang X, 2015, IEEE T IMAGE PROCESS, V24, P9, DOI 10.1109/TIP.2014.2372615
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zhang KH, 2015, IEEE T CYBERNETICS, V45, P1426, DOI 10.1109/TCYB.2014.2352343
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhang MX, 2019, SOFT COMPUT, V23, P2033, DOI 10.1007/s00500-017-2916-9
NR 30
TC 3
Z9 3
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11487
EP 11502
DI 10.1007/s11042-019-08468-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400010
DA 2024-07-18
ER

PT J
AU Mehmood, A
   Khan, MA
   Sharif, M
   Khan, SA
   Shaheen, M
   Saba, T
   Riaz, N
   Ashraf, I
AF Mehmood, Asif
   Khan, Muhammad Attique
   Sharif, Muhammad
   Khan, Sajid Ali
   Shaheen, Muhammad
   Saba, Tanzila
   Riaz, Naveed
   Ashraf, Imran
TI Prosperous Human Gait Recognition: an end-to-end system based on
   pre-trained CNN features selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; Deep features; Features fusion; Features selection
ID CONVOLUTIONAL NEURAL-NETWORKS; CLASSIFICATION; FUSION; FRAMEWORK;
   MOTION; ROBUST
AB Human Gait Recognition (HGR) is a biometric approach, widely used for security purposes from the past few decades. In HGR, the change in an individual walk along with wearing clothes and carrying bag are major covariant controls which impact the performance of a system. Moreover, recognition under various view angles is another key challenge in HGR. In this work, a novel fully automated method is proposed for HGR under various view angles using deep learning. Four primary steps are involved such as: preprocessing of original video frames, exploiting pre-trained Densenet-201 CNN model for features extraction, reduction of additional features from extracted vector based on a hybrid selection method, and finally recognition using supervised learning methods. The extraction of CNN features is a key step in which our target is to extract the most active features. To achieve this goal, we fuse the features of both second last and third last layers in a parallel process. At a later stage, best features are selected by the Firefly algorithm and Skewness based approach. These selected features are serially combined and fed to One against All Multi Support Vector Machine (OAMSVM) for final recognition. Three different angles 18(0), 36(0) and 54(0) of the CASIA B dataset are selected for the evaluation process and accuracy of 94.3%, 93.8% and 94.7% is achieved respectively. Results show significant improvement in accuracy and recall rate as compared to the existing state-of-the-art techniques.
C1 [Mehmood, Asif; Sharif, Muhammad] COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Islamabad, Pakistan.
   [Khan, Muhammad Attique; Ashraf, Imran] HITEC Univ, Dept Comp Sci & Engn, Museum Rd Taxila, Rawalpindi, Pakistan.
   [Khan, Sajid Ali; Shaheen, Muhammad] Fdn Univ Islamabad, Dept Software Engn, Islamabad, Pakistan.
   [Saba, Tanzila] Prince Sultan Univ, Dept Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Riaz, Naveed] Natl Univ Sci & Technol, SEECS, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI); Quaid I Azam University; Prince
   Sultan University; National University of Sciences & Technology -
   Pakistan
RP Khan, MA (corresponding author), HITEC Univ, Dept Comp Sci & Engn, Museum Rd Taxila, Rawalpindi, Pakistan.
EM attique.khan@hitecuni.edu.pk; sajidalibn@gmail.com
RI ashraf, imran/HJA-5212-2022; Saba, Tanzila/D-4593-2018; Khan, Dr.
   Muhammad Attique/AAX-2644-2021; Sharif, Muhammad/ACD-2598-2022; khan,
   sajid/HGE-2406-2022; Shaheen, Prof. Dr. Muhammad/AGH-3143-2022; Sharif,
   Muhammad/AAB-8376-2022
OI ashraf, imran/0000-0003-4480-2489; Saba, Tanzila/0000-0003-3138-3801;
   Khan, Dr. Muhammad Attique/0000-0002-6347-4890; Sharif,
   Muhammad/0000-0002-7258-8400; Shaheen, Prof. Dr.
   Muhammad/0000-0003-3647-1261; 
CR [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2010, ARXIV10031409
   [Anonymous], 2019, ARXIV190609358
   [Anonymous], 2017 INT C ROB AUT S
   [Anonymous], BIOMIMETICS ITS APPL
   [Anonymous], INT J NEURAL SYST
   [Anonymous], PEERJ PREPRINTS
   [Anonymous], 2019, IET Image Process
   [Anonymous], 2019, 2019 2 INT C COMP AP
   [Anonymous], IEEE ACM T COMPUTATI
   [Anonymous], MULTILEVEL PARADIGM
   [Anonymous], 2019, P 2019 INT JOINT C N
   Arora P, 2015, PATTERN RECOGN LETT, V68, P336, DOI 10.1016/j.patrec.2015.05.016
   Arshad H, 2019, INT J MACH LEARN CYB, V10, P3601, DOI 10.1007/s13042-019-00947-0
   Batool FE, 2024, MULTIMED TOOLS APPL, V83, P14959, DOI 10.1007/s11042-020-08851-4
   Ben XY, 2019, PATTERN RECOGN, V90, P87, DOI 10.1016/j.patcog.2019.01.017
   Das Choudhury S, 2015, PATTERN RECOGN, V48, P798, DOI 10.1016/j.patcog.2014.09.022
   El-Rahiem Basma Abd., 2019, INT C ADV MACHINE LE, P23
   Goffredo M, 2008, 2008 IEEE 2 INT C BI, P1
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huang CC, 2016, J CHIN INST ENG, V39, P997, DOI 10.1080/02533839.2016.1230028
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hussain N, 2024, MULTIMED TOOLS APPL, V83, P14935, DOI 10.1007/s11042-020-08852-3
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P77, DOI 10.1016/j.patrec.2019.11.014
   Khan MA, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105986
   Khan MA, 2018, IET IMAGE PROCESS, V12, P200, DOI 10.1049/iet-ipr.2017.0368
   Khan MH, 2019, SIGNAL IMAGE VIDEO P, V13, P369, DOI 10.1007/s11760-018-1365-y
   Kovac J, 2019, MULTIMED TOOLS APPL, V78, P5621, DOI 10.1007/s11042-017-5469-0
   Kumar V., 2014, SMART COMPUTING REV, V4, P211, DOI [10.6029/smartcr.2014.03.007, DOI 10.6029/SMARTCR.2014.03.007, DOI 10.1145/2740070.2626320]
   Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552
   Kusakunniran W, 2012, IEEE T CIRC SYST VID, V22, P966, DOI 10.1109/TCSVT.2012.2186744
   Li C, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7030210
   Li X, 2019, IEEE T INF FOREN SEC, V14, P3102, DOI 10.1109/TIFS.2019.2912577
   Lishani AO, 2019, MULTIMED TOOLS APPL, V78, P5715, DOI 10.1007/s11042-018-5752-8
   Liu GQ, 2019, FUTURE GENER COMP SY, V94, P11, DOI 10.1016/j.future.2018.09.012
   Liu Y, 2005, IEEE IJCNN, P849
   Lynnerup N, 2005, J FORENSIC SCI, V50, P112
   Castro FM, 2017, LECT NOTES COMPUT SC, V10306, P257, DOI 10.1007/978-3-319-59147-6_23
   Negash K, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC), P73, DOI 10.1109/ICCMC.2017.8282572
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Rehman A, 2020, MICROSC RES TECHNIQ, V83, P410, DOI 10.1002/jemt.23429
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   Seo S, 2020, MULTIMED TOOLS APPL
   Sharif M, 2020, J ORGAN END USER COM, V32, P67, DOI 10.4018/JOEUC.2020040104
   Sharif MI, 2020, PATTERN RECOGN LETT, V129, P181, DOI 10.1016/j.patrec.2019.11.019
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shirke S, 2014, INT CONF COMM SYST, P891, DOI 10.1109/CSNT.2014.252
   Song CF, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106988
   Sugandhi K, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P355, DOI [10.1109/aicai.2019.8701366, 10.1109/AICAI.2019.8701366]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tafazzoli F, 2010, ENG APPL ARTIF INTEL, V23, P1237, DOI 10.1016/j.engappai.2010.07.004
   Tian YH, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214389
   Tong SB, 2019, PATTERN RECOGN LETT, V125, P212, DOI 10.1016/j.patrec.2019.04.010
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang FZ, 2019, SENSOR MATER, V31, P1335, DOI 10.18494/SAM.2019.2288
   Wang M, 2019, PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2019), P1560, DOI [10.1109/itnec.2019.8729511, 10.1109/ITNEC.2019.8729511]
   Wang N, 2014, MULTIMED TOOLS APPL, V72, P2339, DOI 10.1007/s11042-013-1551-4
   Yao L., 2019, Pattern Recogn Lett
   Zheng S, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6115889
NR 62
TC 50
Z9 50
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14979
EP 14999
DI 10.1007/s11042-020-08928-0
EA APR 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000529468100003
DA 2024-07-18
ER

PT J
AU Trinh, T
   Wu, DM
   Wang, RL
   Huang, JZ
AF Trinh, Thanh
   Wu, Dingming
   Wang, Ruili
   Huang, Joshua Zhexue
TI An effective content-based event recommendation model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EBSNs; Social networks; Topic model; Recommendation
AB Event-based social networks (EBSNs) facilitate people to interact with each other by sharing similar interests in online groups or taking part in offline events together. Event recommendation in EBSNs has been studied by many researchers. However, the problem of recommending the event to the top N active-friends of the key user has rarely been studied in EBSNs. In this paper, we propose a new method to solve this problem. In this method, we first construct an association matrix from the content of events and user features. Then, we define a new content-based event recommendation model, which combines the matrix, spatio-temporal relations and user interests to recommend an event to the active-friends of a key user. A series of experiments were conducted on real datasets collected from Meetup, and the comparison results have demonstrated the effectiveness of the new model.
C1 [Trinh, Thanh; Wu, Dingming; Huang, Joshua Zhexue] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
   [Wang, Ruili] Massey Univ, Sch Nat & Computat Sci, Auckland, New Zealand.
C3 Shenzhen University; Massey University
RP Wu, DM (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
EM tthanh@szu.edu.cn; dingming@szu.edu.cn; Ruili.wang@massey.ac.nz;
   zx.huang@szu.edu.cn
OI Trinh, Thanh/0000-0002-6973-9749
CR Athira U, 2018, IEEE ACCESS, V6, P4470, DOI 10.1109/ACCESS.2017.2789200
   Bagci H, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P531, DOI 10.1145/2872518.2890466
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cao JX, 2018, INT J COMPUT INT SYS, V11, P618, DOI 10.2991/ijcis.11.1.48
   Chen CC, 2016, INFORM PROCESS LETT, V116, P227, DOI 10.1016/j.ipl.2015.11.013
   Chorley MJ, 2015, COMPUT HUM BEHAV, V46, P45, DOI 10.1016/j.chb.2014.12.038
   Chu CH, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING (IMIS 2013), P365, DOI 10.1109/IMIS.2013.68
   Darling W., 2011, P 49 ANN M, P1
   Hoang DT, 2017, LECT NOTES ARTIF INT, V10448, P182, DOI 10.1007/978-3-319-67074-4_18
   Dong C, 2016, LECT NOTES COMPUTER, V9708, P250, DOI [10.1007/978-3-319-39931-7_24, DOI 10.1007/978-3-319-39931-7_24.HTTP://LINK.SPRINGER.C0M/10.1007/978-3-319-39931-7]
   Du R., 2014, Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing - UbiComp '14 Adjunct, P425
   Eirinaki M, 2018, FUTURE GENER COMP SY, V78, P413, DOI 10.1016/j.future.2017.09.015
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Hannon John, 2010, ACM RecSys'10', P199, DOI [10.1145/1864708.1864746, DOI 10.1145/1864708.1864746]
   Hao Ding, 2016, Social Informatics. 8th International Conference, SocInfo 2016. Proceedings: LNCS 10046, P361, DOI 10.1007/978-3-319-47880-7_22
   Horowitz D, 2018, PATTERN RECOGN LETT, V105, P121, DOI 10.1016/j.patrec.2017.07.003
   Jhamb Y, 2017, INFORM PROCESS MANAG, V53, P559, DOI 10.1016/j.ipm.2017.01.001
   Li SC, 2016, LECT NOTES COMPUT SC, V9645, P27, DOI 10.1007/978-3-319-32055-7_3
   Li X, 2017, NEUROCOMPUTING, V230, P197, DOI 10.1016/j.neucom.2016.12.024
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Liu SH, 2018, IEEE ACCESS, V6, P3020, DOI 10.1109/ACCESS.2017.2786679
   Liu Xingjie., 2012, Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '12, P1032
   Lu D., 2016, P 2016 C N AM CHAPTE, P72
   Macedo A.Q., 2015, P 9 ACM C REC SYST, P123, DOI 10.1145/2792838.2800187
   Minkov E., 2010, P 19 ACM INT C INFOR, P819, DOI DOI 10.1145/1871437.1871542.HTTP://P0RTAL.ACM.0RG/CITATI0N.CFM?D0ID=1871437.1871542
   Ogundele TJ, 2017, 2017 14TH INTERNATIONAL SYMPOSIUM ON PERVASIVE SYSTEMS, ALGORITHMS AND NETWORKS & 2017 11TH INTERNATIONAL CONFERENCE ON FRONTIER OF COMPUTER SCIENCE AND TECHNOLOGY & 2017 THIRD INTERNATIONAL SYMPOSIUM OF CREATIVE COMPUTING (ISPAN-FCST-ISCC), P38, DOI 10.1109/ISPAN-FCST-ISCC.2017.68
   Ogundele TJ, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP), P132
   Ogundele TJ, 2018, IEEE ACCESS, V6, P27579, DOI 10.1109/ACCESS.2018.2832543
   Qiao Z, 2014, AAAI CONF ARTIF INTE, P145
   Qiao Z, 2014, AAAI CONF ARTIF INTE, P3130
   Rui Li, 2012, Proceedings of the 2012 IEEE 7th International Power Electronics and Motion Control Conference (ECCE 2012), P1273, DOI 10.1109/IPEMC.2012.6259029
   Trinh T, 2019, IEEE RIVF INT CONF, P106, DOI 10.1109/rivf.2019.8713716
   Tu WT, 2015, LECT NOTES ARTIF INT, V9077, P591, DOI 10.1007/978-3-319-18038-0_46
   Pham TAN, 2015, PROC INT CONF DATA, P567, DOI 10.1109/ICDE.2015.7113315
   Xu CH, 2018, INFORM PROCESS MANAG, V54, P463, DOI 10.1016/j.ipm.2018.02.005
   Xu MH, 2019, IEEE ACCESS, V7, P17493, DOI 10.1109/ACCESS.2019.2895824
   Zhang S, 2018, KNOWL-BASED SYST, V143, P19, DOI 10.1016/j.knosys.2017.12.002
   Zhang W, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1455, DOI 10.1145/2783258.2783336
   Zhang W, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P910
   Zhang YU, 2013, ICEIS: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS - VOL 2, P371, DOI 10.5220/0004443903710379
NR 40
TC 9
Z9 12
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16599
EP 16618
DI 10.1007/s11042-020-08884-9
EA APR 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000527911600001
DA 2024-07-18
ER

PT J
AU Hu, CR
   Cheng, K
   Xie, YX
   Li, T
AF Hu, Chuanrui
   Cheng, Kai
   Xie, Yixiang
   Li, Teng
TI Arbitrary perspective crowd counting via local to global algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd density map; Convolutional neural network; Perspective distortion
ID SCALE
AB Crowd counting is getting more and more attention. More and more collective activities, such as the Olympics Games and the World Expo, are also important to control the crowd number. In this paper, we address the problem of crowd counting in the crowded scene. Our model accurately estimated the count of people in the crowded scene. Firstly, we proposed a novel and simple convolutional neural network, called Global Counting CNN (GCCNN). The GCCNN can learn a mapping, transforms the appearance of image patches to estimated density maps. Secondly, the Local to Global counting CNN (LGCCNN), calculating the density map from local to global. Stiching the local patches constrains the final density map of the larger area, which makes up for the difference values in the perspective map. In general, it makes the final density map more accurate. The dataset we used is a set of public dataset, which are WorldExpo'10 dataset, Shanghaitech dataset, the UCF_CC_50 dataset and the UCSD dataset. The experiments have proved our method achieves the state-of-the-art result over other algorithms.
C1 [Hu, Chuanrui; Cheng, Kai; Xie, Yixiang; Li, Teng] Anhui Univ, Key Lab Intelligent Comp & Signal Proc, Minist Educ, Sch Elect Engn & Automat, Hefei 230601, Peoples R China.
C3 Anhui University
RP Li, T (corresponding author), Anhui Univ, Key Lab Intelligent Comp & Signal Proc, Minist Educ, Sch Elect Engn & Automat, Hefei 230601, Peoples R China.
EM liteng@ahu.edu.cn
RI xie, Yixiang/GPT-4111-2022
FU National Key R&D Program of China [2018YFB1305804]; Anhui Provincial
   Natural Science Foundation of China [1908085J25]
FX This work is supported by the National Key R&D Program of China (No.
   2018YFB1305804), and the Anhui Provincial Natural Science Foundation of
   China (No. 1908085J25).
CR [Anonymous], 2017, SWITCHING CONVOLUTIO
   [Anonymous], 2015, IEEE C COMP VIS PATT
   [Anonymous], 2009, IEEE C COMP VIS PATT
   [Anonymous], 2011, INT C COMP VIS
   [Anonymous], 2016, COMPUTER VISION PATT
   Chan AB, 2012, IEEE T IMAGE PROCESS, V21, P2160, DOI 10.1109/TIP.2011.2172800
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   He K., 2015, ARXIV150201852
   Hu YC, 2016, J VIS COMMUN IMAGE R, V38, P530, DOI 10.1016/j.jvcir.2016.03.021
   Lempitsky VS, 2010, INT C NEUR INF PROC
   Lin SF, 2001, IEEE T SYST MAN CY A, V31, P645, DOI 10.1109/3468.983420
   Liu RJ, 2016, MULTIMED TOOLS APPL, V75, P15619, DOI 10.1007/s11042-015-2626-1
   Liu T, 2014, IEEE INT C INF SCI T
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Loy CC, 2014, IEEE INT C COMP VIS
   Min L, 2009, INT C PATT REC
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Wu B, 2005, IEEE I CONF COMP VIS, P90
NR 22
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15059
EP 15071
DI 10.1007/s11042-020-08888-5
EA APR 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000527485500001
DA 2024-07-18
ER

PT J
AU Huang, YY
   Wang, DY
   Sun, Y
   Hang, B
AF Huang, Yuanyuan
   Wang, Dayong
   Sun, Yu
   Hang, Bo
TI A fast intra coding algorithm for HEVC by jointly utilizing naive
   Bayesian and SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth prediction; Correlation; Naive Bayesian; Support vector machine
ID CU SIZE DECISION; MODE DECISION; COMPLEXITY
AB The current video coding standard HEVC has very high coding efficiency. However, its coding complexity is also very high, which leads to a negative impact on its wide applications. Therefore, how to improve the coding speed of HEVC has been a research focus recently. In this research, by applying machine learning methodology into video compression, we propose a novel fast intra coding algorithm for HEVC so as to improve the intra encoding speed. We first adopt Naive Bayesian to calculate each depth's probability based on correlations. Then, to speed up coding, we combine textural features and possibilities with support vector machine (SVM) to further predict depth early skip and early termination. Experiments demonstrate that the proposed algorithm can significantly improve the coding speed with negligible loss of coding efficiency.
C1 [Huang, Yuanyuan] Chengdu Univ Informat Technol, Chengdu, Peoples R China.
   [Huang, Yuanyuan; Wang, Dayong] Univ Elect Sci & Technol China, Chengdu, Peoples R China.
   [Wang, Dayong] Chongqing Univ Posts & Telecommun, Chongqing, Peoples R China.
   [Sun, Yu] Univ Cent Arkansas, Dept Comp Sci, Conway, AR USA.
   [Hang, Bo] Hubei Univ Arts & Sci, Comp Sch, Xiangyang, Hubei, Peoples R China.
C3 Chengdu University of Information Technology; University of Electronic
   Science & Technology of China; Chongqing University of Posts &
   Telecommunications; University of Central Arkansas; Hubei University of
   Arts & Science
RP Hang, B (corresponding author), Hubei Univ Arts & Sci, Comp Sch, Xiangyang, Hubei, Peoples R China.
EM bohang@163.com
FU Science and Technology Development Program of Central Guide to Local
   Government of China [2019ZYYD043]; International Science & Technology
   Cooperation Program of Hubei Province [2019AHB059]; Xiangyang Science
   and Technology Research and Development Project; Sichuan Science and
   Technology Program [2018RZ0072, 2019YFS0068, 20ZDYF0660]; Foundation of
   Chengdu University of Information Technology [J201707]; Open Project of
   Hubei University of Arts and Science [XK2018013]
FX This work was supported in part by Science and Technology Development
   Program of Central Guide to Local Government of China under Grant
   2019ZYYD043, in part by International Science & Technology Cooperation
   Program of Hubei Province under Grant 2019AHB059, in part by Xiangyang
   Science and Technology Research and Development Project, in part by the
   Sichuan Science and Technology Program under Grants 2018RZ0072,
   2019YFS0068 and 20ZDYF0660, in part by the Foundation of Chengdu
   University of Information Technology under Grant J201707, and in part by
   Open Project of Hubei University of Arts and Science under Grant
   XK2018013.
CR Bossen Bossen F. F., L1100 JCT VC, P1
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Corrêa G, 2012, IEEE T CIRC SYST VID, V22, P1899, DOI 10.1109/TCSVT.2012.2223411
   Jamali M, 2019, IEEE T BROADCAST, V65, P109, DOI 10.1109/TBC.2018.2847464
   Kim J, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P261, DOI 10.1109/ICCE.2012.6161857
   Kim TS, 2011, PSYCHIAT INVEST, V8, P1, DOI 10.4306/pi.2011.8.1.1
   Liu XG, 2019, IEEE T CIRC SYST VID, V29, P144, DOI 10.1109/TCSVT.2017.2777903
   Shen LQ, 2014, IEEE T CIRC SYST VID, V24, P1709, DOI 10.1109/TCSVT.2014.2313892
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shen XL, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P453, DOI 10.1109/PCS.2012.6213252
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Ugur K, 2010, IEEE T CIRC SYST VID, V20, P1688, DOI 10.1109/TCSVT.2010.2092613
   Wang DY, 2020, IEEE T MULTIMEDIA, V22, P833, DOI 10.1109/TMM.2019.2937240
   Wang DY, 2019, IEEE T IMAGE PROCESS, V28, P2063, DOI 10.1109/TIP.2017.2740161
   Wiegand T, 2010, IEEE T CIRC SYST VID, V20, P1661, DOI 10.1109/TCSVT.2010.2095692
   Xu M, 2018, IEEE T IMAGE PROCESS, V27, P5044, DOI 10.1109/TIP.2018.2847035
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhang Y, 2018, IEEE T CIRC SYST VID, V28, P3208, DOI 10.1109/TCSVT.2017.2747659
   Zhu Hong, 2005, Acta Electronica Sinica, V33, P1576
   Zhu LW, 2017, IEEE T BROADCAST, V63, P547, DOI 10.1109/TBC.2017.2711142
NR 22
TC 8
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33957
EP 33971
DI 10.1007/s11042-020-08882-x
EA APR 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000558430400005
DA 2024-07-18
ER

PT J
AU Kumar, S
   Singh, BK
   Yadav, M
AF Kumar, Sanjay
   Singh, Binod Kumar
   Yadav, Mohit
TI A Recent Survey on Multimedia and Database Watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Frequency Domain; Spatial Domain; Robustness; Capacity; PSNR
ID AUDIO WATERMARKING; COPYRIGHT PROTECTION; DIGITAL WATERMARKING;
   DE-SYNCHRONIZATION; WAVELET TRANSFORM; ROBUST; SCHEME; BLIND; DOMAIN;
   SECURE
AB In today's digital era, it is very easy to copy, manipulate and distribute multimedia data over an open channel. Copyright protection, content authentication, identity theft, and ownership identification have become challenging issues for content owners/distributors. Off late data hiding methods have gained prominence in areas such as medical/healthcare, e-voting systems, military, communication, remote education, media file archiving, insurance companies, etc. Digital watermarking is one of the burning research areas to address these issues. In this survey, we present various aspects of watermarking. In addition, various classification of watermarking is presented. Here various state-of-the-art of multimedia and database watermarking is discussed. With this survey, researchers will be able to implement efficient watermarking techniques for the security of multimedia and database.
C1 [Kumar, Sanjay; Singh, Binod Kumar; Yadav, Mohit] Natl Inst Technol, Jamshedpur, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Kumar, S (corresponding author), Natl Inst Technol, Jamshedpur, Bihar, India.
EM 2017rscs001@nitjsr.ac.in; bksingh.cse@nitjsr.ac.in;
   mohityadav12041995@gmail.com
RI Kumar, Dr. Sanjay/V-3889-2019; Singh, Binod/AAB-8663-2019
OI Kumar, Dr. Sanjay/0000-0002-4564-1085; Singh, Binod/0000-0002-2697-8918
FU Ministry of Human Resource Development, India; National Institute of
   Technology, Jamshedpur
FX The authors would like to thank reviewers for their helpful comments. We
   would also like to thanksthe Ministry of Human Resource Development,
   India and the National Institute of Technology, Jamshedpur for financial
   assistance.
CR Agarwal H, 2015, MULTIMED TOOLS APPL, V74, P6897, DOI 10.1007/s11042-014-1934-1
   Agrawal R, 2003, VLDB J, V12, P157, DOI [10.1007/s000778-003-0097-x, 10.1007/s00778-003-0097-x]
   Akhtar Z, 2018, IET IMAGE PROCESS, V12, P760, DOI 10.1049/iet-ipr.2017.0992
   Akhtar Z, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P652, DOI 10.1109/ICACCI.2016.7732120
   Ali Z, 2018, FUTURE GENER COMP SY, V82, P290, DOI 10.1016/j.future.2017.12.007
   Alotaibi RA, 2018, J KING SAUD UNIV-COM, V30, P236, DOI 10.1016/j.jksuci.2016.12.007
   Alromih A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124346
   [Anonymous], 2010, J ARID ENV, DOI DOI 10.1109/CCNC.2010
   Asikuzzaman Md, 2014, IEEE Transactions on Information Forensics and Security, V9, P1502, DOI 10.1109/TIFS.2014.2338274
   Cedillo-Hernandez A, 2018, J VIS COMMUN IMAGE R, V52, P106, DOI 10.1016/j.jvcir.2018.02.007
   Chen JP, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION PROCESSING, DATA MINING, AND WIRELESS COMMUNICATIONS (DIPDMWC), P117, DOI 10.1109/DIPDMWC.2016.7529374
   Cox IJ., 2007, DIGITAL WATERMARKING
   Dhar PK, 2015, J INF SECUR APPL, V20, P74, DOI 10.1016/j.jisa.2014.10.007
   Doncel VR, 2007, IEEE T VIS COMPUT GR, V13, P851, DOI 10.1109/TVCG.2007.1050
   Fallahpour M, 2015, IEEE-ACM T AUDIO SPE, V23, P1273, DOI 10.1109/TASLP.2015.2430818
   Farri E, 2018, NONLINEAR DYNAM, V93, P1875, DOI 10.1007/s11071-018-4295-x
   Fei Guo, 2006, Applied Computing 2006. 21st Annual ACM Symposium on Applied Computing, P487
   Gangadhar Y, 2018, BIOMED SIGNAL PROCES, V43, P31, DOI 10.1016/j.bspc.2018.02.007
   Gross-Amblard D, 2011, ACM T DATABASE SYST, V36, DOI 10.1145/1929934.1929937
   Gupta G., 2008, P 1 INT C FOR APPL T, P24
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   HALVANI O, 2013, P 1 ACM WORKSH INF H, P00193
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P2469, DOI 10.1007/s11042-013-1561-2
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Hossain MS, 2018, FUTURE GENER COMP SY, V83, P596, DOI 10.1016/j.future.2017.03.029
   Hu HT, 2018, SIGNAL PROCESS, V147, P190, DOI 10.1016/j.sigpro.2018.02.001
   Hua G, 2019, IEEE T CIRC SYST VID, V29, P625, DOI 10.1109/TCSVT.2018.2809585
   Hua G, 2015, IEEE-ACM T AUDIO SPE, V23, P227, DOI 10.1109/TASLP.2014.2387385
   Hwang MJ, 2018, IEEE T MULTIMEDIA, V20, P45, DOI 10.1109/TMM.2017.2721642
   Jain R., 2018, Advances in Computer and Computational Sciences, V2, P433
   Khan A, 2016, J NETW COMPUT APPL, V75, P317, DOI 10.1016/j.jnca.2016.08.026
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Khanduja V, 2017, J INF SECUR APPL, V37, P38, DOI 10.1016/j.jisa.2017.10.001
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Kumar S, 2018, AIP CONF PROC, V1953, DOI [10.1109/CSITSS.2018.8768733, 10.1063/1.5032491]
   Kumar S, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1802, DOI 10.1109/RTEICT.2016.7808145
   Kumar S, 2016, 2016 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE & COMMUNICATION TECHNOLOGY (CICT), P6, DOI 10.1109/CICT.2016.12
   Kumar S, 2017, IET BIOMETRICS, V6, P139, DOI 10.1049/iet-bmt.2016.0017
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Laouamer L, 2018, IEEE ACCESS, V6, P26144, DOI 10.1109/ACCESS.2018.2831599
   Lei BY, 2015, SIGNAL PROCESS, V113, P80, DOI 10.1016/j.sigpro.2014.11.007
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Lin ZX, 2017, SIGNAL PROCESS-IMAGE, V57, P134, DOI 10.1016/j.image.2017.05.012
   Liu XW, 2014, 2014 NINTH INTERNATIONAL CONFERENCE ON BROADBAND AND WIRELESS COMPUTING, COMMUNICATION AND APPLICATIONS (BWCCA), P84, DOI 10.1109/BWCCA.2014.49
   Liu XY, 2017, SIGNAL PROCESS-IMAGE, V54, P140, DOI 10.1016/j.image.2017.03.002
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Liu ZH, 2019, IEEE T INF FOREN SEC, V14, P1171, DOI 10.1109/TIFS.2018.2871748
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Loganathan A, 2016, EXPERT SYST APPL, V63, P412, DOI 10.1016/j.eswa.2016.05.019
   Ma B, 2014, MULTIMED TOOLS APPL, V72, P637, DOI 10.1007/s11042-013-1372-5
   Madine F, 2018, SIGNAL PROCESS-IMAGE, V68, P229, DOI 10.1016/j.image.2018.06.015
   Manikandan VM, 2018, COMPUT ELECTR ENG, V72, P614, DOI 10.1016/j.compeleceng.2018.03.007
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   Mir N, 2014, COMPUT HUM BEHAV, V30, P648, DOI 10.1016/j.chb.2013.07.040
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Najih A, 2017, J KING SAUD UNIV-COM, V29, P288, DOI 10.1016/j.jksuci.2016.02.005
   Nezhadarya E, 2013, DIGIT SIGNAL PROCESS, V23, P1483, DOI 10.1016/j.dsp.2013.04.009
   Nikolaidis N., 2002, Proceedings 2002 IEEE International Conference on Multimedia and Expo (Cat. No.02TH8604), P493, DOI 10.1109/ICME.2002.1035654
   NOUIOUA I, 2018, SECUR COMMUN NETW, V2018, P00001, DOI DOI 10.1155/2018/6712065
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Peng F, 2019, MULTIMED TOOLS APPL, V78, P26885, DOI 10.1007/s11042-017-4362-1
   Gort MLP, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P111, DOI 10.1145/3082031.3083241
   Pournaghshband Vahab, 2008, P 46 ANN SE REG 20, P127, DOI [10.1145/1593105.1593138, DOI 10.1145/1593105.1593138]
   Preda RO, 2010, MEASUREMENT, V43, P1720, DOI 10.1016/j.measurement.2010.07.009
   Qin C, 2016, INFORM SCIENCES, V373, P233, DOI 10.1016/j.ins.2016.09.001
   Rai A, 2018, J INTELL SYST, V27, P105, DOI 10.1515/jisys-2017-0068
   Rasti P, 2016, J VIS COMMUN IMAGE R, V38, P838, DOI 10.1016/j.jvcir.2016.05.001
   Renza D, 2018, EXPERT SYST APPL, V91, P211, DOI 10.1016/j.eswa.2017.09.003
   Rizzo S. G., 2017, P 2017 IEEE ACM INT, P208
   Rosiyadi D., 2012, Int J Comput Theory and Eng (IJCTE), V4, P329
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Roy R, 2018, VIS INFORM, V2, P125, DOI 10.1016/j.visinf.2018.03.001
   Rubio-Hernan J, 2018, T EMERG TELECOMMUN T, V29, DOI 10.1002/ett.3209
   Rubio-Hernan J, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0060-9
   Rui X, 2013, PROCEDIA COMPUT SCI, V17, P844, DOI 10.1016/j.procs.2013.05.108
   Saadi S, 2019, SIGNAL PROCESS, V154, P74, DOI 10.1016/j.sigpro.2018.08.011
   Sandberg H, 2015, IEEE CONTR SYST MAG, V35, P20, DOI 10.1109/MCS.2014.2364708
   Sarreshtedari S, 2015, IEEE T IMAGE PROCESS, V24, P2266, DOI 10.1109/TIP.2015.2414878
   Shih Frank Y, 2017, Digital watermarking and steganography: fundamentals and techniques
   Sreenivas K, 2018, INT J MACH LEARN CYB, V9, P1193, DOI 10.1007/s13042-017-0641-4
   Su QT, 2019, IEEE ACCESS, V7, P30398, DOI 10.1109/ACCESS.2019.2895062
   Su QT, 2019, IEEE ACCESS, V7, P4358, DOI 10.1109/ACCESS.2018.2888857
   Su QT, 2016, IET IMAGE PROCESS, V10, P817, DOI 10.1049/iet-ipr.2016.0048
   Su QT, 2015, SIGNAL IMAGE VIDEO P, V9, P991, DOI 10.1007/s11760-013-0534-2
   Su QT, 2013, OPTIK, V124, P6255, DOI 10.1016/j.ijleo.2013.05.013
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Sun Xingming., 2004, INFOS TERNATIONAL C, P76
   Thanki R, 2017, J KING SAUD U COMPUT
   Thien HT, 2018, INFORM SCIENCES, V426, P1, DOI 10.1016/j.ins.2017.10.016
   Thongkor K, 2018, J VIS COMMUN IMAGE R, V53, P146, DOI 10.1016/j.jvcir.2018.03.005
   Unnikrishnan K, 2017, J INF SECUR APPL, V35, P1, DOI 10.1016/j.jisa.2017.04.005
   Vahedi E, 2012, DIGIT SIGNAL PROCESS, V22, P153, DOI 10.1016/j.dsp.2011.08.006
   Vaidya SP, 2018, MULTIMED TOOLS APPL, V77, P5609, DOI 10.1007/s11042-017-4476-5
   Venugopala PS, 2017, SUSTAIN COMPUT-INFOR, V15, P82, DOI 10.1016/j.suscom.2017.06.003
   Verma VS, 2015, IETE TECH REV, V32, P479, DOI 10.1080/02564602.2015.1042927
   Voloshynovskiy S, 2001, IEEE COMMUN MAG, V39, P118, DOI 10.1109/35.940053
   Xiang Y, 2018, IEEE-ACM T AUDIO SPE, V26, P529, DOI 10.1109/TASLP.2017.2782487
   Xiang Y, 2014, IEEE-ACM T AUDIO SPE, V22, P1413, DOI 10.1109/TASLP.2014.2328175
   Xiang Y, 2011, IEEE T MULTIMEDIA, V13, P2, DOI 10.1109/TMM.2010.2080668
   Xiao D, 2015, MULTIMED TOOLS APPL, V74, P2109, DOI 10.1007/s11042-013-1744-x
   Yassin NI, 2014, ALEX ENG J, V53, P833, DOI 10.1016/j.aej.2014.07.008
   Yu XY, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101891
   Yuan XC, 2015, INFORM SCIENCES, V298, P159, DOI 10.1016/j.ins.2014.11.040
   Zhang SR, 2014, 2014 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C 2014), P713, DOI 10.1109/IS3C.2014.190
   Zhang W, 2006, P IEEE, P1850
   Zhou X, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P254, DOI 10.1145/1244002.1244066
   [No title captured]
   [No title captured]
NR 111
TC 28
Z9 28
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20149
EP 20197
DI 10.1007/s11042-020-08881-y
EA APR 2020
PG 49
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000526210000004
DA 2024-07-18
ER

PT J
AU Yang, FF
   Mou, J
   Sun, KH
   Chu, R
AF Yang, Feifei
   Mou, Jun
   Sun, Kehui
   Chu, Ran
TI Lossless image compression-encryption algorithm based on BP neural
   network and chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lossless image compression-encryption; Fractional-order memristive BPF
   chaotic circuit; BP neural network; Zigzag confusion
ID SCHEME
AB In this paper, a fractional-order memristive band-pass filter (BPF) chaotic circuit is constructed base on BPF chaotic circuit and fractional definition. The attractor and fractal characteristics are analyzed through phase diagrams and time domain response diagrams. In addition, randomness of the chaotic pseudo-random sequences is tested through NIST SP800-22 and correlation of sequence. According to the fractional-order chaotic system and Back-Propagation (BP) neural network, a lossless image compression-encryption algorithm is proposed. In this algorithm, the original image is compressed through BP neural network, and then the compressed image is encrypted by using Zigzag algorithm and xor operation. Numerical simulation results show that the proposed algorithm not only can effectively compression-encryption image, but also have the great security performances, which provides theoretical guide for the application of this algorithm in information safety, and secret communication field.
C1 [Yang, Feifei; Mou, Jun; Chu, Ran] Dalian Polytech Univ, Sch Informat Sci & Engn, Dalian 116034, Peoples R China.
   [Sun, Kehui] Cent South Univ, Sch Phys & Elect, Changsha 410083, Peoples R China.
C3 Dalian Polytechnic University; Central South University
RP Mou, J (corresponding author), Dalian Polytech Univ, Sch Informat Sci & Engn, Dalian 116034, Peoples R China.
EM moujun@csu.edu.cn
RI Yang, Feifei/AAZ-1489-2021
OI Yang, Feifei/0000-0002-1649-1225; Mou, Jun/0000-0002-7774-2833
FU Basic Scientific Research Projects of Colleges and Universities of
   Liaoning Province [2017 J045]; Provincial Natural Science Foundation of
   Liaoning [20170540060]
FX This work was supported by the Basic Scientific Research Projects of
   Colleges and Universities of Liaoning Province (Grant Nos. 2017 J045);
   Provincial Natural Science Foundation of Liaoning (Grant Nos.
   20170540060).
CR Al-Allaf ONA, 2012, INT C INF TECHN MULT
   Alshehri SA, 2016, IET IMAGE PROCESS, V10, P222, DOI 10.1049/iet-ipr.2014.1039
   Amerijckx C, 1998, IEEE T NEURAL NETWOR, V9, P503, DOI 10.1109/72.668891
   [Anonymous], 2016, IEEE T MOBILE COMPUT
   Bao BC, 2017, IEEE T CIRCUITS-II, V64, P977, DOI 10.1109/TCSII.2016.2641008
   Brindha M, 2016, APPL SOFT COMPUT, V40, P379, DOI 10.1016/j.asoc.2015.09.055
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Costa S, 2001, IMAGE VISION COMPUT, V19, P649, DOI 10.1016/S0262-8856(01)00042-7
   DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644
   Denk T, 1993, IEEE INT C AC
   DONY RD, 1995, P IEEE, V83, P288, DOI 10.1109/5.364461
   Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9
   Hui Fang L, 2010, INT C INF SCI MAN EN
   Hussain AJ, 2015, NEUROCOMPUTING, V151, P975, DOI 10.1016/j.neucom.2014.02.078
   Khashman A, 2008 WSEAS T SIGNAL
   Kouamo S, 2013, ADV INTELL SYST, V189, P515
   Kumar SR, 2018, J KING SAUD U COMPUT
   Liang YR, 2015, J MOD OPTIC, V62, P251, DOI 10.1080/09500340.2014.964342
   Masmoudi A, 2014, IET IMAGE PROCESS, V8, P671, DOI 10.1049/iet-ipr.2013.0598
   Ruan JY, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-11828-0
   Rukhin A, 2010, APPL PHYS LETT, V22, P1645
   S Alshehri Ali, 2015, IET IMAGE PROCESSING
   Sahami S, 2012, IET IMAGE PROCESS, V6, P496, DOI 10.1049/iet-ipr.2011.0079
   Singh YS, 2013, INFORM COMMUNICATION
   Tomar RRS, 2016, 5 INT C COMM SYST NE
   Tong XJ, 2016, MULTIMED TOOLS APPL, V76, P1
   Upadhyay P, 2015, PROCEDIA COMPUT SCI, V54, P671, DOI 10.1016/j.procs.2015.06.078
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2015, OPT LASER ENG, V68, P126, DOI 10.1016/j.optlaseng.2014.12.025
   Wu XJ, 2017, INT J AEROSPACE ENG, V2017, P1, DOI 10.1155/2017/8107190
   Xu GQ, 2016, EUR PHYS J PLUS, V131, DOI 10.1140/epjp/i2016-16385-x
   Xu HK, 2012, APPL MECH MAT, V135-136, P126, DOI [10.4028/www.scientific.net/AMM.135-136.126, DOI 10.4028/WWW.SCIENTIFIC.NET/AMM.135-136.126]
   Yan S, 2013, 3 INT C INSTR
   Ye GD, 2013, NONLINEAR DYNAM, V71, P259, DOI 10.1007/s11071-012-0658-x
   Yeo WK, RES DEV
   Zhang LM, 2017, EUR PHYS J PLUS, V132, DOI 10.1140/epjp/i2017-11310-7
   Zhang Y, 2017, OPT COMMUN, V392, P223, DOI 10.1016/j.optcom.2017.01.061
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhu C, 2018, IEEE ACCESS, VPP, P1
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
NR 41
TC 30
Z9 30
U1 5
U2 78
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19963
EP 19992
DI 10.1007/s11042-020-08821-w
EA APR 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000523581300001
DA 2024-07-18
ER

PT J
AU Kavitha, AV
   Srikrishna, A
   Satyanarayana, C
AF Kavitha, A., V
   Srikrishna, A.
   Satyanarayana, Ch
TI Unsupervised linear contact distributions segmentation algorithm for
   land cover high resolution panchromatic images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing images; Panchromatic images; Image segmentation;
   Mathematical morphology; Linear contact distributions; Texture features
ID MATHEMATICAL MORPHOLOGY; ATTRIBUTE PROFILES; CLASSIFICATION;
   MULTISENSOR; EXTRACTION; FEATURES
AB Automatic segmentation of land use and land cover from high resolution remote sensing imagery has been an essential research area in image processing for the past two decades. Timely and reliable information of land use and land cover is very much essential in administration for proper planning and decision making in various areas like agriculture, urban development, environment protection, etc. In this paper, a new algorithm ULCDSA (Unsupervised Linear Contact Distributions Segmentation Algorithm) is proposed for unsupervised segmentation of high resolution panchromatic data. Texture features extracted with the help of linear contact distributions and mathematical morphology are used in this paper. The proposed method has been implemented and tested on various panchromatic images of N.R.S.C's Cartosat-II data sets, Google earth images and on other aerial images. The results have then been compared with gray scale co-occurrence matrix algorithms and promising results have been obtained.
C1 [Kavitha, A., V; Satyanarayana, Ch] JNTUK, Kakinada, Andhra Pradesh, India.
   [Kavitha, A., V] Sri ABR Govt Degree Coll, Dept Comp Sci, Repalle, Andhra Pradesh, India.
   [Srikrishna, A.] RVR & JC Coll Engn, Dept Informat & Technol, Guntur, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Kakinada; RVR & JC College
   of Engineering
RP Kavitha, AV (corresponding author), JNTUK, Kakinada, Andhra Pradesh, India.; Kavitha, AV (corresponding author), Sri ABR Govt Degree Coll, Dept Comp Sci, Repalle, Andhra Pradesh, India.
EM anubrolukavitha@yahoo.com; atlurisrikrishna@yahoo.com;
   chsatyanarayana@yahoo.com
RI A.V, Kavitha/AFT-3208-2022; Srikrishna/Q-1592-2015
OI A.V, Kavitha/0000-0001-7802-9629; Atluri, Srikrishna/0000-0002-5774-8875
CR [Anonymous], 2016, NRSC SATELLITE IMAGE
   [Anonymous], 2013, INT J SCI RES PUBL
   [Anonymous], 2018, REMOTE SENS BASEL, DOI DOI 10.3390/RS10030443
   Benediktsson JA, 2003, IEEE T GEOSCI REMOTE, V41, P1940, DOI 10.1109/TGRS.2003.814625
   Benediktsson JA, 2018, SIGNALS COMMUN TECHN, P277, DOI 10.1007/978-3-319-66330-2_7
   Chaudhuri B, 2018, IEEE T GEOSCI REMOTE, V56, P1144, DOI [10.1109/tgrs.2017.2760909, 10.1109/TGRS.2017.2760909]
   Chima CI, 2018, GEOCARTO INT, V33, P893, DOI 10.1080/10106049.2017.1316778
   Courtrai L., 2014, 2014 8 IAPR WORKSH P, P1
   Dalla Mura M, 2010, IEEE T GEOSCI REMOTE, V48, P3747, DOI 10.1109/TGRS.2010.2048116
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Doraiswamy P, 2007, IEEE P GEOSC REM SEN, V45, P1074
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   Epifanio I, 2002, IEEE T IMAGE PROCESS, V11, P859, DOI 10.1109/TIP.2002.801119
   Epifanio I, 2007, IEEE T GEOSCI REMOTE, V45, P1074, DOI 10.1109/TGRS.2006.890581
   Ghouti L, 2006, IEEE T SIGNAL PROCES, V54, P1519, DOI 10.1109/TSP.2006.870624
   Grinand C, 2017, INT J APPL EARTH OBS, V54, P1, DOI 10.1016/j.jag.2016.09.002
   Hagner O, 2007, REMOTE SENS ENVIRON, V110, P438, DOI 10.1016/j.rse.2006.08.017
   Hansen MB, 1996, SCAND J STAT, V23, P129
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hug D, 2002, LECT NOTES PHYS, V600, P317
   Jayaraman S., 2012, DIGITAL IMAGE PROCES
   Li DR, 2010, IEEE T IMAGE PROCESS, V19, P2781, DOI 10.1109/TIP.2010.2049528
   Li RS, 2018, J INDIAN SOC REMOTE, V46, P51, DOI 10.1007/s12524-017-0678-6
   Luo YM, 2017, ISPRS INT GEO-INF, V6, DOI 10.3390/ijgi6060177
   Mekuriaw A, 2017, J GEOGR SCI, V27, P79, DOI 10.1007/s11442-017-1365-9
   Pham MT, 2018, IEEE T GEOSCI REMOTE, V56, P1199, DOI 10.1109/TGRS.2017.2761402
   Mitchell AL, 2017, CARBON BAL MANAGE, V12, DOI 10.1186/s13021-017-0078-9
   Neophytou M, 2004, IEEE PROCS EMBS 04 C
   Pastor-Guzman J, 2018, REMOTE SENS ENVIRON, V205, P71, DOI 10.1016/j.rse.2017.11.009
   Rampun Andrik, 2013, P 6 INT C COMP VIS C, P1, DOI [10.1145/2466715.2466720, DOI 10.1145/2466715.2466720]
   Robbe N, 2006, WIT TRANS ECOL ENVIR, V95, P347, DOI 10.2495/WP060351
   Schroder M, 1998, P WTA, DOI [10.1120/3528, DOI 10.1120/3528]
   Serra J., 1983, IMAGE ANAL MATH MORP
   Serra J, 1984, MATH MORPHOLOGY ITS
   Soille P, 2002, IEEE T GEOSCI REMOTE, V40, P2042, DOI 10.1109/TGRS.2002.804618
   Song BQ, 2014, IEEE T GEOSCI REMOTE, V52, P5122, DOI 10.1109/TGRS.2013.2286953
   Sulaiman S.M., 2017, INT J ENG SCI COMPUT, V7, P12138
   Sun Y, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 4, PROCEEDINGS, P271, DOI 10.1109/FSKD.2008.249
   Warfield SK, 2004, IEEE T MED IMAGING, V23, P903, DOI 10.1109/TMI.2004.828354
   Watmough GR, 2017, INT J APPL EARTH OBS, V54, P134, DOI 10.1016/j.jag.2016.09.012
   Xue L., 2012, Communications, Signal Processing, and Systems, P13
   ZIJDENBOS AP, 1994, IEEE T MED IMAGING, V13, P716, DOI 10.1109/42.363096
NR 42
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8781
EP 8799
DI 10.1007/s11042-018-6693-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600022
DA 2024-07-18
ER

PT J
AU Liu, BC
   Lai, MZ
   Wu, JL
   Fu, CC
   Binaykia, A
AF Liu, Bingchun
   Lai, Mingzhao
   Wu, Jheng-Long
   Fu, Chuanchuan
   Binaykia, Arihant
TI Patent analysis and classification prediction of biomedicine industry:
   SOM-KPCA-SVM model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Patent analysis; Patent quality; Patent quality
   classification
ID INFRINGEMENT; TECHNOLOGY; INNOVATION; QUALITY; SYSTEM
AB This paper proposed the application of a combinatorial model of machine learning to patent quality classification and forecasting in the biomedical industry. The model consists of three methods: Self-Organizing Map (SOM), Kernel Principal Component Analysis (KPCA) and Support Vector Machine (SVM), and names it SOM-KPCA-SVM model. The model proposed in this paper is implemented in two steps. First, the SOM groups the patent data and defines the patent level. Second, the patent data is reduced by KPCA to decrease noise, and SVM is applied to KPCA's patent data to derive the classification results. The study collected 11,251 biopharmaceutical patent data from the patent transaction news. After training the patent quality model, 2196 historical patents were used to verify the performance of the training model. The accuracy of the match between experimental results and actual transaction status reached 84.13%. Therefore, the proposed patent quality method as a preliminary screening solution automatically and effectively evaluates the quality of patents. This method saves valuable time for reviewing experts, facilitates the rapid identification of high-quality patents, and can be used for the development of commercialization and mass customization of products.
C1 [Liu, Bingchun; Lai, Mingzhao; Fu, Chuanchuan] Tianjin Univ Technol, Sch Management, Tianjin, Peoples R China.
   [Wu, Jheng-Long] Soochow Univ, Innovat Informat Sci, Taipei, Taiwan.
   [Binaykia, Arihant] Indian Inst Technol, Dept Ind & Syst Engn, Kharagpur, W Bengal, India.
C3 Tianjin University of Technology; Soochow University; Indian Institute
   of Technology System (IIT System); Indian Institute of Technology (IIT)
   - Kharagpur
RP Liu, BC (corresponding author), Tianjin Univ Technol, Sch Management, Tianjin, Peoples R China.
EM liubingchun_tjut@163.com
OI Lai, Mingzhao/0009-0004-5426-5730; Liu, Bingchun/0000-0002-0309-1302
CR Abbas A, 2014, WORLD PAT INF, V37, P3, DOI 10.1016/j.wpi.2013.12.006
   BASBERG BL, 1987, RES POLICY, V16, P131, DOI 10.1016/0048-7333(87)90027-8
   Chapelle O, 2000, ADV NEUR IN, V12, P230
   Chiu CY, 2013, ACHP INT C CREAT ACT
   Chiu TF, 2012, AS C INT INF DAT SYS
   Cho Y, 2014, PORTL INT CONF MANAG, P2986
   Dang JW, 2015, CHINA ECON REV, V35, P137, DOI 10.1016/j.chieco.2015.03.012
   Ercan S, 2014, SOFT COMPUT, V18, P313, DOI 10.1007/s00500-013-1059-x
   Fischer T, 2014, RES POLICY, V43, P519, DOI 10.1016/j.respol.2013.07.013
   Guan JC, 2013, TECHNOL FORECAST SOC, V80, P1271, DOI 10.1016/j.techfore.2012.11.013
   Harhoff D, 1999, REV ECON STAT, V81, P511, DOI 10.1162/003465399558265
   Hsu DH, 2013, STRATEGIC MANAGE J, V34, P761, DOI 10.1002/smj.2037
   Hussinger K, 2019, RES POLICY, V48, P665, DOI 10.1016/j.respol.2018.10.022
   Jeong C, 2014, EXPERT SYST APPL, V41, P3605, DOI 10.1016/j.eswa.2013.11.045
   Jiang M, 2017, BIOTECHNOL BIOENG, V114, P2445, DOI 10.1002/bit.26383
   Juntunen P, 2013, APPL SOFT COMPUT, V13, P3191, DOI 10.1016/j.asoc.2013.01.027
   Lee C, 2013, TECHNOL ANAL STRATEG, V25, P23, DOI 10.1080/09537325.2012.748893
   Nijjar R, 2016, J ABNORM CHILD PSYCH, V44, P1347, DOI 10.1007/s10802-015-0112-x
   Noh H, 2015, KEYWORD SELECTION PR
   Ormel J, 2013, NEUROSCI BIOBEHAV R, V37, P59, DOI 10.1016/j.neubiorev.2012.09.004
   Park YN, 2018, AUTOMAT CONSTR, V87, P215, DOI 10.1016/j.autcon.2017.12.023
   RAVALISON FA, 2011, INT J IND ENG MANAGE, V2, P34
   Segev A, 2012, EXPERT SYST APPL, V39, P13235, DOI 10.1016/j.eswa.2012.05.078
   Shao RP, 2014, MEASUREMENT, V54, P118, DOI 10.1016/j.measurement.2014.04.016
   Su HN, 2012, SCIENTOMETRICS, V92, P181, DOI 10.1007/s11192-012-0716-7
   Thelwell C, 2014, SEMIN THROMB HEMOST, V40, P205, DOI 10.1055/s-0033-1364188
   Tidd J, 2010, J PROD INNOV MANAG, V12, P307
   TRAJTENBERG M, 1990, RAND J ECON, V21, P172, DOI 10.2307/2555502
   Trappey AJC, 2013, J NETW COMPUT APPL, V36, P1441, DOI 10.1016/j.jnca.2013.02.035
   Trappey AJC, 2012, ADV ENG INFORM, V26, P26, DOI 10.1016/j.aei.2011.06.005
   Venugopalan S, 2015, TECHNOL FORECAST SOC, V94, P236, DOI 10.1016/j.techfore.2014.10.006
   Wang XM, 2018, ANN OPER RES, V263, P45, DOI 10.1007/s10479-015-2039-6
   Wu CH, 2010, APPL SOFT COMPUT, V10, P1164, DOI 10.1016/j.asoc.2009.11.033
   Zhang GP, 2014, CHINA ECON REV, V28, P37, DOI 10.1016/j.chieco.2013.11.004
   Zoladz PR, 2013, NEUROSCI BIOBEHAV R, V37, P860, DOI 10.1016/j.neubiorev.2013.03.024
NR 35
TC 18
Z9 18
U1 6
U2 90
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10177
EP 10197
DI 10.1007/s11042-019-7422-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600024
DA 2024-07-18
ER

PT J
AU Li, YS
   Liu, XB
   Gong, XP
   Wang, MR
AF Li, Yushuo
   Liu, Xiabi
   Gong, Xiaopeng
   Wang, Murong
TI A Multi-View features hinged siamese U-Net for image Co-segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image co-segmentation; Multi-view features; Siamese U-Net
ID RECOGNITION
AB This paper proposes a new U-shape structure to extract multi-view features from different images which is incorporated into the network that can be trained end-to-end for image co-segmentation task. The multi-view features integrate global correlations between images, so we can segment the common objects in different images from the features directly. Before getting the multi-view features, we extract the deep features of input images through two weights-shared streams. Then we get pixel-level similarity maps through a similarity layer from deep features. The whole architecture is a Siamese U-net hinged by multi-view features, called iMFNet for short. We further introduce Dice loss and employ both positive and negative examples to train the whole network. Furthermore, a learnable conditional random field (CRF) layer is added to iMFNet for more accurate results. Using the training data from MSRC and PASCAL VOC 2012 datasets, the iMFNet achieves the state-of-the-art performance on the Internet datasets and the competitive performance on the iCoseg datasets.
C1 [Li, Yushuo; Liu, Xiabi; Gong, Xiaopeng] Beijing Inst Technol, Sch Comp Sci & Technol, 5 South Zhongguancun St, Beijing, Peoples R China.
   [Wang, Murong] Sun Yat Sen Univ, Canc Ctr, 651 Dongfeng Rd East, Guangzhou, Peoples R China.
C3 Beijing Institute of Technology; Sun Yat Sen University
RP Li, YS (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, 5 South Zhongguancun St, Beijing, Peoples R China.
EM liyushuo@bit.edu.cn; liuxiabi@bit.edu.cn; gongxp@bit.edu.cn;
   wangmr@sysucc.org.cn
CR Ahmad M, 2006, INT C PATT RECOG, P263
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Chandra S, 2016, LECT NOTES COMPUT SC, V9911, P402, DOI 10.1007/978-3-319-46478-7_25
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Choy C. B., 2016, ADV NEURAL INFORM PR, P2414, DOI DOI 10.5555/3157096.3157366
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Faktor A, 2013, IEEE I CONF COMP VIS, P1297, DOI 10.1109/ICCV.2013.164
   FU HZ, 2015, PROC CVPR IEEE, P4428, DOI DOI 10.1109/CVPR.2015
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P5814, DOI 10.1109/TIP.2016.2614132
   Hu YT, 2018, LECT NOTES COMPUT SC, V11212, P56, DOI 10.1007/978-3-030-01237-3_4
   HUANG TW, 2019, P IEEE C COMP VIS PA
   Jerripothula KR, 2017, PROC CVPR IEEE, P3881, DOI 10.1109/CVPR.2017.413
   Jerripothula KR, 2016, IEEE T MULTIMEDIA, V18, P1896, DOI 10.1109/TMM.2016.2576283
   Joulin Armand, 2010, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2010.5539868
   Kim E, 2012, PROC CVPR IEEE, P686, DOI 10.1109/CVPR.2012.6247737
   Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239
   Kim S., 2017, CVPR, P6560
   Kolmogorov V., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91
   LE W, 2014, P EUR C COMP VIS
   Lee C, 2015, PROC CVPR IEEE, P3837, DOI 10.1109/CVPR.2015.7299008
   Li LN, 2018, NEUROCOMPUTING, V275, P1650, DOI 10.1016/j.neucom.2017.10.002
   Li S, 2018, IEEE T PATTERN ANAL, V40, P2963, DOI 10.1109/TPAMI.2017.2764893
   Li Weihao, 2018, ASIAN C COMPUT VIS, P638
   Li Y, 2016, NEUROCOMPUTING, V172, P225, DOI 10.1016/j.neucom.2014.12.110
   Liu LM, 2017, CIRC SYST SIGNAL PR, V36, P4423, DOI 10.1007/s00034-017-0518-5
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   LUO WJ, 2016, PROC CVPR IEEE, P5695, DOI DOI 10.1109/CVPR.2016.614
   Ma JZ, 2017, IEEE T IMAGE PROCESS, V26, P1216, DOI 10.1109/TIP.2016.2631883
   Meng FM, 2016, COMPUT VIS IMAGE UND, V146, P67, DOI 10.1016/j.cviu.2016.02.004
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Oh SW, 2018, PROC CVPR IEEE, P7376, DOI 10.1109/CVPR.2018.00770
   Quan R, 2016, PROC CVPR IEEE, P687, DOI 10.1109/CVPR.2016.81
   Rocco I, 2017, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2017.12
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253
   RUBIO JC, 2012, PROC CVPR IEEE, P749
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Sun J, 2013, IEEE I CONF COMP VIS, P3400, DOI 10.1109/ICCV.2013.422
   Taniai T, 2016, PROC CVPR IEEE, P4246, DOI 10.1109/CVPR.2016.460
   Tao DP, 2018, IEEE T CIRC SYST VID, V28, P2657, DOI 10.1109/TCSVT.2017.2726580
   Tao ZQ, 2017, AAAI CONF ARTIF INTE, P4285
   THEWLIS J, 2016, P BRIT MACH VIS C
   Vemulapalli R, 2016, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2016.351
   Wang C, 2017, IEEE T IMAGE PROCESS, V26, P5825, DOI 10.1109/TIP.2017.2750410
   Wang F, 2013, IEEE I CONF COMP VIS, P849, DOI 10.1109/ICCV.2013.110
   Wang WG, 2016, IEEE T MULTIMEDIA, V18, P1011, DOI 10.1109/TMM.2016.2545409
   Wang YZ, 2019, IEEE INT CONF COMM, DOI 10.1109/iccw.2019.8757130
   Wang Z, 2016, SIGNAL PROCESS, V120, P691, DOI 10.1016/j.sigpro.2014.11.015
   Yoon JS, 2017, IEEE I CONF COMP VIS, P2186, DOI 10.1109/ICCV.2017.238
   Yuan ZH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3371
   Zbontar J, 2016, J MACH LEARN RES, V17
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
   Zhang C, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.74
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zheng WM, 2014, IEEE T AFFECT COMPUT, V5, P71, DOI 10.1109/TAFFC.2014.2304712
   Zhou T, 2020, IEEE T MED IMAGING
   ZHOU T, 2018, IEEE T CYBERN
   Zhou Y, 2018, IEEE CONF COMPUT
NR 66
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22965
EP 22985
DI 10.1007/s11042-020-08794-w
EA MAR 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000521018900003
DA 2024-07-18
ER

PT J
AU Vakili, E
   Shoaran, M
   Sarmadi, MR
AF Vakili, Elnaz
   Shoaran, Maryam
   Sarmadi, Mohammad R.
TI Single-camera vehicle speed measurement using the geometry of the
   imaging system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle speed measurement; License plate detection; Single camera; Solid
   angle
ID RECOGNITION; MODEL
AB In recent years, measuring the speed of vehicles by a single camera has been done using several methods including the road geometric information, the difference in the number of image pixels of moving objects, and the homographic mapping of the motion vector from the image plane to the global coordinate plane. In this paper, we present a new method based on the geometry of the imaging system and the definition of solid angle. Our method does not require 3D modeling; It has a lower computational cost than the existing methods; And it has an accuracy comparable to the other approaches. In this method, we use the video images taken with a single camera on the road to extract the license plate in the image. Then, using the geometric information of the system and the distance travelled by vehicles the speed is computed. The average relative error of the proposed method is 3.23% and the mean absolute error is 1.32 km/h, which is comparable to the available algorithms. Furthermore, the computational cost of our method is less than the existing ones, which makes it suitable for implementing on embedded systems.
C1 [Vakili, Elnaz; Shoaran, Maryam; Sarmadi, Mohammad R.] Univ Tabriz, Sch Engn Emerging Technol, Dept Mechatron Engn, Tabriz, Iran.
C3 University of Tabriz
RP Shoaran, M (corresponding author), Univ Tabriz, Sch Engn Emerging Technol, Dept Mechatron Engn, Tabriz, Iran.
EM vakili.el@gmail.com; mshoaran@tabrizu.ac.ir; sarmadi.mrbs@gmail.com
OI Sarmadi, Mohammad Reza/0000-0003-2382-8022; vakili,
   elnaz/0000-0002-4557-0547; Shoaran, Maryam/0000-0002-4105-0835
CR Bevilacqua M, 2016, IEEE IMTC P, P1428
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Cheng B, 2018, IEEE INTERNET THINGS, V5, P696, DOI 10.1109/JIOT.2017.2747214
   Czajewski W, 2010, LECT NOTES COMPUT SC, V6374, P308, DOI 10.1007/978-3-642-15910-7_35
   Dailey D. J., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P98, DOI 10.1109/6979.880967
   Dehghani A, 2013, IRAN CONF MACH, P190, DOI 10.1109/IranianMVIP.2013.6779976
   Garg M., 2013, ITSI T ELECT ELECT E, V1, P1
   Gunawan AAS, 2019, PROCEDIA COMPUT SCI, V157, P255, DOI 10.1016/j.procs.2019.08.165
   He X. C., 2007, 2007 IEEE Workshop on Applications of Computer Vision (WACV'07), Austin, TX, P12
   He ZW, 2007, CIS WORKSHOPS 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY WORKSHOPS, P283
   Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468
   Javadi S, 2019, COMPUT ELECTR ENG, V76, P238, DOI 10.1016/j.compeleceng.2019.04.001
   Lan JH, 2014, OPTIK, V125, P289, DOI 10.1016/j.ijleo.2013.06.036
   Li Y, 2008, IEEE ENG MED BIO, P439, DOI 10.1109/IEMBS.2008.4649184
   Luvizon DC, 2017, IEEE T INTELL TRANSP, V18, P1393, DOI 10.1109/TITS.2016.2606369
   Maduro C, 2008, IEEE IMAGE PROC, P777, DOI 10.1109/ICIP.2008.4711870
   Moazzam M.G., 2019, J COMP COMM, V07, P1, DOI DOI 10.4236/JCC.2019.76001
   SOCHOR J, 2017, BRNOCOMPSPEED REV TR, V3, P6
   SONTH A, 2019, P 3 INT C COMP VIS I, P267
   Sun C, 1999, J TRANSP ENG, V125, P531, DOI 10.1061/(ASCE)0733-947X(1999)125:6(531)
   TOURANI A, 2019, INT J IMAGE GRAPH SI, V11
   TRUCCO E, 1998, INTRO TECHNIQUES 3 D, P24
   Wang YH, 2000, TRANSPORT RES REC, P120, DOI 10.3141/1727-15
   WOODS DF, 1994, SPEED MEASUREMENT IN, P1
   Wu J, 2009, 2009 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT - WORKSHOPS, P193, DOI 10.1109/INMW.2009.5195959
   Xiao QK, 2018, MULTIMED TOOLS APPL, V77, P6955, DOI 10.1007/s11042-017-4614-0
   Xiao QK, 2015, SOFT COMPUT, V19, P133, DOI 10.1007/s00500-014-1237-5
   Xiao QK, 2014, MULTIMED TOOLS APPL, V72, P951, DOI 10.1007/s11042-013-1416-x
   Xiao QK, 2011, NEUROCOMPUTING, V74, P3486, DOI 10.1016/j.neucom.2011.06.002
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yang L, 2019, IEEE ACCESS, V7, P106627, DOI 10.1109/ACCESS.2019.2932120
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 33
TC 16
Z9 16
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19307
EP 19327
DI 10.1007/s11042-020-08761-5
EA MAR 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000521018900002
DA 2024-07-18
ER

PT J
AU Abd El-Samie, FE
   Ashiba, HI
   Shendy, H
   Mansour, HM
   Ahmed, HM
   Taha, TE
   Dessouky, MI
   Elkordy, MF
   Abd-Elnaby, M
   El-Fishawy, AS
AF Abd El-Samie, Fathi E.
   Ashiba, Huda I.
   Shendy, H.
   Mansour, Hala M.
   Ahmed, Hossameldin M.
   Taha, Taha E.
   Dessouky, Moawad I.
   Elkordy, Mohamed F.
   Abd-Elnaby, Mohammed
   El-Fishawy, Adel S.
TI Enhancement of Infrared Images Using Super Resolution Techniques Based
   on Big Data Processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single-image super-resolution; Image interpolation; IR images; Neural
   networks; Big data processing
ID SUPERRESOLUTION; INTERPOLATION; SPLINES
AB This paper presents a super-resolution (SR) technique for enhancement of infrared (IR) images. The suggested technique relies on the image acquisition model, which benefits from the sparse representations of low-resolution (LR) and high-resolution (HR) patches of the IR images. It uses bicubic interpolation and minimum mean square error (MMSE) estimation in the prediction of the HR image with a scheme that can be interpreted as a feed-forward neural network. The suggested algorithm to overcome the problem of having only LR images due to hardware limitations is represented with a big data processing model. The performance of the suggested technique is compared with that of the standard regularized image interpolation technique as well as an adaptive block-by-block least-squares (LS) interpolation technique from the peak signal-to-noise ratio (PSNR) perspective. Numerical results reveal the superiority of the proposed SR technique.
C1 [Abd El-Samie, Fathi E.; Shendy, H.; Taha, Taha E.; Dessouky, Moawad I.; Elkordy, Mohamed F.; Abd-Elnaby, Mohammed; El-Fishawy, Adel S.] Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
   [Ashiba, Huda I.] Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
   [Mansour, Hala M.; Ahmed, Hossameldin M.] Benha Univ, Shoubra Fac Engn, Dept Elect & Elect Commun, Banha, Egypt.
   [Abd-Elnaby, Mohammed] Taif Univ, Dept Comp Engn, Coll Comp & Informat Technol, Al Hawiya 21974, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Benha University; Taif University
RP Abd El-Samie, FE (corresponding author), Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.; Ashiba, HI (corresponding author), Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
EM fathi_sayed@yahoo.com; eng_h_2006@yahoo.com; hrshendy@yahoo.com;
   hala.mansour@feng.bu.edu.eg; taha117@hotmail.com; dr_moawad@yahoo.com;
   moh_naby@yahoo.com; aelfishawy@hotmail.com
RI Sayed, Fathi/HRA-4752-2023; Abd-Elnaby, Mohammed/AAD-6573-2022; ashiba,
   huda/GQI-4310-2022
OI Sayed, Fathi/0000-0001-8749-9518; Abd-Elnaby,
   Mohammed/0000-0002-8217-1190; El-Fishawy, Adel/0000-0003-1567-457X;
   ashiba, huda/0000-0002-4926-8919; , HM Abdelkader/0009-0005-7854-7545
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2006, J BRAZ COMPUT SOC, DOI DOI 10.1590/S0104-65002006000100006
   [Anonymous], P ICASSP
   Armstrong GR, 1996, P SOC PHOTO-OPT INS, V2774, P257, DOI 10.1117/12.246667
   Ashiba HI, 2011, CIRC SYST SIGNAL PR, V30, P543, DOI 10.1007/s00034-010-9243-z
   Bahy RM, 2014, SIGNAL PROCESS, V103, P155, DOI 10.1016/j.sigpro.2014.01.008
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   Fortin J, 1996, P SOC PHOTO-OPT INS, V2743, P185, DOI 10.1117/12.241959
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Han JK, 2001, OPT ENG, V40, P540, DOI 10.1117/1.1355250
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Liu Y, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/297672
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927
   Mao YX, 2016, INFRARED PHYS TECHN, V76, P735, DOI 10.1016/j.infrared.2016.05.001
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Shin JH, 1998, IEEE T CONSUM ELECTR, V44, P1042, DOI 10.1109/30.713232
   Sun JA, 2010, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2010.5540206
   Thévenaz P, 2000, IEEE T MED IMAGING, V19, P739, DOI 10.1109/42.875199
   Tian J, 2010, J VIS COMMUN IMAGE R, V21, P232, DOI 10.1016/j.jvcir.2010.01.001
   Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930
   UR H, 1992, CVGIP-GRAPH MODEL IM, V54, P181, DOI 10.1016/1049-9652(92)90065-6
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang XM, 2016, J SYST ARCHITECT, V64, P11, DOI 10.1016/j.sysarc.2015.11.007
   Yu GS, 2012, IEEE T IMAGE PROCESS, V21, P2481, DOI 10.1109/TIP.2011.2176743
   Yue LW, 2016, SIGNAL PROCESS, V128, P389, DOI 10.1016/j.sigpro.2016.05.002
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang HC, 2012, IEEE T IMAGE PROCESS, V21, P4054, DOI 10.1109/TIP.2012.2199330
   Zhang KB, 2015, IEEE T IMAGE PROCESS, V24, P846, DOI 10.1109/TIP.2015.2389629
   Zhao Y, 2016, INFRARED PHYS TECHN, V76, P139, DOI 10.1016/j.infrared.2016.02.001
   Zhao Y, 2015, INFRARED PHYS TECHN, V71, P506, DOI 10.1016/j.infrared.2015.06.017
   Zhu Y., 2014, 2014 IEEE International Conference on Multimedia and Expo (ICME), P1
NR 38
TC 3
Z9 3
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5671
EP 5692
DI 10.1007/s11042-019-7634-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900011
DA 2024-07-18
ER

PT J
AU Ashiba, MI
   Tolba, MS
   El-Fishawy, AS
   El-Samie, FEA
AF Ashiba, M. I.
   Tolba, M. S.
   El-Fishawy, A. S.
   El-Samie, F. E. Abd
TI Hybrid enhancement of infrared night vision imaging system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Night vision; Histogram equalization; Bi-histogram equalization; Plateau
   histogram equalization; AWT; Homomorphic enhancement
ID FUSION
AB This paper presents a proposed approach for the enhancement of Infrared (IR) night vision images. This approach is based on a trilateral contrast enhancement in which the IR night vision images pass through three stages: segmentation, enhancement and sharpening. In the first stage, the IR image is divided into segments based on thresholding. The second stage, which is the heart of the enhancement approach, depends on additive wavelet transform (AWT) to decompose the image into an approximation and details. Homomorphic enhancement is performed on the detail components, while plateau histogram equalization is performed on the approximation plane. Then, the image is reconstructed and subjected to a post-processing high-pass filter. Average gradient, Sobel edge magnitude and spectral entropy are used as quality metrics for evaluation of the proposed approach. The used metrics ensure good success of this proposed approach.
C1 [Ashiba, M. I.; Tolba, M. S.] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.
   [El-Fishawy, A. S.; El-Samie, F. E. Abd] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Menofia University
RP Ashiba, MI (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.
EM engashiba@gmail.com; maha_saad_tolba@yahoo.com; aelfishawy@hotmail.com;
   fathi_sayed@yahoo.com
OI El-Fishawy, Adel/0000-0003-1567-457X
CR Alirezanejad M., 2014, INDIAN J SCI TECHNOL, V7, P517, DOI 10.17485/ijst/2014/v7i4.12
   [Anonymous], INT J COMPUT ELECT A
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], J AUTOM ARTIF INTELL
   Ashiba H. I., 2008, Progress In Electromagnetics Research C, V1, P123, DOI 10.2528/PIERC08012301
   Fan ZL, 2017, INFRARED PHYS TECHN, V86, P44, DOI 10.1016/j.infrared.2017.08.015
   Fan ZL, 2016, INFRARED PHYS TECHN, V74, P44, DOI 10.1016/j.infrared.2015.11.006
   Gade R, 2014, MACH VISION APPL, V25, P245, DOI 10.1007/s00138-013-0570-5
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gupta S.G., 2013, Int. J. Adv. Res. Comput. Eng. Technol, V2, P2278
   Kong NSP, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON COMPUTER TECHNOLOGY AND DEVELOPMENT, VOL 2, P308, DOI 10.1109/ICCTD.2009.46
   Lan XY, 2020, PATTERN RECOGN LETT, V130, P12, DOI 10.1016/j.patrec.2018.10.002
   Lan XY, 2018, AAAI CONF ARTIF INTE, P7008
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2017, AAAI CONF ARTIF INTE, P4118
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qi YH, 2016, INFRARED PHYS TECHN, V76, P521, DOI 10.1016/j.infrared.2016.03.021
   Song Q, 2016, INFRARED PHYS TECHN, V77, P464, DOI 10.1016/j.infrared.2016.06.023
   Torabi A, 2012, COMPUT VIS IMAGE UND, V116, P210, DOI 10.1016/j.cviu.2011.10.006
   Wang GL, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P2961, DOI 10.1109/ICAL.2008.4636684
   Wang J, 2014, INFRARED PHYS TECHN, V67, P477, DOI 10.1016/j.infrared.2014.09.019
   Wang Q, 2007, IEEE T CONSUM ELECTR, V53, P757, DOI 10.1109/TCE.2007.381756
   Wu Z, THERMAL INFRARED VID
   Zhang Q, 2016, INFRARED PHYS TECHN, V74, P11, DOI 10.1016/j.infrared.2015.11.003
   Zhang SQ, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10080304
NR 27
TC 6
Z9 9
U1 6
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6085
EP 6108
DI 10.1007/s11042-019-7510-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900030
DA 2024-07-18
ER

PT J
AU Tsai, TH
   Huang, CC
   Zhang, KL
AF Tsai, Tsung-Han
   Huang, Chih-Chi
   Zhang, Kung-Long
TI Design of hand gesture recognition system for human-computer interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin color segmentation; Labeling; Hand gesture recognition; Convex
   hull; Human-computer interaction
AB Human-Computer interaction (HCI) with gesture recognition is designed to recognize a number of meaningful human expressions, and has become a valuable and intuitive computer input technique. Hand gestures are one of the most intuitive and common forms of communication, and can communicate a wide range of meaning. Vision-based hand gesture recognition has received a significant amount of research attention in recent years. However, the field still presents a number of challenges for researchers. In the vision-based hand gesture interaction process between humans and computers, gesture interpretation must be performed quickly and with high accuracy. In this paper, a low-cost HCI system with hand gesture recognition is proposed. This system uses several vision techniques. Skin and motion detection is used for capturing the region-of-interest from the background regions. A connected component labeling algorithm is proposed to identify the centroid of an object. To identify the exact area of hand gesture, the arm area is removed with the aid of a convex hull algorithm. Moreover, a real-time demonstration system is developed, based on a single-camera mechanism which allows for the use of wearable devices. Simulation results show that the recognition rate is still high, although some interference is encountered in the simulated environments.
C1 [Tsai, Tsung-Han; Huang, Chih-Chi; Zhang, Kung-Long] Natl Cent Univ, Dept Elect Engn, 300 Jung Da Rd, Jung Li City 320, Taiwan.
C3 National Central University
RP Tsai, TH (corresponding author), Natl Cent Univ, Dept Elect Engn, 300 Jung Da Rd, Jung Li City 320, Taiwan.
EM han@ee.ncu.edu.tw; peterpeteraa@dsp.ee.ncu.edu.tw;
   dontmove@dsp.ee.ncu.edu.tw
CR Aksac A, 2011, EL EL ENG ELECO 2011, P457
   [Anonymous], INT C INV SYST CONTR
   [Anonymous], 2011, 2011 8 INT C INF COM, DOI DOI 10.1109/ICICS.2011.6174264
   [Anonymous], INT C COMP COMM SYST
   [Anonymous], HDB VIRTUAL ENV TECH
   [Anonymous], IM INF PROC ICIIP 20
   [Anonymous], INT WORKSH IM AN MUL
   Avilés-Arriaga HH, 2003, RO-MAN 2003: 12TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P133
   Bellal A, 2011, INT REV RED CROSS, V93, P47, DOI 10.1017/S1816383111000051
   Berman S, 2012, IEEE T SYST MAN CY C, V42, P277, DOI 10.1109/TSMCC.2011.2161077
   Binh N.D., 2005, Proceedings of International Conference on Graphics, Vision and Image Processing GVIP-05, P362
   Burger Thomas, 2005, 2005 13th European Signal Processing Conference, P1
   Chen Q, 2008, IEEE T INSTRUM MEAS, V57, P1562, DOI 10.1109/TIM.2008.922070
   Chen-Chiung Hsieh, 2010, Proceedings of the 2010 2nd International Conference on Signal Processing Systems (ICSPS 2010), P394, DOI 10.1109/ICSPS.2010.5555462
   Dias Daniel B., 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P697, DOI 10.1109/IJCNN.2009.5178917
   Dipietro L, 2008, IEEE T SYST MAN CY C, V38, P461, DOI 10.1109/TSMCC.2008.923862
   Elmezain M, 2008, JOURNAL WSCG, V16, P65
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Foxlin E, 2002, HUM FAC ER, P163
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hong-xiang Duan, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P139, DOI 10.1109/ICCSN.2011.6014236
   Kukharev G., 2004, Proceedings of the 12th Winter School on Computer Graphics (WSCG), Plzen, Czech Republic, P157
   Kumar P., 2012, Proceedings of the 2012 1st International Conference on Recent Advances in Information Technology (RAIT 2012), P750, DOI 10.1109/RAIT.2012.6194548
   Lacassagne L., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P520, DOI 10.1109/ICIAP.1999.797648
   Lee C, 1996, IEEE INT CONF ROBOT, P2982, DOI 10.1109/ROBOT.1996.509165
   Lin L, 2012, PROCEEDING OF THE IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P311, DOI 10.1109/ICInfA.2012.6246824
   Lu ZY, 2014, IEEE T HUM-MACH SYST, V44, P293, DOI 10.1109/THMS.2014.2302794
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Modler P, 2008, IEEE SYS MAN CYBERN, P1538
   Rahmat RW, 2012, INT CONF ADV COMPUT, P481, DOI 10.1109/ACSAT.2012.71
   Rautaray S.S., 2012, 2012 IEEE International Conference on Technology Enhanced Education (ICTEE), P1, DOI DOI 10.1109/ICTEE.2012.6208628
   Rossol N, 2016, IEEE T HUM-MACH SYST, V46, P350, DOI 10.1109/THMS.2015.2467212
   Sahoo JP, 2018, IET IMAGE PROCESS, V12, P1780, DOI 10.1049/iet-ipr.2017.1312
   Song SN, 2018, IEEE INT C NETW SENS
   Suk HI, 2010, PATTERN RECOGN, V43, P3059, DOI 10.1016/j.patcog.2010.03.016
   Takahashi T., 1991, SIGCHI Bulletin, V23, P67, DOI 10.1145/122488.122499
   Tang C, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2012)
   Te-Cheng Liu, 2009, 2009 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM), P1828, DOI 10.1109/AIM.2009.5229788
   Wachs JP, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1897816.1897838
   Wan MH, 2017, FUZZY SET SYST, V318, P120, DOI 10.1016/j.fss.2016.06.001
   Wan MH, 2017, MULTIMED TOOLS APPL, V76, P355, DOI 10.1007/s11042-015-3057-8
   Wan MH, 2014, INFORM SCIENCES, V274, P55, DOI 10.1016/j.ins.2014.02.145
   Xu DY, 2006, INT C PATT RECOG, P519
   Yi BF, 2005, COMPUT SCI ENG, V7, P92, DOI 10.1109/MCSE.2005.58
   Zhang X, 2011, IEEE T SYST MAN CY A, V41, P1064, DOI 10.1109/TSMCA.2011.2116004
NR 45
TC 26
Z9 26
U1 1
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5989
EP 6007
DI 10.1007/s11042-019-08274-w
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900025
DA 2024-07-18
ER

PT J
AU Waqas, UA
   Khan, M
   Batool, SI
AF Waqas, Umer Aziz
   Khan, Majid
   Batool, Syeda Iram
TI A new watermarking scheme based on Daubechies wavelet and chaotic map
   for quick response code images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; QR-code s; Daubechies wavelet transform
ID TEXTURE MEASURES; S-BOXES; CONSTRUCTION
AB The world is evolving due to fast transmission of digital information in the forms of different digital contents over numerous online web applications. The transmission of information over social media is at its peak. The advanced means of different digital applications make our lives quite easy but it added more sensitivity to our digital information which can accessed through internet. In the advanced digital era, the protection of digital information and intellectual properties of any organizations is one of the vital problems in technologically advanced ages. To protect the illegal access and duplication of any digital information over insecure communication is fall in the copyright protection techniques. The digital watermarking which is one of the fundamental classes of information hiding techniques that can be used to protect the ownership of any digital contents. Generally, the digital contents cannot be altered in information hiding schemes but secret information is embedded in information carriers. The perception of this article is to design a new digital watermarking scheme which uses multi-layer of information security algorithms. We have utilized chaotic logistic map in order to generate a nonlinear component of block cipher and then applied the suggested substitution box (S-box) in order to encrypt a quick response code (QR-code). Moreover, our innovative suggested watermarking scheme uses Daubechies wavelet transform which is an efficient multi-determination frequency domain for the insertion of encrypted digital logo in the form of QR-codes. We have used different strength analysis which clearly authenticates the validity of our anticipated watermarking scheme.
C1 [Waqas, Umer Aziz] Inst Space Technol Islamabad, Dept Elect Engn, Islamabad, Pakistan.
   [Khan, Majid] Inst Space Technol Islamabad, Dept Appl Math & Stat, Islamabad, Pakistan.
   [Khan, Majid; Batool, Syeda Iram] Inst Space Technol Islamabad, Cyber & Informat Secur Lab, Islamabad, Pakistan.
   [Batool, Syeda Iram] Inst Space Technol Islamabad, Dept Avion Engn, Islamabad, Pakistan.
RP Khan, M (corresponding author), Inst Space Technol Islamabad, Dept Appl Math & Stat, Islamabad, Pakistan.; Khan, M (corresponding author), Inst Space Technol Islamabad, Cyber & Informat Secur Lab, Islamabad, Pakistan.
EM mk.cfd1@gmail.com
RI Khan, Majid/T-9408-2019
OI Khan, Majid/0000-0001-5454-3770
CR Ali KM, 2019, INT J THEOR PHYS, V58, P3091, DOI 10.1007/s10773-019-04188-3
   Ali KM, 2019, MULTIMED TOOLS APPL, P1
   [Anonymous], 3D RES
   Arshad U, 2019, INT J THEOR PHYS, P1
   Batool SI, 2019, MULTIMED TOOLS APPL, V78, P27611, DOI 10.1007/s11042-019-07881-x
   Batool S, 2014, NEURAL COMPUT APPL, V25, P2037, DOI 10.1007/s00521-014-1691-0
   CONNERS RW, 1984, COMPUT VISION GRAPH, V25, P273, DOI 10.1016/0734-189X(84)90197-X
   CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204, DOI 10.1109/TPAMI.1980.4767008
   Firdousi F, 2019, INT J THEOR PHYS, V58, P3871, DOI 10.1007/s10773-019-04254-w
   Geo M, 2012, FDN INTELL SYST ADV, V122, P457
   Gunjal BL, 2011, ARXIV11092325
   HARALICK RM, 1973, IEEE T GEOSCI REMOTE, VGE11, P171, DOI 10.1109/TGE.1973.294312
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hasija M, 2011, IJCSI INT J COMPUT S, V8, P559
   HE DC, 1987, PATTERN RECOGN LETT, V6, P269, DOI 10.1016/0167-8655(87)90087-0
   IIZUKA M, 1987, COMPUT VISION GRAPH, V38, P342, DOI 10.1016/0734-189X(87)90118-6
   Javeed A, MULTIMED TOOLS, V78, P31467
   Kaur M, 2012, INT J RES ENG APPL S, V2, P226
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Khan M, 2019, WIRELESS PERS COMMUN, V109, P849, DOI 10.1007/s11277-019-06594-6
   Khan M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206460
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan M, 2017, MULTIMED TOOLS APPL, V76, P24027, DOI 10.1007/s11042-016-4090-y
   Khan M, 2016, SIGNAL IMAGE VIDEO P, V10, P293, DOI 10.1007/s11760-014-0741-5
   Khan M, 2015, NEURAL COMPUT APPL, V26, P1137, DOI 10.1007/s00521-014-1800-0
   Khan M, 2015, NEURAL COMPUT APPL, V26, P845, DOI 10.1007/s00521-014-1747-1
   Khan M, 2014, NONLINEAR DYNAM, V76, P377, DOI 10.1007/s11071-013-1132-0
   Khan M, 2013, NONLINEAR DYNAM, V73, P1795, DOI 10.1007/s11071-013-0904-x
   Khan M, 2013, NONLINEAR DYNAM, V71, P489, DOI 10.1007/s11071-012-0675-9
   Khan MA, 2019, MATER RES FOUND, V50, P1, DOI 10.21741/9781644900239-1
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Lee H.-C., 2013, ADV INTELLIGENT SYST, V2, P141
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Leng L, 2015, MULTIMED TOOLS APPL, V74, P11683, DOI 10.1007/s11042-014-2255-0
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Madane AR, 2008, P SPIT IEEE C INT C, V1, P121
   Munir Noor, 2018, 2018 International Conference on Applied and Engineering Mathematics (ICAEM), P48, DOI 10.1109/ICAEM.2018.8536308
   Naseer Y, 2019, CRYPTOGRAPHY-BASEL, V3, DOI 10.3390/cryptography3010006
   Naseer Y, 2019, MICROPROCESS MICROSY, V65, P1, DOI 10.1016/j.micpro.2018.12.003
   Shah Dawood, 2018, 2018 International Conference on Applied and Engineering Mathematics (ICAEM), P38, DOI 10.1109/ICAEM.2018.8536281
   Shah T, 2019, MULTIMED TOOLS APPL, V78, P1219, DOI 10.1007/s11042-018-6250-8
   Shaikh H., 2012, INT J COMPUTER SCI E, V2, P63
   SIEW LH, 1988, IEEE T PATTERN ANAL, V10, P92, DOI 10.1109/34.3870
   Song W, 2011, J CENT SOUTH UNIV T, V18, P116, DOI 10.1007/s11771-011-0668-8
   Sun M, 2007, NEW ZEAL J AGR RES, V50, P861, DOI 10.1080/00288230709510361
   TRIVEDI MM, 1984, COMPUT VISION GRAPH, V28, P199, DOI 10.1016/S0734-189X(84)80022-5
   Ullah MF, 2019, NUTRACEUTICALS AND NATURAL PRODUCT DERIVATIVES: DISEASE PREVENTION & DRUG DISCOVERY, P1, DOI 10.1002/9781119436713
   Waseem HM, 2019, APPL PHYS B-LASERS O, V125, DOI 10.1007/s00340-019-7142-y
   Waseem HM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063022
   Waseem HM, 2018, INT J THEOR PHYS, V57, P3584, DOI 10.1007/s10773-018-3872-6
   WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777
   WU CM, 1992, CVGIP-GRAPH MODEL IM, V54, P407, DOI 10.1016/1049-9652(92)90025-S
   Younas I, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120913
   Zhang JL, 2017, IEEE T VLSI SYST, V25, P1520, DOI 10.1109/TVLSI.2016.2619682
   Zhang JL, 2015, IEEE T INF FOREN SEC, V10, P1137, DOI 10.1109/TIFS.2015.2400413
   Zhang JL, 2012, RADIOENGINEERING, V21, P764
NR 59
TC 17
Z9 17
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6891
EP 6914
DI 10.1007/s11042-019-08570-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900065
DA 2024-07-18
ER

PT J
AU Anurekha, D
   Sankaran, RA
AF Anurekha, D.
   Sankaran, R. A.
TI Efficient classification and grading of MANGOES with GANFIS for improved
   performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing techniques; Genetic algorithm; Adaptive neuro-fuzzy
   inference system
ID NEURAL-NETWORK
AB The application of image processing has been extended to agricultural industries in recent times. As the concept of image processing has vast application in agricultural industries, fruit grading has been focused in this research. There are number of approaches available for the classification and grading of mangoes, they suffer to achieve higher performance in classification. The most approaches uses color features and shape features only. To improve the performance of classification and fruit grading, an efficient GANFIS (Genetic Adaptive Neuro Fuzzy Inference System) is presented in this paper. The GANFIS approach reads the 2D mango images and extract various features like color, shape and texture features from the input image. Over the features extracted, the genetic algorithm has been applied to perform feature selection. With the extracted features, the method applies adaptive neuro fuzzy inference technique to perform classification and grading. The classification algorithm estimates multi feature class similarity MFCS measure towards each class of mangoes to perform classification where the grading is performed based on the same being estimated within the class. The proposed GANFIS approach has achieved sensitivity (98.05%), specificity (97.39%) and Accuracy (99.18%).
C1 [Anurekha, D.; Sankaran, R. A.] Salem Coll Engn & Technol, Salem, Tamil Nadu, India.
RP Anurekha, D (corresponding author), Salem Coll Engn & Technol, Salem, Tamil Nadu, India.
EM anurekascer14@rediffmail.com
CR Alipasandi A., 2013, International Journal of Agronomy and Plant Production, V4, P2179
   Alrajeh K.M., 2012, Int. J. Comput. Appl., V41, P36
   [Anonymous], 2013, International Journal of Computer Applications
   Bennedsen BS, 2007, T ASABE, V50, P2257, DOI 10.13031/2013.24078
   Boonmung S, 2006, J TEXTURE STUD, V37, P568, DOI 10.1111/j.1745-4603.2006.00069.x
   Dubey SR, 2016, SIGNAL IMAGE VIDEO P, V10, P819, DOI 10.1007/s11760-015-0821-1
   Gupta G, 2011, IJSCE, V1
   Ikenberry GJ, 2009, CRISIS OF AMERICAN FOREIGN POLICY: WILSONIANISM IN THE TWENTY-FIRST CENTURY, P1
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Janik LJ, 2007, ANAL CHIM ACTA, V594, P107, DOI 10.1016/j.aca.2007.05.019
   Kavdir Ismail, 2003, Turkish Journal of Agriculture and Forestry, V27, P375
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Llobet E, 1999, MEAS SCI TECHNOL, V10, P538, DOI 10.1088/0957-0233/10/6/320
   Mercol JP, 2007, AUTOMATIC CLASSIFICA
   Naganur Sannakki, 2012, INT J ADV RES COMPUT, V1
   Rasekhi R, 2011, CIOSTA CIGR 5 C
   Razak T. R. B., 2012, INT C AGR ENV BIOL S, P26
   Salim SNM, 2005, 1 INT WORKSH ART LIF, P7
   Sevo I, 2016, IEEE GEOSCI REMOTE S, V13, P740, DOI 10.1109/LGRS.2016.2542358
   Singh A, 2017, J VIS COMMUN IMAGE R, V42, P173, DOI 10.1016/j.jvcir.2016.11.017
   TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116, DOI 10.1109/TSMC.1985.6313399
   Tang Y, 2017, IEEE T IMAGE PROCESS, V26, P994, DOI [10.1109/TIP.2016.2639440, 10.1109/TIP.2017.2656474]
   Teoh C. C., 2007, J TROP FOOD SCI, V35, P183
   Tiger B, 2013, INT J SCI REIJSR, V2
   Yimyam P, 2005, INT C CAS KINTEX GYE
   Zakaria A, 2012, SENSORS-BASEL, V12, P6023, DOI 10.3390/s120506023
NR 26
TC 7
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 4169
EP 4184
DI 10.1007/s11042-019-07784-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700060
DA 2024-07-18
ER

PT J
AU Kayalvizhi, S
   Malarvizhi, S
AF Kayalvizhi, S.
   Malarvizhi, S.
TI A novel encrypted compressive sensing of images based on fractional
   order hyper chaotic Chen system and DNA operations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing; Hyperchaotic; DNA; Encryption
ID RANDOM NUMBER GENERATOR; ALGORITHM; RECONSTRUCTION
AB Secured Compressive sensing of the images becomes one of the essential issues in multimedia applications. In the recent times, encryption in compressive sensing is achieved via the use of multiple one dimensional chaotic system (1D chaotic) and hyper-chaotic system (HC). However, the security of the system still needs to be improved. To solve this issue, novel encrypted compressive sensing of images based on Fractional order hyper chaotic Chen system and DNA operations is proposed in this paper. The basic idea is to introduce a new algorithm which provides compression rate below the Nyquist rate along with increased security by jointly using Fractional order hyper chaotic chen system and DNA operations for image encryption. The encryption algorithm combines Fractional order hyperchaotic chen system and DNA operations. Fractional order hyperchaotic chen system has high randomness and rich dynamic phenomena which enhance the encryption and the algorithm efficiency is further increased by DNA operations.4-Dimensioanal Fractional order hyper chaotic chen system is used to generate the measurement matrix. Compressive sensing measurements are converted to a stream of binary digits and the correlation between the adjacent bits is further reduced through global scrambling. The DNA operations are performed on the scrambled binary sequences and hyper chaotic sequences, which increases the algorithm efficiency. The results of the experiments accomplish that the proposed encryption method is extremely sensitive to small changes in secret keys, shows good performance in histogram analysis, correlation analysis, Information Entropy and is very sensitive to a bit change in an input image. The Block Compressive sensing (BCS) reconstruction algorithms are used to validate the proposed encryption method. In the proposed method, experimental analysis are performed on different images of size 512 x 512 which are divided in to blocks of size 32 X 32. The reconstruction analysis is performed with different subsampling rates of 0.1, 0.2, 0.3, 0.4 and 0.5.The results depicted that the proposed method maintains the robustness and reconstruction quality of Compressive sensing with enhanced encryption.
C1 [Kayalvizhi, S.; Malarvizhi, S.] SRM Inst Sci & Technol, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Kayalvizhi, S (corresponding author), SRM Inst Sci & Technol, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
EM kayalvizhi.s@ktr.srmuniv.ac.in; malarvizhi.g@ktr.srmuniv.ac.in
RI S, Kayalvizhi/AAE-7468-2021; S, KAYALVIZHI/ABI-8087-2020
OI S, Kayalvizhi/0000-0002-3385-848X; S, KAYALVIZHI/0000-0002-6080-2801;
   SUBRAMANI, MALARVIZHI/0000-0002-0794-3170
CR Akhshani A, 2014, COMMUN NONLINEAR SCI, V19, P101, DOI 10.1016/j.cnsns.2013.06.017
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Baum E. B., 1999, DNA Based Computers II. DIMACS Workshop, P235
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Do TT, 2008, CONF REC ASILOMAR C, P581, DOI 10.1109/ACSSC.2008.5074472
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Fowler JE, 2011, EUR SIGNAL PR CONF, P564
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Haupt J, 2006, IEEE T INFORM THEORY, V52, P4036, DOI 10.1109/TIT.2006.880031
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   King OD, 2007, DISCRETE APPL MATH, V155, P831, DOI 10.1016/j.dam.2005.07.015
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Li YX, 2005, INT J BIFURCAT CHAOS, V15, P3367, DOI 10.1142/S0218127405013988
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Özkaynak F, 2014, NONLINEAR DYNAM, V78, P2015, DOI 10.1007/s11071-014-1591-y
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang XY, 2016, NONLINEAR DYNAM, V83, P333, DOI 10.1007/s11071-015-2330-8
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013021
   Zhang L, 2017, COMPLEXITY, DOI 10.1155/2017/8917258
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 30
TC 31
Z9 31
U1 4
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3957
EP 3974
DI 10.1007/s11042-019-7642-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700048
DA 2024-07-18
ER

PT J
AU Lim, CK
   Tan, KL
   Zaidan, AA
   Zaidan, BB
AF Lim, C. K.
   Tan, K. L.
   Zaidan, A. A.
   Zaidan, B. B.
TI A proposed methodology of bringing past life in digital cultural
   heritage through crowd simulation: a case study in George Town, Malaysia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd simulation; Heterogenous behaviours; Digital heritage
ID ENVIRONMENTS; BEHAVIORS; FRAMEWORK; MODEL
AB One of the heritages can be denoting to the values of human activity in the past and its cultural oral narratives. To virtualize these heritages, it means to actualize the heritage into the digital content. When attempting to understand a particular cultural heritage site, the challenge here is that the connection to the past is non-existence due to insufficient historical information of the heritage sites. On the other hand, crowd simulation has been widely applied for the purpose of construction and reconstruction of tangible and intangible digital heritage. Therefore, the main objective of this research is to bring past life into digital cultural heritage and it would need the inclusions of the visual information of the surroundings and the people in the past. This paper also investigates the phase-by-phase methodology to deal with crowd simulation of different ethnic groups with heterogeneous behaviors in digital cultural heritage. The crowd is modeled and simulated based on the classical particle-based boid algorithm in virtual heritage environment that includes social behaviors of heterogeneous crowd transpired in an old trading port. With respect to bringing the past life into digital cultural heritage, microscopic based crowd simulation is applied to the complex case such as a multi-ethnic trading port, involving distinguished behavioral patterns through a heterogeneous crowd simulation method. In the simulation, a high-level control method, hierarchical state-machine and group formation model are introduced through inter-ethnic interactions formalism. The results of the assessment and validation have shown that the proposed schemes, models and methods have successfully been deployed in George Town, Malaysia through the proposed methodology. Such a simulation can be beneficial for virtual walkthrough and virtual museum applications. Through several investigations, the advantages of applying this approach in simulating the digital George Town are demonstrated as well as its potential for future developments are identified.
C1 [Lim, C. K.; Tan, K. L.; Zaidan, A. A.; Zaidan, B. B.] Sultan Idris Educ Univ UPSI, Fac Art Comp & Creat Ind FSKIK, Dept Comp Sci, Tanjong Malim 35900, Perak Darul Rid, Malaysia.
C3 Universiti Pendidikan Sultan Idris
RP Lim, CK (corresponding author), Sultan Idris Educ Univ UPSI, Fac Art Comp & Creat Ind FSKIK, Dept Comp Sci, Tanjong Malim 35900, Perak Darul Rid, Malaysia.
EM kim@fskik.upsi.edu.my; tankianlam@fskik.upsi.edu.my;
   aws.alaa@fskik.upsi.edu.my; bilalbahaa@fskik.upsi.edu.my
RI Lim, Chen Kim/AAJ-9705-2020; Albahri,, A. S./F-7289-2010; zaidan,
   bilal/AAJ-7841-2021
OI Lim, Chen Kim/0000-0003-4353-4128; Kian Lam, Tan/0000-0003-1627-7437;
   zaidan, bilal/0000-0001-7412-8267
CR Ali S., 2013, Modeling, Simulation and Visual Analysis of Crowds, P1, DOI DOI 10.1007/978-1-4614-8483-7
   [Anonymous], INTERACTION GROUPS A
   [Anonymous], MODELLING WALLED CIT
   [Anonymous], LEARN UN
   [Anonymous], J COMPUTING
   [Anonymous], VIRTUAL SYST MULTIME
   [Anonymous], P 7 INT C MOT GAM 14
   [Anonymous], OLD MYTHS NEW APPROA
   [Anonymous], P UNESCO WORLD HER C
   [Anonymous], DIG HER INT C
   [Anonymous], 1999, P GAM DEV C
   [Anonymous], 2015, BELIEVABLE CROWDS GE
   [Anonymous], 2014, 3D RES CHALLENGES CU
   [Anonymous], C DISTR FRAM APPL DF
   [Anonymous], 13 S VIRT REAL SVR
   [Anonymous], 8 INT S VIRT REAL AR
   [Anonymous], CROWD SIMULATION
   Anvari B, 2015, TRANSPORT RES C-EMER, V51, P83, DOI 10.1016/j.trc.2014.10.012
   Attardi G., 2000, BAR INTERNATIONAL SERIES, V843, P79
   Baig MW, 2014, P INT CONF INTELL, P507, DOI 10.1109/ISMS.2014.93
   Bogdanovych Anton, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P28, DOI 10.1007/978-3-642-33197-8_3
   Bogdanovych A, 2011, SECURITY IN VIRTUAL WORLDS, 3D WEBS, AND IMMERSIVE ENVIRONMENTS: MODELS FOR DEVELOPMENT, INTERACTION, AND MANAGEMENT, P140, DOI 10.4018/978-1-61520-891-3.ch008
   Che XD, 2015, VISUAL COMPUT, V31, P853, DOI 10.1007/s00371-015-1119-6
   Courty N, 2014, PATTERN RECOGN LETT, V44, P161, DOI 10.1016/j.patrec.2014.01.004
   Curtis S., 2016, Collect. Dyn., V1, P1
   Dewi M., 2011, 2011 2nd International Conference on Instrumentation, Communications, Information Technology, and Biomedical Engineering, P186, DOI 10.1109/ICICI-BME.2011.6108638
   Fata AZA, 2015, J TEKNOL, V75, P7
   Gu Q, 2013, IEEE COMPUT GRAPH, V33, P20, DOI 10.1109/MCG.2011.87
   Haciomeroglu M, 2008, COMPUT ANIMAT VIRT W, V19, P307, DOI 10.1002/cav.232
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Herr CM, 2011, PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON COMPUTER-AIDED ARCHITECTURAL DESIGN RESEARCH IN ASIA (CAADRIA 2011), P1
   Hoogendoorn SP, 2015, TRANSPORT RES C-EMER, V59, P183, DOI 10.1016/j.trc.2015.05.003
   Ju E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866162
   Kim S, 2015, VISUAL COMPUT, V31, P541, DOI 10.1007/s00371-014-0946-1
   Kneidl A, 2013, TRANSPORT RES C-EMER, V37, P223, DOI 10.1016/j.trc.2013.03.005
   Kwon T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360679
   Lemercier S, 2012, COMPUT GRAPH FORUM, V31, P489, DOI 10.1111/j.1467-8659.2012.03028.x
   Lemercier S, 2016, CONTEXT AWARE HUMAN, P257, DOI [10.1007/978-3-319-19947-4_12, DOI 10.1007/978-3-319-19947-4_12]
   Lerner A, 2009, LECT NOTES COMPUT SC, V5884, P75, DOI 10.1007/978-3-642-10347-6_7
   Moussaïd M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047
   Nasution KhooSalma., 2006, MORE MERCHANTS HIST
   Navarro L, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS'15), P1939
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   ONeill Rob, 2015, DIGITAL CHARACTER DE
   Patil S, 2011, IEEE T VIS COMPUT GR, V17, P244, DOI 10.1109/TVCG.2010.33
   Pianini D, 2014, 2014 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P460, DOI 10.1109/HPCSim.2014.6903721
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Rodriguez S, 2011, IEEE INT CONF ROBOT, P1738
   Sakellariou Ilias, 2012, Proceedings of the SIMULTECH 2012. 2nd International Conference on Simulation and Modeling Methodologies, Technologies and Applications, P270
   Shao W., 2005, SCA 05 P 2005 ACM SI, P19, DOI DOI 10.1145/1073368.1073371
   Shiffman D., 2012, The Nature of Code
   Silveira R, 2010, VISUAL COMPUT, V26, P1183, DOI 10.1007/s00371-009-0399-0
   Singh S, 2009, COMPUT ANIMAT VIRT W, V20, P533, DOI 10.1002/cav.277
   Sun NP, 2014, 2014 NINTH INTERNATIONAL CONFERENCE ON BROADBAND AND WIRELESS COMPUTING, COMMUNICATION AND APPLICATIONS (BWCCA), P491, DOI 10.1109/BWCCA.2014.106
   Sung M, 2004, COMPUT GRAPH FORUM, V23, P519, DOI 10.1111/j.1467-8659.2004.00783.x
   Takahashi S, 2009, COMPUT GRAPH FORUM, V28, P639, DOI 10.1111/j.1467-8659.2009.01404.x
   Thalmann Daniel, 2014, 3D Research Challenges in Cultural Heritage. A Roadmap in Digital Heritage Preservation: LNCS 8355, P78, DOI 10.1007/978-3-662-44630-0_6
   Thalmann N.M., 1995, COMPUTER GRAPHICS DE, P281
   Ulicny B, 2001, SPRING EUROGRAP, P163
   Ulicny Branislav, 2004, SCA'04'- Proc. of the 2004 ACM SIGGRAPH/Eurographics symposium on Computer animation, P243, DOI [DOI 10.2312/SCA/SCA04/243-252, 10.1145/1028523.1028555, DOI 10.1145/1028523.1028555]
   Wang SX, 2015, SIMUL-T SOC MOD SIM, V91, P71, DOI 10.1177/0037549714562994
   Wang XT, 2014, INT C DIGITAL HOME, P347, DOI 10.1109/ICDH.2014.72
   Xu ML, 2015, NEUROCOMPUTING, V168, P529, DOI 10.1016/j.neucom.2015.05.074
   Zhang P, 2015, VISUAL COMPUT, V31, P5, DOI 10.1007/s00371-013-0900-7
   Zheng YH, 2016, INT CONF COMP SCI ED, P821, DOI 10.1109/ICCSE.2016.7581688
   Zhi XY, 2014, INTERNATIONAL CONFERENCE ON SOCIAL, EDUCATION AND MANAGEMENT ENGINEERING (SEME 2014), P89
   Zhong JH, 2015, J COMPUT SCI-NETH, V6, P11, DOI 10.1016/j.jocs.2014.09.002
NR 67
TC 13
Z9 13
U1 3
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3387
EP 3423
DI 10.1007/s11042-019-07925-2
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700016
DA 2024-07-18
ER

PT J
AU Sakthivelan, RG
   Rjendran, P
   Thangavel, M
AF Sakthivelan, R. G.
   Rjendran, P.
   Thangavel, M.
TI RETRACTED: A video analysis on user feedback based recommendation using
   A-FP hybrid algorithm (Retracted article. See vol. 82, pg. 15923, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE A-FP hybrid algorithm; Event based recommender system; Relevance
   feedback
ID RELEVANCE FEEDBACK; IMAGE RETRIEVAL
AB Video mining is an unsupervised finding of pattern in audio-visual content and also offers the optimized search based on event of interest associated to the target search over the search engine. Video mining is dawn related to other mining. Yet, the objective of existing search is to fetch a specific video from large database. Hence, our proposed goal is to retrieving of user's requisite video based on an event is the major core problem in video mining. This paper propounds a new feedback relevance based video retrieval uses a hybrid of Apriori and Frequent Pattern (A-FP) algorithm creates a new methodology that gives the design of the learning. The A-FP algorithm desire to elicitation the most frequent item search which is pragmatic to the user. It also affords scalable solution for generalizing efficient and highly ambiguous user expected video search.
C1 [Sakthivelan, R. G.] AVS Engn Coll, Salem, Tamil Nadu, India.
   [Rjendran, P.] Knowledge Inst Technol, Dept Comp Sci & Engn, Salem, India.
   [Thangavel, M.] Knowledge Inst Technol, Elect & Commun Engn Dept, Salem, India.
RP Sakthivelan, RG (corresponding author), AVS Engn Coll, Salem, Tamil Nadu, India.
EM sakthi21245@gmail.com
CR [Anonymous], 2015, DIABETES CARE, V38, pS1, DOI 10.2337/dc15-S001
   [Anonymous], PERSONALIZATION USER
   [Anonymous], HYBRID ALGORITHM USI
   [Anonymous], INFORM MED UNLOCKED
   [Anonymous], PERSONAL UBIQUITOUS
   [Anonymous], IEEE INT C ADV COMP
   [Anonymous], INT J SCI RES PUBLIC
   [Anonymous], 158113844X040005 ACM
   [Anonymous], RELEVANCE FEEDBACK T
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2018, DES AUTOM EMBED SYST
   [Anonymous], INT J COMPUT APPL
   [Anonymous], INF SCI LETT
   Bhatt S, 2014, FRONT PEDIATR, V2, DOI 10.3389/fped.2014.00113
   Chandra I, 2019, CLUSTER COMPUT, V22, P2517, DOI 10.1007/s10586-018-2329-2
   He XF, 2003, IEEE T CIRC SYST VID, V13, P39, DOI 10.1109/TCSVT.2002.808087
   Jiang L, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P27, DOI 10.1145/2671188.2749399
   Kanisha B., 2018, PERS UBIQUIT COMPUT, V22, P1
   Kumar PM, 2018, COMPUT NETW, V144, P154, DOI 10.1016/j.comnet.2018.07.001
   Kumar PM, 2018, FUTURE GENER COMP SY, V86, P527, DOI 10.1016/j.future.2018.04.036
   Parthasarathy Panchatchram, 2018, World Review of Science, Technology and Sustainable Development, V14, P52
   Parthasarathy P, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0058-9
   Rishwana SS, 2018, RIV PUB S POL SCI, P1
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621
   Su Z, 2003, IEEE T IMAGE PROCESS, V12, P924, DOI 10.1109/TIP.2003.815254
   Sundarasekar R, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1093-4
   Wang Y, 2016, INT CONF SIGN PROCES, P969, DOI 10.1109/ICSP.2016.7877974
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 29
TC 5
Z9 6
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3847
EP 3859
DI 10.1007/s11042-019-7293-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700041
DA 2024-07-18
ER

PT J
AU Ya-ting, X
   Chen, YJ
   Jiang, M
AF Ya-ting, X.
   Chen, Yao-jie
   Jiang, Min
TI Geometric calibration based on B-spline with multi-parameter and color
   correction based on transition template and decay function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE B-spline; Shape parameter; Color correction; Brightness decay
AB To achieve low-cost and fast multi-channel surface projection geometric correction, the quadratic quasi-uniform B-spline surface is used to reconstruct the deformation screen, and the coordinates of the boundary mesh node are calculated as the texture mapping vertex coordinates by adjusting the position of the control point. On the DirectX platform, the main desktop image is obtained through frame buffer copy, by adjusting the shape parameters and moving the control points as a whole, the multi-projection screen is corrected and the coordinates are saved to realize the surface reconstruction. Compared with the no-parameter curve, by adding a plurality of shape parameters, the distance and the relationship between the control point and the curve are more precisely adjusted, and better correction can be realized. Then, feature image projection is performed between adjacent channels, and the color template is calculated according to the collected color information to apply to a video frame of one channel, thereby eliminating chromatic aberration caused by different projector lamp problems. Finally, a smooth luminance decay function is used to attenuate the highlights appearing in overlapping areas between adjacent channels. The experimental results of the two-channel stereoscopic projection system show that the method is simple and highly efficient, and it has lower requirements for equipment, which is easy to operate in the adjustment process, and has strong adaptability to the engineering environment.
C1 [Ya-ting, X.; Chen, Yao-jie; Jiang, Min] Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan, Peoples R China.
   [Ya-ting, X.; Chen, Yao-jie] Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Peoples R China.
   [Chen, Yao-jie] Wuhan Univ Technol, Coll Shipping, Wuhan, Peoples R China.
   [Jiang, Min] Portland State Univ, Dept Comp Sci, Portland, OR 97207 USA.
C3 Wuhan University of Science & Technology; Wuhan University of
   Technology; Portland State University
RP Ya-ting, X (corresponding author), Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan, Peoples R China.; Ya-ting, X (corresponding author), Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Peoples R China.
EM 1132595344@qq.com
RI JIANG, MIN/KSM-4856-2024
OI Xue, Yating/0000-0002-7669-2029
CR Bhasker EzekielS., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Brown M, 2005, IEEE T VIS COMPUT GR, V11, P193, DOI 10.1109/TVCG.2005.27
   Chao Li, 2004, Proceedings. Third International Conference on Image and Graphics, P452
   Chen H, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P339, DOI 10.1109/VISUAL.2002.1183793
   Chen XQ, 2015, COMPUTER SYSTEMS APP, V24, P32
   Chen Y, 2000, VIS P, V2000, P18
   Chuang YM, 2011, C IND ELECT APPL, P626, DOI 10.1109/ICIEA.2011.5975661
   Ebert A, 2010, IEEE T VIS COMPUT GR, V16, P120, DOI 10.1109/TVCG.2009.57
   Feng L, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P224, DOI 10.1109/ICICISYS.2009.5357709
   Johnson T, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P35, DOI 10.1109/VR.2009.4810996
   Jung H, 2006, INT C PATT REC ICPR, V25, P24, DOI [10.1109/ICPR.2006.417, DOI 10.1109/ICPR.2006.417]
   Leigh J, 2013, P IEEE, V101, P115, DOI 10.1109/JPROC.2012.2191609
   Li SJ, 2014, J COMPUT APPL, P246
   Luo Jian-li, 2010, Acta Electronica Sinica, V38, P1729
   Majumder A, 2004, IEEE T VIS COMPUT GR, V10, P177, DOI 10.1109/TVCG.2004.1260769
   Majumder A, 2013, COMPUTER, V46, P26, DOI 10.1109/MC.2012.429
   Moriya T, 2007, INT C MULTIMEDIA MOD, P265
   Niski K, 2007, IEEE T VIS COMPUT GR, V13, P1352, DOI 10.1109/TVCG.2007.70587
   Ogata M, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P235, DOI 10.1109/VR.2009.4811032
   Okatani T, 2003, IEEE INT C COMP VIS, P125
   Park S, 2015, 2015 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P65, DOI 10.1109/SciVis.2015.7429493
   Raij A, 2004, INT C PATT RECOG, P14, DOI 10.1109/ICPR.2004.1333994
   Raskar R, 2002, IEEE C COMP VIS, P114
   Roman P, 2010, IEEE T VIS COMPUT GR, V16, P1623, DOI 10.1109/TVCG.2010.128
   Saini D, 2017, J KING SAUD UNIV-COM, V29, P116, DOI 10.1016/j.jksuci.2014.12.010
   Sajadi B, 2012, IEEE T VIS COMPUT GR, V18, P381, DOI 10.1109/TVCG.2011.271
   Sajadi B, 2009, IEEE T VIS COMPUT GR, V15, P1307, DOI 10.1109/TVCG.2009.166
   Schollmeyer A, 2018, IEEE T VIS COMPUT GR, P1
   Wallace G, 2005, IEEE COMPUT GRAPH, V25, P24, DOI 10.1109/MCG.2005.89
   Wang Sheng-zheng, 2008, Journal of Shanghai Jiaotong University, V42, P574
   Wang Xiu-Hui, 2007, Journal of Software, V18, P2955, DOI 10.1360/jos182955
   Wang Xiuhui, 2008, Journal of Computer Aided Design & Computer Graphics, V20, P707
   Wu J, 2017, 2017 10 INT C IMAGE, P1, DOI DOI 10.1109/CISP-BMEI.2017.8301945
   Xia MH, 2017, IEEE INT CONF COMP V, P2977, DOI 10.1109/ICCVW.2017.351
   Ya-Hui L, 2009, 2009 INTERNATIONAL ASIA CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION, AND ROBOTICS, PROCEEDINGS, P450, DOI 10.1109/CAR.2009.55
   Zhao Meng, 2008, Journal of Computer Aided Design & Computer Graphics, V20, P1366
   Zhao MR, 2017, Multi-channel projection fusion with color automatic balance control method, Patent No. [CN 106559658, 106559658]
   Zhao Z, 2018, RES COLOR CORRECTION, P699
   Zhou Q, 2017, P IEEE VIRT REAL ANN, P455, DOI 10.1109/VR.2017.7892376
   Zhou Yan-xia, 2011, Journal of Computer Applications, V31, P65, DOI 10.3724/SP.J.1087.2011.00065
   Zijian Song, 2010, 2010 International Conference on Computer Application and System Modeling (ICCASM 2010), P349, DOI 10.1109/ICCASM.2010.5620133
NR 41
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4333
EP 4346
DI 10.1007/s11042-018-6930-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500006
DA 2024-07-18
ER

PT J
AU Sendhil, A
   Muthukkumaran, K
   Punniyamoorthy, M
   Veerapandian, SA
   Sangeetha, G
AF Sendhil, Anu
   Muthukkumaran, K.
   Punniyamoorthy, M.
   Veerapandian, S. A.
   Sangeetha, G.
TI Deciphering the frozen music in building architecture and vice-versa
   process
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music; Architecture; Grid-based logic; Deciphering; Aural parameters
ID GRAPH
AB Efforts to discover the logic of unfreezing the music in architecture started with Vitruvius (80-15 BC) and were continued in the modern era by Iannis Xenakis, among many others. Through these efforts, a process for unfreezing the architecture in music has gradually been constructed. Initially, rhythm, texture, harmony, geometry, proportion and dynamics were considered as the basis of complimentary aural and visual formats used to evolve aural parameters and their corresponding visual parameters. These parameters, which are involved in both visual (architecture) and aural (music) formats form the logic used to decipher music from architecture and vice versa. Using scaled axes as a basis for both aural and visual parameters, a comparison emerged. Thus, aural parameters can be extracted from a grid (the visual parameters in the axes) to compose music as well as the reverse process-visual parameters can be extracted from the grid (the aural parameters in the axes) to arrive at an architectural design. This approach resulted in the development of logic.
C1 [Sendhil, Anu; Muthukkumaran, K.; Veerapandian, S. A.] Natl Inst Technol, Dept Civil Engn, Tiruchirappalli 620015, Tamil Nadu, India.
   [Punniyamoorthy, M.] Natl Inst Technol, Dept Management Studies, Tiruchirappalli 620015, Tamil Nadu, India.
   [Sangeetha, G.] Natl Inst Technol, Dept Architecture, Tiruchirappalli 620015, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; National Institute of Technology (NIT
   System); National Institute of Technology Tiruchirappalli; National
   Institute of Technology (NIT System); National Institute of Technology
   Tiruchirappalli
RP Punniyamoorthy, M (corresponding author), Natl Inst Technol, Dept Management Studies, Tiruchirappalli 620015, Tamil Nadu, India.
EM punniya@nitt.edu
RI Muthukkumaran, Kasinathan/AAM-5562-2020; Ganesan,
   Sangeetha/HOH-6833-2023; M, punniyamoorthy/IZE-0883-2023; M,
   punniyamoorthy/AAO-9180-2020
OI Muthukkumaran, Kasinathan/0000-0002-7664-7068; Ganesan,
   Sangeetha/0000-0001-7347-2162; , Dr M Punniyamoorthy/0000-0003-0053-7740
CR Aucouturier JJ, 2003, J NEW MUSIC RES, V32, P83, DOI 10.1076/jnmr.32.1.83.16801
   Brady D, 1994, THE ART BOOK, V1, P27, DOI [10.1111/J.1467-8357.1994.Tb00212.X, DOI 10.1111/J.1467-8357.1994.TB00212.X]
   Burkat L, 1944, NOTES, V2, P54, DOI [10.2307/891024, DOI 10.2307/891024]
   Cameron J, 1998, MED PHYS, V25, P256, DOI [10.1118/1.598190, DOI 10.1118/1.598190]
   Chan CS, 2012, FRONT ARCHIT RES, V1, P253, DOI 10.1016/j.foar.2012.06.003
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Ching FrancisD.K., 2007, Architecture: Form, Space, and Order
   Dabbour LM, 2012, FRONT ARCHIT RES, V1, P380, DOI 10.1016/j.foar.2012.08.005
   Duckworth W, 2007, CREATIVE APPROACH MU
   Han BJ, 2010, MULTIMED TOOLS APPL, V47, P433, DOI 10.1007/s11042-009-0332-6
   Hsu JL, 2015, MULTIMED TOOLS APPL, V74, P5401, DOI 10.1007/s11042-014-1860-2
   JENCKS Charles., 2013, The Architectural Review
   Kamien Roger., 2011, Music: An Appreciation, V10th
   Kappraff J, 1999, VISUAL MATH, V1
   Katarya R, 2018, MULTIMED TOOLS APPL, V77, P2673, DOI 10.1007/s11042-017-4447-x
   Khalil KF, 2013, INT J SCI RES PUBL, V3
   Kiliçaslan H, 2012, PROCD SOC BEHV, V51, P635, DOI 10.1016/j.sbspro.2012.08.215
   Knott R, 2009, FIBONACCI NUMBERS GO
   Leopold C, 2006, NEXUS NETW J, V8, P123, DOI [10.1007/S00004-006-0012-Z, DOI 10.1007/S00004-006-0012-Z]
   Morgan D, 2010, CHURCH HIST, V79, P922, DOI 10.1017/S0009640710001241
   Muecke MikeschW., 2007, ESSAYS INTERSECTION
   Riad MM, 2009, CHRONICLES, P69
   Ripley Colin., 2007, In the place of sound: architecture, music, acoustics
   Samuel Flora., 2007, CORBUSIER DETAIL
   Sharma V, 2016, INT J ENG APPL SCI T, V2, P62
   Shen JL, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1508850.1508856
   Sterk H., 2005, Geometry in architecture and building
   Sterken Sven., 2001, PERSPECT NEW MUSIC, V39, P262
   Tolonen T, 2000, IEEE T SPEECH AUDI P, V8, P708, DOI 10.1109/89.876309
   Trachtenberg M, 2001, RENAISSANCE QUART, V54, P740, DOI 10.2307/1261923
   Veerapandian SA, 2010, WORLD CLASS TAM C, P161
   Vouzounaras G, 2014, MULTIMED TOOLS APPL, V70, P361, DOI 10.1007/s11042-011-0823-0
   Wittkower Rudolf., 1937, Art Bulletin, V19, P242, DOI [10.1080/00043079.1937.11409151, DOI 10.1080/00043079.1937.11409151]
   Xu Z, 2016, MULTIMED TOOLS APPL, V75, P17421, DOI 10.1007/s11042-016-4104-9
NR 34
TC 1
Z9 1
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13501
EP 13532
DI 10.1007/s11042-019-08316-3
EA JAN 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000510281800002
DA 2024-07-18
ER

PT J
AU Sun, YH
   Hu, JG
   Shi, JL
   Sun, ZX
AF Sun, Yunhan
   Hu, Jiagao
   Shi, Jinlong
   Sun, Zhengxing
TI Progressive decomposition: a method of coarse-to-fine image parsing
   using stacked networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image parsing; coarse-to-fine decomposition; Stacked networks;
   Progressive supervision
ID SEGMENTATION
AB To parse images into fine-grained semantic parts, the complex elements will put it in trouble when using off-the-shelf semantic segmentation networks, because it is difficult for them to utilize the contextual information of fine-grained parts. In this paper we propose a progressive decomposition method to parse images in a coarse-to-fine manner with refined semantic classes. It consists of two aspects: stacked networks and progressive supervisions. The stacked network is achieved by stacking some segmentation layers in a segmentation network. The former segmentation module parses images at a coarser-grained level, and the result will be fed to the following one to provide effective contextual clues for the finer-grained parsing. The skip connections from shallow layers of the network to fine-grained parsing modules are also added to recover the details of small structures. For the training of the stacked networks which have coarse-to-fine outputs, a strategy of progressive supervision is proposed to merge classes in ground truth to get coarse-to-fine label maps, and then train the stacked network end-to-end with the hierarchical supervisions. The proposed framework can be injected into many advanced neural networks to improve the parsing results. Extensive evaluations on several public datasets including face parsing and human parsing well demonstrate the superiority of our method.
C1 [Sun, Yunhan; Shi, Jinlong] Jiangsu Univ Sci & Technol, Sch Comp Sci & Engn, Zhenjiang 212003, Jiangsu, Peoples R China.
   [Hu, Jiagao; Sun, Zhengxing] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210046, Peoples R China.
C3 Jiangsu University of Science & Technology; Nanjing University
RP Shi, JL (corresponding author), Jiangsu Univ Sci & Technol, Sch Comp Sci & Engn, Zhenjiang 212003, Jiangsu, Peoples R China.; Sun, ZX (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210046, Peoples R China.
EM jacksunyh@vip.qq.com; njumagic@nju.edu.cn; jlshifudan@gmail.com;
   szx@nju.edu.cn
RI Sun, YunHan/AAD-7898-2020; shi, jin/GQZ-1206-2022; shi,
   jin/KDO-7906-2024; Sun, Zhengxing/A-7411-2011; shi, jin/JCD-8826-2023;
   Shi, JIn/JYP-1805-2024
OI sun, yunhan/0000-0001-5264-7007
FU National Natural Science Foundation of China [61321491, 61272219];
   National High Technology Research and Development Program of China
   [2007AA01Z334]; National Key Research and, Program for New Century
   Excellent Talents in University of China [NCET-04-04605]; China
   Postdoctoral Science Foundation [2017M621700]; Innovation Fund of State
   Key Laboratory for Novel Software Technology [ZZKT2013A12, ZZKT2016A11,
   ZZKT2018A09];  [2018YFC0309100];  [2018YFC0309104]
FX This work was supported by Development Program of China (Nos.
   2018YFC0309100 and 2018YFC0309104), National Natural Science Foundation
   of China (Nos. 61321491 and 61272219), National High Technology Research
   and Development Program of China (No. 2007AA01Z334), National Key
   Research and, Program for New Century Excellent Talents in University of
   China (NCET-04-04605), the China Postdoctoral Science Foundation (Grant
   No. 2017M621700) and Innovation Fund of State Key Laboratory for Novel
   Software Technology (Nos. ZZKT2013A12, ZZKT2016A11 and ZZKT2018A09).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.348
   [Anonymous], 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298642
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Fu J, 2017, IEEE IMAGE PROC, P3085, DOI 10.1109/ICIP.2017.8296850
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   Hu JH, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351575
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li ZX, 2017, IEEE INT CON MULTI, P307, DOI 10.1109/ICME.2017.8019363
   Liang XD, 2016, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2016.347
   Liang XD, 2016, IEEE T MULTIMEDIA, V18, P1175, DOI 10.1109/TMM.2016.2542983
   Liang XD, 2015, IEEE I CONF COMP VIS, P1386, DOI 10.1109/ICCV.2015.163
   Liang XD, 2015, IEEE T PATTERN ANAL, V37, P2402, DOI 10.1109/TPAMI.2015.2408360
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   LIU S, 2015, PROC CVPR IEEE, P1419, DOI DOI 10.1109/CVPR.2015.7298748
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo P, 2012, PROC CVPR IEEE, P2480, DOI 10.1109/CVPR.2012.6247963
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Porway J, 2010, INT J COMPUT VISION, V88, P254, DOI 10.1007/s11263-009-0306-1
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smith BM, 2013, PROC CVPR IEEE, P3484, DOI 10.1109/CVPR.2013.447
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Xu ZJ, 2008, IEEE T PATTERN ANAL, V30, P955, DOI 10.1109/TPAMI.2008.50
   Yang KW, 2018, MULTIMED TOOLS APPL, V77, P12259, DOI 10.1007/s11042-017-4882-8
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang YZ, 2016, IEEE INT C BIOINFORM, P443, DOI 10.1109/BIBM.2016.7822557
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
NR 37
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13379
EP 13402
DI 10.1007/s11042-019-08288-4
EA JAN 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000510091500003
DA 2024-07-18
ER

PT J
AU Rasipuram, S
   Jayagopi, DB
AF Rasipuram, Sowmya
   Jayagopi, Dinesh Babu
TI Automatic multimodal assessment of soft skills in social interactions: a
   review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Automatic assessment; Interface-based interviews; Face-to-face
   interviews; Group conversations; Perceptual computing; Machine learning
ID THIN SLICES; EMERGENT LEADERS; PERSONALITY; DOMINANCE; SPEAKING;
   VIDEOCONFERENCE; INTERVIEW; BEHAVIOR
AB Automatic assessment of soft skills is an interesting problem in social computing. Soft skills are essential to any individual for personal and career development. Soft skills assessment includes Big Five personality, social and communication skill and leadership skill can now be enabled using behavior tracking and mapping behavior to perception. Such assessments can be used for manpower selection and training. This paper reviews the existing literature on automatic analysis of social interactions for soft skill assessment in different contexts. A variety of social situations offline and online methods are considered for assessment. Offline methods include traditional forms of discussion without any technology mediation. Online methods utilize technology for scalability and alleviate the assessment process without collocation of multiple parties. We address some of the challenges that are still open in the field.
C1 [Rasipuram, Sowmya; Jayagopi, Dinesh Babu] Int Inst Informat Technol, Bangalore, Karnataka, India.
C3 International Institute of Information Technology Bangalore (IIIT
   Bangalore)
RP Rasipuram, S (corresponding author), Int Inst Informat Technol, Bangalore, Karnataka, India.
EM sowmya.r@iiitb.org; jdinesh@iiitb.ac.in
RI Jayagopi, Dinesh Babu/ABE-2546-2021
OI Jayagopi, Dinesh Babu/0000-0003-0080-452X
FU SERB [YSS2015001074]
FX This work was funded by SERB Young Scientist grant of Dr. Jayagopi
   (Grant No. YSS2015001074).
CR Ali MR, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT), P325, DOI 10.1145/3123024.3123196
   Allport G.W., 1968, The handbook of social psychology, V2nd
   AMBADY N, 1992, PSYCHOL BULL, V111, P256, DOI 10.1037/0033-2909.111.2.256
   Anderson Keith, 2013, Advances in Computer Entertainment. 10th International Conference, ACE 2013. Proceedings: LNCS 8253, P476, DOI 10.1007/978-3-319-03161-3_35
   [Anonymous], 2003, VIDEO INTERVIEWING S
   [Anonymous], 2008, P 10 INT C MULT INT
   [Anonymous], 2016, P IEEE WINT C APPL C
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2013, NONVERBAL COMMUNICAT
   [Anonymous], 2013, 2013 10 IEEE INT C W, DOI [10.1109/FG.2013.6553805, DOI 10.1109/FG.2013.6553805]
   [Anonymous], 1993, LEADERSHIP Q, DOI DOI 10.1016/1048-9843(93)90003-C
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], 2015, TEAM ACCELERATION SO
   Aran O., 2010, PROC INT CONF PATT R, P3687
   Azaïs L, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2519
   Batrinca L, 2011, P 13 INT C MULT INT, P255, DOI [DOI 10.1145/2070481.2070528, 10.1145/2070481.2070528]
   Beyan C, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1425, DOI 10.1145/3123266.3123404
   Beyan C, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P317, DOI 10.1145/2993148.2993175
   Biel JI, 2013, IEEE T MULTIMEDIA, V15, P41, DOI 10.1109/TMM.2012.2225032
   Blacksmith N., 2016, Personnel Assessment and Decisions, V2
   Boersma P., 2018, Praat: doing phonetics by computer, DOI DOI 10.1097/AUD.0B013E31821473F7
   Borkenau P, 2004, J PERS SOC PSYCHOL, V86, P599, DOI 10.1037/0022-3514.86.4.599
   Brenner FS, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00863
   Callejas Z, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P93
   Cappella J.N., 1985, MULTICHANNEL INTEGRA, P69
   Carney DR, 2007, J RES PERS, V41, P1054, DOI 10.1016/j.jrp.2007.01.004
   Celiktutan O., 2017, IEEE T AFFECTIVE COM
   Çeliktutan O, 2017, IEEE T AFFECT COMPUT, V8, P29, DOI 10.1109/TAFFC.2015.2513401
   Cepero A, 2013, CCIA, P105
   Chapman DS, 2001, J OCCUP ORGAN PSYCH, V74, P279, DOI 10.1348/096317901167361
   Chen L, 2017, INT CONF AFFECT, P504, DOI 10.1109/ACII.2017.8273646
   Chen L, 2016, INTERSPEECH, P32, DOI 10.21437/Interspeech.2016-1453
   Chen L, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P161, DOI 10.1145/2993148.2993203
   Chen L, 2015, INT CONF AFFECT, P394, DOI 10.1109/ACII.2015.7344601
   Chen L, 2006, WCICA 2006: SIXTH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-12, CONFERENCE PROCEEDINGS, P36
   Chen L, 2014, INT IMMUNOPHARMACOL, V18, P20, DOI 10.1016/j.intimp.2013.11.002
   Cheng LC, 2016, PROCEEDINGS OF CHIUXID 2016: BRIDGING THE GAPS IN THE HCI & UX WORLD, P1, DOI 10.1145/2898459.2898460
   Chollet M., 2016, LREC
   Chollet M, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P1, DOI 10.1145/3267851.3267874
   Chollet M, 2017, IEEE INT CONF AUTOMA, P310, DOI 10.1109/FG.2017.45
   Curhan JR, 2007, J APPL PSYCHOL, V92, P802, DOI 10.1037/0021-9010.92.3.802
   DeGroot T, 2009, J BUS PSYCHOL, V24, P179, DOI 10.1007/s10869-009-9098-0
   Dunbar NE, 2005, J SOC PERS RELAT, V22, P207, DOI 10.1177/0265407505050944
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI DOI 10.1145/2502081.2502224
   Forgas JP, 1985, INTRAPERSONAL BEHAV
   Fung M, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P1167, DOI 10.1145/2750858.2804265
   Gatica-Perez D, 2009, IMAGE VISION COMPUT, V27, P1775, DOI 10.1016/j.imavis.2009.01.004
   Goodstein LD, 1999, J BUS PSYCHOL, V13, P291, DOI 10.1023/A:1022941331649
   Guchait P, 2014, INT J HOSP MANAG, V36, P90, DOI 10.1016/j.ijhm.2013.08.004
   Hilbert F, 2012, ELECTRON P THEOR COM, P1, DOI 10.4204/EPTCS.83.1
   Hoque M, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P697
   Huffcutt AI, 2001, J APPL PSYCHOL, V86, P897, DOI 10.1037//0021-9010.86.5.897
   Hung H., 2007, P ACM MULTIMEDIA, P835
   Hung H, 2008, INT CONF ACOUST SPEE, P2197, DOI 10.1109/ICASSP.2008.4518080
   Hung Hayley., 2008, P OF THE 10 INT C ON, P233, DOI DOI 10.1145/1452392.1452441
   Hung SW, 2008, IN C IND ENG ENG MAN, P1, DOI 10.1109/IEEM.2008.4737821
   Jayagopi D, 2008, P ACM INT C MULT VAN
   Jayagopi DB, 2009, IEEE T AUDIO SPEECH, V17, P501, DOI 10.1109/TASL.2008.2008238
   Joe J., 2015, ETS Research Report Series, V2, P1, DOI [10.1002/ets2.12083, DOI 10.1002/ETS2.120832015]
   Joshi J, 2014, INT C PATT RECOG, P2855, DOI 10.1109/ICPR.2014.492
   Jovanovic N., 2006, 11 C EUR CHAPT ASS C
   Junior Julio, 2018, ARXIV180408046
   Khan SM, 2017, PRACT TRACK P
   Kickul J, 2000, J BUS PSYCHOL, V15, P27, DOI 10.1023/A:1007714801558
   Kindiroglu AA, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0224-z
   Kurihara K, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P358
   Nguyen LS, 2014, IEEE T MULTIMEDIA, V16, P1018, DOI 10.1109/TMM.2014.2307169
   Leary MR, 2011, J PERS, V79, P889, DOI 10.1111/j.1467-6494.2010.00704.x
   Littlewort G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P298, DOI 10.1109/FG.2011.5771414
   Manoharan P. K., 2008, ED PERSONALITY DEV
   Mast MS, 2002, HUM COMMUN RES, V28, P420, DOI 10.1111/j.1468-2958.2002.tb00814.x
   Mohammadi G, 2012, TECHNICAL REPORT
   Morency LP, 2010, IEEE SIGNAL PROC MAG, V27, P112, DOI 10.1109/MSP.2010.937500
   Muralidhar S, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P84, DOI 10.1145/2993148.2993191
   Naim Iftekhar, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163127
   Nguyen Anh-Tuan., 2012, 2012 IEEE S E LEARNI, P1
   Nguyen LS, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P51, DOI 10.1145/2818346.2820760
   Nguyen LS, 2016, IEEE T MULTIMEDIA, V18, P1422, DOI 10.1109/TMM.2016.2557058
   Nitonde R, 2015, S ASIAN ACAD RES CHR, P5
   Nojavanasghari B, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P284, DOI 10.1145/2993148.2993176
   Okada S, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P169, DOI 10.1145/2993148.2993154
   Okada S, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P15, DOI 10.1145/2818346.2820757
   Park S, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P19
   Paso T, 2015, INT SYM MED INFORM, P10, DOI 10.1109/ISMICT.2015.7107487
   Pull CB, 2012, CURR OPIN PSYCHIATR, V25, P32, DOI 10.1097/YCO.0b013e32834e06dc
   Ramanarayanan V, 2015, 16 ANN C INT SPEECH
   Rao S. B. P., 2017, ICMI, P221
   Rasipuram S, 2018, MULTIMED TOOLS APPL, V77, P18709, DOI 10.1007/s11042-018-5654-9
   Rasipuram S, 2017, INT CONF AFFECT, P68, DOI 10.1109/ACIIW.2017.8272588
   Rasipuram S, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P370, DOI 10.1145/2993148.2993183
   Rasipuram S, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574733
   Rienks R, 2005, LECT NOTES COMPUT SC, V3869, P76
   Ru Zhao, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3090097
   Sabouret N, 2014, ARXIV14025045
   Samrose Samiha, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3161186
   Sanchez-Cortes D., 2010, International Conference on Multimodal Interfaces and the Workshop on Machine Learning for Multimodal Interaction (New York, NY, USA, 2010), p39:1, DOI DOI 10.1145/1891903.1891953
   Sanchez-Cortes D, 2015, ACM T INTERACT INTEL, V5, DOI 10.1145/2641577
   Sanchez-Cortes D, 2013, J MULTIMODAL USER IN, V7, P39, DOI 10.1007/s12193-012-0101-0
   Sanchez-Cortes D, 2012, IEEE T MULTIMEDIA, V14, P816, DOI 10.1109/TMM.2011.2181941
   Scherer S, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1114
   Sears GJ, 2013, MANAGE DECIS, V51, P1733, DOI 10.1108/MD-09-2012-0642
   Sellen A. J., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P49, DOI 10.1145/142750.142756
   Spitzberg B.H., 2007, CSRS: The conversational skills rating scale-An instructional assessment of interpersonal competence, V2nd
   STEIN RT, 1975, J PERS SOC PSYCHOL, V32, P125, DOI 10.1037/h0076842
   Stone DL, 2015, HUM RESOUR MANAGE R, V25, P216, DOI 10.1016/j.hrmr.2015.01.002
   Tanaka H, 2017, EMBODIED CONVERSATIO, V12
   Tanveer MI, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P385, DOI 10.1145/2856767.2856785
   Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676
   Toldi N.L., 2011, Employment Relations Today, V38, P19, DOI [10.1002/ert.20351, DOI 10.1002/ERT.20351]
   Vinciarelli A, 2014, IEEE T AFFECT COMPUT, V5, P273, DOI 10.1109/TAFFC.2014.2330816
   Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007
   Wagner Johannes, 2018, ARXIV180202565
   Wörtwein T, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P43, DOI 10.1145/2818346.2820762
   Zancanaro M., 2006, Proceedings of the 8th international conference on Multimodal interfaces, P28
   Zechner K., 2006, P HUMAN TECHNOLOGY C, P216
   Zhang HS, 2010, SPACE SCI EXPLOR POL, P49
NR 116
TC 10
Z9 10
U1 4
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13037
EP 13060
DI 10.1007/s11042-019-08561-6
EA JAN 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000509165900006
DA 2024-07-18
ER

PT J
AU Choi, SH
   Ghil, MS
   Mun, HJ
AF Choi, Shin-Hyeong
   Ghil, Min-Sik
   Mun, Hyung-Jin
TI Development of an ultrasonic wave emission system based on multimedia
   database in a smart farm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IoT; Smart device; Ultrasonic wave; Database; Eco-friendly; Multmedia
ID INTERNET; THINGS
AB Due to the development of the recent ICT (Information and Communication Technology), ICT has been applied to the agriculture and it is improving the productivity and quality of the crop through its utilization. In addition, with the realization of fast networks like 5G, IoT (Internet of Things) technology which can link various things around us has been applied in various aspects of life. Consequently, the services and related markets applying it are expected to grow greatly in the future. On the other hand, in the field of crop cultivation, it was possible to improve productivity by spraying fertilizer or pesticide on crops in the past, but for consumers who seek healthy food, they want to be eco-friendly, and cause no harm to the health of crops. In this paper, we develop an ultrasonic wave emission system based on multimedia database in a smart farm using ICT. Through this, environmental information of crops growing in smart farm is collected by using IoT device and is managed by multimedia database. In addition, by providing an optimal environment through ultrasonic wave emission, we can promote crop growth and suppress diseases and pests. Also, this system stores and manages multimedia data such as temperature, humidity, and ultrasonic waves, and suggests a method of extracting knowledge information for ultrasonic emission based on this. In order to prevent transmission delay time between each component, we also propose optimization methods for database processing. Using the system developed in this paper, it will be possible to make consumers interested in finding healthy food by cultivating more eco-friendly crops.
C1 [Choi, Shin-Hyeong] Kangwon Natl Univ, Div Elect Control & Instrumentat Engn, 346 Jungang Ro, Samcheok Si 25913, Gangwon Do, South Korea.
   [Ghil, Min-Sik] Tobesyst Co Ltd, Samcheok BI Ctr, 346 Jungang Ro, Samcheok Si 25913, Gangwon Do, South Korea.
   [Mun, Hyung-Jin] Sungkyul Univ, Dept Informat & Commun Engn, 53 Sungkyul Unvers Ro, Anyang Si 14097, Gyeonggi Do, South Korea.
C3 Kangwon National University; Sungkyul University
RP Mun, HJ (corresponding author), Sungkyul Univ, Dept Informat & Commun Engn, 53 Sungkyul Unvers Ro, Anyang Si 14097, Gyeonggi Do, South Korea.
EM jinmun@gmail.com
RI Mun, Hyung-Jin/P-3761-2016
OI Mun, Hyung-Jin/0000-0002-9726-8163
CR AlZu'bi S, 2019, MULTIMED TOOLS APPL, V78, P29581, DOI 10.1007/s11042-019-7367-0
   Andrews D, 2014, P 2014 COMSOL C CAMB
   Baral C, 1998, MULTIMED TOOLS APPL, V7, P37, DOI 10.1023/A:1009670119569
   Chowdhury Md. Emran Khan, 2014, [Research in Plant Disease, 식물병 연구], V20, P1, DOI 10.5423/RPD.2014.20.1.001
   Creath K, 2004, J ALTERN COMPLEM MED, V10, P113, DOI 10.1089/107555304322849039
   Gopal B. G., 2015, IOSR Journal of Electronics and Communication Engineering (IOSR-JECE), V10, P67
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Hiratsuka A., 2013, Journal of Water Resource and Protection, V5, P604, DOI 10.4236/jwarp.2013.56061
   Kamilaris A, 2016, 2016 IEEE 3RD WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P442, DOI 10.1109/WF-IoT.2016.7845467
   Kim Yonggyun, 2012, Korean Journal of Applied Entomology, V51, P223, DOI 10.5656/KSAE.2012.05.0.029
   Lim L.J., 2017, INT J SCI ENG TECHNO, V6, P207, DOI [10.5958/2277-1581.2017.00021.3, DOI 10.5958/2277-1581.2017.00021.3]
   Lofqvist T, 1997, 1997 IEEE ULTRASONICS SYMPOSIUM PROCEEDINGS, VOLS 1 & 2, P841, DOI 10.1109/ULTSYM.1997.663144
   Mishra D, 2018, MULTIMED TOOLS APPL, V77, P18295, DOI 10.1007/s11042-017-5376-4
   Park Y, 2019, MULTIMED TOOLS APPL, V78, P28815, DOI 10.1007/s11042-019-7212-5
   Pivoto Dieisson, 2018, Information Processing in Agriculture, V5, P21, DOI 10.1016/j.inpa.2017.12.002
   Prasad S, 2017, MULTIMED TOOLS APPL, V76, P6915, DOI 10.1007/s11042-016-3309-2
   Ramteke A., 2015, INT J CHEM PHYS SCI, V4, P333
   Ray PP, 2017, J AMB INTEL SMART EN, V9, P395, DOI 10.3233/AIS-170440
   Shin J, 2018, PEER PEER NETW APPL, V11, P1166, DOI 10.1007/s12083-017-0606-0
   Shirehjini AAN, 2017, MULTIMED TOOLS APPL, V76, P13343, DOI 10.1007/s11042-016-3697-3
   Wang Yongcheng, 2011, EL MECH ENG INF TECH, V5, P2749
   Zha Yu-Ping, 2012, Journal of Agricultural and Urban Entomology, V28, P34, DOI 10.3954/1523-5475-28.1.34
   Zhang L, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010129
NR 23
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34767
EP 34785
DI 10.1007/s11042-019-08369-4
EA JAN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000574070600002
DA 2024-07-18
ER

PT J
AU Choudhury, P
   Kumar, KRP
   Nandi, S
   Athithan, G
AF Choudhury, Paromita
   Kumar, K. R. Prasanna
   Nandi, Sukumar
   Athithan, G.
TI An empirical approach towards characterization of encrypted and
   unencrypted VoIP traffic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VoIP; Codec; Encryption; Compression; Hamming distance;
   Auto-correlation; Randomness test
ID CLASSIFICATION
AB VoIP traffic classification plays a major role towards network policy enforcements. Characterization of VoIP media traffic is based on codec behaviour. With the introduction of variable bit rate codecs, coding, compression and encryption present different complexities with respect to the classification of VoIP traffic. The randomness tests do not extend directly to classification of compressed and encrypted VoIP traffic. The paper examines the applicability of randomness tests to encrypted and unencrypted VoIP traffic with constant bit rate and variable bit rate codecs. A novel method Construction-by-Selection that constructs a test sequence from partial payload data of VoIP media session is proposed in this paper. The results based on experimentations on this method show that such construction exhibit randomness and hence allows differentiation of encrypted VoIP media traffic from unencrypted VoIP media traffic even in the case of variable bit rate codecs.
C1 [Choudhury, Paromita; Kumar, K. R. Prasanna] DRDO, CAIR, Bangalore, Karnataka, India.
   [Nandi, Sukumar] IIT Guwahati, Dept CSE, Gauhati, India.
   [Athithan, G.] DRDO HQ, Delhi, India.
C3 Defence Research & Development Organisation (DRDO); Center for
   Artificial Intelligence & Robotics (CAIR); Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Guwahati; Defence Research & Development Organisation (DRDO)
RP Choudhury, P (corresponding author), DRDO, CAIR, Bangalore, Karnataka, India.
EM paromitaz@gmail.com; prasanna@cair.drdo.in; sukumar@iitg.ernet.in;
   athithan.g@gmail.com
RI Nandi, Sukumar/AGV-8994-2022
OI Nandi, Sukumar/0000-0002-5869-1057
CR Alshammari R, 2015, J KING SAUD UNIV-COM, V27, P77, DOI 10.1016/j.jksuci.2014.03.013
   Andersen S. V., 2002, P IEEE SPEECH COD WO
   [Anonymous], 1988, INT TELECOMMUN UNION
   [Anonymous], 3951 RFC
   [Anonymous], THESIS
   [Anonymous], 2004, 3711 RFC
   Bassham L.E, 2010, tech. rep.
   Casino F, 2019, IEEE T INF FOREN SEC, V14, P2916, DOI 10.1109/TIFS.2019.2911156
   Chang W, 2010, J COMPUT, V2, P44
   Choudhury P, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P90, DOI 10.1109/ICACCI.2013.6637152
   Dorfinger P, 2011, LECT NOTES COMPUT SC, V6613, P164, DOI 10.1007/978-3-642-20305-3_14
   Freire Emanuel P., 2008, IEEE Transactions on Network and Service Management, V5, P204, DOI 10.1109/TNSM.2009.041102
   Gomes J., 2012, IEEE T PARALLEL DIST, VPP
   HAHN D, 2018, ARXIV180502722
   HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x
   Herlein G., 2009, 5574 RFC
   ITU-T, 1996, G729 INT TEL UN
   Karapantazis S, 2009, COMPUT NETW, V53, P2050, DOI 10.1016/j.comnet.2009.03.010
   Knuth DE, 1969, ART COMUPER PROGRAMM, V2
   Korczynski M, 2014, IEEE INFOCOM SER, P781, DOI 10.1109/INFOCOM.2014.6848005
   Kumano Y, 2014, INT CONF COMPUT NETW, P136, DOI 10.1109/ICCNC.2014.6785319
   LeGrand T, 2013, RTP PAYLOAD FORMAT I
   Li B, 2011, J NETW SYST MANAG, V19, P111, DOI 10.1007/s10922-010-9184-7
   Liu H, 2000, IEEE COMMUN MAG, V38, P142, DOI 10.1109/35.874981
   Loreto S, 2012, IEEE INTERNET COMPUT, V16, P68, DOI 10.1109/MIC.2012.115
   Lotfollahi M, 2020, SOFT COMPUT, V24, P1999, DOI 10.1007/s00500-019-04030-2
   Malhotra P., 2007, DETECTION ENCRYPTED
   Marton K, 2010, ROM J INF SCI TECH, V13, P219
   Ouaissa K, 1996, ANN TELECOMMUN, V51, P595
   Parsons C, 2013, DEEP PACKET INSPECTI
   Penrose P, 2013, DIGIT INVEST, V10, P372, DOI 10.1016/j.diin.2013.08.004
   Schooler E., 2002, 3261 RFC
   Schulzrinne H., 2003, RTP TRANSPORT PROTOC
   Schulzrinne H, 2003, 3551 RFC
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shen M, 2017, IEEE T INF FOREN SEC, V12, P1830, DOI 10.1109/TIFS.2017.2692682
   Soto Jr J., 1999, 6390 NIST IR
   Sun L, 2013, COMPUT COMMUN, DOI [10.1007/978-1-4471-4905-7_2, DOI 10.1007/978-1-4471-4905-7_2]
   Valin J.-M., 2012, Definition of the opus audio codec
   Valin JM, 2006, P LINUX C AUSTR
   Velan P, 2015, INT J NETW MANAG, V25, P355, DOI 10.1002/nem.1901
   Vos K, 2010, SILK SPEECH CODEC DR
   Walker J., PSEUDORANDOM NUMBER
   Zhao B, 2011, IEEE ACM INT C GREEN
NR 44
TC 8
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 603
EP 631
DI 10.1007/s11042-019-08088-w
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600024
DA 2024-07-18
ER

PT J
AU Cao, JM
   Yang, B
   Nan, W
   Wang, H
   Cai, YF
AF Cao, Jinmeng
   Yang, Biao
   Nan, Wang
   Wang, Hai
   Cai, Yingfeng
TI Robust crowd counting based on refined density map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd counting; Multi-task learning; Convolutional neural network;
   Adaptive human-shaped kernel; Weighted loss function
ID PEOPLE
AB Crowd counting has played a substantial role in intelligent surveillance. This work presents a multi-scale multi-task convolutional neural network (MSMT-CNN) to estimate accurate density maps, thus can count the crowd through summing up all values in the estimated density maps. The ground truth density maps used for training are generated by a novel adaptive human-shaped kernel. In addition to resolving the scale problem with the multi-scale strategy, the multi-task learning strategy is added so as to make the estimated density maps more accurate. A weighted loss function is proposed to enhance the activations in dense regions and suppress the background noise. Experimental results on two benchmarking datasets reveal the strong ability of MSMT-CNN. Compared with existing crowd counting methods, the root mean squared error is decreased by 39.8 on the UCF_CC_50 dataset, and the mean absolute error is decreased by 2.3 on the World Expo'10 dataset. Furthermore, the evaluations in practical bus videos verify the practicability of our MSMT-CNN.
C1 [Cao, Jinmeng; Yang, Biao] Changzhou Univ, Coll Informat Sci & Engn, Changzhou 213164, Jiangsu, Peoples R China.
   [Nan, Wang] Ocean Univ China, Coll Informat Sci & Engn, Dept Elect Engn, Qingdao 266100, Shandong, Peoples R China.
   [Wang, Hai] Jiangsu Univ, Sch Automot & Traff Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Cai, Yingfeng] Jiangsu Univ, Engn Res Inst, Zhenjiang 212013, Jiangsu, Peoples R China.
C3 Changzhou University; Ocean University of China; Jiangsu University;
   Jiangsu University
RP Yang, B (corresponding author), Changzhou Univ, Coll Informat Sci & Engn, Changzhou 213164, Jiangsu, Peoples R China.
EM yb6864171@cczu.edu.cn
RI Yan, Jing/JFA-6705-2023
FU National Natural Science Foundation of China [61501060, 61703381,
   61601203, U1762264, U1764257]; National Key Research and Development
   Program of China [2018YFB0105003]
FX This work has been supported by the National Natural Science Foundation
   of China under Grant No. 61501060, No. 61703381, No. 61601203, No.
   U1762264 and No. U1764257, the National Key Research and Development
   Program of China No. 2018YFB0105003.
CR [Anonymous], ARXIV161200220
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2016, ARXIV160200386
   Cao J, 2017, PAC RIM S IM VID TEC, P227
   Chen ML, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-017-9237-1
   Fradi H, 2012, IEEE INT WORKS INFOR, P246, DOI 10.1109/WIFS.2012.6412657
   Gao CQ, 2016, MULTIMED TOOLS APPL, V75, P9315, DOI 10.1007/s11042-016-3344-z
   Hashemzadeh M, 2016, INFORM SCIENCES, V345, P199, DOI 10.1016/j.ins.2016.01.060
   Hu XM, 2013, OPTIK, V124, P5301, DOI 10.1016/j.ijleo.2013.03.057
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Jianjie Yang, 2014, Journal of Multimedia, V9, P1152, DOI 10.4304/jmm.9.10.1152-1159
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liu J., 2017, ARXIV171206679
   Luo J, 2016, SIGNAL PROCESS, V124, P27, DOI 10.1016/j.sigpro.2015.10.036
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   Ryan D, 2015, COMPUT VIS IMAGE UND, V130, P1, DOI 10.1016/j.cviu.2014.07.008
   Sam D. B, 2017, CVPR, V1, P6
   Shang C, 2016, IEEE IMAGE PROC, P1215, DOI 10.1109/ICIP.2016.7532551
   Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550
   Shi ZL, 2018, PROC CVPR IEEE, P5382, DOI 10.1109/CVPR.2018.00564
   Sindagi V. A., 2017, 2017 14 IEEE INT C A, P1
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Wang Q, 2018, IEEE T CIRC SYST VID, V28, P2633, DOI 10.1109/TCSVT.2017.2703920
   Wang T, 2017, LECT NOTES COMPUT SC, V10269, P468, DOI 10.1007/978-3-319-59126-1_39
   Xiong F, 2017, IEEE I CONF COMP VIS, P5161, DOI 10.1109/ICCV.2017.551
   Yang B, 2018, INT APPL COMPUTATION, P1
   Zeiler MD, 2013, INT CONF ACOUST SPEE, P3517, DOI 10.1109/ICASSP.2013.6638312
   Zeng LK, 2017, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2017.8296324
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang XG, 2015, MACH VISION APPL, V26, P871, DOI 10.1007/s00138-015-0703-0
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
NR 31
TC 5
Z9 7
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2837
EP 2853
DI 10.1007/s11042-019-08467-3
EA DEC 2019
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NR2VH
UT WOS:000499684800001
DA 2024-07-18
ER

PT J
AU Inunganbi, S
   Choudhary, P
   Singh, KM
AF Inunganbi, Sanasam
   Choudhary, Prakash
   Singh, Khumanthem Manglem
TI Local texture descriptors and projection histogram based handwritten
   Meitei Mayek character recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Handwritten character recognition; Meitei Mayek; ULBP; CSLBP; ILBP;
   Projection histogram; SVM; KNN; RF
AB In this paper, we use the local texture descriptor and projection histogram feature for handwritten Meitei Mayek (Manipuri script) recognition. The different variations of the local binary pattern (LBP) namely, uniform LBP (ULBP), improved LBP (ILBP), center-symmetric LBP (CS-LBP) account for local texture descriptors. These features along with the projection histogram, separately and combined are presented to machine learning algorithms, k nearest neighbor (KNN), support vector machine (SVM) and Random Forest (RF) for classification of characters. The experiments by these feature descriptors with the classifiers have been evaluated on self-collected handwritten Meitei Mayek character dataset having 9800 samples. High accuracy is achieved even with the simple KNN classifier. Furthermore, classification with SVM and RF are explored, and the results are compared with the pixel-based methods which use the intensities value directly and a classic CNN model for recognition. The comparative results show that local texture descriptors and projection histogram strongly outperform pixel-based methods. The overall superior accuracy is achieved when the feature descriptors are combined with KNN classifier and performed even better than the CNN model.
C1 [Inunganbi, Sanasam; Singh, Khumanthem Manglem] Natl Inst Technol Manipur, Imphal, Manipur, India.
   [Choudhary, Prakash] Natl Inst Technol, Hamirpur, Himachal Prades, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Manipur; National Institute of Technology (NIT System);
   National Institute of Technology Hamirpur
RP Inunganbi, S (corresponding author), Natl Inst Technol Manipur, Imphal, Manipur, India.
EM inung.sam@gmail.com; choudharyprakash87@gmail.com; manglem@gmail.com
RI Singh, Khumanthem/AFZ-2177-2022; Choudhary, Dr. Prakash/ABE-2494-2021
OI Choudhary, Dr. Prakash/0000-0003-4337-7273; Inunganbi,
   Sanasam/0000-0002-7879-1039; Singh, Khumanthem/0000-0002-6698-1185
CR Abdullah A, 2010, PATTERN RECOGN, V43, P650, DOI 10.1016/j.patcog.2009.09.007
   [Anonymous], 2013, ARXIV13033087
   [Anonymous], 2012, P INT C ADV EL EL CO
   [Anonymous], 2006, Estimation of Dependences Based on Empirical Data, DOI DOI 10.2307/2988246
   Baird HS, 1987, P SPSES 40 ANN C S H, P1987
   Blanz V., 1996, Artificial Neural Networks - ICANN 96. 1996 International Conference Proceedings, P251
   Brink AA, 2012, PATTERN RECOGN, V45, P162, DOI 10.1016/j.patcog.2011.07.005
   Burges CJC, 1997, ADV NEUR IN, V9, P375
   Chaithra D, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P548, DOI 10.1109/RTEICT.2017.8256657
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Hegadi RS, 2013, ADV INTELL SYST, V174, P963
   INUNGANBI S, 2018, INT J NAT LANG COMPU, V7, P99
   Inunganbi SC, 2018, RECOGNITION HANDWRIT
   Joshi D, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P607, DOI 10.1109/ICCUBEA.2015.124
   Kamble PM, 2015, PROCEDIA COMPUT SCI, V45, P266, DOI 10.1016/j.procs.2015.03.137
   Kasturi R, 2002, SADHANA-ACAD P ENG S, V27, P3, DOI 10.1007/BF02703309
   Kumar CJ, 2013, INT J COMPUT APPL, V17, P84
   Laishram R, 2014, 2014 IEEE INT C COMP, P1
   Likforman-Sulem L, 2007, INT J DOC ANAL RECOG, V9, P123, DOI 10.1007/s10032-006-0023-z
   Manivannan A, 2007, DOCUMENT RECOGNITION, V6500, p65000T
   Maring KA, 2014, IJCSIT, V1.2
   NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Partiningsih NDA, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, COMPUTER, AND ELECTRICAL ENGINEERING (ICITACEE), P342, DOI 10.1109/ICITACEE.2018.8576945
   Saha S, 2013, 2013 FIFTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, COMMUNICATION SYSTEMS AND NETWORKS (CICSYN), P3, DOI 10.1109/CICSYN.2013.11
   Santosh KC, 2015, FRONT COMPUT SCI-CHI, V9, P678, DOI 10.1007/s11704-015-3400-2
   Santosh KC, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413500080
   Santosh KC, 2011, PROC INT CONF DOC, P264, DOI 10.1109/ICDAR.2011.61
   Santosh KC, 2011, LECT NOTES COMPUT SC, V6915, P249, DOI 10.1007/978-3-642-23687-7_23
   Surinta O, 2013, PROC INT CONF DOC, P165, DOI 10.1109/ICDAR.2013.40
   Thokchom T, 2010, J COMPUT, V5, P1570, DOI 10.4304/jcp.5.10.1570-1574
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
NR 33
TC 5
Z9 6
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2813
EP 2836
DI 10.1007/s11042-019-08482-4
EA DEC 2019
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000501121200001
DA 2024-07-18
ER

PT J
AU Al-Ayyoub, M
   Alawneh, E
   Jararweh, Y
   Al-Smadi, M
   Gupta, BB
AF Al-Ayyoub, Mahmoud
   Alawneh, Esra'a
   Jararweh, Yaser
   Al-Smadi, Mohammad
   Gupta, Brij B.
TI Collaboration networks of arab biomedical researchers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social networks analysis; Collaboration networks; PubMed; Arab
   researchers
ID SCIENTIFIC COLLABORATION; COAUTHORSHIP NETWORKS; KNOWLEDGE NETWORKS;
   PATTERNS; IMPACT
AB Social networks (SN) consist of a set of actors and connections between them. A collaboration network (ColNet) is a special type of SN, in which the actors represent researchers and the link between them indicate that they have co-authored at least one paper. ColNet analysis reveals how researchers interact and behave. A wide range of applications can be based on such studies. The current works on ColNet usually focus on a specific domain/discipline, country/geographical region or time interval. In our study, we focus on one of the understudied regions (the Arab world), and present a novel study on the ColNet of researchers in this region. The domain of interest in our study is biomedicine. We construct, analyze, and study ColNet of biomedical researchers in the Arab world. We divide the region of interest (the Arab world) into four geographical regions and look into the evolution of ColNet of each region separately over time. Our analysis reveals that there is an increase in the number of both authors and publications over time, and that authors tend to work in increasingly larger groups rather than working individually, which is consistent with what is assumed about the nature of research in this field. Our analysis also reveals that a researcher's productivity is correlated with the amount of change in his/her circle of collaborators over time. For example, researchers working in stable or fixed groups and researchers who have completely different research group every few years are not necessarily the most productive ones.
C1 [Al-Ayyoub, Mahmoud; Jararweh, Yaser] Jordan Univ Sci & Technol, Comp Sci, Irbid, Jordan.
   [Alawneh, Esra'a; Al-Smadi, Mohammad] Jordan Univ Sci & Technol, Irbid, Jordan.
   [Gupta, Brij B.] Natl Inst Technol, Kurukshetra, Haryana, India.
C3 Jordan University of Science & Technology; Jordan University of Science
   & Technology; National Institute of Technology (NIT System); National
   Institute of Technology Kurukshetra
RP Al-Ayyoub, M (corresponding author), Jordan Univ Sci & Technol, Comp Sci, Irbid, Jordan.
EM maalshbool@just.edu.jo; isalawneh@gmail.com; yijararweh@just.edu.jo;
   maalsmadi9@just.edu.jo; gupta.brij@gmail.com
RI Gupta, Brij B/E-9813-2011; ALSmadi, Mohammad/KHD-3791-2024; Jararweh,
   Yaser/JCO-2836-2023; Jararweh, Yaser/ABE-6543-2021
OI Gupta, Brij B/0000-0003-4929-4698; ALSmadi,
   Mohammad/0000-0002-7808-6962; 
CR Al-Ayyoub M, 2018, J AMB INTEL HUM COMP, V9, P3, DOI 10.1007/s12652-017-0521-5
   Al-Sadi A, 2018, INT CONF INFORM COMM, P78, DOI 10.1109/IACS.2018.8355445
   [Anonymous], THESIS
   [Anonymous], SOCIAL NETWORKING
   [Anonymous], SIGEVOLUTION, DOI [10.1145/1147192.1147193, DOI 10.1145/1147192.1147193]
   [Anonymous], 17 CROSS STRAIT C IN
   Arkok B, 2014, INT CONF UTIL CLOUD, P658, DOI 10.1109/UCC.2014.106
   Ronda-Pupo GA, 2018, SCIENTOMETRICS, V116, P363, DOI 10.1007/s11192-018-2761-3
   Benckendorff P, 2009, J HOSP TOUR MANAG, V16, P1, DOI 10.1375/jhtm.16.1.1
   De Nooy W., 2011, Exploratory social network analysis with Pajek, V27
   Ding Y, 2011, J INFORMETR, V5, P187, DOI 10.1016/j.joi.2010.10.008
   Ghali N., 2012, Computational social networks, P3, DOI DOI 10.1007/978-1-4471-4054-2_1
   Guan JC, 2017, J INFORMETR, V11, P407, DOI 10.1016/j.joi.2017.02.007
   Horani M, 2018, INT CONF INFORM COMM, P227, DOI 10.1109/IACS.2018.8355472
   Hou H, 2008, SCIENTOMETRICS, V75, P189, DOI 10.1007/s11192-007-1771-3
   Hu C, 2008, INT J HOSP MANAG, V27, P302, DOI 10.1016/j.ijhm.2007.01.002
   KRETSCHMER H, 1994, SCIENTOMETRICS, V30, P363, DOI 10.1007/BF02017234
   Kumar S, 2014, SCIENTOMETRICS, V101, P847, DOI 10.1007/s11192-014-1363-y
   Leskovec Jure, 2007, ACM Trans. Knowl. Discov. Data, V1, DOI DOI 10.1145/1217299.1217301
   Liu XM, 2005, INFORM PROCESS MANAG, V41, P1462, DOI 10.1016/j.ipm.2005.03.012
   Lozano S, 2014, SCIENTOMETRICS, V98, P1505, DOI 10.1007/s11192-013-1162-x
   Luo MN, 2017, COMPUT VIS IMAGE UND, V163, P67, DOI 10.1016/j.cviu.2017.07.001
   LUUKKONEN T, 1992, SCI TECHNOL HUM VAL, V17, P101, DOI 10.1177/016224399201700106
   Ma ZG, 2017, IEEE T MULTIMEDIA, V19, P1558, DOI 10.1109/TMM.2017.2659221
   Newman MEJ, 2004, P NATL ACAD SCI USA, V101, P5200, DOI 10.1073/pnas.0307545100
   Newman MEJ, 2001, P NATL ACAD SCI USA, V98, P404, DOI 10.1073/pnas.021544898
   Newman MEJ, 2001, PHYS REV E, V64, DOI [10.1103/PhysRevE.64.016132, 10.1103/PhysRevE.64.016131]
   Rabab'ah A, 2016, INT CONF INTERNET, P92, DOI 10.1109/ICITST.2016.7856674
   Tsvetovat M., 2011, Social network analysis for startups
   Uddin S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057546
   Vanni T, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093376
   Yan EJ, 2009, J AM SOC INF SCI TEC, V60, P2107, DOI 10.1002/asi.21128
   Ye Q, 2013, J HOSP TOUR RES, V37, P51, DOI 10.1177/1096348011425500
NR 33
TC 3
Z9 4
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33435
EP 33455
DI 10.1007/s11042-018-6557-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600040
DA 2024-07-18
ER

PT J
AU Wang, Y
   Zhao, Y
   Guo, Z
   Qi, M
   Fan, YY
   Meng, HY
AF Wang, Yi
   Zhao, Yi
   Guo, Zhe
   Qi, Min
   Fan, Yangyu
   Meng, Hongying
TI Diffusion Tensor Image segmentation based on multi-atlas Active Shape
   Model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diffusion tensor magnetic resonance imaging; Image segmentation; Active
   Shape Model; STAPLE
ID MR BRAIN IMAGES; AUTOMATIC SEGMENTATION
AB Active Shape Model (ASM) has been successfully applied in the segmentation of Diffusion Tensor Magnetic Resonance Image (DT-MRI, referred to as DTI) of brain. However, due to multiple anatomical structure types, irregular shapes, small gray-scale and large amount of these images, perfect segmentation performance could not be achieved. Especially, it is sensitive to initial values with high computational complexity. In this paper, we introduce the gray information of multiple atlases and the prior information of target shapes into the ASM and propose the Multi-Atlas Active Shape Model (referred to as MA-ASM) approach for DTI segmentation. It was evaluated in a manually labeled database with 7 Region of Interest (ROI)s for each of 20 subjects. In comparison with the state of art method of STAPLE (Simultaneous Truth Performance Level Estimation), the proposed algorithm was closer to the manual segmentation shape by subjective visual effects, and had higher overlap rates and lower error detection rates on quantitative analysis than STAPLE.
C1 [Wang, Yi; Zhao, Yi; Guo, Zhe; Qi, Min; Fan, Yangyu] Northwestern Polytech Univ, Sch Elect & Informat, Xian, Shaanxi, Peoples R China.
   [Meng, Hongying] Brunel Univ London, Dept Elect & Comp Engn, London, England.
C3 Northwestern Polytechnical University; Brunel University
RP Meng, HY (corresponding author), Brunel Univ London, Dept Elect & Comp Engn, London, England.
EM hongying.meng@brunel.ac.uk
RI Meng, Hongying/O-5192-2014; WU, SHAN/KGM-5484-2024; wang,
   yi/KBB-3614-2024
OI Meng, Hongying/0000-0002-8836-1382; Wang, Yi/0000-0002-7743-1779
FU National Key Research and Development Program of China [2016YFC0100300];
   National Natural Science Foundation of China [61402371]; Natural Science
   Basic Research Plan in Shaanxi Province of China [2019JM-311];
   Fundamental Research Funds for the Central Universities of China
   [3102018zy020]
FX This work was supported by the National Key Research and Development
   Program of China (2016YFC0100300), National Natural Science Foundation
   of China (61402371), Natural Science Basic Research Plan in Shaanxi
   Province of China (2019JM-311), the Fundamental Research Funds for the
   Central Universities of China (3102018zy020).
CR ANTONIOS M, 2018, NEUROIMAGE, V170, P231
   Barmpoutis A, 2007, IEEE T MED IMAGING, V26, P1537, DOI 10.1109/TMI.2007.903195
   Bazin PL, 2011, NEUROIMAGE, V58, P458, DOI 10.1016/j.neuroimage.2011.06.020
   Cootes T. F., 1992, BMVC92. Proceedings of the British Machine Vision Conference, P266
   Cootes T. F., 1994, Proceedings of the 12th IAPR International Conference on Pattern Recognition (Cat. No.94CH3440-5), P610, DOI 10.1109/ICPR.1994.576375
   COOTES TF, 1994, INT C PATT RECOG, P63, DOI 10.1109/ICPR.1994.576227
   Cootes TF, 1994, P BRIT MACH VIS C, P317
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x
   Heckemann RA, 2006, NEUROIMAGE, V33, P115, DOI 10.1016/j.neuroimage.2006.05.061
   HILL A, 2010, IMAGE VISION COMPUT, V14, P601
   Jalba AC, 2015, IEEE T IMAGE PROCESS, V24, P1025, DOI 10.1109/TIP.2015.2390139
   JIA X, 2014, NEUROIMAGE, V84, P141
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kobashi S, 2013, IEEE ENG MED BIO, P7136, DOI 10.1109/EMBC.2013.6611203
   Li B, 2018, LECT NOTES COMPUT SC, V11046, P205, DOI 10.1007/978-3-030-00919-9_24
   Li WG, 2013, BMC MED GENOMICS, V6, DOI 10.1186/1755-8794-6-55
   Liang LC, 2007, NEUROIMAGE, V34, P1160, DOI 10.1016/j.neuroimage.2006.07.046
   Lim SJ, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P168, DOI 10.1109/ISSPIT.2006.270791
   Liu TM, 2007, NEUROIMAGE, V38, P114, DOI 10.1016/j.neuroimage.2007.07.002
   LU M, 2012, J NE U, V33, P645
   Lu YL, 2003, NEUROIMAGE, V20, P455, DOI 10.1016/S1053-8119(03)00352-5
   Manikandan S, 2014, MEASUREMENT, V47, P558, DOI 10.1016/j.measurement.2013.09.031
   MIN HB, 2009, NEUROIMAGE, V46, P717
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Moeskops P, 2015, NEUROIMAGE, V118, P628, DOI 10.1016/j.neuroimage.2015.06.007
   Pipitone J, 2014, NEUROIMAGE, V101, P494, DOI 10.1016/j.neuroimage.2014.04.054
   Sanroma G, 2016, LECT NOTES COMPUT SC, V10019, P27, DOI 10.1007/978-3-319-47157-0_4
   Serag A, 2016, SCI REP-UK, V6, DOI 10.1038/srep23470
   Shao XX, 2015, Patent No. [CN, 104361597A, 104361597A]
   Shi YG, 2007, NEUROIMAGE, V37, P792, DOI 10.1016/j.neuroimage.2007.05.016
   Wang L, 2015, NEUROIMAGE, V108, P160, DOI 10.1016/j.neuroimage.2014.12.042
   [王相海 Wang Xianghai], 2013, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V26, P751
   Wang Y. F., 2016, J COMPUT THEOR NANOS, V13, P1, DOI DOI 10.1080/15548627.2016.1245262
   Warfield SK, 2004, IEEE T MED IMAGING, V23, P903, DOI 10.1109/TMI.2004.828354
   Wolz R, 2010, NEUROIMAGE, V52, P109, DOI 10.1016/j.neuroimage.2010.04.006
   Woolrich M, 2011, NEUROIMAGE, V57, P1466, DOI 10.1016/j.neuroimage.2011.04.041
   Zimmerman-Moreno Gali, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4562998
NR 38
TC 5
Z9 5
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34231
EP 34246
DI 10.1007/s11042-019-08051-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800002
OA hybrid
DA 2024-07-18
ER

PT J
AU Yang, GB
   Ma, KL
   Yuan, XH
   Li, J
   Lu, Q
AF Yang, Guibing
   Ma, Kunle
   Yuan, Xiaohui
   Li, Jie
   Lu, Qiang
TI Expectation-based 3D edge bundling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Edge bundling; Force-directed; Expectation model
ID VISUALIZATION
AB In the visualization of the node-link graph, it is common to use edge-bundling algorithms to reduce the visual clutter caused by the increase in nodes and connections while reflecting the high-level structure of the graph. However, the traditional force-directed edge-bundling method has unstable gravitation when applied in three dimensions. To address this issue, we propose an edge-bundling algorithm based on the expectation model, and the edge-bundling rules can be modularized to support the addition of calculation rules. The stability of the proposed method is improved. Our experimental results with 2D and 3D scenarios demonstrate that our algorithm produces superior results that unclutter complex graphs.
C1 [Yang, Guibing; Ma, Kunle; Li, Jie; Lu, Qiang] Hefei Univ Technol, Sch Comp & Informat, Hefei, Peoples R China.
   [Yuan, Xiaohui] Univ North Texas, Dept Comp Sci & Engn, Denton, TX 76203 USA.
C3 Hefei University of Technology; University of North Texas System;
   University of North Texas Denton
RP Lu, Q (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei, Peoples R China.
EM spacemiao_yang@163.com; makunle@163.com; xiaohui.yuan@unt.edu;
   lijie_62@163.com; luqiang@hfut.edu.cn
RI Wu, Celimuge/P-1232-2019; Yuan, Xiaohui/AAQ-1172-2020; Lu,
   Qiang/AAU-9248-2020
OI Wu, Celimuge/0000-0001-6853-5878; Yuan, Xiaohui/0000-0001-6897-4563; LI,
   Jie/0000-0001-8483-6240
FU Natural Science Foundation of Anhui Province of China [1708085MF158];
   National Natural Science Foundation of China [61472115]; Visiting
   Scholar Researcher Program at North Texas University through the State
   Scholarship Fund of the China Scholarship Council [201706695044]; Key
   Project of Transformation and Industrialization of Scientific and
   Technological Achievements of Intelligent Manufacturing Technology
   Research Institute of Hefei University of Technology [IMICZ2017010]
FX This work was supported in part by the Natural Science Foundation of
   Anhui Province of China under Grant 1708085MF158, in part by the
   National Natural Science Foundation of China under Grant 61472115, in
   part by the Visiting Scholar Researcher Program at North Texas
   University through the State Scholarship Fund of the China Scholarship
   Council under Grant 201706695044, and in part by the Key Project of
   Transformation and Industrialization of Scientific and Technological
   Achievements of Intelligent Manufacturing Technology Research Institute
   of Hefei University of Technology under Grant IMICZ2017010.
CR Böttger J, 2014, IEEE T VIS COMPUT GR, V20, P471, DOI 10.1109/TVCG.2013.114
   Bondi A. B., 2000, Proceedings Second International Workshop on Software and Performance. WOSP2000, P195, DOI 10.1145/350391.350432
   Cui WW, 2008, IEEE T VIS COMPUT GR, V14, P1277, DOI 10.1109/TVCG.2008.135
   Ersoy O, 2011, IEEE T VIS COMPUT GR, V17, P2364, DOI 10.1109/TVCG.2011.233
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Hurter C, 2012, COMPUT GRAPH FORUM, V31, P865, DOI 10.1111/j.1467-8659.2012.03079.x
   Lambert A, 2010, COMPUT GRAPH FORUM, V29, P853, DOI 10.1111/j.1467-8659.2009.01700.x
   Lambert A, 2010, IEEE INT CONF INF VI, P329, DOI 10.1109/IV.2010.53
   LU Q, 2016, CAD CG, V28, P1899
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Pupyrev Sergey., 2011, GD 11 PROC 19 INT S, P136, DOI DOI 10.1007/978-3-642-25878-7_14
   Telea A, 2010, COMPUT GRAPH FORUM, V29, P843, DOI 10.1111/j.1467-8659.2009.01680.x
   Ware C, 2008, ACM T APPL PERCEPT, V5, DOI 10.1145/1279640.1279642
   Zhou H, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P55
   Zielasko D, 2016, COMPUT GRAPH FORUM, V35, P51, DOI 10.1111/cgf.12881
NR 17
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35099
EP 35118
DI 10.1007/s11042-019-08060-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800038
DA 2024-07-18
ER

PT J
AU Zhou, JK
   Liu, T
   Zhu, JT
AF Zhou, Jukai
   Liu, Tong
   Zhu, Jingting
TI Weighted adjacent matrix for <i>K</i>-means clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE k-means clustering; Similarity measurement; Adjacent matrix;
   Unsupervised learning
ID ALGORITHM
AB K-means clustering is one of the most popular clustering algorithms and has been embedded in other clustering algorithms, e.g. the last step of spectral clustering. In this paper, we propose two techniques to improve previous k-means clustering algorithm by designing two different adjacent matrices. Extensive experiments on public UCI datasets showed the clustering results of our proposed algorithms significantly outperform three classical clustering algorithms in terms of different evaluation metrics.
C1 [Zhou, Jukai; Liu, Tong; Zhu, Jingting] Massey Univ, Sch Nat & Computat Sci, Auckland, New Zealand.
C3 Massey University
RP Liu, T (corresponding author), Massey Univ, Sch Nat & Computat Sci, Auckland, New Zealand.
EM t.liu@massey.ac.nz
RI lin, yuan/JXL-9592-2024
OI Liu, Tong/0000-0003-3047-1148; Zhu, Jinting/0000-0002-0682-1796
CR Abe S, 2010, ADV PATTERN RECOGNIT, P331, DOI 10.1007/978-1-84996-098-4_7
   Arora P, 2016, PROCEDIA COMPUT SCI, V78, P507, DOI 10.1016/j.procs.2016.02.095
   Bachem O, 2016, AAAI CONF ARTIF INTE, P1459
   Bryant A, 2018, IEEE T KNOWL DATA EN, V30, P1109, DOI 10.1109/TKDE.2017.2787640
   Capó M, 2017, KNOWL-BASED SYST, V117, P56, DOI 10.1016/j.knosys.2016.06.031
   Cassisi C, 2013, INFORM SYST, V38, P317, DOI 10.1016/j.is.2012.09.001
   Chang LJ, 2017, IEEE T KNOWL DATA EN, V29, P387, DOI 10.1109/TKDE.2016.2618795
   Chen JY, 2019, APPL INTELL, V49, P1228, DOI 10.1007/s10489-018-1324-x
   Deng Z, 2015, CLUSTER COMPUT, V18, P549, DOI 10.1007/s10586-014-0413-9
   Ding Y, 2016, NEUROCOMPUTING, V188, P233, DOI 10.1016/j.neucom.2015.01.106
   Domeniconi C., 2009, ACM Transactions on Knowledge Discovery from Data, V2, P1, DOI [10.1145/1460797.1460800, DOI 10.1145/1460797.1460800]
   Du L, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3476
   Du T, 2018, INTERNATIONAL SYMPOSIUM 2018 - MECHANICAL AND ELECTRONICAL SYSTEMS AND CONTROL ENGINEERING, P11
   Ferreira MRP, 2016, PATTERN RECOGN, V51, P310, DOI 10.1016/j.patcog.2015.09.025
   Gan JH, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P519, DOI 10.1145/2723372.2737792
   Gebru ID, 2016, IEEE T PATTERN ANAL, V38, P2402, DOI 10.1109/TPAMI.2016.2522425
   Guha S., 1998, SIGMOD Record, V27, P73, DOI 10.1145/276305.276312
   Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3
   He L, 2019, IEEE T CYBERNETICS, V49, P1058, DOI 10.1109/TCYB.2018.2794998
   Jayasumana S, 2015, IEEE T PATTERN ANAL, V37, P2464, DOI 10.1109/TPAMI.2015.2414422
   Kodinariya T.M., 2013, International Journal of Advance Research in Computer Science and Management Studies, V1, P90, DOI DOI 10.18576/AMIS/100428
   Lattanzi S, 2015, ITCS, P211
   Lei C, 2018, MULTIMED TOOLS APPL, V77, P29605, DOI 10.1007/s11042-017-5381-7
   LIU F, 2017, IOP CONF SER MAT SCI, V242, DOI DOI 10.1088/1757-899X/242/1/012123
   Lv YH, 2016, NEUROCOMPUTING, V171, P9, DOI 10.1016/j.neucom.2015.05.109
   Malinen MI, 2014, BALANCED K MEANS CLU, P32
   Murtagh F, 2012, WIRES DATA MIN KNOWL, V2, P86, DOI 10.1002/widm.53
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Pavan K. Karteeka, 2010, Journal of Computer Sciences, V6, P60, DOI 10.3844/jcssp.2010.60.66
   Sharma A, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING, INSTRUMENTATION AND CONTROL TECHNOLOGIES (ICICICT), P787, DOI 10.1109/ICICICT1.2017.8342664
   Shiokawa H, 2018, LECT NOTES COMPUT SC, V11029, P18, DOI 10.1007/978-3-319-98809-2_2
   Shiokawa H, 2015, PROC VLDB ENDOW, V8, P1178, DOI 10.14778/2809974.2809980
   Souza C. R., 2010, Creative Commons Attribution-Noncommercial-Share Alike, V3, P29
   Sting WWYJMR, 1997, VLDB, P186
   Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293
   Tremblay N., 2016, INT C MACHINE LEARNI, P1002
   Vajda S, 2016, INT C REC TRENDS IM, P185
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Xu D., 2015, Annals of Data Science, V2, P165, DOI [DOI 10.1007/S40745-015-0040-1, 10.1007/s40745-015-0040-1]
   Xu XW, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P824, DOI 10.1145/1281192.1281280
   Zahra S, 2015, INFORM SCIENCES, V320, P156, DOI 10.1016/j.ins.2015.03.062
   Zhang SC, 2020, NEUROCOMPUTING, V391, P234, DOI 10.1016/j.neucom.2018.11.101
   Zhang SC, 2018, WORLD WIDE WEB, V21, P1787, DOI 10.1007/s11280-018-0619-5
   Zhang T., 1996, BIRCH EFFICIENT DATA, V25, P103, DOI [DOI 10.1145/233269.233324, 10.1145/235968.233324]
   Zheng W, 2020, PATTERN RECOGN LETT, V132, P4, DOI 10.1016/j.patrec.2018.06.029
   Zheng W, 2018, MULTIMED TOOLS APPL, V77, P29739, DOI 10.1007/s11042-017-5272-y
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P2022, DOI 10.1109/TKDE.2018.2873378
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P1532, DOI 10.1109/TKDE.2018.2858782
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
NR 50
TC 4
Z9 4
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33415
EP 33434
DI 10.1007/s11042-019-08009-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600039
DA 2024-07-18
ER

PT J
AU Ju, CH
   Wang, J
   Xu, CH
AF Ju, Chunhua
   Wang, Jie
   Xu, Chonghuan
TI A novel application recommendation method combining social relationship
   and trust relationship for future internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data computing; Future internet of things; Application
   recommendation; Social relationship; Social similarity; Trust
   relationship
ID EFFICIENT; SCHEME
AB Traditional collaborative filtering methods always utilize Cosine and Pearson methods to calculate the similarity of users. When the nearest neighbor doesn't comment the predicted item, then the nearest neighbor has no influence on results, thus affecting the accuracy of collaborative filtering recommendation. And the traditional recommendation systems always have the problems of data sparsity, cold start and so on. In this paper, we consider social relationship and trust relationship, and put forward a novel application recommendation method that combines users' social relationship and trust relationship. Specifically, we combine social relationship and user preference towards applications to calculate similarity score, we fuse the trust relationship based on familiarity and user reputation to calculate trust score. The final prediction score is calculated by fusing similar relationship and trust relationship properly. And the proposed method can effectively improve accuracy of recommendations.
C1 [Ju, Chunhua] Zhejiang Gongshang Univ, Grad Sch, Hangzhou 310018, Zhejiang, Peoples R China.
   [Wang, Jie; Xu, Chonghuan] Zhejiang Gongshang Univ, Business Adm Coll, Hangzhou 310018, Zhejiang, Peoples R China.
   [Wang, Jie] Zhejiang Tech Inst Econ, Shangmao Coll, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Zhejiang Gongshang University; Zhejiang Gongshang University
RP Xu, CH (corresponding author), Zhejiang Gongshang Univ, Business Adm Coll, Hangzhou 310018, Zhejiang, Peoples R China.
EM talentxch@zjgsu.edu.cn
OI Xu, Chonghuan/0000-0001-9757-1915
FU Zhejiang Public Welfare Technology Applied Research Project
   [LGN18G010001]; National Natural Science Foundation of China [71702164]
FX This paper is supported by Zhejiang Public Welfare Technology Applied
   Research Project (LGN18G010001), National Natural Science Foundation of
   China (71702164).
CR Birtolo C, 2013, EXPERT SYST APPL, V40, P6997, DOI 10.1016/j.eswa.2013.06.022
   [陈克寒 Chen Kehan], 2013, [计算机学报, Chinese Journal of Computers], V36, P349
   Golbeck J., 2006, ACM Transactions on Internet Technology, V6, P497, DOI 10.1145/1183463.1183470
   Gui JS, 2017, IEEE ACCESS, V5, P2396, DOI 10.1109/ACCESS.2017.2672561
   Illig Jens, 2011, Knowledge Processing and Data Analysis. First International Conference, KONT 2007 and First International Conference, KPP 2007. Revised Selected Papers, P136, DOI 10.1007/978-3-642-22140-8_9
   Jhamb Y, 2017, INFORM PROCESS MANAG, V53, P559, DOI 10.1016/j.ipm.2017.01.001
   Jiang M, 2014, IEEE T KNOWL DATA EN, V26, P2789, DOI 10.1109/TKDE.2014.2300487
   Ju Chunhua, 2015, Journal of the China Society for Scientific and Technical Information, V34, P164, DOI 10.3772/j.issn.1000-0135.2015.002.006
   Ju CH, 2013, SCI WORLD J, DOI 10.1155/2013/869658
   Jyun-Cheng W, 2008, EXPERT SYST APPL, V34, P1666, DOI 10.1016/j.eswa.2007.01.045
   Lee YH, 2012, DECIS SUPPORT SYST, V53, P245, DOI 10.1016/j.dss.2012.01.018
   Li H, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416590163
   Li Y., 2014, J HARBIN I TECHNOL, V21, P26, DOI DOI 10.1016/S1005-8885(14)60516-1
   Lin B, 2016, IEEE T NETW SERV MAN, V13, P581, DOI 10.1109/TNSM.2016.2554143
   Lu Z, 2017, MULTIMED TOOLS APPL, V76, P10855, DOI 10.1007/s11042-016-3877-1
   Ma H, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961201
   Sun ZB, 2015, J SYST SOFTWARE, V99, P109, DOI 10.1016/j.jss.2014.09.019
   Wang YH, 2017, INFORM SCIENCES, V408, P70, DOI 10.1016/j.ins.2017.04.035
   Wei C, 2013, INFORM SYST FRONT, V15, P533, DOI 10.1007/s10796-012-9377-6
   Xia ZH, 2017, INFORM SCIENCES, V387, P195, DOI 10.1016/j.ins.2016.12.030
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xiong NX, 2010, IEEE T PARALL DISTR, V21, P1254, DOI 10.1109/TPDS.2010.29
   Xu C, 2013, EURASIP J ADV SIG PR, V2013, P1, DOI DOI 10.1016/J.MFGLET.2013.09.003
   Xu CH, 2018, INFORM PROCESS MANAG, V54, P463, DOI 10.1016/j.ipm.2018.02.005
   Zhang H, 2016, J INTERNET TECHNOL, V17, P1391, DOI 10.6138/JIT.2016.17.7.20161108
   Zheng HF, 2018, IEEE T SYST MAN CY-S, V48, P2315, DOI 10.1109/TSMC.2017.2734886
NR 26
TC 11
Z9 12
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29867
EP 29880
DI 10.1007/s11042-018-6604-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200013
DA 2024-07-18
ER

PT J
AU Kwolek, B
   Michalczuk, A
   Krzeszowski, T
   Switonski, A
   Josinski, H
   Wojciechowski, K
AF Kwolek, Bogdan
   Michalczuk, Agnieszka
   Krzeszowski, Tomasz
   Switonski, Adam
   Josinski, Henryk
   Wojciechowski, Konrad
TI Calibrated and synchronized multi-view video and motion capture dataset
   for evaluation of gait recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; Covariate factors; Biometrics; Markerless 3D tracking
ID LEVEL FUSION; PERCEPTION; KINEMATICS; PARAMETERS; MARKERLESS; ACCURACY;
   MOVEMENT; MODEL; IMAGE
AB We introduce synchronized and calibrated multi-view video and motion capture dataset for motion analysis and gait identification. The 3D gait dataset consists of 166 data sequences with 32 people. In 128 data sequences, each of 32 individuals was dressed in his/her clothes, in 24 data sequences, 6 of 32 performers changed clothes, and in 14 data sequences, 7 of the performers had a backpack on his/her back. In a single recording session, every performer walked from right to left, then from left to right, and afterwards on the diagonal from upper-right to bottom-left and from bottom-left to upper-right corner of a rectangular scene. We demonstrate that a baseline algorithm achieves promising results in a challenging scenario, in which gallery/training data were collected in walks perpendicular/facing to the cameras, whereas the probe/testing data were collected in diagonal walks. We compare performances of biometric gait recognition that were achieved on marker-less and marker-based 3D data. We present recognition performances, which were achieved by a convolutional neural network and classic classifiers operating on gait signatures obtained by multilinear principal component analysis. The availability of synchronized multi-view image sequences with 3D locations of body markers creates a number of possibilities for extraction of discriminative gait signatures. The gait data are available at .
C1 [Kwolek, Bogdan] AGH Univ Sci & Technol, 30 Mickiewicza Ave, PL-30059 Krakow, Poland.
   [Michalczuk, Agnieszka; Wojciechowski, Konrad] Polish Japanese Acad Informat Technol, Ctr Res & Dev, Aleja Legionow 2, Bytom, Poland.
   [Krzeszowski, Tomasz] Rzeszow Univ Technol, Fac Elect & Comp Engn, W Pola 2, PL-35959 Rzeszow, Poland.
   [Switonski, Adam; Josinski, Henryk] Silesian Tech Univ, Inst Informat, Ul Akad 16, PL-44100 Gliwice, Poland.
C3 AGH University of Krakow; Polsko-Japonska Akademia Technik
   Komputerowych; Rzeszow University of Technology; Silesian University of
   Technology
RP Kwolek, B (corresponding author), AGH Univ Sci & Technol, 30 Mickiewicza Ave, PL-30059 Krakow, Poland.
EM bkw@agh.edu.pl
RI Switonski, Adam/AAG-4805-2019; Krzeszowski, Tomasz/H-7717-2019; Kwolek,
   Bogdan/M-4552-2013
OI Krzeszowski, Tomasz/0000-0001-7359-4637; Kwolek,
   Bogdan/0000-0002-7715-1435
FU Polish National Science Center (NCN) [2014/15/B/ST6/02808,
   2017/27/B/ST6/01743]; Statutory Research funds of Institute of
   Informatics, Silesian University of Technology Poland [BK/204/RAU2/2019]
FX This work was supported by Polish National Science Center (NCN) under
   research grants 2014/15/B/ST6/02808 and 2017/27/B/ST6/01743 as well as
   Statutory Research funds of Institute of Informatics, Silesian
   University of Technology Poland (BK/204/RAU2/2019).
CR Ahmed F, 2015, VISUAL COMPUT, V31, P915, DOI 10.1007/s00371-015-1092-0
   Al-Tayyan A, 2017, IMAGE VISION COMPUT, V61, P54, DOI 10.1016/j.imavis.2017.02.004
   [Anonymous], EVALUATION FRAMEWORK
   [Anonymous], EXPT PLAN AUTOMATIC
   [Anonymous], CHIN AC SCI CAS GAIT
   [Anonymous], GAIT RECOGNITION DAT
   [Anonymous], 2001, Cmu Ri Tr 01-18
   [Anonymous], IEE C MOT AN TRACK
   [Anonymous], 2001, TECH REP
   [Anonymous], 2008, 2008 IEEE 2 INT C BI
   [Anonymous], INT C BIOM SPEC INT
   [Anonymous], HUMAN IDENTIFICATION
   Aqmar M. R., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2190, DOI 10.1109/ICPR.2010.536
   Asadi-Aghbolaghi M, 2017, IEEE INT CONF AUTOMA, P476, DOI 10.1109/FG.2017.150
   Balazia M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152124
   Balazia M, 2017, IET BIOMETRICS, V6, P129, DOI 10.1049/iet-bmt.2015.0072
   BARCLAY CD, 1978, PERCEPT PSYCHOPHYS, V23, P145, DOI 10.3758/BF03208295
   Behrens J, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-89
   Benedek C, 2018, IEEE T CIRC SYST VID, V28, P101, DOI 10.1109/TCSVT.2016.2595331
   Benoit DL, 2006, GAIT POSTURE, V24, P152, DOI 10.1016/j.gaitpost.2005.04.012
   Bouchrika I, 2007, LECT NOTES COMPUT SC, V4418, P150
   Ceseracciu E, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087640
   Chester VL, 2006, CLIN BIOMECH, V21, P726, DOI 10.1016/j.clinbiomech.2006.02.007
   Choi S, 2019, IEEE T INF FOREN SEC, V14, P2577, DOI 10.1109/TIFS.2019.2901823
   Cimolin V, 2014, GAIT POSTURE, V39, P1005, DOI 10.1016/j.gaitpost.2014.02.001
   Connie T, 2015, 2015 3RD INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (ICOICT), P574, DOI 10.1109/ICoICT.2015.7231488
   Connor P, 2018, COMPUT VIS IMAGE UND, V167, P1, DOI 10.1016/j.cviu.2018.01.007
   CUTTING JE, 1977, B PSYCHONOMIC SOC, V9, P353, DOI 10.3758/BF03337021
   Das Choudhury S, 2016, PATTERN RECOGN LETT, V80, P1, DOI 10.1016/j.patrec.2016.05.009
   Das Choudhury S, 2012, PATTERN RECOGN, V45, P3414, DOI 10.1016/j.patcog.2012.02.032
   Deng MQ, 2017, PATTERN RECOGN, V67, P186, DOI 10.1016/j.patcog.2017.02.014
   Devanne M, 2016, INT C PATT RECOG, P895, DOI 10.1109/ICPR.2016.7899749
   Feng Y, 2016, INT C PATT RECOG, P325, DOI 10.1109/ICPR.2016.7899654
   Geerse DJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0139913
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hofmann M, 2014, J VIS COMMUN IMAGE R, V25, P195, DOI 10.1016/j.jvcir.2013.02.006
   Hofmann M, 2011, WSCG 2011: COMMUNICATION PAPERS PROCEEDINGS, P99
   Hosni N, 2018, INT C PATT RECOG, P2130, DOI 10.1109/ICPR.2018.8545040
   Hu HF, 2013, IEEE T CIRC SYST VID, V23, P1274, DOI 10.1109/TCSVT.2013.2242640
   Isaac ERHP, 2017, IEEE SIGNAL PROC LET, V24, P1188, DOI 10.1109/LSP.2017.2715179
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Khokhlova M, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P564, DOI 10.1109/SITIS.2016.95
   Kirtley C., 2006, CLIN GAIT ANAL THEOR
   Krzeszowski T, 2012, LECT NOTES COMPUT SC, V7594, P491, DOI 10.1007/978-3-642-33564-8_59
   Kwolek B, 2014, LECT NOTES ARTIF INT, V8398, P595, DOI 10.1007/978-3-319-05458-2_61
   Kwolek B, 2011, LECT NOTES COMPUT SC, V6915, P115, DOI 10.1007/978-3-642-23687-7_11
   Levine D, 2012, Whittle's gait analysis
   Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122
   López-Fernández D, 2016, IMAGE VISION COMPUT, V48-49, P1, DOI 10.1016/j.imavis.2016.01.003
   López-Fernández D, 2014, LECT NOTES COMPUT SC, V8703, P26, DOI 10.1007/978-3-319-13323-2_3
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Lu HP, 2011, PATTERN RECOGN, V44, P1540, DOI 10.1016/j.patcog.2011.01.004
   Lu TW, 2012, KAOHSIUNG J MED SCI, V28, pS13, DOI 10.1016/j.kjms.2011.08.004
   Luo J, 2016, PATTERN RECOGN, V60, P361, DOI 10.1016/j.patcog.2016.05.030
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Matovski DS, 2012, IEEE T INF FOREN SEC, V7, P543, DOI 10.1109/TIFS.2011.2176118
   Mündermann L, 2006, J NEUROENG REHABIL, V3, DOI 10.1186/1743-0003-3-6
   Nandy A, 2016, NEUROCOMPUTING, V191, P117, DOI 10.1016/j.neucom.2016.01.002
   Neves J, 2016, ARTIF INTELL REV, V46, P515, DOI 10.1007/s10462-016-9474-x
   Perrott MA, 2017, GAIT POSTURE, V52, P57, DOI 10.1016/j.gaitpost.2016.10.020
   Pfister Alexandra, 2014, Journal of Medical Engineering & Technology, V38, P274, DOI 10.3109/03091902.2014.909540
   Portillo-Portillo J, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010006
   Sandau M, 2016, J FORENSIC SCI, V61, P637, DOI 10.1111/1556-4029.13015
   Sandau M, 2014, MED ENG PHYS, V36, P1168, DOI 10.1016/j.medengphy.2014.07.007
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Shutler JD, 2004, ADV SOFT COMP, P339
   Sun JD, 2018, MULTIMED TOOLS APPL, V77, P24909, DOI 10.1007/s11042-018-5722-1
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Urtasun R, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P17, DOI 10.1109/AFGR.2004.1301503
   Wan CS, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3230633
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Wolf T, 2016, IEEE IMAGE PROC, P4165, DOI 10.1109/ICIP.2016.7533144
   Xu X, 2015, GAIT POSTURE, V42, P145, DOI 10.1016/j.gaitpost.2015.05.002
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhang ZX, 2011, LECT NOTES COMPUT SC, V7098, P150, DOI 10.1007/978-3-642-25449-9_19
   Zhao GY, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P529
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 78
TC 27
Z9 27
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32437
EP 32465
DI 10.1007/s11042-019-07945-y
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000061
OA hybrid
DA 2024-07-18
ER

PT J
AU Singh, R
   Dhillon, JK
   Kushwaha, AKS
   Srivastava, R
AF Singh, Roshan
   Dhillon, Jagwinder Kaur
   Kushwaha, Alok Kumar Singh
   Srivastava, Rajeev
TI Depth based enlarged temporal dimension of 3D deep convolutional network
   for activity recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Activity recognition; Depth sequences; Spatiotemporal convolutions
AB An activity takes many seconds to complete which makes it a spatiotemporal structure. Many contemporary techniques tried to learn activity representation using convolutional neural network from such structures to recognize activities from videos. Nevertheless, these representation failed to learn complete activity because they utilized very few video frames for learning. In this work we use raw depth sequences considering its capabilities to record geometric information of objects and apply proposed enlarged time dimension convolution to learn features. Due to these properties, depth sequences are more discriminatory and insensitive to lighting changes as compared to RGB video. As we use raw depth data, time to do preprocessing are also saved. The 3 dimensional space-time filters have been used over increased time dimension for feature learning. Experimental results demonstrated that by lengthening the temporal resolution over raw depth data, accuracy of activity recognition has been improved significantly. We also studied the impact of different spatial resolution and conclude that accuracy stabilizes at larger spatial sizes. We shows the state-of-the-art results on three human activity recognition depth datasets: NTU-RGB+D, MSRAction3D and MSRDailyActivity3D.
C1 [Singh, Roshan; Srivastava, Rajeev] IIT BHU, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
   [Dhillon, Jagwinder Kaur; Kushwaha, Alok Kumar Singh] IKGPTU, Dept Comp Sci & Engn, Kapurthala, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi); I. K. Gujral Punjab
   Technical University
RP Singh, R (corresponding author), IIT BHU, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
EM roshan.cis@iitbhu.ac.in; jagwinder_88@yahoo.co.in;
   dr.alokkushwaha@ptu.ac.in; rajeev.cse@iitbhu.ac.in
RI Srivastava, Rajeev/C-7906-2016; Singh, Roshan/AAX-3387-2021
OI Srivastava, Rajeev/0000-0002-0165-1556; Singh,
   Roshan/0000-0002-8527-1162; KUSHWAHA, ALOK KUMAR
   SINGH/0000-0003-2928-998X
CR [Anonymous], 2016, CVPR
   [Anonymous], 2015, CVPR
   [Anonymous], 2015, P IEEE INT C COMPUTE
   [Anonymous], 2014, NIPS
   [Anonymous], 2015, ARXIV150702159
   [Anonymous], 2009, PROC IEEE C COMPUT V
   [Anonymous], 2008, P BMVC 2008 19 BRIT
   [Anonymous], 2015, CORR
   [Anonymous], 2010, ECCV
   [Anonymous], 2009, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.23.124
   [Anonymous], 2015, IEEE T HUMAN MACHINE
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], 2010, ICML
   [Anonymous], 2012, CVPR
   [Anonymous], 2013, ICCV
   [Anonymous], 2008, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], 2015, CVPR
   [Anonymous], 2011, PLAN ACTIVITY INTENT
   [Anonymous], 2014, CVPR
   Bilen H, 2018, IEEE T PATTERN ANAL, V40, P2799, DOI 10.1109/TPAMI.2017.2769085
   Chen C, 2015, LECT NOTES COMPUT SC, V9474, P613, DOI 10.1007/978-3-319-27857-5_55
   Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439
   Donahue J., 2015, CVPR
   Evangelidis G., 2014, ICPR
   Jin L, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P311, DOI 10.1109/ISM.2014.56
   Khaire P, 2018, PATTERN RECOGN LETT, V115, P107, DOI 10.1016/j.patrec.2018.04.035
   Kim D, 2014, 8 INT C MOB UB COMP
   Krizhevsky Alex., NIPS 2012
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li WQ, 2008, IEEE T CIRC SYST VID, V18, P1499, DOI 10.1109/TCSVT.2008.2005597
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu Z, 2016, IMAGE VIS COMPUT
   Lu CW, 2014, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2014.104
   Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227
   Luo Z, 2017, ARXIV170101821V3CSCV
   Ohn-Bar E., 2013, CVPR WORKSH
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang L., 2015, CVPR
   Wang L, 2016, ARXIV160800859V1CSCV
   Wang LM, 2014, IEEE T IMAGE PROCESS, V23, P810, DOI 10.1109/TIP.2013.2295753
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wu L, 2017, PATTERN RECOGN
   Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Xu H, 2017, ARXIV170307814V2CSCV
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Zhou B., 2014, NIPS
NR 56
TC 9
Z9 10
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30599
EP 30614
DI 10.1007/s11042-018-6425-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200054
DA 2024-07-18
ER

PT J
AU Zhai, SL
   Liu, SQ
   Wang, X
   Tang, J
AF Zhai, Sulan
   Liu, Shunqiang
   Wang, Xiao
   Tang, Jin
TI FMT: fusing multi-task convolutional neural network for person search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person search; Heterogeneous task; Multiple loss; Region proposal
   network; Person labels
ID REIDENTIFICATION
AB Person search is to detect all persons and identify the query persons from detected persons in the image without proposals and bounding boxes, which is different from person re-identification. In this paper, we propose a fusing multi-task convolutional neural network(FMT-CNN) to tackle the correlation and heterogeneity of detection and re-identification with a single convolutional neural network. We focus on how the interplay of person detection and person re-identification affects the overall performance. We employ person labels in region proposal network to produce features for person re-identification and person detection network, which can improve the accuracy of detection and re-identification simultaneously. We also use a multiple loss to train our re-identification network. Experiment results on CUHK-SYSU Person Search dataset show that the performance of our proposed method is superior to state-of-the-art approaches in both mAP and top-1.
C1 [Zhai, Sulan; Liu, Shunqiang] Anhui Univ, Sch Math Sci, Hefei 230601, Anhui, Peoples R China.
   [Wang, Xiao; Tang, Jin] Anhui Univ, Sch Comp Sci & Technol, Hefei 230601, Anhui, Peoples R China.
C3 Anhui University; Anhui University
RP Zhai, SL (corresponding author), Anhui Univ, Sch Math Sci, Hefei 230601, Anhui, Peoples R China.
EM sulanzhai@gmail.com
RI Wang, Xiao/CAG-7835-2022; liu, shunqiang/G-8155-2012
OI Wang, Xiao/0000-0001-6117-6745; 
FU National Natural Science Foundation of China [61872005]; Natural Science
   Research Project of Anhui universities of China [KJ2019A0005,
   KJ2019A0032]; open project of Anhui University [KF2019A03]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61872005, in part by the Natural Science
   Research Project of Anhui universities of China under Grant KJ2019A0005,
   KJ2019A0032, and in part supported by open project of Anhui University
   KF2019A03.
CR [Anonymous], P IEEE INT C COMP VI
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], PERSON REIDENTIFICAT
   [Anonymous], MULTIMED TOOLS APPL
   Cheng D, 2018, MULTIMED TOOLS APPL, V77, P3533, DOI 10.1007/s11042-017-5182-z
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Gao H, 2017, LECT NOTES COMPUT SC, V10559, P259, DOI 10.1007/978-3-319-67777-4_23
   Hamdoun O, 2008, ACMIEEE INT C DISTRI, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Leng QM, 2015, MULTIMED TOOLS APPL, V74, P6989, DOI 10.1007/s11042-014-1949-7
   Li SQ, 2016, INT CONF CLOUD COMPU, P480, DOI 10.1109/CCIS.2016.7790306
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   McLaughlin N, 2017, IEEE T CIRC SYST VID, V27, P525, DOI 10.1109/TCSVT.2016.2619498
   Niño-Castañeda J, 2016, IEEE T IMAGE PROCESS, V25, P2259, DOI 10.1109/TIP.2016.2542021
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Prosser B., 2010, PERSON RE IDENTIFICA, V2, P1
   Shen Y, 2015, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2015.366
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Yang B, 2015, IEEE I CONF COMP VIS, P82, DOI 10.1109/ICCV.2015.18
   Zhang SS, 2015, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2015.7298784
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
NR 33
TC 7
Z9 7
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31605
EP 31616
DI 10.1007/s11042-019-07939-w
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000028
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hu, T
   Zhu, XY
   Wang, SH
   Duan, L
AF Hu, Tao
   Zhu, Xinyan
   Wang, Shaohua
   Duan, Lian
TI Human interaction recognition using spatial-temporal salient feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth sensor; Interaction recognition; Hierarchical saliency; SVM
AB Depth sensor is widely used today and has great impact in object pose estimation, camera tracking, human actions, and scene reconstruction. This paper presents a novel method for human interaction recognition based on 3D skeleton data captured by Kinect sensor using hierarchical spatial-temporal saliency-based representation method. Hierarchical saliency can be conceptualized as Salient Actions at the highest level, determined by the initial movement in an interaction; Salient Points at middle level, determined by a single time point uniquely identified for all instances of Salient Action; Salient Joints at the lowest level, determined by the greatest positional changes of human joints in a Salient Action sequence. Given the interaction saliency at different levels, several types of features, such as spatial displacement, direction relations, and etc., are introduced based on action characteristics. Since there are few publicly accessible test datasets, we created a new dataset with eight types of interactions named K3HI, using the Microsoft Kinect. The method was tested based on Support Vector Machine (SVM) multi-class classifier. In the experiment, the results demonstrate that the average recognition accuracy of hierarchical saliency-based representation is 90.29%, outperforming methods using other features.
C1 [Hu, Tao; Zhu, Xinyan] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Hubei, Peoples R China.
   [Hu, Tao; Zhu, Xinyan] Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, Wuhan 430079, Hubei, Peoples R China.
   [Hu, Tao] Kent State Univ, Sch Informat, Kent, OH 44240 USA.
   [Hu, Tao; Duan, Lian] Guangxi Teachers Educ Univ, Key Lab Environm Change & Resources Use Beibu Gul, Nanning 530001, Guangxi, Peoples R China.
   [Wang, Shaohua] Wuhan Univ, Int Software Sch, Wuhan 430079, Hubei, Peoples R China.
   [Duan, Lian] Guangxi Teachers Educ Univ, Geog Sci & Planning Sch, Nanning 530001, Guangxi, Peoples R China.
C3 Wuhan University; Wuhan University; University System of Ohio; Kent
   State University; Kent State University Kent; Kent State University
   Salem; Nanning Normal University; Wuhan University; Nanning Normal
   University
RP Wang, SH (corresponding author), Wuhan Univ, Int Software Sch, Wuhan 430079, Hubei, Peoples R China.
EM shwang@whu.edu.cn
RI shaohua, wang/AAB-7904-2022; zhu, y x/IVU-7833-2023; 朱,
   欣妍/JZD-6639-2024; zhu, xin/JXN-3188-2024; Hu, Tao/JOZ-6744-2023
FU National Key R&D Program of China [2016YFB0502204]; National Key
   Technology RD Program [2015BAK03B04]; Funds for the Central Universities
   [413000010]; State Laboratory of Information Engineering in Surveying,
   Mapping and Remote Sensing, Wuhan University [16(03)]; Guangxi Higher
   Education Undergraduate Teaching Reform Project Category A [2016JGA258];
   Opening Foundation of Key Laboratory of Environment Change and Resources
   Use in Beibu Gulf Ministry of Education (Guangxi Teachers Education
   University); Guangxi Key Laboratory of Earth Surface Processes and
   Intelligent Simulation (Guangxi Teachers Education University)
   [GTEU-KLOP-K1704]
FX We are grateful to the volunteers for capturing data. This research is
   supported by the National Key R&D Program of China (No. 2016YFB0502204),
   the National Key Technology R&D Program (No. 2015BAK03B04), the Funds
   for the Central Universities (No. 413000010), the Open Found of State
   Laboratory of Information Engineering in Surveying, Mapping and Remote
   Sensing, Wuhan University (No. 16(03)), Guangxi Higher Education
   Undergraduate Teaching Reform Project Category A (2016JGA258), and the
   Opening Foundation of Key Laboratory of Environment Change and Resources
   Use in Beibu Gulf Ministry of Education (Guangxi Teachers Education
   University) and Guangxi Key Laboratory of Earth Surface Processes and
   Intelligent Simulation (Guangxi Teachers Education University) (No.
   GTEU-KLOP-K1704).
CR Aggarwal A, 2004, 2004 IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS DESIGN AND IMPLEMENTATION, PROCEEDINGS, P12
   [Anonymous], P INT C IM PROC
   [Anonymous], COMP VIS PATT REC CV
   [Anonymous], 2012 IE COMP SOC C C
   [Anonymous], COMP VIS PATT REC WO
   [Anonymous], 2001, NIPS
   [Anonymous], 2011, CVPR
   [Anonymous], 2011, PROC IEEE INT C COMP
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], 2011, ABS11070169 CORR
   [Anonymous], IEEE COMP VIS PATT R
   [Anonymous], IEEE C COMP VIS PATT
   Brand M., 1997, Coupled hidden markov models for modeling interacting processes
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Crawford G. P., 1997, Journal of the Society for Information Display, V5, P45, DOI 10.1889/1.1985123
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Du YT, 2007, IEEE SIGNAL PROC LET, V14, P952, DOI 10.1109/LSP.2007.908035
   Edwards M, 2016, COMPUT VIS IMAGE UND, V144, P73, DOI 10.1016/j.cviu.2015.10.010
   Firman M., 2016, IEEE C COMP VIS PATT
   Fryer P. M., 1997, Journal of the Society for Information Display, V5, P49, DOI 10.1889/1.1985124
   Guo P, 2012, IEEE T CIRC SYST VID, V22, P1306, DOI 10.1109/TCSVT.2012.2199390
   Hu T, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/795360
   Kakizaki T., 1997, Journal of the Society for Information Display, V5, P57, DOI 10.1889/1.1985126
   Kong Y, 2016, IEEE T IMAGE PROCESS, V25, P167, DOI 10.1109/TIP.2015.2498410
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu YN, 2018, 2018 WRC SYMPOSIUM ON ADVANCED ROBOTICS AND AUTOMATION (WRC SARA), P1, DOI 10.1109/WRC-SARA.2018.8584214
   Mastorakis G, 2014, J REAL-TIME IMAGE PR, V9, P635, DOI 10.1007/s11554-012-0246-9
   Megavannan V., 2012, Signal Processing and Communications (SPCOM), 2012 International Conference on, P1
   Nowozin Sebastian., 2012, Action points: A representation for lowlatency online human action recognition
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Park S, 2004, MULTIMEDIA SYST, V10, P164, DOI 10.1007/s00530-004-0148-1
   Yao A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.67
   Zhang X., 1997, Journal of the Society for Information Display, V5, P61, DOI 10.1889/1.1985127
NR 33
TC 11
Z9 11
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28715
EP 28735
DI 10.1007/s11042-018-6074-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700021
DA 2024-07-18
ER

PT J
AU Li, YH
   Zhang, QY
   Wu, YZ
   Wang, ST
AF Li, Yaohui
   Zhang, Quanyou
   Wu, Yizhong
   Wang, Shuting
TI A sequential Kriging method assisted by trust region strategy for proxy
   cache size optimization of the streaming media video data due to
   fragment popularity distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surrogate model; Kriging; Proxy cache size optimization; Trust region
   strategy; Streaming media video data
ID EFFICIENT GLOBAL OPTIMIZATION; DESIGN
AB The Kriging method based on machine learning is an attractive tool. In this work, a sequential Kriging method assisted by trust region strategy (SKM-TRS) is proposed to solve unconstrained black-box problems. In this SKM-TRS, the complex and expensive objective function is approximated by Kriging model. And then, a sub-optimization problem, which is constructed by Kriging and a distance factor, is minimized by the improved trust region strategy to determine next update point during each iteration cycle. The proposed method is verified by ten well-known benchmark optimization problems and a proxy cache size optimization of the streaming media video data due to fragment popularity distribution. The final test results demonstrate the efficiency and robustness of the SKM-TRS in contrast with Efficient Global Optimization (EGO), Trust Region Implementation in Kriging-based optimization with Expected improvement (TRIKE) and an Adaptive Metamodel based Global Optimization algorithm (AMGO).
C1 [Li, Yaohui; Zhang, Quanyou] Xuchang Univ, Sch Mech & Elect Engn, Xuchang 461000, Peoples R China.
   [Wu, Yizhong; Wang, Shuting] Huazhong Univ Sci & Technol, Natl CAD Ctr, Wuhan, Hubei, Peoples R China.
C3 Xuchang University; Huazhong University of Science & Technology
RP Li, YH (corresponding author), Xuchang Univ, Sch Mech & Elect Engn, Xuchang 461000, Peoples R China.
EM liyaohui@hust.edu.cn
RI Li, Yaohui/AAM-7796-2020; Wang, Shuting/HQY-9992-2023; Chen,
   Bowen/KFB-3986-2024
OI Wang, Shuting/0000-0002-2038-9979; 
FU National Natural Science Foundation of China [51775472, 51675197,
   51575205]; National Key Technology R&D Program of China
   [2013ZX04005-011]
FX This work is supported by National Natural Science Foundation of China
   (No. 51775472, No. 51675197, No. 51575205) and also supported in part by
   the National Key Technology R&D Program of China (No. 2013ZX04005-011).
CR [Anonymous], 2014, J COMPUTATIONAL SCI, DOI DOI 10.1016/j.jocs.2014.04.005
   [Anonymous], 2008, ENCY STAT QUALITY RE
   [Anonymous], 27 ACM S PRINC DISTR
   [Anonymous], J GLOB OPTIM
   [Anonymous], OPTIMIZATION WELDING
   [Anonymous], 2012, INTERPOLATION SPATIA
   [Anonymous], AER SCI M
   [Anonymous], SEQUENTIAL KRIGING O
   Arlitt M, 2000, PERF E R SI, V27, P3, DOI [10.1145/362883.362920, 10.1145/346000.346003]
   Byrd RH, 2000, MATH PROGRAM, V89, P149, DOI 10.1007/PL00011391
   Cassioli A, 2013, J GLOBAL OPTIM, V57, P177, DOI 10.1007/s10898-011-9834-7
   Gould NIM, 2005, SIAM J OPTIMIZ, V16, P341, DOI 10.1137/040603851
   Han ZH, 2017, AIAA J, V55, P4330, DOI 10.2514/1.J055842
   Hassan AKSO, 2015, J ADV RES, V6, P915, DOI 10.1016/j.jare.2014.08.009
   Jamil Momin, 2013, International Journal of Mathematical Modelling and Numerical Optimisation, V4, P150
   Jie HX, 2015, ENG OPTIMIZ, V47, P1459, DOI 10.1080/0305215X.2014.979814
   Jones DR, 1998, J GLOBAL OPTIM, V13, P455, DOI 10.1023/A:1008306431147
   Kanazaki M, 2013, PROCEDIA ENGINEER, V67, P85, DOI 10.1016/j.proeng.2013.12.008
   KRIGE DG, 1994, J S AFR I MIN METALL, V94, P95
   Kuhnt S, 2010, ASTA-ADV STAT ANAL, V94, P307, DOI 10.1007/s10182-010-0143-0
   Laherrere J, 1998, EUR PHYS J B, V2, P525, DOI 10.1007/s100510050276
   Li YH, 2017, J GLOBAL OPTIM, V67, P343, DOI 10.1007/s10898-016-0455-z
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Nocedal J., 1999, Sequential Quadratic Programming, P526, DOI [DOI 10.1007/0-387-22742-3_18, 10.1007/0-387-22742-3_18]
   Regis RG, 2016, ENG OPTIMIZ, V48, P1037, DOI 10.1080/0305215X.2015.1082350
   Rodriguez JF, 1998, J MECH DESIGN, V120, P58, DOI 10.1115/1.2826677
   Santner T. J., 2013, The design and analysis of computer experiments
   Venkataramani A, 2002, COMPUT COMMUN, V25, P367, DOI 10.1016/S0140-3664(01)00408-X
   Wang GG, 2001, ENG OPTIMIZ, V33, P707, DOI 10.1080/03052150108940940
NR 29
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28737
EP 28756
DI 10.1007/s11042-018-6563-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700022
DA 2024-07-18
ER

PT J
AU Sang, LF
   Zhao, X
   Ding, GG
AF Sang, Liufang
   Zhao, Xin
   Ding, Guiguang
TI MEIAH: Mixing explicit and implicit formulation of attributes in binary
   representation for person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Convolutional neural networks; Deep hashing;
   Pedestrian attribute
ID NETWORK
AB Person Re-identification (ReID) is an important yet challenging task in computer vision. It is far from solved due to the diverse background clutters, variations on viewpoints and body poses. On top of it, effective fast re-identification with binary representation is far more challenging. In this context, how to extract discriminative and robust binary features for identifying people in a large gallery is the core problem. It is observed that the pedestrian attribute labels can be good auxiliary information for learning better features for ReID task, but in most of the application scenarios we do not have the labeled training set with both pedestrian ID and attributes. In this paper, we first introduce a multi-task training method with data from target domain and auxiliary domain with different label types that is able to Mix Explicit and Implicit Attributes for Hashing (MEIAH). MEIAH is a novel end-to-end multi-task model to learn a mixed binary representation with explicit and implicit formulation of attributes for better ReID performance. Our architecture effectively unifies and takes full advantage of information from different domains. We evaluate the proposed method in four different bit lengths on two public benchmark datasets, including CUHK03 and Market-1501. Extensive experimental results show that the proposed method is effective and achieves the state-of-the-art results.
C1 [Sang, Liufang; Zhao, Xin; Ding, Guiguang] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Ding, GG (corresponding author), Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
EM slf12thuss@163.com; zhaoxin19@gmail.com; dinggg@tsinghua.edu.cn
RI Ding, Guiguang/KIL-3528-2024; Xin, Zhao/AFZ-5025-2022
OI Sang, Liufang/0000-0003-3998-8514
CR [Anonymous], 2012, P INT C NEUR INF PRO
   [Anonymous], 2008, NIPS
   [Anonymous], 2014, BRIT MACH VIS C BMVC
   [Anonymous], 2018, ARXIV180207938
   [Anonymous], 2015, INT C BIOM ICB 2015
   [Anonymous], 2009, NIPS
   Cao Y, 2016, AAAI CONF ARTIF INTE, P3457
   Chen JX, 2017, PROC CVPR IEEE, P5330, DOI 10.1109/CVPR.2017.566
   Chen WH, 2017, AAAI CONF ARTIF INTE, P3988
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Cheng ZY, 2016, SIGNAL PROCESS, V124, P13, DOI 10.1016/j.sigpro.2015.10.037
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   Deng Y, 2015, LEARNING RECOGNIZE P
   Deng YB, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P789, DOI 10.1145/2647868.2654966
   Fabbri M, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Feng Zheng, 2016, PROC 25 INT JOINT C
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong Y, 2013, ITERATIVE QUANTIZATI
   He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378
   Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024
   Hou ZJ, 2015, PROCEEDINGS OF 2015 INTERNATIONAL SYMPOSIUM - SAFETY AND HIGH EFFICIENCY MINING IN COAL, P3
   Jaha ES, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Jian Wang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2612, DOI 10.1109/ICCV.2017.283
   Jin ZM, 2014, IEEE T CYBERNETICS, V44, P1362, DOI 10.1109/TCYB.2013.2283497
   Kang J, 2012, TEXT BIOENG INFORM S, P120, DOI 10.3993/tbis2012016
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li DW, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P111, DOI 10.1109/ACPR.2015.7486476
   Li H, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P415, DOI [10.1109/CIS.2016.0101, 10.1109/CIS.2016.100]
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   LI Y, 2017, PROC CVPR IEEE, P4438, DOI [DOI 10.1109/CVPR.2017.472, DOI 10.1109/CVPR.2017.199]
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Lin Y, 2017, ARXIV170307220 CORR
   Liu C, 2012, COMPUTER VISION EC 1
   Liu F, 2017, PROC CVPR IEEE, P4160, DOI 10.1109/CVPR.2017.443
   Liu S, 2016, ACCURATE DEEP REPRES
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Liu X, 2012, PATTERN RECOGN, V45, P4204, DOI 10.1016/j.patcog.2012.05.019
   Liu Z, 2018, ARXIV18031091 CORR
   Norouzi M.E., 2011, ICML
   Peng P, 2016, COMP VIS ECCV 2016 1
   Qian XL, 2017, IEEE I CONF COMP VIS, P5409, DOI 10.1109/ICCV.2017.577
   Shen F, 2015, HASHING NONLINEAR MA
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Shi ZY, 2015, PROC CVPR IEEE, P4184, DOI 10.1109/CVPR.2015.7299046
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Su C, 2018, IEEE T PATTERN ANAL, V40, P1167, DOI 10.1109/TPAMI.2017.2679002
   Su C, 2017, PATTERN RECOGN, V66, P4, DOI 10.1016/j.patcog.2017.01.006
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Sudowe Patrick, 2015, ICCV, P87
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Varior RR, 2016, COMP VIS ECCV 2016 1, P791
   Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976
   Wu L., 2016, ARXIV160107255
   Wu L, 2018, COMPUT VIS IMAGE UND, V167, P63, DOI 10.1016/j.cviu.2017.11.009
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xie L, 2017, DYNAMIC MULTIVIEW HA
   Xu B., 2013, International Joint Conference on Artificial Intelligence, P1820
   Zhang GF, 2010, PROCEEDINGS OF THE 7TH NATIONAL CONFERENCE ON CHINESE FUNCTIONAL MATERIALS AND APPLICATIONS (2010), VOLS 1-3, P1127
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang PC, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P173, DOI 10.1145/2600428.2609600
   Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315
   Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao R, 2017, IEEE T PATTERN ANAL, V39, P356, DOI 10.1109/TPAMI.2016.2544310
   Zhao X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3511
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
   Zhu FQ, 2017, IEEE T IMAGE PROCESS, V26, P4806, DOI 10.1109/TIP.2017.2695101
   Zhu L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P726, DOI 10.1145/3123266.3123301
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
NR 79
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27533
EP 27551
DI 10.1007/s11042-019-07743-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000034
DA 2024-07-18
ER

PT J
AU Tomar, MS
   Shukla, PK
AF Tomar, Mohit Singh
   Shukla, Piyush Kumar
TI Energy Efficient Gravitational Search Algorithm and Fuzzy Based
   Clustering With Hop Count Based Routing For Wireless Sensor Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustering; Gravitational search algorithm (GSA); Supercluster head
   (SCH); Fuzzy inference system (FIS); Hop count
ID SINK
AB In Wireless sensor networks, energy efficiency is the significant attribute to be improved. Clustering is the major technique to enhance energy efficiency. Using this technique, sensor nodes in the network region are grouped as several clusters and cluster head (CH) is chosen for each and every cluster. This CH gathers data packet from the non-CH members inside the cluster and forwards the collected data packet to the base station. However, the CH may drain its energy after a number of transmissions. So, we present the Energy efficient Gravitational search algorithm (GSA) and Fuzzy based clustering with Hop count based routing for WSN in this paper. Initially, CH is selected using Gravitational Search Algorithm (GSA), based on its weight sensor nodes are joined to the CH and thus cluster is formed. Among the selected CHs in the network, supercluster head (SCH) is selected using a fuzzy inference system (FIS). This selected SCH gathers the data packet from all CHs and forwards it to the sink or base station. For transmission, the efficient route is established based on the hop count of the sensor nodes. Simulation results show that the performance of our proposed approach is superior to the existing work in terms of delivery ratio and energy efficiency.
C1 [Tomar, Mohit Singh] Shri Jagdishprasad Jhabarmal Tibrewala Univ, Comp Sci & Engn, Churela, India.
   [Shukla, Piyush Kumar] UIT RGPV Bhopal, Dept Comp Sci & Engn, Bhopal, India.
C3 Rajiv Gandhi Technological University
RP Tomar, MS (corresponding author), Shri Jagdishprasad Jhabarmal Tibrewala Univ, Comp Sci & Engn, Churela, India.
EM mohit12867@gmail.com
RI Tomar, Mohit Singh/GLR-6517-2022; user, user/GLQ-6797-2022; Shukla, Dr.
   Piyush Kumar/GVT-3949-2022; SHukla, Piyush Kumar/AAB-3521-2021; Shukla,
   Piyush Kumar/AAA-1785-2020
OI Shukla, Dr. Piyush Kumar/0000-0002-3715-3882; SHukla, Piyush
   Kumar/0000-0002-3715-3882; 
CR [Anonymous], NEURAL COMPUTING APP
   [Anonymous], 2016 INT C DISTR COM
   [Anonymous], TELKOMNIKA INDONESIA
   [Anonymous], INT J ENG COMPUTER S
   [Anonymous], 2015, TELECOMMUNICATION SY
   [Anonymous], 2016, INT J SCI RES IJSR
   [Anonymous], WIRELESS PERSONAL CO
   [Anonymous], SOFT COMPUTING
   Arebi L, 2012, J PHYS CONF SER, V364, DOI 10.1088/1742-6596/364/1/012049
   Chowdhury C, 2018, WIRELESS PERS COMMUN, V98, P1331, DOI 10.1007/s11277-017-4921-9
   Ghosh K, 2018, WIRELESS PERS COMMUN, V98, P1083, DOI 10.1007/s11277-017-4909-5
   Gupta SK, 2015, WIRELESS PERS COMMUN, V83, P2403, DOI 10.1007/s11277-015-2535-7
   Han GH, 2018, WIRELESS PERS COMMUN, V98, P1171, DOI 10.1007/s11277-017-4914-8
   Karaboga D, 2012, WIREL NETW, V18, P847, DOI 10.1007/s11276-012-0438-z
   Logambigai R, 2016, WIREL NETW, V22, P945, DOI 10.1007/s11276-015-1013-1
   Mottaghi S, 2015, AEU-INT J ELECTRON C, V69, P507, DOI 10.1016/j.aeue.2014.10.021
   Muthukumaran K, 2018, COMPUT ELECTR ENG, V69, P642, DOI 10.1016/j.compeleceng.2017.10.007
   Qu MZ, 2014, APPL MECH MATER, V538, P498, DOI 10.4028/www.scientific.net/AMM.538.498
   Sahoo RR, 2016, NAT COMPUT, V15, P423, DOI 10.1007/s11047-015-9491-8
   Tawalbeh L, 2017, PROCEDIA COMPUT SCI, V109, P1116, DOI 10.1016/j.procs.2017.05.441
   Wang TS, 2018, J SYST SOFTWARE, V146, P196, DOI 10.1016/j.jss.2018.09.067
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Zheng J, 2014, FUTURE GENER COMP SY, V39, P88, DOI 10.1016/j.future.2013.12.014
NR 24
TC 21
Z9 21
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27849
EP 27870
DI 10.1007/s11042-019-07844-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000048
DA 2024-07-18
ER

PT J
AU Almajali, S
   Abou-Tair, DEI
   Salameh, HB
   Ayyash, M
   Elgala, H
AF Almajali, Sufyan
   Abou-Tair, Dhiah el Diehn I.
   Salameh, Haythem Bany
   Ayyash, Moussa
   Elgala, Hany
TI A distributed multi-layer MEC-cloud architecture for processing large
   scale IoT-based multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia applications; Mobile edge computing; IoT; Context-aware
   computing; Cloud computing; Mobile sensors
ID INTERNET
AB The enormous growth of the Internet of Things (IoT) devices gave governments, businesses, and individual users new means to accomplish their missions. Several IoT applications require deployment at a large scale such as smart cities. Large-scale IoT applications help achieve better monitoring services and more efficient cities. IoT multimedia (IoTMM) applications provide a unique level of intelligence that cannot be obtained with traditional IoT applications. IoTMM applications intensely consume bandwidth, processing, and storage resources compared to traditional IoT applications. IoT nodes vary in their capabilities, where some nodes have high processing capabilities while others do not. Cloud services models (IaaS, PaaS, and SaaS) provide a perfect solution for applications of high demand for resources. However, such models are inefficient when dealing with multimedia applications due to the high bandwidth requirements before reaching the cloud. Mobile edge computing (MEC) model creates a new level of providers according to the proximity of the end users to the network resources. Edge providers can offload some processing that is usually done at the cloud, which improves the overall performance of cloud-based applications. In this paper, we propose a new distributed structure for processing multimedia applications in the cloud, where different layers of processing and providers are involved. Every layer is responsible for a specific role depending on the type of the multimedia application and multimedia device. The major contribution of the proposed architecture includes two main elements: the support of scalable IoTMM applications in large deployment scenarios and the support of effective multimedia information sharing. The proposed architecture supports a scalable architecture for IoTMM applications with minimum additional resources compared to the traditional models. The proposed model allows for effective and practical sharing of multimedia information (raw multimedia data or features extracted from multimedia data). In addition, the proposed architecture provides applications with the ability of accessing intelligent multimedia information and services with minimum software development efforts. We support our claims with detailed simulation results and analysis.
C1 [Almajali, Sufyan] Princess Sumaya Univ Technol, Dept Comp Sci, Amman, Jordan.
   [Abou-Tair, Dhiah el Diehn I.] German Jordanian Univ, Dept Comp Sci, Amman, Jordan.
   [Salameh, Haythem Bany] Yarmouk Univ, Dept Telecommun Engn, Irbid, Jordan.
   [Ayyash, Moussa] Chicago State Univ, Dept Informat Studies, Chicago, IL 60628 USA.
   [Elgala, Hany] SUNY Albany, Dept Elect Engn, Albany, NY 12222 USA.
C3 Princess Sumaya University for Technology; German-Jordanian University;
   Yarmouk University; Chicago State University; State University of New
   York (SUNY) System; State University of New York (SUNY) Albany
RP Salameh, HB (corresponding author), Yarmouk Univ, Dept Telecommun Engn, Irbid, Jordan.
EM haythem@yu.edu.jo
RI Abou-Tair, Dhiah el Diehn I./AAE-8866-2020; Salameh, Haythem
   Bany/Y-1223-2018; Elgala, Hany/Y-5175-2019; ALMAJALI,
   SUFYAN/AAI-5175-2020
OI Abou-Tair, Dhiah el Diehn I./0000-0002-8643-5392; Salameh, Haythem
   Bany/0000-0003-3429-7212; Elgala, Hany/0000-0002-7098-9278; ALMAJALI,
   SUFYAN/0000-0001-9076-3519; Ayyash, Moussa/0000-0003-0868-143X
CR Almajali S, 2018, 2018 THIRD INTERNATIONAL CONFERENCE ON FOG AND MOBILE EDGE COMPUTING (FMEC), P58, DOI 10.1109/FMEC.2018.8364045
   Almajali S, 2017, 2017 SECOND INTERNATIONAL CONFERENCE ON FOG AND MOBILE EDGE COMPUTING (FMEC), P133, DOI 10.1109/FMEC.2017.7946420
   Alvi SA, 2015, AD HOC NETW, V33, P87, DOI 10.1016/j.adhoc.2015.04.006
   Anagnostopoulos C, 2007, MOBIMEDIA 07
   Anagnostopoulos C, 2011, IEEE T MOBILE COMPUT, V10, P1710, DOI 10.1109/TMC.2011.19
   Assunçao MD, 2012, INT CONF UTIL CLOUD, P255, DOI 10.1109/UCC.2012.33
   Badidi E., 2011, 2011 International Conference on Innovations in Information Technology (IIT), P35, DOI 10.1109/INNOVATIONS.2011.5893849
   Balan T, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/6965028
   BOLCHINI C., 2006, MDM '06, P5
   Forkan A, 2014, FUTURE GENER COMP SY, V35, P114, DOI 10.1016/j.future.2013.07.009
   Grasa E, 2017, 2017 IEEE CONFERENCE ON NETWORK FUNCTION VIRTUALIZATION AND SOFTWARE DEFINED NETWORKS (NFV-SDN), P192
   Hyun Jung La, 2010, 2010 IEEE 3rd International Conference on Cloud Computing (CLOUD 2010), P466, DOI 10.1109/CLOUD.2010.78
   Min JK, 2012, EXPERT SYST APPL, V39, P8655, DOI 10.1016/j.eswa.2012.01.200
   Moore P, 2014, 2014 EIGHTH INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT AND SOFTWARE INTENSIVE SYSTEMS (CISIS),, P379, DOI 10.1109/CISIS.2014.53
   Moradeyo Otebolaku Abayomi, 2014, 2014 2nd IEEE International Conference on Mobile Cloud Computing, Services and Engineering (MobileCloud), P109, DOI 10.1109/MobileCloud.2014.26
   Mowafi Yaser, 2014, P 3 INT C CONT AW SY, P147
   Nordrum A, 2016, IEEE SPECTRUM, V53, P12, DOI 10.1109/MSPEC.2016.7572524
   Okwuibe J., 2018, A Comprehensive Guide to 5G Security, P373
   Pyattaev A, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE WORKSHOPS (WCNCW), P135, DOI 10.1109/WCNCW.2013.6533328
   Said O, 2017, IEEE ACCESS, V5, P16757, DOI 10.1109/ACCESS.2017.2726902
   Salameh HAB, 2018, IEEE INTERNET THINGS, V5, P1904, DOI 10.1109/JIOT.2018.2817339
   Wang L, 2013, 2013 9TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P323, DOI 10.1109/CIS.2013.75
   Wang Qi., 2017, INT J ANTENN PROPAG, V2017, P1, DOI [DOI 10.1109/GIOTS.2017.8016221, 10.1155/2017/2961090, DOI 10.1155/2017/2961090]
   Wang W, 2017, IEEE INTERNET THINGS, V4, P487, DOI 10.1109/JIOT.2016.2578722
NR 24
TC 13
Z9 14
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24617
EP 24638
DI 10.1007/s11042-018-7049-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900044
DA 2024-07-18
ER

PT J
AU Chakraborty, S
   Singh, SK
   Chakraborty, P
AF Chakraborty, Soumendu
   Singh, Satish Kumar
   Chakraborty, Pavan
TI Cascaded asymmetric local pattern: a novel descriptor for unconstrained
   facial image recognition and retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local pattern descriptors; Local binary pattern (LBP); Center symmetric
   local binary pattern (CSLBP); Center symmetric local ternary pattern
   (CSLTP); Local directional gradient pattern (LDGP); Cascaded asymmetric
   local pattern (CALP); face recognition; image retrieval
ID PRINCIPAL COMPONENT ANALYSIS; FACE-RECOGNITION; DISCRIMINANT-ANALYSIS;
   PCA; REPRESENTATION
AB Feature description is one of the most frequently studied areas in the expert systems and machine learning. Effective encoding of the images is an essential requirement for accurate matching. These encoding schemes play a significant role in recognition and retrieval systems. Facial recognition systems should be effective enough to accurately recognize individuals under intrinsic and extrinsic variations of the system. The templates or descriptors used in these systems encode spatial relationships of the pixels in the local neighbourhood of an image. Features encoded using these hand crafted descriptors should be robust against variations such as; illumination, background, poses, and expressions. In this paper a novel hand crafted cascaded asymmetric local pattern (CALP) is proposed for retrieval and recognition facial image. The proposed descriptor uniquely encodes relationship amongst the neighbouring pixels in horizontal and vertical directions. The proposed encoding scheme has optimum feature length and shows significant improvement in accuracy under environmental and physiological changes in a facial image. State of the art hand crafted descriptors namely; LBP, LDGP, CSLBP, SLBP and CSLTP are compared with the proposed descriptor on most challenging datasets namely; Caltech-face, LFW, Colour-FERET, and CASIA-face-v5. Result analysis shows that, the proposed descriptor outperforms state of the art under uncontrolled variations in expressions, background, pose and illumination.
C1 [Chakraborty, Soumendu] Indian Inst Informat Technol, Lucknow, Uttar Pradesh, India.
   [Singh, Satish Kumar] Indian Inst Informat Technol, Allahabad, Uttar Pradesh, India.
   [Chakraborty, Pavan] IIIT Allahabad, Dept Informat Technol, Allahabad, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad; Indian Institute
   of Information Technology Allahabad
RP Chakraborty, S (corresponding author), Indian Inst Informat Technol, Lucknow, Uttar Pradesh, India.
EM soum.uit@gmail.com; sk.singh@iiita.ac.in; pavan@iiita.ac.in
RI Singh, Dr Satish Kumar/JMP-6186-2023; Chakraborty,
   Soumendu/ABA-2031-2020; singh, satish/U-7158-2018
OI Singh, Dr Satish Kumar/0000-0003-1991-7727; Chakraborty,
   Soumendu/0000-0002-8778-8229; singh, satish/0000-0002-8536-4991;
   chakraborty, pavan/0000-0002-9260-1131
CR Ahmad Radzi S., 2014, International journal of engineering and Technology, V6, P44
   [Anonymous], LABELED FACES WILD D
   [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], PATTERN RECOGN LETT
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chakraborty S, 2018, IEEE T CIRC SYST VID, V28, P171, DOI 10.1109/TCSVT.2016.2603535
   Chakraborty S, 2017, COMPUT ELECTR ENG, V62, P92, DOI 10.1016/j.compeleceng.2017.06.013
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P1201, DOI 10.1007/s11042-015-3111-6
   Chakraborty S, 2018, MICROSYST TECHNOL, V24, P4807, DOI 10.1007/s00542-018-3885-3
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Gao Z, 2018, J VIS COMMUN IMAGE R, V56, P305, DOI 10.1016/j.jvcir.2018.10.007
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gavrielides MA, 2006, IEEE T MULTIMEDIA, V8, P740, DOI 10.1109/TMM.2006.876290
   Gupta R, 2010, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2010.5540195
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Jeong K, 2015, IEEE SIGNAL PROC LET, V22, P1400, DOI 10.1109/LSP.2014.2372762
   Kong H, 2005, NEURAL NETWORKS, V18, P585, DOI 10.1016/j.neunet.2005.06.041
   Lu K, 2015, IEEE T IMAGE PROCESS, V24, P1449, DOI 10.1109/TIP.2015.2395961
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Noushath S, 2006, NEUROCOMPUTING, V69, P1711, DOI 10.1016/j.neucom.2006.01.012
   Noushath S, 2006, PATTERN RECOGN, V39, P1396, DOI 10.1016/j.patcog.2006.01.018
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tommasi T, 2015, LECT NOTES COMPUT SC, V9358, P504, DOI 10.1007/978-3-319-24947-6_42
   TORRALBA A, 2011, PROC CVPR IEEE, P1521, DOI DOI 10.1109/CVPR.2011.5995347
   Xie XD, 2006, IEEE T IMAGE PROCESS, V15, P2481, DOI 10.1109/TIP.2006.877435
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
   Zhang DQ, 2006, PATTERN RECOGN, V39, P140, DOI 10.1016/j.patcog.2005.08.002
NR 39
TC 11
Z9 13
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 25143
EP 25162
DI 10.1007/s11042-019-7707-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900067
DA 2024-07-18
ER

PT J
AU Chen, GY
AF Chen, Guang Yi
TI An experimental study for the effects of noise on face recognition
   algorithms under varying illumination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaussian white noise; Poisson noise; salt & pepper noise; nearest
   neighbour classifier; illumination invariant; Face recognition
ID INVARIANT; IMAGE; NORMALIZATION
AB When the illumination changes, the appearance of facial images will change dramatically. Lighting changes make face recognition a very challenging and difficult job. In addition, the effects of noise on existing face recognition methods have been neglected in the literature, to the best of our knowledge. In this work, we study the effects of noise on existing illumination-invariant face recognition methods. We tested such noise as Gaussian white noise, Poisson noise, salt & pepper noise, speckle noise, etc. In total, 21 methods have been included in this study in this work. We find out that, when noise is added to facial images, Tan and Triggs' method achieves the best results for both the extended Yale B face database and the CMU-PIE face database. When facial images do not contain noise, isotropic smoothing is preferred because it obtains the highest average recognition rate (96%) for the extended Yale B face database and 16 methods obtain perfect correct recognition rates (100%) for the CMU-PIE face database.
C1 [Chen, Guang Yi] Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ H3G 1M8, Canada.
C3 Concordia University - Canada
RP Chen, GY (corresponding author), Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ H3G 1M8, Canada.
EM Guangyi_chen@hotmail.com
CR [Anonymous], 2015, 2015 IEEE INT C SIGN, DOI [DOI 10.1109/SPICES.2015.7091490, 10.1109/SPICES.2015.7091490]
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], MOL EXPRESSIONS MICR
   Chen GY, 2009, PATTERN RECOGN, V42, P2013, DOI 10.1016/j.patcog.2008.10.008
   Chen GY, 2011, OPT ENG, V50, DOI 10.1117/1.3597329
   Chen GY, 2016, P 12 INT C INT COMP
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Dewantara BSB, 2016, MACH VISION APPL, V27, P877, DOI 10.1007/s00138-016-0790-6
   Du S, 2010, IEEE T CIRC SYST VID, V20, P1165, DOI 10.1109/TCSVT.2010.2045817
   Faraji MR, 2015, IET COMPUT VIS, V9, P390, DOI 10.1049/iet-cvi.2014.0200
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Gross R, 2003, LECT NOTES COMPUT SC, V2688, P10
   Han H, 2013, PATTERN RECOGN, V46, P1691, DOI 10.1016/j.patcog.2012.11.022
   Heusch G., 2005, Lighting normalization algorithms for face verification
   Hu HF, 2015, IET COMPUT VIS, V9, P163, DOI 10.1049/iet-cvi.2013.0342
   Lai ZR, 2015, IEEE T IMAGE PROCESS, V24, P1735, DOI 10.1109/TIP.2015.2409988
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Liu Y, 2016, 3RD INTERNATIONAL CONFERENCE ON EDUCATION REFORM AND MODERN MANAGEMENT, 2016, P201
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Nikan S, 2015, IET IMAGE PROCESS, V9, P12, DOI 10.1049/iet-ipr.2013.0792
   OPPENHEI.AV, 1968, PR INST ELECTR ELECT, V56, P1264, DOI 10.1109/PROC.1968.6570
   Park YK, 2008, SIGNAL PROCESS, V88, P1929, DOI 10.1016/j.sigpro.2008.01.028
   Roy H, 2016, IEEE T INFORM FORENS, V11
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Struc V, 2009, LECT NOTES COMPUT SC, V5707, P1, DOI 10.1007/978-3-642-04391-8_1
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Wang B, 2011, IEEE SIGNAL PROC LET, V18, P462, DOI 10.1109/LSP.2011.2158998
   Wang HT, 2004, IEEE IMAGE PROC, P1397
   Xie XH, 2011, IEEE T IMAGE PROCESS, V20, P1807, DOI 10.1109/TIP.2010.2097270
   Zhang TP, 2009, PATTERN RECOGN, V42, P251, DOI 10.1016/j.patcog.2008.03.017
   Zhang TP, 2009, IEEE T IMAGE PROCESS, V18, P2599, DOI 10.1109/TIP.2009.2028255
   Zou X, 2007, 2007 FIRST IEEE INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P113
NR 35
TC 6
Z9 6
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26615
EP 26631
DI 10.1007/s11042-019-07810-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700059
DA 2024-07-18
ER

PT J
AU El Bahi, H
   Zatni, A
AF El Bahi, Hassan
   Zatni, Abdelkarim
TI Text recognition in document images obtained by a smartphone based on
   deep convolutional and recurrent neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text recognition; Document image; Smartphone; Convolutional neural
   network; Recurrent neural network
ID ICDAR2015 COMPETITION; BIDIRECTIONAL LSTM; SEGMENTATION; CLASSIFICATION;
   SEQUENCE; MODELS; VIDEO
AB Automatic text recognition in document images is an important task in many real-world applications. Several systems have been proposed to accomplish this task. However, a little attention has been given to document images obtained by mobile phones. To meet this need, we propose a new system that integrates preprocessing, features extraction and classification in order to recognize text contained in the document images acquired by a smartphone. The preprocessing phase is applied to locate the text region, and then segment that region into text line images. In the second phase, a sliding window divides the text-line image into a sequence of frames; afterwards a deep convolutional neural network (CNN) model is used to extract features from each frame. Finally, an architecture that combines the bidirectional recurrent neural network (RNN), the gated recurrent units (GRU) block and the connectionist temporal classification (CTC) layer is explored to ensure the classification phase. The proposed system has been tested on the ICDAR2015 Smartphone document OCR dataset and the experimental results show that the proposed system is capable to achieve promising recognition rates.
C1 [El Bahi, Hassan; Zatni, Abdelkarim] Ibnou Zohr Univ, Lab Metrol & Informat Proc, Agadir, Morocco.
   [El Bahi, Hassan] Cadi Ayyad Univ, Lab Appl Math & Comp Sci, Marrakech, Morocco.
C3 Ibn Zohr University of Agadir; Cadi Ayyad University of Marrakech
RP El Bahi, H (corresponding author), Ibnou Zohr Univ, Lab Metrol & Informat Proc, Agadir, Morocco.; El Bahi, H (corresponding author), Cadi Ayyad Univ, Lab Appl Math & Comp Sci, Marrakech, Morocco.
EM hassan.elbahi@edu.uiz.ac.ma
CR Ahmad I, 2013, PROC INT CONF DOC, P658, DOI 10.1109/ICDAR.2013.135
   [Anonymous], 2017, CHIN J OCEANOL LIMNO
   [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], INT REV COMPUTERS SO
   [Anonymous], 2008, Advances in Neural Information Processing Systems
   [Anonymous], 2017, NEURAL COMPUT APPL
   [Anonymous], 2017, INT J TOMOGRAPHY SIM
   Antonacopoulos A, 2015, PROC INT CONF DOC, P1151, DOI 10.1109/ICDAR.2015.7333941
   Banumathi KL, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER AND OPTIMIZATION TECHNIQUES (ICEECCOT), P196, DOI 10.1109/ICEECCOT.2016.7955214
   Bertolami R, 2008, PATTERN RECOGN, V41, P3452, DOI 10.1016/j.patcog.2008.04.003
   Bukhari SS, 2011, PROC SPIE, V7874, DOI 10.1117/12.873461
   Burie JC, 2015, PROC INT CONF DOC, P1161, DOI 10.1109/ICDAR.2015.7333943
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Castro DMR, 2015, PROC INT CONF DOC, P156, DOI 10.1109/ICDAR.2015.7333743
   Chung J., 2014, NIPS 2014 WORKSH DEE
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Eskenazi S, 2017, PATTERN RECOGN, V64, P1, DOI 10.1016/j.patcog.2016.10.023
   España-Boquera S, 2011, IEEE T PATTERN ANAL, V33, P767, DOI 10.1109/TPAMI.2010.141
   Gllavata J, 2004, INT C PATT RECOG, P425, DOI 10.1109/ICPR.2004.1334146
   Granell E, 2018, J IMAGING, V4, DOI 10.3390/jimaging4010015
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A., 2006, P 23 INT C MACHINE L, P369
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33
   Keysers D, 2007, IEEE T PATTERN ANAL, V29, P1422, DOI 10.1109/TPAMI.2007.1153
   Keysers D, 2017, IEEE T PATTERN ANAL, V39, P1180, DOI 10.1109/TPAMI.2016.2572693
   Khare V, 2015, EXPERT SYST APPL, V42, P7627, DOI 10.1016/j.eswa.2015.06.002
   Kim BS, 2015, PATTERN RECOGN, V48, P3600, DOI 10.1016/j.patcog.2015.04.026
   Kozielski M, 2013, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2013.190
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Liang J., 2005, International Journal on Document Analysis and Recognition, V7, P84, DOI 10.1007/s10032-004-0138-z
   Liu CS, 2015, INT J DOC ANAL RECOG, V18, P111, DOI 10.1007/s10032-014-0233-8
   Liu XQ, 2015, MULTIMED TOOLS APPL, V74, P4891, DOI 10.1007/s11042-013-1848-3
   Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004
   Maalej R, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P417, DOI 10.1109/DAS.2016.49
   Messina Ronaldo, 2015, 2015 13th International Conference on Document Analysis and Recognition (ICDAR), P171, DOI 10.1109/ICDAR.2015.7333746
   Morillot O, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.2.023028
   Nagabhushan P., 2010, International Journal of Computer Science and Engineering, V2, P907
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Namboodiri AM, 2007, ADV PATTERN RECOGNIT, P29, DOI 10.1007/978-1-84628-726-8_2
   Nayef N, 2015, PROC INT CONF DOC, P1231, DOI 10.1109/ICDAR.2015.7333960
   Naz S, 2016, NEUROCOMPUTING, V177, P228, DOI 10.1016/j.neucom.2015.11.030
   Razak Z, 2008, INT J COMPUT SCI NET, V8, P12
   Rehman A, 2014, ARTIF INTELL REV, V42, P253, DOI 10.1007/s10462-012-9337-z
   Retsinas G, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P411, DOI 10.1109/DAS.2016.61
   Roy PP, 2016, PATTERN RECOGN, V60, P1057, DOI 10.1016/j.patcog.2016.04.012
   Saha S, 2015, MULTIMED TOOLS APPL, V74, P10621, DOI 10.1007/s11042-014-2196-7
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shekar BH, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P280, DOI 10.1109/ICSIP.2014.50
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Smith Raymond W., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P241, DOI 10.1109/ICDAR.2009.257
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Su B, 2014, INT C INTEL HUM MACH, P300, DOI 10.1109/IHMSC.2014.80
   Sueiras J, 2018, NEUROCOMPUTING, V289, P119, DOI 10.1016/j.neucom.2018.02.008
   Tang YB, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P365, DOI 10.1109/DAS.2014.14
   Tran TA, 2016, INT J DOC ANAL RECOG, V19, P191, DOI 10.1007/s10032-016-0265-3
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Wang XB, 2017, MULTIMED TOOLS APPL, V76, P26201, DOI 10.1007/s11042-016-4099-2
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Yan C, 2018, IEEE Trans Multimedia Early Access
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yin XC, 2016, IEEE T IMAGE PROCESS, V25, P2752, DOI 10.1109/TIP.2016.2554321
   Yousfi S, 2017, PATTERN RECOGN, V64, P245, DOI 10.1016/j.patcog.2016.11.011
   Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0
   Zhu YP, 2017, IET IMAGE PROCESS, V11, P455, DOI 10.1049/iet-ipr.2016.0914
NR 69
TC 17
Z9 19
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26453
EP 26481
DI 10.1007/s11042-019-07855-z
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700053
DA 2024-07-18
ER

PT J
AU He, ZL
   Ho, CH
AF He, Zhilin
   Ho, Chun-Hsing
TI An improved clustering algorithm based on finite Gaussian mixture model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaussian mixture model; EM algorithm; Cluster analysis
ID LIKELIHOOD
AB The Finite Gaussian Mixture Model (FGMM) is the most commonly used model for describing mixed density distribution in cluster analysis. An important feature of the FGMM is that it can infinitely approximate any continuous distribution, as long as the model contains enough number of components. In the clustering analysis based on the FGMM, the EM algorithm is usually used to estimate the parameters of the model. The advantage is that the computation is stable and the convergence speed is fast. However, the EM algorithm relies heavily on the estimation of incomplete data. It does not use any information to reduce the uncertainty of missing data. To solve this problem, an EM algorithm based on entropy penalized maximum likelihood estimation is proposed. The novel algorithm constructs the conditional entropy model between incomplete data and missing data, and reduces the uncertainty of missing data through incomplete data. Theoretical analysis and experimental results show that the novel algorithm can effectively adapt to the FGMM, improve the clustering results and improve the efficiency of the algorithm.
C1 [He, Zhilin] Yuncheng Univ, Math & Informat Technol Sch, 1155 Fudan West St, Yuncheng, Shanxi, Peoples R China.
   [Ho, Chun-Hsing] No Arizona Univ, Dept Civil Engn Construct Management & Environm E, POB 15600, Flagstaff, AZ 86011 USA.
C3 Yuncheng University; Northern Arizona University
RP He, ZL (corresponding author), Yuncheng Univ, Math & Informat Technol Sch, 1155 Fudan West St, Yuncheng, Shanxi, Peoples R China.
EM ycuhezhilin@126.com; chun-hsing.ho@nau.edu
FU National Natural Science Foundation of China [11241005]
FX This research was supported by National Natural Science Foundation of
   China(11241005).
CR Alfò M, 2008, STAT COMPUT, V18, P137, DOI 10.1007/s11222-007-9044-9
   [Anonymous], IEEE ACM T COMPUTATI
   [Anonymous], ICMR
   [Anonymous], P ANN M ASS COMP LIN
   [Anonymous], 2013, J INFORM COMPUT SCI
   [Anonymous], TECHNOMETRICS
   [Anonymous], TOIS
   Attorre F, 2014, FOLIA GEOBOT, V49, P313, DOI 10.1007/s12224-012-9139-8
   Biernacki C, 2003, COMPUT STAT DATA AN, V41, P561, DOI 10.1016/S0167-9473(02)00163-9
   Cheng Z., 2017, IJCAI
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Li J, 2018, IEEE Transactions on Cybernetics, V99, P12
   Liu AA, 2018, IEEE T CYBERNETICS, V48, P916, DOI 10.1109/TCYB.2017.2664503
   Liu Z, 2016, SIGNAL IMAGE VIDEO P, V10, P359, DOI 10.1007/s11760-015-0749-5
   Meila M., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P386
   Melnykov V, 2012, COMPUT STAT DATA AN, V56, P1381, DOI 10.1016/j.csda.2011.11.002
   Metallinou A, 2008, IEEE INT SYM MULTIM, P250, DOI 10.1109/ISM.2008.40
   Nie L., 2016, Synthesis Lectures on Information Concepts Retrieval & Services, V8, P1, DOI 10.2200/S00714ED1V01Y201603ICR048
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie WZ, 2017, IEEE T BIG DATA, V3, P458, DOI 10.1109/TBDATA.2017.2723395
   REYNOLDS D, 2009, ENCY BIOMETRICS, P93
   UEBERSAX JS, 1993, BIOMETRICS, V49, P823, DOI 10.2307/2532202
   Wang Y, 2000, IEEE T NEURAL NETWOR, V11, P625, DOI 10.1109/72.846734
   Wedel M, 2002, MARKET LETT, V13, P17, DOI 10.1023/A:1015059024154
   [俞燕 YU Yan], 2006, [应用数学, Mathematics Applicata], V19, P600
   Zhao J, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P2373, DOI 10.1109/ROBIO.2009.5420836
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
   Zhu L, 2015, IEEE T MULTIMEDIA, V17, P981, DOI 10.1109/TMM.2015.2431496
   Zhu L, 2017, IEEE PHOT SPEC CONF, P721, DOI 10.1109/PVSC.2017.8366628
NR 31
TC 9
Z9 9
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24285
EP 24299
DI 10.1007/s11042-018-6988-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900027
DA 2024-07-18
ER

PT J
AU Khan, M
   Masood, F
AF Khan, Majid
   Masood, Fawad
TI A novel chaotic image encryption technique based on multiple discrete
   dynamical maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Confusion; Diffusion; Multiple chaotic maps
ID PERMUTATION; ALGORITHM; SCHEME; CONSTRUCTION; SECURE; TRANSFORM; BOX
AB The propagation of information over insecure communication system is one of the most important aspect of digitally advance era. The electronic information is travels in form of binary bits. The secrecy of these digital contents is one of the most important issue of existing world. In this article, we have utilized multiple chaotic iterative maps in order to propose a novel image encryption technique. The suggested encryption added confusion as well as diffusion in offered scheme which is one of the most fundamental aspect of encryption technique. We have tested our anticipated scheme against different performances analysis and compared it with already existing results. The designed scheme is capable of providing an excellent privacy to digital images.
C1 [Khan, Majid; Masood, Fawad] Inst Space Technol, CISL, Islamabad, Pakistan.
   [Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
   [Masood, Fawad] Inst Space Technol, Dept Elect Engn, Islamabad, Pakistan.
RP Khan, M (corresponding author), Inst Space Technol, CISL, Islamabad, Pakistan.; Khan, M (corresponding author), Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
EM mk.cfd1@gmail.com
RI Khan, Majid/T-9408-2019; Masood, Fawad/AAW-6725-2020
OI Khan, Majid/0000-0001-5454-3770; Masood, Fawad/0000-0002-5788-4228
CR Abokhdair Nuha Omran, 2010, Proceedings of the 2010 6th International Conference on Digital Content, Multimedia Technology and its Applications (IDC 2010), P20
   Ahmad M, 2014, INT J COMMUN NETW DI, V12, P113, DOI 10.1504/IJCNDS.2014.057991
   Ahmad M, 2012, PROCEDIA ENGINEER, V38, P1055, DOI 10.1016/j.proeng.2012.06.133
   Ahmad M, 2011, COMM COM INF SC, V168, P81
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Amigó JM, 2007, PHYS LETT A, V366, P211, DOI 10.1016/j.physleta.2007.02.021
   [Anonymous], HDB RES MODERN CRYPT
   [Anonymous], COMMUNICATIONS COMPU
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2010, IJ NETWORK SECURITY
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Gupta B.B., 2019, COMPUTER CYBER SECUR, V1st, DOI DOI 10.1201/9780429424878
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Huh JH, 2019, J SUPERCOMPUT, V75, P3123, DOI 10.1007/s11227-018-2496-1
   Huh JH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082693
   Jolfaei Alireza, 2010, Proceedings of the 2010 International Conference on Artificial Intelligence and Pattern Recognition (AIPR-10), P279
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan M, 2017, MULTIMED TOOLS APPL, V76, P24027, DOI 10.1007/s11042-016-4090-y
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Khan M, 2015, NEURAL COMPUT APPL, V26, P1137, DOI 10.1007/s00521-014-1800-0
   Khan M, 2014, NONLINEAR DYNAM, V76, P377, DOI 10.1007/s11071-013-1132-0
   Khan M, 2013, NONLINEAR DYNAM, V73, P1795, DOI 10.1007/s11071-013-0904-x
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Liao X, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1982, DOI 10.1109/ICASSP.2018.8462384
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Mastan JMK, 2011, COMM COM INF SC, V193, P524
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Patidar V, 2011, OPT COMMUN, V284, P4331, DOI 10.1016/j.optcom.2011.05.028
   Rafiq A, 2019, MULTIMED TOOLS APPL, V78, P15527, DOI 10.1007/s11042-018-6953-x
   Rhouma R, 2009, CHAOS SOLITON FRACT, V40, P309, DOI 10.1016/j.chaos.2007.07.083
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Sharma M, 2014, 2014 LOUGHBOROUGH ANTENNAS AND PROPAGATION CONFERENCE (LAPC), P173, DOI 10.1109/LAPC.2014.6996349
   Wu XJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119660
   Younas I, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120913
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
NR 45
TC 113
Z9 114
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26203
EP 26222
DI 10.1007/s11042-019-07818-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700043
DA 2024-07-18
ER

PT J
AU Liu, A
   Wang, JT
   Liu, J
   Su, YT
AF Liu, Anan
   Wang, Jingting
   Liu, Jing
   Su, Yuting
TI Comprehensive image quality assessment via predicting the distribution
   of opinion score
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; Label distribution learning; Convolutional
   neural network; Support vector regressor
AB Image quality assessment is a challenge problem in image processing area. Previous works usually predict the mean opinion score (MOS) to evaluate image quality. However, it is found that the distribution of opinion scores provides richer and more precise semantics information. Therefore, in this work, we focus on the distribution of opinion scores (DOS) and aims to comprehensively evaluate image quality via automatically predicting DOS. Specifically, we first extract image features via convolutional neural network and then adopt the label distribution support vector regressor (LDSVR) algorithm to predict score distribution. To the best of our knowledge, we are the first to introduce label distribution learning approach for image quality assessment. Extensive experiments have been carried out and validate that the proposed algorithm can well predict the DOS and provide a comprehensive assessment to image quality.
C1 [Liu, Anan; Wang, Jingting; Liu, Jing; Su, Yuting] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Liu, J (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM anan0422@gmail.com; wangjingting@tju.edu.cn; jliu_tju@tju.edu.cn;
   ytsu@tju.edu.cn
RI Liu-Zeng, Jing/F-8582-2011
FU National Science Foundation of China [61701341, 61472275, 61772359,
   61572356]
FX This work was supported by the National Science Foundation of China
   under Grant 61701341, Grant 61472275, Grant 61772359, and Grant
   61572356.
CR [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], INT JOINT C ART INT
   [Anonymous], 2011, Advances in Neural Information Processing Systems
   Ciocca G, 2014, INT J DIGIT LIBRARIE, V15, P1, DOI 10.1007/s00799-014-0124-0
   Donahue J, 2014, PR MACH LEARN RES, V32
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gatys Leon A., 2015, TEXTURE SYNTHESIS US, P262
   Geng X, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3511
   Geng X, 2016, IEEE T KNOWL DATA EN, V28, P1734, DOI 10.1109/TKDE.2016.2545658
   Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51
   Guo YM, 2018, MULTIMED TOOLS APPL, V77, P10251, DOI 10.1007/s11042-017-5443-x
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jing PG, 2019, IEEE T CIRC SYST VID, V29, P1296, DOI 10.1109/TCSVT.2018.2832095
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kundu D, 2017, IEEE T IMAGE PROCESS, V26, P2957, DOI 10.1109/TIP.2017.2685941
   Larson GW, 1997, IEEE T VIS COMPUT GR, V3, P291, DOI 10.1109/2945.646233
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Muniappan R, 2009, BIOLOGICAL CONTROL OF TROPICAL WEEDS USING ARTHROPODS, P1, DOI 10.1017/CBO9780511576348.001
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Pece F., 2010, Proceedings 2010 Conference on Visual Media Production (CVMP 2010). 7th European Conference on Visual Media Production, P1, DOI 10.1109/CVMP.2010.8
   Pérez-Cruz F, 2001, ADV NEUR IN, V13, P734
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Qi SH, 2016, J VIS COMMUN IMAGE R, V40, P838, DOI 10.1016/j.jvcir.2016.08.015
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Rubin TN, 2012, MACH LEARN, V88, P157, DOI 10.1007/s10994-011-5272-5
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sánchez-Fernádez M, 2004, IEEE T SIGNAL PROCES, V52, P2298, DOI 10.1109/TSP.2004.831028
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang JD, 2011, PATTERN RECOGN, V44, P2274, DOI 10.1016/j.patcog.2010.07.015
   Xu CY, 2019, MULTIMED TOOLS APPL, V78, P573, DOI 10.1007/s11042-017-5262-0
   Xu LC, 2018, IEEE IJCNN
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zhu L, 2017, IEEE PHOT SPEC CONF, P721, DOI 10.1109/PVSC.2017.8366628
NR 46
TC 4
Z9 4
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24205
EP 24222
DI 10.1007/s11042-018-6985-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900023
DA 2024-07-18
ER

PT J
AU Mahalingam, T
   Subramoniam, M
AF Mahalingam, T.
   Subramoniam, M.
TI A trusted waterfall framework based moving object detection using
   FACO-MKFCM techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Modified kernel fuzzy c-means; Ant Colony Optimization (ACO); Fuzzy
   logic (FL); Foreground; Background; Clustering
ID TRACKING; SEGMENTATION
AB Object detection and tracking are necessary and challenging activities in several pc visual scene applications such as security, motor vehicle navigating and independent robotic navigating. Video scenery security in an energetic atmosphere, particularly for people and motor vehicles, is just one of the present difficult research study subjects in computer system vision. It is a vital modern technology to attack in opposition to violence, criminal offense and publicised security as well as for effective administration of heavy traffic. In this area, monitoring of motionless forefront objects is just one of the most essential needs for security systems based upon the monitoring of deserted or taken objects or parked motor vehicles. It is really challenging for the existing approach to efficiently identify the objects as they occur. In this research suggested an effective method, Fuzzy based Ant Colony Optimization (FACO) integrated with modified kernel fuzzy c-means algorithm (MKFCM) for object segmentation. Here FACO algorithm situates optimal initial cluster centroid for the MKFCM, thus improve all applications affiliated fuzzy clustering such as foreground segmentation in image processing. The recommended new method is intellectual and additionally dynamic clustering technique for the dividing of motion objects. After the segmentation, the object tracking can be done using particle filtering method. The morphological operation helps the particle filter to effectively track the objects. Here the flow is based on the traditional waterfall approach. From the empirical impacts, the recommended method outshines than the state of artwork. Below the suggested method attains maximum efficiency for both PETS and also Hall monitor videos when examined to the current algorithm.
C1 [Mahalingam, T.; Subramoniam, M.] Sathyabama Univ, Chennai, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology
RP Mahalingam, T (corresponding author), Sathyabama Univ, Chennai, Tamil Nadu, India.
EM lingamrajthen@gmail.com; subramaniam.viru@gmail.com
RI M, Subramoniam/A-4502-2017; Subramoniam, M/ABI-7985-2020; thangaraj,
   mahalingam/AAG-3346-2021
OI M, Subramoniam/0000-0002-3004-5141; 
CR Agarwal P, 2015, INT CONF SOFT COMP, P84, DOI 10.1109/ISCMI.2015.16
   Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Allin Christe1 S, 2010, ICTACT J IMAGE VIDEO, V1
   [Anonymous], INT J IMAGE PROCESS
   Azab MM, 2014, IET IMAGE PROCESS, V8, P794, DOI 10.1049/iet-ipr.2014.0238
   Bezdek J., 1999, FUZZY MODELS ALGORIT
   Bhaskar P.K., 2014, COMPUTER INFORM SCI, P1
   Bouguessa M, 2006, PATTERN RECOGN LETT, V27, P1419, DOI 10.1016/j.patrec.2006.01.015
   Cheng FH, 2006, PATTERN RECOGN, V39, P1126, DOI 10.1016/j.patcog.2005.12.010
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   Funmilola A. Ajala, 2012, J INFORM ENG APPL, V2
   Guler S, 2003, C COMP VIS PATT REC, P4
   Inkaya T, 2015, APPL SOFT COMPUT, V28, P301, DOI 10.1016/j.asoc.2014.11.060
   Islam S, 2013, INT J EMERGING TECHN, V3
   Jun B, 2012, PATTERN RECOGN, V45, P3304, DOI 10.1016/j.patcog.2012.02.031
   Kamal M., 2010, Inflation Targeting in Brazil, Chile, and South Africa: An empirical Investigation of their monetary policy framework, P1
   Laumer M, 2016, APSIPA T SIGNAL INFO, V5
   Le Capitaine H, 2011, ADV INTEL SYS RES, P1074
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   Liu C, 2009, PATTERN RECOGN, V42, P2897, DOI 10.1016/j.patcog.2009.02.002
   Lu SJ, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P540, DOI 10.1109/AVSS.2007.4425368
   Mahalingam T., 2018, APPL COMPUTING INFOR
   Mahesh CP, 2014, INT J EMERGING TREND, V3, P215
   Meena A, 2013, INDIAN J COMPUTER SC, V4
   Negri P, 2014, PATTERN RECOGN, V47, P56, DOI 10.1016/j.patcog.2013.05.020
   Panda DK, 2016, IEEE SIGNAL PROC LET, V23, P45, DOI 10.1109/LSP.2015.2498839
   Pintea CM, 2016, SMART INNOV SYST TEC, V46, P117, DOI 10.1007/978-3-319-26860-6_7
   Pugazhenthi A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ENGINEERING AND TECHNOLOGY (ICETECH), P104
   Ray KS, 2019, J VIS COMMUN IMAGE R, V58, P662, DOI 10.1016/j.jvcir.2018.12.002
   Ren YY, 2009, ICICTA: 2009 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTATION TECHNOLOGY AND AUTOMATION, VOL I, PROCEEDINGS, P586, DOI 10.1109/ICICTA.2009.148
   Sabirin H, 2012, IEEE T MULTIMEDIA, V14, P657, DOI 10.1109/TMM.2012.2187777
   Sharmila Sujatha G, 2015, INT C INN TRENDS EL, V1, P85
   Sheikh A, 2011, P INT C COMP EL EL M
   Shuai H, 2017, IEEE ACCESS, V6
   Spagnolo P, 2006, IMAGE VISION COMPUT, V24, P411, DOI 10.1016/j.imavis.2006.01.001
   Tian S, 2016, NEUROCOMPUTING, V171, P768, DOI 10.1016/j.neucom.2015.07.028
   Xiao F, 2018, SIGNAL PROCESS, V144, P392, DOI 10.1016/j.sigpro.2017.10.019
   Xiong G, 2006, IEEE T CIRCUITS SYST, V53
   Xu S., 2013, INT J SIGNAL PROCESS, V6, P191, DOI DOI 10.14257/IJSIP.2013.65.17
   Xu XZ, 2017, INTELL AUTOM SOFT CO, V23, P303, DOI 10.1080/10798587.2016.1210258
   Ye Y, 2011, 2011 24TH INTERNATIONAL VACUUM NANOELECTRONICS CONFERENCE (IVNC), P7
   Zhang S, 2015, IEEE SENS J, V15, P2679, DOI 10.1109/JSEN.2014.2382174
NR 42
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26427
EP 26452
DI 10.1007/s11042-019-07787-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700052
DA 2024-07-18
ER

PT J
AU Marin-Castro, HM
   Hernandez-Resendiz, JD
   Escalante-Balderas, HJ
   Pellegrin, L
   Tello-Leal, E
AF Marin-Castro, Heidy M.
   Hernandez-Resendiz, Jaciel D.
   Escalante-Balderas, Hugo J.
   Pellegrin, Luis
   Tello-Leal, Edgar
TI Chained ensemble classifier for image annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic image annotation; Chain classifiers; Multimodal information
   processing; Ensemble models
AB Image annotation is the task of assigning keywords or identifiers to images, holistically or in specific regions. These keywords serve as descriptors of high-level semantics to facilitate retrieval and organization of visual information. It plays an important role in content-based image understanding, as well as in areas such as object recognition in robotics, content-based image searching and knowledge extraction. Automatic image annotation is usually approached by means of supervised classification, where a set of previously annotated images is required to train a learning algorithm that later predicts the labels for new images. This paper proposes a novel ensemble classifier for the supervised image annotation task inspired in chain classifiers. In the proposed approach a chain of individual classifiers is build, where each classifier is trained by using a different modality. In addition, the input space of models in the chain is augmented with the output of the preceding model in the sequence. Each model in the chain deals with the same classification problem, making the proposed method an ensemble model build from multimodal data. To the best of our knowledge, chain classifiers have not been used in this particular setting. Experimental results in a challenging image collection show that the proposed method is able to obtain an f -value superior to 0.5, outperforming related work.
C1 [Marin-Castro, Heidy M.] Univ Autonoma Tamaulipas, Catedras CONACYT, Ciudad Victoria, Mexico.
   [Hernandez-Resendiz, Jaciel D.] Univ Autonoma Tamaulipas, Unidad Acad Multidisciplinaria Reynosa RODHE, Ciudad Victoria, Mexico.
   [Escalante-Balderas, Hugo J.] Inst Nacl Astrofis Opt & Electr, Puebla 72840, Mexico.
   [Escalante-Balderas, Hugo J.] IPN, CINVESTAV, Dept Comp Sci, Mexico City 07360, DF, Mexico.
   [Pellegrin, Luis] Univ Autonoma Baja California, Ensenada, Baja California, Mexico.
   [Tello-Leal, Edgar] Univ Autonoma Tamaulipas, Ciudad Victoria, Mexico.
C3 Universidad Autonoma de Tamaulipas; Universidad Autonoma de Tamaulipas;
   Instituto Nacional de Astrofisica, Optica y Electronica; CINVESTAV -
   Centro de Investigacion y de Estudios Avanzados del Instituto
   Politecnico Nacional; Instituto Politecnico Nacional - Mexico;
   Universidad Autonoma de Baja California; Universidad Autonoma de
   Tamaulipas
RP Marin-Castro, HM (corresponding author), Univ Autonoma Tamaulipas, Catedras CONACYT, Ciudad Victoria, Mexico.
EM hmarin@conacyt.mx; a2183728004@alumnos.uat.edu.mx; hugojair@inaoep.mx;
   luis.pellegrin@uabc.edu.mx; etello@uat.edu.mx
RI Marin-Castro, Heidy M./AAZ-6051-2020; ARSLAN, Okan/AAA-3232-2020;
   Escalante, Hugo Jair/AEP-0896-2022
OI Escalante, Hugo Jair/0000-0003-4603-3513; Luis Pellegrin,
   Luis/0000-0002-4898-1632; Hernandez Resendiz, Jaciel
   David/0000-0002-0166-8083
CR Alham Nasullah Khalid, 2009, Proceedings of the 2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2009), P245, DOI 10.1109/FSKD.2009.531
   [Anonymous], WORK
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2016, International Journal of Computer Applications, DOI [DOI 10.5120/ijca2016910813, DOI 10.5120/IJCA2016910813]
   [Anonymous], REP IM
   [Anonymous], PATTERN RECOGN
   [Anonymous], MULTIMEDIA UBIQUITOU
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ARXIV150306462
   [Anonymous], AUTOMATIC IMAGE ANNO
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   Ballan L., 2014, P INT C MULTIMEDIA R, P73
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Giannoulakis S, 2017, 2017 IEEE 15TH INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, 15TH INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, 3RD INTL CONF ON BIG DATA INTELLIGENCE AND COMPUTING AND CYBER SCIENCE AND TECHNOLOGY CONGRESS(DASC/PICOM/DATACOM/CYBERSCI, P89, DOI 10.1109/DASC-PICom-DataCom-CyberSciTec.2017.29
   Han YH, 2012, PROC CVPR IEEE, P2981, DOI 10.1109/CVPR.2012.6248027
   Hanbury A, 2008, J VISUAL LANG COMPUT, V19, P617, DOI 10.1016/j.jvlc.2008.01.002
   Escalante HJ, 2011, COMPUT VIS IMAGE UND, V115, P787, DOI 10.1016/j.cviu.2011.02.002
   Escalante HJ, 2010, COMPUT VIS IMAGE UND, V114, P419, DOI 10.1016/j.cviu.2009.03.008
   Kotsiantis SB, 2007, INFORM-J COMPUT INFO, V31, P249
   Lu Z., 2012, P 20 ACM INT C MULT, P499, DOI DOI 10.1145/2393347.2393418
   Ma YB, 2018, MOD RHEUMATOL, V28, P849, DOI 10.1080/14397595.2017.1416924
   Murthy V.N., 2014, ICMR 2014 P ACM INT, P369, DOI DOI 10.1145/2578726.2578774
   Murthy VN, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P603, DOI 10.1145/2671188.2749391
   Nikam Sagar S., 2015, Oriental Journal of Computer Science and Technology, V8, P13
   Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110
   Pellegrin L, 2017, MULTIMED TOOLS APPL, V76, P16389, DOI 10.1007/s11042-016-3918-9
   Piao Y, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/590678
   Read J, 2011, MACH LEARN, V85, P333, DOI 10.1007/s10994-011-5256-5
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi F, 2011, AEU-INT J ELECTRON C, V65, P929, DOI 10.1016/j.aeue.2011.03.003
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Theodosiou Z., 2014, SEMANTIC MULTIMEDIA
   Tousch AM, 2012, PATTERN RECOGN, V45, P333, DOI 10.1016/j.patcog.2011.05.017
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   Wang L, 2006, MULTIMED TOOLS APPL, V29, P55, DOI 10.1007/s11042-006-7813-7
   Xia JS, 2014, ADV COMPUT VIS PATT, P135, DOI 10.1007/978-3-319-05696-8_6
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
NR 41
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26263
EP 26285
DI 10.1007/s11042-019-07815-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700046
DA 2024-07-18
ER

PT J
AU Punithavathi, P
   Geetha, S
AF Punithavathi, P.
   Geetha, S.
TI Partial DCT-based cancelable biometric authentication with security and
   privacy preservation for IoT applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancelable biometric system; Cloud computing; DCT; IoT applications;
   Non-invertible transformation
ID REMOTE USER AUTHENTICATION; EFFICIENT; SCHEME; CRYPTANALYSIS;
   IMPROVEMENT
AB Biometric authentication is being vastly used in identity verification for several IoT applications, nowadays. The security and privacy of the biometrics templates used in the authentication process becomes mandatory as it contains rich personal information of the user. Cancelable Biometric System (CBS) is a template securing approach using repeated distortions/transformations at feature/signal level. It is an effective template securing approach which provides non-invertibility, revocability and diversity to the users enrolled with the cancelable template database. The cancelable template database containing cancelable biometric templates of the users is typically stored in a trusted standalone server. To meet the growing demand of IoT applications, cloud computing with provision to store and process even large database, is being largely deployed. However, the security and privacy of the data stored in the cloud is uncertain. In this paper, we have proposed a novel partial DCT-based CBS with privacy and security preservation for providing authentication services in various IoT applications. We have also devised techniques for session key agreement, data encryption and data integrity in the proposed framework to solve the issues of confidentiality, integrity, and availability (CIA) during cancelable template enrolment and authentication. The experimental results and analysis prove that proposed approach performs user authentication with high accuracy and minimal overhead while preserving security and privacy of sensitive cancelable biometric templates.
C1 [Punithavathi, P.; Geetha, S.] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai Campus, Chennai 600127, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Punithavathi, P (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Chennai Campus, Chennai 600127, Tamil Nadu, India.
EM p.punithavathi2015@vit.ac.in
RI , Dr.S.Geetha/ABI-7036-2020; Kamaraj, N./AAS-2531-2020; ,
   Punithavathi/AAH-3433-2019
OI Kamaraj, N./0000-0002-0424-5529; S, Geetha/0000-0002-6850-9423
FU Visvesvaraya PHD scheme an initiative of Digital India Corporation under
   Ministry of Electronics and Information Technology, Government of India
FX The authors would like to thank the Management and Staff of Vellore
   Institute of Technology, Chennai Campus. The first author is supported
   by Visvesvaraya PHD scheme an initiative of Digital India Corporation
   under Ministry of Electronics and Information Technology, Government of
   India.
CR Amin R, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0318-z
   [Anonymous], 2002, FINGERPRINTVERIFICAT
   [Anonymous], 2004, FINGERPRINTVERIFICAT
   [Anonymous], 2001, RFC3174: US Secure Hash Algorithm 1 (SHA1)
   [Anonymous], 2013, IACR CRYP TOLOGY EPR
   [Anonymous], [No title captured]
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Bolle RM, 2002, PATTERN RECOGN, V35, P2727, DOI 10.1016/S0031-3203(01)00247-3
   Bommagani AS, 2014, MIL COMM C MILCOM
   Bringer J, 2017, IMAGE VISION COMPUT, V58, P239, DOI 10.1016/j.imavis.2016.08.002
   Buchholz JJ, 2001, INT WORKSH FAST SOFT
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   Chang YF, 2014, INT J COMMUN SYST, V27, P3430, DOI 10.1002/dac.2552
   Chiou SY, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0453-1
   Das AK, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9948-1
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Gomez-Barrero M, 2017, PATTERN RECOGN, V67, P149, DOI 10.1016/j.patcog.2017.01.024
   Haghighat M, 2015, EXPERT SYST APPL, V42, P7905, DOI 10.1016/j.eswa.2015.06.025
   Hammerle-Uhl J, 2009, INT C INF SEC PIS IT
   Hu P., 2017, FUTURE GENERATION CO
   Hu SS, 2018, IEEE T INF FOREN SEC, V13, P2448, DOI 10.1109/TIFS.2018.2819128
   Huang XY, 2015, IEEE T COMPUT, V64, P971, DOI 10.1109/TC.2014.2315619
   Jin Z, 2014, PATTERN RECOGN LETT, V42, P137, DOI 10.1016/j.patrec.2014.02.011
   Karabat C, 2009, 5 INT C INT INF HID
   Kumar S, 2018, MULTIMED TOOLS APPL, V77, P11017, DOI 10.1007/s11042-017-4966-5
   Li CS, 2011, J STAT COMPUT SIM, V81, P1081, DOI 10.1080/00949651003677410
   Liang KT, 2015, IEEE T INF FOREN SEC, V10, P1578, DOI 10.1109/TIFS.2015.2419186
   Lumini A, 2007, PATTERN RECOGN, V40, P1057, DOI 10.1016/j.patcog.2006.05.030
   Maiorana E, 2011, IEEE INT SYST C
   Ouda O, 2010, 20 INT C PATT REC IC
   Peer P, 2013, INFORM-J COMPUT INFO, V37, P115
   Proaski JG, 1996, DIGITAL SIGNAL PROCE
   Punithavathi P., 2017, Biometric Technology Today, V2017, P8, DOI 10.1016/S0969-4765(17)30138-8
   Punithavathi P, 2017, P 6 INT C BIOINF BIO
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   RATHA NK, 1995, PATTERN RECOGN, V28, P1657, DOI 10.1016/0031-3203(95)00039-3
   Rezaei M, 2016, WATER CONSERV SCI EN, V1, P197, DOI 10.1007/s41101-016-0013-z
   Teoh ABJ, 2007, IEEE T SYSTEMS MAN B
   Wang S, 2017, PATTERN RECOGN, V66, P295, DOI 10.1016/j.patcog.2017.01.019
   Wang S, 2017, PATTERN RECOGN, V61, P447, DOI 10.1016/j.patcog.2016.08.017
   Wang S, 2016, PATTERN RECOGN, V54, P14, DOI 10.1016/j.patcog.2016.01.001
   Wang XM, 2007, COMPUT STAND INTER, V29, P507, DOI 10.1016/j.csi.2006.11.005
   Wang YY, 2009, COMPUT COMMUN, V32, P583, DOI 10.1016/j.comcom.2008.11.008
   Wen FT, 2012, COMPUT ELECTR ENG, V38, P381, DOI 10.1016/j.compeleceng.2011.11.010
   Wu Z, 2017, INF SCI
   Xhafa F, 2014, SOFT COMPUT, V18, P1795, DOI 10.1007/s00500-013-1202-8
   Yuan J, 2013, INFOCOM 2013 P IEEE
NR 48
TC 10
Z9 10
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25487
EP 25514
DI 10.1007/s11042-019-7617-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700012
DA 2024-07-18
ER

PT J
AU Afifi, M
AF Afifi, Mahmoud
TI 11K Hands: Gender recognition and biometric identification using a large
   dataset of hand images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gender recognition; Gender classification; Biometric identification;
   Deep learning; CNN; Hands dataset
ID SHAPE; CLASSIFICATION; GEOMETRY; SYSTEM
AB Human hand not only possesses distinctive feature for gender information, it is also considered one of the primary biometric traits used to identify a person. Unlike face images, which are usually unconstrained, an advantage of hand images is they are usually captured under a controlled position. Most state-of-the-art methods, that rely on hand images for gender recognition or biometric identification, employ handcrafted features to train an off-the-shelf classifier or be used by a similarity metric for biometric identification. In this work, we propose a deep learning-based method to tackle the gender recognition and biometric identification problems. Specifically, we design a two-stream convolutional neural network (CNN) which accepts hand images as input and predicts gender information from these hand images. This trained model is then used as a feature extractor to feed a set of support vector machine classifiers for biometric identification. As part of this effort, we propose a large dataset of human hand images, 11K Hands, which contains dorsal and palmar sides of human hand images with detailed ground-truth information for different problems including gender recognition and biometric identification. By leveraging thousands of hand images, we could effectively train our CNN-based model achieving promising results. One of our findings is that the dorsal side of human hands is found to have effective distinctive features similar to, if not better than, those available in the palmar side of human hand images. To facilitate access to our 11K Hands dataset, the dataset, the trained CNN models, and our Matlab source code are available at (https://goo.gl/rQJndd).
C1 [Afifi, Mahmoud] York Univ, Lassonde Sch Engn, Dept Elect Engn & Comp Sci, Toronto, ON, Canada.
   [Afifi, Mahmoud] Assiut Univ, Asyut, Egypt.
C3 York University - Canada; Egyptian Knowledge Bank (EKB); Assiut
   University
RP Afifi, M (corresponding author), York Univ, Lassonde Sch Engn, Dept Elect Engn & Comp Sci, Toronto, ON, Canada.; Afifi, M (corresponding author), Assiut Univ, Asyut, Egypt.
EM mafifi@eecs.yorku.ca
RI afifi, mahmoud/AAH-3095-2019
OI afifi, mahmoud/0000-0003-0125-4945
CR Afifi M, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043020
   Amayeh Gholamreza, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563122
   [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   [Anonymous], 2018, IEEE T IMAGE PROCESS
   [Anonymous], 2016 INT C INF TECHN
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], IET COMPUTER VISION
   [Anonymous], 2005, SUPPORT VECTOR MACHI, DOI DOI 10.1007/10984697_12
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], ARXIV180500371
   [Anonymous], 2017, ARXIV170604277
   [Anonymous], IET CONTROL THEORY A
   [Anonymous], INTERNATIONAL CONFER
   [Anonymous], ARXIV180305719
   [Anonymous], 2012, MACHINE LEARNING PRO
   [Anonymous], 2008, Handbook of biometrics
   Aslam A, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053023
   Azizpour H, 2016, IEEE T PATTERN ANAL, V38, P1790, DOI 10.1109/TPAMI.2015.2500224
   Bera A, 2020, IEEE T SYST MAN CY-S, V50, P747, DOI 10.1109/TSMC.2017.2744669
   Bera A, 2017, MULTIMED TOOLS APPL, V76, P21451, DOI 10.1007/s11042-016-4075-x
   Charfi N, 2017, MULTIMED TOOLS APPL, V76, P20457, DOI 10.1007/s11042-016-3987-9
   Charfi N, 2014, 2014 6TH INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P261, DOI 10.1109/SOCPAR.2014.7008016
   Chatfield K., 2014, P BRIT MACH VIS C 20
   Chen CJ, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P182
   Conaire Ciaran O., 2007, CVPR '07. IEEE Conference on Computer Vision and Pattern Recognition, P1
   Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Ferrer MA, 2007, CAR C SECUR, P52
   Han CC, 2004, IMAGE VISION COMPUT, V22, P909, DOI 10.1016/j.imavis.2004.05.008
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hu RX, 2012, PATTERN RECOGN, V45, P3348, DOI 10.1016/j.patcog.2012.02.018
   Jain AK, 2004, PROC SPIE, V5404, P561, DOI 10.1117/12.542890
   Kanchan T, 2011, J FORENSIC LEG MED, V18, P14, DOI 10.1016/j.jflm.2010.11.013
   Kong A, 2009, PATTERN RECOGN, V42, P1408, DOI 10.1016/j.patcog.2009.01.018
   Krishan K, 2011, J FORENSIC SCI, V56, P453, DOI 10.1111/j.1556-4029.2010.01652.x
   Kuehlkamp A, 2017, IEEE WINT CONF APPL, P1151, DOI 10.1109/WACV.2017.133
   Kumar A, 2010, IEEE IMAGE PROC, P3121, DOI 10.1109/ICIP.2010.5653214
   Kumar A, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P583, DOI 10.1109/ICVGIP.2008.73
   Lagree S., 2011, 2011 IEEE International Conference on Technologies for Homeland Security (HST 2011), P440, DOI 10.1109/THS.2011.6107909
   Lapuschkin S, 2017, IEEE INT CONF COMP V, P1629, DOI 10.1109/ICCVW.2017.191
   Li XO, 2010, PROC CVPR IEEE, P2590, DOI 10.1109/CVPR.2010.5539969
   McFadden D, 2002, HORM BEHAV, V42, P492, DOI 10.1006/hbeh.2002.1833
   Mordvintsev A, 2015, DEEP DREAM
   Nixon MS, 2015, PATTERN RECOGN LETT, V68, P218, DOI 10.1016/j.patrec.2015.08.006
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Shanmugasundaram Karthikeyan, 2017, 2017 International Conference on Signal Processing and Communication (ICSPC), P53, DOI 10.1109/CSPC.2017.8305806
   Sharma S, 2015, EXPERT SYST APPL, V42, P821, DOI 10.1016/j.eswa.2014.08.052
   Sun YL, 2018, IEEE T PATTERN ANAL, V40, P332, DOI 10.1109/TPAMI.2017.2669035
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Unar JA, 2014, PATTERN RECOGN, V47, P2673, DOI 10.1016/j.patcog.2014.01.016
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu ME, 2014, SCI WORLD J, DOI 10.1155/2014/650537
   Xie J, 2012, SENSORS-BASEL, V12, P8691, DOI 10.3390/s120708691
   Yörük E, 2006, IEEE T IMAGE PROCESS, V15, P1803, DOI 10.1109/TIP.2006.873439
   Yu X, 2016, IEEE T PATTERN ANAL, V38, P2212, DOI 10.1109/TPAMI.2015.2509999
   Zhang L, 2017, PATTERN RECOGN, V69, P199, DOI 10.1016/j.patcog.2017.04.016
NR 64
TC 60
Z9 61
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20835
EP 20854
DI 10.1007/s11042-019-7424-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400013
DA 2024-07-18
ER

PT J
AU Zhu, SQ
   Zhu, CX
AF Zhu, Shuqin
   Zhu, Congxu
TI A new image compression-encryption scheme based on compressive sensing
   and cyclic shift
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression-encryption; Compressive sensing; Chebyshev mapping;
   Cyclic shift; Chaotic system
ID ALGORITHM; PERMUTATION; ROBUST
AB This paper proposes a digital image compression-encryption scheme based on the theory of compressive sensing and cyclic shift, which use random Gauss matrix and sparse transform to compress the digital image, and then cyclic shift and diffusion operation are developed subsequently to the compressive sensing (CS) phase. The algorithm has three advantages: First, the measurement matrix used in the algorithm is generated by Chebyshev mapping, which increases the key space and reduces the burden of key transmission. Second, The Sigmoid function is used to transform the range of compressed data to 0 similar to 255, which are stored as 8-bit binary data, thus further reducing the amount of data transmission and avoiding the expansion of encrypted data. Third, the generation of key stream in encryption phase is related to ciphertext, there are different key streams for different plain images. Thus, our algorithm can resist against the chosen-plaintext and known-plaintext attacks effectively. In addition, the implementation of cyclic shift and diffusion operation further enhances the security of the system. Each pixel of the encrypted image is output in the form of 8-bit integer to facilitate data storage, display and transmission. The experimental results and security analysis show that the algorithm has the advantages of large key space, no obvious statistical characteristics of ciphertext, sensitive to plaintext and key, and able to resist chosen-plaintext attack.
C1 [Zhu, Shuqin] Liaocheng Univ, Sch Comp & Sci, Liaocheng 252059, Shandong, Peoples R China.
   [Zhu, Congxu] Cent S Univ, Sch Comp Sci & Engn, Changsha 410083, Hunan, Peoples R China.
   [Zhu, Congxu] Hunan Police Acad, Hunan Prov Key Lab Network Invest Technol, Changsha 410138, Hunan, Peoples R China.
C3 Liaocheng University; Central South University
RP Zhu, CX (corresponding author), Cent S Univ, Sch Comp Sci & Engn, Changsha 410083, Hunan, Peoples R China.; Zhu, CX (corresponding author), Hunan Police Acad, Hunan Prov Key Lab Network Invest Technol, Changsha 410138, Hunan, Peoples R China.
EM shuqinzhu2008@163.com; zhucx@csu.edu.cn
OI Zhu, Congxu/0000-0002-9662-0532
FU National Natural Science Foundation of China [61472451]; Scientific
   Research Projects of Universities in Shandong Province [J18KA336];
   Shandong Province Natural Science Foundation [ZR2017MEM019]
FX This work was supported by National Natural Science Foundation of China
   (No. 61472451), Scientific Research Projects of Universities in Shandong
   Province (Grant. J18KA336), and Shandong Province Natural Science
   Foundation (Grant. ZR2017MEM019).
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   BOX GEP, 1958, ANN MATH STAT, V29, P610, DOI 10.1214/aoms/1177706645
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chen JX, 2014, NONLINEAR DYNAM, V77, P1191, DOI 10.1007/s11071-014-1370-9
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Dossal C, 2010, LINEAR ALGEBRA APPL, V432, P1663, DOI 10.1016/j.laa.2009.11.022
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Ezeafulukwe UA, 2018, INT J MATH COMPUT SC, V13, P171
   Fang H, 2014, IEEE T SIGNAL PROCES, V62, P196, DOI 10.1109/TSP.2013.2284762
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Li CQ, 2017, IEEE MULTIMEDIA, V24, P64, DOI 10.1109/MMUL.2017.3051512
   Liu H, 2016, SIGNAL PROCESS-IMAGE, V45, P41, DOI 10.1016/j.image.2016.04.002
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Rehman AU, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0084-9
   Tong XJ, 2016, NONLINEAR DYNAM, V84, P2333, DOI 10.1007/s11071-016-2648-x
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang XY, 2015, OPT LASER ENG, V68, P126, DOI 10.1016/j.optlaseng.2014.12.025
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Xiao D, 2015, CHINESE PHYS B, V24, DOI 10.1088/1674-1056/24/6/060505
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Zhang LY, 2016, IEEE T MULTIMEDIA, V18, P1720, DOI 10.1109/TMM.2016.2581593
   Zhang Y, 2017, OPT COMMUN, V392, P223, DOI 10.1016/j.optcom.2017.01.061
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2015, OPT COMMUN, V354, P112, DOI 10.1016/j.optcom.2015.05.043
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhu CX, 2012, ACTA PHYS SIN-CH ED, V61, DOI 10.7498/aps.61.120503
   Zhu CX, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110843
   Zhu CX, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10090399
   Zhu CX, 2018, IEEE ACCESS, V6, P18759, DOI 10.1109/ACCESS.2018.2817600
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu SQ, 2018, IEEE ACCESS, V6, P67095, DOI 10.1109/ACCESS.2018.2874336
   Zhu SQ, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20090716
   Zhu SQ, 2018, MULTIMED TOOLS APPL, V77, P29119, DOI 10.1007/s11042-018-6078-2
NR 36
TC 41
Z9 43
U1 2
U2 69
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20855
EP 20875
DI 10.1007/s11042-019-7405-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400014
DA 2024-07-18
ER

PT J
AU Babic, D
   Stefanovic, D
   Vranjes, M
   Herceg, M
AF Babic, Danijel
   Stefanovic, Dejan
   Vranjes, Mario
   Herceg, Marijan
TI Real-time no-reference histogram-based freezing artifact detection
   algorithm for UHD videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artifact; Freezing; Histogram; No-reference; Real-time; UHD
ID QUALITY; IMPACT
AB During video transmission different errors can occur, which can introduce distinct artifacts in video received at the end user side. One of the most common artifacts that appears in such cases is frame freezing and it can significantly reduce the quality of received video, i.e. decrease the level of end user Quality of Experience (QoE). Thus it is necessary to properly detect the occurrence of frame freezing, in order to assure the satisfactory level of end user QoE. In this paper a novel no-reference (NR) objective algorithm for detection of various types of freezing artifacts in video, called Histogram-Based Freezing artifacts Detection Algorithm (HBFDA), is proposed. HBFDA uses method for comparison of consecutive video frames, which consists of splitting frame into regions and comparing regions' histograms of consecutive frames. In order to operate on different types of video contents (including those containing a low level of movement), while achieving high level of accuracy and reliability, HBFDA dynamically adapts its parameters in real-time. HBFDA performance are compared to this of two freely pulbicly available algorithms for frame freezing detection on videos from three different databases: VQEG HDTV, LIVE Mobile and newly created UHD Video Freezing Database (UHD VFD), which we made publicly available to the research community and it can be downloaded at http://www.rt-rk.com/other/UHDVideoDBReadme.html. Experimental results show that HBFDA has lowest number of false freezing detections when compared to other tested algorithms and that it achieves the highest average total accuracy of 99.26% when all databases are taken into account. Additionally, for UHD videos, HBFDA is able to process 75 frames per second, which makes it suitable for real-time video applications.
C1 [Babic, Danijel] Inst RT RK Osijek LLC Informat Technol, BBT Black Box Testing Grp, R&D, Osijek, Croatia.
   [Stefanovic, Dejan] RT RK Inst Comp Based Syst, Novi Sad, Serbia.
   [Vranjes, Mario; Herceg, Marijan] Univ Osijek, Fac Elect Engn Comp Sci & Informat Technol, Osijek, Croatia.
C3 University of JJ Strossmayer Osijek
RP Vranjes, M (corresponding author), Univ Osijek, Fac Elect Engn Comp Sci & Informat Technol, Osijek, Croatia.
EM danijel.babic@rt-rk.com; dejan.stefanovic@rt-rk.com;
   mario.vranjes@ferit.hr; marijan.herceg@ferit.hr
OI Vranjes, Mario/0000-0003-3563-4735
FU Josip Juraj Strossmayer University of Osijek [IZIP-2016]; Ministry of
   Education, Science and Technological Development of the Republic of
   Serbia [III_044009_6]
FX This work was supported by the Josip Juraj Strossmayer University of
   Osijek IZIP-2016, via the project "Providing of digital video signal
   based services in rural and rarely populated areas" and by the Ministry
   of Education, Science and Technological Development of the Republic of
   Serbia, under grant number III_044009_6.
CR [Anonymous], 2002, P INT C IM PROC
   [Anonymous], REP VAL VID QUAL MOD
   [Anonymous], 2011, Int. J. Comput. Vis. Robot, DOI DOI 10.1504/IJCVR.2011.045267
   [Anonymous], 2008, SUBJ VID QUAL ASS ME
   Baldi M, 2000, IEEE ACM T NETWORK, V8, P479, DOI 10.1109/90.865076
   Borer S., 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P218, DOI 10.1109/QOMEX.2010.5516155
   Dagum L, 1998, IEEE COMPUT SCI ENG, V5, P46, DOI 10.1109/99.660313
   Huynh-Thu Q, 2008, IEEE T BROADCAST, V54, P641, DOI 10.1109/TBC.2008.2001246
   Huynh-Thu Q, 2009, IEEE IMAGE PROC, P2221, DOI 10.1109/ICIP.2009.5413894
   Joshi P, 2017, MULTIMED TOOLS APPL, V76, P18871, DOI 10.1007/s11042-017-4418-2
   Lamb AB, 2018, MULTIMED TOOLS APPL, V77, P8653, DOI 10.1007/s11042-017-4761-3
   Mittal A, 2016, IEEE T IMAGE PROCESS, V25, P289, DOI 10.1109/TIP.2015.2502725
   Moorthy A. K., 2012, IEEE ICC WORKSHOP RE, V6, P652
   Moorthy A. K., 2012, 6 INT WORKSH VID PRO
   Moorthy AK, 2012, IEEE J-STSP, V6, P652, DOI 10.1109/JSTSP.2012.2212417
   Muijs R., 2005, 2005 13th European Signal Processing Conference, P1
   OpenCV, 2018, HIST COMP
   Pastrana-Vidal RR, 2004, P SOC PHOTO-OPT INS, V5292, P182, DOI 10.1117/12.525746
   Qi YN, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P423
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Shahid M, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-40
   Skobi V., 2016, 24 TEL FOR TELFOR, P1, DOI 10.1109/TELFOR.2016.7818805
   Teslic N, 2010, IEEE T CONSUM ELECTR, V56, P1311, DOI 10.1109/TCE.2010.5606264
   Usman M.A., 2016, IETE TECH REV, P1
   Usman M. R., 2015, INT J COMPUTER ELECT, V9, P1570
   Usman MA, 2018, IEEE T MULTIMEDIA, V20, P2344, DOI 10.1109/TMM.2018.2801722
   Usman MA, 2016, INT CONF UBIQ FUTUR, P839, DOI 10.1109/ICUFN.2016.7537155
   van Kester S, 2011, SPIE P INT SOC OPTIC
   Vranjes M, 2013, SIGNAL PROCESS-IMAGE, V28, P1, DOI 10.1016/j.image.2012.10.003
   Wolf S, 2009, 4 INT WORK VID PROC, P15
   Xue YY, 2015, IEEE T MULTIMEDIA, V17, P134, DOI 10.1109/TMM.2014.2368272
   Yammine G, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P341, DOI 10.1109/PCS.2012.6213315
   Zhao SQ, 2016, INT J NUMER ANAL MOD, V13, P879
   Zlokolica V, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P81, DOI 10.1109/ICCE.2011.5722883
NR 34
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17949
EP 17971
DI 10.1007/s11042-019-7184-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200028
DA 2024-07-18
ER

PT J
AU Das, D
   Nayak, DR
   Dash, R
   Majhi, B
AF Das, Dibyasundar
   Nayak, Deepak Ranjan
   Dash, Ratnakar
   Majhi, Banshidahar
TI An empirical evaluation of extreme learning machine: application to
   handwritten character recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extreme learning machine; Weight initialization; Activation function;
   Character recognition
ID CLASSIFIER; DATABASES; NETWORKS; BANGLA; ONLINE; DEEP
AB Extreme learning machine (ELM), a randomized learning paradigm for single hidden layer feed-forward network, has gained significant attention for solving problems in diverse domains due to its faster learning ability. The output weights in ELM are determined by an analytic procedure, while the input weights and biases are randomly generated and fixed during the training phase. The learning performance of ELM is highly sensitive to many factors such as the number of nodes in the hidden layer, the initialization of input weight and the type of activation functions in the hidden layer. Although various works on ELM have been proposed in the last decade, the effect of the all these influencing factors on classification performance has not been fully investigated yet. In this paper, we test the performance of ELM with different configurations through an empirical evaluation on three standard handwritten character datasets, namely, MNIST, ISI-Kolkata Bangla numeral, ISI-Kolkata Odia numeral and a newly developed NIT-RKL Bangla numeral dataset. Finally, we derive some best ELM figurations which can serve as general guidelines to design ELM based classifiers.
C1 [Das, Dibyasundar; Nayak, Deepak Ranjan; Dash, Ratnakar; Majhi, Banshidahar] Natl Inst Technol, Dept Comp Sci & Engn, Pattern Recognit Lab, Rourkela 769008, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Nayak, DR (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Pattern Recognit Lab, Rourkela 769008, India.
EM depakranjannayak@gmail.com
RI Nayak, Deepak Ranjan/AED-5548-2022; Dash, Ratnakar/F-1498-2018; Das,
   Dibyasundar/IYT-4023-2023
OI Nayak, Deepak Ranjan/0000-0002-8929-5778; Das,
   Dibyasundar/0000-0002-0285-2560
CR [Anonymous], 1988, TECH REP
   [Anonymous], 2014, INDIAN J SCI TECHNOL
   [Anonymous], 2015, 2015 INT C COMP COMM
   [Anonymous], 2009, P 26 ANN INT C MACH, DOI [10.1145/1553374.1553439, DOI 10.1145/1553374.1553439]
   [Anonymous], 2014, **DROPPED REF**
   Basu S, 2010, PATTERN RECOGN, V43, P3507, DOI 10.1016/j.patcog.2010.05.018
   Battacharya U, 2005, PROC INT CONF DOC, P789
   Bhalerao M, 2018, L N COMPUT VIS BIOME, V28, P45, DOI 10.1007/978-3-319-71767-8_4
   Bhattacharya U, 2009, IEEE T PATTERN ANAL, V31, P444, DOI 10.1109/TPAMI.2008.88
   Bhowmik TK, 2006, ICIT 2006: 9TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P105
   Cecotti H, 2016, IEEE IJCNN, P3628, DOI 10.1109/IJCNN.2016.7727666
   Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052
   Cui DS, 2018, PATTERN RECOGN, V79, P356, DOI 10.1016/j.patcog.2018.02.019
   Dash KS, 2014, IEEE REGION 10 SYMP, P531, DOI 10.1109/TENCONSpring.2014.6863091
   Dash KS, 2015, 8 INT C ADV PATT REC, P1
   Eshtay M, 2018, EXPERT SYSTEMS APPL
   Ghosh D, 2010, IEEE T PATTERN ANAL, V32, P2142, DOI 10.1109/TPAMI.2010.30
   Glorot X., 2010, P INT C ART INT STAT, P249
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang GB, 2004, I C CONT AUTOMAT ROB, P1029
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y
   Kasun LLC, 2016, IEEE T IMAGE PROCESS, V25, P3906, DOI 10.1109/TIP.2016.2570569
   Keysers D, 2007, IEEE T PATTERN ANAL, V29, P1422, DOI 10.1109/TPAMI.2007.1153
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583
   Liu CL, 2009, PATTERN RECOGN, V42, P3287, DOI 10.1016/j.patcog.2008.10.007
   Liu CL, 2003, PATTERN RECOGN, V36, P2271, DOI 10.1016/S0031-3203(03)00085-2
   Liu TC, 2018, NEUROCOMPUTING, V277, P78, DOI 10.1016/j.neucom.2017.01.115
   Mahto Manoj Kumar, 2011, INT J APPL SCI TECHN, V1, P17
   Mishra TK, 2014, FRONT COMPUT SCI-CHI, V8, P916, DOI 10.1007/s11704-014-3354-9
   Mishra TK, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P790, DOI 10.1109/ICACCI.2013.6637276
   Mohammed AA, 2011, PATTERN RECOGN, V44, P2588, DOI 10.1016/j.patcog.2011.03.013
   Mori S., 1995, Document image analysis, P244
   Nayak DR, 2018, NEUROCOMPUTING, V282, P232, DOI 10.1016/j.neucom.2017.12.030
   Nayak DR, 2017, MULTIMED TOOLS APPL, P1
   Pan C, 2012, NEURAL COMPUT APPL, V21, P1217, DOI 10.1007/s00521-011-0522-9
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Sethy A, 2018, RECENT PATENTS ENG
   Sethy A, 2018, ADV INTELL SYST COMP, V563, P187, DOI 10.1007/978-981-10-6872-0_18
   Song Y, 2018, IEEE J OCEANIC ENG
   Tang BB, 2016, SIGNAL PROCESS, V124, P156, DOI 10.1016/j.sigpro.2015.09.027
   Tao DP, 2018, IEEE T IMAGE PROCESS, V27, P325, DOI 10.1109/TIP.2017.2762588
   Tao DP, 2016, IEEE T CYBERNETICS, V46, P756, DOI 10.1109/TCYB.2015.2414920
   Wang DH, 2016, INFORM SCIENCES, V364, P126, DOI 10.1016/j.ins.2016.05.021
   Wen XH, 2018, SOFT COMPUT, V22, P3533, DOI 10.1007/s00500-018-3108-y
   Wen Y, 2007, PATTERN RECOGN, V40, P99, DOI 10.1016/j.patcog.2006.07.001
   Wen Y, 2012, EXPERT SYST APPL, V39, P948, DOI 10.1016/j.eswa.2011.07.092
   Weng Q, 2018, INT J REMOTE SENS, V39, P6281, DOI 10.1080/01431161.2018.1458346
   Xie WY, 2016, NEUROCOMPUTING, V173, P930, DOI 10.1016/j.neucom.2015.08.048
   Xu Y, 2006, LECT NOTES COMPUT SC, V3971, P644
   Zeng NY, 2017, NEUROCOMPUTING, V240, P175, DOI 10.1016/j.neucom.2017.01.090
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22629, DOI 10.1007/s11042-017-5023-0
   Zou WD, 2018, PROC ADAPT LEARN OPT, V9, P259, DOI 10.1007/978-3-319-57421-9_21
NR 56
TC 18
Z9 18
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19495
EP 19523
DI 10.1007/s11042-019-7330-0
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800026
DA 2024-07-18
ER

PT J
AU Mustapha, A
   Hussain, A
   Ahmad, WSHMW
   Zaki, WMDW
   Hamid, HB
AF Mustapha, Aouache
   Hussain, Aini
   Ahmad, Wan Siti Halimatul Munirah Wan
   Zaki, Wan Mimi Diyana Wan
   Hamid, Hamzaini Bin Abdul
TI CBIR-DSN: integrating clustering and retrieval platforms for disk space
   narrowing degradation assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spine radiography; Disk space narrowing; Modeling; Indexing approach;
   VTM clustering; DSN retrieval
ID RADIOGRAPHIC GRADING SYSTEM; IMAGE RETRIEVAL; INTEROBSERVER AGREEMENT;
   DEGENERATION; CLASSIFICATION; REPRESENTATION; DESCRIPTORS; VALIDITY;
   FOURIER; MODELS
AB A system that is capable of assessing spine osteoarthritis conditions which affect a significant portion of the elderly population could be very valuable to radiologists, researchers of arthritis and musculoskeletal diseases, and educators. To this end, there is very limited research published in the literature concerning the degradation assessment of spinal intervertebral disc space narrowing (DSN). Thus, this paper intends to develop a system that focuses on assessing the degradation of disk space narrowing (DSN) to assist in radiologist's decision-making in the characterization of cervical and lumbar images. A novel experiment based on our previous research (Aouache et al. 2009; Aouache et al. Biomed Eng Online 14(1):6, 2015) was conducted by integrating clustering and retrieval platforms to achieve this objective. Two shape boundary, 9-points, and B-spline have been used as the foundation for DSN model construction using active shape model. The segmented DSNs have then indexed via region and contour-based features descriptor. For better efficiency, clustering using a vocabulary tree model (VTM) is constructed to identify correct DSN cluster and build multi-clusters subsets for faster and robust retrieval research process. Our system achieved an accuracy of average retrieval rate (ARR) more than 90% and 88% for cervical and lumbar data set accordingly. We expect the proposed system will assist in decision-making and uses by radiologists or researchers for further investigation.
C1 [Mustapha, Aouache] CDTA, Div Telecom, Algiers 16303, Algeria.
   [Hussain, Aini; Ahmad, Wan Siti Halimatul Munirah Wan; Zaki, Wan Mimi Diyana Wan] Univ Kebangsaan Malaysia, Fac Engn & Built Environm, Ctr Integrated Syst Engn & Adv Technol INTEGRA, Bangi 43600, DE, Malaysia.
   [Hamid, Hamzaini Bin Abdul] Univ Kebangsaan Malaysia, Fac Med, Dept Radiol, Bangi 43600, DE, Malaysia.
C3 Centre for the Development of Advanced Technologies (CDTA); Universiti
   Kebangsaan Malaysia; Universiti Kebangsaan Malaysia
RP Mustapha, A (corresponding author), CDTA, Div Telecom, Algiers 16303, Algeria.
EM maouache@cdta.dz; draini@ukm.edu.my; wshmunirah@ukm.edu.my;
   wmdiyana@ukm.edu.my; hamzaini@ppukm.ukm.edu.my
RI Hussain, A./D-6915-2017; W Ahmad, W S H Munirah/A-6666-2017; Mustapha,
   AOUACHE/AFK-0820-2022; Mustapha, AOUACHE/AAF-7777-2022
OI Hussain, A./0000-0001-7347-7879; W Ahmad, W S H
   Munirah/0000-0001-6364-6341; Mustapha, AOUACHE/0000-0003-1629-1183
FU Ministry of Science, Technology, and Innovation; Centre for Integrated
   Systems Engineering and Advanced Technologies (INTEGRA), Universiti
   Kebangsaan Malaysia [DIP-2018- 020]
FX This work is supported in parts by the Ministry of Science, Technology,
   and Innovation and Centre for Integrated Systems Engineering and
   Advanced Technologies (INTEGRA), Universiti Kebangsaan Malaysia (project
   code: DIP-2018- 020) along with the collaboration and participation of
   SIA research team, Division Telecom, CDTA, Algeria.
CR Akgül CB, 2011, J DIGIT IMAGING, V24, P208, DOI 10.1007/s10278-010-9290-9
   [Anonymous], 2014, INTRO SECTS SOCIAL D
   [Anonymous], 2016, P 25 INT JOINT C ART
   Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3
   Aouache M, 2008, IFMBE PROC, V21, P607
   Aouache M, 2011, SCI RES ESSAYS, V6, P4246
   Aouache MM, 2007, RES DEV 2007 SCORED, P1
   Aouache M, 2018, MULTIMED TOOLS APPL, V77, P4011, DOI 10.1007/s11042-017-4468-5
   Arebey M, 2012, J ENVIRON MANAGE, V104, P9, DOI 10.1016/j.jenvman.2012.03.035
   AyuniMohd II, 2015, J FIBER BIOENG INFOR, V8, P547
   Baldi A, 2009, BIOMED ENG ONLINE, V8, DOI 10.1186/1475-925X-8-18
   Brown CD, 2006, CHEMOMETR INTELL LAB, V80, P24, DOI 10.1016/j.chemolab.2005.05.004
   Chung CT, 2009, EUR SPINE J, V18, P1669, DOI 10.1007/s00586-009-1072-z
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Frobin W, 2002, CLIN BIOMECH, V17, P423, DOI 10.1016/S0268-0033(02)00044-X
   HAMALAINEN O, 1993, AVIAT SPACE ENVIR MD, V64, P692
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Ikhsan IAM, 2014, 2014 IEEE 10TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2014), P208, DOI 10.1109/CSPA.2014.6805749
   Jian WS, 2012, BIOMED ENG ONLINE, V11, DOI 10.1186/1475-925X-11-96
   Kahn CE, 2007, AM J ROENTGENOL, V188, P1475, DOI 10.2214/AJR.06.1740
   Kalifa G, 2002, EUR RADIOL, V12, P660, DOI 10.1007/s003300100938
   KAUPPINEN H, 1995, IEEE T PATTERN ANAL, V17, P201, DOI 10.1109/34.368168
   Kettler A, 2006, EUR SPINE J, V15, P732, DOI 10.1007/s00586-005-1037-9
   Kumar A, 2013, J DIGIT IMAGING, V26, P1025, DOI 10.1007/s10278-013-9619-2
   Kuo WJ, 2002, ULTRASOUND MED BIOL, V28, P903, DOI 10.1016/S0301-5629(02)00541-0
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2017, AAAI CONF ARTIF INTE, P4118
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lee DJ, 2009, DATA KNOWL ENG, V68, P1359, DOI 10.1016/j.datak.2009.07.008
   Lehmann T. M., 1999, ELECT IMAGING, P312
   Ling C., 2017, 6 INT C IEEE, P1, DOI 10.1109/ICEEI.2017.8312408
   Ling CS, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRICAL, ELECTRONIC AND SYSTEMS ENGINEERING (ICAEES), P120, DOI 10.1109/ICAEES.2016.7888021
   Long LR, 1998, STORAGE RETRIEVAL IM, P392
   Lu J, 2000, CLIN ORTHOP RELAT R, P259
   MEYER F, 1994, SIGNAL PROCESS, V38, P113, DOI 10.1016/0165-1684(94)90060-4
   MILLER JM, 1988, SYST BOT, V13, P173, DOI 10.1097/00007632-198802000-00008
   Mustapha A, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/1475-925X-14-6
   Mustapha A, 2009, LECT NOTES COMPUT SC, V5857, P122, DOI 10.1007/978-3-642-05036-7_13
   Naghdy G, 1996, TEXTURE ANAL USING G
   Nister David, 2006, CVPR
   Paajanen H, 1997, ARCH ORTHOP TRAUM SU, V116, P106, DOI 10.1007/BF00434112
   Parsons JR, 1996, U. S. Patent, Patent No. [5,545,229, 5545229]
   Qian XN, 2010, MED IMAGE ANAL, V14, P243, DOI 10.1016/j.media.2010.01.001
   SHOKR ME, 1991, J GEOPHYS RES-OCEANS, V96, P10625, DOI 10.1029/91JC00693
   Shyu CR, 1999, COMPUT VIS IMAGE UND, V75, P111, DOI 10.1006/cviu.1999.0768
   Tang L.H. Y., 1999, Health Informatics Journal, V5, P40, DOI DOI 10.1177/146045829900500107
   Thoma GR, 2002, CONTENT BASED IMAGE
   Wang JZ, 2000, J AM MED INFORM ASSN, P883
   Wilke HJ, 2006, EUR SPINE J, V15, P720, DOI 10.1007/s00586-005-1029-9
   Xiangyuan L, 2018, AAAI
   Xu XQ, 2008, IEEE T INF TECHNOL B, V12, P100, DOI 10.1109/TITB.2007.904149
   Yadav RB, 2007, OPT LASER ENG, V45, P695, DOI 10.1016/j.optlaseng.2006.11.001
   Yuan Lei, 2012, KDD, P1149
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
NR 54
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18887
EP 18919
DI 10.1007/s11042-019-7176-5
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200069
DA 2024-07-18
ER

PT J
AU Wu, XH
   Lu, XB
AF Wu, Xuehui
   Lu, Xiaobo
TI Adaptive pixel-block based background subtraction using low-rank and
   block-sparse matrix decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background subtraction; Random arrangement; Adaptive parameters;
   Low-rank; Block-sparse
ID PEDESTRIAN DETECTION; SYSTEM
AB We present three stages of a novel backgrounds subtraction method in this paper: a new pixel-block based randomized arrangement is utilized to preprocess all the frame images, so that low-rank property of background and sparsity of foreground can be separated more easily; different foreground regions have different sparsity, we use a set of adaptive parameters for subtracting foregrounds according to the variances of frame pixels; finally, background model is built via an improved low-rank and block-sparse matrix decomposition based on the proposed adaptive pixel-block background subtraction. All these key measurements guarantee the considerable performance in background subtraction, which are also demonstrated in our experimental results.
C1 [Wu, Xuehui; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Wu, Xuehui; Lu, Xiaobo] Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.; Lu, XB (corresponding author), Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
EM xhwu@seu.edu.cn; xblu2013@126.com
FU National Natural Science Foundation of China [61871123]; Key Research
   and Development Program in Jiangsu Province [BE2016739]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions
FX This work was supported by the National Natural Science Foundation of
   China (No. 61871123), Key Research and Development Program in Jiangsu
   Province (No. BE2016739) and a Project Funded by the Priority Academic
   Program Development of Jiangsu Higher Education Institutions.
CR [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2012, AS C COMP VIS
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Barnich O, 2009, INT CONF ACOUST SPEE, P945, DOI 10.1109/ICASSP.2009.4959741
   Bengio S., 2009, Advances in Neural Information Processing Systems, V22, P82
   Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Choudhury SK, 2018, MULTIMED TOOLS APPL, V77, P13075, DOI 10.1007/s11042-017-4933-1
   Combettes PL, 2007, IEEE J-STSP, V1, P564, DOI 10.1109/JSTSP.2007.910264
   Cui Xinyi, 2009, P 17 ACM INT C MULT, P617, DOI DOI 10.1145/1631272.1631370
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Evangelio RH, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P300, DOI 10.1109/AVSS.2012.69
   Fadili MJ, 2009, COMPUT J, V52, P64, DOI 10.1093/comjnl/bxm055
   Ganesh A, 2010, IEEE INT SYMP INFO, P1513, DOI 10.1109/ISIT.2010.5513538
   Gao Z, 2014, IEEE T PATTERN ANAL, V36, P1975, DOI 10.1109/TPAMI.2014.2314663
   Gavrila D., 2000, PROC EUROPEAN C COMP, P37, DOI [DOI 10.1007/3-540-45053-X, 10.1007/3-540-45053-X-3., DOI 10.1007/3-540-45053-X-3]
   Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Guo JM, 2013, IEEE T CIRC SYST VID, V23, P1809, DOI 10.1109/TCSVT.2013.2269011
   Gutchess D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P733, DOI 10.1109/ICCV.2001.937598
   Guyon Charles, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P315, DOI 10.1007/978-3-642-37410-4_28
   Guyon C, 2012, INT C PATT RECOG, P2805
   Guyon C, 2012, LECT NOTES COMPUT SC, V7431, P665, DOI 10.1007/978-3-642-33179-4_63
   Haines TSF, 2014, IEEE T PATTERN ANAL, V36, P670, DOI 10.1109/TPAMI.2013.239
   Hale ET, 2008, SIAM J OPTIMIZ, V19, P1107, DOI 10.1137/070698920
   Han B, 2012, IEEE T PATTERN ANAL, V34, P1017, DOI 10.1109/TPAMI.2011.243
   Huang M, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P1262, DOI 10.1109/ICISCE.2016.270
   Ivanov Y, 2000, INT J COMPUT VISION, V37, P199, DOI 10.1023/A:1008107805263
   Lan X, 2018, NAT C ART INT
   Lan XY, 2020, PATTERN RECOGN LETT, V130, P12, DOI 10.1016/j.patrec.2018.10.002
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2017, AAAI CONF ARTIF INTE, P4118
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Li CL, 2017, IEEE T CIRC SYST VID, V27, P725, DOI 10.1109/TCSVT.2016.2556586
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Lin Z., 2010, Math. Program
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Park MW, 2017, MULTIMED TOOLS APPL, V76, P25343, DOI 10.1007/s11042-017-4521-4
   Reddy V, 2013, IEEE T CIRC SYST VID, V23, P83, DOI 10.1109/TCSVT.2012.2203199
   Rodríguez P, 2013, IEEE IMAGE PROC, P69, DOI 10.1109/ICIP.2013.6738015
   Shu XB, 2014, PROC CVPR IEEE, P3874, DOI 10.1109/CVPR.2014.495
   Starck JL, 2009, IEEE IMAGE PROC, P1453, DOI 10.1109/ICIP.2009.5414556
   Sun L, 2015, MULTIMED TOOLS APPL, V74, P3947, DOI 10.1007/s11042-013-1806-0
   Tang G., 2011, P ANN C INF SCI SYST, P1, DOI DOI 10.1109/CISS.2011.5766144
   Tsai DM, 2009, IEEE T IMAGE PROCESS, V18, P158, DOI 10.1109/TIP.2008.2007558
   Unzueta L, 2012, IEEE T INTELL TRANSP, V13, P527, DOI 10.1109/TITS.2011.2174358
   Van Droogenbroeck M., 2012, 2012 IEEE COMP SOC C, P32
   Wang NY, 2012, LECT NOTES COMPUT SC, V7578, P126, DOI 10.1007/978-3-642-33786-4_10
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Xue YW, 2012, INT CONF ACOUST SPEE, P1485, DOI 10.1109/ICASSP.2012.6288171
   Yang MH, 2015, IEEE T CIRC SYST VID, V25, P595, DOI 10.1109/TCSVT.2014.2361418
   Yi Xinyang, 2016, Advances in Neural Information Processing Systems, P4152
   Yuan X., 2009, SPARSE LOW RANK MATR
   Zhou T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON VEHICULAR ELECTRONICS AND SAFETY (ICVES), P194, DOI 10.1109/ICVES.2013.6619629
NR 61
TC 3
Z9 3
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16507
EP 16526
DI 10.1007/s11042-018-7037-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500035
DA 2024-07-18
ER

PT J
AU Sabri, MA
   Aqel, S
   Aarab, A
AF Abdelouahed Sabri, My
   Aqel, Siham
   Aarab, Abdellah
TI A multiscale based approach for automatic shadow detection and removal
   in natural images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shadow detection and removal; Multi-scale decomposition; Bidimensional
   empirical mode decomposition; Texture features; Photometric features;
   Histogram
AB Shadow is a natural phenomenon observed in most natural images. It can reveal information about the objects shape as well as the illumination direction. In computer vision algorithms, shadow can affect negatively image segmentation results, feature extraction, or object tracking. For that, it is necessary to detect and eliminate shadow. Texture remains the best feature used to detect the shadow and photometric information can be used to eliminate it. However, in case of an image with a shadow projected on a complex texture, most of the proposed approaches in literature are useless. In this study, we propose an automatic and data-driven approach for shadow detection and elimination based on the Bidimensional Empirical Mode Decomposition (BEMD). The main idea is to decompose the shaded image into intrinsic components (IMF) that contains only texture and a residue with only objects shape. Then, shadow detection is performed on the IMFs by matching the pair of segmented regions using texture features, while elimination is carried out via a Gaussian approximation applied only on the residue. Finally, the shadow-free image is obtained by adding all the IMFs and the shadow-free residue. The proposed approach is evaluated in comparison with recent approaches on images with the different type of shadow.
C1 [Abdelouahed Sabri, My] USMBA, Fac Sci Dhar Mahraz, Dept Comp Sci, Fes, Morocco.
   [Aqel, Siham; Aarab, Abdellah] USMBA, Fac Sci Dhar Mahraz, Dept Phys, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Sabri, MA (corresponding author), USMBA, Fac Sci Dhar Mahraz, Dept Comp Sci, Fes, Morocco.
EM abdelouahed.sabri@gmail.com
RI sabri, abdelouahed/ABG-2698-2021; Abdelouahed, Sabri/AGS-2601-2022
OI Abdelouahed, Sabri/0000-0001-5485-486X
CR Agel Siham, 2016, International Journal of Imaging and Robotics, V16, P100
   [Anonymous], SINGLE IMAGE SHADOW
   [Anonymous], INT REV COMPUTERS SO
   [Anonymous], 2010, Chinese Conference on Pattern Recognition, DOI DOI 10.1109/CCPR.2010.5659321
   Arfia FB, 2011, P WORLD C ENG
   Cavallaro A, 2005, IEE P-VIS IMAGE SIGN, V152, P398, DOI 10.1049/ip-vis:20045108
   Gong H, 2014, P BRIT MACH VIS C MV
   Gong H, 2016, J OPT SOC AM A, V33, P1798, DOI 10.1364/JOSAA.33.001798
   Guo RQ, 2013, IEEE T PATTERN ANAL, V35, P2956, DOI 10.1109/TPAMI.2012.214
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Horprasert T., 1999, Proceedings of IEEE ICCV Frame-Rate Workshop, P1
   Huang JB, 2009, PROC CVPR IEEE, P2310, DOI 10.1109/CVPRW.2009.5206629
   Junfeng Wu, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P348, DOI 10.1109/ICIG.2013.75
   Karoud M., 2006, WSEAS Transactions on Computers, V5, P2903
   Khan SH, 2016, IEEE T PATTERN ANAL, V38, P431, DOI 10.1109/TPAMI.2015.2462355
   Leone A, 2007, PATTERN RECOGN, V40, P1222, DOI 10.1016/j.patcog.2006.09.017
   Mahajan R, 2015, PROCEEDINGS OF 2015 IEEE 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO), DOI 10.1109/ISCO.2015.7282374
   Nunes JC, 2003, IMAGE VISION COMPUT, V21, P1019, DOI 10.1016/S0262-8856(03)00094-5
   Rui Qin, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1377, DOI 10.1109/ICPR.2010.340
   Sabri A, 2008, INT J COMPUT SCI NET, V8, P357
   Sabri A, 2008, INT REV COMPUT SOFTW, V4, P8
   Sabri A., 2009, REVIEW, V4, P360
   Sanin A, 2012, PATTERN RECOGN, V45, P1684, DOI 10.1016/j.patcog.2011.10.001
   Vicente TFY, 2018, IEEE T PATTERN ANAL, V40, P682, DOI 10.1109/TPAMI.2017.2691703
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, P4623, DOI 10.1109/TIP.2015.2465159
   ZHU J, PRESS, P223
NR 26
TC 6
Z9 6
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11263
EP 11275
DI 10.1007/s11042-018-6678-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900008
DA 2024-07-18
ER

PT J
AU Dubin, R
   Shalala, R
   Dvir, A
   Pele, O
   Hadar, O
AF Dubin, Ran
   Shalala, Raffael
   Dvir, Amit
   Pele, Ofir
   Hadar, Ofer
TI A fair server adaptation algorithm for HTTP adaptive streaming using
   video complexity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic adaptive streaming over HTTP; Video streaming optimization
AB The increasing popularity of online video content and adaptive video streaming services, especially those based on HTTP Adaptive Streaming (HAS) highlights the need for streaming optimization solutions. From a server perspective, the main drawback of HAS is that the user selects the quality of the next video segment without taking the server constraints into account. These constraints include the number of users simultaneously being served and the server's congestion. Here, we present the Fair Server Adaptation (FSA) algorithm, which is designed to maximize user Quality of Experience (QoE) by tackling the server's bottleneck problem. The algorithm provides the quality representation that is closest to the user's request, subject to the server's constraints. Simulation results show that compared to standard Dynamic Adaptive Streaming over HTTP (DASH) server, FSA increased the number of served users and decreased both the number of rebuffering events and the average rebuffering event duration. Furthermore, the average number of unserved users decreased to almost zero and Jain's fairness index rose. It is clear that these changes increase users' QoE.
C1 [Dubin, Ran; Shalala, Raffael; Hadar, Ofer] Ben Gurion Univ Negev, Commun Syst Engn, Beer Sheva, Israel.
   [Dvir, Amit; Pele, Ofir] Ariel Univ, Dept Comp Sci, Ctr Cyber Technol, Samaria, Israel.
   [Pele, Ofir] Ariel Univ, Dept Elect & Elect Engn, Samaria, Israel.
C3 Ben Gurion University; Ariel University; Ariel University
RP Pele, O (corresponding author), Ariel Univ, Dept Comp Sci, Ctr Cyber Technol, Samaria, Israel.; Pele, O (corresponding author), Ariel Univ, Dept Elect & Elect Engn, Samaria, Israel.
EM ofir.pele@g.ariel.ac.il
RI dvir, amit/AAV-5916-2021; Dubin, Ran/HIR-5440-2022; HADAR,
   OFER/F-2051-2012; Dubin, Ran/CAF-1102-2022
OI dvir, amit/0000-0002-3670-0784; Dubin, Ran/0000-0002-2055-2211; Hadar,
   Ofer/0000-0002-6089-8401; Shalala, Rafael/0009-0005-0832-2236
CR [Anonymous], INF TECHN DYN AD STR
   [Anonymous], SANDV GLOB INT PHEN
   [Anonymous], ARXIV160600341 CORR
   [Anonymous], THESIS
   [Anonymous], 2014, P 13 ACM WORKSH HOT
   [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   [Anonymous], ARXIV170101392 CORR
   [Anonymous], 400 ISOIEC JTC1SC29W
   [Anonymous], WEB FRAM PERF DEADL
   [Anonymous], 2013, PERF EV WIR HOC SENS
   [Anonymous], 2012, CISC VIS NETW IND GL
   [Anonymous], HBO NOW STREAM FAILS
   [Anonymous], 2012, Proceedings of the 22nd international workshop on Network and Operating System Support for Digital Audio and Video
   [Anonymous], P WORLDCOMP NEV
   [Anonymous], 2015, ZETT ER TRENDS AN
   [Anonymous], BANDWIDTH LATENCY MU
   [Anonymous], 2016, MULTIMEDIA SYST
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], XIPH ORG VID DAT BAS
   [Anonymous], P 4 WORKSH MOB VID C
   [Anonymous], 2016, P NOSSDAV 2016
   [Anonymous], IEEE T CIRCUITS SYST
   Bokani A, 2013, 2013 20TH INTERNATIONAL PACKET VIDEO WORKSHOP (PV)
   Broberg J, 2009, J NETW COMPUT APPL, V32, P1012, DOI 10.1016/j.jnca.2009.03.004
   Brodal GS, 2012, STOC'12: PROCEEDINGS OF THE 2012 ACM SYMPOSIUM ON THEORY OF COMPUTING, P1177
   Chen J., 2013, Proceedings of the 19th Annual International Conference on Mobile Computing Networking, P389
   Cicalo Sergio, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P714, DOI 10.1109/ICASSP.2014.6853689
   Claeys M, 2014, CONNECT SCI, V26, DOI 10.1080/09540091.2014.885273
   Dai H., 2011, Acta Horticulturae, P169, DOI 10.1145/1943552.1943575
   De Vleeschauwer D, 2013, IEEE INFOCOM SER, P989
   De Vriendt J, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1288
   Dobrian F, 2011, ACM SIGCOMM COMP COM, V41, P362, DOI 10.1145/2043164.2018478
   Dubin R, 2015, CONSUM COMM NETWORK, P683, DOI 10.1109/CCNC.2015.7158061
   Dubin R, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P2178
   El Essaili A., 2013, 2013 IEEE International Conference on Communications (ICC), P2480, DOI 10.1109/ICC.2013.6654905
   Huang CM, 2014, IEEE CONF WIREL MOB, P679, DOI 10.1109/WiMOB.2014.6962244
   Jain R., 1984, DEC TECHNICAL REPORT
   Janowski L, 2012, MULTIMED TOOLS APPL, V61, P769, DOI 10.1007/s11042-011-0932-9
   Jarnikov D, 2011, SIGNAL PROCESS-IMAGE, V26, P378, DOI 10.1016/j.image.2011.03.003
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Kim K, 2016, MITOCHONDRIAL DNA A, V27, P3033, DOI 10.3109/19401736.2015.1063121
   Krishnan SS, 2013, IEEE ACM T NETWORK, V21, P2001, DOI 10.1109/TNET.2013.2281542
   Le Feuvre J., 2007, P 15 ACM INT C MULT, P1009, DOI [10.1145/1291233.1291452, DOI 10.1145/1291233.1291452]
   Liu Y, 2007, IEEE T CIRC SYST VID, V17, P68, DOI 10.1109/TCSVT.2006.887081
   Miller K., 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P173, DOI 10.1109/PV.2012.6229732
   Mok R.K., 2011, PROC ACM SIGCOMM WOR, P31, DOI DOI 10.1145/2018602.2018611
   Mok R.K., 2012, P 3 MULTIMEDIA SYSTE, P11
   Mueller C., 2012, VISUAL COMMUN-US, P1
   Muller C., 2012, 4th ACM Workshop on Mobile Video (MoVID), P37, DOI DOI 10.1145/2151677.2151686
   Ran DB, 2015, IEEE CONF COMPUT, P269, DOI 10.1109/INFCOMW.2015.7179396
   Rickinson M, 2011, IMPROV LEARN TLRP, P1
   Sieber C, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1318
   Tian G., 2012, P 8 INT C EM NETW EX, P109
   Tingyao Wu, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P553, DOI 10.1007/978-3-319-04114-8_47
   Thang TC, 2012, 2012 FOURTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P130, DOI 10.1109/CCE.2012.6315884
   Yim C, 2011, SIGNAL PROCESS-IMAGE, V26, P24, DOI 10.1016/j.image.2010.11.002
NR 56
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11203
EP 11222
DI 10.1007/s11042-018-6615-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900006
DA 2024-07-18
ER

PT J
AU Araujo, JDL
   Souza, JC
   Neto, OPS
   de Sousa, JA
   de Almeida, JDS
   de Paiva, AC
   Silva, AC
   Braz, G
   Gattass, M
AF Lima Araujo, Jose Denes
   Souza, Johnatan Carvalho
   Silva Neto, Otilio Paulo
   de Sousa, Jefferson Alves
   Sousa de Almeida, Joao Dallyson
   de Paiva, Anselmo Cardoso
   Silva, Aristofanes Correa
   Braz Junior, Geraldo
   Gattass, Marcelo
TI Glaucoma diagnosis in fundus eye images using diversity indexes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Glaucoma; Fundus eye image; Computer aided diagnosis; Diversity indexes
ID AUTOMATED DETECTION; ALGORITHMS
AB Glaucoma is the second major cause of vision loss worldwide. It is usually caused by the increase in the intraocular pressure, which damages the optic nerve resulting in gradual vision loss. Glaucoma is an asymptomatic disease in the initial stages. Early detection and treatment may prevent the vision loss. The head of the optic nerve (optic disc) is examined by using fundus eye images. Computer systems have been used to provide support in glaucoma diagnosis. This work proposes a method for glaucoma diagnosis using fundus eye images. Diversity indexes, which are typically used in ecological studies, are used in this work as texture descriptors in the optic disc region. Then, a feature selection procedure is performed using genetic algorithm and support vector machines (SVM) are used to classify fundus eye images in glaucomatous or normal. The proposed method obtained promising results for glaucoma diagnosis, reaching an accuracy of 93.41%, sensitivity of 92.83% and specificity of 93.69%.
C1 [Lima Araujo, Jose Denes; Souza, Johnatan Carvalho; Silva Neto, Otilio Paulo; de Sousa, Jefferson Alves] Univ Fed Maranhao, Elect Engn, Sao Luis, Maranhao, Brazil.
   [Sousa de Almeida, Joao Dallyson; de Paiva, Anselmo Cardoso; Silva, Aristofanes Correa; Braz Junior, Geraldo] Univ Fed Maranhao, Sao Luis, Maranhao, Brazil.
   [Gattass, Marcelo] Pontificia Univ Catolica Rio de Janeiro, Rio De Janeiro, Brazil.
C3 Universidade Federal do Maranhao; Universidade Federal do Maranhao;
   Pontificia Universidade Catolica do Rio de Janeiro
RP Araujo, JDL (corresponding author), Univ Fed Maranhao, Elect Engn, Sao Luis, Maranhao, Brazil.
EM josedenes17@gmail.com
RI Paiva, Anselmo/L-2358-2013; Braz, Geraldo/AAW-1827-2021
OI Paiva, Anselmo/0000-0003-4921-0626; Braz, Geraldo/0000-0003-3731-6431;
   Almeida, Joao Dallyson Sousa de Almeida/0000-0001-7013-9700
FU Coordination for the Improvement of Higher Education Personnel (CAPES);
   National Council for Scientific and Technological Development (CNPq);
   Foundation for the Protection of Research and Scientific; Technological
   Development of the State of Maranhao (FAPEMA)
FX The authors acknowledge the Coordination for the Improvement of Higher
   Education Personnel (CAPES), the National Council for Scientific and
   Technological Development (CNPq), the Foundation for the Protection of
   Research and Scientific, the Technological Development of the State of
   Maranhao (FAPEMA) for financial support.
CR Abramoff Michael D, 2010, IEEE Rev Biomed Eng, V3, P169, DOI 10.1109/RBME.2010.2084567
   Acharya UR, 2015, BIOMED SIGNAL PROCES, V15, P18, DOI 10.1016/j.bspc.2014.09.004
   Al-Bander B, 2017, INT MULTICONF SYST, P207, DOI 10.1109/SSD.2017.8166974
   Almazroa A, 2015, J OPHTHALMOL, V2015, DOI 10.1155/2015/180972
   [Anonymous], 2004, MEASURING BIOL DIVER
   [Anonymous], 2015, INTRO MED STAT
   [Anonymous], WHAT IS GLAUC
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2016, P INT J COMPUT APPL
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Banic N, 2013, IEEE SIGNAL PROC LET, V20, P1240, DOI 10.1109/LSP.2013.2285960
   Bock R, 2010, MED IMAGE ANAL, V14, P471, DOI 10.1016/j.media.2009.12.006
   de Sousa JA, 2017, MULTIMED TOOLS APPL, V76, P19173, DOI 10.1007/s11042-017-4608-y
   Duda Hart., 1973, PATTERN CLASSIFICATI
   Faust O, 2012, J MED SYST, V36, P145, DOI 10.1007/s10916-010-9454-7
   Gajbhiye GO, 2015, ANNU IEEE IND CONF
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Gonzalez R. C., 2010, PROCESSAMENTO DIGITA
   Haleem MS, 2013, COMPUT MED IMAG GRAP, V37, P581, DOI 10.1016/j.compmedimag.2013.09.005
   Haniz Azril, 2014, 2014 XXXIth URSI General Assembly and Scientific Symposium (URSI GASS), DOI 10.1109/URSIGASS.2014.6929358
   Kanan C, 2012, PLOS ONE, V7, P133, DOI 10.1371/journal.pone.0029740
   Koh JEW, 2013, J MED IMAG HEALTH IN, V3, P401, DOI 10.1166/jmihi.2013.1173
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lin SC, 2007, OPHTHALMOLOGY, V114, P1937, DOI 10.1016/j.ophtha.2007.07.005
   Maheshwari S, 2017, COMPUT BIOL MED, V88, P142, DOI 10.1016/j.compbiomed.2017.06.017
   Maheshwari S, 2017, IEEE J BIOMED HEALTH, V21, P803, DOI 10.1109/JBHI.2016.2544961
   Mary MCVS, 2016, IEEE ACCESS, V4, P4327, DOI 10.1109/ACCESS.2016.2596761
   MCINTOSH RP, 1967, ECOLOGY, V48, P392, DOI 10.2307/1932674
   Mookiah MRK, 2012, KNOWL-BASED SYST, V33, P73, DOI 10.1016/j.knosys.2012.02.010
   Noronha KP, 2014, BIOMED SIGNAL PROCES, V10, P174, DOI 10.1016/j.bspc.2013.11.006
   Oh JE, 2015, INVEST OPHTH VIS SCI, V56, P2872, DOI 10.1167/iovs.14-15096
   Raja C, 2015, COMPUT BIOL MED, V63, P196, DOI 10.1016/j.compbiomed.2015.05.018
   Ramasubramanian B, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P642, DOI 10.1109/ICCSP.2016.7754220
   Shannon C., 1949, MATH THEORY COMMUNIC, P29
   SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8
   Tham YC, 2014, OPHTHALMOLOGY, V121, P2081, DOI 10.1016/j.ophtha.2014.05.013
   Trucco E, 2013, INVEST OPHTH VIS SCI, V54, P3546, DOI 10.1167/iovs.12-10347
   Zhang Z, 2014, BMC MED INFORM DECIS, V14, DOI 10.1186/1472-6947-14-80
   Zhuang L, 2006, J COMPUT, V1, P32
NR 39
TC 9
Z9 9
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 12987
EP 13004
DI 10.1007/s11042-018-6429-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900015
DA 2024-07-18
ER

PT J
AU Majtner, T
   Yildirim-Yayilgan, S
   Hardeberg, JY
AF Majtner, Tomas
   Yildirim-Yayilgan, Sule
   Hardeberg, Jon Yngve
TI Optimised deep learning features for improved melanoma detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin lesion recognition; Linear discriminant analysis; Convolutional
   neural networks; Image classification; Feature selection
ID DECISION-SUPPORT; HAIR REMOVAL; DERMOSCOPY; SKIN; CLASSIFICATION;
   TEXTURE; IMAGES; LEVEL
AB In this article, we are addressing the question of effective usage of the feature set extracted from deep learning models pre-trained on ImageNet. Exploring this option will offer very fast and attractive alternative to transfer learning strategies. The traditional task of skin lesion recognition consists of several stages, where the automated system is typically trained on preprocessed images with known diagnosis, which allows classification of new samples to predefined categories. For this task, we are proposing here an improved melanoma detection method based on the combination of linear discriminant analysis (LDA) and the features extracted from the deep learning approach. We are examining the usage of the LDA approach on activation of the fully-connected layer of deep learning in order to increase the classification accuracy and at the same time to reduce the feature space dimensionality. We tested our method on five different classifiers and evaluated results using various metrics. The presented comparison demonstrates the very high effectiveness of the suggested feature reduction, which leads not only to the significant lowering of employed features but also to the increasing performance of all tested classifiers in almost all measured characteristics.
C1 [Majtner, Tomas; Hardeberg, Jon Yngve] NTNU Norwegian Univ Sci & Technol, Dept Comp Sci, Gjovik, Norway.
   [Yildirim-Yayilgan, Sule] NTNU Norwegian Univ Sci & Technol, Dept Informat Secur & Commun Technol, Gjovik, Norway.
C3 Norwegian University of Science & Technology (NTNU); Norwegian
   University of Science & Technology (NTNU)
RP Majtner, T (corresponding author), NTNU Norwegian Univ Sci & Technol, Dept Comp Sci, Gjovik, Norway.
EM majtner.tom@gmail.com
RI Yıldırım, Şule/JBS-3948-2023; YILDIRIM YAYILGAN, Sule/H-6700-2018;
   Majtner, Tomas/G-3649-2018
OI YILDIRIM YAYILGAN, Sule/0000-0002-1982-6609; Majtner,
   Tomas/0000-0002-5279-8806
FU Research Council of Norway [247689]
FX This research has been supported by the Research Council of Norway
   through project no. 247689 "IQ-MED: Image Quality enhancement in MEDical
   diagnosis, monitoring and treatment".
CR Abbas Q, 2011, BIOMED SIGNAL PROCES, V6, P395, DOI 10.1016/j.bspc.2011.01.003
   [Anonymous], 2005, Synthesis Lectures on Biomedical Engineering
   [Anonymous], 2016, ARXIV160101145
   [Anonymous], ARXIV160501397 CORR
   [Anonymous], INT ENCY STAT SCI
   [Anonymous], NASJONALE RETNINGSLI
   [Anonymous], 2014, ABS14053531 CORR
   [Anonymous], 2015, ARXIV150702313
   [Anonymous], RITA
   [Anonymous], COL VIS COMP S
   Argenziano G, 2003, J AM ACAD DERMATOL, V48, P679, DOI 10.1067/mjd.2003.281
   Ballerini L., 2013, Color medical image analysis, P63
   Barata C, 2014, IEEE SYST J, V8, P965, DOI 10.1109/JSYST.2013.2271540
   Bernstein A, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P330, DOI 10.1109/ICMLA.2014.59
   Beuren A. T., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P284
   Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51
   Codella Noel, 2015, Machine Learning in Medical Imaging. 6th International Workshop, MLMI 2015, held in conjunction with MICCAI 2015. Proceedings: LNCS 9352, P118, DOI 10.1007/978-3-319-24888-2_15
   Codella NCF, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2708299
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Geisler Jurgen, 2013, Tidsskr Nor Laegeforen, V133, P2154, DOI 10.4045/tidsskr.12.1416
   Gilmore S, 2010, EXP DERMATOL, V19, P830, DOI 10.1111/j.1600-0625.2010.01112.x
   Glowacz A, 2016, BIOCYBERN BIOMED ENG, V36, P95, DOI 10.1016/j.bbe.2015.12.005
   Haenssle HA, 2018, ANN ONCOL, V29, P1836, DOI 10.1093/annonc/mdy166
   Hao Pan, 2015, Patch-Based Techniques in Medical Imaging. First International Workshop, Patch-MI 2015, held in conjunction with MICCAI 2015. Revised Selected Papers: LNCS 9467, P87, DOI 10.1007/978-3-319-28194-0_11
   Kawahara J, 2016, I S BIOMED IMAGING, P1397, DOI 10.1109/ISBI.2016.7493528
   Keogh Eamonn, 2010, ENCY MACHINE LEARNIN, P257
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570
   Lee T, 1997, COMPUT BIOL MED, V27, P533, DOI 10.1016/S0010-4825(97)00020-6
   Lei HJ, 2018, PATTERN RECOGN, V79, P290, DOI 10.1016/j.patcog.2018.02.006
   Liu Y, 2015, COMM COM INF SC, V546, P398, DOI 10.1007/978-3-662-48558-3_40
   Lyman JA, 2010, J AM MED INFORM ASSN, V17, P487, DOI 10.1136/jamia.2010.005561
   Majtner T, 2016, PROCEEDINGS OF THE 2016 6TH EUROPEAN WORKSHOP ON VISUAL INFORMATION PROCESSING (EUVIP), DOI 10.1109/EUVIP.2016.7764580
   Majtner T, 2016, INT CONF IMAG PROC, DOI 10.1109/IPTA.2016.7821017
   Majtner T, 2016, LECT NOTES COMPUT SC, V9730, P30, DOI 10.1007/978-3-319-41501-7_4
   Moisl H, 2009, HANDB SPRACH KOMMUN, V29, P874
   Nasr-Esfahani E, 2016, IEEE ENG MED BIO, P1373, DOI 10.1109/EMBC.2016.7590963
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714
   Toossi MTB, 2013, SKIN RES TECHNOL, V19, P230, DOI 10.1111/srt.12015
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
NR 43
TC 23
Z9 24
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11883
EP 11903
DI 10.1007/s11042-018-6734-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900036
DA 2024-07-18
ER

PT J
AU Agrawal, S
   Singh, RK
   Singh, UP
   Jain, S
AF Agrawal, Suchitra
   Singh, Rajeev Kumar
   Singh, Uday Pratap
   Jain, Sanjeev
TI Biogeography particle swarm optimization based counter propagation
   network for sketch based face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BPSO-CPN; SBFR; Exemplar vector; Face recognition
ID DISCRIMINANT-ANALYSIS; FEATURES; TEXTURE; IMAGES; SYSTEM; SCALE
AB In this paper, we present a Biogeography Particle Swarm Optimization (BPSO) based Counter Propagation Network (CPN) i.e. BPSO-CPN for Sketch Based Face Recognition (SBFR) system. A new criterion of selecting exemplar vector using biogeography learning based PSO is used for optimization of Mean Square Error (MSE) between feature vector of sketch and photo. In this work, we use Histogram of Gradient (HOG) feature vector for similarity measures between sketch and photo. Select a sketch as query image from database and using BPSO-CPN to retrieves similar photos from database. Proposed BPSO-CPN method is tested on CUHK and IIITD sketch dataset containing about 1000 sketches and photos. The experimental result envisage that, BPSO-CPN gives promising results and achieves high precision as comparison with other existing methods and neural networks. Motivation behind this research work is to find missing or wanted persons who involve in antinational activities and it help investigating agencies to narrow down the suspects quickly.
C1 [Agrawal, Suchitra; Singh, Rajeev Kumar] Madhav Inst Sci & Technol, Dept CSE & IT, Gwalior 474005, India.
   [Singh, Uday Pratap] Shri Mata Vaishno Devi Univ, Sch Math, Jammu 182320, Jammu & Kashmir, India.
   [Jain, Sanjeev] Shri Mata Vaishno Devi Univ, Dept Comp Sci & Engn, Katra 182320, India.
C3 Madhav Institute of Technology & Science; Shri Mata Vaishno Devi
   University; Shri Mata Vaishno Devi University
RP Agrawal, S (corresponding author), Madhav Inst Sci & Technol, Dept CSE & IT, Gwalior 474005, India.
EM suchiagrawal0007@gmail.com
RI Singh, Uday Pratap/AAW-9594-2020; JAIN, SANJEEV/M-1736-2018; Agrawal,
   Suchitra/KII-5653-2024; Singh, Rajeev Kumar/HKN-4005-2023
OI Singh, Uday Pratap/0000-0003-2077-0793; Agrawal,
   Suchitra/0000-0001-8822-783X; Singh, Rajeev Kumar/0000-0003-1009-3637
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], IEEE C AC SPEECH SIG
   [Anonymous], 2012, P 20 ACM INT C MULT
   Ara V.N., 1999, Proceedings of the IEEE Conference on Audio and Video-Based Biometric Person Authentication, P19
   Baker E, 1998, TR1698 HARV COMP SCI
   Baker E, 1997, TR2097 HARV COMP SCI
   Bhatt HS, 2012, IEEE T INF FOREN SEC, V7, P1522, DOI 10.1109/TIFS.2012.2204252
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Galea C, 2016, EUR SIGNAL PR CONF, P2240, DOI 10.1109/EUSIPCO.2016.7760647
   Galoogahi H. K., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P224, DOI 10.1109/ICME.2012.128
   Galoogahi HK, 2012, IEEE IMAGE PROC, P1837, DOI 10.1109/ICIP.2012.6467240
   Gao XN, 2008, IEEE T CIRC SYST VID, V18, P487, DOI 10.1109/TCSVT.2008.918770
   Gong DH, 2017, IEEE T IMAGE PROCESS, V26, P2079, DOI 10.1109/TIP.2017.2651380
   Gong DH, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P135, DOI 10.1109/ACPR.2013.12
   GUO Z, 1971, TIP, V19, P1657, DOI DOI 10.1109/TIP.2010.2044957
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229
   Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180
   Konen W., 1996, Artificial Neural Networks - ICANN 96. 1996 International Conference Proceedings, P727
   Lei Z, 2012, IEEE T INF FOREN SEC, V7, P1707, DOI 10.1109/TIFS.2012.2210041
   Li ZF, 2014, IEEE T IMAGE PROCESS, V23, P2436, DOI 10.1109/TIP.2014.2315920
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu QS, 2005, PROC CVPR IEEE, P1005
   Liu W, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2141
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma HP, 2010, INFORM SCIENCES, V180, P3444, DOI 10.1016/j.ins.2010.05.035
   Man CH, 2002, P IAPR WORKSH MACH V, P500
   Nagai T, 2004, SIGNAL PROCESS, V5, P749
   Nandagopalan S., 2008, INT J COMPUT ELECT A, V2, P3436
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Saha SK, 2004, INT C PATT RECOG, P985, DOI 10.1109/ICPR.2004.1334424
   Sakhre V, 2017, INT J FUZZY SYST, V19, P452, DOI 10.1007/s40815-016-0145-5
   Shepherd J.W.:., 1986, ASPECTS FACE PROCESS, P398
   Shoujue Wang, 2009, Proceedings of the 2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2009), P81, DOI 10.1109/FSKD.2009.294
   Silva MAA, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P57, DOI 10.1109/SIBGRAPI.2014.24
   Simon D, 2008, IEEE T EVOLUT COMPUT, V12, P702, DOI 10.1109/TEVC.2008.919004
   Singh UP, 2018, SOFT COMPUT, V22, P2667, DOI 10.1007/s00500-017-2522-x
   Singh UP, 2016, INT J COMPUT INTELL, V15, DOI 10.1142/S1469026816500164
   Subudhi B, 2011, APPL SOFT COMPUT, V11, P861, DOI 10.1016/j.asoc.2010.01.006
   Tamura H., 1978, IEEE Transactions on Systems, Man and Cybernetics, VSMC-8, P460, DOI 10.1109/TSMC.1978.4309999
   Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353
   Tang XO, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P687, DOI 10.1109/ICCV.2003.1238414
   Tharwat A, 2015, INT CONF SOFT COMPUT, P117, DOI 10.1109/SOCPAR.2015.7492793
   Tharwat A, 2014, ADV INTELL SYST, V303, P217, DOI 10.1007/978-3-319-08156-4_22
   Uhl R. G.  Jr., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P129, DOI 10.1109/ACV.1994.341299
   Uhl RG, 1996, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.1996.517132
   Wang X., 2008, J CHANGCHUN U SCI TE, V31, P11
   Xiao B, 2009, SIGNAL PROCESS, V89, P1576, DOI 10.1016/j.sigpro.2009.02.008
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhang W, 2011, PROC CVPR IEEE, P513, DOI 10.1109/CVPR.2011.5995324
   Zhong J, 2007, IEEE T CIRCUITS SYST, V18, P487, DOI [10.1109/TCSVT.2008.918770, DOI 10.1109/TCSVT.2008.918770]
NR 63
TC 5
Z9 7
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9801
EP 9825
DI 10.1007/s11042-018-6542-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400014
DA 2024-07-18
ER

PT J
AU Chang, TJ
   Pan, IH
   Huang, PS
   Hu, CH
AF Chang, Te-Jen
   Pan, I-Hui
   Huang, Ping-Sheng
   Hu, Chen-Hao
TI A robust DCT-2DLDA watermark for color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Two-dimensional linear discriminant analysis (2DLDA); Digital watermark;
   Discrete cosine transform (DCT)
ID DWT-SVD; SCHEME; FACE
AB A blind watermarking algorithm is proposed, which is based on the Discrete Cosine Transform (DCT) method. It uses Two-Dimensional Linear Discriminant Analysis (2DLDA) watermark scheme for copyright protection. During the embedding process, the color image is converted into the YIQ color space. The quadrature chrominance component is transformed into frequency domain and it uses DCT method. Then, two binary watermarks for reference and logo are added to particular bits of the AC coefficients. During the extraction process, the logo watermark is extracted using matrix-based 2DLDA based on DCT method. By embedding the training data and using a matrix-based 2DLDA scheme, we do not need all the embedded information. The numbers of training samples for each class are small; the training covariance matrices are directly computed from 2D image samples by using 2DLDA. This ensures the efficient and the robustness of watermark extraction. Experimental results demonstrate that the differences between the watermarked image and the original image are indistinguishable. The proposed method is effectively resist common image processing attacks.
C1 [Chang, Te-Jen] Natl Def Univ, Chung Cheng Inst Technol, Dept Elect & Elect Engn, Taoyuan, Taiwan.
   [Pan, I-Hui] Natl Def Univ, Air Command & Staff Coll, Taoyuan, Taiwan.
   [Huang, Ping-Sheng] Ming Chuan Univ, Dept Elect Engn, Taipei, Taiwan.
   [Hu, Chen-Hao] Air Force Inst Technol, Dept Aeroelect Engn, Gangshan Townwhip 820, Kaohsiung Cty, Taiwan.
C3 National Defense University - Taiwan; National Defense University -
   Taiwan; Ming Chuan University
RP Hu, CH (corresponding author), Air Force Inst Technol, Dept Aeroelect Engn, Gangshan Townwhip 820, Kaohsiung Cty, Taiwan.
EM karl591218@gmail.com; panchefukui@gmail.com; pshuang@mail.mcu.edu.tw;
   chenhao.hu@gmail.com
RI Pan, Indrajit/AAF-4376-2020
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Agarwal H, 2015, MULTIMED TOOLS APPL, V74, P10883, DOI 10.1007/s11042-014-2212-y
   Agarwal H, 2015, MULTIMED TOOLS APPL, V74, P6897, DOI 10.1007/s11042-014-1934-1
   Algashaam FM, 2017, IEEE ACCESS, V5, P14572, DOI 10.1109/ACCESS.2017.2731118
   ALOTAIBI NA, 2014, THE 3RD INTERNATIONA, V3, P73
   Chang TJ, 2014, INFORMATION, V17, P2145
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Han SC, 2018, OPTOELECTRON LETT, V14, P61, DOI 10.1007/s11801-018-7212-0
   Hou DD, 2019, IEEE T CIRC SYST VID, V29, P363, DOI 10.1109/TCSVT.2018.2803303
   Korus P, 2015, IEEE T MULTIMEDIA, V17, P157, DOI 10.1109/TMM.2014.2368696
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Lakrissi Y, 2018, MULTIMED TOOLS APPL, V77, P13531, DOI 10.1007/s11042-017-4974-5
   LEE J, 1950, TIP, V27, P1939, DOI DOI 10.1109/TIP.2018.2790481
   Leng L, 2010, 2010 INT C INF COMM
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li JZ, 2018, SOFT COMPUT, V22, P47, DOI 10.1007/s00500-016-2320-x
   Li LG, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/181050
   Li SM, 2018, IEEE T DIELECT EL IN, V25, P749, DOI 10.1109/TDEI.2018.007038
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Liu S, 2017, IET IMAGE PROCESS, V11, P815, DOI 10.1049/iet-ipr.2016.0862
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lu XQ, 2018, IEEE T GEOSCI REMOTE, V56, P1704, DOI 10.1109/TGRS.2017.2767068
   Lu YH, 2018, IEEE T RADIAT PLASMA, V2, P41, DOI 10.1109/TRPMS.2017.2778008
   Pan I. - H., 2013, LECT NOTES ELECT ENG, V253, P57, DOI DOI 10.1007/978-94-007-6996-07
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Patvardhan C, 2018, MULTIMED TOOLS APPL, V77, P12655, DOI 10.1007/s11042-017-4909-1
   PEI J, 2016, IEEE J SEL TOP QUANT, V9, P2206, DOI DOI 10.1109/JSTARS.2016.2555938
   Phadikar A, 2011, COMPUT ELECTR ENG, V37, P339, DOI 10.1016/j.compeleceng.2011.02.002
   Pizzolante R., 2011, Proceedings of the 2011 Third International Conference on Intelligent Networking and Collaborative Systems (INCoS 2011), P698, DOI 10.1109/INCoS.2011.153
   Pizzolante R, 2016, 10 INT C P2P PAR GRI, P458
   Shifa A, 2018, IEEE ACCESS, V6, P16189, DOI 10.1109/ACCESS.2018.2815037
   Thanh TM, 2017, MULTIMED TOOLS APPL, V76, P13455, DOI 10.1007/s11042-016-3750-2
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Uccellari M, 2018, IET MICROW ANTENNA P, V12, P302, DOI 10.1049/iet-map.2017.0364
   Xing Y, 2018, IEEE-CAA J AUTOMATIC, V5, P645, DOI 10.1109/JAS.2018.7511063
   Zhao JH, 2015, IEEE T NEUR NET LEAR, V26, P1669, DOI 10.1109/TNNLS.2014.2350993
NR 41
TC 11
Z9 12
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9169
EP 9191
DI 10.1007/s11042-018-6505-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800069
DA 2024-07-18
ER

PT J
AU Guo, NX
   Luo, JZ
   Ling, Z
   Yang, M
   Wu, WJ
   Fu, XW
AF Guo, Naixuan
   Luo, Junzhou
   Ling, Zhen
   Yang, Ming
   Wu, Wenjia
   Fu, Xinwen
TI Your clicks reveal your secrets: a novel user-device linking method
   through network and visual data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Linking; Click behavior; Network traffic
AB Cameras for visual surveillance are extensively deployed to monitor people's locations and activities. The law enforcement can analyze the surveillance videos (V-data) to track the whereabouts of the criminal suspects. On the other hand, with the popular use of the mobile phones and a wide coverage of wireless networks, people can easily access the Internet. The law enforcement also need to analyze the network traffic (N-data) to track the device so as to monitor the criminal suspects' online behaviors. In order to match the suspects' online and offline behaviors, the key problem is to link the device and its user. In this paper, we present a novel method to link the target with his mobile device by analyzing the N-V data. We use a camera and a wireless access point to monitor people operating their mobile devices in public places such as bars, shopping malls, or similar gathering places. Our user-device linking method is based on the premise that when a user is playing an app, his click activities can generate particular network traffic packets in a short time. Based on this premise, our research is carried out as follows. First, we design experiments to detect the particular packets and figure out the time gap distribution between the user's clicks and these packets. Through statistical work, we find that for 97.4% of all instances, the time gap is less than 0.5 s. Then we choose five popular social networking apps to evaluate our method. We find that the main impact factors on the experimental results are the different user's habits and the app's category. Finally, by simulating two real-world scenarios in which people use different apps, we verify the effectiveness of the linking method. Both in scenario 1 and 2, the accuracy rate of experimental results reaches about 94% when the participants include 5 persons and exceeds 84% in experiments including 10 persons, with the fastest linking speed achieved in 20 s.
C1 [Guo, Naixuan; Luo, Junzhou; Ling, Zhen; Yang, Ming; Wu, Wenjia] Southeast Univ, Dept Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.
   [Fu, Xinwen] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.
C3 Southeast University - China; State University System of Florida;
   University of Central Florida
RP Guo, NX (corresponding author), Southeast Univ, Dept Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.
EM guonaixuan@seu.edu.cn
RI Fu, Xinwen/AAP-8640-2021; Ling, Zhen/AAH-3954-2021; Yang,
   Ming/K-8245-2012
OI Fu, Xinwen/0000-0003-2391-7789; Ling, Zhen/0000-0001-9691-8702; Yang,
   Ming/0000-0002-8679-9137; Naixuan, Guo/0000-0002-6375-3419
FU National Key R&D Program of China [2017YFB1003000, 2018YFB0803400];
   National Natural Science Foundation of China [61502100, 61532013,
   61572130, 61632008]; Jiangsu Provincial Natural Science Foundation of
   China [BK20150637]; Jiangsu Provincial Scientific and Technological
   Achievements Transfer Fund [BA2016052]; Jiangsu Provincial Key
   Laboratory of Network and Information Security [BM2003201]; Key
   Laboratory of Computer Network and Information Integration of Ministry
   of Education of China [93K-9]; Collaborative Innovation Center of Novel
   Software Technology and Industrialization
FX This work was supported in part by National Key R&D Program of China
   2017YFB1003000, and 2018YFB0803400, National Natural Science Foundation
   of China under grants 61502100, 61532013, 61572130, and 61632008, by
   Jiangsu Provincial Natural Science Foundation of China under grants
   BK20150637, Jiangsu Provincial Scientific and Technological Achievements
   Transfer Fund BA2016052, by Jiangsu Provincial Key Laboratory of Network
   and Information Security under grants BM2003201, by Key Laboratory of
   Computer Network and Information Integration of Ministry of Education of
   China under grants 93K-9 and by Collaborative Innovation Center of Novel
   Software Technology and Industrialization. Any opinions, findings,
   conclusions, and recommendations in this paper are those of the authors
   and do not necessarily reflect the views of the funding agencies.
CR Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Conti M, 2016, IEEE T INF FOREN SEC, V11, P114, DOI 10.1109/TIFS.2015.2478741
   Cunche M, 2014, PERVASIVE MOB COMPUT, V11, P56, DOI 10.1016/j.pmcj.2013.04.001
   Dai SF, 2013, IEEE INFOCOM SER, P809
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Herrmann D, 2013, COMPUT SECUR, V39, P17, DOI 10.1016/j.cose.2013.03.012
   Huang YC, 2015, IEEE SYS MAN CYBERN, P2944, DOI 10.1109/SMC.2015.512
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   KUMPOT M, 2009, LECT NOTES COMPUT SC, P1
   Li G, 2017, INT CON DISTR COMP S, P689, DOI 10.1109/ICDCS.2017.89
   Li XF, 2013, IEEE INFOCOM SER, P500
   Mao JH, 2016, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2016.9
   Matte C, 2015, P 8 ACM C SEC PRIV W, P20
   Mayer JR, 2012, P IEEE S SECUR PRIV, P413, DOI 10.1109/SP.2012.47
   Mills D.L., 2006, COMPUTER NETWORK TIM
   Musa ABM., 2012, P 10 ACM C EMBEDDED, P281, DOI [10.1145/2426656.2426685, DOI 10.1145/2426656.2426685]
   MYERS CS, 1981, AT&T TECH J, V60, P1389, DOI 10.1002/j.1538-7305.1981.tb00272.x
   Nebehay G., 2014, P IEEE WINT C APPL C
   Nebehay G, 2015, PROC CVPR IEEE, P2784, DOI 10.1109/CVPR.2015.7298895
   Nguyen LT, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P529, DOI 10.1145/2632048.2636072
   Olejnik Lukasz, 2013, SELLING PRIVACY AUCT
   Peng P, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P707, DOI 10.1145/2600428.2609557
   Peng P, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P969
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shukla D, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P904, DOI 10.1145/2660267.2660360
   Stober T., 2013, Proc. Sixth ACM Conf. Security and Privacy in Wireless and Mobile Networks (WiSec'13), Budapest, P7, DOI [10.1145/2462096.2462099, DOI 10.1145/2462096.2462099]
   Teng J, 2014, IEEE ACM T NETWORK, V22, P1285, DOI 10.1109/TNET.2013.2274283
   Teng J, 2012, IEEE INFOCOM SER, P109, DOI 10.1109/INFCOM.2012.6195467
   Wang QL, 2015, IEEE CONF COMM NETW, P433, DOI 10.1109/CNS.2015.7346855
   Wang YH, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1231, DOI 10.1145/2736277.2741634
   Yoon Sung-Ho., 2015, APPL MATH, V9, P523
   Yue QG, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1403, DOI 10.1145/2660267.2660288
NR 35
TC 3
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8337
EP 8362
DI 10.1007/s11042-018-6815-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800026
DA 2024-07-18
ER

PT J
AU Jia, XX
   Wang, DS
   Chu, QM
   Chen, ZH
AF Jia, Xingxing
   Wang, Daoshun
   Chu, Qimeng
   Chen, Zhenhua
TI An efficient XOR-based verifiable visual cryptographic scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Verifiable visual cryptographic scheme; Pixel
   expansion
ID CHEATING PREVENTION
AB Visual cryptographic (VC) schemes have been widely used in secure multimedia systems for data transmission and data storage. It divides a secret image into n random-seemingly share images printed on the transparencies. Superimposing the designed shares will display the recovered secret image which can be recognized by human visual system. It is very convenient to decode the secret since it requires no cryptographic knowledge and computation. However, there is a high chance for dishonest shareholders to present faked shares in the secret reconstruction phase, which would result in a huge damage to the honest shareholders. In this article, a secure approach to verify the cheating shares has been proposed to achieve fair reconstruction of the image secret. It is designed to share a verification image among the original shares of the XOR based VC scheme. It only increases pixel expansion by one to achieve the verification function. Cheating detection ability is attained by pairwise superimposing the shares so that any cheating behavior can be detected by the honest participant. The secret image is recovered and its recovered contrast becomes 1times of the original contrast where m denotes the pixel expansion of the original scheme. The verification image is probabilistically recovered and its recovered contrast is 12(m+1) Compared with traditional verifiable (k,n)-VC schemes against cheating, it overcomes the drawbacks such as requiring additional shares, additional large pixel expansion, or lower contrast. The experimental results show that the visual quality of the recovered secret image is as good as expected. The security analysis and comparative results based on various aspects of VC schemes demonstrate the better efficiency of the proposed approach over existing schemes.
C1 [Jia, Xingxing; Chu, Qimeng] Lanzhou Univ, Sch Math & Stat, Lanzhou, Gansu, Peoples R China.
   [Wang, Daoshun] Tsinghua Univ, Sch Comp, Beijing, Peoples R China.
   [Chen, Zhenhua] Xian Univ Sci & Technol, Sch Comp Sci & Technol, Xian, Shaanxi, Peoples R China.
C3 Lanzhou University; Tsinghua University; Xi'an University of Science &
   Technology
RP Jia, XX (corresponding author), Lanzhou Univ, Sch Math & Stat, Lanzhou, Gansu, Peoples R China.
EM jiaxx@lzu.edu.cn
RI Chen, Zhenhua/A-3361-2014
OI Jia, Xingxing/0000-0001-7713-3520
FU 2017 Teaching and Research Program of Lanzhou University [2017114];
   National Natural Science Foundation of China [U1536102, U1536116,
   U1636219, 61872289]; Plan for Scientific Innovation Talent of Henan
   Province [2018JR0018]; Science and Technology Program of Guangxi
   [16380076]; China Mobile Research Fund Project [MCM20170407]; Key
   Laboratory of Digital Content Anti-Counterfeiting and Security Forensics
   of the state Administration of Press, Publication, Radio, Film and
   Television of the People's Republic of China
FX This work was supported in part by 2017 Teaching and Research Program of
   Lanzhou University under Grant No. 2017114, in part by the National
   Natural Science Foundation of China under Grant Nos. U1536102, U1536116,
   U1636219, and 61872289, in part by Plan for Scientific Innovation Talent
   of Henan Province (No. 2018JR0018) and the Science and Technology
   Program of Guangxi (No. 16380076), in part by China Mobile Research Fund
   Project (MCM20170407), and Key Laboratory of Digital Content
   Anti-Counterfeiting and Security Forensics of the state Administration
   of Press, Publication, Radio, Film and Television of the People's
   Republic of China.
CR Adhikari A, 2014, DESIGN CODE CRYPTOGR, V73, P865, DOI 10.1007/s10623-013-9832-5
   ARAZI B, 1989, IEEE T SYST MAN CYB, V19, P1016, DOI 10.1109/21.44016
   Chang CC, 2009, PATTERN RECOGN, V42, P3097, DOI 10.1016/j.patcog.2009.04.012
   Chen YC, 2012, J VIS COMMUN IMAGE R, V22, P55
   Chen YC, 2012, IEEE T IMAGE PROCESS, V21, P3319, DOI 10.1109/TIP.2012.2190082
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   D'Arco P, 2014, LECT NOTES COMPUT SC, V8317, P18, DOI 10.1007/978-3-319-04268-8_2
   De Prisco R, 2010, COMPUT J, V53, P1485, DOI 10.1093/comjnl/bxp068
   Horng G, 2006, DESIGN CODE CRYPTOGR, V38, P219, DOI 10.1007/s10623-005-6342-0
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Jia XX, 2018, IEEE T CIRC SYST VID, V28, P1056, DOI 10.1109/TCSVT.2016.2631404
   Lin PY, 2015, INFORM SCIENCES, V301, P61, DOI 10.1016/j.ins.2014.12.046
   Liu F, 2011, IET INFORM SECUR, V5, P51, DOI 10.1049/iet-ifs.2008.0064
   Liu YN, 2019, IEEE T IND INFORM, V15, P1767, DOI 10.1109/TII.2018.2809672
   Liu YN, 2017, IET INFORM SECUR, V11, P250, DOI 10.1049/iet-ifs.2016.0103
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Naor M, 1997, LECT NOTES COMPUT SC, V1294, P322
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Ren YW, 2017, IET INFORM SECUR, V11, P211, DOI 10.1049/iet-ifs.2016.0126
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   Shyu SJ, 2011, IEEE T INF FOREN SEC, V6, P960, DOI 10.1109/TIFS.2011.2158096
   Shyu SJ, 2017, IEEE T CIRCUITS SYST, P1
   Singh P, 2018, SIGNAL PROCESS, V142, P301, DOI 10.1016/j.sigpro.2017.06.015
   Tsai DS, 2007, PATTERN RECOGN, V40, P2356, DOI 10.1016/j.patcog.2007.01.013
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wu XT, 2014, IEEE T INF FOREN SEC, V9, P1592, DOI 10.1109/TIFS.2014.2346014
   Yang CN, 2014, IEEE T CIRC SYST VID, V24, P189, DOI 10.1109/TCSVT.2013.2276708
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Yuan HD, 2014, INFORM SCIENCES, V254, P197, DOI 10.1016/j.ins.2013.08.012
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 33
TC 13
Z9 13
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8207
EP 8223
DI 10.1007/s11042-018-6779-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800019
DA 2024-07-18
ER

PT J
AU Riofrío-Luzcando, D
   Ramírez, J
   Moral, C
   de Antonio, A
   Berrocal-Lobo, M
AF Riofrio-Luzcando, D.
   Ramirez, J.
   Moral, C.
   de Antonio, A.
   Berrocal-Lobo, M.
TI Visualizing a collective student model for procedural training
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Educational data mining; Information visualization; Human computer
   interaction; Elearning; Procedural training; Intelligent tutoring
   systems
AB Visualization plays a relevant role for discovering patterns in big sets of data. In fact, the most common way to help a human with a pattern interpretation is through a graphic. In 2D/3D virtual environments for procedural training the student interaction is more varied and complex than in traditional e-learning environments. Therefore, the visualization and interpretation of students' behaviors becomes a challenge. This motivated us to design the visualization of a collective student model built from student logs taken from 2D/3D virtual environments for procedural training. This paper presents the design decisions that enable a suitable visualization of this model to instructors as well as a web tool that implements this visualization and is intended: to help instructors to improve their own teaching; and to enhance the tutoring strategy of an Intelligent Tutoring System. Then, this paper illustrates, with three detailed examples, how this tool can be used to those educational purposes. Next, the paper presents an experiment for validating the utility of the tool. In this experiment we show how the tool can help to modify the tutoring strategy of a 3D virtual laboratory. In this way, it is shown that the proposed visualization of the model can serve to improve the performance of students in 2D/3D virtual environments for procedural training.
C1 [Riofrio-Luzcando, D.] Int Univ SEK, Quito, Ecuador.
   [Ramirez, J.; Moral, C.; de Antonio, A.] UPM, ETS Ingn Informat, Madrid, Spain.
   [Berrocal-Lobo, M.] UPM, ETSI Forestal Medio Nat, Madrid, Spain.
C3 Universidad Politecnica de Madrid; University of Sevilla; Universidad
   Politecnica de Madrid
RP Riofrío-Luzcando, D (corresponding author), Int Univ SEK, Quito, Ecuador.
EM diego.riofrio@uisek.edu.ec
RI Moral, Cristian/AAJ-6825-2021; Riofrío-Luzcando, Diego/IXN-0844-2023;
   Berrocal-Lobo, Marta/B-3482-2018; de Antonio, Angélica/B-2584-2009;
   MARTOS, CRISTIAN MORAL/AAS-6259-2020
OI Moral, Cristian/0000-0002-8429-8822; Riofrío-Luzcando,
   Diego/0000-0002-9000-9847; Berrocal-Lobo, Marta/0000-0002-4711-9338; de
   Antonio, Angélica/0000-0002-8936-9095; 
FU Ecuadorian Secretariat of Higher Education, Science, Technology and
   Innovation (SENESCYT)
FX Riofrio would like to acknowledge financial support from the Ecuadorian
   Secretariat of Higher Education, Science, Technology and Innovation
   (SENESCYT). We want to thank Kelly Huang and alvaro de Jesus Sen, for
   their collaboration in this research through their master and
   undergraduate theses.
CR [Anonymous], 1981, Graphics and Graphic Information-Processing
   [Anonymous], 2015, THESIS
   [Anonymous], 1996, ACM Transactions, DOI DOI 10.1145/230562.230563
   Baker R.S. J. D., 2010, INT ENCY ED, V7, P112, DOI [10.1016/B978-0-08-044894-7.01318-X, DOI 10.1016/B978-0-08-044894-7.01318-X]
   Brusilovsky P, 2015, LECT NOTES COMPUT SC, V9146, P44, DOI 10.1007/978-3-319-20267-9_4
   Bull S., 2016, MEASURING VISUALIZIN, P167
   Card S K., 1999, READINGS INFORM VISU
   Card SK, 1997, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P92, DOI 10.1109/INFVIS.1997.636792
   de Jesus Sen A, 2016, THESIS
   Einsfeld K, 2006, INFORMATION VISUALIZATION-BOOK, P569
   Elen J., 2014, Handbook of Research on Educational Communications and Technology, P791, DOI [10.1007/978-1-4614-3185-5_64, DOI 10.1007/978-1-4614-3185-5_64, DOI 10.1007/978-1-4614-3185-564]
   Gomez Aguilar D., 2014, P 9 IB C INF SYST TE, P1, DOI [10.1109/CISTI.2014.6877098, DOI 10.1109/CISTI.2014.6877098]
   Grawemeyer B, 2015, LECT NOTES ARTIF INT, V9112, P591, DOI 10.1007/978-3-319-19773-9_69
   Hartley D, 2002, LECT NOTES COMPUT SC, V2363, P453, DOI 10.1109/MSST.2011.5937220
   Jordao V, 2014, PROCEEDINGS OF THE NORDICHI'14: THE 8TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION: FUN, FAST, FOUNDATIONAL, P1011, DOI 10.1145/2639189.2670263
   Kuosa K, 2016, INT J DIST EDUC, V14, P1, DOI 10.4018/IJDET.2016010101
   Li X, 2015, 2015 IEEE CONFERENCE ON E-LEARNING, E-MANAGEMENT AND E-SERVICES (IC3E), P125, DOI 10.1109/IC3e.2015.7403499
   Li X, 2017, 2017 IEEE 15TH INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, 15TH INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, 3RD INTL CONF ON BIG DATA INTELLIGENCE AND COMPUTING AND CYBER SCIENCE AND TECHNOLOGY CONGRESS(DASC/PICOM/DATACOM/CYBERSCI, P101, DOI 10.1109/DASC-PICom-DataCom-CyberSciTec.2017.31
   Lin C, 2017, P INT S EM TECHN ED, P422
   MacEachren AM, 1995, MAPS WORK REPRESENTA, V3
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Martins Rita, 2015, 2015 IEEE 4th Portuguese Meeting on Bioengineering (ENBENG). Proceedings, P1, DOI 10.1109/ENBENG.2015.7088847
   Mazza R, 2004, THESIS
   Mazza R., 2010, CHAPMAN HALL CRC DAT, P9, DOI 10.1201/b10274-4
   Mazza R., 2009, INTRO INFORM VISUALI
   Mazza R., 2007, J INTERACTIVE LEARNI, V18, P251
   Mazza R, 2007, INT J HUM-COMPUT ST, V65, P125, DOI 10.1016/j.ijhcs.2006.08.008
   Mitrovic A, 2002, INTERNATIONAL CONFERENCE ON COMPUTERS IN EDUCATION, VOLS I AND II, PROCEEDINGS, P1276, DOI 10.1109/CIE.2002.1186210
   Moral C, 2016, THESIS
   Paiva R, 2018, P INT C ART INT ED
   Pesare E, 2016, P DMS 2016 22 INT C, P26
   Rasyidi J, 2009, FRONTIERS ARTIFICIAL, V200, P56572
   Reffay C., 2003, SOCIAL NETWORK ANAL, P343
   Rico M, 2017, J EDUC COMPUT RES
   Rico M., 2012, GLOB ENG ED C EDUCON, P1, DOI DOI 10.1109/EDUCON.2012.6201048
   Rico M, 2017, J UNIVERS COMPUT SCI, V23, P208
   Riofrío-Luzcando D, 2017, IEEE T LEARN TECHNOL, V10, P463, DOI 10.1109/TLT.2017.2658569
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Tan P.-N., 2013, INTRO DATA MINING
   Tervakari A, 2015, IEEE GLOB ENG ED C E, P14251
   Uther J, 2003, LECT NOTES ARTIF INT, V2702, P198
   Vatrapu R., 2011, P 1 INT C LEARNING A, P93
   Wan H, 2017, PR IEEE INT CONF TEA, P250, DOI 10.1109/TALE.2017.8252342
   Wang XH, 2013, PROCEEDINGS OF THE 2013 8TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION (ICCSE 2013), P1189
   Wortman D, 2007, SIGCSE 2007: PROCEEDINGS OF THE THIRTY-EIGHTH SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P430, DOI 10.1145/1227504.1227458
   Xiong R., 1999, 99 UIST. Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology, P37, DOI 10.1145/320719.322581
   Zapata-Rivera J. D., 2000, INT C COMP ED, P755
   Zapata-Rivera J-D., 2001, Proceedings of Workshop on External Representations of AIED: Multiple Forms and Multiple Roles, 10th International Conference on Artificial Intelligence in Education, P71
NR 48
TC 7
Z9 7
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10983
EP 11010
DI 10.1007/s11042-018-6641-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400064
DA 2024-07-18
ER

PT J
AU Benuwa, BB
   Zhan, YZ
   Liu, JQ
   Gou, JP
   Ghansah, B
   Ansah, EK
AF Benuwa, Ben-Bright
   Zhan, Yongzhao
   Liu, JunQi
   Gou, Jianping
   Ghansah, Benjamin
   Ansah, Ernest K.
TI Group sparse based locality - sensitive dictionary learning for video
   semantic analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Group sparsity; Sparse representation; Locality information; Dictionary
   learning; Video semantic analysis
ID DISCRIMINATIVE DICTIONARY; K-SVD; REPRESENTATION; CLASSIFICATION
AB Sparse Representation-based Classifier (SRC) and Dictionary Learning (DL), have significantly impacted greatly on the classification performance of image recognition in recent times. In video semantic analysis, the locality structure of video semantic data containing more discriminative information is very essential for classification. However, this has not been fully considered by the current sparse representation-based approaches. Furthermore, similar coding outcomes are not being realized from video features with the same video category. To handle these issues, we propose a novel DL method, called Group Sparsity Locality-Sensitive Dictionary Learning (GSLSDL) for video semantic analysis. In the proposed GSLSDL, a discriminant loss function for the video category based on group sparse coding of sparse coefficients, is introduced into the structure of the Locality-Sensitive Dictionary Learning (LSDL) method. After solving the optimized dictionary, the sparse coefficients for the testing video feature samples are obtained. The classification result for video semantic is then realized by minimizing the error between the original and reconstructed samples. The experiment results show that, the proposed GSLSDL significantly improves the performance of video semantic detection compared with the competing methods, and robust in various diverse environments of video.
C1 [Benuwa, Ben-Bright; Zhan, Yongzhao; Liu, JunQi; Gou, Jianping; Ghansah, Benjamin] Jiangsu Univ, Sch Comp Sci & Commun Engn, Xuefu Rd 301, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Benuwa, Ben-Bright; Ghansah, Benjamin; Ansah, Ernest K.] Data Link Inst, Sch Comp Sci, POB 2481, Tema, Ghana.
C3 Jiangsu University
RP Benuwa, BB (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Xuefu Rd 301, Zhenjiang 212013, Jiangsu, Peoples R China.; Benuwa, BB (corresponding author), Data Link Inst, Sch Comp Sci, POB 2481, Tema, Ghana.
EM benuwa778@gmail.com; yzzhan@ujs.edu.cn; 694519258@qq.com;
   goujianping@ujs.edu.cn; ben@datalink.edu.gh;
   datalinkuniversity@gmail.com
RI Gou, Jianping/JQX-2453-2023; jin, li/IWU-4648-2023; Ghansah,
   Benjamin/L-9931-2019; Benuwa, Ben-Bright/J-6198-2019
OI Gou, Jianping/0000-0003-1413-0693; Ghansah,
   Benjamin/0000-0002-1599-6301; Benuwa, Ben-Bright/0000-0002-3085-706X
FU National Natural Science Foundation of China [61170126, 61502208];
   Natural Science Foundation of the Jiangsu Higher Education Institutions
   of China [14KJB520007]; China Postdoctoral Science Foundation
   [2015M570411]; Natural Science Foundation of Jiangsu Province of China
   [BK20150522]; Research Foundation for Talented Scholars of JiangSu
   University [14JDG037]
FX This work was buoyed in part by National Natural Science Foundation of
   China (Grant Nos.similar to 61170126, Grant Nos.similar to 61502208),
   the Natural Science Foundation of the Jiangsu Higher Education
   Institutions of China (Grant No. 14KJB520007), China Postdoctoral
   Science Foundation (Grant No. 2015M570411), Natural Science Foundation
   of Jiangsu Province of China (Grant No. BK20150522) and Research
   Foundation for Talented Scholars of JiangSu University (Grant No.
   14JDG037).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2012, J JIANGSU U NATURAL
   [Anonymous], TMM
   [Anonymous], CONNECT TISSUE RES
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], IEEE T IND INFORM
   [Anonymous], TIP
   [Anonymous], NEUROCOMPUTING
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587652
   [Anonymous], 2009, P ADV NEUR INF PROC
   [Anonymous], ARXIV161108983
   [Anonymous], ACCESS
   [Anonymous], DISCRIMINATIVE DICT
   Benuwa B, 2016, INT J ENG RES AFR, V24, P124, DOI 10.4028/www.scientific.net/JERA.24.124
   Benuwa BB, 2016, INT J ENG RES AFR, V23, P141, DOI 10.4028/www.scientific.net/JERA.23.141
   Cai SJ, 2014, LECT NOTES COMPUT SC, V8692, P624, DOI 10.1007/978-3-319-10593-2_41
   Chang HY, 2016, NEUROCOMPUTING, V190, P124, DOI 10.1016/j.neucom.2016.01.026
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100
   Engan K, 1999, INT CONF ACOUST SPEE, P2443, DOI 10.1109/ICASSP.1999.760624
   Feng ZZ, 2013, PATTERN RECOGN, V46, P2134, DOI 10.1016/j.patcog.2013.01.016
   Gou JP, 2018, INFORM SCIENCES, V433, P17, DOI 10.1016/j.ins.2017.12.025
   Guo YJ, 2018, IEEE GEOSCI REMOTE S, V15, P1016, DOI 10.1109/LGRS.2018.2822266
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Harandi M, 2015, PROC CVPR IEEE, P3926, DOI 10.1109/CVPR.2015.7299018
   Hayati S, 2017, C PROC SOC EXP MECH, P223, DOI 10.1007/978-3-319-54777-0_27
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354
   Lee YS, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P481, DOI 10.1145/2964284.2967267
   Lei JJ, 2017, IEEE IMAGE PROC, P3685, DOI 10.1109/ICIP.2017.8296970
   Li L, 2013, IEICE ELECTRON EXPR, V10, DOI 10.1587/elex.10.20130157
   Mairal J., 2009, ADV NEURAL INFORM PR, P1033
   Mukundan R., 2005, TENCON 2005 2005 IEE, P1
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Paluska JM, 2008, INT CONF PERVAS COMP, P1, DOI 10.1109/PERCOM.2008.55
   Song J, 2018, IEEE T IMAGE PROCESS, V1
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang Ping, 2016, Transactions of Tianjin University, V22, P158, DOI 10.1007/s12209-016-2624-z
   Wei CP, 2013, PATTERN RECOGN, V46, P1277, DOI 10.1016/j.patcog.2012.11.014
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu D, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1326, DOI 10.1145/2964284.2964329
   Xu Y, 2015, COMPUT VIS IMAGE UND, V136, P59, DOI 10.1016/j.cviu.2015.01.006
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yuan XT, 2012, IEEE T IMAGE PROCESS, V21, P4349, DOI 10.1109/TIP.2012.2205006
   Zhan YZ, 2016, J VIS COMMUN IMAGE R, V41, P65, DOI 10.1016/j.jvcir.2016.09.006
   Zhan YZ, 2015, MULTIMED TOOLS APPL, V74, P5513, DOI 10.1007/s11042-014-1866-9
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P696, DOI 10.1109/TCSVT.2016.2589858
   Zhang Z, 2018, IEEE T NEUR NET LEAR, V29, P3798, DOI 10.1109/TNNLS.2017.2740224
   Zhang Z, 2016, IEEE T SIGNAL PROCES, V64, P3790, DOI 10.1109/TSP.2016.2550016
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao SC, 2015, IEEE IMAGE PROC, P2459, DOI 10.1109/ICIP.2015.7351244
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 56
TC 2
Z9 2
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6721
EP 6744
DI 10.1007/s11042-018-6417-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700014
DA 2024-07-18
ER

PT J
AU Li, Q
   Liu, B
   Wang, DY
AF Li, Qiang
   Liu, Bo
   Wang, Dayong
TI Fast CU size decision and PU mode decision algorithm for quality SHVC
   inter coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SHVC; CU size decision; PU mode decision; Inter prediction; Low
   complexity compression
ID MOTION ESTIMATION; EXTENSIONS
AB As a scalable extension of the High Efficiency Video Coding (HEVC), the Scalable High Efficiency Video Coding (SHVC) encoder needs to encode multiple HEVC layers with Inter-layer predictions, which causes the significant increase in coding complexity. In this paper, we proposed a novel Inter prediction scheme to effectively reduce computational complexity in Quality SHVC. The new features of the proposed algorithm include: First, spatial and Inter-layer depth correlations are used to predict the most possible coding unit (CU) depth level candidates. Second, a statistical test method on the current CU depth level is introduced to examine whether the residual coefficients within its block present similar distribution to terminate depth selection early. Finally, during Inter prediction selection from 8 Prediction Unit (PU) sizes, spatial and Inter-layer correlations are combined with residual coefficients distribution to determine the PU partitioning mode is Symmetric Motion Partitioning (SMP) or Asymmetric Motion Partitioning (AMP). Experimental results demonstrate that the proposed algorithm can save an average of 65.33% coding time of enhancement layer (EL) while achieving a better rate distortion (RD) performance over other state-of-the-art work.
C1 [Li, Qiang; Liu, Bo; Wang, Dayong] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Signal & Informat Proc, Chongqing, Peoples R China.
C3 Chongqing University of Posts & Telecommunications
RP Liu, B (corresponding author), Chongqing Univ Posts & Telecommun, Chongqing Key Lab Signal & Informat Proc, Chongqing, Peoples R China.
EM liubo068@hotmail.com
FU National Natural Science Foundation of China [61571071]; Nature Science
   Foundation Project of Chongqing [cstc2016jcyjA0543, cstc2017jcyjXB0037]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61571071) and Nature Science Foundation Project of Chongqing
   (No. cstc2016jcyjA0543 and No. cstc2017jcyjXB0037). The authors also
   would like to thank all reviewers for their valuable comments and
   suggestions to improve the quality of this paper.
CR [Anonymous], 2015, High Efficiency Video Coding: coding tools and specifications
   Bailleul R, 2014, I SYMP CONSUM ELECTR, P195
   Bjotegaard G., 2001, VCEGM33
   Bossen Frank., 2011, Joint Collaborative Team on Video Coding (JCT-VC), JCTVC-F900
   Boyce JM, 2016, IEEE T CIRC SYST VID, V26, P20, DOI 10.1109/TCSVT.2015.2461951
   Chen BY, 2017, INT J ROTATING MACH, V2017, DOI 10.1155/2017/2607254
   CHO S, 2013, TECHNOL, V23, P1555, DOI DOI 10.1109/TCSVT.2013.2249017
   Corrêa G, 2012, IEEE T CIRC SYST VID, V22, P1899, DOI 10.1109/TCSVT.2012.2223411
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Hu N, 2014, IEEE T CIRC SYST VID, V24, P1310, DOI 10.1109/TCSVT.2014.2306035
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Kang M, 2016, INT FORUM DIGITAL TV, P349
   Katayama T, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P3079, DOI 10.1109/TENCON.2016.7848614
   Li XN, 2017, MULTIMED TOOLS APPL, V76, P8011, DOI 10.1007/s11042-016-3460-9
   Lim K, 2015, IEEE T CIRC SYST VID, V25, P1335, DOI 10.1109/TCSVT.2014.2380194
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   MIN B, 2015, TECHNOLOGY, V25, P892, DOI DOI 10.1109/TCSVT.2014.2363739
   Pan ZQ, 2014, IEEE T BROADCAST, V60, P405, DOI 10.1109/TBC.2014.2321682
   Seregin Vadim, 2014, JCTVCQ1009, P1
   Shen LQ, 2014, IEEE T CIRC SYST VID, V24, P1709, DOI 10.1109/TCSVT.2014.2313892
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 2012, JOINT CALL PROPOSALS, P16
   Sze V., 2014, Integrated Circuit and Systems, Algorithms and Architectures, P1
   Tai K-H, 2017, IEEE T BROADCASTING
   Tang M, 2017, IEEE SIGNAL PROCESSI
   Tohidypour HR, 2017, IEEE T CIRC SYST VID, V27, P2204, DOI 10.1109/TCSVT.2016.2576738
   Tohidypour HR, 2016, IEEE T BROADCAST, V62, P664, DOI 10.1109/TBC.2016.2576600
   Tohidypour HR, 2016, IEEE T MULTIMEDIA, V18, P182, DOI 10.1109/TMM.2015.2510332
   Tohidypour HR, 2013, INT CONF ACOUST SPEE, P1744, DOI 10.1109/ICASSP.2013.6637951
   Vanne J, 2014, IEEE T CIRC SYST VID, V24, P1579, DOI 10.1109/TCSVT.2014.2308453
   Wang D, 2017, IEEE T IMAGE PROCESS
   Yan SQ, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P225, DOI 10.1109/SITIS.2012.41
   Yang Z, 2017, 36 IEEE INT PERF COM
   Yang Z, 2017, J SCALABLE COMPUT SP, V18
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhao WJ, 2015, IEEE T CIRC SYST VID, V25, P1651, DOI 10.1109/TCSVT.2015.2395751
NR 41
TC 3
Z9 4
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7819
EP 7839
DI 10.1007/s11042-018-6527-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700063
DA 2024-07-18
ER

PT J
AU Wan, L
   Liu, Y
   Dai, HP
   Feng, W
   Zhang, JW
AF Wan, Liang
   Liu, Ye
   Dai, Haipeng
   Feng, Wei
   Zhang, Jiawan
TI Woodblock image decomposition of Chinese new year paintings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Woodblock printed Chinese new year paintings; Woodblock image
   decomposition; Line block; Color block
ID MEAN SHIFT
AB Woodblock printed Chinese new year (WNY) painting has been a popular art form in Chinese folk culture. To make a WNY painting involves carving images on woodblocks and printing colors using woodblocks. Although thousands of WNY paintings were preserved, the ten-year national survey reveals that a great number of woodblocks were damaged or lost. In this paper, we study a novel problem of decomposing woodblock images from WNY paintings, which currently requires a tremendous amount of manual labor. We also find that the state-of-the-art methods of natural image segmentation generate poor results in our application. Instead of using sophisticated schemes, we develop a simple yet robust decomposition approach, which contains the extraction of line block image and the separation of color block images. The effectiveness of the proposed approach is validated through both quantitative evaluation and visual quality comparison with six state-of-the-art methods on multiple WNY paintings.
C1 [Wan, Liang; Liu, Ye; Zhang, Jiawan] Tianjin Univ, Sch Comp Software, Tianjin, Peoples R China.
   [Dai, Haipeng; Feng, Wei] Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University
RP Feng, W (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
EM lwan@tju.edu.cn; wfeng@tju.edu.cn
RI Feng, Wei/E-3985-2016; Li, Mengqi/AAG-6804-2021; Dai,
   Haipeng/JOZ-1338-2023
FU National Natural Science Foundation of China [61572354, 61671325]
FX This work is supported by the National Natural Science Foundation of
   China (61572354, 61671325).
CR Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Donoser M, 2014, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2014.404
   Feng J, 2006, CHINESE NEW YEAR PAI
   Feng W, 2010, IEEE T PATTERN ANAL, V32, P1871, DOI 10.1109/TPAMI.2010.24
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mignotte M, 2008, IEEE T IMAGE PROCESS, V17, P780, DOI 10.1109/TIP.2008.920761
   Mizuno S., 2000, Computer Graphics Forum, V19, pC51, DOI 10.1111/1467-8659.00397
   Mizuno S, 1998, VISUAL COMPUT, V14, P39, DOI 10.1007/s003710050122
   Okada M, 2001, VSMM 2001: SEVENTH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA, PROCEEDINGS, P209, DOI 10.1109/VSMM.2001.969673
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Sykora D, 2005, IMAGE VISION COMPUT, V23, P767, DOI 10.1016/j.imavis.2005.05.010
   Sykora D., 2005, Proceedings of Eurographics Workshop on Sketch-Based Interfaces and Modeling, P27
   Terai T, 2004, EUROGRAPHICS
   Terai T, 2005, ACM SIGGRAPH POSTERS, P30
   Toan Nguyen Dinh, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P597, DOI 10.1109/ICPR.2010.151
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang S.C., 2002, HIST CHINESE NEW YEA
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yang L, 2007, INT J ROTATING MACH, V2007, DOI 10.1155/2007/85275
   Zhang SH, 2009, IEEE T VIS COMPUT GR, V15, P618, DOI 10.1109/TVCG.2009.9
NR 28
TC 3
Z9 4
U1 9
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7621
EP 7641
DI 10.1007/s11042-018-6447-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700054
DA 2024-07-18
ER

PT J
AU Wang, BL
   Meng, L
   Song, J
AF Wang, Beilei
   Meng, Lu
   Song, Jie
TI Image saliency detection for multiple objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BING; Multiple objects; Saliency detection; Super-pixel segmentation
AB Traditional saliency detection methods are designed only for a single salient object and cannot detect multiple salient objects in the image. This paper proposes a novel method for detecting multiple salient objects in the image, which is based on both objectness estimation method and superpixel segmentation method. The present study shows that the proposed method can correctly detect the salient regions for multiple objects and outperforms the other three state-of-the-art saliency detection methods.
C1 [Wang, Beilei; Song, Jie] Northeastern Univ, Coll Software, Shenyang, Liaoning, Peoples R China.
   [Meng, Lu] Northeastern Univ, Coll Informat Sci & Engn, Shenyang, Liaoning, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Meng, L (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang, Liaoning, Peoples R China.
EM 23587926@qq.com
RI Song, Jie/JXK-0735-2024; Lu, Meng/JVO-3171-2024; Meng, Lu/GXN-0092-2022;
   Song, Jie/GLR-2301-2022
FU National Natural Science Foundation of China [61662057, 61672143,
   U1435216]; Fundamental Research Funds for the Central Universities
   [N130404027, N151704004, N161602003]; Doctor Research Starting
   Foundation of Liaoning [20141011]
FX This research is supported by the National Natural Science Foundation of
   China (61662057, 61672143, U1435216), the Fundamental Research Funds for
   the Central Universities (N130404027, N151704004, N161602003), and
   Doctor Research Starting Foundation of Liaoning (No. 20141011).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 2005, Advances in neural information processing systems, DOI DOI 10.5555/2976248.2976268
   Borji Ali, 2019, [Computational Visual Media, 计算可视媒体], V5, P117
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Kootstra G, 2011, COGN COMPUT, V3, P223, DOI 10.1007/s12559-010-9089-5
   Oh KH, 2016, KSII T INTERNET INF, V10, P272, DOI 10.3837/tiis.2016.01.016
   Oh K, 2016, IMAGE VISION COMPUT, V54, P31, DOI 10.1016/j.imavis.2016.07.007
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Rosin PL, 2009, PATTERN RECOGN, V42, P2363, DOI 10.1016/j.patcog.2009.04.021
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Zhang YD, 2014, INFORM SCIENCES, V281, P586, DOI 10.1016/j.ins.2013.12.043
NR 19
TC 1
Z9 1
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5329
EP 5343
DI 10.1007/s11042-018-5731-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100014
DA 2024-07-18
ER

PT J
AU Lee, K
   Lee, YS
   Nam, Y
AF Lee, Keonsoo
   Lee, Yang Sun
   Nam, Yunyoung
TI A novel approach of making better recommendations by revealing hidden
   desires and information curation for users of internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Browsing; Hidden desire; Information curation; Recommendation system
ID PARETO
AB One of the most significant disadvantages of the Internet of Things (IoT) is the overload of information. More information makes it harder to find valuable information. Recommendation systems identify the most suitable items for a given user. The recommended result is only valid if the system users know what they want, and clearly and explicitly convey their needs to the system. Because the role of a recommendation system is to calculate the similarity between the given request and each item, and to rank the similarity, the requests and identity of items should be clear to obtain correct results. However, in most situations in which recommendations are made, requests are implicit and ambiguous. A good recommendation system should make a reliable list of items, even with ambiguous requests. This paper proposes a model of generating recommendations for implicit requests. The model employs two methods that reveals the desire of the requestor and uses content curation with a customized layout to display the recommendations. The first method for revealing the requestor's desire is to specify the implicit request by combining the user's customized preference with the collective intelligence. The second method for employing content curation is to arrange the recommendation for users to accept spontaneously. To persuade users, the recommendations are transformed into a layout based on a personalized cognitive bias. Through these processes, reliable and beneficial recommendations can be provided to any user even if their requests are implicit or unclear.
C1 [Lee, Keonsoo] Soonchunhyang Univ, Convergence Inst Med Informat Commun Technol & Ma, Asan, South Korea.
   [Lee, Yang Sun] Mokwon Univ, Div Convergence Comp & Media, Daejeon, South Korea.
   [Nam, Yunyoung] Soonchunhyang Univ, Dept Comp Sci & Engn, Asan, South Korea.
C3 Soonchunhyang University; Mokwon University; Soonchunhyang University
RP Nam, Y (corresponding author), Soonchunhyang Univ, Dept Comp Sci & Engn, Asan, South Korea.
EM keonsoo@sch.ac.kr; yslee48@gmail.com; ynam@sch.ac.kr
RI Lee, Yangsun/Q-9948-2019; Nam, Yunyoung/AAI-4536-2020
OI Nam, Yunyoung/0000-0002-3318-9394; Lee, Yang Sun/0000-0002-1268-2016
FU Soonchunhyang University Research Fund; "ICT Convergence Smart
   Rehabilitation Industrial Education Program" through the Ministry of
   Trade, Industry Energy (MOTIE); Korea Institute for Advancement of
   Technology (KIAT)
FX This work was supported by the Soonchunhyang University Research Fund
   and also supported by the "ICT Convergence Smart Rehabilitation
   Industrial Education Program" through the Ministry of Trade, Industry &
   Energy (MOTIE) and Korea Institute for Advancement of Technology (KIAT).
CR Barron G, 2010, J BEHAV DECIS MAKING, V23, P117, DOI 10.1002/bdm.676
   Casey Robert., 2008, MODEL T CENTENNIAL H
   Cialdini R.B., 2006, INFLUENCE PSYCHOL PE
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Freud Sigmund., 2009, GEN INTRO PSYCHOANAL
   Fromm E, 2005, HAVE BE REVISED EDIT
   Highhouse S, 1996, ORGAN BEHAV HUM DEC, V65, P68, DOI 10.1006/obhd.1996.0006
   Jungwirth B, 2002, J ADOLESC ADULT LIT, V45, P400
   Jurek AM, 2005, INT J EPIDEMIOL, V34, P680, DOI 10.1093/ije/dyi060
   Kahneman Daniel, 2011, Thinking, fast and slow (macmillan)
   KRUGLANSKI AW, 1983, J EXP SOC PSYCHOL, V19, P448, DOI 10.1016/0022-1031(83)90022-7
   Kuran T, 1999, STANFORD LAW REV, V51, P683, DOI 10.2307/1229439
   Lee K, 2005, P IDW AD 05, P231
   Lee K. S., 2010, The Annual Report of Korean Children and Youth Panel Survey 2010, P1
   Lee K, 2013, PERS UBIQUIT COMPUT, V17, P1753, DOI 10.1007/s00779-012-0608-0
   Lee K, 2008, LECT NOTES ARTIF INT, V5357, P267
   Leibenstein H, 1950, Q J ECON, V64, P183, DOI 10.2307/1882692
   Leibenstein H., 1976, EC MAN NEW FDN MICRO
   Maslow AH, 1943, PSYCHOL REV, V50, P370, DOI 10.1037/h0054346
   Moe WW, 2003, J CONSUM PSYCHOL, V13, P29, DOI 10.1207/S15327663JCP13-1&2_03
   Newman MEJ, 2005, CONTEMP PHYS, V46, P323, DOI 10.1080/00107510500052444
   Novak TP, 2003, J CONSUM PSYCHOL, V13, P3, DOI 10.1207/153276603768344744
   Petrova K, 2011, ELECTRON COMMER RES, V11, P5, DOI 10.1007/s10660-010-9068-7
   Reed WJ, 2001, ECON LETT, V74, P15, DOI 10.1016/S0165-1765(01)00524-9
   Rifkin Jeremy., 2001, AGE ACCESS NEW CULTU
   Ross W.D., 1951, PLATOS THEORY IDEAS
   Sandel Michael J., 2010, Justice: What's the right thing to do?
   Scarle S, 2012, ELECTRON COMMER RES, V12, P379, DOI 10.1007/s10660-012-9098-4
   Schwartz Barry., 2004, PARADOX CHOICE WHY M
   Senecal S, 2005, J BUS RES, V58, P1599, DOI 10.1016/j.jbusres.2004.06.003
   Suki NM, 2013, CONSUMER SHOPPING BE
   Sundar S. S., 2008, P C HUM FACT COMP SY, P3453, DOI [DOI 10.1145/1358628.1358873, https://doi.org/10.1145/1358628.1358873]
   Thaler R. H., 2021, NUDGE FINAL EDITION
   WHITE HC, 1981, AM J SOCIOL, V87, P517, DOI 10.1086/227495
NR 34
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3183
EP 3201
DI 10.1007/s11042-018-6084-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600028
DA 2024-07-18
ER

PT J
AU Mai, XD
AF Mai, Xiaodong
TI <bold>Efficient multimedia information mining framework based on deep
   learning and self-organizing model</bold>
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recurrent neural network; Smart cities; Transportation; Big data;
   Multimedia model; Information organization
AB With the progress of society and the acceleration of urbanization, the problem of multimedia assisted urban traffic is becoming increasingly apparent. Intelligent transportation system arises at the historic moment, but the road traffic information data accumulation of intelligent transportation system is quite large, and the information analysis is complex. Usually, there are huge amounts of data stored in the database of the traffic system, thus we need to analyze and manage the data with scientific methods. As the visualized tools, the multimedia based analysis for the on-time data conditions should also be integrated, therefore, how to effectively model the scenario is challenging. In this paper, we introduce and analyze the structure and related model of recurrent neural network, and apply RNN to traffic big data mining model. According to the characteristics of traffic flow, this paper analyzes the causes of the error data in the process of traffic data collection, and puts forward the corresponding processing methods. The proposed model uses the TensorFlow for development, and applies the proposed deep learning model to implement traffic data mining, and we use charts to visually show the prediction results. Experimental results show that proposed algorithm can effectively mine large traffic multimedia data and has good robustness. At the same time, the prediction accuracy has reached 97.36%.
C1 [Mai, Xiaodong] Guangdong Ind Polytech, Sch Informat Technol, Guangzhou 510300, Guangdong, Peoples R China.
C3 Guangdong Industry Polytechnic
RP Mai, XD (corresponding author), Guangdong Ind Polytech, Sch Informat Technol, Guangzhou 510300, Guangdong, Peoples R China.
EM maixiaodongcn@tom.com
CR [Anonymous], 2017, INT C MOBILE WIRELES, DOI DOI 10.1007/978-981-10-5281-1_35
   Aujla GS, 2018, IEEE T IND INFORM
   Cao MS, 2017, NEURAL COMPUT APPL, V28, P1583, DOI 10.1007/s00521-015-2132-4
   Cao Y, 2018, CONCURRENCY COMPUT P
   Chen DW, 2017, J MED IMAG HEALTH IN, V7, P203, DOI 10.1166/jmihi.2017.2007
   Farzaneh M. H., 2016, 2016 IEEE 7 ANN INF, P1, DOI DOI 10.1109/IEMCON.2016.7746299
   Feng L, 2016, Adv Inform Managemen, P228, DOI 10.1109/IMCEC.2016.7867206
   Goldman A, 2017, CONCURRENCY COMPUT P, V29
   Gupta S, 2018, MULTIMED TOOLS APPL, V77, P4829, DOI 10.1007/s11042-016-3735-1
   Hariharan R, 2017, SIGN PROC COMM NETW, P1
   Hu H, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT, INNOVATION MANAGEMENT AND INDUSTRIAL ENGINEERING, VOL 3, PROCEEDINGS, P263, DOI 10.1109/ICIII.2009.372
   Huang H., 2018, IEEE T IND INF
   Jain V, 2018, NEURAL COMPUT APPL, V29, P555, DOI 10.1007/s00521-016-2533-z
   Jan M, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3986
   Jiao JT, 2017, IEEE T INFORM THEORY, V63, P6774, DOI 10.1109/TIT.2017.2733537
   Kim Y, 2017, MULTIMED TOOLS APPL, V76, P17193, DOI 10.1007/s11042-016-3794-3
   Li Y, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3904
   Liu DT, 2018, J MED IMAG HEALTH IN, V8, P303, DOI 10.1166/jmihi.2018.2294
   Liu ZG, 2018, IEEE T IND INFORM, V14, P1067, DOI 10.1109/TII.2017.2774242
   Lou CJ, 2017, J MED IMAG HEALTH IN, V7, P1648, DOI 10.1166/jmihi.2017.2180
   Maassen J, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3853
   Mahdevari S, 2017, NEURAL COMPUT APPL, V28, P3537, DOI 10.1007/s00521-016-2263-2
   Mansouri I, 2018, NEURAL COMPUT APPL, V29, P873, DOI 10.1007/s00521-016-2492-4
   Piccialli F, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4155
   Wansin Y, 2017, J MED IMAG HEALTH IN, V7, P1149, DOI 10.1166/jmihi.2017.2190
   Yadollahi MM, 2017, NEURAL COMPUT APPL, V28, P1453, DOI 10.1007/s00521-015-2159-6
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Zhang J, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04958-1
NR 28
TC 0
Z9 0
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4605
EP 4622
DI 10.1007/s11042-018-6406-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200036
DA 2024-07-18
ER

PT J
AU Qian, WH
   Xu, D
   Cao, JD
   Guan, Z
   Pu, YY
AF Qian, Wenhua
   Xu, Dan
   Cao, Jinde
   Guan, Zheng
   Pu, Yuanyuan
TI Aesthetic art simulation for embroidery style
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-photorealistic rendering; Miao embroidery; Bump texture; Color
   simulation; Image mergence
ID COLOR
AB Different image styles play a significant role in the human vision. Image rendering methods with non-photorealistic rendering based can simulate different illustrations and increase its aesthetic appeal. Despite many kinds of methods have been put forward to obtain various styles, technical subtleties and stylistic potential of the embroidery simulation are litter attention. This paper offers a detailed review of the embroidery art style simulating approach from a 2D photograph, and performs an evaluation features for these tasks. The primary novelty of this method is that the stitch features are generated through an embroidery stroke model, and stitch stoke will be merged to source image. Therefore, it avoids irregular needling embroidery, and highlights the stereoscopic effect which is not revealed in other rendering methods. Firstly, we generate noise image through gray adaptive method to guide the embroidery lines produced. After that, an improved line integral convolution technique is presented to generate stitch strokes, and scattered noise is normalizing to a certain line based on Hough transform. Next, the paper focuses on the raised strokes, which are rendered and obtained through bulging process technique in this paper. Finally, we can exploit mergence strategy based on mapping method to produce embroidery art style. To demonstrate the performance of our proposed method, this paper compares its simulating results with the real embroidery work and measure of image MSSIM is also used to evaluate the simulation quality. In all cases, the experimental results show that the proposed method can achieve embroidery style stitch visual quality and rich the aesthetic expression.
C1 [Qian, Wenhua; Xu, Dan; Guan, Zheng; Pu, Yuanyuan] Yunnan Univ, Sch Informat Sci & Engn, Kunming 650504, Yunnan, Peoples R China.
   [Qian, Wenhua; Cao, Jinde] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Cao, Jinde] Southeast Univ, Sch Math, Nanjing 210096, Jiangsu, Peoples R China.
C3 Yunnan University; Southeast University - China; Southeast University -
   China
RP Xu, D (corresponding author), Yunnan Univ, Sch Informat Sci & Engn, Kunming 650504, Yunnan, Peoples R China.
EM qwhua003@163.com
RI Cao, Jinde/D-1482-2012; Jinde, Cao/L-2658-2017; Xu, Dan/KPA-7396-2024
OI Cao, Jinde/0000-0003-3133-7119; Xu, Dan/0000-0003-4602-3550
FU Research Natural Science Foundation of China [61462093, 61662087,
   61761046]; Research Foundation of Yunnan Province [2014FB113,
   2014FA021]; Postdoctoral fund of the Ministry of education of China;
   Jiangsu Planned Projects for Postdoctoral Research Funds in 2017
   [1108000197]
FX This research was funded by the grants (No.61462093, 61662087, 61761046)
   from the Research Natural Science Foundation of China, the Research
   Foundation of Yunnan Province (No.2014FB113, 2014FA021), the
   Postdoctoral fund of the Ministry of education of China, Jiangsu Planned
   Projects for Postdoctoral Research Funds in 2017 (1108000197)..
CR An XB, 2010, COMPUT GRAPH FORUM, V29, P263, DOI 10.1111/j.1467-8659.2009.01595.x
   [Anonymous], 2017, Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses
   Blinn JF, 1988, COMPUT SCI, V12, P286
   Buyruk Y, 2017, SIGNAL PROCESS COMMU, V25, DOI [10.1109/SIU.2017.7960661, DOI 10.1109/SIU.2017.7960661]
   Cabral B., 1993, Computer Graphics Proceedings, P263, DOI 10.1145/166117.166151
   Chen Sheng-Guo, 2011, Chinese Journal of Computers, V34, P526, DOI 10.3724/SP.J.1016.2011.00526
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Elad M., 2017, IEEE T IMAGE PROCESS, P1
   Gao H, 2006, COMPUT ENG APPL, V47, P177
   Guay M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766893
   Han X.W., 2011, J YANGTZE U, V34, P9
   Ironi R., 2005, RENDERING TECHNIQUES, P201
   Jeon JY, 2008, J VIB ACOUST, V130, DOI 10.1115/1.2748456
   Jing Z, 2015, COMPOS PART B-ENG, V69, P181, DOI 10.1016/j.compositesb.2014.09.039
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Larussi E, 2015, ACM T GRAPHIC, V34, P1
   Lindemeier T, 2015, COMPUT GRAPH FORUM, V34, P311, DOI 10.1111/cgf.12562
   Liu X, 2006, IEEE IMAGE PROC, P2205, DOI 10.1109/ICIP.2006.312978
   Lu AD, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P655
   Lu Cewu., 2012, Proc. NPAR, P65
   Luan FJ, 2017, DEEP PHOTO STYLE TRA
   MacKay D., 2003, INFORM THEORY INFERE
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   [钱文华 Qian Wenhua], 2013, [中国图象图形学报, Journal of Image and Graphics], V18, P836
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Semmo A., 2015, P WORKSHOP COMPUTATI, P149
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shigeyuki S, 2012, ADV ROBOTICS, V6, P461
   Spicker M, 2015, SIGGRAPH ASIA 2015 T
   [孙硕 SUN Shuo], 2007, [计算机工程与应用, Computer Engineering and Application], V43, P34
   Tian Qiming, 2006, Journal of Computer Aided Design & Computer Graphics, V18, P9
   Tian Qiming, 2005, Journal of Computer Aided Design & Computer Graphics, V17, P2625
   Tu Chuanpeng, 2009, Journal of Computer Aided Design & Computer Graphics, V21, P949
   [王雪松 Wang Xuesong], 2015, [中国图象图形学报, Journal of Image and Graphics], V20, P937
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Wu H, 2014, COMPUT GRAPH-UK, V38, P277, DOI 10.1016/j.cag.2013.10.016
   [项建华 Xiang Jianhua], 2013, [图学学报, Journal of Graphics], V34, P16
   Xu Z, 2015, J SYST SOFTWARE, V102, P217, DOI 10.1016/j.jss.2014.07.024
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   [杨莹 YANG Ying], 2011, [计算机工程与设计, Computer Engineering and Design], V32, P732
   [杨育彬 Yang Yubin], 2003, [计算机研究与发展, Journal of Computer Research and Development], V40, P88
   Ye J, 2018, FUTURE GENER COMP SY, V81, P433, DOI 10.1016/j.future.2017.09.030
   Yin LW, 2001, INT J IMAGE GRAPHICS, V1, P565, DOI DOI 10.1142/S0219467801000396
   [喻扬涛 Yu Yangtao], 2015, [图学学报, Journal of Graphics], V36, P159
   Zhao M., 2011, Proc. NPAR '11, P137, DOI DOI 10.1145/2024676.2024698
   Zhou Jie, 2014, Journal of Computer Aided Design & Computer Graphics, V26, P436
NR 47
TC 12
Z9 16
U1 3
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 995
EP 1016
DI 10.1007/s11042-018-6002-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500056
DA 2024-07-18
ER

PT J
AU Roy, A
   Laskar, RH
AF Roy, Amarjit
   Laskar, Rabul Hussain
TI Fuzzy SVM based fuzzy adaptive filter for denoising impulse noise from
   color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Impulse noise; Fuzzy c-means (FCM) clustering; Fuzzy-SVM (FSVM); Local
   binary pattern (LBP); Adaptive filter; FSIMC
ID SWITCHING MEDIAN FILTER; QUALITY ASSESSMENT; PEPPER NOISE; REMOVAL; SALT
AB Impulse noise is an On-Off noise that corrupts an image drastically. Classification of noisy and non-noisy pixels should be performed more accurately so as to restore the corrupted image with less blurring effect and more image details. In this paper, fuzzy c-means (FCM) clustering has been incorporated with fuzzy- support vector machine (FSVM) classifier for classification of noisy and non-noisy pixels in removal of impulse noise from color images. Here, feature vector comprises of newly introduced local binary pattern (LBP) with previously used feature vector prediction error, median value, absolute difference between median and pixel under operation. In this work, features have been extracted from the image corrupted with 10%, 50 and 90% impulse noise respectively and FCM clustering has been used for reduction of size of the feature vector set before processing through FSVM during training procedure. If the pixel is depicted as noisy in testing phase, fuzzy decision based adaptive vector median filtering is performed in accordance with available non-corrupted pixels within the processing window centring the noisy pixel under operation. It has been observed that proposed FSVM based fuzzy adaptive filter provides better performance than some of the established state-of-art filters in terms of PSNR, MSE, SSIM and FSIMC. It is seen that performance is increased by 4dB than baseline filters such as modified histogram fuzzy color filter (MHFC) and multiclass SVM based adaptive filter (MSVMAF).
C1 [Roy, Amarjit] BML Munjal Univ, Dept Elect & Commun Engn, Gurgaon, India.
   [Laskar, Rabul Hussain] NIT, Dept Elect & Commun Engn, Silchar, Silchar, India.
C3 BML Munjal University; National Institute of Technology (NIT System);
   National Institute of Technology Silchar
RP Roy, A (corresponding author), BML Munjal Univ, Dept Elect & Commun Engn, Gurgaon, India.
EM royamarjit90@gmail.com; rabul18@yahoo.com
RI Roy, Amarjit/ABD-1033-2020; Laskar, Rabul Hussain/AFU-7180-2022
OI Laskar, Rabul Hussain/0000-0003-3988-394X; Roy,
   Amarjit/0000-0003-3725-4568
FU Image and Speech Processing Laboratory, Department of Electronics and
   Communication Engineering, National Institute of Technology Silchar,
   India
FX The authors would like to acknowledge the Image and Speech Processing
   Laboratory, Department of Electronics and Communication Engineering,
   National Institute of Technology Silchar, India for providing support
   and necessary facilities for carrying out this work. I also want to
   thank Mr. Mohiul Islam, Ph. D. research scholar of Department of
   Electronics and Communication Engineering, National Institute of
   Technology Silchar, India for providing valuable suggestions during
   preparation of the revised manuscript.T
CR Ahmed F, 2014, IEEE T FUZZY SYST, V22, P1352, DOI 10.1109/TFUZZ.2013.2286634
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Bhadouria VS, 2014, SIGNAL IMAGE VIDEO P, V8, P71, DOI 10.1007/s11760-013-0487-5
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chan RH, 2004, IEEE SIGNAL PROC LET, V11, P921, DOI 10.1109/LSP.2004.838190
   Chang HW, 2015, NEUROCOMPUTING, V151, P1142, DOI 10.1016/j.neucom.2014.04.081
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Ghosh S, 2013, INT J ADV COMPUT SC, V4, P35
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gupta V, 2015, J VIS COMMUN IMAGE R, V26, P296, DOI 10.1016/j.jvcir.2014.10.004
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P956, DOI 10.1016/j.jvcir.2013.06.012
   Hosseini H, 2015, IEEE SIGNAL PROC LET, V22, P1050, DOI 10.1109/LSP.2014.2381649
   Jin LH, 2007, SIGNAL PROCESS, V87, P1345, DOI 10.1016/j.sigpro.2006.11.008
   Kaliraj G, 2010, IMAGE VISION COMPUT, V28, P458, DOI 10.1016/j.imavis.2009.07.007
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Li YY, 2014, NEUROCOMPUTING, V127, P190, DOI 10.1016/j.neucom.2013.08.015
   Lin CF, 2002, IEEE T NEURAL NETWOR, V13, P464, DOI 10.1109/72.991432
   Masood S, 2014, APPL SOFT COMPUT, V21, P107, DOI 10.1016/j.asoc.2014.03.006
   Meher SK, 2014, AEU-INT J ELECTRON C, V68, P1173, DOI 10.1016/j.aeue.2014.06.006
   Nair MS, 2013, COMPUT ELECTR ENG, V39, P663, DOI 10.1016/j.compeleceng.2012.06.004
   PITAS I, 1992, P IEEE, V80, P1893, DOI 10.1109/5.192071
   Quan HT, 2011, IEEE T BROADCAST, V57, P1, DOI 10.1109/TBC.2010.2086750
   Ramadan ZM, 2012, CIRC SYST SIGNAL PR, V31, P1397, DOI 10.1007/s00034-011-9380-z
   Roy A, 2018, IEEE T IND ELECTRON, V65, P7268, DOI 10.1109/TIE.2018.2793225
   Roy A, 2016, SIGNAL PROCESS, V128, P262, DOI 10.1016/j.sigpro.2016.04.007
   Roy A, 2016, APPL SOFT COMPUT, V46, P816, DOI 10.1016/j.asoc.2015.09.032
   Roy A, 2015, GEOGR JUST SOC TRANS, V24, P1
   Schulte S, 2007, IMAGE VISION COMPUT, V25, P1377, DOI 10.1016/j.imavis.2006.10.002
   Shen JL, 2015, PATTERN RECOGN, V48, P3227, DOI 10.1016/j.patcog.2015.02.027
   Singh KM, 2014, IMAGING SCI J, V62, P313, DOI 10.1179/1743131X14Y.0000000072
   SUN T, 1994, PATTERN RECOGN LETT, V15, P341, DOI 10.1016/0167-8655(94)90082-5
   Tukey J.W., 1977, EXPLORATORY DATA ANA, V2
   Tukey J. W., 1974, P EASCOM, P673
   Wang SH, 2018, J REAL-TIME IMAGE PR, V15, P631, DOI 10.1007/s11554-017-0717-0
   Wang XT, 2016, J VIS COMMUN IMAGE R, V38, P440, DOI 10.1016/j.jvcir.2016.03.024
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang YD, 2008, SCI CHINA SER F, V51, P2115, DOI 10.1007/s11432-008-0124-z
NR 40
TC 17
Z9 17
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1785
EP 1804
DI 10.1007/s11042-018-6303-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700025
DA 2024-07-18
ER

PT J
AU Wang, XY
   Jiao, LX
   Wang, XB
   Yang, HY
   Niu, PP
AF Wang, Xiang-yang
   Jiao, Li-xian
   Wang, Xue-bing
   Yang, Hong-ying
   Niu, Pan-pan
TI Copy-move forgery detection based on compact color content descriptor
   and Delaunay triangle matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery detection; Color invariance SIFER; FQRHFMs; Coherency
   sensitive hashing; Optimized ZNCC
ID ALGORITHM
AB Copy-move (region duplication) is one of the most common types of image forgeries, in which at least one part of an image is copied and pasted onto another area of the same image. The main aims of the copy-move forgery are to overemphasize a concept or conceal objects by duplicating some regions. Keypoint based copy-move forgery detection (CMFD) method extracts image feature points and employs local image features to identify duplicated regions, which exhibits remarkable detection performance with respect to memory requirement, computational cost, and robustness. However, they usually do not work well when the objects are hidden in smooth background areas. Also, the detection and localization accuracy always be lowered because of poor local image feature computation. In this paper, we present a novel approach for the detection and localization of copy-move forgeries, which is based on color invariance SIFER (Scale-invariant feature detector with error resilience) and FQRHFMs (Fast quaternion radial harmonic Fourier moments). Firstly, the original forgery image is segmented into nonoverlapping and nearly uniform superpixel blocks, and the stable keypoints are extracted adaptively from each superpixel block by incorporating the superpixel contents and color invariance SIFER. Secondly, a set of connected Delaunay triangles is constructed using the extracted image keypoints, and suitable local image feature for each Delaunay triangle is computed by using FQRHFMs and gradient entropy. Thirdly, the local image features and coherency sensitive hashing (CSH) are utilized to match quickly the Delaunay triangles. Finally, the falsely matched Delaunay triangles are removed by employing dense linear fitting (DLF), and the duplicated regions are localized using optimized zero mean normalized cross-correlation (ZNCC) measure. We conduct extensive experiments to evaluate the performance of the proposed copy-move forgery detection scheme, in which encouraging results validate the effectiveness of the proposed technique.
C1 [Wang, Xiang-yang; Jiao, Li-xian; Wang, Xue-bing; Yang, Hong-ying; Niu, Pan-pan] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY; Yang, HY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com; yhy_65@126.com
RI Yang, Jing/JFK-4046-2023; Niu, Panpan/Q-9953-2017
OI Yang, Jing/0009-0004-8274-9863; 
FU National Natural Science Foundation of China [61472171, 61272416,
   61701212]; China Postdoctoral Science Foundation [2017M621135]; Natural
   Science Foundation of Liaoning Province of China [201602463]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61472171, 61272416, & 61701212, Project Funded by
   China Postdoctoral Science Foundation No. 2017M621135, and the Natural
   Science Foundation of Liaoning Province of China under Grant No.
   201602463.
CR Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Aymaz S, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P1125, DOI 10.1109/SIU.2016.7495942
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P1759, DOI 10.1016/j.sigpro.2011.01.022
   Cao Ming, 2015, [Wuhan University Journal of Natural Sciences, 武汉大学学报自然科学], V20, P313
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Chambers J, 2015, MULTIMED TOOLS APPL, V74, P4013, DOI 10.1007/s11042-013-1809-x
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Davarzani R, 2016, MULTIMED TOOLS APPL, V75, P4639, DOI 10.1007/s11042-015-2496-6
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   Gong Jiachang, 2016, Transactions of Tianjin University, V22, P151, DOI 10.1007/s12209-016-2705-z
   Hu HT, 2014, PATTERN RECOGN, V47, P2596, DOI 10.1016/j.patcog.2014.02.014
   Isaac MM, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P394, DOI 10.1145/2791405.2791453
   Korman S, 2016, IEEE T PATTERN ANAL, V38, P1099, DOI 10.1109/TPAMI.2015.2477814
   Li C, 2016, 8TH INTERNATIONAL CONFERENCE ON INTERNET MULTIMEDIA COMPUTING AND SERVICE (ICIMCS2016), P5, DOI 10.1145/3007669.3007689
   Li LD, 2014, COMPUT ELECTR ENG, V40, P1951, DOI 10.1016/j.compeleceng.2013.11.034
   Lin C, 2017, SIGNAL PROCESS-IMAGE, V52, P64, DOI 10.1016/j.image.2017.01.001
   Liu MY, 2014, IEEE T PATTERN ANAL, V36, P99, DOI 10.1109/TPAMI.2013.107
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Mainali P, 2013, INT J COMPUT VISION, V104, P172, DOI 10.1007/s11263-013-0622-3
   Oommen RS, 2016, ADV INTELL SYST COMP, V425, P559, DOI 10.1007/978-3-319-28658-7_47
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Ren HP, 2003, J OPT SOC AM A, V20, P631, DOI 10.1364/JOSAA.20.000631
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Thirunavukkarasu V, 2017, WIRELESS PERS COMMUN, P1
   Üstübioglu B, 2015, SIG PROCESS COMMUN, P919, DOI 10.1109/SIU.2015.7129980
   Wang CP, 2016, SIGNAL PROCESS-IMAGE, V45, P10, DOI 10.1016/j.image.2016.03.007
   Wang JW, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P25, DOI 10.1109/MINES.2009.142
   Wang XY, 2015, OPT LASER TECHNOL, V66, P78, DOI 10.1016/j.optlastec.2014.07.020
   Wo Y, 2017, IET IMAGE PROCESS, V11, P99, DOI 10.1049/iet-ipr.2016.0229
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Yang B, 2017, MULTIMED TOOLS APPL, V2017, P1
   Zhao F, 2016, LECT NOTES COMPUT SC, V10066, P478, DOI 10.1007/978-3-319-49148-6_39
   Zhao Jing, 2013, ISRN Neurosci, V2013, P579216, DOI 10.1155/2013/579216
   Zheng JB, 2016, MULTIDIM SYST SIGN P, V27, P989, DOI 10.1007/s11045-016-0416-1
   Zhu Y, 2016, MULTIMED TOOLS APPL, V75, P3221, DOI 10.1007/s11042-014-2431-2
NR 45
TC 12
Z9 12
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2311
EP 2344
DI 10.1007/s11042-018-6354-1
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700045
DA 2024-07-18
ER

PT J
AU Zhou, KZ
   Liao, JM
   Zhou, XR
AF Zhou, Kezhou
   Liao, Jianmin
   Zhou, Xiaorong
TI Counterfeiting ancient Chinese Armour using 3D-printing technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ancient Chinese Armour; Art design; 3D printing
ID 3D; FUTURE
AB 3D-printing (3DP) technology has become widespread over the past few years and has been applied in a number of areas, including the industrial design of tools and moulds, fashion design, and film and television production. Manufacturing products using 3DP has advantages: it accelerates the design process and lowers production time and costs. However, despite the fact that the use of 3DP in creating props and appliances for films and television is well-known, few papers have effectively studied this phenomenon. To this end, in this paper we describe our own experience to recreate ancient Chinese armour using 3DP for movies and discuss how our methods may be applied to the broader field. We use a Chinese army combat uniform, as an example, presenting in-detail the steps to designing, manufacturing, and processing this costume. We then analyse the advantages and disadvantages of 3DP and specific printers. As the use of 3DP in complex design is an emerging topic, we hope that this research will provide designers with information about the use, benefits, and challenges of 3DP in the design process.
C1 [Zhou, Kezhou; Liao, Jianmin; Zhou, Xiaorong] Hunan Univ Commence, Coll Design & Arts, Changsha 410205, Hunan, Peoples R China.
RP Zhou, KZ (corresponding author), Hunan Univ Commence, Coll Design & Arts, Changsha 410205, Hunan, Peoples R China.
EM zkz@hnuc.edu.cn
FU Research Foundation of Hunan Provincial Education Commission [16C0874]
FX This work was supported by the Research Foundation of Hunan Provincial
   Education Commission under Grant No. 16C0874.
CR Baumers M, 2016, TECHNOL FORECAST SOC, V102, P193, DOI 10.1016/j.techfore.2015.02.015
   Berman B, 2012, BUS HORIZONS, V55, P155, DOI 10.1016/j.bushor.2011.11.003
   Boland Thomas, 2006, Biotechnology Journal, V1, P910, DOI 10.1002/biot.200600081
   Campbell PG, 2007, EXPERT OPIN BIOL TH, V7, P1123, DOI 10.1517/14712598.7.8.1123
   Casey L., 2009, Packaging Digest, P54
   Clark L., 2014, 12th International Conference E-Society, V12, P251
   Conner B.P., 2014, Addit. Manuf., V1-4, P64, DOI [10.1016/j.addma.2014.08.005, DOI 10.1016/J.ADDMA.2014.08.005]
   Cozmei C, 2012, PROC ECON FINANC, V3, P457, DOI 10.1016/S2212-5671(12)00180-3
   Evans B., 2012, PRACTICAL 3D PRINTER
   Gebler M, 2014, ENERG POLICY, V74, P158, DOI 10.1016/j.enpol.2014.08.033
   Hopkinson N, 2006, RAPID MANUFACTURING: AN INDUSTRIAL REVOLUTION FOR THE DIGITAL AGE, P1
   Hyysalo S, 2014, CODESIGN, V10, P209, DOI 10.1080/15710882.2014.983937
   Kuhn R., 2015, Moda Documenta: Museu, Memoria e Design, V11, P1
   Levy GN, 2003, CIRP ANN-MANUF TECHN, V52, P589, DOI 10.1016/S0007-8506(07)60206-6
   Liu K, 2017, SCI TECHNOLOGY, V07
   Long YG, 2017, INT J PROD RES, V55, P1488, DOI 10.1080/00207543.2017.1280196
   Ma D, 2005, CULTURAL WIDE ANGLES, V6, P114
   Mau D., 2013, How 3-D Printing Could Change the Fashion Industry For Better and For Worse - Fashionista
   Mpofu TP., 2014, Impact and application of 3D printing technology, V3, P2148
   Orcutt M., 2016, MIT TECHNOL REV, V2016
   Parker CJ, 2015, WIT T ENG SCI, V113, P373
   Perry A., 2017, International Journal of Fashion Design, Technology and Education, DOI DOI 10.1080/17543266.2017.1306118
   Perry A, 2016, J GLOB FASH MARK, V7, P225, DOI 10.1080/20932685.2016.1205953
   Petrick IJ, 2013, RES TECHNOL MANAGE, V56, P12, DOI 10.5437/08956308X5606193
   Petrovic V, 2011, INT J PROD RES, V49, P1061, DOI 10.1080/00207540903479786
   Qian MS, 2016, ART DESIGN RES, V03
   Qian MS, 2017, J ZHEJIANG SCI TECH, V38, P3
   Sachs EM, 1989, Three dimensional printing techniques, Patent No. [5204055A, 5204055]
   TARMY James., 2016, The future of fashion is 3D Printing clothes at home
   Valtas A., 2016, Journal of Fashion Technology Textile Engineering, V4, P1
   Vanderploeg A., 2017, Int J Fash Des Technol Educ, V10, P170, DOI DOI 10.1080/17543266.2016.1223355
   Wang BZ, 2014, 4 INT C FRONT MAN DE
   Wang WT, 2014, SCI TECHNOLOGY MANAG, V496-500, P2687
   YANG En-quan, 2013, AERONAUTICAL SCI TEC, P13
   Yap YL, 2014, VIRTUAL PHYS PROTOTY, V9, P195, DOI 10.1080/17452759.2014.938993
   Zhang Rong-hong, 2015, J GEMS GEMMOLOGY, V17, P45
NR 36
TC 2
Z9 2
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 1103
EP 1116
DI 10.1007/s11042-018-6462-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500062
DA 2024-07-18
ER

PT J
AU Zhu, ZJ
   Xu, F
   Yan, CG
   Li, N
   Gong, BJ
   Zhang, YD
   Dai, QH
AF Zhu, Zunjie
   Xu, Feng
   Yan, Chenggang
   Li, Ning
   Gong, Bingjian
   Zhang, Yongdong
   Dai, Qionghai
TI Real-time indoor scene reconstruction with Manhattan assumption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SLAM; Tracking; Depth sensor; Real-Time; AR
ID PARALLEL FRAMEWORK; POINT; HEVC; 3D; REGISTRATION; MOTION
AB This paper presents a novel end-to-end system for real-time indoor scene reconstruction, which outperforms traditional image feature point-based method and dense geometry correspondence-based method in handling indoor scenes with less texture and geometry features. In our method, we fully explore the Manhattan assumption, i.e. scenes are majorly consisted with planar surfaces with orthogonal normal directions. Given an input depth frame, we first extract dominant axes coordinates via principle component analysis which involves the orthogonal prior and reduce the influence of noise. Then we calculate the coordinates of dominant planes (such as walls, floor and ceiling) in the coordinates using mean shift. Finally, we compute the camera orientation and reconstruct the scene by proposing a fast scheme based on matching the dominant axes and planes to the previous frame. We have tested our approach on several datasets and demonstrated that it outperforms some well known existing methods in these experiments. The performance of our method is also able to meet the requirement of real-time with an unoptimized CPU implementation.
C1 [Zhu, Zunjie; Yan, Chenggang; Li, Ning; Gong, Bingjian] Hangzhou Dianzi Univ, Inst Informat & Control, Hangzhou, Zhejiang, Peoples R China.
   [Xu, Feng] Tsinghua Univ, Sch Software, Beijing, Peoples R China.
   [Zhang, Yongdong] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Dai, Qionghai] Tsinghua Univ, Dept Automat, Beijing, Peoples R China.
C3 Hangzhou Dianzi University; Tsinghua University; Chinese Academy of
   Sciences; Institute of Computing Technology, CAS; Tsinghua University
RP Yan, CG (corresponding author), Hangzhou Dianzi Univ, Inst Informat & Control, Hangzhou, Zhejiang, Peoples R China.; Xu, F (corresponding author), Tsinghua Univ, Sch Software, Beijing, Peoples R China.
EM zunjiezhu@gmail.com; feng-xu@tsinghua.edu.cn; cgyan@hdu.edu.cn
RI Dai, Qionghai/ABD-5298-2021; Li, Ning/I-3417-2012
OI Dai, Qionghai/0000-0001-7043-3061; Li, Ning/0000-0003-1684-4454
FU National Nature Science Foundation of China [61671196, 61327902,
   61671268, 61727808]; Zhejiang Province Nature Science Foundation of
   China [LR17F030006]
FX This work is supported by National Nature Science Foundation of China
   (61671196, 61327902, 61671268, 61727808), Zhejiang Province Nature
   Science Foundation of China LR17F030006.
CR [Anonymous], 2014, ARXIV14100925
   [Anonymous], 2011, IEEE ISMAR
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   CHEN HH, 1991, IEEE T PATTERN ANAL, V13, P530, DOI 10.1109/34.87340
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739
   Eric W, 1987, MODEL BASED RECOGNIT
   Furukawa Y, 2009, PROC CVPR IEEE, P1422, DOI 10.1109/CVPRW.2009.5206867
   He Jun, 2006, Journal of System Simulation, V18, P3055
   Henry Peter, 2014, RGB D MAPPING USING
   Kähler O, 2015, IEEE T VIS COMPUT GR, V21, P1241, DOI 10.1109/TVCG.2015.2459891
   Lee TK, 2012, IEEE INT C INT ROBOT, P1727, DOI 10.1109/IROS.2012.6385909
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   Nistér D, 2007, J MATH IMAGING VIS, V27, P67, DOI 10.1007/s10851-006-0450-y
   Oliva N, 2017, INT EL DEVICES MEET
   Ramalingam S, 2013, INT J COMPUT VISION, V102, P73, DOI 10.1007/s11263-012-0576-x
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377
   Steinbrücker F, 2013, IEEE I CONF COMP VIS, P3264, DOI 10.1109/ICCV.2013.405
   Taguchi Y, 2013, IEEE INT CONF ROBOT, P5182, DOI 10.1109/ICRA.2013.6631318
   Trevor AJB, 2012, IEEE INT CONF ROBOT, P3041, DOI 10.1109/ICRA.2012.6225287
   UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573
   Whelan T, 2013, IEEE INT CONF ROBOT, P5724, DOI 10.1109/ICRA.2013.6631400
   Yan C, 2017, EFFECTIVE UYGHUR LAN, DOI [10. 1109/TITS. 2017. 2749977, DOI 10.1109/TITS.2017.2749977]
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   ZHANG ZY, 1991, IMAGE VISION COMPUT, V9, P10, DOI 10.1016/0262-8856(91)90043-O
NR 31
TC 1
Z9 1
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 713
EP 726
DI 10.1007/s11042-017-5519-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500040
DA 2024-07-18
ER

PT J
AU Chen, LH
   Su, CW
   Hsiao, HA
AF Chen, Liang-Hua
   Su, Chih-Wen
   Hsiao, Hsiang-An
TI Player trajectory reconstruction for tactical analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sport video analysis; Image mosaic; Homography transformation
AB To increase the performance of sport team, the tactical analysis of team from game video is essential. Trajectories of the players are the most useful cues in a sport video for tactical analysis. In this paper, we propose a technique to reconstruct the trajectories of players from broadcast basketball videos. We first propose a mosaic based approach to detect the boundary lines of court. Then, the locations of players are determined by the integration of shape and color visual information. A layered graph is constructed for the detected players, which includes all possible trajectories. A dynamic programming based algorithm is applied to find the trajectory of each player. Finally, the trajectories of players are displayed on a standard basketball court model by a homography transformation. In contrast to related works, our approach exploits more spatio-temporal information in video. Experimental results show that the proposed approach works well and outperforms some existing technique.
C1 [Chen, Liang-Hua; Hsiao, Hsiang-An] Fu Jen Catholic Univ, Dept Comp Sci & Informat Engn, New Taipei, Taiwan.
   [Su, Chih-Wen] Chung Yuan Christian Univ, Dept Informat & Comp Engn, Chungli, Taiwan.
C3 Fu Jen Catholic University; Chung Yuan Christian University
RP Chen, LH (corresponding author), Fu Jen Catholic Univ, Dept Comp Sci & Informat Engn, New Taipei, Taiwan.
EM lchen@csie.fju.edu.tw
CR Alahi Alexandre., 2009, Third ACM/IEEE International Conference on Distributed Smart Cameras, P1, DOI DOI 10.1109/ICDSC.2009.5289406
   [Anonymous], 2009, 4 INT C INT COMP INF
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2017, ARXIV170307402
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Chen HT, 2012, J VIS COMMUN IMAGE R, V23, P932, DOI 10.1016/j.jvcir.2012.06.003
   Cricri F, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P63, DOI 10.1109/ISM.2014.67
   Ekin A, 2003, P INT C IMAGE PROCES, P1
   Felzenszwalb P., 2008, P IEEE C COMPUTER VI
   Hu MC, 2011, IEEE T MULTIMEDIA, V13, P266, DOI 10.1109/TMM.2010.2100373
   Irani M, 1998, P IEEE, V86, P905, DOI 10.1109/5.664279
   Kirkup JA, 2016, IEEE SENS J, V16, P4622, DOI 10.1109/JSEN.2016.2542359
   Lee GG, 2009, IEEE INT CON MULTI, P318, DOI 10.1109/ICME.2009.5202499
   LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Lu WL, 2013, IEEE T PATTERN ANAL, V35, P1704, DOI 10.1109/TPAMI.2012.242
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Rousseeuw P.J., 1987, ROBUST REGRESSION OU
   Tien MC, 2007, INT CONF ACOUST SPEE, P1085
   Zhang YF, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2190
NR 21
TC 1
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30475
EP 30486
DI 10.1007/s11042-018-6164-5
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600015
DA 2024-07-18
ER

PT J
AU Ghosal, SK
   Mandal, JK
   Sarkar, R
AF Ghosal, S. K.
   Mandal, J. K.
   Sarkar, R.
TI High payload image steganography based on Laplacian of Gaussian (LoG)
   edge detector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Edge Detction; Laplacian of Gaussian; Payload; PSNR
ID MODIFICATION DIRECTION
AB Image Steganography is the method of concealing secret information into the digital image, and LSB replacement policy is recognized as the foremost and widely used approach. In traditional LSB based scheme, the secret bits are fabricated into the LSB position of each pixel without making a prior analysis of the image contents. As a consequence, the visual quality as well as the security of the stego-image becomes a concern even to achieve a low embedding rate. In this paper, the embedding of secret data has been made by classifying the pixels of the cover image into following two categories: edge and non-edge. This classification is made by applying the Laplacian of Gaussian (LoG) edge detector over the gray-scale images. It has been observed that the non-edge pixels get affected severely compared to edge pixels at higher embedding rate and therefore, more bits are embedded in edge pixels rather than in the non-edge pixels. The disadvantage of existing edge detection based Steganography schemes is the embedding of (extra) edge information besides the actual embedding. Unlikely, the proposed scheme proficiently avoids the burden of embedding of extra edge information and utilizes the embedding space fully. Experimental results ensure that the proposed scheme achieves higher payload and better stego-image quality compared to existing schemes.
C1 [Ghosal, S. K.] Future Inst Technol, Dept Comp Sci & Engn, 240 Boral Main Rd, Kolkata 7000154, India.
   [Mandal, J. K.] Univ Kalyani, Dept Comp Sci & Engn, Kalyani 741235, W Bengal, India.
   [Sarkar, R.] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
C3 Kalyani University; Jadavpur University
RP Ghosal, SK (corresponding author), Future Inst Technol, Dept Comp Sci & Engn, 240 Boral Main Rd, Kolkata 7000154, India.
EM sudipta.ghosal@gmail.com
RI Sarkar, Ram/AAX-3822-2020; Mandal, Jyotsna Kumar/H-5724-2018
OI Sarkar, Ram/0000-0001-8813-4086; Mandal, Jyotsna
   Kumar/0000-0001-9447-647X
CR Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Chen J, 2014, SIGNAL PROCESS-IMAGE, V29, P375, DOI 10.1016/j.image.2014.01.003
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Hussain M, 2017, SIGNAL PROCESS-IMAGE, V50, P44, DOI 10.1016/j.image.2016.10.005
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2179, DOI 10.1007/s11042-014-2081-4
   Kim HJ, 2010, COMPUT MATH APPL, V60, P319, DOI 10.1016/j.camwa.2010.01.006
   Kuo W.-C., 2014, J INF HIDING MULTIME, V5, P420
   Kuo WC, 2013, IMAGING SCI J, V61, P484, DOI 10.1179/1743131X12Y.0000000011
   Kuo-Nan Chen, 2010, Proceedings of the 2010 International Conference on Computational Aspects of Social Networks (CASoN 2010), P126, DOI 10.1109/CASoN.2010.35
   Lee CF, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P497
   Liao X, 2012, IEICE T FUND ELECTR, VE95A, P1189, DOI 10.1587/transfun.E95.A.1189
   Shen SY, 2018, MULTIMED TOOLS APPL, V77, P12563, DOI 10.1007/s11042-017-4905-5
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Sonka M., 2014, Image processing, analysis, and machine vision
   Kieu TD, 2011, EXPERT SYST APPL, V38, P10648, DOI 10.1016/j.eswa.2011.02.122
   Tseng HW, 2014, IET IMAGE PROCESS, V8, P647, DOI 10.1049/iet-ipr.2013.0584
   Weber A.G, 2018, The USC-SIPI Image Database: Version 6
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Xia B-B, 2016, J INF HIDING MULTIME, V7, P836
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2017, PROC IEEE MICR ELECT, P813, DOI 10.1109/MEMSYS.2017.7863532
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Zhang XD, 2006, IEEE COMMUN LETT, V10, P7, DOI 10.1109/LCOMM.2006.01019
NR 25
TC 29
Z9 30
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30403
EP 30418
DI 10.1007/s11042-018-6126-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600012
DA 2024-07-18
ER

PT J
AU Stojanovski, D
   Strezoski, G
   Madjarov, G
   Dimitrovski, I
   Chorbev, I
AF Stojanovski, Dario
   Strezoski, Gjorgji
   Madjarov, Gjorgji
   Dimitrovski, Ivica
   Chorbev, Ivan
TI Deep neural network architecture for sentiment analysis and emotion
   identification of Twitter messages
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Twitter; Convolutional neural networks; Word embeddings; Sentiment
   analysis; Emotion identification
AB In the work presented in this paper, we showcase a deep learning system for sentiment analysis and emotion identification in Twitter messages. The system consists of a convolutional neural network used for extracting features from textual data and a classifier for which we experiment with several different classifying algorithms. We train the network using pre-trained word embeddings obtained by unsupervised learning on large text corpora and compare the effectiveness of the different word vectors for this task. We evaluate our system on 3-class sentiment analysis with datasets provided by the Sentiment analysis in Twitter task from the SemEval competition. Additionally, we explore the effectiveness of our approach for emotion identification, by using an automatically annotated dataset with 7 distinct emotions. Our architecture achieves comparable performances to state-of-the-art techniques in the field of sentiment analysis and improves results in the field of emotion identification on the test we use in our evaluation. Moreover, the paper presents several use case scenarios, depicting real-world usage of our architecture.
C1 [Stojanovski, Dario; Strezoski, Gjorgji; Madjarov, Gjorgji; Dimitrovski, Ivica; Chorbev, Ivan] Ss Cyril & Methodius Univ, Fac Comp Sci & Engn, Skopje, North Macedonia.
C3 Saints Cyril & Methodius University of Skopje
RP Stojanovski, D (corresponding author), Ss Cyril & Methodius Univ, Fac Comp Sci & Engn, Skopje, North Macedonia.
EM stojanovski.dario@gmail.com; strezoski.g@gmail.com;
   gjorgji.madjarov@finki.ukim.mk; ivica.dimitrovski@finki.ukim.mk;
   ivan.chorbev@finki.ukim.mk
OI Madjarov, Gjorgji/0000-0002-1530-0642; Dimitrovski,
   Ivica/0000-0002-2877-3430
FU European Commission [ICT-2013-612944]; Faculty of Computer Science and
   Engineering at the Ss. Cyril and Methodius University
FX We would like to acknowledge the support of the European Commission
   through the project MAESTRA Learning from Massive, Incompletely
   annotated, and Structured Data (Grant number ICT-2013-612944). Also,
   this work was partially financed by the Faculty of Computer Science and
   Engineering at the Ss. Cyril and Methodius University.
CR [Anonymous], ICT INN 2015 WEB P
   [Anonymous], 2015, ARXIV150302510
   [Anonymous], 2014, P 2014 C EMP METH NA
   [Anonymous], 2010, P PYTHON SCI COMPUTI
   [Anonymous], 2015, COMPUTER SCI
   [Anonymous], 2014, P 8 INT WORKSH SEM E
   [Anonymous], 2012, DEEP LEARNING UNSUPE
   [Anonymous], 2014, ARXIV14085882
   [Anonymous], 2016, EUROPEAN HDB CROWDSO
   [Anonymous], 2014, 52 ANN M ASS COMP LI
   [Anonymous], 2015, Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015)
   [Anonymous], 17 INT WORKSH WEB DA
   [Anonymous], 2013, ARXIV13086242
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2017, ARXIV170101811
   [Anonymous], 2014, ASPECT SPECIFIC SENT
   [Anonymous], 2009, P 17 ACM SIGSPATIAL, DOI DOI 10.1145/1653771.1653781
   [Anonymous], 2012, EACL 2012
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], 2012, SENTIMENT ANAL USING
   [Anonymous], 2015, P 9 INT WORKSHOP SEM
   [Anonymous], 2016, ARXIV161103949
   [Anonymous], P 1 WORKSH NLP COMP
   [Anonymous], 2012, ARXIV PREPRINT ARXIV
   Balabantaray RC., 2012, IJAIS, V4, P48, DOI DOI 10.5120/IJAIS12-450651
   Bichen Shi, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8726, P473, DOI 10.1007/978-3-662-44845-8_38
   Bin Lu, 2011, 2011 IEEE International Conference on Data Mining Workshops, P81, DOI 10.1109/ICDMW.2011.125
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Corney David, 2014, Advances in Information Retrieval. 36th European Conference on IR Research, ECIR 2014. Proceedings: LNCS 8416, P449, DOI 10.1007/978-3-319-06028-6_40
   Demirsoz O, 2017, J INF SCI, V43, P509, DOI 10.1177/0165551516653082
   Dos Santos C., 2014, Coling, P69
   El Rahman SA, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P336, DOI 10.1109/iccisci.2019.8716464
   Geoffrey EHinton., 2012, Improving neural networks by preventing co-adaptation of feature detectors
   Ghazi D, 2010, LECT NOTES ARTIF INT, V6085, P40
   Go A., 2009, Twitter sentiment classification using distant supervision, V150, DOI DOI 10.1016/J.SEDGEO.2006.07.004
   Guo W., 2013, PROC ANN M ASS COMPU, P239
   Ifrim G., 2014, CEUR Workshop Proceedings, V1150, P33
   Kolchyna O, 2015, ARXIV PREPRINT ARXIV, V5656, P33
   Kouloumpis E., 2011, TWITTER SENTIMENT AN, P538
   Lin XJ, 2016, LECT NOTES COMPUT SC, V9877, P467, DOI 10.1007/978-3-319-46922-5_41
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Nichols J., 2012, Summarizing sporting events using Twitter, P189, DOI DOI 10.1145/2166966.2166999
   Pak A, 2010, P 7 C INT LANG RES E, DOI DOI 10.17148/IJARCCE.2016.51274
   Radford A., 2017, LEARNING GENERATE RE
   Roberts K, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3806
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P959, DOI 10.1145/2766462.2767830
   Sintsova V., 2013, 4 WORKSH COMP APPR S
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stajner T, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P50
   Stojanovski D, 2015, IEEE INT CONF INNOV, P52, DOI 10.1109/INNOVATIONS.2015.7381514
   Stojanovski D, 2015, LECT NOTES ARTIF INT, V9121, P726, DOI 10.1007/978-3-319-19644-2_60
   Strezoski G., 2016, P 10 INT WORKSH SEM, P149
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Tang Y, 2013, ARXIV
   Wang J, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P225
   Wang WB, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P587, DOI 10.1109/SocialCom-PASSAT.2012.119
   Wang Y., 2016, P 2016 C EMPIRICAL M, P606, DOI 10.18653/v1/D16-1058
   Wilson TS, 2005, PHIL EDUC, P347, DOI 10.3115/1220575.1220619
   Yessenalina Ainur., 2010, Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, P1046
   Yu Y, 2015, COMPUT HUM BEHAV, V48, P392, DOI 10.1016/j.chb.2015.01.075
   Zhou S, 2010, Proceedings of the 23rd International Conference on Computational Linguistics: Posters
NR 64
TC 28
Z9 30
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 32213
EP 32242
DI 10.1007/s11042-018-6168-1
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000031
DA 2024-07-18
ER

PT J
AU Cao, MY
   Deng, ZP
   Rai, L
   Teng, SH
   Zhao, M
   Collier, M
AF Cao, Maoyong
   Deng, Zhaopeng
   Rai, Laxmisha
   Teng, Shenghua
   Zhao, Meng
   Collier, Michael
TI Generating panoramic unfolded image from borehole video acquired through
   APBT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Borehole video; Rubber sheet model; Image registration; Gray-scale
   projection
ID RECOGNITION; PERFORMANCE
AB In geological engineering, geological structure detection is crucial to the engineering design and implementation. One of the most commonly used method is to acquire the borehole videos by Axial View Panoramic Borehole Televiewer (APBT). However this method analyzes the borehole information by video playback or video snapshot, only providing a qualitative description for borehole, but cannot obtain a unfolded image to make quantitative analysis. In this paper, we propose a novel method to generate a complete borehole unfolded image from the video taken by APBT. Firstly, a center location method based on circularity is proposed to automatically locate the center of annular borehole images obtained from the borehole video. Then the annular borehole image sequences are unfolded into the borehole unfolded image sequences by the Rubber sheet model (RSM) combined with interpolation algorithm. Finally, the unfolded image sequences are fused into an entire panoramic unfolded image based on improved gray-scale projection registration algorithm. The experimental results shows that, with our proposed method, panoramic unfolded images from borehole videos with satisfying visual quality to analyze the geological conditions can be obtained efficiently.
C1 [Cao, Maoyong; Deng, Zhaopeng; Zhao, Meng; Collier, Michael] Shandong Univ Sci & Technol, Dept Elect Engn & Automat, Econ & Tech Dev Zone, 579 Qianwangang Rd, Qingdao 266590, Peoples R China.
   [Rai, Laxmisha; Teng, Shenghua] Shandong Univ Sci & Technol, Coll Elect Commun & Phys, Qingdao 266590, Shandong, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Cao, MY (corresponding author), Shandong Univ Sci & Technol, Dept Elect Engn & Automat, Econ & Tech Dev Zone, 579 Qianwangang Rd, Qingdao 266590, Peoples R China.
EM my-cao@263.net
RI Rai, Laxmisha/B-6552-2008
OI Rai, Laxmisha/0000-0003-1494-1138
CR Aaron J, 2015, CAN GEOTECH J, V53, P623
   Ahn H, 2014, J COMPUT VIROL HACKI, V10, P129, DOI 10.1007/s11416-014-0207-x
   Al-Sit W, 2015, J APPL GEOPHYS, V119, P139, DOI 10.1016/j.jappgeo.2015.05.015
   [Anonymous], 2015, IET J ENG
   [Anonymous], 2015, MULTIMEDIA TOOL APPL
   Attar A, 2016, MULTIMED TOOLS APPL, V75, P7407, DOI 10.1007/s11042-015-2663-9
   Banerjee S, 2016, INFORM SCIENCES, V330, P88, DOI 10.1016/j.ins.2015.10.018
   Castellanos WE, 2017, MULTIMED TOOLS APPL, V76, P437, DOI 10.1007/s11042-015-3046-y
   Chen HM, 2016, ROCK MECH ROCK ENG, V49, P555, DOI 10.1007/s00603-015-0748-4
   Chen LD, 2010, IET IMAGE PROCESS, V4, P403, DOI 10.1049/iet-ipr.2009.0286
   Chitte P.P., 2012, INT J COMPUTER TECHN, V2, P16
   Chong NS, 2014, COMPUT ELECTR ENG, V40, P974, DOI 10.1016/j.compeleceng.2013.04.005
   Chong NS, 2012, IET C IMAGE PROCESSI, P1, DOI [10.1049/cp.2012.0443, DOI 10.1049/CP.2012.0443]
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Fu ZX, 2014, MULTIMED TOOLS APPL, V72, P503, DOI 10.1007/s11042-013-1387-y
   Han ZQ, 2015, POL MARIT RES, V22, P10, DOI 10.1515/pomr-2015-0025
   Hofbauer H, 2016, IET BIOMETRICS, V5, P200, DOI 10.1049/iet-bmt.2015.0069
   Je C, 2013, SIGNAL PROCESS-IMAGE, V28, P779, DOI 10.1016/j.image.2013.04.002
   Kim BW, 2012, IET IMAGE PROCESS, V6, P53, DOI 10.1049/iet-ipr.2009.0415
   Kim HS, 2012, INT SOC DESIGN CONF, P509
   Kopanja L, 2016, MEASUREMENT, V92, P252, DOI 10.1016/j.measurement.2016.06.021
   Li SJ, 2013, ROCK MECH ROCK ENG, V46, P635, DOI 10.1007/s00603-012-0344-9
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YF, 2017, MATH MECH SOLIDS, V22, P1997, DOI 10.1177/1081286516653272
   Lv GH, 2016, PATTERN RECOGN LETT, V84, P156, DOI 10.1016/j.patrec.2016.09.011
   Modat M, 2014, J MED IMAGING, V1, DOI 10.1117/1.JMI.1.2.024003
   Münzer B, 2018, MULTIMED TOOLS APPL, V77, P1323, DOI 10.1007/s11042-016-4219-z
   Mukhopadhyay P, 2015, PATTERN RECOGN, V48, P993, DOI 10.1016/j.patcog.2014.08.027
   Nemesin V, 2016, SIVIP, V1, P1
   Niu C, 2013, VISUAL COMPUT, V29, P253, DOI 10.1007/s00371-012-0763-3
   Rousso B, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P945, DOI 10.1109/ICCV.1998.710830
   Salih WHM, 2011, MEAS SCI TECHNOL, V22, DOI 10.1088/0957-0233/22/3/035801
   Shibata K, 2014, ELECTR COMMUN JPN, V97, P58, DOI 10.1002/ecj.11563
   Sukop MC, 2016, GROUNDWATER, V54, P202, DOI 10.1111/gwat.12354
   WANG Chuan-ying, 2001, CHINESE J ROCK MECH, V20, P1687
   Wang CY, 2016, J APPL GEOPHYS, V135, P135, DOI 10.1016/j.jappgeo.2016.10.005
   Wang SC, 2014, VISUAL COMPUT, V30, P1045, DOI 10.1007/s00371-013-0911-4
   Wang XZ, 2015, IET IMAGE PROCESS, V9, P127, DOI 10.1049/iet-ipr.2014.0301
   Wu X, 2016, IEEE INT C PROGR INF, P133
   Xia P, 2013, OPT REV, V20, P193, DOI 10.1007/s10043-013-0033-2
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Zhang JY, 2011, MULTIMED TOOLS APPL, V52, P175, DOI 10.1007/s11042-010-0471-9
   Zhu H, 2016, IEEE GEOSCI REMOTE S, V13, P706, DOI 10.1109/LGRS.2016.2539207
   Zohreh M, 2016, ARAB J GEOSCI, V9, DOI 10.1007/s12517-015-2091-1
NR 48
TC 7
Z9 7
U1 3
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25149
EP 25179
DI 10.1007/s11042-018-5779-x
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400025
DA 2024-07-18
ER

PT J
AU Nouri, F
   Kazemi, K
   Danyali, H
AF Nouri, Fatemeh
   Kazemi, Kamran
   Danyali, Habibollah
TI Salient object detection method using random graph
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object; Saliency map; Detection; Random graph; Random walk prior
ID HIGHLY PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION; RANDOM-WALK; MODEL;
   IMAGES
AB In this paper, a bottom-up salient object detection method is proposed by modeling image as a random graph. The proposed method starts with portioning input image into superpixels and extracting color and spatial features for each superpixel. Then, a complete graph is constructed by employing superpixels as nodes. A high edge weight is assigned into a pair of superpixels if they have high similarity. Next, a random walk prior on nodes is assumed to generate the probability distribution on edges. On the other hand, a complete directed graph is created that each edge weight represents the probability for transmitting random walker from current node to next node. By considering a threshold and eliminating edges with higher probability than the threshold, a random graph is created to model input image. The inbound degree vector of a random graph is computed to determine the most salient nodes (regions). Finally, a propagation technique is used to form saliency map. Experimental results on two challenging datasets: MSRA10K and SED2 demonstrate the efficiency of the proposed unsupervised RG method in comparison with the state-of-the-art unsupervised methods.
C1 [Nouri, Fatemeh; Kazemi, Kamran; Danyali, Habibollah] Shiraz Univ Technol, Dept Elect & Elect Engn, Shiraz, Iran.
C3 Shiraz University of Technology
RP Nouri, F (corresponding author), Shiraz Univ Technol, Dept Elect & Elect Engn, Shiraz, Iran.
EM f.nouri@sutech.ac.ir
OI Nourilenjan Nokabadi, Fatemeh/0000-0003-0349-8054
FU Cognitive Science and Technology Council (CSTC) of Iran [3232]
FX This work was supported by the Cognitive Science and Technology Council
   (CSTC) of Iran under the grant number 3232.
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alpert S, 2007 C 2007 IEEE COM, V1, P8
   [Anonymous], 2011, Scholarpedia, DOI 10.4249/scholarpedia.6201
   [Anonymous], 2015, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2015.2487833
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 8 INT 2015 HAMBG S A
   [Anonymous], MULTIMED TOOLS APPL
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P742, DOI 10.1109/TIP.2014.2383320
   Buso V, 2015, MULTIMED TOOLS APPL, V74, P10077, DOI 10.1007/s11042-015-2803-2
   Chakraborty S, 2016, COMPUT VIS IMAGE UND, V145, P1, DOI 10.1016/j.cviu.2015.12.005
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Elazary L, 2010, VISION RES, V50, P1338, DOI 10.1016/j.visres.2010.01.002
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fu KR, 2014, INT C PATT RECOG, P2371, DOI 10.1109/ICPR.2014.411
   GILBERT EN, 1959, ANN MATH STAT, V30, P1141, DOI 10.1214/aoms/1177706098
   Gopalakrishnan V, 2010, IEEE T IMAGE PROCESS, V19, P3232, DOI 10.1109/TIP.2010.2053940
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Huang S, 2014, IEEE IMAGE PROC, P3087, DOI 10.1109/ICIP.2014.7025624
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Kim JS, 2014, IEEE T CIRC SYST VID, V24, P198, DOI 10.1109/TCSVT.2013.2270366
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Li YJ, 2017, MULTIMED TOOLS APPL, V76, P26273, DOI 10.1007/s11042-016-4118-3
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Wang W, 2010, PROC CVPR IEEE, P2368, DOI 10.1109/CVPR.2010.5539927
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yu JG, 2014, IEEE T CYBERNETICS, V44, P1661, DOI 10.1109/TCYB.2013.2292054
   Zhang LH, 2015, IEEE SIGNAL PROC LET, V22, P1396, DOI 10.1109/LSP.2014.2377216
   Zhou D, 2006, Learning with hypergraphs: clustering, classification, and embedding
NR 38
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24681
EP 24699
DI 10.1007/s11042-018-5668-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400006
DA 2024-07-18
ER

PT J
AU Pan, ZB
   Li, ZY
   Wu, XQ
AF Pan, Zhibin
   Li, Zhengyi
   Wu, Xiuquan
TI A new encoding scheme of LBP based on maximum run length of state "1"
   for texture classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local binary pattern (LBP); Local binary count (LBC); Encoding scheme;
   Maximumrun length; State "1"
ID SUPERRESOLUTION; PATTERNS; SCALE
AB As a simple and efficient local feature descriptor, local binary pattern (LBP) is mainly made up of two steps: extraction step and encoding step. In the extraction step, a local region is denoted by a difference vector between the center pixel and its neighbors. In the encoding step, the corresponding binary bit-string of the difference vector is encoded for the following texture classification. Though encoding step plays a vital role in the whole process of LBP, two current widely used encoding schemes of LBPriu2 and LBC still have some limitations. Different from these two current encoding schemes, in this paper, we propose a new LBP encoding scheme based on the maximum run length of state "1" (LBPmr1) in a binary bit-string. The maximum run length of state "1" reflects the most important part of the binary bit-string structure and it is used as the LBP code of a binary bit-string for the first time. Experimental results on four representative texture databases of Outex, UIUC, CUReT and UMD show that the proposed LBPmr1 achieves better classification accuracy compared with other related LBP encoding schemes.
C1 [Pan, Zhibin; Li, Zhengyi; Wu, Xiuquan] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Industrial Program of Zhejiang Province [2016C31090]; Priority Academic
   Program Development of Jiangsu Higher Education Institutions (PAPD);
   Open Research Fund of Key Laboratory of Spectral Imaging Technology,
   Chinese Academy of Sciences [LSIT201606D]; Key Science and Technology
   Program of Shaanxi Province [2016GY-097]
FX This work is supported in part by the Industrial Program of Zhejiang
   Province (Grant No. Grant No. 2016C31090), the Priority Academic Program
   Development of Jiangsu Higher Education Institutions (PAPD), the Open
   Research Fund of Key Laboratory of Spectral Imaging Technology, Chinese
   Academy of Sciences (Grant No. LSIT201606D) and the Key Science and
   Technology Program of Shaanxi Province (Grant No. 2016GY-097).
CR [Anonymous], 2015, P 24 INT JOINT C
   [Anonymous], P 25 INT JOINT C ART
   [Anonymous], 2017, IEEE T INF FORENSICS
   [Anonymous], PATTERN RECOGN
   [Anonymous], 2016, INT C PATT RECOG
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dana KJ, 1997, PROC CVPR IEEE, P151, DOI 10.1109/CVPR.1997.609313
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P27, DOI 10.1109/TMM.2016.2601020
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Liu LC, 2014, INT C PATT RECOG, P2619, DOI 10.1109/ICPR.2014.452
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu T, 2017, IEEE ACCESS, V5, P13103, DOI 10.1109/ACCESS.2017.2717963
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Ludwig O, 2009, INT IEEE C INTELLIGE, P1
   Ma JY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4492
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan ZB, 2017, EXPERT SYST APPL, V88, P238, DOI 10.1016/j.eswa.2017.07.007
   Pan ZB, 2017, IEEE SIGNAL PROC LET, V24, P828, DOI 10.1109/LSP.2017.2694460
   Pan ZB, 2015, IEEE T IMAGE PROCESS, V24, P5379, DOI 10.1109/TIP.2015.2476955
   Rani PI, 2017, MULTIMED TOOLS APPL, V76, P10017, DOI 10.1007/s11042-016-3592-y
   Ren FH, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON AGENTS (IEEE ICA 2016), P1, DOI [10.1109/ICA.2016.13, 10.1109/ICA.2016.013]
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Wang K, 2013, IEEE SIGNAL PROC LET, V20, P853, DOI 10.1109/LSP.2013.2270405
   Xu Y, 2010, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2010.5540217
   Yuan CS, 2016, CHINA COMMUN, V13, P60, DOI 10.1109/CC.2016.7559076
   Zhao Y, 2012, IEEE T IMAGE PROCESS, V21, P4492, DOI 10.1109/TIP.2012.2204271
   Zhou ZL, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717694172
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zhou ZL, 2016, IEICE T INF SYST, VE99D, P1531, DOI 10.1587/transinf.2015EDP7341
NR 37
TC 6
Z9 6
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26469
EP 26484
DI 10.1007/s11042-018-5871-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500012
DA 2024-07-18
ER

PT J
AU Geng, L
   Yan, TY
   Xiao, ZT
   Xi, JT
   Li, YL
AF Geng, Lei
   Yan, Tingyu
   Xiao, Zhitao
   Xi, Jiangtao
   Li, Yuelong
TI Hatching eggs classification based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; CNN; Transfer learning; Classification; Hatching eggs
ID FERTILITY
AB In order to realize the fertility detection and classification of hatching eggs, a method based on deep learning is proposed in this paper. The 5-days hatching eggs are divided into fertile eggs, dead eggs and infertile eggs. Firstly, we combine the transfer learning strategy with convolutional neural network (CNN). Then, we use a network of two branches. In the first branch, the dataset is pre-trained with the model trained by AlexNet network on large-scale ImageNet dataset. In the second branch, the dataset is directly trained on a multi-layer network which contains six convolutional layers and four pooling layers. The features of these two branches are combined as input to the following fully connected layer. Finally, a new model is trained on a small-scale dataset by this network and the final accuracy of our method is 99.5%. The experimental results show that the proposed method successfully solves the multi-classification problem in small-scale dataset of hatching eggs and obtains high accuracy. Also, our model has better generalization ability and can be adapted to eggs of diversity.
C1 [Geng, Lei; Yan, Tingyu; Xiao, Zhitao] Tianjin Polytech Univ, Sch Elect & Informat Engn, 399 Binshui West St, Tianjin 300387, NO, Peoples R China.
   [Geng, Lei; Yan, Tingyu; Xiao, Zhitao] Tianjin Key Lab Optoelect Detect Technol & Syst, 399 Binshui West St, Tianjin 300387, NO, Peoples R China.
   [Xi, Jiangtao] Univ Wollongong, Sch Elect Comp & Telecommun Engn, Wollongong, NSW 2522, Australia.
   [Li, Yuelong] Tianjin Polytech Univ, Sch Comp Engn, 399 Binshui West St, Tianjin 300387, NO, Peoples R China.
C3 Tiangong University; University of Wollongong; Tiangong University
RP Xiao, ZT (corresponding author), Tianjin Polytech Univ, Sch Elect & Informat Engn, 399 Binshui West St, Tianjin 300387, NO, Peoples R China.; Xiao, ZT (corresponding author), Tianjin Key Lab Optoelect Detect Technol & Syst, 399 Binshui West St, Tianjin 300387, NO, Peoples R China.
EM xiaozhitao@tjpu.edu.cn
RI geng, lei/KEZ-8801-2024
OI Geng, Lei/0000-0002-5010-2596; Xi, Jiangtao/0000-0002-5550-1975
FU National Natural Science Foundation of China [61771340]; key
   technologies R & D program of Tianjin [14ZCZDGX00033]
FX This work is supported by National Natural Science Foundation of China
   under grant No.61771340 and the key technologies R & D program of
   Tianjin under grant No.14ZCZDGX00033.
CR An-An Liu, 2017, IEEE Transactions on Pattern Analysis and Machine Intelligence, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Baoming Shan, 2010, Proceedings Second International Workshop on Education Technology and Computer Science (ETCS 2010), P95, DOI 10.1109/ETCS.2010.540
   Cogswell M., 2016, INT C LEARN REPR
   Gao W, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-015-5470-z
   Gao Z, 2016, NEURAL COMPUT APPL, V27, P2047, DOI 10.1007/s00521-015-2002-0
   Gao Z, 2016, NEUROCOMPUTING, V173, P110, DOI 10.1016/j.neucom.2015.07.105
   Gao Z, 2014, MULTIMED TOOLS APPL, V68, P641, DOI 10.1007/s11042-012-1071-7
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Glorot Xavier., 2010, J MACH LEARN RES, V15, P315
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Liu L, 2013, FOOD BIOPROCESS TECH, V6, P2503, DOI 10.1007/s11947-012-0933-3
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Xu QL, 2014, CHIN CONT DECIS CONF, P1574, DOI 10.1109/CCDC.2014.6852418
   Xu Y., 2015, NONGYE JIXIE XUEBAO, V46, P20, DOI 10.6041/j.issn.1000-1298.2015.02.004
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yang Y, 2010, IEEE T IMAGE PROCESS, V19, P2761, DOI 10.1109/TIP.2010.2049235
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang HW, 2016, PROC CVPR IEEE, P2809, DOI 10.1109/CVPR.2016.307
NR 27
TC 16
Z9 19
U1 2
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22071
EP 22082
DI 10.1007/s11042-017-5333-2
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500016
DA 2024-07-18
ER

PT J
AU Hossain, MS
   Muhammad, G
   Al-Qurishi, M
   Masud, M
   Almogren, A
   Abdul, W
   Alamri, A
AF Hossain, M. Shamim
   Muhammad, Ghulam
   Al-Qurishi, Muhammad
   Masud, Mehedi
   Almogren, Ahmad
   Abdul, Wadood
   Alamri, Atif
TI Cloud-oriented emotion feedback-based Exergames framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Obesity monitoring; Exergames
ID RECOGNITION
AB Exergames platform can be more appealing to the users if they can interact with emotion. Therefore, in this paper, we propose an automatic emotion recognition system from speech to be embedded in the Exergames platform. While playing and doing exercise, the user expresses his or her feeling by uttering some phrases. The speech is recorded by an omnidirectional mic and transmitted to an emotion recognition server in a cloud environment, where the emotion (e.g. happy, sad or neutral) is recognized. For the recognition, we use MPEG-7 low-level audio features and a Gaussian mixture model based classifier. A tactile vibration is generated based on the emotion and feedback to the user for a real feeling. The user can thus have an instantaneous vibrational feeling based on his or her satisfaction. The recognized emotion can also be used as the user's satisfaction of the framework on the fly without the need of a survey session. The experimental study and performance comparison show that the proposed framework has positive effects on the perception of physical activities.
C1 [Hossain, M. Shamim; Alamri, Atif] King Saud Univ, CCIS, Dept Software Engn, POB 51178, Riyadh 11543, Saudi Arabia.
   [Muhammad, Ghulam; Abdul, Wadood] King Saud Univ, CCIS, Dept Comp Engn, POB 51178, Riyadh 11543, Saudi Arabia.
   [Al-Qurishi, Muhammad; Almogren, Ahmad; Abdul, Wadood; Alamri, Atif] King Saud Univ, Res Chair Pervas & Mobile Comp, Riyadh 11543, Saudi Arabia.
   [Masud, Mehedi] Taif Univ, Dept Comp Sci, At Taif, Saudi Arabia.
C3 King Saud University; King Saud University; King Saud University; Taif
   University
RP Hossain, MS (corresponding author), King Saud Univ, CCIS, Dept Software Engn, POB 51178, Riyadh 11543, Saudi Arabia.
EM mshossain@ksu.edu.sa
RI Abdul, Wadood/ABD-2040-2020; Hossain, M. Shamim/K-1362-2014; Huda, Prof
   Dr Mohammad Nurul Nurul/AAX-1111-2021; Alamri, Atif/KFQ-0028-2024;
   Almogren, Ahmad S/F-1365-2014; Guizani, Mohsen/AAX-4534-2021; Masud,
   Mehedi/AAZ-7022-2020; Abdul, Wadood/GZA-4884-2022; AL-Qurishi,
   Muhammad/F-4147-2018; Muhammad, Ghulam/H-5884-2011
OI Abdul, Wadood/0000-0002-6871-6633; Hossain, M.
   Shamim/0000-0001-5906-9422; Alamri, Atif/0000-0002-1887-5193; Almogren,
   Ahmad S/0000-0002-8253-9709; Guizani, Mohsen/0000-0002-8972-8094; Masud,
   Mehedi/0000-0001-6019-7245; AL-Qurishi, Muhammad/0000-0002-7594-7325;
   Muhammad, Ghulam/0000-0002-9781-3969
FU King Saud University, Deanship of Scientific Research, Research Chair of
   Pervasive and Mobile Computing
FX This work is financially supported by the King Saud University, Deanship
   of Scientific Research, Research Chair of Pervasive and Mobile
   Computing.
CR Alamri A, 2014, COMPUT HUM BEHAV, V30, P468, DOI 10.1016/j.chb.2013.06.021
   [Anonymous], 2001, 159384 ISOIEC CD
   [Anonymous], WHO OB OV FACT SHEET
   Basori AH, 2008, P VRCAI 08 SING
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Chen M, 2016, INDUSTRIALIOT 2016
   Chen M, 2015, IEEE NETWORK, V29, P32, DOI 10.1109/MNET.2015.7064900
   Ciota Zygmunt, 2007, HAVE 2007 - IEEE International Workshop on Haptic Audio Visual Environments and their Applications, P67
   Ginsburg KR, 2007, PEDIATRICS, V119, P182, DOI 10.1542/peds.2006-2697
   Hassan MM, 2013, P IEEE ICME SAN JOS
   Hossain MS, 2016, MOBILE NETW APPL, V21, P753, DOI 10.1007/s11036-016-0685-9
   Hossain MS, 2017, IEEE ACCESS, V5, P2281, DOI 10.1109/ACCESS.2017.2672829
   Hossain MS, 2016, MULTIMEDIA SYST, V22, P659, DOI 10.1007/s00530-015-0481-6
   Hossain MS, 2016, J MULTIMODAL USER IN, V10, P325, DOI 10.1007/s12193-015-0207-2
   Hossain MS, 2015, IEEE T CIRC SYST VID, V25, P2105, DOI 10.1109/TCSVT.2015.2444731
   Hossain MS, 2013, P IEEE HAVE 2013 IST
   Karime A, 2012, IEEE T INSTRUM MEAS, V61, P1816, DOI 10.1109/TIM.2012.2192338
   Koolagudi SG, 2012, INT J SPEECH TECHNOL, V15, P495, DOI 10.1007/s10772-012-9150-8
   Mateas M, 2007, P CHI 07 C COMP HUM
   Muhammad G, 2009, P 4 INT C EMB MULT C
   Muhammad G, 2011, J ELECTR ENG-SLOVAK, V62, P199, DOI 10.2478/v10187-011-0032-0
   Parker JR, CAN J DIABETES, V35, P187
   Patsi C., 2012, BALKAN MILITARY MED, V15, P275
   Schuller B, 2004, INT C AC SPEECH SIGN
   Sinclair J, 2007, P ACM GRAPHITE 07 PE
   Stach T, 2011, LECT NOTES COMPUT SC, V6947, P18, DOI 10.1007/978-3-642-23771-3_2
   Szczuko P, 2004, P AES 116 CONV
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Warburton DER, 2007, APPL PHYSIOL NUTR ME, V32, P655, DOI 10.1139/H07-038
   Yim Jeffrey., 2007, Proceedings of the 2007 conference on Future Play - Future Play '07, ACM Press, P166, DOI https://doi.org/10.1145/1328202.1328232
   Zacharatos H, 2013, P ACM SIGGRAPH C MOT
   Zhang Y, 2016, IEEE T SERV COMPUT, V9, P786, DOI 10.1109/TSC.2016.2592520
   Zhang Y, 2017, FUTURE GENER COMP SY, V66, P30, DOI 10.1016/j.future.2015.12.001
   Zhou Y, 2009, 2009 INTERNATIONAL CONFERENCE ON E-BUSINESS AND INFORMATION SYSTEM SECURITY, VOLS 1 AND 2, P1001
NR 34
TC 14
Z9 14
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 21861
EP 21877
DI 10.1007/s11042-017-4621-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500004
DA 2024-07-18
ER

PT J
AU Laraqui, M
   Saaidi, A
   Mouhib, A
   Abarkan, M
AF Laraqui, Mohammed
   Saaidi, Abderrahim
   Mouhib, Ali
   Abarkan, Mustapha
TI Dense matching for multi-scale images by propagation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereovision; Multi-scale; Propagation; Dense matching
ID BELIEF PROPAGATION; STEREO; COLOR
AB This article puts forward a new algorithm of dense matching between two images of the same scene, not necessarily stereoscopic and which can be of different scales. This algorithm is based on points of interest identified by a multi-scale detector and later matched according to a very high threshold to keep only the most reliable points. Afterwards, these points serve as germs for the next iteration. This propagation process is guided according to geometric constraints, and repeated until all the possible correspondents between the two images are obtained. The results of the experiments obtained on test images and those of the real world are very satisfactory even in difficult cases of great displacements and changes in appearance between the two captures.
C1 [Laraqui, Mohammed; Saaidi, Abderrahim; Mouhib, Ali; Abarkan, Mustapha] Sidi Mohamed Ben Abdellah Univ Fez Morocco, Polydisciplinary Fac Taza, Lab Engn Sci, LSI, Fes, Morocco.
   [Saaidi, Abderrahim] Sidi Mohamed Ben Abdellah Univ Fez Morocco, Fac Sci Dhar El Mahraz, Dept Math & Comp Sci, LIIAN, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Laraqui, M (corresponding author), Sidi Mohamed Ben Abdellah Univ Fez Morocco, Polydisciplinary Fac Taza, Lab Engn Sci, LSI, Fes, Morocco.
EM laraquimed@gmail.com; abderrahim.saaidi@usmba.ac.ma; mouhibali@yahoo.fr;
   mustapha.abarkan@usmba.ac.ma
RI Saaidi, Abderrahim/R-1916-2019
OI Saaidi, Abderrahim/0000-0003-1708-0468
CR [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], C FRANC AFRIF AFIA R
   [Anonymous], 2011, ACM T GRAPHIC, DOI DOI 10.1145/2010324.1964965
   [Anonymous], MULTIPLE VIEW GEOMET
   [Anonymous], 3 INT C ADV COMM COM
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], 12 INT C FIELD PROGR
   [Anonymous], INT WORKSH IM AN MUL
   Barnes C., 2010, LECT NOTES COMPUT SC, V6313, P29
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3057, DOI 10.1109/CVPR.2011.5995552
   Chen DM, 2015, IEEE T CIRC SYST VID, V25, P730, DOI 10.1109/TCSVT.2014.2361422
   Colodro-Conde C, 2014, J SYST ARCHITECT, V60, P22, DOI 10.1016/j.sysarc.2013.11.006
   Pham CC, 2013, IEEE T CIRC SYST VID, V23, P1119, DOI 10.1109/TCSVT.2012.2223794
   Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421
   Ekstrand F, 2015, PROC SPIE, V9445, DOI 10.1117/12.2181365
   El Hazzat S, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0041-z
   Fang JB, 2012, INT C PAR DISTRIB SY, P472, DOI 10.1109/ICPADS.2012.71
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fowers J, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400684
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P3277, DOI 10.1109/TIP.2017.2696747
   Hassner T, 2012, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2012.6247842
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Jin MX, 2014, ACM T RECONFIG TECHN, V7, DOI 10.1145/2567659
   Jinglin Zhang, 2013, 2013 Conference on Design and Architectures for Signal and Image Processing (DASIP), P209
   Kim J, 2013, PROC CVPR IEEE, P2307, DOI 10.1109/CVPR.2013.299
   Kokkinos I, 2008, PROC CVPR IEEE, P3544
   Korman S, 2011, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2011.6126421
   Kowalczuk J, 2013, IEEE T CIRC SYST VID, V23, P94, DOI 10.1109/TCSVT.2012.2203200
   Laraqui M, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0056-5
   Lee Z, 2013, IEEE T MULTIMEDIA, V15, P1855, DOI 10.1109/TMM.2013.2270456
   Lhuillier M, 2002, IEEE T PATTERN ANAL, V24, P1140, DOI 10.1109/TPAMI.2002.1023810
   Li Ma, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P533, DOI 10.1109/ICIG.2013.113
   Lin WY, 2011, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2011.5995314
   Lin YM, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/654139
   Ma YZ, 2005, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - PROCEEDINGS, P575
   Ma ZY, 2013, IEEE I CONF COMP VIS, P49, DOI 10.1109/ICCV.2013.13
   Matsuo T, 2015, PROC SPIE, V9393, DOI 10.1117/12.2083087
   Mattoccia S, 2013, IEEE COMPUT SOC CONF, P636, DOI 10.1109/CVPRW.2013.96
   Megyesi Z, 2004, INT C PATT RECOG, P76, DOI 10.1109/ICPR.2004.1333709
   Miled W, 2009, IEEE T IMAGE PROCESS, V18, P813, DOI 10.1109/TIP.2008.2011386
   Miron A, 2014, PATTERN RECOGN LETT, V38, P70, DOI 10.1016/j.patrec.2013.11.009
   Mota Vasco, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7520, DOI 10.1109/ICASSP.2014.6855062
   Pérez JM, 2011, PATTERN RECOGN LETT, V32, P2250, DOI 10.1016/j.patrec.2011.06.016
   Ploumpis S, 2015, IMAGE VISION COMPUT, V38, P13, DOI 10.1016/j.imavis.2015.04.001
   Qian Chen, 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P29, DOI 10.1109/CVPR.1999.786913
   Sabater N, 2011, SIAM J IMAGING SCI, V4, P472, DOI 10.1137/100797849
   Salmen J, 2009, LECT NOTES COMPUT SC, V5702, P1096, DOI 10.1007/978-3-642-03767-2_133
   Taime A, 2018, MULTIMED TOOLS APPL, V77, P15027, DOI 10.1007/s11042-017-5086-y
   Tippetts B, 2014, INT J RECONFIGURABLE, V2014, DOI 10.1155/2014/945926
   Trulls E, 2013, PROC CVPR IEEE, P2890, DOI 10.1109/CVPR.2013.372
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Vijayanagar KR, 2014, MOBILE NETW APPL, V19, P414, DOI 10.1007/s11036-013-0458-7
   Wang D, 2017, NEUROCOMPUTING, V252, P58, DOI 10.1016/j.neucom.2016.06.095
   Wang YK, 2014, VISUAL COMPUT, V30, P1157, DOI 10.1007/s00371-013-0896-z
   Wu C., 2011, VisualSFM: A visual structure from motion system
   Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25
   Xu LF, 2013, IEEE INT SYMP CIRC S, P1420, DOI 10.1109/ISCAS.2013.6572122
   Xu T, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, 2014 IEEE 6TH INTL SYMP ON CYBERSPACE SAFETY AND SECURITY, 2014 IEEE 11TH INTL CONF ON EMBEDDED SOFTWARE AND SYST (HPCC,CSS,ICESS), P108, DOI 10.1109/HPCC.2014.22
   Yang HS, 2014, PROC CVPR IEEE, P3406, DOI 10.1109/CVPR.2014.435
   Yang QQ, 2014, IMAGE VISION COMPUT, V32, P202, DOI 10.1016/j.imavis.2014.01.001
   Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99
   Yao SH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134242
   Zhang S, 2013, 2013 IEEE 9TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS (CSPA), P49, DOI 10.1109/CSPA.2013.6530012
   Zhao SG, 2015, IJC METAB ENDOCR, V9, P10, DOI 10.1016/j.ijcme.2015.08.001
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zhengyou Zhang, 2001, 3D Structure from Images - SMILE 2000. Second European Workshop on 3D Structure from Multiple Images of Large-Scale Environments. Revised Papers (Lecture Notes in Computer Science Vol.2018), P68
NR 69
TC 2
Z9 3
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22923
EP 22952
DI 10.1007/s11042-018-5644-y
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500062
DA 2024-07-18
ER

PT J
AU Liu, AA
   Liu, NN
   Nie, WZ
   Su, YT
AF Liu, Anan
   Liu, Nannan
   Nie, Weizhi
   Su, Yuting
TI 3D model retrieval via single image based on feature mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; View-based; Feature mapping/learning; Iteration
   optimization; CNN
ID OBJECT RETRIEVAL; SIMILARITY SEARCH; RECOGNITION; HISTOGRAMS; ENGINE
AB With the development of manufacture, more and more 3D models are generated by users and many differnet factories. 3D model retrieval has been receiving more and more attention in computer vision and the field of data analysis. In this paper, we propose a novel 3D model retrieval algorithm by cross-modal feature mapping (CMFM), which utilize one single image as query information to address 3D model retrieval problem. Specifically, in this paper, we first proposed to leverage 2D image to handle 3d model retrieval problem, which is one new problem in this field. The proposed feature learning method can benefit: 1) avoiding the interference of query image recorded by different visual sensor; 2) handling cross-modal data retrieval by simple computer vision technologies, which can guarantee the performance of retrieval and also control that the retrieval time hold a low level; 3) the low complexity of this method can guarantee that this method can be applied in many fields. Finally, we validate the retrieval method on three popular datasets. Extensive comparison experiments show the superiority of the proposed mehtod. To the best of our knowledge, it is the first method to handle 3D model retreival based on one single 2D image.
C1 [Liu, Anan; Liu, Nannan; Nie, Weizhi; Su, Yuting] Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Nie, WZ (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
EM weizhinie@tju.edu.cn
RI Nie, Weizhi/ABF-5316-2021
OI nie, weizhi/0000-0002-0578-8138
CR Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207
   [Anonymous], 2003, INT J IMAGE GRAPH
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996
   Aubry M, 2011, IEEE INT C COMP VIS
   Baumgart BG, 2014, COMP SCI, V58, P85
   Brennecke A., 2004, SIMULATION VISUALIZA, P299
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Chang SH, 2016, IEEE WORK ADV ROBOT, P141, DOI 10.1109/ARSO.2016.7736271
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   Davis J. V., 2007, ICML, P209
   Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110
   Fang Y, 2015, PROC CVPR IEEE, P2319, DOI 10.1109/CVPR.2015.7298845
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2015, NEUROCOMPUTING, V151, P554, DOI 10.1016/j.neucom.2014.06.085
   Gao Z, 2016, NEUROCOMPUTING, V173, P110, DOI 10.1016/j.neucom.2015.07.105
   Gao Z, 2014, MULTIMED TOOLS APPL, V68, P641, DOI 10.1007/s11042-012-1071-7
   Goldberger J., 2004, Advances in Neural Information Processing Systems
   Guétat G, 2006, IEEE T INF TECHNOL B, V10, P362, DOI 10.1109/TITB.2005.863875
   Hsieh CT, 2015, INT C UB COMP
   Ip CY, 2002, P 7 ACM S SOL MOD AP, P273, DOI 10.1145/566282.566322
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   Leibe B, 2003, PROC CVPR IEEE, P409
   Mohamed W, 2012, VISUAL COMPUT, V28, P305, DOI 10.1007/s00371-011-0640-5
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Nie WZ, 2017, MULTIMEDIA SYST, V23, P325, DOI 10.1007/s00530-015-0485-2
   Nie WZ, 2017, MULTIMED TOOLS APPL, V76, P4091, DOI 10.1007/s11042-015-2840-x
   Novatnack J, 2007, SCALE DEPENDENT 3D G, P1
   Ohbuchi Ryutarou, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P63, DOI 10.1109/ICCVW.2009.5457716
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386
   Papoiu ADP, 2014, J NEUROPHYSIOL, V112, P1729, DOI 10.1152/jn.00827.2013
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681
   Polewski Przemyslaw, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P10, DOI 10.1109/CVPRW.2015.7301378
   Regli WC, 2000, COMPUT AIDED DESIGN, V32, P119, DOI 10.1016/S0010-4485(99)00095-0
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   SHINAGAWA Y, 1991, IEEE COMPUT GRAPH, V11, P44, DOI 10.1109/38.103393
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Vavilov D., 2010, 2010 6th Central and Eastern European Software Engineering Conference in Russia (CEE-SECR 2010), P175, DOI 10.1109/CEE-SECR.2010.5783171
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang Y, 2015, BOOSTING 3D MODEL RE, P1
   Yeh JS, 2005, BIOINFORMATICS, V21, P3056, DOI 10.1093/bioinformatics/bti458
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
NR 54
TC 1
Z9 1
U1 3
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22051
EP 22069
DI 10.1007/s11042-017-5271-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500015
DA 2024-07-18
ER

PT J
AU Qiu, YG
   Gu, HH
   Sun, JY
AF Qiu, Yinguo
   Gu, Hehe
   Sun, Jiuyun
TI Reversible watermarking algorithm of vector maps based on ECC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermarking; Vector maps; ECC; Copyright protection
ID SCHEME
AB Robustness of current watermarking schemes of vector maps is mainly dependent on algorithms of watermark embedding and extraction, while few works have been done focusing on error correction algorithms after watermark extraction. In this paper, a reversible watermarking scheme is proposed for vector maps based on error correction codes (ECC). Original copyright information is firstly expressed by a binary array (copyright watermark data), for which ECC are then generated exploiting XOR operation. Then, the copyright watermark data and its corresponding ECC are merged to compose the final watermark data. To enhance the robustness of this scheme under geometric transformation, watermarks are embedded into polar coordinates of map vertices. After watermark extraction, this scheme can not only obtain the original copyright information, but also recover the original map content accurately. Both theoretical analysis and comprehensive experimental results validate the reversibility, invisibility, capacity and robustness of the proposed watermarking scheme.
C1 [Qiu, Yinguo; Gu, Hehe; Sun, Jiuyun] China Univ Min & Technol, Sch Environm Sci & Spatial Informat, Xuzhou 221116, Jiangsu, Peoples R China.
   [Qiu, Yinguo] Anhui Sci & Technol Univ, Coll Resource & Environm, Chuzhou 233100, Peoples R China.
C3 China University of Mining & Technology; Anhui Science & Technology
   University
RP Gu, HH (corresponding author), China Univ Min & Technol, Sch Environm Sci & Spatial Informat, Xuzhou 221116, Jiangsu, Peoples R China.
EM qiuyinguo@foxmail.com
RI Qiu, Yinguo/IZD-6490-2023
OI Sun, Jiuyun/0009-0007-2697-5673
FU National Natural Science Foundation of China [41171343]; Special Project
   for Talents Introduction of Anhui Science and Technology University
   [ZRC2014396]
FX This research is supported by the National Natural Science Foundation of
   China (Grant No. 41171343), and the Special Project for Talents
   Introduction of Anhui Science and Technology University (Grant No.
   ZRC2014396).
CR [Anonymous], 2016, J INFORM HIDING MULT
   [Anonymous], J INFO HIDING MULT S
   [Anonymous], J INF HIDING MULTIME
   Cao LJ, 2015, SIGNAL IMAGE VIDEO P, V9, P1387, DOI 10.1007/s11760-013-0606-3
   Cao LJ, 2013, VISUAL COMPUT, V29, P231, DOI 10.1007/s00371-012-0732-x
   Cao LJ, 2013, DIGIT SIGNAL PROCESS, V23, P912, DOI 10.1016/j.dsp.2012.11.007
   [曹刘娟 Cao Liujuan], 2011, [哈尔滨工程大学学报, Journal of Harbin Engineering University], V32, P340
   [曹刘娟 Cao Liujuan], 2010, [测绘学报, Acta Geodetica et Cartographica Sinica], V39, P422
   Chen YH, 2016, MULTIMED TOOLS APPL, V75, P13679, DOI 10.1007/s11042-015-2825-9
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Huang HC, 2011, IEEE T CONSUM ELECTR, V57, P779, DOI 10.1109/TCE.2011.5955222
   Jian-Guo Sun, 2014, International Journal of Network Security, V16, P40
   Li YC, 2010, DIGIT SIGNAL PROCESS, V20, P1116, DOI 10.1016/j.dsp.2009.10.025
   Neyman S.N., 2014, Telecommun. Comput. Electron. Control, V12, P367
   Peng F, 2011, COMPUT AIDED DESIGN, V43, P1018, DOI 10.1016/j.cad.2011.03.011
   Ren N, 2014, INT CONF GEOINFORM
   [邵承永 SHAO Chengyong], 2007, [中国图象图形学报, Journal of Image and Graphics], V12, P206
   Tashk A, 2012, INT ISC CONF INFO SE, P60, DOI 10.1109/ISCISC.2012.6408192
   Voigt M, 2005, P SOC PHOTO-OPT INS, V5681, P409, DOI 10.1117/12.588195
   Voigt M, 2004, P 2004 MULT SEC WORK, P160, DOI DOI 10.1145/1022431.1022459
   Wang NN, 2013, MULTIMED TOOLS APPL, V67, P709, DOI 10.1007/s11042-012-1333-4
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   Xiao D, 2015, MULTIMED TOOLS APPL, V74, P2109, DOI 10.1007/s11042-013-1744-x
   Xun Wang, 2012, Journal of Software, V7, P2349, DOI 10.4304/jsw.7.10.2349-2356
   Yan HW, 2017, EARTH SCI INFORM, V10, P471, DOI 10.1007/s12145-017-0310-x
   [杨成松 Yang Chengsong], 2011, [测绘学报, Acta Geodetica et Cartographica Sinica], V40, P256
   [杨成松 YANG Chengsong], 2010, [中国图象图形学报, Journal of Image and Graphics], V15, P684
   [张丽娟 ZHANG Lijuan], 2008, [地球信息科学, Geo-information Science], V10, P724
   Zheng L., 2009, 2009 INT C E BUS INF, P1, DOI [10.1109/EBISS.2009.5137869, DOI 10.1109/EBISS.2009.5137869]
NR 29
TC 5
Z9 6
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23651
EP 23672
DI 10.1007/s11042-018-5680-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900026
DA 2024-07-18
ER

PT J
AU Bhardwaj, A
   Verma, VS
   Jha, RK
AF Bhardwaj, Anuj
   Verma, Vivek Singh
   Jha, Rajib Kumar
TI Robust video watermarking using significant frame selection based on
   coefficient difference of lifting wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lifting wavelet transform; Significant frame selection; Coefficient
   difference; Adaptive threshold
ID QUANTIZATION INDEX MODULATION; PRINCIPAL COMPONENT ANALYSIS;
   PREDICTION-ERROR EXPANSION; IMAGE WATERMARKING; DIGITAL WATERMARKING;
   HIDING SCHEME; DECOMPOSITION; DOMAIN; SVD
AB This manuscript presents a significant frame selection (SFS) and quantization of coefficient difference based robust video watermarking scheme in the lifting wavelet transform domain (LWT). In this scheme, a new procedure based on the mathematical relationship between a number of original video frames, coefficient block size and embedding capacity for significant frame selection is proposed. Third level frequency sub-bands of selected frames are obtained using LWT and lower frequency sub-band (i.e. LH3 sub-band) is considered for watermark embedding. Watermark bits are embedded using the quantization of coefficient difference of two maximum frequency components of significant frame blocks. To improve the security against an external intruder, secret key based randomization of video frames, blocks of coefficients and watermark bits is incorporated. Various geometric and image processing operations are tested and the proposed scheme successfully proves its robustness without compromising the quality of watermarked image. Comparing with other existing schemes, a remarkable improvement in terms of robustness is observed however in some cases the imperceptibility is compromised.
C1 [Bhardwaj, Anuj] Jaypee Inst Informat Technol, Noida 201307, India.
   [Verma, Vivek Singh] Ajay Kumar Garg Engn Coll, Ghaziabad 201009, India.
   [Jha, Rajib Kumar] Indian Inst Technol, Patna 800013, Bihar, India.
C3 Jaypee Institute of Information Technology (JIIT); Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Patna
RP Bhardwaj, A (corresponding author), Jaypee Inst Informat Technol, Noida 201307, India.
EM anujbhardwaj8@gmail.com; viveksv10@gmail.com; jharajib@gmail.com
RI Verma, Vivek Singh/HLH-7169-2023; Verma, Vivek/AAE-4391-2020; Bhardwaj,
   Anuj/KIE-2095-2024
OI Verma, Vivek Singh/0000-0002-1497-2754; Bhardwaj,
   Anuj/0000-0003-0866-2618
CR Busch C, 1999, IEEE COMPUT GRAPH, V19, P25, DOI 10.1109/38.736466
   Chan PW, 2005, IEEE T CIRC SYST VID, V15, P1638, DOI 10.1109/TCSVT.2005.856932
   Choi D, 2010, SIGNAL PROCESS, V90, P1327, DOI 10.1016/j.sigpro.2009.10.009
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Faragallah OS, 2013, AEU-INT J ELECTRON C, V67, P189, DOI 10.1016/j.aeue.2012.07.010
   Guo Y, 2016, IET IMAGE PROCESS, V10, P773, DOI 10.1049/iet-ipr.2015.0818
   Huang HY, 2010, IEEE T INF FOREN SEC, V5, P625, DOI 10.1109/TIFS.2010.2080675
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   Karmakar A, 2016, J KING SAUD UNIV-COM, V28, P199, DOI 10.1016/j.jksuci.2014.06.019
   Knuth D. E., ART COMPUTER PROGRAM, V2
   Lancini R, 2002, PROCEEDINGS VIPROMCOM-2002, P251, DOI 10.1109/VIPROM.2002.1026664
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Ling HF, 2011, SIGNAL PROCESS, V91, P1863, DOI 10.1016/j.sigpro.2011.02.009
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Liu Y, 2010, SIGNAL PROCESS, V90, P626, DOI 10.1016/j.sigpro.2009.08.001
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Mohanty SP, 2011, J SYST SOFTWARE, V84, P724, DOI 10.1016/j.jss.2010.12.012
   Nezhadarya E, 2013, DIGIT SIGNAL PROCESS, V23, P1483, DOI 10.1016/j.dsp.2013.04.009
   Phadikar A, 2013, J KING SAUD UNIV-COM, V25, P163, DOI 10.1016/j.jksuci.2012.11.005
   Preda RO, 2010, MEASUREMENT, V43, P1720, DOI 10.1016/j.measurement.2010.07.009
   Qi M, 2015, SIGNAL PROCESS-IMAGE, V31, P161, DOI 10.1016/j.image.2014.12.009
   Qin C, 2012, PATTERN RECOGN LETT, V33, P2166, DOI 10.1016/j.patrec.2012.08.004
   Rasti P, 2016, J VIS COMMUN IMAGE R, V38, P838, DOI 10.1016/j.jvcir.2016.05.001
   Shih FY, 2003, PATTERN RECOGN, V36, P969, DOI 10.1016/S0031-3203(02)00122-X
   Singh TR, 2013, AEU-INT J ELECTRON C, V67, P645, DOI 10.1016/j.aeue.2013.01.008
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Thanh TM, 2014, AEU-INT J ELECTRON C, V68, P1007, DOI 10.1016/j.aeue.2014.05.004
   Toutenburg H., 1971, BIOMETR Z, V13, P285, DOI DOI 10.1002/BIMJ.19710130413
   Tsougenis ED, 2014, EXPERT SYST APPL, V41, P6408, DOI 10.1016/j.eswa.2014.04.021
   Verma VS, 2015, IETE TECH REV, V32, P479, DOI 10.1080/02564602.2015.1042927
   Verma VS, 2015, SIGNAL IMAGE VIDEO P, V9, P1443, DOI 10.1007/s11760-013-0603-6
   Verma VS, 2015, J VIS COMMUN IMAGE R, V31, P75, DOI 10.1016/j.jvcir.2015.06.001
   Yassin NI, 2014, ALEX ENG J, V53, P833, DOI 10.1016/j.aej.2014.07.008
NR 33
TC 31
Z9 31
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19659
EP 19678
DI 10.1007/s11042-017-5340-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500035
DA 2024-07-18
ER

PT J
AU Kumar, N
AF Kumar, Nitin
TI Thresholding in salient object detection: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Global; Local; Adaptive; Hybrid; Taxonomy
ID REGION DETECTION; VISUAL-ATTENTION; GRAY-LEVEL; IMAGE; MODEL;
   EXTRACTION; INTEGRATION; INFORMATION; FRAMEWORK; CONTRAST
AB Salient Object Detection (SOD) in natural images is an active research area with burgeoning applications across diverse disciplines such as object recognition, image compression, video summarization, object discovery, image retargetting etc. Most salient object detection methods model this problem as a binary segmentation problem where firstly a saliency map is found which highlights the salient pixels and suppresses the background pixels in an image. Secondly, some threshold is applied to obtain the binary segmentation from the saliency map. Thus, thresholding is an important ingredient of salient object detection methods and affects the SOD performance. In this paper, we provide a comprehensive review of various thresholding methods in literature employed for SOD. We have developed a taxonomy of thresholding methods which shall be useful to the researchers and practitioners working in this fascinating research field. Further, we also discuss unexplored thresholding approaches which can be employed in SOD. Various existing and proposed performance measures to analyze SOD methods that depend on thresholding are also presented. Experiments on popular thresholding methods have also been carried out to show the dependence of qualitative and quantitative performance on thresholding.
C1 [Kumar, Nitin] Natl Inst Technol, Dept Comp Sci & Engn, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand
RP Kumar, N (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Uttarakhand, India.
EM nitin2689@gmail.com
RI Kumar, Nitin/AAT-9454-2020
CR Abak AT, 1997, PROC INT CONF DOC, P697, DOI 10.1109/ICDAR.1997.620597
   Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], IEEE INT
   [Anonymous], 2010, P BRIT MACH VIS C
   [Anonymous], 1987, Shifts in selective visual attention: Towards the underlying neural circuitry. matters of intelligence
   [Anonymous], 2014, IEEE IMAGE PROC
   [Anonymous], 2004, Advances in Neural Information Processing Systems
   [Anonymous], 11 EUR C COMP VIS
   [Anonymous], 78 NASA STI
   [Anonymous], ARXIV151104192
   [Anonymous], PATTERN RECOGN LETT
   [Anonymous], IEEE T PATTERN ANAL, DOI DOI 10.1007/978-3-642-14267-3_2
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2015, COMPUT VIS MEDIA
   [Anonymous], RECURRENT DOUBLE FEA
   [Anonymous], 1985, INTRO DIGITAL IMAGE
   [Anonymous], 2009, ADV NEURAL INFORM PR
   Arya R, 2016, MULTIMED TOOLS APPL, V75, P8267, DOI 10.1007/s11042-015-2750-y
   Avidan S., 2007, ACM SIGGRAPH 2007 PA, P10, DOI [10.1145/1275808.1276390, DOI 10.1145/1275808.1276390]
   Avraham T, 2010, IEEE T PATTERN ANAL, V32, P693, DOI 10.1109/TPAMI.2009.53
   BHANU B, 1986, IEEE T AERO ELEC SYS, V22, P364, DOI 10.1109/TAES.1986.310772
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P742, DOI 10.1109/TIP.2014.2383320
   Borji A, 2014, IEEE T SYST MAN CY-S, V44, P523, DOI 10.1109/TSMC.2013.2279715
   Borji A, 2013, VISION RES, V91, P62, DOI 10.1016/j.visres.2013.07.016
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Borji A, 2012, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2012.6247706
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Chen LQ, 2003, MULTIMEDIA SYST, V9, P353, DOI 10.1007/s00530-003-0105-4
   Cheng G., 2008, TRANSPORTATION RES B, P1
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Deravi F, 1983, PATTERN RECOGN LETT, V1, P417, DOI 10.1016/0167-8655(83)90080-6
   Dong L, 2014, J VIS COMMUN IMAGE R, V25, P525, DOI 10.1016/j.jvcir.2013.11.009
   Du SZ, 2014, IEEE SIGNAL PROC LET, V21, P51, DOI 10.1109/LSP.2013.2290547
   Fan Q, 2016, NEUROCOMPUTING, V175, P81, DOI 10.1016/j.neucom.2015.10.030
   Fan Q, 2014, J VIS COMMUN IMAGE R, V25, P1823, DOI 10.1016/j.jvcir.2014.09.003
   Fareed MMS, 2015, J VIS COMMUN IMAGE R, V32, P144, DOI 10.1016/j.jvcir.2015.08.002
   FEKETE G, 1981, IEEE T PATTERN ANAL, V3, P459, DOI 10.1109/TPAMI.1981.4767131
   Fernàndez X, 2000, INT C PATT RECOG, P466, DOI 10.1109/ICPR.2000.905377
   Frintrop S, 2014, INT C PATT RECOG, P2329, DOI 10.1109/ICPR.2014.404
   Fu KR, 2014, IEEE INT CON MULTI
   Fu KR, 2015, IEEE T IMAGE PROCESS, V24, P5671, DOI 10.1109/TIP.2015.2485782
   Fu KR, 2013, SIGNAL PROCESS-IMAGE, V28, P1448, DOI 10.1016/j.image.2013.07.005
   Gao HY, 2014, IEEE IMAGE PROC, P3292, DOI 10.1109/ICIP.2014.7025666
   Gao HY, 2014, IEEE INT SYMP CIRC S, P534, DOI 10.1109/ISCAS.2014.6865190
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Goldberg C, 2012, COMPUT GRAPH FORUM, V31, P265, DOI 10.1111/j.1467-8659.2012.03005.x
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Guo MW, 2014, NEUROCOMPUTING, V144, P184, DOI 10.1016/j.neucom.2014.04.054
   Hai-Bo Wang, 2016, 2016 International Conference on Machine Learning and Cybernetics (ICMLC). Proceedings, P285, DOI 10.1109/ICMLC.2016.7860915
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Hu XY, 2013, IEEE GEOSCI REMOTE S, V10, P466, DOI 10.1109/LGRS.2012.2210188
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007
   Jawahar CV, 1997, PATTERN RECOGN, V30, P1605, DOI 10.1016/S0031-3203(97)00004-6
   Ji QG, 2013, SIGNAL PROCESS-IMAGE, V28, P241, DOI 10.1016/j.image.2012.11.008
   Jia C, 2016, NEUROCOMPUTING, V173, P406, DOI 10.1016/j.neucom.2015.03.122
   Jia YQ, 2013, IEEE I CONF COMP VIS, P1761, DOI 10.1109/ICCV.2013.221
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang ZL, 2013, PROC CVPR IEEE, P2043, DOI 10.1109/CVPR.2013.266
   Jin ZL, 2015, ELECTRON LETT, V51, P628, DOI 10.1049/el.2014.4316
   Johannsen G., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P140
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kai Xu, 2013, 2013 IEEE 4th International Conference on Software Engineering and Service Science (ICSESS), P865, DOI 10.1109/ICSESS.2013.6615442
   KAMEL M, 1993, CVGIP-GRAPH MODEL IM, V55, P203, DOI 10.1006/cgip.1993.1015
   Kannan R, 2015, IEEE SIGNAL PROC LET, V22, P686, DOI 10.1109/LSP.2014.2366192
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Karpathy A, 2013, IEEE INT CONF ROBOT, P2088, DOI 10.1109/ICRA.2013.6630857
   Kienzle W, 2009, J VISION, V9, DOI 10.1167/9.5.7
   Kim J, 2013, IEEE IMAGE PROC, P3426, DOI 10.1109/ICIP.2013.6738707
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   KIRBY RL, 1979, IEEE T SYST MAN CYB, V9, P860
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kong LF, 2015, IET COMPUT VIS, V9, P85, DOI 10.1049/iet-cvi.2013.0285
   Ksantini R, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-40
   Kumar N, 2016, LECT NOTES ARTIF INT, V9673, P109, DOI 10.1007/978-3-319-34111-8_15
   Kwak SY, 2004, LECT NOTES COMPUT SC, V3332, P138
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lang CY, 2016, IEEE T NEUR NET LEAR, V27, P1190, DOI 10.1109/TNNLS.2015.2513393
   Lei Zhou, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5372, DOI 10.1109/ICASSP.2014.6854629
   Leitner J, 2013, BIOL INSPIR COGN ARC, V5, P29, DOI 10.1016/j.bica.2013.05.009
   Leung CK, 1998, GRAPH MODEL IM PROC, V60, P57, DOI 10.1006/gmip.1997.0455
   Leung CK, 1996, PATTERN RECOGN, V29, P1523, DOI 10.1016/0031-3203(96)00009-X
   Li C, 2015, CHIN AUTOM CONGR, P669, DOI 10.1109/CAC.2015.7382582
   Li CH, 1998, PATTERN RECOGN LETT, V19, P771, DOI 10.1016/S0167-8655(98)00057-9
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li JL, 2015, IEEE IMAGE PROC, P2189, DOI 10.1109/ICIP.2015.7351189
   Li S, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440755
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Li ZD, 2008, LECT NOTES COMPUT SC, V5359, P782
   Liang Z, 2012, PATTERN RECOGN, V45, P3886, DOI 10.1016/j.patcog.2012.04.017
   Lin MQ, 2016, NEUROCOMPUTING, V205, P301, DOI 10.1016/j.neucom.2016.04.036
   Lin MQ, 2015, NEUROCOMPUTING, V159, P1, DOI 10.1016/j.neucom.2015.02.050
   Liu F, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1477, DOI 10.1109/ICME.2006.262821
   Liu HT, 2009, IEEE IMAGE PROC, P3097, DOI 10.1109/ICIP.2009.5414466
   Liu J, 2015, NEUROCOMPUTING, V147, P435, DOI 10.1016/j.neucom.2014.06.041
   Liu Q, 2013, MULTIMED TOOLS APPL, V67, P231, DOI 10.1007/s11042-012-1077-1
   Liu RS, 2014, PROC CVPR IEEE, P3866, DOI 10.1109/CVPR.2014.494
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Liu Y, 2015, IEEE IMAGE PROC, P4062, DOI 10.1109/ICIP.2015.7351569
   Liu ZX, 2016, ASIAPAC SIGN INFO PR, DOI 10.1109/APSIPA.2016.7820744
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Lu HC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2524198
   Lu S, 2014, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2014.357
   Luo W, 2012, SIGNAL PROCESS-IMAGE, V27, P238, DOI 10.1016/j.image.2011.10.004
   Luo Y, 2011, IEEE T CIRC SYST VID, V21, P1822, DOI 10.1109/TCSVT.2011.2147230
   Ma XL, 2015, J VIS COMMUN IMAGE R, V32, P95, DOI 10.1016/j.jvcir.2015.08.003
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Mahmoudi L, 2012, 2012 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTATIONAL TOOLS FOR ENGINEERING APPLICATIONS (ACTEA), P204, DOI 10.1109/ICTEA.2012.6462867
   Manipoonchelvi P, 2014, IET IMAGE PROCESS, V8, P519, DOI 10.1049/iet-ipr.2013.0434
   Manke R, 2015, ELECTRON LETT, V51, P37, DOI 10.1049/el.2014.3334
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Muratov O, 2013, IEEE INT WORKSH MULT, P390, DOI 10.1109/MMSP.2013.6659320
   MURTHY CA, 1990, PATTERN RECOGN LETT, V11, P197, DOI 10.1016/0167-8655(90)90006-N
   NAKAGAWA Y, 1979, PATTERN RECOGN, V11, P191, DOI 10.1016/0031-3203(79)90006-2
   Naqvi SS, 2016, PATTERN RECOGN, V51, P209, DOI 10.1016/j.patcog.2015.09.026
   Navalpakkam V, 2005, VISION RES, V45, P205, DOI 10.1016/j.visres.2004.07.042
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal SK, 1983, PATTERN RECOGN LETT, V1, P141, DOI 10.1016/0167-8655(83)90053-3
   Palumbo P. W., 1986, Proceedings of the SPIE - The International Society for Optical Engineering, V697, P278, DOI 10.1117/12.976229
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Peters R.J., 2007, P IEEE C COMPUTER VI, P1
   PUN T, 1981, COMPUT VISION GRAPH, V16, P210, DOI 10.1016/0146-664X(81)90038-1
   Qi SX, 2015, NEUROCOMPUTING, V167, P390, DOI 10.1016/j.neucom.2015.04.055
   Qi W, 2017, VISUAL COMPUT, V33, P209, DOI 10.1007/s00371-015-1176-x
   Qin CC, 2014, NEUROCOMPUTING, V129, P378, DOI 10.1016/j.neucom.2013.09.021
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Ramar K, 2000, PATTERN RECOGN LETT, V21, P1, DOI 10.1016/S0167-8655(99)00120-8
   Ramstrom O, 2002, LECT NOTES COMPUT SC, V2525, P462
   Rao RPN, 2002, VISION RES, V42, P1447, DOI 10.1016/S0042-6989(02)00040-8
   Ren YF, 2014, INT CONF MACH LEARN, P7, DOI 10.1109/ICMLC.2014.7009083
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Rodhetbhai W, 2007, LECT NOTES COMPUT SC, V4781, P126
   ROSENFELD A, 1983, IEEE T SYST MAN CYB, V13, P231, DOI 10.1109/TSMC.1983.6313118
   Rosin PL, 2009, PATTERN RECOGN, V42, P2363, DOI 10.1016/j.patcog.2009.04.021
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Roy S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMPUTING AND CONTROL (ISPCC)
   Sahoo P, 1997, PATTERN RECOGN, V30, P71, DOI 10.1016/S0031-3203(96)00065-9
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Scharfenberger C, 2013, PROC CVPR IEEE, P979, DOI 10.1109/CVPR.2013.131
   SEZAN MI, 1990, COMPUT VISION GRAPH, V49, P36, DOI 10.1016/0734-189X(90)90161-N
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Sezgin M, 2000, PATTERN RECOGN LETT, V21, P151, DOI 10.1016/S0167-8655(99)00142-7
   Shao L, 2006, J VIS COMMUN IMAGE R, V17, P1256, DOI 10.1016/j.jvcir.2006.08.002
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Siagian C, 2009, IEEE T ROBOT, V25, P861, DOI 10.1109/TRO.2009.2022424
   Singh Abhinav Kumar, 2014, 2014 IEEE PES General Meeting: Conference & Exposition, DOI [10.1109/ETHICS.2014.6893380, 10.1109/PESGM.2014.6938779]
   Singh N, 2015, SIGNAL IMAGE VIDEO P, V9, P427, DOI 10.1007/s11760-013-0457-y
   Singh N, 2014, PATTERN RECOGN, V47, P1731, DOI 10.1016/j.patcog.2013.11.012
   Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416
   Sugano Y, 2010, PROC CVPR IEEE, P2667, DOI 10.1109/CVPR.2010.5539984
   Sun XL, 2015, OPTIK, V126, P942, DOI 10.1016/j.ijleo.2015.03.004
   Tang C, 2016, MULTIMED TOOLS APPL, V75, P6963, DOI 10.1007/s11042-015-2622-5
   Tang YL, 2016, VISUAL COMPUT, V32, P111, DOI 10.1007/s00371-014-1059-6
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Tong N, 2014, IEEE SIGNAL PROC LET, V21, P1035, DOI 10.1109/LSP.2014.2323407
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511
   Tsai W. - H, 1995, DOCUMENT IMAGE ANAL, P44
   Valenti R, 2009, IEEE I CONF COMP VIS, P2185, DOI 10.1109/ICCV.2009.5459240
   Van Rijsbergen C. J., 1979, Information Retrieval, V2nd
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Wang HP, 2015, CHIN CONT DECIS CONF, P2519, DOI 10.1109/CCDC.2015.7162345
   Wang WN, 2014, SIGNAL PROCESS-IMAGE, V29, P424, DOI 10.1016/j.image.2014.01.004
   Wang ZC, 2016, APPL INTELL, V45, P1, DOI 10.1007/s10489-015-0739-x
   WHITE JM, 1983, IBM J RES DEV, V27, P400, DOI 10.1147/rd.274.0400
   WU AY, 1982, IEEE T PATTERN ANAL, V4, P90, DOI 10.1109/TPAMI.1982.4767203
   Xiang D, 2017, MULTIMED TOOLS APPL, V76, P6209, DOI 10.1007/s11042-016-3310-9
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Xu LF, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-31
   Xu X, 2015, IEEE IMAGE PROC, P3126, DOI 10.1109/ICIP.2015.7351379
   Yan XY, 2014, IEEE IMAGE PROC, P1170, DOI 10.1109/ICIP.2014.7025233
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang XY, 2015, PATTERN RECOGN, V48, P3093, DOI 10.1016/j.patcog.2014.12.017
   YASUDA Y, 1980, P IEEE, V68, P874, DOI 10.1109/PROC.1980.11753
   Yeh MC, 2014, PATTERN RECOGN LETT, V46, P60, DOI 10.1016/j.patrec.2014.05.006
   Yijun Li, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2798, DOI 10.1109/ICASSP.2014.6854110
   Yu H., 2010, PROC ANN ACM INT C M, P891
   Zhang DZ, 2014, BIOL INSPIR COGN ARC, V9, P1, DOI 10.1016/j.bica.2014.06.005
   Zhang JM, 2016, PROC CVPR IEEE, P5733, DOI 10.1109/CVPR.2016.618
   Zhang JX, 2017, PATTERN RECOGN, V64, P39, DOI 10.1016/j.patcog.2016.10.025
   Zhang LH, 2015, IEEE SIGNAL PROC LET, V22, P1396, DOI 10.1109/LSP.2014.2377216
   Zhang L, 2013, IEEE IMAGE PROC, P171, DOI 10.1109/ICIP.2013.6738036
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang MM, 2014, OPTIK, V125, P1469, DOI 10.1016/j.ijleo.2013.09.007
   Zhang Q, 2017, NEUROCOMPUTING, V243, P35, DOI 10.1016/j.neucom.2017.02.064
   Zhang Q, 2016, J INF SCI ENG, V32, P1435
   Zhang WJ, 2016, VISUAL COMPUT, V32, P275, DOI 10.1007/s00371-015-1065-3
   Zhang YY, 2014, OPTIK, V125, P7222, DOI 10.1016/j.ijleo.2014.07.132
   Zhang YJ, 1996, PATTERN RECOGN, V29, P1335, DOI 10.1016/0031-3203(95)00169-7
   Zhao HD, 2015, MULTIMEDIA SYST, V21, P159, DOI 10.1007/s00530-014-0373-1
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhou L, 2015, INT CONF INFO SCI, P108, DOI 10.1109/ICIST.2015.7288950
   Zhou L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2438546
   Zhou Q, 2015, INT CONF ACOUST SPEE, P1463, DOI 10.1109/ICASSP.2015.7178213
   Zhu L, 2014, IEEE T IMAGE PROCESS, V23, P5094, DOI 10.1109/TIP.2014.2361024
   Zou BJ, 2016, MULTIMEDIA SYST, V22, P245, DOI 10.1007/s00530-014-0449-y
   Zou WB, 2015, IEEE T IMAGE PROCESS, V24, P3858, DOI 10.1109/TIP.2015.2456497
   Zou WB, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.78
NR 218
TC 8
Z9 10
U1 1
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19139
EP 19170
DI 10.1007/s11042-017-5329-y
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500012
DA 2024-07-18
ER

PT J
AU Zhao, Y
   Xu, J
   Xu, F
   Song, SJ
   Zhang, YL
AF Zhao, Yong
   Xu, Jing
   Xu, Fei
   Song, Shiji
   Zhang, Yuli
TI Real-time localization in wireless sensor network with multimedia
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor; Real-time location; Historical data analysis; Mobile
   anchor node
AB Node localization is one of the most important supporting technologies in wireless sensor networks. In the practical application, the wireless sensor network nodes need to be positioned in real time, in order to monitor their location. This paper presents an accurate and real-time localization method based on historical data analysis (HDA-RTL). We analyze the behavior characteristics of the node's historical position coordinates, and, according to the different analysis results, propose two positioning methods: real-time localization based on neighbor node location analysis and real-time positioning based on mobile anchor node. Then, we do the analysis through the simulation experiment. The simulation results show that the proposed method has significant advantages in positioning accuracy, success rate and power consumption.
C1 [Zhao, Yong] Beijing Univ Technol, Dept Comp Sci, Beijing 100124, Peoples R China.
   [Xu, Jing; Song, Shiji; Zhang, Yuli] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
   [Xu, Fei] Chinese Acad Sci, Inst Informat Engn, Beijing 100093, Peoples R China.
C3 Beijing University of Technology; Tsinghua University; Chinese Academy
   of Sciences; Institute of Information Engineering, CAS
RP Zhao, Y (corresponding author), Beijing Univ Technol, Dept Comp Sci, Beijing 100124, Peoples R China.
EM zhaoyong1778@126.com
RI Zhang, Yuli/KIL-4487-2024; Zhang, Yuli/B-5886-2018
OI Zhang, Yuli/0000-0002-9382-6308
FU National key research and development plan project [2016YFB0800204]
FX This project is partially supported by National key research and
   development plan project (2016YFB0800204)
CR Akyildiz IF, 2002, COMPUT NETW, V38, P393, DOI 10.1016/S1389-1286(01)00302-4
   [Anonymous], 2016, INT J DISTRIB SENS N
   [Anonymous], 2010, Network Protocols and Algorithms, DOI DOI 10.5296/NPA.V2I1.279
   [Anonymous], 2010, WIRELESS SENSOR NETW
   Arvidson RE, 2004, SCIENCE, V306, P1730, DOI 10.1126/science.1104211
   Bao XR, 2010, I C WIREL COMM NETW
   Chaurasia Sunita, 2011, Proceedings of the 2011 13th International Conference on Advanced Communication Technology (ICACT). Smart Service Innovation through Mobile Interactivity, P190
   Chowdhury TJS, 2016, COMPUT NETW, V110, P284, DOI 10.1016/j.comnet.2016.10.006
   Han GJ, 2016, IEEE COMMUN SURV TUT, V18, P2220, DOI 10.1109/COMST.2016.2544751
   Han GJ, 2013, TELECOMMUN SYST, V52, P2419, DOI 10.1007/s11235-011-9564-7
   He T., 2003, PROC 9 ANN INT C MOB, P81, DOI DOI 10.1145/938985.938995
   Jiang JR, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/529489
   Jianqiao Xiong, 2014, 2014 7th International Symposium on Computational Intelligence and Design (ISCID), P276, DOI 10.1109/ISCID.2014.246
   Jiuqiang Xu, 2010, Wireless Sensor Network, V2, P606, DOI 10.4236/wsn.2010.28072
   Khan H, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION, COMPUTING AND DIGITAL SYSTEMS (C-CODE), P144, DOI 10.1109/C-CODE.2017.7918918
   Mao GQ, 2007, COMPUT NETW, V51, P2529, DOI 10.1016/j.comnet.2006.11.018
   Mistry HP, 2015, INT C ADV COMPUT COM, P647, DOI 10.1109/ACCT.2015.105
   Ou CH, 2013, IEEE SENS J, V13, P466, DOI 10.1109/JSEN.2012.2218100
   [彭宇 Peng Yu], 2011, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V25, P389
   Ran Q, 2016, IEEE INT CONF ELECTR, P10, DOI 10.1109/ICEIEC.2016.7589676
   Rawat P, 2014, J SUPERCOMPUT, V68, P1, DOI 10.1007/s11227-013-1021-9
   Tan G, 2013, ACM T SENSOR NETWORK, V10, DOI 10.1145/2529976
   Tree S., 2014, SELF, V1, pC0
   Wang G, 2011, IEEE T WIREL COMMUN, V10, P1389, DOI 10.1109/TWC.2011.031611.101585
   Wen CY, 2010, SENSORS-BASEL, V10, P9742, DOI 10.3390/s101109742
   Zhu Guo-hui, 2015, Systems Engineering and Electronics, V37, P498, DOI 10.3969/j.issn.1001-506X.2015.03.04
NR 26
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21791
EP 21801
DI 10.1007/s11042-017-5506-z
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300064
DA 2024-07-18
ER

PT J
AU Ma, S
   Zhao, XF
   Guan, QX
   Xu, ZJ
   Ma, Y
AF Ma, Sai
   Zhao, Xianfeng
   Guan, Qingxiao
   Xu, Zhoujun
   Ma, Yi
TI A Priori knowledge based secure payload estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Secure payload estimation(SPE);
   Detection-error-rate-limited sender(PELS); A Priori knowledge
ID STEGANOGRAPHY; STEGANALYSIS
AB Many contemporary steganographic schemes aim to embed fixed-length secret message in the cover while minimizing the stego distortion. However, in some cases, the secret message sender requires to embed a variable-length secret payload within his expected stego security. This kind of problem is named as secure payload estimation (SPE). In this paper, we propose a practical SPE approach for individual cover. The stego security metric we adopt here is the detection error rate of steganalyzer (P-E ). Our method is based on a priori knowledge functions, which are two kinds of functions to be determined before the estimation. The first function is the relation function of detection error rate and stego distortion (P-E - D function). The second function reflects the relationship between stego distortion and payload rate (D - alpha) of the chosen cover. The P-E - D is the general knowledge, which is calculated from image library. On the other hand, D - alpha is for specific cover, which is needed to be determined on site. The estimating procedure is as follows: firstly, the sender solves the distortion D under his expected P-E via P-E - D, and then calculates the corresponding secure payload alpha via D - alpha of the cover. For on-site operations, the most time-consuming part is calculating D - alpha function for cover image, which costs 1 time of STC coding. Besides this, the rest on-site operations are solving single-variable formulas, which can be easily tackled. Our approach is an efficient and practical solution for SPE problem.
C1 [Ma, Sai; Zhao, Xianfeng; Guan, Qingxiao] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Ma, Sai; Zhao, Xianfeng; Guan, Qingxiao] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100093, Peoples R China.
   [Xu, Zhoujun; Ma, Yi] Beijing Informat Technol Inst, Beijing 100094, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Zhao, XF (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.; Zhao, XF (corresponding author), Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100093, Peoples R China.
EM masai@iie.ac.cn; zhaoxianfeng@iie.ac.cn; guanqingxiao@iie.ac.cn;
   pl_xzj@uestc.edu.cn; mayi_5501@126.com
RI Zhao, Xianfeng/AAE-7278-2021
OI Zhao, Xianfeng/0000-0002-5617-8399
FU NSFC [U1636102, U1536105]; National Key Technology RD Program
   [2014BAH41B01, 2016YFB0801003]; Strategic Priority Research Program of
   CAS [XDA06030600]
FX This work was supported by the NSFC under U1636102 and U1536105,
   National Key Technology R&D Program under 2014BAH41B01 and
   2016YFB0801003, and Strategic Priority Research Program of CAS under
   XDA06030600.
CR [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], ACM WORKSH INF HID M
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], P 2 INT WORKSH DIG W
   [Anonymous], 2011, P 13 INF HID C PRAG
   Chen YH, 2016, MULTIMED TOOLS APPL, V75, P13679, DOI 10.1007/s11042-015-2825-9
   Cheng CJ, 2014, J DISP TECHNOL, V10, P263, DOI 10.1109/JDT.2013.2295619
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Fridrich J., 2007, P SOC PHOTO-OPT INS, V6505, P02
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Huang HC, 2011, SENSORS-BASEL, V11, P9717, DOI 10.3390/s111009717
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Provos N, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 10TH USENIX SECURITY SYMPOSIUM, P323
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Wazirali R, 2017, J INFORM HIDING MULT, V8, P404
   Zhang LY, 2015, IEEE I C EMBED SOFTW, P1274, DOI 10.1109/HPCC-CSS-ICESS.2015.62
   Zhang ZW., 2016, J INFORM HIDING MULT, V7, P530
NR 25
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17889
EP 17911
DI 10.1007/s11042-017-4955-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900018
DA 2024-07-18
ER

PT J
AU Wei, Y
   Zhang, WM
   Li, WH
   Yu, NH
   Sun, X
AF Wei, Yao
   Zhang, Weiming
   Li, Weihai
   Yu, Nenghai
   Sun, Xi
TI Which gray level should be given the smallest cost for adaptive
   steganography?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Distortion function; Gamma encoding; Gray level
ID EXPANSION
AB Currently, the most successful approach to steganography in digital image is distortion-minimization framework, which reduces the steganographers' work to the design of distortion function with the aid of practical coding schemes. Previous distortion functions for spatial images are all position dependent, in which cost is determined by the relationships between neighboring pixels. Noticing that Gamma encoding is usually involved in image preprocessing in many cameras or image processing software, which causes some pixels to change greatly, we believe these pixels sensitive to Gamma encoding are more suitable for modification, because they are hard to model due to their large variations. Inspired by this idea, we proposed a position independent scheme, where the cost is only linked to the gray level. The effectiveness of our work is verified by extensive experimental results, which reveal an interesting relationship between steganographic costs and gray levels. The speed test shows that the speed of proposed scheme is very high thus suitable to be used in the real-time applications.
C1 [Wei, Yao; Sun, Xi] Univ Sci & Technol China, Hefei, Anhui, Peoples R China.
   [Zhang, Weiming; Li, Weihai] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei, Anhui, Peoples R China.
   [Yu, Nenghai] Univ Sci & Technol China, Informat Proc Ctr, Hefei, Anhui, Peoples R China.
   [Wei, Yao; Li, Weihai; Yu, Nenghai; Sun, Xi] Chinese Acad Sci, Key Lab Electromagnet Space Informat, Hefei, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS; Chinese Academy of Sciences; University of
   Science & Technology of China, CAS; Chinese Academy of Sciences
RP Zhang, WM (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei, Anhui, Peoples R China.
EM zhangwm@ustc.edu.cn
FU Natural Science Foundation of China [U1636201, 61572452]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant U1636201, 61572452.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], 2015, P 3 ACM WORKSH INF H
   [Anonymous], 2011, P 13 INF HID C PRAG
   Bas P, 2007, BOWS2 ORIGINAL
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Fridrich J, 2007, ELECT IMAGING 2007
   Fridrich J., 2009, INFORM HIDING
   Fridrich J, 2013, INT CONF ACOUST SPEE, P2949, DOI 10.1109/ICASSP.2013.6638198
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Guo LJ, 2012, IEEE INT WORKS INFOR, P169, DOI 10.1109/WIFS.2012.6412644
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Huang FJ, 2012, IEEE T INF FOREN SEC, V7, P1181, DOI 10.1109/TIFS.2012.2198213
   Kodovsky J, 2010, IS T SPIE ELECT IMAG
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Li B, 2014, IEEE T INF FOREN SEC, V9, P1264, DOI 10.1109/TIFS.2014.2326954
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Pevny T, 2008, LECT NOTES COMPUT SC, V5284, P251
   Poynton C, 1998, P SOC PHOTO-OPT INS, V3299, P232, DOI 10.1117/12.320126
   Qin C, 2016, SIGNAL PROCESS, V129, P48, DOI 10.1016/j.sigpro.2016.05.032
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Sedighi V, 2015, IS T SPIE ELECT IMAG
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Zhang W, 2016, IEEE T CIRCUITS SYST
NR 32
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17861
EP 17874
DI 10.1007/s11042-017-4565-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900016
DA 2024-07-18
ER

PT J
AU Gazdar, A
   Alkwai, L
AF Gazdar, Achraf
   Alkwai, Lamia
TI Toward a full peer to peer MPEG-DASH compliant streaming system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive streaming; BitTorrent; MPEG-DASH; Peer-to-peer
AB MPEG-DASH standard has been proposed to standardize the proprietary solutions proposed to stream multi-qualities encoded video/audio over HTTP. Although MPEG-DASH relies on the client/server communication model, in this paper we show that it could be also used in a full P2P streaming system after making the necessary changes in the MPEG-DASH standard as well as in the main modules of the P2P streaming system. The main changes are made in the Media Presentation Description (MPD) file to support the P2P network bootstrapping mechanism (peers selection algorithm) as well as in the pieces selection algorithm to make the peer quality adaptation enabled as imposed by the MPEG-DASH. We choose the famous BitTorrent protocol as an example to implement the required changes. Extensive simulations have been conducted under the OMNeT + + simulator. The obtained results in terms of the average missed segments and the average waiting time on playback are reasonable with regards to 1) the BitTorrent known issue in the streaming context, to 2) the hard conditions we considered in our simulation set-up and 3) compared to some representative related works. This results show that MPEG-DASH could be easily supported by P2P streaming systems.
C1 [Gazdar, Achraf] King Saud Univ, Software Engn Dept, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Alkwai, Lamia] King Abdulaziz City Sci & Technol, Natl Ctr Computat Technol & Appl Math, Riyadh, Saudi Arabia.
C3 King Saud University; King Abdulaziz City for Science & Technology
RP Gazdar, A (corresponding author), King Saud Univ, Software Engn Dept, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
EM agazdar@ksu.edu.sa; lalkwai@kacst.edu.sa
RI Gazdar, Achraf/GYV-3586-2022
OI Gazdar, Achraf/0000-0002-3646-6959
FU Research Center of College of Computer and Information Sciences, King
   Saud University
FX This work was supported by the Research Center of College of Computer
   and Information Sciences, King Saud University. The authors are grateful
   for this support.
CR Abboud O., 2011, Proceedings of the second annual ACM conference on Multimedia systems, MMSys '11, P223, DOI DOI 10.1145/1943552.1943582
   Abboud O, 2009, LECT NOTES COMPUT SC, V5842, P41, DOI 10.1007/978-3-642-04994-1_4
   [Anonymous], 2011, P 19 ACM INT C MULT
   [Anonymous], RFC3550 IETF
   Baumgart I, 2007, 2007 IEEE GLOBAL INTERNET SYMPOSIUM, P79, DOI 10.1109/GI.2007.4301435
   Baumgart Ingmar., 2011, P 4 INT ICST C SIMUL, P402, DOI DOI 10.4108/ICST.SIMUTOOLS.2011.245526
   Detti A, 2013, 2013 IEEE 24TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P3583, DOI 10.1109/PIMRC.2013.6666771
   Do TT, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1467, DOI 10.1109/ICC.2004.1312755
   Fecheyr-Lippens A., 2010, Internet Citation, P1
   Hammami C, 2015, KSII T INTERNET INF, V9, P1035, DOI 10.3837/tiis.2015.03.011
   INET-Authors, 2016, DASH BITT IMPL IN
   Jonsson KV, 2009, P 2 INT C SIM TOOLS, P70
   Katsaros K., 2009, Modeling, Analysis Simulation of Computer and Telecommunication Systems, P1
   Klusch M., 2014, INT C MOBILE UBIQUIT, P277
   Lederer S., 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P161, DOI 10.1109/PV.2012.6229730
   Lederer Stefan., 2013, MULTIMEDIA EXPO ICME, P1
   Li B., 2008, INFOCOM 2008, P1031, DOI [10.1109/INFOCOM.2008.157., DOI 10.1109/INFOCOM.2008.157]
   Liang C, 2009, IEEE T MULTIMEDIA, V11, P348, DOI 10.1109/TMM.2009.2012909
   Mason M, 2014, BITTORRENT BLOG
   Memon SA, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P413, DOI 10.1109/CTS.2014.6867597
   OpenSim, 2008, OPENSIM IN FRAM OMN
   OpenSim, 2015, OPENSIM
   OVERSIM-Authors, 2016, DASH BITT IMPL OV
   Pantos R, 2015, HTTP LIVE STREAMING
   Ramzan N, 2012, SIGNAL PROCESS-IMAGE, V27, P401, DOI 10.1016/j.image.2012.02.004
   Rejaie R., 2003, Proceedings of ACM International Workshop on Network and Operating Systems Support for Digital Audio and Video (NOSSDAV), P153
   Roverso R, 2012, IEEE INT CONF PEER, P65
   Roverso R, 2012, LECT NOTES COMPUT SC, V7290, P29, DOI 10.1007/978-3-642-30054-7_3
   S4, 2015, 26234 3GPP
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Vlavianos Aggelos., 2006, Proceedings IEEE INFOCOM 2006. 25TH IEEE International Conference on Computer Communications, P1
NR 31
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15829
EP 15849
DI 10.1007/s11042-017-5157-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200060
DA 2024-07-18
ER

PT J
AU Jia, S
   Zhang, Y
AF Jia, Sen
   Zhang, Yang
TI Saliency-based deep convolutional neural network for no-reference image
   quality assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NR-IQA; CNN; Saliency map
ID NATURAL SCENE STATISTICS
AB In this paper, we proposed a novel method for No-Reference Image Quality Assessment (NR-IQA) by combining deep Convolutional Neural Network (CNN) with saliency map. We first investigate the effect of depth of CNNs for NR-IQA by comparing our proposed ten-layer Deep CNN (DCNN) for NR-IQA with the state-of-the-art CNN architecture proposed by Kang et al. (2014). Our results show that the DCNN architecture can deliver a higher accuracy on the LIVE dataset. To mimic human vision, we introduce saliency maps combining with CNN to propose a Saliency-based DCNN (SDCNN) framework for NR-IQA. We compute a saliency map for each image and both the map and the image are split into small patches. Each image patch is assigned with a patch importance value based on its saliency patch. A set of Salient Image Patches (SIPs) are selected according to their saliency and we only apply the model on those SIPs to predict the quality score for the whole image. Our experimental results show that the SDCNN framework is superior to other state-of-the-art approaches on the widely used LIVE dataset. The TID2008 and the CISQ image quality datasets are utilised to report cross-dataset results. The results indicate that our proposed SDCNN can generalise well on other datasets.
C1 [Jia, Sen] Univ Bristol, Intelligent Syst Lab, Bristol, Avon, England.
   [Zhang, Yang] Univ Bristol, Bristol Vis Inst, Bristol, Avon, England.
C3 University of Bristol; University of Bristol
RP Jia, S (corresponding author), Univ Bristol, Intelligent Syst Lab, Bristol, Avon, England.
EM sen.jia@bristol.ac.uk; yang.zhang@bristol.ac.uk
OI Jia, Sen/0000-0001-7104-034X
CR [Anonymous], PRESS MONOGRAPH SERI
   [Anonymous], 2014, VERY DEEP CONVOLUTIO
   [Anonymous], PATTERN RECOGN LETT
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2011, IEEE INT C COMP VIS
   Clevert D.A, 2015, 4 INT C LEARN REPR I
   Feng TP, 2016, INT J ADV ROBOT SYST, V13, DOI 10.1177/1729881416669486
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jia S, 2016, INT CONF DAT MIN WOR, P462, DOI [10.1109/ICDMW.2016.0072, 10.1109/ICDMW.2016.45]
   Jia S, 2016, LECT NOTES COMPUT SC, V9730, P765, DOI 10.1007/978-3-319-41501-7_85
   Kang L, 2015, IEEE IMAGE PROC, P2791, DOI 10.1109/ICIP.2015.7351311
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li J, 2016, SIGNAL IMAGE VIDEO P, V10, P609, DOI 10.1007/s11760-015-0784-2
   Li YM, 2015, NEUROCOMPUTING, V154, P94, DOI 10.1016/j.neucom.2014.12.015
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang ZJ, 2011, IEEE SIGNAL PROC MAG, V28, P2, DOI 10.1109/MSP.2011.940297
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang P, 2015, PROC CVPR IEEE, P2394, DOI 10.1109/CVPR.2015.7298853
   Zhang W, 2016, IEEE T NEUR NET LEAR, V27, P1266, DOI 10.1109/TNNLS.2015.2461603
   Zhang Y, 2013, IEEE IMAGE PROC, P2284, DOI 10.1109/ICIP.2013.6738471
NR 29
TC 51
Z9 51
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14859
EP 14872
DI 10.1007/s11042-017-5070-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200018
OA hybrid
DA 2024-07-18
ER

PT J
AU Yang, HY
   Niu, Y
   Jiao, LX
   Liu, YN
   Wang, XY
   Zhou, ZL
AF Yang, Hong-ying
   Niu, Ying
   Jiao, Li-xian
   Liu, Yu-nan
   Wang, Xiang-yang
   Zhou, Zhi-li
TI Robust copy-move forgery detection based on multi-granularity
   Superpixels matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery detection; Multi-granularity superpixel; Quaternion
   exponent moments; SIFER; E2LSH
AB In this paper, we propose a new multi-granularity superpixels matching based algorithm for the accurate detection and localization of copy-move forgeries, which integrated the advantages of keypoint-based and block-based forgery detection approaches. Firstly, we divide the original tempted image into non-overlapping and irregular coarse-granularity superpixels, and the stable image keypoints are extracted from each coarse-granularity superpixel. Secondly, the superpixel features, which is quaternion exponent moments magnitudes, are extracted from each coarse-granularity superpixel, and we find the matching coarse-granularity superpixels (suspected forgery region pairs) rapidly using the Exact Euclidean Locality Sensitive Hashing (E2LSH). Thirdly, the suspected forgery region pairs are further segmented into fine-granularity superpixels, and the matching keypoints within the suspected forgery region pairs are replaced with the fine-granularity superpixels. Finally, the neighboring fine-granularity superpixels are merged, and we obtain the detected forgery regions through morphological operation. Compared with the state-of-the-art approaches, extensive experimental results, conducted on the public databases available online, demonstrate the good performance of our proposed algorithm even under a variety of challenging conditions.
C1 [Yang, Hong-ying; Niu, Ying; Jiao, Li-xian; Liu, Yu-nan; Wang, Xiang-yang] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Zhou, Zhi-li] NUIST, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
   [Zhou, Zhi-li] NUIST, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Liaoning Normal University; Nanjing University of Information Science &
   Technology; Nanjing University of Information Science & Technology
RP Yang, HY; Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM yhy_65@126.com; wxy37@126.com
RI Liu, Yunan/JGM-3801-2023; Yang, Jing/JFK-4046-2023; Liu,
   Yunan/GXH-9776-2022
OI Yang, Jing/0009-0004-8274-9863; 
FU National Natural Science Foundation of China [61472171, 61272416];
   Natural Science Foundation of Liaoning Province of China [201602463];
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions; Jiangsu Collaborative Innovation Center on Atmospheric
   Environment and Equipment Technology
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61472171 & 61272416, the Natural Science
   Foundation of Liaoning Province of China under Grant No. 201602463, A
   Project Funded by the Priority Academic Program Development of Jiangsu
   Higher Education Institutions, and Jiangsu Collaborative Innovation
   Center on Atmospheric Environment and Equipment Technology.
CR Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Chen BJ, 2017, NEUROCOMPUTING, V266, P293, DOI 10.1016/j.neucom.2017.05.047
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Costanzo A, 2014, IEEE T INF FOREN SEC, V9, P1450, DOI 10.1109/TIFS.2014.2337654
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559
   Jiang YJ, 2011, EXPONENT MOMENTS ITS
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Lee JC, 2015, J VIS COMMUN IMAGE R, V31, P320, DOI 10.1016/j.jvcir.2015.07.007
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li YL, 2015, NEUROCOMPUTING, V149, P736, DOI 10.1016/j.neucom.2014.08.003
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Liu MY, 2011, PROC CVPR IEEE
   Mainali P, 2013, INT J COMPUT VISION, V104, P172, DOI 10.1007/s11263-013-0622-3
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Pandey RC, 2016, DIGIT INVEST, V19, P1, DOI 10.1016/j.diin.2016.08.002
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Wu QM, 2011, IEEE SIGNAL PROC LET, V18, P559, DOI 10.1109/LSP.2011.2163507
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xiang-yang W, PATTERN ANAL APPL, DOI [10.1007/s10044-016-0588-1, DOI 10.1007/S10044-016-0588-1]
   Yu LY, 2016, MULTIMED TOOLS APPL, V75, P1159, DOI 10.1007/s11042-014-2362-y
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zhang RJ, 2014, NEUROCOMPUTING, V124, P105, DOI 10.1016/j.neucom.2013.07.027
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zhou ZL, 2016, IEICE T INF SYST, VE99D, P1531, DOI 10.1587/transinf.2015EDP7341
   Zong TR, 2015, IEEE T CIRC SYST VID, V25, P717, DOI 10.1109/TCSVT.2014.2363743
NR 35
TC 9
Z9 11
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13615
EP 13641
DI 10.1007/s11042-017-4978-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900025
DA 2024-07-18
ER

PT J
AU Alherbawi, N
   Shukur, Z
   Sulaiman, R
AF Alherbawi, Nadeem
   Shukur, Zarina
   Sulaiman, Rossilawati
TI JPEG image classification in digital forensic via DCT coefficient
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital investigation; Data carving; JPEG image forgery; DCT coefficient
   analysis; JPEG image classification
AB From the digital forensics point of view, image forgery is considered as evidence that could provide a major breakthrough in the investigation process. Additionally, the development of storage device technologies has increased storage space significantly. Thus a digital investigator can be overwhelmed by the amount of data on storage devices that needs to be analysed. In this paper, we propose a model for classifying bulk JPEG images produced by the data carving process or other means into three different classes to solve the problem of identifying forgery quickly and effectively. The first class is JPEG images that contain errors or corrupted data, the second class is JPEG images that contain forged regions, and the third is JPEG images that have no signs of corruption or forgery. To test the proposed model, some experiments were conducted on our own dataset in addition to CASIA V2 image forgery dataset. The experiments covered different types of forgery technique. The results yielded around 88% accuracy rate in the classification process using five different machine learning methods on CASIA V2 dataset. It can be concluded that the proposed model can help investigators to automatically classify JPEG images, which reduce the time needed in the overall digital investigation process.
C1 [Alherbawi, Nadeem; Shukur, Zarina; Sulaiman, Rossilawati] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Res Ctr Software Technol & Management, Bangi 43600, Selangor, Malaysia.
C3 Universiti Kebangsaan Malaysia
RP Alherbawi, N (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Res Ctr Software Technol & Management, Bangi 43600, Selangor, Malaysia.
EM nalherbawi@gmail.com
OI Sulaiman, Rossilawati/0000-0002-4049-5939
CR Alherbawi N, 2013, PROC TECH, V11, P86, DOI 10.1016/j.protcy.2013.12.165
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bianchi T, 2011, INT CONF ACOUST SPEE, P2444
   Chen Y, 2013, J VIS COMMUN IMAGE R, V24, P857, DOI 10.1016/j.jvcir.2013.06.005
   Garfinkel SL, 2007, DIGIT INVEST, V4, pS2, DOI 10.1016/j.diin.2007.06.017
   Garfinkel SL, 2006, DIGIT INVESTIG, pS71, DOI 10.1016/j.diin.2006.06.007
   Garfinkel SL, 2013, COMPUT SECUR, V32, P56, DOI 10.1016/j.cose.2012.09.011
   Garfinkel SL, 2010, DIGIT INVEST, V7, pS64, DOI 10.1016/j.diin.2010.05.009
   Haines RF, 1992, NASA TECHNICAL DOCUM
   He JF, 2006, LECT NOTES COMPUT SC, V3953, P423
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Miano J., 1999, Compressed image file formats: Jpeg, png, gif, xbm, bmp
   Nadeem A., 2017, J ENG APPL SCI, P104
   Pan XZ, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 4, P79, DOI 10.1109/ICACC.2010.5486869
   Popescu A, 2004, COMPUTER SCI TECHNIC
   Popescu A. C., 2005, STAT TOOLS DIGITAL F, P128
   RICHARD GG, 2007, IFIP INT C DIG FOR J, P217
   Sahani A, 2014, IMAGE, P7551
   Vaida F, 2005, STAT SINICA, V15, P831
   Wang Y, 2010, SIGNAL PROCESS-IMAGE, V25, P577, DOI 10.1016/j.image.2010.06.003
NR 20
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12805
EP 12835
DI 10.1007/s11042-017-4915-3
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100051
DA 2024-07-18
ER

PT J
AU Fan, YY
   Liang, QZ
AF Fan, Yuanyuan
   Liang, Qingzhong
TI An improved method for detection of the pedestrian flow based on RFID
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian detection; RFID; Coverage; Public safety; Emergency
AB The security of public places has been greatly concerned by the government and organizations in recent decades. Detecting the crowd flow in public places can help alerting the congestion of the channel immediately and making an immediate evacuation policy to prevent the occurrence of extrusion stampede. However, the common detection techniques require special additional hardware components that suffer from too many factors. This paper proposed a method of crowd flow detecting based on RFID by analyzing the factors affecting the RFID link state. The system composed of the RFID tag arrays and the reader which detects the pedestrian flow according to the counts and the RSSI value of reading RFID tag arrays. With the evaluation in different scenarios, the coverage and moving status of the crowd can be verified.
C1 [Fan, Yuanyuan; Liang, Qingzhong] China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Sch Comp Sci, Wuhan 430074, Hubei, Peoples R China.
C3 China University of Geosciences
RP Fan, YY (corresponding author), China Univ Geosci, Hubei Key Lab Intelligent Geoinformat Proc, Sch Comp Sci, Wuhan 430074, Hubei, Peoples R China.
EM yyfan@cug.edu.cn; qzliang@cug.edu.cn
FU NSF of China [61673354, 61672474, 61402425, 61272470, 61305087,
   61440060, 61501412]; Provincial Natural Science Foundation of Hubei
   [2015CFA065]; Open Research Project of The Hubei Key Laboratory of
   Intelligent Geo-Information Processing [KLIGIP201603, KLIGIP201607];
   Hubei Key Laboratory of Intelligent Geo-Information Processing, China
   University of Geosciences, Wuhan, China [430074]
FX This research was supported by the NSF of China (Grant No. 61673354,
   61672474, 61402425, 61272470, 61305087, 61440060, 61501412), the
   Provincial Natural Science Foundation of Hubei (Grant No. 2015CFA065).
   This paper has been subjected to Hubei Key Laboratory of Intelligent
   Geo-Information Processing, China University of Geosciences, Wuhan
   430074, China. It was also supported by Open Research Project of The
   Hubei Key Laboratory of Intelligent Geo-Information Processing
   (KLIGIP201603 and KLIGIP201607).
CR [Anonymous], 2014, 10 YEARS PEDESTRIAN
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Hurney P, 2015, IET INTELL TRANSP SY, V9, P824, DOI 10.1049/iet-its.2014.0236
   Leibe B, 2005, PROC CVPR IEEE, P878
   Liu Q, 2015, PROCEEDINGS OF 2015 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2015), P673, DOI 10.1109/ICCSNT.2015.7490834
   Ortakci Y, 2015, ISPRS ANN PHOTO REM, VII-2, P223, DOI 10.5194/isprsannals-II-2-W2-223-2015
   Schauer L., 2014, INT C MOB UB SYST CO
   Shi D. Y., 2012, J WUHAN U TECHNOLOGY
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Tewari A, 2017, J SUPERCOMPUT, V73, P1085, DOI 10.1007/s11227-016-1849-x
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Ye Y, 2013, IEEE ACCESS, V1, P646, DOI 10.1109/ACCESS.2013.2282613
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   ZIEGLER HG, 2016, SMARTGR P 5 INT C, P55, DOI DOI 10.5220/0005761300550062
NR 17
TC 3
Z9 3
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11425
EP 11438
DI 10.1007/s11042-017-5303-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900057
DA 2024-07-18
ER

PT J
AU Fei, MJ
   Jiang, W
   Mao, WJ
AF Fei, Mengjuan
   Jiang, Wei
   Mao, Weijie
TI A novel compact yet rich key frame creation method for compressed video
   summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Key frame creation; Optimal selection; Importance ranking; KNN matting
   and stitching; Compressed video summarization
ID SYNOPSIS
AB Video summarization has great potential to enable rapid browsing and efficient video indexing in many applications. In this study, we propose a novel compact yet rich key frame creation method for compressed video summarization. First, we directly extract DC coefficients of I frame from a compressed video stream, and DC-based mutual information is computed to segment the long video into shots. Then, we select shots with static background and moving object according to the intensity and range of motion vector in the video stream. Detecting moving object outliers in each selected shot, the optimal object set is then selected by importance ranking and solving an optimum programming problem. Finally, we conduct an improved KNN matting approach on the optimal object outliers to automatically and seamlessly splice these outliers to the final key frame as video summarization. Previous video summarization methods typically select one or more frames from the original video as the video summarization. However, these existing key frame representation approaches for video summarization eliminate the time axis and lose the dynamic aspect of the video scene. The proposed video summarization preserves both compactness and considerably richer information than previous video summaries. Experimental results indicate that the proposed key frame representation not only includes abundant semantics but also is natural, which satisfies user preferences.
C1 [Fei, Mengjuan; Jiang, Wei; Mao, Weijie] Zhejiang Univ, Inst Cyber Syst & Control, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Jiang, W (corresponding author), Zhejiang Univ, Inst Cyber Syst & Control, Hangzhou 310027, Zhejiang, Peoples R China.
EM feimengjuan@zju.edu.cn; jiangwei_zju@zju.edu.cn; wjmao@iipc.zju.edu.cn
RI jiang, wei/J-6317-2018
OI jiang, wei/0000-0002-9240-5851; Mao, Weijie/0000-0001-5791-1823
CR Aner-Wolf A, 2004, COMPUT VIS IMAGE UND, V95, P201, DOI 10.1016/j.cviu.2004.03.005
   [Anonymous], INT C COMP AN IM PAT
   [Anonymous], P IR C MACH VIS IM P
   [Anonymous], 2016, P THE 3 MULT INT SOC, DOI [DOI 10.1145/2955129.2955179, 10.1007/s00438-016-1266-0, DOI 10.1007/S00438-016-1266-0]
   [Anonymous], 17 INT C IEEE
   [Anonymous], J HUMAN KINETICS
   [Anonymous], P CVPR
   [Anonymous], P 2006 IEEE COMP SOC
   [Anonymous], 2000, P 2000 ACM WORKSH MU, DOI DOI 10.1145/357744.357942
   Cerneková Z, 2006, IEEE T CIRC SYST VID, V16, P82, DOI 10.1109/TCSVT.2005.856896
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Ejaz N, 2014, COMPUT ELECTR ENG, V40, P993, DOI 10.1016/j.compeleceng.2013.10.005
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gong BQ, 2014, ADV NEUR IN, V27
   Guan GL, 2013, IEEE T CIRC SYST VID, V23, P729, DOI 10.1109/TCSVT.2012.2214871
   Gygli M, 2015, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR.2015.7298928
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Ioannidis A, 2016, PATTERN RECOGN LETT, V72, P52, DOI 10.1016/j.patrec.2016.01.027
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Li L., 2011, Proc. 20th Int. Conf. World Wide Web, P287
   Lienhart R, 1997, COMMUN ACM, V40, P54, DOI 10.1145/265563.265572
   Liu YL, 2013, RADIOENGINEERING, V22, P1072
   Mei SH, 2015, PATTERN RECOGN, V48, P522, DOI 10.1016/j.patcog.2014.08.002
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Ngo CW, 2002, INT J COMPUT VISION, V50, P127, DOI 10.1023/A:1020341931699
   Nie YW, 2013, IEEE T VIS COMPUT GR, V19, P1664, DOI 10.1109/TVCG.2012.176
   Panagiotakis C, 2009, IEEE T CIRC SYST VID, V19, P447, DOI 10.1109/TCSVT.2009.2013517
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29
   Sandip M., 2012, INT J SCI RES PUBLIC, V2, P1
   Vila M, 2013, SIGNAL IMAGE VIDEO P, V7, P507, DOI 10.1007/s11760-013-0452-3
   Wang J, 2005, ACM T GRAPHIC, V24, P585, DOI 10.1145/1073204.1073233
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Zhao B, 2014, PROC CVPR IEEE, P2513, DOI 10.1109/CVPR.2014.322
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zhu XT, 2013, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2013.17
NR 40
TC 12
Z9 13
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11957
EP 11977
DI 10.1007/s11042-017-4843-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100016
DA 2024-07-18
ER

PT J
AU Irshad, A
   Sher, M
   Chaudhry, SA
   Kumari, S
   Sangaiah, AK
   Li, X
   Wu, F
AF Irshad, Azeem
   Sher, Muhammad
   Chaudhry, Shehzad Ashraf
   Kumari, Saru
   Sangaiah, Arun Kumar
   Li, Xiong
   Wu, Fan
TI A secure mutual authenticated key agreement of user with multiple
   servers for critical systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-server authentication; Information security; Cryptanalysis;
   Attacks; Cryptography
ID REMOTE PASSWORD AUTHENTICATION; SCHEME; EFFICIENT; PROTOCOL;
   VERIFICATION; LOGIC
AB Recent technological advances in almost all critical systems' domains have led to an explosive growth of multimedia big data. Those advances encompass the ever increasing innovative digital and remote mobile devices being operated on the users' end. Due to the openness of critical system, the service providers in such networks are facing security challenges to authenticate those mobile devices on the field, and delivering services. In this scenario, the Multi-server authentication (MSA) framework seems to be a promising solution that enables its subscribers to avail services from different servers without getting registered to each server individually. In last few years many MSA protocols depending on RC-Offline authentication during mutual authentication, have been presented. However, to date, there is no efficient MSA scheme to our knowledge that is free of all three weaknesses, simultaneously. That is, 1) free from storage of server-based parameters (public keys or other values) in smart card by registration authority, 2) free from the assumption of publishing of server-based public keys publicly and 3) free from a single secret sharing with all servers so that it could avoid server masquerading (insider) attack. Considering these limitations, we present a multi-server authentication protocol that withstands above drawbacks using lightweight cryptographic operations. The rationale of the proposed work was to present an efficient RC-Offline MSA scheme. Our scheme is also backed by formal security analysis based on GNY logic and automated security verification using ProVerif tool.
C1 [Irshad, Azeem; Sher, Muhammad; Chaudhry, Shehzad Ashraf] Int Islamic Univ, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
   [Kumari, Saru] Chaudhary Charan Singh Univ, Dept Math, Meerut 250004, Uttar Pradesh, India.
   [Sangaiah, Arun Kumar] VIT Univ, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
   [Li, Xiong] Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan, Peoples R China.
   [Wu, Fan] Huaqiao Univ, Xiamen Inst Technol, Xiamen, Peoples R China.
C3 International Islamic University, Pakistan; Chaudhary Charan Singh
   University; Vellore Institute of Technology (VIT); VIT Vellore; Hunan
   University of Science & Technology; Huaqiao University; Xiamen Institute
   of Technology
RP Kumari, S (corresponding author), Chaudhary Charan Singh Univ, Dept Math, Meerut 250004, Uttar Pradesh, India.
EM irshadazeem2@gmail.com; m.sher@iiu.edu.pk; shahzad@iiu.edu.pk;
   saryusiirohi@gmail.com; arunkumarsangaiah@gmail.com; lixiongzhq@163.com;
   conjurer1981@gmail.com
RI Kumari, Saru/K-2038-2019; Irshad, Azeem/E-7400-2010; Li,
   Xiong/K-7233-2012; Ramzan, Muhammad Sher/N-6832-2019; WU,
   FAN/GRX-1654-2022; Sangaiah, Arun Kumar/U-6785-2019; Chaudhry,
   Shehzad/Y-3430-2019; Ramzan, Muhammad/ABG-2396-2020; Wu, Fan/J-9583-2019
OI Kumari, Saru/0000-0003-4929-5383; Irshad, Azeem/0000-0002-1366-2834; Li,
   Xiong/0000-0001-6619-554X; Ramzan, Muhammad Sher/0000-0001-6752-0033;
   Sangaiah, Arun Kumar/0000-0002-0229-2460; Chaudhry,
   Shehzad/0000-0002-9321-6956; Wu, Fan/0000-0003-3615-1217
FU National Natural Science Foundation of China [61300220]; Scientific
   Research Fund of Hunan Provincial Education Department [16B089]
FX This work was supported by the National Natural Science Foundation of
   China under Grant Nos. 61300220, and the Scientific Research Fund of
   Hunan Provincial Education Department under Grant No. 16B089.
CR Abadi M, 2003, LECT NOTES COMPUT SC, V2694, P316
   Akhgar B, 2014, J AMB INTEL HUM COMP, V5, P93, DOI 10.1007/s12652-012-0136-9
   Alcaide A, 2011, LECT NOTES COMPUT SC, V6514, P108, DOI 10.1007/978-3-642-19348-4_9
   Amin R, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0351-y
   [Anonymous], 2012406 IACR CRYPT E
   [Anonymous], J SUPERCOMPUT
   [Anonymous], 2016, HDB APPL CRYPTOGRAPH
   [Anonymous], **NON-TRADITIONAL**
   [Anonymous], PLOS ONE
   [Anonymous], 2005, P 7 WORKSH MULT SEC
   [Anonymous], 2011365 IACR CRYPT E
   [Anonymous], SEC12000EC
   Bellare M, 2000, LECT NOTES COMPUT SC, V1807, P139
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   Cao X, 2006, IEEE COMMUN LETT, V10, P580, DOI 10.1109/LCOMM.2006.060343
   Chang CC, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P417, DOI 10.1109/CW.2004.17
   CHANG CC, 1991, IEE PROC-E, V138, P165, DOI 10.1049/ip-e.1991.0022
   Chaudhry SA, 2017, WIRELESS PERS COMMUN, V93, P311, DOI 10.1007/s11277-015-3139-y
   Chaudhry SA, 2016, MULTIMED TOOLS APPL, V75, P12705, DOI 10.1007/s11042-015-3194-0
   Chen CLP, 2014, INFORM SCIENCES, V275, P314, DOI 10.1016/j.ins.2014.01.015
   Chen CT, 2015, SECUR COMMUN NETW, V8, P1608, DOI 10.1002/sec.1109
   Chuang MC, 2014, EXPERT SYST APPL, V41, P1411, DOI 10.1016/j.eswa.2013.08.040
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Gong L., 1990, Proceedings. 1990 IEEE Computer Society Symposium on Research in Security and Privacy (Cat. No.90CH2884-5), P234, DOI 10.1109/RISP.1990.63854
   He DB, 2012, IEICE T COMMUN, VE95B, P3052, DOI 10.1587/transcom.E95.B.3052
   Hsiang HC, 2009, COMPUT STAND INTER, V31, P1118, DOI 10.1016/j.csi.2008.11.002
   Hsu CL, 2004, COMP STAND INTER, V26, P167, DOI 10.1016/s0920-5489(03)00094-1
   Hwang MS, 2000, IEEE T CONSUM ELECTR, V46, P28, DOI 10.1109/30.826377
   Irshad A, 2015, MULTIMED TOOLS APPL, V74, P3967, DOI 10.1007/s11042-013-1807-z
   Irshad A, 2014, SECUR COMMUN NETW, V7, P1210, DOI 10.1002/sec.834
   Jiang P, 2015, FRONT COMPUT SCI-CHI, V9, P142, DOI 10.1007/s11704-014-3125-7
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Juang WS, 2004, IEEE T CONSUM ELECTR, V50, P251, DOI 10.1109/TCE.2004.1277870
   Kolbitz N., 1987, MATH COMPUT, V48, P203
   LAMPORT L, 1981, COMMUN ACM, V24, P770, DOI 10.1145/358790.358797
   Lee CC, 2011, EXPERT SYST APPL, V38, P13863, DOI 10.1016/j.eswa.2011.04.190
   Lee YS, 2012, IEICE T COMMUN, VE95B, P619, DOI 10.1587/transcom.E95.B.619
   Li LH, 2001, IEEE T NEURAL NETWOR, V12, P1498, DOI 10.1109/72.963786
   Li X, 2016, WIRELESS PERS COMMUN, V89, P569, DOI 10.1007/s11277-016-3293-x
   Li X, 2012, J NETW COMPUT APPL, V35, P763, DOI 10.1016/j.jnca.2011.11.009
   Liao YP, 2013, FUTURE GENER COMP SY, V29, P886, DOI 10.1016/j.future.2012.03.017
   Liao YP, 2009, COMPUT STAND INTER, V31, P24, DOI 10.1016/j.csi.2007.10.007
   Lin H, 2015, WIRELESS PERS COMMUN, V84, P2351, DOI 10.1007/s11277-015-2708-4
   Lin IC, 2003, FUTURE GENER COMP SY, V19, P13, DOI 10.1016/S0167-739X(02)00093-6
   Liu YJ, 2014, INT J COMMUN SYST, V27, P3502, DOI 10.1002/dac.2569
   Lu YR, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126323
   Lumini A, 2007, PATTERN RECOGN, V40, P1057, DOI 10.1016/j.patcog.2006.05.030
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Mishra D, 2016, WIRELESS PERS COMMUN, V86, P1095, DOI 10.1007/s11277-015-2975-0
   Mishra D, 2014, EXPERT SYST APPL, V41, P8129, DOI 10.1016/j.eswa.2014.07.004
   Moon J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145263
   Nessett D. M., 1990, Operating Systems Review, V24, P35, DOI 10.1145/382258.382789
   Pippal RS, 2013, WIRELESS PERS COMMUN, V72, P729, DOI 10.1007/s11277-013-1039-6
   Rubin A. D., 1994, Proceedings. The Computer Security Foundations Workshop VII, CSFW 7 (Cat. No.94TH0686-6), P100, DOI 10.1109/CSFW.1994.315943
   Shen H, 2015, J AMB INTEL HUM COMP, V6, P825, DOI 10.1007/s12652-015-0305-8
   Sood SK, 2011, J NETW COMPUT APPL, V34, P609, DOI 10.1016/j.jnca.2010.11.011
   Tsai JL, 2008, COMPUT SECUR, V27, P115, DOI 10.1016/j.cose.2008.04.001
   Tsai JL, 2015, INT J COMMUN SYST, V28, P1955, DOI 10.1002/dac.2829
   Tsaur WJ, 2005, APPL MATH COMPUT, V170, P258, DOI 10.1016/j.amc.2004.11.033
   Tsaur WJ, 2004, COMPUT STAND INTER, V27, P39, DOI 10.1016/j.csi.2004.03.004
   Wang CQ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149173
   Yeh KH, 2014, WIRELESS PERS COMMUN, V79, P1621, DOI 10.1007/s11277-014-1948-z
   Yoon EJ, 2013, J SUPERCOMPUT, V63, P235, DOI 10.1007/s11227-010-0512-1
   Zhu HF, 2015, WIRELESS PERS COMMUN, V82, P1697, DOI 10.1007/s11277-015-2307-4
NR 64
TC 4
Z9 4
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11067
EP 11099
DI 10.1007/s11042-017-5078-y
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900040
DA 2024-07-18
ER

PT J
AU Masud, M
   Hossain, MS
AF Masud, Mehedi
   Hossain, M. Shamim
TI Secure data-exchange protocol in a cloud-based collaborative health care
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Security; Cryptography; E-health
ID EFFICIENT
AB Cloud-based big data frameworks help collaborative healthcare service providers to efficiently store and manage large-scale health data. In such frameworks each cloud data source is autonomous and exchanges data with another cloud using pair-wise communication for user queries by creating an on-the-fly data-exchange session. The frameworks provide a platform for sharing or exchanging health data residing in multiple clouds for the purpose of data analysis, decision making, and improving patients' treatment. As healthcare data are extremely sensitive, security is vital when sharing such data in a collaborative framework. Since clouds may exchange sensitive patient health data over an insecure channel, the sensitive data might be accessed or intercepted by malicious users or intruders. In this circumstance, a central third-party security mechanism (e.g., Public Key Infrastructure) can not protect confidential data. Concerning pair-wise, on-the-fly data exchange, this paper presents a two-phase security protocol that uses pairing-based cryptography. Each cloud computes a secret session key dynamically by computing a pairing in an elliptic curve. Validating the presented protocol, a formal verification proves that the proposed protocol is robust and safe against the masquerade, man-in-the-middle, and replay attacks.
C1 [Masud, Mehedi] Taif Univ, Dept Comp Sci, At Taif, Saudi Arabia.
   [Hossain, M. Shamim] King Saud Univ, Dept Software Engn, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Hossain, M. Shamim] King Saud Univ, Res Chair Pervas & Mobile Comp, Riyadh 11543, Saudi Arabia.
C3 Taif University; King Saud University; King Saud University
RP Hossain, MS (corresponding author), King Saud Univ, Dept Software Engn, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.; Hossain, MS (corresponding author), King Saud Univ, Res Chair Pervas & Mobile Comp, Riyadh 11543, Saudi Arabia.
EM mmasud@tu.edu.sa; mshossain@ksu.edu.sa
RI Hossain, M. Shamim/K-1362-2014; Guizani, Mohsen/AAX-4534-2021; Masud,
   Mehedi/AAZ-7022-2020
OI Hossain, M. Shamim/0000-0001-5906-9422; Guizani,
   Mohsen/0000-0002-8972-8094; Masud, Mehedi/0000-0001-6019-7245
FU Deanship of Scientific Research, King Saud University
FX The authors are grateful to the Deanship of Scientific Research, King
   Saud University for funding through Vice Deanship of Scientific Research
   Chairs.
CR Alsmirat MA, 2017, J SUPERCOMPUT, V73, P973, DOI 10.1007/s11227-016-1857-x
   [Anonymous], 2000, P S CRYPTOGRAPHY INF
   Asija R, 2016, INT J CLOUD APPL COM, V6, P1, DOI 10.4018/IJCAC.2016070101
   Babaoglu O, 2014, IEEE SPECTRUM
   Barreto PSLM, 2002, LECT NOTES COMPUT SC, V2442, P354
   Basu S, 2012, COMPUTER, V45, P42, DOI 10.1109/MC.2012.291
   Boneh D, 2003, SIAM J COMPUT, V32, P586, DOI 10.1137/S0097539701398521
   Chen TS, 2012, J MED SYST, V36, P4005, DOI 10.1007/s10916-012-9873-8
   Doukas C, 2010, ANN INT C IEEE ENG M
   Guo L., 2010, P IEEE INT C E HLTH, DOI [10.1109/EDT.2010.5496512, DOI 10.1109/EDT.2010.5496512]
   Gupta BB, 2017, INT J CLOUD APPL COM, V7, P1, DOI 10.4018/IJCAC.2017010101
   Gura N, 2004, LECT NOTES COMPUT SC, V3156, P119
   He CG, 2013, IEEE T BIO-MED ENG, V60, P230, DOI 10.1109/TBME.2012.2222404
   Itani W, 2009, EIGHTH IEEE INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, PROCEEDINGS, P711, DOI 10.1109/DASC.2009.139
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Li J, 2015, KNOWL-BASED SYST, V79, P18, DOI 10.1016/j.knosys.2014.04.010
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Li J, 2014, IEEE T PARALL DISTR, V25, P1615, DOI 10.1109/TPDS.2013.284
   Li M, 2011, INT C DISTR COMP SYS
   Li M, 2013, IEEE T PARALL DISTR, V24, P131, DOI 10.1109/TPDS.2012.97
   Masud M, 2012, IJCSI INT J COMPUTER, V9, P36
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Pearson S, 2009, CLOUD: 2009 ICSE WORKSHOP ON SOFTWARE ENGINEERING CHALLENGES OF CLOUD COMPUTING, P44, DOI 10.1109/CLOUD.2009.5071532
   Pearson S, 2009, LECT NOTES COMPUT SC, V5931, P90, DOI 10.1007/978-3-642-10665-1_9
   Rahman Sk, 2011, INT C INT SEC INF IS
   Rahman Sk, 2011, ANN C PRIV SEC TRUST
   Rahman SMM, 2016, PEER PEER NETW APPL, V9, P894, DOI 10.1007/s12083-015-0334-2
   Rahman SMM, 2014, APPL MATH INFORM SCI, V8, P2775, DOI 10.12785/amis/080613
   Ratnam KA, 2012, INT C COMP INF SCI, DOI [10.1109/ICCISci.2012.6297101, DOI 10.1109/ICCISCI.2012.6297101]
   Shini SG, 2012, PROCEDIA ENGINEER, V38, P3454, DOI 10.1016/j.proeng.2012.06.399
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Thilakanathan D, 2016, JMIR MED INF, V4, P56, DOI 10.2196/medinform.4756
   Van Dijk M., 2010, IACR CRYPTOLOGY EPRI, V2010, P305
   Wang C., 2010, IEEE INFOCOM
   Xiong XK, 2009, 2009 8TH IEEE INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND APPLICATIONS, P187, DOI 10.1109/NCA.2009.30
   Zhihua X, 2014, IEEE T INF FOREN SEC, V11, P2594
   Zhijia C, 2009, IEEE INT C ICDCS WOR
NR 37
TC 5
Z9 6
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11121
EP 11135
DI 10.1007/s11042-017-5294-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900042
DA 2024-07-18
ER

PT J
AU Su, PC
   Tsai, TF
   Chien, YC
AF Su, Po-Chyi
   Tsai, Tzung-Fu
   Chien, Yu-Chien
TI Visual secret sharing in halftone images by multi-scale error diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret sharing; Halftone; Multi-scale error diffusion; Information
   hiding
ID DOT DIFFUSION; CRYPTOGRAPHY; WATERMARKING
AB A secret sharing scheme in halftone images is proposed in this research. Given a secret halftone image, several gray-level images with the same resolution will be chosen from the database to collaboratively carry the secret information. The selected images will be transferred to halftone ones using Multi-scale Error Diffusion (MED), with the constraint imposed by the pixels of halftone secret image. The modified MED ensures that the resultant pixels of host halftone images should satisfy the required conditions such that collecting all the processed halftone images can successfully reveal the secret one. In addition to facilitating the perfect extraction of hidden information, maintaining the quality of all the halftone images in this secret sharing scenario is the other major objective, which is achieved by the usage of MED and selection of suitable host images. The experimental results demonstrate the satisfactory performance of the proposed method.
C1 [Su, Po-Chyi; Tsai, Tzung-Fu; Chien, Yu-Chien] Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan 32001, Taiwan.
C3 National Central University
RP Su, PC (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan 32001, Taiwan.
EM pochyisu@csie.ncu.edu.tw
RI SU, PO-CHYI/GWC-9682-2022
FU Ministry of Science and Technology in Taiwan [MOST104-2221-E-008-072,
   MOST105-2221-E-008-086]
FX This research is supported by the Ministry of Science and Technology in
   Taiwan, under Grants MOST104-2221-E-008-072 and MOST105-2221-E-008-086
CR ANALOUI M, 1992, P SOC PHOTO-OPT INS, V1666, P96, DOI 10.1117/12.135959
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Beimel Amos, 2011, Coding and Cryptology. Proceedings of the Third International Workshop, IWCC 2011, P11, DOI 10.1007/978-3-642-20901-7_2
   Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Cimato S., 2014, LECT NOTES COMPUTER, V8363, P91
   Fung YH, 2006, IEEE SIGNAL PROC LET, V13, P153, DOI 10.1109/LSP.2005.862605
   Furht B., 2008, Encyclopedia of Multimedia, DOI [10.1007/978-0-387-78414-4_85, DOI 10.1007/978-0-387-78414-4_85]
   Guo JM, 2012, IEEE T IMAGE PROCESS, V21, P4808, DOI 10.1109/TIP.2012.2210236
   Guo JM, 2012, IEEE T IMAGE PROCESS, V21, P4117, DOI 10.1109/TIP.2012.2198221
   Guo JM, 2010, IEEE INT SYMP CIRC S, P1133, DOI 10.1109/ISCAS.2010.5537324
   Guo JM, 2009, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY, VOL 1, PROCEEDINGS, P201, DOI 10.1109/IAS.2009.13
   Guo JM, 2010, IEEE MULTIMEDIA, V17, P34
   Jarvis JF, 1976, Comput Graph Image Process, V5, P13, DOI DOI 10.1016/S0146-664X(76)80003-2
   Katsavounidis I, 1997, IEEE T IMAGE PROCESS, V6, P483, DOI 10.1109/83.557360
   KNUTH DE, 1987, ACM T GRAPHIC, V6, P245, DOI 10.1145/35039.35040
   Myodo E, 2006, IEEE IMAGE PROC, P97, DOI 10.1109/ICIP.2006.312371
   Myodo E, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2114
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Pan JS, 2006, INT J COMPUT SCI NET, V6, P147
   Pang WM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360688
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Son CH, 2015, INFORM SCIENCES, V299, P1, DOI 10.1016/j.ins.2014.12.002
   Son CH, 2014, SIGNAL PROCESS, V102, P77, DOI 10.1016/j.sigpro.2014.03.016
   Son CH, 2014, DIGIT SIGNAL PROCESS, V28, P93, DOI 10.1016/j.dsp.2014.02.004
   ULICHNEY R, 1993, P SOC PHOTO-OPT INS, V1913, P332, DOI 10.1117/12.152707
   Ulichney R., 1987, DIGITAL HALFTONING
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZM, 2006, IEEE IMAGE PROC, P109, DOI 10.1109/ICIP.2006.312384
   Wang ZM, 2010, INT CONF ACOUST SPEE, P1822, DOI 10.1109/ICASSP.2010.5495395
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Wong PW, 2003, PROC SPIE, V5020, P423, DOI 10.1117/12.479738
   Wong PW, 1996, IEEE T IMAGE PROCESS, V5, P1184, DOI 10.1109/83.502397
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 33
TC 3
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12111
EP 12138
DI 10.1007/s11042-017-4861-0
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100023
DA 2024-07-18
ER

PT J
AU Kim, H
   Kang, SU
AF Kim, Hyunjung
   Kang, Sang-ug
TI Genuine reversible data hiding technology using compensation for H.264
   bitstreams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermarking; Data hiding; Video compression; H. 264/AVC;
   Compensation
ID FRAME ERROR CONCEALMENT; WATERMARKING ALGORITHM; VIDEO WATERMARKING;
   SCHEME
AB Reversible data hiding technologies have been considered largely impractical because those are, in most cases, applicable to raw video data rather than prevailing compressed data. Even though, many algorithms have been recently developed in the compressed video domain, most of them cannot guarantee the reversibility of cover video due to the lossy characteristics of video compression standards. We suggest completely practical data hiding scheme for H.264 baseline bitstream by achieving genuine reversibility for both I and P frames. Regardless of the data hiding algorithm, the proposed scheme can increase embedding payload by 66.9% and reduce computational complexity by 93%. Also, a novel compensation based difference expansion method with clever coefficient pairing strategy is proposed as a data hiding algorithm and achieved superior embedding payload vs. image quality performance. The proposed algorithm improves payload by 48.9% on average at almost the same video quality distortion.
C1 [Kim, Hyunjung; Kang, Sang-ug] Sangmyung Univ, Dept Comp Sci, Seoul, South Korea.
C3 Sangmyung University
RP Kang, SU (corresponding author), Sangmyung Univ, Dept Comp Sci, Seoul, South Korea.
EM halena228@naver.com; sukang@smu.ac.kr
FU Basic Science Research Program through the National Research
   Foundation(NRF) of Korea - Ministry of Science, ICT & Future Planning
   [NRF-2015R1C1A1A02037777]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation(NRF) of Korea funded by the Ministry of
   Science, ICT & Future Planning (NRF-2015R1C1A1A02037777).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], ITU T REC H
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], 2016, IEEE LONG ISL SYST A
   [Anonymous], 3 INT C MULT TECHN A
   [Anonymous], 2009, JVTAE010
   [Anonymous], ACM P 8 IND C COMP V
   Bouchama S., 2013, IEEE International Conference on Information Science and Applications, P1
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chen YH, 2016, MULTIMED TOOLS APPL, V75, P13679, DOI 10.1007/s11042-015-2825-9
   Chung KL, 2010, IEEE T CIRC SYST VID, V20, P1643, DOI 10.1109/TCSVT.2010.2077577
   Fridrich J, 2004, PROC SPIE, V5306, P354, DOI 10.1117/12.525418
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huang HC, 2016, OPTIK, V127, P5950, DOI 10.1016/j.ijleo.2016.04.011
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Kang SU, 2012, ETRI J, V34, P410, DOI [10.4218/etrij.11.0111.0075, 10.4218/etrij.12.0111.0075]
   Liu HM, 2006, LECT NOTES COMPUT SC, V3919, P123
   Liu YX, 2015, NEUROCOMPUTING, V151, P1053, DOI 10.1016/j.neucom.2014.03.088
   Lu CS, 2005, SIGNAL PROCESS-IMAGE, V20, P624, DOI 10.1016/j.image.2005.03.012
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Mitchell J., 1992, ITU-Rec. T. 81
   Mobasseri BG, 2010, IEEE T IMAGE PROCESS, V19, P958, DOI 10.1109/TIP.2009.2035227
   Muhammad K., 2016, MULTIMED TOOLS APPL, P1
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qian ZX, 2012, J SYST SOFTWARE, V85, P309, DOI 10.1016/j.jss.2011.08.015
   Qu X, 2015, J ELECTR ENG TECHNOL, V10, P422, DOI 10.5370/JEET.2015.10.1.422
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai YY, 2013, DIGIT SIGNAL PROCESS, V23, P919, DOI 10.1016/j.dsp.2012.12.014
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Xu DW, 2014, J VIS COMMUN IMAGE R, V25, P410, DOI 10.1016/j.jvcir.2013.12.008
   Xuan GR, 2007, LECT NOTES COMPUT SC, V4633, P715
NR 34
TC 10
Z9 10
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8043
EP 8060
DI 10.1007/s11042-017-4698-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800013
DA 2024-07-18
ER

PT J
AU Li, B
   Liao, XF
   Jiang, Y
AF Li, Bo
   Liao, Xiaofeng
   Jiang, Yan
TI A novel image encryption scheme based on logistic map and dynatomic
   modular curve
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Logistic map; Dynatomic modular curve; Projective transformation;
   Chi-Square test; K-S test
ID SYSTEM
AB A new image encryption and decryption algorithm based on chaotic map and dynatomic modular curve is proposed in this paper. Firstly, the definition of dynatomic modular curve and its periodic points are introduced, and a property of the dynatomic modular curve is proved. Secondly, the relationship between the Logistic map and the dynatomic modular curve is discussed. Finally, the encryption algorithm which is composed of permutation of pixels and substitution is given. In order to eliminate sufficiently the relation between adjacent pixels in the image, pixel values of the original image are sorted as index function, which derives from Logistic map and dynatomic modular curve. And XOR operation is performed between the scrambled pixel sequence and projective transformation sequence. Simulation experiments and nonparametric hypothesis test demonstrate that the proposed algorithm is secure to resist different types of attacks and it can be applied to real-time encryption.
C1 [Li, Bo; Liao, Xiaofeng] Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
   [Li, Bo] Logist Engn Univ, Dept Math, Chongqing 401331, Peoples R China.
   [Jiang, Yan] Chong Qing Energy Coll, Dept Math, Chongqing 402262, Peoples R China.
C3 Southwest University - China
RP Liao, XF (corresponding author), Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
EM xfliao@cqu.edu.cn
RI Liao, Xiaofeng/HPD-6655-2023
FU National Key Research and Development Program of China [2016YFB0800601]
FX This work was supported by the National Key Research and Development
   Program of China 2016YFB0800601.
CR [Anonymous], GRADUATETEXTS MATH
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen WH, 2016, IEEE T NEURAL NETWOR, V33, P300
   Chhotaray A, 2015, NETWORKING INFORM, V9, P355
   Cong-Xu Z, 2012, ACTA PHYS SINICA, V61, P1
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Hua TX, 2015, INT J THEOR PHYS, V54, P526, DOI 10.1007/s10773-014-2245-z
   Huang CK, 2013, TELECOMMUN SYST, V52, P563, DOI 10.1007/s11235-011-9461-0
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Kamara S, 2010, LECT NOTES COMPUT SC, V6054, P136, DOI 10.1007/978-3-642-14992-4_13
   Kumar HSS, 2013, ADV INTELL SYST, V177, P843
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu L, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2374-3
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Prasad M., 2011, COMPUTER SCI, P169, DOI 10.5121/csit.2011.1217
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Rajput AS, 2015, ADV INTELLIGENT INFO, V26, P277
   Silverman Joseph H., 2007, ARITHMETIC DYNAMICAL, P148
   Sivakumar T, 2016, J INF SCI ENG, V32, P133
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Wang H, 2014, COMM COM INF SC, V462, P264
   WANG XY, 2009, COMMUNICATIONS NONLI, V15, P2479
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
   Yuan HM, 2017, MULTIMED TOOLS APPL, V76, P8087, DOI 10.1007/s11042-016-3454-7
   Zhang Q, 2012, SCI WORLD J, DOI 10.1100/2012/286741
   Zhang S, 2016, MULTIMED TOOLS APPL, V75, P17157, DOI 10.1007/s11042-015-2982-x
NR 30
TC 28
Z9 30
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8911
EP 8938
DI 10.1007/s11042-017-4786-7
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800050
DA 2024-07-18
ER

PT J
AU Liu, J
   Pengren A
   Ge, QQ
   Zhao, H
AF Liu, Jin
   Pengren, A.
   Ge, Qianqian
   Zhao, Hang
TI Gabor tensor based face recognition using the boosted nonparametric
   maximum margin criterion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Ensemble learning; Gabor wavelets; MPCA
ID PRINCIPAL COMPONENT ANALYSIS; LDA; MPCA
AB This paper proposes a new face recognition method that combines the ensemble learning with the third-order Gabor tensor. In this method, the third-order Gabor tensor is used to replace the vectorial Gabor feature representation in order to keep high-dimensional adjacent structures in images. In order to avoid to fall into the curse of the dimensions due to the tensor, a multilinear principle component analysis (MPCA) algorithm is utilized to reduce the dimensions of the Gabor tensor. The obtained low-dimensional Gabor tensor features are selected in term of their discriminant ability to form a vectorial Gabor feature representation. It is embedded into a new sample selection scheme to construct a new classifier. Different from the traditional sample selection, the samples with high misclassification rate regardless of their class is used to train a set of diversity Nonparametric Maximum Margin Criterion (NMMC) learners and the scheme allows each class to have different numbers of samples. In construction of the classifier, multiple weak classifiers are first trained in terms of the K-NN criterion and then these weak classifiers are fused into a boosted classifier in terms of the confidence levels of individual weak classifiers. The proposed method inherits the merit of both the boosting technique and the Gabor wavelets. Experimental results on several benchmark face databases show that it attains better performance than the existing state-of-the-art methods.
C1 [Liu, Jin; Pengren, A.; Ge, Qianqian; Zhao, Hang] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Liu, J (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
EM Jinliu@xidian.edu.cn; apengren@126.com; geqianqina_ex@163.com;
   Hzhao_425@163.com
FU National Natural Science Foundation of China [61101246]; Fundamental
   Research Funds for the Central Universities [JB150209]
FX This research was supported in part by the National Natural Science
   Foundation of China (Grant No. 61101246) and the Fundamental Research
   Funds for the Central Universities (Grant No. JB150209).
CR Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Deypir M, 2011, EXPERT SYST APPL, V38, P941, DOI 10.1016/j.eswa.2010.07.078
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Lu H, 2009, J IMAGE VIDEO PROCES, V2009, P1
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Lu JW, 2006, IEEE T NEURAL NETWOR, V17, P166, DOI 10.1109/TNN.2005.860853
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Pin Liao, 2012, Proceedings of the 2012 IEEE International Conference on Computer Science and Automation Engineering (CSAE 2012), P586, DOI 10.1109/CSAE.2012.6273021
   Qiu X P, 2005, IEEE INT C IM PROC, V2, P918
   Schapire RE, 2003, LECT NOTES STAT, V171, P149, DOI 10.1007/978-0-387-21579-2_9
   Schapire RE, 1998, ANN STAT, V26, P1651
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang XG, 2004, PROC CVPR IEEE, P259
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wu J, 2015, LECT NOTES ELECTR EN, V336, P421, DOI 10.1007/978-3-662-46469-4_45
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 17
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 9055
EP 9069
DI 10.1007/s11042-017-4805-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800057
DA 2024-07-18
ER

PT J
AU Nageswari, CS
   Prabha, KH
AF Nageswari, C. Shobana
   Prabha, K. Helen
TI Preserving the border and curvature of fetal heart chambers through
   TDyWT perspective geometry wrap segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Congenital heart defect (CHD); Transverse dyadic wavelet transform
   (TDyWT); Adaptive kernel fuzzy C-means clustering algorithm (AKFCM)
ID SPARSE REPRESENTATION; 4-CHAMBER VIEW; LEVEL-SET; ECHOCARDIOGRAM;
   SEQUENCES
AB Congenital heart defect leads to the structural abnormality in neonatal. Congenital heart defect (CHD) is the major cause for 20% perinatal mortality and 50% infant mortality. However, the fetal cardiac screening plays a vital role to diagnose the CHD during second -trimester. Evaluation of fetal cardiac chamber structure is difficult due to small in size and movement. Four-chamber view has become the first and foremost view of echocardiography to detect structural malformations in the fetal heart. Furthermore, trained obstetricians, Pediatric cardiologists, maternal-fetal medicine specialists, and radiologists need proper knowledge and skills to identify the chamber structure from echocardiography. In addition, the effective diagnosis of fetal heart four-chamber view consumes more time and needs extremely skilled radiologists owing to their low quality, small signal to noise ratio and rapid movement of fetal heart ultrasound images. Thus, the diagnosis of CHD is the most challenging task. In this paper, we propose the Transverse Dyadic Wavelet Transform (TDyWT) algorithm to preserve the border and curvature of four chambers from 18 to 22 weeks ultrasound fetal heart image. We validate the proposed TDyWT algorithm with normal and abnormal images from Mediscan radiological centre. The performance of the TDyWT algorithm analyses qualitatively and quantitatively to prove border and curvature of the chambers is superior to other conventional methods.
C1 [Nageswari, C. Shobana] RMD Engn Coll, Chennai, Tamil Nadu, India.
   [Prabha, K. Helen] RMD Engn Coll, ECE Dept, Chennai, Tamil Nadu, India.
RP Nageswari, CS (corresponding author), RMD Engn Coll, Chennai, Tamil Nadu, India.
EM shobananageswari79@gmail.com; helenprabha@yahoo.com
RI C, SHOBANA NAGESWARI/W-7263-2019; K, D/JRX-3613-2023; K,
   Dr.HelenPrabha/V-9407-2019
OI K, Dr.HelenPrabha/0000-0002-4951-5748; C, Shobana
   nageswari/0000-0003-1150-2965
CR Allan G, 2017, IEEE T MED IMAGING, V36, P40, DOI 10.1109/TMI.2016.2593900
   [Anonymous], 2014, P ADV COMP NETW INF
   Balaji GN, 2015, IETE J RES, V61, P236, DOI 10.1080/03772063.2015.1009403
   Cao Y, 2014, INT C PATT RECOG, P568, DOI 10.1109/ICPR.2014.108
   Carneiro G, 2012, IEEE T IMAGE PROCESS, V21, P968, DOI 10.1109/TIP.2011.2169273
   Deng YH, 2012, COMPUT MED IMAG GRAP, V36, P239, DOI 10.1016/j.compmedimag.2011.04.002
   Dietenbeck T, 2012, MED IMAGE ANAL, V16, P386, DOI 10.1016/j.media.2011.10.003
   Dindoyal I, 2007, I S BIOMED IMAGING, P864, DOI 10.1109/ISBI.2007.356989
   Dindoyal I, 2011, MED PHYS, V38, P4338, DOI 10.1118/1.3592638
   Guo Y, 2014, IEEE T BIO-MED ENG, V61, P1121, DOI 10.1109/TBME.2013.2295376
   Huang XJ, 2014, MED IMAGE ANAL, V18, P253, DOI 10.1016/j.media.2013.10.012
   Leung KYE, 2010, EUR J ECHOCARDIOGR, V11, P97, DOI 10.1093/ejechocard/jeq005
   Nirmala S, 2016, PROCEDIA COMPUT SCI, V79, P344, DOI 10.1016/j.procs.2016.03.045
   Pedrosa J, 2017, IEEE T ULTRASON FERR, V64, P525, DOI 10.1109/TUFFC.2016.2638080
   Sardsud C, 2015, 7 INT C COMP INT MOD
   Sridevi S, 2016, APPL SOFT COMPUT, V46, P577, DOI 10.1016/j.asoc.2015.09.002
   Tutschek B, 2008, ULTRASOUND OBST GYN, V32, P176, DOI 10.1002/uog.5403
   Vargas-Quintero L, 2016, COMPUT METH PROG BIO, V137, P231, DOI 10.1016/j.cmpb.2016.09.021
   Xiaojie Huang, 2012, 2012 IEEE Workshop on Mathematical Methods in Biomedical Image Analysis (MMBIA), P305, DOI 10.1109/MMBIA.2012.6164769
   Yeo L, 2011, ULTRASOUND OBST GYN, V37, P423, DOI 10.1002/uog.8840
   Yu L, 2017, IEEE T BIO-MED ENG, V64, P1886, DOI 10.1109/TBME.2016.2628401
NR 21
TC 6
Z9 6
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10235
EP 10250
DI 10.1007/s11042-017-5428-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200055
DA 2024-07-18
ER

PT J
AU Al-Rousan, R
   Sunar, MS
   Kolivand, H
AF Al-Rousan, Riyad
   Sunar, Mohd Shahrizal
   Kolivand, Hoshang
TI Geometry-based shading for shape depiction enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-photorealistic rendering; Shape depiction; Stylized shading;
   Curvature
ID LINES
AB Recent works on Non-Photorealistic Rendering (NPR) show that object shape enhancement requires sophisticated effects such as: surface details detection and stylized shading. To date, some rendering techniques have been proposed to overcome this issue, but most of which are limited to correlate shape enhancement functionalities to surface feature variations. Therefore, this problem still persists especially in NPR. This paper is an attempt to address this problem by presenting a new approach for enhancing shape depiction of 3D objects in NPR. We first introduce a tweakable shape descriptor that offers versatile functionalities for describing the salient features of 3D objects. Then to enhance the classical shading models, we propose a new technique called Geometry-based Shading. This technique controls reflected lighting intensities based on local geometry. Our approach works without any constraint on the choice of material or illumination. We demonstrate results obtained with Blinn-Phong shading, Gooch shading, and cartoon shading. These results prove that our approach produces more satisfying results compared with the results of previous shape depiction techniques. Finally, our approach runs on modern graphics hardware in real time, which works efficiently with interactive 3D visualization.
C1 [Al-Rousan, Riyad; Sunar, Mohd Shahrizal] Univ Teknol Malaysia, UTM IRDA Digital Media Ctr, Media & Game Innovat Ctr Excellence, Inst Human Ctr Engn, Skudai 81310, Johor, Malaysia.
   [Al-Rousan, Riyad; Sunar, Mohd Shahrizal] Univ Teknol Malaysia, Fac Comp, Dept Software Engn, Skudai 81310, Johor, Malaysia.
   [Kolivand, Hoshang] Liverpool John Moores Univ, Dept Comp Sci, Liverpool L3 3AF, Merseyside, England.
C3 Universiti Teknologi Malaysia; Universiti Teknologi Malaysia; University
   of Liverpool; Liverpool John Moores University
RP Al-Rousan, R (corresponding author), Univ Teknol Malaysia, UTM IRDA Digital Media Ctr, Media & Game Innovat Ctr Excellence, Inst Human Ctr Engn, Skudai 81310, Johor, Malaysia.; Al-Rousan, R (corresponding author), Univ Teknol Malaysia, Fac Comp, Dept Software Engn, Skudai 81310, Johor, Malaysia.
EM riyad@magicx.my; shahrizal@utm.my; kolivand@magicx.my
RI Kolivand, Hoshang/F-4736-2011; Sunar, Mohd Shahrizal/AFQ-7366-2022;
   Kolivand, Hoshang/B-2501-2016
OI Sunar, Mohd Shahrizal/0000-0002-0244-1622; Kolivand,
   Hoshang/0000-0001-5460-5679
CR Anjyo Kenichi., 2006, Symposium on Non-photorealistic Animation and Rendering, NPAR '06, P133
   Cignoni P, 2005, COMPUT GRAPH-UK, V29, P125, DOI 10.1016/j.cag.2004.11.012
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   Decaudin P, 1996, SYNTIM PROJECT INRIA, V6
   Fleming RolandW., 2009, Three dimensional shape perception, chapter Shape from sheen
   Fleming RW, 2004, J VISION, V4, P798, DOI 10.1167/4.9.10
   Gooch A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P447, DOI 10.1145/280814.280950
   Hao W, 2013, 2013 INTERNATIONAL CONFERENCE ON VIRTUAL REALITY AND VISUALIZATION (ICVRV 2013), P9, DOI 10.1109/ICVRV.2013.10
   Hogarth B, 1991, DYNAMIC LIGHT SHADE
   Judd T, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239470
   Kajiya J. T., 1986, SIGGRAPH, P143, DOI 10.1145/15886.15902
   Kindlmann G, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P513, DOI 10.1109/VISUAL.2003.1250414
   Kolomenkin M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409110
   Lake C., 2000, Proceedings of the first international symposium on Non-photorealistic animation and rendering-NPAR'00, P13, DOI 10.1145/340916.3409185[27]M.S.
   Lee CH, 2006, IEEE T VIS COMPUT GR, V12, P197, DOI 10.1109/TVCG.2006.30
   Lee J, 2015, MULTIMED TOOLS APPL, V74, P3401, DOI 10.1007/s11042-014-2104-1
   Lee Y, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239469
   Miao YW, 2012, J COMPUT SCI TECH-CH, V27, P1100, DOI 10.1007/s11390-012-1288-y
   Miao YW, 2011, COMPUT GRAPH-UK, V35, P706, DOI 10.1016/j.cag.2011.03.017
   Ohtake Y, 2004, ACM T GRAPHIC, V23, P609, DOI 10.1145/1015706.1015768
   PHARR M., 2004, GPU GEMS PROGRAMMING, P279
   Ritschel T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360689
   Rusinkiewicz S, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P486, DOI 10.1109/TDPVT.2004.1335277
   Rusinkiewicz S, 2006, ACM T GRAPHIC, V25, P1199, DOI 10.1145/1141911.1142015
   Saito T., 1990, Computer Graphics, V24, P197, DOI 10.1145/97880.97901
   Schulze M, 2011, SOC CHOICE WELFARE, V36, P267, DOI 10.1007/s00355-010-0475-4
   Todo H, 2013, VISUAL COMPUT, V29, P473, DOI 10.1007/s00371-013-0811-7
   Todo H, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276399, 10.1145/1239451.1239468]
   Toler-Franklin C, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P111
   Vanderhaeghe D., 2011, Proceedings of the 8th International Symposium on Non-Photorealistic Animation and Rendering, P99, DOI [10.1145/2024676.2024693, DOI 10.1145/2024676.2024693]
   Vergne R., 2010, ACM SIGGRAPH S INT 3, P143
   Vergne R., 2008, Proceedings of the 6th international symposium on Nonphotorealistic animation and rendering, P23, DOI [10. 1145/1377980. 1377987, DOI 10.1145/1377980.1377987]
   Vergne R, 2011, IEEE T VIS COMPUT GR, V17, P1071, DOI 10.1109/TVCG.2010.252
   Vergne R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531331
   Xie X, 2007, IEEE T VIS COMPUT GR, V13, P1328, DOI 10.1109/TVCG.2007.70538
   Zhang L, 2011, IEEE T VIS COMPUT GR, V17, P993, DOI 10.1109/TVCG.2010.118
   Zhao FK, 2014, VISUAL COMPUT, V30, P113, DOI 10.1007/s00371-013-0787-3
   Zhao HL, 2013, MULTIMED TOOLS APPL, V63, P647, DOI 10.1007/s11042-011-0890-2
NR 38
TC 2
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5737
EP 5766
DI 10.1007/s11042-017-4486-3
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800027
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Ravisankar, P
   Sharmila, TS
   Rajendran, V
AF Ravisankar, Priyadharsini
   Sharmila, T. Sree
   Rajendran, V.
TI Acoustic image enhancement using Gaussian and laplacian pyramid - a
   multiresolution based technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic image; Enhancement; Gaussian; Histogram equalization;
   Laplacian; Pyramid; Unsharp masking
ID HISTOGRAM EQUALIZATION; CLASSIFICATION; TRANSFORM; CONTRAST
AB Acoustic images captured by side scan sonar are normally affected by speckle noise for which the enhancement is required in different domain. The underwater acoustic images obtained using sound as a source, basically contain seafloor, sediments, living and non-living resources. The Multiresolution based image enhancement techniques nowadays play a vital role in improving the quality of the low resolution image with repeated patterns. Image pyramid is the representation of an image at various scales. In this work, a three level Gaussian and Laplacian pyramids are constructed to represent the image in different resolution. The multiscale representation requires different filters at different scales. The contrast of each image in Gaussian and Laplacian pyramids are improved by applying both histogram equalization and unsharp masking method. The sharpened images are used to reconstruct the enhanced image. The performance measure, peak signal to noise ratio proves that the unsharp masking method applied to difference images of Laplacian pyramid outperforms the other image enhancement methods.
C1 [Ravisankar, Priyadharsini] Sri Sivasubramaniya Nadar Coll Engn, Dept CSE, Madras 603110, Tamil Nadu, India.
   [Sharmila, T. Sree] Sri Sivasubramaniya Nadar Coll Engn, Dept IT, Madras 603110, Tamil Nadu, India.
   [Rajendran, V.] Vels Univ, Dept ECE, Madras, Tamil Nadu, India.
C3 SSN College of Engineering; SSN College of Engineering; Vels Institute
   of Science, Technology & Advanced Studies
RP Ravisankar, P (corresponding author), Sri Sivasubramaniya Nadar Coll Engn, Dept CSE, Madras 603110, Tamil Nadu, India.
EM priyadharsinir@ssn.edu.in
RI T., Sree Sharmila/ABC-3930-2021; R, Priyadharsini/JZD-4775-2024; V,
   Rajendran/JEZ-9265-2023; V, R/JWO-9375-2024
OI T., Sree Sharmila/0000-0001-5744-9739; V, Rajendran/0000-0002-6819-3991;
   T, Sree Sharmila/0009-0009-1736-2669
FU SSN institutions
FX We would like to thank SSN institutions for providing financial support
   to carry out this work successfully.
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Anbarjafari G, 2015, SIGNAL IMAGE VIDEO P, V9, P87, DOI 10.1007/s11760-012-0422-1
   [Anonymous], 2015, J COMPUTER SCI SYSTE
   Asmare MH, 2015, SIGNAL IMAGE VIDEO P, V9, P1679, DOI 10.1007/s11760-014-0626-7
   Cherifi D, 2010, SIGNAL IMAGE VIDEO P, V4, P247, DOI 10.1007/s11760-009-0115-6
   Demirel H., 2008, 2008 23rd International Symposium on Computer and Information Sciences, P1
   Demirel H, 2010, IEEE GEOSCI REMOTE S, V7, P333, DOI 10.1109/LGRS.2009.2034873
   Dura E, 2011, INTECH
   Fronthaler H, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P45, DOI 10.1109/AUTOID.2007.380591
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES, P104
   Hasikin K, 2014, SIGNAL IMAGE VIDEO P, V8, P1591, DOI 10.1007/s11760-012-0398-x
   Kara F, 2016, SIGNAL IMAGE VIDEO P, V10, P1159, DOI 10.1007/s11760-016-0872-y
   Mahmoud TA, 2009, SIGNAL IMAGE VIDEO P, V3, P403, DOI 10.1007/s11760-008-0090-3
   Murino V, 2000, P IEEE, V88, P1903, DOI 10.1109/5.899059
   Priyadharsini R, 2015, IEEE INT C APPL THEO, P563
   Santhi K, 2015, SIGNAL IMAGE VIDEO P, V9, P73, DOI 10.1007/s11760-014-0643-6
   Sharmila TS, 2014, SIGNAL IMAGE VIDEO P, V8, P1399, DOI 10.1007/s11760-012-0369-2
   Sharmila TS, 2014, SIGNAL IMAGE VIDEO P, V8, P149, DOI 10.1007/s11760-013-0505-7
   Sharumathi K, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P2930, DOI 10.1109/ICEEOT.2016.7755235
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Sree Sharmila T., 2013, Journal of Computer Science, V9, P176, DOI 10.3844/jcssp.2013.176.182
   Stefanakis N, 2012, INT CONF ACOUST SPEE, P2509, DOI 10.1109/ICASSP.2012.6288426
   Thangaswamy S, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013013
   Xiaoming Liu, 2009, 2009 International Conference on Information and Automation (ICIA), P1167, DOI 10.1109/ICINFA.2009.5205093
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Zahedi M, 2015, SIGNAL IMAGE VIDEO P, V9, P267, DOI 10.1007/s11760-013-0436-3
   Zhang YD, 2015, J MED IMAG HEALTH IN, V5, P1395, DOI 10.1166/jmihi.2015.1542
   Zhe Wu, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P668, DOI 10.1109/CISP.2010.5647218
NR 28
TC 17
Z9 18
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5547
EP 5561
DI 10.1007/s11042-017-4466-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800020
DA 2024-07-18
ER

PT J
AU Shahdoosti, HR
   Hazavei, SM
AF Shahdoosti, Hamid Reza
   Hazavei, Seyede Mahya
TI Combined ripplet and total variation image denoising methods using twin
   support vector machines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Ripplet transform; Sparse representation; Total
   variation; Classification
ID TOTAL VARIATION DIFFUSION; SHEARLET TRANSFORM; ANISOTROPIC DIFFUSION;
   WAVELET SHRINKAGE; NONLOCAL MEANS; SPARSE; REPRESENTATIONS; ALGORITHMS;
   DOMAIN; FILTER
AB The main goals of denoising are to improve the signal-to-noise-ratio (SNR) and to preserve the informative features such as edges and textures. Aiming at reducing Gibbs-type artifacts, several researchers have combined wavelet-like transforms such as curvelets with total variation or diffusion methods. In this paper, a ripplet formulation of the total variation method for denoising images is proposed. The ripplet is known as a developed version of the curvelet transform and proposes a new tight frame with sparse representation for images with discontinuities along any type of boundaries. We manipulate the cost function of the total variation method, such that instead of minimizing the total variation of the noisy image, we minimize the total variation of a new image obtained from non-textured regions of ripplet subbands. To obtain these regions, ripplet coefficients are divided into textured regions and smooth ones using the twin support vector machine classifier. Numerical examples demonstrate that the proposed approach improves the image quality in terms of both subjective and objective inspections, compared with some other state-of-the-art denoising techniques.
C1 [Shahdoosti, Hamid Reza; Hazavei, Seyede Mahya] Hamedan Univ Technol, Dept Elect Engn, Hamadan 65155, Iran.
RP Shahdoosti, HR (corresponding author), Hamedan Univ Technol, Dept Elect Engn, Hamadan 65155, Iran.
EM h.doosti@hut.ac.ir
RI Shahdoosti, Hamid/U-1005-2019
CR [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2000, CURVES SURFACES
   Balster EJ, 2005, IEEE T IMAGE PROCESS, V14, P2024, DOI 10.1109/TIP.2005.859385
   Barash D, 2002, IEEE T PATTERN ANAL, V24, P844, DOI 10.1109/TPAMI.2002.1008390
   Barbu A, 2009, IEEE T IMAGE PROCESS, V18, P2451, DOI 10.1109/TIP.2009.2028254
   Brox T, 2008, IEEE T IMAGE PROCESS, V17, P1083, DOI 10.1109/TIP.2008.924281
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2006, NUMER MATH, V105, P1, DOI 10.1007/s00211-006-0029-v
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Cheng H, 2004, ELECTRON LETT, V40, P1
   Coifman RR, 2000, APPL COMPUT HARMON A, V9, P1, DOI 10.1006/acha.2000.0299
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dixit AA, 2013, INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, IMAGE PROCESSING AND PATTERN RECOGNITION (ICSIPR 2013), P275, DOI 10.1109/ICSIPR.2013.6497937
   Durand S, 2003, SIAM J SCI COMPUT, V24, P1754, DOI 10.1137/S1064827501397792
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Easley GR, 2009, IEEE T IMAGE PROCESS, V18, P260, DOI 10.1109/TIP.2008.2008070
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Geng P, 2014, MULTIMED TOOLS APPL, V75, P1
   Ghahremani M, 2015, IEEE GEOSCI REMOTE S, V12, P502, DOI 10.1109/LGRS.2014.2347955
   Gilboa G, 2003, P VLSM, V3
   Ji ZX, 2009, INFORM PROCESS LETT, V109, P1238, DOI 10.1016/j.ipl.2009.09.007
   Jin LH, 2012, DIGIT SIGNAL PROCESS, V22, P903, DOI 10.1016/j.dsp.2012.06.012
   LEE JS, 1983, COMPUT VISION GRAPH, V24, P255, DOI 10.1016/0734-189X(83)90047-6
   Ma J, 2007, IEEE T IMAGE PROCESS, V16, P2198, DOI 10.1109/TIP.2007.902333
   Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509
   Parrilli S, 2012, IEEE T GEOSCI REMOTE, V50, P606, DOI 10.1109/TGRS.2011.2161586
   Qiu PH, 2010, SIGNAL PROCESS, V90, P2851, DOI 10.1016/j.sigpro.2010.04.009
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shahdoosti HR, 2016, SIGNAL IMAGE VIDEO P, V10, P1081, DOI 10.1007/s11760-016-0862-0
   Shahdoosti HR, 2016, J INTELL FUZZY SYST, V30, P3087, DOI 10.3233/IFS-152035
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Steidl G, 2004, SIAM J NUMER ANAL, V42, P686, DOI 10.1137/S0036142903422429
   Tappen M. F., 2007, P IEEE C COMP VIS PA, P1
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang XY, 2013, INFORM SCIENCES, V246, P155, DOI 10.1016/j.ins.2013.05.028
   Wang XY, 2010, EXPERT SYST APPL, V37, P7040, DOI 10.1016/j.eswa.2010.03.014
   Xu J, 2010, J VIS COMMUN IMAGE R, V21, P627, DOI 10.1016/j.jvcir.2010.04.002
   Yang HY, 2014, NEURAL NETWORKS, V57, P152, DOI 10.1016/j.neunet.2014.06.007
   Yaroslavsky L.P, 2012, DIGITAL PICTURE PROC, V9
   Zhano M, 2008, IEEE T IMAGE PROCESS, V17, P2324, DOI 10.1109/TIP.2008.2006658
NR 40
TC 14
Z9 15
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7013
EP 7031
DI 10.1007/s11042-017-4618-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700027
DA 2024-07-18
ER

PT J
AU Zhao, ZC
   Xiang, R
   Su, F
AF Zhao, Zhicheng
   Xiang, Rui
   Su, Fei
TI Complex event detection via attention-based video representation and
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia event detection; Visual attention; Salient object; Vlad
AB As an important task in managing unconstrained web videos, multimedia event detection (MED) has attracted wide attention recently. However, due to the complexities such as high abstraction of the events, various scenes and frequent interactions of individuals etc., MED is quite challenging. In this paper, we propose a novel MED algorithm via attention-based video representation and classification. Firstly, inspired by human's selective attention mechanism, an attention-based saliency localization network (ASLN) is constructed to quickly predict the semantic saliency objects of video frames. Afterwards, in order to complementarily represent salient objects and the surroundings, two Convolutional Neural Networks (CNNs) features, i.e., local saliency feature and global feature are respectively extracted from the salient objects and the whole feature map. Thirdly, after binding two features together, Vector of Locally Aggregated Descriptors (VLAD) is applied to encode them into the video representation. Finally, the linear Support Vector Machine (SVM) classifiers are trained to classify. We extensively evaluate the performance on TRECVID MED14_10Ex, MED14_100Ex and Columbia Consume Video (CCV) datasets. Experimental results show that the proposed single model outperforms state-of-the-art approaches on all three real-world video datasets, and demonstrate the effectiveness.
C1 [Zhao, Zhicheng; Xiang, Rui; Su, Fei] Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing 100876, Peoples R China.
   [Zhao, Zhicheng; Su, Fei] Beijing Univ Posts & Telecommun, Beijing Key Lab Network Syst & Network Culture, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications
RP Zhao, ZC (corresponding author), Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing 100876, Peoples R China.
EM zhaozc@bupt.edu.cn; 573916084@qq.com; sufei@bupt.edu.cn
FU Chinese National Natural Science Foundation [61471049, 61372169,
   61532018]
FX This work is supported by Chinese National Natural Science Foundation
   under Grants 61471049, 61372169 and 61532018.
CR [Anonymous], ACM INT C MULT RETR
   [Anonymous], INT J EXP PSYCHOL GE
   [Anonymous], 2011, P 1 INT C MULT RETR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], TRECVID 2014 WORKSH
   [Anonymous], ACM INT C MULT RETR
   [Anonymous], ACM INT C MULT RETR
   [Anonymous], ACM MULTIMEDIA
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Chang XJ, 2016, AAAI CONF ARTIF INTE, P3464
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2016, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2016.208
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P581, DOI 10.1145/2733373.2806218
   Chang XJ, 2015, PR MACH LEARN RES, V37, P1348
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Karthikeyan S, 2015, PROC CVPR IEEE, P3241, DOI 10.1109/CVPR.2015.7298944
   Lai KT, 2014, LECT NOTES COMPUT SC, V8691, P675, DOI 10.1007/978-3-319-10578-9_44
   Li WX, 2013, IEEE I CONF COMP VIS, P2728, DOI 10.1109/ICCV.2013.339
   Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419
   MARTIN M, 1979, MEM COGNITION, V7, P476, DOI 10.3758/BF03198264
   Mettes P, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P175, DOI 10.1145/2911996.2912036
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Simonyan K., 2014, 14091556 ARXIV
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808
   TREISMAN AM, 1969, PSYCHOL REV, V76, P282, DOI 10.1037/h0027242
   Treue S, 1999, NATURE, V399, P575, DOI 10.1038/21176
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Ye Guangnan., 2012, ACM International Conference on Multimedia Retrieval, P39
   Ye H, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P435, DOI 10.1145/2671188.2749406
   Zhao ZC, 2016, NEUROCOMPUTING, V208, P378, DOI 10.1016/j.neucom.2016.06.002
NR 43
TC 6
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3209
EP 3227
DI 10.1007/s11042-017-5058-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600016
DA 2024-07-18
ER

PT J
AU Ravanbakhsh, N
   Nazari, M
AF Ravanbakhsh, Niloofar
   Nazari, Mahboubeh
TI An efficient improvement remote user mutual authentication and session
   key agreement scheme for E-health care systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE E-health care systems; Fuzzy extractor; Elliptic curve cryptography;
   Three-factor authentication; Key agreement
ID PROVABLY SECURE; ROAMING SERVICE; ACCESS-CONTROL; PROTOCOL;
   CRYPTANALYSIS
AB The E-health care systems allow patients to gain the health monitoring facility and access medical services remotely. A secure mechanism for mutual authentication and session key agreement is the most important requirements for E-Health Care Systems. Recently, Amin et al.'s proposed a mutual authentication and session key agreement protocol and claimed that their scheme is secure against all possible attacks. In this paper, we show that not only their scheme is vulnerable to privileged-insider attack, replay attack, session key disclosure attack, but also does not provide patient untraceability and backward secrecy. In order to withstand the mentioned security weaknesses, we propose an efficient remote mutual authentication scheme for the systems which are using ECC and Fuzzy Extractor. The proposed scheme not only resists against different security attacks, but it also provides an efficient registration, login, mutual authentication, session key agreement, and password and biometric update phases. During the experimentation, it has been observed that the proposed scheme is secure against various known attacks. Beside, our scheme is robust against privileged-insider attack that it rarely checked in security analysis. The informal analysis will ensure that our scheme provides well security protection against the different security attacks. Furthermore, we analyzed the security of the scheme using AVISPA software and Random Oracle Model. The formal analysis results and performance evaluation vouch that our scheme is also secure and efficient in computation and communication cost.
C1 [Ravanbakhsh, Niloofar] Imam Reza Int Univ, Dept Comp Engn, Mashhad, Iran.
   [Nazari, Mahboubeh] Ferdowsi Univ Mashhad, Dept Math, Mashhad, Iran.
C3 Ferdowsi University Mashhad
RP Nazari, M (corresponding author), Ferdowsi Univ Mashhad, Dept Math, Mashhad, Iran.
EM Niloofar_ravanbakhsh@yahoo.com; Ma.am.math@gmail.com
CR Amin Ruhul, 2015, 2015 International Conference on Cyber Situational Awareness, Data Analytics and Assessment (CyberSA). Proceedings, P1, DOI 10.1109/CyberSA.2015.7166114
   Amin R, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0318-z
   Amin R, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0351-y
   [Anonymous], HLPSL TUT BEG GUID M
   [Anonymous], P SAPS 04 AUSTR COMP
   [Anonymous], J MED SYSTEMS
   [Anonymous], Q CENTURY PUBLIC KEY
   [Anonymous], D2 3 INT FORM
   [Anonymous], 2005, Int. J. Inf. Secur., DOI [DOI 10.1007/S10207-004-0055-7, 10.1007/s10207-004-0055-7]
   [Anonymous], AVISPA V1 1 US MAN
   [Anonymous], 2013, J. Med. Syst.
   Armando, 2003, IST200139252
   Armando A, 2004, LECT NOTES COMPUT SC, V3229, P730, DOI 10.1007/978-3-540-30227-8_68
   Arshad H, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0136-8
   Boichut Y., 2004, Proc. Int. Workshop on Automated Verification of Infinite-State Systems (AVIS 2004), P1
   Chatterjee S, 2015, SECUR COMMUN NETW, V8, P1752, DOI 10.1002/sec.1140
   Chatterjee S, 2014, AD HOC SENS WIREL NE, V21, P121
   Chaudhry SA, 2015, J SUPERCOMPUT, P1
   Chaudhry SA, 2016, MULTIMED TOOLS APPL, V75, P12705, DOI 10.1007/s11042-015-3194-0
   Chaudhry SA, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0244-0
   Chen HM, 2012, J MED SYST, V36, P3907, DOI 10.1007/s10916-012-9862-y
   Chuang YH, 2010, INT J NETW MANAG, V20, P167, DOI 10.1002/nem.739
   Das AK, 2015, WIRELESS PERS COMMUN, V82, P1377, DOI 10.1007/s11277-015-2288-3
   Das AK, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9969-9
   Das AK, 2012, INFORM SCIENCES, V209, P80, DOI 10.1016/j.ins.2012.04.036
   Dodis Y, 2004, LECT NOTES COMPUT SC, V3027, P523
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   Hafizul Islam S. K., 2014, Journal of Electronics (China), V31, P473, DOI 10.1007/s11767-014-4002-0
   He DB, 2015, INT J AD HOC UBIQ CO, V18, P67, DOI 10.1504/IJAHUC.2015.067774
   He DB, 2014, IEEE T CONSUM ELECTR, V60, P30, DOI 10.1109/TCE.2014.6780922
   He DB, 2013, IEEE T CONSUM ELECTR, V59, P811, DOI 10.1109/TCE.2013.6689693
   He DB, 2012, J MED SYST, V36, P1989, DOI 10.1007/s10916-011-9658-5
   He DB, 2012, INFORM FUSION, V13, P223, DOI 10.1016/j.inffus.2011.01.001
   He LJ, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0196-4
   Islam SKH, 2016, INT J COMMUN SYST, V29, P1708, DOI 10.1002/dac.2793
   Islam SKH, 2015, WIRELESS PERS COMMUN, V84, P2013, DOI 10.1007/s11277-015-2542-8
   Islam SKH, 2015, INFORM SCIENCES, V312, P104, DOI 10.1016/j.ins.2015.03.050
   Islam SKH, 2014, WIRELESS PERS COMMUN, V79, P1975, DOI 10.1007/s11277-014-1968-8
   Islam SKH, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0135-9
   Jiang Q, 2013, J MED SYST, V37, DOI 10.1007/s10916-012-9897-0
   Khan Muhammad Khurram, 2012, Data and Knowledge Engineering. Third International Conference, ICDKE 2012. Proceedings, P243, DOI 10.1007/978-3-642-34679-8_22
   Khan MK, 2015, COMPUT SCI INF SYST, V12, P857, DOI 10.2298/CSIS141029030K
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Kumari S., 2015, PEERTOPEER NETWORKIN, P1
   Kumari S, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9952-5
   Lee CC, 2015, NONLINEAR DYNAM, V79, P2485, DOI 10.1007/s11071-014-1827-x
   Lee CC, 2013, NONLINEAR DYNAM, V71, P201, DOI 10.1007/s11071-012-0652-3
   Li CT, 2008, COMPUT COMMUN, V31, P2803, DOI 10.1016/j.comcom.2007.12.005
   Li WM, 2012, COMPUT COMMUN, V35, P188, DOI 10.1016/j.comcom.2011.09.003
   Li X, 2011, J NETW COMPUT APPL, V34, P73, DOI 10.1016/j.jnca.2010.09.003
   Lu YR, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0221-7
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Mishra D, 2016, PEER PEER NETW APPL, V9, P171, DOI 10.1007/s12083-014-0321-z
   Mishra D, 2014, J MED SYST, V38, DOI [10.1007/s10916-014-0120-3, 10.1007/s10916-014-0024-2]
   Nanni L, 2008, PATTERN RECOGN LETT, V29, P295, DOI 10.1016/j.patrec.2007.10.005
   Pu Q, 2012, J MED SYST, V36, P2609, DOI 10.1007/s10916-011-9735-9
   Ren YJ, 2015, J INTERNET TECHNOL, V16, P317, DOI 10.6138/JIT.2015.16.2.20140918
   Tan ZW, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0016-2
   Turuani M, 2006, LECT NOTES COMPUT SC, V4098, P277, DOI 10.1007/11805618_21
   Wang XM, 2007, COMPUT STAND INTER, V29, P507, DOI 10.1016/j.csi.2006.11.005
   Wazid M, 2016, SECUR COMMUN NETW, V9, P1983, DOI 10.1002/sec.1452
   Wei JH, 2012, J MED SYST, V36, P3597, DOI 10.1007/s10916-012-9835-1
   Wu SH, 2012, J MED SYST, V36, P2325, DOI 10.1007/s10916-011-9700-7
   Wu ZY, 2012, J MED SYST, V36, P1529, DOI 10.1007/s10916-010-9614-9
   Zhu ZA, 2012, J MED SYST, V36, P3833, DOI 10.1007/s10916-012-9856-9
NR 65
TC 29
Z9 29
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 55
EP 88
DI 10.1007/s11042-016-4208-2
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400003
DA 2024-07-18
ER

PT J
AU Han, MX
   Hu, HM
   Liu, Y
   Zhang, C
   Tian, RP
   Zheng, J
AF Han, Meng-Xiong
   Hu, Hai-Miao
   Liu, Yang
   Zhang, Chi
   Tian, Rong-Peng
   Zheng, Jin
TI An auto-encoder-based summarization algorithm for unstructured videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Auto-encoder; Video analysis
AB Video summarization is an effective way to quick view videos and relieve the pressure of videos storage. However the traditional algorithms are hardly adapted to unstructured videos, due to the unobvious for scenes changing and ignoring the structure of the videos. Therefore, an Auto-encoder-based summarization algorithm is proposed in this paper for unstructured videos. Each video structure is detected by an Auto-encoder and both of the interestingness and representativeness of each video segment are predicted by the reconstruction errors of the segment. Meanwhile, most interesting and representative summarization is generated with the limited summary length. The experimental results show that the proposed algorithm obtained a better performance by comparing with the state-of-the-art.
C1 [Han, Meng-Xiong; Hu, Hai-Miao; Zhang, Chi; Tian, Rong-Peng; Zheng, Jin] Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100083, Peoples R China.
   [Liu, Yang] Beijing Inst Graph, Beijing 100029, Peoples R China.
   [Zheng, Jin] Beihang Univ, Digital Media Lab, Beijing, Peoples R China.
C3 Beihang University; Beihang University
RP Hu, HM (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100083, Peoples R China.
EM frank0139@163.com
RI zhang, chi/GRX-3610-2022; Zhang, Cheng/JAD-2236-2023; zhang,
   chao/IXD-9965-2023; zhang, chao/HTO-2468-2023
FU National Natural Science Foundation of China [61370121]; National
   Hi-Tech Research and Development Program (863 Program) of China
   [2014AA015102]
FX This work was partially supported by the National Natural Science
   Foundation of China (No. 61370121), the National Hi-Tech Research and
   Development Program (863 Program) of China (No. 2014AA015102).
CR [Anonymous], P 15 INT C MULT
   [Anonymous], 2013, P IEEE C COMP VIS PA
   [Anonymous], 2014, EUR C COMP VIS
   [Anonymous], TEXT SUMM BRANCH OUT
   [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], 2014, ADV NEURAL INFORM PR
   Basak J, 2008, PATT REC 2008 ICPR 2
   Chu Wen-Sheng, 2015, P IEEE C COMP VIS PA
   Dang CT, 2014, IEEE T IMAGE PROCESS, V23, P2704, DOI 10.1109/TIP.2014.2320814
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Japkowicz N., 1995, Ijcai
   Kang H-W, 2005, P 13 ANN ACM INT C M
   Lee YJ, 2012, CVPR, V2
   Li K, 2015, IEEE T PATTERN ANAL, V37, P1233, DOI 10.1109/TPAMI.2014.2361133
   Luan Q, 2014, MULT EXP ICME 2014 I
   Mahmoud KM, 2013, MACH LEARN APPL ICML
   Manevitz LM, 2002, J MACH LEARN RES, V2, P139, DOI 10.1162/15324430260185574
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Mei SH, 2015, PATTERN RECOGN, V48, P522, DOI 10.1016/j.patcog.2014.08.002
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Rumelhart DE, 1985, CALIFORNIA U SAN DIE, DOI DOI 10.21236/ADA164453
   Sun Min, 2014, EUR C COMP VIS
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Tsai CM, 2013, IEEE T CIRC SYST VID, V23, P1927, DOI 10.1109/TCSVT.2013.2269186
   Valdés V, 2012, MULTIMED TOOLS APPL, V59, P795, DOI 10.1007/s11042-011-0774-5
   Wang ZK, 2014, MULTIMED TOOLS APPL, V73, P519, DOI 10.1007/s11042-013-1619-1
   Weninger F, 2014, AC SPEECH SIGN PROC
   Xu J, 2015, P IEEE C COMP VIS PA
   Yang Huan, 2015, P IEEE INT C COMP VI
   Yeung S., 2014, ARXIV14065824
   Zhao Bin, 2014, P IEEE C COMP VIS PA, P2
NR 32
TC 3
Z9 3
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25039
EP 25056
DI 10.1007/s11042-017-4485-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300026
DA 2024-07-18
ER

PT J
AU Itier, V
   Puech, W
AF Itier, V.
   Puech, W.
TI High capacity data hiding for 3D point clouds based on Static Arithmetic
   Coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D point clouds; Hamiltonian path; Synchronization; High capacity
   data-hiding; Security analysis
ID POLYGONAL MESHES; STEGANOGRAPHIC ALGORITHM; TRIANGLE MESHES;
   WATERMARKING; COMPRESSION; DISTORTION
AB 3D meshes are widely used today in very different domains for examples; game, medical diagnostic, CAD (computed aided design) or more recently 3D printing. In this paper we provide a new data hiding method that has a huge capacity, c p=3xcx(n-1) bits where n is the vertex number of the mesh and c is a non null positive integer. Our proposed method synchronizes vertices along a Hamiltonian path, thus we obtained an ordered list of edges. To do this, we have developed a method based on the displacement of a 3D vertex relative to its father in the path. Its new location is computed with static arithmetic coding (SAC) in order to embed data on each coordinate of a vector defined by an edge. Thus, the proposed method is set as a function of the message in order to control the distortions. Moreover, it allows to set the capacity while achieving a better security. Experimental results show that the method has a high capacity and a low distortion while ensuring security of the hidden message.
C1 [Itier, V.; Puech, W.] Univ Montpellier, CNRS, LIRMM, UMR 5506, 860 Rue St Priest,Bat 5, F-34095 Montpellier, France.
   [Itier, V.] STRATEGIES SA, Parc Affaires Icade,56 Rue Arcueil, F-94578 Rungis, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite
   Paul-Valery; Universite Perpignan Via Domitia; Universite de Montpellier
RP Itier, V (corresponding author), Univ Montpellier, CNRS, LIRMM, UMR 5506, 860 Rue St Priest,Bat 5, F-34095 Montpellier, France.; Itier, V (corresponding author), STRATEGIES SA, Parc Affaires Icade,56 Rue Arcueil, F-94578 Rungis, France.
EM vincent.itier@lirmm.fr
RI Itier, Vincent/AAH-8626-2019
OI Puech, William/0000-0001-9383-2401
CR Alface Patrice Rondao, 2007, Transactions on Data Hiding and Multimedia Security II. (Lecture Notes in Computer Science vol. 4499), P91
   Amat P, 2010, SIGNAL PROCESS-IMAGE, V25, P400, DOI 10.1016/j.image.2010.05.002
   [Anonymous], 1996, TECHNICAL REPORT
   [Anonymous], ACM T MULTIMEDIA COM
   [Anonymous], 1883, J SCI MILITAIRES
   Bogomjakov A, 2008, COMPUT GRAPH FORUM, V27, P637, DOI 10.1111/j.1467-8659.2008.01161.x
   Bors AG, 2013, IEEE T IMAGE PROCESS, V22, P1822, DOI 10.1109/TIP.2012.2236345
   Cayre F, 2003, IEEE T SIGNAL PROCES, V51, P939, DOI 10.1109/TSP.2003.809380
   Chao MW, 2009, IEEE T VIS COMPUT GR, V15, P274, DOI 10.1109/TVCG.2008.94
   Chen B, 2001, J VLSI SIG PROCESS S, V27, P7, DOI 10.1023/A:1008107127819
   Cheng YM, 2007, VISUAL COMPUT, V23, P721, DOI 10.1007/s00371-007-0147-2
   Cho JW, 2007, IEEE T SIGNAL PROCES, V55, P142, DOI 10.1109/TSP.2006.882111
   Fridrich J., 2009, INFORM HIDING
   Gao XF, 2012, ACM T MULTIM COMPUT, V8, P1
   Gurung T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964962
   Hamilton WR, 1853, P ROY IRISH ACAD, V6, P462
   Huang YH, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0051-x
   Itier V, 2015, P SOC PHOTO-OPT INS, V9393
   Itier V, 2013, IEEE INT WORKSH MULT, P105, DOI 10.1109/MMSP.2013.6659272
   Kalker T, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P201, DOI 10.1109/MMSP.2001.962734
   Kanai S., 1998, IFIP WG, P296
   Kaveh H, 2015, SECUR COMMUN NETW, V8, P159, DOI 10.1002/sec.968
   Lavoué G, 2011, COMPUT GRAPH FORUM, V30, P1427, DOI 10.1111/j.1467-8659.2011.02017.x
   Lavoué G, 2010, IEEE T MULTIMEDIA, V12, P636, DOI 10.1109/TMM.2010.2060475
   Li MT, 2011, INT J INNOV COMPUT I, V7, P1055
   Li ZY, 2016, INT CONF ACOUST SPEE, P2144, DOI 10.1109/ICASSP.2016.7472056
   Pérez-Freire L, 2009, IEEE T INF FOREN SEC, V4, P2, DOI 10.1109/TIFS.2008.2009603
   RISSANEN J, 1979, IBM J RES DEV, V23, P149, DOI 10.1147/rd.232.0149
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   Tu SC, 2010, VISUAL COMPUT, V26, P1177, DOI 10.1007/s00371-009-0398-1
   Vasic B, 2013, IEEE T MULTIMEDIA, V15, P1532, DOI 10.1109/TMM.2013.2265673
   Wang K, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1235
   Wang K, 2011, COMPUT GRAPH-UK, V35, P1, DOI 10.1016/j.cag.2010.09.010
   Wang K, 2008, IEEE T INF FOREN SEC, V3, P620, DOI 10.1109/TIFS.2008.2007229
   Wang K, 2008, IEEE T MULTIMEDIA, V10, P1513, DOI 10.1109/TMM.2008.2007350
   Yang Y, 2014, IEEE IMAGE PROC, P4782, DOI 10.1109/ICIP.2014.7025969
   Yang Y, 2013, IEEE T VIS COMPUT GR, V19, P45, DOI 10.1109/TVCG.2012.106
   Yeo BL, 1999, IEEE COMPUT GRAPH, V19, P36, DOI 10.1109/38.736467
   Zhang J, 2013, VISUAL COMPUT, V29, P717, DOI 10.1007/s00371-013-0808-2
NR 39
TC 13
Z9 14
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26421
EP 26445
DI 10.1007/s11042-016-4163-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500041
DA 2024-07-18
ER

PT J
AU Feng, FB
   Ran, Q
   Li, W
AF Feng, Fubiao
   Ran, Qiong
   Li, Wei
TI Multi-level fusion of graph based discriminant analysis for
   hyperspectral image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral data; Dimensionality reduction; Graph embedding;
   Multi-level fusion; D-S evidence theory
ID DIMENSIONALITY REDUCTION; SPARSE GRAPH; REPRESENTATION; SUBSPACE
AB Based on the graph-embedding framework, sparse graph-based discriminant analysis (SGDA), collaborative graph-based discriminant analysis (CGDA) and low rankness graph based discriminant analysis (LGDA) have been proposed with different graph construction. However, due to the inherent characteristics of a"" (1)-norm, a"" (2)-norm and nuclear-norm, single graph may be not optimal in capturing global and local structure of the data. In this paper, a multi-level fusion strategy is proposed in combining the three graph construction methods: 1) multiple graphs-based discriminant analysis (MGDA) in feature level with adaptive weights; 2) decision level fusion with D-S theory (GDA-DS), followed by a typical support vector machine (SVM) classification. Experimental results on three hyperspectral images datasets demonstrate that results with the fused strategy prevails with better classification performance.
C1 [Feng, Fubiao; Ran, Qiong; Li, Wei] Beijing Univ Chem Technol, Coll Informat Sci & Technol, Beijing 100029, Peoples R China.
C3 Beijing University of Chemical Technology
RP Ran, Q (corresponding author), Beijing Univ Chem Technol, Coll Informat Sci & Technol, Beijing 100029, Peoples R China.
EM ranqiong@mail.buct.edu.cn
RI LI, WEI/ABD-5001-2021
FU National Natural Science Foundation of China [NSFC-61571033, 61302164,
   61501017]; Fundamental Research Funds for the Central Universities
   [BUCTRC201401, BUCTRC201615, YS1404, XK1521, ZY1504]
FX This work was supported by the National Natural Science Foundation of
   China under Grants No. NSFC-61571033, 61302164, 61501017 and partly by
   the Fundamental Research Funds for the Central Universities under Grants
   No. BUCTRC201401, BUCTRC201615, YS1404, XK1521, ZY1504.
CR [Anonymous], 1998, STAT LEARNING THEORY
   Bao BK, 2012, IEEE T IMAGE PROCESS, V21, P3794, DOI 10.1109/TIP.2012.2192742
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Bo CJ, 2016, REMOTE SENS LETT, V7, P915, DOI 10.1080/2150704X.2016.1196836
   Bo CJ, 2016, IEEE GEOSCI REMOTE S, V13, P177, DOI 10.1109/LGRS.2015.2504449
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Du Q, 2008, IEEE GEOSCI REMOTE S, V5, P564, DOI 10.1109/LGRS.2008.2000619
   Fauvel M, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/783194
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2004, ADV NEUR IN, V16, P153
   Kang XD, 2015, IEEE T GEOSCI REMOTE, V53, P2241, DOI 10.1109/TGRS.2014.2358615
   Kang XD, 2014, IEEE T GEOSCI REMOTE, V52, P2666, DOI 10.1109/TGRS.2013.2264508
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Li W, 2011, IEEE GEOSCI REMOTE S, V8, P894, DOI 10.1109/LGRS.2011.2128854
   Li W, 2015, PATTERN RECOGN, V48, P3904, DOI 10.1016/j.patcog.2015.05.024
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Li W, 2014, IEEE T GEOSCI REMOTE, V52, P3399, DOI 10.1109/TGRS.2013.2272760
   Li W, 2014, IEEE GEOSCI REMOTE S, V11, P153, DOI 10.1109/LGRS.2013.2250905
   Li W, 2013, IEEE GEOSCI REMOTE S, V10, P1374, DOI 10.1109/LGRS.2013.2242042
   Li W, 2012, IEEE T GEOSCI REMOTE, V50, P1185, DOI 10.1109/TGRS.2011.2165957
   Ly NH, 2014, IEEE J-STARS, V7, P2688, DOI 10.1109/JSTARS.2014.2315786
   Ly NH, 2014, IEEE T GEOSCI REMOTE, V52, P3872, DOI 10.1109/TGRS.2013.2277251
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Plaza A, 2005, IEEE T GEOSCI REMOTE, V3, P43
   Rohban MH, 2012, PATTERN RECOGN, V45, P1363, DOI 10.1016/j.patcog.2011.09.001
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shaw G, 2002, IEEE SIGNAL PROC MAG, V19, P12, DOI 10.1109/79.974715
   Su HJ, 2011, IEEE GEOSCI REMOTE S, V8, P1135, DOI 10.1109/LGRS.2011.2158185
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Zeng DH, 2008, J COMPUT, V3, P36
   Zhuang LS, 2012, PROC CVPR IEEE, P2328, DOI 10.1109/CVPR.2012.6247944
NR 34
TC 2
Z9 2
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22959
EP 22977
DI 10.1007/s11042-016-4183-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200055
DA 2024-07-18
ER

PT J
AU Muthukumar, P
   Balasubramaniam, P
   Ratnavelu, K
AF Muthukumar, P.
   Balasubramaniam, P.
   Ratnavelu, K.
TI A novel cascade encryption algorithm for digital images based on
   anti-synchronized fractional order dynamical systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractional order system; Hyperchaos; Anti-synchronization; Image
   encryption
ID CHAOTIC SYSTEM; CONTROLLER-DESIGN; MODEL
AB In this paper, an active control technique is employed for anti-synchronization between two identical fractional order reverse butterfly-shaped hyperchaotic systems. We have shown that the convergence rate of anti-synchronization error is very faster by increasing the value of an active controller gain. A new algorithm for image encryption and decryption is introduced and established by anti-synchronized fractional order dynamical systems. Experimental results show that the proposed encryption algorithm has high level security against various attacks. Further, it confirms that the new algorithm is more efficient compared to other existing algorithms.
C1 [Muthukumar, P.; Balasubramaniam, P.] Deemed Univ, Gandhigram Rural Inst, Dept Math, Dindigul 624302, Tamil Nadu, India.
   [Muthukumar, P.; Ratnavelu, K.] Univ Malaya, Fac Sci, Inst Math Sci, Kuala Lumpur 50603, Malaysia.
C3 Gandhigram Rural Institute; Universiti Malaya
RP Balasubramaniam, P (corresponding author), Deemed Univ, Gandhigram Rural Inst, Dept Math, Dindigul 624302, Tamil Nadu, India.
EM muthukumardgl@gmail.com; balugru@gmail.com; kuru052001@gmail.com
RI P, Balasubramaniam/O-3041-2013; Ratnavelu, Kurunathan/A-5463-2009;
   Muthukumar, P./J-2764-2014
OI Muthukumar, P./0000-0001-7152-2947
FU University of Malaya HIR, Malaysia [UM.C/625/1/HIR/MOHE/SC/13]
FX This work was supported by the University of Malaya HIR Grant
   UM.C/625/1/HIR/MOHE/SC/13, Malaysia.
CR Aghababa MP, 2014, COMPLEXITY, V20, P37, DOI 10.1002/cplx.21502
   Balasubramaniam P, 2015, NONLINEAR DYNAM, V80, P249, DOI 10.1007/s11071-014-1865-4
   Bhalekar S., 2014, World J Model Simul, V10, P60
   CAPUTO M, 1967, GEOPHYS J ROY ASTR S, V13, P529, DOI 10.1111/j.1365-246X.1967.tb02303.x
   Chen DY, 2013, NONLINEAR DYNAM, V73, P1495, DOI 10.1007/s11071-013-0880-1
   Delavari H, 2013, ASIAN J CONTROL, V15, P783, DOI 10.1002/asjc.677
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   He JB, 2015, J APPL ANAL COMPUT, V5, P197
   Huang X, 2015, ENTROPY-SWITZ, V17, P28, DOI 10.3390/e17010028
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Jian X., 2011, INT J PHYS SCI, V6, P2478
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Kwuimy CAK, 2015, NONLINEAR DYNAM, V80, P491, DOI 10.1007/s11071-014-1883-2
   Li HL, 2015, NONLINEAR DYNAM, V79, P919, DOI 10.1007/s11071-014-1711-8
   Li RH, 2014, NONLINEAR DYNAM, V76, P785, DOI 10.1007/s11071-013-1169-0
   Liang Y, 2015, MULTIMED TOOLS APPL, P1
   Liu HJ, 2015, OPT COMMUN, V338, P340, DOI 10.1016/j.optcom.2014.10.021
   Liu HJ, 2014, AEU-INT J ELECTRON C, V68, P676, DOI 10.1016/j.aeue.2014.02.002
   Lopes AM, 2016, NONLINEAR DYNAM, V84, P79, DOI 10.1007/s11071-015-2231-x
   Matignon D., 1996, Symposium on Control, Optimization and Supervision. CESA '96 IMACS Multiconference. Computational Engineering in Systems Applications, P963
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Asheghan MM, 2013, APPL MATH COMPUT, V222, P712, DOI 10.1016/j.amc.2013.07.045
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Muthukumar P, 2015, NONLINEAR DYNAM, V80, P1883, DOI 10.1007/s11071-014-1583-y
   Muthukumar P, 2014, NONLINEAR DYNAM, V77, P1547, DOI 10.1007/s11071-014-1398-x
   Muthukumar P, 2013, NONLINEAR DYNAM, V74, P1169, DOI 10.1007/s11071-013-1032-3
   Muthukumar P, 2014, CHAOS, V24, P105
   Norouzi B, 2015, MULTIMED TOOLS APPL, P1
   Qin WY, 2014, J VIB CONTROL, V20, P146, DOI 10.1177/1077546312463749
   Ratnavelu, 2015, INT J DYNAMICS CONTR, V5, P1
   Razminia A, 2013, J COMPUT NONLIN DYN, V8, DOI 10.1115/1.4023165
   Srivastava M, 2014, NONLINEAR DYNAM, V76, P905, DOI 10.1007/s11071-013-1177-0
   Tavazoei MS, 2007, PHYS LETT A, V367, P102, DOI 10.1016/j.physleta.2007.05.081
   Wu GC, 2016, J VIB CONTROL, V22, P2092, DOI 10.1177/1077546315574649
   Wu XJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119660
   Wu XJ, 2014, COMMUN NONLINEAR SCI, V19, P1884, DOI 10.1016/j.cnsns.2013.10.025
   XU J, 2009, J UNCERTAIN SYSTEMS, V3, P137
   Xu Y, 2014, COMMUN NONLINEAR SCI, V19, P3735, DOI 10.1016/j.cnsns.2014.02.029
   Yao W, 2015, NONLINEAR DYNAM, V81, P151, DOI 10.1007/s11071-015-1979-3
   Zhang RX, 2014, SYST SCI CONTROL ENG, V2, P751, DOI 10.1080/21642583.2014.891955
   Zhong JP, 2015, IEEE T CONTR SYST T, V23, P1648, DOI 10.1109/TCST.2014.2382642
NR 42
TC 17
Z9 17
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23517
EP 23538
DI 10.1007/s11042-016-4052-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700018
DA 2024-07-18
ER

PT J
AU Wang, GD
   Lu, JG
   Pan, ZK
   Miao, QG
AF Wang, Guodong
   Lu, Jingge
   Pan, Zhenkuan
   Miao, Qiguang
TI Color texture segmentation based on active contour model with
   multichannel nonlocal and Tikhonov regularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color texture segmentation; Active contour model; Nonlocal operator;
   Tikhonov regularization; Split-Bregman algorithm
ID NONLINEAR STRUCTURE TENSOR; IMAGE SEGMENTATION; UNSUPERVISED
   SEGMENTATION; SNAKES; CUTS
AB Color texture image segmentation is one of the fundamental task in image processing. For segmenting the color texture, we propose a new active contour model based on multichannel nonlocal and Tikhonov regularization. In the new model, nonlocal operator and Tikhonov regularization are simultaneously contributing to the evolutionary process of the active contour. The nonlocal operator which is based on the image slice similarity can direct the contour evolution on the boundary of the object and is not affected by the texture. The Tikhonov regularization can diffuse the texture areas and then accelerate the evolution process of the active contour. In order to ease the solution of the energy function, we also design the Split-Bregman algorithm of the proposed method. Expeimental color texture image segmentation results demonstrate the validity of the proposed method.
C1 [Wang, Guodong; Lu, Jingge; Pan, Zhenkuan] Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Peoples R China.
   [Miao, Qiguang] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
C3 Qingdao University; Xidian University
RP Wang, GD (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Peoples R China.
EM doctorwgd@gmail.com
OI Miao, Qiguang/0000-0002-2872-388X
FU National Natural Science Foundation of China [61305045]; National
   "Twelfth Five-Year" development plan of science and technology
   [2013BAI01B03, 2014BAG03B05]
FX This work was supported by National Natural Science Foundation of China
   (No. 61305045), National "Twelfth Five-Year" development plan of science
   and technology (No. 2013BAI01B03, No. 2014BAG03B05).
CR Aujol JF, 2003, IEEE T IMAGE PROCESS, V12, P1634, DOI 10.1109/TIP.2003.819309
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chen SF, 2010, IEEE T IMAGE PROCESS, V19, P2254, DOI 10.1109/TIP.2010.2047164
   Cimpoi M, 2015, PROC CVPR IEEE, P3828, DOI 10.1109/CVPR.2015.7299007
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592
   Goldstein T, 2009, 0906 CAM
   Han SD, 2011, PATTERN RECOGN, V44, P503, DOI 10.1016/j.patcog.2010.09.006
   Han SD, 2009, IEEE T IMAGE PROCESS, V18, P2289, DOI 10.1109/TIP.2009.2025560
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Li L, 2013, SIGNAL PROCESS, V93, P2559, DOI 10.1016/j.sigpro.2013.02.010
   Lu JG, 2017, MULTIMED TOOLS APPL, V76, P10991, DOI 10.1007/s11042-016-3462-7
   Lui D, 2014, IEEE T IMAGE PROCESS, V23, P855, DOI 10.1109/TIP.2013.2295752
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Meila M., 2005, P 22 INT C MACHINE L, P577
   Sagiv C., 2004, IEEE T IMAGE PROCESS, V1, P1
   Savelonas MA, 2008, PATTERN RECOGN LETT, V29, P1404, DOI 10.1016/j.patrec.2008.02.013
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Siddiqi K, 1998, IEEE T IMAGE PROCESS, V7, P433, DOI 10.1109/83.661193
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Wang GD, 2014, J APPL MATH, DOI 10.1155/2014/614613
   Wu QG, 2015, NEUROCOMPUTING, V151, P1133, DOI 10.1016/j.neucom.2014.04.085
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005
   Zhou HL, 2013, PATTERN RECOGN, V46, P1719, DOI 10.1016/j.patcog.2012.12.005
NR 29
TC 6
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24515
EP 24526
DI 10.1007/s11042-016-4136-1
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700062
DA 2024-07-18
ER

PT J
AU Zhuang, PX
   Huang, Y
   Zeng, DL
   Ding, XH
AF Zhuang, Peixian
   Huang, Yue
   Zeng, Delu
   Ding, Xinghao
TI Non-blind deconvolution with l1-norm of high-frequency fidelity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-blind deconvolution; Image high-frequency; l1-norm fidelity; Least
   square integration
ID HEVC MOTION ESTIMATION; MANY-CORE PROCESSORS; PARALLEL FRAMEWORK;
   IMAGE-RESTORATION; IMPULSIVE NOISE; ALGORITHMS
AB Non-blind deconvolution has been a long-standing challenge of both image structures preservation and blur and noise removal. However, most existing methods conduct the direct deconvolution on the degraded image, and overlook the difference between low-frequency and high-frequency of the image. Based on the observation that high-frequency (e. g., edges and structures) is more important than low-frequency in image deblurring, we present a novel method for non-blind deconvolution by incorporating the l 1 -norm fidelity of image high-frequency. Firstly, the l 1 -norm fidelity of image high-frequency is proposed in the overall objective function for image structures preservation and noise suppression, and then alternating minimization iterative method is employed to estimate high-frequency components of the image. Secondly, high-frequency estimations are taken as constraint terms, and least square integration and fast fourier transform are efficiently exploited to recover the ideal image. Finally, experimental simulations demonstrate that the proposed algorithm outperforms other state-of-the-art methods in both subjective and objective assessments.
C1 [Zhuang, Peixian; Zeng, Delu] Xiamen Univ, Sch Informat Sci & Technol, Xiamen, Peoples R China.
   [Huang, Yue; Ding, Xinghao] Xiamen Univ, Xiamen, Peoples R China.
C3 Xiamen University; Xiamen University
RP Ding, XH (corresponding author), Xiamen Univ, Xiamen, Peoples R China.
EM dxh@xmu.edu.cn
FU National Natural Science Foundation of China [61571382, 61571005,
   81301278, 61172179, 61103121]; Guangdong Natural Science Foundation
   [2015A030313007]; Fundamental Research Funds for the Central
   Universities [20720160075, 20720150169, 20720150093]; Research Fund for
   the Doctoral Program of Higher Education [20120121120043]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61571382, 61571005, 81301278, 61172179,
   and 61103121, in part by the Guangdong Natural Science Foundation under
   Grant 2015A030313007, in part by the Fundamental Research Funds for the
   Central Universities under Grant 20720160075, 20720150169 and
   20720150093, and in part by the Research Fund for the Doctoral Program
   of Higher Education under Grant 20120121120043.
CR Almeida MSC, 2010, IEEE T IMAGE PROCESS, V19, P36, DOI 10.1109/TIP.2009.2031231
   [Anonymous], 2011, CVPR
   Bar L, 2007, IEEE T IMAGE PROCESS, V16, P1101, DOI 10.1109/TIP.2007.891805
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Chan T., 2005, MATH MODELS COMPUTER, V17
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   CSISZAR I, 1991, ANN STAT, V19, P2032, DOI 10.1214/aos/1176348385
   Dong WS, 2011, IEEE I CONF COMP VIS, P1259, DOI 10.1109/ICCV.2011.6126377
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   Juan Li, 2012, 16th International Conference on Evaluation & Assessment in Software Engineering (EASE 2012), P12, DOI 10.1049/ic.2012.0002
   Kim TH, 2015, PROC CVPR IEEE, P5426, DOI 10.1109/CVPR.2015.7299181
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Pan JS, 2014, PROC CVPR IEEE, P2901, DOI 10.1109/CVPR.2014.371
   Patel VM, 2012, IEEE T IMAGE PROCESS, V21, P94, DOI 10.1109/TIP.2011.2159803
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schmidt U, 2013, PROC CVPR IEEE, P604, DOI 10.1109/CVPR.2013.84
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Shi JP, 2015, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2015.7298665
   Tai YW, 2012, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2012.6247653
   Tikhonov A. N., 1943, Dokl. Akad. Nauk SSSR, V39, P195
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yan M. Y., 2011, THESIS
   Yan M, 2013, SIAM J IMAGING SCI, V6, P1227, DOI 10.1137/12087178X
   Yang H, 2015, PROC CVPR IEEE, P705, DOI 10.1109/CVPR.2015.7298670
   Yang JF, 2009, SIAM J SCI COMPUT, V31, P2842, DOI 10.1137/080732894
   Zhang HC, 2013, IEEE T CYBERNETICS, V43, P1035, DOI 10.1109/TSMCB.2012.2222375
   Zhang J, 2014, IEEE T CIRC SYST VID, V24, P915, DOI 10.1109/TCSVT.2014.2302380
   Zhong L, 2013, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2013.85
   Zhu X, 2010, IEEE T IMAGE PROCESS, V19, P3116, DOI 10.1109/TIP.2010.2052820
NR 42
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23607
EP 23625
DI 10.1007/s11042-016-4083-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700022
DA 2024-07-18
ER

PT J
AU Ou, XY
   Ling, HF
   Liu, S
   Lei, J
AF Ou, Xinyu
   Ling, Hefei
   Liu, Si
   Lei, Jie
TI Hierarchical deep semantic hashing for fast image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hierarchical deep semantic hashing; Similarity search; Large-scale image
   retrieval; Convolutional neural network
AB Content-Based large-scale image retrieval has recently attracted considerable attention because of the explosive increase of online images. Inspired by recent advances in convolutional neural networks, we propose a hierarchical deep semantic method for learning similarity function that solves the problems of precision and speed of retrieval in the setting of large-scale environments. The distinctive contribution of our work is a novel approach that can utilize previous knowledge of the semantic hierarchy. When semantic information and a related hierarchy structure are available, significant improvements can be attained. Exploiting hierarchical relationships is the most important thing for large-scale issues. Binary code can be learned from deep neural network for representing the latent concepts that dominate the semantic labels. Different from other supervised methods that require learning an explicit hashing function to map the binary code features from the images, our method learns Hierarchical Deep Semantic Hashing code (HDSH-code) and image representations in an implicit manner, making it suitable for large-scale datasets. An additional contribution is a novel hashing scheme (generated at the same time with semantic information) that is able to reduce the computational cost of retrieval. Comprehensive experiments were conducted on Holidays, Oxford5k/105k, Caltech256 retrieval datasets, our HDSH performs competitively even when the convolutional neural network has been pre-trained for a surrogate unrelated task. We further demonstrates its efficacy and scalability on a large-scale dataset Imagenet with millions of images. With deep hierarchical semantic hashing, we report retrieval times are 0.15ms and 53.92ms on Holidays and Imagenet dataset, respectively.
C1 [Ou, Xinyu; Ling, Hefei; Lei, Jie] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
   [Ou, Xinyu] Yunnan Open Univ, Yunnan Prov Cadres Online Learning Coll, Kunming, Yunnan, Peoples R China.
   [Ou, Xinyu; Liu, Si] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
C3 Huazhong University of Science & Technology; Chinese Academy of
   Sciences; Institute of Information Engineering, CAS
RP Ling, HF (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
EM ouxinyu@hust.edu.cn; lhefei@hust.edu.cn; liusi@iie.ac.cn;
   lei_jie@hust.edu.cn
OI ou, xinyu/0000-0002-2905-426X
FU Natural Science Foundation of China [U1536203, 61272409]; Major
   Scientific and Technological Innovation Project of Hubei Province
   [2015AAA013]; Nature Science Foundation of the Open University of China
   [G16F3702Z, G16F2505Q]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant U1536203 and 61272409, in part by the Major Scientific
   and Technological Innovation Project of Hubei Province under Grant
   2015AAA013, the Nature Science Foundation of the Open University of
   China under Grant G16F3702Z and G16F2505Q. The authors appreciate the
   valuable suggestions from the anonymous reviewers and the Editors.
CR [Anonymous], 2015, P 29 ANN C NEUR INF
   [Anonymous], 2013, P 21 ACM INT C MULT, DOI 10.1145/2502081.2502171
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Chechik G, 2010, J MACH LEARN RES, V11, P1109
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Griffin G., 2007, CALTECH 256 OBJECT C
   Han GL, 2015, IEEE IC COMP COM NET
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2014, PROC CVPR IEEE, P3310, DOI 10.1109/CVPR.2014.417
   Jia D, 2011, PROC CVPR IEEE, P785, DOI 10.1109/CVPR.2011.5995516
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A., 2011, P ESANN, VVolume 1, P2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Norouzi M.E., 2011, ICML
   Ntalianis K, 2014, MULTIMED TOOLS APPL, V69, P397, DOI 10.1007/s11042-012-0995-2
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Perronnin F, 2010, PROC CVPR IEEE, P3384, DOI 10.1109/CVPR.2010.5540009
   Razavian A. S., 2016, ITE Trans. Media Technol. Appl., V4, P251, DOI [DOI 10.3169/MTA.4.251, 10.3169/mta.4.251]
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky O, 2014, INT J COMPUT VIS, V1-42
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang N, 2013, P ADV NEURAL INFORM
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763
   Zhao WL, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.99
NR 40
TC 2
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21281
EP 21302
DI 10.1007/s11042-016-4057-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400044
DA 2024-07-18
ER

PT J
AU Tiwari, D
   Tyagi, V
AF Tiwari, Deepshikha
   Tyagi, Vipin
TI An auto tuned noise resistant descriptor for dynamic texture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic texture; Local binary pattern; Uniform pattern; Noise resistance
ID LOCAL BINARY PATTERNS; CLASSIFICATION
AB This paper presents a scheme for the representation and recognition of the dynamic texture in the noisy environment. Dynamic texture is the sequence of images of a moving scene that shows some form of temporal regularity. Though, the dynamic texture is the spatiotemporal extension of the conventional texture, its analysis requires additional attention, since the motion causes continuous changes in the geometry of these textures. Hence, to recognize the noisy dynamic texture, the noise should be estimated not only at the spatial level; it must also be estimated at the temporal level. To this end, an auto tuned noise resistance descriptor, based on the Local Binary Pattern approach, is proposed for the modeling and classification of the dynamic texture. Our approach based on the fact that, uniform local binary patterns are the fundamental units of image texture and occur more frequently in an image in comparison to non-uniform patterns. Noise affects these uniform local binary patterns and more likely fall into non-uniform codes. To counter this, we have extended conventional local binary pattern descriptor from a 2-value code to a 3-value code to include an additional state (called indecisive state) to represent the noise affected pixels. However, the estimation of the indecisive state is of the primary concern of this letter due to the inherently varying nature of the dynamic texture. The proposed technique devised a new scheme to estimate the noisy pixels in a dynamic texture. Eventually, the indecisive state is corrected back to non-noisy natural states using a mapping function so as to form a uniform LBP code. Experimental results on the UCLA and Dyntex++ databases demonstrate high classification efficiency of the proposed approach in the noisy environment.
C1 [Tiwari, Deepshikha] Jaypee Univ Engn & Technol, Dept Comp Sci & Engn, Guna, MP, India.
   [Tyagi, Vipin] Jaypee Univ Engn & Technol, Deparment CSE, Guna, MP, India.
RP Tyagi, V (corresponding author), Jaypee Univ Engn & Technol, Deparment CSE, Guna, MP, India.
EM dr.vipin.tyagi@gmail.com
RI tiwari, Deepshikha/C-9942-2017; Tyagi, Vipin/I-2451-2013
OI Tyagi, Vipin/0000-0003-4994-3686
CR Ahonen T., 2007, P FINN SIGN PROC S
   Chan AB, 2005, PROC CVPR IEEE, P846
   Chen J, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.122
   Chetverikov D, 2005, ADV SOFT COMP, P17
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Fathi A, 2012, PATTERN RECOGN LETT, V33, P1093, DOI 10.1016/j.patrec.2012.01.017
   Ghanem B., 2010, LECT NOTES COMPUT SC, P223
   Hossain S, 2013, PATTERN RECOGN LETT, V34, P2007, DOI 10.1016/j.patrec.2013.02.009
   Jianfeng Ren, 2015, Pattern Recognition, V48, P3180, DOI 10.1016/j.patcog.2015.02.001
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Péteri R, 2010, PATTERN RECOGN LETT, V31, P1627, DOI 10.1016/j.patrec.2010.05.009
   Ravichandran A, 2009, PROC CVPR IEEE, P1651, DOI 10.1109/CVPRW.2009.5206847
   Ren JF, 2013, INT CONF ACOUST SPEE, P2400, DOI 10.1109/ICASSP.2013.6638085
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Saisan P, 2001, PROC CVPR IEEE, P58
   Tiwari D, 2017, MULTIMED TOOLS APPL, V76, P6623, DOI 10.1007/s11042-016-3362-x
   Tiwari D, 2016, ADV INTELL SYST COMP, V434, P365, DOI 10.1007/978-81-322-2752-6_36
   Tiwari D, 2016, MULTIDIM SYST SIGN P, V27, P563, DOI 10.1007/s11045-015-0319-6
   Zhao G, 2009, P IAPR C MACH VIS AP, P327
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao G, 2007, LECT NOTES COMPUT SC, V4358, P165
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627
NR 25
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21225
EP 21246
DI 10.1007/s11042-016-4066-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400041
DA 2024-07-18
ER

PT J
AU Park, K
AF Park, KyoungJong
TI A Grey-based risk selection model using fuzzy information of a supply
   chain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Uncertainty; Complexity; Risk; Supply chain; Grey-based risk selection
   model
AB A supply chain is easily exposed to risk by uncertainty and complexity and enterprises being difficult to cope with it because the risk involved is not clear in the aspect of time, intensity, duration, and etc. If the risk in a supply chain is probable or even possible, an enterprise should take action to prevent it according to the precautionary principle. If there is any risk, an enterprise should make a strategy to minimize the impact of the risk and act it. This paper proposes a Grey-based risk selection model to consider the many aspects of intensity and possibility of risk in a supply chain. The intensity and possibility of occurring risk are vague and cannot be expressed by exact numerical values. The Grey-based approach has the ability to measure, model, calculate and integrate uncertainty of a supply chain. The proposed model analyzes various risks to evaluate risk in a supply chain and priorities the seriousness of risk to control it.
C1 [Park, KyoungJong] Gwangju Univ, Sch Business, Dept Business Adm, Gwangju 503703, South Korea.
C3 Gwangju University
RP Park, K (corresponding author), Gwangju Univ, Sch Business, Dept Business Adm, Gwangju 503703, South Korea.
EM kjpark@gwangju.ac.kr
RI Park, KyoungJong/Q-9879-2019
OI Park, KyoungJong/0000-0002-8079-6461
CR [Anonymous], 2002, Grey System Theory
   Baskaran V, 2012, INT J PROD ECON, V135, P647, DOI 10.1016/j.ijpe.2011.06.012
   Brito AJ, 2010, EUR J OPER RES, V200, P812, DOI 10.1016/j.ejor.2009.01.016
   Chen HP, 2015, MULTIMED TOOLS APPL, V27, P1
   Chianese A, 2004, MULTIMED TOOLS APPL, V23, P237, DOI 10.1023/B:MTAP.0000031759.22145.5d
   Chithambaranathan P, 2015, INT J PROD ECON, V166, P163, DOI 10.1016/j.ijpe.2015.01.002
   Chopra S, 2004, MIT SLOAN MANAGE REV, V46, P53
   Claypool E, 2014, COMPUT IND ENG, V78, P44, DOI 10.1016/j.cie.2014.09.026
   Deng Julong, 1989, Journal of Grey Systems, V1, P1
   Fahimnia B, 2015, EUR J OPER RES, V247, P1, DOI 10.1016/j.ejor.2015.04.034
   Heckmann I, 2015, OMEGA-INT J MANAGE S, V52, P119, DOI 10.1016/j.omega.2014.10.004
   Hofmann H, 2014, BUS STRATEG ENVIRON, V23, P160, DOI 10.1002/bse.1778
   Li GD, 2007, MATH COMPUT MODEL, V46, P573, DOI 10.1016/j.mcm.2006.11.021
   Memon MS, 2015, EXPERT SYST APPL, V42, P7951, DOI 10.1016/j.eswa.2015.06.018
   Svensson G., 2000, International Jour- nal of Physical Distribution & Logistics Management, V30, P731
   Wu T, 2009, MANAGING SUPPLY CHAIN RISK AND VULNERABILITY, P1, DOI 10.1007/978-1-84882-634-2
   Yang CC, 2006, J MANUF TECHNOL MANA, V17, P926, DOI 10.1108/17410380610688241
NR 17
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 18083
EP 18097
DI 10.1007/s11042-016-3740-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800028
DA 2024-07-18
ER

PT J
AU Singh, SK
   Tiwari, S
   Abidi, AI
   Singh, A
AF Singh, Sanjay Kumar
   Tiwari, Shrikant
   Abidi, Ali Imam
   Singh, Aruni
TI Prediction of pain intensity using multimedia data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pain; Pain expression; Pain intensity; Machine learning; Intelligent
   computing system
ID SENSING ION CHANNELS; RELIABILITY; RECOGNITION; SCALES
AB Increased medical expenditure, improper treatment, decreased productivity and above all inadequate pain, assessment is the global challenging problem, causing a substantial burden on the individual, their family, and society which often leads to loss of interest in life. The facial expression variation generally reflects clue for the occurrence of pain. This offers a vital aspect for non-verbal patients who are not in a position to rate their pain intensity level. The hypothesis proposes the developing of a multimodal machine based tool which will assess pain intensity. A framework has been designed to meet up with these specific issues which involve extracting features from the face and genes involved in pain. Patients suffering from pain require a comprehensive assessment to be conducted for proper diagnosis. The contributions of this paper are fourfold: Firstly, this paper provides an efficient approach to computational pain quantification. Secondly, it investigates the medical practitioner perception to pain along with the readings of the various tools available. Thirdly, the psychological aspect is taken into consideration to predict how pain is perceived by observers and experts (physicians). Fourthly, genes involved in pain and no pain conditions are taken and classified. Three large databases of spontaneous pain expressions are used i.e., McMaster UNBC Pain Archive database, self-prepared database and the other BioVid heat pain database of pain to verify the accuracy and robustness of the system. The methodology achieves 87% accuracy rate for classification of frames amid four levels of pain intensity. Designing intelligent computing systems with the given methodology will certainly improve the quality of life of patients.
C1 [Singh, Sanjay Kumar] Rajarshi Sch Management & Technol, Dept Comp Sci, Varanasi, Uttar Pradesh, India.
   [Tiwari, Shrikant] Fac Engn & Technol, Durg, Chattisgarh, India.
   [Abidi, Ali Imam] Natl Inst Design, Ahmadabad, Gujarat, India.
   [Singh, Aruni] Kamala Nehru Inst Technol, Dept Comp Sci & Engn, Sultanpur, UP, India.
C3 National Institute of Design (NID)
RP Singh, SK (corresponding author), Rajarshi Sch Management & Technol, Dept Comp Sci, Varanasi, Uttar Pradesh, India.
EM sanjursmt@gmail.com; shrikant.rs.cse@iitbhu.ac.in;
   abidi.rs.cse12@iitbhu.ac.in; arunisingh@rocketmail.com
RI Singh, Sanjay Kumar/AAC-2031-2022; Singh, Sanjay Kumar/AAI-9853-2020;
   Tiwari, Dr. Shrikant/I-3296-2017
OI Singh, Sanjay Kumar/0000-0002-9061-6313; Tiwari, Dr.
   Shrikant/0000-0001-6947-2362; Abidi, Ali/0000-0002-7420-0027
CR Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007
   Basbaum AI, 2009, CELL, V139, P267, DOI 10.1016/j.cell.2009.09.028
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Breivik H, 2008, BRIT J ANAESTH, V101, P17, DOI 10.1093/bja/aen103
   Burckhardt C.S., 2003, ARTHRITIS RHEUMATISM, V49, P96, DOI [10.1002/art.11440, DOI 10.1002/ART.11440]
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Debono DJ, 2013, J AM OSTEOPATH ASSOC, V113, P620, DOI 10.7556/jaoa.2013.023
   Eisenberger NI, 2005, SOCIAL OUTCAST OSTRA, P210
   Ekman P, 2002, TECHNIQUE MEASUREMEN
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   FERRAZ MB, 1990, J RHEUMATOL, V17, P1022
   Gea J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0104381
   Hadjistavropoulos HD, 1996, PAIN, V65, P251, DOI 10.1016/0304-3959(95)00218-9
   Hammal Z, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P47, DOI 10.1145/2388676.2388688
   Hammal Z, 2012, PATTERN RECOGN, V45, P1265, DOI 10.1016/j.patcog.2011.09.014
   HUSKISSON EC, 1974, LANCET, V2, P1127, DOI 10.1016/S0140-6736(74)90884-8
   JENSEN MP, 1986, PAIN, V27, P117, DOI 10.1016/0304-3959(86)90228-9
   Krishtal O, 2003, TRENDS NEUROSCI, V26, P477, DOI 10.1016/S0166-2236(03)00210-8
   Liu C, 1999, P 2 INT C AUD VID BA, P22
   Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Lucey P, 2012, IMAGE VISION COMPUT, V30, P197, DOI 10.1016/j.imavis.2011.12.003
   Lucey P, 2011, IEEE T SYST MAN CY B, V41, P664, DOI 10.1109/TSMCB.2010.2082525
   MCCORMACK HM, 1988, PSYCHOL MED, V18, P1007, DOI 10.1017/S0033291700009934
   McKinney Brett A, 2006, Appl Bioinformatics, V5, P77, DOI 10.2165/00822942-200605020-00002
   Prkachin KM, 2008, PAIN, V139, P267, DOI 10.1016/j.pain.2008.04.010
   Roelofs K, 2010, PSYCHOL SCI, V21, P1575, DOI 10.1177/0956797610384746
   Schnakers C, 2010, EXPERT REV NEUROTHER, V10, P1725, DOI [10.1586/ern.10.148, 10.1586/ERN.10.148]
   Simon D, 2008, PAIN, V135, P55, DOI 10.1016/j.pain.2007.05.008
   Walter Steffen, 2013, 2013 IEEE International Conference on Cybernetics (CYBCO), P128, DOI 10.1109/CYBConf.2013.6617456
   Wemmie JA, 2006, TRENDS NEUROSCI, V29, P578, DOI 10.1016/j.tins.2006.06.014
   Wemmie JA, 2013, NAT REV NEUROSCI, V14, P461, DOI 10.1038/nrn3529
   Williams ACD, 2000, PAIN, V85, P457, DOI 10.1016/S0304-3959(99)00299-7
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
NR 33
TC 6
Z9 6
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 19317
EP 19342
DI 10.1007/s11042-017-4718-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800053
DA 2024-07-18
ER

PT J
AU Singh, VK
   Sharma, G
   Kumar, M
AF Singh, Vishal Krishna
   Sharma, Gajendra
   Kumar, Manish
TI Compressed sensing based acoustic event detection in protected area
   networks with wireless multimedia sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic events; Compressed sensing; Principal component analysis;
   Wiener filter; Wireless multimedia sensors
ID CLASSIFICATION
AB Wireless multimedia sensors have been frequently used for detecting events in acoustic rich environments such as protected area networks. Such areas have diverse habitat, frequently varying terrain and are a source of very large number of acoustic events. This work is aimed at detecting the tree cutting event in a forest area, by identifying the acoustic pattern generated due to an axe hitting a tree bole, with the help of wireless multimedia sensors. A series of operations using the hamming window, wiener filter, Otsu thresholding and mathematical morphology are used for removing the unwanted clutter from the spectrogram obtained from such events. Using the sparse nature of the acoustic signals, a compressed sensing based energy efficient data gathering scheme is devised for accurate event reporting. A network of Mica2 motes is deployed in a real forest area to test the validity of the proposed scheme. Analytical and experimental results proves the efficacy of the proposed event detection scheme.
C1 [Singh, Vishal Krishna; Sharma, Gajendra; Kumar, Manish] Indian Inst Informat Technol, Dept Informat Technol, Allahabad, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Singh, VK (corresponding author), Indian Inst Informat Technol, Dept Informat Technol, Allahabad, Uttar Pradesh, India.
EM vashukrishna@gmail.com
RI Sharma, Gajendra/AAM-2393-2020; Sharma, Gajendra/AAH-8689-2020; Singh,
   Vishal Krishna/ACZ-1600-2022
OI Singh, Vishal Krishna/0000-0002-5438-579X; Kumar,
   Manish/0000-0002-1311-0976
CR Alhilal MS, 2015, INT J DISTRIB SENS N, V2015, P24
   Bhatt R, 2016, WIREL NETW, V22, P267, DOI 10.1007/s11276-015-0971-7
   Bilinska K., 2007, MICA MICA2 MICAZ
   Cai YL, 2009, IEEE T COMPUT, V58, P1259, DOI 10.1109/TC.2009.40
   Ghadi M, 2016, MULTIMED TOOLS APPL, V75, P3425, DOI 10.1007/s11042-014-2443-y
   Huang CJ, 2009, EXPERT SYST APPL, V36, P3737, DOI 10.1016/j.eswa.2008.02.059
   Phan H, 2015, IEEE-ACM T AUDIO SPE, V23, P20, DOI 10.1109/TASLP.2014.2367814
   Kiktova-Vozarikova E, 2015, MULTIMED TOOLS APPL, V74, P4213, DOI 10.1007/s11042-013-1529-2
   Kos M, 2013, DIGIT SIGNAL PROCESS, V23, P659, DOI 10.1016/j.dsp.2012.10.008
   Kotus J, 2014, MULTIMED TOOLS APPL, V68, P5, DOI 10.1007/s11042-012-1183-0
   Küçükbay SE, 2015, IEEE INT C SEMANT CO, P475, DOI 10.1109/ICOSC.2015.7050855
   Lee Y, 2013, IEEE T CONSUM ELECTR, V59, P615, DOI 10.1109/TCE.2013.6626247
   Li Q, 2015, INT J DISTRIB SENS N, V2015, P4
   Lopatka K, 2016, MULTIMED TOOLS APPL, V75, P10407, DOI 10.1007/s11042-015-3105-4
   Ludeña-Choez J, 2015, COMPUT SPEECH LANG, V30, P32, DOI 10.1016/j.csl.2014.04.001
   Mellinger DK, 2011, J ACOUST SOC AM, V129, P4055, DOI 10.1121/1.3531926
   Mesaros A, 2010, EUR SIGNAL PR CONF, P1267
   Molina-Pico A, 2016, J SENSORS, V2016, DOI 10.1155/2016/8325845
   Peng GD, 2015, MOL PHYLOGENET EVOL, V84, P145, DOI 10.1016/j.ympev.2014.06.016
   Sahin YG, 2009, SENSORS-BASEL, V9, P1485, DOI 10.3390/s90301485
   Sandhan T, 2014, INT C CONTR AUTOMAT, P82, DOI 10.1109/ICCAS.2014.6987963
   Singh VK, 2016, INT J ADV COMPUT SC, V7, P58
   Talukder A, 2014, MULTIMED TOOLS APPL, V70, P237, DOI 10.1007/s11042-012-1088-y
NR 23
TC 9
Z9 10
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18531
EP 18555
DI 10.1007/s11042-016-4241-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800018
DA 2024-07-18
ER

PT J
AU Feng, JH
   Zhang, J
   Zhu, XS
   Lian, WW
AF Feng, Junhong
   Zhang, Jie
   Zhu, Xiaoshu
   Lian, Wenwu
TI A novel chaos optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Optimization; Chaotic map; Optimization algorithm
AB In this paper, by analyzing the best chaotic sequences generated by sixteen different chaotic maps, a novel chaos optimization algorithm is presented. It can intelligently base on different chaotic maps to select different strategies so as to map the chaotic variables into the optimization variables. For the proposed algorithm, the obtained best values, the run time, and the role of the first and the second stage search by using different chaotic maps are also analyzed and compared. The simulation results implemented on several classic test functions demonstrate that the proposed algorithm has a high performance and an outstanding efficiency.
C1 [Feng, Junhong; Zhang, Jie; Zhu, Xiaoshu; Lian, Wenwu] Yulin Normal Univ, Sch Comp Sci & Engn, Yulin 537000, Guangxi, Peoples R China.
   [Feng, Junhong; Zhang, Jie; Zhu, Xiaoshu; Lian, Wenwu] Yulin Normal Univ, Guangxi Coll & Univ Key Lab Complex Syst Optimiza, Yulin 537000, Guangxi, Peoples R China.
C3 Yulin Normal University; Yulin Normal University
RP Zhang, J; Zhu, XS (corresponding author), Yulin Normal Univ, Sch Comp Sci & Engn, Yulin 537000, Guangxi, Peoples R China.; Zhang, J; Zhu, XS (corresponding author), Yulin Normal Univ, Guangxi Coll & Univ Key Lab Complex Syst Optimiza, Yulin 537000, Guangxi, Peoples R China.
EM jgxyfjh@126.com; jgxyzjzj@126.com; jgxyzxs@126.com; jgxylww@126.com
OI Zhang, Jie/0000-0002-1078-1766; Feng, Junhong/0000-0001-6443-3153
FU Guangxi Universities Key Project of Science and Technology Research
   [KY2015ZD099]; Guangxi Natural Science Foundation [2014GXNSFBA118268,
   2014GXNSFBA118010]; Scientific Research Staring Foundation for the PHD
   Scholars of Yulin Normal University [G2014005]; Key Project of Yulin
   Normal University [2014YJZD05]; Open Foundation for Guangxi Colleges and
   Universities Key Lab of Complex System Optimization and Big Data
   Processing [2015CSOBDP0301, 2015CSOBDP0303]
FX This research was supported by Guangxi Universities Key Project of
   Science and Technology Research (No. KY2015ZD099), Guangxi Natural
   Science Foundation (No. 2014GXNSFBA118268,2014GXNSFBA118010), Scientific
   Research Staring Foundation for the PHD Scholars of Yulin Normal
   University (No. G2014005), Key Project of Yulin Normal University (No.
   2014YJZD05), and Open Foundation for Guangxi Colleges and Universities
   Key Lab of Complex System Optimization and Big Data Processing (No.
   2015CSOBDP0301,2015CSOBDP0303).
CR [Anonymous], INTRO CHAOS THEORY
   Cheng Zhi-gang, 2007, Systems Engineering and Electronics, V29, P103
   Erramilli A., 1994, MODELING PACKET TRAF
   Feldman D.P., 2012, Chaos and fractals: An elementary introduction, DOI 10.1093/acprof:oso/9780199566433.001.0001
   Fister I, 2015, APPL MATH COMPUT, V252, P155, DOI 10.1016/j.amc.2014.12.006
   Tomida AG, 2008, INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCES AND ITS APPLICATIONS, PROCEEDINGS, P321, DOI 10.1109/ICCSA.2008.7
   Gandomi AH, 2013, COMMUN NONLINEAR SCI, V18, P89, DOI 10.1016/j.cnsns.2012.06.009
   Ji MJ, 2004, CHAOS SOLITON FRACT, V21, P933, DOI 10.1016/j.chaos.2003.12.032
   Jie Zhang, 2009, Proceedings of the 2009 International Conference on Computational Intelligence and Security (CIS 2009), P282, DOI 10.1109/CIS.2009.111
   Li YT, 2011, NEURAL COMPUT APPL, V20, P133, DOI 10.1007/s00521-010-0432-2
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Shayeghi H, 2010, ENERG CONVERS MANAGE, V51, P1572, DOI 10.1016/j.enconman.2010.02.015
   Tavazoei MS, 2007, APPL MATH COMPUT, V187, P1076, DOI 10.1016/j.amc.2006.09.087
   Yan HK, 2014, INT C ELECTR MACH SY, P2265, DOI 10.1109/ICEMS.2014.7013870
   Yuan XF, 2014, APPL SOFT COMPUT, V17, P12, DOI 10.1016/j.asoc.2013.12.016
   Zhao D, 2015, ANALOG INTEG CIRC SI, P1
NR 16
TC 60
Z9 73
U1 8
U2 79
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17405
EP 17436
DI 10.1007/s11042-016-3907-z
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500030
DA 2024-07-18
ER

PT J
AU Guna, J
   Stojmenova-Duh, E
   Pogacnik, M
AF Guna, Joze
   Stojmenova-Duh, Emilija
   Pogacnik, Matevz
TI Users' viewpoint of usability and user experience testing procedure -
   gaining methodological insights in a case of an interactive HbbTV
   application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE TV and Internet; User study; User experience; User centered design;
   Human-computer interaction; Meta-methodology; SEE TV-WEB project
AB We present a novel meta-methodological approach for the user experience and usability methodology procedure evaluation, shown in an example of the user experience and usability study of an interactive HbbTV application. The idea behind this research is not only to evaluate and improve the TV-WEB service but also to gain insights how the participants perceived the whole Ux evaluation procedure itself. The research questions focused mainly on the time complexity (temporal demand) and the frustration level of the TV-WEB evaluation procedure. Additionally the appropriateness of the selected content used, interface and interaction design, and the service impressions and satisfaction/payment related questions was sought. A special questionnaire based on the NASA TLX standard test is presented. The concept has been successfully implemented in several live field trials in three countries (BiH, Serbia and Montenegro). In the user experience and usability study of the service itself more than 150 participants were involved, of those 35 took part in the meta-methodology study. The feedback was quantitatively evaluated on a 7-point Likert scale, with "1" indicating the best positive feedback, "4" neutral/undecided feedback and "7" the most negative feedback. The quantitative average summary results obtained in the three evaluation studies were 1.30 for both the BiH and Serbia test study cases and the score of 1.22 for the test study case in Montenegro. These results show that a great majority of the participants found the whole evaluation procedure time-wise and frustration-wise undemanding, with appropriate content, presentation style and overall attitude towards them. By using this approach it was possible to improve the user experience and usability methodology used, producing more reliable results and providing better user experience in the final version of the product as well as providing a pleasant experience during the testing of the product.
C1 [Guna, Joze; Stojmenova-Duh, Emilija; Pogacnik, Matevz] Univ Ljubljana, Fac Elect Engn, Trzaska 25, Ljubljana 1000, Slovenia.
C3 University of Ljubljana
RP Guna, J (corresponding author), Univ Ljubljana, Fac Elect Engn, Trzaska 25, Ljubljana 1000, Slovenia.
EM joze.guna@fe.uni-lj.si
RI Guna, Jože/AAO-8714-2020
OI Guna, Jože/0000-0002-5161-7751; Pogacnik, Matevz/0000-0002-6134-2827
CR Albert W., 2013, Measuring the User Experience
   [Anonymous], 2006, P HUM FACT ERG SOC A
   Bachmayer S, 2010, INT J WEB INF SYST, V6, P74, DOI 10.1108/17440081011034493
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Chorianopoulos K, 2008, INT J HUM-COMPUT INT, V24, P556, DOI 10.1080/10447310802205750
   ETSI, 2012, 102796 ETSI TS
   ETSI Digital Video Broadcasting (DVB, 2010, 102809 ETSI TS
   Guna J, 2014, P 7 INT WORKSH SEM A
   Guna J, 2013, INT SERIES INFORM SY, P5
   Lowdermilk T., 2013, User-centered design: A developer's guide to building user-friendly applications
   Lugmayr A., 2004, SIG COM TEC
   Lugmayr A, 2014, MULTIMED TOOLS APPL, V71, P7, DOI 10.1007/s11042-012-1346-z
   Pauzie A., 2008, P EUR C HUM INT DES
   Stojmenova E, 2013, PROCEEDINGS OF THE 17TH INTERNATIONAL ACADEMIC MINDTREK CONFERENCE, P17
NR 14
TC 2
Z9 2
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16125
EP 16143
DI 10.1007/s11042-016-3898-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100004
DA 2024-07-18
ER

PT J
AU Ju, CH
   Tao, WQ
AF Ju, Chunhua
   Tao, Wanqiong
TI A novel relationship strength model for online social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online social networks; Topic classification; Indirect relationship;
   K-means clustering method; ABC algorithm; Sentiment classification
AB One of the key foundations of personalized recommendation in a social network is the relationship strength between social network users. The improvement for recommendation accuracy is mostly tied to the precise evaluation of the relationship strengths. With most of the selected factors affecting the relationship strength between users are too simple, the existed researches show low accuracy in calculating the strength, especially those factors related to topic and indirect links. We propose an online social networks users relationship strength estimation model which incorporates topic classification and indirect relationship. We adopt K-means clustering method using ABC algorithm to cluster all the interactive activity documents and calculate the correlation between clusters and activity topic name. After that, we compute the relationship strength between users which belong to the same topic on top of the user profile and interaction data. To accomplish this we employ a language model based on sentiment classification approach and take similarity, timeliness, and interactivity into account. We conduct experiments on two microblog datasets and the results show that the proposed model is promising and can be used to improve the performances of various applications.
C1 [Ju, Chunhua] Zhejiang Gongshang Univ, Contemporary Business & Trade Res Ctr, Hangzhou 310018, Peoples R China.
   [Ju, Chunhua] Zhejiang Gongshang Univ, Contemporary Business & Collaborat Innovat Res Ct, Hangzhou 310018, Peoples R China.
   [Ju, Chunhua; Tao, Wanqiong] Zhejiang Gongshang Univ, Coll Comp Sci & Informat Engn, Hangzhou 310018, Peoples R China.
C3 Zhejiang Gongshang University; Zhejiang Gongshang University; Zhejiang
   Gongshang University
RP Tao, WQ (corresponding author), Zhejiang Gongshang Univ, Coll Comp Sci & Informat Engn, Hangzhou 310018, Peoples R China.
EM wwwwq721com@126.com
FU National Key Technology R&D Program of China [2014BAH24F06]; Natural
   Science Foundation of China [71571162]; Zhejiang Province philosophy
   social sciences planning project [16NDJC188YB]; College Students"
   science and technology innovation activities of Zhejiang Province
   [2016R408080]; Contemporary Business and Trade Research Center of
   Zhejiang Gongshang University which is the Key Research Institutes of
   Social Sciences and Humanities Ministry of Education [14JJD630011]
FX This research is supported by The National Key Technology R&D Program of
   China (Grant 2014BAH24F06); Natural Science Foundation of China (No.
   71571162); Zhejiang Province philosophy social sciences planning project
   (No. 16NDJC188YB); College Students" science and technology innovation
   activities of Zhejiang Province (2016R408080). This research is
   supported by the Contemporary Business and Trade Research Center of
   Zhejiang Gongshang University which is the Key Research Institutes of
   Social Sciences and Humanities Ministry of Education (14JJD630011). The
   authors also gratefully acknowledge the helpful comments and suggestions
   of the reviewers, which have improved the presentation.
CR [Anonymous], 2014, J COMPUT COMMUN, DOI DOI 10.4236/JCC.2014.24012
   Baecchi C, 2016, MULTIMED TOOLS APPL, V75, P2507, DOI 10.1007/s11042-015-2646-x
   Cheng W, 2015, J INTELLIGENCE, V08, P169
   Nuñez-Gonzalez JD, 2015, NEUROCOMPUTING, V166, P1, DOI 10.1016/j.neucom.2014.10.099
   Deng Z-S, 2015, JISUANJI YU XIANDAIH, V02, P30
   Gilbert E, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P211
   GRANOVETTER MS, 1973, AM J SOCIOL, V78, P1360, DOI 10.1086/225469
   [胡熠 Hu Yi], 2007, [计算机研究与发展, Journal of Computer Research and Development], V44, P1469, DOI 10.1360/crad20070904
   Ju CH, 2013, SCI WORLD J, DOI 10.1155/2013/869658
   Kim M, 2013, MULTIMED TOOLS APPL, V64, P505, DOI 10.1007/s11042-011-0897-8
   Li P, 2015, APPL RES COMPUTERS, V07, P1
   Liu FK, 2010, EXPERT SYST APPL, V37, P4772, DOI 10.1016/j.eswa.2009.12.061
   Pham H., 2013, SIGMOD, DOI DOI 10.1145/2463676.2465301
   Shen H, 2014, J CHINA SOC SCI TECH, V8, P846
   Wilson C, 2009, EUROSYS'09: PROCEEDINGS OF THE FOURTH EUROSYS CONFERENCE, P205
   Wu FZ, 2016, NEUROCOMPUTING, V175, P599, DOI 10.1016/j.neucom.2015.10.101
   Xiang R, 2010, P ACM INT C WORLD WI
   Xu K, 2016, NEUROCOMPUTING, V174, P605, DOI 10.1016/j.neucom.2015.09.070
   Zhao Wenbing, 2013, Journal of the China Society for Scientific and Technical Information, V32, P511, DOI 10.3772/j.issn.1000-0135.2013.05.009
   Zhao XJ, 2012, NEUROCOMPUTING, V95, P89, DOI 10.1016/j.neucom.2011.06.036
   Zhou XK, 2015, MULTIMED TOOLS APPL, V74, P5015, DOI 10.1007/s11042-014-2230-9
   Zhu W, 2014, RES MODAL PARAMETERS, P1
NR 22
TC 9
Z9 12
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17577
EP 17594
DI 10.1007/s11042-017-4408-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500039
DA 2024-07-18
ER

PT J
AU Zhang, N
   Jeong, HY
AF Zhang, Ning
   Jeong, Hwa-Young
TI A retrieval algorithm for specific face images in airport surveillance
   multimedia videos on cloud computing platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Airport security; Multimedia video; Specific face image; Retrieval;
   Cloud computing platform
AB During retrieval process for specific face images in the airport surveillance multimedia video on cloud computing platform, because pattern of faces are complicated and vulnerable to interference, when the traditional algorithm is used for face retrieval, the accuracy and efficiency are reduced and robustness is low. A new retrieval algorithm for specific face images is proposed, and this method is deployed to the cloud computing platform. Harr face cascade classifier is used to detect face images in airport surveillance multimedia video, in order to find out the missing face in airport surveillance multimedia video, the block matching method is introduced for face tracking, and the missing face in the video is obtained. PCA method is utilized to extract specific facial features, and discriminant analysis method is used to compare the extracted feature information with the specific face, so as to realize the specific face image retrieval. Experimental results show that the proposed algorithm has a high retrieval efficiency and precision.
C1 [Zhang, Ning] Guangzhou Civil Aviat Coll, Guangzhou, Guangdong, Peoples R China.
   [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, Kyung Hee Univ 1 Hoegi Dong, Seoul, South Korea.
C3 Guangzhou Civil Aviation College; Kyung Hee University
RP Jeong, HY (corresponding author), Kyung Hee Univ, Humanitas Coll, Kyung Hee Univ 1 Hoegi Dong, Seoul, South Korea.
EM hyjeong@khu.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR [Anonymous], 2012, ECCV
   Bilal M, 2014, REMOTE SENS ENVIRON, V153, P50, DOI 10.1016/j.rse.2014.07.015
   Chen L, 2015, TIP
   Cowen AS, 2014, NEUROIMAGE, V94, P12, DOI 10.1016/j.neuroimage.2014.03.018
   Du Y, 2016, J MOD OPTIC, V63, P536, DOI 10.1080/09500340.2015.1083131
   Gao X, 2015, TIP
   Hong DAI, 2014, ELECT DES ENG, V22, P86
   Jarvela T, 2014, KNEE SURG SPORT TR A, V15, P500
   Kassubeck M, 2015, TIP
   Kong SG, 2015, IEEE T IMAGE PROCESS, V24, P1801, DOI 10.1109/TIP.2015.2405483
   Li ZF, 2014, IEEE T IMAGE PROCESS, V23, P2436, DOI 10.1109/TIP.2014.2315920
   Liao M-y, 2015, COMPUT SIMUL, V7, P32
   Lin KC, 2015, IEEE IMTC P, P1078, DOI 10.1109/I2MTC.2015.7151421
   Liu S, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/503924
   Liu S, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/281707
   Maghari A, 2014, IET COMPUT VIS, V8, P441, DOI 10.1049/iet-cvi.2013.0220
   Mbouna RO, 2015, HEAD POSE ESTIMATION
   Moon HM, 2015, I SYMP CONSUM ELECTR, P7, DOI 10.1109/ICCE.2015.7066297
   Muraki T, 2013, AV REL SEC ARES 2013, P517
   Santemiz P, 2013, BIOMETRICS SPECIAL I, P1
   Tsai R, 2014, IEEE J ROBOTIC AUTOM, V3, P323
   Voynichka V, 2015, TECHN HOM SEC HIST, P1
   Wen LY, 2013, IMAGE VISION COMPUT, V31, P392, DOI 10.1016/j.imavis.2013.03.001
   Yao HZ, 2014, OPT EXPRESS, V22, P25149, DOI 10.1364/OE.22.025149
   Zhang G, 2013, PATTERN RECOGN, V46, P642, DOI 10.1016/j.patcog.2012.08.013
   Zhang Q, 2014, J INF PROCESS SYST, V10, P523, DOI 10.3745/JIPS.01.0005
   Zhou H, 2015, TIP
NR 27
TC 3
Z9 3
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17129
EP 17143
DI 10.1007/s11042-016-3640-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500014
DA 2024-07-18
ER

PT J
AU Memon, MH
   Li, JP
   Memon, I
   Arain, QA
AF Memon, Muhammad Hammad
   Li, Jian-Ping
   Memon, Imran
   Arain, Qasim Ali
TI GEO matching regions: multiple regions of interests using content based
   image retrieval based on relative locations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Image clustering; Principal component analysis;
   Spectral clustering; Curvelet transform
ID INVARIANT CURVELET FEATURES; RECOGNITION; DESCRIPTOR; COLOR; SPEED;
   QUERY
AB Information retrieval systems are getting more attention in the era of multimedia technologies such as an image, video, audio and text files. The large numbers of images are challenges in computer systems field to store, manage data effectively and efficiently. The shape retrieval feature of different objects in the image also remains a difficult problem due to distinct angle view of different objects in a scene only; few studies have reported solution to the problem of finding relative locations of ROIs. In this paper, we proposed three methods such as1. Geolocation-based image retrieval (GLBIR), 2. Unsupervised feature technique Principal component analysis (PCA) and 3. multiple region-based image retrieval. The first proposed (GLBIR) method identifies geo location an image using visual attention based mechanism and its color layout descriptors. These features are extracted from geo-location of query image from Flickr database. Our proposed model does not fully semantic understanding of image content, uses visual metrics for example; the proximity, color contrast, size and nearness to image's boundaries to locate viewer's attention. We analyzed results and compared with state of art CBIR Systems and GLBIR Technique. Our second method to refine images exploiting and fusing by unsupervised feature technique using principal component analysis (PCA). The visually similar images clustering together with analyses image retrieval process and remove outliers initially retrieved image set by PCA. To evaluation our proposed approach, we used thousands of images downloaded from Flickr and CIFAR-10 databases using Flickr public API. Finally, we determinately proposed a system for image retrieval based on region. It provides a user interface for availing to designate the watershed ROI within an input image. During the retrieval of images,regions' feature vectors having codes of region homogeneous to a region of input image are utilized for comparison. Standard datasets are used for evaluation of proposed approach. The experiment demonstrates and effectiveness of the proposed method to achieve higher annotation performance increases accuracy and reduces image retrieval time. We evaluated our proposed approach on images dataset from Flickr and CIFAR-10.
C1 [Memon, Muhammad Hammad; Li, Jian-Ping] Univ Elect Sci & Technol, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
   [Memon, Imran] Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Peoples R China.
   [Arain, Qasim Ali] Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing, Peoples R China.
C3 University of Electronic Science & Technology of China; Zhejiang
   University; Beijing University of Posts & Telecommunications
RP Memon, I (corresponding author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Peoples R China.
EM imranmemon52@zju.edu.cn
RI li, jianping/A-9544-2012; memon, Imran/K-1647-2017; Chen,
   John/GPW-8839-2022; MEMON, MUHAMMAD HAMMAD/S-3320-2016
OI memon, Imran/0000-0002-8202-6604; MEMON, MUHAMMAD
   HAMMAD/0000-0002-8680-1831; Li, Jian Ping/0000-0003-2192-1450; Arain,
   Qasim Ali/0000-0003-2095-7435
FU National Natural Science Foundation of China [61370073]; National High
   Technology Research and Development Program of China [2007AA01Z423];
   Sichuan Province Science and technology support program [2013GZX0165,
   2013GZ0119]; Sichuan Province
FX This paper was supported by the National Natural Science Foundation of
   China (Grant No. 61370073), the National High Technology Research and
   Development Program of China (Grant No. 2007AA01Z423), Sichuan Province
   Science and technology support program (2013GZX0165), Sichuan Province
   Science and technology support program (2013GZ0119), Sichuan Province.
CR Agarwal M, 2012, INT J MULTIMED INF R, V1, P129, DOI 10.1007/s13735-012-0005-5
   Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   [Anonymous], P INT C PATT REC
   [Anonymous], IEEE 2006 8 INT C SI
   [Anonymous], WWW2012 COMPANION AP
   [Anonymous], 2010, P 2010 ACM MULT WORK
   [Anonymous], ICMR 14 P INT C MULT
   [Anonymous], ICMR 14 P INT C MULT
   [Anonymous], INT J IMAGE PROCESSI
   [Anonymous], WSDM 14 P 7 ACM INT
   [Anonymous], ICCV
   [Anonymous], 2011, INT J COMPUT APPL
   [Anonymous], ICMR 14 P INT C MULT
   [Anonymous], ICGST GVIP J
   [Anonymous], 076952128204 IEEE
   [Anonymous], ETRA 14 P S EY TRACK
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], SNC 14 P 2014 S SYMB
   [Anonymous], 2012, SIGNAL IMAGE PROCESS
   [Anonymous], ADV COMPUTER ENG
   [Anonymous], 2013, 21 SIGSPATIAL INT C, DOI DOI 10.1145/2525314.2525339
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], KDD 13 P 19 ACM SIGK
   Arampatzis A, 2013, INFORM PROCESS MANAG, V49, P274, DOI 10.1016/j.ipm.2012.03.005
   Ardeshir S, 2014, LECT NOTES COMPUT SC, V8694, P602, DOI 10.1007/978-3-319-10599-4_39
   Ardizzoni S., 1999, Proceedings. Tenth International Workshop on Database and Expert Systems Applications. DEXA 99, P167, DOI 10.1109/DEXA.1999.795161
   Avrithis Yannis, 2010, P 18 ACM INT C MULTI, P153, DOI 10.1145/1873951.1873973Place
   Blincoe K., 2012, Proc. Conf. Computer Supported Cooperative Work (CSCW 12), P1351
   Boujelhane I, 2014, IEEE I C CONS ELECT, P355, DOI 10.1109/ICCE-Berlin.2014.7034321
   Bulatov Y, 2004, LECT NOTES COMPUT SC, V3072, P753
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Choras RyszardS., 2007, INT J BIO BIOMED ENG, V1, P6
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Cusano C, 2004, PROC SPIE, V5304, P330
   de Santos-Sierra D., 2014, 2014 International Carnahan Conference on Security Technology (ICCST), P1
   Ding L, 2013, IEEE T POWER SYST, V28, P75, DOI 10.1109/TPWRS.2012.2197640
   Evans KK, 2005, J EXP PSYCHOL HUMAN, V31, P1476, DOI 10.1037/0096-1523.31.6.1476
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Gangopadhyay A, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P635, DOI 10.1109/ICIIP.2013.6707672
   Gosselin PH, 2008, IEEE T IMAGE PROCESS, V17, P1200, DOI 10.1109/TIP.2008.924286
   Hays J, 2008, PROC CVPR IEEE, P3436
   Huang DC, 2006, LECT NOTES COMPUT SC, V4282, P494
   Islam MM, 2009, IEEE INT CON MULTI, P562, DOI 10.1109/ICME.2009.5202558
   Jian MW, 2011, IMAGING SCI J, V59, P219, DOI 10.1179/136821910X12867873897355
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   Kaftan JN, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P365
   Kasutani E, 2001, IEEE IMAGE PROC, P674, DOI 10.1109/ICIP.2001.959135
   Khan FS, 2012, PROC CVPR IEEE, P3306, DOI 10.1109/CVPR.2012.6248068
   Khurana K., 2013, Int J Adv Res Comput Eng Technol (IJARCET), V2, P1383
   Kumar A, 2003, LECT NOTES COMPUT SC, V2688, P668
   Kumar A, 2006, IEEE T IMAGE PROCESS, V15, P2454, DOI 10.1109/TIP.2006.875214
   Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Marie desJardins., 2006, ICML 06, P273
   Memon I, 2015, WIRELESS PERS COMMUN, V82, P1585, DOI 10.1007/s11277-015-2300-y
   Memon I, 2015, WIRELESS PERS COMMUN, V80, P1347, DOI 10.1007/s11277-014-2082-7
   Memon MH, 2015, 2015 12TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P247, DOI 10.1109/ICCWAMTIP.2015.7493985
   Memon MH, 2014, 2014 11TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P271, DOI 10.1109/ICCWAMTIP.2014.7073406
   Memon MH, 2014, 2014 11TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P280, DOI 10.1109/ICCWAMTIP.2014.7073408
   Meng L, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P219, DOI 10.1145/2671188.2749362
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   NIE L, 2012, MM 12
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Oden C, 2003, PATTERN RECOGN LETT, V24, P2145, DOI 10.1016/S0167-8655(03)00087-4
   Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520
   Ramadevi Y., 2010, International Journal of Computer Science & Information Technology, V2, P153, DOI 10.5121/ijcsit.2010.2614
   Rowe RK, 2007, 2007 BIOMETRICS SYMPOSIUM, P18
   Saadatmand-Tarzjan M, 2007, IEEE T SYST MAN CY B, V37, P139, DOI 10.1109/TSMCB.2006.880137
   Sato YD, 2008, LECT NOTES COMPUT SC, V5163, P991, DOI 10.1007/978-3-540-87536-9_101
   Seber G A., 2009, Multivariate observations, DOI DOI 10.1002/9780470316641
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Shaikh RA, 2014, 2014 11TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P301, DOI 10.1109/ICCWAMTIP.2014.7073413
   Shimazaki H, 2007, NEURAL COMPUT, V19, P1503, DOI 10.1162/neco.2007.19.6.1503
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Siagian C, 2009, IEEE T ROBOT, V25, P861, DOI 10.1109/TRO.2009.2022424
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Sumana IJ, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P11, DOI 10.1109/MMSP.2008.4665041
   Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0
   Vu K, 2003, IEEE T KNOWL DATA EN, V15, P1045, DOI 10.1109/TKDE.2003.1209021
   Wagstaff KL, 2010, J EXP THEOR ARTIF IN, V22, P237, DOI 10.1080/09528130903119336
   WANG DL, 1995, IEEE T NEURAL NETWOR, V6, P283, DOI 10.1109/72.363423
   Wang HN, 2014, WSDM'14: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P203, DOI 10.1145/2556195.2556262
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wardhani A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P783, DOI 10.1109/ICME.2004.1394317
   Wong KM, 2005, IEEE INT SYMP CIRC S, P1541
   Yang C., 2006, P IEEE INT C COMPUTE, P2057
   Yeh CH, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2584105
   Yu ZW, 2012, INFORM SCIENCES, V203, P83, DOI 10.1016/j.ins.2012.03.012
   Zhang DS, 2012, INT J COMPUT VISION, V98, P187, DOI 10.1007/s11263-011-0503-6
   Zhang J, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 4, PROCEEDINGS, P740, DOI 10.1109/FSKD.2007.493
   Zhang Peng, 2004, Journal of Software, V15, P891
NR 97
TC 58
Z9 58
U1 0
U2 67
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15377
EP 15411
DI 10.1007/s11042-016-3834-z
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900009
DA 2024-07-18
ER

PT J
AU Assunçao, PAA
   Marcelino, S
   Soares, S
   de Faria, SMM
AF Amado Assuncao, Pedro A.
   Marcelino, Sylvain
   Soares, Salviano
   de Faria, Sergio M. M.
TI Spatial error concealment for intra-coded depth maps in multiview
   video-plus-depth
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Error concealment; Depth map; Multiview video-plus-depth; Spatial
   interpolation
ID IMAGE; DISPARITY
AB Transmission errors or packet loss in depth maps have great impact on the decoding quality and view synthesis of 3D and multiview video. Thus efficient methods to recover corrupted depth data are critical functions for accurate view rendering. This paper proposes an error concealment method for intra-coded depth maps, based on spatial intra and inter-view methods, which exploit neighbouring data of depth and colour images received error-free. A novel three-stage processing algorithm is devised to reconstruct sharp depth transitions (i.e. lost depth contours), using a disparity map and geometric interpolation based on parametric B,zier curves. The simulation results obtained from different views of various MVD sequences, for different packetisation modes and a wide range of packet loss rates (PLR), show that the proposed method consistently leads to quality improvement of synthesised images in comparison with reference methods.
C1 [Amado Assuncao, Pedro A.; Marcelino, Sylvain; de Faria, Sergio M. M.] Inst Telecomunicacoes, Leiria, Portugal.
   [Marcelino, Sylvain; Soares, Salviano] Univ Tras Os Montes & Alto Douro, ECT Engn Dept, Vila Real, Portugal.
   [Soares, Salviano] IEETA, UA Campus, Aveiro, Portugal.
   [Amado Assuncao, Pedro A.] Inst Politecn Leiria, ESTG, Leiria, Portugal.
   [de Faria, Sergio M. M.] Inst Politecn Leiria, ESTG, Dept Elect Engn, Leiria, Portugal.
C3 University of Tras-os-Montes & Alto Douro; Universidade de Aveiro;
   Polytechnic Institute of Leiria; Polytechnic Institute of Leiria
RP Assunçao, PAA (corresponding author), Inst Telecomunicacoes, Leiria, Portugal.; Assunçao, PAA (corresponding author), Inst Politecn Leiria, ESTG, Leiria, Portugal.
EM amado@co.it.pt; stam@co.it.pt; salblues@utad.pt; sergio.faria@co.it.pt
RI Assuncao, Pedro A. Amado/A-4827-2017; Faria, Sérgio/C-5245-2011; Soares,
   Salviano Pinto/ABC-8044-2020; Pinto Soares, Salviano/AAD-6332-2019
OI Assuncao, Pedro A. Amado/0000-0001-9539-8311; Faria,
   Sérgio/0000-0002-0993-9124; Soares, Salviano Pinto/0000-0001-5862-5706;
   Pinto Soares, Salviano/0000-0001-5862-5706
FU Fundacao para a Ciencia e Tecnologia, Portugal [SFRH/BD/64988/2009,
   PTDC/EEA-TEL 114487/2009]; Fundação para a Ciência e a Tecnologia
   [PTDC/EEA-TEL/114487/2009, SFRH/BD/64988/2009] Funding Source: FCT
FX This work was supported by the Fundacao para a Ciencia e Tecnologia,
   Portugal under PhD Grant SFRH/BD/64988/2009 and Project PTDC/EEA-TEL
   114487/2009.
CR Ali Abidah, 2010, Proceedings of the 2010 IEEE Student Conference on Research and Development (SCOReD 2010). Engineering: Innovation & Beyond, P421, DOI 10.1109/SCORED.2010.5704046
   [Anonymous], IWSSIP 16 18 JUN
   [Anonymous], M16090 ISOIEC JTC1SC
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CHEN YB, 2009, EURASIP, V2009, P1, DOI DOI 10.1155/2009/786015
   Chen Z, 2002, JVT 6 M AW ISL JAP
   Chung B, 2014, SIGNAL PROCESS-IMAGE, V29, P1121, DOI 10.1016/j.image.2014.09.009
   Chung TY, 2011, IEEE T CONSUM ELECTR, V57, P1336, DOI 10.1109/TCE.2011.6018892
   Chung TY, 2010, IEEE IMAGE PROC, P441, DOI 10.1109/ICIP.2010.5654236
   Ekmekcioglu E, 2011, IEEE J-STSP, V5, P352, DOI 10.1109/JSTSP.2010.2052783
   Hasan MM, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P181, DOI 10.1109/VCIP.2014.7051534
   Hewage C., 2011, Multimedia and Expo (ICME), 2011 IEEE International Conference on, P1
   Hewage Chaminda T. E. R., 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P149, DOI 10.1109/3DTV.2008.4547830
   Hewage CTER, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P485, DOI 10.1109/ICME.2008.4607477
   Hewage CTER, 2012, IEEE J-STSP, V6, P471, DOI 10.1109/JSTSP.2012.2195155
   Hughes J.F., 1990, Computer Graphics, Principles and Practice
   Jain R., 2010, TECHNICAL REPORT
   Khatoon S., 2015, 2015 ANN IEEE INDIA, P1, DOI [DOI 10.1109/INDICON.2015.7443701, 10.1109/INDICON.2015.7443701]
   Kim Y, 2007, IEEE T CONSUM ELECTR, V53, P712, DOI 10.1109/TCE.2007.381750
   Kordelas A, 2015, MULTIMED TOOLS APPL, P1
   Kosov S, 2009, LECT NOTES COMPUT SC, V5875, P796, DOI 10.1007/978-3-642-10331-5_74
   Lie WN, 2015, J VIS COMMUN IMAGE R, V32, P237, DOI 10.1016/j.jvcir.2015.08.012
   Lin TL, 2014, J VIS COMMUN IMAGE R, V25, P1811, DOI 10.1016/j.jvcir.2014.09.006
   Liu SJ, 2008, IEEE INT SYMP CIRC S, P3470, DOI 10.1109/ISCAS.2008.4542206
   Liu XM, 2011, PROCEEDINGS OF CHINA DISPLAY/ASIA DISPLAY 2011, P208, DOI 10.1109/ISCE.2011.5973815
   Liu YQ, 2010, IEEE T CIRC SYST VID, V20, P600, DOI 10.1109/TCSVT.2009.2035838
   Marcelino S, 2015, 3DTV C TRUE VIS CAPT, P1
   Marcelino S, 2011, INT C IM PROC ICIP B, P2293
   Merkle P., 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P245, DOI 10.1109/3DTV.2008.4547854
   Micallef B, 2010, P IFIP WIR DAYS OCT, P1
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Rares A, 2005, IEEE T IMAGE PROCESS, V14, P1454, DOI 10.1109/TIP.2005.854466
   Saponara S, 2003, PACK VID WORKSH PVWO
   Soares LD, 2004, IEEE T IMAGE PROCESS, V13, P586, DOI 10.1109/TIP.2004.823826
   Stankiewicz O., 2010, 2010 28th Picture Coding Symposium (PCS 2010), P498, DOI 10.1109/PCS.2010.5702546
   Tai SC, 2015, MULTIMED TOOLS APPL, P1
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiang XG, 2011, INT CONF ACOUST SPEE, P849
   Yan B, IEEE T CONSUMER ELEC, V53, P1546
   Yan B, 2012, MOL BIOL REP, P1
NR 41
TC 4
Z9 5
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 13835
EP 13858
DI 10.1007/s11042-016-3766-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800007
DA 2024-07-18
ER

PT J
AU Fernandes, P
   Bernardo, MV
   Pinheiro, AMG
   Fiadeiro, PT
   Pereira, M
AF Fernandes, Pedro
   Bernardo, Marco V.
   Pinheiro, Antonio M. G.
   Fiadeiro, Paulo T.
   Pereira, Manuela
TI Quality comparison of the HEVC and VP9 encoders performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video codecs; Visual communication; Image quality; Quality assessment
ID EFFICIENCY
AB This paper reports a comparison between two recent video codecs, namely the HEVC and the VP9, using High Definition Video Sequences encoded with different bit rates. A subjective test for the evaluation of the provided Quality of Experience is reported. The video sequences were shown to a panel of subjects on a High Definition LED display and the subjective tests were performed using a Single Stimulus Methodology. The results shown that the HEVC encoder provides a better visual quality on low bit rates than the VP9. Similar performance was obtained for visually lossless conditions, although the HEVC requires lower bit rates to reach that level. Moreover, the correlation of the subjective evaluation and three tested objective metrics (PSNR, SSIM, and FSIM) revealed a good representation of the subjective results, particularly the SSIM and the FSIM metrics.
C1 [Fernandes, Pedro; Bernardo, Marco V.; Pinheiro, Antonio M. G.; Pereira, Manuela] Univ Beira Interior, IT, Rua Marques Avila & Bolama, P-6201001 Covilha, Portugal.
   [Fiadeiro, Paulo T.] Univ Beira Interior, Fiber Mat & Environm Technol FibEnTech, Rua Marques Avila & Bolama, P-6201001 Covilha, Portugal.
C3 Universidade da Beira Interior; Instituto de Telecomunicacoes;
   Universidade da Beira Interior
RP Bernardo, MV (corresponding author), Univ Beira Interior, IT, Rua Marques Avila & Bolama, P-6201001 Covilha, Portugal.
EM pedro.manuel.fernandes@ubi.pt; mbernardo@ubi.pt; pinheiro@ubi.pt;
   fiadeiro@ubi.pt; mpereira@ubi.pt
RI Pereira, Manuela/Q-3456-2019; Fiadeiro, Paulo T/J-2017-2012; Pinheiro,
   Antonio/B-2723-2012; Bernardo, Marco v./HNQ-4992-2023
OI Pereira, Manuela/0000-0002-8648-6464; Fiadeiro, Paulo
   T/0000-0002-7374-3636; Pinheiro, Antonio/0000-0002-5968-9901; Bernardo,
   Marco v./0000-0003-0046-8685
FU Fundacao para a Ciencia e a Tecnologia [UID/EEA/50008/2013]
FX The authors are very grateful to the Instituto de Telecomunicacoes and
   Fundacao para a Ciencia e a Tecnologia (project UID/EEA/50008/2013), and
   to the Optics Center of Universidade da Beira Interior where this work
   has been conducted.
CR [Anonymous], 2014, WEBM WEBM OPEN WEB M
   [Anonymous], 2012, TECH REP
   [Anonymous], 2008, TECH REP
   [Anonymous], 2009, World Medical Association Declaration of Helsinki - Ethical principles for medical research involving human subjects
   [Anonymous], 2000, 1449621999 ISOIEC
   Bankoski J, 2013, P SOC PHOTO-OPT INS, V8666
   Bultje R, COMMUNICATION
   De Simone F, 2011, J VIS COMMUN IMAGE R, V22, P734, DOI 10.1016/j.jvcir.2011.01.008
   Garcia R, 2014, IEEE T CONSUM ELECTR, V60, P116, DOI 10.1109/TCE.2014.6780933
   Grois D, 2013, PCS 2013 30 PIC COD
   Hanhart P, 2012, PROC SPIE, V8499, DOI 10.1117/12.946036
   Haskell B, 1996, DIGITAL MULTIMEDIA S
   Hollander M., 2014, Nonparametric Statistical Methods, Solutions Manual, Vthird
   ISO/IEC, 2000, 1381822000 ISOIEC
   ITU, 2009, METH SUBJ ASS QUAL T
   ITU, 2005, TECH REP
   ITU-T Tutorial, 2004, TECH REP
   Le Callet P., 2012, QUALINET WHITE PAPER
   MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095
   Mitchell J, 2000, MPEG VIDEO COMPRESSI
   MPEG, 2013, REP HEVC
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Ostermann J, 2012, MPEG VIDEO COMPRESSI
   Rerabek M, 2014, SPIE OPTICAL ENG APP
   Rouse DM, 2008, IEEE IMAGE PROC, P1188, DOI 10.1109/ICIP.2008.4711973
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 2005, P IEEE, V93, P18, DOI 10.1109/JPROC.2004.839617
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WebM, 2013, WEBM WEBM OPEN WEB M
   Weerakkody R, 2014, 2014 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P1083, DOI 10.1109/GlobalSIP.2014.7032288
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 33
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13633
EP 13649
DI 10.1007/s11042-016-3726-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900033
OA Green Published
DA 2024-07-18
ER

PT J
AU Mehdi, MZ
   Ben Ayed, NG
   Masmoudi, AD
   Sellami, D
   Abid, R
AF Mehdi, Mouna Zouari
   Ben Ayed, Norhene Gargouri
   Masmoudi, Alima Damak
   Sellami, Dorra
   Abid, Riadh
TI An efficient microcalcifications detection based on dual
   spatial/spectral processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammogram; Breast tissue; Microcalcification; Enhancement; ANLS; Wavelet
   transform; Otsu
AB Microcalcifications are tiny deposits of calcium located in breast tissue. They appeared as very small highlighted regions in comparison with their surrounding tissue. Spatial non linear enhancement can be applied for microcalcification detection. However, efficiency of a such approach depends on breast density: in case of extreme breast density, the contrast between microcalcification's details and their surrounding tissue is attenuated leading to a limitation of spatially based approaches. In that case, frequency analysis such as wavelet based analysis can be more relevant for dissociating microcalcifications. The main goal of Computer Aided Detection systems (CAD) is to detect breast cancer at an early stage for all breast density classes by using entropies to enhance and then detect microcalcification details. Accordingly, we combine our approach a spatial Automatic Non Linear Stretching (ANLS) and Shannon Entropy based Wavelet Coefficient Thresholding (SE_WCT). Validation of the proposed approach is done on the Mammographic Image Analysis Society (MIAS) database. The evaluation of the contras tis based on the Second-Derivative-Like measure of enhancement(SDME). Accordingly, it yields to a mean SDME of 78.8dB on the whole database. The performance metric for evaluating our proposed CAD is the Receiver Operating Characteristic(ROC) curve and the free-response ROC (FROC). An area under the ROC curve A (z) = 0.92 is obtained as well as 97.14 % of True Positives (TP) with 0,48 False positives per image (FP).
C1 [Mehdi, Mouna Zouari] Univ Sfax, Control & Energy Management CEM Lab, Sfax Engn Sch, BP W, Sfax 3038, Tunisia.
   [Ben Ayed, Norhene Gargouri] Res Ctr Comp Sci & Multimedia Sfax, Control & Energy Management CEM Lab, Sfax, Tunisia.
   [Masmoudi, Alima Damak] Fac Sci Sfax, Control & Energy Management CEM Lab, Sfax, Tunisia.
   [Sellami, Dorra] Sfax Engn Sch, Control & Energy Management CEM Lab, Sfax, Tunisia.
   [Abid, Riadh] El Farabi Radiol Ctr, 14 Janvier Ave, Sfax 3000, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); Centre
   de Recherche en Numerique de Sfax (CRNS); Universite de Sfax; Faculty of
   Sciences Sfax; Universite de Sfax; Ecole Nationale dIngenieurs de Sfax
   (ENIS)
RP Mehdi, MZ (corresponding author), Univ Sfax, Control & Energy Management CEM Lab, Sfax Engn Sch, BP W, Sfax 3038, Tunisia.
EM zouarimouna88@gmail.com; Norhene.gargouri@live.fr
RI Gargouri, Norhene/GZN-1041-2022; Sellami, Dorra/KSL-6903-2024
OI Gargouri, Norhene/0000-0003-1613-2115; zouari, mouna/0000-0002-7061-3158
CR [Anonymous], 1 INT C ADV TECHN SI
   [Anonymous], INT J SIGNAL PROCESS
   [Anonymous], LECT NOTES CONTROL I
   [Anonymous], IEEE VISUALIZATION B
   [Anonymous], PLOS ONE
   [Anonymous], INT J COMPUTER THEOR
   [Anonymous], KNOWLEDGE BASED SYST
   [Anonymous], COMPUTER METHODS PRO
   [Anonymous], J DIGIT IMAGING
   [Anonymous], 1 INT C IM PROC APPL
   [Anonymous], ARTIFICIAL INTELLIGE
   [Anonymous], IEEE T INFORM TECHNO
   [Anonymous], 1964, INT BUSINESS
   [Anonymous], COMPUTERS MATH APPL
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], COMPUTERS BIOL MED
   Liu XM, 2015, EURASIP J ADV SIG PR, P1, DOI 10.1186/s13634-015-0249-3
   Mohanalin J, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON SIGNAL ACQUISITION AND PROCESSING, P3, DOI 10.1109/ICSAP.2009.17
   Moradi H, 2012, PROCEEDINGS OF THE ASME INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION - 2010, VOL 8, PTS A AND B, P61
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Vivona L, 2014, BMC MED IMAGING, V14, DOI 10.1186/1471-2342-14-23
   Yu SY, 2000, IEEE T MED IMAGING, V19, P115, DOI 10.1109/42.836371
NR 22
TC 7
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13047
EP 13065
DI 10.1007/s11042-016-3703-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900004
DA 2024-07-18
ER

PT J
AU Weng, SW
   Pan, JS
   Zhou, LZ
AF Weng, Shaowei
   Pan, Jeng-Shyang
   Zhou, Lizhi
TI Reversible data hiding based on the local smoothness estimator and
   optional embedding strategy in four prediction modes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Four improved prediction modes; Local smoothness
   estimator; Optional embedding strategy
ID GENERALIZED INTEGER TRANSFORM; HUMAN VISUAL-SYSTEM;
   HISTOGRAM-MODIFICATION; DIFFERENCE EXPANSION; IMAGE WATERMARKING;
   ALGORITHM; ERRORS
AB Four new prediction modes are proposed in this paper, each of which is a three-step process for all to-be-embedded pixels (nearly three-fourths of all the pixels). By designing each mode reasonably, all to-be-embedded pixels can be predicted with high accuracy, and thus, the number of embeddable pixels can be increased largely. In each step, a local smoothness estimator is utilized to determine if one embeddable pixel is located in a smooth or complex region, which is defined as the variance of the total neighbors of this pixel. In fact, the correlation evaluated by using the total neighbors, instead of a part, can reflect the complexity of the region more accurately. In this paper, an optional embedding strategy is introduced so as to select a low-distortion reversible data hiding (RDH) method according to the desired embedding rate (ER). Specifically, when the required ER is low, difference expansion (DE) is used to process those pixels in smooth regions while leaving the rest unaltered. With ER largely increased, adaptive embedding is used to embed 2-bit into these pixels with low local variance by DE while 1-bit into the remaining ones. The experimental results also demonstrate the proposed method is effective.
C1 [Weng, Shaowei] Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
   [Pan, Jeng-Shyang] Fujian Univ Technol, Fujian Prov Key Lab Data Min & Applicat, Fuzhou, Fujian, Peoples R China.
   [Zhou, Lizhi] NanJing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
C3 Guangdong University of Technology; Fujian University of Technology;
   Nanjing University of Information Science & Technology
RP Weng, SW (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
EM wswweiwei@126.com
RI Pan, Jeng-Shyang/AEO-3450-2022
OI Pan, Jeng-Shyang/0000-0002-3128-9025
FU National NSF of China [61201393, 61272498, 61571139]; New Star of Pearl
   River on Science and Technology of Guangzhou [2014J2200085]
FX This work was supported in part by National NSF of China (No. 61201393,
   No. 61272498, No. 61571139), New Star of Pearl River on Science and
   Technology of Guangzhou (No. 2014J2200085).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Celik MU, 2005, IEEE T IMAGE PROCESS, V12, P157
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Hong W., 2010, EURASIP J ADV SIGNAL
   Hong W, 2013, OPT COMMUN, V291, P87, DOI 10.1016/j.optcom.2012.10.081
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang X, 2010, P ICIP
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Weng SW, 2015, MULTIMED TOOLS APPL, V74, P10657, DOI 10.1007/s11042-014-2197-6
   Weng SW, 2014, MULTIMED TOOLS APPL, V72, P3063, DOI 10.1007/s11042-013-1585-7
   Weng SW, 2009, IET ELECT LETT, V1, P91
   Weng SW, 2008, IEEE SIG PROCESS LET, V45, P1022
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Xuan GR, 2004, P IWDW, V5, P23
NR 39
TC 8
Z9 9
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13173
EP 13195
DI 10.1007/s11042-016-3693-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900011
DA 2024-07-18
ER

PT J
AU Gao, T
   Zhao, XM
   Chen, T
   Liu, ZW
   Ni, C
AF Gao, Tao
   Zhao, X. M.
   Chen, Ting
   Liu, Z. W.
   Ni, Ce
TI Face description based on adaptive local weighted Gabor comprehensive
   histogram feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Gabor wavelet; Gabor comprehensive feature; Adaptive
   weight
ID LINEAR DISCRIMINANT-ANALYSIS; PATTERN; CLASSIFICATION; REPRESENTATION;
   RECOGNITION; PCA; DECOMPOSITION; REDUCTION; FUSION; SCALE
AB Face recognition is an extensively research topic in pattern recognition and image processing fields due to its broad application prospects in many areas such as counter terrorism, access identification, electronic passport, e-government affairs, etc. Inspired by the Gabor phase information and local image information content, a novel face description algorithm using adaptive Local Weighted Gabor Comprehensive Histogram (LWGCH) is proposed. It consists of two components: Local Gabor Comprehensive Histogram (LGCH) and Contribution Map (CM). Actually, the adaptive local weighted Gabor comprehensive histogram is generated with LGCH weighed by CM calculated by information content model. Finally, Extensive experiments on ORL, YALE, CMUPIE and Yale B face databases validate the effectiveness of the proposed methods under various conditions of partial occlusion, complex illumination, different expressions and poses. Experimental results indicate that the proposed algorithm is a competitive and robust method compared with several state-of-the-art approaches.
C1 [Gao, Tao; Zhao, X. M.; Chen, Ting; Liu, Z. W.; Ni, Ce] Changan Univ, Sch Informat Engn, Xian 710064, Peoples R China.
C3 Chang'an University
RP Gao, T (corresponding author), Changan Univ, Sch Informat Engn, Xian 710064, Peoples R China.
EM gtnwpu@126.com
FU National Natural Science Foundation of China [61302150]; Natural Science
   Foundation of Shanxi Province, China [2013JQ8044]; China Postdoctoral
   Science Foundation [2014 M562356]; Xi'an Science and technology
   development project [CXY1341(8)]
FX This project is supported by the National Natural Science Foundation of
   China (61302150), Natural Science Foundation of Shanxi Province, China
   (2013JQ8044), China Postdoctoral Science Foundation (2014 M562356),
   Xi'an Science and technology development project(CXY1341(8)).
CR [Anonymous], 2007, Advances in Neural Information Processing Systems 20
   Conde C, 2013, NEUROCOMPUTING, V100, P19, DOI 10.1016/j.neucom.2011.12.037
   Cui Y, 2012, PATTERN RECOGN, V45, P1471, DOI 10.1016/j.patcog.2011.10.006
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Fàbregas J, 2008, PATTERN RECOGN, V41, P3412, DOI 10.1016/j.patcog.2008.04.020
   Fernandes SL, 2013, INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, IMAGE PROCESSING AND PATTERN RECOGNITION (ICSIPR 2013), P122, DOI 10.1109/ICSIPR.2013.6497972
   Gaianu M, 2014, SIGNAL PROCESS, V96, P90, DOI 10.1016/j.sigpro.2013.06.029
   Gao T, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P1240, DOI 10.1109/ICALIP.2008.4590128
   Gupta S, 2012, PROCEDIA ENGINEER, V41, P827, DOI 10.1016/j.proeng.2012.07.250
   Hsieh PC, 2009, PATTERN RECOGN, V42, P978, DOI 10.1016/j.patcog.2008.09.024
   Kanan HR, 2010, IMAGE VISION COMPUT, V28, P438, DOI 10.1016/j.imavis.2009.06.013
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Li S, 2012, IET IMAGE PROCESS, V6, P770, DOI 10.1049/iet-ipr.2010.0367
   Liu H, 2012, NEUROCOMPUTING, V76, P2, DOI 10.1016/j.neucom.2010.12.045
   Mak KL, 2013, MATH COMPUT MODEL, V58, P1755, DOI 10.1016/j.mcm.2013.02.011
   Masutani Y, 2001, J COMPUT ASSIST TOMO, V25, P587, DOI 10.1097/00004728-200107000-00014
   Meng JC, 2007, PATTERN RECOGN LETT, V28, P1203, DOI 10.1016/j.patrec.2007.01.015
   Newman DJ, 2006, J AM SOC INF SCI TEC, V57, P753, DOI 10.1002/asi.20342
   Oh JH, 2013, PATTERN RECOGN LETT, V34, P679, DOI 10.1016/j.patrec.2013.01.016
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T., 2001, LNCS, V2013, P397
   Pong KH, 2014, PATTERN RECOGN, V47, P556, DOI 10.1016/j.patcog.2013.08.023
   Selvan SE, 2013, NEURAL COMPUT, V25, P2486, DOI 10.1162/NECO_a_00485
   Sharma A, 2008, DATA KNOWL ENG, V66, P338, DOI 10.1016/j.datak.2008.04.004
   Sharma A, 2006, PATTERN RECOGN, V39, P1215, DOI 10.1016/j.patcog.2006.02.001
   Shin K, 2003, MECH SYST SIGNAL PR, V17, P423, DOI 10.1006/mssp.2002.1510
   Shu X, 2012, PATTERN RECOGN, V45, P1892, DOI 10.1016/j.patcog.2011.11.012
   Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103
   Su Y, 2009, IEEE T IMAGE PROCESS, V18, P1885, DOI 10.1109/TIP.2009.2021737
   Sun ZL, 2011, IEEE T INF FOREN SEC, V6, P360, DOI 10.1109/TIFS.2011.2118207
   Tan KR, 2005, NEUROCOMPUTING, V64, P505, DOI 10.1016/j.neucom.2004.10.113
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Walton J, 2005, J ELECTRON SPECTROSC, V148, P29, DOI 10.1016/j.elspec.2005.02.003
   Wei JJ, 2001, IEEE T INF TECHNOL B, V5, P290, DOI 10.1109/4233.966104
   Wong WK, 2012, PATTERN RECOGN, V45, P186, DOI 10.1016/j.patcog.2011.05.014
   Wu M, 2012, ELECTRON LETT, V48, P629, DOI 10.1049/el.2012.0834
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Yang J, 2007, IEEE T INF FOREN SEC, V2, P781, DOI 10.1109/TIFS.2007.910239
   Yang M, 2013, PATTERN RECOGN, V46, P1865, DOI 10.1016/j.patcog.2012.06.022
   Yang WK, 2011, PATTERN RECOGN, V44, P1649, DOI 10.1016/j.patcog.2011.01.019
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhang WC, 2009, PATTERN ANAL APPL, V12, P301, DOI 10.1007/s10044-008-0123-0
   Zhao CR, 2013, NEUROCOMPUTING, V113, P251, DOI 10.1016/j.neucom.2013.01.021
   Zhao ZS, 2012, NEUROCOMPUTING, V97, P398, DOI 10.1016/j.neucom.2012.05.005
   Zhou SR, 2013, NEUROCOMPUTING, V116, P260, DOI 10.1016/j.neucom.2012.05.036
   Zuñiga AG, 2014, PATTERN RECOGN LETT, V36, P135, DOI 10.1016/j.patrec.2013.09.023
NR 48
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12893
EP 12916
DI 10.1007/s11042-016-3701-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200032
DA 2024-07-18
ER

PT J
AU Liu, ZH
   Luo, D
   Huang, JW
   Wang, J
   Qi, CD
AF Liu, Z. H.
   Luo, D.
   Huang, J. W.
   Wang, J.
   Qi, C. D.
TI Tamper recovery algorithm for digital speech signal based on DWT and DCT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermark; Tamper recovery; Speech compression; Tamper
   localization
ID WATERMARKING SCHEME; ROBUST AUDIO; AUTHENTICATION; RECOGNITION
AB It is a challenging work to design tamper recovery schemes for digital speech signal. Briefly, there are two problems need to be solved. One is that the signals used to tamper recovery are difficult to generate and embed, and the second is that it's hard to tamper location precisely for attacked speech signal. In this paper, compression and reconstruction method based on discrete wavelet transform (DWT) and discrete cosine transform (DCT) is given, to obtain the compressed signals used to tamper recovery. And then frame number and compressed signals are embedded based on block-based method. Attacked signal can be located by frame number, and compressed signals are extracted and used to reconstruct the attacked signal. Theory analysis and experimental results indicate that the scheme proposed not only improves the accuracy of tamper localization, but also can reconstruct the attacked signals.
C1 [Liu, Z. H.; Luo, D.; Huang, J. W.] Shenzhen Univ, Coll Informat Engn, Shenzhen 518060, Peoples R China.
   [Liu, Z. H.; Luo, D.; Huang, J. W.] Shenzhen Univ, Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
   [Liu, Z. H.] Xinyang Normal Univ, Coll Comp & Informat Technol, Xinyang 464000, Peoples R China.
   [Wang, J.; Qi, C. D.] Xinyang Normal Univ, Coll Math & Informat Sci, Xinyang 464000, Peoples R China.
C3 Shenzhen University; Shenzhen University; Xinyang Normal University;
   Xinyang Normal University
RP Huang, JW (corresponding author), Shenzhen Univ, Coll Informat Engn, Shenzhen 518060, Peoples R China.; Huang, JW (corresponding author), Shenzhen Univ, Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
EM zhenghui.liu@163.com; luoda@szu.edu.cn; jwhuang@szu.edu.cn;
   wangjing_cosy@163.com; qichuanda@sina.com
RI huang, jw/KVY-9917-2024
FU National Natural Science Foundation of China [61332012, 61272465,
   61502409]; Shenzhen RD Program [GJHZ20140418191518323]; Nanhu Scholars
   Program for Young Scholars of XYNU
FX This paper is supported by the National Natural Science Foundation of
   China (Grant No. 61332012, 61272465, 61502409), Shenzhen R&D Program
   (GJHZ20140418191518323), and Nanhu Scholars Program for Young Scholars
   of XYNU. We would like to thank the anonymous reviewers for their
   constructive suggestions.
CR Akhaee MA, 2010, SIGNAL PROCESS, V90, P2487, DOI 10.1016/j.sigpro.2010.02.013
   Bhat KV, 2011, CIRC SYST SIGNAL PR, V30, P915, DOI 10.1007/s00034-010-9255-8
   Chamlawi R, 2010, COMPUT ELECTR ENG, V36, P578, DOI 10.1016/j.compeleceng.2009.12.003
   Chen OTC, 2007, IEEE T AUDIO SPEECH, V15, P1605, DOI 10.1109/TASL.2007.896658
   Fakhr M. W., 2012, 2012 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC 2012), P535, DOI 10.1109/CyberC.2012.99
   Herbig T, 2012, COMPUT SPEECH LANG, V26, P210, DOI 10.1016/j.csl.2011.11.002
   Khan LA, 2010, DIGIT INVEST, V7, P65, DOI 10.1016/j.diin.2009.10.001
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Lei BY, 2013, IEEE T AUDIO SPEECH, V21, P2368, DOI 10.1109/TASL.2013.2277929
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Li CL, 2012, COMPUT STAND INTER, V34, P367, DOI 10.1016/j.csi.2012.01.003
   Liu ZH, 2016, SIGNAL PROCESS, V123, P157, DOI 10.1016/j.sigpro.2015.10.023
   Liu ZH, 2014, DIGIT SIGNAL PROCESS, V24, P197, DOI 10.1016/j.dsp.2013.09.007
   Luo D, 2016, IEEE SIGNAL PROC LET, V23, P688, DOI 10.1109/LSP.2016.2549600
   Navarathna R, 2013, COMPUT SPEECH LANG, V27, P911, DOI 10.1016/j.csl.2012.07.005
   Park CM, 2007, PATTERN RECOGN LETT, V28, P931, DOI 10.1016/j.patrec.2006.12.010
   Peng H, 2013, DIGIT SIGNAL PROCESS, V23, P382, DOI 10.1016/j.dsp.2012.08.006
   Pun CM, 2013, IEEE T AUDIO SPEECH, V21, P2412, DOI 10.1109/TASL.2013.2279312
   Rosales-Roldan L, 2013, SIGNAL PROCESS-IMAGE, V28, P69, DOI 10.1016/j.image.2012.11.006
   Sahidullah M, 2012, SPEECH COMMUN, V54, P543, DOI 10.1016/j.specom.2011.11.004
   Wang XY, 2011, COMPUT ELECTR ENG, V37, P425, DOI 10.1016/j.compeleceng.2011.05.011
   Wang Y., 2010, J ADV SIGNAL PROCESS, V2010, P1, DOI DOI 10.1016/J.PEPTIDES.2010.12.001
   YUAN S, 2004, P MULT SEC, P220
NR 24
TC 14
Z9 14
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12481
EP 12504
DI 10.1007/s11042-016-3664-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200014
DA 2024-07-18
ER

PT J
AU Lin, CY
   Muchtar, K
   Lin, JY
   Sung, YH
   Yeh, CH
AF Lin, Chih-Yang
   Muchtar, Kahlil
   Lin, Jia-Ying
   Sung, Yu-Hsien
   Yeh, Chia-Hung
TI Moving object detection in the encrypted domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving object detection; Video encryption; Mixture of Gaussians;
   Background modeling
ID BACKGROUND SUBTRACTION; PRIVACY
AB The privacy-preserving moving object detection has drawn a lot of interest lately. Nevertheless, current approaches use Paillier's scheme for encryption that impractical in real-time applications due to high computational complexity. In addition, none of them are fully compatible with popular background modeling methods. In this paper, a fast and secure encryption scheme for a surveillance system has been proposed. The algorithm allows the detection of a moving object to be implemented directly in the encryption domain. The proposed scheme separates every pixel into two parts. The first part of a pixel (most significant bits) is scrambled to encrypt the image, and the second part of the pixel (least significant bits) remains unchanged. This strategy allows the proposed encryption scheme to be compatible with the mixture of Gaussians (GMM) that is one of the most widely used background modeling methods to detect moving objects. The proposed scheme requires low computations and produces almost the same detection result as the GMM when it is applied to unencrypted videos. Security analysis of the proposed method also proves the robustness of the encryption process.
C1 [Lin, Chih-Yang] Asia Univ, Dept Bioinformat & Med Engn, Taichung, Taiwan.
   [Lin, Chih-Yang] China Med Univ, China Med Univ Hosp, Dept Med Res, Taichung, Taiwan.
   [Muchtar, Kahlil; Lin, Jia-Ying; Sung, Yu-Hsien; Yeh, Chia-Hung] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan.
C3 Asia University Taiwan; China Medical University Taiwan; China Medical
   University Hospital - Taiwan; National Sun Yat Sen University
RP Yeh, CH (corresponding author), Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan.
EM yeh@mail.ee.nsysu.edu.tw
RI Muchtar, Kahlil/P-8532-2019; Lin, Chih-Yang/HOF-2583-2023
OI Muchtar, Kahlil/0000-0001-5740-1938; Lin, Chih-Yang/0000-0002-0401-8473
FU National Science Council, Taiwan [MOST 103-2221-E-468-007-MY2, NSC
   102-2221-E-110-032-MY3]
FX This work was supported by National Science Council, Taiwan, under
   Grants MOST 103-2221-E-468-007-MY2 and NSC 102-2221-E-110-032-MY3.
CR Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bestagini P, 2013, IEEE INT WORKSH MULT, P488, DOI 10.1109/MMSP.2013.6659337
   Bitouk D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360638
   Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Bruckner D, 2012, IEEE T IND INFORM, V8, P291, DOI 10.1109/TII.2012.2186142
   Celik MU, 2008, IEEE T INF FOREN SEC, V3, P475, DOI 10.1109/TIFS.2008.926988
   Chen SY, 2012, IEEE T IND INFORM, V8, P118, DOI 10.1109/TII.2011.2173202
   Chu K.-Y., 2013, Proceedings of the 21st ACM international conference on Multimedia, P597
   Tran C, 2012, IEEE T IND INFORM, V8, P178, DOI 10.1109/TII.2011.2172450
   Dufaux F, 2008, IEEE T CIRC SYST VID, V18, P1168, DOI 10.1109/TCSVT.2008.928225
   Erkin Z, 2009, LECT NOTES COMPUT SC, V5672, P235, DOI 10.1007/978-3-642-03168-7_14
   Gil MJM, 2007, TECHNICAL REPORT
   Heidstra J, 2000, TECHNICAL REPORT
   Jung CR, 2009, IEEE T MULTIMEDIA, V11, P571, DOI 10.1109/TMM.2009.2012924
   KaewTraKulPong P., 2001, Proc. European Workshop Advanced Video Based Surveillance Systems, V1, P1
   Kafai M, 2012, IEEE T IND INFORM, V8, P100, DOI 10.1109/TII.2011.2173203
   Lian FL, 2013, IEEE T IND INFORM, V9, P172, DOI 10.1109/TII.2012.2209664
   Liu HH, 2013, IEEE T IND INFORM, V9, P1222, DOI 10.1109/TII.2013.2255616
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Martin K, 2008, IEEE T CIRC SYST VID, V18, P1152, DOI 10.1109/TCSVT.2008.927110
   Mukherjee D, 2014, IEEE T IND INFORM, V10, P1086, DOI 10.1109/TII.2013.2294134
   Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32
   Osadchy M, 2010, P IEEE S SECUR PRIV, P239, DOI 10.1109/SP.2010.39
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Ribnick E, 2006, P IEEE INT C VID SIG, P10
   Sadeghi AR, 2010, LECT NOTES COMPUT SC, V5984, P229
   Sagberg F, 2000, TECHNICAL REPORT
   Senior A, 2005, IEEE SECUR PRIV, V3, P50, DOI 10.1109/MSP.2005.65
   Senior A., 2009, Protecting Privacy in Video Surveillance
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shukla R, 2013, 2013 INTERNATIONAL CONFERENCE ON MACHINE INTELLIGENCE AND RESEARCH ADVANCEMENT (ICMIRA 2013), P174, DOI 10.1109/ICMIRA.2013.40
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Tao DP, 2014, IEEE T IND INFORM, V10, P813, DOI 10.1109/TII.2013.2255061
   Zeng YC, 2010, P APSIPA ANN SUMM C, P89
   Zhang TZ, 2013, IEEE T IND INFORM, V9, P149, DOI 10.1109/TII.2012.2218251
   Zhou XL, 2014, IEEE T IND INFORM, V10, P1064, DOI 10.1109/TII.2013.2294156
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 38
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9759
EP 9783
DI 10.1007/s11042-016-3578-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300029
DA 2024-07-18
ER

PT J
AU Shao, YJ
   Gao, CX
   Sang, N
AF Shao, Yuanjie
   Gao, Changxin
   Sang, Nong
TI A discriminant sparse representation graph-based semi-supervised
   learning for hyperspectral image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image classification; Graph; Semi-supervised learning
   (SSL); Sparse representation (SR)
ID DIMENSIONALITY REDUCTION; MANIFOLD REGULARIZATION
AB The classification of hyperspectral image with a paucity of labeled samples is a challenging task. In this paper, we present a discriminant sparse representation (DSR) graph for semi-supervised learning (SSL) to address this problem. For graph-based methods, how to construct a graph among the pixels is the key to a successful classification. Our graph construction method contains two steps. Sparse representation (SR) method is first employed to estimate the probability matrix of the pairwise pixels belonging to the same class, and then this probability matrix is integrated into the SR graph, which can be obtained by solving an a"" (1) optimization problem, to form a DSR graph. Experiments on Hyperion and AVIRIS hyperspectral data show that our proposed method outperforms state of the art.
C1 [Shao, Yuanjie; Gao, Changxin; Sang, Nong] Huazhong Univ Sci & Technol, Sch Automat, Sci & Technol Multispectral Informat Proc Lab, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Sang, N (corresponding author), Huazhong Univ Sci & Technol, Sch Automat, Sci & Technol Multispectral Informat Proc Lab, Wuhan 430074, Peoples R China.
EM shaoyuanjie1@163.com; nsang@hust.edu.cn
RI Gao, Changxin/L-4841-2016
OI Gao, Changxin/0000-0003-2736-3920
FU National Natural Science Foundation of China [61433007, 61401170]
FX This work is supported by the Project of the National Natural Science
   Foundation of China No. 61433007 and No. 61401170.
CR [Anonymous], 2002, TECH REP
   [Anonymous], TECH REP
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Camps-Valls G, 2007, IEEE T GEOSCI REMOTE, V45, P3044, DOI 10.1109/TGRS.2007.895416
   Cheng H, 2009, IEEE I CONF COMP VIS, P317, DOI 10.1109/ICCV.2009.5459267
   Gao Y, 2014, IEEE T IMAGE PROCESS, V23, P2769, DOI 10.1109/TIP.2014.2319735
   Kim W, 2010, IEEE T GEOSCI REMOTE, V48, P4110, DOI 10.1109/TGRS.2010.2076287
   Lafferty J. D., 2003, P INT C MACH LEARN, P912, DOI DOI 10.5555/3041838.3041953
   Lunga D, 2014, IEEE SIGNAL PROC MAG, V31, P55, DOI 10.1109/MSP.2013.2279894
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Wang D, 2015, PATTERN RECOGN, V48, P3025, DOI 10.1016/j.patcog.2015.01.012
   Wang D, 2015, IEEE T IMAGE PROCESS, V24, P2646, DOI 10.1109/TIP.2015.2427518
   Wang F, 2008, IEEE T KNOWL DATA EN, V20, P55, DOI 10.1109/TKDE.2007.190672
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Mingrui, 2007, International Conference on Artificial Intelligence and Statistics, P628
   Yan Shuicheng., 2009, SOC IND APPL MATH P, P792, DOI [10.1137/1.9781611972795.68, DOI 10.1137/1.9781611972795.68]
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhou DY, 2004, ADV NEUR IN, V16, P321
NR 19
TC 8
Z9 8
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10959
EP 10971
DI 10.1007/s11042-016-3371-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400036
DA 2024-07-18
ER

PT J
AU Kouroupetroglou, G
   Pino, A
   Riga, P
AF Kouroupetroglou, Georgios
   Pino, Alexandros
   Riga, Paraskevi
TI A methodological approach for designing and developing web-based
   inventories of mobile Assistive Technology applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile human-computer interaction; Multimedia accessibility; Mobile
   devices; Assistive technology; Apps; Disabilities
ID ALTERNATIVE COMMUNICATION; CHALLENGES; USABILITY
AB Mobile technologies provide radical opportunities in the domain of Assistive Technologies (AT) for persons with disabilities and the elderly by facilitating them to access multimedia content and improve their social interaction. The search for mobile AT applications that meet specific user needs is not an easy task for the disabled users, their facilitators, and rehabilitation professionals, as the mobile app stores do not include a category for AT or a classification by disability. In this work, we first provide an analysis of the disabled users' needs along with the required mobile software adaptations in order to fulfill them. Then, we introduce a methodological approach for the design and development of web-based inventories which make the search and selection of AT apps simpler and efficient. This methodology has to main parts, first it is based on experts in an AT lab thoroughly testing each application, and second, the creation of a consistent and well-documented presentation of the information for each app. Finally, we present the mATHENA repository of free AT apps for mobile devices (smartphones and tablets), which has been created by following the suggested methodology for creating AT app inventories. Currently, mATHENA includes 420 free mobile AT applications, carefully selected from a total of 1100. The features of mATHENA are compared with the functionality and social interaction services of six other inventories for AT applications.
C1 [Kouroupetroglou, Georgios; Pino, Alexandros; Riga, Paraskevi] Univ Athens, Dept Informat & Telecommun, Panepistimioupolis, GR-15784 Athens, Greece.
   [Kouroupetroglou, Georgios; Riga, Paraskevi] Univ Athens, Accessibil Unit Students Disabil, Panepistimioupolis, GR-15784 Athens, Greece.
C3 National & Kapodistrian University of Athens; National & Kapodistrian
   University of Athens
RP Kouroupetroglou, G (corresponding author), Univ Athens, Dept Informat & Telecommun, Panepistimioupolis, GR-15784 Athens, Greece.; Kouroupetroglou, G (corresponding author), Univ Athens, Accessibil Unit Students Disabil, Panepistimioupolis, GR-15784 Athens, Greece.
EM koupe@di.uoa.gr; pino@di.uoa.gr; p.riga@di.uoa.gr
RI Riga, Vivi/KAL-7377-2024; Pino, Alexandros/AAE-1293-2019;
   Kouroupetroglou, Georgios/F-6807-2012
OI Riga, Vivi/0000-0002-3023-1294; Pino, Alexandros/0000-0002-1993-2284;
   Kouroupetroglou, Georgios/0000-0003-4633-9475
FU project UDLnet: Universal Design for Learning: A Framework for
   Addressing Learner Variability [540659-LLP-1-2013-1-GR-COMENIUS-CNW];
   European Commission
FX This research has been partially financed by the project UDLnet:
   Universal Design for Learning: A Framework for Addressing Learner
   Variability (540659-LLP-1-2013-1-GR-COMENIUS-CNW)
   [www.udlnet-project.eu], funded with support from the European
   Commission. This publication reflects the views only of the authors, and
   the Commission cannot be held responsible for any use, which may be made
   of the information contained therein.
CR ANED, 2016, DTOCOM DIS ONL TOOL
   [Anonymous], 2005, Living in the state of stuck: How technology impacts the lives of people with disabilities
   [Anonymous], NUMB APPS AV LEAD AP
   [Anonymous], 2010, AUGMENTATIVE ALTERNA
   Apple, 2016, APP STOR DOWNL IT
   Apple, 2016, VOICEOVER
   Apple Vis, 2016, FIND SHAR REC IOS MA
   AppsForAAC, 2016, APPS AUGM ALT COMM
   Armstrong L, 2000, INT J LANG COMM DIS, V35, P377
   Arsenjeva J, 2014, ANNOTATED REV EUROPE
   ATutor, 2011, ACHECKER WEB ACC CHE
   Bernstein D., 2008, Language and communication disorders in children, V6A
   Bestwick A, 2010, MOBILE LEARNING ALL, V40
   Beukelman D., 1988, Augmentative and Alternative Communication, V4, P104, DOI DOI 10.1080/07434618812331274687
   Beukelman D. R., 2013, Augmentative & alternative communication: Supporting children and adults with complex communication needs
   Billi M, 2010, UNIVERSAL ACCESS INF, V9, P337, DOI 10.1007/s10209-009-0180-1
   BridgingApps, 2016, APPS SPEC NEEDS
   Chopra S, 2007, DECODING LIBARATION
   Circle F, 2016, SPECIAL NEEDS APPS S
   Citizens Information Board, 2016, ASS IR APPS PEOPL DI
   Coker W, 2006, P 22 ANN INT TECHN P, P19
   D'Ulizia A, 2010, PERVASIVE SMART TECH, P25
   Doughty K, 2011, J ASSIST TECHNOL, V5, P88, DOI 10.1108/17549451111149296
   Doyle M., 2001, AUGMENTATIVE ALTERNA, V17, P167, DOI DOI 10.1080/AAC.17.3.167.178
   Emiliani P.L., 2006, Technology and Disability, V18, P19, DOI [DOI 10.3233/TAD-2006-18104, 10.3233/tad-2006-18104]
   European Commission, 2016, EMPL SOC AFF INCL PO
   European Commission, 2016, JUST TACKL DISCR LEG
   Fossett B, 2009, HDB DEV DISABILITIES, P330
   García-Peñalvo FJ, 2014, LECT NOTES COMPUT SC, V8524, P117, DOI 10.1007/978-3-319-07485-6_12
   Gavigan K., 2009, Library Media Connection, V27, P54
   Hakobyan L, 2013, SURV OPHTHALMOL, V58, P513, DOI 10.1016/j.survophthal.2012.10.004
   Higginbotham J., 2011, Perspectives on Augmentative and Alternative Communication, V20, P52, DOI [DOI 10.1044/AAC20.2.52, 10.1044/aac20.2.52]
   Hu N., 2006, P 7 ACM C EL COMM
   Judge S., 2014, Young children and families in the information age educating the young child, V10, P117
   Kaikkonen A, 2005, J USABILITY STUD, V1, P4
   Khalid H, 2015, IEEE SOFTWARE, V32, P70, DOI 10.1109/MS.2014.50
   Klasnja Predrag, 2009, AMIA Annu Symp Proc, V2009, P338
   Kouroupetroglou G, 2014, ASSISTIVE TECHNOLOGI
   Kouroupetroglou G, 2015, LECT NOTES COMPUT SC, V9416, P519, DOI 10.1007/978-3-319-26138-6_56
   Lindsay G, 2010, INT J LANG COMM DIS, V45, P448, DOI 10.3109/13682820903165693
   Looi CK, 2010, BRIT J EDUC TECHNOL, V41, P154, DOI 10.1111/j.1467-8535.2008.00912.x
   Low Vision Bureau, 2014, 326 ACC APPS IPH VIS
   McNaughton D., 2002, Augmentative and Alternative Communication, V18, P59, DOI DOI 10.1080/07434610212331281171
   McNaughton D, 2013, AUGMENT ALTERN COMM, V29, P107, DOI 10.3109/07434618.2013.784930
   Mirenda P, 2003, LANG SPEECH HEAR SER, V34, P203, DOI 10.1044/0161-1461(2003/017)
   Morelli R, 2009, COMMUN ACM, V52, P67, DOI 10.1145/1536616.1536635
   Pino A, 2014, ASSISTIVE TECHNOLOGI, P110, DOI [10.4018/978-1-4666-4438-0.ch005, DOI 10.4018/978-1-4666-4438-0.CH005]
   Pino A, 2010, LECT NOTES COMPUT SC, V6179, P178, DOI 10.1007/978-3-642-14097-6_29
   Riehle D, 2007, COMPUTER, V40, P25, DOI 10.1109/MC.2007.147
   Seabrook Heather J, 2014, BMC Res Notes, V7, P573, DOI 10.1186/1756-0500-7-573
   Sherwin K, 2015, SCREEN READERS TOUCH
   Sierra JS, 2012, ACHI 2012 5 INT C AD, P47
   Speech and Accessibility Lab, 2016, MATH FREE SOFTW INV
   Speech and Accessibility Lab, 2009, ATH FREE SOFTW INV
   Stephanidis Constantine., 2009, The Universal Access Handbook". 23.2.1.2 Web Content Accessibility: Evaluation Tools
   Strati E, 2014, EUROPEAN SEMESTER CO
   United-Nations, 2015, ESAP241
   W3C, 2004, W3C CSS VAL SERV
   WHO, 2011, WORLD REPORT ON DISABILITY, P1
   World Wide Web Consortium, 2015, UND CONF
   World Wide Web Consortium (W3C), 2008, WEB CONTENT ACCESSIB
   Zhang DS, 2005, INT J HUM-COMPUT INT, V18, P293, DOI 10.1207/s15327590ijhc1803_3
NR 62
TC 10
Z9 12
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5347
EP 5366
DI 10.1007/s11042-016-3822-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500030
DA 2024-07-18
ER

PT J
AU Hua, KL
   Anistyasari, Y
   Hsu, CH
   Chin, TL
   Yang, CL
   Wang, CY
AF Hua, Kai-Lung
   Anistyasari, Yeni
   Hsu, Che-Hao
   Chin, Tai-Lin
   Yang, Chao-Lung
   Wang, Chun-Yen
TI Multicast scheduling for stereoscopic video in wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heterogeneous channel conditions; Rate scheduling; Stereoscopic video;
   WiFi networks
ID QUALITY; TRANSMISSION
AB Stereoscopic video multicast over wireless network is a challenging issue due to large bandwidth requirement, limited resource, and heterogeneous user channel conditions. Recently, most existing methods for stereoscopic video multicast employ symmetric video coding that transmits the same video quality for stereo views. In this paper, we propose a novel rate scheduling method for stereoscopic video multicast in WiFi networks through asymmetric video coding to maximize users' perceived video quality. We first formulated rate scheduling problem which has complexity in non-polynomial time subjected to playback time limit, block dependency, and the ratio of asymmetric video quality for stereo views. Then, a novel algorithm is proposed to assign a suitable rate for each frame per layer. Furthermore, we studied the impact of block dependency and asymmetric coding. Experimental results confirm that our approach resulted in promising perceived video quality while outperforming several existing video multicast techniques.
C1 [Hua, Kai-Lung; Anistyasari, Yeni; Hsu, Che-Hao; Chin, Tai-Lin; Wang, Chun-Yen] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
   [Yang, Chao-Lung] Natl Taiwan Univ Sci & Technol, Dept Ind Management, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology; National Taiwan
   University of Science & Technology
RP Hua, KL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM hua@mail.ntust.edu.tw; D10015801@mail.ntust.edu.tw;
   D9915002@mail.ntust.edu.tw; tchin@mail.ntust.edu.tw;
   clyang@mail.ntust.edu.tw; M9915038@mail.ntust.edu.tw
RI Anistyasari, Yeni/AAN-8799-2020
OI Anistyasari, Yeni/0000-0001-5664-2254; Hua, Kai-Lung/0000-0002-7735-243X
CR [Anonymous], 2008, DIGITAL COMMUNICATIO
   ASHER H, 1953, BRIT J OPHTHALMOL, V37, P37, DOI 10.1136/bjo.37.1.37
   Choupani R, 2014, MULTIMED TOOLS APPL, V69, P843, DOI 10.1007/s11042-012-1150-9
   Deb S, 2008, IEEE INFOCOM SER, P1795
   Ekmekcioglu E, 2010, IEEE IMAGE PROC, P2401, DOI 10.1109/ICIP.2010.5651107
   Hua S, 2011, IEEE T MULTIMEDIA, V13, P402, DOI 10.1109/TMM.2010.2103929
   Jakubczak S., 2011, PROC MOBICOM, P289
   Kordelas A, 2016, MULTIMED TOOLS APPL, V75, P5619, DOI 10.1007/s11042-015-2530-8
   Lee HJ, 2015, MULTIMED TOOLS APPL, V74, P6557, DOI 10.1007/s11042-014-2243-4
   Lee I, 2011, J AMBIENT INTELLIGEN, V3, P87
   Lee JS, 2011, IEEE T MULTIMEDIA, V13, P882, DOI 10.1109/TMM.2011.2157333
   LI WT, 1992, IEEE T INFORM THEORY, V38, P1842, DOI 10.1109/18.165464
   Lim WS, 2012, IEEE T MOBILE COMPUT, V11, P780, DOI 10.1109/TMC.2011.95
   Lin KCJ, 2013, IEEE T MOBILE COMPUT, V12, P21, DOI 10.1109/TMC.2011.242
   Minoli D, 2012, 3DTV CONTENT CAPTURE
   Ozbek N, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1113, DOI 10.1109/ICME.2008.4607634
   Rappaport T. S., 2010, WIRELESS COMMUNICATI
   Saygili G, 2011, IEEE T BROADCAST, V57, P593, DOI 10.1109/TBC.2011.2131450
   Saygili G, 2009, IEEE IMAGE PROC, P717, DOI 10.1109/ICIP.2009.5414317
   Schierl T, 2007, IEEE T CIRC SYST VID, V17, P1204, DOI 10.1109/TCSVT.2007.905528
   Schwarz H, 2007, IEEE T CIRCUITS SYST, V17, P1457
   Shao F, 2012, IEEE T MULTIMEDIA, V14, P157, DOI 10.1109/TMM.2011.2169045
   Shao F, 2011, IEEE T CONSUM ELECTR, V57, P1823, DOI 10.1109/TCE.2011.6131159
   Shao F, 2010, IEEE T CONSUM ELECTR, V56, P2460, DOI 10.1109/TCE.2010.5681128
   Stelmach L, 2000, IEEE T CIRC SYST VID, V10, P188, DOI 10.1109/76.825717
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Villalón J, 2007, IEEE J SEL AREA COMM, V25, P699, DOI 10.1109/JSAC.2007.070507
   Wang K, 2012, IEEE T BROADCAST, V58, P544, DOI 10.1109/TBC.2012.2191031
   Zhou Y, 2011, IEEE T CIRC SYST VID, V21, P1679, DOI 10.1109/TCSVT.2011.2133390
   Zou JN, 2014, MULTIMED TOOLS APPL, V71, P1975, DOI 10.1007/s11042-012-1321-8
NR 30
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 679
EP 706
DI 10.1007/s11042-015-3045-z
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000030
DA 2024-07-18
ER

PT J
AU Huang, DY
   Huang, CN
   Hu, WC
   Chou, CH
AF Huang, Deng-Yuan
   Huang, Ching-Ning
   Hu, Wu-Chih
   Chou, Chih-Hung
TI Robustness of copy-move forgery detection under high JPEG compression
   artifacts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forgery detection; Principal component analysis; Singular value
   decomposition; Fast Fourier transform
AB This paper proposes a robust method for detecting copy-move forgery in images under various JPEG compression and Gaussian noise and blurring attacks. The method comprises feature extraction, feature matching, and duplicate block identification. The fast Fourier transform (FFT), singular value decomposition (SVD), and principal component analysis (PCA) are utilized for feature extraction. Then, the cascading matchers of FFT, SVD, and PCA are adopted for feature matching. Matched blocks are identified using cascade filtering with city block, horizontal, vertical, and frequency filters. Finally, the pixels on upper left corners of detected duplicate blocks are output for visual inspection. The major contributions of this paper are: (1) the proposed method is fully threshold-free; (2) only one-dimensional features are generated using FFT and SVD for feature matching; and (3) a high accuracy rate (> 97 %) is obtained even if the JPEG quality factor Q is 20. In extensive experiments, a 98 % accuracy rate and a 6 % false negative rate were obtained for the worst case of Q = 20 and a region size of 32 x 32 pixels compared to existing works, indicating the feasibility of the proposed method.
C1 [Huang, Deng-Yuan; Huang, Ching-Ning; Chou, Chih-Hung] Dayeh Univ, Dept Elect Engn, 168 Univ Rd, Changhua, Taiwan.
   [Hu, Wu-Chih] Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, 300 Liu Ho Rd, Makung City, Penghu, Taiwan.
C3 Da Yeh University; National Penghu University of Science & Technology
RP Huang, DY (corresponding author), Dayeh Univ, Dept Elect Engn, 168 Univ Rd, Changhua, Taiwan.
EM kevin@mail.dyu.edu.tw; daweimailbox@gmail.com; wchu@npu.edu.tw;
   manp5030@hotmail.com
RI Chou, Chih-Hung/K-9077-2015
OI Chou, Chih-Hung/0000-0001-5714-1718
FU Ministry of Science and Technology, Taiwan [NSC 102-2221-E-212-015, MOST
   104-2221-E-212-005, MOST 104-2218-E-212-001]
FX This paper was in part financially supported by the Ministry of Science
   and Technology, Taiwan, under grants NSC 102-2221-E-212-015, MOST
   104-2221-E-212-005, and MOST 104-2218-E-212-001.
CR Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Fu Lihua, 2012, J CONVERGENCE INFORM, V7, P160
   Hu WC, 2016, MULTIMED TOOLS APPL, V75, P3495, DOI 10.1007/s11042-015-2449-0
   Hu WC, 2015, DIGIT SIGNAL PROCESS, V39, P50, DOI 10.1016/j.dsp.2015.01.006
   Hu WC, 2013, INT J COMPUT SCI ENG, V8, P297
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Ketenci S, 2013, 2013 36TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P813, DOI 10.1109/TSP.2013.6614051
   Li GH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1750
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Liu KC, 2012, IET IMAGE PROCESS, V6, P445, DOI 10.1049/iet-ipr.2011.0574
   Muhammad G., 2014, P INT C EL ENG INF C, P1
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Wen SF, 2009, MODELLING SIMULATION, P1, DOI 10.1109/cisp.2009.5301325
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Yang Wang, 2012, Proceedings of the 2012 Ninth International Conference on Information Technology: New Generations (ITNG), P30, DOI 10.1109/ITNG.2012.13
NR 20
TC 30
Z9 30
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1509
EP 1530
DI 10.1007/s11042-015-3152-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000066
DA 2024-07-18
ER

PT J
AU Ji, L
   Wang, H
   Zheng, TQ
   Qi, XF
AF Ji, Li
   Wang, Hong
   Zheng, Tianqi
   Qi, Xunfang
TI Motion trajectory of human arms based on the dual quaternion with motion
   tracker
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual quaternion; Rotation matrix; Human motion capture; Kinect device;
   Motion trajectory; Singular points
ID SYSTEM
AB In this paper, we present an algorithm for human motion capture of the real-time motion trajectory of human arms based on wireless inertial 3D motion trackers. It aims to improve the accuracy of inertial motion captures and quickly reconstruct some human movements. To evaluate the performance of the proposed dual quaternion algorithm, we present the prototype design. The wireless inertial measurement system and Kinect device are introduced simultaneously in capturing human motion. The dual quaternion algorithm incorporates features of the quaternion rotation and translation. So the singular points of Euler angles can be avoided. Dual quaternion algorithm and DCM(direction cosine matrix) are used to reconstruct human arm movements respectively. Compared with the computing speed in Matlab, the speed of the dual quaternion is faster than it of DCM. To the end, we propose a 3D ADAMS human robotic model for simulating the motion trajectory using dual quaternion algorithm. The results show that the dual quaternion can achieve capabilities of a positive DCM solving, which completed between body segments rotating and translating the coordinate system transformation. Also it can effectively drive in real-time a human model to animate movement, and provide a good algorithm.
C1 [Ji, Li; Wang, Hong; Zheng, Tianqi; Qi, Xunfang] Northeastern Univ, Dept Mech Engn & Automat, WenHua Rd 3-11, Shenyang, Liaoning, Peoples R China.
C3 Northeastern University - China
RP Wang, H (corresponding author), Northeastern Univ, Dept Mech Engn & Automat, WenHua Rd 3-11, Shenyang, Liaoning, Peoples R China.
EM jili_rory@126.com; hongwang@mail.neu.edu.cn; ztq199205@126.com;
   452842565@qq.com
FU National Natural Science Foundation of China [51405073]; Innovation team
   project of higher college in Liaoning province [LT2014006]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No.51405073). Innovation team project of higher college in
   Liaoning province (LT2014006).
CR Chen W, 2010, ADV MATER RES-SWITZ, V121-122, P486, DOI 10.4028/www.scientific.net/AMR.121-122.486
   Esser P, 2009, J BIOMECH, V42, P1578, DOI 10.1016/j.jbiomech.2009.03.049
   Figueredo LFC, 2013, IEEE INT CONF ROBOT, P1949, DOI 10.1109/ICRA.2013.6630836
   Frisoli A, 2013, ROBOT AUTON SYST, V61, P404, DOI 10.1016/j.robot.2012.09.003
   Guan L, 2003, RES MOTION GENERATIO, P18
   [黄波士 Huang Boshi], 2005, [计算机工程与应用, Computer Engineering and Application], V41, P60
   King K, 2008, SENSOR ACTUAT A-PHYS, V141, P619, DOI 10.1016/j.sna.2007.08.028
   Kirtley C, 2001, MULTIMED TOOLS APPL, V14, P259, DOI 10.1023/A:1011362113281
   Ladislav K, 2006, DUAL QUATERNIONS RIG
   Li Q, 2010, J BIOMECH, V43, P1640, DOI 10.1016/j.jbiomech.2010.01.031
   Liang C, 2011, SINS ALGORITHMS BASE, P26
   Nan Z, 2013, REAL TIME MICROSENSO, V334, P685
   Ni Zhensong, 2013, Journal of Tsinghua University (Science and Technology), V53, P683
   [倪振松 NI Zhensong], 2009, [机械工程学报, Chinese Journal of Mechanical Engineering], V45, P25
   Perez A, 2004, J MECH DESIGN, V126, P425, DOI 10.1115/1.1737378
   Peruzzi A, 2011, J BIOMECH, V44, P1991, DOI 10.1016/j.jbiomech.2011.04.035
   Pham HL, 2010, IEEE INT C INT ROBOT, P658, DOI 10.1109/IROS.2010.5651097
   Rosa-Pujazon Alejandro, 2015, International Journal of Creative Interfaces and Computer Graphics, V6, P72, DOI 10.4018/IJCICG.2015010105
   Rosa-Pujazon A, 2015, J MULTIMEDIA TOOLS A, V27, P1
   Sanna A, 2013, ENTERTAIN COMPUT, V78, P48
   Wang XK, 2013, SYST CONTROL LETT, V62, P225, DOI 10.1016/j.sysconle.2012.11.019
   Wu YX, 2005, IEEE T AERO ELEC SYS, V41, P110, DOI 10.1109/TAES.2005.1413751
   Xia Lin-lin, 2008, Journal of System Simulation, V20, P276
   Xiaoying Z, 2012, SCI TECHNOL ENG, V12, P634
   [虞铭财 Yu Mingcai], 2005, [计算机辅助设计与图形学学报, Journal of Compute-Aided Design and Graphics], V17, P437
   Yuan Q, 2013, SENSOR ACTUAT A-PHYS, V183, P123
   Yuan Q, 2011, 2011 IE INT C ROB AU, P9
NR 27
TC 6
Z9 7
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1681
EP 1701
DI 10.1007/s11042-015-3099-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000004
DA 2024-07-18
ER

PT J
AU Liu, J
   Dong, WM
   Zhang, XP
   Jiang, ZG
AF Liu, Jia
   Dong, Weiming
   Zhang, Xiaopeng
   Jiang, Zhiguo
TI Orientation judgment for abstract paintings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abstract paintings; Image classification; Feature extraction;
   Orientation judgment; Art theory
AB Artists decide the orientation at which an abstract painting should be hung based on their ideas, but the correct orientation is not obvious to other viewers. Some studies have found that abstract paintings at the correct orientations generally get higher aesthetic ratings from viewers. This encourages us to deal with the problem of orientation judgment for abstract paintings through machine learning. First, we design a group of methods to extract features from paintings based on the theories in abstract art. Then a machine leaning framework is proposed using Naive Bayes classifier and BP neural network classifier for training and orientation testing. Experiments show that it can classify abstract paintings into up and non-up ones with performance comparable to human. This is the first work of orientation judgment for abstract paintings through computer simulation, and the results demonstrate the validity of abstract art theories used for feature definition. This work provides a new scheme for exploring the relationship between aesthetic quality of abstract paintings and their computational visual features.
C1 [Liu, Jia] Beijing Informat Sci & Technol Univ, Sch Automat, Beijing, Peoples R China.
   [Liu, Jia; Dong, Weiming; Zhang, Xiaopeng] Chinese Acad Sci, Inst Automat, LIAMA NLPR, Beijing, Peoples R China.
   [Jiang, Zhiguo] Beihang Univ, Sch Astronaut, Image Proc Ctr, Beijing, Peoples R China.
C3 Beijing Information Science & Technology University; Chinese Academy of
   Sciences; Institute of Automation, CAS; Beihang University
RP Liu, J (corresponding author), Beijing Informat Sci & Technol Univ, Sch Automat, Beijing, Peoples R China.; Liu, J (corresponding author), Chinese Acad Sci, Inst Automat, LIAMA NLPR, Beijing, Peoples R China.
EM liujiahh@126.com
RI DONG, Weiming/AAG-7678-2020
OI DONG, Weiming/0000-0001-6502-145X
FU National Natural Science Foundation of China [61172104]
FX This work is supported by the National Natural Science Foundation of
   China with project No. 61172104.
CR Amirshahi SA, 2012, PROC SPIE, V8291, DOI 10.1117/12.911973
   [Anonymous], 2004, Visual Thinking
   Barla A, 2002, LECT NOTES COMPUT SC, V2388, P83
   Bosch A, 2007, P CIVR 2007
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   Gossweiler R., 2009, P 18 INT C WORLD WID, P841, DOI DOI 10.1145/1526709.1526822
   Hedges S, 2008, IMAGE ANAL RENAISSAN
   Hollitt C., 2012, P IVCNZ 2012, V2012, P346, DOI [10.1145/2425836.2425904, DOI 10.1145/2425836.2425904]
   Irfan M, 2009, SPIE ELECT IMAGING M, VII, P7251
   Isola P, 2011, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2011.5995721
   Jiang SQ, 2006, PATTERN RECOGN LETT, V27, P734, DOI 10.1016/j.patrec.2005.10.017
   Johnson MG, 2010, PSYCHOL AESTHET CREA, V4, P161, DOI 10.1037/a0018155
   Jones-Smith K, 2006, NATURE, V444, pE9, DOI 10.1038/nature05398
   Kandinsky Wassily., 2012, Point and Line to Plane
   Ke Y., 2006, P IEEE COMP SOC C CO, V1, P419, DOI DOI 10.1109/CVPR.2006.303
   Latto R, 2000, PERCEPTION, V29, P981, DOI 10.1068/p2352
   Li CC, 2009, IEEE J-STSP, V3, P236, DOI 10.1109/JSTSP.2009.2015077
   Lindauer M. S., 1969, P AM PSYCHOL ASSOC, V4, P475
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Mallon B, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00161
   Marchesotti L, 2011, IEEE C COMP VIS PATT
   Mather G, 2012, I-PERCEPTION, V3, P18, DOI 10.1068/i0447aap
   Plumhoff JE, 2009, PERCEPTION, V38, P719, DOI 10.1068/p6160
   Redies C, 2012, LECT NOTES COMPUT SC, V7583, P522, DOI 10.1007/978-3-642-33863-2_54
   Sartori A, 2015, ACM T INTERACT INTEL, V5, DOI 10.1145/2768209
   Shahram M, 2008, PROC SPIE, V6810, DOI 10.1117/12.765773
   Siwei Lyu, 2005, 13th Annual ACM International Conference on Multimedia, P491
   Stork DG, 2009, LECT NOTES COMPUT SC, V5702, P9, DOI 10.1007/978-3-642-03767-2_2
   Taylor RP, 1999, NATURE, V399, P422, DOI 10.1038/20833
   Yanulevskaya V, 2012, MM 12
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
NR 32
TC 9
Z9 9
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1017
EP 1036
DI 10.1007/s11042-015-3104-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000044
DA 2024-07-18
ER

PT J
AU Hachaj, T
   Ogiela, MR
AF Hachaj, Tomasz
   Ogiela, Marek R.
TI Human actions recognition on multimedia hardware using angle-based and
   coordinate-based features and multivariate continuous hidden Markov
   model classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human actions recognition; Hidden Markov models; Features selection;
   Classification; Gym exercises; Kinect
ID GESTURE RECOGNITION; SOUND RECOGNITION; REAL-TIME; SYSTEM; SEGMENTATION;
   TRACKING; VELOCITY; FFT
AB In this paper we have proposed human actions recognition schema that uses angle-based and state-of-the-art coordinates-based features and multivariate continuous hidden Markov model (HMM) classifier with Gaussian distribution. The main novelty of this paper besides presenting this approach is its evaluation on large (containing 770 actions) motion-capture dataset of various gym exercises. We have evaluated HMM with various number of hidden states and Gaussian mixture model classifier. We have performed PCA analysis of both features sets to justify our choices. We have also test 24 subsets of proposed angle-based features dataset in order to estimate which body joints are vital for correct actions recognition. The highest recognition rate in k-fold cross validation was 97 +/- 14 % and was obtained for 4-states HMM with 10 angle-based features. The common problem with markerless motion capture vision - based systems is that if some parts of body surface are covered by another part it is impossible to perform accurate features measurements. Knowing this we have evaluated 24 subsets of proposed features dataset in order to estimate which body joints are vital for correct actions recognition.
C1 [Hachaj, Tomasz] Pedag Univ Krakow, Inst Comp Sci & Comp Methods, 2 Podchorazych Ave, PL-30084 Krakow, Poland.
   [Ogiela, Marek R.] AGH Univ Sci & Technol, Cryptog & Cognit Informat Res Grp, Mickiewicza Ave, PL-30059 Krakow, Poland.
C3 Pedagogical University of Cracow; AGH University of Krakow
RP Hachaj, T (corresponding author), Pedag Univ Krakow, Inst Comp Sci & Comp Methods, 2 Podchorazych Ave, PL-30084 Krakow, Poland.
EM tomekhachaj@o2.pl; mogiela@agh.edu.pl
RI Hachaj, Tomasz/C-1741-2013; Cataldi, Antonio/AAM-7411-2021; Ogiela,
   Marek R/A-7735-2013
OI Hachaj, Tomasz/0000-0003-1390-9021
CR [Anonymous], 2014, INT C IEEE, P1, DOI [10.1109/ICCCNT.2014.6963013, DOI 10.1109/ICCCNT.2014.6963013]
   [Anonymous], CONTINUOUS HIDDEN MA
   Arici T, 2014, MULTIMED TOOLS APPL, V72, P3045, DOI 10.1007/s11042-013-1591-9
   BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196
   Beh J, 2014, PATTERN RECOGN, V47, P1586, DOI 10.1016/j.patcog.2013.11.010
   Boubou S, 2015, J INTELL INF SYST, V44, P49, DOI 10.1007/s10844-014-0329-0
   Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2
   Chen X, 2015, NEUROCOMPUTING, V149, P387, DOI 10.1016/j.neucom.2013.10.046
   Gamage N, 2011, PATTERN RECOGN LETT, V32, P2009, DOI 10.1016/j.patrec.2011.08.015
   Glowacz A, 2008, PRZ ELEKTROTECHNICZN, V84, P159
   Glowacz A, 2008, PRZ ELEKTROTECHNICZN, V84, P43
   Hachaj T, 2014, PROC SPIE, V9217, DOI 10.1117/12.2061171
   Hachaj T, 2014, MULTIMEDIA SYST, V20, P81, DOI 10.1007/s00530-013-0332-2
   Huang CL, 2001, MACH VISION APPL, V12, P243, DOI 10.1007/s001380050144
   Huang CL, 2000, IMAGE VISION COMPUT, V18, P865, DOI 10.1016/S0262-8856(99)00042-6
   Ibañez R, 2014, ADV ENG SOFTW, V76, P171, DOI 10.1016/j.advengsoft.2014.07.005
   Kang H, 2004, PATTERN RECOGN LETT, V25, P1701, DOI 10.1016/j.patrec.2004.06.016
   Khan ZA, 2013, COMPUTING, V95, P109, DOI 10.1007/s00607-012-0216-x
   Kim D, 2007, PATTERN RECOGN, V40, P3012, DOI 10.1016/j.patcog.2007.02.010
   Kim IC, 2001, APPL INTELL, V15, P131, DOI 10.1023/A:1011231305559
   Kim JH, 2000, PATTERN ANAL APPL, V3, P314, DOI 10.1007/s100440070003
   Ko AHR, 2009, PATTERN ANAL APPL, V12, P21, DOI 10.1007/s10044-007-0094-6
   Le S, 2008, J STAT SOFTW, V25, P1, DOI 10.18637/jss.v025.i01
   Lee H, 2013, SIGNAL PROCESS-IMAGE, V28, P114, DOI 10.1016/j.image.2012.10.007
   Lee T., 2000, J ELECT CHINA, V17, P242, DOI [10.1007/s11767-000-0037-5, DOI 10.1007/S11767-000-0037-5]
   Mahapatra A, 2014, AEU-INT J ELECTRON C, V68, P227, DOI 10.1016/j.aeue.2013.08.011
   Piórkowski A, 2014, COMPUT INFORM, V33, P707
   Qian XM, 2012, MULTIMED TOOLS APPL, V60, P233, DOI 10.1007/s11042-011-0817-y
   Shotton J., 2013, DECISION FORESTS COM, P175, DOI DOI 10.1007/978-1-4471-4929-3_13
   Szostek K, 2010, INNOVATIONS IN COMPUTING SCIENCES AND SOFTWARE ENGINEERING, P379, DOI 10.1007/978-90-481-9112-3_64
   Uddin MZ, 2010, APPL INTELL, V33, P193, DOI 10.1007/s10489-008-0159-2
   Yoon HS, 2001, PATTERN RECOGN, V34, P1491, DOI 10.1016/S0031-3203(00)00096-0
   Zarrouk E, 2014, INT J SPEECH TECHNOL, V17, P223, DOI 10.1007/s10772-013-9221-5
   Zhou YH, 2014, APPL INTELL, V40, P613, DOI 10.1007/s10489-013-0492-y
NR 34
TC 9
Z9 9
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16265
EP 16285
DI 10.1007/s11042-015-2928-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700062
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, YT
   Zhou, G
   Li, Y
   Shen, D
AF Li, Yantao
   Zhou, Gang
   Li, Yue
   Shen, Du
TI Determining driver phone use leveraging smartphone sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Driver phone use; Smartphone; GPS; Accelerometer; Driving condition
   classification
ID SPEED
AB Driver distraction by mobile phones has been a huge threat that leads to unnecessary accidents and human casualties, especially in hazardous road conditions. In this paper, we address a fundamental but critical issue of phone use during the driver behind the wheel. We propose, design and implement SafeDrive which achieves the goal of automatically determining driver phone use leveraging built-in smartphone sensors sensing driving conditions. We explore GPS and accelerometer sensors on smartphones to collect data, which can sufficiently capture driving conditions. With inputs of these data, we provide an accurate driving condition classification algorithm, that classifies driving conditions into five categories. Based on the classified driving conditions, SafeDrive makes a flexible control of driver phone use. We excessively evaluate the classification accuracy of our SafeDrive in local, highway, traffic jam, and complex conditions, respectively, and the results demonstrate that it can achieve up to 87 % classification accuracy in complex conditions.
C1 [Li, Yantao] Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.
   [Zhou, Gang; Li, Yue; Shen, Du] Coll William & Mary, Dept Comp Sci, Williamsburg, VA 23187 USA.
C3 Southwest University - China; William & Mary
RP Li, YT (corresponding author), Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.
EM yantaoli@foxmail.com
RI Zhou, Gang/T-7901-2017; l, y/JXY-4631-2024; l, yy/IAQ-9519-2023
OI Zhou, Gang/0000-0002-4425-9837; Li, Yantao/0000-0001-7648-5671
FU National Natural Science Foundation of China [61528206, 61402380,
   61402063]; Natural Science Foundation of CQ CSTC [cstc2015jcyjA40044,
   cstc2013kjrcqnrc40013]; U.S. National Science Foundation [CNS-1253506,
   CNS-1250180]; Fundamental Research Funds for the Central Universities
   [XDJK2015B030]; State Ethnic Affairs Commission of China [14GZZ012];
   Science and Technology Foundation of Guizhou [LH20147386]; Division Of
   Computer and Network Systems; Direct For Computer & Info Scie & Enginr
   [1253506] Funding Source: National Science Foundation
FX We would like to thank the anonymous reviewers for their valuable
   comments. This work is supported in part by the National Natural Science
   Foundation of China (Grant nos. 61528206, 61402380, and 61402063), the
   Natural Science Foundation of CQ CSTC (Grant nos. cstc2015jcyjA40044 and
   cstc2013kjrcqnrc40013), U.S. National Science Foundation (Grant nos.
   CNS-1253506 (CAREER) and CNS-1250180), the Fundamental Research Funds
   for the Central Universities (Grant no. XDJK2015B030), the State Ethnic
   Affairs Commission of China (Grant no. 14GZZ012), and the Science and
   Technology Foundation of Guizhou (Grant no. LH20147386).
CR [Anonymous], 2011, AUSTR TEL NETW APPL
   [Anonymous], INT J TRANSPLANT HEM, DOI DOI 10.1007/978-3-642-39256-6
   [Anonymous], 2014, The Water-Energy Nexus: Challenges and Opportunities, P1
   [Anonymous], REAL TIME POTHOLE DE
   Bergasa LM, 2006, IEEE T INTELL TRANSP, V7, P63, DOI 10.1109/TITS.2006.869598
   Chandrasekaran G, 2011, INT CONF PERVAS COMP, P213, DOI 10.1109/PERCOM.2011.5767589
   Eriksson J, 2008, MOBISYS'08: PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P29
   Gao X, 2014, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM '14), P355, DOI 10.1145/2639108.2642911
   Gundlegård D, 2009, IET INTELL TRANSP SY, V3, P87, DOI 10.1049/iet-its:20070067
   Han HF, 2014, IEEE INFOCOM SER, P727, DOI 10.1109/INFOCOM.2014.6847999
   Hedgecock Will., 2013, Proceeding of the 11th annual international conference on Mobile systems, applications, and services (MobiSys '13), P221, DOI DOI 10.1145/2462456.2464456
   Horrey WJ, 2006, HUM FACTORS, V48, P196, DOI 10.1518/001872006776412135
   Horsman G, 2015, P 2 ANN DFRWS EUR DF, P30
   Hu S, 2015, P 2015 ACM INT JOINT, V15, P1, DOI DOI 10.1186/S12866-015-0595-1
   Hu SH, 2015, ACM T SENSOR NETWORK, V11, DOI 10.1145/2770876
   Jiangpeng D., 2010, 4 INT C PERV COMP TE, P1, DOI DOI 10.4108/ICST.PERVASIVEHEALTH2010.8901
   Johnson DA, 2011, IEEE INT C INTELL TR, P1609, DOI 10.1109/ITSC.2011.6083078
   Kutila M, 2007, IEEE IMAGE PROC, P2997
   Laberge-Nadeau C, 2003, ACCIDENT ANAL PREV, V35, P649, DOI 10.1016/S0001-4575(02)00043-X
   Li KA, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1389
   Li Y, 2011, P 30 INT PERF COMP C, P1
   Lindqvist J., 2011, Proceedings of the 12th Workshop on Mobile Computing Systems and Applications, P70
   Liu L., 2015, P WORKSH WEAR SYST A, P27, DOI DOI 10.1145/2753509.2753518
   Mohan P, 2008, SENSYS'08: PROCEEDINGS OF THE 6TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P323
   Mun M, 2009, MOBISYS'09: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P55
   Nelson L., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P174, DOI 10.1145/365024.365094
   Paek J, 2010, ENERGY EFFICIENT RAT
   Qi X, 2013, IEEE REAL TIME, P163, DOI 10.1109/RTAS.2013.6531089
   Saremi F, 2016, IEEE T MOBILE COMPUT, V15, P672, DOI 10.1109/TMC.2015.2421939
   Seshadri K, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301397
   Thiagarajan A., 2010, P 8 ACM C EMBEDDED N, P85
   White J, 2011, MOBILE NETW APPL, V16, P285, DOI 10.1007/s11036-011-0304-8
   Wiberg M., 2005, ACM Transactions on Computer-Human Interaction, V12, P356, DOI 10.1145/1121112.1121114
   Xu BL, 2015, PROC SPIE, V9407, DOI 10.1117/12.2083126
   Yang J., 2011, P 17 ANN INT C ONMOB, P97
   Yang J, 2012, IEEE T MOBILE COMPUT, V11, P1426, DOI 10.1109/TMC.2012.92
NR 36
TC 9
Z9 9
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 16959
EP 16981
DI 10.1007/s11042-015-2969-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600012
DA 2024-07-18
ER

PT J
AU Liao, JX
   Yang, D
   Li, TH
   Qi, Q
   Wang, JY
   Sun, HF
AF Liao, Jianxin
   Yang, Di
   Li, Tonghong
   Qi, Qi
   Wang, Jingyu
   Sun, Haifeng
TI Fusion feature for LSH-based image retrieval in a cloud datacenter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Content based image retrieval; Peer-to-peer; Locality
   sensitive hashing; Fusion feature
ID FRAMEWORK; COLOR
AB Since the emergence of cloud datacenters provides an enormous amount of resources easily accessible to people, it is challenging to provide an efficient search framework in such a distributed environment. However, traditional search techniques only allow users to search images over exact-match keywords through a centralized index. These methods are insufficient to meet requirements of content based image retrieval (CBIR) and more powerful search frameworks are needed. In this paper, we present LFFIR, a multi-feature image retrieval framework for content similar search in the distributed situation. The key idea is to effectively incorporate image retrieval based on multi-feature into the peer-to-peer (P2P) paradigm. LFFIR fuses the multiple features in order to capture the overall image characteristics. And then it constructs the distributed indexes for the fusion feature through exploiting the property of locality sensitive hashing (LSH). We implement a prototype system to evaluate the system performance with two image datasets. Comprehensive performance evaluations demonstration that our approach brings major performance and accuracy gains compared to the advanced distributed image retrieval framework.
C1 [Liao, Jianxin; Yang, Di; Qi, Qi; Wang, Jingyu; Sun, Haifeng] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
   [Li, Tonghong] Tech Univ Madrid, Dept Comp Sci, Madrid 28660, Spain.
   [Yang, Di] China United Network Commun Ltd, Beijing 100033, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Universidad
   Politecnica de Madrid; China United Network Communications Limited
RP Liao, JX; Yang, D (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.; Yang, D (corresponding author), China United Network Commun Ltd, Beijing 100033, Peoples R China.
EM liaojx@bupt.edu.cn; yangdi.bupt@gmail.com; tonghong@fi.upm.es;
   qiqi8266@bupt.edu.cn; wangjingyu@bupt.edu.cn; sunhaifeng_1@ebupt.com
RI liu, jiajia/IUN-0901-2023; wangwangwang, yuanyaunyuan/HHN-6432-2022;
   Wang, Jingyu/JFK-6346-2023; lu, kai/KBB-4008-2024; Li,
   Chun/KBC-9591-2024
OI Wang, Jingyu/0000-0002-2182-2228; li, tonghong/0000-0003-1533-4954; LI,
   TONGHONG/0000-0003-1165-7836
FU National Basic Research Program of China [2013CB329102]; National
   Natural Science Foundation of China [61471063, 61421061, 61372120,
   61271019, 61101119, 61121001]; Key(Keygrant) Project of Chinese Ministry
   of Education [MCM20130310]; Beijing Municipal Natural Science Foundation
   [4152039]; Beijing Higher Education Young Elite Teacher Project
   [YETP0473]; Spanish Research Council [TIN2013-46883]; Regional
   Government of Madrid [S2013/ICE-2894]; FSE; FEDER
FX This work was jointly supported by: (1) the National Basic Research
   Program of China (No. 2013CB329102); (2) National Natural Science
   Foundation of China (No. 61471063, 61421061, 61372120,61271019,
   61101119, 61121001); (3) the Key(Keygrant) Project of Chinese Ministry
   of Education.(No. MCM20130310); (4) Beijing Municipal Natural Science
   Foundation (No. 4152039); (5) Beijing Higher Education Young Elite
   Teacher Project (No. YETP0473); (6) Spanish Research Council (No:
   TIN2013-46883); (7) Regional Government of Madrid (No: S2013/ICE-2894)
   cofunded by FSE & FEDER.
CR Androutsos P, 2006, IEEE T MULTIMEDIA, V8, P278, DOI 10.1109/TMM.2005.864276
   [Anonymous], P 6 INT WORKSH DAT I
   [Anonymous], 2010, MULTIMED TOOLS APPL, DOI DOI 10.1007/s11042-009-0339-z
   [Anonymous], 2001 C APPL TECHN AR
   Bawa M., 2003, P ACM SIGIR, P306, DOI [10.1145/860435.860491, DOI 10.1145/860435.860491]
   Chen JJ, 2008, IEEE T MULTIMEDIA, V10, P209, DOI 10.1109/TMM.2007.911821
   Crespo A, 2002, INT CON DISTR COMP S, P23, DOI 10.1109/ICDCS.2002.1022239
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Dikaiakos MD, 2009, IEEE INTERNET COMPUT, V13, P10, DOI 10.1109/MIC.2009.103
   Eisenhardt M, 2006, IEEE INT SYM MULTIM, P823
   Forestiero A, 2010, IEEE ACM T NETWORK, V18, P1651, DOI 10.1109/TNET.2010.2046745
   Gaeta R, 2011, IEEE T PARALL DISTR, V22, P2055, DOI 10.1109/TPDS.2011.82
   Guo CX, 2009, ACM SIGCOMM COMP COM, V39, P63, DOI 10.1145/1594977.1592577
   Haghani Parisa., 2009, PROC 12 INT C EXTEND, P744
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jagadish H.V., 2005, Proceedings of the 31st International Conference on Very Large Data Bases (VLDB), P661
   Kalnis P, 2006, INFORM SYST, V31, P57, DOI 10.1016/j.is.2004.09.003
   King I, 2004, ACM T INFORM SYST, V22, P477, DOI 10.1145/1010614.1010619
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Liao JX, 2014, INFORM SYST FRONT, V16, P129, DOI 10.1007/s10796-013-9467-0
   Liao JX, 2012, IEEE COMMUN MAG, V50, P90, DOI 10.1109/MCOM.2012.6122537
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Lv Q., 2002, Conference Proceedings of the 2002 International Conference on SUPERCOMPUTING, P84, DOI 10.1145/514191.514206
   Novak D., 2006, Proceedings of the 1st international conference on Scalable information systems - InfoScale'06, P19
   Peng CY, 2012, IEEE INFOCOM SER, P181, DOI 10.1109/INFCOM.2012.6195556
   Sahin O. D., 2005, 13th Annual ACM International Conference on Multimedia, P946, DOI 10.1145/1101149.1101349
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Sripanidkulchai K., 2003, P 22 ANN JOINT C IEE
   Stoica I, 2001, ACM SIGCOMM COMP COM, V31, P149, DOI 10.1145/964723.383071
   Tang CQ, 2003, ACM SIGCOMM COMP COM, V33, P175
   Tian XL, 2014, SIGNAL PROCESS-IMAGE, V29, P530, DOI 10.1016/j.image.2014.01.010
   Urdaneta G, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1883612.1883615
   Vlachou Akrivi, 2012, Transactions on Large-Scale Data- and Knowledge-Centered Systems V: LNCS 7100, P28, DOI 10.1007/978-3-642-28148-8_2
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Yang Z., 2010, 2010 IEEE International Conference on Communications, P1, DOI DOI 10.1109/ICC.2010.5502549
   Zhang XL, 2010, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE 2010, VOL 2, PTS A AND B, P19
   Zhu YW, 2007, J PARALLEL DISTR COM, V67, P604, DOI 10.1016/j.jpdc.2007.01.005
NR 38
TC 6
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15405
EP 15427
DI 10.1007/s11042-015-2892-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700018
DA 2024-07-18
ER

PT J
AU Wang, ZY
   Hu, RM
   Jiang, JJ
   Han, Z
   Shao, ZF
AF Wang, Zhongyuan
   Hu, Ruimin
   Jiang, Junjun
   Han, Zhen
   Shao, Zhenfeng
TI Heteroskedasticity tuned mixed-norm sparse regularization for face
   hallucination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face hallucination; Sparse regularization; Locally weighted penalty;
   Mixed norms
ID VARIABLE SELECTION; IMAGE SUPERRESOLUTION; MINIMIZATION
AB Face hallucination is typically an ill-posed inverse problem, so it is essential to exploit an effective norm-regularized underlying representation. Due to the under-sparsity or over-sparsity, the widely used regularization methods, such as ridge regression and sparse representation, lead to poor robustness in the presence of noise. In addition, standard forms of penalty functions fail to account for the nature of heteroskedasticity of reconstruction coefficients, thus hardly providing optimal solutions in terms of accuracy and stability. To this end, this paper derives the locally weighted variants of standard regularization representation from Bayesian inference perspective, which impose the similarity constraint within the observed image and training images onto the penalty function. Further, considering the reduced sparseness of noisy images, a moderately sparse regularization method with a mixture of a"" (1) and a"" (2) norms is introduced to deal with noise robust face hallucination. New determination methods on weighting function and regularization parameter are particularly explored. Various experimental results on public face databases as well as real-world images validate the effectiveness of proposed method.
C1 [Wang, Zhongyuan; Hu, Ruimin; Han, Zhen] Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
   [Wang, Zhongyuan; Hu, Ruimin; Han, Zhen] Wuhan Univ, Sch Comp, Wuhan 430072, Peoples R China.
   [Jiang, Junjun] China Univ Geosci, Sch Comp, Wuhan 430074, Peoples R China.
   [Shao, Zhenfeng] Wuhan Univ, State key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
C3 Wuhan University; Wuhan University; China University of Geosciences;
   Wuhan University
RP Wang, ZY (corresponding author), Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.; Wang, ZY (corresponding author), Wuhan Univ, Sch Comp, Wuhan 430072, Peoples R China.
EM wzy_hope@163.com; hrm1964@163.com; junjun0595@163.com;
   hanzhen_2003@hotmail.com; shaozhenfeng@163.com
RI Wang, Zhongyuan/ABD-2189-2020; Jiang, Junjun/L-7087-2019
OI Jiang, Junjun/0000-0002-5694-505X
FU National Natural Science Foundation of China [61172173, 61172174,
   61501413, 61502354]; Fundamental Research Funds for the Central
   Universities [2042014kf0286, 2042014kf0212]; Natural Science Fund of
   Hubei Province [2015CFB406]
FX This work was supported by the National Natural Science Foundation of
   China (61172173,61172174,61501413,61502354), the Fundamental Research
   Funds for the Central Universities (2042014kf0286, 2042014kf0212), and
   Natural Science Fund of Hubei Province (2015CFB406).
CR [Anonymous], P INT C WIR COMM SIG
   [Anonymous], 2009, P ADV NEUR INF PROC
   [Anonymous], PATTERN RECOGNIT
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Bose NK, 2006, IEEE T IMAGE PROCESS, V15, P2239, DOI 10.1109/TIP.2006.877406
   Bose N. K., 2001, ISCAS 2001. The 2001 IEEE International Symposium on Circuits and Systems (Cat. No.01CH37196), P433, DOI 10.1109/ISCAS.2001.921100
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Çetin M, 2001, IEEE T IMAGE PROCESS, V10, P623, DOI 10.1109/83.913596
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699
   Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273
   FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Friedlander MP, 2012, IEEE T INFORM THEORY, V58, P1122, DOI 10.1109/TIT.2011.2167214
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   He R, 2014, IEEE T PATTERN ANAL, V36, P261, DOI 10.1109/TPAMI.2013.102
   Jia Z, 2011, 2011 FIRST ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P179, DOI 10.1109/ACPR.2011.6166702
   Jiang JJ, 2014, IEEE T MULTIMEDIA, V16, P1268, DOI 10.1109/TMM.2014.2311320
   Jung CK, 2011, IEEE SIGNAL PROC LET, V18, P367, DOI 10.1109/LSP.2011.2140370
   Khajehnejad MA, 2009, IEEE INT SYMP INFO, P483, DOI 10.1109/ISIT.2009.5205716
   Li Q, 2010, BAYESIAN ANAL, V5, P151, DOI 10.1214/10-BA506
   Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5
   Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281
   Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P573, DOI 10.1109/83.913592
   Nikolova M, 2005, SIAM J SCI COMPUT, V27, P937, DOI 10.1137/030600862
   Park JS, 2008, IEEE T IMAGE PROCESS, V17, P1806, DOI 10.1109/TIP.2008.2001394
   Tang Y, 2011, INT J MACH LEARN CYB, V2, P15, DOI 10.1007/s13042-011-0011-6
   VAPNIK V, 1993, NEURAL COMPUT, V5, P893, DOI 10.1162/neco.1993.5.6.893
   Wang ZY, 2014, IEEE T CIRC SYST VID, V24, P802, DOI 10.1109/TCSVT.2013.2290574
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang Li, 2004, Proceedings. Third International Conference on Image and Graphics, P298
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang J, 2012, IEEE INT SYMP CIRC S, P1688
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 35
TC 6
Z9 6
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17273
EP 17301
DI 10.1007/s11042-015-2996-4
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600025
DA 2024-07-18
ER

PT J
AU Alamri, A
   Hossain, MS
   Almogren, A
   Hassan, MM
   Alnafjan, K
   Zakariah, M
   Seyam, L
   Alghamdi, A
AF Alamri, Atif
   Hossain, M. Shamim
   Almogren, Ahmad
   Hassan, Mohammad Mehedi
   Alnafjan, Khalid
   Zakariah, Mohammed
   Seyam, Lee
   Alghamdi, Abdullah
TI QoS-adaptive service configuration framework for cloud-assisted video
   surveillance systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive QoS; Cloud-assisted video surveillance; Service configuration;
   Transcoding service
AB Quality of service (QoS)-adaptive service configuration is crucial for seamless access to video services in cloud-assisted video surveillance systems. To maintain seamless access to video on a user's preferred device, suitable video transcoding services are needed. It is a challenging task to choose and configure these services for various devices to ensureQoS-adaptive user experiences. To configure these services for the desired user devices, a suitable configuration algorithm is needed. Therefore, this paper describes a QoS-adaptive service configuration approach to choose the optimal configuration for the preferred user devices in varied contexts so that the user can access the services ubiquitously. We implemented a cloud-assisted video surveillance prototype to show how the proposed method can handle ubiquitous access to target video for possible QoS-adaptive and video processing requirements in terms of bandwidth, delay, and frame rates. The results show that the proposed configuration method outperforms the other comparable approaches.
C1 [Alamri, Atif; Hossain, M. Shamim; Almogren, Ahmad; Hassan, Mohammad Mehedi; Zakariah, Mohammed] King Saud Univ, Coll Comp & Informat Sci, Res Chair Pervas & Mobile Comp, Riyadh 11543, Saudi Arabia.
   [Hossain, M. Shamim; Alnafjan, Khalid; Alghamdi, Abdullah] King Saud Univ, SwE Dept, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.
   [Seyam, Lee] Kyung Hee Univ, Dept Elect Engn, Dongdaemun, South Korea.
C3 King Saud University; King Saud University; Kyung Hee University
RP Hassan, MM (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Res Chair Pervas & Mobile Comp, Riyadh 11543, Saudi Arabia.
EM atif@ksu.edu.sa; mshossain@ksu.edu.sa; ahalmogren@ksu.edu.sa;
   mmhassan@ksu.edu.sa; kalnafjan@ksu.edu.sa; mzakariah@ksu.edu.sa;
   sleekhu@gmail.com; Ghamdi@ksu.edu.sa
RI Hassan, Mohammad/KDM-9524-2024; Hassan, Mohammad/GZA-7507-2022; Guizani,
   Mohsen/AAX-4534-2021; Almogren, Ahmad S/F-1365-2014; Hossain, M.
   Shamim/K-1362-2014; Hassan, Mohammad Mehedi/D-4946-2016; Alamri,
   Atif/KFQ-0028-2024; Zakariah, Mohammed/AAX-4115-2021
OI Hassan, Mohammad/0000-0002-1712-0004; Guizani,
   Mohsen/0000-0002-8972-8094; Almogren, Ahmad S/0000-0002-8253-9709;
   Hossain, M. Shamim/0000-0001-5906-9422; Alamri,
   Atif/0000-0002-1887-5193; 
FU King Saud University through Vice Deanship of Research Chairs
FX This project was full financially supported by the King Saud University,
   through Vice Deanship of Research Chairs.
CR Ahmed DT, 2014, MULTIMED TOOLS APPL, V73, P219, DOI 10.1007/s11042-012-1294-7
   Axis, VID SURV SERV VSAAS
   Cui X, 2003, P ICCNMC 03 SHANGH C
   Ejaz N, 2012, J VIS COMMUN IMAGE R, V23, P1031, DOI 10.1016/j.jvcir.2012.06.013
   Hassan MM, 2014, INT CONF ADV COMMUN, P876, DOI 10.1109/ICACT.2014.6779086
   Hasselmo ME, 2015, PROG BRAIN RES, V219, P1, DOI 10.1016/bs.pbr.2015.03.009
   Hossain MS, 2014, MULTIMED TOOLS APPL, V73, P169, DOI 10.1007/s11042-012-1312-9
   Hossain MS, 2013, MULTIMED TOOLS APPL, V67, P433, DOI 10.1007/s11042-012-1006-3
   Hossain MS, 2010, IEEE T INSTRUM MEAS, V59, P1498, DOI 10.1109/TIM.2009.2024338
   Hossain MS, 2009, CONCURR COMP-PRACT E, V21, P1450, DOI 10.1002/cpe.1400
   Hossain MA, 2013, P HPCC EUC 13 PORT P
   Hossain MA, 2014, INT J DISTRIBUTED SE, V2014
   Hossain MS, 2013, P IEEE ICME 13 SAN J
   Hossain MS, 2012, P IEEE MULT EXP WORK
   Hossain MS, 2006, P IEEE IMTC 06 SORR
   Iqbal R, 2009, P ACM IEEE ICDSC 09
   Lamy-Bergot C, 2009, ITST: 2009 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORT SYSTEMS TELECOMMUNICATIONS, P415, DOI 10.1109/ITST.2009.5399319
   Limna T, 2012, P IEEE CISP 12 SICH
   Musunoori S, 2006, P IEEE CEC 06 VANC C, P2604
   Qi LY, 2012, J COMPUT SYST SCI, V78, P1316, DOI 10.1016/j.jcss.2011.12.016
   Rodriguez-Silva D, 2012, 5 INT C CLOUD COMP C
   Shanshan Z, 2012, P ICICEE 12 XIAN CHI
   Song B, 2014, P IEEE ISBAST 14 KUA
   Song B, 2015, MULTIMED TOOLS APPL
   Wang Z, 2013, P IEEE ICCIS 13 SHIY
   Xu D, 2000, P IEEE DCS 00 IST TU
   Yang Z, 2010, J Comput Inf Syst, V6, P2617
   Ye Z, 2011, LECT NOTES COMPUT SC, V6588, P321, DOI 10.1007/978-3-642-20152-3_24
   Zeng C, 2009, LECT NOTES COMPUT SC, V5931, P290, DOI 10.1007/978-3-642-10665-1_26
   Zou G, 2010, P CCV 2010 SING 17 1
NR 30
TC 6
Z9 6
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13333
EP 13348
DI 10.1007/s11042-015-3074-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800020
DA 2024-07-18
ER

PT J
AU Wan, WB
   Liu, J
   Sun, JD
   Gao, D
AF Wan, Wenbo
   Liu, Ju
   Sun, Jiande
   Gao, Di
TI Improved logarithmic spread transform dither modulation using a robust
   perceptual model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Logarithmic STDM; Perceptual JND model; Watermarking robustness; Edge
   strength
ID WATERMARKING
AB In the quantization-based watermarking framework, the perceptual just noticeable distortion (JND) model has been widely used to determine the quantization step size, as it can be used for the better tradeoff between imperceptibility and robustness. However, the calculated JND values will change as watermark embedding can affect the texture and luminance of the image. Consequently, the changes of JND values will lead to watermark-extraction errors. In this paper, the authors present an improved logarithmic spread transform dither modulation (STDM) watermarking approach using a best-matched DCT-based perceptual JND model, which can be insensitive to the changes caused by watermark embedding and attacks. Experimental results confirm the improved robustness performance of the JND model in the watermarking framework. Simulation results show that the proposed scheme is more robust than the existing JND model-based watermarking algorithms with the uniform fidelity, and our proposed scheme has a superior performance compared with the former proposed perceptual STDM schemes.
C1 [Wan, Wenbo; Liu, Ju; Sun, Jiande; Gao, Di] Shandong Univ, Sch Informat Sci & Engn, Jinan 250100, Peoples R China.
   [Liu, Ju; Sun, Jiande] Hisense State Key Lab Digital Multimedia Technol, Qingdao 266061, Peoples R China.
C3 Shandong University; Hisense
RP Liu, J (corresponding author), Shandong Univ, Sch Informat Sci & Engn, Jinan 250100, Peoples R China.
EM juliu@sdu.edu.cn
RI Sun, Jiande/B-4681-2018
FU Special Development Fund of Shandong Information Industry [2011R0116];
   Natural Science Foundation of Shandong Province [2014ZRE27336]; National
   Natural Science Foundation of China [61001180]
FX This work was supported by the Special Development Fund of Shandong
   Information Industry (2011R0116), the Natural Science Foundation of
   Shandong Province (2014ZRE27336) and the National Natural Science
   Foundation of China (61001180).
CR Ahumada A. J.  Jr., 1992, Proceedings of the SPIE - The International Society for Optical Engineering, V1666, P365, DOI 10.1117/12.135982
   Bae S. H., 2013, 2013 IEEE INT C IMAG, P431, DOI [10.1109/LSP.2013.2272193, DOI 10.1109/LSP.2013.2272193]
   Bae SH, 2013, IEEE SIGNAL PROC LET, V20, P893, DOI 10.1109/LSP.2013.2272193
   Barni M, 2001, IEEE COMMUN MAG, V39, P102, DOI 10.1109/35.940048
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chou J, 2001, INT CONF ACOUST SPEE, P1349, DOI 10.1109/ICASSP.2001.941178
   Comesana P, 2007, IEEE ICIP, P694
   Comesaña P, 2011, INT CONF ACOUST SPEE, P1840
   Kalantari NK, 2010, IEEE T IMAGE PROCESS, V19, P1504, DOI 10.1109/TIP.2010.2042646
   Li QO, 2007, INT CONF ACOUST SPEE, P185
   Li X, 2011, IET INFORM SECUR, V5, P170, DOI 10.1049/iet-ifs.2010.0218
   Ma LH, 2010, IEICE T INF SYST, VE93D, P843, DOI 10.1587/transinf.E93.D.843
   Moulin P, 2005, P IEEE, V93, P2083, DOI 10.1109/JPROC.2005.859599
   Muthuswamy K, 2013, IEEE SIGNAL PROC LET, V20, P996, DOI 10.1109/LSP.2013.2277884
   Pérez-González F, 2005, IEEE T SIGNAL PROCES, V53, P3960, DOI 10.1109/TSP.2005.855407
   Wan WB, 2013, IEEE IMAGE PROC, P4522, DOI 10.1109/ICIP.2013.6738931
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watson AB, 1993, DCT QUANTIZATION MAT, V1913, P202
   Zhang XH, 2005, SIGNAL PROCESS, V85, P795, DOI 10.1016/j.sigpro.2004.12.002
NR 20
TC 17
Z9 17
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13481
EP 13502
DI 10.1007/s11042-015-2853-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800027
DA 2024-07-18
ER

PT J
AU Yu, YL
   Ru, L
   Chi, WS
   Liu, YQ
   Yu, QQ
   Fang, K
AF Yu, Yunlong
   Ru, Le
   Chi, Wensheng
   Liu, Yaqing
   Yu, Qiangqiang
   Fang, Kun
TI Ant colony optimization based polymorphism-aware routing algorithm for
   ad hoc UAV network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ad hoc UAV network; Ant colony algorithm; Dynamic source routing
   algorithm; Polymorphism-aware; The congestion level of a route; The
   stability of a route
ID STABILITY
AB Ad hoc UAV network is characterized for its high node mobility, fast changing network topology, high frequency of interchanging data and complex application environment. The performance of traditional routing algorithms are so poor over aspects such as end to end delay, data packet delivery ratio and routing overhead that they cannot provide efficient communication for multi-UAVs carrying out missions synergistically. An ant colony optimization based polymorphism-aware routing algorithm- APAR algorithm is proposed to solve the problems. This algorithm integrates ACO algorithm and dynamic source routing algorithm, the level of pheromone in routes which are gained in routing discovery process, is chosen as a standard to choose route and calculated by sensing the distance of a route, the congestion level of a route, and the stability of a route. A new volatilization mechanism of pheromone is also introduced to the algorithm. Meanwhile, the algorithm can make adjustment to the variance of UAV formation to prevent the compromise of the network performance. The simulation results show the APAR algorithm has superiority over traditional algorithms in data package delivery ratio, end to end delay, routing overhead and it is dependable in battlefield environment.
C1 [Yu, Yunlong; Ru, Le; Chi, Wensheng; Liu, Yaqing; Yu, Qiangqiang; Fang, Kun] Air Force Engn Univ, Aeronaut & Astronaut Engn Coll, Xian 710038, Peoples R China.
C3 Air Force Engineering University
RP Yu, YL (corresponding author), Air Force Engn Univ, Aeronaut & Astronaut Engn Coll, Xian 710038, Peoples R China.
EM yuyunlongsci@yeah.net
CR [Anonymous], 1992, OPTIMIZATION LEARNIN
   [Anonymous], J AD HOC NETWORKING
   [Anonymous], 2014, INT J DISTRIB SENS N
   [Anonymous], 2007, PROC 3 IEEE ADV INT
   Asokan R, 2008, INT J COMPUT SCI SEC, V2
   Barolli L, 2004, 15TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P326, DOI 10.1109/DEXA.2004.1333494
   Basarkod PI, 2014, IEEE INT ADV COMPUT, P124, DOI 10.1109/IAdCC.2014.6779306
   Bellur B, 2003, TOPOLOGY DI IN PRESS
   Bettstetter C, 2004, WIREL NETW, V10, P555, DOI 10.1023/B:WINE.0000036458.88990.e5
   Csiszár V, 2009, MATH INEQUAL APPL, V12, P839
   Dorigo M, 1996, IEEE T SYST MAN CY B, V26, P29, DOI 10.1109/3477.484436
   Dube R, 1997, IEEE PERS COMMUN, V4, P36, DOI 10.1109/98.575990
   Garcia-Luna-Aceves J. J., 1999, Proceedings Seventh International Conference on Network Protocols (ICNP'99), P273, DOI 10.1109/ICNP.1999.801950
   Goldsmith A., 2005, WIRELESS COMMUNICATI
   Heissenbilttel M., 2003, KOMMUNIKATION VERTEI, P181
   Kang JJ, 2005, IEEE WCNC, P2258
   Dung LT, 2013, 2013 IEEE 10TH INTERNATIONAL CONFERENCE ON AND 10TH INTERNATIONAL CONFERENCE ON AUTONOMIC AND TRUSTED COMPUTING (UIC/ATC) UBIQUITOUS INTELLIGENCE AND COMPUTING, P607, DOI 10.1109/UIC-ATC.2013.91
   Moussaoui A, 2014, J NETW COMPUT APPL, V39, P117, DOI 10.1016/j.jnca.2013.05.014
   Murthy S., 1995, MOBICOM'95. Proceedings of The First Annual International Conference on Mobile Computing and Networking, P86, DOI 10.1145/215530.215560
   Paramasiven A., 2011, INT J COMPUTER SCI T, V2, P15
   Pei G., 1999, WCNC. 1999 IEEE Wireless Communications and Networking Conference (Cat. No.99TH8466), P1538, DOI 10.1109/WCNC.1999.796996
   Pei G, 2000, IEEE INT C COMM ICC
   Perkins C. E., 1994, Computer Communication Review, V24, P234, DOI 10.1145/190809.190336
   Perkins CE, 1999, WMCSA '99, SECOND IEEE WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS, PROCEEDINGS, P90, DOI 10.1109/MCSA.1999.749281
   Qayyam A, 2002, OPTIMIZED LINK STATE
   Qiong H, 2014, MATH PROBL ENG, V1, P1
   Rafsanjani MK, 2010, HYBRID ROUTING ALGOR, P112
   Ramrekha TA, 2013, J SUPERCOMPUT, V64, P409, DOI 10.1007/s11227-011-0705-2
   Reina DG, 2014, J SUPERCOMPUT, V67, P131, DOI 10.1007/s11227-013-0992-x
   Sarma N, 2010, WIRELESS PERS COMMUN, V54, P203, DOI 10.1007/s11277-009-9718-z
   Singh G, 2012, J NETW COMPUT APPL, V35, P1964, DOI 10.1016/j.jnca.2012.07.018
   Stojmenovic M, 2005, WIREL NETW MOB COMP, V3, P167
   Wang JP, 2009, AD HOC NETW, V7, P690, DOI 10.1016/j.adhoc.2008.06.001
   Xi Hu, 2010, 2010 International Conference on Computer Design and Applications (ICCDA 2010), P553, DOI 10.1109/ICCDA.2010.5540716
   Xia Li, 2010, 2010 Second International Conference on Communication Systems, Networks and Applications (ICCSNA 2010), P329, DOI 10.1109/ICCSNA.2010.5588734
   Zhu WY, 2006, INT WORKSH QUAL SERV, P122, DOI 10.1109/IWQOS.2006.250459
NR 36
TC 30
Z9 34
U1 1
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14451
EP 14476
DI 10.1007/s11042-015-3240-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500026
DA 2024-07-18
ER

PT J
AU Suo, AN
   Lin, Y
   Zhang, MH
AF Suo, Anning
   Lin, Yong
   Zhang, Minghui
TI Regional difference of coastal land use around the Bohai sea based on
   remote sensing images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Land use; Coastal zone; Regional difference; Remote sensing
ID SEGMENTATION; NETWORK; ALGORITHM
AB With the thriving development of high spatial resolution sensors, an increasing number of metric and sub-metric resolution remote sensing images are currently available, which allows for accurate geometrical analysis of objects at fine scales. Aimed to reveal the regional difference of coast land use in the Bohai Sea, series remote sensing images of HJ-1ACCD obtained in July of 2013 were employed to monitor land use in 5 km coastal zone of 13 regions around the Bohai Sea. Some evaluation index, such as dominant land use type, land use dominant index and land use intensity index were established to evaluate the regional difference of land use in the coast zone. The result shows: there exist obviously regional differences in coast land use around the Bohai Sea. Some regions such as Huludao and Yantai are typical farmland landscape. Some regions such as Dongying and Panjin are typical reed wetland landscape, While Cangzhou is typical fishpond landscape, Weifang and Binzhou are typical salt pond landscape. Land use in coast of Huludao, Yantai and Weifang are single dominated structure, the dominant land use type are farmland in Huludao and Yantai. It is salt pond in Weifang. Their dominant index is all above 0.34. Land use in coast of Tianjin, Qinhudao and other 8 regions are dual structure. The dominant index of dominant land use type ranged from 0.10 to 0.30. The land use intensity index is biggest in coast of Tianjin and Cangzhou with value 2.15 and 2.12, respectively.
C1 [Suo, Anning; Lin, Yong] Natl Marine Environm Monitoring Ctr, Dalian 116023, Peoples R China.
   [Zhang, Minghui] Dalian Ocean Univ, Coll Civil Engn, Dalian 116023, Peoples R China.
C3 National Marine Environmental Monitoring Center; Dalian Ocean University
RP Zhang, MH (corresponding author), Dalian Ocean Univ, Coll Civil Engn, Dalian 116023, Peoples R China.
EM zhang2015mail@foxmail.com
RI Zhang, Minghui/M-1873-2015
OI Zhang, Minghui/0000-0002-6158-7605
FU National Natural Science Funds of China [41376120]; Chinese Special
   Project for Marine Public [201105006]
FX The authors are grateful to the National Natural Science Funds of China
   (No. 41376120) and the Chinese Special Project for Marine Public (No.
   201105006) for financial support.
CR Allan JD, 2013, P NATL ACAD SCI USA, V110, P372, DOI 10.1073/pnas.1213841110
   Anfuso G, 2013, J COASTAL RES, V29, P1292, DOI 10.2112/JCOASTRES-D-12-00262.1
   Aning S, 2009, ACTA ECOL SIN, V29, P2289
   Arvor D, 2013, ISPRS J PHOTOGRAMM, V82, P125, DOI 10.1016/j.isprsjprs.2013.05.003
   Benediktsson JA, 2012, P IEEE, V100, P1907, DOI 10.1109/JPROC.2012.2190811
   Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Castilla G, 2008, PHOTOGRAMM ENG REM S, V74, P409, DOI 10.14358/PERS.74.4.409
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen JY, 2012, IEEE T GEOSCI REMOTE, V50, P4513, DOI 10.1109/TGRS.2012.2194502
   Chen Q, 2012, IET IMAGE PROCESS, V6, P426, DOI 10.1049/iet-ipr.2010.0078
   Dahiya S., 2013, IEEE 3 INT ADV COMP
   Dogliotti A, 2015, REMOTE SENS ENVIRON, V156, P157, DOI 10.1016/j.rse.2014.09.020
   Giupponi C, 2006, ENVIRON SCI POLICY, V9, P163, DOI 10.1016/j.envsci.2005.11.007
   Hay GJ, 2003, ISPRS J PHOTOGRAMM, V57, P327, DOI 10.1016/S0924-2716(02)00162-4
   Hepcan S, 2013, J COASTAL RES, V29, P301, DOI 10.2112/JCOASTRES-D-11-00064.1
   Hu CP, 2014, IEEE T EMERG TOP COM, V2, P376, DOI 10.1109/TETC.2014.2316525
   Jordan G, 2005, AGR ECOSYST ENVIRON, V108, P119, DOI 10.1016/j.agee.2005.01.013
   Klemas V, 2011, J COASTAL RES, V27, P2, DOI 10.2112/JCOASTRES-D-10-00103.1
   Li ZC, 2011, IEEE T IMAGE PROCESS, V20, P2017, DOI 10.1109/TIP.2010.2099128
   Liu XP, 2008, INT J GEOGR INF SCI, V22, P1247, DOI 10.1080/13658810701757510
   [马万栋 MA Wandong], 2008, [地理科学进展, Progress in Geography], V27, P87
   Murai H, 1997, INT J REMOTE SENS, V18, P811, DOI 10.1080/014311697218773
   Myint SW, 2011, REMOTE SENS ENVIRON, V115, P1145, DOI 10.1016/j.rse.2010.12.017
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Ramsey III Elijah, 2012, J COASTAL RES, V29, P301
   Ruiz-Luna A, 2003, LANDSCAPE ECOL, V18, P159, DOI 10.1023/A:1024461215456
   Suo AN, 2014, J SATELL OCEANOGR ME, V1, P23
   Suo AN, 2015, J COASTAL RES, P725, DOI 10.2112/SI73-124.1
   Tilton JC, 2012, IEEE T GEOSCI REMOTE, V50, P4454, DOI 10.1109/TGRS.2012.2190079
   Tong XH, 2014, IEEE J-STARS, V7, P3998, DOI 10.1109/JSTARS.2013.2272212
   Tweel AW, 2012, LIMNOL OCEANOGR, V57, P18, DOI 10.4319/lo.2012.57.1.0018
   van Hengstum PJ, 2007, J PALEOLIMNOL, V37, P603, DOI 10.1007/s10933-006-9057-y
   Wang ZW, 2010, ENVIRON MODELL SOFTW, V25, P1149, DOI 10.1016/j.envsoft.2010.03.019
   Weixin O, 2003, J PROG GEOGRAPHY, V22, P360, DOI [10.3969/j.issn.1007-6301.2003.04.004, DOI 10.3969/J.ISSN.1007-6301.2003.04.004]
   Wuest B, 2009, ISPRS J PHOTOGRAMM, V64, P55, DOI 10.1016/j.isprsjprs.2008.06.005
   Xiong J.-n., 2011, INT C COMP INF SCI I
   Xu Z, 2016, COMPUTING, V98, P35, DOI 10.1007/s00607-014-0408-7
   Xu Z, 2015, J SYST SOFTWARE, V102, P217, DOI 10.1016/j.jss.2014.07.024
   Xu Z, 2015, FUTURE GENER COMP SY, V43-44, P40, DOI 10.1016/j.future.2014.04.002
   Zhang L., 2014, GEOSCI REMOTE SENS L, V12, P58
   Zhong YF, 2014, IEEE T GEOSCI REMOTE, V52, P7023, DOI 10.1109/TGRS.2014.2306692
NR 42
TC 4
Z9 4
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 12061
EP 12075
DI 10.1007/s11042-016-3334-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200027
DA 2024-07-18
ER

PT J
AU de Ravé, EG
   Jiménez-Hornero, FJ
   Ariza-Villaverde, AB
   Taguas-Ruiz, J
AF Gutierrez de Rave, E.
   Jimenez-Hornero, F. J.
   Ariza-Villaverde, A. B.
   Taguas-Ruiz, J.
TI DiedricAR: a mobile augmented reality system designed for the ubiquitous
   descriptive geometry learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile augmented reality; Descriptive geometry; Interactive learning
   environments
ID ROTATIONS
AB This article presents a mobile Augmented Reality system, called DiedricAR, aimed at the learning of Descriptive Geometry. Thanks to its ability to recreate virtual models in real space, Augmented Reality is a technology suitable for making Descriptive Geometry comprehension and interpretation easier. The DiedricAR application allows students to learn in autonomously way by using their own mobile devices (smartphones and tablets), that work as Augmented Reality displays over training material (DiedricAR exercise workbook) specially designed for the new learning model defined by the European Higher Education System. Compared to some of the existing Augmented Reality systems used to learn Descriptive Geometry, DiedricAR offers the advantage of being specifically developed for mobile devices giving the students the possibility of using ubiquitous learning to its ultimate extent by interacting with the didactical content (i.e. showing the desired intermediate step when solving dihedral exercises). The presentation of DiedricAR is completed by exploring some key items such as the potential benefits for students' spatial ability, the relationship between application design and user experience, and software performance on several mobile devices.
C1 [Gutierrez de Rave, E.; Jimenez-Hornero, F. J.; Ariza-Villaverde, A. B.; Taguas-Ruiz, J.] Univ Cordoba, Dept Graph Engn, Gregor Mendel Bldg,Campus Rabanales, E-14071 Cordoba, Spain.
C3 Universidad de Cordoba
RP de Ravé, EG (corresponding author), Univ Cordoba, Dept Graph Engn, Gregor Mendel Bldg,Campus Rabanales, E-14071 Cordoba, Spain.
EM eduardo@uco.es
RI Jimenez-Hornero, Francisco J./P-9576-2019; Jimenez-Hornero, Francisco
   J./K-8771-2014; Gutierrez de Rave Aguera, Eduardo/I-6867-2017;
   Ariza-Villaverde, Ana B./I-6976-2017
OI Jimenez-Hornero, Francisco J./0000-0003-4498-8797; Gutierrez de Rave
   Aguera, Eduardo/0000-0002-2091-6708; Ariza-Villaverde, Ana
   B./0000-0002-8549-2774
FU ERDF Project (Spanish Ministry of Economy and Competitiveness)
   [CGL2014-54615-C2-1-R]
FX The authors gratefully acknowledge the support from ERDF Project
   CGL2014-54615-C2-1-R (Spanish Ministry of Economy and Competitiveness).
CR Alvarez N., 2003, P 2 INT C MULT ICTS, P1271
   [Anonymous], ICGTR2015001 GRAZ U
   [Anonymous], P ANN INT C VIRTUAL
   [Anonymous], 1977, Purdue spatial visualization tests
   [Anonymous], 2002, World Transactions on Engineering and Technology Education
   Azuma R, 2011, COMPUT GRAPH-UK, V35, pVII, DOI 10.1016/j.cag.2011.05.002
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bennett G, 2007, HDB DAT 5
   Billinghurst M, 2001, COMPUT GRAPH-UK, V25, P745, DOI 10.1016/S0097-8493(01)00117-0
   Bogen M, 2006, LECT NOTES COMPUT SC, V4227, P709
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Cheng KH, 2013, J SCI EDUC TECHNOL, V22, P449, DOI 10.1007/s10956-012-9405-9
   Coulby C, 2011, BRIT J EDUC TECHNOL, V42, P251, DOI 10.1111/j.1467-8535.2009.01022.x
   Cuendet S, 2013, COMPUT EDUC, V68, P557, DOI 10.1016/j.compedu.2013.02.015
   Dias A., 2009, International Business Economics Review, V1, P69
   Gammeter S., 2010, CVPR Workshops, P1
   Guay R.B., 1980, ANNU M AM EDUC RES
   Höllerer TH, 2004, TELEGEOINFORMATICS: LOCATION-BASED COMPUTING AND SERVICES, P221
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   Jee HK, 2014, MULTIMED TOOLS APPL, V68, P225, DOI 10.1007/s11042-011-0880-4
   Jerz R., 2002, ASEE ANN C P MONTR C
   Johnson L., 2011, The 2011 Horizon Report
   Kaufmann H, 2003, COMPUT GRAPH-UK, V27, P339, DOI 10.1016/S0097-8493(03)00028-1
   Kim JI, 2011, COMM COM INF SC, V151, P255
   Klopfer E, 2002, IEEE INTERNATIONAL WORKSHOP ON WIRELESS AND MOBILE TECHNOLOGIES IN EDUCATION, PROCEEDINGS, P95, DOI 10.1109/WMTE.2002.1039227
   Klopfer E, 2005, CSCL 2005: COMPUTER SUPPORTED COLLABORATIVE LEARNING 2005: THE NEXT 10 YEARS, PROCEEDINGS, P316
   Ko SM, 2013, INT J HUM-COMPUT INT, V29, P501, DOI 10.1080/10447318.2012.722466
   Kock T., 2010, P STUD TOUR PIX TWEN
   Kourouthanassis PE, 2015, MULTIMED TOOLS APPL, V74, P1045, DOI 10.1007/s11042-013-1710-7
   Lazoudis A., 2011, P SCI CTR GO WORKSHO, P27
   Liarokapis F., 2004, WORLD T ENG TECHNOLO, V3, P12
   Linaza MT, 2012, INFORMATION AND COMMUNICATION TECHNOLOGIES IN TOURISM 2012, P260
   Loscos C, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P282, DOI 10.1109/ISMAR.2003.1240721
   Maeda Y, 2013, EDUC PSYCHOL REV, V25, P69, DOI 10.1007/s10648-012-9215-x
   Martin-Gutierrez J., 2011, 41 ASEE IEEE FRONT E
   Martín-Gutiérrez J, 2010, COMPUT GRAPH-UK, V34, P77, DOI 10.1016/j.cag.2009.11.003
   Navarro R., 2004, 12 C INT INN ED BARC
   Nincarean D, 2013, PROCD SOC BEHV, V103, P657, DOI 10.1016/j.sbspro.2013.10.385
   Papagiannakis G, 2008, COMPUT ANIMAT VIRT W, V19, P3, DOI 10.1002/cav.221
   Pellegrino J.W., 1984, EDUC PSYCHOL-US, V19, P239, DOI DOI 10.1080/004615284095
   Petrova K, 2007, INT J INNOV LEARN, V4, P1, DOI 10.1504/IJIL.2007.011471
   RAMBLI DRA, 2007, 1 INT MAL ED TECHN C
   Rosenblum L.J., 2012, EXPANDING FRONTIERS, P431, DOI DOI 10.1007/978-1-4471-2804-5_24
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   Seichter H, 2009, INT SYM MIX AUGMENT, P213, DOI 10.1109/ISMAR.2009.5336455
   Sorby SA, 2001, 4 INT C GRAPH ARTS D, P1285
   Specht M., 2011, J RES ED TECHNOLOGY, V7, P117
   Strong S., 2001, J IND TECHNOLOGY, V18, P1
   Traxler J., 2005, IADIS International Conference on Mobile Learning, P261
   Van Krevelen D. W. F., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10/ggxxt5
   VANDENBERG SG, 1978, PERCEPT MOTOR SKILL, V47, P599, DOI 10.2466/pms.1978.47.2.599
   Vargas H, 2013, INT J COMPUT COMMUN, V8, P622, DOI 10.15837/ijccc.2013.4.42
   Wagner D, 2009, 2009 INTERNATIONAL SYMPOSIUM ON UBIQUITOUS VIRTUAL REALITY (ISUVR 2009), P7, DOI 10.1109/ISUVR.2009.11
   Wagner D, 2009, IEEE COMPUT GRAPH, V29, P6, DOI 10.1109/MCG.2009.67
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yuen S.C.Y., 2011, J. Educ. Technol. Dev. Exch. (JETDE), V4, P11, DOI [10.18785/jetde.0401.10, DOI 10.18785/JETDE.0401.10]
   Zagoranski S, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P339
NR 57
TC 36
Z9 41
U1 0
U2 74
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9641
EP 9663
DI 10.1007/s11042-016-3384-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500008
DA 2024-07-18
ER

PT J
AU Lin, YC
   Lai, JC
   Cheng, HC
AF Lin, Yih-Chuan
   Lai, Jian-Cheng
   Cheng, Hsu-Chun
TI Coding unit partition prediction technique for fast video encoding in
   HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; H.264/AVC; Fast CU decision; CU partition; Video coding
ID CU SIZE DECISION; MODE DECISION; INTRA; ALGORITHM
AB In this paper, a prediction technique for the best coding unit (CU) partition tree is proposed to avoid the repeated computation on the variable-sized prediction units (PU) and transform units (TU) in high efficiency video coding (HEVC). In HEVC, many advanced coding tools are introduced to decrease the bit-rate of coded videos with higher visual quality. Of these tools, many seek to partition each CU in the incoming frame into a quad-tree structure of variable sized blocks while performing prediction and transform computations to obtain the optimal rate-distortion performance. During partition tree generation, the CU block and its four partitioned child-blocks need to become PU and TU for calculating the coding rate-distortion cost. This process requires more execution time from the processor because of highly repeated computations on PUs and TUs before finding the best quad-tree partition tree. The proposed prediction technique is based on edge information from the content of the considered CU and the depth information of partition tree from the co-located CU in the neighboring video frames for being able to adapt the reduction of computation time with the varying content in the incoming frames. When the CU is in a smooth frame, the information from the neighboring frames would dominate the prediction results of the partition tree; however, the edge information of the current CU mainly determines the partition tree. With the prediction technique, experiments on several benchmark videos show that the encoding time of HEVC can be reduced by 44.1 % at an acceptable degradation of coding efficiency.
C1 [Lin, Yih-Chuan; Lai, Jian-Cheng; Cheng, Hsu-Chun] Natl Formosa Univ, Dept Comp Sci & Informat Engn, Yunlin 63201, Taiwan.
C3 National Formosa University
RP Lin, YC (corresponding author), Natl Formosa Univ, Dept Comp Sci & Informat Engn, Yunlin 63201, Taiwan.
EM lyc@nfu.edu.tw
CR [Anonymous], 2001, ITU T VCEG M AUST TE
   [Anonymous], 2010, JCTVCC207
   Chen CN, 2014, MULTIMED TOOLS APPL, V72, P687, DOI 10.1007/s11042-013-1388-x
   Cheng YL, 2012, COMM COM INF SC, V331, P292
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Juan He, 2014, Journal of Communications, V9, P441, DOI 10.12720/jcm.9.5.441-447
   Kim Y, 2013, ETRI J, V35, P270, DOI 10.4218/etrij.13.0112.0223
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lee H, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.11.117001
   Lin Yih-Chuan, 2015, J. appl. res. technol, V13, P205
   Qin HC, 2011, KEY ENG MATER, V460-461, P810, DOI 10.4028/www.scientific.net/KEM.460-461.810
   RICHARDSON IEG, 2003, H 264 AVC MPEG 4 VID
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shen XL, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P453, DOI 10.1109/PCS.2012.6213252
   Sullivan G.J., 2014, High Efficiency Video Coding (HEVC)"
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhao Liang, 2011, VISUAL COMMUN-US, P1, DOI DOI 10.1109/VCIP.2011.6115979
   Zhao WQ, 2012, COMM COM INF SC, V331, P284
NR 20
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9861
EP 9884
DI 10.1007/s11042-015-2778-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500020
DA 2024-07-18
ER

PT J
AU Liang, XH
   Yuan, CQ
AF Liang, Xiaohui
   Yuan, Chunqiang
TI Derivation of 3D cloud animation from geostationary satellite images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geostationary satellite image; 3D cloud animation; Weather presentation;
   Physically based system; Meteorological models
ID OPTICAL-THICKNESS; RADIATIVE-TRANSFER; PARAMETERIZATION; RETRIEVAL
AB Large-scale cloud animation is crucial to TV weather presentation, weather observer training and video products. In this paper, a physically based system is presented for the derivation of time-varying 3D clouds from geostationary satellite images. Cloud properties are derived from a set of meteorological models while the clouds are rendered by graphics models, the proposed method thus presents a new modeling methodology, which integrates the reality of the data with the realistic visual feeling. In particular, image pixels are first classified into cloud-free, water cloud, ice cloud, thin cirrus cloud in terms of their spectral signature. Then, cloud top surface, cloud bottom surface and cloud extinction are generated by applying different combinations of images. Finally, clouds are rendered under various light directions or view directions. The results have indicated that the proposed method can yield a realistic and approximately valid clouds with similar appearance to those in the input satellite images.
C1 [Liang, Xiaohui; Yuan, Chunqiang] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
C3 Beihang University
RP Liang, XH (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
EM liang_xiaohui@buaa.edu.cn; chunqiang.yuan@hotmail.com
OI liang, xiaohui/0000-0001-6351-2538
FU National Natural Science Foundation of China [61170186]; National High
   Technology Research and Development Program of China [2013AA013701]
FX This paper is supported by the National Natural Science Foundation of
   China (No. 61170186) and the National High Technology Research and
   Development Program of China (No. 2013AA013701). We would like to thank
   the anonymous reviewers for helpful comments, and Professor Jiming Sun
   for the useful discussions on cloud physics.
CR alvarez L, 2006, IEEE C COMP VIS PATT
   Baker N, 2012, JOINT POLAR SATELLIT
   Bouthors A., 2004, EUROGRAPHICS SHORT P
   Chen W, 2005, SATELLITE METEOROLOG
   CLARK TL, 1974, J ATMOS SCI, V31, P142, DOI 10.1175/1520-0469(1974)031<0142:ASICPP>2.0.CO;2
   Dobashi Y, 1998, PACIFIC GRAPHICS '98, PROCEEDINGS, P53, DOI 10.1109/PCCGA.1998.731998
   Dobashi Y., 2009, PACIFIC GRAPHICS 200
   Dobashi Y, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366164
   Dobashi Y, 2010, COMPUT GRAPH FORUM, V29, P2083, DOI 10.1111/j.1467-8659.2010.01795.x
   Dobashi Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360693
   Ebert D. S., 1997, VISUAL P SIGGRAPH 97, P147
   Gardner G. Y., 1985, Computer Graphics, V19, P297, DOI 10.1145/325165.325248
   Harris MJ, 2001, COMPUT GRAPH FORUM, V20, pC76, DOI 10.1111/1467-8659.00500
   Hocking J, 2011, METEOROL APPL, V18, P307, DOI 10.1002/met.239
   INOUE T, 1987, J GEOPHYS RES-ATMOS, V92, P3991, DOI 10.1029/JD092iD04p03991
   Kajiya J. T., 1984, Computers & Graphics, V18, P165
   Kishtawal C, 2003, SATELLITE REMOTE SEN, P67
   Kokhanovsky AA, 2004, P SOC PHOTO-OPT INS, V5571, P86, DOI 10.1117/12.564741
   Kokhanovsky AA, 2005, J GEOPHYS RES, V110, P1984
   Miyazaki R, 2001, NINTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P363, DOI 10.1109/PCCGA.2001.962893
   NAKAJIMA T, 1990, J ATMOS SCI, V47, P1878, DOI 10.1175/1520-0469(1990)047<1878:DOTOTA>2.0.CO;2
   Nauss T, 2011, REMOTE SENS ENVIRON, V115, P1317, DOI 10.1016/j.rse.2011.01.010
   Nishita T., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P379, DOI 10.1145/237170.237277
   Ou SC, 2003, APPL OPTICS, V42, P7202, DOI 10.1364/AO.42.007202
   Pandey P, 2012, ATMOS CHEM PHYS, V12, P7961, DOI 10.5194/acp-12-7961-2012
   Pruppacher HR, 1998, MICROPHYSICS CLOUDS
   Qiang F, 2008, J ATMOS SCI, V50
   Ricchiazzi P, 1998, B AM METEOROL SOC, V79, P2101, DOI 10.1175/1520-0477(1998)079<2101:SARATS>2.0.CO;2
   Riley K, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P279, DOI 10.1109/VISUAL.2003.1250383
   Schpok J., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P160
   SETVAK M, 1991, MON WEATHER REV, V119, P841, DOI 10.1175/1520-0493(1991)119<0841:TACCTR>2.0.CO;2
   SLINGO A, 1989, J ATMOS SCI, V46, P1419, DOI 10.1175/1520-0469(1989)046<1419:AGPFTS>2.0.CO;2
   SZEJWACH G, 1982, J APPL METEOROL, V21, P384, DOI 10.1175/1520-0450(1982)021<0384:DOSTCC>2.0.CO;2
   Wither J, 2008, EUR WORKSH SKETCH BA
   Wong E, 2011, JOINT POLAR SATELLIT
   Xu J, 2008, HDB FY2 PRODUCTS DAT
   Yuan C, 2013, PACIFIC GRAPHICS SHO
   Yuan CQ, 2014, COMPUT GRAPH FORUM, V33, P288, DOI 10.1111/cgf.12350
NR 38
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8217
EP 8237
DI 10.1007/s11042-015-2738-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300005
DA 2024-07-18
ER

PT J
AU Lin, YL
   Wang, MJJ
AF Lin, Yueh-Ling
   Wang, Mao-Jiun J.
TI The development of a clothing fit evaluation system under virtual
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fit evaluation; Virtual try-on; Real body; Virtual model; Visual
   analysis; Vacant space area
ID 3D GARMENTS; DESIGN; GENERATION
AB This study proposes an innovative clothing fit evaluation method for virtual try- on using 3D digital human model. The clothing patterns are first designed and subsequently sewn together around a human model. Because complex cloth shapes are difficult to fit onto the human body, this study proposes a 3D human model dressed using virtual clothes according to the model's body shape. Different clothing sizes are tested to fit onto a human body to assure satisfactory fit. Several test subjects were recruited in this study. Representations of several different sized clothing were compared between an actual human body (RB) and virtual model (VM) to evaluate the virtual try-on clothing fit. The clothing fit of specified sizes was evaluated quantitatively by calculating the vacant space area between the clothes and human body. The vacant space measure is used to perform real and virtual body fit evaluations. The clothing fit information obtained in this study can be applied to the development of clothing products in the apparel industry.
C1 [Lin, Yueh-Ling; Wang, Mao-Jiun J.] Natl Tsing Hua Univ, Dept Ind Engn & Engn Management, 101,Sect 2 Kuang Fu Rd, Hsinchu 30013, Taiwan.
C3 National Tsing Hua University
RP Wang, MJJ (corresponding author), Natl Tsing Hua Univ, Dept Ind Engn & Engn Management, 101,Sect 2 Kuang Fu Rd, Hsinchu 30013, Taiwan.
EM d943845@oz.nthu.edu.tw; mjwang@ie.nthu.edu.tw
CR Alexander M, 2005, INT J CLOTH SCI TECH, V17, P52, DOI 10.1108/09556220510577961
   [Anonymous], 2002, GEOM US MAN
   [Anonymous], SCANWORX US MAN
   [Anonymous], 2011, THESIS
   Ashdown Susan P., 2004, Journal of Textile and Apparel, Technology and Management, V4, P1
   Au CK, 2010, COMPUT IND, V61, P524, DOI 10.1016/j.compind.2010.03.002
   Chen Y, 2008, INT J CLOTH SCI TECH, V20, P161, DOI 10.1108/09556220810865210
   Cho CS, 2010, COMPUT IND, V61, P550, DOI 10.1016/j.compind.2010.03.005
   Huang HQ, 2012, COMPUT IND, V63, P680, DOI 10.1016/j.compind.2012.04.001
   Keckeisen M, 2005, THESIS
   Lee J, 2007, LECT NOTES COMPUT SC, V4559, P550
   Li JT, 2014, COMPUT AIDED DESIGN, V49, P28, DOI 10.1016/j.cad.2013.12.005
   Li JT, 2011, COMPUT IND, V62, P693, DOI 10.1016/j.compind.2011.04.002
   Lin CC, 1985, CULTURAL CLOTHING
   Liu L, 2013, MULTIMEDIA TOOLS APP
   Liu YJ, 2010, COMPUT IND, V61, P576, DOI 10.1016/j.compind.2010.03.007
   Loker S., 2005, J TEXTILE APPAREL TE, V4, P1
   Magnenat-Thalmann N, 2005, VISUAL COMPUT, V21, P506, DOI 10.1007/s00371-005-0347-6
   Meng YW, 2012, COMPUT AIDED DESIGN, V44, P721, DOI 10.1016/j.cad.2012.03.006
   Meng YW, 2010, COMPUT AIDED DESIGN, V42, P310, DOI 10.1016/j.cad.2009.12.004
   Phoebe RA, 2007, J FASH MARK MANAG, V11, P349
   Volino P, 2005, COMPUT AIDED DESIGN, V37, P593, DOI 10.1016/j.cad.2004.09.003
   Xu B., 2003, J TEXT I, V94, P92
   Yu H, 2011, MULTIMEDIA TOOLS APP
   Zhang M, 2013, MULTIMEDIA TOOLS APP
NR 25
TC 17
Z9 18
U1 5
U2 91
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7575
EP 7587
DI 10.1007/s11042-015-2681-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600006
DA 2024-07-18
ER

PT J
AU Liu, QG
   Xiong, B
   Yang, DC
   Zhang, MH
AF Liu, Qiegen
   Xiong, Biao
   Yang, Dingcheng
   Zhang, Minghui
TI A generalized relative total variation method for image smoothing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image smoothing; Structure preserving; non-convex regularization;
   Iterative Reweighed Least Square
ID MINIMIZATION
AB Recently, two piecewise smooth models L0smoothing and relative total variation (RTV) have been proposed for feature/structure-preserving filtering. One is very efficient for tackling image with little texture patterns and the other has appearance performance on image with abundant uniform textural details. In this work, we present a general relative total variation (GRTV) method, which generalizes the advantages of both approaches. The efficiency of RTV depends on the defined windowed total variation (WTV) and windowed inherent variation (WIV), which focus on edge enhancing and texture suppressing respectively. The key innovations of the presented GRTV method are to extend the norm of WTV in RTV from 1 to [0, 1] and set the norm of WIV inversely proportional to the norm of WTV. These modifications substantially improve the structure extraction ability of RTV. The presented GRTV also improves the edge-boundary enhancing ability of L0smoothing and further enables it to deal with images containing complex textural details and noises. Furthermore, the L2-norm data fidelity term replaced by L1-norm is discussed. Experimental results demonstrate that the proposed method presents better performance as the state-of-the-art methods do.
C1 [Liu, Qiegen; Yang, Dingcheng; Zhang, Minghui] Nanchang Univ, Dept Elect Informat Engn, Nanchang, Peoples R China.
   [Xiong, Biao] Univ Twente, Fac Geoinformat Sci & Earth Observat ITC, Enschede, Netherlands.
C3 Nanchang University; University of Twente
RP Liu, QG (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang, Peoples R China.
EM liuqiegen@ncu.edu.cn; sailor080@126.com; ydcxuanyuan@msn.com;
   zhangmh3529@163.com
RI Yang, Dingcheng/GON-7211-2022; Li, Yuanyuan/J-3539-2014
OI Li, Yuanyuan/0000-0001-6151-9306
FU National Natural Science Foundation of China [61362001, 62162084,
   61261010, 61365013, 51165033]; Science and Technology Department of
   Jiangxi Province of China [20121BBE50023, 20132BAB211030]; Young
   Scientists Training Program of Jiangxi Province [20133ACB21007,
   20142BCB23001]; International Scientific Cooperation Project of Jiangxi
   Province [20141BDH80001]; Jiangxi Advanced Project for Post-doctoral
   Research Funds [2014KY02]; Post-doctoral Research Funds [2014 M551867]
FX This work was partly supported by the National Natural Science
   Foundation of China under 61362001, 62162084, 61261010, 61365013,
   51165033, the Science and Technology Department of Jiangxi Province of
   China under 20121BBE50023, 20132BAB211030, Young Scientists Training
   Program of Jiangxi Province under 20133ACB21007, 20142BCB23001,
   International Scientific Cooperation Project of Jiangxi Province under
   20141BDH80001, Jiangxi Advanced Project for Post-doctoral Research Funds
   under 2014KY02 and Post-doctoral Research Funds under 2014 M551867.
CR ALLINEY S, 1992, IEEE T SIGNAL PROCES, V40, P1548, DOI 10.1109/78.139258
   [Anonymous], 2012, CVPR
   Bac S, 2007, COMPUT GRAPH FORUM, V26, P571, DOI 10.1111/j.1467-8659.2007.01080.x
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Buades A, 2010, IEEE T IMAGE PROCESS, V19, P1978, DOI 10.1109/TIP.2010.2046605
   Cheng X, 2014, COMPUT GRAPH-UK, V38, P150, DOI 10.1016/j.cag.2013.10.025
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Karacan L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508403
   Liu QG, 2012, J VIS COMMUN IMAGE R, V23, P753, DOI 10.1016/j.jvcir.2012.04.003
   Nikolova M, 2002, SIAM J NUMER ANAL, V40, P965, DOI 10.1137/S0036142901389165
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rao BD, 1999, IEEE T SIGNAL PROCES, V47, P187, DOI 10.1109/78.738251
   Rodrguez P., 2008, P 4 IEEE AND TECHN C
   Rodríguez P, 2009, IEEE T IMAGE PROCESS, V18, P322, DOI 10.1109/TIP.2008.2008420
   Rousselle F, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366214
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shen C-T, 2010, EDGE PRESERVING IMAG
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Ye  C., 2013, ARXIV13053971
NR 29
TC 12
Z9 12
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7909
EP 7930
DI 10.1007/s11042-015-2709-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600022
DA 2024-07-18
ER

PT J
AU Mansouri, S
   Ebrahimnezhad, H
AF Mansouri, Saeid
   Ebrahimnezhad, Hossein
TI Efficient axial symmetry aware mesh approximation with application to 3D
   pottery models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Virtual museum; 3D pottery models; Mesh approximation;
   Lossy compression; Axial symmetry; Circle fitting; Slicing parallel
   planes; Sector slicing planes
ID ADAPTIVE SIMPLIFICATION
AB Motivated by the current requirements of digital 3D museums in the low bandwidth networks, we present a novel and efficient approximation algorithm based on axial symmetry of 3D pottery model. Available simplification algorithms suppress detailed features of the mesh without any change to the rest of 3D model. In this paper, we reduce data for mesh representation while preserving the geometric approximation as well as the model quality of the resulting mesh. First, the main symmetry axis of the pottery model is determined and then main body is detected by slicing parallel planes and separation criteria introduced in our proposed algorithm. Second, actual handles are detected based on sector slicing planes using a robust handle separation scheme. Third, every detected part, i.e. main body and handles, is approximated using a novel circle fitting method. Finally, generated vertices are remeshed and create approximated mesh. Experimental results are presented to illustrate superiority and affectivity of our method. Compared with available mesh simplification algorithms and using the same amount of data to represent the model, the proposed approach gives significant improvement in the accuracy of the approximated 3D potteries.
C1 [Mansouri, Saeid; Ebrahimnezhad, Hossein] Sahand Univ Technol, Fac Elect Engn, ICT Ctr, Comp Vis Res Lab, Tabriz, Iran.
C3 Sahand University of Technology
RP Ebrahimnezhad, H (corresponding author), Sahand Univ Technol, Fac Elect Engn, ICT Ctr, Comp Vis Res Lab, Tabriz, Iran.
EM s_mansouri@sut.ac.ir; ebrahimnezhad@sut.ac.ir
RI ebrahimnezhad, hossein/ABC-3865-2021; Ebrahimnezhad,
   Hossein/ACP-2704-2022
OI ebrahimnezhad, hossein/0000-0003-4071-2750; 
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   Bokeloh M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778841
   Botsch M., 2010, Polygon Mesh Processing
   Brodsky D, 2000, PROC GRAPH INTERF, P221
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Castello P, 2014, COMPUT AIDED GEOM D, V31, P279, DOI 10.1016/j.cagd.2014.05.001
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Choi HK, 2010, INT J ADV MANUF TECH, V50, P235, DOI 10.1007/s00170-009-2484-y
   Cohen J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P119, DOI 10.1145/237170.237220
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Gal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531339
   Gao SM, 2010, COMPUT AIDED DESIGN, V42, P1178, DOI 10.1016/j.cad.2010.05.010
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Gotsman C, 2002, TUTORIALS ON MULTIRESOLUTION IN GEOMETRIC MODELLING, P319
   Guéziec A, 1999, IEEE T VIS COMPUT GR, V5, P168, DOI 10.1109/2945.773810
   HECKBERT PS, 1997, SIGGRAPH 97 COURSES
   Hoppe H., 1993, Computer Graphics Proceedings, P19, DOI 10.1145/166117.166119
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Ioannou D, 1999, IMAGE VISION COMPUT, V17, P15, DOI 10.1016/S0262-8856(98)00090-0
   Koutsoudis A, 2008, EUR WORKSH 3D OBJ RE
   Luebke D., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P199, DOI 10.1145/258734.258847
   Morigi S, 2014, VISUAL COMPUT, V30, P479, DOI 10.1007/s00371-013-0873-6
   Pavlidis G, 2006, P 3 INT C MUS JUN 06
   Payne A, 2009, HAMPSON VIRTUAL MUSE
   Ronfard R., 1996, Computer Graphics Forum, V15, pC67, DOI 10.1111/1467-8659.1530067
   Rossignac J., 1993, Geometric Modeling in Computer Graphics, P455
   SCHROEDER WJ, 1992, COMP GRAPH, V26, P65, DOI 10.1145/142920.134010
   Shaffer E, 2001, IEEE VISUAL, P127, DOI 10.1109/VISUAL.2001.964503
   Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x
   Shi BQ, 2011, COMPUT AIDED DESIGN, V43, P910, DOI 10.1016/j.cad.2011.04.001
   Shiaw HY, 2004, ACM-IEEE J CONF DIG, P125
   Shu ZY, 2009, J ZHEJIANG UNIV-SC A, V10, P535, DOI 10.1631/jzus.A0820229
   Soucy M, 1996, COMPUT VIS IMAGE UND, V63, P1, DOI 10.1006/cviu.1996.0001
   Thomas DM, 2012, IEEE J SEL TOP QUANT, V18, P1493, DOI 10.1109/JSTQE.2012.2187276
   Tsirliganis N, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P475, DOI 10.1109/ICDSP.2002.1027921
   TURK G, 1992, COMP GRAPH, V26, P55, DOI 10.1145/142920.134008
   TURK G, 2001, SIGGRAPH 01, P327
   Valette S, 2008, IEEE T VIS COMPUT GR, V14, P369, DOI 10.1109/TVCG.2007.70430
   Witkin A. P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P269, DOI 10.1145/192161.192227
   Zheng QA, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778831
NR 41
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8347
EP 8379
DI 10.1007/s11042-015-2753-8
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300010
DA 2024-07-18
ER

PT J
AU Zhao, Y
   Zhang, XF
   Wang, YL
   Xu, LM
AF Zhao, Yue
   Zhang, Xiaofen
   Wang, Yalin
   Xu, Limin
TI Camera self-calibration based on circular points with two planar mirrors
   using silhouettes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera intrinsic parameters; Two planar mirrors; Circular points;
   Silhouette; Vanishing point
ID RECONSTRUCTION
AB Multiple images of an object can be obtained from a catadioptric system consisting of a pinhole camera and two planar mirrors. In this paper, we present two types of algorithm for obtaining the intrinsic parameters of a camera by computing the imaged circular points. First, according to the geometric features of the two planar mirror images, the vanishing points along the normal directions of the planar mirrors are obtained, and the vanishing points along the directions of the planar mirrors are computed using the cross-ratio invariability. Subsequently, we propose two methods of solving for the imaged circular points: one uses the inference of the Laguerre theorem, and the other uses the intersection points of the conic image and the vanishing line. Finally, the camera's intrinsic parameters are obtained by applying the constraints on imaging the circular points to the image of the absolute conic. A simulation, real data, and a 3D reconstruction are presented to show the feasibility and validity of the proposed approaches.
C1 [Zhao, Yue; Zhang, Xiaofen; Wang, Yalin; Xu, Limin] Yunnan Univ, Sch Math & Stat, Kunming, Yunnan, Peoples R China.
C3 Yunnan University
RP Zhao, Y (corresponding author), Yunnan Univ, Sch Math & Stat, Kunming, Yunnan, Peoples R China.
EM zhao6685@yeah.net
FU National Natural Science Foundation of China [11361074]; Natural Science
   Foundation of Yunnan Province, China [2011FB017]
FX This research was supported by the National Natural Science Foundation
   of China (No. 11361074) and the Natural Science Foundation of Yunnan
   Province, China (2011FB017).
CR [Anonymous], P CVPR
   Bottino A, 2003, IEEE T PATTERN ANAL, V25, P1484, DOI 10.1109/TPAMI.2003.1240121
   Forbes K, 2004, P 15 ANN S PATT REC, P39
   Forbes K, 2006, LECT NOTES COMPUT SC, V3952, P165
   Fujiyama Shinji, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P45, DOI 10.1109/ICPR.2010.20
   Gluckman J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P22, DOI 10.1109/CVPR.1999.786912
   Gluckman J, 2002, IEEE T PATTERN ANAL, V24, P224, DOI 10.1109/34.982902
   Han JY, 2003, ACM T GRAPHIC, V22, P741, DOI 10.1145/882262.882341
   Hecht E., 1979, OPTICS
   Hu B., 2005, TR863 U ROCH COMP SC
   Huang Y. Anny, 2008, 2008 IEEE International Symposium on Electronics and the Environment, P1, DOI 10.1109/ISEE.2008.4562890
   Kim JH, 2013, OPT EXPRESS, V21, P4456, DOI 10.1364/OE.21.004456
   Kumar R.K., 2008, Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2008.4587676
   Lanman D, 2009, COMPUT VIS IMAGE UND, V113, P1107, DOI 10.1016/j.cviu.2009.03.016
   Mariottini GL, 2009, IEEE INT CONF ROBOT, P1510, DOI 10.1109/ROBOT.2009.5152609
   MITSUMOTO H, 1992, IEEE T PATTERN ANAL, V14, P941, DOI 10.1109/34.161352
   Mülayim AY, 2003, IEEE T SYST MAN CY B, V33, P582, DOI 10.1109/TSMCB.2003.814303
   Okatani T, 2000, P IAPR C MACH VIS AP
   SEMPLE JG, 1952, ALGEBRAIC PROJECTIVE
   Springer C.E., 1964, Geometry and Analysis of Projective Spaces
   Tan KH, 2004, IEEE T PATTERN ANAL, V26, P941, DOI 10.1109/TPAMI.2004.33
   Wong KYK, 2004, IEEE T IMAGE PROCESS, V13, P379, DOI 10.1109/TIP.2003.821113
   Wu HHP, 2007, IEEE T CIRC SYST VID, V17, P686, DOI 10.1109/TCSVT.2007.896629
   Ying XH, 2013, IEEE T PATTERN ANAL, V35, P1206, DOI 10.1109/TPAMI.2012.195
   Ying XH, 2010, PROC CVPR IEEE, P1126, DOI 10.1109/CVPR.2010.5540088
   Zhong H, 2006, INT C PATT RECOG, P715
NR 26
TC 3
Z9 3
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7981
EP 7997
DI 10.1007/s11042-015-2716-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600025
DA 2024-07-18
ER

PT J
AU Ai, N
   Peng, JY
   Zhu, X
   Feng, XY
AF Ai, Na
   Peng, Jinye
   Zhu, Xuan
   Feng, Xiaoyi
TI Single image super-resolution by combining self-learning and
   example-based learning methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image super-resolution; Example-based learning; Sparse
   representation model; Boot-strapping approach
ID DICTIONARIES; SPARSE
AB In this paper we propose a novel method for single image super-resolution (SISR) by combining self-learning method and example-based learning method. The self-learning method we used which is proposed by Zeyde et al. (2012) has the ability to scale-up a single image from the given low-resolution (LR) image itself by learning a dictionary pair directly from the given LR image (as high-resolution image) and its scaled-down version (as LR image). This is the so-called boot-strapping method in Zeyde, Elad, Protter (Lect Notes Comput Sci 6920:711-730, 2012). With the output image obtained by the boot-strapping method and the original high-resolution (HR) image, we can get a super-resolution image by learning the sparse representation model proposed in Na, Jinye, Xuan, Xiaoyi (Multimed Tools Appl 74:1997-2007, 2015). Our combined approach shows to perform better even when there are little training example images. A number of experimental results on true images show that our method gains both visual and PSNR improvements.
C1 [Ai, Na; Peng, Jinye; Feng, Xiaoyi] Northwest Polytech Univ, Sch Elect & Informat, Xian 710129, Peoples R China.
   [Ai, Na; Peng, Jinye; Zhu, Xuan] NW Univ Xian, Sch Informat & Technol, Xian 710127, Peoples R China.
C3 Northwestern Polytechnical University; Northwest University Xi'an
RP Ai, N (corresponding author), Northwest Polytech Univ, Sch Elect & Informat, Xian 710129, Peoples R China.; Ai, N (corresponding author), NW Univ Xian, Sch Informat & Technol, Xian 710127, Peoples R China.
EM aina_008@163.com
RI Peng, Jin/HZH-6965-2023
FU Science Foundation of Northwest University [ND10010]
FX This work was supported by Science Foundation of Northwest University
   (ND10010).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2009, INT C COMP VIS
   Elad M., 2006, INT C COMP VIS PATT
   Elad M., 2007, COMPUT J, V50, P1
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1
   Marquina A, 2008, J SCI COMPUT, V37, P367, DOI 10.1007/s10915-008-9214-8
   Na A, 2013, MULTIMED TOOLS APPL, V74, P1997
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   SCHULTZ RR, 1994, IEEE T IMAGE PROCESS, V3, P233, DOI 10.1109/83.287017
   Weisheng Dong et el, 2011, IEEE IP, V20
   Yang J., 2010, IEEE Transactions on Image Processing, V19, P2861
   Zeyde R., 2012, Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), V6920, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
NR 14
TC 9
Z9 11
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6647
EP 6662
DI 10.1007/s11042-015-2597-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700029
DA 2024-07-18
ER

PT J
AU Orozco, ALS
   Corripio, JR
   Villalba, LJG
   Castro, JCH
AF Sandoval Orozco, Ana Lucila
   Rosales Corripio, Jocelin
   Garcia Villalba, Luis Javier
   Castro, Julio Cesar Hernandez
TI Image source acquisition identification of mobile devices based on the
   use of features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forensics analysis; Counter forensics; Image anonymity; Image forgery;
   Photo response non uniformity; Wavelet
ID CAMERA IDENTIFICATION; CLASSIFICATION; FORENSICS; METADATA
AB Nowadays, forensic analysis of digital images is especially important, given the frequent use of digital cameras in mobile devices. The identification of the device type or the make and model of image source are two important branches of forensic analysis of digital images. In this paper we have addressed both of these, with an approach based on different types of image features and the classification using support vector machines. The study has mainly focused on images created with mobile devices and as a result, the techniques and features have been adapted or created for this purpose. There have been a total of 36 experiments classified into 5 sets, in order to test different configurations of the techniques. In the configuration of the experiments, the future use of the technique by the forensic analyst in real situations to create experiments with high technical requirements was taken into account, amongst other things.
C1 [Sandoval Orozco, Ana Lucila; Rosales Corripio, Jocelin; Garcia Villalba, Luis Javier] UCM, Fac Comp Sci & Engn, Dept Software Engn & Artificial Intelligence DISI, GASS,Off 431, Calle Prof Jose Garcia Santesmases,9,Ciudad Univ, Madrid 28040, Spain.
   [Castro, Julio Cesar Hernandez] Univ Kent, Sch Comp, Off S129A, Cornwallis South Bldg, Canterbury CT2 7NF, Kent, England.
C3 Complutense University of Madrid; University of Kent
RP Villalba, LJG (corresponding author), UCM, Fac Comp Sci & Engn, Dept Software Engn & Artificial Intelligence DISI, GASS,Off 431, Calle Prof Jose Garcia Santesmases,9,Ciudad Univ, Madrid 28040, Spain.
EM asandoval@fdi.ucm.es; jocelinr@ucm.es; javiergv@fdi.ucm.es;
   J.C.Hernandez-Castro@kent.ac.uk
RI Villalba, Luis Javier Garcí­a/N-4631-2014; Sandoval Orozco, Ana
   Lucila/H-4148-2012
OI Sandoval Orozco, Ana Lucila/0000-0002-2846-9017; Hernandez-Castro, Julio
   C./0000-0002-6432-5328
FU MECD; MICINN
FX Part of the computations of this work were performed in EOLO, the HPC of
   Climate Change of the International Campus of Excellence of Moncloa,
   funded by MECD and MICINN.
CR Al-Zarouni M, 2006, P 4 AUSTR DIG FOR C
   Baer R, 2010, P IM SYST C TUCS AR, pITuB3, DOI [10.1364/IS.2010.ITuB3, DOI 10.1364/IS.2010.ITUB3]
   Bayram S., 2006, P WG, P24
   Bayram S, 2008, DIGIT INVEST, V5, P49, DOI 10.1016/j.diin.2008.06.004
   Bo Wang, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P702, DOI 10.1109/IIH-MSP.2009.244
   Boutell M, 2005, PATTERN RECOGN, V38, P935, DOI 10.1016/j.patcog.2004.11.013
   Boutell M, 2004, INT C PATT RECOG, P901, DOI 10.1109/ICPR.2004.1333918
   Cao H, 2010, IEEE INT SYMP CIRC S, P1683, DOI 10.1109/ISCAS.2010.5537502
   Capar C., 2007, P IEEE 14 SIGN PROC, P1, DOI [10.1109/SIU.2006.1659882, DOI 10.1109/SIU.2006.1659882]
   Çeliktutan O, 2008, IEEE T INF FOREN SEC, V3, P553, DOI 10.1109/TIFS.2008.926993
   Chang C., 2013, LIBSVM LIB SUPPORT V
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Choi KS, 2006, P DIG PHOT, VII
   Committee S, 2010, EXCHANG IM FIL DIG S
   Corripio JR, 2013, P 5 INT C IM CRIM DE, P1, DOI [10.1049/ic.2013.0267, DOI 10.1049/IC.2013.0267]
   Costa Filipe de O., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P71, DOI 10.1109/SIBGRAPI.2012.19
   Costa FD, 2014, PATTERN RECOGN LETT, V39, P92, DOI 10.1016/j.patrec.2013.09.006
   Gartner Inc, 2013, GARTN SAYS SMARTPH S
   Geradts ZJ, 2000, PROC SPIE, V4232, P505, DOI 10.1117/12.417569
   Gloe T., 2007, Proceedings of the 15th international conference on Multimedia, P78, DOI [10.1145/1291233.1291252, DOI 10.1145/1291233.1291252]
   Ho JS, 2010, IEEE INT CON MULTI, P1475, DOI 10.1109/ICME.2010.5582951
   Hsuand CW, 2003, PRACTICAL GUIDE SUPP
   Jang C.-J., 2007, Digital information management, V1, P110, DOI DOI 10.1109/ICDIM.2007.4444209
   Jiayuan Fan, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P1945, DOI 10.1109/ICIP.2011.6115853
   Khanna N, 2009, IEEE T INF FOREN SEC, V4, P123, DOI 10.1109/TIFS.2008.2009604
   Khannaa N, 2006, FORENSIC CLASSIFICAT
   Long YJ, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P419, DOI 10.1109/MMSP.2006.285343
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Mckay C, 2008, INT CONF ACOUST SPEE, P1657, DOI 10.1109/ICASSP.2008.4517945
   Michie D., 1994, MACHINE LEARNING NEU
   Orozco A. S., 2013, P 6 INT C INF TECHN, P1
   Özparlak L, 2011, IEEE T INF FOREN SEC, V6, P1418, DOI 10.1109/TIFS.2011.2162830
   Platt JC, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P96, DOI 10.1109/IVL.2000.853847
   Qingzhong Liu, 2012, Advanced Research in Applied Artificial Intelligence. Proceedings 25th International Conference on Industrial Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2012, P262, DOI 10.1007/978-3-642-31087-4_28
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Romero NL, 2008, LIBR HI TECH, V26, P302, DOI 10.1108/07378830810880388
   Orozco ALS, 2014, COMPUTING, V96, P829, DOI 10.1007/s00607-013-0313-5
   Orozco ALS, 2015, MULTIMED TOOLS APPL, V74, P4735, DOI 10.1007/s11042-013-1837-6
   Swaminathan A, 2009, IEEE SIGNAL PROC MAG, V26, P38, DOI 10.1109/MSP.2008.931076
   Tesic J, 2005, IEEE MULTIMEDIA, V12, P86, DOI 10.1109/MMUL.2005.50
   Tsai MJ, 2007, INT CONF ACOUST SPEE, P221
   Van LT, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P883
   Van Lanh T, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P16
   Yongjian Hu, 2010, 2010 International Computer Symposium (ICS 2010), P506, DOI 10.1109/COMPSYM.2010.5685458
NR 44
TC 7
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7087
EP 7111
DI 10.1007/s11042-015-2633-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400020
DA 2024-07-18
ER

PT J
AU Kalra, GS
   Singh, S
AF Kalra, G. S.
   Singh, Shilpi
TI Efficient digital image denoising for gray scale images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rank ordered absolute differences; Trimmed global mean filter; Impulse
   noise; Denoise
ID IMPULSE NOISE; MEDIAN FILTERS; REMOVAL
AB We propose an algorithm for image de-noising which uses a trimmed global mean filter with rank order absolute differences to remove random-valued impulse noise, stripes, scratches and blotches. It is a two stage algorithm, in the first stage the corrupted candidate is detected using rank ordered absolute differences (ROAD). In the second stage, the corrupted pixels are replaced by the median of the uncorrupted pixels in the selected window. Trimmed global mean filter is used if the selected window contains all the pixels as noisy candidate. We used a fixed window size in both detection and filtering stages. The visual and quantitative results show that proposed filter outperforms the existing filters in restoring image which is corrupted by random valued impulse noise. The proposed algorithm also provides good results over the impulse noise image corrupted by artificially introduced scratches, blotches, and stripes without causing blurring.
C1 [Kalra, G. S.; Singh, Shilpi] Lovely Profess Univ, Phagwara, Punjab, India.
C3 Lovely Professional University
RP Kalra, GS (corresponding author), Lovely Profess Univ, Phagwara, Punjab, India.
EM gursharanjeetkalra@yahoo.com; er.shilpisingh@yahoo.in
CR Abreu E, 1996, IEEE T IMAGE PROCESS, V5, P1012, DOI 10.1109/83.503916
   Abreu E, 1996, ISCAS 96: 1996 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - CIRCUITS AND SYSTEMS CONNECTING THE WORLD, VOL 2, P730, DOI 10.1109/ISCAS.1996.541829
   Aiswarya K., 2010, Proceedings of the 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P409, DOI 10.1109/ICCMS.2010.310
   [Anonymous], IEEE SIGNAL PROCESSI
   Balasubramanian S, 2009, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION, COMMUNICATION AND ENERGY CONSERVATION INCACEC 2009 VOL 1, P99
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chan RH, 2004, IEEE SIGNAL PROC LET, V11, P921, DOI 10.1109/LSP.2004.838190
   Chen T, 1999, IEEE T IMAGE PROCESS, V8, P1834, DOI 10.1109/83.806630
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Chen T, 2001, IEEE T CIRCUITS-II, V48, P784, DOI 10.1109/82.959870
   Crnojevic V, 2004, IEEE SIGNAL PROC LET, V11, P589, DOI 10.1109/LSP.2004.830117
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   Esakkirajan S., 2011, IEEE SIGNAL PROCESSI, V18
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Hwang H, 1995, IEEE T IMAGE PROCESS, V4, P502
   Ko Sung-Jea, 1991, CIRCUITS SYSTEMS IEE, V38, P984
   Ko Sung-Jea, 1991, CIRCUITS SYSTEMS IEE, V38, P993
   kokaram A., 1995, IEEE T IMAGE PROCESS
   Luo WB, 2005, IEICE T FUND ELECTR, VE88A, P2579, DOI 10.1093/ietfec/e88-a.10.2579
   Nadenau M.J, 1996, P INT WORKSH TIM VAR
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   POMALAZARAEZ CA, 1984, IEEE T ACOUST SPEECH, V32, P571, DOI 10.1109/TASSP.1984.1164361
   Pratt W.K., 1975, Median Filtering
   SUN T, 1994, PATTERN RECOGN LETT, V15, P341, DOI 10.1016/0167-8655(94)90082-5
   Tomasi C., 1998, 6 INT C COMPUTER VIS
   Veerakumar T., 2012, INT J COMPUTER APPL, V39, P29, DOI DOI 10.5120/4874-7303
   Vijay Kumar V.R, 2010, P 2010 IE 17 INT C I
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
NR 30
TC 11
Z9 12
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4467
EP 4484
DI 10.1007/s11042-015-2484-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700014
DA 2024-07-18
ER

PT J
AU Zhang, ZH
   Liang, YH
   Bai, L
   Hancock, ER
AF Zhang, Zhihong
   Liang, Yuanheng
   Bai, Lu
   Hancock, Edwin R.
TI Discriminative sparse representation for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse coding; Coding fidelity; Face recognition; Spatial information
ID IMAGE CLASSIFICATION
AB Recently Sparse Representation (or coding) based Classification (SRC) has gained great success in face recognition. In SRC, the testing image is expected to be best represented as a sparse linear combination of training images from the same class, and the representation fidelity is measured by the a"" (2)-norm or a"" (1)-norm of the coding residual. However, SRC emphasizes the sparsity too much and overlooks the spatial information during local feature encoding process which has been demonstrated to be critical in real-world face recognition problems. Besides, some work considers the spatial information but overlooks the different discriminative ability in different face regions. In this paper, we propose to weight spatial locations based on their discriminative abilities in sparse coding for robust face recognition. Specifically, we learn the weights at face locations according to the information entropy in each face region, so as to highlight locations in face images that are important for classification. Furthermore, in order to construct a robust weights to fully exploit structure information of each face region, we employed external data to learn the weights, which can cover all possible face image variants of different persons, so the robustness of obtained weights can be guaranteed. Finally, we consider the group structure of training images (i.e. those from the same subject) and added an a"" (2,1)-norm (group Lasso) constraint upon the formulation, which enforcing the sparsity at the group level. Extensive experiments on three benchmark face datasets demonstrate that our proposed method is much more robust and effective than baseline methods in dealing with face occlusion, corruption, lighting and expression changes, etc.
C1 [Zhang, Zhihong] Xiamen Univ, Software Sch, Xiamen, Fujian, Peoples R China.
   [Liang, Yuanheng] Xiamen Univ, Sch Math Sci, Xiamen, Fujian, Peoples R China.
   [Bai, Lu] Cent Univ Finance & Econ, Sch Informat, Beijing, Peoples R China.
   [Hancock, Edwin R.] Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.
C3 Xiamen University; Xiamen University; Central University of Finance &
   Economics; University of York - UK
RP Liang, YH (corresponding author), Xiamen Univ, Sch Math Sci, Xiamen, Fujian, Peoples R China.
EM 990042350@qq.com
RI Hancock, Edwin/N-7548-2019
OI Hancock, Edwin/0000-0003-4496-2028
FU National Natural Science Foundation of China [61402389]
FX This work is supported by National Natural Science Foundation of China
   (Grant No. 61402389).
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cover T. M., 2012, ELEMENTS INFORM THEO
   Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   He XF, 2004, ADV NEUR IN, V16, P153
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Ji SH, 2008, IEEE T SIGNAL PROCES, V56, P2346, DOI 10.1109/TSP.2007.914345
   Liu YN, 2010, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2010.5539934
   Martinez A., 1998, AR FACE DATABASE
   Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282
   Quanz B, 2012, IEEE T KNOWL DATA EN, V24, P1789, DOI 10.1109/TKDE.2012.75
   Ramirez I, 2010, TECH REP
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wright J, 2010, IEEE T INFORM THEORY, V56, P3540, DOI 10.1109/TIT.2010.2048473
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang M, 2013, IEEE T IMAGE PROCESS, V22, P1753, DOI 10.1109/TIP.2012.2235849
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Zhang CJ, 2013, PATTERN RECOGN LETT, V34, P1046, DOI 10.1016/j.patrec.2013.02.013
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zhenhua Chai, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P639, DOI 10.1007/978-3-642-37444-9_50
NR 25
TC 8
Z9 9
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3973
EP 3992
DI 10.1007/s11042-015-3136-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200020
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Paramkusam, AV
   Reddy, VSK
AF Paramkusam, A. V.
   Reddy, V. S. K.
TI A novel fast search motion estimation boosted by multilayer concept
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block matching algorithm; Motion estimation; Multi layer motion
   estimation; Fast search algorithm
ID SUCCESSIVE ELIMINATION ALGORITHM; HEXAGONAL SEARCH; PATTERN
AB Most of the fast search motion estimation algorithms reduce the computational cost of motion estimation (ME) greatly by checking only a few search points inside the search area by using full distortion measure. This paper proposes multi-layer motion estimation (MME) which employs partial distortion as its distortion measure to reduce the number of computations involved in each search point instead of reducing the number of search points. The MME, first, constructs the layers from the reference frame so as to facilitate the calculation of partial distortion measures on the layers. Later, it searches motion vectors by computing the partial distortion measures on the layers. A layer is an image which is derived from the reference frame such that the summation of a block of pixels in the reference frame determines the point of a layer. It has been noticed on different video sequences that many motion vectors on the layers are the same as those searched on the reference frame. Experimental results on a wide variety of video sequences show that the proposed algorithm outperforms the other popular conventional fast search motion estimation algorithms computationally while maintaining the motion prediction quality very close to the full-search algorithm.
C1 [Paramkusam, A. V.; Reddy, V. S. K.] JNTUH, Malla Reddy Coll Engn, Elect & Commun, Hyderabad, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Hyderabad
RP Paramkusam, AV (corresponding author), JNTUH, Malla Reddy Coll Engn, Elect & Commun, Hyderabad, Andhra Pradesh, India.
EM adapa74@gmail.com; vskreddy2003@yahoo.com
RI Adapa, Paramkusam/AAF-8136-2019
OI Adapa, Paramkusam/0000-0001-5652-9550
CR BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237
   Chen ZB, 2006, J VIS COMMUN IMAGE R, V17, P264, DOI 10.1016/j.jvcir.2004.12.002
   Cheung CH, 2005, IEEE T MULTIMEDIA, V7, P16, DOI 10.1109/TMM.2004.840609
   Cheung CH, 2002, IEEE T CIRC SYST VID, V12, P1168, DOI 10.1109/TCSVT.2002.806815
   Gao XQ, 2000, IEEE T IMAGE PROCESS, V9, P501, DOI 10.1109/83.826786
   Jung J-H, 2010, IEEE SIGNAL PROCESS, V17
   Koga Toshio, 1981, PROC NAT TELECOMMUN, pG5
   Kuo CM, 2009, IEEE T CIRC SYST VID, V19, P893, DOI 10.1109/TCSVT.2009.2017420
   Lee CH, 1997, IEEE T IMAGE PROCESS, V6, P1587, DOI 10.1109/83.641419
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   LI W, 1995, IEEE T IMAGE PROCESS, V4, P105, DOI 10.1109/83.350809
   Liu S.-W., 2008, IEEE T CIRCUITS SYST, V18, P156
   Ma K. K., 2003, P 2003 INT S CIRC SY, V2, P25, DOI [10.1109/ISCAS.2003.1206072, DOI 10.1109/ISCAS.2003.1206072]
   Ndili O, 2011, IEEE T CIRC SYST VID, V21, P1214, DOI 10.1109/TCSVT.2011.2133990
   Nie Y, 2002, IEEE T IMAGE PROCESS, V11, P1442, DOI 10.1109/TIP.2002.806251
   Po LM, 2007, IEEE T MULTIMEDIA, V9, P9, DOI 10.1109/TMM.2006.886330
   Po LM, 2009, IEEE T CIRC SYST VID, V19, P1189, DOI 10.1109/TCSVT.2009.2020320
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   SRINIVASAN R, 1985, IEEE T COMMUN, V33, P888, DOI 10.1109/TCOM.1985.1096398
   Tham JY, 1998, IEEE T CIRC SYST VID, V8, P369, DOI 10.1109/76.709403
   Tourapis AM, 2002, PROC SPIE, V4671, P1069, DOI 10.1117/12.453031
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu C, 2004, IEEE T CIRC SYST VID, V14, P1210, DOI 10.1109/TCSVT.2004.833166
   Zhu C, 2005, IEEE T IMAGE PROCESS, V14, P213, DOI 10.1109/TIP.2004.840702
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
   Zou BJ, 2010, IEEE T CIRC SYST VID, V20, P156, DOI 10.1109/TCSVT.2009.2031461
NR 26
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2169
EP 2188
DI 10.1007/s11042-014-2400-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000020
DA 2024-07-18
ER

PT J
AU Sun, FM
   Xu, Y
   Zhou, J
AF Sun, Fuming
   Xu, Yan
   Zhou, Jun
TI Active learning SVM with regularization path for image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active Learning; regularization; SVM
ID RETRIEVAL
AB In classification problems, many different active learning techniques are often adopted to find the most informative samples for labeling in order to save human labors. Among them, active learning support vector machine (SVM) is one of the most representative approaches, in which model parameter is usually set as a fixed default value during the whole learning process. Note that model parameter is closely related to the training set. Hence dynamic parameter is desirable to make a satisfactory learning performance. To target this issue, we proposed a novel algorithm, called active learning SVM with regularization path, which can fit the entire solution path of SVM for every value of model parameters. In this algorithm, we first traced the entire solution path of the current classifier to find a series of candidate model parameters, and then used unlabeled samples to select the best model parameter. Besides, in the initial phase of training, we constructed a training sample sets by using an improved K-medoids cluster algorithm. Experimental results conducted from real-world data sets showed the effectiveness of the proposed algorithm for image classification problems.
C1 [Sun, Fuming; Xu, Yan; Zhou, Jun] Liaoning Univ Technol, Sch Elect & Informat Engn, Jinzhou, Liaoning, Peoples R China.
C3 Liaoning University of Technology
RP Sun, FM (corresponding author), Liaoning Univ Technol, Sch Elect & Informat Engn, Jinzhou, Liaoning, Peoples R China.
EM sunwenfriend@hotmail.com
RI Sun, Fuming/HGT-8610-2022; Sun, Fuming/HKN-9901-2023
FU National Natural Science Foundation of China [61272214]
FX This work is supported by National Natural Science Foundation of China
   under Grant No. 61272214.
CR [Anonymous], 2010, MACH LEARN
   [Anonymous], 2003, ICML 2003 WORKSHOP C
   Gosselin PH, 2008, IEEE T IMAGE PROCESS, V17, P1200, DOI 10.1109/TIP.2008.924286
   Hastie T, 2004, J MACH LEARN RES, V5, P1391
   Hoi Steven C. H., 2006, Proceedings of the International Conference on the World Wide Web (WWW-2006), P633, DOI [10.1145/1135777.1135870, DOI 10.1145/1135777.1135870]
   Li XC, 2004, IEEE IMAGE PROC, P2207
   Lughofer E, 2012, PATTERN RECOGN, V45, P884, DOI 10.1016/j.patcog.2011.08.009
   Pang YW, 2014, IEEE T CYBERNETICS, V44, P2122, DOI 10.1109/TCYB.2014.2301453
   Pang YW, 2013, IEEE T NEUR NET LEAR, V24, P1292, DOI 10.1109/TNNLS.2013.2253798
   Qi G.J., 2007, P 15 ACM INT C MULTI, P17, DOI DOI 10.1145/1291233.1291245
   Settles Burr, 2007, ADV NEURAL INFORM PR, P1289
   Tian XM, 2010, IEEE T IMAGE PROCESS, V19, P805, DOI 10.1109/TIP.2009.2035866
   Tur G., 2003, IEEE International Conference on Acoustics, Speech, and Signal Processing, V1, P1
   Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120
   Wang M, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899414
   Wang M, 2007, INT J SEMANT COMPUT, V1, P459, DOI 10.1142/S1793351X0700024X
   Wang Z, 2011, PATTERN RECOGN, V44, P2375, DOI 10.1016/j.patcog.2011.03.008
   Yuan J, 2007, IEEE INT C MULT EXP, P2202
   Zha ZJ, 2012, IEEE T MULTIMEDIA, V14, P17, DOI 10.1109/TMM.2011.2174782
   Zhu J, 2008, 22nd International Conference on Computational Linguistics, Coling 2008, P1137
   Zhu JB, 2010, IEEE T AUDIO SPEECH, V18, P1323, DOI 10.1109/TASL.2009.2033421
NR 21
TC 13
Z9 14
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1427
EP 1442
DI 10.1007/s11042-014-2141-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600005
DA 2024-07-18
ER

PT J
AU Al-Azawi, M
   Yang, YJ
   Istance, H
AF Al-Azawi, Mohammad
   Yang, Yingjie
   Istance, Howell
TI Irregularity-based image regions saliency identification and evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Irregularity; Saliency; Image processing; Thresholding; Fuzzy
ID EARTH MOVERS DISTANCE; VISUAL-ATTENTION; MODEL; ALLOCATION
AB Saliency or salient region extraction from images is still a challenging field as it needs some understanding of the image and its nature. A technique that is suitable for some applications is not necessarily useful in other applications, thus, saliency identification is dependent upon the application. Based on a survey of existing methods of saliency detection, a new technique to extract the salient regions from an image is proposed that utilizes local features of the region surrounding each pixel. The level of saliency is decided based on the irregularity of the region with compared to other regions. To make the process fully automatic, a new Fuzzy-based thresholding technique has also been developed. In addition to the above, a survey of existing saliency evaluation techniques has been carried out and we have proposed new evaluation methods. The proposed saliency extraction technique has been compared with other algorithms reported in the literature, and the results are discussed in detail.
C1 [Al-Azawi, Mohammad; Yang, Yingjie; Istance, Howell] De Montfort Univ, Ctr Computat Intelligence, Leicester LE1 9BH, Leics, England.
   [Al-Azawi, Mohammad] Oman Coll Management & Technol, Dept Comp Sci, Muscat, Oman.
C3 De Montfort University
RP Al-Azawi, M (corresponding author), Oman Coll Management & Technol, Dept Comp Sci, Muscat, Oman.
EM m.a.al-azawi@ieee.org; yyang@dmu.ac.uk; hoi@dmu.ac.uk
RI Al-Azawi, Mohammad A. N./A-1777-2018; Yang, Yingjie/B-4162-2013
OI Al-Azawi, Mohammad A. N./0000-0003-3073-610X; 
CR Achanta R., 2010, SALIENCY DETECTION U
   Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Al-Azawi M, 2014, IEEE INT ADV COMPUT, P946, DOI 10.1109/IAdCC.2014.6779450
   [Anonymous], 2013, PRECISION AND RECALL
   [Anonymous], 2009, IEEE C COMP VIS PATT
   [Anonymous], 2012, CSAIL TECHNICAL REPO
   [Anonymous], IEEE CVPR
   Banerjee M, 2003, PATTERN RECOGN, V36, P2649, DOI 10.1016/S0031-3203(03)00174-2
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Bruce Neil D. B., 2007, VISUAL CORRELATES FI
   Burns R.P., 2008, Business research methods and statistics using SPSS: Extension chapters on advanced techniques, P552
   CHOI YS, 1995, OPTOMETRY VISION SCI, V72, P439, DOI 10.1097/00006324-199507000-00003
   Cook D, 2007, USE R, P103
   Davis JW, 2004, P C COMP VIS PATT RE, DOI [10.1109/CVPR.2004.431, DOI 10.1109/CVPR.2004.431]
   Einhäuser W, 2008, J VISION, V8, DOI 10.1167/8.2.2
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Estivill-Castro V., 2002, Em: SIGKDD Explor. Newsl, V4, P65, DOI [10.1145/568574.568575, DOI 10.1145/568574.568575]
   Fang Y., 2011, ACM INT C MULT 2011
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   Gide MS, 2012, INT WORK QUAL MULTIM, P200, DOI 10.1109/QoMEX.2012.6263871
   Gopalakrishnan V., 2009, RANDOM WALKS GRAPHS
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, Saliency Detection: A spectral Residual Approach
   Hu YQ, 2004, LECT NOTES COMPUT SC, V3332, P993
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Ivanoff RM, 2008, SCHOLARPEDIA, V3, P3650
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   Kapsalas P., 2008, REGIONS INTEREST ACC, P147
   Kim C, 2013, J VISION, V13, DOI 10.1167/13.4.5
   Kim S, 2003, LECT NOTES COMPUT SC, V2728, P39
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kumar V., 2006, Introduction to data mining, P488
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Li J., 2007, J LATEX CLASS, V6, P1, DOI DOI 10.1016/J.APPL
   Lin DW, 2007, LECT NOTES COMPUT SC, V4810, P389
   Lin YW, 2013, IEEE T PATTERN ANAL, V35, P314, DOI 10.1109/TPAMI.2012.119
   Lin YW, 2010, AAAI CONF ARTIF INTE, P967
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Liu Z, 2011, IET IMAGE PROCESS, V5, P122, DOI 10.1049/iet-ipr.2009.0382
   Loupias E., 2000, WAVELET BASED SALIEN, P518
   Luo S., 2013, EFFICIENT SALIENCY D
   Ma Y.F., 2003, ONTRAST BASED IMAGE
   Mancas Matei, 2008, P INT WORKSH ATT PER, P94
   Margolin R., 2013, CVPR 13 P 2013 I E C
   MILLIGAN GW, 1987, APPL PSYCH MEAS, V11, P329, DOI 10.1177/014662168701100401
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Pele O, 2008, LECT NOTES COMPUT SC, V5304, P495, DOI 10.1007/978-3-540-88690-7_37
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Rahmani R., 2008, IEEE T PATTERN ANAL, P1
   Rai P., 2010, Int. J. Comput. Appl., V7, P1, DOI [DOI 10.5120/1326-1808, 10.5120/1326-1808]
   Rosin PL, 2009, PATTERN RECOGN, V42, P2363, DOI 10.1016/j.patcog.2009.04.021
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Sebe N, 2002, LECT NOTES COMPUT SC, V2383, P367
   Selvaraj A., 2009, The Open Signal Processing Journal, V2, P14, DOI [DOI 10.2174/1876825300902010014, 10.2174/1876825300902010014]
   Song H., 2006, P 6 WORLD C INT CONT
   Stottinger Julian, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204286
   Tatler BW, 2011, J VISION, V11, DOI 10.1167/11.5.5
   Tian Q, 2001, J ELECTRON IMAGING, V10, P835, DOI 10.1117/1.1406945
   Toet A, 2011, IEEE T PATTERN ANAL, V33, P2131, DOI 10.1109/TPAMI.2011.53
   Tryfos P., 1998, Methods for business analysis and forecasting: Text and cases
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Zhang H, 2006, IEEE IMAGE PROC, P765, DOI 10.1109/ICIP.2006.312424
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9
   Zhou B., 2010, Proceedings of the Asian Conference on Computer Vision, P225
NR 69
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 25
EP 48
DI 10.1007/s11042-014-2248-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500002
DA 2024-07-18
ER

PT J
AU Arshad, H
   Nikooghadam, M
AF Arshad, Hamed
   Nikooghadam, Morteza
TI An efficient and secure authentication and key agreement scheme for
   session initiation protocol using ECC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Session initiation protocol (SIP); Elliptic curve cryptosystem (ECC);
   Authentication; Key agreement; VoIP; Security
ID SIP AUTHENTICATION; SMART-CARD
AB The session initiation protocol (SIP) is a powerful and superior signaling protocol for the voice over internet protocol (VoIP). Authentication is an important security requirement for SIP. Hitherto, many authentication schemes have been proposed to enhance the security of SIP. Recently, Irshad et al. proposed an improved authentication scheme concerning SIP, in which they claimed that their scheme is secure against various security attacks. However, in this paper, we conclude that Irshad et al.'s scheme is vulnerable to user impersonation attacks. Furthermore, a novel authentication and key agreement scheme is proposed for SIP using elliptic curve cryptosystem (ECC). Security and performance analyses demonstrate that the proposed scheme is secure against security attacks of various types and has low computation cost compared to previously proposed schemes.
C1 [Arshad, Hamed; Nikooghadam, Morteza] Imam Reza Int Univ, Dept Comp Engn & Informat Technol, Mashhad, Iran.
RP Nikooghadam, M (corresponding author), Imam Reza Int Univ, Dept Comp Engn & Informat Technol, Mashhad, Iran.
EM hamedarshad@Imamreza.ac.ir; morteza.nikooghadam@gmail.com
RI Nikooghadam, Morteza/AAR-7984-2020; Arshad, Hamed/D-3598-2017
OI Nikooghadam, Morteza/0000-0003-3894-3103; Arshad,
   Hamed/0000-0003-3885-7408
CR [Anonymous], 2009, INT J NETW SECUR
   [Anonymous], 2617 IETF RFC
   [Anonymous], RFC3261 IETF
   [Anonymous], 2009, SIP SECURITY
   [Anonymous], ADV CRYPTOLOGY CRYPT
   Arshad R, 2013, MULTIMED TOOLS APPL, V66, P165, DOI 10.1007/s11042-011-0787-0
   Durlanik A, 2005, PROC WRLD ACAD SCI E, V8, P350
   Farash MS, 2013, INF TECHNOL CONTROL, V42, P333, DOI 10.5755/j01.itc.42.4.2496
   Frank M, 2013, IEEE T INF FOREN SEC, V8, P136, DOI 10.1109/TIFS.2012.2225048
   Geneiatakis D, 2006, IEEE COMMUN SURV TUT, V8, P68, DOI 10.1109/COMST.2006.253270
   Hankerson Darrel, 2006, Guide to Elliptic Curve Cryptography
   Harn L, 2013, IEEE T COMPUT, V62, P1893, DOI 10.1109/TC.2012.251
   He DB, 2012, SECUR COMMUN NETW, V5, P1423, DOI 10.1002/sec.506
   He DB, 2012, INFORM FUSION, V13, P223, DOI 10.1016/j.inffus.2011.01.001
   Irshad A, 2015, MULTIMED TOOLS APPL, V74, P3967, DOI 10.1007/s11042-013-1807-z
   Irshad A, 2014, SECUR COMMUN NETW, V7, P1210, DOI 10.1002/sec.834
   Jiang Q, 2015, INT J COMMUN SYST, V28, P1340, DOI 10.1002/dac.2767
   Kilinc HH, 2014, IEEE COMMUN SURV TUT, V16, P1005, DOI 10.1109/SURV.2013.091513.00050
   Koblitz N, 2000, DESIGN CODE CRYPTOGR, V19, P173, DOI 10.1023/A:1008354106356
   Ku WC, 2003, IEICE T COMMUN, VE86B, P1682
   Li XW, 2013, SECUR COMMUN NETW, V6, P631, DOI 10.1002/sec.595
   Liu F, 2011, LECT NOTES COMPUT SC, V7025, P134, DOI 10.1007/978-3-642-24712-5_11
   Liu H, 2011, IEEE SENS J, V11, P3235, DOI 10.1109/JSEN.2011.2160052
   Lynn B., PAIRING BASED CRYPTO
   Ma CG, 2014, INT J COMMUN SYST, V27, P2215, DOI 10.1002/dac.2468
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Nikooghadam M, 2012, J MED SYST, V36, P3839, DOI 10.1007/s10916-012-9857-8
   Nikooghadam M, 2010, J SYST SOFTWARE, V83, P1917, DOI 10.1016/j.jss.2010.05.072
   Pu Q, 2013, SECUR COMMUN NETW, V6, P340, DOI 10.1002/sec.568
   Salsano S, 2002, IEEE NETWORK, V16, P38, DOI 10.1109/MNET.2002.1081764
   Sisalem D, 2006, IEEE NETWORK, V20, P26, DOI 10.1109/MNET.2006.1705880
   Stallings W., 2005, CRYPTOGRAPHY NETWORK, V4th
   Tang HB, 2013, MULTIMED TOOLS APPL, V65, P321, DOI 10.1007/s11042-012-1001-8
   Tu H, 2015, PEER PEER NETW APPL, V8, P903, DOI 10.1007/s12083-014-0248-4
   Vanstone SA., 1997, Environ Inform Secur Techn Report, V2, P78
   Wu K, 2013, ROM J INF SCI TECH, V16, P324
   Wu LF, 2009, COMPUT STAND INTER, V31, P286, DOI 10.1016/j.csi.2008.01.002
   Wu SH, 2013, PEER PEER NETW APPL, V6, P61, DOI 10.1007/s12083-012-0129-7
   Xie Q, 2012, INT J COMMUN SYST, V25, P47, DOI 10.1002/dac.1286
   Yang CC, 2005, COMPUT SECUR, V24, P381, DOI 10.1016/j.cose.2004.10.007
   Yoon EJ, 2009, 2009 INTERNATIONAL CONFERENCE ON NEW TRENDS IN INFORMATION AND SERVICE SCIENCE (NISS 2009), VOLS 1 AND 2, P642, DOI 10.1109/NISS.2009.137
   Zhang LP, 2014, SECUR COMMUN NETW, V7, P2405, DOI 10.1002/sec.951
   Zhang LP, 2014, INT J COMMUN SYST, V27, P2691, DOI 10.1002/dac.2499
   Zhou L, 2011, IEEE J SEL AREA COMM, V29, P1358, DOI 10.1109/JSAC.2011.110803
NR 44
TC 68
Z9 71
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 181
EP 197
DI 10.1007/s11042-014-2282-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500010
DA 2024-07-18
ER

PT J
AU Chen, W
   Wang, K
   Jiang, HF
   Li, M
AF Chen, Wei
   Wang, Ke
   Jiang, Haifeng
   Li, Ming
TI Skin color modeling for face detection and segmentation: a review and a
   new approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Skin color modeling; Boundary detection; Region
   based segmentation; Dual hue detector
ID ROBUST; NETWORK; IMAGES
AB Detecting skin-colored pixels, although seems a straightforward easy task, has proven to be quite a challenging task in images that are captured under complex unconstrained imaging conditions. Color segmentation is an important method of segmenting the body in images. In this paper, we first provides a review of skin color modeling research works for face detection. In particular, we focus on discussing the challenges of skin color modeling, detection, and segmentation, and then we present the skin color modeling and region-based skin segmentation. We also propose a new approach to analyze the hue characteristics of monitoring personnel in coal mine. We determine the skin color boundaries of the miners using the boundary detection method based on the response of visual hue. And then, we apply to determining hue area method using dual hue detector to segment skin color for miners. Experiments show that the method has excellent ability to segment skin regions of miners. We also summarize the most widely used methods for skin detection approaches and collecting their numerical evaluation results.
C1 [Chen, Wei; Wang, Ke; Jiang, Haifeng; Li, Ming] China Univ Min & Technol, Coll Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Chen, W (corresponding author), China Univ Min & Technol, Coll Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
EM davior.chen@gmail.com
RI Ming, Li/JRX-2466-2023
FU Qing Lan Project; National Natural Science Foundation of China
   [51104157, 51404258]; China Postdoctoral Science Foundation [2013T60574,
   20100481181]; Ph.D. Programs Foundation of Ministry of Education of
   China [20110095120008]; Natural Science Foundation of Jiangsu Province
   [BK20140202]
FX This work was sponsored by Qing Lan Project, the National Natural
   Science Foundation of China (Grant No. 51104157,51404258), the China
   Postdoctoral Science Foundation (Grant Nos. 2013T60574, 20100481181),
   the Ph.D. Programs Foundation of Ministry of Education of China (Grant
   No. 20110095120008), and Natural Science Foundation of Jiangsu Province
   (Grant No. BK20140202).
CR Al Aghbari Z, 2006, IMAGE VISION COMPUT, V24, P894, DOI 10.1016/j.imavis.2006.02.013
   [Anonymous], P INT C IM SCI SYST
   [Anonymous], 2012, PROC 75 IEEE VEH TEC
   Argyros AA, 2004, LECT NOTES COMPUT SC, V3023, P368
   Baskan S, 2002, PATTERN RECOGN LETT, V23, P1623, DOI 10.1016/S0167-8655(02)00037-5
   Brown D.A., 2001, Proceedings of the 2001 British Machine Vision Conference, V1, P491
   Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122
   Chai D, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P464
   Chen W, 2014, COMPUTERS ELECT ENG
   Chen W, 2009, ICEMI 2009, P454
   Chen W, 2013, COMPUT ELECTR ENG, V39, P1962, DOI 10.1016/j.compeleceng.2013.04.008
   Chen W, 2009, PROCEEDINGS OF THE 2009 2ND INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOLS 1-9, P208
   Chen WC, 2007, INT J PATTERN RECOGN, V21, P831, DOI 10.1142/S0218001407005715
   Cho KM, 2001, PATTERN RECOGN, V34, P1067, DOI 10.1016/S0031-3203(00)00034-0
   Do HC, 2007, IEEE T CONSUM ELECTR, V53, P1103, DOI 10.1109/TCE.2007.4341592
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465
   Gasparini F., 2006, P SPIE, V6061, P128
   Gomez G, 2002, INT C PATT RECOG, P961, DOI 10.1109/ICPR.2002.1048465
   Gomez G., 2002, MICAI 2002: Advances in Artificial Intelligence, Volume, V2313, P3
   Han J, 2009, IET COMPUT VIS, V3, P24, DOI 10.1049/iet-cvi:20080006
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Huang YZ, 2006, J COMPUT ELECTRON, V5, P275, DOI 10.1007/s10825-006-0145-z
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Juang CF, 2008, NEUROCOMPUTING, V71, P3409, DOI 10.1016/j.neucom.2007.11.007
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kawulok M, 2014, PATTERN RECOGN LETT, V41, P3, DOI 10.1016/j.patrec.2013.08.028
   Khan R, 2012, PATTERN RECOGN LETT, V33, P157, DOI 10.1016/j.patrec.2011.09.032
   Kim C, 2008, PATTERN RECOGN, V41, P22, DOI 10.1016/j.patcog.2007.04.011
   Kim MH, 2005, LECT NOTES ARTIF INT, V3809, P557
   Li B, 2007, PATTERN RECOGN, V40, P3621, DOI 10.1016/j.patcog.2007.04.018
   Liu Z, 2005, SIGNAL PROCESS-IMAGE, V20, P295, DOI 10.1016/j.image.2004.12.005
   Long YJ, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P419, DOI 10.1109/MMSP.2006.285343
   Ma YQ, 2009, COMPUT VIS IMAGE UND, V113, P580, DOI 10.1016/j.cviu.2009.01.002
   Ma Z, 2010, P EUR C COMP VIS
   Moallem P, 2010, APPL SOFT COMPUTING, V11
   Naji SA, 2012, DIGIT SIGNAL PROCESS, V22, P933, DOI 10.1016/j.dsp.2012.05.004
   Peer P., 1999, P 4 COMP VIS WINT WO, P122
   Phung SL, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 1, PROCEEDINGS, P525, DOI 10.1109/ISSPA.2003.1224755
   Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17
   Phung SL, 2001, IEEE IJCNN, P2844, DOI 10.1109/IJCNN.2001.938827
   Pratt WK, 2002, RECHERCHE, V67
   Russ JohnC., 2007, IMAGE PROCESSING HDB, Vfifth
   Sebe N, 2004, INT C PATT RECOG, P903, DOI 10.1109/ICPR.2004.1334405
   Seow MJ, 2004, 32ND APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP, PROCEEDINGS, P141
   Shapiro L., 2000, Computer Vision
   Shih FY, 2008, INT J PATTERN RECOGN, V22, P515, DOI 10.1142/S0218001408006296
   Sigal L, 2000, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2000.854764
   Sobottka K, 1998, SIGNAL PROCESS-IMAGE, V12, P263, DOI 10.1016/S0923-5965(97)00042-8
   Solina F, 2002, CONTR AUT ROB VIS 20, P198
   Soriano M, 2003, PATTERN RECOGN, V36, P681, DOI 10.1016/S0031-3203(02)00089-4
   Soriano M, 2000, INT C PATT RECOG, P839, DOI 10.1109/ICPR.2000.905542
   Storring M., 2004, Computer vision and human skin colour
   Taqa AY, 2010, SCI RES ESSAYS, V5, P2480
   Terrillon J.-C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P54, DOI 10.1109/AFGR.2000.840612
   Vadakkepat P, 2008, IEEE T IND ELECTRON, V55, P1385, DOI 10.1109/TIE.2007.903993
   Vezhnevets V, 2003, GRAPHICON, V3
   Wang YJ, 2001, PATTERN RECOGN, V34, P1983, DOI 10.1016/S0031-3203(00)00119-9
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Wu HY, 1999, IEEE T PATTERN ANAL, V21, P557, DOI 10.1109/34.771326
   Xu T, 2013, IET IMAGE PROCESS, V7, P751, DOI 10.1049/iet-ipr.2012.0657
   Yang KF, 2013, PROC CVPR IEEE, P2810, DOI 10.1109/CVPR.2013.362
   Yang M.H., 2000, Hand gesture recognition and face detection in images
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yang MH, 1998, DETECTING HUMAN FACE, V1, P127
   Yogarajah P, 2010, IEEE IMAGE PROC, P2225, DOI 10.1109/ICIP.2010.5652798
   Zaqout I, 2004, ADV COMPLEX SYST, V7, P369, DOI 10.1142/S021952590400024X
   Zarit B. D., 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P58, DOI 10.1109/RATFG.1999.799224
NR 69
TC 17
Z9 21
U1 1
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 839
EP 862
DI 10.1007/s11042-014-2328-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700007
DA 2024-07-18
ER

PT J
AU Peng, ZY
   Yue, ML
   Wu, X
   Peng, YW
AF Peng, Zhiyong
   Yue, Mingliang
   Wu, Xia
   Peng, Yuwei
TI Blind watermarking scheme for polylines in vector geo-spatial data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Geo-spatial data; Polyline; Feature vertex distance ratio;
   Vector
AB With the rapid development of GIS and computer technology, the geo-spatial data has been widely used in many fields. Since the production of geo-spatial data is very costly, illegal copying will lead to huge loss of the data owner. In order to protect the copyright of geo-spatial data, digital watermarking has been employed in recent years. In this paper, current works on geo-spatial watermarking and cardinal attacks are analyzed. Consequently, a blind watermarking scheme for polylines in vector geo-spatial data is proposed. In the proposed scheme, FVDR (feature vertex distance ratio) is constructed based on the feature vertices of polylines. As the cover data, FVDR is slightly modified through quantization index modulation to embed the corresponding watermark bit. Each bit in the watermark is embedded in several polylines, by doing so each of these polylines contains a copy of the corresponding watermark bit. Because of the specially designed cover data, quantization modulation and redundant embedding, the proposed scheme is robust to geometrical attacks, vertex attacks and object attacks. Also, the results of extensive experiments demonstrate the robustness of the proposed scheme.
C1 [Peng, Zhiyong; Yue, Mingliang; Wu, Xia; Peng, Yuwei] Wuhan Univ, Comp Sch, Wuhan 430072, Hubei, Peoples R China.
C3 Wuhan University
RP Peng, YW (corresponding author), Wuhan Univ, Comp Sch, Wuhan 430072, Hubei, Peoples R China.
EM peng@whu.edu.cn; ml.yue@whu.edu.cn; quailquail@sina.com;
   ywpeng@whu.edu.cn
OI Yue, Mingliang/0000-0002-1138-6661
FU National Natural Science Foundation of China (NSFC) [61100019, 61262021]
FX The authors gratefully acknowledge the anonymous reviewers for their
   valuable comments. This work is supported by the National Natural
   Science Foundation of China (NSFC, Grant No. 61100019 and 61262021). The
   work was done while the corresponding author was visiting the School of
   ITEE at the University of Queensland.
CR [Anonymous], 2007, INTELLIGENT MULTIMED
   [Anonymous], 2004, Ph.D. Dissertation.
   [Anonymous], P WORKSH MULT SEC MM
   Bird S, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P454, DOI 10.1109/DICTA.2009.78
   Cao LJ, 2010, IEEE IMAGE PROC, P3685, DOI 10.1109/ICIP.2010.5652535
   Chang HJ, 2009, IEEE INT CON MULTI, P1014, DOI 10.1109/ICME.2009.5202669
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cox IJ., 2007, DIGITAL WATERMARKING
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Giannoula A, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA549
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Huang M, 2007, LECT NOTES COMPUT SC, V4443, P1098
   Jungyeop Kim, 2011, Proceedings of the 2011 7th International Conference on Digital Content, Multimedia Technology and its Applications (IDCTA 2011), P154
   Jungyeop Kim, 2010, Proceedings of the 2010 Sixth International Conference on Networked Computing and Advanced Information Management (NCM 2010), P417
   Kang H, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P234, DOI 10.1109/ITCC.2001.918797
   Kim J, 2010, ADV INFO SCI SERV SC, V2, P79, DOI [DOI 10.4156/AISS.VOL2.ISSUE4.9, 10.4156/aiss.vol2.issue4.9]
   Lee SH, 2013, MULTIMED TOOLS APPL, V63, P757, DOI 10.1007/s11042-011-0894-y
   Liu S, 2012, P INT C INF ENG APPL, P529
   Madelaine J, 2007, ACM S INF COMP COMM, P265
   Ohbuchi R, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P577, DOI 10.1109/ICME.2002.1035847
   Sakamoto M, 2000, S CRYPT INF SEC
   Shen T, 2009, P 24 INT CART C, P15
   Solachidis V, 2004, IEEE COMPUT GRAPH, V24, P44, DOI 10.1109/MCG.2004.1297010
   Voigt M, 2005, P SOC PHOTO-OPT INS, V5681, P409, DOI 10.1117/12.588195
   Voigt M, 2004, P 2004 MULT SEC WORK, P160, DOI DOI 10.1145/1022431.1022459
   Wang CJ, 2012, MULTIMED TOOLS APPL, V57, P67, DOI 10.1007/s11042-010-0536-9
   Xu DH, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND INFORMATION SECURITY (WCNIS), VOL 1, P625, DOI 10.1109/WCINS.2010.5541855
   Yan HW, 2011, COMPUT ENVIRON URBAN, V35, P485, DOI 10.1016/j.compenvurbsys.2010.10.004
   Yu-Chi Pu, 2009, Information Technology Journal, V8, P982, DOI 10.3923/itj.2009.982.989
   Zhang D, 2007, LECT NOTES COMPUT SC, V4672, P71
   Zhang Lei, 2010, Wuhan University Journal of Natural Sciences, V15, P403, DOI 10.1007/s11859-010-0674-y
   Zope-Chaudhari S., 2012, 2012 International Conference on Computer and Communication Engineering (ICCCE), P594, DOI 10.1109/ICCCE.2012.6271256
NR 32
TC 20
Z9 21
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11721
EP 11739
DI 10.1007/s11042-014-2259-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600033
DA 2024-07-18
ER

PT J
AU Taimori, A
   Behrad, A
AF Taimori, Ali
   Behrad, Alireza
TI A new deformable mesh model for face tracking using edge based features
   and novel sets of energy functions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deformable mesh; Face locating and tracking; Feature extraction; Fuzzy
   sets theory; Optical flow; Mesh energy functions
ID RECOGNITION
AB This paper presents a new method for automatic human face locating and tracking. The proposed method consists of two modules including face locating and face tracking. The face locating module has a hierarchical structure, which consists of a skin color classifier together with AdaBoost based face detectors. The face tracking module is considered to be the main contribution of the paper. The module is based on the unstructured 2-D triangular deformable meshes, which employs a new robust and illumination insensitive feature extraction and matching algorithms as well as new sets of mesh energy functions. The feature extraction and matching algorithms are established upon edge points and their representation using fuzzy set theory, which is called fuzzy edges. For matching features, a multiresolution algorithm is utilized based on fuzzy edges and edge pyramid. The new mesh energy functions are also employed to manage both rigid and non-rigid motions in the head and face. Experimental results demonstrate the accuracy and stability of the proposed method for both face locating and face tracking.
C1 [Taimori, Ali] Islamic Azad Univ, Sci & Res Branch, Dept Elect & Comp Engn, Tehran, Iran.
   [Behrad, Alireza] Shahed Univ, Fac Engn, Elect & Elect Engn Dept, Tehran, Iran.
C3 Islamic Azad University; Shahed University
RP Behrad, A (corresponding author), Islamic Azad Univ, Sci & Res Branch, Dept Elect & Comp Engn, Tehran, Iran.
EM a.taimori@srbiau.ac.ir; behrad@shahed.ac.ir
RI Behrad, Alireza/F-8795-2018
OI Behrad, Alireza/0000-0002-1990-6668
CR Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   Behrad A, 2003, IEICE T INF SYST, VE86D, P2764
   Bouguet J-Y, 1999, Pyramidal implementation of the Lucas Kanade feature tracker
   Bradski G., 2008, LEARNING OPENCV
   Cai J, 1999, IMAGE VISION COMPUT, V18, P63, DOI 10.1016/S0262-8856(99)00006-2
   Corcoran P, 2007, INT S SIGN CIRC SYST, V1, P1
   Er MJ, 2005, IEEE T NEURAL NETWOR, V16, P679, DOI 10.1109/TNN.2005.844909
   Essannouni L, 2008, IEEE SYMP COMP COMMU, P1021
   Fatahi M, 2013, IRAN CONF MACH, P333, DOI 10.1109/IranianMVIP.2013.6780006
   Guan YP, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P272
   Gunn SR, 1994, IEE C IM PROC BIOM M, P6
   Hsieh IS, 2002, PATTERN RECOGN, V35, P1583, DOI 10.1016/S0031-3203(01)00146-7
   Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011
   Jamasbi Behzad, 2007, Journal of Multimedia, V2, P7, DOI 10.4304/jmm.2.6.7-14
   Jones M., 2003, Mitsubishi Electric Research Lab TR-20003-96, V3, P2
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57
   Kim EY, 2006, LECT NOTES COMPUT SC, V4224, P562
   Kruppa H., 2003, BRIT MACH VIS C BMVC, P1
   Lin CS, 2001, PATTERN RECOGN, V34, P1271, DOI 10.1016/S0031-3203(00)00075-3
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Metaxas D, 2006, LECT NOTES COMPUT SC, V3993, P554
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Molloy D, 2000, PATTERN RECOGN LETT, V21, P1071, DOI 10.1016/S0167-8655(00)00069-6
   Nallaperumal K, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P436, DOI 10.1109/ICCIMA.2007.208
   Nordstrom M.M., 2004, INFORM MATH MODELING
   Rowley HA, 1998, PROC CVPR IEEE, P38, DOI 10.1109/CVPR.1998.698585
   Sabouri S, 2009, 14 IR ANN C CSICC
   Shewchuk JR, 1997, THESIS CARNEGIE MELL
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shin Y, 2006, LECT NOTES COMPUT SC, V4304, P453
   Taimori A, 2010, MJEE, V10, P126
   Tianrui Wu, 2008, 2008 IEEE Conference on Cybernetics and Intelligent Systems, P728, DOI 10.1109/ICCIS.2008.4670846
   Torr PHS, 1995, THESIS
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Xu Z, 2006, 12 INT MULT MOD C IE, P10
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yoon-Hyung Lee, 2007, SICE '07. 46th SICE Annual Conference, P1985, DOI 10.1109/SICE.2007.4421312
   Zhao GQ, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P5022
   Zhou MC, 2010, PROC CVPR IEEE, P701, DOI 10.1109/CVPR.2010.5540146
   Zhu YD, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P587, DOI 10.1109/IVS.2003.1212978
NR 42
TC 6
Z9 7
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10735
EP 10759
DI 10.1007/s11042-014-2204-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700027
DA 2024-07-18
ER

PT J
AU Wang, HL
   Zhu, FKT
   Xiao, B
   Wang, L
   Jiang, YG
AF Wang, Hanli
   Zhu, Fengkuangtian
   Xiao, Bo
   Wang, Lei
   Jiang, Yu-Gang
TI GPU-based MapReduce for large-scale near-duplicate video retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Near-duplicate video retrieval; MapReduce; GPU; Hadoop
AB With the exponential growth of multimedia data, people are overwhelmed with massive amount of online videos, of which Near-Duplicate Videos (NDVs) occupy a large portion. In this paper, we present a novel framework for NDV retrieval, which explores the parallel power of two promising techniques: Graphics Processing Unit (GPU) and MapReduce. With the power of the proposed framework, various key algorithms in the field of computer vision, such as K-Means clustering, bag of features, inverted file index with hamming embedding and weak geometric consistency, are applied to NDV retrieval. Experimental results on the benchmark CC_WEB_VIDEO NDV dataset demonstrate that the proposed framework can significantly speed up processing huge amounts of video repositories.
C1 [Wang, Hanli; Zhu, Fengkuangtian; Xiao, Bo; Wang, Lei] Tongji Univ, Dept Comp Sci & Technol, Minist Educ, Shanghai 200092, Peoples R China.
   [Wang, Hanli; Zhu, Fengkuangtian; Xiao, Bo; Wang, Lei] Tongji Univ, Key Lab Embedded Syst & Serv Comp, Minist Educ, Shanghai 200092, Peoples R China.
   [Jiang, Yu-Gang] Fudan Univ, Sch Comp Sci, Shanghai 201203, Peoples R China.
C3 Tongji University; Tongji University; Fudan University
RP Wang, HL (corresponding author), Tongji Univ, Dept Comp Sci & Technol, Minist Educ, Shanghai 200092, Peoples R China.
EM hanliwang@tongji.edu.cn
RI Wang, Hanli/K-5717-2019; Wang, Hanli/G-5111-2014
OI Wang, Hanli/0000-0002-9999-4871; Wang, Hanli/0000-0002-9999-4871
FU National Natural Science Foundation of China [61102059]; "Shu Guang"
   project of Shanghai Municipal Education Commission and Shanghai
   Education Development Foundation [12SG23]; Program for Professor of
   Special Appointment (Eastern Scholar) at Shanghai Institutions of Higher
   Learning; Fundamental Research Funds for Central Universities
   [0800219158, 0800219270, 1700219104]; National Basic Research Program
   (973 Program) of China [2010CB328101]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61102059, the "Shu Guang" project of
   Shanghai Municipal Education Commission and Shanghai Education
   Development Foundation under Grant 12SG23, the Program for Professor of
   Special Appointment (Eastern Scholar) at Shanghai Institutions of Higher
   Learning, the Fundamental Research Funds for the Central Universities
   under Grants 0800219158, 0800219270, and 1700219104, and the National
   Basic Research Program (973 Program) of China under Grant 2010CB328101.
CR [Anonymous], 2010, MULTIMED TOOLS APPL, DOI DOI 10.1007/s11042-009-0339-z
   Cevahir A, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P413, DOI 10.1109/ISM.2012.85
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Dong W., 2008, PROCEEDING ACM MULTI, P179, DOI DOI 10.1145/1459359.1459384
   Douze M, 2008, TRECVID WORKSH 08
   He BS, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P260, DOI 10.1145/1454115.1454152
   Hua XS, 2004, IEEE IMAGE PROC, P685
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Karacs Kristof, 2010, 2010 12th International Workshop on Cellular Nanoscale Networks and their Applications (CNNA 2010)
   Liu JJ, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2501654.2501658
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Moise D., 2013, Proceedings of the 3rd ACM International conference on multimedia retrieval - ICMR'13, P17, DOI DOI 10.1145/2461466.2461470
   Owens JD, 2008, P IEEE, V96, P879, DOI 10.1109/JPROC.2008.917757
   Shalom SAA, 2008, LECT NOTES COMPUT SC, V5182, P166, DOI 10.1007/978-3-540-85836-2_16
   Shang L., 2010, Proceedings of the International Conference on Multimedia, P531
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song J., 2011, P 19 ACM INT C MULT, P423, DOI DOI 10.1145/2072298.2072354
   Stuart J. A., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P1068, DOI 10.1109/IPDPS.2011.102
   van de Sande KEA, 2011, IEEE T MULTIMEDIA, V13, P60, DOI 10.1109/TMM.2010.2091400
   Wang HL, 2012, INT CONF CLOUD COMP, DOI 10.1109/CloudCom.2012.6427595
   White B., 2010, MDMKDD, P9
   White T., 2010, Hadoop: The definitive guide
   Wu X, 2009, IEEE T MULTIMEDIA, V11, P196, DOI 10.1109/TMM.2008.2009673
   Yan R., 2009, P 1 ACM WORKSHOP LAR, P35, DOI DOI 10.1145/1631058.1631067
   Yibin Li, 2009, 2009 IEEE International Conference on Automation and Logistics (ICAL), P1957, DOI 10.1109/ICAL.2009.5262626
   Zhao WL, 2010, IEEE T MULTIMEDIA, V12, P448, DOI 10.1109/TMM.2010.2050651
NR 28
TC 10
Z9 10
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10515
EP 10534
DI 10.1007/s11042-014-2185-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700017
DA 2024-07-18
ER

PT J
AU Choe, G
   Wang, TJ
   Liu, F
   Li, G
   O, H
   Kim, S
AF Choe, Gwangmin
   Wang, Tianjiang
   Liu, Fang
   Li, Gwangho
   O, Hyongwang
   Kim, Songryong
TI Moving object tracking based on geogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geogram; Hybrid gradient descent; Mean shift; Similarity measure;
   Feature descriptor
ID SPATIOGRAMS; HISTOGRAMS
AB We introduce the concept of a geogram that captures richer features to represent the objects. The spatiogram contains some moments upon the coordinates of the pixels corresponding to each bin while the geogram contains information about the perimeter of grouped regions in addition to features in the spatiogram. The perimeter of the given region has capability to represent the geometrical compactness on the distribution of the given feature. The geogram-based feature descriptor increases the accuracy of tracking because it can capture the features in lower levels. Also, we consider that a convergence of the mean shift algorithm for the spatiogram is divided into obvious dynamic and steady states as well as in automatic control, and introduce a hybrid technique of the geogram and the histogram to control convergence process. Moreover, we derive a mean shift procedure for the proposed geogram. We test our feature descriptor and measure in object tracking scenario. Experimental results demonstrate that the geogram has promising discriminative capability in comparison with other ones.
C1 [Choe, Gwangmin; Wang, Tianjiang; Liu, Fang] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Intelligent & Distributed Comp Lab, Wuhan 430074, Peoples R China.
   [Li, Gwangho] Kim Il Sung Univ, Sch Comp Sci & Technol, Pyongyang, North Korea.
   [O, Hyongwang; Kim, Songryong] Acad Sci, Inst Math, Pyongyang, North Korea.
C3 Huazhong University of Science & Technology
RP Choe, G (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Intelligent & Distributed Comp Lab, Wuhan 430074, Peoples R China.
EM cca2005@foxmail.com; tjwang@hust.edu.cn; Fang.Liu@hust.edu.cn
CR [Anonymous], TECHNICAL REPORT
   Birchfield ST, 2005, PROC CVPR IEEE, P1158
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Conaire CO, 2007, INT CONF ACOUST SPEE, P1069
   Gong L, 2009, ACM T INTELL SYST TE
   Gong L., 2009, IEEE C COMP VIS PATT
   Gong L., 2009, ICME
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Matthews I, 2003, BRIT MACH VIS C
   Nefian AV, 2000, IEEE IMAGE PROC, P33, DOI 10.1109/ICIP.2000.900885
   Nilsson M, 2005, INT CONF ACOUST SPEE, P429
   Nilsson M, 2008, IEEE IMAGE PROC, P973, DOI 10.1109/ICIP.2008.4711919
   ULGES AU, 2006, TRECV 2006 WORKSH
   Yao AB, 2012, PATTERN RECOGN, V45, P2584, DOI 10.1016/j.patcog.2012.01.016
   Yao AB, 2010, PATTERN RECOGN, V43, P1244, DOI 10.1016/j.patcog.2009.09.024
NR 16
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9771
EP 9794
DI 10.1007/s11042-014-2150-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200033
DA 2024-07-18
ER

EF